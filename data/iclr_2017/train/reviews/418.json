{"conference": "ICLR 2017 conference submission", "title": "Unrolled Generative Adversarial Networks", "abstract": "We introduce a method to stabilize Generative Adversarial Networks (GANs) by defining the generator objective with respect to an unrolled optimization of the discriminator. This allows training to be adjusted between using the optimal discriminator in the generator's objective, which is ideal but infeasible in practice, and using the current value of the discriminator, which is often unstable and leads to poor solutions. We show how this technique solves the common problem of mode collapse, stabilizes training of GANs with complex recurrent generators, and increases diversity and coverage of the data distribution by the generator.", "histories": [], "reviews": [{"IS_META_REVIEW": true, "comments": "The paper presents an approach for tackling the instability problem that is present in generative adversarial networks. The general idea is to allow the generator to \"peek ahead\" at how the discriminator will evolve its decision boundary over-time with the premise that this information should prevent the generator from collapsing to produce only samples from a single mode of the data distribution.\n\nThis is a very well written paper that clearly motivates its attack on an important open issue. The experiments are well carried out and strongly support the presented idea. The pursued approach is substantially more elegant than current existing \"hacks\" that are commonly used to make GANs work in practice. I however have three main issues that let me partly doubt the success of the method. If these can be resolved this paper is a clear candidate for acceptance.\n\n1) I am not entirely convinced that the same effect cannot be obtained by the following procedure: simply train the discriminator for an extended number of K steps when updating the generator (say a number equivalent to the unrolling steps used in the current experiments) then, after the generator was updated undo the K updates to the discriminator and do 1 new update step instead. I only briefly glanced at your response to Reviewer2 which seems to imply you now tried something similar to this setup by stopping gradient flow at an appropriate point (although I think this is not exactly equivalent).\n2) I tried to reproduce the simple MNIST example but using a fully connected network instead of an RNN generator without much success. Even when unrolling the discriminator for 30-40 steps the generator still engages in mode seeking behavior or does not train at all. This could either be because of a bug in my implementation or because of some peculiarities of the RNN generator or because I did not use batch normalization anywhere. If it is one of the latter two this would entail a dependence of the proposed approach on specific forms of the discriminator and generator and should be discussed. My code can be found here"}, {"DATE": "06 Feb 2017", "TITLE": "ICLR committee final decision", "IS_META_REVIEW": false, "comments": "The main idea of this paper is clearly presented, and its empirical claims well-demonstrated. It improves our understanding of how to train GANs.", "OTHER_KEYS": "ICLR 2017 pcs"}, {"OTHER_KEYS": "ICLR 2017 conference AnonReviewer2", "TITLE": "Interesting approach, but evaluation leaving a lot to be desired", "comments": "This work introduces a novel method for training GANs by displacing simultaneous SGD, and unrolling the inner optimization in the minmax game as a computational graph. The paper is very clearly written, and explains the justification very well. The problem being attacked is very significant and important. The approach is novel, however, similar ideas have been tried to solve problems unrelated to GANs.\n\nThe first quantitative experiment is section 3.3.1, where the authors attempt to find the best z which can generate training examples. This is done by using L-BFGS on |G(z) - x|. The claim is that if we're able to find such a z, then the generator can generate this particular training example. It's demonstrated that 0-step GANs are not able to generate many training examples, while unrolled GANs do. However, I find this experiment unreasonable. Being able to find a certain z, which generates a certain sample does not guarantee that this particular mode is high probability. In fact, an identity function can potentially beat all the GAN models in the proposed metric. And due to Cantor's proof of equivalence between all powers of real spaces, this applies to smaller dimension of z as well. More realistically, it should be possible to generate *any* image from a generator by finding a very specific z. That a certain z exists which can generate a sample does not prove that the generator is not missing modes. It just proves that the generator is similar enough to an identity function to be able to generate any possible image. This metric is thus measuring something potentially tangential to diversity or mode-dropping. Another problem with this metric is that that showing that the optimization is not able to find a z for a specific training examples does not prove that such a z does not exist, only that it's harder to find. So, this comparison might just be showing that unrolled GANs have a smoother function than 0-step GANs, and thus easier to optimize for z.\n\nThe second quantitative experiment considers mean pairwise distance between generated samples, and between data samples. The first number is likely to be small in the case of a mode-dropping GAN. The authors argue that the two numbers being closer to each other is an indication of the generated samples being as diverse as the data. Once again, this metric is not convincing. 1. The distances are being measured in pixel-space. 2. A GAN model could be generating garbage, and yet still perform very well in this metric.\n\nThere are no other quantitative results in the paper. Even though the method is optimizing diversity, for a sanity check, scores for quality such as Inception scores or SSL performance would have been useful. Another metric that the authors can consider is training GAN using this approach on the tri-MNIST dataset (concatenation of 3 MNIST digits), which results in 1000 easily-identifiable modes. Then, demonstrate that the GAN is able to generate all the 1000 modes with equal probability. This is not a perfect metric either, but arguably much better than the metrics in this paper. This metric is used in this ICLR submission: ", "SOUNDNESS_CORRECTNESS": 5, "IS_ANNOTATED": true, "IS_META_REVIEW": false, "RECOMMENDATION": 7, "DATE": "17 Dec 2016 (modified: 15 Jan 2017)", "REVIEWER_CONFIDENCE": 5}, {"IMPACT": 4, "APPROPRIATENESS": 2, "RECOMMENDATION_UNOFFICIAL": 2, "OTHER_KEYS": "ICLR 2017 conference AnonReviewer3", "comments": "", "IS_ANNOTATED": true, "TITLE": "None", "IS_META_REVIEW": false, "DATE": "16 Dec 2016", "CLARITY": 2}, {"IMPACT": 4, "APPROPRIATENESS": 2, "RECOMMENDATION_UNOFFICIAL": 2, "OTHER_KEYS": "ICLR 2017 conference AnonReviewer3", "comments": "The paper presents an approach for tackling the instability problem that is present in generative adversarial networks. The general idea is to allow the generator to \"peek ahead\" at how the discriminator will evolve its decision boundary over-time with the premise that this information should prevent the generator from collapsing to produce only samples from a single mode of the data distribution.\n\nThis is a very well written paper that clearly motivates its attack on an important open issue. The experiments are well carried out and strongly support the presented idea. The pursued approach is substantially more elegant than current existing \"hacks\" that are commonly used to make GANs work in practice. I however have three main issues that let me partly doubt the success of the method. If these can be resolved this paper is a clear candidate for acceptance.\n\n1) I am not entirely convinced that the same effect cannot be obtained by the following procedure: simply train the discriminator for an extended number of K steps when updating the generator (say a number equivalent to the unrolling steps used in the current experiments) then, after the generator was updated undo the K updates to the discriminator and do 1 new update step instead. I only briefly glanced at your response to Reviewer2 which seems to imply you now tried something similar to this setup by stopping gradient flow at an appropriate point (although I think this is not exactly equivalent).\n2) I tried to reproduce the simple MNIST example but using a fully connected network instead of an RNN generator without much success. Even when unrolling the discriminator for 30-40 steps the generator still engages in mode seeking behavior or does not train at all. This could either be because of a bug in my implementation or because of some peculiarities of the RNN generator or because I did not use batch normalization anywhere. If it is one of the latter two this would entail a dependence of the proposed approach on specific forms of the discriminator and generator and should be discussed. My code can be found here ", "IS_ANNOTATED": true, "TITLE": "A nice idea for stabilizing GANs", "IS_META_REVIEW": false, "RECOMMENDATION": 7, "DATE": "16 Dec 2016 (modified: 20 Jan 2017)", "CLARITY": 2, "REVIEWER_CONFIDENCE": 5}, {"TITLE": "Excellent and important paper", "OTHER_KEYS": "ICLR 2017 conference AnonReviewer4", "comments": "The paper introduces a technique for stabilizing the training of Generative Adversrial Networks by unrolling the inner (discriminator) optimization in the GAN loss function several steps and optimizing the generator with respect to the final state of this optimization process.\nThe experimental evidence that this actually helps is very compelling: the 2d example shows a toy problem where this technique helps substantially, the LSTM MNIST generator example shows that the procedure helps with stabilizing the training of an unusual architecture of generator, and the image generation experiment, while not being definitive, is very convincing.\nFor future work it would be interesting to see whether a method with smaller memory requirements could be devised based on similar principles.\nI strongly recommend to accept this paper.", "IS_META_REVIEW": false, "RECOMMENDATION": 9, "DATE": "16 Dec 2016", "REVIEWER_CONFIDENCE": 5}, {"TITLE": "multi-discriminator baseline", "OTHER_KEYS": "ICLR 2017 conference AnonReviewer2", "comments": "", "SOUNDNESS_CORRECTNESS": 5, "IS_ANNOTATED": true, "IS_META_REVIEW": false, "DATE": "04 Dec 2016"}, {"DATE": "02 Dec 2016", "TITLE": "More information for replication of experiments", "IS_META_REVIEW": false, "comments": "It would be very helpful if there were some visual aids, such as some sort of neural network graph that shows how everything fits together for the purpose of more intuitive understanding of the techniques involved.", "OTHER_KEYS": "Antreas Antoniou"}, {"IS_META_REVIEW": true, "comments": "The paper presents an approach for tackling the instability problem that is present in generative adversarial networks. The general idea is to allow the generator to \"peek ahead\" at how the discriminator will evolve its decision boundary over-time with the premise that this information should prevent the generator from collapsing to produce only samples from a single mode of the data distribution.\n\nThis is a very well written paper that clearly motivates its attack on an important open issue. The experiments are well carried out and strongly support the presented idea. The pursued approach is substantially more elegant than current existing \"hacks\" that are commonly used to make GANs work in practice. I however have three main issues that let me partly doubt the success of the method. If these can be resolved this paper is a clear candidate for acceptance.\n\n1) I am not entirely convinced that the same effect cannot be obtained by the following procedure: simply train the discriminator for an extended number of K steps when updating the generator (say a number equivalent to the unrolling steps used in the current experiments) then, after the generator was updated undo the K updates to the discriminator and do 1 new update step instead. I only briefly glanced at your response to Reviewer2 which seems to imply you now tried something similar to this setup by stopping gradient flow at an appropriate point (although I think this is not exactly equivalent).\n2) I tried to reproduce the simple MNIST example but using a fully connected network instead of an RNN generator without much success. Even when unrolling the discriminator for 30-40 steps the generator still engages in mode seeking behavior or does not train at all. This could either be because of a bug in my implementation or because of some peculiarities of the RNN generator or because I did not use batch normalization anywhere. If it is one of the latter two this would entail a dependence of the proposed approach on specific forms of the discriminator and generator and should be discussed. My code can be found here"}, {"DATE": "06 Feb 2017", "TITLE": "ICLR committee final decision", "IS_META_REVIEW": false, "comments": "The main idea of this paper is clearly presented, and its empirical claims well-demonstrated. It improves our understanding of how to train GANs.", "OTHER_KEYS": "ICLR 2017 pcs"}, {"OTHER_KEYS": "ICLR 2017 conference AnonReviewer2", "TITLE": "Interesting approach, but evaluation leaving a lot to be desired", "comments": "This work introduces a novel method for training GANs by displacing simultaneous SGD, and unrolling the inner optimization in the minmax game as a computational graph. The paper is very clearly written, and explains the justification very well. The problem being attacked is very significant and important. The approach is novel, however, similar ideas have been tried to solve problems unrelated to GANs.\n\nThe first quantitative experiment is section 3.3.1, where the authors attempt to find the best z which can generate training examples. This is done by using L-BFGS on |G(z) - x|. The claim is that if we're able to find such a z, then the generator can generate this particular training example. It's demonstrated that 0-step GANs are not able to generate many training examples, while unrolled GANs do. However, I find this experiment unreasonable. Being able to find a certain z, which generates a certain sample does not guarantee that this particular mode is high probability. In fact, an identity function can potentially beat all the GAN models in the proposed metric. And due to Cantor's proof of equivalence between all powers of real spaces, this applies to smaller dimension of z as well. More realistically, it should be possible to generate *any* image from a generator by finding a very specific z. That a certain z exists which can generate a sample does not prove that the generator is not missing modes. It just proves that the generator is similar enough to an identity function to be able to generate any possible image. This metric is thus measuring something potentially tangential to diversity or mode-dropping. Another problem with this metric is that that showing that the optimization is not able to find a z for a specific training examples does not prove that such a z does not exist, only that it's harder to find. So, this comparison might just be showing that unrolled GANs have a smoother function than 0-step GANs, and thus easier to optimize for z.\n\nThe second quantitative experiment considers mean pairwise distance between generated samples, and between data samples. The first number is likely to be small in the case of a mode-dropping GAN. The authors argue that the two numbers being closer to each other is an indication of the generated samples being as diverse as the data. Once again, this metric is not convincing. 1. The distances are being measured in pixel-space. 2. A GAN model could be generating garbage, and yet still perform very well in this metric.\n\nThere are no other quantitative results in the paper. Even though the method is optimizing diversity, for a sanity check, scores for quality such as Inception scores or SSL performance would have been useful. Another metric that the authors can consider is training GAN using this approach on the tri-MNIST dataset (concatenation of 3 MNIST digits), which results in 1000 easily-identifiable modes. Then, demonstrate that the GAN is able to generate all the 1000 modes with equal probability. This is not a perfect metric either, but arguably much better than the metrics in this paper. This metric is used in this ICLR submission: ", "SOUNDNESS_CORRECTNESS": 5, "IS_ANNOTATED": true, "IS_META_REVIEW": false, "RECOMMENDATION": 7, "DATE": "17 Dec 2016 (modified: 15 Jan 2017)", "REVIEWER_CONFIDENCE": 5}, {"IMPACT": 4, "APPROPRIATENESS": 2, "RECOMMENDATION_UNOFFICIAL": 2, "OTHER_KEYS": "ICLR 2017 conference AnonReviewer3", "comments": "", "IS_ANNOTATED": true, "TITLE": "None", "IS_META_REVIEW": false, "DATE": "16 Dec 2016", "CLARITY": 2}, {"IMPACT": 4, "APPROPRIATENESS": 2, "RECOMMENDATION_UNOFFICIAL": 2, "OTHER_KEYS": "ICLR 2017 conference AnonReviewer3", "comments": "The paper presents an approach for tackling the instability problem that is present in generative adversarial networks. The general idea is to allow the generator to \"peek ahead\" at how the discriminator will evolve its decision boundary over-time with the premise that this information should prevent the generator from collapsing to produce only samples from a single mode of the data distribution.\n\nThis is a very well written paper that clearly motivates its attack on an important open issue. The experiments are well carried out and strongly support the presented idea. The pursued approach is substantially more elegant than current existing \"hacks\" that are commonly used to make GANs work in practice. I however have three main issues that let me partly doubt the success of the method. If these can be resolved this paper is a clear candidate for acceptance.\n\n1) I am not entirely convinced that the same effect cannot be obtained by the following procedure: simply train the discriminator for an extended number of K steps when updating the generator (say a number equivalent to the unrolling steps used in the current experiments) then, after the generator was updated undo the K updates to the discriminator and do 1 new update step instead. I only briefly glanced at your response to Reviewer2 which seems to imply you now tried something similar to this setup by stopping gradient flow at an appropriate point (although I think this is not exactly equivalent).\n2) I tried to reproduce the simple MNIST example but using a fully connected network instead of an RNN generator without much success. Even when unrolling the discriminator for 30-40 steps the generator still engages in mode seeking behavior or does not train at all. This could either be because of a bug in my implementation or because of some peculiarities of the RNN generator or because I did not use batch normalization anywhere. If it is one of the latter two this would entail a dependence of the proposed approach on specific forms of the discriminator and generator and should be discussed. My code can be found here ", "IS_ANNOTATED": true, "TITLE": "A nice idea for stabilizing GANs", "IS_META_REVIEW": false, "RECOMMENDATION": 7, "DATE": "16 Dec 2016 (modified: 20 Jan 2017)", "CLARITY": 2, "REVIEWER_CONFIDENCE": 5}, {"TITLE": "Excellent and important paper", "OTHER_KEYS": "ICLR 2017 conference AnonReviewer4", "comments": "The paper introduces a technique for stabilizing the training of Generative Adversrial Networks by unrolling the inner (discriminator) optimization in the GAN loss function several steps and optimizing the generator with respect to the final state of this optimization process.\nThe experimental evidence that this actually helps is very compelling: the 2d example shows a toy problem where this technique helps substantially, the LSTM MNIST generator example shows that the procedure helps with stabilizing the training of an unusual architecture of generator, and the image generation experiment, while not being definitive, is very convincing.\nFor future work it would be interesting to see whether a method with smaller memory requirements could be devised based on similar principles.\nI strongly recommend to accept this paper.", "IS_META_REVIEW": false, "RECOMMENDATION": 9, "DATE": "16 Dec 2016", "REVIEWER_CONFIDENCE": 5}, {"TITLE": "multi-discriminator baseline", "OTHER_KEYS": "ICLR 2017 conference AnonReviewer2", "comments": "", "SOUNDNESS_CORRECTNESS": 5, "IS_ANNOTATED": true, "IS_META_REVIEW": false, "DATE": "04 Dec 2016"}, {"DATE": "02 Dec 2016", "TITLE": "More information for replication of experiments", "IS_META_REVIEW": false, "comments": "It would be very helpful if there were some visual aids, such as some sort of neural network graph that shows how everything fits together for the purpose of more intuitive understanding of the techniques involved.", "OTHER_KEYS": "Antreas Antoniou"}], "authors": "Luke Metz, Ben Poole, David Pfau, Jascha Sohl-Dickstein", "accepted": true, "id": "418"}