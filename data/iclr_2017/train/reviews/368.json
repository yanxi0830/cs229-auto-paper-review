{"conference": "ICLR 2017 conference submission", "title": "On the Quantitative Analysis of Decoder-Based Generative Models", "abstract": "The past several years have seen remarkable progress in generative models which produce convincing samples of images and other modalities. A shared component of some popular models such as generative adversarial networks and generative moment matching networks, is a decoder network, a parametric deep neural net that defines a generative distribution. Unfortunately, it can be difficult to quantify the performance of these models because of the intractability of log-likelihood estimation, and inspecting samples can be misleading. We propose to use Annealed Importance Sampling for evaluating log-likelihoods for decoder-based models and validate its accuracy using bidirectional Monte Carlo. Using this technique, we analyze the performance of decoder-based models, the effectiveness of existing log-likelihood estimators, the degree of overfitting, and the degree to which these models miss important modes of the data distribution.", "histories": [], "reviews": [{"IS_META_REVIEW": true, "comments": "The paper describes a method to evaluate generative models such as VAE, GAN and GMMN. This is very much needed in our community where we still eyeball generated images to judge the quality of a model. However, the technical increment over the NIPS 16 paper: \u201cMeasuring the reliability of MCMC inference with bidirectional Monte Carlo\u201d is very small, or nonexistent (but please correct me if I am wrong!).  (Grosse et al). The relative contribution of this paper is the application of this method to generative models. \nIn section 2.3 the authors seem to make a mistake. They write E[p\u2019(x)] <= p(x) but I think they mean: E[log p\u2019(x)] <= log E[p\u2019(x)] = log p(x). Also,  for what value of x? If p(x) is normalized it can\u2019t be true for all values of x. Anyways, I think there are typos here and there and the equations could be more precise.\nOn page 5 top of the page it is said that the AIS procedure can be initialized with q(z|x) instead of p(z). However, it is unclear what value of x is then picked? Is it perhaps Ep(x)[q(z|x)] ?\nI am confused with the use of the term overfitting (p8 bottom). Does a model A overfit relative to a another model B if the test accuracy of A is higher than that of B even though the gap between train and test accuracy is also higher for B than for A. I think not. Perhaps the last sentence on page 8 should say that VAE-50 underfits less than GMMN-50?\nThe experimental results are interesting in that it exposes the fact that GANs and GMMNs seem to have much lover test accuracy than VAE despite the fact that their samples look great."}, {"DATE": "06 Feb 2017", "TITLE": "ICLR committee final decision", "IS_META_REVIEW": false, "comments": "This paper describes a method to estimate likelihood scores for a range of models defined by a decoder.\n \n This work has some issues. The paper mainly applies existing ideas. As discussed on openreview, the isotropic Gaussian noise model used to create a model with a likelihood is questionable, and it's unclear how useful likelihoods are when models are obviously wrong. However, the results, lead to some interesting conclusions, and on balance this is a good paper.", "OTHER_KEYS": "ICLR 2017 pcs"}, {"DATE": "05 Feb 2017", "TITLE": "Adaptive HMC implementation and Gaussian decoder model", "IS_META_REVIEW": false, "comments": "Thanks for the interesting paper.\n\nI have a couple of queries / comments:\n\nIn the code you provide at ", "OTHER_KEYS": "Matt Graham"}, {"DATE": "01 Jan 2017", "TITLE": "A new version of the paper is updated", "IS_META_REVIEW": false, "comments": "A new version of the paper is updated. We revised the section 2.2 on the introduction to AIS, and several other places according to reviewers' comments.", "OTHER_KEYS": "Yuhuai Wu"}, {"DATE": "29 Dec 2016", "TITLE": "Comments", "IS_META_REVIEW": false, "comments": "I have mixed opinions about this work.\n\nOn the one hand I think it does a really nice job at providing a simple method to evaluate mode dropping and overfitting in generative models, which is one of the most important problems in machine learning now. I can see myself and many more people using these ideas to evaluate aspects of generative models\n\nOn the other hand, there is a constant use of the term \"log-likelihood for GANs\", which is extremely misleading. The log-likelihood of GANs is obviously ill-defined, and the assumption of \"Gaussian observation\" is incredibly false, since the true after-sampling variance that GANs are trained on is 0. You should relate how the model with noise added relates to properties on the actual distribution induced by the generator with no gaussian noise, instead of assuming the generator has Gaussian noise in the end, which is obviously false for a GAN and true for a VAE (which is trained this way since the reconstruction error assumes this kind of noise). I'm not asking for a precise mathematical statement of this relation, but I do think the writing sweeps this issue under the carpet, and the addition of isotropic noise on a distribution with an incredibly complex covariance matrix is more than questionable.\n\nAs a final note, I think section 2.2 which describes the central algorithm is very poorly written. After reading the section several times I have no idea how to implement it or how the sampling process is defined in the end. In my opinion, you should try to describe better:\n\n- Which is the sampling distribution of the estimate of p(x) at time t. I believe this is p(x) = E_{z ~ p_t(z)} [ p(x | z) p(z) / p_t(z) ] but I'm far from sure.\n- Explain why the successive estimator's are unbiased (if it's in the above form this is trivial)\n- Explain why the estimators have less variance as t -> T.\n- Explain what the theoretical guarantees of AIS are.\n\nMinor:\n- Typo in line 5 of page 4, \"produces\" -> \"produce\"\n- I appreciate the wall clock times in figure 2.\n\nOverall I think this is a cool paper, with some great consequences, but I think some issues (especially writing) should be polished.", "OTHER_KEYS": "Martin Arjovsky"}, {"TITLE": "Interesting work, their evaluation framework is available online, good contribution to the community ", "SUBSTANCE": 4, "RECOMMENDATION_UNOFFICIAL": 5, "OTHER_KEYS": "ICLR 2017 conference AnonReviewer3", "comments": "# Review\nThis paper proposes a quantitative evaluation for decoder-based generative models that use Annealed Importance Sampling (AIS) to estimate log-likelihoods. Quantitative evaluations are indeed much needed since for some models, like Generative Adversarial Networks (GANs) and Generative Moment Matching Networks (GMMNs), qualitative evaluation of samples is still frequently used to assess their generative capability. Even though, there exist quantitative evaluations like Kernel Density Estimation (KDE), the authors show how AIS is more accurate than KDE and how it can be used to perform fine-grained comparison between generative models (GAN, GMMs and Variational Autoencoders (VAE)).\n\nThe authors report empirical results comparing two different decoder architectures that were both trained, on the continuous MNIST dataset, using the VAE, GAN and GMMN objectives. They also trained an Importance Weighted Autoencoder (IWAE) on binarized MNIST and show that, in this case, the IWAE bound underestimates the true log-likelihoods by at least 1 nat (which is significant for this dataset) according to the AIS evaluation of the same model.\n\n\n# Pros\nTheir evaluation framework is public and is definitely a nice contribution to the community.\n\nThis paper gives some insights about how GAN behaves from log-likelihood perspective. The authors disconfirm the commonly proposed hypothesis that GAN are memorizing training data. The authors also observed that GANs miss important modes of the data distribution.\n\n\n# Cons/Questions\nIt is not clear for me why sometimes the experiments were done using different number of examples (100, 1000, 10000) coming from different sources (trainset, validset, testset or simulation/generated by the model). For instance, in Table 2 why results were not reported using all 10,000 examples of the testing set?\n\nIt is not clear why in Figure 2c, AIS is slower than AIS+encoder? Is the number of intermediate distributions the same in both?\n\n16 independent chains for AIS seems a bit low from what I saw in the literature (e.g. in [Salakhutdinov & Murray, 2008] or [Desjardins etal., 2011], they used 100 chains). Could it be that increasing the number of chains helps tighten the confidence interval reported in Table 2?\n\nI would have like the authors to give their intuitions as to why GAN50 has a BDMC gap of 10 nats, i.e. 1 order of magnitude compared to the others?\n\n\n# Minor comments\nTable 1 is not referenced in the text and lacks description of what the different columns represent.\nFigure 2(a), are the reported values represents the average log-likelihood of 100 (each or total?) training and validation examples of MNIST (as described in Section 5.3.2).\nFigure 2(c), I'm guessing it is on binarized MNIST? Also, why are there fewer points for AIS compared to IWAE and AIS+encoder?\nAre the BDMC gaps mentioned in Section 5.3.1 the same as the ones reported in Table2 ?\nTypo in caption of Figure 3: \"(c) GMMN-10\" but actually showing GMMN-50 according to the graph title and subcaption.", "ORIGINALITY": 3, "IS_ANNOTATED": true, "IS_META_REVIEW": false, "RECOMMENDATION": 7, "DATE": "17 Dec 2016", "REVIEWER_CONFIDENCE": 4}, {"TITLE": "Great empirical work", "OTHER_KEYS": "ICLR 2017 conference AnonReviewer2", "comments": "Summary:\nThis paper describes how to estimate log-likelihoods of currently popular decoder-based generative models using annealed importance sampling (AIS) and HMC. It validates the method using bidirectional Monte Carlo on the example of MNIST, and compares the performance of GANs and VAEs.\n\n\nReview:\nAlthough this seems like a fairly straight-forward application of AIS to me (correct me if I missed an important trick to make this work), I very much appreciate the educational value and empirical contributions of this paper. It should lead to clarity in debates around the density estimation performance of GANs, and should enable more people to use AIS.\n\nSpace permitting, it might be a good idea to try to expand the description of AIS. All the components of AIS are mentioned and a basic description of the algorithm is given, but the paper doesn\u2019t explain well \u201cwhy\u201d the algorithm does what it does/why it works.\n\nI was initially confused by the widely different numbers in Figure 2. On first glance my expectation was that this Figure is comparing GAN, GMMN and IWAE (because of the labeling at the bottom and because of the leading words in the caption\u2019s descriptions). Perhaps mention in the caption that (a) and (b) use continuous MNIST and (c) uses discrete MNIST. \u201cGMMN-50\u201d should probably be \u201cGMMN-10\u201d.\n\n\nUsing reconstructions for evaluation of models may be a necessary but is not sufficient condition for a good model. Depending on the likelihood, a posterior sample might have very low density under the prior, for example. It would be great if the authors could point out and discuss the limitations of this test a bit more.\n\n\nMinor:\n\nPerhaps add a reference to MacKay\u2019s density networks (MacKay, 1995) for decoder-based generative models.\n\nIn Section 2.2, the authors write \u201cthe prior over z can be drastically different than the true posterior p(z|x), especially in high dimension\u201d. I think the flow of the paper could be improved here, especially for people less familiar with importance sampling/AIS. I don\u2019t think the relevance of the posterior for importance sampling is clear at this point in the paper.\n\nIn Section 2.3 the authors claim that is often more \u201cmeaningful\u201d to estimate p(x) in log-space because of underflow problems. \u201cMeaningful\u201d seems like the wrong word here. Perhaps revise to say that it\u2019s more practical to estimate log p(x) because of underflow problems, or to say that it\u2019s more meaningful to estimate log p(x) because of its connection to compression/surprise/entropy.", "IS_META_REVIEW": false, "RECOMMENDATION": 7, "DATE": "16 Dec 2016", "REVIEWER_CONFIDENCE": 4}, {"SUBSTANCE": 4, "OTHER_KEYS": "ICLR 2017 conference AnonReviewer4", "TITLE": "Application of BDMCMC to generative models. Relative contribution small. ", "comments": "The paper describes a method to evaluate generative models such as VAE, GAN and GMMN. This is very much needed in our community where we still eyeball generated images to judge the quality of a model. However, the technical increment over the NIPS 16 paper: \u201cMeasuring the reliability of MCMC inference with bidirectional Monte Carlo\u201d is very small, or nonexistent (but please correct me if I am wrong!).  (Grosse et al). The relative contribution of this paper is the application of this method to generative models. \nIn section 2.3 the authors seem to make a mistake. They write E[p\u2019(x)] <= p(x) but I think they mean: E[log p\u2019(x)] <= log E[p\u2019(x)] = log p(x). Also,  for what value of x? If p(x) is normalized it can\u2019t be true for all values of x. Anyways, I think there are typos here and there and the equations could be more precise.\nOn page 5 top of the page it is said that the AIS procedure can be initialized with q(z|x) instead of p(z). However, it is unclear what value of x is then picked? Is it perhaps Ep(x)[q(z|x)] ?\nI am confused with the use of the term overfitting (p8 bottom). Does a model A overfit relative to a another model B if the test accuracy of A is higher than that of B even though the gap between train and test accuracy is also higher for B than for A. I think not. Perhaps the last sentence on page 8 should say that VAE-50 underfits less than GMMN-50?\nThe experimental results are interesting in that it exposes the fact that GANs and GMMNs seem to have much lover test accuracy than VAE despite the fact that their samples look great. \n", "IS_ANNOTATED": true, "IS_META_REVIEW": false, "RECOMMENDATION": 6, "DATE": "14 Dec 2016", "REVIEWER_CONFIDENCE": 5}, {"DATE": "05 Dec 2016", "TITLE": "log-likelihood", "IS_META_REVIEW": false, "comments": "Very interesting paper to read. But I am a little confused that marginal log-likelihood (log p_\\theta(x)) shown in this paper is usually more than 200, while the log p(x) shown in variational auto-encoder on mnist  is usually around -100(Both on 50 dimensions of VAE).  Does your paper show the same log p_\\theta(x) as that in VAE?\n\nAppreciate if you could solve my puzzle. Thanks.  ", "OTHER_KEYS": "(anonymous)"}, {"TITLE": "Geometric average; GPU implementation of WAE and KDE", "SUBSTANCE": 4, "OTHER_KEYS": "ICLR 2017 conference AnonReviewer3", "RECOMMENDATION_UNOFFICIAL": 5, "comments": "", "ORIGINALITY": 3, "IS_ANNOTATED": true, "IS_META_REVIEW": false, "DATE": "02 Dec 2016"}, {"DATE": "02 Dec 2016", "TITLE": "\"Running the decoder\"", "IS_META_REVIEW": false, "comments": "", "OTHER_KEYS": "ICLR 2017 conference AnonReviewer2"}, {"IS_META_REVIEW": true, "comments": "The paper describes a method to evaluate generative models such as VAE, GAN and GMMN. This is very much needed in our community where we still eyeball generated images to judge the quality of a model. However, the technical increment over the NIPS 16 paper: \u201cMeasuring the reliability of MCMC inference with bidirectional Monte Carlo\u201d is very small, or nonexistent (but please correct me if I am wrong!).  (Grosse et al). The relative contribution of this paper is the application of this method to generative models. \nIn section 2.3 the authors seem to make a mistake. They write E[p\u2019(x)] <= p(x) but I think they mean: E[log p\u2019(x)] <= log E[p\u2019(x)] = log p(x). Also,  for what value of x? If p(x) is normalized it can\u2019t be true for all values of x. Anyways, I think there are typos here and there and the equations could be more precise.\nOn page 5 top of the page it is said that the AIS procedure can be initialized with q(z|x) instead of p(z). However, it is unclear what value of x is then picked? Is it perhaps Ep(x)[q(z|x)] ?\nI am confused with the use of the term overfitting (p8 bottom). Does a model A overfit relative to a another model B if the test accuracy of A is higher than that of B even though the gap between train and test accuracy is also higher for B than for A. I think not. Perhaps the last sentence on page 8 should say that VAE-50 underfits less than GMMN-50?\nThe experimental results are interesting in that it exposes the fact that GANs and GMMNs seem to have much lover test accuracy than VAE despite the fact that their samples look great."}, {"DATE": "06 Feb 2017", "TITLE": "ICLR committee final decision", "IS_META_REVIEW": false, "comments": "This paper describes a method to estimate likelihood scores for a range of models defined by a decoder.\n \n This work has some issues. The paper mainly applies existing ideas. As discussed on openreview, the isotropic Gaussian noise model used to create a model with a likelihood is questionable, and it's unclear how useful likelihoods are when models are obviously wrong. However, the results, lead to some interesting conclusions, and on balance this is a good paper.", "OTHER_KEYS": "ICLR 2017 pcs"}, {"DATE": "05 Feb 2017", "TITLE": "Adaptive HMC implementation and Gaussian decoder model", "IS_META_REVIEW": false, "comments": "Thanks for the interesting paper.\n\nI have a couple of queries / comments:\n\nIn the code you provide at ", "OTHER_KEYS": "Matt Graham"}, {"DATE": "01 Jan 2017", "TITLE": "A new version of the paper is updated", "IS_META_REVIEW": false, "comments": "A new version of the paper is updated. We revised the section 2.2 on the introduction to AIS, and several other places according to reviewers' comments.", "OTHER_KEYS": "Yuhuai Wu"}, {"DATE": "29 Dec 2016", "TITLE": "Comments", "IS_META_REVIEW": false, "comments": "I have mixed opinions about this work.\n\nOn the one hand I think it does a really nice job at providing a simple method to evaluate mode dropping and overfitting in generative models, which is one of the most important problems in machine learning now. I can see myself and many more people using these ideas to evaluate aspects of generative models\n\nOn the other hand, there is a constant use of the term \"log-likelihood for GANs\", which is extremely misleading. The log-likelihood of GANs is obviously ill-defined, and the assumption of \"Gaussian observation\" is incredibly false, since the true after-sampling variance that GANs are trained on is 0. You should relate how the model with noise added relates to properties on the actual distribution induced by the generator with no gaussian noise, instead of assuming the generator has Gaussian noise in the end, which is obviously false for a GAN and true for a VAE (which is trained this way since the reconstruction error assumes this kind of noise). I'm not asking for a precise mathematical statement of this relation, but I do think the writing sweeps this issue under the carpet, and the addition of isotropic noise on a distribution with an incredibly complex covariance matrix is more than questionable.\n\nAs a final note, I think section 2.2 which describes the central algorithm is very poorly written. After reading the section several times I have no idea how to implement it or how the sampling process is defined in the end. In my opinion, you should try to describe better:\n\n- Which is the sampling distribution of the estimate of p(x) at time t. I believe this is p(x) = E_{z ~ p_t(z)} [ p(x | z) p(z) / p_t(z) ] but I'm far from sure.\n- Explain why the successive estimator's are unbiased (if it's in the above form this is trivial)\n- Explain why the estimators have less variance as t -> T.\n- Explain what the theoretical guarantees of AIS are.\n\nMinor:\n- Typo in line 5 of page 4, \"produces\" -> \"produce\"\n- I appreciate the wall clock times in figure 2.\n\nOverall I think this is a cool paper, with some great consequences, but I think some issues (especially writing) should be polished.", "OTHER_KEYS": "Martin Arjovsky"}, {"TITLE": "Interesting work, their evaluation framework is available online, good contribution to the community ", "SUBSTANCE": 4, "RECOMMENDATION_UNOFFICIAL": 5, "OTHER_KEYS": "ICLR 2017 conference AnonReviewer3", "comments": "# Review\nThis paper proposes a quantitative evaluation for decoder-based generative models that use Annealed Importance Sampling (AIS) to estimate log-likelihoods. Quantitative evaluations are indeed much needed since for some models, like Generative Adversarial Networks (GANs) and Generative Moment Matching Networks (GMMNs), qualitative evaluation of samples is still frequently used to assess their generative capability. Even though, there exist quantitative evaluations like Kernel Density Estimation (KDE), the authors show how AIS is more accurate than KDE and how it can be used to perform fine-grained comparison between generative models (GAN, GMMs and Variational Autoencoders (VAE)).\n\nThe authors report empirical results comparing two different decoder architectures that were both trained, on the continuous MNIST dataset, using the VAE, GAN and GMMN objectives. They also trained an Importance Weighted Autoencoder (IWAE) on binarized MNIST and show that, in this case, the IWAE bound underestimates the true log-likelihoods by at least 1 nat (which is significant for this dataset) according to the AIS evaluation of the same model.\n\n\n# Pros\nTheir evaluation framework is public and is definitely a nice contribution to the community.\n\nThis paper gives some insights about how GAN behaves from log-likelihood perspective. The authors disconfirm the commonly proposed hypothesis that GAN are memorizing training data. The authors also observed that GANs miss important modes of the data distribution.\n\n\n# Cons/Questions\nIt is not clear for me why sometimes the experiments were done using different number of examples (100, 1000, 10000) coming from different sources (trainset, validset, testset or simulation/generated by the model). For instance, in Table 2 why results were not reported using all 10,000 examples of the testing set?\n\nIt is not clear why in Figure 2c, AIS is slower than AIS+encoder? Is the number of intermediate distributions the same in both?\n\n16 independent chains for AIS seems a bit low from what I saw in the literature (e.g. in [Salakhutdinov & Murray, 2008] or [Desjardins etal., 2011], they used 100 chains). Could it be that increasing the number of chains helps tighten the confidence interval reported in Table 2?\n\nI would have like the authors to give their intuitions as to why GAN50 has a BDMC gap of 10 nats, i.e. 1 order of magnitude compared to the others?\n\n\n# Minor comments\nTable 1 is not referenced in the text and lacks description of what the different columns represent.\nFigure 2(a), are the reported values represents the average log-likelihood of 100 (each or total?) training and validation examples of MNIST (as described in Section 5.3.2).\nFigure 2(c), I'm guessing it is on binarized MNIST? Also, why are there fewer points for AIS compared to IWAE and AIS+encoder?\nAre the BDMC gaps mentioned in Section 5.3.1 the same as the ones reported in Table2 ?\nTypo in caption of Figure 3: \"(c) GMMN-10\" but actually showing GMMN-50 according to the graph title and subcaption.", "ORIGINALITY": 3, "IS_ANNOTATED": true, "IS_META_REVIEW": false, "RECOMMENDATION": 7, "DATE": "17 Dec 2016", "REVIEWER_CONFIDENCE": 4}, {"TITLE": "Great empirical work", "OTHER_KEYS": "ICLR 2017 conference AnonReviewer2", "comments": "Summary:\nThis paper describes how to estimate log-likelihoods of currently popular decoder-based generative models using annealed importance sampling (AIS) and HMC. It validates the method using bidirectional Monte Carlo on the example of MNIST, and compares the performance of GANs and VAEs.\n\n\nReview:\nAlthough this seems like a fairly straight-forward application of AIS to me (correct me if I missed an important trick to make this work), I very much appreciate the educational value and empirical contributions of this paper. It should lead to clarity in debates around the density estimation performance of GANs, and should enable more people to use AIS.\n\nSpace permitting, it might be a good idea to try to expand the description of AIS. All the components of AIS are mentioned and a basic description of the algorithm is given, but the paper doesn\u2019t explain well \u201cwhy\u201d the algorithm does what it does/why it works.\n\nI was initially confused by the widely different numbers in Figure 2. On first glance my expectation was that this Figure is comparing GAN, GMMN and IWAE (because of the labeling at the bottom and because of the leading words in the caption\u2019s descriptions). Perhaps mention in the caption that (a) and (b) use continuous MNIST and (c) uses discrete MNIST. \u201cGMMN-50\u201d should probably be \u201cGMMN-10\u201d.\n\n\nUsing reconstructions for evaluation of models may be a necessary but is not sufficient condition for a good model. Depending on the likelihood, a posterior sample might have very low density under the prior, for example. It would be great if the authors could point out and discuss the limitations of this test a bit more.\n\n\nMinor:\n\nPerhaps add a reference to MacKay\u2019s density networks (MacKay, 1995) for decoder-based generative models.\n\nIn Section 2.2, the authors write \u201cthe prior over z can be drastically different than the true posterior p(z|x), especially in high dimension\u201d. I think the flow of the paper could be improved here, especially for people less familiar with importance sampling/AIS. I don\u2019t think the relevance of the posterior for importance sampling is clear at this point in the paper.\n\nIn Section 2.3 the authors claim that is often more \u201cmeaningful\u201d to estimate p(x) in log-space because of underflow problems. \u201cMeaningful\u201d seems like the wrong word here. Perhaps revise to say that it\u2019s more practical to estimate log p(x) because of underflow problems, or to say that it\u2019s more meaningful to estimate log p(x) because of its connection to compression/surprise/entropy.", "IS_META_REVIEW": false, "RECOMMENDATION": 7, "DATE": "16 Dec 2016", "REVIEWER_CONFIDENCE": 4}, {"SUBSTANCE": 4, "OTHER_KEYS": "ICLR 2017 conference AnonReviewer4", "TITLE": "Application of BDMCMC to generative models. Relative contribution small. ", "comments": "The paper describes a method to evaluate generative models such as VAE, GAN and GMMN. This is very much needed in our community where we still eyeball generated images to judge the quality of a model. However, the technical increment over the NIPS 16 paper: \u201cMeasuring the reliability of MCMC inference with bidirectional Monte Carlo\u201d is very small, or nonexistent (but please correct me if I am wrong!).  (Grosse et al). The relative contribution of this paper is the application of this method to generative models. \nIn section 2.3 the authors seem to make a mistake. They write E[p\u2019(x)] <= p(x) but I think they mean: E[log p\u2019(x)] <= log E[p\u2019(x)] = log p(x). Also,  for what value of x? If p(x) is normalized it can\u2019t be true for all values of x. Anyways, I think there are typos here and there and the equations could be more precise.\nOn page 5 top of the page it is said that the AIS procedure can be initialized with q(z|x) instead of p(z). However, it is unclear what value of x is then picked? Is it perhaps Ep(x)[q(z|x)] ?\nI am confused with the use of the term overfitting (p8 bottom). Does a model A overfit relative to a another model B if the test accuracy of A is higher than that of B even though the gap between train and test accuracy is also higher for B than for A. I think not. Perhaps the last sentence on page 8 should say that VAE-50 underfits less than GMMN-50?\nThe experimental results are interesting in that it exposes the fact that GANs and GMMNs seem to have much lover test accuracy than VAE despite the fact that their samples look great. \n", "IS_ANNOTATED": true, "IS_META_REVIEW": false, "RECOMMENDATION": 6, "DATE": "14 Dec 2016", "REVIEWER_CONFIDENCE": 5}, {"DATE": "05 Dec 2016", "TITLE": "log-likelihood", "IS_META_REVIEW": false, "comments": "Very interesting paper to read. But I am a little confused that marginal log-likelihood (log p_\\theta(x)) shown in this paper is usually more than 200, while the log p(x) shown in variational auto-encoder on mnist  is usually around -100(Both on 50 dimensions of VAE).  Does your paper show the same log p_\\theta(x) as that in VAE?\n\nAppreciate if you could solve my puzzle. Thanks.  ", "OTHER_KEYS": "(anonymous)"}, {"TITLE": "Geometric average; GPU implementation of WAE and KDE", "SUBSTANCE": 4, "OTHER_KEYS": "ICLR 2017 conference AnonReviewer3", "RECOMMENDATION_UNOFFICIAL": 5, "comments": "", "ORIGINALITY": 3, "IS_ANNOTATED": true, "IS_META_REVIEW": false, "DATE": "02 Dec 2016"}, {"DATE": "02 Dec 2016", "TITLE": "\"Running the decoder\"", "IS_META_REVIEW": false, "comments": "", "OTHER_KEYS": "ICLR 2017 conference AnonReviewer2"}], "authors": "Yuhuai Wu, Yuri Burda, Ruslan Salakhutdinov, Roger Grosse", "accepted": true, "id": "368"}