{"conference": "ICLR 2017 conference submission", "title": "Learning to Query, Reason, and Answer Questions On Ambiguous Texts", "abstract": "A key goal of research in conversational systems is to train an interactive agent to help a user with a task. Human conversation, however, is notoriously incomplete, ambiguous, and full of extraneous detail. To operate effectively, the agent must not only understand what was explicitly conveyed but also be able to reason in the presence of missing or unclear information. When unable to resolve ambiguities on its own, the agent must be able to ask the user for the necessary clarifications and incorporate the response in its reasoning. Motivated by this problem we introduce QRAQ (\"crack\"; Query, Reason, and Answer Questions), a new synthetic domain, in which a User gives an Agent a short story and asks a challenge question. These problems are designed to test the reasoning and interaction capabilities of a learning-based Agent in a setting that requires multiple conversational turns. A good Agent should ask only non-deducible, relevant questions until it has enough information to correctly answer the User's question. We use standard and improved reinforcement learning based memory-network architectures to solve QRAQ problems in the difficult setting where the reward signal only tells the Agent if its final answer to the challenge question is correct or not. To provide an upper-bound to the RL results we also train the same architectures using supervised information that tells the Agent during training which variables to query and the answer to the challenge question. We evaluate our architectures on four QRAQ dataset types, and scale the complexity for each along multiple dimensions.", "histories": [], "reviews": [{"DATE": "06 Feb 2017", "TITLE": "ICLR committee final decision", "IS_META_REVIEW": false, "comments": "The program committee appreciates the authors' response to concerns raised in the reviews. While there are some concerns with the paper that the authors are strongly encouraged to address for the final version of the paper, overall, the work has contributions that are worth presenting at ICLR.", "OTHER_KEYS": "ICLR 2017 pcs"}, {"DATE": "27 Dec 2016", "TITLE": "Thanks to all the reviewers!", "IS_META_REVIEW": false, "comments": "Happy holidays and thank you all for your careful reading and thoughtful, constructive comments!\n\nA few responses to your last set of comments/questions:\n\nTo Reviewer 3:\n\nWe definitely agree that because of the limited vocabulary and grammar, this is more about reasoning than language.  As you point out, the interaction in these problems  boils down to repeated variable queries until the Agent decides it has enough info.  We decided on the term \"interaction\" to differentiate our problems from the bAbI problems, which are 1 shot question answering, and to emphasize the idea that, although simplified, this has the same structure as a dialogue interaction with the Agent (for example a tech support agent) asking clarifying questions of the User until being able to answer the User's question. We can try to think of a better term -- perhaps \"multi-turn\"?\n\nTo Reviewer 2:\n\n(1) how does the model extend to the case with multiple variables in a single sentence?\n\nCurrently we leverage the fact that there is just one variable per sentence to save on parameters and avoid a linear transformation before the softmax in the query network.  To support more than one variable per sentence would just require adding a linear transformation on the output before softmax, making the query network have the same structure as the answer network.\n\n(2) If the answer is out of vocabulary, how would the model handle it?\n\nOut of vocabulary words are in general a problem for networks which do a softmax over a fixed vocabulary.  One potential way to address this would be to use something like the Pointer Networks of Vinyals, Fortunato, and Jaitly(", "OTHER_KEYS": "Tim Klinger"}, {"OTHER_KEYS": "ICLR 2017 conference AnonReviewer2", "TITLE": "No Title", "comments": "This paper proposed an integration of memory network with reinforcement learning. The experimental data is simple, but the model is very interesting and relatively novel. There are some questions about the model:\n\n1. how does the model extend to the case with multiple variables in a single sentence?\n\n2. If the answer is out of vocabulary, how would the model handle it?\n\n3. I hope the authors can provide more analysis about the curriculum learning part, since it is very important for the RL model training.\n\n4. In the training, in each iteration, how the data samples were selected, by random or from simple one depth to multiple depth? \n", "ORIGINALITY": 2, "IS_ANNOTATED": true, "IS_META_REVIEW": false, "RECOMMENDATION": 6, "DATE": "20 Dec 2016", "CLARITY": 5, "REVIEWER_CONFIDENCE": 3}, {"OTHER_KEYS": "ICLR 2017 conference AnonReviewer1", "TITLE": "No Title", "comments": "This paper introduces a nice dataset/data generator that creates bAbI like tasks, except where the questioning answering agent is required to clarify the values of some variables in order to succeed.  I think the baselines the authors use to test the tasks are appropriate.   I am a bit worried that the tasks may be too easy (as the bAbI tasks have been), but still, I think locally these will be useful.  If the generation code is well written, and the tasks are extensible, they may be useful for some time.", "IS_ANNOTATED": true, "IS_META_REVIEW": false, "RECOMMENDATION": 7, "DATE": "17 Dec 2016", "REVIEWER_CONFIDENCE": 4}, {"IMPACT": 3, "OTHER_KEYS": "ICLR 2017 conference AnonReviewer3", "TITLE": "Review", "comments": "This paper investigates a set of tasks that augment the basic bAbI problems. In particular, some of the people and objects in the scenarios are replaced with unknown variables. Some of these variables must be known to solve the question, thus the agent must learn to query for the values of these variables. Interestingly, one can now measure both the performance of the agent in correctly answering the question, and its efficiency in asking for the values of the correct unknown variables (and not variables that are unnecessary to answer the question). This inferring of unknown variables goes beyond what is required for the vanilla version of the bAbI tasks, which are now more or less solved.\n\nThe paper is well-written, and the contributions are clear. Due to the very limited vocabulary and structure of the bAbI problems in general, I think these tasks (and variants on them) should be viewed more as basic reasoning tasks than natural language understanding. I\u2019m not convinced by the claim of the paper that this really tests the \u2018interaction\u2019 capabilities of agents \u2013 while the task is phrased as a kind of interaction, I think it\u2019s more aptly described by simply \u2018inferring important unknown variables\u2019, which (while important) is more related to reasoning. I\u2019m not sure whether the connection of this ability to \u2018interaction\u2019 is more a superficial one.\n\nThat being said, it is certainly true that conversational agents will need basic reasoning abilities to converse meaningfully with humans. I sympathise with the general goal of the bAbI tasks, which is to test these reasoning abilities in synthetic environments, that are just complicated enough (but not more) to drive the construction of interesting models. I am convinced by the authors that their extension to these tasks are interesting and worthy of future investigation, and thus I recommend the acceptance of the paper.\n", "SOUNDNESS_CORRECTNESS": 5, "IS_ANNOTATED": true, "IS_META_REVIEW": false, "RECOMMENDATION": 7, "DATE": "16 Dec 2016", "APPROPRIATENESS": 2, "REVIEWER_CONFIDENCE": 3}, {"TITLE": "reward vs accuracy", "OTHER_KEYS": "ICLR 2017 conference AnonReviewer1", "comments": "", "IS_ANNOTATED": true, "IS_META_REVIEW": false, "DATE": "12 Dec 2016"}, {"OTHER_KEYS": "ICLR 2017 conference AnonReviewer2", "TITLE": "some concerns", "comments": "", "ORIGINALITY": 2, "IS_ANNOTATED": true, "IS_META_REVIEW": false, "DATE": "02 Dec 2016", "CLARITY": 5}, {"IMPACT": 3, "OTHER_KEYS": "ICLR 2017 conference AnonReviewer3", "TITLE": "paper is clear", "comments": "", "SOUNDNESS_CORRECTNESS": 5, "IS_ANNOTATED": true, "IS_META_REVIEW": false, "DATE": "02 Dec 2016", "APPROPRIATENESS": 2}, {"DATE": "07 Nov 2016", "TITLE": "ICLR Paper Format", "IS_META_REVIEW": false, "comments": "Dear Authors,\n\nPlease resubmit your paper in the ICLR 2017 format with the correct font for your submission to be considered. Thank you!\n", "OTHER_KEYS": "Tara N Sainath"}, {"DATE": "06 Feb 2017", "TITLE": "ICLR committee final decision", "IS_META_REVIEW": false, "comments": "The program committee appreciates the authors' response to concerns raised in the reviews. While there are some concerns with the paper that the authors are strongly encouraged to address for the final version of the paper, overall, the work has contributions that are worth presenting at ICLR.", "OTHER_KEYS": "ICLR 2017 pcs"}, {"DATE": "27 Dec 2016", "TITLE": "Thanks to all the reviewers!", "IS_META_REVIEW": false, "comments": "Happy holidays and thank you all for your careful reading and thoughtful, constructive comments!\n\nA few responses to your last set of comments/questions:\n\nTo Reviewer 3:\n\nWe definitely agree that because of the limited vocabulary and grammar, this is more about reasoning than language.  As you point out, the interaction in these problems  boils down to repeated variable queries until the Agent decides it has enough info.  We decided on the term \"interaction\" to differentiate our problems from the bAbI problems, which are 1 shot question answering, and to emphasize the idea that, although simplified, this has the same structure as a dialogue interaction with the Agent (for example a tech support agent) asking clarifying questions of the User until being able to answer the User's question. We can try to think of a better term -- perhaps \"multi-turn\"?\n\nTo Reviewer 2:\n\n(1) how does the model extend to the case with multiple variables in a single sentence?\n\nCurrently we leverage the fact that there is just one variable per sentence to save on parameters and avoid a linear transformation before the softmax in the query network.  To support more than one variable per sentence would just require adding a linear transformation on the output before softmax, making the query network have the same structure as the answer network.\n\n(2) If the answer is out of vocabulary, how would the model handle it?\n\nOut of vocabulary words are in general a problem for networks which do a softmax over a fixed vocabulary.  One potential way to address this would be to use something like the Pointer Networks of Vinyals, Fortunato, and Jaitly(", "OTHER_KEYS": "Tim Klinger"}, {"OTHER_KEYS": "ICLR 2017 conference AnonReviewer2", "TITLE": "No Title", "comments": "This paper proposed an integration of memory network with reinforcement learning. The experimental data is simple, but the model is very interesting and relatively novel. There are some questions about the model:\n\n1. how does the model extend to the case with multiple variables in a single sentence?\n\n2. If the answer is out of vocabulary, how would the model handle it?\n\n3. I hope the authors can provide more analysis about the curriculum learning part, since it is very important for the RL model training.\n\n4. In the training, in each iteration, how the data samples were selected, by random or from simple one depth to multiple depth? \n", "ORIGINALITY": 2, "IS_ANNOTATED": true, "IS_META_REVIEW": false, "RECOMMENDATION": 6, "DATE": "20 Dec 2016", "CLARITY": 5, "REVIEWER_CONFIDENCE": 3}, {"OTHER_KEYS": "ICLR 2017 conference AnonReviewer1", "TITLE": "No Title", "comments": "This paper introduces a nice dataset/data generator that creates bAbI like tasks, except where the questioning answering agent is required to clarify the values of some variables in order to succeed.  I think the baselines the authors use to test the tasks are appropriate.   I am a bit worried that the tasks may be too easy (as the bAbI tasks have been), but still, I think locally these will be useful.  If the generation code is well written, and the tasks are extensible, they may be useful for some time.", "IS_ANNOTATED": true, "IS_META_REVIEW": false, "RECOMMENDATION": 7, "DATE": "17 Dec 2016", "REVIEWER_CONFIDENCE": 4}, {"IMPACT": 3, "OTHER_KEYS": "ICLR 2017 conference AnonReviewer3", "TITLE": "Review", "comments": "This paper investigates a set of tasks that augment the basic bAbI problems. In particular, some of the people and objects in the scenarios are replaced with unknown variables. Some of these variables must be known to solve the question, thus the agent must learn to query for the values of these variables. Interestingly, one can now measure both the performance of the agent in correctly answering the question, and its efficiency in asking for the values of the correct unknown variables (and not variables that are unnecessary to answer the question). This inferring of unknown variables goes beyond what is required for the vanilla version of the bAbI tasks, which are now more or less solved.\n\nThe paper is well-written, and the contributions are clear. Due to the very limited vocabulary and structure of the bAbI problems in general, I think these tasks (and variants on them) should be viewed more as basic reasoning tasks than natural language understanding. I\u2019m not convinced by the claim of the paper that this really tests the \u2018interaction\u2019 capabilities of agents \u2013 while the task is phrased as a kind of interaction, I think it\u2019s more aptly described by simply \u2018inferring important unknown variables\u2019, which (while important) is more related to reasoning. I\u2019m not sure whether the connection of this ability to \u2018interaction\u2019 is more a superficial one.\n\nThat being said, it is certainly true that conversational agents will need basic reasoning abilities to converse meaningfully with humans. I sympathise with the general goal of the bAbI tasks, which is to test these reasoning abilities in synthetic environments, that are just complicated enough (but not more) to drive the construction of interesting models. I am convinced by the authors that their extension to these tasks are interesting and worthy of future investigation, and thus I recommend the acceptance of the paper.\n", "SOUNDNESS_CORRECTNESS": 5, "IS_ANNOTATED": true, "IS_META_REVIEW": false, "RECOMMENDATION": 7, "DATE": "16 Dec 2016", "APPROPRIATENESS": 2, "REVIEWER_CONFIDENCE": 3}, {"TITLE": "reward vs accuracy", "OTHER_KEYS": "ICLR 2017 conference AnonReviewer1", "comments": "", "IS_ANNOTATED": true, "IS_META_REVIEW": false, "DATE": "12 Dec 2016"}, {"OTHER_KEYS": "ICLR 2017 conference AnonReviewer2", "TITLE": "some concerns", "comments": "", "ORIGINALITY": 2, "IS_ANNOTATED": true, "IS_META_REVIEW": false, "DATE": "02 Dec 2016", "CLARITY": 5}, {"IMPACT": 3, "OTHER_KEYS": "ICLR 2017 conference AnonReviewer3", "TITLE": "paper is clear", "comments": "", "SOUNDNESS_CORRECTNESS": 5, "IS_ANNOTATED": true, "IS_META_REVIEW": false, "DATE": "02 Dec 2016", "APPROPRIATENESS": 2}, {"DATE": "07 Nov 2016", "TITLE": "ICLR Paper Format", "IS_META_REVIEW": false, "comments": "Dear Authors,\n\nPlease resubmit your paper in the ICLR 2017 format with the correct font for your submission to be considered. Thank you!\n", "OTHER_KEYS": "Tara N Sainath"}], "authors": "Xiaoxiao Guo, Tim Klinger, Clemens Rosenbaum, Joseph P. Bigus, Murray Campbell, Ban Kawas, Kartik Talamadupula, Gerry Tesauro, Satinder   Singh", "accepted": true, "id": "349"}