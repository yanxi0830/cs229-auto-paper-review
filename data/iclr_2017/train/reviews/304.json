{"conference": "ICLR 2017 conference submission", "title": "Making Neural Programming Architectures Generalize via Recursion", "abstract": "Empirically, neural networks that attempt to learn programs from data have exhibited poor generalizability. Moreover, it has traditionally been difficult to reason about the behavior of these models beyond a certain level of input complexity. In order to address these issues, we propose augmenting neural architectures with a key abstraction: recursion. As an application, we implement recursion in the Neural Programmer-Interpreter framework on four tasks: grade-school addition, bubble sort, topological sort, and quicksort. We demonstrate superior generalizability and interpretability with small amounts of training data. Recursion divides the problem into smaller pieces and drastically reduces the domain of each neural network component, making it tractable to prove guarantees about the overall system\u2019s behavior. Our experience suggests that in order for neural architectures to robustly learn program semantics, it is necessary to incorporate a concept like recursion.", "histories": [], "reviews": [{"IS_META_REVIEW": true, "comments": "This paper improves significantly upon the original NPI work, showing that the model generalizes far better when trained on traces in recursive form. The authors show better sample complexity and generalization results for addition and bubblesort programs, and add two new and more interesting tasks - topological sort and quicksort (added based on reviewer discussion). Furthermore, they actually *prove* that the algorithms learned by the model generalize perfectly, which to my knowledge is the first time this has been done in neural program induction."}, {"DATE": "02 May 2017", "TITLE": "Source code", "IS_META_REVIEW": false, "comments": "Has the source code for this paper been released by the authors?", "OTHER_KEYS": "(anonymous)"}, {"DATE": "06 Feb 2017", "TITLE": "ICLR committee final decision", "IS_META_REVIEW": false, "comments": "The reviewers were very favourable, and the paper is on a highly-relevant topic and explores a useful practical trick.", "OTHER_KEYS": "ICLR 2017 pcs"}, {"OTHER_KEYS": "ICLR 2017 conference AnonReviewer1", "TITLE": "A demonstration that NPI can learn to solve Tower of Hanoi!", "comments": "This paper argues that being able to handle recursion is very important for neural programming architectures \u2014 that handling recursion allows for strong generalization to out of domain test cases and learning from smaller amounts of training data.  Most of the paper is a riff on the Reed & de Freitas paper on Neural Programmer Interpreters from ICLR 2016 which learns from program traces \u2014 this paper trains NPI models on traces that have recursive calls.  The authors show how to verify correctness by evaluating the learned program on only a small set of base cases and reduction rules and impressively, show that the NPI architecture is able to perfectly infer Bubblesort and the Tower of Hanoi problems.  \n\nWhat I like is that the idea is super simple and as the authors even mention, the only change is to the execution traces that the training pipeline gets to see.  I\u2019m actually not sure what the right take-away is \u2014 does this mean that we have effectively solved the neural programming problem when the execution traces are available? (and was the problem too easy to begin with?).    For example, a larger input domain (as one of the reviewers also mentions) is MNIST digits and we can imagine a problem where the NPI must infer how to sort MNIST digits from highest to lowest.  In this setting, having execution traces would effectively decouple the problem of recognizing the digits from that of inferring the program logic \u2014 and so the problem would be no harder than learning to recognize MNIST digits and learning to bubble sort from symbols.  What is a problem where we have access to execution traces but cannot infer it using the proposed method?\n", "ORIGINALITY": 4, "IS_ANNOTATED": true, "IS_META_REVIEW": false, "RECOMMENDATION": 8, "DATE": "16 Dec 2016", "REVIEWER_CONFIDENCE": 4}, {"TITLE": "Nifty extension to make NPI more practical", "OTHER_KEYS": "ICLR 2017 conference AnonReviewer2", "comments": "This is a very interesting and fairly easy to read paper. \nThe authors present a small, yet nifty approach to make Neural Programming Interpreters significantly more powerful. By allowing recursion, NPI generalizes better from fewer execution traces.\nIt's an interesting example of how a small but non-trivial extension can make a machine learning method significantly more practical.\n\nI also appreciate that the same notation was used in this paper and the original Deepmind paper. As a non-expert on this topic, it was easy to read the original paper in tandem. \n\nMy one point of critique is that the generalization proves are a bit vague. For the numerical examples in the paper, you can iterate over all possible execution paths until the next recursive call. However, how would this approach generalize a continuous input space (e.g. the 3D car example in the original paper). It seems that a prove of generalization will still be intractable in the continuous case? \n\nAre you planning on releasing the source code?", "IS_META_REVIEW": false, "RECOMMENDATION": 8, "DATE": "16 Dec 2016", "REVIEWER_CONFIDENCE": 3}, {"TITLE": "Greatly improved training and analysis of NPI", "MEANINGFUL_COMPARISON": 2, "OTHER_KEYS": "ICLR 2017 conference AnonReviewer3", "comments": "This paper improves significantly upon the original NPI work, showing that the model generalizes far better when trained on traces in recursive form. The authors show better sample complexity and generalization results for addition and bubblesort programs, and add two new and more interesting tasks - topological sort and quicksort (added based on reviewer discussion). Furthermore, they actually *prove* that the algorithms learned by the model generalize perfectly, which to my knowledge is the first time this has been done in neural program induction.", "SOUNDNESS_CORRECTNESS": 2, "ORIGINALITY": 2, "IS_ANNOTATED": true, "IS_META_REVIEW": false, "RECOMMENDATION": 9, "DATE": "16 Dec 2016", "CLARITY": 3, "REVIEWER_CONFIDENCE": 5}, {"TITLE": "Application to other tasks", "MEANINGFUL_COMPARISON": 2, "OTHER_KEYS": "ICLR 2017 conference AnonReviewer3", "comments": "", "SOUNDNESS_CORRECTNESS": 2, "ORIGINALITY": 2, "IS_ANNOTATED": true, "IS_META_REVIEW": false, "DATE": "02 Dec 2016", "CLARITY": 3}, {"IS_META_REVIEW": true, "comments": "This paper improves significantly upon the original NPI work, showing that the model generalizes far better when trained on traces in recursive form. The authors show better sample complexity and generalization results for addition and bubblesort programs, and add two new and more interesting tasks - topological sort and quicksort (added based on reviewer discussion). Furthermore, they actually *prove* that the algorithms learned by the model generalize perfectly, which to my knowledge is the first time this has been done in neural program induction."}, {"DATE": "02 May 2017", "TITLE": "Source code", "IS_META_REVIEW": false, "comments": "Has the source code for this paper been released by the authors?", "OTHER_KEYS": "(anonymous)"}, {"DATE": "06 Feb 2017", "TITLE": "ICLR committee final decision", "IS_META_REVIEW": false, "comments": "The reviewers were very favourable, and the paper is on a highly-relevant topic and explores a useful practical trick.", "OTHER_KEYS": "ICLR 2017 pcs"}, {"OTHER_KEYS": "ICLR 2017 conference AnonReviewer1", "TITLE": "A demonstration that NPI can learn to solve Tower of Hanoi!", "comments": "This paper argues that being able to handle recursion is very important for neural programming architectures \u2014 that handling recursion allows for strong generalization to out of domain test cases and learning from smaller amounts of training data.  Most of the paper is a riff on the Reed & de Freitas paper on Neural Programmer Interpreters from ICLR 2016 which learns from program traces \u2014 this paper trains NPI models on traces that have recursive calls.  The authors show how to verify correctness by evaluating the learned program on only a small set of base cases and reduction rules and impressively, show that the NPI architecture is able to perfectly infer Bubblesort and the Tower of Hanoi problems.  \n\nWhat I like is that the idea is super simple and as the authors even mention, the only change is to the execution traces that the training pipeline gets to see.  I\u2019m actually not sure what the right take-away is \u2014 does this mean that we have effectively solved the neural programming problem when the execution traces are available? (and was the problem too easy to begin with?).    For example, a larger input domain (as one of the reviewers also mentions) is MNIST digits and we can imagine a problem where the NPI must infer how to sort MNIST digits from highest to lowest.  In this setting, having execution traces would effectively decouple the problem of recognizing the digits from that of inferring the program logic \u2014 and so the problem would be no harder than learning to recognize MNIST digits and learning to bubble sort from symbols.  What is a problem where we have access to execution traces but cannot infer it using the proposed method?\n", "ORIGINALITY": 4, "IS_ANNOTATED": true, "IS_META_REVIEW": false, "RECOMMENDATION": 8, "DATE": "16 Dec 2016", "REVIEWER_CONFIDENCE": 4}, {"TITLE": "Nifty extension to make NPI more practical", "OTHER_KEYS": "ICLR 2017 conference AnonReviewer2", "comments": "This is a very interesting and fairly easy to read paper. \nThe authors present a small, yet nifty approach to make Neural Programming Interpreters significantly more powerful. By allowing recursion, NPI generalizes better from fewer execution traces.\nIt's an interesting example of how a small but non-trivial extension can make a machine learning method significantly more practical.\n\nI also appreciate that the same notation was used in this paper and the original Deepmind paper. As a non-expert on this topic, it was easy to read the original paper in tandem. \n\nMy one point of critique is that the generalization proves are a bit vague. For the numerical examples in the paper, you can iterate over all possible execution paths until the next recursive call. However, how would this approach generalize a continuous input space (e.g. the 3D car example in the original paper). It seems that a prove of generalization will still be intractable in the continuous case? \n\nAre you planning on releasing the source code?", "IS_META_REVIEW": false, "RECOMMENDATION": 8, "DATE": "16 Dec 2016", "REVIEWER_CONFIDENCE": 3}, {"TITLE": "Greatly improved training and analysis of NPI", "MEANINGFUL_COMPARISON": 2, "OTHER_KEYS": "ICLR 2017 conference AnonReviewer3", "comments": "This paper improves significantly upon the original NPI work, showing that the model generalizes far better when trained on traces in recursive form. The authors show better sample complexity and generalization results for addition and bubblesort programs, and add two new and more interesting tasks - topological sort and quicksort (added based on reviewer discussion). Furthermore, they actually *prove* that the algorithms learned by the model generalize perfectly, which to my knowledge is the first time this has been done in neural program induction.", "SOUNDNESS_CORRECTNESS": 2, "ORIGINALITY": 2, "IS_ANNOTATED": true, "IS_META_REVIEW": false, "RECOMMENDATION": 9, "DATE": "16 Dec 2016", "CLARITY": 3, "REVIEWER_CONFIDENCE": 5}, {"TITLE": "Application to other tasks", "MEANINGFUL_COMPARISON": 2, "OTHER_KEYS": "ICLR 2017 conference AnonReviewer3", "comments": "", "SOUNDNESS_CORRECTNESS": 2, "ORIGINALITY": 2, "IS_ANNOTATED": true, "IS_META_REVIEW": false, "DATE": "02 Dec 2016", "CLARITY": 3}], "authors": "Jonathon Cai, Richard Shin, Dawn Song", "accepted": true, "id": "304"}