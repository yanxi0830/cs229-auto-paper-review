{"conference": "ICLR 2017 conference submission", "title": "Marginal Deep Architectures: Deep learning for Small and Middle Scale Applications", "abstract": "In recent years, many deep architectures have been proposed in different fields. However, to obtain good results, most of the previous deep models need a large number of training data. In this paper, for small and middle scale applications, we propose a novel deep learning framework based on stacked feature learning models. Particularly, we stack marginal Fisher analysis (MFA) layer by layer for the initialization of the deep architecture and call it \u201cMarginal Deep Architectures\u201d (MDA). In the implementation of MDA, the weight matrices of MFA are first learned layer by layer, and then we exploit some deep learning techniques, such as back propagation, dropout and denoising to fine tune the network. To evaluate the effectiveness of MDA, we have compared it with some feature learning methods and deep learning models on 7 small and middle scale real-world applications, including handwritten digits recognition, speech recognition, historical document understanding, image classification, action recognition and so on. Extensive experiments demonstrate that MDA performs not only better than shallow feature learning models, but also state-of-the-art deep learning models in these applications.", "histories": [], "reviews": [{"IS_META_REVIEW": true, "comments": "This paper proposes to initialize the weights of a deep neural network layer-wise with a marginal Fisher analysis model, making use of potentially the similarity metric.\n \nPros: \nThere are a lot of experiments, albeit small datasets, that the authors tested their proposed method on.\n\nCons:\nlacking baseline such as discriminatively trained convolutional network on standard dataset such as CIFAR-10.\nIt is also unclear how costly in computation to compute the association matrix A in equation 4.\n\nThis is an OK paper, where a new idea is proposed, and combined with other existing ideas such as greedy-layerwise stacking, dropout, and denoising auto-encoders.\nHowever, there have been many papers with similar ideas perhaps 3-5 years ago, e.g. SPCANet. \n\nTherefore, the main novelty is the use of marginal Fisher Analysis as a new layer. This would be ok, but the baselines to demonstrate that this approach works better is missing. In particular, I'd like to see a conv net or fully connected net trained from scratch with good initialization would do at these problems.\n\nTo improve the paper, the authors should try to demonstrate without doubt that initializing layers with MFA is better than just random weight matrices."}, {"DATE": "06 Feb 2017", "TITLE": "ICLR committee final decision", "IS_META_REVIEW": false, "comments": "The reviewers unanimously recommend rejection.", "OTHER_KEYS": "ICLR 2017 pcs"}, {"TITLE": "Review", "OTHER_KEYS": "ICLR 2017 conference AnonReviewer3", "comments": "The proposed approach consists in a greedy layer wise initialization strategy for a deep MLP model, which is followed by global gradient-descent with dropout for fine-tuning. The initialization strategy uses a first randomly initialized sigmoid layer for dimensionality expansion followed by 2 sigmoid layers whose weights are initialized by Marginal Fisher Analysis (MFA) which learns a linear dimensionality reduction based on a neighborhood graph constructed using class label information (i.e. supervised dimensionality reduction). Output layer is a standard softmax layer.\n\nThe approach is thus to be added to a growing list of heuristic layer-wise initialization schemes.\nThe particular choice of initialization strategy, while reasonable, is not sufficiently well motivated in the paper relative to alternatives, and thus feels rather arbitrary.\nThe paper lacks clarity in the description of the approach:  MFA is poorly explained with undefined notations (in Eq. 4, what is A? It has not been properly defined); the precise use of alluded denoising in the model is also unclear (is there really training of an additional denoting objective, or just input corruption?).\n\nThe question of the (arguably mild) inconsistency of applying a linear dimensionality reduction algorithm, that is trained without any sigmoid, and then passing its learned representation through a sigmoid is not even raised. This, in addition to the fact that sigmoid hidden layers are no longer commonly used (why did you not also consider using RELUs?).\n\nMore importantly I suspect methodological problems with the experimental comparisons: the paper mentions using *default* values for learning-rate and momentum, and having (arbitrarily?) fixed epoch to 400 (no early stopping?) and L2 regularization to 1e-4 for some models. \n*All* hyper parameters should always be properly hyper-optimized using a validation set (or cross-validation) including early-stopping, and this separately for each model under comparison (ideally also including layer sizes). This is all the more important since you are considering smallish datasets, so that the various initialization strategies act mainly as different indirect regularization schemes: they thus need to be carefully tuned. This casts serious doubts as to the amount of hyper-parameter tuning (close to none?) that went into training the alternative models used for comparison. \n\nThe Marginal Fisher Analysis dimensionality reduction initialization strategy may well offer advantages, but as it currently stands this paper doesn\u2019t yet make a sufficiently convincing case for it, nor provide useful insights into the nature of the expected advantages.\n\nI would also suggest, for image inputs such as CIFAR10, to use the qualitative tool of showing the filters (back projected to input space) learned by the different initialization schemes under consideration, as this could help visually gain insight as to what sets methods apart. \n\n", "IS_META_REVIEW": false, "RECOMMENDATION": 3, "DATE": "21 Dec 2016", "REVIEWER_CONFIDENCE": 4}, {"TITLE": "Interesting motivation but fail to justify the proposed method", "OTHER_KEYS": "ICLR 2017 conference AnonReviewer1", "comments": "The authors pointed out some limitations of existing deep architectures, in particular hard to optimize on small or mid size datasets, and proposed to stack marginal fisher analysis (MFA) to build deep models. The proposed method is tested on several small to mid size datasets and compared with several feature learning methods. The authors also applied some existing techniques in deep learning, such as backprop, denoising and dropout to improve performance. \n\nThe new contribution of the paper is limited. MFA has long been proposed. The authors fail to theoretically or empirically justify the stacking of MFAs. The authors did not include any deep architectures that requires backprop over multiple layers in the comparison, which the authors set out to address, instead all the methods compared were learned layer by layer. Will a randomly initialized deep model such as DBN or CNN perform poorly on these datasets? It is also not clear how the authors came up with each particular model architecture and hyper-parameters used in the different datasets. The writing of the paper needs to be significantly improved. A lot of details were omitted, for example, how is dropout applied in the MFA. ", "IS_META_REVIEW": false, "RECOMMENDATION": 4, "DATE": "19 Dec 2016", "REVIEWER_CONFIDENCE": 4}, {"TITLE": "A deep learning model is proposed where layerwise stacking of a new type of layer (Marginal Fisher Analysis) is used.", "OTHER_KEYS": "ICLR 2017 conference AnonReviewer2", "comments": "This paper proposes to initialize the weights of a deep neural network layer-wise with a marginal Fisher analysis model, making use of potentially the similarity metric.\n \nPros: \nThere are a lot of experiments, albeit small datasets, that the authors tested their proposed method on.\n\nCons:\nlacking baseline such as discriminatively trained convolutional network on standard dataset such as CIFAR-10.\nIt is also unclear how costly in computation to compute the association matrix A in equation 4.\n\nThis is an OK paper, where a new idea is proposed, and combined with other existing ideas such as greedy-layerwise stacking, dropout, and denoising auto-encoders.\nHowever, there have been many papers with similar ideas perhaps 3-5 years ago, e.g. SPCANet. \n\nTherefore, the main novelty is the use of marginal Fisher Analysis as a new layer. This would be ok, but the baselines to demonstrate that this approach works better is missing. In particular, I'd like to see a conv net or fully connected net trained from scratch with good initialization would do at these problems.\n\nTo improve the paper, the authors should try to demonstrate without doubt that initializing layers with MFA is better than just random weight matrices.\n", "IS_META_REVIEW": false, "RECOMMENDATION": 4, "DATE": "19 Dec 2016", "REVIEWER_CONFIDENCE": 4}, {"DATE": "08 Dec 2016", "TITLE": "Clarification", "IS_META_REVIEW": false, "comments": "", "OTHER_KEYS": "ICLR 2017 conference AnonReviewer1"}, {"DATE": "04 Dec 2016", "TITLE": "Clarifications", "IS_META_REVIEW": false, "comments": "", "OTHER_KEYS": "ICLR 2017 conference AnonReviewer3"}, {"DATE": "04 Dec 2016", "TITLE": "Clarifications on notation", "IS_META_REVIEW": false, "comments": "", "OTHER_KEYS": "ICLR 2017 conference AnonReviewer2"}, {"IS_META_REVIEW": true, "comments": "This paper proposes to initialize the weights of a deep neural network layer-wise with a marginal Fisher analysis model, making use of potentially the similarity metric.\n \nPros: \nThere are a lot of experiments, albeit small datasets, that the authors tested their proposed method on.\n\nCons:\nlacking baseline such as discriminatively trained convolutional network on standard dataset such as CIFAR-10.\nIt is also unclear how costly in computation to compute the association matrix A in equation 4.\n\nThis is an OK paper, where a new idea is proposed, and combined with other existing ideas such as greedy-layerwise stacking, dropout, and denoising auto-encoders.\nHowever, there have been many papers with similar ideas perhaps 3-5 years ago, e.g. SPCANet. \n\nTherefore, the main novelty is the use of marginal Fisher Analysis as a new layer. This would be ok, but the baselines to demonstrate that this approach works better is missing. In particular, I'd like to see a conv net or fully connected net trained from scratch with good initialization would do at these problems.\n\nTo improve the paper, the authors should try to demonstrate without doubt that initializing layers with MFA is better than just random weight matrices."}, {"DATE": "06 Feb 2017", "TITLE": "ICLR committee final decision", "IS_META_REVIEW": false, "comments": "The reviewers unanimously recommend rejection.", "OTHER_KEYS": "ICLR 2017 pcs"}, {"TITLE": "Review", "OTHER_KEYS": "ICLR 2017 conference AnonReviewer3", "comments": "The proposed approach consists in a greedy layer wise initialization strategy for a deep MLP model, which is followed by global gradient-descent with dropout for fine-tuning. The initialization strategy uses a first randomly initialized sigmoid layer for dimensionality expansion followed by 2 sigmoid layers whose weights are initialized by Marginal Fisher Analysis (MFA) which learns a linear dimensionality reduction based on a neighborhood graph constructed using class label information (i.e. supervised dimensionality reduction). Output layer is a standard softmax layer.\n\nThe approach is thus to be added to a growing list of heuristic layer-wise initialization schemes.\nThe particular choice of initialization strategy, while reasonable, is not sufficiently well motivated in the paper relative to alternatives, and thus feels rather arbitrary.\nThe paper lacks clarity in the description of the approach:  MFA is poorly explained with undefined notations (in Eq. 4, what is A? It has not been properly defined); the precise use of alluded denoising in the model is also unclear (is there really training of an additional denoting objective, or just input corruption?).\n\nThe question of the (arguably mild) inconsistency of applying a linear dimensionality reduction algorithm, that is trained without any sigmoid, and then passing its learned representation through a sigmoid is not even raised. This, in addition to the fact that sigmoid hidden layers are no longer commonly used (why did you not also consider using RELUs?).\n\nMore importantly I suspect methodological problems with the experimental comparisons: the paper mentions using *default* values for learning-rate and momentum, and having (arbitrarily?) fixed epoch to 400 (no early stopping?) and L2 regularization to 1e-4 for some models. \n*All* hyper parameters should always be properly hyper-optimized using a validation set (or cross-validation) including early-stopping, and this separately for each model under comparison (ideally also including layer sizes). This is all the more important since you are considering smallish datasets, so that the various initialization strategies act mainly as different indirect regularization schemes: they thus need to be carefully tuned. This casts serious doubts as to the amount of hyper-parameter tuning (close to none?) that went into training the alternative models used for comparison. \n\nThe Marginal Fisher Analysis dimensionality reduction initialization strategy may well offer advantages, but as it currently stands this paper doesn\u2019t yet make a sufficiently convincing case for it, nor provide useful insights into the nature of the expected advantages.\n\nI would also suggest, for image inputs such as CIFAR10, to use the qualitative tool of showing the filters (back projected to input space) learned by the different initialization schemes under consideration, as this could help visually gain insight as to what sets methods apart. \n\n", "IS_META_REVIEW": false, "RECOMMENDATION": 3, "DATE": "21 Dec 2016", "REVIEWER_CONFIDENCE": 4}, {"TITLE": "Interesting motivation but fail to justify the proposed method", "OTHER_KEYS": "ICLR 2017 conference AnonReviewer1", "comments": "The authors pointed out some limitations of existing deep architectures, in particular hard to optimize on small or mid size datasets, and proposed to stack marginal fisher analysis (MFA) to build deep models. The proposed method is tested on several small to mid size datasets and compared with several feature learning methods. The authors also applied some existing techniques in deep learning, such as backprop, denoising and dropout to improve performance. \n\nThe new contribution of the paper is limited. MFA has long been proposed. The authors fail to theoretically or empirically justify the stacking of MFAs. The authors did not include any deep architectures that requires backprop over multiple layers in the comparison, which the authors set out to address, instead all the methods compared were learned layer by layer. Will a randomly initialized deep model such as DBN or CNN perform poorly on these datasets? It is also not clear how the authors came up with each particular model architecture and hyper-parameters used in the different datasets. The writing of the paper needs to be significantly improved. A lot of details were omitted, for example, how is dropout applied in the MFA. ", "IS_META_REVIEW": false, "RECOMMENDATION": 4, "DATE": "19 Dec 2016", "REVIEWER_CONFIDENCE": 4}, {"TITLE": "A deep learning model is proposed where layerwise stacking of a new type of layer (Marginal Fisher Analysis) is used.", "OTHER_KEYS": "ICLR 2017 conference AnonReviewer2", "comments": "This paper proposes to initialize the weights of a deep neural network layer-wise with a marginal Fisher analysis model, making use of potentially the similarity metric.\n \nPros: \nThere are a lot of experiments, albeit small datasets, that the authors tested their proposed method on.\n\nCons:\nlacking baseline such as discriminatively trained convolutional network on standard dataset such as CIFAR-10.\nIt is also unclear how costly in computation to compute the association matrix A in equation 4.\n\nThis is an OK paper, where a new idea is proposed, and combined with other existing ideas such as greedy-layerwise stacking, dropout, and denoising auto-encoders.\nHowever, there have been many papers with similar ideas perhaps 3-5 years ago, e.g. SPCANet. \n\nTherefore, the main novelty is the use of marginal Fisher Analysis as a new layer. This would be ok, but the baselines to demonstrate that this approach works better is missing. In particular, I'd like to see a conv net or fully connected net trained from scratch with good initialization would do at these problems.\n\nTo improve the paper, the authors should try to demonstrate without doubt that initializing layers with MFA is better than just random weight matrices.\n", "IS_META_REVIEW": false, "RECOMMENDATION": 4, "DATE": "19 Dec 2016", "REVIEWER_CONFIDENCE": 4}, {"DATE": "08 Dec 2016", "TITLE": "Clarification", "IS_META_REVIEW": false, "comments": "", "OTHER_KEYS": "ICLR 2017 conference AnonReviewer1"}, {"DATE": "04 Dec 2016", "TITLE": "Clarifications", "IS_META_REVIEW": false, "comments": "", "OTHER_KEYS": "ICLR 2017 conference AnonReviewer3"}, {"DATE": "04 Dec 2016", "TITLE": "Clarifications on notation", "IS_META_REVIEW": false, "comments": "", "OTHER_KEYS": "ICLR 2017 conference AnonReviewer2"}], "authors": "Yuchen Zheng, Guoqiang Zhong, Junyu Dong", "accepted": false, "id": "700"}