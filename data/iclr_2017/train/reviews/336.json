{"conference": "ICLR 2017 conference submission", "title": "PixelCNN++: Improving the PixelCNN with Discretized Logistic Mixture Likelihood and Other Modifications", "abstract": "PixelCNNs are a recently proposed class of powerful generative models with tractable likelihood. Here we discuss our implementation of PixelCNNs which we make available at", "histories": [], "reviews": [{"IS_META_REVIEW": true, "comments": "Summary:\nThis paper on autoregressive generative models explores various extensions of PixelCNNs. The proposed changes are to replace the softmax function with a logistic mixture model, to use dropout for regularization, to use downsampling to increase receptive field size, and the introduction of particular skip connections. The authors find that this allows the PixelCNN to outperform a PixelRNN on CIFAR-10, the previous state-of-the-art model. The authors further explore the performance of PixelCNNs with smaller receptive field sizes.\n\nReview:\nThis is a useful contribution towards better tractable image models. In particular, autoregressive models can be quite slow at test time, and the more efficient architectures described here should help with that.\n\nMy main criticism regards the severe neglect of related work. Mixture models have been used a lot in autoregressive image modeling, including for multivariate conditional densities and including downsampling to increase receptive field size, albeit in a different manner: Domke (2008), Hosseini et al. (2010), Theis et al. (2012), Uria et al. (2013), Theis et al. (2015). Note that the logistic distribution is a special case of the Gaussian scale mixture (West, 1978).\n\nThe main difference seems to be the integration of the density to model integers. While this is clearly a good idea and the right way forward, the authors claim but do not support that not doing this has \u201cproved to be a problem for earlier models based on continuous distributions\u201d. Please elaborate, add a reference, or ideally report the performance achieved by PixelCNN++ without integration (and instead adding uniform noise to make the variables continuous).\n\n60,000 images are not a lot in a high-dimensional space. While I can see the usefulness of regularization for specialized content \u2013 and this can serve as a good example to demonstrate the usefulness of dropout \u2013 why not use \u201c80 million tiny images\u201d (superset of CIFAR-10) for natural images? Semi-supervised learning should be fairly trivial here (because the model\u2019s likelihood is tractable), so this data could even be used in the class-conditional case.\n\nIt would be interesting to know how fast the different models are at test time (i.e., when generating images)."}, {"DATE": "06 Feb 2017", "TITLE": "ICLR committee final decision", "IS_META_REVIEW": false, "comments": " The authors acknowledge that the ideas in the paper are incremental, but assert these are not-trivial improvements upon prior work on pixel CNNs. The reviewers tended to agree with this characterization. The paper presents SOTA pixel likelihood results on CIFAR-10. This work is also coupled with a high quality source code contribution, which also appears to have already been well received by the github community. Reviewer 1 made the point that in terms of raw novelty this work is probably a little below the bar for an oral presentation. A public reviewer rated this paper as a strong accept. Given the statistics, quality and originality of the other papers in my AC batch I recommend poster.", "OTHER_KEYS": "ICLR 2017 pcs"}, {"DATE": "18 Jan 2017", "TITLE": "new revision incorporating reviewer recommendations", "IS_META_REVIEW": false, "comments": "We uploaded a new revision incorporating some of the suggestions made by the reviewers. Thank you for your input!\n\nSpecifically, the revision incorporates additional references and an experimental comparison with continuous mixture models as suggested by reviewer 2, and a more detailed description of the likelihood model, including equations, as requested by reviewer 3.", "OTHER_KEYS": "Tim Salimans"}, {"TITLE": "Good experimental work, reinstating classic heuristics back into AR CNN.", "OTHER_KEYS": "Galin Georgiev", "comments": "It is refreshing that OpenAI has taken the time to resurrect classic heuristics like down-sampling and dropout into PixelCNN. Some sort of AR technique like PixelCNN probably holds the missing keys needed to eventually have decent originally-created images from CIFAR10 or other real-life data-sets. So any engineering streamlining, as in this paper, is welcome to the general public, especially when helping to avoid expensive clusters of GPUs, only DeepMind can afford. In this sense, OpenAI is fulfilling its mission and we are all very grateful! Thus the paper is a welcome addition and we hope it finds its way into what appears to be an experimental CS conference anyway. \n\nOn a more conceptual level, our hope is that OpenAI, with so talented a team, will stop competing in these contrived contests to improve by basis points certain obscure log-likelihoods and instead focus on the bigger picture problems. Why for example, almost two years later, the class-conditional CIFAR10 samples, as on the left of Figure 4 in this paper (column 8 - class of horses), are still inferior to, say, the samples on Figure 4 of reference [2]? Forgive the pun, but aren't we beating a dead horse here? Yes, resolution and sharpness have improved, due to good engineering but nobody in the general public will take these samples seriously! Despite the claims put forward by some on the DeepMind team, PixelCNN is not a \"fully-generative\" neural net (as rigorously defined in section 3 of reference [1]), but merely a perturbative net, in the vain of the Boltzmann machine. After the Procrustean experience of lost decades on Boltzmann machines, the time perhaps has come to think more about the fundamentals and less about the heuristics?\n\n[1] ", "IS_META_REVIEW": false, "RECOMMENDATION": 9, "DATE": "06 Jan 2017", "REVIEWER_CONFIDENCE": 4}, {"TITLE": "Review", "SUBSTANCE": 3, "RECOMMENDATION_UNOFFICIAL": 4, "OTHER_KEYS": "ICLR 2017 conference AnonReviewer1", "comments": "Apologies for the late submission of this review, and thank you for the author\u2019s responses to earlier questions.\n\nThis submission proposes an improved implementation of the PixelCNN generative model. Most of the improvements are small and can be considered as specific technical details such as the use of dropout and skip connections, while others are slightly more substantial such as the use of a different likelihood model and multiscale analysis. The submission demonstrates state-of-the-art likelihood results on CIFAR-10.\n\nMy summary of the main contribution:\nAutoregressive-type models - of which PixelCNN is an example - are a nice class of models as their likelihood can be evaluated in closed form. A main differentiator for this type of models is how the conditional likelihood of one pixel conditioned on its causal neighbourhood is modelled:\n\n- In one line of work such as (Theis et al, 2012 MCGSM, Theis et al 2015 Spatial LSTM) the conditional distribution is modelled as a continuous density over real numbers. This approach has limitations: We know that in observed data pixel intensities are quantized to a discrete integer representation so a discrete distribution could give better likelihoods. Furthermore these continuous distributions have a tail and assign some probability mass outside the valid range of pixel intensities, which may hurt the likelihood.\n- In more recent work by van den Oord and colleagues the conditional likelihood is modelled as an arbitrary discrete distribution over the 256 possible values for pixel intensities. This does not suffer from the limitations of continuous likelihoods, but it also seems wasteful and is not very data efficient.\n\nThe authors propose something in the middle by keeping the discretized nature of the conditional likelihood, but restricting the discrete distribution to ones whose CDF that can be modeled as a linear combination of sigmoids. This approach makes sense to me, and is new in a way, but it doesn\u2019t appear to be very revolutionary or significant to me.\n\nThe second somewhat significant modification is the use of downsampling and multiscale modelling (as opposed to dilated convolutions). The main motivation for the authors to do this is saving computation time while keeping the multiscale flexibility of the model. The authors also introduce shortcut connections to compensate for the potential loss of information as they perform downsampling. Again, I feel that this modification not particularly revolutionary. Multiscale image analysis with autoregressive generative models has been done for example in (Theis et al, 2012) and several other papers.\n\nOverall I felt that this submission falls short on presenting substantially new ideas, and reads more like documentation for a particular implementation of an existing idea.", "ORIGINALITY": 5, "IS_ANNOTATED": true, "IS_META_REVIEW": false, "RECOMMENDATION": 6, "DATE": "22 Dec 2016 (modified: 19 Jan 2017)", "REVIEWER_CONFIDENCE": 3}, {"OTHER_KEYS": "ICLR 2017 conference AnonReviewer3", "TITLE": "Great empirical work, insightful ablation experiments, code is available which is a nice contribution to the community", "comments": "# Review\nThis paper proposes five modifications to improve PixelCNN, a generative model with tractable likelihood. The authors empirically showed the impact of each of their proposed modifications using a series of ablation experiments. They also reported a new state-of-the-art result on CIFAR-10.\nImproving generative models, especially for images, is an active research area and this paper definitely contributes to it.\n\n\n# Pros\nThe authors motivate each modification well they proposed. They also used ablation experiments to show each of them is important.\n\nThe authors use a discretized mixture of logistic distributions to model the conditional distribution of a sub-pixel instead of a 256-way softmax. This allows to have a lower output dimension and to be better suited at learning ordinal relationships between sub-pixel values. The authors also mentioned it speeded up training time (less computation) as well as the convergence during the optimization of the model (as shown in Fig.6).\n\nThe authors make an interesting remark about how the dependencies between the color channels of a pixel are likely to be relatively simple and do not require a deep network to model. This allows them to have a simplified architecture where you don't have to separate out all feature maps in 3 groups depending on whether or not they can see the R/G/B sub-pixel of the current location.\n\n\n# Cons\nIt is not clear to me what the predictive distribution for the green channel (and the blue) looks like. More precisely, how are the means of the mixture components linearly depending on the value of the red sub-pixel? I would have liked to see the equations for them.\n\n\n# Minor Comments\nIn Fig.2 it is written \"Sequence of 6 layers\" but in the text (Section 2.4) it says 6 blocks of 5 ResNet layers. What is the remaining layer?\nIn Fig.2 what does the first \"green square -> blue square\" which isn't in the white rectangle represents?\nIs there any reason why the mixture indicator is shared across all three channels?", "SOUNDNESS_CORRECTNESS": 4, "ORIGINALITY": 4, "IS_ANNOTATED": true, "IS_META_REVIEW": false, "RECOMMENDATION": 7, "DATE": "17 Dec 2016", "CLARITY": 5, "REVIEWER_CONFIDENCE": 4}, {"SUBSTANCE": 3, "OTHER_KEYS": "ICLR 2017 conference AnonReviewer2", "TITLE": "Related work", "comments": "Summary:\nThis paper on autoregressive generative models explores various extensions of PixelCNNs. The proposed changes are to replace the softmax function with a logistic mixture model, to use dropout for regularization, to use downsampling to increase receptive field size, and the introduction of particular skip connections. The authors find that this allows the PixelCNN to outperform a PixelRNN on CIFAR-10, the previous state-of-the-art model. The authors further explore the performance of PixelCNNs with smaller receptive field sizes.\n\nReview:\nThis is a useful contribution towards better tractable image models. In particular, autoregressive models can be quite slow at test time, and the more efficient architectures described here should help with that.\n\nMy main criticism regards the severe neglect of related work. Mixture models have been used a lot in autoregressive image modeling, including for multivariate conditional densities and including downsampling to increase receptive field size, albeit in a different manner: Domke (2008), Hosseini et al. (2010), Theis et al. (2012), Uria et al. (2013), Theis et al. (2015). Note that the logistic distribution is a special case of the Gaussian scale mixture (West, 1978).\n\nThe main difference seems to be the integration of the density to model integers. While this is clearly a good idea and the right way forward, the authors claim but do not support that not doing this has \u201cproved to be a problem for earlier models based on continuous distributions\u201d. Please elaborate, add a reference, or ideally report the performance achieved by PixelCNN++ without integration (and instead adding uniform noise to make the variables continuous).\n\n60,000 images are not a lot in a high-dimensional space. While I can see the usefulness of regularization for specialized content \u2013 and this can serve as a good example to demonstrate the usefulness of dropout \u2013 why not use \u201c80 million tiny images\u201d (superset of CIFAR-10) for natural images? Semi-supervised learning should be fairly trivial here (because the model\u2019s likelihood is tractable), so this data could even be used in the class-conditional case.\n\nIt would be interesting to know how fast the different models are at test time (i.e., when generating images).", "IS_ANNOTATED": true, "IS_META_REVIEW": false, "RECOMMENDATION": 7, "DATE": "16 Dec 2016", "REVIEWER_CONFIDENCE": 5}, {"SUBSTANCE": 3, "TITLE": "Model validity after down- and upsampling", "OTHER_KEYS": "ICLR 2017 conference AnonReviewer2", "comments": "", "IS_ANNOTATED": true, "IS_META_REVIEW": false, "DATE": "02 Dec 2016"}, {"TITLE": "Comparison to non-discretized distributions", "SUBSTANCE": 3, "OTHER_KEYS": "ICLR 2017 conference AnonReviewer1", "RECOMMENDATION_UNOFFICIAL": 4, "comments": "", "ORIGINALITY": 5, "IS_ANNOTATED": true, "IS_META_REVIEW": false, "DATE": "02 Dec 2016"}, {"DATE": "02 Dec 2016", "TITLE": "Conditional likelihood score", "IS_META_REVIEW": false, "comments": "Was the class conditional log-likelihood score marginalized over the 10 classes? (Section 3.2)", "OTHER_KEYS": "Ryan Dahl"}, {"OTHER_KEYS": "ICLR 2017 conference AnonReviewer3", "TITLE": "Traversal Ordering", "comments": "", "SOUNDNESS_CORRECTNESS": 4, "ORIGINALITY": 4, "IS_ANNOTATED": true, "IS_META_REVIEW": false, "DATE": "01 Dec 2016", "CLARITY": 5}, {"IS_META_REVIEW": true, "comments": "Summary:\nThis paper on autoregressive generative models explores various extensions of PixelCNNs. The proposed changes are to replace the softmax function with a logistic mixture model, to use dropout for regularization, to use downsampling to increase receptive field size, and the introduction of particular skip connections. The authors find that this allows the PixelCNN to outperform a PixelRNN on CIFAR-10, the previous state-of-the-art model. The authors further explore the performance of PixelCNNs with smaller receptive field sizes.\n\nReview:\nThis is a useful contribution towards better tractable image models. In particular, autoregressive models can be quite slow at test time, and the more efficient architectures described here should help with that.\n\nMy main criticism regards the severe neglect of related work. Mixture models have been used a lot in autoregressive image modeling, including for multivariate conditional densities and including downsampling to increase receptive field size, albeit in a different manner: Domke (2008), Hosseini et al. (2010), Theis et al. (2012), Uria et al. (2013), Theis et al. (2015). Note that the logistic distribution is a special case of the Gaussian scale mixture (West, 1978).\n\nThe main difference seems to be the integration of the density to model integers. While this is clearly a good idea and the right way forward, the authors claim but do not support that not doing this has \u201cproved to be a problem for earlier models based on continuous distributions\u201d. Please elaborate, add a reference, or ideally report the performance achieved by PixelCNN++ without integration (and instead adding uniform noise to make the variables continuous).\n\n60,000 images are not a lot in a high-dimensional space. While I can see the usefulness of regularization for specialized content \u2013 and this can serve as a good example to demonstrate the usefulness of dropout \u2013 why not use \u201c80 million tiny images\u201d (superset of CIFAR-10) for natural images? Semi-supervised learning should be fairly trivial here (because the model\u2019s likelihood is tractable), so this data could even be used in the class-conditional case.\n\nIt would be interesting to know how fast the different models are at test time (i.e., when generating images)."}, {"DATE": "06 Feb 2017", "TITLE": "ICLR committee final decision", "IS_META_REVIEW": false, "comments": " The authors acknowledge that the ideas in the paper are incremental, but assert these are not-trivial improvements upon prior work on pixel CNNs. The reviewers tended to agree with this characterization. The paper presents SOTA pixel likelihood results on CIFAR-10. This work is also coupled with a high quality source code contribution, which also appears to have already been well received by the github community. Reviewer 1 made the point that in terms of raw novelty this work is probably a little below the bar for an oral presentation. A public reviewer rated this paper as a strong accept. Given the statistics, quality and originality of the other papers in my AC batch I recommend poster.", "OTHER_KEYS": "ICLR 2017 pcs"}, {"DATE": "18 Jan 2017", "TITLE": "new revision incorporating reviewer recommendations", "IS_META_REVIEW": false, "comments": "We uploaded a new revision incorporating some of the suggestions made by the reviewers. Thank you for your input!\n\nSpecifically, the revision incorporates additional references and an experimental comparison with continuous mixture models as suggested by reviewer 2, and a more detailed description of the likelihood model, including equations, as requested by reviewer 3.", "OTHER_KEYS": "Tim Salimans"}, {"TITLE": "Good experimental work, reinstating classic heuristics back into AR CNN.", "OTHER_KEYS": "Galin Georgiev", "comments": "It is refreshing that OpenAI has taken the time to resurrect classic heuristics like down-sampling and dropout into PixelCNN. Some sort of AR technique like PixelCNN probably holds the missing keys needed to eventually have decent originally-created images from CIFAR10 or other real-life data-sets. So any engineering streamlining, as in this paper, is welcome to the general public, especially when helping to avoid expensive clusters of GPUs, only DeepMind can afford. In this sense, OpenAI is fulfilling its mission and we are all very grateful! Thus the paper is a welcome addition and we hope it finds its way into what appears to be an experimental CS conference anyway. \n\nOn a more conceptual level, our hope is that OpenAI, with so talented a team, will stop competing in these contrived contests to improve by basis points certain obscure log-likelihoods and instead focus on the bigger picture problems. Why for example, almost two years later, the class-conditional CIFAR10 samples, as on the left of Figure 4 in this paper (column 8 - class of horses), are still inferior to, say, the samples on Figure 4 of reference [2]? Forgive the pun, but aren't we beating a dead horse here? Yes, resolution and sharpness have improved, due to good engineering but nobody in the general public will take these samples seriously! Despite the claims put forward by some on the DeepMind team, PixelCNN is not a \"fully-generative\" neural net (as rigorously defined in section 3 of reference [1]), but merely a perturbative net, in the vain of the Boltzmann machine. After the Procrustean experience of lost decades on Boltzmann machines, the time perhaps has come to think more about the fundamentals and less about the heuristics?\n\n[1] ", "IS_META_REVIEW": false, "RECOMMENDATION": 9, "DATE": "06 Jan 2017", "REVIEWER_CONFIDENCE": 4}, {"TITLE": "Review", "SUBSTANCE": 3, "RECOMMENDATION_UNOFFICIAL": 4, "OTHER_KEYS": "ICLR 2017 conference AnonReviewer1", "comments": "Apologies for the late submission of this review, and thank you for the author\u2019s responses to earlier questions.\n\nThis submission proposes an improved implementation of the PixelCNN generative model. Most of the improvements are small and can be considered as specific technical details such as the use of dropout and skip connections, while others are slightly more substantial such as the use of a different likelihood model and multiscale analysis. The submission demonstrates state-of-the-art likelihood results on CIFAR-10.\n\nMy summary of the main contribution:\nAutoregressive-type models - of which PixelCNN is an example - are a nice class of models as their likelihood can be evaluated in closed form. A main differentiator for this type of models is how the conditional likelihood of one pixel conditioned on its causal neighbourhood is modelled:\n\n- In one line of work such as (Theis et al, 2012 MCGSM, Theis et al 2015 Spatial LSTM) the conditional distribution is modelled as a continuous density over real numbers. This approach has limitations: We know that in observed data pixel intensities are quantized to a discrete integer representation so a discrete distribution could give better likelihoods. Furthermore these continuous distributions have a tail and assign some probability mass outside the valid range of pixel intensities, which may hurt the likelihood.\n- In more recent work by van den Oord and colleagues the conditional likelihood is modelled as an arbitrary discrete distribution over the 256 possible values for pixel intensities. This does not suffer from the limitations of continuous likelihoods, but it also seems wasteful and is not very data efficient.\n\nThe authors propose something in the middle by keeping the discretized nature of the conditional likelihood, but restricting the discrete distribution to ones whose CDF that can be modeled as a linear combination of sigmoids. This approach makes sense to me, and is new in a way, but it doesn\u2019t appear to be very revolutionary or significant to me.\n\nThe second somewhat significant modification is the use of downsampling and multiscale modelling (as opposed to dilated convolutions). The main motivation for the authors to do this is saving computation time while keeping the multiscale flexibility of the model. The authors also introduce shortcut connections to compensate for the potential loss of information as they perform downsampling. Again, I feel that this modification not particularly revolutionary. Multiscale image analysis with autoregressive generative models has been done for example in (Theis et al, 2012) and several other papers.\n\nOverall I felt that this submission falls short on presenting substantially new ideas, and reads more like documentation for a particular implementation of an existing idea.", "ORIGINALITY": 5, "IS_ANNOTATED": true, "IS_META_REVIEW": false, "RECOMMENDATION": 6, "DATE": "22 Dec 2016 (modified: 19 Jan 2017)", "REVIEWER_CONFIDENCE": 3}, {"OTHER_KEYS": "ICLR 2017 conference AnonReviewer3", "TITLE": "Great empirical work, insightful ablation experiments, code is available which is a nice contribution to the community", "comments": "# Review\nThis paper proposes five modifications to improve PixelCNN, a generative model with tractable likelihood. The authors empirically showed the impact of each of their proposed modifications using a series of ablation experiments. They also reported a new state-of-the-art result on CIFAR-10.\nImproving generative models, especially for images, is an active research area and this paper definitely contributes to it.\n\n\n# Pros\nThe authors motivate each modification well they proposed. They also used ablation experiments to show each of them is important.\n\nThe authors use a discretized mixture of logistic distributions to model the conditional distribution of a sub-pixel instead of a 256-way softmax. This allows to have a lower output dimension and to be better suited at learning ordinal relationships between sub-pixel values. The authors also mentioned it speeded up training time (less computation) as well as the convergence during the optimization of the model (as shown in Fig.6).\n\nThe authors make an interesting remark about how the dependencies between the color channels of a pixel are likely to be relatively simple and do not require a deep network to model. This allows them to have a simplified architecture where you don't have to separate out all feature maps in 3 groups depending on whether or not they can see the R/G/B sub-pixel of the current location.\n\n\n# Cons\nIt is not clear to me what the predictive distribution for the green channel (and the blue) looks like. More precisely, how are the means of the mixture components linearly depending on the value of the red sub-pixel? I would have liked to see the equations for them.\n\n\n# Minor Comments\nIn Fig.2 it is written \"Sequence of 6 layers\" but in the text (Section 2.4) it says 6 blocks of 5 ResNet layers. What is the remaining layer?\nIn Fig.2 what does the first \"green square -> blue square\" which isn't in the white rectangle represents?\nIs there any reason why the mixture indicator is shared across all three channels?", "SOUNDNESS_CORRECTNESS": 4, "ORIGINALITY": 4, "IS_ANNOTATED": true, "IS_META_REVIEW": false, "RECOMMENDATION": 7, "DATE": "17 Dec 2016", "CLARITY": 5, "REVIEWER_CONFIDENCE": 4}, {"SUBSTANCE": 3, "OTHER_KEYS": "ICLR 2017 conference AnonReviewer2", "TITLE": "Related work", "comments": "Summary:\nThis paper on autoregressive generative models explores various extensions of PixelCNNs. The proposed changes are to replace the softmax function with a logistic mixture model, to use dropout for regularization, to use downsampling to increase receptive field size, and the introduction of particular skip connections. The authors find that this allows the PixelCNN to outperform a PixelRNN on CIFAR-10, the previous state-of-the-art model. The authors further explore the performance of PixelCNNs with smaller receptive field sizes.\n\nReview:\nThis is a useful contribution towards better tractable image models. In particular, autoregressive models can be quite slow at test time, and the more efficient architectures described here should help with that.\n\nMy main criticism regards the severe neglect of related work. Mixture models have been used a lot in autoregressive image modeling, including for multivariate conditional densities and including downsampling to increase receptive field size, albeit in a different manner: Domke (2008), Hosseini et al. (2010), Theis et al. (2012), Uria et al. (2013), Theis et al. (2015). Note that the logistic distribution is a special case of the Gaussian scale mixture (West, 1978).\n\nThe main difference seems to be the integration of the density to model integers. While this is clearly a good idea and the right way forward, the authors claim but do not support that not doing this has \u201cproved to be a problem for earlier models based on continuous distributions\u201d. Please elaborate, add a reference, or ideally report the performance achieved by PixelCNN++ without integration (and instead adding uniform noise to make the variables continuous).\n\n60,000 images are not a lot in a high-dimensional space. While I can see the usefulness of regularization for specialized content \u2013 and this can serve as a good example to demonstrate the usefulness of dropout \u2013 why not use \u201c80 million tiny images\u201d (superset of CIFAR-10) for natural images? Semi-supervised learning should be fairly trivial here (because the model\u2019s likelihood is tractable), so this data could even be used in the class-conditional case.\n\nIt would be interesting to know how fast the different models are at test time (i.e., when generating images).", "IS_ANNOTATED": true, "IS_META_REVIEW": false, "RECOMMENDATION": 7, "DATE": "16 Dec 2016", "REVIEWER_CONFIDENCE": 5}, {"SUBSTANCE": 3, "TITLE": "Model validity after down- and upsampling", "OTHER_KEYS": "ICLR 2017 conference AnonReviewer2", "comments": "", "IS_ANNOTATED": true, "IS_META_REVIEW": false, "DATE": "02 Dec 2016"}, {"TITLE": "Comparison to non-discretized distributions", "SUBSTANCE": 3, "OTHER_KEYS": "ICLR 2017 conference AnonReviewer1", "RECOMMENDATION_UNOFFICIAL": 4, "comments": "", "ORIGINALITY": 5, "IS_ANNOTATED": true, "IS_META_REVIEW": false, "DATE": "02 Dec 2016"}, {"DATE": "02 Dec 2016", "TITLE": "Conditional likelihood score", "IS_META_REVIEW": false, "comments": "Was the class conditional log-likelihood score marginalized over the 10 classes? (Section 3.2)", "OTHER_KEYS": "Ryan Dahl"}, {"OTHER_KEYS": "ICLR 2017 conference AnonReviewer3", "TITLE": "Traversal Ordering", "comments": "", "SOUNDNESS_CORRECTNESS": 4, "ORIGINALITY": 4, "IS_ANNOTATED": true, "IS_META_REVIEW": false, "DATE": "01 Dec 2016", "CLARITY": 5}], "authors": "Tim Salimans, Andrej Karpathy, Xi Chen, Diederik P. Kingma", "accepted": true, "id": "336"}