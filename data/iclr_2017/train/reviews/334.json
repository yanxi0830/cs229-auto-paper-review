{"conference": "ICLR 2017 conference submission", "title": "Emergence of foveal image sampling from learning to attend in visual scenes", "abstract": "We describe a neural attention model with a learnable retinal sampling lattice. The model is trained on a visual search task requiring the classification of an object embedded in a visual scene amidst background distractors using the smallest number of fixations. We explore the tiling properties that emerge in the model's retinal sampling lattice after training. Specifically, we show that this lattice resembles the eccentricity dependent sampling lattice of the primate retina, with a high resolution region in the fovea surrounded by a low resolution periphery. Furthermore, we find conditions where these emergent properties are amplified or eliminated providing clues to their function.", "histories": [], "reviews": [{"IS_META_REVIEW": true, "comments": "This paper proposed a neural attention model which has a learnable and differentiable sampling lattice. The work is well motivated as few previous work focus on learning the sampling lattice but with a fixed lattice. This work is quite similar to Spatial Transformer Networks (Jaderberg 2015), but the sampling lattice is learned by the model. The experiments showed that the model can learn a meaning lattice to the visual search task where the sampling lattice looks similar to human being's. \n\nThe main concern of the paper is that experiments are not sufficient. The paper only reports the results on a modified clustered MNIST dataset. It would be more interesting if the authors could conduct  the model on real datasets, such as Toronto Face dataset, CUB bird dataset and SVHN. For example, for the Face dataset, it would be nice if the model can learn to attend different parts of the face for expression recognition, or attend different part of birds for fine-grained classification. Since the authors replied in the pre-review question that the model can learn meaningful lattice on MSCOCO dataset, I think it would be better to add that results into the paper.\n\nAnother drawback of the model is that the paper only compare with different variants of itselves. I suggest that this paper should compare with  Spatial Transformer Networks, DRAW, etc., on the same dataset to show the advantage of the learned sampling lattice."}, {"DATE": "06 Feb 2017", "TITLE": "ICLR committee final decision", "IS_META_REVIEW": false, "comments": "This was a borderline case. All reviewers and the AC appeared to find the paper interesting, while having some reservations. Given the originality of the work, the PCs decided to lean toward acceptance. We do encourage however the authors to revise their paper based on reviewer feedback as much as possible, to increase its potential for impact.", "OTHER_KEYS": "ICLR 2017 pcs"}, {"OTHER_KEYS": "ICLR 2017 conference AnonReviewer1", "TITLE": "Solid hypothesis but experiments leave doubts", "comments": "This paper presents a succinct argument that the principle of optimizing receptive field location and size in a simulated eye that can make saccades with respect to a classification error of images of data whose labels depend on variable-size and variable-location subimages, explains the existence of a foveal area in e.g. the primate retina.\n\nThe argument could be improved by using more-realistic image data and drawing more direct correspondence with the number, receptive field sizes and eccentricities of retinal cells in e.g. the macaque, but the authors would then face the challenge of identifying a loss function that is both biologically plausible and supportive of their claim.\n\nThe argument could also be improved by commenting on the timescales involved. Presumably the density of the foveal center depends on the number of of saccades allowed by the inference process, as well as the size of the target sub-images, and also has an impact on the overall classification accuracy.\n\nWhy does the classification error rate of dataset 2 remain stubbornly at 24%? This seems so high that the model may not be working the way we\u2019d like it to. It seems that the overall argument of the paper pre-supposes that the model can be trained to be a good classifier. If there are other training strategies or other models that work better and differently, then it raises the question of why do our eyes and visual cortex not work more like *those ones* if evolutionary pressures are applying the same pressure as our training objective.\n\nWhy does the model with zooming powers out-do the translation-only model on dataset 1 (where all target images are the same size) and tie the translation-only model dataset 2 (where the target images have different sizes, for which the zooming model should be tailor-made?). Between this strange tie and the high classification rate on Dataset 2, I wonder if maybe one or both models isn\u2019t being trained to its potential, which would undermine the overall claim.\n\nComparing this model to other attention models (e.g. spatial transformer networks, DRAW) would be irrelevant to what I take to be the main point of the paper, but it would address the potential concerns above that training just didn\u2019t go very well, or there was some problem with the model parameterization that could be easily fixed.", "SOUNDNESS_CORRECTNESS": 5, "IS_ANNOTATED": true, "IS_META_REVIEW": false, "RECOMMENDATION": 6, "DATE": "24 Dec 2016", "REVIEWER_CONFIDENCE": 4}, {"TITLE": "Review", "RECOMMENDATION_UNOFFICIAL": 2, "OTHER_KEYS": "ICLR 2017 conference AnonReviewer2", "comments": "The paper presented an extension to the current visual attention model that learns a deformable sampling lattice.  Comparing to the fixed sampling lattice from previous works, the proposed method shows different sampling strategy can emerge depending on the visual classification tasks. The authors empirically demonstrated the learnt sampling lattice outperforms the fixed strategies. More interestingly, when the attention mechanism is constrained  to be translation only, the proposed model learns a sampling lattice resembles the retina found in the primate retina.  \n\n\nPros:\n+ The paper is generally well organized and written \n+ The qualitative analysis in the experimental section is very comprehensive.\n\nCons:\n-  The paper could benefit substantially from additional experiments on different datasets.\n-  It is not clear from the tables the proposed learnt sampling  lattice offer any computation benefit when comparing to  a fixed sampling strategy with zooming capability, e.g. the one used in DRAW model.\n\nOverall, I really like the paper. I think the experimental section can be improved by additional experiments and more quantitative analysis with other baselines. Because the current revision of the paper only shows experiments on digit dataset with black background, it is hard to generalize the finding or even to verify the claims in the paper, e.g.  linear relationship\nbetween eccentricity and sampling interval leads to the primate retina, from the results on a single dataset.", "ORIGINALITY": 3, "IS_ANNOTATED": true, "IS_META_REVIEW": false, "RECOMMENDATION": 5, "DATE": "20 Dec 2016", "REVIEWER_CONFIDENCE": 4}, {"OTHER_KEYS": "ICLR 2017 conference AnonReviewer3", "TITLE": "A good apporach to attention-based models", "comments": "This paper proposed a neural attention model which has a learnable and differentiable sampling lattice. The work is well motivated as few previous work focus on learning the sampling lattice but with a fixed lattice. This work is quite similar to Spatial Transformer Networks (Jaderberg 2015), but the sampling lattice is learned by the model. The experiments showed that the model can learn a meaning lattice to the visual search task where the sampling lattice looks similar to human being's. \n\nThe main concern of the paper is that experiments are not sufficient. The paper only reports the results on a modified clustered MNIST dataset. It would be more interesting if the authors could conduct  the model on real datasets, such as Toronto Face dataset, CUB bird dataset and SVHN. For example, for the Face dataset, it would be nice if the model can learn to attend different parts of the face for expression recognition, or attend different part of birds for fine-grained classification. Since the authors replied in the pre-review question that the model can learn meaningful lattice on MSCOCO dataset, I think it would be better to add that results into the paper.\n\nAnother drawback of the model is that the paper only compare with different variants of itselves. I suggest that this paper should compare with  Spatial Transformer Networks, DRAW, etc., on the same dataset to show the advantage of the learned sampling lattice.", "SOUNDNESS_CORRECTNESS": 5, "IS_ANNOTATED": true, "IS_META_REVIEW": false, "RECOMMENDATION": 6, "DATE": "16 Dec 2016", "CLARITY": 5, "REVIEWER_CONFIDENCE": 5}, {"TITLE": "Comparison to distribution of some primate's receptive fields?", "OTHER_KEYS": "ICLR 2017 conference AnonReviewer1", "comments": "", "SOUNDNESS_CORRECTNESS": 5, "IS_ANNOTATED": true, "IS_META_REVIEW": false, "DATE": "11 Dec 2016"}, {"TITLE": "interesting experiments", "OTHER_KEYS": "ICLR 2017 conference AnonReviewer2", "RECOMMENDATION_UNOFFICIAL": 2, "comments": "", "ORIGINALITY": 3, "IS_ANNOTATED": true, "IS_META_REVIEW": false, "DATE": "08 Dec 2016"}, {"OTHER_KEYS": "ICLR 2017 conference AnonReviewer3", "TITLE": "experiments on other real datasets", "comments": "", "SOUNDNESS_CORRECTNESS": 5, "IS_ANNOTATED": true, "IS_META_REVIEW": false, "DATE": "30 Nov 2016", "CLARITY": 5}, {"IS_META_REVIEW": true, "comments": "This paper proposed a neural attention model which has a learnable and differentiable sampling lattice. The work is well motivated as few previous work focus on learning the sampling lattice but with a fixed lattice. This work is quite similar to Spatial Transformer Networks (Jaderberg 2015), but the sampling lattice is learned by the model. The experiments showed that the model can learn a meaning lattice to the visual search task where the sampling lattice looks similar to human being's. \n\nThe main concern of the paper is that experiments are not sufficient. The paper only reports the results on a modified clustered MNIST dataset. It would be more interesting if the authors could conduct  the model on real datasets, such as Toronto Face dataset, CUB bird dataset and SVHN. For example, for the Face dataset, it would be nice if the model can learn to attend different parts of the face for expression recognition, or attend different part of birds for fine-grained classification. Since the authors replied in the pre-review question that the model can learn meaningful lattice on MSCOCO dataset, I think it would be better to add that results into the paper.\n\nAnother drawback of the model is that the paper only compare with different variants of itselves. I suggest that this paper should compare with  Spatial Transformer Networks, DRAW, etc., on the same dataset to show the advantage of the learned sampling lattice."}, {"DATE": "06 Feb 2017", "TITLE": "ICLR committee final decision", "IS_META_REVIEW": false, "comments": "This was a borderline case. All reviewers and the AC appeared to find the paper interesting, while having some reservations. Given the originality of the work, the PCs decided to lean toward acceptance. We do encourage however the authors to revise their paper based on reviewer feedback as much as possible, to increase its potential for impact.", "OTHER_KEYS": "ICLR 2017 pcs"}, {"OTHER_KEYS": "ICLR 2017 conference AnonReviewer1", "TITLE": "Solid hypothesis but experiments leave doubts", "comments": "This paper presents a succinct argument that the principle of optimizing receptive field location and size in a simulated eye that can make saccades with respect to a classification error of images of data whose labels depend on variable-size and variable-location subimages, explains the existence of a foveal area in e.g. the primate retina.\n\nThe argument could be improved by using more-realistic image data and drawing more direct correspondence with the number, receptive field sizes and eccentricities of retinal cells in e.g. the macaque, but the authors would then face the challenge of identifying a loss function that is both biologically plausible and supportive of their claim.\n\nThe argument could also be improved by commenting on the timescales involved. Presumably the density of the foveal center depends on the number of of saccades allowed by the inference process, as well as the size of the target sub-images, and also has an impact on the overall classification accuracy.\n\nWhy does the classification error rate of dataset 2 remain stubbornly at 24%? This seems so high that the model may not be working the way we\u2019d like it to. It seems that the overall argument of the paper pre-supposes that the model can be trained to be a good classifier. If there are other training strategies or other models that work better and differently, then it raises the question of why do our eyes and visual cortex not work more like *those ones* if evolutionary pressures are applying the same pressure as our training objective.\n\nWhy does the model with zooming powers out-do the translation-only model on dataset 1 (where all target images are the same size) and tie the translation-only model dataset 2 (where the target images have different sizes, for which the zooming model should be tailor-made?). Between this strange tie and the high classification rate on Dataset 2, I wonder if maybe one or both models isn\u2019t being trained to its potential, which would undermine the overall claim.\n\nComparing this model to other attention models (e.g. spatial transformer networks, DRAW) would be irrelevant to what I take to be the main point of the paper, but it would address the potential concerns above that training just didn\u2019t go very well, or there was some problem with the model parameterization that could be easily fixed.", "SOUNDNESS_CORRECTNESS": 5, "IS_ANNOTATED": true, "IS_META_REVIEW": false, "RECOMMENDATION": 6, "DATE": "24 Dec 2016", "REVIEWER_CONFIDENCE": 4}, {"TITLE": "Review", "RECOMMENDATION_UNOFFICIAL": 2, "OTHER_KEYS": "ICLR 2017 conference AnonReviewer2", "comments": "The paper presented an extension to the current visual attention model that learns a deformable sampling lattice.  Comparing to the fixed sampling lattice from previous works, the proposed method shows different sampling strategy can emerge depending on the visual classification tasks. The authors empirically demonstrated the learnt sampling lattice outperforms the fixed strategies. More interestingly, when the attention mechanism is constrained  to be translation only, the proposed model learns a sampling lattice resembles the retina found in the primate retina.  \n\n\nPros:\n+ The paper is generally well organized and written \n+ The qualitative analysis in the experimental section is very comprehensive.\n\nCons:\n-  The paper could benefit substantially from additional experiments on different datasets.\n-  It is not clear from the tables the proposed learnt sampling  lattice offer any computation benefit when comparing to  a fixed sampling strategy with zooming capability, e.g. the one used in DRAW model.\n\nOverall, I really like the paper. I think the experimental section can be improved by additional experiments and more quantitative analysis with other baselines. Because the current revision of the paper only shows experiments on digit dataset with black background, it is hard to generalize the finding or even to verify the claims in the paper, e.g.  linear relationship\nbetween eccentricity and sampling interval leads to the primate retina, from the results on a single dataset.", "ORIGINALITY": 3, "IS_ANNOTATED": true, "IS_META_REVIEW": false, "RECOMMENDATION": 5, "DATE": "20 Dec 2016", "REVIEWER_CONFIDENCE": 4}, {"OTHER_KEYS": "ICLR 2017 conference AnonReviewer3", "TITLE": "A good apporach to attention-based models", "comments": "This paper proposed a neural attention model which has a learnable and differentiable sampling lattice. The work is well motivated as few previous work focus on learning the sampling lattice but with a fixed lattice. This work is quite similar to Spatial Transformer Networks (Jaderberg 2015), but the sampling lattice is learned by the model. The experiments showed that the model can learn a meaning lattice to the visual search task where the sampling lattice looks similar to human being's. \n\nThe main concern of the paper is that experiments are not sufficient. The paper only reports the results on a modified clustered MNIST dataset. It would be more interesting if the authors could conduct  the model on real datasets, such as Toronto Face dataset, CUB bird dataset and SVHN. For example, for the Face dataset, it would be nice if the model can learn to attend different parts of the face for expression recognition, or attend different part of birds for fine-grained classification. Since the authors replied in the pre-review question that the model can learn meaningful lattice on MSCOCO dataset, I think it would be better to add that results into the paper.\n\nAnother drawback of the model is that the paper only compare with different variants of itselves. I suggest that this paper should compare with  Spatial Transformer Networks, DRAW, etc., on the same dataset to show the advantage of the learned sampling lattice.", "SOUNDNESS_CORRECTNESS": 5, "IS_ANNOTATED": true, "IS_META_REVIEW": false, "RECOMMENDATION": 6, "DATE": "16 Dec 2016", "CLARITY": 5, "REVIEWER_CONFIDENCE": 5}, {"TITLE": "Comparison to distribution of some primate's receptive fields?", "OTHER_KEYS": "ICLR 2017 conference AnonReviewer1", "comments": "", "SOUNDNESS_CORRECTNESS": 5, "IS_ANNOTATED": true, "IS_META_REVIEW": false, "DATE": "11 Dec 2016"}, {"TITLE": "interesting experiments", "OTHER_KEYS": "ICLR 2017 conference AnonReviewer2", "RECOMMENDATION_UNOFFICIAL": 2, "comments": "", "ORIGINALITY": 3, "IS_ANNOTATED": true, "IS_META_REVIEW": false, "DATE": "08 Dec 2016"}, {"OTHER_KEYS": "ICLR 2017 conference AnonReviewer3", "TITLE": "experiments on other real datasets", "comments": "", "SOUNDNESS_CORRECTNESS": 5, "IS_ANNOTATED": true, "IS_META_REVIEW": false, "DATE": "30 Nov 2016", "CLARITY": 5}], "authors": "Brian Cheung, Eric Weiss, Bruno Olshausen", "accepted": true, "id": "334"}