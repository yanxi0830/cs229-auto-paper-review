{"conference": "ICLR 2017 conference submission", "title": "Understanding trained CNNs by indexing neuron selectivity", "abstract": "The impressive performance and plasticity of convolutional neural networks to solve different vision problems are shadowed by their black-box nature and its consequent lack of full understanding. To reduce this gap we propose to describe the activity of individual neurons by quantifiyng their inherent selectivity to specific properties. Our approach is based on the definition of feature selectivity indexes that allow the ranking of neurons according to specific properties. Here we report the results of exploring selectivity indexes for: (a) an image feature (color); and (b) an image label (class membership). Our contribution is a framework to seek or classify neurons by indexing on these selectivity properties. It helps to find color selective neurons, such as a red-mushroom neuron in layer conv4 or class selective neurons such as dog-face neurons in layer conv5, and establishes a methodology to derive other selectivity properties.  Indexing on neuron selectivity can statistically draw how features and classes are represented through layers at a moment when the size of trained nets is growing and automatic tools to index can be helpful.", "histories": [], "reviews": [{"IS_META_REVIEW": true, "comments": "This paper makes three main methodological contributions:\n - definition of Neural Feature (NF) as the pixel average of the top N images that highly activation a neuron\n - ranking of neurons based on color selectivity\n - ranking of neurons based on class selectivity\n\nThe main weaknesses of the paper are that none of the methodological contributions are very significant, and no singularly significant result arises from the application of the methods.\n\nHowever, the main strengths of the paper are its assortment of moderately-sized interesting conclusions about the basic behavior of neural nets. For example, a few are:\n - \u201cIndexing on class selectivity neurons we found highly class selective neurons like digital-clock at conv2, cardoon at conv3 and ladybug at conv5, much before the fully connected layers.\u201d As far as I know, this had not been previously reported.\n - Color selective neurons are found even in higher layers. (25% color selectivity in conv5)\n - \u201cour main color axis emerge (black-white, blue-yellow, orange-cyan and cyan- magenta). Curiously, these two observations correlate with evidences in the human visual system (Shapley & Hawken (2011)).\u201d Great observation!\n\nOverall, I\u2019d recommend the paper be accepted, because although it\u2019s difficult to predict at this time, there\u2019s a fair chance that one of the \u201csmaller conclusions\u201d would turn out to be important in hindsight a few years hence.\n\n\nOther small comments:\n - The cite for \u201cLearning to generate chairs\u2026\u201d is wrong (first two authors combined resulting in a confusing cite)\n\n - What exactly is the Color Selectivity Index computing? The Opponent Color Space isn\u2019t well defined and it wasn\u2019t previously familiar to me. Intuitively it seems to be selecting for units that respond to a constant color, but the highest color selectivity NF in Fig 5 i for a unit with two colors, not one. Finally, the very last unit (lowest color selectivity) is almost the same edge pattern, but with white -> black instead of blue -> orange. Why are these considered to be so drastically different? This should probably be more clearly described.\n\n - For the sake of argument, imagine a mushroom sensitive neuron in conv5 that fires highly for mushrooms of *any* color but not for anything else. If the dataset contains only red-capped mushrooms, would the color selectivity index for this neuron be high or low? If it is high, it\u2019s somewhat misleading because the unit itself actually isn\u2019t color selective; the dataset just happens only to have red mushrooms in it. (It\u2019s a subtle point but worth considering and probably discussing in the paper)"}, {"DATE": "06 Feb 2017", "TITLE": "ICLR committee final decision", "IS_META_REVIEW": false, "comments": "While this is interesting work, one major concern comes from Reviewer 2 regarding the attempt of characterizing the tuning properties, which has proven useless both in neuroscience and in machine learning. Currently, no attempt so far has lived up to the promises this line of research is aiming for. In summary, this work is explorative and incremental but worthwhile. We encourage the authors to further refine their research effort and resubmit.", "OTHER_KEYS": "ICLR 2017 pcs"}, {"DATE": "03 Feb 2017", "TITLE": "Some connections/cites", "IS_META_REVIEW": false, "comments": "Hi authors,\n\nCongrats for an interesting submission! I wonder what other selectivity indices you could use beside color and class.\n\nI just noticed that your definition of Neuron Feature (weighted average image) is very close to what we use in this paper (an average image):\n\n", "OTHER_KEYS": "Anh Nguyen"}, {"TITLE": "Solid work leading to a few interesting conclusions", "OTHER_KEYS": "ICLR 2017 conference AnonReviewer3", "comments": "This paper makes three main methodological contributions:\n - definition of Neural Feature (NF) as the pixel average of the top N images that highly activation a neuron\n - ranking of neurons based on color selectivity\n - ranking of neurons based on class selectivity\n\nThe main weaknesses of the paper are that none of the methodological contributions are very significant, and no singularly significant result arises from the application of the methods.\n\nHowever, the main strengths of the paper are its assortment of moderately-sized interesting conclusions about the basic behavior of neural nets. For example, a few are:\n - \u201cIndexing on class selectivity neurons we found highly class selective neurons like digital-clock at conv2, cardoon at conv3 and ladybug at conv5, much before the fully connected layers.\u201d As far as I know, this had not been previously reported.\n - Color selective neurons are found even in higher layers. (25% color selectivity in conv5)\n - \u201cour main color axis emerge (black-white, blue-yellow, orange-cyan and cyan- magenta). Curiously, these two observations correlate with evidences in the human visual system (Shapley & Hawken (2011)).\u201d Great observation!\n\nOverall, I\u2019d recommend the paper be accepted, because although it\u2019s difficult to predict at this time, there\u2019s a fair chance that one of the \u201csmaller conclusions\u201d would turn out to be important in hindsight a few years hence.\n\n\nOther small comments:\n - The cite for \u201cLearning to generate chairs\u2026\u201d is wrong (first two authors combined resulting in a confusing cite)\n\n - What exactly is the Color Selectivity Index computing? The Opponent Color Space isn\u2019t well defined and it wasn\u2019t previously familiar to me. Intuitively it seems to be selecting for units that respond to a constant color, but the highest color selectivity NF in Fig 5 i for a unit with two colors, not one. Finally, the very last unit (lowest color selectivity) is almost the same edge pattern, but with white -> black instead of blue -> orange. Why are these considered to be so drastically different? This should probably be more clearly described.\n\n - For the sake of argument, imagine a mushroom sensitive neuron in conv5 that fires highly for mushrooms of *any* color but not for anything else. If the dataset contains only red-capped mushrooms, would the color selectivity index for this neuron be high or low? If it is high, it\u2019s somewhat misleading because the unit itself actually isn\u2019t color selective; the dataset just happens only to have red mushrooms in it. (It\u2019s a subtle point but worth considering and probably discussing in the paper)\n", "IS_META_REVIEW": false, "RECOMMENDATION": 7, "DATE": "27 Dec 2016", "REVIEWER_CONFIDENCE": 4}, {"TITLE": "review of \"UNDERSTANDING TRAINED CNNS BY INDEXING NEURON SELECTIVITY\"", "OTHER_KEYS": "ICLR 2017 conference AnonReviewer2", "comments": "The authors analyze trained neural networks by quantifying the selectivity of individual neurons in the network for a variety of specific features, including color and category.   \n\nPros:\n   * The paper is clearly written and has good figures. \n   * I think they executed their specific stated goal reasonably well technically.   E.g. the various indexes they use seem well-chosen for their purposes. \n\nCons:\n   * I must admit that I am biased against the whole enterprise of this paper.   I do not think it is well-motivated or provides any useful insight whatever.   What I view their having done is produced, and then summarized anecdotally, a catalog of piecemeal facts about a neural network without any larger reason to think these particular facts are important.  In a way, I feel like this paper suffers from the same problem that plagues a typical line of research in neurophysiology, in which a catalog of selectivity distributions of various neurons for various properties is produced -- full stop.  As if that were in and of itself important or useful information.   I do not feel that either the original neural version of that project, or this current model-based virtual electrophysiology, is that useful.   Why should we care about the distribution of color selectivities?   Why does knowing distribution as such constitute \"understanding\"?    To my mind it doesn't, at least not directly.   \n\nHere's what they could have done to make a more useful investigation:\n  \n     (a) From a neuroscience point of view, they could have compared the properties that they measure in models to the same properties as measured in neurons the real brain.   If they could show that some models are better matches on these properties to the actual neural data than others, that would be a really interesting result.   That is is to say, the two isolated catalogs of selectivities (from model neurons and real neurons)  alone seem pretty pointless.  But if the correspondence between the two catalogs was made -- both in terms of where the model neurons and the real neurons were similar, and (especially importantly) where they were different --- that would be the beginning of nontrivial understanding.   Such results would also complement a growing body of literature that attempts to link CNNs to visual brain areas.  Finding good neural data is challenging, but whatever the result, the comparison would be interesting. \n\nand/or \n\n    (b) From an artificial intelligence point of view, they could have shown that their metrics are *prescriptive* constraints.   That is, suppose they had shown that the specific color and class selectivity indices that they compute, when imposed as a loss-function criterion on an untrained neural network, cause the network to develop useful filters and achieve significantly above-chance performance on the original task the networks were trained on.     This would be a really great result, because it would not only give us a priori reason to care about the specific property metrics they chose, but it would also help contribute to efforts to find unsupervised (or semi-supervised) learning procedures, since the metrics they compute can be estimated from comparatively small numbers of stimuli and/or high-level semantic labels.    To put this in perspective, imagine that they had actually tested the above hypothesis and found it to be false:  that is, that their metrics, when used as loss function constraints, do not improve performance noticeably above chance performance.  What would we then make of this whole investigation?  It would then be reasonable to think that the measured properties were essentially epiphenomenal and didn't contribute at all to the power of neural networks in solving perceptual tasks.  (The same could be said about neurophysiology experiments doing the same thing.)  \n     [--> NB: I've actually tried things just like this myself over the years, and have found exactly this disappointing result.  Specifically,  I've found a number of high-level generic statistical property of DNNs that seem like they might potentially \"interesting\", e.g. because they apparently correlate with complexity or appear to illustrate difference between low, intermediate and high layers of DNNs.  Every single one of these, when imposed as optimization constraints, has basically lead nowhere on the challenging tasks (like ImageNet) that cause the DNNs to be interesting in the first place.  Basically, there is to my mind no evidence at this point that highly-summarized generic statistical distributions of selectivities, like those illustrated here, place any interesting constraints on filter weights at all.   Of course, I haven't tried the specific properties the authors highlight in these papers, so maybe there's something important there.]\n\nI know that both of these asks are pretty hard, but I just don't know what else to say -- this work otherwise seems like a step backwards for what the community ought to be spending its time on. \n ", "IS_META_REVIEW": false, "RECOMMENDATION": 3, "DATE": "20 Dec 2016", "REVIEWER_CONFIDENCE": 5}, {"TITLE": "Review of \"indexing neuron selectivity\"", "OTHER_KEYS": "ICLR 2017 conference AnonReviewer1", "comments": "This paper attempts to understand and visualize what deep nets are representing as one ascends from low levels to high levels of the network.  As has been shown previously, lower levels are more local image feature based, whereas higher levels correspond to abstract properties such as object identity.  In semantic space, we find higher level nodes to be more semantically selective, whereas low level nodes are more diffuse.\n\nThis seems like a good attempt to tease apart deep net representations.  Perhaps the most important finding is that color figures prominently into all levels of the network, and that performance on gray scale images is significantly diminished.  The new NF measure proposed here is sensible, but still based on the images shown to the network.  What one really wants to know is what function these nodes are computing - i.e., out of the space of *all* possible images, which most activate a unit?  Of course this is a difficult problem, but it would be nice to see us getting closer to understanding the answer.  The color analysis here I think brings us a bit closer.  The semantic analysis is nice but I'm not sure what new insight we gain from this.  \n", "IS_META_REVIEW": false, "RECOMMENDATION": 7, "DATE": "17 Dec 2016", "REVIEWER_CONFIDENCE": 3}, {"DATE": "16 Dec 2016", "TITLE": "Updated version", "IS_META_REVIEW": false, "comments": "We have updated the pdf of the paper after the reviewer comments, in this way:\n  - Giving more details about similarities and differences between the proposed approach and previous.\n  - Adding the clarifications required by the reviewers on Figure1\n  - Improving the global understanding by joining section 1 and 2 into a single one. ", "OTHER_KEYS": "Ivet Rafegas Fonoll"}, {"DATE": "15 Dec 2016", "TITLE": "Details of NF", "IS_META_REVIEW": false, "comments": "", "OTHER_KEYS": "ICLR 2017 conference AnonReviewer3"}, {"DATE": "11 Dec 2016", "TITLE": "Clarification of neural feature", "IS_META_REVIEW": false, "comments": "", "OTHER_KEYS": "ICLR 2017 conference AnonReviewer1"}, {"IS_META_REVIEW": true, "comments": "This paper makes three main methodological contributions:\n - definition of Neural Feature (NF) as the pixel average of the top N images that highly activation a neuron\n - ranking of neurons based on color selectivity\n - ranking of neurons based on class selectivity\n\nThe main weaknesses of the paper are that none of the methodological contributions are very significant, and no singularly significant result arises from the application of the methods.\n\nHowever, the main strengths of the paper are its assortment of moderately-sized interesting conclusions about the basic behavior of neural nets. For example, a few are:\n - \u201cIndexing on class selectivity neurons we found highly class selective neurons like digital-clock at conv2, cardoon at conv3 and ladybug at conv5, much before the fully connected layers.\u201d As far as I know, this had not been previously reported.\n - Color selective neurons are found even in higher layers. (25% color selectivity in conv5)\n - \u201cour main color axis emerge (black-white, blue-yellow, orange-cyan and cyan- magenta). Curiously, these two observations correlate with evidences in the human visual system (Shapley & Hawken (2011)).\u201d Great observation!\n\nOverall, I\u2019d recommend the paper be accepted, because although it\u2019s difficult to predict at this time, there\u2019s a fair chance that one of the \u201csmaller conclusions\u201d would turn out to be important in hindsight a few years hence.\n\n\nOther small comments:\n - The cite for \u201cLearning to generate chairs\u2026\u201d is wrong (first two authors combined resulting in a confusing cite)\n\n - What exactly is the Color Selectivity Index computing? The Opponent Color Space isn\u2019t well defined and it wasn\u2019t previously familiar to me. Intuitively it seems to be selecting for units that respond to a constant color, but the highest color selectivity NF in Fig 5 i for a unit with two colors, not one. Finally, the very last unit (lowest color selectivity) is almost the same edge pattern, but with white -> black instead of blue -> orange. Why are these considered to be so drastically different? This should probably be more clearly described.\n\n - For the sake of argument, imagine a mushroom sensitive neuron in conv5 that fires highly for mushrooms of *any* color but not for anything else. If the dataset contains only red-capped mushrooms, would the color selectivity index for this neuron be high or low? If it is high, it\u2019s somewhat misleading because the unit itself actually isn\u2019t color selective; the dataset just happens only to have red mushrooms in it. (It\u2019s a subtle point but worth considering and probably discussing in the paper)"}, {"DATE": "06 Feb 2017", "TITLE": "ICLR committee final decision", "IS_META_REVIEW": false, "comments": "While this is interesting work, one major concern comes from Reviewer 2 regarding the attempt of characterizing the tuning properties, which has proven useless both in neuroscience and in machine learning. Currently, no attempt so far has lived up to the promises this line of research is aiming for. In summary, this work is explorative and incremental but worthwhile. We encourage the authors to further refine their research effort and resubmit.", "OTHER_KEYS": "ICLR 2017 pcs"}, {"DATE": "03 Feb 2017", "TITLE": "Some connections/cites", "IS_META_REVIEW": false, "comments": "Hi authors,\n\nCongrats for an interesting submission! I wonder what other selectivity indices you could use beside color and class.\n\nI just noticed that your definition of Neuron Feature (weighted average image) is very close to what we use in this paper (an average image):\n\n", "OTHER_KEYS": "Anh Nguyen"}, {"TITLE": "Solid work leading to a few interesting conclusions", "OTHER_KEYS": "ICLR 2017 conference AnonReviewer3", "comments": "This paper makes three main methodological contributions:\n - definition of Neural Feature (NF) as the pixel average of the top N images that highly activation a neuron\n - ranking of neurons based on color selectivity\n - ranking of neurons based on class selectivity\n\nThe main weaknesses of the paper are that none of the methodological contributions are very significant, and no singularly significant result arises from the application of the methods.\n\nHowever, the main strengths of the paper are its assortment of moderately-sized interesting conclusions about the basic behavior of neural nets. For example, a few are:\n - \u201cIndexing on class selectivity neurons we found highly class selective neurons like digital-clock at conv2, cardoon at conv3 and ladybug at conv5, much before the fully connected layers.\u201d As far as I know, this had not been previously reported.\n - Color selective neurons are found even in higher layers. (25% color selectivity in conv5)\n - \u201cour main color axis emerge (black-white, blue-yellow, orange-cyan and cyan- magenta). Curiously, these two observations correlate with evidences in the human visual system (Shapley & Hawken (2011)).\u201d Great observation!\n\nOverall, I\u2019d recommend the paper be accepted, because although it\u2019s difficult to predict at this time, there\u2019s a fair chance that one of the \u201csmaller conclusions\u201d would turn out to be important in hindsight a few years hence.\n\n\nOther small comments:\n - The cite for \u201cLearning to generate chairs\u2026\u201d is wrong (first two authors combined resulting in a confusing cite)\n\n - What exactly is the Color Selectivity Index computing? The Opponent Color Space isn\u2019t well defined and it wasn\u2019t previously familiar to me. Intuitively it seems to be selecting for units that respond to a constant color, but the highest color selectivity NF in Fig 5 i for a unit with two colors, not one. Finally, the very last unit (lowest color selectivity) is almost the same edge pattern, but with white -> black instead of blue -> orange. Why are these considered to be so drastically different? This should probably be more clearly described.\n\n - For the sake of argument, imagine a mushroom sensitive neuron in conv5 that fires highly for mushrooms of *any* color but not for anything else. If the dataset contains only red-capped mushrooms, would the color selectivity index for this neuron be high or low? If it is high, it\u2019s somewhat misleading because the unit itself actually isn\u2019t color selective; the dataset just happens only to have red mushrooms in it. (It\u2019s a subtle point but worth considering and probably discussing in the paper)\n", "IS_META_REVIEW": false, "RECOMMENDATION": 7, "DATE": "27 Dec 2016", "REVIEWER_CONFIDENCE": 4}, {"TITLE": "review of \"UNDERSTANDING TRAINED CNNS BY INDEXING NEURON SELECTIVITY\"", "OTHER_KEYS": "ICLR 2017 conference AnonReviewer2", "comments": "The authors analyze trained neural networks by quantifying the selectivity of individual neurons in the network for a variety of specific features, including color and category.   \n\nPros:\n   * The paper is clearly written and has good figures. \n   * I think they executed their specific stated goal reasonably well technically.   E.g. the various indexes they use seem well-chosen for their purposes. \n\nCons:\n   * I must admit that I am biased against the whole enterprise of this paper.   I do not think it is well-motivated or provides any useful insight whatever.   What I view their having done is produced, and then summarized anecdotally, a catalog of piecemeal facts about a neural network without any larger reason to think these particular facts are important.  In a way, I feel like this paper suffers from the same problem that plagues a typical line of research in neurophysiology, in which a catalog of selectivity distributions of various neurons for various properties is produced -- full stop.  As if that were in and of itself important or useful information.   I do not feel that either the original neural version of that project, or this current model-based virtual electrophysiology, is that useful.   Why should we care about the distribution of color selectivities?   Why does knowing distribution as such constitute \"understanding\"?    To my mind it doesn't, at least not directly.   \n\nHere's what they could have done to make a more useful investigation:\n  \n     (a) From a neuroscience point of view, they could have compared the properties that they measure in models to the same properties as measured in neurons the real brain.   If they could show that some models are better matches on these properties to the actual neural data than others, that would be a really interesting result.   That is is to say, the two isolated catalogs of selectivities (from model neurons and real neurons)  alone seem pretty pointless.  But if the correspondence between the two catalogs was made -- both in terms of where the model neurons and the real neurons were similar, and (especially importantly) where they were different --- that would be the beginning of nontrivial understanding.   Such results would also complement a growing body of literature that attempts to link CNNs to visual brain areas.  Finding good neural data is challenging, but whatever the result, the comparison would be interesting. \n\nand/or \n\n    (b) From an artificial intelligence point of view, they could have shown that their metrics are *prescriptive* constraints.   That is, suppose they had shown that the specific color and class selectivity indices that they compute, when imposed as a loss-function criterion on an untrained neural network, cause the network to develop useful filters and achieve significantly above-chance performance on the original task the networks were trained on.     This would be a really great result, because it would not only give us a priori reason to care about the specific property metrics they chose, but it would also help contribute to efforts to find unsupervised (or semi-supervised) learning procedures, since the metrics they compute can be estimated from comparatively small numbers of stimuli and/or high-level semantic labels.    To put this in perspective, imagine that they had actually tested the above hypothesis and found it to be false:  that is, that their metrics, when used as loss function constraints, do not improve performance noticeably above chance performance.  What would we then make of this whole investigation?  It would then be reasonable to think that the measured properties were essentially epiphenomenal and didn't contribute at all to the power of neural networks in solving perceptual tasks.  (The same could be said about neurophysiology experiments doing the same thing.)  \n     [--> NB: I've actually tried things just like this myself over the years, and have found exactly this disappointing result.  Specifically,  I've found a number of high-level generic statistical property of DNNs that seem like they might potentially \"interesting\", e.g. because they apparently correlate with complexity or appear to illustrate difference between low, intermediate and high layers of DNNs.  Every single one of these, when imposed as optimization constraints, has basically lead nowhere on the challenging tasks (like ImageNet) that cause the DNNs to be interesting in the first place.  Basically, there is to my mind no evidence at this point that highly-summarized generic statistical distributions of selectivities, like those illustrated here, place any interesting constraints on filter weights at all.   Of course, I haven't tried the specific properties the authors highlight in these papers, so maybe there's something important there.]\n\nI know that both of these asks are pretty hard, but I just don't know what else to say -- this work otherwise seems like a step backwards for what the community ought to be spending its time on. \n ", "IS_META_REVIEW": false, "RECOMMENDATION": 3, "DATE": "20 Dec 2016", "REVIEWER_CONFIDENCE": 5}, {"TITLE": "Review of \"indexing neuron selectivity\"", "OTHER_KEYS": "ICLR 2017 conference AnonReviewer1", "comments": "This paper attempts to understand and visualize what deep nets are representing as one ascends from low levels to high levels of the network.  As has been shown previously, lower levels are more local image feature based, whereas higher levels correspond to abstract properties such as object identity.  In semantic space, we find higher level nodes to be more semantically selective, whereas low level nodes are more diffuse.\n\nThis seems like a good attempt to tease apart deep net representations.  Perhaps the most important finding is that color figures prominently into all levels of the network, and that performance on gray scale images is significantly diminished.  The new NF measure proposed here is sensible, but still based on the images shown to the network.  What one really wants to know is what function these nodes are computing - i.e., out of the space of *all* possible images, which most activate a unit?  Of course this is a difficult problem, but it would be nice to see us getting closer to understanding the answer.  The color analysis here I think brings us a bit closer.  The semantic analysis is nice but I'm not sure what new insight we gain from this.  \n", "IS_META_REVIEW": false, "RECOMMENDATION": 7, "DATE": "17 Dec 2016", "REVIEWER_CONFIDENCE": 3}, {"DATE": "16 Dec 2016", "TITLE": "Updated version", "IS_META_REVIEW": false, "comments": "We have updated the pdf of the paper after the reviewer comments, in this way:\n  - Giving more details about similarities and differences between the proposed approach and previous.\n  - Adding the clarifications required by the reviewers on Figure1\n  - Improving the global understanding by joining section 1 and 2 into a single one. ", "OTHER_KEYS": "Ivet Rafegas Fonoll"}, {"DATE": "15 Dec 2016", "TITLE": "Details of NF", "IS_META_REVIEW": false, "comments": "", "OTHER_KEYS": "ICLR 2017 conference AnonReviewer3"}, {"DATE": "11 Dec 2016", "TITLE": "Clarification of neural feature", "IS_META_REVIEW": false, "comments": "", "OTHER_KEYS": "ICLR 2017 conference AnonReviewer1"}], "authors": "Ivet Rafegas, Maria Vanrell, Lu\u00eds A. Alexandre", "accepted": false, "id": "717"}