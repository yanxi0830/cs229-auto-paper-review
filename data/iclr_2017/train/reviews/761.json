{"conference": "ICLR 2017 conference submission", "title": "Learning a Static Analyzer: A Case Study on a Toy Language", "abstract": "Static analyzers are meta-programs that analyze programs to detect   potential errors or collect information. For example, they are used   as security tools to detect potential buffer overflows. Also, they   are used by compilers to verify that a program is well-formed and   collect information to generate better code. In this paper, we   address the following question: can a static analyzer be learned   from data? More specifically, can we use deep learning to learn a   static analyzer without the need for complicated feature   engineering? We show that long short-term memory networks are able   to learn a basic static analyzer for a simple toy language. However,   pre-existing approaches based on feature engineering, hidden Markov   models, or basic recurrent neural networks fail on such a simple   problem. Finally, we show how to make such a tool usable by   employing a language model to help the programmer detect where the   reported errors are located.", "histories": [], "reviews": [{"IS_META_REVIEW": true, "comments": "The authors explore the idea of deep-learning a static analyzer. They do it with a toy programming language and a very simplified analysis problem -- just checking if all variables are initalized.\n\nWhile the idea is interesting and might be developped into a tool in the future, the toy task presented in this paper is too simple to warrant an ICLR submission. Just detecting whether a variable is initialized in a string is a toy algorihtmic task, similar to the ones solved in a number of paper in recent years by models such as the Neural Turing Machine, Stack RNNs, Neural GPU, or Differentiable Neural Computer. All these architectures perform almost perfectly on a number of algorithmic tasks, so it is highly probable that they would also solve this one. Unluckily, the authors only compare to much more basic models, such as HMMs. Since the code for many of the above-mentioned models is available online, a paper without these baselines is not ready for ICLR. Moreover, there is a risk that existing models already solve this problem very well, making the contribution unclear."}, {"DATE": "06 Feb 2017", "TITLE": "ICLR committee final decision", "IS_META_REVIEW": false, "comments": "There is a general consensus that, though the idea is interesting, the work is not mature enough for a conference publication (e.g., the problem is too toy, not clear that really solves any, even artificial problem, better than existing techniques).", "OTHER_KEYS": "ICLR 2017 pcs"}, {"TITLE": "Interesting start, but I think not quite ready for publication", "OTHER_KEYS": "ICLR 2017 conference AnonReviewer1", "comments": "This paper takes a first step towards learning to statically analyze source code. It develops a simple toy programming language that includes loops and branching. The aim is to determine whether all variables in the program are defined before they are used. The paper tries a variety of off-the-shelf sequence classification models and develops a new model that makes use of a ``differentiable set'' to keep track of which variables have been defined so far. Result show that an LSTM model can achieve 98% accuracy, and the differentiable set model can achieve 99.3% accuracy with sequence-level supervision and 99.7% accuracy with strong token-level supervision. An additional result is used whereby an LSTM language model is trained over correct code, and then low probability (where a threshold to determine low is tuned by hand) tokens are highlighted as sources of possible error.\n\nOne further question is if the authors could clarify what reasoning patterns are needed to solve these problems. Does the model need to, e.g., statically determine whether an `if` condition can ever evaluate to true in order to solve these tasks? Or is it just as simple as checking whether a variable appears on a LHS before it appears on a RHS later in the textual representation of the program?\n\nStrengths:\n- Learning a static analyzer is an interesting concept, and I think there is good potential for this line of work\n- The ability to determine whether variables are defined before they are used is certainly a prerequisite for more complicated static analysis.\n- The experimental setup seems reasonable\n- The differentiable set seems like a useful (albeit simple) modelling tool\n\nWeaknesses:\n- The setup is very toy, and it's not clear to me that this makes much progress towards the challenges that would arise if one were trying to learn a static analyzer \n- The models are mostly very simple. The one novelty on the modelling front (the differentiable set) provides a small win on this task, but it's not clear if it is a useful general construct or not.\n\nOverall:\nI think it's an interesting start, and I'm eager to see how this line of work progresses. In my opinion, it's a bit too early to accept this work to ICLR, but I'd be excited about seeing what happens as the authors try to push the system to learn to analyze more properties of code, and as they push towards scenarios where the learned static analyzer would be useful, perhaps leveraging strengths of machine learning that are not available to standard programming languages analyses.", "IS_META_REVIEW": false, "RECOMMENDATION": 4, "DATE": "16 Dec 2016 (modified: 19 Dec 2016)", "REVIEWER_CONFIDENCE": 4}, {"TITLE": "Too toy: doesn't effectively prove a point", "OTHER_KEYS": "ICLR 2017 conference AnonReviewer3", "comments": "The authors are trying to understand whether static analysis can be learned. As I hinted in my question, I think that all of the interesting complexity of static analysis has been removed in the toy language --- extraordinarily simple logic using a set can solve the problem posed, and an LSTM (unsurprisingly) can learn the extraordinarily simple logic (when given a differentiable set object). This extreme simplicity gives me no confidence that a more realistic static analysis problem can be solved.\n\nLSTMs (and deep learning) have had remarkable successes in solving messy real-world language problems. It's certainly possible that LSTMs could solve static analysis -- but being technically timid is not the right way to go about it.", "IS_META_REVIEW": false, "RECOMMENDATION": 3, "DATE": "14 Dec 2016", "REVIEWER_CONFIDENCE": 4}, {"DATE": "14 Dec 2016", "TITLE": "No questions, just making this message go away.", "IS_META_REVIEW": false, "comments": "", "OTHER_KEYS": "ICLR 2017 conference AnonReviewer2"}, {"TITLE": "Fine idea but small-scale and lacks crucial baselines", "OTHER_KEYS": "ICLR 2017 conference AnonReviewer2", "comments": "The authors explore the idea of deep-learning a static analyzer. They do it with a toy programming language and a very simplified analysis problem -- just checking if all variables are initalized.\n\nWhile the idea is interesting and might be developped into a tool in the future, the toy task presented in this paper is too simple to warrant an ICLR submission. Just detecting whether a variable is initialized in a string is a toy algorihtmic task, similar to the ones solved in a number of paper in recent years by models such as the Neural Turing Machine, Stack RNNs, Neural GPU, or Differentiable Neural Computer. All these architectures perform almost perfectly on a number of algorithmic tasks, so it is highly probable that they would also solve this one. Unluckily, the authors only compare to much more basic models, such as HMMs. Since the code for many of the above-mentioned models is available online, a paper without these baselines is not ready for ICLR. Moreover, there is a risk that existing models already solve this problem very well, making the contribution unclear.", "IS_META_REVIEW": false, "RECOMMENDATION": 3, "DATE": "14 Dec 2016", "REVIEWER_CONFIDENCE": 5}, {"DATE": "07 Dec 2016", "TITLE": "Unclear motivation + Related work", "IS_META_REVIEW": false, "comments": "-- The motivation behind the work is somewhat unclear: by now, it is very well understood how to design analyzers and what sound/optimal means. Creating a ``black box'' analyzer that can make basic predictions (that are sometimes incorrect) without being able to modify it would be useful if the predictions were challenging and need not be sound all the time (like in some of the cited papers). Note that when analyzers are not sound there are typically clear  reasons for why this is so, e.g., dealing with native methods, frameworks, dynamic evaluation, etc. They are not unsound for 'random reasons'. \n\n-- There is also related work, already pointed out: the one of Hindle and others which already addresses what is in section 4.\n\n-- Here is also recent related work on learning (the transformers of the) static analyzers from data, one that is more elaborate as it learns the transformers of real analyzers and even finds real-world issues in Facebook's Flow: ", "OTHER_KEYS": "(anonymous)"}, {"DATE": "03 Dec 2016", "TITLE": "Isn't using a differentiable set \"cheating\" in some sense?", "IS_META_REVIEW": false, "comments": "", "OTHER_KEYS": "ICLR 2017 conference AnonReviewer3"}, {"DATE": "28 Nov 2016", "TITLE": "Evaluating strong generalization?", "IS_META_REVIEW": false, "comments": "", "OTHER_KEYS": "ICLR 2017 conference AnonReviewer1"}, {"IS_META_REVIEW": true, "comments": "The authors explore the idea of deep-learning a static analyzer. They do it with a toy programming language and a very simplified analysis problem -- just checking if all variables are initalized.\n\nWhile the idea is interesting and might be developped into a tool in the future, the toy task presented in this paper is too simple to warrant an ICLR submission. Just detecting whether a variable is initialized in a string is a toy algorihtmic task, similar to the ones solved in a number of paper in recent years by models such as the Neural Turing Machine, Stack RNNs, Neural GPU, or Differentiable Neural Computer. All these architectures perform almost perfectly on a number of algorithmic tasks, so it is highly probable that they would also solve this one. Unluckily, the authors only compare to much more basic models, such as HMMs. Since the code for many of the above-mentioned models is available online, a paper without these baselines is not ready for ICLR. Moreover, there is a risk that existing models already solve this problem very well, making the contribution unclear."}, {"DATE": "06 Feb 2017", "TITLE": "ICLR committee final decision", "IS_META_REVIEW": false, "comments": "There is a general consensus that, though the idea is interesting, the work is not mature enough for a conference publication (e.g., the problem is too toy, not clear that really solves any, even artificial problem, better than existing techniques).", "OTHER_KEYS": "ICLR 2017 pcs"}, {"TITLE": "Interesting start, but I think not quite ready for publication", "OTHER_KEYS": "ICLR 2017 conference AnonReviewer1", "comments": "This paper takes a first step towards learning to statically analyze source code. It develops a simple toy programming language that includes loops and branching. The aim is to determine whether all variables in the program are defined before they are used. The paper tries a variety of off-the-shelf sequence classification models and develops a new model that makes use of a ``differentiable set'' to keep track of which variables have been defined so far. Result show that an LSTM model can achieve 98% accuracy, and the differentiable set model can achieve 99.3% accuracy with sequence-level supervision and 99.7% accuracy with strong token-level supervision. An additional result is used whereby an LSTM language model is trained over correct code, and then low probability (where a threshold to determine low is tuned by hand) tokens are highlighted as sources of possible error.\n\nOne further question is if the authors could clarify what reasoning patterns are needed to solve these problems. Does the model need to, e.g., statically determine whether an `if` condition can ever evaluate to true in order to solve these tasks? Or is it just as simple as checking whether a variable appears on a LHS before it appears on a RHS later in the textual representation of the program?\n\nStrengths:\n- Learning a static analyzer is an interesting concept, and I think there is good potential for this line of work\n- The ability to determine whether variables are defined before they are used is certainly a prerequisite for more complicated static analysis.\n- The experimental setup seems reasonable\n- The differentiable set seems like a useful (albeit simple) modelling tool\n\nWeaknesses:\n- The setup is very toy, and it's not clear to me that this makes much progress towards the challenges that would arise if one were trying to learn a static analyzer \n- The models are mostly very simple. The one novelty on the modelling front (the differentiable set) provides a small win on this task, but it's not clear if it is a useful general construct or not.\n\nOverall:\nI think it's an interesting start, and I'm eager to see how this line of work progresses. In my opinion, it's a bit too early to accept this work to ICLR, but I'd be excited about seeing what happens as the authors try to push the system to learn to analyze more properties of code, and as they push towards scenarios where the learned static analyzer would be useful, perhaps leveraging strengths of machine learning that are not available to standard programming languages analyses.", "IS_META_REVIEW": false, "RECOMMENDATION": 4, "DATE": "16 Dec 2016 (modified: 19 Dec 2016)", "REVIEWER_CONFIDENCE": 4}, {"TITLE": "Too toy: doesn't effectively prove a point", "OTHER_KEYS": "ICLR 2017 conference AnonReviewer3", "comments": "The authors are trying to understand whether static analysis can be learned. As I hinted in my question, I think that all of the interesting complexity of static analysis has been removed in the toy language --- extraordinarily simple logic using a set can solve the problem posed, and an LSTM (unsurprisingly) can learn the extraordinarily simple logic (when given a differentiable set object). This extreme simplicity gives me no confidence that a more realistic static analysis problem can be solved.\n\nLSTMs (and deep learning) have had remarkable successes in solving messy real-world language problems. It's certainly possible that LSTMs could solve static analysis -- but being technically timid is not the right way to go about it.", "IS_META_REVIEW": false, "RECOMMENDATION": 3, "DATE": "14 Dec 2016", "REVIEWER_CONFIDENCE": 4}, {"DATE": "14 Dec 2016", "TITLE": "No questions, just making this message go away.", "IS_META_REVIEW": false, "comments": "", "OTHER_KEYS": "ICLR 2017 conference AnonReviewer2"}, {"TITLE": "Fine idea but small-scale and lacks crucial baselines", "OTHER_KEYS": "ICLR 2017 conference AnonReviewer2", "comments": "The authors explore the idea of deep-learning a static analyzer. They do it with a toy programming language and a very simplified analysis problem -- just checking if all variables are initalized.\n\nWhile the idea is interesting and might be developped into a tool in the future, the toy task presented in this paper is too simple to warrant an ICLR submission. Just detecting whether a variable is initialized in a string is a toy algorihtmic task, similar to the ones solved in a number of paper in recent years by models such as the Neural Turing Machine, Stack RNNs, Neural GPU, or Differentiable Neural Computer. All these architectures perform almost perfectly on a number of algorithmic tasks, so it is highly probable that they would also solve this one. Unluckily, the authors only compare to much more basic models, such as HMMs. Since the code for many of the above-mentioned models is available online, a paper without these baselines is not ready for ICLR. Moreover, there is a risk that existing models already solve this problem very well, making the contribution unclear.", "IS_META_REVIEW": false, "RECOMMENDATION": 3, "DATE": "14 Dec 2016", "REVIEWER_CONFIDENCE": 5}, {"DATE": "07 Dec 2016", "TITLE": "Unclear motivation + Related work", "IS_META_REVIEW": false, "comments": "-- The motivation behind the work is somewhat unclear: by now, it is very well understood how to design analyzers and what sound/optimal means. Creating a ``black box'' analyzer that can make basic predictions (that are sometimes incorrect) without being able to modify it would be useful if the predictions were challenging and need not be sound all the time (like in some of the cited papers). Note that when analyzers are not sound there are typically clear  reasons for why this is so, e.g., dealing with native methods, frameworks, dynamic evaluation, etc. They are not unsound for 'random reasons'. \n\n-- There is also related work, already pointed out: the one of Hindle and others which already addresses what is in section 4.\n\n-- Here is also recent related work on learning (the transformers of the) static analyzers from data, one that is more elaborate as it learns the transformers of real analyzers and even finds real-world issues in Facebook's Flow: ", "OTHER_KEYS": "(anonymous)"}, {"DATE": "03 Dec 2016", "TITLE": "Isn't using a differentiable set \"cheating\" in some sense?", "IS_META_REVIEW": false, "comments": "", "OTHER_KEYS": "ICLR 2017 conference AnonReviewer3"}, {"DATE": "28 Nov 2016", "TITLE": "Evaluating strong generalization?", "IS_META_REVIEW": false, "comments": "", "OTHER_KEYS": "ICLR 2017 conference AnonReviewer1"}], "authors": "Manzil Zaheer, Jean-Baptiste Tristan, Michael L. Wick, Guy L. Steele Jr.", "accepted": false, "id": "761"}