{"conference": "ICLR 2017 conference submission", "title": "Multi-label learning with semantic embeddings", "abstract": "Multi-label learning aims to automatically assign to an instance (e.g., an image or a document) the most relevant subset of labels from a large set of possible labels. The main challenge is to maintain accurate predictions while scaling efficiently on data sets with extremely large label sets and many training data points. We propose a simple but effective neural net approach, the Semantic Embedding Model (SEM), that models the labels for an instance as draws from a multinomial distribution parametrized by nonlinear functions of the instance features. A Gauss-Siedel mini-batch adaptive gradient descent algorithm is used to fit the model. To handle extremely large label sets, we propose and experimentally validate the efficacy of fitting randomly chosen marginal label distributions. Experimental results on eight real-world data sets show that SEM garners significant performance gains over existing methods. In particular, we compare SEM to four recent state-of-the-art algorithms (NNML, BMLPL, REmbed, and SLEEC) and find that SEM uniformly outperforms these algorithms in several widely used evaluation metrics while requiring significantly less training time.", "histories": [], "reviews": [{"IS_META_REVIEW": true, "comments": "This paper proposes SEM, a simple large-size multilabel learning algorithm which models the probability of each label as softmax(sigmoid(W^T X) + b), so a one-layer hidden network. This in and of itself is not novel, nor is the idea of optimizing this by adagrad. Though it's weird that the paper explicitly derives the gradient and suggests doing alternating adagrad steps instead of the more standard adagrad steps; it's unclear whether this matters at all for performance. The main trick responsible for increasing the efficiency of this model is the candidate label sampling, which is done in a relatively standard way by sampling labels proportionally to their frequency in the dataset.\n\nGiven that neither the model nor the training strategy is novel, it's surprising that the results are better than the state-of-the-art in quality and efficiency (though non-asymptotic efficiency claims are always questionable since implementation effort trades off fairly well against performance). I feel like this paper doesn't quite meet the bar."}, {"DATE": "06 Feb 2017", "TITLE": "ICLR committee final decision", "IS_META_REVIEW": false, "comments": "This is largely a well written paper proposing a sensible approach for multilabel learning that is shown to be effective in practice. However, the main technical elements of this work: the model used and its connections to basic MLPs and related methods in the literature, the optimization strategy, and the speedup tricks are all familiar from prior work. Hence the reviewers are somewhat unanimous in their view that the novelty aspect of this paper is its main shortcomings. The authors are encouraged to revise the paper and clarify the precise contributions.", "OTHER_KEYS": "ICLR 2017 pcs"}, {"TITLE": "not very convinced", "OTHER_KEYS": "ICLR 2017 conference AnonReviewer3", "comments": "The paper proposes a semantic embedding based approach to multilabel classification. \nConversely to previous proposals, SEM considers the underlying parameters determining the\nobserved labels are low-rank rather than that the observed label matrix is itself low-rank. \nHowever, It is not clear to what extent the difference between the two assumptions is significant\n\nSEM models the labels for an instance as draws from a multinomial distribution\nparametrized by nonlinear functions of the instance features. As such, it is a neural network.\nThe proposed training algorithm is slightly more complicated than vanilla backprop.  The significance of the results compared to NNML (in particular on large datasets Delicious and EUrlex) is not very clear. \n\nThe paper is well written and the main idea is clearly presented. However, the experimental results are not significant enough to compensate the lack of conceptual novelty. \n\n\n", "IS_META_REVIEW": false, "RECOMMENDATION": 4, "DATE": "20 Dec 2016", "REVIEWER_CONFIDENCE": 4}, {"TITLE": "review", "OTHER_KEYS": "ICLR 2017 conference AnonReviewer2", "comments": "The paper presents the semantic embedding model for multi-label prediction.\nIn my questions, I pointed that the proposed approach assumes the number of labels to predict is known, and the authors said this was an orthogonal question, although I don't think it is!\nI was trying to understand how different is SEM from a basic MLP with softmax output which would be trained with a two step approach instead of stochastic gradient descent. It seems reasonable given their similarity to compare to this very basic baseline.\nRegarding the sampling strategy to estimate the posterior distribution, and the difference with Jean et al, I agree it is slightly different but I think you should definitely refer to it and point to the differences.\nOne last question: why is it called \"semantic\" embeddings? usually this term is used to show some semantic meaning between trained embeddings, but this doesn't seem to appear in this paper.\n", "IS_META_REVIEW": false, "RECOMMENDATION": 4, "DATE": "15 Dec 2016", "REVIEWER_CONFIDENCE": 4}, {"TITLE": "Weak reject", "OTHER_KEYS": "ICLR 2017 conference AnonReviewer1", "comments": "This paper proposes SEM, a simple large-size multilabel learning algorithm which models the probability of each label as softmax(sigmoid(W^T X) + b), so a one-layer hidden network. This in and of itself is not novel, nor is the idea of optimizing this by adagrad. Though it's weird that the paper explicitly derives the gradient and suggests doing alternating adagrad steps instead of the more standard adagrad steps; it's unclear whether this matters at all for performance. The main trick responsible for increasing the efficiency of this model is the candidate label sampling, which is done in a relatively standard way by sampling labels proportionally to their frequency in the dataset.\n\nGiven that neither the model nor the training strategy is novel, it's surprising that the results are better than the state-of-the-art in quality and efficiency (though non-asymptotic efficiency claims are always questionable since implementation effort trades off fairly well against performance). I feel like this paper doesn't quite meet the bar.", "IS_META_REVIEW": false, "RECOMMENDATION": 5, "DATE": "15 Dec 2016", "REVIEWER_CONFIDENCE": 4}, {"DATE": "03 Dec 2016", "TITLE": "prior work and experiments.", "IS_META_REVIEW": false, "comments": "", "OTHER_KEYS": "ICLR 2017 conference AnonReviewer3"}, {"DATE": "02 Dec 2016", "TITLE": "Questions", "IS_META_REVIEW": false, "comments": "", "OTHER_KEYS": "ICLR 2017 conference AnonReviewer1"}, {"DATE": "30 Nov 2016", "TITLE": "Questions", "IS_META_REVIEW": false, "comments": "", "OTHER_KEYS": "ICLR 2017 conference AnonReviewer2"}, {"IS_META_REVIEW": true, "comments": "This paper proposes SEM, a simple large-size multilabel learning algorithm which models the probability of each label as softmax(sigmoid(W^T X) + b), so a one-layer hidden network. This in and of itself is not novel, nor is the idea of optimizing this by adagrad. Though it's weird that the paper explicitly derives the gradient and suggests doing alternating adagrad steps instead of the more standard adagrad steps; it's unclear whether this matters at all for performance. The main trick responsible for increasing the efficiency of this model is the candidate label sampling, which is done in a relatively standard way by sampling labels proportionally to their frequency in the dataset.\n\nGiven that neither the model nor the training strategy is novel, it's surprising that the results are better than the state-of-the-art in quality and efficiency (though non-asymptotic efficiency claims are always questionable since implementation effort trades off fairly well against performance). I feel like this paper doesn't quite meet the bar."}, {"DATE": "06 Feb 2017", "TITLE": "ICLR committee final decision", "IS_META_REVIEW": false, "comments": "This is largely a well written paper proposing a sensible approach for multilabel learning that is shown to be effective in practice. However, the main technical elements of this work: the model used and its connections to basic MLPs and related methods in the literature, the optimization strategy, and the speedup tricks are all familiar from prior work. Hence the reviewers are somewhat unanimous in their view that the novelty aspect of this paper is its main shortcomings. The authors are encouraged to revise the paper and clarify the precise contributions.", "OTHER_KEYS": "ICLR 2017 pcs"}, {"TITLE": "not very convinced", "OTHER_KEYS": "ICLR 2017 conference AnonReviewer3", "comments": "The paper proposes a semantic embedding based approach to multilabel classification. \nConversely to previous proposals, SEM considers the underlying parameters determining the\nobserved labels are low-rank rather than that the observed label matrix is itself low-rank. \nHowever, It is not clear to what extent the difference between the two assumptions is significant\n\nSEM models the labels for an instance as draws from a multinomial distribution\nparametrized by nonlinear functions of the instance features. As such, it is a neural network.\nThe proposed training algorithm is slightly more complicated than vanilla backprop.  The significance of the results compared to NNML (in particular on large datasets Delicious and EUrlex) is not very clear. \n\nThe paper is well written and the main idea is clearly presented. However, the experimental results are not significant enough to compensate the lack of conceptual novelty. \n\n\n", "IS_META_REVIEW": false, "RECOMMENDATION": 4, "DATE": "20 Dec 2016", "REVIEWER_CONFIDENCE": 4}, {"TITLE": "review", "OTHER_KEYS": "ICLR 2017 conference AnonReviewer2", "comments": "The paper presents the semantic embedding model for multi-label prediction.\nIn my questions, I pointed that the proposed approach assumes the number of labels to predict is known, and the authors said this was an orthogonal question, although I don't think it is!\nI was trying to understand how different is SEM from a basic MLP with softmax output which would be trained with a two step approach instead of stochastic gradient descent. It seems reasonable given their similarity to compare to this very basic baseline.\nRegarding the sampling strategy to estimate the posterior distribution, and the difference with Jean et al, I agree it is slightly different but I think you should definitely refer to it and point to the differences.\nOne last question: why is it called \"semantic\" embeddings? usually this term is used to show some semantic meaning between trained embeddings, but this doesn't seem to appear in this paper.\n", "IS_META_REVIEW": false, "RECOMMENDATION": 4, "DATE": "15 Dec 2016", "REVIEWER_CONFIDENCE": 4}, {"TITLE": "Weak reject", "OTHER_KEYS": "ICLR 2017 conference AnonReviewer1", "comments": "This paper proposes SEM, a simple large-size multilabel learning algorithm which models the probability of each label as softmax(sigmoid(W^T X) + b), so a one-layer hidden network. This in and of itself is not novel, nor is the idea of optimizing this by adagrad. Though it's weird that the paper explicitly derives the gradient and suggests doing alternating adagrad steps instead of the more standard adagrad steps; it's unclear whether this matters at all for performance. The main trick responsible for increasing the efficiency of this model is the candidate label sampling, which is done in a relatively standard way by sampling labels proportionally to their frequency in the dataset.\n\nGiven that neither the model nor the training strategy is novel, it's surprising that the results are better than the state-of-the-art in quality and efficiency (though non-asymptotic efficiency claims are always questionable since implementation effort trades off fairly well against performance). I feel like this paper doesn't quite meet the bar.", "IS_META_REVIEW": false, "RECOMMENDATION": 5, "DATE": "15 Dec 2016", "REVIEWER_CONFIDENCE": 4}, {"DATE": "03 Dec 2016", "TITLE": "prior work and experiments.", "IS_META_REVIEW": false, "comments": "", "OTHER_KEYS": "ICLR 2017 conference AnonReviewer3"}, {"DATE": "02 Dec 2016", "TITLE": "Questions", "IS_META_REVIEW": false, "comments": "", "OTHER_KEYS": "ICLR 2017 conference AnonReviewer1"}, {"DATE": "30 Nov 2016", "TITLE": "Questions", "IS_META_REVIEW": false, "comments": "", "OTHER_KEYS": "ICLR 2017 conference AnonReviewer2"}], "authors": "Liping Jing, MiaoMiao Cheng, Liu Yang, Alex Gittens, Michael W. Mahoney", "accepted": false, "id": "787"}