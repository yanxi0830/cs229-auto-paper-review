{"conference": "ICLR 2017 conference submission", "title": "Beyond Bilingual: Multi-sense Word Embeddings using Multilingual Context", "abstract": "Word embeddings, which represent a word as a point in a vector space, have become ubiquitous to several NLP tasks. A recent line of work uses bilingual (two languages) corpora to learn a different vector for each sense of a word, by exploiting crosslingual signals to aid sense identification. We present a multi-view Bayesian non-parametric algorithm which improves multi-sense word embeddings by (a) using multilingual (i.e., more than two languages) corpora to significantly improve sense embeddings beyond what one achieves with bilingual information, and (b) uses a principled approach to learn a variable number of senses per word, in a data-driven manner. Ours is the first approach with the ability to leverage multilingual corpora efficiently for multi-sense representation learning. Experiments show that multilingual training significantly improves performance over monolingual and bilingual training, by allowing us to combine different parallel corpora to leverage multilingual context. Multilingual training yields com- parable performance to a state of the art monolingual model trained on five times more training data.", "histories": [], "reviews": [{"IS_META_REVIEW": true, "comments": "In this paper, the authors propose a Bayesian variant of the skipgram model to learn word embeddings. There are two important variant compared to the original model. First, aligned sentences from multiple languages are used to train the model. Therefore, the context words of a given target word can be either from the same sentence, or from an aligned sentence in a different language. This allows to learn multilingual embedding. The second difference is that each word is represented by multiple vectors, one for each of its different senses. A latent variable z models which sense should be used, given the context.\n\nOverall, I believe that the idea of using a probabilistic model to capture polysemy is an interesting idea. The model introduced in this paper is a nice generalization of the skipgram model in that direction. However, I found the paper a bit hard to follow. The formulation might probably be simplified (e.g. why not consider a target word w and a context c, where c is either in the source or target language. Since all factors are independent, this should not change the model much, and would make the presentation easier). The performance of all models reported in Table 2 & 3 seem pretty low.\n\nOverall, I like the main idea of the paper, which is to represent word senses by latent variables in a probabilistic model. I feel that the method could be presented more clearly, which would make the paper much stronger. I also have some concerns regarding the experimental results.\n\nPros:\nInteresting extension of skipgram to capture polysemy.\nCons:\nThe paper is not clearly written.\nResults reported in the paper seems pretty low."}, {"DATE": "06 Feb 2017", "TITLE": "ICLR committee final decision", "IS_META_REVIEW": false, "comments": "While the reviewers find the core idea intriguing, the method needs a clearer explanation and a more thorough comparison to related work.", "OTHER_KEYS": "ICLR 2017 pcs"}, {"TITLE": "Interesting idea, execution needs more work", "OTHER_KEYS": "ICLR 2017 conference AnonReviewer2", "comments": "This paper discusses multi-sense embedddings and proposes learning those by using aligned text across languages. Further, the paper suggests that adding more languages helps improve word sense disambiguation (as some ambiguities can be carried across language pairs). While this idea in itself isn't new, the authors propose a particular setup for learning multi-sense embeddings by exploiting multilingual data.\n\nBroadly this is fine, but unfortunately the paper then falls short in a number of ways. For one, the model section is unnecessarily convoluted for what is a nice idea that could be described in a far more concise fashion. Next (and more importantly), comparison with other work is lacking to such an extent that it is impossible to evaluate the merits of the proposed model in an objective fashion. \n\nThis paper could be a lot stronger if the learned embeddings were evaluated in downstream tasks and evaluated against other published methods. In the current version there is too little of this, leaving us with mostly relative results between model variants and t-SNE plots that don't really add anything to the story.", "IS_META_REVIEW": false, "RECOMMENDATION": 4, "DATE": "19 Dec 2016", "REVIEWER_CONFIDENCE": 3}, {"TITLE": "needs better comparison", "OTHER_KEYS": "ICLR 2017 conference AnonReviewer3", "comments": "this work aims to address representation of multi-sense words by exploiting multilingual context. Experiments on word sense induction and word similarity in context show that the proposed solution improves over the baseline.\n\nFrom a computational linguistics perspective, the fact that languages less similar to English help more is intriguing. I see following problem with this work:\n- the paper is hard to follow and hard to see what's new compared to the baseline model [1]. A paragraph of discussion should clearly compare and contrast with that work.\n\n- the proposed model is a slight variation of the previous work [1] thus the experimental setup should be designed in a way so that we compare which part helps improvement and how much. thus MONO has not been exposed the same training data and we can't be sure that the proposed model is better because MONO does not observe the data or lacks the computational power. I suggest following baseline: turning multilingual data to monolingual one using the alignment, then train the baseline model[1] on this pseudo monolingual data.\n\n- the paper provides good benchmarks for intrinsic evaluation but the message could be conveyed more strongly if we see improvement in a downstream task.\n\n[1] ", "IS_META_REVIEW": false, "RECOMMENDATION": 4, "DATE": "17 Dec 2016", "REVIEWER_CONFIDENCE": 4}, {"TITLE": "Review", "OTHER_KEYS": "ICLR 2017 conference AnonReviewer1", "comments": "In this paper, the authors propose a Bayesian variant of the skipgram model to learn word embeddings. There are two important variant compared to the original model. First, aligned sentences from multiple languages are used to train the model. Therefore, the context words of a given target word can be either from the same sentence, or from an aligned sentence in a different language. This allows to learn multilingual embedding. The second difference is that each word is represented by multiple vectors, one for each of its different senses. A latent variable z models which sense should be used, given the context.\n\nOverall, I believe that the idea of using a probabilistic model to capture polysemy is an interesting idea. The model introduced in this paper is a nice generalization of the skipgram model in that direction. However, I found the paper a bit hard to follow. The formulation might probably be simplified (e.g. why not consider a target word w and a context c, where c is either in the source or target language. Since all factors are independent, this should not change the model much, and would make the presentation easier). The performance of all models reported in Table 2 & 3 seem pretty low.\n\nOverall, I like the main idea of the paper, which is to represent word senses by latent variables in a probabilistic model. I feel that the method could be presented more clearly, which would make the paper much stronger. I also have some concerns regarding the experimental results.\n\nPros:\nInteresting extension of skipgram to capture polysemy.\nCons:\nThe paper is not clearly written.\nResults reported in the paper seems pretty low.", "IS_META_REVIEW": false, "RECOMMENDATION": 5, "DATE": "16 Dec 2016", "REVIEWER_CONFIDENCE": 3}, {"DATE": "03 Dec 2016", "TITLE": "Model clarification", "IS_META_REVIEW": false, "comments": "", "OTHER_KEYS": "ICLR 2017 conference AnonReviewer1"}, {"DATE": "02 Dec 2016", "TITLE": "the polysemy & morphology in the foreign language", "IS_META_REVIEW": false, "comments": "", "OTHER_KEYS": "ICLR 2017 conference AnonReviewer3"}, {"IS_META_REVIEW": true, "comments": "In this paper, the authors propose a Bayesian variant of the skipgram model to learn word embeddings. There are two important variant compared to the original model. First, aligned sentences from multiple languages are used to train the model. Therefore, the context words of a given target word can be either from the same sentence, or from an aligned sentence in a different language. This allows to learn multilingual embedding. The second difference is that each word is represented by multiple vectors, one for each of its different senses. A latent variable z models which sense should be used, given the context.\n\nOverall, I believe that the idea of using a probabilistic model to capture polysemy is an interesting idea. The model introduced in this paper is a nice generalization of the skipgram model in that direction. However, I found the paper a bit hard to follow. The formulation might probably be simplified (e.g. why not consider a target word w and a context c, where c is either in the source or target language. Since all factors are independent, this should not change the model much, and would make the presentation easier). The performance of all models reported in Table 2 & 3 seem pretty low.\n\nOverall, I like the main idea of the paper, which is to represent word senses by latent variables in a probabilistic model. I feel that the method could be presented more clearly, which would make the paper much stronger. I also have some concerns regarding the experimental results.\n\nPros:\nInteresting extension of skipgram to capture polysemy.\nCons:\nThe paper is not clearly written.\nResults reported in the paper seems pretty low."}, {"DATE": "06 Feb 2017", "TITLE": "ICLR committee final decision", "IS_META_REVIEW": false, "comments": "While the reviewers find the core idea intriguing, the method needs a clearer explanation and a more thorough comparison to related work.", "OTHER_KEYS": "ICLR 2017 pcs"}, {"TITLE": "Interesting idea, execution needs more work", "OTHER_KEYS": "ICLR 2017 conference AnonReviewer2", "comments": "This paper discusses multi-sense embedddings and proposes learning those by using aligned text across languages. Further, the paper suggests that adding more languages helps improve word sense disambiguation (as some ambiguities can be carried across language pairs). While this idea in itself isn't new, the authors propose a particular setup for learning multi-sense embeddings by exploiting multilingual data.\n\nBroadly this is fine, but unfortunately the paper then falls short in a number of ways. For one, the model section is unnecessarily convoluted for what is a nice idea that could be described in a far more concise fashion. Next (and more importantly), comparison with other work is lacking to such an extent that it is impossible to evaluate the merits of the proposed model in an objective fashion. \n\nThis paper could be a lot stronger if the learned embeddings were evaluated in downstream tasks and evaluated against other published methods. In the current version there is too little of this, leaving us with mostly relative results between model variants and t-SNE plots that don't really add anything to the story.", "IS_META_REVIEW": false, "RECOMMENDATION": 4, "DATE": "19 Dec 2016", "REVIEWER_CONFIDENCE": 3}, {"TITLE": "needs better comparison", "OTHER_KEYS": "ICLR 2017 conference AnonReviewer3", "comments": "this work aims to address representation of multi-sense words by exploiting multilingual context. Experiments on word sense induction and word similarity in context show that the proposed solution improves over the baseline.\n\nFrom a computational linguistics perspective, the fact that languages less similar to English help more is intriguing. I see following problem with this work:\n- the paper is hard to follow and hard to see what's new compared to the baseline model [1]. A paragraph of discussion should clearly compare and contrast with that work.\n\n- the proposed model is a slight variation of the previous work [1] thus the experimental setup should be designed in a way so that we compare which part helps improvement and how much. thus MONO has not been exposed the same training data and we can't be sure that the proposed model is better because MONO does not observe the data or lacks the computational power. I suggest following baseline: turning multilingual data to monolingual one using the alignment, then train the baseline model[1] on this pseudo monolingual data.\n\n- the paper provides good benchmarks for intrinsic evaluation but the message could be conveyed more strongly if we see improvement in a downstream task.\n\n[1] ", "IS_META_REVIEW": false, "RECOMMENDATION": 4, "DATE": "17 Dec 2016", "REVIEWER_CONFIDENCE": 4}, {"TITLE": "Review", "OTHER_KEYS": "ICLR 2017 conference AnonReviewer1", "comments": "In this paper, the authors propose a Bayesian variant of the skipgram model to learn word embeddings. There are two important variant compared to the original model. First, aligned sentences from multiple languages are used to train the model. Therefore, the context words of a given target word can be either from the same sentence, or from an aligned sentence in a different language. This allows to learn multilingual embedding. The second difference is that each word is represented by multiple vectors, one for each of its different senses. A latent variable z models which sense should be used, given the context.\n\nOverall, I believe that the idea of using a probabilistic model to capture polysemy is an interesting idea. The model introduced in this paper is a nice generalization of the skipgram model in that direction. However, I found the paper a bit hard to follow. The formulation might probably be simplified (e.g. why not consider a target word w and a context c, where c is either in the source or target language. Since all factors are independent, this should not change the model much, and would make the presentation easier). The performance of all models reported in Table 2 & 3 seem pretty low.\n\nOverall, I like the main idea of the paper, which is to represent word senses by latent variables in a probabilistic model. I feel that the method could be presented more clearly, which would make the paper much stronger. I also have some concerns regarding the experimental results.\n\nPros:\nInteresting extension of skipgram to capture polysemy.\nCons:\nThe paper is not clearly written.\nResults reported in the paper seems pretty low.", "IS_META_REVIEW": false, "RECOMMENDATION": 5, "DATE": "16 Dec 2016", "REVIEWER_CONFIDENCE": 3}, {"DATE": "03 Dec 2016", "TITLE": "Model clarification", "IS_META_REVIEW": false, "comments": "", "OTHER_KEYS": "ICLR 2017 conference AnonReviewer1"}, {"DATE": "02 Dec 2016", "TITLE": "the polysemy & morphology in the foreign language", "IS_META_REVIEW": false, "comments": "", "OTHER_KEYS": "ICLR 2017 conference AnonReviewer3"}], "authors": "Shyam Upadhyay, Kai-Wei Chang, James Zou, Matt Taddy, Adam Kalai", "accepted": false, "id": "640"}