{"conference": "ICLR 2017 conference submission", "title": "Learning Recurrent Representations for Hierarchical Behavior Modeling", "abstract": "We propose a framework for detecting action patterns from motion sequences and modeling the sensory-motor relationship of animals, using a generative recurrent neural network. The network has a discriminative part (classifying actions) and a generative part (predicting motion), whose recurrent cells are laterally connected, allowing higher levels of the network to represent high level behavioral phenomena. We test our framework on two types of tracking data, fruit fly behavior and online handwriting. Our results show that 1) taking advantage of unlabeled sequences, by predicting future motion, significantly improves action detection performance when training labels are scarce, 2) the network learns to represent high level phenomena such as writer identity and fly gender, without supervision, and 3) simulated motion trajectories, generated by treating motion prediction as input to the network, look realistic and may be used to qualitatively evaluate whether the model has learnt generative control rules.", "histories": [], "reviews": [{"IS_META_REVIEW": true, "comments": "This paper proposes a recurrent architecture for simultaneously predicting motion and action states of agents.\nThe paper is well written, clear in its presentation and backed up by good experiments.\nThey demonstrate that by forcing the network to predict motion has beneficial consequences on the classification of actions states,\nallowing more accurate classification with less training data.\nThey also show how the information learned by the network is interpretable and organised in a hierarchy.\n\nWeaknesses:\n- a critical discussion on the interplay between motion an behaviour that is needed to experience the benefits of their proposed model is missing from the paper.\n- moreover, a discussion on how this approach could scale to more challenging scenarios \"involving animals\" and visual input for instance and more general \"behaviours\" is also missing;\nThe criticism here is pointed at the fact that the title/abstract claim general behaviour modelling, whilst the experiments are focused on two very specific and relatively simple scenarios,\nmaking the original claim a little bit far fetched unless its backed up by additional evidence.\nUsing \"Insects\", or \"fruit flies\" would be more appropriate than \"animals\"."}, {"DATE": "06 Feb 2017", "TITLE": "ICLR committee final decision", "IS_META_REVIEW": false, "comments": "Originality and Significance:\n  The paper develops a recurrently coupled discriminative / generative hierarchical model, as applied to fruit-fly behavior and online handwriting. Qualitative evaluation is provided by generating motions, in addition to quantitative results. Writer identity and fly gender are learned in an unsupervised fashion. While the individual components of the solution are not particularly novel, their combination together with the detailed experimental validation makes the method potentially interesting to a broad audience. Some reviewers have concerns about the broad claims that are implied by the title and abstract, and thus it is recommended that these be refined to be more specific about the method and the applications.\n \n Quality and Clarity:\n  The paper is well written.\n \n Pros:\n - interesting problem and application domains; will be of broad interest\n - useful ideas and architecture: shows that forcing the network to predictions about motion leads to improved classification\n - well written paper backed up by good experiments\n \n Cons:\n - the individual architectural features have for the most part been proposed before", "OTHER_KEYS": "ICLR 2017 pcs"}, {"DATE": "20 Jan 2017", "TITLE": "Response to all reviewers", "IS_META_REVIEW": false, "comments": "Dear reviewers,\n\nThank you all for your feedback and suggestions.\n\n** We have added the following changes to the paper: \n- better explanation of figures 4 and 5 in their captions\n- clearer definition a bout (Section 5.1, first paragraph)\n- analogy between diagonal connections and skip connections added (Section 3.1, first paragraph)\n\n** Regarding scaling to other data\nIn Section 4, paragraph 1, we describe how data should be represented to fit our framework, and we have added a discussion at the end of the paper about scaling to more complex scenarios (Section 6, paragraph 2).\n\n** In response to modeling \u201cbehavior\u201d being too strong of a claim and that it should be replaced with \u201cspatiotemporal behavior\u201d or \u201cfruit fly behavior\u201d:\n1) We qualify our statement in the abstract, stating both that we focus on motion sequences (i.e. trajectories) and that we test it on fruit flies and handwriting, which we further elaborate on in the introduction.\n\n2) I would argue that behavior is spatiotemporal.\nPeople from different fields may think of behavior differently, ranging from generating to observing behavior. A roboticist may think of it in terms of moving joints, an animator in terms of moving vertices, and a computer vision researcher in terms of moving pixels.\n\nAs noted by Levitis et al. (", "OTHER_KEYS": "Eyrun Eyjolfsdottir"}, {"TITLE": "using auxiliary tasks, skip connections and \"internal labels\" to classify spatiotemporal trajectories with an RNN", "OTHER_KEYS": "ICLR 2017 conference AnonReviewer3", "comments": "While my above review title is too verbose, it would be a more accurate title for the paper than the current one (an overall better title would probably be somewhere in between). \n\nThe overall approach is interesting: all three of the key techniques (aux. tasks, skip/diagonal connections, and the use of internal labels for the kind of data available) make a lot of sense.\n\nI found some of the results hard to understand/interpret. Some of the explanation in the discussion below has been helpful (e.g. see my earlier questions about Fig 4 and 5); the paper would benefit from including more such explanations. \n\nIt may be worthwhile very briefly mentioning the relationship of \"diagonal\" connections to other emerging terms for similar ideas (e.g. skip connections, etc). \"Skip\" seems to me to be accurate regardless of how you draw the network, whereas \"diagonal\" only makes sense for certain visual layouts.\n\nIn response to comment in the discussion below: \"leading to less over-segmentation of action bouts\" (and corresponding discussion in section 5.1 of the paper): I would be like to have a bit more about this in the paper. I have assumed that \"per-bout\" refers to \"per-action event\", but now I am not certain that I have understood this correctly (i.e. can a \"bout\" last for a few minutes?): given the readership, I think it would not be inappropriate to define some of these things explicitly.\n\nIn response to comment about fly behaviours that last minutes vs milliseconds: This is interesting, and I would be curious to know how classification accuracy relates to the time-scale of the behaviour (e.g. are most of the mistakes on long-term behaviours? i realize that this would only tell part of the story, e.g. if you have a behaviour that has both a long-term duration, but that also has very different short-term characteristics than many other behaviours, it should be easy to classify accuractely despite being \"long-term\"). If easy to investigate this, I would add a comment about it; if this is hard to investigate, it's probably not worth it at this point, although it's something you might want to look at in future.\n\nIn response to comment about scaling to human behavior: I agree that in principle, adding conv layers directly above the sensory input would be the right thing to try, but seriously: there is usually a pretty big gap between what \"should\" work and what actually works, as I am sure the authors are aware. (Indeed, I am sure the authors have a much more experiential and detailed understanding of the limitations of their work than I do). What I see presented is a nice system that has been demonstrated to handle spatiotemporal trajectories. The claims made should correspond to this. \n\nI would consider adjusting my rating to a 7 depending on future revisions.\n", "IS_META_REVIEW": false, "RECOMMENDATION": 7, "DATE": "21 Dec 2016 (modified: 25 Jan 2017)", "REVIEWER_CONFIDENCE": 3}, {"TITLE": "Interesting paper with mostly qualitative evaluation ", "OTHER_KEYS": "ICLR 2017 conference AnonReviewer1", "comments": "The paper presents a method for joint motion prediction and activity classification from sequences with two different applications: motion of fruit flies and online handwriting recognition.\n\nThe method uses a classical encoder-decoder pipeline, with skip connections allowing direct communication between the encoder and the decoder on respective levels of abstraction.\nMotion is discretized and predicted using classification. The model is trained on classification loss combined with a loss on motion prediction. The goal is to leverage latter loss in a semi-supervised setting from parts of the data which do not contain action labels.\n\nThe idea of leveraging predictions to train feature representations for discrimination is not new. However, the paper presents a couple of interesting ideas, partially inspired from other work in other areas.\n\nMy biggest concern is with the experimental evaluation. The experimental section contains a large amount of figures, which visualize what the model has learned in a qualitative way. However, quantitative evaluation is rarer.\n\n- On the fly application, the authors compare the classification performance with another method previously published by the first author.\n- Again on the fly application, the performance gain on motion prediction in figure 5c looks small compared to the baseline. I am not sure it is significant.\n- I did not see any recognition results on the handwriting application. Has this part not been evaluated?\n\nFigure 5a is difficult to understand and to interpret. The term \"BesNet\" is used here without any introduction.\n\nFigure 4 seems to tell multiple and different stories. I'd suggest splitting it into at least two different figures.\n", "IS_META_REVIEW": false, "RECOMMENDATION": 6, "DATE": "16 Dec 2016", "REVIEWER_CONFIDENCE": 4}, {"TITLE": "Review", "OTHER_KEYS": "ICLR 2017 conference AnonReviewer2", "comments": "This paper proposes a recurrent architecture for simultaneously predicting motion and action states of agents.\nThe paper is well written, clear in its presentation and backed up by good experiments.\nThey demonstrate that by forcing the network to predict motion has beneficial consequences on the classification of actions states,\nallowing more accurate classification with less training data.\nThey also show how the information learned by the network is interpretable and organised in a hierarchy.\n\nWeaknesses:\n- a critical discussion on the interplay between motion an behaviour that is needed to experience the benefits of their proposed model is missing from the paper.\n- moreover, a discussion on how this approach could scale to more challenging scenarios \"involving animals\" and visual input for instance and more general \"behaviours\" is also missing;\nThe criticism here is pointed at the fact that the title/abstract claim general behaviour modelling, whilst the experiments are focused on two very specific and relatively simple scenarios,\nmaking the original claim a little bit far fetched unless its backed up by additional evidence.\nUsing \"Insects\", or \"fruit flies\" would be more appropriate than \"animals\".", "IS_META_REVIEW": false, "RECOMMENDATION": 7, "DATE": "16 Dec 2016", "REVIEWER_CONFIDENCE": 4}, {"DATE": "12 Dec 2016", "TITLE": "performance detail", "IS_META_REVIEW": false, "comments": "In Figure 4b, BESNet and BENet have very comparable performance. In particular, BENet is better both with and without filter in the per-bout score. Do you happen to have any intuition or thoughts on why that is the case? Would that be related to the fact that in Fig 5b, there is almost no difference between the LL's associated with RNN and BESNet?\n", "OTHER_KEYS": "ICLR 2017 conference AnonReviewer3"}, {"DATE": "12 Dec 2016", "TITLE": "extent of behavior modeling", "IS_META_REVIEW": false, "comments": "", "OTHER_KEYS": "ICLR 2017 conference AnonReviewer3"}, {"DATE": "08 Dec 2016", "TITLE": "Non-Deterministic nature", "IS_META_REVIEW": false, "comments": "\"Animal behavior is nondeterministic\": I think that this is an overstatement, since it depends on your frame of reference. At the very least I'd rephrase it by saying that we do not have access to the underlying cognitive processes, which makes the behavior look like a non-determinist one given the information we have.\n\nMy actual question is: given that the model of the behavior is non-deterministic, would a GAN be more natural fit for the predictive part of this task?\n", "OTHER_KEYS": "ICLR 2017 conference AnonReviewer1"}, {"DATE": "08 Dec 2016", "TITLE": "Actions as states", "IS_META_REVIEW": false, "comments": "", "OTHER_KEYS": "ICLR 2017 conference AnonReviewer1"}, {"DATE": "29 Nov 2016", "TITLE": "On the correlation of behaviour and motion", "IS_META_REVIEW": false, "comments": "", "OTHER_KEYS": "ICLR 2017 conference AnonReviewer2"}, {"IS_META_REVIEW": true, "comments": "This paper proposes a recurrent architecture for simultaneously predicting motion and action states of agents.\nThe paper is well written, clear in its presentation and backed up by good experiments.\nThey demonstrate that by forcing the network to predict motion has beneficial consequences on the classification of actions states,\nallowing more accurate classification with less training data.\nThey also show how the information learned by the network is interpretable and organised in a hierarchy.\n\nWeaknesses:\n- a critical discussion on the interplay between motion an behaviour that is needed to experience the benefits of their proposed model is missing from the paper.\n- moreover, a discussion on how this approach could scale to more challenging scenarios \"involving animals\" and visual input for instance and more general \"behaviours\" is also missing;\nThe criticism here is pointed at the fact that the title/abstract claim general behaviour modelling, whilst the experiments are focused on two very specific and relatively simple scenarios,\nmaking the original claim a little bit far fetched unless its backed up by additional evidence.\nUsing \"Insects\", or \"fruit flies\" would be more appropriate than \"animals\"."}, {"DATE": "06 Feb 2017", "TITLE": "ICLR committee final decision", "IS_META_REVIEW": false, "comments": "Originality and Significance:\n  The paper develops a recurrently coupled discriminative / generative hierarchical model, as applied to fruit-fly behavior and online handwriting. Qualitative evaluation is provided by generating motions, in addition to quantitative results. Writer identity and fly gender are learned in an unsupervised fashion. While the individual components of the solution are not particularly novel, their combination together with the detailed experimental validation makes the method potentially interesting to a broad audience. Some reviewers have concerns about the broad claims that are implied by the title and abstract, and thus it is recommended that these be refined to be more specific about the method and the applications.\n \n Quality and Clarity:\n  The paper is well written.\n \n Pros:\n - interesting problem and application domains; will be of broad interest\n - useful ideas and architecture: shows that forcing the network to predictions about motion leads to improved classification\n - well written paper backed up by good experiments\n \n Cons:\n - the individual architectural features have for the most part been proposed before", "OTHER_KEYS": "ICLR 2017 pcs"}, {"DATE": "20 Jan 2017", "TITLE": "Response to all reviewers", "IS_META_REVIEW": false, "comments": "Dear reviewers,\n\nThank you all for your feedback and suggestions.\n\n** We have added the following changes to the paper: \n- better explanation of figures 4 and 5 in their captions\n- clearer definition a bout (Section 5.1, first paragraph)\n- analogy between diagonal connections and skip connections added (Section 3.1, first paragraph)\n\n** Regarding scaling to other data\nIn Section 4, paragraph 1, we describe how data should be represented to fit our framework, and we have added a discussion at the end of the paper about scaling to more complex scenarios (Section 6, paragraph 2).\n\n** In response to modeling \u201cbehavior\u201d being too strong of a claim and that it should be replaced with \u201cspatiotemporal behavior\u201d or \u201cfruit fly behavior\u201d:\n1) We qualify our statement in the abstract, stating both that we focus on motion sequences (i.e. trajectories) and that we test it on fruit flies and handwriting, which we further elaborate on in the introduction.\n\n2) I would argue that behavior is spatiotemporal.\nPeople from different fields may think of behavior differently, ranging from generating to observing behavior. A roboticist may think of it in terms of moving joints, an animator in terms of moving vertices, and a computer vision researcher in terms of moving pixels.\n\nAs noted by Levitis et al. (", "OTHER_KEYS": "Eyrun Eyjolfsdottir"}, {"TITLE": "using auxiliary tasks, skip connections and \"internal labels\" to classify spatiotemporal trajectories with an RNN", "OTHER_KEYS": "ICLR 2017 conference AnonReviewer3", "comments": "While my above review title is too verbose, it would be a more accurate title for the paper than the current one (an overall better title would probably be somewhere in between). \n\nThe overall approach is interesting: all three of the key techniques (aux. tasks, skip/diagonal connections, and the use of internal labels for the kind of data available) make a lot of sense.\n\nI found some of the results hard to understand/interpret. Some of the explanation in the discussion below has been helpful (e.g. see my earlier questions about Fig 4 and 5); the paper would benefit from including more such explanations. \n\nIt may be worthwhile very briefly mentioning the relationship of \"diagonal\" connections to other emerging terms for similar ideas (e.g. skip connections, etc). \"Skip\" seems to me to be accurate regardless of how you draw the network, whereas \"diagonal\" only makes sense for certain visual layouts.\n\nIn response to comment in the discussion below: \"leading to less over-segmentation of action bouts\" (and corresponding discussion in section 5.1 of the paper): I would be like to have a bit more about this in the paper. I have assumed that \"per-bout\" refers to \"per-action event\", but now I am not certain that I have understood this correctly (i.e. can a \"bout\" last for a few minutes?): given the readership, I think it would not be inappropriate to define some of these things explicitly.\n\nIn response to comment about fly behaviours that last minutes vs milliseconds: This is interesting, and I would be curious to know how classification accuracy relates to the time-scale of the behaviour (e.g. are most of the mistakes on long-term behaviours? i realize that this would only tell part of the story, e.g. if you have a behaviour that has both a long-term duration, but that also has very different short-term characteristics than many other behaviours, it should be easy to classify accuractely despite being \"long-term\"). If easy to investigate this, I would add a comment about it; if this is hard to investigate, it's probably not worth it at this point, although it's something you might want to look at in future.\n\nIn response to comment about scaling to human behavior: I agree that in principle, adding conv layers directly above the sensory input would be the right thing to try, but seriously: there is usually a pretty big gap between what \"should\" work and what actually works, as I am sure the authors are aware. (Indeed, I am sure the authors have a much more experiential and detailed understanding of the limitations of their work than I do). What I see presented is a nice system that has been demonstrated to handle spatiotemporal trajectories. The claims made should correspond to this. \n\nI would consider adjusting my rating to a 7 depending on future revisions.\n", "IS_META_REVIEW": false, "RECOMMENDATION": 7, "DATE": "21 Dec 2016 (modified: 25 Jan 2017)", "REVIEWER_CONFIDENCE": 3}, {"TITLE": "Interesting paper with mostly qualitative evaluation ", "OTHER_KEYS": "ICLR 2017 conference AnonReviewer1", "comments": "The paper presents a method for joint motion prediction and activity classification from sequences with two different applications: motion of fruit flies and online handwriting recognition.\n\nThe method uses a classical encoder-decoder pipeline, with skip connections allowing direct communication between the encoder and the decoder on respective levels of abstraction.\nMotion is discretized and predicted using classification. The model is trained on classification loss combined with a loss on motion prediction. The goal is to leverage latter loss in a semi-supervised setting from parts of the data which do not contain action labels.\n\nThe idea of leveraging predictions to train feature representations for discrimination is not new. However, the paper presents a couple of interesting ideas, partially inspired from other work in other areas.\n\nMy biggest concern is with the experimental evaluation. The experimental section contains a large amount of figures, which visualize what the model has learned in a qualitative way. However, quantitative evaluation is rarer.\n\n- On the fly application, the authors compare the classification performance with another method previously published by the first author.\n- Again on the fly application, the performance gain on motion prediction in figure 5c looks small compared to the baseline. I am not sure it is significant.\n- I did not see any recognition results on the handwriting application. Has this part not been evaluated?\n\nFigure 5a is difficult to understand and to interpret. The term \"BesNet\" is used here without any introduction.\n\nFigure 4 seems to tell multiple and different stories. I'd suggest splitting it into at least two different figures.\n", "IS_META_REVIEW": false, "RECOMMENDATION": 6, "DATE": "16 Dec 2016", "REVIEWER_CONFIDENCE": 4}, {"TITLE": "Review", "OTHER_KEYS": "ICLR 2017 conference AnonReviewer2", "comments": "This paper proposes a recurrent architecture for simultaneously predicting motion and action states of agents.\nThe paper is well written, clear in its presentation and backed up by good experiments.\nThey demonstrate that by forcing the network to predict motion has beneficial consequences on the classification of actions states,\nallowing more accurate classification with less training data.\nThey also show how the information learned by the network is interpretable and organised in a hierarchy.\n\nWeaknesses:\n- a critical discussion on the interplay between motion an behaviour that is needed to experience the benefits of their proposed model is missing from the paper.\n- moreover, a discussion on how this approach could scale to more challenging scenarios \"involving animals\" and visual input for instance and more general \"behaviours\" is also missing;\nThe criticism here is pointed at the fact that the title/abstract claim general behaviour modelling, whilst the experiments are focused on two very specific and relatively simple scenarios,\nmaking the original claim a little bit far fetched unless its backed up by additional evidence.\nUsing \"Insects\", or \"fruit flies\" would be more appropriate than \"animals\".", "IS_META_REVIEW": false, "RECOMMENDATION": 7, "DATE": "16 Dec 2016", "REVIEWER_CONFIDENCE": 4}, {"DATE": "12 Dec 2016", "TITLE": "performance detail", "IS_META_REVIEW": false, "comments": "In Figure 4b, BESNet and BENet have very comparable performance. In particular, BENet is better both with and without filter in the per-bout score. Do you happen to have any intuition or thoughts on why that is the case? Would that be related to the fact that in Fig 5b, there is almost no difference between the LL's associated with RNN and BESNet?\n", "OTHER_KEYS": "ICLR 2017 conference AnonReviewer3"}, {"DATE": "12 Dec 2016", "TITLE": "extent of behavior modeling", "IS_META_REVIEW": false, "comments": "", "OTHER_KEYS": "ICLR 2017 conference AnonReviewer3"}, {"DATE": "08 Dec 2016", "TITLE": "Non-Deterministic nature", "IS_META_REVIEW": false, "comments": "\"Animal behavior is nondeterministic\": I think that this is an overstatement, since it depends on your frame of reference. At the very least I'd rephrase it by saying that we do not have access to the underlying cognitive processes, which makes the behavior look like a non-determinist one given the information we have.\n\nMy actual question is: given that the model of the behavior is non-deterministic, would a GAN be more natural fit for the predictive part of this task?\n", "OTHER_KEYS": "ICLR 2017 conference AnonReviewer1"}, {"DATE": "08 Dec 2016", "TITLE": "Actions as states", "IS_META_REVIEW": false, "comments": "", "OTHER_KEYS": "ICLR 2017 conference AnonReviewer1"}, {"DATE": "29 Nov 2016", "TITLE": "On the correlation of behaviour and motion", "IS_META_REVIEW": false, "comments": "", "OTHER_KEYS": "ICLR 2017 conference AnonReviewer2"}], "authors": "Eyrun Eyjolfsdottir, Kristin Branson, Yisong Yue, Pietro Perona", "accepted": true, "id": "480"}