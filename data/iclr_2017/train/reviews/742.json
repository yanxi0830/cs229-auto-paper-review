{"conference": "ICLR 2017 conference submission", "title": "On the Expressive Power of Deep Neural Networks", "abstract": "We study the expressive power of deep neural networks before and after training. Considering neural nets after random initialization, we show that three natural measures of expressivity all display an exponential dependence on the depth of the network. We prove, theoretically and experimentally, that all of these measures are in fact related to a fourth quantity, trajectory length. This quantity grows exponentially in the depth of the network, and is responsible for the depth sensitivity observed. These results translate to consequences for networks during and after training. They suggest that parameters earlier in a network have greater influence on its expressive power \u2013 in particular, given a layer, its influence on expressivity is determined by the remaining depth of the network after that layer. This is verified with experiments on MNIST and CIFAR-10. We also explore the effect of training on the input-output map, and find that it trades off between the stability and expressivity of the input-output map.", "histories": [], "reviews": [{"IS_META_REVIEW": true, "comments": "SUMMARY \nThis paper studies the expressive power of deep neural networks under various related measures of expressivity. \nIt discusses how these measures relate to the `trajectory length', which is shown to depend exponentially on the depth of the network, in expectation (at least experimentally, at an intuitive level, or theoretically under certain assumptions). \nThe paper also emphasises the importance of the weights in the earlier layers of the network, as these have a larger influence on the represented classes of functions, and demonstrates this in an experimental setting. \n\nPROS \nThe paper further advances on topics related to the expressive power of feedforward neural networks with piecewise linear activation functions, in particular elaborating on the relations between various points of view. \n\nCONS \nThe paper further advances and elaborates on interesting topics, but to my appraisal it does not contribute significantly new aspects to the discussion. \n\nCOMMENTS\n- The paper is a bit long (especially the appendix) and seems to have been written a bit in a rush. \nOverall the main points are presented clearly, but the results and conclusions could be clearer about the assumptions / experimental vs theoretical nature. \nThe connection to previous works could also be clearer. \n\n- On page 2 one finds the statement ``Furthermore, architectures are often compared via \u2018hardcoded\u2019 weight values -- a specific function that can be represented efficiently by one architecture is shown to only be inefficiently approximated by another.'' \n\nThis is partially true, but it neglects important parts of the discussion conducted in the cited papers. \nIn particular, the paper [Montufar, Pascanu, Cho, Bengio 2014] discusses not one hard coded function, but classes of functions with a given number of linear regions. \nThat paper shows that deep networks generically* produce functions with at least a given number of linear regions, while shallow networks never do. \n* Generically meaning that, after fixing the number of parameters, any function represented by the network, for parameter values form an open, positive -measure, neighbourhood, belongs to the class of functions which have at least a certain number of linear regions. \nIn particular, such statements can be directly interpreted in terms of networks with random weights. \n\n- One of the measures for expressivity discussed in the present paper is the number of Dichotomies. In statistical learning theory, this notion is used to define the VC-dimension. In that context, a high value is associated with a high statistical complexity, meaning that picking a good hypothesis requires more data. \n\n- On page 2 one finds the statement ``We discover and prove the underlying reason for this \u2013 all three measures are directly proportional to a fourth quantity, trajectory length.'' \nThe expected trajectory length increasing exponentially with depth can be interpreted as the increase (or decrease) in the scale by a composition of the form a*...*a x, which scales the inputs by a^d. Such a scaling by itself certainly is not an underlying cause for an increase in the number of dichotomies or activation patterns or transitions. Here it seems that at least the assumptions on the considered types of trajectories also play an important role. \nThis is probably related to another observation from page 4: ``if the variance of the bias is comparatively too large... then we no longer see exponential growth.''\n\nOTHER SPECIFIC COMMENTS \nIn Theorem 1 \n- Here it would be good to be more specific about ``random neural network'', i.e., fixed connectivity structure with random weights, and also about the kind of one-dimensional trajectory, i.e., finite in length, closed, differentiable almost everywhere, etc. \n\n- The notation ``g \\geq O(f)'' used in the theorem reads literally as |g| \\geq \\leq k |f| for some k>0, for large enough arguments. It could also be read as g being not smaller than some function that is bounded above by f, which holds for instance whenever g\\geq 0. \nFor expressing asymptotic lower bounds one can use the notation \\Omega (see"}, {"DATE": "06 Feb 2017", "TITLE": "ICLR committee final decision", "IS_META_REVIEW": false, "comments": "While the reviewers saw some value in your contribution, there were also serious issues, so the paper does not reach the acceptance threshold.", "OTHER_KEYS": "ICLR 2017 pcs"}, {"TITLE": "Not clear. The approach and methodology are not explained.", "OTHER_KEYS": "ICLR 2017 conference AnonReviewer3", "comments": "This paper presents a theoretical and empirical approach to the problem of understanding the expressivity of deep networks.\n\nRandom networks (deep networks with random Gaussian weights, hard tanh or ReLU activation) are studied according to several criterions: number of neutron transitions, activation patterns, dichotomies and trajectory length.\n\nThere doesn't seem to be a solid justification for why the newly introduced measures of expressivity really measure expressivity.\nFor instance the trajectory length seems a very discutable measure of expressivity. The only justification given for why it should be a good measure of expressivity is proportionality with other measures of expressivity in the specific case of random networks.\n\nThe paper is too obscure and too long. The work may have some interesting ideas but it does not seem to be properly replaced in context.\n\nSome findings seem trivial.\n\ndetailed comments\n\np2 \n\n\"Much of the work examining achievable functions relies on unrealistic architectural assumptions such as layers being exponentially wide\"\n\nI don\u2019t think so. In \"Deep Belief Networks are Compact Universal Approximators\" by Leroux et al., proof is given that deep but narrow feed-forward neural networks with sigmoidal units can represent any Boolean expression i.e. A neural network with 2n\u22121 + 1 layers of n units (with n the number of input neutron).\n\n\u201cComparing architectures in such a fashion limits the generality of the conclusions\u201d\n\nTo my knowledge much of the previous work has focused on mathematical proof, and has led to very general conclusions on the representative power of deep networks (one example being Leroux et al again).\n\nIt is much harder to generalise the approach you propose, based on random networks which are not used in practice.\n\n\u201c[we study] a family of networks arising in practice: the behaviour of networks after random initialisation\u201d\n\nThese networks arise in practice as an intermediate step that is not used to perform computations; this means that the representative power of such intermediate networks is a priori irrelevant. You would need to justify why it is not.\n\n\u201cresults on random networks provide natural baselines to compare trained networks with\u201d\n\nrandom networks are not \u201cnatural\u201d for the study of expressivity of deep networks. It is not clear how the representative power of random networks (what kind of random networks seems an important question here) is linked to the representative power of (i) of the whole class of networks or (ii) the class of networks after training. Those two classes of networks are the ones we would a priori care about and you would need to justify why the study of random networks helps in understanding either (i) or (ii).\n\np5\n\n\u201cAs FW is a random neural network [\u2026] it would suggest that points far enough away from each other would have independent signs, i.e. a direct proportionality between the length of z(n)(t) and the number of times it crosses the decision boundary.\u201d\n\nAs you say, it seems that proportionality of the two measures depends on the network being random. This seems to invalidate generalisation to other networks, i.e. if the networks are not random, one would assume that path lengths are not proportional.\n\np6\n\nthe expressivity w.r.t. remaining depth seems a trivial concerns, completely equivalent to the expressivity w.r.t. depth. This makes the remark in figure 5 that the number of achievable dichotomies only depends *only* on the number of layers above the layer swept seem trivial\n\np7\n\nin figure 6 a network width of 100 for MNIST seems much too small. Accordingly performance is very poor and it is difficult to generalise the results to relevant situations.\n", "IS_META_REVIEW": false, "RECOMMENDATION": 3, "DATE": "23 Dec 2016", "REVIEWER_CONFIDENCE": 3}, {"TITLE": "Review of ``ON THE EXPRESSIVE POWER OF DEEP NEURAL NETWORKS''", "OTHER_KEYS": "ICLR 2017 conference AnonReviewer1", "comments": "SUMMARY \nThis paper studies the expressive power of deep neural networks under various related measures of expressivity. \nIt discusses how these measures relate to the `trajectory length', which is shown to depend exponentially on the depth of the network, in expectation (at least experimentally, at an intuitive level, or theoretically under certain assumptions). \nThe paper also emphasises the importance of the weights in the earlier layers of the network, as these have a larger influence on the represented classes of functions, and demonstrates this in an experimental setting. \n\nPROS \nThe paper further advances on topics related to the expressive power of feedforward neural networks with piecewise linear activation functions, in particular elaborating on the relations between various points of view. \n\nCONS \nThe paper further advances and elaborates on interesting topics, but to my appraisal it does not contribute significantly new aspects to the discussion. \n\nCOMMENTS\n- The paper is a bit long (especially the appendix) and seems to have been written a bit in a rush. \nOverall the main points are presented clearly, but the results and conclusions could be clearer about the assumptions / experimental vs theoretical nature. \nThe connection to previous works could also be clearer. \n\n- On page 2 one finds the statement ``Furthermore, architectures are often compared via \u2018hardcoded\u2019 weight values -- a specific function that can be represented efficiently by one architecture is shown to only be inefficiently approximated by another.'' \n\nThis is partially true, but it neglects important parts of the discussion conducted in the cited papers. \nIn particular, the paper [Montufar, Pascanu, Cho, Bengio 2014] discusses not one hard coded function, but classes of functions with a given number of linear regions. \nThat paper shows that deep networks generically* produce functions with at least a given number of linear regions, while shallow networks never do. \n* Generically meaning that, after fixing the number of parameters, any function represented by the network, for parameter values form an open, positive -measure, neighbourhood, belongs to the class of functions which have at least a certain number of linear regions. \nIn particular, such statements can be directly interpreted in terms of networks with random weights. \n\n- One of the measures for expressivity discussed in the present paper is the number of Dichotomies. In statistical learning theory, this notion is used to define the VC-dimension. In that context, a high value is associated with a high statistical complexity, meaning that picking a good hypothesis requires more data. \n\n- On page 2 one finds the statement ``We discover and prove the underlying reason for this \u2013 all three measures are directly proportional to a fourth quantity, trajectory length.'' \nThe expected trajectory length increasing exponentially with depth can be interpreted as the increase (or decrease) in the scale by a composition of the form a*...*a x, which scales the inputs by a^d. Such a scaling by itself certainly is not an underlying cause for an increase in the number of dichotomies or activation patterns or transitions. Here it seems that at least the assumptions on the considered types of trajectories also play an important role. \nThis is probably related to another observation from page 4: ``if the variance of the bias is comparatively too large... then we no longer see exponential growth.''\n\nOTHER SPECIFIC COMMENTS \nIn Theorem 1 \n- Here it would be good to be more specific about ``random neural network'', i.e., fixed connectivity structure with random weights, and also about the kind of one-dimensional trajectory, i.e., finite in length, closed, differentiable almost everywhere, etc. \n\n- The notation ``g \\geq O(f)'' used in the theorem reads literally as |g| \\geq \\leq k |f| for some k>0, for large enough arguments. It could also be read as g being not smaller than some function that is bounded above by f, which holds for instance whenever g\\geq 0. \nFor expressing asymptotic lower bounds one can use the notation \\Omega (see ", "IS_META_REVIEW": false, "RECOMMENDATION": 6, "DATE": "19 Dec 2016", "REVIEWER_CONFIDENCE": 5}, {"DATE": "17 Dec 2016", "TITLE": "Response to Reviewer2", "IS_META_REVIEW": false, "comments": "Thank you for the review! We will take the comments into account and endeavour to make the text even clearer.\n\nA quick comment about motivation: our goal in this work improve interpretability in deep neural networks through a better understanding of neural network expressivity. In particular, we look at different \"diagnostics\" (transitions/activation patterns/dichotomies) for measuring the expressiveness of different neural network architectures, and their practical consequences. The surprising fact that three natural measures of expressiveness are related by *direct* proportion (see below) to trajectory length suggests consequences on remaining depth (earlier parameters are more important to fit the final function) and a trade off between expressivity and stability during training due to initialization choices.  \n\nResponses inline to other specific comments below:\n\nTrajectory Length: We will add this as a definition before Theorem 1. We take a 1-d trajectory to be a 1-d curve in the high dimensional space, and we measure the length  -- ", "OTHER_KEYS": "Maithra Raghu"}, {"TITLE": "Interesting ideas on the trajectory lengths, the motivations and the conclusion of the study are not clear ", "OTHER_KEYS": "ICLR 2017 conference AnonReviewer2", "comments": "Summary of the paper:\n\nAuthors study in this paper quantities related to the expressivity of neural networks.The analysis is done for a random network. authors define the \u2018trajectory length\u2019 of a one dimensional trajectory as the length of the trajectory as the points (in a m- dimensional space) are embedded by layers of the network. They provide growth factors as function of hidden units k, and number of layers d.  the growth factor is exponential in the number of layers. Authors relates this trajectory length to authors quantities : \u2018transitions\u2019,\u2019activation patterns \u2019 and \u2018Dichotomies\u2019. \nAs a consequence of this study authors suggest that training only  earlier layers in the network  leads higher accuracy then just training later layers. Experiments are presented on MNIST and CIFAR10.\n\nClarity:\n\nThe  paper is a little hard to follow, since  the motivations are not clear in the introduction and the definitions across the paper are not clear. \n\nNovelty:\n\nStudying the trajectory length as function of transforming the data by a multilayer network is   new and interesting idea. The relation to transition numbers is in term of the growth factor, and not as a quantity to quantity relationship. Hence it is hard to understand what are the implications.\n\nSignificance:\n\nThe geometry of the input set (of dimension m)  shows up only weakly in the activation patterns analysis.  The trajectory study should tell us how the network organizes the input set. As observed in the experiments the network becomes contractive/selective as we train the network. It would be interesting to study those phenomenas using this trajectory length , as a measure for disentangling nuisance factors ( such as invariances etc.). In the supervised setting the network need not to be contractive every where , so it needs to be selective to the class label, a  theoretical study of the selectivity and contraction using the trajectory length would be more appealing.\n\nDetailed comments:\n\nTheorem 1:\n\n- As raised by reviewer one the definition of a one dimensional input trajectory is missing. \n- What does theorem 1 tells us about the design and the architecture to use in neural networks as promised in the introduction is not clear. The connection to transitions in Theorem 2 is rather weak. \n\nTheorem 2:\n\n- in the proof of theorem 2 it not clear what is meant by T and t. Notations are confusing, the expectation is taken with respect to which weight: is it W_{d+1} or (W_{d+1} and W_{d})? I understand you don't want to overload notation but maybe E_{d+1} can help keeping track. I don't see how the recursion is applied if T and t in it, have different definitions. seems T_{d+1} for you is a random variable and t_{d} is fixed. Are you fixing W_d and then looking at W_{d+1} as  random?\n\n- In the same proof:  the recursion  is for d>1  ? your analysis is for W \\in R^{k\\times k}, you don't not study the W \\in \\mathbb{R}^{k\\times m}. In this case you can not assume assume that |z^(0)|=1.\n\n- should d=1, be analyzed alone to know how it scales with m?\n\nTheorem 4 in main text:\n\n- Is the proof missing? or Theorem 4 in the main text is Theorem 6 in the appendix?\n\nFigures 8 and 9:\n\n- the trajectory length reduction in the training isn't that just the network becoming contractive to enable mapping the training points to the labels? See for instance  on contraction in deep networks ", "IS_META_REVIEW": false, "RECOMMENDATION": 5, "DATE": "15 Dec 2016", "REVIEWER_CONFIDENCE": 3}, {"DATE": "02 Dec 2016", "TITLE": "sigma", "IS_META_REVIEW": false, "comments": "", "OTHER_KEYS": "ICLR 2017 conference AnonReviewer3"}, {"DATE": "02 Dec 2016", "TITLE": "notation, definitions", "IS_META_REVIEW": false, "comments": "", "OTHER_KEYS": "ICLR 2017 conference AnonReviewer1"}, {"DATE": "07 Nov 2016", "TITLE": "ICLR Paper Format", "IS_META_REVIEW": false, "comments": "Dear Authors,\n\nPlease resubmit your paper in the ICLR 2017 format with the correct font type for your submission to be considered. Thank you!", "OTHER_KEYS": "Tara N Sainath"}, {"IS_META_REVIEW": true, "comments": "SUMMARY \nThis paper studies the expressive power of deep neural networks under various related measures of expressivity. \nIt discusses how these measures relate to the `trajectory length', which is shown to depend exponentially on the depth of the network, in expectation (at least experimentally, at an intuitive level, or theoretically under certain assumptions). \nThe paper also emphasises the importance of the weights in the earlier layers of the network, as these have a larger influence on the represented classes of functions, and demonstrates this in an experimental setting. \n\nPROS \nThe paper further advances on topics related to the expressive power of feedforward neural networks with piecewise linear activation functions, in particular elaborating on the relations between various points of view. \n\nCONS \nThe paper further advances and elaborates on interesting topics, but to my appraisal it does not contribute significantly new aspects to the discussion. \n\nCOMMENTS\n- The paper is a bit long (especially the appendix) and seems to have been written a bit in a rush. \nOverall the main points are presented clearly, but the results and conclusions could be clearer about the assumptions / experimental vs theoretical nature. \nThe connection to previous works could also be clearer. \n\n- On page 2 one finds the statement ``Furthermore, architectures are often compared via \u2018hardcoded\u2019 weight values -- a specific function that can be represented efficiently by one architecture is shown to only be inefficiently approximated by another.'' \n\nThis is partially true, but it neglects important parts of the discussion conducted in the cited papers. \nIn particular, the paper [Montufar, Pascanu, Cho, Bengio 2014] discusses not one hard coded function, but classes of functions with a given number of linear regions. \nThat paper shows that deep networks generically* produce functions with at least a given number of linear regions, while shallow networks never do. \n* Generically meaning that, after fixing the number of parameters, any function represented by the network, for parameter values form an open, positive -measure, neighbourhood, belongs to the class of functions which have at least a certain number of linear regions. \nIn particular, such statements can be directly interpreted in terms of networks with random weights. \n\n- One of the measures for expressivity discussed in the present paper is the number of Dichotomies. In statistical learning theory, this notion is used to define the VC-dimension. In that context, a high value is associated with a high statistical complexity, meaning that picking a good hypothesis requires more data. \n\n- On page 2 one finds the statement ``We discover and prove the underlying reason for this \u2013 all three measures are directly proportional to a fourth quantity, trajectory length.'' \nThe expected trajectory length increasing exponentially with depth can be interpreted as the increase (or decrease) in the scale by a composition of the form a*...*a x, which scales the inputs by a^d. Such a scaling by itself certainly is not an underlying cause for an increase in the number of dichotomies or activation patterns or transitions. Here it seems that at least the assumptions on the considered types of trajectories also play an important role. \nThis is probably related to another observation from page 4: ``if the variance of the bias is comparatively too large... then we no longer see exponential growth.''\n\nOTHER SPECIFIC COMMENTS \nIn Theorem 1 \n- Here it would be good to be more specific about ``random neural network'', i.e., fixed connectivity structure with random weights, and also about the kind of one-dimensional trajectory, i.e., finite in length, closed, differentiable almost everywhere, etc. \n\n- The notation ``g \\geq O(f)'' used in the theorem reads literally as |g| \\geq \\leq k |f| for some k>0, for large enough arguments. It could also be read as g being not smaller than some function that is bounded above by f, which holds for instance whenever g\\geq 0. \nFor expressing asymptotic lower bounds one can use the notation \\Omega (see"}, {"DATE": "06 Feb 2017", "TITLE": "ICLR committee final decision", "IS_META_REVIEW": false, "comments": "While the reviewers saw some value in your contribution, there were also serious issues, so the paper does not reach the acceptance threshold.", "OTHER_KEYS": "ICLR 2017 pcs"}, {"TITLE": "Not clear. The approach and methodology are not explained.", "OTHER_KEYS": "ICLR 2017 conference AnonReviewer3", "comments": "This paper presents a theoretical and empirical approach to the problem of understanding the expressivity of deep networks.\n\nRandom networks (deep networks with random Gaussian weights, hard tanh or ReLU activation) are studied according to several criterions: number of neutron transitions, activation patterns, dichotomies and trajectory length.\n\nThere doesn't seem to be a solid justification for why the newly introduced measures of expressivity really measure expressivity.\nFor instance the trajectory length seems a very discutable measure of expressivity. The only justification given for why it should be a good measure of expressivity is proportionality with other measures of expressivity in the specific case of random networks.\n\nThe paper is too obscure and too long. The work may have some interesting ideas but it does not seem to be properly replaced in context.\n\nSome findings seem trivial.\n\ndetailed comments\n\np2 \n\n\"Much of the work examining achievable functions relies on unrealistic architectural assumptions such as layers being exponentially wide\"\n\nI don\u2019t think so. In \"Deep Belief Networks are Compact Universal Approximators\" by Leroux et al., proof is given that deep but narrow feed-forward neural networks with sigmoidal units can represent any Boolean expression i.e. A neural network with 2n\u22121 + 1 layers of n units (with n the number of input neutron).\n\n\u201cComparing architectures in such a fashion limits the generality of the conclusions\u201d\n\nTo my knowledge much of the previous work has focused on mathematical proof, and has led to very general conclusions on the representative power of deep networks (one example being Leroux et al again).\n\nIt is much harder to generalise the approach you propose, based on random networks which are not used in practice.\n\n\u201c[we study] a family of networks arising in practice: the behaviour of networks after random initialisation\u201d\n\nThese networks arise in practice as an intermediate step that is not used to perform computations; this means that the representative power of such intermediate networks is a priori irrelevant. You would need to justify why it is not.\n\n\u201cresults on random networks provide natural baselines to compare trained networks with\u201d\n\nrandom networks are not \u201cnatural\u201d for the study of expressivity of deep networks. It is not clear how the representative power of random networks (what kind of random networks seems an important question here) is linked to the representative power of (i) of the whole class of networks or (ii) the class of networks after training. Those two classes of networks are the ones we would a priori care about and you would need to justify why the study of random networks helps in understanding either (i) or (ii).\n\np5\n\n\u201cAs FW is a random neural network [\u2026] it would suggest that points far enough away from each other would have independent signs, i.e. a direct proportionality between the length of z(n)(t) and the number of times it crosses the decision boundary.\u201d\n\nAs you say, it seems that proportionality of the two measures depends on the network being random. This seems to invalidate generalisation to other networks, i.e. if the networks are not random, one would assume that path lengths are not proportional.\n\np6\n\nthe expressivity w.r.t. remaining depth seems a trivial concerns, completely equivalent to the expressivity w.r.t. depth. This makes the remark in figure 5 that the number of achievable dichotomies only depends *only* on the number of layers above the layer swept seem trivial\n\np7\n\nin figure 6 a network width of 100 for MNIST seems much too small. Accordingly performance is very poor and it is difficult to generalise the results to relevant situations.\n", "IS_META_REVIEW": false, "RECOMMENDATION": 3, "DATE": "23 Dec 2016", "REVIEWER_CONFIDENCE": 3}, {"TITLE": "Review of ``ON THE EXPRESSIVE POWER OF DEEP NEURAL NETWORKS''", "OTHER_KEYS": "ICLR 2017 conference AnonReviewer1", "comments": "SUMMARY \nThis paper studies the expressive power of deep neural networks under various related measures of expressivity. \nIt discusses how these measures relate to the `trajectory length', which is shown to depend exponentially on the depth of the network, in expectation (at least experimentally, at an intuitive level, or theoretically under certain assumptions). \nThe paper also emphasises the importance of the weights in the earlier layers of the network, as these have a larger influence on the represented classes of functions, and demonstrates this in an experimental setting. \n\nPROS \nThe paper further advances on topics related to the expressive power of feedforward neural networks with piecewise linear activation functions, in particular elaborating on the relations between various points of view. \n\nCONS \nThe paper further advances and elaborates on interesting topics, but to my appraisal it does not contribute significantly new aspects to the discussion. \n\nCOMMENTS\n- The paper is a bit long (especially the appendix) and seems to have been written a bit in a rush. \nOverall the main points are presented clearly, but the results and conclusions could be clearer about the assumptions / experimental vs theoretical nature. \nThe connection to previous works could also be clearer. \n\n- On page 2 one finds the statement ``Furthermore, architectures are often compared via \u2018hardcoded\u2019 weight values -- a specific function that can be represented efficiently by one architecture is shown to only be inefficiently approximated by another.'' \n\nThis is partially true, but it neglects important parts of the discussion conducted in the cited papers. \nIn particular, the paper [Montufar, Pascanu, Cho, Bengio 2014] discusses not one hard coded function, but classes of functions with a given number of linear regions. \nThat paper shows that deep networks generically* produce functions with at least a given number of linear regions, while shallow networks never do. \n* Generically meaning that, after fixing the number of parameters, any function represented by the network, for parameter values form an open, positive -measure, neighbourhood, belongs to the class of functions which have at least a certain number of linear regions. \nIn particular, such statements can be directly interpreted in terms of networks with random weights. \n\n- One of the measures for expressivity discussed in the present paper is the number of Dichotomies. In statistical learning theory, this notion is used to define the VC-dimension. In that context, a high value is associated with a high statistical complexity, meaning that picking a good hypothesis requires more data. \n\n- On page 2 one finds the statement ``We discover and prove the underlying reason for this \u2013 all three measures are directly proportional to a fourth quantity, trajectory length.'' \nThe expected trajectory length increasing exponentially with depth can be interpreted as the increase (or decrease) in the scale by a composition of the form a*...*a x, which scales the inputs by a^d. Such a scaling by itself certainly is not an underlying cause for an increase in the number of dichotomies or activation patterns or transitions. Here it seems that at least the assumptions on the considered types of trajectories also play an important role. \nThis is probably related to another observation from page 4: ``if the variance of the bias is comparatively too large... then we no longer see exponential growth.''\n\nOTHER SPECIFIC COMMENTS \nIn Theorem 1 \n- Here it would be good to be more specific about ``random neural network'', i.e., fixed connectivity structure with random weights, and also about the kind of one-dimensional trajectory, i.e., finite in length, closed, differentiable almost everywhere, etc. \n\n- The notation ``g \\geq O(f)'' used in the theorem reads literally as |g| \\geq \\leq k |f| for some k>0, for large enough arguments. It could also be read as g being not smaller than some function that is bounded above by f, which holds for instance whenever g\\geq 0. \nFor expressing asymptotic lower bounds one can use the notation \\Omega (see ", "IS_META_REVIEW": false, "RECOMMENDATION": 6, "DATE": "19 Dec 2016", "REVIEWER_CONFIDENCE": 5}, {"DATE": "17 Dec 2016", "TITLE": "Response to Reviewer2", "IS_META_REVIEW": false, "comments": "Thank you for the review! We will take the comments into account and endeavour to make the text even clearer.\n\nA quick comment about motivation: our goal in this work improve interpretability in deep neural networks through a better understanding of neural network expressivity. In particular, we look at different \"diagnostics\" (transitions/activation patterns/dichotomies) for measuring the expressiveness of different neural network architectures, and their practical consequences. The surprising fact that three natural measures of expressiveness are related by *direct* proportion (see below) to trajectory length suggests consequences on remaining depth (earlier parameters are more important to fit the final function) and a trade off between expressivity and stability during training due to initialization choices.  \n\nResponses inline to other specific comments below:\n\nTrajectory Length: We will add this as a definition before Theorem 1. We take a 1-d trajectory to be a 1-d curve in the high dimensional space, and we measure the length  -- ", "OTHER_KEYS": "Maithra Raghu"}, {"TITLE": "Interesting ideas on the trajectory lengths, the motivations and the conclusion of the study are not clear ", "OTHER_KEYS": "ICLR 2017 conference AnonReviewer2", "comments": "Summary of the paper:\n\nAuthors study in this paper quantities related to the expressivity of neural networks.The analysis is done for a random network. authors define the \u2018trajectory length\u2019 of a one dimensional trajectory as the length of the trajectory as the points (in a m- dimensional space) are embedded by layers of the network. They provide growth factors as function of hidden units k, and number of layers d.  the growth factor is exponential in the number of layers. Authors relates this trajectory length to authors quantities : \u2018transitions\u2019,\u2019activation patterns \u2019 and \u2018Dichotomies\u2019. \nAs a consequence of this study authors suggest that training only  earlier layers in the network  leads higher accuracy then just training later layers. Experiments are presented on MNIST and CIFAR10.\n\nClarity:\n\nThe  paper is a little hard to follow, since  the motivations are not clear in the introduction and the definitions across the paper are not clear. \n\nNovelty:\n\nStudying the trajectory length as function of transforming the data by a multilayer network is   new and interesting idea. The relation to transition numbers is in term of the growth factor, and not as a quantity to quantity relationship. Hence it is hard to understand what are the implications.\n\nSignificance:\n\nThe geometry of the input set (of dimension m)  shows up only weakly in the activation patterns analysis.  The trajectory study should tell us how the network organizes the input set. As observed in the experiments the network becomes contractive/selective as we train the network. It would be interesting to study those phenomenas using this trajectory length , as a measure for disentangling nuisance factors ( such as invariances etc.). In the supervised setting the network need not to be contractive every where , so it needs to be selective to the class label, a  theoretical study of the selectivity and contraction using the trajectory length would be more appealing.\n\nDetailed comments:\n\nTheorem 1:\n\n- As raised by reviewer one the definition of a one dimensional input trajectory is missing. \n- What does theorem 1 tells us about the design and the architecture to use in neural networks as promised in the introduction is not clear. The connection to transitions in Theorem 2 is rather weak. \n\nTheorem 2:\n\n- in the proof of theorem 2 it not clear what is meant by T and t. Notations are confusing, the expectation is taken with respect to which weight: is it W_{d+1} or (W_{d+1} and W_{d})? I understand you don't want to overload notation but maybe E_{d+1} can help keeping track. I don't see how the recursion is applied if T and t in it, have different definitions. seems T_{d+1} for you is a random variable and t_{d} is fixed. Are you fixing W_d and then looking at W_{d+1} as  random?\n\n- In the same proof:  the recursion  is for d>1  ? your analysis is for W \\in R^{k\\times k}, you don't not study the W \\in \\mathbb{R}^{k\\times m}. In this case you can not assume assume that |z^(0)|=1.\n\n- should d=1, be analyzed alone to know how it scales with m?\n\nTheorem 4 in main text:\n\n- Is the proof missing? or Theorem 4 in the main text is Theorem 6 in the appendix?\n\nFigures 8 and 9:\n\n- the trajectory length reduction in the training isn't that just the network becoming contractive to enable mapping the training points to the labels? See for instance  on contraction in deep networks ", "IS_META_REVIEW": false, "RECOMMENDATION": 5, "DATE": "15 Dec 2016", "REVIEWER_CONFIDENCE": 3}, {"DATE": "02 Dec 2016", "TITLE": "sigma", "IS_META_REVIEW": false, "comments": "", "OTHER_KEYS": "ICLR 2017 conference AnonReviewer3"}, {"DATE": "02 Dec 2016", "TITLE": "notation, definitions", "IS_META_REVIEW": false, "comments": "", "OTHER_KEYS": "ICLR 2017 conference AnonReviewer1"}, {"DATE": "07 Nov 2016", "TITLE": "ICLR Paper Format", "IS_META_REVIEW": false, "comments": "Dear Authors,\n\nPlease resubmit your paper in the ICLR 2017 format with the correct font type for your submission to be considered. Thank you!", "OTHER_KEYS": "Tara N Sainath"}], "authors": "Maithra Raghu, Ben Poole, Jon Kleinberg, Surya Ganguli, Jascha Sohl-Dickstein", "accepted": false, "id": "742"}