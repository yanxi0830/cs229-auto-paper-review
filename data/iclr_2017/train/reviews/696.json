{"conference": "ICLR 2017 conference submission", "title": "Emergent Predication Structure in Vector Representations of Neural Readers", "abstract": "Reading comprehension is a question answering task where the answer is to be found in a given passage about entities and events not mentioned in general knowledge sources. A significant number of neural architectures for this task (neural readers) have recently been developed and evaluated on large cloze-style datasets. We present experiments supporting the emergence of \u201cpredication structure\u201d in the hidden state vectors of a class of neural readers including the Attentive Reader and Stanford Reader. We posits that the hidden state vectors can be viewed as (a representation of) a concatenation [P, c] of a \u201cpredicate vector\u201d P and a \u201cconstant symbol vector\u201d c and that the hidden state represents the atomic formula P(c). This predication structure plays a conceptual role in relating \u201caggregation readers\u201d such as the Attentive Reader and the Stanford Reader to \u201cexplicit reference readers\u201d such as the Attention-Sum Reader, the Gated-Attention Reader and the Attention-over-Attention Reader. In an independent contribution, we show that the addition of linguistics features to the input to existing neural readers significantly boosts performance yielding the best results to date on the Who-did-What dataset.", "histories": [], "reviews": [{"IS_META_REVIEW": true, "comments": "The paper proposed to analyze several recently developed machine readers and found that some machine readers could potentially take advantages of the entity marker (given that the same marker points out to the same entity). I usually like analysis papers, but I found the argument proposed in this paper not very clear.\n\nI like the experiments on the Stanford reader, which shows that the entity marker in fact helps the Stanford reader on WDW. I found that results rather interesting.\n\nHowever, I found the organization and the overall message of this paper quite confusing. First of all, it feels that the authors want to explain the above behavior with some definition of the \u201cstructures\u201d. However, I am not sure that how successful the attempt is. For me, it is still not clear what the structures are. This makes reading section 4 a bit frustrating. \n\nI am also not sure what is the take home message of this paper. Does it mean that the entity marking should be used in the MR models? Should we design models that can also model the entity reference at the same time? What are the roles of the linguistic features here? Should we use linguistic structure to overcome the reference issue?\n\nOverall, I feel that the analysis is interesting, but I feel that the paper can benefit from having a more focused argument."}, {"DATE": "06 Feb 2017", "TITLE": "ICLR committee final decision", "IS_META_REVIEW": false, "comments": "The reviewers mostly agree that this paper offers valuable insights about a family of problems in automatic \"reading\" of text, as well as current solutions. The paper seems to fail to generate excitement because it doesn't really point the way forward. I disagree with some reviewers about the work's suitability for ICLR (as opposed to an ACL venue) since ML researchers are also thinking about these tasks now. The consensus is that the paper will have greater impact (wherever it is published) with a clearer message.", "OTHER_KEYS": "ICLR 2017 pcs"}, {"TITLE": "Simple predicate structure and data set", "OTHER_KEYS": "ICLR 2017 conference AnonReviewer1", "comments": "The paper aims to consolidate some recent literature in simple types of \"reading comprehension\" tasks involving matching questions to answers to be found in a passage, and then to explore the types of structure learned by these models and propose modifications. These reading comprehension datasets such as CNN/Daily Mail are on the simpler side because they do not generally involve chains of reasoning over multiple pieces of supporting evidence as can be found in datasets like MCTest. Many models have been proposed for this task, and the paper breaks down these models into \"aggregation readers\" and \"explicit reference readers.\" The authors show that the aggregation readers organize their hidden states into a predicate structure which allows them to mimic the explicit reference readers. The authors then experiment with adding linguistic features, including reference features, to the existing models to improve performance.\n\nI appreciate the re-naming and re-writing of the paper to make it more clear that the aggregation readers are specifically learning a predicate structure, as well as the inclusion of results about dimensionality of the symbol space. Further, I think the effort to organize and categorize several different reading comprehension models into broader classes is useful, as the field has been producing many such models and the landscape is unclear. \n\nThe concerns with this paper are that the predicate structure demonstrated is fairly simple, and it is not clear that it provides insight towards the development of better models in the future, since the \"explicit reference readers\" need not learn it, and the CNN/Daily Mail dataset has very little headroom left as demonstrated by Chen et al. 2016. The desire for \"dramatic improvements in performance\" mentioned in the discussion section probably cannot be achieved on these datasets. More complex datasets would probably involve multi-hop inference which this paper does not discuss. Further, the message of the paper is a bit scattered and hard to parse, and could benefit from a bit more focus.\n\nI think that with the explosion of various competing neural network models for NLP tasks, contributions like this one which attempt to organize and analyze the landscape are valuable, but that this paper might be better suited for an NLP conference or journal such as TACL.\n", "IS_META_REVIEW": false, "RECOMMENDATION": 6, "DATE": "20 Dec 2016", "REVIEWER_CONFIDENCE": 5}, {"TITLE": "No Title", "OTHER_KEYS": "ICLR 2017 conference AnonReviewer3", "comments": "This paper aims to provide an insightful and analytic survey over the recent literature on reading comprehension with the distinct goal of investigating whether logical structure (or predication, as the authors rephrased in their response) arises in many of the recent models. I really like the spirit of the paper and appreciate the efforts to organize rather chaotic recent literature into two unified themes: \"aggregation readers\" and \"explicit reference models\u201d. Overall the quality of writing is great and section 3 was especially nice to read. I\u2019m also happy with the proposed rewording from \"logical structure\" to \u201cpredication\", and the clarification by the authors was detailed and helpful.\n\nI think I still have slight mixed feelings about the contribution of the work. First, I wonder whether the choice of the dataset was ideal in the first place to accomplish the desired goal of the paper. There have been concerns about CNN/DailyMail dataset (Chen et al. ACL\u201916) and it is not clear to me whether the dataset supports investigation on logical structure of interesting kinds. Maybe it is bound to be rather about lack of logical structure.\n\nSecond, I wish the discussion on predication sheds more practical insights into dataset design or model design to better tackle reading comprehension challenges. In that sense, it may have been more helpful if the authors could make more precise analysis on different types of reading comprehension challenges, what types of logical structure are lacking in various existing models and datasets, and point to specific directions where the community needs to focus more.\n\n", "IS_META_REVIEW": false, "RECOMMENDATION": 6, "DATE": "17 Dec 2016", "REVIEWER_CONFIDENCE": 4}, {"DATE": "14 Dec 2016", "TITLE": "Update the papers", "IS_META_REVIEW": false, "comments": "Hi, Dear reviewers,\n     \n   Thanks for the valuable suggestions on our paper and sorry to make you confused about the notations, we have updated the paper to make it more clear. Please see the latest version.", "OTHER_KEYS": "Hai Wang"}, {"TITLE": "Review", "OTHER_KEYS": "ICLR 2017 conference AnonReviewer2", "comments": "The paper proposed to analyze several recently developed machine readers and found that some machine readers could potentially take advantages of the entity marker (given that the same marker points out to the same entity). I usually like analysis papers, but I found the argument proposed in this paper not very clear.\n\nI like the experiments on the Stanford reader, which shows that the entity marker in fact helps the Stanford reader on WDW. I found that results rather interesting.\n\nHowever, I found the organization and the overall message of this paper quite confusing. First of all, it feels that the authors want to explain the above behavior with some definition of the \u201cstructures\u201d. However, I am not sure that how successful the attempt is. For me, it is still not clear what the structures are. This makes reading section 4 a bit frustrating. \n\nI am also not sure what is the take home message of this paper. Does it mean that the entity marking should be used in the MR models? Should we design models that can also model the entity reference at the same time? What are the roles of the linguistic features here? Should we use linguistic structure to overcome the reference issue?\n\nOverall, I feel that the analysis is interesting, but I feel that the paper can benefit from having a more focused argument.\n", "IS_META_REVIEW": false, "RECOMMENDATION": 5, "DATE": "13 Dec 2016", "REVIEWER_CONFIDENCE": 3}, {"DATE": "03 Dec 2016", "TITLE": "Questions", "IS_META_REVIEW": false, "comments": "", "OTHER_KEYS": "ICLR 2017 conference AnonReviewer1"}, {"DATE": "02 Dec 2016", "TITLE": "logical structure", "IS_META_REVIEW": false, "comments": "", "OTHER_KEYS": "ICLR 2017 conference AnonReviewer3"}, {"DATE": "02 Dec 2016", "TITLE": "Pre-review Questions", "IS_META_REVIEW": false, "comments": "", "OTHER_KEYS": "ICLR 2017 conference AnonReviewer2"}, {"IS_META_REVIEW": true, "comments": "The paper proposed to analyze several recently developed machine readers and found that some machine readers could potentially take advantages of the entity marker (given that the same marker points out to the same entity). I usually like analysis papers, but I found the argument proposed in this paper not very clear.\n\nI like the experiments on the Stanford reader, which shows that the entity marker in fact helps the Stanford reader on WDW. I found that results rather interesting.\n\nHowever, I found the organization and the overall message of this paper quite confusing. First of all, it feels that the authors want to explain the above behavior with some definition of the \u201cstructures\u201d. However, I am not sure that how successful the attempt is. For me, it is still not clear what the structures are. This makes reading section 4 a bit frustrating. \n\nI am also not sure what is the take home message of this paper. Does it mean that the entity marking should be used in the MR models? Should we design models that can also model the entity reference at the same time? What are the roles of the linguistic features here? Should we use linguistic structure to overcome the reference issue?\n\nOverall, I feel that the analysis is interesting, but I feel that the paper can benefit from having a more focused argument."}, {"DATE": "06 Feb 2017", "TITLE": "ICLR committee final decision", "IS_META_REVIEW": false, "comments": "The reviewers mostly agree that this paper offers valuable insights about a family of problems in automatic \"reading\" of text, as well as current solutions. The paper seems to fail to generate excitement because it doesn't really point the way forward. I disagree with some reviewers about the work's suitability for ICLR (as opposed to an ACL venue) since ML researchers are also thinking about these tasks now. The consensus is that the paper will have greater impact (wherever it is published) with a clearer message.", "OTHER_KEYS": "ICLR 2017 pcs"}, {"TITLE": "Simple predicate structure and data set", "OTHER_KEYS": "ICLR 2017 conference AnonReviewer1", "comments": "The paper aims to consolidate some recent literature in simple types of \"reading comprehension\" tasks involving matching questions to answers to be found in a passage, and then to explore the types of structure learned by these models and propose modifications. These reading comprehension datasets such as CNN/Daily Mail are on the simpler side because they do not generally involve chains of reasoning over multiple pieces of supporting evidence as can be found in datasets like MCTest. Many models have been proposed for this task, and the paper breaks down these models into \"aggregation readers\" and \"explicit reference readers.\" The authors show that the aggregation readers organize their hidden states into a predicate structure which allows them to mimic the explicit reference readers. The authors then experiment with adding linguistic features, including reference features, to the existing models to improve performance.\n\nI appreciate the re-naming and re-writing of the paper to make it more clear that the aggregation readers are specifically learning a predicate structure, as well as the inclusion of results about dimensionality of the symbol space. Further, I think the effort to organize and categorize several different reading comprehension models into broader classes is useful, as the field has been producing many such models and the landscape is unclear. \n\nThe concerns with this paper are that the predicate structure demonstrated is fairly simple, and it is not clear that it provides insight towards the development of better models in the future, since the \"explicit reference readers\" need not learn it, and the CNN/Daily Mail dataset has very little headroom left as demonstrated by Chen et al. 2016. The desire for \"dramatic improvements in performance\" mentioned in the discussion section probably cannot be achieved on these datasets. More complex datasets would probably involve multi-hop inference which this paper does not discuss. Further, the message of the paper is a bit scattered and hard to parse, and could benefit from a bit more focus.\n\nI think that with the explosion of various competing neural network models for NLP tasks, contributions like this one which attempt to organize and analyze the landscape are valuable, but that this paper might be better suited for an NLP conference or journal such as TACL.\n", "IS_META_REVIEW": false, "RECOMMENDATION": 6, "DATE": "20 Dec 2016", "REVIEWER_CONFIDENCE": 5}, {"TITLE": "No Title", "OTHER_KEYS": "ICLR 2017 conference AnonReviewer3", "comments": "This paper aims to provide an insightful and analytic survey over the recent literature on reading comprehension with the distinct goal of investigating whether logical structure (or predication, as the authors rephrased in their response) arises in many of the recent models. I really like the spirit of the paper and appreciate the efforts to organize rather chaotic recent literature into two unified themes: \"aggregation readers\" and \"explicit reference models\u201d. Overall the quality of writing is great and section 3 was especially nice to read. I\u2019m also happy with the proposed rewording from \"logical structure\" to \u201cpredication\", and the clarification by the authors was detailed and helpful.\n\nI think I still have slight mixed feelings about the contribution of the work. First, I wonder whether the choice of the dataset was ideal in the first place to accomplish the desired goal of the paper. There have been concerns about CNN/DailyMail dataset (Chen et al. ACL\u201916) and it is not clear to me whether the dataset supports investigation on logical structure of interesting kinds. Maybe it is bound to be rather about lack of logical structure.\n\nSecond, I wish the discussion on predication sheds more practical insights into dataset design or model design to better tackle reading comprehension challenges. In that sense, it may have been more helpful if the authors could make more precise analysis on different types of reading comprehension challenges, what types of logical structure are lacking in various existing models and datasets, and point to specific directions where the community needs to focus more.\n\n", "IS_META_REVIEW": false, "RECOMMENDATION": 6, "DATE": "17 Dec 2016", "REVIEWER_CONFIDENCE": 4}, {"DATE": "14 Dec 2016", "TITLE": "Update the papers", "IS_META_REVIEW": false, "comments": "Hi, Dear reviewers,\n     \n   Thanks for the valuable suggestions on our paper and sorry to make you confused about the notations, we have updated the paper to make it more clear. Please see the latest version.", "OTHER_KEYS": "Hai Wang"}, {"TITLE": "Review", "OTHER_KEYS": "ICLR 2017 conference AnonReviewer2", "comments": "The paper proposed to analyze several recently developed machine readers and found that some machine readers could potentially take advantages of the entity marker (given that the same marker points out to the same entity). I usually like analysis papers, but I found the argument proposed in this paper not very clear.\n\nI like the experiments on the Stanford reader, which shows that the entity marker in fact helps the Stanford reader on WDW. I found that results rather interesting.\n\nHowever, I found the organization and the overall message of this paper quite confusing. First of all, it feels that the authors want to explain the above behavior with some definition of the \u201cstructures\u201d. However, I am not sure that how successful the attempt is. For me, it is still not clear what the structures are. This makes reading section 4 a bit frustrating. \n\nI am also not sure what is the take home message of this paper. Does it mean that the entity marking should be used in the MR models? Should we design models that can also model the entity reference at the same time? What are the roles of the linguistic features here? Should we use linguistic structure to overcome the reference issue?\n\nOverall, I feel that the analysis is interesting, but I feel that the paper can benefit from having a more focused argument.\n", "IS_META_REVIEW": false, "RECOMMENDATION": 5, "DATE": "13 Dec 2016", "REVIEWER_CONFIDENCE": 3}, {"DATE": "03 Dec 2016", "TITLE": "Questions", "IS_META_REVIEW": false, "comments": "", "OTHER_KEYS": "ICLR 2017 conference AnonReviewer1"}, {"DATE": "02 Dec 2016", "TITLE": "logical structure", "IS_META_REVIEW": false, "comments": "", "OTHER_KEYS": "ICLR 2017 conference AnonReviewer3"}, {"DATE": "02 Dec 2016", "TITLE": "Pre-review Questions", "IS_META_REVIEW": false, "comments": "", "OTHER_KEYS": "ICLR 2017 conference AnonReviewer2"}], "authors": "Hai Wang, Takeshi Onishi, Kevin Gimpel, David McAllester", "accepted": false, "id": "696"}