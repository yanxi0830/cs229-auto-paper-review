{"conference": "ICLR 2017 conference submission", "title": "Sigma Delta Quantized Networks", "abstract": "Deep neural networks can be obscenely wasteful. When processing video, a convolutional network expends a fixed amount of computation for each frame with no regard to the similarity between neighbouring frames. As a result, it ends up repeatedly doing very similar computations. To put an end to such waste, we introduce Sigma-Delta networks. With each new input, each layer in this network sends a discretized form of its change in activation to the next layer. Thus the amount of computation that the network does scales with the amount of change in the input and layer activations, rather than the size of the network. We introduce an optimization method for converting any pre-trained deep network into an optimally efficient Sigma-Delta network, and show that our algorithm, if run on the appropriate hardware, could cut at least an order of magnitude from the computational cost of processing video data.", "histories": [], "reviews": [{"IS_META_REVIEW": true, "comments": "This is an interesting paper about quantized networks that work on temporal difference inputs.  The basic idea is that when a network has only to process differences then this is computational much more efficient specifically with natural video data since large parts of an image would be fairly constant so that the network only has to process the informative sections of the image (video stream). This is of course how the human visual system works, and it is hence of interest even beyond the core machine learning community. \n\nAs an aside, there is a strong community interested in event-based vision such as the group of Tobi Delbr\u00fcck, and it might be interesting to connect to this community. This might even provide a reference for your comments on page 1.\n\nI guess the biggest novel contribution is that a rounding network can be replaced by a sigma-delta network, but that the order of discretization and summation doe make some difference in the actual processing load. I think I followed the steps and \nMost of my questions have already been answers in the pre-review period. My only question remaining is on page 3, \u201cIt should be noted that when we refer to \u201ctemporal differences\u201d, we refer not to the change in the signal over time, but in the change between two inputs presented sequentially. The output of our network only depends on the value and order of inputs, not on the temporal spacing between them.\u201d\n\nThis does not make sense to me. As I understand you just take the difference between two frames regardless if you call this temporal or not it is a change in one frame. So this statement rather confuses me and maybe should be dropped unless I do miss something here, in which case some more explanation would be necessary.\n\nFigure 1 should be made bigger.\n\nAn improvement of the paper that I could think about is a better discussion of the relevance of the findings. Yes, you do show that your sigma-delta network save some operation compared to threshold, but is this difference essential for a specific task, or does your solution has relevance for neuroscience?"}, {"DATE": "06 Feb 2017", "TITLE": "ICLR committee final decision", "IS_META_REVIEW": false, "comments": "The reviewers are in consensus that this paper introduces an interesting idea with potentially huge gains in the efficiency of video analysis tasks (dependent on hardware advances). There was extensive discussion during the question/review period. Two of the reviewers scored this paper in the Top 50% of accepted papers. The lower score is from the less confident reviewer. This seems to the AC to be a clear accept.", "OTHER_KEYS": "ICLR 2017 pcs"}, {"DATE": "24 Jan 2017", "TITLE": "Updated Version", "IS_META_REVIEW": false, "comments": "Dear Reviewers.\n\nThank you for all your comments.  We have uploaded a final draft based on your feedback.  \n\nSummary of changes:\n- Added to the discussion section, mentioning applicability for hardware, and how training on \"slow features\" may improve our network, as mentioned by Reviewers 1 and 2.  \n- Added new plots to the final figure, showing how computation breaks down across layers in different versions of the network. \n- Added a small experiment, in appendix, demonstrating that in the pretrained VGGnet we used, features to not change significantly more slowly in higher layers than in lower layers.\n- Moved connection to herding to appendix.\n- Clarified the point about Temporal vs Sequential differences brought up by Reviewer 3.\n", "OTHER_KEYS": "Peter OConnor"}, {"OTHER_KEYS": "ICLR 2017 conference AnonReviewer1", "TITLE": "No Title", "comments": "This paper presented a method of improving the efficiency of deep networks acting on a sequence of correlated inputs, by only performing the computations required to capture changes between adjacent inputs. The paper was clearly written, the approach is clever, and it's neat to see a practical algorithm driven by what is essentially a spiking network. The benefits of this approach are still more theoretical than practical -- it seems unlikely to be worthwhile to do this on current hardware. I strongly suspect that if deep networks were trained with an appropriate sparse slowness penalty, the reduction in computation would be much larger.", "IS_ANNOTATED": true, "IS_META_REVIEW": false, "RECOMMENDATION": 8, "DATE": "17 Dec 2016", "REVIEWER_CONFIDENCE": 4}, {"TITLE": "Review", "OTHER_KEYS": "ICLR 2017 conference AnonReviewer2", "comments": "The paper presents a method to improve the efficiency of CNNs that encode sequential inputs in a \u2018slow\u2019 fashion such that there is only a small change between the representation of adjacent steps in the sequence.\nIt demonstrates theoretical performance improvements for toy video data (temporal mnist) and natural movies with a powerful Deep CNN (VGG). \n\nThe improvement is naturally limited by the \u2018slowness\u2019 of the CNN representation that is transformed into a sigma-delta network: CNNs that are specifically designed to have \u2018slow\u2019 representations will benefit most. Also, it is likely that only specialised hardware can fully harness the improved efficiency achieved by the proposed method. Thus as of now, the full potential of the method cannot be thoroughly evaluated.\nHowever, since the processing of sequential data seems to be a broad and general area of application, it is conceivable that this work will be useful in the design and application of future CNNs.\n\nAll in all, this paper introduces an interesting idea to address an important topic. It shows promising initial results, but the demonstration of the actual usefulness and relevance of the presented method relies on future work.\n", "IS_META_REVIEW": false, "RECOMMENDATION": 6, "DATE": "16 Dec 2016", "REVIEWER_CONFIDENCE": 3}, {"TITLE": "No Title", "MEANINGFUL_COMPARISON": 3, "OTHER_KEYS": "ICLR 2017 conference AnonReviewer3", "comments": "This is an interesting paper about quantized networks that work on temporal difference inputs.  The basic idea is that when a network has only to process differences then this is computational much more efficient specifically with natural video data since large parts of an image would be fairly constant so that the network only has to process the informative sections of the image (video stream). This is of course how the human visual system works, and it is hence of interest even beyond the core machine learning community. \n\nAs an aside, there is a strong community interested in event-based vision such as the group of Tobi Delbr\u00fcck, and it might be interesting to connect to this community. This might even provide a reference for your comments on page 1.\n\nI guess the biggest novel contribution is that a rounding network can be replaced by a sigma-delta network, but that the order of discretization and summation doe make some difference in the actual processing load. I think I followed the steps and \nMost of my questions have already been answers in the pre-review period. My only question remaining is on page 3, \u201cIt should be noted that when we refer to \u201ctemporal differences\u201d, we refer not to the change in the signal over time, but in the change between two inputs presented sequentially. The output of our network only depends on the value and order of inputs, not on the temporal spacing between them.\u201d\n\nThis does not make sense to me. As I understand you just take the difference between two frames regardless if you call this temporal or not it is a change in one frame. So this statement rather confuses me and maybe should be dropped unless I do miss something here, in which case some more explanation would be necessary.\n\nFigure 1 should be made bigger.\n\nAn improvement of the paper that I could think about is a better discussion of the relevance of the findings. Yes, you do show that your sigma-delta network save some operation compared to threshold, but is this difference essential for a specific task, or does your solution has relevance for neuroscience? ", "ORIGINALITY": 1, "IS_ANNOTATED": true, "IS_META_REVIEW": false, "RECOMMENDATION": 8, "DATE": "16 Dec 2016", "REVIEWER_CONFIDENCE": 4}, {"DATE": "11 Dec 2016", "TITLE": "Practical performance gains", "IS_META_REVIEW": false, "comments": "", "OTHER_KEYS": "ICLR 2017 conference AnonReviewer2"}, {"TITLE": "quantization", "OTHER_KEYS": "ICLR 2017 conference AnonReviewer1", "comments": "", "IS_ANNOTATED": true, "IS_META_REVIEW": false, "DATE": "01 Dec 2016"}, {"TITLE": "Significance of difference between rounding and sigma-delta", "OTHER_KEYS": "ICLR 2017 conference AnonReviewer3", "MEANINGFUL_COMPARISON": 3, "comments": "", "ORIGINALITY": 1, "IS_ANNOTATED": true, "IS_META_REVIEW": false, "DATE": "29 Nov 2016"}, {"IS_META_REVIEW": true, "comments": "This is an interesting paper about quantized networks that work on temporal difference inputs.  The basic idea is that when a network has only to process differences then this is computational much more efficient specifically with natural video data since large parts of an image would be fairly constant so that the network only has to process the informative sections of the image (video stream). This is of course how the human visual system works, and it is hence of interest even beyond the core machine learning community. \n\nAs an aside, there is a strong community interested in event-based vision such as the group of Tobi Delbr\u00fcck, and it might be interesting to connect to this community. This might even provide a reference for your comments on page 1.\n\nI guess the biggest novel contribution is that a rounding network can be replaced by a sigma-delta network, but that the order of discretization and summation doe make some difference in the actual processing load. I think I followed the steps and \nMost of my questions have already been answers in the pre-review period. My only question remaining is on page 3, \u201cIt should be noted that when we refer to \u201ctemporal differences\u201d, we refer not to the change in the signal over time, but in the change between two inputs presented sequentially. The output of our network only depends on the value and order of inputs, not on the temporal spacing between them.\u201d\n\nThis does not make sense to me. As I understand you just take the difference between two frames regardless if you call this temporal or not it is a change in one frame. So this statement rather confuses me and maybe should be dropped unless I do miss something here, in which case some more explanation would be necessary.\n\nFigure 1 should be made bigger.\n\nAn improvement of the paper that I could think about is a better discussion of the relevance of the findings. Yes, you do show that your sigma-delta network save some operation compared to threshold, but is this difference essential for a specific task, or does your solution has relevance for neuroscience?"}, {"DATE": "06 Feb 2017", "TITLE": "ICLR committee final decision", "IS_META_REVIEW": false, "comments": "The reviewers are in consensus that this paper introduces an interesting idea with potentially huge gains in the efficiency of video analysis tasks (dependent on hardware advances). There was extensive discussion during the question/review period. Two of the reviewers scored this paper in the Top 50% of accepted papers. The lower score is from the less confident reviewer. This seems to the AC to be a clear accept.", "OTHER_KEYS": "ICLR 2017 pcs"}, {"DATE": "24 Jan 2017", "TITLE": "Updated Version", "IS_META_REVIEW": false, "comments": "Dear Reviewers.\n\nThank you for all your comments.  We have uploaded a final draft based on your feedback.  \n\nSummary of changes:\n- Added to the discussion section, mentioning applicability for hardware, and how training on \"slow features\" may improve our network, as mentioned by Reviewers 1 and 2.  \n- Added new plots to the final figure, showing how computation breaks down across layers in different versions of the network. \n- Added a small experiment, in appendix, demonstrating that in the pretrained VGGnet we used, features to not change significantly more slowly in higher layers than in lower layers.\n- Moved connection to herding to appendix.\n- Clarified the point about Temporal vs Sequential differences brought up by Reviewer 3.\n", "OTHER_KEYS": "Peter OConnor"}, {"OTHER_KEYS": "ICLR 2017 conference AnonReviewer1", "TITLE": "No Title", "comments": "This paper presented a method of improving the efficiency of deep networks acting on a sequence of correlated inputs, by only performing the computations required to capture changes between adjacent inputs. The paper was clearly written, the approach is clever, and it's neat to see a practical algorithm driven by what is essentially a spiking network. The benefits of this approach are still more theoretical than practical -- it seems unlikely to be worthwhile to do this on current hardware. I strongly suspect that if deep networks were trained with an appropriate sparse slowness penalty, the reduction in computation would be much larger.", "IS_ANNOTATED": true, "IS_META_REVIEW": false, "RECOMMENDATION": 8, "DATE": "17 Dec 2016", "REVIEWER_CONFIDENCE": 4}, {"TITLE": "Review", "OTHER_KEYS": "ICLR 2017 conference AnonReviewer2", "comments": "The paper presents a method to improve the efficiency of CNNs that encode sequential inputs in a \u2018slow\u2019 fashion such that there is only a small change between the representation of adjacent steps in the sequence.\nIt demonstrates theoretical performance improvements for toy video data (temporal mnist) and natural movies with a powerful Deep CNN (VGG). \n\nThe improvement is naturally limited by the \u2018slowness\u2019 of the CNN representation that is transformed into a sigma-delta network: CNNs that are specifically designed to have \u2018slow\u2019 representations will benefit most. Also, it is likely that only specialised hardware can fully harness the improved efficiency achieved by the proposed method. Thus as of now, the full potential of the method cannot be thoroughly evaluated.\nHowever, since the processing of sequential data seems to be a broad and general area of application, it is conceivable that this work will be useful in the design and application of future CNNs.\n\nAll in all, this paper introduces an interesting idea to address an important topic. It shows promising initial results, but the demonstration of the actual usefulness and relevance of the presented method relies on future work.\n", "IS_META_REVIEW": false, "RECOMMENDATION": 6, "DATE": "16 Dec 2016", "REVIEWER_CONFIDENCE": 3}, {"TITLE": "No Title", "MEANINGFUL_COMPARISON": 3, "OTHER_KEYS": "ICLR 2017 conference AnonReviewer3", "comments": "This is an interesting paper about quantized networks that work on temporal difference inputs.  The basic idea is that when a network has only to process differences then this is computational much more efficient specifically with natural video data since large parts of an image would be fairly constant so that the network only has to process the informative sections of the image (video stream). This is of course how the human visual system works, and it is hence of interest even beyond the core machine learning community. \n\nAs an aside, there is a strong community interested in event-based vision such as the group of Tobi Delbr\u00fcck, and it might be interesting to connect to this community. This might even provide a reference for your comments on page 1.\n\nI guess the biggest novel contribution is that a rounding network can be replaced by a sigma-delta network, but that the order of discretization and summation doe make some difference in the actual processing load. I think I followed the steps and \nMost of my questions have already been answers in the pre-review period. My only question remaining is on page 3, \u201cIt should be noted that when we refer to \u201ctemporal differences\u201d, we refer not to the change in the signal over time, but in the change between two inputs presented sequentially. The output of our network only depends on the value and order of inputs, not on the temporal spacing between them.\u201d\n\nThis does not make sense to me. As I understand you just take the difference between two frames regardless if you call this temporal or not it is a change in one frame. So this statement rather confuses me and maybe should be dropped unless I do miss something here, in which case some more explanation would be necessary.\n\nFigure 1 should be made bigger.\n\nAn improvement of the paper that I could think about is a better discussion of the relevance of the findings. Yes, you do show that your sigma-delta network save some operation compared to threshold, but is this difference essential for a specific task, or does your solution has relevance for neuroscience? ", "ORIGINALITY": 1, "IS_ANNOTATED": true, "IS_META_REVIEW": false, "RECOMMENDATION": 8, "DATE": "16 Dec 2016", "REVIEWER_CONFIDENCE": 4}, {"DATE": "11 Dec 2016", "TITLE": "Practical performance gains", "IS_META_REVIEW": false, "comments": "", "OTHER_KEYS": "ICLR 2017 conference AnonReviewer2"}, {"TITLE": "quantization", "OTHER_KEYS": "ICLR 2017 conference AnonReviewer1", "comments": "", "IS_ANNOTATED": true, "IS_META_REVIEW": false, "DATE": "01 Dec 2016"}, {"TITLE": "Significance of difference between rounding and sigma-delta", "OTHER_KEYS": "ICLR 2017 conference AnonReviewer3", "MEANINGFUL_COMPARISON": 3, "comments": "", "ORIGINALITY": 1, "IS_ANNOTATED": true, "IS_META_REVIEW": false, "DATE": "29 Nov 2016"}], "authors": "Peter O'Connor, Max Welling", "accepted": true, "id": "413"}