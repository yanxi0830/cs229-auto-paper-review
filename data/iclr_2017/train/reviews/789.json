{"conference": "ICLR 2017 conference submission", "title": "Improving Sampling from Generative Autoencoders with Markov Chains", "abstract": "We focus on generative autoencoders, such as variational or adversarial autoencoders, which jointly learn a generative model alongside an inference model. Generative autoencoders are those which are trained to softly enforce a prior on the latent distribution learned by the inference model. We call the distribution to which the inference model maps observed samples, the learned latent distribution, which may not be consistent with the prior. We formulate a Markov chain Monte Carlo (MCMC) sampling process, equivalent to iteratively decoding and encoding, which allows us to sample from the learned latent distribution. Since, the generative model learns to map from the learned latent distribution, rather than the prior, we may use MCMC to improve the quality of samples drawn from the generative model, especially when the learned latent distribution is far from the prior. Using MCMC sampling, we are able to reveal previously unseen differences between generative autoencoders trained either with or without a denoising criterion.", "histories": [], "reviews": [{"IS_META_REVIEW": true, "comments": "The authors propose to sample from VAEs through a Markov chain [z_t ~ q(z|x=x_{t-1}), x_t ~ p(x|z=z_t)]. The paper uses confusing notation, oversells the novelty, ignoring some relevant previous results. The qualitative difference between regular sampling and this Gibbs chain is not very convincing, judging from the figures. It would be a great workshop paper (perhaps more), if the authors fix the notation, fix the discussion to related work, and produce more convincing (perhaps simply upscaled?) figures.\n\nComments: \n - Rezende et al's (2014) original VAE paper already discusses the Markov chain, which is ignored in this paper\n - Notation is nonstandard / confusing. At page 1, it\u2019s unclear what the authors mean with \u201cp(x|z) which is approximated as q(x|z)\u201d.\n- It\u2019s also not clear what\u2019s meant with q(z). At page 2, q(z) is called the learned distribution, while p(z) can in general also be a learned distribution.\n- It\u2019s not true that it\u2019s impossible to draw samples from q(z): one can sample x ~ q(x) from the dataset, then draw z ~ q(z|x).\n- It's not explained whether the analysis only applies to continuous observed spaces, or also discrete observed spaces\n- Figures 3 and 4 are not very convincing."}, {"DATE": "06 Feb 2017", "TITLE": "ICLR committee final decision", "IS_META_REVIEW": false, "comments": "This approach taken in this paper is topical, especially since the importance of sampling and generating diverse samples is increasingly discussed in work on generative models. There were several concerns from reviewers, in three areas particularly: connection and comparison to related work; lack of clarity and understanding of the paper; experiments that are not sufficiently convincing. These have been addressed to some extent by the authors, discussing in more detail the related work, especially in connection to Rezende et al., and GSN of Bengio et al., and with improved figures. But these points are still of concern especially in terms of assessing sample diversity in relation to much of the recent work on richer variational posterior methods and other techniques. For these reasons, the paper is not yet ready for acceptance at this years conference.", "OTHER_KEYS": "ICLR 2017 pcs"}, {"DATE": "13 Jan 2017", "TITLE": "Updated paper", "IS_META_REVIEW": false, "comments": "We have updated our paper to include changes that reflect comments made by the reviewers. A PDF document detailing our changes  may be found at: ", "OTHER_KEYS": "Antonia Creswell"}, {"TITLE": "No Title", "OTHER_KEYS": "ICLR 2017 conference AnonReviewer3", "comments": "This paper attempts to learn a Markov chain to estimate a probability distribution over latent variables Z, such that P(X | Z) can be eased to generate samples from a data distribution.\n\nThe paper in its current form is not acceptable due to the following reasons:\n1. No quantitative evaluation. The authors do include samples from the generative model, which however are insufficient to judge performance of the model. See comment 2.\n2. The description of the model is very unclear. I had to indulge in a lot of charity to interpret what the authors \"must be doing\". What does Q(Z) mean? Does it mean the true posterior P(Z | X) ? What is the generative model here? Typically, it's P(Z)P(X|Z). VAEs use a variational approximation Q(Z | X) to the true posterior P(Z | X). Are you trying to say that your model can sample from the true posterior P(Z | X)?\n\nComments:\n1. Using additive noise in the input does not seem like a reasonable idea. Any justification of why this is being done?\n2. Approaches which learn transition operators are usually very amenable to data augmentation-based semi-supervised learning. I encourage the authors to improve their paper by testing their model on semi-supervised learning benchmarks.", "IS_META_REVIEW": false, "RECOMMENDATION": 3, "DATE": "19 Dec 2016", "REVIEWER_CONFIDENCE": 5}, {"TITLE": "Review", "OTHER_KEYS": "ICLR 2017 conference AnonReviewer2", "comments": "The authors propose to sample from VAEs through a Markov chain [z_t ~ q(z|x=x_{t-1}), x_t ~ p(x|z=z_t)]. The paper uses confusing notation, oversells the novelty, ignoring some relevant previous results. The qualitative difference between regular sampling and this Gibbs chain is not very convincing, judging from the figures. It would be a great workshop paper (perhaps more), if the authors fix the notation, fix the discussion to related work, and produce more convincing (perhaps simply upscaled?) figures.\n\nComments: \n - Rezende et al's (2014) original VAE paper already discusses the Markov chain, which is ignored in this paper\n - Notation is nonstandard / confusing. At page 1, it\u2019s unclear what the authors mean with \u201cp(x|z) which is approximated as q(x|z)\u201d.\n- It\u2019s also not clear what\u2019s meant with q(z). At page 2, q(z) is called the learned distribution, while p(z) can in general also be a learned distribution.\n- It\u2019s not true that it\u2019s impossible to draw samples from q(z): one can sample x ~ q(x) from the dataset, then draw z ~ q(z|x).\n- It's not explained whether the analysis only applies to continuous observed spaces, or also discrete observed spaces\n- Figures 3 and 4 are not very convincing.\n", "IS_META_REVIEW": false, "RECOMMENDATION": 3, "DATE": "19 Dec 2016", "REVIEWER_CONFIDENCE": 4}, {"TITLE": "Review", "OTHER_KEYS": "ICLR 2017 conference AnonReviewer1", "comments": "The authors argues that the standard ancestral sampling from stochastic autoencoders (such as the Variational Autoencoder and the Adversarial\nAutoencoder) imposes the overly-restrictive constraint that the encoder distribution must marginally match the latent variable prior. They propose, as an alternative, a Markov Chain Monte Carlo approach that avoids the need to specify a simple parametric form for the prior.\n\nThe paper is not clearly written. Most critically, the notation the authors use is either deeply flawed, or there are simple misunderstanding with respect to the manipulations of probability distributions. For example, the authors seem to suggest that both distributions Q(Z|X) and Q(X|Z) are parametrized. For this to be true the model must either be trivially simple, or an energy-based model. There is no indication that they are speaking of an energy-based model. Another example of possible confusion is the statement that the ratio of distributions Q(Z|X)/P(Z) = 1. I believe this is supposed to be a ratio of marginals: Q(Z)/P(X) = 1. Overall, it seems like there is a confusion of what Q and P represent. The standard notation used in VAEs is to use P to represent the decoder distribution and\nQ to represent the encoder distribution. This seems not to be how the authors are using these terms. Nor does it seem like there is a single consistent interpretation. \n\nThe empirical results consist entirely of qualitative results (samples and reconstructions) from a single dataset (CelebA). The samples are also not at all up to the quality of the SOTA models. The interpolations shown in Figures 1 and 3 both seems to look like interpolation in pixel space for both the VAE model and the proposed DVAE. \n", "IS_META_REVIEW": false, "RECOMMENDATION": 3, "DATE": "17 Dec 2016", "REVIEWER_CONFIDENCE": 4}, {"DATE": "09 Dec 2016", "TITLE": "Question", "IS_META_REVIEW": false, "comments": "", "OTHER_KEYS": "ICLR 2017 conference AnonReviewer3"}, {"DATE": "08 Dec 2016", "TITLE": "Prior art", "IS_META_REVIEW": false, "comments": "While you cite Rezende et al. 2014 when referring to VAEs, you claim the main contribution of your work is the generation of posterior samples from a Markov Chain. However, Rezende et al. 2014 presented a very similar idea. Let me quote them directly:\n\nWe do not integrate over the missing\nvalues, but use a procedure that simulates a Markov\nchain that we show converges to the true marginal distribution\nof missing given observed pixels.\n\n-- Section 5.4\n\nImage completion can be approximatively achieved by\na simple iterative procedure which consists of (i) initializing\nthe non-observed pixels with random values;\n(ii) sampling from the recognition distribution given\nthe resulting image; (iii) reconstruct the image given\nthe sample from the recognition model; (iv) iterate the\nprocedure.\n\n-- Appendix F\n\nHow is this procedure different from your main contribution? I mean, they motivate with missing data imputation and start in a different way, but the main loop seems the same. Even if there is a significant difference between the procedures, I believe this should be addressed in the paper. I also suggest taking a closer look at appendix F, they provide some proofs which seem relevant to your work.\n", "OTHER_KEYS": "Pedro Tabacof"}, {"DATE": "08 Nov 2016", "TITLE": "Novelty of samples?", "IS_META_REVIEW": false, "comments": "How are the novelty of samples affected as more samples are generated from the Markov Chain? I played around with a similar idea and found that after about 6-7 Monte Carlo samples, the images looked identical to the training data. Do you observe something similar in your experiments?\n\nAlso, the interpolation experiments are interesting. It seems that the proposed method implicitly interpolates along the Fischer metric rather than the Euclidean metric. Some discussion on this might be illuminating. ", "OTHER_KEYS": "Suraj Srinivas"}, {"IS_META_REVIEW": true, "comments": "The authors propose to sample from VAEs through a Markov chain [z_t ~ q(z|x=x_{t-1}), x_t ~ p(x|z=z_t)]. The paper uses confusing notation, oversells the novelty, ignoring some relevant previous results. The qualitative difference between regular sampling and this Gibbs chain is not very convincing, judging from the figures. It would be a great workshop paper (perhaps more), if the authors fix the notation, fix the discussion to related work, and produce more convincing (perhaps simply upscaled?) figures.\n\nComments: \n - Rezende et al's (2014) original VAE paper already discusses the Markov chain, which is ignored in this paper\n - Notation is nonstandard / confusing. At page 1, it\u2019s unclear what the authors mean with \u201cp(x|z) which is approximated as q(x|z)\u201d.\n- It\u2019s also not clear what\u2019s meant with q(z). At page 2, q(z) is called the learned distribution, while p(z) can in general also be a learned distribution.\n- It\u2019s not true that it\u2019s impossible to draw samples from q(z): one can sample x ~ q(x) from the dataset, then draw z ~ q(z|x).\n- It's not explained whether the analysis only applies to continuous observed spaces, or also discrete observed spaces\n- Figures 3 and 4 are not very convincing."}, {"DATE": "06 Feb 2017", "TITLE": "ICLR committee final decision", "IS_META_REVIEW": false, "comments": "This approach taken in this paper is topical, especially since the importance of sampling and generating diverse samples is increasingly discussed in work on generative models. There were several concerns from reviewers, in three areas particularly: connection and comparison to related work; lack of clarity and understanding of the paper; experiments that are not sufficiently convincing. These have been addressed to some extent by the authors, discussing in more detail the related work, especially in connection to Rezende et al., and GSN of Bengio et al., and with improved figures. But these points are still of concern especially in terms of assessing sample diversity in relation to much of the recent work on richer variational posterior methods and other techniques. For these reasons, the paper is not yet ready for acceptance at this years conference.", "OTHER_KEYS": "ICLR 2017 pcs"}, {"DATE": "13 Jan 2017", "TITLE": "Updated paper", "IS_META_REVIEW": false, "comments": "We have updated our paper to include changes that reflect comments made by the reviewers. A PDF document detailing our changes  may be found at: ", "OTHER_KEYS": "Antonia Creswell"}, {"TITLE": "No Title", "OTHER_KEYS": "ICLR 2017 conference AnonReviewer3", "comments": "This paper attempts to learn a Markov chain to estimate a probability distribution over latent variables Z, such that P(X | Z) can be eased to generate samples from a data distribution.\n\nThe paper in its current form is not acceptable due to the following reasons:\n1. No quantitative evaluation. The authors do include samples from the generative model, which however are insufficient to judge performance of the model. See comment 2.\n2. The description of the model is very unclear. I had to indulge in a lot of charity to interpret what the authors \"must be doing\". What does Q(Z) mean? Does it mean the true posterior P(Z | X) ? What is the generative model here? Typically, it's P(Z)P(X|Z). VAEs use a variational approximation Q(Z | X) to the true posterior P(Z | X). Are you trying to say that your model can sample from the true posterior P(Z | X)?\n\nComments:\n1. Using additive noise in the input does not seem like a reasonable idea. Any justification of why this is being done?\n2. Approaches which learn transition operators are usually very amenable to data augmentation-based semi-supervised learning. I encourage the authors to improve their paper by testing their model on semi-supervised learning benchmarks.", "IS_META_REVIEW": false, "RECOMMENDATION": 3, "DATE": "19 Dec 2016", "REVIEWER_CONFIDENCE": 5}, {"TITLE": "Review", "OTHER_KEYS": "ICLR 2017 conference AnonReviewer2", "comments": "The authors propose to sample from VAEs through a Markov chain [z_t ~ q(z|x=x_{t-1}), x_t ~ p(x|z=z_t)]. The paper uses confusing notation, oversells the novelty, ignoring some relevant previous results. The qualitative difference between regular sampling and this Gibbs chain is not very convincing, judging from the figures. It would be a great workshop paper (perhaps more), if the authors fix the notation, fix the discussion to related work, and produce more convincing (perhaps simply upscaled?) figures.\n\nComments: \n - Rezende et al's (2014) original VAE paper already discusses the Markov chain, which is ignored in this paper\n - Notation is nonstandard / confusing. At page 1, it\u2019s unclear what the authors mean with \u201cp(x|z) which is approximated as q(x|z)\u201d.\n- It\u2019s also not clear what\u2019s meant with q(z). At page 2, q(z) is called the learned distribution, while p(z) can in general also be a learned distribution.\n- It\u2019s not true that it\u2019s impossible to draw samples from q(z): one can sample x ~ q(x) from the dataset, then draw z ~ q(z|x).\n- It's not explained whether the analysis only applies to continuous observed spaces, or also discrete observed spaces\n- Figures 3 and 4 are not very convincing.\n", "IS_META_REVIEW": false, "RECOMMENDATION": 3, "DATE": "19 Dec 2016", "REVIEWER_CONFIDENCE": 4}, {"TITLE": "Review", "OTHER_KEYS": "ICLR 2017 conference AnonReviewer1", "comments": "The authors argues that the standard ancestral sampling from stochastic autoencoders (such as the Variational Autoencoder and the Adversarial\nAutoencoder) imposes the overly-restrictive constraint that the encoder distribution must marginally match the latent variable prior. They propose, as an alternative, a Markov Chain Monte Carlo approach that avoids the need to specify a simple parametric form for the prior.\n\nThe paper is not clearly written. Most critically, the notation the authors use is either deeply flawed, or there are simple misunderstanding with respect to the manipulations of probability distributions. For example, the authors seem to suggest that both distributions Q(Z|X) and Q(X|Z) are parametrized. For this to be true the model must either be trivially simple, or an energy-based model. There is no indication that they are speaking of an energy-based model. Another example of possible confusion is the statement that the ratio of distributions Q(Z|X)/P(Z) = 1. I believe this is supposed to be a ratio of marginals: Q(Z)/P(X) = 1. Overall, it seems like there is a confusion of what Q and P represent. The standard notation used in VAEs is to use P to represent the decoder distribution and\nQ to represent the encoder distribution. This seems not to be how the authors are using these terms. Nor does it seem like there is a single consistent interpretation. \n\nThe empirical results consist entirely of qualitative results (samples and reconstructions) from a single dataset (CelebA). The samples are also not at all up to the quality of the SOTA models. The interpolations shown in Figures 1 and 3 both seems to look like interpolation in pixel space for both the VAE model and the proposed DVAE. \n", "IS_META_REVIEW": false, "RECOMMENDATION": 3, "DATE": "17 Dec 2016", "REVIEWER_CONFIDENCE": 4}, {"DATE": "09 Dec 2016", "TITLE": "Question", "IS_META_REVIEW": false, "comments": "", "OTHER_KEYS": "ICLR 2017 conference AnonReviewer3"}, {"DATE": "08 Dec 2016", "TITLE": "Prior art", "IS_META_REVIEW": false, "comments": "While you cite Rezende et al. 2014 when referring to VAEs, you claim the main contribution of your work is the generation of posterior samples from a Markov Chain. However, Rezende et al. 2014 presented a very similar idea. Let me quote them directly:\n\nWe do not integrate over the missing\nvalues, but use a procedure that simulates a Markov\nchain that we show converges to the true marginal distribution\nof missing given observed pixels.\n\n-- Section 5.4\n\nImage completion can be approximatively achieved by\na simple iterative procedure which consists of (i) initializing\nthe non-observed pixels with random values;\n(ii) sampling from the recognition distribution given\nthe resulting image; (iii) reconstruct the image given\nthe sample from the recognition model; (iv) iterate the\nprocedure.\n\n-- Appendix F\n\nHow is this procedure different from your main contribution? I mean, they motivate with missing data imputation and start in a different way, but the main loop seems the same. Even if there is a significant difference between the procedures, I believe this should be addressed in the paper. I also suggest taking a closer look at appendix F, they provide some proofs which seem relevant to your work.\n", "OTHER_KEYS": "Pedro Tabacof"}, {"DATE": "08 Nov 2016", "TITLE": "Novelty of samples?", "IS_META_REVIEW": false, "comments": "How are the novelty of samples affected as more samples are generated from the Markov Chain? I played around with a similar idea and found that after about 6-7 Monte Carlo samples, the images looked identical to the training data. Do you observe something similar in your experiments?\n\nAlso, the interpolation experiments are interesting. It seems that the proposed method implicitly interpolates along the Fischer metric rather than the Euclidean metric. Some discussion on this might be illuminating. ", "OTHER_KEYS": "Suraj Srinivas"}], "authors": "Antonia Creswell, Kai Arulkumaran, Anil Anthony Bharath", "accepted": false, "id": "789"}