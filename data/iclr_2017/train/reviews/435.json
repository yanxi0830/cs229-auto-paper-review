{"conference": "ICLR 2017 conference submission", "title": "SGDR: Stochastic Gradient Descent with Warm Restarts", "abstract": "Restart techniques are common in gradient-free optimization to deal with multimodal functions. Partial warm restarts are also gaining popularity in gradient-based optimization to improve the rate of convergence in accelerated gradient schemes to deal with ill-conditioned functions. In this paper, we propose a simple warm restart technique for stochastic gradient descent to improve its anytime performance when training deep neural networks. We empirically study its performance on the CIFAR-10 and CIFAR-100 datasets,    where we demonstrate new state-of-the-art results at 3.14\\% and 16.21\\%, respectively. We also demonstrate its advantages on a dataset of EEG recordings and on a downsampled version of the ImageNet dataset. Our source code is available at \\\\ \\url{", "histories": [], "reviews": [{"IS_META_REVIEW": true, "comments": "This paper describes a way to speed up convergence through sudden increases of otherwise monotonically decreasing learning rates. Several techniques are presented in a clear way and parameterized method is proposed and evaluated on the CIFAR task. The concept is easy to understand and the authors chose state-of-the-art models to show the performance of their algorithm. The relevance of these results goes beyond image classification.\n\n\nPros:\n\n- Simple and effective method to improve convergence\n- Good evaluation on well known database\n\n\nCons:\n\n- Connection of introduction and topic of the paper is a bit unclear\n- Fig 2, 4 and 5 are hard to read. Lines are out of bounds and maybe only the best setting for T_0 and T_mult would be clearer. The baseline also doesn't seem to converge\n\nRemarks:\nAn loss surface for T_0 against T_mult would be very helpful. Also understanding the relationship of network depth and the performance of this method would add value to this analysis."}, {"DATE": "06 Feb 2017", "TITLE": "ICLR committee final decision", "IS_META_REVIEW": false, "comments": "All reviewers viewed the paper favourably, with the only criticism being that seeing how the method complements other approaches (momentum, Adam) would make the paper more complete. We encourage the authors to include such a comparison in the camera ready version of their paper.", "OTHER_KEYS": "ICLR 2017 pcs"}, {"DATE": "14 Jan 2017", "TITLE": "Rebuttal", "IS_META_REVIEW": false, "comments": "We thank all reviewers for their positive evaluation and their valuable comments. We've uploaded a revision to address the issues raised and briefly reply to the reviewers' concerns here.\n\nExperiments on additional benchmarks \n==============================\n\nIn order to address the concerns of AnonReviewer4 about our method's generality, we added two more benchmarks to the main paper.\n\n1. We had already included additional results for another domain in the appendix of the original submission. That domain is motor-control decoding based on EEG data, which, due to the large noise present in brain signals, is very different from visual object recognition in general, and CIFAR in particular. We realize that it was not the best decision to only mention those results in the supplementary material, and we have now moved them to the main paper (new Section 4.4). In fact, our work is in part motivated and funded by a project aimed at accelerating the processing of this sort of brain data (see acknowledgments).\n\n2. We've now added a new experiment on a new downsampled version of the ImageNet dataset (new Section 4.5), which is much harder than the CIFAR benchmark because there are 1000 classes and because the target concept often only occupies a small part of the image. Due to the computational expense of training on 1 million images, these results are very preliminary -- e.g., we didn't tune hyperparameters yet. While the dataset is difficult for both the default learning rate schedule and SGDR, SGDR achieved much better results. An interpretation of this might be that, while the initial learning rate seems to be very important, SGDR reduces the problem of improper learning rate selection by quickly annealing from the initial learning rate to 0.\n\nWe would also like to point out that the simplicity and generality of SGDR let Huang et al use it to develop snapshot ensembles (", "OTHER_KEYS": "Ilya Loshchilov"}, {"TITLE": "Great trick worth publishing, but is there enough material for a full paper?", "OTHER_KEYS": "ICLR 2017 conference AnonReviewer4", "comments": "This heuristic to improve gradient descent in image classification is simple and effective, but this looks to me more like a workshop track paper. Demonstration of the algorithm is limited to one task (CIFAR) and there is no theory to support it, so we do not know how it will generalize on other tasks\n\nWorking on DNNs for NLP, I find some observations in the paper opposite to my own experience. In particular, with architectures that combine a wide variety of layer types (embedding, RNN, CNN, gating), I found that ADAM-type techniques far outperform simple SGD with momentum, as they save searching for the right learning rate for each type of layer. But ADAM only works well combined with Poliak averaging, as it fluctuates a lot from one batch to another.\n\nRevision:\n-  the authors substantially improved the contents of the paper, including experiments on another set than Cifar\n-  the workshop track has been modified to breakthrough work, so my recommendation for it is not longer appropriate\nI have therefore improved my rating", "IS_META_REVIEW": false, "RECOMMENDATION": 7, "DATE": "20 Dec 2016 (modified: 20 Jan 2017)", "REVIEWER_CONFIDENCE": 3}, {"TITLE": "No Title", "OTHER_KEYS": "ICLR 2017 conference AnonReviewer3", "comments": "This an interesting investigation into learning rate schedules, bringing in the idea of restarts, often overlooked in deep learning. The paper does a thorough study on non-trivial datasets, and while the outcomes are not fully conclusive, the results are very good and the approach is novel enough to warrant publication. \n\nI thank the authors for revising the paper based on my concerns.\n\nTypos:\n- \u201cflesh\u201d -> \u201cflush\u201d", "IS_META_REVIEW": false, "RECOMMENDATION": 7, "DATE": "15 Dec 2016", "REVIEWER_CONFIDENCE": 4}, {"TITLE": "An effective method to improve convergence of neural network training", "OTHER_KEYS": "ICLR 2017 conference AnonReviewer1", "comments": "This paper describes a way to speed up convergence through sudden increases of otherwise monotonically decreasing learning rates. Several techniques are presented in a clear way and parameterized method is proposed and evaluated on the CIFAR task. The concept is easy to understand and the authors chose state-of-the-art models to show the performance of their algorithm. The relevance of these results goes beyond image classification.\n\n\nPros:\n\n- Simple and effective method to improve convergence\n- Good evaluation on well known database\n\n\nCons:\n\n- Connection of introduction and topic of the paper is a bit unclear\n- Fig 2, 4 and 5 are hard to read. Lines are out of bounds and maybe only the best setting for T_0 and T_mult would be clearer. The baseline also doesn't seem to converge\n\nRemarks:\nAn loss surface for T_0 against T_mult would be very helpful. Also understanding the relationship of network depth and the performance of this method would add value to this analysis.\n", "IS_META_REVIEW": false, "RECOMMENDATION": 7, "DATE": "15 Dec 2016", "REVIEWER_CONFIDENCE": 5}, {"DATE": "03 Dec 2016", "TITLE": "CIFAR evaluation", "IS_META_REVIEW": false, "comments": "", "OTHER_KEYS": "ICLR 2017 conference AnonReviewer1"}, {"DATE": "02 Dec 2016", "TITLE": "restarts versus annealing", "IS_META_REVIEW": false, "comments": "", "OTHER_KEYS": "ICLR 2017 conference AnonReviewer3"}, {"IS_META_REVIEW": true, "comments": "This paper describes a way to speed up convergence through sudden increases of otherwise monotonically decreasing learning rates. Several techniques are presented in a clear way and parameterized method is proposed and evaluated on the CIFAR task. The concept is easy to understand and the authors chose state-of-the-art models to show the performance of their algorithm. The relevance of these results goes beyond image classification.\n\n\nPros:\n\n- Simple and effective method to improve convergence\n- Good evaluation on well known database\n\n\nCons:\n\n- Connection of introduction and topic of the paper is a bit unclear\n- Fig 2, 4 and 5 are hard to read. Lines are out of bounds and maybe only the best setting for T_0 and T_mult would be clearer. The baseline also doesn't seem to converge\n\nRemarks:\nAn loss surface for T_0 against T_mult would be very helpful. Also understanding the relationship of network depth and the performance of this method would add value to this analysis."}, {"DATE": "06 Feb 2017", "TITLE": "ICLR committee final decision", "IS_META_REVIEW": false, "comments": "All reviewers viewed the paper favourably, with the only criticism being that seeing how the method complements other approaches (momentum, Adam) would make the paper more complete. We encourage the authors to include such a comparison in the camera ready version of their paper.", "OTHER_KEYS": "ICLR 2017 pcs"}, {"DATE": "14 Jan 2017", "TITLE": "Rebuttal", "IS_META_REVIEW": false, "comments": "We thank all reviewers for their positive evaluation and their valuable comments. We've uploaded a revision to address the issues raised and briefly reply to the reviewers' concerns here.\n\nExperiments on additional benchmarks \n==============================\n\nIn order to address the concerns of AnonReviewer4 about our method's generality, we added two more benchmarks to the main paper.\n\n1. We had already included additional results for another domain in the appendix of the original submission. That domain is motor-control decoding based on EEG data, which, due to the large noise present in brain signals, is very different from visual object recognition in general, and CIFAR in particular. We realize that it was not the best decision to only mention those results in the supplementary material, and we have now moved them to the main paper (new Section 4.4). In fact, our work is in part motivated and funded by a project aimed at accelerating the processing of this sort of brain data (see acknowledgments).\n\n2. We've now added a new experiment on a new downsampled version of the ImageNet dataset (new Section 4.5), which is much harder than the CIFAR benchmark because there are 1000 classes and because the target concept often only occupies a small part of the image. Due to the computational expense of training on 1 million images, these results are very preliminary -- e.g., we didn't tune hyperparameters yet. While the dataset is difficult for both the default learning rate schedule and SGDR, SGDR achieved much better results. An interpretation of this might be that, while the initial learning rate seems to be very important, SGDR reduces the problem of improper learning rate selection by quickly annealing from the initial learning rate to 0.\n\nWe would also like to point out that the simplicity and generality of SGDR let Huang et al use it to develop snapshot ensembles (", "OTHER_KEYS": "Ilya Loshchilov"}, {"TITLE": "Great trick worth publishing, but is there enough material for a full paper?", "OTHER_KEYS": "ICLR 2017 conference AnonReviewer4", "comments": "This heuristic to improve gradient descent in image classification is simple and effective, but this looks to me more like a workshop track paper. Demonstration of the algorithm is limited to one task (CIFAR) and there is no theory to support it, so we do not know how it will generalize on other tasks\n\nWorking on DNNs for NLP, I find some observations in the paper opposite to my own experience. In particular, with architectures that combine a wide variety of layer types (embedding, RNN, CNN, gating), I found that ADAM-type techniques far outperform simple SGD with momentum, as they save searching for the right learning rate for each type of layer. But ADAM only works well combined with Poliak averaging, as it fluctuates a lot from one batch to another.\n\nRevision:\n-  the authors substantially improved the contents of the paper, including experiments on another set than Cifar\n-  the workshop track has been modified to breakthrough work, so my recommendation for it is not longer appropriate\nI have therefore improved my rating", "IS_META_REVIEW": false, "RECOMMENDATION": 7, "DATE": "20 Dec 2016 (modified: 20 Jan 2017)", "REVIEWER_CONFIDENCE": 3}, {"TITLE": "No Title", "OTHER_KEYS": "ICLR 2017 conference AnonReviewer3", "comments": "This an interesting investigation into learning rate schedules, bringing in the idea of restarts, often overlooked in deep learning. The paper does a thorough study on non-trivial datasets, and while the outcomes are not fully conclusive, the results are very good and the approach is novel enough to warrant publication. \n\nI thank the authors for revising the paper based on my concerns.\n\nTypos:\n- \u201cflesh\u201d -> \u201cflush\u201d", "IS_META_REVIEW": false, "RECOMMENDATION": 7, "DATE": "15 Dec 2016", "REVIEWER_CONFIDENCE": 4}, {"TITLE": "An effective method to improve convergence of neural network training", "OTHER_KEYS": "ICLR 2017 conference AnonReviewer1", "comments": "This paper describes a way to speed up convergence through sudden increases of otherwise monotonically decreasing learning rates. Several techniques are presented in a clear way and parameterized method is proposed and evaluated on the CIFAR task. The concept is easy to understand and the authors chose state-of-the-art models to show the performance of their algorithm. The relevance of these results goes beyond image classification.\n\n\nPros:\n\n- Simple and effective method to improve convergence\n- Good evaluation on well known database\n\n\nCons:\n\n- Connection of introduction and topic of the paper is a bit unclear\n- Fig 2, 4 and 5 are hard to read. Lines are out of bounds and maybe only the best setting for T_0 and T_mult would be clearer. The baseline also doesn't seem to converge\n\nRemarks:\nAn loss surface for T_0 against T_mult would be very helpful. Also understanding the relationship of network depth and the performance of this method would add value to this analysis.\n", "IS_META_REVIEW": false, "RECOMMENDATION": 7, "DATE": "15 Dec 2016", "REVIEWER_CONFIDENCE": 5}, {"DATE": "03 Dec 2016", "TITLE": "CIFAR evaluation", "IS_META_REVIEW": false, "comments": "", "OTHER_KEYS": "ICLR 2017 conference AnonReviewer1"}, {"DATE": "02 Dec 2016", "TITLE": "restarts versus annealing", "IS_META_REVIEW": false, "comments": "", "OTHER_KEYS": "ICLR 2017 conference AnonReviewer3"}], "authors": "Ilya Loshchilov, Frank Hutter", "accepted": true, "id": "435"}