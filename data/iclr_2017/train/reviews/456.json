{"conference": "ICLR 2017 conference submission", "title": "Central Moment Discrepancy (CMD) for Domain-Invariant Representation Learning", "abstract": "The learning of domain-invariant representations in the context of domain adaptation with neural networks is considered. We propose a new regularization method that minimizes the  domain-specific latent feature representations directly in the hidden activation space. Although some standard distribution matching approaches exist that can be interpreted as the matching of weighted sums of moments, e.g. Maximum Mean Discrepancy (MMD), an explicit order-wise matching of higher order moments has not been considered before. We propose to match the higher order central moments of probability distributions by means of order-wise moment differences. Our model does not require computationally expensive distance and kernel matrix computations. We utilize the equivalent representation of probability distributions by moment sequences to define a new distance function, called Central Moment Discrepancy (CMD). We prove that CMD is a metric on the set of probability distributions on a compact interval. We further prove that convergence of probability distributions on compact intervals w.r.t. the new metric implies convergence in distribution of the respective random variables. We test our approach on two different benchmark data sets for object recognition (Office) and sentiment analysis of product reviews (Amazon reviews). CMD achieves a new state-of-the-art performance on most domain adaptation tasks of Office and outperforms networks trained with MMD, Variational Fair Autoencoders and Domain Adversarial Neural Networks on Amazon reviews. In addition, a post-hoc parameter sensitivity analysis shows that the new approach is stable w. r. t. parameter changes in a certain interval. The source code of the experiments is publicly available.", "histories": [], "reviews": [{"IS_META_REVIEW": true, "comments": "Variational auto-encoders, adversarial networks, and kernel scoring rules like MMD have recently gained popularity as methods for learning directed generative models and for other applications like domain adaptation. This paper gives an additional method along the scoring rules direction that uses the matching of central moments to match two probability distributions. The technique is simple, and in the case of domain adaptation, highly effective.\n\nCMD seems like a very nice and straightforward solution to the domain adaptation problem. The method is computationally straightforward to implement, and seems quite stable with respect to the tuning parameters when compared to MMD. I was skeptical reading through this, especially given the fact that you only use K=5 in your experiments, but the results seem quite good. The natural question that I have now is: how will this method do in training generative models? This is beyond the scope of this paper, but it\u2019s the lowest hanging fruit.\n\nBelow I give more detailed feedback.\n\nOne way to speed up MMD is to use a random Fourier basis as was done in \u201cFastmmd: Ensemble of circular discrepancy for efficient two-sample test\u201d by Zhao and Meng, 2015. There are also linear time estimators, e.g., in \u201cA Kernel Two-Sample Test\u201c by Gretton et al., 2012. I don\u2019t think you need to compare against these approaches since you compare to the full MMD, but they should be cited.\n\nThe paper \u201cGenerative Models and Model Criticism via Optimized Maximum Mean Discrepancy\u201d by Sutherland et al. submitted to ICLR 2017 as well, discusses techniques for optimizing the kernel used in MMD and is worth citing in section 3.\n\nHow limiting is the assumption that the distribution has independent marginals?\n\nThe sample complexity of MMD depends heavily on the dimensionality of the input space - do you have any intuitions about the sample complexity of CMD? It seems like it's relatively insensitive based on the results in Figure 4, but I would be surprised if this were the case with 10,000 hidden units. I mainly ask this because with generative models, the output space can be quite high-dimensional.\n\nI\u2019m concerned that the central moments won\u2019t be numerically stable at higher orders when backpropagating. This doesn\u2019t seem to be a problem in the experimental results, but perhaps the authors could comment a bit on this? I\u2019m referring to the fact that ck(X) can be very large for k >= 3. Proposition 1 alleviates my concerns that the overall objective is unstable, I\u2019m referring specifically to the individual terms within.\n\nFigure 3 is rather cluttered, and aside from the mouse class it\u2019s not clear to me from the visualization that the CMD regularizer is actually helping. It would be useful to remove some of the classes for the purpose of visualization.\n\nI would like some clarification about the natural geometric interpretations of K=5. Do you mean that the moments up to K=5 have been well-studied? Do you have any references for this? Why does K >= 6 not have a natural geometric interpretation?\n\nFigure 4 should have a legend"}, {"DATE": "06 Feb 2017", "TITLE": "ICLR committee final decision", "IS_META_REVIEW": false, "comments": "The proposed Central Moment Discrepancy criterion is well-described and supported in this paper. Its performance on domain adaptation tasks is good as well. The reviewers had several good comments and suggestions and the authors have taken most of these into account and improved the paper considerably. The paper thus makes a nice contribution to the distribution matching literature and toolbox.", "OTHER_KEYS": "ICLR 2017 pcs"}, {"TITLE": "Good work with some limitations", "OTHER_KEYS": "ICLR 2017 conference AnonReviewer1", "comments": "The work introduces a new regularization for learning domain-invariant representations with neural networks. The regularization aims at matching the higher order central moments of the hidden activations of the NNs of the source and target domain. The authors compared the proposed method vs MMD and two state-of-art NN domain adaptation algorithms on the Amazon review and office datasets, and showed comparable performance. \n\nThe idea proposed is simple and straightforward, and the empirical results suggest that it is quite effective. The biggest limitation I can see with the proposed method is the assumption that the hidden activations are independently distributed. For example, this assumption will clearly be violated for the hidden activations of convolutional layers, where neighboring activations are dependent. I guess this is why the authors start with the output of dense layers for the image dataset. Do the authors have insight on if it is beneficial to start adaptation from lower level? If so, do the authors have insight on how to relax the assumption? In these scenarios, if MMD has an advantage as it does not make this assumption? \n\nFigure 3 does not seems to clearly support the boost of performance shown in table 2. The only class where the new regularization brings the source and target domain closer seem to be the mouse class pointed by the authors. Is the performance improvement only coming from this single class? ", "IS_META_REVIEW": false, "RECOMMENDATION": 6, "DATE": "19 Dec 2016", "REVIEWER_CONFIDENCE": 4}, {"TITLE": "CMD for distribution matching.", "OTHER_KEYS": "ICLR 2017 conference AnonReviewer3", "comments": "This paper proposed a new metric central moment discrepancy (CMD) for matching two distributions, with applications to domain adaptation.  Compared to a more well-known variant, MMD, CMD has the benefit of not over penalizing the mean, and therefore can focus more on the shape of distribution around the center.\n\nIn terms of discriminative power (the ability to tell two distributions apart), MMD and CMD should be equivalent, but in practice I can understand that CMD may be better as MMD tries to match the raw moments which may over penalize data that are not zero centered.\n\nIn the paper CMD is used only up to Kth order, and not all the central moments are used, but rather only the diagonal entries are considered in the CMD objective, I think this is mostly motivated for computation efficiency.  A natural comparison with MMD therefore can be made, by also explicitly include raw moments up to Kth order.  Another thing to compare against is to include all moments, not just the diagonal terms, in the objective.  This is computationally expensive, but can be done for e.g. 1st and 2nd orders.\n\nSince the experiments only compare CMD in the above form with kernelized MMD, the claim that explicit moment matching is helpful is not very well supported.  To make this a solid claim CMD should be compared against MMD with explicit raw moments.\n\nThe claim that the kernel parameter in MMD is hard to tune and CMD does not have such parameters only applies to kernel MMD, not explicit MMD.  For kernel MMD, there are also studies on how to set these parameters, for example:\n\nSriperumbudur et al.  Kernel choice and classifiability for rkhs embeddings of probability distributions.\nGretton et al.  A kernel two-sample test.\n\nand also using multiple kernels (Li et al. 2015) which removes the need to tune them.  Tuning the beta directly like done in this paper is usually not the way MMD is tuned.  At least simple heuristics like dividing |x-y|^2 by dimensionality or mean pairwise distance first should be applied first before trying beta in the way done in this paper.\n\nOverall I think CMD could be better than MMD, and could have applications in many domains.  But it also has the problem of not easily kernelizable (you can argue this both ways though).  The experiments demonstrating that CMD is better could be done more convincinly.\n\n", "IS_META_REVIEW": false, "RECOMMENDATION": 7, "DATE": "17 Dec 2016", "REVIEWER_CONFIDENCE": 4}, {"TITLE": "A very simple method with impressive results", "OTHER_KEYS": "ICLR 2017 conference AnonReviewer2", "comments": "Variational auto-encoders, adversarial networks, and kernel scoring rules like MMD have recently gained popularity as methods for learning directed generative models and for other applications like domain adaptation. This paper gives an additional method along the scoring rules direction that uses the matching of central moments to match two probability distributions. The technique is simple, and in the case of domain adaptation, highly effective.\n\nCMD seems like a very nice and straightforward solution to the domain adaptation problem. The method is computationally straightforward to implement, and seems quite stable with respect to the tuning parameters when compared to MMD. I was skeptical reading through this, especially given the fact that you only use K=5 in your experiments, but the results seem quite good. The natural question that I have now is: how will this method do in training generative models? This is beyond the scope of this paper, but it\u2019s the lowest hanging fruit.\n\nBelow I give more detailed feedback.\n\nOne way to speed up MMD is to use a random Fourier basis as was done in \u201cFastmmd: Ensemble of circular discrepancy for efficient two-sample test\u201d by Zhao and Meng, 2015. There are also linear time estimators, e.g., in \u201cA Kernel Two-Sample Test\u201c by Gretton et al., 2012. I don\u2019t think you need to compare against these approaches since you compare to the full MMD, but they should be cited.\n\nThe paper \u201cGenerative Models and Model Criticism via Optimized Maximum Mean Discrepancy\u201d by Sutherland et al. submitted to ICLR 2017 as well, discusses techniques for optimizing the kernel used in MMD and is worth citing in section 3.\n\nHow limiting is the assumption that the distribution has independent marginals?\n\nThe sample complexity of MMD depends heavily on the dimensionality of the input space - do you have any intuitions about the sample complexity of CMD? It seems like it's relatively insensitive based on the results in Figure 4, but I would be surprised if this were the case with 10,000 hidden units. I mainly ask this because with generative models, the output space can be quite high-dimensional.\n\nI\u2019m concerned that the central moments won\u2019t be numerically stable at higher orders when backpropagating. This doesn\u2019t seem to be a problem in the experimental results, but perhaps the authors could comment a bit on this? I\u2019m referring to the fact that ck(X) can be very large for k >= 3. Proposition 1 alleviates my concerns that the overall objective is unstable, I\u2019m referring specifically to the individual terms within.\n\nFigure 3 is rather cluttered, and aside from the mouse class it\u2019s not clear to me from the visualization that the CMD regularizer is actually helping. It would be useful to remove some of the classes for the purpose of visualization.\n\nI would like some clarification about the natural geometric interpretations of K=5. Do you mean that the moments up to K=5 have been well-studied? Do you have any references for this? Why does K >= 6 not have a natural geometric interpretation?\n\nFigure 4 should have a legend", "IS_META_REVIEW": false, "RECOMMENDATION": 9, "DATE": "17 Dec 2016", "REVIEWER_CONFIDENCE": 5}, {"DATE": "08 Dec 2016", "TITLE": "Sensitivity w.r.t. number of hidden nodes", "IS_META_REVIEW": false, "comments": "", "OTHER_KEYS": "ICLR 2017 conference AnonReviewer1"}, {"DATE": "07 Dec 2016", "TITLE": "explicit high-order moment matching and computation cost", "IS_META_REVIEW": false, "comments": "", "OTHER_KEYS": "ICLR 2017 conference AnonReviewer3"}, {"DATE": "02 Dec 2016", "TITLE": "Why central moments?", "IS_META_REVIEW": false, "comments": "", "OTHER_KEYS": "ICLR 2017 conference AnonReviewer2"}, {"IS_META_REVIEW": true, "comments": "Variational auto-encoders, adversarial networks, and kernel scoring rules like MMD have recently gained popularity as methods for learning directed generative models and for other applications like domain adaptation. This paper gives an additional method along the scoring rules direction that uses the matching of central moments to match two probability distributions. The technique is simple, and in the case of domain adaptation, highly effective.\n\nCMD seems like a very nice and straightforward solution to the domain adaptation problem. The method is computationally straightforward to implement, and seems quite stable with respect to the tuning parameters when compared to MMD. I was skeptical reading through this, especially given the fact that you only use K=5 in your experiments, but the results seem quite good. The natural question that I have now is: how will this method do in training generative models? This is beyond the scope of this paper, but it\u2019s the lowest hanging fruit.\n\nBelow I give more detailed feedback.\n\nOne way to speed up MMD is to use a random Fourier basis as was done in \u201cFastmmd: Ensemble of circular discrepancy for efficient two-sample test\u201d by Zhao and Meng, 2015. There are also linear time estimators, e.g., in \u201cA Kernel Two-Sample Test\u201c by Gretton et al., 2012. I don\u2019t think you need to compare against these approaches since you compare to the full MMD, but they should be cited.\n\nThe paper \u201cGenerative Models and Model Criticism via Optimized Maximum Mean Discrepancy\u201d by Sutherland et al. submitted to ICLR 2017 as well, discusses techniques for optimizing the kernel used in MMD and is worth citing in section 3.\n\nHow limiting is the assumption that the distribution has independent marginals?\n\nThe sample complexity of MMD depends heavily on the dimensionality of the input space - do you have any intuitions about the sample complexity of CMD? It seems like it's relatively insensitive based on the results in Figure 4, but I would be surprised if this were the case with 10,000 hidden units. I mainly ask this because with generative models, the output space can be quite high-dimensional.\n\nI\u2019m concerned that the central moments won\u2019t be numerically stable at higher orders when backpropagating. This doesn\u2019t seem to be a problem in the experimental results, but perhaps the authors could comment a bit on this? I\u2019m referring to the fact that ck(X) can be very large for k >= 3. Proposition 1 alleviates my concerns that the overall objective is unstable, I\u2019m referring specifically to the individual terms within.\n\nFigure 3 is rather cluttered, and aside from the mouse class it\u2019s not clear to me from the visualization that the CMD regularizer is actually helping. It would be useful to remove some of the classes for the purpose of visualization.\n\nI would like some clarification about the natural geometric interpretations of K=5. Do you mean that the moments up to K=5 have been well-studied? Do you have any references for this? Why does K >= 6 not have a natural geometric interpretation?\n\nFigure 4 should have a legend"}, {"DATE": "06 Feb 2017", "TITLE": "ICLR committee final decision", "IS_META_REVIEW": false, "comments": "The proposed Central Moment Discrepancy criterion is well-described and supported in this paper. Its performance on domain adaptation tasks is good as well. The reviewers had several good comments and suggestions and the authors have taken most of these into account and improved the paper considerably. The paper thus makes a nice contribution to the distribution matching literature and toolbox.", "OTHER_KEYS": "ICLR 2017 pcs"}, {"TITLE": "Good work with some limitations", "OTHER_KEYS": "ICLR 2017 conference AnonReviewer1", "comments": "The work introduces a new regularization for learning domain-invariant representations with neural networks. The regularization aims at matching the higher order central moments of the hidden activations of the NNs of the source and target domain. The authors compared the proposed method vs MMD and two state-of-art NN domain adaptation algorithms on the Amazon review and office datasets, and showed comparable performance. \n\nThe idea proposed is simple and straightforward, and the empirical results suggest that it is quite effective. The biggest limitation I can see with the proposed method is the assumption that the hidden activations are independently distributed. For example, this assumption will clearly be violated for the hidden activations of convolutional layers, where neighboring activations are dependent. I guess this is why the authors start with the output of dense layers for the image dataset. Do the authors have insight on if it is beneficial to start adaptation from lower level? If so, do the authors have insight on how to relax the assumption? In these scenarios, if MMD has an advantage as it does not make this assumption? \n\nFigure 3 does not seems to clearly support the boost of performance shown in table 2. The only class where the new regularization brings the source and target domain closer seem to be the mouse class pointed by the authors. Is the performance improvement only coming from this single class? ", "IS_META_REVIEW": false, "RECOMMENDATION": 6, "DATE": "19 Dec 2016", "REVIEWER_CONFIDENCE": 4}, {"TITLE": "CMD for distribution matching.", "OTHER_KEYS": "ICLR 2017 conference AnonReviewer3", "comments": "This paper proposed a new metric central moment discrepancy (CMD) for matching two distributions, with applications to domain adaptation.  Compared to a more well-known variant, MMD, CMD has the benefit of not over penalizing the mean, and therefore can focus more on the shape of distribution around the center.\n\nIn terms of discriminative power (the ability to tell two distributions apart), MMD and CMD should be equivalent, but in practice I can understand that CMD may be better as MMD tries to match the raw moments which may over penalize data that are not zero centered.\n\nIn the paper CMD is used only up to Kth order, and not all the central moments are used, but rather only the diagonal entries are considered in the CMD objective, I think this is mostly motivated for computation efficiency.  A natural comparison with MMD therefore can be made, by also explicitly include raw moments up to Kth order.  Another thing to compare against is to include all moments, not just the diagonal terms, in the objective.  This is computationally expensive, but can be done for e.g. 1st and 2nd orders.\n\nSince the experiments only compare CMD in the above form with kernelized MMD, the claim that explicit moment matching is helpful is not very well supported.  To make this a solid claim CMD should be compared against MMD with explicit raw moments.\n\nThe claim that the kernel parameter in MMD is hard to tune and CMD does not have such parameters only applies to kernel MMD, not explicit MMD.  For kernel MMD, there are also studies on how to set these parameters, for example:\n\nSriperumbudur et al.  Kernel choice and classifiability for rkhs embeddings of probability distributions.\nGretton et al.  A kernel two-sample test.\n\nand also using multiple kernels (Li et al. 2015) which removes the need to tune them.  Tuning the beta directly like done in this paper is usually not the way MMD is tuned.  At least simple heuristics like dividing |x-y|^2 by dimensionality or mean pairwise distance first should be applied first before trying beta in the way done in this paper.\n\nOverall I think CMD could be better than MMD, and could have applications in many domains.  But it also has the problem of not easily kernelizable (you can argue this both ways though).  The experiments demonstrating that CMD is better could be done more convincinly.\n\n", "IS_META_REVIEW": false, "RECOMMENDATION": 7, "DATE": "17 Dec 2016", "REVIEWER_CONFIDENCE": 4}, {"TITLE": "A very simple method with impressive results", "OTHER_KEYS": "ICLR 2017 conference AnonReviewer2", "comments": "Variational auto-encoders, adversarial networks, and kernel scoring rules like MMD have recently gained popularity as methods for learning directed generative models and for other applications like domain adaptation. This paper gives an additional method along the scoring rules direction that uses the matching of central moments to match two probability distributions. The technique is simple, and in the case of domain adaptation, highly effective.\n\nCMD seems like a very nice and straightforward solution to the domain adaptation problem. The method is computationally straightforward to implement, and seems quite stable with respect to the tuning parameters when compared to MMD. I was skeptical reading through this, especially given the fact that you only use K=5 in your experiments, but the results seem quite good. The natural question that I have now is: how will this method do in training generative models? This is beyond the scope of this paper, but it\u2019s the lowest hanging fruit.\n\nBelow I give more detailed feedback.\n\nOne way to speed up MMD is to use a random Fourier basis as was done in \u201cFastmmd: Ensemble of circular discrepancy for efficient two-sample test\u201d by Zhao and Meng, 2015. There are also linear time estimators, e.g., in \u201cA Kernel Two-Sample Test\u201c by Gretton et al., 2012. I don\u2019t think you need to compare against these approaches since you compare to the full MMD, but they should be cited.\n\nThe paper \u201cGenerative Models and Model Criticism via Optimized Maximum Mean Discrepancy\u201d by Sutherland et al. submitted to ICLR 2017 as well, discusses techniques for optimizing the kernel used in MMD and is worth citing in section 3.\n\nHow limiting is the assumption that the distribution has independent marginals?\n\nThe sample complexity of MMD depends heavily on the dimensionality of the input space - do you have any intuitions about the sample complexity of CMD? It seems like it's relatively insensitive based on the results in Figure 4, but I would be surprised if this were the case with 10,000 hidden units. I mainly ask this because with generative models, the output space can be quite high-dimensional.\n\nI\u2019m concerned that the central moments won\u2019t be numerically stable at higher orders when backpropagating. This doesn\u2019t seem to be a problem in the experimental results, but perhaps the authors could comment a bit on this? I\u2019m referring to the fact that ck(X) can be very large for k >= 3. Proposition 1 alleviates my concerns that the overall objective is unstable, I\u2019m referring specifically to the individual terms within.\n\nFigure 3 is rather cluttered, and aside from the mouse class it\u2019s not clear to me from the visualization that the CMD regularizer is actually helping. It would be useful to remove some of the classes for the purpose of visualization.\n\nI would like some clarification about the natural geometric interpretations of K=5. Do you mean that the moments up to K=5 have been well-studied? Do you have any references for this? Why does K >= 6 not have a natural geometric interpretation?\n\nFigure 4 should have a legend", "IS_META_REVIEW": false, "RECOMMENDATION": 9, "DATE": "17 Dec 2016", "REVIEWER_CONFIDENCE": 5}, {"DATE": "08 Dec 2016", "TITLE": "Sensitivity w.r.t. number of hidden nodes", "IS_META_REVIEW": false, "comments": "", "OTHER_KEYS": "ICLR 2017 conference AnonReviewer1"}, {"DATE": "07 Dec 2016", "TITLE": "explicit high-order moment matching and computation cost", "IS_META_REVIEW": false, "comments": "", "OTHER_KEYS": "ICLR 2017 conference AnonReviewer3"}, {"DATE": "02 Dec 2016", "TITLE": "Why central moments?", "IS_META_REVIEW": false, "comments": "", "OTHER_KEYS": "ICLR 2017 conference AnonReviewer2"}], "authors": "Werner Zellinger, Thomas Grubinger, Edwin Lughofer, Thomas Natschl\u00e4ger, Susanne Saminger-Platz", "accepted": true, "id": "456"}