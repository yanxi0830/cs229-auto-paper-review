{"conference": "ICLR 2017 conference submission", "title": "A Simple yet Effective Method to Prune Dense Layers of Neural Networks", "abstract": "Neural networks are usually over-parameterized with significant redundancy in the number of required neurons which results in unnecessary computation and memory usage at inference time. One common approach to address this issue is to prune these big networks by removing extra neurons and parameters while maintaining the accuracy. In this paper, we propose NoiseOut, a fully automated pruning algorithm based on the correlation between activations of neurons in the hidden layers. We prove that adding additional output neurons with entirely random targets results into a higher correlation between neurons which makes pruning by NoiseOut even more efficient. Finally, we test our method on various networks and datasets. These experiments exhibit high pruning rates while maintaining the accuracy of the original network.", "histories": [], "reviews": [{"DATE": "06 Feb 2017", "TITLE": "ICLR committee final decision", "IS_META_REVIEW": false, "comments": "all reviewers agree that the paper is not convincing enough at this stage but needs more work to be ready for ICLR (e.g. missing comparisons to other existing methods).", "OTHER_KEYS": "ICLR 2017 pcs"}, {"DATE": "02 Feb 2017", "TITLE": "Some related works", "IS_META_REVIEW": false, "comments": "1) Wen, Wei, et al. \"Learning structured sparsity in deep neural networks.\" Advances in Neural Information Processing Systems. 2016.\n2) Lebedev, Vadim, and Victor Lempitsky. \"Fast convnets using group-wise brain damage.\" Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. 2016.\n3) Alvarez, Jose M., and Mathieu Salzmann. \"Learning the Number of Neurons in Deep Networks.\" Advances in Neural Information Processing Systems. 2016.", "OTHER_KEYS": "(anonymous)"}, {"DATE": "26 Dec 2016", "TITLE": "Possible relevant work not discussed", "IS_META_REVIEW": false, "comments": "This paper misses discussion of 'Diversity Networks' published in ICLR 2016 (", "OTHER_KEYS": "(anonymous)"}, {"TITLE": "Good proof of concept, but more experimental evidence needed", "OTHER_KEYS": "ICLR 2017 conference AnonReviewer3", "comments": "Summary:\nIn this paper, the authors introduce NoiseOut, a way to reduce parameters by pruning neurons from a network. \nThey do this by identifying pairs of neurons produce the most correlated outputs, and replacing the pair by one neuron, and then appropriately adjusting weights.\nThis technique relies on neurons having high correlations however, so they introduce an additional output neuron -- a noise output, which results in the network trying to predict the mean of the noise distribution.\nAs this is a constant, it increases correlation between neurons.\nExperiments test this out on MNIST and SVHN\n\nComments:\nThis is an interesting suggestion on how to prune neurons, but more experiments (on larger datasets) are probably need to be convincing that this is an approach that is guaranteed to work well. \n\nEquation (5) seems to be very straightforwards?\n\nIt seems like that for larger datasets, more noise outputs might have to be added to ensure higher correlations? Is there a downside to this in terms of the overall accuracy?\n\nThe paper is presented clearly, and was definitely interesting to read, so I encourage the authors to continue this line of work.\n", "IS_META_REVIEW": false, "RECOMMENDATION": 5, "DATE": "21 Dec 2016", "REVIEWER_CONFIDENCE": 4}, {"TITLE": "Interesting results and the start of a good paper", "OTHER_KEYS": "ICLR 2017 conference AnonReviewer2", "comments": "This paper proposes and tests two ideas. (1) a method of pruning networks by identifying highly correlated neuron pairs, pruning one of the pair, and then modifying downstream weights to compensate for the removal (which works well if the removed neurons were highly correlated). (2) a method, dubbed NoiseOut, for increasing neuron correlation by adding auxiliary noise target outputs to the network during training.\n\n\nThe first idea (1) is fairly straightforward, and it is not clear if it has been tried before. It does seem to work.\n\n\nThe second idea (2) is of unclear value and seems to this reviewer that it may merely add a regularizing effect. Comments in this direction:\n - In Fig 4 (right), the constant and Gaussian treatments seem to produce the same effect in both networks, right? And the Binomial effect seems the same as No_Noise. If this is true, can we conclude that the NoiseOut targets are simply serving to regularize the network, that is, to reduce its capacity slightly?\n - To show whether this effect is true, one would need to compare to other methods of reducing the network capacity, for example: by reducing the number of neurons, by applying L2 regularization of various values, or by applying Dropout of various strengths. Fig 7 makes an attempt at this direction, but critically misses several comparison treatments: \u201cPruned without any regularization\u201d, \u201cPruned with only L2\u201d, and \u201cPruned with only DropOut\u201d. Have these experiments been run? Can their results be included and used to produce plots like Fig 5 and Fig 7?\n\nWithout these comparisons, it seems impossible to conclude that NoiseOut does anything but provide similar regularization to DropOut or L2.\n\n\nThe combined ideas (1) + (2) DO produce a considerable reduction in parameters, but sadly the experiments and exposition are somewhat too lacking to really understand what is going on. With a little more work the paper could be quite interesting, but as is it should probably not be accepted.\n\n\nAdditional comments:\n - Section 4 states: \u201cIn all of these experiments, the only stop criteria is the accuracy decay of the model. We set the threshold for this criteria to match the original accuracy; therefore all the compressed network have the same accuracy as the original network.\u201d Is this accuracy the train accuracy or test accuracy? If train, then test accuracy needs to be shown (how much test performance is lost when pruning?). If test, then this would typically be referred to as \u201ccheating\u201d and so the choice needs to be very clearly stated and then defended.\n - Lowercase rho is used to indicate correlation but this is never actually specified, which is confusing for. Just state once that it indicates correlation.\n - How do these results compare to other pruning methods? No numerical comparison is attempted.", "IS_META_REVIEW": false, "RECOMMENDATION": 5, "DATE": "19 Dec 2016", "REVIEWER_CONFIDENCE": 3}, {"DATE": "19 Dec 2016", "TITLE": "Train vs. Test acc?", "IS_META_REVIEW": false, "comments": "", "OTHER_KEYS": "ICLR 2017 conference AnonReviewer2"}, {"TITLE": "Intriguing idea, but theory and experiments are lacking.", "OTHER_KEYS": "ICLR 2017 conference AnonReviewer1", "comments": "The paper proposes to prune a neural network by removing neurons whose operation is highly correlated with other neurons. The idea is nice and somewhat novel - most pruning methods concentrate on removal of individual weights, however I haven't done a through research on this topic. However, the experimental and theoretical justification of this method need to be improved before publication:\n\n1. Experiments. The authors do not report accuracy degradation while pruning in the tables, laconically stating that the networks did not degrade. This is not convincing. The only details are given in Figure 5, however this Figure disagrees with Table 2: in the Table, the number of parameters ranges from 40k-600k, while the Figure pictures the range 12k-24k. Unless more details are provided, simply claiming that a network can remove 50% neurons with no number on the degradation of accuracy is not convincing.\n\n2. Theory. The proofs do not match the experimental conditions and make unreasonable assumptions. The proofs show that in the absence of biases a network with a constant output will have two correlated neurons that generate the output offset. However, this is exactly why networks have biases and doesn't explain why noise injection helps (the proof suggests that all should be fine with deterministic auxiliary neuron). My interpretation is that the noisy output injects gradient noise (see e.g. the concurrent ICLR submission ", "IS_META_REVIEW": false, "RECOMMENDATION": 3, "DATE": "17 Dec 2016", "REVIEWER_CONFIDENCE": 4}, {"DATE": "01 Dec 2016", "TITLE": "Do you use bias terms?", "IS_META_REVIEW": false, "comments": "", "OTHER_KEYS": "ICLR 2017 conference AnonReviewer1"}, {"DATE": "06 Feb 2017", "TITLE": "ICLR committee final decision", "IS_META_REVIEW": false, "comments": "all reviewers agree that the paper is not convincing enough at this stage but needs more work to be ready for ICLR (e.g. missing comparisons to other existing methods).", "OTHER_KEYS": "ICLR 2017 pcs"}, {"DATE": "02 Feb 2017", "TITLE": "Some related works", "IS_META_REVIEW": false, "comments": "1) Wen, Wei, et al. \"Learning structured sparsity in deep neural networks.\" Advances in Neural Information Processing Systems. 2016.\n2) Lebedev, Vadim, and Victor Lempitsky. \"Fast convnets using group-wise brain damage.\" Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. 2016.\n3) Alvarez, Jose M., and Mathieu Salzmann. \"Learning the Number of Neurons in Deep Networks.\" Advances in Neural Information Processing Systems. 2016.", "OTHER_KEYS": "(anonymous)"}, {"DATE": "26 Dec 2016", "TITLE": "Possible relevant work not discussed", "IS_META_REVIEW": false, "comments": "This paper misses discussion of 'Diversity Networks' published in ICLR 2016 (", "OTHER_KEYS": "(anonymous)"}, {"TITLE": "Good proof of concept, but more experimental evidence needed", "OTHER_KEYS": "ICLR 2017 conference AnonReviewer3", "comments": "Summary:\nIn this paper, the authors introduce NoiseOut, a way to reduce parameters by pruning neurons from a network. \nThey do this by identifying pairs of neurons produce the most correlated outputs, and replacing the pair by one neuron, and then appropriately adjusting weights.\nThis technique relies on neurons having high correlations however, so they introduce an additional output neuron -- a noise output, which results in the network trying to predict the mean of the noise distribution.\nAs this is a constant, it increases correlation between neurons.\nExperiments test this out on MNIST and SVHN\n\nComments:\nThis is an interesting suggestion on how to prune neurons, but more experiments (on larger datasets) are probably need to be convincing that this is an approach that is guaranteed to work well. \n\nEquation (5) seems to be very straightforwards?\n\nIt seems like that for larger datasets, more noise outputs might have to be added to ensure higher correlations? Is there a downside to this in terms of the overall accuracy?\n\nThe paper is presented clearly, and was definitely interesting to read, so I encourage the authors to continue this line of work.\n", "IS_META_REVIEW": false, "RECOMMENDATION": 5, "DATE": "21 Dec 2016", "REVIEWER_CONFIDENCE": 4}, {"TITLE": "Interesting results and the start of a good paper", "OTHER_KEYS": "ICLR 2017 conference AnonReviewer2", "comments": "This paper proposes and tests two ideas. (1) a method of pruning networks by identifying highly correlated neuron pairs, pruning one of the pair, and then modifying downstream weights to compensate for the removal (which works well if the removed neurons were highly correlated). (2) a method, dubbed NoiseOut, for increasing neuron correlation by adding auxiliary noise target outputs to the network during training.\n\n\nThe first idea (1) is fairly straightforward, and it is not clear if it has been tried before. It does seem to work.\n\n\nThe second idea (2) is of unclear value and seems to this reviewer that it may merely add a regularizing effect. Comments in this direction:\n - In Fig 4 (right), the constant and Gaussian treatments seem to produce the same effect in both networks, right? And the Binomial effect seems the same as No_Noise. If this is true, can we conclude that the NoiseOut targets are simply serving to regularize the network, that is, to reduce its capacity slightly?\n - To show whether this effect is true, one would need to compare to other methods of reducing the network capacity, for example: by reducing the number of neurons, by applying L2 regularization of various values, or by applying Dropout of various strengths. Fig 7 makes an attempt at this direction, but critically misses several comparison treatments: \u201cPruned without any regularization\u201d, \u201cPruned with only L2\u201d, and \u201cPruned with only DropOut\u201d. Have these experiments been run? Can their results be included and used to produce plots like Fig 5 and Fig 7?\n\nWithout these comparisons, it seems impossible to conclude that NoiseOut does anything but provide similar regularization to DropOut or L2.\n\n\nThe combined ideas (1) + (2) DO produce a considerable reduction in parameters, but sadly the experiments and exposition are somewhat too lacking to really understand what is going on. With a little more work the paper could be quite interesting, but as is it should probably not be accepted.\n\n\nAdditional comments:\n - Section 4 states: \u201cIn all of these experiments, the only stop criteria is the accuracy decay of the model. We set the threshold for this criteria to match the original accuracy; therefore all the compressed network have the same accuracy as the original network.\u201d Is this accuracy the train accuracy or test accuracy? If train, then test accuracy needs to be shown (how much test performance is lost when pruning?). If test, then this would typically be referred to as \u201ccheating\u201d and so the choice needs to be very clearly stated and then defended.\n - Lowercase rho is used to indicate correlation but this is never actually specified, which is confusing for. Just state once that it indicates correlation.\n - How do these results compare to other pruning methods? No numerical comparison is attempted.", "IS_META_REVIEW": false, "RECOMMENDATION": 5, "DATE": "19 Dec 2016", "REVIEWER_CONFIDENCE": 3}, {"DATE": "19 Dec 2016", "TITLE": "Train vs. Test acc?", "IS_META_REVIEW": false, "comments": "", "OTHER_KEYS": "ICLR 2017 conference AnonReviewer2"}, {"TITLE": "Intriguing idea, but theory and experiments are lacking.", "OTHER_KEYS": "ICLR 2017 conference AnonReviewer1", "comments": "The paper proposes to prune a neural network by removing neurons whose operation is highly correlated with other neurons. The idea is nice and somewhat novel - most pruning methods concentrate on removal of individual weights, however I haven't done a through research on this topic. However, the experimental and theoretical justification of this method need to be improved before publication:\n\n1. Experiments. The authors do not report accuracy degradation while pruning in the tables, laconically stating that the networks did not degrade. This is not convincing. The only details are given in Figure 5, however this Figure disagrees with Table 2: in the Table, the number of parameters ranges from 40k-600k, while the Figure pictures the range 12k-24k. Unless more details are provided, simply claiming that a network can remove 50% neurons with no number on the degradation of accuracy is not convincing.\n\n2. Theory. The proofs do not match the experimental conditions and make unreasonable assumptions. The proofs show that in the absence of biases a network with a constant output will have two correlated neurons that generate the output offset. However, this is exactly why networks have biases and doesn't explain why noise injection helps (the proof suggests that all should be fine with deterministic auxiliary neuron). My interpretation is that the noisy output injects gradient noise (see e.g. the concurrent ICLR submission ", "IS_META_REVIEW": false, "RECOMMENDATION": 3, "DATE": "17 Dec 2016", "REVIEWER_CONFIDENCE": 4}, {"DATE": "01 Dec 2016", "TITLE": "Do you use bias terms?", "IS_META_REVIEW": false, "comments": "", "OTHER_KEYS": "ICLR 2017 conference AnonReviewer1"}], "authors": "Mohammad Babaeizadeh, Paris Smaragdis, Roy H. Campbell", "accepted": false, "id": "695"}