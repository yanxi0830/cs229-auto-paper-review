{"conference": "ICLR 2017 conference submission", "title": "Understanding intermediate layers using linear classifier probes", "abstract": "Neural network models have a reputation for being black boxes. We propose a new method to better understand the roles and dynamics of the intermediate layers. This has direct consequences on the design of such models and it enables the expert to be able to justify certain heuristics (such as adding auxiliary losses in middle layers). Our method uses linear classifiers, referred to as ``probes'', where a probe can only use the hidden units of a given intermediate layer as discriminating features. Moreover, these probes cannot affect the training phase of a model, and they are generally added after training. They allow the user to visualize the state of the model at multiple steps of training. We demonstrate how this can be used to develop a better intuition about models and to diagnose potential problems.", "histories": [], "reviews": [{"IS_META_REVIEW": true, "comments": "The authors propose a method to investigate the predictiveness of intermediate layer activations. To do so, they propose training linear classifiers and evaluate the error on the test set.\n\nThe paper is well motivated and aims to shed some light onto the progress of model training and hopes to provide insights into deep learning architecture design.\n\nThe two main reasons for why the authors decided to use linear probes seem to be:\n- convexity\n- The last layer in the network is (usually) linear\n\nIn the second to last paragraph of page 4 the authors point out that it could happen that the intermediate features are useless for a linear classifier. This is correct and what I consider the main flaw of the paper. I am missing any motivation as to the usefulness of the suggested analysis to architecture design. In fact, the example with the skip connection (Figure 8) seems to suggest that skip connections shouldn't be used. Doesn't that contradict the recent successes of ResNet?\n\nWhile the results are interesting, they aren't particularly surprising and I am failing to see direct applicability to understanding deep models as the authors suggest."}, {"DATE": "06 Feb 2017", "TITLE": "ICLR committee final decision", "IS_META_REVIEW": false, "comments": "The reviewers generally agreed that the research direction pursued in the paper is a valuable one, but all reviewers expressed strong reservations about the value of a linear probe on intermediate features. The lack of experiments on more complex state-of-the-art networks is also potentially problematic. In the end, it seems that there is insufficient evidence that the proposed approach is actually a useful tool in its present state, though the authors should be encouraged to pursue this line of research further.", "OTHER_KEYS": "ICLR 2017 pcs"}, {"TITLE": "Final review", "OTHER_KEYS": "ICLR 2017 conference AnonReviewer2", "comments": "This paper proposes a method that attempts to \"understand\" what is happening within a neural network by using linear classifier probes which are inserted at various levels of the network.\n\nI think the idea is nice overall because it allows network designers to better understand the representational power of each layer in the network, but at the same time, this works feels a bit rushed. In particular, the fact that the authors did not provide any results in \"real\" networks, which are used to win competitions makes the results less strong, since researchers who want to created competitive network architectures don't have enough evidence from this work to decides whether they should use it or not.\n\nIdeally, I would encourage the authors to consider continuing this line of research and show how to use the information given by these linear classifiers to construct better network architectures. \n\nUnfortunately, as is, I don't think we have enough novelty to justify accepting this work in the conference. ", "IS_META_REVIEW": false, "RECOMMENDATION": 5, "DATE": "18 Dec 2016", "REVIEWER_CONFIDENCE": 3}, {"TITLE": "Interesting problem, but technically and experimentally not solid enough", "OTHER_KEYS": "ICLR 2017 conference AnonReviewer3", "comments": "This paper proposes to use a linear classifier as the probe for the informativeness of the hidden activations from different neural network layers. The training of the linear classifier does not affect the training of the neural network. \n\nThe paper is well motivated for investigating how much useful information (or how good the representations are) for each layer. The observations in this paper agrees with existing insights, such as, 1) (Fig 5a) too many random layers are harmful. 2) (Fig 5b) training is helpful. 3) (Fig 7) lower layers converge faster than higher layer. 4) (Fig 8) too deep network is hard to train, and skip link can remedy this problem.\n\nHowever, this paper has following problems:\n\n1. It is not sufficiently justified why the linear classifier is a good probe. It is not crystal clear why good intermediate features need to show high linear classification accuracy. More theoretical analysis and/or intuition will be helpful.   \n2. This paper does not provide much insight on how to design better networks based on the observations. Designing a better network is also the best way to justify the usefulness of the analysis.\n\nOverall, this paper is tackling an interesting problem, but the technique (the linear classifier as the probe) is not novel and more importantly need to be better justified. Moreover, it is important to show how to design better neural networks using the observations in this paper.\n  \n", "IS_META_REVIEW": false, "RECOMMENDATION": 4, "DATE": "13 Dec 2016", "REVIEWER_CONFIDENCE": 4}, {"TITLE": "Linear predictiveness of intermediate layer activations.", "OTHER_KEYS": "ICLR 2017 conference AnonReviewer1", "comments": "The authors propose a method to investigate the predictiveness of intermediate layer activations. To do so, they propose training linear classifiers and evaluate the error on the test set.\n\nThe paper is well motivated and aims to shed some light onto the progress of model training and hopes to provide insights into deep learning architecture design.\n\nThe two main reasons for why the authors decided to use linear probes seem to be:\n- convexity\n- The last layer in the network is (usually) linear\n\nIn the second to last paragraph of page 4 the authors point out that it could happen that the intermediate features are useless for a linear classifier. This is correct and what I consider the main flaw of the paper. I am missing any motivation as to the usefulness of the suggested analysis to architecture design. In fact, the example with the skip connection (Figure 8) seems to suggest that skip connections shouldn't be used. Doesn't that contradict the recent successes of ResNet?\n\nWhile the results are interesting, they aren't particularly surprising and I am failing to see direct applicability to understanding deep models as the authors suggest.", "IS_META_REVIEW": false, "RECOMMENDATION": 4, "DATE": "13 Dec 2016", "REVIEWER_CONFIDENCE": 4}, {"DATE": "02 Dec 2016", "TITLE": "Novelty and usefulness of the linear probes", "IS_META_REVIEW": false, "comments": "", "OTHER_KEYS": "ICLR 2017 conference AnonReviewer3"}, {"DATE": "28 Nov 2016", "TITLE": "Pre-review questions", "IS_META_REVIEW": false, "comments": "", "OTHER_KEYS": "ICLR 2017 conference AnonReviewer2"}, {"IS_META_REVIEW": true, "comments": "The authors propose a method to investigate the predictiveness of intermediate layer activations. To do so, they propose training linear classifiers and evaluate the error on the test set.\n\nThe paper is well motivated and aims to shed some light onto the progress of model training and hopes to provide insights into deep learning architecture design.\n\nThe two main reasons for why the authors decided to use linear probes seem to be:\n- convexity\n- The last layer in the network is (usually) linear\n\nIn the second to last paragraph of page 4 the authors point out that it could happen that the intermediate features are useless for a linear classifier. This is correct and what I consider the main flaw of the paper. I am missing any motivation as to the usefulness of the suggested analysis to architecture design. In fact, the example with the skip connection (Figure 8) seems to suggest that skip connections shouldn't be used. Doesn't that contradict the recent successes of ResNet?\n\nWhile the results are interesting, they aren't particularly surprising and I am failing to see direct applicability to understanding deep models as the authors suggest."}, {"DATE": "06 Feb 2017", "TITLE": "ICLR committee final decision", "IS_META_REVIEW": false, "comments": "The reviewers generally agreed that the research direction pursued in the paper is a valuable one, but all reviewers expressed strong reservations about the value of a linear probe on intermediate features. The lack of experiments on more complex state-of-the-art networks is also potentially problematic. In the end, it seems that there is insufficient evidence that the proposed approach is actually a useful tool in its present state, though the authors should be encouraged to pursue this line of research further.", "OTHER_KEYS": "ICLR 2017 pcs"}, {"TITLE": "Final review", "OTHER_KEYS": "ICLR 2017 conference AnonReviewer2", "comments": "This paper proposes a method that attempts to \"understand\" what is happening within a neural network by using linear classifier probes which are inserted at various levels of the network.\n\nI think the idea is nice overall because it allows network designers to better understand the representational power of each layer in the network, but at the same time, this works feels a bit rushed. In particular, the fact that the authors did not provide any results in \"real\" networks, which are used to win competitions makes the results less strong, since researchers who want to created competitive network architectures don't have enough evidence from this work to decides whether they should use it or not.\n\nIdeally, I would encourage the authors to consider continuing this line of research and show how to use the information given by these linear classifiers to construct better network architectures. \n\nUnfortunately, as is, I don't think we have enough novelty to justify accepting this work in the conference. ", "IS_META_REVIEW": false, "RECOMMENDATION": 5, "DATE": "18 Dec 2016", "REVIEWER_CONFIDENCE": 3}, {"TITLE": "Interesting problem, but technically and experimentally not solid enough", "OTHER_KEYS": "ICLR 2017 conference AnonReviewer3", "comments": "This paper proposes to use a linear classifier as the probe for the informativeness of the hidden activations from different neural network layers. The training of the linear classifier does not affect the training of the neural network. \n\nThe paper is well motivated for investigating how much useful information (or how good the representations are) for each layer. The observations in this paper agrees with existing insights, such as, 1) (Fig 5a) too many random layers are harmful. 2) (Fig 5b) training is helpful. 3) (Fig 7) lower layers converge faster than higher layer. 4) (Fig 8) too deep network is hard to train, and skip link can remedy this problem.\n\nHowever, this paper has following problems:\n\n1. It is not sufficiently justified why the linear classifier is a good probe. It is not crystal clear why good intermediate features need to show high linear classification accuracy. More theoretical analysis and/or intuition will be helpful.   \n2. This paper does not provide much insight on how to design better networks based on the observations. Designing a better network is also the best way to justify the usefulness of the analysis.\n\nOverall, this paper is tackling an interesting problem, but the technique (the linear classifier as the probe) is not novel and more importantly need to be better justified. Moreover, it is important to show how to design better neural networks using the observations in this paper.\n  \n", "IS_META_REVIEW": false, "RECOMMENDATION": 4, "DATE": "13 Dec 2016", "REVIEWER_CONFIDENCE": 4}, {"TITLE": "Linear predictiveness of intermediate layer activations.", "OTHER_KEYS": "ICLR 2017 conference AnonReviewer1", "comments": "The authors propose a method to investigate the predictiveness of intermediate layer activations. To do so, they propose training linear classifiers and evaluate the error on the test set.\n\nThe paper is well motivated and aims to shed some light onto the progress of model training and hopes to provide insights into deep learning architecture design.\n\nThe two main reasons for why the authors decided to use linear probes seem to be:\n- convexity\n- The last layer in the network is (usually) linear\n\nIn the second to last paragraph of page 4 the authors point out that it could happen that the intermediate features are useless for a linear classifier. This is correct and what I consider the main flaw of the paper. I am missing any motivation as to the usefulness of the suggested analysis to architecture design. In fact, the example with the skip connection (Figure 8) seems to suggest that skip connections shouldn't be used. Doesn't that contradict the recent successes of ResNet?\n\nWhile the results are interesting, they aren't particularly surprising and I am failing to see direct applicability to understanding deep models as the authors suggest.", "IS_META_REVIEW": false, "RECOMMENDATION": 4, "DATE": "13 Dec 2016", "REVIEWER_CONFIDENCE": 4}, {"DATE": "02 Dec 2016", "TITLE": "Novelty and usefulness of the linear probes", "IS_META_REVIEW": false, "comments": "", "OTHER_KEYS": "ICLR 2017 conference AnonReviewer3"}, {"DATE": "28 Nov 2016", "TITLE": "Pre-review questions", "IS_META_REVIEW": false, "comments": "", "OTHER_KEYS": "ICLR 2017 conference AnonReviewer2"}], "authors": "Guillaume Alain, Yoshua Bengio", "accepted": false, "id": "577"}