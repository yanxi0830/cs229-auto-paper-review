{"conference": "ICLR 2017 conference submission", "title": "Skip-graph: Learning graph embeddings with an encoder-decoder model", "abstract": "In this work, we study the problem of feature representation learning for graph-structured data. Many of the existing work in the area are task-specific and based on supervised techniques. We study a method for obtaining a generic feature representation for a graph using an unsupervised approach. The neural encoder-decoder model is a method that has been used in the natural language processing domain to learn feature representations of sentences. In our proposed approach, we train the encoder-decoder model to predict the random walk sequence of neighboring regions in a graph given a random walk along a particular region. The goal is to map subgraphs \u2014 as represented by their random walks \u2014 that are structurally and functionally similar to nearby locations in feature space. We evaluate the learned graph vectors using several real-world datasets on the graph classification task. The proposed model is able to achieve good results against state-of- the-art techniques.", "histories": [], "reviews": [{"IS_META_REVIEW": true, "comments": "The paper presents a method to learn graph embeddings in a unsupervised way using random walks. It is well written and the execution appears quite accurate. The area of learning whole graph representations does not seem to be very well explored in general, and the proposed approach enjoys having very few competitors.\n\nIn a nutshell, the idea is to linearize the graph using random walks and to compute the embedding of the central segment of each walk using the skip-thought criterion. Being not an expert in biology, I can not comment whether or not this makes sense, but the gains reported in Table 2 are quite significant. \n\nAn anonymous public comment compared this work to a number of others in which the problem of learning representations of nodes is considered. While this is arguably a different goal, one natural baseline would be to pool these representations using mean- or max- pooling. It would very interesting to do such a comparison, especially given that the considered approach heavily relies on pooling (see Figure 3(c))\n\nTo sum up, I think it is a nice paper, and with more baselines I would be ready to further increase the numerical score."}, {"DATE": "06 Feb 2017", "TITLE": "ICLR committee final decision", "IS_META_REVIEW": false, "comments": "The idea of applying skip-graphs to this graph domain to learn embeddings is good. The results demonstrate that this approach is competitive, but do not show a clear advantage. This is difficult, as the variety of approaches in this area is rapidly increasing. But comparisons to other methods could be improved, notably deep graph kernels.", "OTHER_KEYS": "ICLR 2017 pcs"}, {"DATE": "11 Jan 2017", "TITLE": "Summary of changes", "IS_META_REVIEW": false, "comments": "Dear reviewers, thank you very much for all the insightful comments and suggestions. Please find below a summary of our response to each of the points that were raised. Please note that we have paraphrased some of the comments and combined similar ones.\n\nAnonymous Reviewer 2:\n\nComment 1. Use the same classifier for all the compared methods.\n\nWe have updated the results in our paper to reflect the changes from using a common classifier for all the compared methods. The changes can be found in section 3.2.\n\nComment 2. Use mean- or max-pooling to aggregate the embeddings learned by methods such as DeepWalk or node2vec and include this as a baseline.\n\nThe paper has been updated to include results from Deepwalk which was added as an additional baseline. Changes were made to sections 3.2 and 3.3.\n\nAnonymous Reviewer 3:\n\nComment 3. Provide more information about the exact values of the parameters that were used in the grid search.\n\nThe information have been added to the paper. This can be found in section 3.2.\n\nAnonymous Reviewer 1:\n\nComment 4. Need more experiment to demonstrate the power of their feature extraction methods. (Clustering, Search, Prediction etc.). Only comparing the classification accuracy by using the proposed method is not enough.\n\nWe plan to extend the experiments by using the embedding for graph clustering and graph search tasks in future works/journal extension. Due to the suggested page limit of ICLR, it is not easy to add these additional experiments without deleting some existing results in the paper. In the existing results, we have demonstrated the power of the embedding through prediction tasks and visualization of the embedding.\n\nComment 5. Presentation of the paper is weak. There are lots of typos and unclear statements. \n\nThe latest version of the paper has been proofread by several individuals and to the best of our knowledge we have removed the major typos and/or unclear statements. \n\nComment 6. What is the difference from graph kernel methods? The comparison with graph kernel is missing. \n\nWe agree that the problem studied in the deep graph kernel paper seems to be very similar, or even the same, to the one we are studying. However, the underlying approach is slightly different and we argue that that in itself is a good motivation for the work as there has not been too many work published in the area. We use an encoder-decoder model which has not been used, and for one we can identify functionally similar subgraphs. \n\nRegrettably, due to time constraints we are unable to add a comparison with Deep Graph Kernels. However, we have tested against methods that have been shown to achieve good results on the type of graphs we used (ECFP and NeuralFPS) and we have also tested against DeepWalk. The introduction section has been updated to include some discussion on this.\n\nAnonymous Reviewer 4:\n\nComment 7. Comparisons with recent work like LINE and node2vec are missing. You can compare them easily by applying the same aggregation strategy to their node embeddings.\n\nWe have already addressed the comment of a previous reviewer and have included DeepWalk as a baseline. We did not add comparisons against node2vec and LINE as these, in general, belong to the same family of methods.\n\nComment 8. As the current datasets are small (e.g., the average number of nodes per graph is around 30), it would be great to explore larger graph datasets to further investigate the method. \n\nTo compensate in a way, we tested the method on four different molecular graph datasets. Regrettably, we are unable to add experiments on more datasets at the moment.\n\nComment 9. The description about how to split the random walk sequence into 3 sub-sequences is missing. Also, the line \u201cl_min >= (n_k - 1), \u2026 >= l_max\u201d in section 2.2.2 is a mistake.\n\nSection 2.2.2 has been updated to correct this. Thank you very much for pointing this out.\n\n", "OTHER_KEYS": "John Boaz Lee"}, {"TITLE": "Experiments Are Incomplete", "OTHER_KEYS": "(anonymous)", "comments": "This paper proposes an unsupervised graph embedding learning method based on random walk and skip-thought model. They show promising results compared to several competitors on four chemical compound datasets.\n\nStrength:\n1, The idea of learning the graph embedding by applying skip-thought model to random walk sequences is interesting. \n2, The paper is well organized.\n\nWeakness:\n1, As the current datasets are small (e.g., the average number of nodes per graph is around 30), it would be great to explore larger graph datasets to further investigate the method. \n2, Comparisons with recent work like LINE and node2vec are missing. You can compare them easily by applying the same aggregation strategy to their node embeddings.\n\nDetailed Questions:\n1, The description about how to split the random walk sequence into 3 sub-sequences is missing. Also, the line \u201cl_min >= (n_k - 1), \u2026 >= l_max\u201d in section 2.2.2 is a mistake.\n2, Can you provide the standard deviations of the 5-fold cross validation in Table 2? I\u2019m curious about how stable the algorithm is.", "IS_META_REVIEW": false, "RECOMMENDATION": 5, "DATE": "02 Jan 2017", "REVIEWER_CONFIDENCE": 4}, {"TITLE": "Comparison with Graph kernels Missing", "OTHER_KEYS": "ICLR 2017 conference AnonReviewer1", "comments": "This paper studies the graph embedding problem by using the encoder-decoder method. The experimental study on real network data sets show the features extracted by the proposed model is good for classification.\n\nStrong points of this paper:\n  1. The idea of using the methods from natural language processing to graph mining is quite interesting.\n  2. The organization of the paper is clear\n\nWeak points of this paper:\n  1. Comparisons with state-of-art methods (Graph Kernels) is missing. \n  2. The problem is not well motivated, are there any application of this. What is the different from the graph kernel methods? The comparison with graph kernel is missing. \n  3. Need more experiment to demonstrate the power of their feature extraction methods. (Clustering, Search, Prediction etc.)\n  4. Presentation of the paper is weak. There are lots of typos and unclear statements. \n  5. The author mentioned about the graph kernel things, but in the experiment they didn't compare them. Also, only compare the classification accuracy by using the proposed method is not enough.", "IS_META_REVIEW": false, "RECOMMENDATION": 5, "DATE": "29 Dec 2016", "REVIEWER_CONFIDENCE": 4}, {"TITLE": "An extension of skip-graph architecture to classifying similar molecular graphs ", "OTHER_KEYS": "ICLR 2017 conference AnonReviewer3", "comments": "Authors take the skip-graph architecture (Kiros 2015) and apply it to classifying labeled graphs (molecular graphs). They do it by creating many sentences by walking the graph randomly, and asking the model to predict previous part and next part from the middle part. Activations of the decoder part of this model on a walk generated from a new graph are used as features for a binary classifier use to predict whether the molecule has anti-cancer properties.\n\nPaper is well written, except that evaluation section is missing details of how the embedding is used for actual classification (ie, what classifier is used)\n\nUnfortunately I'm not familiar with the dataset and how hard it is to achieve the results they demonstrate, that would be the important factor to weight on the papers acceptance.", "IS_META_REVIEW": false, "RECOMMENDATION": 6, "DATE": "19 Dec 2016", "REVIEWER_CONFIDENCE": 1}, {"DATE": "19 Dec 2016", "TITLE": "How do you go from embedding to final classification?", "IS_META_REVIEW": false, "comments": "", "OTHER_KEYS": "ICLR 2017 conference AnonReviewer3"}, {"TITLE": "Good paper", "OTHER_KEYS": "ICLR 2017 conference AnonReviewer2", "comments": "The paper presents a method to learn graph embeddings in a unsupervised way using random walks. It is well written and the execution appears quite accurate. The area of learning whole graph representations does not seem to be very well explored in general, and the proposed approach enjoys having very few competitors.\n\nIn a nutshell, the idea is to linearize the graph using random walks and to compute the embedding of the central segment of each walk using the skip-thought criterion. Being not an expert in biology, I can not comment whether or not this makes sense, but the gains reported in Table 2 are quite significant. \n\nAn anonymous public comment compared this work to a number of others in which the problem of learning representations of nodes is considered. While this is arguably a different goal, one natural baseline would be to pool these representations using mean- or max- pooling. It would very interesting to do such a comparison, especially given that the considered approach heavily relies on pooling (see Figure 3(c))\n\nTo sum up, I think it is a nice paper, and with more baselines I would be ready to further increase the numerical score.  \n", "IS_META_REVIEW": false, "RECOMMENDATION": 7, "DATE": "16 Dec 2016", "REVIEWER_CONFIDENCE": 3}, {"DATE": "02 Dec 2016", "TITLE": "Classifier for ECFP", "IS_META_REVIEW": false, "comments": "", "OTHER_KEYS": "ICLR 2017 conference AnonReviewer2"}, {"DATE": "05 Nov 2016", "TITLE": "Baseline comparisons", "IS_META_REVIEW": false, "comments": "Hi,\n\nIn the abstract you have mentioned, \"Many of the existing work in the area are task-specific and based on supervised techniques\". I don't think this is a valid statement, since lot of recent work in graph embeddings is based on unsupervised methods. Like LINE and DeepWalk. \n\nAnd is there any particular reason you didn't compare your method with DeepWalk and LINE, considering the fact that they are state-of-the art methods in representation learning for graphs?\n\nRegards,", "OTHER_KEYS": "(anonymous)"}, {"IS_META_REVIEW": true, "comments": "The paper presents a method to learn graph embeddings in a unsupervised way using random walks. It is well written and the execution appears quite accurate. The area of learning whole graph representations does not seem to be very well explored in general, and the proposed approach enjoys having very few competitors.\n\nIn a nutshell, the idea is to linearize the graph using random walks and to compute the embedding of the central segment of each walk using the skip-thought criterion. Being not an expert in biology, I can not comment whether or not this makes sense, but the gains reported in Table 2 are quite significant. \n\nAn anonymous public comment compared this work to a number of others in which the problem of learning representations of nodes is considered. While this is arguably a different goal, one natural baseline would be to pool these representations using mean- or max- pooling. It would very interesting to do such a comparison, especially given that the considered approach heavily relies on pooling (see Figure 3(c))\n\nTo sum up, I think it is a nice paper, and with more baselines I would be ready to further increase the numerical score."}, {"DATE": "06 Feb 2017", "TITLE": "ICLR committee final decision", "IS_META_REVIEW": false, "comments": "The idea of applying skip-graphs to this graph domain to learn embeddings is good. The results demonstrate that this approach is competitive, but do not show a clear advantage. This is difficult, as the variety of approaches in this area is rapidly increasing. But comparisons to other methods could be improved, notably deep graph kernels.", "OTHER_KEYS": "ICLR 2017 pcs"}, {"DATE": "11 Jan 2017", "TITLE": "Summary of changes", "IS_META_REVIEW": false, "comments": "Dear reviewers, thank you very much for all the insightful comments and suggestions. Please find below a summary of our response to each of the points that were raised. Please note that we have paraphrased some of the comments and combined similar ones.\n\nAnonymous Reviewer 2:\n\nComment 1. Use the same classifier for all the compared methods.\n\nWe have updated the results in our paper to reflect the changes from using a common classifier for all the compared methods. The changes can be found in section 3.2.\n\nComment 2. Use mean- or max-pooling to aggregate the embeddings learned by methods such as DeepWalk or node2vec and include this as a baseline.\n\nThe paper has been updated to include results from Deepwalk which was added as an additional baseline. Changes were made to sections 3.2 and 3.3.\n\nAnonymous Reviewer 3:\n\nComment 3. Provide more information about the exact values of the parameters that were used in the grid search.\n\nThe information have been added to the paper. This can be found in section 3.2.\n\nAnonymous Reviewer 1:\n\nComment 4. Need more experiment to demonstrate the power of their feature extraction methods. (Clustering, Search, Prediction etc.). Only comparing the classification accuracy by using the proposed method is not enough.\n\nWe plan to extend the experiments by using the embedding for graph clustering and graph search tasks in future works/journal extension. Due to the suggested page limit of ICLR, it is not easy to add these additional experiments without deleting some existing results in the paper. In the existing results, we have demonstrated the power of the embedding through prediction tasks and visualization of the embedding.\n\nComment 5. Presentation of the paper is weak. There are lots of typos and unclear statements. \n\nThe latest version of the paper has been proofread by several individuals and to the best of our knowledge we have removed the major typos and/or unclear statements. \n\nComment 6. What is the difference from graph kernel methods? The comparison with graph kernel is missing. \n\nWe agree that the problem studied in the deep graph kernel paper seems to be very similar, or even the same, to the one we are studying. However, the underlying approach is slightly different and we argue that that in itself is a good motivation for the work as there has not been too many work published in the area. We use an encoder-decoder model which has not been used, and for one we can identify functionally similar subgraphs. \n\nRegrettably, due to time constraints we are unable to add a comparison with Deep Graph Kernels. However, we have tested against methods that have been shown to achieve good results on the type of graphs we used (ECFP and NeuralFPS) and we have also tested against DeepWalk. The introduction section has been updated to include some discussion on this.\n\nAnonymous Reviewer 4:\n\nComment 7. Comparisons with recent work like LINE and node2vec are missing. You can compare them easily by applying the same aggregation strategy to their node embeddings.\n\nWe have already addressed the comment of a previous reviewer and have included DeepWalk as a baseline. We did not add comparisons against node2vec and LINE as these, in general, belong to the same family of methods.\n\nComment 8. As the current datasets are small (e.g., the average number of nodes per graph is around 30), it would be great to explore larger graph datasets to further investigate the method. \n\nTo compensate in a way, we tested the method on four different molecular graph datasets. Regrettably, we are unable to add experiments on more datasets at the moment.\n\nComment 9. The description about how to split the random walk sequence into 3 sub-sequences is missing. Also, the line \u201cl_min >= (n_k - 1), \u2026 >= l_max\u201d in section 2.2.2 is a mistake.\n\nSection 2.2.2 has been updated to correct this. Thank you very much for pointing this out.\n\n", "OTHER_KEYS": "John Boaz Lee"}, {"TITLE": "Experiments Are Incomplete", "OTHER_KEYS": "(anonymous)", "comments": "This paper proposes an unsupervised graph embedding learning method based on random walk and skip-thought model. They show promising results compared to several competitors on four chemical compound datasets.\n\nStrength:\n1, The idea of learning the graph embedding by applying skip-thought model to random walk sequences is interesting. \n2, The paper is well organized.\n\nWeakness:\n1, As the current datasets are small (e.g., the average number of nodes per graph is around 30), it would be great to explore larger graph datasets to further investigate the method. \n2, Comparisons with recent work like LINE and node2vec are missing. You can compare them easily by applying the same aggregation strategy to their node embeddings.\n\nDetailed Questions:\n1, The description about how to split the random walk sequence into 3 sub-sequences is missing. Also, the line \u201cl_min >= (n_k - 1), \u2026 >= l_max\u201d in section 2.2.2 is a mistake.\n2, Can you provide the standard deviations of the 5-fold cross validation in Table 2? I\u2019m curious about how stable the algorithm is.", "IS_META_REVIEW": false, "RECOMMENDATION": 5, "DATE": "02 Jan 2017", "REVIEWER_CONFIDENCE": 4}, {"TITLE": "Comparison with Graph kernels Missing", "OTHER_KEYS": "ICLR 2017 conference AnonReviewer1", "comments": "This paper studies the graph embedding problem by using the encoder-decoder method. The experimental study on real network data sets show the features extracted by the proposed model is good for classification.\n\nStrong points of this paper:\n  1. The idea of using the methods from natural language processing to graph mining is quite interesting.\n  2. The organization of the paper is clear\n\nWeak points of this paper:\n  1. Comparisons with state-of-art methods (Graph Kernels) is missing. \n  2. The problem is not well motivated, are there any application of this. What is the different from the graph kernel methods? The comparison with graph kernel is missing. \n  3. Need more experiment to demonstrate the power of their feature extraction methods. (Clustering, Search, Prediction etc.)\n  4. Presentation of the paper is weak. There are lots of typos and unclear statements. \n  5. The author mentioned about the graph kernel things, but in the experiment they didn't compare them. Also, only compare the classification accuracy by using the proposed method is not enough.", "IS_META_REVIEW": false, "RECOMMENDATION": 5, "DATE": "29 Dec 2016", "REVIEWER_CONFIDENCE": 4}, {"TITLE": "An extension of skip-graph architecture to classifying similar molecular graphs ", "OTHER_KEYS": "ICLR 2017 conference AnonReviewer3", "comments": "Authors take the skip-graph architecture (Kiros 2015) and apply it to classifying labeled graphs (molecular graphs). They do it by creating many sentences by walking the graph randomly, and asking the model to predict previous part and next part from the middle part. Activations of the decoder part of this model on a walk generated from a new graph are used as features for a binary classifier use to predict whether the molecule has anti-cancer properties.\n\nPaper is well written, except that evaluation section is missing details of how the embedding is used for actual classification (ie, what classifier is used)\n\nUnfortunately I'm not familiar with the dataset and how hard it is to achieve the results they demonstrate, that would be the important factor to weight on the papers acceptance.", "IS_META_REVIEW": false, "RECOMMENDATION": 6, "DATE": "19 Dec 2016", "REVIEWER_CONFIDENCE": 1}, {"DATE": "19 Dec 2016", "TITLE": "How do you go from embedding to final classification?", "IS_META_REVIEW": false, "comments": "", "OTHER_KEYS": "ICLR 2017 conference AnonReviewer3"}, {"TITLE": "Good paper", "OTHER_KEYS": "ICLR 2017 conference AnonReviewer2", "comments": "The paper presents a method to learn graph embeddings in a unsupervised way using random walks. It is well written and the execution appears quite accurate. The area of learning whole graph representations does not seem to be very well explored in general, and the proposed approach enjoys having very few competitors.\n\nIn a nutshell, the idea is to linearize the graph using random walks and to compute the embedding of the central segment of each walk using the skip-thought criterion. Being not an expert in biology, I can not comment whether or not this makes sense, but the gains reported in Table 2 are quite significant. \n\nAn anonymous public comment compared this work to a number of others in which the problem of learning representations of nodes is considered. While this is arguably a different goal, one natural baseline would be to pool these representations using mean- or max- pooling. It would very interesting to do such a comparison, especially given that the considered approach heavily relies on pooling (see Figure 3(c))\n\nTo sum up, I think it is a nice paper, and with more baselines I would be ready to further increase the numerical score.  \n", "IS_META_REVIEW": false, "RECOMMENDATION": 7, "DATE": "16 Dec 2016", "REVIEWER_CONFIDENCE": 3}, {"DATE": "02 Dec 2016", "TITLE": "Classifier for ECFP", "IS_META_REVIEW": false, "comments": "", "OTHER_KEYS": "ICLR 2017 conference AnonReviewer2"}, {"DATE": "05 Nov 2016", "TITLE": "Baseline comparisons", "IS_META_REVIEW": false, "comments": "Hi,\n\nIn the abstract you have mentioned, \"Many of the existing work in the area are task-specific and based on supervised techniques\". I don't think this is a valid statement, since lot of recent work in graph embeddings is based on unsupervised methods. Like LINE and DeepWalk. \n\nAnd is there any particular reason you didn't compare your method with DeepWalk and LINE, considering the fact that they are state-of-the art methods in representation learning for graphs?\n\nRegards,", "OTHER_KEYS": "(anonymous)"}], "authors": "John Boaz Lee, Xiangnan Kong", "accepted": false, "id": "677"}