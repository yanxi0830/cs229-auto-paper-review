{"conference": "ICLR 2017 conference submission", "title": "Towards Principled Methods for Training Generative Adversarial Networks", "abstract": "The goal of this paper is not to introduce a single algorithm or method, but to make theoretical steps towards fully understanding the training dynamics of gen- erative adversarial networks. In order to substantiate our theoretical analysis, we perform targeted experiments to verify our assumptions, illustrate our claims, and quantify the phenomena. This paper is divided into three sections. The first sec- tion introduces the problem at hand. The second section is dedicated to studying and proving rigorously the problems including instability and saturation that arize when training generative adversarial networks. The third section examines a prac- tical and theoretically grounded direction towards solving these problems, while introducing new tools to study them.", "histories": [], "reviews": [{"IS_META_REVIEW": true, "comments": "This paper makes a valuable contribution to provide a more clear understanding of generative adversarial network (GAN) training procedure. \n\nWith the new insight of the training dynamics of GAN, as well as its variant, the authors reveal the reason that why the gradient is either vanishing in original GAN or unstable in its variant. More importantly, they also provide a way to avoid such difficulties by introducing perturbation. I believe this paper will inspire more principled research in this direction. \n\nI am very interested in the perturbation trick to avoid the gradient instability and vanishment. In fact, this is quite related to dropout trick in where the perturbation can be viewed as Bernoulli distribution. It will be great if the connection can be discussed.  Besides the theoretical analysis, is there any empirical study to justify this trick? Could you please add some experiments like Fig 2 and 3 for the perturbated GAN for comparison?"}, {"DATE": "06 Feb 2017", "TITLE": "ICLR committee final decision", "IS_META_REVIEW": false, "comments": "The paper provides a detailed analysis of the instability issues surrounding the training of GANs. They demonstrate how perturbations can help with improving stability. Given the popularity of GANs, this paper is expected to have a significant impact.", "OTHER_KEYS": "ICLR 2017 pcs"}, {"DATE": "02 Feb 2017", "TITLE": "Theorem 2.1", "IS_META_REVIEW": false, "comments": "I am a bit confused with your proof of Theorem 2.1: shouldn't it be that the Urysohn's lemma imply that D* is 1 on M and 0 on P (not on M^{hat} and P^{hat})?\nAlso small typo in the formulation: discrimator -> discriminator. ", "OTHER_KEYS": "(anonymous)"}, {"DATE": "27 Jan 2017", "TITLE": "high quality paper", "IS_META_REVIEW": false, "comments": "Hi!\nI think this is an outstanding paper. \nIt has greatly helped me towards understanding where failure modes of GANs come from, and I think it will also have great practical implications on how to train GANs. \n\nFollowing your ideas, I have played with added noise on GANs. I am able to get the generator to yield 'good looking' samples in much less G iterations than in the standard setting. Also, it appears that 'successful' training is a LOT less sensitive to the setting of hyperparameters. For example I am able to use 10 times higher learning rates, forget about gradient clipping, etc... so this is great! I think this paper paves the way to further research on the following points:\n- how to choose noise variance and schedule its decrease over training ?\n- what does 'training D to convergence' mean ? In practice it seems that training D 'more than G' but only a few steps is already sufficient. Can we get a theoretical understanding of this...\n\nAlso, in my (quick and dirty) first experiments, using instance noise helped training in less G iterations, but the mode dropping problem remained. In my understanding, your theoretical analysis demonstrates that the addition of noise helps D provide gradients to G so that at anytime, G is able to escape its current modes. However, and due to the fact that D outputs are calculated from single examples there is no 'coverage guarantee', for example G could keep switching between different modes. Is this right ? Minibatch discrimination appears to be a good first way to answer this, although not 100% satisfactory because the metric is combinatorial... What is your view on these practical considerations ?\n\nMany thanks !\n\nArnaud Sors", "OTHER_KEYS": "Arnaud Sors"}, {"IMPACT": 3, "OTHER_KEYS": "ICLR 2017 conference AnonReviewer2", "TITLE": "final evaluation - strong submission", "comments": "Very good paper, I hope it will be accepted. I keep my original evaluation.", "ORIGINALITY": 2, "IS_ANNOTATED": true, "IS_META_REVIEW": false, "DATE": "20 Jan 2017"}, {"DATE": "12 Jan 2017", "TITLE": "New version", "IS_META_REVIEW": false, "comments": "Hi! We would like to comment that we added a revision with the following changes at its core:\n\n- We extended the proofs and definitions in section 2 to work with manifolds with boundary.\n\n- We included a one page Appendix B with further clarifications for the things that were suggested in the comments, such as a small comment on continuity vs absolute continuity of random variables, and how it is relevant to our paper.\n\n- We did some minor rewriting to take into account the suggestions from the reviewers and commenters.\n\n- We fixed all the typos :)\n\nBest!\nMartin", "OTHER_KEYS": "Martin Arjovsky"}, {"DATE": "03 Jan 2017", "TITLE": "Very good paper", "IS_META_REVIEW": false, "comments": "I think this paper is a very good step towards interpreting and understanding GANs. While some experiments have been (often successfully) done with adding noise, there was no theoretical reason, mainly intuition and hand waving.\nThis paper clearly states the reason why these methods work, by pointing a fundamental pitfall in GANs that was overlooked so far.\nI believe that this is a crucial step towards making useful, large scale GANs.\n\nSome notes and typos (sorry if it was already addressed in previous comments):\n- First paragraph of section 2, the cost part is quite unclear (it\u2019s the negative of what was described earlier (after equation 2), and the words \"maximizing\" and \"minimizing\" are mixed).\n- Definition 2.1: what is the tangent space of the whole space around a point? Isn\u2019t it just the point? I think you mean TxM + TxP = F . Also, I thin the + should be a (+) (vector space sum)\n- Bottom of page 4, before Lemma 2: its -> their (intersection)\n- Maybe I'm not familiar enough with the vocabulary, but I did not quite understand what you meant by \"non continuous distribution\", despite the footnote. As a consequence, it took me until much later in the paper to fully understand the link between non-continuous and low-dimensional manifold.\n- There is a numbering problem. In particular, theorem 2.6 refers to theorems 1.1 and 1.2, which don\u2019t exist.\n- Theorem 2.6: I think the definition and role of epsilon could be clarified.\n- Corollary 3.2: missing a tilde, g -> g_\\theta\n- Paragraph above lemma 4: missing \u2018)\u2019 after JSD(...", "OTHER_KEYS": "Michael Mathieu"}, {"DATE": "28 Dec 2016", "TITLE": "last paragraph", "IS_META_REVIEW": false, "comments": "I've always considered myself something of a GAN sceptic, so I'm very excited to see so many papers popping up that try to analyse and address their shortcomings. There are many ICLR submissions on this topic but I found this one a particularly enlightening read, nice work!\n\nThe last paragraph of the paper is perhaps the most interesting, as it seems to propose an alternative training method that would solve most of the problems: the gradients no longer vanish when the discriminator is trained to convergence, which eliminates the careful balancing act that GAN training currently requires.\n\nBut unfortunately the paper ends there, with no discussion of how this would be implemented in practice and no experiments to demonstrate the proposed solution. Is this work that is currently underway? It seems like an excellent idea so it's strange that only one paragraph of the paper is dedicated to it (although admittedly the paper is already quite long).", "OTHER_KEYS": "Sander Dieleman"}, {"DATE": "24 Dec 2016", "TITLE": "Revision", "IS_META_REVIEW": false, "comments": "Hi! We would first like to thank the reviewers for your comments. We will aim to make all the suggestions fit into a revision. We will update the paper shortly and provide individual responses to the reviews :)\n\nBest!\nMartin", "OTHER_KEYS": "Martin Arjovsky"}, {"TITLE": "good submission", "MEANINGFUL_COMPARISON": 3, "OTHER_KEYS": "ICLR 2017 conference AnonReviewer3", "comments": "This paper makes a valuable contribution to provide a more clear understanding of generative adversarial network (GAN) training procedure. \n\nWith the new insight of the training dynamics of GAN, as well as its variant, the authors reveal the reason that why the gradient is either vanishing in original GAN or unstable in its variant. More importantly, they also provide a way to avoid such difficulties by introducing perturbation. I believe this paper will inspire more principled research in this direction. \n\nI am very interested in the perturbation trick to avoid the gradient instability and vanishment. In fact, this is quite related to dropout trick in where the perturbation can be viewed as Bernoulli distribution. It will be great if the connection can be discussed.  Besides the theoretical analysis, is there any empirical study to justify this trick? Could you please add some experiments like Fig 2 and 3 for the perturbated GAN for comparison? ", "ORIGINALITY": 2, "IS_ANNOTATED": true, "IS_META_REVIEW": false, "RECOMMENDATION": 8, "DATE": "20 Dec 2016", "APPROPRIATENESS": 2, "REVIEWER_CONFIDENCE": 3}, {"IMPACT": 3, "OTHER_KEYS": "ICLR 2017 conference AnonReviewer2", "TITLE": "next steps", "comments": "", "ORIGINALITY": 2, "IS_ANNOTATED": true, "IS_META_REVIEW": false, "DATE": "19 Dec 2016"}, {"IMPACT": 3, "OTHER_KEYS": "ICLR 2017 conference AnonReviewer2", "TITLE": "very interesting submission", "comments": "This is a strong submission regarding one of the most important and recently introduced methods in neural networks - generative adversarial networks. The authors analyze theoretically the convergence of GANs and discuss the stability of GANs. Both are very important. To the best of my knowledge, this is one of the first theoretical papers about GANs and the paper, contrary to most of the submissions in the field, actually provides deep theoretical insight into this architecture. The stability issues regarding GANs are extremely important since the first proposed versions of GANs architecture were very unstable and did not work well in practice. Theorems 2.4-2.6 are novel and introduces mathematical techniques are interesting. I have some technical questions regarding the proof of Theorem 2.5 but these are pretty minor.\n", "ORIGINALITY": 2, "IS_ANNOTATED": true, "IS_META_REVIEW": false, "RECOMMENDATION": 10, "DATE": "19 Dec 2016", "REVIEWER_CONFIDENCE": 5}, {"TITLE": "review of ``TOWARDS PRINCIPLED METHODS FOR TRAINING GENERATIVE ADVERSARIAL NETWORKS'' ", "MEANINGFUL_COMPARISON": 4, "RECOMMENDATION_UNOFFICIAL": 2, "comments": "SUMMARY \nThis paper addresses important questions about the difficulties in training generative adversarial networks. It discusses consequences of using an asymmetric divergence function and sources of instability in training GANs. Then it proposes an alternative using a smoothening approach. \n\nPROS \nTheory, good questions, nice answers. \nMakes an interesting use of concepts form analysis and differential topology. \nProposes avenues to avoid instability in GANs. \n\nCONS \nA bit too long, technical. Some parts and consequences still need to be further developed (which is perfectly fine for future work). \n\nMINOR COMMENTS\n\n- Section 2.1 Maybe shorten this section a bit. E.g., move all proofs to the appendix. \n\n- Section 3 provides a nice, intuitive, simple solution. \n\n- On page 2 second bullet. This also means that P_g is smaller than the data distribution in some other x, which in turn will make the KL divergence non zero. \n\n- On page 2, ``for not generating plausibly looking pictures'' should be ``for generating not plausibly looking pictures''.  \n\n- Lemma 1 would also hold in more generality. \n\n- Theorem 2.1 seems to be basic analysis. (In other words, a reference could spare the proof). \n\n- In Theorem 2.4, it would be good to remind the reader about p(z). \n\n- Lemma 2 seems to be basic analysis. (In other words, a reference could spare the proof). \nSpecify the domain of the random variables. \n\n- relly - > rely \n\n- Theorem 2.2 the closed manifolds have boundary or not? (already in the questions)\n\n- Corollary 2.1, ``assumptions of Theorem 1.3''. I could not find Theorem 1.3. \n\n- Theorem 2.5 ``Therefore'' -> `Then'? \n\n- Theorem 2.6 ``Is a... '' -> `is a' ? \n\n- The number of the theorems is confusing. \n", "SOUNDNESS_CORRECTNESS": 4, "IS_ANNOTATED": true, "IS_META_REVIEW": false, "RECOMMENDATION": 7, "DATE": "19 Dec 2016", "CLARITY": 4, "OTHER_KEYS": "ICLR 2017 conference AnonReviewer1", "REVIEWER_CONFIDENCE": 4}, {"TITLE": "very solid contribution to the theoretical understanding of GANS", "OTHER_KEYS": "(anonymous)", "comments": "This is a strong submission regarding one of the most important and recently introduced methods in neural networks - generative adversarial networks. The authors analyze theoretically the convergence of GANs and discuss the stability of GANs. Both are very important. To the best of my knowledge, this is one of the first theoretical papers about GANs and the paper, contrary to most of the submissions in the field, actually provides deep theoretical insight into this architecture. The stability issues regarding GANs are extremely important since the first proposed versions of GANs architecture were very unstable and did not work well in practice. Theorems 2.4-2.6 are novel and introduces mathematical techniques are interesting. I have some technical questions regarding the proof of Theorem 2.5 but these are pretty minor.", "IS_META_REVIEW": false, "RECOMMENDATION": 10, "DATE": "17 Dec 2016", "REVIEWER_CONFIDENCE": 5}, {"DATE": "16 Dec 2016", "TITLE": "Questions and inconsistencies.", "IS_META_REVIEW": false, "comments": "This paper makes many valuable contributions and explains many of the issues related to training GANs; I feel it will be an essential platform for future work. However I have the following questions and found the following inconsistencies.\n\n1) \n\t\u201cIf n <= d, we are done since the image of \u03c0 is contained in all Rn, a manifold with at \n\tmost dimension d. We now turn to the case where d > n.\u201d\n\nIs the case  d>n  not contained in the first,  n<=d ? Should this be n>d?\n\n2) The perfect discriminator theorems: \n\n\t\u201cWe say that a discriminator D : X \u2192 [0, 1] has accuracy 1 if it takes the value 1 on a set that \n\tcontains the support of P_r  and value 0 on a set that contains the support of P_g .\u201d\n\nIf a set S_g or S_r contains the support of P_g or P_r, this suggests that it may contain the support but may also contain regions outside of the support.  Are you suggesting that for x in S_r that are outside the support of P_r, D(x)=1? However, surely regions outside the support of P_r should correspond to generated images, so D(x) should be 0.\n\nb) Following from a), if a set S_g (or S_r) contained regions outside the support (as well as the support) then S_g (or S_r)  would contain the support of P_g (or P_r) but may also contain regions in the support of P_r (or P_g).\n\n3) \n\t\tP_r[D(x) = 1] = 1 and P_g[D(x) = 0] = 1 \n\na) This notation is not clear, do you mean:\n\tP_r(x)=1 for all x in {x : D(x)=1} and P_g(x)=1 for all x in {x : D(x)=0}\n\n4) Theorem 2.1\n\na) It is not clear what distance measure you are using between sets\nb) Where does the delta/3 come from? Is this arbitrary?\n\n5) Theorem 2.2\na) What is P^c?\nb) Is the ball B(x,e_x) defined for all x in M\\L? This is not explicit.\n\nIf defined for all x in M\\L:\nc) For x on the boundary of M\\L and P\\L is e_x=0? Otherwise, is it possible that for x on the boundary of M\\L or P\\L , M_hat and P_hat intersect with P\\L or M\\L respectively? \n\nFinally:\nd) M_hat is a superset of M\\L, how can you say D*(x)=1 for all x in M_hat, when M_hat may include regions outside the support of M?\n\n9) Corollary 2.1; \n\t\"Under the same assumptions of Theorem 1.3\u2028\"\na) What is Theorem 1.3?\n\n11) Theorem 2.5 \na) Could this be explicitly linked to the collapsing generator problem talked about by [1] and [2].  Citations might make the link clearer. \n\n12) Theorem 2.6 \na) Why do you assume that the distribution of difference between D and D* is white noise? This suggests that most of the time D is optimal, from the rest of the paper this is believable, however if this is what you are assuming, this could be made more explicit. \nb) Similar question for difference in gradient, though since grad D* is zero most of the time, that would suggest that grad D is zero most of the time. Is this true?\nc) extra bracket in final line of proof\n\n16) \n       \u201cThis is in drastic contrast to the noiseless variants P_g  and P_g,\u201d\na) repeated P_g\n\n17) \n         \u201cagain that JSD(P_x,P_{x+e} is maxed out,\u201d\na) missing bracket and inconsistent notation, JSD(P_x||P_{x+e})\nb) \u201cmaxed out\u201c is a colloquialism\n\n[1] Salimans, Tim, et al. \"Improved techniques for training gans.\" arXiv preprint arXiv:1606.03498 (2016).\n[2]Odena, Augustus, Christopher Olah, and Jonathon Shlens. \"Conditional Image Synthesis With Auxiliary Classifier GANs.\" arXiv preprint arXiv:1610.09585 (2016).", "OTHER_KEYS": "Antonia Creswell"}, {"TITLE": "minor questions", "MEANINGFUL_COMPARISON": 4, "RECOMMENDATION_UNOFFICIAL": 2, "comments": "", "SOUNDNESS_CORRECTNESS": 4, "IS_ANNOTATED": true, "IS_META_REVIEW": false, "DATE": "02 Dec 2016", "CLARITY": 4, "OTHER_KEYS": "ICLR 2017 conference AnonReviewer1"}, {"IS_META_REVIEW": true, "comments": "This paper makes a valuable contribution to provide a more clear understanding of generative adversarial network (GAN) training procedure. \n\nWith the new insight of the training dynamics of GAN, as well as its variant, the authors reveal the reason that why the gradient is either vanishing in original GAN or unstable in its variant. More importantly, they also provide a way to avoid such difficulties by introducing perturbation. I believe this paper will inspire more principled research in this direction. \n\nI am very interested in the perturbation trick to avoid the gradient instability and vanishment. In fact, this is quite related to dropout trick in where the perturbation can be viewed as Bernoulli distribution. It will be great if the connection can be discussed.  Besides the theoretical analysis, is there any empirical study to justify this trick? Could you please add some experiments like Fig 2 and 3 for the perturbated GAN for comparison?"}, {"DATE": "06 Feb 2017", "TITLE": "ICLR committee final decision", "IS_META_REVIEW": false, "comments": "The paper provides a detailed analysis of the instability issues surrounding the training of GANs. They demonstrate how perturbations can help with improving stability. Given the popularity of GANs, this paper is expected to have a significant impact.", "OTHER_KEYS": "ICLR 2017 pcs"}, {"DATE": "02 Feb 2017", "TITLE": "Theorem 2.1", "IS_META_REVIEW": false, "comments": "I am a bit confused with your proof of Theorem 2.1: shouldn't it be that the Urysohn's lemma imply that D* is 1 on M and 0 on P (not on M^{hat} and P^{hat})?\nAlso small typo in the formulation: discrimator -> discriminator. ", "OTHER_KEYS": "(anonymous)"}, {"DATE": "27 Jan 2017", "TITLE": "high quality paper", "IS_META_REVIEW": false, "comments": "Hi!\nI think this is an outstanding paper. \nIt has greatly helped me towards understanding where failure modes of GANs come from, and I think it will also have great practical implications on how to train GANs. \n\nFollowing your ideas, I have played with added noise on GANs. I am able to get the generator to yield 'good looking' samples in much less G iterations than in the standard setting. Also, it appears that 'successful' training is a LOT less sensitive to the setting of hyperparameters. For example I am able to use 10 times higher learning rates, forget about gradient clipping, etc... so this is great! I think this paper paves the way to further research on the following points:\n- how to choose noise variance and schedule its decrease over training ?\n- what does 'training D to convergence' mean ? In practice it seems that training D 'more than G' but only a few steps is already sufficient. Can we get a theoretical understanding of this...\n\nAlso, in my (quick and dirty) first experiments, using instance noise helped training in less G iterations, but the mode dropping problem remained. In my understanding, your theoretical analysis demonstrates that the addition of noise helps D provide gradients to G so that at anytime, G is able to escape its current modes. However, and due to the fact that D outputs are calculated from single examples there is no 'coverage guarantee', for example G could keep switching between different modes. Is this right ? Minibatch discrimination appears to be a good first way to answer this, although not 100% satisfactory because the metric is combinatorial... What is your view on these practical considerations ?\n\nMany thanks !\n\nArnaud Sors", "OTHER_KEYS": "Arnaud Sors"}, {"IMPACT": 3, "OTHER_KEYS": "ICLR 2017 conference AnonReviewer2", "TITLE": "final evaluation - strong submission", "comments": "Very good paper, I hope it will be accepted. I keep my original evaluation.", "ORIGINALITY": 2, "IS_ANNOTATED": true, "IS_META_REVIEW": false, "DATE": "20 Jan 2017"}, {"DATE": "12 Jan 2017", "TITLE": "New version", "IS_META_REVIEW": false, "comments": "Hi! We would like to comment that we added a revision with the following changes at its core:\n\n- We extended the proofs and definitions in section 2 to work with manifolds with boundary.\n\n- We included a one page Appendix B with further clarifications for the things that were suggested in the comments, such as a small comment on continuity vs absolute continuity of random variables, and how it is relevant to our paper.\n\n- We did some minor rewriting to take into account the suggestions from the reviewers and commenters.\n\n- We fixed all the typos :)\n\nBest!\nMartin", "OTHER_KEYS": "Martin Arjovsky"}, {"DATE": "03 Jan 2017", "TITLE": "Very good paper", "IS_META_REVIEW": false, "comments": "I think this paper is a very good step towards interpreting and understanding GANs. While some experiments have been (often successfully) done with adding noise, there was no theoretical reason, mainly intuition and hand waving.\nThis paper clearly states the reason why these methods work, by pointing a fundamental pitfall in GANs that was overlooked so far.\nI believe that this is a crucial step towards making useful, large scale GANs.\n\nSome notes and typos (sorry if it was already addressed in previous comments):\n- First paragraph of section 2, the cost part is quite unclear (it\u2019s the negative of what was described earlier (after equation 2), and the words \"maximizing\" and \"minimizing\" are mixed).\n- Definition 2.1: what is the tangent space of the whole space around a point? Isn\u2019t it just the point? I think you mean TxM + TxP = F . Also, I thin the + should be a (+) (vector space sum)\n- Bottom of page 4, before Lemma 2: its -> their (intersection)\n- Maybe I'm not familiar enough with the vocabulary, but I did not quite understand what you meant by \"non continuous distribution\", despite the footnote. As a consequence, it took me until much later in the paper to fully understand the link between non-continuous and low-dimensional manifold.\n- There is a numbering problem. In particular, theorem 2.6 refers to theorems 1.1 and 1.2, which don\u2019t exist.\n- Theorem 2.6: I think the definition and role of epsilon could be clarified.\n- Corollary 3.2: missing a tilde, g -> g_\\theta\n- Paragraph above lemma 4: missing \u2018)\u2019 after JSD(...", "OTHER_KEYS": "Michael Mathieu"}, {"DATE": "28 Dec 2016", "TITLE": "last paragraph", "IS_META_REVIEW": false, "comments": "I've always considered myself something of a GAN sceptic, so I'm very excited to see so many papers popping up that try to analyse and address their shortcomings. There are many ICLR submissions on this topic but I found this one a particularly enlightening read, nice work!\n\nThe last paragraph of the paper is perhaps the most interesting, as it seems to propose an alternative training method that would solve most of the problems: the gradients no longer vanish when the discriminator is trained to convergence, which eliminates the careful balancing act that GAN training currently requires.\n\nBut unfortunately the paper ends there, with no discussion of how this would be implemented in practice and no experiments to demonstrate the proposed solution. Is this work that is currently underway? It seems like an excellent idea so it's strange that only one paragraph of the paper is dedicated to it (although admittedly the paper is already quite long).", "OTHER_KEYS": "Sander Dieleman"}, {"DATE": "24 Dec 2016", "TITLE": "Revision", "IS_META_REVIEW": false, "comments": "Hi! We would first like to thank the reviewers for your comments. We will aim to make all the suggestions fit into a revision. We will update the paper shortly and provide individual responses to the reviews :)\n\nBest!\nMartin", "OTHER_KEYS": "Martin Arjovsky"}, {"TITLE": "good submission", "MEANINGFUL_COMPARISON": 3, "OTHER_KEYS": "ICLR 2017 conference AnonReviewer3", "comments": "This paper makes a valuable contribution to provide a more clear understanding of generative adversarial network (GAN) training procedure. \n\nWith the new insight of the training dynamics of GAN, as well as its variant, the authors reveal the reason that why the gradient is either vanishing in original GAN or unstable in its variant. More importantly, they also provide a way to avoid such difficulties by introducing perturbation. I believe this paper will inspire more principled research in this direction. \n\nI am very interested in the perturbation trick to avoid the gradient instability and vanishment. In fact, this is quite related to dropout trick in where the perturbation can be viewed as Bernoulli distribution. It will be great if the connection can be discussed.  Besides the theoretical analysis, is there any empirical study to justify this trick? Could you please add some experiments like Fig 2 and 3 for the perturbated GAN for comparison? ", "ORIGINALITY": 2, "IS_ANNOTATED": true, "IS_META_REVIEW": false, "RECOMMENDATION": 8, "DATE": "20 Dec 2016", "APPROPRIATENESS": 2, "REVIEWER_CONFIDENCE": 3}, {"IMPACT": 3, "OTHER_KEYS": "ICLR 2017 conference AnonReviewer2", "TITLE": "next steps", "comments": "", "ORIGINALITY": 2, "IS_ANNOTATED": true, "IS_META_REVIEW": false, "DATE": "19 Dec 2016"}, {"IMPACT": 3, "OTHER_KEYS": "ICLR 2017 conference AnonReviewer2", "TITLE": "very interesting submission", "comments": "This is a strong submission regarding one of the most important and recently introduced methods in neural networks - generative adversarial networks. The authors analyze theoretically the convergence of GANs and discuss the stability of GANs. Both are very important. To the best of my knowledge, this is one of the first theoretical papers about GANs and the paper, contrary to most of the submissions in the field, actually provides deep theoretical insight into this architecture. The stability issues regarding GANs are extremely important since the first proposed versions of GANs architecture were very unstable and did not work well in practice. Theorems 2.4-2.6 are novel and introduces mathematical techniques are interesting. I have some technical questions regarding the proof of Theorem 2.5 but these are pretty minor.\n", "ORIGINALITY": 2, "IS_ANNOTATED": true, "IS_META_REVIEW": false, "RECOMMENDATION": 10, "DATE": "19 Dec 2016", "REVIEWER_CONFIDENCE": 5}, {"TITLE": "review of ``TOWARDS PRINCIPLED METHODS FOR TRAINING GENERATIVE ADVERSARIAL NETWORKS'' ", "MEANINGFUL_COMPARISON": 4, "RECOMMENDATION_UNOFFICIAL": 2, "comments": "SUMMARY \nThis paper addresses important questions about the difficulties in training generative adversarial networks. It discusses consequences of using an asymmetric divergence function and sources of instability in training GANs. Then it proposes an alternative using a smoothening approach. \n\nPROS \nTheory, good questions, nice answers. \nMakes an interesting use of concepts form analysis and differential topology. \nProposes avenues to avoid instability in GANs. \n\nCONS \nA bit too long, technical. Some parts and consequences still need to be further developed (which is perfectly fine for future work). \n\nMINOR COMMENTS\n\n- Section 2.1 Maybe shorten this section a bit. E.g., move all proofs to the appendix. \n\n- Section 3 provides a nice, intuitive, simple solution. \n\n- On page 2 second bullet. This also means that P_g is smaller than the data distribution in some other x, which in turn will make the KL divergence non zero. \n\n- On page 2, ``for not generating plausibly looking pictures'' should be ``for generating not plausibly looking pictures''.  \n\n- Lemma 1 would also hold in more generality. \n\n- Theorem 2.1 seems to be basic analysis. (In other words, a reference could spare the proof). \n\n- In Theorem 2.4, it would be good to remind the reader about p(z). \n\n- Lemma 2 seems to be basic analysis. (In other words, a reference could spare the proof). \nSpecify the domain of the random variables. \n\n- relly - > rely \n\n- Theorem 2.2 the closed manifolds have boundary or not? (already in the questions)\n\n- Corollary 2.1, ``assumptions of Theorem 1.3''. I could not find Theorem 1.3. \n\n- Theorem 2.5 ``Therefore'' -> `Then'? \n\n- Theorem 2.6 ``Is a... '' -> `is a' ? \n\n- The number of the theorems is confusing. \n", "SOUNDNESS_CORRECTNESS": 4, "IS_ANNOTATED": true, "IS_META_REVIEW": false, "RECOMMENDATION": 7, "DATE": "19 Dec 2016", "CLARITY": 4, "OTHER_KEYS": "ICLR 2017 conference AnonReviewer1", "REVIEWER_CONFIDENCE": 4}, {"TITLE": "very solid contribution to the theoretical understanding of GANS", "OTHER_KEYS": "(anonymous)", "comments": "This is a strong submission regarding one of the most important and recently introduced methods in neural networks - generative adversarial networks. The authors analyze theoretically the convergence of GANs and discuss the stability of GANs. Both are very important. To the best of my knowledge, this is one of the first theoretical papers about GANs and the paper, contrary to most of the submissions in the field, actually provides deep theoretical insight into this architecture. The stability issues regarding GANs are extremely important since the first proposed versions of GANs architecture were very unstable and did not work well in practice. Theorems 2.4-2.6 are novel and introduces mathematical techniques are interesting. I have some technical questions regarding the proof of Theorem 2.5 but these are pretty minor.", "IS_META_REVIEW": false, "RECOMMENDATION": 10, "DATE": "17 Dec 2016", "REVIEWER_CONFIDENCE": 5}, {"DATE": "16 Dec 2016", "TITLE": "Questions and inconsistencies.", "IS_META_REVIEW": false, "comments": "This paper makes many valuable contributions and explains many of the issues related to training GANs; I feel it will be an essential platform for future work. However I have the following questions and found the following inconsistencies.\n\n1) \n\t\u201cIf n <= d, we are done since the image of \u03c0 is contained in all Rn, a manifold with at \n\tmost dimension d. We now turn to the case where d > n.\u201d\n\nIs the case  d>n  not contained in the first,  n<=d ? Should this be n>d?\n\n2) The perfect discriminator theorems: \n\n\t\u201cWe say that a discriminator D : X \u2192 [0, 1] has accuracy 1 if it takes the value 1 on a set that \n\tcontains the support of P_r  and value 0 on a set that contains the support of P_g .\u201d\n\nIf a set S_g or S_r contains the support of P_g or P_r, this suggests that it may contain the support but may also contain regions outside of the support.  Are you suggesting that for x in S_r that are outside the support of P_r, D(x)=1? However, surely regions outside the support of P_r should correspond to generated images, so D(x) should be 0.\n\nb) Following from a), if a set S_g (or S_r) contained regions outside the support (as well as the support) then S_g (or S_r)  would contain the support of P_g (or P_r) but may also contain regions in the support of P_r (or P_g).\n\n3) \n\t\tP_r[D(x) = 1] = 1 and P_g[D(x) = 0] = 1 \n\na) This notation is not clear, do you mean:\n\tP_r(x)=1 for all x in {x : D(x)=1} and P_g(x)=1 for all x in {x : D(x)=0}\n\n4) Theorem 2.1\n\na) It is not clear what distance measure you are using between sets\nb) Where does the delta/3 come from? Is this arbitrary?\n\n5) Theorem 2.2\na) What is P^c?\nb) Is the ball B(x,e_x) defined for all x in M\\L? This is not explicit.\n\nIf defined for all x in M\\L:\nc) For x on the boundary of M\\L and P\\L is e_x=0? Otherwise, is it possible that for x on the boundary of M\\L or P\\L , M_hat and P_hat intersect with P\\L or M\\L respectively? \n\nFinally:\nd) M_hat is a superset of M\\L, how can you say D*(x)=1 for all x in M_hat, when M_hat may include regions outside the support of M?\n\n9) Corollary 2.1; \n\t\"Under the same assumptions of Theorem 1.3\u2028\"\na) What is Theorem 1.3?\n\n11) Theorem 2.5 \na) Could this be explicitly linked to the collapsing generator problem talked about by [1] and [2].  Citations might make the link clearer. \n\n12) Theorem 2.6 \na) Why do you assume that the distribution of difference between D and D* is white noise? This suggests that most of the time D is optimal, from the rest of the paper this is believable, however if this is what you are assuming, this could be made more explicit. \nb) Similar question for difference in gradient, though since grad D* is zero most of the time, that would suggest that grad D is zero most of the time. Is this true?\nc) extra bracket in final line of proof\n\n16) \n       \u201cThis is in drastic contrast to the noiseless variants P_g  and P_g,\u201d\na) repeated P_g\n\n17) \n         \u201cagain that JSD(P_x,P_{x+e} is maxed out,\u201d\na) missing bracket and inconsistent notation, JSD(P_x||P_{x+e})\nb) \u201cmaxed out\u201c is a colloquialism\n\n[1] Salimans, Tim, et al. \"Improved techniques for training gans.\" arXiv preprint arXiv:1606.03498 (2016).\n[2]Odena, Augustus, Christopher Olah, and Jonathon Shlens. \"Conditional Image Synthesis With Auxiliary Classifier GANs.\" arXiv preprint arXiv:1610.09585 (2016).", "OTHER_KEYS": "Antonia Creswell"}, {"TITLE": "minor questions", "MEANINGFUL_COMPARISON": 4, "RECOMMENDATION_UNOFFICIAL": 2, "comments": "", "SOUNDNESS_CORRECTNESS": 4, "IS_ANNOTATED": true, "IS_META_REVIEW": false, "DATE": "02 Dec 2016", "CLARITY": 4, "OTHER_KEYS": "ICLR 2017 conference AnonReviewer1"}], "authors": "Martin Arjovsky, Leon Bottou", "accepted": true, "id": "308"}