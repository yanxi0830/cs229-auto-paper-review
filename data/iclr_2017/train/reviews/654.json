{"conference": "ICLR 2017 conference submission", "title": "The Variational Walkback Algorithm", "abstract": "A recognized obstacle to training undirected graphical models with latent variables such as Boltzmann machines is that the maximum likelihood training procedure requires sampling from Monte-Carlo Markov chains which may not mix well, in the inner loop of training, for each example.  We first propose the idea that it is sufficient to locally carve the energy function everywhere so that its gradient points in the \"right\" direction (i.e., towards generating the data). Following on previous work on contrastive divergence, denoising autoencoders, generative stochastic networks and unsupervised learning using non-equilibrium dynamics, we propose a variational bound on the marginal log-likelihood of the data which corresponds to a new learning procedure that first walks away from data points by following the model transition operator and then trains that operator to walk backwards for each of these steps, back towards the training example. The tightness of the variational bound relies on gradually increasing temperature as we walk away from the data, at each step providing a gradient on the parameters to maximize the probability that the transition operator returns to its previous state. Interestingly, this algorithm admits a variant where there is no explicit energy function, i.e., the parameters are used to directly define the transition operator. This also eliminates the explicit need for symmetric weights which previous Boltzmann machine or Hopfield net models require, and which makes these models less biologically plausible.", "histories": [], "reviews": [{"IS_META_REVIEW": true, "comments": "This paper proposes a new kind of generative model based on an annealing process, where the transition probabilities are learned directly to maximize a variational lower bound on the log-likelihood. Overall, the idea is clever and appealing, but I think the paper needs more quantitative validation and better discussion of the relationship with prior work.\n\nIn terms of prior work, AIS and RAISE are both closely related algorithms, and share much of the mathematical structure with the proposed method. For this reason, it\u2019s not sufficient to mention them in passing in the related work section; those methods and their relationship to variational walkback need to be discussed in detail. If I understand correctly, the proposed method is essentially an extension of RAISE where the transition probabilities are learned rather than fixed based on an existing MRF. I think this is an interesting and worthwhile extension, but the relationship to existing work needs to be clarified.\n\nThe analysis of Appendix D seems incorrect. It derives a formula for the ratios of prior and posterior probabilities, but this formula only holds under the assumption of constant temperature (in which case the ratio is very large). When the temperature is varied, the analysis of Neal (2001) applies, and the answer is different. \n\nOne of the main selling points of the method is that it optimizes a variational lower bound on the log-likelihood; even more accurate estimates can be obtained using importance sampling. It ought to be easy to report log-likelihood estimates for this method, so I wonder why such estimates aren\u2019t reported. There are lots of prior results to compare against on MNIST. (In addition, a natural baseline would be RAISE, so that one can check if the ability to learn the transitions actually helps.)\n\nI think the basic idea here is a sound one, so I would be willing to raise my score if the above issues are addressed in a revised version.\n\n\nMinor comments:\n\n\u201cA recognized obstacle to training undirected graphical models\u2026 is that ML training requires sampling from MCMC chains in the inner loop of training, for each example.\u201d This seems like an unfair characterization, since the standard algorithm is PCD, which usually takes only a single step per mini-batch.\n\nSome of the methods discussed in the related work are missing citations.\n\nThe method is justified in terms of \u201ccarving the energy function in the right direction at each point\u201d, but I\u2019m not sure this is actually what\u2019s happening. Isn\u2019t the point of the method that it can optimize a lower bound on the log-likelihood, and therefore learn a globally correct allocation of probability mass?"}, {"DATE": "06 Feb 2017", "TITLE": "ICLR committee final decision", "IS_META_REVIEW": false, "comments": "This paper proposes an algorithm for training undirected probabilistic graphical models. However, there are technical concerns of correctness that haven't been responded to. It also wasn't felt the method was evaluated appropriately.", "OTHER_KEYS": "ICLR 2017 pcs"}, {"TITLE": "Review", "OTHER_KEYS": "ICLR 2017 conference AnonReviewer4", "comments": "The authors present a method for training probabilistic models by maximizing a stochastic variational-lower-bound-type objective. Training involves sampling and then learning a transition-based inference to \"walk back\" samples to the data. Because of its focus on transitions, it can be used to learn a raw transition operator rather than purely learning an energy-based model. The objective is intuitively appealing because of its similarity to previous successful but less principled training methods for MRFs like Contrastive Divergence.\n\nThe idea for the algorithm is appealing, and it looks like it could find a nice place in the literature. However, the submission in its current form is not yet ready for publication. Experiments are qualitative and the generated samples are not obviously indicative of a high model quality. As pointed out elsewhere, the mathematical analysis does not currently demonstrate tightness of the variational bound in the case of a learned transition operator. More evaluation using e.g. annealed importance sampling to estimate held-out likelihoods is necessary. Assuming that the analysis can be repaired, the ability to directly parametrize a transition operator, an interesting strength of this method, should be explored in further experiments and contrasted with the more standard energy-based modeling.\n\nThis looks like a promising idea, and other reviews and questions have already raised some important technical points which should help strengthen this paper for future submission.", "IS_META_REVIEW": false, "RECOMMENDATION": 4, "DATE": "20 Dec 2016", "REVIEWER_CONFIDENCE": 4}, {"TITLE": "Like the underlying idea, not convinced by its current incarnation", "OTHER_KEYS": "ICLR 2017 conference AnonReviewer1", "comments": "I very much like the underlying idea for this paper. I wasn't convinced by the execution in its current state. My primary concern is the one I expressed in my pre-review question below, which I don't think the authors addressed. Specifically, I think the choice of q(s | s') = p(s | s') will make the forward and reverse trajectories almost pathologically mismatched to each other, and will thus make the variational bound extremely loose and high variance. \n\nThe claim about the tightness of the bound in Appendix D relies on the assumption that the transition distribution obeys detailed balance. The learned transition distribution in the paper does not obey detailed balance, and therefore the tightness claim in Appendix D does not hold. (In Section 2.1 you briefly discuss the idea of learning an energy function, rather than directly learning a transition distribution. I think this would be excellent, and in that case you could choose an MCMC transition operator that does obey detailed balance for that energy function.) I did not go through Appendix D beyond this step.\n\nThe experimental results were not visually impressive. I suspect this is primarily driven by the mismatch between generative and inference trajectories. See my concern above and in the pre-review question below.\n\nAlso, see note below for sec. 5. I suspect some terms are being dropped from the training gradient.\n\nThe paper is optimizing a variational bound on log likelihood. You should really, really, really report and compare log likelihoods against competing methods!\n\nDetailed comments below. Some of these were written based on a previous version of the paper.\nsec 1.2 - first paragraph is very difficult to follow\n\"these modes these spurious modes\" -> \"these spurious modes\"\nsec 2.1 - \"s = (v,h)\" -> \"s = {v,h}\"\nsec 2.2 - \"with an MCMC\" -> \"with an MCMC chain\"\n\"(ideally an MCMC)\" -> \"(e.g. via MCMC)\" MCMC is not ideal ... it's just often the best we can do.\nsec 3, last bullet - could make the temperature infinite for the last step, in which case the last step will sample directly from the prior, and the posterior and the prior will be exactly the same.\nsec. 4 -- Using an energy function would be great!! Especially, because many MCMC transition operators obey detailed balance, you would be far less prone to suffer from the forward/backward transition mismatch that is my primary concern about this technique.\neq. 12,13 -- What is alpha? How does it depend on the temperature. It's never specified.\nsec. 5, last paragraph in GSN section -- Note that q also depends on theta, so by not backpropagating through the full q chain you are dropping terms from the gradient.\nsec. 5, non-equilibrium thermodynamics -- Note that the noneq. paper also increases the noise variance as the distance from the data increases.\nFig. 1 -- right/left mislabeled\nFig. 2 -- label panes\nFig. 3 -- After how many walkback steps?", "IS_META_REVIEW": false, "RECOMMENDATION": 5, "DATE": "16 Dec 2016", "REVIEWER_CONFIDENCE": 5}, {"TITLE": "clever idea, but needs more quantitative validation and discussion of (closely) related work", "OTHER_KEYS": "ICLR 2017 conference AnonReviewer3", "comments": "This paper proposes a new kind of generative model based on an annealing process, where the transition probabilities are learned directly to maximize a variational lower bound on the log-likelihood. Overall, the idea is clever and appealing, but I think the paper needs more quantitative validation and better discussion of the relationship with prior work.\n\nIn terms of prior work, AIS and RAISE are both closely related algorithms, and share much of the mathematical structure with the proposed method. For this reason, it\u2019s not sufficient to mention them in passing in the related work section; those methods and their relationship to variational walkback need to be discussed in detail. If I understand correctly, the proposed method is essentially an extension of RAISE where the transition probabilities are learned rather than fixed based on an existing MRF. I think this is an interesting and worthwhile extension, but the relationship to existing work needs to be clarified.\n\nThe analysis of Appendix D seems incorrect. It derives a formula for the ratios of prior and posterior probabilities, but this formula only holds under the assumption of constant temperature (in which case the ratio is very large). When the temperature is varied, the analysis of Neal (2001) applies, and the answer is different. \n\nOne of the main selling points of the method is that it optimizes a variational lower bound on the log-likelihood; even more accurate estimates can be obtained using importance sampling. It ought to be easy to report log-likelihood estimates for this method, so I wonder why such estimates aren\u2019t reported. There are lots of prior results to compare against on MNIST. (In addition, a natural baseline would be RAISE, so that one can check if the ability to learn the transitions actually helps.)\n\nI think the basic idea here is a sound one, so I would be willing to raise my score if the above issues are addressed in a revised version.\n\n\nMinor comments:\n\n\u201cA recognized obstacle to training undirected graphical models\u2026 is that ML training requires sampling from MCMC chains in the inner loop of training, for each example.\u201d This seems like an unfair characterization, since the standard algorithm is PCD, which usually takes only a single step per mini-batch.\n\nSome of the methods discussed in the related work are missing citations.\n\nThe method is justified in terms of \u201ccarving the energy function in the right direction at each point\u201d, but I\u2019m not sure this is actually what\u2019s happening. Isn\u2019t the point of the method that it can optimize a lower bound on the log-likelihood, and therefore learn a globally correct allocation of probability mass?\n", "IS_META_REVIEW": false, "RECOMMENDATION": 4, "DATE": "16 Dec 2016", "REVIEWER_CONFIDENCE": 5}, {"DATE": "02 Dec 2016", "TITLE": "Question", "IS_META_REVIEW": false, "comments": "", "OTHER_KEYS": "ICLR 2017 conference AnonReviewer4"}, {"DATE": "30 Nov 2016", "TITLE": "matching inference and generative chains", "IS_META_REVIEW": false, "comments": "", "OTHER_KEYS": "ICLR 2017 conference AnonReviewer1"}, {"DATE": "30 Nov 2016", "TITLE": "relationship with prior work?", "IS_META_REVIEW": false, "comments": "", "OTHER_KEYS": "ICLR 2017 conference AnonReviewer3"}, {"IS_META_REVIEW": true, "comments": "This paper proposes a new kind of generative model based on an annealing process, where the transition probabilities are learned directly to maximize a variational lower bound on the log-likelihood. Overall, the idea is clever and appealing, but I think the paper needs more quantitative validation and better discussion of the relationship with prior work.\n\nIn terms of prior work, AIS and RAISE are both closely related algorithms, and share much of the mathematical structure with the proposed method. For this reason, it\u2019s not sufficient to mention them in passing in the related work section; those methods and their relationship to variational walkback need to be discussed in detail. If I understand correctly, the proposed method is essentially an extension of RAISE where the transition probabilities are learned rather than fixed based on an existing MRF. I think this is an interesting and worthwhile extension, but the relationship to existing work needs to be clarified.\n\nThe analysis of Appendix D seems incorrect. It derives a formula for the ratios of prior and posterior probabilities, but this formula only holds under the assumption of constant temperature (in which case the ratio is very large). When the temperature is varied, the analysis of Neal (2001) applies, and the answer is different. \n\nOne of the main selling points of the method is that it optimizes a variational lower bound on the log-likelihood; even more accurate estimates can be obtained using importance sampling. It ought to be easy to report log-likelihood estimates for this method, so I wonder why such estimates aren\u2019t reported. There are lots of prior results to compare against on MNIST. (In addition, a natural baseline would be RAISE, so that one can check if the ability to learn the transitions actually helps.)\n\nI think the basic idea here is a sound one, so I would be willing to raise my score if the above issues are addressed in a revised version.\n\n\nMinor comments:\n\n\u201cA recognized obstacle to training undirected graphical models\u2026 is that ML training requires sampling from MCMC chains in the inner loop of training, for each example.\u201d This seems like an unfair characterization, since the standard algorithm is PCD, which usually takes only a single step per mini-batch.\n\nSome of the methods discussed in the related work are missing citations.\n\nThe method is justified in terms of \u201ccarving the energy function in the right direction at each point\u201d, but I\u2019m not sure this is actually what\u2019s happening. Isn\u2019t the point of the method that it can optimize a lower bound on the log-likelihood, and therefore learn a globally correct allocation of probability mass?"}, {"DATE": "06 Feb 2017", "TITLE": "ICLR committee final decision", "IS_META_REVIEW": false, "comments": "This paper proposes an algorithm for training undirected probabilistic graphical models. However, there are technical concerns of correctness that haven't been responded to. It also wasn't felt the method was evaluated appropriately.", "OTHER_KEYS": "ICLR 2017 pcs"}, {"TITLE": "Review", "OTHER_KEYS": "ICLR 2017 conference AnonReviewer4", "comments": "The authors present a method for training probabilistic models by maximizing a stochastic variational-lower-bound-type objective. Training involves sampling and then learning a transition-based inference to \"walk back\" samples to the data. Because of its focus on transitions, it can be used to learn a raw transition operator rather than purely learning an energy-based model. The objective is intuitively appealing because of its similarity to previous successful but less principled training methods for MRFs like Contrastive Divergence.\n\nThe idea for the algorithm is appealing, and it looks like it could find a nice place in the literature. However, the submission in its current form is not yet ready for publication. Experiments are qualitative and the generated samples are not obviously indicative of a high model quality. As pointed out elsewhere, the mathematical analysis does not currently demonstrate tightness of the variational bound in the case of a learned transition operator. More evaluation using e.g. annealed importance sampling to estimate held-out likelihoods is necessary. Assuming that the analysis can be repaired, the ability to directly parametrize a transition operator, an interesting strength of this method, should be explored in further experiments and contrasted with the more standard energy-based modeling.\n\nThis looks like a promising idea, and other reviews and questions have already raised some important technical points which should help strengthen this paper for future submission.", "IS_META_REVIEW": false, "RECOMMENDATION": 4, "DATE": "20 Dec 2016", "REVIEWER_CONFIDENCE": 4}, {"TITLE": "Like the underlying idea, not convinced by its current incarnation", "OTHER_KEYS": "ICLR 2017 conference AnonReviewer1", "comments": "I very much like the underlying idea for this paper. I wasn't convinced by the execution in its current state. My primary concern is the one I expressed in my pre-review question below, which I don't think the authors addressed. Specifically, I think the choice of q(s | s') = p(s | s') will make the forward and reverse trajectories almost pathologically mismatched to each other, and will thus make the variational bound extremely loose and high variance. \n\nThe claim about the tightness of the bound in Appendix D relies on the assumption that the transition distribution obeys detailed balance. The learned transition distribution in the paper does not obey detailed balance, and therefore the tightness claim in Appendix D does not hold. (In Section 2.1 you briefly discuss the idea of learning an energy function, rather than directly learning a transition distribution. I think this would be excellent, and in that case you could choose an MCMC transition operator that does obey detailed balance for that energy function.) I did not go through Appendix D beyond this step.\n\nThe experimental results were not visually impressive. I suspect this is primarily driven by the mismatch between generative and inference trajectories. See my concern above and in the pre-review question below.\n\nAlso, see note below for sec. 5. I suspect some terms are being dropped from the training gradient.\n\nThe paper is optimizing a variational bound on log likelihood. You should really, really, really report and compare log likelihoods against competing methods!\n\nDetailed comments below. Some of these were written based on a previous version of the paper.\nsec 1.2 - first paragraph is very difficult to follow\n\"these modes these spurious modes\" -> \"these spurious modes\"\nsec 2.1 - \"s = (v,h)\" -> \"s = {v,h}\"\nsec 2.2 - \"with an MCMC\" -> \"with an MCMC chain\"\n\"(ideally an MCMC)\" -> \"(e.g. via MCMC)\" MCMC is not ideal ... it's just often the best we can do.\nsec 3, last bullet - could make the temperature infinite for the last step, in which case the last step will sample directly from the prior, and the posterior and the prior will be exactly the same.\nsec. 4 -- Using an energy function would be great!! Especially, because many MCMC transition operators obey detailed balance, you would be far less prone to suffer from the forward/backward transition mismatch that is my primary concern about this technique.\neq. 12,13 -- What is alpha? How does it depend on the temperature. It's never specified.\nsec. 5, last paragraph in GSN section -- Note that q also depends on theta, so by not backpropagating through the full q chain you are dropping terms from the gradient.\nsec. 5, non-equilibrium thermodynamics -- Note that the noneq. paper also increases the noise variance as the distance from the data increases.\nFig. 1 -- right/left mislabeled\nFig. 2 -- label panes\nFig. 3 -- After how many walkback steps?", "IS_META_REVIEW": false, "RECOMMENDATION": 5, "DATE": "16 Dec 2016", "REVIEWER_CONFIDENCE": 5}, {"TITLE": "clever idea, but needs more quantitative validation and discussion of (closely) related work", "OTHER_KEYS": "ICLR 2017 conference AnonReviewer3", "comments": "This paper proposes a new kind of generative model based on an annealing process, where the transition probabilities are learned directly to maximize a variational lower bound on the log-likelihood. Overall, the idea is clever and appealing, but I think the paper needs more quantitative validation and better discussion of the relationship with prior work.\n\nIn terms of prior work, AIS and RAISE are both closely related algorithms, and share much of the mathematical structure with the proposed method. For this reason, it\u2019s not sufficient to mention them in passing in the related work section; those methods and their relationship to variational walkback need to be discussed in detail. If I understand correctly, the proposed method is essentially an extension of RAISE where the transition probabilities are learned rather than fixed based on an existing MRF. I think this is an interesting and worthwhile extension, but the relationship to existing work needs to be clarified.\n\nThe analysis of Appendix D seems incorrect. It derives a formula for the ratios of prior and posterior probabilities, but this formula only holds under the assumption of constant temperature (in which case the ratio is very large). When the temperature is varied, the analysis of Neal (2001) applies, and the answer is different. \n\nOne of the main selling points of the method is that it optimizes a variational lower bound on the log-likelihood; even more accurate estimates can be obtained using importance sampling. It ought to be easy to report log-likelihood estimates for this method, so I wonder why such estimates aren\u2019t reported. There are lots of prior results to compare against on MNIST. (In addition, a natural baseline would be RAISE, so that one can check if the ability to learn the transitions actually helps.)\n\nI think the basic idea here is a sound one, so I would be willing to raise my score if the above issues are addressed in a revised version.\n\n\nMinor comments:\n\n\u201cA recognized obstacle to training undirected graphical models\u2026 is that ML training requires sampling from MCMC chains in the inner loop of training, for each example.\u201d This seems like an unfair characterization, since the standard algorithm is PCD, which usually takes only a single step per mini-batch.\n\nSome of the methods discussed in the related work are missing citations.\n\nThe method is justified in terms of \u201ccarving the energy function in the right direction at each point\u201d, but I\u2019m not sure this is actually what\u2019s happening. Isn\u2019t the point of the method that it can optimize a lower bound on the log-likelihood, and therefore learn a globally correct allocation of probability mass?\n", "IS_META_REVIEW": false, "RECOMMENDATION": 4, "DATE": "16 Dec 2016", "REVIEWER_CONFIDENCE": 5}, {"DATE": "02 Dec 2016", "TITLE": "Question", "IS_META_REVIEW": false, "comments": "", "OTHER_KEYS": "ICLR 2017 conference AnonReviewer4"}, {"DATE": "30 Nov 2016", "TITLE": "matching inference and generative chains", "IS_META_REVIEW": false, "comments": "", "OTHER_KEYS": "ICLR 2017 conference AnonReviewer1"}, {"DATE": "30 Nov 2016", "TITLE": "relationship with prior work?", "IS_META_REVIEW": false, "comments": "", "OTHER_KEYS": "ICLR 2017 conference AnonReviewer3"}], "authors": "Anirudh Goyal, Nan Rosemary Ke, Alex Lamb, Yoshua Bengio", "accepted": false, "id": "654"}