{
  "name" : "513.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : null,
    "authors" : [ "Mehdi Mirza", "Aaron Courville", "Yoshua Bengio" ],
    "emails" : [ "yoshua.umontreal}@gmail.com" ],
    "sections" : [ {
      "heading" : "1 INTRODUCTION",
      "text" : "Humans learn a tremendous amount of knowledge about the world with almost no supervision and can construct a predictive model of the world. We use this model of the world to interact with our environment. As also argued by Lake et al. (2016) one of the core ingredients of human intelligence is intuitive physics. Children can learn and predict some of the common physical behaviors of our world just by observing and interacting without any direct supervision. And they form a sophisticated predictive model of the physical environment and expect the world to behave based on their mental model and have a reasonable expectation about unseen situations Téglás et al. (2011).\nDespite impressive progress in the last few years in the training of the supervised models, we have not yet quite been able to achieve similar results in unsupervised learning, and it remains one of the challenging research areas in the field. The full potential of the application of unsupervised learning is yet to be realized.\nIn this work, we leverage unsupervised learning to train a predictive model over sequences. We use the imagined and predicted future sequence data to help a physical environment prediction model generalize better to unseen settings.\nMore specifically we focus on the task of predicting if a tower of square bricks will fall or not, as introduced by Lerer et al. (2016). They showed that a deep convolution neural network could predict the fall of the towers with super-human accuracy. But despite the strengths of convolution neural networks, Zhang et al. (2016) shows how deep neural networks have a hard time generalizing to novel situations in the same way as humans or simulation-based models can do. In this work, we show that deep neural networks are capable of generalizing to novel situations through a form of unsupervised learning. The core idea is to observe the world without any supervision and build a future predictive model of it, and in a later stage leverage and utilize the imagined future to train a better fall prediction model."
    }, {
      "heading" : "2 RELATED WORK",
      "text" : "In the beginning, unsupervised learning and generative models emerged as pre-training method Hinton & Salakhutdinov (2006); Hinton et al. (2006); Bengio et al. (2007) to help other tasks such as\nsupervised learning. But since Krizhevsky et al. (2012) many other regularization Srivastava et al. (2014), weight initialization Glorot & Bengio (2010) and normalization Ioffe & Szegedy (2015) techniques and architecture designs He et al. (2015) has been introduced that diminish the effect of pre-training. Although pre-training still could be useful in data scarce domains they are many other ways and applications that unsupervised learning are still very interesting models and it is a very active area of research. Just to name a few applications are semi-supervised learning Kingma et al. (2014); Salimans et al. (2016); Dumoulin et al. (2016) super resolution Sønderby et al. (2016).\nVideo generation is one active area of research with many applications, and many of the recent works have been using some of the states of the art neural networks for video generation. Srivastava et al. (2015) uses LSTM recurrent neural networks to train an unsupervised future predictive model for video generation. And here we use a very similar architecture as described in Section 4.1. Mathieu et al. (2015) combines the common mean-squared-error objective function with an adversarial training cost in order to generate sharper samples. Lotter et al. (2016) introduce another form of unsupervised video prediction training scheme that manages to predict future events such as the direction of the turn of a car which could have potential use in training of the self-driving cars.\nModel-based reinforcement learning (RL) is an active research area that holds the promise of making the RL agents less data hungry. Learning agents could explore, learn in an unsupervised way about their world, and learn even more by dreaming about future states. We believe that action-condition video prediction models are an important ingredient for this task. Fragkiadaki et al. (2015) learn the dynamics of billiards balls by supervised training of a neural net. Action-conditioned video prediction models have been applied to Atari playing agent Oh et al. (2015) as well as robotics (Finn et al., 2016; Finn & Levine, 2016)."
    }, {
      "heading" : "3 DATASET",
      "text" : "Recent datasets for predicting the stability of block configurations (Lerer et al., 2016; Zhang et al., 2016) only provide binary labels of stability, and exclude the video simulation of the block configuration. We, therefore, construct a new dataset, with a similar setup as Lerer et al. (2016); Zhang et al. (2016), that includes this video sequence. We use a Javascript based physics engine1 to generate the data.\nWe construct towers made of 3 − 5 square blocks. To sample a random tower configuration, we uniformly shift each block in its x and y position such that it touches the block below. Because taller towers are more unstable, this shift is smaller when we add more blocks. To simplify our learning setting, we balance the number of stable and unstable block configurations. For each tower height, we create 8000, 1000 and 3000 video clips for the training, validation, and test set, respectively. The video clips are sub-sampled in time to include more noticeable changes in the blocks configurations. We decided to keep 39 number of frames which with our sub-sampling rate was enough time for unstable towers to collapse. Each video frame is an RGB image of size 64x64. In addition to binary stability label, we include the number of blocks that fell down."
    }, {
      "heading" : "4 ARCHITECTURE",
      "text" : "The core idea of this paper is to use future state predictions of a generative video model to enhance the performance of a supervised prediction model. Our architecture consists of two separate modules:\nFrame predictor A generative model to predict future frames of a video sequence. This model is trained to either generate the last frame or the complete sequence of frames.\nStability predictor In the original task, stability is predicted from a static image of a block configuration. We explore whether, in addition to initial configuration, the last frame prediction of our unsupervised model improves the performance of the stability prediction.\nIn the following sections, we explore several different architectures for both modules.\n1https://chandlerprall.github.io/Physijs/"
    }, {
      "heading" : "4.1 FUTURE FRAME PREDICTION",
      "text" : "We consider two different model architectures for this task. The first one, named ConvDeconv, only takes the first frame as input and predicts the last frame of the video sequence. The architecture consist of a block of convolution and max-pooling layers. To compensate for the dimensionality reduction of the max-pooling layers, we have a fully-connected layer following the last max-pooling layer. And finally a subsequent block of deconvolution layers with the output size same as the model input size. All activation functions are ReLU(Nair & Hinton, 2010). See Table 1 for more details of the architecture. The objective function is the mean squared error between the generated last frame and the ground-truth frame; as a result, this training will not require any labels. We also experimented with an additional adversarial cost as in Mathieu et al. (2015) but did not observe any improvement for the stability prediction task. We hypothesize that although the adversarial objective function helps to have sharper images, such improved sample quality does not transfer to better stability prediction. Figure 1 shows a few examples of the generated data on the test set. Mean squared error is minimized using the AdaM Optimizer(Kingma & Ba, 2014) and we use earlystopping when the validation loss does not improve for 100 epochs.\nWe extend this ConvDeconv model in a second architecture, named ConvLSTMDeconv, to predict the next frame at each timestep. This model is composed of an LSTM architecture. The same convolutional and deconvolutional blocks as ConvDeconv is utilized to respectively input the current frame to the LSTM transition and output the next frame from the current LSTM state. The details of the ConvLSTMDeconv model architecture are shown in Table 2 and Figure 3 shows the diagram of the both architectures. During the training at each time step the ground-truth data feeds in to the model, but during the test time only the initial time step gets the first frame from the data and for subsequent time steps the generated frames from the previous time steps feed in to the model. The is similar setup to recurrent neural network language models Mikolov (2012), and this is necessary as during the test time we only have access to the first frame. As before, the model is trained to predict the next frame at each time step by minimizing the predictive mean-squared-error using AdaM optimizer and early-stopping. For training, we further subsample in time dimension and reduce the sequence length to 5-time steps. Figure 2 shows some sample generated sequences from the test set.\nLayer Type Output channels/Dimension Kernel/Pool size\n1 Conv 64 3× 3 2 MaxPool 64 4× 4 3 Conv 128 3× 3 4 MaxPool 64 3× 3 5 Conv 64 3× 3 6 MaxPool 64 3× 3 7 FC LSTM 2000 8 FC 64× 64× 3 9 DeConv 64 3× 3 10 DeConv 64 3× 3 11 DeConv 3 3× 3\nTable 2: ConvLSTMDeconv model architecture. FC stands for ”Fully Connected”."
    }, {
      "heading" : "4.2 STABILITY PREDICTION",
      "text" : "We have two supervised models for stability prediction. The first one will be a baseline that takes as input the first frame and predict the fall of the tower. For this model we use 50 layer ResNet\narchitecture from He et al. (2016). We trained the baseline model on each of the different tower heights 3, 4, 5. We call it the single model and name experiments 3S, 4S, 5S respectively for the number of blocks that it was trained on. The second model will be the one using the generated data: it takes as input the first frame and the generated last frame. It consisted of two 50 Layer ResNet blocks in parallel, one for the first frame and one for last frame and the last hidden layer of both models are concatenated together before a logistic regression layer (or Softmax in the case of non-binary labels). Both ResNet blocks share parameters. Based on whether the generated data is coming from ConvDeconv model or ConvLSTMDeconv model we labeled experiments as 3CD, 4CD, 5CD and 3CLD, 4CLD, 5CLD respectively.\nNone of the models are pre-trained and all the weights are randomly initialized. As in 4.1, we use AdaM and we stopped the training when the validation accuracy was not improved for 100 epochs. All images are contrast normalized independently and we augment our training set using random horizontal flip of the images and randomly changing the contrast and brightness."
    }, {
      "heading" : "5 RESULTS",
      "text" : "Figure 4 shows the classification results for each of the 9 models described in Section 4.2 tested on 3, 4 and 5 blocks. Each test case is shown with a different color. And Table 3 shows all the 27 test case results’ numerical values. In almost all cases the generated data improves the generalization performance to test cases with a different number of blocks than it was trained on. For comparison we have included results from Zhang et al. (2016) in Table 4. Since Zhang et al. (2016) only reports the results when the models are trained on tower of 4 blocks, the corresponding results would be the second block row in Table 3, models 4S, 4CD and 4CLD. Even though the datasets are not the same, but it can be observed that the range of performance of the baseline 4S model is consistent with the range of performance of AlexNet model on Table 4. It can be seen that how the results of the 4CD model are significantly better than both IPE and human performance reported in Zhang et al. (2016), while the baselines have similar performances.\nOne observation is the fact that the improvements are more significant when it’s been tested on scenarios with more bricks than during training. It also improves the reverse case, i.e. fewer bricks than during training, but the improvement is not as significant. It is worth mentioning that testing on a lower number of bricks is a much harder problem as pointed out in Zhang et al. (2016) too. In their case, the prediction performance was almost random when going from 4 blocks to 3 blocks, which is not the case in our experiments2. One possible explanation for performance loss is that a balanced tower with fewer blocks corresponds to an unstable configuration for a tower with more blocks e.g. a tower with 3 blocks is classified as unstable for a prediction model trained on towers of 5 blocks. One solution could be to train these models to predict how many blocks have fallen instead of a binary stability label. Because we have access to this data in our dataset, we explored the same experiments using these labels. Unfortunately, we did not observe any significant improvement. The main reason could be that the distribution of the number of fallen blocks is extremely unbalanced. It is hard to collect data with a balanced number of fallen blocks because some configurations are thus very unlikely e.g. a tower of 5 blocks with only two blocks falls (the majority of the time the whole tower collapses).\nThe another observation is the fact that models that use ConvDeconv generated data performed slightly better than those that use ConvLSTMDeconv. As seen in Figure 2 the samples in the ConvLSTMDeconv case are more noisy and less sharper than those in Figure 1. This could be caused since after the first time step the model outputs from the last time step is used as input for the next time step, the samples degenerates the longer the sequence is.\nData augmentation was crucial to increase the generalization performance of the stability prediction e.g. 5CD model tested on 4 bricks achieved only 50% without data augmentation while reaching 74.5% accuracy with data augmentation. This significant improvement from data augmentation could be partly because our dataset was relatively small.\n2We are not using the same dataset as Zhang et al. (2016) and hence direct comparison is not possible.\nModel Train set Test set Accuracy AlexNet 4 3 51 % AlexNet 4 4 95 % AlexNet 4 5 78.5 %\nIPE N/A 3 72 % IPE N/A 4 64 % IPE N/A 5 56 %\nHuman N/A 3 76.5 % Human N/A 4 68.5 % Human N/A 5 59 %\nTable 4: The results reported on Zhang et al. (2016). We emphasize that these results are on a different dataset."
    }, {
      "heading" : "6 CONCLUSION",
      "text" : "In this paper, we showed that data generated from an unsupervised model could help a supervised learner to generalize to unseen scenarios. We argue that this ability of transfer learning and generalization by observing the world could be one of the ingredients to construct a model of the world that could have applications in many tasks, such as model-based RL. We aim to extend this work in future by looking at the videos of robots manipulating objects and being able to predict their failure beforehand, which could help an RL agent to explore more intelligently."
    }, {
      "heading" : "ACKNOWLEDGMENTS",
      "text" : "We would like to thank Harm de Vries and Laurent Dinh for their help and feedback in writing the paper. And also thank Adam Lerer and Jiajun Wu for sharing their dataset. We thank NSERC, CIFAR, IBM, Canada Research Chairs, Google and Samsung for funding."
    } ],
    "references" : [ {
      "title" : "Greedy layer-wise training of deep networks",
      "author" : [ "Yoshua Bengio", "Pascal Lamblin", "Dan Popovici", "Hugo Larochelle" ],
      "venue" : "Advances in neural information processing systems,",
      "citeRegEx" : "Bengio et al\\.,? \\Q2007\\E",
      "shortCiteRegEx" : "Bengio et al\\.",
      "year" : 2007
    }, {
      "title" : "Adversarially learned inference",
      "author" : [ "Vincent Dumoulin", "Ishmael Belghazi", "Ben Poole", "Alex Lamb", "Martin Arjovsky", "Olivier Mastropietro", "Aaron Courville" ],
      "venue" : "arXiv preprint arXiv:1606.00704,",
      "citeRegEx" : "Dumoulin et al\\.,? \\Q2016\\E",
      "shortCiteRegEx" : "Dumoulin et al\\.",
      "year" : 2016
    }, {
      "title" : "Deep visual foresight for planning robot motion",
      "author" : [ "Chelsea Finn", "Sergey Levine" ],
      "venue" : "arXiv preprint arXiv:1610.00696,",
      "citeRegEx" : "Finn and Levine.,? \\Q2016\\E",
      "shortCiteRegEx" : "Finn and Levine.",
      "year" : 2016
    }, {
      "title" : "Unsupervised learning for physical interaction through video prediction",
      "author" : [ "Chelsea Finn", "Ian Goodfellow", "Sergey Levine" ],
      "venue" : "arXiv preprint arXiv:1605.07157,",
      "citeRegEx" : "Finn et al\\.,? \\Q2016\\E",
      "shortCiteRegEx" : "Finn et al\\.",
      "year" : 2016
    }, {
      "title" : "Learning visual predictive models of physics for playing billiards",
      "author" : [ "Katerina Fragkiadaki", "Pulkit Agrawal", "Sergey Levine", "Jitendra Malik" ],
      "venue" : "arXiv preprint arXiv:1511.07404,",
      "citeRegEx" : "Fragkiadaki et al\\.,? \\Q2015\\E",
      "shortCiteRegEx" : "Fragkiadaki et al\\.",
      "year" : 2015
    }, {
      "title" : "Understanding the difficulty of training deep feedforward neural networks",
      "author" : [ "Xavier Glorot", "Yoshua Bengio" ],
      "venue" : "In Aistats,",
      "citeRegEx" : "Glorot and Bengio.,? \\Q2010\\E",
      "shortCiteRegEx" : "Glorot and Bengio.",
      "year" : 2010
    }, {
      "title" : "Deep residual learning for image recognition",
      "author" : [ "Kaiming He", "Xiangyu Zhang", "Shaoqing Ren", "Jian Sun" ],
      "venue" : "arXiv preprint arXiv:1512.03385,",
      "citeRegEx" : "He et al\\.,? \\Q2015\\E",
      "shortCiteRegEx" : "He et al\\.",
      "year" : 2015
    }, {
      "title" : "Identity mappings in deep residual networks",
      "author" : [ "Kaiming He", "Xiangyu Zhang", "Shaoqing Ren", "Jian Sun" ],
      "venue" : "arXiv preprint arXiv:1603.05027,",
      "citeRegEx" : "He et al\\.,? \\Q2016\\E",
      "shortCiteRegEx" : "He et al\\.",
      "year" : 2016
    }, {
      "title" : "Reducing the dimensionality of data with neural networks",
      "author" : [ "Geoffrey E Hinton", "Ruslan R Salakhutdinov" ],
      "venue" : null,
      "citeRegEx" : "Hinton and Salakhutdinov.,? \\Q2006\\E",
      "shortCiteRegEx" : "Hinton and Salakhutdinov.",
      "year" : 2006
    }, {
      "title" : "A fast learning algorithm for deep belief nets",
      "author" : [ "Geoffrey E Hinton", "Simon Osindero", "Yee-Whye Teh" ],
      "venue" : "Neural computation,",
      "citeRegEx" : "Hinton et al\\.,? \\Q2006\\E",
      "shortCiteRegEx" : "Hinton et al\\.",
      "year" : 2006
    }, {
      "title" : "Batch normalization: Accelerating deep network training by reducing internal covariate shift",
      "author" : [ "Sergey Ioffe", "Christian Szegedy" ],
      "venue" : "arXiv preprint arXiv:1502.03167,",
      "citeRegEx" : "Ioffe and Szegedy.,? \\Q2015\\E",
      "shortCiteRegEx" : "Ioffe and Szegedy.",
      "year" : 2015
    }, {
      "title" : "Adam: A method for stochastic optimization",
      "author" : [ "Diederik Kingma", "Jimmy Ba" ],
      "venue" : "arXiv preprint arXiv:1412.6980,",
      "citeRegEx" : "Kingma and Ba.,? \\Q2014\\E",
      "shortCiteRegEx" : "Kingma and Ba.",
      "year" : 2014
    }, {
      "title" : "Semi-supervised learning with deep generative models",
      "author" : [ "Diederik P Kingma", "Shakir Mohamed", "Danilo Jimenez Rezende", "Max Welling" ],
      "venue" : "In Advances in Neural Information Processing Systems,",
      "citeRegEx" : "Kingma et al\\.,? \\Q2014\\E",
      "shortCiteRegEx" : "Kingma et al\\.",
      "year" : 2014
    }, {
      "title" : "Imagenet classification with deep convolutional neural networks. In Advances in neural information processing",
      "author" : [ "Alex Krizhevsky", "Ilya Sutskever", "Geoffrey E Hinton" ],
      "venue" : null,
      "citeRegEx" : "Krizhevsky et al\\.,? \\Q2012\\E",
      "shortCiteRegEx" : "Krizhevsky et al\\.",
      "year" : 2012
    }, {
      "title" : "Building machines that learn and think like people",
      "author" : [ "Brenden M Lake", "Tomer D Ullman", "Joshua B Tenenbaum", "Samuel J Gershman" ],
      "venue" : "arXiv preprint arXiv:1604.00289,",
      "citeRegEx" : "Lake et al\\.,? \\Q2016\\E",
      "shortCiteRegEx" : "Lake et al\\.",
      "year" : 2016
    }, {
      "title" : "Learning physical intuition of block towers by example",
      "author" : [ "Adam Lerer", "Sam Gross", "Rob Fergus" ],
      "venue" : "arXiv preprint arXiv:1603.01312,",
      "citeRegEx" : "Lerer et al\\.,? \\Q2016\\E",
      "shortCiteRegEx" : "Lerer et al\\.",
      "year" : 2016
    }, {
      "title" : "Deep predictive coding networks for video prediction and unsupervised learning",
      "author" : [ "William Lotter", "Gabriel Kreiman", "David Cox" ],
      "venue" : "arXiv preprint arXiv:1605.08104,",
      "citeRegEx" : "Lotter et al\\.,? \\Q2016\\E",
      "shortCiteRegEx" : "Lotter et al\\.",
      "year" : 2016
    }, {
      "title" : "Deep multi-scale video prediction beyond mean square error",
      "author" : [ "Michael Mathieu", "Camille Couprie", "Yann LeCun" ],
      "venue" : "arXiv preprint arXiv:1511.05440,",
      "citeRegEx" : "Mathieu et al\\.,? \\Q2015\\E",
      "shortCiteRegEx" : "Mathieu et al\\.",
      "year" : 2015
    }, {
      "title" : "Statistical language models based on neural networks. Presentation at Google",
      "author" : [ "Tomáš Mikolov" ],
      "venue" : "Mountain View,",
      "citeRegEx" : "Mikolov.,? \\Q2012\\E",
      "shortCiteRegEx" : "Mikolov.",
      "year" : 2012
    }, {
      "title" : "Rectified linear units improve restricted boltzmann machines",
      "author" : [ "Vinod Nair", "Geoffrey E Hinton" ],
      "venue" : "In Proceedings of the 27th International Conference on Machine Learning",
      "citeRegEx" : "Nair and Hinton.,? \\Q2010\\E",
      "shortCiteRegEx" : "Nair and Hinton.",
      "year" : 2010
    }, {
      "title" : "Action-conditional video prediction using deep networks in atari games",
      "author" : [ "Junhyuk Oh", "Xiaoxiao Guo", "Honglak Lee", "Richard L Lewis", "Satinder Singh" ],
      "venue" : "In Advances in Neural Information Processing Systems,",
      "citeRegEx" : "Oh et al\\.,? \\Q2015\\E",
      "shortCiteRegEx" : "Oh et al\\.",
      "year" : 2015
    }, {
      "title" : "Improved techniques for training gans",
      "author" : [ "Tim Salimans", "Ian Goodfellow", "Wojciech Zaremba", "Vicki Cheung", "Alec Radford", "Xi Chen" ],
      "venue" : "arXiv preprint arXiv:1606.03498,",
      "citeRegEx" : "Salimans et al\\.,? \\Q2016\\E",
      "shortCiteRegEx" : "Salimans et al\\.",
      "year" : 2016
    }, {
      "title" : "Amortised map inference for image super-resolution",
      "author" : [ "Casper Kaae Sønderby", "Jose Caballero", "Lucas Theis", "Wenzhe Shi", "Ferenc Huszár" ],
      "venue" : "arXiv preprint arXiv:1610.04490,",
      "citeRegEx" : "Sønderby et al\\.,? \\Q2016\\E",
      "shortCiteRegEx" : "Sønderby et al\\.",
      "year" : 2016
    }, {
      "title" : "Dropout: a simple way to prevent neural networks from overfitting",
      "author" : [ "Nitish Srivastava", "Geoffrey E Hinton", "Alex Krizhevsky", "Ilya Sutskever", "Ruslan Salakhutdinov" ],
      "venue" : "Journal of Machine Learning Research,",
      "citeRegEx" : "Srivastava et al\\.,? \\Q1929\\E",
      "shortCiteRegEx" : "Srivastava et al\\.",
      "year" : 1929
    }, {
      "title" : "Unsupervised learning of video representations using lstms",
      "author" : [ "Nitish Srivastava", "Elman Mansimov", "Ruslan Salakhutdinov" ],
      "venue" : "CoRR, abs/1502.04681,",
      "citeRegEx" : "Srivastava et al\\.,? \\Q2015\\E",
      "shortCiteRegEx" : "Srivastava et al\\.",
      "year" : 2015
    }, {
      "title" : "Pure reasoning in 12-month-old infants as probabilistic inference",
      "author" : [ "Ernő Téglás", "Edward Vul", "Vittorio Girotto", "Michel Gonzalez", "Joshua B Tenenbaum", "Luca L Bonatti" ],
      "venue" : null,
      "citeRegEx" : "Téglás et al\\.,? \\Q2011\\E",
      "shortCiteRegEx" : "Téglás et al\\.",
      "year" : 2011
    }, {
      "title" : "A comparative evaluation of approximate probabilistic simulation and deep neural networks as accounts of human physical scene understanding",
      "author" : [ "Renqiao Zhang", "Jiajun Wu", "Chengkai Zhang", "William T Freeman", "Joshua B Tenenbaum" ],
      "venue" : "arXiv preprint arXiv:1605.01138,",
      "citeRegEx" : "Zhang et al\\.,? \\Q2016\\E",
      "shortCiteRegEx" : "Zhang et al\\.",
      "year" : 2016
    } ],
    "referenceMentions" : [ {
      "referenceID" : 14,
      "context" : "One important aspect of this ability is physical intuition (Lake et al., 2016).",
      "startOffset" : 59,
      "endOffset" : 78
    }, {
      "referenceID" : 14,
      "context" : "As also argued by Lake et al. (2016) one of the core ingredients of human intelligence is intuitive physics.",
      "startOffset" : 18,
      "endOffset" : 37
    }, {
      "referenceID" : 14,
      "context" : "As also argued by Lake et al. (2016) one of the core ingredients of human intelligence is intuitive physics. Children can learn and predict some of the common physical behaviors of our world just by observing and interacting without any direct supervision. And they form a sophisticated predictive model of the physical environment and expect the world to behave based on their mental model and have a reasonable expectation about unseen situations Téglás et al. (2011). Despite impressive progress in the last few years in the training of the supervised models, we have not yet quite been able to achieve similar results in unsupervised learning, and it remains one of the challenging research areas in the field.",
      "startOffset" : 18,
      "endOffset" : 470
    }, {
      "referenceID" : 14,
      "context" : "As also argued by Lake et al. (2016) one of the core ingredients of human intelligence is intuitive physics. Children can learn and predict some of the common physical behaviors of our world just by observing and interacting without any direct supervision. And they form a sophisticated predictive model of the physical environment and expect the world to behave based on their mental model and have a reasonable expectation about unseen situations Téglás et al. (2011). Despite impressive progress in the last few years in the training of the supervised models, we have not yet quite been able to achieve similar results in unsupervised learning, and it remains one of the challenging research areas in the field. The full potential of the application of unsupervised learning is yet to be realized. In this work, we leverage unsupervised learning to train a predictive model over sequences. We use the imagined and predicted future sequence data to help a physical environment prediction model generalize better to unseen settings. More specifically we focus on the task of predicting if a tower of square bricks will fall or not, as introduced by Lerer et al. (2016). They showed that a deep convolution neural network could predict the fall of the towers with super-human accuracy.",
      "startOffset" : 18,
      "endOffset" : 1170
    }, {
      "referenceID" : 14,
      "context" : "As also argued by Lake et al. (2016) one of the core ingredients of human intelligence is intuitive physics. Children can learn and predict some of the common physical behaviors of our world just by observing and interacting without any direct supervision. And they form a sophisticated predictive model of the physical environment and expect the world to behave based on their mental model and have a reasonable expectation about unseen situations Téglás et al. (2011). Despite impressive progress in the last few years in the training of the supervised models, we have not yet quite been able to achieve similar results in unsupervised learning, and it remains one of the challenging research areas in the field. The full potential of the application of unsupervised learning is yet to be realized. In this work, we leverage unsupervised learning to train a predictive model over sequences. We use the imagined and predicted future sequence data to help a physical environment prediction model generalize better to unseen settings. More specifically we focus on the task of predicting if a tower of square bricks will fall or not, as introduced by Lerer et al. (2016). They showed that a deep convolution neural network could predict the fall of the towers with super-human accuracy. But despite the strengths of convolution neural networks, Zhang et al. (2016) shows how deep neural networks have a hard time generalizing to novel situations in the same way as humans or simulation-based models can do.",
      "startOffset" : 18,
      "endOffset" : 1364
    }, {
      "referenceID" : 8,
      "context" : "In the beginning, unsupervised learning and generative models emerged as pre-training method Hinton & Salakhutdinov (2006); Hinton et al. (2006); Bengio et al.",
      "startOffset" : 124,
      "endOffset" : 145
    }, {
      "referenceID" : 0,
      "context" : "(2006); Bengio et al. (2007) to help other tasks such as",
      "startOffset" : 8,
      "endOffset" : 29
    }, {
      "referenceID" : 3,
      "context" : "(2015) as well as robotics (Finn et al., 2016; Finn & Levine, 2016).",
      "startOffset" : 27,
      "endOffset" : 67
    }, {
      "referenceID" : 7,
      "context" : "But since Krizhevsky et al. (2012) many other regularization Srivastava et al.",
      "startOffset" : 10,
      "endOffset" : 35
    }, {
      "referenceID" : 7,
      "context" : "But since Krizhevsky et al. (2012) many other regularization Srivastava et al. (2014), weight initialization Glorot & Bengio (2010) and normalization Ioffe & Szegedy (2015) techniques and architecture designs He et al.",
      "startOffset" : 10,
      "endOffset" : 86
    }, {
      "referenceID" : 7,
      "context" : "But since Krizhevsky et al. (2012) many other regularization Srivastava et al. (2014), weight initialization Glorot & Bengio (2010) and normalization Ioffe & Szegedy (2015) techniques and architecture designs He et al.",
      "startOffset" : 10,
      "endOffset" : 132
    }, {
      "referenceID" : 7,
      "context" : "But since Krizhevsky et al. (2012) many other regularization Srivastava et al. (2014), weight initialization Glorot & Bengio (2010) and normalization Ioffe & Szegedy (2015) techniques and architecture designs He et al.",
      "startOffset" : 10,
      "endOffset" : 173
    }, {
      "referenceID" : 3,
      "context" : "(2014), weight initialization Glorot & Bengio (2010) and normalization Ioffe & Szegedy (2015) techniques and architecture designs He et al. (2015) has been introduced that diminish the effect of pre-training.",
      "startOffset" : 130,
      "endOffset" : 147
    }, {
      "referenceID" : 3,
      "context" : "(2014), weight initialization Glorot & Bengio (2010) and normalization Ioffe & Szegedy (2015) techniques and architecture designs He et al. (2015) has been introduced that diminish the effect of pre-training. Although pre-training still could be useful in data scarce domains they are many other ways and applications that unsupervised learning are still very interesting models and it is a very active area of research. Just to name a few applications are semi-supervised learning Kingma et al. (2014); Salimans et al.",
      "startOffset" : 130,
      "endOffset" : 503
    }, {
      "referenceID" : 3,
      "context" : "(2014), weight initialization Glorot & Bengio (2010) and normalization Ioffe & Szegedy (2015) techniques and architecture designs He et al. (2015) has been introduced that diminish the effect of pre-training. Although pre-training still could be useful in data scarce domains they are many other ways and applications that unsupervised learning are still very interesting models and it is a very active area of research. Just to name a few applications are semi-supervised learning Kingma et al. (2014); Salimans et al. (2016); Dumoulin et al.",
      "startOffset" : 130,
      "endOffset" : 527
    }, {
      "referenceID" : 1,
      "context" : "(2016); Dumoulin et al. (2016) super resolution Sønderby et al.",
      "startOffset" : 8,
      "endOffset" : 31
    }, {
      "referenceID" : 1,
      "context" : "(2016); Dumoulin et al. (2016) super resolution Sønderby et al. (2016). Video generation is one active area of research with many applications, and many of the recent works have been using some of the states of the art neural networks for video generation.",
      "startOffset" : 8,
      "endOffset" : 71
    }, {
      "referenceID" : 1,
      "context" : "(2016); Dumoulin et al. (2016) super resolution Sønderby et al. (2016). Video generation is one active area of research with many applications, and many of the recent works have been using some of the states of the art neural networks for video generation. Srivastava et al. (2015) uses LSTM recurrent neural networks to train an unsupervised future predictive model for video generation.",
      "startOffset" : 8,
      "endOffset" : 282
    }, {
      "referenceID" : 1,
      "context" : "(2016); Dumoulin et al. (2016) super resolution Sønderby et al. (2016). Video generation is one active area of research with many applications, and many of the recent works have been using some of the states of the art neural networks for video generation. Srivastava et al. (2015) uses LSTM recurrent neural networks to train an unsupervised future predictive model for video generation. And here we use a very similar architecture as described in Section 4.1. Mathieu et al. (2015) combines the common mean-squared-error objective function with an adversarial training cost in order to generate sharper samples.",
      "startOffset" : 8,
      "endOffset" : 484
    }, {
      "referenceID" : 1,
      "context" : "(2016); Dumoulin et al. (2016) super resolution Sønderby et al. (2016). Video generation is one active area of research with many applications, and many of the recent works have been using some of the states of the art neural networks for video generation. Srivastava et al. (2015) uses LSTM recurrent neural networks to train an unsupervised future predictive model for video generation. And here we use a very similar architecture as described in Section 4.1. Mathieu et al. (2015) combines the common mean-squared-error objective function with an adversarial training cost in order to generate sharper samples. Lotter et al. (2016) introduce another form of unsupervised video prediction training scheme that manages to predict future events such as the direction of the turn of a car which could have potential use in training of the self-driving cars.",
      "startOffset" : 8,
      "endOffset" : 635
    }, {
      "referenceID" : 1,
      "context" : "(2016); Dumoulin et al. (2016) super resolution Sønderby et al. (2016). Video generation is one active area of research with many applications, and many of the recent works have been using some of the states of the art neural networks for video generation. Srivastava et al. (2015) uses LSTM recurrent neural networks to train an unsupervised future predictive model for video generation. And here we use a very similar architecture as described in Section 4.1. Mathieu et al. (2015) combines the common mean-squared-error objective function with an adversarial training cost in order to generate sharper samples. Lotter et al. (2016) introduce another form of unsupervised video prediction training scheme that manages to predict future events such as the direction of the turn of a car which could have potential use in training of the self-driving cars. Model-based reinforcement learning (RL) is an active research area that holds the promise of making the RL agents less data hungry. Learning agents could explore, learn in an unsupervised way about their world, and learn even more by dreaming about future states. We believe that action-condition video prediction models are an important ingredient for this task. Fragkiadaki et al. (2015) learn the dynamics of billiards balls by supervised training of a neural net.",
      "startOffset" : 8,
      "endOffset" : 1247
    }, {
      "referenceID" : 1,
      "context" : "(2016); Dumoulin et al. (2016) super resolution Sønderby et al. (2016). Video generation is one active area of research with many applications, and many of the recent works have been using some of the states of the art neural networks for video generation. Srivastava et al. (2015) uses LSTM recurrent neural networks to train an unsupervised future predictive model for video generation. And here we use a very similar architecture as described in Section 4.1. Mathieu et al. (2015) combines the common mean-squared-error objective function with an adversarial training cost in order to generate sharper samples. Lotter et al. (2016) introduce another form of unsupervised video prediction training scheme that manages to predict future events such as the direction of the turn of a car which could have potential use in training of the self-driving cars. Model-based reinforcement learning (RL) is an active research area that holds the promise of making the RL agents less data hungry. Learning agents could explore, learn in an unsupervised way about their world, and learn even more by dreaming about future states. We believe that action-condition video prediction models are an important ingredient for this task. Fragkiadaki et al. (2015) learn the dynamics of billiards balls by supervised training of a neural net. Action-conditioned video prediction models have been applied to Atari playing agent Oh et al. (2015) as well as robotics (Finn et al.",
      "startOffset" : 8,
      "endOffset" : 1426
    }, {
      "referenceID" : 15,
      "context" : "Recent datasets for predicting the stability of block configurations (Lerer et al., 2016; Zhang et al., 2016) only provide binary labels of stability, and exclude the video simulation of the block configuration.",
      "startOffset" : 69,
      "endOffset" : 109
    }, {
      "referenceID" : 26,
      "context" : "Recent datasets for predicting the stability of block configurations (Lerer et al., 2016; Zhang et al., 2016) only provide binary labels of stability, and exclude the video simulation of the block configuration.",
      "startOffset" : 69,
      "endOffset" : 109
    }, {
      "referenceID" : 15,
      "context" : "Recent datasets for predicting the stability of block configurations (Lerer et al., 2016; Zhang et al., 2016) only provide binary labels of stability, and exclude the video simulation of the block configuration. We, therefore, construct a new dataset, with a similar setup as Lerer et al. (2016); Zhang et al.",
      "startOffset" : 70,
      "endOffset" : 296
    }, {
      "referenceID" : 15,
      "context" : "Recent datasets for predicting the stability of block configurations (Lerer et al., 2016; Zhang et al., 2016) only provide binary labels of stability, and exclude the video simulation of the block configuration. We, therefore, construct a new dataset, with a similar setup as Lerer et al. (2016); Zhang et al. (2016), that includes this video sequence.",
      "startOffset" : 70,
      "endOffset" : 317
    }, {
      "referenceID" : 17,
      "context" : "We also experimented with an additional adversarial cost as in Mathieu et al. (2015) but did not observe any improvement for the stability prediction task.",
      "startOffset" : 63,
      "endOffset" : 85
    }, {
      "referenceID" : 17,
      "context" : "We also experimented with an additional adversarial cost as in Mathieu et al. (2015) but did not observe any improvement for the stability prediction task. We hypothesize that although the adversarial objective function helps to have sharper images, such improved sample quality does not transfer to better stability prediction. Figure 1 shows a few examples of the generated data on the test set. Mean squared error is minimized using the AdaM Optimizer(Kingma & Ba, 2014) and we use earlystopping when the validation loss does not improve for 100 epochs. We extend this ConvDeconv model in a second architecture, named ConvLSTMDeconv, to predict the next frame at each timestep. This model is composed of an LSTM architecture. The same convolutional and deconvolutional blocks as ConvDeconv is utilized to respectively input the current frame to the LSTM transition and output the next frame from the current LSTM state. The details of the ConvLSTMDeconv model architecture are shown in Table 2 and Figure 3 shows the diagram of the both architectures. During the training at each time step the ground-truth data feeds in to the model, but during the test time only the initial time step gets the first frame from the data and for subsequent time steps the generated frames from the previous time steps feed in to the model. The is similar setup to recurrent neural network language models Mikolov (2012), and this is necessary as during the test time we only have access to the first frame.",
      "startOffset" : 63,
      "endOffset" : 1407
    }, {
      "referenceID" : 6,
      "context" : "architecture from He et al. (2016). We trained the baseline model on each of the different tower heights 3, 4, 5.",
      "startOffset" : 18,
      "endOffset" : 35
    }, {
      "referenceID" : 26,
      "context" : "For comparison we have included results from Zhang et al. (2016) in Table 4.",
      "startOffset" : 45,
      "endOffset" : 65
    }, {
      "referenceID" : 26,
      "context" : "For comparison we have included results from Zhang et al. (2016) in Table 4. Since Zhang et al. (2016) only reports the results when the models are trained on tower of 4 blocks, the corresponding results would be the second block row in Table 3, models 4S, 4CD and 4CLD.",
      "startOffset" : 45,
      "endOffset" : 103
    }, {
      "referenceID" : 26,
      "context" : "For comparison we have included results from Zhang et al. (2016) in Table 4. Since Zhang et al. (2016) only reports the results when the models are trained on tower of 4 blocks, the corresponding results would be the second block row in Table 3, models 4S, 4CD and 4CLD. Even though the datasets are not the same, but it can be observed that the range of performance of the baseline 4S model is consistent with the range of performance of AlexNet model on Table 4. It can be seen that how the results of the 4CD model are significantly better than both IPE and human performance reported in Zhang et al. (2016), while the baselines have similar performances.",
      "startOffset" : 45,
      "endOffset" : 611
    }, {
      "referenceID" : 26,
      "context" : "For comparison we have included results from Zhang et al. (2016) in Table 4. Since Zhang et al. (2016) only reports the results when the models are trained on tower of 4 blocks, the corresponding results would be the second block row in Table 3, models 4S, 4CD and 4CLD. Even though the datasets are not the same, but it can be observed that the range of performance of the baseline 4S model is consistent with the range of performance of AlexNet model on Table 4. It can be seen that how the results of the 4CD model are significantly better than both IPE and human performance reported in Zhang et al. (2016), while the baselines have similar performances. One observation is the fact that the improvements are more significant when it’s been tested on scenarios with more bricks than during training. It also improves the reverse case, i.e. fewer bricks than during training, but the improvement is not as significant. It is worth mentioning that testing on a lower number of bricks is a much harder problem as pointed out in Zhang et al. (2016) too.",
      "startOffset" : 45,
      "endOffset" : 1049
    }, {
      "referenceID" : 26,
      "context" : "We are not using the same dataset as Zhang et al. (2016) and hence direct comparison is not possible.",
      "startOffset" : 37,
      "endOffset" : 57
    }, {
      "referenceID" : 26,
      "context" : "Table 4: The results reported on Zhang et al. (2016). We emphasize that these results are on a different dataset.",
      "startOffset" : 33,
      "endOffset" : 53
    } ],
    "year" : 2016,
    "abstractText" : "Humans learn a predictive model of the world and use this model to reason about future events and the consequences of actions. In contrast to most machine predictors, we exhibit an impressive ability to generalize to unseen scenarios and reason intelligently in these settings. One important aspect of this ability is physical intuition (Lake et al., 2016). In this work, we explore the potential of unsupervised learning to find features that promote better generalization to settings outside the supervised training distribution. Our task is predicting the stability of towers of square blocks. We demonstrate that an unsupervised model, trained to predict future frames of a video sequence of stable and unstable block configurations, can yield features that support extrapolating stability prediction to blocks configurations outside the training set distribution.",
    "creator" : "LaTeX with hyperref package"
  }
}