{
  "name" : "514.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : null,
    "authors" : [ "POINT CLOUDS", "Siamak Ravanbakhsh", "Jeff Schneider", "Barnabás Póczos" ],
    "emails" : [ "mravanba@cs.cmu.edu", "jeff.schneider@cs.cmu.edu", "bapoczos@cs.cmu.edu" ],
    "sections" : [ {
      "heading" : "1 INTRODUCTION",
      "text" : "Recent progress in deep learning (LeCun et al., 2015) has witnessed its application to structured settings, including graphs (Bruna et al., 2013; Duvenaud et al., 2015) groups (Gens & Domingos, 2014; Christopher, 2014; Cohen & Welling, 2016), sequences and hierarchies (Irsoy & Cardie, 2014; Socher et al., 2013). Here, we introduce a simple permutation-equivariant layer for deep learning with set structure, where the primary dataset is a collection of sets, possibly of different sizes. Note that each instance may have a structure of its own, such as graph, image, or another set. In typical machine-learning applications, iid assumption implies that the entire data-set itself has a set structure. Therefore, our special treatment of the set structure is only necessary due to multiplicity of distinct yet homogeneous (data)sets. Here, we show that a simple parameter-sharing scheme enables a general treatment of sets within supervised and semi-supervised settings.\nIn the following, after introducing the set layer in Section 2, we explore several novel applications. Section 3 studies supervised learning with sets that requires “invariance” to permutation of inputs. Section 3.1 considers the task of summing multiple MNIST digits, and Section 3.2 studies an important application of sets in representing low-dimensional point-clouds. Here, we show that deep networks can successfully classify objects using their point-cloud representation.\nSection 4 presents numerical study in semi-supervised setting where the output of the multi-layer network is “equivariant” to the permutation of inputs. We use permutation-equivariant layer to perform outlier detection on CelebA face dataset in Section 4.1 and improve galaxy red-shift estimates using its clustering information in Section 5."
    }, {
      "heading" : "2 PERMUTATION-EQUIVARIANT LAYER",
      "text" : "Let xn ∈ X denote use x = [x1, . . . , xN ] to denote a vector of xn instances. Here, xn, could be a feature-vector, an image or any other structured object. Our goal is to design neural network layers that are “indifferent” to permutations of instances in x. Achieving this goal amounts to treating x as a “set” rather than a vector.\nThe function f : XN → YN is equivariant to the permutation of its inputs iff f(πx) = πf(x) ∀π ∈ SN\nwhere the symmetric group SN is the set of all permutation of indices 1, . . . , N . Similarly, the function f : <N → < is invariant to permutation of its inputs –i.e., a.k.a. a symmetric function (David\net al., 1966)– iff f(πx) = f(x) ∀π ∈ SN . Here, the action of π on a vector x ∈ <N can be represented by a permutation matrix. With some abuse of notation, we use π ∈ {0, 1}N×N to also denote this matrix.\nGiven two permutation equivariance function f : XN → YN and g : YN → ZN , their composition is also permutation-equivariance; this is because g(f(πx)) = g(πf(x)) = πg(f(x)).\nConsider the standard neural network layer\nfΘ(x) . = σ(Θx) Θ ∈ <N×N (1)\nwhere Θ is the weight vector and σ : < → < is a nonlinearity such as sigmoid function. σ : <N → <N is the point-wise application of σ to its input vector. The following theorem states the necessary and sufficient conditions for permutation-equivariance in this type of function. Theorem 2.1. The function fΘ : <N → <N as defined in Eq. (1) is permutation equivariant iff all the off-diagonal elements of Θ are tied together and all the diagonal elements are equal as well,\nΘ = λI + γ (11T) λ, γ ∈ < 1 = [1, . . . , 1]T ∈ <N (2) where I is the identity matrix.1\nThis function is simply a non-linearity applied to a weighted combination of I) its input Ix and; II) the sum of input values (11T)x. Since summation does not depend on the permutation, the layer is permutation-equivariant. Therefore we can manipulate the operations and parameters in this layer, for example to get another variation\nf(x) . = σ(λIx− γ(max\nn x)1) (3)\nwhere the max operation over elements of the set is (similar to summation) commutative and using −γ instead of +γ amounts to a reparametrization. In practice using this variation performs better in some applications. This may be due to the fact that for λ = γ, the input to the non-linearity is max-normalized.\nFor multiple input-output channels, we may speed up the operation of the layer using matrix multiplication. Suppose we haveK input channels –corresponding toK features for each instance in the set– with a set of sizeN , andK ′ output channels. Here, x ∈ <N×K and fΘ : <N×K → <N×K ′ . The permutation-equivariant layer parameters are Λ,Γ ∈ <K,K′ (replacing λ and γ in Eq. (2)). The output of this layer becomes\ny = σ ( xΛ + 11TxΓ ) Similarly, the multiple input-output channel variation of the Eq. (3) is\ny = σ ( xΛ − 1xmaxΓ ) (4)\nwhere xmax = (maxn x) ∈ <1×K is a row-vector of maximum value of x ∈ <N×K over the “set” dimension. In practice, we may further reduce the number of parameters in favor of better generalization by factoring Γ and Λ and keeping a single λ ∈ <K,K′\ny = σ ( β + ( x − 1(max n x) ) Γ )\n(5)\n1See the Appendix A for the proof.\nwhere β ∈ <K′ is a bias parameter. This final variation of permutation-equivariant layer is simply a fully connected layer where input features are max-normalized within each set.\nWith multiple input-output channels, the complexity of this layer for each set is O(N K K ′). Subtracting the mean or max over the set also reduces the internal covariate shift (Ioffe & Szegedy, 2015) and we observe that for deep networks (even using tanh activation), batch-normalization is not required.\nWhen applying dropout (Srivastava et al., 2014) to regularize permutation-equivariant layers with multiple output channels, it is often beneficial to simultaneously dropout the channels for all instances within a set. In particular, when set-members share similar features, independent dropout effectively does not regularize the model as the the network learns to replace the missing features from other set-members.\nIn the remainder of this paper, we demonstrate how this simple treatment of sets can solve novel and non-trivial problems that occasionally have no alternative working solutions within deep learning."
    }, {
      "heading" : "3 SUPERVISED LEARNING",
      "text" : "The permutation-equivariant layers that we introduced so far are useful for semi-supervised learning (or transductive) setting, where we intend to predict a value per each instance in every set. In supervised (or inductive) setting the task is to make a prediction for each set (rather than instances within them), and we require permutation “invariance” of f : XN → Y . A pooling operation over the set-dimension can turn any permutation equivariant function f : XN → YN , permutation invariant f(x) . = ⊕\nn f(x). Here ⊕ is any commutative operation such as summation or maximization. In a related work Chen et al. (2014) construct deep permutation invariant features by pairwise coupling of features at the previous layer, where fi,j([xi, xj ]) . = [|xi − xj |, xi + xj ] is invariant to transposition of i and j.2\nAs we see shortly in Section 3.1, in the supervised setting, even simple application of setpooling, without max-normalization of Eq. (5) performs very well in practice. However, in semisupervised setting since there is no pooling operation, the permutation invariant layer requires maxnormalization in order to obtain the required information about the context of each instance."
    }, {
      "heading" : "3.1 PREDICTING THE SUM OF MNIST DIGITS",
      "text" : "MNIST dataset (LeCun et al., 1998) contains 70,000 instances of 28×28 grey-scale stamps of digits in {0, . . . , 9}. We randomly sample a subset of N images from this dataset to build 10,000 “sets” of training and 10,000 sets of validation images, where the set-label is the sum of digits in that set (i.e., individual labels per image is unavailable).\n2Due to change in the number of features/channels in each layer this approach cannot produce permutation“equivariant” layers. Also, this method requires a graph to guide the multi-resolution partitioning of the nodes, which is then used to define pairing of features in each layer.\nIn our first experiment, each set contains N = 3 images, and the set label is a number between 0 ≤ y ≤ 3 ∗ 9 = 27. We then considered four different models for predicting the sum:\nI) Concatenating instances along the horizontal axis. II) Stacking images in each set as different input channels. III) Using set-pooling without max-normalization. IV) Using the permutation equivariant layer of Eq. (5) with set-pooling.\nAll models are defined to have similar number of layers and parameters; see Appendix B.1 for details. The output of all models is a (9N + 1)-way softmax, predicting the sum of N digits.\nFigure 1(left) show the prediction accuracy over the validation-set for different models for N = 3. We see that using the set-layer performs the best. However, interestingly, using set-pooling alone produces similarly good results. We also observe that concatenating the digits eventually performs well, despite its lack of invariance. This is because due to the sufficiently large size of the dataset most permutations of length three appear in the training set.\nHowever, as we increase the size of each set to N = 6, permutation invariance becomes crucial; see Figure 1(right). We see that using the default dropout rate of 20%, the model simply memorizes the input instances (indicated by discrepancy of training/validation error) and by increasing this dropout rate, the model simply predicts values close to the mean value. However, the permutation-invariant layer learns to predict the sum of six digits with> 80% accuracy, without having access to individual image labels. Performance using set-pooling alone is similar."
    }, {
      "heading" : "3.2 POINT CLOUD CLASSIFICATION",
      "text" : "A low-dimensional point-cloud is a set of low-dimensional vectors. This type of data is frequently encountered in various applications from robotics and vision to cosmology. In these applications, point-cloud data is often converted to voxel or mesh representation at a preprocessing step (e.g., Maturana & Scherer, 2015; Ravanbakhsh et al., 2016; Lin et al., 2004). Since the output of many range sensors such as LiDAR – which are extensively used in applications such as autonomous vehicles – is in the form of point-cloud, direct application of deep learning methods to point-cloud is highly desirable. Moreover, when working with point-clouds rather than voxelized 3D objects, it is easy to apply transformations such as rotation and translation as differentiable layers at low cost.\nHere, we show that treating the point-cloud data as a set, we can use the set-equivariant layer of Eq. (5) to classify point-cloud representation of a subset of ShapeNet objects (Chang et al., 2015), called ModelNet40 (Wu et al., 2015). This subset consists of 3D representation of 9,843 training and 2,468 test instances belonging to 40 classes of objects; see Fig. 2. We produce point-clouds with 100, 1000 and 5000 particles each (x, y, z-coordinates) from the mesh representation of objects using the point-cloud-library’s sampling routine (Rusu & Cousins, 2011). Each set is normalized by the initial layer of the deep network to have zero mean (along individual axes) and unit (global)\nvariance. Additionally we experiment with the K-nearest neighbor graph of each point-cloud and report the results using graph-convolution; see Appendix B.3 for model details.\nTable 1 compares our method against the competition.3 Note that we achieve our best accuracy using 5000×3 dimensional representation of each object, which is much smaller than most other methods. All other techniques use either voxelization or multiple view of the 3D object for classification. Interestingly, variations of view/angle-pooling (e.g., Su et al., 2015; Shi et al., 2015) can be interpreted as set-pooling where the class-label is invariant to permutation of different views. The results also shows that using fully-connected layers with set-pooling alone (without max-normalization over the set) works relatively well.\nWe see that reducing the number of particles to only 100, still produces comparatively good results. Using graph-convolution is computationally more challenging and produces inferior results in this setting. The results using 5000 particles is also invariant to small changes in scale and rotation around the z-axis; see Appendix B.3 for details.\nFeatures. To visualize the features learned by the set layers, we used Adamax (Kingma & Ba, 2014) to locate 1000 particle coordinates maximizing the activation of each unit.4 Activating the tanh units beyond the second layer proved to be difficult. Figure 3 shows the particle-cloud-features learned at the first and second layers of our deep network. We observed that the first layer learns simple localized (often cubic) point-clouds at different (x, y, z) locations, while the second layer learns more complex surfaces with different scales and orientations."
    }, {
      "heading" : "4 SEMI-SUPERVISED LEARNING",
      "text" : "In semi-supervised or transductive learning, some/all instances within each training set are labelled. Our goal is to make predictions for individual instances within a test set. Therefore, the permutation equivariant layer leverages the interaction between the set-members to label individual member. Note that in this case, we do not perform any pooling operation over the set dimension of the data."
    }, {
      "heading" : "4.1 SET ANOMALY DETECTION",
      "text" : "The objective here is for the deep model to find the anomalous face in each set, simply by observing examples and without any access to the attribute values. CelebA dataset (Liu et al., 2015) contains\n3The error-bar on our results is due to variations depending on the choice of particles during test time and it is estimated over three trials.\n4We started from uniformly distributed set of particles and used a learning rate of .01 for Adamax, with first and second order moment of .1 and .9 respectively. We optimized the input in 105 iterations. The results of Fig. 3 are limited to instances where tanh units were successfully activated. Since the input at the first layer of our deep network is normalized to have a zero mean and unit standard deviation, we do not need to constrain the input while maximizing unit’s activation.\n202,599 face images, each annotated with 40 boolean attributes. We use 64 × 64 stamps and using these attributes we build 18,000 sets, each containingN = 16 images (on the training set) as follows: after randomly selecting two attributes, we draw 15 images where those attributes are present and a single image where both attributes are absent. Using a similar procedure we build sets on the test images. No individual person’s face appears in both train and test sets.\nOur deep neural network consists of 9 2D-convolution and max-pooling layers followed by 3 permutation-equivariant layers and finally a softmax layer that assigns a probability value to each set member (Note that one could identify arbitrary number of outliers using a sigmoid activation at the output.) Our trained model successfully finds the anomalous face in 75% of test sets. Visually inspecting these instances suggests that the task is non-trivial even for humans; see Fig. 4. For details of the model, training and more identification examples see Appendix B.2.\nAs a baseline, we repeat the same experiment by using a set-pooling layer after convolution layers, and replacing the permutation-equivariant layers with fully connected layers, with the same number of hidden units/output-channels, where the final layer is a 16-way softmax. The resulting network shares the convolution filters for all instances within all sets, however the input to the softmax is not equivariant to the permutation of input images. Permutation equivariance seems to be crucial here as the baseline model achieves a training and test accuracy of∼ 6.3%; the same as random selection."
    }, {
      "heading" : "5 IMPROVED RED-SHIFT ESTIMATION USING CLUSTERING INFORMATION",
      "text" : "An important regression problem in cosmology is to estimate the red-shift of galaxies, corresponding to their age as well as their distance from us (Binney & Merrifield, 1998). Two common types of observation for distant galaxies include a) photometric and b) spectroscopic observations, where the latter can produce more accurate red-shift estimates.\nOne way to estimate the red-shift from photometric observations is using a regression model (Connolly et al., 1995). We use a multi-layer Perceptron for this purpose and use the more accurate spectroscopic red-shift estimates as the ground-truth. As another baseline, we have a photometric redshift estimate that is provided by the catalogue and uses various observations (including clustering information) to estimate individual galaxy-red-shift. Our objective is to use clustering information of the galaxies to improve our red-shift prediction using the multi-layer Preceptron.\nNote that the prediction for each galaxy does not change by permuting the members of the galaxy cluster. Therefore, we can treat each galaxy cluster as a “set” and use permutation-equivariant layer to estimate the individual galaxy red-shifts.\nFor each galaxy, we have 17 photometric features 5 from the redMaPPer galaxy cluster catalog (Rozo & Rykoff, 2014), which contains photometric readings for 26,111 red galaxy clusters. In this task in contrast to the previous ones, sets have different cardinalities; each galaxy-cluster in this catalog has between ∼ 20− 300 galaxies – i.e., x ∈ <N(c)×17, where N(c) is the cluster-size. See Fig. 5(a) for distribution of cluster sizes. The catalog also provides accurate spectroscopic red-shift estimates for a subset of these galaxies as well as photometric estimates that uses clustering information. Fig. 5(b) reports the distribution of available spectroscopic red-shift estimates per cluster.\nWe randomly split the data into 90% training and 10% test clusters, and use the following simple architecture for semi-supervised learning. We use four permutation-equivariant layers with 128, 128, 128 and 1 output channels respectively, where the output of the last layer is used as red-shift estimate. The squared loss of the prediction for available spectroscopic red-shifts is minimized.6 Fig. 5(c) shows the agreement of our estimates with spectroscopic readings on the galaxies in the test-set with spectroscopic readings. The figure also compares the photometric estimates provided by the catalogue (see Rozo & Rykoff, 2014), to the ground-truth. As it is customary in cosmology literature, we report the average scatter |zspec−z|1+zspec , where zspec is the accurate spectroscopic measurement and z is a photometric estimate. The average scatter using our model is .023 compared to the scatter of .025 in the original photometric estimates for the redMaPPer catalog. Both of these values are averaged over all the galaxies with spectroscopic measurements in the test-set.\nWe repeat this experiment, replacing the permutation-equivariant layers with fully connected layers (with the same number of parameters) and only use the individual galaxies with available spectroscopic estimate for training. The resulting average scatter for multi-layer Perceptron is .026, demonstrating that using clustering information indeed improves photometric red-shift estimates.\nCONCLUSION\nWe introduced a simple parameter-sharing scheme to effectively achieve permutation-equivariance in deep networks and demonstrated its effectiveness in several novel supervised and semi-supervised tasks. Our treatment of set structure also generalizes various settings in multi-instance learning (Ray et al., 2011; Zhou et al., 2009). In addition to our experimental settings, the permutation-invariant layer can be used for distribution regression and classification which have become popular recently (Szabo et al., 2016). In our experiments with point-cloud data we observed the model to be robust to the variations in the number of particles in each cloud, suggesting the usefulness of our method in the general setting of distribution regression – where the number of samples should not qualitatively affect our representation of a distribution. We leave further investigation of this direction to future work.\n5We have a single measurement for each u,g,r, i and z band as well as measurement error bars, location of the galaxy in the sky, as well as the probability of each galaxy being the cluster center. We do not include the information regarding the richness estimates of the clusters from the catalog, for any of the methods, so that baseline multi-layer Preceptron is blind to the clusters.\n6We use mini-batches of size 128, Adam (Kingma & Ba, 2014), with learning rate of .001, β1 = .9 and β2 = .999. All layers except for the last layer use Tanh units and simultaneous dropout with 50% dropout rate."
    }, {
      "heading" : "ACKNOWLEDGEMENT",
      "text" : "We would like to thank Francois Lanusse for the pointing us to the redMaPPer dataset and the anonymous reviewers as well as Andrew Wagner for valuable feedback."
    }, {
      "heading" : "A PROOFS",
      "text" : "Proof. of the Theorem 2.1 From definition of permutation equivariance fΘ(πx) = πfΘ(x) and definition of f in Eq. (1), the condition becomes σ(Θπx) = πσ(Θx), which (assuming sigmoid is a bijection) is equivalent to Θπ = πΘ. Therefore we need to show that the necessary and sufficient conditions for the matrix Θ ∈ <N×N to commute with all permutation matrices π ∈ Sn is given by Eq. (2). We prove this in both directions:\n• To see why Θ = λI + γ (11T) commutes with any permutation matrix, first note that commutativity is linear – that is\nΘ1π = πΘ1 ∧Θ2π = πΘ2 ⇒ (aΘ1 + bΘ2)π = π(aΘ1 + bΘ2).\nSince both Identity matrix I, and constant matrix 11T, commute with any permutation matrix, so does their linear combination Θ = λI + γ (11T).\n• We need to show that in a matrix Θ that commutes with “all” permutation matrices\n– All diagonal elements are identical: Let πk,l for 1 ≤ k, l ≤ N, k 6= l, be a transposition (i.e., a permutation that only swaps two elements). The inverse permutation matrix of πk,l is the permutation matrix of πl,k = πTk,l. We see that commutativity of Θ with the transposition πk,l implies that Θk,k = Θl,l:\nπk,lΘ = Θπk,l ⇒ πk,lΘπl,k = Θ ⇒ (πk,lΘπl,k)l,l = Θl,l ⇒ Θk,k = Θl,l Therefore, π and Θ commute for any permutation π, they also commute for any transposition πk,l and therefore Θi,i = λ ∀i. – All off-diagonal elements are identical: We show that since Θ commutes with any product of transpositions, any choice two off-diagonal elements should be identical. Let (i, j) and (i′, j′) be the index of two off-diagonal elements (i.e., i 6= j and i′ 6= j′). Moreover for now assume i 6= i′ and j 6= j′. Application of the transposition πi,i′Θ, swaps the rows i, i′ in Θ. Similarly, Θπj,j′ switches the jth column with j′th column. From commutativity property of Θ and π ∈ Sn we have\nπj′,jπi,i′Θ = Θπj′,jπi,i′ ⇒ πj′,jπi,i′Θ(πj′,jπi,i′)−1 = Θ ⇒ πj′,jπi,i′Θπi′,iπj,j′ = Θ ⇒ (πj′,jπi,i′Θπi′,iπj,j′)i,j = Θi,j ⇒ Θi′,j′ = Θi,j\nwhere in the last step we used our assumptions that i 6= i′, j 6= j′, i 6= j and i′ 6= j′. In the cases where either i = i′ or j = j′, we can use the above to show that Θi,j = Θi′′,j′′ and Θi′,j′ = Θi′′,j′′ , for some i′′ 6= i, i′ and j′′ 6= j, j′, and conclude Θi,j = Θi′,j′ ."
    }, {
      "heading" : "B DETAILS OF MODELS",
      "text" : "In the following, all our implementations use Tensorflow (Abadi et al., 2016).\nB.1 MNIST SUMMATION\nAll nonlinearities are exponential linear units (ELU Clevert et al., 2015). All models have 4 convolution layers followed by max-pooling. The convolution layers have respectively 16-32-64-128 output channels and 5× 5 receptive fields. Each pooling, fully-connected and set-layer is followed by a 20% dropout. For models III and IV we use simultaneous dropout. In models I and II, the convolution layers are followed by two fullyconnected layers with 128 hidden units. In model III, after the first fully connected layer we perform\nset-pooling followed by another dense layer with 128 hidden units. In the model IV, the convolution layers are followed by a permutation-equivariant layer with 128 output channels, followed by setpooling and a fully connected layer with 128 hidden units. For optimization, we used a learning rate of .0003 with Adam using the default β1 = .9 and β2 = .999.\nB.2 FACE OUTLIER DETECTION MODEL\nOur model has 9 convolution layers with 3 × 3 receptive fields. The model has convolution layers with 32, 32, 64 feature-maps followed by max-pooling followed by 2D convolution layers with 64, 64, 128 feature-maps followed by another max-pooling layer. The final set of convolution layers have 128, 128, 256 feature-maps, followed by a max-pooling layer with pool-size of 5 that reduces the output dimension to batch− size.N × 256, where the set-size N = 16. This is then forwarded to three permutation-equivariant layers with 256, 128 and 1 output channels. The output of final layer is fed to the Softmax, to identify the outlier. We use exponential linear units (Clevert et al., 2015), drop out with 20% dropout rate at convolutional layers and 50% dropout rate at the first two set layers. When applied to set layers, the selected feature (channel) is simultaneously dropped in all the set members of that particular set. We use Adam (Kingma & Ba, 2014) for optimization and use batch-normalization only in the convolutional layers. We use mini-batches of 8 sets, for a total of 128 images per batch.\nB.3 MODELS FOR POINT-CLOUDS CLASSIFICATION\nSet convolution. We use a network comprising of 3 permutation-equivariant layers with 256 channels followed by max-pooling over the set structure. The resulting vector representation of the set is then fed to a fully connected layer with 256 units followed by a 40-way softmax unit. We use Tanh activation at all layers and dropout on the layers after set-max-pooling (i.e., two dropout operations) with 50% dropout rate. Applying dropout to permutation-equivariant layers for point-cloud data deteriorated the performance. We observed that using different types of permutation-equivariant layers (see Section 2) and as few as 64 channels for set layers changes the result by less than 5% in classification accuracy.\nFor the setting with 5000 particles, we increase the number of units to 512 in all layers and randomly rotate the input around the z-axis. We also randomly scale the point-cloud by s ∼ U(.8, 1./.8). For this setting only, we use Adamax (Kingma & Ba, 2014) instead of Adam and reduce learning rate from .001 to .0005.\nGraph convolution. For each point-cloud instance with 1000 particles, we build a sparse K-nearest neighbor graph and use the three point coordinates as input features. We normalized all graphs at the preprocessing step. For direct comparison with set layer, we use the exact architecture of 3 graphconvolution layer followed by set-pooling (global graph pooling) and dense layer with 256 units. We use exponential linear activation function instead of Tanh as it performs better for graphs. Due to over-fitting, we use a heavy dropout of 50% after graph-convolution and dense layers. Similar to dropout for sets, all the randomly selected features are simultaneously dropped across the graph nodes. the We use a mini-batch size of 64 and Adam for optimization where the learning rate is .001 (the same as that of permutation-equivariant counter-part).\nDespite our efficient sparse implementation using Tensorflow, graph-convolution is significantly slower than the set layer. This prevented a thorough search for hyper-parameters and it is quite possible that better hyper-parameter tuning would improve the results that we report here."
    } ],
    "references" : [ {
      "title" : "Tensorflow: Large-scale machine learning on heterogeneous distributed systems",
      "author" : [ "Martın Abadi", "Ashish Agarwal", "Paul Barham", "Eugene Brevdo", "Zhifeng Chen", "Craig Citro", "Greg S Corrado", "Andy Davis", "Jeffrey Dean", "Matthieu Devin" ],
      "venue" : "arXiv preprint arXiv:1603.04467,",
      "citeRegEx" : "Abadi et al\\.,? \\Q2016\\E",
      "shortCiteRegEx" : "Abadi et al\\.",
      "year" : 2016
    }, {
      "title" : "Galactic astronomy",
      "author" : [ "James Binney", "Michael Merrifield" ],
      "venue" : null,
      "citeRegEx" : "Binney and Merrifield.,? \\Q1998\\E",
      "shortCiteRegEx" : "Binney and Merrifield.",
      "year" : 1998
    }, {
      "title" : "Generative and discriminative voxel modeling with convolutional neural networks",
      "author" : [ "Andrew Brock", "Theodore Lim", "JM Ritchie", "Nick Weston" ],
      "venue" : "arXiv preprint arXiv:1608.04236,",
      "citeRegEx" : "Brock et al\\.,? \\Q2016\\E",
      "shortCiteRegEx" : "Brock et al\\.",
      "year" : 2016
    }, {
      "title" : "Spectral networks and locally connected networks on graphs",
      "author" : [ "Joan Bruna", "Wojciech Zaremba", "Arthur Szlam", "Yann LeCun" ],
      "venue" : "arXiv preprint arXiv:1312.6203,",
      "citeRegEx" : "Bruna et al\\.,? \\Q2013\\E",
      "shortCiteRegEx" : "Bruna et al\\.",
      "year" : 2013
    }, {
      "title" : "Shapenet: An information-rich 3d model repository",
      "author" : [ "Angel X Chang", "Thomas Funkhouser", "Leonidas Guibas", "Pat Hanrahan", "Qixing Huang", "Zimo Li", "Silvio Savarese", "Manolis Savva", "Shuran Song", "Hao Su" ],
      "venue" : "arXiv preprint arXiv:1512.03012,",
      "citeRegEx" : "Chang et al\\.,? \\Q2015\\E",
      "shortCiteRegEx" : "Chang et al\\.",
      "year" : 2015
    }, {
      "title" : "Unsupervised deep haar scattering on graphs",
      "author" : [ "Xu Chen", "Xiuyuan Cheng", "Stéphane Mallat" ],
      "venue" : "In Advances in Neural Information Processing Systems,",
      "citeRegEx" : "Chen et al\\.,? \\Q2014\\E",
      "shortCiteRegEx" : "Chen et al\\.",
      "year" : 2014
    }, {
      "title" : "Groups and group convolutions",
      "author" : [ "Olah Christopher" ],
      "venue" : "http://colah.github.io/posts/ 2014-12-Groups-Convolution/,",
      "citeRegEx" : "Christopher.,? \\Q2014\\E",
      "shortCiteRegEx" : "Christopher.",
      "year" : 2014
    }, {
      "title" : "Fast and accurate deep network learning by exponential linear units (elus)",
      "author" : [ "Djork-Arné Clevert", "Thomas Unterthiner", "Sepp Hochreiter" ],
      "venue" : "arXiv preprint arXiv:1511.07289,",
      "citeRegEx" : "Clevert et al\\.,? \\Q2015\\E",
      "shortCiteRegEx" : "Clevert et al\\.",
      "year" : 2015
    }, {
      "title" : "Group equivariant convolutional networks",
      "author" : [ "Taco S Cohen", "Max Welling" ],
      "venue" : "arXiv preprint arXiv:1602.07576,",
      "citeRegEx" : "Cohen and Welling.,? \\Q2016\\E",
      "shortCiteRegEx" : "Cohen and Welling.",
      "year" : 2016
    }, {
      "title" : "Slicing through multicolor space: Galaxy redshifts from broadband photometry",
      "author" : [ "AJ Connolly", "I Csabai", "AS Szalay", "DC Koo", "RG Kron", "JA Munn" ],
      "venue" : "arXiv preprint astro-ph/9508100,",
      "citeRegEx" : "Connolly et al\\.,? \\Q1995\\E",
      "shortCiteRegEx" : "Connolly et al\\.",
      "year" : 1995
    }, {
      "title" : "Symmetric Functions and Allied Tables",
      "author" : [ "F.N. David", "M.S. Kendall", "D.E. Barton" ],
      "venue" : null,
      "citeRegEx" : "David et al\\.,? \\Q1966\\E",
      "shortCiteRegEx" : "David et al\\.",
      "year" : 1966
    }, {
      "title" : "Convolutional networks on graphs for learning molecular fingerprints",
      "author" : [ "David K Duvenaud", "Dougal Maclaurin", "Jorge Iparraguirre", "Rafael Bombarell", "Timothy Hirzel", "Alán AspuruGuzik", "Ryan P Adams" ],
      "venue" : "In Advances in Neural Information Processing Systems,",
      "citeRegEx" : "Duvenaud et al\\.,? \\Q2015\\E",
      "shortCiteRegEx" : "Duvenaud et al\\.",
      "year" : 2015
    }, {
      "title" : "Deep symmetry networks",
      "author" : [ "Robert Gens", "Pedro M Domingos" ],
      "venue" : "In Advances in neural information processing systems,",
      "citeRegEx" : "Gens and Domingos.,? \\Q2014\\E",
      "shortCiteRegEx" : "Gens and Domingos.",
      "year" : 2014
    }, {
      "title" : "Batch normalization: Accelerating deep network training by reducing internal covariate shift",
      "author" : [ "Sergey Ioffe", "Christian Szegedy" ],
      "venue" : "arXiv preprint arXiv:1502.03167,",
      "citeRegEx" : "Ioffe and Szegedy.,? \\Q2015\\E",
      "shortCiteRegEx" : "Ioffe and Szegedy.",
      "year" : 2015
    }, {
      "title" : "Deep recursive neural networks for compositionality in language",
      "author" : [ "Ozan Irsoy", "Claire Cardie" ],
      "venue" : "In Advances in Neural Information Processing Systems,",
      "citeRegEx" : "Irsoy and Cardie.,? \\Q2014\\E",
      "shortCiteRegEx" : "Irsoy and Cardie.",
      "year" : 2014
    }, {
      "title" : "Adam: A method for stochastic optimization",
      "author" : [ "Diederik Kingma", "Jimmy Ba" ],
      "venue" : "arXiv preprint arXiv:1412.6980,",
      "citeRegEx" : "Kingma and Ba.,? \\Q2014\\E",
      "shortCiteRegEx" : "Kingma and Ba.",
      "year" : 2014
    }, {
      "title" : "Gradient-based learning applied to document recognition",
      "author" : [ "Yann LeCun", "Léon Bottou", "Yoshua Bengio", "Patrick Haffner" ],
      "venue" : "Proceedings of the IEEE,",
      "citeRegEx" : "LeCun et al\\.,? \\Q1998\\E",
      "shortCiteRegEx" : "LeCun et al\\.",
      "year" : 1998
    }, {
      "title" : "A mesh reconstruction algorithm driven by an intrinsic property of a point cloud",
      "author" : [ "Hong-Wei Lin", "Chiew-Lan Tai", "Guo-Jin Wang" ],
      "venue" : "Computer-Aided Design,",
      "citeRegEx" : "Lin et al\\.,? \\Q2004\\E",
      "shortCiteRegEx" : "Lin et al\\.",
      "year" : 2004
    }, {
      "title" : "Deep learning face attributes in the wild",
      "author" : [ "Ziwei Liu", "Ping Luo", "Xiaogang Wang", "Xiaoou Tang" ],
      "venue" : "In Proceedings of International Conference on Computer Vision (ICCV),",
      "citeRegEx" : "Liu et al\\.,? \\Q2015\\E",
      "shortCiteRegEx" : "Liu et al\\.",
      "year" : 2015
    }, {
      "title" : "Voxnet: A 3d convolutional neural network for real-time object recognition",
      "author" : [ "Daniel Maturana", "Sebastian Scherer" ],
      "venue" : "In Intelligent Robots and Systems (IROS),",
      "citeRegEx" : "Maturana and Scherer.,? \\Q2015\\E",
      "shortCiteRegEx" : "Maturana and Scherer.",
      "year" : 2015
    }, {
      "title" : "Estimating cosmological parameters from the dark matter distribution",
      "author" : [ "Siamak Ravanbakhsh", "Junier Oliva", "Sebastien Fromenteau", "Layne C Price", "Shirley Ho", "Jeff Schneider", "Barnabás Póczos" ],
      "venue" : "In Proceedings of The 33rd International Conference on Machine Learning,",
      "citeRegEx" : "Ravanbakhsh et al\\.,? \\Q2016\\E",
      "shortCiteRegEx" : "Ravanbakhsh et al\\.",
      "year" : 2016
    }, {
      "title" : "Multi-instance learning",
      "author" : [ "Soumya Ray", "Stephen Scott", "Hendrik Blockeel" ],
      "venue" : "In Encyclopedia of Machine Learning,",
      "citeRegEx" : "Ray et al\\.,? \\Q2011\\E",
      "shortCiteRegEx" : "Ray et al\\.",
      "year" : 2011
    }, {
      "title" : "Rykoff. redmapper ii: X-ray and sz performance benchmarks for the sdss catalog",
      "author" : [ "Eduardo Rozo", "Eli S" ],
      "venue" : "The Astrophysical Journal,",
      "citeRegEx" : "Rozo and S,? \\Q2014\\E",
      "shortCiteRegEx" : "Rozo and S",
      "year" : 2014
    }, {
      "title" : "3D is here: Point Cloud Library (PCL)",
      "author" : [ "Radu Bogdan Rusu", "Steve Cousins" ],
      "venue" : "In IEEE International Conference on Robotics and Automation (ICRA),",
      "citeRegEx" : "Rusu and Cousins.,? \\Q2011\\E",
      "shortCiteRegEx" : "Rusu and Cousins.",
      "year" : 2011
    }, {
      "title" : "Deeppano: Deep panoramic representation for 3-d shape recognition",
      "author" : [ "Baoguang Shi", "Song Bai", "Zhichao Zhou", "Xiang Bai" ],
      "venue" : "IEEE Signal Processing Letters,",
      "citeRegEx" : "Shi et al\\.,? \\Q2015\\E",
      "shortCiteRegEx" : "Shi et al\\.",
      "year" : 2015
    }, {
      "title" : "Recursive deep models for semantic compositionality over a sentiment treebank",
      "author" : [ "Richard Socher", "Alex Perelygin", "Jean Y Wu", "Jason Chuang", "Christopher D Manning", "Andrew Y Ng", "Christopher Potts" ],
      "venue" : "In Proceedings of the conference on empirical methods in natural language processing (EMNLP),",
      "citeRegEx" : "Socher et al\\.,? \\Q2013\\E",
      "shortCiteRegEx" : "Socher et al\\.",
      "year" : 2013
    }, {
      "title" : "Dropout: a simple way to prevent neural networks from overfitting",
      "author" : [ "Nitish Srivastava", "Geoffrey E Hinton", "Alex Krizhevsky", "Ilya Sutskever", "Ruslan Salakhutdinov" ],
      "venue" : "Journal of Machine Learning Research,",
      "citeRegEx" : "Srivastava et al\\.,? \\Q1929\\E",
      "shortCiteRegEx" : "Srivastava et al\\.",
      "year" : 1929
    }, {
      "title" : "Multi-view convolutional neural networks for 3d shape recognition",
      "author" : [ "Hang Su", "Subhransu Maji", "Evangelos Kalogerakis", "Erik Learned-Miller" ],
      "venue" : "In Proceedings of the IEEE International Conference on Computer Vision, pp",
      "citeRegEx" : "Su et al\\.,? \\Q2015\\E",
      "shortCiteRegEx" : "Su et al\\.",
      "year" : 2015
    }, {
      "title" : "Learning theory for distribution regression",
      "author" : [ "Z. Szabo", "B. Sriperumbudur", "B. Poczos", "A. Gretton" ],
      "venue" : "Journal of Machine Learning Research,",
      "citeRegEx" : "Szabo et al\\.,? \\Q2016\\E",
      "shortCiteRegEx" : "Szabo et al\\.",
      "year" : 2016
    }, {
      "title" : "Learning a probabilistic latent space of object shapes via 3d generative-adversarial modeling",
      "author" : [ "Jiajun Wu", "Chengkai Zhang", "Tianfan Xue", "William T Freeman", "Joshua B Tenenbaum" ],
      "venue" : "arXiv preprint arXiv:1610.07584,",
      "citeRegEx" : "Wu et al\\.,? \\Q2016\\E",
      "shortCiteRegEx" : "Wu et al\\.",
      "year" : 2016
    }, {
      "title" : "3d shapenets: A deep representation for volumetric shapes",
      "author" : [ "Zhirong Wu", "Shuran Song", "Aditya Khosla", "Fisher Yu", "Linguang Zhang", "Xiaoou Tang", "Jianxiong Xiao" ],
      "venue" : "In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition,",
      "citeRegEx" : "Wu et al\\.,? \\Q2015\\E",
      "shortCiteRegEx" : "Wu et al\\.",
      "year" : 2015
    }, {
      "title" : "Multi-instance learning by treating instances as non-iid samples",
      "author" : [ "Zhi-Hua Zhou", "Yu-Yin Sun", "Yu-Feng Li" ],
      "venue" : "In Proceedings of the 26th annual international conference on machine learning,",
      "citeRegEx" : "Zhou et al\\.,? \\Q2009\\E",
      "shortCiteRegEx" : "Zhou et al\\.",
      "year" : 2009
    } ],
    "referenceMentions" : [ {
      "referenceID" : 3,
      "context" : ", 2015) has witnessed its application to structured settings, including graphs (Bruna et al., 2013; Duvenaud et al., 2015) groups (Gens & Domingos, 2014; Christopher, 2014; Cohen & Welling, 2016), sequences and hierarchies (Irsoy & Cardie, 2014; Socher et al.",
      "startOffset" : 79,
      "endOffset" : 122
    }, {
      "referenceID" : 11,
      "context" : ", 2015) has witnessed its application to structured settings, including graphs (Bruna et al., 2013; Duvenaud et al., 2015) groups (Gens & Domingos, 2014; Christopher, 2014; Cohen & Welling, 2016), sequences and hierarchies (Irsoy & Cardie, 2014; Socher et al.",
      "startOffset" : 79,
      "endOffset" : 122
    }, {
      "referenceID" : 6,
      "context" : ", 2015) groups (Gens & Domingos, 2014; Christopher, 2014; Cohen & Welling, 2016), sequences and hierarchies (Irsoy & Cardie, 2014; Socher et al.",
      "startOffset" : 15,
      "endOffset" : 80
    }, {
      "referenceID" : 25,
      "context" : ", 2015) groups (Gens & Domingos, 2014; Christopher, 2014; Cohen & Welling, 2016), sequences and hierarchies (Irsoy & Cardie, 2014; Socher et al., 2013).",
      "startOffset" : 108,
      "endOffset" : 151
    }, {
      "referenceID" : 5,
      "context" : "In a related work Chen et al. (2014) construct deep permutation invariant features by pairwise coupling of features at the previous layer, where fi,j([xi, xj ]) .",
      "startOffset" : 18,
      "endOffset" : 37
    }, {
      "referenceID" : 16,
      "context" : "MNIST dataset (LeCun et al., 1998) contains 70,000 instances of 28×28 grey-scale stamps of digits in {0, .",
      "startOffset" : 14,
      "endOffset" : 34
    }, {
      "referenceID" : 30,
      "context" : "3% set-layer (ours) 1000× 3 point-cloud 87± 1% set-pooling only (ours) 1000× 3 point-cloud 83± 1% set-layer (ours) 100× 3 point-cloud 82± 2% KNN graph-convolution (ours) 1000× (3 + 8) directed 8-regular graph 58± 2% 3DShapeNets (Wu et al., 2015) 30 voxels (using convolutional deep belief net) 77% DeepPano (Shi et al.",
      "startOffset" : 228,
      "endOffset" : 245
    }, {
      "referenceID" : 24,
      "context" : ", 2015) 30 voxels (using convolutional deep belief net) 77% DeepPano (Shi et al., 2015) 64× 160 panoramic image (2D CNN + angle-pooling) 77.",
      "startOffset" : 69,
      "endOffset" : 87
    }, {
      "referenceID" : 27,
      "context" : "10% MVCNN (Su et al., 2015) 164× 164× 12 multi-vew images (2D CNN + view-pooling) 90.",
      "startOffset" : 10,
      "endOffset" : 27
    }, {
      "referenceID" : 2,
      "context" : "1% VRN Ensemble (Brock et al., 2016) 32 voxels (3D CNN, variational autoencoder) 95.",
      "startOffset" : 16,
      "endOffset" : 36
    }, {
      "referenceID" : 29,
      "context" : "54% 3D GAN (Wu et al., 2016) 64 voxels (3D CNN, generative adversarial training) 83.",
      "startOffset" : 11,
      "endOffset" : 28
    }, {
      "referenceID" : 20,
      "context" : "In these applications, point-cloud data is often converted to voxel or mesh representation at a preprocessing step (e.g., Maturana & Scherer, 2015; Ravanbakhsh et al., 2016; Lin et al., 2004).",
      "startOffset" : 115,
      "endOffset" : 191
    }, {
      "referenceID" : 17,
      "context" : "In these applications, point-cloud data is often converted to voxel or mesh representation at a preprocessing step (e.g., Maturana & Scherer, 2015; Ravanbakhsh et al., 2016; Lin et al., 2004).",
      "startOffset" : 115,
      "endOffset" : 191
    }, {
      "referenceID" : 4,
      "context" : "(5) to classify point-cloud representation of a subset of ShapeNet objects (Chang et al., 2015), called ModelNet40 (Wu et al.",
      "startOffset" : 75,
      "endOffset" : 95
    }, {
      "referenceID" : 30,
      "context" : ", 2015), called ModelNet40 (Wu et al., 2015).",
      "startOffset" : 27,
      "endOffset" : 44
    }, {
      "referenceID" : 24,
      "context" : "Interestingly, variations of view/angle-pooling (e.g., Su et al., 2015; Shi et al., 2015) can be interpreted as set-pooling where the class-label is invariant to permutation of different views.",
      "startOffset" : 48,
      "endOffset" : 89
    }, {
      "referenceID" : 18,
      "context" : "CelebA dataset (Liu et al., 2015) contains The error-bar on our results is due to variations depending on the choice of particles during test time and it is estimated over three trials.",
      "startOffset" : 15,
      "endOffset" : 33
    }, {
      "referenceID" : 9,
      "context" : "One way to estimate the red-shift from photometric observations is using a regression model (Connolly et al., 1995).",
      "startOffset" : 92,
      "endOffset" : 115
    }, {
      "referenceID" : 21,
      "context" : "Our treatment of set structure also generalizes various settings in multi-instance learning (Ray et al., 2011; Zhou et al., 2009).",
      "startOffset" : 92,
      "endOffset" : 129
    }, {
      "referenceID" : 31,
      "context" : "Our treatment of set structure also generalizes various settings in multi-instance learning (Ray et al., 2011; Zhou et al., 2009).",
      "startOffset" : 92,
      "endOffset" : 129
    }, {
      "referenceID" : 28,
      "context" : "In addition to our experimental settings, the permutation-invariant layer can be used for distribution regression and classification which have become popular recently (Szabo et al., 2016).",
      "startOffset" : 168,
      "endOffset" : 188
    } ],
    "year" : 2017,
    "abstractText" : "We introduce a simple permutation equivariant layer for deep learning with set structure. This type of layer, obtained by parameter-sharing, has a simple implementation and linear-time complexity in the size of each set. We use deep permutation-invariant networks to perform point-could classification and MNISTdigit summation, where in both cases the output is invariant to permutations of the input. In a semi-supervised setting, where the goal is make predictions for each instance within a set, we demonstrate the usefulness of this type of layer in set-outlier detection as well as semi-supervised learning with clustering sideinformation.",
    "creator" : "LaTeX with hyperref package"
  }
}