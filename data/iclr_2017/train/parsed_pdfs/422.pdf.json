{
  "name" : "422.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "DEEP VARIATIONAL BAYES FILTERS: UNSUPERVISED LEARNING OF STATE SPACE MODELS FROM RAW DATA",
    "authors" : [ "Maximilian Karl", "Maximilian Soelch", "Justin Bayer", "Patrick van der Smagt" ],
    "emails" : [ "[@volkswagen.de])" ],
    "sections" : [ {
      "heading" : null,
      "text" : "We introduce Deep Variational Bayes Filters (DVBF), a new method for unsupervised learning and identification of latent Markovian state space models. Leveraging recent advances in Stochastic Gradient Variational Bayes, DVBF can overcome intractable inference distributions via variational inference. Thus, it can handle highly nonlinear input data with temporal and spatial dependencies such as image sequences without domain knowledge. Our experiments show that enabling backpropagation through transitions enforces state space assumptions and significantly improves information content of the latent embedding. This also enables realistic long-term prediction."
    }, {
      "heading" : "1 INTRODUCTION",
      "text" : "Estimating probabilistic models for sequential data is central to many domains, such as audio, natural language or physical plants, Graves (2013); Watter et al. (2015); Chung et al. (2015); Deisenroth & Rasmussen (2011); Ko & Fox (2011). The goal is to obtain a model p(x1:T ) that best reflects a data set of observed sequences x1:T . Recent advances in deep learning have paved the way to powerful models capable of representing high-dimensional sequences with temporal dependencies, e.g., Graves (2013); Watter et al. (2015); Chung et al. (2015); Bayer & Osendorfer (2014).\nTime series for dynamic systems have been studied extensively in systems theory, cf. McGoff et al. (2015) and sources therein. In particular, state space models have shown to be a powerful tool to analyze and control the dynamics. Two tasks remain a significant challenge to this day: Can we identify the governing system from data only? And can we perform inference from observables to the latent system variables? These two tasks are competing: A more powerful representation of system requires more computationally demanding inference, and efficient inference, such as the well-known Kalman filters, Kalman & Bucy (1961), can prohibit sufficiently complex system classes.\nLeveraging a recently proposed estimator based on variational inference, stochastic gradient variational Bayes (SGVB, Kingma & Welling (2013); Rezende et al. (2014)), approximate inference of latent variables becomes tractable. Extensions to time series have been shown in Bayer & Osendorfer (2014); Chung et al. (2015). Empirically, they showed considerable improvements in marginal data likelihood, i.e., compression, but lack full-information latent states, which prohibits, e.g., long-term sampling. Yet, in a wide range of applications, full-information latent states should be valued over compression. This is crucial if the latent spaces are used in downstream applications.\nOur contribution is, to our knowledge, the first model that (i) enforces the latent state-space model assumptions, allowing for reliable system identification, and plausible long-term prediction of the observable system, (ii) provides the corresponding inference mechanism with rich dependencies, (iii) inherits the merit of neural architectures to be trainable on raw data such as images or other sensory inputs, and (iv) scales to large data due to optimization of parameters based on stochastic gradient descent, Bottou (2010). Hence, our model has the potential to exploit systems theory methodology for downstream tasks, e.g., control or model-based reinforcement learning, Sutton (1996)."
    }, {
      "heading" : "2 BACKGROUND AND RELATED WORK",
      "text" : ""
    }, {
      "heading" : "2.1 PROBABILISTIC MODELING AND FILTERING OF DYNAMICAL SYSTEMS",
      "text" : "We consider non-linear dynamical systems with observations xt ∈ X ⊂ Rnx , depending on control inputs (or actions) ut ∈ U ⊂ Rnu . Elements of X can be high-dimensional sensory data, e.g., raw images. In particular they may exhibit complex non-Markovian transitions. Corresponding timediscrete sequences of length T are denoted as x1:T = (x1,x2, . . . ,xT ) and u1:T = (u1,u2, . . . ,uT ).\nWe are interested in a probabilistic model1 p(x1:T | u1:T ). Formally, we assume the graphical model p(x1:T | u1:T ) = ∫ p(x1:T | z1:T ,u1:T ) p(z1:T | u1:T ) dz1:T , (1)\nwhere z1:T , zt ∈ Z ⊂ Rnz , denotes the corresponding latent sequence. That is, we assume a generative model with an underlying latent dynamical system with emission model p(x1:T | z1:T ,u1:T ) and transition model p(z1:T | u1:T ). We want to learn both components, i.e., we want to perform latent system identification. In order to be able to apply the identified system in downstream tasks, we need to find efficient posterior inference distributions p(z1:T | x1:T ). Three common examples are prediction, filtering, and smoothing: inference of zt from x1:t−1, x1:t, or x1:T , respectively. Accurate identification and efficient inference are generally competing tasks, as a wider generative model class typically leads to more difficult or even intractable inference.\nThe transition model is imperative for achieving good long-term results: a bad transition model can lead to divergence of the latent state. Accordingly, we put special emphasis on it through a Bayesian treatment. Assuming that the transitions may differ for each time step, we impose a regularizing prior distribution on a set of transition parameters β1:T :\n(1) = ∫∫\np(x1:T | z1:T ,u1:T )p(z1:T | β1:T ,u1:T ) p(β1:T ) dβ1:T dz1:T (2)\nTo obtain state-space models, we impose assumptions on emission and state transition model,\np(x1:T | z1:T ,u1:T ) = T∏ t=1 p(xt | zt), (3)\np(z1:T | β1:T ,u1:T ) = T−1∏ t=0 p(zt+1 | zt,ut,βt). (4)\nEquations (3) and (4) assume that the current state zt contains all necessary information about the current observation xt, as well as the next state zt+1 (given the current control input ut and transition parameters βt). That is, in contrast to observations, zt exhibits Markovian behavior.\nA typical example of these assumptions are Linear Gaussian Models (LGMs), i.e., both state transition and emission model are affine transformations with Gaussian offset noise,\nzt+1 = Ftzt +Btut +wt wt ∼ N (0,Qt), (5) xt = Htzt + yt yt ∼ N (0,Rt). (6)\nTypically, state transition matrix Ft and control-input matrix Bt are assumed to be given, so that βt = wt. Section 3.3 will show that our approach allows other variants such as βt = (Ft,Bt,wt). Under the strong assumptions (5) and (6) of LGMs, inference is provably solved optimally by the well-known Kalman filters. While extensions of Kalman filters to nonlinear dynamical systems exist, Julier & Uhlmann (1997), and are successfully applied in many areas, they suffer from two major drawbacks: firstly, its assumptions are restrictive and are violated in practical applications, leading to suboptimal results. Secondly, parameters such as Ft and Bt have to be known in order to perform posterior inference. There have been efforts to learn such system dynamics, cf. Ghahramani & Hinton (1996); Honkela et al. (2010) based on the expectation maximization (EM) algorithm or Valpola & Karhunen (2002), which uses neural networks. However, these algorithms are not applicable in cases\n1Throughout this paper, we consider u1:T as given. The case without any control inputs can be recovered by setting U = ∅, i.e., not conditioning on control inputs.\nwhere the true posterior distribution is intractable. This is the case if, e.g., image sequences are used, since the posterior is then highly nonlinear—typical mean-field assumptions on the approximate posterior are too simplified. Our new approach will tackle both issues, and moreover learn both identification and inference jointly by exploiting Stochastic Gradient Variational Bayes."
    }, {
      "heading" : "2.2 STOCHASTIC GRADIENT VARIATIONAL BAYES (SGVB) FOR TIME SERIES DISTRIBUTIONS",
      "text" : "Replacing the bottleneck layer of a deterministic auto-encoder with stochastic units z, the variational auto-encoder (VAE, Kingma & Welling (2013); Rezende et al. (2014)) learns complex marginal data distributions on x in an unsupervised fashion from simpler distributions via the graphical model\np(x) = ∫ p(x, z) dz = ∫ p(x | z)p(z) dz.\nIn VAEs, p(x | z) ≡ pθ(x | z) is typically parametrized by a neural network with parameters θ. Within this framework, models are trained by maximizing a lower bound to the marginal data log-likelihood via stochastic gradients:\nln p(x) ≥ Eqφ(z|x)[ln pθ(x | z)]−KL(qφ(z | x) || p(z)) =: LSGVB(x, φ, θ) (7) This is provably equivalent to minimizing the KL-divergence between the approximate posterior or recognition model qφ(z | x) and the true, but usually intractable posterior distribution p(z | x). qφ is parametrized by a neural network with parameters φ.\nThe principle of VAEs has been transferred to time series, Bayer & Osendorfer (2014); Chung et al. (2015). Both employ nonlinear state transitions in latent space, but violate eq. (4): Observations are directly included in the transition process. Empirically, reconstruction and compression work well. The state space Z , however, does not reflect all information available, which prohibits plausible generative long-term prediction. Such phenomena with generative models have been explained in Theis et al. (2015).\nIn Krishnan et al. (2015), the state-space assumptions (3) and (4) are softly encoded in the Deep Kalman Filter (DKF) model. Despite that, experiments, cf. section 4, show that their model fails to extract information such as velocity (and in general time derivatives), which leads to similar problems with prediction.\nJohnson et al. (2016) give an algorithm for general graphical model variational inference, not tailored to dynamical systems. In contrast to previously discussed methods, it does not violate eq. (4). The approaches differ in that the recognition model outputs node potentials in combination with message passing to infer the latent state. Our approach focuses on learning dynamical systems for controlrelated tasks and therefore uses a neural network for inferring the latent state directly instead of an inference subroutine.\nOthers have been specifically interested in applying variational inference for controlled dynamical systems. In Watter et al. (2015) (Embed to Control—E2C), a VAE is used to learn the mappings to and from latent space. The regularization is clearly motivated by eq. (7). Still, it fails to be a mathematically correct lower bound to the marginal data likelihood. More significantly, their recognition model requires all observations that contain information w.r.t. the current state. This is nothing short of an additional temporal i.i.d. assumption on data: Multiple raw samples need to be stacked into one training sample such that all latent factors (in particular all time derivatives) are present within one sample. The task is thus greatly simplified, because instead of time-series, we learn a static auto-encoder on the processed data.\nA pattern emerges: good prediction should boost compression. Still, previous methods empirically excel at compression, while prediction will not work. We conjecture that this is caused by previous methods trying to fit the latent dynamics to a latent state that is beneficial for reconstruction. This encourages learning of a stationary auto-encoder with focus of extracting as much from a single observation as possible. Importantly, it is not necessary to know the entire sequence for excellent reconstruction of single time steps. Once the latent states are set, it is hard to adjust the transition to them. This would require changing the latent states slightly, and that comes at a cost of decreasing the reconstruction (temporarily). The learning algorithm is stuck in a local optimum with good reconstruction and hence good compression only. Intriguingly, E2C bypasses this problem with its data augmentation.\nThis leads to a key contribution of this paper: We force the latent space to fit the transition—reversing the direction, and thus achieving the state-space model assumptions and full information in the latent states."
    }, {
      "heading" : "3 DEEP VARIATIONAL BAYES FILTERS",
      "text" : ""
    }, {
      "heading" : "3.1 REPARAMETRIZING THE TRANSITION",
      "text" : "The central problem for learning latent states system dynamics is efficient inference of a latent space that obeys state-space model assumptions. If the latter are fulfilled, the latent space must contain all information. Previous approaches emphasized good reconstruction, so that the space only contains information necessary for reconstruction of one time step. To overcome this, we establish gradient paths through transitions over time so that the transition becomes the driving factor for shaping the latent space, rather than adjusting the transition to the recognition model’s latent space. The key is to prevent the recognition model qφ(z1:T | x1:T ) from directly drawing the latent state zt. Similar to the reparametrization trick from Kingma & Welling (2013); Rezende et al. (2014) for making the Monte Carlo estimate differentiable w.r.t. the parameters, we make the transition differentiable w.r.t. the last state and its parameters:\nzt+1 = f(zt,ut,βt) (8) Given the stochastic parameters βt, the state transition is deterministic (which in turn means that by marginalizing βt, we still have a stochastic transition). The immediate and crucial consequence is that errors in reconstruction of xt from zt are backpropagated directly through time.\nThis reparametrization has a couple of other important implications: the recognition model no longer infers latent states zt, but transition parameters βt. In particular, the gradient ∂zt+1/∂zt is well-defined from (8)—gradient information can be backpropagated through the transition.\nThis is different from the method used in Krishnan et al. (2015), where the transition only occurs in the KL-divergence term of their loss function (a variant of eq. (7)). No gradient from the generative model is backpropagated through the transitions.\nMuch like in eq. (5), the stochastic parameters includes a corrective offset term wt, which emphasizes the notion of the recognition model as a filter. In theory, the learning algorithm could still learn the transition as zt+1 = wt. However, the introduction of βt also enables us to regularize the transition with meaningful priors, which not only prevents overfitting the recognition model, but also enforces meaningful manifolds in the latent space via transition priors. Ignoring the potential of the transition over time yields large penalties from these priors. Thus, the problems outlined in Section 2 are overcome by construction.\nTo install such transition priors, we split βt = (wt,vt). The interpretation of wt is a sample-specific process noise which can be inferred from incoming data, like in eq. (5). On the other hand, vt\nare universal transition parameters, which are sample-independent (and are only inferred from data during training). This corresponds to the idea of weight uncertainty in Hinton & Van Camp (1993). This interpretation leads to a natural factorization assumption on the recognition model:\nqφ(β1:T | x1:T ) = qφ(w1:T | x1:T ) qφ(v1:T ) (9)\nWhen using the fully trained model for generative sampling, i.e., sampling without input, the universal state transition parameters can still be drawn from qφ(v1:T ), whereas w1:T is drawn from the prior in the absence of input data.\nFigure 1 shows the underlying graphical model and the inference procedure. Figure 2a shows a generic view on our new computational architecture. An example of a locally linear transition parametrization will be given in section 3.3."
    }, {
      "heading" : "3.2 THE LOWER BOUND OBJECTIVE FUNCTION",
      "text" : "In analogy to eq. (7), we now derive a lower bound to the marginal likelihood p(x1:T | u1:T ). After reflecting the Markov assumptions (3) and (4) in the factorized likelihood (2), we have:\np(x1:T | u1:T ) = ∫∫ p(β1:T ) T∏ t=1 pθ(xt | zt) T−1∏ t=0 p(zt+1 | zt,ut,βt) dβ1:T dz1:T\nDue to the deterministic transition given βt+1, the last term is a product of Dirac distributions and the overall distribution simplifies greatly:\np(x1:T | u1:T ) = ∫ p(β1:T ) T∏ t=1 pθ(xt | zt) ∣∣∣ zt=f(zt−1,ut−1,βt−1)\ndβ1:T( = ∫ p(β1:T )pθ(x1:T | z1:T ) dβ1:T )\nThe last formulation is for notational brevity: the term pθ(x1:T | z1:T ) is not independent of β1:T and u1:T . We now derive the objective function, a lower bound to the data likelihood:\nln p(x1:T | u1:T ) = ln ∫ p(β1:T )pθ(x1:T | z1:T )\nqφ(β1:T | x1:T ,u1:T ) qφ(β1:T | x1:T ,u1:T ) dβ1:T\n≥ ∫ qφ(β1:T | x1:T ,u1:T ) ln ( pθ(x1:T | z1:T )\np(β1:T )\nqφ(β1:T | x1:T ,u1:T )\n) dβ1:T\n= Eqφ [ln pθ(x1:T | z1:T )− ln qφ(β1:T | x1:T ,u1:T ) + ln p(β1:T )] (10) = Eqφ [ln pθ(x1:T | z1:T )]−KL(qφ(β1:T | x1:T ,u1:T ) || p(β1:T )) (11) =: LDVBF(x1:T , θ, φ | u1:T )\nOur experiments show that an annealed version of (10) is beneficial to the overall performance:\n(10′) = Eqφ [ci ln pθ(x1:T | z1:T )− ln qφ(β1:T | x1:T ,u1:T ) + ci ln p(w1:T ) + ln p(v1:T )] Here, ci = max(1, 0.01 + i/TA) is an inverse temperature that increases linearly in the number of gradient updates i until reaching 1 after TA annealing iterations. Similar annealing schedules have been applied in, e.g., Ghahramani & Hinton (2000); Mandt et al. (2016); Rezende & Mohamed (2015), where it is shown that they smooth the typically highly non-convex error landscape. Additionally, the transition prior p(v1:T ) was estimated during optimization, i.e., through an empirical Bayes approach. In all experiments, we used isotropic Gaussian priors."
    }, {
      "heading" : "3.3 EXAMPLE: LOCALLY LINEAR TRANSITIONS",
      "text" : "We have derived a learning algorithm for time series with particular focus on general transitions in latent space. Inspired by Watter et al. (2015), this section will show how to learn a particular instance: locally linear state transitions. That is, we set eq. (8) to\nzt+1 = Atzt +Btut +Ctwt, t = 1, . . . , T, (12)\nwhere wt is a stochastic sample from the recognition model and At,Bt, and Ct are matrices of matching dimensions. They are stochastic functions of zt and ut (thus local linearity). We draw\nvt = { A (i) t ,B (i) t ,C (i) t | i = 1, . . . ,M } ,\nfrom qφ(vt), i.e.,M triplets of matrices, each corresponding to data-independent, but learned globally linear system. These can be learned as point estimates. We employed a Bayesian treatment as in Blundell et al. (2015). We yield At,Bt, and Ct as state- and control-dependent linear combinations:\nAt = M∑ i=1 α (i) t A (i) t\nαt = fψ(zt,ut) ∈ RM\nBt = M∑ i=1 α (i) t B (i) t\nCt = M∑ i=1 α (i) t C (i) t\nThe computation is depicted in fig. 2b. The function fψ can be, e.g., a (deterministic) neural network with weights ψ. As a subset of the generative parameters θ, ψ is part of the trainable parameters of our model. The weight vector αt is shared between the three matrices. There is a correspondence to eq. (5): At and Ft, Bt and Bt, as well as CtC>t and Qt are related.\nWe used this parametrization of the state transition model for our experiments. It is important that the parametrization is up to the user and the respective application."
    }, {
      "heading" : "4 EXPERIMENTS AND RESULTS",
      "text" : "In this section we validate that DVBF with locally linear transitions (DVBF-LL) (section 3.3) outperforms Deep Kalman Filters (DKF, Krishnan et al. (2015)) in recovering latent spaces with full information. 2 We focus on environments that can be simulated with full knowledge of the\n2We do not include E2C, Watter et al. (2015), due to the need for data modification and its inability to provide a correct lower bound as mentioned in section 2.2.\nground truth latent dynamical system. The experimental setup is described in the Supplementary Material. We published the code for DVBF and a link will be made available at https://brml. org/projects/dvbf."
    }, {
      "heading" : "4.1 DYNAMIC PENDULUM",
      "text" : "In order to test our algorithm on truly non-Markovian observations of a dynamical system, we simulated a dynamic torque-controlled pendulum governed by the differential equation\nml2ϕ̈(t) = −µϕ̇(t) +mgl sinϕ(t) + u(t),\nm = l = 1, µ = 0.5, g = 9.81, via numerical integration, and then converted the ground-truth angle ϕ into an image observation in X . The one-dimensional control corresponds to angle acceleration (which is proportional to joint torque). Angle and angular velocity fully describe the system.\nFigure 3 shows the latent spaces for identical input data learned by DVBF-LL and DKF, respectively, colored with the ground truth in the top row. It should be noted that latent samples are shown, not means of posterior distributions. The state-space model was allowed to use three latent dimensions. As we can see in fig. 3a, DVBF-LL learned a two-dimensional manifold embedding, i.e., it encoded the angle in polar coordinates (thus circumventing the discontinuity of angles modulo 2π). The bottom row shows ordinary least-squares regressions (OLS) underlining the performance: there exists a high correlation between latent states and ground-truth angle and angular velocity for DVBF-LL. On the contrary, fig. 3b verifies our prediction that DKF is equally capable of learning the angle, but extracts little to no information on angular velocity.\nThe OLS regression results shown in table 1 validate this observation.3 Predicting sin(ϕ) and cos(ϕ), i.e., polar coordinates of the ground-truth angle ϕ, works almost equally well for DVBF-LL and DKF, with DVBF-LL slightly outperforming DKF. For predicting the ground truth velocity ϕ̇, DVBF-LL\n3Linear regression is a natural choice: after transforming the ground truth to polar coordinates, an affine transformation should be a good fit for predicting ground truth from latent states. We also tried nonlinear regression with vanilla neural networks. While not being shown here, the results underlined the same conclusion.\nTable 1: Results for pendulum OLS regressions of all latent states on respective dependent variable.\nDependent ground truth variable\nDVBF-LL DKF Log-Likelihood R2 Log-Likelihood R2\nsin(ϕ) 3990.8 0.961 1737.6 0.929 cos(ϕ) 7231.1 0.982 6614.2 0.979 ϕ̇ −11139 0.916 −20289 0.035\n(a) Generative latent walk. (b) Reconstructive latent walk.\n...\n...\n... 51 10 15 20 40 45\n(c) Ground truth (top), reconstructions (middle), generative samples (bottom) from identical initial latent state.\nFigure 4: (a) Latent space walk in generative mode. (b) Latent space walk in filtering mode. (c) Ground truth and samples from recognition and generative model. The reconstruction sampling has access to observation sequence and performs filtering. The generative samples only get access to the observations once for creating the initial state while all subsequent samples are predicted from this single initial state. The red bar indicates the length of training sequences. Samples beyond show the generalization capabilities for sequences longer than during training. The complete sequence can be found in the Appendix in fig. 7.\nshows remarkable performance. DKF, instead, contains hardly any information, resulting in a very low goodness-of-fit score of R2 = 0.035.\nFigure 4 shows that the strong relation between ground truth and latent state is beneficial for generative sampling. All plots show 100 time steps of a pendulum starting from the exact same latent state and not being actuated. The top row plots show a purely generative walk in the latent space on the left, and a walk in latent space that is corrected by filtering observations on the right. We can see that both follow a similar trajectory to an attractor. The generative model is more prone to noise when approaching the attractor.\nThe bottom plot shows the first 45 steps of the corresponding observations (top row), reconstructions (middle row), and generative samples (without correcting from observations). Interestingly, DVBF works very well even though the sequence is much longer than all training sequences (indicated by the red line).\nTable (2) shows values of the lower bound to the marginal data likelihood (for DVBF-LL, this corresponds to eq. (11)). We see that DVBF-LL outperforms DKF in terms of compression, but only\nTable 2: Average test set objective function values for pendulum experiment.\nLower Bound = Reconstruction Error − KL divergence DVBF-LL 798.56 802.06 3.50\nDKF 784.70 788.58 3.88\n(a) Latent walk of bouncing ball. (b) Latent space velocities.\nFigure 5: (a) Two dimensions of 4D bouncing ball latent space. Ground truth x and y coordinates are combined into a regular 3×3 checkerboard coloring. This checkerboard is correctly extracted by the embedding. (b) Remaining two latent dimensions. Same latent samples, colored with ball velocities in x and y direction (left and right image, respectively). The smooth, perpendicular coloring indicates that the ground truth value is stored in the latent dimension.\nwith a slight margin, which does not reflect the better generative sampling as Theis et al. (2015) argue."
    }, {
      "heading" : "4.2 BOUNCING BALL",
      "text" : "The bouncing ball experiment features a ball rolling within a bounding box in a plane. The system has a two-dimensional control input, added to the directed velocity of the ball. If the ball hits the wall, it bounces off, so that the true dynamics are highly dependent on the current position and velocity of the ball. The system’s state is four-dimensional, two dimensions each for position and velocity.\nConsequently, we use a DVBF-LL with four latent dimensions. Figure 5 shows that DVBF again captures the entire system dynamics in the latent space. The checkerboard is quite a remarkable result: the ground truth position of the ball lies within the 2D unit square, the bounding box. In order to visualize how ground truth reappears in the learned latent states, we show the warping of the ground truth bounding box into the latent space. To this end, we partitioned (discretized) the ground truth unit square into a regular 3x3 checkerboard with respective coloring. We observed that DVBF learned to extract the 2D position from the 256 pixels, and aligned them in two dimensions of the latent space in strong correspondence to the physical system. The algorithm does the exact same pixel-to-2D inference that a human observer automatically does when looking at the image."
    }, {
      "heading" : "4.3 TWO BOUNCING BALLS",
      "text" : "Another more complex environment4 features two balls in a bounding box. We used a 10-dimensional latent space to fully capture the position and velocity information of the balls. Reconstruction and generative samples are shown in fig. 6. Same as in the pendulum example we get a generative model with stable predictions beyond training data sequence length."
    }, {
      "heading" : "5 CONCLUSION",
      "text" : "We have proposed Deep Variational Bayes Filters (DVBF), a new method to learn state space models from raw non-Markovian sequence data. DVBFs perform latent dynamic system identification, and subsequently overcome intractable inference. As DVBFs make use of stochastic gradient variational Bayes they naturally scale to large data sets. In a series of vision-based experiments we demonstrated that latent states can be recovered which identify the underlying physical quantities. The generative model showed stable long-term predictions far beyond the sequence length used during training."
    }, {
      "heading" : "ACKNOWLEDGEMENTS",
      "text" : "Part of this work was conducted at Chair of Robotics and Embedded Systems, Department of Informatics, Technische Universität München, Germany, and supported by the TACMAN project, EC Grant agreement no. 610967, within the FP7 framework programme.\nWe would like to thank Jost Tobias Springenberg, Adam Kosiorek, Moritz Münst, and anonymous reviewers for valuable input."
    }, {
      "heading" : "A SUPPLEMENTARY TO LOWER BOUND",
      "text" : "A.1 ANNEALED KL-DIVERGENCE\nWe used the analytical solution of the annealed KL-divergence in eq. (10) for optimization:\nEqφ [− ln qφ(w1:T | x1:T ,u1:T ) + ci ln p(w1:T )] =\nci 1\n2 ln(2πσ2p)−\n1 2 ln(2πσ2q ) + ci\nσ2q + (µq − µp)2\n2σ2p − 1 2"
    }, {
      "heading" : "B SUPPLEMENTARY TO IMPLEMENTATION",
      "text" : "B.1 EXPERIMENTAL SETUP\nIn all our experiments, we use sequences of 15 raw images of the respective system with 16×16 pixels each, i.e., observation space X ⊂ R256, as well as control inputs of varying dimension and interpretation depending on the experiment. We used training, validation and test sets with 500 sequences each. Control input sequences were drawn randomly (“motor babbling”). Additional details about the implementation can be found in the published code at https://brml.org/ projects/dvbf.\nB.2 ADDITIONAL EXPERIMENT PLOTS\nB.3 IMPLEMENTATION DETAILS FOR DVBF IN PENDULUM EXPERIMENT\n• Input: 15 timesteps of 162 observation dimensions and 1 action dimension\n• Latent Space: 3 dimensions\n• Observation Network p(xt|zt) = N (xt;µ(zt), σ): 128 ReLU + 162 identity output\n• Recognition Model: 128 ReLU + 6 identity output\nq(wt|zt,xt+1,ut) = N (wt;µ, σ), (µ, σ) = f(zt,xt+1,ut)\n• Transition Network αt(zt): 16 softmax output\n• Initial Network w1 ∼ p(x1:T ): Fast Dropout BiRNN with: 128 ReLU + 3 identity output\n• Initial Transition z1(w1): 128 ReLU + 3 identity output\n• Optimizer: adadelta, 0.1 step rate\n• Inverse temperature: c0 = 0.01, updated every 250th gradient update, TA = 105 iterations\n• Batch-size: 500\nB.4 IMPLEMENTATION DETAILS FOR DVBF IN BOUNCING BALL EXPERIMENT\n• Input: 15 timesteps of 162 observation dimensions and 2 action dimension • Latent Space: 4 dimensions • Observation Network p(xt|zt) = N (xt;µ(zt), σ): 128 ReLU + 162 identity output • Recognition Model: 128 ReLU + 8 identity output\nq(wt|zt,xt+1,ut) = N (wt;µ, σ), (µ, σ) = f(zt,xt+1,ut)\n• Transition Network αt(zt): 16 softmax output • Initial Network w1 ∼ p(x1:T ): Fast Dropout BiRNN with: 128 ReLU + 4 identity output • Initial Transition z1(w1): 128 ReLU + 4 identity output • Optimizer: adadelta, 0.1 step rate • Inverse temperature: c0 = 0.01, updated every 250th gradient update, TA = 105 iterations • Batch-size: 500\nB.5 IMPLEMENTATION DETAILS FOR DVBF IN TWO BOUNCING BALLS EXPERIMENT\n• Input: 15 timesteps of 202 observation dimensions and 2000 samples • Latent Space: 10 dimensions • Observation Network p(xt|zt) = N (xt;µ(zt), σ): 128 ReLU + 202 sigmoid output • Recognition Model: 128 ReLU + 20 identity output\nq(wt|zt,xt+1,ut) = N (wt;µ, σ), (µ, σ) = f(zt,xt+1,ut)\n• Transition Network αt(zt): 64 softmax output • Initial Network w1 ∼ p(x1:T ): MLP with: 128 ReLU + 10 identity output • Initial Transition z1(w1): 128 ReLU + 10 identity output • Optimizer: adam, 0.001 step rate • Inverse temperature: c0 = 0.01, updated every gradient update, TA = 2 105 iterations • Batch-size: 80\nB.6 IMPLEMENTATION DETAILS FOR DKF IN PENDULUM EXPERIMENT\n• Input: 15 timesteps of 162 observation dimensions and 1 action dimension • Latent Space: 3 dimensions • Observation Network p(xt|zt) = N (xt;µ(zt), σ(zt)): 128 Sigmoid + 128 Sigmoid + 2 162\nidentity output • Recognition Model: Fast Dropout BiRNN 128 Sigmoid + 128 Sigmoid + 3 identity output • Transition Network p(zt|zt−1,ut−1): 128 Sigmoid + 128 Sigmoid + 6 output • Optimizer: adam, 0.001 step rate • Inverse temperature: c0 = 0.01, updated every 25th gradient update, TA = 2000 iterations • Batch-size: 500"
    } ],
    "references" : [ {
      "title" : "Learning stochastic recurrent networks",
      "author" : [ "Justin Bayer", "Christian Osendorfer" ],
      "venue" : "arXiv preprint arXiv:1411.7610,",
      "citeRegEx" : "Bayer and Osendorfer.,? \\Q2014\\E",
      "shortCiteRegEx" : "Bayer and Osendorfer.",
      "year" : 2014
    }, {
      "title" : "Weight uncertainty in neural networks",
      "author" : [ "Charles Blundell", "Julien Cornebise", "Koray Kavukcuoglu", "Daan Wierstra" ],
      "venue" : "arXiv preprint arXiv:1505.05424,",
      "citeRegEx" : "Blundell et al\\.,? \\Q2015\\E",
      "shortCiteRegEx" : "Blundell et al\\.",
      "year" : 2015
    }, {
      "title" : "Large-scale machine learning with stochastic gradient descent",
      "author" : [ "Léon Bottou" ],
      "venue" : "In Proceedings of COMPSTAT’2010,",
      "citeRegEx" : "Bottou.,? \\Q2010\\E",
      "shortCiteRegEx" : "Bottou.",
      "year" : 2010
    }, {
      "title" : "A recurrent latent variable model for sequential data",
      "author" : [ "Junyoung Chung", "Kyle Kastner", "Laurent Dinh", "Kratarth Goel", "Aaron C. Courville", "Yoshua Bengio" ],
      "venue" : "CoRR, abs/1506.02216,",
      "citeRegEx" : "Chung et al\\.,? \\Q2015\\E",
      "shortCiteRegEx" : "Chung et al\\.",
      "year" : 2015
    }, {
      "title" : "Pilco: A model-based and data-efficient approach to policy search",
      "author" : [ "Marc Deisenroth", "Carl E Rasmussen" ],
      "venue" : "In Proceedings of the 28th International Conference on machine learning",
      "citeRegEx" : "Deisenroth and Rasmussen.,? \\Q2011\\E",
      "shortCiteRegEx" : "Deisenroth and Rasmussen.",
      "year" : 2011
    }, {
      "title" : "Parameter estimation for linear dynamical systems",
      "author" : [ "Zoubin Ghahramani", "Geoffrey E Hinton" ],
      "venue" : "Technical report, Technical Report CRG-TR-96-2, University of Toronto, Dept. of Computer Science,",
      "citeRegEx" : "Ghahramani and Hinton.,? \\Q1996\\E",
      "shortCiteRegEx" : "Ghahramani and Hinton.",
      "year" : 1996
    }, {
      "title" : "Variational learning for switching state-space models",
      "author" : [ "Zoubin Ghahramani", "Geoffrey E Hinton" ],
      "venue" : "Neural computation,",
      "citeRegEx" : "Ghahramani and Hinton.,? \\Q2000\\E",
      "shortCiteRegEx" : "Ghahramani and Hinton.",
      "year" : 2000
    }, {
      "title" : "Generating sequences with recurrent neural networks",
      "author" : [ "Alex Graves" ],
      "venue" : "arXiv preprint arXiv:1308.0850,",
      "citeRegEx" : "Graves.,? \\Q2013\\E",
      "shortCiteRegEx" : "Graves.",
      "year" : 2013
    }, {
      "title" : "Keeping the neural networks simple by minimizing the description length of the weights",
      "author" : [ "Geoffrey E Hinton", "Drew Van Camp" ],
      "venue" : "In Proceedings of the sixth annual conference on Computational learning theory,",
      "citeRegEx" : "Hinton and Camp.,? \\Q1993\\E",
      "shortCiteRegEx" : "Hinton and Camp.",
      "year" : 1993
    }, {
      "title" : "Approximate riemannian conjugate gradient learning for fixed-form variational bayes",
      "author" : [ "Antti Honkela", "Tapani Raiko", "Mikael Kuusela", "Matti Tornio", "Juha Karhunen" ],
      "venue" : "Journal of Machine Learning Research,",
      "citeRegEx" : "Honkela et al\\.,? \\Q2010\\E",
      "shortCiteRegEx" : "Honkela et al\\.",
      "year" : 2010
    }, {
      "title" : "Structured VAEs: Composing probabilistic graphical models and variational autoencoders",
      "author" : [ "Matthew J Johnson", "David Duvenaud", "Alexander B Wiltschko", "Sandeep R Datta", "Ryan P Adams" ],
      "venue" : "arXiv preprint arXiv:1603.06277,",
      "citeRegEx" : "Johnson et al\\.,? \\Q2016\\E",
      "shortCiteRegEx" : "Johnson et al\\.",
      "year" : 2016
    }, {
      "title" : "New extension of the kalman filter to nonlinear systems",
      "author" : [ "Simon J Julier", "Jeffrey K Uhlmann" ],
      "venue" : "In AeroSense’97,",
      "citeRegEx" : "Julier and Uhlmann.,? \\Q1997\\E",
      "shortCiteRegEx" : "Julier and Uhlmann.",
      "year" : 1997
    }, {
      "title" : "New results in linear filtering and prediction theory",
      "author" : [ "Rudolph E Kalman", "Richard S Bucy" ],
      "venue" : "Journal of basic engineering,",
      "citeRegEx" : "Kalman and Bucy.,? \\Q1961\\E",
      "shortCiteRegEx" : "Kalman and Bucy.",
      "year" : 1961
    }, {
      "title" : "Auto-encoding variational bayes",
      "author" : [ "Diederik P Kingma", "Max Welling" ],
      "venue" : "arXiv preprint arXiv:1312.6114,",
      "citeRegEx" : "Kingma and Welling.,? \\Q2013\\E",
      "shortCiteRegEx" : "Kingma and Welling.",
      "year" : 2013
    }, {
      "title" : "Learning gp-bayesfilters via gaussian process latent variable models",
      "author" : [ "Jonathan Ko", "Dieter Fox" ],
      "venue" : "Autonomous Robots,",
      "citeRegEx" : "Ko and Fox.,? \\Q2011\\E",
      "shortCiteRegEx" : "Ko and Fox.",
      "year" : 2011
    }, {
      "title" : "Variational tempering",
      "author" : [ "Stephan Mandt", "James McInerney", "Farhan Abrol", "Rajesh Ranganath", "David Blei" ],
      "venue" : "In Proceedings of the 19th International Conference on Artificial Intelligence and Statistics,",
      "citeRegEx" : "Mandt et al\\.,? \\Q2016\\E",
      "shortCiteRegEx" : "Mandt et al\\.",
      "year" : 2016
    }, {
      "title" : "Statistical inference for dynamical systems: A review",
      "author" : [ "Kevin McGoff", "Sayan Mukherjee", "Natesh Pillai" ],
      "venue" : "Statistics Surveys,",
      "citeRegEx" : "McGoff et al\\.,? \\Q2015\\E",
      "shortCiteRegEx" : "McGoff et al\\.",
      "year" : 2015
    }, {
      "title" : "Stochastic backpropagation and approximate inference in deep generative models",
      "author" : [ "Danilo J. Rezende", "Shakir Mohamed", "Daan Wierstra" ],
      "venue" : "Proceedings of the 31st International Conference on Machine Learning",
      "citeRegEx" : "Rezende et al\\.,? \\Q2014\\E",
      "shortCiteRegEx" : "Rezende et al\\.",
      "year" : 2014
    }, {
      "title" : "Variational inference with normalizing flows",
      "author" : [ "Danilo Jimenez Rezende", "Shakir Mohamed" ],
      "venue" : "arXiv preprint arXiv:1505.05770,",
      "citeRegEx" : "Rezende and Mohamed.,? \\Q2015\\E",
      "shortCiteRegEx" : "Rezende and Mohamed.",
      "year" : 2015
    }, {
      "title" : "Learning multilevel distributed representations for high-dimensional sequences",
      "author" : [ "Ilya Sutskever", "Geoffrey E. Hinton" ],
      "venue" : "Proceedings of the Eleventh International Conference on Artificial Intelligence and Statistics (AISTATS-07),",
      "citeRegEx" : "Sutskever and Hinton.,? \\Q2007\\E",
      "shortCiteRegEx" : "Sutskever and Hinton.",
      "year" : 2007
    }, {
      "title" : "Model-based reinforcement learning with an approximate, learned model",
      "author" : [ "Leonid Kuvayev Rich Sutton" ],
      "venue" : "In Proceedings of the ninth Yale workshop on adaptive and learning systems,",
      "citeRegEx" : "Sutton.,? \\Q1996\\E",
      "shortCiteRegEx" : "Sutton.",
      "year" : 1996
    }, {
      "title" : "A note on the evaluation of generative models",
      "author" : [ "Lucas Theis", "Aäron van den Oord", "Matthias Bethge" ],
      "venue" : "arXiv preprint arXiv:1511.01844,",
      "citeRegEx" : "Theis et al\\.,? \\Q2015\\E",
      "shortCiteRegEx" : "Theis et al\\.",
      "year" : 2015
    }, {
      "title" : "An unsupervised ensemble learning method for nonlinear dynamic state-space models",
      "author" : [ "Harri Valpola", "Juha Karhunen" ],
      "venue" : "Neural computation,",
      "citeRegEx" : "Valpola and Karhunen.,? \\Q2002\\E",
      "shortCiteRegEx" : "Valpola and Karhunen.",
      "year" : 2002
    }, {
      "title" : "Embed to control: A locally linear latent dynamics model for control from raw images",
      "author" : [ "Manuel Watter", "Jost Springenberg", "Joschka Boedecker", "Martin Riedmiller" ],
      "venue" : "In Advances in Neural Information Processing Systems,",
      "citeRegEx" : "Watter et al\\.,? \\Q2015\\E",
      "shortCiteRegEx" : "Watter et al\\.",
      "year" : 2015
    } ],
    "referenceMentions" : [ {
      "referenceID" : 5,
      "context" : "Estimating probabilistic models for sequential data is central to many domains, such as audio, natural language or physical plants, Graves (2013); Watter et al.",
      "startOffset" : 132,
      "endOffset" : 146
    }, {
      "referenceID" : 5,
      "context" : "Estimating probabilistic models for sequential data is central to many domains, such as audio, natural language or physical plants, Graves (2013); Watter et al. (2015); Chung et al.",
      "startOffset" : 132,
      "endOffset" : 168
    }, {
      "referenceID" : 2,
      "context" : "(2015); Chung et al. (2015); Deisenroth & Rasmussen (2011); Ko & Fox (2011).",
      "startOffset" : 8,
      "endOffset" : 28
    }, {
      "referenceID" : 2,
      "context" : "(2015); Chung et al. (2015); Deisenroth & Rasmussen (2011); Ko & Fox (2011).",
      "startOffset" : 8,
      "endOffset" : 59
    }, {
      "referenceID" : 2,
      "context" : "(2015); Chung et al. (2015); Deisenroth & Rasmussen (2011); Ko & Fox (2011). The goal is to obtain a model p(x1:T ) that best reflects a data set of observed sequences x1:T .",
      "startOffset" : 8,
      "endOffset" : 76
    }, {
      "referenceID" : 2,
      "context" : "(2015); Chung et al. (2015); Deisenroth & Rasmussen (2011); Ko & Fox (2011). The goal is to obtain a model p(x1:T ) that best reflects a data set of observed sequences x1:T . Recent advances in deep learning have paved the way to powerful models capable of representing high-dimensional sequences with temporal dependencies, e.g., Graves (2013); Watter et al.",
      "startOffset" : 8,
      "endOffset" : 345
    }, {
      "referenceID" : 2,
      "context" : "(2015); Chung et al. (2015); Deisenroth & Rasmussen (2011); Ko & Fox (2011). The goal is to obtain a model p(x1:T ) that best reflects a data set of observed sequences x1:T . Recent advances in deep learning have paved the way to powerful models capable of representing high-dimensional sequences with temporal dependencies, e.g., Graves (2013); Watter et al. (2015); Chung et al.",
      "startOffset" : 8,
      "endOffset" : 367
    }, {
      "referenceID" : 2,
      "context" : "(2015); Chung et al. (2015); Deisenroth & Rasmussen (2011); Ko & Fox (2011). The goal is to obtain a model p(x1:T ) that best reflects a data set of observed sequences x1:T . Recent advances in deep learning have paved the way to powerful models capable of representing high-dimensional sequences with temporal dependencies, e.g., Graves (2013); Watter et al. (2015); Chung et al. (2015); Bayer & Osendorfer (2014).",
      "startOffset" : 8,
      "endOffset" : 388
    }, {
      "referenceID" : 2,
      "context" : "(2015); Chung et al. (2015); Deisenroth & Rasmussen (2011); Ko & Fox (2011). The goal is to obtain a model p(x1:T ) that best reflects a data set of observed sequences x1:T . Recent advances in deep learning have paved the way to powerful models capable of representing high-dimensional sequences with temporal dependencies, e.g., Graves (2013); Watter et al. (2015); Chung et al. (2015); Bayer & Osendorfer (2014). Time series for dynamic systems have been studied extensively in systems theory, cf.",
      "startOffset" : 8,
      "endOffset" : 415
    }, {
      "referenceID" : 2,
      "context" : "(2015); Chung et al. (2015); Deisenroth & Rasmussen (2011); Ko & Fox (2011). The goal is to obtain a model p(x1:T ) that best reflects a data set of observed sequences x1:T . Recent advances in deep learning have paved the way to powerful models capable of representing high-dimensional sequences with temporal dependencies, e.g., Graves (2013); Watter et al. (2015); Chung et al. (2015); Bayer & Osendorfer (2014). Time series for dynamic systems have been studied extensively in systems theory, cf. McGoff et al. (2015) and sources therein.",
      "startOffset" : 8,
      "endOffset" : 522
    }, {
      "referenceID" : 2,
      "context" : "(2015); Chung et al. (2015); Deisenroth & Rasmussen (2011); Ko & Fox (2011). The goal is to obtain a model p(x1:T ) that best reflects a data set of observed sequences x1:T . Recent advances in deep learning have paved the way to powerful models capable of representing high-dimensional sequences with temporal dependencies, e.g., Graves (2013); Watter et al. (2015); Chung et al. (2015); Bayer & Osendorfer (2014). Time series for dynamic systems have been studied extensively in systems theory, cf. McGoff et al. (2015) and sources therein. In particular, state space models have shown to be a powerful tool to analyze and control the dynamics. Two tasks remain a significant challenge to this day: Can we identify the governing system from data only? And can we perform inference from observables to the latent system variables? These two tasks are competing: A more powerful representation of system requires more computationally demanding inference, and efficient inference, such as the well-known Kalman filters, Kalman & Bucy (1961), can prohibit sufficiently complex system classes.",
      "startOffset" : 8,
      "endOffset" : 1040
    }, {
      "referenceID" : 2,
      "context" : "(2015); Chung et al. (2015); Deisenroth & Rasmussen (2011); Ko & Fox (2011). The goal is to obtain a model p(x1:T ) that best reflects a data set of observed sequences x1:T . Recent advances in deep learning have paved the way to powerful models capable of representing high-dimensional sequences with temporal dependencies, e.g., Graves (2013); Watter et al. (2015); Chung et al. (2015); Bayer & Osendorfer (2014). Time series for dynamic systems have been studied extensively in systems theory, cf. McGoff et al. (2015) and sources therein. In particular, state space models have shown to be a powerful tool to analyze and control the dynamics. Two tasks remain a significant challenge to this day: Can we identify the governing system from data only? And can we perform inference from observables to the latent system variables? These two tasks are competing: A more powerful representation of system requires more computationally demanding inference, and efficient inference, such as the well-known Kalman filters, Kalman & Bucy (1961), can prohibit sufficiently complex system classes. Leveraging a recently proposed estimator based on variational inference, stochastic gradient variational Bayes (SGVB, Kingma & Welling (2013); Rezende et al.",
      "startOffset" : 8,
      "endOffset" : 1233
    }, {
      "referenceID" : 2,
      "context" : "(2015); Chung et al. (2015); Deisenroth & Rasmussen (2011); Ko & Fox (2011). The goal is to obtain a model p(x1:T ) that best reflects a data set of observed sequences x1:T . Recent advances in deep learning have paved the way to powerful models capable of representing high-dimensional sequences with temporal dependencies, e.g., Graves (2013); Watter et al. (2015); Chung et al. (2015); Bayer & Osendorfer (2014). Time series for dynamic systems have been studied extensively in systems theory, cf. McGoff et al. (2015) and sources therein. In particular, state space models have shown to be a powerful tool to analyze and control the dynamics. Two tasks remain a significant challenge to this day: Can we identify the governing system from data only? And can we perform inference from observables to the latent system variables? These two tasks are competing: A more powerful representation of system requires more computationally demanding inference, and efficient inference, such as the well-known Kalman filters, Kalman & Bucy (1961), can prohibit sufficiently complex system classes. Leveraging a recently proposed estimator based on variational inference, stochastic gradient variational Bayes (SGVB, Kingma & Welling (2013); Rezende et al. (2014)), approximate inference of latent variables becomes tractable.",
      "startOffset" : 8,
      "endOffset" : 1256
    }, {
      "referenceID" : 2,
      "context" : "(2015); Chung et al. (2015); Deisenroth & Rasmussen (2011); Ko & Fox (2011). The goal is to obtain a model p(x1:T ) that best reflects a data set of observed sequences x1:T . Recent advances in deep learning have paved the way to powerful models capable of representing high-dimensional sequences with temporal dependencies, e.g., Graves (2013); Watter et al. (2015); Chung et al. (2015); Bayer & Osendorfer (2014). Time series for dynamic systems have been studied extensively in systems theory, cf. McGoff et al. (2015) and sources therein. In particular, state space models have shown to be a powerful tool to analyze and control the dynamics. Two tasks remain a significant challenge to this day: Can we identify the governing system from data only? And can we perform inference from observables to the latent system variables? These two tasks are competing: A more powerful representation of system requires more computationally demanding inference, and efficient inference, such as the well-known Kalman filters, Kalman & Bucy (1961), can prohibit sufficiently complex system classes. Leveraging a recently proposed estimator based on variational inference, stochastic gradient variational Bayes (SGVB, Kingma & Welling (2013); Rezende et al. (2014)), approximate inference of latent variables becomes tractable. Extensions to time series have been shown in Bayer & Osendorfer (2014); Chung et al.",
      "startOffset" : 8,
      "endOffset" : 1390
    }, {
      "referenceID" : 2,
      "context" : "(2015); Chung et al. (2015); Deisenroth & Rasmussen (2011); Ko & Fox (2011). The goal is to obtain a model p(x1:T ) that best reflects a data set of observed sequences x1:T . Recent advances in deep learning have paved the way to powerful models capable of representing high-dimensional sequences with temporal dependencies, e.g., Graves (2013); Watter et al. (2015); Chung et al. (2015); Bayer & Osendorfer (2014). Time series for dynamic systems have been studied extensively in systems theory, cf. McGoff et al. (2015) and sources therein. In particular, state space models have shown to be a powerful tool to analyze and control the dynamics. Two tasks remain a significant challenge to this day: Can we identify the governing system from data only? And can we perform inference from observables to the latent system variables? These two tasks are competing: A more powerful representation of system requires more computationally demanding inference, and efficient inference, such as the well-known Kalman filters, Kalman & Bucy (1961), can prohibit sufficiently complex system classes. Leveraging a recently proposed estimator based on variational inference, stochastic gradient variational Bayes (SGVB, Kingma & Welling (2013); Rezende et al. (2014)), approximate inference of latent variables becomes tractable. Extensions to time series have been shown in Bayer & Osendorfer (2014); Chung et al. (2015). Empirically, they showed considerable improvements in marginal data likelihood, i.",
      "startOffset" : 8,
      "endOffset" : 1411
    }, {
      "referenceID" : 2,
      "context" : "Our contribution is, to our knowledge, the first model that (i) enforces the latent state-space model assumptions, allowing for reliable system identification, and plausible long-term prediction of the observable system, (ii) provides the corresponding inference mechanism with rich dependencies, (iii) inherits the merit of neural architectures to be trainable on raw data such as images or other sensory inputs, and (iv) scales to large data due to optimization of parameters based on stochastic gradient descent, Bottou (2010). Hence, our model has the potential to exploit systems theory methodology for downstream tasks, e.",
      "startOffset" : 516,
      "endOffset" : 530
    }, {
      "referenceID" : 2,
      "context" : "Our contribution is, to our knowledge, the first model that (i) enforces the latent state-space model assumptions, allowing for reliable system identification, and plausible long-term prediction of the observable system, (ii) provides the corresponding inference mechanism with rich dependencies, (iii) inherits the merit of neural architectures to be trainable on raw data such as images or other sensory inputs, and (iv) scales to large data due to optimization of parameters based on stochastic gradient descent, Bottou (2010). Hence, our model has the potential to exploit systems theory methodology for downstream tasks, e.g., control or model-based reinforcement learning, Sutton (1996).",
      "startOffset" : 516,
      "endOffset" : 693
    }, {
      "referenceID" : 9,
      "context" : "Ghahramani & Hinton (1996); Honkela et al. (2010) based on the expectation maximization (EM) algorithm or Valpola & Karhunen (2002), which uses neural networks.",
      "startOffset" : 28,
      "endOffset" : 50
    }, {
      "referenceID" : 9,
      "context" : "Ghahramani & Hinton (1996); Honkela et al. (2010) based on the expectation maximization (EM) algorithm or Valpola & Karhunen (2002), which uses neural networks.",
      "startOffset" : 28,
      "endOffset" : 132
    }, {
      "referenceID" : 17,
      "context" : "2 STOCHASTIC GRADIENT VARIATIONAL BAYES (SGVB) FOR TIME SERIES DISTRIBUTIONS Replacing the bottleneck layer of a deterministic auto-encoder with stochastic units z, the variational auto-encoder (VAE, Kingma & Welling (2013); Rezende et al. (2014)) learns complex marginal data distributions on x in an unsupervised fashion from simpler distributions via the graphical model",
      "startOffset" : 225,
      "endOffset" : 247
    }, {
      "referenceID" : 3,
      "context" : "The principle of VAEs has been transferred to time series, Bayer & Osendorfer (2014); Chung et al. (2015). Both employ nonlinear state transitions in latent space, but violate eq.",
      "startOffset" : 86,
      "endOffset" : 106
    }, {
      "referenceID" : 3,
      "context" : "The principle of VAEs has been transferred to time series, Bayer & Osendorfer (2014); Chung et al. (2015). Both employ nonlinear state transitions in latent space, but violate eq. (4): Observations are directly included in the transition process. Empirically, reconstruction and compression work well. The state space Z , however, does not reflect all information available, which prohibits plausible generative long-term prediction. Such phenomena with generative models have been explained in Theis et al. (2015). In Krishnan et al.",
      "startOffset" : 86,
      "endOffset" : 515
    }, {
      "referenceID" : 3,
      "context" : "The principle of VAEs has been transferred to time series, Bayer & Osendorfer (2014); Chung et al. (2015). Both employ nonlinear state transitions in latent space, but violate eq. (4): Observations are directly included in the transition process. Empirically, reconstruction and compression work well. The state space Z , however, does not reflect all information available, which prohibits plausible generative long-term prediction. Such phenomena with generative models have been explained in Theis et al. (2015). In Krishnan et al. (2015), the state-space assumptions (3) and (4) are softly encoded in the Deep Kalman Filter (DKF) model.",
      "startOffset" : 86,
      "endOffset" : 542
    }, {
      "referenceID" : 3,
      "context" : "The principle of VAEs has been transferred to time series, Bayer & Osendorfer (2014); Chung et al. (2015). Both employ nonlinear state transitions in latent space, but violate eq. (4): Observations are directly included in the transition process. Empirically, reconstruction and compression work well. The state space Z , however, does not reflect all information available, which prohibits plausible generative long-term prediction. Such phenomena with generative models have been explained in Theis et al. (2015). In Krishnan et al. (2015), the state-space assumptions (3) and (4) are softly encoded in the Deep Kalman Filter (DKF) model. Despite that, experiments, cf. section 4, show that their model fails to extract information such as velocity (and in general time derivatives), which leads to similar problems with prediction. Johnson et al. (2016) give an algorithm for general graphical model variational inference, not tailored to dynamical systems.",
      "startOffset" : 86,
      "endOffset" : 857
    }, {
      "referenceID" : 3,
      "context" : "The principle of VAEs has been transferred to time series, Bayer & Osendorfer (2014); Chung et al. (2015). Both employ nonlinear state transitions in latent space, but violate eq. (4): Observations are directly included in the transition process. Empirically, reconstruction and compression work well. The state space Z , however, does not reflect all information available, which prohibits plausible generative long-term prediction. Such phenomena with generative models have been explained in Theis et al. (2015). In Krishnan et al. (2015), the state-space assumptions (3) and (4) are softly encoded in the Deep Kalman Filter (DKF) model. Despite that, experiments, cf. section 4, show that their model fails to extract information such as velocity (and in general time derivatives), which leads to similar problems with prediction. Johnson et al. (2016) give an algorithm for general graphical model variational inference, not tailored to dynamical systems. In contrast to previously discussed methods, it does not violate eq. (4). The approaches differ in that the recognition model outputs node potentials in combination with message passing to infer the latent state. Our approach focuses on learning dynamical systems for controlrelated tasks and therefore uses a neural network for inferring the latent state directly instead of an inference subroutine. Others have been specifically interested in applying variational inference for controlled dynamical systems. In Watter et al. (2015) (Embed to Control—E2C), a VAE is used to learn the mappings to and from latent space.",
      "startOffset" : 86,
      "endOffset" : 1495
    }, {
      "referenceID" : 17,
      "context" : "Similar to the reparametrization trick from Kingma & Welling (2013); Rezende et al. (2014) for making the Monte Carlo estimate differentiable w.",
      "startOffset" : 69,
      "endOffset" : 91
    }, {
      "referenceID" : 17,
      "context" : "Similar to the reparametrization trick from Kingma & Welling (2013); Rezende et al. (2014) for making the Monte Carlo estimate differentiable w.r.t. the parameters, we make the transition differentiable w.r.t. the last state and its parameters: zt+1 = f(zt,ut,βt) (8) Given the stochastic parameters βt, the state transition is deterministic (which in turn means that by marginalizing βt, we still have a stochastic transition). The immediate and crucial consequence is that errors in reconstruction of xt from zt are backpropagated directly through time. This reparametrization has a couple of other important implications: the recognition model no longer infers latent states zt, but transition parameters βt. In particular, the gradient ∂zt+1/∂zt is well-defined from (8)—gradient information can be backpropagated through the transition. This is different from the method used in Krishnan et al. (2015), where the transition only occurs in the KL-divergence term of their loss function (a variant of eq.",
      "startOffset" : 69,
      "endOffset" : 907
    }, {
      "referenceID" : 15,
      "context" : ", Ghahramani & Hinton (2000); Mandt et al. (2016); Rezende & Mohamed (2015), where it is shown that they smooth the typically highly non-convex error landscape.",
      "startOffset" : 30,
      "endOffset" : 50
    }, {
      "referenceID" : 15,
      "context" : ", Ghahramani & Hinton (2000); Mandt et al. (2016); Rezende & Mohamed (2015), where it is shown that they smooth the typically highly non-convex error landscape.",
      "startOffset" : 30,
      "endOffset" : 76
    }, {
      "referenceID" : 23,
      "context" : "Inspired by Watter et al. (2015), this section will show how to learn a particular instance: locally linear state transitions.",
      "startOffset" : 12,
      "endOffset" : 33
    }, {
      "referenceID" : 1,
      "context" : "We employed a Bayesian treatment as in Blundell et al. (2015). We yield At,Bt, and Ct as state- and control-dependent linear combinations:",
      "startOffset" : 39,
      "endOffset" : 62
    }, {
      "referenceID" : 23,
      "context" : "2 We focus on environments that can be simulated with full knowledge of the We do not include E2C, Watter et al. (2015), due to the need for data modification and its inability to provide a correct lower bound as mentioned in section 2.",
      "startOffset" : 99,
      "endOffset" : 120
    }, {
      "referenceID" : 21,
      "context" : "with a slight margin, which does not reflect the better generative sampling as Theis et al. (2015) argue.",
      "startOffset" : 79,
      "endOffset" : 99
    } ],
    "year" : 2017,
    "abstractText" : "We introduce Deep Variational Bayes Filters (DVBF), a new method for unsupervised learning and identification of latent Markovian state space models. Leveraging recent advances in Stochastic Gradient Variational Bayes, DVBF can overcome intractable inference distributions via variational inference. Thus, it can handle highly nonlinear input data with temporal and spatial dependencies such as image sequences without domain knowledge. Our experiments show that enabling backpropagation through transitions enforces state space assumptions and significantly improves information content of the latent embedding. This also enables realistic long-term prediction.",
    "creator" : "LaTeX with hyperref package"
  }
}