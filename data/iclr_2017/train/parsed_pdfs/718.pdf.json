{
  "name" : "718.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "MULTIAGENT SYSTEM FOR LAYER FREE NETWORK",
    "authors" : [ "Hiroki Kurotaki", "Kotaro Nakayama", "Yutaka Matsuo" ],
    "emails" : [ "matsuo}@weblab.t.u-tokyo.ac.jp" ],
    "sections" : [ {
      "heading" : null,
      "text" : "We propose a multiagent system that have feedforward networks as its subset while free from layer structure with matrix-vector scheme. Deep networks are often compared to the brain neocortex or visual perception system. One of the largest difference from human brain is the use of matrix-vector multiplication based on layer architecture. It would help understanding the way human brain works if we manage to develop good deep network model without the layer architecture while preserving their performance. The brain neocortex works as an aggregation of the local level interactions between neurons, which is rather similar to multiagent system consists of autonomous partially observing agents than units aligned in column vectors and manipulated by global level algorithm. Therefore we suppose that it is an effective approach for developing more biologically plausible model while preserving compatibility with deep networks to alternate units with multiple agents. Our method also has advantage in scalability and memory efficiency. We reimplemented Stacked Denoising Autoencoder(SDAE) as a concrete instance with our multiagent system and verified its equivalence with the standard SDAE from both theoritical and empirical perspectives. Additionary, we also proposed a variant of our multiagent SDAE named \"Sparse Connect SDAE\", and showed its computational advantage with the MNIST dataset."
    }, {
      "heading" : "1 INTRODUCTION",
      "text" : "Deep networks are used in many tasks, especially in image recognition, signal processing, NLP and robot manipulation. Almost all deep network models utilize structure with layers. One of the primary reasons to use those layer structure is to utilize parallel computation techniques and hardware level technologies such as GPU or dedicated tensor processors.\nLayers can be viewed as a restriction on the connection pattern of the units that they must be aligned in a row to form a vector. Though layers are related to vector-matrix processing technologies and necessary to make use of them, it is not evident that this vector-matrix restriction is the most appropriate model to capture the latent representation of the data.\nVector-matrix approach requires dense matrices to store weight parameters even after sparse representations and weights are learned, which requires inefficient use of memory.\nThere are several methods to reduce the cost by downsize the model such as distillation(Hinton et al. (2014)), and limiting the model space with binarizing(Courbariaux et al. (2015)) and hashing Han et al. (2015), but they still needs dense matrix filled with many zeros.\nIn this paper we propose a framework of multiagent calculation network that has feedforward matrix-vector network as a subset but free from the notion of layer to solve these problems.\nOur multiagent network consists of many agents that replaces each unit in standard deep networks. The agents act autonomously and calculations are executed as an accumulation of many local level communication among the agents. This local calculation scheme is contrary to the previous feedforward network implementation that all computations in the units in the same layer is done simultaneously (Figure 1).\nSpecifically, we reimplemented Stacked Denoising Autoencoder(SDAE) (Vincent et al. (2008)) as one of the variations in our framework. SDAE is one of the earliest successful deep network model and free from spatiality assumption in CNNs and RNNs. SDAE is related to the Ladder Network (Rasmus et al. (2015)) in that both employ reconstruction and denoising mechanism. We suppose starting from the model strictly derived from SDAE and gradually extending the model is one good approach to develop useful algorithms to construct deep multiagent networks. We show that the standard vector-matrix SDAE can be interpreted and reconstructed as a specific case of our multiagent network in the sense that both SDAE compute the exact same result in the end but with different implementations and processes.\nOnce we establish the basic multiagent SDAE, we aim to extend the SDAE and examine its behavior. One of the minimum and simplest modification to the proposed multiagent SDAE is to keep the node’s locations and possible edge connections as they are, but randomly truncate the edges. We call this testing model \"Sparse connect SDAE\" or \"SCSDAE\" in the latter section. This model is an example of the potential of our model to handle sparse weight parameters more efficient than the standard networks composed of dense weight matrices.\nOur contributions are the following.\n1. We propose new multiagent-based neural network system framework that free from restrictions of layer scheme with matrix-vector while getting more biologically plausible.\n2. We prove that SDAE can be reinterpreted as a special case of our multiagent system.\n3. We also propose Sparse Connect SDAE, a primitive extension of our multiagent system.\n4. We demonstrate the performance of the proposed models on XOR toy dataset and the permutation-invariant MNIST task."
    }, {
      "heading" : "2 RELATED WORKS",
      "text" : "Foerster et al. (2016) and Sukhbaatar et al. (2016) model multiagent environment as a deep network, but their unit of agent is a whole network which models an individual actor and not a feature inside the network. The motivation and architecture of our proposal multiagent framework is different from theirs and we suppose our method could be a complementary method between the different granularities of agents.\nThere are several approaches to design biologically plausible model (Sussillo & Abbott (2009); Risi & Stanley (2014); Mi et al. (2014)). Cao et al. (2014) convert regular CNN into spiking neural networks (SNN). Osogami & Otsuka (2015) build a variation of Boltzman Machine that follows the properties of Spike-timing dependent plasticity (STDP), which makes it more close to biological neural networks. Lee et al. (2014) proposes a modification of autoencoder that uses a novel credit assignment method called \"target propagation\" in place of back-propagation and achieved state\nof the art performance. It can be a solution to remove inherent biologiacal implausibility of back propagation.\nOur SCSDAE is a variation of SDAE and can be viewed as a technique for truncating edges and reduce the computational cost. There are several techniques to downsize networks and enables us to load them on mobile devices for realtime processing. One example is distillation (Hinton et al. (2014)). It needs huge networks as a superviser network and it cannot be used as a mean to full scratch to new domain. MADE (Mathieu et al. (2015)) uses binary masking matrix to represent hard zero and thus conditional distribution. Limiting weight connection to binary (Courbariaux et al. (2015)) is another approach and its applicability is actively studied. Han et al. (2015) combines pruning, quantization and Huffman coding together."
    }, {
      "heading" : "3 REIMPLEMENTATION OF DEEP NETWORK AS A MULTIAGENT SYSTEM",
      "text" : "In this section we describe our algorithm. First we show how we can reinterpret some common properties of multiagent systems to form a deep network. Next we define our multiagent system in general form. Then we prove the standard SDAE is indeed a special case of our multiagent system in the sense that both calculate the exact same computational result in the same order. Finally we show an example of our SDAE’s variations."
    }, {
      "heading" : "3.1 THE PROPERTIES OUR MULTIAGENT SYSTEM SHOULD SUFFICE",
      "text" : "We extracted some common aspects of those multiagent system from the view of deep network development as follows:\n1. The system consists of several number of autonomous units (as agents) and the environment.\n2. All units are autonomous and only act when stimulated by messages from the other units and the environment.\n3. Units process calculation only with local information they hold."
    }, {
      "heading" : "3.2 DEFINITION OF MULTIAGENT NETWORK",
      "text" : "In this section we define the multiagent system that has the properties we stated above.\n• A system is consists of several units and one environment. • Units are consists of nodes and edges. • Edges connect between two nodes. • Nodes has some variables and can memorize actual computed values of them.\nThe variables includes not only the input data and feature variables themselves, but parameters of adjacent edge’s weights and intermediate variables that are needed to calculate feature variable’s activation values. These additional variables can also be updated.\nNodes can transfer informations with other nodes connected with edges by message passing. These information may involve the value of variable computed by the units, the errors accumulated through epoch in the units, and any other things. Sometimes nodes may receive data input from the environment as a message, and may send value back to environment to let them compute global cost function.\nThe environment can manipulate unit from outside (via message passing) and change their relationships. For example,\n• The environment can generate new unit. • The environment can connect between nodes. • The environment can change the state of the unit. • The environment can send units input data.\nThese special manipulation may seems to break locality and autonomy, but its global manipulation is limited to changing the overall network structure. In the calculation process, the algorithm still run by agents local algorithm themselves rather than step-by-step instructions from the environment. The environment input some data to input units, and then, all it can do is to wait at the output units to get the result and it isn’t aware of the internal behavior of each units and the order of execution.\nAlgorithm 2 is the general form of our proposed multiagent system. The notation is matched with the multiagent MLP in later sections. Note that the order of calculation is not yet specialized to match to standard MLP, and thus free from the constants related to global structure such as Nx and Nz ."
    }, {
      "heading" : "3.3 THE EQUIVALENCE BETWEEN THE MULTIAGENT AND STANDARD VERSIONS OF SDAE",
      "text" : "We show how to reconstruct Stacked Denoising Autoencoder((Vincent et al. (2008))) with the proposed multiagent system.We concurrently prove that our multiagent version of SDAE and the standard SDAE have indeed the same algorithm and do the same calculation. In our case, we suppose that the two criteria below are sufficient for our objective\n• the equivalence of the value computed • the equivalence of the order of computation\ngiven the same input and the same random sampling. (e.g. initial parameters, order of input data, noise variables, etc.)\nWe begin our proof with a simple model and reuse it for prove of more complex models. Our first target model is the simple multi layer perceptron(MLP) with only one hidden layer and no pretraining. We then go on to the autoencoder and Denoising Autoencoder, which is a kind of extension of MLP. Finally we show the equivalence of the two SDAEs.\nFor bravity, we limit the choice of activation function for each unit to sigmoid, and we use unit-wise mean square error (MSE) for cost function. We also use simple SGD without minibatch. There are several methods that empirically known to perform well. (e.g. Adam (Kingma & Ba (2014)) for optimization, cross entropy for cost function, ReLU and softmax for activation function.) However we prioritize to establish the basic architecture of deep multiagent network, and choose these simpler methods. We can also extend the algorithm to apply minibatch updating easily."
    }, {
      "heading" : "3.3.1 EQUIVALENCE WITH MLP",
      "text" : "Now we prove the equivalence of our proposed multiagent version of MLP and standard implementation.\nSuppose there is a MLP consists of an input layer, a hidden layer and an output layer. Let Nx, Ny, Nz be the number of input, hidden and output layer’s dimension respectively. Simillary, let xi(i = 1 · · ·Nx), yj(j = 1 · · ·Ny), zk(k = 1 · · ·Nz) be the activated output value (hereafter simply \"output value\" ) at each unit in each layer respectively. The weight value between these variables are wij , wjk, thus the forward propagation from input to hidden is calculated by yj ← σ(w0j + ∑Nx i=1 wijxi) and from hidden to output is zk ← σ(w ′ 0k + ∑Ny j=1 wjkyj). Here Θ = {wij , w ′\njk | i = 0 · · ·Nx, j = 0 · · ·Ny, k = 1 · · ·Nz} represents the weight parameters and σ is the sigmoid function. We also define dataset D = {(x(1)data, t (1) data), · · · , (x (D) data, t (D) data)} as an array of pairs of input data x (d) data = {x(d)1data , · · · , x (d) Nxdata } and label data t(d)data = {t (d) 1data\n, · · · , t(d)Nzdata}, where d = 1 · · ·D. Hereafter we might drop the data index (d) for readability.\nWe define our objective function as L = ∑D\nd=1 L (d) , where L(d) = 1Nz ∑Nz k=1(tk − zk)2 and η be a\nlearning rate. Algorithm 1 is the standard version algorithm to optimize this objective.\nNext we construct a multiagent network that is equivalent to Algorithm 1 by specializing the general Algorithm 2. We first generate units uxi , uyj , uzk(i = 1 · · ·Nx, j = 1 · · ·Ny, k = 1 · · ·Nz) from the environment. We also denote the set of units Ux = {uxi | i = 1 · · ·Nx}, and similary Uy, Uz for set of all uyj , uzk respectively. Each unit and the environment possess the unique varibles as listed in Table 1.\nAlgorithm 1 Standard MLP\nInitialize wij , w ′\njk for all (i, j), (j, k) while criteria is not satisfied do\nfor d = 1 · · ·D do for k = 1 · · ·Nz do tk ← t(d)kdata\nend for for i = 1 · · ·Nx do xi ← x(d)idata end for for j = 1 · · ·Ny do yj ← σ(w0j + ∑Nx i=1 wijxi) end for for k = 1 · · ·Nz do zk ← σ(w ′ 0k + ∑Ny j=1 wjkyj)\nδk ← 2Nz (zk − tk)zk(1− zk) for j = 1 · · ·Ny do w ′\njk ← w ′\njk − ηδkyj end for\nend for for j = 1 · · ·Ny do δj ← yj(1− yj) ∑Nz k=1 w ′\njkδk for i = 1 · · ·Nx do wij ← wij − ηδjxi\nend for end for L(d) ← 1Nz ∑Nz k=1(tk − zk)2\nend for L← ∑D d=1 L (d)\nend while\nAlgorithm 2 General form of our multiagent algorithm (the environment)\nInitialize uxi , uyj , uzk for all i, j, k while criteria is not satisfied do\nfor all d ∈ {1 · · ·D} do for all uzk ∈ Uz do\nInput t(d)kdata to uzk end for for all uxi ∈ Ux do\nInput x(d)idata to ux end for L(d) ← ∑ k(tk − zk)2\nend for L← ∑ d L (d)\nend while\nAlgorithm 3 Multiagent MLP (the environment) Initialize uxi , uyj , uzk for all i, j, k while criteria is not satisfied do\nfor d = 1 · · ·D do for k = 1 · · ·Nz do\nInput t(d)kdata to uz end for for i = 1 · · ·Nx do\nInput x(d)idata to ux end for L(d) ← 1Nz ∑Nz k=1(tk − zk)2\nend for L← ∑D d=1 L (d)\nend while\nThe unit uxi corresponds to xi and receive xidata from the environment. The unit uzk corresponds to both zk, tk and is input tkdata . Each uxi receive input data, assign the data into the variable owned by itself, then send that value as message to uyj (algorithm 6).\nuyj corresponds to yj and stores wij(i = 0 · · ·Nx) to calculate yj . The unit must wait until receive message from all uxi(i = 1 · · ·M). Then the unit can calculate yj (algorithm 4). The calculated value of yj is sent again to uzk , so similary zk can also become able to be calculated.\nWe also need to introduce a state variable for SDAE. We will discuss it at the end of this section.\nFinally, the environment inputs data in the following order: uz1 → · · · → uzNz → ux1 → · · · → uxNx (Algorithm 3). These inputs stimulate units and the units invoke their message handling algorithm individually. The information required to calculate the cost function L(d) is eventually acumulated in the units uyk . The environment would read out these and calculate the objective L (d).\nAlgorithm 4 The handler of uyj when receiving a message\nif The sender is uxi then if Received messages from all uxi(i = 1 · · ·Nx) then yj ← σ(w0j + ∑Nx i=1 wijxi)\nfor k = 1 · · ·Nz do Send uzk the value of yj\nend for end if\nelse if The sender is uzk then if Received messages from all uzk(z = 1 · · ·Nz) then δj ← yj(1− yj) ∑Nz k=1 w ′\njkδk for i = 1 · · ·Nx do wij ← wij − ηδjxi\nend for end if\nend if\nAlgorithm 5 The handler of uzk when receiving data from the environment tk ← tdkdata\nAlgorithm 6 The handler of uxi when receiving data from the environment xi ← xdidata for j = 1 · · ·Ny do\nSend uyj the value of xi via message end for\nAlgorithm 7 The handler of uzkwhen receiving a message\nif Received messages from all uyi(j = 1 · · ·Ny) and the environment then zk ← σ(w ′ 0k + ∑Ny j=1 w ′\njkyj δk ← 2Nz (zk − tk)zk(1− zk) for j = 1 · · ·Ny do w ′\njk ← w ′\njk − ηδkyj end for for j = 1 · · ·Ny do\nSend uyj the value of w ′\njkδzk end for\nend if\nComparing both algorithms, we can verify that the all update statement and order for all variables are strictly matched between the proposed multiagent SDAE and the standard version."
    }, {
      "heading" : "3.3.2 EQUIVALENCE WITH AUTOENCODER",
      "text" : "Now we advance to the autoencoder algorithm which is a special case of MLP. In autoencoders, The input and output dimension is the same (Nx = Nz). The cost function and difference at output units are changed to L(d) ← 1Nz ∑Nz k=1(xk − zk)2 and δk ← 2 Nz\n(zk − xk)zk(1− zk) respectively. In the corresponding multiagent version, the environment don’t need to send tidata to uzi . Instead uxi send the input value xi to uzi right before messaging to uy1 .\nuzi don’t take any action in response to receiving message from uxi , just as same as from the environment. With the modifications above, the two versions become equivalent."
    }, {
      "heading" : "3.3.3 EQUIVALENCE WITH DENOISING AUTOENCODER",
      "text" : "Denoising Autoencoder (hereafter \"DAE\") is an extension of autoencoder and used as a building block of SDAE. In DAE, when calculating y of the hidden layer, we don’t directly use raw value of x. Instead, we add noise to x to make x̃, then y uses x̃. Note that the reconstruction layer z still use the original x value.\nTo reinterpret this DAE by our multiagent system, we can assign x̃i to uxi along with xi. When the data is input, we can calculate x̃ right after the assignment to xi. Each xi(i = 1 · · ·Nx) send corresponding yj(j = 1 · · ·Ny) the noised value x̃i instead of xi. Then the two algorithm become equivalent again."
    }, {
      "heading" : "3.3.4 EQUIVALENCE WITH STANDARD SDAE",
      "text" : "We finally reimplement the whole SDAE algorithm by our multiagent system and show its equivalence with the standard version again. The learning process of SDAE can be divided into pretraining and fine-tuning and we can explain the two phase separately.\npretraining phase In the pretraining phase of SDAE, let xi, yi, zi be the input, hidden, the associated reconstruction layer value of DA, respectively. To stack a learning DA, yj is considered as a new input units from the view of the new DA. Let z ′\nj be the reconstruction unit’s value of yj itself, and y ′\nk be the new stacked hidden layer units. We make a full connection between each layers. Thus the equations relating to these variables change to y ′ k ← σ(w0 + ∑Ny j=1 wjkyj) and z ′ j ←\nσ(w0 + ∑N y ′ k=1 wkjy ′ k). The new objective function after the stacking is Lj = 1 Ny ∑Ny j=1(z ′\nj − yj)2. Note that by stacking a new DAE layer, we are making a new task of objective function from the previous objective.\nNow we describe the change needed on our multiagent system. We need to introduce the notion of state for the units associated with the hidden layers in the standard version. When the objective function changed, the network structure and the state of the units must be changed in response too.\nThe hidden units can take the the two states, \"state A (On learning)\" and \"state B (Learned, stable)\". The units are initiated to \"state A\" and the behavior in this state doesn’t change from the previous sections. But the units in \"state B\" doesn’t send messages to the units for reconstruction zi and instead send the same messages to the \"state A\" units in the stacked layer.\nAdditionary, we need to append a reconstruction unit for each hidden unit changed to \"state B\". These pairs of the \"state B\" unit and appended reconstruction unit act as same as the pairs of input and reconstruction units we stated in DAE section except that they send message not after the data is input, but after the feature yj is calculated.\nOnce the pretraining for one block of DAE ends, all the hidden units in that DAE change to \"state B\". Then they form a new DAE starting from \"state B\" hidden units through the new stacked \"state A\" units then the associated reconstruction units appended. This DAE can be optimized in the same way of the single multiagent DAE we have described with only one exception that the data is not sent from the environment, but instaed the feature value yj in the previous DAE is calculated in the same order (j = 1 · · ·Ny)\nfine-tuning phase In order to use SDAE for supervised learning task, we pretrain some predefined number of hidden layers by layerwise pretraining, and at the end stack the layer for supervised purpose (typically a softmax layer for classification). This is another form of the change of the objective function and the multiagent system can deal with it too by changing network and unit’s state.\nSpecifically, when the all pretraining phase ends, connect the output units for supervised learning onto the topmost hidden units, and all feature unit changes its state to the newly introduced \"state C (On fine-tuning)\". The \"state C\" is almost the same as \"state A\", but the only differences are the two:\n• They don’t send message to reconstruction units. • They always send backpropagation message to the previous units.\nThis backpropagation message must be sent in ascending order as well as the previous message passing.\nHere we reinterpreted the standard pretraining and fine-tuning algorithm with our proposed multiagent system. These two cover the all learning phase of SDAE, therefore we have successfully reinterpreted the whole SDAE and showed its equivalence of the standard SDAE."
    }, {
      "heading" : "3.4 SPARSE CONNECT SDAE",
      "text" : "Now we obtain new multiagent SDAE, and theoritically showed its equivalence to standard SDAE. Next we want to extend this model and experiment its behavior. One of the minimal and simplest\nmodification to this model is to truncate the edges randomly. We call this model \"Sparse connect SDAE\" or \"SCSDAE\" for the latter section.\nSince our goal here is to check the basic behavior when we truncate edges, we take one of the simplest rule that we basically connect all edges between nodes (if the distance meets criteria) but drop them for certain threshold probability. Once the connection is established, we fix them and will not modify online. For example, connection rate 1.0 (100%) means it is the same network as SDAE and 0.3 means 30% of edges in SDAE remain intact and the others are dropped.\nWe can expect the time spent in learning is proportional to the connection rate. This is an obvious strong point against the standard matrix-vector based network. In matrix-vector based networks, we must fix the size of weight matrices and keep them at their original size even if most weights are learned to be soft zero. In our multiagent model however, we only need to calculate for existing edges. We will see whether this expectation holds in the next experiments section."
    }, {
      "heading" : "4 EXPERIMENTS",
      "text" : "We implemented the proposed multiagent network and measure its performance. We verified empirical equivalence between the multiagent SDAE and standard SDAE. We also measure performance of Sparse connect SDAE, which we described in 3.4. We change its connection rate and see how the performance and learning time changes."
    }, {
      "heading" : "4.1 DATASET",
      "text" : "We use two datasets for experiment, one is an artificial XOR function toy dataset made by us for this experiment, and the other is the MNIST handwritten digit dataset. Since the result and conclusion is almost same, we only report for the MNIST dataset. The details of the datasets are described in Appendix A."
    }, {
      "heading" : "4.2 MODEL SETTINGS",
      "text" : "We use the sigmoid function as activation functions of all units. We use the unit-wise MSRE as mentioned in the section 3 for both reconstruction errors in pretraining phase and classification in finetune phase. In pretraining, we simply take the mean through the all reconstruction units to check if the training works. For finetuning, we again take the sum of MSRE as cost function, and as classification error, we take the label associated with the unit that has the most activated value and discretely compare that value to measure the error rate. The SDAE algorithm includes random noise addition and is not fully deterministic. So we run each experiment settings for 3 times and take the average through the runs for all metrics we show. We set learning rate for pretraining and finetuning to 0.001 and 0.1, respectively. Corruption rate of SDAE is fixed to 0.3."
    }, {
      "heading" : "4.3 COMPARISON BETWEEN MULTIAGENT AND NORMAL SDAE",
      "text" : "We compared the test error rate through epochs between multiagnt and normal SDAE. Figure 2 show the mean classification error rate through 3 simulations with the MNIST dataset. We can see the two graphs form almost the same shape, which suggests the multiagent implementation of SDAE is empirically equivalent to normal SDAE. This is a verification of the theoritical proof we showed in section 3.\nIn order to check this equivalence more precisely, we evaluate the difference of maximum weight update between multiagent and normal SDAE (Table 2). We gave an input data to both networks and measure the largest change of weight change update for each edge group shown in Table 2. To make the problem simple and clear, for this experiment we used only one hidden layer and no pretraining, so the model is similiar to a naive MLP. From the Table 2, we can see that the decimal order of largest difference is 3 digits small as that of information error with 32bit floating point numbers. We suppose this difference is small enough to be well ignored."
    }, {
      "heading" : "4.4 SPARSE CONNENCT SDA",
      "text" : "We gradually changed the connectivity rate of our proposed SCSDAE and compare its performance. In this experiment, we measure the performance by the two aspect, the error rate and the calculation time, because we expect that the less number of edge mean the less calculation in time in our model as we described in chapter 3.\nFigure 3 shows the meausred calculation time and Figure 4 for the error rate. In both figures the horizontal coordinate indicates the number of iterated epochs and the vertical is for time and error rate, respectively. From Figure 3, we can verify that the calculation time decreases linearly as we expected.\nFigure 4 shows the error rate on test set after the given number of epochs passed. Contrary to our intuition, it can be said that in some cases despite of the decrease in connection probability, error rate do not deteriorate. The reason is not obvious, but we suppose that the more connection established, the more it became difficult and time requiring to the model to converge enough to show the potential of the model class. It can be also possible that the forced sparsity gave the model unexpected advantage to obtain sparse coding efficiently."
    }, {
      "heading" : "5 CONCLUSION",
      "text" : "We proposed a fundamental framework to reinterpret deep networks as multiagent systems. Specifically, we reimplemented a model equivalent to Stacked Denoising Autoencoder(SDAE) but the inside implementation is given with the multiagent system. We verified this equivalence from both theoritical and empirical aspects. We also tested the behaviour when we actually let the model drop\nsome edges permanently and demostrated the reduction of computation time as the connection rate decreases.\nOur contribution is to propose new multiagent based neural network system that free existing deep network from restriction of layer scheme. Our system involves the standard SDAE as its subset and has large potential of extension. Our model could be extended to more biologically plausible variation. Our experiment with the proposed Sparse Connect SDAE demostrate the advantage of non-matrix calculation and permanent drop of edges.\nThe next step is to sophisticate the model so that the agents are more strictly independent from the environment. Then we will be able to use this system as a framework for extending more flexible deep network. For example, we can make arbitrary connection of units. We can also consider mixing of units with different activation function, dropout strategy, learning rate."
    }, {
      "heading" : "A. DATASETS",
      "text" : "XOR function toy dataset consists of random ordering of four points representing the four region of XOR function on 2D coordinate, which are set of tuple (x1, x2, y) = [(1, 1, 1), (1,−1,−1), (−1, 1,−1), (−1,−1,−1)]. The value ’1’ represents boolean value ’true’ and ’-1’ for ’false’. x1 and x2 mean boolean value input to the XOR function and y is the output.\nMNIST handwritten digit dataset is a famous image recognision task. The input is a 28x28 image patch of digit classified to 10 classes(0-9). It contains 60000 train images and 10000 test images. Since our goal is not to pursue the state of the art performance of this dataset, but verify the common property of our proposed model with more realistic problem rather than the XOR toy sample, so we did no preprocessing on the dataset. We directly input image pixel value as a 784 row vector and didn’t use the prior that the image is 2D data with spatiality which is importatnt in convolutional network. This setting is called \"permutation invariant\" version of the MNIST task."
    }, {
      "heading" : "B. EXPERIMENTS DETAILS",
      "text" : "For the XOR task, we set the number of hidden units to [3, 4, 5]. For MNIST, we used [100, 100, 100] network for all experiments. The learning rate was fixed to 0.001 at pretraining time and 0.1 at finetuning. We trained 30 epochs of pretrainings for each MLP layer and 50 epochs of finetuning. We used a single core of Intel(R) E5-2630 @ 2.40GHz to measure the performance invariant to paralization method. The effect of paralization is a question for future research."
    } ],
    "references" : [ {
      "title" : "Spiking Deep Convolutional Neural Networks for Energy-Efficient Object Recognition",
      "author" : [ "Yongqiang Cao", "Yang Chen", "Deepak Khosla" ],
      "venue" : "International Journal of Computer Vision,",
      "citeRegEx" : "Cao et al\\.,? \\Q2014\\E",
      "shortCiteRegEx" : "Cao et al\\.",
      "year" : 2014
    }, {
      "title" : "BinaryConnect: Training Deep Neural Networks with binary weights during propagations",
      "author" : [ "Matthieu Courbariaux", "Yoshua Bengio", "Jean-Pierre David" ],
      "venue" : "arXiv preprint arXiv:1511.00363,",
      "citeRegEx" : "Courbariaux et al\\.,? \\Q2015\\E",
      "shortCiteRegEx" : "Courbariaux et al\\.",
      "year" : 2015
    }, {
      "title" : "Learning to Communicate with Deep Multi-Agent Reinforcement Learning",
      "author" : [ "Jakob N. Foerster", "Yannis M. Assael", "Nando de Freitas", "Shimon Whiteson" ],
      "venue" : "arXiv preprint arXiv:1605.06676,",
      "citeRegEx" : "Foerster et al\\.,? \\Q2016\\E",
      "shortCiteRegEx" : "Foerster et al\\.",
      "year" : 2016
    }, {
      "title" : "Deep Compression: Compressing Deep Neural Networks with Pruning, Trained Quantization and Huffman Coding",
      "author" : [ "Song Han", "Huizi Mao", "William J. Dally" ],
      "venue" : "In ICLR,",
      "citeRegEx" : "Han et al\\.,? \\Q2015\\E",
      "shortCiteRegEx" : "Han et al\\.",
      "year" : 2015
    }, {
      "title" : "Distilling the Knowledge in a Neural Network",
      "author" : [ "Geoffrey Hinton", "Oriol Vinyals", "Jeff Dean" ],
      "venue" : "In NIPS 2014 Deep Learning Workshop,",
      "citeRegEx" : "Hinton et al\\.,? \\Q2014\\E",
      "shortCiteRegEx" : "Hinton et al\\.",
      "year" : 2014
    }, {
      "title" : "Adam: A Method for Stochastic Optimization",
      "author" : [ "Diederik Kingma", "Jimmy Ba" ],
      "venue" : "arXiv preprint arXiv:1412.6980,",
      "citeRegEx" : "Kingma and Ba.,? \\Q2014\\E",
      "shortCiteRegEx" : "Kingma and Ba.",
      "year" : 2014
    }, {
      "title" : "Difference Target Propagation",
      "author" : [ "Dong-Hyun Lee", "Saizheng Zhang", "Asja Fischer", "Antoine Biard", "Yoshua Bengio" ],
      "venue" : "arXiv preprint arXiv:1412.7525,",
      "citeRegEx" : "Lee et al\\.,? \\Q2014\\E",
      "shortCiteRegEx" : "Lee et al\\.",
      "year" : 2014
    }, {
      "title" : "MADE: Masked Autoencoder for Distribution Estimation",
      "author" : [ "Mathieu Germain Mathieu", "Karol Gregor Karol", "Iain Murray Iain", "Hugo Larochelle Hugo", "Mathieu Germain", "Karol Gregor", "Google Deepmind", "Gmail Com", "Iain Murray", "Hugo Larochelle" ],
      "venue" : "In ICML,",
      "citeRegEx" : "Mathieu et al\\.,? \\Q2015\\E",
      "shortCiteRegEx" : "Mathieu et al\\.",
      "year" : 2015
    }, {
      "title" : "Spike Frequency Adaptation Implements Anticipative Tracking in Continuous Attractor Neural Networks",
      "author" : [ "Yuanyuan Mi", "C.C. Alan Fung", "K.Y. Michael Wong", "Si Wu" ],
      "venue" : "In NIPS,",
      "citeRegEx" : "Mi et al\\.,? \\Q2014\\E",
      "shortCiteRegEx" : "Mi et al\\.",
      "year" : 2014
    }, {
      "title" : "Seven neurons memorizing sequences of alphabetical images via spike-timing dependent plasticity",
      "author" : [ "Takayuki Osogami", "Makoto Otsuka" ],
      "venue" : "Scientific Reports,",
      "citeRegEx" : "Osogami and Otsuka.,? \\Q2015\\E",
      "shortCiteRegEx" : "Osogami and Otsuka.",
      "year" : 2015
    }, {
      "title" : "Semi-supervised Learning with Ladder Networks",
      "author" : [ "Antti Rasmus", "Mathias Berglund", "Mikko Honkala", "Harri Valpola", "Tapani Raiko" ],
      "venue" : "arXiv preprint arXiv:1507.02672,",
      "citeRegEx" : "Rasmus et al\\.,? \\Q2015\\E",
      "shortCiteRegEx" : "Rasmus et al\\.",
      "year" : 2015
    }, {
      "title" : "Guided Self-organization in Indirectly Encoded and Evolving Topographic Maps",
      "author" : [ "Sebastian Risi", "Kenneth O. Stanley" ],
      "venue" : "In GECCO,",
      "citeRegEx" : "Risi and Stanley.,? \\Q2014\\E",
      "shortCiteRegEx" : "Risi and Stanley.",
      "year" : 2014
    }, {
      "title" : "Learning Multiagent Communication with Backpropagation",
      "author" : [ "Sainbayar Sukhbaatar", "Arthur Szlam", "Rob Fergus" ],
      "venue" : "arXiv preprint arXiv:1605.07736,",
      "citeRegEx" : "Sukhbaatar et al\\.,? \\Q2016\\E",
      "shortCiteRegEx" : "Sukhbaatar et al\\.",
      "year" : 2016
    }, {
      "title" : "Generating Coherent Patterns of Activity from Chaotic",
      "author" : [ "David Sussillo", "L.F. Abbott" ],
      "venue" : "Neural Networks. Neuron,",
      "citeRegEx" : "Sussillo and Abbott.,? \\Q2009\\E",
      "shortCiteRegEx" : "Sussillo and Abbott.",
      "year" : 2009
    }, {
      "title" : "Extracting and composing robust features with denoising autoencoders",
      "author" : [ "Pascal Vincent", "Hugo Larochelle", "Yoshua Bengio", "Pierre-Antoine Manzagol" ],
      "venue" : "In ICML,",
      "citeRegEx" : "Vincent et al\\.,? \\Q2008\\E",
      "shortCiteRegEx" : "Vincent et al\\.",
      "year" : 2008
    } ],
    "referenceMentions" : [ {
      "referenceID" : 2,
      "context" : "There are several methods to reduce the cost by downsize the model such as distillation(Hinton et al. (2014)), and limiting the model space with binarizing(Courbariaux et al.",
      "startOffset" : 88,
      "endOffset" : 109
    }, {
      "referenceID" : 1,
      "context" : "(2014)), and limiting the model space with binarizing(Courbariaux et al. (2015)) and hashing Han et al.",
      "startOffset" : 54,
      "endOffset" : 80
    }, {
      "referenceID" : 1,
      "context" : "(2014)), and limiting the model space with binarizing(Courbariaux et al. (2015)) and hashing Han et al. (2015), but they still needs dense matrix filled with many zeros.",
      "startOffset" : 54,
      "endOffset" : 111
    }, {
      "referenceID" : 13,
      "context" : "Specifically, we reimplemented Stacked Denoising Autoencoder(SDAE) (Vincent et al. (2008)) as one of the variations in our framework.",
      "startOffset" : 68,
      "endOffset" : 90
    }, {
      "referenceID" : 10,
      "context" : "SDAE is related to the Ladder Network (Rasmus et al. (2015)) in that both employ reconstruction and denoising mechanism.",
      "startOffset" : 39,
      "endOffset" : 60
    }, {
      "referenceID" : 0,
      "context" : "Cao et al. (2014) convert regular CNN into spiking neural networks (SNN).",
      "startOffset" : 0,
      "endOffset" : 18
    }, {
      "referenceID" : 0,
      "context" : "Cao et al. (2014) convert regular CNN into spiking neural networks (SNN). Osogami & Otsuka (2015) build a variation of Boltzman Machine that follows the properties of Spike-timing dependent plasticity (STDP), which makes it more close to biological neural networks.",
      "startOffset" : 0,
      "endOffset" : 98
    }, {
      "referenceID" : 0,
      "context" : "Cao et al. (2014) convert regular CNN into spiking neural networks (SNN). Osogami & Otsuka (2015) build a variation of Boltzman Machine that follows the properties of Spike-timing dependent plasticity (STDP), which makes it more close to biological neural networks. Lee et al. (2014) proposes a modification of autoencoder that uses a novel credit assignment method called \"target propagation\" in place of back-propagation and achieved state",
      "startOffset" : 0,
      "endOffset" : 284
    }, {
      "referenceID" : 2,
      "context" : "One example is distillation (Hinton et al. (2014)).",
      "startOffset" : 29,
      "endOffset" : 50
    }, {
      "referenceID" : 2,
      "context" : "One example is distillation (Hinton et al. (2014)). It needs huge networks as a superviser network and it cannot be used as a mean to full scratch to new domain. MADE (Mathieu et al. (2015)) uses binary masking matrix to represent hard zero and thus conditional distribution.",
      "startOffset" : 29,
      "endOffset" : 190
    }, {
      "referenceID" : 1,
      "context" : "Limiting weight connection to binary (Courbariaux et al. (2015)) is another approach and its applicability is actively studied.",
      "startOffset" : 38,
      "endOffset" : 64
    }, {
      "referenceID" : 1,
      "context" : "Limiting weight connection to binary (Courbariaux et al. (2015)) is another approach and its applicability is actively studied. Han et al. (2015) combines pruning, quantization and Huffman coding together.",
      "startOffset" : 38,
      "endOffset" : 146
    }, {
      "referenceID" : 14,
      "context" : "We show how to reconstruct Stacked Denoising Autoencoder((Vincent et al. (2008))) with the proposed multiagent system.",
      "startOffset" : 58,
      "endOffset" : 80
    } ],
    "year" : 2016,
    "abstractText" : "We propose a multiagent system that have feedforward networks as its subset while free from layer structure with matrix-vector scheme. Deep networks are often compared to the brain neocortex or visual perception system. One of the largest difference from human brain is the use of matrix-vector multiplication based on layer architecture. It would help understanding the way human brain works if we manage to develop good deep network model without the layer architecture while preserving their performance. The brain neocortex works as an aggregation of the local level interactions between neurons, which is rather similar to multiagent system consists of autonomous partially observing agents than units aligned in column vectors and manipulated by global level algorithm. Therefore we suppose that it is an effective approach for developing more biologically plausible model while preserving compatibility with deep networks to alternate units with multiple agents. Our method also has advantage in scalability and memory efficiency. We reimplemented Stacked Denoising Autoencoder(SDAE) as a concrete instance with our multiagent system and verified its equivalence with the standard SDAE from both theoritical and empirical perspectives. Additionary, we also proposed a variant of our multiagent SDAE named \"Sparse Connect SDAE\", and showed its computational advantage with the MNIST dataset.",
    "creator" : "LaTeX with hyperref package"
  }
}