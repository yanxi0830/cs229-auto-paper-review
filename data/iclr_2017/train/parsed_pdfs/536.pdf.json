{
  "name" : "536.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "ON ROBUST CONCEPTS AND SMALL NEURAL NETS",
    "authors" : [ "Amit Deshpande", "Sushrut Karmalkar" ],
    "emails" : [ "amitdesh@microsoft.com", "sushrutk@cs.utexas.edu" ],
    "sections" : [ {
      "heading" : "1 INTRODUCTION",
      "text" : "The universal approximation theorem of Hornik et al. (1989) and Cybenko (1992) provides a foundation to the mathematical theory of artificial neural networks. It states that any continuous function on a compact subset of the Euclidean space can be approximated arbitrarily well by a feed-forward artificial neural network with only one hidden layer containing finitely many neurons, under mild assumptions on the activation function. In such neural networks, each node applies an activation function to a weighted linear combination of its inputs, and the above theorem holds true for many different choices of activation functions as shown by Hornik (1991). However, the universal approximation theorem and its quantitative improvements by Barron (1993) and others have certain limitations, namely, they do not provide reasonable, practical bounds or efficient learning algorithms for the parameters of these neural networks, that is, the number of neurons in the hidden layer and the size of weights used in the linear combinations. For a detailed survey of these results in approximation theory, we point the reader to Pinkus (1999).\nIn practice, we notice that even moderate-sized neural networks can be trained to learn various natural concepts in computer vision tasks, and the typical rules of thumb followed for their model and size selection are usually guided by the domain knowledge, the learning algorithm, and the available computational resources more than any theoretical bounds; see Simard et al. (2003). The known theoretical bounds are either based on the Network Information Criterion (NIC) by Amari (1998), which is a generalization of Akaike Information Criterion (AIC) by Akaike (1974) used in statistical inference, or based on the Vapnik-Chervonenkis dimension; see Baum & Haussler (1989), Bartlett (1993), Maass (1995), Karpinski & Macintyre (1997). These bounds do not adequately explain the observed efficiency of learning many natural concepts in practice.\n∗This work was done during an internship at Microsoft Research India, when the author was a student at Chennai Mathematical Institute, H1, SIPCOT IT Park, Siruseri, Chennai 603103, India\nMost natural concepts are often based on a small number of relevant attributes or features, and can be learnt efficiently once we implicitly map our input to the correct attribute space and focus on these relevant attributes or features. Moreover, most natural concepts are also robust, that is, their positive and negative examples are reasonably unambiguous and far from each other. Thus, an important theoretical question is to understand the underlying cognitive process, find a reasonably close and accurate model for it, and answer why certain models like artificial neural networks can mimic this cognitive process in practice.\nThe implicit mapping of our input coordinates to the space of attributes is formalized by the kernel method in machine learning; see Hofmann et al. (2008). Attribute-efficient learning proposed by Valiant (2000) and Littlestone (1988) captures the ease of learning via improved VC-dimension bounds that depend only a small number of relevant attributes. Robust concepts are often defined using large-margin classifiers studied in the context of Support Vector Machines; see Cortes & Vapnik (1995). We use a different notion of robustness suited to the boolean hypercube known as noise-stability. Due to known results from Fourier analysis over the boolean hypercube, noisestability also implies closeness to a function that depends only on a small number of attributes.\nSince the universal approximation theorem gives a depth-2 neural network with only one hidden layer, the effect of depth on the power of neural networks has attracted considerable interest in approximation theory as well as boolean circuit complexity; see de Villiers & Barnard (1993) and Siu et al. (1995). Note that on the boolean hypercube, depth-d circuits with sigmoid gates and linear threshold gates are essentially equivalent. An important result relevant to our paper is due to a long line of work including Goldmann et al. (1992), Goldmann & Karpinski (1998), and Hofmeister (1996) which proved that any depth-d linear threshold circuit with polynomially (in the number n of input variables) many nodes but arbitrary weights can be efficiently simulated by a depth-(d+ 1) linear threshold circuit with polynomially many nodes and polynomially bounded integer weights."
    }, {
      "heading" : "2 OUR RESULTS",
      "text" : "We work with linear threshold circuits with boolean inputs and outputs, which are discrete analogs of the neural networks with real-valued inputs and continuous activation functions. They are also known as multi-layer perceptrons as in Minsky & Papert (1987), which are simply feed-forward neural networks where each node computes a weighted linear combination of its inputs and applies a threshold function for activation. As mentioned above, the notion of robustness we use is noisestability or low noise-sensitivity. The noise sensitivity of a boolean function is simply the fraction of inputs whose output changes, if we change each coordinate of the input independently with a small probability, say some > 0.\nAs a warm-up, we show that if a boolean function defined on the boolean hypercube {−1, 1}n is noise-stable, that is, if it has low noise-sensitivity, then it can be approximated by a depth-2 linear threshold circuit (that is, with one hidden layer), that depends only on constantly many variables in the input, and its number of hidden nodes and the weights are also constants, all independent of n. Here we quantify approximation or closeness based on the fraction of inputs where two functions differ. This result may be folklore although we are not aware of any reference.\nTheorem 1. Any f : {−1, 1}n → {−1, 1} that has small noise-sensitivity for -perturbations, that is, NS (f) = O (δ √ ), is δ-close to a depth-2 linear threshold circuit that depends only on O(1) variables of the input with O(1) hidden nodes and O(1) weights, where the constants O(1) depend on and δ but are independent of n.\nWhen the given function is actually a linear threshold function, that is, when it represents a halfspace, we can improve the above theorem with constants O(1) that are polynomial in 1/ and 1/δ, and thus, give an efficient analog of the universal approximation theorem for neural networks over the boolean hypercube. Note that this is consistent with the intuition that better noise-stable concepts can be approximated by smaller neural networks. It also shows that a given concept may be linearly separable in a high n-dimensional kernel space but its approximation by neural networks only depends on an inherent parameter like robustness or noise-sensitivity, independent of n.\nTheorem 2. Any linear threshold function f : {−1, 1}n → {−1, 1} that has small noise-sensitivity for -perturbations, that is, NS (f) = O ( δ3 √ ) , is δ-close to a depth-2 linear threshold circuit\nthat depends only on O(1) variables of the input with O(1) hidden nodes and O(1) integer weights, where the constants are poly(1/ , 1/δ) but independent of n.\nEquipped with this, we show the following implication for learning. Given oracle access to such a linear threshold function f of low noise-sensitivity, we can learn a depth-2 linear threshold circuit that approximates f well, in polynomial time. Theorem 3. Let f : {−1, 1}n → {−1, 1} be any linear threshold function with small noisesensitivity for -perturbations, that is, NS (f) = O ( δ3 √ ) . Then we can learn a depth-2 linear\nthreshold circuit on k variables that is exp ( −Ω( 3 √ log(1/δ)) ) -close to f with probability 1 − γ,\nin time nk · p (1/ , 1/δ, 1/γ), where p is polynomial in 1/ , exponential in polylog (1/δ), and logarithmic in 1/γ, and k = O ( 1/ 2 · log(1/ ) · log(1/δ) ) . Moreover, the size and integer weights of\nthe depth-2 linear threshold circuits are polynomially bounded in 1/ and 1/δ.\nWe would also like to note that it is possible to extend our result for halfspaces to polynomial threshold functions. This uses the facts that any degree-d polynomial threshold function -close to a J-junta, is close to junta that is a polynomial threshold function of degree at most d, and that the machinery from De et al. (2014) extends to small weight polynomial threshold functions as well.\nIn a recent paper, Feldman & Vondrak (2013) have shown that sub-modular functions are close to O ( 1/ 2 · log (1/ ) ) -juntas. Note that this tells us that we can -approximate submodular func-\ntions by polynomials of degree O ( 1/ 2 · log (1/ ) ) . This means we can approximate submodular functions by depth-3 neural networks with linear threshold gates everywhere except for the top gate."
    }, {
      "heading" : "2.1 OBSTACLES TO IMPROVEMENTS",
      "text" : "We now discuss some obstacles to possible improvements of our results. The nk running time is needed to identify the specific set of O ( 1/ 2 · log(1/ ) · log(1/δ) ) relevant\ncoordinates. This nO(k) factor is unavoidable while learning k-juntas, and a candidate hard case is presented in Blum et al. (1994). Only recently Valiant (2015) gave an improved algorithm to learn k-juntas with noise rate η that runs in time less than n0.8k · poly ( 2k, 1/(1− 2η) ) .\nWeak, proper, agnostic learning of halfspaces under non-uniform distributions is NP-hard as shown by Guruswami & Raghavendra (2006), and extended to improper learning by Daniely et al. (2013) and Daniely (2015). Daniely’s result rules out efficient, constant factor approximation for even improper learning of halfspaces using any hypothesis class on the boolean hypercube under nonuniform distributions1. However, Daniely (2014) can get around this by giving a PTAS for improper learning of halfspaces on the unit sphere under uniform distribution. Our result can be seen as another way to circumvent the hardness results. We learn noise-stable halfspaces on the boolean hypercube under uniform distribution, by giving an efficient, agnostic-type learning algorithm where the output hypothesis is a depth-2 neural network. This is arguably more natural than other improper learning results for halfspaces via low-degree polynomials.\nNot having an efficient version of Bourgain’s theorem for arbitrary noise-stable boolean functions, where the number of junta variables is polynomial in the noise-sensitivity parameters is another obstacle to efficient generalizations of our result. Note that the proof of this for noise-stable halfspaces does not generalize to higher depth linear threshold circuits. Another approach is to approximate any noise-stable function first using a halfspace and then by a depth-2 linear threshold circuit, but this has been ruled out by Mossel & Neeman (2016) with an example of a noise-stable function that is far from any halfspace.\nWe now give a brief outline of the proofs of the above theorems. Bourgain (2002) proved that any function with small noise-sensitivity can be approximated by another function that is a junta, which means that it depends on very few coordinates. In Theorem 1, we show that such a function can also be represented by a small depth-2 linear threshold circuit with small size and small integer weights. Moreover, any linear threshold function that is close to a junta is actually close to a linear threshold\n1Results in Daniely et al. (2013) are under certain assumptions that are refuted in Allen et al. (2015). However, Daniely (2015) recovers a slightly weaker but very similar result for halfspaces under different assumptions\nfunction defined over those junta coordinates. Thus, we can approximate the given noise-stable function by a linear threshold function on a small number of inputs, however, its weights may be large. Therefore, we use the size-depth-weight trade-off from Goldmann et al. (1992) to simulate this linear threshold function by a depth-2 linear threshold circuit with small size as well as small weights in Theorem 2. We also use a recent improvement over Bourgain’s theorem by Diakonikolas et al. (2014) to get bounds polynomial in the noise-stability parameters. Theorem 3 follows by combining a result of De et al. (2014) on agnostic-type learning by a linear threshold function with a constructive, efficient simulation of the Goldmann et al. (1992) result by Goldmann & Karpinski (1998)."
    }, {
      "heading" : "3 RELATED WORK",
      "text" : "Motivated by the recent advances in neural networks, there have been various attempts to build a theory to understand why neural networks can efficiently simulate many natural concepts and why their models and parameters can be learnt efficiently, for example, Andoni et al. (2014) and Arora et al. (2014). Our objective is to show efficient analogs of the universal approximation theorem for neural networks, a question that has been studied in approximation theory as well as boolean circuit complexity. We combine the size-depth-weight trade-off results from about two decades ago such as Goldmann et al. (1992) and Goldmann & Karpinski (1998) with more recent work on the Fourier analysis of boolean functions and its corollaries in learning. Also note that There are known NP-hardness results for learning halfspaces by Guruswami & Raghavendra (2009) and for approximately learning depth-2 threshold circuits by Bartlett & Ben-David (2002). However, these are for arbitrary threshold circuits. As we will show, the noise-stability constraint allows us to get a polynomial time algorithm to learn a depth-2 threshold circuit approximating the original function.\nThe low effective-dimension of hyperparameters has been observed and exploited to learn using neural networks in practice by Bergstra & Bengio (2012). We propose noise-stability as an approach to study this theoretically.\nArriaga & Vempala (2006) showed that robust or large-margin halfspaces in Rn can be learnt efficiently using random projections. Their learning algorithm outputs a depth-2 neural network with different activation functions in different layers. We define robustness using noise-stability instead, and show that better noise-stability reduces learning complexity. Our results also generalize to polynomial threshold functions, that is, a noise-stable polynomial threshold function (PTF) can be represented by a small, depth-2 neural network."
    }, {
      "heading" : "4 PRELIMINARIES",
      "text" : "Here we give a compilation of definitions and known results that we will use to prove Theorems 1, 2, and 3. Noise-stable boolean functions have low noise-sensitivity. Noise-sensitivity of a boolean function, with respect to -perturbations, is defined as the fraction of inputs whose output changes, when we change each bit of the input independently with a small probability .\nDefinition 1. The noise sensitivity of a boolean function f : {−1, 1}n → {−1, 1} at a given noise rate > 0 is defined as\nNS (f) = Probx,y (f(x) 6= f(y)) ,\nwhere x is uniformly distributed in {−1, 1}n, and y is obtained from x by flipping each bit of x independently with probability .\nA theorem of Bourgain (2002) states that boolean functions with small noise-sensitivity are close to juntas, which are boolean functions that depend on very few coordinates. Note that the number of these relevant coordinates is independent of n. Lemma 1. Any f : {−1, 1}n → {−1, 1} that satisfies NS (f) = O (δ √ ) is δ-close to a k-junta, where\nk =\n( 1\nδ\n)O(1/ ) .\nHere, δ-closeness means agreement on 1− δ fraction of the inputs. Note that the √ in the bound has a special significance for linear threshold functions, as we explain below. Definition 2. A linear threshold function f : {−1, 1}n → {−1, 1} is defined as\nf(x) = sgn ( ∑n i=1 wixi − w0) ,\nfor some weights w0, w1, w2, . . . , wn ∈ R.\nA theorem of Peres (2004) states that the noise sensitivity of any linear threshold function at noise rate is at most 2 √ . Lemma 2. Any linear threshold function f : {−1, 1}n → {−1, 1} satisfies NS (f) ≤ 2 √ .\nThe bounds in Proposition 1 can be improved when f is a linear threshold function as shown by the result of Diakonikolas et al. (2014) mentioned below. Thus, a noise-stable linear threshold function is close to a k-junta, where k is polynomial dependent on the noise and approximation parameters, but is independent of n. Lemma 3. Any linear threshold function f : {−1, 1}n → {−1, 1} that satisfies NS (f) = O ( δ(2− )/(1− ) √ ) , for some 0 < < 1/2, is δ-close to a k-junta, where\nk = O\n( 1\n2 log\n( 1 ) log ( 1\nδ\n)) .\nRemark: For convenience, we use NS (f) = O ( δ3 √ )\nin our assumption whenever using the above theorem.\nThe following lemma from O’Donnell & Servedio (2011) ties it up nicely to say that if any linear threshold function is close to a junta, then it must be close to a linear threshold function defined over those junta coordinates. Lemma 4. If a linear threshold function f : {−1, 1}n → {−1, 1} is δ-close to a junta over a subset J ⊆ [n] of coordinates, then f is δ-close to a linear threshold function defined over that subset J ⊆ [n] of coordinates.\nLinear threshold circuits where each gate computes a linear threshold function forms an important class in circuit complexity. We borrow the standard definitions and notation from Siu et al. (1995) and Goldmann et al. (1992). Definition 3. LTd is defined as the class of linear threshold circuits of depth d on n inputs with the number of nodes polynomial in n but arbitrary weights inside the linear threshold functions. L̂T d is defined as the class of linear threshold circuit of depth d on n inputs with both the number of nodes and weights inside the linear threshold functions polynomially bounded in n.\nThe size-depth-weight trade-offs for linear threshold circuits have been studied in circuit complexity with keen interest, and a long line of work culminated in the following result by Goldmann et al. (1992). Here, the weight bounds are bounds on the ratio of the maximum and the minimum weights, when all of them are integers.\nLemma 5. LTd ⊆ L̂T d+1.\nThis means that any depth-d linear threshold circuit of polynomial size but arbitrary weights can be simulated by a depth-(d+ 1) linear threshold circuit whose size and weights are both polynomially bounded. While Goldmann et al. (1992) gives an existence result, Goldmann & Karpinski (1998) gives a constructive proof and it is easy to check that the underlying simulation is efficient and can be computed in polynomial time as well. Hofmeister (1996) has a simplified proof of Goldmann & Karpinski (1998) with improved explicit bounds.\nBourgain’s theorem has also been extended to the case of boolean functions with inputs that come from constant biased distributions over {−1, 1}n in Kindler & Safra (2002). Our general result can be extended to these cases as well. For this we need to define the λ-noise-sensitivity of a boolean function with respect to µp, where µp is the distribution that picks −1 with probability p and 1 with probability 1− p.\nDefinition 4. The λ-noise-sensitivity of a Boolean funciton f : {−1, 1}n → {−1, 1} with respect to µp is defined as\nNSλ,p (f) = Probx,y (f(x) 6= f(y))\nwhere x ∼ µnp and y is constructed by first sampling coordinates I from [n] according to µnλ and then replacing those coordinates in x by coordinates independently sampled from µIp.\nLemma 6. For any parameter λ > 0, fix k = log1−λ(1/2). Then every Boolean function f : {−1, 1}n → {−1, 1} whose λ-noise-sensitivity with respect to µnp is bounded by ( /k)2, is a max[O( log(1/p)/p2), J ]-junta, where\nJ = O\n( k3\n2pk\n)"
    }, {
      "heading" : "5 PROOF OF THEOREM 1",
      "text" : "Proof. (Proof of Theorem 1) The proof immediately follows from Proposition 1 and the following easy lemma.\nLemma 7. Any f : {−1, 1}n → {−1, 1} that is a k-junta can be represented by a depth-2 linear threshold circuit with the number of nodes and weights bounded by 2O(k).\nProof. Since f is a k-junta we can pretend that f : {−1, 1}k → {−1, 1}. Each positive example x ∈ {−1, 1}k such that f(x) = 1 can be isolated by a single halfspace h(y) = sgn (〈x, y〉 − (k − 1/2)), which outputs positive value for y ∈ {−1, 1}k iff x = y. We can build a depth-2 linear threshold circuit where all the hidden nodes correspond to h(x), one for each positive examples of f . Thus, for a positive example of f , exactly one of the hidden layer node outputs 1. Otherwise, all hidden layer nodes output −1. Now we can have a linear threshold gate are the top with all weights 1 and threshold 1− p, where p is the number of positive examples of f . Note that all the hidden threshold gates have integer weights bounded by k and they are at most 2k in number. The top gate has integer weights bounded by 2k. Thus, f can be represented by an LT2 or depth-2 linear threshold circuit where the size of the circuit and the integer weights used in it are bounded by 2O(k).\nTherefore, combining this with Proposition 1, we get that any noise-stable f as required in Theorem 1 is δ-close to a depth-2 linear threshold circuit whose size and integer weights are bounded by 2O(k), where\nk =\n( 1\nδ\n)O(1/ ) ,\nindependent of n."
    }, {
      "heading" : "6 PROOF OF THEOREM 2",
      "text" : "Since Bourgain’s theorem can be improved for linear threshold functions with polynomial dependency in the noise and approximation parameters, we can approximate the given function using a junta where the number of junta variables is polynomially bounded. Due to Lemma 4, we can moreover, say that our function is not just close to a junta but close to a linear threshold function defined over these junta variables. The only caveat is that the weights used in this linear threshold function may be large. This is where we invoke size-depth-weight trade-off result such as Proposition 5 from circuit complexity to simulate this linear threshold function by a linear threshold circuit with an extra depth but polynomially bounded weights.\nProof. (Proof of Theorem 2) From Proposition 3, we see that any linear threshold function f with low noise-sensitivity NS (f) = O ( δ3 √ ) is δ-close to an O ( 1/ 2 log (1/ ) log (1/δ) ) -junta. From Lemma 4, moreover, it must be δ-close a linear threshold function over these junta variables.\nThus, f is δ-close to an LT1 function over these junta variables but the weights could be large. However, Proposition 5 shows that this can be simulated by an LT2 function over these junta variables with weights polynomially bounded in the number of junta variables. Therefore, f is δ-close to an LT2 function over O ( 1/ 2 log (1/ ) log (1/δ) ) variables with the size of the circuits and the weights at the threshold gates polynomially bounded in 1/ and 1/δ, but independent of n. This concludes the proof of Theorem 2."
    }, {
      "heading" : "7 PROOF OF THEOREM 3",
      "text" : "Proof. (Proof of Theorem 3) Looking at Theorem 2, the broad outline of the algorithm is as follows. As seen in the proof of Theorem 2, we know that the given linear threshold function of low noisesensitivity is close to another linear threshold function that depends only on a small, constant number of input variables. We can go over each small subset by brute force. Now over each small subset, we can try to learn a linear threshold function over them that is closest to the given function. Here we use a result from De et al. (2014) (see Theorem 36 of De et al. (2014)) on agnostic-type learning halfspaces via reconstructing the Chow parameters of a linear threshold function; Chow parameters are the level-0 and level-1 Fourier coefficients which are known to completely determine a linear threshold function.\nLemma 8. Let f : {−1, 1}n → {−1, 1} and let opt be the minimum disagreement (in fraction of the inputs) of f with its closest linear threshold function. Then given any 0 < , γ < 1/2 and access to independent uniform samples (x, f(x)), we can output a linear threshold function g (given by its weights) such that, with probability 1− γ,\nd(f, g) ≤ 2−Ω( 3 √ log(1/opt)) + ,\nwhere the algorithm runs in time\nÕ(n2) · ( 1 )O(log2(1/ )) · log ( 1\nγ\n) .\nAn immediate corollary that is useful to us is\nCorollary 1. Let f : {−1, 1}n → {−1, 1} be a boolean function that is δ-close to a linear threshold function in a given subset S ⊆ [n] of k input variables. Then, for 0 < δ, γ < 1/2, and given access to independent uniform examples (x, f(x)), we can output a linear threshold function g (given by its weights) such that, with probability 1− γ,\nd(f, g) ≤ 2−Ω( 3 √ log(1/δ)) + δ,\nwhere the algorithm runs in time\nÕ(k2)\n( 1\nδ\n)O(log2(1/δ)) log ( 1\nγ\n) .\nThus, we go over all subsets of size O ( 1/ 2 · log(1/ ) · log(1/δ) ) and run the agnostic-type learning of linear threshold functions by De et al. (2014). We take the best of these and convert the corresponding output, which is a linear threshold function with weights possibly exponential in 1/ and 1/δ, and apply Goldmann & Karpinski (1998) to convert it into a depth-2 linear threshold circuit whose size and weights both are polynomially bounded in 1/ and 1/δ."
    }, {
      "heading" : "8 CONCLUSION AND FUTURE WORK",
      "text" : "We show an efficient analog of the universal approximation theorem for neural networks in the case of noise-sensitive halfspaces of boolean hypercube, and gave efficient learning algorithms for the same. We do this via an interplay of techniques from Fourier analysis over the boolean hypercube and size-weight-depth trade-off results on linear threshold circuits from circuit complexity.\nOne might be able to extend these result to continuous domains where the input is sampled uniformly from [−1, 1]n by using the ANOVA (analysis of variance) decomposition of a function. However, to do this one will have to prove a Bourgain-type theorem for these settings."
    } ],
    "references" : [ {
      "title" : "A new look at the statistical model identification",
      "author" : [ "H. Akaike" ],
      "venue" : "Automatic Control, IEEE Transactions on,",
      "citeRegEx" : "Akaike.,? \\Q1974\\E",
      "shortCiteRegEx" : "Akaike.",
      "year" : 1974
    }, {
      "title" : "How to refute a random CSP",
      "author" : [ "Sarah R. Allen", "Ryan O’Donnell", "David Witmer" ],
      "venue" : "CoRR, abs/1505.04383,",
      "citeRegEx" : "Allen et al\\.,? \\Q2015\\E",
      "shortCiteRegEx" : "Allen et al\\.",
      "year" : 2015
    }, {
      "title" : "The handbook of brain theory and neural networks. chapter Learning and Statistical Inference, pp. 522–526",
      "author" : [ "Shun-ichi Amari" ],
      "venue" : "URL http://dl.acm.org/citation.cfm?id=303568.303829",
      "citeRegEx" : "Amari.,? \\Q1998\\E",
      "shortCiteRegEx" : "Amari.",
      "year" : 1998
    }, {
      "title" : "Learning polynomials with neural networks",
      "author" : [ "Alexandr Andoni", "Rina Panigrahy", "Gregory Valiant", "Li Zhang" ],
      "venue" : "In Proceedings of the 31th International Conference on Machine Learning,",
      "citeRegEx" : "Andoni et al\\.,? \\Q2014\\E",
      "shortCiteRegEx" : "Andoni et al\\.",
      "year" : 2014
    }, {
      "title" : "Provable bounds for learning some deep representations",
      "author" : [ "Sanjeev Arora", "Aditya Bhaskara", "Rong Ge", "Tengyu Ma" ],
      "venue" : "In Proceedings of the 31th International Conference on Machine Learning,",
      "citeRegEx" : "Arora et al\\.,? \\Q2014\\E",
      "shortCiteRegEx" : "Arora et al\\.",
      "year" : 2014
    }, {
      "title" : "An algorithmic theory of learning: Robust concepts and random projection",
      "author" : [ "Rosa I. Arriaga", "Santosh Vempala" ],
      "venue" : "Machine Learning,",
      "citeRegEx" : "Arriaga and Vempala.,? \\Q2006\\E",
      "shortCiteRegEx" : "Arriaga and Vempala.",
      "year" : 2006
    }, {
      "title" : "Universal approximation bounds for superpositions of a sigmoidal function",
      "author" : [ "Andrew R. Barron" ],
      "venue" : "IEEE Transactions on Information Theory,",
      "citeRegEx" : "Barron.,? \\Q1993\\E",
      "shortCiteRegEx" : "Barron.",
      "year" : 1993
    }, {
      "title" : "Vapnik-chervonenkis dimension bounds for two- and three-layer networks",
      "author" : [ "Peter L. Bartlett" ],
      "venue" : "Neural Computation,",
      "citeRegEx" : "Bartlett.,? \\Q1993\\E",
      "shortCiteRegEx" : "Bartlett.",
      "year" : 1993
    }, {
      "title" : "Hardness results for neural network approximation problems",
      "author" : [ "Peter L. Bartlett", "Shai Ben-David" ],
      "venue" : "Theoretical Computer Science,",
      "citeRegEx" : "Bartlett and Ben.David.,? \\Q2002\\E",
      "shortCiteRegEx" : "Bartlett and Ben.David.",
      "year" : 2002
    }, {
      "title" : "What size net gives valid generalization",
      "author" : [ "Eric B. Baum", "David Haussler" ],
      "venue" : "Neural Comput.,",
      "citeRegEx" : "Baum and Haussler.,? \\Q1989\\E",
      "shortCiteRegEx" : "Baum and Haussler.",
      "year" : 1989
    }, {
      "title" : "Random search for hyper-parameter optimization",
      "author" : [ "James Bergstra", "Yoshua Bengio" ],
      "venue" : "J. Mach. Learn. Res.,",
      "citeRegEx" : "Bergstra and Bengio.,? \\Q2012\\E",
      "shortCiteRegEx" : "Bergstra and Bengio.",
      "year" : 2012
    }, {
      "title" : "Cryptographic primitives based on hard learning problems",
      "author" : [ "Avrim Blum", "Merrick L. Furst", "Michael J. Kearns", "Richard J. Lipton" ],
      "venue" : "In Proceedings of the 13th Annual International Cryptology Conference on Advances in Cryptology,",
      "citeRegEx" : "Blum et al\\.,? \\Q1994\\E",
      "shortCiteRegEx" : "Blum et al\\.",
      "year" : 1994
    }, {
      "title" : "On the distribution of the fourier spectrum of Boolean functions",
      "author" : [ "J. Bourgain" ],
      "venue" : "Israel Journal of Mathematics,",
      "citeRegEx" : "Bourgain.,? \\Q2002\\E",
      "shortCiteRegEx" : "Bourgain.",
      "year" : 2002
    }, {
      "title" : "Approximation by superpositions of a sigmoidal function",
      "author" : [ "George Cybenko" ],
      "venue" : "MCSS, 5(4):455,",
      "citeRegEx" : "Cybenko.,? \\Q1992\\E",
      "shortCiteRegEx" : "Cybenko.",
      "year" : 1992
    }, {
      "title" : "A PTAS for agnostically learning halfspaces",
      "author" : [ "Amit Daniely" ],
      "venue" : "CoRR, abs/1410.7050,",
      "citeRegEx" : "Daniely.,? \\Q2014\\E",
      "shortCiteRegEx" : "Daniely.",
      "year" : 2014
    }, {
      "title" : "Complexity theoretic limitations on learning halfspaces",
      "author" : [ "Amit Daniely" ],
      "venue" : "CoRR, abs/1505.05800,",
      "citeRegEx" : "Daniely.,? \\Q2015\\E",
      "shortCiteRegEx" : "Daniely.",
      "year" : 2015
    }, {
      "title" : "From average case complexity to improper learning",
      "author" : [ "Amit Daniely", "Nati Linial", "Shai Shalev-Shwartz" ],
      "venue" : "complexity. CoRR,",
      "citeRegEx" : "Daniely et al\\.,? \\Q2013\\E",
      "shortCiteRegEx" : "Daniely et al\\.",
      "year" : 2013
    }, {
      "title" : "Nearly optimal solutions for the chow parameters problem and low-weight approximation of halfspaces",
      "author" : [ "Anindya De", "Ilias Diakonikolas", "Vitaly Feldman", "Rocco A. Servedio" ],
      "venue" : "J. ACM,",
      "citeRegEx" : "De et al\\.,? \\Q2014\\E",
      "shortCiteRegEx" : "De et al\\.",
      "year" : 2014
    }, {
      "title" : "Backpropagation neural nets with one and two hidden layers",
      "author" : [ "J. de Villiers", "E. Barnard" ],
      "venue" : "Neural Networks, IEEE Transactions on,",
      "citeRegEx" : "Villiers and Barnard.,? \\Q1993\\E",
      "shortCiteRegEx" : "Villiers and Barnard.",
      "year" : 1993
    }, {
      "title" : "Noise Stable Halfspaces are Close to Very Small Juntas",
      "author" : [ "I. Diakonikolas", "R. Jaiswal", "R.A. Servedio", "L.-Y. Tan", "A. Wan" ],
      "venue" : null,
      "citeRegEx" : "Diakonikolas et al\\.,? \\Q2014\\E",
      "shortCiteRegEx" : "Diakonikolas et al\\.",
      "year" : 2014
    }, {
      "title" : "Optimal bounds on approximation of submodular and xos functions by juntas",
      "author" : [ "Vitaly Feldman", "Jan Vondrak" ],
      "venue" : "In Proceedings of the 2013 IEEE 54th Annual Symposium on Foundations of Computer Science,",
      "citeRegEx" : "Feldman and Vondrak.,? \\Q2013\\E",
      "shortCiteRegEx" : "Feldman and Vondrak.",
      "year" : 2013
    }, {
      "title" : "Simulating threshold circuits by majority circuits",
      "author" : [ "Mikael Goldmann", "Marek Karpinski" ],
      "venue" : "SIAM Journal on Computing,",
      "citeRegEx" : "Goldmann and Karpinski.,? \\Q1998\\E",
      "shortCiteRegEx" : "Goldmann and Karpinski.",
      "year" : 1998
    }, {
      "title" : "Majority gates vs. general weighted threshold",
      "author" : [ "Mikael Goldmann", "Johan Håstad", "Alexander Razborov" ],
      "venue" : "gates. computational complexity,",
      "citeRegEx" : "Goldmann et al\\.,? \\Q1992\\E",
      "shortCiteRegEx" : "Goldmann et al\\.",
      "year" : 1992
    }, {
      "title" : "Hardness of learning halfspaces with noise",
      "author" : [ "V. Guruswami", "P. Raghavendra" ],
      "venue" : "47th Annual IEEE Symposium on Foundations of Computer Science",
      "citeRegEx" : "Guruswami and Raghavendra.,? \\Q2006\\E",
      "shortCiteRegEx" : "Guruswami and Raghavendra.",
      "year" : 2006
    }, {
      "title" : "Hardness of learning halfspaces with noise",
      "author" : [ "Venkatesan Guruswami", "Prasad Raghavendra" ],
      "venue" : "SIAM Journal on Computing,",
      "citeRegEx" : "Guruswami and Raghavendra.,? \\Q2009\\E",
      "shortCiteRegEx" : "Guruswami and Raghavendra.",
      "year" : 2009
    }, {
      "title" : "Kernel methods in machine learning",
      "author" : [ "Thomas Hofmann", "Bernhard Schlkopf", "Alexander J. Smola" ],
      "venue" : "Ann. Statist., 36(3):1171–1220,",
      "citeRegEx" : "Hofmann et al\\.,? \\Q2008\\E",
      "shortCiteRegEx" : "Hofmann et al\\.",
      "year" : 2008
    }, {
      "title" : "Computing and Combinatorics",
      "author" : [ "Thomas Hofmeister" ],
      "venue" : "Second Annual International Conference, COCOON ’96 Hong Kong, June 17–19,",
      "citeRegEx" : "Hofmeister.,? \\Q1996\\E",
      "shortCiteRegEx" : "Hofmeister.",
      "year" : 1996
    }, {
      "title" : "Approximation capabilities of multilayer feedforward networks",
      "author" : [ "Kurt Hornik" ],
      "venue" : "Neural Networks,",
      "citeRegEx" : "Hornik.,? \\Q1991\\E",
      "shortCiteRegEx" : "Hornik.",
      "year" : 1991
    }, {
      "title" : "Multilayer feedforward networks are universal approximators",
      "author" : [ "Kurt Hornik", "Maxwell B. Stinchcombe", "Halbert White" ],
      "venue" : "Neural Networks,",
      "citeRegEx" : "Hornik et al\\.,? \\Q1989\\E",
      "shortCiteRegEx" : "Hornik et al\\.",
      "year" : 1989
    }, {
      "title" : "Noise-resistant boolean functions are juntas",
      "author" : [ "Guy Kindler", "Shmuel Safra" ],
      "venue" : null,
      "citeRegEx" : "Kindler and Safra.,? \\Q2002\\E",
      "shortCiteRegEx" : "Kindler and Safra.",
      "year" : 2002
    }, {
      "title" : "Learning quickly when irrelevant attributes abound: A new linear-threshold algorithm",
      "author" : [ "Nick Littlestone" ],
      "venue" : "Mach. Learn.,",
      "citeRegEx" : "Littlestone.,? \\Q1988\\E",
      "shortCiteRegEx" : "Littlestone.",
      "year" : 1988
    }, {
      "title" : "Vapnik-chervonenkis dimension of neural nets",
      "author" : [ "Wolfgang Maass" ],
      "venue" : "Handbook of Brain Theory and Neural Networks,",
      "citeRegEx" : "Maass.,? \\Q1995\\E",
      "shortCiteRegEx" : "Maass.",
      "year" : 1995
    }, {
      "title" : "Perceptrons - an introduction to computational geometry",
      "author" : [ "Marvin Minsky", "Seymour Papert" ],
      "venue" : null,
      "citeRegEx" : "Minsky and Papert.,? \\Q1987\\E",
      "shortCiteRegEx" : "Minsky and Papert.",
      "year" : 1987
    }, {
      "title" : "Noise Stability and Correlation with Half Spaces",
      "author" : [ "E. Mossel", "J. Neeman" ],
      "venue" : "ArXiv e-prints,",
      "citeRegEx" : "Mossel and Neeman.,? \\Q2016\\E",
      "shortCiteRegEx" : "Mossel and Neeman.",
      "year" : 2016
    }, {
      "title" : "The chow parameters problem",
      "author" : [ "Ryan O’Donnell", "Rocco A. Servedio" ],
      "venue" : "SIAM J. Comput.,",
      "citeRegEx" : "O.Donnell and Servedio.,? \\Q2011\\E",
      "shortCiteRegEx" : "O.Donnell and Servedio.",
      "year" : 2011
    }, {
      "title" : "Noise stability of weighted majority",
      "author" : [ "Yuval Peres" ],
      "venue" : "URL http://arxiv.org/abs/ math/0412377",
      "citeRegEx" : "Peres.,? \\Q2004\\E",
      "shortCiteRegEx" : "Peres.",
      "year" : 2004
    }, {
      "title" : "Approximation theory of the mlp model in neural networks",
      "author" : [ "Allan Pinkus" ],
      "venue" : "Acta Numerica,",
      "citeRegEx" : "Pinkus.,? \\Q1999\\E",
      "shortCiteRegEx" : "Pinkus.",
      "year" : 1999
    }, {
      "title" : "Best practices for convolutional neural networks applied to visual document analysis",
      "author" : [ "Patrice Y. Simard", "Dave Steinkraus", "John C. Platt" ],
      "venue" : "In Proceedings of the Seventh International Conference on Document Analysis and Recognition - Volume 2,",
      "citeRegEx" : "Simard et al\\.,? \\Q2003\\E",
      "shortCiteRegEx" : "Simard et al\\.",
      "year" : 2003
    }, {
      "title" : "Discrete Neural Computation: A Theoretical Foundation. Prentice-Hall, Inc",
      "author" : [ "Kai-Yeung Siu", "Vwani Roychowdhury", "Thomas Kailath" ],
      "venue" : "Upper Saddle River, NJ, USA,",
      "citeRegEx" : "Siu et al\\.,? \\Q1995\\E",
      "shortCiteRegEx" : "Siu et al\\.",
      "year" : 1995
    }, {
      "title" : "Finding correlations in subquadratic time, with applications to learning parities and the closest pair problem",
      "author" : [ "Gregory Valiant" ],
      "venue" : "J. ACM,",
      "citeRegEx" : "Valiant.,? \\Q2015\\E",
      "shortCiteRegEx" : "Valiant.",
      "year" : 2015
    }, {
      "title" : "A neuroidal architecture for cognitive computation",
      "author" : [ "Leslie G. Valiant" ],
      "venue" : "J. ACM,",
      "citeRegEx" : "Valiant.,? \\Q2000\\E",
      "shortCiteRegEx" : "Valiant.",
      "year" : 2000
    } ],
    "referenceMentions" : [ {
      "referenceID" : 22,
      "context" : "The universal approximation theorem of Hornik et al. (1989) and Cybenko (1992) provides a foundation to the mathematical theory of artificial neural networks.",
      "startOffset" : 39,
      "endOffset" : 60
    }, {
      "referenceID" : 9,
      "context" : "(1989) and Cybenko (1992) provides a foundation to the mathematical theory of artificial neural networks.",
      "startOffset" : 11,
      "endOffset" : 26
    }, {
      "referenceID" : 9,
      "context" : "(1989) and Cybenko (1992) provides a foundation to the mathematical theory of artificial neural networks. It states that any continuous function on a compact subset of the Euclidean space can be approximated arbitrarily well by a feed-forward artificial neural network with only one hidden layer containing finitely many neurons, under mild assumptions on the activation function. In such neural networks, each node applies an activation function to a weighted linear combination of its inputs, and the above theorem holds true for many different choices of activation functions as shown by Hornik (1991). However, the universal approximation theorem and its quantitative improvements by Barron (1993) and others have certain limitations, namely, they do not provide reasonable, practical bounds or efficient learning algorithms for the parameters of these neural networks, that is, the number of neurons in the hidden layer and the size of weights used in the linear combinations.",
      "startOffset" : 11,
      "endOffset" : 605
    }, {
      "referenceID" : 4,
      "context" : "However, the universal approximation theorem and its quantitative improvements by Barron (1993) and others have certain limitations, namely, they do not provide reasonable, practical bounds or efficient learning algorithms for the parameters of these neural networks, that is, the number of neurons in the hidden layer and the size of weights used in the linear combinations.",
      "startOffset" : 82,
      "endOffset" : 96
    }, {
      "referenceID" : 4,
      "context" : "However, the universal approximation theorem and its quantitative improvements by Barron (1993) and others have certain limitations, namely, they do not provide reasonable, practical bounds or efficient learning algorithms for the parameters of these neural networks, that is, the number of neurons in the hidden layer and the size of weights used in the linear combinations. For a detailed survey of these results in approximation theory, we point the reader to Pinkus (1999). In practice, we notice that even moderate-sized neural networks can be trained to learn various natural concepts in computer vision tasks, and the typical rules of thumb followed for their model and size selection are usually guided by the domain knowledge, the learning algorithm, and the available computational resources more than any theoretical bounds; see Simard et al.",
      "startOffset" : 82,
      "endOffset" : 477
    }, {
      "referenceID" : 4,
      "context" : "However, the universal approximation theorem and its quantitative improvements by Barron (1993) and others have certain limitations, namely, they do not provide reasonable, practical bounds or efficient learning algorithms for the parameters of these neural networks, that is, the number of neurons in the hidden layer and the size of weights used in the linear combinations. For a detailed survey of these results in approximation theory, we point the reader to Pinkus (1999). In practice, we notice that even moderate-sized neural networks can be trained to learn various natural concepts in computer vision tasks, and the typical rules of thumb followed for their model and size selection are usually guided by the domain knowledge, the learning algorithm, and the available computational resources more than any theoretical bounds; see Simard et al. (2003). The known theoretical bounds are either based on the Network Information Criterion (NIC) by Amari (1998), which is a generalization of Akaike Information Criterion (AIC) by Akaike (1974) used in statistical inference, or based on the Vapnik-Chervonenkis dimension; see Baum & Haussler (1989), Bartlett (1993), Maass (1995), Karpinski & Macintyre (1997).",
      "startOffset" : 82,
      "endOffset" : 861
    }, {
      "referenceID" : 1,
      "context" : "The known theoretical bounds are either based on the Network Information Criterion (NIC) by Amari (1998), which is a generalization of Akaike Information Criterion (AIC) by Akaike (1974) used in statistical inference, or based on the Vapnik-Chervonenkis dimension; see Baum & Haussler (1989), Bartlett (1993), Maass (1995), Karpinski & Macintyre (1997).",
      "startOffset" : 92,
      "endOffset" : 105
    }, {
      "referenceID" : 0,
      "context" : "The known theoretical bounds are either based on the Network Information Criterion (NIC) by Amari (1998), which is a generalization of Akaike Information Criterion (AIC) by Akaike (1974) used in statistical inference, or based on the Vapnik-Chervonenkis dimension; see Baum & Haussler (1989), Bartlett (1993), Maass (1995), Karpinski & Macintyre (1997).",
      "startOffset" : 135,
      "endOffset" : 187
    }, {
      "referenceID" : 0,
      "context" : "The known theoretical bounds are either based on the Network Information Criterion (NIC) by Amari (1998), which is a generalization of Akaike Information Criterion (AIC) by Akaike (1974) used in statistical inference, or based on the Vapnik-Chervonenkis dimension; see Baum & Haussler (1989), Bartlett (1993), Maass (1995), Karpinski & Macintyre (1997).",
      "startOffset" : 135,
      "endOffset" : 292
    }, {
      "referenceID" : 0,
      "context" : "The known theoretical bounds are either based on the Network Information Criterion (NIC) by Amari (1998), which is a generalization of Akaike Information Criterion (AIC) by Akaike (1974) used in statistical inference, or based on the Vapnik-Chervonenkis dimension; see Baum & Haussler (1989), Bartlett (1993), Maass (1995), Karpinski & Macintyre (1997).",
      "startOffset" : 135,
      "endOffset" : 309
    }, {
      "referenceID" : 0,
      "context" : "The known theoretical bounds are either based on the Network Information Criterion (NIC) by Amari (1998), which is a generalization of Akaike Information Criterion (AIC) by Akaike (1974) used in statistical inference, or based on the Vapnik-Chervonenkis dimension; see Baum & Haussler (1989), Bartlett (1993), Maass (1995), Karpinski & Macintyre (1997).",
      "startOffset" : 135,
      "endOffset" : 323
    }, {
      "referenceID" : 0,
      "context" : "The known theoretical bounds are either based on the Network Information Criterion (NIC) by Amari (1998), which is a generalization of Akaike Information Criterion (AIC) by Akaike (1974) used in statistical inference, or based on the Vapnik-Chervonenkis dimension; see Baum & Haussler (1989), Bartlett (1993), Maass (1995), Karpinski & Macintyre (1997). These bounds do not adequately explain the observed efficiency of learning many natural concepts in practice.",
      "startOffset" : 135,
      "endOffset" : 353
    }, {
      "referenceID" : 24,
      "context" : "The implicit mapping of our input coordinates to the space of attributes is formalized by the kernel method in machine learning; see Hofmann et al. (2008). Attribute-efficient learning proposed by Valiant (2000) and Littlestone (1988) captures the ease of learning via improved VC-dimension bounds that depend only a small number of relevant attributes.",
      "startOffset" : 133,
      "endOffset" : 155
    }, {
      "referenceID" : 24,
      "context" : "The implicit mapping of our input coordinates to the space of attributes is formalized by the kernel method in machine learning; see Hofmann et al. (2008). Attribute-efficient learning proposed by Valiant (2000) and Littlestone (1988) captures the ease of learning via improved VC-dimension bounds that depend only a small number of relevant attributes.",
      "startOffset" : 133,
      "endOffset" : 212
    }, {
      "referenceID" : 24,
      "context" : "The implicit mapping of our input coordinates to the space of attributes is formalized by the kernel method in machine learning; see Hofmann et al. (2008). Attribute-efficient learning proposed by Valiant (2000) and Littlestone (1988) captures the ease of learning via improved VC-dimension bounds that depend only a small number of relevant attributes.",
      "startOffset" : 133,
      "endOffset" : 235
    }, {
      "referenceID" : 24,
      "context" : "The implicit mapping of our input coordinates to the space of attributes is formalized by the kernel method in machine learning; see Hofmann et al. (2008). Attribute-efficient learning proposed by Valiant (2000) and Littlestone (1988) captures the ease of learning via improved VC-dimension bounds that depend only a small number of relevant attributes. Robust concepts are often defined using large-margin classifiers studied in the context of Support Vector Machines; see Cortes & Vapnik (1995). We use a different notion of robustness suited to the boolean hypercube known as noise-stability.",
      "startOffset" : 133,
      "endOffset" : 497
    }, {
      "referenceID" : 24,
      "context" : "The implicit mapping of our input coordinates to the space of attributes is formalized by the kernel method in machine learning; see Hofmann et al. (2008). Attribute-efficient learning proposed by Valiant (2000) and Littlestone (1988) captures the ease of learning via improved VC-dimension bounds that depend only a small number of relevant attributes. Robust concepts are often defined using large-margin classifiers studied in the context of Support Vector Machines; see Cortes & Vapnik (1995). We use a different notion of robustness suited to the boolean hypercube known as noise-stability. Due to known results from Fourier analysis over the boolean hypercube, noisestability also implies closeness to a function that depends only on a small number of attributes. Since the universal approximation theorem gives a depth-2 neural network with only one hidden layer, the effect of depth on the power of neural networks has attracted considerable interest in approximation theory as well as boolean circuit complexity; see de Villiers & Barnard (1993) and Siu et al.",
      "startOffset" : 133,
      "endOffset" : 1055
    }, {
      "referenceID" : 24,
      "context" : "The implicit mapping of our input coordinates to the space of attributes is formalized by the kernel method in machine learning; see Hofmann et al. (2008). Attribute-efficient learning proposed by Valiant (2000) and Littlestone (1988) captures the ease of learning via improved VC-dimension bounds that depend only a small number of relevant attributes. Robust concepts are often defined using large-margin classifiers studied in the context of Support Vector Machines; see Cortes & Vapnik (1995). We use a different notion of robustness suited to the boolean hypercube known as noise-stability. Due to known results from Fourier analysis over the boolean hypercube, noisestability also implies closeness to a function that depends only on a small number of attributes. Since the universal approximation theorem gives a depth-2 neural network with only one hidden layer, the effect of depth on the power of neural networks has attracted considerable interest in approximation theory as well as boolean circuit complexity; see de Villiers & Barnard (1993) and Siu et al. (1995). Note that on the boolean hypercube, depth-d circuits with sigmoid gates and linear threshold gates are essentially equivalent.",
      "startOffset" : 133,
      "endOffset" : 1077
    }, {
      "referenceID" : 22,
      "context" : "An important result relevant to our paper is due to a long line of work including Goldmann et al. (1992), Goldmann & Karpinski (1998), and Hofmeister (1996) which proved that any depth-d linear threshold circuit with polynomially (in the number n of input variables) many nodes but arbitrary weights can be efficiently simulated by a depth-(d+ 1) linear threshold circuit with polynomially many nodes and polynomially bounded integer weights.",
      "startOffset" : 82,
      "endOffset" : 105
    }, {
      "referenceID" : 22,
      "context" : "An important result relevant to our paper is due to a long line of work including Goldmann et al. (1992), Goldmann & Karpinski (1998), and Hofmeister (1996) which proved that any depth-d linear threshold circuit with polynomially (in the number n of input variables) many nodes but arbitrary weights can be efficiently simulated by a depth-(d+ 1) linear threshold circuit with polynomially many nodes and polynomially bounded integer weights.",
      "startOffset" : 82,
      "endOffset" : 134
    }, {
      "referenceID" : 22,
      "context" : "An important result relevant to our paper is due to a long line of work including Goldmann et al. (1992), Goldmann & Karpinski (1998), and Hofmeister (1996) which proved that any depth-d linear threshold circuit with polynomially (in the number n of input variables) many nodes but arbitrary weights can be efficiently simulated by a depth-(d+ 1) linear threshold circuit with polynomially many nodes and polynomially bounded integer weights.",
      "startOffset" : 82,
      "endOffset" : 157
    }, {
      "referenceID" : 17,
      "context" : "This uses the facts that any degree-d polynomial threshold function -close to a J-junta, is close to junta that is a polynomial threshold function of degree at most d, and that the machinery from De et al. (2014) extends to small weight polynomial threshold functions as well.",
      "startOffset" : 196,
      "endOffset" : 213
    }, {
      "referenceID" : 17,
      "context" : "This uses the facts that any degree-d polynomial threshold function -close to a J-junta, is close to junta that is a polynomial threshold function of degree at most d, and that the machinery from De et al. (2014) extends to small weight polynomial threshold functions as well. In a recent paper, Feldman & Vondrak (2013) have shown that sub-modular functions are close to O ( 1/ 2 · log (1/ ) ) -juntas.",
      "startOffset" : 196,
      "endOffset" : 321
    }, {
      "referenceID" : 11,
      "context" : "This n factor is unavoidable while learning k-juntas, and a candidate hard case is presented in Blum et al. (1994). Only recently Valiant (2015) gave an improved algorithm to learn k-juntas with noise rate η that runs in time less than n · poly ( 2, 1/(1− 2η) ) .",
      "startOffset" : 96,
      "endOffset" : 115
    }, {
      "referenceID" : 11,
      "context" : "This n factor is unavoidable while learning k-juntas, and a candidate hard case is presented in Blum et al. (1994). Only recently Valiant (2015) gave an improved algorithm to learn k-juntas with noise rate η that runs in time less than n · poly ( 2, 1/(1− 2η) ) .",
      "startOffset" : 96,
      "endOffset" : 145
    }, {
      "referenceID" : 11,
      "context" : "This n factor is unavoidable while learning k-juntas, and a candidate hard case is presented in Blum et al. (1994). Only recently Valiant (2015) gave an improved algorithm to learn k-juntas with noise rate η that runs in time less than n · poly ( 2, 1/(1− 2η) ) . Weak, proper, agnostic learning of halfspaces under non-uniform distributions is NP-hard as shown by Guruswami & Raghavendra (2006), and extended to improper learning by Daniely et al.",
      "startOffset" : 96,
      "endOffset" : 396
    }, {
      "referenceID" : 11,
      "context" : "This n factor is unavoidable while learning k-juntas, and a candidate hard case is presented in Blum et al. (1994). Only recently Valiant (2015) gave an improved algorithm to learn k-juntas with noise rate η that runs in time less than n · poly ( 2, 1/(1− 2η) ) . Weak, proper, agnostic learning of halfspaces under non-uniform distributions is NP-hard as shown by Guruswami & Raghavendra (2006), and extended to improper learning by Daniely et al. (2013) and Daniely (2015).",
      "startOffset" : 96,
      "endOffset" : 456
    }, {
      "referenceID" : 11,
      "context" : "This n factor is unavoidable while learning k-juntas, and a candidate hard case is presented in Blum et al. (1994). Only recently Valiant (2015) gave an improved algorithm to learn k-juntas with noise rate η that runs in time less than n · poly ( 2, 1/(1− 2η) ) . Weak, proper, agnostic learning of halfspaces under non-uniform distributions is NP-hard as shown by Guruswami & Raghavendra (2006), and extended to improper learning by Daniely et al. (2013) and Daniely (2015). Daniely’s result rules out efficient, constant factor approximation for even improper learning of halfspaces using any hypothesis class on the boolean hypercube under nonuniform distributions1.",
      "startOffset" : 96,
      "endOffset" : 475
    }, {
      "referenceID" : 11,
      "context" : "This n factor is unavoidable while learning k-juntas, and a candidate hard case is presented in Blum et al. (1994). Only recently Valiant (2015) gave an improved algorithm to learn k-juntas with noise rate η that runs in time less than n · poly ( 2, 1/(1− 2η) ) . Weak, proper, agnostic learning of halfspaces under non-uniform distributions is NP-hard as shown by Guruswami & Raghavendra (2006), and extended to improper learning by Daniely et al. (2013) and Daniely (2015). Daniely’s result rules out efficient, constant factor approximation for even improper learning of halfspaces using any hypothesis class on the boolean hypercube under nonuniform distributions1. However, Daniely (2014) can get around this by giving a PTAS for improper learning of halfspaces on the unit sphere under uniform distribution.",
      "startOffset" : 96,
      "endOffset" : 694
    }, {
      "referenceID" : 11,
      "context" : "This n factor is unavoidable while learning k-juntas, and a candidate hard case is presented in Blum et al. (1994). Only recently Valiant (2015) gave an improved algorithm to learn k-juntas with noise rate η that runs in time less than n · poly ( 2, 1/(1− 2η) ) . Weak, proper, agnostic learning of halfspaces under non-uniform distributions is NP-hard as shown by Guruswami & Raghavendra (2006), and extended to improper learning by Daniely et al. (2013) and Daniely (2015). Daniely’s result rules out efficient, constant factor approximation for even improper learning of halfspaces using any hypothesis class on the boolean hypercube under nonuniform distributions1. However, Daniely (2014) can get around this by giving a PTAS for improper learning of halfspaces on the unit sphere under uniform distribution. Our result can be seen as another way to circumvent the hardness results. We learn noise-stable halfspaces on the boolean hypercube under uniform distribution, by giving an efficient, agnostic-type learning algorithm where the output hypothesis is a depth-2 neural network. This is arguably more natural than other improper learning results for halfspaces via low-degree polynomials. Not having an efficient version of Bourgain’s theorem for arbitrary noise-stable boolean functions, where the number of junta variables is polynomial in the noise-sensitivity parameters is another obstacle to efficient generalizations of our result. Note that the proof of this for noise-stable halfspaces does not generalize to higher depth linear threshold circuits. Another approach is to approximate any noise-stable function first using a halfspace and then by a depth-2 linear threshold circuit, but this has been ruled out by Mossel & Neeman (2016) with an example of a noise-stable function that is far from any halfspace.",
      "startOffset" : 96,
      "endOffset" : 1754
    }, {
      "referenceID" : 11,
      "context" : "This n factor is unavoidable while learning k-juntas, and a candidate hard case is presented in Blum et al. (1994). Only recently Valiant (2015) gave an improved algorithm to learn k-juntas with noise rate η that runs in time less than n · poly ( 2, 1/(1− 2η) ) . Weak, proper, agnostic learning of halfspaces under non-uniform distributions is NP-hard as shown by Guruswami & Raghavendra (2006), and extended to improper learning by Daniely et al. (2013) and Daniely (2015). Daniely’s result rules out efficient, constant factor approximation for even improper learning of halfspaces using any hypothesis class on the boolean hypercube under nonuniform distributions1. However, Daniely (2014) can get around this by giving a PTAS for improper learning of halfspaces on the unit sphere under uniform distribution. Our result can be seen as another way to circumvent the hardness results. We learn noise-stable halfspaces on the boolean hypercube under uniform distribution, by giving an efficient, agnostic-type learning algorithm where the output hypothesis is a depth-2 neural network. This is arguably more natural than other improper learning results for halfspaces via low-degree polynomials. Not having an efficient version of Bourgain’s theorem for arbitrary noise-stable boolean functions, where the number of junta variables is polynomial in the noise-sensitivity parameters is another obstacle to efficient generalizations of our result. Note that the proof of this for noise-stable halfspaces does not generalize to higher depth linear threshold circuits. Another approach is to approximate any noise-stable function first using a halfspace and then by a depth-2 linear threshold circuit, but this has been ruled out by Mossel & Neeman (2016) with an example of a noise-stable function that is far from any halfspace. We now give a brief outline of the proofs of the above theorems. Bourgain (2002) proved that any function with small noise-sensitivity can be approximated by another function that is a junta, which means that it depends on very few coordinates.",
      "startOffset" : 96,
      "endOffset" : 1910
    }, {
      "referenceID" : 13,
      "context" : "Results in Daniely et al. (2013) are under certain assumptions that are refuted in Allen et al.",
      "startOffset" : 11,
      "endOffset" : 33
    }, {
      "referenceID" : 1,
      "context" : "(2013) are under certain assumptions that are refuted in Allen et al. (2015). However, Daniely (2015) recovers a slightly weaker but very similar result for halfspaces under different assumptions",
      "startOffset" : 57,
      "endOffset" : 77
    }, {
      "referenceID" : 1,
      "context" : "(2013) are under certain assumptions that are refuted in Allen et al. (2015). However, Daniely (2015) recovers a slightly weaker but very similar result for halfspaces under different assumptions",
      "startOffset" : 57,
      "endOffset" : 102
    }, {
      "referenceID" : 19,
      "context" : "Therefore, we use the size-depth-weight trade-off from Goldmann et al. (1992) to simulate this linear threshold function by a depth-2 linear threshold circuit with small size as well as small weights in Theorem 2.",
      "startOffset" : 55,
      "endOffset" : 78
    }, {
      "referenceID" : 12,
      "context" : "We also use a recent improvement over Bourgain’s theorem by Diakonikolas et al. (2014) to get bounds polynomial in the noise-stability parameters.",
      "startOffset" : 38,
      "endOffset" : 87
    }, {
      "referenceID" : 12,
      "context" : "We also use a recent improvement over Bourgain’s theorem by Diakonikolas et al. (2014) to get bounds polynomial in the noise-stability parameters. Theorem 3 follows by combining a result of De et al. (2014) on agnostic-type learning by a linear threshold function with a constructive, efficient simulation of the Goldmann et al.",
      "startOffset" : 38,
      "endOffset" : 207
    }, {
      "referenceID" : 12,
      "context" : "We also use a recent improvement over Bourgain’s theorem by Diakonikolas et al. (2014) to get bounds polynomial in the noise-stability parameters. Theorem 3 follows by combining a result of De et al. (2014) on agnostic-type learning by a linear threshold function with a constructive, efficient simulation of the Goldmann et al. (1992) result by Goldmann & Karpinski (1998).",
      "startOffset" : 38,
      "endOffset" : 336
    }, {
      "referenceID" : 12,
      "context" : "We also use a recent improvement over Bourgain’s theorem by Diakonikolas et al. (2014) to get bounds polynomial in the noise-stability parameters. Theorem 3 follows by combining a result of De et al. (2014) on agnostic-type learning by a linear threshold function with a constructive, efficient simulation of the Goldmann et al. (1992) result by Goldmann & Karpinski (1998).",
      "startOffset" : 38,
      "endOffset" : 374
    }, {
      "referenceID" : 3,
      "context" : "Motivated by the recent advances in neural networks, there have been various attempts to build a theory to understand why neural networks can efficiently simulate many natural concepts and why their models and parameters can be learnt efficiently, for example, Andoni et al. (2014) and Arora et al.",
      "startOffset" : 261,
      "endOffset" : 282
    }, {
      "referenceID" : 3,
      "context" : "Motivated by the recent advances in neural networks, there have been various attempts to build a theory to understand why neural networks can efficiently simulate many natural concepts and why their models and parameters can be learnt efficiently, for example, Andoni et al. (2014) and Arora et al. (2014). Our objective is to show efficient analogs of the universal approximation theorem for neural networks, a question that has been studied in approximation theory as well as boolean circuit complexity.",
      "startOffset" : 261,
      "endOffset" : 306
    }, {
      "referenceID" : 3,
      "context" : "Motivated by the recent advances in neural networks, there have been various attempts to build a theory to understand why neural networks can efficiently simulate many natural concepts and why their models and parameters can be learnt efficiently, for example, Andoni et al. (2014) and Arora et al. (2014). Our objective is to show efficient analogs of the universal approximation theorem for neural networks, a question that has been studied in approximation theory as well as boolean circuit complexity. We combine the size-depth-weight trade-off results from about two decades ago such as Goldmann et al. (1992) and Goldmann & Karpinski (1998) with more recent work on the Fourier analysis of boolean functions and its corollaries in learning.",
      "startOffset" : 261,
      "endOffset" : 615
    }, {
      "referenceID" : 3,
      "context" : "Motivated by the recent advances in neural networks, there have been various attempts to build a theory to understand why neural networks can efficiently simulate many natural concepts and why their models and parameters can be learnt efficiently, for example, Andoni et al. (2014) and Arora et al. (2014). Our objective is to show efficient analogs of the universal approximation theorem for neural networks, a question that has been studied in approximation theory as well as boolean circuit complexity. We combine the size-depth-weight trade-off results from about two decades ago such as Goldmann et al. (1992) and Goldmann & Karpinski (1998) with more recent work on the Fourier analysis of boolean functions and its corollaries in learning.",
      "startOffset" : 261,
      "endOffset" : 647
    }, {
      "referenceID" : 3,
      "context" : "Motivated by the recent advances in neural networks, there have been various attempts to build a theory to understand why neural networks can efficiently simulate many natural concepts and why their models and parameters can be learnt efficiently, for example, Andoni et al. (2014) and Arora et al. (2014). Our objective is to show efficient analogs of the universal approximation theorem for neural networks, a question that has been studied in approximation theory as well as boolean circuit complexity. We combine the size-depth-weight trade-off results from about two decades ago such as Goldmann et al. (1992) and Goldmann & Karpinski (1998) with more recent work on the Fourier analysis of boolean functions and its corollaries in learning. Also note that There are known NP-hardness results for learning halfspaces by Guruswami & Raghavendra (2009) and for approximately learning depth-2 threshold circuits by Bartlett & Ben-David (2002).",
      "startOffset" : 261,
      "endOffset" : 856
    }, {
      "referenceID" : 3,
      "context" : "Motivated by the recent advances in neural networks, there have been various attempts to build a theory to understand why neural networks can efficiently simulate many natural concepts and why their models and parameters can be learnt efficiently, for example, Andoni et al. (2014) and Arora et al. (2014). Our objective is to show efficient analogs of the universal approximation theorem for neural networks, a question that has been studied in approximation theory as well as boolean circuit complexity. We combine the size-depth-weight trade-off results from about two decades ago such as Goldmann et al. (1992) and Goldmann & Karpinski (1998) with more recent work on the Fourier analysis of boolean functions and its corollaries in learning. Also note that There are known NP-hardness results for learning halfspaces by Guruswami & Raghavendra (2009) and for approximately learning depth-2 threshold circuits by Bartlett & Ben-David (2002). However, these are for arbitrary threshold circuits.",
      "startOffset" : 261,
      "endOffset" : 945
    }, {
      "referenceID" : 3,
      "context" : "Motivated by the recent advances in neural networks, there have been various attempts to build a theory to understand why neural networks can efficiently simulate many natural concepts and why their models and parameters can be learnt efficiently, for example, Andoni et al. (2014) and Arora et al. (2014). Our objective is to show efficient analogs of the universal approximation theorem for neural networks, a question that has been studied in approximation theory as well as boolean circuit complexity. We combine the size-depth-weight trade-off results from about two decades ago such as Goldmann et al. (1992) and Goldmann & Karpinski (1998) with more recent work on the Fourier analysis of boolean functions and its corollaries in learning. Also note that There are known NP-hardness results for learning halfspaces by Guruswami & Raghavendra (2009) and for approximately learning depth-2 threshold circuits by Bartlett & Ben-David (2002). However, these are for arbitrary threshold circuits. As we will show, the noise-stability constraint allows us to get a polynomial time algorithm to learn a depth-2 threshold circuit approximating the original function. The low effective-dimension of hyperparameters has been observed and exploited to learn using neural networks in practice by Bergstra & Bengio (2012). We propose noise-stability as an approach to study this theoretically.",
      "startOffset" : 261,
      "endOffset" : 1316
    }, {
      "referenceID" : 3,
      "context" : "Motivated by the recent advances in neural networks, there have been various attempts to build a theory to understand why neural networks can efficiently simulate many natural concepts and why their models and parameters can be learnt efficiently, for example, Andoni et al. (2014) and Arora et al. (2014). Our objective is to show efficient analogs of the universal approximation theorem for neural networks, a question that has been studied in approximation theory as well as boolean circuit complexity. We combine the size-depth-weight trade-off results from about two decades ago such as Goldmann et al. (1992) and Goldmann & Karpinski (1998) with more recent work on the Fourier analysis of boolean functions and its corollaries in learning. Also note that There are known NP-hardness results for learning halfspaces by Guruswami & Raghavendra (2009) and for approximately learning depth-2 threshold circuits by Bartlett & Ben-David (2002). However, these are for arbitrary threshold circuits. As we will show, the noise-stability constraint allows us to get a polynomial time algorithm to learn a depth-2 threshold circuit approximating the original function. The low effective-dimension of hyperparameters has been observed and exploited to learn using neural networks in practice by Bergstra & Bengio (2012). We propose noise-stability as an approach to study this theoretically. Arriaga & Vempala (2006) showed that robust or large-margin halfspaces in R can be learnt efficiently using random projections.",
      "startOffset" : 261,
      "endOffset" : 1413
    }, {
      "referenceID" : 12,
      "context" : "A theorem of Bourgain (2002) states that boolean functions with small noise-sensitivity are close to juntas, which are boolean functions that depend on very few coordinates.",
      "startOffset" : 13,
      "endOffset" : 29
    }, {
      "referenceID" : 35,
      "context" : "A theorem of Peres (2004) states that the noise sensitivity of any linear threshold function at noise rate is at most 2 √ .",
      "startOffset" : 13,
      "endOffset" : 26
    }, {
      "referenceID" : 19,
      "context" : "The bounds in Proposition 1 can be improved when f is a linear threshold function as shown by the result of Diakonikolas et al. (2014) mentioned below.",
      "startOffset" : 108,
      "endOffset" : 135
    }, {
      "referenceID" : 37,
      "context" : "We borrow the standard definitions and notation from Siu et al. (1995) and Goldmann et al.",
      "startOffset" : 53,
      "endOffset" : 71
    }, {
      "referenceID" : 22,
      "context" : "(1995) and Goldmann et al. (1992). Definition 3.",
      "startOffset" : 11,
      "endOffset" : 34
    }, {
      "referenceID" : 22,
      "context" : "The size-depth-weight trade-offs for linear threshold circuits have been studied in circuit complexity with keen interest, and a long line of work culminated in the following result by Goldmann et al. (1992). Here, the weight bounds are bounds on the ratio of the maximum and the minimum weights, when all of them are integers.",
      "startOffset" : 185,
      "endOffset" : 208
    }, {
      "referenceID" : 21,
      "context" : "While Goldmann et al. (1992) gives an existence result, Goldmann & Karpinski (1998) gives a constructive proof and it is easy to check that the underlying simulation is efficient and can be computed in polynomial time as well.",
      "startOffset" : 6,
      "endOffset" : 29
    }, {
      "referenceID" : 21,
      "context" : "While Goldmann et al. (1992) gives an existence result, Goldmann & Karpinski (1998) gives a constructive proof and it is easy to check that the underlying simulation is efficient and can be computed in polynomial time as well.",
      "startOffset" : 6,
      "endOffset" : 84
    }, {
      "referenceID" : 21,
      "context" : "While Goldmann et al. (1992) gives an existence result, Goldmann & Karpinski (1998) gives a constructive proof and it is easy to check that the underlying simulation is efficient and can be computed in polynomial time as well. Hofmeister (1996) has a simplified proof of Goldmann & Karpinski (1998) with improved explicit bounds.",
      "startOffset" : 6,
      "endOffset" : 245
    }, {
      "referenceID" : 21,
      "context" : "While Goldmann et al. (1992) gives an existence result, Goldmann & Karpinski (1998) gives a constructive proof and it is easy to check that the underlying simulation is efficient and can be computed in polynomial time as well. Hofmeister (1996) has a simplified proof of Goldmann & Karpinski (1998) with improved explicit bounds.",
      "startOffset" : 6,
      "endOffset" : 299
    }, {
      "referenceID" : 12,
      "context" : "Bourgain’s theorem has also been extended to the case of boolean functions with inputs that come from constant biased distributions over {−1, 1} in Kindler & Safra (2002). Our general result can be extended to these cases as well.",
      "startOffset" : 0,
      "endOffset" : 171
    }, {
      "referenceID" : 17,
      "context" : "Here we use a result from De et al. (2014) (see Theorem 36 of De et al.",
      "startOffset" : 26,
      "endOffset" : 43
    }, {
      "referenceID" : 17,
      "context" : "Here we use a result from De et al. (2014) (see Theorem 36 of De et al. (2014)) on agnostic-type learning halfspaces via reconstructing the Chow parameters of a linear threshold function; Chow parameters are the level-0 and level-1 Fourier coefficients which are known to completely determine a linear threshold function.",
      "startOffset" : 26,
      "endOffset" : 79
    }, {
      "referenceID" : 17,
      "context" : "Thus, we go over all subsets of size O ( 1/ 2 · log(1/ ) · log(1/δ) ) and run the agnostic-type learning of linear threshold functions by De et al. (2014). We take the best of these and convert the corresponding output, which is a linear threshold function with weights possibly exponential in 1/ and 1/δ, and apply Goldmann & Karpinski (1998) to convert it into a depth-2 linear threshold circuit whose size and weights both are polynomially bounded in 1/ and 1/δ.",
      "startOffset" : 138,
      "endOffset" : 155
    }, {
      "referenceID" : 17,
      "context" : "Thus, we go over all subsets of size O ( 1/ 2 · log(1/ ) · log(1/δ) ) and run the agnostic-type learning of linear threshold functions by De et al. (2014). We take the best of these and convert the corresponding output, which is a linear threshold function with weights possibly exponential in 1/ and 1/δ, and apply Goldmann & Karpinski (1998) to convert it into a depth-2 linear threshold circuit whose size and weights both are polynomially bounded in 1/ and 1/δ.",
      "startOffset" : 138,
      "endOffset" : 344
    } ],
    "year" : 2016,
    "abstractText" : "The universal approximation theorem for neural networks says that any reasonable function is well-approximated by a two-layer neural network with sigmoid gates but it does not provide good bounds on the number of hidden-layer nodes or the weights. However, robust concepts often have small neural networks in practice. We show an efficient analog of the universal approximation theorem on the boolean hypercube in this context. We prove that any noise-stable boolean function on n boolean-valued input variables can be well-approximated by a two-layer linear threshold circuit with a small number of hidden-layer nodes and small weights, that depend only on the noisestability and approximation parameters, and are independent of n. We also give a polynomial time learning algorithm that outputs a small two-layer linear threshold circuit that approximates such a given function. We also show weaker generalizations of this to noise-stable polynomial threshold functions and noise-stable boolean functions in general.",
    "creator" : "LaTeX with hyperref package"
  }
}