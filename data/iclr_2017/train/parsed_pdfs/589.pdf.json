{
  "name" : "589.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "GRAPH CONVOLUTIONAL RECURRENT NETWORKS",
    "authors" : [ "Youngjoo Seo" ],
    "emails" : [ "youngjoo.seo@epfl.ch", "michael.defferrard@epfl.ch", "pierre.vandergheynst@epfl.ch", "xavier.bresson@epfl.ch" ],
    "sections" : [ {
      "heading" : "1 INTRODUCTION",
      "text" : "Many real-world data can be cast as structured sequences, with spatio-temporal sequences being a special case. A well-studied example of spatio-temporal data are videos, where succeeding frames share temporal and spatial structures. Many works, such as Donahue et al. (2015); Karpathy & FeiFei (2015); Vinyals et al. (2015), leveraged a combination of CNN and RNN to exploit such spatial and temporal regularities. Their models are able to process possibly time-varying visual inputs for variable-length prediction. These neural network architectures consist of combining a CNN for visual feature extraction followed by a RNN for sequence learning. Such architectures have been successfully used for video activity recognition, image captioning and video description.\nMore recently, interest has grown in properly fusing the CNN and RNN models for spatio-temporal sequence modeling. Inspired by language modeling, Ranzato et al. (2014) proposed a model to represent complex deformations and motion patterns by discovering both spatial and temporal correlations. They showed that prediction of the next video frame and interpolation of intermediate frames can be achieved by building a RNN-based language model on the visual words obtained by quantizing the image patches. Their highest-performing model, recursive CNN (rCNN), uses convolutions for both inputs and states. Shi et al. (2015) then proposed the convolutional LSTM network (convLSTM), a recurrent model for spatio-temporal sequence modeling which uses 2D-grid convolution to leverage the spatial correlations in input data. They successfully applied their model to the prediction of the evolution of radar echo maps for precipitation nowcasting.\nThe spatial structure of many important problems may however not be as simple as regular grids. For instance, the data measured from meteorological stations lie on a irregular grid, i.e. a network of heterogeneous spatial distribution of stations. More challenging, the spatial structure of data may not even be spatial, as it is the case for social or biological networks. Eventually, the interpretation that sentences can be regarded as random walks on vocabulary graphs, a view popularized by Mikolov et al. (2013), allows us to cast language analysis problems as graph-structured sequence models.\nThis work leverages on the recent models of Defferrard et al. (2016); Ranzato et al. (2014); Shi et al. (2015) to design the GCRN model for modeling and predicting time-varying graph-based data. The core idea is to merge CNN for graph-structured data and RNN to identify simultaneously meaningful spatial structures and dynamic patterns. A generic illustration of the proposed GCRN architecture is given by Figure 1."
    }, {
      "heading" : "2 PRELIMINARIES",
      "text" : ""
    }, {
      "heading" : "2.1 STRUCTURED SEQUENCE MODELING",
      "text" : "Sequence modeling is the problem of predicting the most likely future length-K sequence given the previous J observations:\nx̂t+1, . . . , x̂t+K = arg max xt+1,...,xt+K\nP (xt+1, . . . , xt+K |xt−J+1, . . . , xt), (1)\nwhere xt ∈ D is an observation at time t and D denotes the domain of the observed features. The archetypal application being the n-gram language model (with n = J + 1), where P (xt+1|xt−J+1, . . . , xt) models the probability of word xt+1 to appear conditioned on the past J words in the sentence (Graves, 2013).\nIn this paper, we are interested in special structured sequences, i.e. sequences where features of the observations xt are not independent but linked by pairwise relationships. Such relationships are universally modeled by weighted graphs.\nData xt can be viewed as a graph signal, i.e. a signal defined on an undirected and weighted graph G = (V, E , A), where V is a finite set of |V| = n vertices, E is a set of edges and A ∈ Rn×n is a weighted adjacency matrix encoding the connection weight between two vertices. A signal xt : V → Rdx defined on the nodes of the graph may be regarded as a matrix xt ∈ Rn×dx whose column i is the dx-dimensional value of xt at the ith node. While the number of free variables in a structured sequence of length K is in principle O(nKdxK), we seek to exploit the structure of the space of possible predictions to reduce the dimensionality and hence make those problems more tractable."
    }, {
      "heading" : "2.2 LONG SHORT-TERM MEMORY",
      "text" : "A special class of recurrent neural networks (RNN) that prevents the gradient from vanishing too quickly is the popular long short-term memory (LSTM) introduced by Hochreiter & Schmidhuber (1997). This architecture has proven stable and powerful for modeling long-range dependencies in various general-purpose sequence modeling tasks (Graves, 2013; Srivastava et al., 2015; Sutskever et al., 2014). A fully-connected LSTM (FC-LSTM) may be seen as a multivariate version of LSTM where the input xt ∈ Rdx , cell output ht ∈ [−1, 1]dh and states ct ∈ Rdh are all vectors. In this paper, we follow the FC-LSTM formulation of Graves (2013), that is:\ni = σ(Wxixt +Whiht−1 + wci ct−1 + bi), f = σ(Wxfxt +Whfht−1 + wcf ct−1 + bf ), ct = ft ct−1 + it tanh(Wxcxt +Whcht−1 + bc), o = σ(Wxoxt +Whoht−1 + wco ct + bo), ht = o tanh(ct),\n(2)\nwhere denotes the Hadamard product, σ(·) the sigmoid function σ(x) = 1/(1 + e−x) and i, f, o ∈ [0, 1]dh are the input, forget and output gates. The weights Wx· ∈ Rdh×dx , Wh· ∈ Rdh×dh , wc· ∈ Rdh and biases bi, bf , bc, bo ∈ Rdh are the model parameters.1 Such a model is called fullyconnected because the dense matricesWx· andWh· linearly combine all the components of x and h. The optional peephole connections wc· ct, introduced by Gers & Schmidhuber (2000), have been found to improve performance on certain tasks."
    }, {
      "heading" : "2.3 CONVOLUTIONAL NEURAL NETWORKS ON GRAPHS",
      "text" : "Generalizing convolutional neural networks (CNNs) to arbitrary graphs is a recent area of interest. Two approaches have been explored in the literature: (i) a generalization of the spatial definition of a convolution (Masci et al., 2015; Niepert et al., 2016) and (ii), a multiplication in the graph Fourier domain by the way of the convolution theorem (Bruna et al., 2014; Defferrard et al., 2016). Masci et al. (2015) introduced a spatial generalization of CNNs to 3D meshes. The authors used geodesic polar coordinates to define convolution operations on mesh patches, and formulated a deep learning architecture which allows comparison across different meshes. Hence, this method is tailored to manifolds and is not directly generalizable to arbitrary graphs. Niepert et al. (2016) proposed a spatial approach which may be decomposed in three steps: (i) select a node, (ii) construct its neighborhood and (iii) normalize the selected sub-graph, i.e. order the neighboring nodes. The extracted patches are then fed into a conventional 1D Euclidean CNN. As graphs generally do not possess a natural ordering (temporal, spatial or otherwise), a labeling procedure should be used to impose it. Bruna et al. (2014) were the first to introduce the spectral framework described below in the context of graph CNNs. The major drawback of this method is itsO(n2) complexity, which was overcome with the technique of Defferrard et al. (2016), which offers a linear complexity O(|E|) and provides strictly localized filters. Kipf & Welling (2016) took a first-order approximation of the spectral filters proposed by Defferrard et al. (2016) and successfully used it for semi-supervised classification of nodes. While we focus on the framework introduced by Defferrard et al. (2016), the proposed model is agnostic to the choice of the graph convolution operator ∗G . As it is difficult to express a meaningful translation operator in the vertex domain (Bruna et al., 2014; Niepert et al., 2016), Defferrard et al. (2016) chose a spectral formulation for the convolution operator on graph ∗G . By this definition, a graph signal x ∈ Rn×dx is filtered by a non-parametric kernel gθ(Λ) = diag(θ), where θ ∈ Rn is a vector of Fourier coefficients, as\ny = gθ ∗G x = gθ(L)x = gθ(UΛUT )x = Ugθ(Λ)UTx ∈ Rn×dx , (3)\nwhere U ∈ Rn×n is the matrix of eigenvectors and Λ ∈ Rn×n the diagonal matrix of eigenvalues of the normalized graph Laplacian L = In − D−1/2AD−1/2 = UΛUT ∈ Rn×n, where In is the identity matrix and D ∈ Rn×n is the diagonal degree matrix with Dii = ∑ j Aij (Chung, 1997). Note that the signal x is filtered by gθ with an element-wise multiplication of its graph Fourier transform UTx with gθ (Shuman et al., 2013). Evaluating (3) is however expensive, as the multiplication with U is O(n2). Furthermore, computing the eigendecomposition of L might\n1A practical trick is to initialize the biases bi, bf and bo to one such that the gates are initially open.\nbe prohibitively expensive for large graphs. To circumvent this problem, Defferrard et al. (2016) parametrizes gθ as a truncated expansion, up to order K − 1, of Chebyshev polynomials Tk such that\ngθ(Λ) = K−1∑ k=0 θkTk(Λ̃), (4)\nwhere the parameter θ ∈ RK is a vector of Chebyshev coefficients and Tk(Λ̃) ∈ Rn×n is the Chebyshev polynomial of order k evaluated at Λ̃ = 2Λ/λmax − In. The graph filtering operation can then be written as\ny = gθ ∗G x = gθ(L)x = K−1∑ k=0 θkTk(L̃)x, (5)\nwhere Tk(L̃) ∈ Rn×n is the Chebyshev polynomial of order k evaluated at the scaled Laplacian L̃ = 2L/λmax − In. Using the stable recurrence relation Tk(x) = 2xTk−1(x) − Tk−2(x) with T0 = 1 and T1 = x, one can evaluate (5) in O(K|E|) operations, i.e. linearly with the number of edges. Note that as the filtering operation (5) is an order K polynomial of the Laplacian, it is K-localized and depends only on nodes that are at maximum K hops away from the central node, the K-neighborhood. The reader is referred to Defferrard et al. (2016) for details and an in-depth discussion."
    }, {
      "heading" : "3 RELATED WORKS",
      "text" : "Shi et al. (2015) introduced a model for regular grid-structured sequences, which can be seen as a special case of the proposed model where the graph is an image grid where the nodes are well ordered. Their model is essentially the classical FC-LSTM (2) where the multiplications by dense matrices W have been replaced by convolutions with kernels W :\ni = σ(Wxi ∗ xt +Whi ∗ ht−1 + wci ct−1 + bi), f = σ(Wxf ∗ xt +Whf ∗ ht−1 + wcf ct−1 + bf ), ct = ft ct−1 + it tanh(Wxc ∗ xt +Whc ∗ ht−1 + bc), o = σ(Wxo ∗ xt +Who ∗ ht−1 + wco ct + bo), ht = o tanh(ct),\n(6)\nwhere ∗ denotes the 2D convolution by a set of kernels. In their setting, the input tensor xt ∈ Rnr×nc×dx is the observation of dx measurements at time t of a dynamical system over a spatial region represented by a grid of nr rows and nc columns. The model holds spatially distributed hidden and cell states of size dh given by the tensors ct, ht ∈ Rnr×nc×dh . The size m of the convolutional kernels Wh· ∈ Rm×m×dh×dh and Wx· ∈ Rm×m×dh×dx determines the number of parameters, which is independent of the grid size nr × nc. Earlier, Ranzato et al. (2014) proposed a similar RNN variation which uses convolutional layers instead of fully connected layers. The hidden state at time t is given by\nht = tanh(σ(Wx2 ∗ σ(Wx1 ∗ xt)) + σ(Wh ∗ ht−1)), (7) where the convolutional kernels Wh ∈ Rdh×dh are restricted to filters of size 1x1 (effectively a fully connected layer shared across all spatial locations).\nObserving that natural language exhibits syntactic properties that naturally combine words into phrases, Tai et al. (2015) proposed a model for tree-structured topologies, where each LSTM has access to the states of its children. They obtained state-of-the-art results on semantic relatedness and sentiment classification. Liang et al. (2016) followed up and proposed a variant on graphs. Their sophisticated network architecture obtained state-of-the-art results for semantic object parsing on four datasets. In those models, the states are gathered from the neighborhood by way of a weighted sum with trainable weight matrices. Those weights are however not shared across the graph, which would otherwise have required some ordering of the nodes, alike any other spatial definition of graph convolution. Moreover, their formulations are limited to the one-neighborhood of the current node, with equal weight given to each neighbor.\nMotivated by spatio-temporal problems like modeling human motion and object interactions, Jain et al. (2016) developed a method to cast a spatio-temporal graph as a rich RNN mixture which\nessentially associates a RNN to each node and edge. Again, the communication is limited to directly connected nodes and edges.\nThe closest model to our work is probably the one proposed by Li et al. (2015), which showed stat-of-the-art performance on a problem from program verification. Whereas they use the iterative procedure of the Graph Neural Networks (GNNs) model introduced by Scarselli et al. (2009) to propagate node representations until convergence, we instead use the graph CNN introduced by Defferrard et al. (2016) to diffuse information across the nodes. While their motivations are quite different, those models are related by the fact that a spectral filter defined as a polynomial of order K can be implemented as a K-layer GNN.2"
    }, {
      "heading" : "4 PROPOSED GCRN MODELS",
      "text" : "We propose two GCRN architectures that are quite natural, and investigate their performances in real-world applications in Section 5.\nModel 1. The most straightforward definition is to stack a graph CNN, defined as (5), for feature extraction and an LSTM, defined as (2), for sequence learning:\nxCNNt = CNNG(xt)\ni = σ(Wxix CNN t +Whiht−1 + wci ct−1 + bi),\nf = σ(Wxfx CNN t +Whfht−1 + wcf ct−1 + bf ), ct = ft ct−1 + it tanh(WxcxCNNt +Whcht−1 + bc), o = σ(Wxox CNN t +Whoht−1 + wco ct + bo),\nht = o tanh(ct).\n(8)\nIn that setting, the input matrix xt ∈ Rn×dx may represent the observation of dx measurements at time t of a dynamical system over a network whose organization is given by a graph G. xCNNt is the output of the graph CNN gate. For a proof of concept, we simply choose here xCNNt = W\nCNN ∗G xt, where WCNN ∈ RK×dx×dx are the Chebyshev coefficients for the graph convolutional kernels of support K. The model also holds spatially distributed hidden and cell states of size dh given by the matrices ct, ht ∈ Rn×dh . Peepholes are controlled by wc· ∈ Rn×dh . The weights Wh· ∈ Rdh×dh and Wx· ∈ Rdh×dx are the parameters of the fully connected layers. An architecture such as (8) may be enough to capture the data distribution by exploiting local stationarity and compositionality properties as well as the dynamic properties.\nModel 2. To generalize the convLSTM model (6) to graphs we replace the Euclidean 2D convolution ∗ by the graph convolution ∗G :\ni = σ(Wxi ∗G xt +Whi ∗G ht−1 + wci ct−1 + bi), f = σ(Wxf ∗G xt +Whf ∗G ht−1 + wcf ct−1 + bf ), ct = ft ct−1 + it tanh(Wxc ∗G xt +Whc ∗G ht−1 + bc), o = σ(Wxo ∗G xt +Who ∗G ht−1 + wco ct + bo), ht = o tanh(ct).\n(9)\nIn that setting, the support K of the graph convolutional kernels defined by the Chebyshev coefficients Wh· ∈ RK×dh×dh and Wx· ∈ RK×dh×dx determines the number of parameters, which is independent of the number of nodes n. To keep the notation simple, we write Wxi ∗G xt to mean a graph convolution of xt with dhdx filters which are functions of the graph Laplacian L parametrized by K Chebyshev coefficients, as noted in (4) and (5). In a distributed computing setting, K controls the communication overhead, i.e. the number of nodes any given node i should exchange with in order to compute its local states.\nThe proposed blend of RNNs and graph CNNs is not limited to LSTMs and is straightforward to apply to any kind of recursive networks. For example, a vanilla RNN ht = tanh(Wxxt +Whht−1)\n2The basic idea is to set the transition function as a diffusion and the output function such as to realize the polynomial recurrence, then stack K of those. See Defferrard et al. (2016) for details.\nwould be modified as ht = tanh(Wx ∗G xt +Wh ∗G ht−1), (10)\nand a Gated Recurrent Unit (GRU) (Cho et al., 2014) as\nz = σ(Wxz ∗G xt +Whz ∗G ht−1), r = σ(Wxr ∗G xt +Whr ∗G ht−1), h̃ = tanh(Wxh ∗G xt +Whh ∗G (r ht−1)), ht = z ht−1 + (1− z) h̃.\n(11)\nAs demonstrated by Shi et al. (2015), structure-aware LSTM cells can be stacked and used as sequence-to-sequence models using an architecture composed of an encoder, which processes the input sequence, and a decoder, which generates an output sequence. A standard practice for machine translation using RNNs (Cho et al., 2014; Sutskever et al., 2014)."
    }, {
      "heading" : "5 EXPERIMENTS",
      "text" : ""
    }, {
      "heading" : "5.1 SPATIO-TEMPORAL SEQUENCE MODELING ON MOVING-MNIST",
      "text" : "For this synthetic experiment, we use the moving-MNIST dataset generated by Shi et al. (2015). All sequences are 20 frames long (10 frames as input and 10 frames for prediction) and contain two handwritten digits bouncing inside a 64 × 64 patch. Following their experimental setup, all models are trained by minimizing the binary cross-entropy loss using back-propagation through time (BPTT) and RMSProp with a learning rate of 10−3 and a decay rate of 0.9. We choose the best model with early-stopping on validation set. All implementations are based on their Theano code and dataset.3 The adjacency matrix A is constructed as a k-nearest-neighbor (knn) graph with Euclidean distance and Gaussian kernel between pixel locations. For a fair comparison with Shi et al. (2015) defined in (6), all GCRN experiments are conducted with Model 2 defined in (9), which is the same architecture with the 2D convolution ∗ replaced by a graph convolution ∗G . To further explore the impact of the isotropic property of our filters, we generated a variant of the moving MNIST dataset where digits are also rotating (see Figure 4).\nTable 1 shows the performance of various models: (i) the baseline FC-LSTM from Shi et al. (2015), (ii) the 1-layer LSTM+CNN from Shi et al. (2015) with different filter sizes, and (iii) the proposed LSTM+graph CNN(GCNN) defined in (9) with different supports K. These results show the ability of the proposed method to capture spatio-temporal structures. Perhaps surprisingly, GCNNs can offer better performance than regular CNNs, even when the domain is a 2D grid and the data is images, the problem CNNs were initially developed for. The explanation is to be found in the differences between 2D filters and spectral graph filters. While a spectral filter of support K = 3 corresponds to the reach of a patch of size 5×5 (see Figure 2), the difference resides in the isotropic nature of the former and the number of parameters: K = 3 for the former and 52 = 25 for the later.\n3http://www.wanghao.in/code/SPARNN-release.zip\nTable 1 indeed shows that LSTM+CNN(5 × 5) rivals LSTM+GCNN with K = 3. However, when increasing the filter size to 9× 9 or K = 5, the GCNN variant clearly outperforms the CNN variant. This experiment demonstrates that graph spectral filters can obtain superior performance on regular domains with much less parameters thanks to their isotropic nature, a controversial property. Indeed, as the nodes are not ordered, there is no notion of an edge going up, down, on the right or on the left. All edges are treated equally, inducing some sort of rotation invariance. Additionally, Table 1 shows that the computational complexity of each model is linear with the filter size, and Figure 3 shows the learning dynamic of some of the models."
    }, {
      "heading" : "5.2 NATURAL LANGUAGE MODELING ON PENN TREEBANK",
      "text" : "The Penn Treebank dataset has 1,036,580 words. It was pre-processed in Zaremba et al. (2014) and split4 into a training set of 929k words, a validation set of 73k words, and a test set of 82k words. The size of the vocabulary of this corpus is 10,000. We use the gensim library5 to compute a word2vec model (Mikolov et al., 2013) for embedding the words of the dictionary in a 200-dimensional space. Then we build the adjacency matrix of the word embedding using a 4-nearest neighbor graph with cosine distance. Figure 6 presents the computed adjacency matrix, and its 3D visualization. We used the hyperparameters of the small configuration given by the code6 based on Zaremba et al. (2014): the size of the data mini-batch is 20, the number of temporal steps to unroll is 20, the dimension of the hidden state is 200. The global learning rate is 1.0 and the norm of the gradient is bounded by 5. The learning decay function is selected to be 0.5max(0,#epoch−4). All experiments have 13 epochs, and dropout value is 0.75. For Zaremba et al. (2014), the input representation xt can be either the 200-dim embedding vector of the word, or the 10,000-dim one-hot representation of the word. For\n4https://github.com/wojzaremba/lstm 5https://radimrehurek.com/gensim/models/word2vec.html\nour models, the input representation is a one-hot representation of the word. This choice allows us to use the graph structure of the words.\nTable 2 reports the final train and test perplexity values for each investigated model and Figure 5 plots the perplexity value vs. the number of epochs for the train and test sets with and without dropout regularization. Numerical experiments show:\n1. Given the same experimental conditions in terms of architecture and no dropout regularization, the standalone model of LSTM is more accurate than LSTM using the spatial graph information (120.16 vs. 177.14), extracted by graph CNN with the GCRN architecture of Model 1, Eq. (8).\n2. However, using dropout regularization, the graph LSTM model overcomes the standalone LSTM with perplexity values 98.67 vs. 112.98.\n3. The use of spatial graph information found by graph CNN speeds up the learning process, and overfits the training dataset in the absence of dropout regularization. The graph structure likely acts a constraint on the learning system that is forced to move in the space of language topics.\n4. We performed the same experiments with LSTM and Model 2 defined in (9). Model 1 significantly outperformed Model 2, and Model 2 did worse than standalone LSTM. This bad performance may be the result of the large increase of dimensionality in Model 2, as the dimension of the hidden and cell states changes from 200 to 10,000, the size of the vocabulary. A solution would be to downsize the data dimensionality, as done in Shi et al. (2015) in the case of image data.\n6https://github.com/tensorflow/tensorflow/blob/master/tensorflow/ models/rnn/ptb/ptb_word_lm.py"
    }, {
      "heading" : "6 CONCLUSION AND FUTURE WORK",
      "text" : "This work aims at learning spatio-temporal structures from graph-structured and time-varying data. In this context, the main challenge is to identify the best possible architecture that combines simultaneously recurrent neural networks like vanilla RNN, LSTM or GRU with convolutional neural networks for graph-structured data. We have investigated here two architectures, one using a stack of CNN and RNN (Model 1), and one using convLSTM that considers convolutions instead of fully connected operations in the RNN definition (Model 2). We have then considered two applications: video prediction and natural language modeling. Model 2 has shown good performances in the case of video prediction, by improving the results of Shi et al. (2015). Model 1 has also provided promising performances in the case of language modeling, particularly in terms of learning speed. It has been shown that (i) isotropic filters, maybe surprisingly, can outperform classical 2D filters on images while requiring much less parameters, and (ii) that graphs coupled with graph CNN and RNN are a versatile way of introducing and exploiting side-information, e.g. the semantic of words, by structuring a data matrix.\nFuture work will investigate applications to data naturally structured as dynamic graph signals, for instance fMRI and sensor networks. The graph CNN model we have used is rotationally-invariant and such spatial property seems quite attractive in real situations where motion is beyond translation. We will also investigate how to benefit of the fast learning property of our system to speed up language modeling models. Eventually, it will be interesting to analyze the underlying dynamical property of generic RNN architectures in the case of graphs. Graph structures may introduce stability to RNN systems, and prevent them to express unstable dynamic behaviors."
    }, {
      "heading" : "ACKNOWLEDGMENT",
      "text" : "This research was supported in part by the European Union’s H2020 Framework Programme (H2020-MSCA-ITN-2014) under grant No. 642685 MacSeNet, and Nvidia equipment grant."
    } ],
    "references" : [ {
      "title" : "Long-term recurrent convolutional networks for visual recognition and description",
      "author" : [ "Jeffrey Donahue", "Lisa Anne Hendricks", "Sergio Guadarrama", "Marcus Rohrbach", "Subhashini Venugopalan", "Kate Saenko", "Trevor Darrell" ],
      "venue" : "In IEEE Conference on Computer Vision and Pattern Recognition (CVPR),",
      "citeRegEx" : "Donahue et al\\.,? \\Q2015\\E",
      "shortCiteRegEx" : "Donahue et al\\.",
      "year" : 2015
    }, {
      "title" : "Recurrent nets that time and count",
      "author" : [ "Felix A Gers", "Jürgen Schmidhuber" ],
      "venue" : "In IEEE-INNS-ENNS International Joint Conference on Neural Networks,",
      "citeRegEx" : "Gers and Schmidhuber.,? \\Q2000\\E",
      "shortCiteRegEx" : "Gers and Schmidhuber.",
      "year" : 2000
    }, {
      "title" : "Generating sequences with recurrent neural networks",
      "author" : [ "Alex Graves" ],
      "venue" : null,
      "citeRegEx" : "Graves.,? \\Q2013\\E",
      "shortCiteRegEx" : "Graves.",
      "year" : 2013
    }, {
      "title" : "Long short-term memory",
      "author" : [ "Sepp Hochreiter", "Jürgen Schmidhuber" ],
      "venue" : "Neural computation,",
      "citeRegEx" : "Hochreiter and Schmidhuber.,? \\Q1997\\E",
      "shortCiteRegEx" : "Hochreiter and Schmidhuber.",
      "year" : 1997
    }, {
      "title" : "Structural-RNN: Deep Learning on SpatioTemporal Graphs",
      "author" : [ "Ashesh Jain", "Amir R. Zamir", "Silvio Savarese", "Ashutosh Saxena" ],
      "venue" : "In IEEE Conference on Computer Vision and Pattern Recognition",
      "citeRegEx" : "Jain et al\\.,? \\Q2016\\E",
      "shortCiteRegEx" : "Jain et al\\.",
      "year" : 2016
    }, {
      "title" : "Deep visual-semantic alignments for generating image descriptions",
      "author" : [ "Andrej Karpathy", "Li Fei-Fei" ],
      "venue" : "In IEEE Conference on Computer Vision and Pattern Recognition (CVPR),",
      "citeRegEx" : "Karpathy and Fei.Fei.,? \\Q2015\\E",
      "shortCiteRegEx" : "Karpathy and Fei.Fei.",
      "year" : 2015
    }, {
      "title" : "Semi-Supervised Classification with Graph",
      "author" : [ "Thomas N. Kipf", "Max Welling" ],
      "venue" : "Convolutional Networks",
      "citeRegEx" : "Kipf and Welling.,? \\Q2016\\E",
      "shortCiteRegEx" : "Kipf and Welling.",
      "year" : 2016
    }, {
      "title" : "Gated graph sequence neural networks",
      "author" : [ "Yujia Li", "Daniel Tarlow", "Marc Brockschmidt", "Richard Zemel" ],
      "venue" : "arXiv preprint arXiv:1511.05493,",
      "citeRegEx" : "Li et al\\.,? \\Q2015\\E",
      "shortCiteRegEx" : "Li et al\\.",
      "year" : 2015
    }, {
      "title" : "Semantic object parsing with graph lstm",
      "author" : [ "Xiaodan Liang", "Xiaohui Shen", "Jiashi Feng", "Liang Lin", "Shuicheng Yan" ],
      "venue" : null,
      "citeRegEx" : "Liang et al\\.,? \\Q2016\\E",
      "shortCiteRegEx" : "Liang et al\\.",
      "year" : 2016
    }, {
      "title" : "Geodesic convolutional neural networks on riemannian manifolds",
      "author" : [ "Jonathan Masci", "Davide Boscaini", "Michael M. Bronstein", "Pierre Vandergheynst" ],
      "venue" : "In IEEE International Conference on Computer Vision (ICCV) Workshops,",
      "citeRegEx" : "Masci et al\\.,? \\Q2015\\E",
      "shortCiteRegEx" : "Masci et al\\.",
      "year" : 2015
    }, {
      "title" : "Estimation of Word Representations in Vector Space",
      "author" : [ "T. Mikolov", "K. Chen", "G. Corrado", "J. Dean" ],
      "venue" : "In International Conference on Learning Representations (ICLR),",
      "citeRegEx" : "Mikolov et al\\.,? \\Q2013\\E",
      "shortCiteRegEx" : "Mikolov et al\\.",
      "year" : 2013
    }, {
      "title" : "Learning Convolutional Neural Networks for Graphs",
      "author" : [ "Mathias Niepert", "Mohamed Ahmed", "Konstantin Kutzkov" ],
      "venue" : "In International Conference on Machine Learning (ICML),",
      "citeRegEx" : "Niepert et al\\.,? \\Q2016\\E",
      "shortCiteRegEx" : "Niepert et al\\.",
      "year" : 2016
    }, {
      "title" : "Video (language) modeling: a baseline for generative models of natural videos",
      "author" : [ "MarcAurelio Ranzato", "Arthur Szlam", "Joan Bruna", "Michael Mathieu", "Ronan Collobert", "Sumit Chopra" ],
      "venue" : null,
      "citeRegEx" : "Ranzato et al\\.,? \\Q2014\\E",
      "shortCiteRegEx" : "Ranzato et al\\.",
      "year" : 2014
    }, {
      "title" : "The graph neural network model",
      "author" : [ "Franco Scarselli", "Marco Gori", "Ah Chung Tsoi", "Markus Hagenbuchner", "Gabriele Monfardini" ],
      "venue" : "IEEE Transactions on Neural Networks,",
      "citeRegEx" : "Scarselli et al\\.,? \\Q2009\\E",
      "shortCiteRegEx" : "Scarselli et al\\.",
      "year" : 2009
    }, {
      "title" : "Convolutional LSTM Network: A Machine Learning Approach for Precipitation Nowcasting",
      "author" : [ "Xingjian Shi", "Zhourong Chen", "Hao Wang", "Dit-Yan Yeung", "Wai-kin Wong", "Wang-chun Woo" ],
      "venue" : "In Advances in Neural Information Processing Systems (NIPS),",
      "citeRegEx" : "Shi et al\\.,? \\Q2015\\E",
      "shortCiteRegEx" : "Shi et al\\.",
      "year" : 2015
    }, {
      "title" : "The Emerging Field of Signal Processing on Graphs: Extending High-Dimensional Data Analysis to Networks and other Irregular Domains",
      "author" : [ "D. Shuman", "S. Narang", "P. Frossard", "A. Ortega", "P. Vandergheynst" ],
      "venue" : "IEEE Signal Processing Magazine,",
      "citeRegEx" : "Shuman et al\\.,? \\Q2013\\E",
      "shortCiteRegEx" : "Shuman et al\\.",
      "year" : 2013
    }, {
      "title" : "Unsupervised learning of video representations using lstms",
      "author" : [ "Nitish Srivastava", "Elman Mansimov", "Ruslan Salakhudinov" ],
      "venue" : "In International Conference on Machine Learning (ICML),",
      "citeRegEx" : "Srivastava et al\\.,? \\Q2015\\E",
      "shortCiteRegEx" : "Srivastava et al\\.",
      "year" : 2015
    }, {
      "title" : "Sequence to sequence learning with neural networks. In Advances in neural information processing systems",
      "author" : [ "Ilya Sutskever", "Oriol Vinyals", "Quoc V Le" ],
      "venue" : null,
      "citeRegEx" : "Sutskever et al\\.,? \\Q2014\\E",
      "shortCiteRegEx" : "Sutskever et al\\.",
      "year" : 2014
    }, {
      "title" : "Improved semantic representations from treestructured long short-term memory networks",
      "author" : [ "Kai Sheng Tai", "Richard Socher", "Christopher D. Manning" ],
      "venue" : "In Association for Computational Linguistics (ACL),",
      "citeRegEx" : "Tai et al\\.,? \\Q2015\\E",
      "shortCiteRegEx" : "Tai et al\\.",
      "year" : 2015
    }, {
      "title" : "Show and tell: A neural image caption generator",
      "author" : [ "Oriol Vinyals", "Alexander Toshev", "Samy Bengio", "Dumitru Erhan" ],
      "venue" : "In IEEE Conference on Computer Vision and Pattern Recognition (CVPR),",
      "citeRegEx" : "Vinyals et al\\.,? \\Q2015\\E",
      "shortCiteRegEx" : "Vinyals et al\\.",
      "year" : 2015
    }, {
      "title" : "Recurrent neural network regularization",
      "author" : [ "Wojciech Zaremba", "Ilya Sutskever", "Oriol Vinyals" ],
      "venue" : null,
      "citeRegEx" : "Zaremba et al\\.,? \\Q2014\\E",
      "shortCiteRegEx" : "Zaremba et al\\.",
      "year" : 2014
    } ],
    "referenceMentions" : [ {
      "referenceID" : 0,
      "context" : "Many works, such as Donahue et al. (2015); Karpathy & FeiFei (2015); Vinyals et al.",
      "startOffset" : 20,
      "endOffset" : 42
    }, {
      "referenceID" : 0,
      "context" : "Many works, such as Donahue et al. (2015); Karpathy & FeiFei (2015); Vinyals et al.",
      "startOffset" : 20,
      "endOffset" : 68
    }, {
      "referenceID" : 0,
      "context" : "Many works, such as Donahue et al. (2015); Karpathy & FeiFei (2015); Vinyals et al. (2015), leveraged a combination of CNN and RNN to exploit such spatial and temporal regularities.",
      "startOffset" : 20,
      "endOffset" : 91
    }, {
      "referenceID" : 0,
      "context" : "Many works, such as Donahue et al. (2015); Karpathy & FeiFei (2015); Vinyals et al. (2015), leveraged a combination of CNN and RNN to exploit such spatial and temporal regularities. Their models are able to process possibly time-varying visual inputs for variable-length prediction. These neural network architectures consist of combining a CNN for visual feature extraction followed by a RNN for sequence learning. Such architectures have been successfully used for video activity recognition, image captioning and video description. More recently, interest has grown in properly fusing the CNN and RNN models for spatio-temporal sequence modeling. Inspired by language modeling, Ranzato et al. (2014) proposed a model to represent complex deformations and motion patterns by discovering both spatial and temporal correlations.",
      "startOffset" : 20,
      "endOffset" : 703
    }, {
      "referenceID" : 0,
      "context" : "Many works, such as Donahue et al. (2015); Karpathy & FeiFei (2015); Vinyals et al. (2015), leveraged a combination of CNN and RNN to exploit such spatial and temporal regularities. Their models are able to process possibly time-varying visual inputs for variable-length prediction. These neural network architectures consist of combining a CNN for visual feature extraction followed by a RNN for sequence learning. Such architectures have been successfully used for video activity recognition, image captioning and video description. More recently, interest has grown in properly fusing the CNN and RNN models for spatio-temporal sequence modeling. Inspired by language modeling, Ranzato et al. (2014) proposed a model to represent complex deformations and motion patterns by discovering both spatial and temporal correlations. They showed that prediction of the next video frame and interpolation of intermediate frames can be achieved by building a RNN-based language model on the visual words obtained by quantizing the image patches. Their highest-performing model, recursive CNN (rCNN), uses convolutions for both inputs and states. Shi et al. (2015) then proposed the convolutional LSTM network (convLSTM), a recurrent model for spatio-temporal sequence modeling which uses 2D-grid convolution to leverage the spatial correlations in input data.",
      "startOffset" : 20,
      "endOffset" : 1157
    }, {
      "referenceID" : 0,
      "context" : "Many works, such as Donahue et al. (2015); Karpathy & FeiFei (2015); Vinyals et al. (2015), leveraged a combination of CNN and RNN to exploit such spatial and temporal regularities. Their models are able to process possibly time-varying visual inputs for variable-length prediction. These neural network architectures consist of combining a CNN for visual feature extraction followed by a RNN for sequence learning. Such architectures have been successfully used for video activity recognition, image captioning and video description. More recently, interest has grown in properly fusing the CNN and RNN models for spatio-temporal sequence modeling. Inspired by language modeling, Ranzato et al. (2014) proposed a model to represent complex deformations and motion patterns by discovering both spatial and temporal correlations. They showed that prediction of the next video frame and interpolation of intermediate frames can be achieved by building a RNN-based language model on the visual words obtained by quantizing the image patches. Their highest-performing model, recursive CNN (rCNN), uses convolutions for both inputs and states. Shi et al. (2015) then proposed the convolutional LSTM network (convLSTM), a recurrent model for spatio-temporal sequence modeling which uses 2D-grid convolution to leverage the spatial correlations in input data. They successfully applied their model to the prediction of the evolution of radar echo maps for precipitation nowcasting. The spatial structure of many important problems may however not be as simple as regular grids. For instance, the data measured from meteorological stations lie on a irregular grid, i.e. a network of heterogeneous spatial distribution of stations. More challenging, the spatial structure of data may not even be spatial, as it is the case for social or biological networks. Eventually, the interpretation that sentences can be regarded as random walks on vocabulary graphs, a view popularized by Mikolov et al. (2013), allows us to cast language analysis problems as graph-structured sequence models.",
      "startOffset" : 20,
      "endOffset" : 1993
    }, {
      "referenceID" : 12,
      "context" : "(2016); Ranzato et al. (2014); Shi et al.",
      "startOffset" : 8,
      "endOffset" : 30
    }, {
      "referenceID" : 12,
      "context" : "(2016); Ranzato et al. (2014); Shi et al. (2015) to design the GCRN model for modeling and predicting time-varying graph-based data.",
      "startOffset" : 8,
      "endOffset" : 49
    }, {
      "referenceID" : 2,
      "context" : ", xt) models the probability of word xt+1 to appear conditioned on the past J words in the sentence (Graves, 2013).",
      "startOffset" : 100,
      "endOffset" : 114
    }, {
      "referenceID" : 2,
      "context" : "This architecture has proven stable and powerful for modeling long-range dependencies in various general-purpose sequence modeling tasks (Graves, 2013; Srivastava et al., 2015; Sutskever et al., 2014).",
      "startOffset" : 137,
      "endOffset" : 200
    }, {
      "referenceID" : 16,
      "context" : "This architecture has proven stable and powerful for modeling long-range dependencies in various general-purpose sequence modeling tasks (Graves, 2013; Srivastava et al., 2015; Sutskever et al., 2014).",
      "startOffset" : 137,
      "endOffset" : 200
    }, {
      "referenceID" : 17,
      "context" : "This architecture has proven stable and powerful for modeling long-range dependencies in various general-purpose sequence modeling tasks (Graves, 2013; Srivastava et al., 2015; Sutskever et al., 2014).",
      "startOffset" : 137,
      "endOffset" : 200
    }, {
      "referenceID" : 2,
      "context" : "This architecture has proven stable and powerful for modeling long-range dependencies in various general-purpose sequence modeling tasks (Graves, 2013; Srivastava et al., 2015; Sutskever et al., 2014). A fully-connected LSTM (FC-LSTM) may be seen as a multivariate version of LSTM where the input xt ∈ Rx , cell output ht ∈ [−1, 1]h and states ct ∈ Rh are all vectors. In this paper, we follow the FC-LSTM formulation of Graves (2013), that is: i = σ(Wxixt +Whiht−1 + wci ct−1 + bi), f = σ(Wxfxt +Whfht−1 + wcf ct−1 + bf ), ct = ft ct−1 + it tanh(Wxcxt +Whcht−1 + bc), o = σ(Wxoxt +Whoht−1 + wco ct + bo), ht = o tanh(ct), (2)",
      "startOffset" : 138,
      "endOffset" : 435
    }, {
      "referenceID" : 9,
      "context" : "Two approaches have been explored in the literature: (i) a generalization of the spatial definition of a convolution (Masci et al., 2015; Niepert et al., 2016) and (ii), a multiplication in the graph Fourier domain by the way of the convolution theorem (Bruna et al.",
      "startOffset" : 117,
      "endOffset" : 159
    }, {
      "referenceID" : 11,
      "context" : "Two approaches have been explored in the literature: (i) a generalization of the spatial definition of a convolution (Masci et al., 2015; Niepert et al., 2016) and (ii), a multiplication in the graph Fourier domain by the way of the convolution theorem (Bruna et al.",
      "startOffset" : 117,
      "endOffset" : 159
    }, {
      "referenceID" : 11,
      "context" : "As it is difficult to express a meaningful translation operator in the vertex domain (Bruna et al., 2014; Niepert et al., 2016), Defferrard et al.",
      "startOffset" : 85,
      "endOffset" : 127
    }, {
      "referenceID" : 15,
      "context" : "Note that the signal x is filtered by gθ with an element-wise multiplication of its graph Fourier transform Ux with gθ (Shuman et al., 2013).",
      "startOffset" : 119,
      "endOffset" : 140
    }, {
      "referenceID" : 9,
      "context" : "Two approaches have been explored in the literature: (i) a generalization of the spatial definition of a convolution (Masci et al., 2015; Niepert et al., 2016) and (ii), a multiplication in the graph Fourier domain by the way of the convolution theorem (Bruna et al., 2014; Defferrard et al., 2016). Masci et al. (2015) introduced a spatial generalization of CNNs to 3D meshes.",
      "startOffset" : 118,
      "endOffset" : 320
    }, {
      "referenceID" : 9,
      "context" : "Two approaches have been explored in the literature: (i) a generalization of the spatial definition of a convolution (Masci et al., 2015; Niepert et al., 2016) and (ii), a multiplication in the graph Fourier domain by the way of the convolution theorem (Bruna et al., 2014; Defferrard et al., 2016). Masci et al. (2015) introduced a spatial generalization of CNNs to 3D meshes. The authors used geodesic polar coordinates to define convolution operations on mesh patches, and formulated a deep learning architecture which allows comparison across different meshes. Hence, this method is tailored to manifolds and is not directly generalizable to arbitrary graphs. Niepert et al. (2016) proposed a spatial approach which may be decomposed in three steps: (i) select a node, (ii) construct its neighborhood and (iii) normalize the selected sub-graph, i.",
      "startOffset" : 118,
      "endOffset" : 686
    }, {
      "referenceID" : 9,
      "context" : "Two approaches have been explored in the literature: (i) a generalization of the spatial definition of a convolution (Masci et al., 2015; Niepert et al., 2016) and (ii), a multiplication in the graph Fourier domain by the way of the convolution theorem (Bruna et al., 2014; Defferrard et al., 2016). Masci et al. (2015) introduced a spatial generalization of CNNs to 3D meshes. The authors used geodesic polar coordinates to define convolution operations on mesh patches, and formulated a deep learning architecture which allows comparison across different meshes. Hence, this method is tailored to manifolds and is not directly generalizable to arbitrary graphs. Niepert et al. (2016) proposed a spatial approach which may be decomposed in three steps: (i) select a node, (ii) construct its neighborhood and (iii) normalize the selected sub-graph, i.e. order the neighboring nodes. The extracted patches are then fed into a conventional 1D Euclidean CNN. As graphs generally do not possess a natural ordering (temporal, spatial or otherwise), a labeling procedure should be used to impose it. Bruna et al. (2014) were the first to introduce the spectral framework described below in the context of graph CNNs.",
      "startOffset" : 118,
      "endOffset" : 1114
    }, {
      "referenceID" : 9,
      "context" : "Two approaches have been explored in the literature: (i) a generalization of the spatial definition of a convolution (Masci et al., 2015; Niepert et al., 2016) and (ii), a multiplication in the graph Fourier domain by the way of the convolution theorem (Bruna et al., 2014; Defferrard et al., 2016). Masci et al. (2015) introduced a spatial generalization of CNNs to 3D meshes. The authors used geodesic polar coordinates to define convolution operations on mesh patches, and formulated a deep learning architecture which allows comparison across different meshes. Hence, this method is tailored to manifolds and is not directly generalizable to arbitrary graphs. Niepert et al. (2016) proposed a spatial approach which may be decomposed in three steps: (i) select a node, (ii) construct its neighborhood and (iii) normalize the selected sub-graph, i.e. order the neighboring nodes. The extracted patches are then fed into a conventional 1D Euclidean CNN. As graphs generally do not possess a natural ordering (temporal, spatial or otherwise), a labeling procedure should be used to impose it. Bruna et al. (2014) were the first to introduce the spectral framework described below in the context of graph CNNs. The major drawback of this method is itsO(n) complexity, which was overcome with the technique of Defferrard et al. (2016), which offers a linear complexity O(|E|) and provides strictly localized filters.",
      "startOffset" : 118,
      "endOffset" : 1334
    }, {
      "referenceID" : 9,
      "context" : "Two approaches have been explored in the literature: (i) a generalization of the spatial definition of a convolution (Masci et al., 2015; Niepert et al., 2016) and (ii), a multiplication in the graph Fourier domain by the way of the convolution theorem (Bruna et al., 2014; Defferrard et al., 2016). Masci et al. (2015) introduced a spatial generalization of CNNs to 3D meshes. The authors used geodesic polar coordinates to define convolution operations on mesh patches, and formulated a deep learning architecture which allows comparison across different meshes. Hence, this method is tailored to manifolds and is not directly generalizable to arbitrary graphs. Niepert et al. (2016) proposed a spatial approach which may be decomposed in three steps: (i) select a node, (ii) construct its neighborhood and (iii) normalize the selected sub-graph, i.e. order the neighboring nodes. The extracted patches are then fed into a conventional 1D Euclidean CNN. As graphs generally do not possess a natural ordering (temporal, spatial or otherwise), a labeling procedure should be used to impose it. Bruna et al. (2014) were the first to introduce the spectral framework described below in the context of graph CNNs. The major drawback of this method is itsO(n) complexity, which was overcome with the technique of Defferrard et al. (2016), which offers a linear complexity O(|E|) and provides strictly localized filters. Kipf & Welling (2016) took a first-order approximation of the spectral filters proposed by Defferrard et al.",
      "startOffset" : 118,
      "endOffset" : 1438
    }, {
      "referenceID" : 9,
      "context" : "Two approaches have been explored in the literature: (i) a generalization of the spatial definition of a convolution (Masci et al., 2015; Niepert et al., 2016) and (ii), a multiplication in the graph Fourier domain by the way of the convolution theorem (Bruna et al., 2014; Defferrard et al., 2016). Masci et al. (2015) introduced a spatial generalization of CNNs to 3D meshes. The authors used geodesic polar coordinates to define convolution operations on mesh patches, and formulated a deep learning architecture which allows comparison across different meshes. Hence, this method is tailored to manifolds and is not directly generalizable to arbitrary graphs. Niepert et al. (2016) proposed a spatial approach which may be decomposed in three steps: (i) select a node, (ii) construct its neighborhood and (iii) normalize the selected sub-graph, i.e. order the neighboring nodes. The extracted patches are then fed into a conventional 1D Euclidean CNN. As graphs generally do not possess a natural ordering (temporal, spatial or otherwise), a labeling procedure should be used to impose it. Bruna et al. (2014) were the first to introduce the spectral framework described below in the context of graph CNNs. The major drawback of this method is itsO(n) complexity, which was overcome with the technique of Defferrard et al. (2016), which offers a linear complexity O(|E|) and provides strictly localized filters. Kipf & Welling (2016) took a first-order approximation of the spectral filters proposed by Defferrard et al. (2016) and successfully used it for semi-supervised classification of nodes.",
      "startOffset" : 118,
      "endOffset" : 1532
    }, {
      "referenceID" : 9,
      "context" : "Two approaches have been explored in the literature: (i) a generalization of the spatial definition of a convolution (Masci et al., 2015; Niepert et al., 2016) and (ii), a multiplication in the graph Fourier domain by the way of the convolution theorem (Bruna et al., 2014; Defferrard et al., 2016). Masci et al. (2015) introduced a spatial generalization of CNNs to 3D meshes. The authors used geodesic polar coordinates to define convolution operations on mesh patches, and formulated a deep learning architecture which allows comparison across different meshes. Hence, this method is tailored to manifolds and is not directly generalizable to arbitrary graphs. Niepert et al. (2016) proposed a spatial approach which may be decomposed in three steps: (i) select a node, (ii) construct its neighborhood and (iii) normalize the selected sub-graph, i.e. order the neighboring nodes. The extracted patches are then fed into a conventional 1D Euclidean CNN. As graphs generally do not possess a natural ordering (temporal, spatial or otherwise), a labeling procedure should be used to impose it. Bruna et al. (2014) were the first to introduce the spectral framework described below in the context of graph CNNs. The major drawback of this method is itsO(n) complexity, which was overcome with the technique of Defferrard et al. (2016), which offers a linear complexity O(|E|) and provides strictly localized filters. Kipf & Welling (2016) took a first-order approximation of the spectral filters proposed by Defferrard et al. (2016) and successfully used it for semi-supervised classification of nodes. While we focus on the framework introduced by Defferrard et al. (2016), the proposed model is agnostic to the choice of the graph convolution operator ∗G .",
      "startOffset" : 118,
      "endOffset" : 1673
    }, {
      "referenceID" : 9,
      "context" : "Two approaches have been explored in the literature: (i) a generalization of the spatial definition of a convolution (Masci et al., 2015; Niepert et al., 2016) and (ii), a multiplication in the graph Fourier domain by the way of the convolution theorem (Bruna et al., 2014; Defferrard et al., 2016). Masci et al. (2015) introduced a spatial generalization of CNNs to 3D meshes. The authors used geodesic polar coordinates to define convolution operations on mesh patches, and formulated a deep learning architecture which allows comparison across different meshes. Hence, this method is tailored to manifolds and is not directly generalizable to arbitrary graphs. Niepert et al. (2016) proposed a spatial approach which may be decomposed in three steps: (i) select a node, (ii) construct its neighborhood and (iii) normalize the selected sub-graph, i.e. order the neighboring nodes. The extracted patches are then fed into a conventional 1D Euclidean CNN. As graphs generally do not possess a natural ordering (temporal, spatial or otherwise), a labeling procedure should be used to impose it. Bruna et al. (2014) were the first to introduce the spectral framework described below in the context of graph CNNs. The major drawback of this method is itsO(n) complexity, which was overcome with the technique of Defferrard et al. (2016), which offers a linear complexity O(|E|) and provides strictly localized filters. Kipf & Welling (2016) took a first-order approximation of the spectral filters proposed by Defferrard et al. (2016) and successfully used it for semi-supervised classification of nodes. While we focus on the framework introduced by Defferrard et al. (2016), the proposed model is agnostic to the choice of the graph convolution operator ∗G . As it is difficult to express a meaningful translation operator in the vertex domain (Bruna et al., 2014; Niepert et al., 2016), Defferrard et al. (2016) chose a spectral formulation for the convolution operator on graph ∗G .",
      "startOffset" : 118,
      "endOffset" : 1912
    }, {
      "referenceID" : 10,
      "context" : "Earlier, Ranzato et al. (2014) proposed a similar RNN variation which uses convolutional layers instead of fully connected layers.",
      "startOffset" : 9,
      "endOffset" : 31
    }, {
      "referenceID" : 10,
      "context" : "Earlier, Ranzato et al. (2014) proposed a similar RNN variation which uses convolutional layers instead of fully connected layers. The hidden state at time t is given by ht = tanh(σ(Wx2 ∗ σ(Wx1 ∗ xt)) + σ(Wh ∗ ht−1)), (7) where the convolutional kernels Wh ∈ Rdh×dh are restricted to filters of size 1x1 (effectively a fully connected layer shared across all spatial locations). Observing that natural language exhibits syntactic properties that naturally combine words into phrases, Tai et al. (2015) proposed a model for tree-structured topologies, where each LSTM has access to the states of its children.",
      "startOffset" : 9,
      "endOffset" : 502
    }, {
      "referenceID" : 7,
      "context" : "Liang et al. (2016) followed up and proposed a variant on graphs.",
      "startOffset" : 0,
      "endOffset" : 20
    }, {
      "referenceID" : 4,
      "context" : "Motivated by spatio-temporal problems like modeling human motion and object interactions, Jain et al. (2016) developed a method to cast a spatio-temporal graph as a rich RNN mixture which",
      "startOffset" : 90,
      "endOffset" : 109
    }, {
      "referenceID" : 7,
      "context" : "The closest model to our work is probably the one proposed by Li et al. (2015), which showed stat-of-the-art performance on a problem from program verification.",
      "startOffset" : 62,
      "endOffset" : 79
    }, {
      "referenceID" : 7,
      "context" : "The closest model to our work is probably the one proposed by Li et al. (2015), which showed stat-of-the-art performance on a problem from program verification. Whereas they use the iterative procedure of the Graph Neural Networks (GNNs) model introduced by Scarselli et al. (2009) to propagate node representations until convergence, we instead use the graph CNN introduced by Defferrard et al.",
      "startOffset" : 62,
      "endOffset" : 282
    }, {
      "referenceID" : 7,
      "context" : "The closest model to our work is probably the one proposed by Li et al. (2015), which showed stat-of-the-art performance on a problem from program verification. Whereas they use the iterative procedure of the Graph Neural Networks (GNNs) model introduced by Scarselli et al. (2009) to propagate node representations until convergence, we instead use the graph CNN introduced by Defferrard et al. (2016) to diffuse information across the nodes.",
      "startOffset" : 62,
      "endOffset" : 403
    }, {
      "referenceID" : 14,
      "context" : "Cross-entropy of FC-LSTM is taken from Shi et al. (2015).",
      "startOffset" : 39,
      "endOffset" : 57
    }, {
      "referenceID" : 17,
      "context" : "A standard practice for machine translation using RNNs (Cho et al., 2014; Sutskever et al., 2014).",
      "startOffset" : 55,
      "endOffset" : 97
    }, {
      "referenceID" : 14,
      "context" : "As demonstrated by Shi et al. (2015), structure-aware LSTM cells can be stacked and used as sequence-to-sequence models using an architecture composed of an encoder, which processes the input sequence, and a decoder, which generates an output sequence.",
      "startOffset" : 19,
      "endOffset" : 37
    }, {
      "referenceID" : 14,
      "context" : "For this synthetic experiment, we use the moving-MNIST dataset generated by Shi et al. (2015). All sequences are 20 frames long (10 frames as input and 10 frames for prediction) and contain two handwritten digits bouncing inside a 64 × 64 patch.",
      "startOffset" : 76,
      "endOffset" : 94
    }, {
      "referenceID" : 14,
      "context" : "For this synthetic experiment, we use the moving-MNIST dataset generated by Shi et al. (2015). All sequences are 20 frames long (10 frames as input and 10 frames for prediction) and contain two handwritten digits bouncing inside a 64 × 64 patch. Following their experimental setup, all models are trained by minimizing the binary cross-entropy loss using back-propagation through time (BPTT) and RMSProp with a learning rate of 10−3 and a decay rate of 0.9. We choose the best model with early-stopping on validation set. All implementations are based on their Theano code and dataset.3 The adjacency matrix A is constructed as a k-nearest-neighbor (knn) graph with Euclidean distance and Gaussian kernel between pixel locations. For a fair comparison with Shi et al. (2015) defined in (6), all GCRN experiments are conducted with Model 2 defined in (9), which is the same architecture with the 2D convolution ∗ replaced by a graph convolution ∗G .",
      "startOffset" : 76,
      "endOffset" : 775
    }, {
      "referenceID" : 14,
      "context" : "For this synthetic experiment, we use the moving-MNIST dataset generated by Shi et al. (2015). All sequences are 20 frames long (10 frames as input and 10 frames for prediction) and contain two handwritten digits bouncing inside a 64 × 64 patch. Following their experimental setup, all models are trained by minimizing the binary cross-entropy loss using back-propagation through time (BPTT) and RMSProp with a learning rate of 10−3 and a decay rate of 0.9. We choose the best model with early-stopping on validation set. All implementations are based on their Theano code and dataset.3 The adjacency matrix A is constructed as a k-nearest-neighbor (knn) graph with Euclidean distance and Gaussian kernel between pixel locations. For a fair comparison with Shi et al. (2015) defined in (6), all GCRN experiments are conducted with Model 2 defined in (9), which is the same architecture with the 2D convolution ∗ replaced by a graph convolution ∗G . To further explore the impact of the isotropic property of our filters, we generated a variant of the moving MNIST dataset where digits are also rotating (see Figure 4). Table 1 shows the performance of various models: (i) the baseline FC-LSTM from Shi et al. (2015), (ii) the 1-layer LSTM+CNN from Shi et al.",
      "startOffset" : 76,
      "endOffset" : 1216
    }, {
      "referenceID" : 14,
      "context" : "For this synthetic experiment, we use the moving-MNIST dataset generated by Shi et al. (2015). All sequences are 20 frames long (10 frames as input and 10 frames for prediction) and contain two handwritten digits bouncing inside a 64 × 64 patch. Following their experimental setup, all models are trained by minimizing the binary cross-entropy loss using back-propagation through time (BPTT) and RMSProp with a learning rate of 10−3 and a decay rate of 0.9. We choose the best model with early-stopping on validation set. All implementations are based on their Theano code and dataset.3 The adjacency matrix A is constructed as a k-nearest-neighbor (knn) graph with Euclidean distance and Gaussian kernel between pixel locations. For a fair comparison with Shi et al. (2015) defined in (6), all GCRN experiments are conducted with Model 2 defined in (9), which is the same architecture with the 2D convolution ∗ replaced by a graph convolution ∗G . To further explore the impact of the isotropic property of our filters, we generated a variant of the moving MNIST dataset where digits are also rotating (see Figure 4). Table 1 shows the performance of various models: (i) the baseline FC-LSTM from Shi et al. (2015), (ii) the 1-layer LSTM+CNN from Shi et al. (2015) with different filter sizes, and (iii) the proposed LSTM+graph CNN(GCNN) defined in (9) with different supports K.",
      "startOffset" : 76,
      "endOffset" : 1266
    }, {
      "referenceID" : 10,
      "context" : "We use the gensim library5 to compute a word2vec model (Mikolov et al., 2013) for embedding the words of the dictionary in a 200-dimensional space.",
      "startOffset" : 55,
      "endOffset" : 77
    }, {
      "referenceID" : 19,
      "context" : "It was pre-processed in Zaremba et al. (2014) and split4 into a training set of 929k words, a validation set of 73k words, and a test set of 82k words.",
      "startOffset" : 24,
      "endOffset" : 46
    }, {
      "referenceID" : 10,
      "context" : "We use the gensim library5 to compute a word2vec model (Mikolov et al., 2013) for embedding the words of the dictionary in a 200-dimensional space. Then we build the adjacency matrix of the word embedding using a 4-nearest neighbor graph with cosine distance. Figure 6 presents the computed adjacency matrix, and its 3D visualization. We used the hyperparameters of the small configuration given by the code6 based on Zaremba et al. (2014): the size of the data mini-batch is 20, the number of temporal steps to unroll is 20, the dimension of the hidden state is 200.",
      "startOffset" : 56,
      "endOffset" : 440
    }, {
      "referenceID" : 10,
      "context" : "We use the gensim library5 to compute a word2vec model (Mikolov et al., 2013) for embedding the words of the dictionary in a 200-dimensional space. Then we build the adjacency matrix of the word embedding using a 4-nearest neighbor graph with cosine distance. Figure 6 presents the computed adjacency matrix, and its 3D visualization. We used the hyperparameters of the small configuration given by the code6 based on Zaremba et al. (2014): the size of the data mini-batch is 20, the number of temporal steps to unroll is 20, the dimension of the hidden state is 200. The global learning rate is 1.0 and the norm of the gradient is bounded by 5. The learning decay function is selected to be 0.5max(0,#epoch−4). All experiments have 13 epochs, and dropout value is 0.75. For Zaremba et al. (2014), the input representation xt can be either the 200-dim embedding vector of the word, or the 10,000-dim one-hot representation of the word.",
      "startOffset" : 56,
      "endOffset" : 797
    }, {
      "referenceID" : 20,
      "context" : "Architecture Representation Parameters Train Perplexity Test Perplexity Zaremba et al. (2014) code embedding 681,800 36.",
      "startOffset" : 72,
      "endOffset" : 94
    }, {
      "referenceID" : 20,
      "context" : "Architecture Representation Parameters Train Perplexity Test Perplexity Zaremba et al. (2014) code embedding 681,800 36.96 117.29 Zaremba et al. (2014) code one-hot 34,011,600 53.",
      "startOffset" : 72,
      "endOffset" : 152
    }, {
      "referenceID" : 20,
      "context" : "Zaremba et al. (2014) code is ran as benchmark algorithm.",
      "startOffset" : 0,
      "endOffset" : 22
    }, {
      "referenceID" : 20,
      "context" : "Zaremba et al. (2014) code is ran as benchmark algorithm. The original Zaremba et al. (2014) code used as input representation for xt the 200-dim embedding representation of words, computed here by the gensim library.",
      "startOffset" : 0,
      "endOffset" : 93
    }, {
      "referenceID" : 20,
      "context" : "Zaremba et al. (2014) code is ran as benchmark algorithm. The original Zaremba et al. (2014) code used as input representation for xt the 200-dim embedding representation of words, computed here by the gensim library. As our model runs on the 10,000-dim one-hot representation of words, we also ran Zaremba et al. (2014) code on this representation.",
      "startOffset" : 0,
      "endOffset" : 321
    }, {
      "referenceID" : 20,
      "context" : "Zaremba et al. (2014) code is ran as benchmark algorithm. The original Zaremba et al. (2014) code used as input representation for xt the 200-dim embedding representation of words, computed here by the gensim library. As our model runs on the 10,000-dim one-hot representation of words, we also ran Zaremba et al. (2014) code on this representation. We re-implemented Zaremba et al. (2014) code with the same architecture and hyperparameters.",
      "startOffset" : 0,
      "endOffset" : 390
    }, {
      "referenceID" : 14,
      "context" : "A solution would be to downsize the data dimensionality, as done in Shi et al. (2015) in the case of image data.",
      "startOffset" : 68,
      "endOffset" : 86
    }, {
      "referenceID" : 14,
      "context" : "Model 2 has shown good performances in the case of video prediction, by improving the results of Shi et al. (2015). Model 1 has also provided promising performances in the case of language modeling, particularly in terms of learning speed.",
      "startOffset" : 97,
      "endOffset" : 115
    } ],
    "year" : 2016,
    "abstractText" : "This paper introduces Graph Convolutional Recurrent Network (GCRN), a deep learning model able to predict structured sequences of data. Precisely, GCRN is a generalization of classical recurrent neural networks (RNN) to data structured by an arbitrary graph. Such structured sequences can represent series of frames in videos, spatio-temporal measurements on a network of sensors, or random walks on a vocabulary graph for natural language modeling. The proposed model combines convolutional neural networks (CNN) on graphs to identify spatial structures and RNN to find dynamic patterns. We study two possible architectures of GCRN, and apply the models to two practical problems: predicting moving MNIST data, and modeling natural language with the Penn Treebank dataset. Experiments show that exploiting simultaneously graph spatial and dynamic information about data can improve both precision and learning speed.",
    "creator" : "LaTeX with hyperref package"
  }
}