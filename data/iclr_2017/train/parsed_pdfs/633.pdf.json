{
  "name" : "633.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : null,
    "authors" : [ "Jianwen Xie", "Yang Lu", "Ruiqi Gao", "Song-Chun Zhu", "Ying Nian Wu" ],
    "emails" : [ "ruiqigao}@ucla.edu,", "ywu}@stat.ucla.edu" ],
    "sections" : [ {
      "heading" : "1 INTRODUCTION",
      "text" : ""
    }, {
      "heading" : "1.1 TWO CONVNETS OF OPPOSITE DIRECTIONS",
      "text" : "We begin with a story that the reader of this paper can readily relate to. A student writes up an initial draft of a paper. His advisor then revises it. After that they submit the revised paper for review. The student then learns from his advisor’s revision, while the advisor learns from the outside review. In this story, the advisor guides the student, but the student does most of the work.\nThis paper is about two probabilistic models of signals such as images, and they play the roles of student and advisor as described above. Both models are parametrized by convolutional neural networks (ConvNets or CNNs) (LeCun et al., 1998; Krizhevsky et al., 2012). The two nets take two opposite directions. One is bottom-up, and the other is top-down, as illustrate by the following diagram:\nBottom-up ConvNet Top-down ConvNet features latent variables ⇑ ⇓\nsignal signal (a) Descriptor Net (b) Generator Net\n(1)\nThe simultaneous training of such two nets was first studied by the recent work of Kim & Bengio (2016). These two nets belong to two major classes of probabilistic models. (a) The exponential family models or the energy-based models (LeCun et al., 2006) or the Markov random field models (Zhu et al., 1997), where the probability distribution is defined by feature statistics or energy function computed from the signal by a bottom-up process. (b) The latent variable models or the directed graphical models, where the signal is assumed to be a transformation of the latent factors that follow a known prior distribution. The latent factors generate the signal by a top-down process. A classical example is factor analysis.\nThe two classes of models have been contrasted by Zhu (2003); Teh et al. (2003); Ngiam et al. (2011). Zhu (2003) called the two classes of models the descriptive models and the generative\nmodels respectively. Both classes of models can benefit from the high capacity of the multi-layer ConvNets. (a) In the exponential family models or the energy-based models, the feature statistics or the energy function can be defined by a bottom-up ConvNet that maps the signal to the features and the energy function (Ngiam et al., 2011; Xie et al., 2016). We call the resulting model a descriptive network or a descriptor net following Zhu (2003), because it is built on descriptive feature statistics. (b) In the latent variable models or the directed graphical models, the transformation from the latent factors to the signal can be defined by a top-down ConvNet (Dosovitskiy et al., 2015), which maps the latent factors to the signal. We call the resulting model a generative network or generator net following Goodfellow et al. (2014), who proposed such a model in their work on the generative adversarial networks (GAN)."
    }, {
      "heading" : "1.2 TWO TRAINING ALGORITHMS AND THEIR COOPERATION",
      "text" : "Fig. 1(a) and (b) display the flowcharts of the maximum likelihood learning algorithms for training the descriptor and generator nets . We call the two algorithms Algorithm D and Algorithm G respectively. Algorithm D (Xie et al., 2016) iterates two steps: Step D1 synthesizes examples by sampling from the current model by Langevin dynamics. Step D2 updates the parameters to shift the density from the synthesized examples towards the observed examples. Algorithm G (Han et al., 2017) also iterates two steps. Step G1 infers latent factors for each observed example by sampling from their posterior distribution by Langevin dynamics. Step G2 updates the parameters by a non-linear regression of the observed examples on their corresponding latent factors. We use Langevin dynamics for Markov chain Monte Carlo (MCMC) sampling because the gradient term of Langevin dynamics can be readily computed via back-propagation. Thus all the steps D1, D2 and G1, G2 are powered by back-propagation, and both Algorithms D and G are alternating back-propagation algorithms.\nIn this article, we propose to couple Algorithms D and G into a cooperative training algorithm that interweaves the steps of the two algorithms seamlessly. We call the resulting algorithm the CoopNets algorithm, and we show that it can train both nets simultaneously.\nFigure 1(c) displays the flowchart of the CoopNets algorithm. The generator is like the student. It generates the initial draft of the synthesized examples. The descriptor is like the advisor. It revises the initial draft by initializing its Langevin dynamics from the initial draft in Step D1, which produces the revised draft of the synthesized examples. The descriptor learns from the outside review in Step D2, which is in the form of the difference between the observed examples and the revised\nsynthesized examples. The generator learns from how the descriptor revises the initial draft by reconstructing the revised draft in Step G2. For each synthesized example, the generator knows the latent factors that generate the initial draft, so that Step G1 can infer the latent factors by initializing its Langevin dynamics from their known values.\nIn the CoopNets algorithm, the generator fuels the MCMC of the descriptor by supplying initial synthesized examples, which can be obtained by direct ancestral sampling. The generator then learns from the revised synthesized examples with virtually known latent factors. The cooperation is thus beneficial to both nets."
    }, {
      "heading" : "2 RELATED WORK",
      "text" : "Our work is inspired by the generative adversarial networks (GAN) (Goodfellow et al., 2014; Denton et al., 2015; Radford et al., 2015). In GAN, the generator net is paired with a discriminator net. The two nets play adversarial roles. In our work, the generator net and the descriptor net play cooperative roles, and they feed each other the initial, revised and reconstructed synthesized data. The learning of both nets is based on maximum likelihood, and the learning process is quite stable because of the cooperative nature and the consistent directions of the two maximum likelihood training algorithms.\nAnother method to train the generator network is variational auto-encoder (VAE) (Kingma & Welling, 2014; Rezende et al., 2014; Mnih & Gregor, 2014), which learns an inferential or recognition network to approximate the posterior distribution of the latent factors.\nThe connection between the descriptor net and the discriminator net has been explored by Xie et al. (2016), where the descriptor can be derived from the discriminator.\nOur work is most similar to the recent work of Kim & Bengio (2016). In fact, the settings of the two nets are the same. In their work, the generator learns from the descriptor by minimizing the Kullback-Leibler divergence from the generator to the descriptor, which can be decomposed into an energy term and an entropy term. In our work, the two nets interact with each other via synthesized data, and the generator learns from the descriptor by reconstructing the revised draft of synthesized examples. Our method does not need to approximate the intractable entropy term.\nOur work is related to the contrastive divergence algorithm (Hinton, 2002) for training the descriptor net. The contrastive divergence initializes the MCMC sampling from the observed examples. The CoopNets algorithm initializes the MCMC sampling from the examples supplied by the generator."
    }, {
      "heading" : "3 TWO NETS AND TWO TRAINING ALGORITHMS",
      "text" : ""
    }, {
      "heading" : "3.1 DESCRIPTOR NET AND TRAINING ALGORITHM",
      "text" : "Let Y be the D-dimensional signal, such as an image. The descriptor model is in the form of exponential tilting of a reference distribution (Xie et al., 2016):\nPD(Y ;WD) = 1\nZ(WD) exp [f(Y ;WD)] q(Y ), (2)\nwhere q(Y ) is the reference distribution such as Gaussian white noise q(Y ) ∝ exp ( −‖Y ‖2/2s2 ) ,\nf(Y ;WD) (f stands for features) is the feature statistics or energy function, defined by a ConvNet whose parameters are denoted by WD. This ConvNet is bottom-up because it maps the signal Y to a number. See the diagram in (1). Z(WD) = ∫ exp [f(Y ;WD)] q(Y )dY = Eq{exp[f(Y ;WD)]} is the normalizing constant, where Eq is the expectation with respect to q.\nSuppose we observe training examples {Yi, i = 1, ..., n} from an unknown data distribution Pdata(Y ). The maximum likelihood training seeks to maximize the log-likelihood function LD(WD) = 1 n ∑n i=1 logPD(Yi;WD). If the sample size n is large, the maximum likelihood estimator minimizes KL(Pdata|PD), the Kullback-Leibler divergence from the data distribution Pdata to the model distribution PD. The gradient of the LD(WD) is\nL′D(WD) = 1\nn n∑ i=1 ∂ ∂WD f(Yi;WD)− EWD [ ∂ ∂WD f(Y ;WD) ] , (3)\nwhere EWD denotes the expectation with respect to PD(Y ;WD).\nThe expectation in equation (3) is analytically intractable and has to be approximated by MCMC, such as Langevin dynamics, which iterates the following step:\nYτ+1 = Yτ − δ2\n2 [ Yτ s2 − ∂ ∂Y f(Yτ ;WD) ] + δUτ , (4)\nwhere τ indexes the time steps of the Langevin dynamics, δ is the step size, and Uτ ∼ N(0, ID) is the Gaussian white noise term.\nWe can run ñ parallel chains of Langevin dynamics according to (4) to obtain the synthesized examples {Ỹi, i = 1, ..., ñ}. The Monte Carlo approximation to L′D(WD) is\nL′D(WD) ≈ 1\nn n∑ i=1 ∂ ∂WD f(Yi;WD)− 1 ñ ñ∑ i=1 ∂ ∂WD f(Ỹi;WD), (5)\nwhich is used to update WD.\nAlgorithm D (Xie et al., 2016) iterates the following two steps after initializing WD and {Ỹi, i = 1, ..., ñ}. Step D1: Run lD steps of Langevin from the current {Ỹ } according according to (4). Step D2: update W (t+1)D = W (t) D + γtL ′ D(W (t) D ) with learning rate γt. The convergence of such an algorithm follows Younes (1999)."
    }, {
      "heading" : "3.2 GENERATOR NET AND TRAINING ALGORITHM",
      "text" : "The generator net (Goodfellow et al., 2014) seeks to explain the signal Y of dimensionD by a vector of latent factors X of dimension d, and usually d D. The model is of the following form:\nX ∼ N(0, Id), Y = g(X;WG) + , ∼ N(0, σ2ID). (6) g(X;WG) (g stands for generator) is a top-down ConvNet defined by the parameters WG . The ConvNet g maps the latent factors X to the signal Y . See the diagram in (1).\nThe joint density of model (6) is PG(X,Y ;WG) = PG(X)PG(Y |X;WG), and\nlogPG(X,Y ;WG) = − 1\n2σ2 ‖Y − g(X;WG)‖2 −\n1 2 ‖X‖2 + constant, (7)\nwhere the constant term is independent of X , Y and WG . The marginal density is obtained by integrating out the latent factors X , i.e., PG(Y ;WG) = ∫ PG(X,Y ;WG)dX . The inference of X given Y is based on the posterior density PG(X|Y ;WG) = PG(X,Y ;WG)/PG(Y ;WG) ∝ PG(X,Y ;WG) as a function of X .\nFor the training data {Yi, i = 1, ..., n}, the generator net can be trained by maximizing the loglikelihood LG(WG) = 1n ∑n i=1 logPG(Yi;WG). For large sample, the learned WG minimizes the Kullback-Leibler divergence KL(Pdata|PG) from the data distribution Pdata to the model distribution PG . The gradient of LG(WG) is obtained according to the following identity\n∂\n∂WG logPG(Y ;WG) =\n1\nPG(Y ;WG)\n∂\n∂WG\n∫ PG(Y,X;WG)dX\n= 1\nPG(Y ;WG)\n∫ [ ∂\n∂WG logPG(Y,X;WG)\n] PG(Y,X;WG)dX\n=\n∫ [ ∂\n∂WG logPG(Y,X;WG)\n] PG(Y,X;WG)\nPG(Y ;WG) dX\n= EPG(X|Y ;WG)\n[ ∂\n∂WG logPG(X,Y ;WG)\n] , (8)\nwhich underlies the EM algorithm. In general, the expectation in (8) is analytically intractable, and has to be approximated by MCMC that samples from the posterior PG(X|Y ;WG), such as Langevin dynamics, which iterates\nXτ+1 = Xτ + δ2\n2\n∂\n∂X logPG(Xτ , Y ;WG) + δUτ , (9)\nwhere Uτ ∼ N(0, Id). With Xi sampled from PG(Xi | Yi,WG) for each observation Yi, the Monte Carlo approximation to L′G(WG) is\nL′G(WG) ≈ 1\nn n∑ i=1 ∂ ∂WG logPG(Xi, Yi;WG) = 1 n n∑ i=1 1 σ2 (Yi − g(Xi;WG)) ∂ ∂WG g(Xi;WG). (10)\nAlgorithm G (Han et al., 2017) iterates the following two steps after initializing WG and {Xi, i = 1, ..., n}. Step G1: run lG steps of Langevin from the current {Xi} according to (9). Step G2: update W\n(t+1) G =W (t) G +γtL ′ G(W (t) G ) with learning rate γt. The convergence of such an algorithm follows\nYounes (1999)."
    }, {
      "heading" : "4 COOPNETS ALGORITHM: RECONSTRUCTING THE REVISION",
      "text" : "In Algorithms D and G, both steps D1 and G1 are Langevin dynamics, which may be slow to converge. An interesting observation is that the two algorithms can cooperate with each other by jumpstarting each other’s Langevin sampling.\nSpecifically, in Step D1, we can initialize the synthesized examples by generating examples from the generator net. We first generate X̂i ∼ N(0, Id), and then generate Ŷi = g(X̂i;WG) + i, for i = 1, ..., ñ. If the current generator PG is close to the current descriptor PD, then the generated {Ŷi} should be a good initialization for sampling from the descriptor net, i.e., starting from the {Ŷi, i = 1, ..., ñ}, we run Langevin dynamics in Step D1 for lD steps to get {Ỹi, i = 1, ..., ñ}, which are revised versions of {Ŷi}. These {Ỹi} can be used as the synthesized examples from the descriptor net. We can then update WD according to Step D2 of Algorithm D.\nIn order to update WG of the generator net, we treat the {Ỹi, i = 1, ..., ñ} produced by the above Step D1 as the training data for the generator. Since these {Ỹi} are obtained by the Langevin dynamics initialized from the {Ŷi, i = 1, ..., ñ} produced by the generator net with known latent factors {X̂i, i = 1, ..., ñ}, we can update WG by learning from {(Ỹi, X̂i), i = 1, ..., ñ}, which is a supervised learning problem, or more specifically, a non-linear regression of Ỹi on X̂i. At W (t) G , the latent factors X̂i generates and thus reconstructs the initial example Ŷi. After updating WG , we want X̂i to reconstruct the revised example Ỹi. That is, we revise WG to absorb the revision from Ŷi to Ỹi, so that the generator shifts its density from {Ŷi} to {Ỹi}. The reconstruction error can tell us whether the generator has caught up with the descriptor by fully absorbing the revision.\nThe left diagram in (11) illustrates the basic idea.\nX̂i\nŶi Ỹi\nW (t) G W (t+1) G\nW (t) D\nX̂i Xi\nŶi Ỹi\nW (t) G\nW (t) G W (t+1) G\nW (t) D (11)\nIn the two diagrams in (11), the double-line arrows indicate generation and reconstruction by the generator net, while the dashed-line arrows indicate Langevin dynamics for revision and inference in the two nets. The diagram on the right in (11) illustrates a more rigorous method, where we initialize the Langevin inference of {Xi, i = 1, ..., ñ} in Step G1 from {X̂i}, and then update WG in Step G2 based on {(Ỹi, Xi), i = 1, ..., ñ}. The diagram on the right shows how the two nets jumpstart each other’s Langevin dynamics.\nAlgorithm 1 describes the cooperative training that interweaves Algorithm D and Algorithm G. See Figure 1(c) for the flowchart of the CoopNets algorithm. In our experiments, we set lG = 0 and infer Xi = X̂i for simplicity, i.e., we follow the left diagram in (11).\nSee Appendix for a theoretical understanding of the convergence of the CoopNets algorithm.\nAlgorithm 1 CoopNets Algorithm Input:\n(1) training examples {Yi, i = 1, ..., n} (2) numbers of Langevin steps lD ad lG (3) number of learning iterations T\nOutput: (1) estimated parameters WD and WG (2) synthesized examples {Ŷi, Ỹi, i = 1, ..., ñ}\n1: Let t← 0, initialize WD and WG . 2: repeat 3: Step G0: For i = 1, ..., ñ, generate X̂i ∼ N(0, Id), and generate Ŷi = g(X̂i;W (t)G ) + i. 4: Step D1: For i = 1, ..., ñ, starting from Ŷi, Run lD steps of Langevin dynamics to obtain Ỹi, each step following equation (4). 5: Step G1: Treat the current {Ỹi, i = 1, ..., ñ} as the training data, for each i, infer Xi = X̂i.\nOr more rigorously, starting from Xi = X̂i, run lG steps of Langevin dynamics to update Xi, each step following equation (9).\n6: Step D2: Update W (t+1)D = W (t) D + γtL ′ D(W (t) D ), where L ′ D(W (t) D ) is computed according to (5). 7: Step G2: Update W (t+1)G = W (t) G + γtLG ′(W (t) G ), where LG\n′(WG) is computed according to (10), except that Yi is replaced by Ỹi, and n by ñ.\n8: Let t← t+ 1 9: until t = T"
    }, {
      "heading" : "5 EXPERIMENTS",
      "text" : "We use the MatConvNet of Vedaldi & Lenc (2015) for coding. For the descriptor net, we adopt the structure of Xie et al. (2016), where the bottom-up network consists of multiple layers of convolution by linear filtering, ReLU non-linearity, and down-sampling. We adopt the structure of the generator network of Radford et al. (2015); Dosovitskiy et al. (2015), where the top-down network consists of multiple layers of deconvolution by linear superposition, ReLU non-linearity, and up-sampling, with tanh non-linearity at the bottom-layer (Radford et al., 2015) to make the signals fall within [−1, 1]."
    }, {
      "heading" : "5.1 QUANTITATIVE EXPERIMENT ON FACE COMPLETION",
      "text" : "We conduct an experiment on learning from complete training images of human faces, and then testing the learned model on completing the occluded testing images. The structure of the generator network is the same as in (Radford et al., 2015; Dosovitskiy et al., 2015). We adopt a 4-layer descriptor net. The first layer has 96 5 × 5 filters with sub-sampling of 2, the second layers has 128 5 × 5 filters with sub-sampling of 2, the third layer has 256 5 × 5 filters with sub-sampling of 2, and the final layer is a fully connected layer with 50 channels as output. We use L=10 steps of Langevin revision dynamics within each learning iteration, and the Langevin step size is set at 0.002. The learning rate is 0.07. The training data are 10, 000 human faces randomly selected from CelebA dataset (Liu et al., 2015). We run 600 cooperative learning iterations. Figure 2 displays 144 synthesized human faces by the descriptor net.\nTo quantitatively test whether we have learned a good generator net g(X;WG) even though it has never seen the training images directly in the training stage, we apply it to the task of recovering the occluded pixels of testing images. For each occluded testing image Y , we use Step G1 of Algorithm G to infer the latent factors X . The only change is with respect to the term ‖Y − g(X;WG)‖2, where the sum of squares is over all the observed pixels of Y in back-propagation computation. We run 1000 Langevin steps, initializing X from N(0, Id). After inferring X , the completed image g(X;WG) is automatically obtained. We design 3 experiments, where we randomly place a 20×20, 30 × 30, or 40 × 40 mask on each 64 × 64 testing image. These 3 experiments are denoted by M20 M30, and M40 respectively (M for mask). We report the recovery errors and compare our method with 8 different image inpainting methods as well as the DCGAN of Radford et al. (2015).\nFor DCGAN, we use the parameter setting in Radford et al. (2015) except changing the number of learning iterations to 600. We use the same 10, 000 training images to learn DCGAN. After the model is learned, we keep the generator and use the same method as ours to infer latent factors X , and recover the unobserved pixels. In 8 inpainting methods, Methods 1 and 2 are based on Markov random field prior where the nearest neighbor potential terms are `2 and `1 differences respectively. Methods 3 to 8 are interpolation methods. Please refer to D’Errico (2004) for more details. Table 1 displays the recovery errors of the 3 experiments, where the error is measured by per pixel difference (relative to the range of pixel values) between the original image and the recovered image on the occluded region, averaged over 100 testing images. Fig. 3 displays some recovery results by our method. The first row shows the original images as the ground truth. The second row displays the testing images with occluded pixels. The third row displays the recovered images by the generator net trained by the CoopNets algorithm on the 10,000 training images."
    }, {
      "heading" : "5.2 QUALITATIVE EXPERIMENT ON SYNTHESIS",
      "text" : "We conduct an experiment on synthesizing images of categories from Imagenet ILSVRC2012 dataset (Deng et al., 2009) and MIT places205 dataset (Zhou et al., 2014). We adopt a 4-layer descriptor net. The first layer has 64 5 × 5 filters with sub-sampling of 2, the second layers has 128 3 × 3 filters with sub-sampling of 2, the third layer has 256 3 × 3 filters with sub-sampling of 1, and the final layer is a fully connected layer with 100 channels as output. We set the number of Langevin dynamics steps in each learning iteration to 10 and the step size to 0.002. The learning rate is 0.07. For each category, we randomly choose 1,000 images as training data and resize the images to 64× 64. We run 1, 000 cooperative learning iterations to train the model. Figures 4 and 5 display the results for two categories, where for each category, we show 144 original images sampled from the training set, and 144 synthesized images generated by our method. The appendix contains more synthesis results.\nAs a comparison, we apply the Algorithm G alone and GAN code on the same 1,000 hotel room training images to learn the generator of the same structure as in CoopNets. Figure 6 displays the synthesis results.\nWe also try to synthesize images at high resolution (224× 224). We adopt a 4-layer descriptor net. The first layer has 128 15× 15 filters with sub-sampling of 3, the second layer has 256 3× 3 filters with sub-sampling of 2, the third layer has 512 3 × 3 filters with sub-sampling of 1, and the final layer is a fully connected layer with 100 channels as output. We enlarge the filters of the final layer of generator net to 14 × 14 to generate 224 × 224 images. The learning rate is 0.05. We run 1000 cooperative learning iterations to train the model. Figures 7 and 8 show the synthesized images of two categories from MIT places205 dataset."
    }, {
      "heading" : "6 CONCLUSION",
      "text" : "The most unique feature of our work is that the two networks feed each other the synthesized data in the learning process, including initial, revised, and reconstructed synthesized data.\nAnother unique feature of our work is that the learning process interweaves the existing maximum likelihood learning algorithms for the two networks.\nA third unique feature of our work is that the MCMC for the descriptor keeps rejuvenating the chains by refreshing the samples by independent replacements supplied by the generator, so that a single chain effectively amounts to an infinite number of chains or the evolution of the whole marginal distribution modeled by the generator.\nCODE AND DATA\nhttp://www.stat.ucla.edu/˜ywu/CoopNets/main.html"
    }, {
      "heading" : "7 APPENDIX: CONVERGENCE",
      "text" : ""
    }, {
      "heading" : "7.1 GENERATOR OF INFINITE CAPACITY",
      "text" : "In the CoopNets algorithm, the descriptor learns from the observed examples, while the generator learns from the descriptor through the synthesized examples. Therefore, the descriptor is the driving force in terms of learning, although the generator is the driving force in terms of synthesis. In order to understand the convergence of learning, we can start from Algorithm D for learning the descriptor.\nAlgorithm D is a stochastic approximation algorithm (Robbins & Monro, 1951), except that the samples are generated by finite step MCMC transitions. According to Younes (1999), Algorithm D converges to the maximum likelihood estimate under suitable regularity conditions on the mixing of the transition kernel of the MCMC and the schedule of the learning rate γt, even if the number of Langevin steps lD is finite or small (e.g., lD = 1), and even if the number of parallel chains ñ is finite or small (e.g., ñ = 1). The reason is that the random fluctuations caused by the finite number of chains, ñ, and the limited mixing caused by the finite steps of MCMC, lD, are mitigated if the\nlearning rate γt is sufficiently small. At learning iteration t, let W (t) D be the estimated parameter of the descriptor. Let P (t+1)D be the marginal distribution of {Ỹi}. Even though P (t+1) D 6= PD(Y ;W (t) D ) because lD is finite (P (t+1) D = PD(Y ;W (t) D ) if lD → ∞), we still have W (t) D → ŴD in probability according to Younes (1999), where ŴD is the maximum likelihood estimate of WD.\nThe efficiency of Algorithm D increases if the number of parallel chains ñ is large because it leads to more accurate estimation of the expectation in the gradient L′D(WD) of equation (3), so that we can afford to use larger learning rate γt for faster convergence.\nNow let us come back to the CoopNets algorithm. In order to understand how the descriptor net helps the training of the generator net, let us consider the idealized scenario where the number of parallel chains ñ → ∞, and the generator has infinite capacity, and in each iteration it estimates WG by maximum likelihood using the synthesized data from P (t+1)D . In this idealized scenario, the learned generator PG(Y ;W (t+1) G ) will reproduce P (t+1) D by minimizing KL(P (t+1) D (Y )|PG(Y ;WG)), with P (t+1) D serving as its data distribution. Then eventually the learned generator PG(Y, ŴG) will reproduce PD(Y ; ŴD). Thus the cooperative training helps the learning of the generator. Note that the learned generator PG(Y, ŴG) will not reproduce the distribution of the observed data Pdata, unless the descriptor is of infinite capacity too.\nConversely, the generator net also helps the learning of the descriptor net in the CoopNets algorithm. In Algorithm D, it is impractical to make the number of parallel chains ñ too large. On the other hand, it would be difficult for a small number of chains {Ỹi, i = 1, ..., ñ} to explore the state space. In the CoopNets algorithm, because PG(Y ;W (t) G ) reproduces P (t) D , we can generate a completely new batch of independent samples {Ŷi} from PG(Y ;W (t)G ), and revise {Ŷi} to {Ỹi} by Langevin dynamics, instead of running Langevin dynamics from the same old batch of {Ỹi} as in the original Algorithm D. This is like implementing an infinite number of parallel chains, because each iteration evolves a fresh batch of examples, as if each iteration evolves a new set of chains. By updating the generator WG , it is like we are updating the infinite number of parallel chains, because WG memorizes the whole distribution. Even if ñ in the CoopNets algorithm is small, e.g., ñ = 1, viewed from the perspective of Algorithm D, it is as if ñ→∞. Thus the above idealization ñ→∞ is sound."
    }, {
      "heading" : "7.2 GENERATOR OF FINITE CAPACITY",
      "text" : "From an information geometry point of view, let D = {PD(Y ;WD),∀WD} be the manifold of the descriptor models, where each distribution PD(Y ;WD) is a point on this manifold. Then the maximum likelihood estimate of WD is a projection of the data distribution Pdata onto the manifold D. Let G = {PG(Y ;WG),∀WG} be the manifold of the generator models, where each distribution PG(Y ;WG) is a point on this manifold. Then the maximum likelihood estimate ofWG is a projection of the data distribution Pdata onto the manifold G. From now on, for notational simplicity and with a slight abuse of notation, we use WD to denote the descriptor distribution PD(Y ;WD), and use WG to denote the generator distribution PG(Y ;WG).\nWe assume both the observed data size n and the synthesized data size ñ are large enough so that we shall work on distributions or populations instead of finite samples. As explained above, assuming ñ→∞ is sound because the generator net can supply unlimited number of examples.\nThe Langevin revision dynamics runs a Markov chain from W (t)G towards W (t) D . Let LWD be the Markov transition kernel of lD steps of Langevin revisions towards WD. The distribution of the revised synthesized data is\nP (t+1) D = LW (t)D ·W (t)G , (12)\nwhere the notation L ·P denotes the marginal distribution obtained by running the Markov transition L fromP . The distributionP (t+1)D is in the middle between the two netsW (t) G andW (t) D , and it serves as the data distribution to train the generator, i.e., we project this distribution onto the manifold G = {PG(Y ;WG),∀WG} = {WG} (recall we use WG to denote the distribution PG(Y ;WG)) in the\ninformation geometry picture, so that\nW (t+1) G = argminG KL(P (t+1) D |WG). (13)\nThe learning process alternates between Markov transition in (12) and projection in (13), as illustrated by Figure 9.\nIn the case of lD →∞,\nW (t) D → ŴD = argminD KL(Pdata|WD), (14)\nW (t) G → ŴG = argminG KL(ŴD|WG). (15)\nThat is, we first project Pdata onto D, and from there continue to project onto G. Therefore, WD converges to the maximum likelihood estimate with Pdata being the data distribution, while WG converges to the maximum likelihood estimate with ŴD serving as the data distribution.\nFor finite lD, the algorithm may converge to the following fixed points. The fixed point for the generator satisfies\nŴG = argmin G KL(LŴD · ŴG |WG). (16)\nThe fixed point for the descriptor satisfies\nŴD = argmin D [ KL(Pdata|WD)−KL(LŴD · ŴG |WD) ] , (17)\nwhich is similar to contrastive divergence (Hinton, 2002), except that ŴG takes the place of Pdata in the second Kullback-Leibler divergence. Because ŴG is supposed to be close to ŴD, the second Kullback-Leibler divergence is supposed to be small, hence our algorithm is closer to maximum likelihood learning than contrastive divergence.\nKim & Bengio (2016) learned the generator by gradient descent on KL(WG |W (t)D ) over G. The objective function is KL(WG |W (t)D ) = EWG [logPG(Y ;WG)]− EWG [logPD(Y ;W (t) D )], where the first term is the negative entropy that is intractable, and the second term is the expected energy that is tractable. Our learning method for the generator is consistent with the learning objective KL(WG |W (t)D ), because\nKL(P (t+1) D |W (t) D ) ≤ KL(W (t) G |W (t) D ). (18)\nIn fact, KL(P (t+1)D |W (t) D ) → 0 monotonically as lD → ∞ due to the second law of thermodynamics. The reduction of the Kullback-Leibler divergence in (18) and the projection in (13) in our learning of the generator are consistent with the learning objective of reducing KL(WG |W (t)D ) in Kim & Bengio (2016). But the Monte Carlo implementation of L in our work avoids the need to approximate the intractable entropy term."
    }, {
      "heading" : "7.3 MORE SYNTHESIS RESULTS",
      "text" : "We display more synthesis results at the resolution of 64 × 64."
    }, {
      "heading" : "ACKNOWLEDGEMENT",
      "text" : "We thank Hansheng Jiang for her work on this project as a summer visiting student. We thank Tian Han for sharing the code on learning the generator network, and for helpful discussions.\nThe work is supported by NSF DMS 1310391, DARPA SIMPLEX N66001-15-C-4035, ONR MURI N00014-16-1-2007, and DARPA ARO W911NF-16-1-0579."
    } ],
    "references" : [ {
      "title" : "Imagenet: A large-scale hierarchical image database",
      "author" : [ "Jia Deng", "Wei Dong", "Richard Socher", "Li-Jia Li", "Kai Li", "Li Fei-Fei" ],
      "venue" : "In Computer Vision and Pattern Recognition,",
      "citeRegEx" : "Deng et al\\.,? \\Q2009\\E",
      "shortCiteRegEx" : "Deng et al\\.",
      "year" : 2009
    }, {
      "title" : "Deep generative image models using a laplacian pyramid of adversarial networks",
      "author" : [ "Emily L Denton", "Soumith Chintala", "Rob Fergus" ],
      "venue" : "In Advances in Neural Information Processing Systems,",
      "citeRegEx" : "Denton et al\\.,? \\Q2015\\E",
      "shortCiteRegEx" : "Denton et al\\.",
      "year" : 2015
    }, {
      "title" : "Learning to generate chairs with convolutional neural networks",
      "author" : [ "E Dosovitskiy", "J.T. Springenberg", "T Brox" ],
      "venue" : "In IEEE International Conference on Computer Vision and Pattern Recognition (CVPR),",
      "citeRegEx" : "Dosovitskiy et al\\.,? \\Q2015\\E",
      "shortCiteRegEx" : "Dosovitskiy et al\\.",
      "year" : 2015
    }, {
      "title" : "Generative adversarial nets",
      "author" : [ "Ian Goodfellow", "Jean Pouget-Abadie", "Mehdi Mirza", "Bing Xu", "David Warde-Farley", "Sherjil Ozair", "Aaron Courville", "Yoshua Bengio" ],
      "venue" : "In Advances in Neural Information Processing Systems,",
      "citeRegEx" : "Goodfellow et al\\.,? \\Q2014\\E",
      "shortCiteRegEx" : "Goodfellow et al\\.",
      "year" : 2014
    }, {
      "title" : "Alternating back-propagation for generator network",
      "author" : [ "Tian Han", "Yang Lu", "Song-Chun Zhu", "Ying Nian Wu" ],
      "venue" : "In 31st AAAI Conference on Artificial Intelligence,",
      "citeRegEx" : "Han et al\\.,? \\Q2017\\E",
      "shortCiteRegEx" : "Han et al\\.",
      "year" : 2017
    }, {
      "title" : "Training products of experts by minimizing contrastive divergence",
      "author" : [ "Geoffrey E Hinton" ],
      "venue" : "Neural Computation,",
      "citeRegEx" : "Hinton.,? \\Q2002\\E",
      "shortCiteRegEx" : "Hinton.",
      "year" : 2002
    }, {
      "title" : "Deep directed generative models with energy-based probability estimation",
      "author" : [ "Taesup Kim", "Yoshua Bengio" ],
      "venue" : "arXiv preprint arXiv:1606.03439,",
      "citeRegEx" : "Kim and Bengio.,? \\Q2016\\E",
      "shortCiteRegEx" : "Kim and Bengio.",
      "year" : 2016
    }, {
      "title" : "Auto-encoding variational bayes",
      "author" : [ "Diederik P. Kingma", "Max Welling" ],
      "venue" : "ICLR,",
      "citeRegEx" : "Kingma and Welling.,? \\Q2014\\E",
      "shortCiteRegEx" : "Kingma and Welling.",
      "year" : 2014
    }, {
      "title" : "Imagenet classification with deep convolutional neural networks",
      "author" : [ "Alex Krizhevsky", "Ilya Sutskever", "Geoffrey E Hinton" ],
      "venue" : "In NIPS, pp",
      "citeRegEx" : "Krizhevsky et al\\.,? \\Q2012\\E",
      "shortCiteRegEx" : "Krizhevsky et al\\.",
      "year" : 2012
    }, {
      "title" : "Gradient-based learning applied to document recognition",
      "author" : [ "Yann LeCun", "Léon Bottou", "Yoshua Bengio", "Patrick Haffner" ],
      "venue" : "Proceedings of the IEEE,",
      "citeRegEx" : "LeCun et al\\.,? \\Q1998\\E",
      "shortCiteRegEx" : "LeCun et al\\.",
      "year" : 1998
    }, {
      "title" : "A tutorial on energy-based learning",
      "author" : [ "Yann LeCun", "Sumit Chopra", "Rata Hadsell", "Mare’Aurelio Ranzato", "Fu Jie Huang" ],
      "venue" : null,
      "citeRegEx" : "LeCun et al\\.,? \\Q2006\\E",
      "shortCiteRegEx" : "LeCun et al\\.",
      "year" : 2006
    }, {
      "title" : "Deep learning face attributes in the wild",
      "author" : [ "Ziwei Liu", "Ping Luo", "Xiaogang Wang", "Xiaoou Tang" ],
      "venue" : "In Proceedings of the IEEE International Conference on Computer Vision, pp",
      "citeRegEx" : "Liu et al\\.,? \\Q2015\\E",
      "shortCiteRegEx" : "Liu et al\\.",
      "year" : 2015
    }, {
      "title" : "Neural variational inference and learning in belief networks",
      "author" : [ "Andriy Mnih", "Karol Gregor" ],
      "venue" : "In ICML,",
      "citeRegEx" : "Mnih and Gregor.,? \\Q2014\\E",
      "shortCiteRegEx" : "Mnih and Gregor.",
      "year" : 2014
    }, {
      "title" : "Learning deep energy models",
      "author" : [ "Jiquan Ngiam", "Zhenghao Chen", "Pang Wei Koh", "Andrew Y. Ng" ],
      "venue" : "In International Conference on Machine Learning,",
      "citeRegEx" : "Ngiam et al\\.,? \\Q2011\\E",
      "shortCiteRegEx" : "Ngiam et al\\.",
      "year" : 2011
    }, {
      "title" : "Unsupervised representation learning with deep convolutional generative adversarial networks",
      "author" : [ "Alec Radford", "Luke Metz", "Soumith Chintala" ],
      "venue" : "arXiv preprint arXiv:1511.06434,",
      "citeRegEx" : "Radford et al\\.,? \\Q2015\\E",
      "shortCiteRegEx" : "Radford et al\\.",
      "year" : 2015
    }, {
      "title" : "Stochastic backpropagation and approximate inference in deep generative models",
      "author" : [ "Danilo J. Rezende", "Shakir Mohamed", "Daan Wierstra" ],
      "venue" : "JMLR Workshop and Conference Proceedings,",
      "citeRegEx" : "Rezende et al\\.,? \\Q2014\\E",
      "shortCiteRegEx" : "Rezende et al\\.",
      "year" : 2014
    }, {
      "title" : "A stochastic approximation method",
      "author" : [ "Herbert Robbins", "Sutton Monro" ],
      "venue" : "The annals of mathematical statistics,",
      "citeRegEx" : "Robbins and Monro.,? \\Q1951\\E",
      "shortCiteRegEx" : "Robbins and Monro.",
      "year" : 1951
    }, {
      "title" : "Energy-based models for sparse overcomplete representations",
      "author" : [ "Yee Whye Teh", "Max Welling", "Simon Osindero", "Geoffrey E Hinton" ],
      "venue" : "Journal of Machine Learning Research,",
      "citeRegEx" : "Teh et al\\.,? \\Q2003\\E",
      "shortCiteRegEx" : "Teh et al\\.",
      "year" : 2003
    }, {
      "title" : "Matconvnet – convolutional neural networks for matlab",
      "author" : [ "A. Vedaldi", "K. Lenc" ],
      "venue" : "In Proceeding of the ACM Int. Conf. on Multimedia,",
      "citeRegEx" : "Vedaldi and Lenc.,? \\Q2015\\E",
      "shortCiteRegEx" : "Vedaldi and Lenc.",
      "year" : 2015
    }, {
      "title" : "A theory of generative convnet",
      "author" : [ "Jianwen Xie", "Yang Lu", "Song-Chun Zhu", "Ying Nian Wu" ],
      "venue" : "In ICML,",
      "citeRegEx" : "Xie et al\\.,? \\Q2016\\E",
      "shortCiteRegEx" : "Xie et al\\.",
      "year" : 2016
    }, {
      "title" : "On the convergence of markovian stochastic algorithms with rapidly decreasing ergodicity rates",
      "author" : [ "Laurent Younes" ],
      "venue" : "Stochastics: An International Journal of Probability and Stochastic Processes,",
      "citeRegEx" : "Younes.,? \\Q1999\\E",
      "shortCiteRegEx" : "Younes.",
      "year" : 1999
    }, {
      "title" : "Learning deep features for scene recognition using places database",
      "author" : [ "Bolei Zhou", "Agata Lapedriza", "Jianxiong Xiao", "Antonio Torralba", "Aude Oliva" ],
      "venue" : "In Advances in neural information processing systems,",
      "citeRegEx" : "Zhou et al\\.,? \\Q2014\\E",
      "shortCiteRegEx" : "Zhou et al\\.",
      "year" : 2014
    }, {
      "title" : "Statistical modeling and conceptualization of visual patterns",
      "author" : [ "Song-Chun Zhu" ],
      "venue" : "IEEE Transactions on Pattern Analysis and Machine Intelligence,",
      "citeRegEx" : "Zhu.,? \\Q2003\\E",
      "shortCiteRegEx" : "Zhu.",
      "year" : 2003
    }, {
      "title" : "Minimax entropy principle and its application to texture modeling",
      "author" : [ "Song-Chun Zhu", "Ying Nian Wu", "David Mumford" ],
      "venue" : "Neural Computation,",
      "citeRegEx" : "Zhu et al\\.,? \\Q1997\\E",
      "shortCiteRegEx" : "Zhu et al\\.",
      "year" : 1997
    } ],
    "referenceMentions" : [ {
      "referenceID" : 9,
      "context" : "Both models are parametrized by convolutional neural networks (ConvNets or CNNs) (LeCun et al., 1998; Krizhevsky et al., 2012).",
      "startOffset" : 81,
      "endOffset" : 126
    }, {
      "referenceID" : 8,
      "context" : "Both models are parametrized by convolutional neural networks (ConvNets or CNNs) (LeCun et al., 1998; Krizhevsky et al., 2012).",
      "startOffset" : 81,
      "endOffset" : 126
    }, {
      "referenceID" : 10,
      "context" : "(a) The exponential family models or the energy-based models (LeCun et al., 2006) or the Markov random field models (Zhu et al.",
      "startOffset" : 61,
      "endOffset" : 81
    }, {
      "referenceID" : 23,
      "context" : ", 2006) or the Markov random field models (Zhu et al., 1997), where the probability distribution is defined by feature statistics or energy function computed from the signal by a bottom-up process.",
      "startOffset" : 42,
      "endOffset" : 60
    }, {
      "referenceID" : 9,
      "context" : "(a) The exponential family models or the energy-based models (LeCun et al., 2006) or the Markov random field models (Zhu et al., 1997), where the probability distribution is defined by feature statistics or energy function computed from the signal by a bottom-up process. (b) The latent variable models or the directed graphical models, where the signal is assumed to be a transformation of the latent factors that follow a known prior distribution. The latent factors generate the signal by a top-down process. A classical example is factor analysis. The two classes of models have been contrasted by Zhu (2003); Teh et al.",
      "startOffset" : 62,
      "endOffset" : 613
    }, {
      "referenceID" : 9,
      "context" : "(a) The exponential family models or the energy-based models (LeCun et al., 2006) or the Markov random field models (Zhu et al., 1997), where the probability distribution is defined by feature statistics or energy function computed from the signal by a bottom-up process. (b) The latent variable models or the directed graphical models, where the signal is assumed to be a transformation of the latent factors that follow a known prior distribution. The latent factors generate the signal by a top-down process. A classical example is factor analysis. The two classes of models have been contrasted by Zhu (2003); Teh et al. (2003); Ngiam et al.",
      "startOffset" : 62,
      "endOffset" : 632
    }, {
      "referenceID" : 9,
      "context" : "(a) The exponential family models or the energy-based models (LeCun et al., 2006) or the Markov random field models (Zhu et al., 1997), where the probability distribution is defined by feature statistics or energy function computed from the signal by a bottom-up process. (b) The latent variable models or the directed graphical models, where the signal is assumed to be a transformation of the latent factors that follow a known prior distribution. The latent factors generate the signal by a top-down process. A classical example is factor analysis. The two classes of models have been contrasted by Zhu (2003); Teh et al. (2003); Ngiam et al. (2011). Zhu (2003) called the two classes of models the descriptive models and the generative",
      "startOffset" : 62,
      "endOffset" : 653
    }, {
      "referenceID" : 9,
      "context" : "(a) The exponential family models or the energy-based models (LeCun et al., 2006) or the Markov random field models (Zhu et al., 1997), where the probability distribution is defined by feature statistics or energy function computed from the signal by a bottom-up process. (b) The latent variable models or the directed graphical models, where the signal is assumed to be a transformation of the latent factors that follow a known prior distribution. The latent factors generate the signal by a top-down process. A classical example is factor analysis. The two classes of models have been contrasted by Zhu (2003); Teh et al. (2003); Ngiam et al. (2011). Zhu (2003) called the two classes of models the descriptive models and the generative",
      "startOffset" : 62,
      "endOffset" : 665
    }, {
      "referenceID" : 13,
      "context" : "(a) In the exponential family models or the energy-based models, the feature statistics or the energy function can be defined by a bottom-up ConvNet that maps the signal to the features and the energy function (Ngiam et al., 2011; Xie et al., 2016).",
      "startOffset" : 210,
      "endOffset" : 248
    }, {
      "referenceID" : 19,
      "context" : "(a) In the exponential family models or the energy-based models, the feature statistics or the energy function can be defined by a bottom-up ConvNet that maps the signal to the features and the energy function (Ngiam et al., 2011; Xie et al., 2016).",
      "startOffset" : 210,
      "endOffset" : 248
    }, {
      "referenceID" : 2,
      "context" : "(b) In the latent variable models or the directed graphical models, the transformation from the latent factors to the signal can be defined by a top-down ConvNet (Dosovitskiy et al., 2015), which maps the latent factors to the signal.",
      "startOffset" : 162,
      "endOffset" : 188
    }, {
      "referenceID" : 11,
      "context" : "(a) In the exponential family models or the energy-based models, the feature statistics or the energy function can be defined by a bottom-up ConvNet that maps the signal to the features and the energy function (Ngiam et al., 2011; Xie et al., 2016). We call the resulting model a descriptive network or a descriptor net following Zhu (2003), because it is built on descriptive feature statistics.",
      "startOffset" : 211,
      "endOffset" : 341
    }, {
      "referenceID" : 2,
      "context" : "(b) In the latent variable models or the directed graphical models, the transformation from the latent factors to the signal can be defined by a top-down ConvNet (Dosovitskiy et al., 2015), which maps the latent factors to the signal. We call the resulting model a generative network or generator net following Goodfellow et al. (2014), who proposed such a model in their work on the generative adversarial networks (GAN).",
      "startOffset" : 163,
      "endOffset" : 336
    }, {
      "referenceID" : 19,
      "context" : "Algorithm D (Xie et al., 2016) iterates two steps: Step D1 synthesizes examples by sampling from the current model by Langevin dynamics.",
      "startOffset" : 12,
      "endOffset" : 30
    }, {
      "referenceID" : 4,
      "context" : "Algorithm G (Han et al., 2017) also iterates two steps.",
      "startOffset" : 12,
      "endOffset" : 30
    }, {
      "referenceID" : 3,
      "context" : "2 RELATED WORK Our work is inspired by the generative adversarial networks (GAN) (Goodfellow et al., 2014; Denton et al., 2015; Radford et al., 2015).",
      "startOffset" : 81,
      "endOffset" : 149
    }, {
      "referenceID" : 1,
      "context" : "2 RELATED WORK Our work is inspired by the generative adversarial networks (GAN) (Goodfellow et al., 2014; Denton et al., 2015; Radford et al., 2015).",
      "startOffset" : 81,
      "endOffset" : 149
    }, {
      "referenceID" : 14,
      "context" : "2 RELATED WORK Our work is inspired by the generative adversarial networks (GAN) (Goodfellow et al., 2014; Denton et al., 2015; Radford et al., 2015).",
      "startOffset" : 81,
      "endOffset" : 149
    }, {
      "referenceID" : 15,
      "context" : "Another method to train the generator network is variational auto-encoder (VAE) (Kingma & Welling, 2014; Rezende et al., 2014; Mnih & Gregor, 2014), which learns an inferential or recognition network to approximate the posterior distribution of the latent factors.",
      "startOffset" : 80,
      "endOffset" : 147
    }, {
      "referenceID" : 5,
      "context" : "Our work is related to the contrastive divergence algorithm (Hinton, 2002) for training the descriptor net.",
      "startOffset" : 60,
      "endOffset" : 74
    }, {
      "referenceID" : 1,
      "context" : ", 2014; Denton et al., 2015; Radford et al., 2015). In GAN, the generator net is paired with a discriminator net. The two nets play adversarial roles. In our work, the generator net and the descriptor net play cooperative roles, and they feed each other the initial, revised and reconstructed synthesized data. The learning of both nets is based on maximum likelihood, and the learning process is quite stable because of the cooperative nature and the consistent directions of the two maximum likelihood training algorithms. Another method to train the generator network is variational auto-encoder (VAE) (Kingma & Welling, 2014; Rezende et al., 2014; Mnih & Gregor, 2014), which learns an inferential or recognition network to approximate the posterior distribution of the latent factors. The connection between the descriptor net and the discriminator net has been explored by Xie et al. (2016), where the descriptor can be derived from the discriminator.",
      "startOffset" : 8,
      "endOffset" : 897
    }, {
      "referenceID" : 1,
      "context" : ", 2014; Denton et al., 2015; Radford et al., 2015). In GAN, the generator net is paired with a discriminator net. The two nets play adversarial roles. In our work, the generator net and the descriptor net play cooperative roles, and they feed each other the initial, revised and reconstructed synthesized data. The learning of both nets is based on maximum likelihood, and the learning process is quite stable because of the cooperative nature and the consistent directions of the two maximum likelihood training algorithms. Another method to train the generator network is variational auto-encoder (VAE) (Kingma & Welling, 2014; Rezende et al., 2014; Mnih & Gregor, 2014), which learns an inferential or recognition network to approximate the posterior distribution of the latent factors. The connection between the descriptor net and the discriminator net has been explored by Xie et al. (2016), where the descriptor can be derived from the discriminator. Our work is most similar to the recent work of Kim & Bengio (2016). In fact, the settings of the two nets are the same.",
      "startOffset" : 8,
      "endOffset" : 1025
    }, {
      "referenceID" : 19,
      "context" : "The descriptor model is in the form of exponential tilting of a reference distribution (Xie et al., 2016): PD(Y ;WD) = 1 Z(WD) exp [f(Y ;WD)] q(Y ), (2)",
      "startOffset" : 87,
      "endOffset" : 105
    }, {
      "referenceID" : 19,
      "context" : "Algorithm D (Xie et al., 2016) iterates the following two steps after initializing WD and {Ỹi, i = 1, .",
      "startOffset" : 12,
      "endOffset" : 30
    }, {
      "referenceID" : 19,
      "context" : "Algorithm D (Xie et al., 2016) iterates the following two steps after initializing WD and {Ỹi, i = 1, ..., ñ}. Step D1: Run lD steps of Langevin from the current {Ỹ } according according to (4). Step D2: update W (t+1) D = W (t) D + γtL ′ D(W (t) D ) with learning rate γt. The convergence of such an algorithm follows Younes (1999).",
      "startOffset" : 13,
      "endOffset" : 333
    }, {
      "referenceID" : 3,
      "context" : "2 GENERATOR NET AND TRAINING ALGORITHM The generator net (Goodfellow et al., 2014) seeks to explain the signal Y of dimensionD by a vector of latent factors X of dimension d, and usually d D.",
      "startOffset" : 57,
      "endOffset" : 82
    }, {
      "referenceID" : 4,
      "context" : "Algorithm G (Han et al., 2017) iterates the following two steps after initializing WG and {Xi, i = 1, .",
      "startOffset" : 12,
      "endOffset" : 30
    }, {
      "referenceID" : 4,
      "context" : "Algorithm G (Han et al., 2017) iterates the following two steps after initializing WG and {Xi, i = 1, ..., n}. Step G1: run lG steps of Langevin from the current {Xi} according to (9). Step G2: update W (t+1) G =W (t) G +γtL ′ G(W (t) G ) with learning rate γt. The convergence of such an algorithm follows Younes (1999).",
      "startOffset" : 13,
      "endOffset" : 321
    }, {
      "referenceID" : 14,
      "context" : "(2015), where the top-down network consists of multiple layers of deconvolution by linear superposition, ReLU non-linearity, and up-sampling, with tanh non-linearity at the bottom-layer (Radford et al., 2015) to make the signals fall within [−1, 1].",
      "startOffset" : 186,
      "endOffset" : 208
    }, {
      "referenceID" : 17,
      "context" : "For the descriptor net, we adopt the structure of Xie et al. (2016), where the bottom-up network consists of multiple layers of convolution by linear filtering, ReLU non-linearity, and down-sampling.",
      "startOffset" : 50,
      "endOffset" : 68
    }, {
      "referenceID" : 13,
      "context" : "We adopt the structure of the generator network of Radford et al. (2015); Dosovitskiy et al.",
      "startOffset" : 51,
      "endOffset" : 73
    }, {
      "referenceID" : 2,
      "context" : "(2015); Dosovitskiy et al. (2015), where the top-down network consists of multiple layers of deconvolution by linear superposition, ReLU non-linearity, and up-sampling, with tanh non-linearity at the bottom-layer (Radford et al.",
      "startOffset" : 8,
      "endOffset" : 34
    }, {
      "referenceID" : 14,
      "context" : "The structure of the generator network is the same as in (Radford et al., 2015; Dosovitskiy et al., 2015).",
      "startOffset" : 57,
      "endOffset" : 105
    }, {
      "referenceID" : 2,
      "context" : "The structure of the generator network is the same as in (Radford et al., 2015; Dosovitskiy et al., 2015).",
      "startOffset" : 57,
      "endOffset" : 105
    }, {
      "referenceID" : 11,
      "context" : "The training data are 10, 000 human faces randomly selected from CelebA dataset (Liu et al., 2015).",
      "startOffset" : 80,
      "endOffset" : 98
    }, {
      "referenceID" : 2,
      "context" : ", 2015; Dosovitskiy et al., 2015). We adopt a 4-layer descriptor net. The first layer has 96 5 × 5 filters with sub-sampling of 2, the second layers has 128 5 × 5 filters with sub-sampling of 2, the third layer has 256 5 × 5 filters with sub-sampling of 2, and the final layer is a fully connected layer with 50 channels as output. We use L=10 steps of Langevin revision dynamics within each learning iteration, and the Langevin step size is set at 0.002. The learning rate is 0.07. The training data are 10, 000 human faces randomly selected from CelebA dataset (Liu et al., 2015). We run 600 cooperative learning iterations. Figure 2 displays 144 synthesized human faces by the descriptor net. To quantitatively test whether we have learned a good generator net g(X;WG) even though it has never seen the training images directly in the training stage, we apply it to the task of recovering the occluded pixels of testing images. For each occluded testing image Y , we use Step G1 of Algorithm G to infer the latent factors X . The only change is with respect to the term ‖Y − g(X;WG)‖, where the sum of squares is over all the observed pixels of Y in back-propagation computation. We run 1000 Langevin steps, initializing X from N(0, Id). After inferring X , the completed image g(X;WG) is automatically obtained. We design 3 experiments, where we randomly place a 20×20, 30 × 30, or 40 × 40 mask on each 64 × 64 testing image. These 3 experiments are denoted by M20 M30, and M40 respectively (M for mask). We report the recovery errors and compare our method with 8 different image inpainting methods as well as the DCGAN of Radford et al. (2015).",
      "startOffset" : 8,
      "endOffset" : 1650
    }, {
      "referenceID" : 14,
      "context" : "For DCGAN, we use the parameter setting in Radford et al. (2015) except changing the number of learning iterations to 600.",
      "startOffset" : 43,
      "endOffset" : 65
    }, {
      "referenceID" : 14,
      "context" : "For DCGAN, we use the parameter setting in Radford et al. (2015) except changing the number of learning iterations to 600. We use the same 10, 000 training images to learn DCGAN. After the model is learned, we keep the generator and use the same method as ours to infer latent factors X , and recover the unobserved pixels. In 8 inpainting methods, Methods 1 and 2 are based on Markov random field prior where the nearest neighbor potential terms are `2 and `1 differences respectively. Methods 3 to 8 are interpolation methods. Please refer to D’Errico (2004) for more details.",
      "startOffset" : 43,
      "endOffset" : 561
    }, {
      "referenceID" : 0,
      "context" : "2 QUALITATIVE EXPERIMENT ON SYNTHESIS We conduct an experiment on synthesizing images of categories from Imagenet ILSVRC2012 dataset (Deng et al., 2009) and MIT places205 dataset (Zhou et al.",
      "startOffset" : 133,
      "endOffset" : 152
    }, {
      "referenceID" : 21,
      "context" : ", 2009) and MIT places205 dataset (Zhou et al., 2014).",
      "startOffset" : 34,
      "endOffset" : 53
    }, {
      "referenceID" : 20,
      "context" : "According to Younes (1999), Algorithm D converges to the maximum likelihood estimate under suitable regularity conditions on the mixing of the transition kernel of the MCMC and the schedule of the learning rate γt, even if the number of Langevin steps lD is finite or small (e.",
      "startOffset" : 13,
      "endOffset" : 27
    }, {
      "referenceID" : 20,
      "context" : "Even though P (t+1) D 6= PD(Y ;W (t) D ) because lD is finite (P (t+1) D = PD(Y ;W (t) D ) if lD → ∞), we still have W (t) D → ŴD in probability according to Younes (1999), where ŴD is the maximum likelihood estimate of WD.",
      "startOffset" : 158,
      "endOffset" : 172
    }, {
      "referenceID" : 5,
      "context" : "which is similar to contrastive divergence (Hinton, 2002), except that ŴG takes the place of Pdata in the second Kullback-Leibler divergence.",
      "startOffset" : 43,
      "endOffset" : 57
    }, {
      "referenceID" : 5,
      "context" : "which is similar to contrastive divergence (Hinton, 2002), except that ŴG takes the place of Pdata in the second Kullback-Leibler divergence. Because ŴG is supposed to be close to ŴD, the second Kullback-Leibler divergence is supposed to be small, hence our algorithm is closer to maximum likelihood learning than contrastive divergence. Kim & Bengio (2016) learned the generator by gradient descent on KL(WG |W (t) D ) over G.",
      "startOffset" : 44,
      "endOffset" : 358
    }, {
      "referenceID" : 5,
      "context" : "which is similar to contrastive divergence (Hinton, 2002), except that ŴG takes the place of Pdata in the second Kullback-Leibler divergence. Because ŴG is supposed to be close to ŴD, the second Kullback-Leibler divergence is supposed to be small, hence our algorithm is closer to maximum likelihood learning than contrastive divergence. Kim & Bengio (2016) learned the generator by gradient descent on KL(WG |W (t) D ) over G. The objective function is KL(WG |W (t) D ) = EWG [logPG(Y ;WG)]− EWG [logPD(Y ;W (t) D )], where the first term is the negative entropy that is intractable, and the second term is the expected energy that is tractable. Our learning method for the generator is consistent with the learning objective KL(WG |W (t) D ), because KL(P (t+1) D |W (t) D ) ≤ KL(W (t) G |W (t) D ). (18) In fact, KL(P (t+1) D |W (t) D ) → 0 monotonically as lD → ∞ due to the second law of thermodynamics. The reduction of the Kullback-Leibler divergence in (18) and the projection in (13) in our learning of the generator are consistent with the learning objective of reducing KL(WG |W (t) D ) in Kim & Bengio (2016). But the Monte Carlo implementation of L in our work avoids the need to approximate the intractable entropy term.",
      "startOffset" : 44,
      "endOffset" : 1121
    } ],
    "year" : 2017,
    "abstractText" : "This paper studies the cooperative training of two probabilistic models of signals such as images. Both models are parametrized by convolutional neural networks (ConvNets). The first network is a descriptor network, which is an exponential family model or an energy-based model, whose feature statistics or energy function are defined by a bottom-up ConvNet, which maps the observed signal to the feature statistics. The second network is a generator network, which is a nonlinear version of factor analysis. It is defined by a top-down ConvNet, which maps the latent factors to the observed signal. The maximum likelihood training algorithms of both the descriptor net and the generator net are in the form of alternating back-propagation, and both algorithms involve Langevin sampling. We observe that the two training algorithms can cooperate with each other by jumpstarting each other’s Langevin sampling, and they can be seamlessly interwoven into a CoopNets algorithm that can train both nets simultaneously.",
    "creator" : "LaTeX with hyperref package"
  }
}