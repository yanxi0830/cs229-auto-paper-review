{
  "name" : "534.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : null,
    "authors" : [ "Balaji Lakshminarayanan" ],
    "emails" : [ "shakir@google.com", "balajiln@google.com" ],
    "sections" : [ {
      "heading" : "1 IMPLICIT GENERATIVE MODELS",
      "text" : "It is useful to make a distinction between two types of probabilistic models: prescribed and implicit models (Diggle and Gratton, 1984). Prescribed probabilistic models are those that provide an explicit parametric specification of the distribution of an observed random variable x, specifying a log-likelihood function log qθ(x) with parameters θ. Most models in machine learning and statistics are of this form, whether they be state-of-the-art classifiers for object recognition, complex sequence models for machine translation, or fine-grained spatio-temporal models tracking the spread of disease. Alternatively, we can specify implicit probabilistic models that define a stochastic procedure that directly generates data. Such models are the natural approach for problems in climate and weather, population genetics, and ecology, since the mechanistic understanding of such systems can be used to directly create a data simulator, and hence the model. It is exactly because implicit models are more natural for many problems that they are of interest and importance.\nImplicit generative models use a latent variable z and transform it using a deterministic function Gθ that maps from Rm → Rd using parameters θ. Such models are amongst the most fundamental of models, e.g., many of the basic methods for generating non-uniform random variates are based on simple implicit models and one-line transformations (Devroye, 2006). In general, implicit generative models specify a valid density on the output space that forms an effective likelihood function:\nx = Gθ(z′); z′ ∼ q(z) (1)\nqθ(x) = ∂\n∂x1 . . .\n∂\n∂xd ∫ {Gθ(z)≤x} q(z)dz, (2)\nwhere q(z) is a latent variable that provides the external source of randomness and equation (2) is the definition of the transformed density as the derivative of the cumulative distribution function. When the function G is well-defined, such as when the function is invertible, or has dimensions m = d with easily characterised roots, we recover the familiar rule for transformations of probability distributions.\nWe are interested in developing more general and flexible implicit generative models where the function G is a non-linear function with d > m, specified by deep networks. The integral (2) is intractable in this case: we will be unable to determine the set {Gθ(z) ≤ x}, the integral will often be unknown even when the integration regions are known and, the derivative is high-dimensional and difficult to compute. Intractability is also a challenge for prescribed models, but the lack of a likelihood term significantly reduces the tools available for learning. In implicit models, this difficulty motivates the need for methods that side-step the intractability of the likelihood (2), or are likelihood-free.\nGenerative adversarial networks (GANs) (Goodfellow et al., 2014) provide a solution for exactly this type of problem. This connection makes it possible to export GAN-type solutions to other areas, and to import new approaches from areas addressing the same research problem. GANs specify an algorithmic framework for learning in implicit generative models, also referred to as generator networks or generative neural samplers or differentiable simulators in the literature. The framework relies on a learning principle based on discriminating real from generated data, which we shall show instantiates a core principle of likelihood-free inference, that of hypothesis and two-sample testing.\nNote on notation. We denote data by the random variable x, the (unknown) true data density by p∗(x), our (intractable) model density by qθ(x). q(z) is a density over latent variables z. Parameters of the model are θ, and parameters of the ratio and discriminator functions are φ."
    }, {
      "heading" : "2 HYPOTHESIS TESTING AND DENSITY RATIOS",
      "text" : ""
    }, {
      "heading" : "2.1 LIKELIHOOD-FREE INFERENCE",
      "text" : "Without a likelihood function, many of the widely-used tools for inference and parameter learning become unavailable. But there are tools that remain, including the method-of-moments (Hall, 2005), the empirical likelihood (Owen, 1988), Monte Carlo sampling (Marin et al., 2012), and mean-shift estimation (Fukunaga and Hostetler, 1975). Since we can easily draw samples from the model, we can use any method that compares two sets of samples—one from the true data distribution and one from the model distribution—to drive learning. This is a process of density estimation-by-comparison that tests the hypothesis that the true data distribution p∗(x) and our model distribution q(x) are equal, using the density ratio function r(x) = p∗(x)/q(x). The density ratio provides information about the departure of our model distribution from the true distribution, and our aim is to see this ratio be one. The density ratio r(x) is the core quantity for hypothesis testing, motivated by either the NeymanPearson lemma or the Bayesian posterior evidence, appearing as the likelihood ratio or the Bayes factor (Kass and Raftery, 1995), respectively. This is the focus of our approach for likelihood-free inference: estimating density ratios and using them as the driving principle for learning in implicit generative models.\nThe direct approach of computing the density ratio by first computing the individual marginals is not possible with implicit models. By directly estimating the ratio and exploiting knowledge of the probabilities involved, it will turn out that computing the ratio can be a much easier problem than computing the marginal likelihoods, and is what will make this approach appealing. There are four general approaches to consider (Sugiyama et al., 2012a): 1) class-probability estimation, 2) divergence minimisation, 3) ratio matching, and 4) moment matching. These are highly developed research areas in their own right, but their role in providing a learning principle for density estimation is under-appreciated and opens up an exciting range of approaches for learning in implicit generative models. Figure 1 summarises these approaches by showing pathways available for learning, which follow from the choice of inference driven by hypothesis testing and comparison."
    }, {
      "heading" : "2.2 CLASS PROBABILITY ESTIMATION",
      "text" : "The density ratio can be computed by building a classifier to distinguish observed data from that generated by the model. This is the most popular approach for density ratio estimation and the first port of call for learning in implicit models. Hastie et al. (2013) call this approach unsupervised-assupervised learning, Qin (1998) explore this for analysis of case-control in observational studies, both Neal (2008) and Cranmer et al. (2015) explore this approach for high-energy physics applications, Gutmann and Hyvärinen (2012) exploit it for learning un-normalised models, Lopez-Paz and Oquab\n(2016) for causal discovery, and Goodfellow et al. (2014) for learning in implicit generative models specified by neural networks.\nWe denote the domain of our data by X ⊂ Rd. The true data distribution has a density p∗(x) and our model has density qθ(x), both defined on X . We also have access to a set of n samples Xp = {x(p)1 , . . . ,x (p) n } from the true data distribution, and a set of n′ samples Xq = {x(q)1 , . . . ,x (q) n′ } from our model. We introduce a random variable y, and assign a label y = 1 to all samples in Xp and y = 0 to all samples in Xq . We can now represent p∗(x) = p(x|y = 1) and qθ(x) = p(x|y = 0). By application of Bayes’ rule, we can compute the ratio r(x) as:\np∗(x) qθ(x) = p(x|y = 1) p(x|y = 0) = p(y = 1|x)p(x) p(y = 1)\n/ p(y = 0|x)p(x)\np(y = 0) = p(y = 1|x) p(y = 0|x) · 1− π π , (3)\nwhich indicates that the problem of density ratio estimation is equivalent to that of class probability estimation, since the problem is reduced to computing the probability p(y = 1|x). We assume that the marginal probability over classes is p(y = 1) = π, which allows the relative proportion of data from the two classes to be adjusted if they are imbalanced; in most formulations π = ½ for the balanced case, and in imbalanced cases 1−ππ ≈ n ′/n.\nOur task is now to specify a scoring function, or discriminator, D(x;φ) = p(y = 1|x): a function bounded in [0,1] with parameters φ that computes the probability of data belonging to the positive (real data) class. This discriminator is related to the density ratio through the mapping D = r/(r + 1); r = D/(1−D). Conveniently, we can use our knowledge of building classifiers and specify these functions using deep neural networks. Given this scoring function, we must specify a proper scoring rule (Gneiting and Raftery, 2007; Buja et al., 2005) for binary discrimination to allow for parameter learning, such as those in Table 1. A natural choice is to use the Bernoulli (logarithmic) loss:\nL(φ,θ) = Ep(x|y)p(y)[−y logD(x;φ)− (1− y) log(1−D(x;φ))] (4) = πEp∗(x)[− logD(x;φ)] + (1− π)Eqθ(x)[− log(1−D(x;φ))]. (5)\nSince we know the underlying generative process for qθ(x), using a change of variables, we can express the loss in term of an expectation over the latent variable z and the generative model G(z;θ):\nL(φ,θ) = πEp∗(x)[− logD(x;φ)] + (1− π)Eq(z)[− log(1−D(G(z;θ);φ))]. (6)\nThe final form of this objective (6) is exactly that used in generative adversarial networks (GANs) (Goodfellow et al., 2014). In practice, the expectations are computed by Monte Carlo integration using samples from p∗ and qθ. Equation (6) allows us to specify a bi-level optimisation (Colson et al., 2007) by forming a ratio loss and a generative loss, using which we perform an alternating optimisation. Our convention throughout the paper will be to always form the ratio loss by extracting all terms in L related to the ratio function parameters φ, and minimise the resulting objective. For the generative loss, we will similarly extract all terms related to the model parameters θ, flip the sign, and minimise the resulting objective. For equation (6), the bi-level optimisation is:\nRatio loss: min φ πEp∗(x)[− logD(x;φ)] + (1− π)Eqθ(x)[− log(1−D(x;φ))] (7)\nGenerative loss: min θ Eq(z)[log(1−D(G(z;θ)))]. (8)\nThe ratio loss is minimised since it acts as a surrogate negative log-likelihood; the generative loss is minimised since we wish to minimise the probability of the negative (generated-data) class. We explicitly write out these two stages to emphasise that the objectives used are separable. While we can derive the generative loss from the ratio loss as we have done, any generative loss that drives qθ to p∗, such as minimising the widely-used Eq(z)[− logD(G(z;θ))] (Goodfellow et al., 2014; Nowozin et al., 2016) or Eq(z)[− log D(G(z;θ))1−D(G(z;θ)) ] = Eq(z)[− log r(G(z;θ)) (Sønderby et al., 2016), is possible. Any scoring rule from Table 1 can be used to give a loss function for optimisation. These rules are amenable to stochastic approximation and alternating optimisation, as described by Goodfellow et al. (2014), along with many of the insights for optimisation that have been developed since (Salimans et al., 2016; Radford et al., 2015; Zhao et al., 2016; Sønderby et al., 2016). The Bernoulli loss can be criticised in a number of ways and makes other scoring rules interesting to explore. The Brier loss provides a similar decision rule, and its use in calibrated regression makes it appealing; the motivations behind many of these scoring rules are discussed in (Gneiting and Raftery, 2007). Finally, while we have focussed on the two sample hypothesis test, we believe it could be advantageous to extend this reasoning to the case of multiple testing, where we simultaneously test several sets of data (Bickel et al., 2008).\nThe advantage of using a proper scoring rule is that the global optimum is achieved iff qθ = p∗ (cf. the proof in (Goodfellow et al., 2014) for the Bernoulli loss); however there are no convergence guarantees since the optimisation is non-convex. Goodfellow et al. (2014) discuss the relationship to maximum likelihood estimation, which minimises the divergence KL[p∗‖q], and show that the GAN objective with Bernoulli loss is instead related to the Jensen Shannon divergence JS [p∗||q]. In the objective (6), π denotes the marginal probability of the positive class; however several authors have proposed choosing π depending on the problem. In particular, Huszár (2015) showed that varying π is related to optimizing a generalised Jensen-Shannon divergence JSπ [p∗||q]. Creswell and Bharath (2016) presented results showing that different values of π are desirable, depending on whether we wish to fit one of the modes (a ‘high precision, low recall’ task such as generation) or explain all of the modes (a ‘high recall, low precision’ task such as retrieval)."
    }, {
      "heading" : "2.3 DIVERGENCE MINIMISATION",
      "text" : "A second approach to testing is to use the divergence between the true density p∗and our model q, and use this as an objective to drive learning of the generative model. A natural class of divergences to use are the f -divergences (or Ali-Silvey (Ali and Silvey, 1966) or Csiszar’s φ-divergence (Csiszàr, 1967)) since they are fundamentally linked to the problem of two-sample hypothesis testing (Liese and Vajda, 2008): f -divergences represent an integrated Bayes risk since they are an expectation of the density ratio. Nowozin et al. (2016) develop f -GANs using this view. The f -divergences contain the KL divergence as a special case and are equipped with an exploitable variational formulation:\nDf [p ∗(x)‖qθ(x)]= ∫ qθ(x)f ( p∗(x) qθ(x) ) dx=Eqθ(x)[f(r(x))]≥sup t Ep∗(x)[t(x)]−Eqθ(x)[f†(t(x))] (9)\nwhere f is a convex function with derivative f ′ and Fenchel conjugate f†; this divergence class instantiates many familiar divergences, such as the KL and Jensen-Shannon divergence. The variational formulation introduces the functions t(x) whose optimum is related to the density ratio since t∗(x) = f ′(r(x)). Substituting t∗ in (9), we transform the objective (10) into supremum over rφ (which is attained when rφ = r∗ = p ∗ /qθ). For self-consistency, we flip the sign to make it a minimisation problem in rφ, leading to the bi-level optimisation:\nL = Ep∗(x)[−f ′(rφ(x))] + Eqθ(x)[f†(f ′(rφ(x))] (10)\nRatio loss: min φ\nEp∗(x)[−f ′(rφ(x))] + Eqθ(x)[f†(f ′(rφ(x))] (11)\nGenerative loss: min θ\nEq(z)[−f†(f ′(r(G(z;θ)))], (12)\nwhere we derived equation (12) by extracting all the terms involving qθ(x) in equation (10), used the change of variables to express it in terms of the underlying generative model and flipping the sign to obtain a minimisation. There is no discriminator in this formulation, and this role is taken by the ratio function. We minimise the ratio loss, since we wish to minimise the negative of the variational lower bound; we minimise the generative loss since we wish to drive the ratio to one. By using the function f(u) = u log u, we recover an objective using the KL divergence; when f(u) = u log u − (u + 1) log(u + 1), we recover the objective function in equation (6) from the previous section using the Bernoulli loss, and hence the objective for GANs.\nThe density ratio implies that p∗(x) ≈ p̃ = rφ(x)qθ(x), since it is the amount by which we must correct our model qθ(x) to match the true distribution. This led us to a divergence formulation that evaluates the divergence between the distributions p∗ and p̃, using the KL divergence:\nDKL[p ∗(x)‖p̃(x)] = ∫ p∗(x) log\np∗(x) rφ(x)qθ(x) dx +\n∫ (rφ(x)qθ(x)− p∗(x))dx (13)\nL = Ep∗(x)[− log rφ(x)] + Eqθ(x)[rφ(x)− 1]− Ep∗(x)[log qθ(x)] + Ep∗(x)[log p∗(x)], (14)\nwhere the first equation is the KL for un-normalised densities (Minka, 2005). This leads to a convenient and valid ratio loss since all terms independent of r can be ignored. But we are unable to derive a useful generative loss from this expression (14) , since the third term with log q cannot be ignored, and is unavailable. Since the generative loss and ratio losses need not be coupled, any other generative loss can be used, e.g., equation (8). But this is not ideal, since we would prefer to derive valid ratio losses from the same principle to make reasoning about correctness and optimality easier. We include this discussion to point out that while the formulation of equation (9) is generally applicable, the formulation (14), while useful for ratio estimation, is not useful for generative learning. The difficulty of specifying stable and correct generative losses is a common theme of work in GANs; we will see a similar difficulty in the next section.\nThe equivalence between divergence minimisation and class probability estimation is also widely discussed, and most notably developed by Reid and Williamson (2011) using the tools of weighted integral measures, and more recently by Menon and Ong (2016). This divergence minimisation viewpoint (9) was used in f -GANs and explored in depth by Nowozin et al. (2016) who provide a detailed description, and explore many of the objectives that become available and practical guidance."
    }, {
      "heading" : "2.4 RATIO MATCHING",
      "text" : "A third approach is to directly minimise the error between the true density ratio and an estimate of it. If we denote the true density ratio as r∗(x) = p∗(x)/qθ(x) and its approximation as rφ(x), we can define a loss using the squared error:\nL = 1 2 ∫ qθ(x)(r(x)− r∗(x))2dx = 12Eqθ(x)[rφ(x)2]− Ep∗(x)[rφ(x)] + 12Ep∗(x)[r∗(x)] (15)\n= 12Eqθ(x)[rφ(x) 2]− Ep∗(x)[rφ(x)] s.t. rφ(x) ≥ 0, (16)\nwhere the final objective is obtained by ignoring terms independent of rφ(x) and is used to derive ratio and generative losses. When used to learn the ratio function, Sugiyama et al. (2012b) refer to this objective as KL importance estimation procedure (KLIEP). Concurrently with this work, Uehara et al. (2016) recognised the centrality of the density ratio, the approach for learning by ratio matching, and its connections to GANs (Goodfellow et al., 2014) and f -GANs (Nowozin et al., 2016), and provide useful guidance on practical use of ratio matching.\nWe can generalise (16) to loss functions beyond the squared error using the Bregman divergence for density ratio estimation (Sugiyama et al., 2012a; Uehara et al., 2016), and is the unifying tool exploited in previous work (Reid and Williamson, 2011; Sriperumbudur et al., 2009; Sugiyama et al., 2012a; Menon and Ong, 2016). This leads to a minimisation of the Bregman divergence Bf between ratios:\nBf (r ∗(x)‖rφ(x)) = ∫ ( f(r∗(x))− f(rφ(x))− f ′(rφ(x)) [ r∗(x)− rφ(x) ]) qθ(x)dx (17)\n= Eqθ(x) [rφ(x)f ′(rφ(x))− f(rφ(x))]− Ep∗[f ′(rφ(x))] +Df [p∗(x)‖qθ(x)] (18)\n= LB(rφ(x)) +Df [p∗(x)‖qθ(x)], (19) where we have used p∗= r∗qθ, and Df is the f -divergence defined in equation (9). We can derive a ratio loss from (19) by extracting all the terms in rφ, leading to the minimisation of LB(rφ). The role of the discriminator in GANs is again taken by the ratio r that provides information about the relationship between the two distributions. This ratio loss, as pointed out by Uehara et al. (2016), is equivalent to the ratio loss we derived using divergence minimisation (10), since:\nLB(rφ(x)) = Ep∗[−f ′(rφ(x))] + Eqθ(x)[rφ(x)f ′(rφ(x))− f(rφ(x))] (20) = Ep∗[−f ′(rφ(x))] + Eqθ(x)[f†(f ′(rφ(x)))]. (21)\nThe equivalence of the second terms in (20) and (21) can be derived by using the definition of the dual function: f†(f ′(x)) = maxr rf ′(x)− f(r). The maximum is attained at x = r, leading to the identity f†(f ′(rφ(x))) = rφ(x)f ′(rφ(x))− f(rφ(x)). If we follow the strategy we used in previous sections to obtain a generative loss, by collecting the terms in equation (19) dependent on qθ, we obtain:\nL(qθ) = Eqθ(x)[rφ(x)f ′(rφ(x))]− Eqθ(x)[f(rφ(x))] +Df [p∗(x)||qθ(x)]. (22) But this does not lead to a useful generative loss since there are terms involving qθ whose density is always unknown, similar to the difficulty we encountered with divergence minimisation in equation (14). Since we can use any generative loss that drives the ratio to one, we can employ other losses, like the alternatives described in section 2.2 . One approximation suggested by Uehara et al. (2016) is to assume p∗≈ rφqθ, i.e. assume a near-optimal ratio, which reduces the f -divergence to:\nDf [p ∗(x)‖qθ(x)]=Eqθ(x)\n[ f ( p∗\nqθ(x)\n)] ≈ Eqθ(x) [ f ( qθ(x)rφ(x)\nqθ(x)\n)] = Eqθ(x)[f(rφ(x))] (23)\nAs a result, the last two terms in equation (22) cancel, leaving a generative loss that can be used for learning. Using ratio matching under the Bregman divergence we obtain the bi-level optimisation:\nRatio loss: min φ\nEqθ(x)[rφ(x)f ′(rφ(x))− f(rφ(x))]− Ep∗[f ′(rφ(x))] (24)\nGenerative loss: min θ\nEqθ(x)[rφ(x)f ′(rφ(x))] (25)"
    }, {
      "heading" : "2.5 MOMENT MATCHING",
      "text" : "A final approach for testing is to evaluate whether the moments of the distributions p∗and q are the same, i.e. by moment matching. We compare the moments of the two distributions by minimising their distance, using test statistics s(x) that provides the moments of interest:\nL(φ,θ) = (Ep∗(x)[s(x)]− Eqθ(x)[s(x)])2 = (Ep∗(x)[s(x)]− Eq(z)[s(G(z;θ))])2 (26) The choice of test statistics s(x) is critical, since ideally, we wish to match all moments of the two distributions. When the functions s(x) are defined within a reproducing kernel Hilbert space, we obtain kernel-based forms of these objectives, which are highly flexible and allow easy handling of data such as images, strings and graphs. The objective (26) can then be re-expressed in closed-form in terms of kernel functions, leading to the maximum mean discrepancy criterion (MMD). The role of the MMD for learning in implicit generative models defined by neural networks has been explored by both Li et al. (2015) and Dziugaite et al. (2015). While typically expensive to compute, there are now highly efficient approaches for computing the MMD (Chwialkowski et al., 2015). The objective using feature matching by Salimans et al. (2016) is a form of moment matching that defines the test statistics using intermediate layers of the discriminator function. And a further set of objective functions is possible by framing this problem as one of density difference (rather than ratio) estimation (Sugiyama et al., 2013).\nThe other significant body of research that focusses on learning in implicit generative models using the lens of moment matching is approximate Bayesian computation (ABC) (Marin et al., 2012). The models in ABC are often related to problems in population genetics and ecology, where knowledge of these systems leads to ABC being easily exploited to learn simulator parameters. The ABC literature has widely-explored the use of test statistics, including fixed functions and kernels, and Markov chain Monte Carlo methods to learn the posterior distribution of the parameters. There is a great deal of opportunity for exchange between GANs, ABC and ratio estimation in aspects of scalability, applications, and theoretical understanding. A further insight obtained from a moment-matching approach is that other empirical measures such as the Dudley and Wasserstein distances can easily be considered, establishing even further connections to other growing areas, such as optimal transport (Frogner et al., 2015; Sriperumbudur et al., 2009).\nThe moment matching approach can be generalised by representing them as an integral probability metric (Sriperumbudur et al., 2009), which is what makes it possible to describe the relationships and ways of transforming from density ratio estimation using using moment-matching, f -divergences, and class-probability estimation. Sriperumbudur et al. (2009) showed that f -divergences and integral probability metrics (MMD, Wasserstein) intersect only at the total variation distance. As we described previously, by cleverly formulating our problem as a Bregman divergence minimisation, we show that all the methods we described for density ratio estimation are very closely related (Sugiyama et al., 2012a; Reid and Williamson, 2011; Sriperumbudur et al., 2009; Sugiyama et al., 2012b; Uehara et al., 2016)."
    }, {
      "heading" : "3 DISCUSSION",
      "text" : "By using an inferential principle driven by hypothesis testing, we have been able to develop a number of indirect methods for learning the parameters of generative models. These methods do not compute the probability of the data or posterior distributions over latent variables, but instead only involve relative statements of probability by comparing populations of data from the generative model to observed data. This view allows us to better understand how algorithms such as generative adversarial networks, approximate Bayesian computation, noise-contrastive estimation, and density ratio estimation are related. Ultimately, these techniques make it possible for us to make contributions to applications in climate and weather, economics, population genetics, and epidemiology, all areas whose principal tools are implicit generative models.\nDistinction between implicit and prescribed models. The distinction between implicit and prescribed models is useful to keep in mind for at least two reasons: the choice of model has direct implications on the types of learning and inferential principles that can be called upon; and it makes explicit that there are many different ways in which to specify a model that captures our beliefs about data generating processes. Any implicit model can be easily turned into a prescribed model by adding a simple likelihood function (noise model) on the generated outputs, so the distinction is\nnot essential. And models with likelihood functions also regularly face the problem of intractable marginal likelihoods. But the specification of a likelihood function provides knowledge of p∗ that leads to different algorithms by exploiting this knowledge, e.g., NCE resulting from class-probability based testing in un-normalised models (Gutmann and Hyvärinen, 2012), or variational lower bounds for directed graphical models. We strive to maintain a clear distinction between the choice of model, choice of inference, and the resulting algorithm, since it is through such a structured view that we can best recognise the connections between research areas that rely on the same sets of tools.\nModel misspecification and non-maximum likelihood methods. Once we have made the choice of an implicit generative model, we cannot use likelihood-based techniques, which then makes testing and estimation-by-comparison appealing. What is striking, is that this leads us to principles for parameter learning that do not require inference of any underlying latent variables, side-stepping one of the major challenges in statistical practice. This piques our interest in more general approaches for non-maximum likelihood and likelihood-free estimation methods, of which there is much work (Lyu, 2011; Gutmann and Hyvärinen, 2012; Hall, 2005; Marin et al., 2012; Frogner et al., 2015). We often deal with misspecified models where qθ cannot represent p∗, and non maximum likelihood methods could be a more robust choice depending on the task (see figure 1 in (Huszár, 2015) for an illustrative example).\nChoice of loss function. This density ratio viewpoint has led us to derive multiple different objective functions and an understanding of how they are related. But it has left us unsatisfied since we have not gained the insight needed to choose between them. Sugiyama et al. (2012a) make statements on this choice in the simpler setting where only the density ratio is to be estimated. But when we wish to learn implicit generative models, this choice, at present, remains unclear.\nPerceptual losses. Several authors have also proposed using pre-trained discriminative networks to define the test functions since the difference in activations (of say a pre-trained VGG classifier) can better capture perceptual similarity than the reconstruction error in pixel space. This provides a strong motivation for further research into joint models of images and labels. However, it is not completely unsupervised as the pre-trained discriminative network contains information about labels and invariances. This makes evaluation difficult since we lack good metrics and can only fairly compare to other joint models that use both label and image information.\nBayesian inference. We have mainly discussed point estimation methods for parameter learning. It is also desirable to perform Bayesian inference in implicit models, where we learn the posterior distribution over the model parameters p(θ|x), allowing knowledge of parameter uncertainty to be used in risk minimisation and other decision-making tasks. This is the aim of approximate Bayesian computation (ABC) (Marin et al., 2012). The most common approach for thinking about ABC is through moment-matching, but as we explored, there are other approaches available. An approach through class-probability estimation is appealing and leads to classifier ABC (Gutmann et al., 2014). We have highly diverse approaches for Bayesian reasoning in prescribed models, and it is desirable to develop a similar breadth of choice for implicit models.\nEvaluation. Our view suggests that value of the density ratio, a quantity we can always compute using the approaches described, can be a useful metric to report. But density ratio estimation has not yet illuminated a method for consistent evaluation of the generative model that is learnt. Without such a measure, it is hard to make fair comparisons; but this is a problem faced by all related fields, and establishing such measures is an important contribution to be made. Furthermore, we have also not yet gained the tools to make theoretical statements that allow us to assess the correctness of the model learning framework, although theoretical developments in the literature on approximate Bayesian computation may help in this regard, e.g., Frazier et al. (2016).\nNon-differentiable models. We have restricted our development to implicit models that are differentiable. In many practical applications, the implicit model (or simulator) will be non-differentiable, discrete or defined in other ways, such as through a stochastic differential equation . The stochastic optimisation problem we are generally faced with (for differentiable and non-differentiable models), is to compute ∆ = ∇θEqθ(x)[f(x)], the gradient of the expectation of a function. As our exposition followed, when the implicit model is differentiable, the pathwise derivative estimator can be used, i.e. ∆ = Eq(z)[∇θf(Gθ(z))] by rewriting the expectation in terms of the known and easy to sample distribution q(z). It is commonly assumed that when we encounter non-differentiable functions that the score function estimator (or likelihood ratio or reinforce estimator) can be used; the score-function\nestimator is ∆ = Eqθ(x)[f(x)∇θ log qθ(x)]. For implicit models, we do not have knowledge of the density q(x) whose log derivative we require, making this estimator inapplicable. This leads to the first of three tools available for non-differentiable models: the use of the weak derivative and related stochastic finite difference estimators, which require forward-simulation only and compute gradients by perturbation of the parameters (Glasserman, 2003; Fu, 2005).\nThe two other approaches are: moment matching and ABC-MCMC (Marjoram et al., 2003), which has been successful for many problems with moderate dimension; and the natural choice of gradientfree optimisation methods, which include familiar tools such as Bayesian optimisation (Gutmann and Corander, 2016), evolutionary search like CMA-ES, and the Nelder-Mead method, amongst others (Conn et al., 2009). For all three approaches, new insights will be needed to help scale to high-dimensional data with complex dependency structures.\nUltimately, these concerns serve to highlight the many opportunities that remain for advancing our understanding of inference and parameter learning in implicit generative models."
    } ],
    "references" : [ {
      "title" : "A general class of coefficients of divergence of one distribution from another",
      "author" : [ "S.M. Ali", "S.D. Silvey" ],
      "venue" : "Journal of the Royal Statistical Society. Series B (Methodological),",
      "citeRegEx" : "Ali and Silvey.,? \\Q1966\\E",
      "shortCiteRegEx" : "Ali and Silvey.",
      "year" : 1966
    }, {
      "title" : "Multi-task learning for HIV therapy screening",
      "author" : [ "S. Bickel", "J. Bogojeska", "T. Lengauer", "T. Scheffer" ],
      "venue" : "In Proceedings of the 25th international conference on Machine learning,",
      "citeRegEx" : "Bickel et al\\.,? \\Q2008\\E",
      "shortCiteRegEx" : "Bickel et al\\.",
      "year" : 2008
    }, {
      "title" : "Loss functions for binary class probability estimation and classification: Structure and applications",
      "author" : [ "A. Buja", "W. Stuetzle", "Y. Shen" ],
      "venue" : "Working draft,",
      "citeRegEx" : "Buja et al\\.,? \\Q2005\\E",
      "shortCiteRegEx" : "Buja et al\\.",
      "year" : 2005
    }, {
      "title" : "Fast two-sample testing with analytic representations of probability measures",
      "author" : [ "K.P. Chwialkowski", "A. Ramdas", "D. Sejdinovic", "A. Gretton" ],
      "venue" : "In Advances in Neural Information Processing Systems,",
      "citeRegEx" : "Chwialkowski et al\\.,? \\Q2015\\E",
      "shortCiteRegEx" : "Chwialkowski et al\\.",
      "year" : 2015
    }, {
      "title" : "An overview of bilevel optimization",
      "author" : [ "B. Colson", "P. Marcotte", "G. Savard" ],
      "venue" : "Annals of operations research,",
      "citeRegEx" : "Colson et al\\.,? \\Q2007\\E",
      "shortCiteRegEx" : "Colson et al\\.",
      "year" : 2007
    }, {
      "title" : "Introduction to derivative-free optimization, volume",
      "author" : [ "A.R. Conn", "K. Scheinberg", "L.N. Vicente" ],
      "venue" : null,
      "citeRegEx" : "Conn et al\\.,? \\Q2009\\E",
      "shortCiteRegEx" : "Conn et al\\.",
      "year" : 2009
    }, {
      "title" : "Approximating likelihood ratios with calibrated discriminative classifiers",
      "author" : [ "K. Cranmer", "J. Pavez", "G. Louppe" ],
      "venue" : "arXiv preprint arXiv:1506.02169,",
      "citeRegEx" : "Cranmer et al\\.,? \\Q2015\\E",
      "shortCiteRegEx" : "Cranmer et al\\.",
      "year" : 2015
    }, {
      "title" : "Task specific adversarial cost function",
      "author" : [ "A. Creswell", "A.A. Bharath" ],
      "venue" : "arXiv preprint arXiv:1609.08661,",
      "citeRegEx" : "Creswell and Bharath.,? \\Q2016\\E",
      "shortCiteRegEx" : "Creswell and Bharath.",
      "year" : 2016
    }, {
      "title" : "Information-type measures of difference of probability distributions and indirect observations",
      "author" : [ "I. Csiszàr" ],
      "venue" : "Studia Scientiarum Mathematicarum Hungarica,",
      "citeRegEx" : "Csiszàr.,? \\Q1967\\E",
      "shortCiteRegEx" : "Csiszàr.",
      "year" : 1967
    }, {
      "title" : "Non-uniform random variate generation",
      "author" : [ "L. Devroye" ],
      "venue" : "Handbooks in operations research and management science,",
      "citeRegEx" : "Devroye.,? \\Q2006\\E",
      "shortCiteRegEx" : "Devroye.",
      "year" : 2006
    }, {
      "title" : "Monte Carlo methods of inference for implicit statistical models",
      "author" : [ "P.J. Diggle", "R.J. Gratton" ],
      "venue" : "Journal of the Royal Statistical Society. Series B (Methodological),",
      "citeRegEx" : "Diggle and Gratton.,? \\Q1984\\E",
      "shortCiteRegEx" : "Diggle and Gratton.",
      "year" : 1984
    }, {
      "title" : "Training generative neural networks via maximum mean discrepancy optimization",
      "author" : [ "G.K. Dziugaite", "D.M. Roy", "Z. Ghahramani" ],
      "venue" : "arXiv preprint arXiv:1505.03906,",
      "citeRegEx" : "Dziugaite et al\\.,? \\Q2015\\E",
      "shortCiteRegEx" : "Dziugaite et al\\.",
      "year" : 2015
    }, {
      "title" : "Asymptotic properties of approximate Bayesian computation",
      "author" : [ "D.T. Frazier", "G.M. Martin", "C.P. Robert", "J. Rousseau" ],
      "venue" : "arXiv preprint arXiv:1607.06903,",
      "citeRegEx" : "Frazier et al\\.,? \\Q2016\\E",
      "shortCiteRegEx" : "Frazier et al\\.",
      "year" : 2016
    }, {
      "title" : "Learning with a Wasserstein loss",
      "author" : [ "C. Frogner", "C. Zhang", "H. Mobahi", "M. Araya", "T.A. Poggio" ],
      "venue" : "In Advances in Neural Information Processing Systems,",
      "citeRegEx" : "Frogner et al\\.,? \\Q2015\\E",
      "shortCiteRegEx" : "Frogner et al\\.",
      "year" : 2015
    }, {
      "title" : "Stochastic gradient estimation",
      "author" : [ "M.C. Fu" ],
      "venue" : "Technical report, DTIC Document,",
      "citeRegEx" : "Fu.,? \\Q2005\\E",
      "shortCiteRegEx" : "Fu.",
      "year" : 2005
    }, {
      "title" : "The estimation of the gradient of a density function, with applications in pattern recognition",
      "author" : [ "K. Fukunaga", "L. Hostetler" ],
      "venue" : "IEEE Transactions on information theory,",
      "citeRegEx" : "Fukunaga and Hostetler.,? \\Q1975\\E",
      "shortCiteRegEx" : "Fukunaga and Hostetler.",
      "year" : 1975
    }, {
      "title" : "Monte Carlo methods in financial engineering, volume 53",
      "author" : [ "P. Glasserman" ],
      "venue" : "Springer Science & Business Media,",
      "citeRegEx" : "Glasserman.,? \\Q2003\\E",
      "shortCiteRegEx" : "Glasserman.",
      "year" : 2003
    }, {
      "title" : "Strictly proper scoring rules, prediction, and estimation",
      "author" : [ "T. Gneiting", "A.E. Raftery" ],
      "venue" : "Journal of the American Statistical Association,",
      "citeRegEx" : "Gneiting and Raftery.,? \\Q2007\\E",
      "shortCiteRegEx" : "Gneiting and Raftery.",
      "year" : 2007
    }, {
      "title" : "Generative adversarial nets",
      "author" : [ "I. Goodfellow", "J. Pouget-Abadie", "M. Mirza", "B. Xu", "D. Warde-Farley", "S. Ozair", "A. Courville", "Y. Bengio" ],
      "venue" : "In Advances in Neural Information Processing Systems,",
      "citeRegEx" : "Goodfellow et al\\.,? \\Q2014\\E",
      "shortCiteRegEx" : "Goodfellow et al\\.",
      "year" : 2014
    }, {
      "title" : "Bayesian optimization for likelihood-free inference of simulatorbased statistical models",
      "author" : [ "M.U. Gutmann", "J. Corander" ],
      "venue" : "Journal of Machine Learning Research,",
      "citeRegEx" : "Gutmann and Corander.,? \\Q2016\\E",
      "shortCiteRegEx" : "Gutmann and Corander.",
      "year" : 2016
    }, {
      "title" : "Noise-contrastive estimation of unnormalized statistical models, with applications to natural image statistics",
      "author" : [ "M.U. Gutmann", "A. Hyvärinen" ],
      "venue" : "Journal of Machine Learning Research,",
      "citeRegEx" : "Gutmann and Hyvärinen.,? \\Q2012\\E",
      "shortCiteRegEx" : "Gutmann and Hyvärinen.",
      "year" : 2012
    }, {
      "title" : "Statistical inference of intractable generative models via classification",
      "author" : [ "M.U. Gutmann", "R. Dutta", "S. Kaski", "J. Corander" ],
      "venue" : "arXiv preprint arXiv:1407.4981,",
      "citeRegEx" : "Gutmann et al\\.,? \\Q2014\\E",
      "shortCiteRegEx" : "Gutmann et al\\.",
      "year" : 2014
    }, {
      "title" : "Generalized method of moments",
      "author" : [ "A.R. Hall" ],
      "venue" : null,
      "citeRegEx" : "Hall.,? \\Q2005\\E",
      "shortCiteRegEx" : "Hall.",
      "year" : 2005
    }, {
      "title" : "The elements of statistical learning. Springer, pp 495–497",
      "author" : [ "T. Hastie", "R. Tibshirani", "J. Friedman" ],
      "venue" : "10th printing,",
      "citeRegEx" : "Hastie et al\\.,? \\Q2013\\E",
      "shortCiteRegEx" : "Hastie et al\\.",
      "year" : 2013
    }, {
      "title" : "How (not) to train your generative model: Scheduled sampling, likelihood, adversary",
      "author" : [ "F. Huszár" ],
      "venue" : "arXiv preprint arXiv:1511.05101,",
      "citeRegEx" : "Huszár.,? \\Q2015\\E",
      "shortCiteRegEx" : "Huszár.",
      "year" : 2015
    }, {
      "title" : "Bayes factors",
      "author" : [ "R.E. Kass", "A.E. Raftery" ],
      "venue" : "Journal of the american statistical association,",
      "citeRegEx" : "Kass and Raftery.,? \\Q1995\\E",
      "shortCiteRegEx" : "Kass and Raftery.",
      "year" : 1995
    }, {
      "title" : "Generative moment matching networks",
      "author" : [ "Y. Li", "K. Swersky", "R. Zemel" ],
      "venue" : "In International Conference on Machine Learning,",
      "citeRegEx" : "Li et al\\.,? \\Q2015\\E",
      "shortCiteRegEx" : "Li et al\\.",
      "year" : 2015
    }, {
      "title" : "divergences: Sufficiency, deficiency and testing of hypotheses",
      "author" : [ "F. Liese", "I. Vajda" ],
      "venue" : "Advances in Inequalities from Probability Theory and Statistics,",
      "citeRegEx" : "Liese and Vajda.,? \\Q2008\\E",
      "shortCiteRegEx" : "Liese and Vajda.",
      "year" : 2008
    }, {
      "title" : "Revisiting classifier two-sample tests for GAN evaluation and causal discovery",
      "author" : [ "D. Lopez-Paz", "M. Oquab" ],
      "venue" : "arXiv preprint arXiv:1610.06545,",
      "citeRegEx" : "Lopez.Paz and Oquab.,? \\Q2016\\E",
      "shortCiteRegEx" : "Lopez.Paz and Oquab.",
      "year" : 2016
    }, {
      "title" : "Unifying non-maximum likelihood learning objectives with minimum KL contraction",
      "author" : [ "S. Lyu" ],
      "venue" : "In Advances in Neural Information Processing Systems,",
      "citeRegEx" : "Lyu.,? \\Q2011\\E",
      "shortCiteRegEx" : "Lyu.",
      "year" : 2011
    }, {
      "title" : "Approximate Bayesian computational methods",
      "author" : [ "J.-M. Marin", "P. Pudlo", "C.P. Robert", "R.J. Ryder" ],
      "venue" : "Statistics and Computing,",
      "citeRegEx" : "Marin et al\\.,? \\Q2012\\E",
      "shortCiteRegEx" : "Marin et al\\.",
      "year" : 2012
    }, {
      "title" : "Markov chain Monte Carlo without likelihoods",
      "author" : [ "P. Marjoram", "J. Molitor", "V. Plagnol", "S. Tavaré" ],
      "venue" : "Proceedings of the National Academy of Sciences,",
      "citeRegEx" : "Marjoram et al\\.,? \\Q2003\\E",
      "shortCiteRegEx" : "Marjoram et al\\.",
      "year" : 2003
    }, {
      "title" : "Linking losses for density ratio and class-probability estimation",
      "author" : [ "A. Menon", "C.S. Ong" ],
      "venue" : "In Proceedings of The 33rd International Conference on Machine Learning,",
      "citeRegEx" : "Menon and Ong.,? \\Q2016\\E",
      "shortCiteRegEx" : "Menon and Ong.",
      "year" : 2016
    }, {
      "title" : "Divergence measures and message passing",
      "author" : [ "T. Minka" ],
      "venue" : "Technical report,",
      "citeRegEx" : "Minka.,? \\Q2005\\E",
      "shortCiteRegEx" : "Minka.",
      "year" : 2005
    }, {
      "title" : "Computing likelihood functions for high-energy physics experiments when distributions are defined by simulators with nuisance parameters",
      "author" : [ "R.M. Neal" ],
      "venue" : "In PHYSTAT LHC Workshop on Statistical Issues for LHC Physics,",
      "citeRegEx" : "Neal.,? \\Q2008\\E",
      "shortCiteRegEx" : "Neal.",
      "year" : 2008
    }, {
      "title" : "GAN: Training generative neural samplers using variational divergence minimization",
      "author" : [ "S. Nowozin", "B. Cseke", "R. Tomioka" ],
      "venue" : "arXiv preprint arXiv:1606.00709,",
      "citeRegEx" : "Nowozin et al\\.,? \\Q2016\\E",
      "shortCiteRegEx" : "Nowozin et al\\.",
      "year" : 2016
    }, {
      "title" : "Empirical likelihood ratio confidence intervals for a single functional",
      "author" : [ "A.B. Owen" ],
      "venue" : null,
      "citeRegEx" : "Owen.,? \\Q1988\\E",
      "shortCiteRegEx" : "Owen.",
      "year" : 1988
    }, {
      "title" : "Inferences for case-control and semiparametric two-sample density ratio models",
      "author" : [ "J. Qin" ],
      "venue" : null,
      "citeRegEx" : "Qin.,? \\Q1998\\E",
      "shortCiteRegEx" : "Qin.",
      "year" : 1998
    }, {
      "title" : "Unsupervised representation learning with deep convolutional generative adversarial networks",
      "author" : [ "A. Radford", "L. Metz", "S. Chintala" ],
      "venue" : "arXiv preprint arXiv:1511.06434,",
      "citeRegEx" : "Radford et al\\.,? \\Q2015\\E",
      "shortCiteRegEx" : "Radford et al\\.",
      "year" : 2015
    }, {
      "title" : "Information, divergence and risk for binary experiments",
      "author" : [ "M.D. Reid", "R.C. Williamson" ],
      "venue" : "Journal of Machine Learning Research,",
      "citeRegEx" : "Reid and Williamson.,? \\Q2011\\E",
      "shortCiteRegEx" : "Reid and Williamson.",
      "year" : 2011
    }, {
      "title" : "Improved techniques for training GANs",
      "author" : [ "T. Salimans", "I. Goodfellow", "W. Zaremba", "V. Cheung", "A. Radford", "X. Chen" ],
      "venue" : "arXiv preprint arXiv:1606.03498,",
      "citeRegEx" : "Salimans et al\\.,? \\Q2016\\E",
      "shortCiteRegEx" : "Salimans et al\\.",
      "year" : 2016
    }, {
      "title" : "Amortised MAP inference for image super-resolution",
      "author" : [ "C.K. Sønderby", "J. Caballero", "L. Theis", "W. Shi", "F. Huszár" ],
      "venue" : "arXiv preprint arXiv:1610.04490,",
      "citeRegEx" : "Sønderby et al\\.,? \\Q2016\\E",
      "shortCiteRegEx" : "Sønderby et al\\.",
      "year" : 2016
    }, {
      "title" : "On integral probability metrics, φ-divergences and binary classification",
      "author" : [ "B.K. Sriperumbudur", "K. Fukumizu", "A. Gretton", "B. Schölkopf", "G.R. Lanckriet" ],
      "venue" : "arXiv preprint arXiv:0901.2698,",
      "citeRegEx" : "Sriperumbudur et al\\.,? \\Q2009\\E",
      "shortCiteRegEx" : "Sriperumbudur et al\\.",
      "year" : 2009
    }, {
      "title" : "Density-ratio matching under the Bregman divergence: a unified framework of density-ratio estimation",
      "author" : [ "M. Sugiyama", "T. Suzuki", "T. Kanamori" ],
      "venue" : "Annals of the Institute of Statistical Mathematics,",
      "citeRegEx" : "Sugiyama et al\\.,? \\Q2012\\E",
      "shortCiteRegEx" : "Sugiyama et al\\.",
      "year" : 2012
    }, {
      "title" : "Density ratio estimation in machine learning",
      "author" : [ "M. Sugiyama", "T. Suzuki", "T. Kanamori" ],
      "venue" : null,
      "citeRegEx" : "Sugiyama et al\\.,? \\Q2012\\E",
      "shortCiteRegEx" : "Sugiyama et al\\.",
      "year" : 2012
    }, {
      "title" : "Density-difference estimation",
      "author" : [ "M. Sugiyama", "T. Kanamori", "T. Suzuki", "M.C. du Plessis", "S. Liu", "I. Takeuchi" ],
      "venue" : "Neural Computation,",
      "citeRegEx" : "Sugiyama et al\\.,? \\Q2013\\E",
      "shortCiteRegEx" : "Sugiyama et al\\.",
      "year" : 2013
    }, {
      "title" : "Generative adversarial nets from a density ratio estimation perspective",
      "author" : [ "M. Uehara", "I. Sato", "M. Suzuki", "K. Nakayama", "Y. Matsuo" ],
      "venue" : "arXiv preprint arXiv:1610.02920,",
      "citeRegEx" : "Uehara et al\\.,? \\Q2016\\E",
      "shortCiteRegEx" : "Uehara et al\\.",
      "year" : 2016
    }, {
      "title" : "Energy-based generative adversarial network",
      "author" : [ "J. Zhao", "M. Mathieu", "Y. LeCun" ],
      "venue" : "arXiv preprint arXiv:1609.03126,",
      "citeRegEx" : "Zhao et al\\.,? \\Q2016\\E",
      "shortCiteRegEx" : "Zhao et al\\.",
      "year" : 2016
    } ],
    "referenceMentions" : [ {
      "referenceID" : 10,
      "context" : "1 IMPLICIT GENERATIVE MODELS It is useful to make a distinction between two types of probabilistic models: prescribed and implicit models (Diggle and Gratton, 1984).",
      "startOffset" : 138,
      "endOffset" : 164
    }, {
      "referenceID" : 9,
      "context" : ", many of the basic methods for generating non-uniform random variates are based on simple implicit models and one-line transformations (Devroye, 2006).",
      "startOffset" : 136,
      "endOffset" : 151
    }, {
      "referenceID" : 18,
      "context" : "Generative adversarial networks (GANs) (Goodfellow et al., 2014) provide a solution for exactly this type of problem.",
      "startOffset" : 39,
      "endOffset" : 64
    }, {
      "referenceID" : 22,
      "context" : "But there are tools that remain, including the method-of-moments (Hall, 2005), the empirical likelihood (Owen, 1988), Monte Carlo sampling (Marin et al.",
      "startOffset" : 65,
      "endOffset" : 77
    }, {
      "referenceID" : 36,
      "context" : "But there are tools that remain, including the method-of-moments (Hall, 2005), the empirical likelihood (Owen, 1988), Monte Carlo sampling (Marin et al.",
      "startOffset" : 104,
      "endOffset" : 116
    }, {
      "referenceID" : 30,
      "context" : "But there are tools that remain, including the method-of-moments (Hall, 2005), the empirical likelihood (Owen, 1988), Monte Carlo sampling (Marin et al., 2012), and mean-shift estimation (Fukunaga and Hostetler, 1975).",
      "startOffset" : 139,
      "endOffset" : 159
    }, {
      "referenceID" : 15,
      "context" : ", 2012), and mean-shift estimation (Fukunaga and Hostetler, 1975).",
      "startOffset" : 35,
      "endOffset" : 65
    }, {
      "referenceID" : 25,
      "context" : "The density ratio r(x) is the core quantity for hypothesis testing, motivated by either the NeymanPearson lemma or the Bayesian posterior evidence, appearing as the likelihood ratio or the Bayes factor (Kass and Raftery, 1995), respectively.",
      "startOffset" : 202,
      "endOffset" : 226
    }, {
      "referenceID" : 21,
      "context" : "Hastie et al. (2013) call this approach unsupervised-assupervised learning, Qin (1998) explore this for analysis of case-control in observational studies, both Neal (2008) and Cranmer et al.",
      "startOffset" : 0,
      "endOffset" : 21
    }, {
      "referenceID" : 21,
      "context" : "Hastie et al. (2013) call this approach unsupervised-assupervised learning, Qin (1998) explore this for analysis of case-control in observational studies, both Neal (2008) and Cranmer et al.",
      "startOffset" : 0,
      "endOffset" : 87
    }, {
      "referenceID" : 21,
      "context" : "Hastie et al. (2013) call this approach unsupervised-assupervised learning, Qin (1998) explore this for analysis of case-control in observational studies, both Neal (2008) and Cranmer et al.",
      "startOffset" : 0,
      "endOffset" : 172
    }, {
      "referenceID" : 6,
      "context" : "(2013) call this approach unsupervised-assupervised learning, Qin (1998) explore this for analysis of case-control in observational studies, both Neal (2008) and Cranmer et al. (2015) explore this approach for high-energy physics applications, Gutmann and Hyvärinen (2012) exploit it for learning un-normalised models, Lopez-Paz and Oquab",
      "startOffset" : 162,
      "endOffset" : 184
    }, {
      "referenceID" : 6,
      "context" : "(2013) call this approach unsupervised-assupervised learning, Qin (1998) explore this for analysis of case-control in observational studies, both Neal (2008) and Cranmer et al. (2015) explore this approach for high-energy physics applications, Gutmann and Hyvärinen (2012) exploit it for learning un-normalised models, Lopez-Paz and Oquab",
      "startOffset" : 162,
      "endOffset" : 273
    }, {
      "referenceID" : 18,
      "context" : "(2016) for causal discovery, and Goodfellow et al. (2014) for learning in implicit generative models specified by neural networks.",
      "startOffset" : 33,
      "endOffset" : 58
    }, {
      "referenceID" : 17,
      "context" : "Given this scoring function, we must specify a proper scoring rule (Gneiting and Raftery, 2007; Buja et al., 2005) for binary discrimination to allow for parameter learning, such as those in Table 1.",
      "startOffset" : 67,
      "endOffset" : 114
    }, {
      "referenceID" : 2,
      "context" : "Given this scoring function, we must specify a proper scoring rule (Gneiting and Raftery, 2007; Buja et al., 2005) for binary discrimination to allow for parameter learning, such as those in Table 1.",
      "startOffset" : 67,
      "endOffset" : 114
    }, {
      "referenceID" : 18,
      "context" : "The final form of this objective (6) is exactly that used in generative adversarial networks (GANs) (Goodfellow et al., 2014).",
      "startOffset" : 100,
      "endOffset" : 125
    }, {
      "referenceID" : 4,
      "context" : "Equation (6) allows us to specify a bi-level optimisation (Colson et al., 2007) by forming a ratio loss and a generative loss, using which we perform an alternating optimisation.",
      "startOffset" : 58,
      "endOffset" : 79
    }, {
      "referenceID" : 18,
      "context" : "While we can derive the generative loss from the ratio loss as we have done, any generative loss that drives qθ to p∗, such as minimising the widely-used Eq(z)[− logD(G(z;θ))] (Goodfellow et al., 2014; Nowozin et al., 2016) or Eq(z)[− log D(G(z;θ)) 1−D(G(z;θ)) ] = Eq(z)[− log r(G(z;θ)) (Sønderby et al.",
      "startOffset" : 176,
      "endOffset" : 223
    }, {
      "referenceID" : 35,
      "context" : "While we can derive the generative loss from the ratio loss as we have done, any generative loss that drives qθ to p∗, such as minimising the widely-used Eq(z)[− logD(G(z;θ))] (Goodfellow et al., 2014; Nowozin et al., 2016) or Eq(z)[− log D(G(z;θ)) 1−D(G(z;θ)) ] = Eq(z)[− log r(G(z;θ)) (Sønderby et al.",
      "startOffset" : 176,
      "endOffset" : 223
    }, {
      "referenceID" : 41,
      "context" : ", 2016) or Eq(z)[− log D(G(z;θ)) 1−D(G(z;θ)) ] = Eq(z)[− log r(G(z;θ)) (Sønderby et al., 2016), is possible.",
      "startOffset" : 71,
      "endOffset" : 94
    }, {
      "referenceID" : 40,
      "context" : "(2014), along with many of the insights for optimisation that have been developed since (Salimans et al., 2016; Radford et al., 2015; Zhao et al., 2016; Sønderby et al., 2016).",
      "startOffset" : 88,
      "endOffset" : 175
    }, {
      "referenceID" : 38,
      "context" : "(2014), along with many of the insights for optimisation that have been developed since (Salimans et al., 2016; Radford et al., 2015; Zhao et al., 2016; Sønderby et al., 2016).",
      "startOffset" : 88,
      "endOffset" : 175
    }, {
      "referenceID" : 47,
      "context" : "(2014), along with many of the insights for optimisation that have been developed since (Salimans et al., 2016; Radford et al., 2015; Zhao et al., 2016; Sønderby et al., 2016).",
      "startOffset" : 88,
      "endOffset" : 175
    }, {
      "referenceID" : 41,
      "context" : "(2014), along with many of the insights for optimisation that have been developed since (Salimans et al., 2016; Radford et al., 2015; Zhao et al., 2016; Sønderby et al., 2016).",
      "startOffset" : 88,
      "endOffset" : 175
    }, {
      "referenceID" : 17,
      "context" : "The Brier loss provides a similar decision rule, and its use in calibrated regression makes it appealing; the motivations behind many of these scoring rules are discussed in (Gneiting and Raftery, 2007).",
      "startOffset" : 174,
      "endOffset" : 202
    }, {
      "referenceID" : 1,
      "context" : "Finally, while we have focussed on the two sample hypothesis test, we believe it could be advantageous to extend this reasoning to the case of multiple testing, where we simultaneously test several sets of data (Bickel et al., 2008).",
      "startOffset" : 211,
      "endOffset" : 232
    }, {
      "referenceID" : 18,
      "context" : "the proof in (Goodfellow et al., 2014) for the Bernoulli loss); however there are no convergence guarantees since the optimisation is non-convex.",
      "startOffset" : 13,
      "endOffset" : 38
    }, {
      "referenceID" : 15,
      "context" : "These rules are amenable to stochastic approximation and alternating optimisation, as described by Goodfellow et al. (2014), along with many of the insights for optimisation that have been developed since (Salimans et al.",
      "startOffset" : 99,
      "endOffset" : 124
    }, {
      "referenceID" : 1,
      "context" : "Finally, while we have focussed on the two sample hypothesis test, we believe it could be advantageous to extend this reasoning to the case of multiple testing, where we simultaneously test several sets of data (Bickel et al., 2008). The advantage of using a proper scoring rule is that the global optimum is achieved iff qθ = p∗ (cf. the proof in (Goodfellow et al., 2014) for the Bernoulli loss); however there are no convergence guarantees since the optimisation is non-convex. Goodfellow et al. (2014) discuss the relationship to maximum likelihood estimation, which minimises the divergence KL[p∗‖q], and show that the GAN objective with Bernoulli loss is instead related to the Jensen Shannon divergence JS [p∗||q].",
      "startOffset" : 212,
      "endOffset" : 506
    }, {
      "referenceID" : 1,
      "context" : "Finally, while we have focussed on the two sample hypothesis test, we believe it could be advantageous to extend this reasoning to the case of multiple testing, where we simultaneously test several sets of data (Bickel et al., 2008). The advantage of using a proper scoring rule is that the global optimum is achieved iff qθ = p∗ (cf. the proof in (Goodfellow et al., 2014) for the Bernoulli loss); however there are no convergence guarantees since the optimisation is non-convex. Goodfellow et al. (2014) discuss the relationship to maximum likelihood estimation, which minimises the divergence KL[p∗‖q], and show that the GAN objective with Bernoulli loss is instead related to the Jensen Shannon divergence JS [p∗||q]. In the objective (6), π denotes the marginal probability of the positive class; however several authors have proposed choosing π depending on the problem. In particular, Huszár (2015) showed that varying π is related to optimizing a generalised Jensen-Shannon divergence JSπ [p∗||q].",
      "startOffset" : 212,
      "endOffset" : 906
    }, {
      "referenceID" : 1,
      "context" : "Finally, while we have focussed on the two sample hypothesis test, we believe it could be advantageous to extend this reasoning to the case of multiple testing, where we simultaneously test several sets of data (Bickel et al., 2008). The advantage of using a proper scoring rule is that the global optimum is achieved iff qθ = p∗ (cf. the proof in (Goodfellow et al., 2014) for the Bernoulli loss); however there are no convergence guarantees since the optimisation is non-convex. Goodfellow et al. (2014) discuss the relationship to maximum likelihood estimation, which minimises the divergence KL[p∗‖q], and show that the GAN objective with Bernoulli loss is instead related to the Jensen Shannon divergence JS [p∗||q]. In the objective (6), π denotes the marginal probability of the positive class; however several authors have proposed choosing π depending on the problem. In particular, Huszár (2015) showed that varying π is related to optimizing a generalised Jensen-Shannon divergence JSπ [p∗||q]. Creswell and Bharath (2016) presented results showing that different values of π are desirable, depending on whether we wish to fit one of the modes (a ‘high precision, low recall’ task such as generation) or explain all of the modes (a ‘high recall, low precision’ task such as retrieval).",
      "startOffset" : 212,
      "endOffset" : 1034
    }, {
      "referenceID" : 0,
      "context" : "A natural class of divergences to use are the f -divergences (or Ali-Silvey (Ali and Silvey, 1966) or Csiszar’s φ-divergence (Csiszàr, 1967)) since they are fundamentally linked to the problem of two-sample hypothesis testing (Liese and Vajda, 2008): f -divergences represent an integrated Bayes risk since they are an expectation of the density ratio.",
      "startOffset" : 76,
      "endOffset" : 98
    }, {
      "referenceID" : 8,
      "context" : "A natural class of divergences to use are the f -divergences (or Ali-Silvey (Ali and Silvey, 1966) or Csiszar’s φ-divergence (Csiszàr, 1967)) since they are fundamentally linked to the problem of two-sample hypothesis testing (Liese and Vajda, 2008): f -divergences represent an integrated Bayes risk since they are an expectation of the density ratio.",
      "startOffset" : 125,
      "endOffset" : 140
    }, {
      "referenceID" : 27,
      "context" : "A natural class of divergences to use are the f -divergences (or Ali-Silvey (Ali and Silvey, 1966) or Csiszar’s φ-divergence (Csiszàr, 1967)) since they are fundamentally linked to the problem of two-sample hypothesis testing (Liese and Vajda, 2008): f -divergences represent an integrated Bayes risk since they are an expectation of the density ratio.",
      "startOffset" : 226,
      "endOffset" : 249
    }, {
      "referenceID" : 0,
      "context" : "A natural class of divergences to use are the f -divergences (or Ali-Silvey (Ali and Silvey, 1966) or Csiszar’s φ-divergence (Csiszàr, 1967)) since they are fundamentally linked to the problem of two-sample hypothesis testing (Liese and Vajda, 2008): f -divergences represent an integrated Bayes risk since they are an expectation of the density ratio. Nowozin et al. (2016) develop f -GANs using this view.",
      "startOffset" : 77,
      "endOffset" : 375
    }, {
      "referenceID" : 33,
      "context" : "where the first equation is the KL for un-normalised densities (Minka, 2005).",
      "startOffset" : 63,
      "endOffset" : 76
    }, {
      "referenceID" : 32,
      "context" : "where the first equation is the KL for un-normalised densities (Minka, 2005). This leads to a convenient and valid ratio loss since all terms independent of r can be ignored. But we are unable to derive a useful generative loss from this expression (14) , since the third term with log q cannot be ignored, and is unavailable. Since the generative loss and ratio losses need not be coupled, any other generative loss can be used, e.g., equation (8). But this is not ideal, since we would prefer to derive valid ratio losses from the same principle to make reasoning about correctness and optimality easier. We include this discussion to point out that while the formulation of equation (9) is generally applicable, the formulation (14), while useful for ratio estimation, is not useful for generative learning. The difficulty of specifying stable and correct generative losses is a common theme of work in GANs; we will see a similar difficulty in the next section. The equivalence between divergence minimisation and class probability estimation is also widely discussed, and most notably developed by Reid and Williamson (2011) using the tools of weighted integral measures, and more recently by Menon and Ong (2016).",
      "startOffset" : 64,
      "endOffset" : 1130
    }, {
      "referenceID" : 32,
      "context" : "The equivalence between divergence minimisation and class probability estimation is also widely discussed, and most notably developed by Reid and Williamson (2011) using the tools of weighted integral measures, and more recently by Menon and Ong (2016). This divergence minimisation viewpoint (9) was used in f -GANs and explored in depth by Nowozin et al.",
      "startOffset" : 232,
      "endOffset" : 253
    }, {
      "referenceID" : 32,
      "context" : "The equivalence between divergence minimisation and class probability estimation is also widely discussed, and most notably developed by Reid and Williamson (2011) using the tools of weighted integral measures, and more recently by Menon and Ong (2016). This divergence minimisation viewpoint (9) was used in f -GANs and explored in depth by Nowozin et al. (2016) who provide a detailed description, and explore many of the objectives that become available and practical guidance.",
      "startOffset" : 232,
      "endOffset" : 364
    }, {
      "referenceID" : 18,
      "context" : "(2016) recognised the centrality of the density ratio, the approach for learning by ratio matching, and its connections to GANs (Goodfellow et al., 2014) and f -GANs (Nowozin et al.",
      "startOffset" : 128,
      "endOffset" : 153
    }, {
      "referenceID" : 35,
      "context" : ", 2014) and f -GANs (Nowozin et al., 2016), and provide useful guidance on practical use of ratio matching.",
      "startOffset" : 20,
      "endOffset" : 42
    }, {
      "referenceID" : 46,
      "context" : "We can generalise (16) to loss functions beyond the squared error using the Bregman divergence for density ratio estimation (Sugiyama et al., 2012a; Uehara et al., 2016), and is the unifying tool exploited in previous work (Reid and Williamson, 2011; Sriperumbudur et al.",
      "startOffset" : 124,
      "endOffset" : 169
    }, {
      "referenceID" : 39,
      "context" : ", 2016), and is the unifying tool exploited in previous work (Reid and Williamson, 2011; Sriperumbudur et al., 2009; Sugiyama et al., 2012a; Menon and Ong, 2016).",
      "startOffset" : 61,
      "endOffset" : 161
    }, {
      "referenceID" : 42,
      "context" : ", 2016), and is the unifying tool exploited in previous work (Reid and Williamson, 2011; Sriperumbudur et al., 2009; Sugiyama et al., 2012a; Menon and Ong, 2016).",
      "startOffset" : 61,
      "endOffset" : 161
    }, {
      "referenceID" : 32,
      "context" : ", 2016), and is the unifying tool exploited in previous work (Reid and Williamson, 2011; Sriperumbudur et al., 2009; Sugiyama et al., 2012a; Menon and Ong, 2016).",
      "startOffset" : 61,
      "endOffset" : 161
    }, {
      "referenceID" : 38,
      "context" : "When used to learn the ratio function, Sugiyama et al. (2012b) refer to this objective as KL importance estimation procedure (KLIEP).",
      "startOffset" : 39,
      "endOffset" : 63
    }, {
      "referenceID" : 38,
      "context" : "When used to learn the ratio function, Sugiyama et al. (2012b) refer to this objective as KL importance estimation procedure (KLIEP). Concurrently with this work, Uehara et al. (2016) recognised the centrality of the density ratio, the approach for learning by ratio matching, and its connections to GANs (Goodfellow et al.",
      "startOffset" : 39,
      "endOffset" : 184
    }, {
      "referenceID" : 46,
      "context" : "This ratio loss, as pointed out by Uehara et al. (2016), is equivalent to the ratio loss we derived using divergence minimisation (10), since:",
      "startOffset" : 35,
      "endOffset" : 56
    }, {
      "referenceID" : 46,
      "context" : "One approximation suggested by Uehara et al. (2016) is to assume p∗≈ rφqθ, i.",
      "startOffset" : 31,
      "endOffset" : 52
    }, {
      "referenceID" : 3,
      "context" : "While typically expensive to compute, there are now highly efficient approaches for computing the MMD (Chwialkowski et al., 2015).",
      "startOffset" : 102,
      "endOffset" : 129
    }, {
      "referenceID" : 45,
      "context" : "And a further set of objective functions is possible by framing this problem as one of density difference (rather than ratio) estimation (Sugiyama et al., 2013).",
      "startOffset" : 137,
      "endOffset" : 160
    }, {
      "referenceID" : 30,
      "context" : "The other significant body of research that focusses on learning in implicit generative models using the lens of moment matching is approximate Bayesian computation (ABC) (Marin et al., 2012).",
      "startOffset" : 171,
      "endOffset" : 191
    }, {
      "referenceID" : 13,
      "context" : "A further insight obtained from a moment-matching approach is that other empirical measures such as the Dudley and Wasserstein distances can easily be considered, establishing even further connections to other growing areas, such as optimal transport (Frogner et al., 2015; Sriperumbudur et al., 2009).",
      "startOffset" : 251,
      "endOffset" : 301
    }, {
      "referenceID" : 42,
      "context" : "A further insight obtained from a moment-matching approach is that other empirical measures such as the Dudley and Wasserstein distances can easily be considered, establishing even further connections to other growing areas, such as optimal transport (Frogner et al., 2015; Sriperumbudur et al., 2009).",
      "startOffset" : 251,
      "endOffset" : 301
    }, {
      "referenceID" : 42,
      "context" : "The moment matching approach can be generalised by representing them as an integral probability metric (Sriperumbudur et al., 2009), which is what makes it possible to describe the relationships and ways of transforming from density ratio estimation using using moment-matching, f -divergences, and class-probability estimation.",
      "startOffset" : 103,
      "endOffset" : 131
    }, {
      "referenceID" : 39,
      "context" : "As we described previously, by cleverly formulating our problem as a Bregman divergence minimisation, we show that all the methods we described for density ratio estimation are very closely related (Sugiyama et al., 2012a; Reid and Williamson, 2011; Sriperumbudur et al., 2009; Sugiyama et al., 2012b; Uehara et al., 2016).",
      "startOffset" : 198,
      "endOffset" : 322
    }, {
      "referenceID" : 42,
      "context" : "As we described previously, by cleverly formulating our problem as a Bregman divergence minimisation, we show that all the methods we described for density ratio estimation are very closely related (Sugiyama et al., 2012a; Reid and Williamson, 2011; Sriperumbudur et al., 2009; Sugiyama et al., 2012b; Uehara et al., 2016).",
      "startOffset" : 198,
      "endOffset" : 322
    }, {
      "referenceID" : 46,
      "context" : "As we described previously, by cleverly formulating our problem as a Bregman divergence minimisation, we show that all the methods we described for density ratio estimation are very closely related (Sugiyama et al., 2012a; Reid and Williamson, 2011; Sriperumbudur et al., 2009; Sugiyama et al., 2012b; Uehara et al., 2016).",
      "startOffset" : 198,
      "endOffset" : 322
    }, {
      "referenceID" : 23,
      "context" : "The role of the MMD for learning in implicit generative models defined by neural networks has been explored by both Li et al. (2015) and Dziugaite et al.",
      "startOffset" : 116,
      "endOffset" : 133
    }, {
      "referenceID" : 10,
      "context" : "(2015) and Dziugaite et al. (2015). While typically expensive to compute, there are now highly efficient approaches for computing the MMD (Chwialkowski et al.",
      "startOffset" : 11,
      "endOffset" : 35
    }, {
      "referenceID" : 3,
      "context" : "While typically expensive to compute, there are now highly efficient approaches for computing the MMD (Chwialkowski et al., 2015). The objective using feature matching by Salimans et al. (2016) is a form of moment matching that defines the test statistics using intermediate layers of the discriminator function.",
      "startOffset" : 103,
      "endOffset" : 194
    }, {
      "referenceID" : 3,
      "context" : "While typically expensive to compute, there are now highly efficient approaches for computing the MMD (Chwialkowski et al., 2015). The objective using feature matching by Salimans et al. (2016) is a form of moment matching that defines the test statistics using intermediate layers of the discriminator function. And a further set of objective functions is possible by framing this problem as one of density difference (rather than ratio) estimation (Sugiyama et al., 2013). The other significant body of research that focusses on learning in implicit generative models using the lens of moment matching is approximate Bayesian computation (ABC) (Marin et al., 2012). The models in ABC are often related to problems in population genetics and ecology, where knowledge of these systems leads to ABC being easily exploited to learn simulator parameters. The ABC literature has widely-explored the use of test statistics, including fixed functions and kernels, and Markov chain Monte Carlo methods to learn the posterior distribution of the parameters. There is a great deal of opportunity for exchange between GANs, ABC and ratio estimation in aspects of scalability, applications, and theoretical understanding. A further insight obtained from a moment-matching approach is that other empirical measures such as the Dudley and Wasserstein distances can easily be considered, establishing even further connections to other growing areas, such as optimal transport (Frogner et al., 2015; Sriperumbudur et al., 2009). The moment matching approach can be generalised by representing them as an integral probability metric (Sriperumbudur et al., 2009), which is what makes it possible to describe the relationships and ways of transforming from density ratio estimation using using moment-matching, f -divergences, and class-probability estimation. Sriperumbudur et al. (2009) showed that f -divergences and integral probability metrics (MMD, Wasserstein) intersect only at the total variation distance.",
      "startOffset" : 103,
      "endOffset" : 1871
    }, {
      "referenceID" : 20,
      "context" : ", NCE resulting from class-probability based testing in un-normalised models (Gutmann and Hyvärinen, 2012), or variational lower bounds for directed graphical models.",
      "startOffset" : 77,
      "endOffset" : 106
    }, {
      "referenceID" : 29,
      "context" : "This piques our interest in more general approaches for non-maximum likelihood and likelihood-free estimation methods, of which there is much work (Lyu, 2011; Gutmann and Hyvärinen, 2012; Hall, 2005; Marin et al., 2012; Frogner et al., 2015).",
      "startOffset" : 147,
      "endOffset" : 241
    }, {
      "referenceID" : 20,
      "context" : "This piques our interest in more general approaches for non-maximum likelihood and likelihood-free estimation methods, of which there is much work (Lyu, 2011; Gutmann and Hyvärinen, 2012; Hall, 2005; Marin et al., 2012; Frogner et al., 2015).",
      "startOffset" : 147,
      "endOffset" : 241
    }, {
      "referenceID" : 22,
      "context" : "This piques our interest in more general approaches for non-maximum likelihood and likelihood-free estimation methods, of which there is much work (Lyu, 2011; Gutmann and Hyvärinen, 2012; Hall, 2005; Marin et al., 2012; Frogner et al., 2015).",
      "startOffset" : 147,
      "endOffset" : 241
    }, {
      "referenceID" : 30,
      "context" : "This piques our interest in more general approaches for non-maximum likelihood and likelihood-free estimation methods, of which there is much work (Lyu, 2011; Gutmann and Hyvärinen, 2012; Hall, 2005; Marin et al., 2012; Frogner et al., 2015).",
      "startOffset" : 147,
      "endOffset" : 241
    }, {
      "referenceID" : 13,
      "context" : "This piques our interest in more general approaches for non-maximum likelihood and likelihood-free estimation methods, of which there is much work (Lyu, 2011; Gutmann and Hyvärinen, 2012; Hall, 2005; Marin et al., 2012; Frogner et al., 2015).",
      "startOffset" : 147,
      "endOffset" : 241
    }, {
      "referenceID" : 24,
      "context" : "We often deal with misspecified models where qθ cannot represent p∗, and non maximum likelihood methods could be a more robust choice depending on the task (see figure 1 in (Huszár, 2015) for an illustrative example).",
      "startOffset" : 173,
      "endOffset" : 187
    }, {
      "referenceID" : 30,
      "context" : "This is the aim of approximate Bayesian computation (ABC) (Marin et al., 2012).",
      "startOffset" : 58,
      "endOffset" : 78
    }, {
      "referenceID" : 21,
      "context" : "An approach through class-probability estimation is appealing and leads to classifier ABC (Gutmann et al., 2014).",
      "startOffset" : 90,
      "endOffset" : 112
    }, {
      "referenceID" : 12,
      "context" : ", 2012; Frogner et al., 2015). We often deal with misspecified models where qθ cannot represent p∗, and non maximum likelihood methods could be a more robust choice depending on the task (see figure 1 in (Huszár, 2015) for an illustrative example). Choice of loss function. This density ratio viewpoint has led us to derive multiple different objective functions and an understanding of how they are related. But it has left us unsatisfied since we have not gained the insight needed to choose between them. Sugiyama et al. (2012a) make statements on this choice in the simpler setting where only the density ratio is to be estimated.",
      "startOffset" : 8,
      "endOffset" : 532
    }, {
      "referenceID" : 12,
      "context" : ", Frazier et al. (2016). Non-differentiable models.",
      "startOffset" : 2,
      "endOffset" : 24
    }, {
      "referenceID" : 16,
      "context" : "This leads to the first of three tools available for non-differentiable models: the use of the weak derivative and related stochastic finite difference estimators, which require forward-simulation only and compute gradients by perturbation of the parameters (Glasserman, 2003; Fu, 2005).",
      "startOffset" : 258,
      "endOffset" : 286
    }, {
      "referenceID" : 14,
      "context" : "This leads to the first of three tools available for non-differentiable models: the use of the weak derivative and related stochastic finite difference estimators, which require forward-simulation only and compute gradients by perturbation of the parameters (Glasserman, 2003; Fu, 2005).",
      "startOffset" : 258,
      "endOffset" : 286
    }, {
      "referenceID" : 31,
      "context" : "The two other approaches are: moment matching and ABC-MCMC (Marjoram et al., 2003), which has been successful for many problems with moderate dimension; and the natural choice of gradientfree optimisation methods, which include familiar tools such as Bayesian optimisation (Gutmann and Corander, 2016), evolutionary search like CMA-ES, and the Nelder-Mead method, amongst others (Conn et al.",
      "startOffset" : 59,
      "endOffset" : 82
    }, {
      "referenceID" : 19,
      "context" : ", 2003), which has been successful for many problems with moderate dimension; and the natural choice of gradientfree optimisation methods, which include familiar tools such as Bayesian optimisation (Gutmann and Corander, 2016), evolutionary search like CMA-ES, and the Nelder-Mead method, amongst others (Conn et al.",
      "startOffset" : 198,
      "endOffset" : 226
    }, {
      "referenceID" : 5,
      "context" : ", 2003), which has been successful for many problems with moderate dimension; and the natural choice of gradientfree optimisation methods, which include familiar tools such as Bayesian optimisation (Gutmann and Corander, 2016), evolutionary search like CMA-ES, and the Nelder-Mead method, amongst others (Conn et al., 2009).",
      "startOffset" : 304,
      "endOffset" : 323
    } ],
    "year" : 2017,
    "abstractText" : "Generative adversarial networks (GANs) provide an algorithmic framework for constructing generative models with several appealing properties: they do not require a likelihood function to be specified, only a generating procedure; they provide samples that are sharp and compelling; and they allow us to harness our knowledge of building highly accurate neural network classifiers. Here, we develop our understanding of GANs with the aim of forming a rich view of this growing area of machine learning—to build connections to the diverse set of statistical thinking on this topic, of which much can be gained by a mutual exchange of ideas. We frame GANs within the wider landscape of algorithms for learning in implicit generative models—models that only specify a stochastic procedure with which to generate data—and relate these ideas to modelling problems in related fields, such as econometrics and approximate Bayesian computation. We develop likelihood-free inference methods and highlight hypothesis testing as a principle for learning in implicit generative models, using which we are able to derive the objective function used by GANs, and many other related objectives. The testing viewpoint directs our focus to the general problem of density ratio estimation. There are four approaches for density ratio estimation, one of which is a solution using classifiers to distinguish real from generated data. Other approaches such as divergence minimisation and moment matching have also been explored in the GAN literature, and we synthesise these views to form an understanding in terms of the relationships between them and the wider literature, highlighting avenues for future exploration and cross-pollination. 1 IMPLICIT GENERATIVE MODELS It is useful to make a distinction between two types of probabilistic models: prescribed and implicit models (Diggle and Gratton, 1984). Prescribed probabilistic models are those that provide an explicit parametric specification of the distribution of an observed random variable x, specifying a log-likelihood function log qθ(x) with parameters θ. Most models in machine learning and statistics are of this form, whether they be state-of-the-art classifiers for object recognition, complex sequence models for machine translation, or fine-grained spatio-temporal models tracking the spread of disease. Alternatively, we can specify implicit probabilistic models that define a stochastic procedure that directly generates data. Such models are the natural approach for problems in climate and weather, population genetics, and ecology, since the mechanistic understanding of such systems can be used to directly create a data simulator, and hence the model. It is exactly because implicit models are more natural for many problems that they are of interest and importance. Implicit generative models use a latent variable z and transform it using a deterministic function Gθ that maps from R → R using parameters θ. Such models are amongst the most fundamental of models, e.g., many of the basic methods for generating non-uniform random variates are based on simple implicit models and one-line transformations (Devroye, 2006). In general, implicit generative models specify a valid density on the output space that forms an effective likelihood function: x = Gθ(z); z′ ∼ q(z) (1) qθ(x) = ∂ ∂x1 . . . ∂ ∂xd ∫ {Gθ(z)≤x} q(z)dz, (2) where q(z) is a latent variable that provides the external source of randomness and equation (2) is the definition of the transformed density as the derivative of the cumulative distribution function. When the function G is well-defined, such as when the function is invertible, or has dimensions m = d with easily characterised roots, we recover the familiar rule for transformations of probability distributions.",
    "creator" : "LaTeX with hyperref package"
  }
}