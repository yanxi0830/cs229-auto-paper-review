{
  "name" : "581.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "SEQUENCE GENERATION WITH A PHYSIOLOGICALLY PLAUSIBLE MODEL OF HANDWRITING AND RECURRENT MIXTURE DENSITY NETWORKS",
    "authors" : [ "Daniel Berio", "Memo Akten", "Frederic Fol Leymarie", "Mick Grierson", "Réjean Plamondon" ],
    "emails" : [ ],
    "sections" : [ {
      "heading" : "1 INTRODUCTION",
      "text" : "Recent results (Graves, 2013) have demonstrated that, given a sufficiently large training data-set, Long Short-Term Memory (LSTM) (Hochreiter & Schmidhuber, 1997) Recurrent Mixture Density Networks (RMDNs) (Schuster, 1999) are capable of learning and generating convincing synthetic handwriting sequences. In this study we explore a similar network architecture combined with an intermediate feature representation, given by the parameters of a physiologically plausible model of handwriting: the Sigma Lognormal model (Plamondon, 1995; Plamondon et al., 2014).\nIn the work by Graves (2013) and subsequent derivations, the RMDN operates on raw sequences of points recorded with a digitizing device. In our approach we preprocess the training data using an intermediate representation that describes a form of “motor program” coupled with a sequence of dynamic parameters that describe the evolution of the pen tip. By doing so, we use a representation that is more concise (i.e. lower in dimensionality), meaningful (i.e. every data point is a high level segment descriptor of the trajectory), and is resolution independent.\nThis project stems from the observation that human handwriting results from the orchestration of a large number of motor and neural subsystems, and is ultimately produced with the execution of complex and skillful motions. As such we seek a representation that abstracts the complex task of trajectory formation from the neural network, which is then rather focused on a higher level task of movement planning. Note that for the scope of this study, we do not implement text-to-handwriting synthesis (Graves, 2013), but rather focus on the task of generating sequences that possess the statistical and dynamic qualities of handwriting, which can be expanded to calligraphy, asemic handwriting, drawings and graffiti (Berio & Leymarie, 2015; Berio et al., 2016)). In particular, we focus on two distinct tasks: (1) learning and generating motor plans and (2) given a motor plan,\n1Goldsmiths College, University of London. Department of Computing. 2École Polytechnique de Montréal, Canada.\npredicting the corresponding dynamic parameters that determine the visual and dynamic qualities of the pen trace. We then go on to show that this modular workflow can be exploited in ways such as: mixing of dynamic qualities between data-sets (a form of handwriting “style transfer” ) as well as learning from small datasets (a form of “one shot learning”).\nThe remainder of this paper is organised as follows: in Section 2, after briefly summarising the background context, we then briefly describe the Sigma Lognormal model and RMDNs; in Section 3 we present the data preprocessing step and the RMDN models that build up our system; in Section 4 we propose various applications of the system, including learning handwriting representations from small datasets and mixing styles."
    }, {
      "heading" : "2 BACKGROUND",
      "text" : "Our study is grounded on a number of notions and principles that have been observed in the general study of human movement as well as in the handwriting synthesis/analysis field (known as Graphonomics (Kao et al., 1986)). The speed profile of aiming movements is typically characterised by a “bell shape” that is variably skewed depending on the rapidity of the movement (Lestienne, 1979; Nagasaki, 1989; Plamondon et al., 2013). Complex movements can be described by the superimposition of a discrete number of “ballistic” units of motion, which in turn can each be represented by the classic bell shaped velocity profile and are often referred to as strokes. A number of methods synthesise handwriting through the temporal superimposition of strokes, the velocity profile of which is modelled with a variety of functions including sinusoidal functions (Morasso & Mussa Ivaldi, 1982; Maarse, 1987; Rosenbaum et al., 1995), Beta functions (Lee & Cho, 1998; Bezine et al., 2004), and lognormals (Plamondon et al., 2009). In this study we rely on a family of models known as the Kinematic Theory of Rapid Human Movements, that has been developed by Plamondon et al. in an extensive body of work since the 1990’s (Plamondon, 1995; Plamondon et al., 2014). Plamondon et al. (2003) show that if we consider that a movement is the result of the parallel and hierarchical interaction of a large number of coupled linear systems, the impulse response of such a system to a centrally generated command asymptotically converges to a lognormal function. This assumption is attractive from a modelling perspective because it abstracts the high complexity of the neuromuscular system in charge of generating movements with a relatively simple mathematical model which further provides state of the art reconstruction of human velocity data (Rohrer & Hogan, 2006; Plamondon et al., 2013).\nA number of methods have used neural inspired approaches for the task of handwriting trajectory formation (Schomaker, 1992; Bullock et al., 1993; Wada & Kawato, 1993). Similarly to our proposed method, Ltaief et al. (2012) train a neural on a preprocessed dataset where the raw input data is reconstructed in the form of handwriting model parameters. Nair & Hinton (2005) use a sequence of neural networks to learn the motion of two orthogonal mass spring systems from images of handwritten digits for classification purposes. With a similar motivation to ours, Plamondon & Privitera (1996) use a Self Organising Map (SOM) to learn a sequence of ballistic targets, which describe a coarse motor plan of handwriting trajectories. Our method builds in particular on the work of Graves (2013), who describes a system that uses a recurrent mixture density networks (RMDNs) (Bishop, 1994) extended with a LSTM architecture (Hochreiter & Schmidhuber, 1997), to generate synthetic handwriting in a variety of styles."
    }, {
      "heading" : "2.1 SIGMA LOGNORMAL MODEL",
      "text" : "On the basis of Plamondon’s Kinematic Theory (Plamondon, 1995), the Sigma Lognormal (ΣΛ) model (Plamondon & Djioua, 2006) describes complex handwriting trajectories via the vectorial superimposition of a discrete number of strokes. With the assumption that curved handwriting movements are done by rotating the wrist, the curvilinear evolution of strokes is described with a circular arc shape. Each stroke is charactersied by a variably assymmetric \"bell shape\" speed profile, which is described with a (3 parameter) lognormal function. The planar evolution of a trajectory is then described by a sequence of virtual targets {vi}i=mi=1 , which define “imaginary” (i.e. not necessarily located along the generated trajectory) loci at which each consecutive stroke is aimed. The virtual targets provide a low level description of the motor plan for the handwriting trajectory. A smooth trajectory is then generated by integrating the velocity of each stroke over time. The trajectory smoothness can be defined by adjusting the activation-time offset of a given stroke with respect to the\nprevious stroke, which is denoted with ∆t0i; a smaller time offset (i.e. a greater overlap between lognormal components) will result in a smoother trajectory (Fig. 1, c). The curvature of the trajectory can be varied by adjusting the central angle of each circular arc, which is denoted with θi. Equations and further details for the ΣΛ model can be found in Appendix A.\nA sequence of virtual targets provides a very sparse spatial description or “motor plan” for the trajectory evolution. The remaining stroke parameters, ∆t0i and θi, define the temporal, dynamic and geometric features of the trajectory and we refer to those as dynamic parameters."
    }, {
      "heading" : "2.2 RECURRENT MIXTURE DENSITY NETWORKS",
      "text" : "Mixture Density Networks (MDN) were introduced by Bishop (1994) in order to model and predict the parameters of a Gaussian Mixture Model (GMM), i.e. a set of means, covariances and mixture weights. Schuster (1999) showed that MDNs could be to model temporal data using RNNs. The author used Recurrent Mixture Density Networks (RMDN) to model the statistical properties of speech, and they were found to be more successful than traditional GMMs. Graves (2013) used LSTM RMDNs to model and synthesise online handwriting, providing the basis for extensions to the method, also used in Ha et al. (2016); Zhang et al. (2016). Note that in the case of a sequential model, the RMDN outputs a unique set of GMM parameters for each timestep t, allowing the probability distribution to change with time as the input sequence develops. Further details can be found in Appendix C.1."
    }, {
      "heading" : "3 METHOD",
      "text" : "We operate on discrete and temporally ordered sequences of planar coordinates. Similarly to Graves (2013), most of our results come from experiments made on the IAM online handwriting database (Marti & Bunke, 2002). However, we have made preliminary experiments with other datasets, such as the Graffiti Analysis Database (Lab, 2009) as well as limited samples collected in our laboratory from a user with a digitiser tablet.\nAs a first step, we preprocess the raw data and reconstruct it in the form of ΣΛ model parameters Section 3.1. We then train and evaluate a number of RMDN models for two distinct tasks:\n1. Virtual target prediction. We use the V2V-model for this task. Given a sequence of virtual targets, this model predicts the next virtual target.\n2. Dynamic parameter prediction. For this task we trained and compared two model architectures. Given a sequence of virtual targets, the task of these models is to predict the corresponding dynamic parameters. The V2D-model is condititioned only on the previous virtual targets, whereas the A2D-model is conditioned on both the previous virtual targets and dynamic parameters.\nWe then exploit the modularity of this system to conduct various experiments, details of which can found in Section 4."
    }, {
      "heading" : "3.1 PREPROCESSING: RECONSTRUCTING ΣΛ PARAMETERS",
      "text" : "A number of methods have been developed by Plamondon et. al in order to reconstruct ΣΛ-model parameters from digitised pen input data (O’Reilly & Plamondon, 2008; Plamondon et al., 2014; Fischer et al., 2014). These methods provide the ideal reconstruction of model parameters, given a high resolution digitised pen trace. While such methods are superior for handwriting analysis and biometric purposes, we opt for a less precise method (Berio & Leymarie, 2015) that is less sensitive to sampling quality and is aimed at generating virtual target sequences that remain perceptually similar to the original trace. We purposely choose to ignore the original dynamics of the input, and base the method on a geometric input data only. This is done in order to work with training sequences that are independent of sampling rate, and in sight of future developments in which we intend to extract handwriting traces from bitmaps, inferring causal/dynamic information from a static input as humans are capable of (Edelman & Flash, 1987; Freedberg & Gallese, 2007).\nOur method operates on a uniformly sampled input contour, which is then segmented in correspondence with perceptually salient key points: loci of curvature extrema modulated by neighbouring contour segments (Brault & Plamondon, 1993; Berio & Leymarie, 2015), which gives an initial estimate of each virtual target vi. We then (i) fit a circular arc to each contour segment in order to estimate the θi parameters and (ii) estimate the ∆t0i parameters by analysing the contour curvature in the region of each key point. Finally, (iii) we iteratively adjust the virtual target positions to minimise the error between the original trajectory and the one generated by the corresponding ΣΛ parameters. For Further details on the ΣΛ parameter reconstruction method, the reader is referred to Appendix B."
    }, {
      "heading" : "3.2 DATA AUGMENTATION",
      "text" : "We can exploit the ΣΛ parameterisation to generate many variations over a single trajectory, which are visually consistent with the original, and with a variability that is similar to the one that would be seen in multiple instances of handwriting made by the same writer (Fig. 3) (Djioua & Plamondon, 2008a; Fischer et al., 2014; Berio & Leymarie, 2015). Given a dataset of n training samples, we randomly perturb the virtual target positions and dynamic parameters of each sample np times, which results in a new augmented dataset of size n+ n× np where legibility and trajectory smoothness is maintained across samples. This would not be possible on the raw online dataset, as perturbations for each data-point would eventually result in a noisy trajectory."
    }, {
      "heading" : "3.3 PREDICTING VIRTUAL TARGETS WITH THE V2V-MODEL",
      "text" : "The V2V-model is conditioned on a history of virtual targets and given a new virtual target it predicts the next virtual target (hence the name V2V). Note that each virtual target includes the corresponding\npen state — up (not touching the paper) or down (touching the paper). Repeatedly feeding the predicted virtual target back into the model at every timestep allows the model to synthesise sequences of arbitrary length. The implementation of this model is very similar to the handwriting prediction demonstrated by Graves (2013), although instead of operating directly on the digitised pen positions, we operate on the much coarser virtual target sequences which are extracted during the preprocessing step. The details of this model can be found in Appendix C.3"
    }, {
      "heading" : "3.4 PREDICTING DYNAMIC PARAMETERS WITH THE V2D AND A2D MODELS",
      "text" : "The goal of these models is to predict the corresponding dynamic parameters (∆t0i, θi) for a given sequence of virtual targets. We train and compare two model architectures for this task. The V2Dmodel is conditioned on the history of virtual targets, and given a new virtual target, this model predicts the corresponding dynamic parameters (∆t0i, θi) for the current stroke (hence the name V2D). Running this model incrementally for every stroke of a given virtual target sequence allows us to predict dynamic parameters for each stroke. The implementation of this model is very similar to the V2V-model, and details can be found in Appendix C.4.\nAt each timestep, the V2D model outputs and maintains internal memory of a probability distribution for the predicted dynamic parameters. However, the network has no knowledge of the parameters that are sampled and used. Hence, dynamic parameters might not be consistent across timesteps. This problem can be overcome by feeding the sampled dynamic parameters back into the model at the next timestep. From a human motor planning perspective this makes sense as, for a given drawing style, when we decide the curvature and smoothness of a stroke we will take into consideration the choices made in previously executed strokes.\nThe A2D model predicts the corresponding dynamic parameters (∆t0i, θi) for the current stroke conditioned on a history of both virtual targets and dynamic parameters (i.e. all ΣΛ parameters - hence the name A2D). We use this model in a similar way to the V2D model, whereby we run it incrementally for every stroke of a given virtual target sequence. However, internally, at every timestep the predicted dynamic parameters are fed back into the model at the next timestep along with the virtual target from the given sequence. The details of this implementation can be found in Appendix C.5."
    }, {
      "heading" : "4 EXPERIMENTS AND RESULTS",
      "text" : "Predicting Virtual Targets. In a first experiment we use the V2V model, trained on the preprocessed IAM dataset, to predict sequences of virtual targets. We prime the network by first feeding it a sequence from the test dataset. This conditions the network to predict sequences that are similar to the prime. We can see from the results (Fig. 4) that the network is indeed able to produce sequences that capture the statistical qualities of the priming sequence, such as overall incline, proportions, and oscillation frequency. On the other hand, we observe that amongst the generated sequences, there are often patterns which do not represent recognisable letters or words. This can be explained by the high variability of samples contained in the IAM dataset, and by the fact that our representation is very concise, with each data-point containing high significance. As a result, the slightest variation in a prediction is likely to cause a large error in the next. To overcome this problem, we train a new model with a dataset augmented with 10× variations as described in Section 3.2. Due to our limited computing resources 1, we test this method on 1/10th of the dataset, which results in a new dataset with the same size as the original, but with a lower number of handwriting specimens with a number of subtle variations per specimen. With this approach, the network predictions maintain statistical similarity with the priming sequences, and patterns emerge that are more evocative of letters of the alphabet or whole words, with fewer unrecognizable patterns (Fig. 4). To validate this result, we also test the model’s performance training it on 1/10th of the dataset, without data augmentation, and the results are clearly inferior to the previous two models. This suggests that the data augmentation step is highly beneficial to the performance of the network.\n1We are thus not able to thoroughly test the large network architectures that would be necessary to train on the whole augmented dataset.\nPredicting Dynamic Parameters. We first evaluate the performance of both the V2D and A2D models on virtual targets extracted from the test set. Remarkably, although the networks have not been trained on these sequences, both models predict dynamic parameters that result in trajectories that are readable, and are often similar to the target sample. We settle on the A2D model trained on a 3× augmented dataset, which we qualitatively assess to produce the best results (Fig. 5).\nWe then proceed with applying the same A2D model on virtual targets generated by the V2V models primed on the test set. We observe that the predictions on sequences generated with the augmented dataset are highly evocative of handwriting and are clearly different depending on the priming sequence (Fig. 6, c), while the predictions made with the non-augmented dataset are more likely to resemble random scribbles rather than human readable handwriting (Fig. 6, b). This further confirms the utility of the data augmentation step.\nUser defined virtual targets. The dynamic parameter prediction models can also be used in combination with user defined virtual target sequences (Fig. 7). Such a method can be used to quickly and interactively generate handwriting trajectories in a given style, by a simple point and click procedure. The style (in terms of curvature and dynamics) of the generated trajectory is determined by the data used to train the A2D model, and by priming the A2D model with different samples, we can apply different styles to the user defined virtual targets.\nOne shot learning. In a subsequent experiment, we apply the data augmentaion method described in Section 3.2 to enable both virtual target and dynamic prediction models to learn from a small dataset of calligraphic samples recorded by a user using a digitiser tablet. We observe that with a low number of augmentations (50×) the models generate quasi-random outputs, and seem to learn only the left to right trend of the input. With higher augmentation (700×), the system generates outputs that are consistent to the human eye with the input data (Fig. 8). We also train our models using only a single sample (augmented 7000×) and again observe that the model is able to reproduce novel sequences that are similar to the input sample (Fig. 9). Naturally, the output is a form of recombination of the input, but this is sufficient to synthesise novel outputs that are qualitatively similar to the input. It should be noted that we are judging the performance of the one-shot learned models qualitatively, and we may not be testing the full limits of how well the models are able to generalise. On the other hand, these results, as well as the “style transfer” capabilities exposed in following section suggest a certain degree of generalisation.\nStyle Transfer. Here, with a slight abuse of terminology, we utilise the term \"style\" to refer to the dynamic and geometric features (such as pen-tip acceleration and curvature) that determine the visual qualities of a handwriting trajectory. Given a sequence of virtual targets generated with the V2V model trained on one dataset, we can also predict the corresponding dynamic parameters with the A2D model trained on another. The result is an output that is similar to one dataset in lettering structure, but possesses the fine dynamic and geometric features of the other. If we visually inspect Fig. 10, we can see that both the sequence of virtual targets reconstructed by the dataset preprocessing method, and the trajectory generated over the same sequence of virtual targets with dynamic parameters learned from a different datasets, are both readable. This emphasises the importance of using perceptually salient points along the input for estimating key-points in the data-set preprocessing step (Section 3.1).\nFurthermore, we can perform the same type of operation within a single dataset, by priming the A2D model with the dynamic parameters of a particular training example, while feeding it with the virtual targets of another. To test this we train both (V2V, A2D) models on a corpus containing 5 samples of the same sentence written in different styles and then augmented 1400× (Fig. 11). We envision the utility of such as system in combination with virtual targets interactively specified by a user."
    }, {
      "heading" : "5 CONCLUSIONS AND FUTURE WORK",
      "text" : "We have presented a system that is able to learn the parameters for a physiologically plausible model of handwriting from an online dataset. We hypothesise that such a movement centric approach is advantageous as a feature representation for a number of reasons. Using such a representation provides a performance that is similar to the handwriting prediction demonstrated by Graves (2013) and Ha et al. (2016), with a number of additional benefits. These include the ability to: (i) capture both the geometry and dynamics of a hand drawn/written trace with a single representation, (ii) express the variability of different types of movement concisely at the feature level, (iii) demonstrate greater flexibility for procedural manipulations of the output, (iv) mix “styles” (applying curvature and dynamic properties from one example, to the motor plan of another), (v) learn a generative model from a small number of samples (n < 5), (vi) generate resolution independent outputs.\nThe reported work provides a solid basis for a number of different future research avenues. As a first extension, we plan to implement the label/text input alignment method described in Graves’ original work that should allow us to synthesise readable handwritten text and also to provide a more thorough comparison of the two methods. Our method strongly relies on an accurate reconstruction of the input in the preprocessing step. Improvements should target especially parts of the latter method that depend on user tuned parameters, such as the identification of salient points along the input (which requires a final peak detection pass), and measuring the sharpness of the input in correspondence with salient points."
    }, {
      "heading" : "ACKNOWLEDGMENTS",
      "text" : "The system takes as a starting point the original work developed by (Graves, 2013). We use Tensorflow, the open-source software library for numerical computation and deep learning (Abadi et al., 2015), and a rapid implementation was possible thanks to a public domain implementation developed by (Ha, 2015)."
    }, {
      "heading" : "A SIGMA LOGNORMAL MODEL",
      "text" : "The Sigma Lognormal model (Plamondon & Djioua, 2006) describes complex handwriting trajectories via the vectorial superimposition of lognormal strokes. The corresponding speed profile Λi(t) assumes a variably asymmetric \"bell shape\" which is described with a 3 parameter lognormal function\nΛi(t) = − 1\nσi √ 2π(t− t0i) exp\n( (ln(t− t0i)− µi)2\n2σi2\n) (1)\nwhere t0i defines the activation time of a stroke and the parameters µi and σi determine the shape of the lognormal function. µi is referred to as log-time delay and is biologically interpreted as the rapidity of the neuromuscular system to react to an impulse generated by the central nervous system (Plamondon et al., 2003); σi is referred to as log-response time and determines the spread and asymmetry of the lognormal.\nThe curvilinear evolution of strokes is described with a circular arc shape, which results in\nφi(t) = θi + θi\n[ 1 + erf ( ln(t− t0i)− µi\nσi √ 2\n)] , (2)\nwhere θi is the central angle of the circular arc that defines the shape of the ith stroke.\nThe planar evolution of a trajectory is defined by a sequence of virtual targets {vi}i=mi=1 , where a trajectory with m virtual targets will be characterised by m− 1 circular arc strokes. A ΣΛ trajectory, parameterised by the virtual target positions, is given by\nξ(t) = v1 + ∫ t 0 dτΛi(τ) m−1∑ i=1 Φi(τ) (vi+1 − vi), (3)\nwith Φi(t) = [ h(θi)cosφi(t) −h(θi)sinφi(t) h(θi)sinφi(t) −h(θi)cosφi(t) ] , and h(θi) = { 2θi 2sinθi if |sinθi| > 0,\n1 otherwise, (4)\nwhich scales the extent of the stroke based on the ratio between the perimeter and the chord length of the circular arc.\nIntermediate parameterisation. In order to facilitate the precise specification of timing and profile shape of each stroke, we recur to an intermediate parametrisation that takes advantage of a few known properties of the lognormal (Djioua & Plamondon, 2008b) in order to define each stroke with (i) a time offset ∆ti with respect to the previous stroke, (ii) a stroke duration Ti and (iii) a shape parameter αi, which defines the skewedness of the lognormal. The corresponding ΣΛ parameters {t0i, µi, σi} can be then computed with:\nσi = ln(1 + αi), (5)\nµi = −ln ( −e\n−3σi − e3σi Ti\n) , (6)\nand t0i = t1i − eµ−3σ t1i = t1(i−1) + ∆ti t1(0) = 0, (7)\nwhere t1i is the onset time of the lognormal stroke profile. As α approaches 0, the shape of the lognormal converges to a Gaussian, with mean t1 + eµ−σ 2\n(the mode of the lognormal) and standard deviation d6 ."
    }, {
      "heading" : "B RECONSTRUCTING ΣΛ PARAMETERS FROM AN ONLINE DATASET",
      "text" : "The ΣΛ parameter reconstruction method operates on a input contour uniformly sampled at a fixed distance which is defined depending on the extent of the input, where we denote the kth sampled point along the input with p[k]. The input contour is then segmented in correspondence with perceptually salient key points, which correspond with loci of curvature extrema modulated by neighbouring contour segments (Brault & Plamondon, 1993; Berio & Leymarie, 2015). The proposed approach shares strong similarities with previous work done for (i) compressing online handwriting data with a circular-arc based segmentation (Li et al., 1998) and (ii) for generating synthetic data for handwriting recognisers (Varga et al., 2005). The parameter reconstruction algorithm can be summarised with the following steps:\n• Find m key-points in the input contour. • Fit a circular arc to each contour segment defined between two consecutive key-points\n(defining individual strokes), and obtain an estimate of each curvature parameter θi.\n• For each stroke compute the corresponding ∆ti parameter by analysing the curvature signal in the region of the corresponding key-point.\n• Define an initial sequence of virtual targets with m positions corresponding with each input key-point.\n• Repeat the following until convergence or until a maximum number of iterations is reached Berio & Leymarie (2015):\n– Integrate the ΣΛ trajectory with the current parameter estimate. – Identify m key-points in the generated trajectory. – Move the virtual target positions to minimise the distance between the key-points of\nthe generated trajectory and the key-points on the input contour.\nThe details for each step are highlighted in the following paragraphs.\nEstimating input key-points. Finding significant curvature extrema (which can be counted as convex and concave features for a closed/solid shape) is an active area of research, as relying on discrete curvature measurements remains challenging. We currently rely on a method described by Feldman & Singh (2005), and supported experimentally by De Winter & Wagemans (2008): first we measure the turning angle at each position of the input p[k] and then compute a smooth version of the signal by convolving it with a Hanning window. We assume that the turning angles have\nbeen generated by a random process with a Von Mises distribution with mean at 0 degrees, which corresponds with giving maximum probability to a straight line. We then measure the surprisal (i.e. the negative logarithm of the probability) for each sample as defined by Feldman & Singh (2005), which normalised to the [0, 1] range simplifies to:\n1− cos(θ[k]), (8)\nwhere θ[k] is the (smoothed) turning angle. The first and last sample indices of the surprisal signal together with its local maxima results in m key-point indices {ẑi}. The corresponding key-points along the input contour are then given by {p [ẑi]}.\nEstimating stroke curvature parameters. For each section of the input contour defined between two consecutive key-points, we estimate the corresponding stroke curvature parameter θi by first computing a least square fit of a circle to the contour section. We then compute the internal angle of the arc supported between the two key-points, which is equal 2θi, i.e. two times the corresponding curvature parameter θi.\nEstimating stroke time-overlap parameters. This step is based on the observation that a smaller values of ∆t0i, i.e. a greater time overlap between strokes, result in smoother trajectories. On the contrary, a sufficiently large value of ∆t0i will result in a sharp corner in proximity of the corresponding virtual target. We exploit this notion, and compute an estimate of the ∆t0i parameters by examining the sharpness of the input contour in the region of each key-point.\nTo do so we examine the previously computed turning angle surprisal signal, in which we can observe that sharp corners in the contour correspond with sharper peaks, while smoother corners correspond with smooth peaks with a larger spread. By treating the surprisal signal as a probability density function, we can then use statistical methods to measure the shape of each peak with a mixture of parametric distributions, and examine the shape of each mixture component in order to get an estimate of the corresponding sharpness along the input contour. To do so we employ a variant of Expectation Maximisation (EM) (Dempster et al., 1977) in which we treat the distance along the contour as a random variable weighted by the corresponding signal amplitude normalised to the [0, 1] range. Once the EM algorithm has converged, we treat each mixture component as a radial basis function (RBF) centred at the corresponding mean, and use linear regression as in Radial Basis Function Networks (Stulp & Sigaud, 2015) to fit the mixture parameters to the original signal (Calinon, 2016). Finally we generate an estimate of sharpness λi (bounded in the [0, 1] range) for each key point using as a logarithmic function of the mixture parameters and weights. The corresponding ∆t0i parameters are then given by\n∆ti = ∆tmin + (∆tmax −∆tmin)λi , (9)\nwhere ∆tmin and ∆tmax are user specified parameters that determine the range of the ∆t0i estimates.\nNote that we currently utilise an empirically defined function for this task. But in future steps, we intend to learn the mapping between sharpness and mixture component parameters from synthetically samples generated with the ΣΛ model (for which ∆t0i, and consequently λi, are known).\nIteratively estimating virtual target positions. The loci along the input contour corresponding with the estimated key-points provide an initial estimate for a sequence of virtual targets, where each virtual target position is given by vi = p[ẑi]. Due to the trajectory-smoothing effect produced by the time overlaps, the initial estimate will result in a generated trajectory that is likely to have a reduced scale with respect to the input we wish to reconstruct (Varga et al., 2005). In order to produce a more accurate reconstruction, we use an iterative method that shifts each virtual target towards a position that will minimise the error between the generated trajectory and the reconstructed input. To do so, we compute an estimate of m output key-points {ξ (zi)} in the generated trajectory, where z2, ..., zm are the time occurrences at which the influence of one stroke exceeds the previous. These will correspond with salient points along the trajectory (extrema of curvature) and can be easily computed by finding the time occurrence at which two consecutive lognormals intersect. Similarly to the input key-point case, ξ(z1) and ξ(zm) respectively denote the first and last points of the generated trajectory. We then iteratively adjust the virtual target positions in order to move each generated\nkey-point ξ(zi) towards the corresponding input key-point p[ẑi] with:\nvi ← vi + p [ẑi]− ξ (zi) , (10)\nThe iteration continues until the Mean Square Error (MSE) of the distances between every pair p [ẑi] and ξ(zi) is less than an experimentally set threshold or until a maximum number of iterations is reached (Fig. 16). This method usually converges to a good reconstruction of the input within few iterations (usually < 5). Interestingly, even though the dynamic information of the input is discarded, the reconstructed velocity profile is often similar to the original (in number of peaks and shape), which can be explained by the extensively studied relationships between geometry and dynamics of movement trajectories (Viviani & Terzuolo, 1982; Lacquaniti et al., 1983; Viviani & Schneider, 1991; Flash & Handzel, 2007)."
    }, {
      "heading" : "C RMDN MODEL DETAILS",
      "text" : "In order to increase the expressive generative capabilities of our networks, we train them to model parametric probability distributions. Specifically, we use Recurrent Mixture Density Networks that output the parameters of a bivariate Gaussian Mixture Model.\nC.1 BIVARIATE RECURRENT MIXTURE DENSITY NETWORK\nIf a target variable zt can be expressed as a bivariate GMM, then for K Gaussians we can use a network architecture with output dimensions of 6K. This output vector would then consist of (µ̂t ∈ IR2K , σ̂t ∈ IR2K , ρ̂t ∈ IRK , π̂t ∈ IRK), which we use to calculate the parameters of the\nGMM via (Graves, 2013)\nµkt = µ̂ k t : means for k’th Gaussian, µ k t ∈ IR 2\nσkt = exp(σ̂ k t ) : standard deviations for k’th Gaussian, σ k t ∈ IR 2\nρkt = tanh(ρ̂ k t ) : correlations for k’th Gaussian, ρ k t ∈ (−1, 1)\nπkt = softmax(π̂ k t ) : mixture weight for k’th Gaussian , K∑ k πkt = 1\n(11)\nWe can then formulate the probability distribution function Pt at timestep t as\nPt = K∑ k πktN(zt | µkt ,σkt , ρkt ), where (12)\nN (x | µ,σ, ρ) = 1 2πσ1σ2 √ 1− ρ2 exp\n[ − Z\n2(1− ρ2)\n] , and (13)\nZ = (x1 − µ1)2\nσ21 +\n(x2 − µ2)2 σ22 − 2ρ(x1 − µ2)(x2 − µ2) σ1σ2 (14)\nC.2 TRAINING OBJECTIVE\nIf we let θ denote the parameters of a network, and given a training set S of input-target pairs (x ∈X, ŷ ∈ Ŷ ), our training objective is to find the set of parameters θML which has the maximum likelihood (ML). This is the θ that maximises the probability of training set S and is formulated as (Graves, 2008)\nθML = arg max θ\nPr(S | θ) (15)\n= arg max θ S∏ (x,ŷ) Pr(ŷ | x,θ). (16)\nSince the logarithm is a monotonic function, a common method for maximizing this likelihood is minimizing its negative logarithm, also known as the Negative Log Likelihood (NLL), Hamiltonian or surprisal (Lin & Tegmark, 2016). We can then define our cost function J as\nJ = − ln S∏\n(x,ŷ)\nPr(ŷ | x,θ) (17)\n= − S∑\n(x,ŷ)\nln Pr(ŷ | x,θ). (18)\nFor a bivariate RMDN, the objective function can be formulated by substituting eqn. (12) in place of Pr(ŷ | x,θ) in eqn. (18).\nC.3 V2V MODEL\nInput At each timestep i, the input to the V2V model is xi ∈ IR3, where the first two elements are given by ∆vi (the relative position displacement for the i’th stroke, i.e. between the i’th virtual target and the next), and the last element is ui ∈ {0, 1} (the pen-up state during the same stroke). Given input xi and its current internal state (ci,hi), the network learns to predict xi+1, by learning the parameters for the Probability Density Function (PDF) : Pr(xi+1 |xi, ci,hi). With a slight abuse of notation, this can be expressed more intuitively as Pr(xi+1 | xi,xi−1, ...,xi−n) where n is the maximum sequence length.\nOutput We express the predicted probability of ∆vi as a bivariate GMM as described in Section C.1, and ui as a Bernoulli distribution. Thus for K Gaussians the network has output dimensions of (6K + 1) which, in addition to eqn. (11), contains êi which we use to calculate the pen state probability via (Graves, 2013)\nei = 1\n1 + exp(êi) , ei ∈ (0, 1) (19)\nArchitecture We use Long Short-Term Memory (Hochreiter & Schmidhuber, 1997) networks with input, output and forget gates (Gers et al., 2000), and we use Dropout regularization as described by Pham et al. (2014). We employ both a grid search and a random search (Bergstra & Bengio, 2012) on various hyperparameters in the ranges: sequence length {64, 128}, number of hidden recurrent layers {1, 2, 3}, dimensions per hidden layer {64, 128, 256, 400, 512, 900, 1024}, number of Gaussians {5, 10, 20}, dropout keep probability {50%, 70%, 80%, 90%, 95%} and peepholes {with, without}.\nFor comparison we also tried a deterministic architecture whereby instead of outputing a probability distribution, the network outputs a direct prediction for xi+1. As expected, the network was unable to learn this function, and all sequence of virtual targets synthesized with this method simply travel in a repeating zig-zag line.\nTraining We use a form of Truncated Backpropagation Through Time (BPTT) (Sutskever, 2013) whereby we segment long sequences into overlapping segments of maximum length n. In this case long-term dependencies greater than length n are lost, however with enough overlap the network can effectively learn a sliding window of length n timesteps. We shuffle our training data and reset the internal state after each sequence. We empirically found an overlap factor of 50% to perform well, though further studies are needed to confirm the sensitivity of this figure.\nWe use dynamic unrolling of the RNN, whereby the number of timesteps to unroll to is not set at compile time, in the architecture of the network, but unrolled dynamically while training, allowing variable length sequences. We also experimented with repeating sequences which were shorter than the maximum sequence length n, to complete them to length n. We found that for our case they produced desirable results, with some side-effects which we discuss in later sections.\nWe split our dataset into training: 70%, validation: 20% and test:10% and use the Adam optimizer (Kingma & Ba, 2014) with the recommended hyperparameters. To prevent exploding gradients we clip gradients by their global L2 norm as described in (Pascanu et al., 2013). We tried thresholds of both 5 and 10, and found 5 to provide more stability.\nWe formulate the loss function J to minimise the Negative Log Likelihood as described in Section C.2 using the probability density functions described in eqn. (12) and eqn. (19).\nC.4 V2D MODEL\nInput The input to this network at each timestep i is identical to that of the V2V-model, xi ∈ IR3, where the first two elements are ∆vi (normalised relative position displacement for the i’th stroke), and ui ∈ {0, 1} (the pen state during the same stroke). Given input xi and its current internal state (ci,hi), the network learns to predict the dynamic parameters (∆t0i, θi) for the current stroke i, by learning the parameters for Pr(∆t0i, θi | xi, ci,hi). Again with an abuse of notation, this can be expressed more intuitively as Pr(∆t0i, θi | xi,xi−1, ...,xi−n) where n is the maximum sequence length.\nOutput We express the predicted probability of the dynamic parameters (∆t0i, θi) as a bivariate GMM as described in Section C.1.\nArchitecture We explored very similar architecture and hyperparamereters as the V2V-model, but found that we achieved much better results with a shorter maximum sequence length. We trained a number of models with a variety of sequence lengths {3, ..., 8, 13, 16, 21, 32}.\nTraining We use the same procedure for training as the V2V-model.\nC.5 A2D MODEL\nInput The input to this network xi ∈ IR5 at each timestep i is slightly different to the V2V and V2D models. Similar to the V2V and V2D models, the first two elements are ∆vi (normalised relative position displacement for the i’th stroke), and the third element is ui ∈ {0, 1} (the pen state during the same stroke). However in this case the final two elements are the dynamic parameters for the previous stroke (∆t0i−1, θi−1), normalized to zero mean and unit standard deviation.\nGiven input xi and its current internal state (ci,hi), the network learns to predict the dynamic parameters (∆t0i, θi) for the current stroke i, by learning the parameters for Pr(∆t0i, θi |xi, ci,hi). Again with an abuse of notation, this can be expressed more intuitively as Pr(∆t0i, θi | xi,xi−1, ...,xi−n) where n is the maximum sequence length.\nOutput The output of this network is identical to that of the V2D model.\nArchitecture We explored very similar architecture and hyperparamereters as the V2D model.\nTraining We use the same procedure for training as the V2V-model.\nC.6 MODEL SELECTION\nWe evaluated and batch rendered the outputs of many different architectures and models at different training epochs, and settled on models which were amongst those with the lowest validation error, but also produced visibily more desirable results. Once we picked the models, the results displayed are not cherry picked.\nThe preprocessed IAM dataset contains 12087 samples (8460 in the training set) with maximum sequence length 305, minimum 6, median 103 and mean 103.9. For the V2V/V2D/A2V models trained on the IAM database we settle on an architecture of 3 recurrent layers, each with size 512, a maximum sequence length of 128, 20 Gaussians, dropout keep probability of 80% and no peepholes.\nFor the augmented one-shot learning models we used similar architectures, but found that 2 recurrent layers each with size 256 was able to generalise better and produce more interesting results that both captured the prime inputs without overfitting.\nFor V2V we used L2 normalisation on ∆vi input, and for A2D/V2D we used\nWe also tried a number of different methods for normalising and representing ∆vi on the input to the models. We first tried normalising the components individually to have zero mean and unit standard deviation. We also tried normalising uniformly on L2 norm again to have zero mean and unit standard deviation. Finally, we tried normalised polar coordinates, both absolute and relative."
    } ],
    "references" : [ {
      "title" : "TensorFlow: Large-scale machine learning on heterogeneous systems, 2015. URL http://tensorflow.org/. Software available from tensorflow.org",
      "author" : [ "Martín Abadi" ],
      "venue" : null,
      "citeRegEx" : "Abadi,? \\Q2015\\E",
      "shortCiteRegEx" : "Abadi",
      "year" : 2015
    }, {
      "title" : "Random Search for Hyper-Parameter Optimization",
      "author" : [ "James Bergstra", "Yoshua Bengio" ],
      "venue" : "Journal of Machine Learning Research,",
      "citeRegEx" : "Bergstra and Bengio.,? \\Q2012\\E",
      "shortCiteRegEx" : "Bergstra and Bengio.",
      "year" : 2012
    }, {
      "title" : "Learning dynamic graffiti strokes with a compliant robot",
      "author" : [ "D. Berio", "S. Calinon", "F. Fol Leymarie" ],
      "venue" : "In Proc. IEEE/RSJ Intl Conf. on Intelligent Robots and Systems (IROS),",
      "citeRegEx" : "Berio et al\\.,? \\Q2016\\E",
      "shortCiteRegEx" : "Berio et al\\.",
      "year" : 2016
    }, {
      "title" : "Computational Models for the Analysis and Synthesis of Graffiti Tag Strokes",
      "author" : [ "Daniel Berio", "Frederic Fol Leymarie" ],
      "venue" : "In Paul Rosin (ed.), Computational Aesthetics. Eurographics Association,",
      "citeRegEx" : "Berio and Leymarie.,? \\Q2015\\E",
      "shortCiteRegEx" : "Berio and Leymarie.",
      "year" : 2015
    }, {
      "title" : "Generation and analysis of handwriting script with the beta-elliptic model",
      "author" : [ "Hala Bezine", "Adel M. Alimi", "Nasser Sherkat" ],
      "venue" : "Proceedings - International Workshop on Frontiers in Handwriting Recognition, IWFHR,",
      "citeRegEx" : "Bezine et al\\.,? \\Q2004\\E",
      "shortCiteRegEx" : "Bezine et al\\.",
      "year" : 2004
    }, {
      "title" : "Mixture density networks",
      "author" : [ "Christopher M Bishop" ],
      "venue" : null,
      "citeRegEx" : "Bishop.,? \\Q1994\\E",
      "shortCiteRegEx" : "Bishop.",
      "year" : 1994
    }, {
      "title" : "Segmenting handwritten signatures at their perceptually important points",
      "author" : [ "J-J Brault", "Rejean Plamondon" ],
      "venue" : "IEEE Transactions on Pattern Analysis and Machine Intelligence,",
      "citeRegEx" : "Brault and Plamondon.,? \\Q1993\\E",
      "shortCiteRegEx" : "Brault and Plamondon.",
      "year" : 1993
    }, {
      "title" : "A neural network model for cursive script production",
      "author" : [ "Daniel Bullock", "Stephen Grossberg", "Christian Mannes" ],
      "venue" : "Biological Cybernetics,",
      "citeRegEx" : "Bullock et al\\.,? \\Q1993\\E",
      "shortCiteRegEx" : "Bullock et al\\.",
      "year" : 1993
    }, {
      "title" : "A tutorial on task-parameterized movement learning and retrieval",
      "author" : [ "Sylvain Calinon" ],
      "venue" : "Intelligent Service Robotics,",
      "citeRegEx" : "Calinon.,? \\Q2016\\E",
      "shortCiteRegEx" : "Calinon.",
      "year" : 2016
    }, {
      "title" : "Perceptual saliency of points along the contour of everyday objects: A large-scale study",
      "author" : [ "Joeri De Winter", "Johan Wagemans" ],
      "venue" : "Perception & Psychophysics,",
      "citeRegEx" : "Winter and Wagemans.,? \\Q2008\\E",
      "shortCiteRegEx" : "Winter and Wagemans.",
      "year" : 2008
    }, {
      "title" : "Maximum likelihood from incomplete data via the EM algorithm",
      "author" : [ "A.P. Dempster" ],
      "venue" : "J. Royal Statistical Society B,",
      "citeRegEx" : "Dempster,? \\Q1977\\E",
      "shortCiteRegEx" : "Dempster",
      "year" : 1977
    }, {
      "title" : "An interactive system for the automatic generation of huge handwriting databases from a few specimens",
      "author" : [ "Moussa Djioua", "Réjean Plamondon" ],
      "venue" : "In Pattern Recognition,",
      "citeRegEx" : "Djioua and Plamondon.,? \\Q2008\\E",
      "shortCiteRegEx" : "Djioua and Plamondon.",
      "year" : 2008
    }, {
      "title" : "A new methodology to improve myoelectric signal processing using handwriting",
      "author" : [ "Moussa Djioua", "Réjean Plamondon" ],
      "venue" : "In International Conference on Frontiers in Handwriting Recognition,",
      "citeRegEx" : "Djioua and Plamondon.,? \\Q2008\\E",
      "shortCiteRegEx" : "Djioua and Plamondon.",
      "year" : 2008
    }, {
      "title" : "A model of handwriting",
      "author" : [ "Shimon Edelman", "Tamar Flash" ],
      "venue" : "Biological cybernetics,",
      "citeRegEx" : "Edelman and Flash.,? \\Q1987\\E",
      "shortCiteRegEx" : "Edelman and Flash.",
      "year" : 1987
    }, {
      "title" : "Information along contours and object boundaries",
      "author" : [ "Jacob Feldman", "Manish Singh" ],
      "venue" : "Psychological review,",
      "citeRegEx" : "Feldman and Singh.,? \\Q2005\\E",
      "shortCiteRegEx" : "Feldman and Singh.",
      "year" : 2005
    }, {
      "title" : "Neuromuscular representation and synthetic generation of handwritten whiteboard notes",
      "author" : [ "Anath Fischer", "Rejean Plamondon", "Colin O’Reilly", "Yvon Savaria" ],
      "venue" : "In Frontiers in Handwriting Recognition (ICFHR),",
      "citeRegEx" : "Fischer et al\\.,? \\Q2014\\E",
      "shortCiteRegEx" : "Fischer et al\\.",
      "year" : 2014
    }, {
      "title" : "Affine differential geometry analysis of human arm movements",
      "author" : [ "Tamar Flash", "Amir A Handzel" ],
      "venue" : "Biological cybernetics,",
      "citeRegEx" : "Flash and Handzel.,? \\Q2007\\E",
      "shortCiteRegEx" : "Flash and Handzel.",
      "year" : 2007
    }, {
      "title" : "Motion, emotion and empathy in esthetic experience",
      "author" : [ "David Freedberg", "Vittorio Gallese" ],
      "venue" : "Trends in cognitive sciences,",
      "citeRegEx" : "Freedberg and Gallese.,? \\Q2007\\E",
      "shortCiteRegEx" : "Freedberg and Gallese.",
      "year" : 2007
    }, {
      "title" : "Learning to forget: Continual prediction with LSTM",
      "author" : [ "Felix A Gers", "Jürgen Schmidhuber", "Fred Cummins" ],
      "venue" : "Neural Computation,",
      "citeRegEx" : "Gers et al\\.,? \\Q2000\\E",
      "shortCiteRegEx" : "Gers et al\\.",
      "year" : 2000
    }, {
      "title" : "Supervised Sequence Labelling with Recurrent Neural Networks",
      "author" : [ "Alex Graves" ],
      "venue" : "PhD thesis,",
      "citeRegEx" : "Graves.,? \\Q2008\\E",
      "shortCiteRegEx" : "Graves.",
      "year" : 2008
    }, {
      "title" : "Generating sequences with recurrent neural networks",
      "author" : [ "Alex Graves" ],
      "venue" : "arXiv preprint arXiv:1308.0850,",
      "citeRegEx" : "Graves.,? \\Q2013\\E",
      "shortCiteRegEx" : "Graves.",
      "year" : 2013
    }, {
      "title" : "Generative Handwriting Demo using TensorFlow",
      "author" : [ "David Ha" ],
      "venue" : null,
      "citeRegEx" : "Ha.,? \\Q2015\\E",
      "shortCiteRegEx" : "Ha.",
      "year" : 2015
    }, {
      "title" : "Long short-term memory",
      "author" : [ "Sepp Hochreiter", "Jürgen Schmidhuber" ],
      "venue" : "Neural computation,",
      "citeRegEx" : "Hochreiter and Schmidhuber.,? \\Q1997\\E",
      "shortCiteRegEx" : "Hochreiter and Schmidhuber.",
      "year" : 1997
    }, {
      "title" : "Graphonomics: Contemporary research in handwriting",
      "author" : [ "Henry SR Kao", "Rumjahn Hoosain", "GP Van Galen" ],
      "venue" : null,
      "citeRegEx" : "Kao et al\\.,? \\Q1986\\E",
      "shortCiteRegEx" : "Kao et al\\.",
      "year" : 1986
    }, {
      "title" : "Adam: A method for stochastic optimization",
      "author" : [ "Diederik Kingma", "Jimmy Ba" ],
      "venue" : "arXiv preprint arXiv:1412.6980,",
      "citeRegEx" : "Kingma and Ba.,? \\Q2014\\E",
      "shortCiteRegEx" : "Kingma and Ba.",
      "year" : 2014
    }, {
      "title" : "The law relating the kinematic and figural aspects of drawing movements",
      "author" : [ "Francesco Lacquaniti", "Carlo Terzuolo", "Paolo Viviani" ],
      "venue" : "Acta psychologica,",
      "citeRegEx" : "Lacquaniti et al\\.,? \\Q1983\\E",
      "shortCiteRegEx" : "Lacquaniti et al\\.",
      "year" : 1983
    }, {
      "title" : "The beta-velocity model for simulating handwritten korean scripts. In Electronic Publishing, Artistic Imaging, and Digital Typography",
      "author" : [ "Do-Hoon Lee", "Hwan-Gue Cho" ],
      "venue" : null,
      "citeRegEx" : "Lee and Cho.,? \\Q1998\\E",
      "shortCiteRegEx" : "Lee and Cho.",
      "year" : 1998
    }, {
      "title" : "Effects of inertial load and velocity on the braking process of voluntary limb movements",
      "author" : [ "F Lestienne" ],
      "venue" : "Experimental Brain Research,",
      "citeRegEx" : "Lestienne.,? \\Q1979\\E",
      "shortCiteRegEx" : "Lestienne.",
      "year" : 1979
    }, {
      "title" : "Segmentation and reconstruction of on-line handwritten scripts",
      "author" : [ "Xiaolin Li", "Marc Parizeau", "Réjean Plamondon" ],
      "venue" : "Pattern recognition,",
      "citeRegEx" : "Li et al\\.,? \\Q1998\\E",
      "shortCiteRegEx" : "Li et al\\.",
      "year" : 1998
    }, {
      "title" : "Why does deep and cheap learning work so well",
      "author" : [ "Henry W Lin", "Max Tegmark" ],
      "venue" : "arXiv preprint arXiv:1608.08225,",
      "citeRegEx" : "Lin and Tegmark.,? \\Q2016\\E",
      "shortCiteRegEx" : "Lin and Tegmark.",
      "year" : 2016
    }, {
      "title" : "A neuro-beta-elliptic model for handwriting generation movements",
      "author" : [ "Majda Ltaief", "Hala Bezine", "Adel M Alimi" ],
      "venue" : "In Frontiers in Handwriting Recognition (ICFHR),",
      "citeRegEx" : "Ltaief et al\\.,? \\Q2012\\E",
      "shortCiteRegEx" : "Ltaief et al\\.",
      "year" : 2012
    }, {
      "title" : "The iam-database: an english sentence database for offline handwriting recognition",
      "author" : [ "U-V Marti", "Horst Bunke" ],
      "venue" : "International Journal on Document Analysis and Recognition,",
      "citeRegEx" : "Marti and Bunke.,? \\Q2002\\E",
      "shortCiteRegEx" : "Marti and Bunke.",
      "year" : 2002
    }, {
      "title" : "Trajectory formation and handwriting: a computational model",
      "author" : [ "P. Morasso", "FA Mussa Ivaldi" ],
      "venue" : "Biological cybernetics,",
      "citeRegEx" : "Morasso and Ivaldi.,? \\Q1982\\E",
      "shortCiteRegEx" : "Morasso and Ivaldi.",
      "year" : 1982
    }, {
      "title" : "Asymmetric velocity and acceleration profiles of human arm movements",
      "author" : [ "H. Nagasaki" ],
      "venue" : "Experimental Brain Research,",
      "citeRegEx" : "Nagasaki.,? \\Q1989\\E",
      "shortCiteRegEx" : "Nagasaki.",
      "year" : 1989
    }, {
      "title" : "Inferring motor programs from images of handwritten digits",
      "author" : [ "Vinod Nair", "Geoffrey E Hinton" ],
      "venue" : "In Advances in neural information processing systems,",
      "citeRegEx" : "Nair and Hinton.,? \\Q2005\\E",
      "shortCiteRegEx" : "Nair and Hinton.",
      "year" : 2005
    }, {
      "title" : "Automatic extraction of sigma-lognormal parameters on signatures",
      "author" : [ "Christian O’Reilly", "Réjean Plamondon" ],
      "venue" : "In Proceedings of the 11th International Conference on Frontier in Handwriting Recognition,",
      "citeRegEx" : "O.Reilly and Plamondon.,? \\Q2008\\E",
      "shortCiteRegEx" : "O.Reilly and Plamondon.",
      "year" : 2008
    }, {
      "title" : "On the difficulty of training recurrent neural networks",
      "author" : [ "Razvan Pascanu", "Tomas Mikolov", "Yoshua Bengio" ],
      "venue" : "In International Conference on Machine Learning ICML,",
      "citeRegEx" : "Pascanu et al\\.,? \\Q2013\\E",
      "shortCiteRegEx" : "Pascanu et al\\.",
      "year" : 2013
    }, {
      "title" : "Dropout Improves Recurrent Neural Networks for Handwriting Recognition",
      "author" : [ "Vu Pham", "Théodore Bluche", "Christopher Kermorvant", "Jérôme Louradour" ],
      "venue" : "In Frontiers in Handwriting Recognition (ICFHR),",
      "citeRegEx" : "Pham et al\\.,? \\Q2014\\E",
      "shortCiteRegEx" : "Pham et al\\.",
      "year" : 2014
    }, {
      "title" : "A kinematic theory of rapid human movement",
      "author" : [ "R. Plamondon" ],
      "venue" : "Part IV. Biological Cybernetics,",
      "citeRegEx" : "Plamondon,? \\Q2003\\E",
      "shortCiteRegEx" : "Plamondon",
      "year" : 2003
    }, {
      "title" : "Recent developments in the study of rapid human movements with the kinematic theory",
      "author" : [ "R. Plamondon" ],
      "venue" : "Pattern Recognition Letters,",
      "citeRegEx" : "Plamondon,? \\Q2014\\E",
      "shortCiteRegEx" : "Plamondon",
      "year" : 2014
    }, {
      "title" : "A Kinematic Theory of Rapid Human Movements",
      "author" : [ "Réjean Plamondon" ],
      "venue" : "Part I . Movement Representation and Generation. Biological cybernetics,",
      "citeRegEx" : "Plamondon.,? \\Q1995\\E",
      "shortCiteRegEx" : "Plamondon.",
      "year" : 1995
    }, {
      "title" : "A multi-level representation paradigm for handwriting stroke generation",
      "author" : [ "Réjean Plamondon", "Moussa Djioua" ],
      "venue" : "Human Movement Science,",
      "citeRegEx" : "Plamondon and Djioua.,? \\Q2006\\E",
      "shortCiteRegEx" : "Plamondon and Djioua.",
      "year" : 2006
    }, {
      "title" : "A neural model for generating and learning a rapid movement sequence",
      "author" : [ "Réjean Plamondon", "Claudio M Privitera" ],
      "venue" : "Biological cybernetics,",
      "citeRegEx" : "Plamondon and Privitera.,? \\Q1996\\E",
      "shortCiteRegEx" : "Plamondon and Privitera.",
      "year" : 1996
    }, {
      "title" : "Recent Developments in the Study of Rapid Human Movements with the Kinematic Theory",
      "author" : [ "Rejean Plamondon", "Moussa Djioua", "Christian O’Reilly" ],
      "venue" : "Traitement Du Signal,",
      "citeRegEx" : "Plamondon et al\\.,? \\Q2009\\E",
      "shortCiteRegEx" : "Plamondon et al\\.",
      "year" : 2009
    }, {
      "title" : "The Lognormal Handwriter: Learning, Performing and Declining",
      "author" : [ "Rejean Plamondon", "Christian O’Reilly", "Celine Remi", "Theresa Duval" ],
      "venue" : "Frontiers in Psychology,",
      "citeRegEx" : "Plamondon et al\\.,? \\Q2013\\E",
      "shortCiteRegEx" : "Plamondon et al\\.",
      "year" : 2013
    }, {
      "title" : "Avoiding spurious submovement decompositions II",
      "author" : [ "Brandon Rohrer", "Neville Hogan" ],
      "venue" : "Biological cybernetics,",
      "citeRegEx" : "Rohrer and Hogan.,? \\Q2006\\E",
      "shortCiteRegEx" : "Rohrer and Hogan.",
      "year" : 2006
    }, {
      "title" : "Planning reaches by evaluating stored postures",
      "author" : [ "David A Rosenbaum", "Loukia D Loukopoulos", "Ruud GJ Meulenbroek", "Jonathan Vaughan", "Sascha E Engelbrecht" ],
      "venue" : "Psychological review,",
      "citeRegEx" : "Rosenbaum et al\\.,? \\Q1995\\E",
      "shortCiteRegEx" : "Rosenbaum et al\\.",
      "year" : 1995
    }, {
      "title" : "A neural oscillator-network model of temporal pattern generation",
      "author" : [ "Lambert Schomaker" ],
      "venue" : "Human movement science,",
      "citeRegEx" : "Schomaker.,? \\Q1992\\E",
      "shortCiteRegEx" : "Schomaker.",
      "year" : 1992
    }, {
      "title" : "Better Generative Models for Sequential Data Problems: Bidirectional Recurrent Mixture Density Networks",
      "author" : [ "Mike Schuster" ],
      "venue" : "In Advances in Neural Information Processing Systems (NIPS),",
      "citeRegEx" : "Schuster.,? \\Q1999\\E",
      "shortCiteRegEx" : "Schuster.",
      "year" : 1999
    }, {
      "title" : "Many regression algorithms, one unified model: A review",
      "author" : [ "Freek Stulp", "Olivier Sigaud" ],
      "venue" : "Neural Networks,",
      "citeRegEx" : "Stulp and Sigaud.,? \\Q2015\\E",
      "shortCiteRegEx" : "Stulp and Sigaud.",
      "year" : 2015
    }, {
      "title" : "Training Recurrent neural Networks",
      "author" : [ "Ilya Sutskever" ],
      "venue" : "PhD thesis, University of Toronto,",
      "citeRegEx" : "Sutskever.,? \\Q2013\\E",
      "shortCiteRegEx" : "Sutskever.",
      "year" : 2013
    }, {
      "title" : "Template-based Synthetic Handwriting Generation for the Training of Recognition Systems",
      "author" : [ "Tamas Varga", "Daniel Kilchhofer", "Horst Bunke" ],
      "venue" : "In Proc. of 12th Conf. of the International Graphonomics Society,",
      "citeRegEx" : "Varga et al\\.,? \\Q2005\\E",
      "shortCiteRegEx" : "Varga et al\\.",
      "year" : 2005
    }, {
      "title" : "Trajectory determines movement",
      "author" : [ "P Viviani", "C Terzuolo" ],
      "venue" : "dynamics. Neuroscience,",
      "citeRegEx" : "Viviani and Terzuolo.,? \\Q1982\\E",
      "shortCiteRegEx" : "Viviani and Terzuolo.",
      "year" : 1982
    }, {
      "title" : "A developmental study of the relationship between geometry and kinematics in drawing movements",
      "author" : [ "Paolo Viviani", "Roland Schneider" ],
      "venue" : "Journal of Experimental Psychology: Human Perception and Performance,",
      "citeRegEx" : "Viviani and Schneider.,? \\Q1991\\E",
      "shortCiteRegEx" : "Viviani and Schneider.",
      "year" : 1991
    }, {
      "title" : "A neural network model for arm trajectory formation using forward and inverse dynamics models",
      "author" : [ "Yasuhiro Wada", "Mitsuo Kawato" ],
      "venue" : "Neural Networks,",
      "citeRegEx" : "Wada and Kawato.,? \\Q1993\\E",
      "shortCiteRegEx" : "Wada and Kawato.",
      "year" : 1993
    }, {
      "title" : "Drawing and Recognizing Chinese Characters with Recurrent Neural Network",
      "author" : [ "Xu-Yao Zhang", "Fei Yin", "Yan-Ming Zhang", "Cheng-Lin Liu", "Yoshua Bengio" ],
      "venue" : "arXiv preprint arXiv:1606.06539,",
      "citeRegEx" : "Zhang et al\\.,? \\Q2016\\E",
      "shortCiteRegEx" : "Zhang et al\\.",
      "year" : 2016
    }, {
      "title" : "2008): first we measure the turning angle at each position of the input p[k] and then compute a smooth version of the signal by convolving it with a Hanning window. We assume that the turning angles have Figure 13: Input key-point estimation. Left, the (smoothed) turning angle surprisal signal and the key-points estimated with peak detection. Right, the corresponding key-points along the input trajectory",
      "author" : [ "Feldman", "Singh" ],
      "venue" : null,
      "citeRegEx" : "Feldman and Singh,? \\Q2005\\E",
      "shortCiteRegEx" : "Feldman and Singh",
      "year" : 2005
    } ],
    "referenceMentions" : [ {
      "referenceID" : 19,
      "context" : "We build on recent results in handwriting prediction developed by Graves (2013), and we focus on generating sequences that possess the statistical and dynamic qualities of handwriting and calligraphic art forms.",
      "startOffset" : 66,
      "endOffset" : 80
    }, {
      "referenceID" : 20,
      "context" : "Recent results (Graves, 2013) have demonstrated that, given a sufficiently large training data-set, Long Short-Term Memory (LSTM) (Hochreiter & Schmidhuber, 1997) Recurrent Mixture Density Networks (RMDNs) (Schuster, 1999) are capable of learning and generating convincing synthetic handwriting sequences.",
      "startOffset" : 15,
      "endOffset" : 29
    }, {
      "referenceID" : 48,
      "context" : "Recent results (Graves, 2013) have demonstrated that, given a sufficiently large training data-set, Long Short-Term Memory (LSTM) (Hochreiter & Schmidhuber, 1997) Recurrent Mixture Density Networks (RMDNs) (Schuster, 1999) are capable of learning and generating convincing synthetic handwriting sequences.",
      "startOffset" : 206,
      "endOffset" : 222
    }, {
      "referenceID" : 40,
      "context" : "In this study we explore a similar network architecture combined with an intermediate feature representation, given by the parameters of a physiologically plausible model of handwriting: the Sigma Lognormal model (Plamondon, 1995; Plamondon et al., 2014).",
      "startOffset" : 213,
      "endOffset" : 254
    }, {
      "referenceID" : 20,
      "context" : "Note that for the scope of this study, we do not implement text-to-handwriting synthesis (Graves, 2013), but rather focus on the task of generating sequences that possess the statistical and dynamic qualities of handwriting, which can be expanded to calligraphy, asemic handwriting, drawings and graffiti (Berio & Leymarie, 2015; Berio et al.",
      "startOffset" : 89,
      "endOffset" : 103
    }, {
      "referenceID" : 2,
      "context" : "Note that for the scope of this study, we do not implement text-to-handwriting synthesis (Graves, 2013), but rather focus on the task of generating sequences that possess the statistical and dynamic qualities of handwriting, which can be expanded to calligraphy, asemic handwriting, drawings and graffiti (Berio & Leymarie, 2015; Berio et al., 2016)).",
      "startOffset" : 305,
      "endOffset" : 349
    }, {
      "referenceID" : 18,
      "context" : "Recent results (Graves, 2013) have demonstrated that, given a sufficiently large training data-set, Long Short-Term Memory (LSTM) (Hochreiter & Schmidhuber, 1997) Recurrent Mixture Density Networks (RMDNs) (Schuster, 1999) are capable of learning and generating convincing synthetic handwriting sequences. In this study we explore a similar network architecture combined with an intermediate feature representation, given by the parameters of a physiologically plausible model of handwriting: the Sigma Lognormal model (Plamondon, 1995; Plamondon et al., 2014). In the work by Graves (2013) and subsequent derivations, the RMDN operates on raw sequences of points recorded with a digitizing device.",
      "startOffset" : 16,
      "endOffset" : 591
    }, {
      "referenceID" : 23,
      "context" : "Our study is grounded on a number of notions and principles that have been observed in the general study of human movement as well as in the handwriting synthesis/analysis field (known as Graphonomics (Kao et al., 1986)).",
      "startOffset" : 201,
      "endOffset" : 219
    }, {
      "referenceID" : 27,
      "context" : "The speed profile of aiming movements is typically characterised by a “bell shape” that is variably skewed depending on the rapidity of the movement (Lestienne, 1979; Nagasaki, 1989; Plamondon et al., 2013).",
      "startOffset" : 149,
      "endOffset" : 206
    }, {
      "referenceID" : 33,
      "context" : "The speed profile of aiming movements is typically characterised by a “bell shape” that is variably skewed depending on the rapidity of the movement (Lestienne, 1979; Nagasaki, 1989; Plamondon et al., 2013).",
      "startOffset" : 149,
      "endOffset" : 206
    }, {
      "referenceID" : 44,
      "context" : "The speed profile of aiming movements is typically characterised by a “bell shape” that is variably skewed depending on the rapidity of the movement (Lestienne, 1979; Nagasaki, 1989; Plamondon et al., 2013).",
      "startOffset" : 149,
      "endOffset" : 206
    }, {
      "referenceID" : 46,
      "context" : "A number of methods synthesise handwriting through the temporal superimposition of strokes, the velocity profile of which is modelled with a variety of functions including sinusoidal functions (Morasso & Mussa Ivaldi, 1982; Maarse, 1987; Rosenbaum et al., 1995), Beta functions (Lee & Cho, 1998; Bezine et al.",
      "startOffset" : 193,
      "endOffset" : 261
    }, {
      "referenceID" : 4,
      "context" : ", 1995), Beta functions (Lee & Cho, 1998; Bezine et al., 2004), and lognormals (Plamondon et al.",
      "startOffset" : 24,
      "endOffset" : 62
    }, {
      "referenceID" : 43,
      "context" : ", 2004), and lognormals (Plamondon et al., 2009).",
      "startOffset" : 24,
      "endOffset" : 48
    }, {
      "referenceID" : 40,
      "context" : "in an extensive body of work since the 1990’s (Plamondon, 1995; Plamondon et al., 2014).",
      "startOffset" : 46,
      "endOffset" : 87
    }, {
      "referenceID" : 44,
      "context" : "This assumption is attractive from a modelling perspective because it abstracts the high complexity of the neuromuscular system in charge of generating movements with a relatively simple mathematical model which further provides state of the art reconstruction of human velocity data (Rohrer & Hogan, 2006; Plamondon et al., 2013).",
      "startOffset" : 284,
      "endOffset" : 330
    }, {
      "referenceID" : 47,
      "context" : "A number of methods have used neural inspired approaches for the task of handwriting trajectory formation (Schomaker, 1992; Bullock et al., 1993; Wada & Kawato, 1993).",
      "startOffset" : 106,
      "endOffset" : 166
    }, {
      "referenceID" : 7,
      "context" : "A number of methods have used neural inspired approaches for the task of handwriting trajectory formation (Schomaker, 1992; Bullock et al., 1993; Wada & Kawato, 1993).",
      "startOffset" : 106,
      "endOffset" : 166
    }, {
      "referenceID" : 5,
      "context" : "Our method builds in particular on the work of Graves (2013), who describes a system that uses a recurrent mixture density networks (RMDNs) (Bishop, 1994) extended with a LSTM architecture (Hochreiter & Schmidhuber, 1997), to generate synthetic handwriting in a variety of styles.",
      "startOffset" : 140,
      "endOffset" : 154
    }, {
      "referenceID" : 4,
      "context" : ", 1995), Beta functions (Lee & Cho, 1998; Bezine et al., 2004), and lognormals (Plamondon et al., 2009). In this study we rely on a family of models known as the Kinematic Theory of Rapid Human Movements, that has been developed by Plamondon et al. in an extensive body of work since the 1990’s (Plamondon, 1995; Plamondon et al., 2014). Plamondon et al. (2003) show that if we consider that a movement is the result of the parallel and hierarchical interaction of a large number of coupled linear systems, the impulse response of such a system to a centrally generated command asymptotically converges to a lognormal function.",
      "startOffset" : 42,
      "endOffset" : 362
    }, {
      "referenceID" : 4,
      "context" : ", 1995), Beta functions (Lee & Cho, 1998; Bezine et al., 2004), and lognormals (Plamondon et al., 2009). In this study we rely on a family of models known as the Kinematic Theory of Rapid Human Movements, that has been developed by Plamondon et al. in an extensive body of work since the 1990’s (Plamondon, 1995; Plamondon et al., 2014). Plamondon et al. (2003) show that if we consider that a movement is the result of the parallel and hierarchical interaction of a large number of coupled linear systems, the impulse response of such a system to a centrally generated command asymptotically converges to a lognormal function. This assumption is attractive from a modelling perspective because it abstracts the high complexity of the neuromuscular system in charge of generating movements with a relatively simple mathematical model which further provides state of the art reconstruction of human velocity data (Rohrer & Hogan, 2006; Plamondon et al., 2013). A number of methods have used neural inspired approaches for the task of handwriting trajectory formation (Schomaker, 1992; Bullock et al., 1993; Wada & Kawato, 1993). Similarly to our proposed method, Ltaief et al. (2012) train a neural on a preprocessed dataset where the raw input data is reconstructed in the form of handwriting model parameters.",
      "startOffset" : 42,
      "endOffset" : 1183
    }, {
      "referenceID" : 4,
      "context" : ", 1995), Beta functions (Lee & Cho, 1998; Bezine et al., 2004), and lognormals (Plamondon et al., 2009). In this study we rely on a family of models known as the Kinematic Theory of Rapid Human Movements, that has been developed by Plamondon et al. in an extensive body of work since the 1990’s (Plamondon, 1995; Plamondon et al., 2014). Plamondon et al. (2003) show that if we consider that a movement is the result of the parallel and hierarchical interaction of a large number of coupled linear systems, the impulse response of such a system to a centrally generated command asymptotically converges to a lognormal function. This assumption is attractive from a modelling perspective because it abstracts the high complexity of the neuromuscular system in charge of generating movements with a relatively simple mathematical model which further provides state of the art reconstruction of human velocity data (Rohrer & Hogan, 2006; Plamondon et al., 2013). A number of methods have used neural inspired approaches for the task of handwriting trajectory formation (Schomaker, 1992; Bullock et al., 1993; Wada & Kawato, 1993). Similarly to our proposed method, Ltaief et al. (2012) train a neural on a preprocessed dataset where the raw input data is reconstructed in the form of handwriting model parameters. Nair & Hinton (2005) use a sequence of neural networks to learn the motion of two orthogonal mass spring systems from images of handwritten digits for classification purposes.",
      "startOffset" : 42,
      "endOffset" : 1332
    }, {
      "referenceID" : 4,
      "context" : ", 1995), Beta functions (Lee & Cho, 1998; Bezine et al., 2004), and lognormals (Plamondon et al., 2009). In this study we rely on a family of models known as the Kinematic Theory of Rapid Human Movements, that has been developed by Plamondon et al. in an extensive body of work since the 1990’s (Plamondon, 1995; Plamondon et al., 2014). Plamondon et al. (2003) show that if we consider that a movement is the result of the parallel and hierarchical interaction of a large number of coupled linear systems, the impulse response of such a system to a centrally generated command asymptotically converges to a lognormal function. This assumption is attractive from a modelling perspective because it abstracts the high complexity of the neuromuscular system in charge of generating movements with a relatively simple mathematical model which further provides state of the art reconstruction of human velocity data (Rohrer & Hogan, 2006; Plamondon et al., 2013). A number of methods have used neural inspired approaches for the task of handwriting trajectory formation (Schomaker, 1992; Bullock et al., 1993; Wada & Kawato, 1993). Similarly to our proposed method, Ltaief et al. (2012) train a neural on a preprocessed dataset where the raw input data is reconstructed in the form of handwriting model parameters. Nair & Hinton (2005) use a sequence of neural networks to learn the motion of two orthogonal mass spring systems from images of handwritten digits for classification purposes. With a similar motivation to ours, Plamondon & Privitera (1996) use a Self Organising Map (SOM) to learn a sequence of ballistic targets, which describe a coarse motor plan of handwriting trajectories.",
      "startOffset" : 42,
      "endOffset" : 1551
    }, {
      "referenceID" : 4,
      "context" : ", 1995), Beta functions (Lee & Cho, 1998; Bezine et al., 2004), and lognormals (Plamondon et al., 2009). In this study we rely on a family of models known as the Kinematic Theory of Rapid Human Movements, that has been developed by Plamondon et al. in an extensive body of work since the 1990’s (Plamondon, 1995; Plamondon et al., 2014). Plamondon et al. (2003) show that if we consider that a movement is the result of the parallel and hierarchical interaction of a large number of coupled linear systems, the impulse response of such a system to a centrally generated command asymptotically converges to a lognormal function. This assumption is attractive from a modelling perspective because it abstracts the high complexity of the neuromuscular system in charge of generating movements with a relatively simple mathematical model which further provides state of the art reconstruction of human velocity data (Rohrer & Hogan, 2006; Plamondon et al., 2013). A number of methods have used neural inspired approaches for the task of handwriting trajectory formation (Schomaker, 1992; Bullock et al., 1993; Wada & Kawato, 1993). Similarly to our proposed method, Ltaief et al. (2012) train a neural on a preprocessed dataset where the raw input data is reconstructed in the form of handwriting model parameters. Nair & Hinton (2005) use a sequence of neural networks to learn the motion of two orthogonal mass spring systems from images of handwritten digits for classification purposes. With a similar motivation to ours, Plamondon & Privitera (1996) use a Self Organising Map (SOM) to learn a sequence of ballistic targets, which describe a coarse motor plan of handwriting trajectories. Our method builds in particular on the work of Graves (2013), who describes a system that uses a recurrent mixture density networks (RMDNs) (Bishop, 1994) extended with a LSTM architecture (Hochreiter & Schmidhuber, 1997), to generate synthetic handwriting in a variety of styles.",
      "startOffset" : 42,
      "endOffset" : 1750
    }, {
      "referenceID" : 40,
      "context" : "1 SIGMA LOGNORMAL MODEL On the basis of Plamondon’s Kinematic Theory (Plamondon, 1995), the Sigma Lognormal (ΣΛ) model (Plamondon & Djioua, 2006) describes complex handwriting trajectories via the vectorial superimposition of a discrete number of strokes.",
      "startOffset" : 69,
      "endOffset" : 86
    }, {
      "referenceID" : 5,
      "context" : "2 RECURRENT MIXTURE DENSITY NETWORKS Mixture Density Networks (MDN) were introduced by Bishop (1994) in order to model and predict the parameters of a Gaussian Mixture Model (GMM), i.",
      "startOffset" : 87,
      "endOffset" : 101
    }, {
      "referenceID" : 5,
      "context" : "2 RECURRENT MIXTURE DENSITY NETWORKS Mixture Density Networks (MDN) were introduced by Bishop (1994) in order to model and predict the parameters of a Gaussian Mixture Model (GMM), i.e. a set of means, covariances and mixture weights. Schuster (1999) showed that MDNs could be to model temporal data using RNNs.",
      "startOffset" : 87,
      "endOffset" : 251
    }, {
      "referenceID" : 5,
      "context" : "2 RECURRENT MIXTURE DENSITY NETWORKS Mixture Density Networks (MDN) were introduced by Bishop (1994) in order to model and predict the parameters of a Gaussian Mixture Model (GMM), i.e. a set of means, covariances and mixture weights. Schuster (1999) showed that MDNs could be to model temporal data using RNNs. The author used Recurrent Mixture Density Networks (RMDN) to model the statistical properties of speech, and they were found to be more successful than traditional GMMs. Graves (2013) used LSTM RMDNs to model and synthesise online handwriting, providing the basis for extensions to the method, also used in Ha et al.",
      "startOffset" : 87,
      "endOffset" : 496
    }, {
      "referenceID" : 5,
      "context" : "2 RECURRENT MIXTURE DENSITY NETWORKS Mixture Density Networks (MDN) were introduced by Bishop (1994) in order to model and predict the parameters of a Gaussian Mixture Model (GMM), i.e. a set of means, covariances and mixture weights. Schuster (1999) showed that MDNs could be to model temporal data using RNNs. The author used Recurrent Mixture Density Networks (RMDN) to model the statistical properties of speech, and they were found to be more successful than traditional GMMs. Graves (2013) used LSTM RMDNs to model and synthesise online handwriting, providing the basis for extensions to the method, also used in Ha et al. (2016); Zhang et al.",
      "startOffset" : 87,
      "endOffset" : 636
    }, {
      "referenceID" : 5,
      "context" : "2 RECURRENT MIXTURE DENSITY NETWORKS Mixture Density Networks (MDN) were introduced by Bishop (1994) in order to model and predict the parameters of a Gaussian Mixture Model (GMM), i.e. a set of means, covariances and mixture weights. Schuster (1999) showed that MDNs could be to model temporal data using RNNs. The author used Recurrent Mixture Density Networks (RMDN) to model the statistical properties of speech, and they were found to be more successful than traditional GMMs. Graves (2013) used LSTM RMDNs to model and synthesise online handwriting, providing the basis for extensions to the method, also used in Ha et al. (2016); Zhang et al. (2016). Note that in the case of a sequential model, the RMDN outputs a unique set of GMM parameters for each timestep t, allowing the probability distribution to change with time as the input sequence develops.",
      "startOffset" : 87,
      "endOffset" : 657
    }, {
      "referenceID" : 19,
      "context" : "Similarly to Graves (2013), most of our results come from experiments made on the IAM online handwriting database (Marti & Bunke, 2002).",
      "startOffset" : 13,
      "endOffset" : 27
    }, {
      "referenceID" : 15,
      "context" : "al in order to reconstruct ΣΛ-model parameters from digitised pen input data (O’Reilly & Plamondon, 2008; Plamondon et al., 2014; Fischer et al., 2014).",
      "startOffset" : 77,
      "endOffset" : 151
    }, {
      "referenceID" : 15,
      "context" : "3) (Djioua & Plamondon, 2008a; Fischer et al., 2014; Berio & Leymarie, 2015).",
      "startOffset" : 3,
      "endOffset" : 76
    }, {
      "referenceID" : 19,
      "context" : "The implementation of this model is very similar to the handwriting prediction demonstrated by Graves (2013), although instead of operating directly on the digitised pen positions, we operate on the much coarser virtual target sequences which are extracted during the preprocessing step.",
      "startOffset" : 95,
      "endOffset" : 109
    }, {
      "referenceID" : 19,
      "context" : "Using such a representation provides a performance that is similar to the handwriting prediction demonstrated by Graves (2013) and Ha et al.",
      "startOffset" : 113,
      "endOffset" : 127
    }, {
      "referenceID" : 19,
      "context" : "Using such a representation provides a performance that is similar to the handwriting prediction demonstrated by Graves (2013) and Ha et al. (2016), with a number of additional benefits.",
      "startOffset" : 113,
      "endOffset" : 148
    } ],
    "year" : 2016,
    "abstractText" : "The purpose of this study is to explore the feasibility and potential benefits of using a physiological plausible model of handwriting as a feature representation for sequence generation with recurrent mixture density networks. We build on recent results in handwriting prediction developed by Graves (2013), and we focus on generating sequences that possess the statistical and dynamic qualities of handwriting and calligraphic art forms. Rather than model raw sequence data, we first preprocess and reconstruct the input training data with a concise representation given by a motor plan (in the form of a coarse sequence of ‘ballistic’ targets) and corresponding dynamic parameters (which define the velocity and curvature of the pen-tip trajectory). This representation provides a number of advantages, such as enabling the system to learn from very few examples by introducing artificial variability in the training data, and mixing of visual and dynamic qualities learned from different datasets.",
    "creator" : "LaTeX with hyperref package"
  }
}