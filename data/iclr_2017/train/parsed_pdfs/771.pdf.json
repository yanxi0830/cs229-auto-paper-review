{
  "name" : "771.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "TATIONS WITH A LEXICON",
    "authors" : [ "Yuanzhi Ke", "Masafumi Hagiwara" ],
    "emails" : [ "hagiwara}@keio.jp" ],
    "sections" : [ {
      "heading" : "1 INTRODUCTION",
      "text" : "Vector-space representations of words are reported useful and improve the performance of the machine learning algorithms for many natural language processing tasks such as name entity recognition and chunking (Turian et al., 2010), text classification (Socher et al., 2012; Le & Mikolov, 2014; Kim, 2014; Joulin et al., 2016), topic extraction (Das et al., 2015; Li et al., 2016), and machine translation (Zaremba et al., 2014; Sutskever et al., 2014).\nPeople are still trying to improve the vector-space representations for words. Bojanowski et al. (2016) attempt to improve word vectors by involving character level information. Other works (Yu & Dredze, 2014; Xu et al., 2014; Faruqui et al., 2015; Bollegala et al., 2016) try to estimate better word vectors by using a lexicon or ontology. The idea is simple: because a lexicon or ontology contains well-defined relations about words, we can use them to improve word vectors.\nHowever, for a polysemous word, one of its synonym does not always mean the same thing with the original one under different contexts. For example, the word ”point” equals ”score” in ”Team A got 3 points”, but does not in ”my point of view.” A method to address this issue is to estimate a vector for each word sense (Huang et al., 2012; Chen et al., 2014) or per word type (Neelakantan et al., 2014). However, it requires additional word sense disambiguation or part-of-speech tagging to use such word vectors.\nIn this paper, we propose a method to improve the vector-space representations using a lexicon and alleviate the adverse effect of polysemy, keeping one vector per word. We estimate the degree of reliability for each paraphrase in the lexicon and eliminate the ones with lower degrees in learning. The experimental results show that the proposed method is effective and outperforms the prior works. The major contributions of our work include:\n• We propose a novel approach involving fuzzy sets to reduce the noise brought by polysemous words in the word vector space when a lexicon is used for learning, and a model to use the fuzzy paraphrase sets to learn the word vector space.\n• Although some prior works propose to solve the polysemy problem by estimating one vector per word sense or type, using such word vectors requires additional pre-process. Our proposed method keeps one vector per word. It makes the word vectors easier to use in practical terms: it is neither necessary to disambiguate the word senses nor to tag the part-of-speeches before we use the word vectors.\nWe give an introduction of our proposed method in section 2. We show the effects of different paraphrase sets, parameters, corpus size, and evaluate the effectiveness of our approach by comparing to simpler algorithms in section 3. We compare our approach with the prior works via an evaluation experiment in section 4. We give the findings, conclusions and outlook in section 5."
    }, {
      "heading" : "2 THE PROPOSED METHOD",
      "text" : ""
    }, {
      "heading" : "2.1 FUZZY PARAPHRASES",
      "text" : "As described in section 1, whether a polysemous word’s paraphrase is the same as the original depends on the context.\nHenceforth, if we simply use all the paraphrases of a word in the lexicon to improve the word vector without discrimination, they may sometimes bring noise to the vector-space.\nA conventional method for them is to give each word sense a vector. However, such vector-spaces require additional word sense disambiguation in practical use.\nHere, we propose a method to alleviate the adverse effects of polysemous words’ paraphrases without word sense disambiguation. Our idea is to annotate each paraphrase with a degree about its reliability, like a member of a fuzzy set. We call such paraphrases as “fuzzy paraphrases”, and their degrees as the “memberships.”"
    }, {
      "heading" : "2.2 LEARNING WITH FUZZY PARAPHRASES",
      "text" : "We also propose a novel method to jointly learn corpus with a lexicon, in order to use fuzzy paraphrases to improve the word vectors.\nIf the meanings of two words are totally the same, they can replace each other in a text without changing the semantic features. Henceforth, we can learn the lexicon by replacing the words in the corpus with its lexical paraphrases.\nWe learn the word vectors by maximizing the probability of a word for a given context, and also for a generated context where words are replaced by their paraphrases randomly. The memberships of the fuzzy paraphrases are used here to control the probability that the replacements occur by a control function as shown in Figure 1.\nFor a text corpus T , denote wi the ith word in T , c the context window, wj a word in the context window, Lwj the paraphrase set of wj in the lexicon L, wk the kth fuzzy paraphrase in Lwj , and xjk the membership of wk for wj , the objective is\nT∑ wi∈T ∑ (i−c)≤j≤(i+c) log p(wi|wj) + Lwj∑ wk∈Lwj f(xjk) log p(wi|wk)  . (1) The function f(xjk) of the membership xjk is a specified drop-out function. It returns 0 more for the paraphrases that have lower memberships, and 1 more for the others.\n2.3 MEMBERSHIP ESTIMATION & CONTROL FUNCTION f(x)\nLooking for a control function that is easy to train, we notice that if two words are more often to be translated to the same word in another language, the replacement of them are less likely to change the meaning of the original sentence. Thus, we use a function of the bilingual similarity (denoted as Sjk) as the membership function:\nxjk = g(Sjk). (2)\nThere have been works about calculating the similarity of words using such bilingual information. A lexicon called the paraphrase database (PPDB) provides scores of the similarity of paraphrases on the basis of bilingual features (Ganitkevitch et al., 2013; Pavlick et al., 2015b;a).\nWe scale the similarity score of the paraphrase wk to [0, 1] in PPDB2.0 as the memberships, and draw the values of f(xjk) from a Bernoulli distribution subjected to them. Denote Sjk the similarity score of word wj and wk in PPDB2.0, the value of f(xjk) is drawn from the Bernoulli distribution:\nf(xjk) ∼ Bernoulli(xjk), (3)\nxjk = Sjk\nmax j∈T,k∈L\nSjk . (4)"
    }, {
      "heading" : "2.4 TRAINING",
      "text" : "We do not need to train f(xjk) using the method described above. The model can be trained by negative sampling (Mikolov et al., 2013b): For word wO and a word wI in its context, denote AI as the set of the paraphrases for wI accepted by f(xjk), we maximize log p(wO|wI) by distinguishing the noise words from a noise distribution Pn(w) from wO and its accepted paraphrases in AI by logistic regression:\nlog p(wO|wI) = log σ(vwOTvwI ) + n∑\ni=1\nEwi ∼ Pn(w)[log σ(−vwiTvwI )], wi 6= wO, wi /∈ AI\n(5)\nHere, vwO T and vwi T stand for the transposed matrices of vwO and vwi , respectively. n is the number of negative samples used. σ(x) is a sigmoid function, σ(x) = 1/(1 + e−x)."
    }, {
      "heading" : "3 MODEL EXPLORATION",
      "text" : ""
    }, {
      "heading" : "3.1 CORPUS FOR EXPERIMENTS",
      "text" : "We use enwiki91 mainly for tuning and model exploration. It has a balanced size(1 GB), containing 123,353,508 tokens. It provides enough data to alleviate randomness while it does not take too much time for our model to learn.\n1http://mattmahoney.net/dc/enwiki9.zip\nWe use ukWaC (Baroni et al., 2009) to compare with the prior works in section 4. But we do not use it for model exploration, because it takes more than 20 hours to learn it, as an enormous corpus containing 12 GB text."
    }, {
      "heading" : "3.2 BENCHMARKS",
      "text" : "We used several benchmarks. They are Wordsim-353 (WS353) (Finkelstein et al., 2001) (353 word pairs), SimLex-999 (SimLex) (Hill et al., 2016) (999 word pairs), the Stanford Rare Word Similarity Dataset (RW) (Luong et al., 2013) (2034 word pairs), the MEN Dataset (MEN) (Bruni et al., 2014) (3000 word pairs), and the Mikolov’s (Google’s) word analogical reasoning task (Mikolov et al., 2013a).\nWS353, SimLex, and RW are gold standards. They provide the similarity of words labeled by humans. We report the Spearman’s rank correlation (ρ) for them.\nMikolov’s word analogical reasoning task is another widely used benchmark for word vectors. It contains a semantic part (SEM), and a syntactic part (SYN). We use the basic way suggested in their paper to find the answer for it: to guess word b′ related to b in the way how a′ is related to a, the word closest in cosine similarity to a′ − a+ b is returned as b′. We find that the benchmark scores change every time we learn the corpus, even under the same settings. It is because that the models involve random numbers. Therefore we should consider the margin of error of the changes when we use the benchmarks.\nTo test the margin of error, we firstly used our proposed method to repeat learning enwiki9 for 10 times under the same parameters. Then we tested the vectors under each benchmark, to find the margin of error. In each test, we used the same parameters: the vector dimension was set to 100 for speed, the window size was set to 8, and 25 negative samples were used. The results are shown in Table 1. We use them to analyze the other experimental results later."
    }, {
      "heading" : "3.3 DIFFERENT TYPES OF PARAPHRASES",
      "text" : "In PPDB2.0, there are six relationships for paraphrases. For word X and Y , the different relationships between them defined in PPDB2.0 are shown in Table 2. We do not consider the exclusion and independent relations because they are not semantic paraphrases. Those of equivalence are the most reliable because they are the closest ones. But we still want to know whether it is better to take\nthe entailment and the other related paraphrases into consideration. We learn enwiki9 with different paraphrase sets and use SimLex to evaluate the trained vectors.\nFigure 2 compares the performance using different paraphrase sets, tested by SimLex. We can see that it is best to use the equivalence and entailment (forward + reverse) paraphrases together or use only the equivalence paraphrases. Only using the entailment paraphrases is weak. Involving the other related paraphrases deteriorates the performance. We use the Equivalence and Entailment paraphrases in the experiments according to these results."
    }, {
      "heading" : "3.4 EFFECTS OF PARAMETERS",
      "text" : "We use our proposed method to learn enwiki9 under different parameter settings to evaluate the effects of parameters. We firstly learn enwiki9 under different parameter settings and then test the vectors using SimLex, WS353, RW, MEN, SEM and SYN. We report Spearman’s rank correlation ρ for SimLex, WS353, RW and MEN, the percentage of correct answers for SEM and SYN."
    }, {
      "heading" : "3.4.1 EFFECTS OF VECTOR SPACE DIMENSION",
      "text" : "We compare the benchmarks using different vector-space dimensions. Figure 3 shows the change of each benchmark’s scores under different dimensions.\nWe find that:\n• The larger vectors do not bring the better performance for most of the benchmarks (except SimLex), although some previous works suggest that the higher dimensions brings better performance for their methods (Pennington et al., 2014; Levy & Goldberg, 2014b).\n• The curves of SimLex and SYN are gradual. However, there are several abrupt changes in the others. And those of WS353 and RW do not change gradually.\n• The best dimension for different benchmarks is not consistent.\nThe differences in the content of the benchmarks may cause the inconsistence. For example, SimLex rates related but dissimilar words lower than the other word similarity benchmarks (Hill et al., 2016; Chiu et al., 2016). The results suggest that the best dimensions for our method depends on the task."
    }, {
      "heading" : "3.4.2 EFFECTS OF CONTEXT WINDOW SIZE",
      "text" : "We compared the benchmarks using different context window sizes. They are shown in Figure 4. Previous works argue that larger window sizes introduce more topic words, and smaller ones emphasize word functions (Turney, 2012; Levy & Goldberg, 2014a; Levy et al., 2015; Hill et al., 2016; Chiu et al., 2016). Different context window sizes provide different balances between relatedness and similarity. The best window size depends on what we want the vectors to be. We also see that in our results.\nThe relationship between the window size and performance depends on how they rate the pairs. For example, WS353 rates word pairs according to association rather than similarity (Finkelstein et al., 2001; Hill et al., 2016). As larger window capture relatedness rather than similarity, the results show\nthat the larger the window is, the better for WS353. The MEN dataset also prefer relatedness than similarity (Bruni et al., 2014), but they gave annotators examples involving similarity2. It may be the reason that the windows larger than 8 deteriorate the benchmarks based on MEN (Figure 4d). The standards of WS353 and MEN to rate the words are similar (Bruni et al., 2014). It leads to their similar curves (Figure 4b and 4d). The worst window sizes of them are also close. When the window size is set to about 2 or 3, respectively, the balance of similarity and relatedness is the worst for them.\nUnlike the other word similarity dataset, SimLex rates synonyms high and related dissimilar word pairs low. Therefore, the smallest window is the most suitable for SimLex because it is best for capturing the functional similarity.\nThe results of RW differs from the others (Figure 4c). There are many abrupt changes. The best window size is 10, but 1 is better than 2-9. The dataset contains rare words. Because of their low frequencies, usage of broad context window may be better to draw features for them. However, additional words introduced by larger windows may also deteriorate the vectors of unusual words. For such tasks requiring rare word vectors of high quality, we should be careful in tuning the context window size.\nFor Google’s word analogical tasks (SEM and SYN), the questions are quite related to the topic or domain. For examples, there are questions about the capitals of the countries. They are associated but not synonymous. Therefore a larger window is usually better. However for SYN, using window size 9 is a little better than 10 in Figure 4d and for MEN 8 is best in Figure 4f. It may be because that if the window is too large, it introduces too many words and reduces the sparsity (Chiu et al., 2016).\nWe can consider that the best context window size depends on the task, but we should avoid using too large window."
    }, {
      "heading" : "3.4.3 EFFECTS OF NEGATIVE SAMPLES",
      "text" : "We also explored the effects of the number of negative samples. The results are shown in Figure 5. 2According to their homepage: http://clic.cimec.unitn.it/ elia.bruni/MEN.html.\nIn Figures 5a, 5c and 5f, we see that overfitting occurs when we use more than 15 negative samples. In Figure 5b and Figure 5e, it occurs from 25 and 20, respectively. In Figure 5d, the performance does not change very much when we use more than 30 negative samples.\nThe results indicate that too many negative samples may cause overfitting. For 3 of the 6 benchmarks, it is best to use 15 negative samples. But we should be careful in practice use because the other different results suggest that the best number depends on the task.\nThe abrupt change at around 15 in Figure 5b is interesting. WS353 is the smallest dataset among those we used. Because of the small size, the effects of randomness may cause such singularities when the vector-space is not well trained."
    }, {
      "heading" : "3.5 EFFECTS OF THE CONTROL FUNCTION & THE CORPUS SIZE",
      "text" : "In this section, we evaluate the effectiveness of our fuzzy approach, by comparing to the situations that set f(x) in Equation (1) as:\n• f(x) = 1: It makes the model regard all paraphrases equally. They are all used without drop-out.\n• f(x) = 0: It makes the model use no paraphrases, equivalent to CBOW.\nIt is also a good way to show the effects of corpus size by comparing the proposed method to the situations above using corpora in varying size. Therefore we discuss them together in this section.\nWe use text83 together with eEnwiki9 and ukWaC described in section 3.1. It is a small corpus containing 100 MB text. To show the difference, we report the benchmarks scores including not only SimLex, but also MEN, and the word analogical task (SEM and SYN). They are the other benchmarks that are shown relatively solid in section 3.2. The vector-space dimension is set to 300. The context window size is set to 8. 25 negative samples are used in learning. The results are shown in Figure 6.\n3http://mattmahoney.net/dc/text8.zip\nWe can see that:\n• The proposed function outperforms the others for SimLex and MEN under text8, for all the benchmarks under enwiki9, for SimLex, SEM and SYN under ukWaC.\n• The proposed function is always better than f(x) = 1 in the experiments, no matter what the benchmark is or how big the corpus is.\n• For SEM, the proposed function is weaker than f(x) = 0 under text8, slightly better under enwiki9, and obviously outperforms f(x) = 0 under ukWaC. As the proposed function outperforms under larger corpora, the relatively low scores under text8 may be caused by the effects of randomness: the proposed function involves random numbers; they bring huge instability under such tiny corpora. Another possible reason is that the control function is less useful for text8 because there are few polysemous words in the tiny corpus.\n• There is no advantages to use f(x) = 1 instead of f(x) = 0 for both text8 and enwiki9. It shows that learning the context words replaced by paraphrases may be not a good idea without fuzzy approaches. However, if we use the proposed control function, the results are better and go beyond those of f(x) = 0 in most tests. It shows that the control function utilizing fuzzy paraphrases improves the performance.\nTherefore, we can see that the proposed control function using the fuzzy paraphrases annotated with the degrees of reliability improves the quality of the learned word vector-space."
    }, {
      "heading" : "4 COMPARISON WITH THE PRIOR WORKS",
      "text" : "We compared our work to the prior works using a lexicon to improve word vectors. However, we failed to use the public code to reproduce the works of Yu & Dredze (2014) and Bollegala et al. (2016). We also failed to find an available implementation of Xu et al. (2014). Hence, we use the\nsame corpus and benchmarks with Bollegala et al. (2016) and compare our results with the reported scores of the prior works in their paper. The benchmarks are:\n• The MEN Dataset (MEN); • Word Analogical Reasoning Task (SEM and SYN).\nRubenstein-Goodenough dataset (RG) (Rubenstein & Goodenough, 1965) is also used in their works. However, we do not use it, because it fails the sanity check in Batchkarov et al. (2016): ρ may increase when noise is added.\nWe use ukWaC to learn the word vectors, the same with Bollegala et al. (2016). We also use the same parameters with the prior works: The vector-space dimension is set to 300; the context window size is set to 8; the number of negative samples is set to 25. Then we calculate the cosine similarity of the words and report 100 ∗ ρ for Men. We use the add method described in section 3.2 and report the percentage of correct answers, for the word analogical reasoning task.\nTable 3 shows the results of the experiments. The of MEN and SEM is 0.86 and 0.44 as shown in Table 1. Therefore we see that our proposed method outperforms the prior works under these benchmarks. We consider our score for SYN is as good as Bollegala et al. (2016) achieved, and better than the others, because its margin of error is 1.79 as shown in Table 1."
    }, {
      "heading" : "5 CONCLUSION & THE FUTURE WORKS",
      "text" : "We proposed a fuzzy approach to control the contamination caused by the polysemous words when a lexicon is used to improve the vector-space word representations. We annotate each paraphrase of a word with a degree of reliability, like the members of a fuzzy set with their memberships, on the basis of their multilingual similarities to the original ones. We use the fuzzy paraphrases to learn a corpus by jointly learning a generated text, in which the original words are randomly replaced by their paraphrases. A paraphrase is less likely to be put into the generated text if it has lower reliability than the others, and vice versa.\nWe tested the performance using different types of paraphrases in the lexicon PPDB2.0 and find that it is best to use the equivalence type and the entailment type. Using other related paraphrases deteriorates the performance.\nWe explored the effects of parameters. We find that the best parameter setting depends on the task. We should tune the model carefully in practical use.\nWe evaluated the effectiveness of our approach by comparing it to the situations that simpler functions are used to control replacements: f(x) = 1 which accepts all, and f(x) = 0 which rejects\nall. We also repeated the experiments under a tiny, a medium sized, and a large corpus, to see the effects of the corpus size on the effectiveness. Our approach achieves the best in 3 of 4 benchmarks under the tiny corpus, and in all benchmarks under the medium sized and the large one. The results indicate that our approach is effective to improve the word vectors.\nOur proposed method also achieved the top scores, compared with the prior works.\nUnlike the previous works that solve the problems about polysemy by estimating a vector for each word sense or word type, our approach keeps one vector per word. It makes the word vectors easier to use in practical terms: it is neither necessary to disambiguate the word senses nor to tag the part-of-speeches before we use the word vectors.\nThe fuzzy paraphrases can also be employed for the other models with some changes. We are going to show it in the future. The proposed idea for the polysemy problem without word sense disambiguation is meaningful especially for practical use because it saves the effort of part-of-speech tagging and word sense disambiguation.\nBesides, the control function may be more accurate if it considers all the context. We are also going to work on it in the future.\nWe have opened the source of a demo of the proposed method online4."
    } ],
    "references" : [ {
      "title" : "The wacky wide web: a collection of very large linguistically processed web-crawled corpora",
      "author" : [ "Marco Baroni", "Silvia Bernardini", "Adriano Ferraresi", "Eros Zanchetta" ],
      "venue" : "Language resources and evaluation,",
      "citeRegEx" : "Baroni et al\\.,? \\Q2009\\E",
      "shortCiteRegEx" : "Baroni et al\\.",
      "year" : 2009
    }, {
      "title" : "A critique of word similarity as a method for evaluating distributional semantic models. the 54th annual meeting of the Association for Computational Linguistics",
      "author" : [ "Miroslav Batchkarov", "Thomas Kober", "Jeremy Reffin", "Julie Weeds", "David Weir" ],
      "venue" : "(ACL 2016),",
      "citeRegEx" : "Batchkarov et al\\.,? \\Q2016\\E",
      "shortCiteRegEx" : "Batchkarov et al\\.",
      "year" : 2016
    }, {
      "title" : "Enriching word vectors with subword information",
      "author" : [ "Piotr Bojanowski", "Edouard Grave", "Armand Joulin", "Tomas Mikolov" ],
      "venue" : "arXiv preprint arXiv:1607.04606,",
      "citeRegEx" : "Bojanowski et al\\.,? \\Q2016\\E",
      "shortCiteRegEx" : "Bojanowski et al\\.",
      "year" : 2016
    }, {
      "title" : "Joint word representation learning using a corpus and a semantic lexicon",
      "author" : [ "Danushka Bollegala", "Alsuhaibani Mohammed", "Takanori Maehara", "Ken-Ichi Kawarabayashi" ],
      "venue" : "In Proceedings of the 30th AAAI Conference on Artificial Intelligence",
      "citeRegEx" : "Bollegala et al\\.,? \\Q2016\\E",
      "shortCiteRegEx" : "Bollegala et al\\.",
      "year" : 2016
    }, {
      "title" : "Multimodal distributional semantics",
      "author" : [ "Elia Bruni", "Nam Khanh Tran", "Marco Baroni" ],
      "venue" : "J. Artif. Int. Res.,",
      "citeRegEx" : "Bruni et al\\.,? \\Q2014\\E",
      "shortCiteRegEx" : "Bruni et al\\.",
      "year" : 2014
    }, {
      "title" : "A unified model for word sense representation and disambiguation",
      "author" : [ "Xinxiong Chen", "Zhiyuan Liu", "Maosong Sun" ],
      "venue" : "In Proceedings of the conference on empirical methods in natural language processing (EMNLP),",
      "citeRegEx" : "Chen et al\\.,? \\Q2014\\E",
      "shortCiteRegEx" : "Chen et al\\.",
      "year" : 2014
    }, {
      "title" : "Intrinsic evaluation of word vectors fails to predict extrinsic performance",
      "author" : [ "Billy Chiu", "Anna Korhonen", "Sampo Pyysalo" ],
      "venue" : "In Proceedings of RepEval",
      "citeRegEx" : "Chiu et al\\.,? \\Q2016\\E",
      "shortCiteRegEx" : "Chiu et al\\.",
      "year" : 2016
    }, {
      "title" : "Gaussian lda for topic models with word embeddings. In Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)",
      "author" : [ "Rajarshi Das", "Manzil Zaheer", "Chris Dyer" ],
      "venue" : "Association for Computational Linguistics,",
      "citeRegEx" : "Das et al\\.,? \\Q2015\\E",
      "shortCiteRegEx" : "Das et al\\.",
      "year" : 2015
    }, {
      "title" : "Retrofitting word vectors to semantic lexicons",
      "author" : [ "Manaal Faruqui", "Jesse Dodge", "Sujay K. Jauhar", "Chris Dyer", "Eduard Hovy", "Noah A. Smith" ],
      "venue" : "In Proceedings of NAACL,",
      "citeRegEx" : "Faruqui et al\\.,? \\Q2015\\E",
      "shortCiteRegEx" : "Faruqui et al\\.",
      "year" : 2015
    }, {
      "title" : "Placing search in context: The concept revisited",
      "author" : [ "Lev Finkelstein", "Evgeniy Gabrilovich", "Yossi Matias", "Ehud Rivlin", "Zach Solan", "Gadi Wolfman", "Eytan Ruppin" ],
      "venue" : "In Proceedings of the 10th international conference on World Wide Web,",
      "citeRegEx" : "Finkelstein et al\\.,? \\Q2001\\E",
      "shortCiteRegEx" : "Finkelstein et al\\.",
      "year" : 2001
    }, {
      "title" : "PPDB: The paraphrase database",
      "author" : [ "Juri Ganitkevitch", "Benjamin Van Durme", "Chris Callison-Burch" ],
      "venue" : "In Proceedings of NAACL-HLT,",
      "citeRegEx" : "Ganitkevitch et al\\.,? \\Q2013\\E",
      "shortCiteRegEx" : "Ganitkevitch et al\\.",
      "year" : 2013
    }, {
      "title" : "Simlex-999: Evaluating semantic models with (genuine) similarity estimation",
      "author" : [ "Felix Hill", "Roi Reichart", "Anna Korhonen" ],
      "venue" : "Computational Linguistics,",
      "citeRegEx" : "Hill et al\\.,? \\Q2016\\E",
      "shortCiteRegEx" : "Hill et al\\.",
      "year" : 2016
    }, {
      "title" : "Improving word representations via global context and multiple word prototypes",
      "author" : [ "Eric H Huang", "Richard Socher", "Christopher D Manning", "Andrew Y Ng" ],
      "venue" : "In Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics: Long Papers-Volume",
      "citeRegEx" : "Huang et al\\.,? \\Q2012\\E",
      "shortCiteRegEx" : "Huang et al\\.",
      "year" : 2012
    }, {
      "title" : "Bag of tricks for efficient text classification",
      "author" : [ "Armand Joulin", "Edouard Grave", "Piotr Bojanowski", "Tomas Mikolov" ],
      "venue" : "arXiv preprint arXiv:1607.01759,",
      "citeRegEx" : "Joulin et al\\.,? \\Q2016\\E",
      "shortCiteRegEx" : "Joulin et al\\.",
      "year" : 2016
    }, {
      "title" : "Convolutional neural networks for sentence classification",
      "author" : [ "Yoon Kim" ],
      "venue" : "In Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP),",
      "citeRegEx" : "Kim.,? \\Q2014\\E",
      "shortCiteRegEx" : "Kim.",
      "year" : 2014
    }, {
      "title" : "Distributed representations of sentences and documents",
      "author" : [ "Quoc V Le", "Tomas Mikolov" ],
      "venue" : "In the 31st International Conference on Machine Learning (ICML 2014),",
      "citeRegEx" : "Le and Mikolov.,? \\Q2014\\E",
      "shortCiteRegEx" : "Le and Mikolov.",
      "year" : 2014
    }, {
      "title" : "Dependencybased word embeddings",
      "author" : [ "Omer Levy", "Yoav Goldberg" ],
      "venue" : "In the 52nd Annual Meeting of the Association for Computational Linguistics (ACL 2014),",
      "citeRegEx" : "Levy and Goldberg.,? \\Q2014\\E",
      "shortCiteRegEx" : "Levy and Goldberg.",
      "year" : 2014
    }, {
      "title" : "Neural word embedding as implicit matrix factorization",
      "author" : [ "Omer Levy", "Yoav Goldberg" ],
      "venue" : "In Proceedings of the 27th International Conference on Neural Information Processing Systems, Advances in Neural Information Processing Systems",
      "citeRegEx" : "Levy and Goldberg.,? \\Q2014\\E",
      "shortCiteRegEx" : "Levy and Goldberg.",
      "year" : 2014
    }, {
      "title" : "Improving distributional similarity with lessons learned from word embeddings",
      "author" : [ "Omer Levy", "Yoav Goldberg", "Ido Dagan" ],
      "venue" : "Transactions of the Association for Computational Linguistics,",
      "citeRegEx" : "Levy et al\\.,? \\Q2015\\E",
      "shortCiteRegEx" : "Levy et al\\.",
      "year" : 2015
    }, {
      "title" : "Generative topic embedding: a continuous representation of documents. In the 54th annual meeting of the Association for Computational Linguistics (ACL 2016)",
      "author" : [ "Shaohua Li", "Tat-Seng Chua", "Jun Zhu", "Chunyan Miao" ],
      "venue" : "Association for Computational Linguistics,",
      "citeRegEx" : "Li et al\\.,? \\Q2016\\E",
      "shortCiteRegEx" : "Li et al\\.",
      "year" : 2016
    }, {
      "title" : "Better word representations with recursive neural networks for morphology",
      "author" : [ "Minh-Thang Luong", "Richard Socher", "Christopher D. Manning" ],
      "venue" : null,
      "citeRegEx" : "Luong et al\\.,? \\Q2013\\E",
      "shortCiteRegEx" : "Luong et al\\.",
      "year" : 2013
    }, {
      "title" : "Efficient estimation of word representations in vector space",
      "author" : [ "Tomas Mikolov", "Kai Chen", "Greg Corrado", "Jeffrey Dean" ],
      "venue" : "In ICLR Workshop,",
      "citeRegEx" : "Mikolov et al\\.,? \\Q2013\\E",
      "shortCiteRegEx" : "Mikolov et al\\.",
      "year" : 2013
    }, {
      "title" : "Distributed representations of words and phrases and their compositionality",
      "author" : [ "Tomas Mikolov", "Ilya Sutskever", "Kai Chen", "Greg S Corrado", "Jeff Dean" ],
      "venue" : "In Advances in neural information processing systems,",
      "citeRegEx" : "Mikolov et al\\.,? \\Q2013\\E",
      "shortCiteRegEx" : "Mikolov et al\\.",
      "year" : 2013
    }, {
      "title" : "Efficient nonparametric estimation of multiple embeddings per word in vector space",
      "author" : [ "Arvind Neelakantan", "Jeevan Shankar", "Alexandre Passos", "Andrew McCallum" ],
      "venue" : "In Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP),",
      "citeRegEx" : "Neelakantan et al\\.,? \\Q2014\\E",
      "shortCiteRegEx" : "Neelakantan et al\\.",
      "year" : 2014
    }, {
      "title" : "Adding semantics to data-driven paraphrasing. In Association for Computational Linguistics, Beijing, China, July 2015a",
      "author" : [ "Ellie Pavlick", "Johan Bos", "Malvina Nissim", "Charley Beller", "Benjamin Van Durme", "Chris CallisonBurch" ],
      "venue" : null,
      "citeRegEx" : "Pavlick et al\\.,? \\Q2015\\E",
      "shortCiteRegEx" : "Pavlick et al\\.",
      "year" : 2015
    }, {
      "title" : "Ppdb 2.0: Better paraphrase ranking, fine-grained entailment relations, word embeddings, and style classification",
      "author" : [ "Ellie Pavlick", "Pushpendre Rastogi", "Juri Ganitkevich", "Benjamin Van Durme", "Chris CallisonBurch" ],
      "venue" : "In Association for Computational Linguistics,",
      "citeRegEx" : "Pavlick et al\\.,? \\Q2015\\E",
      "shortCiteRegEx" : "Pavlick et al\\.",
      "year" : 2015
    }, {
      "title" : "Glove: Global vectors for word representation",
      "author" : [ "Jeffrey Pennington", "Richard Socher", "Christopher D. Manning" ],
      "venue" : "In Empirical Methods in Natural Language Processing (EMNLP),",
      "citeRegEx" : "Pennington et al\\.,? \\Q2014\\E",
      "shortCiteRegEx" : "Pennington et al\\.",
      "year" : 2014
    }, {
      "title" : "Contextual correlates of synonymy",
      "author" : [ "Herbert Rubenstein", "John B Goodenough" ],
      "venue" : "Communications of the ACM,",
      "citeRegEx" : "Rubenstein and Goodenough.,? \\Q1965\\E",
      "shortCiteRegEx" : "Rubenstein and Goodenough.",
      "year" : 1965
    }, {
      "title" : "Semantic compositionality through recursive matrix-vector spaces",
      "author" : [ "Richard Socher", "Brody Huval", "Christopher D Manning", "Andrew Y Ng" ],
      "venue" : "In Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning,",
      "citeRegEx" : "Socher et al\\.,? \\Q2012\\E",
      "shortCiteRegEx" : "Socher et al\\.",
      "year" : 2012
    }, {
      "title" : "Sequence to sequence learning with neural networks",
      "author" : [ "Ilya Sutskever", "Oriol Vinyals", "Quoc V. Le" ],
      "venue" : "In Advances in Neural Information Processing Systems",
      "citeRegEx" : "Sutskever et al\\.,? \\Q2014\\E",
      "shortCiteRegEx" : "Sutskever et al\\.",
      "year" : 2014
    }, {
      "title" : "Word representations: a simple and general method for semi-supervised learning. In Proceedings of the 48th annual meeting of the association for computational linguistics (ACL",
      "author" : [ "Joseph Turian", "Lev Ratinov", "Yoshua Bengio" ],
      "venue" : "Association for Computational Linguistics,",
      "citeRegEx" : "Turian et al\\.,? \\Q2010\\E",
      "shortCiteRegEx" : "Turian et al\\.",
      "year" : 2010
    }, {
      "title" : "Domain and function: A dual-space model of semantic relations and compositions",
      "author" : [ "Peter D. Turney" ],
      "venue" : "J. Artif. Int. Res.,",
      "citeRegEx" : "Turney.,? \\Q2012\\E",
      "shortCiteRegEx" : "Turney.",
      "year" : 2012
    }, {
      "title" : "Rc-net: A general framework for incorporating knowledge into word representations",
      "author" : [ "Chang Xu", "Yalong Bai", "Jiang Bian", "Bin Gao", "Gang Wang", "Xiaoguang Liu", "Tie-Yan Liu" ],
      "venue" : "In Proceedings of the 23rd ACM International Conference on Conference on Information and Knowledge Management,",
      "citeRegEx" : "Xu et al\\.,? \\Q2014\\E",
      "shortCiteRegEx" : "Xu et al\\.",
      "year" : 2014
    }, {
      "title" : "Improving lexical embeddings with semantic knowledge",
      "author" : [ "Mo Yu", "Mark Dredze" ],
      "venue" : "In the 52nd Annual Meeting of the Association for Computational Linguistics (ACL",
      "citeRegEx" : "Yu and Dredze.,? \\Q2014\\E",
      "shortCiteRegEx" : "Yu and Dredze.",
      "year" : 2014
    }, {
      "title" : "Recurrent neural network regularization",
      "author" : [ "Wojciech Zaremba", "Ilya Sutskever", "Oriol Vinyals" ],
      "venue" : "CoRR, abs/1409.2329,",
      "citeRegEx" : "Zaremba et al\\.,? \\Q2014\\E",
      "shortCiteRegEx" : "Zaremba et al\\.",
      "year" : 2014
    } ],
    "referenceMentions" : [ {
      "referenceID" : 30,
      "context" : "1 INTRODUCTION Vector-space representations of words are reported useful and improve the performance of the machine learning algorithms for many natural language processing tasks such as name entity recognition and chunking (Turian et al., 2010), text classification (Socher et al.",
      "startOffset" : 224,
      "endOffset" : 245
    }, {
      "referenceID" : 28,
      "context" : ", 2010), text classification (Socher et al., 2012; Le & Mikolov, 2014; Kim, 2014; Joulin et al., 2016), topic extraction (Das et al.",
      "startOffset" : 29,
      "endOffset" : 102
    }, {
      "referenceID" : 14,
      "context" : ", 2010), text classification (Socher et al., 2012; Le & Mikolov, 2014; Kim, 2014; Joulin et al., 2016), topic extraction (Das et al.",
      "startOffset" : 29,
      "endOffset" : 102
    }, {
      "referenceID" : 13,
      "context" : ", 2010), text classification (Socher et al., 2012; Le & Mikolov, 2014; Kim, 2014; Joulin et al., 2016), topic extraction (Das et al.",
      "startOffset" : 29,
      "endOffset" : 102
    }, {
      "referenceID" : 7,
      "context" : ", 2016), topic extraction (Das et al., 2015; Li et al., 2016), and machine translation (Zaremba et al.",
      "startOffset" : 26,
      "endOffset" : 61
    }, {
      "referenceID" : 19,
      "context" : ", 2016), topic extraction (Das et al., 2015; Li et al., 2016), and machine translation (Zaremba et al.",
      "startOffset" : 26,
      "endOffset" : 61
    }, {
      "referenceID" : 34,
      "context" : ", 2016), and machine translation (Zaremba et al., 2014; Sutskever et al., 2014).",
      "startOffset" : 33,
      "endOffset" : 79
    }, {
      "referenceID" : 29,
      "context" : ", 2016), and machine translation (Zaremba et al., 2014; Sutskever et al., 2014).",
      "startOffset" : 33,
      "endOffset" : 79
    }, {
      "referenceID" : 32,
      "context" : "Other works (Yu & Dredze, 2014; Xu et al., 2014; Faruqui et al., 2015; Bollegala et al., 2016) try to estimate better word vectors by using a lexicon or ontology.",
      "startOffset" : 12,
      "endOffset" : 94
    }, {
      "referenceID" : 8,
      "context" : "Other works (Yu & Dredze, 2014; Xu et al., 2014; Faruqui et al., 2015; Bollegala et al., 2016) try to estimate better word vectors by using a lexicon or ontology.",
      "startOffset" : 12,
      "endOffset" : 94
    }, {
      "referenceID" : 3,
      "context" : "Other works (Yu & Dredze, 2014; Xu et al., 2014; Faruqui et al., 2015; Bollegala et al., 2016) try to estimate better word vectors by using a lexicon or ontology.",
      "startOffset" : 12,
      "endOffset" : 94
    }, {
      "referenceID" : 12,
      "context" : "” A method to address this issue is to estimate a vector for each word sense (Huang et al., 2012; Chen et al., 2014) or per word type (Neelakantan et al.",
      "startOffset" : 77,
      "endOffset" : 116
    }, {
      "referenceID" : 5,
      "context" : "” A method to address this issue is to estimate a vector for each word sense (Huang et al., 2012; Chen et al., 2014) or per word type (Neelakantan et al.",
      "startOffset" : 77,
      "endOffset" : 116
    }, {
      "referenceID" : 23,
      "context" : ", 2014) or per word type (Neelakantan et al., 2014).",
      "startOffset" : 25,
      "endOffset" : 51
    }, {
      "referenceID" : 2,
      "context" : "Bojanowski et al. (2016) attempt to improve word vectors by involving character level information.",
      "startOffset" : 0,
      "endOffset" : 25
    }, {
      "referenceID" : 0,
      "context" : "We use ukWaC (Baroni et al., 2009) to compare with the prior works in section 4.",
      "startOffset" : 13,
      "endOffset" : 34
    }, {
      "referenceID" : 9,
      "context" : "They are Wordsim-353 (WS353) (Finkelstein et al., 2001) (353 word pairs), SimLex-999 (SimLex) (Hill et al.",
      "startOffset" : 29,
      "endOffset" : 55
    }, {
      "referenceID" : 11,
      "context" : ", 2001) (353 word pairs), SimLex-999 (SimLex) (Hill et al., 2016) (999 word pairs), the Stanford Rare Word Similarity Dataset (RW) (Luong et al.",
      "startOffset" : 46,
      "endOffset" : 65
    }, {
      "referenceID" : 20,
      "context" : ", 2016) (999 word pairs), the Stanford Rare Word Similarity Dataset (RW) (Luong et al., 2013) (2034 word pairs), the MEN Dataset (MEN) (Bruni et al.",
      "startOffset" : 73,
      "endOffset" : 93
    }, {
      "referenceID" : 4,
      "context" : ", 2013) (2034 word pairs), the MEN Dataset (MEN) (Bruni et al., 2014) (3000 word pairs), and the Mikolov’s (Google’s) word analogical reasoning task (Mikolov et al.",
      "startOffset" : 49,
      "endOffset" : 69
    }, {
      "referenceID" : 26,
      "context" : "We find that: • The larger vectors do not bring the better performance for most of the benchmarks (except SimLex), although some previous works suggest that the higher dimensions brings better performance for their methods (Pennington et al., 2014; Levy & Goldberg, 2014b).",
      "startOffset" : 223,
      "endOffset" : 272
    }, {
      "referenceID" : 11,
      "context" : "For example, SimLex rates related but dissimilar words lower than the other word similarity benchmarks (Hill et al., 2016; Chiu et al., 2016).",
      "startOffset" : 103,
      "endOffset" : 141
    }, {
      "referenceID" : 6,
      "context" : "For example, SimLex rates related but dissimilar words lower than the other word similarity benchmarks (Hill et al., 2016; Chiu et al., 2016).",
      "startOffset" : 103,
      "endOffset" : 141
    }, {
      "referenceID" : 31,
      "context" : "Previous works argue that larger window sizes introduce more topic words, and smaller ones emphasize word functions (Turney, 2012; Levy & Goldberg, 2014a; Levy et al., 2015; Hill et al., 2016; Chiu et al., 2016).",
      "startOffset" : 116,
      "endOffset" : 211
    }, {
      "referenceID" : 18,
      "context" : "Previous works argue that larger window sizes introduce more topic words, and smaller ones emphasize word functions (Turney, 2012; Levy & Goldberg, 2014a; Levy et al., 2015; Hill et al., 2016; Chiu et al., 2016).",
      "startOffset" : 116,
      "endOffset" : 211
    }, {
      "referenceID" : 11,
      "context" : "Previous works argue that larger window sizes introduce more topic words, and smaller ones emphasize word functions (Turney, 2012; Levy & Goldberg, 2014a; Levy et al., 2015; Hill et al., 2016; Chiu et al., 2016).",
      "startOffset" : 116,
      "endOffset" : 211
    }, {
      "referenceID" : 6,
      "context" : "Previous works argue that larger window sizes introduce more topic words, and smaller ones emphasize word functions (Turney, 2012; Levy & Goldberg, 2014a; Levy et al., 2015; Hill et al., 2016; Chiu et al., 2016).",
      "startOffset" : 116,
      "endOffset" : 211
    }, {
      "referenceID" : 9,
      "context" : "For example, WS353 rates word pairs according to association rather than similarity (Finkelstein et al., 2001; Hill et al., 2016).",
      "startOffset" : 84,
      "endOffset" : 129
    }, {
      "referenceID" : 11,
      "context" : "For example, WS353 rates word pairs according to association rather than similarity (Finkelstein et al., 2001; Hill et al., 2016).",
      "startOffset" : 84,
      "endOffset" : 129
    }, {
      "referenceID" : 4,
      "context" : "The MEN dataset also prefer relatedness than similarity (Bruni et al., 2014), but they gave annotators examples involving similarity2.",
      "startOffset" : 56,
      "endOffset" : 76
    }, {
      "referenceID" : 4,
      "context" : "The standards of WS353 and MEN to rate the words are similar (Bruni et al., 2014).",
      "startOffset" : 61,
      "endOffset" : 81
    }, {
      "referenceID" : 6,
      "context" : "It may be because that if the window is too large, it introduces too many words and reduces the sparsity (Chiu et al., 2016).",
      "startOffset" : 105,
      "endOffset" : 124
    }, {
      "referenceID" : 3,
      "context" : "However, we failed to use the public code to reproduce the works of Yu & Dredze (2014) and Bollegala et al. (2016). We also failed to find an available implementation of Xu et al.",
      "startOffset" : 91,
      "endOffset" : 115
    }, {
      "referenceID" : 3,
      "context" : "However, we failed to use the public code to reproduce the works of Yu & Dredze (2014) and Bollegala et al. (2016). We also failed to find an available implementation of Xu et al. (2014). Hence, we use the",
      "startOffset" : 91,
      "endOffset" : 187
    }, {
      "referenceID" : 3,
      "context" : "The scores of the prior works under ukWaC are from Bollegala et al. (2016). The SYN score of ours and Bollegala’s are marked as best together because the margin of error is 1.",
      "startOffset" : 51,
      "endOffset" : 75
    }, {
      "referenceID" : 32,
      "context" : "90 R-Net (Xu et al., 2014) - 32.",
      "startOffset" : 9,
      "endOffset" : 26
    }, {
      "referenceID" : 32,
      "context" : "46 C-Net (Xu et al., 2014) - 37.",
      "startOffset" : 9,
      "endOffset" : 26
    }, {
      "referenceID" : 32,
      "context" : "06 RC-Net (Xu et al., 2014) - 34.",
      "startOffset" : 10,
      "endOffset" : 27
    }, {
      "referenceID" : 3,
      "context" : "89 Bollegala et al. (2016) 70.",
      "startOffset" : 3,
      "endOffset" : 27
    }, {
      "referenceID" : 3,
      "context" : "89 Bollegala et al. (2016) 70.90 61.46 69.33 Yu & Dredze (2014) 50.",
      "startOffset" : 3,
      "endOffset" : 64
    }, {
      "referenceID" : 3,
      "context" : "89 Bollegala et al. (2016) 70.90 61.46 69.33 Yu & Dredze (2014) 50.10 - 29.90 R-Net (Xu et al., 2014) - 32.64 43.46 C-Net (Xu et al., 2014) - 37.07 40.06 RC-Net (Xu et al., 2014) - 34.36 44.42 Faruqui et al. (2015)(Pretrained by CBOW) 60.",
      "startOffset" : 3,
      "endOffset" : 215
    }, {
      "referenceID" : 3,
      "context" : "89 Bollegala et al. (2016) 70.90 61.46 69.33 Yu & Dredze (2014) 50.10 - 29.90 R-Net (Xu et al., 2014) - 32.64 43.46 C-Net (Xu et al., 2014) - 37.07 40.06 RC-Net (Xu et al., 2014) - 34.36 44.42 Faruqui et al. (2015)(Pretrained by CBOW) 60.50 36.65 52.50 Faruqui et al. (2015)(Pretrained by Skipgram) 65.",
      "startOffset" : 3,
      "endOffset" : 275
    }, {
      "referenceID" : 2,
      "context" : "same corpus and benchmarks with Bollegala et al. (2016) and compare our results with the reported scores of the prior works in their paper.",
      "startOffset" : 32,
      "endOffset" : 56
    }, {
      "referenceID" : 1,
      "context" : "However, we do not use it, because it fails the sanity check in Batchkarov et al. (2016): ρ may increase when noise is added.",
      "startOffset" : 64,
      "endOffset" : 89
    }, {
      "referenceID" : 1,
      "context" : "However, we do not use it, because it fails the sanity check in Batchkarov et al. (2016): ρ may increase when noise is added. We use ukWaC to learn the word vectors, the same with Bollegala et al. (2016). We also use the same parameters with the prior works: The vector-space dimension is set to 300; the context window size is set to 8; the number of negative samples is set to 25.",
      "startOffset" : 64,
      "endOffset" : 204
    }, {
      "referenceID" : 1,
      "context" : "However, we do not use it, because it fails the sanity check in Batchkarov et al. (2016): ρ may increase when noise is added. We use ukWaC to learn the word vectors, the same with Bollegala et al. (2016). We also use the same parameters with the prior works: The vector-space dimension is set to 300; the context window size is set to 8; the number of negative samples is set to 25. Then we calculate the cosine similarity of the words and report 100 ∗ ρ for Men. We use the add method described in section 3.2 and report the percentage of correct answers, for the word analogical reasoning task. Table 3 shows the results of the experiments. The of MEN and SEM is 0.86 and 0.44 as shown in Table 1. Therefore we see that our proposed method outperforms the prior works under these benchmarks. We consider our score for SYN is as good as Bollegala et al. (2016) achieved, and better than the others, because its margin of error is 1.",
      "startOffset" : 64,
      "endOffset" : 862
    } ],
    "year" : 2017,
    "abstractText" : "A synonym of a polysemous word is usually only the paraphrase of one sense among many. When lexicons are used to improve vector-space word representations, such paraphrases are unreliable and bring noise to the vector-space. The prior works use a coefficient to adjust the overall learning of the lexicons. They regard the paraphrases equally. In this paper, we propose a novel approach that regards the paraphrases diversely to alleviate the adverse effects of polysemy. We annotate each paraphrase with a degree of reliability. The paraphrases are randomly eliminated according to the degrees when our model learns word representations. In this way, our approach drops the unreliable paraphrases, keeping more reliable paraphrases at the same time. The experimental results show that the proposed method improves the word vectors. Our approach is an attempt to address the polysemy problem keeping one vector per word. It makes the approach easier to use than the conventional methods that estimate multiple vectors for a word. Our approach also outperforms the prior works in the experiments.",
    "creator" : "LaTeX with hyperref package"
  }
}