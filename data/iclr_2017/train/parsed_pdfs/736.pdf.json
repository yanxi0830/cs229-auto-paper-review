{
  "name" : "736.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "REVISITING BATCH NORMALIZATION FOR PRACTICAL DOMAIN ADAPTATION",
    "authors" : [ "Yanghao Li", "Naiyan Wang", "Jianping Shi", "Jiaying Liu", "Xiaodi Hou", "TuSimple SenseTime" ],
    "emails" : [ "lyttonhao@pku.edu.cn", "winsty@gmail.com", "shijianping5000@gmail.com", "liujiaying@pku.edu.cn", "xiaodi.hou@gmail.com" ],
    "sections" : [ {
      "heading" : "1 INTRODUCTION",
      "text" : "Training a DNN for a new image recognition task is expensive. It requires a large amount of labeled training images that are not easy to obtain. One common practice is to use labeled data from other related source such as a different public dataset, or harvesting images by keywords from a search engine. Because 1) the distributions of the source domains (third party datasets or Internet images) are often different from the target domain (testing images); and 2) DNN is particularly good at capturing dataset bias in its internal representation (Torralba & Efros, 2011), which eventually leads to overfitting, imperfectly paired training and testing sets usually leads to inferior performance.\nKnown as domain adaptation, the effort to bridge the gap between training and testing data distributions has been discussed several times under the context of deep learning (Tzeng et al., 2014; Long et al., 2015; Tzeng et al., 2015; Ganin & Lempitsky, 2015). To make the connection between the domain of training and the domain of testing, most of these methods require additional optimization steps and extra parameters. Such additional computational burden could greatly complicate the training of a DNN which is already intimidating enough for most people.\nIn this paper, we propose a simple yet effective approach called AdaBN for batch normalized DNN domain adaptation. We hypothesize that the label related knowledge is stored in the weight matrix of each layer, whereas domain related knowledge is represented by the statistics of the Batch Normalization (BN) (Ioffe & Szegedy, 2015) layer. Therefore, we can easily transfer the trained model to a new domain by modulating the statistics in the BN layer. This approach is straightforward to implement, has zero parameter to tune, and requires minimal computational resources. Moreover, our AdaBN is ready to be extended to more sophisticated scenarios such as multi-source domain adaptation and semi-supervised settings. Fig. 1 illustrates the flowchart of AdaBN. To summarize, our contributions are as follows:\n1. We propose a novel domain adaptation technique called Adaptive Batch Normalization (AdaBN). We show that AdaBN can naturally dissociate bias and variance of a dataset, which is ideal for domain adaptation tasks.\n2. We validate the effectiveness of our approach on standard benchmarks for both single source and multi-source domain adaptation. Our method outperforms the state-of-the-art methods.\n3. We conduct experiments on the cloud detection for remote sensing images to further demonstrate the effectiveness of our approach in practical use."
    }, {
      "heading" : "2 RELATED WORK",
      "text" : "Domain transfer in visual recognition tasks has gained increasing attention in recent literature (Beijbom, 2012; Patel et al., 2015). Often referred to as covariate shift (Shimodaira, 2000) or dataset bias (Torralba & Efros, 2011), this problem poses a great challenge to the generalization ability of a learned model. One key component of domain transfer is to model the difference between source and target distributions. In Khosla et al. (2012), the authors assign each dataset with an explicit bias vector, and train one discriminative model to handle multiple classification problems with different bias terms. A more explicit way to compute dataset difference is based on Maximum Mean Discrepancy (MMD) (Gretton et al., 2012). This approach projects each data sample into a Reproducing Kernel Hilbert Space, and then computes the difference of sample means. To reduce dataset discrepancies, many methods are proposed, including sample selections (Huang et al., 2006; Gong et al., 2013), explicit projection learning (Pan et al., 2011; Gopalan et al., 2011; Baktashmotlagh et al., 2013) and principal axes alignment (Fernando et al., 2013; Gong et al., 2012; Aljundi et al., 2015).\nAll of these methods face the same challenge of constructing the domain transfer function – a highdimensional non-linear function. Due to computational constraints, most of the proposed transfer functions are in the category of simple shallow projections, which are typically composed of kernel transformations and linear mapping functions.\nIn the field of deep learning, feature transferability across different domains is a tantalizing yet generally unsolved topic (Yosinski et al., 2014; Tommasi et al., 2015). To transfer the learned representations to a new dataset, pre-training plus fine-tuning (Donahue et al., 2014) have become de facto procedures. However, adaptation by fine-tuning is far from perfect. It requires a considerable amount of labeled data from the target domain, and non-negligible computational resources to retrain the whole network.\nA series of progress has been made in DNN to facilitate domain transfer. Early works of domain adaptation either focus on reordering fine-tuning samples (Chopra et al., 2013), or regularizing MMD (Gretton et al., 2012) in a shallow network (Ghifary et al., 2014). It is only until recently that the problem is directly attacked under the setting of classification of unlabeled target domain using modern convolutional neural network (CNN) architecture. DDC (Tzeng et al., 2014) used the classical MMD loss to regularize the representation in the last layer of CNN. DAN (Long et al., 2015) further extended the method to multiple kernel MMD and multiple layer adaptation. Besides adapting features using MMD, RTN (Long et al., 2016) also added a gated residual layer for classifier adaptation. RevGrad (Ganin & Lempitsky, 2015) devised a gradient reversal layer to compensate the back-propagated gradients that are domain specific. Recently, by explicitly modeling both private and shared components of the domain representations in the network, Bousmalis et al. (2016) proposed a Domain Separation Network to extract better domain-invariant features.\nAnother related work is CORAL (Sun et al., 2016). This model focuses on the last layer of CNN. CORAL whitens the data in source domain, and then re-correlates the source domain features to target domain. This operation aligns the second order statistics of source domain and target domain distributions. Surprisingly, such simple approach yields state-of-the-arts results in various text classification and visual recognition tasks. Recently, Deep CORAL (Sun & Saenko, 2016) also extends the method into DNN by incorporating a CORAL loss."
    }, {
      "heading" : "2.1 BATCH NORMALIZATION",
      "text" : "In this section, we briefly review Batch Normalization (BN) (Ioffe & Szegedy, 2015) which is closely related to our AdaBN. The BN layer is originally designed to alleviate the issue of internal covariate shifting – a common problem while training a very deep neural network. It first standardizes each feature in a mini-batch, and then learns a common slope and bias for each mini-batch. Formally, given the input to a BN layer X ∈ Rn×p, where n denotes the batch size, and p is the feature dimension, BN layer transforms a feature j ∈ {1 . . . p} into:\nx̂j = xj − E[X·j ]√\nVar[X·j ] ,\nyj = γj x̂j + βj ,\n(1)\nwhere xj and yj are the input/output scalars of one neuron response in one data sample; X·j denotes the jth column of the input data; and γj and βj are parameters to be learned. This transformation guarantees that the input distribution of each layer remains unchanged across different mini-batches. For Stochastic Gradient Descent (SGD) optimization, a stable input distribution could greatly facilitate model convergence, leading to much faster training speed for CNN. Moreover, if training data are shuffled at each epoch, the same training sample will be applied with different transformations, or in other words, more comprehensively augmented throughout the training. During the testing phase, the global statistics of all training samples is used to normalize every mini-batch of test data.\nExtensive experiments have shown that Batch Normalization significantly reduces the number of iteration to converge, and improves the final performance at the same time. BN layer has become a standard component in recent top-performing CNN architectures, such as deep residual network (He et al., 2016), and Inception V3 (Szegedy et al., 2015)."
    }, {
      "heading" : "3 THE MODEL",
      "text" : "In Sec. 3.1, we first analyze the domain shift in deep neural network, and reveal two key observations. Then in Sec. 3.2, we introduce our Adaptive Batch Normalization (AdaBN) method based on these observations."
    }, {
      "heading" : "3.1 A PILOT EXPERIMENT",
      "text" : "The Batch Normalization (BN) technique is originally proposed to help SGD optimization by aligning the distribution of training data. From this perspective, it is interesting to examine the BN parameters (batch-wise mean and variance) over different dataset at different layers of the network.\nIn this pilot experiment, we use MXNet implementation (Chen et al., 2016b) of the Inception-BN model (Ioffe & Szegedy, 2015) pre-trained on ImageNet classification task (Russakovsky et al., 2015) as our baseline DNN model. Our image data are drawn from (Bergamo & Torresani, 2010), which contains the same classes of images from both Caltech-256 dataset (Griffin et al., 2007) and Bing image search results. For each mini-batch sampled from one dataset, we concatenate the mean and variance of all neurons from one layer to form a feature vector. Using linear SVM, we can almost perfectly classify whether the mini-batch feature vector is from Caltech-256 or Bing dataset. Fig. 2 visualizes the distributions of mini-batch feature vectors from two datasets in 2D. It is clear that BN statistics from different domains are separated into clusters.\nThis pilot experiment suggests:\n1. Both shallow layers and deep layers of the DNN are influenced by domain shift. Domain adaptation by manipulating the output layer alone is not enough.\n2. The statistics of BN layer contain the traits of the data domain.\nBoth observations motivate us to adapt the representation across different domains by BN layer."
    }, {
      "heading" : "3.2 ADAPTIVE BATCH NORMALIZATION",
      "text" : "Given the pre-trained DNN model and a target domain, our Adaptive Batch Normalization algorithm is as follows1:\nAlgorithm 1 Adaptive Batch Normalization (AdaBN) for neuron j in DNN do\nConcatenate neuron responses on all images of target domain t: xj = [. . . , xj(m), . . .] Compute the mean and variance of the target domain: µtj = E(xtj), σtj = √ Var(xtj). end for for neuron j in DNN, testing imagem in target domain do\nCompute BN output yj(m) := γj\n( xj(m)−µtj ) σtj + βj\nend for\nThe intuition behind our method is straightforward: The standardization of each layer by domain ensures that each layer receives data from a similar distribution, no matter it comes from the source\n1In practice we adopt an online algorithm (Donald, 1999) to efficiently estimate the mean and variance.\ndomain or the target domain. Although modulating statistics in one BN layer by AdaBN is a simple translation and scaling operation, such linear transformation in one layer can achieve a highly nonlinear transformation through the whole deep CNN architecture. Thus, we believe this AdaBN process could approximate the intrinsically non-linear domain transfer function.\nFor K domain adaptation where K > 2, we standardize each sample by the statistics in its own domain. During training, the statistics are calculated for every mini-batch, the only thing that we need to make sure is that the samples in every mini-batch are from the same domain. For (semi)supervised domain adaptation, we may use the labeled data to fine-tune the weights as well. As a result, our method could fit in all different settings of domain adaptation with minimal effort.\nCompared with CORAL (Sun et al., 2016), one natural question is why we transform the neuron responses independently, not decorrelate and then re-correlate the responses together as suggested in Sun et al. (2016). Under certain conditions, decorrelation could improve the performance. However, in CNN, the mini-batch size is usually smaller than the feature dimension, leading to singular covariance matrices that is hard to be inversed. As a result, the covariance matrix is always singular. In addition, decorrelation requires to compute the inverse of the covariance matrix which is computationally intensive, especially if we plan to apply AdaBN to all layers of the network."
    }, {
      "heading" : "4 EXPERIMENTS",
      "text" : "In this section, we demonstrate the effectiveness of AdaBN on standard domain adaptation datasets, and empirically analyze our AdaBN model. We also evaluation our method on a practical application with remote sensing images."
    }, {
      "heading" : "4.1 EXPERIMENTAL SETTINGS",
      "text" : "We first introduce our experiments on two standard datasets: Office (Saenko et al., 2010) and Caltech-Bing (Bergamo & Torresani, 2010).\nOffice (Saenko et al., 2010) is a standard benchmark for domain adaptation, which is a collection of 4652 images in 31 classes from three different domains: Amazon(A), DSRL(D) and Webcam(W). Similar to (Tzeng et al., 2014; Sun et al., 2016; Long et al., 2015), we evaluate the pairwise domain adaption performance of AdaBN on all six pairs of domains. For the multi-source setting, we evaluate our method on three transfer tasks {A, W} → D, {A, D} →W, {D, W} → A. Caltech-Bing (Bergamo & Torresani, 2010) is a much larger domain adaptation dataset, which contains 30,607 and 121,730 images in 256 categories from two domains Caltech-256(C) and Bing(B). The images in the Bing set are collected from Bing image search engine by keyword search. Apparently Bing data contains noise, and its data distribution is dramatically different from that of Caltech-256.\nWe compare our approach with a variety of methods, including four shallow methods: SA (Fernando et al., 2013), LSSA (Aljundi et al., 2015), GFK (Gong et al., 2012), CORAL (Sun et al., 2016), and four deep methods: DDC (Tzeng et al., 2014), DAN (Long et al., 2015), RevGrad (Ganin & Lempitsky, 2015), Deep CORAL (Sun & Saenko, 2016). Specifically, GFK models domain shift by integrating an infinite number of subspaces that characterize changes in statistical properties from the source to the target domain. SA, LSSA and CORAL align the source and target subspaces by explicit feature space transformations that would map source distribution into the target one. DDC and DAN are deep learning based methods which maximize domain invariance by adding to AlexNet one or several adaptation layers using MMD. RevGrad incorporates a gradient reversal layer in the deep model to encourage learning domain-invariant features. Deep CORAL extends CORAL to perform end-to-end adaptation in DNN. It should be noted that these deep learning methods have the adaptation layers on top of the output layers of DNNs, which is a sharp contrast to our method that delves into early convolution layers as well with the help of BN layers.\nWe follow the full protocol (Donahue et al., 2014) for the single source setting; while for multiple sources setting, we use all the samples in the source domains as training data, and use all the samples in the target domain as testing data. We fine-tune the Inception-BN (Ioffe & Szegedy, 2015) model on source domain in each task for 100 epochs. The learning rate is set to 0.01 initially, and then is dropped by a factor 0.1 every 40 epochs. Since the office dataset is quite small, following the\nbest practice in Long et al. (2015), we freeze the first three groups of Inception modules, and set the learning rate of fourth and fifth group one tenth of the base learning rate to avoid overfitting. For Caltech-Bing dataset, we fine-tune the whole model with the same base learning rate."
    }, {
      "heading" : "4.2 RESULTS",
      "text" : ""
    }, {
      "heading" : "4.2.1 OFFICE DATASET",
      "text" : "Our results on Office dataset is reported in Table 1 and Table 2 for single/multi source(s), respectively. Note that the first 5 models of the Table 1 are pre-trained on AlexNet (Krizhevsky et al., 2012) instead of the Inception-BN (Ioffe & Szegedy, 2015) model, due to the lack of publicly available pre-trained Inception BN model in Caffe (Jia et al., 2014). Thus, the relative improvements over the baseline (AlexNet/Inception BN) make more sense than the absolute numbers of each algorithm.\nFrom Table 1, we first notice that the Inception-BN indeed improves over the AlexNet on average, which means that the CNN pre-trained on ImageNet has learned general features, the improvements on ImageNet can be transferred to new tasks. Among the methods based on Inception-BN features, our method improves the most over the baseline. Moreover, since our method is complementary to other methods, we can simply apply CORAL on the top of AdaBN. Not surprisingly, this simple combination exhibits 0.5% increase in performance. This preliminary test reveals further potential of AdaBN if combined with other advanced domain adaptation methods. Finally, we could improve 1.7% over the baseline, and advance the state-of-the-art results for this dataset.\nNone of the compared methods has reported their performance on multi-source domain adaptation. To demonstrate the capacity of AdaBN under multi-domain settings, we compare it against CORAL, which is the best performing algorithm in the single source setting. The result is reported in Table 2. We find that simply combining two domains does not lead to better performance. The result is generally worse compared to the best performing single domain between the two. This phenomenon suggests that if we cannot properly cope with domain bias, the increase of training samples may be reversely affect to the testing performance. This result confirms the necessity of domain adaptation. In this more challenging setting, AdaBN still outperforms the baseline and CORAL on average. Again, when combined with CORAL, our method demonstrates further improvements. At last, our method archives 2.3% gain over the baseline."
    }, {
      "heading" : "4.2.2 CALTECH-BING DATASET",
      "text" : "To further evaluate our method on the large-scale dataset, we show our results on Caltech-Bing Dataset in Table 3. Compared with CORAL, AdaBN achieves better performance, which improves 1.8% over the baseline. Note that all the domain adaptation methods show minor improvements over the baseline in the task C→ B. One of the hypotheses to this relatively small improvement is that the images in Bing dataset are collected from Internet, which are more diverse and noisier (Bergamo & Torresani, 2010). Thus, it is not easy to adapt on the Bing dataset from the relatively clean dataset Caltech-256. Combining CORAL with our method does not offer further improvements. This might be explained by the noise of the Bing dataset and the imbalance of the number of images in the two domains."
    }, {
      "heading" : "4.3 EMPIRICAL ANALYSIS",
      "text" : "In this section, we investigate the influence of the number of samples in target domain to the performance and empirically analyze the adaptation effect of different BN layers."
    }, {
      "heading" : "4.3.1 SENSITIVITY TO TARGET DOMAIN SIZE.",
      "text" : "Since the key of our method is to calculate the mean and variance of the target domain on different BN layers, it is very natural to ask how many target images is necessary to obtain stable statistics. In this experiment, we randomly select a subset of images in target domain to calculate the statistics and then evaluate the performance on the whole target set. Fig. 3 illustrates the effect of using different number of batches. The results demonstrate that our method can obtain good results when using only a small part of the target examples. It should also be noted that in the extremal case of one batch of target images, our method still achieves better results than the baseline. This is valuable in practical use since a large number of target images are often not available."
    }, {
      "heading" : "4.3.2 ADAPTATION EFFECT FOR DIFFERENT BN LAYERS.",
      "text" : "In this experiment, we analyze the effect of adapting on different BN layers with our AdaBN method. According to the structure of Inception-BN network Ioffe & Szegedy (2015), we categorize the BN layers into 9 blocks: 1, 2, 3a, 3b, 4a, 4b, 4c, 5a, 5b. Since the back BN layers are influenced by the outputs of previous BN layers, when adapting a specific block we adapted all the blocks before it. Fig. 4 illustrates the adaptation effect for different BN layers. It shows that adapting BN layers consistently improves the results over the baseline method in most cases. Specifically, when incorporating more BN layers in the adaptation, we could achiever better transfer results."
    }, {
      "heading" : "4.4 PRACTICAL APPLICATION FOR CLOUD DETECTION IN REMOTE SENSING IMAGES",
      "text" : "In this section, we further demonstrate the effectiveness of AdaBN on a practical problem: Cloud Detection in Remote Sensing Images. Since remote sensing images are taken by different satellites with different sensors and resolutions, the captured images are visually different in texture, color, and value range distributions, as shown in Fig. 5. How to adapt a model trained on one satellite to another satellite images is naturally a domain adaptation problem.\nOur task here is to identify cloud from the remote sensing images, which can be regarded as a semantic segmentation task. The experiment is taken under a self-collected dataset, which includes three image sets, from GF2, GF1 and Tianhui satellites. Each image set contains 635, 324 and 113 images with resolution over 6000x6000 pixels respectively. We name the three different datasets following the satellite names. GF2 dataset is used as the training dataset while GF1 and Tianhui datasets are for testing. We use a state-of-art semantic segmentation method (Chen et al., 2016a) as our baseline model.\nThe results on GF1 and Tianhui datasets are shown in Table 4. The relatively low results of the baseline method indicate that there exists large distribution disparity among images from different satellites. Thus, the significant improvement after applying AdaBN reveals the effectiveness of our method. Some of the visual results are shown in Fig. 6. Since other domain adaptation methods require either additional optimization steps and extra components (e.g. MMD) or post-processing distribution alignment (like CORAL), it is very hard to apply these methods from image classification to this large-size (6000x6000) segmentation problem. Comparatively, besides the effective performance, our method needs no extra parameters and very few computations over the whole adaptation process."
    }, {
      "heading" : "5 CONCLUSION AND FUTURE WORKS",
      "text" : "In this paper, we have introduced a simple yet effective approach for domain adaptation on batch normalized neural networks. Besides its original uses, we have exploited another functionality of Batch Normalization (BN) layer: domain adaptation. The main idea is to replace the statistics of each BN layer in source domain with those in target domain. The proposed method is easy to implement and parameter-free, and it takes almost no effort to extend to multiple source domains and semi-supervised settings. Our method established new state-of-the-art results on both single and multiple source(s) domain adaptation settings on standard benchmarks. At last, the experiments on cloud detection for large-size remote sensing images further demonstrate the effectiveness of our method in practical use. We believe our method opens up a new direction for domain adaptation.\nIn contrary to other methods that use Maximum Mean Discrepancy (MMD) or domain confusion loss to update the weights in CNN for domain adaptation, our method only modifies the statistics of BN layer. Therefore, our method is fully complementary to other existing deep learning based methods. It is interesting to see how these different methods can be unified under one framework."
    } ],
    "references" : [ {
      "title" : "Landmarks-based kernelized subspace alignment for unsupervised domain adaptation",
      "author" : [ "Rahaf Aljundi", "Rémi Emonet", "Damien Muselet", "Marc Sebban" ],
      "venue" : "In CVPR,",
      "citeRegEx" : "Aljundi et al\\.,? \\Q2015\\E",
      "shortCiteRegEx" : "Aljundi et al\\.",
      "year" : 2015
    }, {
      "title" : "Unsupervised domain adaptation by domain invariant projection",
      "author" : [ "Mahsa Baktashmotlagh", "Mehrtash Harandi", "Brian Lovell", "Mathieu Salzmann" ],
      "venue" : "In ICCV, pp",
      "citeRegEx" : "Baktashmotlagh et al\\.,? \\Q2013\\E",
      "shortCiteRegEx" : "Baktashmotlagh et al\\.",
      "year" : 2013
    }, {
      "title" : "Domain adaptations for computer vision applications",
      "author" : [ "Oscar Beijbom" ],
      "venue" : "arXiv preprint arXiv:1211.4860,",
      "citeRegEx" : "Beijbom.,? \\Q2012\\E",
      "shortCiteRegEx" : "Beijbom.",
      "year" : 2012
    }, {
      "title" : "Exploiting weakly-labeled web images to improve object classification: a domain adaptation approach",
      "author" : [ "Alessandro Bergamo", "Lorenzo Torresani" ],
      "venue" : "In NIPS,",
      "citeRegEx" : "Bergamo and Torresani.,? \\Q2010\\E",
      "shortCiteRegEx" : "Bergamo and Torresani.",
      "year" : 2010
    }, {
      "title" : "Domain separation networks",
      "author" : [ "Konstantinos Bousmalis", "George Trigeorgis", "Nathan Silberman", "Dilip Krishnan", "Dumitru Erhan" ],
      "venue" : null,
      "citeRegEx" : "Bousmalis et al\\.,? \\Q2016\\E",
      "shortCiteRegEx" : "Bousmalis et al\\.",
      "year" : 2016
    }, {
      "title" : "Deeplab: Semantic image segmentation with deep convolutional nets, atrous convolution, and fully connected crfs",
      "author" : [ "Liang-Chieh Chen", "George Papandreou", "Iasonas Kokkinos", "Kevin Murphy", "Alan L Yuille" ],
      "venue" : "arXiv preprint arXiv:1606.00915,",
      "citeRegEx" : "Chen et al\\.,? \\Q2016\\E",
      "shortCiteRegEx" : "Chen et al\\.",
      "year" : 2016
    }, {
      "title" : "MXNet: A flexible and efficient machine learning library for heterogeneous distributed systems",
      "author" : [ "Tianqi Chen", "Mu Li", "Yutian Li", "Min Lin", "Naiyan Wang", "Minjie Wang", "Tianjun Xiao", "Bing Xu", "Chiyuan Zhang", "Zheng Zhang" ],
      "venue" : "NIPS Workshop on Machine Learning Systems,",
      "citeRegEx" : "Chen et al\\.,? \\Q2016\\E",
      "shortCiteRegEx" : "Chen et al\\.",
      "year" : 2016
    }, {
      "title" : "DLID: Deep learning for domain adaptation by interpolating between domains",
      "author" : [ "Sumit Chopra", "Suhrid Balakrishnan", "Raghuraman Gopalan" ],
      "venue" : "In ICML Workshop on Challenges in Representation Learning,",
      "citeRegEx" : "Chopra et al\\.,? \\Q2013\\E",
      "shortCiteRegEx" : "Chopra et al\\.",
      "year" : 2013
    }, {
      "title" : "DeCAF: A deep convolutional activation feature for generic visual recognition",
      "author" : [ "Jeff Donahue", "Yangqing Jia", "Oriol Vinyals", "Judy Hoffman", "Ning Zhang", "Eric Tzeng", "Trevor Darrell" ],
      "venue" : "In ICML, pp",
      "citeRegEx" : "Donahue et al\\.,? \\Q2014\\E",
      "shortCiteRegEx" : "Donahue et al\\.",
      "year" : 2014
    }, {
      "title" : "The art of computer programming",
      "author" : [ "E Knuth Donald" ],
      "venue" : "Sorting and searching,",
      "citeRegEx" : "Donald.,? \\Q1999\\E",
      "shortCiteRegEx" : "Donald.",
      "year" : 1999
    }, {
      "title" : "Unsupervised visual domain adaptation using subspace alignment",
      "author" : [ "Basura Fernando", "Amaury Habrard", "Marc Sebban", "Tinne Tuytelaars" ],
      "venue" : "In ICCV, pp",
      "citeRegEx" : "Fernando et al\\.,? \\Q2013\\E",
      "shortCiteRegEx" : "Fernando et al\\.",
      "year" : 2013
    }, {
      "title" : "Unsupervised domain adaptation by backpropagation",
      "author" : [ "Yaroslav Ganin", "Victor Lempitsky" ],
      "venue" : "In ICML, pp. 1180–1189,",
      "citeRegEx" : "Ganin and Lempitsky.,? \\Q2015\\E",
      "shortCiteRegEx" : "Ganin and Lempitsky.",
      "year" : 2015
    }, {
      "title" : "Domain adaptive neural networks for object recognition",
      "author" : [ "Muhammad Ghifary", "W Bastiaan Kleijn", "Mengjie Zhang" ],
      "venue" : "In PRICAI: Trends in Artificial Intelligence,",
      "citeRegEx" : "Ghifary et al\\.,? \\Q2014\\E",
      "shortCiteRegEx" : "Ghifary et al\\.",
      "year" : 2014
    }, {
      "title" : "Geodesic flow kernel for unsupervised domain adaptation",
      "author" : [ "Boqing Gong", "Yuan Shi", "Fei Sha", "Kristen Grauman" ],
      "venue" : "In CVPR, pp. 2066–2073,",
      "citeRegEx" : "Gong et al\\.,? \\Q2012\\E",
      "shortCiteRegEx" : "Gong et al\\.",
      "year" : 2012
    }, {
      "title" : "Connecting the dots with landmarks: Discriminatively learning domain-invariant features for unsupervised domain adaptation",
      "author" : [ "Boqing Gong", "Kristen Grauman", "Fei Sha" ],
      "venue" : "In ICML, pp",
      "citeRegEx" : "Gong et al\\.,? \\Q2013\\E",
      "shortCiteRegEx" : "Gong et al\\.",
      "year" : 2013
    }, {
      "title" : "Domain adaptation for object recognition: An unsupervised approach",
      "author" : [ "Raghuraman Gopalan", "Ruonan Li", "Rama Chellappa" ],
      "venue" : "In ICCV, pp",
      "citeRegEx" : "Gopalan et al\\.,? \\Q2011\\E",
      "shortCiteRegEx" : "Gopalan et al\\.",
      "year" : 2011
    }, {
      "title" : "A kernel two-sample test",
      "author" : [ "Arthur Gretton", "Karsten M Borgwardt", "Malte J Rasch", "Bernhard Schölkopf", "Alexander Smola" ],
      "venue" : "The Journal of Machine Learning Research,",
      "citeRegEx" : "Gretton et al\\.,? \\Q2012\\E",
      "shortCiteRegEx" : "Gretton et al\\.",
      "year" : 2012
    }, {
      "title" : "Caltech-256 object category dataset",
      "author" : [ "Gregory Griffin", "Alex Holub", "Pietro Perona" ],
      "venue" : null,
      "citeRegEx" : "Griffin et al\\.,? \\Q2007\\E",
      "shortCiteRegEx" : "Griffin et al\\.",
      "year" : 2007
    }, {
      "title" : "Deep residual learning for image recognition",
      "author" : [ "Kaiming He", "Xiangyu Zhang", "Shaoqing Ren", "Jian Sun" ],
      "venue" : null,
      "citeRegEx" : "He et al\\.,? \\Q2016\\E",
      "shortCiteRegEx" : "He et al\\.",
      "year" : 2016
    }, {
      "title" : "Correcting sample selection bias by unlabeled data",
      "author" : [ "Jiayuan Huang", "Arthur Gretton", "Karsten M Borgwardt", "Bernhard Schölkopf", "Alex J Smola" ],
      "venue" : "In NIPS, pp",
      "citeRegEx" : "Huang et al\\.,? \\Q2006\\E",
      "shortCiteRegEx" : "Huang et al\\.",
      "year" : 2006
    }, {
      "title" : "Batch normalization: Accelerating deep network training by reducing internal covariate shift",
      "author" : [ "Sergey Ioffe", "Christian Szegedy" ],
      "venue" : "In ICML, pp",
      "citeRegEx" : "Ioffe and Szegedy.,? \\Q2015\\E",
      "shortCiteRegEx" : "Ioffe and Szegedy.",
      "year" : 2015
    }, {
      "title" : "Caffe: Convolutional architecture for fast feature embedding",
      "author" : [ "Yangqing Jia", "Evan Shelhamer", "Jeff Donahue", "Sergey Karayev", "Jonathan Long", "Ross Girshick", "Sergio Guadarrama", "Trevor Darrell" ],
      "venue" : "In ACM MM,",
      "citeRegEx" : "Jia et al\\.,? \\Q2014\\E",
      "shortCiteRegEx" : "Jia et al\\.",
      "year" : 2014
    }, {
      "title" : "Undoing the damage of dataset bias",
      "author" : [ "Aditya Khosla", "Tinghui Zhou", "Tomasz Malisiewicz", "Alexei A Efros", "Antonio Torralba" ],
      "venue" : "In ECCV, pp",
      "citeRegEx" : "Khosla et al\\.,? \\Q2012\\E",
      "shortCiteRegEx" : "Khosla et al\\.",
      "year" : 2012
    }, {
      "title" : "Imagenet classification with deep convolutional neural networks",
      "author" : [ "Alex Krizhevsky", "Ilya Sutskever", "Geoffrey E Hinton" ],
      "venue" : "In NIPS, pp",
      "citeRegEx" : "Krizhevsky et al\\.,? \\Q2012\\E",
      "shortCiteRegEx" : "Krizhevsky et al\\.",
      "year" : 2012
    }, {
      "title" : "Learning transferable features with deep adaptation networks",
      "author" : [ "Mingsheng Long", "Yue Cao", "Jianmin Wang", "Michael Jordan" ],
      "venue" : "In ICML, pp",
      "citeRegEx" : "Long et al\\.,? \\Q2015\\E",
      "shortCiteRegEx" : "Long et al\\.",
      "year" : 2015
    }, {
      "title" : "Unsupervised domain adaptation with residual transfer networks",
      "author" : [ "Mingsheng Long", "Jianmin Wang", "Michael I Jordan" ],
      "venue" : "In NIPS,",
      "citeRegEx" : "Long et al\\.,? \\Q2016\\E",
      "shortCiteRegEx" : "Long et al\\.",
      "year" : 2016
    }, {
      "title" : "Domain adaptation via transfer component analysis",
      "author" : [ "Sinno Jialin Pan", "Ivor W Tsang", "James T Kwok", "Qiang Yang" ],
      "venue" : "IEEE Transactions on Neural Networks,",
      "citeRegEx" : "Pan et al\\.,? \\Q2011\\E",
      "shortCiteRegEx" : "Pan et al\\.",
      "year" : 2011
    }, {
      "title" : "Visual domain adaptation: A survey of recent advances",
      "author" : [ "Vishal M Patel", "Raghuraman Gopalan", "Ruonan Li", "Rama Chellappa" ],
      "venue" : "IEEE Signal Processing Magazine,",
      "citeRegEx" : "Patel et al\\.,? \\Q2015\\E",
      "shortCiteRegEx" : "Patel et al\\.",
      "year" : 2015
    }, {
      "title" : "ImageNet large scale visual recognition challenge",
      "author" : [ "Olga Russakovsky", "Jia Deng", "Hao Su", "Jonathan Krause", "Sanjeev Satheesh", "Sean Ma", "Zhiheng Huang", "Andrej Karpathy", "Aditya Khosla", "Michael Bernstein" ],
      "venue" : "International Journal of Computer Vision,",
      "citeRegEx" : "Russakovsky et al\\.,? \\Q2015\\E",
      "shortCiteRegEx" : "Russakovsky et al\\.",
      "year" : 2015
    }, {
      "title" : "Adapting visual category models to new domains",
      "author" : [ "Kate Saenko", "Brian Kulis", "Mario Fritz", "Trevor Darrell" ],
      "venue" : "In ECCV, pp",
      "citeRegEx" : "Saenko et al\\.,? \\Q2010\\E",
      "shortCiteRegEx" : "Saenko et al\\.",
      "year" : 2010
    }, {
      "title" : "Improving predictive inference under covariate shift by weighting the loglikelihood function",
      "author" : [ "Hidetoshi Shimodaira" ],
      "venue" : "Journal of statistical planning and inference,",
      "citeRegEx" : "Shimodaira.,? \\Q2000\\E",
      "shortCiteRegEx" : "Shimodaira.",
      "year" : 2000
    }, {
      "title" : "Deep coral: Correlation alignment for deep domain adaptation",
      "author" : [ "Baochen Sun", "Kate Saenko" ],
      "venue" : "arXiv preprint arXiv:1607.01719,",
      "citeRegEx" : "Sun and Saenko.,? \\Q2016\\E",
      "shortCiteRegEx" : "Sun and Saenko.",
      "year" : 2016
    }, {
      "title" : "Return of frustratingly easy domain adaptation",
      "author" : [ "Baochen Sun", "Jiashi Feng", "Kate Saenko" ],
      "venue" : null,
      "citeRegEx" : "Sun et al\\.,? \\Q2016\\E",
      "shortCiteRegEx" : "Sun et al\\.",
      "year" : 2016
    }, {
      "title" : "Rethinking the inception architecture for computer vision",
      "author" : [ "Christian Szegedy", "Vincent Vanhoucke", "Sergey Ioffe", "Jonathon Shlens", "Zbigniew Wojna" ],
      "venue" : "arXiv preprint arXiv:1512.00567,",
      "citeRegEx" : "Szegedy et al\\.,? \\Q2015\\E",
      "shortCiteRegEx" : "Szegedy et al\\.",
      "year" : 2015
    }, {
      "title" : "A deeper look at dataset bias",
      "author" : [ "Tatiana Tommasi", "Novi Patricia", "Barbara Caputo", "Tinne Tuytelaars" ],
      "venue" : "German Conference on Pattern Recognition,",
      "citeRegEx" : "Tommasi et al\\.,? \\Q2015\\E",
      "shortCiteRegEx" : "Tommasi et al\\.",
      "year" : 2015
    }, {
      "title" : "Unbiased look at dataset bias",
      "author" : [ "Antonio Torralba", "Alexei A Efros" ],
      "venue" : "In CVPR, pp",
      "citeRegEx" : "Torralba and Efros.,? \\Q2011\\E",
      "shortCiteRegEx" : "Torralba and Efros.",
      "year" : 2011
    }, {
      "title" : "Deep domain confusion: Maximizing for domain invariance",
      "author" : [ "Eric Tzeng", "Judy Hoffman", "Ning Zhang", "Kate Saenko", "Trevor Darrell" ],
      "venue" : "arXiv preprint arXiv:1412.3474,",
      "citeRegEx" : "Tzeng et al\\.,? \\Q2014\\E",
      "shortCiteRegEx" : "Tzeng et al\\.",
      "year" : 2014
    }, {
      "title" : "Simultaneous deep transfer across domains and tasks",
      "author" : [ "Eric Tzeng", "Judy Hoffman", "Trevor Darrell", "Kate Saenko" ],
      "venue" : "In ICCV, pp",
      "citeRegEx" : "Tzeng et al\\.,? \\Q2015\\E",
      "shortCiteRegEx" : "Tzeng et al\\.",
      "year" : 2015
    }, {
      "title" : "Visualizing data using t-sne",
      "author" : [ "Laurens Van der Maaten", "Geoffrey Hinton" ],
      "venue" : "Journal of Machine Learning Research,",
      "citeRegEx" : "Maaten and Hinton.,? \\Q2008\\E",
      "shortCiteRegEx" : "Maaten and Hinton.",
      "year" : 2008
    }, {
      "title" : "How transferable are features in deep neural networks",
      "author" : [ "Jason Yosinski", "Jeff Clune", "Yoshua Bengio", "Hod Lipson" ],
      "venue" : "In NIPS,",
      "citeRegEx" : "Yosinski et al\\.,? \\Q2014\\E",
      "shortCiteRegEx" : "Yosinski et al\\.",
      "year" : 2014
    } ],
    "referenceMentions" : [ {
      "referenceID" : 34,
      "context" : "Recent study (Tommasi et al., 2015) shows that a DNN has strong dependency towards the training dataset, and the learned features cannot be easily transferred to a different but relevant task without fine-tuning.",
      "startOffset" : 13,
      "endOffset" : 35
    }, {
      "referenceID" : 36,
      "context" : "Known as domain adaptation, the effort to bridge the gap between training and testing data distributions has been discussed several times under the context of deep learning (Tzeng et al., 2014; Long et al., 2015; Tzeng et al., 2015; Ganin & Lempitsky, 2015).",
      "startOffset" : 173,
      "endOffset" : 257
    }, {
      "referenceID" : 24,
      "context" : "Known as domain adaptation, the effort to bridge the gap between training and testing data distributions has been discussed several times under the context of deep learning (Tzeng et al., 2014; Long et al., 2015; Tzeng et al., 2015; Ganin & Lempitsky, 2015).",
      "startOffset" : 173,
      "endOffset" : 257
    }, {
      "referenceID" : 37,
      "context" : "Known as domain adaptation, the effort to bridge the gap between training and testing data distributions has been discussed several times under the context of deep learning (Tzeng et al., 2014; Long et al., 2015; Tzeng et al., 2015; Ganin & Lempitsky, 2015).",
      "startOffset" : 173,
      "endOffset" : 257
    }, {
      "referenceID" : 2,
      "context" : "Domain transfer in visual recognition tasks has gained increasing attention in recent literature (Beijbom, 2012; Patel et al., 2015).",
      "startOffset" : 97,
      "endOffset" : 132
    }, {
      "referenceID" : 27,
      "context" : "Domain transfer in visual recognition tasks has gained increasing attention in recent literature (Beijbom, 2012; Patel et al., 2015).",
      "startOffset" : 97,
      "endOffset" : 132
    }, {
      "referenceID" : 30,
      "context" : "Often referred to as covariate shift (Shimodaira, 2000) or dataset bias (Torralba & Efros, 2011), this problem poses a great challenge to the generalization ability of a learned model.",
      "startOffset" : 37,
      "endOffset" : 55
    }, {
      "referenceID" : 16,
      "context" : "A more explicit way to compute dataset difference is based on Maximum Mean Discrepancy (MMD) (Gretton et al., 2012).",
      "startOffset" : 93,
      "endOffset" : 115
    }, {
      "referenceID" : 19,
      "context" : "To reduce dataset discrepancies, many methods are proposed, including sample selections (Huang et al., 2006; Gong et al., 2013), explicit projection learning (Pan et al.",
      "startOffset" : 88,
      "endOffset" : 127
    }, {
      "referenceID" : 14,
      "context" : "To reduce dataset discrepancies, many methods are proposed, including sample selections (Huang et al., 2006; Gong et al., 2013), explicit projection learning (Pan et al.",
      "startOffset" : 88,
      "endOffset" : 127
    }, {
      "referenceID" : 26,
      "context" : ", 2013), explicit projection learning (Pan et al., 2011; Gopalan et al., 2011; Baktashmotlagh et al., 2013) and principal axes alignment (Fernando et al.",
      "startOffset" : 38,
      "endOffset" : 107
    }, {
      "referenceID" : 15,
      "context" : ", 2013), explicit projection learning (Pan et al., 2011; Gopalan et al., 2011; Baktashmotlagh et al., 2013) and principal axes alignment (Fernando et al.",
      "startOffset" : 38,
      "endOffset" : 107
    }, {
      "referenceID" : 1,
      "context" : ", 2013), explicit projection learning (Pan et al., 2011; Gopalan et al., 2011; Baktashmotlagh et al., 2013) and principal axes alignment (Fernando et al.",
      "startOffset" : 38,
      "endOffset" : 107
    }, {
      "referenceID" : 10,
      "context" : ", 2013) and principal axes alignment (Fernando et al., 2013; Gong et al., 2012; Aljundi et al., 2015).",
      "startOffset" : 37,
      "endOffset" : 101
    }, {
      "referenceID" : 13,
      "context" : ", 2013) and principal axes alignment (Fernando et al., 2013; Gong et al., 2012; Aljundi et al., 2015).",
      "startOffset" : 37,
      "endOffset" : 101
    }, {
      "referenceID" : 0,
      "context" : ", 2013) and principal axes alignment (Fernando et al., 2013; Gong et al., 2012; Aljundi et al., 2015).",
      "startOffset" : 37,
      "endOffset" : 101
    }, {
      "referenceID" : 39,
      "context" : "In the field of deep learning, feature transferability across different domains is a tantalizing yet generally unsolved topic (Yosinski et al., 2014; Tommasi et al., 2015).",
      "startOffset" : 126,
      "endOffset" : 171
    }, {
      "referenceID" : 34,
      "context" : "In the field of deep learning, feature transferability across different domains is a tantalizing yet generally unsolved topic (Yosinski et al., 2014; Tommasi et al., 2015).",
      "startOffset" : 126,
      "endOffset" : 171
    }, {
      "referenceID" : 8,
      "context" : "To transfer the learned representations to a new dataset, pre-training plus fine-tuning (Donahue et al., 2014) have become de facto procedures.",
      "startOffset" : 88,
      "endOffset" : 110
    }, {
      "referenceID" : 0,
      "context" : "Domain transfer in visual recognition tasks has gained increasing attention in recent literature (Beijbom, 2012; Patel et al., 2015). Often referred to as covariate shift (Shimodaira, 2000) or dataset bias (Torralba & Efros, 2011), this problem poses a great challenge to the generalization ability of a learned model. One key component of domain transfer is to model the difference between source and target distributions. In Khosla et al. (2012), the authors assign each dataset with an explicit bias vector, and train one discriminative model to handle multiple classification problems with different bias terms.",
      "startOffset" : 98,
      "endOffset" : 448
    }, {
      "referenceID" : 7,
      "context" : "Early works of domain adaptation either focus on reordering fine-tuning samples (Chopra et al., 2013), or regularizing MMD (Gretton et al.",
      "startOffset" : 80,
      "endOffset" : 101
    }, {
      "referenceID" : 16,
      "context" : ", 2013), or regularizing MMD (Gretton et al., 2012) in a shallow network (Ghifary et al.",
      "startOffset" : 29,
      "endOffset" : 51
    }, {
      "referenceID" : 12,
      "context" : ", 2012) in a shallow network (Ghifary et al., 2014).",
      "startOffset" : 29,
      "endOffset" : 51
    }, {
      "referenceID" : 36,
      "context" : "DDC (Tzeng et al., 2014) used the classical MMD loss to regularize the representation in the last layer of CNN.",
      "startOffset" : 4,
      "endOffset" : 24
    }, {
      "referenceID" : 24,
      "context" : "DAN (Long et al., 2015) further extended the method to multiple kernel MMD and multiple layer adaptation.",
      "startOffset" : 4,
      "endOffset" : 23
    }, {
      "referenceID" : 25,
      "context" : "Besides adapting features using MMD, RTN (Long et al., 2016) also added a gated residual layer for classifier adaptation.",
      "startOffset" : 41,
      "endOffset" : 60
    }, {
      "referenceID" : 32,
      "context" : "Another related work is CORAL (Sun et al., 2016).",
      "startOffset" : 30,
      "endOffset" : 48
    }, {
      "referenceID" : 4,
      "context" : "Recently, by explicitly modeling both private and shared components of the domain representations in the network, Bousmalis et al. (2016) proposed a Domain Separation Network to extract better domain-invariant features.",
      "startOffset" : 114,
      "endOffset" : 138
    }, {
      "referenceID" : 18,
      "context" : "BN layer has become a standard component in recent top-performing CNN architectures, such as deep residual network (He et al., 2016), and Inception V3 (Szegedy et al.",
      "startOffset" : 115,
      "endOffset" : 132
    }, {
      "referenceID" : 33,
      "context" : ", 2016), and Inception V3 (Szegedy et al., 2015).",
      "startOffset" : 26,
      "endOffset" : 48
    }, {
      "referenceID" : 28,
      "context" : ", 2016b) of the Inception-BN model (Ioffe & Szegedy, 2015) pre-trained on ImageNet classification task (Russakovsky et al., 2015) as our baseline DNN model.",
      "startOffset" : 103,
      "endOffset" : 129
    }, {
      "referenceID" : 17,
      "context" : "Our image data are drawn from (Bergamo & Torresani, 2010), which contains the same classes of images from both Caltech-256 dataset (Griffin et al., 2007) and Bing image search results.",
      "startOffset" : 131,
      "endOffset" : 153
    }, {
      "referenceID" : 9,
      "context" : "The intuition behind our method is straightforward: The standardization of each layer by domain ensures that each layer receives data from a similar distribution, no matter it comes from the source In practice we adopt an online algorithm (Donald, 1999) to efficiently estimate the mean and variance.",
      "startOffset" : 239,
      "endOffset" : 253
    }, {
      "referenceID" : 32,
      "context" : "Compared with CORAL (Sun et al., 2016), one natural question is why we transform the neuron responses independently, not decorrelate and then re-correlate the responses together as suggested in Sun et al.",
      "startOffset" : 20,
      "endOffset" : 38
    }, {
      "referenceID" : 32,
      "context" : "Compared with CORAL (Sun et al., 2016), one natural question is why we transform the neuron responses independently, not decorrelate and then re-correlate the responses together as suggested in Sun et al. (2016). Under certain conditions, decorrelation could improve the performance.",
      "startOffset" : 21,
      "endOffset" : 212
    }, {
      "referenceID" : 29,
      "context" : "We first introduce our experiments on two standard datasets: Office (Saenko et al., 2010) and Caltech-Bing (Bergamo & Torresani, 2010).",
      "startOffset" : 68,
      "endOffset" : 89
    }, {
      "referenceID" : 29,
      "context" : "Office (Saenko et al., 2010) is a standard benchmark for domain adaptation, which is a collection of 4652 images in 31 classes from three different domains: Amazon(A), DSRL(D) and Webcam(W).",
      "startOffset" : 7,
      "endOffset" : 28
    }, {
      "referenceID" : 36,
      "context" : "Similar to (Tzeng et al., 2014; Sun et al., 2016; Long et al., 2015), we evaluate the pairwise domain adaption performance of AdaBN on all six pairs of domains.",
      "startOffset" : 11,
      "endOffset" : 68
    }, {
      "referenceID" : 32,
      "context" : "Similar to (Tzeng et al., 2014; Sun et al., 2016; Long et al., 2015), we evaluate the pairwise domain adaption performance of AdaBN on all six pairs of domains.",
      "startOffset" : 11,
      "endOffset" : 68
    }, {
      "referenceID" : 24,
      "context" : "Similar to (Tzeng et al., 2014; Sun et al., 2016; Long et al., 2015), we evaluate the pairwise domain adaption performance of AdaBN on all six pairs of domains.",
      "startOffset" : 11,
      "endOffset" : 68
    }, {
      "referenceID" : 10,
      "context" : "We compare our approach with a variety of methods, including four shallow methods: SA (Fernando et al., 2013), LSSA (Aljundi et al.",
      "startOffset" : 86,
      "endOffset" : 109
    }, {
      "referenceID" : 0,
      "context" : ", 2013), LSSA (Aljundi et al., 2015), GFK (Gong et al.",
      "startOffset" : 14,
      "endOffset" : 36
    }, {
      "referenceID" : 13,
      "context" : ", 2015), GFK (Gong et al., 2012), CORAL (Sun et al.",
      "startOffset" : 13,
      "endOffset" : 32
    }, {
      "referenceID" : 32,
      "context" : ", 2012), CORAL (Sun et al., 2016), and four deep methods: DDC (Tzeng et al.",
      "startOffset" : 15,
      "endOffset" : 33
    }, {
      "referenceID" : 36,
      "context" : ", 2016), and four deep methods: DDC (Tzeng et al., 2014), DAN (Long et al.",
      "startOffset" : 36,
      "endOffset" : 56
    }, {
      "referenceID" : 24,
      "context" : ", 2014), DAN (Long et al., 2015), RevGrad (Ganin & Lempitsky, 2015), Deep CORAL (Sun & Saenko, 2016).",
      "startOffset" : 13,
      "endOffset" : 32
    }, {
      "referenceID" : 8,
      "context" : "We follow the full protocol (Donahue et al., 2014) for the single source setting; while for multiple sources setting, we use all the samples in the source domains as training data, and use all the samples in the target domain as testing data.",
      "startOffset" : 28,
      "endOffset" : 50
    }, {
      "referenceID" : 23,
      "context" : "Method A → W D → W W → D A → D D → A W → A Avg AlexNet (Krizhevsky et al., 2012) 61.",
      "startOffset" : 55,
      "endOffset" : 80
    }, {
      "referenceID" : 36,
      "context" : "1 DDC (Tzeng et al., 2014) 61.",
      "startOffset" : 6,
      "endOffset" : 26
    }, {
      "referenceID" : 24,
      "context" : "6 DAN (Long et al., 2015) 68.",
      "startOffset" : 6,
      "endOffset" : 25
    }, {
      "referenceID" : 10,
      "context" : "5 SA (Fernando et al., 2013) 69.",
      "startOffset" : 5,
      "endOffset" : 28
    }, {
      "referenceID" : 13,
      "context" : "3 GFK (Gong et al., 2012) 66.",
      "startOffset" : 6,
      "endOffset" : 25
    }, {
      "referenceID" : 0,
      "context" : "7 LSSA (Aljundi et al., 2015) 67.",
      "startOffset" : 7,
      "endOffset" : 29
    }, {
      "referenceID" : 32,
      "context" : "9 CORAL (Sun et al., 2016) 70.",
      "startOffset" : 8,
      "endOffset" : 26
    }, {
      "referenceID" : 29,
      "context" : "Table 1: Single source domain adaptation results on Office-31 (Saenko et al., 2010) dataset with standard unsupervised adaptation protocol.",
      "startOffset" : 62,
      "endOffset" : 83
    }, {
      "referenceID" : 24,
      "context" : "best practice in Long et al. (2015), we freeze the first three groups of Inception modules, and set the learning rate of fourth and fifth group one tenth of the base learning rate to avoid overfitting.",
      "startOffset" : 17,
      "endOffset" : 36
    }, {
      "referenceID" : 23,
      "context" : "Note that the first 5 models of the Table 1 are pre-trained on AlexNet (Krizhevsky et al., 2012) instead of the Inception-BN (Ioffe & Szegedy, 2015) model, due to the lack of publicly available pre-trained Inception BN model in Caffe (Jia et al.",
      "startOffset" : 71,
      "endOffset" : 96
    }, {
      "referenceID" : 21,
      "context" : ", 2012) instead of the Inception-BN (Ioffe & Szegedy, 2015) model, due to the lack of publicly available pre-trained Inception BN model in Caffe (Jia et al., 2014).",
      "startOffset" : 145,
      "endOffset" : 163
    }, {
      "referenceID" : 32,
      "context" : "1 CORAL (Sun et al., 2016) 92.",
      "startOffset" : 8,
      "endOffset" : 26
    }, {
      "referenceID" : 29,
      "context" : "Table 2: Multi-source domain adaptation results on Office-31 (Saenko et al., 2010) dataset with standard unsupervised adaptation protocol.",
      "startOffset" : 61,
      "endOffset" : 82
    }, {
      "referenceID" : 32,
      "context" : "9 CORAL (Sun et al., 2016) 35.",
      "startOffset" : 8,
      "endOffset" : 26
    } ],
    "year" : 2016,
    "abstractText" : "Deep neural networks (DNN) have shown unprecedented success in various computer vision applications such as image classification and object detection. However, it is still a common annoyance during the training phase, that one has to prepare at least thousands of labeled images to fine-tune a network to a specific domain. Recent study (Tommasi et al., 2015) shows that a DNN has strong dependency towards the training dataset, and the learned features cannot be easily transferred to a different but relevant task without fine-tuning. In this paper, we propose a simple yet powerful remedy, called Adaptive Batch Normalization (AdaBN) to increase the generalization ability of a DNN. By modulating the statistics from the source domain to the target domain in all Batch Normalization layers across the network, our approach achieves deep adaptation effect for domain adaptation tasks. In contrary to other deep learning domain adaptation methods, our method does not require additional components, and is parameter-free. It archives stateof-the-art performance despite its surprising simplicity. Furthermore, we demonstrate that our method is complementary with other existing methods. Combining AdaBN with existing domain adaptation treatments may further improve model performance.",
    "creator" : "TeX"
  }
}