{"conference": "ICLR 2017 conference submission", "title": "Rectified Factor Networks for Biclustering", "abstract": "Biclustering is evolving into one of the major tools for analyzing large datasets given as matrix of samples times features. Biclustering has several noteworthy applications and has been successfully applied in life sciences and e-commerce for drug design and recommender systems, respectively.  FABIA is one of the most successful biclustering methods and is used by companies like Bayer, Janssen, or Zalando. FABIA is a generative model that represents each bicluster by two sparse membership vectors: one for the samples and one for the features. However, FABIA is restricted to about 20 code units because of the high computational complexity of computing the posterior. Furthermore, code units are sometimes insufficiently decorrelated. Sample membership is difficult to determine because vectors do not have exact zero entries and can have both large positive and large negative values.  We propose to use the recently introduced unsupervised Deep Learning approach Rectified Factor Networks (RFNs) to overcome the drawbacks of existing biclustering methods. RFNs efficiently construct very sparse, non-linear, high-dimensional representations of the input via their posterior means. RFN learning is a generalized alternating minimization algorithm based on the posterior regularization method which enforces non-negative and normalized posterior means. Each code unit represents a bicluster, where samples for which the code unit is active belong to the bicluster and features that have activating weights to the code unit belong to the bicluster.  On 400 benchmark datasets with artificially implanted biclusters, RFN significantly outperformed 13 other biclustering competitors including FABIA. In biclustering experiments on three gene expression datasets with known clusters that were determined by separate measurements, RFN biclustering was two times significantly better than the other 13 methods and once on second place. On data of the 1000 Genomes Project, RFN could identify DNA segments which indicate, that interbreeding with other hominins starting already before ancestors of modern humans left Africa.", "histories": [], "reviews": [{"IS_META_REVIEW": true, "comments": "This paper applies RFN for biclustering to overcome the drawbacks in FABIA. The proposed method performs best among 14 biclustering methods, However, my first concern is that from the methodological point of view, the novelty of the proposed method seems small. The authors replied to the same question which another reviewer gave, but the replies were not so convincing. \n\nThis paper was actually difficult for me to follow. For instance, in Figure 1, a bicluster matrix is constructed as an outer product of $h$ and $w$. $h$ is a hidden unit, but what is $w$? I could not find any definition. Furthermore, I could not know how $h$ is estimated in this method. Therefore, I do NOT understand how this method performs biclustering. \n\nTotally, I am not sure that this paper is suitable for publication. \n\nProns:\nEmpirical performance is good.\n\nCons:\nNovelty of the proposed method\nSome description in the paper is unclear."}, {"DATE": "06 Feb 2017", "TITLE": "ICLR committee final decision", "IS_META_REVIEW": false, "comments": "The reviewers pointed out several issues with the paper, and all recommended rejection.", "OTHER_KEYS": "ICLR 2017 pcs"}, {"TITLE": "Interesting work but poorly presented", "OTHER_KEYS": "ICLR 2017 conference AnonReviewer1", "comments": "The paper presents a repurposing of rectified factor networks proposed\nearlier by the same authors to biclustering. The method seems\npotentially quite interesting but the paper has serious problems in\nthe presentation.\n\n\nQuality:\n\nThe method relies mainly on techniques presented in a NIPS 2015 paper\nby (mostly) the same authors. The experimental procedure should be\nclarified further. The results (especially Table 2) seem to depend\ncritically upon the sparsity of the reported clusters, but the authors\ndo not explain in sufficient detail how the sparsity hyperparameter is\ndetermined.\n\n\nClarity:\n\nThe style of writing is terrible and completely unacceptable as a\nscientific publication. The text looks more like an industry white\npaper or advertisement, not an objective scientific paper. A complete\nrewrite would be needed before the paper can be considered for\npublication. Specifically, all references to companies using your\nmethods must be deleted.\n\nAdditionally, Table 1 is essentially unreadable. I would recommend\nusing a figure or cleaning up the table by removing all engineering\nnotation and reporting numbers per 1000 so that e.g. \"0.475 +/- 9e-4\"\nwould become \"475 +/- 0.9\". In general figures would be preferred as a\nprimary means for presenting the results in text while tables can be\nincluded as supplementary information.\n\n\nOriginality:\n\nThe novelty of the work appears limited: the method is mostly based on\na NIPS 2015 paper by the same authors. The experimental evaluation\nappears at least partially novel, but for example the IBD detection is\nvery similar to Hochreiter (2013) but without any comparison.\n\n\nSignificance:\n\nThe authors' strongest claim is based on strong empirical performance\nin their own benchmark problems. It is however unclear how useful this\nwould be to others as there is no code available and the details of\nthe implementation are less than complete. Furthermore, the method\ndepends on many specific tuning parameters whose tuning method is not\nfully defined, leaving it unclear how to guarantee the generalisation\nof the good performance.\n", "IS_META_REVIEW": false, "RECOMMENDATION": 4, "DATE": "15 Dec 2016", "REVIEWER_CONFIDENCE": 4}, {"TITLE": "Interesting paper, but the exact model being used is difficult to understand. ", "OTHER_KEYS": "ICLR 2017 conference AnonReviewer3", "comments": "Clarity: The novel contribution of the paper --- Section 2.2 --- was very difficult to understand. The notation seemed inconsistent (particularly the use of l, p, and m), and I am still not confident that I understand the model being used.\n\nOriginality: The novelty comes from applying the RFN model (including the ReLU non-linearity and dropout training) to the problem of biclustering. It sounds like a good idea. \n\nSignificance: The proposed algorithm appears to be a useful tool for unsupervised data modelling, and the authors make a convincing argument that it is significant. (I.E. The previous state-of-the-art, FABIA, is widely used and this method both outperforms and addresses some of the practical difficulties with that method.)\n\nQuality: The experiments are high-quality. \n\nComments:\n1) The introduction claims that this method is much faster than FABIA because the use of rectified units allow it to be run on GPUs. It is not clear to me how this works. How many biclusters can be supported with this method? It looks like the number of biclusters used for this method in the experiments is only 3-5?\n2) The introduction claims that using dropout during training increases sparsity in the bicluster assignments. This seems like a reasonable hypothesis, but this claim should be supported with a better argument or experiments.\n3) How is the model deep? The model isn't deep just because it uses a relu and dropout.", "IS_META_REVIEW": false, "RECOMMENDATION": 5, "DATE": "12 Dec 2016", "REVIEWER_CONFIDENCE": 2}, {"TITLE": "Review on the paper", "OTHER_KEYS": "ICLR 2017 conference AnonReviewer2", "comments": "This paper applies RFN for biclustering to overcome the drawbacks in FABIA. The proposed method performs best among 14 biclustering methods, However, my first concern is that from the methodological point of view, the novelty of the proposed method seems small. The authors replied to the same question which another reviewer gave, but the replies were not so convincing. \n\nThis paper was actually difficult for me to follow. For instance, in Figure 1, a bicluster matrix is constructed as an outer product of $h$ and $w$. $h$ is a hidden unit, but what is $w$? I could not find any definition. Furthermore, I could not know how $h$ is estimated in this method. Therefore, I do NOT understand how this method performs biclustering. \n\nTotally, I am not sure that this paper is suitable for publication. \n\nProns:\nEmpirical performance is good.\n\nCons:\nNovelty of the proposed method\nSome description in the paper is unclear.\n\n", "IS_META_REVIEW": false, "RECOMMENDATION": 5, "DATE": "08 Dec 2016", "REVIEWER_CONFIDENCE": 2}, {"DATE": "02 Dec 2016", "TITLE": "Relationship with the previous NIPS paper", "IS_META_REVIEW": false, "comments": "", "OTHER_KEYS": "ICLR 2017 conference AnonReviewer1"}, {"IS_META_REVIEW": true, "comments": "This paper applies RFN for biclustering to overcome the drawbacks in FABIA. The proposed method performs best among 14 biclustering methods, However, my first concern is that from the methodological point of view, the novelty of the proposed method seems small. The authors replied to the same question which another reviewer gave, but the replies were not so convincing. \n\nThis paper was actually difficult for me to follow. For instance, in Figure 1, a bicluster matrix is constructed as an outer product of $h$ and $w$. $h$ is a hidden unit, but what is $w$? I could not find any definition. Furthermore, I could not know how $h$ is estimated in this method. Therefore, I do NOT understand how this method performs biclustering. \n\nTotally, I am not sure that this paper is suitable for publication. \n\nProns:\nEmpirical performance is good.\n\nCons:\nNovelty of the proposed method\nSome description in the paper is unclear."}, {"DATE": "06 Feb 2017", "TITLE": "ICLR committee final decision", "IS_META_REVIEW": false, "comments": "The reviewers pointed out several issues with the paper, and all recommended rejection.", "OTHER_KEYS": "ICLR 2017 pcs"}, {"TITLE": "Interesting work but poorly presented", "OTHER_KEYS": "ICLR 2017 conference AnonReviewer1", "comments": "The paper presents a repurposing of rectified factor networks proposed\nearlier by the same authors to biclustering. The method seems\npotentially quite interesting but the paper has serious problems in\nthe presentation.\n\n\nQuality:\n\nThe method relies mainly on techniques presented in a NIPS 2015 paper\nby (mostly) the same authors. The experimental procedure should be\nclarified further. The results (especially Table 2) seem to depend\ncritically upon the sparsity of the reported clusters, but the authors\ndo not explain in sufficient detail how the sparsity hyperparameter is\ndetermined.\n\n\nClarity:\n\nThe style of writing is terrible and completely unacceptable as a\nscientific publication. The text looks more like an industry white\npaper or advertisement, not an objective scientific paper. A complete\nrewrite would be needed before the paper can be considered for\npublication. Specifically, all references to companies using your\nmethods must be deleted.\n\nAdditionally, Table 1 is essentially unreadable. I would recommend\nusing a figure or cleaning up the table by removing all engineering\nnotation and reporting numbers per 1000 so that e.g. \"0.475 +/- 9e-4\"\nwould become \"475 +/- 0.9\". In general figures would be preferred as a\nprimary means for presenting the results in text while tables can be\nincluded as supplementary information.\n\n\nOriginality:\n\nThe novelty of the work appears limited: the method is mostly based on\na NIPS 2015 paper by the same authors. The experimental evaluation\nappears at least partially novel, but for example the IBD detection is\nvery similar to Hochreiter (2013) but without any comparison.\n\n\nSignificance:\n\nThe authors' strongest claim is based on strong empirical performance\nin their own benchmark problems. It is however unclear how useful this\nwould be to others as there is no code available and the details of\nthe implementation are less than complete. Furthermore, the method\ndepends on many specific tuning parameters whose tuning method is not\nfully defined, leaving it unclear how to guarantee the generalisation\nof the good performance.\n", "IS_META_REVIEW": false, "RECOMMENDATION": 4, "DATE": "15 Dec 2016", "REVIEWER_CONFIDENCE": 4}, {"TITLE": "Interesting paper, but the exact model being used is difficult to understand. ", "OTHER_KEYS": "ICLR 2017 conference AnonReviewer3", "comments": "Clarity: The novel contribution of the paper --- Section 2.2 --- was very difficult to understand. The notation seemed inconsistent (particularly the use of l, p, and m), and I am still not confident that I understand the model being used.\n\nOriginality: The novelty comes from applying the RFN model (including the ReLU non-linearity and dropout training) to the problem of biclustering. It sounds like a good idea. \n\nSignificance: The proposed algorithm appears to be a useful tool for unsupervised data modelling, and the authors make a convincing argument that it is significant. (I.E. The previous state-of-the-art, FABIA, is widely used and this method both outperforms and addresses some of the practical difficulties with that method.)\n\nQuality: The experiments are high-quality. \n\nComments:\n1) The introduction claims that this method is much faster than FABIA because the use of rectified units allow it to be run on GPUs. It is not clear to me how this works. How many biclusters can be supported with this method? It looks like the number of biclusters used for this method in the experiments is only 3-5?\n2) The introduction claims that using dropout during training increases sparsity in the bicluster assignments. This seems like a reasonable hypothesis, but this claim should be supported with a better argument or experiments.\n3) How is the model deep? The model isn't deep just because it uses a relu and dropout.", "IS_META_REVIEW": false, "RECOMMENDATION": 5, "DATE": "12 Dec 2016", "REVIEWER_CONFIDENCE": 2}, {"TITLE": "Review on the paper", "OTHER_KEYS": "ICLR 2017 conference AnonReviewer2", "comments": "This paper applies RFN for biclustering to overcome the drawbacks in FABIA. The proposed method performs best among 14 biclustering methods, However, my first concern is that from the methodological point of view, the novelty of the proposed method seems small. The authors replied to the same question which another reviewer gave, but the replies were not so convincing. \n\nThis paper was actually difficult for me to follow. For instance, in Figure 1, a bicluster matrix is constructed as an outer product of $h$ and $w$. $h$ is a hidden unit, but what is $w$? I could not find any definition. Furthermore, I could not know how $h$ is estimated in this method. Therefore, I do NOT understand how this method performs biclustering. \n\nTotally, I am not sure that this paper is suitable for publication. \n\nProns:\nEmpirical performance is good.\n\nCons:\nNovelty of the proposed method\nSome description in the paper is unclear.\n\n", "IS_META_REVIEW": false, "RECOMMENDATION": 5, "DATE": "08 Dec 2016", "REVIEWER_CONFIDENCE": 2}, {"DATE": "02 Dec 2016", "TITLE": "Relationship with the previous NIPS paper", "IS_META_REVIEW": false, "comments": "", "OTHER_KEYS": "ICLR 2017 conference AnonReviewer1"}], "authors": "Djork-Arn\u00e9 Clevert, Thomas Unterthiner, Sepp Hochreiter", "accepted": false, "id": "773"}