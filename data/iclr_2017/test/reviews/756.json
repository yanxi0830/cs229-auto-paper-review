{"conference": "ICLR 2017 conference submission", "title": "Learning similarity preserving representations with neural similarity and context encoders", "abstract": "We introduce similarity encoders (SimEc), which learn similarity preserving representations by using a feed-forward neural network to map data into an embedding space where the original similarities can be approximated linearly. The model can easily compute representations for novel (out-of-sample) data points, even if the original pairwise similarities of the training set were generated by an unknown process such as human ratings. This is demonstrated by creating embeddings of both image and text data. Furthermore, the idea behind similarity encoders gives an intuitive explanation of the optimization strategy used by the continuous bag-of-words (CBOW) word2vec model trained with negative sampling. Based on this insight, we define context encoders (ConEc), which can improve the word embeddings created with word2vec by using the local context of words to create out-of-vocabulary embeddings and representations for words with multiple meanings. The benefit of this is illustrated by using these word embeddings as features in the CoNLL 2003 named entity recognition task.", "histories": [], "reviews": [{"IS_META_REVIEW": true, "comments": "This paper presents a method for embedding data instances into a low-dimensional space that preserves some form of similarity.\n\nAlthough the paper presents this notion as new, basically every pre-trained embedding (be it auto-encoders or word2vec) has been doing the same: representing items in a low-dimensional space that inherently encodes their similarities. Even when looking at the specific case of word/context embeddings, the method is not novel either: this method is almost identical to one of the similarity functions presented in \"A Simple Word Embedding Model for Lexical Substitution\" (Melamud et al., 2015). The novelty claim must be more accurate and position itself with respect to existing work.\n\nIn addition, I think the evaluation could be done better. There are plenty of benchmarks for word embeddings in context, for example: \n*"}, {"DATE": "06 Feb 2017", "TITLE": "ICLR committee final decision", "IS_META_REVIEW": false, "comments": "There is consensus among the reviewers that the novelty of the paper is limited, and that the experimental evaluation of the proposed method needs to be improved.", "OTHER_KEYS": "ICLR 2017 pcs"}, {"TITLE": "Novelty claim is false, evaluation is partial", "OTHER_KEYS": "ICLR 2017 conference AnonReviewer2", "comments": "This paper presents a method for embedding data instances into a low-dimensional space that preserves some form of similarity.\n\nAlthough the paper presents this notion as new, basically every pre-trained embedding (be it auto-encoders or word2vec) has been doing the same: representing items in a low-dimensional space that inherently encodes their similarities. Even when looking at the specific case of word/context embeddings, the method is not novel either: this method is almost identical to one of the similarity functions presented in \"A Simple Word Embedding Model for Lexical Substitution\" (Melamud et al., 2015). The novelty claim must be more accurate and position itself with respect to existing work.\n\nIn addition, I think the evaluation could be done better. There are plenty of benchmarks for word embeddings in context, for example: \n* ", "IS_META_REVIEW": false, "RECOMMENDATION": 3, "DATE": "19 Dec 2016", "REVIEWER_CONFIDENCE": 4}, {"TITLE": "marginal novelty", "OTHER_KEYS": "ICLR 2017 conference AnonReviewer3", "comments": "this paper proposes to use feed-forward neural networks to learn similarity preserving embeddings. They also use the proposed idea to represent out-of-vocabulary words using the words in given context. \n\nFirst, considering the related work [1,2] the proposed approach brings marginal novelty. Especially\nContext Encoders is just a small improvement over word2vec. \n\nExperimental setup should provide more convincing results other than visualizations and non-standard benchmark for NER evaluation with word vectors [3].\n\n[1] ", "IS_META_REVIEW": false, "RECOMMENDATION": 2, "DATE": "17 Dec 2016", "REVIEWER_CONFIDENCE": 5}, {"TITLE": "Standard feed-forward neural net with unconvincing experimental results", "OTHER_KEYS": "ICLR 2017 conference AnonReviewer1", "comments": "This paper introduces a similarity encoder based on a standard feed-forward neural network with the aim of generating similarity-preserving embeddings. The approach is utilized to generate a simple extension of the CBOW word2vec model that transforms the learned embeddings by their average context vectors. Experiments are performed on an analogy task and named entity recognition.\n\nWhile this paper offers some reasonable intuitive arguments for why a feed-forward neural network can generate good similarity-preserving embeddings, the architecture and approach is far from novel. As far as I can tell, the model is nothing more than the most vanilla neural network trained with SGD on similarity signals.\n\nSlightly more original is the idea to use context embeddings to augment the expressive capacity of learned word representations. Of course, using explicit contextual information is not a new idea, especially for tasks like word sense disambiguation (see, e.g., 'Efficient Non-parametric Estimation of Multiple Embeddings per Word in Vector Space' by Neelakantan et al, which should also be cited), but the specific method used here is original, as far as I know.\n\nThe evaluation of the method is far from convincing. The corpora used to train the embeddings are far smaller than would ever be used in practice for unsupervised or semi-supervised embedding learning. The performance on the analogy task says little about the benefit of this method for larger corpora, and, as the authors mentioned in the comments, they expect \"the gain will be less significant, as the global context statistics brought in by the ConEc can also be picked up by word2vec with more training.\"\n\nThe argument can be made (and the authors do claim) that extrinsic evaluations are more important for real-world applications, so it is good to see experiments on NER. However, again the embeddings were trained on a very small corpus and I am not convinced that the observed benefit will persist when trained on larger corpora.\n\nOverall, I believe this paper offers little novelty and weak experimental evidence supporting its claims. I cannot recommend it for acceptance.", "IS_META_REVIEW": false, "RECOMMENDATION": 3, "DATE": "16 Dec 2016", "REVIEWER_CONFIDENCE": 4}, {"DATE": "03 Dec 2016", "TITLE": "Related literature on context embeddings", "IS_META_REVIEW": false, "comments": "", "OTHER_KEYS": "ICLR 2017 conference AnonReviewer2"}, {"DATE": "03 Dec 2016", "TITLE": "questions and suggestions", "IS_META_REVIEW": false, "comments": "", "OTHER_KEYS": "ICLR 2017 conference AnonReviewer3"}, {"DATE": "02 Dec 2016", "TITLE": "Analogy task", "IS_META_REVIEW": false, "comments": "", "OTHER_KEYS": "ICLR 2017 conference AnonReviewer1"}, {"IS_META_REVIEW": true, "comments": "This paper presents a method for embedding data instances into a low-dimensional space that preserves some form of similarity.\n\nAlthough the paper presents this notion as new, basically every pre-trained embedding (be it auto-encoders or word2vec) has been doing the same: representing items in a low-dimensional space that inherently encodes their similarities. Even when looking at the specific case of word/context embeddings, the method is not novel either: this method is almost identical to one of the similarity functions presented in \"A Simple Word Embedding Model for Lexical Substitution\" (Melamud et al., 2015). The novelty claim must be more accurate and position itself with respect to existing work.\n\nIn addition, I think the evaluation could be done better. There are plenty of benchmarks for word embeddings in context, for example: \n*"}, {"DATE": "06 Feb 2017", "TITLE": "ICLR committee final decision", "IS_META_REVIEW": false, "comments": "There is consensus among the reviewers that the novelty of the paper is limited, and that the experimental evaluation of the proposed method needs to be improved.", "OTHER_KEYS": "ICLR 2017 pcs"}, {"TITLE": "Novelty claim is false, evaluation is partial", "OTHER_KEYS": "ICLR 2017 conference AnonReviewer2", "comments": "This paper presents a method for embedding data instances into a low-dimensional space that preserves some form of similarity.\n\nAlthough the paper presents this notion as new, basically every pre-trained embedding (be it auto-encoders or word2vec) has been doing the same: representing items in a low-dimensional space that inherently encodes their similarities. Even when looking at the specific case of word/context embeddings, the method is not novel either: this method is almost identical to one of the similarity functions presented in \"A Simple Word Embedding Model for Lexical Substitution\" (Melamud et al., 2015). The novelty claim must be more accurate and position itself with respect to existing work.\n\nIn addition, I think the evaluation could be done better. There are plenty of benchmarks for word embeddings in context, for example: \n* ", "IS_META_REVIEW": false, "RECOMMENDATION": 3, "DATE": "19 Dec 2016", "REVIEWER_CONFIDENCE": 4}, {"TITLE": "marginal novelty", "OTHER_KEYS": "ICLR 2017 conference AnonReviewer3", "comments": "this paper proposes to use feed-forward neural networks to learn similarity preserving embeddings. They also use the proposed idea to represent out-of-vocabulary words using the words in given context. \n\nFirst, considering the related work [1,2] the proposed approach brings marginal novelty. Especially\nContext Encoders is just a small improvement over word2vec. \n\nExperimental setup should provide more convincing results other than visualizations and non-standard benchmark for NER evaluation with word vectors [3].\n\n[1] ", "IS_META_REVIEW": false, "RECOMMENDATION": 2, "DATE": "17 Dec 2016", "REVIEWER_CONFIDENCE": 5}, {"TITLE": "Standard feed-forward neural net with unconvincing experimental results", "OTHER_KEYS": "ICLR 2017 conference AnonReviewer1", "comments": "This paper introduces a similarity encoder based on a standard feed-forward neural network with the aim of generating similarity-preserving embeddings. The approach is utilized to generate a simple extension of the CBOW word2vec model that transforms the learned embeddings by their average context vectors. Experiments are performed on an analogy task and named entity recognition.\n\nWhile this paper offers some reasonable intuitive arguments for why a feed-forward neural network can generate good similarity-preserving embeddings, the architecture and approach is far from novel. As far as I can tell, the model is nothing more than the most vanilla neural network trained with SGD on similarity signals.\n\nSlightly more original is the idea to use context embeddings to augment the expressive capacity of learned word representations. Of course, using explicit contextual information is not a new idea, especially for tasks like word sense disambiguation (see, e.g., 'Efficient Non-parametric Estimation of Multiple Embeddings per Word in Vector Space' by Neelakantan et al, which should also be cited), but the specific method used here is original, as far as I know.\n\nThe evaluation of the method is far from convincing. The corpora used to train the embeddings are far smaller than would ever be used in practice for unsupervised or semi-supervised embedding learning. The performance on the analogy task says little about the benefit of this method for larger corpora, and, as the authors mentioned in the comments, they expect \"the gain will be less significant, as the global context statistics brought in by the ConEc can also be picked up by word2vec with more training.\"\n\nThe argument can be made (and the authors do claim) that extrinsic evaluations are more important for real-world applications, so it is good to see experiments on NER. However, again the embeddings were trained on a very small corpus and I am not convinced that the observed benefit will persist when trained on larger corpora.\n\nOverall, I believe this paper offers little novelty and weak experimental evidence supporting its claims. I cannot recommend it for acceptance.", "IS_META_REVIEW": false, "RECOMMENDATION": 3, "DATE": "16 Dec 2016", "REVIEWER_CONFIDENCE": 4}, {"DATE": "03 Dec 2016", "TITLE": "Related literature on context embeddings", "IS_META_REVIEW": false, "comments": "", "OTHER_KEYS": "ICLR 2017 conference AnonReviewer2"}, {"DATE": "03 Dec 2016", "TITLE": "questions and suggestions", "IS_META_REVIEW": false, "comments": "", "OTHER_KEYS": "ICLR 2017 conference AnonReviewer3"}, {"DATE": "02 Dec 2016", "TITLE": "Analogy task", "IS_META_REVIEW": false, "comments": "", "OTHER_KEYS": "ICLR 2017 conference AnonReviewer1"}], "authors": "Franziska Horn, Klaus-Robert M\u00fcller", "accepted": false, "id": "756"}