{"conference": "ICLR 2017 conference submission", "title": "Efficient Calculation of Polynomial Features on Sparse Matrices", "abstract": "We provide an algorithm for polynomial feature expansion that both operates on and produces a compressed sparse row matrix without any densification. For a vector of dimension D, density d, and degree k the algorithm has time complexity O(d^k * D^k) where k is the polynomial-feature order; this is an improvement by a factor d^k over the standard method.", "histories": [], "reviews": [{"IS_META_REVIEW": true, "comments": "The paper is beyond my expertise. I cannot give any solid review comments regarding the techniques that are better than an educated guess.\n\nHowever, it seems to me that the topic is not very relevant to the focus of ICLR. Also the quality of writing requires improvement, especially literature review and experiment analysis."}, {"DATE": "06 Feb 2017", "TITLE": "ICLR committee final decision", "IS_META_REVIEW": false, "comments": "The approach/problem seems interesting, and several reviewers commented on this. However, the experimental evaluation is quite preliminary and the paper would be helped a lot with a connection to a motivating application. All of the reviewers pointed out that the work is not written in the usual in the scope of ICLR papers, and putting these together at this time it makes sense to reject the paper.", "OTHER_KEYS": "ICLR 2017 pcs"}, {"TITLE": "Interesting algorithm, but poor fit with ICLR", "OTHER_KEYS": "ICLR 2017 conference AnonReviewer2", "comments": "The authors present here a new algorithm for the effective calculation of polynomial features on Sparse Matrices. The key idea is to use a proper mapping between matrices and their polynomial versions, in order to derive an effective CSR expansion algorithm. The authors analyse the time complexity in a convincing way with experiments.\n\nOverall, the algorithm is definitely interesting, quite simple and nice, with many possible applications. The paper is however very superficial in terms of experiments, or applications of the proposed scheme. Most importantly, the fit with the main scope of ICLR is far from obvious with this work, that should probably re-submitted to better targets. ", "IS_META_REVIEW": false, "RECOMMENDATION": 3, "DATE": "21 Dec 2016", "REVIEWER_CONFIDENCE": 3}, {"TITLE": "No Title", "OTHER_KEYS": "ICLR 2017 conference AnonReviewer1", "comments": "This paper proposes an algorithm for polynomial feature expansion on CSR matrices, which reduces the time complexity of the standard method by a factor d^k where d is the density of the sparse matrix. The main contribution of this work is not significant enough. The experiments are incomplete and not convincing.\n\nThe background of the problem is not sufficiently introduced. There are only two references in the introduction part (overall only three papers are cited), which are from decades ago. Many more relevant papers should be cited from the recent literature.\n\nThe experiment part is very weak. This paper claims that the time complexity of their algorithm is O(d^k D^k), which is an improvement over standard method O(D^k) by a factor d^k. But in the experiments, when d=1, there is still a large gap (~14s vs. ~90s) between the proposed method and the standard one. The authors explain this as \"likely a language implementation\", which is not convincing. To fairly compare the two methods, of course you need to implement both in the same programming language and run experiments in the same environment. For higher degree feature expansion, there is no empirical experiments to show the advantage of the proposed method.\n\nSome minor problems are listed below.\n1) In Section 2, the notation \"p_i:p_i+1\" is not clearly defined.\n2) In Section 3.1, typo: \"efter\" - \"after\"\n3) All the algorithms in this paper are not titled. The input and output is not clearly listed.\n4) In Figure 1, the meaning of the colored area is not described. Is it standard deviation or some quantile of the running time? How many runs of each algorithm are used to generate the ribbons? Many details of the experimental settings are missing.\n", "IS_META_REVIEW": false, "RECOMMENDATION": 3, "DATE": "19 Dec 2016", "REVIEWER_CONFIDENCE": 3}, {"TITLE": "This is not quite related with ICLR's field of interests", "OTHER_KEYS": "ICLR 2017 conference AnonReviewer3", "comments": "The paper is beyond my expertise. I cannot give any solid review comments regarding the techniques that are better than an educated guess.\n\nHowever, it seems to me that the topic is not very relevant to the focus of ICLR. Also the quality of writing requires improvement, especially literature review and experiment analysis. ", "IS_META_REVIEW": false, "RECOMMENDATION": 3, "DATE": "18 Dec 2016", "REVIEWER_CONFIDENCE": 1}, {"IS_META_REVIEW": true, "comments": "The paper is beyond my expertise. I cannot give any solid review comments regarding the techniques that are better than an educated guess.\n\nHowever, it seems to me that the topic is not very relevant to the focus of ICLR. Also the quality of writing requires improvement, especially literature review and experiment analysis."}, {"DATE": "06 Feb 2017", "TITLE": "ICLR committee final decision", "IS_META_REVIEW": false, "comments": "The approach/problem seems interesting, and several reviewers commented on this. However, the experimental evaluation is quite preliminary and the paper would be helped a lot with a connection to a motivating application. All of the reviewers pointed out that the work is not written in the usual in the scope of ICLR papers, and putting these together at this time it makes sense to reject the paper.", "OTHER_KEYS": "ICLR 2017 pcs"}, {"TITLE": "Interesting algorithm, but poor fit with ICLR", "OTHER_KEYS": "ICLR 2017 conference AnonReviewer2", "comments": "The authors present here a new algorithm for the effective calculation of polynomial features on Sparse Matrices. The key idea is to use a proper mapping between matrices and their polynomial versions, in order to derive an effective CSR expansion algorithm. The authors analyse the time complexity in a convincing way with experiments.\n\nOverall, the algorithm is definitely interesting, quite simple and nice, with many possible applications. The paper is however very superficial in terms of experiments, or applications of the proposed scheme. Most importantly, the fit with the main scope of ICLR is far from obvious with this work, that should probably re-submitted to better targets. ", "IS_META_REVIEW": false, "RECOMMENDATION": 3, "DATE": "21 Dec 2016", "REVIEWER_CONFIDENCE": 3}, {"TITLE": "No Title", "OTHER_KEYS": "ICLR 2017 conference AnonReviewer1", "comments": "This paper proposes an algorithm for polynomial feature expansion on CSR matrices, which reduces the time complexity of the standard method by a factor d^k where d is the density of the sparse matrix. The main contribution of this work is not significant enough. The experiments are incomplete and not convincing.\n\nThe background of the problem is not sufficiently introduced. There are only two references in the introduction part (overall only three papers are cited), which are from decades ago. Many more relevant papers should be cited from the recent literature.\n\nThe experiment part is very weak. This paper claims that the time complexity of their algorithm is O(d^k D^k), which is an improvement over standard method O(D^k) by a factor d^k. But in the experiments, when d=1, there is still a large gap (~14s vs. ~90s) between the proposed method and the standard one. The authors explain this as \"likely a language implementation\", which is not convincing. To fairly compare the two methods, of course you need to implement both in the same programming language and run experiments in the same environment. For higher degree feature expansion, there is no empirical experiments to show the advantage of the proposed method.\n\nSome minor problems are listed below.\n1) In Section 2, the notation \"p_i:p_i+1\" is not clearly defined.\n2) In Section 3.1, typo: \"efter\" - \"after\"\n3) All the algorithms in this paper are not titled. The input and output is not clearly listed.\n4) In Figure 1, the meaning of the colored area is not described. Is it standard deviation or some quantile of the running time? How many runs of each algorithm are used to generate the ribbons? Many details of the experimental settings are missing.\n", "IS_META_REVIEW": false, "RECOMMENDATION": 3, "DATE": "19 Dec 2016", "REVIEWER_CONFIDENCE": 3}, {"TITLE": "This is not quite related with ICLR's field of interests", "OTHER_KEYS": "ICLR 2017 conference AnonReviewer3", "comments": "The paper is beyond my expertise. I cannot give any solid review comments regarding the techniques that are better than an educated guess.\n\nHowever, it seems to me that the topic is not very relevant to the focus of ICLR. Also the quality of writing requires improvement, especially literature review and experiment analysis. ", "IS_META_REVIEW": false, "RECOMMENDATION": 3, "DATE": "18 Dec 2016", "REVIEWER_CONFIDENCE": 1}], "authors": "Andrew Nystrom, John Hughes", "accepted": false, "id": "739"}