{"conference": "ICLR 2017 conference submission", "title": "Designing Neural Network Architectures using Reinforcement Learning", "abstract": "At present, designing convolutional neural network (CNN) architectures requires both human expertise and labor. New architectures are handcrafted by careful experimentation or modified from a handful of existing networks. We introduce MetaQNN, a meta-modeling algorithm based on reinforcement learning to automatically generate high-performing CNN architectures for a given learning task. The learning agent is trained to sequentially choose CNN layers using $Q$-learning with an $\\epsilon$-greedy exploration strategy and experience replay. The agent explores a large but finite space of possible architectures and iteratively discovers designs with improved performance on the learning task. On image classification benchmarks, the agent-designed networks (consisting of only standard convolution, pooling, and fully-connected layers) beat existing networks designed with the same layer types and are competitive against the state-of-the-art methods that use more complex layer types. We also outperform existing meta-modeling approaches for network design on image classification tasks.", "histories": [], "reviews": [{"DATE": "06 Feb 2017", "TITLE": "ICLR committee final decision", "IS_META_REVIEW": false, "comments": "This paper comes up with a novel approach to searching the space of architectures for deep neural networks using reinforcement learning. The idea is straightforward and sensible: use a reinforcement learning strategy to iteratively grow a deep net graph (the space of actions is e.g. adding different layer types) via Q-learning. The reviewers agree that the idea is interesting, novel and promising but are underwhelmed with the execution of the experiments and the empirical results. \n \n The idea behind the paper and the formulation of the problem are quite similar to a concurrent submission (", "OTHER_KEYS": "ICLR 2017 pcs"}, {"DATE": "20 Jan 2017", "TITLE": "A new revision updated", "IS_META_REVIEW": false, "comments": "We have added the results of the stability experiment (as suggested by AnonReviewer1) into the Appendix section D.1. We have also included a citation to the CNF paper and results from the latest ResNet paper.", "OTHER_KEYS": "Nikhil Naik"}, {"IMPACT": 4, "MEANINGFUL_COMPARISON": 3, "OTHER_KEYS": "ICLR 2017 conference AnonReviewer1", "comments": "This paper introduces a reinforcement learning framework for designing a neural network architecture. For each time-step, the agent picks a new layer type with corresponding layer parameters (e.g., #filters). In order to reduce the size of state-action space, they used a small set of design choices.\n\nStrengths:\n- A novel approach for automatic design of neural network architectures.\n- Shows quite promising results on several datasets (MNIST, CIFAR-10).\n\nWeakness:\n- Limited architecture design choices due to many prior assumptions (e.g., a set of possible number of convolution filters, at most 2 fully-connected layers, maximum depth, hard-coded dropout, etc.)\n- The method is demonstrated in tabular Q-learning setting, but it is unclear whether the proposed method would work in a large state-action space.\n\nOverall, this is an interesting and novel approach for neural network architecture design, and it seems to be worth publication despite some weaknesses.", "ORIGINALITY": 3, "IS_ANNOTATED": true, "TITLE": "review", "IS_META_REVIEW": false, "RECOMMENDATION": 6, "DATE": "21 Dec 2016", "REVIEWER_CONFIDENCE": 4}, {"IMPACT": 2, "APPROPRIATENESS": 3, "OTHER_KEYS": "ICLR 2017 conference AnonReviewer2", "TITLE": "No Title", "comments": "The paper looks solid and the idea is natural. Results seem promising as well.\n\nI am mostly concerned about the computational cost of the method. 8-10 days on 10 GPUs for relatively tiny datasets is quite prohibitive for most applications I would ever encounter.\n I think the main question is how this approach scales to larger images and also when applied to more exotic and possibly tiny datasets. Can you run an experiment on Caltech-101 for instance? I would be very curious to see if your approach is suitable for the low-data regime and areas where we all do not know right away how a suitable architecture looks like. For Cifar-10/100, MNIST and SVHN, everyone knows very well what a reasonable model initialization looks like.\n\nIf you show proof that you can discover a competitive architecture for something like Caltech-101, I would recommend the paper for publication.\n\nMinor: \n- ResNets should be mentioned in Table ", "ORIGINALITY": 5, "IS_ANNOTATED": true, "IS_META_REVIEW": false, "RECOMMENDATION": 6, "DATE": "19 Dec 2016", "CLARITY": 5, "REVIEWER_CONFIDENCE": 3}, {"OTHER_KEYS": "ICLR 2017 conference AnonReviewer3", "TITLE": "Review", "comments": "Authors learn deep architectures on a few small vision problems using Q-learning and obtain solid results, SOTA results when limiting to certain types of layers and competitive against everything else. It would be good to know how well this performs when allowing more complex structures. Paper would be much more convincing on a real-size task such as ImageNet.", "ORIGINALITY": 3, "IS_ANNOTATED": true, "IS_META_REVIEW": false, "RECOMMENDATION": 6, "DATE": "16 Dec 2016", "CLARITY": 4, "REVIEWER_CONFIDENCE": 4}, {"OTHER_KEYS": "ICLR 2017 conference AnonReviewer3", "TITLE": "Details", "comments": "", "ORIGINALITY": 3, "IS_ANNOTATED": true, "IS_META_REVIEW": false, "DATE": "11 Dec 2016", "CLARITY": 4}, {"IMPACT": 4, "OTHER_KEYS": "ICLR 2017 conference AnonReviewer1", "MEANINGFUL_COMPARISON": 3, "comments": "", "ORIGINALITY": 3, "IS_ANNOTATED": true, "TITLE": "questions", "IS_META_REVIEW": false, "DATE": "05 Dec 2016"}, {"IMPACT": 2, "APPROPRIATENESS": 3, "OTHER_KEYS": "ICLR 2017 conference AnonReviewer2", "TITLE": "CNF", "comments": "", "ORIGINALITY": 5, "IS_ANNOTATED": true, "IS_META_REVIEW": false, "DATE": "03 Dec 2016", "CLARITY": 5}, {"DATE": "06 Feb 2017", "TITLE": "ICLR committee final decision", "IS_META_REVIEW": false, "comments": "This paper comes up with a novel approach to searching the space of architectures for deep neural networks using reinforcement learning. The idea is straightforward and sensible: use a reinforcement learning strategy to iteratively grow a deep net graph (the space of actions is e.g. adding different layer types) via Q-learning. The reviewers agree that the idea is interesting, novel and promising but are underwhelmed with the execution of the experiments and the empirical results. \n \n The idea behind the paper and the formulation of the problem are quite similar to a concurrent submission (", "OTHER_KEYS": "ICLR 2017 pcs"}, {"DATE": "20 Jan 2017", "TITLE": "A new revision updated", "IS_META_REVIEW": false, "comments": "We have added the results of the stability experiment (as suggested by AnonReviewer1) into the Appendix section D.1. We have also included a citation to the CNF paper and results from the latest ResNet paper.", "OTHER_KEYS": "Nikhil Naik"}, {"IMPACT": 4, "MEANINGFUL_COMPARISON": 3, "OTHER_KEYS": "ICLR 2017 conference AnonReviewer1", "comments": "This paper introduces a reinforcement learning framework for designing a neural network architecture. For each time-step, the agent picks a new layer type with corresponding layer parameters (e.g., #filters). In order to reduce the size of state-action space, they used a small set of design choices.\n\nStrengths:\n- A novel approach for automatic design of neural network architectures.\n- Shows quite promising results on several datasets (MNIST, CIFAR-10).\n\nWeakness:\n- Limited architecture design choices due to many prior assumptions (e.g., a set of possible number of convolution filters, at most 2 fully-connected layers, maximum depth, hard-coded dropout, etc.)\n- The method is demonstrated in tabular Q-learning setting, but it is unclear whether the proposed method would work in a large state-action space.\n\nOverall, this is an interesting and novel approach for neural network architecture design, and it seems to be worth publication despite some weaknesses.", "ORIGINALITY": 3, "IS_ANNOTATED": true, "TITLE": "review", "IS_META_REVIEW": false, "RECOMMENDATION": 6, "DATE": "21 Dec 2016", "REVIEWER_CONFIDENCE": 4}, {"IMPACT": 2, "APPROPRIATENESS": 3, "OTHER_KEYS": "ICLR 2017 conference AnonReviewer2", "TITLE": "No Title", "comments": "The paper looks solid and the idea is natural. Results seem promising as well.\n\nI am mostly concerned about the computational cost of the method. 8-10 days on 10 GPUs for relatively tiny datasets is quite prohibitive for most applications I would ever encounter.\n I think the main question is how this approach scales to larger images and also when applied to more exotic and possibly tiny datasets. Can you run an experiment on Caltech-101 for instance? I would be very curious to see if your approach is suitable for the low-data regime and areas where we all do not know right away how a suitable architecture looks like. For Cifar-10/100, MNIST and SVHN, everyone knows very well what a reasonable model initialization looks like.\n\nIf you show proof that you can discover a competitive architecture for something like Caltech-101, I would recommend the paper for publication.\n\nMinor: \n- ResNets should be mentioned in Table ", "ORIGINALITY": 5, "IS_ANNOTATED": true, "IS_META_REVIEW": false, "RECOMMENDATION": 6, "DATE": "19 Dec 2016", "CLARITY": 5, "REVIEWER_CONFIDENCE": 3}, {"OTHER_KEYS": "ICLR 2017 conference AnonReviewer3", "TITLE": "Review", "comments": "Authors learn deep architectures on a few small vision problems using Q-learning and obtain solid results, SOTA results when limiting to certain types of layers and competitive against everything else. It would be good to know how well this performs when allowing more complex structures. Paper would be much more convincing on a real-size task such as ImageNet.", "ORIGINALITY": 3, "IS_ANNOTATED": true, "IS_META_REVIEW": false, "RECOMMENDATION": 6, "DATE": "16 Dec 2016", "CLARITY": 4, "REVIEWER_CONFIDENCE": 4}, {"OTHER_KEYS": "ICLR 2017 conference AnonReviewer3", "TITLE": "Details", "comments": "", "ORIGINALITY": 3, "IS_ANNOTATED": true, "IS_META_REVIEW": false, "DATE": "11 Dec 2016", "CLARITY": 4}, {"IMPACT": 4, "OTHER_KEYS": "ICLR 2017 conference AnonReviewer1", "MEANINGFUL_COMPARISON": 3, "comments": "", "ORIGINALITY": 3, "IS_ANNOTATED": true, "TITLE": "questions", "IS_META_REVIEW": false, "DATE": "05 Dec 2016"}, {"IMPACT": 2, "APPROPRIATENESS": 3, "OTHER_KEYS": "ICLR 2017 conference AnonReviewer2", "TITLE": "CNF", "comments": "", "ORIGINALITY": 5, "IS_ANNOTATED": true, "IS_META_REVIEW": false, "DATE": "03 Dec 2016", "CLARITY": 5}], "authors": "Bowen Baker, Otkrist Gupta, Nikhil Naik, Ramesh Raskar", "accepted": true, "id": "383"}