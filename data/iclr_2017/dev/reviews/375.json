{"conference": "ICLR 2017 conference submission", "title": "A Simple but Tough-to-Beat Baseline for Sentence Embeddings", "abstract": "The success of neural network methods for computing word embeddings has motivated methods for generating semantic embeddings of longer pieces of text, such as sentences and paragraphs. Surprisingly, Wieting et al (ICLR'16) showed that such complicated methods are outperformed, especially in out-of-domain (transfer learning) settings, by simpler methods involving mild retraining of word embeddings and basic linear regression. The  method of Wieting et al. requires retraining with a substantial labeled dataset such as Paraphrase Database (Ganitkevitch et al., 2013).   The current paper goes further, showing that the following completely unsupervised sentence embedding is a formidable baseline: Use word embeddings computed using one of the popular methods on unlabeled corpus like Wikipedia, represent the sentence by a weighted average of the word vectors, and then modify them a bit using PCA/SVD. This weighting improves performance by about 10% to 30% in textual similarity tasks, and beats sophisticated supervised methods including RNN's and LSTM's. It even improves Wieting et al.'s embeddings.   This simple method should be used as the baseline to beat in future, especially when labeled training data is scarce or nonexistent.   The paper also gives a theoretical explanation of the success of the above unsupervised method using a latent variable generative model for sentences, which is a simple extension of the model in Arora et al. (TACL'16) with new \"smoothing\" terms that allow for  words occurring out of context, as well as high probabilities for words like and, not in all contexts.", "histories": [], "reviews": [{"IS_META_REVIEW": true, "comments": "This paper presents a new theoretically-principled method of representing sentences as vectors. The experiments show that vectors produced by this method perform well on similarity and entailment benchmarks, surpassing some RNN-based methods too.\n\nOverall, this is an interesting empirical result, especially since the model is not order-sensitive (as far as I can tell). I would like to see some more discussion on why such a simple model does better than LSTMs at capturing similarity and entailment. Could this be an artifact of these benchmarks?"}, {"DATE": "06 Feb 2017", "TITLE": "ICLR committee final decision", "IS_META_REVIEW": false, "comments": "A new method for sentence embedding that is simple and performs well. Important contribution that will attract attention and help move the field forward.", "OTHER_KEYS": "ICLR 2017 pcs"}, {"SUBSTANCE": 4, "OTHER_KEYS": "ICLR 2017 conference AnonReviewer3", "TITLE": "Accept", "comments": "This is a good paper with an interesting probabilistic motivation for weighted bag of words models.\nThe (hopefully soon) added comparison to Wang and Manning will make it stronger. \nThough it is sad that for sufficiently large datasets, NB-SVM still works better.\n\nIn the second to last paragraph of the introduction you describe a problem of large cooccurrence counts which was already fixed by the Glove embeddings with their weighting function f.\n\nMinor comments:\n\n\"The capturing the similarities\" -- typo in line 2 of intro.\n\"Recently, (Wieting et al.,2016) learned\" -- use citet instead of parenthesized citation\n ", "SOUNDNESS_CORRECTNESS": 3, "IS_ANNOTATED": true, "IS_META_REVIEW": false, "RECOMMENDATION": 7, "DATE": "22 Dec 2016", "REVIEWER_CONFIDENCE": 4}, {"OTHER_KEYS": "ICLR 2017 conference AnonReviewer1", "TITLE": "Interesting model and analysis", "comments": "This paper proposes a simple way to reweight the word embedding in the simple composition function for sentence representation. This paper also shows the connection between this new weighting scheme and some previous work.\n\nHere are some comments on technical details:\n\n- The word \"discourse\" is confusing. I am not sure whether the words \"discourse\" in \"discourse vector c_s\" and the one in \"most frequent discourse\" have the same meaning.\n- Is there any justification about $c_0$ related to syntac?\n- Not sure what thie line means: \"In fact the new model was discovered by our detecting the common component c0 in existing embeddings.\" in section \"Computing the sentence embedding\"\n- Is there any explanation about the results on sentiment in Table 2?", "SOUNDNESS_CORRECTNESS": 4, "ORIGINALITY": 4, "IS_ANNOTATED": true, "IS_META_REVIEW": false, "RECOMMENDATION": 7, "DATE": "19 Dec 2016", "CLARITY": 5, "REVIEWER_CONFIDENCE": 4}, {"TITLE": "Accept", "RECOMMENDATION_UNOFFICIAL": 3, "OTHER_KEYS": "ICLR 2017 conference AnonReviewer2", "comments": "This paper presents a new theoretically-principled method of representing sentences as vectors. The experiments show that vectors produced by this method perform well on similarity and entailment benchmarks, surpassing some RNN-based methods too.\n\nOverall, this is an interesting empirical result, especially since the model is not order-sensitive (as far as I can tell). I would like to see some more discussion on why such a simple model does better than LSTMs at capturing similarity and entailment. Could this be an artifact of these benchmarks?", "IS_ANNOTATED": true, "IS_META_REVIEW": false, "RECOMMENDATION": 8, "DATE": "14 Dec 2016", "CLARITY": 4, "REVIEWER_CONFIDENCE": 3}, {"TITLE": "Performance on the SNLI dataset", "OTHER_KEYS": "ICLR 2017 conference AnonReviewer2", "RECOMMENDATION_UNOFFICIAL": 3, "comments": "", "IS_ANNOTATED": true, "IS_META_REVIEW": false, "DATE": "02 Dec 2016", "CLARITY": 4}, {"OTHER_KEYS": "ICLR 2017 conference AnonReviewer1", "TITLE": "Experimental setup", "comments": "", "SOUNDNESS_CORRECTNESS": 4, "ORIGINALITY": 4, "IS_ANNOTATED": true, "IS_META_REVIEW": false, "DATE": "02 Dec 2016", "CLARITY": 5}, {"SUBSTANCE": 4, "OTHER_KEYS": "ICLR 2017 conference AnonReviewer3", "TITLE": "Comparison", "comments": "", "SOUNDNESS_CORRECTNESS": 3, "IS_ANNOTATED": true, "IS_META_REVIEW": false, "DATE": "02 Dec 2016"}, {"DATE": "17 Nov 2016", "TITLE": "a simpler baseline?", "IS_META_REVIEW": false, "comments": "We (J. Mu and P. Viswanath) thoroughly enjoyed the authors' previous work on linear algebraic structure of word senses (cf. ", "OTHER_KEYS": "Jiaqi Mu"}, {"DATE": "07 Nov 2016", "TITLE": "ICLR Paper Format", "IS_META_REVIEW": false, "comments": "Dear Authors,\n\nPlease resubmit your paper in the ICLR 2017 format with the correct font for your submission to be considered. Thank you!", "OTHER_KEYS": "Tara N Sainath"}, {"IS_META_REVIEW": true, "comments": "This paper presents a new theoretically-principled method of representing sentences as vectors. The experiments show that vectors produced by this method perform well on similarity and entailment benchmarks, surpassing some RNN-based methods too.\n\nOverall, this is an interesting empirical result, especially since the model is not order-sensitive (as far as I can tell). I would like to see some more discussion on why such a simple model does better than LSTMs at capturing similarity and entailment. Could this be an artifact of these benchmarks?"}, {"DATE": "06 Feb 2017", "TITLE": "ICLR committee final decision", "IS_META_REVIEW": false, "comments": "A new method for sentence embedding that is simple and performs well. Important contribution that will attract attention and help move the field forward.", "OTHER_KEYS": "ICLR 2017 pcs"}, {"SUBSTANCE": 4, "OTHER_KEYS": "ICLR 2017 conference AnonReviewer3", "TITLE": "Accept", "comments": "This is a good paper with an interesting probabilistic motivation for weighted bag of words models.\nThe (hopefully soon) added comparison to Wang and Manning will make it stronger. \nThough it is sad that for sufficiently large datasets, NB-SVM still works better.\n\nIn the second to last paragraph of the introduction you describe a problem of large cooccurrence counts which was already fixed by the Glove embeddings with their weighting function f.\n\nMinor comments:\n\n\"The capturing the similarities\" -- typo in line 2 of intro.\n\"Recently, (Wieting et al.,2016) learned\" -- use citet instead of parenthesized citation\n ", "SOUNDNESS_CORRECTNESS": 3, "IS_ANNOTATED": true, "IS_META_REVIEW": false, "RECOMMENDATION": 7, "DATE": "22 Dec 2016", "REVIEWER_CONFIDENCE": 4}, {"OTHER_KEYS": "ICLR 2017 conference AnonReviewer1", "TITLE": "Interesting model and analysis", "comments": "This paper proposes a simple way to reweight the word embedding in the simple composition function for sentence representation. This paper also shows the connection between this new weighting scheme and some previous work.\n\nHere are some comments on technical details:\n\n- The word \"discourse\" is confusing. I am not sure whether the words \"discourse\" in \"discourse vector c_s\" and the one in \"most frequent discourse\" have the same meaning.\n- Is there any justification about $c_0$ related to syntac?\n- Not sure what thie line means: \"In fact the new model was discovered by our detecting the common component c0 in existing embeddings.\" in section \"Computing the sentence embedding\"\n- Is there any explanation about the results on sentiment in Table 2?", "SOUNDNESS_CORRECTNESS": 4, "ORIGINALITY": 4, "IS_ANNOTATED": true, "IS_META_REVIEW": false, "RECOMMENDATION": 7, "DATE": "19 Dec 2016", "CLARITY": 5, "REVIEWER_CONFIDENCE": 4}, {"TITLE": "Accept", "RECOMMENDATION_UNOFFICIAL": 3, "OTHER_KEYS": "ICLR 2017 conference AnonReviewer2", "comments": "This paper presents a new theoretically-principled method of representing sentences as vectors. The experiments show that vectors produced by this method perform well on similarity and entailment benchmarks, surpassing some RNN-based methods too.\n\nOverall, this is an interesting empirical result, especially since the model is not order-sensitive (as far as I can tell). I would like to see some more discussion on why such a simple model does better than LSTMs at capturing similarity and entailment. Could this be an artifact of these benchmarks?", "IS_ANNOTATED": true, "IS_META_REVIEW": false, "RECOMMENDATION": 8, "DATE": "14 Dec 2016", "CLARITY": 4, "REVIEWER_CONFIDENCE": 3}, {"TITLE": "Performance on the SNLI dataset", "OTHER_KEYS": "ICLR 2017 conference AnonReviewer2", "RECOMMENDATION_UNOFFICIAL": 3, "comments": "", "IS_ANNOTATED": true, "IS_META_REVIEW": false, "DATE": "02 Dec 2016", "CLARITY": 4}, {"OTHER_KEYS": "ICLR 2017 conference AnonReviewer1", "TITLE": "Experimental setup", "comments": "", "SOUNDNESS_CORRECTNESS": 4, "ORIGINALITY": 4, "IS_ANNOTATED": true, "IS_META_REVIEW": false, "DATE": "02 Dec 2016", "CLARITY": 5}, {"SUBSTANCE": 4, "OTHER_KEYS": "ICLR 2017 conference AnonReviewer3", "TITLE": "Comparison", "comments": "", "SOUNDNESS_CORRECTNESS": 3, "IS_ANNOTATED": true, "IS_META_REVIEW": false, "DATE": "02 Dec 2016"}, {"DATE": "17 Nov 2016", "TITLE": "a simpler baseline?", "IS_META_REVIEW": false, "comments": "We (J. Mu and P. Viswanath) thoroughly enjoyed the authors' previous work on linear algebraic structure of word senses (cf. ", "OTHER_KEYS": "Jiaqi Mu"}, {"DATE": "07 Nov 2016", "TITLE": "ICLR Paper Format", "IS_META_REVIEW": false, "comments": "Dear Authors,\n\nPlease resubmit your paper in the ICLR 2017 format with the correct font for your submission to be considered. Thank you!", "OTHER_KEYS": "Tara N Sainath"}], "authors": "Sanjeev Arora, Yingyu Liang, Tengyu Ma", "accepted": true, "id": "375"}