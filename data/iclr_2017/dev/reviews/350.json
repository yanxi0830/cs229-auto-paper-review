{"conference": "ICLR 2017 conference submission", "title": "Deep Predictive Coding Networks for Video Prediction and Unsupervised Learning", "abstract": "While great strides have been made in using deep learning algorithms to solve supervised learning tasks, the problem of unsupervised learning - leveraging unlabeled examples to learn about the structure of a domain - remains a difficult unsolved challenge. Here, we explore prediction of future frames in a video sequence as an unsupervised learning rule for learning about the structure of the visual world. We describe a predictive neural network (\"PredNet\") architecture that is inspired by the concept of \"predictive coding\" from the neuroscience literature. These networks learn to predict future frames in a video sequence, with each layer in the network making local predictions and only forwarding deviations from those predictions to subsequent network layers. We show that these networks are able to robustly learn to predict the movement of synthetic (rendered) objects, and that in doing so, the networks learn  internal representations that are useful for decoding latent object parameters (e.g. pose) that support object recognition with fewer training views. We also show that these networks can scale to complex natural image streams (car-mounted camera videos), capturing key aspects of both egocentric movement and the movement of objects in the visual scene, and the representation learned in this setting is useful for estimating the steering angle. These results suggest that prediction represents a powerful framework for unsupervised learning, allowing for implicit learning of object and scene structure.", "histories": [], "reviews": [{"IS_META_REVIEW": true, "comments": "Paper Summary\nThis paper proposes an unsupervised learning model in which the network\npredicts what its state would look like at the next time step (at input layer\nand potentially other layers).  When these states are observed, an error signal\nis computed by comparing the predictions and the observations. This error\nsignal is fed back into the model. The authors show that this model is able to\nmake good predictions on a toy dataset of rotating 3D faces as well as on\nnatural videos. They also show that these features help perform supervised\ntasks.\n\nStrengths\n- The model is an interesting embodiment of the idea of predictive coding\n  implemented using a end-to-end backpropable recurrent neural network architecture.\n- The idea of feeding forward an error signal is perhaps not used as widely as it could\n  be, and this work shows a compelling example of using it. \n- Strong empirical results and relevant comparisons show that the model works well.\n- The authors present a detailed ablative analysis of the proposed model.\n\nWeaknesses\n- The model (esp. in Fig 1) is presented as a generalized predictive model\n  where next step predictions are made at each layer. However, as discovered by\nrunning the experiments, only the predictions at the input layer are the ones\nthat actually matter and the optimal choice seems to be to turn off the error\nsignal from the higher layers. While the authors intend to address this in future\nwork, I think this point merits some more discussion in the current work, given\nthe way this model is presented.\n- The network currently lacks stochasticity and does not model the future as a\n  multimodal distribution (However, this is mentioned as potential future work).\n\nQuality\nThe experiments are well-designed and a detailed analysis is provided\nin the appendix.\n\nClarity\nThe paper is well-written and easy to follow.\n\nOriginality\nSome deep models have previously been proposed that use predictive coding.\nHowever, the proposed model is most probably novel in the way it feds back the\nerror signal and implements the entire model as a single differentiable\nnetwork.\n\nSignificance\nThis paper will be of wide interest to the growing set of researchers working\nin unsupervised learning of time series. This helps draw attention to\npredictive coding as an important learning paradigm.\n\nOverall\nGood paper with detailed and well-designed experiments. The idea of feeding\nforward the error signal is not being used as much as it could be in our\ncommunity. This work helps to draw the community's attention to this idea."}, {"DATE": "06 Feb 2017", "TITLE": "ICLR committee final decision", "IS_META_REVIEW": false, "comments": "This paper proposes an interesting architecture for predicting future frames of videos using end-to-end trained deep predictive coding.\n  The architecture is well presented and the paper is clearly written. The experiments are extensive and convincing, include ablation analyses, and show that this architecture performs well compared to other current methods.\n Overall, this is an interesting, solid contribution.", "OTHER_KEYS": "ICLR 2017 pcs"}, {"TITLE": "an interesting architecture for future prediction inspired by deep predictive coding", "MEANINGFUL_COMPARISON": 5, "OTHER_KEYS": "ICLR 2017 conference AnonReviewer1", "comments": "An interesting architecture that accumulates and continuously corrects mistakes as you see more and more of a video sequence.\n\nClarity: The video you generated seems very helpful towards understanding the information flow in your network, it would be nice to link to it from the paper.\n\n \"Our model with hyperparameters optimized for KITTI underperforms the model of Finn et al. (2016), but outperforms the previous state-of-the-art model by Mathieu et al. (2016).\"\n\n It is not clear how different are the train and test sequences at the moment, since standard benchmarks do not really exist for video prediction and each author picks his/her favorite. Underperforming Finn et al 206 at the H3.6m Walking videos is a bit disappointing.\n\n", "ORIGINALITY": 4, "IS_ANNOTATED": true, "IS_META_REVIEW": false, "RECOMMENDATION": 6, "DATE": "19 Dec 2016", "REVIEWER_CONFIDENCE": 3}, {"OTHER_KEYS": "ICLR 2017 conference AnonReviewer2", "TITLE": "Review", "comments": "Learning about the physical structure and semantics of the world from video (without supervision) is a very hot area in computer vision and machine learning.\nIn this paper, the authors investigate how the prediction of future image frames (inherently unsupervised) can help to deduce object/s structure and it's properties (in this case single object pose, category, and steering angle, (after a supervised linear readout step))\n\nI enjoyed reading this paper, it is clear, interesting and proposes an original network architecture (PredNet) for video frame prediction that has produced promising results on both synthetic and natural images.\nMoreover, the extensive experimental evaluation and analysis the authors provide puts it on solid ground to which others can compare.\n\nThe weaknesses:\n- the link to predictive coding should be better explained in the paper if it is to be used as a motivation for the prednet model.\n- any idea that the proposed method is learning an implicit `model' of the `objects' that make up the `scene' is vague and far fetched, but it sounds great.\n\nMinor comment:\nNext to the number of labeled training examples (Fig.5), it would be interesting to see how much unsupervised training data was used to train your representations.", "ORIGINALITY": 4, "IS_ANNOTATED": true, "IS_META_REVIEW": false, "RECOMMENDATION": 8, "DATE": "16 Dec 2016", "REVIEWER_CONFIDENCE": 4}, {"TITLE": "Good paper, nice example of using the idea of feeding forward error signals.", "MEANINGFUL_COMPARISON": 2, "OTHER_KEYS": "ICLR 2017 conference AnonReviewer3", "comments": "Paper Summary\nThis paper proposes an unsupervised learning model in which the network\npredicts what its state would look like at the next time step (at input layer\nand potentially other layers).  When these states are observed, an error signal\nis computed by comparing the predictions and the observations. This error\nsignal is fed back into the model. The authors show that this model is able to\nmake good predictions on a toy dataset of rotating 3D faces as well as on\nnatural videos. They also show that these features help perform supervised\ntasks.\n\nStrengths\n- The model is an interesting embodiment of the idea of predictive coding\n  implemented using a end-to-end backpropable recurrent neural network architecture.\n- The idea of feeding forward an error signal is perhaps not used as widely as it could\n  be, and this work shows a compelling example of using it. \n- Strong empirical results and relevant comparisons show that the model works well.\n- The authors present a detailed ablative analysis of the proposed model.\n\nWeaknesses\n- The model (esp. in Fig 1) is presented as a generalized predictive model\n  where next step predictions are made at each layer. However, as discovered by\nrunning the experiments, only the predictions at the input layer are the ones\nthat actually matter and the optimal choice seems to be to turn off the error\nsignal from the higher layers. While the authors intend to address this in future\nwork, I think this point merits some more discussion in the current work, given\nthe way this model is presented.\n- The network currently lacks stochasticity and does not model the future as a\n  multimodal distribution (However, this is mentioned as potential future work).\n\nQuality\nThe experiments are well-designed and a detailed analysis is provided\nin the appendix.\n\nClarity\nThe paper is well-written and easy to follow.\n\nOriginality\nSome deep models have previously been proposed that use predictive coding.\nHowever, the proposed model is most probably novel in the way it feds back the\nerror signal and implements the entire model as a single differentiable\nnetwork.\n\nSignificance\nThis paper will be of wide interest to the growing set of researchers working\nin unsupervised learning of time series. This helps draw attention to\npredictive coding as an important learning paradigm.\n\nOverall\nGood paper with detailed and well-designed experiments. The idea of feeding\nforward the error signal is not being used as much as it could be in our\ncommunity. This work helps to draw the community's attention to this idea.", "ORIGINALITY": 4, "IS_ANNOTATED": true, "IS_META_REVIEW": false, "RECOMMENDATION": 8, "DATE": "16 Dec 2016", "CLARITY": 5, "REVIEWER_CONFIDENCE": 5}, {"DATE": "13 Dec 2016", "TITLE": "Update for all reviewers and commenters", "IS_META_REVIEW": false, "comments": "In response to the helpful comments and questions, we have made several changes to the manuscript:\n\n1.  In our original manuscript, we primarily compared the PredNet to a CNN-LSTM Encoder-Decoder, which we chose because it serves as a tight control for the more novel elements of our architecture. However, we agree that it is useful to compare against other published architectures.  One reason that this isn\u2019t a trivial task is because a standard benchmark for next frame prediction arguably has yet to be established.  Another issue is that published models are often optimized for performance on particular datasets, so evaluating competing models on KITTI/CalTech isn\u2019t necessarily fair to those models.  Searching the very recent literature, we found that the most relevant comparison to make is probably against the DFN model by Brabandere et al. (2016), which was recently presented at NIPS and was developed concurrently with our work.  One of their experiments was on a 64x64 pixel, grayscale car-cam dataset.  Training our KITTI model on this dataset, we outperform their results by 29%.  To compare against another concurrently developed model, also published at NIPS 2016, we have additionally evaluated on the Human3.6M dataset (Ionescu et al., 2014).  Our model with hyperparameters optimized for KITTI underperforms the model of Finn et al. (2016), but outperforms the previous state-of-the-art model by Mathieu et al. (2016).  We have added all of these comparisons to the appendix.\n\n2.  To make the main text more clear and concise, and to properly explain all of the necessary details, we have moved portions of the steering angle analysis to the appendix.  Our main point has been to demonstrate that our model learns a representation of important underlying factors, using other models as points of reference, so we have emphasized this.\n\nAt the reviewer\u2019s suggestion, we have added a video clip to help illustrate the flow of information in the network: ", "OTHER_KEYS": "William Lotter"}, {"TITLE": "Model architecture - finetuning", "OTHER_KEYS": "ICLR 2017 conference AnonReviewer1", "MEANINGFUL_COMPARISON": 5, "comments": "", "ORIGINALITY": 4, "IS_ANNOTATED": true, "IS_META_REVIEW": false, "DATE": "08 Dec 2016"}, {"DATE": "02 Dec 2016", "TITLE": "Questions", "IS_META_REVIEW": false, "comments": "\nWhat's the difference between this work and \"Deep Predictive Coding Networks\" (ref [4]).\nPlease explain it clearly in the text.\n\nWhy not comparing the performance of prednet with the previous work of authors(ref[25])?\n\nThe improvement in MSE of prednet over previous frame prediction is 0.005. How significant is this?\nMaybe you could provide images showing the difference between images in t+1 and t, and between t+1 and your prediction.\nThis could reveal in which regions prednet does better than previous frame prediction. ", "OTHER_KEYS": "(anonymous)"}, {"TITLE": "Why loss at input layer only and other questions", "OTHER_KEYS": "ICLR 2017 conference AnonReviewer3", "MEANINGFUL_COMPARISON": 2, "comments": "", "ORIGINALITY": 4, "IS_ANNOTATED": true, "IS_META_REVIEW": false, "DATE": "02 Dec 2016", "CLARITY": 5}, {"TITLE": "Several questions!", "OTHER_KEYS": "ICLR 2017 conference AnonReviewer2", "comments": "", "ORIGINALITY": 4, "IS_ANNOTATED": true, "IS_META_REVIEW": false, "DATE": "24 Nov 2016"}, {"IS_META_REVIEW": true, "comments": "Paper Summary\nThis paper proposes an unsupervised learning model in which the network\npredicts what its state would look like at the next time step (at input layer\nand potentially other layers).  When these states are observed, an error signal\nis computed by comparing the predictions and the observations. This error\nsignal is fed back into the model. The authors show that this model is able to\nmake good predictions on a toy dataset of rotating 3D faces as well as on\nnatural videos. They also show that these features help perform supervised\ntasks.\n\nStrengths\n- The model is an interesting embodiment of the idea of predictive coding\n  implemented using a end-to-end backpropable recurrent neural network architecture.\n- The idea of feeding forward an error signal is perhaps not used as widely as it could\n  be, and this work shows a compelling example of using it. \n- Strong empirical results and relevant comparisons show that the model works well.\n- The authors present a detailed ablative analysis of the proposed model.\n\nWeaknesses\n- The model (esp. in Fig 1) is presented as a generalized predictive model\n  where next step predictions are made at each layer. However, as discovered by\nrunning the experiments, only the predictions at the input layer are the ones\nthat actually matter and the optimal choice seems to be to turn off the error\nsignal from the higher layers. While the authors intend to address this in future\nwork, I think this point merits some more discussion in the current work, given\nthe way this model is presented.\n- The network currently lacks stochasticity and does not model the future as a\n  multimodal distribution (However, this is mentioned as potential future work).\n\nQuality\nThe experiments are well-designed and a detailed analysis is provided\nin the appendix.\n\nClarity\nThe paper is well-written and easy to follow.\n\nOriginality\nSome deep models have previously been proposed that use predictive coding.\nHowever, the proposed model is most probably novel in the way it feds back the\nerror signal and implements the entire model as a single differentiable\nnetwork.\n\nSignificance\nThis paper will be of wide interest to the growing set of researchers working\nin unsupervised learning of time series. This helps draw attention to\npredictive coding as an important learning paradigm.\n\nOverall\nGood paper with detailed and well-designed experiments. The idea of feeding\nforward the error signal is not being used as much as it could be in our\ncommunity. This work helps to draw the community's attention to this idea."}, {"DATE": "06 Feb 2017", "TITLE": "ICLR committee final decision", "IS_META_REVIEW": false, "comments": "This paper proposes an interesting architecture for predicting future frames of videos using end-to-end trained deep predictive coding.\n  The architecture is well presented and the paper is clearly written. The experiments are extensive and convincing, include ablation analyses, and show that this architecture performs well compared to other current methods.\n Overall, this is an interesting, solid contribution.", "OTHER_KEYS": "ICLR 2017 pcs"}, {"TITLE": "an interesting architecture for future prediction inspired by deep predictive coding", "MEANINGFUL_COMPARISON": 5, "OTHER_KEYS": "ICLR 2017 conference AnonReviewer1", "comments": "An interesting architecture that accumulates and continuously corrects mistakes as you see more and more of a video sequence.\n\nClarity: The video you generated seems very helpful towards understanding the information flow in your network, it would be nice to link to it from the paper.\n\n \"Our model with hyperparameters optimized for KITTI underperforms the model of Finn et al. (2016), but outperforms the previous state-of-the-art model by Mathieu et al. (2016).\"\n\n It is not clear how different are the train and test sequences at the moment, since standard benchmarks do not really exist for video prediction and each author picks his/her favorite. Underperforming Finn et al 206 at the H3.6m Walking videos is a bit disappointing.\n\n", "ORIGINALITY": 4, "IS_ANNOTATED": true, "IS_META_REVIEW": false, "RECOMMENDATION": 6, "DATE": "19 Dec 2016", "REVIEWER_CONFIDENCE": 3}, {"OTHER_KEYS": "ICLR 2017 conference AnonReviewer2", "TITLE": "Review", "comments": "Learning about the physical structure and semantics of the world from video (without supervision) is a very hot area in computer vision and machine learning.\nIn this paper, the authors investigate how the prediction of future image frames (inherently unsupervised) can help to deduce object/s structure and it's properties (in this case single object pose, category, and steering angle, (after a supervised linear readout step))\n\nI enjoyed reading this paper, it is clear, interesting and proposes an original network architecture (PredNet) for video frame prediction that has produced promising results on both synthetic and natural images.\nMoreover, the extensive experimental evaluation and analysis the authors provide puts it on solid ground to which others can compare.\n\nThe weaknesses:\n- the link to predictive coding should be better explained in the paper if it is to be used as a motivation for the prednet model.\n- any idea that the proposed method is learning an implicit `model' of the `objects' that make up the `scene' is vague and far fetched, but it sounds great.\n\nMinor comment:\nNext to the number of labeled training examples (Fig.5), it would be interesting to see how much unsupervised training data was used to train your representations.", "ORIGINALITY": 4, "IS_ANNOTATED": true, "IS_META_REVIEW": false, "RECOMMENDATION": 8, "DATE": "16 Dec 2016", "REVIEWER_CONFIDENCE": 4}, {"TITLE": "Good paper, nice example of using the idea of feeding forward error signals.", "MEANINGFUL_COMPARISON": 2, "OTHER_KEYS": "ICLR 2017 conference AnonReviewer3", "comments": "Paper Summary\nThis paper proposes an unsupervised learning model in which the network\npredicts what its state would look like at the next time step (at input layer\nand potentially other layers).  When these states are observed, an error signal\nis computed by comparing the predictions and the observations. This error\nsignal is fed back into the model. The authors show that this model is able to\nmake good predictions on a toy dataset of rotating 3D faces as well as on\nnatural videos. They also show that these features help perform supervised\ntasks.\n\nStrengths\n- The model is an interesting embodiment of the idea of predictive coding\n  implemented using a end-to-end backpropable recurrent neural network architecture.\n- The idea of feeding forward an error signal is perhaps not used as widely as it could\n  be, and this work shows a compelling example of using it. \n- Strong empirical results and relevant comparisons show that the model works well.\n- The authors present a detailed ablative analysis of the proposed model.\n\nWeaknesses\n- The model (esp. in Fig 1) is presented as a generalized predictive model\n  where next step predictions are made at each layer. However, as discovered by\nrunning the experiments, only the predictions at the input layer are the ones\nthat actually matter and the optimal choice seems to be to turn off the error\nsignal from the higher layers. While the authors intend to address this in future\nwork, I think this point merits some more discussion in the current work, given\nthe way this model is presented.\n- The network currently lacks stochasticity and does not model the future as a\n  multimodal distribution (However, this is mentioned as potential future work).\n\nQuality\nThe experiments are well-designed and a detailed analysis is provided\nin the appendix.\n\nClarity\nThe paper is well-written and easy to follow.\n\nOriginality\nSome deep models have previously been proposed that use predictive coding.\nHowever, the proposed model is most probably novel in the way it feds back the\nerror signal and implements the entire model as a single differentiable\nnetwork.\n\nSignificance\nThis paper will be of wide interest to the growing set of researchers working\nin unsupervised learning of time series. This helps draw attention to\npredictive coding as an important learning paradigm.\n\nOverall\nGood paper with detailed and well-designed experiments. The idea of feeding\nforward the error signal is not being used as much as it could be in our\ncommunity. This work helps to draw the community's attention to this idea.", "ORIGINALITY": 4, "IS_ANNOTATED": true, "IS_META_REVIEW": false, "RECOMMENDATION": 8, "DATE": "16 Dec 2016", "CLARITY": 5, "REVIEWER_CONFIDENCE": 5}, {"DATE": "13 Dec 2016", "TITLE": "Update for all reviewers and commenters", "IS_META_REVIEW": false, "comments": "In response to the helpful comments and questions, we have made several changes to the manuscript:\n\n1.  In our original manuscript, we primarily compared the PredNet to a CNN-LSTM Encoder-Decoder, which we chose because it serves as a tight control for the more novel elements of our architecture. However, we agree that it is useful to compare against other published architectures.  One reason that this isn\u2019t a trivial task is because a standard benchmark for next frame prediction arguably has yet to be established.  Another issue is that published models are often optimized for performance on particular datasets, so evaluating competing models on KITTI/CalTech isn\u2019t necessarily fair to those models.  Searching the very recent literature, we found that the most relevant comparison to make is probably against the DFN model by Brabandere et al. (2016), which was recently presented at NIPS and was developed concurrently with our work.  One of their experiments was on a 64x64 pixel, grayscale car-cam dataset.  Training our KITTI model on this dataset, we outperform their results by 29%.  To compare against another concurrently developed model, also published at NIPS 2016, we have additionally evaluated on the Human3.6M dataset (Ionescu et al., 2014).  Our model with hyperparameters optimized for KITTI underperforms the model of Finn et al. (2016), but outperforms the previous state-of-the-art model by Mathieu et al. (2016).  We have added all of these comparisons to the appendix.\n\n2.  To make the main text more clear and concise, and to properly explain all of the necessary details, we have moved portions of the steering angle analysis to the appendix.  Our main point has been to demonstrate that our model learns a representation of important underlying factors, using other models as points of reference, so we have emphasized this.\n\nAt the reviewer\u2019s suggestion, we have added a video clip to help illustrate the flow of information in the network: ", "OTHER_KEYS": "William Lotter"}, {"TITLE": "Model architecture - finetuning", "OTHER_KEYS": "ICLR 2017 conference AnonReviewer1", "MEANINGFUL_COMPARISON": 5, "comments": "", "ORIGINALITY": 4, "IS_ANNOTATED": true, "IS_META_REVIEW": false, "DATE": "08 Dec 2016"}, {"DATE": "02 Dec 2016", "TITLE": "Questions", "IS_META_REVIEW": false, "comments": "\nWhat's the difference between this work and \"Deep Predictive Coding Networks\" (ref [4]).\nPlease explain it clearly in the text.\n\nWhy not comparing the performance of prednet with the previous work of authors(ref[25])?\n\nThe improvement in MSE of prednet over previous frame prediction is 0.005. How significant is this?\nMaybe you could provide images showing the difference between images in t+1 and t, and between t+1 and your prediction.\nThis could reveal in which regions prednet does better than previous frame prediction. ", "OTHER_KEYS": "(anonymous)"}, {"TITLE": "Why loss at input layer only and other questions", "OTHER_KEYS": "ICLR 2017 conference AnonReviewer3", "MEANINGFUL_COMPARISON": 2, "comments": "", "ORIGINALITY": 4, "IS_ANNOTATED": true, "IS_META_REVIEW": false, "DATE": "02 Dec 2016", "CLARITY": 5}, {"TITLE": "Several questions!", "OTHER_KEYS": "ICLR 2017 conference AnonReviewer2", "comments": "", "ORIGINALITY": 4, "IS_ANNOTATED": true, "IS_META_REVIEW": false, "DATE": "24 Nov 2016"}], "authors": "William Lotter, Gabriel Kreiman, David Cox", "accepted": true, "id": "350"}