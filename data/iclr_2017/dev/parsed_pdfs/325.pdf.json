{
  "name" : "325.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : null,
    "authors" : [ "INFUSION TRAINING", "Florian Bordes", "Sina Honari", "Pascal Vincent" ],
    "emails" : [ "{firstname.lastname@umontreal.ca}" ],
    "sections" : [ {
      "heading" : "1 INTRODUCTION AND MOTIVATION",
      "text" : "To go beyond the relatively simpler tasks of classification and regression, advancing our ability to learn good generative models of high-dimensional data appears essential. There are many scenarios where one needs to efficiently produce good high-dimensional outputs where output dimensions have unknown intricate statistical dependencies: from generating realistic images, segmentations, text, speech, keypoint or joint positions, etc..., possibly as an answer to the same, other, or multiple input modalities. These are typically cases where there is not just one right answer but a variety of equally valid ones following a non-trivial and unknown distribution. A fundamental ingredient for such scenarios is thus the ability to learn a good generative model from data, one from which we can subsequently efficiently generate varied samples of high quality.\nMany approaches for learning to generate high dimensional samples have been and are still actively being investigated. These approaches can be roughly classified under the following broad categories:\n• Ordered visible dimension sampling (van den Oord et al., 2016; Larochelle & Murray, 2011). In this type of auto-regressive approach, output dimensions (or groups of conditionally independent dimensions) are given an arbitrary fixed ordering, and each is sampled conditionally on the previous sampled ones. This strategy is often implemented using a recurrent network (LSTM or GRU). Desirable properties of this type of strategy are that the exact log likelihood can usually be computed tractably, and sampling is exact. Undesirable properties follow from the forced ordering, whose arbitrariness feels unsatisfactory especially for domains that do not have a natural ordering (e.g. images), and imposes for high-dimensional output a long sequential generation that can be slow. • Undirected graphical models with multiple layers of latent variables. These make inference, and thus learning, particularly hard and tend to be costly to sample from (Salakhutdinov & Hinton, 2009). • Directed graphical models trained as variational autoencoders (VAE) (Kingma & Welling, 2014; Rezende et al., 2014)\n∗Associate Fellow, Canadian Institute For Advanced Research (CIFAR)\n• Adversarially-trained generative networks. (GAN)(Goodfellow et al., 2014) • Stochastic neural networks, i.e. networks with stochastic neurons, trained by an adapted\nform of stochastic backpropagation • Generative uses of denoising autoencoders (Vincent et al., 2010) and their generalization\nas Generative Stochastic Networks (Alain et al., 2016) • Inverting a non-equilibrium thermodynamic slow diffusion process (Sohl-Dickstein et al.,\n2015) • Continuous transformation of a distribution by invertible functions (Dinh et al. (2014), also\nused for variational inference in Rezende & Mohamed (2015))\nSeveral of these approaches are based on maximizing an explicit or implicit model log-likelihood or a lower bound of its log-likelihood, but some successful ones are not e.g. GANs. The approach we propose here is based on the notion of “denoising” and thus takes its root in denoising autoencoders and the GSN type of approaches. It is also highly related to the non-equilibrium thermodynamics inverse diffusion approach of Sohl-Dickstein et al. (2015). One key aspect that distinguishes these types of methods from others listed above is that sample generation is achieved thanks to a learned stochastic mapping from input space to input space, rather than from a latent-space to input-space.\nSpecifically, in the present work, we propose to learn to generate high quality samples through a process of progressive, stochastic, denoising, starting from a simple initial “noise” sample generated in input space from a simple factorial distribution i.e. one that does not take into account any dependency or structure between dimensions. This, in effect, amounts to learning the transition operator of a Markov chain operating on input space. Starting from such an initial “noise” input, and repeatedly applying the operator for a small fixed number T of steps, we aim to obtain a high quality resulting sample, effectively modeling the training data distribution. Our training procedure uses a novel “target-infusion” technique, designed to slightly bias model sampling to move towards a specific data point during training, and thus provide inputs to denoise which are likely under the model’s sample generation paths. By contrast with Sohl-Dickstein et al. (2015) which consists in inverting a slow and fixed diffusion process, our infusion chains make a few large jumps and follow the model distribution as the learning progresses.\nThe rest of this paper is structured as follows: Section 2 formally defines the model and training procedure. Section 3 discusses and contrasts our approach with the most related methods from the literature. Section 4 presents experiments that validate the approach. Section 5 concludes and proposes future work directions."
    }, {
      "heading" : "2 PROPOSED APPROACH",
      "text" : ""
    }, {
      "heading" : "2.1 SETUP",
      "text" : "We are given a finite data set D containing n points in Rd, supposed drawn i.i.d from an unknown distribution q∗. The data set D is supposed split into training, validation and test subsets Dtrain, Dvalid, Dtest. We will denote q∗train the empirical distribution associated to the training set, and use x to denote observed samples from the data set. We are interested in learning the parameters of a generative model p conceived as a Markov Chain from which we can efficiently sample. Note that we are interested in learning an operator that will display fast “burn-in” from the initial factorial “noise” distribution, but beyond the initial T steps we are not concerned about potential slow mixing or being stuck. We will first describe the sampling procedure used to sample from a trained model, before explaining our training procedure."
    }, {
      "heading" : "2.2 GENERATIVE MODEL SAMPLING PROCEDURE",
      "text" : "The generative model p is defined as the following sampling procedure:\n• Using a simple factorial distribution p(0)(z(0)), draw an initial sample z(0) ∼ p(0), where z(0) ∈ Rd. Since p(0) is factorial, the d components of z(0) are independent: p0 cannot model any dependency structure. z(0) can be pictured as essentially unstructured random noise. • Repeatedly apply T times a stochastic transition operator p(t)(z(t)|z(t−1)), yielding a more “denoised” sample z(t) ∼ p(t)(z(t)|z(t−1)), where all z(t) ∈ Rd.\n• Output z(T ) as the final generated sample. Our generative model distribution is thus p(z(T )), the marginal associated to joint p(z(0), . . . , z(T )) = p(0)(z(0)) (∏T t=1 p (t)(z(t)|z(t−1)) ) .\nIn summary, samples from model p are generated, starting with an initial sample from a simple distribution p(0), by taking the T thsample along Markov chain z(0) → z(1) → z(2) → . . . → z(T ) whose transition operator is p(t)(z(t)|z(t−1)). We will call this chain the model sampling chain. Figure 1 illustrates this sampling procedure using a model (i.e. transition operator) that was trained on MNIST. Note that we impose no formal requirement that the chain converges to a stationary distribution, as we simply read-out z(T ) as the samples from our model p. The chain also needs not be time-homogeneous, as highlighted by notation p(t) for the transitions.\nThe set of parameters θ of model p comprise the parameters of p(0) and the parameters of transition operator p(t)(z(t)|z(t−1)). For tractability, learnability, and efficient sampling, these distributions will be chosen factorial, i.e. p(0)(z(0)) = ∏d i=1 p (0) i (z (0) i ) and p\n(t)(z(t)|z(t−1)) =∏d i=1 p (t) i (z (t) i |z(t−1)). Note that the conditional distribution of an individual component i, p (t) i (z (t) i |z(t−1)) may however be multimodal, e.g. a mixture in which case p(t)(z(t)|z(t−1)) would be a product of independent mixtures (conditioned on z(t−1)), one per dimension. In our experiments, we will take the p(t)(z(t)|z(t−1)) to be simple diagonal Gaussian yielding a Deep Latent Gaussian Model (DLGM) as in Rezende et al. (2014)."
    }, {
      "heading" : "2.3 INFUSION TRAINING PROCEDURE",
      "text" : "We want to train the parameters of model p such that samples from Dtrain are likely of being generated under the model sampling chain. Let θ(0) be the parameters of p(0) and let θ(t) be the parameters of p(t)(z(t)|z(t−1)). Note that parameters θ(t) for t > 0 can straightforwardly be shared across time steps, which we will be doing in practice. Having committed to using (conditionally) factorial distributions for our p(0)(z(0)) and p(t)(z(t)|z(t−1)), that are both easy to learn and cheap to sample from, let us first consider the following greedy stagewise procedure. We can easily learn p(0)i (z\n(0)) to model the marginal distribution of each component xi of the input, by training it by gradient descent on a maximum likelihood objective, i.e.\nθ(0) = argmax θ Ex∼q∗train [ log p(0)(x; θ) ] (1)\nThis gives us a first, very crude unstructured (factorial) model of q∗.\nHaving learned this p(0), we might be tempted to then greedily learn the next stage p(1) of the chain in a similar fashion, after drawing samples z(0) ∼ p(0) in an attempt to learn to “denoise” the sampled z(0) into x. Yet the corresponding following training objective θ(1) = argmaxθ Ex∼q∗train,z(0)∼p(0) [ log p(1)(x|z(0); θ) ] makes no sense: x and z(0) are sampled independently of each other so z(0) contains no information about x, hence p(1)(x|z(0)) = p(1)(x). So maximizing this second objective becomes essentially the same as what we did when learning p(0). We would learn nothing more. It is essential, if we hope to learn a useful conditional distribution p(1)(x|z(0)) that it be trained on particular z(0) containing some information about x. In other words, we should not take our training inputs to be samples from p(0) but from a slightly different distribution, biased towards containing some information about x. Let us call it q(0)(z(0)|x). A natural choice for it, if it were possible, would be to take q(0)(z(0)|x) = p(z(0)|z(T ) = x) but this is an intractable inference, as all intermediate z(t) between z(0) and z(T ) are effectively latent states that we would need to marginalize over. Using a workaround such as a variational or MCMC approach would be a usual fallback. Instead, let us focus on our initial intent of guiding a progressive stochastic denoising, and think if we can come up with a different way to construct q(0)(z(0)|x) and similarly for the next steps q(t)i (z̃ (t) i |z̃(t−1),x).\nEventually, we expect a sequence of samples from Markov chain p to move from initial “noise” towards a specific example x from the training set rather than another one, primarily if a sample along the chain “resembles” x to some degree. This means that the transition operator should learn to pick up a minor resemblance with an x in order to transition to something likely to be even more similar to x. In other words, we expect samples along a chain leading to x to both have high probability under the transition operator of the chain p(t)(z(t)|z(t−1)), and to have some form of at least partial “resemblance” with x likely to increase as we progress along the chain. One highly inefficient way to emulate such a chain of samples would be, for teach step t, to sample many candidate samples from the transition operator (a conditionally factorial distribution) until we generate one that has some minimal “resemblance” to x (e.g. for a discrete space, this resemblance measure could be based on their Hamming distance). A qualitatively similar result can be obtained at a negligible cost by sampling from a factorial distribution that is very close to the one given by the transition operator, but very slightly biased towards producing something closer to x. Specifically, we can “infuse” a little of x into our sample by choosing for each input dimension, whether we sample it from the distribution given for that dimension by the transition operator, or whether, with a small probability, we take the value of that dimension from x. Samples from this biased chain, in which we slightly “infuse” x, will provide us with the inputs of our input-target training pairs for the transition operator. The target part of the training pairs is simply x."
    }, {
      "heading" : "2.3.1 THE INFUSION CHAIN",
      "text" : "Formally we define an infusion chain z̃(0) → z̃(1) → . . . → z̃(T−1) whose distribution q(z̃(0), . . . , z̃(T−1)|x) will be “close” to the sampling chain z(0) → z(1) → z(2) → . . . → z(T−1) of model p in the sense that q(t)(z̃(t)|z̃(t−1),x) will be close to p(t)(z(t)|z(t−1)), but will at every step be slightly biased towards generating samples closer to target x, i.e. x gets progressively “infused” into the chain. This is achieved by defining q(0)i (z̃ (0) i |x) as a mixture between p (0) i (with a large mixture weight) and δxi , a concentrated unimodal distribution around xi, such as a Gaussian with small variance (with a small mixture weight)1. Formally q(0)i (z̃ (0) i |x) = (1 − α(t))p(0)i (z̃ (0) i ) + α (t)δxi(z̃ (0) i ), where 1 − α(t) and α(t) are the mixture weights 2. In other words, when sampling a value for z̃(0)i from q (0) i there will be a small probability α (0) to pick value close to xi (as sampled from δxi ) rather than sampling the value from p (0) i . We call α(t) the infusion rate. We define the transition operator of the infusion chain similarly as: q (t) i (z̃ (t) i |z̃(t−1),x) = (1− α(t))p (t) i (z̃ (t) i |z̃(t−1)) + α(t)δxi(z̃ (t) i ).\n1Note that δxi does not denote a Dirac-Delta but a Gaussian with small sigma. 2In all experiments, we use an increasing schedule α(t) = α (t−1) +ω with α (0)\nand ω constant. This allows to build our chain such that in the first steps, we give little information about the target and in the last steps we give more informations about the target. This forces the network to have less confidence (greater incertitude) at the beginning of the chain and more confidence on the convergence point at the end of the chain."
    }, {
      "heading" : "2.3.2 DENOISING-BASED INFUSION TRAINING PROCEDURE",
      "text" : "For all x ∈ Dtrain: • Sample from the infusion chain z̃ = (z̃(0), . . . , z̃(T−1)) ∼ q(z̃(0), . . . , z̃(T−1)|x).\nprecisely so: z̃0 ∼ q(0)(z̃(0)|x) . . . z̃(t) ∼ q(t)(z̃(t)|z̃(t−1),x) . . . • Perform a gradient step so that p learns to “denoise” every z̃(t) into x.\nθ(t) ← θ(t) + η(t) ∂ log p (t)(x|z̃(t−1); θ(t)) ∂θ(t)\nwhere η(t) is a scalar learning rate. 3\nAs illustrated in Figure 2, the distribution of samples from the infusion chain evolves as training progresses, since this chain remains close to the model sampling chain."
    }, {
      "heading" : "2.4 STOCHASTIC LOG LIKELIHOOD ESTIMATION",
      "text" : "The exact log-likelihood of the generative model implied by our model p is intractable. The logprobability of an example x can however be expressed using proposal distribution q as:\nlog p(x) = logEq(z̃|x) [ p(z̃,x)\nq(z̃|x)\n] (2)\nUsing Jensen’s inequality we can thus derive the following lower bound:\nlog p(x) ≥ Eq(z̃|x) [log p(z̃,x)− log q(z̃|x)] (3)\nwhere log p(z̃,x) = log p(0)(z̃(0)) + (∑T−1\nt=1 log p (t)(z̃(t)|z̃(t−1))\n) + log p(T )(x|z̃(T−1)) and\nlog q(z̃|x) = log q(0)(z̃(0)|x) + ∑T−1 t=1 log q\n(t)(z̃(t)|z̃(t−1),x). 3Since we will be sharing parameters between the p(t), in order for the expected larger error gradients on the earlier transitions not to dominate the parameter updates over the later transitions we used an increasing schedule η(t) = η0 tT for t ∈ {1, . . . , T}.\nA stochastic estimation can easily be obtained by replacing the expectation by an average using a few samples from q(z̃|x). We can thus compute a lower bound estimate of the average log likelihood over training, validation and test data.\nSimilarly in addition to the lower-bound based on Eq.3 we can use the same few samples from q(z̃|x) to get an importance-sampling estimate of the likelihood based on Eq. 24."
    }, {
      "heading" : "2.4.1 LOWER-BOUND-BASED INFUSION TRAINING PROCEDURE",
      "text" : "Since we have derived a lower bound on the likelihood, we can alternatively choose to optimize this stochastic lower-bound directly during training. This alternative lower-bound based infusion training procedure differs only slightly from the denoising-based infusion training procedure by using z̃(t) as a training target at step t (performing a gradient step to increase log p(t)(z̃(t)|z̃(t−1); θ(t))) whereas denoising training always uses x as its target (performing a gradient step to increase log p(t)(x|z̃(t−1); θ(t))). Note that the same reparametrization trick as used in Variational Autoencoders (Kingma & Welling, 2014) can be used here to backpropagate through the chain’s Gaussian sampling."
    }, {
      "heading" : "3 RELATIONSHIP TO PREVIOUSLY PROPOSED APPROACHES",
      "text" : ""
    }, {
      "heading" : "3.1 MARKOV CHAIN MONTE CARLO FOR ENERGY-BASED MODELS",
      "text" : "Generating samples as a repeated application of a Markov transition operator that operates on input space is at the heart of Markov Chain Monte Carlo (MCMC) methods. They allow sampling from an energy-model, where one can efficiently compute the energy or unnormalized negated log probability (or density) at any point. The transition operator is then derived from an explicit energy function such that the Markov chain prescribed by a specific MCMC method is guaranteed to converge to the distribution defined by that energy function, as the equilibrium distribution of the chain. MCMC techniques have thus been used to obtain samples from the energy model, in the process of learning to adjust its parameters.\nBy contrast here we do not learn an explicit energy function, but rather learn directly a parameterized transition operator, and define an implicit model distribution based on the result of running the Markov chain."
    }, {
      "heading" : "3.2 VARIATIONAL AUTO-ENCODERS",
      "text" : "Variational auto-encoders (VAE) (Kingma & Welling, 2014; Rezende et al., 2014) also start from an unstructured (independent) noise sample and non-linearly transform this into a distribution that matches the training data. One difference with our approach is that the VAE typically maps from a lower-dimensional space to the observation space. By contrast we learn a stochastic transition operator from input space to input space that we repeat for T steps. Another key difference, is that the VAE learns a complex heavily parameterized approximate posterior proposal q whereas our infusion based q can be understood as a simple heuristic proposal distribution based on p. Importantly the specific heuristic we use to infuse x into q makes sense precisely because our operator is a map from input space to input space, and couldn’t be readily applied otherwise. The generative network in Rezende et al. (2014) is a Deep Latent Gaussian Model (DLGM) just as ours. But their approximate posterior q is taken to be factorial, including across all layers of the DLGM, whereas our infusion based q involves an ordered sampling of the layers, as we sample from q(t)(z̃(t)|z̃(t−1),x). More recent proposals involve sophisticated approaches to sample from better approximate posteriors, as the work of Salimans et al. (2015) in which Hamiltonian Monte Carlo is combined with variational inference, which looks very promising, though computationally expensive, and Rezende & Mohamed (2015) that generalizes the use of normalizing flows to obtain a better approximate posterior.\n4Specifically, the two estimates (lower-bound and IS) start by collecting k samples from q(z̃|x) and computing for each the corresponding ` = log p(z̃,x) − log q(z̃|x). The lower-bound estimate is then obtained by averaging the resulting `1, . . . `k, whereas the IS estimate is obtained by taking the log of the averaged e`1 , . . . , e`k (in a numerical stable manner as logsumexp(`1, . . . , `k)− log k)."
    }, {
      "heading" : "3.3 SAMPLING FROM AUTOENCODERS AND GENERATIVE STOCHASTIC NETWORKS",
      "text" : "Earlier works that propose to directly learn a transition operator resulted from research to turn autoencoder variants that have a stochastic component, in particular denoising autoencoders (Vincent et al., 2010), into generative models that one can sample from. This development is natural, since a stochastic auto-encoder is a stochastic transition operator form input space to input space. Generative Stochastic Networks (GSN) (Alain et al., 2016) generalized insights from earlier stochastic autoencoder sampling heuristics (Rifai et al., 2012) into a more formal and general framework. These previous works on generative uses of autoencoders and GSNs attempt to learn a chain whose equilibrium distribution will fit the training data. Because autoencoders and the chain are typically started from or very close to training data points, they are concerned with the chain mixing quickly between modes. By contrast our model chain is always restarted from unstructured noise, and is not required to reach or even have an equilibrium distribution. Our concern is only what happens during the T “burn-in” initial steps, and to make sure that it transforms the initial factorial noise distribution into something that best fits the training data distribution. There are no mixing concerns beyond those T initial steps.\nA related aspect and limitation of previous denoising autoencoder and GSN approaches is that these were mainly “local” around training samples: the stochastic operator explored space starting from and primarily centered around training examples, and learned based on inputs in these parts of space only. Spurious modes in the generated samples might result from large unexplored parts of space that one might encounter while running a long chain."
    }, {
      "heading" : "3.4 REVERSING A DIFFUSION PROCESS IN NON-EQUILIBRIUM THERMODYNAMICS",
      "text" : "The approach of Sohl-Dickstein et al. (2015) is probably the closest to the approach we develop here. Both share a similar model sampling chain that starts from unstructured factorial noise. Neither are concerned about an equilibrium distribution. They are however quite different in several key aspects: Sohl-Dickstein et al. (2015) proceed to invert an explicit diffusion process that starts from a training set example and very slowly destroys its structure to become this random noise, they then learn to reverse this process i.e. an inverse diffusion. To maintain the theoretical argument that the exact reverse process has the same distributional form (e.g. p(x(t−1)|x(t)) and p(x(t)|x(t−1)) both factorial Gaussians), the diffusion has to be infinitesimal by construction, hence the proposed approaches uses chains with thousands of tiny steps. Instead, our aim is to learn an operator that can yield a high quality sample efficiently using only a small number T of larger steps. Also our infusion training does not posit a fixed a priori diffusion process that we would learn to reverse. And while the distribution of diffusion chain samples of Sohl-Dickstein et al. (2015) is fixed and remains the same all along the training, the distribution of our infusion chain samples closely follow the model chain as our model learns. Our proposed infusion sampling technique thus adapts to the changing generative model distribution as the learning progresses.\nDrawing on both Sohl-Dickstein et al. (2015) and the walkback procedure introduced for GSN in Alain et al. (2016), a variational variant of the walkback algorithm was investigated by Goyal et al. (2017) at the same time as our work. It can be understood as a different approach to learning a Markov transition operator, in which a “heating” diffusion operator is seen as a variational approximate posterior to the forward “cooling” sampling operator with the exact same form and parameters, except for a different temperature."
    }, {
      "heading" : "4 EXPERIMENTS",
      "text" : "We trained models on several datasets with real-valued examples. We used as prior distribution p(0) a factorial Gaussian whose parameters were set to be the mean and variance for each pixel through the training set. Similarly, our models for the transition operators are factorial Gaussians. Their mean and elementwise variance is produced as the output of a neural network that receives the previous z(t−1) as its input, i.e. p(t)(z(t)i |z(t−1)) = N (µi(z(t−1)), σ2i (z(t−1))) where µ and σ2 are computed as output vectors of a neural network. We trained such a model using our infusion training procedure on MNIST (LeCun & Cortes, 1998), Toronto Face Database (Susskind et al., 2010), CIFAR-10 (Krizhevsky & Hinton, 2009), and CelebA (Liu et al., 2015). For all datasets, the only preprocessing we did was to scale the integer pixel values down to range [0,1]. The network\ntrained on MNIST and TFD is a MLP composed of two fully connected layers with 1200 units using batch-normalization (Ioffe & Szegedy, 2015) 5. The network trained on CIFAR-10 is based on the same generator as the GANs of Salimans et al. (2016), i.e. one fully connected layer followed by three transposed convolutions. CelebA was trained with the previous network where we added another transposed convolution. We use rectifier linear units (Glorot et al., 2011) on each layer inside the networks. Each of those networks have two distinct final layers with a number of units corresponding to the image size. They use sigmoid outputs, one that predict the mean and the second that predict a variance scaled by a scalar β (In our case we chose β = 0.1) and we add an epsilon = 1e − 4 to avoid an excessively small variance. For each experiment, we trained the network on 15 steps of denoising with an increasing infusion rate of 1% (ω = 0.01, α (0)\n= 0), except on CIFAR-10 where we use an increasing infusion rate of 2% (ω = 0.02, α (0) = 0) on 20 steps."
    }, {
      "heading" : "4.1 NUMERICAL RESULTS",
      "text" : "Since we can’t compute the exact log-likelihood, the evaluation of our model is not straightforward. However we use the lower bound estimator derived in Section 2.4 to evaluate our model during training and prevent overfitting (see Figure 3). Since most previous published results on non-likelihood based models (such as GANs) used a Parzen-window-based estimator (Breuleux et al., 2011), we use it as our first comparison tool, even if it can be misleading (Lucas Theis & Bethge, 2016). Results are shown in Table 1, we use 10 000 generated samples and σ = 0.17 . To get a better estimate of the log-likelihood, we then computed both the stochastic lower bound and the importance sampling estimate (IS) given in Section 2.4. For the IS estimate in our MNIST-trained model, we used 20 000 intermediates samples. In Table 2 we compare our model with the recent Annealed Importance Sampling results (Wu et al., 2016). Note that following their procedure we add an uniform noise of 1/256 to the (scaled) test point before evaluation to avoid overevaluating models that might have overfitted on the 8 bit quantization of pixel values. Another comparison tool that we used is the Inception score as in Salimans et al. (2016) which was developed for natural images and is thus most relevant for CIFAR-10. Since Salimans et al. (2016) used a GAN trained in a semi-supervised way with some tricks, the comparison with our unsupervised trained model isn’t straightforward. However, we can see in Table 3 that our model outperforms the traditional GAN trained without labeled data."
    }, {
      "heading" : "4.2 SAMPLE GENERATION",
      "text" : "Another common qualitative way to evaluate generative models is to look at the quality of the samples generated by the model. In Figure 4 we show various samples on each of the datasets we used. In order to get sharper images, we use at sampling time more denoising steps than in the training time (In the MNIST case we use 30 denoising steps for sampling with a model trained on 15 denoising steps). To make sure that our network didn’t learn to copy the training set, we show in the last column the nearest training-set neighbor to the samples in the next-to last column. We can see that our training method allow to generate very sharp and accurate samples on various dataset.\n5We don’t share batch norm parameters across the network, i.e for each time step we have different parameters and independent batch statistics."
    }, {
      "heading" : "4.3 INPAINTING",
      "text" : "Another method to evaluate a generative model is inpainting. It consists of providing only a partial image from the test set and letting the model generate the missing part. In one experiment, we provide only the top half of CelebA test set images and clamp that top half throughout the sampling chain. We restart sampling from our model several times, to see the variety in the distribution of the bottom part it generates. Figure 5 shows that the model is able to generate a varied set of bottom halves, all consistent with the same top half, displaying different type of smiles and expression. We also see that the generated bottom halves transfer some information about the provided top half of the images (such as pose and more or less coherent hair cut)."
    }, {
      "heading" : "5 CONCLUSION AND FUTURE WORK",
      "text" : "We presented a new training procedure that allows a neural network to learn a transition operator of a Markov chain. Compared to the previously proposed method of Sohl-Dickstein et al. (2015) based on inverting a slow diffusion process, we showed empirically that infusion training requires far fewer denoising steps, and appears to provide more accurate models. Currently, many successful generative models, judged on sample quality, are based on GAN architectures. However these require to use two different networks, a generator and a discriminator, whose balance is reputed delicate to adjust, which can be source of instability during training. Our method avoids this problem by using only a single network and a simpler training objective.\nDenoising-based infusion training optimizes a heuristic surrogate loss for which we cannot (yet) provide theoretical guarantees, but we empirically verified that it results in increasing log-likelihood estimates. On the other hand the lower-bound-based infusion training procedure does maximize an explicit variational lower-bound on the log-likelihood. While we have run most of our experiments with the former, we obtained similar results on the few problems we tried with lower-bound-based infusion training.\nFuture work shall further investigate the relationship and quantify the compromises achieved with respect to other Markov Chain methods including Sohl-Dickstein et al. (2015); Salimans et al. (2015)\nand also to powerful inference methods such as Rezende & Mohamed (2015). As future work, we also plan to investigate the use of more sophisticated neural net generators, similar to DCGAN’s (Radford et al., 2016) and to extend the approach to a conditional generator applicable to structured output problems."
    }, {
      "heading" : "ACKNOWLEDGMENTS",
      "text" : "We would like to thank the developers of Theano (Theano Development Team, 2016) for making this library available to build on, Compute Canada and Nvidia for their computation resources, NSERC and Ubisoft for their financial support, and three ICLR anonymous reviewers for helping us improve our paper."
    }, {
      "heading" : "A DETAILS ON THE EXPERIMENTS",
      "text" : "A.1 MNIST EXPERIMENTS\nWe show the impact of the infusion rate α(t) = α (t−1)\n+ ω for different numbers of training steps on the lower bound estimate of log-likelihood on the Validation set of MNIST in Figure 6. We also show the quality of generated samples and the lower bound evaluated on the test set in Table 4. Each experiment in Table 4 uses the corresponding models of Figure 6 that obtained the best lower bound value on the validation set. We use the same network architecture as described in Section 4, i.e two fully connected layers with Relu activations composed of 1200 units followed by two distinct fully connected layers composed of 784 units, one that predicts the means, the other one that predicts the variances. Each mean and variance is associated with one pixel. All of the the parameters of the model are shared across different steps except for the batch norm parameters. During training, we use the batch statistics of the current mini-batch in order to evaluate our model on the train and validation sets. At test time (Table 4), we first compute the batch statistics over the entire train set for each step and then use the computed statistics to evaluate our model on the test test.\nWe did some experiments to evaluate the impact of α or ω in α(t) = α (t−1)\n+ ω. Figure 6 shows that as the number of steps increases, the optimal value for infusion rate decreases. Therefore, if we want to use many steps, we should have a small infusion rate. These conclusions are valid for both increasing and constant infusion rate. For example, the optimal α for a constant infusion rate, in Figure 6e with 10 steps is 0.08 and in Figure 6f with 15 steps is 0.06. If the number of steps is not enough or the infusion rate is too small, the network will not be able to learn the target distribution as shown in the first rows of all subsection in Table 4.\nIn order to show the impact of having a constant versus an increasing infusion rate, we show in Figure 7 the samples created by infused and sampling chains. We observe that having a small infusion rate over many steps ensures a slow blending of the model distribution into the target distribution.\nIn Table 4, we can see high lower bound values on the test set with few steps even if the model can’t generate samples that are qualitatively satisfying. These results indicate that we can’t rely on the lower bound as the only evaluation metric and this metric alone does not necessarily indicate the suitability of our model to generated good samples. However, it is still a useful tool to prevent overfitting (the networks in Figure 6e and 6f overfit when the infusion rate becomes too high). Concerning the samples quality, we observe that having a small infusion rate over an adequate number of steps leads to better samples.\nA.2 INFUSION AND MODEL SAMPLING CHAINS ON NATURAL IMAGES DATASETS\nIn order to show the behavior of our model trained by Infusion on more complex datasets, we show in Figure 8 chains on CIFAR-10 dataset and in Figure 9 chains on CelebA dataset. In each Figure, the first sub-figure shows the chains infused by some test examples and the second subfigure shows the model sampling chains. In the experiment on CIFAR-10, we use an increasing schedule α(t) = α (t−1) + 0.02 with α(0) = 0 and 20 infusion steps (this corresponds to the training parameters). In the experiment on CelebA, we use an increasing schedule α(t) = α (t−1)\n+0.01 with α(0) = 0 and 15 infusion steps."
    } ],
    "references" : [ {
      "title" : "GSNs: generative stochastic networks. Information and Inference, 2016",
      "author" : [ "Guillaume Alain", "Yoshua Bengio", "Li Yao", "Jason Yosinski", "Eric Thibodeau-Laufer", "Saizheng Zhang", "Pascal Vincent" ],
      "venue" : null,
      "citeRegEx" : "Alain et al\\.,? \\Q2016\\E",
      "shortCiteRegEx" : "Alain et al\\.",
      "year" : 2016
    }, {
      "title" : "Better mixing via deep representations",
      "author" : [ "Yoshua Bengio", "Grégoire Mesnil", "Yann Dauphin", "Salah Rifai" ],
      "venue" : "In Proceedings of the 30th International Conference on Machine Learning",
      "citeRegEx" : "Bengio et al\\.,? \\Q2013\\E",
      "shortCiteRegEx" : "Bengio et al\\.",
      "year" : 2013
    }, {
      "title" : "Deep generative stochastic networks trainable by backprop",
      "author" : [ "Yoshua Bengio", "Eric Laufer", "Guillaume Alain", "Jason Yosinski" ],
      "venue" : "In Proceedings of the 31st International Conference on Machine Learning (ICML",
      "citeRegEx" : "Bengio et al\\.,? \\Q2014\\E",
      "shortCiteRegEx" : "Bengio et al\\.",
      "year" : 2014
    }, {
      "title" : "Quickly generating representative samples from an rbm-derived process",
      "author" : [ "Olivier Breuleux", "Yoshua Bengio", "Pascal Vincent" ],
      "venue" : "Neural Computation,",
      "citeRegEx" : "Breuleux et al\\.,? \\Q2011\\E",
      "shortCiteRegEx" : "Breuleux et al\\.",
      "year" : 2011
    }, {
      "title" : "Nice: Non-linear independent components estimation",
      "author" : [ "Laurent Dinh", "David Krueger", "Yoshua Bengio" ],
      "venue" : "arXiv preprint arXiv:1410.8516,",
      "citeRegEx" : "Dinh et al\\.,? \\Q2014\\E",
      "shortCiteRegEx" : "Dinh et al\\.",
      "year" : 2014
    }, {
      "title" : "Deep sparse rectifier neural networks",
      "author" : [ "Xavier Glorot", "Antoine Bordes", "Yoshua Bengio" ],
      "venue" : "In Aistats,",
      "citeRegEx" : "Glorot et al\\.,? \\Q2011\\E",
      "shortCiteRegEx" : "Glorot et al\\.",
      "year" : 2011
    }, {
      "title" : "Generative adversarial nets",
      "author" : [ "Ian Goodfellow", "Jean Pouget-Abadie", "Mehdi Mirza", "Bing Xu", "David Warde-Farley", "Sherjil Ozair", "Aaron Courville", "Yoshua Bengio" ],
      "venue" : "Advances in Neural Information Processing Systems",
      "citeRegEx" : "Goodfellow et al\\.,? \\Q2014\\E",
      "shortCiteRegEx" : "Goodfellow et al\\.",
      "year" : 2014
    }, {
      "title" : "The variational walkback algorithm",
      "author" : [ "Anirudh Goyal", "Nan Rosemary Ke", "Alex Lamb", "Yoshua Bengio" ],
      "venue" : "Technical report, Université de Montréal,",
      "citeRegEx" : "Goyal et al\\.,? \\Q2017\\E",
      "shortCiteRegEx" : "Goyal et al\\.",
      "year" : 2017
    }, {
      "title" : "Batch normalization: Accelerating deep network training by reducing internal covariate shift",
      "author" : [ "Sergey Ioffe", "Christian Szegedy" ],
      "venue" : "Proceedings of The 32nd International Conference on Machine Learning,",
      "citeRegEx" : "Ioffe and Szegedy.,? \\Q2015\\E",
      "shortCiteRegEx" : "Ioffe and Szegedy.",
      "year" : 2015
    }, {
      "title" : "Auto-encoding variational bayes",
      "author" : [ "Diederik P Kingma", "Max Welling" ],
      "venue" : "In Proceedings of the 2nd International Conference on Learning Representations (ICLR",
      "citeRegEx" : "Kingma and Welling.,? \\Q2014\\E",
      "shortCiteRegEx" : "Kingma and Welling.",
      "year" : 2014
    }, {
      "title" : "Learning multiple layers of features from tiny images",
      "author" : [ "Alex. Krizhevsky", "Geoffrey E Hinton" ],
      "venue" : "Master’s thesis,",
      "citeRegEx" : "Krizhevsky and Hinton.,? \\Q2009\\E",
      "shortCiteRegEx" : "Krizhevsky and Hinton.",
      "year" : 2009
    }, {
      "title" : "The neural autoregressive distribution estimator",
      "author" : [ "Hugo Larochelle", "Iain Murray" ],
      "venue" : "In AISTATS,",
      "citeRegEx" : "Larochelle and Murray.,? \\Q2011\\E",
      "shortCiteRegEx" : "Larochelle and Murray.",
      "year" : 2011
    }, {
      "title" : "The mnist database of handwritten digits",
      "author" : [ "Yann LeCun", "Corinna Cortes" ],
      "venue" : null,
      "citeRegEx" : "LeCun and Cortes.,? \\Q1998\\E",
      "shortCiteRegEx" : "LeCun and Cortes.",
      "year" : 1998
    }, {
      "title" : "Generative moment matching networks",
      "author" : [ "Yujia Li", "Kevin Swersky", "Richard Zemel" ],
      "venue" : "In International Conference on Machine Learning (ICML",
      "citeRegEx" : "Li et al\\.,? \\Q2015\\E",
      "shortCiteRegEx" : "Li et al\\.",
      "year" : 2015
    }, {
      "title" : "Deep learning face attributes in the wild",
      "author" : [ "Ziwei Liu", "Ping Luo", "Xiaogang Wang", "Xiaoou Tang" ],
      "venue" : "In Proceedings of International Conference on Computer Vision (ICCV",
      "citeRegEx" : "Liu et al\\.,? \\Q2015\\E",
      "shortCiteRegEx" : "Liu et al\\.",
      "year" : 2015
    }, {
      "title" : "A note on the evaluation of generative models",
      "author" : [ "Aäron van den Oord Lucas Theis", "Matthias Bethge" ],
      "venue" : "In Proceedings of the 4th International Conference on Learning Representations (ICLR",
      "citeRegEx" : "Theis and Bethge.,? \\Q2016\\E",
      "shortCiteRegEx" : "Theis and Bethge.",
      "year" : 2016
    }, {
      "title" : "Unsupervised representation learning with deep convolutional generative adversarial networks",
      "author" : [ "Alec Radford", "Luke Metz", "Soumith Chintala" ],
      "venue" : "International Conference on Learning Representations,",
      "citeRegEx" : "Radford et al\\.,? \\Q2016\\E",
      "shortCiteRegEx" : "Radford et al\\.",
      "year" : 2016
    }, {
      "title" : "Variational inference with normalizing flows",
      "author" : [ "Danilo Rezende", "Shakir Mohamed" ],
      "venue" : "In Proceedings of the 32nd International Conference on Machine Learning (ICML",
      "citeRegEx" : "Rezende and Mohamed.,? \\Q2015\\E",
      "shortCiteRegEx" : "Rezende and Mohamed.",
      "year" : 2015
    }, {
      "title" : "Stochastic backpropagation and approximate inference in deep generative models",
      "author" : [ "Danilo Jimenez Rezende", "Shakir Mohamed", "Daan Wierstra" ],
      "venue" : "In Proceedings of the 31th International Conference on Machine Learning,",
      "citeRegEx" : "Rezende et al\\.,? \\Q2014\\E",
      "shortCiteRegEx" : "Rezende et al\\.",
      "year" : 2014
    }, {
      "title" : "A generative process for sampling contractive auto-encoders",
      "author" : [ "Salah Rifai", "Yoshua Bengio", "Yann Dauphin", "Pascal Vincent" ],
      "venue" : "In Proceedings of the 29th International Conference on Machine Learning",
      "citeRegEx" : "Rifai et al\\.,? \\Q2012\\E",
      "shortCiteRegEx" : "Rifai et al\\.",
      "year" : 2012
    }, {
      "title" : "Deep boltzmann machines",
      "author" : [ "Ruslan Salakhutdinov", "Geoffrey E Hinton" ],
      "venue" : "In AISTATS,",
      "citeRegEx" : "Salakhutdinov and Hinton.,? \\Q2009\\E",
      "shortCiteRegEx" : "Salakhutdinov and Hinton.",
      "year" : 2009
    }, {
      "title" : "Markov chain monte carlo and variational inference: Bridging the gap",
      "author" : [ "Tim Salimans", "Diederik Kingma", "Max Welling" ],
      "venue" : "In Proceedings of The 32nd International Conference on Machine Learning,",
      "citeRegEx" : "Salimans et al\\.,? \\Q2015\\E",
      "shortCiteRegEx" : "Salimans et al\\.",
      "year" : 2015
    }, {
      "title" : "Improved techniques for training",
      "author" : [ "Tim Salimans", "Ian J. Goodfellow", "Wojciech Zaremba", "Vicki Cheung", "Alec Radford", "Xi Chen" ],
      "venue" : "gans. CoRR,",
      "citeRegEx" : "Salimans et al\\.,? \\Q2016\\E",
      "shortCiteRegEx" : "Salimans et al\\.",
      "year" : 2016
    }, {
      "title" : "Deep Unsupervised Learning using Nonequilibrium Thermodynamics",
      "author" : [ "Jascha Sohl-Dickstein", "Eric A. Weiss", "Niru Maheswaranathan", "Surya Ganguli" ],
      "venue" : "In Proceedings of the 32nd International Conference on Machine Learning,",
      "citeRegEx" : "Sohl.Dickstein et al\\.,? \\Q2015\\E",
      "shortCiteRegEx" : "Sohl.Dickstein et al\\.",
      "year" : 2015
    }, {
      "title" : "The toronto face database",
      "author" : [ "Josh M Susskind", "Adam K Anderson", "Geoffrey E Hinton" ],
      "venue" : "Department of Computer Science,",
      "citeRegEx" : "Susskind et al\\.,? \\Q2010\\E",
      "shortCiteRegEx" : "Susskind et al\\.",
      "year" : 2010
    }, {
      "title" : "Pixel recurrent neural networks",
      "author" : [ "Aäron van den Oord", "Nal Kalchbrenner", "Koray Kavukcuoglu" ],
      "venue" : "In Proceedings of the 33nd International Conference on Machine Learning (ICML 2016),",
      "citeRegEx" : "Oord et al\\.,? \\Q2016\\E",
      "shortCiteRegEx" : "Oord et al\\.",
      "year" : 2016
    }, {
      "title" : "Stacked denoising autoencoders: Learning useful representations in a deep network with a local denoising criterion",
      "author" : [ "Pascal Vincent", "Hugo Larochelle", "Isabelle Lajoie", "Yoshua Bengio", "Pierre-Antoine Manzagol" ],
      "venue" : "Journal of Machine Learning Research,",
      "citeRegEx" : "Vincent et al\\.,? \\Q2010\\E",
      "shortCiteRegEx" : "Vincent et al\\.",
      "year" : 2010
    }, {
      "title" : "On the quantitative analysis of decoder-based generative models",
      "author" : [ "Yuhuai Wu", "Yuri Burda", "Ruslan Salakhutdinov", "Roger B. Grosse" ],
      "venue" : null,
      "citeRegEx" : "Wu et al\\.,? \\Q2016\\E",
      "shortCiteRegEx" : "Wu et al\\.",
      "year" : 2016
    } ],
    "referenceMentions" : [ {
      "referenceID" : 18,
      "context" : "• Directed graphical models trained as variational autoencoders (VAE) (Kingma & Welling, 2014; Rezende et al., 2014)",
      "startOffset" : 70,
      "endOffset" : 116
    }, {
      "referenceID" : 6,
      "context" : "(GAN)(Goodfellow et al., 2014) • Stochastic neural networks, i.",
      "startOffset" : 5,
      "endOffset" : 30
    }, {
      "referenceID" : 26,
      "context" : "networks with stochastic neurons, trained by an adapted form of stochastic backpropagation • Generative uses of denoising autoencoders (Vincent et al., 2010) and their generalization as Generative Stochastic Networks (Alain et al.",
      "startOffset" : 135,
      "endOffset" : 157
    }, {
      "referenceID" : 0,
      "context" : ", 2010) and their generalization as Generative Stochastic Networks (Alain et al., 2016) • Inverting a non-equilibrium thermodynamic slow diffusion process (Sohl-Dickstein et al.",
      "startOffset" : 67,
      "endOffset" : 87
    }, {
      "referenceID" : 23,
      "context" : ", 2016) • Inverting a non-equilibrium thermodynamic slow diffusion process (Sohl-Dickstein et al., 2015) • Continuous transformation of a distribution by invertible functions (Dinh et al.",
      "startOffset" : 75,
      "endOffset" : 104
    }, {
      "referenceID" : 0,
      "context" : ", 2010) and their generalization as Generative Stochastic Networks (Alain et al., 2016) • Inverting a non-equilibrium thermodynamic slow diffusion process (Sohl-Dickstein et al., 2015) • Continuous transformation of a distribution by invertible functions (Dinh et al. (2014), also used for variational inference in Rezende & Mohamed (2015)) Several of these approaches are based on maximizing an explicit or implicit model log-likelihood or a lower bound of its log-likelihood, but some successful ones are not e.",
      "startOffset" : 68,
      "endOffset" : 275
    }, {
      "referenceID" : 0,
      "context" : ", 2010) and their generalization as Generative Stochastic Networks (Alain et al., 2016) • Inverting a non-equilibrium thermodynamic slow diffusion process (Sohl-Dickstein et al., 2015) • Continuous transformation of a distribution by invertible functions (Dinh et al. (2014), also used for variational inference in Rezende & Mohamed (2015)) Several of these approaches are based on maximizing an explicit or implicit model log-likelihood or a lower bound of its log-likelihood, but some successful ones are not e.",
      "startOffset" : 68,
      "endOffset" : 340
    }, {
      "referenceID" : 0,
      "context" : ", 2010) and their generalization as Generative Stochastic Networks (Alain et al., 2016) • Inverting a non-equilibrium thermodynamic slow diffusion process (Sohl-Dickstein et al., 2015) • Continuous transformation of a distribution by invertible functions (Dinh et al. (2014), also used for variational inference in Rezende & Mohamed (2015)) Several of these approaches are based on maximizing an explicit or implicit model log-likelihood or a lower bound of its log-likelihood, but some successful ones are not e.g. GANs. The approach we propose here is based on the notion of “denoising” and thus takes its root in denoising autoencoders and the GSN type of approaches. It is also highly related to the non-equilibrium thermodynamics inverse diffusion approach of Sohl-Dickstein et al. (2015). One key aspect that distinguishes these types of methods from others listed above is that sample generation is achieved thanks to a learned stochastic mapping from input space to input space, rather than from a latent-space to input-space.",
      "startOffset" : 68,
      "endOffset" : 794
    }, {
      "referenceID" : 0,
      "context" : ", 2010) and their generalization as Generative Stochastic Networks (Alain et al., 2016) • Inverting a non-equilibrium thermodynamic slow diffusion process (Sohl-Dickstein et al., 2015) • Continuous transformation of a distribution by invertible functions (Dinh et al. (2014), also used for variational inference in Rezende & Mohamed (2015)) Several of these approaches are based on maximizing an explicit or implicit model log-likelihood or a lower bound of its log-likelihood, but some successful ones are not e.g. GANs. The approach we propose here is based on the notion of “denoising” and thus takes its root in denoising autoencoders and the GSN type of approaches. It is also highly related to the non-equilibrium thermodynamics inverse diffusion approach of Sohl-Dickstein et al. (2015). One key aspect that distinguishes these types of methods from others listed above is that sample generation is achieved thanks to a learned stochastic mapping from input space to input space, rather than from a latent-space to input-space. Specifically, in the present work, we propose to learn to generate high quality samples through a process of progressive, stochastic, denoising, starting from a simple initial “noise” sample generated in input space from a simple factorial distribution i.e. one that does not take into account any dependency or structure between dimensions. This, in effect, amounts to learning the transition operator of a Markov chain operating on input space. Starting from such an initial “noise” input, and repeatedly applying the operator for a small fixed number T of steps, we aim to obtain a high quality resulting sample, effectively modeling the training data distribution. Our training procedure uses a novel “target-infusion” technique, designed to slightly bias model sampling to move towards a specific data point during training, and thus provide inputs to denoise which are likely under the model’s sample generation paths. By contrast with Sohl-Dickstein et al. (2015) which consists in inverting a slow and fixed diffusion process, our infusion chains make a few large jumps and follow the model distribution as the learning progresses.",
      "startOffset" : 68,
      "endOffset" : 2006
    }, {
      "referenceID" : 18,
      "context" : "In our experiments, we will take the p(t)(z(t)|z(t−1)) to be simple diagonal Gaussian yielding a Deep Latent Gaussian Model (DLGM) as in Rezende et al. (2014).",
      "startOffset" : 137,
      "endOffset" : 159
    }, {
      "referenceID" : 18,
      "context" : "Variational auto-encoders (VAE) (Kingma & Welling, 2014; Rezende et al., 2014) also start from an unstructured (independent) noise sample and non-linearly transform this into a distribution that matches the training data.",
      "startOffset" : 32,
      "endOffset" : 78
    }, {
      "referenceID" : 18,
      "context" : "Variational auto-encoders (VAE) (Kingma & Welling, 2014; Rezende et al., 2014) also start from an unstructured (independent) noise sample and non-linearly transform this into a distribution that matches the training data. One difference with our approach is that the VAE typically maps from a lower-dimensional space to the observation space. By contrast we learn a stochastic transition operator from input space to input space that we repeat for T steps. Another key difference, is that the VAE learns a complex heavily parameterized approximate posterior proposal q whereas our infusion based q can be understood as a simple heuristic proposal distribution based on p. Importantly the specific heuristic we use to infuse x into q makes sense precisely because our operator is a map from input space to input space, and couldn’t be readily applied otherwise. The generative network in Rezende et al. (2014) is a Deep Latent Gaussian Model (DLGM) just as ours.",
      "startOffset" : 57,
      "endOffset" : 909
    }, {
      "referenceID" : 21,
      "context" : "More recent proposals involve sophisticated approaches to sample from better approximate posteriors, as the work of Salimans et al. (2015) in which Hamiltonian Monte Carlo is combined with variational inference, which looks very promising, though computationally expensive, and Rezende & Mohamed (2015) that generalizes the use of normalizing flows to obtain a better approximate posterior.",
      "startOffset" : 116,
      "endOffset" : 139
    }, {
      "referenceID" : 21,
      "context" : "More recent proposals involve sophisticated approaches to sample from better approximate posteriors, as the work of Salimans et al. (2015) in which Hamiltonian Monte Carlo is combined with variational inference, which looks very promising, though computationally expensive, and Rezende & Mohamed (2015) that generalizes the use of normalizing flows to obtain a better approximate posterior.",
      "startOffset" : 116,
      "endOffset" : 303
    }, {
      "referenceID" : 26,
      "context" : "Earlier works that propose to directly learn a transition operator resulted from research to turn autoencoder variants that have a stochastic component, in particular denoising autoencoders (Vincent et al., 2010), into generative models that one can sample from.",
      "startOffset" : 190,
      "endOffset" : 212
    }, {
      "referenceID" : 0,
      "context" : "Generative Stochastic Networks (GSN) (Alain et al., 2016) generalized insights from earlier stochastic autoencoder sampling heuristics (Rifai et al.",
      "startOffset" : 37,
      "endOffset" : 57
    }, {
      "referenceID" : 19,
      "context" : ", 2016) generalized insights from earlier stochastic autoencoder sampling heuristics (Rifai et al., 2012) into a more formal and general framework.",
      "startOffset" : 85,
      "endOffset" : 105
    }, {
      "referenceID" : 23,
      "context" : "The approach of Sohl-Dickstein et al. (2015) is probably the closest to the approach we develop here.",
      "startOffset" : 16,
      "endOffset" : 45
    }, {
      "referenceID" : 23,
      "context" : "The approach of Sohl-Dickstein et al. (2015) is probably the closest to the approach we develop here. Both share a similar model sampling chain that starts from unstructured factorial noise. Neither are concerned about an equilibrium distribution. They are however quite different in several key aspects: Sohl-Dickstein et al. (2015) proceed to invert an explicit diffusion process that starts from a training set example and very slowly destroys its structure to become this random noise, they then learn to reverse this process i.",
      "startOffset" : 16,
      "endOffset" : 334
    }, {
      "referenceID" : 23,
      "context" : "The approach of Sohl-Dickstein et al. (2015) is probably the closest to the approach we develop here. Both share a similar model sampling chain that starts from unstructured factorial noise. Neither are concerned about an equilibrium distribution. They are however quite different in several key aspects: Sohl-Dickstein et al. (2015) proceed to invert an explicit diffusion process that starts from a training set example and very slowly destroys its structure to become this random noise, they then learn to reverse this process i.e. an inverse diffusion. To maintain the theoretical argument that the exact reverse process has the same distributional form (e.g. p(x(t−1)|x(t)) and p(x(t)|x(t−1)) both factorial Gaussians), the diffusion has to be infinitesimal by construction, hence the proposed approaches uses chains with thousands of tiny steps. Instead, our aim is to learn an operator that can yield a high quality sample efficiently using only a small number T of larger steps. Also our infusion training does not posit a fixed a priori diffusion process that we would learn to reverse. And while the distribution of diffusion chain samples of Sohl-Dickstein et al. (2015) is fixed and remains the same all along the training, the distribution of our infusion chain samples closely follow the model chain as our model learns.",
      "startOffset" : 16,
      "endOffset" : 1182
    }, {
      "referenceID" : 21,
      "context" : "Drawing on both Sohl-Dickstein et al. (2015) and the walkback procedure introduced for GSN in Alain et al.",
      "startOffset" : 16,
      "endOffset" : 45
    }, {
      "referenceID" : 0,
      "context" : "(2015) and the walkback procedure introduced for GSN in Alain et al. (2016), a variational variant of the walkback algorithm was investigated by Goyal et al.",
      "startOffset" : 56,
      "endOffset" : 76
    }, {
      "referenceID" : 0,
      "context" : "(2015) and the walkback procedure introduced for GSN in Alain et al. (2016), a variational variant of the walkback algorithm was investigated by Goyal et al. (2017) at the same time as our work.",
      "startOffset" : 56,
      "endOffset" : 165
    }, {
      "referenceID" : 24,
      "context" : "We trained such a model using our infusion training procedure on MNIST (LeCun & Cortes, 1998), Toronto Face Database (Susskind et al., 2010), CIFAR-10 (Krizhevsky & Hinton, 2009), and CelebA (Liu et al.",
      "startOffset" : 117,
      "endOffset" : 140
    }, {
      "referenceID" : 14,
      "context" : ", 2010), CIFAR-10 (Krizhevsky & Hinton, 2009), and CelebA (Liu et al., 2015).",
      "startOffset" : 58,
      "endOffset" : 76
    }, {
      "referenceID" : 21,
      "context" : "We use the models in Salimans et al. (2016) as baseline.",
      "startOffset" : 21,
      "endOffset" : 44
    }, {
      "referenceID" : 21,
      "context" : "We use the models in Salimans et al. (2016) as baseline. ’SP’ corresponds to the best model described by Salimans et al. (2016) trained in a semi-supervised fashion.",
      "startOffset" : 21,
      "endOffset" : 128
    }, {
      "referenceID" : 5,
      "context" : "We use rectifier linear units (Glorot et al., 2011) on each layer inside the networks.",
      "startOffset" : 30,
      "endOffset" : 51
    }, {
      "referenceID" : 20,
      "context" : "The network trained on CIFAR-10 is based on the same generator as the GANs of Salimans et al. (2016), i.",
      "startOffset" : 78,
      "endOffset" : 101
    }, {
      "referenceID" : 3,
      "context" : "Since most previous published results on non-likelihood based models (such as GANs) used a Parzen-window-based estimator (Breuleux et al., 2011), we use it as our first comparison tool, even if it can be misleading (Lucas Theis & Bethge, 2016).",
      "startOffset" : 121,
      "endOffset" : 144
    }, {
      "referenceID" : 27,
      "context" : "In Table 2 we compare our model with the recent Annealed Importance Sampling results (Wu et al., 2016).",
      "startOffset" : 85,
      "endOffset" : 102
    }, {
      "referenceID" : 3,
      "context" : "Since most previous published results on non-likelihood based models (such as GANs) used a Parzen-window-based estimator (Breuleux et al., 2011), we use it as our first comparison tool, even if it can be misleading (Lucas Theis & Bethge, 2016). Results are shown in Table 1, we use 10 000 generated samples and σ = 0.17 . To get a better estimate of the log-likelihood, we then computed both the stochastic lower bound and the importance sampling estimate (IS) given in Section 2.4. For the IS estimate in our MNIST-trained model, we used 20 000 intermediates samples. In Table 2 we compare our model with the recent Annealed Importance Sampling results (Wu et al., 2016). Note that following their procedure we add an uniform noise of 1/256 to the (scaled) test point before evaluation to avoid overevaluating models that might have overfitted on the 8 bit quantization of pixel values. Another comparison tool that we used is the Inception score as in Salimans et al. (2016) which was developed for natural images and is thus most relevant for CIFAR-10.",
      "startOffset" : 122,
      "endOffset" : 977
    }, {
      "referenceID" : 3,
      "context" : "Since most previous published results on non-likelihood based models (such as GANs) used a Parzen-window-based estimator (Breuleux et al., 2011), we use it as our first comparison tool, even if it can be misleading (Lucas Theis & Bethge, 2016). Results are shown in Table 1, we use 10 000 generated samples and σ = 0.17 . To get a better estimate of the log-likelihood, we then computed both the stochastic lower bound and the importance sampling estimate (IS) given in Section 2.4. For the IS estimate in our MNIST-trained model, we used 20 000 intermediates samples. In Table 2 we compare our model with the recent Annealed Importance Sampling results (Wu et al., 2016). Note that following their procedure we add an uniform noise of 1/256 to the (scaled) test point before evaluation to avoid overevaluating models that might have overfitted on the 8 bit quantization of pixel values. Another comparison tool that we used is the Inception score as in Salimans et al. (2016) which was developed for natural images and is thus most relevant for CIFAR-10. Since Salimans et al. (2016) used a GAN trained in a semi-supervised way with some tricks, the comparison with our unsupervised trained model isn’t straightforward.",
      "startOffset" : 122,
      "endOffset" : 1085
    }, {
      "referenceID" : 1,
      "context" : "Model Test DBM (Bengio et al., 2013) 138± 2 SCAE (Bengio et al.",
      "startOffset" : 15,
      "endOffset" : 36
    }, {
      "referenceID" : 1,
      "context" : ", 2013) 138± 2 SCAE (Bengio et al., 2013) 121± 1.",
      "startOffset" : 20,
      "endOffset" : 41
    }, {
      "referenceID" : 2,
      "context" : "6 GSN (Bengio et al., 2014) 214± 1.",
      "startOffset" : 6,
      "endOffset" : 27
    }, {
      "referenceID" : 23,
      "context" : "1 Diffusion (Sohl-Dickstein et al., 2015) 220± 1.",
      "startOffset" : 12,
      "endOffset" : 41
    }, {
      "referenceID" : 27,
      "context" : "Table 2: Log-likelihood (in nats) estimated by AIS on MNIST test and training sets as reported in Wu et al. (2016) and the log likelihood estimates of our model obtained by infusion training (last three lines).",
      "startOffset" : 98,
      "endOffset" : 115
    }, {
      "referenceID" : 27,
      "context" : "Table 2: Log-likelihood (in nats) estimated by AIS on MNIST test and training sets as reported in Wu et al. (2016) and the log likelihood estimates of our model obtained by infusion training (last three lines). Our initial model uses a Gaussian output with diagonal covariance, and we applied both our lower bound and importance sampling (IS) log-likelihood estimates to it. Since Wu et al. (2016) used only an isotropic output observation model, in order to be comparable to them, we also evaluated our model after replacing the output by an isotropic Gaussian output (same fixed variance for all pixels).",
      "startOffset" : 98,
      "endOffset" : 398
    }, {
      "referenceID" : 23,
      "context" : "Compared to the previously proposed method of Sohl-Dickstein et al. (2015) based on inverting a slow diffusion process, we showed empirically that infusion training requires far fewer denoising steps, and appears to provide more accurate models.",
      "startOffset" : 46,
      "endOffset" : 75
    }, {
      "referenceID" : 21,
      "context" : "Future work shall further investigate the relationship and quantify the compromises achieved with respect to other Markov Chain methods including Sohl-Dickstein et al. (2015); Salimans et al.",
      "startOffset" : 146,
      "endOffset" : 175
    }, {
      "referenceID" : 21,
      "context" : "(2015); Salimans et al. (2015)",
      "startOffset" : 8,
      "endOffset" : 31
    }, {
      "referenceID" : 16,
      "context" : "As future work, we also plan to investigate the use of more sophisticated neural net generators, similar to DCGAN’s (Radford et al., 2016) and to extend the approach to a conditional generator applicable to structured output problems.",
      "startOffset" : 116,
      "endOffset" : 138
    } ],
    "year" : 2017,
    "abstractText" : "In this work, we investigate a novel training procedure to learn a generative model as the transition operator of a Markov chain, such that, when applied repeatedly on an unstructured random noise sample, it will denoise it into a sample that matches the target distribution from the training set. The novel training procedure to learn this progressive denoising operation involves sampling from a slightly different chain than the model chain used for generation in the absence of a denoising target. In the training chain we infuse information from the training target example that we would like the chains to reach with a high probability. The thus learned transition operator is able to produce quality and varied samples in a small number of steps. Experiments show competitive results compared to the samples generated with a basic Generative Adversarial Net.",
    "creator" : "LaTeX with hyperref package"
  }
}