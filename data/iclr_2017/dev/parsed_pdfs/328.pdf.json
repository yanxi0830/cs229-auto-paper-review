{
  "name" : "328.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "MULTILAYER RECURRENT NETWORK MODELS OF PRI- MATE RETINAL GANGLION CELL RESPONSES",
    "authors" : [ "Eleanor Batty", "Josh Merel", "Alexander Heitman", "Liam Paninski" ],
    "emails" : [ "nbrack@stanford.edu", "alexkenheitman@gmail.com", "sashake3@ucsc.edu,", "Alan.Litke@cern.ch", "ej@stanford.edu", "liam@stat.columbia.edu" ],
    "sections" : [ {
      "heading" : "1 INTRODUCTION",
      "text" : "Our understanding of sensory processing in the brain is most straightforwardly reflected in our ability to model the process by which stimuli presented at the sensory periphery are transformed into the spiking activity of populations of neurons. For decades, researchers have interrogated stimulus-response\n∗These authors contributed equally.\nneural properties using simplified targeted stimuli, such as bars, spots, or gratings. While these types of stimuli uncovered many interesting aspects of visual computation, they have several limitations (Barlow & Levick, 1965). These stimuli may not fully drive important components of neural response, and modeling efforts have often assumed a quasi-linear mapping from stimulus to firing rate. Subsequent efforts to characterize cells relied on white noise stimulation and building models through reverse correlation (de Boer R & Kuyper, 1968; Marmarelis & Naka, 1972; Chichilnisky, 2001). A standard model used to relate white noise to spiking responses is the linear-nonlinear-Poisson (LN) or generalized linear model (GLM) which consists of a spatiotemporal linear filtering of the stimulus followed by a nonlinearity and probabilistic spike generation (Chichilnisky, 2001; Simoncelli et al., 2004; Schwartz et al., 2006). Although this family of models have advanced our understanding, they do not optimally capture neural responses, especially to natural scenes which can lead to more complex responses than white noise stimuli (David et al., 2004). Even in the retina, early in the visual processing stream, these commonly-used models capture retinal ganglion cell (RGC) responses to natural stimuli less accurately than to white noise (Heitman et al., 2016).\nRecently, deep neural networks have been used to dramatically improve performance on a diverse array of machine learning tasks (Krizhevsky et al., 2012; LeCun et al., 2015). Furthermore, these networks bear a loose resemblance to real neural networks, and provide a sufficiently rich model class that can still be roughly constrained to match the biological architecture (Kriegeskorte, 2015). Most previous research at this intersection of neuroscience and artificial neural networks has focused on training networks on a certain task, such as object recognition, and then comparing the computations performed in different layers of the artificial network to those performed by real neurons (Yamins et al., 2014). Here we take a different approach: we fit multilayer models directly to the spiking responses of neurons, an approach that has not been explored in detail (but see (McIntosh et al., 2016) for some recent independent parallel developments)."
    }, {
      "heading" : "2 APPROACH",
      "text" : "We fit a range of models, detailed below, to spiking responses of primate RGCs. Our baseline comparisons are the GLM architectures that have been widely used to construct previous neural models (Pillow et al., 2008), though here we focus on individual neuronal responses (we leave modeling of correlations between neurons for future work). We focused on RNNs as a flexible framework in which to model more complex temporal and spatial nonlinearities. We also explored a number of network architectures involving features or weights shared across observed neurons. Given the complexity of the network architectures, we reasoned that sharing statistical strength across neurons by learning a shared feature space might improve predictive performance. This is conceptually a form of multitask learning - we are using a shared representation to achieve better generalization (Baxter, 2000). Motivated by previous research showing significant differences in the processing properties of the two cell types examined, ON and OFF parasol retinal ganglion cells, we fit separate models for each of these cell types (Chichilnisky & Kalmar, 2002)."
    }, {
      "heading" : "3 METHODS",
      "text" : ""
    }, {
      "heading" : "3.1 DATA COLLECTION",
      "text" : "We fit spiking responses of OFF and ON parasol retinal ganglion cells to natural scenes. Recordings were performed on isolated retina using a large-scale multi-electrode recording system (Litke et al., 2004; Frechette et al., 2005; Field et al., 2007). A standard spike sorting algorithm was used to identify spikes from different cells from the voltage signals on each electrode during visual stimulation (Litke et al., 2004). We focus on two separate experiments (the same experimental procedure in two separate retinas) here; analyses of other datasets yielded similar results. Models were fit separately for the two experiments due to animal to animal variability in cell properties, such as receptive field size and firing rate. Almost all spike sorted cells were used for training (exp 1 = 118 OFF cells, 66 ON cells; exp 2 = 142 OFF cells, 103 ON cells): two cells were removed due to data quality issues (see sec 3.3). Performance metrics in this paper are reported for the same subset of cells used in a previous study (Heitman et al., 2016). These cells passed passed a manual screen for spike sorting accuracy, demonstrated stable light responses, and met a convergence criteria in prior linear-nonlinear modeling (exp 1 = 10 OFF cells, 18 ON cells; exp 2 = 65 OFF cells, 14 ON cells). The naturalistic movie\nstimulus consisted of images from the Van Hateren database shown for one second each, with spatial jitter based on eye movements during fixation by awake macaque monkeys (Z.M. Hafed and R.J. Krauzlis, personal communication), (van Hateren & van der Schaaf, 1998). An example stimulus can be found at https://youtu.be/sG_18Uz_6OE. 59 distinct natural scenes movies of length one minute (the training data) were interleaved with 59 repetitions of a 30 second movie (the test data). Interleaving ensured that the test movie repetitions spanned the same period of time as the training data and therefore experienced the same range of experimental conditions (in case of neural response drifts over time). The first 4 movies shown (2 training movies and 2 repetitions of the test movie) were excluded to avoid initial transients. Test metrics are reported for the last 29 seconds of the 30 second test movie for the same reason. For further details on the experimental set-up, data preprocessing, and visual stimulation, see Heitman et al. (2016)."
    }, {
      "heading" : "3.2 MODEL TRAINING",
      "text" : "All models were implemented in Theano and trained on a combination of CPUs and GPUs (Theano Development Team, 2016). Training was performed using the Adam optimizer on the mean squared error (MSE) between predicted firing rate and true spikes (Kingma & Ba, 2014). We also experimented with optimizing a Poisson likelihood; this led to qualitatively similar results but occasionally less stable fits, so we focus on the MSE results here. All recurrent dynamics and temporal filters operated on time bins of 8.33 ms (the frame rate of the movie). Spike history terms and performance metrics were calculated for 0.833 ms bins. We used the same split of training and validation data for both experiments: 104 thirty-second movies as training data and 10 thirty-second movies as a held-out validation set.\nDuring training, the performance on the held-out validation set is checked after every pass through the training data. After each iteration through the training data, if the model exhibits significantly better validation performance than our previous best, we reset the minimum number of iterations to be twice the current iteration number. If we make it through those iterations without another significant improvement, we stop. We train for a maximum of 150 epochs, where we define one epoch as one pass through all the training data. The model with the best validation performance is saved and used to assess test performance. All models with shared parameters were trained on a combined MSE over\nall neurons and the parameters picked were those which minimized validation MSE for all neurons. For individual LNs/GLMs/RNNs, the validation MSE was minimized for each neuron separately."
    }, {
      "heading" : "3.3 RECEPTIVE FIELD CENTER ESTIMATION",
      "text" : "In all models used in this paper, we estimate the receptive field (RF) center of each neuron in order to identify the appropriate portion of the image to use as input. We calculate a 250 ms long spike triggered average (STA) using reverse correlation of the neuron’s spikes with a white noise stimulus. We reduce the noise in this STA by using a rank 1 approximation (singular value decomposition followed by reconstruction using the primary temporal and spatial components). We then smooth each frame of the STA via convolution with a Gaussian spatial filter. The center location is defined as the pixel location that has the maximum absolute magnitude over time. The center locations were visually assessed to check accuracy of the algorithm. Rare cases where the algorithm failed to identify the correct center indicated neurons that responded to very little of the image as their receptive field was more than half-way displaced out of the image. These two neurons (two Exp 1 ON cells) were removed from further analysis. If the receptive field center is close to the edge of the image, the image patch is padded with the average training stimulus value."
    }, {
      "heading" : "3.4 PERFORMANCE EVALUATION",
      "text" : "To quantitatively evaluate the accuracy of model spike predictions, we used the fraction of explainable variance, which has been described in previous literature (Heitman et al., 2016). Average firing rates over time are obtained after generating spikes from the model in 0.833 ms bins and smoothing with a Gaussian temporal filter (SD=10ms). The fraction of variance is computed as\nF (r, rs) = 1− ∑\nt(r(t)− rs(t))2∑ t(r(t)− µ)2\n(1)\nwhere r(t) is the smoothed recorded firing rate, rs(t) is the smoothed predicted firing rate, and µ is the average recorded rate. Finally, to account for the reproducibility of responses over repeated trials, we normalize by the fraction of variance captured by using the average firing rate on the odd (ro) trials of the repeated test movie to predict responses on the even (re) trials:\nFV = F (r, rs)\nF (re, ro) . (2)"
    }, {
      "heading" : "4 MODEL ANALYSIS",
      "text" : ""
    }, {
      "heading" : "4.1 NETWORK ARCHITECTURES",
      "text" : "Individual LNs and GLMs: The linear-nonlinear model (LN) consists of a spatiotemporal filtering of the 31x31x30 movie patch (Xt, width by height by time) surrounding the estimated center of the neuron’s receptive field plus a bias term (b), followed by a sigmoid nonlinearity (f ), and Poisson spike generation to produce the responses rt. The generalized linear model (GLM), given by\nrt ∼ Poiss [ f ( ~wTs (Xt ~wt) + b+ ∑ i hirt−i )] , (3)\nhas the same architecture with the addition of a post-spike history filter h before the nonlinearity f (Pillow et al., 2008). We used a rank 1 approximation of the full spatiotemporal filter (higher rank models did not significantly improve fits on a subset of examined neurons), resulting in a vectorized 31x31 spatial filter (~ws) and a 30 bin temporal filter (~wt) which spans 250 ms (Heitman et al., 2016). The post-spike history filter consists of a weighted sum of a basis of 20 raised cosines spanning approximately 100 ms (Pillow et al., 2008). The models with spike history were fit by initializing with the model fit without spike history. The filter either operates on the recorded spikes (training and validation) or the spikes generated by the model (testing). The nonlinearity is the logistic sigmoid: f = L/(1 + exp(−x)), which has been shown to improve fitting over an exponential nonlinearity for modeling RGC responses to natural scenes (Heitman et al., 2016).\nShared LN: In this model, the architecture is similar to the individual LNs but all cells of a given type (OFF or ON) share the same temporal and spatial filters (Figure 1A; note that the spatial filters are displaced to the RF center of each individual RGC). All other parameters are individually tuned for each observed neuron. There is an additional gain term that weights the output of the filtering individually for each observed neuron.\nTwo-layer RNN, 50 units: In this architecture, there are two recurrent neural network (RNN) layers between the image patch and Poisson neural unit:\n~h (1) j,t = max(0, U1~sj,t + V1 ~h (1) j,t−1 + ~c) (4)\n~h (2) j,t = max(0, U2 ~h (1) j,t + V2 ~h (2) j,t−1 + ~d) (5) rj,t ∼ Poiss [ f(~wTj ~h (2) j,t + bj) ] . (6)\nThe activity of the 50 units in the first RNN layer at time t is given by ~h(1)j,t in Eqn. 4. These units are rectified linear, and receive input from the vectorized 31x31 image patch surrounding the center of neuron j’s receptive field, ~sj,t, with weights U1, along with input from the other units in the layer with weights V1 and a bias ~c. The output of the first RNN is then fed into a second RNN with similar architecture. The firing rate for each observed neuron in the final layer is then given by Eqn. 6, and is a weighted sum of the recurrent units plus a bias bj , followed by a softplus nonlinearity f = log(1 + exp(−x)). Note that all parameters are shared across neurons except for the weights to the final layer and the final bias terms (~wj and bj).\nGLM-RNN Hybrid: The GLM-RNN hybrid model consists of a spatial filter followed by a two-layer RNN. The architecture resembles that of the full two-layer RNN with 50 units, except the input to the first layer is a scalar (post multiplication with the spatial filter) at each time step instead of the full image patch; thus the RNN in this model is responsible for shaping the temporal properties of the output, but does not affect spatial processing after the first linear spatial filtering stage. All weights\nare shared across neurons except for weights to the final layer (~wj) and the final bias terms (bj):\nyj,t = ~w T s ~sj,t (7)\n~h (1) j,t = max(0, ~u1yj,t + V1 ~h (1) j,t−1 + ~c) (8)\n~h (2) j,t = max(0, U2h (1) j,t + V2 ~h (2) j,t−1 + ~d) (9) rj,t ∼ Poiss [ f(~wTj ~h (2) t + bj) ] . (10)"
    }, {
      "heading" : "4.2 MODEL PERFORMANCE",
      "text" : "RNNs of varying architectures consistently outperformed LNs and GLMs in predicting neural spiking responses to a novel natural scene movie for both OFF and ON parasol retinal ganglion cells in both experiments (Figure 2). A shared two-layer recurrent network consistently captures around 80% of the explainable variance across experiments and cell types. Other recurrent architectures (1-3 layer RNNs and a 2 layer LSTM) led to similar levels of performance (Supplementary Figure 6). The increase in performance according to the fraction of explainable variance metric was not an average effect: almost all neurons were significantly better predicted by the RNN (Figure 2B). A 2 layer RNN model with additional trained spike history filters outperformed GLMs and LNs according to a normalized log likelihood metric (Supplementary Figure 7).\nInspection of the mean predicted firing rate traces for LNs and RNNs in Figure 3 reveals that the recurrent network seems to be capturing the timing of firing more precisely. The LN often predicts a general increase in firing rate at the correct times, but the RNN captures the sudden increase in firing rate followed by decay which often occurs when the image changes. On the other hand, the LN models sometimes predict modest increases or decreases in firing rate that the recurrent nets miss.\nUnderstanding why the recurrent models improve performance is a challenging task due to the black-box nature of deep networks. The first layer filters (U1, from image patches to recurrent units) have an interpretable structure resembling traditional receptive fields expected in the retina\n(Supplementary Figure 8). However, the computations performed by the recurrent units are difficult to tease apart, because the weights are less interpretable. Thus, instead of attempting a mechanistic explanation of the internals of the RNN, we focused on what additional captured information resulted in the improved RNN performance.\nOne possibility is that capturing nonlinear effects in parts of the image far from the receptive field center improved predictions (McIlwain, 1964; Passaglia et al., 2009). We restricted the size of the image patch surrounding each receptive field center from 31x31 to 15x15 (Supplementary Figure 9). Shared RNNs trained on the smaller image patch size did as well, or better, than those trained on the larger patch across almost all combinations of cell type and experiment. (We see a similar small improvement when training the LN models on the small patch.) Thus we concluded that long-range nonlinear spatial interactions do not contribute to the increased performance produced by the RNNs.\nWe also investigated whether nonlinear spatial interactions or nonlinear temporal processing primarily contributed to better predictions. To accomplish this, we constructed a GLM-RNN hybrid, described previously, in which a single spatial filter precedes a two-layer RNN - effectively allowing only temporal nonlinearities to be captured. This model improved prediction over the LNs and GLMs but did not reach full RNN performance. The amount by which this model closed the gap differed for different experiments and cell types. We quantified this by computing the difference between multitask RNN and multitask LN performance for each neuron and the difference between multitask hybrid and multitask LN performance. We divide the latter by the former (on a cell-by-cell basis) to obtain the ratios summarized in Figure 2C. The hybrid model closed greater than half of the gap on average between multitask LN and RNN performance, indicating that the richer temporal dynamics of the RNN model account for a large part of the difference between RNN and LN performance, though spatial nonlinearities play a role too."
    }, {
      "heading" : "5 MODEST TRAINING DATA LENGTH SUFFICES FOR GOOD PERFORMANCE",
      "text" : "Deep networks can be complex and often require large amounts of data to adequately train: convolutional neural networks used for object recognition are trained on over a million images (Krizhevsky et al., 2012). Standard neuroscience experiments yield limited data sets, so it is crucial to assess whether we have enough data to adequately fit our network architectures. We trained the RNN on varying amounts of data, and ran several different iterations of the network to explore variation over random initializations and randomly chosen training sets. These results are shown for both ON and OFF cells in Figure 4. Surprisingly small amounts of training data resulted in good predictive abilities. For larger amounts of training data, different iterations resulted in very similar mean fraction of variance values, indicating fairly robust fitting in these models. See Supplementary Figure 10 for further details."
    }, {
      "heading" : "6 BENEFITS OF MULTITASK FRAMEWORK",
      "text" : "We investigated whether the multitask framework with shared parameters across neurons actually helps to improve predictive performance with reasonable amounts of experimental data. First, we quantified the benefits of parameter-sharing in the simple LN model. This is a highly constrained\nframework: every cell has the same spatial and temporal filter. The shared LN does not improve performance for most neurons (Figure 5A).\nWe expected the multitask framework to be more helpful applied to the RNN model because in this case we are sharing features but not all parameters across neurons. Indeed, the multitask RNN consistently outperformed RNNs trained individually on single neurons (Figure 5B); individuallytrained RNNs also had much more variable losses than did the multitask-trained RNNs. In a realistic experimental setting with limited data, the multitask framework is a useful way to leverage all of the data collected for all neurons."
    }, {
      "heading" : "7 CONCLUSION",
      "text" : "Using retinal neurons responding to natural scenes as an example, we showed that: using deep networks to model neural spiking responses can significantly improve prediction over current state-ofthe-art models; sharing information across neurons in a multi-task framework leads to better and more stable predictions; and these models work well even given relatively small amounts of experimental data. We believe that the multitask RNN framework presented here will enable new, richer models of complex nonlinear spiking computations in other brain areas.\nWhile one could argue that we have merely exchanged the black box of the brain for another black box, just having a more predictive model is an important tool for research: these predictive models of the primate retina can be used in retinal prosthetics research, to probe decoding, and as a first stage of processing in the modeling of higher visual areas. Additionally, the recurrent network is more accessible and available for experimentation and quantitative analysis. For example, the trained neural network models may guide choices for more accurate simpler models by identifying key computational features that are important to include. Training smaller models on the denoised compression of spiking data (the predicted firing rate) may help them to learn features they otherwise would not (Ba & Caruana, 2014). The deep network approach allows one to determine types of information important to the neuron without having to build an exact mechanistic model of how such information is incorporated, as demonstrated by our finding that both spatial and temporal nonlinearities are not fully captured by the standard pseudo-linear models. We hope in future work to gain a more thorough and quantitative understanding of the dynamics captured by the recurrent networks and to extend this approach to higher sensory areas."
    }, {
      "heading" : "ACKNOWLEDGMENTS",
      "text" : "Funding for this research was provided by the National Science Foundation Graduate Research Fellowship Program under grant No. DGE-114747 (NB), Grant Number No. DGE-16-44869 (EB), the National Science Foundation IGERT Training Grant No. 0801700 (NB), the National Institutes of Health Grant EY017992 (EJC), NSF CRCNS IIS-1430239 (LP, EJC) and Google Faculty Research awards (LP, EJC); in addition, this work was supported by the Intelligence Advanced Research Projects Activity (IARPA) via Department of Interior/ Interior Business Center (DoI/IBC) contract number D16PC00003 (LP). The U.S. Government is authorized to reproduce and distribute reprints for Governmental purposes notwithstanding any copyright annotation thereon. Disclaimer: The views and conclusions contained herein are those of the authors and should not be interpreted as necessarily representing the official policies or endorsements, either expressed or implied, of IARPA, DoI/IBC, or the U.S. Government."
    } ],
    "references" : [ {
      "title" : "Do deep nets really need to be deep",
      "author" : [ "Jimmy Ba", "Rich Caruana" ],
      "venue" : "Advances in Neural Information Processing Systems,",
      "citeRegEx" : "Ba and Caruana.,? \\Q2014\\E",
      "shortCiteRegEx" : "Ba and Caruana.",
      "year" : 2014
    }, {
      "title" : "The mechanism of directionally selective units in rabbit’s retina",
      "author" : [ "HB Barlow", "William R Levick" ],
      "venue" : "The Journal of Physiology,",
      "citeRegEx" : "Barlow and Levick.,? \\Q1965\\E",
      "shortCiteRegEx" : "Barlow and Levick.",
      "year" : 1965
    }, {
      "title" : "A model of inductive bias learning",
      "author" : [ "Jonathan Baxter" ],
      "venue" : "Journal of Artificial Intelligence Research,",
      "citeRegEx" : "Baxter.,? \\Q2000\\E",
      "shortCiteRegEx" : "Baxter.",
      "year" : 2000
    }, {
      "title" : "Functional asymmetries in on and off ganglion cells of primate retina",
      "author" : [ "E.J. Chichilnisky", "Rachel S. Kalmar" ],
      "venue" : "The Journal of Neuroscience,",
      "citeRegEx" : "Chichilnisky and Kalmar.,? \\Q2002\\E",
      "shortCiteRegEx" : "Chichilnisky and Kalmar.",
      "year" : 2002
    }, {
      "title" : "A simple white noise analysis of neuronal light responses",
      "author" : [ "E.J. Chichilnisky" ],
      "venue" : "Network: Computation in Neural Systems,",
      "citeRegEx" : "Chichilnisky.,? \\Q2001\\E",
      "shortCiteRegEx" : "Chichilnisky.",
      "year" : 2001
    }, {
      "title" : "Natural stimulus statistics alter the receptive field structure of v1 neurons",
      "author" : [ "Stephen V. David", "William E. Vinje", "Jack L. Gallant" ],
      "venue" : "The Journal of Neuroscience,",
      "citeRegEx" : "David et al\\.,? \\Q2004\\E",
      "shortCiteRegEx" : "David et al\\.",
      "year" : 2004
    }, {
      "title" : "Triggered correlation",
      "author" : [ "de Boer R", "P Kuyper" ],
      "venue" : "IEEE Transactions on Biomedical Engineering,",
      "citeRegEx" : "R and Kuyper.,? \\Q1968\\E",
      "shortCiteRegEx" : "R and Kuyper.",
      "year" : 1968
    }, {
      "title" : "Spatial properties and functional organization of small bistratified ganglion cells in primate retina",
      "author" : [ "Greg D. Field", "Alexander Sher", "Jeffrey L. Gauthier", "Martin Greschner", "Jonathon Shlens", "Alan M. Litke", "E.J. Chichilnisky" ],
      "venue" : "The Journal of Neuroscience,",
      "citeRegEx" : "Field et al\\.,? \\Q2007\\E",
      "shortCiteRegEx" : "Field et al\\.",
      "year" : 2007
    }, {
      "title" : "Fidelity of the ensemble code for visual motion in primate retina",
      "author" : [ "E.S. Frechette", "A. Sher", "M.I. Grivich", "D. Petrusca", "A.M. Litke", "E.J. Chichilnisky" ],
      "venue" : "Journal of Neurophysiology,",
      "citeRegEx" : "Frechette et al\\.,? \\Q2005\\E",
      "shortCiteRegEx" : "Frechette et al\\.",
      "year" : 2005
    }, {
      "title" : "Testing pseudo-linear models of responses to natural scenes in primate retina",
      "author" : [ "Alexander Heitman", "Nora Brackbill", "Martin Greschner", "Alexander Sher", "Alan M. Litke", "E.J. Chichilnisky" ],
      "venue" : "bioRxiv,",
      "citeRegEx" : "Heitman et al\\.,? \\Q2016\\E",
      "shortCiteRegEx" : "Heitman et al\\.",
      "year" : 2016
    }, {
      "title" : "Long short-term memory",
      "author" : [ "Sepp Hochreiter", "Jürgen Schmidhuber" ],
      "venue" : "Neural Computation,",
      "citeRegEx" : "Hochreiter and Schmidhuber.,? \\Q1997\\E",
      "shortCiteRegEx" : "Hochreiter and Schmidhuber.",
      "year" : 1997
    }, {
      "title" : "Adam: A method for stochastic optimization",
      "author" : [ "Diederik P. Kingma", "Jimmy Ba" ],
      "venue" : "arXiv preprint,",
      "citeRegEx" : "Kingma and Ba.,? \\Q2014\\E",
      "shortCiteRegEx" : "Kingma and Ba.",
      "year" : 2014
    }, {
      "title" : "Deep neural networks: A new framework for modeling biological vision and brain information processing",
      "author" : [ "Nikolaus Kriegeskorte" ],
      "venue" : "Annual Review of Vision Science,",
      "citeRegEx" : "Kriegeskorte.,? \\Q2015\\E",
      "shortCiteRegEx" : "Kriegeskorte.",
      "year" : 2015
    }, {
      "title" : "Imagenet classification with deep convolutional neural networks",
      "author" : [ "Alex Krizhevsky", "Ilya Sutskever", "Geoffrey E Hinton" ],
      "venue" : "In Advances in Neural Information Processing Systems,",
      "citeRegEx" : "Krizhevsky et al\\.,? \\Q2012\\E",
      "shortCiteRegEx" : "Krizhevsky et al\\.",
      "year" : 2012
    }, {
      "title" : "What does the eye tell the brain?: Development of a system for the large-scale recording of retinal output activity",
      "author" : [ "A.M. Litke", "N. Bezayiff", "E.J. Chichilnisky", "W. Cunningham", "W. Dabrowski", "A.A. Grillo", "M. Grivich", "P. Grybos", "P. Hottowy", "S. Kachiguine", "R.S. Kalmar", "K. Mathieson", "D. Petrusca", "M. Rahman", "A. Sher" ],
      "venue" : "IEEE Transactions on Nuclear Science,",
      "citeRegEx" : "Litke et al\\.,? \\Q2004\\E",
      "shortCiteRegEx" : "Litke et al\\.",
      "year" : 2004
    }, {
      "title" : "White-noise analysis of a neuron chain: an application of the wiener theory",
      "author" : [ "P.Z. Marmarelis", "K. Naka" ],
      "venue" : "Science, 175:1276–1278,",
      "citeRegEx" : "Marmarelis and Naka.,? \\Q1972\\E",
      "shortCiteRegEx" : "Marmarelis and Naka.",
      "year" : 1972
    }, {
      "title" : "Receptive fields of optic tract axons and lateral geniculate cells: peripheral extent and barbiturate sensitivity",
      "author" : [ "James T. McIlwain" ],
      "venue" : "Journal of Neurophysiology,",
      "citeRegEx" : "McIlwain.,? \\Q1964\\E",
      "shortCiteRegEx" : "McIlwain.",
      "year" : 1964
    }, {
      "title" : "Deep convolutional neural network models of the retinal response to natural scenes",
      "author" : [ "Lane McIntosh", "Niru Maheswaranathan", "Aran Nayebi", "Surya Ganguli", "Stephen Baccus" ],
      "venue" : "In Cosyne Abstracts, Salt Lake City USA,",
      "citeRegEx" : "McIntosh et al\\.,? \\Q2016\\E",
      "shortCiteRegEx" : "McIntosh et al\\.",
      "year" : 2016
    }, {
      "title" : "Effects of remote stimulation of the modulated activity of cat retina",
      "author" : [ "CL. Passaglia", "Freeman DK", "Troy JB" ],
      "venue" : "Journal of Neuroscience,",
      "citeRegEx" : "Passaglia et al\\.,? \\Q2009\\E",
      "shortCiteRegEx" : "Passaglia et al\\.",
      "year" : 2009
    }, {
      "title" : "Spatio-temporal correlations and visual signalling in a complete neuronal population",
      "author" : [ "Jonathan W Pillow", "Jonathon Shlens", "Liam Paninski", "Alexander Sher", "Alan M Litke", "E.J. Chichilnisky", "Eero P Simoncelli" ],
      "venue" : null,
      "citeRegEx" : "Pillow et al\\.,? \\Q2008\\E",
      "shortCiteRegEx" : "Pillow et al\\.",
      "year" : 2008
    }, {
      "title" : "Spike-triggered neural characterization",
      "author" : [ "Odelia Schwartz", "Jonathan W. Pillow", "Nicole C. Rust", "Eero P. Simoncelli" ],
      "venue" : "Journal of Vision,",
      "citeRegEx" : "Schwartz et al\\.,? \\Q2006\\E",
      "shortCiteRegEx" : "Schwartz et al\\.",
      "year" : 2006
    }, {
      "title" : "Characterization of neural responses with stochastic stimuli, pp. 327–338",
      "author" : [ "Eero Simoncelli", "Jonathan W. Pillow", "Liam Paninski", "Odelia Schwartz" ],
      "venue" : null,
      "citeRegEx" : "Simoncelli et al\\.,? \\Q2004\\E",
      "shortCiteRegEx" : "Simoncelli et al\\.",
      "year" : 2004
    }, {
      "title" : "Independent component filters of natural images compared with simple cells in primary visual cortex. Proceedings",
      "author" : [ "J.H. van Hateren", "A. van der Schaaf" ],
      "venue" : "Biological sciences / The Royal Society,",
      "citeRegEx" : "Hateren and Schaaf.,? \\Q1998\\E",
      "shortCiteRegEx" : "Hateren and Schaaf.",
      "year" : 1998
    }, {
      "title" : "Performance-optimized hierarchical models predict neural responses in higher visual cortex",
      "author" : [ "Daniel LK Yamins", "Ha Hong", "Charles F Cadieu", "Ethan A Solomon", "Darren Seibert", "James J DiCarlo" ],
      "venue" : "Proceedings of the National Academy of Sciences,",
      "citeRegEx" : "Yamins et al\\.,? \\Q2014\\E",
      "shortCiteRegEx" : "Yamins et al\\.",
      "year" : 2014
    } ],
    "referenceMentions" : [ {
      "referenceID" : 4,
      "context" : "Subsequent efforts to characterize cells relied on white noise stimulation and building models through reverse correlation (de Boer R & Kuyper, 1968; Marmarelis & Naka, 1972; Chichilnisky, 2001).",
      "startOffset" : 123,
      "endOffset" : 194
    }, {
      "referenceID" : 4,
      "context" : "A standard model used to relate white noise to spiking responses is the linear-nonlinear-Poisson (LN) or generalized linear model (GLM) which consists of a spatiotemporal linear filtering of the stimulus followed by a nonlinearity and probabilistic spike generation (Chichilnisky, 2001; Simoncelli et al., 2004; Schwartz et al., 2006).",
      "startOffset" : 266,
      "endOffset" : 334
    }, {
      "referenceID" : 21,
      "context" : "A standard model used to relate white noise to spiking responses is the linear-nonlinear-Poisson (LN) or generalized linear model (GLM) which consists of a spatiotemporal linear filtering of the stimulus followed by a nonlinearity and probabilistic spike generation (Chichilnisky, 2001; Simoncelli et al., 2004; Schwartz et al., 2006).",
      "startOffset" : 266,
      "endOffset" : 334
    }, {
      "referenceID" : 20,
      "context" : "A standard model used to relate white noise to spiking responses is the linear-nonlinear-Poisson (LN) or generalized linear model (GLM) which consists of a spatiotemporal linear filtering of the stimulus followed by a nonlinearity and probabilistic spike generation (Chichilnisky, 2001; Simoncelli et al., 2004; Schwartz et al., 2006).",
      "startOffset" : 266,
      "endOffset" : 334
    }, {
      "referenceID" : 5,
      "context" : "Although this family of models have advanced our understanding, they do not optimally capture neural responses, especially to natural scenes which can lead to more complex responses than white noise stimuli (David et al., 2004).",
      "startOffset" : 207,
      "endOffset" : 227
    }, {
      "referenceID" : 9,
      "context" : "Even in the retina, early in the visual processing stream, these commonly-used models capture retinal ganglion cell (RGC) responses to natural stimuli less accurately than to white noise (Heitman et al., 2016).",
      "startOffset" : 187,
      "endOffset" : 209
    }, {
      "referenceID" : 13,
      "context" : "Recently, deep neural networks have been used to dramatically improve performance on a diverse array of machine learning tasks (Krizhevsky et al., 2012; LeCun et al., 2015).",
      "startOffset" : 127,
      "endOffset" : 172
    }, {
      "referenceID" : 12,
      "context" : "Furthermore, these networks bear a loose resemblance to real neural networks, and provide a sufficiently rich model class that can still be roughly constrained to match the biological architecture (Kriegeskorte, 2015).",
      "startOffset" : 197,
      "endOffset" : 217
    }, {
      "referenceID" : 23,
      "context" : "Most previous research at this intersection of neuroscience and artificial neural networks has focused on training networks on a certain task, such as object recognition, and then comparing the computations performed in different layers of the artificial network to those performed by real neurons (Yamins et al., 2014).",
      "startOffset" : 298,
      "endOffset" : 319
    }, {
      "referenceID" : 17,
      "context" : "Here we take a different approach: we fit multilayer models directly to the spiking responses of neurons, an approach that has not been explored in detail (but see (McIntosh et al., 2016) for some recent independent parallel developments).",
      "startOffset" : 164,
      "endOffset" : 187
    }, {
      "referenceID" : 19,
      "context" : "Our baseline comparisons are the GLM architectures that have been widely used to construct previous neural models (Pillow et al., 2008), though here we focus on individual neuronal responses (we leave modeling of correlations between neurons for future work).",
      "startOffset" : 114,
      "endOffset" : 135
    }, {
      "referenceID" : 2,
      "context" : "This is conceptually a form of multitask learning - we are using a shared representation to achieve better generalization (Baxter, 2000).",
      "startOffset" : 122,
      "endOffset" : 136
    }, {
      "referenceID" : 14,
      "context" : "Recordings were performed on isolated retina using a large-scale multi-electrode recording system (Litke et al., 2004; Frechette et al., 2005; Field et al., 2007).",
      "startOffset" : 98,
      "endOffset" : 162
    }, {
      "referenceID" : 8,
      "context" : "Recordings were performed on isolated retina using a large-scale multi-electrode recording system (Litke et al., 2004; Frechette et al., 2005; Field et al., 2007).",
      "startOffset" : 98,
      "endOffset" : 162
    }, {
      "referenceID" : 7,
      "context" : "Recordings were performed on isolated retina using a large-scale multi-electrode recording system (Litke et al., 2004; Frechette et al., 2005; Field et al., 2007).",
      "startOffset" : 98,
      "endOffset" : 162
    }, {
      "referenceID" : 14,
      "context" : "A standard spike sorting algorithm was used to identify spikes from different cells from the voltage signals on each electrode during visual stimulation (Litke et al., 2004).",
      "startOffset" : 153,
      "endOffset" : 173
    }, {
      "referenceID" : 9,
      "context" : "Performance metrics in this paper are reported for the same subset of cells used in a previous study (Heitman et al., 2016).",
      "startOffset" : 101,
      "endOffset" : 123
    }, {
      "referenceID" : 9,
      "context" : "For further details on the experimental set-up, data preprocessing, and visual stimulation, see Heitman et al. (2016).",
      "startOffset" : 96,
      "endOffset" : 118
    }, {
      "referenceID" : 9,
      "context" : "4 PERFORMANCE EVALUATION To quantitatively evaluate the accuracy of model spike predictions, we used the fraction of explainable variance, which has been described in previous literature (Heitman et al., 2016).",
      "startOffset" : 187,
      "endOffset" : 209
    }, {
      "referenceID" : 19,
      "context" : "has the same architecture with the addition of a post-spike history filter h before the nonlinearity f (Pillow et al., 2008).",
      "startOffset" : 103,
      "endOffset" : 124
    }, {
      "referenceID" : 9,
      "context" : "We used a rank 1 approximation of the full spatiotemporal filter (higher rank models did not significantly improve fits on a subset of examined neurons), resulting in a vectorized 31x31 spatial filter (~ ws) and a 30 bin temporal filter (~ wt) which spans 250 ms (Heitman et al., 2016).",
      "startOffset" : 263,
      "endOffset" : 285
    }, {
      "referenceID" : 19,
      "context" : "The post-spike history filter consists of a weighted sum of a basis of 20 raised cosines spanning approximately 100 ms (Pillow et al., 2008).",
      "startOffset" : 119,
      "endOffset" : 140
    }, {
      "referenceID" : 9,
      "context" : "The nonlinearity is the logistic sigmoid: f = L/(1 + exp(−x)), which has been shown to improve fitting over an exponential nonlinearity for modeling RGC responses to natural scenes (Heitman et al., 2016).",
      "startOffset" : 181,
      "endOffset" : 203
    }, {
      "referenceID" : 16,
      "context" : "One possibility is that capturing nonlinear effects in parts of the image far from the receptive field center improved predictions (McIlwain, 1964; Passaglia et al., 2009).",
      "startOffset" : 131,
      "endOffset" : 171
    }, {
      "referenceID" : 18,
      "context" : "One possibility is that capturing nonlinear effects in parts of the image far from the receptive field center improved predictions (McIlwain, 1964; Passaglia et al., 2009).",
      "startOffset" : 131,
      "endOffset" : 171
    }, {
      "referenceID" : 13,
      "context" : "5 MODEST TRAINING DATA LENGTH SUFFICES FOR GOOD PERFORMANCE Deep networks can be complex and often require large amounts of data to adequately train: convolutional neural networks used for object recognition are trained on over a million images (Krizhevsky et al., 2012).",
      "startOffset" : 245,
      "endOffset" : 270
    } ],
    "year" : 2017,
    "abstractText" : "Developing accurate predictive models of sensory neurons is vital to understanding sensory processing and brain computations. The current standard approach to modeling neurons is to start with simple models and to incrementally add interpretable features. An alternative approach is to start with a more complex model that captures responses accurately, and then probe the fitted model structure to understand the neural computations. Here, we show that a multitask recurrent neural network (RNN) framework provides the flexibility necessary to model complex computations of neurons that cannot be captured by previous methods. Specifically, multilayer recurrent neural networks that share features across neurons outperform generalized linear models (GLMs) in predicting the spiking responses of parasol ganglion cells in the primate retina to natural images. The networks achieve good predictive performance given surprisingly small amounts of experimental training data. Additionally, we present a novel GLM-RNN hybrid model with separate spatial and temporal processing components which provides insights into the aspects of retinal processing better captured by the recurrent neural networks.",
    "creator" : "LaTeX with hyperref package"
  }
}