{
  "name" : "1410.1228.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "Interactive Fingerprinting Codes and the Hardness of Preventing False Discovery",
    "authors" : [ "Thomas Steinke", "Jonathan Ullman" ],
    "emails" : [ "tsteinke@seas.harvard.edu.", "jullman@cs.columbia.edu." ],
    "sections" : [ {
      "heading" : null,
      "text" : "∗Harvard University School of Engineering and Applied Sciences. Supported by NSF grant CCF-1116616. Email: tsteinke@seas.harvard.edu. †Harvard University Center for Research on Computation and Society and Columbia University. Supported by NSF Grant CNS-1237235 and a Simons Society of Fellows Junior Fellowship. Email: jullman@cs.columbia.edu.\nar X\niv :1\n41 0.\n12 28\nv1 [\ncs .C\nR ]\n5 O\nct 2\nContents"
    }, {
      "heading" : "1 Introduction 1",
      "text" : "1.1 Discussion of Results . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2\n1.1.1 Techniques . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 3 1.2 Applications to Data Privacy . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 3 1.3 Related Work . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 4"
    }, {
      "heading" : "2 Interactive Fingerprinting Codes 5",
      "text" : "2.1 Definition and Existence . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 6 2.2 The Construction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 7 2.3 Analysis Overview . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 8\n2.3.1 Soundness . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 8 2.3.2 Completeness . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 9 2.3.3 Establishing Correlation . . . . . . . . . . . . . . . . . . . . . . . . . . . . 9\n2.4 Proof of Soundness . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 10 2.5 Proof of Completeness . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 13\n2.5.1 Biased Fourier Analysis . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 13 2.5.2 Robustness . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 15 2.5.3 Concentration . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 16 2.5.4 Bounding the Score . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 19"
    }, {
      "heading" : "3 Hardness of False Discovery 22",
      "text" : "3.1 The Statistical Query Model . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 22 3.2 Encryption Schemes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 23 3.3 Description of the Attack . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 23 3.4 Analysis of the Attack . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 23 3.5 An Information-Theoretic Lower Bound . . . . . . . . . . . . . . . . . . . . . . . 27"
    }, {
      "heading" : "4 Hardness of Avoiding Blatant Non Privacy 28",
      "text" : "4.1 Blatant Non Privacy and Sample Accuracy . . . . . . . . . . . . . . . . . . . . . . 28 4.2 Lower Bounds . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 28 4.3 An Information-Theoretic Lower Bound . . . . . . . . . . . . . . . . . . . . . . . 33\nReferences 33\nA Security Reductions from Sections 3 and 4 34"
    }, {
      "heading" : "1 Introduction",
      "text" : "Empirical research is commonly done by asking multiple “queries” (e.g., summary statistics, hypothesis tests, or learning algorithms) on a finite sample drawn from some population. “False discovery” occurs if the outcome of the queries on the sample does not reflect the population. For example, if a certain irrelevant gene is believed to be predictive for cancer based on the sample. For decades statisticians have been devising methods for preventing false discovery, such as the “Bonferroni correction” [Bon36, Dun61] and the widely used and highly influential method of Benjamini and Hochberg [BH95] for controlling the “false discovery rate.”\nNevertheless, false discovery persists across all empirical sciences, and both popular and scientific articles report on an increasing number of invalid research findings. Typically false discovery is attributed to misuse of statistics. However, another possible explanation—recently proposed by Dwork et al. [DFH+14] and Hardt and Ullman [HU14]—is that methods for preventing false discovery do not address the fact that modern data analysis is inherently adaptive. The queries made, the experimental setup, and the selection and tuning of the algorithms all depend on previous interactions with the data. [DFH+14] gave methods for preventing false discovery in some cases, while [HU14] showed contrasting hardness results suggesting that there may be an inherent computational barrier to preventing false discovery. In this work we give a new, nearly optimal hardness result, showing that the algorithms of Dwork et al. [DFH+14] are nearly optimal in the worst case.\nThese results are formalized in Kearns’ statistical-query (SQ) model [Kea93]. In the SQ model, there is an algorithm called the oracle that gets access to n samples from an unknown distribution D over some finite universe {0,1}d , where the parameter d is the dimensionality of the distribution. The oracle must answer statistical queries about D. A statistical query q is specified by a predicate p : X → {0,1} and the answer to a statistical query is q(D) = E\nx∼D [p(x)] .\nThe oracle’s answer a to a query q is accurate if |a − q(D)| ≤ α with high probability. Importantly, the goal of the oracle is to provide answers that “generalize” to the underlying distribution rather than answers that are specific to the sample. The latter is easy to achieve by outputting the empirical average of the query predicate on the sample.\nThe analyst makes a sequence of queries q1,q2, . . . , qk to the oracle, which responds with answers a1, a2, . . . , ak . In the adaptive setting, the analyst receives each answer ai to qi before the next query is asked, so qi+1 may depend on q1, a1,q2, a2, . . . , qi , ai . We say the oracle is accurate given n samples for k adaptively chosen queries, if when given n samples from an arbitrary distribution D, the oracle accurately responds to any adaptive analyst that makes at most k queries. A computationally efficient oracle answers each query in time polynomial in n and d.1\nWhen the queries q1,q2, . . . , qk are specified non adaptively (i.e. independent of a1, a2, . . . , ak), then the empirical average of each query on the sample is accurate with high probability as long as k ≤ 2o(n). However, this guarantee no longer holds in the interactive setting and a more sophisticated oracle is required.\nThe results of Dwork et al. [DFH+14] gave a surprising way to construct an accurate oracle, by showing that any oracle that satisfies differential privacy [DMNS06] and provides accurate answers with respect to the sample, also provides accurate answers with respect to the underlying distribution. Using known constructions of differentially private algorithms, they obtain a computationally efficient algorithm that is accurate for Ω̃(n2) queries, and a computationally inefficient algorithm that is accurate for nearly 2n queries.\n1We assume that the analyst asks queries that can be evaluated on the sample in polynomial time.\nIt was already known that computationally efficient differentially private algorithms could not answer more than Õ(n2) queries [Ull13], but differentially privacy may not be necessary at all. Unfortunately, [HU14] showed that no computationally efficient algorithm could answer too many more queries. Specifically, assuming the existence of one-way functions, there is no computationally efficient oracle that answers more than Õ(n3) queries.\nIn this work we resolve this gap almost completely, and show that, assuming the existence of one-way functions, there is no efficient oracle that answers O(n2) queries. Conceptually, our result gives further evidence that there may be an inherent computational barrier to preventing false discovery in interactive data analysis. It also shows that when answering arbitrary adaptively chosen statistical queries, one cannot do better than to use a differentially private algorithm in the worst case. We believe it is an intriguing open question to see whether this sort of equivalence holds in more restricted settings. Finally, as a consequence of our results, we obtain a dichotomy for privacy preserving data analysis in the adaptive setting. There is a computationally efficient differentially private algorithm that answers Ω̃(n2) arbitrary adaptive queries, but, assuming the existence of one-way functions, every computationally efficient algorithm that answers O(n2) arbitrary adaptive queries is blatantly non private.\nTo prove our result, we modify the adversary used in [HU14]. First, we abstract the combinatorial properties required by their adversary into a new combinatorial object that we call an interactive fingerprinting code. Then, we give a nearly optimal construction of interactive fingerprinting codes, which is the main technical contribution of our work."
    }, {
      "heading" : "1.1 Discussion of Results",
      "text" : "Our main result is the following nearly optimal hardness result for preventing false discovery in interactive data analysis.\nTheorem 1.1 (Informal). Assuming the existence of one-way functions, there is no computationally efficient oracle that given n samples is accurate on O(n2) adaptively chosen queries.\nAs in [HU14], our hardness result applies whenever the dimensionality of the data grows with the sample size faster than logarithmically so that 2d is no longer polynomial in n.2 This requirement is rather mild, and is also necessary. If n 2d then the empirical distribution of the n samples will be close to the underlying distribution in statistical distance, so every statistical query can be answered accurately given the sample. Thus, the dimensionality of the data has a major effect on the hardness of the problem. [HU14] also showed that if the dimensionality is much larger than n, then we cannot even hope for a computationally unbounded oracle that provides accuracy on adaptive queries. We obtain a nearly optimal version of that result.\nTheorem 1.2 (Informal). There is no oracle (even a computationally unbounded one) that given n samples in dimension d =O(n2) is accurate on O(n2) adaptively chosen queries.\nThis result should be contrasted with the aforementioned result of Dwork et al. [DFH+14] showing that if d n2 then there is an oracle that runs in time polynomial in n and 2d and accurately answers nearly 2n adaptive queries.\n2This is under the stronger, but still standard, assumption that exponentially hard one-way functions exist."
    }, {
      "heading" : "1.1.1 Techniques",
      "text" : "The structure of our proof is rather simple, and closely follows the framework in [HU14]. We will design a challenge distribution D and a computationally efficient adaptive analyst A who knows D. If any computationally efficient oracle O is given n samples S = {x1, . . . ,xn} drawn from D, then our analyst A can use the answers of O to reconstruct the set S. Using this information, the adversary can construct a query on which S is not representative of D.\nOur adversary A and the distribution D, like that of [HU14], is built from a combinatorial object with a computational “wrapper.” The computational wrapper is cryptographic queries which “hide” information from the oracle O. The combinatorial object is what we call an interactive fingerprinting code, which we introduce.\nInteractive fingerprinting codes (IFPCs) are an abstraction of the technique in [HU14]. They generalize fingerprinting codes, which were introduced by Boneh and Shaw [BS98] for the problem of watermarking digital content. Our main contribution is to define and construct IFPCs.\nAn interactive fingerprinting code F is an efficient interactive algorithm that defeats any adversary P (called the pirate) with high probability in the following game. The adversary P picks S ⊂ [N ] unknown to F . The goal of F is to identify S by making ` interactive queries to P . F specifies each query by a vector c ∈ {±1}N . In response, the adversary P must simply output a ∈ {±1} such that a = ci for some i ∈ [N ]. However, the adversary is restricted to only see ci for i ∈ S. At any time, F may accuse some i ∈ [N ]. If i ∈ S is accused, then i is removed from S (i.e. S ← S\\{i}), thereby further restricting P . If i < S is accused, then this is referred to as a false accusation. To win, the interactive fingerprinting code F must identify all of S, without making “too many” false accusations.\nThe difference between interactive and non interactive fingerprinting codes is that a non interactive fingerprinting code must give all ` queries to P at once, but is (necessarily) only required to identify one i ∈ S.\n[HU14] implicitly construct an interactive fingerprinting code with ` = Õ(N3) by concatenatingN independent copies of a non interactive fingerprinting code. We give a construction of an interactive fingerprinting codes using the optimal O(N2) queries based on the construction of non interactive fingerprinting codes by [Tar08].\nTheorem 1.3 (Informal). For everyN , there exists an interactive fingerprinting code with ` =O(N2) that, except with negligible probability, makes at most N/1000 false accusations.\nThis result suffices for our applications, but our construction is somewhat more general and has several additional parameters, which we detail in Section 2."
    }, {
      "heading" : "1.2 Applications to Data Privacy",
      "text" : "The adversary used to show hardness of preventing false discovery is effectively carrying out a reconstruction attack against the database of samples. Roughly, if there is an adversary who can reconstruct the set of samples S from the oracle’s answers, then the oracle is said to be “blatantly non-private”—it reveals essentially all of the data it holds, and so cannot guarantee any reasonable notion of privacy to the owners of the data. Since the seminal work of Dinur and Nissim [DN03], such reconstruction attacks have been used to establish strong limitations on the accuracy of privacy-preserving oracles.\nUsing interactive fingerprinting codes, combined with the framework of [HU14], we obtain the following results. In both cases, [HU14] show similar results, in which our O(n2) bounds are replaced with Õ(n3).\nTheorem 1.4 (Informal). Assuming the existence of one-way functions, every computationally efficient oracle that, given n samples, is accurate on O(n2) adaptively chosen queries is blatantly non private.\nTheorem 1.4 should be compared with the result in [Ull13], which showed that any computationally efficient oracle that, given n samples, is accurate for Õ(n2) non-adaptively chosen queries cannot satisfy the strong guarantee of “differential privacy” [DN03, DMNS06]. Theorem 1.4 shows that, in the adaptive setting, we can obtain a stronger privacy violation using fewer queries than [Ull13].\nTheorem 1.5 (Informal). Every (possibly computationally unbounded) oracle that, given n samples in dimension d =O(n2), is accurate on O(n2) adaptively chosen queries is blatantly non private.\nTheorem 1.5 should be compared with the result in [BUV14] that showed any (possibly computationally unbounded) oracle that answers a fixed family of Õ(n2) simple queries in dimension d = Õ(n2) cannot satisfy differential privacy.\nIn contrast with Theorems 1.4 and 1.5, the well-known result of [DMNS06] shows that there is an efficient differentially private algorithm that answers Ω̃(n2) adaptively chosen queries. Our results show that, in the adaptive setting, there is a sharp threshold for the number of queries where, below this threshold, the strong notation of differential privacy can be achieved and, above this threshold, even minimal notions of privacy are unachievable."
    }, {
      "heading" : "1.3 Related Work",
      "text" : "Our work and [HU14] build on techniques for attacking allegedly privacy preserving algorithms. These works showed a surprising tension between methods for secure content-distribution and privacy-preserving algorithms. This connection first appeared in the work of Dwork, Naor, Reingold, Rothblum, and Vadhan [DNR+09], who showed that the existence of traitor-tracing schemes [CFN94] implies hardness results for differential privacy. This connection was expanded and strengthened in [Ull13], which introduced the use of fingerprinting codes in the context of differential privacy, and used them to prove nearly optimal hardness results for certain problems in differential privacy. Bun et al. [BUV14] showed that fingerprinting codes can be used to prove nearly-optimal information-theoretic lower bounds for differential privacy, which established fingerprinting codes as the key information-theoretic object underlying lower bounds in differential privacy.\nInteractive fingerprinting codes are similar in spirit to the work of Fiat and Tassa [FT01] on dynamic traitor-tracing. They too used the power of adaptivity to reconstruct the entire set of samples, as opposed to only one sample. Technically their results are incomparable to ours, and their techniques do not suffice in our setting. Specifically, they allowed codewords over a large alphabet, c ∈ [N ]N , and achieve a length of Õ(N ). This large alphabet generalization is fundamentally different, and does not lead to hardness results for answering adaptive queries. This is inherent, since, by [DFH+14], there is no hardness result for answering Õ(N ) queries.3\nThe algorithms of Dwork et al. [DFH+14] rely on known differentially private mechanisms for answering adaptive statistical queries. Recently, [Ull14] showed how to design differentially private mechanisms for answering exponentially many adaptively chosen queries\n3This problem is not merely an artifact of restricting the data to distributions over {±1}. Even if we were to consider more general distributions over [N ], the methods of Fiat and Tassa [FT01] inherently do not suffice. Queries over [N ] are equivalent to queries over {±1}logN , whereas the large alphabet is fundamental to the analysis in Fiat and Tassa and cannot be straightforwardly replaced by the binary alphabet.\nfrom the richer class of convex empirical risk minimization queries. By the results of Dwork et al. [DFH+14], this algorithm is also a (computationally inefficient) oracle that is accurate for exponentially many adaptively chosen convex empirical risk minimization queries.\nOrganization In Section 2 we define and construct interactive fingerprinting codes, the main new technical ingredient we use to establish our results. In Sections 3 and 4 we show how interactive fingerprinting codes can be used to obtain hardness results for preventing false discovery and blatant non privacy, respectively. The definition of interactive fingerprinting codes is contained in Section 2.1 and is necessary for Sections 3 and 4, but the remainder of Section 2 and Sections 3 and 4 can be read in either order."
    }, {
      "heading" : "2 Interactive Fingerprinting Codes",
      "text" : "In order to motivate the definition of interactive fingerprinting codes, it will be helpful to review the motivation for standard, non-interactive fingerprinting codes.\nFingerprinting codes were introduced by Boneh and Shaw [BS98] for the problem of watermarking digital content (such as a movie or a piece of software). Consider a company that distributes some content to N users. Some of the users may illegally distribute copies of the content. To combat this, the company gives each user a unique version of the content by adding distinctive “watermarks” to it. Thus, if the company finds an illegal copy, it can be traced back to the user who originally purchased it. Unfortunately, users may be able to remove the watermarks. In particular, a coalition of users may combine their copies in a way that mixes or obfuscates the watermarks. A fingerprinting code ensures that, even if up to n users collude to combine their codewords, an illegal copy can be still be traced to at least one of the users.\nFormally, every user i ∈ [N ] is given a codeword (c1i , c 2 i , . . . , c ` i ) ∈ {±1} ` by the fingerprinting code, which represents the combination of watermarks in that user’s copy. A subset S ⊂ [N ] of at most n users can arbitrarily combine their codewords to create a “pirate codeword” a = (a1, a2, . . . , a`) ∈ {±1}`. The only constraint is so-called consistency—for every j ∈ [`], if, for every colluding user i ∈ S, we have cji = b, then a\nj = b. That is to say, if each of the colluding users receives the same watermark, then their combined codeword must also have that watermark. Given a, the fingerprinting code must be able to trace at least one user i ∈ S. Tardos [Tar08] constructed optimal fingerprinting codes with ` =O(n2 logN ).\nA key drawback of fingerprinting codes is that we can only guarantee that a single user i ∈ S is traced. This is inherent, as setting the pirate codeword a to be the codeword of a single user prevents any other user from being identified. We will see that this can be circumvented by moving to an interactive setting.\nSuppose the company is instead distributing a stream of content (such as a TV series) to N users—that is, the content is not distributed all at once and the illegal copies are obtained whilst the content is being distributed (e.g. the episodes of the TV series appear on the internet before the next episode is shown). Again, the content is watermarked so that each user receives a unique stream and a subset S ⊂ [N ] of at most n users combine their streams and distribute an illegal stream. The company obtains the illegal stream and uses this to trace the colluding users S. As soon as the company can identify a colluding user i ∈ S, that user’s stream is terminated (e.g. their subscription is cancelled). This process continues until every i ∈ S has been traced and the distribution of illegal copies ceases.\nAnother twist on fingerprinting codes is robustness [BUV14]. Suppose that the consistency constraint only holds for (1 − β)` choices of j ∈ [`]. That is to say, the colluding users can somehow remove a β fraction of the watermarks. [BUV14] showed how to modify the Tardos fingerprinting code to be robust to a small constant fraction of inconsistencies. In this work, we show that robustness to any β < 1/2 fraction of inconsistencies can be achieved."
    }, {
      "heading" : "2.1 Definition and Existence",
      "text" : "We are now ready to formally define interactive fingerprinting codes. To do so we make use of the following game between an adversary P and the fingerprinting code F . Both P and F may be stateful. For a given execution of F , we let C ∈ {±1}N×` be the matrix with columns c1, . . . , c`\nand let a ∈ {±1}` be the vector with entries a1, . . . , a`. We want to construct the fingerprinting code so that, if a is consistent, then the tracer succeeds in recovering every user in S. For convenience, we will define the notation θj to be the number of rounds 1, . . . , j in which aj is not consistent with cj . Formally, for a given execution of F ,\nθj = ∣∣∣∣{1 ≤ k ≤ j ∣∣∣ @ i ∈ [N ], ak = cki }∣∣∣∣ .\nUsing this notation, a is β-consistent if θ` ≤ β`. We also define the notation ψj to be the number of users in I1, . . . , I j who are falsely accused (i.e. not in the coalition S1). Formally,\nψj = ∣∣∣∣∣∣∣∣  ⋃ 1≤k≤j Ik  \\ S1 ∣∣∣∣∣∣∣∣ .\nUsing this notation, we require ψ` ≤ δN - that is, the tracing algorithm does not make too many false accusations.\nDefinition 2.1 (Interactive Fingerprinting Codes). We say that an algorithm F is an n-collusionresilient interactive fingerprinting code of length ` for N users robust to a β fraction of errors with failure probability ε and false accusation probability δ if for every adversary P , it holds that\nP IFPCN,n,`[P ,F ]\n[( θ` ≤ β` ) ∨ ( ψ` > δN )] ≤ ε\nThe length ` may depend on N,n,β,ε,δ.\nThe constraint ψ` ≤ δN is called soundness—the interactive fingerprinting code should not make (many) false accusations. The constraint θ` > β` is called completeness—the interactive fingerprinting code should force the adversary P to be inconsistent. Although it may seem strange that we make no reference to recovering the coalition S1, notice that if Sj , ∅, then P can easily be consistent. Therefore, if the pirate cannot be consistent, it must be the case that Sj = ∅ for some j, meaning all of S1 has been accused.\nIn the remainder of this section, we give a construction of interactive fingerprinting codes, and establish the following theorem.\nTheorem 2.2 (Existence of Interactive Fingerprinting Codes). For every 1 ≤ n ≤ N , 0 ≤ β < 1/2, and 0 < δ ≤ 1, there is a n-collusion-resilient interactive fingerprinting code of length ` for N users robust to a β fraction of errors with failure probability ε ≤min{δN,2−Ω(δN )}+ δΩ(( 1 2−β)n) and false accusation probability δ for\n` =O n2 log(1/δ)(1 2 − β )4  .\nThe expression for the failure probability ε is a bit mysterious. To interpret it, we fix β = 1/2 −Ω(1) and consider two parameter regimes: δN 1 and δN 1. In the traditional parameter regime for fingerprinting codes δN = ε′ 1, and so no users are falsely accused. Then our fingerprinting code has length O(n2 log(N/ε′)) and a failure probability of ε′. However, if we are willing to tolerate falsely accusing a small constant fraction of users, then we can set, for example, δN = .01N , and our fingerprinting code will have lengthO(n2) and failure probability 2−Ω(n)."
    }, {
      "heading" : "2.2 The Construction",
      "text" : "Our construction and analysis is based on the optimal (non interactive) fingerprinting codes of Tardos [Tar08], and the robust variant by Bun et al. [BUV14]. The code is essentially the same, but columns are generated and shown to the adversary one at a time, and tracing is modified to identify users interactively.\nWe begin with some definitions and notation. For 0 ≤ a < b ≤ 1, let Da,b be the distribution with support (a,b) and probability density function µ(p) = Ca,b/ √ p(1− p), where Ca,b is a normalising constant.4 For α,ζ ∈ (0,1/2), let Dα,ζ be the distribution on [0,1] that returns a sample from Dα,1−α with probability 1− 2ζ and 0 or 1 each with probability ζ.\nFor p ∈ [0,1], let c ∼ p denote that c ∈ {±1} is drawn from the distribution with P [c = 1] = p and P [c = −1] = 1− p. Let c1···n ∼ p denote that c ∈ {±1}n is drawn from a product distribution in which ci ∼ p independently for all i ∈ [n].\nDefine φp : {±1} →R by φ0(c) = φ1(c) = 0 and, for p ∈ (0,1), φp(1) = √\n(1− p)/p and φp(−1) = − √ p/(1− p). The function φp is chosen so that φp(c) has mean 0 and variance 1 when c ∼ p. The fingerprinting code F is defined in Figure 2. In addition to the precise setting of parameters, we have given asymptotic bounds to help follow the analysis. We now analyze F and establish Theorem 2.2. The proof of Theorem 2.2 is split into Theorems 2.7 and 2.17. For convenience, define I = ⋃ j∈[`] I j .\n4To sample from Da,b, first sample ϕ ∈ (sin−1( √ a),sin−1( √ b)) uniformly, then output sin2(ϕ) as the sample."
    }, {
      "heading" : "2.3 Analysis Overview",
      "text" : "Intuitively, the quantity sji , which we call the score of user i, measures the “correlation” between the answers (a1, · · · , aj ) of P and the i-th codeword (c1i , · · · , c j i ), using a particular measure of correlation that takes into account the choices p1, . . . ,pj . If sji ever exceeds the threshold σ , meaning that the answers are significantly correlated with the i-th codeword, then we accuse user i. Thus, our goal is to show two things: Soundness, that the score of an innocent user (i.e. i < S1) never exceeds the threshold, as the answers cannot be correlated with the unknown i-th codeword. And completeness, that the score of every guilty user (i.e. i ∈ S1) will at some point exceed the threshold, meaning that the answers must correlate with the i-th codeword for every i ∈ S1."
    }, {
      "heading" : "2.3.1 Soundness",
      "text" : "The proof of soundness closely mirrors Tardos’ analysis [Tar08] of the non-interactive case. If i is innocent, then, since P doesn’t see the codeword (c1i , · · · , c j i ) of the i th user, there cannot be too much correlation. In this case, one can show that sji is the sum of j independent random variables, each with mean 0 and variance 1, where we take the answers a1, . . . , aj as fixed and the randomness is over the choice of the unknown codeword. By analogy to Gaussian random\nvariables, one would expect that sji ≤ σ = Θ( √ ` log(1/δ)) with probability at least 1−δ. Formally, the fact that the score in each round is not bounded prevents the use of a Chernoff bound. But nonetheless, in Section 2.4, we prove soundness using a Chernoff-like tail bound for sji ."
    }, {
      "heading" : "2.3.2 Completeness",
      "text" : "To prove completeness, we must show that, for guilty users i ∈ S1, we have sji > σ for some j ∈ [`] with high probability. In Sections 2.5.1 and 2.5.3, we prove that if P gives consistent answers in a 1− β fraction of rounds, then the sum of the scores for each of the guilty users is large. Specifically, in Theorem 2.15, we prove that with high probability∑\ni∈S1 s`i ≥Θ (`) (1)\nThe constants hidden by the asymptotic notation are set to imply that, for at least one i ∈ S1, the score s`i is above the threshold σ = Θ (`/n). This step is not too different from the analysis of Tardos and Bun et al. [Tar08, BUV14] for the non-interactive case. To show that, for every i ∈ S1, we will have sji > σ at some point, we must depart from the analysis of non-interactive fingerprinting codes. If sji > σ , and user i is accused in round j, then the adversary will not see the suffix of codeword (cj+1i , · · · , c ` i ). By the same argument that was used to prove soundness, the answers will not be correlated with this suffix, so with high probability the score s`i does not increase much beyond σ . Thus,∑\ni∈S1 s`i ≤ n ·O(σ ) = Θ (`) . (2)\nThe hidden constants are set to ensure that Equation (2) conflicts with Equation (1). Thus, we can conclude that P cannot give consistent answers for a 1 − β fraction of rounds. That is to say, P is forced to be inconsistent because all of S1 is accused and eventually P sees none of the codewords and is reduced to guessing an answer aj ."
    }, {
      "heading" : "2.3.3 Establishing Correlation",
      "text" : "Proving Equation (1) is key to the analysis. Our proof thereof combines and simplifies the analyses of [Tar08] and [BUV14]. For this high level overview, we ignore the issue of robustness and fix β = 0.\nFirst we prove that the correlation bound holds in expectation and then we show that it holds with high probability using an Azuma-like concentration bound. (Again, as the random variables being summed are not bounded, we are forced to use a more tailored analysis to prove concentration.) We show that it holds in expectation for each round. In Proposition 2.12, we show that the concentration grows in expectation in each round. For every j ∈ [`],\nE ∑ i∈S1 s j i − s j−1 i  = E ∑ i∈S1 aj ·φp j (cji )  ≥Ω(1), (3) where the expectations are taken over the randomness of pj , cj , and aj . Equation (3), combined with a concentration result, implies Equation (1).\nThe intuition behind Equation (3) and the choice of pj is as follows. Consistency guarantees that, if cji = b for all i ∈ S\n1, then aj = b. This is a weak correlation guarantee, but it suffices to ensure correlation between aj and ∑ i∈S1 c j i . The affine scaling φ pj ensures that φp j (cji ) has mean zero (i.e. is uncorrelated with a constant) and and unit variance (i.e. has unit correlation with itself). The expectation of aj ·φpj (cji ) can be interpreted as the i-th first-order Fourier coefficient of aj as a function of cj . To understand first-order Fourier coefficients, consider the “dictator” function: Suppose aj = cji∗ for some i ∗ ∈ S1 - that is, P always outputs the i∗-th bit. Then\nE aj ,cj ,pj aj ∑ i∈S1 φp j (cji )  = Ecj ,pj [ c j i∗ ·φ pj (cji∗) ] = E pj [ 2 √ pj(1− pj ) ] = Θ(1).\nThis example can be generalised to aj being an arbitrary function of cjS1 using Fourier analysis. This calculation also indicates why we choose the probability density function of pj ∼ Dα,1−α to be proportional to 1/ √ p(1− p).\nTo handle robustness (β > 0) we use the ideas of [BUV14]. With probability 2ζ each round is a “special” constant round—i.e. cj = (1)N or cj = (−1)N . Otherwise it is a “normal” round where cj is sampled as before. Intuitively, the adversary P cannot distinguish the special rounds from the normal rounds in which c happens to be constant. If the adversary gives inconsistent answers on normal rounds, then it must also give inconsistent answers on special rounds. Since there are many more special rounds than normal rounds, this means that a small number of inconsistencies in normal rounds implies a large number of inconsistencies on special rounds. Conversely, inconsistencies are absorbed by the special rounds, so we can assume there are very few inconsistencies in normal rounds. Thus P is forced to behave consistently on the normal rounds and the analysis on these rounds proceeds as before."
    }, {
      "heading" : "2.4 Proof of Soundness",
      "text" : "We first show that no user is falsely accused except with probability δ/2. This boils down to proving a concentration bound. Then another concentration bound shows that with high probability at most a δ fraction of users are falsely accused.\nThese concentrations bounds are essentially standard. However, we are showing concentration of sums of variables of the form φp(c), which may be quite large if p ≈ 0 or p ≈ 1. This technical problem prevents us from directly applying standard concentration bounds. Instead we open up the standard proofs and verify the desired concentration. We take the usual approach of bounding the moment generating function and using that to give a tail bound. Lemma 2.3. For p ∈ [α,1−α]∪ {0,1} and t ∈ [− √ α/2, √ α/2], we have\nE c∼p\n[ etφ p(c) ] ≤ et 2 .\nProof. If p ∈ {0,1}, φp = 0 and the result is trivial. We have E c∼p [φp(c)] = 0, E c∼p\n[ φp(c)2 ] = 1,\nand, for c ∈ {±1}, |φp(c)| ≤ 1/ √ α. In particular, |φp(c) · t| ≤ 1/2. For u ∈ [−1/2,1/2], we have eu ≤ 1 +u +u2. Thus\nE c∼p\n[ etφ p(c) ] ≤ 1 + t E\nc∼p [φp(c)] + t2 E c∼p\n[ φp(c)2 ] = 1 + t2 ≤ et 2 .\nLemma 2.4. Let p1 · · ·pm ∈ [α,1 − α] ∪ {0,1} and c1 · · ·cm drawn independently with ci ∼ pi . Let a1 · · ·am ∈ [−1,1] be fixed. For all λ ≥ 0, we have\nP ∑ i∈[m] aiφ pi (ci) ≥ λ  ≤ e−λ2/4m + e−√αλ/4. Proof. By Lemma 2.3, for all t ∈ [− √ α/2, √ α/2],\nE c\n[ et ∑ i∈[m] aiφ pi (ci ) ] ≤ ∏ i∈[m] E ci [ etaiφ pi (ci ) ] ≤ et 2m.\nBy Markov’s inequality,\nP ∑ i∈[m] aiφ pi (ci) ≥ λ  ≤ E [ et ∑ i∈[m] aiφ pi (ci ) ] etλ ≤ et 2m−tλ.\nSet t = min{ √ α/2,λ/2m}. If λ ∈ [0,m √ α], then\nP ∑ i∈[m] aiφ pi (ci) ≥ λ  ≤ e−λ2/4m. On the other hand, if λ ≥m √ α, then\nP ∑ i∈[m] aiφ pi (ci) ≥ λ  ≤ eαm/4−√αλ/2 ≤ e−√αλ/4. The result is obtained by adding these expressions.\nThe following theorem shows how we can beat the union bound for tail bounds on partial sums.\nTheorem 2.5 (Etemadi’s Inequality [Ete85]). Let X1 · · ·Xn ∈ R be independent random variables. For k ∈ [n], define Sk = ∑ i∈[k]Xi to be the k th partial sum. Then, for all λ > 0,\nP [ max k∈[n] |Sk | > 4λ ] ≤ 4 ·max k∈[n] P [|Sk | > λ] .\nProposition 2.6 (Individual Soundness). For all i ∈ [N ], we have P [ i ∈ I \\ S1 ] ≤ 8(e−σ 2/64` + e−σ √ α/16) ≤ δ/2,\nwhere the probability is taken over IFPCN,N,`[P ,FN,n,δ,β] for an arbitrary P .\nProof. Let i ∈ [N ] \\ S1. Since the adversary does not see cji for any j ∈ [`], we may treat the answers of the adversary as fixed and analyse sji as if c j i was drawn after the actions of the adversary are fixed. Thus, by Lemma 2.4, for every j ∈ [`],\nP [ s j i > σ 4 ] = P ∑ k∈[j] akφp k (cki ) > σ 4  ≤ e−σ2/64` + e−σ√α/16.\nLikewise P [ s j i < − σ 4 ] ≤ e−σ2/64` + e−σ √ α/16. Thus, by Theorem 2.5,\nP [i ∈ I] ≤ P [ max j∈[`] |sji | > σ ] ≤ 4max j∈[`] P [ |sji | > σ 4 ] ≤ 8(e−σ 2/64` + e−σ √ α/16) ≤ δ 2 .\nTheorem 2.7 (Soundness). We have P [ |I \\ S1| > δN ] ≤min { δN,e−δN/8 } ,\nwhere the probability is taken over IFPCN,N,`[P ,FN,n,δ,β] for an arbiratry P .\nInterestingly, this theorem does not require |S1| ≤ n – that is, it holds with respect to IFPCN,N,`[P ,FN,n,δ,β], rather than IFPCN,n,`[P ,FN,n,δ,β]. It only requires that F does not see the codewords of users not in S1.\nProof. Let Ei ∈ {0,1} be the indicator of the event i ∈ I\\S1. The Eis for i ∈ [N ] are independent (conditioned on the choice of S1 and pj for j ∈ [`]). Moreover, by Proposition 2.6, E [Ei] ≤ δ/2 for all i ∈ [N ]\\S1. Thus, by a Chernoff bound,\nP [ |I\\S1| > δN ] = P  ∑ i∈[N ] Ei > δN  ≤ e−δN/8. If δ < 1/N , then this is a very poor bound. Instead we use the fact that the Eis are discrete\nand Markov’s inequality, which amounts to a union bound. For δN < 1, we have\nP [ |I\\S1| > δN ] = P [ |I\\S1| ≥ 1 ] ≤ E  ∑ i∈[N ] Ei  ≤ δN2 ≤ δN.\nThe following lemma will be useful later.\nLemma 2.8. For i ∈ [N ], let ji ∈ [` + 1] be the first j such that i < Sj , where we define S`+1 = ∅. For any S ⊂ [N ],\nP ∑ i∈S s`i − s ji−1 i > λ  ≤ e−λ2/4|S |` + e−√αλ/4, where the probability is taken over IFPCN,N,`[P ,FN,n,δ,β] for an arbitrary P . Proof. We have ∑ i∈S s`i − s ji−1 i = ∑ i∈S ∑ j∈[`] I(j ≥ ji)ajφp j (cji ).\nAgain, since the adversary doesn’t see cji for j ≥ ji , the random variables I(j ≥ ji)a j and φp j (cji ) are independent, so we can view I(j ≥ ji)aj ∈ [−1,1] as fixed. Now the result follows from Lemma 2.4."
    }, {
      "heading" : "2.5 Proof of Completeness",
      "text" : "To show that the fingerprinting code identifies guilty users we must lower bound the scores∑ i∈S1 s ` i . First we bound their expectation and then their tails."
    }, {
      "heading" : "2.5.1 Biased Fourier Analysis",
      "text" : "For this section, assume that the adversary P is always consistent - that is, we have no robustness and β = 0. Robustness will be added in Section 2.5.2. Here we establish that the scores have good expectation, namely\nE ∑ i∈S1 s j i − s j−1 i  ≥Ω(1) for all j ∈ [`]. The score s`i computes the ‘correlation’ between the bits given to user i and the output of the adversary. We must show that that the adversary’s consistency constraint implies that there exists some correlation on average.\nIn this section we deviate from the proof in [Tar08]. We use biased Fourier analysis to give a more intuitive proof of the correlation bound.\nWe have the following lemma and proposition, which relate the correlation aj · ∑ i∈S1φ\npj (cji ) to the properties of aj as a function of pj . To interpret these imagine that f represents the adversary P with one round viewed in isolation – the fingerprinting code gives the adversary cj and the adversary responds with f (cj\nSj ).\nFirstly, the following lemma gives an interpretation of the correlation value for a fixed pj .\nLemma 2.9. Let f : {±1}n→R. Define g : [0,1]→R by g(p) = E c1···n∼p [f (c)]. For any p ∈ (0,1),\nE c1···n∼p f (c) ·∑ i∈[n] φp(ci)  = g ′(p)√p(1− p). Proof. For p ∈ (0,1) and s ⊂ [n], define φps : {±1}n→ R by φ p s (c) = ∏ i∈sφ p(ci). The functions φ p s form an orthonormal basis with respect to the product distribution with bias p – that is,\n∀s, t ⊂ [n] E c1···n∼p\n[ φ p s (c) ·φ p t (c) ] = { 1 s = t 0 s , t } .\nThus, for any p ∈ (0,1), we can write f in terms of these basis functions: ∀c ∈ {±1}n f (c) = ∑ s⊂[n] f̃ p(s)φps (c),\nwhere ∀s ⊂ [n] f̃ p(s) = E\nc1···n∼p\n[ f (c)φps (c) ] .\nThis decomposition is a generalisation of Fourier analysis to biased distributions [O’D14, §8.4].\nFor p,q ∈ (0,1), the expansion of f gives the following expressions for g(q), g ′(q) and g ′(p).\ng(q) = E c1···n∼q [f (c)] = ∑ s⊂[n] f̃ p(s) E c1···n∼q [ φ p s (c) ] =\n∑ s⊂[n] f̃ p(s) ∏ i∈s E c∼q [φp(c)]\n= ∑ s⊂[n] f̃ p(s) ( q √ 1− p p − (1− q) √ p 1− p )|s| .\ng ′(q) = ∑\ns⊂[n]:s,∅ f̃ p(s) · |s| ·\n( q √ 1− p p − (1− q) √ p 1− p )|s|−1 · (√ 1− p p + √ p 1− p ) .\ng ′(p) = ∑\ns⊂[n]:s,∅ f̃ p(s) · |s| · 0|s|−1 ·\n(√ 1− p p + √ p 1− p )\n= ∑ i∈[n] f̃ p({i}) · (√ 1− p p + √ p 1− p ) .\nNote that f̃ p({i}) = E c1···n∼p [f (c)φp(ci)] and, hence,\nE c1···n∼p f (c) ·∑ i∈[n] φp(ci)  = ∑ i∈[n] f̃ p({i}) = g ′(p)√\n1−p p +\n√ p\n1−p\n= g ′(p) √ p(1− p).\nNow we can interpret the correlation for a random pj ∼Da,b. Proposition 2.10. Let f : {±1}n→ R. Define g : [0,1]→ R by g(p) = E\nc1···n∼p [f (c)]. For any 0 ≤ a <\nb ≤ 1,\nE p∼Da,b  Ec1···n∼p f (c) ·∑\ni∈[n] φp(ci)   = g(b)− g(a)2sin−1(√b)− 2sin−1(√a) ≥ g(b)− g(a)π .\nThis effectively follows by integrating Lemma 2.9. Proof. Let µ(p) = Ca,b/ √ p(1− p) be the probability density function for the distribution Da,b on the interval (a,b). By Lemma 2.9 and the fundamental theorem of calculus, we have\nE p∼Da,b  Ec1···n∼p f (c) ·∑\ni∈[n] φp(ci)\n  = Ep∼Da,b [g ′(p)√p(1− p)]\n= ∫ b a g ′(p) √ p(1− p)µ(p)dp\n=Ca,b ∫ b a g ′(p)dp =Ca,b · (g(b)− g(a)).\nIt remains to show that Ca,b = ( 2sin−1( √ b)− 2sin−1( √ a) )−1 ≥ 1/π. This follows from observing that\nC−1a,b = ∫ b a 1√ p(1− p) dp = ∫ b a ( d dp 2sin−1( √ p) ) dp = 2sin−1( √ b)− 2sin−1( √ a)\nand C−1a,b ≤ C −1 0,1 = 2sin −1(1)− 2sin−1(0) = π.\nNow we have a lemma to bring consistency into the picture. If f is consistent, b ≈ 1, and a ≈ 0, then g(b)− g(a) ≈ g(1)− g(0) = f ((1)n)− f ((−1)n) = 1− (−1) = 2. This gives a lower bound on the correlation for consistent f .\nLemma 2.11. Let f : {±1}n → {±1}. Define g : [0,1] → [−1,1] by g(p) = E c1···n∼p [f (c)]. Suppose α ∈ [0,1]. Then |g(1−α)− g(1)| ≤ 2nα and |g(α)− g(0)| ≤ 2nα.\nProof. We have P c1···n∼1−α\n[X = (1)n] = (1−α)n and\ng(1−α)− g(1) =f ((1)n) · P c1···n∼1−α [c = (1)n] + E c1···n∼p [f (c)|c , (1)n] · P c1···n∼1−α [c , (1)n]− g(1)\n=g(1) · (1−α)n + E c1···n∼p [f (c)|c , (1)n] · (1− (1−α)n)− g(1) = ( g(1)− E\nc1···n∼p [f (c)|c , (1)n]\n) · ((1−α)n − 1) .\nNow ∣∣∣∣∣g(1)− Ec1···n∼p [f (c)|c , (1)n] ∣∣∣∣∣ ≤ 2 and |(1−α)n − 1| ≤ nα, whence |g(1−α)− g(1)| ≤ 2nα. The other half of the lemma is symmetric."
    }, {
      "heading" : "2.5.2 Robustness",
      "text" : "We require the fingerprinting code to be robust to inconsistent answers. We show that the correlation is still good in the presence of inconsistencies.\nFor f : {±1}n→ {±1}, define a random variable ξα,ζ(f ) by ξα,ζ(f ) = f (c) · ∑ i∈[n] φp(ci) +γI (p ∈ {0,1} ∧ f (c) , 2p − 1) , p ∼Dα,ζ , c1···n ∼ p,\nwhere I is the indicator function and γ ∈ (0,1/2) satisfies ζγ/2 = (1− 2ζ)/π - that is,\nγ := 2 π 1− 2ζ ζ .\nThe first term f (c) · ∑ i∈[n]φ\np(ci) measures the correlation as before. The second term γI (p ∈ {0,1} ∧ f (c) , 2p − 1) measures inconsistencies. We will lower bound the expectation of ξα,ζ(f ), which amounts to saying “either there is good correlation or there is an inconsistency with good probability.” Thus either the fingerprinting code is able to accuse users or the adversary is forced to be inconsistent.\nThe following bounds the expected increase in scores from one round of interaction.\nProposition 2.12. Let f : {±1}n→ {±1} and α,ζ ∈ (0,1/2). Then\nE [ ξα,ζ(f ) ] ≥ 2 π (1− 2ζ)(1− 2nα).\nProof. Define g : [0,1]→ [−1,1] by g(p) = E c1···n∼p [f (c)]. Now\nE [ ξα,ζ(f ) ] = P p∼Dα,ζ [p = 0] ·γI(f ((−1)n) = 1) + P p∼Dα,ζ [p = 1] ·γI(f ((1)n) = −1)\n+ P p∼Dα,ζ [p ∈ [α,1−α]] · E p∼Dα,1−α  Ec1···n∼p f (c) ·∑ i∈[n] φp(ci)  \n=ζ ·γ (I(g(0) = 1) + I(g(1) = −1))\n(by Proposition 2.10) + (1− 2ζ) · g(1−α)− g(α)\n2sin−1( √ 1−α)− 2sin−1( √ α) ≥ζ ·γ (\n1 + g(0) 2 + 1− g(1) 2\n) + (1− 2ζ) ·\ng(1−α)− g(α) π\n= 1− 2ζ π (1 + g(0) + 1− g(1) + g(1−α)− g(α)) ≥1− 2ζ π (2− |g(α)− g(0)| − |g(1−α)− g(1)|)\n(by Lemma 2.11) ≥1− 2ζ π (2− 4nα)."
    }, {
      "heading" : "2.5.3 Concentration",
      "text" : "So far we have shown that the fingerprinting code achieves good correlation or the adversary is not consistent in expectation. However, we need this to hold with high probability. Thus we now show that sums of ξα,ζ(f ) variables concentrate around their expectation.\nAgain, the proofs in this section are standard. However, the ξα,ζ(f ) variables can be quite unwieldy and we are thus unable to apply standard results directly. So instead we must open the proofs and verify that the concentration bounds hold. We proceed by bounding the moment generating function of ξα,ζ(f ) and then proving an Azuma-like concentration inequality. These calculations are not novel or insightful. Proposition 2.13. Let f : {±1}n→ {±1}, α ∈ (0,1/2), ζ ∈ [1/4,1/2), and t ∈ [− √ α/8, √ α/8]. Then\nE [ e t(ξα,ζ(f )−E[ξα,ζ(f )]) ] ≤ eCt 2 ,\nwhere C = 64e nα/4\nα .\nProof. We have ξα,ζ(f ) = f (c) · ∑ i∈[n] φp(ci) +γI (p ∈ {0,1} ∧ f (c) , 2p − 1) , p ∼Dα,ζ , c1···n ∼ p.\nLet Y = ∑ i∈[n]φ p(ci). By Lemma 2.3 and independence,\nE [ etY ] = E c1···n∼p [ et ∑ i∈[n]φ p(ci ) ] = ( E c∼p [ etφ p(c) ])n ≤ et 2n\nfor t ∈ [− √ α/2, √ α/2]. Pick t ∈ {± √ α/2} such that\n∞∑ k=0 t2k+1 (2k + 1)! E [ Y 2k+1 ] ≥ 0.\nThen by dropping positive terms, for all j ≥ 1,\n0 ≤ E [ Y 2j ] ≤\n(2j)! t2j ∞∑ k=0 tk k! E [ Y k ] = (2j)! t2j E [ etY ] ≤ (2j)! t2j ent 2 = 4j(2j)! αj enα/4.\nThus we have bounded the even moments of Y . By Cauchy-Schwartz, for k = 2j + 1 ≥ 3,\nE [ |Y |k ] ≤ √ E [ Y 2j ] ·E [ Y 2j+2 ] ≤ √ 4j(2j)! αj enα/4 · 4j+1(2j + 2)! αj+1 enα/4 = 2kk! αk/2 enα/4 √ k + 1 k .\nSince |f (c)| ≤ 1, we have E [ |f (c) ·Y |k ] ≤ E [ |Y |k ] ≤ 2k+1k!enα/4/αk/2 for all k ≥ 2. Since ζ ∈\n[1/4,1/2), we have γ = (2/π)(1 − 2ζ)/ζ ∈ (0,1). Hence E [ |γI (p ∈ {0,1} ∧ f (c) , 2p − 1) |k ] ≤ 1 for\nall k. The map u 7→ |u|k is convex for all k ≥ 2, thus |(x + y)/2|k ≤ (|x|k + |y|k)/2 for all k ≥ 2 and x,y ∈R. Combining these three facts, we have\nE [ |ξα,ζ(f )|k ] ≤ 2k−1E [ |f (c) ·Y |k + |γI(f (c) , f ∗(c))|k ] ≤ 2 2kk!enα/4\nαk/2 + 2k−1 ≤ 2\n2k+1k!enα/4\nαk/2 .\nFor t ∈ [− √ α/8, √ α/8], we have\nE [ etξα,ζ(f ) ] ≤1 + tE [ ξα,ζ(f ) ] + ∞∑ k=2 |t|k k! E [ |ξα,ζ(f )|k ] ≤1 + tE [ ξα,ζ(f )\n] + ∞∑ k=2 |t|k k! 22k+1k!enα/4 αk/2\n=1 + tE [ ξα,ζ(f ) ] + 2enα/4 ∞∑ k=2 ( 4|t| √ α )k ≤1 + tE [ ξα,ζ(f ) ] + 2enα/4\n∞∑ k=2 ( 4|t| √ α )2 2−(k−2)\n=1 + tE [ ξα,ζ(f ) ] + 64enα/4\nα t2\n≤etE[ξα,ζ(f )]+Ct 2\nTheorem 2.14 (Azuma-Doob Inequality). Let X1 · · ·Xm ∈ R, µ1 · · ·µmR and U0 · · ·Um ∈Ω be random variables such that, for all i ∈ [m],\n• Xi is determined by Ui ,\n• µi is determined by Ui−1, and\n• Ui−1 is determined by Ui .\nSuppose that, for all i ∈ [m], u ∈Ω, and t ∈ [−c,c],\nE [ et(Xi−µi ) | Ui−1 = u ] ≤ eCt 2 .\nIf λ ∈ [0,2Cmc], then\nP  ∣∣∣∣∣∣∣∣ ∑ i∈[m] (Xi −µi) ∣∣∣∣∣∣∣∣ ≥ λ  ≤ 2e−λ2/4Cm.\nIf λ ≥ 2Cmc, then\nP  ∣∣∣∣∣∣∣∣ ∑ i∈[m] (Xi −µi) ∣∣∣∣∣∣∣∣ ≥ λ  ≤ 2emCc2−cλ ≤ 2e−cλ/2.\nProof. First we show by induction on k ∈ [m] that, for all u ∈Ω and t ∈ [−c,c],\nE [ et ∑m i=m−k+1(Xi−µi ) | Um−k = u ] ≤ ek·Ct 2 .\nThis clearly holds for k = 1, as this is our supposition for i = m. Now suppose this holds for some k ∈ [m− 1]. For u ∈Ω and t ∈ [−c,c], we have\nE [ et ∑m i=m−k(Xi−µi ) | Um−(k+1) = u ] = ∑ v∈Ω P [Um−k = v | Um−k−1 = u]E [ et ∑m i=m−k(Xi−µi ) | Um−k = v ] = ∑ v∈Ω P [v | u]E [ et(Xm−k−µm−k)et ∑m i=m−k+1(Xi−µi ) | v\n] (using shorthand v ≡ Um−k = v and u ≡ Um−k−1 = u)\n= ∑ v∈Ω P [v | u]E [ et(Xm−k−µm−k) | v ] E [ et ∑m i=m−k+1(Xi−µi ) | v ] (since Um−k = v determines Xm−k and µm−k)\n≤ ∑ v∈Ω P [v | u]E [ et(Xm−k−µm−k) | v ] ek·Ct 2\n(by the induction hypothesis) =E [ et(Xm−k−µm−k) | u ] ek·Ct 2\n≤eCt 2 ek·Ct 2\n(by our supposition for i =m− k)\n=e(k+1)·Ct 2 .\nThus, for all t ∈ [−c,c], we have E [ et ∑m i=1(Xi−µi ) ] ≤ em·Ct 2 .\nBy Markov’s inequality we have\nP ∑ i∈[m] (Xi −µi) ≥ λ  ≤ E [ et ∑ i∈[m](Xi−µi ) ] etλ ≤ emCt 2−tλ\nand\nP ∑ i∈[m] (Xi −µi) ≤ −λ  ≤ E [ e−t ∑ i∈[m](Xi−µi ) ] e(−t)(−λ) ≤ emCt 2−tλ\nfor all t ∈ [0, c] and λ > 0. Set t = min{c,λ/2mC} to obtain the result."
    }, {
      "heading" : "2.5.4 Bounding the Score",
      "text" : "Now we can finally show that the scores are large with high probability.\nTheorem 2.15 (Correlation Lower Bound). At the end of IFPCN,n,`[P ,FN,n,δ,β] for arbitrary P , we have, for any λ ∈ [0,17.5`/ √ α],\nγθ` + ∑ i∈S1 s`i ≥ 2 π (1− 2ζ)(1− 2nα)` −λ\nwith probability at least 1− 2e− λ2α 280` .\nProof. Since the adversary P is computationally unbounded and arbitrary, we may assume it is deterministic. We may also assume n = |S1| and that the adversary is able to see cjS1 at each round. (This only gives the adversary more power.)\nThis means that for each j ∈ [`] we can define a function f j : {±1}n→ {±1} that only depends on the interaction up to round j − 1 (i.e. is a function of the state of P before it receives cj ) and satisfies f j(cj\nSj ) = aj . For j ∈ [`], define\nXj := γ · I ( pj ∈ {0,1} ∧ f j(cjS1) , 2p j − 1 ) + f j(cjS1) · ∑ i∈S1 φp j (cji ) ∼ ξα,ζ(f j ),\nwhere ∼ denotes having the same distribution. We have γ · (θj −θj−1) + ∑ i∈S1 (sji − s j−1 i ) ≤ Xj\nand γθ` + ∑ i∈S1 s`i ≤ ∑ j∈[`] Xj ∼ ∑ j∈[`] ξα,ζ(f j ).\nNow we can apply the above lemmas to bound the expectation and tail of this random variable. Firstly, Proposition 2.12 shows that\nµj := E [ Xj ] = E [ ξα,ζ(f j ) ] ≥ 2 π (1− 2ζ)(1− 2nα)\nfor all f j . Moreover, by Proposition 2.13,\nE [ et(X j−µj ) ] = E [ e t(ξα,ζ(f j )−E[ξα,ζ(f j )]) ] ≤ eCt 2\nfor all t ∈ [− √ α/8, √ α/8], where C = 70/α ≥ 64enα/4/α, as α ≤ 1/4n.\nDefine Uj = (f 1,p1, c1, · · · , f j ,pj , cj , f j+1) for j ∈ [`]∪{0}. Now X1 · · ·X`, µ1 · · ·µ`, and U0, · · · ,U` satisfy the hypotheses of Theorem 2.14 with C = 70/α, c = √ α/8, and m = `.\nFor λ ∈ [0,2Cmc] = [0,17.5`/ √ α], we have\nP ∑ j∈[`] Xj ≤ 2 π (1− 2ζ)(1− 2nα)` −λ  ≤ P  ∣∣∣∣∣∣∣∣ ∑ i∈[m] (Xi −µi) ∣∣∣∣∣∣∣∣ ≥ λ  ≤ 2e−λ2/4Cm ≤ 2e− λ2α280` ,\nas required.\nHowever, we can also prove that the scores are small with high probability. This follows from the fact that users with large scores are accused and therefore no user’s score can be too large:\nLemma 2.16. For all λ > 0,\nP ∑ i∈S1 s`i > λ+nσ + n √ α  ≤ e−λ2/4n` + e−√αλ/4, where the probability is taken over IFPCN,n,`[P ,FN,n,δ,β] for an arbitrary P .\nWe will set λ = σ and, since 1/ √ α ≤ σ , we get that ∑ i∈S1 s ` i ≤ 3σn with high probability.\nProof. Let ji ∈ [`+ 1] be as in Lemma 2.8 – that is, i < Sji and i ∈ Sji−1, where we define S`+1 = ∅ and S0 = [N ]. By the definition of ji , sj , and Sj , we have s ji−2 i ≤ σ for all i ∈ S 1, as otherwise i ∈ I ji−2 and therefore i < Sji−1 = Sji−2\\I ji−2. If i ∈ S1, then ji = 1 and s ji−1 i = 0. Thus∑\ni∈S1 s ji−1 i = ∑ i∈S1 s ji−2 i + a ji−1φp ji−1(cji−1i ) ≤ ∑ i∈S1 σ + 1 √ α ≤ nσ + n√ α .\nBy Lemma 2.8,\nP ∑ i∈S1 s`i − s ji−1 i > λ  ≤ e−λ2/4n` + e−√αλ/4. The lemma follows.\nNow we show that the conflicting bounds of Theorem 2.15 and Lemma 2.16 imply completeness - that is, the adversary P cannot be consistent.\nTheorem 2.17 (Completeness). At the end of IFPCN,n,`[P ,FN,n,δ,β] for an arbitrary P , we have θ` > β` with probability at least 1− δ 1 2 ( 12−β)n, assuming ( 1 2 − β ) n ≥ 1.\nProof. Suppose for the sake of contradiction that θ` ≤ β`. By Lemma 2.16, ∑ i∈S1 s ` i ≤ λ+nσ+ n√ α with probability at least 1− e−λ2/4n` − e− √ αλ/4. Set λ = nσ ≥ n√\nα . Now we assume∑ i∈S1 s`i ≤ 3nσ,\nwhich holds with probability at least 1− e−nσ2/4` − e− √ αnσ/4. Then\nγθ` + ∑ i∈S1 s`i ≤ γβ` + 3nσ. (4)\nBy Theorem 2.15, with probabilty at least 1− 2e− λ2α 280` ,\nγθ` + ∑ i∈S1 s`i ≥ 2 π (1− 2ζ)(1− 2nα)` −λ (5)\nfor all λ ∈ [0,17.5`/ √ α]. Set λ = ( 1 2 − β )2 `/2π and assme Equation (5) also holds.\nCombining Equations (4) and (5) gives\n2 π (1− 2ζ)(1− 2nα)` −\n( 1 2 − β )2 2π ` ≤ γβ` + 3nσ. (6)\nWe claim this is a contradiction, which then holds with high probability, thus proving the theorem.\nRearranging Equation (6) gives\n2 π (1− 2ζ)(1− 2nα) ≤\n( 1 2 − β )2 2π +γβ + 3nσ ` . (7)\nOur setting of parameters gives\n2nα ≤\n( 1 2 − β ) 2\nand 3nσ ` ≤\n( 1 2 − β )2 2π .\nSubstituting these into Equation (7) gives\n2 π\n(1− 2ζ) ( 1− 1\n2 (1 2 − β )) ≤\n( 1 2 − β )2 π +γβ. (8)\nNow we use 1 − 2ζ = 12 ( 1 2 − β ) and γ = 2π 1−2ζ ζ = ( 12−β) πζ to derive a contradiction from Equation (8): ( 1 2 − β\n) π ( 1− 1 2 (1 2 − β )) ≤ ( 1 2 − β )2 π + ( 1 2 − β ) πζ β,\n1− 1 2 (1 2 − β ) ≤ (1 2 − β ) + β ζ ,\nζ ( 1− 3\n2 (1 2 − β )) ≤β.\nSince ζ = 12 − 1 4 ( 1 2 − β ) , we have\nζ ( 1− 3\n2 (1 2 − β )) = 1 2 ( 1− 1 2 (1 2 − β ))( 1− 3 2 (1 2 − β )) > 1 2 ( 1− 2 (1 2 − β )) .\nAnd β =\n1 2\n( 1− 2 (1 2 − β )) .\nThis gives a contradiction. The total failure probability is bounded by\ne−nσ 2/4` + e− √ αnσ/4 + 2e−λ 2α/280` ≤ ( δ\n32\n)16n + ( δ\n32\n)4n + 2 ( δ 32 ) 1 2 ( 12−β)n ≤ δ 1 2 ( 12−β)n,\nassuming (\n1 2 − β\n) n ≥ 1."
    }, {
      "heading" : "3 Hardness of False Discovery",
      "text" : ""
    }, {
      "heading" : "3.1 The Statistical Query Model",
      "text" : "Given a distribution D over {0,1}d , we would like to answer statistical queries about D. A statistical query on {0,1}d is specified by a function q : {0,1}d → [−1,1] and (abusing notation) is defined to be\nq(D) = E x←RD [q(x)] .\nOur goal is to design an oracle O that answers statistical queries onD using only iid samples x1, . . . ,xn←R D. Our focus is the case where the queries are chosen adaptively and adversarially.\nSpecifically, O is a stateful algorithm that holds a collection of samples x1, . . . ,xn ∈ {0,1}d , takes a statistical query q as input, and returns a real-valued answer a ∈ [−1,1]. We require that when x1, . . . ,xn are iid samples from D, the answer a is close to q(D), and moreover that this condition holds for every query in an adaptively chosen sequence q1, . . . , q`. Formally, we define the following game between an O and a stateful adversary A.\nDefinition 3.1 (Accuracy). An oracle O is (α,β,γ)-accurate for ` adaptively chosen queries given n samples in {0,1}d if for every adversary A,\nP Accn,d,`[O,A]\n[ For (1− β)` choices of j, ∣∣∣O(x,qj )− qj(D)∣∣∣ ≤ α] ≥ 1−γ . As a shorthand, we will say that O is (α,β)-accurate for ` queries if for every n,d ∈ N, O is (α,β,on(1))-accurate for ` queries given n samples in {0,1}d . Here, ` may depend on n and d and on(1) is a function of n that tends to 0.\nWe are interested in oracles that are both accurate and computationally efficient. We say that an oracle O is computationally efficient if when given samples x1, . . . ,xn ∈ {0,1}d and a query q : {0,1}d → [−1,1] it runs in time poly(n,d, |q|). Here q will be represented as a circuit that evaluates q(x) and |q| denotes the size of this circuit."
    }, {
      "heading" : "3.2 Encryption Schemes",
      "text" : "Our attack relies on the existence of a semantically secure private-key encryption scheme. An encryption scheme is a triple of efficient algorithms (Gen,Enc,Dec) with the following syntax:\n• Gen is a randomized algorithm that takes as input a security parameter λ and outputs a λ-bit secret key. Formally, sk←R Gen(1λ).\n• Enc is a randomized algorithm that takes as input a secret key and a messagem ∈ {−1,0,1} and outputs a ciphertext ct. Formally, ct←R Enc(sk,m).\n• Dec is a deterministic algorithm that takes as input a secret key and a ciphertext ct and outputs a decrypted message m′. If the ciphertext ct was an encryption of m under the key sk, then m′ =m. Formally, if ct←R Enc(sk,m), then Dec(sk,ct) =m with probability 1.\nRoughly, security of the encryption scheme asserts that no polynomial time adversary who does not know the secret key can distinguish encryptions of m = 0 from encryptions of m = 1, even if the adversary has access to an oracle that returns the encryption of an arbitrary message under the unknown key. For convenience, we will require that this security property holds simultaneously for an arbitrary polynomial number of secret keys. The existence of an encryption scheme with this property follows immediately from the existence an ordinary semantically secure encryption scheme. We start with the stronger definition only to simplify our proofs. A secure encryption scheme exists under the minimal cryptographic assumption that one-way functions exist. The formal definition of security is not needed until Section A."
    }, {
      "heading" : "3.3 Description of the Attack",
      "text" : "The adversary is specified in Figure 4. In Figure 4, (Gen,Enc,Dec) is an encryption scheme and F is an n-collusion resilient interactive fingerprinting code for N users of length ` = `(N ) robust to a β fraction of errors with false accusation probability δ = 1/8. Observe that Attackn,d is only well defined for pairs n,d ∈ N for which 1 + dlog2(2000n)e ≤ d, so that there exists a suitable choice of λ ∈ N. Through this section we will assume that n = n(d) is a polynomial in d and that d is a sufficiently large unspecified constant, which ensures that Attackn,d is well defined."
    }, {
      "heading" : "3.4 Analysis of the Attack",
      "text" : "We will start by establishing that the number of falsely accused users is small. That is, letting ψ` denote the number of users in T ` who are not in the set S, we have ψ` ≤ N/8 with high probability. This condition will follow from the security of the interactive fingerprinting code F . However, security alone is not enough to guarantee that the number of falsely accused users is small, because security of F applies to adversaries that only have access to cji for users i ∈ S \\ T j , whereas the queries to the oracle depend on cji for users i < S \\ T j . To remedy this\nproblem we rely on the fact entries cji for i outside of S \\ T j are encrypted under keys ski that are not known to the oracle. Thus, a computationally efficient oracle “does not know” those rows. We can formalize this argument by comparing Attack to an IdealAttack (Figure 5) where these entries are replaced with zeros, and argue that the adversary cannot distinguish between these two attacks without breaking the security of the encryption scheme.\nClaim 3.2. For every oracle O, every polynomial n = n(d), and every sufficiently large d ∈N,\nP IdealAttackn,d [O]\n[ ψ` > N/8 ] ≤ negl(n)\nProof. This follow straightforwardly from a reduction to the security of the fingerprinting code. Notice that since the query qj does not depend on any entry cji for i < S \\ T j−1. Thus, an adversary for the fingerprinting code who has access to cj S\\T j−1 can simulate the view of the oracle. Since we have for any adversary P\nP IFPCN,n,`[P ,F ]\n[ ψ` > N/8 ] ≤ negl(n),\nwe also have P\nIdealAttackn,d [O]\n[ ψ` > N/8 ] ≤ negl(n),\nas desired.\nNow we can argue that an efficient oracle cannot distinguish between the real attack and the ideal attack. Thus the conclusion that ψ` ≤N/8 with high probability must also hold in the real game.\nThe distribution D: Given parameters d,n, let N = 2000n, and λ = d − dlog2(2000n)e. For i ∈ [N ], let ski ←R Gen(1λ) and let yi = (i, ski) ∈ {0,1}d . Let D be the uniform distribution over {y1, . . . , yN } ⊆ {0,1}d .\nChoose samples x1, . . . ,xn←R D, let x = (x1, . . . ,xn). Let S ⊆ [N ] be the set of unique indices i such that (i, ski) appears in x.\nRecovery phase: Let T 1 = ∅. For j = 1, . . . , ` = `(N ):\nLet cj ∈ {±1}N be the column given by F . For i ∈ S, let ctji = Enc(ski , c j i ), for i ∈ [N ] \\ S, let ct j i = Enc(ski ,0). Define the query qj(i′ , sk′) to be Dec(sk′ , ctji′ ) if i ′ < T j and 0 otherwise. Let aj = O(x;qj ) and round aj to {±1} to obtain aj . Give aj to F and let I j ⊆ [N ] be the set of accused users and T j = T j−1 ∪ I j .\nFigure 5: IdealAttackn,d[O]\nClaim 3.3. Let Z1 be the event {\nψ` > N/8\n}\n. Assume (Gen,Enc,Dec) is a computationally secure encryption scheme and let n = n(d) be any polynomial. Then if O is computationally efficient, for every d ∈N ∣∣∣∣∣∣ PIdealAttackn,d [O] [Z1]− PAttackn,d [O] [Z1]\n∣∣∣∣∣∣ ≤ negl(n) The proof is straightforward from the definition of security, and is deferred to Section A.\nCombining Claims 3.2 and 3.3 we easily obtain the following.\nClaim 3.4. For every computionally efficient oracle O, every polynomial n = n(d), and every sufficiently large d ∈N,\nP Attackn,d [O]\n[ ψ` > N/8 ] ≤ negl(n)\nClaim 3.4 will be useful because it will allow us to establish that an accurate oracle must give answers that are consistent with the fingerprinting code. That is, using θ` to denote the number of inconsistent answers a1, . . . , a`, we will have θ` `/2 with high probability.\nClaim 3.5. If O is (1/3,β)-accurate for ` = `(2000n) adaptively chosen queries then for every polynomial n = n(d) and every sufficiently large d ∈N,\nP Attackn,d [O]\n[ θ` ≤ β` ] ≥ 1− on(1)\nProof. In the attack, the oracle’s input consists of n samples from D, and the total number of queries issued is `. Therefore, by the assumption that O is (1/3,β)-accurate for ` queries, we have\nP  For (1− β)` choices of j ∈ [`],∣∣∣∣∣∣O(x,qj )− E(i,ski )←RD [qj(i, ski)] ∣∣∣∣∣∣ ≤ 1/3  ≥ 1− on(1). (9)\nObserve that, by construction, for every j ∈ [`],∣∣∣∣∣∣ E(i,ski )←RD [qj(i, ski)]− Ei∈[N ] [ c j i ]∣∣∣∣∣∣ =\n∣∣∣∣∣∣∣∣  1N ∑ i∈[N ]\\T j−1 Dec(ski , ct j i ) + 1 N ∑ i∈T j−1 0 − Ei∈[n] [ c j i ]∣∣∣∣∣∣∣∣ =\n∣∣∣∣∣∣∣∣  1N ∑ i∈[N ]\\T j−1 c j i − Ei∈[n] [ c j i ]∣∣∣∣∣∣∣∣ ≤ 2 ∣∣∣T j−1∣∣∣ N\n≤ 2(ψj−1 +n)\nN (10)\nwhere the second equality is because by construction ctji ←R Enc(ski , c j i ) and the inequality is because we have cji ∈ {±1}. By Claim 3.4, and the fact that ψj−1 ≤ ψ`, we have\nP [ ψj−1 > N/8 +n ] ≤ P [ ψ` > N/8 +n ] ≤ negl(n).\nNoting that N/8 +n ≤N/6 and combining with (10), we have\nP [ ∀ j ∈ [`], ∣∣∣∣∣∣ E(i,ski )←RD [qj(i, ski)]− Ei∈[n] [ c j i ]∣∣∣∣∣∣ ≤ 1/3 ] ≥ 1−negl(n)\nApplying the triangle inequality to (9) and (10), we obtain\nP  For (1− β)` choices of j ∈ [`],∣∣∣∣∣∣O(x,qj )− Ei∈[N ] [ c j i ]∣∣∣∣∣∣ ≤ 2/3  ≥ 1− on(1). (11)\nFix a j ∈ [`] such that aj is accurate for query qj . If cji = 1 for every i ∈ S \\T j−1, then by (10), aj = O(x,qj ) ≥ 1/3, so the rounded answer aj = 1. Similarly if cji = −1 for every i ∈ S \\ T j−1, aj = −1. Therefore there must exist i ∈ S \\T j−1 so that aj = cji . Thus there are (1−β)` choices of j ∈ [`] for which this condition holds, so the number of errors θ` is at most β`. This completes the proof of the claim.\nAs before, we can argue that the real attack and the ideal attack are computationally indistinguishable, and thus the oracle must also give consistent answers in the ideal attack.\nClaim 3.6. Let Z2 be the event { θ` ≤ β` } . Assume (Gen,Enc,Dec) is a computationally secure encryption scheme and let n = n(d) be any polynomial. Then if O is computationally efficient, for every d ∈N ∣∣∣∣∣∣ PIdealAttackn,d [O] [Z2]− PAttackn,d [O] [Z2] ∣∣∣∣∣∣ ≤ negl(n)\nThe proof is straightforward from the definition of security, and is deferred to Section A. Combining Claims 3.5 and 3.6 we easily obtain the following.\nClaim 3.7. If O computationally efficient and (1/3,β)-accurate for ` = `(2000n) adaptively chosen queries then for every polynomial n = n(d) and every sufficiently large d ∈N,\nP IdealAttackn,d [O]\n[ θ` ≤ β` ] ≥ 1− on(1)\nHowever, the conclusion of 3.7 can easily be seen to lead to a contradiction, because the security of the fingerprinting code assures that no attacker who only has access to cj\nS\\T j−1 in\neach round j = 1, . . . , ` can give answers that are consistent for (1− β)` of the columns cj . Thus, we have\nClaim 3.8. For every oracle O, every polynomial n = n(d), and every sufficiently large d ∈N,\nP IdealAttackn,d [O]\n[ θ` ≤ β` ] ≤ negl(n)\nPutting it together, we obtain the following theorem. Theorem 3.9. There is a function `(2000n,β) = O(n2/ (\n1 2 − β\n)4 ) such that there is no computa-\ntionally efficient oracle O that is (1/3,β)-accurate for `(2000n,β) adaptively chosen queries given n samples in {0,1}d .\nProof. Assume for the sake of contradiction that there were such an oracle. Then by Claim 3.7 we would have\nP IdealAttackn,d [O]\n[ θ` ≤ β` ] ≥ 1− on(1).\nBut, by Claim 3.8 we have P\nIdealAttackn,d [O]\n[ θ` ≤ β` ] ≤ negl(n),\nwhich is a contradiction."
    }, {
      "heading" : "3.5 An Information-Theoretic Lower Bound",
      "text" : "As in [HU14], we observe that the techniques underlying our computational hardness result can also be used to prove an information-theoretic lower bound when the dimension of the data is large. At a high level, the argument uses the fact that the encryption scheme we rely on only needs to satisfy relatively weak security properties, specifically security for at most O(n2) messages. This security property can actually be achieved against computationally unbounded adversaries provided that the length of the secret keys is O(n2). As a result, our lower bound can be made to hold against computationally unbounded oracles, but since the secret keys have length O(n2), we will require d =O(n2). We refer the reader to [HU14] for a slightly more detailed discussion, and simply state the following result.\nTheorem 3.10. There is a function `(2000n,β) =O(n2/ (\n1 2 − β\n)4 ) such that there is no oracleO (even\none that is computationally unbounded) that is (1/3,β)-accurate for `(2000n,β) adaptively chosen queries given n samples in {0,1}d when d ≥ `(2000n,β)."
    }, {
      "heading" : "4 Hardness of Avoiding Blatant Non Privacy",
      "text" : "In this section we show how our arguments also imply that computationally efficient oracles that guarantee accuracy for adaptively chosen statistical queries must be blatantly non-private."
    }, {
      "heading" : "4.1 Blatant Non Privacy and Sample Accuracy",
      "text" : "Before we can define blatant non-privacy, we need to define a notion of accuracy that is more appropriate for the application to privacy. In contrast to Definition 3.1 where accuracy is defined with respect to the distribution, here we define accurate with respect to the sample itself. With this change in mind, we model blatant non-privacy via the following game.\nDefinition 4.1. An oracle O is (α,β,γ)-sample-accurate for ` adaptively chosen queries given n samples in {0,1}d if for every adversary Apriv,\nP NonPrivacyn,d,`[O,Apriv]\n[ For (1− β)` choices of j ∈ [`], ∣∣∣O(x,qj )− qj(x)∣∣∣ ≤ α] ≥ 1−γ where q(x) = 1n ∑ i∈[n] q(xi) is the average over the sample.\nAs a shorthand, we will say that O is (α,β)-sample-accurate for ` queries if for every n,d ∈N, O is (α,β,on(1))-accurate for ` queries given n samples in {0,1}d . Here, ` may depend on n and d and on(1) is a function of n that tends to 0.\nDefinition 4.2. Giving (α,β)-accurate answers to ` adaptively chosen queries is blatantly nonprivate for efficient oracles if there exists an adversary Apriv such that for every oracle O that is computationally efficient and (α,β)-sample-accurate for ` adaptively chosen queries,\nP NonPrivacyn,d,`[O,Apriv]\n[ |x4x′ | > n/100 ] ≤ on(1)\nIf the conclusion holds even for computationally inefficient oracles then we replace “for efficient oracles” with “for unbounded oracles” in the definition."
    }, {
      "heading" : "4.2 Lower Bounds",
      "text" : "In this section we show the following theorem\nTheorem 4.3. Giving accurate answers to O(n2) adaptively chosen queries is blatantly non-private for computationally efficient oracles.\nThe attack is defined in Figure 7. Therein F is a n-collusion-resilient interactive fingerprinting code of length ` for N = 2n users robust to a β fraction of errors with false accusation probability δ = 1/2000.\nWe will start by establishing that the number of falsely accused users is small. That is, letting ψj denote the number of users in T j who are not in the set x, we have ψL ≤ n/1000 with high probability. As in Section 3, this condition will follow from the security of the interactive fingerprinting code F combined with the security of the encryption scheme, via the introduction of an “ideal attack” (Figure 8).\nClaim 4.4. For every oracle O, every polynomial n = n(d), and every sufficiently large d ∈N,\nP IdealAttackn,d [O]\n[ ψL > n/1000 ] ≤ negl(n)\nProof. This follow straightforwardly from a reduction to the security of the fingerprinting code. Notice that since the query qj does not depend on any entry cji for i < x\\T j−1. Thus, an adversary for the fingerprinting code who has access to cj x\\T j−1 can simulate the view of the oracle. Since we have for any adversary P\nP IFPCN,n,`[P ,F ]\n[ ψ` > N/2000 ] ≤ negl(n),\nwe also have P\nIdealPrivacyAttackn,d [O]\n[ ψL > n/1000 ] ≤ negl(n),\nwhere we have used the fact that for every j ′ ≤ j, ψj ′ ≤ ψj . This completes the proof.\nNow we can argue that an efficient oracle cannot distinguish between the real attack and the ideal attack. Thus the conclusion that ψL ≤ n/1000 with high probability must also hold in the real game.\nClaim 4.5. Let Z1 be the event { ψL > n/1000 } Assume (Gen,Enc,Dec) is a computationally secure encryption scheme and let n = n(d) be any polynomial. Then if O is computationally efficient, for every d ∈N ∣∣∣∣∣∣ PIdealPrivacyAttackn,d [O] [Z1]− PPrivacyAttackn,d [O] [Z1]\n∣∣∣∣∣∣ ≤ negl(n) The proof is straightforward from the definition of security, and is deferred to Section A.\nCombining Claims 4.4 and 4.5 we easily obtain the following.\nClaim 4.6. For every computionally efficient oracle O, every polynomial n = n(d), and every sufficiently large d ∈N,\nP PrivacyAttackn,d [O]\n[ ψL > n/1000 ] ≤ negl(n)\nBy Claim 4.6 we have |x′ \\ x| ≤ n/1000. Now, in order to show |x′4x| ≤ n/100, it suffices to show that |x\\x′ | ≤ n/200. In order to do so we begin with the following claim, which establishes that if the oracle O is sufficiently accurate, and |x \\ T j−1| ≤ n/200, then the oracle returns a consistent answer to the query qj . Recalling that we use θj to denote the number of rounded answers ak for 1 ≤ k ≤ j that are inconsistent with cj , we can state the following claim.\nClaim 4.7. If O is (1/1000,0)-sample-accurate for ` = `(2n) adaptively chosen queries then for every polynomial n = n(d), every sufficiently large d ∈N, and every j ∈ [L],\nP PrivacyAttackn,d [O]\n[ θL = 0 ] ≥ 1− on(1)\nProof. Observe that, by construction, for every j ∈ [`],\nE i∈x\n[ qj(xi) ] =\n1 n  ∑ i∈(x\\T j−1) c j i + ∑ i∈(x∩T j−1) 0  = E i∈(x\\T j−1) [ c j i ] · ( |x \\ T j−1| n\n) After renormalizing by (n/n− |T j−1|) we have(\nn\nn− |T j−1| ) · E i∈x [ qj(xi) ] = E i∈(x\\T j−1) [ c j i ] · ( n n− |T j−1| ) · ( |x \\ T j−1| n\n) = E i∈(x\\T j−1) [ c j i ] · ( n− T j−1 +ψj−1 n− |T j−1|\n) = E i∈(x\\T j−1) [ c j i ] · ( 1 + ψj−1 n− |T j−1|\n) Since 0 ≤ ψj−1 ≤ n/10000 (by Claim 4.6), and since the algorithm terminates unless |T j−1| ≤ 499n/500, we obtain\nE i∈(x\\T j−1)\n[ c j i ] ≤ ( n\nn− |T j−1| ) · E i∈x [ qj(xi) ] ≤ 11 10 · E i∈(x\\T j−1) [ c j i ] =⇒ ∣∣∣∣∣∣ ( n n− |T j−1| ) · E i∈x [ qj(xi) ] − E i∈(x\\T j−1) [ c j i\n]∣∣∣∣∣∣ ≤ 110 (12) By the assumption that O is (1/1000,0)-sample-accurate, we have that, with probability 1 − on(1), for every j ∈ [L], ∣∣∣∣∣aj − Ei∈x [qj(xi)]\n∣∣∣∣∣ ≤ 1/1000. (13) Now, combining (12) and (13), we have∣∣∣∣∣∣ ( n n− |T j−1| ) · aj − E i∈(x\\T j−1) [ c j i\n]∣∣∣∣∣∣ ≤ ∣∣∣∣∣∣ (( n n− |T j−1| ) · E i∈x [ qj(xi) ] − E i∈(x\\T j−1) [ c j i ]) + (\nn\nn− |T j−1|\n) · 1\n1000 ∣∣∣∣∣∣ ≤ 12 + 110 ≤ 23 (14) Finally, observe that if cji = 1 for every i ∈ [2n], then we have\nE i∈(x\\T j−1)\n[ c j i ] = 1,\nand by (14) we have (n/(n− |T j |))aj ≥ 1− 2/3 = 1/3. Thus, the rounded answer aj = 1. Similarly, if cji = −1 for every i ∈ [2n], then we have a j = −1. This completes the proof of the claim.\nAs before, we can argue that the real attack and the ideal attack are computationally indistinguishable, and thus the oracle must also give consistent answers in the ideal attack.\nClaim 4.8. Let Z2 be the event { θL = 0 } Assume (Gen,Enc,Dec) is a computationally secure encryption scheme and let n = n(d) be any polynomial. Then if O is computationally efficient, for every d ∈N ∣∣∣∣∣∣ PIdealPrivacyAttackn,d [O] [Z2]− PPrivacyAttackn,d [O] [Z2]\n∣∣∣∣∣∣ ≤ negl(n) The proof is straightforward from the definition of security, and is deferred to Section A.\nCombining Claims 4.7 and 4.8 we easily obtain the following.\nClaim 4.9. If O computationally efficient and (1/1000,0)-accurate for ` = `(2n) adaptively chosen queries then for every polynomial n = n(d) and every sufficiently large d ∈N,\nP IdealPrivacyAttackn,d [O]\n[ θL = 0 ] ≥ 1− on(1)\nWe can use Claim 4.9 to derive a contradiction. To do so we use the fact that the security of the fingerprinting code assures that no attacker who only has access to cj\nx\\T j−1 in each round\nj = 1, . . . , ` can give answers that are consistent for all ` of the columns cj . Thus, we have\nClaim 4.10. For every oracle O, every polynomial n = n(d), and every sufficiently large d ∈ N, if L = `\nP IdealPrivacyAttackn,d [O]\n[ θ` = 0 ] ≤ negl(n)\nPutting it together, we obtain the following theorem.\nTheorem 4.11. There is a function `(2n) = O(n2) such that there is no computationally efficient oracle O that is (1/1000,0)-accurate for `(2n) adaptively chosen queries given n samples in {0,1}d .\nProof. Assume for the sake of contradiction that there were such an oracle. Now consider two cases. First consider the case that L < `, which means the algorithm has terminated early due to the condition |T L| ≥ 499n/500 being reached. In this case we have |x′ | = |T L| ≥ 499n/500. However, by Claim 4.4, we have that |x′ \\ x| ≤ n/10000. Therefore we have |x4x′ | ≤ (499/500− 1/5000)n ≤ n/100, as desired.\nNow consider the case where L = `, meaning the algorithm does not terminate early. In this case, by Claim 4.9 we have\nP IdealPrivacyAttackn,d [O]\n[ θ` = 0 ] ≥ 1− on(1)\nbut by Claim 4.10 we have\nP IdealPrivacyAttackn,d [O]\n[ θ` = 0 ] ≤ negl(n),\nwhich is a contradiction. This completes the proof of the theorem."
    }, {
      "heading" : "4.3 An Information-Theoretic Lower Bound",
      "text" : "As we did in Section 3.5, we can prove an information-theoretic analogue of our hardness result for avoiding blatant non-privacy.\nTheorem 4.12. There is a function `(2n) = O(n2) such that there is no oracle O (even a computationally unbounded one) that is (1/1000,0)-accurate for `(2n) adaptively chosen queries given n samples in {0,1}d where d ≥ `(2n).\nThe proof is essentially identical to what is sketched in Section 3.5."
    }, {
      "heading" : "Acknowledgements",
      "text" : "We thank Moritz Hardt and Salil Vadhan for insightful discussions during the early stages of this work."
    }, {
      "heading" : "A Security Reductions from Sections 3 and 4",
      "text" : "In Section 3 we made several claims comparing the probability of events in Attack to the probability of events in IdealAttack. Each of these claims follow from the assumed security of the encryption scheme. In this section we restate and prove these claims. Since the claims are all of a similar nature, the proof will be somewhat modular. The claims in Section 4 relating PrivacyAttack to IdealPrivacyAttack can be proven in an essentially identical fashion, and we omit these proofs for brevity.\nBefore we begin recall the formal definition of security of an encryption scheme. Security is defined via a pair of oracles E0 and E1. E1(sk1, . . . , skN , ·) takes as input the index of a key i ∈ [N ] and a message m and returns Enc(ski ,m), whereas E0(sk1, . . . , skN , ·) takes the same input but returns Enc(ski ,0). The security of the encryption scheme asserts that for randomly chosen secret keys, no computationally efficient adversary can tell whether or not it is interacting with E0 or E1.\nDefinition A.1. An encryption scheme (Gen,Enc,Dec) is secure if for every polynomial N = N (λ), and every poly(λ)-time adversary B, if sk1, . . . , skN ←R Gen(1λ)∣∣∣∣P [BE0(sk1,...,skN ,·) = 1]−P [BE1(sk1,...,skN ,·) = 1]∣∣∣∣ = negl(λ)\nWe now restate the relevant claims from Section 3. Claim A.2 (Claim 3.3 Restated). Let Z1 be the event { ψ` > N/8 } . Assume (Gen,Enc,Dec) is a computationally secure encryption scheme and let n = n(d) be any polynomial. Then if O is computationally efficient, for every d ∈N∣∣∣∣∣∣ PIdealAttackn,d [O] [Z1]− PAttackn,d [O] [Z1] ∣∣∣∣∣∣ ≤ negl(n)\nClaim A.3 (Claim 3.6 Restated). Let Z2 be the event { θ` ≤ β` } . Assume (Gen,Enc,Dec) is a computationally secure encryption scheme and let n = n(d) be any polynomial. Then ifO is computationally efficient, for every d ∈N ∣∣∣∣∣∣ PIdealAttackn,d [O] [Z2]− PAttackn,d [O] [Z2]\n∣∣∣∣∣∣ ≤ negl(n) To prove both of these claims, for c ∈ {1,2} we construct an adversary Bc that will attempt to use O to break the security of the encryption. We construct Bc in such a way that its advantage in breaking the security of encryption is precisely the difference in the probability of the event Zc between Attack and IdealAttack, which implies that the difference in probabilities is negligible. The simulator is given in Figure 9\nProof of Claims A.2, A.3. First, observe that for c ∈ {1,2}, Bc is computationally efficient as long as F and O are both computationally efficient. It is not hard to see that our construction F is efficient and efficiency ofO is an assumption of the claim. Also notice B can determine whether Zc has occurred efficiently.\nNow we observe that when the oracle is E1 (the oracle that takes as input i andm and returns Enc(ski ,m)), and sk1, . . . , skN are chosen randomly from Gen(1λ), then the view of the oracle is identical to Attackn,d[O]. Specifically, the oracle holds a random sample of pairs (i, ski) and is shown queries that are encryptions either under keys it knows or random unknown keys. Moreover, the messages being encrypted are chosen from the same distribution. On the other hand, when the oracle is E0 (the oracle that takes as input i and ct and returns Enc(ski ,0)), then\nthe view of the oracle is identical to Attackn,d[O]. Thus we have that for c ∈ {1,2},∣∣∣∣∣∣ PIdealAttackn,d [O] [Zc]− PAttackn,d [O] [Zc] ∣∣∣∣∣∣\n= ∣∣∣∣∣∣ Psk1,...,skN←RGen(1λ) [ BE0(sk1,...,skN ,·)c,n,d = 1 ] − P sk1,...,skN←RGen(1λ) [ BE1(sk1,...,skN ,·)c,n,d = 1 ]∣∣∣∣∣∣ = negl(λ) = negl(d) The last equality holds because we have chosen N = 2000n(d) = poly(d), and therefore we have λ = d − dlogN e = d −O(logd). This completes the proof of both claims."
    } ],
    "references" : [ {
      "title" : "Controlling the false discovery rate: a practical and powerful approach to multiple testing",
      "author" : [ "Yoav Benjamini", "Yosef Hochberg" ],
      "venue" : "Journal of the Royal Statistical Society. Series B (Methodological),",
      "citeRegEx" : "Benjamini and Hochberg.,? \\Q1995\\E",
      "shortCiteRegEx" : "Benjamini and Hochberg.",
      "year" : 1995
    }, {
      "title" : "Bonferroni. Teoria statistica delle classi e calcolo delle probabilita",
      "author" : [ "Carlo Emilio" ],
      "venue" : "Pubbl. d. R. Ist. Super. di Sci. Econom. e Commerciali di Firenze.,",
      "citeRegEx" : "Emilio,? \\Q1936\\E",
      "shortCiteRegEx" : "Emilio",
      "year" : 1936
    }, {
      "title" : "Collusion-secure fingerprinting for digital data",
      "author" : [ "Dan Boneh", "James Shaw" ],
      "venue" : "IEEE Transactions on Information Theory,",
      "citeRegEx" : "Boneh and Shaw.,? \\Q1998\\E",
      "shortCiteRegEx" : "Boneh and Shaw.",
      "year" : 1998
    }, {
      "title" : "Fingerprinting codes and the price of approximate differential privacy",
      "author" : [ "Mark Bun", "Jonathan Ullman", "Salil P. Vadhan" ],
      "venue" : "In STOC,",
      "citeRegEx" : "Bun et al\\.,? \\Q2014\\E",
      "shortCiteRegEx" : "Bun et al\\.",
      "year" : 2014
    }, {
      "title" : "Tracing traitors",
      "author" : [ "Benny Chor", "Amos Fiat", "Moni Naor" ],
      "venue" : "In CRYPTO,",
      "citeRegEx" : "Chor et al\\.,? \\Q1994\\E",
      "shortCiteRegEx" : "Chor et al\\.",
      "year" : 1994
    }, {
      "title" : "Guilt-free data exploration (tentative title)",
      "author" : [ "Cynthia Dwork", "Vitaly Feldman", "Moritz Hardt", "Toniann Pitassi", "Omer Reingold", "Aaron Roth" ],
      "venue" : null,
      "citeRegEx" : "Dwork et al\\.,? \\Q2014\\E",
      "shortCiteRegEx" : "Dwork et al\\.",
      "year" : 2014
    }, {
      "title" : "Calibrating noise to sensitivity in private data analysis",
      "author" : [ "Cynthia Dwork", "Frank McSherry", "Kobbi Nissim", "Adam Smith" ],
      "venue" : "In TCC,",
      "citeRegEx" : "Dwork et al\\.,? \\Q2006\\E",
      "shortCiteRegEx" : "Dwork et al\\.",
      "year" : 2006
    }, {
      "title" : "Revealing information while preserving privacy",
      "author" : [ "Irit Dinur", "Kobbi Nissim" ],
      "venue" : "In PODS, pages 202–210",
      "citeRegEx" : "Dinur and Nissim.,? \\Q2003\\E",
      "shortCiteRegEx" : "Dinur and Nissim.",
      "year" : 2003
    }, {
      "title" : "On the complexity of differentially private data release: efficient algorithms and hardness results",
      "author" : [ "Cynthia Dwork", "Moni Naor", "Omer Reingold", "Guy N. Rothblum", "Salil P. Vadhan" ],
      "venue" : "In STOC,",
      "citeRegEx" : "Dwork et al\\.,? \\Q2009\\E",
      "shortCiteRegEx" : "Dwork et al\\.",
      "year" : 2009
    }, {
      "title" : "Multiple comparisons among means",
      "author" : [ "Olive Jean Dunn" ],
      "venue" : "Journal of the American Statistical Association,",
      "citeRegEx" : "Dunn.,? \\Q1961\\E",
      "shortCiteRegEx" : "Dunn.",
      "year" : 1961
    }, {
      "title" : "On some classical results in probability theory",
      "author" : [ "N. Etemadi" ],
      "venue" : "Sankhya: The Indian Journal of Statistics, Series A (1961-2002),",
      "citeRegEx" : "Etemadi.,? \\Q1985\\E",
      "shortCiteRegEx" : "Etemadi.",
      "year" : 1985
    }, {
      "title" : "Dynamic traitor tracing",
      "author" : [ "Amos Fiat", "Tamir Tassa" ],
      "venue" : "J. Cryptology,",
      "citeRegEx" : "Fiat and Tassa.,? \\Q2001\\E",
      "shortCiteRegEx" : "Fiat and Tassa.",
      "year" : 2001
    }, {
      "title" : "Preventing false discovery in interactive data analysis is hard",
      "author" : [ "Moritz Hardt", "Jonathan Ullman" ],
      "venue" : "In FOCS. IEEE, October",
      "citeRegEx" : "Hardt and Ullman.,? \\Q2014\\E",
      "shortCiteRegEx" : "Hardt and Ullman.",
      "year" : 2014
    }, {
      "title" : "Efficient noise-tolerant learning from statistical queries",
      "author" : [ "Michael J. Kearns" ],
      "venue" : "In STOC, pages 392–401",
      "citeRegEx" : "Kearns.,? \\Q1993\\E",
      "shortCiteRegEx" : "Kearns.",
      "year" : 1993
    }, {
      "title" : "Analysis of Boolean Functions",
      "author" : [ "Ryan O’Donnell" ],
      "venue" : null,
      "citeRegEx" : "O.Donnell.,? \\Q2014\\E",
      "shortCiteRegEx" : "O.Donnell.",
      "year" : 2014
    }, {
      "title" : "Optimal probabilistic fingerprint codes",
      "author" : [ "Gábor Tardos" ],
      "venue" : "J. ACM,",
      "citeRegEx" : "Tardos.,? \\Q2008\\E",
      "shortCiteRegEx" : "Tardos.",
      "year" : 2008
    }, {
      "title" : "Answering n2+o(1) counting queries with differential privacy is hard",
      "author" : [ "Jonathan Ullman" ],
      "venue" : "In STOC, pages 361–370",
      "citeRegEx" : "Ullman.,? \\Q2013\\E",
      "shortCiteRegEx" : "Ullman.",
      "year" : 2013
    }, {
      "title" : "Private multiplicative weights beyond linear queries",
      "author" : [ "Jonathan Ullman" ],
      "venue" : "CoRR, abs/1407.1571,",
      "citeRegEx" : "Ullman.,? \\Q2014\\E",
      "shortCiteRegEx" : "Ullman.",
      "year" : 2014
    } ],
    "referenceMentions" : [ ],
    "year" : 2017,
    "abstractText" : "We show a tight bound on the number of adaptively chosen statistical queries that a computationally efficient algorithm can answer accurately given n samples from an unknown distribution. A statistical query asks for the expectation of a predicate over the underlying distribution, and an answer to a statistical query is accurate if it is “close” to the correct expectation over the distribution. This question was recently considered by Dwork et al. [DFH+14], who showed that Ω̃(n2) queries can be answer efficiently, and also by Hardt and Ullman [HU14], who showed that answering Õ(n3) queries is computationally hard. We close the gap between the two bounds by proving a new, nearly-optimal hardness result. Specifically, we show that, under a standard hardness assumption, there is no computationally efficient algorithm that given n samples from an unknown distribution can give valid answers toO(n2) adaptively chosen statistical queries. An implication of our results is that computationally efficient algorithms for answering arbitrary, adaptively chosen statistical queries may as well be differentially private. We obtain our results via an optimal construction of a new combinatorial object that we call an interactive fingerprinting code, which may be of independent interest. ∗Harvard University School of Engineering and Applied Sciences. Supported by NSF grant CCF-1116616. Email: tsteinke@seas.harvard.edu. †Harvard University Center for Research on Computation and Society and Columbia University. Supported by NSF Grant CNS-1237235 and a Simons Society of Fellows Junior Fellowship. Email: jullman@cs.columbia.edu. ar X iv :1 41 0. 12 28 v1 [ cs .C R ] 5 O ct 2 01 4",
    "creator" : "LaTeX with hyperref package"
  }
}