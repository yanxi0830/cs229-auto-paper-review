{
  "name" : "1302.6927.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "Online Learning for Time Series Prediction",
    "authors" : [ "Oren Anava", "Elad Hazan", "Shie Mannor", "Ohad Shamir" ],
    "emails" : [ "soanava@tx.technion.ac.il", "ehazan@ie.technion.ac.il", "shie@ee.technion.ac.il", "ohadsh@microsoft.com" ],
    "sections" : [ {
      "heading" : null,
      "text" : "ar X\niv :1\n30 2.\n69 27\nv1 [\ncs .L\nG ]\n2 7\nFe b"
    }, {
      "heading" : "1 Introduction",
      "text" : "A time series is a sequence of real-valued signals that are measured at successive time intervals. Autoregressive (AR), moving average (MA), and autoregressive moving average (ARMA) models are often used for the purpose of time-series modeling, analysis and prediction. These models have been successfully used in a wide range of applications such as speech analysis, noise cancelation, and stock market analysis ([Ham94, BJR94, SS05, BD09]). Roughly speaking, they are based on the assumption that each new signal is a noisy linear combination of the last few signals and independent noise terms.\nA great deal of work has been done on parameter identification and signal prediction using these models, mainly in the “proper learning” setting, in which the fitted model tries to mimic the assumed underlying model. Most of this work relied on strong assumptions regarding the noise terms, such as independence and identical Gaussian distribution. These assumptions are quite strict in general and the following statement from [Tho94] is sometimes quoted:\nExperience with real-world data, however, soon convinces one that both stationarity and Gaussianity are fairy tales invented for the amusement of undergraduates.\nIn this paper we argue that these assumptions can be relaxed into less strict assumptions on the noise terms. Moreover, we offer a novel approach for time series analysis and prediction — an online learning approach that allows the noise to be arbitrarily or even (to some extent) adversarially generated. The goal of this paper is to show that the new approach is more general, and is capable of coping with a wider range of time series and loss functions (rather than only the squared loss)."
    }, {
      "heading" : "1.1 Summary of results",
      "text" : "We present and analyze two online algorithms for the prediction problem, one designed for general convex loss functions and the other for exp-concave ones. Each of these algorithms attains sublinear regret bound against the best ARMA prediction in hindsight, under weak assumptions on the noise terms. We apply our results to the most commonly used loss function in time series analysis, the squared loss, and achieve a regret bound of O ( log2(T ) )\nagainst the best ARMA prediction in hindsight. Finally, we present an empirical study that verifies our theoretical results."
    }, {
      "heading" : "1.2 Related work",
      "text" : "In standard time series analysis, the squared loss is usually considered and the noise terms are assumed to be independent with bounded variance and zero-mean. In this specific setting, one can assume without loss of generality that the noise terms have identical Gaussian distribution (see [Ham94, BJR94, BD09] for more information). This allows the use of statistical methods, such as least squares and maximum likelihood based methods, for the tasks of analysis and prediction. However, when different loss functions are considered these assumptions do not hold in general, and the aforementioned methods are not applicable. We are not aware of a previous approach that tries to relax these assumptions for general convex loss functions. We note that there has been previous work which tries to relax such assumptions for the squared loss, usually under additional modelling assumptions such as t-distribution of the noise (e.g., [DES89, TWVB00]). We emphasize that the independence assumption is rather strict and previous works that relax this assumption usually offer specific dependency model, e.g., as proposed by [Eng82] for the ARCH model.\nFurthermore, an online approach that relies on regret minimization techniques was never considered for ARMA prediction, and hence regret bounds of the type we are interested simply do not exist. Yet, results on the convergence rate of the coefficient vectors do exist, and regret bounds can be derived from these results. E.g., in [DSC06] such results are presented, and a regret bound of O ( log2(T ) )\ncan be derived for the squared loss. We are not familiar of these kind of results for general convex loss functions."
    }, {
      "heading" : "2 Preliminaries and model",
      "text" : ""
    }, {
      "heading" : "2.1 Time series modelling",
      "text" : "A time series is a sequence of signals, measured at successive times, which are assumed to be spaced at uniform intervals. We denote by Xt the signal measured at time t, and by ǫt the noise term at time t. The AR(k) (short for autoregressive) model, parameterized by a horizon k and a coefficient vector α ∈ Rk, assumes that the time series is generated according to the following model, where ǫt is a zero-mean random noise term:\nXt =\nk ∑\ni=1\nαiXt−i + ǫt. (1)\nIn words, the model assumes that each Xt is a noisy linear combination of the previous k signals. A more sophisticated model is the ARMA(k, q) (short for autoregressive moving average) model, which is\nparameterized by two horizon terms k, q and coefficient vectors α ∈ Rk and β ∈ Rq. This model assumes that Xt is generated via the formula:\nXt = k ∑\ni=1\nαiXt−i +\nq ∑\ni=1\nβiǫt−i + ǫt, (2)\nwhere again ǫt are zero-mean noise terms. Sometimes, an additional constant bias term is added to the equation (to indicate constant drift), but we will ignore this for simplicity. Note that the AR(k) model is a special case of the ARMA(k, q) model, where the βi coefficients are all zero."
    }, {
      "heading" : "2.2 The online setting for ARMA prediction",
      "text" : "Online learning is usually defined in a game-theoretic framework, where the data, rather than being chosen stochastically, are chosen arbitrarily, possibly by an all-powerful adversary with full knowledge of our learning algorithm (see for instance [CBL06]). In our context, we will describe the setting as follows: First, some coefficient vectors (α, β) are fixed by the adversary. At each time point t, the adversary chooses ǫt and generates the resulting signal Xt using the formula in Equation 2. We emphasize that (α, β) and the noise terms are not revealed to us at any time point.\nAt iteration t, we need to make a prediction X̃t for the signal, after which the real signal Xt is revealed, and we suffer a loss denoted by ℓt ( Xt, X̃t )\n. Our goal is to minimize the sum of losses over a predefined number of iterations T . A reasonable benchmark is to try to be not much worse than the best possible ARMA model. More precisely, we let\nft(α, β) = ℓt ( Xt, X̃t(α, β) ) = ℓt\n(\nXt,\n(\nk ∑\ni=1\nαiXt−i +\nq ∑\ni=1\nβiǫt−i\n))\n(3)\ndenote the loss at time t of the (conditionally expected) prediction given by an ARMA model with some coefficients (α, β). We then define the regret as\nRT = T ∑\nt=1\nℓt ( Xt, X̃t ) −min α,β\nT ∑\nt=1\nℓt ( Xt, X̃t(α, β) ) . (4)\nWe wish to obtain efficient algorithms, whose regret grows sublinearly in T , corresponding to an average per-round regret going to zero as T increases. 1\nA major challenge in our setting is that the noise terms {ǫt}Tt=1 are unknown. As a result, we cannot use existing online convex optimization algorithms over the space of coefficient vectors (α, β). Moreover, even if we are given some (α, β), we cannot generate a prediction X̃t using the ARMA model. This lack of information makes it also hard to compute the best coefficient vectors in hindsight, and hence competing against the best ARMA model is ill-defined in this case.\n1The iterations in which t ≤ k are usually ignored since we assume that the loss per iteration is bounded by a constant, this adds at most a constant to the final regret bound."
    }, {
      "heading" : "2.3 Our assumptions",
      "text" : "Throughout Section 3 we assume the following:\n1. The noise terms are stochastically and independently generated, each from a zero-mean distribution which might be chosen adversarially (up to the assumptions below). In Section 4 we show how to relax this assumption to adversarial noise. Also, we assume that E [|ǫt|] < Mmax < ∞ and E [ℓt (Xt,Xt − ǫt)] < ∞ for all t.\n2. The loss function ℓt is Lipshitz continuous for some Lipshitz constant L > 0. This is a standard assumption and it holds in particular for the squared loss, as well as for other convex loss functions, with compact domain.\n3. The coefficients αi satisfy |αi| < c for some c ∈ R. This assumption is also standard, and needed in general for the decision set (defined in Subsection 3.1) to be bounded. We assume that c = 1 without loss of generality.\n4. The coefficients βi satisfy ∑q i=1 |βi| < 1− ε, for some ε > 0. 5. The signal is bounded (by constant which is independent of T ). Without loss of generality we assume\nthat |Xt| < 1 for all t."
    }, {
      "heading" : "3 Online time series prediction",
      "text" : "As said before, we cannot use existing online convex optimization algorithms over the space of coefficient vectors (α, β) since the noise terms are unknown to us at any stage. Instead, we use an improper learning approach, where our predictions at each time point will not come from an ARMA model that tries to mimic the underlying model. More specifically, we fix some m ∈ N, and at each time point t, we choose an (m+ k)-dimensional coefficient vector γ ∈ Rm+k and predict by X̃t(γ) = ∑m+k i=1 γiXt−i. It follows that our loss at iteration t is determined by the loss function\nℓmt (γ t) = ℓt\n( Xt, X̃t(γ t) ) = ℓt\n(\nXt,\n(\nm+k ∑\ni=1\nγtiXt−i\n))\n. (5)\nThis can be seen as an AR model with horizon (m+ k). This leads to one of our key results: we can learn ARMA(k, q) model using AR(m+ k) model, for a properly chosen value of m. We quantify this result in Theorem 3.1 in terms of regret."
    }, {
      "heading" : "3.1 Algorithm parameters definition and calculation",
      "text" : "Before presenting the algorithm and stating our main theorem, we need to define the following parameters. The decision set K is the set of candidates ((m+ k)-dimensional coefficient vectors) we can choose from at each iteration; it is defined as\nK = { γ ∈ Rm+k , |γj | ≤ 1 , j = 1, . . . ,m } .\nIntuitively, the structure of K follows from Assumptions 3-4 on α and β, which restrict our improper learning variable γ. We denote by D the diameter of K, and bound:\nD = sup γ1,γ2∈K\n‖γ1 − γ2‖2 = √ 2 (m+ k). (6)\nNext, we denote by G the upper-bound of ‖∇ℓmt (γ)‖ for all t and γ ∈ K. This parameter depends on the loss function considered, and its computation is done accordingly. E.g., for the squared loss we get that G = 2 √ m+ kD, relying on Assumption 5. Finally, we denote by λ the exp-concavity parameter of the loss functions {ℓmt }Tt=1, i.e., it holds that e−λ·ℓ m t (γ) is concave for all t 2. This parameter is relevant only for exp-concave loss functions, and its computation is also done according to the loss function considered. It can be shown that λ = 1\nm+k when the squared loss is considered."
    }, {
      "heading" : "3.2 ARMA Online Newton Step (ARMA-ONS)",
      "text" : "Algorithm 1 shows how to choose γt in each iteration, when the loss functions {ℓmt }Tt=1 are assumed to be λ-exp-concave in γ. The notation ΠAtK refers to the projection onto K in the norm induced by At, i.e., ΠAtK (y) = argminx∈K(y − x)⊤At(y − x).\nAlgorithm 1 ARMA-ONS(k,q) 1: Input: ARMA order k,q; learning rate η; an initial (m+ k)× (m+ k) matrix A0. 2: Set m = q · log1−ε ( (TLMmax) −1 ) .\n3: Choose γ1 ∈ K arbitrarily. 4: for t = 1 to (T − 1) do 5: Predict X̃t(γt) = ∑m+k i=1 γ t iXt−i. 6: Observe Xt and suffer loss ℓmt (γ t). 7: Let ∇t = ∇ℓmt (γt), update At ← At−1 +∇t∇⊤t 8: Set γt+1 ← ΠAtK ( γt − 1 η A−1t ∇t ) 9: end for\nIn case the dimension (m+ k) of At is large, we note that its inverse can be efficiently re-computed after each update using the Sherman-Morrison formula.\nFor Algorithm 1 we can prove the following:\nTheorem 3.1. Let k, q ≥ 1, and set A0 = ǫIm+k, ǫ = 1η2D2 , η = 12 min{4GD,λ}. Then, for any data sequence {Xt}Tt=1 that satisfies the assumptions from Section 2.3, Algorithm 1 generates an online sequence {γt}Tt=1, for which the following holds:\nT ∑\nt=1\nℓmt (γ t)−min\nα,β\nT ∑\nt=1\nE [ft(α, β)] = O\n((\nGD + 1\nλ\n)\nlog(T )\n)\n. (7)\n2It is easy to show that every exp-concave function is convex, the opposite is not correct.\nRemark: The expectation is necessary since the noise terms ǫt are unknown. Also, obtaining a high probability bound on the regret is possible but requires additional assumptions on the noise process such as boundedness or light tail.\nProof. Intuitively, Theorem 3.1 states that we can have a regret as low as the best ARMA(k, q) model, using only an AR(m + k) model. The proof consists of two steps. In the first step we bound the regret suffered by an AR(m+k) prediction using familiar techniques of online convex optimization. In the second step we bound the distance between the AR(m + k) loss function and the ARMA(k, q) loss function, using a chain of bounds and inequalities. Integrating both steps yields the requested regret bound for the ARMA(k, q) loss function. Step 1: Relying on the fact that the loss functions {ℓmt }Tt=1 are λ-exp-concave, we can guarantee that\nT ∑\nt=1\nℓmt (γ t)−min\nγ\nT ∑\nt=1\nℓmt (γ) = O (( GD + 1\nλ\n) log(T ) ) ,\nusing the Online Newton Step (ONS) algorithm, presented in [HAK07]. Step 2: Define recursively\nX∞t (α, β) = k ∑\ni=1\nαiXt−i +\nq ∑\ni=1\nβi ( Xt−i −X∞t−i(α, β) ) ,\nwith initial condition X∞1 (α, β) = X1. We then denote by\nf∞t (α, β) = ℓt (Xt,X ∞ t (α, β)) (8)\nthe loss suffered by the prediction X∞t (α, β) at iteration t. From this definition it follows that X ∞ t (α, β) is of the form X∞t (α, β) = ∑t−1\ni=1 ci(α, β)Xt−i for some appropriate coefficients ci(α, β). The motivation behind the definition of f∞t follows from the need to replace ft with a loss function that fits the full information online optimization model (no unknown parameters). We set m ∈ N, and define\nXmt (α, β) =\nk ∑\ni=1\nαiXt−i +\nq ∑\ni=1\nβi ( Xt−i −Xm−it−i (α, β) ) ,\nwith initial condition Xmt (α, β) = Xt for all t and m ≤ 0. We denote by\nfmt (α, β) = ℓt (Xt,X m t (α, β)) (9)\nthe loss suffered by the prediction Xmt (α, β) at iteration t. The motivation here is simple: it is easier to generate predictions using only the last (m+ k) signals, and the distance between the loss function is relatively small. Now, let\n(α⋆, β⋆) = argmin α,β\nT ∑\nt=1\nE [ft(α, β)] (10)\ndenote the best ARMA coefficient in hindsight for predicting the signal {Xt}Tt=1. Then, from Lemma 3.2, stated and proven below, we have that\nmin γ\nT ∑\nt=1\nℓmt (γ) ≤ T ∑\nt=1\nfmt (α ⋆, β⋆) ,\nand it follows that T ∑\nt=1\nℓmt (γ t)−\nT ∑\nt=1\nfmt (α ⋆, β⋆) = O\n(( GD + 1\nλ\n) log(T ) ) .\nFrom Lemma 3.3 below we know that ∣\n∣ ∣ ∣ ∣\nT ∑\nt=1\nE [f∞t (α ⋆, β⋆)]−\nT ∑\nt=1\nE [fmt (α ⋆, β⋆)]\n∣ ∣ ∣ ∣ ∣ = O(1),\nfor m = q · log1−ε ( (TLMmax) −1 ) , which implies that\nT ∑\nt=1\nℓmt (γ t)−\nT ∑\nt=1\nE [f∞t (α ⋆, β⋆)] = O\n(( GD + 1\nλ\n) log(T ) ) .\nFinally, from Lemma 3.4 below we know that ∣\n∣ ∣ ∣ ∣\nT ∑\nt=1\nE [f∞t (α ⋆, β⋆)]−\nT ∑\nt=1\nE [ft (α ⋆, β⋆)]\n∣ ∣ ∣ ∣ ∣ = O ( 1),\nand thus T ∑\nt=1\nℓmt (γ t)−min\nα,β\nT ∑\nt=1\nE [ft(α, β)] = O\n((\nGD + 1\nλ\n)\nlog(T )\n)\n.\nNext, we prove the lemmas we used.\nLemma 3.2. Let ℓmt (γ), f m t (α, β) and (α ⋆, β⋆) be as denoted in Equations 5, 9 and 10. Then, for all m ∈ N and data sequence {Xt}Tt=1 that satisfies the assumptions from Section 2.3, it holds that\nmin γ\nT ∑\nt=1\nℓmt (γ) ≤ T ∑\nt=1\nfmt (α ⋆, β⋆) .\nProof. Note that if we set γ⋆i = ci(α ⋆, β⋆), we immediately get that\nT ∑\nt=1\nℓmt (γ ⋆) =\nT ∑\nt=1\nfmt (α ⋆, β⋆) .\nTrivially, it always holds that\nmin γ\nT ∑\nt=1\nℓmt (γ) ≤ T ∑\nt=1\nℓmt (γ ⋆),\nwhich completes the proof.\nLemma 3.3. Let f∞t (α, β), f m t (α, β) and (α ⋆, β⋆) be as denoted in Equations 8, 9 and 10. Then, for any data sequence {Xt}Tt=1 that satisfies the assumptions from Section 2.3, it holds that\n∣ ∣ ∣ ∣ ∣ T ∑\nt=1\nE [f∞t (α ⋆, β⋆)]−\nT ∑\nt=1\nE [fmt (α ⋆, β⋆)]\n∣ ∣ ∣ ∣ ∣ = O(1),\nif we choose m = q · log1−ε ( (TLMmax) −1 ) .\nProof. We set t, and look at the distance between f∞t (α ⋆, β⋆) and fmt (α ⋆, β⋆) in expectation. We show by induction that\nE [|Xmt (α⋆, β⋆)−X∞t (α⋆, β⋆) |] ≤ 2Mmax · (1− ε) m q .\nFor m = 0 we have that X0t (α ⋆, β⋆) = Xt from the definition, and hence\n|X0t (α⋆, β⋆)−X∞t (α⋆, β⋆) | ≤ |Xt −X∞t (α⋆, β⋆) | ≤ |Xt −X∞t (α⋆, β⋆)− ǫt|+ |ǫt|.\nNow, E [|ǫt|] < Mmax < ∞ for all t and E [|Xt −X∞t (α⋆, β⋆)− ǫt|] decays exponentially as proven in lemma 3.4, and hence the inductive basis holds for m = 0. Next, we prove that the inductive basis holds for m = 1, . . . , q − 1:\n|Xmt (α⋆, β⋆)−X∞t (α⋆, β⋆) |\n=\n∣ ∣ ∣ ∣ ∣ q ∑\ni=1\nβ⋆i ( Xt−i −Xm−it−i (α⋆, β⋆) )\n− q ∑\ni=1\nβ⋆i ( Xt−i −X∞t−i (α⋆, β⋆) )\n∣ ∣ ∣ ∣ ∣\n=\n∣ ∣ ∣ ∣ ∣ m ∑\ni=1\nβ⋆i ( X∞t−i (α ⋆, β⋆)−Xm−it−i (α⋆, β⋆) ) +\nq ∑\ni=m+1\nβ⋆i ( X∞t−i (α ⋆, β⋆)−Xm−it−i (α⋆, β⋆) )\n∣ ∣ ∣ ∣ ∣\n(1) ≤ m ∑\ni=1\n|β⋆i | · ∣ ∣X∞t−i (α ⋆, β⋆)−Xm−it−i (α⋆, β⋆) ∣ ∣+\nq ∑\ni=m+1\n|β⋆i | · ∣ ∣X∞t−i (α ⋆, β⋆)−Xt ∣ ∣\n(2) ≤ m ∑\ni=1\n|β⋆i | · 2Mmax · (1− ε) m−i q +\nq ∑\ni=m+1\n|β⋆i | · 2Mmax (3) ≤ q ∑\ni=1\n|β⋆i | · 2Mmax · (1− ε) m−q q\n≤ 2Mmax · (1− ε) m q .\n(1) is true from the triangle inequality and from the definition of Xmt for m ≤ 0. (2) is true from the inductive hypothesis on m. (3) is true since 1 ≤ (1− ε) m−q\nq for m = 1, . . . , q − 1. For the inductive step we assume that\n|Xµτ (α⋆, β⋆)−X∞τ (α⋆, β⋆) | ≤ 2Mmax · (1− ε) µ q\nfor q ≤ µ < m and τ < t, and prove that\n|Xmt (α⋆, β⋆)−X∞t (α⋆, β⋆) | ≤ 2Mmax · (1− ε) m q .\nThus,\n|Xmt (α⋆, β⋆)−X∞t (α⋆, β⋆) |\n=\n∣ ∣ ∣ ∣ ∣ q ∑\ni=1\nβ⋆i ( Xt−i −Xm−it−i (α⋆, β⋆) )\n− q ∑\ni=1\nβ⋆i ( Xt−i −X∞t−i (α⋆, β⋆) )\n∣ ∣ ∣ ∣ ∣\n=\n∣ ∣ ∣ ∣ ∣ q ∑\ni=1\nβ⋆i ( X∞t−i (α ⋆, β⋆)−Xm−it−i (α⋆, β⋆) )\n∣ ∣ ∣ ∣ ∣ ≤ q ∑\ni=1\n|β⋆i | · ∣ ∣X∞t−i (α ⋆, β⋆)−Xm−it−i (α⋆, β⋆) ∣ ∣\n≤ q ∑\ni=1\n|β⋆i | · 2Mmax · (1− ε) m−i q ≤\nq ∑\ni=1\n|β⋆i | · 2Mmax · (1− ε) m−q q\n≤ (1− ε) · 2Mmax · (1− ε) m−q q = 2Mmax · (1− ε) m q ,\nwhich completes the induction. Recall that ℓt is Lipshitz continuous for some Lipshitz constant L > 0 from Assumption 2, and hence it follows that\n|E [f∞t (α⋆, β⋆)]− E [fmt (α⋆, β⋆)]| = |E [ℓt (Xt,X∞t (α⋆, β⋆))]− E [ℓt (Xt,Xmt (α⋆, β⋆))]| ≤ E [|ℓt (Xt,X∞t (α⋆, β⋆))− ℓt (Xt,Xmt (α⋆, β⋆))|] ≤ L · E [|Xmt (α⋆, β⋆)−X∞t (α⋆, β⋆) |] ≤ L · 2Mmax · (1− ε) m q ,\nwhere the first inequality follows from Jensen’s inequality. By summing the above for all t we get that\n∣ ∣ ∣ ∣ ∣ T ∑\nt=1\nE [f∞t (α ⋆, β⋆)]−\nT ∑\nt=1\nE [fmt (α ⋆, β⋆)]\n∣ ∣ ∣ ∣ ∣ ≤ TL · 2Mmax · (1− ε) m q .\nFinally, choosing m = q · log1−ε ( (TLMmax) −1 ) yields\n∣ ∣ ∣ ∣ ∣ T ∑\nt=1\nE [f∞t (α ⋆, β⋆)]−\nT ∑\nt=1\nE [fmt (α ⋆, β⋆)]\n∣ ∣ ∣ ∣ ∣ = O(1).\nLemma 3.4. Let ft(α, β), f∞t (α, β) and (α ⋆, β⋆) be as denoted in Equations 3, 8 and 10. Then, for any data sequence {Xt}Tt=1 that satisfies the assumptions from Subsection 2.3, it holds that ∣\n∣ ∣ ∣ ∣\nT ∑\nt=1\nE [f∞t (α ⋆, β⋆)]−\nT ∑\nt=1\nE [ft (α ⋆, β⋆)]\n∣ ∣ ∣ ∣ ∣ = O (1) .\nProof. First, denote by (α′, β′) the coefficient vectors that have generated the signal. Trivially, it holds that\nT ∑\nt=1\nft ( α′, β′ ) = T ∑\nt=1\nℓt (Xt,Xt − ǫt) .\nFrom Assumption 1, ǫt is independent of ǫ1, . . . , ǫt−1, and hence the best prediction available at time t will cause a loss of at least ℓt (Xt,Xt − ǫt) in expectation. We can think of it in the following way: at time t, the online player has no previous information regarding the adversary’s choice of ǫt. Since E [ǫt] = 0 and ℓt is convex, predicting the expected signal is the optimal policy of the online player at time t. It follows that (α⋆, β⋆) = (α′, β′), meaning the best ARMA coefficients in hindsight are those that have generated the signal. Next, we show by induction that E [|Xt −X∞t (α⋆, β⋆)− ǫt|] decays exponentially as t grows linearly. Without loss of generality, we can assume that for t = 1, . . . , q we have that E [|Xt −X∞t (α⋆, β⋆)− ǫt|] < ρ for some ρ > 0, as the inductive basis. Now, for the inductive step we assume that\nE [|Xτ −X∞τ (α⋆, β⋆)− ǫτ |] < ρ · (1− ε) τ q\nfor q < τ < t, and prove that\nE [|Xt −X∞t (α⋆, β⋆)− ǫt|] ≤ ρ · (1− ε) t q .\nThus,\nE [|Xt −X∞t (α⋆, β⋆)− ǫt|]\n= E\n[ ∣\n∣ ∣ ∣ ∣\nk ∑\ni=1\nα⋆iXt−i +\nq ∑\ni=1\nβ⋆i ǫt−i + ǫt − k ∑\ni=1\nα⋆iXt−i − q ∑\ni=1\nβ⋆i ( Xt−i −X∞t−i (α⋆, β⋆) ) − ǫt ∣ ∣ ∣ ∣\n∣\n]\n= E\n[∣\n∣ ∣ ∣ ∣\nq ∑\ni=1\nβ⋆i ( X∞t−i (α ⋆, β⋆)−Xt−i − ǫt−i )\n∣ ∣ ∣ ∣ ∣ ] ≤ q ∑\ni=1\n|β⋆i | · E [∣ ∣X∞t−i (α ⋆, β⋆)−Xt−i − ǫt−i ∣ ∣ ]\n≤ q ∑\ni=1\n|β⋆i | · ρ · (1− ε) t−i q ≤\nq ∑\ni=1\n|β⋆i | · ρ · (1− ε) t−q q ≤ (1− ε) · ρ (1− ε) t−q q = ρ · (1− ε) t q\nwhich ends the induction. Recall that ℓt is assumed to be Lipshitz continuous for some constant L > 0, and hence it follows that\n|E [f∞t (α⋆, β⋆)]− E [ft (α⋆, β⋆)]| = |E [ℓt (Xt,X∞t (α⋆, β⋆))]− E [ℓt (Xt,Xt − ǫt)]| = |E [ℓt (Xt,X∞t (α⋆, β⋆))− ℓt (Xt,Xt − ǫt)]| ≤ E [|ℓt (Xt,X∞t (α⋆, β⋆))− ℓt (Xt,Xt − ǫt)|] ≤ L · E [|Xt −X∞t (α⋆, β⋆)− ǫt|] ≤ ρL · (1− ε) t q .\nFinally, summing over all iterations yields ∣\n∣ ∣ ∣ ∣\nT ∑\nt=1\nE [f∞t (α ⋆, β⋆)]−\nT ∑\nt=1\nE [ft (α ⋆, β⋆)]\n∣ ∣ ∣ ∣ ∣ = O (1) .\nRemark: In Lemma 3.4 we assume here that ρqL = O (1). Otherwise, an element of O (ρqL) is added to the regret bound in Theorems 3.1, which does not affect the asymptotic result."
    }, {
      "heading" : "3.3 ARMA Online Gradient Descent (ARMA-OGD)",
      "text" : "We now turn to present a different algorithm for choosing γt at each time point. This algorithm is applicable to general convex loss functions, as well as to exp-concave ones. It is computationally simpler but has a somewhat worse theoretical (and empirical) performance compared to the previous one, when considering an exp-concave loss function. The notation ΠK refers to the Euclidean projection onto K, i.e., ΠK(y) = argminx∈K ‖y − x‖2 .\nAlgorithm 2 ARMA-OGD(k,q) 1: Input: ARMA order k,q. Learning rate η.\n2: Set m = q · log1−ε ( (TLMmax) −1 ) . 3: Choose γ1 ∈ K arbitrarily. 4: for t = 1 to (T − 1) do 5: Predict X̃t(γt) = ∑m+k i=1 γ t iXt−i. 6: Observe Xt and suffer loss ℓmt (γt). 7: Let ∇t = ∇ℓmt (γt) 8: Set γt+1 ← ΠK ( γt − 1 η ∇t ) 9: end for\nFor Algorithm 2 we can prove the following:\nTheorem 3.5. Let k, q ≥ 1, and set η = D G √ T . Then, for any data sequence {Xt}Tt=1 that satisfies the assumptions from Section 2.3, Algorithm 2 generates an online sequence {γt}Tt=1, for which the following holds:\nT ∑\nt=1\nℓmt (γ t)−min\nα,β\nT ∑\nt=1\nE [ft(α, β)] = O ( GD √ T ) . (11)\nThe proof of this theorem is very similar to the proof of Theorem 3.1, albeit plugging into our framework the Online Gradient Descent (OGD) algorithm of [Zin03] rather than the Online Newton Step algorithm."
    }, {
      "heading" : "4 Additional results",
      "text" : "In this section we present an analysis for the case when the noise terms are allowed to be adversarial, and also an application of Theorem 3.1 for squared loss."
    }, {
      "heading" : "4.1 Adversarial noise",
      "text" : "The results presented in Theorems 3.1 and 3.5 rely on the assumptions that the noise terms are independent and zero-mean. Under these assumptions, the best coefficient vectors in hindsight are those that have generated the signal. However, if we allow the noise terms to be adversarially generated (the adversary chooses ǫt at time t with no limitations), the best coefficient vectors in hindsight are not necessarily the ones used for generating the signal. For this case we have the following theorem:\nTheorem 4.1. Denote by (α′, β′) the coefficient vectors that have generated the signal, and assume that {Xt}Tt=1 satisfies Assumptions 2-5 from Section 2.3, when the noise terms are allowed to be chosen adversarially. Then, for exp-concave loss functions Algorithm 1 generates an online sequence {γt}Tt=1, for which the following holds:\nT ∑\nt=1\nℓmt (γ t)−\nT ∑\nt=1\nE [ ft ( α′, β′ )] = O\n((\nGD + 1\nλ\n)\nlog(T )\n)\n,\nand for convex loss functions, Algorithm 2 generates an online sequence {γt}Tt=1, for which the following holds:\nT ∑\nt=1\nℓmt (γ t)−\nT ∑\nt=1\nE [ ft ( α′, β′ )] = O ( GD √ T ) .\nNotice that we compare here the total loss suffered by our algorithms to the expected loss suffered by ARMA prediction with the coefficient vectors that have generated the signal, and not to the expected loss of the best ARMA prediction in hindsight. Nevertheless, this theorem captures interesting cases (e.g., correlated noise), in which traditional approaches fail to perform properly. The proof of this theorem resembles the proof of Theorem 3.1, with the modification of plugging (α′, β′) into Lemmas 3.3 and 3.4, instead of (α⋆, β⋆)."
    }, {
      "heading" : "4.2 Application of Theorem 3.1 to squared loss",
      "text" : "As already mentioned, the squared loss is the most commonly used loss function in time series analysis. It is defined as ℓt(Xt, X̃t) = (Xt − X̃t)2 for prediction X̃t and signal Xt. In our case, the predictions come from an AR model with horizon (m+ k), and hence our loss at time t is (Xt − ∑m+k i=1 γ t iXt−i)\n2, when {γt}Tt=1 are generated using Algorithm 1. Substituting the values of G, D and λ, as defined and computed in Subsection 3.1 for the squared loss, yields the following result:\nT ∑\nt=1\nℓmt (γ t)−min\nα,β\nT ∑\nt=1\nE [ft(α, β)] = O ( k log (T ) + q log2 (T ) ) . (12)\nThis result implies that the average loss suffered by Algorithm 1 converges asymptotically to the average loss suffered by the best ARMA prediction in hindsight, under the assumptions from Section 2.3. In section 5 we empirically verify this theoretical result, under some different settings."
    }, {
      "heading" : "5 Experiments",
      "text" : "The following experiments demonstrate the prediction effectiveness of the proposed algorithms, under some different settings. We compare the performance to the ARMA-RLS algorithm, which was presented in [DSC06]. In a few words, the ARMA-RLS is a “proper learning” algorithm — it tries to mimic the underlying model. It estimates the noise terms using a recursive least squares based method, and satisfies a prediction using these estimations and the previous signals. The ARMA-RLS does not assume noise stationarity or ergodicity. We also benchmark the standard Yule-Walker estimation method3. The results are displayed in the figures below. In all cases, the x-axis is time (number of samples), and the y-axis is the average squared loss."
    }, {
      "heading" : "5.1 Experiments with artificial data",
      "text" : "In all experimental settings below we have averaged the results over 20 runs for stability. Also, we choose the order of our AR prediction to be m+ k = 10 in all settings.\nSetting 1. We started with a simple sanity check using Gaussian noise. We generated a stationary ARMA process using the coefficient vectors α = [0.6,−0.5, 0.4,−0.4, 0.3] and β = [0.3,−0.2], when the noise terms are uncorrelated and normally distributed as N (0, 0.32). Note that since predicting the noise is impossible, a perfect predictor will suffer an average error rate of at least the variance of the noise — 0.09 in this setting. As can be seen in Figure 1(a) the ARMA-ONS algorithm outperforms the other online algorithms due to its lower regret in this setting of exp-concave loss functions, and quickly approaches the performance of the perfect predictor.\nSetting 2. We generated the non-stationary ARMA process using the coefficient vectors β = [0.32,−0.2] and\nα(t) = [−0.4,−0.5, 0.4, 0.4, 0.1] ∗ ( t\n104\n) + [0.6,−0.4, 0.4,−0.5, 0.4] ∗ ( 1− t 104 ) ,\ni.e., the coefficient vectors change slowly in time. The noise terms are uncorrelated and distributed uniformly on [−0.5, 0.5] (denoted as Uni[−0.5, 0.5]). In this setting, a perfect predictor will suffer average error rate of at least 0.0833, due to the variance of the noise. The motivation behind this setting is to demonstrate the effectiveness of the online algorithms in the non-stationary case, in which the coefficients change in time. This is especially important when dealing with real data time series, since the stationarity assumption is rather strict. In Figure 1(b) we can see the clear advantage of our online algorithms. Here again, ARMA-ONS is superior to the other algorithms, despite it being less adaptive — as the theoretical bounds predict; see [HS09] for discussion of adaptivity of OGD vs. ONS.\nSetting 3. Here we consider the non-stationary ARMA process that is generated using two different sets of coefficient vectors. The first set is α = [0.6,−0.5, 0.4,−0.4, 0.3] and β = [0.3,−0.2], and it is used for\n3Yule-Walker estimation method is offline. We use it as an online prediction method by a simple adaptation — we let it predict the signal at time t with the knowledge of the signal at times 1, . . . , t− 1.\ngenerating the signal at the first half of the iterations. The second set is α = [−0.4,−0.5, 0.4, 0.4, 0.1] and β = [−0.3, 0.2], and it is used for generating the signal at the second half of the iterations. The noise terms are uncorrelated and distributed Uni[−0.5, 0.5]. In Figure 1(c) we demonstrate the effectiveness of online algorithms in a scenario when the coefficients abruptly change. Here again, a perfect predictor will suffer average error rate of at least 0.0833, due to the variance of the noise.\nSetting 4. Consider an ARMA process that is generated using the coefficient vectors α = [0.11,−0.5] and β = [0.41,−0.39,−0.685, 0.1]. Each noise term is distributed normally, with expectation that is the value of the previous noise term, and variance 0.32. I.e., the noise terms are positively correlated. In Figure 1(d)\none can clearly see the robustness of online algorithms to correlated noise. Note that despite the correlativity introduced in this setting, ARMA-ONS achieves an average error rate that converges approximately to the variance of the noise — 0.09."
    }, {
      "heading" : "5.2 Experiments with real data",
      "text" : "In this section we provide some preliminary results on real data time series, and show that for such data as well, our online learning approach is reasonably effective compared to existing approaches. For robustness, we consider time series from different fields.\nThe first time series is taken from the field of weather research. Each data point in this time series is the monthly average temperature of the sea surface, measured at a specific point. The data is taken from the Global Climate Observing System (GCOS) website. Since we are dealing with a weather related time series, and considering the monthly average temperature, it is rather reasonable that the time series follows a certain pattern. As can be seen in Figure 2(a), this pattern can be well learned using the ARMA model by all four algorithms. However, the results clearly indicate the superiority of online algorithms.\nThe second time series is taken from the field of finance. Each data point in this time series is the daily return of the S&P 500 index. The data is taken from Yahoo! Finance. The results in Figure 2(b) indicate that the ARMA model is probably not a good model for predicting the returns of the S&P 500 index. A possible reason is that the ARMA model is not rich enough, i.e., knowing the history of returns is not sufficient for satisfying a good prediction. The fact that offline familiar methods also fail here, strengthens this claim. See Section 6 for further discussion about fitting a time series model for financial data."
    }, {
      "heading" : "6 Conclusion and discussion",
      "text" : "In this paper we developed a new approach for time series analysis — an online learning approach. Our main result in this paper is that one can predict time series as well as the best ARMA model, regardless of the loss function considered, under weak assumptions on the noise terms — zero mean distribution. This result is strengthened in light of the fact that the noise terms in the underlying model are unknown to us at any stage. We overcome this difficulty by using improper learning techniques. Additionally, we present an analytical extension of our approach to adversarially generated noise terms. The main powerful properties of the online approach, as pointed out in our work, are generality, simplicity and efficiency, in comparison to existing methods.\nThere are three issues that remain for further research. First, in our analysis we assume that ∑q i=1 |βi| < 1 − ε for some ε > 0, which seems to limit the freedom of the β coefficients. This assumption appears sometimes in the literature (e.g. in GARCH models) and is a sufficient condition for the MA component to be causally invertible, yet not necessary. In our case, we believe that this assumption follows from our proof techniques and the results would still hold for any β coefficients. Second, in Section 4 we present results in which the total loss suffered by our algorithms is compared to the expected loss suffered by ARMA prediction with the coefficient vectors that have generated the signal. Whereas competing against the best ARMA prediction under adversarial noise is impossible because of identifiability issues, it would be interesting to study intermediate setups such as correlated or adversarial noise to some extent. Third, the ARMA model is not compatible for any time series, as can be seen in Section 5.2, when a finance related time series is considered. However, [Eng82] showed that some finance related time series can be well predicted using the ARCH model and its expansions. Therefore, it would be interesting to generalize our work to other time series models, such as ARCH and ARIMA."
    } ],
    "references" : [ {
      "title" : "Time Series Analysis: Forecasting and Control",
      "author" : [ "G. Box", "G. Jenkins", "G. Reinsel" ],
      "venue" : "PrenticeHall, 3 edition,",
      "citeRegEx" : "Box et al\\.,? \\Q1994\\E",
      "shortCiteRegEx" : "Box et al\\.",
      "year" : 1994
    }, {
      "title" : "Prediction, learning, and games",
      "author" : [ "N. Cesa-Bianchi", "G. Lugosi" ],
      "venue" : null,
      "citeRegEx" : "Cesa.Bianchi and Lugosi.,? \\Q2006\\E",
      "shortCiteRegEx" : "Cesa.Bianchi and Lugosi.",
      "year" : 2006
    }, {
      "title" : "El-Shaarawi. ARMA models with double-exponentially distributed noise",
      "author" : [ "A.H.E. Damsleth" ],
      "venue" : "Journal of the Royal Statistical Society. Series B,",
      "citeRegEx" : "Damsleth,? \\Q1989\\E",
      "shortCiteRegEx" : "Damsleth",
      "year" : 1989
    }, {
      "title" : "Performance analysis of estimation algorithms of nonstationary ARMA processes",
      "author" : [ "F. Ding", "Y. Shi", "T. Chen" ],
      "venue" : "IEEE Transactions on Signal Processing,",
      "citeRegEx" : "Ding et al\\.,? \\Q2006\\E",
      "shortCiteRegEx" : "Ding et al\\.",
      "year" : 2006
    }, {
      "title" : "Autoregressive conditional heteroscedasticity with estimates of the variance of united kingdom",
      "author" : [ "R.F. Engle" ],
      "venue" : "inflation. Econometrica,",
      "citeRegEx" : "Engle.,? \\Q1982\\E",
      "shortCiteRegEx" : "Engle.",
      "year" : 1982
    }, {
      "title" : "Logarithmic regret algorithms for online convex optimization",
      "author" : [ "E. Hazan", "A. Agarwal", "S. Kale" ],
      "venue" : "Machine Learning,",
      "citeRegEx" : "Hazan et al\\.,? \\Q2007\\E",
      "shortCiteRegEx" : "Hazan et al\\.",
      "year" : 2007
    }, {
      "title" : "Time Series Analysis",
      "author" : [ "J. Hamilton" ],
      "venue" : null,
      "citeRegEx" : "Hamilton.,? \\Q1994\\E",
      "shortCiteRegEx" : "Hamilton.",
      "year" : 1994
    }, {
      "title" : "Efficient learning algorithms for changing environments",
      "author" : [ "E. Hazan", "C. Seshadhri" ],
      "venue" : "In ICML, page",
      "citeRegEx" : "Hazan and Seshadhri.,? \\Q2009\\E",
      "shortCiteRegEx" : "Hazan and Seshadhri.",
      "year" : 2009
    }, {
      "title" : "Time Series Analysis and Its Applications",
      "author" : [ "R. Shumway", "D. Stoffer" ],
      "venue" : null,
      "citeRegEx" : "Shumway and Stoffer.,? \\Q2005\\E",
      "shortCiteRegEx" : "Shumway and Stoffer.",
      "year" : 2005
    }, {
      "title" : "Jackknifing multiple-window spectra",
      "author" : [ "D. Thomson" ],
      "venue" : "In ICASSP,",
      "citeRegEx" : "Thomson.,? \\Q1994\\E",
      "shortCiteRegEx" : "Thomson.",
      "year" : 1994
    }, {
      "title" : "Time series models in non-normal situations: Symmetric innovations",
      "author" : [ "M. Tiku", "W.K. Wong", "D. Vaughan", "G. Bian" ],
      "venue" : "Journal of Time Series Analysis,",
      "citeRegEx" : "Tiku et al\\.,? \\Q2000\\E",
      "shortCiteRegEx" : "Tiku et al\\.",
      "year" : 2000
    }, {
      "title" : "Online convex programming and generalized infinitesimal gradient ascent",
      "author" : [ "M. Zinkevich" ],
      "venue" : "In ICML,",
      "citeRegEx" : "Zinkevich.,? \\Q2003\\E",
      "shortCiteRegEx" : "Zinkevich.",
      "year" : 2003
    } ],
    "referenceMentions" : [ ],
    "year" : 2013,
    "abstractText" : "In this paper we address the problem of predicting a time series using the ARMA (autoregressive moving average) model, under minimal assumptions on the noise terms. Using regret minimization techniques, we develop effective online learning algorithms for the prediction problem, without assuming that the noise terms are Gaussian, identically distributed or even independent. Furthermore, we show that our algorithm’s performances asymptotically approaches the performance of the best ARMA model in hindsight.",
    "creator" : "LaTeX with hyperref package"
  }
}