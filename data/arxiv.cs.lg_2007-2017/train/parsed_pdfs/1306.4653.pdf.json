{
  "name" : "1306.4653.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "Multiarmed Bandits With Limited Expert Advice",
    "authors" : [ "Satyen Kale" ],
    "emails" : [ "sckale@us.ibm.com" ],
    "sections" : [ {
      "heading" : null,
      "text" : "ar X\niv :1\n30 6.\n46 53\nv1 [\ncs .L\nG ]\n1 9\nJu n\n20 13\nin each round, which has a regret bound of 4 √\nmin{K,M}N log(N) M T after T rounds."
    }, {
      "heading" : "1 Introduction",
      "text" : "Consider the following advice-efficient setting of the multiarmed bandits with expert advice problem, introduced by Seldin et al. [2]. In each round t = 1, 2, . . . , T , we are required to pull one arm At ∈ {1, 2, . . . ,K} =: K. Simultaneously, an adversary sets losses ℓt(a) ∈ [0, 1] for each arm a ∈ K. Assisting us in this task are N experts in the set N = {1, 2, . . . , N}. Each expert h can provide advice on which arm to pull in the form of a probability distribution ξht on the set of arms. This advice gives the expert h an expected loss of ξht ·ℓt in round t. The catch is that we can only observe the advice of at most M experts of our choosing in each round. The goal is to choose subsets of M experts in each round to query the advice of, and using their advice play some arm At ∈ K (probabilistically, if desired) to minimize the expected regret with respect to the loss of the best expert, where the regret is defined as:\nRegretT := T ∑\nt=1\nℓt(At)−min h∈N\nT ∑\nt=1\nξht · ℓt.\nIn the following sections we give an algorithm whose expected regret is bounded by\n4\n√\nmin{K,M}N log(N) M T\nafter T rounds. This matches the regret of the best known algorithms (up to the O( √ logN) factor)\nfor the special cases M = 1 and M = N , and interpolates between them for intermediate values of M . This solves the COLT 2013 open problem proposed by Seldin et al. [2], and in fact gives a\nbetter regret bound than the bound conjectured in [2], which was O\n(\n√\nKN log(N) M T\n)\n."
    }, {
      "heading" : "2 Preliminaries",
      "text" : "For any event E, let I{E} be the indicator random variable set to 1 if E happens. In any round t of the algorithm, let Prt[·] and Et[·] denote probability and expectation respectively conditioned on all the randomness defined up to round t− 1.\nWithout loss of generality, we may assume that each expert suggests exactly one arm to play in any round; i.e. ξht (a) = 1 for exactly one arm a ∈ K and 0 for all other arms. Call such advice vectors “standard basis vectors”. To see this, for every expert h we can randomly round a general advice vector ξht to a standard basis vector by sampling some arm ah ∼ ξht and constructing a new advice vector ξ̂ht by setting ξ̂ h t (ah) = 1 and ξ̂ h t (a) = 0 for all a 6= ah. Note that in E[ξ̂ht ] = ξht ; thus for any expert h following the randomly rounded advices ξ̂ht for t = 1, 2, . . . , T has the same expected cost as following the advices ξht . Since this randomized rounding trick can be applied to the advices (algorithmically for the observed advices, and conceptually for the unobserved advices), in the rest of the paper we assume that all advice vectors are standard basis vectors; this helps us in getting a tighter bound on the regret.\nFor any time period t and any set U ⊆ N , define the “active set of arms” to be the set of all arms recommended by experts in U , i.e.\nKUt = {a ∈ K : ∃h ∈ U s.t. ξht (a) = 1}.\nNote that since we are allowed to query at most M experts in any round, if U is the queried set of experts in round t, then |KUt | ≤ min{K,M}; this leads to min{K,M} factor in the regret bound. Define K ′ := min{K,M}, the effective number of arms."
    }, {
      "heading" : "3 Algorithm",
      "text" : "Partition the N experts into R = N/M groups of M experts each arbitrarily. Call the groups B1, B2, . . . , BR, and define R := {1, 2, . . . , R}. Run the Multiplicative Weights (MW) algorithm on all the experts, where the loss of expert h at time t is given as\nY ht := ξ h t · ℓ̂ht ,\nwhere ξht is the probability distribution over the K arms specified by expert h at time t, ℓ̂ h t is an estimator for the losses of the arms (we will specify this later; we will ensure that ℓ̂ht = 0 for all but M experts so that only M experts need to be queried for their advice). If the distribution over experts generated by the MW algorithm at time t is qt, then the distribution in round t+1 is specified by the following update rule:\nqt+1(h) := qt(h) exp(−ηY ht )/Zt,\nwhere Zt is the normalization constant required to make qt+1 a distribution, and η is a learning rate parameter to specified later.\nDefine the probability distribution rt over group indices R as rt(i) = ∑\nh∈Bi qt(h). Each group\nBi defines a probability distribtion over arms:\npit :=\n∑\nh∈Bi qt(h)ξ h t\n∑\nh∈Bi qt(h)\n=\n∑\nh∈Bi qt(h)ξ h t\nrt(i) .\nFor some parameter γ ≤ 1/2 to be defined later, do the following in round t. With probability γ, sample It uniformly from R and At uniformly from KBIt , and with probability (1 − γ), sample It from rt, and At from p It t . Play At and observe its loss ℓt(At). For every group Bi, define the loss estimator given by\nℓ̂it(a) :=\n{\nℓit(a) I{It=i,At=a} Prt[i,a] if a ∈ KBit 0 otherwise, (1)\nwhere for a ∈ KBit , Pr t [i, a] = (1− γ)rt(i)pit(a) +\nγ\nR|KBit | is the probability of the event {It = i, At = a}, conditioned on all the randomness up to round t− 1.\nFor all experts h ∈ Bi, define the loss estimator:\nℓ̂ht := ℓ̂ i t.\nNote that except for h ∈ BIt , all ℓ̂ht are zero, and for BIt , the probabilities Prt[It, a] for all arms a can be computed using the only the advices of the experts h ∈ BIt . Thus Y ht for all experts h can be computed and the algorithm is well-defined."
    }, {
      "heading" : "4 Analysis",
      "text" : "Theorem 1 Set η = √\nM log(N) K ′NT and γ = min\n{\n√\nK ′N log(N) MT , 12\n}\n. Then the expected regret of the\nalgorithm is bounded by 4\n√\nK ′N log(N) M T .\nProof: For T ≤ 4K ′N log(N) M\n, the regret of the algorithm is trivially bounded by T ≤ 4 √\nK ′N log(N) M T .\nSo assume T > 4K ′N log(N) M so that γ =\n√\nK ′N log(N) MT . The MW algorithm guarantees (see [1]) that\nas long as η is chosen so that |ηY ht | ≤ 1 for all t, h, we have for any expert h⋆\nT ∑\nt=1\n∑\nh\nqt(h)Y h t ≤\n∑\nt\nY h ⋆ t + η ∑\nt\n∑\nh\nqt(h)(Y h t )\n2 + logN\nη . (2)\nNow, we have for any expert h⋆\n∑\nt\nE[ℓt(At)] ≤ ∑\nt\nE[ ∑\nh\nqt(h)Y h t ] + γT (By Lemma 2)\n≤ ∑\nt\nE[Y h ⋆ t ] + η ∑\nt\nE[ ∑\nh\nqt(h)(Y h t )\n2] + logN\nη + γT (By (2))\n≤ ∑\nt\nξh ⋆ t · ℓt + η 2K ′N\nM T +\nlogN\nη + γT (By Lemmas 1 and 3)\n≤ ∑\nt\nξh ⋆ t · ℓt + 4 √ K ′N log(N)\nM T,\nusing η =\n√\nM log(N) K ′NT =\n√\nlog(N) RK ′T and γ =\n√\nK ′N log(N) MT =\n√\nRK ′ log(N) T .\nAll that remains is to verify that |ηY ht | ≤ 1. Let h ∈ Bi. Note that |ℓ̂ht (a)| ≤ RK ′ γ , since if\na /∈ KBit , then ℓ̂ht (a) = 0, and if a ∈ KBit , then Prt[i, a] ≥ γ R|K\nBi t\n| ≥ γ RK ′ . Since Y ht = ξ h t · ℓ̂ht and ξht\nis a distribution over arms, this implies that |Y ht | ≤ RK ′ γ . Thus\n|ηY ht | ≤ √ log(N) RK ′T · √ RK ′T log(N) = 1.\n✷\nLemma 1 For all rounds t and all experts h, we have\nEt[Y h t ] = ξ h t · ℓt and E[Y ht ] = ξht · ℓt.\nProof: Note that Y ht = ∑ a∈K ξ h t (a)ℓ̂ h t (a). We show that for all rounds t, experts h, and arms a, Et[ξ h t (a)ℓ̂ h t (a)] = ξ h t (a)ℓt(a), which implies the required bounds. Let h ∈ Bi. If ξht (a) = 0, then the equality holds trivially. Otherwise, if ξht (a) = 1, then a ∈ KBit , so by the definition of the loss estimator in (1), we have\nEt[ξ h t (a)ℓ̂ h t (a)] = Et\n[\nξht (a)ℓ h t (a) I{It = i, At = a} Prt[i, a] ] = ξht (a)ℓ h t (a) Prt[i, a] Prt[i, a] = ξht (a)ℓ h t (a).\n✷\nLemma 2 For all rounds t we have\nE[ℓt(At)] ≤ E[ ∑\nh\nqt(h)Y h t ] + γ.\nProof:\nEt[ℓt(At)] = ∑\ni∈R\n∑\na∈K Bi t\nℓt(a) Pr t [i, a]\n= ∑\ni∈R\n∑\na∈K Bi t\nℓt(a) · ( (1− γ)rt(i)pit(a) + γ\nR|KBit |\n)\n≤ (1− γ) [ ∑\ni∈R\nrt(i)(p i t · ℓt)\n]\n+ γ (∵ ℓt(a) ∈ [0, 1])\n= (1− γ)\n\n\n∑\ni∈R\n∑\nh∈Bi\nqht ξ h t · ℓt\n\n+ γ\n= (1− γ)Et[ ∑\nh\nqht Y h t ] + γ (By Lemma 1)\n≤ Et[ ∑\nh\nqht Y h t ] + γ,\nsince Y ht ≥ 0. Taking expectation over all the randomness up to time t− 1, the proof is complete. ✷\nLemma 3 For all rounds t we have\nE[ ∑\nh\nqt(h)(Y h t ) 2] ≤ 2RK ′.\nProof: Note that in any round, the algorithm only plays arms in KBItt . Fix the values of the random variables It ∈ R and At ∈ KBItt . Then ∑ h qt(h)(Y h t )\n2 is a deterministic quantity, for which we provide an upper bound below.\n∑\nh\nqt(h)(Y h t )\n2 = ∑\nh∈BIt\nqt(h)(ξ h t · ℓ̂Itt )2\n= ∑\nh∈BIt\nqt(h)\n(\nξh(At) · ℓt(At)\nPrt[It, At]\n)2\n(∵ ℓ̂Itt (a) = 0 for all a 6= At)\n≤ ∑\nh∈BIt\nqt(h)ξ h(At)\n(\n1\nPrt[It, At]\n)2\n(∵ ξh(At) ∈ [0, 1] and ℓt(At) ∈ [0, 1])\n= rt(It)p It t (At) ·\n1\nPrt[It, At]2\n(\n∵ pItt (At) =\n∑\nh∈BIt qt(h)ξ\nh(At)\nrt(It)\n)\n≤ 2 Prt[It, At] , (3)\nsince Prt[It, At] ≥ (1− γ)rt(It)pItt (At) ≥ 12rt(It)p It t (At) because γ ≤ 1/2. Next, we have\nEt[ ∑\nh\nqt(h)(Y h t ) 2] = Et[Et[ ∑\nh\nqt(h)(Y h t ) 2 | It, At ∈ KBItt ]]\n= ∑\nIt∈R\n∑\nAt∈K BIt t\nPr t [It, At] ·\n2\nPrt[It, At] (By (3))\n= ∑\nIt∈R\n2|KBItt |\n≤ 2RK ′. Taking expectation over all the randomness up to time t− 1, the proof is complete. ✷"
    }, {
      "heading" : "Acknowledgments",
      "text" : "The author thanks Elad Hazan, Dean Foster, Rob Schapire, and Yevgeny Seldin for discussions on this problem."
    } ],
    "references" : [ {
      "title" : "The Multiplicative Weights Update Method: a Meta-Algorithm and Applications",
      "author" : [ "Sanjeev Arora", "Elad Hazan", "Satyen Kale" ],
      "venue" : "Theory of Computing,",
      "citeRegEx" : "1",
      "shortCiteRegEx" : "1",
      "year" : 2012
    }, {
      "title" : "Open Problem: Advice-Efficient Adversarial Multiarmed Bandits with Expert Advice",
      "author" : [ "Yevgeny Seldin", "Koby Crammer", "Peter Bartlett" ],
      "venue" : "In COLT,",
      "citeRegEx" : "2",
      "shortCiteRegEx" : "2",
      "year" : 2013
    } ],
    "referenceMentions" : [ {
      "referenceID" : 1,
      "context" : "[2] on minimizing regret in the setting of advice-efficient multiarmed bandits with expert advice.",
      "startOffset" : 0,
      "endOffset" : 3
    }, {
      "referenceID" : 1,
      "context" : "[2].",
      "startOffset" : 0,
      "endOffset" : 3
    }, {
      "referenceID" : 0,
      "context" : "Simultaneously, an adversary sets losses lt(a) ∈ [0, 1] for each arm a ∈ K.",
      "startOffset" : 49,
      "endOffset" : 55
    }, {
      "referenceID" : 1,
      "context" : "[2], and in fact gives a better regret bound than the bound conjectured in [2], which was O ( √ KN log(N) M T )",
      "startOffset" : 0,
      "endOffset" : 3
    }, {
      "referenceID" : 1,
      "context" : "[2], and in fact gives a better regret bound than the bound conjectured in [2], which was O ( √ KN log(N) M T )",
      "startOffset" : 75,
      "endOffset" : 78
    }, {
      "referenceID" : 0,
      "context" : "The MW algorithm guarantees (see [1]) that as long as η is chosen so that |ηY h t | ≤ 1 for all t, h, we have for any expert h T ∑",
      "startOffset" : 33,
      "endOffset" : 36
    }, {
      "referenceID" : 0,
      "context" : "+ γ (∵ lt(a) ∈ [0, 1]) = (1− γ) ",
      "startOffset" : 15,
      "endOffset" : 21
    }, {
      "referenceID" : 0,
      "context" : "h∈BIt qt(h)ξ (At) ( 1 Prt[It, At] 2 (∵ ξ(At) ∈ [0, 1] and lt(At) ∈ [0, 1]) = rt(It)p It t (At) · 1 Prt[It, At] (",
      "startOffset" : 47,
      "endOffset" : 53
    }, {
      "referenceID" : 0,
      "context" : "h∈BIt qt(h)ξ (At) ( 1 Prt[It, At] 2 (∵ ξ(At) ∈ [0, 1] and lt(At) ∈ [0, 1]) = rt(It)p It t (At) · 1 Prt[It, At] (",
      "startOffset" : 67,
      "endOffset" : 73
    } ],
    "year" : 2017,
    "abstractText" : "We solve the COLT 2013 open problem of Seldin et al. [2] on minimizing regret in the setting of advice-efficient multiarmed bandits with expert advice. We give an algorithm for the setting of K arms and N experts out of which we are allowed to query and use only M experts’ advices in each round, which has a regret bound of 4 √ min{K,M}N log(N) M T after T rounds.",
    "creator" : "LaTeX with hyperref package"
  }
}