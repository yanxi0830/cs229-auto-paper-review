{
  "name" : "1409.0553.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "Sampling-based Approximations with Quantitative Performance for the Probabilistic Reach-Avoid Problem over General Markov Processes",
    "authors" : [ "Sofie Haesaert", "Robert Babuska" ],
    "emails" : [ "s.haesaert@tue.nl", "r.babuska@tudelft.nl", "alessandro.abate@cs.ox.ac.uk" ],
    "sections" : [ {
      "heading" : null,
      "text" : "ar X\niv :1\n40 9.\n05 53\nv2 [\nKeywords: General state-space processes, reach-avoid problem, dynamic programming, fitted value iteration, computational approximation with error bounds."
    }, {
      "heading" : "1. Introduction",
      "text" : "This contribution concerns a problem grounded in concepts from a few different areas: we deal with probabilistic processes evolving over continuous (and in particular uncountable) state spaces – this leads to the use of measure-theoretical material from Stochastic Processes and Probability Theory (Meyn and Tweedie, 1993); we work with models endowed with a\ncontrol input and investigate control synthesis, which relate to a broad literature in Control Theory (Bertsekas and Shreve, 1996); furthermore, we are interested in quantifying the probability associated to a dynamical property, known as reach-avoid, which corresponds to a widely used model specification in the field of Formal Verification (Baier and Katoen, 2008); and finally we employ a sampling-based algorithm to approximately compute the likelihood associated to the above specification. The algorithm, known as Fitted Value Iteration (FVI) (Munos and Szepesvari, 2008), is a regression scheme developed in Machine Learning.\nWe focus on stochastic processes endowed with the Markov property (where the future is independent of the past, conditional on the present) and, aiming for generality, we deal with processes evolving over a continuous state space. We are further interested in a class of such models known as stochastic hybrid systems (SHS) (Abate et al., 2008), which are endowed with a “hybrid” (that is, both continuous and discrete) state space, which are relevant for a number of applications in Engineering and the Life Sciences (Blom and Lygeros, 2006; Cassandras and J. Lygeros, 2006). This work investigates the problem of controller synthesis over these models, namely the selection of sequences of control inputs (which in particular can be functions of the states of the model) over a finite time horizon, in order to optimise a given figure of merit.\nAs for the figure of merit of interest in this work, we choose to go beyond the classical properties investigated in Systems and Control theory, which by and large deal with known and standard problems of stability, regulation, and tracking. Instead, we focus on the reachavoid specification, a property that is well known and central within the Formal Verification field (Baier and Katoen, 2008). Notice that classical results in Formal Verification deal with simple models – usually finite-state transition systems or Markov chains – which allow for the development of computational results, and which mostly deal with verification tasks that do not involve policy synthesis. In this work instead we consider reach-avoid specifications over models with continuous stochastic transitions and endowed with control inputs.\nThe reach-avoid problem deals with computing the likelihood that, within a given finite time horizon, a trajectory of the model enters a goal set, while avoiding a given set of undesired states (both sets are arbitrary measurable subsets of the state space). Equivalently, the property can be expressed as the probability that the process enters a goal set while dwelling within a set of allowed states. The reach-avoid property is a generalization of widely studied properties, such as reachability and invariance, and represents a known specification (denoted as “bounded until”) that lies at the core of a number of modal logics used in the field of formal verification, such as Linear Temporal Logic and Computational Time Logic (Baier and Katoen, 2008). From a controller synthesis perspective, the goal becomes that of either maximizing or minimizing the above specification over the given time horizon.\nIn the context of probabilistic models evolving over continuous domains and in discrete time (which is the framework considered in this work), the probabilistic reachability and reach-avoid specifications have been investigated in (Abate et al., 2008; Summers and Lygeros, 2010). These results have recently led to the study of other properties, either richer (Abate et al., 2011) or defined over unbounded time horizons (Tkachev and Abate, 2014). These results have focused on the theoretical characterization of the specifications/properties\nof interest: of course it is also of much interest to provide algorithms that can numerically compute these figures. Computational approaches to probabilistic reachability have been studied in (Abate et al., 2010; Esmaeil Zadeh Soudjani and Abate, 2013): the strength of these results is that the proposed numerical schemes have explicitly quantified error bounds. This is unlike other, known approximation schemes in the literature (Koutsoukos and Riley, 2006; Kushner and Dupuis, 2001; Prandini and Hu, 2006), which provide results with properties that are only known asymptotically.\nThis article provides a new approximate computational scheme for the reach-avoid specification based on the Fitted Value Iteration algorithm, which hinges on random sample extractions. This work originally derives formal probabilistic bounds on the error made by the approximation algorithm. In order to do so, the FVI scheme is tailored to the characterization of the reach-avoid problem, which leads to Dynamic Programming (DP) recursions based on a sum-multiplicative form that is non-standard since it departs from the classical additive (possibly discounted) cost functions (Bertsekas and Shreve, 1996). Starting from the regression bounds in Munos and Szepesvari (2008), this work includes new results on the error for the FVI approximation and a-priori performance guarantees. Additionally, novel and tighter probabilistic error bounds for dynamic programming solutions of the reach-avoid problem based on samples extraction are presented. As a comparison to the alternative techniques in the literature (Abate et al., 2010; Esmaeil Zadeh Soudjani and Abate, 2013), we show the related techniques provide bounds that are valid deterministically, whereas the proposed result yields tighter results in general that are valid with a certain (tunable) confidence. The outcomes lead to an approach providing controller synthesis with a certified performance, which is relevant for safety-critical applications (Blom and Lygeros, 2006). The proofs of the statements are included in the Appendix."
    }, {
      "heading" : "2. Probabilistic Reach-Avoid Problem over General Markov Processes",
      "text" : "Definition 1 (General Markov process) A discrete-time general Markov process is comprised of:\n• A continuous (uncountable) state space X ⊂ Rn;\n• An action space A = {a1, . . . , am} consisting of a finite number of actions;\n• A Borel-measurable stochastic kernel Tx, which assigns to each state-action pair x ∈ X and a ∈ A a probability distribution Tx (· | x, a) over X .\nWe denote with (X ,B(X ), P ) a probability structure on X , where B(X ) is the σ-algebra associated to X and P is characterized as P (y ∈A|x∈X , a∈A)= ∫\nA Tx(dy|x, a). We assume that the stochastic kernels admit densities so that ∫\nA Tx (dy | x, a) = ∫ A tx (y | x, a) dy.\nDefinition 2 (Markov policy) A Markov policy µ over horizon [0, Nt] is a sequence µ = (µ0, µ1, . . . , µNt−1) of universally measurable maps, µk : X → A, k = 0, 1, . . . , Nt − 1, from the state space X to the action space A. The set of Markov policies is denoted as M.\nThe evolution of the general Markov process is considered over a finite horizon k = 0, 1, . . . , Nt, with Nt ∈ N. Consider a discrete-time general Markov process, a Markov policy µ, a deterministic initial state x0 ∈ X and a finite time horizon Nt: an execution of the process characterizes a state trajectory given as {xk|k = 0, 1, . . . , Nt}. The process evolves over the product space (X )Nt+1, which is again endowed with a (product) σ-algebra and allows computing probability associated to events over trajectories – we denote this probability by P, and further define the probabilities Px0 ,P µ x0 as P conditioned on an initial state and on an initial state and a policy, respectively. The state at the (k + 1)-st time instant, xk+1, is obtained as a realization of the controlled Borel-measurable stochastic kernel Tx (· | xk, µk(xk)). The model can be initialized according to an initial probability measure P0 ∈ M(X ), where M(·) denotes the collection of probability distributions over a given set."
    }, {
      "heading" : "2.1 Probabilistic Reach-Avoid Problem: Definition",
      "text" : "Let us define the probabilistic reach-avoid problem, also known as constrained reachability (Baier and Katoen, 2008), and provide its characterization. Consider a safe set A ∈ B(X ), a target set K ∈ B(X ), and a finite time horizon Nt ∈ N. A given state trajectory {xk|k = 0, 1, . . . , Nt} verifies the reach-avoid property if it reaches the target set K within the time horizon, while staying inside the safe set A. This property can be expressed as\n∃j ∈ [0, Nt] : xj ∈ K ∧ ∀i ∈ [0, j − 1] : xi ∈ A \\K.\nLet us now consider the probabilistic reach-avoid property for a general stochastic system, defined as the probability that an execution associated with a fixed Markov policy µ ∈ M and an initial condition x0 ∈ X reaches the target set K while avoiding X \\ A. Formally,\nrµx0(K,A) = P µ x0 {∃j ∈ [0, Nt] : xj ∈ K ∧ ∀i ∈ [0, j − 1] : xi ∈ A \\K} , (1)\nwhere the states x0, x1, . . . , xNt ∈ X are sampled via the stochastic kernel Tx under policy µ. The formula contained in (1) can be written as a boolean expression using indicator functions, which leads to an expectation over the state trajectories as\nrµx0(K,A) = E µ x0\n[\n∑\nj∈[0,Nt]\n(\n∏j−1 i=0 1A\\K(xi)\n)\n1K(xj)\n]\n,\nwhere 1B(x) = 1 if x ∈ B, else it is equal to 0. The reach-avoid problem subsumes other known problems widely studied in System and Control Theory and in Formal Verification, such as that of reachability of set K, which is simply obtained by selecting A = X , or that of invariance within a set B, which is characterized as the dual of the reachability problem over set X \\B.\nFor a given policy µ, the time-dependent value function Wk : X → [0, 1], defined as\nW µk (x)= E µ\n[\n∑\nj∈[k+1,Nt]\n(\nj−1 ∏\ni=k+1\n1A\\K(xi)\n)\n1K(xj)\n∣ ∣ ∣ ∣ xk = x ] ,\nis the probability that the state trajectory {xk+1, . . . , xNt}, starting from xk, will reach the target set K within the time horizon [k,Nt], while staying within the safe set A. This function allows expressing the reach-avoid probability backward recursively, as follows.\nProposition 3 Given a policy µ = (µ0, µ1, . . . , µNt−1), define function W µ k : X → [0, 1] by backward recursion\nW µk (x) = E µk x [ 1K(xk+1) + 1A\\K(xk+1)W µ k+1(xk+1) ] ,\nand initialized with W µNt(x) = 0. Then for any initial state x0 ∈ X , the probabilistic reachavoid property rµx0(K,A) can be expressed as\nrµx0(K,A) = 1K(x0) + 1A\\K(x0)W µ 0 (x0) .\nProof The proof follows (Summers and Lygeros, 2010, Lemma 4), where the above statement is proven for a value function V µk (x) = 1K(x) + 1A\\K(x)W µ k (x).\nNotice that, while the probabilistic reach-avoid problem has been formulated above via DP recursions, it hinges on a sum-multiplicative characterization which is non-standard: much of the analytical and computational results in DP are formulated for additive (possibly discounted) cost functions (Bertsekas and Shreve, 1996).\nRather than selecting and fixing a policy µ as done above, we now focus on the controller synthesis problem, which seeks the Markov policy µ∗ that maximizes the probabilistic reach-avoid property, and which is such that r∗x0(K,A) = supµ∈M r µ x0(K,A). Let us emphasize that the optimization is over finite-action policies, which are however functions of the continuous state space. The optimal policy can be characterized as follows.\nProposition 4 Define functions W ∗k : X → [0, 1], by the backward recursions\nW ∗k (x) = max a∈A Eax [ 1K(xk+1) + 1A\\K(xk+1)W ∗ k+1(xk+1) ] ,\nwith xk+1 ∼ Tx (· | x, a) for k = Nt − 1, Nt − 2, . . . , 0, and initialized by W ∗Nt(x) = 0. Then for any initial state x0 ∈ X the optimal probabilistic reach-avoid property r∗x0(K,A) can be expressed as\nr∗x0(K,A) = 1K(x0) + 1A\\K(x0)W ∗ 0 (x0).\nFurthermore, µ∗k : X → A for k = Nt − 1, Nt − 2, . . . , 0, is such that ∀x ∈ X :\nµ∗k(x) = argmax a∈A Eax [ 1K(xk+1)+1A\\K(xk+1)W ∗ k+1(xk+1) ]\nand µ∗ = (µ∗0, µ ∗ 1, . . . , µ ∗ Nt−1 ) is the optimal probabilistic reach-avoid Markov policy.\nProof See again (Summers and Lygeros, 2010, Theorem 6) and (Abate et al., 2008).\nFor a given time horizon Nt, the computation of r ∗ x0(K,A), as in Proposition 4, can be seen as the application ofNt mappings. More precisely, let us define a dynamic programming operator T as W ∗k = TW ∗ k+1, such that for all states x ∈ X , the function W ∗k : X → [0, 1] is defined as\nW ∗k (x) = ( TW ∗k+1 ) (x) (2)\n= max a∈A\nEax [ 1K(xk+1)+1A\\K(xk+1)W ∗ k+1(xk+1) ] .\nThe value of the optimal probabilistic reach-avoid property can be written as the composition of Nt mappings,\nr∗x0(K,A) = 1K(x0) + 1A\\K(x0) ( T NtW ∗Nt ) (x0)."
    }, {
      "heading" : "2.2 Computation of the Reach-Avoid Probability",
      "text" : "Notice that generally it is not possible to solve the above recursions exactly: in order to determine the backwards iteration at a single point xi ∈ X , namely W ∗k (xi) = ( TW ∗k+1 )\n(xi), one should exactly solve (2). The exact solution of (2) however is seldom analytical and can possibly result in computationally expensive procedures. The absence of an analytical representation for W ∗k : X → [0, 1] leads to the use of approximation techniques, which can be categorized in two families:\n1. Numerical approximation techniques, which provide an approximation of the optimal probabilistic reach-avoid problem with actual error bounds. More precisely, for a given error bound ∆ > 0 we seek a numerical scheme that obtains an approximation r̂∗x0(K,A), which is such that |r̂∗x0(K,A) − r∗x0(K,A)| ≤ ∆. This approach is taken in (Abate et al., 2010; Esmaeil Zadeh Soudjani and Abate, 2013), and the scheme is prone to suffer from the curse of dimensionality, since it approximates a general stochastic system with a Markov chain by partitioning the state space. 2. Probabilistic approximation techniques, which approximate the original problem with probabilistic guarantees. The obtained approximation scheme r̂∗x0(K,A) for r ∗ x0(K,A)\ndepends on a finite number of samples or sampled paths of the underlying model. For a given error bound∆ > 0 and confidence 1−δ∆, the probability that the approximation is not close to the the optimal value can be bounded probabilistically as\nP { ∣ ∣r̂∗x0(K,A) − r∗x0(K,A) ∣ ∣ > ∆ } ≤ δ∆. (3)\nIn this work, we newly pursue the second approach by focusing on results from the area of learning, and in particular on algorithms for functional approximations. A learning approach is suitable for complex systems, such as general Markov processes, since it replaces model-based evaluations by model-free, sample-based evaluations (Busoniu et al., 2010). We adopt the Fitted Value Iteration scheme (FVI) (Munos and Szepesvari, 2008), a learning algorithm fit in particular for finite horizon settings. In practice, bounds for probabilistic approximation methods (3) can be divided into two groups. Firstly, general model-free and sample-free bounds, which provide a-priori guarantees on the achievable accuracy for a finite sample set. Though they can show convergence in probability up to a bias term, their generality can render them conservative when used\nas a tool to assign an accuracy guarantee. Alternatively, model-based and sample-based bounds: these bounds verify the accuracy of a dynamic programming scheme by drawing samples of the model and using available information from the model, and from the specific reach-avoid property under study. In the analysis of the algorithm these bounds can be perceived as complementary. A-priori and sample-free bounds are derived in Section 4 based on model-free/distribution-free notions, whereas model-based and sample-based bounds are given in Section 5."
    }, {
      "heading" : "3. Fitted Value Iteration",
      "text" : "In this section we consider a learning algorithm that has been developed to solve additivecost optimal control problems, and adapt it to the reach-avoid optimal control setting. Known as FVI Munos and Szepesvari (2008), the algorithm extracts a finite number of samples from the underlying model to numerically approximate the value recursions in (2). More precisely, the scheme generalizes the information gathered from the samples to approximate the “exact” optimal value function W ∗k as Ŵ ∗ k in two steps: first by estimating W ∗k over a finite number of states, thereafter fitting the analytical function Ŵ ∗ k ∈ W to the estimate. We define W to be a strict subset of B(X ; 1), the class of measurable functions defined over X , lower bounded by 0 and upper bounded by 1.\nAlgorithm 1: Sample generation for the FVI algorithm\nGiven a safe set A, a target set K, a time horizon Nt, and distribution η, generate N base points, and M samples at each base point as follows:\n1. Draw N base points ( xik ) 1≤i≤N from the distribution η in A \\K; 2. Draw M samples at each base point xik and at each actions a ∈ A from the stochastic kernel Tx, and denote the set of samples as ( xi,a,jk+1 )\n1≤j≤M .\nThe FVI algorithm employs samples that are generated by the underlying model. Samples referred to as “base points” are taken from a chosen distribution η, and additional samples are drawn at the base points from the transition kernel. Algorithm 1 summarizes the sample generation. Let us remark that at each iteration k = Nt − 1, . . . , 0, a new set of samples is generated and used. We denote as “sample complexity” the cardinality of the sample generation, namely N and M .\nAt each (backward) iteration k = Nt − 1, . . . , 0, the algorithm executes two steps in order to approximate the exact recursion in (2):\n1. The first step consists of estimating the value of the backward mapping (TŴ ∗k+1)(x i k)\nat N base points xik. The recursion (TŴ ∗ k+1)(x i k) is estimated by an empirical operator T̂ as follows:\n( T̂Ŵ ∗k+1 ) (xik) = max a∈A\n1\nM\nM ∑\nj=1\n1K(x i,a,j k+1) + 1A\\K(x i,a,j k+1)Ŵ ∗ k+1(x i,a,j k+1). (4)\nHere xi,a,jk+1 represent M independent and identically distributed realizations obtained from Tx ( · | xik, a ) . Hence, j ∈ [1,M ], i ∈ [1, N ], and a ∈ A. For an increasing number\nof samples xi,a,jk+1 , the estimate (T̂Ŵ ∗ k+1)(x i k) converges to (TŴ ∗ k+1)(x i k) with probability 1, by the law of large numbers.\n2. In the second step, function Ŵ ∗k ∈ W is estimated as the solution of\nŴ ∗k = arg min w∈W\nN ∑\ni=1\n∣ ∣ ∣ w(xik)− T̂Ŵ ∗k+1(xik) ∣ ∣ ∣ p . (5)\nWe assume that the argument of the minimum belongs to the function class (this fact will be further discussed below). The base points (xik)1≤i≤N are independently drawn from a distribution η supported over the set A \\K. The power factor p ≥ 1 is a given positive number. Given a function w(x) and an increasing value of N , the summation in (5) converges to ∫\nA\\K |w(x)−T̂Ŵ ∗k+1(x)|pη(x)dx, by the law of large numbers. This leads (cf. Section 4) to the convergence of the argument Ŵ ∗k to the optimal fit that minimizes the distance between T̂Ŵ ∗k+1 and the functions w ∈ W with respect to the p-norm, weighted by a distribution with density η and supported over the set A \\K, namely\n‖Ŵ ∗k −T̂Ŵ ∗k+1‖p,η = ( ∫\nA\\K\n|Ŵ ∗k (x)−T̂Ŵ ∗k+1(x)|pη(x)dx )\n1 p\n.\nThe overall FVI algorithm is summarized in Algorithm 2. The iterations are initialized as Ŵ ∗Nt(x) = 0, x ∈ X , and updated over the functions Ŵ ∗Nt−1, Ŵ ∗Nt−2, . . . , Ŵ ∗1 . Finally the value function at k = 0 is approximated at the initial condition x0 with a sample-based integration, similar to (4), using M0 independent and identically distributed realizations of Tx (· | x0, a) for all a ∈ A.\nAlgorithm 2: Fitted Value Iteration algorithm\nGiven an initial condition x0 ∈ X , a safe set A, a target set K, a time horizon Nt, a set of N base points and of M samples at each base point (for each iteration k), a number p and a distribution η, perform:\n1. Initialize Ŵ ∗Nt(x) = 0, ∀x ∈ X ; 2. For k = Nt − 1 to 1 do\n(a) Collect samples (cfr. Algorithm 1); (b) Estimate TŴ ∗k+1 as ( T̂Ŵ ∗k+1 )\n(xik) (cfr. (4)) (c) Find the function that minimizes the empirical p-norm as\nŴ ∗k = arg min w∈W\nN ∑\ni=1\n∣ ∣ ∣ w(xik)− T̂Ŵ ∗k+1(xik) ∣ ∣ ∣ p ;\n3. Collect M0 samples for the single initial condition x0 and for every action a ∈ A, and estimate Ŵ ∗0 (x0) as in step (2)(b); 4. Return reach-avoid probability\nr̂∗x0(K,A) = 1K(x0) + 1A\\K(x0)Ŵ ∗ 0 (x0), ∀x0 ∈ X .\nRemark 5 (Approximately Optimal Policy) The FVI algorithm can be extended to include the synthesis of a policy a = µ̂k(x). At every iteration in Algorithm 2, first the policy is estimated at all the base points xik, as the argument of (2)(b). Secondly a classification algorithm is used, providing an approximately optimal policy µ̂k : X → A for each k."
    }, {
      "heading" : "4. A-Priori Probabilistic Error Bounds",
      "text" : "Let us recall the accuracy of the FVI algorithm as in (3): we say that the FVI algorithm has an accuracy ∆, with a confidence 1− δ∆, if the probability that the error made by the approximate solution r̂∗x0(K,A) is larger than ∆, is upper-bounded by δ∆. We explicitly quantify the accuracy in (3) and analyse it in two steps: first by computing a bound on the error of a single iteration (Sec. 4.1); then by studying the propagation of the singlestep error over multiple iterations (Sec. 4.2). Notice that this section provides a-priori bounds which are model- and distribution-free, hence computable before applying the FVI algorithm. Alternatively, a-posteriori error bounds based on an additional sample set are proposed in Section 5."
    }, {
      "heading" : "4.1 Error Bounds on a Single Iteration of the FVI",
      "text" : "Let TŴ ∗k+1 : X → [0, 1] be an unknown map, and consider a function class W ⊂ B(X ; 1). Recall that at each iteration k = Nt−1, Nt−2, ..., 1, the objective of the learning algorithm is to find a function w ∈ W that is close to TŴ ∗k+1 with respect to the following weighted, p-norm:\n‖w − TŴ ∗k+1‖p,η = ( ∫\nX\n∣ ∣ ∣ w − TŴ ∗k+1 ∣ ∣ ∣ p η(x)dx\n) 1 p\n. (6)\nNotice that if TŴ ∗k+1 6∈ W, the optimal approximation infw∈W ‖w − TŴ ∗k+1‖p,η provides only a lower bound on this error: the presence of this non-zero bias error indicates that the FVI scheme is not asymptotically consistent, namely that the error does not converge to zero for an increasing sample size. Of interest to this work, a general upper bound on infw∈W ‖w − TŴ ∗k+1‖p,η is derived as\ndp,η(TW,W) = sup g∈W inf f∈W ‖f − Tg‖p,η. (7)\nIn (Munos and Szepesvari, 2008) the bias dp,η(TW,W) is referred to as the inherent Bellman error of the function space W.\nAs discussed, the FVI algorithm employs empirical estimates, given in (4)-(5), of the quantity in (6). Therefore, the single step error hinges both on the inherent Bellman error, and on the deviations caused by using estimates of the recursion step TŴ ∗k+1 over the base points (cfr. Section 4.1.1) and of the norm ‖ · ‖p,η as the integral in (6) (cfr. Section 4.1.2). The error contributions depend on the number of samples used (N,M) and on the capacity of the function class W (Section 4.1.2, and Appendix B), whereas they do not depend on the distribution η, nor on the stochastic state transitions characterizing the model dynamics: as such the bounds are general and “distribution-free”.\nIn the following subsections, two lemmas are derived, which are necessary to obtain a general upper bound for the single step error. First (Section 4.1.1), the error introduced by\nusing the estimation T̂Ŵ ∗k+1 of the recursion step is bounded using Hoeffding’s inequality (Hoeffding, 1963). Then in Section 4.1.2 the maximal deviation of the empirical evaluation of the integral in (6) is bounded using methods from Statistical Learning Theory (Vapnik, 1998)."
    }, {
      "heading" : "4.1.1 Accuracy of the Estimation of TŴ ∗k+1",
      "text" : "Recall that the estimate ( T̂Ŵ ∗k+1 ) (xik) of the exact recursion ( TŴ ∗k+1 ) (xik) uses, for a given state-action pair (xik, a), the individual Monte-Carlo estimates\n1\nM\nM ∑\nj=1\n1K(x i,a,j k+1) + 1A\\K(x i,a,j k+1)Ŵ ∗ k+1(x i,a,j k+1)\nof Ea xi k\n[\n1K(xk+1) + 1A\\K(xk+1)Ŵ ∗ k+1(xk+1)\n]\n. Since the cardinality of the action space A is finite, a bound on the error of the estimates for a given state-action pair can lead to a bound on the error over the states xik: we elaborate on this idea next.\nThe M random quantities for 1 ≤ j ≤ M , 1K(xi,a,jk+1) + 1A\\K(x i,a,j k+1)Ŵ ∗ k+1(x i,a,j k+1), are obtained via independent and identically distributed realizations over the closed interval [0, 1]. Hoeffding’s inequality (Hoeffding, 1963) leads to an upper bound on the deviation of the estimate from the expected value as follows:\nP { ∣ ∣\n∣ Eaxi\nk\n[\n1K(xk+1) + 1A\\K(xk+1)Ŵ ∗ k+1(xk+1)\n]\n− 1 M\nM ∑\nj=1\n[\n1K(x i,a,j k+1) + 1A\\K(x i,a,j k+1)Ŵ ∗ k+1(x i,a,j k+1)\n] ∣\n∣ ∣ ≤ ǫ1\n}\n≥ 1− 2e−2M(ǫ1)2 ,\nwhere ǫ1 is the bound on the error. We can then provide a lower bound on the probability that the deviation incurred by the quantity (\nT̂Ŵ ∗k+1 ) (xik) is bounded by ǫ1 via the joint probability of |A| independent events, as follows:\nP {∣ ∣\n∣ TŴ ∗k+1(x i k)− T̂Ŵ ∗k+1(xik)\n∣ ∣ ∣ ≤ ǫ1 }\n≥ ∏\na∈A\nP {∣ ∣\n∣ Eaxi\nk\n[\n1K(xk+1) + 1A\\K(xk+1)Ŵ ∗ k+1(xk+1)\n]\n− 1 M\nM ∑\nj=1\n[ 1K(x i,a,j k+1)+1A\\K(x i,a,j k+1)Ŵ ∗ k+1(x i,a,j k+1) ]\n∣ ∣ ∣ ≤ ǫ1 } .\nLet us now extend the above probabilistic bound for the error computed at a single point xik to a bound for the error over all the N base points: we can express this bound via an empirical p-norm defined over the base points, as follows:\n‖TŴ ∗k+1−T̂Ŵ ∗k+1‖p,η̂ = ( 1\nN\nN ∑\ni=1\n∣ ∣ ∣ TŴ ∗k+1(x i k)− T̂Ŵ ∗k+1(xik) ∣ ∣ ∣ p )1/p . (8)\nThis leads to the following result.\nLemma 6 For a given error bound ǫ1 and sample complexity N and M , the estimation error can be probabilistically bounded as follows:\nP { ‖TŴ ∗k+1 − T̂Ŵ ∗k+1‖p,η̂ ≤ ǫ1 } ≥ 1− δ1, (9)\nwhere δ1 = 1− (1− 2e−2M(ǫ1)2)|A|N , as long as 0 < 2e−2M(ǫ1)2 ≤ 1. Notice that for an increasing number of samples M , by Lemma 6 the empirical norm of the error as in (8) is less than ǫ1 with a probability that increases to 1."
    }, {
      "heading" : "4.1.2 Accuracy of the Empirical Norm",
      "text" : "Let TŴ ∗k+1 : X → [0, 1] be an unknown function and η a probability measure on X , η ∈ M(X ). The objective is to find a function w ∈ W that is close to TŴ ∗k+1 with respect to the following expected loss:\ninf w∈W ‖w−TŴ ∗k+1‖pp,η= inf w∈W\n∫\nX\n|w(x)−TŴ ∗k+1(x)|pη(x)dx.\nThis section provides a bound for the error originating from the use of a finite number of samples to evaluate the loss: this empirical loss is defined as\n‖w − TŴ ∗k+1‖pp,η̂ = 1\nN\nN ∑\ni=1\n|w(xik)− TŴ ∗k+1(xik)|p,\nfor a given set of N random variables drawn independently over A \\K according to xik ∼ η. Let us express a probabilistic bound on this error that holds uniformly over all functions w ∈ W as follows:\nP {\nsup w∈W\n∣ ∣‖w − TŴ ∗k+1‖pp,η−‖w−TŴ ∗k+1‖pp,η̂ ∣ ∣ ≥ ǫp2 } ≤ δ2.\nObserve that since the expected and the empirical losses can be reformulated respectively as the mean and the empirical mean of a loss function, defined informally as f(x) = |w(x) − TŴ ∗k+1(x)|p, the above problem can be framed as the uniform convergence of a standard learning problem (Haussler, 1992; Pollard, 1984; Vapnik, 1998). Resorting to related literature, results on bounds for the error probability of the regression of real-valued functions employ capacity concepts (including Rademacher averages, covering numbers, and pseudo dimensions) of a function class (Bartlett et al., 2005; Hoeffding, 1963). We focus on pseudo dimensions to deal with the capacity (or the complexity) of the function class. By results in (Haussler, 1992) and (Pollard, 1984), we obtain the following uniform convergence bound.\nLemma 7 Let W be a set of finitely parameterized, measurable functions on X taking values in the interval [0, 1] with pseudo dimension dimp (W) = d < ∞. Let (xik)1≤i≤N be generated by N independent draws according to any distribution η on A \\K and let p ≥ 1. Then for any ǫ2 > 0 we have that\nP\n{\nsup w∈W\n∣ ∣‖w − TŴ ∗k+1‖pp,η − ‖w − TŴ ∗k+1‖pp,η̂ ∣ ∣ ≥ ǫp2 } ≤ 4e(d + 1) ( 32e\nǫp2\n)d\ne− Nǫ\n2p 2\n128 . (10)\nThe characterization and computability of the pseudo dimension of a function class is given in Appendix B."
    }, {
      "heading" : "4.1.3 Global Accuracy of Single Iterations",
      "text" : "The error bounds introduced in Lemmas 6 and 7, together with the inherent Bellman error, yield an upper bound on the error introduced at each iteration, which is recapitulated in the following statement. Since the bounds are independent of the distributions η and Tx (· | x, a), they are in fact distribution-free bounds (Bartlett et al., 2005).\nTheorem 8 Consider a reach-avoid property defined over a general stochastic system with continuous state space X and finite action space A. Let A ⊂ X and K ⊂ X be Borel measurable sets and fix p ≥ 1, the distribution η ∈ M(A \\K) and W ⊂ B(X ; 1). Pick any Ŵ ∗k+1 ∈ B(X ; 1) and let T̂Ŵ ∗k+1 and Ŵ ∗k be calculated using (4) and (5). For given upper bounds on\nP { ‖TŴ ∗k+1 − T̂Ŵ ∗k+1‖p,η̂ > ǫ1 } ≤ δ1, and (11) P {\nsup w∈W\n∣ ∣‖w − TŴ ∗k+1‖pp,η − ‖w − TŴ ∗k+1‖pp,η̂ ∣ ∣ > ǫp2 } ≤ δ2, (12)\nthe bound on a single step update is as follows:\nP { ‖Ŵ ∗k − TŴ ∗k+1‖p,η > dp,η(TŴ ∗k+1,W) + ǫ } ≤ δ1 + δ2, (13)\nwhere the optimal approximation is given as a biasing term defined as dp,η(TŴ ∗ k+1,W) = infw∈W ‖w − TŴ ∗k+1‖p,η, and the error ǫ is given as ǫ = 2ǫ1 + 2ǫ2.\nNote that the statement assumes that Ŵ ∗k is the unique solution to the optimization problem in (5). This strict assumption can be weakened by adding a tolerance term to the theorem. The quantity dp,η(TŴ ∗ k+1,W) admits the inherent Bellman error dp,η(TW,W) in (7) as a general upper bound."
    }, {
      "heading" : "4.2 Error Propagation and Global Error Bounds",
      "text" : "We express a global bound on the accuracy of the FVI algorithm ∣ ∣r̂∗x0(K,A) − r∗x0(K,A) ∣ ∣ by using the probabilistic bounds (derived in Section 4.1) on the errors introduced by the approximate one-step mappings | (\nT̂Ŵ ∗1 ) (x0) − ( TŴ ∗1 ) (x0)|, as well as ‖Ŵ ∗1 − TŴ ∗2 ‖p,η, ‖Ŵ ∗2 −TŴ ∗3 ‖p,η, . . . , ‖Ŵ ∗Nt−1−TŴ ∗Nt‖p,η, and by propagating the error introduced by each single iteration to the successive value iterations, as done in the next statement. More precisely, in the following lemma we show that the deviation of the approximate value function Ŵ ∗k from the optimal value function T\nNt−kW ∗Nt can be expressed as a function of this deviation at step k + 1, plus the approximation error introduced at the (Nt − k)th iteration (which has been bounded above). Recall that the optimal value functions can be written as W ∗k = T Nt−kW ∗Nt and that by definition W ∗ Nt = Ŵ ∗Nt .\nLemma 9 Let η be the density of a probability distribution with support on A \\K and tx be the density function of the stochastic kernel Tx. Then\n‖Ŵ ∗k − TNt−kŴ ∗Nt‖p,η ≤ ‖Ŵ ∗k − TŴ ∗k+1‖p,η +B 1 p\n∥ ∥ ∥ Ŵ ∗k+1 − TNt−(k+1)Ŵ ∗Nt ∥ ∥ ∥\np,η ,\nfor k = 0, 1, . . . , Nt − 1, and where B is defined as\nB = sup xk+1∈A\\K\n∫\nA\\K\nmax a∈A tx (xk+1 |xk, a) η(xk) η(xk+1) dxk.\nPutting all the pieces together, the following theorem provides an expression for the global FVI error bound as the accumulation of the errors from the single iterations over the whole time horizon.\nTheorem 10 Consider a reach-avoid problem defined on a Markov process with a continuous state space X and a finite action space A. The optimal reach-avoid probability r∗x0(K,A) for a given target set K, safe set A, initial state x0, and time horizon Nt, is approximated by the quantity r̂∗x0(K,A) obtained with the FVI Algorithm in Algorithm 2, which has an accuracy of ∆ and a confidence δ∆, as stated in (3), if the following holds:\nP\n{\nB0\nNt−1 ∑\nk=1\nB k−1 p ‖Ŵ ∗k − TŴ ∗k+1‖p,η (14)\n+ |Ŵ ∗0 (x0)− TŴ ∗1 (x0)| > ∆ } ≤ δ∆, (15)\nwhere B is given in (14), B0 is defined as\nB0 = sup x1∈A\\K max a∈A tx (x1 | x0, a) η(x1) , (16)\nand where η is the density of a probability distribution supported on A \\ K and tx is the density of the stochastic kernel Tx of the given Markov process.\nRemark 11 Notice that the scaling factor B has a significant influence on the error propagation. It is related to the notion of concentrability of the future-state distribution (Munos and Szepesvari, 2008; Farahmand et al., 2010). If B > 1 the error of the algorithm will increase exponentially with the time horizon, whereas if B < 1 the accuracy of the algorithm will depend mostly on the errors in the last few iterations (backwards in time). It B expresses the maximal concentration of the dynamics (relative to η) over the relevant set A \\ K after one transition starting from distribution η.\nThe case study discussed in Section 6 displays a choice of a density function η leading to bounded values for B and B0, respectively. The relation between the scaling factor B and the model dynamics for the considered Markov process is also analyzed."
    }, {
      "heading" : "4.2.1 Discussion on the Global Error Bounds",
      "text" : "Suppose that we require that the error in the estimation of r∗x0(K,A), with a confidence at least equal to α, is less than ∆, as per (3). Let us assume that there exist positive values ǫ0, ǫ1, ǫ2 such that the approximation error ∆ can be split up into individual bounds based on Theorem 8 and 10 as follows:\n∆ =B0 Nt−1 ∑\nk=1\nB k−1 p dp,η (TW,W) + 2B0\nNt−1 ∑\nk=1\nB k−1 p (ǫ1)\n+ 2B0 Nt−1 ∑\nk=1\nB k−1 p (ǫ2) + ǫ0,\naccounting for, respectively, the inherent Bellman error (Section 4.1); the error on the estimation of TŴ ∗k+1 (Section 4.1.1); the error on the empirical norm (Section 4.1.2); and the error related to |Ŵ ∗0 (x0) − TŴ ∗1 (x0)|. We compute a lower bound on the confidence that the approximation error is bounded by∆ by upper bounding the complementary event. Using a union bounding argument on the probability of invalidating any of the bounding terms in the above equation, we obtain that the probability that the overall error is larger than ∆ is upper bounded with δ∆, as\nδ∆ =0 + (Nt − 1) ( 1− (1− 2e−2M(ǫ1)2)|A|N )\n(17)\n+ (Nt − 1) ( 4e(d + 1) (\n32e ǫp2\n)d e−\nNǫ 2p 2\n128\n)\n+ 1− (1− 2e−2M0(ǫ0)2)|A|,\nwith respectively the inherent Bellman error (Section 4.1), the confidence terms from Lemma 6 with sample complexity M and N , from Lemma 7 with dimp (W) = d < ∞, and from Lemma 6 with M = M0 and N = 1. Eqn. (17) holds as long as 0 < 2e\n−2M(ǫ1)2 ≤ 1 and 0 < 2e−2M0(ǫ0)\n2 ≤ 1. We can observe that it is possible to find finite values for N ,M ,M0 such that 1 − α > δ∆. Moreover for each choice of positive ǫ0, ǫ1, ǫ2 > 0 and confidence 0 ≤ α < 1, the necessary number of samples can be upper bounded by polynomials in 1 ǫ0 , 1ǫ1 , 1 ǫ2 and 11−α , as follows:\nN = ⌈ 128 ( ln(4e(d+ 1)) + d ln(32e) ) ( 1\nǫ2\n)2p\n(18a)\n+ 128dp ( 1\nǫ2\n)2p\nln ( 1\nǫ2\n) + 128 ( 1\nǫ2\n)2p\nln ( 1\nδ2\n)⌉\n,\nM = ⌈ 1\n2\n(\n1 ǫ1\n)2(\nln(2|A|) + ln( 1 δ1 ) + ln(N)\n)⌉\n, (18b)\nM0 = ⌈ 1\n2\n(\n1 ǫ0\n)2(\nln ( 2|A| ) + ln ( 1\nδ0\n)\n)⌉\n, (18c)\nwith positive parameters δ0, δ1, δ2 > 0 such that 1 − α = δ0 + (Nt − 1)δ1 + (Nt − 1)δ2 (derivation in Appendix F).\nNote that the above accuracy does not depend on the dimensionality n of the state space. Therefore the accuracy for models with higher state space dimension will directly depend on the complexity of the function class employed to approximate given value functions. This is unlike standard grid-based numerical approximation techniques, such as that proposed in (Esmaeil Zadeh Soudjani and Abate, 2013), which are known to break down over models with large state-space dimensionality.\nLet us add a few comments on the dependency of the accuracy from several design variables of the FVI algorithm. Firstly, the choice of function class affects both the inherent Bellman error and the pseudo dimension: while the former gives a measure of how well the the function class W can represent the value functions W ∗k , the latter is directly related to the complexity of the function class. The objective is to obtain a low complexity function\nclass that is capable to accurately fit the given value functions. A good accuracy can be hard to attain when a bad choice of the function class leads to both a large bias (due to the inherent Bellman error) and to a large number of samples. Secondly, the sample distribution η defines, together with the state transitions, the scaling factors B and B0. In order to minimize the error propagation caused by B, the distribution η should be “aligned” with the model dynamics characterized by the density of the transition kernel. Finally, the parameters N,M,M0 follow from the required accuracy demands, which are reformulated as polynomial functions depending on ǫ0, ǫ1, ǫ2 and δ0, δ1, δ2, e.g. as in (18a).\nWith regards to the single-step errors, Lemmas 6 and 7 determine a bound uniformly over the whole function class and for any possible probability distribution. The used distributionfree notions lead to conservative bounds (Bartlett et al., 2005), which then result in a large set of required samples. Notice however that the construction allows to compute the bounds a-priori, before any sample is drawn from the system.\nIn conclusion, the formal probabilistic bounds on the error made by the approximation algorithm show that the algorithm converges in probability to the best approximation for an increasing cardinality of the samples."
    }, {
      "heading" : "5. Sample-Based Error Bounds",
      "text" : "In this section, a probabilistic bound on the error of the approximated reach-avoid probability is developed according to a model- and sample-based philosophy. This bound can be computed after the reach-avoid probability has been obtained via dynamic programming as time-dependent, approximate value functions Ŵ ∗k for 0 ≤ k ≤ Nt − 1. The obtained bounds are not only sample dependent but also distribution dependent, since knowledge of the transition kernel is necessary to compute scaling factors such as (14). Throughout the section it is assumed that the used samples are not correlated with Ŵ ∗k , in other words if the estimated value functions Ŵ ∗k are a result of a sampled-based optimization, then the samples used for the bounds in this section are drawn anew and independently.\nThe probabilistic bound on the accuracy P { | r̂∗x0(K,A) − r∗x0(K,A) | > ∆ } ≤ δ∆, as given in (3), and computed now in a sample-based manner, includes an empirical estimate of the quantity | r̂∗x0(K,A) − r∗x0(K,A) |. This sample-based estimate is computed as follows:\na. collect samples (xi)1≤i≤Ñ according to (1) in Algorithm1 (with N = Ñ), and subse-\nquently use (2) with M = M̃ to draw both (yi,a,j1 )1≤j≤M̃ and (y i,a,j 2 )1≤j≤M̃ ;\nb. estimate the single step error (19) for each k; c. estimate the bias (21) for each k; d. compute the multi-step error as a propagation and a composition of the estimates in\n(b.) and (c.). The single step error is estimated as\n∥ ∥Ŵ ∗k − T̂Ŵ ∗k+1 ∥ ∥ 1,η̃ = 1\nÑ\nÑ ∑\ni=1\n∣ ∣Ŵ ∗k (x i)−max a∈A T̂ a 1Ŵ ∗ k+1(x i) ∣ ∣ (19)\nfor all 1 ≤ k ≤ Nt−1. The term on the right is the empirical 1-norm and can be written as a 1-norm with weighting η̃, which is the empirical distribution of η resulting from (xi)1≤i≤Ñ .\nLet the operator T̂aα be, for α = 1, 2,\nT̂ a αŴ ∗ k+1(x i)= 1 M̃\nM̃ ∑ j=1 1K(y i,a,j α )+1A\\K(y i,a,j α )Ŵ ∗k+1(y i,a,j α ). (20)\nThe estimate in (19) is biased due to the maximization over the action space, therefore as a second step we estimate a bound on this bias. The combination of the two sample sets (yi,a,j1 )1≤j≤M̃ and (y i,a,j 2 )1≤j≤M̃ , for each x\ni and a, allows us to estimate this bias for 1 ≤ k ≤ Nt − 1 as\n∥ ∥ ∥ max a∈A ∣ ∣T̂ a 1Ŵ ∗ k+1 − T̂a2Ŵ ∗k+1 ∣ ∣ ∥ ∥ ∥ 1,η̃ . (21)\nIn the following theorem, an expression for the bound on P { | r̂∗x0(K,A) − r∗x0(K,A) | > ∆ } ≤ δ∆ is derived, employing the error propagation technique first used in Section 4.2, the estimates of the single step error above, and the bias (21) in combination with Hoeffding’s inequality (Hoeffding, 1963).\nTheorem 12 Consider a reach-avoid problem defined on a Markov process with a continuous state space X and a finite action space A. The optimal reach-avoid probability r∗x0(K,A) for a given target set K, safe set A, initial state x0, and time horizon Nt, is approximated by the quantity r̂∗x0(K,A) obtained with the FVI Algorithm in Algorithm 2, which has an accuracy of ∆ and a confidence δ∆, as stated in (3), if the following holds:\n∆ = B0 Nt−1 ∑\nk=1\nBk−1 ( ∥ ∥\n∥ Ŵ ∗k − T̂Ŵ ∗k+1\n∥ ∥ ∥\n1,η̃ +\n∥ ∥ ∥ maxa∈A ∣ ∣ ∣ T̂ a 1Ŵ ∗ k+1 − T̂a2Ŵ ∗k+1 ∣ ∣ ∣ ∥ ∥ ∥\n1,η̃\n)\n+B0ǫ+ ǫ0,\n(22a)\nδ∆ = e −2 Ñǫ\n2\nL2 − δ0, (22b)\nwith L = 2 ∑Nt−1 k=1 B k−1, and sample sizes M̃ and Ñ according to the sample sets drawn according to the distribution η. Equation (22a) includes the estimated error as a combination of (19) and (21). The scaling factors B and B0 are computed as in (14) and (16) for the same sampling distribution η. The factors δ0 and ǫ0 are computed as in Lemma 6 with M = M0 and N = 1.\nThe accuracy ∆ depends on two terms, the propagation of the estimated single-step and bias errors over the time horizon up to k = 1, and the estimation errors B0ǫ+ ǫ0 for k = 0, related to the confidence δ∆.\nSuppose that a close-to-optimal policy is given, for example a policy as detailed in Remark 5 and computed from the series of estimated value functions Ŵ ∗k . Then we know that r∗x0(K,A) ≥ r µ̂∗ x0 (K,A), therefore a lower bound on the value of r µ̂∗ x0 (K,A) is also a lower bound on r∗x0(K,A). Note that for a policy µ, the closed-loop Markov process is time dependent. This allows us to estimate rµx0(K,A) directly from traces of this autonomous Markov process. The deviation of this empirical mean can be bounded probabilistically using Hoeffding’s inequality. Additionally an upper bound on the deviation |r̂∗x0(K,A) − rµx0(K,A)| can be computed. The combination of the bound in Theorem 12 and of the bound on |r̂∗x0(K,A)− r µ x0(K,A)| provide a bound on the performance deviation of rµx0(K,A): the\ntriangle inequality leads to |r∗x0(K,A)− r µ x0(K,A)| ≤ |r∗x0(K,A)− r̂∗x0(K,A)|+ |r̂∗x0(K,A)− rµx0(K,A)|. In comparison to the a-priori bound derived in Section 4, the sample-based bounds do not depend on the inherent Bellman error and can be shown to be less conservative in general. Moreover, they provide insight into the accuracy of the iterations steps. However, they give no information about the expected convergence of the algorithm, and they can only be computed after a run of the algorithm. Similarly to the a-priori bounds, they do not depend on the dimensionality of the state space and are expected to scale better than those used for grid-based approaches such as (Esmaeil Zadeh Soudjani and Abate, 2013)."
    }, {
      "heading" : "6. Case Study and Numerical Experiments",
      "text" : "We consider a case study from the literature (Fehnker and Ivančić, 2004), where the goal is to maximize the probability that the temperature of two interconnected rooms, while staying within a comfortable range, reaches a smaller target range within a given finite time horizon. The temperature can be affected using local heaters. A reach-avoid problem is set up by selecting as the safe set A = [17.5 22]2, as the target set K = [19.25 20.25]2, and a fixed time horizon Nt = 10. The case study was implemented in Matlab R2013b on a notebook with 2.6 GHz Intel Core i5 and 16 GB of RAM."
    }, {
      "heading" : "6.1 Model",
      "text" : "The dynamics of the temperature in the two rooms is described by a Markov model, with the temperature of the rooms making up the state space X = R2, and where the possible configurations {OFF,ON} = {0, 1} of the two heaters form the finite action space A. Hence A = {0, 1}×{0, 1}, and as an example the action related to the first heater in the ON mode and the second in the OFF one is given as a = [1 0]T ∈ A. The dynamics at discrete time k is characterized by the following stochastic difference equation:\nxk+1 = Axk +Ba+C+ nk, where (23) A= [\n1−b1−a1,2 a1,2 a2,1 1−b2−a2,1\n] , C = [\nb1xa b2xa\n]\n, and B = [ c1 0 0 c2 ] ,\nand with the following parameters: xa is the ambient temperature (assumed to be constant), bi ≥ 0 is a constant for the average heat loss rate of room i to the environment; aij ≥ 0 is a constant for the average heat exchange rate of room i to room j 6= i; ci ≥ 0 is a constant for the rate of heat supplied by the heater in room i. The parameters re instantiated as b1 = 0.0375, c1 = 0.65, xa = 6, b2 = 0.025, c2 = 0.6, and aij = 0.0625. The noise process nk is a realization of zero-mean Gaussian random variables with covariance ν\n2I2×2 (2-dimensional identity matrix I2×2) and ν = 0.5. Let N (· | µ,Σ) be a 2-dimensional multivariate normal distribution over (X ,B(X )) with mean µ and covariance matrix Σ, then the stochastic kernel Tx is given as\nTx (· | x, a) = N ( · | Ax+Ba+C, ν2I2×2 )\n(24)\nand characterises the probability distribution of the stochastic transitions in (23). The stochastic kernel (24) admits the probability density\ntx (y | x, a) = 1 √\n|Σ|(2π)2 e(− 1 2 (y−µ̄)TΣ−1(y−µ̄)), (25)\nwhere | · | denotes the determinant of a matrix, and as before the covariance matrix equals Σ = ν2I2×2 and the mean value is µ̄ = Ax+Ba+C."
    }, {
      "heading" : "6.2 Application of the Fitted Value Iteration Algorithm",
      "text" : "The FVI scheme is implemented as in Algorithm 2, and approximates the solution of the reach-avoid problem. We obtain an approximation of r∗x0(K,A) = T 10Ŵ ∗10(x0) by T̂Ŵ ∗ 1 (x0), while using the auxiliary functions Ŵ ∗9 , . . . , Ŵ ∗ 1 to approximate TŴ ∗ 10, . . . ,TŴ ∗ 2 in the FVI scheme – equivalently, function Ŵ ∗k approximates T Nt−kŴ ∗Nt . For a given temperature xk at time instant k, the function Ŵ ∗k (xk) gives the approximate probability that the consecutive temperature values xk+1, . . . , xNt will reach the temperature range [19.25, 20.25]\n2 within Nt − k time steps, while staying inside the safe set [17.5, 22]2 .\nIn order to apply the FVI algorithm, we select a uniform distribution η over A \\K to sample from, then select a function class W and a value for p ≥ 1 to solve (5). We consider a function class W composed of Gaussian radial basis function (RBF) neural networks with 50 RBFs with a uniform width of 0.7. The neural network toolbox of Matlab is used to solve the regression problem in (5) as a least-square problem (with p = 2). A neural network with a single layer of hidden units of Gaussian type radial basis functions is proved to be a universal approximator for real-valued functions (Hartman et al., 1990). Furthermore the pseudo dimension of an artificial neural network with W free parameters and k hidden nodes has been upper bounded by O(W 2k2) (Karpinski and Macintyre, 1997; Anthony and Bartlett, 1999). This means that for any desired precision the required number of samples is bounded by a polynomial in the number of hidden nodes.\nThe following quantities are obtained for the sample complexities: N = 600, M = 103, M0 = 10 3. The approximate value functions for Ŵ ∗9 , Ŵ ∗ 5 , and Ŵ ∗ 1 are displayed in Fig. 1. On the top plots, a point on the state space is associated with a probability for the reach-avoid property over the given time horizon. At the bottom, the contour plots (level sets) characterize the set of points that verify the reach-avoid property with a probability at least equal to the given level.\nFig. 2 displays a suboptimal policy µ̂∗ that is obtained via the FVI algorithm as discussed in Remark 5, by employing the tree classification method ClassificationTree.fit of Matlab. Observe that policy µ̂∗9 for k = 9 is not accurate over the flat regions of Ŵ ∗ 9 (corresponding to the blue spots in the left side of Fig. 2 - left plot), which are far away from the reach set K. Since the average heat loss rate of room 1 is the highest, we expect that the heating should be turned on relatively longer. Fig. 2 confirms this, i.e. the red (ON,ON) region is not square-shaped as the heaters stay ON for higher temperatures in room 1 than in room 2."
    }, {
      "heading" : "6.3 Performance of the Fitted Value Iteration",
      "text" : "We are interested in the performance of the FVI algorithm and in analyzing how the computed accuracy deteriorates over the iterations from Nt−1 to 1. Note that the last iteration is of little interest, since it does not include the fitting step. The accuracy is computed using the model-based and sample-based bounds of Section 5. Fig. 3 plots the sample-based estimates of the single step error (19), namely ‖Ŵ ∗k − T̂Ŵ ∗k+1‖1,η̃ and of the bias (21), namely\n∥ ∥maxa∈A ∣ ∣T̂ a 1Ŵ ∗ k+1− T̂a2Ŵ ∗k+1 ∣ ∣ ∥ ∥ 1,η̃ . Observe that the values of both (19) and (21) fall in the interval between 3× 10−3 and 5× 10−3. The bias estimate (21) appears distributed all over this interval, whereas there is a noticeable trend in the plot of (19), which suggests that the first iterations can be fitted more easily. In Fig. 4, the accuracy of the FVI algorithm propagated over the iterations is given, starting from the first iteration ‖Ŵ ∗9 − TW ∗Nt‖η until the last iteration ‖Ŵ ∗1 − TNtW ∗Nt‖η. This accuracy is computed using Theorem 12. The estimates in Fig. 3 are used to compute the estimate of the accuracy ‖Ŵ ∗k − TW ∗Nt‖η and the accuracy ∆ for a given δ∆. For each iteration step, it can be observed in Fig. 3 that the error caused by estimating the dynamic programming operator T and by fitting a function is relatively small (< 10−2). However, the error grows exponentially over the whole horizon: as expected, the accuracy of the algorithm depends strongly on B, which has been computed numerically and amounts to 3.07."
    }, {
      "heading" : "7. Conclusions and Future Work",
      "text" : "This article has investigated the performance of a sample-based approximation scheme for the synthesis of optimal controllers maximizing the probability of the known “reach-avoid” specification. The approximate computational scheme is based on the Fitted Value Iteration\nalgorithm, which hinges on random sample extractions. We are interested in the non-trivial extension to continuous control spaces, as well as in the assessment of the performance of synthesized approximate policies over the concrete model. Finally, the development of better sampling distributions that minimize the error propagation can lead to tighter errors, which can be more relevant in practice. To this end, the optimal sampling distribution should be used to optimize the scaling factors by resembling more closely the local stochastic kernels."
    }, {
      "heading" : "Appendix A. Proof of Lemma 6: Bound on Estimation Error",
      "text" : "We employ results on the concentration of random variables (Anthony, 2002), which in general raise conditions on a random variable ensuring its realizations to be concentrated around its expectation, in the sense that the probability of a deviation from the expectation is exponentially small (as a function of the deviation). Of interest to this work is a known bound holding for sums of bounded and independent random variables Hoeffding (1963).\nProposition 13 (Hoeffding’s inequality, Hoeffding (1963)) Suppose that Xi, for i = 1, 2, . . . , N, are independent random variables supported on [0, 1]. Then\nP {∣ ∣\n∣ ∑N i=1 x i k −E ∑N i=1Xi\n∣ ∣ ∣ ≥ Nǫ } ≤ 2e−2Nǫ2 ,\nwhere E ∑N i=1 Xi is the mean of the random variable ∑ i Xi, whereas the empirical mean is defined as ∑N\ni=1 x i k, where x i k is a realization of Xi.\nUsing Proposition 13 the proof of Lemma 6 is provided as follows.\nProof Let us express a probabilistic error bound on the accuracy of the estimate T̂Ŵ ∗k+1 at each base point xik and given any a ∈ A as\nP { ‖TŴ ∗k+1 − T̂Ŵ ∗k+1‖p,η̂ > ǫ1 }\n≤ δ1, where we have used the empirical norm based on η̂. We obtain\nP { ‖TŴ ∗k+1 − T̂Ŵ ∗k+1‖p,η̂ ≤ ǫ1 } = P { ‖TŴ ∗k+1 − T̂Ŵ ∗k+1‖pp,η̂ ≤ ǫ p 1 }\nvia definition of the empirical norm in (8)\n= P\n{\n1\nN\nN ∑\ni=1\n∣ ∣TŴ ∗k+1(x i k)− T̂Ŵ ∗k+1(xik) ∣ ∣ p ≤ ǫp1 }\nNote the mutual independence between the sample sets at different base points xik given as ⋃\na∈A\n( xi,a,jk+1 )\n1≤j≤M\n≥ P { N ⋂\ni=1\n{ ∣\n∣ ∣ TŴ ∗k+1\n( xik ) − T̂Ŵ ∗k+1(xik) ∣ ∣ ∣ p ≤ ǫp1 }\n}\n= N ∏ i=1 P { ∣ ∣ ∣ TŴ ∗k+1 ( xik ) − T̂Ŵ ∗k+1(xik) ∣ ∣ ∣ ≤ ǫ1 } .\nLet us now express the argument of the probability operator as follows ∣ ∣ ∣ TŴ ∗k+1 ( xik ) − T̂Ŵ ∗k+1(xik) ∣ ∣ ∣\n= ∣ ∣\n∣ max a∈A Exk+1\n[\n1K(xk+1) + 1A\\K(xk+1)Ŵ ∗ k+1(xk+1)\n]\n−max a∈A\n1\nM\nM ∑ j=1 [1K(x i,a,j k+1) + 1A\\K(x i,a,j k+1)Ŵ ∗ k+1(x i,a,j k+1)] ∣ ∣ ∣\nW.r.t Exk+1 defined over random variable xk+1 ∼ Tx ( · | xik, a )\n≤ max a∈A\n∣ ∣ ∣ Exk+1 [ 1K(xk+1) + 1A\\K(xk+1)Ŵ ∗ k+1(xk+1) ]\n− 1 M\nM ∑ j=1 [1K(x i,a,j k+1) + 1A\\K(x i,a,j k+1)Ŵ ∗ k+1(x i,a,j k+1)] ∣ ∣ ∣ .\nTherefore the probability of the last event above can be lower bounded by the probability associated to several independent events over the finite action space, as follows:\nP { ∣ ∣\n∣ TŴ ∗k+1\n( xik ) − T̂Ŵ ∗k+1(xik) ∣ ∣ ∣ ≤ ǫ1 }\n≥ ∏ a∈A\nP { ∣ ∣\n∣ Exk+1\n[\n1K(xk+1) + 1A\\K(xk+1)Ŵ ∗ k+1(xk+1)\n]\n− 1 M\nM ∑\nj=1\n[\n1K(x i,a,j k+1) + 1A\\K(x i,a,j k+1)Ŵ ∗ k+1(x i,a,j k+1)\n] ∣\n∣ ∣ ≤ ǫ1\n}\n.\nFor a given base point xik ∈ X , action a ∈ A, and function Ŵ ∗k+1 ∈ W, define random variables Zj via their realizations 1K(x i,a,j k+1) + 1A\\K(x i,a,j k+1)Ŵ ∗ k+1(x i,a,j k+1), with j = 1, . . . ,M . Since each xi,a,jk+1 is independently drawn from Tx ( · | xik, a )\n, the random variables Zj are independent, identically distributed, and take values within the closed interval [0, 1]. By application of Hoeffding’s inequality (as in Proposition 13), the concentration of the M samples around the expected value of Zj can be expressed as\nP { ∣\n∣Exk+1\n[\n1K(xk+1) + 1A\\K(xk+1)Ŵ ∗ k+1(xk+1)\n]\n− 1 M\nM ∑\nj=1\n[\n1K(x i,a,j k+1) + 1A\\K(x i,a,j k+1)Ŵ ∗ k+1(x i,a,j k+1)\n]\n∣ ∣ǫ1\n}\n≤ 2e−2M(ǫ1)2 .\nTherefore as long as 0 ≤ 2e−2M(ǫ1)2 ≤ 1, it follows that P { ‖TŴ ∗k+1 − T̂Ŵ ∗k+1‖p,η̂ ≤ ǫ1 }\n≥ (\n1− 2e−2M(ǫ1)2 )N |A| .\nRemark 14 As long as we only know that the random variables Zj are bounded, the use of Hoeffding’s inequality is sufficient. If we further have information on the variance of Zj , one can leverage the inequalities of Chebyshev and of Bienaym-Chebyshev (Hoeffding, 1963), or alternatively Bernstein’s inequality (Peshkin and Mukherjee, 2001): the former bounds are only function of the variance, whereas the latter inequality depends not only on variance of Zj but also on its bounded domain. Upper bounds on either the variance of Zj or on its range can be derived exploiting prior knowledge on properties of the function space W and of the distribution Tx (· | x, a)."
    }, {
      "heading" : "Appendix B. Proof of Lemma 7",
      "text" : "We derive a general, analytical bound on the error of a single backward recursion using notions from statistical learning theory (Haussler, 1992; Pollard, 1984). The error bound takes into account that, for any TŴ ∗k+1, the optimal fit can be anywhere in the function class. Furthermore the bound will be distribution-free, namely holding for any Markov process (with dynamics characterized by Tx) and any sample distribution η over the set A \\K.\nWe exclusively consider function classes W ⊂ B(X ; 1) endowed with a finite pseudodimension: this includes all finitely-parameterized function classes (Munos and Szepesvari, 2008). The notion of pseudo dimension (Pollard, 1984; Anthony, 2002; Haussler, 1992) expresses the capability of a function class W to the fit a set of samples. Proof In order to prove Lemma 7, we show that the inequality in (10) holds for any Ŵ ∗k+1 ∈ W at any time instant k = 0, . . . , Nt − 1. For the sake of notation in the following we substitute Ŵ ∗k+1 by W , and instead of considering the set of base points (x i k)1≤i≤N drawn at the time instant k we simply introduce ~x = (x1, . . . , xN ) as a sequence of N independent realizations drawn from a distribution over A \\K with density η.\nFor any given function W ∈ W , induce a new function class lW = {|w−TW |p : w ∈ W} with elements lw ∈ lW : lw = |w − TW |p. The inequality in (10) can be rewritten over the function class lW as follows\nP {\nsup w∈W\n∣ ∣‖w − TW‖pp,η − ‖w − TW‖pp,η̂ ∣ ∣ ≥ ǫp2 } = P {\nsup lw∈lW\n∣ ∣Eη [lw]− 1\nN\nN ∑ i=1 lw(x i) ∣ ∣ ≥ ǫp2 } ,\nwhere Eη denotes the expected value with respect to η. This allows us to use a result in (Pollard, 1984), which provides an upper-bound on the probability of the above event as a function of the covering number of the metric space ((lW)~x, ‖ · ‖1).\nProposition 15 (Pollard (1984)) Let F be a permissable set of functions on X with 0 ≤ f(x) ≤ K for all f ∈ F and x ∈ X . Let ~x = (x1, . . . , xN ) be a sequence of N samples drawn independently from X according to any distribution on X . Then for all ǫ > 0\nP { ∀f ∈ F : ∣\n∣Ef − 1N ∑ ~x f(xi) ∣ ∣ ≥ ǫ } ≤ 4EN (ǫ/16, F|~x, ‖ · ‖1)e− Nǫ2 128K2 , (26)\nwhere the quantity N will be introduced shortly and where the definition of a permissible set of functions (Pollard, 1984) includes all finitely parameterized functions.\nLet us introduce the concept of covering number of a metric space (Haussler, 1992). Given a (pseudo-)metric space (A, ρ) and a subset S of A, we say that the set T ⊆ A is an ǫ-cover for S (where ǫ > 0) if, for every s ∈ S there is a t ∈ T such that ρ(s, t) < ǫ. For a given ǫ > 0 we denote the covering number N (ǫ, S, ρ) (Haussler, 1992) as the cardinality of the smallest ǫ-cover of S.\nFor a given set of samples xi with i = 1, . . . , N , the evaluation of a function lw ∈ lW over each of these samples is given as the N dimensional vector in [0, 1] N : (lw)|~x = (lw(x 1), lw(x 2), . . . , lw(x N )). The induced set of vectors is\n(lW)|~x = {(lw)|~x = (lw(x1), lw(x2), . . . , lw(xN )), lw ∈ lW} ⊆ [0, 1]N .\nThe minimal ǫ-cover of ((lW )|~x, ‖ · ‖1) is denoted as N (ǫ, (lW )|~x, ‖ · ‖1). The deviation of the expected value from the empirical mean can be bounded using Pollard’s proposition (Pollard, 1984)\nP {\nsuplw∈lW ∣ ∣Ex [lw(x)]− 1N ∑N i=1 lw(xi) ∣ ∣ ≥ ǫp2 } ≤ 4E [ N (ǫp2/16, (lW)|~x , ‖ · ‖1) ] e− N(ǫ2)\n2p\n128 .\nThe expected value of N (ǫp2/16, (lW)|~x , ‖ · ‖1) is computed over the samples xi of ~x, drawn independently from a probability distribution with density η. Since there is a trivial isometry (Haussler, 1992) between (lW|~x, ‖ · ‖1) and (lW , ‖ · ‖1,η̂), both spaces have equal covering numbers\nN (ǫp2/16, lW|~x, ‖ · ‖1) = N (ǫ p 2/16, lW , ‖ · ‖1,η̂).\nIn practice a value for E [N (ǫp2/16, lW , ‖ · ‖1,η̂)] can be obtained by upper bounding N (ǫp2/16, lW , ‖ · ‖1,η̂) independently of the sample distribution. For this we introduce the pseudo dimension of a function class, formally defined as follows Pollard (1984); Anthony (2002); Haussler (1992). Suppose F is a class of functions, f ∈ F , f : X → [0, 1]. Then S ⊆ X is shattered by F if there are numbers rx ∈ [0, 1] for x ∈ S such that for every T ⊆ S there is some fT ∈ F with the property that fT ≥ rx if x ∈ T and fT < rx if x ∈ S \\T . We say that F has a finite pseudo dimension dimp (F) = d if d is the maximum cardinality of a shattered set.\nFor any distribution P ∈ M(X ), the packing number (Haussler, 1992) and therefore also tho covering number of the metric space (lW , ‖ · ‖1,P ) can be upper bounded as a function of the pseudo-dimension and the base of the natural logarithm e: for any ǫ > 0,\nN (ǫ, lW , ‖ · ‖1,P ) ≤ e(d+ 1) ( 2e ǫ )d , with dimp(lW) = d.\nWe have proved that a sufficient upper bound is given as\nP {\nsupw∈W ∣ ∣‖w − TW‖pp,η − ‖w − TW‖pp,η̂ ∣ ∣ ≥ ǫp2 } ≤ 4e(d+ 1) (\n32e ǫp2\n)d e− N(ǫ2) 2p 128 .\nThe proof can be concluded by showing that the pseudo dimension d of the induced class lW is the same as the pseudo dimension of W. Let {w − TW : w ∈ W} be a new function class induced from W. The invariance properties of the pseudo dimension dimp(W) shown in (Haussler, 1992) allow to conclude that dimp( { w − TW ∣ ∣w ∈ W }\n) = dimp(W). The induced function class lW can then be defined as follows: lW = { |k|p ∣ ∣k ∈ {w − TW : w ∈ W} }\n. Since it was shown in (Kearns and Schapire, 1994) that the pseudo dimension is invariant over function composition (|·|p), we conclude that the pseudo dimension is dimp(lW) = dimp({w − TW : w ∈ W}) = dimp(W) = d.\nRemark 16 (Computing the pseudo-dimension) When the function class W is a vector space of real-valued functions, the pseudo dimension is equal to the dimensionality of the function class (Anthony and Bartlett, 1999, Theorem 11.4). (Anthony and Bartlett, 1999) elaborates the details of the computation of pseudo dimensions of parameterized function classes, especially for function classes defined over neural networks.\nSince it is possible to bound the pseudo dimension of lW (as introduced in the proof) by the pseudo dimension of W, this capacity concept has been used to bound the error caused by using an empirical estimate of the weighted p-norm. Notice that for non-parametric function classes, concepts such as covering number or Rademacher average of the function class lW can be used instead (Bartlett et al., 2005).\nLet us shortly discuss how the derived bounds can be tightened. A first option is to circumvent the notion of pseudo dimension and work with the covering numbers in Pollard inequality (Proposition 15), however the increase in assumptions on the function class and in overall computations make the gain in accuracy undeserving. A second option is to explore alternatives over Pollard inequality in (15) with better constants (Bartlett et al., 2005). An alternative concentration inequality based on Bernstein’s inequality is used in (Peshkin and Mukherjee, 2001). Hoeffding inequality gives a concentration inequality on the sum of bounded random variables, whereas Bernstein inequality gives a tighter bound based on knowledge of both the boundness and the variance of the random variables. Even with improved constants or alternative inequalities, the error bounds can still result to be conservative for reasonable sample complexities."
    }, {
      "heading" : "Appendix C. Proof of Theorem 8",
      "text" : "The proof of Theorem 8 is adapted from the proof of the single-step error bound for Fitted Value Iteration with multiple sample batches in (Munos and Szepesvari, 2008). Proof Let us introduce a simplified notation for Ŵ ∗k+1 by replacing it with a general functionW ′ ∈ W that minimizes the empirical norm asW ′ = argminw∈W ‖w−T̂W‖p,η̂. Let us further define a space Ω for the batch of samples drawn at any of the iterations, such that\nat any instant k the realized sample batch ω := ⋃\ni∈{1,...,N}\n( xik ∪ ( ⋃ a∈A ( xi,a,jk+1 )\n1≤j≤M\n))\nis an element of the sample space, ω ∈ Ω. For any given ǫ′ > 0, consider a function w∗ ∈ W such that ‖w∗−TW‖p,η ≤ infw∈W ‖w− TW‖p,η + ǫ′ (this in particular holds since W has been assumed to be close and bounded). The error bound in (13) holds for a sample realization ω if the following sequence of inequalities holds simultaneously:\n‖W ′ − TW‖p,η ≤ ‖W ′ − TW‖p,η̂ + ǫ2 (27a) ≤ ‖W ′ − T̂W‖p,η̂ + ǫ1 + ǫ2 (27b) ≤ ‖w∗ − T̂W‖p,η̂ + ǫ1 + ǫ2 (27c) ≤ ‖w∗ − TW‖p,η̂ + 2ǫ1 + ǫ2 (27d) ≤ ‖w∗ − TW‖p,η + 2ǫ1 + 2ǫ2. (27e)\nAs long as the previous sequence of inequalities is true, the following one also holds:\n‖W ′ − TW‖p,η ≤ inf w∈W ‖w − TW‖p,η + 2ǫ1 + 2ǫ2 + ǫ′.\nWe claim that the sequence of inequalities holds with a probability at least 1−(δ1+δ2). Since there exists a function w∗ for any ǫ′ > 0 it follows with a probability at least 1 − (δ1 + δ2) that ‖W ′ − TW‖p,η ≤ dp,η(TW,W) + 2ǫ1 + 2ǫ2. By the union bound argument (Anthony, 2002), the probability of the union of events can be bounded by the sum of the probabilities of the single events. Using this argument it is possible to define a lower bound on the probability associated with the simultaneous\noccurrence of the five inequalities in (27). We first show that the third inequality is always true. Then we give the probability associated to the first inequality (27a) and the fifth (27e) (this is based on (12)). Afterwards we provide an upper bound on the probability associated to the second and fourth inequalities (27b),(27d), based on the bound given in (11).\nThe third inequality (27c) is true for the whole sample space Ω due to the choice of W ′. For all functions w in W it follows that ‖W ′ − T̂W‖p,η̂ ≤ ‖w − T̂W‖p,η̂ holds, because W ′ = argminw∈W ‖w − T̂W‖p,η̂.\nThe first and last inequalities (27a),(27e) bound the deviation between the empirical loss and the expected loss. This can be bounded with the worst case error. Firstly we observe that the inequality\n∣ ∣ ∣ ‖w − TW‖p,η̂ − ‖w − TW‖p,η ∣ ∣ ∣ p ≤ ∣ ∣ ∣ ‖w − TW‖pp,η − ‖w − TW‖pp,η̂ ∣ ∣ ∣\nis always true. In the case that ‖w − TW‖p,η̂ ≤ ‖w − TW‖p,η then ∣\n∣ ∣ ‖w − TW‖p,η̂ − ‖w − TW‖p,η\n∣ ∣ ∣ = ‖w − TW‖p,η̂ − ‖w − TW‖p,η\n‖w − TW‖p,η̂ = (‖w − TW‖p,η̂ − ‖w − TW‖p,η) + ‖w − TW‖p,η ‖w − TW‖pp,η̂ = ((‖w − TW‖p,η̂ − ‖w − TW‖p,η) + ‖w − TW‖p,η) p ‖w − TW‖pp,η̂ ≥ (‖w − TW‖p,η̂ − ‖w − TW‖p,η) p + ‖w − TW‖pp,η\n‖w − TW‖pp,η̂ − ‖w − TW‖pp,η ≥ (‖w − TW‖p,η̂ − ‖w − TW‖p,η) p\n∣ ∣ ∣ ‖w − TW‖pp,η̂ − ‖w − TW‖pp,η ∣ ∣ ∣ ≥ ∣ ∣ ∣ ‖w − TW‖p,η̂ − ‖w − TW‖p,η ∣ ∣ ∣ p\nOn the other hand, for the case when ‖w−TW‖p,η̂ > ‖w−TW‖p,η a similar argument can be used. We can then observe that\n∣ ∣ ∣ ‖w∗ − TW‖p,η̂ − ‖w∗ − TW‖p,η ∣ ∣ ∣ p ≤ sup\nw∈W\n∣ ∣ ∣ ‖w − TW‖pp,η − ‖w − TW‖pp,η̂ ∣ ∣ ∣ ,\nand that ∣\n∣ ∣ ‖W ′ − TW‖p,η − ‖W ′ − TW‖p,η̂\n∣ ∣ ∣ p ≤ sup\nw∈W\n∣ ∣ ∣ ‖w − TW‖pp,η − ‖w − TW‖pp,η̂ ∣ ∣ ∣ .\nGiven two functions w∗ and W ′ define events A1 and A2\nA1 : ǫ p 2 <\n∣ ∣ ∣ ‖w∗ − TW‖p,η̂ − ‖w∗ − TW‖p,η ∣ ∣ ∣ p , A2 : ǫ p 2 < ∣ ∣ ∣ ‖W ′ − TW‖p,η − ‖W ′ − TW‖p,η̂ ∣ ∣ ∣ p .\nObserve that the event sets A1 and A2 are subsets of the more general event B defined as\nB : ǫp2 < sup w∈W\n∣ ∣ ∣ ‖w − TW‖pp,η − ‖w − TW‖pp,η̂ ∣ ∣ ∣ .\nThus it follows that for any ǫ2 > 0: P {A1 ∪A2} ≤ P {B} and, based on (12), we have\nP {{ ∣ ∣‖W ′ − TW‖p,η − ‖W ′ − TW‖p,η̂ ∣ ∣ > ǫ2 } ∪ { ∣ ∣‖w∗ − TW‖p,η̂ − ‖w∗ − TW‖p,η ∣ ∣ > ǫ2 }}\n≤ P {\nsup w∈W\n∣ ∣‖w − TW‖pp,η − ‖w − TW‖pp,η̂ ∣ ∣ > ǫp2\n}\n≤ δ2.\nThus the probability that the inequalities (27a) and (27e) do not hold is less then δ2.\nThe second and fourth inequalities (27b),(27d) depend the accuracy of the estimation of the backward recursion at each base point xik. Employing the inequality |‖w − g‖p,η̂ − ‖w − h‖p,η̂| ≤ ‖g − h‖p,η̂, we can see that\n∣ ∣ ∣ ‖W ′ − TW‖p,η̂ − ‖W ′ − T̂W‖p,η̂ ∣ ∣ ∣ ≤ ‖TW − T̂W‖p,η̂,\nand ∣\n∣ ∣ ‖w∗ − T̂W‖p,η̂ − ‖w∗ − TW‖p,η̂\n∣ ∣ ∣ ≤ ‖TW − T̂W‖p,η̂.\nFor every sample set ω the inequalities (27b),(27d) apply if ‖TW − T̂W‖p,η̂ ≤ ǫ1. Thus\nP {{ ‖W ′ − TW‖p,η̂ − ‖W ′ − T̂W‖p,η̂ > ǫ1 } ∪ { ‖w∗ − T̂W‖p,η̂ − ‖w∗ − TW‖p,η̂ > ǫ1 }}\n≤ P { ‖TW − T̂W‖p,η̂ > ǫ1 }\n≤ δ1. (28)\nThe probability that at least one of the inequalities in (27) does not hold can be expressed using the union bound as δ1 + δ2. Thus the sequence of inequalities holds with at least a probability of 1− δ1 − δ2."
    }, {
      "heading" : "Appendix D. Proof of Lemma 9",
      "text" : "Proof Let us set up the following chain of inequalities:\n‖TNt−kŴ ∗Nt − Ŵ ∗k ‖p,η = [ Add and subtract function TŴ ∗k+1 ]\n= ‖T (\nT Nt−k−1Ŵ ∗Nt − Ŵ ∗k+1 + Ŵ ∗k+1\n)\n− Ŵ ∗k ‖p,η = [ Definition of T in (2), where we have considered a single xk ∼ η ] = ∥ ∥\n∥ max a∈A\nE [ 1K(xk+1) + 1A\\K(xk+1) ( T Nt−k−1Ŵ ∗Nt − Ŵ ∗k+1 + Ŵ ∗k+1 ) (xk+1) ∣ ∣xk+1 ∼ Tx (· | xk, a) ]\n− Ŵ ∗k ∥ ∥ ∥\np,η\n= [ maxE[ξ1 + ξ2] ≤ maxE|ξ1|+maxE|ξ2| ] ≤ ∥ ∥ ∥\n∥ max a∈A\nE ∣ ∣\n∣ 1A\\K(xk+1)\n(\nT Nt−k−1Ŵ ∗Nt − Ŵ ∗k+1\n) (xk+1)|xk+1 ∼ Tx (· | xk, a) ∣ ∣ ∣\n+max a∈A\nE ∣ ∣\n∣ 1K(xk+1) + 1A\\K(xk+1)Ŵ ∗ k+1(xk+1)|xk+1 ∼ Tx (· | xk, a)\n∣ ∣ ∣ − Ŵ ∗k\n∥ ∥ ∥ ∥\np,η\n= [ Triangular inequality] ≤ ∥ ∥ ∥\n∥ max a∈A\nE ∣ ∣\n∣ 1A\\K(xk+1)\n(\nT Nt−k−1Ŵ ∗Nt − Ŵ ∗k+1\n) (xk+1)|xk+1 ∼ Tx (· | xk, a) ∣ ∣ ∣\n∥ ∥ ∥ ∥\np,η\n+\n∥ ∥ ∥ ∥\nmax a∈A\nE ∣ ∣\n∣ 1K(xk+1) + 1A\\K(xk+1)Ŵ ∗ k+1(xk+1)|xk+1 ∼ Tx (· | xk, a)\n∣ ∣ ∣ − Ŵ ∗k\n∥ ∥ ∥ ∥\np,η\n= [ Definition of T in (2) ]\n=\n∥ ∥ ∥ ∥\nmax a∈A\nE [ ∣ ∣\n∣ 1A\\K(xk+1)\n(\nT Nt−k−1Ŵ ∗Nt − Ŵ ∗k+1\n) (xk+1) ∣ ∣ ∣ |xk+1 ∼ Tx (· | xk, a) ]\n∥ ∥ ∥ ∥\np,η\n+ ∥ ∥\n∥ TŴ ∗k+1 − Ŵ ∗k\n∥ ∥ ∥\np,η\n= [ Introduce density function tx (xk+1 | xk, a) for kernel Tx ]\n=\n∥ ∥ ∥ ∥\nmax a∈A\n∫\nX\n∣ ∣ ∣ 1A\\K(xk+1) ( T Nt−k−1Ŵ ∗Nt − Ŵ ∗k+1 ) (xk+1) ∣ ∣ ∣ tx(xk+1|xk, a)dxk+1\n∥ ∥ ∥ ∥\np,η\n∥ ∥ ∥ TŴ ∗k+1 − Ŵ ∗k ∥ ∥ ∥\np,η .\nLet us now show that the first term is bounded by B 1 p\n∥ ∥ ∥ T Nt−k−1Ŵ ∗Nt − Ŵ ∗k+1 ∥ ∥ ∥\np,η :\n∥ ∥ ∥ ∥\nmax a∈A\n∫\nX\n∣ ∣ ∣ 1A\\K(xk+1) ( T Nt−k−1Ŵ ∗Nt − Ŵ ∗k+1 ) ∣ ∣ ∣ tx(xk+1|xk, a)dxk+1\n∥ ∥ ∥ ∥\np,η\n= [ monotonicity of Lp-norms with respect to a probability measure ] ≤ ∥ ∥ ∥\n∥ ∥ max a∈A\n( ∫\nX\n∣ ∣ ∣ 1A\\K(xk+1) ( T Nt−k−1Ŵ ∗Nt − Ŵ ∗k+1 )∣ ∣ ∣ p tx(xk+1|xk, a)dxk+1\n) 1 p\n∥ ∥ ∥ ∥ ∥\np,η\n= [ Express the η-weighted p-norm over A \\K ]\n=\n(\n∫\nA\\K\n∣ ∣ ∣ ∣ maxa∈A ∣ ∣ ∣ ∫ A\\K ∣ ∣ ∣ T Nt−k−1Ŵ ∗Nt − Ŵ ∗k+1 ∣ ∣ ∣ p tx(xk+1|xk, a)dxk+1 ∣ ∣ ∣ 1 p ∣ ∣ ∣ ∣\np\nη(xk)dxk\n) 1 p\n=\n(\n∫\nA\\K maxa∈A\n∣ ∣ ∣ ∣ ∣ ∣ ∣ ∫ A\\K ∣ ∣ ∣ T Nt−k−1Ŵ ∗Nt − Ŵ ∗k+1 ∣ ∣ ∣ p tx(xk+1|xk, a)dxk+1 ∣ ∣ ∣ 1 p ∣ ∣ ∣ ∣\np\nη(xk)dxk\n) 1 p\n= ( ∫\nA\\K maxa∈A ∫ A\\K\n∣ ∣ ∣ T Nt−k−1Ŵ ∗Nt − Ŵ ∗k+1 ∣ ∣ ∣ p tx(xk+1|xk, a)dxk+1η(xk)dxk\n) 1 p\n≤ ( ∫\nA\\K\n∫\nA\\K maxa∈A\n( ∣\n∣ ∣ T Nt−k−1Ŵ ∗Nt − Ŵ ∗k+1\n∣ ∣ ∣ p tx(xk+1|xk, a) ) dxk+1η(xk)dxk\n) 1 p\n= [ Introduce dummy term η(xk+1) η(xk+1) , which is defined over xk+1 ∈ A \\K ]\n= ( ∫\nA\\K\n∫\nA\\K maxa∈A\n( ∣\n∣ ∣ T Nt−k−1Ŵ ∗Nt − Ŵ ∗k+1\n∣ ∣ ∣ p tx(xk+1|xk, a) )\nη(xk) η(xk+1) dxkη(xk+1)dxk+1\n) 1 p\n= [ Recall that ∣ ∣\n∣ T Nt−k−1Ŵ ∗Nt − Ŵ ∗k+1\n∣ ∣ ∣ p is only a function of xk+1 ]\n= ( ∫\nA\\K\n∣ ∣ ∣ T Nt−k−1Ŵ ∗Nt − Ŵ ∗k+1 ∣ ∣ ∣ p ∫ A\\K ( maxa∈A tx(xk+1|xk,a)η(xk)\nη(xk+1)\n)\ndxkη(xk+1)dxk+1\n) 1 p .\nIntroduce now the upper bound on ∫\nA\\K\n(\nmaxa∈A tx(xk+1|xk,a)η(xk)\nη(xk+1)\n)\ndxk over the domain\nA \\K as B = supxk+1∈A\\K ∫ A\\K maxa∈A tx(xk+1|xk,a)η(xk) η(xk+1) dxk, obtaining\n≤ ( ∫\nA\\K\n∣ ∣ ∣ T Nt−k−1Ŵ ∗Nt − Ŵ ∗k+1 ∣ ∣ ∣ p Bη(xk+1)dxk+1 ) 1 p = B 1 p ‖TNt−k−1Ŵ ∗Nt − Ŵ ∗k+1‖p,η.\nWe have finally shown that ∥ ∥\n∥ T Nt−kŴ ∗Nt − Ŵ ∗k\n∥ ∥ ∥\np,η ≤\n∥ ∥ ∥ TŴ ∗k+1 − Ŵ ∗k ∥ ∥ ∥\np,η +B\n1 p\n∥ ∥ ∥ T Nt−k−1Ŵ ∗Nt − Ŵ ∗k+1 ∥ ∥ ∥\np,η ."
    }, {
      "heading" : "Appendix E. Proof of Theorem 10",
      "text" : "Proof If we estimate the quantity r∗x0(K,A) = ( T NtW ∗Nt ) (x0) = ( T NtŴ ∗Nt )\n(x0) by (\nT̂Ŵ ∗1\n)\n(x0), then we have that r̂ ∗ x0(K,A) = 1K(x0)+1A\\K(x0)\n(\nT̂Ŵ ∗1\n)\n(x0). The absolute\ndeviation of the approximated r̂∗x0(K,A) from the exact r ∗ x0(K,A) is given as\n∣ ∣r̂∗x0(K,A) − r∗x0(K,A) ∣\n∣ = ∣ ∣\n∣\n(\nT NtŴ ∗Nt\n) (x0)− ( T̂Ŵ ∗1 ) (x0) ∣ ∣ ∣ .\nThe objective is to present this error as a function of the errors introduced by the\napproximate mappings ∣ ∣\n∣\n(\nT NtŴ ∗Nt\n) (x0)− ( T̂Ŵ ∗1 ) (x0) ∣ ∣ ∣ , as well as of the quantities ‖Ŵ ∗1 −\nTŴ ∗2 ‖p,η, ‖Ŵ ∗2 − TŴ ∗3 ‖p,η, . . . , ‖Ŵ ∗Nt−1 − TŴ ∗Nt‖p,η. To this end, we first express a bound on ∣ ∣\n∣\n(\nT NtŴ ∗Nt\n) (x0)− ( T̂Ŵ ∗1 ) (x0) ∣ ∣ ∣ as a function\nof | ( T̂ (\nTŴ ∗1\n) (x0)− Ŵ ∗1 ) (x0)| and of ∥ ∥ ∥ T Nt−1Ŵ ∗Nt − Ŵ ∗1 ∥ ∥ ∥\np,η . Then Lemma 9 is used to\nexpress ‖TNt−1Ŵ ∗Nt − Ŵ ∗1 ‖p,η as a function of the errors introduced by the approximate mappings. Similar to the first chain of inequality in the proof of Lemma 9 applied at step k = 0 and point x0, we obtain that\n∣ ∣ ∣ (\nT NtŴ ∗Nt\n) (x0)− ( T̂Ŵ ∗1 ) (x0) ∣ ∣ ∣\n≤ max a∈A\n∫\nA\\K\n∣ ∣ ∣ T Nt−1Ŵ ∗Nt(x1)− Ŵ ∗1 (x1) ∣ ∣ ∣ tx (x1 | x0, a) dx1 + ∣ ∣ ∣ ( TŴ ∗1 ) (x0)− ( T̂Ŵ ∗1 ) (x0) ∣ ∣ ∣ .\nLet us now introduce a measure for the maximum concentration of the density function tx (x1 | x0, a) over x1 ∈ A \\K, for any a ∈ A, defined relative to the density of the distribution η in (16), as B0 = supx1∈A\\K maxa∈A tx(x1|x0,a) η(x1)\n. Since B0η(x1) ≥ tx (x1 | x0, a), it follows that\nmax a∈A\n∫\nA\\K\n∣ ∣ ∣ T Nt−1Ŵ ∗Nt(x1)− Ŵ ∗1 (x1) ∣ ∣ ∣ tx (x1 | x0, a) dx1 ≤ B0\n∫\nA\\K\n∣ ∣ ∣ T Nt−1Ŵ ∗Nt(x1)− Ŵ ∗1 (x1) ∣ ∣ ∣ η(x1)dx1.\nThe last expression corresponds to a 1-norm with respect to a probability measure η over A \\K. Exploiting the monotonicity of the p-norm with respect to a probability measure, a more general expression for the approximation error is obtained as ∣ ∣ ∣ (\nT NtŴ ∗Nt\n) (x0)− T̂Ŵ ∗1 (x0) ∣ ∣ ∣ ≤ ∣ ∣ ∣ ( T̂Ŵ ∗1 ) (x0)− ( TŴ ∗1 ) (x0) ∣ ∣ ∣ +B0 ∥ ∥ ∥ ( T Nt−1Ŵ ∗Nt ) − Ŵ ∗1 ∥ ∥ ∥\np,η .\nThe second term can be expressed as a function of the weighted p-norm of the approximations by applying Lemma 9. This leads to the expression for an upper bound on the approximation error as\n∣ ∣r̂∗x0(K,A) − r∗x0(K,A) ∣\n∣ ≤ ∣ ∣\n∣\n(\nT̂Ŵ ∗1\n) (x0)− ( TŴ ∗1 ) (x0) ∣ ∣ ∣ +B0 ∑Nt−1 k=1 B k−1 p ∥ ∥ ∥ Ŵ ∗k − TŴ ∗k+1 ∥ ∥ ∥\np,η .\nFrom the above expression, a sufficient condition the accuracy in (3) to hold is\nP { ∣ ∣\n∣\n(\nT̂Ŵ ∗1\n) (x0)− ( TŴ ∗1 ) (x0) ∣ ∣ ∣ +B0\nNt−1 ∑\nk=1\nB k−1 p\n∥ ∥ ∥ Ŵ ∗k − TŴ ∗k+1 ∥ ∥ ∥\np,η > ∆\n}\n≤ δ∆."
    }, {
      "heading" : "Appendix F. Sample Complexities",
      "text" : "Given ǫ0,1,2 and α, select δ0,1,2 > 0 such that 1− α = δ0 + (Nt − 1)δ1 + (Nt − 1)δ2, and let us pick values for N ,M , M0 such that\nδ0 ≤ 2|A|e−2M0(ǫ0) 2 , δ1 ≤ 2|A|Ne−2M(ǫ1) 2 , δ2 ≤ 4e(d + 1)\n(32e\nǫp2\n)d e−\nNǫ 2p 2\n128 .\nNote that the first two inequalities are approximated with first order approximation for which we know that 1− (1−2e−2M0(ǫ0)2)|A| ≤ 2|A|e−2M0(ǫ0)2 and 1− (1−2e−2M(ǫ1)2)|A|N ≤ 2|A|Ne−2M(ǫ1)2 . The obtained integer values for N ,M , M0 are given as \n    \n    \nN = ⌈ 128 (ln(4e(d + 1)) + d ln(32e)) (\n1 ǫ2\n)2p + 128dp (\n1 ǫ2\n)2p ln (\n1 ǫ2\n) + 128 (\n1 ǫ2\n)2p ln (\n1 δ2\n)⌉\n,\nM = ⌈\n1 2\n(\n1 ǫ1\n)2 (\nln(2|A|) + ln( 1δ1 ) + ln(N) ) ⌉ ,\nM0 = ⌈ 1 2 ( 1 ǫ0\n)2 (\nln(2|A|) + ln( 1δ0 ) )⌉ ,\n.\nThe use of the obtained M,M0, N in (17) leads to a confidence of at least α."
    }, {
      "heading" : "Appendix G. Proof of Theorem 12",
      "text" : "Proof The proof of Theorem 12 is built observing that (a.) the single step error ‖Ŵ ∗k − TŴ ∗k+1‖1,η is bounded by the sum of the expectations of (19) and (21); that (b.) the propagation of the single step errors gives a bound on the overall approximation error, see Theorem 10 – hence the expected value of the estimates, propagated over the time horizon, also gives a bound on the approximation error; and that (c.) the one-sided application of the Hoeffding’s inequality provides a probabilistic upper bound on the deviation of the estimate from its mean, and therefore also bounds the approximation error probabilistically. Part (a.)\n‖Ŵ ∗k − TŴ ∗k+1‖1,η = Ex [ ∣ ∣ ∣ Ŵ ∗k (x)− TŴ ∗k+1(x) ∣ ∣ ∣ ] with Ex [f(x)] the mean of f(x) for x ∼ η.\nDefine a set of i.i.d. random variables ~y1 = [y a,1 1 , y a,2 1 , . . . , y a,M̃ 1 ] drawn from the distribution ya,j1 ∼ Tx (· | x, a). Introduce E~y1 [ maxa∈A T̂ a 1Ŵ ∗ k+1(x)|x ]\nas an auxiliary variable with T̂a1 the estimated operator as defined in (20) and computed over the ~y1.\n= Ex [ ∣ ∣ ∣ ∣Ŵ ∗ k (x)− E~y1 [\nmax a∈A\nT̂ a 1Ŵ ∗ k+1(x)|x\n]\n+ E~y1\n[\nmax a∈A\nT̂ a 1Ŵ ∗ k+1(x)|x\n]\n− TŴ ∗k+1(x) ∣ ∣ ∣ ∣ ]\n≤ Ex [∣ ∣ ∣ ∣ Ŵ ∗k (x)− E~y1 [\nmax a∈A\nT̂ a 1Ŵ ∗ k+1(x)|x ]∣ ∣ ∣ ∣ ] +Ex [∣ ∣ ∣ ∣ E~y1 [\nmax a∈A\nT̂ a 1Ŵ ∗ k+1(x)|x\n]\n− TŴ ∗k+1(x) ∣ ∣ ∣ ∣ ]\n≤ Ex, ~y1 [∣ ∣ ∣ ∣Ŵ ∗ k (x)−max\na∈A T̂ a 1Ŵ ∗ k+1(x)\n∣ ∣ ∣ ∣ ]\n︸ ︷︷ ︸\n[ Single step error ]\n+Ex [∣ ∣ ∣ ∣E~y1 [\nmax a∈A\nT̂ a 1Ŵ ∗ k+1(x)|x\n]\n− TŴ ∗k+1(x) ∣ ∣ ∣ ∣ ]\n︸ ︷︷ ︸\n[ Bias term ]\n.\nObserve that the single step error, Ex, ~y1\n[\n∣ ∣Ŵ ∗k (x)−maxa∈A T̂a1Ŵ ∗k+1(x) ∣ ∣\n]\nis equal to ‖Ŵ ∗k − T̂Ŵ ∗k+1‖1,η and E‖Ŵ ∗k − T̂Ŵ ∗k+1‖1,η̃. The bias term gives the bias introduced by using an estimate of the operator and it can be rewritten as the expected value of (21). Note that maxa∈AEy [Vk+1(y)|x, a] is a function of x, a and |E~y1 [f(~y)] | ≤ E~y1 [|f(~y)|], thus it follows that\n[ Bias term ] ≤ ExE~y1 [ ∣ ∣ ∣ ∣ max a∈A T̂ a 1Ŵ ∗ k+1(x)− TŴ ∗ k+1(x) ∣ ∣ ∣ ∣ ∣ ∣ ∣ ∣ x ] ≤ ExE~y1 [ max a∈A ∣ ∣ ∣T̂ a 1Ŵ ∗ k+1(x) −E~y2 [ T̂ a 2Ŵ ∗ k+1(x)|x ]∣ ∣ ∣ ∣ ∣ ∣ ∣ x ] .\nThe second inequality follows from introducing a secondary set of random variables ~y2 = [ya,12 , y a,2 2 , . . . , y a,1M̃ 2 ] for which the elements are i.i.d. as y a,1 2 ∼ Tx (· | x, a) and which are independent of ~y1. Substituting TŴ ∗ k+1(x) with maxa∈AE~y2 [ T̂ a 2Ŵ ∗ k+1(x)|x, a ] we have\n[ Bias term ] ≤ ExE~y1\n[\nmax a∈A E~y2\n[∣ ∣ ∣T̂\na 1Ŵ ∗ k+1(x)− T̂ a 2Ŵ ∗ k+1(x) ∣ ∣ ∣ |x, a, ~y1 ] |x\n]\n= Ex,~y1,~y2\n[\nmax a∈A\n∣ ∣ ∣T̂ a 1Ŵ ∗ k+1(x)− T̂ a 2Ŵ ∗ k+1(x) ∣ ∣ ∣\n]\n.\nThe last equality is equal to the expected value of the estimated bias E ∥ ∥maxa∈A ∣ ∣T̂ a 1Ŵ ∗ k+1−\nT̂ a 2Ŵ ∗ k+1\n∣ ∣ ∥ ∥\n1,η̃ . This proves statement (a.).\nPart (b.) & (c.) Based on Theorem 10 r̂∗x0(K,A) has accuracy ∆ with probability δ∆ if\nP\n{\n|Ŵ ∗0 (x0)− TŴ ∗ 1 (x0)|+ B0\nNt−1∑\nk=1\nBk−1E [∣ ∣ ∣ ∣ Ŵ ∗k (x) −max\na∈A T̂ a 1Ŵ ∗ k+1(x)\n∣ ∣ ∣ ∣ +max\na∈A\n∣ ∣ ∣T̂ a 1Ŵ ∗ k+1(x)− T̂ a 2Ŵ ∗ k+1(x) ∣ ∣ ∣\n]\n≥ ∆ }\n< δ∆.\nWhich holds under a union bounding argument if\nP\n{\n|Ŵ ∗0 (x0)− TŴ ∗ 1 (x0)| ≥ ǫ0\n}\n< δ0 (29)\nP\n \n\nB0 ∑Nt−1\nk=1 B k−1E [∣ ∣ ∣Ŵ ∗k (x)−maxa∈A T̂ a 1Ŵ ∗ k+1(x) ∣ ∣ ∣ +maxa∈A ∣ ∣ ∣T̂ a 1Ŵ ∗ k+1(x)− T̂ a 2Ŵ ∗ k+1(x) ∣ ∣ ∣ ] ≥ B0ǫ\n+B0 ∑Nt−1\nk=1 B k−1 (∥ ∥ ∥Ŵ ∗k − T̂Ŵ ∗ k+1 ∥ ∥ ∥ 1,η̃ + ∥ ∥ ∥maxa∈A ∣ ∣ ∣T̂ a 1Ŵ ∗ k+1 − T̂ a 2Ŵ ∗ k+1 ∣ ∣ ∣ ∥ ∥ ∥ 1,η̃ )\n \n\n< e −2 Ñǫ\n2\nL2\n(30)\nand ∆ and δ∆ are given as (22a) and (22b). The probabilistic bound (29) follows from Lemma 8 for the estimation error of an empirical norm with accuracy ǫ0, δ0 obtained for p = 1, M = M0 and N = 1 as long as 0 < 2e\n−2M0ǫ20 < 1. The probabilistic bound (30) follows from a one-sided Hoeffding’s inequality (Hoeffding, 1963) with random variable\n∑Nt−1 k=1 B\nk−1 (∣ ∣\n∣ Ŵ ∗k (x)−maxa∈A T̂a1Ŵ ∗k+1(x)\n∣ ∣ ∣ +maxa∈A ∣ ∣ ∣ T̂ a 1Ŵ ∗ k+1(x)− T̂a2Ŵ ∗k+1(x) ∣ ∣ ∣ ) ,\nobtained from the combination of random variable x ∼ η and conditional random variables ~y1 and ~y2 and taking values in the range [0, 2 ∑Nt−1 k=1 B\nk−1]. Note that its estimated of interest over Ñ samples can be rewritten in the form of (22a),\n∑Nt−1 k=1 B\nk−1 ( ∥\n∥Ŵ ∗k − T̂Ŵ ∗k+1 ∥ ∥ 1,η̃ + ∥ ∥maxa∈A\n∣ ∣ ∣ T̂ a 1Ŵ ∗ k+1 − T̂a2Ŵ ∗k+1 ∣ ∣ ∣ ∥ ∥\n1,η̃\n)\n.\nThis concludes the proof of Theorem 12."
    }, {
      "heading" : "Appendix H. Scaling factor for case study",
      "text" : "Compute B as in (14) using the given density distribution of the transitions (25), as\nB = sup y∈A\\K\n∫\nA\\K\n1 √\n|Σ|(2π)2 max a∈A\n( exp ( − 12 (y − µ) T Σ−1 (y − µ) ) η(x)\nη(y)\n)\ndx\n= [ µ is a function of a and x, and η(·) is constant over A \\K ]\n= sup y∈A\\K\n∫\nA\\K\n1 √\n|Σ|(2π)2 max a∈A exp\n(\n−1 2 (y − µ)T Σ−1 (y − µ)\n)\ndx\n= [Suppose A is invertible, and define µ̄(y, a) = A−1y −A−1Ba−A−1C, Σ̄ = A−1ΣA−T ]\n= sup y∈A\\K\n1\n|A|\n∫\nA\\K\n1 √\n|Σ̄|(2π)2 max a∈A exp\n(\n−1 2 (x− µ̄(y, a))T Σ̄−1 (x− µ̄(y, a))\n)\ndx\n≤ sup y∈A\\K\n1\n|A|\n∫\nA\\K\n1 √ |Σ̄|(2π)2 ∑\na∈A\n(\nexp\n(\n−1 2 (x− µ̄(y, a))T Σ̄−1 (x− µ̄(y, a))\n))\ndx\n= sup y∈A\\K\n1\n|A|\n(\n∑\na∈A\n∫\nA\\K\n1 √\n|Σ̄|(2π)2 exp\n(\n−1 2 (x− µ̄(y, a))T Σ̄−1 (x− µ̄(y, a))\n)\ndx\n)\n.\nThe integral is rewritten as one over a scaled 2-dimension multivariate Gaussian density distribution with mean µ̄ and covariance Σ̄. With this result, it can be deduced that B is smaller than 1|A| |A| as\nB ≤ sup y∈A\\K\n1 |A| ( ∑\na∈A\n∫\nX\n1√ |Σ̄|(2π)2\nexp (\n−12 (x− µ̄(y, a)) T Σ̄−1 (x− µ̄(y, a))\n) dx )\n(31)\n≤ sup y∈A\\K\n1\n|A| ∑ a∈A 1 = 1|A| |A|."
    } ],
    "references" : [ {
      "title" : "Probabilistic reachability and safety for controlled discrete time stochastic hybrid systems",
      "author" : [ "A. Abate", "M. Prandini", "J. Lygeros", "S. Sastry" ],
      "venue" : null,
      "citeRegEx" : "Abate et al\\.,? \\Q2008\\E",
      "shortCiteRegEx" : "Abate et al\\.",
      "year" : 2008
    }, {
      "title" : "Approximate model checking of stochastic hybrid systems",
      "author" : [ "A. Abate", "J.P. Katoen", "J. Lygeros", "M. Prandini" ],
      "venue" : "European Journal of Control,",
      "citeRegEx" : "Abate et al\\.,? \\Q2010\\E",
      "shortCiteRegEx" : "Abate et al\\.",
      "year" : 2010
    }, {
      "title" : "Quantitative automata model checking of autonomous stochastic hybrid systems",
      "author" : [ "A. Abate", "J.-P. Katoen", "A. Mereacre" ],
      "venue" : "In Proceedings of the 14th ACM international conference on Hybrid Systems: computation and control,",
      "citeRegEx" : "Abate et al\\.,? \\Q2011\\E",
      "shortCiteRegEx" : "Abate et al\\.",
      "year" : 2011
    }, {
      "title" : "Uniform Glivenko-Cantelli theorems and concentration of measure in the mathematical modelling of learning",
      "author" : [ "M. Anthony" ],
      "venue" : "Research report, Department of Mathematics London School of Economics,",
      "citeRegEx" : "Anthony.,? \\Q2002\\E",
      "shortCiteRegEx" : "Anthony.",
      "year" : 2002
    }, {
      "title" : "Neural Network Learning: Theoretical Foundations",
      "author" : [ "M. Anthony", "P.L. Bartlett" ],
      "venue" : "cambridge university press,",
      "citeRegEx" : "Anthony and Bartlett.,? \\Q1999\\E",
      "shortCiteRegEx" : "Anthony and Bartlett.",
      "year" : 1999
    }, {
      "title" : "Principles of Model Checking",
      "author" : [ "C. Baier", "J.-P. Katoen" ],
      "venue" : null,
      "citeRegEx" : "Baier and Katoen.,? \\Q2008\\E",
      "shortCiteRegEx" : "Baier and Katoen.",
      "year" : 2008
    }, {
      "title" : "Local Rademacher Complexities",
      "author" : [ "P.L. Bartlett", "O. Bousquet", "S. Mendelson" ],
      "venue" : "Annals of Statistics,",
      "citeRegEx" : "Bartlett et al\\.,? \\Q2005\\E",
      "shortCiteRegEx" : "Bartlett et al\\.",
      "year" : 2005
    }, {
      "title" : "Stochastic Optimal Control: The discrete time case",
      "author" : [ "D.P. Bertsekas", "S.E. Shreve" ],
      "venue" : "Athena Scientific,",
      "citeRegEx" : "Bertsekas and Shreve.,? \\Q1996\\E",
      "shortCiteRegEx" : "Bertsekas and Shreve.",
      "year" : 1996
    }, {
      "title" : "Stochastic Hybrid Systems: Theory and Safety Critical Applications. Number 337 in Lecture Notes in Control and Information Sciences",
      "author" : [ "H.A.P. Blom", "J. Lygeros" ],
      "venue" : null,
      "citeRegEx" : "Blom and Lygeros.,? \\Q2006\\E",
      "shortCiteRegEx" : "Blom and Lygeros.",
      "year" : 2006
    }, {
      "title" : "Reinforcement Learning and Dynamic Programming Using Function Approximators. Automation and Control Engineering",
      "author" : [ "L. Busoniu", "R. Babuska", "B.D. Schutter", "D. Ernst" ],
      "venue" : null,
      "citeRegEx" : "Busoniu et al\\.,? \\Q2010\\E",
      "shortCiteRegEx" : "Busoniu et al\\.",
      "year" : 2010
    }, {
      "title" : "Stochastic Hybrid Systems. Number 24 in Control Engineering",
      "author" : [ "C.G. Cassandras", "J. Lygeros" ],
      "venue" : "CRC Press, Boca Raton,",
      "citeRegEx" : "Cassandras and Lygeros.,? \\Q2006\\E",
      "shortCiteRegEx" : "Cassandras and Lygeros.",
      "year" : 2006
    }, {
      "title" : "Adaptive and sequential gridding procedures for the abstraction and verification of stochastic processes",
      "author" : [ "S. Esmaeil Zadeh Soudjani", "A. Abate" ],
      "venue" : "SIAM Journal on Applied Dynamical Systems,",
      "citeRegEx" : "Soudjani and Abate.,? \\Q2013\\E",
      "shortCiteRegEx" : "Soudjani and Abate.",
      "year" : 2013
    }, {
      "title" : "Error Propagation for Approximate Policy and Value Iteration",
      "author" : [ "A.M. Farahmand", "R. Munos", "C. Szepesvari" ],
      "venue" : "In Neural Information Processing Systems,",
      "citeRegEx" : "Farahmand et al\\.,? \\Q2010\\E",
      "shortCiteRegEx" : "Farahmand et al\\.",
      "year" : 2010
    }, {
      "title" : "Benchmarks for hybrid systems verification",
      "author" : [ "A. Fehnker", "F. Ivančić" ],
      "venue" : "In Hybrid Systems: Computation and Control (HSCC",
      "citeRegEx" : "Fehnker and Ivančić.,? \\Q2004\\E",
      "shortCiteRegEx" : "Fehnker and Ivančić.",
      "year" : 2004
    }, {
      "title" : "Layered neural networks with gaussian hidden units as universal approximations",
      "author" : [ "E.J. Hartman", "J.D. Keeler", "J.M. Kowalski" ],
      "venue" : "Neural computation,",
      "citeRegEx" : "Hartman et al\\.,? \\Q1990\\E",
      "shortCiteRegEx" : "Hartman et al\\.",
      "year" : 1990
    }, {
      "title" : "Decision theoretic generalizations of the PAC model for neural net and other learning applications",
      "author" : [ "D. Haussler" ],
      "venue" : "Information and Computation/information and Control,",
      "citeRegEx" : "Haussler.,? \\Q1992\\E",
      "shortCiteRegEx" : "Haussler.",
      "year" : 1992
    }, {
      "title" : "Probability inequalities for sums of bounded random variables",
      "author" : [ "W. Hoeffding" ],
      "venue" : "Journal of the American Statistical Association,",
      "citeRegEx" : "Hoeffding.,? \\Q1963\\E",
      "shortCiteRegEx" : "Hoeffding.",
      "year" : 1963
    }, {
      "title" : "Polynomial bounds for VC dimension of sigmoidal and general Pfaffian neural networks",
      "author" : [ "M. Karpinski", "A. Macintyre" ],
      "venue" : "Journal of Computer and System Sciences,",
      "citeRegEx" : "Karpinski and Macintyre.,? \\Q1997\\E",
      "shortCiteRegEx" : "Karpinski and Macintyre.",
      "year" : 1997
    }, {
      "title" : "Efficient distribution-free learning of probabilistic concepts",
      "author" : [ "M.J. Kearns", "R.E. Schapire" ],
      "venue" : "Journal of Computer and System Sciences,",
      "citeRegEx" : "Kearns and Schapire.,? \\Q1994\\E",
      "shortCiteRegEx" : "Kearns and Schapire.",
      "year" : 1994
    }, {
      "title" : "Computational methods for reachability analysis of stochastic hybrid systems",
      "author" : [ "K. Koutsoukos", "D. Riley" ],
      "venue" : "Hybrid Systems: Computation and Control,",
      "citeRegEx" : "Koutsoukos and Riley.,? \\Q2006\\E",
      "shortCiteRegEx" : "Koutsoukos and Riley.",
      "year" : 2006
    }, {
      "title" : "Numerical Methods for Stochastic Control Problems in Continuous Time",
      "author" : [ "H.J. Kushner", "P.G. Dupuis" ],
      "venue" : null,
      "citeRegEx" : "Kushner and Dupuis.,? \\Q2001\\E",
      "shortCiteRegEx" : "Kushner and Dupuis.",
      "year" : 2001
    }, {
      "title" : "reach-avoid decision problem",
      "author" : [ "I. Tkachev", "A. Abate" ],
      "venue" : null,
      "citeRegEx" : "Tkachev and Abate.,? \\Q1951\\E",
      "shortCiteRegEx" : "Tkachev and Abate.",
      "year" : 1951
    }, {
      "title" : "Proof of Lemma 6: Bound on Estimation Error We employ results on the concentration of random variables (Anthony, 2002), which in general raise conditions on a random variable ensuring its realizations to be concentrated around its expectation, in the sense that the probability of a deviation from the expectation",
      "author" : [ "Haesaert", "Babuska", "Abate Appendix A" ],
      "venue" : null,
      "citeRegEx" : "Haesaert et al\\.,? \\Q2002\\E",
      "shortCiteRegEx" : "Haesaert et al\\.",
      "year" : 2002
    }, {
      "title" : "Remark 16 (Computing the pseudo-dimension) When the function class W is a vector space of real-valued functions, the pseudo dimension is equal to the dimensionality of the function class (Anthony and Bartlett, 1999, Theorem 11.4)",
      "author" : [ ],
      "venue" : "(Anthony and Bartlett,",
      "citeRegEx" : "d.,? \\Q1999\\E",
      "shortCiteRegEx" : "d.",
      "year" : 1999
    }, {
      "title" : "dp,η(TW,W) + 2ǫ1 + 2ǫ2. By the union bound argument (Anthony, 2002), the probability of the union of events can be bounded by the sum of the probabilities of the single events. Using this argument it is possible to define a lower bound on the probability associated with the simultaneous 28",
      "author" : [ "− TW‖p" ],
      "venue" : null,
      "citeRegEx" : "TW.p and ≤,? \\Q2002\\E",
      "shortCiteRegEx" : "TW.p and ≤",
      "year" : 2002
    } ],
    "referenceMentions" : [ {
      "referenceID" : 7,
      "context" : "Haesaert, Babuska and Abate control input and investigate control synthesis, which relate to a broad literature in Control Theory (Bertsekas and Shreve, 1996); furthermore, we are interested in quantifying the probability associated to a dynamical property, known as reach-avoid, which corresponds to a widely used model specification in the field of Formal Verification (Baier and Katoen, 2008); and finally we employ a sampling-based algorithm to approximately compute the likelihood associated to the above specification.",
      "startOffset" : 130,
      "endOffset" : 158
    }, {
      "referenceID" : 5,
      "context" : "Haesaert, Babuska and Abate control input and investigate control synthesis, which relate to a broad literature in Control Theory (Bertsekas and Shreve, 1996); furthermore, we are interested in quantifying the probability associated to a dynamical property, known as reach-avoid, which corresponds to a widely used model specification in the field of Formal Verification (Baier and Katoen, 2008); and finally we employ a sampling-based algorithm to approximately compute the likelihood associated to the above specification.",
      "startOffset" : 371,
      "endOffset" : 395
    }, {
      "referenceID" : 0,
      "context" : "We are further interested in a class of such models known as stochastic hybrid systems (SHS) (Abate et al., 2008), which are endowed with a “hybrid” (that is, both continuous and discrete) state space, which are relevant for a number of applications in Engineering and the Life Sciences (Blom and Lygeros, 2006; Cassandras and J.",
      "startOffset" : 93,
      "endOffset" : 113
    }, {
      "referenceID" : 8,
      "context" : ", 2008), which are endowed with a “hybrid” (that is, both continuous and discrete) state space, which are relevant for a number of applications in Engineering and the Life Sciences (Blom and Lygeros, 2006; Cassandras and J. Lygeros, 2006).",
      "startOffset" : 181,
      "endOffset" : 238
    }, {
      "referenceID" : 5,
      "context" : "Instead, we focus on the reachavoid specification, a property that is well known and central within the Formal Verification field (Baier and Katoen, 2008).",
      "startOffset" : 130,
      "endOffset" : 154
    }, {
      "referenceID" : 5,
      "context" : "The reach-avoid property is a generalization of widely studied properties, such as reachability and invariance, and represents a known specification (denoted as “bounded until”) that lies at the core of a number of modal logics used in the field of formal verification, such as Linear Temporal Logic and Computational Time Logic (Baier and Katoen, 2008).",
      "startOffset" : 329,
      "endOffset" : 353
    }, {
      "referenceID" : 0,
      "context" : "In the context of probabilistic models evolving over continuous domains and in discrete time (which is the framework considered in this work), the probabilistic reachability and reach-avoid specifications have been investigated in (Abate et al., 2008; Summers and Lygeros, 2010).",
      "startOffset" : 231,
      "endOffset" : 278
    }, {
      "referenceID" : 2,
      "context" : "These results have recently led to the study of other properties, either richer (Abate et al., 2011) or defined over unbounded time horizons (Tkachev and Abate, 2014).",
      "startOffset" : 80,
      "endOffset" : 100
    }, {
      "referenceID" : 1,
      "context" : "Computational approaches to probabilistic reachability have been studied in (Abate et al., 2010; Esmaeil Zadeh Soudjani and Abate, 2013): the strength of these results is that the proposed numerical schemes have explicitly quantified error bounds.",
      "startOffset" : 76,
      "endOffset" : 136
    }, {
      "referenceID" : 19,
      "context" : "This is unlike other, known approximation schemes in the literature (Koutsoukos and Riley, 2006; Kushner and Dupuis, 2001; Prandini and Hu, 2006), which provide results with properties that are only known asymptotically.",
      "startOffset" : 68,
      "endOffset" : 145
    }, {
      "referenceID" : 20,
      "context" : "This is unlike other, known approximation schemes in the literature (Koutsoukos and Riley, 2006; Kushner and Dupuis, 2001; Prandini and Hu, 2006), which provide results with properties that are only known asymptotically.",
      "startOffset" : 68,
      "endOffset" : 145
    }, {
      "referenceID" : 7,
      "context" : "In order to do so, the FVI scheme is tailored to the characterization of the reach-avoid problem, which leads to Dynamic Programming (DP) recursions based on a sum-multiplicative form that is non-standard since it departs from the classical additive (possibly discounted) cost functions (Bertsekas and Shreve, 1996).",
      "startOffset" : 287,
      "endOffset" : 315
    }, {
      "referenceID" : 1,
      "context" : "As a comparison to the alternative techniques in the literature (Abate et al., 2010; Esmaeil Zadeh Soudjani and Abate, 2013), we show the related techniques provide bounds that are valid deterministically, whereas the proposed result yields tighter results in general that are valid with a certain (tunable) confidence.",
      "startOffset" : 64,
      "endOffset" : 124
    }, {
      "referenceID" : 8,
      "context" : "The outcomes lead to an approach providing controller synthesis with a certified performance, which is relevant for safety-critical applications (Blom and Lygeros, 2006).",
      "startOffset" : 145,
      "endOffset" : 169
    }, {
      "referenceID" : 0,
      "context" : "Computational approaches to probabilistic reachability have been studied in (Abate et al., 2010; Esmaeil Zadeh Soudjani and Abate, 2013): the strength of these results is that the proposed numerical schemes have explicitly quantified error bounds. This is unlike other, known approximation schemes in the literature (Koutsoukos and Riley, 2006; Kushner and Dupuis, 2001; Prandini and Hu, 2006), which provide results with properties that are only known asymptotically. This article provides a new approximate computational scheme for the reach-avoid specification based on the Fitted Value Iteration algorithm, which hinges on random sample extractions. This work originally derives formal probabilistic bounds on the error made by the approximation algorithm. In order to do so, the FVI scheme is tailored to the characterization of the reach-avoid problem, which leads to Dynamic Programming (DP) recursions based on a sum-multiplicative form that is non-standard since it departs from the classical additive (possibly discounted) cost functions (Bertsekas and Shreve, 1996). Starting from the regression bounds in Munos and Szepesvari (2008), this work includes new results on the error for the FVI approximation and a-priori performance guarantees.",
      "startOffset" : 77,
      "endOffset" : 1145
    }, {
      "referenceID" : 5,
      "context" : "1 Probabilistic Reach-Avoid Problem: Definition Let us define the probabilistic reach-avoid problem, also known as constrained reachability (Baier and Katoen, 2008), and provide its characterization.",
      "startOffset" : 140,
      "endOffset" : 164
    }, {
      "referenceID" : 7,
      "context" : "Notice that, while the probabilistic reach-avoid problem has been formulated above via DP recursions, it hinges on a sum-multiplicative characterization which is non-standard: much of the analytical and computational results in DP are formulated for additive (possibly discounted) cost functions (Bertsekas and Shreve, 1996).",
      "startOffset" : 296,
      "endOffset" : 324
    }, {
      "referenceID" : 0,
      "context" : "Proof See again (Summers and Lygeros, 2010, Theorem 6) and (Abate et al., 2008).",
      "startOffset" : 59,
      "endOffset" : 79
    }, {
      "referenceID" : 1,
      "context" : "This approach is taken in (Abate et al., 2010; Esmaeil Zadeh Soudjani and Abate, 2013), and the scheme is prone to suffer from the curse of dimensionality, since it approximates a general stochastic system with a Markov chain by partitioning the state space.",
      "startOffset" : 26,
      "endOffset" : 86
    }, {
      "referenceID" : 9,
      "context" : "A learning approach is suitable for complex systems, such as general Markov processes, since it replaces model-based evaluations by model-free, sample-based evaluations (Busoniu et al., 2010).",
      "startOffset" : 169,
      "endOffset" : 191
    }, {
      "referenceID" : 23,
      "context" : "Quantitative Approximations for Reach-Avoid over General Markov Processes as a tool to assign an accuracy guarantee. Alternatively, model-based and sample-based bounds: these bounds verify the accuracy of a dynamic programming scheme by drawing samples of the model and using available information from the model, and from the specific reach-avoid property under study. In the analysis of the algorithm these bounds can be perceived as complementary. A-priori and sample-free bounds are derived in Section 4 based on model-free/distribution-free notions, whereas model-based and sample-based bounds are given in Section 5. 3. Fitted Value Iteration In this section we consider a learning algorithm that has been developed to solve additivecost optimal control problems, and adapt it to the reach-avoid optimal control setting. Known as FVI Munos and Szepesvari (2008), the algorithm extracts a finite number of samples from the underlying model to numerically approximate the value recursions in (2).",
      "startOffset" : 42,
      "endOffset" : 868
    }, {
      "referenceID" : 16,
      "context" : "Haesaert, Babuska and Abate using the estimation T̂Ŵ ∗ k+1 of the recursion step is bounded using Hoeffding’s inequality (Hoeffding, 1963).",
      "startOffset" : 121,
      "endOffset" : 138
    }, {
      "referenceID" : 16,
      "context" : "Hoeffding’s inequality (Hoeffding, 1963) leads to an upper bound on the deviation of the estimate from the expected value as follows: P { ∣ ∣",
      "startOffset" : 23,
      "endOffset" : 40
    }, {
      "referenceID" : 15,
      "context" : "Observe that since the expected and the empirical losses can be reformulated respectively as the mean and the empirical mean of a loss function, defined informally as f(x) = |w(x) − TŴ ∗ k+1(x)|, the above problem can be framed as the uniform convergence of a standard learning problem (Haussler, 1992; Pollard, 1984; Vapnik, 1998).",
      "startOffset" : 286,
      "endOffset" : 331
    }, {
      "referenceID" : 6,
      "context" : "Resorting to related literature, results on bounds for the error probability of the regression of real-valued functions employ capacity concepts (including Rademacher averages, covering numbers, and pseudo dimensions) of a function class (Bartlett et al., 2005; Hoeffding, 1963).",
      "startOffset" : 238,
      "endOffset" : 278
    }, {
      "referenceID" : 16,
      "context" : "Resorting to related literature, results on bounds for the error probability of the regression of real-valued functions employ capacity concepts (including Rademacher averages, covering numbers, and pseudo dimensions) of a function class (Bartlett et al., 2005; Hoeffding, 1963).",
      "startOffset" : 238,
      "endOffset" : 278
    }, {
      "referenceID" : 15,
      "context" : "By results in (Haussler, 1992) and (Pollard, 1984), we obtain the following uniform convergence bound.",
      "startOffset" : 14,
      "endOffset" : 30
    }, {
      "referenceID" : 6,
      "context" : "Since the bounds are independent of the distributions η and Tx (· | x, a), they are in fact distribution-free bounds (Bartlett et al., 2005).",
      "startOffset" : 117,
      "endOffset" : 140
    }, {
      "referenceID" : 12,
      "context" : "It is related to the notion of concentrability of the future-state distribution (Munos and Szepesvari, 2008; Farahmand et al., 2010).",
      "startOffset" : 80,
      "endOffset" : 132
    }, {
      "referenceID" : 6,
      "context" : "The used distributionfree notions lead to conservative bounds (Bartlett et al., 2005), which then result in a large set of required samples.",
      "startOffset" : 62,
      "endOffset" : 85
    }, {
      "referenceID" : 16,
      "context" : "2, the estimates of the single step error above, and the bias (21) in combination with Hoeffding’s inequality (Hoeffding, 1963).",
      "startOffset" : 110,
      "endOffset" : 127
    }, {
      "referenceID" : 13,
      "context" : "Case Study and Numerical Experiments We consider a case study from the literature (Fehnker and Ivančić, 2004), where the goal is to maximize the probability that the temperature of two interconnected rooms, while staying within a comfortable range, reaches a smaller target range within a given finite time horizon.",
      "startOffset" : 82,
      "endOffset" : 109
    }, {
      "referenceID" : 14,
      "context" : "A neural network with a single layer of hidden units of Gaussian type radial basis functions is proved to be a universal approximator for real-valued functions (Hartman et al., 1990).",
      "startOffset" : 160,
      "endOffset" : 182
    }, {
      "referenceID" : 17,
      "context" : "Furthermore the pseudo dimension of an artificial neural network with W free parameters and k hidden nodes has been upper bounded by O(W 2k2) (Karpinski and Macintyre, 1997; Anthony and Bartlett, 1999).",
      "startOffset" : 142,
      "endOffset" : 201
    }, {
      "referenceID" : 4,
      "context" : "Furthermore the pseudo dimension of an artificial neural network with W free parameters and k hidden nodes has been upper bounded by O(W 2k2) (Karpinski and Macintyre, 1997; Anthony and Bartlett, 1999).",
      "startOffset" : 142,
      "endOffset" : 201
    }, {
      "referenceID" : 3,
      "context" : "Proof of Lemma 6: Bound on Estimation Error We employ results on the concentration of random variables (Anthony, 2002), which in general raise conditions on a random variable ensuring its realizations to be concentrated around its expectation, in the sense that the probability of a deviation from the expectation is exponentially small (as a function of the deviation).",
      "startOffset" : 103,
      "endOffset" : 118
    }, {
      "referenceID" : 3,
      "context" : "Proof of Lemma 6: Bound on Estimation Error We employ results on the concentration of random variables (Anthony, 2002), which in general raise conditions on a random variable ensuring its realizations to be concentrated around its expectation, in the sense that the probability of a deviation from the expectation is exponentially small (as a function of the deviation). Of interest to this work is a known bound holding for sums of bounded and independent random variables Hoeffding (1963). Proposition 13 (Hoeffding’s inequality, Hoeffding (1963)) Suppose that Xi, for i = 1, 2, .",
      "startOffset" : 104,
      "endOffset" : 491
    }, {
      "referenceID" : 3,
      "context" : "Proof of Lemma 6: Bound on Estimation Error We employ results on the concentration of random variables (Anthony, 2002), which in general raise conditions on a random variable ensuring its realizations to be concentrated around its expectation, in the sense that the probability of a deviation from the expectation is exponentially small (as a function of the deviation). Of interest to this work is a known bound holding for sums of bounded and independent random variables Hoeffding (1963). Proposition 13 (Hoeffding’s inequality, Hoeffding (1963)) Suppose that Xi, for i = 1, 2, .",
      "startOffset" : 104,
      "endOffset" : 549
    }, {
      "referenceID" : 16,
      "context" : "If we further have information on the variance of Zj , one can leverage the inequalities of Chebyshev and of Bienaym-Chebyshev (Hoeffding, 1963), or alternatively Bernstein’s inequality (Peshkin and Mukherjee, 2001): the former bounds are only function of the variance, whereas the latter inequality depends not only on variance of Zj but also on its bounded domain.",
      "startOffset" : 127,
      "endOffset" : 144
    }, {
      "referenceID" : 15,
      "context" : "Proof of Lemma 7 We derive a general, analytical bound on the error of a single backward recursion using notions from statistical learning theory (Haussler, 1992; Pollard, 1984).",
      "startOffset" : 146,
      "endOffset" : 177
    }, {
      "referenceID" : 3,
      "context" : "The notion of pseudo dimension (Pollard, 1984; Anthony, 2002; Haussler, 1992) expresses the capability of a function class W to the fit a set of samples.",
      "startOffset" : 31,
      "endOffset" : 77
    }, {
      "referenceID" : 15,
      "context" : "The notion of pseudo dimension (Pollard, 1984; Anthony, 2002; Haussler, 1992) expresses the capability of a function class W to the fit a set of samples.",
      "startOffset" : 31,
      "endOffset" : 77
    }, {
      "referenceID" : 15,
      "context" : "Let us introduce the concept of covering number of a metric space (Haussler, 1992).",
      "startOffset" : 66,
      "endOffset" : 82
    }, {
      "referenceID" : 15,
      "context" : "For a given ǫ > 0 we denote the covering number N (ǫ, S, ρ) (Haussler, 1992) as the cardinality of the smallest ǫ-cover of S.",
      "startOffset" : 60,
      "endOffset" : 76
    }, {
      "referenceID" : 22,
      "context" : ", where Eη denotes the expected value with respect to η. This allows us to use a result in (Pollard, 1984), which provides an upper-bound on the probability of the above event as a function of the covering number of the metric space ((lW)~x, ‖ · ‖1). Proposition 15 (Pollard (1984)) Let F be a permissable set of functions on X with 0 ≤ f(x) ≤ K for all f ∈ F and x ∈ X .",
      "startOffset" : 11,
      "endOffset" : 282
    }, {
      "referenceID" : 15,
      "context" : "Since there is a trivial isometry (Haussler, 1992) between (lW|~x, ‖ · ‖1) and (lW , ‖ · ‖1,η̂), both spaces have equal covering numbers N (ǫp2/16, lW|~x, ‖ · ‖1) = N (ǫ p 2/16, lW , ‖ · ‖1,η̂).",
      "startOffset" : 34,
      "endOffset" : 50
    }, {
      "referenceID" : 15,
      "context" : "For any distribution P ∈ M(X ), the packing number (Haussler, 1992) and therefore also tho covering number of the metric space (lW , ‖ · ‖1,P ) can be upper bounded as a function of the pseudo-dimension and the base of the natural logarithm e: for any ǫ > 0, N (ǫ, lW , ‖ · ‖1,P ) ≤ e(d+ 1) ( 2e ǫ d , with dimp(lW) = d.",
      "startOffset" : 51,
      "endOffset" : 67
    }, {
      "referenceID" : 14,
      "context" : "Since there is a trivial isometry (Haussler, 1992) between (lW|~x, ‖ · ‖1) and (lW , ‖ · ‖1,η̂), both spaces have equal covering numbers N (ǫp2/16, lW|~x, ‖ · ‖1) = N (ǫ p 2/16, lW , ‖ · ‖1,η̂). In practice a value for E [N (ǫp2/16, lW , ‖ · ‖1,η̂)] can be obtained by upper bounding N (ǫp2/16, lW , ‖ · ‖1,η̂) independently of the sample distribution. For this we introduce the pseudo dimension of a function class, formally defined as follows Pollard (1984); Anthony (2002); Haussler (1992).",
      "startOffset" : 35,
      "endOffset" : 460
    }, {
      "referenceID" : 3,
      "context" : "For this we introduce the pseudo dimension of a function class, formally defined as follows Pollard (1984); Anthony (2002); Haussler (1992).",
      "startOffset" : 108,
      "endOffset" : 123
    }, {
      "referenceID" : 3,
      "context" : "For this we introduce the pseudo dimension of a function class, formally defined as follows Pollard (1984); Anthony (2002); Haussler (1992). Suppose F is a class of functions, f ∈ F , f : X → [0, 1].",
      "startOffset" : 108,
      "endOffset" : 140
    }, {
      "referenceID" : 15,
      "context" : "The invariance properties of the pseudo dimension dimp(W) shown in (Haussler, 1992) allow to conclude that dimp( { w − TW ∣ w ∈ W } ) = dimp(W).",
      "startOffset" : 67,
      "endOffset" : 83
    }, {
      "referenceID" : 18,
      "context" : "Since it was shown in (Kearns and Schapire, 1994) that the pseudo dimension is invariant over function composition (|·|), we conclude that the pseudo dimension is dimp(lW) = dimp({w − TW : w ∈ W}) = dimp(W) = d.",
      "startOffset" : 22,
      "endOffset" : 49
    }, {
      "referenceID" : 4,
      "context" : "(Anthony and Bartlett, 1999) elaborates the details of the computation of pseudo dimensions of parameterized function classes, especially for function classes defined over neural networks.",
      "startOffset" : 0,
      "endOffset" : 28
    }, {
      "referenceID" : 6,
      "context" : "Notice that for non-parametric function classes, concepts such as covering number or Rademacher average of the function class lW can be used instead (Bartlett et al., 2005).",
      "startOffset" : 149,
      "endOffset" : 172
    }, {
      "referenceID" : 6,
      "context" : "A second option is to explore alternatives over Pollard inequality in (15) with better constants (Bartlett et al., 2005).",
      "startOffset" : 97,
      "endOffset" : 120
    }, {
      "referenceID" : 3,
      "context" : "By the union bound argument (Anthony, 2002), the probability of the union of events can be bounded by the sum of the probabilities of the single events.",
      "startOffset" : 28,
      "endOffset" : 43
    }, {
      "referenceID" : 16,
      "context" : "The probabilistic bound (30) follows from a one-sided Hoeffding’s inequality (Hoeffding, 1963) with random variable ∑Nt−1 k=1 B k−1 (∣ ∣",
      "startOffset" : 77,
      "endOffset" : 94
    } ],
    "year" : 2015,
    "abstractText" : "This article deals with stochastic processes endowed with the Markov (memoryless) property and evolving over general (uncountable) state spaces. The models further depend on a non-deterministic quantity in the form of a control input, which can be selected to affect the probabilistic dynamics. We address the computation of maximal reach-avoid specifications, together with the synthesis of the corresponding optimal controllers. The reach-avoid specification deals with assessing the likelihood that any finite-horizon trajectory of the model enters a given goal set, while avoiding a given set of undesired states. This article newly provides an approximate computational scheme for the reach-avoid specification based on the Fitted Value Iteration algorithm, which hinges on random sample extractions, and gives a-priori computable formal probabilistic bounds on the error made by the approximation algorithm: as such, the output of the numerical scheme is quantitatively assessed and thus meaningful for safety-critical applications. Furthermore, we provide tighter probabilistic error bounds that are sample-based. The overall computational scheme is put in relationship with alternative approximation algorithms in the literature, and finally its performance is practically assessed over a benchmark case study.",
    "creator" : "LaTeX with hyperref package"
  }
}