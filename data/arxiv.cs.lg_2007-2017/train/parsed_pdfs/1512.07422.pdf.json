{
  "name" : "1512.07422.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "Adaptive Algorithms for Online Convex Optimization with Long-term Constraints",
    "authors" : [ "Rodolphe Jenatton", "Jim Huang", "Cédric Archambeau" ],
    "emails" : [ "jenatton@amazon.com", "huangjim@amazon.com", "cedrica@amazon.com" ],
    "sections" : [ {
      "heading" : null,
      "text" : "We present an adaptive online gradient descent algorithm to solve online convex optimization problems with long-term constraints, which are constraints that need to be satisfied when accumulated over a finite number of rounds T , but can be violated in intermediate rounds. For some user-defined trade-off parameter β ∈ (0, 1), the proposed algorithm achieves cumulative regret bounds ofO(Tmax{β,1−β}) andO(T 1−β/2) for the loss and the constraint violations respectively. Our results hold for convex losses and can handle arbitrary convex constraints without requiring knowledge of the number of rounds in advance. Our contributions improve over the best known cumulative regret bounds by Mahdavi, et al. (2012) that are respectively O(T 1/2) and O(T 3/4) for general convex domains, and respectively O(T 2/3) andO(T 2/3) when further restricting to polyhedral domains. We supplement the analysis with experiments validating the performance of our algorithm in practice."
    }, {
      "heading" : "1 Introduction",
      "text" : "Online convex optimization (OCO) plays a key role in machine learning applications, such as adaptive routing in networks [2] and online display advertising [1]. In general, an OCO problem can be formulated as a sequential and repeated game between a learner and an adversary. In each round t, the learner first plays a vector xt ∈ X ⊆ Rp, where X is a compact convex set corresponding to the set of possible solutions. The learner then incurs a loss ft(xt) for playing vector xt. The function ft(x) : X → R+ is defined by the adversary and can vary in each round, but it is assumed to\nbe convex. We say that a function ft : Rd 7→ R+ is strongly convex with modulus σ > 0 if\nft(x) ≤ ft(y) +∇ft(x)>(x− y)− σ\n2 ‖x− y‖2.\nfor any x,y ∈ Rd. We use the notation ∇ft(x) to refer to any (sub-)gradient of ft at x. Furthermore, we say that ft is convex if σ = 0.\nThe learner’s objective is to generate a sequence of vectors xt ∈ X for t = 1, 2, · · · , T that minimizes the cumulative regret over T rounds relative to the optimal vector x?:\nRegretT (x ∗), T∑ t=1 ft(xt)− T∑ t=1 ft(x ?). (1)\nThe latter measures the difference between the cumulative loss of the learner’s sequence of vectors {xt}Tt=1 and the accumulated loss that would be incurred if the sequence of loss functions ft would be known in advance and the learner could choose the best vector x? in hindsight.\nSeveral algorithms have been developed over the past decade that achieve sub-linear cumulative regret in the OCO setting. The problem was formalized in the seminal work of [26], which presents an online algorithm based on projected gradient descent [3] that guarantees a cumulative regret of O(T 1/2) when the set X is convex and the loss functions are Lipschitz-continuous over X . In [11] and [22], algorithms with logarithmic regret bounds were proposed for strongly convex loss functions. Notably, online gradient descent achieves anO(log T ) regret bound for strongly convex loss functions for appropriate choices of step size.\nIn the aforementioned work, the constraint on vector xt is assumed to hold in round t, such that a projection step is applied in every round to enforce the feasibility of each xt. For general convex sets X , the projection step may require solving an auxiliary optimization problem, which can be computationally expensive (e.g., projections onto the semi-definite cone). More importantly, in practical applications, the learner may\nar X\niv :1\n51 2.\n07 42\n2v 1\n[ st\nat .M\nL ]\n2 3\nD ec\n2 01\nin fact only be concerned with satisfying long-term constraints, that is, the cumulative constraint violations resulting from the sequence of vectors {xt}Tt=1 should not exceed a certain amount by the final round T . An example of such an application is in online display advertising, where xt corresponds to a vector of ad budget allocations and the learner is primarily concerned in enforcing the long-term constraint that each ad consumes its budget in full over the lifetime of the ad. Another example is from wireless communications [18], where xt is a vector of power allocations across multiple devices, and the learner must satisfy average power consumption constraints per device.\nIn this work, we consider OCO problems where the learner is required to satisfy long-term constraints. For such problems, we will be concerned both with a) the learner’s cumulative regret as defined by (1) and b) the learner’s ability to satisfy long-term constraints – the notion of long-term shall be made more formal in Section 2.2. This class of problems was studied previously in [15, 16]. In particular, [16] considered online exponentially-weighted average in the case where the loss and constraints are linear, while [15] presented online algorithms based on projected subgradients and the mirror prox method [20]. The authors derived cumulative regret bounds for the cumulative loss and cumulative constraint violations respectively of O(T 1/2) and O(T 3/4) in the case of online projected subgradients, and respectively of O(T 2/3) and O(T 2/3) in the case of mirror prox. To our knowledge, these are the best-known regret bounds for OCO with long-term constraints. The analysis of [15] assumes the number of rounds is known ahead of time, which enables the authors to set the various constants in the algorithm that lead to the desired regret bounds. For the mirror prox method, it is additionally required that the constraint set X is fully specified by a finite number of linear constraints.\nThe concept of long-term constraints also enables us to avoid the computation of potentially expensive projections onto the domain X of x in each round. This is closely related to recent work in stochastic optimization that aims to minimize the number of expensive projection steps [17]. The guarantees sought in our analysis have also similarities with the results obtained in the context of the online alternating direction method [23], where regret bounds are provided for the violation of equality constraints.\nContributions: Building on the work of [15], we propose an algorithm based on a saddle-point formulation of the OCO problem with long-term constraints, which is adaptive (i.e., the step sizes and the regularisation parameter depend on the round t). We show that the algorithm satisfies cumulative regret bounds\nof O(T 2/3) for both the cumulative loss and the cumulative constraint violations without requiring us to know the number of rounds T in advance to set the algorithmic hyperparameters. Unlike mirror prox, our method can deal with any convex constraint set X , making it amenable to a wider range of OCO problems. Also, the algorithm we derive allows us to interpolate between the regret bounds of O(T 1/2) and O(T 3/4) from [15] and the above bound of O(T 2/3), depending on how we wish to trade off between the cumulative regret associated to the loss and the long-term constraints. In addition to our analysis of regret bounds, we empirically validate our algorithm by comparing it to the methods of [15] on a) the online estimation of doubly stochastic matrices and b) the online learning of sparse logistic regression based on the elastic net penalty [27]."
    }, {
      "heading" : "2 Online Convex Optimization with Long-term Constraints",
      "text" : ""
    }, {
      "heading" : "2.1 Preliminaries",
      "text" : "Consider m convex functions gj : Rd 7→ R which induce a convex constraint set\nX , {\nx ∈ Rd : max j∈{1,··· ,m}\ngj(x) ≤ 0 } .\nWe assume that the set X is bounded so that it is included in some Euclidean ball B with radius R > 0 (to be further discussed in Section 5):\nX ⊆ B , { x ∈ Rd : ‖x‖2 ≤ R } .\nAlong with the functions gj , we consider a sequence of convex functions ft : Rd 7→ R+ such that\nmax t∈{1,··· ,T} max x,x′∈B\n|ft(x)− ft(x′)| ≤ F for some F > 0.\nAs is typically assumed in online learning [6], the functions gj and ft shall be taken to be Lipschitz continuous. We do not generally assume gj and ft to be differentiable. We further assume that for some finite G > 0 the (sub-)gradients of f and gj are bounded\nmax j∈{1,··· ,m} max x∈B ‖∇gj(x)‖2 ≤ G,\nmax t∈{1,··· ,T} max x∈B ‖∇ft(x)‖2 ≤ G.\nWe take the same constant G for, both, gj and ft for simplicity as we can always take the maximum between that of gj and that of ft. Finally, we assume that there exists a finite D > 0 such that the constraint functions are bounded over B:\nmax j∈{1,··· ,m} max x∈B |gj(x)| ≤ D.\nFinally, we note that the set of assumptions enumerated in this section are equivalent to the ones in [15].\nR.Jenatton, J.Huang, C. Archambeau"
    }, {
      "heading" : "2.2 Problem Statement",
      "text" : "Let {xt}Tt=1 be the sequence of vectors played by the learner and {ft(xt)}Tt=1 the corresponding sequence of incurred losses. We aim at efficiently solving the following optimization problem in online fashion:\nmin xT∈B\n{ fT (xT ) + . . .\n+ min x2∈B\n{ f2(x2) + min\nx1∈B f1(x1)\n}} −min\nx∈X T∑ t=1 ft(x)\nsubject to the following long-term constraint :\nmax j∈{1,··· ,m} T∑ t=1 gj(xt) ≤ 0."
    }, {
      "heading" : "3 Adaptive Online Algorithms based on a Saddle-point Formulation",
      "text" : "Following [15], we consider a saddle-point formulation of the optimization problem. For any λ ∈ R+,x ∈ B we define the following function:\nLt(x, λ) , ft(x) + λg(x)− θt 2 λ2\nwhere g(x) , maxj∈{1,··· ,m} gj(x) and {θt}Tt=1 is a sequence of positive numbers to be specified later. The role of g is to aggregate the m constraints into a single function. It otherwise preserves the same properties as those of individual gj ’s (sub-differentiability, bounded (sub-)gradients and bounded values; see Proposition 6 in [15] or Section 2.3 in [5] for a proof). In the saddle-point formulation (2), we will alternate between minimizing with respect to the primal variable x and maximizing with respect to the dual parameter λ. A closer look at the function λ 7→ Lt(x, λ) indicates that we penalize the violation of the constraint g(x) ≤ 0 through, using [u]+ , max{0, u},\n1\n2θt [g(x)]2+ = sup λ∈R+\n[ λg(x)− θt 2 λ2 ] , (2)\nwhich is a penalty commonly used when going from constrained to unconstrained problems (e.g., Section 17.1 in [21]). Also, we can see from (2) that θt acts as a regularization parameter. We note at this point that in contrast to our method, [15] make use of a single θ that is constant in all rounds.1\nIn the sequel, we study the following online algorithm where we alternate between primal-descent and dualascent steps:\n• Initialize x1 = 0 and λ1 = 0 1More precisely, in [15], θ is equal to the product of a\nconstant step size times a constant scaling factor.\n• For t ∈ {1, · · · , T − 1}: xt+1 = ΠB(xt − ηt∇xLt(xt, λt)) λt+1 = ΠR+(λt + µt∇λLt(xt, λt)),\nwhere ΠC stands for the Euclidean projection onto the set C, while {ηt}Tt=1 and {µt}Tt=1 are sequences of nonnegative step sizes that respectively drive the update of x and λ. The algorithm is in the same vein as the ones proposed in [15, 13], but it is adaptive. The step sizes, which are different for the updates of x and λ, are listed in Table 1. They result from the analysis we provide in the next section. We also derive sub-linear regret bounds associated to these instantiations of the sequences {θt}Tt=1, {ηt}Tt=1 and {µt}Tt=1."
    }, {
      "heading" : "3.1 Main Results",
      "text" : "We begin by listing three sufficient conditions for obtaining sub-linear regret bounds for the proposed algorithm:\n(C1): For any t ≥ 2, 1µt − 1 µt−1 − θt ≤ 0.\n(C2): For any t ≥ 2, ηtG2 + µtθ2t − 12θt ≤ 0. (C3): For some finite Uη > 0,∑T t=2 [ 1 ηt − 1ηt−1 − σ ] ≤ Uη.\nConditions C1 and C3 impose constraints on the decreasing speed of the step sizes. We note that there is an asymmetry between µt and ηt: while we will always be able to control the norm of the variables xt (by design, they must lie in B), the sequence {λt}Tt=1 is not directly upper-bounded in the absence of further assumptions on the gradient of g, hence the most stringent condition C1 is to avoid any dependencies on λt. Condition C2 couples the behaviour of the three sequences to guarantee their validity. Finally, C1, C2 and C3 are expressed for t ≥ 2 because of our choice for the initial conditions x1 = 0 and λ1 = 0.\nOur main result is described in the following theorem, whose proof is in Section 3.2:\nTheorem 1. Consider the convex case (σ = 0) and the corresponding instantiations of the sequences µt, ηt and θt for some β ∈ (0, 1), as summarized in Table 1. It holds for any T ≥ 1 that\nT∑ t=1 ∆ft≤RfT , [ RG+ D2 6βRG ] T β + 2RG 1− β T 1−β\nwhere ∆ft , ft(xt)− ft(x?), and\nT∑ t=1 g(xt) ≤\n√ 24RG\n1− β\n( RfT + FT ) T 1−β .\nFor the strongly convex case (σ > 0), we also have valid instantiations of ηt, µt, θt (see Table 1), whose resulting cumulative regret bounds are tighter than those given in Theorem 1, but with the same leading terms. Theorem 1 can be stated in a simplified form, forgetting momentarily about the dependencies on {D,G,R, F}:∑T\nt=1 ∆ft ≤ O(max{T β , T 1−β}),∑T t=1 g(xt) ≤ O(T 1−β/2).\nIn particular, by setting β = 2/3, we obtain\nT∑ t=1 ∆ft ≤ O(T 2/3) and T∑ t=1 g(xt) ≤ O(T 2/3),\nwhich matches the mirror prox guarantees of [15] while being valid for general convex constraint sets X as opposed to just polyhedral constraint sets. Similarly, taking β = 1/2, we recover the regret bounds\nT∑ t=1 ∆ft ≤ O(T 1/2) and T∑ t=1 g(xt) ≤ O(T 3/4),\nof Section 3.1 in [15]. We can, of course, also define novel trade-offs between loss and constraint violations, e.g., β = 3/4 with regret bounds of O(T 3/4) and O(T 5/8) respectively."
    }, {
      "heading" : "3.2 Analysis and Proofs",
      "text" : "To analyze the above algorithm, we first introduce a series of lemmas. The analysis is analogous to that developed in [15], which we provide below for selfcontainedness. We begin by upper-bounding the variations of Lt with respect to its two arguments. In particular, the following lemma takes advantage of the fact that the partial function λ 7→ Lt(xt, λ) is not only concave as considered in [15], but strongly concave with parameter θt. This observation is at the origin of our improved regret bounds.\nLemma 1 (Upper bound of Lt(xt, λ)−Lt(xt, λt)). For Lt(x, λ) as defined above and for non-negative ηt, θt and µt, we have\nLt(xt, λ)− Lt(xt, λt) ≤ 12µt [ bt − bt+1 ] − θt2 bt\n+µt2 [∇λLt(xt, λt)] 2\nwhere bt , (λ− λt)2.\nProof. Expanding (λ− λt+1)2 yields (λ− λt+1)2 = ( λ−ΠR+(λt + µt∇λLt(xt, λt)) )2 ≤ ( λ− (λt + µt∇λLt(xt, λt))\n)2 = (λ− λt)2 − 2µt(λ− λt)∇λLt(xt, λt) + µ2t (∇λLt(xt, λt))2\nBy strong concavity of Lt(xt, λ) with respect to λ,\nLt(xt, λt)− Lt(x̂t, λ) ≤ (λ− λt)∇λLt(xt, λt)− θt 2 bt.\nSubstituting the inequality for µt(λ− λt)∇λLt(xt, λt) completes the proof.\nWe omit the derivation for x 7→ Lt(x, λt) that follows similar arguments. We now turn to a lower-bound of the variations of Lt. Lemma 2. Let x? = arg minx∈X ∑T t=1 ft(x). Then\nT∑ t=1 Lt(xt, λ)− Lt(x?, λt) ≥\nT∑ t=1 ∆ft + λ T∑ t=1 g(xt)− λ2 2 T∑ t=1 θt + 1 2 T∑ t=1 θtλ 2 t .\nProof. We have Lt(xt, λ)− Lt(x?, λt) equal to\nft(xt)− ft(x?) + λg(xt)− λtg(x?)− θt 2 (λ2 − λ2t ).\nWe simply notice that g(x?) ≤ 0 to obtain a lower bound −g(x?) ∑T t=1 λt to complete the proof after summing both sides over rounds t = 1, · · · , T .\nLemma 3. Let at , ‖xt − x‖2. For any σ, θt ≥ 0, T∑ t=1 1 2ηt [ at − at+1 ] − σ 2 at ≤\nR2\n2 δη +\n1\n2 T∑ t=2 at [ 1 ηt − 1 ηt−1 − σ ] ,\nT∑ t=1 1 2µt [ bt − bt+1 ] − θt 2 bt ≤\nλ2\n2 δµ +\n1\n2 T∑ t=2 bt [ 1 µt − 1 µt−1 − θt ]\nR.Jenatton, J.Huang, C. Archambeau\nwhere we have used δη , 1η1 − σ and δµ , 1 µ1 − θ1.\nProof. Shifting indices in the sums for terms that depend on at+1/ηt, bt+1/µt and collecting terms that depend on at, bt, we then use a1 = ‖x1 − x‖22 = ‖x‖22 ≤ R2 and b1 = (λ− λ1)2 = λ2 to conclude.\nWe now present the key lemma of the analysis.\nLemma 4. [Cumulative regret bound] Let x? = arg minx∈X ∑T t=1 ft(x) and assume C1, C2 and C3 hold. Define RfT , R2 2 δη+G 2Sη+D 2Sµ+R 2Uη, where\nwe have introduced Sη , ∑T t=1 ηt, Sµ , ∑T t=1 µt and\nSθ , ∑T t=1 θt. Then, it holds that∑T\nt=1 ∆ft ≤ R f T ,\nand∑T t=1 g(xt) ≤ √ 2(Sθ + δµ)(RfT + FT ).\nProof. By the triangle inequality, we have ‖∇xLt(x, λ)‖22 ≤ 2G2(1 + λ2) and ( ∇λLt(x, λ) )2 ≤ 2(D2 + θ2tλ\n2). We then combine Lemmas 1-3, starting from Lt(xt, λ) − Lt(x∗, λt) = Lt(xt, λ) − Lt(xt, λt) + Lt(xt, λt) − Lt(x∗, λt), yielding∑T\nt=1 ∆ft + λ ∑T t=1 g(xt)− λ2 2 [ Sθ + δµ ] ≤\nRfT + ∑T t=1 λ 2 t [ ηtG 2 + µtθ 2 t − 12θt ] .\nMaximizing the left-hand side with respect to λ ∈ R+, we obtain:\n∑T t=1 ∆ft +\n[∑T t=1 g(xt) ]2 +\n2 [ Sθ+δµ ] ≤ RfT + ∑T t=1 λ 2 t [ ηtG 2 + µtθ 2 t − 12θt ] .\nThe regret bound on the loss is obtained by using C2 and [ ∑T t=1 g(xt)] 2 +/(2[Sθ + δµ]) ≥ 0. The bound on constraint violations is obtained as above, but by substituting the lower bound ∑ t ∆ft ≥ −FT .\nIn order to discuss the scaling of our regret bounds, we state the next simple lemma without proof\nLemma 5. Let β ∈ (0, 1). Then ∑T t=1 1 tβ ≤ T 1−β 1−β .\nWith the above lemmas, we now prove Theorem 1:\nProof of Theorem 1. For the proposed choices of θt, µt and ηt, we can verify that C1, C2 and C3 hold. Here we focus on the convex case, the strongly convex one following along the same lines. First, we can easily see that C1 is true as long as θt is non-increasing. Then, we can notice that, given the choice of µt, condition C2\nis implied by the stronger condition ηt ≤ θt6G2 (satisfied by the choice of ηt and θt in Table 1). This results in\nSµ = T∑ t=1\n1\nθt(t+ 1) ≤ T∑ t=1 tβ 6RGt ≤ T β 6βRG .\nSη = T∑ t=1 ηt ≤ R G T 1−β 1− β , Sθ = T∑ t=1 6RG tβ ≤ 6RG 1− β T 1−β ,\nalong with 1/µ1 − θ1 = 6RG and 1/η1 − σ = G/R. The term Uη can be obtained by summing the series 1/ηt − 1/ηt−1 = (G/R)(tβ − (t − 1)β) over t, which directly simplifies by telescoping for the σ = 0 case, and is identically equal to zero for σ > 0. As a result, we obtain from Lemma 4 T∑ t=1 ∆ft≤RfT , [ RG+ D2 6βRG ] T β + RG 1− β T 1−β + RG 2\nand for the constraint\nT∑ t=1 g(xt) ≤\n√ 2(RfT + FT ) [ 6RG\n1− β T 1−β + 6RG\n] .\nWe obtain the desired conclusion by noticing that for any T ≥ 1 and β ∈ (0, 1), we have T 1−β\n1−β ≥ 1."
    }, {
      "heading" : "3.3 Towards No Violation of Constraints",
      "text" : "We next show that our extension also applies to the more specific setting developed in Section 3.2 from [15], where additional assumptions on the gradient of g can translate into no constraint violations. For the sake of self-containedness, we briefly recall it. Assume that there exist γ ≥ 0 and r > 0 such that the variations of g are lower bounded as\nmin x∈Rd:g(x)+γ=0\n‖∇g(x)‖2 ≥ r. (3)\nDenote Xγ , {x ∈ Rd : g(x) + γ ≤ 0} ⊂ X . It can then be shown that (see Theorem 7 in [15]):∣∣∣∑Tt=1 ft(x?)−∑Tt=1 ft(xγ)∣∣∣ ≤ Gr Tγ, (4) where x? and xγ are solutions of minx∈X ∑T t=1 ft(x)\nand minx∈Xγ ∑T t=1 ft(x) respectively. In words, the gap between the optimal value of the original optimization problem and that of the problem over Xγ is well-controlled as a function of (γ, r). Examples where (3) holds include the positive semi-definite cone, as described in Section 4 of [17]. For space limitation reasons, we state our result in a simplified form, only briefly sketching its proof that follows the same logic as that of the previous section.\nCorollary 1. Assume (3) holds. Consider the convex case (σ = 0) and some instantiations of the sequences µt, ηt and θt for some β ∈ (0, 1), differing from Table 1 only up to numerical constants. There exist c0 and c1 depending on {D,G,R, F, r} such that setting γ , c1T\n−β/2, we have for any T ≥ c0∑T t=1 ∆ft ≤ O(max{T β , T 1−β , T 1−β/2}),\nand no constraint violations ∑T t=1 g(xt) ≤ 0.\nSketch of proof. We can apply the same analysis as before to the function gγ(x) , g(x) + γ, replacing D by D + γ and adapting the constants in both C2 (i.e., ηtG 2 + 32µtθ 2 t − 12θt) as well as for the instantia-\ntions of µt, ηt and θt. The regret bound on ∑T t=1 ∆ft is identical as earlier, with additional additive terms 3γ2Sµ/2 and GTγ/r introduced as a result of (4). As\nfor ∑T t=1 g(xt), the term [ ∑T t=1 g(xt)] 2 + becomes here\n[ ∑T t=1 g(xt) + γT ] 2 +, which in turn leads to the same regret bound as previously stated, minus the contribution −γT . We cancel out the constraint violations— scaling in O(T 1−β/2) according to Theorem 1—by setting γ = c1T\n−β/2. Note that c0 is determined by examining when the extra term 3γ2Sµ/2 can be upper bounded by those in RfT .\nThe regret bound presented in Corollary 1 is minimized for β = 2/3, leading to a regret of O(T 2/3) with no constraint violations. This result extends Theorem 8 and Corollary 13 from [15] in that it holds for general convex domains X (as opposed to only polyhedral ones)."
    }, {
      "heading" : "4 Experiments",
      "text" : "We ran two sets of experiments to validate the regret bounds obtained for our adaptive algorithms for OCO with long-term constraints and compare to the algorithms proposed in [15]. First, we examine the online estimation of doubly-stochastic matrices where the convex domain of interest X is polyhedral but whose projection operator is difficult to compute [12, 10]. Second, we consider sparse online binary classification based on the elastic net penalty [27].\nWe shall refer to our adaptive online gradient descent (A-OGD) for convex ft (i.e., σ = 0) as Convex A-OGD and for strongly convex ft (i.e., σ > 0) as Strongly convex A-OGD, which enjoy the same regret guarantees of O(T 2/3) for the loss and constraint. The method of [15] that handles general convex domains X will be referred to as Convex OGD, while the mirror prox method analyzed in [15], which is only applicable to polyhedral domains, will be denoted by Convex mirror prox. The parameters of\nConvex OGD and Convex mirror prox are instantiated according to [15].\nAlthough we generate the sequence of losses {ft}Tt=1 stochastically in the experiments, we would like to emphasize that the regret bounds we obtain are also valid for adversarially-generated sequences, so that it is not required that {ft}Tt=1 are generated in i.i.d. fashion."
    }, {
      "heading" : "4.1 Doubly-Stochastic Matrices",
      "text" : "Doubly-stochastic matrices appear in many machine learning and optimization problems, such as clustering applications [25] or learning permutations [12, 10]. Briefly, for a sequence of matrices {Yt}Tt=1 in Rp×p, we solve the following optimization problem in an online fashion:\nmin X∈Rp×p T∑ t=1 1 2 ‖Yt −X‖2F (5)\nsubject to the (linear) convex constraints\nX ≥ 0, X1 = 1 and X>1 = 1.\nThis problem can easily be mapped to OCO setting by assuming that the sequence {Y}Tt=1 is generated by random permutation matrices which are known to constitute the extreme points of the set of doublystochastic matrices [4]. We have d = p2, ft(X) = 1 2‖Yt − X‖ 2 F and m = p\n2 + 4p to describe all the linear constraints, more specifically there are p2 nonnegativity constraints, along with 4p inequalities to model the 2p equality constraints. This leads to the following instantiations of the parameters controlling ft and g: R = √ p, G = 2R and D = R. Note that we can apply a) Strongly convex A-OGD (since ft is by construction strongly convex with parameter σ = 1), and b) Convex mirror prox since X is polyhedral.\nThe cumulative regret for the loss and the long-term constraint are shown in Figures 1 and 2. They are computed over T = 1000 iterations with d = 64, and are averaged over 10 random sequences {Yt}Tt=1 (the standard deviations are not shown since they are negligible). The offline solutions of (5) required for various t ∈ {1, · · · , T} to compute the regret are obtained using CVXPY [8].\nThe results shown in Figure 1 and 2 indicate that although the cumulative regret bounds for Strongly convex A-OGD were not demonstrated to be tighter in our analysis than those for Convex A-OGD, they achieve a better cumulative regret for this problem, especially with respect to the long-term constraint. Also, while Convex mirror prox and Convex A-OGD should theoretically exhibit the same behavior, the results suggest that mirror prox is not able to decrease cumulative regret at the same\nR.Jenatton, J.Huang, C. Archambeau\nrate as our proposed method. We surmise that this may be due to the fact that the guarantees of Convex mirror prox proved in [15] only hold for very large T .2"
    }, {
      "heading" : "4.2 Sparse Online Binary Classification",
      "text" : "Next, we examine the application of sparse online binary classification. Our goal will be to minimize the log-loss subject to a constrained elastic-net penalty:3\nmin x∈Rd:‖x‖1+ 12‖x‖ 2 2≤ρ T∑ t=1 log(1 + e−ytx >ut), (6)\nwhere {yt,ut}Tt=1 denotes a sequence of label/featurevector pairs and ρ > 0 is a parameter that measures the degree of the sparsity of the solutions of (6).\nThis problem is mapped to our formulation by setting ft(x) = log(1 + e −ytx>ut) with m = 1, g(x) = ‖x‖1 + 12‖x‖ 2 2 − ρ, R = √ 1 + 2ρ− 1,4 G = max{ √ d+\nR,maxt ‖ut‖2} and D = √ dR+R2/2. The sequences {yt,ut}Tt=1 are generated by drawing pairs at random with replacement.\nWe solve the above problem using the datasets ijcnn1 and covtype, consisting respectively of 49, 990 and 581, 012 samples of dimension d = 22 and d = 54\n2Theorem 12 from [15] requires T ≥ 164(m+1)2, which translates into T > 107 in our setting.\n3Constraint formulations with sparsity-inducing terms are sometimes preferred over their penalized counterparts when they express some concrete physical budget, e.g., in the context of learning predictors with low-latency [24].\n4The value for R is found by noticing that ‖x‖1 + 1 2 ‖x‖22 ≥ ‖x‖2 + 12‖x‖ 2 2 and solving the resulting secondorder polynomial inequality.\neach5. The parameter ρ is set to obtain approximately 30% of non-zero variables. Moreover, and in order to best display cumulative regret, we compute offline solutions of (6) for various t ∈ {1, · · · , T} thanks to an implementation of [7].\nThe results are summarized in Figures 3 and 4 and represent an average over 10 random sequences {yt,ut}Tt=1 (the standard deviations are not shown since they are negligible). The number of iterations T is equal to the number of samples in each dataset. Interestingly, we observe that the constraint is not violated on average (i.e., via a negative cumulative regret) and the iterates xt remain feasible within the domain ‖x‖1 + 12‖x‖ 2 2 ≤ ρ. This tendency is more pronounced for Convex OGD\n5 www.csie.ntu.edu.tw/ cjlin/libsvmtools/datasets/binary.html\nsince a closer inspection of the sequence {ηt}Tt=1 shows numerical values smaller than those of our approach Convex A-OGD (by 2 to 3 orders of magnitude). As a result, starting from x1 = 0, we found that the iterates generated by Convex OGD do not approach the boundary of the domain, hence increasing regret on cumulative loss. We also note that the offline solutions of (6) always saturate the constraint. Although our analysis predicts that the cumulative regret of Convex OGD associated to the loss (i.e., O(T 1/2)) should be smaller than that associated to Convex A-OGD (i.e., O(T 2/3)), Convex A-OGD achieves here a lower cumulative regret. This observation may be explained by the same argument as that described previously, namely that the larger step sizes {ηt}Tt=1 of Convex A-OGD enables us to make faster progress."
    }, {
      "heading" : "5 Discussion",
      "text" : "In this section, we discuss several generalizations.\nBroader families of step sizes. We have assumed that the updates of the primal variable x are driven by a projected gradient step controlled through a single step size ηt. Following the ideas developed in [19, 9], we could analyze the regret guarantees of our algorithm when there is a vector of step sizes ηt that is given by a diagonal matrix Diag(ηt) ∈ Rd×d, updating adaptively and separately each coordinate of x.\nCan we identify a better penalty? In the light of (2), it is tempting to ask whether we can find a penalty function that will lead to lower cumulative regret guarantees. To this end, we could for example introduce a smooth, 1-strongly-convex function φ with domain Ω. The saddle-point formulation of the new problem is then given by\nLt(x, λ) , ft(x) + λg(x)− θtφ(λ),\nwhere {θt}Tt=1 is, as earlier, a sequence of non-negative numbers to be specified subsequently for any λ ∈ Ω,x ∈ B. Interestingly, it can be shown that condition C2 becomes a first-order nonlinear ordinary differential inequality in this setting, leading to\nηtG 2λ2 + µtθ 2 t\n[ dφ\ndλ\n]2 − θtφ(λ) ≤ 0, for all λ ∈ Ω.\nHence, the above differential inequality suggests a family of penalty functions which we could use. In particular, we see that φ must grow at least quadratically and stay greater than its squared first derivative, which rules out a softmax penalty like λ 7→ log(1+eλ). Moreover, the maximization with respect to λ in the last step of Lemma 4 introduces the Moreau envelope [14] of the Fenchel conjugate of φ, namely\nφ∗Sθ (u) , sup λ∈Ω\n[ λu− Sθφ(λ)− δµ λ2\n2\n] .\nThe goal is then to find a feasible penalty φ of which the inverse mapping u 7→ [φ∗Sθ ]\n−1(u) would minimize the regret bound. For instance, the inverse mapping would scale as u 7→ √ u when using the squared `2 norm over Ω = R+. We defer to future work the study of this admissible family of penalties.\nWhich enclosing set for X? Our current analysis relies on the idea that instead of having to perform a projection on X in each update (which could be computationally costly and perhaps intractable in some cases), we restrict the iterates xt to remain within a simpler convex set B ⊇ X . While we assumed de facto an Euclidean ball for B, we could consider sets enclosing X more tightly, while preserving the appealing computational properties. Having a principled methodology to choose B and carefully assessing its impact on the regret bounds is an interesting avenue for future research."
    } ],
    "references" : [ {
      "title" : "Fast algorithms for online stochastic convex programming",
      "author" : [ "Shipra Agrawal", "Nikhil R. Devanur" ],
      "venue" : "In SODA 2015 (ACM-SIAM Symposium on Discrete Algorithms). SIAM-Society for Industrial and Applied Mathematics,",
      "citeRegEx" : "1",
      "shortCiteRegEx" : "1",
      "year" : 2015
    }, {
      "title" : "Online linear optimization and adaptive routing",
      "author" : [ "Baruch Awerbuch", "Robert Kleinberg" ],
      "venue" : "Journal of Computer and System Sciences,",
      "citeRegEx" : "2",
      "shortCiteRegEx" : "2",
      "year" : 2008
    }, {
      "title" : "Parallel and Distributed Computation: Numerical Methods",
      "author" : [ "Dimitri P. Bertsekas", "John N. Tsitsiklis" ],
      "venue" : "Prentice-Hall, Inc.,",
      "citeRegEx" : "3",
      "shortCiteRegEx" : "3",
      "year" : 1989
    }, {
      "title" : "Tres observaciones sobre el algebra lineal",
      "author" : [ "Garrett Birkhoff" ],
      "venue" : "Univ. Nac. Tucumán Rev. Ser. A,",
      "citeRegEx" : "4",
      "shortCiteRegEx" : "4",
      "year" : 1946
    }, {
      "title" : "Convex Analysis and Nonlinear Optimization: Theory and Examples",
      "author" : [ "J.M. Borwein", "A.S. Lewis" ],
      "venue" : "Springer",
      "citeRegEx" : "5",
      "shortCiteRegEx" : null,
      "year" : 2006
    }, {
      "title" : "Prediction, learning, and games",
      "author" : [ "Nicolo Cesa-Bianchi", "Gábor Lugosi" ],
      "venue" : null,
      "citeRegEx" : "6",
      "shortCiteRegEx" : "6",
      "year" : 2006
    }, {
      "title" : "Saga: A fast incremental gradient method with support for non-strongly convex composite objectives",
      "author" : [ "Aaron Defazio", "Francis Bach", "Simon Lacoste- Julien" ],
      "venue" : "Technical report, preprint arXiv:1407.0202,",
      "citeRegEx" : "7",
      "shortCiteRegEx" : "7",
      "year" : 2014
    }, {
      "title" : "CVXPY: A Python-embedded modeling language for convex optimization, version 0.2",
      "author" : [ "Steven Diamond", "Eric Chu", "Stephen Boyd" ],
      "venue" : "http://cvxpy.org/,",
      "citeRegEx" : "8",
      "shortCiteRegEx" : "8",
      "year" : 2014
    }, {
      "title" : "Adaptive subgradient methods for online learning and stochastic optimization",
      "author" : [ "J. Duchi", "E. Hazan", "Y. Singer" ],
      "venue" : "Journal of Machine Learning Research, 12:2121–2159",
      "citeRegEx" : "9",
      "shortCiteRegEx" : null,
      "year" : 2011
    }, {
      "title" : "d’Aspremont. Convex relaxations for permutation problems",
      "author" : [ "Fajwel Fogel", "Rodolphe Jenatton", "Francis Bach", "Alexandre" ],
      "venue" : "In Advances in Neural Information Processing Systems,",
      "citeRegEx" : "10",
      "shortCiteRegEx" : "10",
      "year" : 2013
    }, {
      "title" : "Logarithmic regret algorithms for online convex optimization",
      "author" : [ "Elad Hazan", "Amit Agarwal", "Satyen Kale" ],
      "venue" : "Machine Learning,",
      "citeRegEx" : "11",
      "shortCiteRegEx" : "11",
      "year" : 2007
    }, {
      "title" : "Learning permutations with exponential weights",
      "author" : [ "D.P. Helmbold", "M.K. Warmuth" ],
      "venue" : "Journal of Machine Learning Research, 10:1705–1736",
      "citeRegEx" : "12",
      "shortCiteRegEx" : null,
      "year" : 2009
    }, {
      "title" : "A saddle point algorithm for networked online convex optimization",
      "author" : [ "Alec Koppel", "Felicia Y Jakubiec", "Alejandro Ribeiro" ],
      "venue" : "In Acoustics, Speech and Signal Processing (ICASSP),",
      "citeRegEx" : "13",
      "shortCiteRegEx" : "13",
      "year" : 2014
    }, {
      "title" : "Practical aspects of the moreau–yosida regularization: Theoretical preliminaries",
      "author" : [ "Claude Lemaréchal", "Claudia Sagastizábal" ],
      "venue" : "SIAM Journal on Optimization,",
      "citeRegEx" : "14",
      "shortCiteRegEx" : "14",
      "year" : 1997
    }, {
      "title" : "Trading regret for efficiency: online convex optimization with long term constraints",
      "author" : [ "Mehrdad Mahdavi", "Rong Jin", "Tianbao Yang" ],
      "venue" : "Journal of Machine Learning Research,",
      "citeRegEx" : "15",
      "shortCiteRegEx" : "15",
      "year" : 2012
    }, {
      "title" : "Efficient constrained regret minimization",
      "author" : [ "Mehrdad Mahdavi", "Tianbao Yang", "Rong Jin" ],
      "venue" : "Technical report, preprint arXiv:1205.2265,",
      "citeRegEx" : "16",
      "shortCiteRegEx" : "16",
      "year" : 2012
    }, {
      "title" : "Stochastic gradient descent with only one projection",
      "author" : [ "Mehrdad Mahdavi", "Tianbao Yang", "Rong Jin", "Shenghuo Zhu", "Jinfeng Yi" ],
      "venue" : "In Advances in Neural Information Processing Systems,",
      "citeRegEx" : "17",
      "shortCiteRegEx" : "17",
      "year" : 2012
    }, {
      "title" : "Online learning with constraints. In Learning Theory, pages 529–543",
      "author" : [ "Shie Mannor", "John N Tsitsiklis" ],
      "venue" : null,
      "citeRegEx" : "18",
      "shortCiteRegEx" : "18",
      "year" : 2006
    }, {
      "title" : "Adaptive bound optimization for online convex optimization",
      "author" : [ "H Brendan McMahan", "Matthew Streeter" ],
      "venue" : "In Proceedings of the annual conference on Computational Learning Theory (COLT),",
      "citeRegEx" : "19",
      "shortCiteRegEx" : "19",
      "year" : 2010
    }, {
      "title" : "Prox-method with rate of convergence o (1/t) for variational inequalities with lipschitz continuous monotone operators and smooth convex-concave saddle point problems",
      "author" : [ "Arkadi Nemirovski" ],
      "venue" : "SIAM Journal on Optimization,",
      "citeRegEx" : "20",
      "shortCiteRegEx" : "20",
      "year" : 2004
    }, {
      "title" : "Numerical Optimization",
      "author" : [ "J. Nocedal", "S.J. Wright" ],
      "venue" : "Springer",
      "citeRegEx" : "21",
      "shortCiteRegEx" : null,
      "year" : 2006
    }, {
      "title" : "Mind the duality gap: Logarithmic regret algorithms for online optimization",
      "author" : [ "Shai Shalev-Shwartz", "Sham M Kakade" ],
      "venue" : "In Advances in Neural Information Processing Systems,",
      "citeRegEx" : "22",
      "shortCiteRegEx" : "22",
      "year" : 2009
    }, {
      "title" : "Online alternating direction method",
      "author" : [ "Huahua Wang", "Arindam Banerjee" ],
      "venue" : "Technical report, preprint arXiv:1306.3721,",
      "citeRegEx" : "23",
      "shortCiteRegEx" : "23",
      "year" : 2013
    }, {
      "title" : "The greedy miser: Learning under test-time budgets",
      "author" : [ "Zhixiang Xu", "Kilian Weinberger", "Olivier Chapelle" ],
      "venue" : "Technical report, preprint arXiv:1206.6451,",
      "citeRegEx" : "24",
      "shortCiteRegEx" : "24",
      "year" : 2012
    }, {
      "title" : "Doubly stochastic normalization for spectral clustering",
      "author" : [ "Ron Zass", "Amnon Shashua" ],
      "venue" : "In Advances in Neural Information Processing Systems,",
      "citeRegEx" : "25",
      "shortCiteRegEx" : "25",
      "year" : 2006
    }, {
      "title" : "Online convex programming and generalized infinitesimal gradient ascent",
      "author" : [ "Martin Zinkevich" ],
      "venue" : "In Proceedings of the International Conference on Machine Learning (ICML),",
      "citeRegEx" : "26",
      "shortCiteRegEx" : "26",
      "year" : 2003
    }, {
      "title" : "Regularization and variable selection via the elastic net",
      "author" : [ "H. Zou", "T. Hastie" ],
      "venue" : "Journal of the Royal Statistical Society. Series B, 67(2):301–320",
      "citeRegEx" : "27",
      "shortCiteRegEx" : null,
      "year" : 2005
    } ],
    "referenceMentions" : [ {
      "referenceID" : 1,
      "context" : "Online convex optimization (OCO) plays a key role in machine learning applications, such as adaptive routing in networks [2] and online display advertising [1].",
      "startOffset" : 121,
      "endOffset" : 124
    }, {
      "referenceID" : 0,
      "context" : "Online convex optimization (OCO) plays a key role in machine learning applications, such as adaptive routing in networks [2] and online display advertising [1].",
      "startOffset" : 156,
      "endOffset" : 159
    }, {
      "referenceID" : 25,
      "context" : "The problem was formalized in the seminal work of [26], which presents an online algorithm based on projected gradient descent [3] that guarantees a cumulative regret of O(T ) when the set X is convex and the loss functions are Lipschitz-continuous over X .",
      "startOffset" : 50,
      "endOffset" : 54
    }, {
      "referenceID" : 2,
      "context" : "The problem was formalized in the seminal work of [26], which presents an online algorithm based on projected gradient descent [3] that guarantees a cumulative regret of O(T ) when the set X is convex and the loss functions are Lipschitz-continuous over X .",
      "startOffset" : 127,
      "endOffset" : 130
    }, {
      "referenceID" : 10,
      "context" : "In [11] and [22], algorithms with logarithmic regret bounds were proposed for strongly convex loss functions.",
      "startOffset" : 3,
      "endOffset" : 7
    }, {
      "referenceID" : 21,
      "context" : "In [11] and [22], algorithms with logarithmic regret bounds were proposed for strongly convex loss functions.",
      "startOffset" : 12,
      "endOffset" : 16
    }, {
      "referenceID" : 17,
      "context" : "Another example is from wireless communications [18], where xt is a vector of power allocations across multiple devices, and the learner must satisfy average power consumption constraints per device.",
      "startOffset" : 48,
      "endOffset" : 52
    }, {
      "referenceID" : 14,
      "context" : "This class of problems was studied previously in [15, 16].",
      "startOffset" : 49,
      "endOffset" : 57
    }, {
      "referenceID" : 15,
      "context" : "This class of problems was studied previously in [15, 16].",
      "startOffset" : 49,
      "endOffset" : 57
    }, {
      "referenceID" : 15,
      "context" : "In particular, [16] considered online exponentially-weighted average in the case where the loss and constraints are linear, while [15] presented online algorithms based on projected subgradients and the mirror prox method [20].",
      "startOffset" : 15,
      "endOffset" : 19
    }, {
      "referenceID" : 14,
      "context" : "In particular, [16] considered online exponentially-weighted average in the case where the loss and constraints are linear, while [15] presented online algorithms based on projected subgradients and the mirror prox method [20].",
      "startOffset" : 130,
      "endOffset" : 134
    }, {
      "referenceID" : 19,
      "context" : "In particular, [16] considered online exponentially-weighted average in the case where the loss and constraints are linear, while [15] presented online algorithms based on projected subgradients and the mirror prox method [20].",
      "startOffset" : 222,
      "endOffset" : 226
    }, {
      "referenceID" : 14,
      "context" : "The analysis of [15] assumes the number of rounds is known ahead of time, which enables the authors to set the various constants in the algorithm that lead to the desired regret bounds.",
      "startOffset" : 16,
      "endOffset" : 20
    }, {
      "referenceID" : 16,
      "context" : "This is closely related to recent work in stochastic optimization that aims to minimize the number of expensive projection steps [17].",
      "startOffset" : 129,
      "endOffset" : 133
    }, {
      "referenceID" : 22,
      "context" : "The guarantees sought in our analysis have also similarities with the results obtained in the context of the online alternating direction method [23], where regret bounds are provided for the violation of equality constraints.",
      "startOffset" : 145,
      "endOffset" : 149
    }, {
      "referenceID" : 14,
      "context" : "Contributions: Building on the work of [15], we propose an algorithm based on a saddle-point formulation of the OCO problem with long-term constraints, which is adaptive (i.",
      "startOffset" : 39,
      "endOffset" : 43
    }, {
      "referenceID" : 14,
      "context" : "Also, the algorithm we derive allows us to interpolate between the regret bounds of O(T ) and O(T ) from [15] and the above bound of O(T ), depending on how we wish to trade off between the cumulative regret associated to the loss and the long-term constraints.",
      "startOffset" : 105,
      "endOffset" : 109
    }, {
      "referenceID" : 14,
      "context" : "In addition to our analysis of regret bounds, we empirically validate our algorithm by comparing it to the methods of [15] on a) the online estimation of doubly stochastic matrices and b) the online learning of sparse logistic regression based on the elastic net penalty [27].",
      "startOffset" : 118,
      "endOffset" : 122
    }, {
      "referenceID" : 26,
      "context" : "In addition to our analysis of regret bounds, we empirically validate our algorithm by comparing it to the methods of [15] on a) the online estimation of doubly stochastic matrices and b) the online learning of sparse logistic regression based on the elastic net penalty [27].",
      "startOffset" : 271,
      "endOffset" : 275
    }, {
      "referenceID" : 5,
      "context" : "As is typically assumed in online learning [6], the functions gj and ft shall be taken to be Lipschitz continuous.",
      "startOffset" : 43,
      "endOffset" : 46
    }, {
      "referenceID" : 14,
      "context" : "Finally, we note that the set of assumptions enumerated in this section are equivalent to the ones in [15].",
      "startOffset" : 102,
      "endOffset" : 106
    }, {
      "referenceID" : 14,
      "context" : "Following [15], we consider a saddle-point formulation of the optimization problem.",
      "startOffset" : 10,
      "endOffset" : 14
    }, {
      "referenceID" : 14,
      "context" : "It otherwise preserves the same properties as those of individual gj ’s (sub-differentiability, bounded (sub-)gradients and bounded values; see Proposition 6 in [15] or Section 2.",
      "startOffset" : 161,
      "endOffset" : 165
    }, {
      "referenceID" : 4,
      "context" : "3 in [5] for a proof).",
      "startOffset" : 5,
      "endOffset" : 8
    }, {
      "referenceID" : 20,
      "context" : "1 in [21]).",
      "startOffset" : 5,
      "endOffset" : 9
    }, {
      "referenceID" : 14,
      "context" : "We note at this point that in contrast to our method, [15] make use of a single θ that is constant in all rounds.",
      "startOffset" : 54,
      "endOffset" : 58
    }, {
      "referenceID" : 14,
      "context" : "• Initialize x1 = 0 and λ1 = 0 More precisely, in [15], θ is equal to the product of a constant step size times a constant scaling factor.",
      "startOffset" : 50,
      "endOffset" : 54
    }, {
      "referenceID" : 14,
      "context" : "The algorithm is in the same vein as the ones proposed in [15, 13], but it is adaptive.",
      "startOffset" : 58,
      "endOffset" : 66
    }, {
      "referenceID" : 12,
      "context" : "The algorithm is in the same vein as the ones proposed in [15, 13], but it is adaptive.",
      "startOffset" : 58,
      "endOffset" : 66
    }, {
      "referenceID" : 14,
      "context" : "which matches the mirror prox guarantees of [15] while being valid for general convex constraint sets X as opposed to just polyhedral constraint sets.",
      "startOffset" : 44,
      "endOffset" : 48
    }, {
      "referenceID" : 14,
      "context" : "1 in [15].",
      "startOffset" : 5,
      "endOffset" : 9
    }, {
      "referenceID" : 14,
      "context" : "The analysis is analogous to that developed in [15], which we provide below for selfcontainedness.",
      "startOffset" : 47,
      "endOffset" : 51
    }, {
      "referenceID" : 14,
      "context" : "In particular, the following lemma takes advantage of the fact that the partial function λ 7→ Lt(xt, λ) is not only concave as considered in [15], but strongly concave with parameter θt.",
      "startOffset" : 141,
      "endOffset" : 145
    }, {
      "referenceID" : 14,
      "context" : "2 from [15], where additional assumptions on the gradient of g can translate into no constraint violations.",
      "startOffset" : 7,
      "endOffset" : 11
    }, {
      "referenceID" : 14,
      "context" : "It can then be shown that (see Theorem 7 in [15]): ∣∣∣∑Tt=1 ft(x?)−∑Tt=1 ft(xγ)∣∣∣ ≤ Gr Tγ, (4)",
      "startOffset" : 44,
      "endOffset" : 48
    }, {
      "referenceID" : 16,
      "context" : "Examples where (3) holds include the positive semi-definite cone, as described in Section 4 of [17].",
      "startOffset" : 95,
      "endOffset" : 99
    }, {
      "referenceID" : 14,
      "context" : "This result extends Theorem 8 and Corollary 13 from [15] in that it holds for general convex domains X (as opposed to only polyhedral ones).",
      "startOffset" : 52,
      "endOffset" : 56
    }, {
      "referenceID" : 14,
      "context" : "We ran two sets of experiments to validate the regret bounds obtained for our adaptive algorithms for OCO with long-term constraints and compare to the algorithms proposed in [15].",
      "startOffset" : 175,
      "endOffset" : 179
    }, {
      "referenceID" : 11,
      "context" : "First, we examine the online estimation of doubly-stochastic matrices where the convex domain of interest X is polyhedral but whose projection operator is difficult to compute [12, 10].",
      "startOffset" : 176,
      "endOffset" : 184
    }, {
      "referenceID" : 9,
      "context" : "First, we examine the online estimation of doubly-stochastic matrices where the convex domain of interest X is polyhedral but whose projection operator is difficult to compute [12, 10].",
      "startOffset" : 176,
      "endOffset" : 184
    }, {
      "referenceID" : 26,
      "context" : "Second, we consider sparse online binary classification based on the elastic net penalty [27].",
      "startOffset" : 89,
      "endOffset" : 93
    }, {
      "referenceID" : 14,
      "context" : "The method of [15] that handles general convex domains X will be referred to as Convex OGD, while the mirror prox method analyzed in [15], which is only applicable to polyhedral domains, will be denoted by Convex mirror prox.",
      "startOffset" : 14,
      "endOffset" : 18
    }, {
      "referenceID" : 14,
      "context" : "The method of [15] that handles general convex domains X will be referred to as Convex OGD, while the mirror prox method analyzed in [15], which is only applicable to polyhedral domains, will be denoted by Convex mirror prox.",
      "startOffset" : 133,
      "endOffset" : 137
    }, {
      "referenceID" : 14,
      "context" : "The parameters of Convex OGD and Convex mirror prox are instantiated according to [15].",
      "startOffset" : 82,
      "endOffset" : 86
    }, {
      "referenceID" : 24,
      "context" : "1 Doubly-Stochastic Matrices Doubly-stochastic matrices appear in many machine learning and optimization problems, such as clustering applications [25] or learning permutations [12, 10].",
      "startOffset" : 147,
      "endOffset" : 151
    }, {
      "referenceID" : 11,
      "context" : "1 Doubly-Stochastic Matrices Doubly-stochastic matrices appear in many machine learning and optimization problems, such as clustering applications [25] or learning permutations [12, 10].",
      "startOffset" : 177,
      "endOffset" : 185
    }, {
      "referenceID" : 9,
      "context" : "1 Doubly-Stochastic Matrices Doubly-stochastic matrices appear in many machine learning and optimization problems, such as clustering applications [25] or learning permutations [12, 10].",
      "startOffset" : 177,
      "endOffset" : 185
    }, {
      "referenceID" : 3,
      "context" : "This problem can easily be mapped to OCO setting by assuming that the sequence {Y}t=1 is generated by random permutation matrices which are known to constitute the extreme points of the set of doublystochastic matrices [4].",
      "startOffset" : 219,
      "endOffset" : 222
    }, {
      "referenceID" : 7,
      "context" : "The offline solutions of (5) required for various t ∈ {1, · · · , T} to compute the regret are obtained using CVXPY [8].",
      "startOffset" : 116,
      "endOffset" : 119
    }, {
      "referenceID" : 14,
      "context" : "We surmise that this may be due to the fact that the guarantees of Convex mirror prox proved in [15] only hold for very large T .",
      "startOffset" : 96,
      "endOffset" : 100
    }, {
      "referenceID" : 14,
      "context" : "Theorem 12 from [15] requires T ≥ 164(m+1), which translates into T > 10 in our setting.",
      "startOffset" : 16,
      "endOffset" : 20
    }, {
      "referenceID" : 23,
      "context" : ", in the context of learning predictors with low-latency [24].",
      "startOffset" : 57,
      "endOffset" : 61
    }, {
      "referenceID" : 6,
      "context" : "Moreover, and in order to best display cumulative regret, we compute offline solutions of (6) for various t ∈ {1, · · · , T} thanks to an implementation of [7].",
      "startOffset" : 156,
      "endOffset" : 159
    }, {
      "referenceID" : 18,
      "context" : "Following the ideas developed in [19, 9], we could analyze the regret guarantees of our algorithm when there is a vector of step sizes ηt that is given by a diagonal matrix Diag(ηt) ∈ Rd×d, updating adaptively and separately each coordinate of x.",
      "startOffset" : 33,
      "endOffset" : 40
    }, {
      "referenceID" : 8,
      "context" : "Following the ideas developed in [19, 9], we could analyze the regret guarantees of our algorithm when there is a vector of step sizes ηt that is given by a diagonal matrix Diag(ηt) ∈ Rd×d, updating adaptively and separately each coordinate of x.",
      "startOffset" : 33,
      "endOffset" : 40
    }, {
      "referenceID" : 13,
      "context" : "Moreover, the maximization with respect to λ in the last step of Lemma 4 introduces the Moreau envelope [14] of the Fenchel conjugate of φ, namely",
      "startOffset" : 104,
      "endOffset" : 108
    } ],
    "year" : 2015,
    "abstractText" : "We present an adaptive online gradient descent algorithm to solve online convex optimization problems with long-term constraints, which are constraints that need to be satisfied when accumulated over a finite number of rounds T , but can be violated in intermediate rounds. For some user-defined trade-off parameter β ∈ (0, 1), the proposed algorithm achieves cumulative regret bounds ofO(Tmax{β,1−β}) andO(T 1−β/2) for the loss and the constraint violations respectively. Our results hold for convex losses and can handle arbitrary convex constraints without requiring knowledge of the number of rounds in advance. Our contributions improve over the best known cumulative regret bounds by Mahdavi, et al. (2012) that are respectively O(T ) and O(T ) for general convex domains, and respectively O(T ) andO(T ) when further restricting to polyhedral domains. We supplement the analysis with experiments validating the performance of our algorithm in practice.",
    "creator" : "LaTeX with hyperref package"
  }
}