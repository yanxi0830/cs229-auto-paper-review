{
  "name" : "1605.08283.pdf",
  "metadata" : {
    "source" : "META",
    "title" : "Discrete Deep Feature Extraction: A Theory and New Architectures",
    "authors" : [ "Thomas Wiatowski", "Michael Tschannen", "Aleksandar Stanić", "Philipp Grohs", "Helmut Bölcskei" ],
    "emails" : [ "WITHOMAS@NARI.EE.ETHZ.CH", "MICHAELT@NARI.EE.ETHZ.CH", "ASTANIC@STUDENT.ETHZ.CH", "PHILIPP.GROHS@UNIVIE.AC.AT", "BOELCSKEI@NARI.EE.ETHZ.CH" ],
    "sections" : [ {
      "heading" : "1. Introduction",
      "text" : "Deep convolutional neural networks (DCNNs) have proven tremendously successful in a wide range of machine learning tasks (Bengio et al., 2013; LeCun et al., 2015). Such networks are composed of multiple layers, each of which computes convolutional transforms followed by the application of non-linearities and pooling operators.\nDCNNs are typically distinguished according to (i) whether the filters employed are learned (in a supervised (LeCun et al., 1998; Huang & LeCun, 2006; Jarrett et al., 2009) or unsupervised (Ranzato et al., 2006; 2007; Jar-\nProceedings of the 33 rd International Conference on Machine Learning, New York, NY, USA, 2016. JMLR: W&CP volume 48. Copyright 2016 by the author(s).\nrett et al., 2009) fashion) or pre-specified (and structured, such as, e.g., wavelets (Serre et al., 2005; Mutch & Lowe, 2006; Mallat, 2012), or unstructured, such as random filters (Ranzato et al., 2007; Jarrett et al., 2009)), (ii) the non-linearities used (e.g., logistic sigmoid, hyperbolic tangent, modulus, or rectified linear unit), and (iii) the pooling operator employed (e.g., sub-sampling, average pooling, or max-pooling). While a given choice of filters, nonlinearities, and pooling operators will lead to vastly different performance results across datasets, it is remarkable that the overall DCNN architecture allows for impressive classification results across an extraordinarily broad range of applications. It is therefore of significant interest to understand the mechanisms underlying this universality.\nFirst steps towards addressing this question and developing a mathematical theory of DCNNs for feature extraction were made—for the continuous-time case—in (Mallat, 2012; Wiatowski & Bölcskei, 2015). Specifically, (Mallat, 2012) analyzed so-called scattering networks, where signals are propagated through layers that employ directional wavelet filters and modulus non-linearities but no intra-layer pooling. The resulting wavelet-modulus feature extractor is horizontally (i.e., in every network layer) translation-invariant (accomplished by letting the wavelet scale parameter go to infinity) and deformationstable, both properties of significance in practical feature extraction applications. Recently, (Wiatowski & Bölcskei, 2015) considered Mallat-type networks with arbitrary filters (that may be learned or pre-specified), general Lipschitz-continuous non-linearities (e.g., rectified linear unit, shifted logistic sigmoid, hyperbolic tangent, and the modulus function), and a continuous-time pooling operator that amounts to a dilation. The essence of the results in (Wiatowski & Bölcskei, 2015) is that vertical (i.e., asymptotically in the network depth) translation invariance and Lipschitz continuity of the feature extractor are induced by the network structure per se rather than the specific choice of filters and non-linearities. For band-limited ar X iv :1 60 5.\n08 28\n3v 1\n[ cs\n.L G\n] 2\n6 M\nay 2\nsignals (Wiatowski & Bölcskei, 2015), cartoon functions (Grohs et al., 2016), and Lipschitz-continuous functions (Grohs et al., 2016), Lipschitz continuity of the feature extractor automatically leads to bounds on deformation sensitivity.\nA discrete-time setup for wavelet-modulus scattering networks (referred to as ScatNets) was considered in (Bruna & Mallat, 2013).\nContributions. The purpose of the present paper is to develop a theory of discrete DCNNs for feature extraction. Specifically, we follow the philosophy put forward in (Wiatowski & Bölcskei, 2015; Grohs et al., 2016). Our theory incorporates general filters, Lipschitz non-linearities, and Lipschitz pooling operators. In addition, we introduce and analyze a wide variety of new network architectures which build the feature vector from subsets of the layers. This leads us to the notions of local and global feature vector properties with globality pertaining to characteristics brought out by the union of features across all network layers, and locality identifying attributes made explicit in individual layers.\nBesides providing analytical performance results of general validity, we also investigate how certain structural properties of the input signal are reflected in the corresponding feature vectors. Specifically, we analyze the (local and global) deformation and translation sensitivity properties of feature vectors corresponding to sampled cartoon functions (Donoho, 2001). For simplicity of exposition, we focus on the 1-D case throughout the paper, noting that the extension to the higher-dimensional case does not pose any significant difficulties.\nOur theoretical results are complemented by extensive numerical studies on facial landmark detection and handwritten digit classification. Specifically, we elucidate the role of local feature vector properties through a feature relevance study.\nNotation. The complex conjugate of z ∈ C is denoted by z. We write Re(z) for the real, and Im(z) for the imaginary part of z ∈ C. We let HN := {f : Z → C | f [n] = f [n+ N ], ∀n ∈ Z} be the set of N -periodic discrete-time signals1, and set IN := {0, 1, . . . , N − 1}. The delta function δ ∈ HN is δ[n] := 1, for n = kN , k ∈ Z, and δ[n] := 0, else. For f, g ∈ HN , we set 〈f, g〉 := ∑ k∈IN f [k]g[k],\n‖f‖1 := ∑ n∈IN |f [n]|, ‖f‖2 := ( ∑ n∈IN |f [n]|\n2)1/2, and ‖f‖∞ := supn∈IN |f [n]|. We denote the discrete Fourier transform (DFT) of f ∈ HN by f̂ [k] :=∑ n∈IN f [n]e\n−2πikn/N . The circular convolution of f ∈ HN and g ∈ HN is (f ∗ g)[n] := ∑ k∈IN f [k]g[n − k].\n1We note that HN is isometrically isomorphic to CN , but we prefer to work with HN for the sake of expositional simplicity.\nWe write (Tmf)[n] := f [n − m], m ∈ Z, for the cyclic translation operator. The supremum norm of a continuoustime function c : R → C is ‖c‖∞ := supx∈R |c(x)|. The indicator function of an interval [a, b] ⊆ R is defined as 1[a,b](x) := 1, for x ∈ [a, b], and 1[a,b](x) := 0, for x ∈ R\\[a, b]. The cardinality of the set A is denoted by card(A)."
    }, {
      "heading" : "2. The basic building block",
      "text" : "The basic building block of a DCNN, described in this section, consists of a convolutional transform followed by a non-linearity and a pooling operation."
    }, {
      "heading" : "2.1. Convolutional transform",
      "text" : "A convolutional transform is made up of a set of filters ΨΛ = {gλ}λ∈Λ. The finite index set Λ can be thought of as labeling a collection of scales, directions, or frequency-shifts. The filters gλ—referred to as atoms— may be learned (in a supervised or unsupervised fashion), pre-specified and unstructured such as random filters, or pre-specified and structured such as wavelets, curvelets, shearlets, or Weyl-Heisenberg functions. Definition 1. Let Λ be a finite index set. The collection ΨΛ = {gλ}λ∈Λ ⊆ HN is called a convolutional set with Bessel bound B ≥ 0 if∑\nλ∈Λ\n‖f ∗ gλ‖22 ≤ B‖f‖22, ∀f ∈ HN . (1)\nCondition (1) is equivalent to∑ λ∈Λ |ĝλ[k]|2 ≤ B, ∀k ∈ IN , (2) and hence, every finite set {gλ}λ∈Λ is a convolutional set with Bessel bound B∗ := maxk∈IN ∑ λ∈Λ |ĝλ[k]|2. As\n(f ∗ gλ)[n] = 〈 f, gλ[n− ·] 〉 , n ∈ IN , λ ∈ Λ, the outputs of the filters gλ may be interpreted as inner products of the input signal f with translates of the atoms gλ. Frame theory (Daubechies, 1992) therefore tells us that the existence of a lower bound A > 0 in (2) according to\nA ≤ ∑ λ∈Λ |ĝλ[k]|2 ≤ B, ∀k ∈ IN , (3)\nimplies that every element in HN can be written as a linear combination of elements in the set{ gλ[n− ·] } n∈IN ,λ∈Λ (or in more technical parlance, the\nset { gλ[n− ·] } n∈IN ,λ∈Λ\nis complete for HN ). The absence of a lower bound A > 0 may therefore result in ΨΛ failing to extract essential features of the signal f . We note, however, that even learned filters are likely to satisfy (3) as all that is needed is, for each k ∈ IN , to have ĝλ[k] 6= 0 for at least one λ ∈ Λ. As we shall see below, the existence of a lower bound A > 0 in (3) is, however, not needed for our theory to apply.\nExamples of structured convolutional sets withA = B = 1 include, in the 1-D case, wavelets (Daubechies, 1992) and Weyl-Heisenberg functions (Bölcskei & Hlawatsch, 1997), and in the 2-D case, tensorized wavelets (Mallat, 2009), curvelets (Candès et al., 2006), and shearlets (Kutyniok & Labate, 2012a)."
    }, {
      "heading" : "2.2. Non-linearities",
      "text" : "The non-linearities ρ : C → C we consider are all pointwise and satisfy the Lipschitz property |ρ(x) − ρ(y)| ≤ L|x− y|, ∀x, y ∈ C, for some L > 0."
    }, {
      "heading" : "2.2.1. EXAMPLE NON-LINEARITIES",
      "text" : "• The hyperbolic tangent non-linearity, defined as ρ(x) = tanh(Re(x)) + i tanh(Im(x)), where tanh(x) = e\nx−e−x ex+e−x , has Lipschitz constant L = 2.\n• The rectified linear unit non-linearity is given by ρ(x) = max{0,Re(x)} + imax{0, Im(x)}, and has Lipschitz constant L = 2.\n• The modulus non-linearity is ρ(x) = |x|, and has Lipschitz constant L = 1.\n• The logistic sigmoid non-linearity is defined as ρ(x) = sig(Re(x)) + i sig(Im(x)), where sig(x) =\n1 1+e−x , and has Lipschitz constant L = 1/2.\nWe refer the reader to (Wiatowski & Bölcskei, 2015) for proofs of the Lipschitz properties of these example nonlinearities."
    }, {
      "heading" : "2.3. Pooling operators",
      "text" : "The essence of pooling is to reduce signal dimensionality in the individual network layers and to ensure robustness of the feature vector w.r.t. deformations and translations.\nThe theory developed in this paper applies to general pooling operators P : HN → HN/S , where N,S ∈ N with N/S ∈ N, that satisfy the Lipschitz property ‖Pf − Pg‖2 ≤ R‖f − g‖, ∀f, g ∈ HN , for some R > 0. The integer S will be referred to as pooling factor, and determines the “size” of the neighborhood values are combined in."
    }, {
      "heading" : "2.3.1. EXAMPLE POOLING OPERATORS",
      "text" : "• Sub-sampling, defined as P : HN → HN/S , (Pf)[n] = f [Sn], n ∈ IN/S , has Lipschitz constant R = 1. For S = 1, P is the identity operator which amounts to “no pooling”.\n• Averaging, defined as P : HN → HN/S , (Pf)[n] =∑Sn+S−1 k=Sn αk−Snf [k], n ∈ IN/S , has Lipschitz con-\nstant R = S1/2 maxk∈{0,...,S−1} |αk|. The weights\n{αk}S−1k=0 can be learned (LeCun et al., 1998) or prespecified (Pinto et al., 2008) (e.g., uniform pooling corresponds to αk = 1S , for k ∈ {0, . . . , S − 1}).\n• Maximization, defined as P : HN → HN/S , (Pf)[n] = maxk∈{Sn,...,Sn+S−1} |f [k]|, n ∈ IN/S , has Lipschitz constant R = 1.\nWe refer to Appendix B in the Supplement for proofs of the Lipschitz property of these three example pooling operators along with the derivations of the corresponding Lipschitz constants."
    }, {
      "heading" : "3. The network architecture",
      "text" : "The architecture we consider is flexible in the following sense. In each layer, we can feed into the feature vector either the signals propagated down to that layer (i.e., the feature maps), filtered versions thereof, or we can decide not to have that layer contribute to the feature vector.\nThe basic building blocks of our network are the triplets (Ψd, ρd, Pd) of filters, non-linearities, and pooling operators associated with the d-th network layer and referred to as modules. We emphasize that these triplets are allowed to be different across layers.\nDefinition 2. For network layers d, 1 ≤ d ≤ D, let Ψd = {gλd}λd∈Λd ⊆ HNd be a convolutional set, ρd : C → C a point-wise Lipschitz-continuous non-linearity, and Pd : HNd → HNd+1 a Lipschitz-continuous pooling operator withNd+1 = NdSd , where Sd ∈ N denotes the pooling factor in the d-th layer. Then, the sequence of triplets\nΩ := ( (Ψd, ρd, Pd) )\n1≤d≤D\nis called a module-sequence.\nNote that the dimensions of the spaces HNd satisfy N1 ≥ N2 ≥ . . . ≥ ND. Associated with the module (Ψd, ρd, Pd), we define the operator\n(Ud[λd]f) := Pd(ρd(f ∗ gλd)) (4)\nand extend it to paths on index sets\nq = (λ1, λ2, . . . , λd) ∈ Λ1 × Λ2 × · · · × Λd := Λd1,\nfor 1 ≤ d ≤ D, according to\nU [q]f =U [(λ1, λ2, . . . , λd)]f\n:=Ud[λd] · · ·U2[λ2]U1[λ1]f. (5)\nFor the empty path e := ∅ we set Λ01 := {e} and let U [e]f := f , for all f ∈ HN1 .\nThe network output in the d-th layer is given by (U [q]f) ∗ χd, q ∈ Λd1, where χd ∈ HNd+1 is referred to as outputgenerating atom. Specifically, we let χd be (i) the delta\nU [e]f = f\nU [ λ\n(j) 1 ] f(\nU [ λ\n(j) 1 ] f ) ∗ χ1\nU [( λ\n(j) 1 , λ (l) 2\n)] f\n( U [( λ\n(j) 1 , λ (l) 2 )] f ) ∗ χ2\nU [( λ\n(j) 1 , λ (l) 2 , λ (m) 3\n)] f\nU [ λ\n(p) 1 ] f(\nU [ λ\n(p) 1 ] f ) ∗ χ1\nU [( λ\n(p) 1 , λ (r) 2\n)] f\n( U [( λ\n(p) 1 , λ (r) 2 )] f ) ∗ χ2\nU [( λ\n(p) 1 , λ (r) 2 , λ (s) 3\n)] f\nf ∗ χ0\nFigure 1. Network architecture underlying the feature extractor (6). The index λ(k)d corresponds to the k-th atom gλ(k) d of the convolutional set Ψd associated with the d-th network layer. The function χd is the output-generating atom of the d-th layer. The root of the network corresponds to d = 0.\nfunction δ[n], n ∈ INd+1 , if we want the output to equal the unfiltered features U [q]f , q ∈ Λd1, propagated down to layer d, or (ii) any other signal of length Nd+1, or (iii) χd = 0 if we do not want layer d to contribute to the feature vector. From now on we formally add χd to the set Ψd+1 = {gλd+1}λd+1∈Λd+1 , noting that {gλd+1}λd+1∈Λd+1 ∪ {χd} forms a convolutional set Ψ′d+1 with Bessel boundB ′ d+1 ≤ Bd+1 + maxk∈INd+1 |χ̂d[k]| 2. We emphasize that the atoms of the augmented set {gλd+1}λd+1∈Λd+1 ∪ {χd} are employed across two consecutive layers in the sense of χd generating the output in the d-th layer according to (U [q]f) ∗ χd, q ∈ Λd1, and the remaining atoms {gλd+1}λd+1∈Λd+1 propagating the signals U [q]f , q ∈ Λd1, from the d-th layer down to the (d + 1)-st layer according to (4), see Fig. 1. With slight abuse of notation, we shall henceforth write Ψd for Ψ′d and Bd for B ′ d as well.\nWe are now ready to define the feature extractor ΦΩ based on the module-sequence Ω. Definition 3. Let Ω = ( (Ψd, ρd, Pd) ) 1≤d≤D be a modulesequence. The feature extractor ΦΩ based on Ω maps f ∈ HN1 to its features\nΦΩ(f) := D−1⋃ d=0 ΦdΩ(f), (6)\nwhere ΦdΩ(f) := {(U [q]f) ∗ χd}q∈Λd1 is the collection of features generated in the d-th network layer (see Fig. 1).\nThe dimension of the feature vector ΦΩ(f) is given by ε0N1 + ∑D−1 d=1 εdNd+1 (∏d k=1 card(Λk) ) , where εd = 1, if an output is generated (either filtered or unfiltered) in the d-th network layer, and εd = 0, else. As Nd+1 = NdSd = · · · = N1S1···Sd , for d ≥ 1, the dimension of the overall feature vector is determined by the pooling factors Sk and, of course, the layers that contribute to the feature vector. Remark 1. It was argued in (Bruna & Mallat, 2013; Andén & Mallat, 2014; Oyallon & Mallat, 2014) that the\nfeatures Φ1Ω(f) when generated by wavelet filters, modulus non-linearities, without intra-layer pooling, and by employing output-generating atoms with low-pass characteristics, describe mel frequency cepstral coefficients (Davis & Mermelstein, 1980) in 1-D, and SIFT-descriptors (Lowe, 2004; Tola et al., 2010) in 2-D."
    }, {
      "heading" : "4. Sampled cartoon functions",
      "text" : "While our main results hold for general signals f , we can provide a refined analysis for the class of sampled cartoon functions. This allows to understand how certain structural properties of the input signal, such as the presence of sharp edges, are reflected in the feature vector. Cartoon functions—as introduced in continuous time in (Donoho, 2001)—are piecewise “smooth” apart from curved discontinuities along Lipschitz-continuous hypersurfaces. They hence provide a good model for natural images (see Fig. 2, left) such as those in the Caltech-256 (Griffin et al., 2007) and the CIFAR-100 (Krizhevsky, 2009) datasets, for images of handwritten digits (LeCun & Cortes, 1998) (see Fig. 2, middle), and for images of geometric objects of different shapes, sizes, and colors as in the Baby AI School dataset2.\nBounds on deformation sensitivity for cartoon functions in continuous-time DCNNs were recently reported in (Grohs et al., 2016). Here, we analyze deformation sensitivity for sampled cartoon functions passed through discrete DCNNs.\nDefinition 4. The function c : R → C is referred to as a cartoon function if it can be written as c = c1 + 1[a,b]c2, where [a, b] ⊆ [0, 1] is a closed interval, and ci : R → C, i = 1, 2, satisfies the Lipschitz property\n|ci(x)− ci(y)| ≤ C|x− y|, ∀x, y ∈ R,\nfor some C > 0. Furthermore, we denote by\nCKCART := {c1 + 1[a,b]c2 | |ci(x)− ci(y)| ≤ K|x− y|, ∀x, y ∈ R, i = 1, 2, ‖c2‖∞ ≤ K}\nthe class of cartoon functions of variation K > 0, and by CN,KCART := { f [n] = c(n/N), n ∈ {0, 1, . . . , N − 1} ∣∣∣ c = (c1 + 1[a,b]c2) ∈ CKCART with\na, b /∈ { 0, 1\nN , . . . , N − 1 N }} the class of sampled cartoon functions of length N and variation K > 0.\nWe note that excluding the boundary points a, b of the interval [a, b] from being sampling points n/N in the def-\n2http://www.iro.umontreal.ca/%7Elisa/ twiki/bin/view.cgi/Public/BabyAISchool\ninition of CN,KCART is of conceptual importance (see Remark D.1 in the Supplement). Moreover, our results can easily be generalized to classes CN,KCART consisting of functions f [n] = c(n/N) with c containing multiple “1-D edges” (i.e., multiple discontinuity points) according to c = c1 + ∑L l=1 1[al,bl]c2 with ∩Ll=1[al, bl] = ∅. We also note that CN,KCART reduces to the class of sampled Lipschitzcontinuous functions upon setting c2 = 0.\nA sampled cartoon function in 2-D models, e.g., an image acquired by a digital camera (see Fig. 2, middle); in 1- D, f ∈ CN,KCART can be thought of as the pixels in a row or column of this image (see Fig. 2 right, which shows a cartoon function with 6 discontinuity points)."
    }, {
      "heading" : "5. Analytical results",
      "text" : "We analyze global and local feature vector properties with globality pertaining to characteristics brought out by the union of features across all network layers, and locality identifying attributes made explicit in individual layers."
    }, {
      "heading" : "5.1. Global properties",
      "text" : "Theorem 1. Let Ω = ( (Ψd, ρd, Pd) ) 1≤d≤D be a modulesequence. Assume that the Bessel bounds Bd > 0, the Lipschitz constants Ld > 0 of the non-linearities ρd, and the Lipschitz constants Rd > 0 of the pooling operators Pd satisfy\nmax 1≤d≤D\nmax{Bd, BdR2dL2d} ≤ 1. (7)\ni) The feature extractor ΦΩ is Lipschitz-continuous with Lipschitz constant LΩ = 1, i.e.,\n|||ΦΩ(f)− ΦΩ(h)||| ≤ ‖f − h‖2, (8)\nfor all f, h ∈ HN1 , where the feature space norm is defined as\n|||ΦΩ(f)|||2 := D−1∑ d=0 ∑ q∈Λd1 ||(U [q]f) ∗ χd||22. (9)\nii) If, in addition to (7), for all d ∈ {1, . . . , D − 1} the non-linearities ρd and the pooling operators Pd sa-\ntisfy ρd(0) = 0 and Pd(0) = 0 (as all non-linearities and pooling operators in Sections 2.2.1 and 2.3.1, apart from the logistic sigmoid non-linearity, do), then\n|||ΦΩ(f)||| ≤ ‖f‖2, ∀f ∈ HN1 . (10) iii) For every variation K > 0 and deformation Fτ of the\nform\n(Fτf)[n] : = c(n/N1 − τ(n/N1)), n ∈ IN1 , (11)\nwhere τ : R → [−1, 1], the deformation sensitivity is bounded according to\n|||ΦΩ(Fτf)− ΦΩ(f)||| ≤ 4KN1/21 ‖τ‖1/2∞ , (12)\nfor all f ∈ CN1,KCART.\nProof. See Appendix C in the Supplement.\nThe Lipschitz continuity (8) guarantees that pairwise distances of input signals do not increase through feature extraction. As an immediate implication of the Lipschitz continuity we get robustness of the feature extractor w.r.t. additive bounded noise η ∈ HN1 in the sense of\n|||ΦΩ(f + η)− ΦΩ(f)||| ≤ ‖η‖2, for all f ∈ HN1 . Remark 2. As detailed in the proof of Theorem 1, the Lipschitz continuity (8) combined with the deformation sensitivity bound (see Proposition D.1 in the Supplement) for the signal class under consideration, namely sampled cartoon functions, establishes the deformation sensitivity bound (12) for the feature extractor. This insight has important practical ramifications as it shows that whenever we have deformation sensitivity bounds for a signal class, we automatically get deformation sensitivity guarantees for the corresponding feature extractor.\nFrom (12) we can deduce a statement on the sensitivity of ΦΩ w.r.t. translations on R. To this end, we first note that setting τt(x) = t, x ∈ R, for t ∈ [−1, 1], (11) becomes\n(Fτtf)[n] = c(n/N1 − t), n ∈ IN1 .\nParticularizing (12) accordingly, we obtain\n|||ΦΩ(Fτtf)− ΦΩ(f)||| ≤ 4KN 1/2 1 |t|1/2, (13)\nwhich shows that small translations |t| of the underlying analog signal c(x), x ∈ R, lead to small changes in the feature vector obtained by passing the resulting sampled signal through a discrete DCNN. We shall say that (13) is a translation sensitivity bound. Analyzing the impact of deformations and translations over R on the discrete feature vector generated by the sampled analog signal closely models real-world phenomena (e.g., the jittered acquisition of an analog signal with a digital camera, where different values of N1 in (11) correspond to different camera resolutions).\nWe note that, while iii) in Theorem 1 is specific to cartoon functions, i) and ii) apply to all signals in HN1 .\nThe strength of the results in Theorem 1 derives itself from the fact that condition (7) on the underlying modulesequence Ω is easily met in practice. To see this, we first note that Bd is determined by the convolutional set Ψd, Ld by the non-linearity ρd, andRd by the pooling operator Pd. Condition (7) is met if\nBd ≤ min{1, R−2d L −2 d }, ∀ d ∈ {1, 2, . . . , D}, (14)\nwhich, if not satisfied by default, can be enforced simply by normalizing the elements in Ψd. Specifically, for Cd := max{Bd, R2dL2d} the set Ψ̃d := {C −1/2 d gλd}λd∈Λd has Bessel bound B̃d = BdCd and hence satisfies (14). While this normalization does not have an impact on the results in Theorem 1, there exists, however, a tradeoff between energy preservation and deformation (respectively translation) sensitivity in ΦdΩ as detailed in the next section."
    }, {
      "heading" : "5.2. Local properties",
      "text" : "Theorem 2. Let Ω = ( (Ψd, ρd, Pd) ) 1≤d≤D be a modulesequence with corresponding Bessel bounds Bd > 0, Lipschitz constants Ld > 0 of the non-linearities ρd, Lipschitz constants Rd > 0 of the pooling operators Pd, and outputgenerating atoms χd. Let further L0Ω := ‖χ0‖1 and 3\nLdΩ := ‖χd‖1 ( d∏ k=1 BkL 2 kR 2 k )1/2 , d ≥ 1. (15) i) The features generated in the d-th network layer are Lipschitz-continuous with Lipschitz constant LdΩ, i.e.,\n|||ΦdΩ(f)− ΦdΩ(h)||| ≤ LdΩ‖f − h‖2, (16)\nfor all f, h ∈ HN1 , where |||ΦdΩ(f)|||2 :=∑ q∈Λd1\n||(U [q]f) ∗ χd||22. ii) If the non-linearities ρk and the pooling operators Pk\nsatisfy ρk(0) = 0 and Pk(0) = 0, respectively, for all k ∈ {1, . . . , d}, then\n|||ΦdΩ(f)||| ≤ LdΩ‖f‖2, ∀f ∈ HN1 . (17)\niii) For all K > 0 and all τ : R → [−1, 1], the features generated in the d-th network layer satisfy\n|||ΦdΩ(Fτf)− ΦdΩ(f)||| ≤ 4LdΩKN1/2‖τ‖1/2∞ , (18)\nfor all f ∈ CN1,KCART, where Fτf is defined in (11). iv) If the module-sequence employs sub-sampling, ave-\nrage pooling, or max-pooling with corresponding pooling factors Sd ∈ N, then\nΦdΩ(Tmf) = T mS1...Sd ΦdΩ(f), (19)\n3We note that ‖χd‖1 in (15) can be upper-bounded (and hence substituted) by Bd+1, see Remark E.1 in the Supplement.\nfor all f ∈ HN1 and all m ∈ Z with mS1...Sd ∈ Z. Here, TmΦdΩ(f) refers to element-wise application of Tm, i.e., TmΦdΩ(f) := {Tmh | ∀h ∈ ΦdΩ(f)}.\nProof. See Appendix E in the Supplement.\nOne may be tempted to infer the global results (8), (10), and (12) in Theorem 1 from the corresponding local results in Theorem 2, e.g., the energy bound in (10) from (17)\naccording to |||ΦΩ(f)||| = (∑D−1 d=0 |||ΦdΩ(f)|||2 )1/2\n≤ √ D‖f‖2, where we employed LdΩ ≤ 1 owing to (7). This would, however, lead to the “global” Lipschitz constant LΩ = 1 in (8), (10), and (12) to be replaced by LΩ = √ D and thereby render the corresponding results much weaker.\nAgain, we emphasize that, while iii) in Theorem 2 is specific to cartoon functions, i), ii), and iv) apply to all signals in HN1 .\nFor a fixed network layer d, the “local” Lipschitz constant LdΩ determines the noise sensitivity of the features Φ d Ω(f) according to\n|||ΦdΩ(f + η)− ΦdΩ(f)||| ≤ LdΩ‖η‖2, (20)\nwhere (20) follows from (16). Moreover, LdΩ via (18) also quantifies the impact of deformations (or translations when τt(x) = t, x ∈ R, for t ∈ [−1, 1]) on the feature vector. In practice, it may be desirable to have the features ΦdΩ become more robust to additive noise and less deformationsensitive (respectively, translation-sensitive) as we progress deeper into the network. Formally, this vertical sensitivity reduction can be induced by ensuring that Ld+1Ω < L d Ω. Thanks to LdΩ = ‖χd‖1B1/2d LdRd ‖χd−1‖1 L d−1 Ω , this can be accomplished by choosing the module-sequence such that ‖χd‖1B1/2d LdRd < ‖χd−1‖1. Note, however, that owing to (17) this will also reduce the signal energy contained in the features ΦdΩ(f). We therefore have a tradeoff between deformation (respectively translation) sensitivity and energy preservation. Having control over this tradeoff through the choice of the module-sequence Ω may come in handy in practice.\nFor average pooling with uniform weights αdk = 1 Sd , k = 0, . . . , Sd − 1 (noting that the corresponding Lipschitz constant is Rd = S −1/2 d , see Section 2.3.1), we\nget LdΩ = ‖χd‖1 (∏d k=1 BkL 2 k\nSk\n)1/2 , which illustrates that\npooling can have an impact on the sensitivity and energy properties of ΦdΩ.\nWe finally turn to interpreting the translation covariance result (19). Owing to the condition mS1...Sd ∈ Z, we get translation covariance only on the rough grid induced by the product of the pooling factors. In the absence of pooling,\ni.e., Sk = 1, for k ∈ {1, . . . , d}, we obtain translation covariance w.r.t. the fine grid the input signal f ∈ HN1 lives on.\nRemark 3. We note that ScatNets (Bruna & Mallat, 2013) are translation-covariant on the rough grid induced by the factor 2J corresponding to the coarsest wavelet scale. Our result in (19) is hence in the spirit of (Bruna & Mallat, 2013) with the difference that the grid in our case is induced by the pooling factors Sk.\n6. Experiments4\nWe consider the problem of handwritten digit classification and evaluate the performance of the feature extractor ΦΩ in combination with a support vector machine (SVM). The results we obtain are competitive with the state-of-the-art in the literature. The second line of experiments we perform assesses the importance of the features extracted by ΦΩ in facial landmark detection and in handwritten digit classification, using random forests (RF) for regression and classification, respectively. Our results are based on a DCNN with different non-linearities and pooling operators, and with tensorized (i.e., separable) wavelets as filters, sensitive to 3 directions (horizontal, vertical, and diagonal). Furthermore, we generate outputs in all layers through low-pass filtering. Circular convolutions with the 1-D filters underlying the tensorized wavelets are efficiently implemented using the algorithme à trous (Holschneider et al., 1989).\nTo reduce the dimension of the feature vector, we compute features along frequency decreasing paths only (Bruna & Mallat, 2013), i.e., for every node U [q]f , q ∈ Λd−11 , we retain only those child nodes Ud[λd]U [q]f = Pd ( ρd((U [q]f)∗gλd) ) that correspond to wavelets gλd with scales larger than the maximum scale of the wavelets used to get U [q]f . We refer to (Bruna & Mallat, 2013) for a detailed justification of this approach for scattering networks."
    }, {
      "heading" : "6.1. Handwritten digit classification",
      "text" : "We use the MNIST dataset of handwritten digits (LeCun & Cortes, 1998) which comprises 60,000 training and 10,000 test images of size 28×28. We setD = 3, and compare different network configurations, each defined by a single module (i.e., we use the same filters, non-linearity, and pooling operator in all layers). Specifically, we consider Haar wavelets and reverse biorthogonal 2.2 (RBIO2.2) wavelets (Mallat, 2009), both with J = 3 scales, the non-linearities described in Section 2.2.1, and the pooling operators described in Section 2.3.1 (with S1 = 1 and S2 = 2). We use a SVM with radial basis function (RBF) kernel for classification. To reduce the dimension of the feature vec-\n4Code available at http://www.nari.ee.ethz.ch/ commth/research/\ntors from 18,424 (or 50,176, for the configurations without pooling) down to 1000, we employ the supervised orthogonal least squares feature selection procedure described in (Oyallon & Mallat, 2014). The penalty parameter of the SVM and the localization parameter of the RBF kernel are selected via 10-fold cross-validation for each combination of wavelet filter, non-linearity, and pooling operator.\nTable 1 shows the resulting classification errors on the test set (obtained for the SVM trained on the full training set). Configurations employing RBIO2.2 wavelets tend to yield a marginally lower classification error than those using Haar wavelets. For the tanh and LogSig non-linearities, max-pooling leads to a considerably lower classification error than other pooling operators. The configurations involving the modulus and ReLU non-linearities achieve classification accuracy competitive with the state-of-theart (Bruna & Mallat, 2013) (class. err.: 0.43%), which is based on directional non-separable wavelets with 6 directions without intra-layer pooling. This is interesting as the separable wavelet filters employed here can be implemented more efficiently."
    }, {
      "heading" : "6.2. Feature importance evaluation",
      "text" : "In this experiment, we investigate the “importance” of the features generated by ΦΩ corresponding to different layers, wavelet scales, and directions in two different learning tasks, namely, facial landmark detection and handwritten digit classification. The primary goal of this experiment is to illustrate the practical relevance of the notion of local properties of ΦΩ as established in Section 5.2. For facial landmark detection we employ a RF regressor and for handwritten digit classification a RF classifier (Breiman, 2001). In both cases, we fix the number of trees to 30 and select the tree depth using out-of-bag error estimates (noting that increasing the number of trees does not significantly increase the accuracy). The impurity measure used for learning the node tests is the mean square error for facial landmark detection and the Gini impurity for handwritten digit classification. In both cases, feature importance is assessed using the Gini importance (Breiman et al., 1984), averaged over all trees. The Gini importance I(θ, T ) of feature θ in the (trained) tree T is defined as\nI(θ, T ) = ∑ `∈T : ϕ(`)=θ n` ntot (̂ı`− n`L n` ı̂`L− n`R n` ı̂`R), where ϕ(`) denotes the feature determined in the training phase for the test at node `, n` is the number of training samples passed through node `, ntot = ∑ `∈T n`, ı̂` is the impurity at node `, and `L and `R denote the left and right child node, respectively, of node `. For the feature extractor ΦΩ we set D = 4, employ Haar wavelets with J = 3 scales and the modulus non-linearity in every network layer, no pooling in the first layer and average pooling with uniform weights 1/S2d , Sd = 2, in layers d = 2, 3.\nFacial landmark detection. We use the Caltech 10,000 Web Faces data base (Angelova et al., 2005). Each of the 7092 images in the data base depicts one or more faces in different contexts (e.g., portrait images, groups of people). The data base contains annotations of the positions of eyes, nose, and mouth for at least one face per image. The learning task is to estimate the positions of these facial landmarks. The annotations serve as ground truth for training and testing. We preprocess the data set as follows. The patches containing the faces are extracted from the images using the Viola-Jones face detector (Viola & Jones, 2004). After discarding false positives, the patches are converted to grayscale and resampled to size 120 × 120 (using linear interpolation), before feeding them to the feature extractor ΦΩ. This procedure yields a dataset containing a total of 8776 face images. We select 80% of the images uniformly at random to form a training set and use the remaining images for testing. We train a separate RF for each facial landmark. Following (Dantone et al., 2012) we report the localization error, i.e., the `2-distance between the estimated and the ground truth landmark positions, on the test set as a fraction of the (true) inter-ocular distance. The errors obtained are: left eye: 0.062; right eye: 0.064; nose; 0.080, mouth: 0.095. As an aside, we note that these values are comparable with the ones reported in (Dantone et al., 2012) for a conditional RF using patch comparison features (evaluated on a different dataset and a larger set of facial landmarks).\nHandwritten digit classification. For this experiment, we again rely on the MNIST dataset. The training set is obtained by sampling uniformly at random 1, 000 images per digit from the MNIST training dataset and we use the complete MNIST test set. We train two RFs, one based on unmodified images, and the other one based on images subject to a random uniform displacement of at most 4 pixels in (positive and negative) x and y direction to study the impact of offsets on feature importance. The resulting RFs achieve a classification error of 4.2% and 9.6%, respectively.\nDiscussion. Figure 3 shows the cumulative feature importance (per triplet of layer index, wavelet scale, and direction, averaged over all trees in the respective RF) in handwritten digit classification and in facial landmark detection. Table 2 shows the corresponding cumulative fea-\nture importance for each layer.\nFor facial landmark detection, the features in layer 1 clearly have the highest importance, and the feature importance decreases with increasing layer index d. For handwritten digit classification using the unshifted MNIST images, the cumulative importance of the features in the second/third layer relative to those in the first layer is considerably higher than in facial landmark detection (see Table 2). For the translated MNIST images, the importance of the features in the second/third layer is significantly higher than those in the 0-th and in the first layer. An explanation for this observation could be as follows: In a classification task small sensitivity to translations is beneficial. Now, according to our theory (see Section 5.2) translation sensitivity, indeed, decreases with increasing layer index for average pooling as used here. For localization of landmarks, on the other hand, the RF needs features that are covariant on the fine grid of the input image thus favoring features in the layers closer to the root."
    }, {
      "heading" : "Acknowledgments",
      "text" : "The authors would like to thank C. Geiger for preliminary work on the experiments in Section 6.2 and M. Lerjen for help with computational issues."
    }, {
      "heading" : "A. Appendix: Additional numerical results",
      "text" : "A.1. Handwritten digit classification\nFor the handwritten digit classification experiment described in Section 6.1, Table 3 shows the classification error for Daubechies wavelets with 2 vanishing moments (DB2).\nA.2. Feature importance evaluation\nFor the feature importance experiment described in Section 6.2, Figure 4 shows the cumulative feature importance (per triplet of layer index, wavelet scale, and direction, averaged over all trees in the respective RF) in facial landmark detection (right eye and mouth)."
    }, {
      "heading" : "B. Appendix: Lipschitz continuity of pooling operators",
      "text" : "We verify the Lipschitz property\n‖P (f)− P (h)‖2 ≤ R‖f − h‖2, ∀f, h ∈ HN ,\nfor the pooling operators in Section 2.3.1.\nSub-sampling: Pooling by sub-sampling is defined as\nP : HN → HN/S , P (f)[n] = f [Sn], n ∈ IN/S ,\nwhere N/S ∈ N. Lipschitz continuity with R = 1 follows from\n‖P (f)− P (h)‖22 = ∑\nn∈IN/S\n|f [Sn]− h[Sn]|2\n≤ ∑ n∈IN |f [n]− h[n]|2 = ‖f − h‖22, ∀f, h ∈ HN .\nAveraging: Pooling by averaging is defined as\nP : HN → HN/S , P (f)[n] = Sn+S−1∑ k=Sn αk−Snf [k],\nfor n ∈ IN/S , where N/S ∈ N. We start by setting α′ :=\nmaxk∈{0,...,S−1} |αk|. Then,\n‖P (f)− P (h)‖22\n= ∑\nn∈IN/S\n∣∣∣ Sn+S−1∑ k=Sn αk−Sn(f [k]− h[k]) ∣∣∣2\n≤ ∑\nn∈IN/S\n∣∣∣ Sn+S−1∑ k=Sn α′|f [k]− h[k]| ∣∣∣2\n≤ α′2S ∑\nn∈IN/S\nSn+S−1∑ k=Sn ∣∣∣f [k]− h[k]∣∣∣2 (B.1) = α′2S\n∑ n∈IN ∣∣∣f [k]− h[k]∣∣∣2 = α′2S‖f − h‖22, where we used ∑ k∈IS |f [k]−h[k]| ≤ S\n1/2‖f−h‖2, f, h ∈ HS , to get (B.1), see, e.g., (Golub & Van Loan, 2013).\nMaximization: Pooling by maximization is defined as\nP : HN → HN/S , P (f)[n] = max k∈{Sn,...,Sn+S−1} |f [k]|,\nfor n ∈ IN/S , where N/S ∈ N. We have\n‖P (f)− P (h)‖22 = ∑ n∈IN/S ∣∣ max k∈{Sn,...,Sn+S−1} |f [k]|\n− max k∈{Sn,...,Sn+S−1}\n|h[k]| ∣∣2\n≤ ∑\nn∈IN/S\nmax k∈{Sn,...,Sn+S−1} ∣∣f [k]− h[k]∣∣2 (B.2) ≤\n∑ n∈IN/S S−1∑ k=0 |f [Sn+ k]− h[Sn+ k]|2 (B.3)\n= ‖f − h‖22,\nwhere we employed the reverse triangle inequality∣∣‖f‖∞ − ‖h‖∞∣∣ ≤ ‖f − h‖∞, f, h ∈ HS , to get (B.2), and in (B.3) we used ‖f‖∞ ≤ ‖f‖2, f ∈ HS , see, e.g., (Golub & Van Loan, 2013)."
    }, {
      "heading" : "C. Appendix: Proof of Theorem 1",
      "text" : "We start by proving i). The key idea of the proof is— similarly to the proof of Proposition 4 in (Wiatowski & Bölcskei, 2015)—to employ telescoping series arguments. For ease of notation, we let fq := U [q]f and hq := U [q]h, for f, h ∈ HN1 , q ∈ Λd1. With (9) we have\n|||ΦΩ(f)− ΦΩ(h)|||2 = D−1∑ d=0 ∑ q∈Λd1\n||(fq − hq) ∗ χd||22︸ ︷︷ ︸ =:ad .\nThe key step is then to show that ad can be upper-bounded according to\nad ≤ bd − bd+1, d = 0, . . . , D − 1, (C.1)\nwith bd := ∑ q∈Λd1\n‖fq − hq‖22, for d = 0, . . . , D, and to note that\nD−1∑ d=0 ad ≤ D−1∑ d=0 (bd − bd+1) = b0 − bD︸︷︷︸ ≥0 ≤ b0\n= ∑ q∈Λ01 ‖fq − hq‖22 = ‖f − h‖22,\nwhich then yields (8). Writing out (C.1), it follows that we need to establish\n∑ q∈Λd1 ‖(fq − hq) ∗ χd‖22 ≤ ∑ q∈Λd1 ||fq − hq‖22\n− ∑\nq∈Λd+11\n‖fq − hq‖22, d = 0, . . . , D − 1. (C.2)\nWe start by examining the second sum on the right-hand side (RHS) in (C.2). Every path\nq̃ ∈ Λd+11 = Λ1 × · · · × Λd︸ ︷︷ ︸ =Λd1 ×Λd+1\nof length d + 1 can be decomposed into a path q ∈ Λd1 of length d and an index λd+1 ∈ Λd+1 according to q̃ = (q, λd+1). Thanks to (5) we have U [q̃] = U [(q, λd+1)] = Ud+1[λd+1]U [q], which yields\n∑ q̃∈Λd+11 ‖fq̃ − hq̃‖22 = ∑ q∈Λd1 ∑ λd+1∈Λd+1 ‖Ud+1[λd+1]fq − Ud+1[λd+1]hq‖22. (C.3)\nSubstituting (C.3) into (C.2) and rearranging terms, we obtain\n∑ q∈Λd1 ( ‖(fq − hq) ∗ χd‖22 (C.4)\n+ ∑\nλd+1∈Λd+1\n‖Ud+1[λd+1]fq − Ud+1[λd+1]hq‖22 ) (C.5)\n≤ ∑ q∈Λd1 ||fq − hq‖22, d = 0, . . . , D − 1. (C.6)\nWe next note that the sum over the index set Λd+1 inside the brackets in (C.4)-(C.5) satisfies∑\nλd+1∈Λd+1\n‖Ud+1[λd+1]fq − Ud+1[λd+1]hq‖22\n= ∑\nλd+1∈Λd+1\n‖Pd+1 ( ρd+1(fq ∗ gλd+1) ) − Pd+1 ( ρd+1(hq ∗ gλd+1) ) ‖22\n≤ R2d+1 ∑\nλd+1∈Λd+1\n‖ρd+1(fq ∗ gλd+1) (C.7)\n− ρd+1(hq ∗ gλd+1)‖22 (C.8) ≤ R2d+1L2d+1 ∑\nλd+1∈Λd+1\n‖(fq − hq) ∗ gλd+1‖22, (C.9)\nwhere we employed the Lipschitz continuity of Pd+1 in (C.7)-(C.8) and the Lipschitz continuity of ρd+1 in (C.9). Substituting the sum over the index set Λd+1 inside the brackets in (C.4)-(C.5) by the upper bound (C.9) yields∑ q∈Λd1 ( ‖(fq − hq) ∗ χd‖22\n+ ∑\nλd+1∈Λd+1\n‖Ud+1[λd+1]fq − Ud+1[λd+1]hq‖22 )\n≤ ∑ q∈Λd1 max{1, R2d+1L2d+1} ( ‖(fq − hq) ∗ χd‖22 (C.10)\n+ ∑\nλd+1∈Λd+1\n‖(fq − hq) ∗ gλd+1‖22 ) , (C.11)\nfor d = 0, . . . , D − 1. As {gλd+1}λd+1∈Λd+1 ∪ {χd} are atoms of the convolutional set Ψd+1, and fq, hq ∈ HNd+1 , we have\n‖(fq − hq) ∗ χd‖22 + ∑\nλd+1∈Λd+1\n‖(fq − hq) ∗ gλd+1‖22\n≤ Bd+1‖fq − hq‖22,\nwhich, when used in (C.10)-(C.11) yields∑ q∈Λd1 ( ‖(fq − hq) ∗ χd‖22\n+ ∑\nλd+1∈Λd+1\n‖Ud+1[λd+1]fq − Ud+1[λd+1]hq‖22 )\n≤ ∑ q∈Λd1 max{Bd+1, Bd+1R2d+1L2d+1}‖fq − hq‖22,\n(C.12)\nfor d = 0, . . . , D − 1. Finally, invoking (7) in (C.12) we get (C.4)-(C.6) and hence (C.1). This completes the proof of i).\nWe continue with ii). The key step in establishing (10) is to show that for ρd(0) = 0 and Pd(0) = 0, for\nd ∈ {1, . . . , D − 1}, the feature extractor ΦΩ satisfies ΦΩ(0) = 0, and to employ (8) with h = 0 which yields\n|||Φ(f)||| ≤ ‖f‖,\nfor f ∈ HN1 . It remains to prove that ΦΩ(h) = 0 for h = 0. For h = 0, the operator Ud, d ∈ {1, 2, . . . , D}, defined in (4) satisfies\n(Ud[λd]h) = Pd ( ρd(h ∗ gλd︸ ︷︷ ︸\n=0\n)\n︸ ︷︷ ︸ =0 ) ︸ ︷︷ ︸\n=0\n,\nfor λd ∈ Λd, by assumption. With the definition of U [q] in (5) this then yields (U [q]h) = 0 for h = 0 and all q ∈ Λd1. ΦΩ(0) = 0 finally follows from\nΦΩ(h) = D−1⋃ d=0 { ( U [q]h ) ∗ χd︸ ︷︷ ︸\n=0\n} q∈Λd1 = 0. (C.13)\nWe proceed to iii). The proof of the deformation sensitivity bound (12) is based on two key ingredients. The first one is the Lipschitz continuity result stated in (8). The second ingredient, stated in Proposition D.1 in Appendix D, is an upper bound on the deformation error ‖f − Fτf‖2 given by\n‖f − Fτf‖2 ≤ 4KN1/21 ‖τ‖1/2∞ , (C.14)\nwhere f ∈ CN1,KCART . We now show how (8) and (C.14) can be combined to establish (12). To this end, we first apply (8) with h := (Fτf) to get\n|||ΦΩ(f)− ΦΩ(Fτf)||| ≤ ‖f − Fτf‖2, (C.15)\nfor f ∈ CN1,KCART ⊆ HN1 , N1 ∈ N, and K > 0, and then replace the RHS of (C.15) by the RHS of (C.14). This completes the proof of iii)."
    }, {
      "heading" : "D. Appendix: Proposition D.1",
      "text" : "Proposition D.1. For every N ∈ N, every K > 0, and every τ : R→ [−1, 1], we have\n‖f − Fτf‖2 ≤ 4KN1/2‖τ‖1/2∞ , (D.1)\nfor all f ∈ CN,KCART. Remark D.1. As already mentioned at the end of Section 4, excluding the interval boundary points a, b in the definition of sampled cartoon functions CN,KCART (see Definition 4) is necessary for technical reasons. Specifically, without imposing this exclusion, we can not expect to get deformation sensitivity results of the form (D.1). This can be seen as follows. Let us assume that we seek a bound of the form\n‖f − Fτf‖2 ≤ CN,K‖τ‖α∞, for some CN,K > 0 and some α > 0, that applies to all f [n] = c(n/N), n ∈ IN , with c ∈ CKCART. Take τ(x) = 1/N , in which case the deformation (Fτf)[n] = c(n/N − 1/N) amounts to a simple translation by 1/N and ‖τ‖∞ = 1/N ≤ 1. Let c(x) = 1[0,2/N ](x). Then c ∈ CKCART for K = 1 and ‖f − Fτf‖2 = √ 2, which obviously does not decay with ‖τ‖α∞ = N−α for some α > 0. We note that this phenomenon occurs only in the discrete case.\nProof. The proof of (D.1) is based on judiciously combining deformation sensitivity bounds for the sampled components c1(n/N), c2(n/N), n ∈ IN , in (c1 + 1[a,b]c2) ∈ CKCART, and the sampled indicator function 1[a,b](n/N), n ∈ IN . The first bound, stated in Lemma D.1 below, reads\n‖f − Fτf‖2 ≤ CN1/2‖τ‖∞, (D.2)\nand applies to discrete-time signals f [n] = f(n/N), n ∈ IN , with f : R→ C satisfying the Lipschitz property with Lipschitz constant C. The second bound we need, stated in Lemma D.2 below, is given by\n‖1N[a,b] − Fτ1 N [a,b]‖2 ≤ 2N 1/2‖τ‖1/2∞ , (D.3)\nand applies to sampled indicator functions 1N[a,b][n] := 1[a,b](n/N), n ∈ IN , with a, b /∈ {0, 1N , . . . , N−1 N }. We now show how (D.2) and (D.3) can be combined to establish (D.1). For a sampled cartoon function f ∈ CN,KCART, i.e.,\nf [n] = c1(n/N) + 1[a,b](n/N)c2(n/N)\n=: f1[n] + 1 N [a,b][n]f2[n], n ∈ IN ,\nwe have\n‖f − Fτf‖2 ≤ ‖f1 − Fτf1‖2 + ‖1N[a,b](f2 − Fτf2)‖2 + ‖(1N[a,b] − Fτ1 N [a,b])(Fτf2)‖2 (D.4)\n≤ ‖f1 − Fτf1‖2 + ‖f2 − Fτf2‖2 + ‖1N[a,b] − Fτ1 N [a,b]‖2‖Fτf2‖∞,\nwhere in (D.4) we used( Fτ (1 N [a,b]f2) ) [n] = (1[a,b]c2)(n/N − τ(n/N))\n= 1[a,b](n/N − τ(n/N))c2((n/N − τ(n/N))) = (Fτ1 N [a,b])[n](Fτf2)[n].\nWith the upper bounds (D.2) and (D.3), invoking properties of CN,KCART (namely, (i) c1, c2 satisfy the Lipschitz property with Lipschitz constant C = K and hence f1[n] = c1(n/N), f2[n] = c2(n/N), n ∈ IN , satisfy (D.2) with C = K, and (ii) ‖Fτf2‖∞ = supn∈IN |(Fτf2)[n]| =\nsupn∈IN |c2(n/N − τ(n/N))| ≤ supx∈R |c2(x)| = ‖c2‖∞ ≤ K), this yields\n‖f − Fτf‖2 ≤ 2KN1/2 ‖τ‖∞ + 2KN1/2‖τ‖1/2∞ ≤ 4KN1/2‖τ‖1/2∞ ,\nwhere in the last step we used ‖τ‖∞ ≤ ‖τ‖1/2∞ , which is thanks to the assumption ‖τ‖∞ ≤ 1. This completes the proof of (D.1).\nIt remains to establish (D.2) and (D.3). Lemma D.1. Let c : R → C be Lipschitz-continuous with Lipschitz constantC. Let further f [n] := c(n/N), n ∈ IN . Then,\n‖f − Fτf‖2 ≤ CN1/2‖τ‖∞.\nProof. Invoking the Lipschitz property of c according to ‖f − Fτf‖22 = ∑ n∈IN |f [n]− (Fτf)[n]|2\n= ∑ n∈IN |c(n/N)− c(n/N − τ(n/N))|2\n≤ C2 ∑ n∈IN |τ(n/N)|2 ≤ C2N‖τ‖2∞\ncompletes the proof.\nWe continue with a deformation sensitivity result for sampled indicator functions 1[a,b](x). Lemma D.2. Let [a, b] ⊆ [0, 1] and set 1N[a,b][n] := 1[a,b](n/N), n ∈ IN , with a, b /∈ {0, 1N , . . . , N−1 N }. Then, we have\n‖1N[a,b] − Fτ1 N [a,b]‖2 ≤ 2N 1/2‖τ‖1/2∞ .\nProof. In order to upper-bound\n‖1N[a,b] − Fτ1 N [a,b]‖ 2 2 = ∑ n∈IN |1N[a,b][n]− (Fτ1 N [a,b])[n]| 2\n= ∑ n∈IN |1[a,b](n/N)− 1[a,b](n/N − τ(n/N))|2,\nwe first note that the summand h(n) := |1[a,b](n/N) − 1[a,b](n/N − τ(n/N))|2 satisfies h(n) = 1, for n ∈ S, where\nS := { n ∈ IN ∣∣∣ n N ∈ [a, b] and n N − τ ( n N ) /∈ [a, b] } ∪ { n ∈ IN ∣∣∣ n N /∈ [a, b] and n N − τ ( n N ) ∈ [a, b] } ,\nand h(n) = 0, for n ∈ IN\\S. Thanks to a, b /∈ {0, 1N , . . . , N−1 N }, we have S ⊆ Σ, where\nΣ := { n ∈ Z ∣∣∣ ∣∣∣ n N − a ∣∣∣ < ‖τ‖∞}\n∪ { n ∈ Z ∣∣∣ ∣∣∣ n N − b ∣∣∣ < ‖τ‖∞}.\nThe cardinality of the set Σ can be upper-bounded by 2 2‖τ‖∞1/N , which then yields\n‖1N[a,b] − Fτ1 N [a,b]‖ 2 2 = ∑ n∈IN |h(n)|2\n= ∑ n∈S 1 ≤ ∑ n∈Σ 1 ≤ 4N‖τ‖∞. (D.5)\nThis completes the proof.\nRemark D.2. For general a, b ∈ [0, 1], i.e., when we drop the assumption a, b /∈ {0, 1N , . . . , N−1 N }, it follows that S ⊆ Σ′, where\nΣ′ := { n ∈ Z ∣∣∣ ∣∣∣ n N − a ∣∣∣ ≤ ‖τ‖∞}\n∪ { n ∈ Z ∣∣∣ ∣∣∣ n N − b ∣∣∣ ≤ ‖τ‖∞}.\nNoting that the cardinality of Σ′ can be upper-bounded by 2 ( 2‖τ‖∞ 1/N + 1 )\n= 4N‖τ‖∞ + 2, this then yields (similarly to (D.5))\n‖1N[a,b] − Fτ1 N [a,b]‖ 2 2 ≤ ∑ n∈Σ 1 ≤ 4N‖τ‖∞ + 2,\nwhich shows that the deformation error—for general a, b ∈ [0, 1]—does not decay with ‖τ‖α∞ for some α > 0 (see also the example in Remark D.1)."
    }, {
      "heading" : "E. Appendix: Theorem 2",
      "text" : "We start by establishing i). For ease of notation, again, we let fq := U [q]f and hq := U [q]h, for f, h ∈ HN1 , q ∈ Λd1. We have\n|||ΦdΩ(f)− ΦdΩ(h)|||2 = ∑ q∈Λd1 ||(fq − hq) ∗ χd||22 (E.1)\n≤ ‖χd‖21 ∑ q∈Λd1\n||(fq − hq)||22︸ ︷︷ ︸ =:ad , (E.2)\nwhere (E.2) follows by Young’s inequality (Folland, 2015).\nRemark E.1. We emphasize that (E.1) can also be upperbounded byBd+1 ∑ q∈Λd1\n||(fq−hq)||22, which follows from the fact that {gλd+1}λd+1∈Λd+1 ∪ {χd} are atoms of the convolutional set Ψd+1 with Bessel bound Bd+1. Hence, one can substitute ‖χd‖1 in (15) by Bd+1.\nThe key step is then to show that ad can be upper-bounded according to\nak ≤ (BkL2kR2k)ak−1, k = 1, . . . , d, (E.3)\nand to note that\nad ≤ (BdL2dR2d)ad−1 ≤ · · · ≤ ( d∏ k=1 BkL 2 kR 2 k ) a0\n= ( d∏ k=1 BkL 2 kR 2 k ) ∑ q∈Λ01 ‖fq − hq‖22\n= ( d∏ k=1 BkL 2 kR 2 k ) ‖f − h‖22,\nwhich yields (16). We now establish (E.3). Every path\nq̃ ∈ Λk1 = Λ1 × · · · × Λk−1︸ ︷︷ ︸ =Λk−11 ×Λk\nof length k can be decomposed into a path q ∈ Λk−11 of length k − 1 and an index λk ∈ Λk according to q̃ = (q, λk). Thanks to (5) we have U [q̃] = U [(q, λk)] = Uk[λk]U [q], which yields∑\nq̃∈Λk1\n‖fq̃ − hq̃‖22 = ∑\nq∈Λk−11\n∑ λk∈Λk ‖Uk[λk]fq\n− Uk[λk]hq‖22. (E.4)\nWe next note that the term inside the sums on the RHS in (E.4) satisfies\n‖Uk[λk]fq − Uk[λk]hq‖22 = ‖Pk ( ρk(fq ∗ gλk) ) − Pk ( ρk(hq ∗ gλk) ) ‖22\n≤ L2kR2k‖(fq − hq) ∗ gλk‖22, (E.5)\nwhere we used the Lipschitz continuity of Pk and ρk with Lipschitz constants Rk > 0 and Lk > 0, respectively. As {gλk}λk∈Λk ∪ {χk−1} are the atoms of the convolutional set Ψk, and fq, hq ∈ HNk by (5), we have∑\nλk∈Λk\n‖(fq − hq) ∗ gλk‖22 ≤ Bk‖fq − hq‖22,\nwhich, when used in (E.5) together with (E.4), yields∑ q̃∈Λk1 ‖fq̃ − hq̃‖22 ≤ BkL2kR2k ∑ q∈Λk−11 ‖fq − hq‖22,\nand hence establishes (E.3), thereby completing the proof of i).\nWe now turn to ii). The proof of (17) follows—as in the proof of ii) in Theorem 1 in Appendix C—from (16) together with ΦdΩ(h) = {(U [q]h) ∗ χd}q∈Λd1 = 0 for h = 0, see (C.13).\nWe continue with iii). The proof of the deformation sensitivity bound (18) is based on two key ingredients. The\nfirst one is the Lipschitz continuity result in (16). The second ingredient is, again, the deformation sensitivity bound (D.1) stated in Proposition D.1 in Appendix D. Combining (16) and (D.1)—as in the proof of iii) in Theorem 1 in Appendix C—then establishes (18) and completes the proof of iii).\nWe proceed to iv). For ease of notation, again, we let fq := U [q]f , for f ∈ HN1 , q ∈ Λd1. Thanks to (5), we have fq ∈ HNd+1 , for q ∈ Λd1. The key step in establishing (19) is to show that the operator Uk, k ∈ {1, 2, . . . , d}, defined in (4) satisfies the relation\n(Uk[λk]Tmf) = Tm/Sk(Uk[λk]f), (E.6)\nfor f ∈ HNk , m ∈ Z with mSk ∈ Z, and λk ∈ Λk. With the definition of U [q] in (5) this then yields\n(U [q]Tmf) = Tm/(S1···Sd)(U [q]f), (E.7)\nfor f ∈ HN1 , m ∈ Z with mS1...Sd ∈ Z, and q ∈ Λ d 1. The identity (19) is then a direct consequence of (E.7) and the translation-covariance of the circular convolution operator (which holds thanks to mS1...Sd ∈ Z):\nΦdΩ(Tmf) = {( U [q]Tmf ) ∗ χd } q∈Λd1\n= {( Tm/(S1···Sd)U [q]f ) ∗ χd } q∈Λd1\n= { Tm/(S1···Sd) ( (U [q]f) ∗ χd )} q∈Λd1 = Tm/(S1···Sd)Φ d Ω(f),\nfor f ∈ HN1 and m ∈ Z with mS1...Sd ∈ Z. It remains to establish (E.6):\n(Uk[λk]Tmf) = ( Pk ( ρk((Tmf) ∗ gλk) )) = ( Pk ( ρk(Tm(f ∗ gλk)) )) (E.8)\n= ( Pk ( Tm(ρk(f ∗ gλk)) )) , (E.9)\nwhere in (E.8) we used the translation covariance of the circular convolution operator (which holds thanks to m ∈ Z), and in (E.9) we used the fact that point-wise non-linearities commute with the translation operator thanks to\n(ρkTmf)[n] = ρk((Tmf)[n])\n= ρk(f [n−m]) = (Tmρkf)[n],\nfor f ∈ HNk , n ∈ INk , and m ∈ Z. Next, we note that the pooling operators Pk in Section 2.3.1 (namely, sub-sampling, average pooling, and max-pooling) can all be written as (Pkf)[n] = (P ′kf)[Skn], for some P ′ k that commutes with the translation operator, namely, for (i) sub-sampling (P ′kf)[n] = f [n], with (P ′ kTmf)[n] =\n(Tmf)[n] = f [n−m] = (TmP ′kf)[n], (ii) average pooling (P ′kf)[n] = ∑n+Sk−1 l=n αl−nf [l] with\n(P ′kTmf)[n] = n+Sk−1∑ l=n αl−nf [l −m]\n= (n−m)+Sk−1∑ l′=(n−m) αl−(n−m)f [l ′] = (TmP ′ kf)[n],\nand for (iii) max-pooling (P ′kf)[n] = maxl∈{n,...,n+Sk−1} |f [l]| with\n(P ′kTmf)[n] = max l∈{n,...,n+Sk−1} |f [l −m]|\n= max (l−m)∈{n−m,...,(n−m)+Sk−1}\n|f [l −m]|\n= max l′∈{(n−m),...,(n−m)+Sk−1}\n|f [l′]|\n= (TmP ′ kf)[n],\nin all three cases for f ∈ HNk , n ∈ INk , and m ∈ Z. This then yields\n(PkTmf)[n] = (P ′ kTmf)[Skn] = (TmP ′ kf)[Skn]\n= P ′k(f)[Skn−m] = P ′k(f)[Sk(n− S−1k m)] = Pk(f)[n− S−1k m] = (Tm/SkPkf)[n], (E.10)\nfor f ∈ HNk and n ∈ INk+1 . Here, we used m/Sk ∈ Z, which is by assumption. Substituting (E.10) into (E.9) finally yields\n(Uk[λk]Tmf) = Tm/SkUk[λk]f,\nfor f ∈ HNk , m ∈ Z with mSk ∈ Z, and λk ∈ Λk. This completes the proof of (E.6) and hence establishes (19)."
    } ],
    "references" : [ {
      "title" : "Deep scattering spectrum",
      "author" : [ "J. Andén", "S. Mallat" ],
      "venue" : "IEEE Trans. Sig. Process.,",
      "citeRegEx" : "Andén and Mallat,? \\Q2014\\E",
      "shortCiteRegEx" : "Andén and Mallat",
      "year" : 2014
    }, {
      "title" : "Pruning training sets for learning of object categories",
      "author" : [ "A. Angelova", "Y. Abu-Mostafa", "P. Perona" ],
      "venue" : "In Proc. of IEEE Conf. Comp. Vision Pattern Recog. (CVPR),",
      "citeRegEx" : "Angelova et al\\.,? \\Q2005\\E",
      "shortCiteRegEx" : "Angelova et al\\.",
      "year" : 2005
    }, {
      "title" : "Representation learning: A review and new perspectives",
      "author" : [ "Y. Bengio", "A. Courville", "P. Vincent" ],
      "venue" : "IEEE Trans. Pattern Anal. Mach. Intell.,",
      "citeRegEx" : "Bengio et al\\.,? \\Q2013\\E",
      "shortCiteRegEx" : "Bengio et al\\.",
      "year" : 2013
    }, {
      "title" : "Discrete Zak transforms, polyphase transforms, and applications",
      "author" : [ "H. Bölcskei", "F. Hlawatsch" ],
      "venue" : "IEEE Trans. Sig. Process.,",
      "citeRegEx" : "Bölcskei and Hlawatsch,? \\Q1997\\E",
      "shortCiteRegEx" : "Bölcskei and Hlawatsch",
      "year" : 1997
    }, {
      "title" : "Classification and regression trees",
      "author" : [ "L. Breiman", "J. Friedman", "C.J. Stone", "R.A. Olshen" ],
      "venue" : null,
      "citeRegEx" : "Breiman et al\\.,? \\Q1984\\E",
      "shortCiteRegEx" : "Breiman et al\\.",
      "year" : 1984
    }, {
      "title" : "Invariant scattering convolution networks",
      "author" : [ "J. Bruna", "S. Mallat" ],
      "venue" : "IEEE Trans. Pattern Anal. Mach. Intell.,",
      "citeRegEx" : "Bruna and Mallat,? \\Q2013\\E",
      "shortCiteRegEx" : "Bruna and Mallat",
      "year" : 2013
    }, {
      "title" : "Fast discrete curvelet transforms",
      "author" : [ "E.J. Candès", "L. Demanet", "D. Donoho", "L. Ying" ],
      "venue" : "Multiscale Modeling and Simulation,",
      "citeRegEx" : "Candès et al\\.,? \\Q2006\\E",
      "shortCiteRegEx" : "Candès et al\\.",
      "year" : 2006
    }, {
      "title" : "Realtime facial feature detection using conditional regression forests",
      "author" : [ "M. Dantone", "J. Gall", "G. Fanelli", "L. Van Gool" ],
      "venue" : "In Proc. of IEEE Conf. Comp. Vision Pattern Recog. (CVPR),",
      "citeRegEx" : "Dantone et al\\.,? \\Q2012\\E",
      "shortCiteRegEx" : "Dantone et al\\.",
      "year" : 2012
    }, {
      "title" : "Comparison of parametric representations for monosyllabic word recognition in continuously spoken sentences",
      "author" : [ "S. Davis", "P. Mermelstein" ],
      "venue" : "IEEE Trans. Acoust., Speech, and Signal Process.,",
      "citeRegEx" : "Davis and Mermelstein,? \\Q1980\\E",
      "shortCiteRegEx" : "Davis and Mermelstein",
      "year" : 1980
    }, {
      "title" : "Sparse components of images and optimal atomic decompositions",
      "author" : [ "D. Donoho" ],
      "venue" : "Constructive Approximation,",
      "citeRegEx" : "Donoho,? \\Q2001\\E",
      "shortCiteRegEx" : "Donoho",
      "year" : 2001
    }, {
      "title" : "A course in abstract harmonic analysis, volume 29",
      "author" : [ "G.B. Folland" ],
      "venue" : "CRC Press,",
      "citeRegEx" : "Folland,? \\Q2015\\E",
      "shortCiteRegEx" : "Folland",
      "year" : 2015
    }, {
      "title" : "Matrix computations",
      "author" : [ "G.H. Golub", "C.F. Van Loan" ],
      "venue" : null,
      "citeRegEx" : "Golub and Loan,? \\Q2013\\E",
      "shortCiteRegEx" : "Golub and Loan",
      "year" : 2013
    }, {
      "title" : "Deep convolutional neural networks on cartoon functions",
      "author" : [ "P. Grohs", "T. Wiatowski", "H. Bölcskei" ],
      "venue" : "In Proc. of IEEE Int. Symp. on Inform. Theory (ISIT),",
      "citeRegEx" : "Grohs et al\\.,? \\Q2016\\E",
      "shortCiteRegEx" : "Grohs et al\\.",
      "year" : 2016
    }, {
      "title" : "A real-time algorithm for signal analysis with the help of the wavelet transform",
      "author" : [ "M. Holschneider", "R. Kronland-Martinet", "J. Morlet", "P. Tchamitchian" ],
      "venue" : "In Wavelets,",
      "citeRegEx" : "Holschneider et al\\.,? \\Q1989\\E",
      "shortCiteRegEx" : "Holschneider et al\\.",
      "year" : 1989
    }, {
      "title" : "Large-scale learning with SVM and convolutional nets for generic object categorization",
      "author" : [ "F.J. Huang", "Y. LeCun" ],
      "venue" : "In Proc. of IEEE Conf. Comp. Vision Pattern Recog. (CVPR),",
      "citeRegEx" : "Huang and LeCun,? \\Q2006\\E",
      "shortCiteRegEx" : "Huang and LeCun",
      "year" : 2006
    }, {
      "title" : "What is the best multi-stage architecture for object recognition",
      "author" : [ "K. Jarrett", "K. Kavukcuoglu", "M.A. Ranzato", "Y. LeCun" ],
      "venue" : "In Proc. of IEEE Int. Conf. on Computer Vision (ICCV),",
      "citeRegEx" : "Jarrett et al\\.,? \\Q2009\\E",
      "shortCiteRegEx" : "Jarrett et al\\.",
      "year" : 2009
    }, {
      "title" : "Learning multiple layers of features from tiny images",
      "author" : [ "A. Krizhevsky" ],
      "venue" : "MS thesis, University of Toronto,",
      "citeRegEx" : "Krizhevsky,? \\Q2009\\E",
      "shortCiteRegEx" : "Krizhevsky",
      "year" : 2009
    }, {
      "title" : "Shearlets: Multiscale analysis for multivariate data",
      "author" : [ "G. Kutyniok", "Labate", "D. (eds" ],
      "venue" : null,
      "citeRegEx" : "Kutyniok et al\\.,? \\Q2012\\E",
      "shortCiteRegEx" : "Kutyniok et al\\.",
      "year" : 2012
    }, {
      "title" : "Introduction to shearlets. In Shearlets: Multiscale analysis for multivariate data, pp. 1–38",
      "author" : [ "G. Kutyniok", "D. Labate" ],
      "venue" : null,
      "citeRegEx" : "Kutyniok and Labate,? \\Q2012\\E",
      "shortCiteRegEx" : "Kutyniok and Labate",
      "year" : 2012
    }, {
      "title" : "The MNIST database of handwritten digits",
      "author" : [ "Y. LeCun", "C. Cortes" ],
      "venue" : "http://yann.lecun.com/exdb/ mnist/,",
      "citeRegEx" : "LeCun and Cortes,? \\Q1998\\E",
      "shortCiteRegEx" : "LeCun and Cortes",
      "year" : 1998
    }, {
      "title" : "Gradientbased learning applied to document recognition",
      "author" : [ "Y. LeCun", "L. Bottou", "Y. Bengio", "P. Haffner" ],
      "venue" : "In Proc. of the IEEE,",
      "citeRegEx" : "LeCun et al\\.,? \\Q1998\\E",
      "shortCiteRegEx" : "LeCun et al\\.",
      "year" : 1998
    }, {
      "title" : "Distinctive image features from scaleinvariant keypoints",
      "author" : [ "D.G. Lowe" ],
      "venue" : "International Journal of Computer Vision,",
      "citeRegEx" : "Lowe,? \\Q2004\\E",
      "shortCiteRegEx" : "Lowe",
      "year" : 2004
    }, {
      "title" : "A wavelet tour of signal processing: The sparse way",
      "author" : [ "S. Mallat" ],
      "venue" : null,
      "citeRegEx" : "Mallat,? \\Q2009\\E",
      "shortCiteRegEx" : "Mallat",
      "year" : 2009
    }, {
      "title" : "Group invariant scattering",
      "author" : [ "S. Mallat" ],
      "venue" : "Comm. Pure Appl. Math.,",
      "citeRegEx" : "Mallat,? \\Q2012\\E",
      "shortCiteRegEx" : "Mallat",
      "year" : 2012
    }, {
      "title" : "Multiclass object recognition with sparse, localized features",
      "author" : [ "J. Mutch", "D.G. Lowe" ],
      "venue" : "In Proc. of IEEE Conf. Comp. Vision Pattern Recog. (CVPR), pp",
      "citeRegEx" : "Mutch and Lowe,? \\Q2006\\E",
      "shortCiteRegEx" : "Mutch and Lowe",
      "year" : 2006
    }, {
      "title" : "Deep roto-translation scattering for object classification",
      "author" : [ "E. Oyallon", "S. Mallat" ],
      "venue" : null,
      "citeRegEx" : "Oyallon and Mallat,? \\Q2014\\E",
      "shortCiteRegEx" : "Oyallon and Mallat",
      "year" : 2014
    }, {
      "title" : "Why is real-world visual object recognition hard",
      "author" : [ "N. Pinto", "D.D. Cox", "J.J. DiCarlo" ],
      "venue" : "PLoS Computational Biology,",
      "citeRegEx" : "Pinto et al\\.,? \\Q2008\\E",
      "shortCiteRegEx" : "Pinto et al\\.",
      "year" : 2008
    }, {
      "title" : "Efficient learning of sparse representations with an energybased model",
      "author" : [ "M. Ranzato", "C. Poultney", "S. Chopra", "Y. LeCun" ],
      "venue" : "In Proc. of Int. Conf. on Neural Information Processing Systems (NIPS),",
      "citeRegEx" : "Ranzato et al\\.,? \\Q2006\\E",
      "shortCiteRegEx" : "Ranzato et al\\.",
      "year" : 2006
    }, {
      "title" : "Unsupervised learning of invariant feature hierarchies with applications to object recognition",
      "author" : [ "M.A. Ranzato", "F.J. Huang", "Y.L. Boureau", "Y. LeCun" ],
      "venue" : "In Proc. of IEEE Conf. Comp. Vision Pattern Recog. (CVPR),",
      "citeRegEx" : "Ranzato et al\\.,? \\Q2007\\E",
      "shortCiteRegEx" : "Ranzato et al\\.",
      "year" : 2007
    }, {
      "title" : "Object recognition with features inspired by visual cortex",
      "author" : [ "T. Serre", "L. Wolf", "T. Poggio" ],
      "venue" : "In Proc. of IEEE Conf. Comp. Vision Pattern Recog. (CVPR),",
      "citeRegEx" : "Serre et al\\.,? \\Q2005\\E",
      "shortCiteRegEx" : "Serre et al\\.",
      "year" : 2005
    }, {
      "title" : "An efficient dense descriptor applied to wide-baseline stereo",
      "author" : [ "E. Tola", "V. Lepetit", "Fua", "P. Daisy" ],
      "venue" : "IEEE Trans. Pattern Anal. Mach. Intell.,",
      "citeRegEx" : "Tola et al\\.,? \\Q2010\\E",
      "shortCiteRegEx" : "Tola et al\\.",
      "year" : 2010
    }, {
      "title" : "Robust real-time face detection",
      "author" : [ "P. Viola", "M.J. Jones" ],
      "venue" : "International Journal of Computer Vision,",
      "citeRegEx" : "Viola and Jones,? \\Q2004\\E",
      "shortCiteRegEx" : "Viola and Jones",
      "year" : 2004
    }, {
      "title" : "A mathematical theory of deep convolutional neural networks for feature extraction",
      "author" : [ "T. Wiatowski", "H. Bölcskei" ],
      "venue" : null,
      "citeRegEx" : "Wiatowski and Bölcskei,? \\Q2015\\E",
      "shortCiteRegEx" : "Wiatowski and Bölcskei",
      "year" : 2015
    } ],
    "referenceMentions" : [ {
      "referenceID" : 2,
      "context" : "Deep convolutional neural networks (DCNNs) have proven tremendously successful in a wide range of machine learning tasks (Bengio et al., 2013; LeCun et al., 2015).",
      "startOffset" : 121,
      "endOffset" : 162
    }, {
      "referenceID" : 20,
      "context" : "DCNNs are typically distinguished according to (i) whether the filters employed are learned (in a supervised (LeCun et al., 1998; Huang & LeCun, 2006; Jarrett et al., 2009) or unsupervised (Ranzato et al.",
      "startOffset" : 109,
      "endOffset" : 172
    }, {
      "referenceID" : 15,
      "context" : "DCNNs are typically distinguished according to (i) whether the filters employed are learned (in a supervised (LeCun et al., 1998; Huang & LeCun, 2006; Jarrett et al., 2009) or unsupervised (Ranzato et al.",
      "startOffset" : 109,
      "endOffset" : 172
    }, {
      "referenceID" : 29,
      "context" : ", wavelets (Serre et al., 2005; Mutch & Lowe, 2006; Mallat, 2012), or unstructured, such as random filters (Ranzato et al.",
      "startOffset" : 11,
      "endOffset" : 65
    }, {
      "referenceID" : 23,
      "context" : ", wavelets (Serre et al., 2005; Mutch & Lowe, 2006; Mallat, 2012), or unstructured, such as random filters (Ranzato et al.",
      "startOffset" : 11,
      "endOffset" : 65
    }, {
      "referenceID" : 28,
      "context" : ", 2005; Mutch & Lowe, 2006; Mallat, 2012), or unstructured, such as random filters (Ranzato et al., 2007; Jarrett et al., 2009)), (ii) the non-linearities used (e.",
      "startOffset" : 83,
      "endOffset" : 127
    }, {
      "referenceID" : 15,
      "context" : ", 2005; Mutch & Lowe, 2006; Mallat, 2012), or unstructured, such as random filters (Ranzato et al., 2007; Jarrett et al., 2009)), (ii) the non-linearities used (e.",
      "startOffset" : 83,
      "endOffset" : 127
    }, {
      "referenceID" : 23,
      "context" : "First steps towards addressing this question and developing a mathematical theory of DCNNs for feature extraction were made—for the continuous-time case—in (Mallat, 2012; Wiatowski & Bölcskei, 2015).",
      "startOffset" : 156,
      "endOffset" : 198
    }, {
      "referenceID" : 23,
      "context" : "Specifically, (Mallat, 2012) analyzed so-called scattering networks, where signals are propagated through layers that employ directional wavelet filters and modulus non-linearities but no intra-layer pooling.",
      "startOffset" : 14,
      "endOffset" : 28
    }, {
      "referenceID" : 12,
      "context" : "signals (Wiatowski & Bölcskei, 2015), cartoon functions (Grohs et al., 2016), and Lipschitz-continuous functions (Grohs et al.",
      "startOffset" : 56,
      "endOffset" : 76
    }, {
      "referenceID" : 12,
      "context" : ", 2016), and Lipschitz-continuous functions (Grohs et al., 2016), Lipschitz continuity of the feature extractor automatically leads to bounds on deformation sensitivity.",
      "startOffset" : 44,
      "endOffset" : 64
    }, {
      "referenceID" : 12,
      "context" : "Specifically, we follow the philosophy put forward in (Wiatowski & Bölcskei, 2015; Grohs et al., 2016).",
      "startOffset" : 54,
      "endOffset" : 102
    }, {
      "referenceID" : 9,
      "context" : "Specifically, we analyze the (local and global) deformation and translation sensitivity properties of feature vectors corresponding to sampled cartoon functions (Donoho, 2001).",
      "startOffset" : 161,
      "endOffset" : 175
    }, {
      "referenceID" : 22,
      "context" : "Examples of structured convolutional sets withA = B = 1 include, in the 1-D case, wavelets (Daubechies, 1992) and Weyl-Heisenberg functions (Bölcskei & Hlawatsch, 1997), and in the 2-D case, tensorized wavelets (Mallat, 2009), curvelets (Candès et al.",
      "startOffset" : 211,
      "endOffset" : 225
    }, {
      "referenceID" : 6,
      "context" : "Examples of structured convolutional sets withA = B = 1 include, in the 1-D case, wavelets (Daubechies, 1992) and Weyl-Heisenberg functions (Bölcskei & Hlawatsch, 1997), and in the 2-D case, tensorized wavelets (Mallat, 2009), curvelets (Candès et al., 2006), and shearlets (Kutyniok & Labate, 2012a).",
      "startOffset" : 237,
      "endOffset" : 258
    }, {
      "referenceID" : 20,
      "context" : "The weights {αk} k=0 can be learned (LeCun et al., 1998) or prespecified (Pinto et al.",
      "startOffset" : 36,
      "endOffset" : 56
    }, {
      "referenceID" : 26,
      "context" : ", 1998) or prespecified (Pinto et al., 2008) (e.",
      "startOffset" : 24,
      "endOffset" : 44
    }, {
      "referenceID" : 21,
      "context" : "It was argued in (Bruna & Mallat, 2013; Andén & Mallat, 2014; Oyallon & Mallat, 2014) that the features ΦΩ(f) when generated by wavelet filters, modulus non-linearities, without intra-layer pooling, and by employing output-generating atoms with low-pass characteristics, describe mel frequency cepstral coefficients (Davis & Mermelstein, 1980) in 1-D, and SIFT-descriptors (Lowe, 2004; Tola et al., 2010) in 2-D.",
      "startOffset" : 373,
      "endOffset" : 404
    }, {
      "referenceID" : 30,
      "context" : "It was argued in (Bruna & Mallat, 2013; Andén & Mallat, 2014; Oyallon & Mallat, 2014) that the features ΦΩ(f) when generated by wavelet filters, modulus non-linearities, without intra-layer pooling, and by employing output-generating atoms with low-pass characteristics, describe mel frequency cepstral coefficients (Davis & Mermelstein, 1980) in 1-D, and SIFT-descriptors (Lowe, 2004; Tola et al., 2010) in 2-D.",
      "startOffset" : 373,
      "endOffset" : 404
    }, {
      "referenceID" : 9,
      "context" : "Cartoon functions—as introduced in continuous time in (Donoho, 2001)—are piecewise “smooth” apart from curved discontinuities along Lipschitz-continuous hypersurfaces.",
      "startOffset" : 54,
      "endOffset" : 68
    }, {
      "referenceID" : 16,
      "context" : ", 2007) and the CIFAR-100 (Krizhevsky, 2009) datasets, for images of handwritten digits (LeCun & Cortes, 1998) (see Fig.",
      "startOffset" : 26,
      "endOffset" : 44
    }, {
      "referenceID" : 12,
      "context" : "Bounds on deformation sensitivity for cartoon functions in continuous-time DCNNs were recently reported in (Grohs et al., 2016).",
      "startOffset" : 107,
      "endOffset" : 127
    }, {
      "referenceID" : 13,
      "context" : "Circular convolutions with the 1-D filters underlying the tensorized wavelets are efficiently implemented using the algorithme à trous (Holschneider et al., 1989).",
      "startOffset" : 135,
      "endOffset" : 162
    }, {
      "referenceID" : 22,
      "context" : "2) wavelets (Mallat, 2009), both with J = 3 scales, the non-linearities described in Section 2.",
      "startOffset" : 12,
      "endOffset" : 26
    }, {
      "referenceID" : 4,
      "context" : "In both cases, feature importance is assessed using the Gini importance (Breiman et al., 1984), averaged over all trees.",
      "startOffset" : 72,
      "endOffset" : 94
    }, {
      "referenceID" : 1,
      "context" : "We use the Caltech 10,000 Web Faces data base (Angelova et al., 2005).",
      "startOffset" : 46,
      "endOffset" : 69
    }, {
      "referenceID" : 7,
      "context" : "Following (Dantone et al., 2012) we report the localization error, i.",
      "startOffset" : 10,
      "endOffset" : 32
    }, {
      "referenceID" : 7,
      "context" : "As an aside, we note that these values are comparable with the ones reported in (Dantone et al., 2012) for a conditional RF using patch comparison features (evaluated on a different dataset and a larger set of facial landmarks).",
      "startOffset" : 80,
      "endOffset" : 102
    }, {
      "referenceID" : 10,
      "context" : "2) follows by Young’s inequality (Folland, 2015).",
      "startOffset" : 33,
      "endOffset" : 48
    } ],
    "year" : 2016,
    "abstractText" : "First steps towards a mathematical theory of deep convolutional neural networks for feature extraction were made—for the continuous-time case— in Mallat, 2012, and Wiatowski and Bölcskei, 2015. This paper considers the discrete case, introduces new convolutional neural network architectures, and proposes a mathematical framework for their analysis. Specifically, we establish deformation and translation sensitivity results of local and global nature, and we investigate how certain structural properties of the input signal are reflected in the corresponding feature vectors. Our theory applies to general filters and general Lipschitz-continuous non-linearities and pooling operators. Experiments on handwritten digit classification and facial landmark detection—including feature importance evaluation—complement the theoretical findings.",
    "creator" : "LaTeX with hyperref package"
  }
}