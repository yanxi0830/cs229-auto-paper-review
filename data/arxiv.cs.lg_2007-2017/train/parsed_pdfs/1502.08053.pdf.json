{
  "name" : "1502.08053.pdf",
  "metadata" : {
    "source" : "META",
    "title" : "Stochastic Dual Coordinate Ascent with Adaptive Probabilities",
    "authors" : [ "Dominik Csiba" ],
    "emails" : [ "CDOMINIK@GMAIL.COM", "ZHENG.QU@ED.AC.UK", "PETER.RICHTARIK@ED.AC.UK" ],
    "sections" : [ {
      "heading" : null,
      "text" : "ar X\niv :1\n50 2.\n08 05\n3v 1\n[ m\nat h.\nO C\n] 2\n7 Fe\nb 20"
    }, {
      "heading" : "1. Introduction",
      "text" : "Empirical Loss Minimization. In this paper we consider the regularized empirical risk minimization problem:\nmin w∈Rd\n[\nP (w) def =\n1\nn\nn ∑\ni=1\nφi(A ⊤ i w) + λg(w)\n]\n. (1)\nIn the context of supervised learning,w is a linear predictor, A1, . . . , An ∈ Rd are samples, φ1, . . . , φn : Rd → R are loss functions, g : Rd → R is a regularizer and λ > 0 a regularization parameter. Hence, we are seeking to identify the predictor which minimizes the average (empirical) loss P (w).\nWe assume throughout that the loss functions are 1/γsmooth for some γ > 0. That is, we assume they are differentiable and have Lipschitz derivative with Lipschitz constant 1/γ:\n|φ′(a)− φ′(b)| ≤ 1 γ |a− b|\nfor all a, b ∈ R. Moreover, we assume that g is 1-strongly convex with respect to the L2 norm:\ng(w) ≤ αg(w1) + (1− α)g(w2)− α(1− α)\n2 ‖w1 − w2‖2\nfor all w1, w2 ∈ dom g, 0 ≤ α ≤ 1 and w = αw1 + (1 − α)w2.\nThe ERM problem (1) has received considerable attention in recent years due to its widespread usage in supervised statistical learning (Shalev-Shwartz & Zhang, 2013b). Often, the number of samples n is very large and it is important to design algorithms that would be efficient in this regime.\nModern stochastic algorithms for ERM. Several highly efficient methods for solving the ERM problem were proposed and analyzed recently. These include primal methods such as SAG (Schmidt et al., 2013), SVRG (Johnson & Zhang, 2013), S2GD (Konečný & Richtárik, 2014), SAGA (Defazio et al., 2014), mS2GD (Konečný et al., 2014a) and MISO (Mairal, 2014). Importance sampling was considered in ProxSVRG (Xiao & Zhang, 2014) and S2CD (Konečný et al., 2014b).\nStochastic Dual Coordinate Ascent. One of the most successful methods in this category is stochastic dual coordinate ascent (SDCA), which operates on the dual of the ERM problem (1):\nmax α=(α1,...,αn)∈Rn\n[\nD(α) def = −f(α)− ψ(α)\n]\n, (2)\nwhere functions f and ψ are defined by\nf(α) def = λg∗\n(\n1\nλn\nn ∑\ni=1\nAiαi\n)\n, (3)\nψ(α) def =\n1\nn\nn ∑\ni=1\nφ∗i (−αi), (4)\nand g∗ and φ∗i are the convex conjugates 1 of g and φi, respectively. Note that in dual problem, there are as many variables as there are samples in the primal: α ∈ Rn. SDCA in each iteration randomly selects a dual variable αi, and performs its update, usually via closed-form\n1By the convex (Fenchel) conjugate of a function h : R\nk → R we mean the function h∗ : Rk → R defined by h∗(u) = sup\ns {s⊤u− h(s)}.\nformula – this strategy is know as randomized coordinate descent. Methods based on updating randomly selected dual variables enjoy, in our setting, a linear convergence rate (Shalev-Shwartz & Zhang, 2013b; 2012; Takáč et al., 2013; Shalev-Shwartz & Zhang, 2013a; Zhao & Zhang, 2014; Qu et al., 2014). These methods have attracted considerable attention in the past few years, and include SCD (Shalev-Shwartz & Tewari, 2011), RCDM (Nesterov, 2012), UCDC (Richtárik & Takáč, 2014), ICD (Tappenden et al., 2013), PCDM (Richtárik & Takáč, 2012), SPCDM (Fercoq & Richtárik, 2013), SPDC (Zhang & Xiao, 2014), APCG (Lin et al., 2014), RCD (Necoara & Patrascu, 2014), APPROX (Fercoq & Richtárik, 2013), QUARTZ (Qu et al., 2014) and ALPHA (Qu & Richtárik, 2014). Recent advances on mini-batch and distributed variants can be found in (Liu & Wright, 2014), (Zhao et al., 2014b), (Richtárik & Takáč, 2013a), (Fercoq et al., 2014), (Trofimov & Genkin, 2014), (Jaggi et al., 2014), (Mareček et al., 2014) and (Mahajan et al., 2014). Other related work includes (Nemirovski et al., 2009; Duchi et al., 2011; Agarwal & Bottou, 2014; Zhao et al., 2014a; Fountoulakis & Tappenden, 2014; Tappenden et al., 2014). We also point to (Wright, 2014) for a review on coordinate descent algorithms.\nSelection Probabilities. Naturally, both the theoretical convergence rate and practical performance of randomized coordinate descent methods depends on the probability distribution governing the choice of individual coordinates. While most existing work assumes uniform distribution, it was shown by Richtárik & Takáč (2014); Necoara et al. (2012); Zhao & Zhang (2014) that coordinate descent works for an arbitrary fixed probability distribution over individual coordinates and even subsets of coordinates (Richtárik & Takáč, 2013b; Qu et al., 2014; Qu & Richtárik, 2014; Qu & Richtárik, 2014). In all of these works the theory allows the computation of a fixed probability distribution, known as importance sampling, which optimizes the complexity bounds. However, such a distribution often depends on unknown quantities, such as the distances of the individual variables from their optimal values (Richtárik & Takáč, 2014; Qu & Richtárik, 2014). In some cases, such as for smooth strongly convex functions or in the primal-dual setup we consider here, the probabilities forming an importance sampling can be explicitly computed (Richtárik & Takáč, 2013b; Zhao & Zhang, 2014; Qu et al., 2014; Qu & Richtárik, 2014; Qu & Richtárik, 2014). Typically, the theoretical influence of using the importance sampling is in the replacement of the maximum of certain data-dependent quantities in the complexity bound by the average.\nAdaptivity. Despite the striking developments in the field, there is virtually no literature on methods using an adap-\ntive choice of the probabilities. We are aware of a few pieces of work; but all resort to heuristics unsupported by theory (Glasmachers & Dogan, 2013; Lukasewitz, 2013; Schaul et al., 2013; Banks-Watson, 2012; Loshchilov et al., 2011), which unfortunately also means that the methods are sometimes effective, and sometimes not. We observe that in the primal-dual framework we consider, each dual variable can be equipped with a natural measure of progress which we call “dual residue”. We propose that the selection probabilities be constructed based on these quantities.\nOutline: In Section 2 we summarize the contributions of our work. In Section 3 we describe our first, theoretical methods (Algorithm 1) and describe the intuition behind it. In Section 4 we provide convergence analysis. In Section 5 we introduce Algorithm 2: an variant of Algorithm 1 containing heuristic elements which make it efficiently implementable. We conclude with numerical experiments in Section 6. Technical proofs and additional numerical experiments can be found in the appendix."
    }, {
      "heading" : "2. Contributions",
      "text" : "We now briefly highlight the main contributions of this work.\nTwo algorithms with adaptive probabilities. We propose two new stochastic dual ascent algorithms: AdaSDCA (Algorithm 1) and AdaSDCA+ (Algorithm 2) for solving (1) and its dual problem (2). The novelty of our algorithms is in adaptive choice of the probability distribution over the dual coordinates.\nComplexity analysis. We provide a convergence rate analysis for the first method, showing that AdaSDCA enjoys better rate than the best known rate for SDCA with a fixed sampling (Zhao & Zhang, 2014; Qu et al., 2014). The probabilities are proportional to a certain measure of dual suboptimality associated with each variable.\nPractical method. AdaSDCA requires the same computational effort per iteration as the batch gradient algorithm. To solve this issue, we propose AdaSDCA+ (Algorithm 2): an efficient heuristic variant of the AdaSDCA. The computational effort of the heuristic method in a single iteration is low, which makes it very competitive with methods based on importance sampling, such as IProxSDCA (Zhao & Zhang, 2014). We support this with computational experiments in Section 6.\nOutline: In Section 2 we summarize the contributions of our work. In Section 3 we describe our first, theoretical methods (AdaSDCA) and describe the intuition behind it. In Section 4 we provide convergence analysis. In Section 5 we introduce AdaSDCA+: a variant of AdaSDCA\ncontaining heuristic elements which make it efficiently implementable. We conclude with numerical experiments in Section 6. Technical proofs and additional numerical experiments can be found in the appendix."
    }, {
      "heading" : "3. The Algorithm: AdaSDCA",
      "text" : "It is well known that the optimal primal-dual pair (w∗, α∗) ∈ Rd×Rn satisfies the following optimality conditions:\nw∗ = ∇g∗ ( 1\nλn Aα∗\n)\n(5)\nα∗i = −∇φi(A⊤i w∗), ∀i ∈ [n] def = {1, . . . , n}, (6)\nwhere A is the d-by-n matrix with columns A1, . . . , An.\nDefinition 1 (Dual residue). The dual residue, κ = (κ1, . . . , κn) ∈ Rn, associated with (w,α) is given by:\nκi def = αi +∇φi(A⊤i w). (7)\nNote, that κti = 0 if and only if αi satisfies (5). This motivates the design of AdaSDCA (Algorithm 1) as follows: whenever |κti| is large, the ith dual coordinate αi is suboptimal and hence should be updated more often.\nDefinition 2 (Coherence). We say that probability vector pt ∈ Rn is coherent with the dual residue κt if for all i ∈ [n] we have\nκti 6= 0 ⇒ pti > 0.\nAlternatively, pt is coherent with kt if for\nIt def = {i ∈ [n] : κti 6= 0} ⊆ [n].\nwe have mini∈It p t i > 0.\nAdaSDCA is a stochastic dual coordinate ascent method, with an adaptive probability vector pt, which could potentially change at every iteration t. The primal and dual update rules are exactly the same as in standard SDCA (Shalev-Shwartz & Zhang, 2013b), which instead uses uniform sampling probability at every iteration and does not require the computation of the dual residue κ.\nOur first result highlights a key technical tool which ultimately leads to the development of good adaptive sampling distributions pt in AdaSDCA. For simplicity we denote by Et the expectation with respect to the random index it ∈ [n] generated at iteration t. Lemma 3. Consider the AdaSDCA algorithm during iteration t ≥ 0 and assume that pt is coherent with κt. Then\nEt\n[ D(αt+1)−D(αt) ] − θ ( P (wt)−D(αt) )\n≥ − θ 2λn2 ∑\ni∈It\n(\nθ(vi + nλγ)\npti − nλγ\n)\n|κti|2, (8)\nAlgorithm 1 AdaSDCA\nInit: vi = A⊤i Ai for i ∈ [n]; α0 ∈ Rn; ᾱ0 = 1λnAα0 for t ≥ 0 do\nPrimal update: wt = ∇g∗ (ᾱt) Set: αt+1 = αt Compute residue κt: κti = α t i+∇φi(A⊤i wt), ∀i ∈ [n]\nCompute probability distribution pt coherent with κt Generate random it ∈ [n] according to pt Compute:\n∆αtit = argmax ∆∈R\n{\n−φ∗it(−(αtit +∆))\n−A⊤itwt∆− vit 2λn |∆|2 }\nDual update: αt+1it = α t it +∆αtit Average update: ᾱt = ᾱt + ∆αit λn\nAit end for Output: wt, αt\nfor arbitrary\n0 ≤ θ ≤ min i∈It pti. (9)\nProof. Lemma 3 is proved similarly to Lemma 2 in (Zhao & Zhang, 2014), but in a slightly more general setting. For completeness, we provide the proof in the appendix.\nLemma 3 plays a key role in the analysis of stochastic dual coordinate methods (Shalev-Shwartz & Zhang, 2013b; Zhao & Zhang, 2014; Shalev-Shwartz & Zhang, 2013a). Indeed, if the right-hand side of (8) is positive, then the primal dual error P (wt) − D(αt) can be bounded by the expected dual ascent Et[D(αt+1)−D(αt)] times 1/θ, which yields the contraction of the dual error at the rate of 1 − θ (see Theorem 7). In order to make the right-hand side of (8) positive we can take any θ smaller than θ(κt, pt) where the function θ(·, ·) : Rn+ × Rn+ → R is defined by:\nθ(κ, p) ≡ nλγ\n∑\ni:κi 6=0 |κi|2\n∑\ni:κi 6=0 p−1i |κi|2(vi + nλγ)\n. (10)\nWe also need to make sure that 0 ≤ θ ≤ mini∈It pti in order to apply Lemma 3. A “good” adaptive probability pt should then be the solution of the following optimization problem:\nmax p∈Rn\n+\nθ(κt, p) (11)\ns.t.\nn ∑\ni=1\npi = 1\nθ(κt, p) ≤ min i:κt\ni 6=0\npi\nA feasible solution to (11) is the importance sampling (also known as optimal serial sampling) p∗ defined by:\np∗i def = vi + nλγ ∑n\nj=1 (vj + nλγ) , ∀i ∈ [n], (12)\nwhich was proposed in (Zhao & Zhang, 2014) to obtain proximal stochastic dual coordinate ascent method with importance sampling (IProx-SDCA). The same optimal probability vector was also deduced, via different means and in a more general setting in (Qu et al., 2014). Note that in this special case, since pt is independent of the residue κt, the computation of κt is unnecessary and hence the complexity of each iteration does not scale up with n.\nIt seems difficult to identify other feasible solutions to program (11) apart from p∗, not to mention solve it exactly. However, by relaxing the constraint θ(κt, p) ≤ mini:κt\ni 6=0 pi, we obtain an explicit optimal solution.\nLemma 4. The optimal solution p∗(κt) of\nmax p∈Rn\n+\nθ(κt, p) (13)\ns.t.\nn ∑\ni=1\npi = 1\nis:\n(p∗(κt))i = |κti|\n√ vi + nλγ\n∑n j=1 |κtj | √ vj + nλγ , ∀i ∈ [n]. (14)\nProof. The proof is deferred to the appendix.\nThe suggestion made by (14) is clear: we should update more often those dual coordinates αi which have large absolute dual residue |κti| and/or large Lipschitz constant vi. If we let pt = p∗(κt) and θ = θ(κt, pt), the constraint (9) may not be sastified, in which case (8) does not necessarily hold. However, as shown by the next lemma, the constraint (9) is not required for obtaining (8) when all the functions {φi}i are quadratic. Lemma 5. Suppose that all {φi}i are quadratic. Let t ≥ 0. If mini∈It p t i > 0, then (8) holds for any θ ∈ [0,+∞).\nThe proof is deferred to Appendix."
    }, {
      "heading" : "4. Convergence results",
      "text" : "In this section we present our theoretical complexity results for AdaSDCA. The main results are formulated in Theorem 7, covering the general case, and in Theorem 11 in the special case when {φi}ni=1 are all quadratic."
    }, {
      "heading" : "4.1. General loss functions",
      "text" : "We derive the convergence result from Lemma 3.\nProposition 6. Let t ≥ 0. If mini∈It pti > 0 and θ(κt, pt) ≤ mini∈It pti, then\nEt\n[ D(αt+1)−D(αt) ] ≥ θ(κt, pt) ( P (wt)−D(αt) ) .\nProof. This follows directly from Lemma 3 and the fact that the right-hand side of (8) equals 0 when θ = θ(κt, pt).\nTheorem 7. Consider AdaSDCA. If at each iteration t ≥ 0, mini∈It p t i > 0 and θ(κ t, pt) ≤ mini∈It pti, then\nE[P (wt)−D(αt)] ≤ 1 θ̃t\nt ∏\nk=0\n(1− θ̃k) ( D(α∗)−D(α0) ) ,\n(15)\nfor all t ≥ 0 where\nθ̃t def = E[θ(κt, pt)(P (wt)−D(αt))] E[P (wt)−D(αt)] . (16)\nProof. By Proposition 6, we know that\nE[D(αt+1)−D(αt)] ≥ E[θ(κt, pt)(P (wt)−D(αt))] (16) = θ̃t E[P (w\nt)−D(αt)] (17) ≥ θ̃t E[D(α∗)−D(αt)],\nwhence\nE[D(α∗)−D(αt+1)] ≤ (1− θ̃t)E[D(α∗)−D(αt)].\nTherefore,\nE[D(α∗)−D(αt)] ≤ t ∏\nk=0\n(1 − θ̃k) ( D(α∗)−D(α0) ) .\nBy plugging the last bound into (17) we get the bound on the primal dual error:\nE[P (wt)−D(αt)] ≤ 1 θ̃t E[D(αt+1)−D(αt)]\n≤ 1 θ̃t E[D(α∗)−D(αt)]\n≤ 1 θ̃t\nt ∏\nk=0\n(1− θ̃k) ( D(α∗)−D(α0) ) .\nAs mentioned in Section 3, by letting every sampling probability pt be the importance sampling (optimal serial sampling) p∗ defined in (12), AdaSDCA reduces to IProx-SDCA proposed in (Zhao & Zhang, 2014). The convergence theory established for IProx-SDCA in (Zhao & Zhang, 2014), which can also be derived as a direct corollary of our Theorem 7, is stated as follows.\nTheorem 8 ((Zhao & Zhang, 2014)). Consider AdaSDCA with pt = p∗ defined in (12) for all t ≥ 0. Then\nE[P (wt)−D(αt)] ≤ 1 θ∗ (1− θ∗)t ( D(α∗)−D(α0) ) ,\nwhere\nθ∗ = nλγ ∑n\ni=1(vi + λγn) .\nThe next corollary suggests that a better convergence rate than IProx-SDCA can be achieved by using properly chosen adaptive sampling probability. Corollary 9. Consider AdaSDCA. If at each iteration t ≥ 0, pt is the optimal solution of (11), then (15) holds and θ̃t ≥ θ∗ for all t ≥ 0.\nHowever, solving (11) requires large computational effort, because of the dimension n and the non-convex structure of the program. We show in the next section that when all the loss functions {φi}i are quadratic, then we can get better convergence rate in theory than IProx-SDCA by using the optimal solution of (13)."
    }, {
      "heading" : "4.2. Quadratic loss functions",
      "text" : "The main difficulty of solving (11) comes from the inequality constraint, which originates from (9). In this section we mainly show that the constraint (9) can be released if all {φi}i are quadratic. Proposition 10. Suppose that all {φi}i are quadratic. Let t ≥ 0. If mini∈It pti > 0, then Et [ D(αt+1)−D(αt) ] ≥ θ(κt, pt) ( P (wt)−D(αt) ) .\nProof. This is a direct consequence of Lemma 5 and the fact that the right-hand side of (8) equals 0 when θ = θ(κt, pt).\nTheorem 11. Suppose that all {φi}i are quadratic. Consider AdaSDCA. If at each iteration t ≥ 0, mini∈It pti > 0, then (15) holds for all t ≥ 0.\nProof. We only need to apply Proposition 10. The rest of the proof is the same as in Theorem 7.\nCorollary 12. Suppose that all {φi}i are quadratic. Consider AdaSDCA. If at each iteration t ≥ 0, pt is the optimal solution of (13), which has a closed form (14), then (15) holds and θ̃t ≥ θ∗ for all t ≥ 0."
    }, {
      "heading" : "5. Efficient heuristic variant",
      "text" : "Corollary 9 and 12 suggest how to choose adaptive sampling probability in AdaSDCA which yields a theoretical convergence rate at least as good as IProxSDCA (Zhao & Zhang, 2014). However, there are two main implementation issues of AdaSDCA:\n1. The update of the dual residue κt at each iteration costs O(nnz(A)) where nnz(A) is the number of nonzero elements of the matrix A;\n2. We do not know how to compute the optimal solution of (11).\nIn this section, we propose a heuristic variant of AdaSDCA, which avoids the above two issues while staying close to the ’good’ adaptive sampling distribution."
    }, {
      "heading" : "5.1. Description of Algorithm",
      "text" : "Algorithm 2 AdaSDCA+ Parameter a number m > 1 Initialization Choose α0 ∈ Rn, set ᾱ0 = 1\nλn Aα0\nfor t ≥ 0 do Primal update: wt = ∇g∗ (ᾱt) Set: αt+1 = αt\nif mod (t, n) == 0 then Option I: Adaptive probability\nCompute: κti = α t i +∇φi(A⊤i wt), ∀i ∈ [n]\nSet: pti ∼ |κti| √ vi + nλγ, ∀i ∈ [n]\nOption II: Optimal Importance probability Set: pti ∼ (vi + nλγ), ∀i ∈ [n]\nend if Generate random it ∈ [n] according to pt Compute:\n∆αtit = argmax ∆∈R\n{\n−φ∗it(−(αtit +∆))\n−A⊤itwt∆− vit 2λn |∆|2 }\nDual update: αt+1it = α t it +∆αtit Average update: ᾱt = ᾱt + ∆αit λn\nAit Probability update:\npt+1it ∼ ptit/m, p t+1 j ∼ ptj , ∀j 6= it\nend for Output: wt, αt\nAdaSDCA+ has the same structure as AdaSDCA with a few important differences.\nEpochs AdaSDCA+ is divided into epochs of length n. At the beginning of every epoch, sampling probabilities are computed according to one of two options. During each epoch the probabilities are cheaply updated at the end of every iteration to approximate the adaptive model. The intuition behind is as follows. After i is sampled and the dual coordinate αi is updated, the residue κi naturally decreases. We then decrease also the probability that i is chosen in the next iteration, by setting pt+1 to be proportional to (pt1, . . . p t i−1, p t i/m, p t i+1, . . . , p t n). By doing this we avoid the computation of κ at each iteration (issue 1) which costs as much as the full gradient algorithm, while following closely the changes of the dual residue κ. We re-\nset the adaptive sampling probability after every epoch of length n.\nParameter m The setting of parameter m in AdaSDCA+ directly affects the performance of the algorithm. If m is too large, the probability of sampling the same coordinate twice during an epoch will be very small. This will result in a random permutation through all coordinates every epoch. On the other hand, for m too small the coordinates having larger probabilities at the beginning of an epoch could be sampled more often than it should, even after their corresponding dual residues become sufficiently small. We don’t have a definitive rule on the choice of m and we leave this to future work. Experiments with different choices of m can be found in Section 6.\nOption I & Option II At the beginning of each epoch, one can choose between two options for resetting the sampling probability. Option I corresponds to the optimal solution of (13), given by the closed form (14). Option II is the optimal serial sampling probability (12), the same as the one used in IProx-SDCA (Zhao & Zhang, 2014). However, AdaSDCA+ differs significantly with IProx-SDCA since we also update iteratively the sampling probability, which as we show through numerical experiments yields a faster convergence than IProx-SDCA."
    }, {
      "heading" : "5.2. Computational cost",
      "text" : "Sampling and probability update During the algorithm we sample i ∈ [n] from non-uniform probability distribution pt, which changes at each iteration. This process can be done efficiently using the Random Counters algorithm introduced in Section 6.2 of (Nesterov, 2012), which takes O(n log(n)) operations to create the probability tree and O(log(n)) operations to sample from the distribution or change one of the probabilities.\nTotal computational cost We can compute the computational cost of one epoch. At the beginning of an epoch, we need O(nnz) operations to calculate the dual residue κ. Then we create a probability tree using O(n log(n)) operations. At each iteration we need O(log(n)) operations to sample a coordinate, O(nnz /n) operations to calculate the update to α and a further O(log(n)) operations to update the probability tree. As a result an epoch needs O(nnz+n log(n)) operations. For comparison purpose we list in Table 1 the one epoch computational cost of comparable algorithms."
    }, {
      "heading" : "6. Numerical Experiments",
      "text" : "In this section we present results of numerical experiments."
    }, {
      "heading" : "6.1. Loss functions",
      "text" : "We test AdaSDCA and AdaSDCA+, SDCA, and IProxSDCA for two different types of loss functions {φi}ni=1: quadratic loss and smoothed Hinge loss. Let y ∈ Rn be the vector of labels. The quadratic loss is given by\nφi(x) = 1\n2γ (x− yi)2\nand the smoothed Hinge loss is:\nφi(x) =\n\n \n  0 yix ≥ 1 1− yix− γ/2 yix ≤ 1− γ (1−yix) 2\n2γ otherwise,\nIn both cases we use L2-regularizer, i.e.,\ng(w) = 1\n2 ‖w‖2.\nQuadratic loss functions appear usually in regression problems, and smoothed Hinge loss can be found in linear support vector machine (SVM) problems (Shalev-Shwartz & Zhang, 2013a)."
    }, {
      "heading" : "6.2. Numerical results",
      "text" : "We used 5 different datasets: w8a, dorothea, mushrooms, cov1 and ijcnn1 (see Table 2).\nIn all our experiments we used γ = 1 and λ = 1/n.\nAdaSDCA The results of the theory developed in Section 4 can be observed through Figure 1 to Figure 4. AdaSDCA needs the least amount of iterations to converge, confirming the theoretical result.\nAdaSDCA+ V.S. others We can observe through Figure 15 to 24, that both options of AdaSDCA+ outperforms SDCA and IProx-SDCA, in terms of number of iterations, for quadratic loss functions and for smoothed Hinge loss functions. One can observe similar results in terms of time through Figure 5 to Figure 14.\nOption I V.S. Option II Despite the fact that Option I is not theoretically supported for smoothed hinge loss, it still converges faster than Option II on every dataset and for every loss function. The biggest difference can be observed on Figure 13, where Option I converges to the machine precision in just 15 seconds.\nDifferent choices of m To show the impact of different choices of m on the performance of AdaSDCA+, in Figures 25 to 33 we compare the results of the two options of AdaSDCA+ using different m equal to 2, 10 and 50. It is hard to draw a clear conclusion here because clearly the optimal m shall depend on the dataset and the problem type."
    } ],
    "references" : [ ],
    "referenceMentions" : [ ],
    "year" : 2015,
    "abstractText" : "<lb>This paper introduces AdaSDCA: an adap-<lb>tive variant of stochastic dual coordinate as-<lb>cent (SDCA) for solving the regularized empir-<lb>ical risk minimization problems. Our modifica-<lb>tion consists in allowing the method adaptively<lb>change the probability distribution over the dual<lb>variables throughout the iterative process. AdaS-<lb>DCA achieves provably better complexity bound<lb>than SDCA with the best fixed probability dis-<lb>tribution, known as importance sampling. How-<lb>ever, it is of a theoretical character as it is expen-<lb>sive to implement. We also propose AdaSDCA+:<lb>a practical variant which in our experiments out-<lb>performs existing non-adaptive methods.",
    "creator" : "LaTeX with hyperref package"
  }
}