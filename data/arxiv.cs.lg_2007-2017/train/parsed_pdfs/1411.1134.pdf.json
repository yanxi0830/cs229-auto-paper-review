{
  "name" : "1411.1134.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "Global Convergence of Stochastic Gradient Descent for Some Non-convex Matrix Problems",
    "authors" : [ "Christopher De Sa", "Kunle Olukotun" ],
    "emails" : [ "cdesa@stanford.edu,", "kunle@stanford.edu,", "chrismre@stanford.edu" ],
    "sections" : [ {
      "heading" : null,
      "text" : "ar X\niv :1\n41 1.\n11 34\nv3 [\ncs .L\nG ]\n1 0"
    }, {
      "heading" : "1 Introduction",
      "text" : "We analyze an algorithm to solve the stochastic optimization problem\nminimize E\n[\n∥ ∥ ∥Ã−X ∥ ∥ ∥ 2\nF\n]\nsubject to X ∈ Rn×n, rank (X) ≤ p,X 0, (1)\nwhere p is an integer and Ã is a symmetric matrix drawn from some distribution with bounded covariance. The solution to this problem is the matrix formed by zeroing out all but the largest p eigenvalues of the matrix E[Ã]. This problem, or problems that can be transformed to this problem, appears in a variety of machine learning applications including matrix completion [14, 25, 36], general data analysis [37], subspace tracking [6], principle component analysis [3], optimization [10, 23, 27, 29], and recommendation systems [20, 32].\nSometimes, (1) arises under conditions in which the samples Ã are sparse, but the matrix X would be too large to store and operate on efficiently; a standard heuristic to use in this case is a low-rank factorization [9]. The idea is to substitute X = Y Y T and solve the problem\nminimize E\n[\n∥ ∥ ∥Ã− Y Y T ∥ ∥ ∥ 2\nF\n]\nsubject to Y ∈ Rn×p. (2)\nBy construction, if we set X = Y Y T , then X ∈ Rn×n, rank (X) ≤ p, and X 0; this allows us to drop these constraints. Instead of having to store the matrix X (of size n2), we only need to store the matrix Y (of size np).\nIn practice, many people use stochastic gradient descent (SGD) to solve (2). Efficient SGD implementations can scale to very large datasets [2, 7, 8, 16, 24, 30, 33, 36]. However, standard stochastic gradient descent on (2) does not converge globally, in the sense that there will always be some initial values for which the norm of the iterate will diverge (see Appendix A).\nPeople have attempted to compensate for this with sophisticated methods like geodesic step rules [27] and manifold projections [1]; however, even these methods cannot guarantee global convergence. Motivated by this, we describe Alecton, an algorithm for solving (2), and analyze its convergence. Alecton is an SGDlike algorithm that has a simple update rule with a step size that is a simple function of the norm of the iterate Yk. We show that Alecton converges globally. We make the following contributions:\n• We establish the convergence rate to a global optimum of Alecton using a random initialization; in contrast, prior analyses [11, 25] have required more expensive initialization methods, such as the singular value decomposition of an empirical average of the data.\n• In contrast to previous work that uses bounds on the magnitude of the noise [21], our analysis depends only on the variance of the samples. As a result, we are able to be robust to different noise models, and we apply our technique to these problems, which did not previously have global convergence rates:\n– matrix completion, in which we observe entries of A one at a time [25, 28] (Section 4.1),\n– phase retrieval, in which we observe tr(uTAv) for randomly selected u, v [11, 13] (Section 4.3), and\n– subspace tracking, in which A is a projection matrix and we observe random entries of a random vector in its column space [6] (Section 4.4).\nOur result is also robust to different noise models.\n• We describe a martingale-based analysis technique that is novel in the space of non-convex optimization. We are able to generalize this technique to some simple regularized problems, and we are optimistic that it has more applications."
    }, {
      "heading" : "1.1 Related Work",
      "text" : "Much related work exists in the space of solving low-rank factorized optimization problems. Foundational work in this space was done by Burer and Monteiro [9, 10], who analyzed the low-rank factorization of general semidefinite programs. Their results focus on the classification of the local minima of such problems, and on conditions under which no non-global minima exist. They do not analyze the convergence rate of SGD.\nAnother general analysis in Journée et al. [27] exhibits a second-order algorithm that converges to a local solution. Their results use manifold optimization techniques to optimize over the manifold of lowrank matrices. These approaches have attempted to correct for falling off the manifold using Riemannian retractions [27], geodesic steps [6], or projections back onto the manifold. General non-convex manifold optimization techniques [1] tell us that first-order methods, such as SGD, will converge to a fixed point, but they provide no convergence rate to the global optimum. Our algorithm only involves a simple rescaling, and we are able to provide global convergence results.\nOur work follows others who have studied individual problems that we consider. Jain et al. [25] study matrix completion and provides a convergence rate for an exact recovery algorithm, alternating minimization. Candès et al. [11] provide a similar result for phase retrieval. In contrast to these results, which require expensive SVD-like operations to initialize, our results allow random initialization. Our provided convergence rates apply to additional problems and SGD algorithms that are used in practice (but are not covered\nby previous analysis). However, our convergence rates are slower in their respective settings. This is likely unavoidable in our setting, as we show that our convergence rate is optimal in this more general setting (see Appendix E).\nA related class of algorithms that are similar to Alecton is stochastic power iteration [3]. These algorithms reconsider (1) as an eigenvalue problem, and uses the familiar power iteration algorithm, adapted to a stochastic setting. Stochastic power iteration has been applied to a wide variety of problems [3, 26]. Oja [31] show convergence of this algorithm, but provides no rate. Arora et al. [4] analyze this problem, and state that “obtaining a theoretical understanding of the stochastic power method, or of how the step size should be set, has proved elusive.” Our paper addresses this by providing a method for selecting the step size, although our analysis shows convergence for any sufficiently small step size.\nShamir [35] provide exponential-rate local convergence results for a stochastic power iteration algorithm for PCA. As they note, it can be used in practice to improve the accuracy of an estimate returned by another, globally-convergent algorithm such as Alecton.\nAlso recently, Balsubramani et al. [5] and Hardt and Price [21] provide a global convergence rate for the stochastic power iteration algorithm. Our result only depends on the variance of the samples, while both their results require absolute bounds on the magnitude of the noise. This allows us to analyze a different class of noise models, which enables us to do matrix completion, phase retrieval, and subspace tracking in the same model."
    }, {
      "heading" : "2 Algorithmic Derivation",
      "text" : "We focus on the low-rank factorized stochastic optimization problem (2). We can rewrite the objective as\nE\n[ f̃(Y ) ] , with sampled objective function\nf̃(Y ) = tr ( Y Y TY Y T ) − 2tr ( Y ÃY T ) + ∥ ∥ ∥Ã ∥ ∥ ∥ 2\nF .\nIn the analysis that follows, we let A = E [ Ã ]\n, and let its eigenvalues be λ1 ≥ λ2 ≥ · · · ≥ λn with corresponding orthonormal eigenvectors u1, u2, . . . , un (such a decomposition is guaranteed since A is symmetric). The standard stochastic gradient descent update rule for this problem is, for some step size αk,\nYk+1 = Yk − αk∇f̃k(Y )\n= Yk − 4αk ( YkY T k Yk − ÃkYk ) ,\nwhere Ãk is the sample we use at timestep k. The low-rank factorization introduces symmetry into the problem. If we let\nOp = { U ∈ Rp×p | UTU = Ip }\ndenote the set of orthogonal matrices in Rp×p, then f̃(Y ) = f̃(Y U) for any U ∈ Op. Previous work has used manifold optimization techniques to solve such symmetric problems [27]. Absil et al. [1] state that stochastic gradient descent on a manifold has the general form\nxk+1 = xk − αkG−1xk ∇f̃k(xk),\nwhere Gx is the matrix such that for all u and v,\nuTGxv = 〈u, v〉x,\nwhere the right side of this equation denotes the Riemannian metric [15] of the manifold at x. For (2), the manifold in question is M = Rn×p/Op, which is the quotient manifold of Rn×p under the orthogonal group action. According to Absil et al. [1], this manifold has induced Riemannian metric\n〈U, V 〉Y = tr ( UY TY V T ) . (3)\nFor Alecton, we are free to pick any Riemannian metric and step size. Inspired by (3), we pick a new step size parameter η, and let αk = 1 4η and set\n〈U, V 〉Y = tr ( U(I + ηY TY )V T ) .\nWith this, the SGD update rule becomes\nYk+1 = Yk − η ( YkY T k Yk − ÃkYk ) ( I + ηY Tk Yk )−1\n= ( Yk ( I + ηY Tk Yk ) − η ( YkY T k Yk − ÃkYk )) ( I + ηY Tk Yk )−1\n= (\nI + ηÃk\n)\nYk ( I + ηY Tk Yk )−1 .\nFor p = 1, choosing a Riemannian metric to use with SGD results in the same algorithm as choosing an SGD step size that depends on the iterate Yk. The same update rule would result if we substituted\nαk = 1\n4 η (\n1 + ηY TY )−1\ninto the standard SGD update formula. We can think of this as the manifold results giving us intuition on how to set our step size.\nThe reason why selecting this particular step size/metric is useful in practice is that we can run the simpler update rule\nȲk+1 = ( I + ηÃk ) Ȳk. (4)\nIf Ȳ0 = Y0, the iteration will satisfy the property that the column space of Yk will always be equal to the column space of Ȳk, (since C(XY ) = C(X) for any invertible matrix Y ). That is, if we just care about computing the column space of Yk, we can do it using the much simpler update rule (4). Intuitively, we have transformed an optimization problem operating in the whole space Rn to one operating on the Grassmannian; one benefit of Alecton is that we don’t have to work on the actual Grassmannian, but get some of the same benefits from a rescaling of the Yk space. In this specific case, the Alecton update rule is akin to stochastic power iteration, since it involves a repeated multiplication by the sample; this would not hold for optimization on other manifolds.\nWe can use (4) to compute the column space (or “angular component”) of the solution, before then recovering the rest of the solution (the “radial component”) using averaging. Doing this corresponds to Algorithm 1, Alecton. Notice that, unlike most iterative algorithms for matrix recovery, Alecton does not require any special initialization phase and can be initialized randomly.\nAnalysis Analyzing this algorithm is challenging, as the low-rank decomposition also introduces symmetrical families of fixed points. Not all these points are globally optimal: in fact, a fixed point will occur whenever\nY Y T = ∑\ni∈C λiuiu\nT i\nAlgorithm 1 Alecton: Solve stochastic matrix problem Require: η ∈ R, K ∈ N, L ∈ N, and a sampling distribution A\n⊲ Angular component (eigenvector) estimation phase Select Y0 uniformly in Rn×m s.t. Y T0 Y0 = I . for k = 0 to K − 1 do\nSelect Ãk uniformly and independently at random from the sampling distribution A. Yk+1 ← Yk + ηÃkYk\nend for Ŷ ← YK ( Y TKYK )− 1 2 ⊲ Radial component (eigenvalue) estimation phase R0 ← 0 for l = 0 to L− 1 do\nSelect Ãl uniformly and independently at random from the sampling distribution A. Rl+1 ← Rl + Ŷ T ÃlŶ\nend for R̄ ← RL/L return ŷR̄ 1 2\nfor any set C of size less than p. One consequence of the non-optimal fixed points is that the standard proof of SGD’s convergence, in which we choose a Lyapunov function and show that this function’s expectation decreases with time, cannot work. This is because, if such a Lyapunov function were to exist, it would show that no matter where we initialize the iteration, convergence to a global optimum will still occur rapidly; this cannot be possible due to the presence of the non-optimal fixed points. Thus, a standard statement of global convergence, that convergence occurs uniformly regardless of initial condition, cannot hold.\nWe therefore use martingale-based methods to show convergence. Specifically, our attack involves defining a process xk with respect to the natural filtration Fk of the iteration, such that xk is a supermartingale, that is E [xk+1|Fk] ≤ xk. We then use the optional stopping theorem [17] to bound both the probability and rate of convergence of xk, from which we derive convergence of the original algorithm. We describe this analysis in the next section."
    }, {
      "heading" : "3 Convergence Analysis",
      "text" : "First, we need a way to define convergence for the angular phase. For most problems, we want C(Yk) to be as close as possible to the span of u1, u2, . . . , up. However, for some cases, this is not what we want. For example, consider the case where p = 1 but λ1 = λ2. In this case, the algorithm could not recover u1, since it is indistinguishable from u2. Instead, it is reasonable to expect C(Yk) to converge to the span of u1 and u2.\nTo handle this case, we instead want to measure convergence to the subspace spanned by some number, q ≥ p, of the algebraically largest eigenvectors (in most cases, q = p). For a particular q, let U be the projection matrix onto the subspace spanned by u1, u2, . . . , uq , and define ∆, the eigengap, as ∆ = λq − λq+1. We now let ǫ > 0 be an arbitrary error term, and define an angular success condition for Alecton.\nDefinition 1. When running the angular phase of Alecton, we say that success has occurred at timestep k if and only if for all z ∈ Rp,\n‖UYkz‖2\n‖Ykz‖2 ≥ 1− ǫ.\nThis condition requires that all members of the column space of Yk are close to the desired subspace. We say that success has occurred by time t if success has occurred for some timestep k < t. Otherwise, we say the algorithm has failed, and we let Ft denote this failure event.\nTo prove convergence, we need to put some restrictions on the problem. Our theorem requires the following three conditions.\nCondition 1 (Alecton Variance). A sampling distribution A with expected value A satisfies the Alecton Variance Condition (AVC) with parameters (σa, σr) if and only if for any y ∈ R and for any symmetric matrix W 0 that commutes with A, if Ã is sampled from A, the following bounds hold:\nE\n[ yT ÃTWÃy ]\n≤ σ2atr (W ) ‖y‖2\nand\nE\n[\n( yT Ãy )2\n]\n≤ σ2r ‖y‖4 .\nIn Section 4, we show several models that satisfy AVC.\nCondition 2 (Alecton Rank). An instance of Alecton satisfies the Alecton Rank Condition if either p = 1 (rank-1 recovery), or each sample Ã from A is rank-1 (rank-1 sampling).\nMost of the noise models we analyze have rank-1 samples, and so satisfy the rank condition.\nCondition 3 (Alecton Step Size). Define γ as\nγ = 2nσ2ap 2(p+ ǫ)\n∆ǫ η.\nThis represents a constant step size parameter that is independent of problem scaling. An instance of Alecton satisfies the Alecton Step Size Condition if and only if γ ≤ 1.\nNote that the step size condition is only an upper bound on the step size. This means that, even if we do not know the problem parameters exactly, we can still choose a feasible step size as long as we can bound them. (However, smaller step sizes imply slower convergence, so it is a good idea to choose η as large as possible.)\nWe will now define a useful function, then state our main theorem that bounds the probability of failure.\nDefinition 2. For some p, let R ∈ Rp×p be a random matrix the entries of which are independent standard normal random variables. Define function Zp as\nZp(γ) = 2 ( 1−E [ ∣ ∣I + γp−1(RTR)−1 ∣ ∣ −1]) .\nTheorem 1. Assume that we run an instance of Alecton that satisfies the variance, rank, and step size conditions. Then for any t, the probability that the angular phase will have failed up to time t is\nP (Ft) ≤ Zp(γ) + 4nσ2ap 2(p+ ǫ)\n∆2γǫt log\n(\nnp2\nγqǫ\n)\n. (5)\nAlso, in the radial phase, for any constant ψ it holds that\nP\n(\n∥ ∥ ∥R̄− Ŷ TAŶ ∥ ∥ ∥ 2\nF ≥ ψ\n)\n≤ p 2σ2r Lψ .\nIn particular, if σa∆−1 does not vary with n, this theorem implies convergence of the angular phase with constant probability after O(ǫ−1np3 log n) iterations and in the same amount of time. Note that since we do not reuse samples in Alecton, our rates do not differentiate between sampling and computational complexity, unlike many other algorithms (see Appendix B). We also do not consider numerical error or overflow: periodically re-normalizing the iterate may be necessary to prevent these in an implementation of Alecton.\nSince the upper bound expression uses Zp, which is obscure, we plot it here (Figure 1). We also can make a more precise statement about the failure rate for p = 1.\nLemma 1. For the case of rank-1 recovery,\nZ1(γ) = √ 2πγ exp (γ\n2\n)\nerfc\n( √\nγ\n2\n)\n≤ √ 2πγ."
    }, {
      "heading" : "3.1 Martingale Technique",
      "text" : "A proof for Theorem 1 and full formal definitions will appear in Appendix C of this document, but since the method is nonstandard for non-convex optimization (although it has been used in Shamir [34] to show convergence for convex problems), we will outline it here. First, we define a failure event fk at each timestep, that occurs if the iterate gets “too close” to the unstable fixed points. Next, we define a sequence τk, where\nτk =\n∣ ∣Y Tk UYk ∣ ∣\n∣ ∣Y Tk (γn −1p−2qI + (1− γn−1p−2q)U)Yk ∣ ∣\n(where |X| denotes the determinant of X); the intuition here is that τk is close to 1 if and only if success occurs, and close to 0 when failure occurs. We show that, if neither success nor failure occurs at time k,\nE [τk+1|Fk] ≥ τk (1 +R (1− τk)) (6)\nfor some constant R; here, Fk denotes the filtration at time k, which contains all the events that have occurred up to time k [17]. If we let T denote the first time at which either success or failure occurs, then this implies that τk is a submartingale for k < T . We use the optional stopping Theorem [17] (here we state a discrete-time version).\nDefinition 3 (Stopping Time). A random variable T is a stopping time with respect to a filtration Fk if and only if {T ≤ k} ∈ Fk for all k. That is, we can tell whether T ≤ k using only events that have occurred up to time k.\nTheorem 2 (Optional Stopping Theorem). If xk is a martingale (or submartingale) with respect to a filtration Fk, and T is a stopping time with respect to the same filtration, then xk∧T is also a martingale (resp. submartingale) with respect to the same filtration, where k ∧ T denotes the minimum of k and T . In particular, for bounded submartingales, this implies that E [x0] ≤ E [xT ].\nHere, T is a stopping time since it depends only on events occurring before timestep T . Applying this to the submartingale τk results in\nE [τ0] ≤ E [τT ] = E [τT |FT ]P (fT ) +E [τT |¬FT ] (1− P (fT ))\n≤ δP (fT ) + (1− P (fT )).\nThis isolates the probability of the failure event occurring. Next, subtracting 1 from both sides of (6) and taking the logarithm results in\nE [log (1− τk+1)|Fk] ≤ log(1− τk) + log (1−Rτk) ≤ log(1− τk)−Rδ.\nSo, if we let Wk = log(1− τk) +Rδk, then Wk is a supermartingale. We again apply the optional stopping theorem to produce E [W0] ≥ E [WT ] = E [log(1− τT )] +RδE [T ] . This isolates the expected value of the stopping time. Finally, we notice that success occurs before time t if T ≤ t and fT does not occur. By the union bound, this implies that\nPfailure ≤ P (fT ) + P (T ≤ t) ,\nand by Markov’s inequality, Pfailure ≤ P (fT ) + t−1E [T ] .\nSubstituting the isolated values for P (fT ) and E [T ] produces the expression above in (5).\nThe radial part of the theorem follows from an application of Chebychev’s inequality to the average of L samples of ŷT Ãŷ — we do not devote any discussion to it since averages are already well understood."
    }, {
      "heading" : "4 Application Examples",
      "text" : ""
    }, {
      "heading" : "4.1 Entrywise Sampling",
      "text" : "One sampling distribution that arises in many applications (most importantly, matrix completion [12]) is entrywise sampling. This occurs when the samples are independently chosen from the entries of A. Specifically,\nÃ = n2eie T i Aeje T j ,\nwhere i and j are each independently drawn from 1, . . . , n. It is standard for these types of problems to introduce a matrix coherence bound [25].\nDefinition 4. A matrix A ∈ Rn×n is incoherent with parameter µ if and only if for every unit eigenvector ui of the matrix, and for all standard basis vectors ej ,\n∣ ∣eTj ui ∣ ∣ ≤ µn− 12 .\nUnder an incoherence assumption, we can provide a bound on the second moment of Ã, which is all that we need to apply Theorem 1 to this problem.\nLemma 2. If A is incoherent with parameter µ, and Ã is sampled uniformly from the entries of A, then the distribution of Ã satisfies the Alecton variance condition with parameters σ2a = µ\n4 ‖A‖2F and σ2r = µ4tr (A)2.\nFor problems in which the matrix A is of constant rank, and its eigenvalues do not vary with n, neither ‖A‖F nor tr (A) will vary with n. In this case, σ2a, σ2r , and ∆ will be constants, and the O(ǫ−1n log n) bound on convergence time will hold."
    }, {
      "heading" : "4.2 Rectangular Entrywise Sampling",
      "text" : "Entrywise sampling also commonly appear in rectangular matrix recovery problems. In these cases, we are trying to solve something like\nminimize ‖M −X‖2F subject to X ∈ Rm×n, rank (X) ≤ p.\nTo solve this problem using Alecton, we first convert it into a symmetric matrix problem by constructing the block matrix\nA =\n[\n0 M MT 0\n]\n;\nit is known that recovering the dominant eigenvectors of A is equivalent to recovering the dominant singular vectors of M .\nEntrywise sampling on M corresponds to choosing a random i ∈ 1, . . . ,m and j ∈ 1, . . . , n, and then sampling Ã as\nÃ = mnMij(eie T m+j + em+je T i ).\nIn the case where we can bound the entries of M (this is natural for recommender systems), we can prove the following.\nLemma 3. If M ∈ Rm×n satisfies the entry bound\nM2ij ≤ ξm−1n−1 ‖M‖2F\nfor all i and j, then the rectangular entrywise sampling distribution on M satisfies the Alecton variance condition with parameters\nσ2a = σ 2 r = 2ξ ‖M‖2F .\nAs above, for problems in which the singular values of M do not vary with problem size, our big-O convergence time bound will still hold."
    }, {
      "heading" : "4.3 Trace Sampling",
      "text" : "Another common sampling distribution arises from the matrix sensing problem [25]. In this problem, we are given the value of vTAw for unit vectors v and w selected uniformly at random. (This problem has been handled for the more general complex case in [11] using Wirtinger flow.) Using a trace sample, we can construct an unbiased sample\nÃ = n2vvTAwwT .\nThis lets us bound the variance as follows.\nLemma 4. If n > 50, and v and w are sampled uniformly from the unit sphere in Rn, then for any positive semidefinite matrix A, if we let Ã = n2vvTAwwT , then the distribution of Ã satisfies the Alecton variance condition with parameters σ2a = 16 ‖A‖2F and σ2r = 16tr (A) 2.\nAs above, for problems in which the eigenvalues of A do not vary with problem size, our big-O convergence time bound will still hold.\nIn some cases of the trace sampling problem, instead of being given samples of the form uTAv, we know uTAu. In this case, we need to use two independent samples uT1 Au1 and u T 2 Au2, and let u ∝ u1 + u2 and v ∝ u1 − u2 be two unit vectors which we will use in the above sampling scheme. Notice that since u1 and u2 are independent and uniformly distributed, u and v will also be independent and uniformly distributed (by the spherical symmetry of the underlying distribution). Furthermore, we can compute\nuTAv = (u1 + u2) TA(u1 − u2) = uT1 Au1 − uT2 Au2.\nThis allows us to use our above trace sampling scheme even with samples of the form uTAu."
    }, {
      "heading" : "4.4 Subspace Sampling",
      "text" : "Our analysis can handle more complicated sampling schemes. Consider the following distribution, which arises in subspace tracking [6]. Our matrix A is a rank-r projection matrix, and each sample consists of some randomly-selected entries from a randomly-selected vector in its column space. Specifically, we are given Qv and Rv, where v is some vector selected uniformly at random from C(A), and Q and R are independent random diagonal projection matrices with expected value mn−1I . Using this, we can construct the distribution\nÃ = rn2m−2QvvTR.\nThis distribution is unbiased since E [ qvvT ]\n= A. When bounding its second moment, we run into the same coherence problem as we did in the entrywise case, which motivates us to introduce a coherence constraint for subspaces.\nDefinition 5. A subspace of Rn of dimension q with associated projection matrix U is incoherent with parameter µ if and only if for all standard basis vectors ei,\n‖Uei‖2 ≤ µrn−1.\nUsing this, we can prove the following facts about the second moment of this distribution.\nLemma 5. The subspace sampling distribution, when sampled from a subspace that is incoherent with parameter µ, satisfies the Alecton variance condition with parameters\nσ2a = σ 2 r = r 2(1 + µrm−1)2.\nIn many cases of subspace sampling, we are given just some entries of v at each timestep (as opposed to two separate random sets of entries associated with Q and R). That is, we are given a random diagonal projection matrix S, and the product Sv. We can use this to construct a sample of the above form by randomly splitting the given entries among Q and R in such a way that Q = QS and R = RS, and Q and R are independent. We can then construct an unbiased sample as\nÃ = rn2m−2QSvvTSR,\nwhich uses only the entries of v that we are given."
    }, {
      "heading" : "4.5 Noisy Sampling",
      "text" : "Since our analysis depends only on a variance bound, it is straightforward to handle the case in which the values of our samples themselves are noisy. Using the additive property of the variance for independent random variables, we can show that additive noise only increases the variance of the sampling distribution by a constant amount proportional to the variance of the noise. Similarly, using the multiplicative property of the variance for independent random variables, multiplicative noise only multiplies the variance of the sampling distribution by a constant factor proportional to the variance of the noise. In either case, we can show that the noisy sampling distribution satisfies AVC."
    }, {
      "heading" : "4.6 Extension to Higher Ranks",
      "text" : "It is possible to use multiple iterations of the rank-1 version of Alecton to recover additional eigenvalue/eigenvector pairs of the data matrix A one-at-a-time. This is a standard technique for using power iteration algorithms to recover multiple eigenvalues. Sometimes, this may be preferable to using a single higher-rank invocation of Alecton (for example, we may not know a priori how many eigenvectors we want). We outline this technique as Algorithm 2. This strategy allows us to recover the largest p eigenvectors of A using p executions\nAlgorithm 2 Alecton One-at-a-time Require: A sampling distribution A\nA1 → A for i = 1 to p do\n⊲ Run rank-1 Alecton to produce output yi. yi → Alectonp=1(Ai) Generate sampling distribution Ai+1 such that, if Ã′ is sampled from Ai+1 and Ã is sampled from Ai, E [ Ã′ ] = E [ Ã ]\n− yiyTi . end for return\n∑p i=1 yiy T i\nof Alecton. If the eigenvalues of the matrix are independent of n and p, we will be able to accomplish this in O(ǫ−1pn log n) total steps."
    }, {
      "heading" : "5 Experiments",
      "text" : "We experimentally verify our main claim, that Alecton does converge quickly for practical datasets. All experiments were run on a machine with a single twelve-core socket (Intel Xeon E5-2697, 2.70GHz), and 256 GB of shared memory. All were written in C++, excepting the Netflix Prize problem experiment, which was written in Julia. No data was collected for the radial phase of Alecton, since the performance of averaging is already well understood.\nThe first experiments were run on randomly-generated rank-10 data matrices A ∈ Rn×n. Each was generated by selecting a random orthogonal matrix U ∈ Rn×n, then independently selecting a diagonal matrix Λ with 10 positive nonzero eigenvalues, and constructing A = UΛU ′. Figure 2(a) illustrates the convergence of Alecton with p = q = 1 using three sampling distributions on datasets with n = 104. We ran Alecton starting from five random initial values; the different plotted trajectories illustrate how convergence time can depend on the initial value.\nFigure 2(b) illustrates the performance of Alecton (p = q = 1 again) on a larger dataset with n = 106 as the step size parameter η is varied. As we would expect, a smaller value of η yields slower, but more\naccurate convergence. Also notice that the smaller the value of η, the more the initial value seems to affect convergence time.\nFigure 3 demonstrates convergence results on real data from the Netflix Prize problem. This problem involves recovering a matrix with 480,189 columns and 17,770 rows from a training dataset containing 110,198,805 revealed entries. We used the rectangular entrywise distribution described above, then ran Alecton with η = 10−12 and p = q = 1 for ten million iterations to recover the most significant singular vector. Next, we used Algorithm 2 to recover additional singular vectors of the matrix, up to a maximum of p = 12. The absolute runtime and RMS errors after the recovery of each subsequent eigenvector are plotted in Figure 3. This plot illustrates that the runtime of the one-at-a-time algorithm does not increase disastrously as the number of recovered eigenvectors expands."
    }, {
      "heading" : "5.1 Discussion",
      "text" : "The Hogwild! algorithm [30] is a parallel, lock-free version of stochastic gradient descent that has been shown to perform similarly to sequential SGD on convex problems, while allowing for a good parallel speedup. It is an open question whether a Hogwild! version of Alecton for non-convex problems converges with a good rate, but we are optimistic that it will."
    }, {
      "heading" : "6 Conclusion",
      "text" : "This paper exhibited Alecton, a stochastic gradient descent algorithm applied to a non-convex low-rank factorized problem; it is similar to the algorithms used in practice to solve a wide variety of problems. We prove that Alecton converges globally, and provide a rate of convergence. We do not require any special initialization step but rather initialize randomly. Furthermore, our result depends only on the variance of the samples, and therefore holds under broad sampling conditions that include both matrix completion and matrix sensing, and is also able to take noisy samples into account. We show these results using a martingale-based technique that is novel in the space of non-convex optimization, and we are optimistic that this technique can be applied to other problems in the future."
    }, {
      "heading" : "A Negative Results",
      "text" : "Divergence Example Here, we observe what happens when we choose a constant step size for stochastic gradient descent for quartic objective functions. Consider the simple optimization problem of minimizing\nf(x) = 1\n4 x4.\nThis function will have gradient descent update rule\nxk+1 = xk − αkx3k = ( 1− αkx2k ) xk.\nWe now prove that, for any reasonable step size rule chosen independently of xk, there is some initial condition such that this iteration diverges to infinity.\nProposition 1. Assume that we iterate using the above rule, for some choice of αk that is not superexponentially decreasing; that is, for some C > 1 and some α > 0, αk ≥ αC−2k for all k. Then, if x20 ≥ α−1(C + 1), for all k\nx2k > α −1C2k(C + 1).\nProof. We will prove this by induction. The base case follows directly from the assumption, while under the inductive case, if the proposition is true for k, then\nαkx 2 k ≥ αC−2kα−1C2k(C + 1) = C + 1.\nTherefore, x2k+1 = ( αkx 2 k − 1 )2 x2k\n≥ C2x2k ≥ C2α−1C2k(C + 1) = α−1C2(k+1)(C + 1).\nThis proves the statement.\nThis proof shows that, for some choice of x0, xk will diverge to infinity exponentially quickly. Furthermore, no reasonable choice of αk will be able to halt this increase for all initial conditions. We can see the effect of this in stochastic gradient descent as well, where there is always some probability that, due to an unfortunate series of gradient steps, we will enter the zone in which divergence occurs. On the other hand, if we chose step size αk = γkx −2 k , for some 0 < γk < 2, then\nxk+1 = (1− γk)xk,\nwhich converges for all starting values of xk. This simple example is what motivates us to take ‖Yk‖ into account when choosing the step size for Alecton.\nGlobal Convergence Counterexample We now exhibit a particular problem for which SGD on a lowrank factorization doesn’t converge to the global optimum for a particular starting point. Let matrix A ∈ R 2×2 be the diagonal matrix with diagonal entries 4 and 1. Further, let’s assume that we are trying to minimize the expected value of the decomposed rank-1 objective function\nf̃(y) = ∥ ∥ ∥Ã− yyT ∥ ∥ ∥\nF = ‖y‖4 − 2yT Ãy +\n∥ ∥ ∥Ã ∥ ∥ ∥ 2\nF .\nIf our stochastic samples satisfy Ã = A (i.e. we use a perfect sampler), then the SGD update rule is\nyk+1 = yk − αk∇f̃(yk) = yk − 4αk ( yk ‖yk‖2 −Ayk ) .\nNow, we know that e1 is the most significant eigenvector of A, and that y = 2e1 is the global solution to the problem. However,\neT1 yk+1 = e T 1 yk − 4αk\n( eT1 yk ‖yk‖2 − eT1 Ayk )\n= ( 1− 4αk ( ‖yk‖2 − 4 )) eT1 yk\n. This implies that if eT1 y0 = 0, then e T 1 yk = 0 for all k, which means that convergence to the global optimum cannot occur. This illustrates that global convergence does not occur for all manifold optimization problems using a low-rank factorization and for all starting points.\nConstraints Counterexample We might think that our results can be generalized to give O(n log n) convergence of low-rank factorized problems with arbitrary constraints. Here, we show that this will not work for all problems by encoding an NP-complete problem as a constrained low-rank optimization problem.\nFor any graph with node set N and edge set E, the MAXCUT problem on the graph requires us to solve\nminimize ∑\n(i,j)∈E yiyj subject to yi ∈ {−1, 1}.\nAlgorithm Sampling Scheme Complexity\nSampling Computational\nAlecton Any O(ǫ−1p3n log n)\nSVD Various o(pn) O(n3)\nSpectral Matrix Completion [28] Elementwise o(pn) O(p2n log n)\nPhaseLift [13] Phase Retrieval o(n) O(ǫ−1n3)\nAlternating Minimization [41] Phase Retrieval o(n log(ǫ−1)) O(n2 log2(ǫ−1))\nWirtinger Flow [11] Phase Retrieval o(n log2 n) O(pn log(ǫ−1))\nEquivalently, if we let A denote the edge-matrix of the graph, we can represent this as a matrix problem [19, 22]\nminimize yTAy subject to yi ∈ {−1, 1}.\nWe relax this problem to minimize yTAy subject to −1 ≤ yi ≤ 1.\nSince the diagonal of A is zero, if we fix all but one of the entries of y, the objective function will have an affine dependence on that entry. In particular, this means that a global minimum of the problem must occur on the boundary where yi ∈ {−1, 1}, which implies that this problem has the same global solution as the original MAXCUT problem. Furthermore, for sufficiently large values of σ, the problem\nminimize ‖y‖4 + 2σyTAy + σ2 ‖A‖2F subject to −1 ≤ yi ≤ 1\nwill also have the same solution. But, this problem is in the same form as a low-rank factorization of\nminimize ‖X + σA‖2F subject to Xii ≤ 1,X 0, rank (X) = 1\nwhere X = yyT . Since MAXCUT is NP-complete, it can’t possibly be the case that SGD applied to this low-rank factorized problem converges quickly to the global optimum, because that would imply an efficient solution to this NP-complete problem. This suggests that care will be needed when analyzing problems with constraints, in order to exclude these sorts of cases."
    }, {
      "heading" : "B Comparison with Other Methods",
      "text" : "There are several other algorithms that solve similar matrix recover problems in the literature. In Table B, we list some other algorithms, and their convergence rates, in terms of both number of samples required (sampling complexity) and number of iterations performed (computational complexity). For this table, the data is assumed to be of dimension n, and the rank (where applicable) is assumed to be p. (In order to save space, factors of log log ǫ−1 have been omitted from some formulas.)"
    }, {
      "heading" : "C Proofs of Main Results",
      "text" : "In this appendix, we provide rigorous definitions and detail the proof outlined in Section 3.1.\nC.1 Definitions\nFleming and Harrington [17] provide the following definitions of filtration and martingale. We state the definitions adapted to the discrete-time case.\nDefinition 6 (Filtration). Given a measurable probability space (Ω,F), a filtration is a sequence of sub-σalgebras {Ft} for t ≥ 0, such that for all s ≤ t,\nFs ⊂ Ft.\nThat is, if an event A is in Fs, and t ≥ s, then A is also in Ft. This definition encodes the monotonic increase in available information over time.\nDefinition 7 (Martingale). Let {Xt} be a stochastic process and {Ft} be a filtration over the same probability space. Then X is called a martingale with respect to the filtration if for every t, Xt is Ft-measurable, and E [Xt+1|Ft] = Xt. (7) We call X a submartingale if the same conditions hold, except (7) is replaced with\nE [Xt+1|Ft] ≥ Xt.\nWe call X a supermartingale if the same conditions hold, except (7) is replaced with\nE [Xt+1|Ft] ≤ Xt.\nC.2 Preliminaries\nIn addition to the quantities used in the statement of Theorem 1, we let\nW = γn−1p−2qI + (1− γn−1p−2q)U,\nand define sequences τk and φk as\nτk =\n∣ ∣Y Tk UYk ∣ ∣ ∣ ∣Y Tk WYk ∣ ∣ ,\nand φk = tr ( I − Y Tk UYk ( Y Tk WYk )−1) .\nThis agrees with the definition of τk stated in the body of the paper. Using this sequence, we define the failure event fk as the event that occurs when\nτk ≤ 1\n2 . (8)\nWe recall that we defined the success event at time k as the event that, for all z ∈ Rp,\n‖UYkz‖2\n‖Ykz‖2 ≥ 1− ǫ.\nFinally, we define T , the stopping time, to be the first time at which either the success event or the failure event occurs.\nNow, we state some lemmas we will need in the following proofs. We defer proofs of the lemmas themselves to Appendix D. First, we state a lemma about quadratic rational functions that we will need in the next section.\nLemma 6 (Quadratic rational lower bound). For any a, b, c, and d in R, if 1+by+cy2 > 0 and 1+ay+dy2 ≥ 0 for all y, then for all x ∈ R,\n1 + ax+ dx2 1 + bx+ cx2 ≥ 1 + (a− b)x− cx2.\nNext, a lemma about the expected initial value of τ :\nLemma 7. If we initialize Y0 uniformly as in the Alecton algorithm, then\nE [τ0] ≥ 1− 1\n2 Zp(γ).\nNext, a lemmas that bounds a determinant expression.\nLemma 8. For any B ∈ Rn×n, Y ∈ Rn×m, and any symmetric positive-semidefinite Z ∈ Rn×n, if either B is rank-1 or m = 1, then\n∣ ∣Y T (I +B)TZ(I +B)Y ∣ ∣\n≥ ∣ ∣Y TZY ∣ ∣ ( tr ( Y (Y TZY )−1Y TZB ) + 1 )2\nand ∣\n∣Y T (I +B)TZ(I +B)Y ∣ ∣\n≤ ∣ ∣Y TZY ∣ ∣\n(\n1 + 2tr ( Y (Y TZY )−1Y TZB )\n+ tr ( Y (Y TZY )−1Y TBTZB )\n)\n.\nNext, a lemma that bounds τ in the case that the success condition does not occur.\nLemma 9. If we run Alecton, and at timestep k, the success condition does not hold, then\nτk ≤ 1− γn−1p−2qǫ.\nFinally, a lemma that relates φ and τ .\nLemma 10. Using the definitions above, for all k,\nφk ≥ 1− τk.\nC.3 Main Proofs\nWe now proceed to prove Theorem 1 in six steps, as outlined in Section 3.1.\n• First, we prove Lemma 11, the dominant mass bound lemma, which bounds E [τk+1|Fk] from below by a quadratic function of the step size η.\n• We use this to prove Lemma 12, which establishes the result stated in (6).\n• We use the optional stopping theorem to prove Lemma 13, which bounds the probability of a failure event occurring before success.\n• We use the optional stopping theorem again to prove Lemma 14, which bounds the expected time until either a failure or success event occurs.\n• We use Markov’s inequality and the union bound to bound the angular failure probability of Theorem 1.\n• Finally, we prove the radial phase result stated in Theorem 1.\nLemma 11 (Dominant Mass Bound). If we run Alecton under the conditions of Theorem 1, then for any k,\nE [τk+1|Fk] ≥ τk ( 1 + 2η ( ∆− ησ2aγ−1np2 ) (1− τk)\n− η2σ2ap(q + 1) ) .\nProof. From the definition of τ , at the next timestep we will have\nτk+1 =\n∣ ∣Y Tk+1UYk+1 ∣ ∣ ∣ ∣Y Tk+1WYk+1 ∣ ∣\n=\n∣ ∣ ∣ ∣ Y Tk ( I + ηÃk )T U ( I + ηÃk ) Yk ∣ ∣ ∣ ∣\n∣ ∣ ∣ ∣ Y Tk ( I + ηÃk )T W ( I + ηÃk ) Yk ∣ ∣ ∣ ∣\n.\nNow, since our instance of Alecton satisfies the rank condition, either Ãk is rank-1 or p = 1. Therefore, we can apply Lemma 8 to these determinant quantities. In order to produce a lower bound on τk+1, we will apply lower bound to the numerator and the upper bound to the denominator. If we let Bk = Yk(Y Tk UYk)\n−1Y Tk , and Ck = Yk(Y Tk WYk) −1Y Tk , then this results in\nτk+1 ≥ ∣ ∣Y Tk UYk ∣ ∣ ∣\n∣Y Tk WYk ∣ ∣\n·\n( 1 + ηtr (\nBkUÃk\n))2\n1 + 2ηtr (\nCkWÃk\n) + η2tr (\nCkÃ T kWÃk\n) .\nNext, we apply Lemma 6, which results in\nτk+1 ≥ τk ( 1 + 2η ( tr ( BkUÃk ) − tr ( CkWÃk ))\n− η2tr (\nCkÃ T kWÃk\n))\n≥ τk ( 1 + 2ηRk + η 2Qk ) ,\nfor sequences Rk and Qk. Now, we investigate the expected values of these sequences. First, since the estimator has E [\nÃk\n∣ ∣ ∣ Fk ] = A, the expected value of Rk is\nE [Rk|Fk] = tr (BkUA)− tr (CkWA) = tr ((Bk − Ck)UA)\n− γn−1p−2qtr (Ck(I − U)A) .\nNow, since U commutes with A, we will have that\nUA λqU,\nand similarly (I − U)A λq+1(I − U).\nApplying this results in\nE [Rk|Fk] ≥ tr (BkUA)− tr (CkWA) = λqtr ((Bk −Ck)U)\n− λq+1γn−1p−2qtr (Ck(I − U)) .\nNow, we first notice that\ntr ((Bk − Ck)U) = tr ( I − YkUY Tk (Y Tk WYk)−1 )\n= φk.\nWe also notice that\nγn−1p−2qtr (Ck(I − U)) = tr (Ck(W − U)) = tr (\nI − YkUY Tk (Y Tk WYk)−1 )\n= φk.\nIt therefore follows that\nE [Rk|Fk] ≥ (λq − λq+1)φk = ∆φk.\nNext, the expected value of Qk is\nE [Qk|Fk] = tr ( CkE [ ÃTkWÃk ]) .\nSince our instance of Alecton satisfies the variance condition, and W commutes with A,\nE [Qk|Fk] ≤ σ2atr (W ) tr (Ck) .\nWe notice that\ntr (Ck) = tr ( Ck ( W + (1− γn−1p−2q)(I − U) ))\n= p+ (1− γn−1p−2q)tr (Ck(I − U)) ≤ p+ tr (Ck(I − U)) .\nBy the logic above,\ntr (Ck) ≤ p+ γ−1np2q−1φk.\nAlso,\ntr (W ) = tr ( γn−1p−2qI + (1− γn−1p−2q)U )\n= γp−2q + q − γn−1p−2q2\n≥ q + 1\nand therefore, since tr (W ) ≤ q + 1,\nE [Qk|Fk] ≤ σ2a(q + 1) ( p+ γ−1np2q−1φk ) .\nSubstituting these in results in\nE [τk+1|Fk] ≥ τk ( 1 + 2η∆φk − η2 ( σ2ap(q + 1) + σ 2 aγ −1np2(q + 1)q−1φk ))\n= τk ( 1 + η ( 2∆ − ησ2aγ−1np2(q + 1)q−1 ) φk − η2σ2ap(q + 1) ) ≥ τk ( 1 + 2η ( ∆− ησ2aγ−1np2 ) φk − η2σ2ap(q + 1) ) .\nFinally, since for our chosen value of γ,\n∆ > ησ2aγ −1np2,\nwe can apply Lemma 10, which produces\nE [τk+1|Fk] ≥ τk ( 1 + 2η ( ∆− ησ2aγ−1np2 ) (1− τk)\n− η2σ2ap(q + 1) ) .\nThis is the desired expression.\nLemma 12. If we run Alecton under the conditions of Theorem 1, then for any time k at which neither the success event nor the failure event occur,\nE [τk+1|Fk] ≥ τk (1 + η∆(1− τk)) .\nProof. From the result of Lemma 11,\nE [τk+1|Fk] ≥ τk ( 1 + 2η ( ∆− ησ2aγ−1np2 ) (1− τk)− η2σ2ap(q + 1) )\n= τk ( 1 + η∆(1 − τk) + η ( ∆− 2ησ2aγ−1np2 ) (1− τk)− η2σ2ap(q + 1) ) = τk (1 + η∆(1− τk) + ηSk, )\nfor sequence Sk. Now, it can be easily verified that we chose γ such that\n∆ ≥ 2ησ2aγ−1np2,\nand so it follows that, by Lemma 9,\nSk = ( ∆− 2ησ2aγ−1np2 ) (1− τk)− ησ2ap(q + 1) ≥ (\n∆− 2ησ2aγ−1np2 ) γn−1p−2qǫ− ησ2ap(q + 1) = ∆γn−1p−2qǫ− 2ησ2aqǫ− ησ2ap(q + 1) ≥ ∆γn−1p−2qǫ− 2ησ2aq(p+ ǫ).\nIf we substitute the value of γ,\nγ = 2nσ2ap 2(p+ ǫ)\n∆ǫ η.\nthen we arrive at Sk ≥ 0.\nSubstituting this in to our original expression produces\nE [τk+1|Fk] ≥ τk (1 + η∆(1− τk)) ,\nas desired.\nLemma 13 (Failure Probability Bound). If we run Alecton under the conditions of Theorem 1, then the probability that the failure event will occur before the success event is\nP (fT ) ≤ Zp(γ).\nProof. To prove this, we use the stopping time T , which we defined as the first time at which either the success event or failure event occurs. First, if k < T , it follows that neither success nor failure have occurred yet, so we can apply Lemma 12, which results in\nE [τk+1|Fk] ≥ τk (1 + η∆(1− τk)) .\nTherefore τk is a supermartingale for k < T . So, we can apply the optional stopping theorem, which produces E [τ0] ≤ E [τT ] . So, by the law of total expectation,\nE [τ0] ≤ E [τT |fT ]P (fT ) +E [τT |¬fT ]P (¬fT ) ,\nwhere fT is the failure event at time T . Applying the definition of the failure event from (8),\nE [τ0] ≤ 1\n2 P (fT ) + 1\n( 1− P (fT ) ) .\nTherefore, solving for P (fT ),\nP (fT ) ≤ 2 (1−E [τ0]) .\nNow applying Lemma 7,\nP (fT ) ≤ 2 ( 1− ( 1− 1 2 Zp(γ) )) = Zp(γ),\nas desired.\nLemma 14 (Stopping Time Expectation). If we run Alecton under the conditions of Theorem 1, then the expected value of the stopping time T will be\nE [T ] ≤ 4nσ 2 ap 2(p+ ǫ)\n∆2γǫ log\n(\nnp2\nγqǫ\n)\n.\nProof. First, as above if k < T , we can apply Lemma 12, which results in\nE [τk+1|Fk] ≥ τk (1 + η∆(1− τk)) = τk + η∆τk (1− τk) ,\nand so E [1− τk+1|Fk] ≤ (1− τk) (1− η∆τk) .\nNow, if k < T , then since failure hasn’t occurred yet, τk > 12 . So,\nE [1− τk+1|Fk] ≤ (1− τk) ( 1− 1 2 η∆ ) .\nNow, since the logarithm function is concave, by Jensen’s inequality we have\nE [log (1− τk+1)|Fk] ≤ logE [1− τk+1|Fk] ,\nand thus by transitivity,\nE [log (1− τk+1)|Fk] ≤ log(1− τk) + log ( 1− 1 2 η∆ )\n≤ log(1− τk)− 1\n2 η∆.\nNow, we define a new process ψk as\nψk = log(1− τk) + 1\n2 η∆k.\nUsing this definition, for k < T ,\nE [ψk+1|Fk] = E [log(1− τk+1)|Fk] + 1\n2 η∆(k + 1)\n≤ log(1− τk)− 1\n2 η∆+\n1 2 η∆(k + 1)\n= log(1− τk) + 1\n2 η∆k\n= ψk,\nso ψk is a supermartingale for k < T . We can therefore apply the optional stopping theorem, which states that E [log(1− τ0)] = E [ψ0] ≥ E [ψT ] . Since 1− τ0 < 1, it follows that log(1− τ0) < 0. Therefore,\n0 ≥ E [ψT ] = E [log(1− τT )] + 1\n2 η∆E [T ] .\nApplying Lemma 9, 1− τT ≥ γn−1p−2qǫ,\nand so\n0 ≥ log(γn−1p−2qǫ) + 1 2 η∆E [T ] .\nSolving for the expected value of the stopping time,\nE [T ] ≤ 2 η∆δ log\n(\nnp2\nγqǫ\n)\n.\nFinally, substituting η in terms of γ results in\nE [T ] ≤ 4nσ 2 ap 2(p+ ǫ)\n∆2γǫ log\n(\nnp2\nγqǫ\n)\n,\nas desired.\nFinally, we prove Theorem 1.\nProof of angular part of Theorem 1. First, we notice that the total failure event up to time t can be written as\nFt = fT ∪ {T > t} .\nThat is, total failure up to time t occurs if either failure happens before success (event fT ), or neither success nor failure happen before t. By the union bound,\nFt ≤ P (fT ) + P (T > t) .\nApplying Markov’s inequality,\nP (Ft) ≤ P (fT ) + 1\nt E [T ] .\nFinally, applying Lemmas 13 and 14 produces\nP (Ft) ≤ Zp(γ) + 4nσ2ap 2(p+ ǫ)\n∆2γǫt log\n(\nnp2\nγqǫ\n)\n.\nThis is the desired expression.\nProof of radial part of Theorem 1. Recall that in Alecton, R̄ is defined as\nR̄ = 1\nL\nL−1 ∑\nl=0\nŶ T ÃlŶ .\nNow, computing the expected distance to the mean,\nE\n[\n∥ ∥ ∥R̄− Ŷ TAŶ ∥ ∥ ∥ 2\nF\n]\n= E\n\n\n∥ ∥ ∥ ∥ ∥ 1 L L−1 ∑\nl=0\nŶ T ÃlŶ − Ŷ TAŶ ∥ ∥ ∥ ∥\n∥\n2\nF\n\n\n= E\n\n\n∥ ∥ ∥ ∥ ∥ 1 L L−1 ∑\nl=0\nŶ T (Ãl −A)Ŷ ∥ ∥ ∥ ∥\n∥\n2\nF\n\n\n= 1\nL2 E\n[ L−1 ∑\nk=0\nL−1 ∑\nl=0\ntr\n( Ŷ T (Ãk −A)T Ŷ Ŷ T (Ãl −A)Ŷ )\n]\nSince E [ Ã ]\n= A, and the Ãl are independently sampled, the summand here will be zero unless k = l.\nTherefore,\nE\n[\n∥ ∥ ∥R̄− Ŷ TAŶ ∥ ∥ ∥ 2\nF\n]\n= 1\nL2\nL−1 ∑\nl=0\nE\n[\ntr\n( Ŷ T (Ãl −A)T Ŷ Ŷ T (Ãl −A)Ŷ )]\n= 1\nL E\n[\ntr\n( Ŷ T (Ã−A)T Ŷ Ŷ T (Ã−A)Ŷ )]\n≤ 1 L E [ tr ( Ŷ T ÃT Ŷ Ŷ T ÃŶ )] .\nApplying the Alecton variance condition, and recalling that tr ( Ŷ Ŷ T ) = p, results in\nE\n[\n∥ ∥ ∥ R̄− Ŷ TAŶ ∥ ∥ ∥ 2\nF\n]\n≤ p 2σ2r L .\nWe can now apply Markov’s inequality to this expression. This results in, for any constant ψ > 0,\nP (∥ ∥ ∥R̄− Ŷ TAŶ ∥ ∥ ∥ 2 F ≥ ψ ) ≤ p 2σ2r Lψ ,\nwhich is the desired result."
    }, {
      "heading" : "D Proofs of Lemmas",
      "text" : "First, we prove the lemmas used above to demonstrate the general result.\nProof of quadratic rational lower bound lemma (Lemma 6). Expanding the product results in (\n1+bx+cx2 ) ( 1+(2a−b)x−cx2 ) =1+((2a−b)+b)x+(c−c+(2a−b)b)x2+((2a−b)c−bc)x3−c2x4\n= 1 + 2ax+ (2ab− b2)x2 + 2(a− b)cx3 − c2x4 = 1 + 2ax+ a2x2 − (a2 − 2ab+ b2)x2 + 2(a− b)cx3 − c2x4 = 1 + 2ax+ a2x2 − x2 ( (a− b)2 − 2(a− b)cx+ c2x2 )\n= (1 + ax)2 − x2((a− b)− cx)2 ≤ (1 + ax)2.\nDividing both sides by 1 + bx+ cx2 (which we can do since this is assumed to be positive) reconstructs the desired identity.\nProof of Lemma 7. We first note that, by the symmetry of the multivariate Gaussian distribution, initializing Y0 uniformly at random such that Y T0 Y0 = I is equivalent to initializing the entries of Y0 as independent standard normal random variables, for the purposes of computing τ0. Under this initialization strategy, E [τ0] is\nE [τ0] = E\n[ ∣\n∣Y T0 UY0 ∣ ∣ ∣ ∣Y T0 WY0 ∣ ∣\n]\n= E\n[ ∣\n∣Y T0 UY0 ∣ ∣\n∣ ∣γn−1p−2qY T0 (I − U)Y0 + Y T0 UY0 ∣ ∣\n]\n.\nNow, let X ∈ Rq×p be the component of Y0 that is in the column space of U , and let Z ∈ R(n−q)×p be the component of Y0 in the null space of U . Then,\nE [τ0] = E\n[ ∣\n∣XTX ∣ ∣\n|γn−1p−2qZTZ +XTX|\n]\n.\nSince X and Z are selected orthogonally from a Gaussian random matrix, they must be independent, so we can take their expected values independently. Taking the expected value first with respect to Z , we notice\nthat |V |−1 is a convex function in V , and so by Jensen’s inequality,\nE [τ0] ≥ E [\n∣ ∣XTX ∣ ∣\n|γn−1p−2qE [ZTZ] +XTX|\n]\n≥ E [\n∣ ∣XTX ∣ ∣\n|γn−1p−2q(n− q)I +XTX|\n]\n≥ E [\n∣ ∣XTX ∣ ∣\n|γp−2qI +XTX|\n]\n= E [ ∣ ∣I + γp−2q(XTX)−1 ∣ ∣ −1] .\nNow, let V ∈ Rq×p be a random full-rank projection matrix, selected independently of X. Then,\nE [ V V T ] = p\nq I,\nand so\nE [τ0] ≥ E [ ∣ ∣ ∣I + γp−1E [ XTV V TX ∣ ∣X ]−1∣ ∣ ∣ −1 ] .\nApplying Jensen’s inequality again,\nE [τ0] ≥ E [ E [ ∣ ∣ ∣I + γp−1 ( XTV V TX )−1∣ ∣ ∣ −1 ∣ ∣ ∣\n∣\nX\n]]\n.\nand by the law of total expectation,\nE [τ0] ≥ E [ ∣ ∣ ∣I + γp−1 ( XTV V TX )−1∣ ∣ ∣ −1] .\nNow, since V and X were sampled independently, it follows that V TX is sampled as a standard normal random matrix in Rp×p. If we call this matrix R, then\nE [τ0] ≥ E [ ∣ ∣ ∣ I + γp−1 ( RTR )−1∣ ∣ ∣ −1 ]\n= 1− 1 2 Zp(γ),\nas desired.\nLemma 15. For any B ∈ Rn×n, any Y ∈ Rn×m, and any symmetric positive- semidefinite Z ∈ Rn×n, if either B is rank-1 or m = 1, then\n∣ ∣Y T (I +B)TZ(I +B)Y ∣ ∣\n= ∣ ∣Y TZY ∣ ∣\n(\n( tr ( Y (Y TZY )−1Y TZB ) + 1 )2\n+ tr ( Y (Y TZY )−1Y TBTZB )\n− tr ( ZY (Y TZY )−1Y TZBY (Y TZY )−1Y TBT )\n)\n.\nProof. We will prove this separately for each case. First, if m = 1, then Y is a vector, and the desired expression simplifies to\nY T (I +B)TZ(I +B)Y\n= Y TZY ( (Y TZY )−1Y TZBY + 1 )2\n+ tr ( Y TBTZBY ) − (Y TZY )−1(Y TZBY )2.\nStraightforward evaluation indicates that this expression holds in this case. Next, we consider the case where B is rank-1. In this case, we can rewrite it as B = uvT for vectors u and v, such that uTZu = 1. Then,\n∣ ∣Y T (I +B)TZ(I +B)Y ∣ ∣\n= ∣ ∣Y T (I + uvT )TZ(I + uvT )Y ∣ ∣\n= ∣ ∣Y TZY + 2Y TZuvTY + Y T vvTY ∣ ∣\nIf we define M = Y TZY and W = [ Y TZu Y T v ] ,\nthen\n∣ ∣Y T (I +B)TZ(I +B)Y ∣ ∣\n=\n∣ ∣ ∣ ∣ M +W [ 0 1 1 1 ] W T ∣ ∣ ∣ ∣ .\nApplying the matrix determinant lemma, and recalling that\n[\n0 1 1 1\n]−1 = [\n−1 1 1 0\n]\nand ∣\n∣ ∣ ∣ 0 1 1 1\n∣ ∣ ∣ ∣ = −1,\nwe produce\n− detM−1 ∣ ∣Y T (I +B)TZ(I +B)Y ∣ ∣\n= − ∣ ∣ ∣\n∣\n[\n−1 1 1 0\n]\n+W TM−1W\n∣ ∣ ∣ ∣\n=\n∣ ∣ ∣ ∣ uTZYM−1Y TZu− 1 vTYM−1Y TZu+ 1 vTYM−1Y TZu+ 1 vTYM−1Y T v ∣ ∣ ∣ ∣\n= ( uTZYM−1Y TZu− 1 ) ( vTYM−1Y T v )\n− ( vTYM−1Y TZu+ 1 )2\n= uTZYM−1Y TZuvTYM−1Y T v\n− vTYM−1Y T vuTZu − ( vTYM−1Y TZu+ 1 )2 .\nRewriting this in terms of the matrix B = uvT ,\n− detM−1 ∣ ∣Y T (I +B)TZ(I +B)Y ∣ ∣\n= tr ( ZYM−1Y TZBYM−1Y TBT )\n− tr ( YM−1Y TBTZB )\n− ( tr ( YM−1Y TZB ) + 1 )2 .\nSubstitution produces the desired result.\nProof of Lemma 8. First, for the lower bound, we notice that\nZY (Y TZY )−1Y TZ Z,\nsince the interior of the left expression is a projection matrix. This lets us conclude that\ntr ( Y (Y TZY )−1Y TBTZB )\n≥ tr ( ZY (Y TZY )−1Y TZBY (Y TZY )−1Y TBT ) .\nAppling this to the result of Lemma 15 produces the desired lower bound. For the upper bound, recall that, by the Cauchy-Schwarz inequality, for any rank-1 matrix A,\ntr (A)2 ≤ tr ( ATA ) .\nSince B is rank-1, it follows that\ntr ( Y (Y TZY )−1Y TZB )\n≤ tr ( ZY (Y TZY )−1Y TZBY (Y TZY )−1Y TBT ) .\nAppling this to the result of Lemma 15 produces the desired upper bound.\nLemma 16. For any symmetric matrix 0 X I ,\ntr (I −X) ≥ 1− |X| .\nProof. If x1, x2, . . . , xp are the eigenvalues of x, then this statement is equivalent to\n(\np ∑\ni=1\n(1− xi) ) − ( 1− p ∏\ni=1\nxi\n)\n> 0.\nIf we let f(X) denote this expression, then\n∂f ∂xj = −1 + 1 xj\np ∏\ni=1\nxi ≤ 0.\nIt follows that the minimum of f is attained at X = I . However, when X = I , f(X) = 0, and so f > 0, which proves the lemma.\nProof of Lemma 10. From the definition of φk, if we let Z2 = ( Y Tk WYk )−1\nfor Z positive semidefinite, then\nφk = tr ( I − Y Tk UTUYk ( Y Tk WYk )−1)\n= tr ( I − ZY Tk UTUYkZ ) .\nSince 0 ZY Tk UTUYkZ I , we can apply Lemma 16, which produces\nφk ≥ 1− ∣ ∣ZY Tk U TUYkZ ∣ ∣\n= 1− ∣ ∣Y Tk U TUYk ∣ ∣ ∣\n∣Y Tk WYk ∣ ∣\n= 1− τk,\nwhich is the desired expression.\nProof of Lemma 9. Since the success event does not occur, it follows that there exists a z ∈ Rp such that\n‖UYkz‖2\n‖Ykz‖2 ≤ 1− ǫ.\nIf we let Ŷk = Yk ( Y Tk Yk )− 1 2 ,\nand define ẑ as the unit vector such that ẑ ∝ (\nY Tk Yk )\n1 2 z,\nthen we can rewrite this as ∥\n∥ ∥ UŶkẑ\n∥ ∥ ∥ 2 ≤ 1− ǫ.\nIt follows that Ŷ Tk UŶk has an eigenvalues less than 1− ǫ. Now, expanding τk,\nτk =\n∣ ∣Y Tk UYk ∣ ∣ ∣ ∣Y Tk WYk ∣ ∣\n=\n∣ ∣ ∣ Ŷ Tk UŶk ∣ ∣ ∣ ∣ ∣ ∣ Ŷ Tk WŶk ∣ ∣ ∣\n=\n∣ ∣ ∣ ∣ (1− γn−1p−2q)I + γn−1p−2q ( Ŷ Tk UŶk )−1 ∣ ∣ ∣ ∣\n−1\nSince this is a matrix that has eigenvalues between 0 and 1, it follows that its determinant is less than each of its eigenvalues. From the analysis above, we can bound one of the eigenvalues of this matrix. Doing this results in\nτk ≤ ( (1− γn−1p−2q) + γn−1p−2q (1− ǫ)−1 )−1\n= 1− ǫ\nγn−1p−2q + (1− γn−1p−2q)(1 − ǫ)\n= 1− γn −1p−2qǫ γn−1p−2q + (1− γn−1p−2q)(1− ǫ) ≤ 1− γn−1p−2qǫ,\nas desired.\nLemma 17. Let x be a standard normal random variable, and a ∈ R a constant. Then\nE\n[\na2\nx2 + a2\n]\n= exp\n(\na2\n2\n)\n√\nπa2\n2 erfc\n( √\na2\n2\n)\n.\nProof. By the definition of expected value, since x is normally distributed,\nE\n[\na2\nx2 + a2\n]\n=\n∫ ∞\n−∞\n(\na2\nx2 + a2\n)(\n1√ 2π exp\n(\n−x 2\n2\n))\ndx.\nIf we let F denote the fourier transform, then\nF [\na\nx2 + a2\n] = √ 2π exp (−a |ω|) .\nFurthermore, since the Gaussian functions are eigenfunctions of the Fourier transform, we know that\nF [ 1√ 2π exp ( −x 2 2 )] = 1√ 2π exp ( −ω 2 2 ) .\nAnd so, by Parseval’s theorem,\nE\n[\n1\nx2 + 1\n]\n= a\n∫ ∞\n−∞ F [\na\nx2 + a2\n] F [ 1√ 2π exp ( −x 2 2 )] dω\n= a\n∫ ∞\n−∞\n√ 2π exp (−a |ω|) (\n1√ 2π exp\n(\n−ω 2\n2\n))\ndω\n= a\n∫ ∞\n0 exp\n(\n−aω − ω 2\n2\n)\ndω\n= a exp\n(\na2\n2\n) ∫ ∞\n0 exp\n(\n−a 2 2 − aω − ω 2 2\n)\ndω.\nLetting u = ω+a√ 2\nand dω = √ 2du, so\nE\n[\n1\nx2 + 1\n]\n= a exp\n(\na2\n2\n)∫ ∞\na √\n2\nexp ( −u2 ) √ 2du\n= exp\n(\na2\n2\n)\n√\nπa2\n2 erfc\n( √\na2\n2\n)\n,\nas desired.\nProof of Lemma 1. We start by stating the definition of Z1(γ). For some Gaussian random matrix R ∈ R 1×1,\nZ1(γ) = 2 ( 1−E [ ∣ ∣I + γ(RTR)−1 ∣ ∣ −1]) .\nSince R is a scalar, this reduces to\nZ1(γ) = 2 ( 1−E [ ( 1 + γR−2 )−1])\n= E\n[\n2\n(\n1− 1 1 + γR−2\n)]\n= E\n[ 2 γR−2\n1 + γR−2\n]\n= 2E\n[(\nγ\nR2 + γ\n)]\n.\nApplying Lemma 17,\nZ1(γ) = 2 exp (γ\n2\n)\n√\nπγ\n2 erfc\n( √\nγ\n2\n)\n= √ 2πγ exp (γ\n2\n)\nerfc\n( √\nγ\n2\n)\n.\nThis is the desired expression. Furthermore, since for all x,\nerfc (√ x ) ≤ exp (x) ,\nwe can also produce the desired upper bound on Z1,\nZ1 ≤ √ 2πγ.\nD.1 Proofs of Alecton Variance Condition Lemmas\nNext, we prove the Alecton Variance Conditions lemmas for the distributions mentioned in the body of the paper.\nD.1.1 Entrywise Sampling\nTo analyze the entrywise sampling case, we need some lemmas that makes the incoherence condition more accessible.\nLemma 18. If matrix A is symmetric and incoherent with parameter µ, and B is a symmetric matrix that commutes with A, then B is incoherent with parameter µ.\nProof. Since A and B commute, they must have the same eigenvectors. Therefore, the set of eigenvectors that shows that A is incoherent with parameter µ will also show that B has the same property.\nLemma 19. If matrix A is symmetric and incoherent with parameter µ, and ei is a standard basis element, then\neTi Aei ≤ µ2\nn tr (A) .\nProof. Let u1, u2, . . . , un be the eigenvectors guaranteed by the incoherence of A, and let λ1, . . . , λn be the corresponding eigenvalues. Then,\neTi Aei = e T i\n\n\nn ∑\nj=1\nujλju T j\n\n ei\n=\nn ∑\nj=1\nujλj(e T i uj) 2.\nApplying the definition of incoherence,\neTi Aei ≤ n ∑\nj=1\nujλj\n(\nµ√ n\n)2\n= µ2\nn tr (A) ,\nas desired.\nProof of the σa bound part of Lemma 2. We recall that the entrywise samples are of the form\nÃ = n2uuTAvvT ,\nwhere u and v are independently, uniformly chosen standard basis elements. We further recall that E [ uuT ]\n= E [ vvT ] = n−1I . Now, evaluating the desired quantity,\nE\n[ yT ÃTWÃy ] = n4E [ yT vvTAuuTWuuTAvvT y ] .\nSince W commutes with A, by Lemmas 18 and 19, uTWu ≤ µ2n−1tr (W ). Therefore,\nE\n[ yT ÃTWÃy ] ≤ µ2n3tr (W )E [ yTvvTAuuTAvvT y ]\n= µ2n2tr (W )E [ yTvvTA2vvT y ] .\nSince A2 commutes with A, the same logic shows that vTA2v ≤ µ2n−1tr ( A2 ) , and so,\nE\n[ yT ÃTWÃy ] ≤ µ4ntr (W ) tr ( A2 ) E [ yT vvT y ]\n= µ4tr (W ) ‖A‖2F ‖y‖ 2 .\nSo it suffices to choose σ2a = µ 4 ‖A‖2F , as desired.\nProof of the σr bound part of Lemma 2. Evaluating the desired quantity,\nE\n[\n( yT Ãy )2\n]\n= n4E [ ( yTuuTAvvT y )2 ]\n= n4E [ (uT y)2(vT y)2(uTAv)2 ] .\nBy the CauchySchwarz inequality,\n(uTAv)2 ≤ (uTAu)(vTAv),\nand by Lemma 19, uTAu ≤ µ2n−1tr (A), and so\n(uTAv)2 ≤ µ4n−2tr (A)2 .\nTherefore,\nE\n[\n( yT Ãy )2\n]\n≤ µ4n2tr (A)2 E [ (uT y)2(vT y)2 ]\n= µ4tr (A)2 ‖y‖4 .\nSo it suffices to choose σ2r = µ 4 tr (A)2, as desired.\nD.1.2 Rectangular Entrywise Sampling\nProof of Lemma 3. We recall that the rectangular entrywise samples are of the form\nÃ = mnMij(eie T m+j + em+je T i ),\nwhere i ∈ 1, . . . ,m and j ∈ 1, . . . , n are chosen uniformly and independently. Now, for any y and z in R m+n,\nE\n[ (zT Ãy)2 ] = m2n2E [\nM2ij(z T (eie T m+j + em+je T i )y)\n2 ]\n.\nApplying the entry bound,\nE\n[ (zT Ãy)2 ]\n≤ ξmn ‖M‖2F E [ (zT eie T m+jy + z T em+je T i y) 2 ] .\nNow, since (x+ y)2 ≤ 2(x2 + y2), if we let P be the projection matrix onto the first m basis vectors, then E [\neie T i\n] = m−1P and E [\nem+je T m+j\n]\n= n−1(I − P ), and so,\nE\n[ (zT Ãy)2 ]\n≤ 2ξmn ‖M‖2F E [ (zT ei) 2(eTm+jy) 2 + (zT em+j) 2(eTi y) 2 ] = 2ξ ‖M‖2F ( ‖Pz‖2 ‖(I − P )y‖2 + ‖(I − P )z‖2 ‖Py‖2 )\n≤ 2ξ ‖M‖2F ‖y‖ 2 ‖z‖2 .\nSince this is true for any y and z, it is true in particular for z being an eigenvector of A. Therefore, it suffices to pick σ2a = 2ξ ‖M‖2F . Similarly, it is true in particular for z = y, and therefore it suffices to pick σ2r = 2ξ ‖M‖2F . This proves the lemma.\nD.1.3 Trace Sampling\nIn order to prove our second moment lemma for the trace sampling case, we must first derive some lemmas about the way this distribution behaves.\nLemma 20 (Sphere Component Fourth Moment). If n > 50, and v ∈ Rn is sampled uniformly from the unit sphere, then for any unit vector y ∈ Rn,\nE\n[\n( yT v )4 ] ≤ 4 n2 .\nProof. Let x be sampled from the standard normal distribution in Rn. Then, by radial symmetry,\nE\n[\n( yTv )4 ] = E\n[\n( yTx )4\n‖x‖4\n]\n.\nIf we let u denote yTx, and z denote the components of x orthogonal to y, then ‖x‖2 = u2 + ‖z‖2. Furthermore, by the properties of the normal distribution, u and z are independent. Therefore,\nE\n[\n( yT v )4 ] = E\n[\nu4 ( u2 + ‖z‖2 )−2\n]\n≤ E [ u4 ( ‖z‖2 )−2 ]\n= E [ u4 ] E\n[ ‖z‖−4 ] .\nNow, E [ u4 ] is the fourth moment of the normal distribution, which is known to be 3. Furthermore,\nE\n[ ‖z‖−4 ]\nis the second moment of an inverse-chi-squared distribution with parameter n − 1, which is also a known result. Substituting these in,\nE\n[\n( yT v )4 ] ≤ 3 ( (n− 3)−2 + 2 (n− 3)−2 (n− 5)−1 )\n= 3 (n− 3)−2 ( 1 + 2 (n− 5)−1 ) .\nThis quantity has the asymptotic properties we want. In particular, applying the constraint that n > 50,\nE\n[\n( yT v )4 ] ≤ 4 n2 .\nThis is the desired result.\nLemma 21 (Sphere Component Fourth Moment Matrix). If n > 50, and v ∈ Rn is sampled uniformly from the unit sphere, then for any positive semidefinite matrix W ,\nE [ vvTWvvT ] 4n−2tr (W ) I.\nProof. Let\nW =\nn ∑\ni=1\nλiwiw T i\nbe the eigendecomposition of W . Then for any unit vector z,\nzTE [ vvTWvvT ] z = E\n[\nzT vvT\n(\nn ∑\ni=1\nλiwiw T i\n)\nvvT z\n]\n= n ∑\ni=1\nλiE [ ( zT v )2 ( wTi v )2 ] .\nBy the Cauchy-Schwarz inequality applied to the expectation,\nE\n[\n( zT v )2 ( wTi v )2 ] ≤ √ E [ (zT v)4 ] E [ ( wTi v )2 ]\n= E [ (zT v)4 ] .\nBy Lemma 20, E [ (zT v)4 ] ≤ 4n−2, and so\nzTE [ vvTWvvT ] z ≤ n ∑\ni=1\nλi(4n −2) = 4n−2tr (W ) .\nSince this is true for any unit vector z, by the definition of the positive semidefinite relation,\nE [ vvTWvvT ] 4n−2tr (W ) I,\nas desired.\nNow, we prove the AVC lemma for this distribution.\nProof of σa bound part of Lemma 4. Evaluating the expression we want to bound,\nE\n[ yT ÃTWÃy ] = n4E [ yT vvTAuuTWuuTAvvT y ] .\nApplying Lemma 21,\nE\n[ yT ÃTWÃy ] ≤ n4E [ yT vvTA ( 4n−2tr (W ) I ) AvvT y ]\n= 4n2tr (W )E [ yT vvTA2vvT y ] .\nAgain applying Lemma 21,\nE\n[ yT ÃTWÃy ] ≤ 4n2tr (W ) yT ( 4n−2tr ( A2 ) I ) y\n= 16 ‖A‖2F tr (W ) ‖y‖ 2 .\nSo it suffices to pick σ2a = 16 ‖A‖2F , as desired.\nProof of σr bound part of Lemma 4. Evaluating the expression we want to bound,\nE\n[\n( yÃy )2\n]\n= n4E [ ( yvvTAwwT y )2 ]\n= n4E [ tr ( AvvT yyT vvTAwwT yyTwwT )]\n= n4tr ( AE [ vvT yyT vvT ] AE [ wwT yyTwwT ]) .\nApplying Lemma 21 to this results in\nE\n[\n( yÃy )2\n]\n≤ n4tr ( A ( 4n−2tr ( yyT ) I ) A ( 4n−2tr ( yyT ) I ))\n= 16 ‖A‖2F ‖y‖ 4 .\nSo it suffices to pick σ2r = 16 ‖A‖2F , as desired.\nD.1.4 Subspace Sampling\nRecall that, in subspace sampling, our samples are of the form\nÃ = rn2m−2QvvTR,\nwhere Q and R are independent projection matrices that select m entries uniformly at random, and v is uniformly and independently selected from the column space of A. Using this, we first prove some lemmas, then prove our bounds.\nLemma 22. If Q is a projection matrix that projects onto a subspace spanned by m random standard basis vectors, and v is a member of a subspace that is incoherent with parameter µ, then for any vector x,\n(xTQv)2 ≤ (µmr +m2)n−2 ‖x‖2 ‖v‖2 ."
    }, {
      "heading" : "As a corollary, for any symmetric matrix W 0,",
      "text" : "vTQWQv ≤ (µmr +m2)n−2tr (W ) ‖v‖2 .\nProof. Let λi be 1 in the event that ei is in the column space of Q, and 0 otherwise. Then an eigendecomposition of Q is\nQ =\nn ∑\ni=1\nλieie T i .\nTherefore,\n(xTQv)2 =\n(\nn ∑\ni=1\nλix T eie T i v\n)2\n=\nn ∑\ni=1\nn ∑\nj=1\nλiλjxixjvivj .\nTaking the expected value, and noting that λi and λj are independent, and have expected value E [λi] = mn−1,\nE [ (xTQv)2 ] = m2n−2 n ∑\ni=1\nn ∑\nj=1\nxixjvivj\n+mn−1(1−mn−1) n ∑\ni=1\nx2i v 2 i .\nSince v is part of a subspace that is incoherent,\nE [ (xTQv)2 ] ≤ m2n−2 n ∑\ni=1\nn ∑\nj=1\nxixjvivj\n+ µmrn−2(1−mn−1) ‖v‖2 n ∑\ni=1\nx2i\n= m2n−2(xT v)2\n+ µmrn−2 ‖x‖2 ‖v‖2\n≤ (µmr +m2)n−2 ‖x‖2 ‖v‖2 ,\nas desired.\nProof of σa bound part of Lemma 5. Evaluating the expression we want to bound,\nE\n[ yT ÃTWÃy ]\n= r2n4m−4E [ yTRvvTQWQvvTRy ] = r2n4m−4E [ E [ vTRyyTRv ] E [ vTQWQv ]] .\nApplying Lemma 22,\nE\n[ yT ÃTWÃy ] ≤ r2m−4(µmr +m2)2tr (W ) ‖y‖2\n= r2(1 + µrm−1)2tr (W ) ‖y‖2 .\nSo, we can choose σ2a = r 2(1 + µrm−1)2, as desired.\nProof of σr bound part of Lemma 5. Evaluating the expression we want to bound,\nE\n[ (yT Ãy)2 ] = r2n4m−4E [ (yTQvvTRy)2 ]\n= r2n4m−4E [ E [ (yTQv)2 ] E [ (yTRv)2 ]] .\nApplying Lemma 22,\nE\n[ (yT Ãy)2 ] ≤ r2m−4(µmr +m2)2 ‖y‖4\n= r2(1 + µrm−1)2 ‖y‖4 .\nSo, we can choose σ2r = r 2(1 + µrm−1)2, as desired."
    }, {
      "heading" : "E Lower Bound on Alecton Rate",
      "text" : "In this section, we prove a rough lower bound on the rate of convergence of an Alecton-like algorithm for bounded sampling distributions. Specifically, we analyze the case where, rather than choosing a constant η, we allow the step size to vary at each timestep. Our result shows that we can’t hope for a better step size rule that improves the convergence rate of Alecton to, for example, a linear rate.\nTo show this lower bound, we assume we run Alecton with p = 1 for some sampling distribution such that for all η and all y, for some constant C ,\n∥ ∥ ∥y + ηÃy ∥ ∥ ∥ ≤ (1 + ηC) ‖y‖ .\nFurther assume that for some eigenvector u (with eigenvalue λ ≥ 0) that is not global solution, the sample variance in the direction of u satisfies\nE\n[ ÃTuuT Ã ] ≥ σ2I.\nWe now define ρk to be\nρk = (uTYk) 2\n‖Yk‖2 .\nThis quantity measures the error of the iterate at timestep k in the direction of u. We will show that the expected value of ρk can only decrease with at best a Ω ( 1 K+1 ) rate.\nFirst, we require a lemma.\nLemma 23. For any a ≥ 0, b ≥ 0, and 0 ≤ x ≤ 1,\na(1− x)2 + bx2 ≥ ab a+ b .\nProof. Expanding the left side,\na(1− x)2 + bx2 = a− 2ax+ (a+ b)x2\n= a− a 2\na+ b +\na2\na+ b − 2ax+ (a+ b)x2\n= ab\na+ b + (a− (a+ b)x)2 a+ b\n≥ ab a+ b ,\nas desired.\nTheorem 3. Under the above conditions, regardless of how we choose the step size in the Alecton algorithm, even if we are able to choose a different step size each iteration, the expected error will still satisfy\nE [ρK ] ≥ σ2\nσ2n+ C2K .\nProof. Using the Alecton update rule with a time-varying step size ηk,\nρk+1 = (uTYk) 2\n‖Yk‖2\n= (uTYk + ηku T ÃkYk) 2\n∥ ∥ ∥ Yk + ηkÃkYk ∥ ∥ ∥ 2\n≥ (u TYk + ηku T ÃkYk) 2\n(1 + ηkC)2 ‖Yk‖2 .\nTaking the expected value,\nE [ρk+1] ≥ E [ (uTYk + ηku T ÃkYk) 2\n(1 + ηkC)2 ‖Yk‖2\n]\n≥ E [ (1 + 2ηkλ)(u TYk) 2 + η2kσ 2Y Tk Yk (1 + ηkC)2 ‖Yk‖2 ]\n= 1 + 2ηkλ\n(1 + ηkC)2 E [ρk] +\nη2kσ 2\n(1 + ηkC)2\n≥ 1 (1 + ηkC)2 E [ρk] + η2kσ 2 (1 + ηkC)2\nNow, if we define ζk as\nζk = ηkC\n1 + ηkC ,\nthen E [ρk+1] ≥ (1− ζk)2E [ρk] + ζ2kσ2C−2.\nApplying Lemma 23,\nE [ρk+1] ≥ σ2C−2E [ρk]\nE [ρk] + σ2C−2 .\nTaking the inverse, 1\nE [ρk+1] ≤ 1 E [ρk] +\nC2 σ2 .\nTherefore, summing across steps, 1\nE [ρK ] ≤ 1 E [ρ0] +\nC2K\nσ2 .\nSince, by symmetry, E [ρ0] = n−1, we have\n1 E [ρK ] ≤ n+ C\n2K\nσ2 .\nand taking the inverse again produces\nE [ρK ] ≥ σ2\nσ2n+ C2K ,\nwhich is the desired expression."
    }, {
      "heading" : "F Handling Constraints",
      "text" : "Alecton can easily be adapted to solve the problem of finding a low-rank approximation to a matrix under a spectahedral constraint. That is, we want to solve the problem\nminimize ‖A−X‖2F subject to X ∈ RN×N , tr (X) = 1,\nrank (X) ≤ 1,X 0.\nThis is equivalent to the decomposed problem\nminimize ‖y‖4 − 2yTAy + ‖A‖2F subject to y ∈ RN , ‖y‖2 = 1,\nwhich is itself equivalent to: minimize 1− 2yTAy + ‖A‖2F subject to y ∈ RN , ‖y‖2 = 1.\nThis will have a minimum when y = u1. We can therefore solve the problem using only the angular phase of Alecton, which recovers the vector u1. The same convergence analysis described above still applies.\nFor an example of a constrained problem that Alecton cannot handle, because it is NP-hard, see the elliptope-constrained MAXCUT embedding in Appendix A. This shows that constrained problems can’t be solved efficiently by SGD algorithms in all cases."
    }, {
      "heading" : "G Towards a Linear Rate",
      "text" : "In this section, we consider a special case of the matrix recovery problem: one in which the samples we are given would allow us to exactly recover A. That is, for some linear operator Ω : Rn×n → Rs, we are given the value of Ω(A) as an input, and we know that the unique solution of the optimization problem\nminimize ‖Ω(X −A)‖2 subject to X ∈ Rn×n, rank (X) ≤ p,X 0\nis X = A. Performing a rank-p quadratic substitution on this problem results in:\nminimize ∥ ∥Ω(Y Y T −A) ∥ ∥ 2 subject to Y ∈ Rn×p\nThe specific case we will be looking at is where the operator Ω satisfies the p-RIP constraint.\nDefinition 8 (Restricted isometry property). A linear operator Ω : Rn×n → Rs satisfies p-RIP with constant δ if for all X ∈ Rn×n of rank at most p,\n(1− δ) ‖X‖2F ≤ ‖Ω(X)‖ 2 ≤ (1 + δ) ‖X‖2F .\nThis definition encodes the notion that Ω preserves the norm of low-rank matrices under its transformation. We can prove a simple lemma that extends this to the inner product.\nLemma 24. If Ω is (p+ q)-RIP with parameter δ, then for any symmetric matrices X and Y of rank at most p and q respectively,\nΩ(X)TΩ(Y ) ≥ tr (XY )− δ ‖X‖F ‖Y ‖F\nProof. For any a ∈ R, since Ω is linear,\ntr (Ω(X)Ω(Y )) = 1\n4a\n( ‖Ω(X) + aΩ(Y )‖2 − ‖Ω(X)− aΩ(Y )‖2 )\n= 1\n4a\n( ‖Ω(X + aY )‖2 − ‖Ω(X − aY )‖2 ) .\nSince rank (X − aY ) ≤ rank (X) + rank (Y ) ≤ p + q, we can apply our RIP inequalities, which produces\ntr (Ω(X)Ω(Y )) ≥ 1 4a ( (1− δ) ‖X + aY ‖ 2F − (1 + δ) ‖X − aY ‖ 2F )\n≥ 1 4a ( −2δ ‖X‖ 2F + 4atr (XY )− 2δa2 ‖Y ‖ 2F ) = tr (XY )− δ‖X‖ 2 F + a\n2 ‖Y ‖ 2F 2a .\nSubstituting a = ‖X‖F‖Y ‖ F results in\ntr (Ω(X)Ω(Y )) ≥ tr (XY )− δ ‖X‖F ‖Y ‖F ,\nas desired.\nFinally, we prove our main theorem that shows that the quadratically transformed objective function is strongly convex in a ball about the solution.\nTheorem 4. If we define f(Y ) as the objective function of the above optimization problem, that is for Y ∈ Rn×p and A ∈ Rn×n symmetric of rank no greater than p,\nf(Y ) = ∥ ∥Ω(Y Y T −A) ∥ ∥ 2 ,\nand Ω is 3p-RIP with parameter δ, then for all Y , if we let λp denote the smallest positive eigenvalue of A then\n∇2V f(Y ) 2 ( (1− δ)λp − (3 + δ) ∥ ∥Y Y T −A ∥ ∥\nF\n)\nI.\nProof. The directional derivative of f along some direction V will be, by the product rule,\n∇V f(Y ) = 2Ω(Y Y T −A)TΩ(Y V T + V Y T ).\nThe second derivative along this same direction will be\n∇2V f(Y ) = 4Ω(Y Y T −A)TΩ(V V T ) + 2Ω(Y V T + V Y T )TΩ(Y V T + V Y T ) = 4Ω(Y Y T −A)TΩ(V V T ) + 2 ∥ ∥Ω(Y V T + V Y T ) ∥ ∥ 2 .\nTo this, we can apply the definition of RIP, and the corollary lemma, which results in\n∇2V f(Y ) ≥ 4tr ( (Y Y T −A)(UUT ) ) − 4δ ∥ ∥Y Y T −A ∥ ∥ F ∥ ∥UUT ∥ ∥ F + 2(1− δ) ∥ ∥Y UT + UY T ∥ ∥ 2 F .\nBy Cauchy-Schwarz,\n∇2V f(Y ) ≥ −4 ∥ ∥Y Y T −A ∥ ∥ F tr ( UUT ) − 4δ ∥ ∥Y Y T −A ∥ ∥ F tr ( UUT ) + 2(1− δ)λmin(Y TY )tr ( UUT )\n= 2 ( (1− δ)λmin(Y TY )− 2(1 + δ) ∥ ∥Y Y T −A ∥ ∥ F ) tr ( UUT ) .\nNow, since at the optimum, λmin(Y TY ) = λp, it follows that for general Y ,\nλmin(Y TY ) ≥ λp −\n∥ ∥Y Y T −A ∥ ∥\nF .\nSubstituting this in to the previous expression,\n∇2V f(Y ) ≥ 2 ( (1− δ)(λp − ∥ ∥Y Y T −A ∥ ∥ F )− 2(1 + δ) ∥ ∥Y Y T −A ∥ ∥ F ) tr ( UUT )\n= 2 ( (1− δ)λp − (3 + δ) ∥ ∥Y Y T −A ∥ ∥ F ) ‖U‖ 2F .\nSince this is true for an arbitrary direction vector U , it follows that\n∇2V f(Y ) 2 ( (1− δ)λp − (3 + δ) ∥ ∥Y Y T −A ∥ ∥\nF\n)\nI,\nwhich is the desired result.\nThis theorem shows that there is a region of size O(1) (i.e. not dependent on n) within which the above problem is strongly convex. So, if we start within this region, any standard convex descent method will converge at a linear rate. In particular, coordinate descent will do so. Therefore, we can imagine doing the following:\n• First, use Alecton to, with high probability, recover an estimate Y that for which ∥ ∥Y Y T −A ∥ ∥\nF is\nsufficiently small for the objective function to be strongly convex with some probability. This will only require O(n log n) steps of the angular phase of the algorithm per iteration of Alecton, as stated in the main body of the paper. We will need p iterations of the algorithm to recover a rank-p estimate, so a total O(np log n) iterations will be required.\n• Use a descent method, such as coordinate descent, to recover additional precision of the estimate. This method is necessarily more heavyweight than an SGD scheme (see Section E for the reason why an SGD scheme cannot achieve a linear rate), but it will converge monotonically at a linear rate to the exact solution matrix A.\nThis hybrid method is in some sense a best-of-both worlds approach. We use fast SGD steps when we can afford to, and then switch to slower coordinate descent steps when we need additional precision.\nSecondary Literature\n[11] Emmanuel Candès, Xiaodong Li, and Mahdi Soltanolkotabi. Phase retrieval via wirtinger flow: Theory and algorithms. arXiv preprint arXiv:1407.1065, 2014.\n[13] EmmanuelJ. Candès and Xiaodong Li. Solving quadratic equations via phaselift when there are about as many equations as unknowns. FoCM, 14(5):1017–1026, 2014.\n[28] R.H. Keshavan, A. Montanari, and Sewoong Oh. Matrix completion from a few entries. Information Theory, IEEE Transactions on, 56(6):2980–2998, June 2010.\n[41] Praneeth Netrapalli, Prateek Jain, and Sujay Sanghavi. Phase retrieval using alternating minimization. In Advances in Neural Information Processing Systems 26, pages 2796–2804. 2013."
    } ],
    "references" : [ {
      "title" : "Optimization Algorithms on Matrix Manifolds",
      "author" : [ "P.-A. Absil", "R. Mahony", "R. Sepulchre" ],
      "venue" : null,
      "citeRegEx" : "1",
      "shortCiteRegEx" : "1",
      "year" : 2008
    }, {
      "title" : "A reliable effective terascale linear learning system",
      "author" : [ "Alekh Agarwal", "Olivier Chapelle", "Miroslav Dudı́k", "John Langford" ],
      "venue" : "CoRR, abs/1110.4198,",
      "citeRegEx" : "2",
      "shortCiteRegEx" : "2",
      "year" : 2011
    }, {
      "title" : "Stochastic optimization for pca and pls",
      "author" : [ "R. Arora", "A. Cotter", "K. Livescu", "N. Srebro" ],
      "venue" : "In Communication, Control, and Computing (Allerton),",
      "citeRegEx" : "3",
      "shortCiteRegEx" : "3",
      "year" : 2012
    }, {
      "title" : "Stochastic optimization of pca with capped msg",
      "author" : [ "Raman Arora", "Andy Cotter", "Nati Srebro" ],
      "venue" : "Advances in Neural Information Processing Systems",
      "citeRegEx" : "4",
      "shortCiteRegEx" : "4",
      "year" : 2013
    }, {
      "title" : "The fast convergence of incremental pca",
      "author" : [ "Akshay Balsubramani", "Sanjoy Dasgupta", "Yoav Freund" ],
      "venue" : "In NIPS,",
      "citeRegEx" : "5",
      "shortCiteRegEx" : "5",
      "year" : 2013
    }, {
      "title" : "Online identification and tracking of subspaces from highly incomplete information",
      "author" : [ "Laura Balzano", "Robert Nowak", "Benjamin Recht" ],
      "venue" : "In Communication, Control, and Computing (Allerton),",
      "citeRegEx" : "6",
      "shortCiteRegEx" : "6",
      "year" : 2010
    }, {
      "title" : "Large-scale machine learning with stochastic gradient descent",
      "author" : [ "Lon Bottou" ],
      "venue" : "In Proceedings of COMP- STAT’2010,",
      "citeRegEx" : "7",
      "shortCiteRegEx" : "7",
      "year" : 2010
    }, {
      "title" : "The tradeoffs of large scale learning",
      "author" : [ "Lon Bottou", "Olivier Bousquet" ],
      "venue" : "In IN: ADVANCES IN NEU- RAL INFORMATION PROCESSING SYSTEMS",
      "citeRegEx" : "8",
      "shortCiteRegEx" : "8",
      "year" : 2008
    }, {
      "title" : "A nonlinear programming algorithm for solving semidefinite programs via low-rank factorization",
      "author" : [ "Samuel Burer", "Renato DC Monteiro" ],
      "venue" : "Mathematical Programming,",
      "citeRegEx" : "9",
      "shortCiteRegEx" : "9",
      "year" : 2003
    }, {
      "title" : "Local minima and convergence in low-rank semidefinite programming",
      "author" : [ "Samuel Burer", "Renato DC Monteiro" ],
      "venue" : "Mathematical Programming,",
      "citeRegEx" : "10",
      "shortCiteRegEx" : "10",
      "year" : 2005
    }, {
      "title" : "Phase retrieval via wirtinger flow: Theory and algorithms",
      "author" : [ "Emmanuel Candès", "Xiaodong Li", "Mahdi Soltanolkotabi" ],
      "venue" : "arXiv preprint arXiv:1407.1065,",
      "citeRegEx" : "11",
      "shortCiteRegEx" : "11",
      "year" : 2014
    }, {
      "title" : "Exact matrix completion via convex optimization",
      "author" : [ "Emmanuel J. Candès", "Benjamin Recht" ],
      "venue" : "FoCM, 9(6):717–772,",
      "citeRegEx" : "12",
      "shortCiteRegEx" : "12",
      "year" : 2009
    }, {
      "title" : "Solving quadratic equations via phaselift when there are about as many equations as unknowns. FoCM",
      "author" : [ "EmmanuelJ. Candès", "Xiaodong Li" ],
      "venue" : null,
      "citeRegEx" : "13",
      "shortCiteRegEx" : "13",
      "year" : 2014
    }, {
      "title" : "Matrix completion via an alternating direction method",
      "author" : [ "Caihua Chen", "Bingsheng He", "Xiaoming Yuan" ],
      "venue" : "IMAJNA,",
      "citeRegEx" : "14",
      "shortCiteRegEx" : "14",
      "year" : 2011
    }, {
      "title" : "Adaptive subgradient methods for online learning and stochastic optimization",
      "author" : [ "John Duchi", "Elad Hazan", "Yoram Singer" ],
      "venue" : "J. Mach. Learn. Res.,",
      "citeRegEx" : "16",
      "shortCiteRegEx" : "16",
      "year" : 2011
    }, {
      "title" : "Counting processes and survival analysis",
      "author" : [ "Thomas R Fleming", "David P Harrington" ],
      "venue" : null,
      "citeRegEx" : "17",
      "shortCiteRegEx" : "17",
      "year" : 1991
    }, {
      "title" : "Improved approximation algorithms for maximum cut and satisfiability problems using semidefinite programming",
      "author" : [ "Michel X. Goemans", "David P. Williamson" ],
      "venue" : "J. ACM,",
      "citeRegEx" : "19",
      "shortCiteRegEx" : "19",
      "year" : 1995
    }, {
      "title" : "Wtf: The who to follow service at twitter",
      "author" : [ "Pankaj Gupta", "Ashish Goel", "Jimmy Lin", "Aneesh Sharma", "Dong Wang", "Reza Zadeh" ],
      "venue" : "WWW ’13,",
      "citeRegEx" : "20",
      "shortCiteRegEx" : "20",
      "year" : 2013
    }, {
      "title" : "The noisy power method: A meta algorithm with applications",
      "author" : [ "Moritz Hardt", "Eric Price" ],
      "venue" : "Advances in Neural Information Processing Systems",
      "citeRegEx" : "21",
      "shortCiteRegEx" : "21",
      "year" : 2014
    }, {
      "title" : "Design and performance of parallel and distributed approximation algorithms for maxcut",
      "author" : [ "Steven Homer", "Marcus Peinado" ],
      "venue" : "J. Parallel Distrib. Comput.,",
      "citeRegEx" : "22",
      "shortCiteRegEx" : "22",
      "year" : 1997
    }, {
      "title" : "Solving ptychography with a convex relaxation",
      "author" : [ "R. Horstmeyer", "R.Y. Chen", "X. Ou", "B. Ames", "J.A. Tropp", "C. Yang" ],
      "venue" : "ArXiv e-prints,",
      "citeRegEx" : "23",
      "shortCiteRegEx" : "23",
      "year" : 2014
    }, {
      "title" : "Accelerated gradient methods for stochastic optimization and online learning",
      "author" : [ "Chonghai Hu", "James T. Kwok", "Weike Pan" ],
      "venue" : "In Advances in Neural Information Processing Systems",
      "citeRegEx" : "24",
      "shortCiteRegEx" : "24",
      "year" : 2009
    }, {
      "title" : "Low-rank matrix completion using alternating minimization",
      "author" : [ "Prateek Jain", "Praneeth Netrapalli", "Sujay Sanghavi" ],
      "venue" : "In Proceedings of the Forty-fifth Annual ACM STOC,",
      "citeRegEx" : "25",
      "shortCiteRegEx" : "25",
      "year" : 2013
    }, {
      "title" : "Robust stochastic principal component analysis",
      "author" : [ "Raman Arora John Goes", "Teng Zhang", "Gilad Lerman" ],
      "venue" : "In Proceedings of the 17th International Conference on Artificial Intelligence and Statistics,",
      "citeRegEx" : "26",
      "shortCiteRegEx" : "26",
      "year" : 2014
    }, {
      "title" : "Low-rank optimization on the cone of positive semidefinite matrices",
      "author" : [ "M. Journée", "F. Bach", "P.-A. Absil", "R. Sepulchre" ],
      "venue" : "SIAM J. on Optimization,",
      "citeRegEx" : "27",
      "shortCiteRegEx" : "27",
      "year" : 2010
    }, {
      "title" : "Matrix completion from a few entries",
      "author" : [ "R.H. Keshavan", "A. Montanari", "Sewoong Oh" ],
      "venue" : "Information Theory, IEEE Transactions on,",
      "citeRegEx" : "28",
      "shortCiteRegEx" : "28",
      "year" : 2010
    }, {
      "title" : "Low-rank optimization with trace norm penalty",
      "author" : [ "Bamdev Mishra", "Gilles Meyer", "Francis Bach", "Rodolphe Sepulchre" ],
      "venue" : "SIAM Journal on Optimization,",
      "citeRegEx" : "29",
      "shortCiteRegEx" : "29",
      "year" : 2013
    }, {
      "title" : "Hogwild: A lock-free approach to parallelizing stochastic gradient descent",
      "author" : [ "Feng Niu", "Benjamin Recht", "Christopher Ré", "Stephen J. Wright" ],
      "venue" : null,
      "citeRegEx" : "30",
      "shortCiteRegEx" : "30",
      "year" : 2011
    }, {
      "title" : "On stochastic approximation of the eigenvectors and eigenvalues of the expectation of a random matrix",
      "author" : [ "Erkki Oja" ],
      "venue" : "Journal of Mathematical Analysis and Applications,",
      "citeRegEx" : "31",
      "shortCiteRegEx" : "31",
      "year" : 1985
    }, {
      "title" : "Summingbird: A framework for integrating batch and online mapreduce computations",
      "author" : [ "Sam Ritchie" ],
      "venue" : "In Proceedings of the VLDB Endowment,",
      "citeRegEx" : "32",
      "shortCiteRegEx" : "32",
      "year" : 2014
    }, {
      "title" : "Parallel stochastic gradient algorithms for large-scale matrix completion",
      "author" : [ "Benjamin Recht", "Christopher Ré" ],
      "venue" : "Mathematical Programming Computation,",
      "citeRegEx" : "33",
      "shortCiteRegEx" : "33",
      "year" : 2013
    }, {
      "title" : "Making gradient descent optimal for strongly convex stochastic optimization",
      "author" : [ "Ohad Shamir" ],
      "venue" : "CoRR, abs/1109.5647,",
      "citeRegEx" : "34",
      "shortCiteRegEx" : "34",
      "year" : 2011
    }, {
      "title" : "A stochastic PCA algorithm with an exponential convergence rate",
      "author" : [ "Ohad Shamir" ],
      "venue" : "CoRR, abs/1409.2848,",
      "citeRegEx" : "35",
      "shortCiteRegEx" : "35",
      "year" : 2014
    }, {
      "title" : "Distributed matrix completion",
      "author" : [ "Christina Teflioudi", "Faraz Makari", "Rainer Gemulla" ],
      "venue" : "IEEE 13th ICDM,",
      "citeRegEx" : "36",
      "shortCiteRegEx" : "36",
      "year" : 2013
    } ],
    "referenceMentions" : [ {
      "referenceID" : 8,
      "context" : "edu Departments of Electrical Engineering and Computer Science Stanford University, Stanford, CA 94309 February 11, 2015 Abstract Stochastic gradient descent (SGD) on a low-rank factorization [9] is commonly employed to speed up matrix problems including matrix completion, subspace tracking, and SDP relaxation.",
      "startOffset" : 192,
      "endOffset" : 195
    }, {
      "referenceID" : 13,
      "context" : "This problem, or problems that can be transformed to this problem, appears in a variety of machine learning applications including matrix completion [14, 25, 36], general data analysis [37], subspace tracking [6], principle component analysis [3], optimization [10, 23, 27, 29], and recommendation systems [20, 32].",
      "startOffset" : 149,
      "endOffset" : 161
    }, {
      "referenceID" : 22,
      "context" : "This problem, or problems that can be transformed to this problem, appears in a variety of machine learning applications including matrix completion [14, 25, 36], general data analysis [37], subspace tracking [6], principle component analysis [3], optimization [10, 23, 27, 29], and recommendation systems [20, 32].",
      "startOffset" : 149,
      "endOffset" : 161
    }, {
      "referenceID" : 33,
      "context" : "This problem, or problems that can be transformed to this problem, appears in a variety of machine learning applications including matrix completion [14, 25, 36], general data analysis [37], subspace tracking [6], principle component analysis [3], optimization [10, 23, 27, 29], and recommendation systems [20, 32].",
      "startOffset" : 149,
      "endOffset" : 161
    }, {
      "referenceID" : 5,
      "context" : "This problem, or problems that can be transformed to this problem, appears in a variety of machine learning applications including matrix completion [14, 25, 36], general data analysis [37], subspace tracking [6], principle component analysis [3], optimization [10, 23, 27, 29], and recommendation systems [20, 32].",
      "startOffset" : 209,
      "endOffset" : 212
    }, {
      "referenceID" : 2,
      "context" : "This problem, or problems that can be transformed to this problem, appears in a variety of machine learning applications including matrix completion [14, 25, 36], general data analysis [37], subspace tracking [6], principle component analysis [3], optimization [10, 23, 27, 29], and recommendation systems [20, 32].",
      "startOffset" : 243,
      "endOffset" : 246
    }, {
      "referenceID" : 9,
      "context" : "This problem, or problems that can be transformed to this problem, appears in a variety of machine learning applications including matrix completion [14, 25, 36], general data analysis [37], subspace tracking [6], principle component analysis [3], optimization [10, 23, 27, 29], and recommendation systems [20, 32].",
      "startOffset" : 261,
      "endOffset" : 277
    }, {
      "referenceID" : 20,
      "context" : "This problem, or problems that can be transformed to this problem, appears in a variety of machine learning applications including matrix completion [14, 25, 36], general data analysis [37], subspace tracking [6], principle component analysis [3], optimization [10, 23, 27, 29], and recommendation systems [20, 32].",
      "startOffset" : 261,
      "endOffset" : 277
    }, {
      "referenceID" : 24,
      "context" : "This problem, or problems that can be transformed to this problem, appears in a variety of machine learning applications including matrix completion [14, 25, 36], general data analysis [37], subspace tracking [6], principle component analysis [3], optimization [10, 23, 27, 29], and recommendation systems [20, 32].",
      "startOffset" : 261,
      "endOffset" : 277
    }, {
      "referenceID" : 26,
      "context" : "This problem, or problems that can be transformed to this problem, appears in a variety of machine learning applications including matrix completion [14, 25, 36], general data analysis [37], subspace tracking [6], principle component analysis [3], optimization [10, 23, 27, 29], and recommendation systems [20, 32].",
      "startOffset" : 261,
      "endOffset" : 277
    }, {
      "referenceID" : 17,
      "context" : "This problem, or problems that can be transformed to this problem, appears in a variety of machine learning applications including matrix completion [14, 25, 36], general data analysis [37], subspace tracking [6], principle component analysis [3], optimization [10, 23, 27, 29], and recommendation systems [20, 32].",
      "startOffset" : 306,
      "endOffset" : 314
    }, {
      "referenceID" : 29,
      "context" : "This problem, or problems that can be transformed to this problem, appears in a variety of machine learning applications including matrix completion [14, 25, 36], general data analysis [37], subspace tracking [6], principle component analysis [3], optimization [10, 23, 27, 29], and recommendation systems [20, 32].",
      "startOffset" : 306,
      "endOffset" : 314
    }, {
      "referenceID" : 8,
      "context" : "Sometimes, (1) arises under conditions in which the samples Ã are sparse, but the matrix X would be too large to store and operate on efficiently; a standard heuristic to use in this case is a low-rank factorization [9].",
      "startOffset" : 216,
      "endOffset" : 219
    }, {
      "referenceID" : 1,
      "context" : "Efficient SGD implementations can scale to very large datasets [2, 7, 8, 16, 24, 30, 33, 36].",
      "startOffset" : 63,
      "endOffset" : 92
    }, {
      "referenceID" : 6,
      "context" : "Efficient SGD implementations can scale to very large datasets [2, 7, 8, 16, 24, 30, 33, 36].",
      "startOffset" : 63,
      "endOffset" : 92
    }, {
      "referenceID" : 7,
      "context" : "Efficient SGD implementations can scale to very large datasets [2, 7, 8, 16, 24, 30, 33, 36].",
      "startOffset" : 63,
      "endOffset" : 92
    }, {
      "referenceID" : 14,
      "context" : "Efficient SGD implementations can scale to very large datasets [2, 7, 8, 16, 24, 30, 33, 36].",
      "startOffset" : 63,
      "endOffset" : 92
    }, {
      "referenceID" : 21,
      "context" : "Efficient SGD implementations can scale to very large datasets [2, 7, 8, 16, 24, 30, 33, 36].",
      "startOffset" : 63,
      "endOffset" : 92
    }, {
      "referenceID" : 27,
      "context" : "Efficient SGD implementations can scale to very large datasets [2, 7, 8, 16, 24, 30, 33, 36].",
      "startOffset" : 63,
      "endOffset" : 92
    }, {
      "referenceID" : 30,
      "context" : "Efficient SGD implementations can scale to very large datasets [2, 7, 8, 16, 24, 30, 33, 36].",
      "startOffset" : 63,
      "endOffset" : 92
    }, {
      "referenceID" : 33,
      "context" : "Efficient SGD implementations can scale to very large datasets [2, 7, 8, 16, 24, 30, 33, 36].",
      "startOffset" : 63,
      "endOffset" : 92
    }, {
      "referenceID" : 24,
      "context" : "People have attempted to compensate for this with sophisticated methods like geodesic step rules [27] and manifold projections [1]; however, even these methods cannot guarantee global convergence.",
      "startOffset" : 97,
      "endOffset" : 101
    }, {
      "referenceID" : 0,
      "context" : "People have attempted to compensate for this with sophisticated methods like geodesic step rules [27] and manifold projections [1]; however, even these methods cannot guarantee global convergence.",
      "startOffset" : 127,
      "endOffset" : 130
    }, {
      "referenceID" : 10,
      "context" : "We make the following contributions: • We establish the convergence rate to a global optimum of Alecton using a random initialization; in contrast, prior analyses [11, 25] have required more expensive initialization methods, such as the singular value decomposition of an empirical average of the data.",
      "startOffset" : 163,
      "endOffset" : 171
    }, {
      "referenceID" : 22,
      "context" : "We make the following contributions: • We establish the convergence rate to a global optimum of Alecton using a random initialization; in contrast, prior analyses [11, 25] have required more expensive initialization methods, such as the singular value decomposition of an empirical average of the data.",
      "startOffset" : 163,
      "endOffset" : 171
    }, {
      "referenceID" : 18,
      "context" : "• In contrast to previous work that uses bounds on the magnitude of the noise [21], our analysis depends only on the variance of the samples.",
      "startOffset" : 78,
      "endOffset" : 82
    }, {
      "referenceID" : 22,
      "context" : "As a result, we are able to be robust to different noise models, and we apply our technique to these problems, which did not previously have global convergence rates: – matrix completion, in which we observe entries of A one at a time [25, 28] (Section 4.",
      "startOffset" : 235,
      "endOffset" : 243
    }, {
      "referenceID" : 25,
      "context" : "As a result, we are able to be robust to different noise models, and we apply our technique to these problems, which did not previously have global convergence rates: – matrix completion, in which we observe entries of A one at a time [25, 28] (Section 4.",
      "startOffset" : 235,
      "endOffset" : 243
    }, {
      "referenceID" : 10,
      "context" : "1), – phase retrieval, in which we observe tr(uAv) for randomly selected u, v [11, 13] (Section 4.",
      "startOffset" : 78,
      "endOffset" : 86
    }, {
      "referenceID" : 12,
      "context" : "1), – phase retrieval, in which we observe tr(uAv) for randomly selected u, v [11, 13] (Section 4.",
      "startOffset" : 78,
      "endOffset" : 86
    }, {
      "referenceID" : 5,
      "context" : "3), and – subspace tracking, in which A is a projection matrix and we observe random entries of a random vector in its column space [6] (Section 4.",
      "startOffset" : 132,
      "endOffset" : 135
    }, {
      "referenceID" : 8,
      "context" : "Foundational work in this space was done by Burer and Monteiro [9, 10], who analyzed the low-rank factorization of general semidefinite programs.",
      "startOffset" : 63,
      "endOffset" : 70
    }, {
      "referenceID" : 9,
      "context" : "Foundational work in this space was done by Burer and Monteiro [9, 10], who analyzed the low-rank factorization of general semidefinite programs.",
      "startOffset" : 63,
      "endOffset" : 70
    }, {
      "referenceID" : 24,
      "context" : "[27] exhibits a second-order algorithm that converges to a local solution.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 24,
      "context" : "These approaches have attempted to correct for falling off the manifold using Riemannian retractions [27], geodesic steps [6], or projections back onto the manifold.",
      "startOffset" : 101,
      "endOffset" : 105
    }, {
      "referenceID" : 5,
      "context" : "These approaches have attempted to correct for falling off the manifold using Riemannian retractions [27], geodesic steps [6], or projections back onto the manifold.",
      "startOffset" : 122,
      "endOffset" : 125
    }, {
      "referenceID" : 0,
      "context" : "General non-convex manifold optimization techniques [1] tell us that first-order methods, such as SGD, will converge to a fixed point, but they provide no convergence rate to the global optimum.",
      "startOffset" : 52,
      "endOffset" : 55
    }, {
      "referenceID" : 22,
      "context" : "[25] study matrix completion and provides a convergence rate for an exact recovery algorithm, alternating minimization.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 10,
      "context" : "[11] provide a similar result for phase retrieval.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 2,
      "context" : "A related class of algorithms that are similar to Alecton is stochastic power iteration [3].",
      "startOffset" : 88,
      "endOffset" : 91
    }, {
      "referenceID" : 2,
      "context" : "Stochastic power iteration has been applied to a wide variety of problems [3, 26].",
      "startOffset" : 74,
      "endOffset" : 81
    }, {
      "referenceID" : 23,
      "context" : "Stochastic power iteration has been applied to a wide variety of problems [3, 26].",
      "startOffset" : 74,
      "endOffset" : 81
    }, {
      "referenceID" : 28,
      "context" : "Oja [31] show convergence of this algorithm, but provides no rate.",
      "startOffset" : 4,
      "endOffset" : 8
    }, {
      "referenceID" : 3,
      "context" : "[4] analyze this problem, and state that “obtaining a theoretical understanding of the stochastic power method, or of how the step size should be set, has proved elusive.",
      "startOffset" : 0,
      "endOffset" : 3
    }, {
      "referenceID" : 32,
      "context" : "Shamir [35] provide exponential-rate local convergence results for a stochastic power iteration algorithm for PCA.",
      "startOffset" : 7,
      "endOffset" : 11
    }, {
      "referenceID" : 4,
      "context" : "[5] and Hardt and Price [21] provide a global convergence rate for the stochastic power iteration algorithm.",
      "startOffset" : 0,
      "endOffset" : 3
    }, {
      "referenceID" : 18,
      "context" : "[5] and Hardt and Price [21] provide a global convergence rate for the stochastic power iteration algorithm.",
      "startOffset" : 24,
      "endOffset" : 28
    }, {
      "referenceID" : 24,
      "context" : "Previous work has used manifold optimization techniques to solve such symmetric problems [27].",
      "startOffset" : 89,
      "endOffset" : 93
    }, {
      "referenceID" : 0,
      "context" : "[1] state that stochastic gradient descent on a manifold has the general form xk+1 = xk − αkG xk ∇f̃k(xk), where Gx is the matrix such that for all u and v, uGxv = 〈u, v〉x, 3",
      "startOffset" : 0,
      "endOffset" : 3
    }, {
      "referenceID" : 0,
      "context" : "[1], this manifold has induced Riemannian metric 〈U, V 〉Y = tr ( UY Y V T ) .",
      "startOffset" : 0,
      "endOffset" : 3
    }, {
      "referenceID" : 15,
      "context" : "We then use the optional stopping theorem [17] to bound both the probability and rate of convergence of xk, from which we derive convergence of the original algorithm.",
      "startOffset" : 42,
      "endOffset" : 46
    }, {
      "referenceID" : 31,
      "context" : "1 Martingale Technique A proof for Theorem 1 and full formal definitions will appear in Appendix C of this document, but since the method is nonstandard for non-convex optimization (although it has been used in Shamir [34] to show convergence for convex problems), we will outline it here.",
      "startOffset" : 218,
      "endOffset" : 222
    }, {
      "referenceID" : 15,
      "context" : "We show that, if neither success nor failure occurs at time k, E [τk+1|Fk] ≥ τk (1 +R (1− τk)) (6) for some constant R; here, Fk denotes the filtration at time k, which contains all the events that have occurred up to time k [17].",
      "startOffset" : 225,
      "endOffset" : 229
    }, {
      "referenceID" : 15,
      "context" : "We use the optional stopping Theorem [17] (here we state a discrete-time version).",
      "startOffset" : 37,
      "endOffset" : 41
    }, {
      "referenceID" : 11,
      "context" : "1 Entrywise Sampling One sampling distribution that arises in many applications (most importantly, matrix completion [12]) is entrywise sampling.",
      "startOffset" : 117,
      "endOffset" : 121
    }, {
      "referenceID" : 22,
      "context" : "It is standard for these types of problems to introduce a matrix coherence bound [25].",
      "startOffset" : 81,
      "endOffset" : 85
    }, {
      "referenceID" : 22,
      "context" : "3 Trace Sampling Another common sampling distribution arises from the matrix sensing problem [25].",
      "startOffset" : 93,
      "endOffset" : 97
    }, {
      "referenceID" : 10,
      "context" : "(This problem has been handled for the more general complex case in [11] using Wirtinger flow.",
      "startOffset" : 68,
      "endOffset" : 72
    }, {
      "referenceID" : 5,
      "context" : "Consider the following distribution, which arises in subspace tracking [6].",
      "startOffset" : 71,
      "endOffset" : 74
    }, {
      "referenceID" : 27,
      "context" : "1 Discussion The Hogwild! algorithm [30] is a parallel, lock-free version of stochastic gradient descent that has been shown to perform similarly to sequential SGD on convex problems, while allowing for a good parallel speedup.",
      "startOffset" : 36,
      "endOffset" : 40
    }, {
      "referenceID" : 0,
      "context" : "References [1] P.",
      "startOffset" : 11,
      "endOffset" : 14
    }, {
      "referenceID" : 1,
      "context" : "[2] Alekh Agarwal, Olivier Chapelle, Miroslav Dudı́k, and John Langford.",
      "startOffset" : 0,
      "endOffset" : 3
    }, {
      "referenceID" : 2,
      "context" : "[3] R.",
      "startOffset" : 0,
      "endOffset" : 3
    }, {
      "referenceID" : 3,
      "context" : "[4] Raman Arora, Andy Cotter, and Nati Srebro.",
      "startOffset" : 0,
      "endOffset" : 3
    }, {
      "referenceID" : 4,
      "context" : "[5] Akshay Balsubramani, Sanjoy Dasgupta, and Yoav Freund.",
      "startOffset" : 0,
      "endOffset" : 3
    }, {
      "referenceID" : 5,
      "context" : "[6] Laura Balzano, Robert Nowak, and Benjamin Recht.",
      "startOffset" : 0,
      "endOffset" : 3
    }, {
      "referenceID" : 6,
      "context" : "[7] Lon Bottou.",
      "startOffset" : 0,
      "endOffset" : 3
    }, {
      "referenceID" : 7,
      "context" : "[8] Lon Bottou and Olivier Bousquet.",
      "startOffset" : 0,
      "endOffset" : 3
    }, {
      "referenceID" : 8,
      "context" : "[9] Samuel Burer and Renato DC Monteiro.",
      "startOffset" : 0,
      "endOffset" : 3
    }, {
      "referenceID" : 9,
      "context" : "[10] Samuel Burer and Renato DC Monteiro.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 10,
      "context" : "[11] Emmanuel Candès, Xiaodong Li, and Mahdi Soltanolkotabi.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 11,
      "context" : "[12] Emmanuel J.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 12,
      "context" : "[13] EmmanuelJ.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 13,
      "context" : "[14] Caihua Chen, Bingsheng He, and Xiaoming Yuan.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 14,
      "context" : "[16] John Duchi, Elad Hazan, and Yoram Singer.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 15,
      "context" : "[17] Thomas R Fleming and David P Harrington.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 16,
      "context" : "[19] Michel X.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 17,
      "context" : "[20] Pankaj Gupta, Ashish Goel, Jimmy Lin, Aneesh Sharma, Dong Wang, and Reza Zadeh.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 18,
      "context" : "[21] Moritz Hardt and Eric Price.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 19,
      "context" : "[22] Steven Homer and Marcus Peinado.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 20,
      "context" : "[23] R.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 21,
      "context" : "[24] Chonghai Hu, James T.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 22,
      "context" : "[25] Prateek Jain, Praneeth Netrapalli, and Sujay Sanghavi.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 23,
      "context" : "[26] Raman Arora John Goes, Teng Zhang and Gilad Lerman.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 24,
      "context" : "[27] M.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 25,
      "context" : "[28] R.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 26,
      "context" : "[29] Bamdev Mishra, Gilles Meyer, Francis Bach, and Rodolphe Sepulchre.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 27,
      "context" : "[30] Feng Niu, Benjamin Recht, Christopher Ré, and Stephen J.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 28,
      "context" : "[31] Erkki Oja.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 29,
      "context" : "[32] Ian O’Connell Jimmy Lin Oscar Boykin, Sam Ritchie.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 30,
      "context" : "[33] Benjamin Recht and Christopher Ré.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 31,
      "context" : "[34] Ohad Shamir.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 32,
      "context" : "[35] Ohad Shamir.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 33,
      "context" : "[36] Christina Teflioudi, Faraz Makari, and Rainer Gemulla.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 25,
      "context" : "Algorithm Sampling Scheme Complexity Sampling Computational Alecton Any O(ǫ−1p3n log n) SVD Various o(pn) O(n3) Spectral Matrix Completion [28] Elementwise o(pn) O(p2n log n) PhaseLift [13] Phase Retrieval o(n) O(ǫ−1n3) Alternating Minimization [41] Phase Retrieval o(n log(ǫ−1)) O(n2 log2(ǫ−1)) Wirtinger Flow [11] Phase Retrieval o(n log n) O(pn log(ǫ−1)) Equivalently, if we let A denote the edge-matrix of the graph, we can represent this as a matrix problem [19, 22] minimize yAy subject to yi ∈ {−1, 1}.",
      "startOffset" : 139,
      "endOffset" : 143
    }, {
      "referenceID" : 12,
      "context" : "Algorithm Sampling Scheme Complexity Sampling Computational Alecton Any O(ǫ−1p3n log n) SVD Various o(pn) O(n3) Spectral Matrix Completion [28] Elementwise o(pn) O(p2n log n) PhaseLift [13] Phase Retrieval o(n) O(ǫ−1n3) Alternating Minimization [41] Phase Retrieval o(n log(ǫ−1)) O(n2 log2(ǫ−1)) Wirtinger Flow [11] Phase Retrieval o(n log n) O(pn log(ǫ−1)) Equivalently, if we let A denote the edge-matrix of the graph, we can represent this as a matrix problem [19, 22] minimize yAy subject to yi ∈ {−1, 1}.",
      "startOffset" : 185,
      "endOffset" : 189
    }, {
      "referenceID" : 10,
      "context" : "Algorithm Sampling Scheme Complexity Sampling Computational Alecton Any O(ǫ−1p3n log n) SVD Various o(pn) O(n3) Spectral Matrix Completion [28] Elementwise o(pn) O(p2n log n) PhaseLift [13] Phase Retrieval o(n) O(ǫ−1n3) Alternating Minimization [41] Phase Retrieval o(n log(ǫ−1)) O(n2 log2(ǫ−1)) Wirtinger Flow [11] Phase Retrieval o(n log n) O(pn log(ǫ−1)) Equivalently, if we let A denote the edge-matrix of the graph, we can represent this as a matrix problem [19, 22] minimize yAy subject to yi ∈ {−1, 1}.",
      "startOffset" : 311,
      "endOffset" : 315
    }, {
      "referenceID" : 16,
      "context" : "Algorithm Sampling Scheme Complexity Sampling Computational Alecton Any O(ǫ−1p3n log n) SVD Various o(pn) O(n3) Spectral Matrix Completion [28] Elementwise o(pn) O(p2n log n) PhaseLift [13] Phase Retrieval o(n) O(ǫ−1n3) Alternating Minimization [41] Phase Retrieval o(n log(ǫ−1)) O(n2 log2(ǫ−1)) Wirtinger Flow [11] Phase Retrieval o(n log n) O(pn log(ǫ−1)) Equivalently, if we let A denote the edge-matrix of the graph, we can represent this as a matrix problem [19, 22] minimize yAy subject to yi ∈ {−1, 1}.",
      "startOffset" : 463,
      "endOffset" : 471
    }, {
      "referenceID" : 19,
      "context" : "Algorithm Sampling Scheme Complexity Sampling Computational Alecton Any O(ǫ−1p3n log n) SVD Various o(pn) O(n3) Spectral Matrix Completion [28] Elementwise o(pn) O(p2n log n) PhaseLift [13] Phase Retrieval o(n) O(ǫ−1n3) Alternating Minimization [41] Phase Retrieval o(n log(ǫ−1)) O(n2 log2(ǫ−1)) Wirtinger Flow [11] Phase Retrieval o(n log n) O(pn log(ǫ−1)) Equivalently, if we let A denote the edge-matrix of the graph, we can represent this as a matrix problem [19, 22] minimize yAy subject to yi ∈ {−1, 1}.",
      "startOffset" : 463,
      "endOffset" : 471
    }, {
      "referenceID" : 15,
      "context" : "1 Definitions Fleming and Harrington [17] provide the following definitions of filtration and martingale.",
      "startOffset" : 37,
      "endOffset" : 41
    }, {
      "referenceID" : 0,
      "context" : "∣ M +W [ 0 1 1 1 ]",
      "startOffset" : 7,
      "endOffset" : 18
    }, {
      "referenceID" : 0,
      "context" : "∣ M +W [ 0 1 1 1 ]",
      "startOffset" : 7,
      "endOffset" : 18
    }, {
      "referenceID" : 0,
      "context" : "∣ M +W [ 0 1 1 1 ]",
      "startOffset" : 7,
      "endOffset" : 18
    }, {
      "referenceID" : 0,
      "context" : "[ 0 1 1 1 ]−1 = [ −1 1 1 0 ]",
      "startOffset" : 0,
      "endOffset" : 11
    }, {
      "referenceID" : 0,
      "context" : "[ 0 1 1 1 ]−1 = [ −1 1 1 0 ]",
      "startOffset" : 0,
      "endOffset" : 11
    }, {
      "referenceID" : 0,
      "context" : "[ 0 1 1 1 ]−1 = [ −1 1 1 0 ]",
      "startOffset" : 0,
      "endOffset" : 11
    }, {
      "referenceID" : 10,
      "context" : "Secondary Literature [11] Emmanuel Candès, Xiaodong Li, and Mahdi Soltanolkotabi.",
      "startOffset" : 21,
      "endOffset" : 25
    }, {
      "referenceID" : 12,
      "context" : "[13] EmmanuelJ.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 25,
      "context" : "[28] R.",
      "startOffset" : 0,
      "endOffset" : 4
    } ],
    "year" : 2014,
    "abstractText" : "Abstract Stochastic gradient descent (SGD) on a low-rank factorization [9] is commonly employed to speed up matrix problems including matrix completion, subspace tracking, and SDP relaxation. In this paper, we exhibit a step size scheme for SGD on a low-rank least-squares problem, and we prove that, under broad sampling conditions, our method converges globally from a random starting point within O(ǫn logn) steps with constant probability for constant-rank problems. Our modification of SGD relates it to stochastic power iteration. We also show experiments to illustrate the runtime and convergence of the algorithm.",
    "creator" : "gnuplot 4.6 patchlevel 4"
  }
}