{
  "name" : "1511.06418.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : null,
    "authors" : [ "RECONSTRUCTION CLUSTERING", "Klaus Greff", "Rupesh Kumar Srivastava" ],
    "emails" : [ "klaus@idsia.ch", "rupesh@idsia.ch", "juergen@idsia.ch" ],
    "sections" : [ {
      "heading" : "1 THE BINDING PROBLEM",
      "text" : "Two important properties of good representations are that they are distributed and disentangled. Distributed representations (Hinton, 1984) are far more expressive than local ones, requiring exponentially fewer features to capture the same space. Complementary to that, disentangling (Barlow et al., 1989; Schmidhuber, 1992; Bengio et al., 2007) requires the factors of variation in the data to be separated into different independent features. This concept is closely related to invariance and eases further processing because many properties, that we might be interested in, are invariant under a wide variety of transformations (Bengio et al., 2013a). Unfortunately distributed representations can interfere and lead to ambiguities when multiple objects are to be represented at the same time.\nThe binding problem refers to these ambiguities that can arise from the superposition of multiple distributed representations. This problem has been debated quite extensively in the neuroscience and psychology communities perhaps starting with Milner (1974) and von der Malsburg (1981), but its existence can be traced back at least to a description by Rosenblatt (1961). It is classically demonstrated with a system required to identify an input as either square( ) or triangle(4) and to decide whether it is at the top(↑) or at the bottom(↓). It represents every object as a distributed representation with two active disentangled features (see Figure 1b). The binding problem arises when the system is presented with two objects at the same time: In this scenario, all four features become active and from the representation alone it cannot be determined whether the input contains a square on top and a triangle at the bottom or vice versa.\nOne way the system can circumvent this problem is through the use of a local representation, with one feature for each combination of shape and position: 4↑,4↓, ↑, ↓. Sadly the size of such a purely local-representation scales exponentially with the number of factors to represent. In contrast, distributed representations (Hinton, 1984) are much more expressive and can generalize better through the reuse of features. The former system could, for example, correctly represent the position for a new object such as a circle by the already available position features (↑↓). Generalization of internal representations is a crucial capability of any intelligent system, and one that still sets humans apart from current machine learning systems. Consider Figure 1a, an example from studies in psychology: chances are this is the first time you see a Greeble (Gauthier & Tarr, 1997). Nevertheless, you are capable of describing its shape, texture, and color. Moreover, you can easily segment it and tell it apart from the background, without having seen any other Greeble before.\nar X\niv :1\n51 1.\n06 41\n8v 4\n[ cs\n.L G\n] 2\n0 Ja\nn 20\n16\nIt has long been argued that such generalization capabilities are a result of the use of distributed representations in the human brain.\nDespite its importance to the neuroscience community, binding has received relatively little attention in representation learning. Two important reasons for this are:\nFirstly, most pattern recognition tasks and benchmarks are set up to avoid the binding problem. Many popular visual pattern recognition datasets consist of images that contain only one object at a time. Similarly, speech recognition mostly considers recordings of just one speaker talking and little background noise. In these settings, a machine learning algorithm can assume that there is only a single prominent object of interest, reducing the binding problem to the problem of ignoring irrelevant details. When tackling more challenging problems such as image caption generation, scene parsing segmentation, or the cocktail party problem, the deficiencies of popular methods become more apparent and restrictive.\nSecondly, the recent increase in processing power due to the use of Graphics Processing Units made it feasible to mitigate the binding problem using localized binding in the form of convolutions (Riesenhuber & Poggio, 1999). Convolutional Networks (Fukushima, 1979; Le Cun et al., 1990) use feature detectors with limited receptive fields (filters) replicated over the whole input to represent its inputs. Therefore the resulting features of spatially separated objects do not interact: they are invariant to changes outside their field of view. On the other hand, they do not disentangle the location from the detected pattern, which comes at the cost of having to compute the same feature replicated many times over the image. While this is reasonable for low-level features like edges, it seems wasteful to replicate specialized high-level features such as dog-faces.\nIn this paper, we develop an unsupervised method that dynamically binds features of different objects together. This is in contrast to local representations which by nature statically bind several input features together (a feature for ↑ permanently binds the concepts and ↑ together). It explicitly models inputs as a composition of multiple entities and recovers these “objects” using the notion of mutual predictability. This is achieved through a clustering process which utilizes a denoising autoencoder (DAE; Behnke, 2001; Vincent et al., 2008) to iteratively reconstruct an input. In the future, such a mechanism could help to effectively use distributed representations in multi-object settings without being impaired by the ambiguities due to superposition. Alternative approaches to the binding problem proposed in the literature are discussed in Section 5."
    }, {
      "heading" : "2 RECONSTRUCTION CLUSTERING",
      "text" : "This section describes Reconstruction Clustering (RC), a formal framework for tackling the binding problem as a clustering problem. For ease of explanation we will refer to inputs as images and the individual dimensions of an input as pixels, though the framework is not restricted to visual inputs. It is based upon two insights: Firstly, if the image was segmented into its constituent objects, there would be no binding problem. Secondly, the intuitive notion of an object can be formalized as a group of mutually predictive pixels. The proposed method therefore iteratively clusters pixels based on how well they predict each other."
    }, {
      "heading" : "2.1 IMAGES AS COMPOSITIONS",
      "text" : "The first central idea behind RC is to model images as being composed of several independent objects with each pixel belonging to one of them. Unlike in classic segmentation where each pixel is assigned to a predefined class, the goal here is to simply segregate different objects. In doing so we avoid all ambiguities that might arise from a superposition of their representations. Of course, the information about which objects are present and which pixels they consist of is unknown in practical applications. So for each image, the aim is to infer both the object representations and the corresponding pixel assignments.\nFormally, we introduce a binary latent vector zi for each pixel xi that specifies which of the K objects it belongs to. Therefore, zi = (zi1, zi2, . . . , ziK) ∈ {0, 1}K with the constraint that ∑K k=1 zik = 1. Let N ∈ N denote the number of pixels in the image x = {x1, . . . , xN}. Then we define the prior over Z = {z1, . . . , zN} as:\nP (Z|π) = N∏ i=1 P (zi|π) = N∏ i=1 K∏ k=1 πzikk , (1)\nwhere the zi’s are assumed to be independent given π = {π1, . . . , πK}. The assumed probabilistic structure is shown in Figure 2a. We assume π to be uniformly distributed for simplicity, but its estimation can be incorporated into the algorithm if required (see Appendix)."
    }, {
      "heading" : "2.2 OBJECTS",
      "text" : "So far, we have used the word object to describe a group of pixels that somehow “belong together”. The second central idea of RC is to concretize that notion using mutual predictability of the pixels. Intuitively, knowing about some pixel values that belong to an object helps in predicting the others. An example can be seen in Figure 1c where the corrupted pixels in the bottom left corner of the square could be reconstructed from knowledge about the rest of the square, but not from any of the triangles. So we define an object as a group of pixels that help in predicting each other, but do not carry information about pixels outside of that group.\nPredictability, as we use it here, is derived from the structure of the underlying data-distribution. Knowledge about this structure is also precisely what is needed in order to remove corruption from an image. Based on this insight, we propose to use a denoising autoencoder (DAE) to measure predictability."
    }, {
      "heading" : "2.3 DENOISING AUTOENCODER",
      "text" : "Let f be the encoder and g be the decoder of a DAE, such that θ = f(x) is the encoded representation of input x and µ = g(θ) is the decoded output. The DAE is trained to remove corruption from images of single objects and thus learns a local model of the data generating distribution (Vincent et al., 2008; Bengio et al., 2013b). After training the same DAE is used for each of the clusters to get predictions µik from cluster k for pixel i, where the object in cluster k is represented by θk:\nP (x|θk) = N∏ i=1 P (xi|θk) = N∏ i=1 P (xi|µik) (2)\nHere xi’s are assumed to be independent given µ. Combining this with the latent variables we get:\nP (x|Z, θ) = N∏ i=1 K∏ k=1 P (xi|µik)zik (3)"
    }, {
      "heading" : "2.4 CLUSTERING",
      "text" : "We can now outline a clustering algorithm that estimates the object identities and the corresponding pixel assignments. Formally, we seek to maximize the complete data log-likelihood:\nlogP (x,Z|µ,π) = N∑ i=1 K∑ k=1 zik(logP (xi|µi) + log πk) (4)\nThis can be done in an iterative procedure where we start by randomly initializing the latent cluster assignments Z and then alternating between the following two steps:\n1. Apply the autoencoder to the each of the K images that are assigned to the clusters to get a new estimate of the K object representations. (R-step)\n2. Re-assign the pixels to the clusters according to their reconstruction accuracy. (E-step)"
    }, {
      "heading" : "2.4.1 RECONSTRUCTION STEP",
      "text" : "The R-step applies the encoder to generate a new object representation from each of the K partial images that are assigned to each cluster. We call this representation of a partial image since the encoder only gets to see as much of each pixel of the original image as has been soft-assigned to the current cluster. The DAE then denoises the “corruption” caused by the cluster assignments. The R-Step is thus given by the following formula, where denotes point-wise multiplication:\nθk = f(γk x), (5)\nUnfortunately this step can not be guaranteed to increase the expected log-likelihood, because only in expectation does the DAE map from regions of low likelihood to regions of higher likelihood. Moreover, this property only holds for the whole image and not for all subsets of pixels. Thus, convergence can’t be proven and RC is not an Expectation Maximization algorithm (Dempster et al., 1977). Nevertheless, empirical results show that convergence does occur reliably (Section 4.2)."
    }, {
      "heading" : "2.4.2 ESTIMATION STEP",
      "text" : "In the E-step, for each pixel xi the posterior γik of Z, given the data and the predictions µi = {g(θ1)i, . . . , g(θK)i} of the autoencoders based on the object representations, is\nγik = P (zik = 1|xi,µi,π) = P (xi|zik = 1,µi)P (zik = 1|π)\nP (xi|µi,π) . (6)\nIn this paper, we assume the pixels x to be binary and the predictions of the network µ to correspond to the mean of a binomial distribution. Then the following performs a soft-assignment of the pixels to the K different clusters:\nγik = µxiik(1− µik) 1−xiπk K∑ j=1 µxiij (1− µij) 1−xiπj . (7)"
    }, {
      "heading" : "3 EXPERIMENTS",
      "text" : "We evaluated RC on a series of artificially generated datasets consisting of binary images of varying complexity. For each dataset, a DAE was trained to remove salt&pepper noise on images with single objects. The autoencoders used were fully-connected feed-forward neural networks with a single hidden layer and sigmoid output units. A random search was used to select appropriate hyperparameters (see Appendix for details). The best DAE obtained for each dataset was used for reconstruction clustering on 1000 test images containing multiple objects, and the binding performance was evaluated based on groud-truth object identities. All the code for this paper (including the creation of the datasets and figures) is available online on GitHub.com/Qwlouse/Binding."
    }, {
      "heading" : "3.1 DATASETS",
      "text" : "Representative examples from the datasets are shown in Figure 3.\nSimple Superposition A collection of simple pixel patterns two of which are superimposed. Taken from Rao et al. (2008). This is a simple dataset with no translations, but significant overlap between patterns.\nShapes Taken from Reichert & Serre (2013). Three shapes ( ,4,5) are randomly placed in an image (possibly with overlap). This dataset tests binding of shapes under translation invariance and varying overlap.\nBars Introduced by Földiak (1990) to demonstrate unsupervised learning of independent components of an image. We use the variant from Reichert & Serre (2013) which employs 6 horizontal, and 6 vertical lines placed in random positions in the image.\nCorners This dataset consists of 8 corner shapes placed in random orientations and positions, such that 4 of them align to form a square. It was introduced by Reichert & Serre (2013) to demonstrate that spatial connected-ness is not a requirement for binding.\nMNIST+Shape Another dataset from Reichert & Serre (2013), which combines a random shape from the shapes dataset with a single MNIST digit. This dataset is useful to investigate binding multiple types of objects.\nMulti-MNIST Three random MNIST digits are randomly placed in a 48×48 image. It provides a more challenging setup with multiple complex objects.\n0.0 0.2 0.4 0.6 0.8 1.0 mean(AMI Score)\nBars\nCorners\nShapes\nMulti MNIST\nMNIST+Shape\nSimple Superposition\n# Clusters 12 5 3 2\n(a) Overall Scores\n0 1 2 3 4 5 6 7 8 9 Iteration\n350\n300\n250\n200\n150\n100\n50\n0\nLo g \nLi ke\nlih oo\nd\n# Clusters 12 5 3 2\n(b) Convergence\nFigure 4: Left: Mean AMI score over 1000 test samples for all datasets and various number of clusters K. Right: Convergence of the log-likelihood on the shapes dataset for different numbers of clusters, showing test set mean (line) and standard deviation (shaded) over the test set."
    }, {
      "heading" : "3.2 EVALUATION",
      "text" : "Since the data is generated, a ground-truth segmentation for each image is available. For the binding task, all pixels corresponding to the same object should be clustered together. We evaluated performance by measuring the Adjusted Mutual Information (AMI; Vinh et al., 2010) between the true segmentation and the result of the binding, to which we refer to as the score. This score measures how well two cluster assignments agree and takes a value of 1 when they are equivalent, and 0 when their agreement corresponds to that expected by chance. Only pixels that unambiguously belong to one object were counted, ignoring background pixels and regions where multiple objects overlap."
    }, {
      "heading" : "4 RESULTS",
      "text" : ""
    }, {
      "heading" : "4.1 SCORES",
      "text" : "Figure 4a shows the mean scores obtained using RC for each dataset averaged over 100 runs. Scores obtained with different choices of the number of clusters K. Results are consistent across runs, hence the standard deviations are very low and barely visible. The optimal number of clusters is two for Simple Superposition and MNIST+Shape, three for Multi MNIST and Shapes, five for Corners, and 12 for Bars. Scores are higher than 0.5 for all datasets and higher than 0.8 for four out of the six datasets demonstrating the ability of RC to successfully bind objects together."
    }, {
      "heading" : "4.2 CONVERGENCE",
      "text" : "Figure 4b shows the convergence of the mean log-likelihood over RC iterations on the shapes dataset. Convergence is quick, typically within 5-10 iterations, depending on the chosen number of clusters K and the dataset (not shown). As expected, the final likelihood is highest when the number of clusters equals the number of objects in the shapes dataset (3), matching the results from Figure 4a. The likelihood is much lower for k = 2 than for k = 3 and drops again slightly if we choose k = 5. The likelihood for k = 12 is significantly lower. In some cases the correct choice of k did not result in the highest likelihood, but in general this correspondence appeared to hold. If the number of objects is unknown, this trend can be used to determine the correct number of clusters."
    }, {
      "heading" : "4.3 QUALITATIVE ANALYSIS",
      "text" : "Figure 5 shows a few example RC runs of on the shapes dataset for qualitative evaluation. The initial cluster assignments are random, therefore all observed structure is due to the clustering process. The final clustering corresponds well to the ground truth even for cases with significant overlap. Again, it is notable that RC converges quickly (within 5 iterations)."
    }, {
      "heading" : "4.4 LOSS VS SCORE",
      "text" : "RC utilizes autoencoders trained with the denoising objective for binding. Therefore, it is instructive to examine the relationship between denoising performance and the final RC binding score. For this purpose, we trained 100 DAEs with the same architecture on each dataset with random learning rates and initializations, and then performed RC using each of them. Figure 6a shows the relationship between the denoising loss and binding score for each dataset. It can be observed that lower loss correlates positively with higher score for all datasets, indicating that denoising is a suitable surrogate training objective. We added a regression line to indicate that relation for each dataset, even though for MNIST+Shape and Multi MNIST it doesn’t look even remotely linear. Instead, the individual points are approximately arranged on a curve. This suggests that there is a direct but complex interplay between the denoising performance and the score."
    }, {
      "heading" : "4.5 TRAINING ON MULTIPLE OBJECTS",
      "text" : "So far the DAEs were trained on single-object images, then used to bind objects in multi-object images. In general it is desirable to not require single-object images for training, and be able to directly use any image without this restriction. This would remove the last bit of supervision and make RC a truly unsupervised method.\nWhy should this work at all? On the surface it seems that RC would depend on the DAE to prefer single objects in order to work correctly. However, even if each cluster tries to reconstruct every object, there will be small asymmetries due to the difference in inputs they see. Since no object carries any information about the shape and position of another object in our datasets, this will lead to differences in prediction quality of the objects. The resulting difference in reconstruction quality will then be amplified by RC and can still lead to a segregation of the objects.\nTo test this scenario, we performed a new random search to tune DAE hyperparameters for the case of multi-object training. Similar to the single-object case, we then used the best obtained DAEs to perform RC on test examples. We found that with soft-assignments to the clusters, the differences were too small and would even out over several iterations, leading to uniform cluster assignments. By changing the E-step to hard (K-Means-like) assignments, we were able to amplify these changes enough to make the whole procedure work. Figure 6b shows that DAEs trained on multi-object images can indeed be used for binding via RC with hard assignments, although they lead to lower scores in comparison. Further discussion and examples for this case can be found in Appendix C."
    }, {
      "heading" : "4.6 GENERALIZATION TO A NEW DOMAIN",
      "text" : "A central intuition behind our approach to binding is that the low-level structures learned by the model will generalize to new and unseen configurations. Evaluation on unseen test sets demonstrated\nthis to be true, but we can take it one step further. We can test what happens when we confront our method with novel objects that the auto-encoders have not been trained on.\nWe ran RC on several images with non-digits using a DAE trained on the Multi-MNIST dataset. Figure 7 shows that RC “correctly” binds letters and circles together. We also show images for which the resulting binding differs from our expectation. It appears that the network has mainly learned to bind based on spatial proximity with a slight bias towards vertical proximity. This can be expected since that it has only seen digits of roughly the same size so far, and because the used autoencoder is very limited. Nevertheless, it is very interesting that a fully-connected network which is permutation invariant learns the preference for spatial proximity entirely from data. It is reasonable to speculate that it in the future it may be possible to recover other Gestalt Principles such as continuity and similarity with a similar procedure."
    }, {
      "heading" : "5 RELATIONSHIP TO OTHER METHODS",
      "text" : "The binding problem and its possible solutions are a long standing debate in the neuroscience literature (see e.g. Milner (1974); von der Malsburg (1981); Gray (1999); Treisman (1999); Di Lollo (2012)). A major thread of work on binding has been inspired by the temporal correlation theory (von der Malsburg, 1981), based on utilizing synchronous oscillations to bind neuronal activities together. von der Malsburg (1995) provides an overview of these ideas. Recently, these ideas were implemented using complex valued activations in neural networks to jointly encode firing rate and phase (Rao et al., 2008; Reichert & Serre, 2013). Such binding mechanisms are close to their biological inspiration, clustering only implicitly through synchronization. In contrast, RC is based on a mathematical framework which explicitly incorporates binding.\nMechanisms for tackling the binding problem which do not require temporal synchronization have also been proposed (e.g. O’Reilly et al., 2003). O’reilly & Busby (2002) argued that the intuitive explanation of the binding problem from Figure 1b only applies if the distributed features themselves are local codes. They suggested that neural networks can avoid the binding problem using coarse-coded representations. Various feature representation types including coarse-coding and their limitations were described by Hinton (1984).\nIn principle, Recurrent Neural Networks (RNNs; e.g. Robinson & Fallside, 1987; Werbos, 1988) can solve the binding problem by learning a mechanism to avoid it. Psychologists (Di Lollo, 2012) and machine learning researchers (Weng et al., 2006) alike have suggested feedback as a mechanism to do binding. An RNN may utilize an implicit or explicit attention mechanism to selectively process different parts of the input (Schmidhuber & Huber, 1991; Mnih et al., 2014; Bahdanau et al., 2014). In this context, explicit binding via RC can be seen as a technique of paying attention to multiple objects at once, instead of focusing on them sequentially.\nIn some aspects, RC is similar to segmentation algorithms. The main difference is that RC learns the segmentation from the data in a largely unsupervised manner. In this sense, it is more similar to superpixel methods (see e.g. Achanta et al. (2012) for an overview). However, these methods impose a handcrafted similarity measure over pixels or pixel regions, whereas RC learns a non-linear similarity measure from the data, parameterized by a DAE."
    }, {
      "heading" : "6 CONCLUSION AND FUTURE WORK",
      "text" : "We introduced the Reconstruction Clustering framework to explicitly model data as a composition of objects, where the notion of object-ness is defined by mutual predictability. Compared to many previous solutions to the binding problem, this framework is mathematically rigorous, integrates well with current representation learning methods, and is effective for a variety of binary image datasets.\nWhile a typical representation learning method (such as a denoising autoencoder) learns a static binding of features, Reconstruction Clustering utilizes it to iteratively perform dynamic binding for every input example by introducing interaction between the statically bound features extracted by the autoencoder. In particular, this interaction enables dynamic binding of feature combinations never seen before by the autoencoder.\nThis paper lays the groundwork for many concrete lines of future exploration. The treatment of real-valued inputs is an important next step to extension RC towards natural data. Also the use of more powerful autoencoders will be key. Integrating RC with the training of the DAE should help to deal with multiple objects in the training data. Since the method is general, we expect to apply it to other domains such as audio data (binding different speaker voices together) or medical data (binding various related symptoms of disease together). A particularly interesting direction for future work is to show that Gestalt principles are a natural result of such a representation learning approach."
    }, {
      "heading" : "ACKNOWLEDGMENTS",
      "text" : "We thank Jan Koutnı́k, Sjoerd van Steenkiste, Boyan Beronov and Julian Zilly for helpful discussions and comments. This project was funded by the EU project NASCENCE (FP7-ICT-317662)."
    }, {
      "heading" : "A RECONSTRUCTION CLUSTERING DERIVATION",
      "text" : "This section contains a more detailed derivation of Reconstruction Clustering (RC) for binary inputs. It follows the notation and derivation of an Expectation Maximization (EM) algorithm wherever possible. Only for the M-step does RC deviate from EM.\nConsider N binary random variables (one for each pixel) that are distributed according to a mixture of K Bernoulli distributions with means µi = (µi1, µi2, . . . , µiK) and mixing coefficients π = (π1, π2, . . . , πK) that sum to one ∑K k=1 πk = 1. Under this model the data likelihood given the parameters is given by:\nP (xi|µi,π) = K∑\nk=1\nπkµ xi ik(1− µik) 1−xi (8)\nBy defining x = (x1, x2, . . . , xN ) and µ = (µ1,µ2, . . . ,µN ) and assuming independence of the xi’s given µ and π (but not identical distribution)1 we get the (incomplete) log likelihood function for this model:\nlogP (x|µ,π) = N∑ i=1 logP (xi|µi,π) (9)\nLet us now introduce an explicit binary latent variable zi = (zi1, zi2, . . . , ziK) ∈ {0, 1}K with∑K k=1 zik = 1 associated with each xi. Let the prior distribution be:\nP (Z|π) = N∏ i=1 P (zi|π) = N∏ i=1 K∏ k=1 πzikk , (10)\nwhere we set Z = (z1, z2, . . . , zN ) and assume zi’s to be independent given π. With that we define the conditional distribution of xi given the latent variables as:\nP (xi|zi,µi) = K∏\nk=1\nP (xi|µik)zik (11)\n= K∏ k=1 (µxiik(1− µik) 1−xi)zik (12)\nIf we marginalize Equation 12 over all choices of zi we recover Equation 8:\n∑ z P (xi|z,µi,π)P (z|π) = ∑ z K∏ k=1 (µxiik(1− µik) 1−xi)zkπzkk (13)\n= K∑ k=1 πkµ xi ik(1− µik) 1−xi (14)\n= P (xi|µi,π) (15)\nThe second line is obtained by realizing that the ∑\nz sums over exactly K terms, each corresponding to a z with one zk = 1 and all other entries equal to zero. So we can replace this sum by ∑K k=1. The product over the entries of z then vanishes except for the term corrsponding to the k-th entry. 1This assumption means that we assume the hidden representation of the DAE to capture the structure in the image well.\nUsing the same conditional independence assumption from before we can thus write the data distribution given all the latent variables as follows:\nP (x|Z,µ,π) = N∏ i=1 P (xi|zi,µi,π) (16)\nAnd by using Bayes rule and assuming that Z is independent of µ:\nP (x,Z|µ,π) = P (x|Z,µ,π)P (Z|π) (17)\n= N∏ i=1 K∏ k=1 (µxiik(1− µik) 1−xiπk) zik (18)\nIf we set θ = {µ,π}2 the complete-data log likelihood becomes:\nL(θ|x,Z) = logP (x,Z|µ,π) (19)\n= N∑ i=1 K∑ k=1 zik [xi logµik + (1− xi) log(1− µik) + log πk] (20)\nTo maximize L with respect to θ and Z we follow the same idea as the EM algorithm: Based on the observation that if we knew the values of either of these two, optimizing the other would be feasible. So we divide the optimization problem into two steps where we pretend to know either θ (E-step) or Z (M-step).\nIn the E-Step we assume to know θ and calculate the posterior probability of zik = 1 for each datapoint calling it γik: (We assume the zik to be independent of xj for i 6= j)\nγik = P (zik = 1|xi,µi,π) = P (xi|zik = 1,µi)P (zik = 1|π)\nP (xi|µi,π) (21)\n= µxiik(1− µik) 1−xiπk K∑ j=1 µxiij (1− µij) 1−xiπj\n(22)\nNext we calculate the Q value used in EM which is defined as the expectation of the complete data log-likelihood L with respect to the posterior of Z given the data and the old parameters θold:\nQ(θ,θold) = EZ[logP (x,Z|θ)|x,θold] (23) = ∑ Z P (Z|x,θold) logP (x,Z|θ) (24)\n= N∑ i=1 K∑ k=1 γik [xi logµik + (1− xi) log(1− µik) + log πk] (25)\nIn the M-step of EM we aim to maximize Q(θ,θold) over all choices of θ:\nθnew = argmax θ Q(θ,θold) (26)\n2Here we deviate slightly from the notation in the paper.\nUsing a Lagrange multiplier to enforce ∑K\nk=1 πk = 1 we find:\nπnewk = ∑N i=1 γik N\n(27)\nBut when maximizing wrt. µ we see that the maximum is trivially obtained by setting µik = xi for all k. This is due to the fact that the problem is actually ill-posed in the sense that we have K parameters to fit for each datapoint. So there are infinitely many solutions which achieve the optimal log likelihood of the data of 0.\nAt this point we introduce an autoencoder with encoder f and decoder g to restrict the capacity of our model by forcing µ to be:\nµ·k = g(f(γk x)) (28)\nWe use this reconstruction step (Equation 28) instead of an actual maximization step, thus deviating from the EM formulation."
    }, {
      "heading" : "B TRAINING DETAILS",
      "text" : "All experiments have been performed with the brainstorm library and were organized and logged using sacred. The code for this paper can be found on GitHub.\nB.1 TRAINING DENOISING AUTONCODERS\n• simple feed forward fully connected NNs • with sigmoid output layer • loss is Binomial Cross Entropy Error • trained with SGD • minibatch size 100 • salt& pepper noise • early stopped when validation BinomialCEE doesn’t decrease for more than 10 epochs\nB.2 RANDOM SEARCH\nThere are several hyperparameters to be chosen for the denoising autoencoders. To find good values we performed a random search with 100 runs for each dataset. For each run we randomly sampled from the following parameters:\n• learning rate log-uniform from [10−3, 1] • Amount of Salt& Pepper Noise from [0.0, 0.1, . . . , 0.9] • hidden layer size from [100, 250, 500, 1000] • hidden layer activation function from [rel, sigmoid, tanh]\nThe best network configurations found by that search can be found in Table 1.\nB.3 RANDOM SEARCH FOR TRAINING WITH MULTIPLE OBJECTS\nFor training with multiple objects we do an equivalent random search for hyperparameters. The only difference is the training data and that for determining the final score we use K-means-like (hard) cluster assignments in RC. Note also that we didn’t include the Simple Superposition dataset, since we only have 120 images with multiple objects available, and no separate test set."
    }, {
      "heading" : "C MULTI OBJECT TRAINING",
      "text" : "When training the DAEs on images with multiple objects, it is less obvious why running RC should lead to a segregation of the objects. It seems that the autoencoder should always try to reconstruct the whole image including all the objects. And if we run normal (soft) RC we in fact see that after a few iterations each pixel is equally represented by each cluster.\nBy switching to hard cluster assignments we eliminate this stable state, and force the clusters to compete more for the pixels. Together with the fact that in our datasets objects don’t carry any information about other objects this leads to a stronger amplification of the initial differences in reconstruction quality. In Figure 10 this process can be seen on the shapes dataset. Note that the hard RC converges even faster, but generally leads to worse performance.\nD ADDITIONAL FIGURES\n0.4 0.5 0.6 0.7 0.8 0.9 1.0\nTest Samples Sorted by Score\nscore confidence\nIn pu\nt I m\nag e\nA B C D E F\nC lu\nst er\n A ss\nig nm\nen ts\nG ro\nun d\nT ru\nth\n1400 1200 1000 800 600 400 200 0\nlog Likelihood\n10\n9\n8\n7\n6\n5\n4\n3\n2\n1\n0\nIteration nr\nA B C D E F\n600 500 400 300 200 100\n0 Z oom ed\nFigure 11\n0.4 0.5 0.6 0.7 0.8 0.9 1.0\nIn pu\nt I m\nag e\nC lu\nst er\n A ss\nig nm\nen ts\nG ro\nun d\nT ru\nth\n0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0\nIn pu\nt I m\nag e\nC lu\nst er\n A ss\nig nm\nen ts\nG ro\nun d\nT ru\nth"
    } ],
    "references" : [ {
      "title" : "SLIC superpixels compared to state-of-the-art superpixel methods",
      "author" : [ "Achanta", "Radhakrishna", "Shaji", "Appu", "Smith", "Kevin", "Lucchi", "Aurelien", "Fua", "Pascal", "Susstrunk", "Sabine" ],
      "venue" : "Pattern Analysis and Machine Intelligence, IEEE Transactions on,",
      "citeRegEx" : "Achanta et al\\.,? \\Q2012\\E",
      "shortCiteRegEx" : "Achanta et al\\.",
      "year" : 2012
    }, {
      "title" : "Neural machine translation by jointly learning to align and translate",
      "author" : [ "Bahdanau", "Dzmitry", "Cho", "Kyunghyun", "Bengio", "Yoshua" ],
      "venue" : "arXiv preprint arXiv:1409.0473,",
      "citeRegEx" : "Bahdanau et al\\.,? \\Q2014\\E",
      "shortCiteRegEx" : "Bahdanau et al\\.",
      "year" : 2014
    }, {
      "title" : "Finding minimum entropy codes",
      "author" : [ "Barlow", "Horace B", "Kaushal", "Tej P", "Mitchison", "Graeme J" ],
      "venue" : "Neural Computation,",
      "citeRegEx" : "Barlow et al\\.,? \\Q1989\\E",
      "shortCiteRegEx" : "Barlow et al\\.",
      "year" : 1989
    }, {
      "title" : "Learning iterative image reconstruction in the Neural Abstraction Pyramid",
      "author" : [ "Behnke", "Sven" ],
      "venue" : "International Journal of Computational Intelligence and Applications,",
      "citeRegEx" : "Behnke and Sven.,? \\Q2001\\E",
      "shortCiteRegEx" : "Behnke and Sven.",
      "year" : 2001
    }, {
      "title" : "Scaling learning algorithms towards AI",
      "author" : [ "Bengio", "Yoshua", "LeCun", "Yann", "others" ],
      "venue" : "Large-scale kernel machines,",
      "citeRegEx" : "Bengio et al\\.,? \\Q2007\\E",
      "shortCiteRegEx" : "Bengio et al\\.",
      "year" : 2007
    }, {
      "title" : "Representation learning: A review and new perspectives",
      "author" : [ "Bengio", "Yoshua", "Courville", "Aaron", "Vincent", "Pierre" ],
      "venue" : "Pattern Analysis and Machine Intelligence, IEEE Transactions on,",
      "citeRegEx" : "Bengio et al\\.,? \\Q2013\\E",
      "shortCiteRegEx" : "Bengio et al\\.",
      "year" : 2013
    }, {
      "title" : "Generalized denoising auto-encoders as generative models",
      "author" : [ "Bengio", "Yoshua", "Yao", "Li", "Alain", "Guillaume", "Vincent", "Pascal" ],
      "venue" : "In Advances in Neural Information Processing Systems,",
      "citeRegEx" : "Bengio et al\\.,? \\Q2013\\E",
      "shortCiteRegEx" : "Bengio et al\\.",
      "year" : 2013
    }, {
      "title" : "Maximum likelihood from incomplete data via the EM algorithm. Journal of the royal statistical society",
      "author" : [ "Dempster", "Arthur P", "Laird", "Nan M", "Rubin", "Donald B" ],
      "venue" : "Series B (methodological),",
      "citeRegEx" : "Dempster et al\\.,? \\Q1977\\E",
      "shortCiteRegEx" : "Dempster et al\\.",
      "year" : 1977
    }, {
      "title" : "The feature-binding problem is an ill-posed problem",
      "author" : [ "Di Lollo", "Vincent" ],
      "venue" : "Trends in Cognitive Sciences,",
      "citeRegEx" : "Lollo and Vincent.,? \\Q2012\\E",
      "shortCiteRegEx" : "Lollo and Vincent.",
      "year" : 2012
    }, {
      "title" : "Forming sparse representations by local anti-Hebbian learning",
      "author" : [ "Földiak", "Peter" ],
      "venue" : "Biological cybernetics,",
      "citeRegEx" : "Földiak and Peter.,? \\Q1990\\E",
      "shortCiteRegEx" : "Földiak and Peter.",
      "year" : 1990
    }, {
      "title" : "Neural network model for a mechanism of pattern recognition unaffected by shift in position - Neocognitron",
      "author" : [ "K. Fukushima" ],
      "venue" : "Trans. IECE,",
      "citeRegEx" : "Fukushima,? \\Q1979\\E",
      "shortCiteRegEx" : "Fukushima",
      "year" : 1979
    }, {
      "title" : "Becoming a “Greeble” expert: Exploring mechanisms for face recognition",
      "author" : [ "Gauthier", "Isabel", "Tarr", "Michael J" ],
      "venue" : "Vision Research,",
      "citeRegEx" : "Gauthier et al\\.,? \\Q1997\\E",
      "shortCiteRegEx" : "Gauthier et al\\.",
      "year" : 1997
    }, {
      "title" : "The temporal correlation hypothesis of visual feature integration",
      "author" : [ "Gray", "Charles M" ],
      "venue" : "Still alive and well. Neuron,",
      "citeRegEx" : "Gray and M.,? \\Q1999\\E",
      "shortCiteRegEx" : "Gray and M.",
      "year" : 1999
    }, {
      "title" : "Handwritten digit recognition with a back-propagation network. In Advances in neural information processing systems",
      "author" : [ "Le Cun", "B. Boser", "Denker", "John S", "D. Henderson", "Howard", "Richard E", "W. Hubbard", "Jackel", "Lawrence D" ],
      "venue" : "URL http://citeseerx.ist.psu. edu/viewdoc/summary?doi=10.1.1.32.5076",
      "citeRegEx" : "Cun et al\\.,? \\Q1990\\E",
      "shortCiteRegEx" : "Cun et al\\.",
      "year" : 1990
    }, {
      "title" : "A model for visual shape recognition",
      "author" : [ "Milner", "Peter M" ],
      "venue" : "Psychological review,",
      "citeRegEx" : "Milner and M.,? \\Q1974\\E",
      "shortCiteRegEx" : "Milner and M.",
      "year" : 1974
    }, {
      "title" : "Recurrent models of visual attention",
      "author" : [ "Mnih", "Volodymyr", "Heess", "Nicolas", "Graves", "Alex" ],
      "venue" : "In Advances in Neural Information Processing Systems, pp. 2204–2212,",
      "citeRegEx" : "Mnih et al\\.,? \\Q2014\\E",
      "shortCiteRegEx" : "Mnih et al\\.",
      "year" : 2014
    }, {
      "title" : "Generalizable relational binding from coarse-coded distributed representations",
      "author" : [ "O’reilly", "Randall C", "Busby", "Richard S" ],
      "venue" : "Advances in neural information processing systems,",
      "citeRegEx" : "O.reilly et al\\.,? \\Q2002\\E",
      "shortCiteRegEx" : "O.reilly et al\\.",
      "year" : 2002
    }, {
      "title" : "Three forms of binding and their neural substrates: Alternatives to temporal synchrony. The unity of consciousness: Binding, integration, and dissociation",
      "author" : [ "O’Reilly", "Randall C", "Busby", "Richard S", "Soto", "Rodolfo" ],
      "venue" : "pp. 168–192,",
      "citeRegEx" : "O.Reilly et al\\.,? \\Q2003\\E",
      "shortCiteRegEx" : "O.Reilly et al\\.",
      "year" : 2003
    }, {
      "title" : "Unsupervised segmentation with dynamical units",
      "author" : [ "Rao", "Ravishankar A", "Cecchi", "Guillermo", "Peck", "Charles C", "Kozloski", "James R" ],
      "venue" : "Neural Networks, IEEE Transactions on,",
      "citeRegEx" : "Rao et al\\.,? \\Q2008\\E",
      "shortCiteRegEx" : "Rao et al\\.",
      "year" : 2008
    }, {
      "title" : "Neuronal synchrony in Complex-Valued deep networks. arXiv:1312.6115 [cs, q-bio, stat",
      "author" : [ "Reichert", "David P", "Serre", "Thomas" ],
      "venue" : "URL http://arxiv.org/abs/1312",
      "citeRegEx" : "Reichert et al\\.,? \\Q2013\\E",
      "shortCiteRegEx" : "Reichert et al\\.",
      "year" : 2013
    }, {
      "title" : "Hierarchical models of object recognition in cortex",
      "author" : [ "Riesenhuber", "Maximilian", "Poggio", "Tomaso" ],
      "venue" : "Nature neuroscience,",
      "citeRegEx" : "Riesenhuber et al\\.,? \\Q1999\\E",
      "shortCiteRegEx" : "Riesenhuber et al\\.",
      "year" : 1999
    }, {
      "title" : "The utility driven dynamic error propagation network",
      "author" : [ "A.J. Robinson", "F. Fallside" ],
      "venue" : "Technical Report CUED/F-INFENG/TR.1,",
      "citeRegEx" : "Robinson and Fallside,? \\Q1987\\E",
      "shortCiteRegEx" : "Robinson and Fallside",
      "year" : 1987
    }, {
      "title" : "Principles of neurodynamics. perceptrons and the theory of brain mechanisms",
      "author" : [ "Rosenblatt", "Frank" ],
      "venue" : "Technical report, DTIC Document,",
      "citeRegEx" : "Rosenblatt and Frank.,? \\Q1961\\E",
      "shortCiteRegEx" : "Rosenblatt and Frank.",
      "year" : 1961
    }, {
      "title" : "Learning to generate artificial fovea trajectories for target detection",
      "author" : [ "Schmidhuber", "Juergen", "Huber", "Rudolf" ],
      "venue" : "International Journal of Neural Systems,",
      "citeRegEx" : "Schmidhuber et al\\.,? \\Q1991\\E",
      "shortCiteRegEx" : "Schmidhuber et al\\.",
      "year" : 1991
    }, {
      "title" : "Learning factorial codes by predictability minimization",
      "author" : [ "Schmidhuber", "Jürgen" ],
      "venue" : "Neural Computation,",
      "citeRegEx" : "Schmidhuber and Jürgen.,? \\Q1992\\E",
      "shortCiteRegEx" : "Schmidhuber and Jürgen.",
      "year" : 1992
    }, {
      "title" : "Solutions to the binding problem: Progress through controversy and convergence",
      "author" : [ "Treisman", "Anne" ],
      "venue" : "ISSN 0896-6273. doi: 10.1016/S08966273(00)80826-0. URL http://www.sciencedirect.com/science/article/ pii/S0896627300808260",
      "citeRegEx" : "Treisman and Anne.,? \\Q1999\\E",
      "shortCiteRegEx" : "Treisman and Anne.",
      "year" : 1999
    }, {
      "title" : "Extracting and composing robust features with denoising autoencoders",
      "author" : [ "Vincent", "Pascal", "Larochelle", "Hugo", "Bengio", "Yoshua", "Manzagol", "Pierre-Antoine" ],
      "venue" : "In Proceedings of the 25th international conference on Machine learning,",
      "citeRegEx" : "Vincent et al\\.,? \\Q2008\\E",
      "shortCiteRegEx" : "Vincent et al\\.",
      "year" : 2008
    }, {
      "title" : "Information theoretic measures for clusterings comparison: Variants, properties, normalization and correction for chance",
      "author" : [ "Vinh", "Nguyen Xuan", "Epps", "Julien", "Bailey", "James" ],
      "venue" : "The Journal of Machine Learning Research,",
      "citeRegEx" : "Vinh et al\\.,? \\Q2010\\E",
      "shortCiteRegEx" : "Vinh et al\\.",
      "year" : 2010
    }, {
      "title" : "The correlation theory of brain function",
      "author" : [ "von der Malsburg", "Christoph" ],
      "venue" : null,
      "citeRegEx" : "Malsburg and Christoph.,? \\Q1981\\E",
      "shortCiteRegEx" : "Malsburg and Christoph.",
      "year" : 1981
    }, {
      "title" : "Binding in models of perception and brain function",
      "author" : [ "von der Malsburg", "Christoph" ],
      "venue" : "Current opinion in neurobiology,",
      "citeRegEx" : "Malsburg and Christoph.,? \\Q1995\\E",
      "shortCiteRegEx" : "Malsburg and Christoph.",
      "year" : 1995
    }, {
      "title" : "Learning lateral interactions for feature binding and sensory segmentation from prototypic basis interactions",
      "author" : [ "Weng", "Shijie", "Steil", "Jochen Jakob", "Ritter", "Helge" ],
      "venue" : "Neural Networks, IEEE Transactions on,",
      "citeRegEx" : "Weng et al\\.,? \\Q2006\\E",
      "shortCiteRegEx" : "Weng et al\\.",
      "year" : 2006
    }, {
      "title" : "Generalization of backpropagation with application to a recurrent gas market model",
      "author" : [ "P.J. Werbos" ],
      "venue" : "Neural Networks,",
      "citeRegEx" : "Werbos,? \\Q1988\\E",
      "shortCiteRegEx" : "Werbos",
      "year" : 1988
    } ],
    "referenceMentions" : [ {
      "referenceID" : 2,
      "context" : "Complementary to that, disentangling (Barlow et al., 1989; Schmidhuber, 1992; Bengio et al., 2007) requires the factors of variation in the data to be separated into different independent features.",
      "startOffset" : 37,
      "endOffset" : 98
    }, {
      "referenceID" : 4,
      "context" : "Complementary to that, disentangling (Barlow et al., 1989; Schmidhuber, 1992; Bengio et al., 2007) requires the factors of variation in the data to be separated into different independent features.",
      "startOffset" : 37,
      "endOffset" : 98
    }, {
      "referenceID" : 2,
      "context" : "Complementary to that, disentangling (Barlow et al., 1989; Schmidhuber, 1992; Bengio et al., 2007) requires the factors of variation in the data to be separated into different independent features. This concept is closely related to invariance and eases further processing because many properties, that we might be interested in, are invariant under a wide variety of transformations (Bengio et al., 2013a). Unfortunately distributed representations can interfere and lead to ambiguities when multiple objects are to be represented at the same time. The binding problem refers to these ambiguities that can arise from the superposition of multiple distributed representations. This problem has been debated quite extensively in the neuroscience and psychology communities perhaps starting with Milner (1974) and von der Malsburg (1981), but its existence can be traced back at least to a description by Rosenblatt (1961).",
      "startOffset" : 38,
      "endOffset" : 808
    }, {
      "referenceID" : 2,
      "context" : "Complementary to that, disentangling (Barlow et al., 1989; Schmidhuber, 1992; Bengio et al., 2007) requires the factors of variation in the data to be separated into different independent features. This concept is closely related to invariance and eases further processing because many properties, that we might be interested in, are invariant under a wide variety of transformations (Bengio et al., 2013a). Unfortunately distributed representations can interfere and lead to ambiguities when multiple objects are to be represented at the same time. The binding problem refers to these ambiguities that can arise from the superposition of multiple distributed representations. This problem has been debated quite extensively in the neuroscience and psychology communities perhaps starting with Milner (1974) and von der Malsburg (1981), but its existence can be traced back at least to a description by Rosenblatt (1961).",
      "startOffset" : 38,
      "endOffset" : 836
    }, {
      "referenceID" : 2,
      "context" : "Complementary to that, disentangling (Barlow et al., 1989; Schmidhuber, 1992; Bengio et al., 2007) requires the factors of variation in the data to be separated into different independent features. This concept is closely related to invariance and eases further processing because many properties, that we might be interested in, are invariant under a wide variety of transformations (Bengio et al., 2013a). Unfortunately distributed representations can interfere and lead to ambiguities when multiple objects are to be represented at the same time. The binding problem refers to these ambiguities that can arise from the superposition of multiple distributed representations. This problem has been debated quite extensively in the neuroscience and psychology communities perhaps starting with Milner (1974) and von der Malsburg (1981), but its existence can be traced back at least to a description by Rosenblatt (1961). It is classically demonstrated with a system required to identify an input as either square( ) or triangle(4) and to decide whether it is at the top(↑) or at the bottom(↓).",
      "startOffset" : 38,
      "endOffset" : 921
    }, {
      "referenceID" : 10,
      "context" : "Convolutional Networks (Fukushima, 1979; Le Cun et al., 1990) use feature detectors with limited receptive fields (filters) replicated over the whole input to represent its inputs.",
      "startOffset" : 23,
      "endOffset" : 61
    }, {
      "referenceID" : 26,
      "context" : "This is achieved through a clustering process which utilizes a denoising autoencoder (DAE; Behnke, 2001; Vincent et al., 2008) to iteratively reconstruct an input.",
      "startOffset" : 85,
      "endOffset" : 126
    }, {
      "referenceID" : 26,
      "context" : "The DAE is trained to remove corruption from images of single objects and thus learns a local model of the data generating distribution (Vincent et al., 2008; Bengio et al., 2013b).",
      "startOffset" : 136,
      "endOffset" : 180
    }, {
      "referenceID" : 7,
      "context" : "Thus, convergence can’t be proven and RC is not an Expectation Maximization algorithm (Dempster et al., 1977).",
      "startOffset" : 86,
      "endOffset" : 109
    }, {
      "referenceID" : 18,
      "context" : "Taken from Rao et al. (2008). This is a simple dataset with no translations, but significant overlap between patterns.",
      "startOffset" : 11,
      "endOffset" : 29
    }, {
      "referenceID" : 18,
      "context" : "Taken from Rao et al. (2008). This is a simple dataset with no translations, but significant overlap between patterns. Shapes Taken from Reichert & Serre (2013). Three shapes ( ,4,5) are randomly placed in an image (possibly with overlap).",
      "startOffset" : 11,
      "endOffset" : 161
    }, {
      "referenceID" : 18,
      "context" : "Taken from Rao et al. (2008). This is a simple dataset with no translations, but significant overlap between patterns. Shapes Taken from Reichert & Serre (2013). Three shapes ( ,4,5) are randomly placed in an image (possibly with overlap). This dataset tests binding of shapes under translation invariance and varying overlap. Bars Introduced by Földiak (1990) to demonstrate unsupervised learning of independent components of an image.",
      "startOffset" : 11,
      "endOffset" : 361
    }, {
      "referenceID" : 18,
      "context" : "Taken from Rao et al. (2008). This is a simple dataset with no translations, but significant overlap between patterns. Shapes Taken from Reichert & Serre (2013). Three shapes ( ,4,5) are randomly placed in an image (possibly with overlap). This dataset tests binding of shapes under translation invariance and varying overlap. Bars Introduced by Földiak (1990) to demonstrate unsupervised learning of independent components of an image. We use the variant from Reichert & Serre (2013) which employs 6 horizontal, and 6 vertical lines placed in random positions in the image.",
      "startOffset" : 11,
      "endOffset" : 485
    }, {
      "referenceID" : 18,
      "context" : "Taken from Rao et al. (2008). This is a simple dataset with no translations, but significant overlap between patterns. Shapes Taken from Reichert & Serre (2013). Three shapes ( ,4,5) are randomly placed in an image (possibly with overlap). This dataset tests binding of shapes under translation invariance and varying overlap. Bars Introduced by Földiak (1990) to demonstrate unsupervised learning of independent components of an image. We use the variant from Reichert & Serre (2013) which employs 6 horizontal, and 6 vertical lines placed in random positions in the image. Corners This dataset consists of 8 corner shapes placed in random orientations and positions, such that 4 of them align to form a square. It was introduced by Reichert & Serre (2013) to demonstrate that spatial connected-ness is not a requirement for binding.",
      "startOffset" : 11,
      "endOffset" : 758
    }, {
      "referenceID" : 18,
      "context" : "Taken from Rao et al. (2008). This is a simple dataset with no translations, but significant overlap between patterns. Shapes Taken from Reichert & Serre (2013). Three shapes ( ,4,5) are randomly placed in an image (possibly with overlap). This dataset tests binding of shapes under translation invariance and varying overlap. Bars Introduced by Földiak (1990) to demonstrate unsupervised learning of independent components of an image. We use the variant from Reichert & Serre (2013) which employs 6 horizontal, and 6 vertical lines placed in random positions in the image. Corners This dataset consists of 8 corner shapes placed in random orientations and positions, such that 4 of them align to form a square. It was introduced by Reichert & Serre (2013) to demonstrate that spatial connected-ness is not a requirement for binding. MNIST+Shape Another dataset from Reichert & Serre (2013), which combines a random shape from the shapes dataset with a single MNIST digit.",
      "startOffset" : 11,
      "endOffset" : 892
    }, {
      "referenceID" : 27,
      "context" : "We evaluated performance by measuring the Adjusted Mutual Information (AMI; Vinh et al., 2010) between the true segmentation and the result of the binding, to which we refer to as the score.",
      "startOffset" : 70,
      "endOffset" : 94
    }, {
      "referenceID" : 18,
      "context" : "Recently, these ideas were implemented using complex valued activations in neural networks to jointly encode firing rate and phase (Rao et al., 2008; Reichert & Serre, 2013).",
      "startOffset" : 131,
      "endOffset" : 173
    }, {
      "referenceID" : 31,
      "context" : "In principle, Recurrent Neural Networks (RNNs; e.g. Robinson & Fallside, 1987; Werbos, 1988) can solve the binding problem by learning a mechanism to avoid it.",
      "startOffset" : 40,
      "endOffset" : 92
    }, {
      "referenceID" : 30,
      "context" : "Psychologists (Di Lollo, 2012) and machine learning researchers (Weng et al., 2006) alike have suggested feedback as a mechanism to do binding.",
      "startOffset" : 64,
      "endOffset" : 83
    }, {
      "referenceID" : 15,
      "context" : "An RNN may utilize an implicit or explicit attention mechanism to selectively process different parts of the input (Schmidhuber & Huber, 1991; Mnih et al., 2014; Bahdanau et al., 2014).",
      "startOffset" : 115,
      "endOffset" : 184
    }, {
      "referenceID" : 1,
      "context" : "An RNN may utilize an implicit or explicit attention mechanism to selectively process different parts of the input (Schmidhuber & Huber, 1991; Mnih et al., 2014; Bahdanau et al., 2014).",
      "startOffset" : 115,
      "endOffset" : 184
    }, {
      "referenceID" : 14,
      "context" : "O’Reilly et al., 2003). O’reilly & Busby (2002) argued that the intuitive explanation of the binding problem from Figure 1b only applies if the distributed features themselves are local codes.",
      "startOffset" : 0,
      "endOffset" : 48
    }, {
      "referenceID" : 14,
      "context" : "O’Reilly et al., 2003). O’reilly & Busby (2002) argued that the intuitive explanation of the binding problem from Figure 1b only applies if the distributed features themselves are local codes. They suggested that neural networks can avoid the binding problem using coarse-coded representations. Various feature representation types including coarse-coding and their limitations were described by Hinton (1984). In principle, Recurrent Neural Networks (RNNs; e.",
      "startOffset" : 0,
      "endOffset" : 410
    }, {
      "referenceID" : 0,
      "context" : "Achanta et al. (2012) for an overview).",
      "startOffset" : 0,
      "endOffset" : 22
    } ],
    "year" : 2016,
    "abstractText" : "Disentangled distributed representations of data are desirable for machine learning, since they are more expressive and can generalize from fewer examples. However, for complex data, the distributed representations of multiple objects present in the same input can interfere and lead to ambiguities, which is commonly referred to as the binding problem. We argue for the importance of the binding problem to the field of representation learning, and develop a probabilistic framework that explicitly models inputs as a composition of multiple objects. We propose an algorithm that uses a denoising autoencoder to dynamically bind features together in multi-object inputs through an Expectation-Maximization-like clustering process. The effectiveness of this method is demonstrated on artificially generated datasets of binary images, showing that it can even generalize to bind together new objects never seen by the autoencoder during training.",
    "creator" : "LaTeX with hyperref package"
  }
}