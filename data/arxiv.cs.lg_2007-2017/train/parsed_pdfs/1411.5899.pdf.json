{
  "name" : "1411.5899.pdf",
  "metadata" : {
    "source" : "META",
    "title" : "Falling Rule Lists",
    "authors" : [ "Fulton Wang", "Cynthia Rudin" ],
    "emails" : [ ],
    "sections" : [ {
      "heading" : "1. Introduction",
      "text" : "In healthcare, patients and actions need to be prioritized based on risk. The most at-risk patients should be handled with the highest priority, patients in the second at-risk set should receive the second highest priority, and so on. This decision process is perfectly natural for a human decision-maker – for instance a physician – who might check the patient for symptoms of high severity diseases first, then check for symptoms of less serious diseases, etc.; however, the traditional paradigm of predictive modeling does not naturally contain this type of logic. If such clear logic were well-founded, a typical machine learning model would not usually be able to discover it: most machine learning methods produce highly complex models, and were not designed to provide an ability to reason about each prediction. This leaves a gap, where predictive models are not directly aligned with the decisions that need to be made from them.\nThe algorithm introduced in this work aims to resolve this problem, and could be directly useful for clinical practice. A falling rule list is an ordered list of if-then rules, where (i) the order of rules determines which example should be classified by each rule (falling rule lists are a type of decision list), and (ii) the estimated probability of success decreases monotonically down the list. Thus, a falling rule list directly contains the decision-making process, whereby the most at-risk observations are classified first, then the second set, and so on. A falling rule list might say, for instance, that patients with a history of heart disease are in the highest risk set with a 7% stroke risk, patients with high blood pressure (who are not in the highest risk set) are in the second highest risk set with a 4% stroke risk, and patients with neither conditions of these are in the lowest risk set with a 1% stroke risk.\nTable 1 shows an example of one of the decision lists we constructed for the mammographic mass dataset (Bache & Lichman, 2013) as part of our experimental study. It took 35 seconds to construct this model on a laptop. The model states that if biopsy results show that the tumor has irregular shape, and the patient is over age 60, then the tumor is at the highest risk of being malignant (the risk is 85%). The next risk set is for the remaining tumors that have spiculated margins and are from patients above 45 years of age (the risk is 78%), and so on. The right column of Table 1 shows how many patients fit into each of the rules (so that its sum is the size of the dataset), and the risk probabilities were directly calibrated to the data.\nFalling rule lists serve a dual purpose: they rank rules to form a predictive model, and stratify patients into decreasing risk sets. This saves work for a physician; sorting is an expensive mental operation, and this model does the sorting naturally. If one were to use a standard decision tree or\n1\nar X\niv :1\n41 1.\n58 99\nv1 [\ncs .A\nI] 2\n1 N\nov 2\n01 4\ndecision list method instead, identifying the highest at-risk patients could be a much more involved calculation, and the number of conditions the most at-risk patients need to satisfy might be difficult for physicians to memorize.\nMost of the models currently in use for medical decision making were designed by teams of medical experts rather than by data-driven or algorithmic approaches. These manually-created risk assessment tools are used in possibly every hospital; e.g., the TIMI scores, CHADS2 score, Apache scores, and the Ranson score, to name a few (Antman et al. , 2000; Morrow et al. , 2000; Gage et al. , 2001; Knaus et al. , 1981, 1985, 1991; Ranson et al. , 1974). These models can be computed without the use of a calculator, which makes them very practical as decision aids. Of course, we aim for this level of interpretability in purely data-driven classifiers, with no manual feature selection or rounding coefficients.\nIn the industrial world, algorithms that discretize the input space have gained in popularity purely because they yield interpretable models. The CART algorithm of Breiman et al. (1984) seems to be the algorithm of choice, despite its drawbacks of being greedy and not as accurate as other methods. The vast majority of other methods that discretize the input space are also greedy, such as decision tree (Quinlan, 1986, 1993) and decision list methods (Rivest, 1987; Fawcett, 2008). Since it is possible that decision tree methods can produce results that are inconsistent with monotonicity properties of the data, there is a subfield dedicated to altering these greedy decision tree algorithms to obey monotonicity properties (Ben-David, 1995; Feelders & Pardoel, 2003; Altendorf et al. , 2012). Studies showed that in many cases, no accuracy is lost in enforcing monotonicity constraints, and that medical experts were more willing to use the models with the monotonicity constraints (Pazzani et al. , 2001).\nEven with (what seem like) rather severe constraints on the hypothesis space such as monotonicity or sparsity in the number of leaves and nodes, it still seems that the set of accurate classifiers is often large enough so that it contains interpretable classifiers (see Holte, 1993). Because the monotonicity properties we enforce are much stronger than those of Ben-David (1995); Feelders & Pardoel (2003); Altendorf et al. (2012) (we are looking at monotonicity along the whole list rather than for individual features), we do find that accuracy is sometimes sacrificed, but not always, and generally not by much. On the other hand, it is possible that our method gains a level of practicality and interpretability that other methods simply cannot.\nInterpretability is very context dependent (see Kodratoff, 1994; Pazzani, 2000; Freitas, 2014; Huysmans et al. , 2011; Allahyari & Lavesson, 2011; Martens & Baesens, 2010; Rüping, 2006; Verbeke et al. , 2011; Martens et al. , 2011), and no matter how one measures it in one domain, it can be different in the next domain. A falling rule list used in medical practice has the benefit that it can, in practice, be as sparse as desired. Since it automatically stratifies patients by risk in the order used for decision making, physicians can choose to look at as much of the list as they need to make a decision; the list is as sparse as one requires it to be. If physicians only care about the most high risk patients, then they look only at the top few rules, and check whether the patient obeys any of the top clauses.\nThe algorithm we provide for falling rule lists aims to have the best of all worlds: accuracy, interpretability, and computation. The algorithm starts with a statistical assumption, which is that we can build an accurate model from pre-mined itemsets. This helps tremendously with computation,\nand restricts us to building models with only interpretable building blocks (see also Letham et al. , 2012; Wang et al. , 2014). Once the itemsets are discovered, a Bayesian modeling approach chooses a subset and permutation of the rules to form the decision list. The user determines the desired size of the rule list through a Bayesian prior. Our generative model is constructed so that the monotonicity property is fully enforced (one cannot have “soft” monotonicity)."
    }, {
      "heading" : "2. Falling Rule Lists Model",
      "text" : "We consider binary classification, where the goal is to learn a distribution p(Y |x) where Y is binary. For example, Y might indicate the presence of a disease, and x would be a patient’s features. We will represent this condition distribution Y |x as a decision list, which is an ordered list of IF...THEN... rules. We will require a special structure to this decision list: that the probability of Y = 1 associated with each rule is decreasing as one moves down the decision list.\nWe will use a Bayesian approach to characterize a posterior distribution over falling rule lists from data D = {(xn, yn)}n=1,...,N , where N is the size of the training data, xn ∈ X, the patient feature space, and yn ∈ {0, 1}. We will represent a falling rule list with a set of parameters θ, specify the prior pθ(·;H) and the likelihood pY({yn}|θ; {xn}), and use simulated annealing and Monte Carlo sampling to approximate the MAP estimate and posterior, respectively, over falling rule lists, pθ(θ|{yn}; {xn}, H)."
    }, {
      "heading" : "2.1. Parameters of Model",
      "text" : "A falling rule list is parameterized by the following objects:\nL ∈ Z+ (size of list) (1) cl(·) ∈ BX(·), for l = 0, . . . , L− 1 (IF clauses) (2) rl ∈ R, for l = 0, . . . , L (risk scores) (3)\nsuch that\nrl+1 ≤ rl for l = 0, . . . , L− 1 (monotonic) (4)\nwhere BX(·) denotes the space of boolean functions on patient feature space X. BX(·) is the space of possible IF clauses; cl(x) will be 1 if x satisfies a given set of conditions. For this work, we will not assume L, the size of the decision list, to be known in advance. The value of rl will be fed into the logistic function to produce a risk probability between 0 and 1. Thus, c0(·) corresponds to the rule at the top of the list, determining the patients with the highest risk, and there are L+ 1 nodes and associated risk probabilities in the list: L associated with the cl(·)’s, plus one for patients who do not match any of the L rules."
    }, {
      "heading" : "2.2. Likelihood",
      "text" : "Given these parameters, the likelihood is as follows: Given L, let Z(x; {cl(·)}L−1l=0 ) : X → {0, . . . , L} be the mapping from feature x to the rule of the length L list it “belongs” to:\nZ(x; {cl(·)}L−1l=0 ) = { L if cl(x) = 0 for l = 0, . . . , L− 1 min(l : cl(x) = 1, l = 0, . . . , L− 1) otherwise.\n(5)\nThen, the likelihood is\nyn|L, {cl(·)}L−1l=0 , {rl} L l=0, ;xn ∼ Bernoulli(logistic(rl)), where (6)\nzn = Z(xn; {cl(·)}L−1l=0 ). (7)"
    }, {
      "heading" : "2.3. Prior",
      "text" : "Here, we describe the prior over the parameters L, {cl}L−1l=0 , {rl}Ll=0. We will provide a reparameterization that enforces monotonicity constraints, and finally give a generative model for the parameters.\nAs discussed earlier, to help with computation, we place positive prior probability of {cl}L−1l=0 only over lists consisting of boolean clauses B returned by a frequent itemset mining algorithm, where for c(·) ∈ B, we have c(·) : X → {0, 1}. For this particular work we used FPGrowth (Borgelt, 2005), whose input is a binary dataset where each x is a boolean vector, and whose output is a set of subsets of the features of the dataset. For example, x2 might indicate the presence of diabetes, and x15 might indicate the presence of hypertension, and a boolean function returned by FPGrowth might return 1 for patients who have diabetes and hypertension. We stress that it does not matter which rule mining algorithm is chosen because they all perform exhaustive searches to return the same set of clauses that have sufficient support. Also, note that the maximum length a decision list can have under our model is |B|, the number of clauses returned by the rule mining algorithm, and that |B| can be viewed as a hyperparameter."
    }, {
      "heading" : "2.3.1. Reparameterization",
      "text" : "To ensure the monotonicity constraints that rl ≥ rl−1 for l = 1 . . . L in the posterior, we choose the scores rl to, on a log scale, come from products of real numbers constrained to be greater than 1. That is, conditioned on L, we let\nrl = log(vl) for l = 0, . . . , L (8) vl = KΠ L−1 l̀=l γl̀ for l = 0, . . . , L− 1 (9)\nvL = K (10)\nand require that\nγl ≥ 1 for l = 0, . . . , L− 1 (11) K ≥ 0, (12)\nso that rL, the risk score associated with the default rule, equals logK. The prior we place over {γl}L−1l=0 and K will respect those constraints.\nThus, after reparameterizing, the parameters of our model are\nθ = {L, {cl(·)}L−1l=0 , {γl} L−1 l=0 ,K} (13)\n."
    }, {
      "heading" : "2.3.2. Prior Specifics",
      "text" : "The prior over parameters L, {cl(·)}L−1l=0 , {γl} L−1 l=0 ,K is generated through the following process:\n1. Let hyperparameters H = {B, λ, {αl}|B|−1l=0 , {βl} |B|−1 l=0 , αK , βK , {wl} |B|−1 l=0 } be given. 2. Initialize Θ← {}. 3. Draw L ∼ Poisson(λ). 4. For l = 0, . . . , L− 1\ndraw cl(·) ∼ pc(·)(·|Θ;B, {wl} |B|−1 l=0 ) where\npc(·) (c(·) = cj(·)|Θ;B, {wl} |B|−1 l=0 ) ∝ { wj if cj(·) ∈ B \\Θ 0 otherwise.\n(14)\nUpdate Θ← Θ ∪ {cl(·)}. 5. For l = 0, . . . , L− 1\ndraw γl ∼ Gamma1(αl, βl) where Gamma1 is a Gamma distribution truncated to have support only above 1.\n6. Draw K ∼ Gamma(αK , βK).\nWe now elaborate on our choice for each involved distribution. We let L ∼ Poisson(λ), where λ reflects the prior decision length desired by the user. We let cl(·) be the result of a draw from a discrete distribution over the yet unchosen rules, B \\ {cl̀(·)} l−1 l̀=0\n, where a rule is drawn with probability proportional to a user designed weight. For example, a rule might be chosen with probability proportional to the number of clauses in it. This allows the user to express preferences over different types of clauses in the list. Given L, only {c(·)l}L−1l=1 are observed, though note this process specifies a joint distribution over all of {c(·)l}|B|−1l=1 . Letting {γl} L−1 l=0 to be independently distributed truncated gamma variables permits posterior Gibbs sampling while enforcing the monotonicity constraints and still permitting diversity over prior distributions. For example, one could encourage some of the γ’s near the middle (of L) of the list to be large, in which case the risks would be widely spaced in the middle of the list (but this would force closer spacing at the top of the list where the risks concentrate near 1). Finally, K models the risk of patients who do not satisfy any rules, does not need to be truncated, and likewise comes from a Gamma distribution in the prior to facilitate posterior sampling."
    }, {
      "heading" : "3. Fitting the Model",
      "text" : "First we describe our approach to finding the decision list with the maximum a posteriori probability. Then we discuss our approach to perform Monte Carlo sampling from the posterior distribution over decision list parameters θ = {L, c0,...,L−1(·),K, γ0,...,L−1} as described in Equation 13,\npposterior(L, c0,...,L−1(·),K, γ0,...,L−1|y1,...,N ;x1,...,N ). (15)"
    }, {
      "heading" : "3.1. Obtaining the MAP decision list",
      "text" : "We adopted a simulated annealing approach to find θ∗ = {L∗, c0,...,L−1(·)∗,K∗, γ0,...,L−1}∗, where\nL∗, c∗0,...,L∗−1(·),K∗, γ∗0,...,L∗−1 ∈ argmaxL,C0,...,L−1(·),K,γ0,...,L−1 L (16)\nwhere L is shorthand for the unnormalized log of the posterior given in Equation (15). We note that the optimization problem in Equation (16) is equivalent to finding:\nL∗, c0,...,L−1(·)∗ ∈ argmaxL,{cl(·)}L−1l=0 L(L, {cl(·)} L−1 l=0 ,K ∗, γ∗0,...,L−1) (17)\nwhere\nK∗, γ∗0,...,L−1 ∈ argmaxK,γ0,...,L−1 L(L, {cl(·)} L−1 l=0 ,K, γ0,...,L−1).\nNote that K∗ and γ∗0,...,L−1 depend on L, {cl(·)} L−1 l=0 .\nFurthermore, the solution to the subproblem of findingK∗ and γ∗0,...,L−1 can be approximated fairly closely using a simple optimization procedure, as it involves maximizing the posterior probability of a decision list given the rules {cl(·)}L−1l=0 . Optimizing Equation (17) lends itself better to simulated annealing than Equation (16); optimizing (17) involves optimization over a discrete space, namely the set and order of rules cl(·). Under this formulation, at each simulated annealing iteration, we need to evaluate the objective function for the current rule list {cl(·)}L−1l=0 , which involves solving the continuous subproblem of finding the corresponding K∗ and γ∗0,...,L−1.\nGiven a objective function E(s) over discrete search space S, a function specifying the set of neighbors of a state N(s), and a temperature schedule function over time steps, T (t), a simulated annealing procedure is a discrete time, discrete state Markov Chain {st} where at time t, given the current state st, the next state st+1 is chosen by first randomly selecting a proposal s̀ from the set N(s), and setting st+1 = s̀ with probability min(1, exp( E(s̀)−E(s)\nT (t) )), and st+1 = st otherwise. The search space of the optimization problem of Equation (17) is { L, {cl(·)}L−1l=0 } , the set of ordered\nlists of rules drawing from the finite pre-mined set of rules B. Based on Equation (17), we let\nE({cl(·)}L−1l=0 ) = L(L, {cl(·)} L−1 l=0 ,K ∗, γ∗0,...,L−1). (18)\nWe simultaneously define the set of neighbors and the process by which to randomly choose a neighbor through the following random procedure that alters the current rule list {cl(·)}L−1l=0 to produce a new rule list {c̀l(·)}L̀−1l=0 . Note that the length of the new rule list can be different from the old one.\nChoose uniformly at random one of the following 4 operations to apply to the current rule list, {cl(·)}L−1l=0 :\n1. SWAP: Select i 6= j uniformly from 0, . . . , L−1, and swap the rules at those 2 positions, letting c̀i(·)← cj(·) and c̀j(·)← ci(·).\n2. REPLACE: Select i uniformly from 0, . . . , L− 1, draw c(·) from the the distribution pc(·)(·|Θ;B, {wl} |B|−1 l=0 ) defined in Equation (14), where Θ = {cl(·)}l=0,...,i−1,i+1,...,L−1 and set\nc̀i(·)← c(·).\n3. ADD: Choose one of the L+ 1 possible insertion points uniformly at random, draw a rule c(·) from pc(·)(·|Θ;B, {wl} |B|−1 l=0 ), where Θ = {cl(·)}l=0,...,L−1, and insert it at the chosen insertion\npoint, so that L̀← L+ 1.\n4. REMOVE: Choose i uniformly at random from 0, . . . , L− 1, and remove ci(·) from the current rule list, so that L̀← L− 1.\nNote that this approach optimizes over the full set of rule lists from itemsets, and does not rely on greedy splitting. (Even Bayesian tree methods that aim to traverse a wider search space use greedy splitting and mostly produce local solutions, e.g., Chipman et al. , 1998, .)"
    }, {
      "heading" : "3.2. Obtaining the posterior over decision lists",
      "text" : "To perform posterior sampling, we use Gibbs sampling steps over {γl}L−1l=0 and K made possible by variable augmentation, and Metropolis-Hastings steps over L and {cl(·)}. We describe the variable augmentation step, the schedule of updates we employ, and finally the details of each individual update step.\nAugmenting the model with two additional variables Un, ζn for each n = 1, . . . , N preserves the marginal distribution over the original variables, and enables Gibbs sampling over K and each γl\n(see Dunson, 2004):\nUn ∼ Poisson(ζnvzn) for n = 1, . . . , N (19) ζn ∼ Exponential(1) for n = 1, . . . , N (20) Yn = 1(Un > 0) for n = 1, . . . , N. (21)\nMarginalizing over ζn and Un, we see that in this augmented model, it remains true that yn ∼ Bernoulli(logistic(rzn)):\np(Yn = 1) = p(Un > 0) (22) = 1− ∫ ∞\n0\np(Un = 0|ζn)p(ζn)dζn (23)\n= 1− ∫ ∞\n0\nexp(−ζnvzn) exp(−ζn)dζn (24)\n= 1− (1 + vzn)−1 (25) = vzn\n1 + vzn (26)\n= exp(rzn)\n1 + exp(rzn) (27)\nso that yn ∼ Bernoulli(logistic(rzn)) as desired."
    }, {
      "heading" : "3.2.1. Schedule of Updates",
      "text" : "Given the augmented model, we cycle through the following steps in the following deterministic order. These will each be discussed in detail shortly. Regarding notation, we will use use θaug to refer to the parameters of the augmented model: (L, {cl(·)}L−1l=0 ,K, {γl} L−1 l=0 , {Un}Nn=1, {ζn}Nn=1), so that Gibbs updates can be described more succinctly.\nStep 1: Sample γ̀l ∼ pγl(·|(θaug \\ γl), {yn}Nn=1; {xn}Nn=1) for l = 0, . . . , L − 1 (Gibbs steps for each γl).\nStep 2: Sample K̀ ∼ pK(·|(θaug \\K), {yn}Nn=1; {xn}Nn=1) (Gibbs step for K). Step 3: Perform Metropolis-Hastings update over (L, {cl(·)}L−1l=0 ), under the original model from Equation (15). This can be viewed as a collapsed Metropolis-Hastings step, where the collapsed parameters are the augmenting variables {Un}Nn=1, {ζn}Nz=1.\nStep 4: Jointly sample\n({ζ̀n}Nn=1, {Ùn}Nn=1) ∼ p{ζn}Nn=1,{Un}Nn=1(·|θaug \\ ({ζn} N n=1, {Un}Nn=1), {yn}Nn=1; {xn}Nn=1)\n(Gibbs step for ({ζn}Nn=1, {Un}Nn=1)).\nMixing Gibbs and collapsed Metropolis-Hastings sampling steps requires special care to ensure the Markov chain is proper in that it possesses the desired stationary distribution. We refer to van Dyk & Park (2011) for details, but do note that after the collapsed Metropolis-Hastings step, first performing a Gibbs update of {ζn}Nn=1, and then a separate Gibbs update for {Un}Nn=1 (or in the reverse order) would not have been proper."
    }, {
      "heading" : "3.2.2. Update Details",
      "text" : "We now describe each step of the update schedule in more detail:\nStep 1 In this augmented model, the full conditional distribution of each γl is Gamma distributed, so that it can be sampled from directly. Let, for l = 0, . . . , L− 1\nσ (l) k = { KΠki=L−1,i6=lγi for 0 ≤ k ≤ l 0 for l < k ≤ L.\n(28)\nThen, it can be derived that\nγl|(θaug \\ γl), {yn}Nn=1; {xn}Nn=1 ∼ Gamma ( αl + N∑ n=1 1[zn ≤ l]Un, βl + N∑ n=1 ζnσ (l) zn ) , (29)\nwhere αl, βl govern the prior of γl and zn as described in Equation (7) denotes the rule that a data belongs to.\nStep 2 Similarily, let\nok = { Πki=L−1γi for 0 ≤ k ≤ L− 1 1 for k = L.\n(30)\nThen\nK|(θaug \\K), {yn}Nn=1; {xn}Nn=1 ∼ Gamma ( αK + N∑ n=1 Un, βK + N∑ n=1 ζnozn ) . (31)\nStep 3 The reason for using a collapsed rather than regular Metropolis-Hastings step was to improve chain mixing. The Metropolis-Hastings proposal distributions over (L,{cl(·)}L−1l=0 ) are exactly as in the proposal distribution used to generate a successor state in the simulated annealing we used to find the MAP decision list. The only difference is that if the ADD operation is chosen, then sample γ̀L̀−1 ∼ Gamma(αL̀−1, βL̀−1). The Metropolis-Hastings step does not involve γL̀−1; the sampling step is simply to instantiate a previously unobserved parameter from the prior. Thus, we simply provide the Q probabilities. For simplicity, we do so for the case when the weights {wl}|B|−1l=0 associated with each c(·) ∈ B are equal.\nQ({c̀(·)}L̀−1l=1 |{cl(·)} L−1 l=1 ) =  1 (L+1)(|B|−L) if ADD 1 |B|−L if REPLACE 1 L if REMOVE\n1 L(L−1) if SWAP .\nStep 4 In the full conditional distribution of ({ζn}Nn=1, {Un}Nn=1), the set of pairs of variables, {(Un, ζn)}Nn=1 is mutually independent, due to conditioning. Therefore to sample from it, it is sufficient to independently sample (Un, ζn) for n = 1, . . . , N . It can be shown that the following sampling scheme samples from the full conditional distribution:\nFor n = 1, . . . , N : if yn = 0:\nset Ùn = 0, sample ζ̀n ∼ exponential(1 + vzn), otherwise:\nsample Ùn ∼ 1 + Geometric( 11+vzn ) then sample ζ̀n ∼ Gamma(1 + Ùn, 1 + vzn)"
    }, {
      "heading" : "4. Simulation Studies",
      "text" : "We show that for simulated data generated by a known decision list, our simulated annealing procedure that searches for the MAP decision list, with high probability, recovers the true decision list.\nGiven observations with arbitrary features, and a collection of rules on those features, we can construct a binary matrix where the rows represent observations and the columns represent rules, and the entry is 1 if the rule applies to that observation and 0 otherwise. We need only simulate this binary matrix to represent the observations without losing generality. For our simulations, we generated independent binary rule sets with 100 rules by setting each feature value to 1 independently with probability 0.25.\nWe generated a random decision list of size 5 by selecting 5 rules at random, adding the default rule, and setting the γ0, . . . , γ5 so that the induced p0, . . . , p5 were roughly evenly spaced on the unit interval: (0.84, 0.70, 0.54, 0.40, 0.25, 0.14). For each N , we performed the following procedure 100 times: generate the random rule matrix, random decision list, and assign it the aforementioned {γl}, obtain an independent dataset of size N by generating labels from this decision list, and then perform simulated annealing using the procedure described in Section 3.1 to obtain a point estimate of the decision list. We then calculate the edit distance of the decision list returned by simulated annealing to the true decision list. Figure 1 shows the average distance over those 100 replicates, for each N . Note that the maximum possible edit distance is 5.\nWe ran simulated annealing for 5000 steps in each replicate. Further, we found that a cooling schedule with a slow temperature decrease balanced exploration and exploitation sufficiently to recover the true list."
    }, {
      "heading" : "5. Experiments",
      "text" : "Our main experimental result is an application of Falling Rule Lists to predict 30 day hospital readmission from an ongoing collaboration with medical practitioners (see Cronin et al. , 2014, which describes the collection of data).\nSince we placed an extremely strong restriction on the characteristics of the predictive model (namely the monotonicity property, sparsity of rules, and sparsity of conditions per rule), we expect to lose predictive accuracy over unrestricted methods. The interpretability benefit may or not be sufficient to compensate for this, but this is heavily application-dependent. We have found several cases where there is no loss in performance (with a substantial gain in interpretability) by using a\nfalling rule list instead of, for instance, a support vector machine, consistent with the hypothesis and observations of Holte (1993) about very simple classifiers performing well.\nLater in this section, we aim to quantify the loss in predictive power from Falling Rule Lists over other methods by using an out-of-sample predictive performance evaluation. Specifically, we compare to several baseline methods on standard publicly available datasets to quantify the possible loss in predictive performance."
    }, {
      "heading" : "5.1. Predicting Hospital Readmissions",
      "text" : "We applied Falling Rule Lists to preliminary readmissions data being compiled through a collaboration with a major hospital in the U.S. (Cronin et al. , 2014), where the goal is to predict whether a patient will be readmitted to the hospital with 30 days, using data prior to their release. The dataset contains features and binary readmissions outcomes for approximately 8,000 patients who had no prior history of readmissions. The features are very detailed, and include aspects like “impaired mental status,” “difficult behavior,” “chronic pain,” “feels unsafe” and over 30 other detailed features that might be predictive of readmission. As we will see, luckily a physician may not be required to collect this amount of detailed information to assess whether a particular patient is at a high risk for readmission.\nFor these experiments and the experiments in the next section, no parameters were tuned in Falling Rule Lists (FRL), and the global hyperparameters were chosen as follows. We mined rules with a support of at least 5% and a cardinality of at most 2 conditions per rule. We assumed in the prior that conditioned on L, each rule had an equal chance of being in the rule list. We set the prior of {γl}|L to have noninformative and independent distributions of gamma(1, 0.1), and the prior expected length of the decision list, λ, to be 8. We performed simulated annealing search for 5000 steps with a constant temperature of 1 for simplicity.\nWe measured out-of-sample performance using AUROC (the area under the received operator characteristic curve) from 5-fold cross validation where the MAP decision list from training was used to predict on each test fold in turn. We compared with SVM (with Radial Basis Function kernels), `2 regularized logistic regression (Ridge regression, denoted LogReg), CART, and random forests(denoted RF). We used the Python scikit-learn package for the implementations. For SVM RBF and logistic regression, hyperparameters were tuned using grid search in nested cross validation.\nThe AUROC’s for the different methods are in Table 2, indicating that there was no loss in accuracy for using Falling Rule Lists on this particular dataset. For four of the training folds, decision lists were of length 6 and for remaining fold, the decision list was of length 7 - all very sparse.\nFigure 2 shows ROC curves for all test folds for all methods. For this particular dataset, SVM RBF and CART did not perform well. It is unclear why SVM did not perform well, as cross-validation was performed for SVM; the no free lunch theorems clearly state the possibility of any given algorithm to perform poorly on any specific dataset. (On the other hand, CART often does not perform as well as other methods in our experience.) In any case, FRL performed on par with the best method, despite its being limited to a very small number of features with the monotonic structure.\nTable 3 shows a point estimate obtained from training Falling Rule Lists on the full dataset, which took 88 seconds to train. In the “probability” column we provide the empirical probability of\nreadmission for each rule, and the “support” column is the number of patients being classified by that rule. The model indicate that patients with bed sores and who have skipped appointments are the most likely to be readmitted. The other conditions used in the model include “PoorPrognosis” meaning the patient is in need of hospice or palliative care services, “PoorCondition” meaning the patient exhibits frailty, signs of neglect or malnutrition, “NegativeIdeation” which means suicidal or violent thoughts, and “MaxCare” which means the patient needs maximum care (is non-ambulatory, confined to bed). This model lends itself naturally to decision-making, as one need only traverse the top of the list to obtain a characterization of high risk patients."
    }, {
      "heading" : "5.2. Performance on Public Datasets",
      "text" : "We performed an empirical comparison on several UCI datasets (Bache & Lichman, 2013), using the experimental setup discussed above. This allows us to quantify the loss in accuracy due to the restricted form of the model.\nTable 4 displays the results. As discussed earlier, we observed that even with the severe restrictions on the model, performance levels are still on par with those of other methods, and not often substantially worse. This is likely due to the benefits of not using a greedy splitting method, restricting to the space of mined rules, careful formulation, and optimization.\nTo construct full rule list on the mammographic mass dataset (n=961, p=13) took 35 seconds, for the spam dataset (n=4601, p=57) it took 102 seconds, for the breast cancer (n=683, p=27) dataset it took 35 seconds, and for the cars dataset (n=1728, p=21) it took 39 seconds. This method can be parallelized naturally by running multiple chains in parallel on separate processors.\nFigure 1 from the introduction provides a rule list trained on the full mammographic mass dataset."
    }, {
      "heading" : "6. Conclusion",
      "text" : "We are designing a new class of interpretable predictive models that could potentially have a major benefit in decision-making for some domains. As nicely stated by the director of the U.S. National Institute of Justice (Ridgeway, 2013), an interpretable model that is actually used is better than one that is more accurate that sits on a shelf. We envision that models produced by FRL can be used, for instance, by physicians in third world countries who require models printed on laminated cards. In high stakes decisions (like medical decisions), it is important that we know whether to trust the model we are using to make decisions; models like FRL help tell us when (and when not) to trust."
    } ],
    "references" : [ {
      "title" : "User-oriented Assessment of Classification Model Understandability. Pages 11–19 of: SCAI",
      "author" : [ "Allahyari", "Hiva", "Lavesson", "Niklas" ],
      "venue" : null,
      "citeRegEx" : "Allahyari et al\\.,? \\Q2011\\E",
      "shortCiteRegEx" : "Allahyari et al\\.",
      "year" : 2011
    }, {
      "title" : "Learning from sparse data by exploiting monotonicity constraints. arXiv preprint arXiv:1207.1364",
      "author" : [ "Altendorf", "Eric E", "Restificar", "Angelo C", "Dietterich", "Thomas G" ],
      "venue" : null,
      "citeRegEx" : "Altendorf et al\\.,? \\Q2012\\E",
      "shortCiteRegEx" : "Altendorf et al\\.",
      "year" : 2012
    }, {
      "title" : "The TIMI risk score for unstable angina/non–ST elevation MI",
      "author" : [ "Antman", "Elliott M", "Cohen", "Marc", "Bernink", "Peter JLM", "McCabe", "Carolyn H", "Horacek", "Thomas", "Papuchis", "Gary", "Mautner", "Branco", "Corbalan", "Ramon", "Radley", "David", "Braunwald", "Eugene" ],
      "venue" : "The Journal of the American Medical Association,",
      "citeRegEx" : "Antman et al\\.,? \\Q2000\\E",
      "shortCiteRegEx" : "Antman et al\\.",
      "year" : 2000
    }, {
      "title" : "Monotonicity maintenance in information-theoretic machine learning algorithms",
      "author" : [ "Ben-David", "Arie." ],
      "venue" : "Machine Learning, 19(1), 29–43.",
      "citeRegEx" : "Ben.David and Arie.,? 1995",
      "shortCiteRegEx" : "Ben.David and Arie.",
      "year" : 1995
    }, {
      "title" : "An Implementation of the FP-growth Algorithm",
      "author" : [ "Borgelt", "Christian." ],
      "venue" : "Pages 1–5 of: Proceedings of the 1st international workshop on open source data mining: frequent pattern mining implementations. ACM.",
      "citeRegEx" : "Borgelt and Christian.,? 2005",
      "shortCiteRegEx" : "Borgelt and Christian.",
      "year" : 2005
    }, {
      "title" : "Classification and Regression Trees",
      "author" : [ "Breiman", "Leo", "Friedman", "Jerome H", "Olshen", "Richard A", "Stone", "Charles J" ],
      "venue" : null,
      "citeRegEx" : "Breiman et al\\.,? \\Q1984\\E",
      "shortCiteRegEx" : "Breiman et al\\.",
      "year" : 1984
    }, {
      "title" : "Bayesian CART model search",
      "author" : [ "Chipman", "Hugh A", "George", "Edward I", "McCulloch", "Robert E" ],
      "venue" : "Journal of the American Statistical Association,",
      "citeRegEx" : "Chipman et al\\.,? \\Q1998\\E",
      "shortCiteRegEx" : "Chipman et al\\.",
      "year" : 1998
    }, {
      "title" : "Predicting Hospital Readmissions Using Supersparse Interpretable Models. Work In Progress",
      "author" : [ "Cronin", "Patrick", "Ustun", "Berk", "Rudin", "Cynthia", "Greenwald", "Jeffrey" ],
      "venue" : null,
      "citeRegEx" : "Cronin et al\\.,? \\Q2014\\E",
      "shortCiteRegEx" : "Cronin et al\\.",
      "year" : 2014
    }, {
      "title" : "Bayesian isotonic regression for discrete outcomes",
      "author" : [ "Dunson", "David B." ],
      "venue" : "Tech. rept. Citeseer.",
      "citeRegEx" : "Dunson and B.,? 2004",
      "shortCiteRegEx" : "Dunson and B.",
      "year" : 2004
    }, {
      "title" : "PRIE: a system for generating rulelists to maximize ROC performance",
      "author" : [ "Fawcett", "Tom." ],
      "venue" : "Data Mining and Knowledge Discovery, 17(2), 207–224.",
      "citeRegEx" : "Fawcett and Tom.,? 2008",
      "shortCiteRegEx" : "Fawcett and Tom.",
      "year" : 2008
    }, {
      "title" : "Pruning for monotone classification trees. Pages 1–12 of: Advances in intelligent data analysis",
      "author" : [ "Feelders", "Ad", "Pardoel", "Martijn" ],
      "venue" : null,
      "citeRegEx" : "Feelders et al\\.,? \\Q2003\\E",
      "shortCiteRegEx" : "Feelders et al\\.",
      "year" : 2003
    }, {
      "title" : "Comprehensible classification models: a position paper",
      "author" : [ "Freitas", "Alex A." ],
      "venue" : "ACM SIGKDD Explorations Newsletter, 15(1), 1–10.",
      "citeRegEx" : "Freitas and A.,? 2014",
      "shortCiteRegEx" : "Freitas and A.",
      "year" : 2014
    }, {
      "title" : "Validation of clinical classification schemes for predicting stroke",
      "author" : [ "Gage", "Brian F", "Waterman", "Amy D", "Shannon", "William", "Boechler", "Michael", "Rich", "Michael W", "Radford", "Martha J" ],
      "venue" : "The journal of the American Medical Association,",
      "citeRegEx" : "Gage et al\\.,? \\Q2001\\E",
      "shortCiteRegEx" : "Gage et al\\.",
      "year" : 2001
    }, {
      "title" : "Very simple classification rules perform well on most commonly used datasets",
      "author" : [ "Holte", "Robert C." ],
      "venue" : "Machine learning, 11(1), 63–90.",
      "citeRegEx" : "Holte and C.,? 1993",
      "shortCiteRegEx" : "Holte and C.",
      "year" : 1993
    }, {
      "title" : "An empirical evaluation of the comprehensibility of decision table, tree and rule based predictive models",
      "author" : [ "Huysmans", "Johan", "Dejaeger", "Karel", "Mues", "Christophe", "Vanthienen", "Jan", "Baesens", "Bart" ],
      "venue" : "Decision Support Systems,",
      "citeRegEx" : "Huysmans et al\\.,? \\Q2011\\E",
      "shortCiteRegEx" : "Huysmans et al\\.",
      "year" : 2011
    }, {
      "title" : "APACHE-acute physiology and chronic health evaluation: a physiologically based classification system",
      "author" : [ "Knaus", "William A", "Zimmerman", "Jack E", "Wagner", "Douglas P", "Draper", "Elizabeth A", "Lawrence", "Diane E" ],
      "venue" : "Critical Care Medicine,",
      "citeRegEx" : "Knaus et al\\.,? \\Q1981\\E",
      "shortCiteRegEx" : "Knaus et al\\.",
      "year" : 1981
    }, {
      "title" : "APACHE II: a severity of disease classification system",
      "author" : [ "Knaus", "William A", "Draper", "Elizabeth A", "Wagner", "Douglas P", "Zimmerman", "Jack E" ],
      "venue" : "Critical Care Medicine,",
      "citeRegEx" : "Knaus et al\\.,? \\Q1985\\E",
      "shortCiteRegEx" : "Knaus et al\\.",
      "year" : 1985
    }, {
      "title" : "The APACHE III prognostic system. Risk prediction of hospital mortality for critically ill hospitalized adults",
      "author" : [ "Knaus", "William A", "DP Wagner", "EA Draper", "JE Zimmerman", "Bergner", "Marilyn", "PG Bastos", "CA Sirio", "DJ Murphy", "T Lotring", "A. Damiano" ],
      "venue" : "Chest Journal,",
      "citeRegEx" : "Knaus et al\\.,? \\Q1991\\E",
      "shortCiteRegEx" : "Knaus et al\\.",
      "year" : 1991
    }, {
      "title" : "The comprehensibility manifesto",
      "author" : [ "Y. Kodratoff" ],
      "venue" : "KDD Nugget Newsletter, 94(9).",
      "citeRegEx" : "Kodratoff,? 1994",
      "shortCiteRegEx" : "Kodratoff",
      "year" : 1994
    }, {
      "title" : "Building Interpretable Classifiers with Rules using Bayesian Analysis",
      "author" : [ "Letham", "Benjamin", "Rudin", "Cynthia", "McCormick", "Tyler H", "Madigan", "David" ],
      "venue" : null,
      "citeRegEx" : "Letham et al\\.,? \\Q2012\\E",
      "shortCiteRegEx" : "Letham et al\\.",
      "year" : 2012
    }, {
      "title" : "Building acceptable classification models. Pages 53–74 of: Data",
      "author" : [ "Martens", "David", "Baesens", "Bart" ],
      "venue" : null,
      "citeRegEx" : "Martens et al\\.,? \\Q2010\\E",
      "shortCiteRegEx" : "Martens et al\\.",
      "year" : 2010
    }, {
      "title" : "Performance of classification models from a user perspective",
      "author" : [ "Martens", "David", "Vanthienen", "Jan", "Verbeke", "Wouter", "Baesens", "Bart" ],
      "venue" : "Decision Support Systems,",
      "citeRegEx" : "Martens et al\\.,? \\Q2011\\E",
      "shortCiteRegEx" : "Martens et al\\.",
      "year" : 2011
    }, {
      "title" : "TIMI risk score for ST-elevation myocardial infarction: a convenient, bedside, clinical score for risk assessment at presentation an intravenous nPA for treatment of infarcting myocardium early II trial",
      "author" : [ "Morrow", "David A", "Antman", "Elliott M", "Charlesworth", "Andrew", "Cairns", "Richard", "Murphy", "Sabina A", "de Lemos", "James A", "Giugliano", "Robert P", "McCabe", "Carolyn H", "Braunwald", "Eugene" ],
      "venue" : "substudy. Circulation,",
      "citeRegEx" : "Morrow et al\\.,? \\Q2000\\E",
      "shortCiteRegEx" : "Morrow et al\\.",
      "year" : 2000
    }, {
      "title" : "Knowledge discovery from data",
      "author" : [ "Pazzani", "Michael J" ],
      "venue" : "Intelligent systems and their applications,",
      "citeRegEx" : "Pazzani and J.,? \\Q2000\\E",
      "shortCiteRegEx" : "Pazzani and J.",
      "year" : 2000
    }, {
      "title" : "Acceptance of rules generated by machine learning among medical experts",
      "author" : [ "MJ Pazzani", "S Mani", "Shankle", "WR" ],
      "venue" : "Methods of information in medicine,",
      "citeRegEx" : "Pazzani et al\\.,? \\Q2001\\E",
      "shortCiteRegEx" : "Pazzani et al\\.",
      "year" : 2001
    }, {
      "title" : "Induction of decision trees",
      "author" : [ "Quinlan", "J. Ross." ],
      "venue" : "Machine learning, 1(1), 81–106.",
      "citeRegEx" : "Quinlan and Ross.,? 1986",
      "shortCiteRegEx" : "Quinlan and Ross.",
      "year" : 1986
    }, {
      "title" : "C4",
      "author" : [ "Quinlan", "John Ross." ],
      "venue" : "5: programs for machine learning. Vol. 1. Morgan kaufmann.",
      "citeRegEx" : "Quinlan and Ross.,? 1993",
      "shortCiteRegEx" : "Quinlan and Ross.",
      "year" : 1993
    }, {
      "title" : "Prognostic signs and the role of operative management in acute pancreatitis",
      "author" : [ "JH Ranson", "KM Rifkind", "DF Roses", "SD Fink", "K Eng", "FC Spencer" ],
      "venue" : "Surgery, gynecology & obstetrics,",
      "citeRegEx" : "Ranson et al\\.,? \\Q1974\\E",
      "shortCiteRegEx" : "Ranson et al\\.",
      "year" : 1974
    }, {
      "title" : "The Pitfalls of Prediction",
      "author" : [ "Ridgeway", "Greg." ],
      "venue" : "NIJ Journal, National Institute of Justice, 271, 34–40.",
      "citeRegEx" : "Ridgeway and Greg.,? 2013",
      "shortCiteRegEx" : "Ridgeway and Greg.",
      "year" : 2013
    }, {
      "title" : "Learning decision lists",
      "author" : [ "Rivest", "Ronald L." ],
      "venue" : "Machine learning, 2(3), 229–246.",
      "citeRegEx" : "Rivest and L.,? 1987",
      "shortCiteRegEx" : "Rivest and L.",
      "year" : 1987
    }, {
      "title" : "Learning interpretable models",
      "author" : [ "Rüping", "Stefan." ],
      "venue" : "Ph.D. thesis, Universität Dortmund.",
      "citeRegEx" : "Rüping and Stefan.,? 2006",
      "shortCiteRegEx" : "Rüping and Stefan.",
      "year" : 2006
    }, {
      "title" : "Partially collapsed Gibbs sampling and path-adaptive Metropolis-Hastings in high-energy astrophysics",
      "author" : [ "van Dyk", "David A", "Park", "Taeyoung" ],
      "venue" : "Handbook of Markov Chain Monte Carlo,",
      "citeRegEx" : "Dyk et al\\.,? \\Q2011\\E",
      "shortCiteRegEx" : "Dyk et al\\.",
      "year" : 2011
    }, {
      "title" : "Building comprehensible customer churn prediction models with advanced rule induction techniques",
      "author" : [ "Verbeke", "Wouter", "Martens", "David", "Mues", "Christophe", "Baesens", "Bart" ],
      "venue" : "Expert Systems with Applications,",
      "citeRegEx" : "Verbeke et al\\.,? \\Q2011\\E",
      "shortCiteRegEx" : "Verbeke et al\\.",
      "year" : 2011
    }, {
      "title" : "Bayesian Ors of Ands for Interpretable Classification with Application to Context Aware Recommender Systems",
      "author" : [ "Wang", "Tong", "Rudin", "Cynthia", "Doshi", "Finale", "Liu", "Yimin", "Klampfl", "Erica", "MacNeille", "Perry" ],
      "venue" : null,
      "citeRegEx" : "Wang et al\\.,? \\Q2014\\E",
      "shortCiteRegEx" : "Wang et al\\.",
      "year" : 2014
    } ],
    "referenceMentions" : [ {
      "referenceID" : 1,
      "context" : ", the TIMI scores, CHADS2 score, Apache scores, and the Ranson score, to name a few (Antman et al. , 2000; Morrow et al. , 2000; Gage et al. , 2001; Knaus et al. , 1981, 1985, 1991; Ranson et al. , 1974). These models can be computed without the use of a calculator, which makes them very practical as decision aids. Of course, we aim for this level of interpretability in purely data-driven classifiers, with no manual feature selection or rounding coefficients. In the industrial world, algorithms that discretize the input space have gained in popularity purely because they yield interpretable models. The CART algorithm of Breiman et al. (1984) seems to be the algorithm of choice, despite its drawbacks of being greedy and not as accurate as other methods.",
      "startOffset" : 85,
      "endOffset" : 650
    }, {
      "referenceID" : 1,
      "context" : "Since it is possible that decision tree methods can produce results that are inconsistent with monotonicity properties of the data, there is a subfield dedicated to altering these greedy decision tree algorithms to obey monotonicity properties (Ben-David, 1995; Feelders & Pardoel, 2003; Altendorf et al. , 2012). Studies showed that in many cases, no accuracy is lost in enforcing monotonicity constraints, and that medical experts were more willing to use the models with the monotonicity constraints (Pazzani et al. , 2001). Even with (what seem like) rather severe constraints on the hypothesis space such as monotonicity or sparsity in the number of leaves and nodes, it still seems that the set of accurate classifiers is often large enough so that it contains interpretable classifiers (see Holte, 1993). Because the monotonicity properties we enforce are much stronger than those of Ben-David (1995); Feelders & Pardoel (2003); Altendorf et al.",
      "startOffset" : 288,
      "endOffset" : 908
    }, {
      "referenceID" : 1,
      "context" : "Since it is possible that decision tree methods can produce results that are inconsistent with monotonicity properties of the data, there is a subfield dedicated to altering these greedy decision tree algorithms to obey monotonicity properties (Ben-David, 1995; Feelders & Pardoel, 2003; Altendorf et al. , 2012). Studies showed that in many cases, no accuracy is lost in enforcing monotonicity constraints, and that medical experts were more willing to use the models with the monotonicity constraints (Pazzani et al. , 2001). Even with (what seem like) rather severe constraints on the hypothesis space such as monotonicity or sparsity in the number of leaves and nodes, it still seems that the set of accurate classifiers is often large enough so that it contains interpretable classifiers (see Holte, 1993). Because the monotonicity properties we enforce are much stronger than those of Ben-David (1995); Feelders & Pardoel (2003); Altendorf et al.",
      "startOffset" : 288,
      "endOffset" : 935
    }, {
      "referenceID" : 1,
      "context" : "Since it is possible that decision tree methods can produce results that are inconsistent with monotonicity properties of the data, there is a subfield dedicated to altering these greedy decision tree algorithms to obey monotonicity properties (Ben-David, 1995; Feelders & Pardoel, 2003; Altendorf et al. , 2012). Studies showed that in many cases, no accuracy is lost in enforcing monotonicity constraints, and that medical experts were more willing to use the models with the monotonicity constraints (Pazzani et al. , 2001). Even with (what seem like) rather severe constraints on the hypothesis space such as monotonicity or sparsity in the number of leaves and nodes, it still seems that the set of accurate classifiers is often large enough so that it contains interpretable classifiers (see Holte, 1993). Because the monotonicity properties we enforce are much stronger than those of Ben-David (1995); Feelders & Pardoel (2003); Altendorf et al. (2012) (we are looking at monotonicity along the whole list rather than for individual features), we do find that accuracy is sometimes sacrificed, but not always, and generally not by much.",
      "startOffset" : 288,
      "endOffset" : 960
    } ],
    "year" : 2017,
    "abstractText" : "Falling rule lists are classification models consisting of an ordered list of if-then rules, where (i) the order of rules determines which example should be classified by each rule, and (ii) the estimated probability of success decreases monotonically down the list. These kinds of rule lists are inspired by healthcare applications where patients would be stratified into risk sets and the highest at-risk patients should be considered first. We provide a Bayesian framework for learning falling rule lists that does not rely on traditional greedy decision tree learning methods.",
    "creator" : "LaTeX with hyperref package"
  }
}