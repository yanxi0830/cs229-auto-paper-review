{
  "name" : "1412.1463.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "On the String Kernel Pre-Image Problem with Applications in Drug Discovery",
    "authors" : [ "Sébastien Giguère", "Amélie Rolland", "François Laviolette", "Mario Marchand" ],
    "emails" : [ ],
    "sections" : [ {
      "heading" : null,
      "text" : "ar X\niv :1\n41 2.\n14 63\nv2 [\ncs .L\nG ]\n4 D\nec 2"
    }, {
      "heading" : "1 Introduction",
      "text" : "This work focuses on the challenges of using regression learning algorithms in the design of highly active peptides. Let A be the set of all amino acids and A∗ be the set of all possible peptides. Throughout this paper we will assume that we have a dataset S = {(x1, e1), . . . , (xm, em)} ∈ A∗ ×R where xi is the amino acid sequence of the i-th peptide in S and ei is its bioactivity (which could be its binding affinity to some target protein, its antimicrobial activity, or some other desirable activity for peptides). The regression approach consists of learning a predictor h from the training dataset S. Let h(x) be the estimated bioactivity of x according to the predictor h. There are many ways to represent such a predictor but this work focuses on string kernel based predictors. Many learning algorithm, such as the Support Vector Regression, Ridge Regression, and Gaussian Processes, produce predictors h whose output h(x), on input x, is given by\nh(x) =\nm ∑\ni=1\nαiK(xi,x) , (1)\nwhere αi is the weight on the i-th training example, K(xi,x) = 〈φ(x),φ(x′)〉 is a string kernel, 〈·, ·〉 denotes the inner product between feature vectors, and φ is the feature map associated to K . The weight vector α = (α1, α2, .., αm) is obtained by minimizing the learning algorithm objective function.\nFor the discovery of peptide inhibitors and peptides that could act as drug precursors, we are interested in finding the peptide xh maximizing the predicted bioactivity:\nx h = arg max\nx∈A∗ h(x) . (2)\nThe complexity of this combinatorial problem will obviously depend on the string kernel used to learn h. For few kernels like the Hamming kernel, solving Equation (2) is trivial [1]. However, this kernel is not well suited for peptides [2]. On another hand, the Generic String (GS) kernel [2] is well suited for peptides. It is defined as follows:\nGS(x,x′, k, σp, σc) def =\nk ∑\nl=1\n|x|−l ∑\ni=0\n|x′|−l ∑\nj=0\nexp ( −(i−j)2\n2σ2p\n)\nexp\n(\n−‖ψl(xi+1,..,xi+l)−ψ l(x′j+1,..,x ′ j+l )‖2\n2σ2c\n)\n, (3)\n1Corresponding author: amelie.rolland.1@ulaval.ca Peer-reviewed and accepted for presentation at Machine Learning in Computational Biology 2014, Montréal, Québec, Canada.\nwhere k controls the length of compared k-mers, ψk : Ak → Rdk encodes the physico-chemical properties of k-mers by mapping each of the k amino acids to a real valued vector containing d properties, σc controls the penalty incurred when the physico-chemical properties of two k-mers differ, and σp controls the penalty incurred when two k-mers are not sharing the same position in their respective peptides. Depending on the chosen hyper-parameters, this kernel can be specialized to eight known kernels [2], namely the Hamming kernel, the Blended Spectrum [3], the Radial Basis Function (RBF), the Oligo [4], and the Weighted degree [5]. Since the proposed approach uses the GS kernel it is also valid for all of these kernels.\nIt was recently shown [6] that when K is the Generic String (GS) kernel, and when we restrict peptides to be of length l, the peptide xh ∈ Al can be found in polynomial time for any predictor h in the form of Equation (1). Their approach maps the combinatorial problem to a directed acyclic graph (DAG) that is basically a de Bruijn graph with weights on the arcs. Then, they show that finding the longest (weighted) path in this graph is equivalent to finding xh ∈ Al. Finally, the longest path can be found in polynomial time by dynamic programming since the graph is acyclic.\nHowever, with the GS kernel, given two peptides x and x′ of the same length, the Euclidean norms of their feature vectors φ(x) and φ(x′) can differ substantially, i.e. we can have √ K(x,x) ≫ √\nK(x′,x′). Let us first show, with a simple example, why this can be problematic. We will then show how to avoid this problem through kernel normalization. Such normalization does not have any computational impact in the learning phase of the regression algorithm. It does however impact substantially the prediction phase, leading to a harder combinatorial problem.\nHence, let us consider the strings “AAAAA” and “ABCDE” and the Spectrum kernel [7] (also known as the n-gram kernel) with k-mers of size two. The string “AAAAA” has a norm of √ 16 = 4, while “ABCDE” has a norm of√\n1 + 1 + 1 + 1 = 2. Hence the Spectrum kernel is sensitive to k-mers repetitions in the string. Note that this problem is shared by many other string kernels. In the case of the GS kernel, it is possible to avoid this problem by fixing the hyper-parameter σp to 0, which forces a constant norm, i.e. K(x,x) = c for all x ∈ Al. However, K(x,x) will vary whenever σp > 0, as it is the case for the Blended Spectrum and the Oligo kernels, for example. A consequence of a non-constant norm is that h(x) will heavily depend on the norm of φ(x). Hence, xh will be more likely a peptide having a feature vector with a large norm, i.e., a peptide having many repetitions. This is generally an undesired bias. It is easy to overcome this problem by normalizing kernel values, in that case the output function becomes\nh⋆(x) = m ∑\ni=1\nαi K(xi,x) √\nK(xi,xi)K(x,x) =\n1 √\nK(x,x)\nm ∑\ni=1\nβiK(xi,x) (4)\nwhere βi = αi√ K(xi,xi) . In that case we are now interested in finding\nx h⋆ = arg max\nx∈A∗\n1 √\nK(x,x)\nm ∑\ni=1\nβiK(xi,x) . (5)\nThis optimization problem is also a pre-image problem, but written in a slightly different form. We conjecture that solving Equation (5) is NP-Hard when K is the GS kernel. Given the similarity between the problems of Equation (2) and Equation (5), the difference in their computational complexity is unexpected.\nIn the next section, we will present a low complexity upper bound on Equation (4) that makes it a good candidate for a branch and bound search to solve Equation (5)."
    }, {
      "heading" : "2 Method",
      "text" : "Since the number of peptides grows exponentially with its length, it becomes impossible to evaluate all solutions for large peptides, we propose a branch and bound scheme to guide this search. A branch and bound algorithm starts by dividing the search space into disjoint subspaces. For example, one subspace could be all peptides ending with the string “DE”. For a maximization problem, an upper bound on the best achievable solution is computed for each of these subspaces. Then, the subspace with the highest upper bound is further divided into smaller subspaces. Finally, the search stops when a subspace can no longer be divided (a leaf is reached in the search tree), or when the upper bound value is lower than the value of an already achieved solution (i.e., an already reached leaf in the search tree). A branch and bound approach can thus avoid exploring a large part of the search space.\nAlgorithm 1 gives the specifics of the branch and bound algorithm applied to our case. The search algorithm alternates between a greedy phase and a branch and bound phase. The greedy phase is important to ensure that leaves of the search tree are quickly visited. This allows good but sub-optimal solutions to be returned by the algorithm if the allowed computational time expires. Whenever a node is visited, the bound is computed for all its children and they\nare added to the priority queue accordingly. This greedy process is repeated until a leaf is reached. Then, the node with the largest bound is visited and the greedy process starts again. At all time, the best solution found so far is kept and the search stops when the bound of the node on top of the priority queue is smaller than the value of the best solution.\nAlgorithm 1 Branch and bound search for maximal string of length l Q : empty priority queue ordering bounds in descending order\nbest node ← Node(empty string, 0) for all s ∈ Ak do ⊲ Add all k-mer in Q\nQ.push(Node(s, F (s, l))) end for while current node ← Q.pop() & current node.bound > best node.bound do ⊲ Get maximal node in Q\nwhile |current node.string| < l & current node.bound > best node.bound do best child ← Node(empty-string, 0) for all a ∈ A do ⊲ Evaluate all children of node\ns′ ← Concatenate(a, current node.string) if F (s′, l) > best node.bound then\nif F (s′, l) > best child.bound then best child ← Node(s′, F (s′, l)) ⊲ Update best child end if Q.push(Node(s′, F (s′, l))) ⊲ Add child to Q end if end for current node ← best child Q.remove(best child) ⊲ Remove best child from Q if it was added\nend while if |current node.string| = l & current node.bound > best node.bound then\nbest node ← current node ⊲ Update best node end if\nend while\nreturn best node.string, best node.bound ⊲ Return string and maximal bioactivity\nLet Al−p ×{x′1, . . . , x′p} be the set of all possible strings of length l that end with x′1, . . . , x′p, in other words, Al−p × {x′1, . . . , x′p} is a set of strings having their last p characters fixed. Our goal is to have a function F that upper bounds h⋆ for every Al−p × {x′1, . . . , x′p}. In other words:\nF (x′, l) ≥ max x∈Al−p×{x′\n1 ,...,x′p}\n1 √\nK(x,x)\nm ∑\ni=1\nβiK(xi,x) . (6)\nTo do so, let F (x′, l) def = 1√\nf(x′,l) g(x′, l), where\nf(x′, l) ≤ min x∈Al−p×{x′\n1 ,...,x′p}\nK(x,x) and g(x′, l) ≥ max x∈Al−p×{x′\n1 ,...,x′p}\nm ∑\ni=1\nβiK(xi,x) (7)\nare, respectively, a lower and an upper bound.\nWhen K is the GS kernel with hyper-parameters k , σp and σc, the lower bound f can be obtained as follows:\nfk,σp,σc (x ′, l) def = GS(x′,x′, k, σp, σc) + 2XX ′(x′, l, k, σp, σc) +XX(x ′, l, k, σp, σc) , (8)\nwhere\nXX ′(x′, l, k, σp, σc) def =\nk ∑\np=1\nl−|x′| ∑\ni=1\nmin x∈Ap\n|x′| ∑\nj=1\nexp ( −(i−j)2\n2σ2p\n)\nexp\n(\n−‖ψl(x1,..,xp)−ψ l(x′j ,..,x ′ j+p)‖ 2\n2σ2c\n)\n, (9)\nXX(x′, l, k, σp, σc) def =\nk ∑\np=1\nl−|x′| ∑\ni=1\nl−|x′| ∑\nj=1\nexp ( −(i−(l−|x′|+j))2\n2σ2p\n) exp ( −(D(i,j)2+...+D(i+p,j+p)2\n2σ2c\n)\n(10)\nand\nD(i, j) =\n{\n0 if i = j,\nmax a,a′∈A\nψ(a, a′) otherwise.\nNote that the lower bound f is not attained since it under-estimates the value of the string x ∈ Al−p × {x′1, . . . , x′p} minimizing K(x,x).\nFor g(x′, l), note that ∑m\ni=1 βiK(xi,x) is what [6] proposed to maximize. Their approach uses a dynamic programming table to compute the longest path in a graph. It is relatively easy to modify their algorithm to return the table instead of the longest path. In that way, given a string with suffix x′, it is possible to determine in constant time, by accessing the dynamic programming table, the prefix from Al−p maximizing ∑mi=1 βiK(xi,x). The computation of g is thus very efficient, the algorithm of [6] only needs to be done once before the branch and bound search, then g(x′, l) can be computed in constant time for any x′. Finally, g is the least upper bound (or suprema) since there is always a string x ∈ Al−p × {x′1, . . . , x′p} with g(x, l) = ∑m i=1 βiK(xi,x). In other words, there are no tighter bound."
    }, {
      "heading" : "3 Results and Discussion",
      "text" : "We followed the protocol suggested by [6] and, as a proof of concept, we used the same dataset they used: 101 cationic antimicrobial pentadecapeptides (CAMPs) from the synthetic antibiotic peptides database [8]. Peptide antibacterial activities are expressed as the logarithm of bactericidal potency. As in [6], we used kernel ridge regression as the learning algorithm. Except when stated otherwise, all hyper-parameters for the GS kernel (k, σc, σp) and the kernel ridge regression (λ) were chosen by standard cross-validation. We learned two predictors of antimicrobial potency, one uses unnormalized kernel values (thus, the same predictor used in [6]), the other was trained using normalized kernel values. We refer to these predictors respectively as h and h⋆.\nThe method presented in [6] was used to identify the peptide xh ∈ A15 of maximal predicted bioactivity according to h and the branch and bound was used to identify xh⋆ ∈ A15, the peptide maximizing h⋆. Both approaches found the same peptide, which is “WWKWWKRLRRLFLLV”.\nNote that both methods are able to output more than one sequence. The method of [6] uses a k-longest path algorithm to obtain the k peptides of maximal bioactivity. It is also possible for the branch and bound by stopping the search only when the bound on top of the priority queue is lower than the k-th peptide found. These peptides can be used, for example, for motif generation, for multiple peptide synthesis or in combinatorial chemistry. To highlight the differences between the methods, they were used to list the top 1000 peptides and the lists were compared: 70.5% of the 1000 peptides were found by both methods. Then, the Pearson correlation coefficient (PCC) was computed between the rank of the 679 peptides present in both lists: a PCC of 0.56 was obtained. Hence, the ranking of peptides found by h and by h⋆ differ significantly.\nThe overlap in the lists is attributed to the value of σp that was chosen during cross-validation for h. As explained earlier, when σp is 0, the unnormalized predictor h will not suffer from differences in the norm of φ(x). In the case of antimicrobial peptides, σp = 0.8 was found to be the optimal value for h. This suggests that the method of [6] offers some resistance to variation in norm when σp is small. Indeed, for small σp, all examples have about the same norm.\nTo further highlight the difference between the methods, we intentionally fixed σp to infinity and cross-validated all other parameters for h and h⋆ and compared the best peptides found. Situations were σp would have to be set to infinity are not at all unlikely. For example, cyclic peptides have no N-terminus and no C-terminus. For that reason, there is no origin from which we can express the positions of k-mers in these peptides. The method of [6] found the peptide “FKKIFKKIFKKIFKF” using the predictor h and the branch and bound approach found the peptide “WKKIFKKIWKFRVFK” using the predictorh⋆. The peptide identified by h shares almost no similarity with peptides of the training set and is basically composed of repetition of the k-mer “FKK”. In contrast, the peptide identified by h⋆ shares many substructures with the most bioactive peptides of the training set. This tends to point out that in situation where example norms vary a lot, h clearly favors examples having a large norm. However, this bias is unjustified and is not related to a biological reality."
    }, {
      "heading" : "4 Conclusion",
      "text" : "We proposed a bound for maximizing the inference function of kernel methods that uses normalized string kernels. Moreover, the bound is also valid for solving the pre-image of a variety of string kernels. Empirical results show that the method proposed by [6] can suffer from a dominance of the norm for certain strings, a problem which is present\nwith many string kernels. In these situations, the proposed method was shown to overcome this problem. Tighter bounds should take advantage of the proposed framework and allow the discovery of novel peptide inhibitors. Finally, applications for drugs based on cyclic peptides and other structured output applications are expected."
    }, {
      "heading" : "Acknowledgments",
      "text" : "The authors would like to thank Prudencio Tossu for his help in the experimentations. Computations were performed on the Colosse supercomputer at Université Laval (resource allocation project: avt-710-aa), under the auspices of Calcul Québec and Compute Canada. AR is recipient of a Master’s Scholarship from the Fonds de recherche du Québec - Nature et technologies (FRQNT). This work was supported by the FRQNT (FL & MM; 2013-PR-166708)."
    } ],
    "references" : [ {
      "title" : "Risk bounds and learning algorithms for the regression approach to structured output prediction",
      "author" : [ "Sébastien Giguère", "François Laviolette", "Mario Marchand", "Khadidja Sylla" ],
      "venue" : "In International Conference on Machine Learning (ICML),",
      "citeRegEx" : "1",
      "shortCiteRegEx" : "1",
      "year" : 2013
    }, {
      "title" : "Learning a peptide-protein binding affinity predictor with kernel ridge regression",
      "author" : [ "Sébastien Giguère", "Mario Marchand", "François Laviolette", "Alexandre Drouin", "Jacques Corbeil" ],
      "venue" : "BMC Bioinformatics,",
      "citeRegEx" : "2",
      "shortCiteRegEx" : "2",
      "year" : 2013
    }, {
      "title" : "Kernel methods for pattern analysis",
      "author" : [ "John Shawe-Taylor", "Nello Cristianini" ],
      "venue" : "Cambridge university press,",
      "citeRegEx" : "3",
      "shortCiteRegEx" : "3",
      "year" : 2004
    }, {
      "title" : "Oligo kernels for datamining on biological sequences: A case study on prokaryotic translation initiation sites",
      "author" : [ "P. Meinicke", "M. Tech", "B. Morgenstern", "R. Merkl" ],
      "venue" : "BMC Bioinformatics,",
      "citeRegEx" : "4",
      "shortCiteRegEx" : "4",
      "year" : 2004
    }, {
      "title" : "Accurate Splice Site Detection for Caenorhabditis elegans",
      "author" : [ "Gunnar Rätsch", "Sören Sonnenburg" ],
      "venue" : "Kernel Methods in Computational Biology,",
      "citeRegEx" : "5",
      "shortCiteRegEx" : "5",
      "year" : 2004
    }, {
      "title" : "Machine learning assisted design of highly active peptides for drug discovery",
      "author" : [ "Sébastien Giguère", "François Laviolette", "Mario Marchand", "Denise Tremblay", "Sylvain Moineau", "Éric Biron", "Jacques Corbeil" ],
      "venue" : "Under review, Submitted to MLCB,",
      "citeRegEx" : "6",
      "shortCiteRegEx" : "6",
      "year" : 2014
    }, {
      "title" : "The spectrum kernel: A string kernel for svm protein classification",
      "author" : [ "Christina S Leslie", "Eleazar Eskin", "William Stafford Noble" ],
      "venue" : "In Pacific symposium on biocomputing,",
      "citeRegEx" : "7",
      "shortCiteRegEx" : "7",
      "year" : 2002
    }, {
      "title" : "Synthetic antibiotic peptides database",
      "author" : [ "David Wade", "Jukka Englund" ],
      "venue" : "Protein and peptide letters,",
      "citeRegEx" : "8",
      "shortCiteRegEx" : "8",
      "year" : 2002
    } ],
    "referenceMentions" : [ {
      "referenceID" : 0,
      "context" : "For few kernels like the Hamming kernel, solving Equation (2) is trivial [1].",
      "startOffset" : 73,
      "endOffset" : 76
    }, {
      "referenceID" : 1,
      "context" : "However, this kernel is not well suited for peptides [2].",
      "startOffset" : 53,
      "endOffset" : 56
    }, {
      "referenceID" : 1,
      "context" : "On another hand, the Generic String (GS) kernel [2] is well suited for peptides.",
      "startOffset" : 48,
      "endOffset" : 51
    }, {
      "referenceID" : 1,
      "context" : "Depending on the chosen hyper-parameters, this kernel can be specialized to eight known kernels [2], namely the Hamming kernel, the Blended Spectrum [3], the Radial Basis Function (RBF), the Oligo [4], and the Weighted degree [5].",
      "startOffset" : 96,
      "endOffset" : 99
    }, {
      "referenceID" : 2,
      "context" : "Depending on the chosen hyper-parameters, this kernel can be specialized to eight known kernels [2], namely the Hamming kernel, the Blended Spectrum [3], the Radial Basis Function (RBF), the Oligo [4], and the Weighted degree [5].",
      "startOffset" : 149,
      "endOffset" : 152
    }, {
      "referenceID" : 3,
      "context" : "Depending on the chosen hyper-parameters, this kernel can be specialized to eight known kernels [2], namely the Hamming kernel, the Blended Spectrum [3], the Radial Basis Function (RBF), the Oligo [4], and the Weighted degree [5].",
      "startOffset" : 197,
      "endOffset" : 200
    }, {
      "referenceID" : 4,
      "context" : "Depending on the chosen hyper-parameters, this kernel can be specialized to eight known kernels [2], namely the Hamming kernel, the Blended Spectrum [3], the Radial Basis Function (RBF), the Oligo [4], and the Weighted degree [5].",
      "startOffset" : 226,
      "endOffset" : 229
    }, {
      "referenceID" : 5,
      "context" : "It was recently shown [6] that when K is the Generic String (GS) kernel, and when we restrict peptides to be of length l, the peptide x ∈ Al can be found in polynomial time for any predictor h in the form of Equation (1).",
      "startOffset" : 22,
      "endOffset" : 25
    }, {
      "referenceID" : 6,
      "context" : "Hence, let us consider the strings “AAAAA” and “ABCDE” and the Spectrum kernel [7] (also known as the n-gram kernel) with k-mers of size two.",
      "startOffset" : 79,
      "endOffset" : 82
    }, {
      "referenceID" : 5,
      "context" : "For g(x, l), note that ∑m i=1 βiK(xi,x) is what [6] proposed to maximize.",
      "startOffset" : 48,
      "endOffset" : 51
    }, {
      "referenceID" : 5,
      "context" : "The computation of g is thus very efficient, the algorithm of [6] only needs to be done once before the branch and bound search, then g(x, l) can be computed in constant time for any x.",
      "startOffset" : 62,
      "endOffset" : 65
    }, {
      "referenceID" : 5,
      "context" : "3 Results and Discussion We followed the protocol suggested by [6] and, as a proof of concept, we used the same dataset they used: 101 cationic antimicrobial pentadecapeptides (CAMPs) from the synthetic antibiotic peptides database [8].",
      "startOffset" : 63,
      "endOffset" : 66
    }, {
      "referenceID" : 7,
      "context" : "3 Results and Discussion We followed the protocol suggested by [6] and, as a proof of concept, we used the same dataset they used: 101 cationic antimicrobial pentadecapeptides (CAMPs) from the synthetic antibiotic peptides database [8].",
      "startOffset" : 232,
      "endOffset" : 235
    }, {
      "referenceID" : 5,
      "context" : "As in [6], we used kernel ridge regression as the learning algorithm.",
      "startOffset" : 6,
      "endOffset" : 9
    }, {
      "referenceID" : 5,
      "context" : "We learned two predictors of antimicrobial potency, one uses unnormalized kernel values (thus, the same predictor used in [6]), the other was trained using normalized kernel values.",
      "startOffset" : 122,
      "endOffset" : 125
    }, {
      "referenceID" : 5,
      "context" : "The method presented in [6] was used to identify the peptide x ∈ A15 of maximal predicted bioactivity according to h and the branch and bound was used to identify x⋆ ∈ A15, the peptide maximizing h⋆.",
      "startOffset" : 24,
      "endOffset" : 27
    }, {
      "referenceID" : 5,
      "context" : "The method of [6] uses a k-longest path algorithm to obtain the k peptides of maximal bioactivity.",
      "startOffset" : 14,
      "endOffset" : 17
    }, {
      "referenceID" : 5,
      "context" : "This suggests that the method of [6] offers some resistance to variation in norm when σp is small.",
      "startOffset" : 33,
      "endOffset" : 36
    }, {
      "referenceID" : 5,
      "context" : "The method of [6] found the peptide “FKKIFKKIFKKIFKF” using the predictor h and the branch and bound approach found the peptide “WKKIFKKIWKFRVFK” using the predictorh⋆.",
      "startOffset" : 14,
      "endOffset" : 17
    }, {
      "referenceID" : 5,
      "context" : "Empirical results show that the method proposed by [6] can suffer from a dominance of the norm for certain strings, a problem which is present",
      "startOffset" : 51,
      "endOffset" : 54
    } ],
    "year" : 2014,
    "abstractText" : "The pre-image problem has to be solved during inference by most structured output predictors. For string kernels, this problem corresponds to finding the string associated to a given input. An algorithm capable of solving or finding good approximations to this problem would have many applications in computational biology and other fields. This work uses a recent result on combinatorial optimization of linear predictors based on string kernels to develop, for the pre-image, a low complexity upper bound valid for many string kernels. This upper bound is used with success in a branch and bound searching algorithm. Applications and results in the discovery of druggable peptides are presented and discussed.",
    "creator" : "LaTeX with hyperref package"
  }
}