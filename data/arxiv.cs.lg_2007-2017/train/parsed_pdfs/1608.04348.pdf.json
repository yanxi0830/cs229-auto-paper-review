{
  "name" : "1608.04348.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : null,
    "authors" : [ "Bilal Abbasi", "Jeff Calder", "Adam M. Oberman" ],
    "emails" : [ "(bilal.abbasi.ba@gmail.com)", "(jcalder@umn.edu)", "(adam.oberman@mcgill.ca)" ],
    "sections" : [ {
      "heading" : null,
      "text" : "ar X\niv :1\n60 8.\n04 34\n8v 1\n[ cs\n.L G\n] 1\n5 A"
    }, {
      "heading" : "1 Introduction",
      "text" : "Sorting, or ordering of multivariate data is an important and challenging problem in many fields of computational science. Since there is no canonical linear ordering for multivariate data, many different notions of ordering have been proposed in the literature [23], and the problem is very much application dependent.\nIn the context of multiobjective optimization, ordering by dominance relations has achieved prominence. A general multiobjective optimization problem involves finding among a set of feasible solutions those that minimize a collection of objectives. One feasible solution is said to dominate another if it gives a smaller value for every objective. The collection of feasible solutions that are not dominated by any other solution are called Pareto-optimal or nondominated. In the database community the Pareto-optimal solutions are called the skyline of the dataset [22].\nThe notion of Pareto-optimality is widely used in evolutionary algorithms for multiobjective optimization [27], such as the Nondominated Sorting Genetic Algorithm (NSGA-II) [10], the Strength Pareto Evolutionary Algorithm (SPEA) [29, 30], and the Pareto envelope-based selection algorithm (PESA) [9], among many others (see [15] for a survey). Central to many of these algorithms is the assignment of a fitness to each feasible solution based on sorting all the feasible solutions via dominance.\nThe NSGA-II algorithm assigns its fitness level via nondominated sorting, sometimes called Pareto Depth Analysis (PDA), which arranges the feasible solutions into layers by repeatedly\n∗The second author was supported by NSF grant DMS-1500829. †Department of Mathematics and Statistics, McGill University. (bilal.abbasi.ba@gmail.com) ‡School of Mathematics, University of Minnesota. (jcalder@umn.edu) §Department of Mathematics and Statistics, McGill University. (adam.oberman@mcgill.ca)\npeeling off the Pareto-optimal solutions. Nondominated sorting has also found applications in gene selection and ranking [16], anomaly detection [19, 20], and multiquery image retrieval [18]. As it turns out, nondominated sorting is equivalent to the longest chain problem, which has a long history in combinatorics and probability [2].\nDue to the wide use of NSGA-II, there has been significant interest in fast algorithms for nondominated sorting [10, 21, 14]. Recently, Calder et al. [5] established a continuum limit for nondominated sorting that corresponds to solving a Hamilton-Jacobi partial differential equation (HJE). This result shows that there is a simple asymptotic structure underlying nondominated sorting, and this opens the door to extremely fast algorithms based on exploiting this structure. Calder et al. [6] recently proposed a sublinear algorithm for approximate nondominated sorting called PDE-based ranking that is based on estimating the distribution of the data and solving the HJE numerically.\nThe purpose of this paper is twofold. First, we show how to use PDE-based ranking to significantly improve the performance of algorithms that are based on nondominated sorting. To illustrate this in a concrete setting, we propose a new real-time version of the multicriteria PDA anomaly detection algorithm from [20] that uses PDE-based ranking in place of nondominated sorting. The computational complexity is reduced by an order of magnitude (from quadratic to linear), and this allows the model to be updated in real-time upon the acquisition of each additional data sample. We also prove in Theorem 2 a convergence rate for the PDE-based ranking continuum approximation.\nSecond, we present a new partial differential equation (PDE) continuum limit for ordering solutions within the layers generated by nondominated sorting in two dimensions. This new continuum limit allows us to efficiently explore the tradeoff between multiple objectives. In the context of multi-criteria anomaly detection, we show how to use this PDE continuum limit to classify anomalies based on which criterion is more significantly violated. We give a derivation of these new continuum limits and present a convergence analysis. In both cases, we trade exact algorithms of high computational complexity for fast approximate algorithms that are convergent, meaning that the error in the approximation goes to zero as the sample size grows.\nThis paper is organized as follows. In Section 2 we review the continuum limit for nondominated sorting from [5], and present the PDA multicriteria anomaly detection algorithm from [20]. In Section 3, we derive two new PDE continuum limits for ordering points within Pareto fronts, and fast upwind schemes for solving these PDEs numerically. In Section 4, we present our fast PDE-based anomaly detection and classification algorithm in the context of streaming data, and in Section 5 we present the results of numerical experiments for both real and synthetic data streams."
    }, {
      "heading" : "2 Previous work",
      "text" : ""
    }, {
      "heading" : "2.1 Nondominated sorting",
      "text" : "Nondominated sorting arranges a set of points in Rd into layers by repeatedly peeling off the coordinatewise minimal points. The coordinatewise partial order on Rd is defined by\nx ≦ y ⇐⇒ ∀i xi ≤ yi (x, y ∈ Rd).\nLet Sn = {X1, . . . ,Xn} ⊂ Rd be a collection of n points in Rd. We say a point Xi ∈ Sn is minimal (or nondominated), if no other non-identical point in Sn is smaller with respect to the coordinatewise partial order ≦. The first nondominated layer, denoted F1, consists of the minimal points from Sn. The second nondominated layer, denoted F2, consists of the minimal points from Sn \\ F1 and the kth layer is defined recursively by\nFk = Minimal points from Sn \\ (F1 ∪ · · · ∪ Fk−1).\nNondominated sorting refers to the process of arranging the set Sn into the nondominated layers F1,F2,F3, . . . , which are also called Pareto fronts. See Figure 1 for a demonstration of nondominated sorting applied to random points. The index of the Pareto front that a point Xi ∈ Sn lies on is often called the Pareto depth or Pareto rank of Xi, and provides the fitness score for the NSGA-II algorithm. In the context of multiobjective optimization, d represents the number of objectives.\nThe original nondominated sorting algorithm proposed in [10] requires O(dn2) memory and operations. The quadratic memory complexity in n renders the algorithm intractable for even moderate n. Jensen [21] proposed an algorithm with asymptotic complexity of O(n(log n)d−1) as n → ∞. The two dimensional version of Jensen’s algorithm was discovered independently in the combinatorics community by Felsner and Wernisch [13]. Fortin et al. [14] recently made some improvements to Jensen’s algorithm regarding its treatment of points with identical coordinates. The exponential complexity of the Jensen-Fortin algorithm with respect to d suggests it may not be useful for high dimensional problems. However, recent numerical results have suggested a better asymptotic complexity as d → ∞ with n fixed [20]. See [26, 7, 12] for other notable approaches to nondominated sorting.\nCalder et al. [5] discovered a Hamilton-Jacobi equation continuum limit for nondominated sorting. The result applies in the setting where Sn = {X1, . . . ,Xn} is a sequence of i.i.d. random variables with probability density f on the unit box (0, 1)d. Define the Pareto depth function Un : Sn → N associated with nondominated sorting of Sn by Un(Xi) = k if and only if Xi ∈ Fk. The following continuum limit was established in [5].\nTheorem 1 (HJE Continuum Limit). With probability one\nn− 1 dUn −→ Cdu uniformly on [0, 1]d as n → ∞\nwhere Cd > 0 is a constant depending only on d, and u : [0, 1] d → R is the unique nondecreasing viscosity solution of the Hamilton-Jacobi equation\nux1 · · · uxd = f in (0, 1]d\nu = 0 on ∂(0, 1)d \\ (0, 1]d.\n} (1)\nHere uxi := ∂u ∂xi denotes the partial derivative of u with respect to xi, and by nondecreasing we mean that uxi ≥ 0 for all i. Figure 1 gives an illustration of this continuum limit when X1, . . . ,Xn are independent and uniformly distributed. The continuum limit in Theorem 1 states that the Pareto fronts converge to the level sets of the viscosity solution u of (1). While the value of Cd is not needed for sorting, we should mention that it is known only in dimension d = 2, in which case C2 = 1 [24, 28].\nCalder et al. [6] proposed a fast algorithm for approximate nondominated sorting called PDE-based ranking that is based on estimating the density function f from a small subset of the data X1, . . . ,Xn and then solving (1) numerically.\nHamilton-Jacobi equations like (1) generally do not admit classical solutions (i.e., continuously differentiable solutions) due to the possibility of crossing characteristics. There are, however, infinitely many functions u that are differentiable almost everywhere and satisfy (1) at each point of differentiability. The notion of viscosity solution selects from among these infinitely many feasible solutions the one that is ‘physically correct’ for a very wide range of problems. In this context, the viscosity solution is correct because it captures the continuum limit of the Pareto depth function [5].\nThe notion of viscosity solution is based on the maximum principle and enjoys very strong stability properties. It is a notion of weak solution that allows merely continuous functions to be solutions of a PDE. While viscosity solutions may not possess the derivatives appearing in the equation in the classical sense, the reader will not lose much in the way of understanding by assuming that u is continuously differentiable. It is possible to prove that the viscosity solution u of (1) is Hölder continuous with exponent 1/d [5]. For more details on viscosity solutions we refer the reader to [1]."
    }, {
      "heading" : "2.2 Anomaly detection",
      "text" : "To illustrate the computational advantages of PDE-based ranking, we consider a concrete application of nondominated sorting to anomaly detection [20]. Anomaly detection refers to the problem of detecting patterns in data that deviate from the expected behavior. It is an important and challenging problem with a wide array of applications, including computer intrusion detection, video surveillance, credit card fraud, and biometrics [17, 8]. Many anomaly detection algorithms rely on the availability of a measure of distance (or similarity) between data samples, and look for anomalies by finding samples that are far from their nearest neighbors (see [20] and references therein). These algorithms are usually called similarity-based, and are widely used due to their simplicity and robustness.\nIn contrast, feature-based algorithms seek to embed the data into a relatively low dimensional Euclidean space and make use of the ambient Euclidean (or other) distance to detect anomalies. Techniques used for feature-based algorithms include support vector machines (SVM), clustering, neural networks, and statistical approaches based on density estimation [8]. In this paper we consider similarity-based approaches.\nIn many applications, multiple measures of similarity may be required to detect certain types of anomalies. For example, when tracking pedestrians in video surveillance, one criterion may correspond to differences in individual walking speeds, while another might correspond to differences in the shapes of trajectories. Using multiple criteria allows one to detect a wider range of anomalies than could be obtained from a single criterion alone.\nHsiao et al. [20] proposed an algorithm for multi-criteria anomaly detection that integrates the information from multiple similarity measures via nondominated sorting (or Pareto Depth Analysis (PDA)). Suppose we have a training set consisting of N objects Y1, . . . , YN and d measures of similarity c1, . . . , cd for comparing these objects. Without loss of generality, we assume 0 ≤ ci(·, ·) ≤ 1—a lower score indicates the objects are more similar with respect to the ith criteria. The training phase of the algorithm consists of computing the n := ( N 2 ) dyads\nXi,j = (c1(Yi, Yj), . . . , cd(Yi, Yj)) ∈ [0, 1]d, (2) and constructing the Pareto depth function Un by applying nondominated sorting to the n points {Xi,j}Ni,j=1. Recall that Un(Xi,j) = k if and only if Xi,j belongs to the kth Pareto front.\nThe testing phase of the algorithm receives a new object Y and compares it to all training samples to create N new dyads Z1, . . . , ZN given by\nZj = (c1(Y, Yj), . . . , cd(Y, Yj)).\nFix a number k, and let I ⊂ {1, . . . , N} denote the indices of training samples that are among the k nearest neighbors of Y with respect to at least one similarity measure ci. The anomaly score for Y is\nν = 1 |I| ∑\nj∈I\nUn(Zi), (3)\nand Y is declared an anomaly when ν is larger than a predefined threshold ρ > 0. We note that it is possible to allow different values of k for each criterion. The idea is that typical samples should be close to many of their nearest neighbors in one or many similarities, and thus the dyads Z1, . . . , ZN will lie on earlier Pareto fronts. An anomalous sample should be far from its nearest neighbors in many or all of the similarities, and the dyads will consequently fall on deeper fronts. The PDA anomaly detection algorithm has been validated on real and synthetic data in [19, 20] and has been shown to achieve state of the art results for integrating information from multiple similarities."
    }, {
      "heading" : "3 New PDE continuum limits",
      "text" : "The Hamilton-Jacobi Equation (HJE) continuum limit (1) gives information about which Pareto front a sample lies on. It is also important in applications to know where a sample lies within its Pareto front, as this gives information about the trade-off between the multiple objectives. We present here some new PDE continuum limits for ordering of points within Pareto fronts in dimension two, and we present fast sweeping numerical schemes for solving the PDE.\nSuppose d = 2 and let Sn = {X1, . . . ,Xn} be a sequence of i.i.d. random variables with continuous density f on (0, 1)2. Apply nondominated sorting to Sn and then order the points within each Pareto front by x1-coordinate. This defines a function Vn : Sn → N given by\nVn(Xi) := Index of Xi within its Pareto front. (4)\nFigure 2(a) gives an illustration of Vn. We give an argument in Section A of the appendix suggesting that\nn− 1 2Vn −→ v as n → ∞\nuniformly with probability one, where v : [0, 1]2 → R solves the linear transport equation\n∇v · ∇⊥u = f in (0, 1)2\nv = 0 on {x2 = 1},\n} (5)\nwhere ∇⊥u := (ux2 ,−ux1) and u is the viscosity solution of (1). Figure 2(b) illustrates this continuum limit. The transport equation (5) can be solved efficiently with the upwind scheme\nux2D − 1 vh − ux1D+2 vh = f in (0, 1)2h,\nvh(0, x2) = vh(x1, 1) = 0.\n} (6)\nwhere vh : [0, 1] 2 h → R is the numerical solution, h > 0 is the grid resolution, [0, 1]2h denotes the grid of spacing h on [0, 1]2, D±i v(x) := ±h−1(v(x ± hei) − v(x)), and e1 = (1, 0) and e2 = (0, 1). At each grid point, (6) is linear equation that is readily solved for vh(x) in terms of vh(x− he1) and vh(x+ he2). The numerical solution vh is computed by sweeping the grid (0, 1)2h exactly once in the upwind direction (1,−1).\nSince each Pareto front has in general a different number of points, the values of Vn within different fronts are difficult to compare. Therefore it is natural to consider the following normalization:\nWn(Xi) := Vn(Xi)\n#F(Xi) , (7)\nwhere F(Xi) denotes the Pareto front that Xi belongs to. The quantity Wn(Xi) is an index between 0 and 1 that gives information about where the point Xi falls within its Pareto front. We give an argument in Section A of the appendix showing that Wn → w where w solves\nv∇w · ∇⊥u = wf in (0, 1)2\nw = 1 on {x1 = 1}.\n} (8)\nFigure 2(c) illustrates this continuum limit. We solve (8) with an upwind scheme in the opposite direction:\nvhux2D + 1 wh − vhux1D−2 wh = whf in (0, 1)2h,\nwh(1, x2) = wh(x1, 0) = 1.\n} (9)\nWe present a convergence analysis for these new continuum limits in Section A.1 of the appendix.\nA few remarks are in order. Each PDE involves the solution of the previous PDEs, so they must be solved in the order (1)-(5)-(8). We solve (1) numerically using the first order accurate scheme presented in [4], which also has linear complexity. The transport PDEs (5) and (8) are degenerate when ∇u = 0, which can only happen when f vanishes. To avoid this degeneracy, we numerically precondition the density by replacing f with f + h2."
    }, {
      "heading" : "4 Real-time anomaly detection",
      "text" : "We propose here a modification of the PDA multicriteria anomaly detection algorithm [20] to the setting of online streaming data. Suppose we have a stream of possibly nonstationary data {Yt}t∈N, and d measures of similarity c1, . . . , cd for comparing data samples. As before we suppose that 0 ≤ ci(·, ·) ≤ 1. In the streaming setting, we observe the data Yt sequentially and must determine whether Yt is an anomaly based only on the previous history {Ys : s < t}. Due to memory and computational constraints, it may not be feasible to use this entire history, especially when t is large. Therefore, we fix T ≥ 1 and consider the windowed history\nHt = {Ys : t− T ≤ s ≤ t− 1}. (10)\nWe use the history Ht as training data in order to determine whether Yt is an anomaly. Even without memory constraints, only the recent history Ht can be considered reliable when the data is nonstationary. As before, we define dyads\nXr,s = (c1(Yr, Ys), . . . , cd(Yr, Ys)) ∈ [0, 1]d\ncorresponding to every pair (Yr, Ys) of the data stream. If we use the PDA anomaly detection algorithm with exact nondominated sorting, then we would need to store in memory all of the n := ( T 2 ) = O(T 2) dyads corresponding to pairs from the history Ht. Since the addition of a single new sample can potentially affect the arrangement of all the Pareto fronts, retraining the model when new samples are acquired requires applying nondominated sorting to all O(T 2) dyads, which has complexity slightly worse than O(T 2) for memory and operations. This makes it impossible to update the model frequently in the streaming setting without considering some type of approximation to the sorting.\nUsing PDE-based ranking we can reduce this complexity to O(T ). We keep a running estimate of the marginal distribution of the dyads using the following kernel density estimator\nft(x) = 1\nnhd\n∑\nt−T≤r<s≤t−1\nK\n( x−Xr,s\nh\n) . (11)\nAlthough there are O(T 2) terms in the sum above, the density estimation ft(x) can be updated recursively in O(T ) time by writing ft(x) = ft−1(x) + gt(x) where\ngt(x) = 1\nnhd\nt−1∑\ns=t−T\nK ( x−Xs,t\nh\n) −K ( x−X(t−T−1),s\nh\n) .\nIn our experiments, we use a simple histogram estimator, which is a special case of (11). We then compute an approximation Ut of the Pareto depth function by solving the HJE (1) numerically using the estimated density ft. By Theorem 1 the continuum approximation of the anomaly score is\nνt = 1 |It| ∑\ns∈It\nUt(Xs,t), (12)\nwhere It ⊂ {t−T, . . . , t−1} denotes the indices of samples from the history Ht that are among the ki nearest neighbors of Yt with respect to ci for at least one i ∈ {1, . . . , d}. We declare Yt anomalous if νt is greater than a predefined threshold ρ. The steps above work in arbitrary dimension d ≥ 2.\nFor the anomaly classification, we specialize to the case of d = 2. If Yt is declared an anomaly, we then solve the transport equations (5) and (8) using the schemes (6) and (9), respectively, to obtain Wt := wh. We define the anomaly classification score\nµt = 1 |It| ∑\ns∈It\nWt(Xs,t), (13)\nand we declare Yt a c1-anomaly if µt > 0.5, and a c2-anomaly if µt < 0.5. Our algorithm is summarized in pseudocode below.\nAlgorithm 1 PDE-based online anomaly detection\n1: Given: ρ > 0 and T ∈ N 2: fT ← (11) {Initialize density} 3: for t = T + 1 → ∞ do 4: ft ← ft−1 + gt {Update density estimation} 5: Ut ←(1) {Solve HJE continuum limit} 6: νt ← (12) {Compute anomaly score} 7: if νt > ρ then 8: Declare Yt to be anomalous 9: Wt ← (9) {Solve transport equations}\n10: µt ← (13) {Compute anomaly class. score} 11: if µt > 0.5 then Yt is a c1-anomaly 12: if µt ≤ 0.5 then Yt is a c2-anomaly 13: end if\n14: end for\nThere are some obvious modifications we could make to improve the performance of the algorithm. First, the continuum limit PDE need not be solved at every iteration, and could instead be solved only periodically, or whenever the density estimation ft has substantially changed. Second, to keep track of a larger history without incurring additional costs, the\nhistory Ht could contain T elements equally (or randomly) spaced among the previous αT samples, where α ≫ 1. The algorithm would remain otherwise unchanged and the complexity of each iteration remains O(T ).\nSince the PDE-based anomaly detection algorithm is based on continuum approximations, it is natural to seek a quantification of the approximation error. If we assume the dyads are i.i.d. we can prove the following convergence rate.\nTheorem 2 (Convergence Rate). Let X1, . . . ,Xn be i.i.d. with a Lipschitz continuous probability density f : [0, 1]2 → [m,∞), where m > 0. For h > 0 let ûh denote the numerical solution of (1) obtained via estimating f with a histogram aligned to the grid of spacing h on [0, 1]2. Then there exist constants C1, C2 > 0 such that\nmax [0,1]2\nh\n|ûh − u| ≤ C1 √ h (14)\nholds with probability at least 1− exp(−C2nh5 − 2 log(h)), where u is the viscosity solution of (1).\nAs a remark, if we consider estimating f with a random subset of X1, . . . ,Xn of size k ≪ n, then the same bound (14) holds with probability 1 − exp(−C2kh5 − 2 log(h)). Theorem 2 extends easily to higher dimensions d ≥ 3. In this case the same convergence rate (14) holds with probability 1− exp(−C2nh2d+1 − d log(h)).\nProof of Theorem 2. Let X1, . . . ,Xn be independent and identically distributed random variables on [0, 1]2 with Lipschitz continuous density f : [0, 1]2 → [0,∞). Recall that f is assumed to be positive on [0, 1]2, i.e., there exists m > 0 such that f ≥ m. Let h := 1/K > 0 be the grid resolution for solving (1) numerically and for estimating the density f with a histogram estimator, where K ∈ N. For 1 ≤ i ≤ k and 1 ≤ j ≤ K let\nBij = [(i− 1)h, ih) × [(j − 1)h, jh)\ndenote the grid cell corresponding to (i, j), and let Nij denote the number of samples from X1, . . . ,Xn falling in Bij . Then Nij is a Binomial random variable with parameters n and\npij =\n∫\nBij\nf(x) dx.\nBy the Chernoff-Hoeffding bound (see, e.g., [11]) we have\nP (|Nij − ENij| ≥ t) ≤ exp (−2t2\nn\n) (15)\nfor all t ≥ 0. Let xij = (ih, jh) denote the grid points. The histogram estimation of f at grid point xij is given by\nf̂h(xij) := Nij\nn|Bij| = Nij nh2 .\nCombining this with (15) we have\nP (∣∣∣f̂h(xij)− Ef̂h(xij) ∣∣∣ ≥ t ) ≤ exp ( −2nh4t2 ) (16)\nSince Ef̂h(xij) = pij/h 2 we have\n∣∣∣f(xij)− Ef̂h(xij) ∣∣∣ = 1\nh2 ∣∣∣∣∣ ∫\nBij\nf(xij)− f(x) dx ∣∣∣∣∣ ≤ 1 h2 ∫\nBij\n|f(xij)− f(x)| dx ≤ Ch, (17)\ndue to the fact that f is Lipschitz. Here, C depends on the Lipschitz constant of f , which is defined by\nLip(f) = sup x 6=y |f(x)− f(y)| |x− y| .\nIt follows from (17) that\n|f(xij)− f̂h(xij)| ≤ ∣∣∣f̂h(xij)− Ef̂h(xij) ∣∣∣+ ∣∣∣f(xij)− Ef̂h(xij) ∣∣∣ ≤ ∣∣∣f̂h(xij)− Ef̂h(xij) ∣∣∣+ Ch.\nCombining this with (16) and the union bound, there exists C1 > 0 such that\nP ( ‖f̂h − f‖∞ ≥ λ ) ≤ exp ( −2nh4(λ−C1h)2 − 2 log(h) ) , (18)\nfor all λ > C1h, where ‖u− v‖∞ := max\nxij∈[0,1]2h\n|u(xij)− v(xij)|.\nLet uh and ûh denote the numerical solutions of (1) on the grid of spacing h > 0 computed with f and f̂h on the right hand side, respectively. Standard maximum principle arguments (see [4]) yield ‖ûh − uh‖∞ ≤ C‖f̂h − f‖∞, (19) where the constant C depends on the lower bound m > 0 on f . By [4, Theorem 1,2], there exists a constant C > 0 such that\n‖uh − u‖∞ ≤ C √ h.\nCombining this with (19) we have\n‖ûh − u‖∞ ≤ C2(‖f̂h − f‖∞ + √ h),\nfor some C2 > 0. By (18)\nP ( ‖ûh − uh‖∞ ≥ C2(λ+ √ h) ) ≤ exp ( −2nh4(λ− C1h)2 − 2 log(h) ) .\nSetting λ = C √ h for large enough C we have\nP ( ‖ûh − u‖∞ ≥ C3 √ h ) ≤ exp ( −C4nh5 − 2 log(h) ) ,\nfor all 0 < h ≤ 1."
    }, {
      "heading" : "5 Numerical results",
      "text" : "We present several experiments that provide numerical evidence supporting the above arguments and outlining the effectiveness of our algorithm. The first two experiments were performed using synthetic data from [19, 20]. The streaming experiments consist of 1500 total samples with a window history of T = 500. To underscore the adaptive nature of our algorithm, each of these experiments incurs a significant trend change in the middle of the stream. The third and final experiment was performed with a real pedestrian trajectory data set from a video surveillance problem.\nTo evaluate the performance of the streaming algorithm we use a Receiver Operating Characteristic (ROC) curve and its resulting Area Under the Curve (AUC). We consider how the AUC varies with time as the algorithm takes in points from a stream. When changing the trend in the simulated streams, we also accordingly change the data used to generate the ROC curves, thereby giving us an appropriate method to visualize the learning aspect of the algorithm. In each simulated data stream we evaluate both the anomaly detection and anomaly classification. The results presented below represent the average of 20 trials. All PDEs were solved on a 100 × 100 grid.\nIn each experiment, we compare our continuum limits against the exact sorting PDA algorithm from [19, 20] and we see little to no difference in anomaly detection performance. The PDE-approximations reduce the complexity by an order of magnitude—from O(T 2) to O(T ). To give an idea of the difference in CPU time, each trial in the experiments below takes 27 seconds to process with the PDE-approximations, compared to 413 seconds with exact sorting. If we increase the stream length and data history T by a factor of 3, the PDE-approximations take 160 seconds, while the exact sorting PDA algorithm takes over 9.3 hours."
    }, {
      "heading" : "5.1 Uniformly distributed data",
      "text" : "The first experiment conducted with synthetic data took i.i.d. uniform samples on [0, 1]2 to be nominal, and uniform samples from the region [1, 1.1]2 \\ [0, 1]2 to be anomalous. Halfway through the stream the nominal region was changed to the box [0, 2]2, and the corresponding anomalous region was changed to [0, 2.2]2\\[0, 2]2. The two similarity criteria were simply taken to be the component-wise differences |∆x1| and |∆x2|, respectively. The nearest neighbour\nparameters were chosen as k1 = 6, k2 = 7. At each time step in the simulated stream there was a 0.05 probability of drawing from the anomalous region.\nFigure 3(a) shows the resulting AUCs at each time step. As expected, one can see a significant drop in the AUC of the anomaly detection at the mid-point when the trend is changed. We observe a sharp recovery of the AUC of the anomaly detection once the training history Ht contains a significant number of samples from the new distribution. This illustrates how the algorithm can quickly and efficiently learn a new trend in the data."
    }, {
      "heading" : "5.2 Categorical data",
      "text" : "For the second experiment, we used the synthetic categorical data from [20]. Each sample consists of 2 groups of categorical data A1 and A2. Each group is comprised of 20 different attributes, where each attribute can assume a different number of values. The number of possible values for the jth attribute of the ith group, denoted ni,j, is chosen uniformly at random between 6 and 10. Each attribute is then assigned a categorical distribution with parameters p1, . . . , pni,j which are in turn drawn from a Dirichlet distribution with parameters α1, . . . , αni,j .\nThe nominal distribution is characterized by setting α1 = 5 and αk = 1 for every k 6= 1 for every attribute. For the anomalous distribution we set αk = 1 for every k. Halfway through the stream the nominal distributions were changed so that for every attribute, the parameters of the categorical distribution were drawn from a Dirichlet distribution with parameters α2 = 5 and αk = 1 for every k 6= 2. To generate a nominal sample, we draw from the nominal distribution for each group. To generate an anomalous sample, we randomly choose a group with probability 0.5 and draw from the anomalous distribution for that group, and nominal distribution for the other. At each time step in the stream there was a 0.05 probability of drawing an anomalous sample.\nThe similarity between samples was computed between respective groups using the Inverse Occurrence Frequency (IOF) measure presented in [3]. The Goodall2 and Overlap metrics gave similar performance. The nearest neighbour parameters were chosen as k1 = k2 = 10. Figure 3(b) shows the resulting AUCs at each time step. Similar to the previous experiment we observe a drop in the AUC of the anomaly detection and a recovery thereafter. We also observe a similar drop in anomaly classification, as the new criteria anomalies are anomalous\nin both criteria for the old trend."
    }, {
      "heading" : "5.3 Pedestrian trajectories",
      "text" : "Our third experiment consisted of data from a real pedestrian trajectory data set [25], with over 100,000 trajectories. The first similarity criterion used to compare trajectories was their difference in shape, given by the ℓ2-distance between interpolated trajectories. The second was their difference in walking speed, given by the ℓ2-distance between the velocity histograms of each trajectory.\nAs a preliminary experiment, we tested the anomaly detection and anomaly classification on 1666 trajectories from a single day. These trajectories were hand-labelled as normal or anomalous by [20]. In each experiment the training set consisted of 500 trajectories randomly drawn from a total of 1666 trajectories that day. The mean AUCs of the PDE-based and exact sorting based algorithms were 0.9274± 0.0085 and 0.9363± 0.0072, respectively and the ROC curves are shown in Figure 4(a). We observe very little difference between the exact sorting and the PDE-approximations. We cannot present quantitative results for anomaly classification in this setting as there is no ground truth labeled data available. Along with some normal trajectories, we also plotted some anomalous trajectories with their respective classification scores in Figure 4(b,c).\nFinally, we applied the PDE-based streaming anomaly detection algorithm to a large portion of the pedestrian dataset, spanning over several days of data. Figure 3(c) shows the AUC as a function of artificial time for a simulated stream consisting of 15,000 trajectories with an initial training set of 400 randomly drawn trajectories. The small labeled portion of the dataset (approx. 1000 trajectories) was used to generate the ROC curves."
    }, {
      "heading" : "6 Conclusion",
      "text" : "In this paper, we showed how to use some recently discovered PDE continuum limits for nondominated sorting to perform anomaly detection and classification in real-time in a streaming setting. The classification is performed using new PDE continuum limits for ordering within the nondominated layers. We proved convergence rates for the continuum approximations and presented the results of numerical experiments with synthetic and real data that show our algorithm can adapt quickly and efficiently to a changing data stream. Although we focused in this paper on the anomaly detection problem, the ideas are not restricted to this context. Indeed, nondominated sorting is widely used in multiobjective optimization, and the ideas in this paper potentially apply to any such application, leaving many interesting problems for future work."
    }, {
      "heading" : "A Derivation of new continuum limits",
      "text" : "We give here derivations of the new PDE continuum limits presented in Section 3. For ease of reference, we recall some of the definitions from the main paper here.\nSuppose d = 2 and let Sn = {X1, . . . ,Xn} be a sequence of i.i.d. random variables with continuous density f on (0, 1)2. Apply nondominated sorting to Sn and then order the points\nwithin each Pareto front by x1-coordinate. This defines a function Vn : Sn → N given by\nVn(Xi) := Index of Xi within its Pareto front. (20)\nBy the continuum limit of nondominated sorting (Theorem 1), there are on the order of n 1 2 Pareto fronts. Since there are n points in total, is is reasonable to conjecture that each front has on the order of n 1 2 points. Therefore, we need to normalize Vn by n 1 2 , and suppose that\nn− 1 2Vn −→ v as n → ∞\nuniformly with probability one, where v : [0, 1]2 → R is continuously differentiable. Fix a large value of n and consider a point x ∈ (0, 1)2. Fix ε > 0 and let\ny = x+ ε∇⊥u(x),\nwhere ∇⊥u = (ux2 ,−ux1). Since ∇⊥u is tangent to the level set {u = u(x)}, we have u(y) ≈ u(x), i.e., x and y are roughly on the same Pareto front. See Figure 5 for an illustration. Let A denote the rectangle whose diagonal is the line segment from x to y, and let Ln denote the number of points on the Pareto front passing through x and y that fall within A. Then we have\nε∇v(x) · ∇⊥u(x) ≈ v(y)− v(x) ≈ n− 12 (Vn(y)− Vn(x)) = n− 1 2Ln. (21)\nHere, ∇v = (vx1 , vx2) denotes the gradient of v. When ε > 0 is small, the random variables within A are approximately uniformly distributed within A. Furthermore, as illustrated in Figure 5, we can scale A to the unit box [0, 1]2 without changing the partial ordering within A. Hence, it is reasonable to conjecture that Ln ∼ c √ m, where c > 0 is a universal constant and m is the number of samples falling in A. While the value of c is not needed for sorting (since we perform a normalization in (23) below), a simple scaling argument that we omit suggests that c = 1, so we will take Ln ∼ √ m. By the law of large numbers\nm ∼ n ∫\nA\nf dx ≈ n|A|f(x) = nε2ux1ux2f(x),\nsince the side lengths of A are |x1 − y1| = εux2 and |x2 − y2| = ux1 . Combining this with ux1ux2 = f , (21) and Ln ∼ √ m yields\nε∇v(x) · ∇⊥u(x) ≈ f(x)ε. Hence this simple heuristic argument suggests that v satisfies the linear transport PDE\n∇v · ∇⊥u = f in (0, 1)2\nv = 0 on {x2 = 1}.\n} (22)\nSince each Pareto front has in general a different number of points, the values of Vn within different fronts are difficult to compare. Therefore it is natural to consider the following normalization:\nWn(Xi) := Vn(Xi)\n#F(Xi) , (23)\nwhere F(Xi) denotes the Pareto front that Xi belongs to. The quantity Wn(Xi) is an index between 0 and 1 that gives information about where the point Xi falls within its Pareto front.\nThe heuristics above suggest that Wn → w uniformly with probability one, where\nw(x) = v(x)\nv(1, ψ(u(x)) , (24)\nand ψ is the inverse of x2 7→ u(1, x2). In other words, we are normalizing v(x) by the asymptotic number of points on the front to which x belongs.\nThe expression in (24) is difficult to work with numerically. We will instead derive a PDE for w. Differentiating (24) yields\nv∇w = w∇v − w2vx2ψ′(u)∇u. Take the dot product of both sides with ∇⊥u and recall (22) to find that\nv∇w · ∇⊥u = w∇v · ∇⊥u = wf. Since w = 1 on {x1 = 1}, w can be characterized as the solution of the following transport PDE\nv∇w · ∇⊥u = wf in (0, 1)2\nw = 1 on {x1 = 1}.\n} (25)\nOn a slightly more technical note, since u is not necessarily differentiable the velocity ∇⊥u in the transport equations (5) and (25) is not well-defined. To make sense of these PDE rigorously, we can instead write them in divergence form, since\n−div(u∇⊥v) = ∇v · ∇⊥u. It is possible to prove existence and uniqueness of weak solutions of (5) and (25) in the Sobolev space H1. Such results are outside the scope of this paper, and we intend to pursue them in a future work.\nWe also note the case of dimension d ≥ 3 is considerably more complicated, since there is no canonical linear ordering of the points within each front. If we instead consider ordering the points within fronts via nondominated sorting with respect to different partial orders, it is possible to derive similar continuum limits. However the PDE are highly nonlinear and the analysis is significantly more difficult. We leave these considerations to future work.\nA.1 Convergence analysis\nThe derivations of the transport equations (5) and (8) are heuristic in nature. Establishing these continuum limits rigorously is an important and challenging PDE problem that we plan to pursue in the future. In the meantime, we present here a convergence analysis for the continuum limits (5) and (8) in the case that f ≡ 1, i.e., the samples are independent and uniformly distributed on the unit box [0, 1]2. In this case we can solve all three PDEs (1), (5), and (8) in closed form. We have\nu(x) = 2 √ x1x2, v(x) = − √ x1x2 log(x2), and w(x) =\nlog(x2)\nlog(x1) + log(x2) .\nWe performed a convergence analysis by drawing X1, . . . ,Xn independent and uniformly distributed on [0, 1]2 and computing Vn and Wn according to their definitions (20) and (23), respectively. We measured the discrepancy with the continuum limits in the ℓ1 and ℓ∞ norms, computed by\n‖v − n− 12Vn‖ℓ1 := 1\nn\nn∑\ni=1\n|v(Xi)− n− 1 2Vn(Xi)|.\nand ‖v − n− 12Vn‖ℓ∞ := max\n1≤i≤n |v(Xi)− n−\n1 2Vn(Xi)|,\nrespectively. The definitions of ‖w −Wn‖ℓ∞ and ‖w −Wn‖ℓ1 are similar. Figure 6 shows the errors for a single realization and various values of n ranging from n = 102 to n = 108.\nEach of the errors is observed to be converging to zero at a rate of O(n−α) where α ≈ 0.25, except for ‖w−Wn‖ℓ∞ . Upon closer inspection, the function w(x) = log(x2)/(log(x1)+log(x2)) is discontinuous at x = (1, 1), hence uniform convergence is impossible. This discontinuity reflects the fact that near x = (1, 1) the Pareto fronts cut off an infinitesimal portion of the top corner of the box, and hence Wn transitions from 0 to 1 over an infinitesimally short distance."
    } ],
    "references" : [ {
      "title" : "Optimal control and viscosity solutions of Hamilton-Jacobi- Bellman equations",
      "author" : [ "M. Bardi", "I. Dolcetta" ],
      "venue" : "Springer,",
      "citeRegEx" : "1",
      "shortCiteRegEx" : null,
      "year" : 1997
    }, {
      "title" : "The longest chain among random points in Euclidean space",
      "author" : [ "B. Bollobás", "P. Winkler" ],
      "venue" : "Proceedings of the American Mathematical Society, 103(2):347–353,",
      "citeRegEx" : "2",
      "shortCiteRegEx" : null,
      "year" : 1988
    }, {
      "title" : "Similarity measures for categorical data: A comparative evaluation",
      "author" : [ "L. Boriah", "V. Chandola", "V. Kumar" ],
      "venue" : "red, 30(2):3,",
      "citeRegEx" : "3",
      "shortCiteRegEx" : null,
      "year" : 2008
    }, {
      "title" : "Numerical schemes and rates of convergence for the Hamilton-Jacobi equation continuum limit of nondominated sorting",
      "author" : [ "J. Calder" ],
      "venue" : "arXiv preprint:1508.01557,",
      "citeRegEx" : "4",
      "shortCiteRegEx" : null,
      "year" : 2015
    }, {
      "title" : "A Hamilton-Jacobi equation for the continuum limit of non-dominated sorting",
      "author" : [ "J. Calder", "S. Esedoḡlu", "A.O. Hero" ],
      "venue" : "SIAM Journal on Mathematical Analysis, 46(1):603–638,",
      "citeRegEx" : "5",
      "shortCiteRegEx" : null,
      "year" : 2014
    }, {
      "title" : "A PDE-based approach to non-dominated sorting",
      "author" : [ "J. Calder", "S. Esedoḡlu", "A.O. Hero" ],
      "venue" : "SIAM Journal on Numerical Analysis, 53(1):82–104,",
      "citeRegEx" : "6",
      "shortCiteRegEx" : null,
      "year" : 2015
    }, {
      "title" : "Pareto Sort",
      "author" : [ "Y. Cao" ],
      "venue" : "[Online]. Available: http://www.mathworks.com/matlabcentral/fileexchange/17251,",
      "citeRegEx" : "7",
      "shortCiteRegEx" : null,
      "year" : 2007
    }, {
      "title" : "Anomaly detection: A survey",
      "author" : [ "V. Chandola", "A. Banerjee", "V. Kumar" ],
      "venue" : "ACM Computing Surveys (CSUR), 41(3):15,",
      "citeRegEx" : "8",
      "shortCiteRegEx" : null,
      "year" : 2009
    }, {
      "title" : "The pareto envelope-based selection algorithm for multiobjective optimization",
      "author" : [ "D.W. Corne", "J.D. Knowles", "M.J. Oates" ],
      "venue" : "Parallel Problem Solving from Nature PPSN VI, pages 839–848. Springer,",
      "citeRegEx" : "9",
      "shortCiteRegEx" : null,
      "year" : 2000
    }, {
      "title" : "A fast and elitist multiobjective genetic algorithm: NSGA-II",
      "author" : [ "K. Deb", "A. Pratap", "S. Agarwal", "T. Meyarivan" ],
      "venue" : "IEEE Transactions on Evolutionary Computation, 6(2):182–197,",
      "citeRegEx" : "10",
      "shortCiteRegEx" : null,
      "year" : 2002
    }, {
      "title" : "Concentration of measure for the analysis of randomized algorithms",
      "author" : [ "D.P. Dubhashi", "A. Panconesi" ],
      "venue" : "Cambridge University Press,",
      "citeRegEx" : "11",
      "shortCiteRegEx" : null,
      "year" : 2009
    }, {
      "title" : "An efficient non-dominated sorting method for evolutionary algorithms",
      "author" : [ "H. Fang", "Q. Wang", "Y.-C. Tu", "M.F. Horstemeyer" ],
      "venue" : "Evolutionary computation, 16(3):355–384,",
      "citeRegEx" : "12",
      "shortCiteRegEx" : null,
      "year" : 2008
    }, {
      "title" : "Maximum k-chains in planar point sets: combinatorial structure and algorithms",
      "author" : [ "S. Felsner", "L. Wernisch" ],
      "venue" : "SIAM Journal on Computing, 28(1):192–209,",
      "citeRegEx" : "13",
      "shortCiteRegEx" : null,
      "year" : 1999
    }, {
      "title" : "Generalizing the improved run-time complexity algorithm for non-dominated sorting",
      "author" : [ "F.-A. Fortin", "S. Grenier", "M. Parizeau" ],
      "venue" : "Proceeding of the fifteenth annual conference on Genetic and evolutionary computation conference, pages 615–622. ACM,",
      "citeRegEx" : "14",
      "shortCiteRegEx" : null,
      "year" : 2013
    }, {
      "title" : "Evolutionary algorithms for multi-criterion optimization: a survey",
      "author" : [ "A. Ghosh", "S. Dehuri" ],
      "venue" : "International Journal of Computing & Information Sciences, 2(1):38–57,",
      "citeRegEx" : "15",
      "shortCiteRegEx" : null,
      "year" : 2004
    }, {
      "title" : "Posterior Pareto front analysis for gene filtering",
      "author" : [ "A. Hero", "G. Fleury" ],
      "venue" : "Proceedings of the Workshop on Genomic Signal Processing and Statistics (GENSIPS),",
      "citeRegEx" : "16",
      "shortCiteRegEx" : null,
      "year" : 2002
    }, {
      "title" : "A survey of outlier detection methodologies",
      "author" : [ "V.J. Hodge", "J. Austin" ],
      "venue" : "Artificial Intelligence Review, 22(2):85–126,",
      "citeRegEx" : "17",
      "shortCiteRegEx" : null,
      "year" : 2004
    }, {
      "title" : "Pareto-depth for multiple-query image retrieval",
      "author" : [ "K.-J. Hsiao", "J. Calder", "A.O. Hero" ],
      "venue" : "IEEE Transactions on Image Processing, 24(2):583–594,",
      "citeRegEx" : "18",
      "shortCiteRegEx" : null,
      "year" : 2015
    }, {
      "title" : "Multi-criteria anomaly detection using Pareto Depth Analysis",
      "author" : [ "K.-J. Hsiao", "K. Xu", "J. Calder", "A. Hero" ],
      "venue" : "Advances in Neural Information Processing Systems 25, pages 854–862.",
      "citeRegEx" : "19",
      "shortCiteRegEx" : null,
      "year" : 2012
    }, {
      "title" : "Multi-criteria similarity-based anomaly detection using Pareto Depth Analysis",
      "author" : [ "K.-J. Hsiao", "K. Xu", "J. Calder", "A. Hero" ],
      "venue" : "IEEE Transactions on Neural Networks and Learning Systems,",
      "citeRegEx" : "20",
      "shortCiteRegEx" : null,
      "year" : 2015
    }, {
      "title" : "Reducing the run-time complexity of multiobjective EAs: The NSGA-II and other algorithms",
      "author" : [ "M.T. Jensen" ],
      "venue" : "IEEE Transactions on Evolutionary Computation, 7(5):503–515,",
      "citeRegEx" : "21",
      "shortCiteRegEx" : null,
      "year" : 2003
    }, {
      "title" : "Shooting stars in the sky: an online algorithm for skyline queries",
      "author" : [ "D. Kossmann", "F. Ramsak", "S. Rost" ],
      "venue" : "In Proceedings of the 28th International Conference on Very Large Data Bases,",
      "citeRegEx" : "22",
      "shortCiteRegEx" : "22",
      "year" : 2002
    }, {
      "title" : "Multivariate analysis by data depth: descriptive statistics, graphics and inference",
      "author" : [ "R.Y. Liu", "J.M. Parelius", "K. Singh" ],
      "venue" : "The Annals of Statistics, 27(3):783–858,",
      "citeRegEx" : "23",
      "shortCiteRegEx" : null,
      "year" : 1999
    }, {
      "title" : "A variational problem for random Young tableaux",
      "author" : [ "B.F. Logan", "L.A. Shepp" ],
      "venue" : "Advances in Mathematics, 26(2):206–222,",
      "citeRegEx" : "24",
      "shortCiteRegEx" : null,
      "year" : 1977
    }, {
      "title" : "Statistical models of pedestrian behaviour in the forum",
      "author" : [ "B. Majecka" ],
      "venue" : "Master’s thesis, School of Informatics, University of Edinburgh,",
      "citeRegEx" : "25",
      "shortCiteRegEx" : null,
      "year" : 2009
    }, {
      "title" : "A fast nondominated sorting algorithm",
      "author" : [ "C. Shi", "M. Chen", "Z. Shi" ],
      "venue" : "Neural Networks and Brain, 2005. ICNN&B’05. International Conference on, volume 3, pages 1605–1610. IEEE,",
      "citeRegEx" : "26",
      "shortCiteRegEx" : null,
      "year" : 2005
    }, {
      "title" : "Muiltiobjective optimization using nondominated sorting in genetic algorithms",
      "author" : [ "N. Srinivas", "K. Deb" ],
      "venue" : "Evolutionary Computation, 2(3):221–248,",
      "citeRegEx" : "27",
      "shortCiteRegEx" : null,
      "year" : 1994
    }, {
      "title" : "Asymptotics of the Plancherel measure of the symmetric group and the limiting form of Young tables",
      "author" : [ "A. Vershik", "S. Kerov" ],
      "venue" : "Soviet Doklady Mathematics, 18(527-531):38,",
      "citeRegEx" : "28",
      "shortCiteRegEx" : null,
      "year" : 1977
    }, {
      "title" : "Spea2: Improving the strength pareto evolutionary algorithm",
      "author" : [ "E. Zitzler", "M. Laumanns", "L. Thiele" ],
      "venue" : null,
      "citeRegEx" : "29",
      "shortCiteRegEx" : "29",
      "year" : 2001
    }, {
      "title" : "Multiobjective evolutionary algorithms: a comparative case study and the strength pareto approach",
      "author" : [ "E. Zitzler", "L. Thiele" ],
      "venue" : "evolutionary computation, IEEE transactions on, 3(4):257–271,",
      "citeRegEx" : "30",
      "shortCiteRegEx" : null,
      "year" : 1999
    } ],
    "referenceMentions" : [ {
      "referenceID" : 22,
      "context" : "Since there is no canonical linear ordering for multivariate data, many different notions of ordering have been proposed in the literature [23], and the problem is very much application dependent.",
      "startOffset" : 139,
      "endOffset" : 143
    }, {
      "referenceID" : 21,
      "context" : "In the database community the Pareto-optimal solutions are called the skyline of the dataset [22].",
      "startOffset" : 93,
      "endOffset" : 97
    }, {
      "referenceID" : 26,
      "context" : "The notion of Pareto-optimality is widely used in evolutionary algorithms for multiobjective optimization [27], such as the Nondominated Sorting Genetic Algorithm (NSGA-II) [10], the Strength Pareto Evolutionary Algorithm (SPEA) [29, 30], and the Pareto envelope-based selection algorithm (PESA) [9], among many others (see [15] for a survey).",
      "startOffset" : 106,
      "endOffset" : 110
    }, {
      "referenceID" : 9,
      "context" : "The notion of Pareto-optimality is widely used in evolutionary algorithms for multiobjective optimization [27], such as the Nondominated Sorting Genetic Algorithm (NSGA-II) [10], the Strength Pareto Evolutionary Algorithm (SPEA) [29, 30], and the Pareto envelope-based selection algorithm (PESA) [9], among many others (see [15] for a survey).",
      "startOffset" : 173,
      "endOffset" : 177
    }, {
      "referenceID" : 28,
      "context" : "The notion of Pareto-optimality is widely used in evolutionary algorithms for multiobjective optimization [27], such as the Nondominated Sorting Genetic Algorithm (NSGA-II) [10], the Strength Pareto Evolutionary Algorithm (SPEA) [29, 30], and the Pareto envelope-based selection algorithm (PESA) [9], among many others (see [15] for a survey).",
      "startOffset" : 229,
      "endOffset" : 237
    }, {
      "referenceID" : 29,
      "context" : "The notion of Pareto-optimality is widely used in evolutionary algorithms for multiobjective optimization [27], such as the Nondominated Sorting Genetic Algorithm (NSGA-II) [10], the Strength Pareto Evolutionary Algorithm (SPEA) [29, 30], and the Pareto envelope-based selection algorithm (PESA) [9], among many others (see [15] for a survey).",
      "startOffset" : 229,
      "endOffset" : 237
    }, {
      "referenceID" : 8,
      "context" : "The notion of Pareto-optimality is widely used in evolutionary algorithms for multiobjective optimization [27], such as the Nondominated Sorting Genetic Algorithm (NSGA-II) [10], the Strength Pareto Evolutionary Algorithm (SPEA) [29, 30], and the Pareto envelope-based selection algorithm (PESA) [9], among many others (see [15] for a survey).",
      "startOffset" : 296,
      "endOffset" : 299
    }, {
      "referenceID" : 14,
      "context" : "The notion of Pareto-optimality is widely used in evolutionary algorithms for multiobjective optimization [27], such as the Nondominated Sorting Genetic Algorithm (NSGA-II) [10], the Strength Pareto Evolutionary Algorithm (SPEA) [29, 30], and the Pareto envelope-based selection algorithm (PESA) [9], among many others (see [15] for a survey).",
      "startOffset" : 324,
      "endOffset" : 328
    }, {
      "referenceID" : 15,
      "context" : "Nondominated sorting has also found applications in gene selection and ranking [16], anomaly detection [19, 20], and multiquery image retrieval [18].",
      "startOffset" : 79,
      "endOffset" : 83
    }, {
      "referenceID" : 18,
      "context" : "Nondominated sorting has also found applications in gene selection and ranking [16], anomaly detection [19, 20], and multiquery image retrieval [18].",
      "startOffset" : 103,
      "endOffset" : 111
    }, {
      "referenceID" : 19,
      "context" : "Nondominated sorting has also found applications in gene selection and ranking [16], anomaly detection [19, 20], and multiquery image retrieval [18].",
      "startOffset" : 103,
      "endOffset" : 111
    }, {
      "referenceID" : 17,
      "context" : "Nondominated sorting has also found applications in gene selection and ranking [16], anomaly detection [19, 20], and multiquery image retrieval [18].",
      "startOffset" : 144,
      "endOffset" : 148
    }, {
      "referenceID" : 1,
      "context" : "As it turns out, nondominated sorting is equivalent to the longest chain problem, which has a long history in combinatorics and probability [2].",
      "startOffset" : 140,
      "endOffset" : 143
    }, {
      "referenceID" : 9,
      "context" : "Due to the wide use of NSGA-II, there has been significant interest in fast algorithms for nondominated sorting [10, 21, 14].",
      "startOffset" : 112,
      "endOffset" : 124
    }, {
      "referenceID" : 20,
      "context" : "Due to the wide use of NSGA-II, there has been significant interest in fast algorithms for nondominated sorting [10, 21, 14].",
      "startOffset" : 112,
      "endOffset" : 124
    }, {
      "referenceID" : 13,
      "context" : "Due to the wide use of NSGA-II, there has been significant interest in fast algorithms for nondominated sorting [10, 21, 14].",
      "startOffset" : 112,
      "endOffset" : 124
    }, {
      "referenceID" : 4,
      "context" : "[5] established a continuum limit for nondominated sorting that corresponds to solving a Hamilton-Jacobi partial differential equation (HJE).",
      "startOffset" : 0,
      "endOffset" : 3
    }, {
      "referenceID" : 5,
      "context" : "[6] recently proposed a sublinear algorithm for approximate nondominated sorting called PDE-based ranking that is based on estimating the distribution of the data and solving the HJE numerically.",
      "startOffset" : 0,
      "endOffset" : 3
    }, {
      "referenceID" : 19,
      "context" : "To illustrate this in a concrete setting, we propose a new real-time version of the multicriteria PDA anomaly detection algorithm from [20] that uses PDE-based ranking in place of nondominated sorting.",
      "startOffset" : 135,
      "endOffset" : 139
    }, {
      "referenceID" : 4,
      "context" : "In Section 2 we review the continuum limit for nondominated sorting from [5], and present the PDA multicriteria anomaly detection algorithm from [20].",
      "startOffset" : 73,
      "endOffset" : 76
    }, {
      "referenceID" : 19,
      "context" : "In Section 2 we review the continuum limit for nondominated sorting from [5], and present the PDA multicriteria anomaly detection algorithm from [20].",
      "startOffset" : 145,
      "endOffset" : 149
    }, {
      "referenceID" : 0,
      "context" : ",Xn drawn from the uniform distribution on [0, 1]2.",
      "startOffset" : 43,
      "endOffset" : 49
    }, {
      "referenceID" : 9,
      "context" : "The original nondominated sorting algorithm proposed in [10] requires O(dn2) memory and operations.",
      "startOffset" : 56,
      "endOffset" : 60
    }, {
      "referenceID" : 20,
      "context" : "Jensen [21] proposed an algorithm with asymptotic complexity of O(n(log n)d−1) as n → ∞.",
      "startOffset" : 7,
      "endOffset" : 11
    }, {
      "referenceID" : 12,
      "context" : "The two dimensional version of Jensen’s algorithm was discovered independently in the combinatorics community by Felsner and Wernisch [13].",
      "startOffset" : 134,
      "endOffset" : 138
    }, {
      "referenceID" : 13,
      "context" : "[14] recently made some improvements to Jensen’s algorithm regarding its treatment of points with identical coordinates.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 19,
      "context" : "However, recent numerical results have suggested a better asymptotic complexity as d → ∞ with n fixed [20].",
      "startOffset" : 102,
      "endOffset" : 106
    }, {
      "referenceID" : 25,
      "context" : "See [26, 7, 12] for other notable approaches to nondominated sorting.",
      "startOffset" : 4,
      "endOffset" : 15
    }, {
      "referenceID" : 6,
      "context" : "See [26, 7, 12] for other notable approaches to nondominated sorting.",
      "startOffset" : 4,
      "endOffset" : 15
    }, {
      "referenceID" : 11,
      "context" : "See [26, 7, 12] for other notable approaches to nondominated sorting.",
      "startOffset" : 4,
      "endOffset" : 15
    }, {
      "referenceID" : 4,
      "context" : "[5] discovered a Hamilton-Jacobi equation continuum limit for nondominated sorting.",
      "startOffset" : 0,
      "endOffset" : 3
    }, {
      "referenceID" : 4,
      "context" : "The following continuum limit was established in [5].",
      "startOffset" : 49,
      "endOffset" : 52
    }, {
      "referenceID" : 0,
      "context" : "n 1 dUn −→ Cdu uniformly on [0, 1] as n → ∞",
      "startOffset" : 28,
      "endOffset" : 34
    }, {
      "referenceID" : 0,
      "context" : "where Cd > 0 is a constant depending only on d, and u : [0, 1] d → R is the unique nondecreasing viscosity solution of the Hamilton-Jacobi equation",
      "startOffset" : 56,
      "endOffset" : 62
    }, {
      "referenceID" : 23,
      "context" : "While the value of Cd is not needed for sorting, we should mention that it is known only in dimension d = 2, in which case C2 = 1 [24, 28].",
      "startOffset" : 130,
      "endOffset" : 138
    }, {
      "referenceID" : 27,
      "context" : "While the value of Cd is not needed for sorting, we should mention that it is known only in dimension d = 2, in which case C2 = 1 [24, 28].",
      "startOffset" : 130,
      "endOffset" : 138
    }, {
      "referenceID" : 5,
      "context" : "[6] proposed a fast algorithm for approximate nondominated sorting called PDE-based ranking that is based on estimating the density function f from a small subset of the data X1, .",
      "startOffset" : 0,
      "endOffset" : 3
    }, {
      "referenceID" : 4,
      "context" : "In this context, the viscosity solution is correct because it captures the continuum limit of the Pareto depth function [5].",
      "startOffset" : 120,
      "endOffset" : 123
    }, {
      "referenceID" : 4,
      "context" : "It is possible to prove that the viscosity solution u of (1) is Hölder continuous with exponent 1/d [5].",
      "startOffset" : 100,
      "endOffset" : 103
    }, {
      "referenceID" : 0,
      "context" : "For more details on viscosity solutions we refer the reader to [1].",
      "startOffset" : 63,
      "endOffset" : 66
    }, {
      "referenceID" : 19,
      "context" : "To illustrate the computational advantages of PDE-based ranking, we consider a concrete application of nondominated sorting to anomaly detection [20].",
      "startOffset" : 145,
      "endOffset" : 149
    }, {
      "referenceID" : 16,
      "context" : "It is an important and challenging problem with a wide array of applications, including computer intrusion detection, video surveillance, credit card fraud, and biometrics [17, 8].",
      "startOffset" : 172,
      "endOffset" : 179
    }, {
      "referenceID" : 7,
      "context" : "It is an important and challenging problem with a wide array of applications, including computer intrusion detection, video surveillance, credit card fraud, and biometrics [17, 8].",
      "startOffset" : 172,
      "endOffset" : 179
    }, {
      "referenceID" : 19,
      "context" : "Many anomaly detection algorithms rely on the availability of a measure of distance (or similarity) between data samples, and look for anomalies by finding samples that are far from their nearest neighbors (see [20] and references therein).",
      "startOffset" : 211,
      "endOffset" : 215
    }, {
      "referenceID" : 7,
      "context" : "Techniques used for feature-based algorithms include support vector machines (SVM), clustering, neural networks, and statistical approaches based on density estimation [8].",
      "startOffset" : 168,
      "endOffset" : 171
    }, {
      "referenceID" : 19,
      "context" : "[20] proposed an algorithm for multi-criteria anomaly detection that integrates the information from multiple similarity measures via nondominated sorting (or Pareto Depth Analysis (PDA)).",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 0,
      "context" : ", cd(Yi, Yj)) ∈ [0, 1], (2) and constructing the Pareto depth function Un by applying nondominated sorting to the n points {Xi,j}i,j=1.",
      "startOffset" : 16,
      "endOffset" : 22
    }, {
      "referenceID" : 18,
      "context" : "The PDA anomaly detection algorithm has been validated on real and synthetic data in [19, 20] and has been shown to achieve state of the art results for integrating information from multiple similarities.",
      "startOffset" : 85,
      "endOffset" : 93
    }, {
      "referenceID" : 19,
      "context" : "The PDA anomaly detection algorithm has been validated on real and synthetic data in [19, 20] and has been shown to achieve state of the art results for integrating information from multiple similarities.",
      "startOffset" : 85,
      "endOffset" : 93
    }, {
      "referenceID" : 0,
      "context" : "We give an argument in Section A of the appendix suggesting that n 1 2Vn −→ v as n → ∞ uniformly with probability one, where v : [0, 1]2 → R solves the linear transport equation ∇v · ∇u = f in (0, 1) v = 0 on {x2 = 1}, } (5)",
      "startOffset" : 129,
      "endOffset" : 135
    }, {
      "referenceID" : 0,
      "context" : "where vh : [0, 1] 2 h → R is the numerical solution, h > 0 is the grid resolution, [0, 1]h denotes the grid of spacing h on [0, 1]2, D i v(x) := ±h−1(v(x ± hei) − v(x)), and e1 = (1, 0) and e2 = (0, 1).",
      "startOffset" : 11,
      "endOffset" : 17
    }, {
      "referenceID" : 0,
      "context" : "where vh : [0, 1] 2 h → R is the numerical solution, h > 0 is the grid resolution, [0, 1]h denotes the grid of spacing h on [0, 1]2, D i v(x) := ±h−1(v(x ± hei) − v(x)), and e1 = (1, 0) and e2 = (0, 1).",
      "startOffset" : 83,
      "endOffset" : 89
    }, {
      "referenceID" : 0,
      "context" : "where vh : [0, 1] 2 h → R is the numerical solution, h > 0 is the grid resolution, [0, 1]h denotes the grid of spacing h on [0, 1]2, D i v(x) := ±h−1(v(x ± hei) − v(x)), and e1 = (1, 0) and e2 = (0, 1).",
      "startOffset" : 124,
      "endOffset" : 130
    }, {
      "referenceID" : 3,
      "context" : "We solve (1) numerically using the first order accurate scheme presented in [4], which also has linear complexity.",
      "startOffset" : 76,
      "endOffset" : 79
    }, {
      "referenceID" : 19,
      "context" : "We propose here a modification of the PDA multicriteria anomaly detection algorithm [20] to the setting of online streaming data.",
      "startOffset" : 84,
      "endOffset" : 88
    }, {
      "referenceID" : 0,
      "context" : ", cd(Yr, Ys)) ∈ [0, 1] corresponding to every pair (Yr, Ys) of the data stream.",
      "startOffset" : 16,
      "endOffset" : 22
    }, {
      "referenceID" : 0,
      "context" : "with a Lipschitz continuous probability density f : [0, 1]2 → [m,∞), where m > 0.",
      "startOffset" : 52,
      "endOffset" : 58
    }, {
      "referenceID" : 0,
      "context" : "For h > 0 let ûh denote the numerical solution of (1) obtained via estimating f with a histogram aligned to the grid of spacing h on [0, 1]2.",
      "startOffset" : 133,
      "endOffset" : 139
    }, {
      "referenceID" : 0,
      "context" : "max [0,1]2 h |ûh − u| ≤ C1 √ h (14)",
      "startOffset" : 4,
      "endOffset" : 9
    }, {
      "referenceID" : 0,
      "context" : ",Xn be independent and identically distributed random variables on [0, 1]2 with Lipschitz continuous density f : [0, 1]2 → [0,∞).",
      "startOffset" : 67,
      "endOffset" : 73
    }, {
      "referenceID" : 0,
      "context" : ",Xn be independent and identically distributed random variables on [0, 1]2 with Lipschitz continuous density f : [0, 1]2 → [0,∞).",
      "startOffset" : 113,
      "endOffset" : 119
    }, {
      "referenceID" : 0,
      "context" : "Recall that f is assumed to be positive on [0, 1]2, i.",
      "startOffset" : 43,
      "endOffset" : 49
    }, {
      "referenceID" : 10,
      "context" : ", [11]) we have",
      "startOffset" : 2,
      "endOffset" : 6
    }, {
      "referenceID" : 0,
      "context" : "for all λ > C1h, where ‖u− v‖∞ := max xij∈[0,1]h |u(xij)− v(xij)|.",
      "startOffset" : 42,
      "endOffset" : 47
    }, {
      "referenceID" : 3,
      "context" : "Standard maximum principle arguments (see [4]) yield ‖ûh − uh‖∞ ≤ C‖f̂h − f‖∞, (19) where the constant C depends on the lower bound m > 0 on f .",
      "startOffset" : 42,
      "endOffset" : 45
    }, {
      "referenceID" : 18,
      "context" : "The first two experiments were performed using synthetic data from [19, 20].",
      "startOffset" : 67,
      "endOffset" : 75
    }, {
      "referenceID" : 19,
      "context" : "The first two experiments were performed using synthetic data from [19, 20].",
      "startOffset" : 67,
      "endOffset" : 75
    }, {
      "referenceID" : 18,
      "context" : "In each experiment, we compare our continuum limits against the exact sorting PDA algorithm from [19, 20] and we see little to no difference in anomaly detection performance.",
      "startOffset" : 97,
      "endOffset" : 105
    }, {
      "referenceID" : 19,
      "context" : "In each experiment, we compare our continuum limits against the exact sorting PDA algorithm from [19, 20] and we see little to no difference in anomaly detection performance.",
      "startOffset" : 97,
      "endOffset" : 105
    }, {
      "referenceID" : 0,
      "context" : "uniform samples on [0, 1]2 to be nominal, and uniform samples from the region [1, 1.",
      "startOffset" : 19,
      "endOffset" : 25
    }, {
      "referenceID" : 0,
      "context" : "1]2 \\ [0, 1]2 to be anomalous.",
      "startOffset" : 6,
      "endOffset" : 12
    }, {
      "referenceID" : 1,
      "context" : "Halfway through the stream the nominal region was changed to the box [0, 2]2, and the corresponding anomalous region was changed to [0, 2.",
      "startOffset" : 69,
      "endOffset" : 75
    }, {
      "referenceID" : 1,
      "context" : "2]2\\[0, 2]2.",
      "startOffset" : 4,
      "endOffset" : 10
    }, {
      "referenceID" : 19,
      "context" : "For the second experiment, we used the synthetic categorical data from [20].",
      "startOffset" : 71,
      "endOffset" : 75
    }, {
      "referenceID" : 2,
      "context" : "The similarity between samples was computed between respective groups using the Inverse Occurrence Frequency (IOF) measure presented in [3].",
      "startOffset" : 136,
      "endOffset" : 139
    }, {
      "referenceID" : 24,
      "context" : "Our third experiment consisted of data from a real pedestrian trajectory data set [25], with over 100,000 trajectories.",
      "startOffset" : 82,
      "endOffset" : 86
    }, {
      "referenceID" : 19,
      "context" : "These trajectories were hand-labelled as normal or anomalous by [20].",
      "startOffset" : 64,
      "endOffset" : 68
    }, {
      "referenceID" : 0,
      "context" : "Therefore, we need to normalize Vn by n 1 2 , and suppose that n 1 2Vn −→ v as n → ∞ uniformly with probability one, where v : [0, 1]2 → R is continuously differentiable.",
      "startOffset" : 127,
      "endOffset" : 133
    }, {
      "referenceID" : 0,
      "context" : "Furthermore, as illustrated in Figure 5, we can scale A to the unit box [0, 1]2 without changing the partial ordering within A.",
      "startOffset" : 72,
      "endOffset" : 78
    }, {
      "referenceID" : 0,
      "context" : ", the samples are independent and uniformly distributed on the unit box [0, 1]2.",
      "startOffset" : 72,
      "endOffset" : 78
    }, {
      "referenceID" : 0,
      "context" : ",Xn independent and uniformly distributed on [0, 1]2 and computing Vn and Wn according to their definitions (20) and (23), respectively.",
      "startOffset" : 45,
      "endOffset" : 51
    } ],
    "year" : 2017,
    "abstractText" : "Nondominated sorting, or Pareto Depth Analysis (PDA), is widely used in multiobjective optimization and has recently found important applications in multi-criteria anomaly detection. We propose in this paper a fast real-time streaming version of the PDA algorithm for anomaly detection and classification that exploits the computational advantages of partial differential equation (PDE) continuum limits. We prove convergence rates for the continuum approximations and present the results of numerical experiments.",
    "creator" : "LaTeX with hyperref package"
  }
}