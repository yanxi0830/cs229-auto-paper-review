{
  "name" : "1406.4619.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "A Generalized Markov-Chain Modelling Approach to (1, λ)-ES Linear Optimization: Technical Report",
    "authors" : [ "Alexandre Chotard" ],
    "emails" : [ "alexandre.chotard@lri.fr", "martin@cs.cas.cz" ],
    "sections" : [ {
      "heading" : null,
      "text" : "ar X\niv :1\n40 6.\n46 19\nv1 [\ncs .N\nA ]\n1 8\nJu n\nKeywords: evolution strategies, continuous optimization, linear optimization, linear constraint, linear function, Markov chain models, Archimedean copulas"
    }, {
      "heading" : "1 Introduction",
      "text" : "Evolution Strategies (ES) are Derivative Free Optimization (DFO) methods, and as such are suited for the optimization of numerical problems in a black-box context, where the algorithm has no information on the function f it optimizes (e.g. existence of gradient) and can only query the function’s values. In such a context, it is natural to assume normality of the random steps, as the normal distribution has maximum entropy for given mean and variance, meaning that it is the most general assumption one can make without the use of additional information on f . However such additional information may be available, and then using normal steps may not be optimal. Cases where different distributions have been studied include so-called Fast Evolution Strategies [1] or SNES [2,3] which exploits the separability of f , or heavy-tail distributions on multimodal problems [4,3].\nIn several recent publications [5,6,7,8], attention has been paid to Markovchain modelling of linear optimization by a (1, λ)-ES, i.e. by an evolution strategy in which λ children are generated from a single parent X ∈ Rn by adding normally distributed n-dimensional random steps M ,\nX ←X + σC 1 2 M , where M ∼ N (0, In). (1)\nHere, σ is called step size, C is a covariance matrix, and N (0, In) denotes the ndimensional standard normal distribution with zero mean and covariance matrix identity. The best among the λ children, i.e. the one with the highest fitness, becomes the parent of the next generation, and the step-size σ and the covariance matrix C may then be adapted to increase the probability of sampling better children. In this paper we relax the normality assumption of the movement M to a more general distribution H .\nThe linear function models a situation where the step-size is relatively small compared to the distance towards a local optimum. This is a simple problem that must be solved by any effective evolution strategy by diverging with positive increments of ∇f.M . This unconstrained case was studied in [7] for normal steps with cumulative step-size adaptation (the step-size adaptation mechanism in CMA-ES [9]).\nLinear constraints naturally arise in real-world problems (e.g. need for positive values, box constraints) and also model a step-size relatively small compared to the curvature of the constraint. Many techniques to handle constraints in randomised algorithms have been proposed (see [10]). In this paper we focus on the resampling method, which consists in resampling any unfeasible candidate until a feasible one is sampled. We chose this method as it makes the algorithm easier to study, and is consistent with the previous studies assuming normal steps [11,5,6,8], studying constant step-size, self adaptation and cumulative step-size adaptation mechanisms (with fixed covariance matrix).\nOur aim is to study the (1, λ)-ES with constant step-size, constant covariance matrix and random steps with a general absolutely continuous distribution H optimizing a linear function under a linear constraint handled through resampling. We want to extend the results obtained in [5,8] using the theory of Markov chains. It is our hope that such results will help in designing new algorithms using information on the objective function to make non-normal steps. We pay a special attention to distributions with Archimedean copulas, which are a particularly well transparent alternative to the normal distribution. Such distributions have been recently considered in the Estimation of Distribution Algorithms [12,13], continuing the trend of using copulas in that kind of evolutionary optimization algorithms [14].\nIn the next section, the basic setting for modelling the considered evolutionary optimization task is formally defined. In Section 3, the distributions of the feasible steps and of the selected steps are linked to the distribution of the random steps, and another way to sample them is provided. In Section 4, it is shown that, under some conditions on the distribution of the random steps, the normalized distance to the constraint is a ergodic Markov chain, and a law of large numbers for Markov chains is applied. Finally, Section 5 gives properties\non the distribution of the random steps under which some of the aforementioned conditions are verified.\nNotations\nFor (a, b) ∈ N2 with a < b, [a..b] denotes the set of integers i such that a ≤ i ≤ b. For X and Y two random vectors, X (d) = Y denotes that these variables are equal in distribution, X a.s.→ Y and X P→ Y denote, respectively, almost sure convergence and convergence in probability. For (x,y) ∈ Rn, x.y denotes the scalar product between the vectors x and y, and for i ∈ [1..n], [x]i denotes the ith coordinate of x. For A a subset of Rn, 1A denotes the indicator function of A. For X a topological set, B(X ) denotes the Borel algebra on X ."
    }, {
      "heading" : "2 Problem setting and algorithm definition",
      "text" : "Throughout this paper, we study a (1, λ)-ES optimizing a linear function f : R\nn → R where λ ≥ 2 and n ≥ 2, with a linear constraint g : Rn → R, handling the constraint by resampling unfeasible solutions until a feasible solution is sampled.\nTake (ek)k∈[1..n] a orthonormal basis of R n. We may assume ∇f to be normalized as the behaviour of an ES is invariant to the composition of the objective function by a strictly increasing function (e.g. h : x 7→ x/‖∇f‖), and the same holds for∇g since our constraint handling method depends only on the inequality g(x) ≤ 0 which is invariant to the composition of g by a homothetic transformation. Hence w.l.o.g. we assume that ∇f = e1 and ∇g = cos θe1 + sin θe2 with the set of feasible solutions Xfeasible := {x ∈ Rn|g(x) ≤ 0}. We restrict our study to θ ∈ (0, π/2). Overall the problem reads\nmaximize f(x) = [x]1 subject to\ng(x) = [x]1 cos θ + [x]2 sin θ ≤ 0 . (2)\nAt iteration t ∈ N, from a so-called parent point Xt ∈ Xfeasible and with step-size σt ∈ R∗+ we sample new candidate solutions by adding to Xt a random vector σtM i,j t where M i,j t is called a random step and (M i,j t )i∈[1..λ],j∈N,t∈N is a i.i.d. sequence of random vectors with distribution H . The i index stands for the λ new samples to be generated, and the j index stands for the unbounded number of samples used by the resampling. We denote M it a feasible step, that is the first element of (M i,jt )j∈N such that Xt + σtM i t ∈ Xfeasible (random steps are sampled until a suitable candidate is found). The ith feasible solution Y it is then\nY it := Xt + σtM i t . (3)\nThen we denote ⋆ := argmaxi∈[1..λ] f(Y i t) the index of the feasible solution maximizing the function f , and update the parent point\nXt+1 := Y ⋆ t = Xt + σtM ⋆ t , (4)\nwhere M⋆t is called the selected step. Then the step-size σt, the distribution of the random steps H or other internal parameters may be adapted.\nFollowing [5,6,11,8] we define δt as\nδt := − g(Xt)\nσt . (5)"
    }, {
      "heading" : "3 Distribution of the feasible and selected steps",
      "text" : "In this section we link the distributions of the random vectors M it and M ⋆ t to the distribution of the random steps M i,jt , and give another way to sample M i t and M⋆t not requiring an unbounded number of samples.\nLemma 1. Let a (1, λ)-ES optimize the problem defined in (2) handling constraint through resampling. Take H the distribution of the random step M i,jt , and for δ ∈ R∗+ denote Lδ := {x ∈ Rn|g(x) ≤ δ}. Providing that H is absolutely continuous and that H(Lδ) > 0 for all δ ∈ R+, the distribution H̃δ of the feasible step and H̃⋆δ the distribution of the selected step when δt = δ are absolutely continuous, and denoting h, h̃δ and h̃ ⋆ δ the probability density functions of, respectively, the random step, the feasible step M it and the selected step M ⋆ t when δt = δ\nh̃δ(x) = h(x)1Lδ(x)\nH(Lδ) , (6)\nand\nh̃⋆δ(x) = λh̃δ(x)H̃δ((−∞, [x]1)× Rn−1)λ−1\n= λ h(x)1Lδ (x)H((−∞, [x]1)× Rn−1 ∩ Lδ)λ−1\nH(Lδ)λ . (7)\nProof. Let δ > 0, A ∈ B(Rn). Then for t ∈ N, i = 1 . . . λ, using the the fact that (M i,jt )j∈N is a i.i.d. sequence\nH̃δ(A) = Pr(M i t ∈ A|δt = δ)\n= ∑\nj∈N\nPr(M i,jt ∈ A ∩ Lδ and ∀k < j,M i,kt ∈ Lcδ|δt = δ)\n= ∑\nj∈N\nPr(M i,jt ∈ A ∩ Lδ|δt = δ) Pr(∀k < j,M i,kt ∈ Lcδ|δt = δ)\n= ∑\nj∈N\nH(A ∩ Lδ)(1 −H(Lδ))j\n= H(A ∩ Lδ) H(Lδ) = ∫\nA\nh(x)1Lδ (x)dx\nH(Lδ) ,\nwhich yield Eq. (6) and that H̃δ admits a density h̃δ and is therefore absolutely continuous.\nSince ((M i,jt )j∈N)i∈[1..λ] is i.i.d., (M i t)i∈[1..λ] is i.i.d. and\nH̃⋆δ (A) = Pr(M ⋆ t ∈ A|δt = δ)\n=\nλ ∑\ni=1\nPr(M it ∈ A and ∀j ∈ [1..λ]\\{i}, [M it]1 > [M jt ]1|δt = δ)\n= λPr(M1t ∈ A and ∀j ∈ [2..λ], [M1t ]1 > [M jt ]1|δt = δ)\n= λ\n∫\nA\nh̃δ(x) Pr(∀j ∈ [2..λ], [M jt ]1 < [x]1|δt = δ)dx\n=\n∫\nA\nλh̃δ(x)H̃δ((−∞, [x]1)× Rn−1)λ−1dx ,\nwhich shows that H̃⋆δ possess a density, and with (6) yield Eq. (7). ⊓⊔\nThe vectors (M it)i∈[1..λ] andM ⋆ t are functions of the vectors (M i,j t )i∈[1..λ],j∈N\nand of δt. In the following Lemma an equivalent way to sample M i t and M ⋆ t is given which uses a finite number of samples. This method is useful if one wants to avoid dealing with the infinite dimension space implied by the sequence (M i,jt )i∈[1..λ,j∈N.\nLemma 2. Let a (1, λ)-ES optimize problem (2), handling the constraint through resampling, and take δt as defined in (5). Let H denote the distribution of M i,j t that we assume absolutely continuous, ∇g⊥ := − sin θe1 + cos θe2, Q the rotation matrix of angle θ changing (e1, e2, . . . , en) into (∇g,∇g⊥, . . . , en). Take F1,δ(x) := Pr(M i t.∇g ≤ x|δt = δ), F2,δ(x) := Pr(M it.∇g⊥ ≤ x|δt = δ) and Fk,δ(x) := Pr([M i t]k ≤ x|δt = δ) for k ∈ [3..n], the marginal cumulative distribution functions when δt = δ, and Cδ the copula of (M i t.∇g,M it.∇g⊥, . . . ,M it.en).\nWe define\nG : (δ, (ui)i∈[1..n]) ∈ R+ × [0, 1]n 7→ Q\n\n  F−11,δ (u1) ...\nF−1n,δ (un)\n\n  , (8)\nG⋆ : (δ, (vi)i∈[1..λ]) ∈ R+ × [0, 1]nλ 7→ argmax G∈{G(δ,vi)|i∈[1..λ]} f(G) . (9)\nThen, if the copula Cδ is constant in regard to δ, for Wt = (V i,t)i∈[1..λ] a i.i.d. sequence with V i,t ∼ Cδ\nG(δt,V i,t) (d) = M it , (10)\nG⋆(δt,Wt) (d) = M⋆t . (11)\nProof. Since V i,t ∼ Cδ\n(M it.∇g,M it.∇g⊥, . . . ,M it.en) (d) = (F−11,δ (V 1,t), F −1 2,δ (V 2,t), . . . , F −1 n,δ (V n,t)) ,\nand if the function δ ∈ R+ 7→ Cδ is constant, then the sequence of random vectors (V i,t)i∈[1..λ],t∈N is i.i.d.. Finally by definitionQ −1M it = (M i t.∇g,M it.∇g⊥, . . . ,M it.en), which shows Eq. (10). Eq. (11) is a direct consequence of Eq. (10) and the fact that M⋆t = argmax\nG∈{G(δ,vi)|i∈[1..λ]}\nf(G) (which holds as f is linear). ⊓⊔\nWe may now use these results to show the divergence of the algorithm when the step-size is constant, using the theory of Markov chains [15].\n4 Divergence of the (1, λ)-ES with constant step-size\nFollowing the first part of [8], we restrict our attention to the constant step size in the remainder of the paper, that is for all t ∈ N we take σt = σ ∈ R∗+.\nFrom Eq. (4), by recurrence and dividing by t, we see that\n[Xt −X0]1 t = σ t\nt−1 ∑\ni=0\nM⋆i . (12)\nThe latter term suggests the use of a Law of Large Numbers to show the convergence of the LHS (Left Hand Side) to a constant that we call the divergence rate. The random vectors (M⋆t )t∈N are not i.i.d. so in order to apply a Law of Large Numbers on the RHS (Right Hand Side) of the previous equation we use Markov chain theory, more precisely the fact that (M⋆t )t∈N is a function of a (δt, (M i,j t )i∈[1..λ],j∈N)t∈N which is a geometrically ergodic Markov chain. As (M i,jt )i∈[1..λ],j∈N,t∈N is a i.i.d. sequence, it is a Markov chain, and the sequence (δt)t∈N is also a Markov chain as stated in the following proposition.\nProposition 1. Let a (1, λ)-ES with constant step-size optimize problem (2), handling the constraint through resampling, and take δt as defined in (5). Then no matter what distribution the i.i.d. sequence (M i,jt )i∈[1..λ],(j,t)∈N2 have, (δt)t∈N is a homogeneous Markov chain and\nδt+1 = δt − g(M⋆t ) = δt − cos θ[M⋆t ]1 − sin θ[M⋆t ]2 . (13)\nProof. By definition in (5) and since for all t, σt = σ,\nδt+1 = − g(Xt+1)\nσt+1\n= −g(Xt) + σg(M ⋆ t ) σ = δt − g(M⋆t ) ,\nand as shown in (7) the density of M⋆t is determined by δt. So the distribution of δt+1 is determined by δt, hence (δt)t∈N is a time-homogeneous Markov chain. ⊓⊔\nWe now show ergodicity of the Markov chain (δt)t∈N, which implies that the t-steps transition kernel (the function A 7→ Pr(δt ∈ A|δ0 = δ) for A ∈ B(R+)) converges towards a stationary measure π, generalizing Propositions 3 and 4 of [8].\nProposition 2. Let a (1, λ)-ES with constant step-size optimize problem (2), handling the constraint through resampling. We assume that the distribution of M\ni,j t is absolutely continuous with probability density function h, and that h is continuous and strictly positive on Rn. Denote µ+ the Lebesgue measure on (R+,B(R+)), and for α > 0 take the functions V : δ 7→ δ, Vα : δ 7→ exp(αδ) and r1 : δ 7→ 1. Then (δt)t∈N is µ+-irreducible, aperiodic and compact sets are small sets for the Markov chain.\nIf the following two additional conditions are fulfilled\nE(|g(M i,jt )| | δt = δ) < ∞ for all δ ∈ R+ , and (14)\nlim δ→+∞\nE(g(M⋆t )|δt = δ) ∈ R∗+ , (15)\nthen (δt)t∈N is r1-ergodic and positive Harris recurrent with some invariant measure π.\nFurthermore, if\nE(exp(g(M i,jt ))|δt = δ) < ∞ for all δ ∈ R+ , (16)\nthen for α > 0 small enough, (δt)t∈N is also Vα−geometrically ergodic.\nProof. The probability transition kernel of (δt)t∈N writes\nP (δ, A) =\n∫\nRn\n1A(δ − g(x))h̃⋆δ(x)dx\n=\n∫\nRn\n1A(δ − g(x))λ h(x)1Lδ (x)H((−∞, [x]1)× Rn−1 ∩ Lδ)λ−1\nH(Lδ)λ\n= λ\nH(Lδ)λ\n∫\ng−1(A)\nh\n\n   \nδ − [u]1 −[u]2\n... −[u]n\n\n    H((−∞, δ − [u]1)× Rn−1 ∩ Lδ)λ−1du ,\nwith the substitution of variables [u]1 = δ − [x]1 and [u]i = −[x]i for i ∈ [2..n]. Denote L⋆δ,v := (−∞, v) × Rn−1 ∩ Lδ and tδ : u 7→ (δ − [u]1,−[u]2, . . . ,−[u]n), take C a compact of R+, and define νC such that for A ∈ B(R+)\nνC(A) := λ\n∫\ng−1(A)\ninf δ∈C\nh(tδ(u))H(L ⋆ δ,[u]1 )λ−1\nH(Lδ)λ du .\nAs the density h is supposed to be strictly positive on Rn, for all δ ∈ R+ we have H(Lδ) ≥ H(L0) > 0. Using the fact that H is a finite measure, and is absolutely continuous, applying the dominated convergence theorem shows that the functions δ 7→ H(Lδ) and δ 7→ H((−∞, δ− [u]1)×Rn−1∩Lδ) are continuous. Therefore the function δ 7→ h(tδ(u))H(L⋆δ,[u]1) λ−1/H(Lδ) λ is continuous and C being a compact, the infimum of this function is reached on C is reached on C. Since this function is strictly positive, if g−1(A) has strictly positive Lebesgue measure then νC(A) > 0 which proves that this measure is not trivial. By construction P (δ, A) ≥ νC(A) for all δ ∈ C, so C is a small set which shows that compact sets are small. Since if µ+(A) > 0 we have P (δ, A) ≥ νC(A) > 0, the Markov chain (δt)t∈N is µ+-irreducible. Finally, if we take C a compact set of R+ with strictly positive Lebesgue measure, then it is a small set and νC(C) > 0 which means the Markov chain (δt)t∈N is strongly aperiodic.\nThe function ∆V is defined as δmapstoE(V (δt+1)|δt = δ) − V (δ). We want to show a drift condition (see [15]) on V . Using Eq. (13)\n∆V (δ) = E(δ − g(M⋆t )|δt = δ)− δ) = −E(g(M⋆t )) .\nTherefore using the condition (15), we have that there exists a ǫ > 0 and a M ∈ R+ such that ∀δ ∈ (M,+∞), ∆V (δ) ≤ −ǫ. With condtion (14) implies that the function ∆V + ǫ is bounded on the compact [0,M ] by a constant b ∈ R. Hence for all δ ∈ R+\n∆V (δ) ǫ ≤ −1 + b ǫ 1[0,M ](δ) . (17)\nFor all x ∈ R the level set CV,x of the function V , {y ∈ R+|V (y) ≤ x}, is equal to [0, x] which is a compact set, hence a small set according to what we proved\nearlier (and hence petite [15, Proposition 5.5.3]). Therefore V is unbounded off small sets and with (17) and Theorem 9.1.8 of [15], the Markov chain (δt)t∈N is Harris recurrent. The set [0,M ] is compact and therefore small and petite, so with (17), if we denote r1 the constant function δ ∈ R+ 7→ 1 then with Theorem 14.0.1 of [15] the Markov chain (δt)t∈N is positive and is r1-ergodic.\nWe now want to show a drift condition (see [15]) on Vα.\n∆Vα(δ) = E (exp (αδ − αg (M⋆t )) |δt = δ)− exp (αδ) ∆Vα Vα (δ) = E (exp (−αg (M⋆t )) |δt = δ)− 1\n=\n∫\nRn\nlim t→+∞\nt ∑\nk=0\n(−αg(x))k k! h̃⋆δ(x)dx− 1 .\nWith Eq. (7) we see that h̃⋆δ(x) ≤ λh(x)/H(L0)λ, so with our assumption that E(expα|g(M i,jt )||δt = δ) < ∞ for α > 0 small enough we have that the function δ 7→ E(exp(α|g(M⋆t )||δt = δ) is bounded for the same α. As ∑t\nk=0(−αg(x))k/k!h̃⋆δ(x) ≤ exp(α|g(x)|)h̃⋆δ(x) which, with condition (16), is integrable so we may apply the theorem of dominated convergence to invert limit and integral:\n∆Vα Vα (δ) = lim t→+∞\nt ∑\nk=0\n∫\nRn\n(−αg(x))k k! h̃⋆δ(x)dx− 1\n= ∑\nk∈N\n(−α)k E ( g (M⋆t ) k|δt = δ )\nk! − 1\nSince h̃⋆δ(x) ≤ λh(x)/H(L0)2, (−α)kE(g(M⋆t ) k|δt = δ)/k! ≤ (−α)kE(g(M i,jt ) k )/k! which is integrable with respect to the counting measure so we may apply the dominated convergence theorem with the counting measure to invert limit and serie.\nlim δ→+∞ ∆Vα Vα (δ) = ∑\nk∈N\nlim δ→+∞\n(−α)k E ( g (M⋆t ) k|δt = δ )\nk! − 1\n= −α lim δ→+∞ E (g (M⋆t ) |δt = δ) + o (α) .\nWith condition (17) we supposed that limδ→+∞E(g(M ⋆ t )|δt = δ) > 0 this implies that for α > 0 and small enough, limδ→+∞∆Vα(δ)/Vα(δ) < 0, hence there exists M ∈ R+ and epsilon > 0 such that ∀δ > M , ∆Vα(δ) < −ǫVα(δ). Finally as ∆Vα − Vα is bounded on [0,M ] there exists b ∈ R such that\n∆Vα(δ) ≤ −ǫVα(δ) + b1[0,M ](δ) .\nAccording to what we did before in this proof, the compact set [0,M ] is small, and hence is petite ([15, Proposition 5.5.3]). So the µ+-irreducible Markov chain\n(δt)t∈N satisfies the conditions of Theorem 15.0.1 of [15] which with Theorem 14.0.1 of [15] proves that the Markov chain (δt)t∈N is Vα-geometrically ergodic.\n⊓⊔\nWe now use a law of large numbers ([15] Theorem 17.0.1) on the Markov chain (δt, (M i,j t )i∈[1..λ],j∈N)t∈N to obtain an almost sure divergence of the algorithm.\nProposition 3. Let a (1, λ)-ES optimize problem (2), handling the constraint through resampling. Assume that the distribution H of the random step M i,jt is absolutely continuous with continuous and strictly positive density h, that conditions (16) and (15) of Proposition 2 hold, and denote π and µM the stationary distribution of respectively (δt)t∈N and (M i,j t )i∈[1..λ],(j,t)∈N2 . Then\n[Xt −X0]1 t a.s.−→ t→+∞ σEπ×µM ([M ⋆ t ]1) . (18)\nFurthermore if E([M⋆t ]2) < 0, then the right hand side of Eq. (18) is strictly positive.\nProof. According to Proposition 2 the sequence (δt)t∈N is a Harris recurrent positive Markov chain with invariant measure π. As (M i,jt )i∈[1..λ],(j,t)∈N2 is a i.i.d. sequence with distribution µM , (δt, (M i,j t )i∈[1..λ],j∈N)t∈N is also a Harris recurrent positive Markov chain. As [M⋆t ]1 is a function of δt and (M i,j t )i∈[1..λ],j∈N, if Eπ×µM (|[M⋆t ]1|) < ∞, according to Theorem 17.0.1 of [15], we may apply a law of large numbers on the right hand side of Eq. (12) to obtain (18).\nUsing Fubini-Tonelli’s theorem Eπ×µM (|[M⋆t ]1|) = Eπ(EµM (|[M⋆t ]1||δt = δ)). From Eq. (7) for all x ∈ Rn, h̃⋆δ(x) ≤ λh(x)/H(L0)2, so the condition in (16) implies that for all δ ∈ R+, EµM (|[M⋆t ]1||δt = δ) is finite. Furthermore, with condition (15), the function δ ∈ R+ 7→ EµM (|[M⋆t ]1||δt = δ) is bounded by some M ∈ R. Therefore as π is a probability measure, Eπ(EµM (|[M⋆t ]1||δt = δ)) ≤ M < ∞ so we may apply the law of large numbers of Theorem 17.0.1 of [15].\nUsing the fact that π is an invariant measure, we have Eπ(δt) = Eπ(δt+1), so Eπ(δt) = Eπ(δt − σg(M⋆t )) and hence cos θEπ([M⋆t ]1) = − sin θEπ([M⋆t ]2). So using the assumption that E([M i,jt ]2) ≤ 0 then we get the strict positivity of Eπ×µM ([M i,j t ]1). ⊓⊔"
    }, {
      "heading" : "5 Application to More Specific Distributions",
      "text" : "Throughout this section we give cases where the assumptions on the distribution of the random steps H used in Proposition 2 or Proposition 3 are verified.\nThe following lemma shows an equivalence between a non-identity covariance matrix for H and a different norm and constraint angle θ.\nLemma 3. Let a (1, λ)-ES optimize problem (2), handling the constraint with resampling. Assume that the distribution H of the random step M i,jt has positive definite covariance matrix C with eigenvalues (α2i )i∈[1..n] and take B =\n(bi,j)(i,j)∈[1..n]2 such that BCB −1 is diagonal. Denote AH,g,X0 the sequence of parent points (Xt)t∈N of the algorithm with distribution H for the random steps M\ni,j t , constraint angle θ and initial parent X0. Then for all k ∈ [1..n]\nβk [AH,θ,X0 ]k (d) =\n[\nAC−1/2H,θ′,X′ 0\n]\nk , (19)\nwhere βk =\n√\n∑n j=1 b2j,i α2i , θ′ = arccos(β1cosθβg ) with βg = √ β21 cos 2 θ + β22 sin 2 θ,\nand [X ′0]k = βk[X0]k for all k ∈ [1..n].\nProof. Take (ēk)k∈[1..n] the image of (ek)k∈[1..n] by B −1. We define a new norm ‖ · ‖− such that ‖ēk‖− = 1/αk. We define two orthonormal basis (e′k)k∈[1..n] and (ē′k)k∈[1..n] for (R\nn, ‖·‖−) by taking e′k = ek/‖ek‖− and ē′k = ēk/‖ēk‖− = αkēk. As Var(M i,jt .ēk) = α 2 k, Var(M i,j t .ē ′ k) = 1 so in (R\nn, ‖·‖−) the covariance matrix of M i,jt is the identity.\nTake h the function that to x ∈ Rn maps its image in the new orthonormal basis (e′k)k∈[1..n]. As e ′ k = ek/‖ek‖−, h(x) = (‖ek‖−[x]k)k∈[1..n], where ‖ek‖− = ‖ ∑n i=1 bi,kēk‖− = √ ∑n i=1 b 2 i,k/α 2 k = βk. As we changed the norm, the angle between ∇f and ∇g is also different in the new space. Indeed cos θ′ = h(∇g).h(∇f)/(‖h(∇g)‖−‖h(∇f)‖−) = β21 cos θ/( √ β21 cos 2 θ + β22 sin 2 θβ1) = β1 cos θ/βg.\nIf we take N i,jt ∼ C−1/2H then it has the same distribution as h(M i,jt ). Take X ′t = h(Xt) then for a constraint angle θ\n′ = arccos(β1 cos θ/βg) and a normalized distance to the constraint δt = X ′ t.h(∇g)/σt the ressampling is the same for N i,jt and h(M i,j t ) so N i t (d) = h(M it). Finally the rankings induced by ∇f or h(∇f) are the same so the selection in the same, hence N⋆t (d) = h(M⋆t ), and therefore X ′t+1 (d) = h(Xt+1). ⊓⊔\nAlthough Eq. (18) shows divergence of the algorithm, it is important that it diverges in the right direction, i.e. that the right hand side of Eq. (18) has a positive sign. This is achieved when the distribution of the random steps is isotropic, as stated in the following proposition.\nProposition 4. Let a (1, λ)-ES optimize problem (2) with constant step-size, handling the constraint with resampling. Suppose that the Markov chain (δt)t∈N is positive Harris, that the distribution H of the random step M i,jt is absolutely continuous with strictly positive density h, and take C its covariance matrix. If the distribution C−1/2H is isotropic then Eπ×µM ([M ⋆ t ]1) > 0.\nProof. First if C = In, using the same method than in the proof of Lemma 1\nh⋆δ,2(y) = λ\n∫\nR\n. . .\n∫\nR\nh̃δ(u1, y, u3, . . . , un) Pr(u1 ≥ [M it]1)λ−1du1 n ∏\nk=3\nduk .\nUsing Eq.(6) and the fact that the condition x ∈ Lδ is equivalent to [x]1 ≤ (δ − [x]2 sin θ)/ cos θ we obtain\nh⋆δ,2(y) = λ\n∫\nR\n. . .\n∫ δ−y sin θ\ncos θ\n−∞\nh(u1, y, u3, . . . , un)\nH(Lδ) Pr(u1 ≥ [M it]1)λ−1du1\nn ∏\nk=3\nduk .\nIf the distribution of the random steps steps is isotropic then h(u1, y, u3, . . . , un) = h(u1,−y, u3, . . . , un), and as the density h is supposed strictly positive, for y > 0 and all δ ∈, h⋆δ,2(y)− h⋆δ,2(−y) < 0 so E([M⋆t ]2|δt = δ) < 0. If the Markov chain is Harris recurrent and positive then this imply that Eπ([M ⋆ t ]2) < 0 and using the reasoning in the proof of Proposition 3 Eπ([M ⋆ t ]1) > 0.\nFor any covariance matrixC this result is generalized with the use of Lemma 3. ⊓⊔\nLemma 3 and Proposition 4 imply the following result to hold for multivariate normal distributions.\nProposition 5. Let a (1, λ)-ES optimize problem (2) with constant step-size, handling the constraint with resampling. If H is a multivariate normal distribution with mean 0, then (δt)t∈N is a geometrically ergodic positive Harris Markov chain, Eq. (18) holds and its right hand side is strictly positive.\nProof. Suppose M i,jt ∼ N (0, In). Then H is absolutely continuous and h is strictly positive. The function x 7→ exp(g(x)) exp(−‖x‖2/2)/ √ 2π is integrable, so Eq. (16) is satisfied. Furthermore, when δ → +∞ the constraint disappear so M i,jt behaves like (Nλ:λ,N (0, 1), . . . ,N (0, 1)) where Nλ:λ is the last order statistic of λ i.i.d. standard normal variables, so using that E(Nλ:λ) > 0 and E(N (0, 1)) = 0, with multiple uses of the dominated convergence theorem we obtain condition (15) so with Proposition 2 the Markov chain (δt)t∈N is geometrically ergodic and positive Harris.\nFinally H being isotropic the conditions of Proposition 4 are fulfilled, and therefore so are every condition of Proposition 3 which shows what we wanted.\n⊓⊔\nTo obtain sufficient conditions for the density of the random steps to be strictly positive, it is advantageous to decompose that distribution into its marginals and the copula combining them. We pay a particular attention to Archimedean copulas, i.e., copulas defined\n(∀u ∈ [0, 1]n) Cψ(u) = ψ(ψ−1([u]1) + · · ·+ ψ−1([u]n)), (20)\nwhere ψ : [0,+∞] → [0, 1] is an Archimedean generator, i.e., ψ(0) = 1, ψ(+∞) = limt→+∞ ψ(t) = 0, ψ is continuous and strictly decreasing on [0, inf{t : ψ(t) = 0}), and ψ−1 denotes the generalized inverse of ψ,\n(∀u ∈ [0, 1]) ψ−1(u) = inf{t ∈ [0,+∞] : ψ(t) = u}. (21)\nThe reason for our interest is that Archimedean copulas are invariant with respect to permutations of variables, i.e.,\n(∀u ∈ [0, 1]n) Cψ(Qu) = Cψ(u). (22)\nholds for any permutation matrix Q ∈ Rn,n. This can be seen as a weak form of isotropy because in the case of isotropy, (20) holds for any rotation matrix, and a permutation matrix is a specific rotation matrix.\nProposition 6. Let H be the distribution of the two first dimensions of the random step M i,jt , H1 and H2 be its marginals, and C be the copula relating H to H1 and H2. Then the following holds:\n1. Sufficient for H to have a continuous strictly positive density is the simultaneous validity of the following two conditions. (i) H1 and H2 have continuous strictly positive densities h1 and h2, respec-\ntively. (ii) C has a continuous strictly positive density c. Moreover, if (i) and (ii) are valid, then\n(∀x ∈ R2) h(x) = c(H1([x]1), H2([x]2))h1([x]1)h2([x]2). (23)\n2. If C is Archimedean with generator ψ, then it is sufficient to replace (ii) with (ii’) ψ is at least 4-monotone, i.e., ψ is continuous on [0,+∞], ψ′′ is decreas-\ning and convex on R+, and (∀t ∈ R+) (−1)kψ(k)(t) ≥ 0, k = 0, 1, 2. In this case, if (i) and (ii’) are valid, then\n(∀x ∈ R2) h(x) = ψ ′′(ψ−1(H1([x]1)) + ψ −1(H2([x]2)))\nψ′(ψ−1(H1([x]1)) + ψ−1(H2([x]2))) h1([x]1)h2([x]2).\n(24)"
    }, {
      "heading" : "6 Discussion",
      "text" : "The paper presents a generalization of recent results of the first author [8] concerning linear optimization by a (1, λ)-ES in the constant step size case. The generalization consists in replacing the assumption of normality of random steps involved in the evolution strategy by substantially more general distributional assumptions. This generalization shows that isotropic distributions solve the linear problem. Also, although the conditions for the ergodicity of the studied Markov chain accept some heavy-tail distributions, an expnentially vanishing tail allow for geometric ergodicity, which imply a faster convergence to its stationary distribution, and faster convergence of Monte Carlo simulations. In our opinion, these conditions increase the insight into the role that different kinds of distributions play in evolutionary computation, and enlarges the spectrum of possibilities for designing evolutionary algorithms with solid theoretical fundamentals. At the same time, applying the decomposition of a multidimensional distribution into its marginals and the copula combining them, the paper attempts to bring a\nsmall contribution to the research into applicability of copulas in evolutionary computation, complementing the more common application of copulas to the Estimation of Distribution Algorithms [12,14,13].\nNeedless to say, more realistic than the constant step size case, but also more difficult to investigate, is the varying step size case. The most important results in [8] actually concern that case. A generalization of those results for non-Gaussian distributions of random steps for cumulative step-size adaptation ([9]) is especially difficult as the evolution path is tailored for Gaussian steps, and some careful tweaking would have to be applied. The σ self-adaptation evolution strategy ([16]), studied in [6] for the same problem, appears easier, and would be our direction for future research.\nAcknowledgment\nThe research reported in this paper has been supported by grant ANR-2010COSI-002 (SIMINOLE) of the French National Research Agency, and Czech Science Foundation (GAČR) grant 13-17187S."
    }, {
      "heading" : "10. C. A. Coello Coello, “Constraint-handling techniques used with evolutionary al-",
      "text" : "gorithms,” in Proceedings of the 2008 GECCO conference companion on Genetic and evolutionary computation, GECCO ’08, (New York, NY, USA), pp. 2445–2466, ACM, 2008. 11. D. Arnold and D. Brauer, “On the behaviour of the (1 + 1)-ES for a simple constrained problem,” in Parallel Problem Solving from Nature - PPSN X (I. G. R. et al., ed.), pp. 1–10, Springer, 2008. 12. A. Cuesta-Infante, R. Santana, J. Hidalgo, C. Bielza, and P. Larrañaga, “Bivariate empirical and n-variate archimedean copulas in estimation of distribution algorithms,” in IEEE Congress on Evolutionary Computation, pp. 1–8, 2010. 13. L. Wang, X. Guo, J. Zeng, and Y. Hong, “Copula estimation of distribution algorithms based on exchangeable archimedean copula,” International Journal of Computer Applications in Technology, vol. 43, pp. 13–20, 2012. 14. R. Salinas-Gutierrez, A. Hernández Aguirre, and E. Villa Diharce, “Using copulas in estimation of distribution algorithms,” in MICAI 2009: Advances in Artificial Intelligence, pp. 658–668, 2009. 15. S. P. Meyn and R. L. Tweedie, Markov chains and stochastic stability. Cambridge University Press, second ed., 1993. 16. H.-G. Beyer, “Toward a theory of evolution strategies: Self-adaptation,” Evolutionary Computation, vol. 3, no. 3, pp. 311–347, 1995."
    } ],
    "references" : [ {
      "title" : "Fast evolution strategies,",
      "author" : [ "X. Yao", "Y. Liu" ],
      "venue" : "Evolutionary Programming VI,",
      "citeRegEx" : "1",
      "shortCiteRegEx" : "1",
      "year" : 1997
    }, {
      "title" : "Benchmarking Separable Natural Evolution Strategies on the Noiseless and Noisy Black-box Optimization Testbeds,” in Black-box Optimization Benchmarking Workshop, Genetic and Evolutionary Computation",
      "author" : [ "T. Schaul" ],
      "venue" : null,
      "citeRegEx" : "2",
      "shortCiteRegEx" : "2",
      "year" : 2012
    }, {
      "title" : "High dimensions and heavy tails for natural evolution strategies,",
      "author" : [ "T. Schaul", "T. Glasmachers", "J. Schmidhuber" ],
      "venue" : "Genetic and Evolutionary Computation Conference (GECCO),",
      "citeRegEx" : "3",
      "shortCiteRegEx" : "3",
      "year" : 2011
    }, {
      "title" : "When do heavy-tail distributions help?,",
      "author" : [ "N. Hansen", "F. Gemperle", "A. Auger", "P. Koumoutsakos" ],
      "venue" : "P. Runarsson et al., eds.),",
      "citeRegEx" : "4",
      "shortCiteRegEx" : "4",
      "year" : 2006
    }, {
      "title" : "On the behaviour of the (1,λ)-ES for a simple constrained problem,",
      "author" : [ "D. Arnold" ],
      "venue" : "in Foundations of Genetic Algorithms - FOGA",
      "citeRegEx" : "5",
      "shortCiteRegEx" : "5",
      "year" : 2011
    }, {
      "title" : "On the behaviour of the (1, λ)-σSA-ES for a constrained linear problem,” in Parallel Problem Solving from Nature ",
      "author" : [ "D. Arnold" ],
      "venue" : "PPSN XII,",
      "citeRegEx" : "6",
      "shortCiteRegEx" : "6",
      "year" : 2012
    }, {
      "title" : "Cumulative step-size adaptation on linear functions,” in Parallel Problem Solving from Nature - PPSN XII",
      "author" : [ "A. Chotard", "A. Auger", "N. Hansen" ],
      "venue" : null,
      "citeRegEx" : "7",
      "shortCiteRegEx" : "7",
      "year" : 2012
    }, {
      "title" : "Markov chain analysis of evolution strategies on a linear constraint optimization problem,",
      "author" : [ "A. Chotard", "A. Auger", "N. Hansen" ],
      "venue" : null,
      "citeRegEx" : "8",
      "shortCiteRegEx" : "8",
      "year" : 2014
    }, {
      "title" : "Completely derandomized self-adaptation in evolution strategies,",
      "author" : [ "N. Hansen", "A. Ostermeier" ],
      "venue" : "Evolutionary Computation,",
      "citeRegEx" : "9",
      "shortCiteRegEx" : "9",
      "year" : 2001
    }, {
      "title" : "Constraint-handling techniques used with evolutionary algorithms,",
      "author" : [ "C.A. Coello Coello" ],
      "venue" : "Proceedings of the 2008 GECCO conference companion on Genetic and evolutionary computation,",
      "citeRegEx" : "10",
      "shortCiteRegEx" : "10",
      "year" : 2008
    }, {
      "title" : "On the behaviour of the (1 + 1)-ES for a simple constrained problem,” in Parallel Problem Solving from Nature ",
      "author" : [ "D. Arnold", "D. Brauer" ],
      "venue" : "PPSN X (I. G. R. et al.,",
      "citeRegEx" : "11",
      "shortCiteRegEx" : "11",
      "year" : 2008
    }, {
      "title" : "Copula estimation of distribution algorithms based on exchangeable archimedean copula,",
      "author" : [ "L. Wang", "X. Guo", "J. Zeng", "Y. Hong" ],
      "venue" : "International Journal of Computer Applications in Technology,",
      "citeRegEx" : "13",
      "shortCiteRegEx" : "13",
      "year" : 2012
    }, {
      "title" : "Using copulas in estimation of distribution algorithms,",
      "author" : [ "R. Salinas-Gutierrez", "A. Hernández Aguirre", "E. Villa Diharce" ],
      "venue" : "MICAI",
      "citeRegEx" : "14",
      "shortCiteRegEx" : "14",
      "year" : 2009
    }, {
      "title" : "Markov chains and stochastic stability",
      "author" : [ "S.P. Meyn", "R.L. Tweedie" ],
      "venue" : null,
      "citeRegEx" : "15",
      "shortCiteRegEx" : "15",
      "year" : 1993
    }, {
      "title" : "Toward a theory of evolution strategies: Self-adaptation,",
      "author" : [ "H.-G. Beyer" ],
      "venue" : "Evolutionary Computation,",
      "citeRegEx" : "16",
      "shortCiteRegEx" : "16",
      "year" : 1995
    } ],
    "referenceMentions" : [ {
      "referenceID" : 0,
      "context" : "Cases where different distributions have been studied include so-called Fast Evolution Strategies [1] or SNES [2,3] which exploits the separability of f , or heavy-tail distributions on multimodal problems [4,3].",
      "startOffset" : 98,
      "endOffset" : 101
    }, {
      "referenceID" : 1,
      "context" : "Cases where different distributions have been studied include so-called Fast Evolution Strategies [1] or SNES [2,3] which exploits the separability of f , or heavy-tail distributions on multimodal problems [4,3].",
      "startOffset" : 110,
      "endOffset" : 115
    }, {
      "referenceID" : 2,
      "context" : "Cases where different distributions have been studied include so-called Fast Evolution Strategies [1] or SNES [2,3] which exploits the separability of f , or heavy-tail distributions on multimodal problems [4,3].",
      "startOffset" : 110,
      "endOffset" : 115
    }, {
      "referenceID" : 3,
      "context" : "Cases where different distributions have been studied include so-called Fast Evolution Strategies [1] or SNES [2,3] which exploits the separability of f , or heavy-tail distributions on multimodal problems [4,3].",
      "startOffset" : 206,
      "endOffset" : 211
    }, {
      "referenceID" : 2,
      "context" : "Cases where different distributions have been studied include so-called Fast Evolution Strategies [1] or SNES [2,3] which exploits the separability of f , or heavy-tail distributions on multimodal problems [4,3].",
      "startOffset" : 206,
      "endOffset" : 211
    }, {
      "referenceID" : 4,
      "context" : "In several recent publications [5,6,7,8], attention has been paid to Markovchain modelling of linear optimization by a (1, λ)-ES, i.",
      "startOffset" : 31,
      "endOffset" : 40
    }, {
      "referenceID" : 5,
      "context" : "In several recent publications [5,6,7,8], attention has been paid to Markovchain modelling of linear optimization by a (1, λ)-ES, i.",
      "startOffset" : 31,
      "endOffset" : 40
    }, {
      "referenceID" : 6,
      "context" : "In several recent publications [5,6,7,8], attention has been paid to Markovchain modelling of linear optimization by a (1, λ)-ES, i.",
      "startOffset" : 31,
      "endOffset" : 40
    }, {
      "referenceID" : 7,
      "context" : "In several recent publications [5,6,7,8], attention has been paid to Markovchain modelling of linear optimization by a (1, λ)-ES, i.",
      "startOffset" : 31,
      "endOffset" : 40
    }, {
      "referenceID" : 6,
      "context" : "This unconstrained case was studied in [7] for normal steps with cumulative step-size adaptation (the step-size adaptation mechanism in CMA-ES [9]).",
      "startOffset" : 39,
      "endOffset" : 42
    }, {
      "referenceID" : 8,
      "context" : "This unconstrained case was studied in [7] for normal steps with cumulative step-size adaptation (the step-size adaptation mechanism in CMA-ES [9]).",
      "startOffset" : 143,
      "endOffset" : 146
    }, {
      "referenceID" : 9,
      "context" : "Many techniques to handle constraints in randomised algorithms have been proposed (see [10]).",
      "startOffset" : 87,
      "endOffset" : 91
    }, {
      "referenceID" : 10,
      "context" : "We chose this method as it makes the algorithm easier to study, and is consistent with the previous studies assuming normal steps [11,5,6,8], studying constant step-size, self adaptation and cumulative step-size adaptation mechanisms (with fixed covariance matrix).",
      "startOffset" : 130,
      "endOffset" : 140
    }, {
      "referenceID" : 4,
      "context" : "We chose this method as it makes the algorithm easier to study, and is consistent with the previous studies assuming normal steps [11,5,6,8], studying constant step-size, self adaptation and cumulative step-size adaptation mechanisms (with fixed covariance matrix).",
      "startOffset" : 130,
      "endOffset" : 140
    }, {
      "referenceID" : 5,
      "context" : "We chose this method as it makes the algorithm easier to study, and is consistent with the previous studies assuming normal steps [11,5,6,8], studying constant step-size, self adaptation and cumulative step-size adaptation mechanisms (with fixed covariance matrix).",
      "startOffset" : 130,
      "endOffset" : 140
    }, {
      "referenceID" : 7,
      "context" : "We chose this method as it makes the algorithm easier to study, and is consistent with the previous studies assuming normal steps [11,5,6,8], studying constant step-size, self adaptation and cumulative step-size adaptation mechanisms (with fixed covariance matrix).",
      "startOffset" : 130,
      "endOffset" : 140
    }, {
      "referenceID" : 4,
      "context" : "We want to extend the results obtained in [5,8] using the theory of Markov chains.",
      "startOffset" : 42,
      "endOffset" : 47
    }, {
      "referenceID" : 7,
      "context" : "We want to extend the results obtained in [5,8] using the theory of Markov chains.",
      "startOffset" : 42,
      "endOffset" : 47
    }, {
      "referenceID" : 11,
      "context" : "Such distributions have been recently considered in the Estimation of Distribution Algorithms [12,13], continuing the trend of using copulas in that kind of evolutionary optimization algorithms [14].",
      "startOffset" : 94,
      "endOffset" : 101
    }, {
      "referenceID" : 12,
      "context" : "Such distributions have been recently considered in the Estimation of Distribution Algorithms [12,13], continuing the trend of using copulas in that kind of evolutionary optimization algorithms [14].",
      "startOffset" : 194,
      "endOffset" : 198
    }, {
      "referenceID" : 4,
      "context" : "Following [5,6,11,8] we define δt as δt := − g(Xt) σt .",
      "startOffset" : 10,
      "endOffset" : 20
    }, {
      "referenceID" : 5,
      "context" : "Following [5,6,11,8] we define δt as δt := − g(Xt) σt .",
      "startOffset" : 10,
      "endOffset" : 20
    }, {
      "referenceID" : 10,
      "context" : "Following [5,6,11,8] we define δt as δt := − g(Xt) σt .",
      "startOffset" : 10,
      "endOffset" : 20
    }, {
      "referenceID" : 7,
      "context" : "Following [5,6,11,8] we define δt as δt := − g(Xt) σt .",
      "startOffset" : 10,
      "endOffset" : 20
    }, {
      "referenceID" : 0,
      "context" : "n]) ∈ R+ × [0, 1] 7→ Q ",
      "startOffset" : 11,
      "endOffset" : 17
    }, {
      "referenceID" : 0,
      "context" : "λ]) ∈ R+ × [0, 1] 7→ argmax G∈{G(δ,vi)|i∈[1.",
      "startOffset" : 11,
      "endOffset" : 17
    }, {
      "referenceID" : 13,
      "context" : "We may now use these results to show the divergence of the algorithm when the step-size is constant, using the theory of Markov chains [15].",
      "startOffset" : 135,
      "endOffset" : 139
    }, {
      "referenceID" : 7,
      "context" : "Following the first part of [8], we restrict our attention to the constant step size in the remainder of the paper, that is for all t ∈ N we take σt = σ ∈ R+.",
      "startOffset" : 28,
      "endOffset" : 31
    }, {
      "referenceID" : 7,
      "context" : "We now show ergodicity of the Markov chain (δt)t∈N, which implies that the t-steps transition kernel (the function A 7→ Pr(δt ∈ A|δ0 = δ) for A ∈ B(R+)) converges towards a stationary measure π, generalizing Propositions 3 and 4 of [8].",
      "startOffset" : 232,
      "endOffset" : 235
    }, {
      "referenceID" : 13,
      "context" : "We want to show a drift condition (see [15]) on V .",
      "startOffset" : 39,
      "endOffset" : 43
    }, {
      "referenceID" : 13,
      "context" : "8 of [15], the Markov chain (δt)t∈N is Harris recurrent.",
      "startOffset" : 5,
      "endOffset" : 9
    }, {
      "referenceID" : 13,
      "context" : "1 of [15] the Markov chain (δt)t∈N is positive and is r1-ergodic.",
      "startOffset" : 5,
      "endOffset" : 9
    }, {
      "referenceID" : 13,
      "context" : "We now want to show a drift condition (see [15]) on Vα.",
      "startOffset" : 43,
      "endOffset" : 47
    }, {
      "referenceID" : 13,
      "context" : "1 of [15] which with Theorem 14.",
      "startOffset" : 5,
      "endOffset" : 9
    }, {
      "referenceID" : 13,
      "context" : "1 of [15] proves that the Markov chain (δt)t∈N is Vα-geometrically ergodic.",
      "startOffset" : 5,
      "endOffset" : 9
    }, {
      "referenceID" : 13,
      "context" : "⊓⊔ We now use a law of large numbers ([15] Theorem 17.",
      "startOffset" : 38,
      "endOffset" : 42
    }, {
      "referenceID" : 13,
      "context" : "1 of [15], we may apply a law of large numbers on the right hand side of Eq.",
      "startOffset" : 5,
      "endOffset" : 9
    }, {
      "referenceID" : 13,
      "context" : "1 of [15].",
      "startOffset" : 5,
      "endOffset" : 9
    }, {
      "referenceID" : 0,
      "context" : ", copulas defined (∀u ∈ [0, 1]) Cψ(u) = ψ(ψ([u]1) + · · ·+ ψ([u]n)), (20) where ψ : [0,+∞] → [0, 1] is an Archimedean generator, i.",
      "startOffset" : 24,
      "endOffset" : 30
    }, {
      "referenceID" : 0,
      "context" : ", copulas defined (∀u ∈ [0, 1]) Cψ(u) = ψ(ψ([u]1) + · · ·+ ψ([u]n)), (20) where ψ : [0,+∞] → [0, 1] is an Archimedean generator, i.",
      "startOffset" : 93,
      "endOffset" : 99
    }, {
      "referenceID" : 0,
      "context" : ", ψ(0) = 1, ψ(+∞) = limt→+∞ ψ(t) = 0, ψ is continuous and strictly decreasing on [0, inf{t : ψ(t) = 0}), and ψ denotes the generalized inverse of ψ, (∀u ∈ [0, 1]) ψ(u) = inf{t ∈ [0,+∞] : ψ(t) = u}.",
      "startOffset" : 155,
      "endOffset" : 161
    }, {
      "referenceID" : 0,
      "context" : ", (∀u ∈ [0, 1]) Cψ(Qu) = Cψ(u).",
      "startOffset" : 8,
      "endOffset" : 14
    }, {
      "referenceID" : 7,
      "context" : "The paper presents a generalization of recent results of the first author [8] concerning linear optimization by a (1, λ)-ES in the constant step size case.",
      "startOffset" : 74,
      "endOffset" : 77
    }, {
      "referenceID" : 12,
      "context" : "small contribution to the research into applicability of copulas in evolutionary computation, complementing the more common application of copulas to the Estimation of Distribution Algorithms [12,14,13].",
      "startOffset" : 192,
      "endOffset" : 202
    }, {
      "referenceID" : 11,
      "context" : "small contribution to the research into applicability of copulas in evolutionary computation, complementing the more common application of copulas to the Estimation of Distribution Algorithms [12,14,13].",
      "startOffset" : 192,
      "endOffset" : 202
    }, {
      "referenceID" : 7,
      "context" : "The most important results in [8] actually concern that case.",
      "startOffset" : 30,
      "endOffset" : 33
    }, {
      "referenceID" : 8,
      "context" : "A generalization of those results for non-Gaussian distributions of random steps for cumulative step-size adaptation ([9]) is especially difficult as the evolution path is tailored for Gaussian steps, and some careful tweaking would have to be applied.",
      "startOffset" : 118,
      "endOffset" : 121
    }, {
      "referenceID" : 14,
      "context" : "The σ self-adaptation evolution strategy ([16]), studied in [6] for the same problem, appears easier, and would be our direction for future research.",
      "startOffset" : 42,
      "endOffset" : 46
    }, {
      "referenceID" : 5,
      "context" : "The σ self-adaptation evolution strategy ([16]), studied in [6] for the same problem, appears easier, and would be our direction for future research.",
      "startOffset" : 60,
      "endOffset" : 63
    } ],
    "year" : 2014,
    "abstractText" : "Several recent publications investigated Markov-chain modelling of linear optimization by a (1, λ)-ES, considering both unconstrained and linearly constrained optimization, and both constant and varying step size. All of them assume normality of the involved random steps, and while this is consistent with a black-box scenario, information on the function to be optimized (e.g. separability) may be exploited by the use of another distribution. The objective of our contribution is to complement previous studies realized with normal steps, and to give sufficient conditions on the distribution of the random steps for the success of a constant step-size (1, λ)-ES on the simple problem of a linear function with a linear constraint. The decomposition of a multidimensional distribution into its marginals and the copula combining them is applied to the new distributional assumptions, particular attention being paid to distributions with Archimedean copulas.",
    "creator" : "LaTeX with hyperref package"
  }
}