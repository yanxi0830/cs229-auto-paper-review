{
  "name" : "1703.06485.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "A Near Optimal Hamiltonian-Control and Learning via Chattering",
    "authors" : [ "PEEYUSH KUMAR", "WOLF KOHN", "ZELDA B. ZABINSKY" ],
    "emails" : [ ],
    "sections" : [ {
      "heading" : null,
      "text" : "A Near Optimal Hamiltonian-Control and Learning via Chattering\nPEEYUSH KUMAR, WOLF KOHN and ZELDA B. ZABINSKY, Atigeo, 800 Bellevue Way NE Suite 600, Bellevue, WA\nMany applications require solving non-linear control problems that are classically not well behaved. This paper develops a simple and efficient chattering algorithm that learns near optimal decision policies through an open-loop feedback strategy. The optimal control problem reduces to a series of linear optimization programs that can be easily solved to recover a relaxed optimal trajectory. This algorithm is implemented on a real-time enterprise scheduling and control process.\nAdditional Key Words and Phrases: Relaxed optimal control problem, Variational optimization, Chattering approximation, Hamiltonian control, Continuous dynamical systems, Non-convex optimization"
    }, {
      "heading" : "1. INTRODUCTION",
      "text" : "Many decision problems involve solving a non-linear control problem that lacks traditional properties such as smooth controls and convex state spaces. This paper develops a chattering algorithm to solve non-linear control problems that are classically not well-behaved. The algorithm works with the Hamiltonian formulation for optimal control problems. This formulation provides many advantages as it can incorporate logic rules (the language of communication in enterprises), can facilitate planning and model adaptation (Hamiltonian describes the time evolution of a system), and scales to big data systems (Hamiltonians are additive for multi-body sytems). In addition, this method is implemented using an open-loop feedback strategy that balances the trade-off between control adaptability and computational efficiency. We demonstrate this method on a real-time enterprise scheduling and control process.\nNon-linear control problems are used in diverse applications but they remain challenging to solve computationally. One generally successful method is the StateDependent Riccati Equation (SDRE) technique [Çimen, 2012]. While this method has been used in many applications, its major limitation is that it requires solving the Riccati equations multiple times. This is generally computationally inefficient. Another recent work in the field solves the non-linear optimal control problem using homotopy perturbation methods [Jajarmi et al., 2012]. This method is computationally efficient as compared to the SDRE technique. However, the approximation methods that are used lack formal analysis on error bounds. It is not well understood how these methods can generalize to ill-behaved, non-differentiable, non-convex systems.\nAnother well studied approach to solving non-linear control problems is dynamic programming and various approximate solutions enable better computational performance [Bertsekas, 2007; Powell, 2007]. The reinforcement learning and Bayesian learning literature has many algorithms using dynamic programming for Markov\nThis work is supported by Atigeo, 800 Bellevue Way NE Suite 600, Bellevue, WA 98004. Author’s addresses: Peeyush Kumar and Zelda B. Zabinsky, Industrial and Systems Engineering, University of Washington Seattle. Wolf Kohn, Atigeo, 800 Bellevue Way NE Suite 600, Bellevue, WA 98004. Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org. c© YYYY ACM. 0004-5411/YYYY/01-ARTA $15.00 DOI: http://dx.doi.org/10.1145/0000000.0000000\nJournal of the ACM, Vol. V, No. N, Article A, Publication date: January YYYY.\nar X\niv :1\n70 3.\n06 48\n5v 1\n[ cs\n.L G\n] 1\n9 M\nar 2\n01 7\nsystems [Sutton and Barto, 1998; Wiering and van Otterlo, 2014]. These methods are generally adaptive and can solve a wide variety of problems, although their success is largely limited to discrete Markovian systems or discretized approximations to continuous Markovian systems. Dynamic programming approaches do not scale well to high dimensional systems due to the curse-of-dimensionality for discrete problems. One common approach to handle large systems is to solve a tailored approximation to the system of interest. This paper introduces a generalizable, scalable approach to ill-behaved non-linear control problems.\nAny control problem can be written as an optimization program with an objective to be optimized and with constraints on state variables. The goal is to compute a control u(t) that minimizes the objective function:\nJ(t, x(t), u(t)) = ∫ T 0 g(t, x(t), u(t))dt+ Ψ(x(T )) (1)\nwhere x(t) is the system state, which evolves according to the state equations\nx(t) = x(0) + ∫ t 0 f(τ, x(τ), u(τ))dτ, x(0) = x0, t ∈ [0, T ] (2)\nand the control u(t) ∈ U is bounded. The objective function J(t, x(t), u(t)) is the total accumulated cost over the time horizon of the problem. It is composed of an operational running cost g(t, x(t), u(t)) and the operational terminal cost Ψ(x(T )). The function f(τ, x(τ), u(τ)) is the continuous dynamics of the system which can be non-differentiable with respect to the state (x(t)) and the control variable (u(t)). The state set X = {x} can in general be a non-convex set.\nThe Hamiltonian formulation for control problems was introduced by Pontryagin as part of his minimum principle [Athans and Falb, 2006]. In this formulation the optimal control problem is given in terms of the Hamiltonian H(t, x(t), p(t), u(t)) = g(t, x(t), u(t)) + pT f(t, x(t), u(t)) where p(t) is the momentum (co-state). The necessary conditions for optimality are\n( dx(t)\ndt\n)T = ∂H(t, x(t), p(t), u(t))\n∂p (3)\n( dp(t)\ndt\n)T = −∂H(t, x(t), p(t), u(t))\n∂x (4)\nH(t, x∗(t), p(t), u∗(t)) ≤ H(t, x(t), p(t), u(t)) (5) and optimal u∗(t), and where p(T ) = ∂Ψ∂x ∣∣∣ x(T ) and x(0) = x0.\nThus we seek an optimal trajectory u∗(t) such that (3), (4) and (5) hold.\nSolving (3), (4) and (5) directly is a two point boundary value problem because x(0) and p(T ) are known. Unfortunately, there are no analytic solutions to solve such problems. Additionally, Pontryagin’s necessary conditions of optimality are only valid for continuous systems.\nThe chattering approach approximates a solution to the optimal control problem defined by (3), (4) and (5) that are non-linear, non-convex and non-smooth. The chattering problem can also be applied to discrete systems by continualizing the discrete system. A good description of the advantages of approximating a discrete dynamical system using a continuous system model is discussed in the article by Nykamp, 2015]. Kohn and Nerode, 1999] provide a formal method to find a continuous approximation to discrete systems.\nSection 2 describes the chattering approximation approach. Section 3 provides a numerical method, we call the chattering algorithm. Section 4 demonstrates this approach on a real time enterprise scheduling and control system."
    }, {
      "heading" : "2. CHATTERING APPROACH TO CONTROL",
      "text" : "The chattering approach to optimal control problems is motivated through measure based controls. Kohn et al., 2010] provide an approach for optimization of a specific class of variational problems via chattering. This paper extends the chattering lemma [Kohn et al., 2010] to a chattering approach for generic optimal control problems. The main idea in this paper is to work directly with control Hamiltonians by converting (3), (4) and (5) into a sequence of standard variational problems. Each variational problem is defined over a small time interval ∆ti at time ti, i = 0, · · · , I − 1, by partitioning [0, T ] into I intervals [ti, ti+1] defined for each i with ∆ti = ti+1 − ti and such that t0 = 0 and tI = T .\nThe necessary conditions in (5) are relaxed by defining the optimization problem over a small time interval ∆ti, ∆ti = ti+1 − ti, where the objective function is an accumulation of the Hamiltonian and the constraints are obtained by integrating (4) and (5) over the same interval [ti, ti+1] for every i. The approach consists of finding a solution to the following sequence of variational problems.\ninf u(t)∈U, t∈[t0,t1] ∫ t1 t0 H(t, x(t), p(t), u(t))dt\nsubject to\nx(t) = xt0+ ∫ t t0 ∂H(t, x(t), p(t), u(t)) ∂p dt\np(t) = pt1− ∫ t t1 ∂H(t, x(t), p(t), u(t)) ∂x dt\n(6)\ninf u(t)∈U, t∈[t1,t2] ∫ t2 t1 H(t, x(t), p(t), u(t))dt\nsubject to\nx(t) = xt1+ ∫ t t1 ∂H(t, x(t), p(t), u(t)) ∂p dt\np(t) = pt2− ∫ t t2 ∂H(t, x(t), p(t), u(t)) ∂x dt\n(7)\n...\ninf u(t)∈U, t∈[tI−1,tI ] ∫ tI tI−1 H(t, x(t), p(t), u(t))dt\nsubject to\nx(t) = xtI−1+ ∫ t tI ∂H(t, x(t), p(t), u(t)) ∂p dt\np(t) = ptI− ∫ t tI ∂H(t, x(t), p(t), u(t)) ∂x dt.\n(8)\nwith initial condition x(0) = x0 and terminal transversality condition p(T ) = ∂Ψ∂x ∣∣∣ x(T ) .\nWe apply the chattering lemma to convert the sequence of variational problems in (6), (7) and (8) over the interval [0, T ] to a sequence of linear optimization problems over time intervals [ti, ti+1],∀i.\nLEMMA 2.1. (Chattering Lemma c.f. [Kohn et al., 2010; Kohn et al., 2003; Roubicek, 1997]) Let c1(ti), · · · , cK(ti) be given integrable functions from interval [ti, ti+1] into Rn with compact support and let a constant > 0 be given. Then there exists a chattering combination gαti defined for any α ti = (αti1 , · · · , α ti K) ∈ RK+ ,with ∑K k=1 α ti k = 1 and α ti k ≥ 0 such that\nmax t∈[ti,ti+1] ∣∣∣∣∣ ∫ t ti ( gαti(τ)− K∑ k=1 αtik c ti k ) dτ ∣∣∣∣∣ < and\nmeas{t : gαti(t) 6= g β(t)} → 0, as, β → αti , ∀β\n.\nFigure 1 provides a graphical representation of the partitioning schema, where x(ti) = xti , p(ti) = pti are instantiated at the beginning of the interval [ti, ti+1] while the chattering function ctik and measure α ti k are defined over the interval [ti, ti+1]. The chattering levels ctik can be any function over the interval [ti, ti+1] but we assume them to be constant for the purpose of this paper.\nFigure 2 gives a graphical representation of the chattering in the interval [ti, ti+1]. The chattering measure αtik = α\nti(s), where s = [k, k+ 1] for some k, can be interpreted as a probability that in an infinitesimally small neighborhood ∆t around t, we can find ctik (τ) ∈ s for all τ ∈ ∆t. For illustration k = 1, · · · , 5, s = [3, 4], t = ti and ∆t = ti+1 − ti in Figure 2.\nThe following theorem enables us to derive the chattering formulation for the optimization problem in (6), (7) and (8).\nTHEOREM 2.2. Consider the sequence of variational problems in (6), (7) and (8), i = {1, · · · , I − 1}. For each [ti, ti+1], define levels ctik , k = 1, · · · ,K that discretize the range of u ∈ U such that they form an ordered bounded set. Then there exist αtik , k = 1, · · · ,K; i = 0, · · · , I − 1 and ∑K k=1 α ti k = 1,∀i such that the chattering combination gαti for t ∈ ∆ ti k closely approximates, in a Lebesgue norm sense, a solution u\n∗(t) to the variational problem, and, moreover,∫ ti+∆ti\nti\nH(t, x(t), p(t), u(t))dt ≈ K∑ k=1 H(ti, xti , pti , c ti k )α ti k ∆ti .\nwhere ti+1 = ti + ∆ti and x(ti) = xti and p(ti) = pti\nProof. Let us consider a sequence ctik , k = 1, · · · ,K in U . Define a Young’s measure α(t, S), for S ⊆ U , as the limit of the sequence as k → ∞. We associate with α(ti, s),∀s ∈ S a constant measure αti(s), such that α(ti, s) = αti(s) for t ∈ [ti, ti+1] and αti(s) = ∑K k=1 α ti k δ(c ti k ), where the levels c ti k , k = 1, · · · ,K discretize the range of\nu ∈ U, ∑K k=1 α ti k = 1 and α ti k ≥ 0, ∀i and δ(c ti k ) are Dirac measures concentrated on c ti k . Then\nu(t) = ∫ U sαtk(ds)\nwhere the integral is written as (with a slight abuse of notation)\n∫ U s K∑ k=1 αti(s)δ(ctik ) = ∫ U αti(s) K∑ k=1 sδ(ctik ) = ∑ k=1 αtik c ti k .\nThis implies that the last sum gives a close approximation to the solution of the relaxed problem in (6), (7) and (8) which is a close approximation to the solution of the original variational problem (1) and (2). Applying the chattering lemma the last sum above is arbitrarily closely approximated by the chattering combination for all i.\nTherefore, by the properties of a Lebesgue integral and H continuous in (x, p) and piecewise continuous in u, for any u ∈ U ,∫ ti+∆ti\nti\nH(t, x(t), p(t), u(t))dt ≈ ∑ k H(ti, xti , pti , c ti k )α ti k ∆ti\nfor small enough ∆ti .\nThe chattering approximation of u(t) on t yields\n∫ ti+1 ti u(s)ds ≈ ∑ k=1 αtik c ti k (9)\nfor i = 0, · · · , I − 1, which also implies that the chattering approximation to equations (3) and (4) (in the integral form) can be written as\nxti+1 = xti + K∑ k=1 αtik ∂H(t, x(t), p(t), ctk) ∂p ∣∣∣ t=ti ∆ti (10) pti+1 = pti − K∑ k=1 αtik ∂H(t, x(t), p(t), ctk) ∂x ∣∣∣ t=ti ∆ti (11)\nNote that this chattering approximation can in general be written for any variable whose evolution depends on the variable u(t)."
    }, {
      "heading" : "3. LINEAR OPTIMIZATION PROBLEM AND NUMERICAL METHOD",
      "text" : "Now we use the chattering approximation in Section 2 to formulate a sequence of linear optimization programs where we optimize over α for each time interval indexed by i.\nThe linear optimization program based on the approximations in Theorem 2.2 is\nmin α ti k ∑ k H(ti, xti , pti , c ti k )α ti k (12)\nsubject to ∑ k αtik = 1 (13)\n0 ≤ αtik ≤ 1, ∀k (14)\ngiven xti , pti and known c ti k , for each i = 0, · · · I− 1. This is a relaxed knapsack problem which has an analytic solution. Hence, there is no computational cost in solving this linear program.\nThe control problem can now be solved using the above chattering formulation and the known initial condition on the state (x(0) = x0) and a good estimate of the initial value of the co-state. In practical problems it is almost impossible to know apriori a good estimate of the initial co-state. In order to find a good estimate\nof the initial condition we use a similar procedure as in the numerical method of variation of extremals (see [Kirk, 2004]) but while solving the chattering optimization program described above. This approach converts the two point boundary value problem into an initial value problem, which is much easier to solve numerically.\nThe algorithm starts by guessing the initial value of the co-state (p(0) = p0) and iteratively corrects on this guess based on the final observation p(T ). This adaptation is done by considering a perturbation on the initial condition of the co-state. Given (xti , pti) and the chattering levels ckti , the optimization program given by (12), (13) and (14) is solved to obtain the optimal chattering measure αkti . The chattering levels and the chattering measure along with equations (10) and (11) are used to obtain the trajectory (xti , pti).\nIn order to propagate (xti , pti) starting at (x0, p0), the algorithm defines the chattering levels ctik for each time interval from index i to i+1, such that they cover the control set U and that any bounded constraints on xti+1 ,∀i are not violated. Additionally, in order to find a suitable bound for the levels, cimax = maxk c ti k , ∀i and cmin = mink c ti k , the following equation has to be satisfied\nxmin ≤ xti + f(xti , uti)∆ti ≤ xmax. (15) Given xmin and xmax, bounds on chattering levels can be determined nuemrically from (15). This will ensure that the chattering levels cover the set U and the state constraints are satisfied.\nThe algorithm also propagates a perturbed trajectory that starts at the initial state xδti = x0 and the perturbed initial co-state p δ 0 = p0 + δp, for small δp. The corresponding trajectory for state and co-state, starting at (x0, pδ0) at index i is given by (xδti , p δ ti).\nThe algorithm then corrects the initial estimate of co-state by adapting the guesstimate based on deviation of the propagated co-state (p(T )) starting from p0 from the actual final value of the co-state ∂Ψ∂x ∣∣∣ x(T ) . This correction is done using\np0 ← p0 + γ ([ ∂2Ψ\n∂x2 (x(T ))\n] Px(T )− Pp(T ) )−1( pT − ∂Ψ\n∂x (x(T )) ) where γ is a step parameter, Px(ti) = ∂x∂p0 ∣∣∣ x=xti ,p=pti and Pp(ti) = ∂p∂p0 ∣∣∣ x=xti ,p=pti . The partial derivative can be numerically estimated by using a finite difference method. This process is repeated until convergence, i.e.,\n∥∥pT − ∂Ψ∂x (x(T ))∥∥ < . At convergence the solution obtained for xti is the optimal control trajectory and the solution obtained for uti = ∑ k=1 α ti k c ti k is the optimal control signal. The triple {ti, xti , uti} defines a control law (policy).\nThe procedure described above gives a simple routine for solving the optimal control problem, which is given by Algorithm 1."
    }, {
      "heading" : "4. RESULTS",
      "text" : "This section presents two applications that demonstrate the chattering control method described in this paper. The first example is used as a proof-of-concept. We use a standard linear quadratic oscillator to compare the solution from the chattering algorithm (Alg. 1) described in this paper with the known analytic solution. The second demon-\nALGORITHM 1: Algorithm for Hamiltonian-Control via Chattering Input: Historical data containing the sequence {t, x(t), u(t), x′(t)}, where x′(t) is the next state\nobtained on applying control u(t) at time t while in state x(t). The criterion (g(t, x(t), u(t) and Ψ(x)) that needs to be optimized.\nResult: A sequence of (near) optimal control law {ti, xti , uti} for i = 0, · · · , I. begin\nEstimate the Hamiltonian H(t, x(t), p(t), u(t)) from the given data or estimate the dynamics f (using generalized Kalman filter or any other equivalent method) and compute H = g(t, x(t), u(t)) + pT f(t, x, u); If the system is discrete use a continuous approximation (via continualization); Initialize i = 0, ti = 0, x(0) = x0 and guess p(0) = p0 and pδ0 = p0 + δp for a fixed δp; flag = False.; while flag is False or iter ≤ maximumIterations do\nwhile i < I do Measure xti ; Determine chattering levels ctik such that they satisfy bounded constraints on u(t); Solve the optimization program (12), (13) and (14) twice, once with (xti , pti) and second one with (xδti , p δ ti);\nCompute uti = ∑K k=1 α ti k c ti k ; Compute pti+1 , p δ ti+1 , x δ ti+1 using (10) and (11);\nStore xti , pti , uti end if ∥∥pT − ∂Ψ∂x (x(T ))∥∥ < then\nflag = True else\nCompute Px(T ) = xδT−xT δp , Pp(T ) = pδT−pT δp ; p0 ← p0 + γ ([ ∂2Ψ ∂x2 (x(T )) ] Px(T )− Pp(T ) )−1 ( pT − ∂Ψ∂x (x(T )) ) end\nend end\nstration is on a real-time enterprise scheduling and control process. This enterprise problem was first introduced by Kohn et al., 2005]. This problem is a hybrid of continuous and discrete systems that is highly non-linear, non-convex and non-smooth."
    }, {
      "heading" : "4.1. Linear Quadratic Controller",
      "text" : "A linear quadratic controller is a system with quadratic operational cost that is constrained to move on a linear manifold.\nThe control problem is\nmin u(t) ∫ 1 0 x(t)2 + u(t)2dt\ns.t.\nẋ(t) = x(t) + u(t)\nwith initial condition x(0) = 10.\nThe Hamiltonian for the linear quadratic controller is given by\nH(x, p, u) = x2 + u2 + p(x+ u)\nFigure 3 compares the state trajectory and the near-optimal control obtained using the chattering method vs the state trajectory and optimal control obtained through the analytic solution.\nAs observed the chattering method provides a good approximation to the optimal state trajectory, see Fig. 3(a). The chattering artifact can be observed in Fig. 3(b), where the controller chatters on discretized control levels."
    }, {
      "heading" : "4.2. Real Time Enterprise Scheduling and Control Problem",
      "text" : "The second example uses a modified version of the problem defined by Kohn et al., 2005]. Consider a food distribution system with 14 suppliers, one warehouse, and three customers (graphically illustrated in Figure 4).\nThere are five types of food items to be distributed, each type is supplied by one or more suppliers and all items are perishable. The demands by the three customers are given in Figure 5. The customers are given an importance factor of: (i) 1.0 for most preferable, whose orders always need to be satisfied; ii) 0.40 for average customers whose orders need to be satisfied completely in 40% of the cases; and (iii) 0.25 for least preferable customers whose orders need to be satisfied completely in 25% of the cases. The problem data includes: (i) a list of customers with ranking and demands for each item type; (ii) a list of suppliers with the lead times, fixed and variable costs of delivery and min and max order quantities; and (iii) a list of item types with warehouse carryover cost per item type, penalties per unit time for not satisfying demands, and days of life before perishing. Tables I and II provide the values of these external parameters\nof the grocer.\n(a) Apples (b) Oranges\n(c) Banana (d) Tea\nThe problem is to allocate the requested quantities vji (t) of items (j) to customers (i) by ordering µjk(t) of items j from appropriate supplier k while minimizing the total incremental cost. The dynamics model consists of two elements (i) market conservation; and (ii) inventory conservation.\n— The market conservation dynamics are given by\nŻji (t) = −Z j i (t) + Θ j i (t)− v j i (t), i = 1, · · · , 3, j = 1, · · · , 5\nwhere, Zji (t) is the unsatisfied demand of product j to customer i at time t, Θ j i (t) is the continulized demand of product j to customer i at time t and vji (t) is the continualized delivery action of product j to customer i at time t.\n— The inventory conservation dynamics are given by Ẋj(t) = −Xj(t) + ∑ k∈Sj sjk(t) + µ̂ j(t)− pj(t), j = 1, · · · , 5\nwhere, Xj(t) is the inventory of product j at time t, ∑ k∈Sj s j k(t) is the total rate of\nsupply of product j from suppliers k at time t, µ̂j(t) = ∑ k∈Sj µ j k(t) is the cumulative ordering action of product j from supplier k ∈ Sj at time t and pj(t) is the cumulative rate of delivery of product j to customers i.\nThe cost function to be minimized is given by\nJ(t) = − 3∑ i=1 5∑ j=1 vji (t)r j i (t) + 5∑ j=1 (αj µ̂j(t) + βj) + 5∑ j=1 γjXj(t) 3∑ i=1 5∑ j=1 w̄jiZ j i (t)\nwhere, rji (t) is the unit revenue obtained by selling product j to customer i at time t, γj is the inventory cost of carrying product j per unit time, αj = ∑ k α j k is the\nenvelop unit cost of ordering product j, βj = ∑ k β j k is the envelop fixed cost of ordering product j, w̄ji = wiδ j∑3 i=1 ∑5 j=1 wiδ\nj is the cost for not satisfying demand, δj is the penalty for not satisfying demand for product j and wi is the relative weight for not satisfying the demand for product j. We use the function J(t) |J(t)| as the objective function to be minimized (the reason we chose this function is because it provides stable and bounded solutions). For this system the state variable is x(t) = [X(t), Z(t)]T . The control variable is u(t) = [µ(t), v(t)]T . The state space is continuous with dimension dX = 20 and the control space is also continuous with dimension dU = 29.\nFigure 6 illustrates the delivery amount of product j to customer i (vji (t)) and the inventory levels Xj(t), computed using the chattering method described in this paper. The algorithm converged in less than 100 iterations. The total computer time was approximately 20 minutes on a single core CPU with 2.5GHz and 8GB RAM.\nConventional optimal control methods that use dynamic programming would be intractable on this system. This is due to the reason that dynamic programming (DP) works on a discretized formulation of the control problem. Even though the dimensionality of the continuous system is not very high, the discretization results in exponential number of states. Feature extraction, based on tile coding of the state space with unit size, with state space (X) bounded by 0 ≤ x ≤ [100, · · · , 100], and tile coding of the control space with unit size, with control space (U ) bounded by the values given in Table II for order quantities µ and 0 ≤ v ≤ [20, · · · , 20] for delivery quantities, would give a discretized system of net dimension XdX ×XdX ×{×U}dU ≈ 10040 × 2029. Since not all controls are simultaneouosly admissable, this reduces to ∼ 10102. Hence, DP algorithms run into the curse-of-dimensionality. Additionally, parametric and approximate methods would be difficult to condition due to the nature of the problem. Conventional methods based on the Pontryagin’s principle are unable to solve this problem due to the problem being non-smooth and non-convex, while the Hamiltonian chattering method achieves a good solution efficiently."
    }, {
      "heading" : "5. DISCUSSION AND CONCLUSION",
      "text" : "This paper develops a chattering approach to Hamiltonian control problems that are not necessarily convex, linear or smooth. This method is observed to be robust with respect to the structure of the underlying problems as it does not assume any conditions on the state-control space of the system. Additionally, it provides a good approximation for non-smooth controls within a dense subset of the space. Computationally, the optimal control problem reduces to a sequence of linear optimization programs of size equal to the number of chattering levels which is of the order of the dimension of the state variable. The linear optimization programs are relaxed knapsack problems which can be solved analytically. In practice, we find that the algorithm converges in a very few number of iterations to the optimal solution.\nThis method also provides a computationally efficient way of solving continuous space-time control systems. The chattering approach intrinsically discretizes the problem which enables a numerical solution. Note that the discretization, using this method, is of the order of the dimension of the state space, as opposed to being exponential in conventional canonical discretization approaches. The control problem intrinsically is a 2-point boundary value problem, which unfortunately, is very challenging to solve. This method uses a variation of extremals to convert the two-point boundary value control problem into an initial value problem, which can be solved numerically.\nFor future research, we are focusing on finding more efficient and parallelizable solutions to control problems by exploring the theory of parallel transport in manifolds. The theory of parallel transport is well studied in the differential geometry community. We aim to use these results to efficiently find the neighborhood around the optimal trajectory."
    }, {
      "heading" : "ACKNOWLEDGMENTS",
      "text" : "The authors would like to thank Atigeo Corporation for the generous support to carry out this research."
    } ],
    "references" : [ {
      "title" : "Optimal Control: An Introduction to the Theory and Its Applications",
      "author" : [ "M. Athans", "P. Falb" ],
      "venue" : "Dover Books on Engineering Series. Dover Publications",
      "citeRegEx" : "Athans and Falb,? \\Q2006\\E",
      "shortCiteRegEx" : "Athans and Falb",
      "year" : 2006
    }, {
      "title" : "Dynamic Programming and Optimal Control, Vol. II",
      "author" : [ "D.P. Bertsekas" ],
      "venue" : "Athena Scientific,",
      "citeRegEx" : "Bertsekas,? \\Q2007\\E",
      "shortCiteRegEx" : "Bertsekas",
      "year" : 2007
    }, {
      "title" : "Survey of state-dependent riccati equation in nonlinear optimal feedback control synthesis",
      "author" : [ "T. Çimen" ],
      "venue" : "Journal of Guidance, Control, and Dynamics,",
      "citeRegEx" : "Çimen,? \\Q2012\\E",
      "shortCiteRegEx" : "Çimen",
      "year" : 2012
    }, {
      "title" : "A highly computational efficient method to solve nonlinear optimal control problems",
      "author" : [ "A. Jajarmi", "N. Pariz", "A.V. Kamyad", "S. Effati" ],
      "venue" : "Scientia Iranica,",
      "citeRegEx" : "Jajarmi et al\\.,? \\Q2012\\E",
      "shortCiteRegEx" : "Jajarmi et al\\.",
      "year" : 2012
    }, {
      "title" : "Optimal Control Theory: An Introduction",
      "author" : [ "D. Kirk" ],
      "venue" : "Dover Books on Electrical Engineering Series. Dover Publications",
      "citeRegEx" : "Kirk,? \\Q2004\\E",
      "shortCiteRegEx" : "Kirk",
      "year" : 2004
    }, {
      "title" : "Control in hybrid systems",
      "author" : [ "W. Kohn", "V. Brayman", "P. Cholewinski", "A. Nerode" ],
      "venue" : "International Journal of Hybrid Systems,",
      "citeRegEx" : "Kohn et al\\.,? \\Q2003\\E",
      "shortCiteRegEx" : "Kohn et al\\.",
      "year" : 2003
    }, {
      "title" : "Repair-control of enterprise systems using rfid sensory data",
      "author" : [ "W. Kohn", "V. Brayman", "J. Littleton" ],
      "venue" : "IIE Transactions,",
      "citeRegEx" : "Kohn et al\\.,? \\Q2005\\E",
      "shortCiteRegEx" : "Kohn et al\\.",
      "year" : 2005
    }, {
      "title" : "Variational optimization via chattering",
      "author" : [ "W. Kohn", "V. Brayman", "Z.B. Zabinsky", "Y. Shen" ],
      "venue" : "Nonlinear Analysis: Hybrid Systems,",
      "citeRegEx" : "Kohn et al\\.,? \\Q2010\\E",
      "shortCiteRegEx" : "Kohn et al\\.",
      "year" : 2010
    }, {
      "title" : "Multiple-agent hybrid control architecture for intelligent real-time control of distributed nonlinear processes. US Patent 5,963,447",
      "author" : [ "W. Kohn", "A. Nerode" ],
      "venue" : null,
      "citeRegEx" : "Kohn and Nerode,? \\Q1999\\E",
      "shortCiteRegEx" : "Kohn and Nerode",
      "year" : 1999
    }, {
      "title" : "From discrete dynamical systems to continuous dynamical systems",
      "author" : [ "D. Nykamp" ],
      "venue" : "From Math Insight",
      "citeRegEx" : "Nykamp,? \\Q2015\\E",
      "shortCiteRegEx" : "Nykamp",
      "year" : 2015
    }, {
      "title" : "Approximate Dynamic Programming: Solving the Curses of Dimensionality (Wiley Series in Probability and Statistics)",
      "author" : [ "W.B. Powell" ],
      "venue" : null,
      "citeRegEx" : "Powell,? \\Q2007\\E",
      "shortCiteRegEx" : "Powell",
      "year" : 2007
    }, {
      "title" : "Relaxation in Optimization Theory and Variational Calculus. De Gruyter Series in Nonlinear Analysis and Applications",
      "author" : [ "T. Roubicek" ],
      "venue" : null,
      "citeRegEx" : "Roubicek,? \\Q1997\\E",
      "shortCiteRegEx" : "Roubicek",
      "year" : 1997
    }, {
      "title" : "Introduction to Reinforcement Learning",
      "author" : [ "R.S. Sutton", "A.G. Barto" ],
      "venue" : null,
      "citeRegEx" : "Sutton and Barto,? \\Q1998\\E",
      "shortCiteRegEx" : "Sutton and Barto",
      "year" : 1998
    }, {
      "title" : "Reinforcement Learning: State-of-the-Art",
      "author" : [ "M. Wiering", "M. van Otterlo" ],
      "venue" : null,
      "citeRegEx" : "Wiering and Otterlo,? \\Q2014\\E",
      "shortCiteRegEx" : "Wiering and Otterlo",
      "year" : 2014
    } ],
    "referenceMentions" : [ {
      "referenceID" : 2,
      "context" : "One generally successful method is the StateDependent Riccati Equation (SDRE) technique [Çimen, 2012].",
      "startOffset" : 88,
      "endOffset" : 101
    }, {
      "referenceID" : 3,
      "context" : "Another recent work in the field solves the non-linear optimal control problem using homotopy perturbation methods [Jajarmi et al., 2012].",
      "startOffset" : 115,
      "endOffset" : 137
    }, {
      "referenceID" : 1,
      "context" : "Another well studied approach to solving non-linear control problems is dynamic programming and various approximate solutions enable better computational performance [Bertsekas, 2007; Powell, 2007].",
      "startOffset" : 166,
      "endOffset" : 197
    }, {
      "referenceID" : 10,
      "context" : "Another well studied approach to solving non-linear control problems is dynamic programming and various approximate solutions enable better computational performance [Bertsekas, 2007; Powell, 2007].",
      "startOffset" : 166,
      "endOffset" : 197
    }, {
      "referenceID" : 12,
      "context" : "systems [Sutton and Barto, 1998; Wiering and van Otterlo, 2014].",
      "startOffset" : 8,
      "endOffset" : 63
    }, {
      "referenceID" : 0,
      "context" : "The Hamiltonian formulation for control problems was introduced by Pontryagin as part of his minimum principle [Athans and Falb, 2006].",
      "startOffset" : 111,
      "endOffset" : 134
    }, {
      "referenceID" : 7,
      "context" : "This paper extends the chattering lemma [Kohn et al., 2010] to a chattering approach for generic optimal control problems.",
      "startOffset" : 40,
      "endOffset" : 59
    }, {
      "referenceID" : 7,
      "context" : "[Kohn et al., 2010; Kohn et al., 2003; Roubicek, 1997]) Let c(ti), · · · , c(ti) be given integrable functions from interval [ti, ti+1] into R with compact support and let a constant > 0 be given.",
      "startOffset" : 0,
      "endOffset" : 54
    }, {
      "referenceID" : 5,
      "context" : "[Kohn et al., 2010; Kohn et al., 2003; Roubicek, 1997]) Let c(ti), · · · , c(ti) be given integrable functions from interval [ti, ti+1] into R with compact support and let a constant > 0 be given.",
      "startOffset" : 0,
      "endOffset" : 54
    }, {
      "referenceID" : 11,
      "context" : "[Kohn et al., 2010; Kohn et al., 2003; Roubicek, 1997]) Let c(ti), · · · , c(ti) be given integrable functions from interval [ti, ti+1] into R with compact support and let a constant > 0 be given.",
      "startOffset" : 0,
      "endOffset" : 54
    }, {
      "referenceID" : 4,
      "context" : "of the initial condition we use a similar procedure as in the numerical method of variation of extremals (see [Kirk, 2004]) but while solving the chattering optimization program described above.",
      "startOffset" : 110,
      "endOffset" : 122
    } ],
    "year" : 2017,
    "abstractText" : "Many applications require solving non-linear control problems that are classically not well behaved. This paper develops a simple and efficient chattering algorithm that learns near optimal decision policies through an open-loop feedback strategy. The optimal control problem reduces to a series of linear optimization programs that can be easily solved to recover a relaxed optimal trajectory. This algorithm is implemented on a real-time enterprise scheduling and control process.",
    "creator" : "LaTeX with hyperref package"
  }
}