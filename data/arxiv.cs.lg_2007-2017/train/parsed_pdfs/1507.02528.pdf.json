{
  "name" : "1507.02528.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "Faster Convex Optimization: Simulated Annealing with an Efficient Universal Barrier",
    "authors" : [ "Jacob Abernethy" ],
    "emails" : [ "jabernet@umich.edu", "ehazan@princeton.edu" ],
    "sections" : [ {
      "heading" : null,
      "text" : "ar X\niv :1\n50 7.\n02 52\n8v 2\n[ m\nat h.\nO C\n] 5"
    }, {
      "heading" : "1 Introduction",
      "text" : "Convex optimization is by now a well established field and a cornerstone of the fields of algorithms and machine learning. Polynomial time methods for convex optimization belong to relatively few classes: the oldest and perhaps most general is the ellipsoid method with roots back to Kachiyan in the 50s [4]. Despite its generality and simplicity, the ellipsoid method is known to perform poorly in practice.\nA more recent family of algorithms are the celebrated interior point methods, initially developed by Karmarkar in the context of linear programming, and generalized in the seminal work of Nesterov and Nemirovskii [16]. These methods are known to perform well in practice and come with rigorous theoretical guarantees of polynomial running time, but with a significant catch: the underlying constraints must admit an efficiently-computable self-concordant barrier function. Barrier functions are defined as satisfying certain differential inequality conditions that facilitate the path-following scheme developed by Nesterov and Nemirovskii [16], in particular it guarantees that the Newton step procedure maintains feasibility of the iterates. Indeed the iterative path following scheme essentially reduces the optimization problem to the construction of a barrier function, and in many nice scenarios a self-concordant barrier is easy to obtain; e.g., for polytopes the simple logarithmic barrier suffices. Yet up to the present there is no known universal efficient construction of a barrier that applies to any convex set. The problem is seemingly even more difficult in the membership oracle model where our access to K is given only via queries of the form “is x ∈ K?”.\nThe most recent polynomial time algorithms are random-walk based methods, originally pioneered in the work of Dyer et al. [3] and greatly advanced by Lovász and Vempala [13]. These algorithms apply in full generality of convex optimization and require only a membership oracle. The state of the art in polynomial time convex optimization is the random-walk based algorithm of simulated annealing and the specific temperature schedule analyzed in the breakthrough of Kalai and Vempala [7]. Improvements have been given in certain cases, most notably in the work of Narayanan and Rakhlin [14] where barrier functions were utilized.\nIn this paper we tie together two of the three known methodologies for convex optimization, give an efficiently computable universal barrier for interior point methods, and derive a faster algorithm for convex optimization in the membership oracle model. Specifically,\n1. We define the heat path of a simulated annealing method as the (determinisitc) curve formed by the mean of the annealing distribution as the temperature parameter is continuously decreased. We show that the heat path coincides with the central path of an interior point algorithm with the entropic universal barrier function. This intimately ties the two major convex optimization methods together and shows they are approximately equivalent over any convex set.\nWe further enhance this connection by showing that the central path following interior point method applied with the universal entropic barrier is a first-order approximation of simulated annealing.\n2. Using the connection above, we give an efficient randomized interior point method with an efficiently computable universal barrier for any convex set described by a membership oracle. Previously, efficiently computable barriers were known only for particular convex sets.\n3. We give a new temperature schedule for simulated annealing inspired by interior point methods. This gives rise to an algorithm for general convex optimization with running time of Õ( √ νn4),\nwhere ν is the self-concordance parameter of the entropic barrier. The previous state of the\nart is Õ(n4.5) by [7]. We note that our algorithm does not need explicit access to the entropic barrier, it only appears in the analysis of the temperature schedule.\nIt was recently shown by Bubeck and Eldan [2] that the entropic barrier satisfies all require self-concordance properties and that the associated barrier parameter satisfies ν ≤ n(1 + o(1)), although this is generally not tight. Our algorithm improves the previous annealing run time by a factor of Õ( √ n ν ) which in many cases is o(1). For example, in the case of semi-definite programming over matrices in Rn×n, the entropic barrier is identically the standard log-determinant barrier [5], exhibiting a parameter ν = n, rather than n2, which an improvement of n compared to the state-of-the-art. More details are given in section 4.4.\nThe Problem of Convex Optimization For the remainder of the paper, we will be considering the following algorithmic optimization problem. Assume we are given access to an arbitrary bounded convex set K ⊂ Rn, and we shall assume without loss of generality that K lies in a 2-norm ball of radius 1. Assume we are also given as input a vector θ̂ ∈ Rn. Our goal is to solve the following:\nmin x∈K\nθ̂>x. (1)\nWe emphasize that this is, in a certain sense, the most general convex optimization problem one can pose. While the objective is linear in x, we can always reduce non-linear convex objectives to the problem (1). If we want to solve minx∈K f(x) for some convex f : K → R, we can instead define a new problem as follows. Letting K′ := {(x, c) ∈ K × R : f(x) − c ≤ 0}, this non-linear problem is equivalent to solving the linear problem min{(x,c)∈K′} c. This equivalence is true in in the membership oracle model, since a membership oracle for K immediately implies an efficient membership oracle for K′."
    }, {
      "heading" : "1.1 Preliminaries",
      "text" : "This paper ties together notions from probability theory and convex analysis, most definitions are deferred to where they are first used. We try to follow the conventions of interior point literature as in the excellent text of Nemirovski [15], and the simulated annealing and random-walk notation of [7].\nFor some constant C, we say a distribution P is C-isotropic if for any vector v ∈ Rd we have\n1 C ‖v‖2 ≤ E X∼P [(v>X)2] ≤ C‖v‖2.\nLet P, P ′ be two distributions on Rn with means µ, µ′, respectively. We say P is C-isotropic with respect to P ′ if\n1 C E X∼P ′ [(v>X)2] ≤ E X∼P [(v>X)2] ≤ C E X∼P ′ [(v>X)2].\nOne measure of the distance between two distributions, often referred to as the `2 norm, is given by ∥∥∥µ\nπ ∥∥∥ ≡ E x∼µ ( µ(x) π(x) ) = ∫ x∼µ ( µ(x) π(x) ) dµ(x).\nWe note that this distance is not symmetric in general.\nFor a differentiable convex function f : Rn → R, the Bregman divergence Df (x, y) between points x, y ∈ dom(f) is the quantity\nDf (x, y) ≡ f(x)− f(y)−∇f(y)>(x− y).\nFurther, we can always define the Fenchel conjugate (or Fenchel dual) [17] which is the function f∗ defined as\nf∗(θ) := supx∈dom(f) θ >x− f(x). (2)\nIt is easy to see that f∗(·) is also convex, and under weak conditions one has f∗∗ = f . A classic duality result (see e.g. [17]) states that when f∗ is smooth and strictly convex on its domain and tends to infinity at the boundary, we have a characterization of the gradients of f and f∗ in terms of maximizers:\n∇f∗(θ) = arg max x∈dom(f) θ>x− f(x) and ∇f(x) = arg max θ∈dom(f∗) θ>x− f∗(θ). (3)"
    }, {
      "heading" : "1.2 Structure of this paper",
      "text" : "We start by an overview of random-walk methods for optimization in the next section, and introduce the notion of the heat path for simulated annealing. The following section surveys the important notions from interior point methods for optimization and the entropic barrier function. In section 4 we tie the two approaches together formally by proving that the heat path and central path are the same for the entropic barrier. We proceed to give a new temperature schedule for simulated annealing as well as prove its convergence properties. In the appendix we describe the KalaiVempala methodology for analyzing simulated annealing and its main components for completeness."
    }, {
      "heading" : "2 An Overview of Simulated Annealing",
      "text" : "Consider the following distribution over the set K for an arbitrary input vector θ ∈ Rn.\nPθ(x) := exp(−θ>x)∫\nK exp(−θ>x′) dx′ . (4)\nThis is often referred to as the Boltzmann distribution and is a natural exponential family parameterized by θ. It was observed by [7] that the optimization objective (1) can be reduced to sampling from these distributions. That is, if we choose some scaling quantity t > 0, usually referred to as the temperature, then any sample X from the distribution Pθ̂/t must be nt-optimal in expectation. More precisely, [7] show that\nE X∼Pθ̂/t\n[θ̂>X]−min x∈K θ̂>x ≤ nt. (5)\nAs we show later, our connection implies an even stronger statement, replacing n above by the self-concordant parameter of the entropic barrier, as we will define in the next section equation (10).\nIt is quite natural that for small temperature parameter t ∈ R, samples from the P θ t are essentially optimal – the exponential nature of the distribution will eventually concentrate all probability mass on a small neightborhood around the maximizing point x∗ ∈ K. The problem, of course, is that sampling from a point mass around x∗ is precisely as hard as finding x∗.\nThis brings us to the technique of so-called simulated annealing, originally introduced by Kirkpatrick et al. [9] for solving generic problems of the form minx∈K f(x), for arbitrary (potentially non-convex) functions f . At a very high level, simulated annealing would begin by sampling from a “high-entropy” distribution (t very close to 0), and then continue by slowly “turning down the temperature” on the distribution, i.e. decreasing t, which involves sampling according to the pdf Qf,t(x) ∝ exp(−1t f(x)). The intuition behind annealing is that, as long as t\n′/t is a small constant, then the distributions Qf,t′ and Qf,t will be “close” in the sense that a random walk starting from the initial distribution Qf,t′ will mix quickly towards its stationary distribution Qf,t.\nSince its inception, simulated annealing is generally referred to as a heuristic for optimization, as polynomial-time guarantees have been difficult to establish. However, the seminal work of Kalai and Vempala [7] exhibited a poly-time annealing method with formal guarantees for solving linear optimization problems in the form of (1). Their technique possessed a particularly nice feature: the sampling algorithm utilizes a well-studied random walk (Markov chain) known as HitAndRun [18, 10, 13], and the execution of this Markov chain requires only access to a membership oracle on the set K. That is, HitAndRun does not rely on a formal description of K but only the ability to (quickly) answer queries “x ∈ K?” for arbitrary x ∈ Rd.\nLet us now describe the HitAndRun algorithm in detail. We note that this Markov chain was first introduced by Smith [18], a poly-time guarantee was given by Lovász [10] for uniform sampling, and this was generalized to arbitrary log-concave distributions by Lovász and Vempala [11]. HitAndRun requires several inputs, including: (a) the distribution parameter θ, (b) an estimate of the covariance matrix Σ of Pθ, (c) the membership oracle OK, for K, (d) a starting point X0, and (e) the number of iterations N of the random walk.\nAlgorithm 1: HitAndRun(θ,OK, N,Σ, X0) for approximately sampling Pθ 1 Inputs: parameter vector θ, oracle OK for K, covariance matrix Σ, #iterations N , initial X0 ∈ K. 2 for i = 1, 2, . . . , N do 3 Sample a random direction u ∼ N(0,Σ) 4 Querying OK, determine the line segment R = {Xi−1 + ρu : ρ ∈ R} ∩ K 5 Sample a point Xi from R according to the distribution Pθ restricted to R\n6 Return XN\nThe first key fact of HitAndRun(θ) is that the stationary distribution of this Markov chain is indeed the desired Pθ; a proof can be found in [19]. The difficulty for this and many other random walk techniques is to show that the Markov chain “mixes quickly”, in that the number of steps N needn’t be too large as a function of n. This issue has been the subject of much research will be discussed below. Before proceeding, we note that a single step of HitAndRun can be executed quite efficiently. Sampling a random gaussian vector with covariance Σ (line 3) can be achieved by simply sampling a standard gaussian vector z and returning Σ1/2z. Computing the line segment R (line 4) requires simply finding the two locations where the line {Xi−1 +ρu : ρ ∈ R} intersects with the boundary of K, but an -approximation of these points can be found via binary search using O ( log 1 ) queries to OK. Sampling from Pθ restricted to the line segment R can also be achieved efficiently, and we refer the reader to Vempala [19]. The analysis for simulated annealing in [7] proceeds by imagining a sequence of distributions\nPθk = Pθ̂/tk where t1 = R is the diameter of the set K and tk := ( 1− 1√ n )k . Let k = O( √ n log n ), then sampling from Pθk is enough to achieve the desired optimization guarantee. That is, via Equation 5, we see a sample from Pθk is -optimal in expectation.\nTo sample from Pθk , [7] construct a recursive sampling oracle using HitAndRun. The idea is that samples from Pθk+1 can be obtained from a warm start by sampling from Pθk according to a carefully chosen temperature schedule. The details are given in Algorithm 2.\nAlgorithm 2: SimulatedAnnealing with HitAndRun – Kalai and Vempala [7]\n1 Input: temperature schedule {tk, k ∈ [T ]}, objective θ̂. 2 Set X0 = 0, Σ1 = I, t1 = R 3 for k = 1, ..., T do 4 θk ← θ̂tk 5 Xk ← HitAndRun(θk,OK, N,Σk, Xk−1) 6 for j = 1, .., n do 7 Y jk = HitAndRun(θk,OK, N,Σk, Y j k−1) 8 Estimate covariance: Σk+1 := CovMtx(Y k 1 , . . . , Y k n )\n9 Return XT\nThe Kalai and Vempala [7] analysis leans on a number of technical but crucial facts which they prove. The temperature update schedule that they devise, namely tk = (1− 1√n)tk−1, is shown to satisfy these iterative rules and thus return an approximate solution.\nTheorem 1 (Key result of Kalai and Vempala [7] and Lovász and Vempala [11]). Fix k and consider the HitAndRun walk used in Algorithm 2 to compute Xk and Y j k for each j. Assume we choose the temperature schedule in order that successive distributions Pθk , Pθk−1 are close in `2:\nmax {∥∥∥ PθkPθk−1 ∥∥∥2 , ∥∥∥Pθk−1Pθk ∥∥∥2 } ≤ 10. (6)\nThen, as long as the warm start samples Xk−1 and Y j k−1 are (approximately) distributed according to Pθk−1, the random walk HitAndRun mixes to Pθk with N = Õ(n 3) steps. That is, the output samples Xk and Y j k are distributed according to Pθk up to error ≤ .\nIn the appendix we sketch the proof of this theorem for completeness.\nCorollary 1. The temperature schedule tk := (1− 1/ √ n) k t1 satisfies condition (6), and thus Algorithm 2 with this schedule returns an -approximate solution in time Õ(n4.5).\nProof. By equation (5), to achieve error it suffice that 1t ≥ n , or in other words k needs to be large enough such that (1− 1√ n )k ≤ n for which k = 8 √ n log n suffices: (1− 1√ n )k ≤ e− k 2 √ n = e−4 log n ≤ n . Hence the temperature schedule need be applied with T = Õ( √ n) iterations. Each iteration requires O(n) applications of HitAndRun that cost O(n3), for the total running time of Õ(n4.5).\nIn later sections we proceed to give a more refined temperature schedule that satisfies the KalaiVempala conditions, and thus results in a faster algorithm. Our temperature schedule is based on new observations in interior point methods, which we describe next."
    }, {
      "heading" : "2.1 The heat path for simulated annealing",
      "text" : "Our main result follow from the observation that the path-following interior point method has an analogue in the random walk world. Simulated annealing incorporates a carefully chosen temperature schedule to reach its objective from a near-uniform distribution. We can think of all temperature schedules as performing a random process whose changing mean is a single well-defined curve. For a given convex set K ⊆ Rd and objective θ̂, define the heat path as the following set of points, parametrized by the temperature t ∈ [0,∞] as follows:\nHeatPath(t) = E x∼Pθ̂/t [x]\nWe can now define the heat path as HeatPath = ∪t≥0{HeatPath(t)}. At this point it is not yet clear why this set of points is even a continuous curve in space, let alone equivalent to an analogous notion in the interior point world. We will return to this equivalence in section 4."
    }, {
      "heading" : "3 An Overview of Interior Point Methods for Optimization",
      "text" : "Let us now review the vast literature on Interior Point Methods (IPMs) for optimization, and in particular the use of the Iterative Newton Step technique. The first instance of polynomial time algorithms for convex optimization using interior point machinery was the linear programming algorithm of Karmarkar [8]. The pioneering book of Nesterov and Nemirovskii [16] brought up\ntechniques in convex analysis that allowed for polynomial time algorithms for much more general convex optimization, ideas that are reviewed in great detail and clarity in [15] .\nThe goal remains the same, to solve the linear optimization problem posed in Equation (1). The intuition behind IPMs is that iterative update schemes such as gradient descent for solving (1) can fail because the boundary of K can be difficult to manage, and “moving in the direction of descent” will fail to achieve a fast rate of convergence. Thus one needs to “smooth out” the objective with the help of an additional function. In order to produce an efficient algorithm, a well-suited type of function is known as a self-concordant barrier which have received a great deal of attention in the optimization literature.\nA self-concordant barrier function ϕ : int(K)→ R, with barrier parameter, ν is a convex function satisfying two differential conditions: for any h ∈ Rn and any x ∈ K,\n∇3ϕ[h, h, h] ≤ 2(∇2ϕ[h, h])3/2, and ∇ϕ[h] ≤ √ ν∇2ϕ[h, h], (7)\nin addition to the property that the barrier should approach infinity when approaching the boundary of K. Such function possess very desirable properties from the perspective of optimization, several of which we discuss in the present section. We note an important fact: while the existence of such a function ϕ for general sets K has been given by Nesterov and Nemirovskii [16]—the universal barrier with parameter parameter ν = O(n), to be discussed further in Section 4.4—an efficient construction of such a function has remained elusive and was considered an important question in convex optimization. This indeed suggests that the annealing results we previously outlined are highly desirable, as HitAndRun requires only a membership oracle on K. However, one of the central results of the present work is the equivalence between annealing and IPMs, where we show that sampling gives one implicit access to a particular barrier function. This will be discussed at length in Section 4.\nLet us now assume we are given such a function ϕ with barrier parameter ν. A standard approach to solving (1) is to add the function ϕ(x) to the primary objective, scaling the linear term by a “temperature” parameter t > 0:\nmin x∈K {tθ̂>x+ ϕ(x)}. (8)\nAs the the temperature t tends to ∞ the solution of (8) will tend towards the optimal solution to 1. This result is proved for completeness in Theorem 2.\nTowards developing in detail the iterative Newton algorithm, let us define the following for every positive integer k:\ntk := (\n1 + c√ ν\n)k for some c > 0, (9)\nΦk(x) := tkθ̂ >x+ ϕ(x)\nx̄k := arg min x Φk(x)\nAs ϕ is a barrier function, it is clear that x̄k is in the interior of K and, in particular, ∇Φk(x̄k) = 0 =⇒ ∇ϕ(x̄k) = tkθ̂. It is shown in [15] (Equation 3.6) that any ν-SCB (Self-Concordant Barrier) ϕ satisfies ∇ϕ(x)>(y − x) ≤ ν, whence we can bound the difference in objective value between x̄k and the optimal point x∗:\nθ̂>(x∗ − x̄k) = ∇ϕ(x̄k)>(x∗ − x̄k)\ntk ≤ ν tk . (10)\nWe see that the approximation point x̄k becomes exponentially better as k increases. Indeed, setting k = d √ ν c log(ν/ )e guarantees that the error is bounded by .\nThe iterative Newton’s method technique actually involves approximating x̄k with x̂k, a nearoptimal maximizer of Φk, at each iteration k. For an arbitrary v ∈ Rn, x ∈ int(K), and any k ≥ 1, following [15] we define:\n‖v‖x := √ v>∇2ϕ(x)v, the “local norm” of v w.r.t x; (11)\n‖v‖∗x := √ v>∇−2ϕ(x)v, the corresponding dual norm of v, (12) λ(x, tk) := ‖∇Φk(x)‖∗x, the Newton decrement of x for temperature tk. (13)\nNote that, for a fixed point x ∈ K, the norms ‖ · ‖x and ‖ · ‖∗x are dual to each other1. It will turn out that λ(x, tk) will be used both as a quantity in the algorithm, and as a kind of potential that we need to keep small.\nIn Algorithm 3 we describe the damped newton update algorithm, henceforth called IterativeNewtonStep. We note that the\nAlgorithm 3: IterativeNewtonStep\n1 Input: θ̂ ∈ Rd, K and barrier function ϕ 2 Solve: x̂0 = arg maxx∈K θ̂\n>x+ ϕ(x) 3 for k = 1, 2, . . . do 4 x̂k ← x̂k−1 − 11+λ(x̂k−1,tk)∇ −2ϕ(x̂k−1)∇Φk(x̂k−1)\nThe most difficult part of the analysis is in the following two lemmas, which are crucial elements of the IterativeNewtonStep analysis. A full exposition of these results is found in the excellent survey [15]. The first lemma tells us that when we update the temperature, we don’t perturb the Newton decrement too much. The second lemma establishes the quadratic convergence of the Newton Update for a fixed temperature.\nLemma 1. Let c be the constant chosen in the definition (9). Let t > 0 be arbitrary and let t′ = t (\n1 + c√ ν\n) . Then for any x ∈ int(K), we have λ(x, t′) ≤ (1 + c)λ(x, t) + c.\nLemma 2. Let k be arbitrary and assume we have some x̂k−1 such that λ(x̂k−1, tk) is finite. The Newton update x̂k satisfies λ(x̂k, tk) ≤ 2λ2(x̂k−1, tk).\nThe previous two lemmas can be combined to show that the following invariant is maintained. Neither the constant bound of 1/3 on the Newton decrement nor the choice of c = 1/20 are particularly fundamental; they are convenient for the analysis but alternative choices are possible.\nLemma 3. Assume we choose c = 1/20 for the parameter in (9). Then for all k we have λ(x̂k, tk) < 1 3 .\n1Technically, for ‖ · ‖x and its dual to be a norm, we need ∇2ϕ to be positive definite and ϕ to be strictly convex. One can verify this is the case for bounded sets, which is the focus of this paper.\nProof. We give a simple proof by induction. The base case is satisfied since we assume that λ(x̂0, t0) = 0, as t0 = 1. 2 For the inductive step, assume λ(x̂k−1, tk−1) < 1/3. Then\nλ(x̂k, tk) ≤ 2λ2(x̂k−1, tk) ≤ 2((1 + c)λ(x̂k−1, tk−1) + c)2 < 2(0.4)2 < 1/3.\nThe first inequality follows by Lemma 2 and the second by Lemma 1, hence we are done.\nTheorem 2. Let x∗ be a solution to the objective (1). For every k, x̂k is an k-approximate solution to (1), where k = ν+ √ ν/4\ntk . In particular, for any > 0, as long as k > √ ν c log(2ν/ ) then x̂k is an\n-approximation solution.\nProof. Let k be arbitrary. Then,\nθ̂>(x̂k − x∗) = θ̂>(x̄k − x∗) + θ̂>(x̂k − x̄k) (By (10)) ≤ νtk + θ̂ >(x̂k − x̄k)\n(Hölder’s Inequality) ≤ νtk + ‖θ̂‖ ∗ x̄k ‖x̄k − x̂k‖x̄k\n([15] Eqn. 2.20) ≤ νtk + ‖θ̂‖ ∗ x̄k λ(x̂k,tk) 1−λ(x̂k,tk) (Applying Lemma 3 and (14)) ≤ νtk + ∥∥∥∇ϕ(x̄k)tk ∥∥∥∗x̄k 14 ≤ ν+√ν/4tk\nThe last equation utilizes a fact that derives immediately from the definition (7), namely\n‖∇ϕ∗(x)‖∗x = ‖∇ϕ∗(x)‖θ(x) ≤ √ ν (14)\nholds for any SCBF ϕ with parameter ν, and for any x ∈ K.\nWe proceed to give a specific barrier function that applies to any convex set and gives rise to an efficient algorithm."
    }, {
      "heading" : "4 The Equivalence of IterativeNewton and SimulatedAnnealing",
      "text" : "We now show that the previous two techniques, Iterative Newton’s Method and Simulated Annealing, are in a certain sense two sides of the same coin. In particular, with the appropriate choice of barrier function ϕ the task of computing the sequence of Newton iterates x̂1, x̂2, . . . may be viewed precisely as estimating the means for each of the distributions Pθ1 , Pθ2 , . . .. This correspondence helps to unify two very popular optimization methods, but also provides three additional novel results:\n1. We show that the heat path for simulated annealing is equivalent to the central path with the entropic barrier.\n2As stated, Algorithm 3 requires finding the minimizer of ϕ(·) on K, but this is not strictly necessary. The convergence rate can be established as long as a “reasonable” initial point x̂0 can be computed—e.g. it suffices that λ(x̂0, 1) < 1/2.\n2. We show that the running time of Simulated Annealing can be improved to O(n4 √ ν) from the\nprevious best of O(n4.5). In the most general case we know that ν = O(n), but there are many convex sets in which the parameter ν is significantly smaller. Notably such is the case for the positive-semi-definite cone, which is the basis of semi-definite programming and a cornerstone of many approximation algorithms. Further examples are surveyed in section 4.4.\n3. We show that Iterative Newton’s Method, which previously required a provided barrier function on the set K, can now be executed efficiently where the only access to K is through a membership oracle. This method relies heavily on previously-developed sampling techniques [7]. Discussion is deferred to Appendix C."
    }, {
      "heading" : "4.1 The Duality of Optimization and Sampling",
      "text" : "We begin by rewriting our Boltzmann distribution for θ in exponential family form, Pθ(x) := exp(−θ>x−A(θ)) where A(θ) := log ∫ K exp(−θ >x′)dx′. (15)\nThe function A(·) is known as the log partition function of the exponential family, and it has several very natural properties in terms of the mean and variance of Pθ:\n∇A(θ) = − E X∼Pθ [X] (16)\n∇2A(θ) = E X∼Pθ [(X − EX)(X − EX)>]. (17)\nWe can also appeal to Convex (Fenchel) Duality [17] to obtain the conjugate\nA∗(x) := supθ θ >x−A(θ). (18)\nIt is easy to establish that A∗ is smooth and strictly convex. The domain of A∗(·) is precisely the space of gradients of A(·), and it is straightforward to show that this is the set int(−K), the interior of the reflection of K about the origin. However we want a function defined on (the interior of) K, not its reflection, so let us define a new function A∗−(x) := A\n∗(−x) whose domain is int(K). We now present a recent result of Bubeck and Eldan [2].\nTheorem 3 ([2]). The function A∗− is a ν-self-concordant barrier function on K with ν ≤ n(1 + o(1)).\nOne of the significant drawbacks of barrier/Newton techniques is the need for a readily-available self-concordant barrier function. In their early work on interior point methods, Nesterov and Nemirovskii [16] provided such a function, often referred to as the “universal barrier”, yet the actual construction was given implicitly without oracle access to function values or derivatives. Bubeck and Eldan [2] refer to function A∗−(·) as the entropic barrier, a term we will also use, as it relates to a notion of differential entropy of the exponential family of distributions.\nIt is important to note that, when our set of interest is a cone K, the entropic barrier on K corresponds exactly to the Fenchel dual of the universal barrier on the dual cone K∗ [6], which immediately establishes the self-concordance. Indeed, many beautiful properties of the entropic barrier on cones have been developed, and for a number of special cases A∗−(·) corresponds exactly\nto the canonical barrier used in practice; e.g. A∗−(·) on the PSD cone corresponds to the logdeterminant barrier. In many such cases one obtains a much smaller barrier parameter ν than the n(1 + o(1)) bound. We defer a complete discussion to Section 4.4.\nIn order to utilize A∗−(·) as a barrier function as in (8) we must be able to approximately solve objectives of the form minx∈K{θ>x + A∗−(x)}. One of the key observations of the paper, given in the following Proposition, is that solving this objective correponds to computing the mean of the distribution Pθ.\nProposition 1. Let θ ∈ Rn be arbitrary, and let Pθ be defined as in (15). Then we have\nE X∼Pθ [X] = arg min x∈int(K)\n{ θ>x+A∗−(x) } . (19)\nProof. Let θ be an arbitrary input vector. As we mentioned in (3), standard Fechel duality theory gives us\n∇A(θ) = arg max x∈dom(A∗)\n{ θ>x−A∗(x) } = arg min\nx∈dom(A∗)\n{ −θ>x+A∗(x) } .\nIt can be verified that the domain of A∗ is precisely the interior of −K, the reflection of K. Thus we have\n∇A(θ) = arg min x∈int(−K)\n{ −θ>x+A∗(x) } = − ( arg min x∈int(K) { θ>x+A∗−(x) }) .\nIn addition, we noted in (15) that ∇A(θ) = −EX∼Pθ [X]. Combining the latter two facts gives the result.\nWe now have a direct connection between sampling methods and barrier optimization. For the remainder of this section, we shall assume that our chosen ϕ(·) is the entropic barrier A∗(·), and the quantities Φk(·), ‖ · ‖x, λ(·, ·) are defined accordingly. We shall also use the notation x(θ) := EX∼Pθ [X] = −∇A(θ). Lemma 4. Let θ, θ′ be such that ‖x(θ′)− x(θ)‖x(θ) ≤ 12 . Then we have\nDA∗−(x(θ ′), x(θ)) = KL(P ′θ, Pθ) = DA(θ, θ ′) ≤ 2‖x(θ′)− x(θ)‖2x(θ) (20)\nProof. The duality relationship of the Bregman divergence, and its equivalence to Kullback-Leibler divergence, is classical and can be found in, e.g., [20] equation (5.10) The final inequality follow as a direct consequence of [15], Equation 2.4."
    }, {
      "heading" : "4.2 Equivalence of the heat path and central path",
      "text" : "The most appealing observation on the equivalence between random walk optimization and interior point methods is the following geometric equivalence of curves. For a given convex set K ⊆ Rd and objective θ̂, define the heat path as the following set of points:\nHeatPath = ∪ t≥0 {HeatPath(t)} = ∪ t≥0 { E x∼P θ̂\nt\n[x]}\nTo see that this set of points is a continuous curve in space, consider the central path w.r.t. barrier function ϕ(x):\nCentralPath(ϕ) = ∪ t≥0 {CentralPath(t, ϕ)} = ∪ t≥0 {arg min x∈K {tθ̂>x+ ϕ(x)}\nIt is well known that the central path is a continuous curve in space for any self-concordant barrier function φ. We now have the following immediate corollary of Proposition 1:\nCorollary 2. The central path corresponding to the self-concordant barrier A∗ over any set K is equivalent to the heat path over the same set, i.e.\nHeatPath ≡ CentralPath(A∗)\nThis mathematical equivalence is demonstrated in figure 2 generated by simulation over a polytope."
    }, {
      "heading" : "4.3 IPM techniques for sampling and the new schedule",
      "text" : "We now prove our main theorem, formally stated as: Theorem 4. The temperature schedule of θ1 = R where R = diam(K) and θk := (\n1− 1 4 √ ν\n) θk−1,\nfor ν being the self-concordance parameter of the entropic barrier for the set K, satisfies condition (6) of theorem 1. Therefore algorithm 2 with this schedule returns an -approximate solution in time Õ( √ νn4).\nCondition (6) is formally proved in the following lemma, which crucially uses the interior point methodology, namely Lemma 3.\nLemma 5. Consider distributions Pθ and Pθ′ where θ ′ = (1 + γ)θ for γ < 1\n6 √ ν . Then we have the\nfollowing bound on the `2 distance between distributions:\nmax {∥∥∥∥ PθP(1+γ)θ ∥∥∥∥\n2\n, ∥∥∥∥P(1+γ)θPθ ∥∥∥∥\n2\n} ≤ 10\nProof. We first show by elementary linear algebra that\n‖Pθ/P(1−γ)θ‖ = ‖Pθ/P(1+γ)θ‖ = exp(DA((1 + γ)θ, θ) +DA((1− γ)θ, θ)).\nLet us consider the log of the 2-norm:\nlog ‖Pθ/P(1+γ)θ‖ = log ∫ K exp(−θ>x−A(θ)) exp(−(1 + γ)θ>x−A((1 + γ)θ)) dPθ\n= log ∫ K exp(γθ>x−A(θ) +A((1 + γ)θ))dPθ\n= log ∫ K exp(γθ>x−A(θ) +A((1 + γ)θ)) exp(−θ>x−A(θ))dx\n= A((1 + γ)θ)− 2A(θ) + log ∫ K exp(−(1− γ)θ>x)dx = A((1 + γ)θ)− 2A(θ) +A((1− γ)θ) = DA((1 + γ)θ, θ) +DA((1− γ)θ, θ).\nReplacing γ by −γ, we get a completely symmetrical expression. Next, we observe that\n‖Pθ(1+γ)/Pθ‖ = ‖Pθ̃/Pθ̃(1−γ̃)‖\nwhere θ̃ = θ(1 + γ) and 1− γ̃ = 11+γ = 1− γ 1+γ , thus γ̃ ∈ γ × [1, 2]. By this observation, both sides of the lemma follow if we prove an upper bound∥∥∥∥ PθP(1+γ)θ ∥∥∥∥ 2 ≤ 10 for γ < 1 6 √ ν × 2 = 1 3 √ ν\nLemma 1 implies λ(x(θ), 1 + γ) ≤ (1 + c)λ(x(θ), 1) + c = c ≤ 14 . Applying Lemma 4,\nDA((1 + γ)θ, θ) ≤ 2‖x(θ)− x((1 + γ)θ)‖2x((1+γ)θ) Lemma 4 ≤ 2 (\nλ(x(θ),1+γ) 1−λ(x(θ),1+γ)\n)2 (2.28) in [15]\n≤ 2 (\nc 1−c\n)2 < 2 (1/3) 2\n(2/3)2 = 12 Lemma 1\nNotice that to apply Lemma 4, we need the point x((1 + γ)θ) to lie in the Dikin ellipsoid of x(θ), which is exactly whats proved in the last two lines of the above proof.\nThe bound on DA((1−γ)θ, θ) follows in precisely the same fashion, by similar change of variables as before (again, the condition for applying Lemma 4 is proven in the last few lines of the equations\nbelow):\nDA((1− γ)θ, θ) = DA(θ̃, θ̃(1 + γ̃)) ≤ 2‖x(θ̃)− x((1 + γ̃)θ̃)‖2\nx(θ̃) Lemma 4 ≤ 2 ( λ(x(θ̃),1+γ̃)\n1−λ(x(θ̃),1+γ̂)\n)2 (2.27) in [15]\n≤ 2 (\nc 1−c\n)2 < 2 (1/3) 2\n(2/3)2 = 12 Lemma 1\nIt follows that ‖Pθ/P(1+γ)θ‖ ≤ eDA((1+γ)θ,θ)+DA((1−γ)θ,θ) ≤ e 1 2 + 1 2 ≤ 10."
    }, {
      "heading" : "4.4 Some history on the entropic barrier and the universal barrier for cones",
      "text" : "Let K be a cone in Rn and let K∗ = {θ : θ>x ≥ 0 ∀x ∈ K} be its dual cone. We note that a cone K is homogeneous if its automorphism group is transitive; that is, for every x, y ∈ K there is an automorphism B : K → K such that Bx = y. Homogeneous cones are very rare, but one notable example is the PD cone (matrices with all positive eigenvalues). Given any point x ∈ K, we can define a truncated region of K∗ as the set K∗(x) := {y ∈ K∗ : x>y ≤ 1}. Nesterov and Nemirovskii [16] defined the first generic self-concordant barrier function, known as the universal barrier in terms of these regions. Namely, they show that the function\nuK(x) := log(vol(K ∗(x)))\nis a self concordant barrier function with an O(n) parameter. There is an alternative characterization of the universal barrier in terms of the larg partition function. Let FK(x) := log ∫ K∗ exp(θ >x)dθ and equivalently let FK∗(θ) := log ∫ K exp(θ\n>x)dx. It was shown by Güler [5] that\nFK(x) = uK(x) + n!,\nthat is, the universal barrier corresponds exactly to a log-partition function but defined on the dual cone K∗, modulo a simple additive constant. We note that this is not the entropic barrier construction we have here, as our function of interest is A∗−(·) ≡ F ∗K∗(·) (the Fenchel conjugate of FK∗(x)), and not FK(x). However, it was also shown by Güler [5] that, when K is a homogeneous cone, we have the identity FK(·) ≡ F ∗K∗(·); in other words, the universal barrier and the entropic barrier are equivalent for homogeneous cones.\nIt is worth noting that, following the connection of Güler [5], A∗−(·) is (up to additive constant) the Fenchel conjugate of the universal barrier uK∗ forK\n∗. It was shown by Nesterov and Nemirovskii [16] (Theorem 2.4.1) that Fenchel conjugation preserves all required self concordance properties and in particular if g is a ν-self-concordant barrier for a cone K, then g∗ will be a self-concordant barrier for K∗ with the same parameter ν. With this observation it follows immediately that the entropic barrier F ∗K∗(·) on K is an O(n)-self-concordant barrier. Bubeck and Eldan [2] took this statement further, proving that F ∗K∗(·) enjoys an essentially optimal self-concordance parameter ν = n(1 + o(1)).\nIt is important to note that the assumption that the set of interest is a cone is, roughly speaking, without loss of generality. Given any convex set U ⊂ Rn we have the fitted cone K(U) := {α(x, 1) : x ∈ U,α ≥ 0} ⊆ Rn+1. Hence once can always work with the barrier function F ∗K(U)∗(·) on K(U),\nand take its restriction to the set U × {1} ⊂ K(U) to obtain a barrier on U (affine restriction preserves the barrier properties).\nWe conclude by summarizing several results in Güler [5] regarding the entropic barrier for various cones, as well as the associated barrier parameter of each. In these canonical cases the entropic barrier corresponds exactly to the “typical” barrier, up to additive and multiplicative constants. We use the notation f(·) ∼= g(·) to denote that f and g are identical up to additive constants.\n1. Assume K := Rn+ the nonnegative orthant. This is a homogeneous cone and we have FK(x) ∼= F ∗K∗(x) ∼= − ∑n i=1 log xi. This is the optimal barrier for K and the barrier parameter is ν = n.\n2. Assume K := {x ∈ Rn : x21 + . . .+x2n−1 ≤ x2n} be the Lorentz cone. K is a homogeneous self-dual cone. K can also be described by the fitted cone of the radius-1 L2 ball, so we may parameterize elements of K as α(x, 1) where α ≥ 0 and x is vector in Rn−1 with L2 norm bounded by 1. Then FK(α(x, 1)) ∼= F ∗K∗(α(x, 1)) ∼= − n+1 2 log(α\n2 − x2). This barrier has parameter ν = n + 1 which is indeed not optimal, one has the optimal barrer − log(α2 − x2) which has parameter ν = 2, but this is simply a scaled version of the entropic barrier.\n3. The PSD cone K of positive semi-definite matrices, i.e. symmetric matrices with non-negative eigenvalues, is a homogeneous self-dual cone. The entropic barrier is FK(x) ∼= F ∗K∗(x) ∼= −n+12 log det(x) and exhibits a parameter of ν = n(n+1) 2 which is multiplicatively n+1 2 worse\nthan the optimal barrier, the log-determined − log det(x). However, as can be seen this barrier is quite simply a scaled version of the entropic barrier."
    }, {
      "heading" : "A An Explanation of Newton’s Method via Reweighting",
      "text" : "Proposition 1 brings out a strong connection between interior point techniques and the ability to sample from Boltzmann distributions. But with this stochastic viewpoint, it is not immediately clear why Newton’s method is an appropriate iterative update scheme for optimization. We now provide some evidence along these lines.\nAssuming we have already computed (an approximation of) x(θ), and our distribution parameter is updated to a “nearby” θ′, our goal is now to compute the new mean x(θ′).\n−x(θ′) = ∫ K x dPθ′ = ∫ K x dPθ′(x) dPθ(x) dPθ = E X∼Pθ [ X exp(X>(θ − θ′) +A(θ′)−A(θ)) ] Think of the last term as the reweighting factor. Now we are going to rewrite A(θ) − A(θ′) = −∇A(θ)(θ′−θ)−DA(θ′, θ) = x(θ)>(θ′−θ)−KL(Pθ, Pθ′). We shall use the following approximation of the exponential: exp(z) ≈ 1 + z for small values of z. Proceeding,\n−x(θ′) = E X∼Pθ\n[ X exp(X>(θ − θ′)− x(θ)>(θ′ − θ) + KL(Pθ, Pθ′)) ] = eKL(Pθ,Pθ′ ) E\nX∼Pθ\n[ X exp((X − x(θ))>(θ′ − θ)) ] ≈ eKL(Pθ,Pθ′ ) E\nX∼Pθ\n[ X(1 + (X − x(θ))>(θ′ − θ)) ] = eKL(Pθ,Pθ′ )(−x(θ) + Σθ(θ′ − θ)).\nDuality theory tells us that Σθ = ∇2A(θ) = ∇−2A∗(x(θ)) and θ′− θ is precisely the gradient of the objective θ′>x−A∗(x) at the point x(θ). The eKL(Pθ,Pθ′ ) term is somewhat mysterious, but it can be interpreted as something of a “damping” factor akin to the Newton decrement damping of the the Newton update."
    }, {
      "heading" : "B Proof structure of the Kalai-Vempala theorem",
      "text" : "We hereby sketch the structure of the proof of theorem 1 for completeness. Recall the statement of the theorem:\nAlgorithm 2 with a temperature schedule that satisfies the following condition:\nThe successive distributions are not “too far” in total variational distance. That is, for every j,\nmax {∥∥∥∥ PθjPθj−1 ∥∥∥∥\n2\n, ∥∥∥∥Pθj−1Pθj ∥∥∥∥\n2\n} ≤ 10\nGuarantees that HitAndRun requires N = Õ(n3) steps in order to ensure mixing to the stationary distribution Pθj .\nProof sketch. The proof is based on iteratively applying the following Theorem from [12]:\nTheorem 5. Let f be a density proportional to e−a T x over a convex set K such that\n[a]. the level set of probability 1/64 contains a ball of radius s\n[b]. Ef (‖x− µf‖2) ≤ S, where µf = Ef [x] is the mean of f\n[c]. the `2 norm of the starting distribution σ w.r.t. the stationary distribution of HitAndRun denoted πf , is at most M.\nLet σm be the distribution of the current point after m steps of HitAndRun applied to f. Then, for any τ > 0, after m = O(n 2S2\ns2 log5 nMτ ) steps, the total variation distance of σ m and πf is less than τ .\nThe proof proceeds to show that conditions [a]-[c] of the theorem above are all satisfied if indeed condition (6) is satisfied, along the steps below. Once it is established that the conditions of the theorem hold, then the next HitAndRun walk mixes and computes warm start and variance estimates for the next epoch. Then again, the conditions of the theorem hold, and this whole process is repeated for the entire temperature schedule.\nTo show conditions [a]-[c], first notice that condition (6) is essentially equivalent to condition [c] above. Thus we only need to worry about conditions [a],[b].\n[I]. For simplicity, we assumed that at the current iteration, Σj = I is the identity. This can be assumed by a transformation of the space, and allows for simpler discussion of isotropy of densities (otherwise, the isotropy condition would be replaced by relative-isotropy w.r.t the current variance).\n[II]. A density f is C-isotropic if for any unit vector ‖v‖ = 1,\n1 C ≤ ∫ Rn (v>(x− µf ))2f(x)dx ≤ C\nIt is shown (Lemma 4.2) that if the density given by f is O(1)-isotropic, then conditions [a],[b] are satisfied with Ss = Õ( √ n).\n[III]. It is shown (Lemma 4.3) that if f is C-isotropic, and max {∥∥∥fg∥∥∥2 , ∥∥∥ gf ∥∥∥2} ≤ D, then g is\nCD-isotropic.\n[IV]. Since condition (6) holds, together with the previous points [II,III] this implies that fθj+1 is isotropic for some constant. Thus, conditions [a]-[c] of Theorem 5 hold. Therefore we can sample sufficiently many samples to estimate the covariance matrix Σj+1 and proceed to the next epoch.\nThroughout the proof special care needs to be taken to ensure that repeated samples are nearlyindependent for various concentration lemmas to apply, we omit discussion of these and the reader is referred to the original paper of [7].\nC Interior point methods with a membership oracle\nBelow we sketch a universal IPM algorithm - one that applies to any convex set described by a membership oracle - that can be implemented to run in polynomial time. This algorithm is an instantiation of Algorithm 3 with the particular barrier function A∗(x) as defined in section 4.1.\nWithout loss of generality, we can assume our goal is to (approximately) compute the update direction\n∇−2A∗(x)(θ −∇A∗(x))\nfor some x which is already within the Dikin ellipsoid of radius 1/2 around x(θ). First, we note that the IPM analysis of [15] allows one to replace the inverse hessian ∇−2A∗(x) with the nearby ∇−2A∗(x(θ)) = CovMtx(Pθ). Of course the latter can be estimated via sampling, in the sense that the estimate Σ̂ will be “ -isotropically close”:\n(1− )v>∇2Ψ(θ′)v ≤ v>Σ̂v ≤ (1 + )v>∇2Ψ(θ′)v\nfor any unit vector v. See, for example, [1] on the concentration of empirical covariance matrices. It remains to compute ∇A∗(x). Define θ(x) to be\nθ(x) = arg max θ θ · x− log ∫ K exp(−θ · y)dy = ∇A∗(x) (21)\nThen θ(x) can be computed in polynomial time by another interior point algorithm – this problem, however, is much simpler to work with. Define Ψ(θ′) := θ·x−log ∫ K exp(−θ·y)dy to be the objective we want to optimize. Notice that ∇Ψ(θ′) = x − EX′∼Pθ′ [X ′] and the latter can be estimated to within via SimulatedAnnealing with Õ(n/ 2) samples. The hessian ∇2Ψ(θ′) = −CovMtx(Pθ′) can similarly be estimated with an -isotropically close empirical covariance. Because the error gap is multiplicatively close to 1, the inverse operation on ∇2Ψ(θ′) maintains the approximation."
    } ],
    "references" : [ ],
    "referenceMentions" : [ ],
    "year" : 2015,
    "abstractText" : "<lb>This paper explores a surprising equivalence between two seemingly-distinct convex opti-<lb>mization methods. We show that simulated annealing, a well-studied random walk algorithms,<lb>is directly equivalent, in a certain sense, to the central path interior point algorithm for the the<lb>entropic universal barrier function. This connection exhibits several benefits. First, we are able<lb>improve the state of the art time complexity for convex optimization under the membership<lb>oracle model. We improve the analysis of the randomized algorithm of Kalai and Vempala [7]<lb>by utilizing tools developed by Nesterov and Nemirovskii [16] that underly the central path fol-<lb>lowing interior point algorithm. We are able to tighten the temperature schedule for simulated<lb>annealing which gives an improved running time, reducing by square root of the dimension<lb>in certain instances. Second, we get an efficient randomized interior point method with an<lb>efficiently computable universal barrier for any convex set described by a membership oracle.<lb>Previously, efficiently computable barriers were known only for particular convex sets. 1<lb>ar<lb>X<lb>iv<lb>:1<lb>50<lb>7.<lb>02<lb>52<lb>8v<lb>2<lb>[<lb>m<lb>at<lb>h.<lb>O<lb>C<lb>]<lb>5<lb>N<lb>ov<lb>2<lb>01<lb>5",
    "creator" : "LaTeX with hyperref package"
  }
}