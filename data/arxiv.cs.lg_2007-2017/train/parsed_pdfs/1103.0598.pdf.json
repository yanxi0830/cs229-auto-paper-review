{
  "name" : "1103.0598.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "Learning transformed product distributions",
    "authors" : [ "Constantinos Daskalakis", "Ilias Diakonikolas", "Rocco A. Servedio" ],
    "emails" : [ "costis@csail.mit.edu", "ilias@cs.berkeley.edu", "rocco@cs.columbia.edu" ],
    "sections" : [ {
      "heading" : null,
      "text" : "ar X\niv :1\n10 3.\n05 98\nv1 [\ncs .L\nG ]\n3 M\nar 2\n01 1\nInformation-theoretic arguments show that for every transformation function f the corresponding learning problem can be solved to accuracy ǫ, using Õ(n/ǫ2) examples, by a generic algorithm whose running time may be exponential in n. We show that this learning problem can be computationally intractable even for constant ǫ and rather simple transformation functions. Moreover, the above sample complexity bound is nearly optimal for the general problem, as we give a simple explicit linear transformation function f (x) = w · x with integer weights wi ≤ n and prove that the corresponding learning problem requires Ω(n) samples.\nAs our main positive result we give a highly efficient algorithm for learning a sum of independent unknown Bernoulli random variables, corresponding to the transformation function f (x) = ∑n i=1 xi. Our algorithm learns to ǫ-accuracy in poly(n) time, using a surprising poly(1/ǫ) number of samples that is independent of n. We also give an efficient algorithm that uses log n · poly(1/ǫ) samples but has running time that is only poly(log n, 1/ǫ)."
    }, {
      "heading" : "1 Introduction",
      "text" : "We consider the problem of learning an unknown product distribution that has been transformed according to a known function f . This is a simple and natural learning problem, but one which does not seem to have been explicitly studied in a systematic way from a computational learning theory perspective.\nMore precisely, in this paper we restrict our model to the natural case when the input distribution is a a product distribution over the Boolean cube {0, 1}n. In this learning scenario the learner is provided with samples from the random variable f (X), where X = (X1, . . . , Xn) is a vector of independent 0/1 Bernoulli random variables Xi whose expectations are unknown to the learner. We write p = (p1, . . . , pn) ∈ [0, 1]n to denote E[X], and refer to p as the target vector of probabilities; we shall sometimes write f (p) to denote the random variable f (X) described above. Using these samples, the learner must with probability 1 − δ 1 output a hypothesis distribution H over f ({0, 1}n) such that the total variation distance dTV( f (X),H) is at most ǫ. A proper learning algorithm in this framework outputs a hypothesis vector p̂ ∈ [0, 1]n defining a hypothesis distribution f (X̂), where X̂ = (X̂1, . . . , X̂n) is a vector of independent 0/1 Bernoulli random variables X̂i whose expectation is E[X̂] = p̂.\nWe emphasize that in this learning scenario, the transformation function f is fixed and known to the learner; the choice of a particular transformation function f specifies a particular learning problem in this model, much as the choice of a concept class C specifies a learning problem in Valiant’s PAC learning model. We will be interested in both the computational complexity (running time) and sample complexity (number of samples required) for algorithms that solve this problem, for different transformation functions f .\n∗Research supported by NSF CAREER award CCF-0953960 and by a Sloan Foundation Fellowship. †Research supported by a Simons Foundation Postdoctoral Fellowship. Most of this work was done while at Columbia University, supported by NSF grant CCF-0728736, and by an Alexander S. Onassis Foundation Fellowship. ‡Supported by NSF grants CCF-0347282, CCF-0523664 and CNS-0716245, and by DARPA award HR0011-08-10069. 1For ease of exposition we state all our positive results throughout the paper with δ fixed to 1/10. All our results extend to general δ with a log(1/δ) overhead in sample complexity."
    }, {
      "heading" : "1.1 Motivation, examples, and connection to prior work",
      "text" : "Our motivation for considering this model is twofold. First, we feel that it is so simple and natural as to warrant study for its own sake. Second, we believe that it offers a useful perspective on modeling probability distributions in settings where the underlying source of randomness is not directly accessible to the learner. In many settings we may wish to understand some phenomenon (in the physical world, in a market, etc.) where the available observations can be viewed as the output of a transformation f applied to some underlying random source X; learning an accurate approximation of the distribution of f (X) is a natural goal in such a setting. (The restriction on X imposed in this paper – that it is a product of independent Bernoulli random variables – admittedly represents an idealized scenario, but it is a natural starting point for theoretical study.) It is plausible that in such a situation the transformation function f may be well understood (as a consequence of our knowledge of the laws governing the physical world, the marketplace, etc.), but that much less is known about the parameters of the underlying random variable X (we may have no direct access to this random variable, it could represent private information, etc.). This corresponds to our model’s assumption that f is “known” and the task is to infer the parameters of X that give rise to the observed data.\nExamples: As a simple example to illustrate our learning model, we consider the product distribution learning problem for f where f is any read-once AND-gate function. A function f : {0, 1}n → {0, 1}m, f (x) = ( f1(x), . . . , fm(x)) is a read-once AND-gate function if each fi(x) is an AND over some subset S i ⊆ [n] of the n input bits x1, . . . , xn and the sets S 1, . . . , S m are pairwise disjoint. It is not hard to see that there is a straightforward proper learning algorithm based on linear programming that succeeds for any read-once AND-gate function regardless of the fanin of the AND gates (see Appendix A):\nObservation 1.1 Let f : {0, 1}n → {0, 1}m be any fixed read-once AND-gate function (known to the learner). There is an algorithm that uses poly(n, 1/ǫ) samples from the target distribution f (p), runs in poly(n, 1/ǫ) time, and with probability at least 9/10 outputs a hypothesis vector p̂ such that dTV( f (p), f ( p̂)) ≤ ǫ.\nAs a second example, we point out that the transformed product distribution learning model is broad enough to encompass the problem of learning an unknown mixture of k product distributions over {0, 1}n that was considered by Freund and Mansour (1999), Cryan et al. (2002), Feldman et al. (2008). For simplicity we describe the case k = 2: there are unknown product distributions p, q over {0, 1}n and unknown mixing weights πp, πq = 1 − πp. The learner is given independent draws from the mixture distribution (each draw is independently taken from p with probability πp and from q with probability πq), and must output hypothesis product distributions p̂, q̂ and hypothesis mixing weights π̂p, π̂q. This problem is easily seen to be equivalent to the transformed product distribution learning problem for the function f : {0, 1}2n+1 → {0, 1}n which is such that on input (z, x1, . . . , xn, y1, . . . , yn) ∈ {0, 1}2n+1 the i-th bit of f ’s output is zxi + (1 − z)yi. It is easy to see that if the target vector of probabilities for f is (πp, p1, . . . , pn, q1, . . .qn) then samples of f are distributed exactly according to the mixture of product distributions, and finding a good hypothesis vector in [0, 1]2n+1 amounts to finding a hypothesis mixing weight π̂p and hypothesis product distributions p̂, q̂ as required in the original “learning mixtures of product distributions” problem.\nConnection to prior work: The transformed product distribution learning model is related to the PACstyle model of learning discrete probability distributions that was introduced by Kearns et al. (1994) and studied in several subsequent works of Naor (1996), Ambainis et al. (1997), Farach and Kannan (1999), Freund and Mansour (1999), Cryan et al. (2002), Feldman et al. (2008). In the Kearns et al. (1994) framework a learning problem is defined by a class C of Boolean circuits, and an instance of the problem corresponds to the choice of a specific (unknown to the learner) target circuit C ∈ C. The learner is given samples from C(X) where X is a uniform random string from {0, 1}m, and the learner must with high probability output a hypothesis circuit C′ such that the random variable C′(X) is ǫ-close to C(X) (in KL-divergence).\nStrictly speaking the transformed product distribution learning model may be viewed as a special case of the Kearns et al model. This is done by considering a circuit class C that has a circuit C = Cp for each possible product distribution p over {0, 1}n; the circuit Cp first transforms the uniform distribution over {0, 1}m to the product distribution p over {0, 1}n and then applies the transformation function f to the output of p. However, learning problems C of this sort do not seem to have been previously considered in the Kearns et al. (1994) model, and we feel it is more natural to view our model as dual in spirit to the earlier model. In Kearns et al. (1994) the learner’s task is to infer an unknown transformation (the circuit C) into which are fed n-bit strings that are known to be distributed uniformly. In our case the transformation function f is known to the learner but the underlying product distribution that is fed into f is unknown and must be inferred."
    }, {
      "heading" : "1.2 Our results and techniques",
      "text" : "We establish a range of positive and negative results for this learning problem, both for general functions and for particular transformation functions of interest. For most of this paper we focus on the case in which f (X) is simply a real-valued random variable, i.e. f is a transformation mapping {0, 1}n to R.\nWe begin by considering the most general possible setting, in which the transformation function f can be any function mapping the domain {0, 1}n into any range. By an approach similar to the algorithm of Devroye and Lugosi (2001) for choosing a density estimate, we show (Theorem 6) that if the space { f (p)}p∈[0,1]n of all f -transformed product distributions has an ǫ-cover of size N, then there is a generic learning algorithm for the f -transformed product distribution problem that uses O((log N)/ǫ2) samples. The algorithm works by carrying out a tournament that matches every pair of distributions in the cover against each other; our analysis shows that with high probability some ǫ-accurate distribution in the cover will survive the tournament undefeated, and that any undefeated tournament will with high probability be highly accurate.\nAs an immediate consequence of the general result Theorem 6 we get that for any transformation function f there is an algorithm that learns to accuracy ǫ using Õ(n/ǫ2) samples:\nTheorem 1 (Information-theoretic upper bound for any f ) Let f : {0, 1}n → Ω be an arbitrary function where Ω is any range set. There is an algorithm that uses O((n/ǫ2) · log(n/ǫ)) samples from the target distribution f (p), runs in time (n/ǫ)O(n), and with probability at least 9/10 outputs a hypothesis vector p̂ such that dTV( f (p), f ( p̂)) ≤ ǫ.\nSince an ǫ-cover of the space of all f -transformed product distributions may have size exponential in n, Theorem 1 does not in general provide a computationally efficient algorithm. Indeed, in Appendix C we show that the learning problem can be computationally hard even for rather simple transformation functions: using a reduction to the PARTITION problem, we prove:\nTheorem 2 (NP-hardness) Suppose NP * BPP. Then there is an explicit degree-2 polynomial f : {0, 1}n → R such that there is no polynomial-time algorithm that solves the transformed product distribution learning problem for f to accuracy ǫ = 1/3.\nWe also show that even for a simple linear transformation function f (x) = w · x with small integer weights, it can be impossible to significantly improve on the Õ(n) sample complexity of the generic algorithm from Theorem 1. In Appendix D we prove:\nTheorem 3 (Sample complexity lower bound) Fix any even k ≤ n and let f (x) = ∑k\ni=k/2+1 ixi. Let L be any learning algorithm that outputs a hypothesis vector p̂ such that dTV( f (p), f ( p̂)) ≤ 1/40 with probability at least e−o(k). Then L must use Ω(k) samples from f (p).\nThese negative results provide strong motivation for considering what is perhaps the most natural of all transformation functions mapping {0, 1}n to R, the sum f (x) = ∑n i=1 xi; we refer to the corresponding learning problem as “learning an unknown sum of Bernoulli random variables.” Our main contribution is a detailed study of this learning problem.\nLearning sums of Bernoullis from constantly many samples. As our main result, we show that any sum of independent unknown Bernoulli random variables can be efficiently approximated to ǫ-accuracy by a proper learning algorithm that uses poly(1/ǫ) samples, independent of n. More precisely, we prove:\nTheorem 4 (Learning sums of Bernoullis from constantly many samples) Let f (x) = ∑n\ni=1 xi. There is an algorithm that uses poly(1/ǫ) samples from the target distribution f (p), runs in time n3 · poly(1/ǫ) + n · (1/ǫ)O(log\n2(1/ǫ)), and with probability at least 9/10 outputs a hypothesis vector p̂ ∈ [0, 1]n which is such that dTV( f (p), f ( p̂)) ≤ ǫ.\nIt should be stressed that the generic algorithm of Theorem 6 requiresΩ((1/ǫ2)·log n) samples for this learning problem (easy arguments give an nΩ(1) lower bound on the size of any cover for sums of Bernoullis). We view this sample complexity independent of n as a surprising result which may find subsequent applications. We next give a brief overview of the obstacles that appear and the techniques involved in our proof.\nAs a first step in the proof of Theorem 4, we observe that a simple learning algorithm using O(1/ǫ2) samples gives a hypothesis which has error at most ǫ with respect to the Kolmogorov distance (see Section 2). While the algorithm itself is simple, its analysis relies on a fundamental result from probability theory, known as the Dvoretzky-Kiefer-Wolfowitz inequality (Dvoretzky et al. (1956)), which may be viewed as a special case of the fundamental Vapnik-Chervonenkis theorem (see Chapter 3 of Devroye and Lugosi (2001)). In Appendix E we give a self-contained proof of the DKW inequality using elementary techniques (martingales and the method of bounded differences) and an interesting trick that goes back to Kolmogorov (see Peres (2009)); this proof is significantly different from the proofs we know of in the probability literature (see Dvoretzky et al. (1956), Massart (1990), and Chapter 3 of Devroye and Lugosi (2001)).\nA natural attempt is to use Kolmogorov approximation as a black box to obtain an approximation in total variation distance. In the special case when X is a sum of Bernoulli random variables and Y is a binomial\ndistribution B(n, p) (i.e. all the Bernoullis Y1, . . . , Yn have the same mean p), it is indeed possible to bound the total variation distance between X and Y as a function of their Kolmogorov distance. It can be shown that in this case the distributions of X and Y cross each other at most a constant number of times, and this is easily seen to imply that the two distances (total variation and Kolmogorov) are within a constant factor. This fact about crossings goes back to an argument by Newton (c.f. Hardy et al. (1934) section 2.22), establishing that the sequence ak = Pr[X = k]/ Pr[Y = k] is log-concave if Y is binomially distributed.\nUnfortunately, if X and Y are both generic sums of independent Bernoullis with arbitrary means (as in our setting), then such a bound is not known in the literature, and indeed it seems that essentially nothing is known about the relation between the two distances in this general case. Without such a bound, it is rather unclear whether a number of samples that does not scale with n suffices to accurately learn in total variation distance. Nevertheless, we extend the Kolmogorov distance learning algorithm to total variation distance via a delicate algorithm that exploits the detailed structure of a small ǫ-cover (Daskalakis and Papadimitriou (2011), Daskalakis (2008)) of the space of all distributions that are sums of independent Bernoulli random variables (see Theorem 9). Interestingly, this becomes feasible by establishing an analog of the aforementioned argument by Newton to a class of distributions used in the cover that are called heavy (see Lemma 15). This in turn relies on probabilistic approximation results via translated Poisson distributions (see Definition 18, Röllin (2006)).\nLearning sums of Bernoullis in sublinear time. While the poly(1/ǫ) sample complexity of Theorem 4 is essentially optimal2, the running time is poly(n) (and superpoly(1/ǫ)). Moreover, generating a single sample from the hypothesis product distribution requires Ω(n) uniformly random bits. In general, any proper learning algorithm that explicitly outputs a hypothesis vector p̂ ∈ [0, 1]n will take Ω(n) running time, and generating a sample from the hypothesis f ( p̂) will require Ω(n) random bits.\nMore broadly, any algorithm (not necessarily proper) for learning sums of Bernoullis must have running time Ω((1/ǫ2) · log n) in the bit model (since each sample is an Ω(log n) bit string and Ω(1/ǫ2) samples are needed). Generating a sample from an arbitrary hypothesis distribution will in general require Ω(log n) bits (since the entropy of the binomial distribution is Ω(log n)). Hence a natural goal is to have a learning algorithm that runs in poly(log n, 1/ǫ) time and requires O(log n) bits of randomness to generate a draw from its hypothesis distribution. As discussed in the previous paragraph, such an algorithm needs to be non-proper.\nWe show that there is an algorithm that satisfies all of these efficiency considerations, at the cost of a log n factor in the sample complexity:\nTheorem 5 (Learning sums of Bernoullis in polylog(n) time with efficient hypotheses) Let f (x) = ∑n\ni=1 xi. There is an algorithm that uses log(n) ·poly(1/ǫ) samples from the target distribution f (p), performs log2(n) · poly(1/ǫ) bit operations, and with probability at least 9/10 outputs a (succinct representation of a) hypothesis distribution H over {0, 1, . . . , n} such that dTV ( f (X),H) ≤ ǫ. Moreover, a draw from the hypothesis distribution H can be obtained in poly(log n, 1/ǫ) time using O(log(n/ǫ)) bits of randomness.\nThe key to Theorem 5 is the simple observation that any sum of Bernoullis is a unimodal distribution over the domain {0, 1, . . . , n}. This lets us apply a powerful algorithm due to Birgé (1997) that can learn any unimodal distribution to accuracy ǫ using O(log n)/ǫ3 samples. The algorithm outputs a hypothesis distribution that is a histogram over O((log n)/ǫ) intervals that cover {0, . . . , n}: more precisely, the hypothesis is uniform within each interval, and for each interval the total mass it assigns to the interval is simply the fraction of samples that landed in that interval. Thus, the hypothesis distribution has a succinct description and can be efficiently evaluated using a small amount of randomness. We give details in Appendix F.\nWe remark that by applying the algorithm of Theorem 5 to the hypothesis distribution that is provided by Theorem 4, one can obtain a 2ǫ-accurate hypothesis satisfying the efficiency conditions of Theorem 5 (i.e. the hypothesis can be evaluated in poly-logarithmic time and a sample from it can be generated using O(log(n/ǫ)) random bits). Thus, it is possible to construct an ǫ-accurate efficient hypothesis using poly(1/ǫ) samples and poly(n) time. Whether this can be achieved in poly-logarithmic time is an interesting and challenging open problem; we discuss this and other questions for future work in Section 6."
    }, {
      "heading" : "2 Preliminaries",
      "text" : "Recall that the total variation distance between two distributionsP andQ over a finite domain D is dTV (P,Q) := (1/2) · ∑ α∈D |P(α) − Q(α)|. Similarly, if X and Y are two random variables ranging over a finite set, their total variation distance dTV(X, Y) is defined as the total variation distance between their distributions. Another notion of distance between distributions/random variables that we use is the Kolmogorov distance. For two distributionsP andQ supported on R, their Kolmogorov distance is dK (P,Q) := supx∈R |P((−∞, x]) − Q((−∞, x])| .\n2An easy reduction to distinguishing a fair coin from an ǫ-biased coin shows that any learning algorithm for this problem needs Ω(1/ǫ2) samples.\nSimilarly, if X and Y are two random variables ranging over a subset of R, their Kolmogorov distance, denoted dK(X, Y), is the Kolmogorov distance between their distributions. If two distributions P and Q are supported on a finite subset of R we obtain immediately that dK (P,Q) ≤ 2 · dTV (P,Q) .\nFix a finite domain D, and let P denote some set of distributions over D. Given δ > 0, a subset Q ⊆ P is said to be a δ-cover of P (w.r.t. total variation distance) if for every P in P there exists some Q in Q such that dTV(P,Q) ≤ δ.\nWe write S = Sn to denote the set of all product distributions over {0, 1}n, and f (S) to denote the set of all transformed product distributions { f (p)}p∈S. We write f (p)(α) to denote the probability of outcome α under distribution f (p). Finally, for ℓ ∈ Z+ we write [ℓ] to denote {1, . . . , ℓ}."
    }, {
      "heading" : "3 A generic algorithm for any f and some lower bounds",
      "text" : "In this section we give a simple generic algorithm to solve the transformed product distribution learning problem for any transformation function f , and state some lower bounds showing that even for rather simple functions f , the time and sample complexity of the generic algorithm may be essentially the best possible."
    }, {
      "heading" : "3.1 A generic algorithm",
      "text" : "The key ingredient in the generic algorithm is the following:\nTheorem 6 Fix a function f : {0, 1}n → Ω where Ω is any range set. Suppose there exists a δ-cover for f (S) of size N = N(n, δ). Then there is an algorithm that uses O(δ−2 log N) samples and solves the f -transformed product distribution learning problem to accuracy 6δ.\nThe high-level idea behind Theorem 6 is as follows: for a pair of distributions Q1,Q2 ∈ S, we define a competition between Q1 and Q2 that takes as input a sample from the target distribution f (X) and either crowns one of Q1,Q2 as the winner of the competition or calls the competition a draw. Let Q ⊆ S be a δ-cover for f (S) of cardinality N = N(n, δ). The algorithm performs a tournament between every pair of distributions from Q and outputs a distribution Q∗ ∈ Q that was never a loser, i.e. won or achieved a draw in all competitions. (If no such distribution exists, the algorithm outputs “failure.”)\nThis basic approach of running a tournament between distributions in an δ-cover is quite similar to the algorithm of Devroye and Lugosi for choosing a density estimate (see Devroye and Lugosi (1996a,b) and Chapters 6 and 7 of Devroye and Lugosi (2001)), which in turn built closely on the work of Yatracos (1985). Our algorithm achieves essentially the same bounds as these earlier approaches but there are some small differences. (The DL approach uses a notion of the “competition” between two tournaments which is not symmetric under swapping the two competing tournaments, whereas our competition is symmetric; also, the DL approach chooses a distribution which wins the maximum number of competitions as the output distribution, whereas our algorithm chooses a distribution that is never defeated.) We give our proof of Theorem 6 in Appendix B.\nTheorem 1 is an easy consequence of Theorem 6. Recall Theorem 1:\nTheorem 1 (Information-theoretic upper bound for any f ) Let f : {0, 1}n → Ω be an arbitrary function where Ω is any range set. There is an algorithm that uses O((n/ǫ2) · log(n/ǫ)) samples from the target distribution f (p), runs in time (n/ǫ)O(n), and with probability at least 9/10 outputs a hypothesis vector p̂ such that dTV( f (p), f ( p̂)) ≤ ǫ.\nProof: We argue that for any f there is a δ-cover for f (S) of size at most (n/δ)n. The desired result then follows from Theorem 6. Since for any pair of distributions P,Q ∈ S and any function f we have dTV( f (P), f (Q)) ≤ dTV(P,Q), it suffices to exhibit a δ-cover of the desired cardinality for S.\nWe claim that if we discretize each individual expectation of our input Bernoulli random variables to integer multiples of α := δn , we obtain a δ-cover for S. Let us call the set of all such discretized product\ndistributions Q. Clearly, |Q| ≤ (\nn δ )n . Let P = (P1, . . . , Pn) ∈ S. Consider a point Q = (Q1, . . . ,Qn) ∈ Q\nsuch that dTV (Qi, Pi) ≤ δ/n for all i. Since both P and Q are product distributions, we have that dTV(P,Q) ≤∑n i=1 dTV(Qi, Pi) ≤ δ. This completes the proof."
    }, {
      "heading" : "3.2 Learning transformed product distributions can be computationally hard",
      "text" : "Though Theorem 1 shows that any learning problem f in our framework can be solved with Õ(n) sample complexity, it is natural to expect that some learning problems can be computationally hard. We confirm this intuition by establishing an NP-hardness result for a specific function f that is computed by an explicit degree2 polynomial. We show that if there is a poly(n)-time algorithm for the transformed product distribution learning problem for this f , even for learning to constant accuracy, then NP ⊆ BPP. Recall Theorem 2:\nTheorem 2 Suppose NP * BPP. Then there is an explicit degree-2 polynomial f such that there is no polynomial-time algorithm that solves the transformed product distribution learning problem for f to accuracy ǫ = 1/3.\nThe proof is a reduction from the PARTITION problem and is given in Appendix C."
    }, {
      "heading" : "3.3 Linear transformation functions can require Ω(n) samples",
      "text" : "We now show that even for a simple linear transformation function f (x) = w · x with small integer weights, it can be impossible to significantly improve on the Õ(n) sample complexity of the generic algorithm from Theorem 1. Recall Theorem 3: Theorem 3 (Sample complexity lower bound) Fix any even k ≤ n and let f (x) = ∑k\ni=k/2+1 ixi. Let L be any learning algorithm that outputs a hypothesis vector p̂ such that dTV( f (p), f ( p̂)) ≤ 1/40 with probability at least e−o(k). Then L must use Ω(k) samples from f (p).\nTheorem 3 is proved in Appendix D."
    }, {
      "heading" : "4 Learning an unknown sum of Bernoullis from poly(1/ǫ) samples",
      "text" : ""
    }, {
      "heading" : "4.1 Learning with respect to Kolmogorov distance",
      "text" : "Let X be any random variable supported on {0, 1, . . . , n}. We write FX and fX to denote respectively the cumulative distribution and the probability density function of X.\nLet Z1, . . . , Zk be independent samples of the random variable X, and define Z (ℓ) i := 1Zi≤ℓ for all ℓ =\n0, . . . , n and i = 1, . . . , k. Clearly we have E [ ∑\ni Z (ℓ) i /k ] = FX(ℓ), which suggests that F̂X(ℓ) := ∑ i Z (ℓ) i /k\nmay be a good estimator of FX(ℓ) for all values of ℓ, if k is large enough. The Dvoretzky-Kiefer-Wolfowitz inequality (Dvoretzky et al. (1956), Massart (1990)) confirms this, and in fact shows that a surprisingly small value of k – independent of n – suffices. The bound on k given below is optimal up to constant factors.\nTheorem 7 (DKW Inequality) Let k = max{576, (9/8) ln(1/δ)} · (1/ǫ2). Then with probability at least 1 − δ we have max0≤ℓ≤n ∣∣∣F̂X(ℓ) − FX(ℓ) ∣∣∣ ≤ ǫ.\nIn Appendix E we give a self-contained proof of the theorem using elementary techniques (martingales and the method of bounded differences) and an interesting trick that goes back to Kolmogorov (see Peres (2009)). We start by defining a coupling between the process of learning the cumulative distribution function as our samples are revealed and a random walk on the line. Then Kolmogorov’s trick is invoked to get a handle on the maximum estimation error, proving a weaker version of the theorem in which k equals Θ( 1\nδǫ2 ). We then\napply McDiarmid’s inequality to bootstrap the weaker bound and obtain the tighter bound. Now we specialize to the case in which X = ∑n i=1 Xi is a sum of independent Bernoulli random variables. We use the DKW inequality to prove the following:\nTheorem 8 (Proper Learning under Kolmogorov Distance) Let X = ∑n\ni=1 Xi be a sum of independent Bernoulli random variables. There is an algorithm which, given k = max{9216, 18 ln(1/δ)} · (1/ǫ2) independent samples from FX , produces with probability at least 1 − δ a set of independent Bernoullis Y1, . . . , Yn such that dK(X, Y) ≤ ǫ, where Y := ∑n i=1 Yi. The running time of the algorithm is poly(n/ǫ) + n · ( 1 ǫ )O(log 2 1 ǫ ).\nProof of Theorem 8: Use Theorem 7 to produce an ǫ4 -approximation {F̂X(ℓ)}ℓ of the cumulative distribution of X. Theorem 9 below gives us that for all γ > 0, there exists a γ-cover in total variation distance of the set of all sums of n Bernoulli random variables that has size poly(n/γ) + n · ( 1 γ )O(log 2 1 γ ) . Construct such a cover using γ = ǫ/8. Given that the Kolmogorov distance between two distributions is always at most twice their total variation distance, this cover is in fact a ǫ/4-cover in the Kolmogorov distance. Output any Y = ∑n i=1 Yi in the cover whose cumulative distribution FY satisfies\nmax 0≤ℓ≤n |FY (ℓ) − F̂X(ℓ)| ≤ ǫ/2. (1)\nIt is easy to see that a Y satisfying (1) exists in the cover. Indeed, if Y is the closest point of the cover to X in Kolmogorov distance, then it must be that max0≤ℓ≤n |FY(ℓ) − FX(ℓ)| ≤ ǫ/4. Given that {F̂X(ℓ)}ℓ is an ǫ/4-approximation to FX the above inequality implies (1).\nMoreover, it is easy to check that any Y satisfying (1) will satisfy max0≤ℓ≤n |FY(ℓ) − FX(ℓ)| ≤ 3ǫ/4 < ǫ, using again that {F̂X(ℓ)}ℓ is an ǫ/4-approximation to FX . Hence, we have dK(X, Y) < ǫ."
    }, {
      "heading" : "4.2 From Kolmogorov distance to total variation distance",
      "text" : "The algorithm of the previous subsection learns the target sum of Bernoullis to high accuracy with respect to Kolmogorov distance. Ideally, we would like to use this approximation as a black box to obtain an approximation in total variation distance. As we discussed in the introduction, this runs to a very basic, apparently unresolved question in probability theory: is there a bound on the total variation distance between two sums of independent indicators in terms of their Kolmogorov distance? If at least one of the two sums is a Binomial distribution, then an argument due to Newton gives a positive answer. However nothing is known about the relation between the two distances in this general case. Without such a bound, it is rather unclear whether constantly many samples (independent of n) suffices to accurately learn in total variation distance...\nNevertheless, we manage to extend our Kolmogorov distance learning algorithm to the total variation distance via a delicate algorithm that exploits the structure of a small ǫ-cover (in total variation distance) of the space of all distributions that are sums of independent Bernoulli random variables. Interestingly, this becomes feasible by establishing an analog of the aforementioned argument by Newton to a class of distributions used in the cover that are called heavy; and this argument relies on probabilistic approximation results via translated Poisson distributions (see Definition 18).\nWe give more details below. Let us start by formally stating a theorem that defines a cover (in total variation distance) of the space of sums of independent indicators. The following is Theorem 9 of the full version of (Daskalakis and Papadimitriou (2011)):\nTheorem 9 (Cover for sums of Bernoullis) For all ǫ > 0, there exists a set Sǫ ⊆ S such that (i) |Sǫ | ≤ n3 · O(1/ǫ)+n· (\n1 ǫ )O(log2 1/ǫ) ; (ii) For every {Xi}i ∈ S there exists some {Yi}i ∈ Sǫ such that dTV( ∑ i Xi, ∑ i Yi) ≤ ǫ (i.e.\nf (Sǫ ) is an ǫ-cover of f (S)); and (iii) the set Sǫ can be constructed in time O ( n3 · O(1/ǫ) + n · ( 1 ǫ )O(log2 1/ǫ)) .\nMoreover, if {Yi}i ∈ Sǫ , then the collection {Yi}i has one of the following forms, where k = k(ǫ) = O(1/ǫ) is a positive integer:\n• (Sparse Form) There is a value ℓ ≤ k3 = O(1/ǫ3) such that for all i ≤ ℓ we have E[Yi] ∈ { 1 k2 , 2 k2 , . . . , k2−1 k2 } ,\nand for all i > ℓ we have E[Yi] ∈ {0, 1}.\n• (k-heavy Binomial Form) There is a value ℓ ∈ {0, 1, . . . , n} and a value q ∈ {\n1 kn , 2 kn , . . . , kn−1 kn\n} such that for\nall i ≤ ℓ we have E[Yi] = q; for all i > ℓ we have E[Yi] ∈ {0, 1}; and ℓ, q satisfy the bounds ℓq ≥ k2 − 1k and ℓq(1 − q) ≥ k2 − k − 1 − 3k .\n(We remark that Daskalakis (2008) establishes the same theorem, except that the size of the cover given there, as well as the time needed to produce it, are n3 ·O(1/ǫ)+n · (\n1 ǫ\n)O(1/ǫ2) . Indeed, this weaker bound is obtained by\nenumerating over all possible collections {Yi}i in sparse form and all possible collections in k-heavy Binomial Form, for k = O(1/ǫ) specified by the theorem.)\nUsing the cover described in Theorem 9, we prove the following, which immediately gives Theorem 4:\nTheorem 10 (Learning under Total Variation Distance) Let X = ∑n\ni=1 Xi be a sum of independent Bernoullis. Fix any τ > 0. There is an algorithm which, given O( 1\nǫ8+τ ) independent samples from X, produces with proba-\nbility at least 9/10 a list of Bernoulli random variables Y1, . . . , Yn such that dTV(X, Y) ≤ ǫ, where Y := ∑n\ni=1 Yi. The running time of the algorithm is n3 · poly(1/ǫ) + n · (1/ǫ)O(log 2 1/ǫ).\nWe first give a high-level outline of our argument. The proof works by considering the points in a cover Sǫβ where β is some constant > 1. We define two tests that can be performed on points (i.e. distributions) in Sǫβ . The first of these, called the ∆-test, is run on every sparse form distribution in Sǫβ , and is designed to identify a sparse form distribution that is close to X if such a distribution exists. The second test, called the H-test, is run on every k-heavy Binomial form distribution in Sǫβ and is designed to identify a Binomial form distribution that is close to X if such a distribution exists. Since Sǫβ is a cover, some test will succeed. (Of course, we must also show that for each test, any distribution it outputs is indeed legitimately close to X; this is part of our analysis as well.)\nWe now enter into the detailed proof. Let β = 1 + τ12 and let α = 4 + τ 2 . Using Theorem 7, from O(ǫ −2α) independent samples of X we can obtain estimates {F̂X(ℓ)}nℓ=0 such that |F̂X(ℓ) − FX(ℓ)| ≤ ǫ\nα, for all ℓ, with probability at least 9/10. For the rest of the proof we condition on the event that each of our estimates F̂X(ℓ) is indeed within ǫα of the actual value FX(ℓ). Define f̂X(0) = F̂X(0) and f̂X(z) = F̂X(z) − F̂X(z − 1), for all z ∈ [n]."
    }, {
      "heading" : "4.2.1 Handling sparse form distributions in the cover.",
      "text" : "Let Y = ∑ i Yi, where Y := {Yi} n i=1 ∈ Sǫβ , and suppose that Y is of the sparse form, as defined in statement of Theorem 9. Let supp(Y) denote the support of Y. By the definition of the sparse form, we have that |supp(Y)| ≤ (cǫ)−3β, where c is some universal constant. Define ∆Y as follows:\n∆Y = 1 2 ( ∑ z∈supp(Y) | fY (z) − f̂X(z)| + 1 − ∑ z∈supp(Y) | f̂X(z)| ) .\nWe observe that given {F̂X(ℓ)}nℓ=0 and Y, the value of ∆Y can be straightforwardly computed in time poly(1/ǫ) using dynamic programming.\nThe following two claims (whose proofs we defer to Section 4.3) say that if dTV(X, Y) is large (at least ǫ) then ∆Y must be fairly large, while if dTV(X, Y) is small (at most ǫβ) then ∆Y must also be fairly small.\nClaim 11 If dTV(X, Y) ≥ ǫ, then ∆Y ≥ ǫ − 2(cǫ)−3β · ǫα.\nClaim 12 If dTV(X, Y) ≤ ǫβ, then ∆Y ≤ ǫβ + 2(cǫ)−3β · ǫα.\nBy our choice of β = 1 + τ12 and α = 4 + τ 2 , for ǫ smaller than a certain constant (depending on c and τ)\nthe following condition holds:\nǫ > ǫβ + 4c−3βǫα−3β. (2)\nClaims 11 and 12 imply that if we use the Sǫβ cover of Theorem 9, we can filter collections {Yi}i ∈ Sǫβ in the sparse form whose sum Y is ǫ-far in total variation distance from X, by computing ∆Y and thresholding at the value ǫβ + 2(cǫ)−3β · ǫα. Moreover, this filtration is not going to get rid of any collections in sparse form that are within ǫβ total variation distance from the target distribution. Formally, let us define the following test, which takes as input the estimates {F̂X(ℓ)}nℓ=0 and decides whether or not to reject a point in Sǫβ in sparse form.\nDefinition 13 (∆-test) The input is Y = {Yi}i ∈ Sǫβ in the sparse form. Let Y = ∑ i Yi. If ∆Y ≤ ǫ β+2(cǫ)−3β ·ǫα then the ∆-test accepts Y, otherwise it rejects Y.\nSince ∆Y can be computed in poly(1/ǫ) time, an execution of the ∆-test can be performed in poly(1/ǫ) time. If (2) is satisfied, Claims 11 and 12 imply the following: Lemma 14 (Correctness of the ∆-test) Let {Yi}i ∈ Sǫβ be in the sparse form and Y = ∑\ni Yi. If Y is accepted by the ∆-test then dTV(X, Y) ≤ ǫ, and if dTV(X, Y) ≤ ǫb then Y is accepted by the ∆-test.\nLemma 14 implies in particular that if {Xi}i has an ǫβ-neighbor {Yi}i in Sǫβ that is in the sparse form, then this neighbor will be accepted by the ∆-test. Moreover, no element {Yi}i ∈ Sǫβ in sparse form that is accepted by the ∆-test has ∑ i Yi further than ǫ in total variation distance from ∑ i Xi."
    }, {
      "heading" : "4.2.2 Handling Binomial form distributions in the cover.",
      "text" : "We can use the ∆-test for the sparse points in the cover, but it could be that the target collection X = {Xi}i has no sparse ǫβ-neighbor in Sǫβ and the ∆-test fails to accept any sparse point in the cover. We need to devise a procedure which similarly filters the points of heavy Binomial form in the cover so that we do not eliminate any ǫβ-close point, while at the same time not admitting any ǫ-far point. Since X has no sparse ǫβ-neighbor in the cover, it follows from Theorem 9 that there is a collection X′ := {X′i }i ∈ Sǫβ in k(ǫ\nβ)-heavy Binomial form such that ∑ i Xi and ∑ i X ′ i are within ǫ\nβ in total variation distance. We show that the total variation distance is essentially within a constant factor of the Kolmogorov distance\nfor two collections of random variables in heavy Binomial form:\nLemma 15 Let X := {Xi}i and Y := {Yi}i be two collections of independent indicators in k-heavy Binomial form and set X = ∑ i Xi, Y = ∑ i Yi. Then 1 2 dK(X, Y) ≤ dTV(X, Y) ≤ 2 · dK(X, Y) + O(1/k).\nThe proof is somewhat lengthy so we defer it to Section 4.4. Given Lemma 15, we are inspired to define the H-test as follows. The test takes as input the estimates {F̂X(ℓ)}nℓ=0 and needs to decide whether or not to reject a point in Sǫβ in k(ǫβ)-heavy Binomial form. Definition 16 (H-test) The input is Y = {Yi}i ∈ Sǫβ in the k(ǫβ)-heavy Binomial form. Let Y = ∑\ni Yi. If max0≤ℓ≤n |FY (ℓ) − F̂X(ℓ)| ≤ 2ǫβ + ǫα then the H-test accepts Y, otherwise it rejects Y.\nLike the ∆-test, the H-test can be performed in poly(1/ǫ) time. We now prove:\nLemma 17 (Correctness of the H-test) Suppose that X is not ǫβ-close to any point in Sǫβ of the sparse form. Let Y = {Yi}i ∈ Sǫβ be of the k(ǫβ)-heavy Binomial form, and let Y = ∑ i Yi. If Y is accepted by the H-test, then dTV(X, Y) ≤ 4ǫα + O(ǫβ). On the other hand, if dTV(X, Y)) ≤ ǫβ, then Y is accepted by the H-test.\nProof of Lemma 17: Since X is not ǫβ-close to any sparse point in the cover, it follows from Theorem 9 that there exists a collection X′ := {X′i }i ∈ S in the k(ǫ β)-heavy Binomial form such that X := ∑\ni Xi and X′ := ∑ i X ′ i are within ǫ\nβ in total variation distance. Suppose that Y passes the H-test. For all ℓ, we have |FY(ℓ) − FX(ℓ)| ≤ |FY(ℓ) − F̂X(ℓ)| + |F̂X(ℓ) − FX(ℓ)|,\nand hence dK(X, Y) ≤ 2ǫβ + 2ǫα. Given this, we have\ndTV(X, Y) ≤ dTV(X, X ′) + dTV(X ′, Y) (using the triangle inequality)\n≤ ǫβ + dTV(X ′, Y)\n≤ ǫβ + 2dK(X′, Y) + O(1/k(ǫβ)) (using Lemma 15)\n≤ 2dK(X′, Y) + O(ǫβ) (since Theorem 9 gives 1/k(ǫβ) = O(ǫβ))\n≤ 2dK(X′, X) + 2dK(X, Y) + O(ǫβ) (using the triangle inequality)\n≤ 4dTV(X′, X) + 2dK(X, Y) + O(ǫβ) (using that dK ≤ 2 · dTV )\n≤ 2dK(X, Y) + O(ǫβ) ≤ 4ǫα + O(ǫβ).\nOn the other hand, if dTV(X, Y)) ≤ ǫβ, it follows that dK(X, Y)) ≤ 2ǫβ. Hence, for all ℓ,\n|FY (ℓ) − F̂X(ℓ)| ≤ |FY(ℓ) − FX(ℓ)| + |F̂X(ℓ) − FX(ℓ)|\n≤ dK(X, Y) + ǫ α ≤ 2dTV(X, Y) + ǫ α ≤ 2ǫβ + ǫα.\nHence, Y is accepted by the H-test."
    }, {
      "heading" : "4.2.3 Finishing the Proof of Theorem 10",
      "text" : "Let ĉ be the constant hidden in the O(·)-notation in the statement of Lemma 17. We may assume that ǫ is smaller than any fixed constant, and hence that it satisfies ǫ ≥ 4ǫα + ĉ · ǫβ as well as (2). We now describe the algorithm promised in Theorem 10. The algorithm takes as input the estimates {F̂X(ℓ)}nℓ=0 (which, as described at the beginning of the proof, can be obtained from the samples from X using Theorem 7).\nAlgorithm\n1. Compute the cover Sǫβ defined in Theorem 9.\n2. If any Y ∈ Sǫβ in the sparse form passes the ∆-test, output such a Y and halt.\n3. Otherwise, if any Y ∈ Sǫβ in the k(ǫβ)-heavy Binomial form passes the H-test, output such a Y. It follows from Theorem 9 that there exists some {Yi}i ∈ Sǫβ such that ∑ i Yi is within ǫ β in total variation\ndistance from ∑\ni Xi. If there exists such an element in the cover that is also in the sparse form, it follows from Lemma 14 that this point will pass the test at the second test of the algorithm and hence be returned in the output. On the other hand, any element {Yi}i of the cover returned by the second step of the algorithm will satisfy that ∑ i Yi is within ǫ in total variation distance from ∑ i Xi. If the second step of the algorithm fails to return any element of the cover, it follows that X has an ǫβ-neighbor in the cover in heavy Binomial form. Lemma 17 implies then that such a neighbor will be output in the third step of the algorithm. Moreover, the lemma implies that any element returned in the third step is an ǫ-neighbor of X. Hence the algorithm is correct and always succeeds in returning an ǫ-neighbor of X. Finally, the running time is dominated by the time to run the ∆-test or the H-test on each point in the coverSǫβ , which is easily seen to be n3·poly(1/ǫ)+n·(1/ǫ)O(log 2 1/ǫ). This concludes the proof of Theorem 10 and thus also of Theorem 4."
    }, {
      "heading" : "4.3 Proof of Claims 11 and 12",
      "text" : "Recall that Y = ∑\ni Yi where Y := {Yi} n i=1 ∈ Sǫβ is of the sparse form, as defined in statement of Theorem 9.\nRecall Claim 11:\nClaim 11 If dTV(X, Y) ≥ ǫ, then ∆Y ≥ ǫ − 2(cǫ)−3β · ǫα.\nProof of Claim 11: By the definition of the total variation distance, the hypothesis implies\n1 2\n∑\nz\n| fY (z) − fX (z)| ≥ ǫ. (3)\nWe can bound the left hand side of the above as follows∑\nz\n| fY (z) − fX(z)| = ∑\nz∈supp(Y)\n| fY (z) − fX(z)| + ∑\nz<supp(Y)\n| fX(z)|\n≤ ∑\nz∈supp(Y)\n| fY (z) − f̂X(z)| + ∑\nz∈supp(Y)\n| fX(z) − f̂X (z)| + ∑\nz<supp(Y)\n| fX(z)|\n≤ ∑\nz∈supp(Y)\n| fY (z) − f̂X(z)| + 2(cǫ) −3β · ǫα +\n∑\nz<supp(Y)\n| fX(z)|. (4)\nIn the last line of the above we used the bound on the support of Y and the fact that for all z ∈ [n]:\n| fX(z) − f̂X(z)| = |(FX(z) − FX(z − 1)) − (F̂X(z) − F̂X(z − 1)|\n≤ |FX(z) − F̂X(z)| + |FX(z − 1) − F̂X(z − 1)| ≤ 2 · ǫα,\nwhile | fX(0) − f̂X(0)| = |FX(0) − F̂X(0)| ≤ ǫα. Finally, note that\n∑\nz∈supp(Y)\n| fX(z)| = ∑\nz∈supp(Y)\n| f̂X(z) − ( f̂X(z) − fX (z))|\n≥ ∑\nz∈supp(Y)\n(| f̂X(z)| − | f̂X(z) − fX(z)|).\nHence, ∑\nz<supp(Y)\n| fX(z)| = 1 − ∑\nz∈supp(Y)\n| fX(z)|\n≤ 1 − ∑\nz∈supp(Y)\n| f̂X(z)| + ∑\nz∈supp(Y)\n| f̂X(z) − fX(z)|\n≤ 1 − ∑\nz∈supp(Y)\n| f̂X(z)| + 2(cǫ) −3β · ǫα. (5)\nUsing (3), (4), (5) we obtain that ∆Y ≥ ǫ − 2(cǫ)−3β · ǫα.\nRecall Claim 12:\nClaim 12 If dTV(X, Y) ≤ ǫβ, then ∆Y ≤ ǫβ + 2(cǫ)−3β · ǫα.\nProof of Claim 12: By definition of the total variation distance, the hypothesis implies\n1 2\n∑\nz\n| fY (z) − fX(z)| ≤ ǫβ.\nWe can bound the left hand side of the above as follows∑\nz\n| fY (z) − fX(z)| = ∑\nz∈supp(Y)\n| fY (z) − fX(z)| + ∑\nz<supp(Y)\n| fX(z)|\n≥ ∑\nz∈supp(Y)\n| fY (z) − f̂X(z)| − ∑\nz∈supp(Y)\n| fX(z) − f̂X (z)| + ∑\nz<supp(Y)\n| fX(z)|\n≥ ∑\nz∈supp(Y)\n| fY (z) − f̂X(z)| − 2(cǫ)−3β · ǫα + ∑\nz<supp(Y)\n| fX(z)|.\nIn the last line of the above we used the same bound we used for deriving (4). Finally, note that\n∑\nz<supp(Y)\n| fX(z)| = 1 − ∑\nz∈supp(Y)\n| fX(z)|\n≥ 1 − ∑\nz∈supp(Y)\n| f̂X(z)| − ∑\nz∈supp(Y)\n| f̂X(z) − fX(z)|\n≥ 1 − ∑\nz∈supp(Y)\n| f̂X(z)| − 2(cǫ) −3β · ǫα\nUsing the bounds above we obtain ∆Y ≤ ǫβ + 2(cǫ)−3β · ǫα."
    }, {
      "heading" : "4.4 Proof of Lemma 15",
      "text" : "Recall Lemma 15:\nLemma 15 Let X := {Xi}i and Y := {Yi}i be two collections of independent indicators in k-heavy Binomial form and set X = ∑ i Xi, Y = ∑ i Yi. Then\n1 2 dK(X, Y) ≤ dTV (X, Y) ≤ 2 · dK(X, Y) + O(1/k).\nProof of Lemma 15: The first inequality is immediate from the definition of the Kolmogorov and Total Variation distances. To show the other bound, let ZX , ZY ⊆ [n] be the indices of the variables in the collections {Xi}i and {Yi}i respectively that are deterministically zero, OX ,OY the indices of variables that are deterministically 1, and define EX = [n] \\ ZX \\ OX , EY = [n] \\ ZY \\ OY , n1 = |EX |, n2 = |EY |, and m = |OX | − |OY |. Moreover, let p1 be the common mean of the variables Xi, i ∈ EX , and p2 the common mean of the variables in Yi, i ∈ EY . Without loss of generality, we can assume that m ≥ 0. Now we define X′ = m + Bin(n1, p1) and Y′ = Bin(n2, p2). It is straightforward to check that\ndTV (X, Y) = dTV(X′, Y′)\nand dK(X, Y) = dK(X′, Y′).\nGiven that X and Y are in k-heavy Binomial form, it follows that for i = 1, 2:\nµi := ni · pi ≥ k2 − 1 k ;\nσ2i := ni · pi(1 − pi) ≥ k 2 − k − 1 − 3 k .\nWe recall that the Translated Poisson distribution is defined as follows.\nDefinition 18 (Röllin (2006)) We say that an integer random variable Y has a translated Poisson distribution with paremeters µ and σ2 and write L(Y) = T P(µ, σ2) if L(Y − ⌊µ − σ2⌋) = Poisson(σ2 + {µ − σ2}), where {µ − σ2} represents the fractional part of µ − σ2.\nGiven the above, and following Daskalakis (2008) (see Section 6.1), we can show the following for i = 1, 2:\ndTV ( Bin(ni, pi), T P(µi, σ2i ) ) = O(1/k). (6)\nNow we show the following:\nLemma 19 For λ, λ̂ > 0, m, m̂ ∈ N0, let Y = m + Poisson(λ) and Ŷ = m̂ + Poisson(̂λ). Then\ndTV(Y, Ŷ) ≤ 2dK(Y, Ŷ).\nProof of Lemma 19: Without loss of generality assume that m′ := m − m̂ ≥ 0. Then it is enough to compare Y′ = m′ + Poisson(λ) and Ŷ′ = Poisson(̂λ), since dTV(Y, Ŷ) = dTV(Y′, Ŷ′) and dK(Y, Ŷ) = dK(Y′, Ŷ′). For i ≥ 0, define\nRi := Pr[Y′ = i]\nPr[Ŷ′ = i] .\nClearly, Ri = 0, for i = 0, 1, . . . ,m′ − 1, since Y′ is not supported on that set. On the other hand for all i ≥ m′, we have\nRi := λi−m\n′ ·e−λ\n(i−m′)!\nλ̂i ·e−̂λ i!\n,\nand for all i ≥ m′ + 1:\nRi Ri+1 = λ̂ · (i + 1 − m′) λ · (i + 1) .\nLet us distinguish the following cases:\n• If λ > λ̂, then RiRi+1 < 1 for all i. Hence, Ri is increasing in i, so that it can change from a value ≤ 1 to a\nvalue ≥ 1 at most one time. Hence, there exists a single i∗ such that Pr[Y′ = i] < Pr[Ŷ′ = i] for all i < i∗, and Pr[Y′ = i] < Pr[Ŷ′ = i] for all i > i∗. In this case, it is easy to see that\ndTV(Y ′, Ŷ′) = dK(Y ′, Ŷ′).\n• If λ = λ̂ and m′ = 0 the variables Y′ and Ŷ′ are identically distributed so that their total variation distance and Kolmogorov distance are both identically 0. If λ = λ̂ and m′ > 0, then RiRi+1 < 1 for all i and from our argument in the previous case we obtain\ndTV (Y′, Ŷ′) = dK(Y′, Ŷ′).\n• Finally, if λ < λ̂, then RiRi+1 ≥ 1 for all i ≤ m′\n1− λ λ̂\n− 1 and RiRi+1 > 1 for all i > m′\n1− λ λ̂\n− 1. So Ri is increasing\nup to some i∗ and decreasing above i∗. So the distributions of Y′ and Ŷ′ have at most two intersections. Hence, we obtain\ndTV(Y′, Ŷ′) ≤ 2dK(Y′, Ŷ′).\nGiven the above we have,\ndTV (X′, Y′) ≡ dTV(m + Bin(n1, p1),Bin(n2, p2))\n≤ dTV ( m + Bin(n1, p1), m + T P(µ1, σ 2 1) ) + dTV ( m + T P(µ1, σ 2 1), T P(µ2, σ 2 2) )\n+ dTV ( Bin(n2, p2), T P(µ2, σ 2 2) )\n(using the triangle inequality)\n≤ O(1/k) + dTV ( m + T P(µ1, σ 2 1), T P(µ2, σ 2 2) )\n(using (6))\n≤ O(1/k) + 2dK ( m + T P(µ1, σ21), T P(µ2, σ 2 2) )\n(using Lemma 19)\n≤ O(1/k) + 2dK ( m + Bin(n1, p1),m + T P(µ1, σ21) ) + 2dK ( Bin(n2, p2), T P(µ2, σ22) )\n+ 2dK (m + Bin(n1, p1), Bin(n2, p2)) (using the triangle inequality)\n≤ O(1/k) + 2dK (m + Bin(n1, p1), Bin(n2, p2)) (using that dK ≤ 2 · dTV and (6)). = O(1/k) + 2dK ( X′, Y′ )\nThis concludes the proof of Lemma 15.\n5 An intermediate case: Linear transformation functions with O(1) distinct weights\nRecall that Theorem 2 shows that the exponential running time of Theorem 6 cannot be significantly improved even if the transformation function f is a degree-2 polynomial, and Theorem 3 shows that the Õ(n) sample complexity cannot be significantly improved even if f is a simple linear function. In contrast with these strong negative results, we have also seen that the sum-of-Bernoullis transformation function f (x) = ∑n i=1 xi admits highly efficient algorithms both in terms of running time and sample complexity. We close this paper by showing that in an intermediate case – if the transformation function f is a linear function with constantly many different weights – then it is also possible to improve on the generic time and sample complexity bounds of Theorem 6, though not quite as dramatically as for sums of Bernoullis:\nTheorem 20 (Linear transformation functions with O(1) different weights) Let f (x) = ∑n\ni=1 aixi be any function such that there are at most k different values in the set {a1, . . . , an}. Then there is an algorithm that uses k log(n) · Õ(ǫ−2) samples from the target distribution f (p), runs in time poly(nk · ǫ−k log\n2(1/ǫ)), and with probability at least 9/10 outputs a hypothesis vector p̂ such that dTV( f (p), f ( p̂)) ≤ ǫ.\nNote that setting a1 = · · · = an = 1 in Theorem 20 gives a weaker result than Theorem 4 since the resulting sample complexity is log(n) · Õ(ǫ−2), whereas Theorem 4 gives a poly(1/ǫ) sample complexity bound independent of n.\nProof of Theorem 20: We claim that the algorithm of Theorem 6 has the desired sample complexity and can be implemented to run in polynomial time.\nLet {b j}kj=1 denote the set of distinct weights and n j = ∣∣∣i ∈ [n] | ai = b j ∣∣∣, where k = O(1). With this notation, we can write f (X) = ∑k j=1 b jS j = g(S ), where S = (S 1, . . . , S k) with each S j a sum of n j many\nindependent Bernoulli random variables and g(y1, . . . , yk) = ∑k j=1 b jy j. Clearly, ∑k j=1 n j = n. By Theorem 9, S j has an explicit ǫ-cover S j ǫ of size |S j ǫ | ≤ n3j · O(1/ǫ) + n · (1/ǫ) O(log2 1/ǫ). By independence across S j’s, the product Q = ∏k\nj=1 S j ǫ is an ǫ-cover for S , hence also for f (X). That is, f (X) has an explicit ǫ-cover of size\n|Q| = ∏k\nj=1 |S j ǫ | ≤ (n/k)3k · (1/ǫ)k·O(log 2 1/ǫ). The sample complexity bound follows directly. It remains to argue about the time complexity. Note that the running time of the algorithm is O(|Q|2) times the running time of a competition. We will show that a competition between Q1,Q2 ∈ Q can be efficiently computed. This amounts to efficiently computing the probabilities p1 = f (Q1)(W1) and q1 = f (Q2)(W1). Note that W = f ({0, 1}n) = ∑k j=1 bi · {0, 1, . . . , n j}. Clearly, |W| ≤ ∏k j=1(n j + 1) = O((n/k)\nk). It is thus easy to see that p1, q1 can be efficiently computed as long as there is an efficient algorithm for the following problem: given Q ∈ Q and w ∈ W, compute f (Q)(w). Indeed, fix any such Q, w. We have that f (Q)(w) =∑\nm1,...,mk ∏k j=1 PrX∼Q[S j = m j], where the sum is over all k-tuples (m1, . . . ,mk) such that 0 ≤ m j ≤ n j for all j and b1m1 + · · · + bkmk = w (as noted above there are at most O((n/k)k) such k-tuples). To complete the proof of Theorem 20 we note that PrX∼Q[S j = m j] can be computed in O(n2j) time by standard dynamic programming."
    }, {
      "heading" : "6 Conclusion and open problems",
      "text" : "We feel that the transformed product distribution learning model offers a rich field for further study, with many natural directions to explore. We close this paper with some specific questions and suggestions for future work.\nOptimally learning sums of Bernoullis? An obvious question is whether the competing advantages of Theorems 4 and 5 can be simultaneously achieved by a single algorithm: is there an algorithm to learn sums of Bernoullis that uses poly(1/ǫ) samples and runs in poly(log n, 1/ǫ) time?\nLearning weighted sums of Bernoullis? In Section 5 we observed that a poly(n)-time algorithm exists for any linear transformation function f (x1, . . . , xn) = ∑n i=1 aixi in which there are only O(1) many different ai’s.\nCan a poly(n)-time algorithm be obtained for every linear transformation function f (x) = ∑n\ni=1 aixi, where (a1, . . . , an) is an arbitrary vector in Rn? What if each ai is a positive integer that is at most poly(n)?\nLearning when the transformation function is in NC0? Suppose that the transformation function f maps {0, 1}n to {0, 1}n, i.e. f = ( f1, . . . , fn), where each fi : {0, 1}n → {0, 1} is a k-junta – a function that depends only on k of the n input variables – for some constant k. Is the corresponding transformed product distribution learning problem solvable in poly(n, 1/ǫ) time? We conjecture that the answer is yes. (Note that as suggested by the second example of the Introduction, an algorithm for a special case of this question (in which each fi is a particular (2k− 1)-junta) yields a poly(n/ǫ)-time algorithm for learning a mixture of k product distributions over {0, 1}n. This mixture learning problem is indeed known to be solvable in poly(n/ǫ) time for constant k but the algorithm is somewhat involved, see Feldman et al. (2008).)\nWhen do O(1) samples information-theoretically suffice? Our main result in Section 4 shows that for the transformation function f (x) = ∑n i=1 xi, the sample complexity required for learning to accuracy ǫ is poly(1/ǫ) independent of n. But as we show in Appendix D, the seemingly similar linear transformation function f (x) = ∑n i=n/2+1 ixi requires Ω(n) samples, which is close to the worst possible for any f . This disparity motivates the following question: what necessary or sufficient conditions can be given on a function f : {0, 1}n → R that cause the corresponding learning problem to have sample complexity depending only on ǫ (independent of n)? More ambitiously, is there a quantitative measure of the “complexity” of a function f that gives a tight quantitative bound on the sample complexity of the product distribution learning problem for f ? The Vapnik-Chervonenkis dimension of a concept class C plays such a role in the PAC learning model, since it tightly characterizes the number of examples that are required to solve the learning problem for C. Is there an analogous measure of the “complexity” of a transformation f for our product distribution learning problem?"
    }, {
      "heading" : "A Proof of Observation 1.1: AND-gate functions",
      "text" : "Let p = (p1, . . . , pn) be the unknown target vector of probabilities. For each i ∈ [m] let Pi denote the true probability PrX[ fi(X) = 1] where the probability is over X drawn from the product distribution p. Using poly(n, 1/ǫ) random samples of f (X) it is straightforward to obtain upper and lower bounds 0 ≤ Pi,− < Pi,+ ≤ 1 such that Pi,+ − Pi,− ≤ ǫn and with probability at least 9/10, every i ∈ [m] has Pi,− ≤ Pi ≤ Pi,+.\nFor each i ∈ [m] we have that the function fi(x) is ∧ i∈S i xi; by independence we have\nPi = ∏\ni∈S i\npi and thus log Pi = ∑\ni∈S i\nlog pi.\nUsing the bounds Pi,− and Pi,+ it is straightforward to set up a system of linear inequalities in variables q1, . . . , qn where each qi plays the role of log pi, i.e. for a given i we have the inequalities\nlog Pi,− ≤ ∑\ni∈S i\nqi ≤ log Pi,+.\n(We also include the inequalities qi ≤ 0 for each i since the pi’s must be probabilities, i.e. values at most 1.) With probability at least 9/10 the system is feasible (since setting each qi to be log pi gives a feasible solution), so we can use polynomial-time linear programming to obtain a feasible solution q̂1, . . . , q̂n. The corresponding product distribution p̂ = ( p̂1, . . . , p̂n) where p̂i = 2q̂i has the property that for each i, we have | PrX∼p̂[ fi(X) = 1] − Pi| ≤ ǫm . A simple argument (using independence between the different fi(X)’s, which holds since the sets S i are pairwise disjoint) then shows that the total variation distance dTV( f ( p̂), f (p)) is at most ǫ, and Observation 1.1 is proved."
    }, {
      "heading" : "B Proof of Theorem 6: A tournament between distributions in a cover",
      "text" : "Recall Theorem 6:\nTheorem 6 Fix a function f : {0, 1}n → Ω where Ω is any range set. Suppose there exists a δ-cover for f (S) of size N = N(n, δ). Then there is an algorithm that uses O(δ−2 log N) samples and solves the f -transformed product distribution learning problem to accuracy 6δ.\nProof: Let P ∈ S be the input distribution fed to the circuit f . We will describe an algorithm that, given m = O(δ−2 log N) independent samples s = {si}mi=1 from f (P), finds a distribution Q\n∗ ∈ S that satisfies dTV( f (P), f (Q∗)) ≤ 6δ with probability at least 9/10.\nRecall that the high-level idea of the proof is as follows. For a pair of distributions Q1,Q2 ∈ S, we will define a competition between Q1 and Q2 that takes as input the sample s and either crowns one of Q1,Q2 as the winner of the competition or calls the competition a draw. Let Q ⊆ S be a δ-cover for f (S) of cardinality N = N(n, δ). The algorithm performs a tournament between every pair of distributions from Q and outputs a distribution Q∗ ∈ Q that was never a loser (i.e. won or was a draw in all competitions). If no such distribution exists, the algorithm outputs “failure.”\nTo describe the competition procedure between two distributions Q1,Q2 ∈ S, we define the following partition of the range space W = f ({0, 1}n) ⊆ Ω:\nW1 := {w ∈ W | f (Q1)(w) ≥ f (Q2)(w)}; W2 := W\\W1.\nLet p1 = f (Q1)(W1) and q1 = f (Q2)(W1), and define p2 = 1 − p1 and q2 = 1 − q1. Clearly, p1 ≥ q1 and p2 < q2. Moreover, dTV( f (Q1), f (Q2)) = p1 − q1. Finally, let T (s) = 1m |{i | si ∈ W1}| be the fraction of samples falling in the set W1. The outcome of the competition between Q1 and Q2 is decided as follows:\n• If p1 − q1 ≤ 5δ, return “draw”;\n• else if T (s) > p1 − 32δ, return Q1;\n• else if T (s) < q1 + 32δ, return Q2;\n• else return “draw”.\nObserve that the outcome of the competition does not depend on the ordering of the pair of distributions given in the input; i.e. on inputs (Q1,Q2) and (Q2,Q1) the competition outputs the same result for a fixed sequence of samples s1, . . . , sm.\nWe now prove correctness. Our first lemma quantifies the following intuitive fact: If f (Q1) is “close” to f (P) while f (Q2) is “far” from f (P), then with very high probability over the sample Q1 will be the winner of the competition.\nLemma 21 Let Q1 ∈ S be such that dTV( f (P), f (Q1)) ≤ δ. (i) If Q2 ∈ S is such that dTV( f (P), f (Q2)) > 6δ, the probability that the competition between Q1 and Q2 does not return Q1 as the winner is at most e−mδ 2/8.\n(ii) If Q2 ∈ S is such that dTV( f (P), f (Q2)) > 4δ, the probability that the competition between Q1 and Q2 returns Q2 as the winner is at most e−mδ 2/8.\nProof: Let r denote f (P)(W1). The definition of the total variation distance implies that |r − p1| ≤ δ. Let us define the 0/1 (indicator) random variables {Zi}mi=1, as Zi = 1 iff si ∈ W1. Clearly, T (s) = 1 m ∑m i=1 Zi and E[T ] = E[Zi] = r. Since the Zi’s are mutually independent, it follows from the Chernoff bound that Pr[T ≤ r − δ/2] ≤ e−mδ 2/8. Using |r − p1| ≤ δ we get that Pr[T ≤ p1 − 3δ/2] ≤ e−mδ 2/8.\nWe prove part (i) first. Since dTV ( f (P), f (Q2)) > 6δ, the triangle inequality implies that p1 − q1 = dTV( f (Q1), f (Q2)) > 5δ. Hence, with probability at least 1 − e−mδ\n2/8 the competition between Q1 and Q2 will output Q1 as the winner.\nNow we prove part (ii). If p1 − q1 ≤ 5δ then the competition returns “draw” and Q2 is not the winner. If p1 − q1 > 5δ then the above implies that the competition between Q1 and Q2 will output Q2 as the winner with probability at most e−mδ 2/8.\nOur second lemma completes the proof of Theorem 6.\nLemma 22 If m = Ω(δ−2 log N), then with probability at least 9/10 the tournament outputs some distribution Q∗ ∈ Q such that dTV ( f (Q∗), f (P)) ≤ 6δ.\nProof: Since Q is a δ-cover of f (S), there exists Q̃ ∈ Q such that dTV( f (Q̃), f (P)) ≤ δ. We first argue that with high probability this distribution Q̃ never loses a competition against any other Q′ ∈ Q (so the tournament does not output “failure”). Consider any Q′ ∈ Q. If dTV( f (P), f (Q′)) > 4δ, by Lemma 21(ii) the probability that Q̃ loses to Q′ is at most e−mδ\n2/8 = O(1/N). On the other hand, if dTV( f (P), f (Q′)) ≤ 4δ, the triangle inequality gives that dTV( f (Q̃), f (Q′)) ≤ 5δ and thus Q̃ draws against Q′. A union bound over all N distributions in Q shows that with probability 19/20, the distribution Q̃ never loses a competition.\nWe next argue that with probability at least 19/20, every distribution Q′ ∈ Q that never loses has f (Q′) close to f (P). Fix a distribution Q′ such that dTV( f (Q′), f (P)) > 6δ; Lemma 21(i) implies that Q′ loses to Q̃ with probability 1−e−mδ\n2/8 = 1−O(1/N). A union bound gives that with probability 19/20, every distribution Q′ that has dTV( f (Q′), f (P)) > 6δ loses some competition.\nThus, with overall probability at least 9/10, the tournament does not output “failure” and outputs some distribution Q∗ such that dTV ( f (P), f (Q∗)) is at most 6δ. This proves Lemma 22 and Theorem 6."
    }, {
      "heading" : "C Learning transformed product distributions can be computationally hard",
      "text" : "Recall Theorem 2:\nTheorem 2 Suppose NP * BPP. Then there is an explicit degree-2 polynomial f (given in Equation (7) below) such that there is no polynomial-time algorithm that solves the transformed product distribution learning problem for f to accuracy ǫ = 1/3.\nProof: The function f is quite simple. It takes m = n2 + n bits of input\n(w, s) = (w1,1, . . . , w1,n, w2,1, . . . , w2,n, . . . , wn,1, . . . , wn,n, s1, . . . , sn).\nHere we think of each n-bit substring wi,1 . . . wi,n ∈ {0, 1}n as the binary representation of the number Wi =∑n j=1 2\nn− jwi, j ∈ {0, 1, . . . , 2n − 1}. We think of s1, . . . , sn as representing a subset S ⊆ [n], where i ∈ S if and only if si = 1. The function f (w, s) is defined to be\nf (w, s) = n∑\ni=1 22inWn+1−i + n∑ i=1 Wi(2si − 1) (7)\nwhich is easily seen to be a degree-2 polynomial. Recall that an input to the NP-complete PARTITION problem is a list of n numbers W1, . . . ,Wn. The input\nis a yes-instance if there is a set S ⊆ [n] such that ∑ i∈S Wi = ∑\ni<S Wi ( equivalently, if there is a bitstring (s1, . . . , sn) such that ∑n i=1 Wi(2si − 1) = 0).\nIt is easy to see from the definition of f that the output number f (w, s) can be viewed (reading from most significant bit to least significant bit) as specifying\n• the n numbers W1, . . . ,Wn; and • the value ∑n\ni=1 Wi(2si − 1) of the candidate solution S ⊆ [n]. Note that this value is 0 if and only if S is a legitimate solution to the PARTITION instance specified by (W1, . . . ,Wn).\nSo we may view the input to f as the tuple (W1, . . . ,Wn, S ) and its corresponding output as the tuple (W1, . . . ,Wn, v) where v = ∑n i=1 Wi(2si − 1) ∈ N is the value of the candidate solution S .\nThe proof is by contradiction, so let us suppose that L is a learning algorithm that runs in polynomial time and learns to accuracy ǫ = 1/3. For any “target distribution” p ∈ [0, 1]m, if L is given access to q(n) = poly(n) many independent draws from f (p), then with probability 9/10 algorithm L outputs a vector p̂ = ( p̂1, . . . , p̂m) of probabilities s.t. the total variation distance dTV( f (p), f ( p̂)) is at most 1/3.\nWe now explain how L yields a randomized poly(n)-time algorithm A to solve PARTITION. Given a PARTITION instance (W1, . . . ,Wn) as input, algorithm A runs L on a data set consisting of q(n) copies of the tuple (W1, . . . ,Wn, 0). If L fails to return a vector p̂ then A outputs “no” (meaning that the PARTITION instance has no solution). If L returns a vector p̂ then:\n• A checks that ∏n2\ni=1 max{p̂i, 1 − p̂i} ≥ 2/3; if not it returns “no.”\n• If A reaches this step, for each i ∈ [n2] let bi be the result of rounding p̂i to the nearest integer (0 or 1) and let (W′1, . . . ,W ′ n) be the PARTITION instance represented by the string (b1, . . . , bn2). A checks that\n(W′1, . . . ,W ′ n) is identical to (W1, . . . ,Wn); if not it outputs “no.”\n• If A reaches this step, then A draws 100 random n-bit strings x1, . . . , x100 independently from the product distribution ( p̂n2+1, . . . , p̂n2+n) and evaluates ∑n i=1 W ′ i (2xi − 1) on each of them. If any evaluation yields 0\nthen A outputs “yes” and otherwise it evaluates “no.”\nWe now prove correctness. Suppose first that (W1, . . . ,Wn) is a yes-instance of PARTITION. With probability 1 the data set consisting of q(n) copies of (W1, . . . ,Wn, 0) is identical to the outcome of q(n) draws from the distribution f (p⋆), where each coordinate of p⋆ is either 0 or 1, the first n2 coordinates p⋆1 , . . . , p ⋆ n2\nencode the numbers (W1, . . . ,Wn), and the last n coordinates encode a legitimate solution S for (W1, . . . ,Wn). Thus, with probability at least 9/10 the algorithm L outputs a vector p̂ = ( p̂1, . . . , p̂m) s.t. dTV( f ( p̂), f (p⋆)) ≤ 1/3. Since f (p⋆) puts all its weight on one output string (W1, . . . ,Wn, 0), it must indeed be the case that ∏n2 i=1 max{p̂i, 1 − p̂i} ≥ 2/3, and it is easy to see that the string b = (b1, . . . , bn2 ) defined in the second bullet will be identical to (W1, . . . ,Wn). Thus (W′1, . . . ,W ′ n) is identical to (W1, . . . ,Wn), and A makes it through the second bullet. Finally, since dTV( f ( p̂), f (p⋆)) ≤ 1/3, in expectation at least 2/3 of the 100 strings independently drawn from ( p̂n2+1, . . . , p̂m) should be legitimate solutions, and the probablity that none of x1, . . . , x100 is a legitimate solution is at most 0.001. Thus, if (W1, . . . ,Wn) is a yes-instance of PARTITION, the overall probability that A outputs “yes” is at least 0.89.\nNow suppose that (W1, . . . ,Wn) is a no-instance of PARTITION, but that A outputs “yes” on (W1, . . . ,Wn) with probability at least 0.1. This means that with probability at least 0.1, L outputs a vector p̂ such that∏n2\ni=1 max{p̂i, 1 − p̂i} ≥ 2/3, which can be uniquely decoded into a PARTITION instance (W ′ 1, . . . ,W ′ n) which must equal (W1, . . . ,Wn). The PARTITION instance (W′1, . . . ,W ′ n) = (W1, . . . ,Wn) must be satisfied with probability at least 1/1000 by a random string drawn from the probability distribution ( p̂n+1, . . . , p̂m) (for otherwise the probability of a “yes” output would be less than 1/10). But this violates the assumption that (W1, . . . ,Wn) is a no-instance. So if (W1, . . . ,Wn) is a no-instance of PARTITION, then it must be the case that A outputs “no” on (W1, . . . ,Wn) with probability less than 0.1.\nThus we have shown that A is a BPP algorithm for the PARTITION problem, and Theorem 2 is proved.\nD Proof of Theorem 3: f (x) = ∑k\ni=k/2+1 ixi requires Ω(k) samples\nWe define a probability distribution over problem instances (i.e. target probability vectors p) as follows: A subset S ⊂ {k/2+1, . . . , k} of size |S | = k/100 is drawn uniformly at random, i.e. each of the ( k/2\nk/100\n) outcomes\nfor S is equally likely. For each i ∈ S the value pi equals 100/k = 1/|S |, and for all other i the value pi equals 0. We will need two easy lemmas:\nLemma 23 Fix any S , p as described above. For any j ∈ {k/2 + 1, . . . , k} we have f (p)( j) , 0 if and only if j ∈ S . For any j ∈ S the value f (p)( j) is exactly (100/k)(1 − 100/k)k/100−1 > 35/k (for k sufficiently large), and similarly f (p)({k/2 + 1, . . . , k}) > 0.35 (again for k sufficiently large).\nThe first claim of the lemma holds because any set of c ≥ 2 numbers from {k/2 + 1, . . . , k} must sum to more than k. The second claim holds because the only way a draw of X from p can have f (X) = j is if X j = 1 and all other Xi are 0 (and uses limx←0+ (1 − 1/x)x = 1/e).\nThe next lemma is an easy consequence of Chernoff bounds:\nLemma 24 Fix any p as defined above, and consider a sequence of k/2000 independent draws of X from p. With probability 1 − e−Ω(k) the total number of indices j ∈ [k] such that X j = 1 in any of the k/2000 draws is at most k/1000.\nProof of Theorem 3: Let L be a learning algorithm that receives k/2000 samples. Let S ⊂ {k/2 + 1, . . . , k} and the target distribution p be chosen randomly as defined above.\nWe consider an augmented learner L′ that is given “extra information.” For each point f (X) in the sample, instead of receiving f (X) = ∑k i=k/2+1 iXi, the learner L\n′ is given the entire vector (X1, . . . , Xk) ∈ {0, 1}k. Let T denote the set of elements j ∈ {k/2+1, . . . , k} for which the learner is given some vector X that has X j = 1. By Lemma 24 we have |T | ≤ k/1000 with probability at least 1 − e−Ω(k); we condition on the event |T | ≤ k/1000 going forth.\nFix any value ℓ ≤ k/1000. Conditioned on |T | = ℓ, the set T is equally likely to be any ℓ-element subset of S , and all possible “completions” of T with an additional k/100−ℓ ≥ 9k/1000 elements of {k/2+1, . . . , k}\\T are equally likely to be the true set S .\nLet p̂ = ( p̂1, . . . , p̂k) denote the hypothesis vector of probabilities that L′ outputs. Let R denote the set {k/2 + 1, . . . , k} \\ T ; note that since |T | = ℓ ≤ k/1000, we have |R| ≥ 499k/1000. We consider two possible cases for p̂ and show that in either case the learner’s hypothesis distribution f ( p̂) has high error (in the first case because of outcomes in R, in the second case because of the outcome 0) with high probability.\nCase 1: Fewer than k/4 of the (at least 499k/1000) elements i ∈ R have p̂i ≥ 10/k. Let U be the set of those (fewer than k/4) elements. Since every (k/100 − ℓ)-element subset of R is equally likely to be the correct completion S \\T , and as observed above k/100−ℓ is at least 9k/1000, an elementary argument shows that with probability 1− e−Ω(k) we have that U contains at most 8k/1000 of the k/100− ℓ ≥ 9k/1000 elements of S \\T. Assuming this happens, Lemma 23 now implies that each of the (at least) k/1000 “missed” elements (that are in S \\ T but not in U) contributes at least 35/k − 10/k > 25/k to the total variation distance between f (p) and f ( p̂). (This is because each point in (S \\ T ) \\ U has probability at most 10/k under f ( p̂); the only way to get such an outcome i from f ( p̂) is for the draw of X̂ from p̂ to have X̂i = 1, which occurs with probability 10/k.) So in this case dTV( f (p, f ( p̂)) is at least 25/1000 = 1/40.\nCase 2: At least k/4 of the (at least 499k/1000) elements i ∈ R have p̂i ≥ 10/k. In this case, we have f ( p̂)(0) ≤ (1 − 10/k)k/4 < 1/10. Since the target distribution f (p) has f (p)(0) = (1 − 100/k)k/100 > 0.35, it follows that dTV( f (p), f ( p̂)) ≥ 1/4 in this case."
    }, {
      "heading" : "E A Simple Proof of the DKW Inequality",
      "text" : "Recall the framework of the DKW inequality: X is any random variable supported on {0, 1, . . . , n}. Z1, . . . , Zk are independent copies of X, and Z(ℓ)i is defined to be 1Zi≤ℓ, for all ℓ = 0, . . . , n and i = 1, . . . , k. Finally, define F̂X(ℓ) := ∑ i Z (ℓ) i /k.\nWe prove:\nTheorem 7 (DKW Inequality) Let k = max{576, (9/8) ln(1/δ)} · (1/ǫ2). Then with probability at least 1 − δ we have\nmax 0≤ℓ≤n\n∣∣∣F̂X(ℓ) − FX(ℓ) ∣∣∣ ≤ ǫ.\nWe first prove the following weaker version of the inequality:\nTheorem 25 Let k = 4 δǫ2 . Then with probability at least 1 − δ we have\nmax 0≤ℓ≤n\n∣∣∣F̂X(ℓ) − FX(ℓ) ∣∣∣ ≤ ǫ.\nProof of Theorem 25: Let L be the smallest index in {0, . . . , n} such that 12 < FX(L). We first show the following.\nLemma 26 Let k = 1 ǫ2c , where c > 0. Then\nPr [\nmax 0≤ℓ≤L−1\n∣∣∣F̂X(ℓ) − FX(ℓ) ∣∣∣ > ǫ ] ≤ 2c.\nProof of Lemma 26: If L = 0 the statement is vacuously true. If L > 0, let us denote Λℓ := F̂X(ℓ) − FX(ℓ), for ℓ = 0, . . . ,L − 1, and define\nΩ−1 := 0\nΩℓ :=  Λℓ 1−FX (ℓ) , if Λ j ≤ ǫ for all 0 ≤ j ≤ ℓ − 1\nΩℓ−1, otherwise , for ℓ = 0, . . . ,L − 1.\nAlso, define Ω∗ −1 = 0 and Ω ∗ ℓ := Λℓ1−FX (ℓ) , for ℓ = 0, . . . ,L − 1.\nClaim 27 Both {Ω∗ ℓ }ℓ=−1,...,L−1 and {Ωℓ}ℓ=−1,...,L−1 are martingale sequences.\nProof: Clearly, E [ Ω∗0 ] = 0 = E [Ω0]. Moreover, for ℓ = 1, . . . ,L − 1:\nE [ Λℓ Λℓ−1 =\nm k − FX(ℓ − 1)\n] =\nm k + k − m k Pr[Z1 = ℓ | Z1 ≥ ℓ] − FX(ℓ)\n= m k + k − m k FX(ℓ) − FX(ℓ − 1) 1 − FX(ℓ − 1) − FX(ℓ) = 1 − FX(ℓ)\n1 − FX(ℓ − 1) · [m k − FX(ℓ − 1) ]\n= 1 − FX(ℓ)\n1 − FX(ℓ − 1) · Λℓ−1.\nIt follows that the sequence {Ω∗ ℓ }ℓ=−1,...,L−1 is a martingale sequence. Hence, {Ωℓ}ℓ=−1,...,L−1 is also a martingale sequence.\nNote that\nL−1∑\nℓ=0\nE [ (Ωℓ −Ωℓ−1)2 ] = L−1∑\nℓ=0\nE [ (Ω2ℓ + Ω 2 ℓ−1 − 2ΩℓΩℓ−1 ]\n=\nL−1∑\nℓ=0\nE [ (Ω2ℓ + Ω 2 ℓ−1 − 2(Ωℓ −Ωℓ−1 + Ωℓ−1)Ωℓ−1 ]\n=\nL−1∑\nℓ=0\nE [ (Ω2ℓ −Ω 2 ℓ−1 − 2(Ωℓ −Ωℓ−1)Ωℓ−1 ]\n= E [ Ω2L−1 ] − E [ Ω2−1 ] − L−1∑\nℓ=0\n2E [(Ωℓ −Ωℓ−1)Ωℓ−1]\n= E [ Ω2L−1 ] − E [ Ω2−1 ] = E [ Ω2L−1 ] ,\nwhere in the second to last line we used the martingale property and in the last line we used that Ω−1 = 0. The same analysis holds true for the martingale sequence Ω∗\nℓ giving:\nL−1∑\nℓ=0\nE [ (Ω∗ℓ −Ω ∗ ℓ−1) 2 ] = E [ (Ω∗L−1) 2 ] .\nIn particular, the above imply that E [ (ΩL−1)2 ] ≤ E [ (Ω∗ L−1) 2 ] . Now we have:\nPr[max ℓ Λℓ > ǫ] ≤ Pr\n[ ΩL−1 >\nǫ\n1 − FX(0)\n]\n≤ Pr [ ΩL−1 > ǫ ]\n≤ 1 ǫ2\nE [ Ω2L−1 ]\n≤ 1 ǫ2\nE [ (Ω∗L−1) 2 ]\n= 1 ǫ2 · 1 (1 − FX(L − 1))2 · E\n[ (ΛL−1)2 ]\n= 1 ǫ2 · 1 (1 − FX(L − 1))2 · Var[ΛL−1] ≤ 4 ǫ2 · Var[ΛL−1]\n≤ 4 ǫ2 · Var\n ∑ i Z (L−1) i\nk\n\n= 4 ǫ2 · 1 k FX(L − 1) · (1 − FX(L − 1)) ≤ 1 ǫ2 · 1 k\nConsidering the random variables Λ′ ℓ := −Λℓ and repeating the analysis above, we can establish in a similar fashion that\nPr[min ℓ Λℓ < −ǫ] ≤ 1 ǫ2 · 1 k .\nCombining the above together with a union bound completes the proof of the lemma.\nNow let us denote by L′ the smallest index in {0, . . . , n} such that 1/2 < 1 − FX(n − L′ − 1). Applying Lemma 26 to the random variable n − X we obtain the following.\nLemma 28 Let k = 1 ǫ2c , where c > 0. Then\nPr [\nmax n−L′≤ℓ≤n−1\n∣∣∣F̂X(ℓ) − FX(ℓ) ∣∣∣ > ǫ ] ≤ 2c.\nRecall that FX(L) > 1/2 > FX(n − L′ − 1). Hence, L > n − L′ − 1, which implies that L − 1 ≥ n − L′ − 1.\nThis observation, a union bound and Lemmas 26 and 28 (applied for c = δ/4) imply Theorem 25.\nWe are now ready to prove the actual DKW inequality. Let M denote the random variable\nmax 0≤ℓ≤n |Λℓ| = max 0≤ℓ≤n\n∣∣∣F̂X(ℓ) − FX(ℓ) ∣∣∣ .\nSince M is defined by the outcomes of Z1, . . . , Zk, we can write M = g(Z1, . . . , Zk), for some function g : Rk → R. It is also easy to see that g(Z1, . . . , Zk) is 1/k-Lipschitz as a function of its arguments Z1, . . . , Zk. Since the Zis are independent, we can apply McDiarmid’s inequality to obtain\nPr [M − E[M] > ǫ] ≤ exp(−2ǫ2k).\nBy repeated applications of Theorem 25 we show the following:\nClaim 29 Let k ≥ 256 ǫ2 . Then\nEZ1 ,...,Zk [M] ≤ ǫ\n2 .\nProof of Claim 29: Note that M is supported in [0, 1]. We have\nE[M] ≤ ǫ\n4 · Pr[0 ≤ M ≤ ǫ/4] +\n⌈log(4/ǫ)⌉∑\ni=1\n( 2iǫ 4 ) · Pr[ 2i−1ǫ 4 < M ≤ 2iǫ 4 ]\n≤ ǫ\n4 +\n⌈log(4/ǫ)⌉∑\ni=1\n( 2iǫ 4 ) · Pr[M > 2i−1ǫ 4 ]\n≤ ǫ\n4 +\n⌈log(4/ǫ)⌉∑\ni=1\n( 2iǫ 4 ) · 2−2i\n≤ ǫ\n4 +\n∞∑\ni=1\nǫ\n4 · 2i =\nǫ\n2\nwhere we used Theorem 25 for the third inequality.\nNote that Claim 29 imposes a lower bound on the sample complexity. From this claim and McDiarmid’s inequality we get\nPr [M > 3ǫ/2] ≤ Pr [M − E[M] > ǫ] ≤ exp(−2ǫ2k).\nTheorem 7 immediately follows by setting 2ǫ/3 in place of ǫ.\nF Proof of Theorem 5: Learning sums of Bernoullis in poly(log(n), 1/ǫ) time with efficient hypotheses\nIn this section we observe that the probability theory literature already provides a non-proper algorithm (Birgé (1997)) that can be used as an alternative to our Theorem 4 for learning a sum of n Bernoulli random variables. This algorithm has faster running time, requiring only poly(log n, 1/ǫ) time steps, but significantly worse sample complexity of log(n) ·poly(1/ǫ) samples (recall that Theorem 4 requires only poly(1/ǫ) samples independent of n).\nWe say that a distribution p over domain {0, 1, . . . , n} is unimodal if there exists some mode M ∈ {0, 1, . . . , n} (not necessarily unique) such that the probability density function (pdf) of p is monotone nonincreasing on {0, . . . , M} and monotone nondecreasing on {M, . . . , n}. Our starting point is the observation that any sum of n Bernoullis is a unimodal distribution over {0, 1, . . . , n}. (This can be shown by a straightforward induction on n, see e.g. Keilson and Gerber (1971).) This observation lets us use a powerful algorithm due to Birgé (1997) that can learn any unimodal distribution to accuracy ǫ in total variation distance using sample complexity is optimal up to constant factors (Birgé (1987)). (Birgé’s work deals with unimodal distributions over the continuous interval [0, n], but it is easily modified to apply to our discrete setting.) His algorithm uses O(log n/ǫ3) samples and has overall running time of O(log2 n)/ǫ3 bit operations (note that this running time is best possible, given the sample complexity, since each sample is an Ω(log n) bit string.). It outputs a hypothesis distribution that is a histogram over O((log n)/ǫ) intervals that cover {0, . . . , n}: more precisely, the hypothesis is uniform within each interval, and for each interval the total mass it assigns to the interval is simply the fraction of samples that landed in that interval. Thus the hypothesis distribution has a succinct description and can be efficiently evaluated using a small amount of randomness as claimed in Theorem 5."
    } ],
    "references" : [ {
      "title" : "Nearly tight bounds on the learnability of evolution",
      "author" : [ "Andris Ambainis", "Richard Desper", "Martin Farach", "Sampath Kannan" ],
      "venue" : "In FOCS,",
      "citeRegEx" : "Ambainis et al\\.,? \\Q1997\\E",
      "shortCiteRegEx" : "Ambainis et al\\.",
      "year" : 1997
    }, {
      "title" : "Estimating a density under order restrictions: Nonasymptotic minimax risk",
      "author" : [ "L. Birgé" ],
      "venue" : "Annals of Statistics,",
      "citeRegEx" : "Birgé.,? \\Q1987\\E",
      "shortCiteRegEx" : "Birgé.",
      "year" : 1987
    }, {
      "title" : "Estimation of unimodal densities without smoothness assumptions",
      "author" : [ "L. Birgé" ],
      "venue" : "Annals of Statistics,",
      "citeRegEx" : "Birgé.,? \\Q1997\\E",
      "shortCiteRegEx" : "Birgé.",
      "year" : 1997
    }, {
      "title" : "Evolutionary trees can be learned in polynomial time in the two state general Markov model",
      "author" : [ "M. Cryan", "L. Goldberg", "P. Goldberg" ],
      "venue" : "SIAM Journal on Computing,",
      "citeRegEx" : "Cryan et al\\.,? \\Q2002\\E",
      "shortCiteRegEx" : "Cryan et al\\.",
      "year" : 2002
    }, {
      "title" : "An efficient ptas for two-strategy anonymous games",
      "author" : [ "Constantinos Daskalakis" ],
      "venue" : "WINE 2008; full version in CoRR,",
      "citeRegEx" : "Daskalakis.,? \\Q2008\\E",
      "shortCiteRegEx" : "Daskalakis.",
      "year" : 2008
    }, {
      "title" : "On oblivious ptas’s for nash equilibrium",
      "author" : [ "Constantinos Daskalakis", "Christos H. Papadimitriou" ],
      "venue" : "STOC 2009; full version in,",
      "citeRegEx" : "Daskalakis and Papadimitriou.,? \\Q2011\\E",
      "shortCiteRegEx" : "Daskalakis and Papadimitriou.",
      "year" : 2011
    }, {
      "title" : "A universally acceptable smoothing factor for kernel density estimation",
      "author" : [ "L. Devroye", "G. Lugosi" ],
      "venue" : "Annals of Statistics,",
      "citeRegEx" : "Devroye and Lugosi.,? \\Q1996\\E",
      "shortCiteRegEx" : "Devroye and Lugosi.",
      "year" : 1996
    }, {
      "title" : "Nonasymptotic universal smoothing factors, kernel complexity and Yatracos classes",
      "author" : [ "L. Devroye", "G. Lugosi" ],
      "venue" : "Annals of Statistics,",
      "citeRegEx" : "Devroye and Lugosi.,? \\Q1996\\E",
      "shortCiteRegEx" : "Devroye and Lugosi.",
      "year" : 1996
    }, {
      "title" : "Combinatorial methods in density estimation",
      "author" : [ "L. Devroye", "G. Lugosi" ],
      "venue" : null,
      "citeRegEx" : "Devroye and Lugosi.,? \\Q2001\\E",
      "shortCiteRegEx" : "Devroye and Lugosi.",
      "year" : 2001
    }, {
      "title" : "Asymptotic minimax character of the sample distribution function and of the classical multinomial estimator",
      "author" : [ "A. Dvoretzky", "J. Kiefer", "J. Wolfowitz" ],
      "venue" : "Ann. Mathematical Statistics,",
      "citeRegEx" : "Dvoretzky et al\\.,? \\Q1956\\E",
      "shortCiteRegEx" : "Dvoretzky et al\\.",
      "year" : 1956
    }, {
      "title" : "Efficient algorithms for inverting evolution",
      "author" : [ "Martin Farach", "Sampath Kannan" ],
      "venue" : "J. ACM,",
      "citeRegEx" : "Farach and Kannan.,? \\Q1999\\E",
      "shortCiteRegEx" : "Farach and Kannan.",
      "year" : 1999
    }, {
      "title" : "Learning mixtures of product distributions over discrete domains",
      "author" : [ "Jon Feldman", "Ryan O’Donnell", "Rocco A. Servedio" ],
      "venue" : "SIAM J. Comput.,",
      "citeRegEx" : "Feldman et al\\.,? \\Q2008\\E",
      "shortCiteRegEx" : "Feldman et al\\.",
      "year" : 2008
    }, {
      "title" : "Estimating a mixture of two product distributions",
      "author" : [ "Y. Freund", "Y. Mansour" ],
      "venue" : "In Proceedings of the Twelfth Annual Conference on Computational Learning Theory,",
      "citeRegEx" : "Freund and Mansour.,? \\Q1999\\E",
      "shortCiteRegEx" : "Freund and Mansour.",
      "year" : 1999
    }, {
      "title" : "Polya. Inequalities",
      "author" : [ "G.H. Hardy", "J.E. Littlewood" ],
      "venue" : null,
      "citeRegEx" : "Hardy et al\\.,? \\Q1934\\E",
      "shortCiteRegEx" : "Hardy et al\\.",
      "year" : 1934
    }, {
      "title" : "On the learnability of discrete distributions",
      "author" : [ "M. Kearns", "Y. Mansour", "D. Ron", "R. Rubinfeld", "R. Schapire", "L. Sellie" ],
      "venue" : "In Proceedings of the 26th Symposium on Theory of Computing,",
      "citeRegEx" : "Kearns et al\\.,? \\Q1994\\E",
      "shortCiteRegEx" : "Kearns et al\\.",
      "year" : 1994
    }, {
      "title" : "Some Results for Discrete Unimodality",
      "author" : [ "J. Keilson", "H. Gerber" ],
      "venue" : "J. American Statistical Association,",
      "citeRegEx" : "Keilson and Gerber.,? \\Q1971\\E",
      "shortCiteRegEx" : "Keilson and Gerber.",
      "year" : 1971
    }, {
      "title" : "The tight constant in the Dvoretzky-Kiefer-Wolfowitz inequality",
      "author" : [ "P. Massart" ],
      "venue" : "Annals of Probability,",
      "citeRegEx" : "Massart.,? \\Q1990\\E",
      "shortCiteRegEx" : "Massart.",
      "year" : 1990
    }, {
      "title" : "Evaluation may be easier than generation",
      "author" : [ "M. Naor" ],
      "venue" : "In Proceedings of the 28th Symposium on Theory of Computing (STOC),",
      "citeRegEx" : "Naor.,? \\Q1996\\E",
      "shortCiteRegEx" : "Naor.",
      "year" : 1996
    }, {
      "title" : "The unreasonable effectiveness of martingales",
      "author" : [ "Y. Peres" ],
      "venue" : "Plenary talk at SODA,",
      "citeRegEx" : "Peres.,? \\Q2009\\E",
      "shortCiteRegEx" : "Peres.",
      "year" : 2009
    }, {
      "title" : "Translated Poisson Approximation Using Exchangeable Pair Couplings",
      "author" : [ "A. Röllin" ],
      "venue" : "ArXiV Report,",
      "citeRegEx" : "Röllin.,? \\Q2006\\E",
      "shortCiteRegEx" : "Röllin.",
      "year" : 2006
    }, {
      "title" : "Rates of convergence of minimum distance estimators and Kolmogorov’s entropy",
      "author" : [ "Y.G. Yatracos" ],
      "venue" : "Annals of Statistics,",
      "citeRegEx" : "Yatracos.,? \\Q1985\\E",
      "shortCiteRegEx" : "Yatracos.",
      "year" : 1985
    } ],
    "referenceMentions" : [ {
      "referenceID" : 8,
      "context" : "As a second example, we point out that the transformed product distribution learning model is broad enough to encompass the problem of learning an unknown mixture of k product distributions over {0, 1}n that was considered by Freund and Mansour (1999), Cryan et al.",
      "startOffset" : 226,
      "endOffset" : 252
    }, {
      "referenceID" : 2,
      "context" : "As a second example, we point out that the transformed product distribution learning model is broad enough to encompass the problem of learning an unknown mixture of k product distributions over {0, 1}n that was considered by Freund and Mansour (1999), Cryan et al. (2002), Feldman et al.",
      "startOffset" : 253,
      "endOffset" : 273
    }, {
      "referenceID" : 2,
      "context" : "As a second example, we point out that the transformed product distribution learning model is broad enough to encompass the problem of learning an unknown mixture of k product distributions over {0, 1}n that was considered by Freund and Mansour (1999), Cryan et al. (2002), Feldman et al. (2008). For simplicity we describe the case k = 2: there are unknown product distributions p, q over {0, 1}n and unknown mixing weights πp, πq = 1 − πp.",
      "startOffset" : 253,
      "endOffset" : 296
    }, {
      "referenceID" : 2,
      "context" : "As a second example, we point out that the transformed product distribution learning model is broad enough to encompass the problem of learning an unknown mixture of k product distributions over {0, 1}n that was considered by Freund and Mansour (1999), Cryan et al. (2002), Feldman et al. (2008). For simplicity we describe the case k = 2: there are unknown product distributions p, q over {0, 1}n and unknown mixing weights πp, πq = 1 − πp. The learner is given independent draws from the mixture distribution (each draw is independently taken from p with probability πp and from q with probability πq), and must output hypothesis product distributions p̂, q̂ and hypothesis mixing weights π̂p, π̂q. This problem is easily seen to be equivalent to the transformed product distribution learning problem for the function f : {0, 1}2n+1 → {0, 1}n which is such that on input (z, x1, . . . , xn, y1, . . . , yn) ∈ {0, 1}2n+1 the i-th bit of f ’s output is zxi + (1 − z)yi. It is easy to see that if the target vector of probabilities for f is (πp, p1, . . . , pn, q1, . . .qn) then samples of f are distributed exactly according to the mixture of product distributions, and finding a good hypothesis vector in [0, 1]2n+1 amounts to finding a hypothesis mixing weight π̂p and hypothesis product distributions p̂, q̂ as required in the original “learning mixtures of product distributions” problem. Connection to prior work: The transformed product distribution learning model is related to the PACstyle model of learning discrete probability distributions that was introduced by Kearns et al. (1994) and studied in several subsequent works of Naor (1996), Ambainis et al.",
      "startOffset" : 253,
      "endOffset" : 1596
    }, {
      "referenceID" : 2,
      "context" : "As a second example, we point out that the transformed product distribution learning model is broad enough to encompass the problem of learning an unknown mixture of k product distributions over {0, 1}n that was considered by Freund and Mansour (1999), Cryan et al. (2002), Feldman et al. (2008). For simplicity we describe the case k = 2: there are unknown product distributions p, q over {0, 1}n and unknown mixing weights πp, πq = 1 − πp. The learner is given independent draws from the mixture distribution (each draw is independently taken from p with probability πp and from q with probability πq), and must output hypothesis product distributions p̂, q̂ and hypothesis mixing weights π̂p, π̂q. This problem is easily seen to be equivalent to the transformed product distribution learning problem for the function f : {0, 1}2n+1 → {0, 1}n which is such that on input (z, x1, . . . , xn, y1, . . . , yn) ∈ {0, 1}2n+1 the i-th bit of f ’s output is zxi + (1 − z)yi. It is easy to see that if the target vector of probabilities for f is (πp, p1, . . . , pn, q1, . . .qn) then samples of f are distributed exactly according to the mixture of product distributions, and finding a good hypothesis vector in [0, 1]2n+1 amounts to finding a hypothesis mixing weight π̂p and hypothesis product distributions p̂, q̂ as required in the original “learning mixtures of product distributions” problem. Connection to prior work: The transformed product distribution learning model is related to the PACstyle model of learning discrete probability distributions that was introduced by Kearns et al. (1994) and studied in several subsequent works of Naor (1996), Ambainis et al.",
      "startOffset" : 253,
      "endOffset" : 1651
    }, {
      "referenceID" : 0,
      "context" : "(1994) and studied in several subsequent works of Naor (1996), Ambainis et al. (1997), Farach and Kannan (1999), Freund and Mansour (1999), Cryan et al.",
      "startOffset" : 63,
      "endOffset" : 86
    }, {
      "referenceID" : 0,
      "context" : "(1994) and studied in several subsequent works of Naor (1996), Ambainis et al. (1997), Farach and Kannan (1999), Freund and Mansour (1999), Cryan et al.",
      "startOffset" : 63,
      "endOffset" : 112
    }, {
      "referenceID" : 0,
      "context" : "(1994) and studied in several subsequent works of Naor (1996), Ambainis et al. (1997), Farach and Kannan (1999), Freund and Mansour (1999), Cryan et al.",
      "startOffset" : 63,
      "endOffset" : 139
    }, {
      "referenceID" : 0,
      "context" : "(1994) and studied in several subsequent works of Naor (1996), Ambainis et al. (1997), Farach and Kannan (1999), Freund and Mansour (1999), Cryan et al. (2002), Feldman et al.",
      "startOffset" : 63,
      "endOffset" : 160
    }, {
      "referenceID" : 0,
      "context" : "(1994) and studied in several subsequent works of Naor (1996), Ambainis et al. (1997), Farach and Kannan (1999), Freund and Mansour (1999), Cryan et al. (2002), Feldman et al. (2008). In the Kearns et al.",
      "startOffset" : 63,
      "endOffset" : 183
    }, {
      "referenceID" : 0,
      "context" : "(1994) and studied in several subsequent works of Naor (1996), Ambainis et al. (1997), Farach and Kannan (1999), Freund and Mansour (1999), Cryan et al. (2002), Feldman et al. (2008). In the Kearns et al. (1994) framework a learning problem is defined by a class C of Boolean circuits, and an instance of the problem corresponds to the choice of a specific (unknown to the learner) target circuit C ∈ C.",
      "startOffset" : 63,
      "endOffset" : 212
    }, {
      "referenceID" : 0,
      "context" : "(1994) and studied in several subsequent works of Naor (1996), Ambainis et al. (1997), Farach and Kannan (1999), Freund and Mansour (1999), Cryan et al. (2002), Feldman et al. (2008). In the Kearns et al. (1994) framework a learning problem is defined by a class C of Boolean circuits, and an instance of the problem corresponds to the choice of a specific (unknown to the learner) target circuit C ∈ C. The learner is given samples from C(X) where X is a uniform random string from {0, 1}m, and the learner must with high probability output a hypothesis circuit C such that the random variable C(X) is ǫ-close to C(X) (in KL-divergence). Strictly speaking the transformed product distribution learning model may be viewed as a special case of the Kearns et al model. This is done by considering a circuit class C that has a circuit C = Cp for each possible product distribution p over {0, 1}n; the circuit Cp first transforms the uniform distribution over {0, 1}m to the product distribution p over {0, 1}n and then applies the transformation function f to the output of p. However, learning problems C of this sort do not seem to have been previously considered in the Kearns et al. (1994) model, and we feel it is more natural to view our model as dual in spirit to the earlier model.",
      "startOffset" : 63,
      "endOffset" : 1192
    }, {
      "referenceID" : 0,
      "context" : "(1994) and studied in several subsequent works of Naor (1996), Ambainis et al. (1997), Farach and Kannan (1999), Freund and Mansour (1999), Cryan et al. (2002), Feldman et al. (2008). In the Kearns et al. (1994) framework a learning problem is defined by a class C of Boolean circuits, and an instance of the problem corresponds to the choice of a specific (unknown to the learner) target circuit C ∈ C. The learner is given samples from C(X) where X is a uniform random string from {0, 1}m, and the learner must with high probability output a hypothesis circuit C such that the random variable C(X) is ǫ-close to C(X) (in KL-divergence). Strictly speaking the transformed product distribution learning model may be viewed as a special case of the Kearns et al model. This is done by considering a circuit class C that has a circuit C = Cp for each possible product distribution p over {0, 1}n; the circuit Cp first transforms the uniform distribution over {0, 1}m to the product distribution p over {0, 1}n and then applies the transformation function f to the output of p. However, learning problems C of this sort do not seem to have been previously considered in the Kearns et al. (1994) model, and we feel it is more natural to view our model as dual in spirit to the earlier model. In Kearns et al. (1994) the learner’s task is to infer an unknown transformation (the circuit C) into which are fed n-bit strings that are known to be distributed uniformly.",
      "startOffset" : 63,
      "endOffset" : 1312
    }, {
      "referenceID" : 6,
      "context" : "By an approach similar to the algorithm of Devroye and Lugosi (2001) for choosing a density estimate, we show (Theorem 6) that if the space { f (p)}p∈[0,1]n of all f -transformed product distributions has an ǫ-cover of size N, then there is a generic learning algorithm for the f -transformed product distribution problem that uses O((log N)/ǫ2) samples.",
      "startOffset" : 43,
      "endOffset" : 69
    }, {
      "referenceID" : 6,
      "context" : "While the algorithm itself is simple, its analysis relies on a fundamental result from probability theory, known as the Dvoretzky-Kiefer-Wolfowitz inequality (Dvoretzky et al. (1956)), which may be viewed as a special case of the fundamental Vapnik-Chervonenkis theorem (see Chapter 3 of Devroye and Lugosi (2001)).",
      "startOffset" : 159,
      "endOffset" : 183
    }, {
      "referenceID" : 6,
      "context" : "(1956)), which may be viewed as a special case of the fundamental Vapnik-Chervonenkis theorem (see Chapter 3 of Devroye and Lugosi (2001)).",
      "startOffset" : 112,
      "endOffset" : 138
    }, {
      "referenceID" : 6,
      "context" : "(1956)), which may be viewed as a special case of the fundamental Vapnik-Chervonenkis theorem (see Chapter 3 of Devroye and Lugosi (2001)). In Appendix E we give a self-contained proof of the DKW inequality using elementary techniques (martingales and the method of bounded differences) and an interesting trick that goes back to Kolmogorov (see Peres (2009)); this proof is significantly different from the proofs we know of in the probability literature (see Dvoretzky et al.",
      "startOffset" : 112,
      "endOffset" : 359
    }, {
      "referenceID" : 6,
      "context" : "(1956)), which may be viewed as a special case of the fundamental Vapnik-Chervonenkis theorem (see Chapter 3 of Devroye and Lugosi (2001)). In Appendix E we give a self-contained proof of the DKW inequality using elementary techniques (martingales and the method of bounded differences) and an interesting trick that goes back to Kolmogorov (see Peres (2009)); this proof is significantly different from the proofs we know of in the probability literature (see Dvoretzky et al. (1956), Massart (1990), and Chapter 3 of Devroye and Lugosi (2001)).",
      "startOffset" : 112,
      "endOffset" : 485
    }, {
      "referenceID" : 6,
      "context" : "(1956)), which may be viewed as a special case of the fundamental Vapnik-Chervonenkis theorem (see Chapter 3 of Devroye and Lugosi (2001)). In Appendix E we give a self-contained proof of the DKW inequality using elementary techniques (martingales and the method of bounded differences) and an interesting trick that goes back to Kolmogorov (see Peres (2009)); this proof is significantly different from the proofs we know of in the probability literature (see Dvoretzky et al. (1956), Massart (1990), and Chapter 3 of Devroye and Lugosi (2001)).",
      "startOffset" : 112,
      "endOffset" : 501
    }, {
      "referenceID" : 6,
      "context" : "(1956)), which may be viewed as a special case of the fundamental Vapnik-Chervonenkis theorem (see Chapter 3 of Devroye and Lugosi (2001)). In Appendix E we give a self-contained proof of the DKW inequality using elementary techniques (martingales and the method of bounded differences) and an interesting trick that goes back to Kolmogorov (see Peres (2009)); this proof is significantly different from the proofs we know of in the probability literature (see Dvoretzky et al. (1956), Massart (1990), and Chapter 3 of Devroye and Lugosi (2001)).",
      "startOffset" : 112,
      "endOffset" : 545
    }, {
      "referenceID" : 11,
      "context" : "Hardy et al. (1934) section 2.",
      "startOffset" : 0,
      "endOffset" : 20
    }, {
      "referenceID" : 4,
      "context" : "Nevertheless, we extend the Kolmogorov distance learning algorithm to total variation distance via a delicate algorithm that exploits the detailed structure of a small ǫ-cover (Daskalakis and Papadimitriou (2011), Daskalakis (2008)) of the space of all distributions that are sums of independent Bernoulli random variables (see Theorem 9).",
      "startOffset" : 177,
      "endOffset" : 213
    }, {
      "referenceID" : 4,
      "context" : "Nevertheless, we extend the Kolmogorov distance learning algorithm to total variation distance via a delicate algorithm that exploits the detailed structure of a small ǫ-cover (Daskalakis and Papadimitriou (2011), Daskalakis (2008)) of the space of all distributions that are sums of independent Bernoulli random variables (see Theorem 9).",
      "startOffset" : 177,
      "endOffset" : 232
    }, {
      "referenceID" : 4,
      "context" : "Nevertheless, we extend the Kolmogorov distance learning algorithm to total variation distance via a delicate algorithm that exploits the detailed structure of a small ǫ-cover (Daskalakis and Papadimitriou (2011), Daskalakis (2008)) of the space of all distributions that are sums of independent Bernoulli random variables (see Theorem 9). Interestingly, this becomes feasible by establishing an analog of the aforementioned argument by Newton to a class of distributions used in the cover that are called heavy (see Lemma 15). This in turn relies on probabilistic approximation results via translated Poisson distributions (see Definition 18, Röllin (2006)).",
      "startOffset" : 177,
      "endOffset" : 658
    }, {
      "referenceID" : 1,
      "context" : "This lets us apply a powerful algorithm due to Birgé (1997) that can learn any unimodal distribution to accuracy ǫ using O(log n)/ǫ3 samples.",
      "startOffset" : 47,
      "endOffset" : 60
    }, {
      "referenceID" : 6,
      "context" : "”) This basic approach of running a tournament between distributions in an δ-cover is quite similar to the algorithm of Devroye and Lugosi for choosing a density estimate (see Devroye and Lugosi (1996a,b) and Chapters 6 and 7 of Devroye and Lugosi (2001)), which in turn built closely on the work of Yatracos (1985).",
      "startOffset" : 120,
      "endOffset" : 255
    }, {
      "referenceID" : 6,
      "context" : "”) This basic approach of running a tournament between distributions in an δ-cover is quite similar to the algorithm of Devroye and Lugosi for choosing a density estimate (see Devroye and Lugosi (1996a,b) and Chapters 6 and 7 of Devroye and Lugosi (2001)), which in turn built closely on the work of Yatracos (1985). Our algorithm achieves essentially the same bounds as these earlier approaches but there are some small differences.",
      "startOffset" : 120,
      "endOffset" : 316
    }, {
      "referenceID" : 9,
      "context" : "The Dvoretzky-Kiefer-Wolfowitz inequality (Dvoretzky et al. (1956), Massart (1990)) confirms this, and in fact shows that a surprisingly small value of k – independent of n – suffices.",
      "startOffset" : 43,
      "endOffset" : 67
    }, {
      "referenceID" : 9,
      "context" : "The Dvoretzky-Kiefer-Wolfowitz inequality (Dvoretzky et al. (1956), Massart (1990)) confirms this, and in fact shows that a surprisingly small value of k – independent of n – suffices.",
      "startOffset" : 43,
      "endOffset" : 83
    }, {
      "referenceID" : 18,
      "context" : "In Appendix E we give a self-contained proof of the theorem using elementary techniques (martingales and the method of bounded differences) and an interesting trick that goes back to Kolmogorov (see Peres (2009)).",
      "startOffset" : 199,
      "endOffset" : 212
    }, {
      "referenceID" : 4,
      "context" : "The following is Theorem 9 of the full version of (Daskalakis and Papadimitriou (2011)):",
      "startOffset" : 51,
      "endOffset" : 87
    }, {
      "referenceID" : 4,
      "context" : "(We remark that Daskalakis (2008) establishes the same theorem, except that the size of the cover given there, as well as the time needed to produce it, are n3 ·O(1/ǫ)+n · ( 1 ǫ )O(1/ǫ2) .",
      "startOffset" : 16,
      "endOffset" : 34
    }, {
      "referenceID" : 19,
      "context" : "Definition 18 (Röllin (2006)) We say that an integer random variable Y has a translated Poisson distribution with paremeters μ and σ2 and write L(Y) = T P(μ, σ2) if L(Y − ⌊μ − σ2⌋) = Poisson(σ2 + {μ − σ2}), where {μ − σ2} represents the fractional part of μ − σ2.",
      "startOffset" : 15,
      "endOffset" : 29
    }, {
      "referenceID" : 4,
      "context" : "Given the above, and following Daskalakis (2008) (see Section 6.",
      "startOffset" : 31,
      "endOffset" : 49
    } ],
    "year" : 2011,
    "abstractText" : "We consider the problem of learning an unknown product distribution X over {0, 1}n using samples f (X) where f is a known transformation function. Each choice of a transformation function f specifies a learning problem in this framework. Information-theoretic arguments show that for every transformation function f the corresponding learning problem can be solved to accuracy ǫ, using Õ(n/ǫ2) examples, by a generic algorithm whose running time may be exponential in n. We show that this learning problem can be computationally intractable even for constant ǫ and rather simple transformation functions. Moreover, the above sample complexity bound is nearly optimal for the general problem, as we give a simple explicit linear transformation function f (x) = w · x with integer weights wi ≤ n and prove that the corresponding learning problem requires Ω(n) samples. As our main positive result we give a highly efficient algorithm for learning a sum of independent unknown Bernoulli random variables, corresponding to the transformation function f (x) = ∑n i=1 xi. Our algorithm learns to ǫ-accuracy in poly(n) time, using a surprising poly(1/ǫ) number of samples that is independent of n. We also give an efficient algorithm that uses log n · poly(1/ǫ) samples but has running time that is only poly(log n, 1/ǫ).",
    "creator" : "LaTeX with hyperref package"
  }
}