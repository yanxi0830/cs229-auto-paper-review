{
  "name" : "1312.1031.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "Analysis of Distributed Stochastic Dual Coordinate Ascent",
    "authors" : [ "Tianbao Yang", "Shenghuo Zhu", "Rong Jin", "Yuanqing Lin" ],
    "emails" : [ "ylin}@nec-labs.com,", "rongjin@cse.msu.edu" ],
    "sections" : [ {
      "heading" : null,
      "text" : "ar X\niv :1\n31 2.\n10 31\nv2 [\ncs .D\nC ]\n2 3\nM ar"
    }, {
      "heading" : "1 Introduction",
      "text" : "With the exponential growth of data, it has become an urgent task to design distributed (or parallel) optimization for big data analytics. The surge of a large cluster of machines has made the distributed optimization possible. The goal of distributed optimization is to optimize a certain objective defined over millions of billions of data that is distributed over many machines by utilizing the computational power of these machines.\nThe key concern in distributed optimization is how to coordinate the communication between so many machines such that the latency is minimized while the convergence performance is maximized. In this work, we focus on a particular distributed optimization algorithm, i.e., distributed stochastic dual coordinate ascent (DisDCA). The idea behind the stochastic dual coordinate ascent is to update the dual variables to increase the dual objective. It has been proven and observed that the stochastic dual coordinate ascent could achieve extraordinary performances in optimizing regularized loss minimization problems (e.g., SVMs, least square regression, and logistic regression).\nThe mechanism of DisDCA is to introduce an sequence of m updates on individual machines before performing a communication between machines. The motivation is that if the speed of gain in convergence is faster than the speed of incurred computation, the increasing m would alleviate the communication demand. Two variants of DisDCA (Yang, 2013)(the basic variant and the practical variant) have been proposed and compared empirically. Although the basic one (as referred to the naive variant in this paper) has been analyzed, however, its empirical performance is significantly worse than the practical variant. The contribution of the paper is to present some theoretical analysis as well as empirical studies of the practical DisDCA, which provides more insights into the practical DisDCA. In particular, we first prove the the practical DisDCA for orthogonal data (data on different machines or orthogonal) and establish its convergence. The result is not only interesting by itself, but also relates to the one-communication distributed optimization. Moreover, we analyze the practical\nDisDCA for general cases. Our analysis under the help of empirical studies have shown that it could yield an exponential speed-up in convergence by increasing m, which is significantly faster as compared to the partially linear speed-up of the naive variant."
    }, {
      "heading" : "2 DisDCA: the practical updates versus the naive updates",
      "text" : "We begin with a description of the practical updates and the naive updates of DisDCA. To this end, we introduce some notations.\nLet (xi, yi), i = 1, . . . , n denote a set of n training data with feature factor xi ∈ Rd and the label yi ∈ Y . Assume the training data are evenly distributed over K machines, and let Xk = (x k 1 , . . . , x k nk) denote the feature vectors of data on the k-th machine. The goal is to solve the following optimization problem:\nmin w∈Rd P (w)\nwhere P (w) = 1\nn\nn∑\ni=1\nφ(xi · w, yi) + g(w) (1)\nwhere x ·w denotes the inner product of two vectors, φ(x ·w, y) denote a convex loss function w.r.t the first argument, and g(w) denotes a convex regularizer. In this paper, we focus on smooth loss function φ(z, y) and strongly convex regularizer g(w), which satisfying the following properties, respectively:\n|∇φ(z1)−∇φ(z2)| ≤ L|z1 − z2| (2)\n‖∇g(w)−∇g(w)‖2 ≥ λ‖w1 − w2‖2 (3)\nwhere L characterizes the smoothness of φ(z) and λ characterizes the strong convexity of g(w). In order to solve the above problem by SDCA, we cast the primal problem in (1) into a dual problem. To this end, we introduce two notations, φ∗(α) and g∗(u) to denote the convex conjugate of φ(z, y) and g(w), respectively. Assuming g∗(u) is continuous function, we can cast the problem into the following dual problem:\nmax α∈Rn D(α)\nwhere 1\nn\nn∑\ni=1\n−φ∗i (−αi)− g ∗\n(\n1\nn\nn∑\ni=1\nαixi\n) (4)\nThe correspondence between the optimal solution w∗ to (1) and the optimal solution α∗ to (4) is given by\nw∗ = ∇g∗(v∗), v∗ = 1\nn\nn∑\ni=1\nαixi (5)\nBefore proceeding, let us recall several important applications of SDCA. For classification, we can choose the squared hinge loss function φ(z, y) = (1 − z)2+ or the logistic loss φ(z, y) = log(1 + exp(−yz)); for regression one can consider the least square loss φ(z, y) = |y − z|2/2. It is not difficult to derive that squared hinge loss is 2-smooth convex function, logistic loss is 1/2-smooth convex function, and least square loss is 1-smooth convex function. In terms of regularizer, one can consider the ℓ2 norm square regularizer g(w) = λ2 ‖w‖ 2 2 or the elastic net regularizer g(w) = λ 2 ‖w‖ 2 2 + µ‖w‖1, which are all λ-strongly convex regularizer. In the following analysis, we let c = L/λ denote the condition number of the problem, which is an important factor that impacts the convergence of optimization.\nTo facilitate the understanding of the algorithm and the proof, in the sequel we simply assume g(w) = λ/2‖w‖22, and thus g ∗(v) = 12λ‖v‖ 2 2. A slight modification of the algorithm and a careful examination of the analysis reveals that the results hold for any strongly convex function g(w) by exploring the following inequality:\ng∗(v +∆v) ≤ g∗(v) + ∆v · ∇g∗(v) + 1\n2λ ‖∆v‖22\nAlgorithm 1 DisDCA Algorithm Input: iterations T , size m, size K Excute: mR-SDCA(m,T ) on K machines\nmR-SDCA on machine k\nInput: iterations T , size m Load Data: Xk,yk Initializations: α0 = 0, w0k = w\n0 = ∇g∗(0) for t = 1 to T do\nSample m examples randomly, indexed by Im Update dual vars by Inc-Dual(wt−1, scale, Im) Update wtk = K λn ∑nk i=1 α t k,ixk,i Reduce wt = 1K ∑K k=1 w t k\nend for\nAlgorithm 2 Inc-Dual(wt−1, scale, Im)\nInput: wt−1, scale and Im //scale = mK if n-variant, otherwise K\np-variant Initializations: ut,0k = w t−1, αt,0k = α t−1 k for j = 1 to m do Let i = Im[j] n-variant: Compute ∆αk,i by solving (6) p-variant: Compute ∆αk,i by solving (7) p-variant: Update ut,jk = u t,j−1 k + K λn∆αk,ixk,i\nUpdate αt,jk,i = α t,j−1 k,i +∆αk,i\nend for\ndue to that the convex conjugate g∗(v) of a λ-strongly convex function g(w) is a 1/λ smooth convex function.\nWe present in Algorithm 1 the DisDCA algorithm. The algorithm deployes K processes mR-SDCA on K different machines that work on different subsets of data. The procedure mR-SDCA runs a total of T -iterations and at each iteration samples m examples and calls Inc-Dual to update the dual variables of the sampled examples. Algorithm 2 drafts the two different variants of the DisDCA for updating the sampled dual variables, where n-variant refers to the naive variant and p-variant refers to the practical variant.\nThe difference between the naive variant and the practical variant lies on how to update the dual variables at each iteration. In the naive variant, all the dual variables are updated using the same primal solution wt−1, i.e.,\n∆αk,i = max ∆α\n− φ∗k,i(−(α t−1 k,i +∆α)) −∆αx ⊤ k,iw t−1\n− [scale = mK]\n2λn (∆α)2‖xk,i‖ 2 2, (6)\nwhile the dual updates in the practical variant is achieved by using and updating local primal solution ut,jk , i.e.,\n∆αk,i = max ∆α\n−φ∗k,i(−(α t−1 k,i +∆α)) −∆αx ⊤ k,iu t,j−1 k\n− [scale = K]\n2λn (∆α)2‖xk,i‖ 2 2 (7)\nut,jk = u t,j−1 k +\nK λn ∆αk,ixk,i\nIntuitively, the practical variant makes use of the updated information as in the updated dual variables and therefore in the updated local primal solution ut,jk , therefore it is of no surprise that it can have\nbetter performances than the naive variants. From another point of view, by utilizing the updated solution ut,jk , the practical DisDCA is abel to use a larger step size (corresponding to smaller scale) in updating α.\nIt has been shown in (Yang, 2013), the procedure in Inc-Dual for the practical variant is to increase the objective of the following sub-dual problem:\nmax α\n1\nnk\n∑\ni∈Im\n−φ∗k,i(−αk,i) (8)\n+ λ\n2 ∥ ∥ ∥ ∥ ∥ wt−1 − 1\nλnk\n∑\ni∈Im\nαt−1k,i xk,i + 1\nλnk\n∑\ni∈Im\nαk,ixk,i ∥ ∥ ∥ ∥ ∥ 2\n2\nby employing SDCA to update the sampled dual variables once with initial dual solutions αt,0k,i = αt−1k,i .\nFigure 1 shows an empirical comparison between the two variants in optimizing SVM with squared hinge loss. It clearly demonstrates the faster convergence of the practical DisDCA versus the naive DisDCA. While Yang (2013) has established the convergence rate of the naive DisDCA, however, it still remains an open problem and is of great interest to analyze the convergence of the practical DisDCA. In the next two sections, we provide a theoretical analysis as well as empirical studies to justify the practical DisDCA. For comparison, we state in the following theorem the convergence result of the native DisDCA.\nTheorem 1 (Yang (2013)). Assume all data points are in the unit ball, i.e., ‖x‖2 ≤ 1. For a Lsmooth loss function φi and a λ-strongly convex function g(w), let wT , αT be the primal and dual solution obtained by the DisDCA algorithm with the naive updates in (6), then we have\nE [ D(α∗)−D(αT ) ] ≤\n(\n1− 1\nc+ nmK\n)T\nǫ0\nand\nE [ P (wT )−D(αT ) ] ≤\n(\nc+ n\nmK\n)(\n1− 1\nc+ nmK\n)T\nǫ0\nwhere c = L/λ is the condition number and ǫ0 = D(α∗)−D(α0) ≤ P (w0)−D(α0) is a constant.\nRemark: From Theorem 1, we can see that the effective region, where increasing m and K can improve the convergence rate, is heavily impacted by the condition number c = L/λ. In particular, when c = Ω(n), the benefit of increasing m and K becomes very small because the term c + n/(mK) is dominated by c."
    }, {
      "heading" : "3 Analysis of DisDCA for Orthogonal Data",
      "text" : "In this section, we present our first theoretical result regarding the convergence rate of the practical DisDCA for orthogonal data on different machines. Actually, in this case the practical DisDCA can be modified slightly to obtain better convergence. We can set scale = 1 in Inc-Dual, i.e., updating α by\n∆αk,i = max ∆α\n−φ∗k,i(−(α t−1 k,i +∆α)) −∆αx ⊤ k,iu t,j−1 k\n− 1\n2λn (∆α)2‖xk,i‖ 2 2 (9)\nAccordingly, we need to change the updates of the primal variables ut,jk to\nut,jk = u t,j−1 k +\n1\nλn ∆αk,ixk,i (10)\nAs we can see the scale factor is reduced to 1 compared to K in the original DisDCA algorithm of the practical variant. This is due to the exploitation of the orthogonality of data on different machines. The theorem below present the convergence rate of the practical DisDCA in this case.\nTheorem 2. Assume all data points are in the unit ball, i.e., ‖x‖2 ≤ 1, and the data Xk on different machines are orthogonal to each other, i.e., X⊤k Xl = 0, ∀k 6= l. For a L-smooth loss function φi and a λ-strongly convex function g(w), let wT , αT be the primal and dual solution obtained by the practical DisDCA algorithm with slight modifications scale = 1 and (10), then\nE [ D(α∗)−D(αT ) ] ≤\n(\n1− K\nc+ n\n)mT\nǫ0\nand\nE [ P (wT )−D(αT ) ] ≤ c+ n\nK\n(\n1− K\nc+ n\n)mT\nǫ0\nRemark: Theorem 2 well justifies the benefit of the practical DisDCA compared with the naive DisDCA. In particular, increasing m can always speed-up the convergence rate by an exponential rate. Also, there is a linear speed-up by increasing the number of machines. In addition, the convergence rate in Theorem 2 for the practical DisDCA is better than that in Theorem 1 for the naive DisDCA.\nTo understand the theoretical result in Thereom 2, we note that when the data on different machines are orthogonal, the Gram matrix G = [x⊤i xj ]n×n can be shuffled to align the distribution of data on K machines, and becomes a block diagonal matrix\nG =\n\n  G1 0 · · · 0 0 G2 · · · 0 · · · · 0 · · · 0 Gk\n\n \nand the dual problem in (4) with a square norm regularizer can be split into K independent subproblems:\nmax α∈Rn\n1\nn\nn∑\ni=1\n−φ∗i (−αi)− 1\n2n2λ α⊤Gα\n= max α∈Rn\n1\nn\nK∑\nk=1\nnk∑\ni=1\n−φ∗i (−αi)− 1\n2n2λ\nK∑\nk=1\nα⊤k Gkαk\nAs we see shortly, an algorithmic consequence due to the orthogonality is that the communication between K machines becomes optional (c.f. equation in (11)), as a result we solve K independent sub-problems separately. Therefore, increasing m the number of dual variables to be updated on each machine would yield an exponential speed-up and increasing K the number of machines would yield a linear speed-up.\nAlthough we note that it is usually rare to have the property of orthogonality in reality 1, however, the discussion here can be related to a particular type of distributed optimization algorithms, i.e., one-communication distributed optimization. In particular, one can regard the data on different machines are orthogonal and solve K sub-problems separately and finally perform an average of models from all machines. It was advocated by practitioners and has been analyzed in (Zhang et al., 2012; Mann et al., 2009; Zinkevich et al., 2010) for least square regression, conditional maximum entropy models and stochastic gradient descent. However, the final averaged solution may not be (in most cases) exactly the optimal solution to the original problem and our analysis reveals that the orthogonality plays an important role in the accuracy of the final averaged solution. Moreover, it suggests the closer to orthogonality of data the closer to the optimal solution of the averaged solution.\nTo verify our claim, we present an experimental result in Figure 2, which compares the onecommunication DisDCA with different data partitions on a synthetic data for regression. The data is generated similarly as in (Zhang et al., 2012) with extra concern. In particular, we generate data of d = 250 dimension and split the 250 features into 50 non-overlapping groups. For each group, we generate 5 features following N (0, 1) for 5000 data points. The response variable is generated by y = u⊤x +\n∑d j=1(xj/2) 3, where u is a constant vector. As a result, there are a total of 250000\n1The orthogonality may occur when data on different machines have non-overlapping features.\ndata points. We distribute the data over K = 5, 10, 25, 50 machines. For each K , we generate two data partitions, one following the block partition and another one following a random partition. For the block partition, we run the updates in (9), for the random partition we run the updates in (7). We note that for the random partition, the update in (9) would fail. For each sub-problem, we run the dual updates until the duality gaps of the sub-problems are within 10−6. The results verify that the one-communication DisDCA for orthogonal data partition achieves better optimality.\nFinally, we note that although the one-communication DisDCA optimization with a random partition may not find the optimal solution, however, it may give sufficiently accurate predictions. For example, in Figure 1(b) we show the error of classification 2 on rcv1 binary data set 3. The results show that with K = 20 machines, the one-communication DisDCA gains 8-times speed-up in running time while only losses 0.2% in accuracy. Similar results have been reported in previous works (Zhang et al., 2012; Mann et al., 2009), where they have established the statistical convergence of the final averaged solution as well. Our analysis in next section reveals the optimization convergence of the one-communication DisDCA."
    }, {
      "heading" : "3.1 Proof",
      "text" : "To ease the proof, we introduce some notations to simplify our analysis. Let αt,j denote all dual variables at the t-th iteration after updating the j-th variable, αt = αt,0 and αt+1 = αt,m. Let wtk\n2We use the provided testing data (n = 677399, d = 47236) as training data and evaluate the model on the provided training data.\n3http://www.csie.ntu.edu.tw/˜cjlin/libsvmtools/datasets/\ndenote the local primal solution spans over the data points in its corresponding machine, i.e.,\nwtk = 1\nλn\nnk∑\ni=1\nαtk,ixk,i, w t =\nK∑\nk=1\nwtk\nNote that compared to Algorithm 1 we slightly change the definition of wtk .\nSimilarly, let wt,jk and w t,j denote the local and global primal solution constructed from the updated dual variables αt,j after updating the j-th dual variable at the t-th iteration, i.e.,\nwt,jk = w t,j−1 k +\n1\nλn ∆αt,jk,ijxk,ij , w t,0 k = w t−1 k ,\nwt,j =\nK∑\nk=1\nwt,jk\nThus, we can establish the relationship between wt,jk and u k t,j as follows:\nut,jk = u t,j−1 k +\n1\nλn ∆αt,jk,ijxk,ij = w t,j k + w̄ t−1 k\nwhere w̄t−1k = w t−1 −wt−1k . Essentially, w t,j denotes the summed solution of all local wt,jk , which is not computed in the algorithm. ut,jk denotes the local variable maintained at each machine, whose starting point at the beginning of the inner iteration is the global wt−1. Due to that the data on different machines are orthogonal, it is not difficult to verify that\nx⊤k,iw t,j−1 = x⊤k,iw t,j−1 k = x ⊤ k,iu t,j−1 k (11) ∥ ∥ ∥ ∥ ∥ K∑\nk=1\nwtk ∥ ∥ ∥ ∥ ∥ 2\n2\n=\nK∑\nk=1\n‖wtk‖ 2 2. (12)\nAn important consequence springing from the data orthogonality is that we can update the dual variables separately without any loss in decomposing the quadratic term in the dual objective (4), i.e.,\nλn\n2 ∥ ∥ ∥ ∥ ∥ wt,j−1 + 1 λn ∑\nk\n∆αk,ijxk,ij ∥ ∥ ∥ ∥ ∥ 2\n= λn\n2 ‖wt,j−1‖22 +\nK∑\nk=1\n1\nλn (∆αk,ij )\n2‖xk,ij‖ 2 2 +\nK∑\nk=1\n∆αk,ijxk,ij · u t,j−1 k\nThe last equality is due to (11). This is exactly where the update in (9) comes from.\nBelow, we divide the proof into three parts: (1) bounding the increase of the dual objective for one inner iteration; (2) establishing the relationship between the increased dual objective and the duality gap; and (3) finally proving the convergence rate of the dual objective and the duality gap. For each part, we present a Lemma with the proof deferred to appendix.\nWe start by bounding the increase of the dual objective for one inner iteration. It is easy to verify that wt,j = 1λn ∑ k,i α t,j k,ixk,i. By the definition of D(α), we have\nn[D(αt,j)−D(αt,j−1)]\n=\n[ ∑\nk\n∑\ni\n−φ∗k,i(−α t,j k,i)−\nλn\n2 ‖wt,j‖22\n]\n−\n[ ∑\nk\n∑\ni\n−φ∗k,i(−α t,j−1 k,i )−\nλn\n2 ‖wt,j−1‖22\n]\n= ∑\nk\n[\n−φ∗k,ij (−α t,j k,ij\n)− λn\n2 ‖wt,jk ‖ 2 2\n]\n︸ ︷︷ ︸\nAk\n− ∑\nk\n[\n−φ∗k,ij (−α t,j−1 k,ij\n)− λn\n2 ‖wt,j−1k ‖ 2 2\n]\n︸ ︷︷ ︸\nBk\nThe last equality is because we only update the dual variable of the data point with index ij , and the equality in (12). We proceed to bound Ak by writing α\nt,j k,ij = αt,jk,ij + ∆α and w t,j k = w t,j−1 k +\n1/(λn)∆αk,ijxk,ij , and bounding φ ∗(α) using its strong convexity. The result is summarized in the following Lemma.\nLemma 1. Let ωt,j−1k,ij = −∇φ(xk,ij · w t,j−1 k ). Then for any s ∈ [0, 1], we have\nAk −Bk ≥ s\n2\n( 1− s\nL −\ns‖xk,ij‖ 2 2\nλn\n)\n‖ωt,j−1k,jj − α t,j−1 k,ij ‖22\n+ s [\nφk,ij (xk,ij · w t,j−1 k ) + φ ∗ k,ij (−α t,j−1 k,ij ) + αt,j−1k,ij x ⊤ k,ijw t,j−1 k\n]\n.\nSince we assume ‖x‖2 ≤ 1, we can set s = n\nc+ n and we have\nAk −Bk ≥ s [ φk,ij (xk,ij · w t,j−1 k ) + φ ∗ k,ij (−α t,j−1 k,ij ) + αt,j−1k,ij x ⊤ k,ijw t,j−1 k ] .\nTaking summation over k = 1, . . . ,K on both sides and taking expectation over the randomness, we can prove the following Lemma, which establishes the relationship between the increased dual objective and the duality gap.\nLemma 2. Let s = n/(c+ n). Then\nE [ D(αt,j)−D(αt,j−1) ] ≥ sK\nn\n[ P (wt,j−1)−D(αt,j−1) ] .\nGiven Lemma 2 and D(α∗) ≤ P (wt,j−1), we have\nE [ D(α∗)−D(α t) ] ≤\n(\n1− sK\nn\n)m\nE [ D(α∗)−D(α t−1) ] ≤\n(\n1− sK\nn\n)mt\nǫ0\nTherefore\nE [ D(α∗)−D(α T ) ] ≤\n(\n1− sK\nn\n)mT\nǫ0 =\n(\n1− K\nc+ n\n)mT\nǫ0\nand\nE [ P (wT )−D(αT ) ] ≤ n sK E [ D(α∗)−D(α T ) ] = c+ n K\n(\n1− K\nc+ n\n)mT\nǫ0"
    }, {
      "heading" : "4 Analysis of the Practical DisDCA in General Case",
      "text" : "The challenge for the analysis of the general case comes from that we cannot decompose the square norm of wt,j as the sum of square norm of each wt,jk without any loss. Our strategy for analysis is to derive a similar inequality as in Lemma 2. However, as we will see shortly, there is an additional term that accounts for the difference between using the global primal solution wt,j−1 and the local primal solution ut,j−1k . According to the updates, let us define:\nwtk = K\nλn\nnk∑\ni=1\nαtk,ixk,i, w t =\n1\nK\nK∑\nk=1\nwtk,\nwt,jk = w t,j−1 k +\nK λn ∆αt,jt,ijxk,ij , w t,j = 1 K\nK∑\nk=1\nwt,jk ,\nwt,0k = w t−1 k , w t+1 = wt,m, ut,0k = w t−1\nut,jk = u t,j−1 k +\nK λn ∆αt,jk,ijxk,ij = w t,j k + w̄ t−1 k\nwhere w̄t−1k = w t−1 − wt−1k . The following lemma establishes a similar result as in Lemma 2. Lemma 3. Let ωt,j−1k,i = −∇φ(xk,i · w t,j−1). For any s ∈ [0, 1], we have\nE[D(αt,j)−D(αt,j−1)] ≥ sK\nn E[P (wt,j−1)−D(αt,j−1)]\n+ sE\nK∑\nk=1\n( 1− s\n2L −\nsK 2λn ‖xk,ij‖ 2 2\n)\n‖ωt,j−1k,ij − α t,j−1 k,ij ‖22 − E [ Rt,j ] ,\nwhere\nRt,j = 1\nn\nK∑\nk=1\n(s(ωt,j−1k,ij − α t,j−1 k,ij )−∆αt,jk,ij )x ⊤ k,ij (u t,j−1 k − w t,j−1)\nIf we let s = n\ncK + n , then the second term in the R.H.S of the inequality in Lemma 3 diminishes,\nand we get a similar result as in Lemma 2, except that there is an additional negative term −Rt,j .\nIdeally, if we use wt,j−1 to replaceut,j−1k , thenR t,j = 0 and we can prove a similar result. However, computing wt,j−1 involves communication among all K machines, which is not adopted in our algorithm. Essentially, Rt,j can be regarded as a measure of deviation from the local primal solution ut,j−1k to the global primal solution w t,j−1. To see this, let use consider an example using squared hinge loss φ(x · w) = (1 − yx · w)2+, whose convex conjugate is φ ∗(α) = αy + α 2\n4 . It is safely to let ∆αt,jk,ij be the solution to the following problem, assuming ‖x‖2 ≤ 1,\n∆αt,jk,ij = max∆α −φ∗k,ij (−α t,j−1 k,ij −∆α) −∆αx⊤k,iju t,j−1 k −\nK\n2λn (∆α)2\nIt is easy to check that ∆αt,jk,ij is given by\n∆αt,jk,ij = λn\n2K + λn\n[\n2(yk,ij − x ⊤ k,iju t,j−1 k )− α t,j−1 k,ij\n]\nNoting that L = 2, c = 2/λ, we have\ns(ωt,j−1k,ij − α t,j−1 k,ij\n) = λn\n2K + λn\n[\n2(yk,ij − x ⊤ k,ijw t,j−1)− αt,j−1k,ij\n]\nThen we have\nRt,j ≤ 1\nn\nK∑\nk=1\nλn\n2K + λn ‖xk,ij‖\n2 2 ∥ ∥ ∥u t,j−1 k − w t,j−1 ∥ ∥ ∥ 2\n2\n∝ K∑\nk=1\n∥ ∥ ∥ ∥ ∥ K λn j−1 ∑\nτ=1\n∆αt,τk,iτxk,iτ − 1\nλn\nK∑\nk=1\nj−1 ∑\nτ=1\n∆αt,τk,iτ xk,iτ ∥ ∥ ∥ ∥ ∥ 2\n2\nWhen the dual variables αt,j converge to the optimal solution α∗, we have ∆αt,j → 0, therefore Rt,j → 0. Following similar analysis, we have\nE[ǫ(t,j)] ≤\n(\n1− sK\nn\n)\nE[ǫ(t,j−1)] + E[R(t,j)]\nLet µ = 1− (sK)/n, and by induction we have\nE[ǫ(t,m)] ≤ µmE[ǫ(t,0)] + E [ µm−1Rt,1 + · · ·+Rt,m ]\n︸ ︷︷ ︸\nS(t,m)\n(13)\nNote that since we are mostly interested in the dependence on m, we hide the dependence on K in S(t,m). If we let t = 0,m → ∞, then the above bound indicates that the residual of the dual objective for the one-commutation DisDCA will geometrically converge to S(0,∞). This coincides with the fact that one-communication DisDCA performs independent SDCA on individual machines . In Figure 3, we show that the curves of ǫ(0,m) and S(0,m) for classification and regression. The curves clearly illustrate that both ǫ(0,m) and S(0,m) will eventually converge to a value, where the convergent value of ǫ(0,m) is slightly smaller than the convergent value of S(0,m). These results justify the the inequality in (13) for one-communication DisDCA.\nWith fixed m, we have ǫ(t+1) = ǫ(t,m), ǫ(t) = ǫ(t,0) due to our definitions, then we have\nE[ǫ(t+1)] ≤ µmE[ǫ(t)] + E[S(t,m)]\nGenerally, bounding S(t,m) is a non-trivial task. Below, we provide some empirical studies to aid our analysis. In Figure 4, we plot the curve for S(t,m) and also ǫ(t+1) = ǫ(t,m) for fixed m. The figures not only show that S(m,t) converges to zero, but also indicate that S(t,m) ≤ ε(t,m)ǫ(t+1), where ε(t,m) < 1 depends on t,m. Thus, we can establish\n(1− ε(t,m))E[ǫ(t+1)] ≤\n(\n1− sK\nn\n)m\nE[ǫ(t)]\nThen we can get\nE[ǫ(T )] ≤ T∏\nt=1\n( 1\n1− ε(t,m)\n)(\n1− sK\nn\n)mT\nǫ(0)\nThe dependence of the convergence on t and m is also verified by the results in Figure 4. At the earlier stages ε(t,m) is smaller, therefore the slope of log(ǫ(t,m)) is larger. Noting that s =\nn/(cK + n), we have\nE[ǫ(T )] ≤ T∏\nt=1\n( 1\n1− ε(t,m)\n)(\n1− 1\nc+ n/K\n)mT\nǫ(0)\nWe can also see that how the number of machines K plays the role in the convergence rate. Let us consider an interesting case when c = L/λ = O(n1/(1+τ)), where τ ∈ (0, 1] (Yang, 2013). Then increasingK upto nτ/(1+τ), the convergence rate can be speed-up via decreasing µ = 1− 1\nc+ n/K .\nOn the other hand, increasing K would increase the communication cost. In practice, it is important to tune m and K to achieve the best balance between computation and communication."
    }, {
      "heading" : "5 Conclusions and Open Problems",
      "text" : "In this manuscript, we have made a progress in analyzing the practical DisDCA theoretically. In particular, we have established the convergence rate of the practical DisDCA for orthogonal data. We also provided an analysis of the practical DisDCA for genera data. Helped by empirical studies, we show that the practical DisDCA is able to achieve an exponential speed-up on the convergence by increasing the number of dual updates at each iteration. This result well justifies the superiority of the practical DisDCA over the naive variant, which only has a partially linear speed-up.\nThere still exist open problems for future research. First, what is the analytical form of ε(t,m) that upper bounds S(t,m) by ǫ(t,m). Second, how to make the communication asynchronous and prove the convergence."
    }, {
      "heading" : "Appendix",
      "text" : ""
    }, {
      "heading" : "Proof of Lemma 1",
      "text" : "Ak = −φ ∗ k,ij (−α t,j−1 k,ij −∆αt,jk,ij )− λn\n2\n∥ ∥ ∥ ∥ wt,j−1k + 1\nλn ∆αt,jk,ijxk,ij\n∥ ∥ ∥ ∥ 2\n2\n= −φ∗k,ij (−α t,j−1 k,ij −∆αt,jk,ij )− λn 2 ‖wt,j−1k ‖ 2 2 −∆α t,j k,ij x⊤k,ijw t,j−1 k − 1 λn ‖∆αt,jk,ijxk,ij‖ 2 2\n= −φ∗k,ij (−α t,j−1 k,ij −∆αt,jk,ij )− λn 2 ‖wt,j−1k ‖ 2 2 −∆α t,j k,ij x⊤k,ij (u t,j−1 k − w̄ t−1 k )− 1 λn ‖∆αt,jk,ijxk,ij ‖ 2 2\n= −φ∗k,ij (−α t,j−1 k,ij −∆αt,jk,ij )− λn 2 ‖wt,j−1k ‖ 2 2 −∆α t,j k,ij x⊤k,iju t,j−1 k − 1 λn ‖∆αt,jk,ijxk,ij‖ 2 2\n≥ −(1− s)φ∗k,ij (−α t,j−1 k,ij )− sφ∗k,ij (−ω t,j−1 k,ij\n) + 1\n2L s(1 − s)‖ωt,j−1k,ij − α t,j−1 k,ij ‖22\n− λn\n2 ‖wt,j−1k ‖ 2 2 − s(ω t,j−1 k,ij − αt,j−1k,ij )x ⊤ k,ijw t,j−1 k −\n1\nλn s2(ωt,j−1k,jj − α t,j−1 k,ij )‖xk,ij‖ 2 2\n≥ −s(φ∗k,ij (−ω t,j−1 k,ij ) + ωt,j−1k,ij x ⊤ k,ijw t,j−1 k )\n+ sφ∗k,ij (−α t,j−1 k,ij )) + sαt,j−1k,ij x ⊤ k,ijw t,j−1 k −φ ∗ k,ij (−α t,j−1 k,ij\n)− λn\n2 ‖wt,j−1k ‖ 2 2\n︸ ︷︷ ︸\nBk\n+ s\n2\n( (1− s)\nL −\ns\nλn ‖xk,ij‖\n2 2\n)\n‖ωt,j−1k,jj − α t,j−1 k,ij ‖22\n≥ s [\nφk,ij (x ⊤ k,ijw t,j−1 k ) + φ ∗ k,ij (−α t,j−1 k,ij ) + αt,j−1k,ij x ⊤ k,ijw t,j−1 k\n]\nBy setting s = n/(c+ n), we have\nn(D(αt,j)−D(αt,j−1))\n≥ K∑\nk=1\ns [\nφk,ij (x ⊤ k,ijw t,j−1 k ) + φ ∗ k,ij (−α t,j−1 k,ij ) + αt,j−1k,ij x ⊤ k,ijw t,j−1 k\n]\n=\nK∑\nk=1\ns [\nφk,ij (x ⊤ k,ijw t,j−1) + φ∗k,ij (−α t,j−1 k,ij ) + αt,j−1k,ij x ⊤ k,ijw\nt,j−1 ]\nThe Lemma 2 can be proved by showing that the expectation of the R.H.S of the above inequality is equal to the duality gap P (wt,j−1)−D(αt,j−1) with appropriate scaling."
    }, {
      "heading" : "Proof of Lemma 3",
      "text" : "By the definition of D(α), we have\nn[D(αt,j)−D(αt,j−1)]\n=\n[ ∑\nk\n∑\ni\n−φ∗k,i(−α t,j k,i)−\nλn\n2 ‖wt,j‖22\n]\n−\n[ ∑\nk\n∑\ni\n−φ∗k,i(−α t,j−1 k,i )−\nλn\n2 ‖wt,j−1‖22\n]\n≥ K∑\nk=1\n−φ∗k,ij (−α t,j k,ij\n)− λn\n2 ∥ ∥ ∥ ∥ ∥ wt,j−1 + K∑\nk=1\n1\nλn ∆αt,jk,ijxk,ij ∥ ∥ ∥ ∥ ∥ 2\n2\n− K∑\nk=1\n−φ∗k,ij (−α t,j−1 k,ij\n)− λn\n2 ‖wt,j−1‖22\n≥ K∑\nk=1\n−φ∗k,ij (−α t,j k,ij\n)− λn\n2\n∥ ∥wt,j−1 ∥ ∥ 2\n2 −\nK∑\nk=1\n∆αt,jk,ijx ⊤ k,ijw\nt,j−1 − 1\n2λn ∥ ∥ ∥ ∥ ∥ K∑\nk=1\n∆αt,jk,ijxk,ij ∥ ∥ ∥ ∥ ∥ 2\n2\n− K∑\nk=1\n−φ∗k,ij (−α t,j−1 k,ij\n)− λn\n2 ‖wt,j−1‖22\n≥ K∑\nk=1\n−φ∗k,ij (−α t,j k,ij\n)− λn\n2\n∥ ∥wt,j−1 ∥ ∥ 2\n2\n− K∑\nk=1\n∆αt,jk,ijx ⊤ k,ijw\nt,j−1 − 1\n2λnk\nK∑\nk=1\n∥ ∥ ∥∆α\nt,j k,ij xk,ij\n∥ ∥ ∥ 2\n2 −\nK∑\nk=1\n−φ∗k,ij (−α t,j−1 k,ij\n)− λn\n2 ‖wt,j−1‖22\n≥ K∑\nk=1\n−φ∗k,ij (−α t,j−1 k,ij −∆αt,jk,ij )− K∑\nk=1\n∆αt,jk,ijx ⊤ k,iju t,j−1 k −\nK\n2λn\nK∑\nk=1\n∥ ∥ ∥∆α\nt,j k,ij xk,ij\n∥ ∥ ∥ 2\n2\n− K∑\nk=1\n−φ∗k,ij (−α t,j−1 k,ij ) +\nK∑\nk=1\n∆αt,jk,ijx ⊤ k,ij (u t,j−1 k − w t,j−1)\n≥ K∑\nk=1\n−(1− s)φ∗k,ij (−α t,j−1 k,ij )− sφ∗k,ij (−ω t,j−1 k,ij\n) + 1\n2L s(1− s)‖ωt,j−1k,ij − α t,j−1 k,ij )‖22\n− K∑\nk=1\ns(ωt,j−1k,ij − α t,j−1 k,ij )x⊤k,iju t,j−1 k −\nK\n2λn\nK∑\nk=1\ns2 (\nωt,j−1k,ij − α t,j−1 k,ij )2‖xk,ij\n∥ ∥ ∥ 2\n2\n− K∑\nk=1\n−φ∗k,ij (−α t,j−1 k,ij\n) + K∑\nk=1\n∆αt,jk,ijx ⊤ k,ij (u t,j−1 k − w t,j−1)\n≥ K∑\nk=1\nsφ∗k,ij (−α t,j−1 k,ij\n) + K∑\nk=1\nsαt,j−1k,ij x ⊤ k,iju t,j−1 k + [−sφ ∗ k,ij (−ω t,j−1 k,ij )− sωt,j−1k,ij x ⊤ k,iju t,j−1 k ]\n+ s\nK∑\nk=1\n( 1\n2L (1− s)−\n1\n2λnk ‖xk,ij‖\n2 2\n)\n‖ωt,j−1k,ij − α t,j−1 k,ij ‖22 + K∑\nk=1\n∆αt,jk,ijx ⊤ k,ij (u t,j−1 k − w t,j−1)\n≥ K∑\nk=1\nsφ∗k,ij (−α t,j−1 k,ij ) +\nK∑\nk=1\nsαt,j−1k,ij x ⊤ k,ijw t,j−1 + [−sφ∗k,ij (−ω t,j−1 k,ij )− sωt,j−1k,ij x ⊤ k,ijw t,j−1]\n+ s\nK∑\nk=1\n( 1\n2L (1− s)−\n1\n2λnk ‖xk,ij‖\n2 2\n)\n‖ωt,j−1k,ij − α t,j−1 k,ij ‖22 + K∑\nk=1\n(∆αt,jk,ij − s(ω t,j−1 k,ij − αt,j−1k,ij ))x ⊤ k,ij (u t,j−1 k − w t,j−1)\n≥ s\n[ K∑\nk=1\nφ∗k,ij (−α t,j−1 k,ij ) + φk,ij (x ⊤ k,ijw t,j−1) +\nK∑\nk=1\nαt,j−1k,ij x ⊤ k,ijw t,j−1\n]\n+ s\nK∑\nk=1\n( 1\n2L (1− s)−\n1\n2λnk ‖xk,ij‖\n2 2\n)\n‖ωt,j−1k,ij − α t,j−1 k,ij ‖22\n− K∑\nk=1\n(s(ωt,j−1k,ij − α t,j−1 k,ij )−∆αt,jk,ij )x ⊤ k,ij (u t,j−1 k − w t,j−1)\n︸ ︷︷ ︸\nnRt,j\n13"
    } ],
    "references" : [ {
      "title" : "Efficient Large-Scale distributed training of conditional maximum entropy models",
      "author" : [ "Mann", "Gideon", "McDonald", "Ryan", "Mohri", "Mehryar", "Silberman", "Nathan", "Walker", "Dan" ],
      "venue" : "In Advances in Neural Information Processing Systems",
      "citeRegEx" : "Mann et al\\.,? \\Q2009\\E",
      "shortCiteRegEx" : "Mann et al\\.",
      "year" : 2009
    }, {
      "title" : "Trading computation for communication: Distributed stochastic dual coordinate ascent",
      "author" : [ "Yang", "Tianbao" ],
      "venue" : null,
      "citeRegEx" : "Yang and Tianbao.,? \\Q2013\\E",
      "shortCiteRegEx" : "Yang and Tianbao.",
      "year" : 2013
    }, {
      "title" : "Communication-Efficient algorithms for statistical optimization",
      "author" : [ "Zhang", "Yuchen", "Duchi", "John", "Wainwright", "Martin" ],
      "venue" : "In dvances in Neural Information Processing Systems",
      "citeRegEx" : "Zhang et al\\.,? \\Q2012\\E",
      "shortCiteRegEx" : "Zhang et al\\.",
      "year" : 2012
    }, {
      "title" : "Parallelized stochastic gradient descent",
      "author" : [ "Zinkevich", "Martin", "Weimer", "Markus", "Smola", "Alexander J", "Li", "Lihong" ],
      "venue" : "In Advances in Neural Information Processing Systems",
      "citeRegEx" : "Zinkevich et al\\.,? \\Q2010\\E",
      "shortCiteRegEx" : "Zinkevich et al\\.",
      "year" : 2010
    } ],
    "referenceMentions" : [ {
      "referenceID" : 2,
      "context" : "It was advocated by practitioners and has been analyzed in (Zhang et al., 2012; Mann et al., 2009; Zinkevich et al., 2010) for least square regression, conditional maximum entropy models and stochastic gradient descent.",
      "startOffset" : 59,
      "endOffset" : 122
    }, {
      "referenceID" : 0,
      "context" : "It was advocated by practitioners and has been analyzed in (Zhang et al., 2012; Mann et al., 2009; Zinkevich et al., 2010) for least square regression, conditional maximum entropy models and stochastic gradient descent.",
      "startOffset" : 59,
      "endOffset" : 122
    }, {
      "referenceID" : 3,
      "context" : "It was advocated by practitioners and has been analyzed in (Zhang et al., 2012; Mann et al., 2009; Zinkevich et al., 2010) for least square regression, conditional maximum entropy models and stochastic gradient descent.",
      "startOffset" : 59,
      "endOffset" : 122
    }, {
      "referenceID" : 2,
      "context" : "The data is generated similarly as in (Zhang et al., 2012) with extra concern.",
      "startOffset" : 38,
      "endOffset" : 58
    }, {
      "referenceID" : 2,
      "context" : "Similar results have been reported in previous works (Zhang et al., 2012; Mann et al., 2009), where they have established the statistical convergence of the final averaged solution as well.",
      "startOffset" : 53,
      "endOffset" : 92
    }, {
      "referenceID" : 0,
      "context" : "Similar results have been reported in previous works (Zhang et al., 2012; Mann et al., 2009), where they have established the statistical convergence of the final averaged solution as well.",
      "startOffset" : 53,
      "endOffset" : 92
    } ],
    "year" : 2014,
    "abstractText" : "In (Yang, 2013), the author presented distributed stochastic dual coordinate ascent (DisDCA) algorithms for solving large-scale regularized loss minimization. Extraordinary performances have been observed and reported for the well-motivated updates, as referred to the practical updates, compared to the naive updates. However, no serious analysis has been provided to understand the updates and therefore the convergence rates. In the paper, we bridge the gap by providing a theoretical analysis of the convergence rates of the practical DisDCA algorithm. Our analysis helped by empirical studies has shown that it could yield an exponential speed-up in the convergence by increasing the number of dual updates at each iteration. This result justifies the superior performances of the practical DisDCA as compared to the naive variant. As a byproduct, our analysis also reveals the convergence behavior of the one-communication DisDCA.",
    "creator" : "LaTeX with hyperref package"
  }
}