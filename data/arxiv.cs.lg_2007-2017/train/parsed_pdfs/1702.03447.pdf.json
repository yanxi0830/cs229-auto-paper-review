{
  "name" : "1702.03447.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "A Collective, Probabilistic Approach to Schema Mapping: Appendix",
    "authors" : [ "Angelika Kimmig", "Renée J. Miller", "Lise Getoor" ],
    "emails" : [ "angelika.kimmig@cs.kuleuven.be", "memory@cs.umd.edu", "miller@cs.toronto.edu", "getoor@ucsc.edu" ],
    "sections" : [ {
      "heading" : null,
      "text" : "ar X\niv :1\n70 2.\n03 44\n7v 1\n[ cs\n.D B\n] 1\n1 Fe\nb 20\n17\nA Collective, Probabilistic Approach\nto Schema Mapping: Appendix\nAngelika Kimmig\nKU Leuven\nangelika.kimmig@cs.kuleuven.be\nAlex Memory\nUniversity of Maryland\nmemory@cs.umd.edu\nRenée J. Miller\nUniversity of Toronto\nmiller@cs.toronto.edu\nLise Getoor\nUC Santa Cruz\ngetoor@ucsc.edu\nIn this appendix we provide additional supplementary material to “A Collective, Probabilistic Approach to Schema Mapping” [1]. We include an additional extended example, supplementary experiment details, and proof for the complexity result stated in the main paper."
    }, {
      "heading" : "I. EXAMPLE OF SELECTION OVER ST TGDS",
      "text" : "We extend the running example from the main paper to illustrate objective Eq. (9) of [1]. We use a reduced candidate set C′ = {θ1, θ3} (Figure 1(d) in [1]) and the data in\nFigure 1(b)-(c) in [1], but omit the leader relation. A universal solution Kθ1 of I contains the task tuples (BigData, Bob, Null1) and (ML, Alice, Null2), while a Kθ3 contains the task tuples (BigData, Bob, Null3) and (ML, Alice, Null4) and the org tuples (Null3, IBM) and (Null4, SAP).\nFor θ1, creates is 1 for tuple task(BigData, Bob, Null1), and 0 for all other tuples, and covers is 2/3 for task(ML, Alice, 111) and 0 otherwise. This is because task(ML, Alice, Null2) partially explains the latter via a homomorphismmapping Null2 to 111. Similarly, for θ3, creates is 1 for task(BigData, Bob, Null3) and org(Null3,IBM), but 0 for task(ML, Alice, Null4) and org(Null4,SAP), which partially explain task(ML, Alice, 111) and org(111, SAP) to degree 3/3 and 2/2 respectively, via a homomorphism mapping Null4 to 111, with corresponding values for covers. The different subsets of candidate st tgds thus obtain the following values for the individual parts and the total of objective function Eq. (9) of [1].\nM ∑ 1− explains ∑\nerror size Eq. (9) of [1] {} 4 0 0 4 {θ1} 31/3 1 3 71/3 {θ3} 2 2 4 8\n{θ1, θ3} 2 3 7 12\nAs the data example is small compared to the mappings, the minimal value for the objective is that of the empty mapping, but we also see that {θ1} is preferred over {θ3}, which in turn is preferred over {θ1, θ3}. The reason is that while θ3 covers more tuples than θ1, it also produces more errors and is larger. The fact that the empty mapping has a better objective value is an important guard against overfitting on too little data; this is easily overcome by slightly larger data instances. If we add at least five more projects X of the same kind as the ML one, i.e., pairs of tuples proj(X,N,1) and task(X,Alice,111), the preferred mapping is {θ3}, as the empty mapping cannot explain the new target tuples, θ1 explains each to degree 2/3, and θ3 fully explains them (while no mapping introduces additional errors)."
    }, {
      "heading" : "II. SCENARIO GENERATION",
      "text" : "We provide additional details of the scenario generation process discussed in Section VI-A of [1].\niBench. We used seven iBench primitives [2], [3]: CP copies a source relation to the target, changing its name. ADD copies a source relation and adds attributes; DL does the same, but removes attributes instead; and ADL adds and removes attributes to the same relation. The number that are added or removed are controlled by range parameters, which we set to (2,4). ME copies two relations, after joining them, to form a target relation. VP copies a source relation to form two, joined, target relations. VNM is the same as VP but introduces an additional target relation to form a N-to-M relationship between the other target relations.\nModifying the metadata evidence through random correspondences. If πCorresp > 0 (cf. Table I of [1]), we introduce additional correspondences as follows. We randomly select πCorresp percent of the target relations. For every selected target relation T , we randomly select a source relation S from those of the iBench primitive invocations not involving T (so Clio [4] can generate MG as part of C). For each attribute of T , we introduce a correspondence to a randomly selected attribute of S.\nModifying the data instance. As certain errors and certain unexplained tuples can be removed prior to optimization (cf. Section III-C of [1]), we restrict data instance modifications to non-certain errors and non-certain unexplained tuples (with respect to MG). Note that in our scenarios, MG ⊆ C, and thusKG ⊆ KC. So each tuple in KC is either generated by both MG and C−MG, only by MG (i.e., a non-certain error tuple if deleted from J), or only by C−MG (i.e., a non-certain unexplained tuple if added to J). As tuples in KC may have nulls, we take into account homomorphisms when determining which of these cases applies to a given tuple. We randomly select πUnexplained% of the potential non-certain unexplained tuples, which we add to J , and πErrors% of the potential noncertain error tuples, which we delete from J ."
    }, {
      "heading" : "III. MAPPING SELECTION IS NP-HARD",
      "text" : "We provide a proof for the complexity result stated in Section III-C of the main paper.\nTheorem 1: The mapping selection problem for full st tgds as defined in Eq. (4) of [1] is NP-hard.\nProof: We use a reduction from SET COVER, which is well known to be NP-complete, and is defined as follows:\nGiven a finite set U , a finite collection R = {Ri | Ri ⊆ U, 1 ≤ i ≤ k} and a natural number n ≤ k, is there a set R′ ⊆ R consisting of at most n sets Ri such that ⋃\nRi∈R ′ Ri = U?\nWe first consider the decision variant of mapping selection, which is defined as follows:\nGiven schemas S, T, a data example (I, J), a set C of candidate full st tgds, and a natural number m, is there a selection M ⊆ C with F (M) ≤ m?\nwhere F (M) is the function minimized in Eq. (4) of [1], i.e.,\nF (M) = ∑\nt∈J\n[1− explainsfull(M, t)]\n+ ∑\nt∈KC−J\n[errorfull(M, t)] + sizem(M) (1)\nWe construct a mapping selection decision instance from a SET COVER instance as follows. We set m = 2n, introduce an auxiliary domain D = {1, . . . ,m+ 1}, and define\nS = {Ri/2 | Ri ∈ R}\nT = {U/2}\nC = {Ri(X,Y ) → U(X,Y ) | Ri ∈ R}\nJ = {U(x, y) | (x, y) ∈ U ×D} I = ⋃\nRi∈R\n{Ri(x, y) | (x, y) ∈ Ri ×D}\nIt is easily verified that this construction is polynomial in the size of the SET COVER instance. We next show that the answers to SET COVER and the constructed mapping selection problem coincide.\nFor each Ri, the candidate st tgd θi = Ri(X,Y ) → U(X,Y ) has size two, makes no errors (as Ri ⊆ U ), and for each x ∈ Ri explains the tuples U(x, 1), . . . , U(x,m+1). We thus have\nF (M) = ∑\nt∈J\n[1− explainsfull(M, t)] + 2 · |M| (2)\n= (m+ 1) ·\n(\n|U | − | ⋃\nθi∈M\nRi|\n)\n+ 2 · |M| (3)\nA mapping M ⊆ C with F (M) ≤ m = 2n thus exists if and only if | ⋃\nθi∈M Ri| = |U | and |M| ≤ n, which is exactly the\ncase where M encodes a covering selection with at most n sets. Furthermore, if such mappings exist, the optimal mapping according to Eq. (4) of [1] is one of them, and a polynomial time solution for mapping selection with full st tgds can thus be used to find a candidate solution that can be verified or rejected in polynomial time to answer SET COVER.\nWe note that the mapping selection problem for arbitrary st tgds as defined in Eq. (9) of [1] coincides with the one in Eq. (4) of [1] if all candidates are full, and thus is NPhard as well. Furthermore, the reduction used in the proof directly generalizes to the following weighted version of the optimization criterion:\nF (M) =w1 · ∑\nt∈J\n[1− explainsfull(M, t)]\n+ w2 · ∑\nt∈KC−J\n[errorfull(M, t)] + w3 · ∑\nθ∈M\nsize(θ)\nwith positive integer weights w1, w2, w3 and any size function that assigns equal size to the candidate mappings θi = Ri(X,Y ) → U(X,Y ). More precisely, setting m = size(θ1) · w3 · n in the proof above shows that this generalization is NP-hard as well."
    } ],
    "references" : [ {
      "title" : "A collective, probabilistic approach to schema mapping",
      "author" : [ "A. Kimmig", "A. Memory", "R.J. Miller", "L. Getoor" ],
      "venue" : "ICDE, (accepted) 2017.",
      "citeRegEx" : "1",
      "shortCiteRegEx" : null,
      "year" : 2017
    }, {
      "title" : "STBenchmark: towards a benchmark for mapping systems",
      "author" : [ "B. Alexe", "W.-C. Tan", "Y. Velegrakis" ],
      "venue" : "PVLDB, vol. 1, no. 1, pp. 230–244, 2008.",
      "citeRegEx" : "2",
      "shortCiteRegEx" : null,
      "year" : 2008
    }, {
      "title" : "The iBench Integration Metadata Generator",
      "author" : [ "P.C. Arocena", "B. Glavic", "R. Ciucanu", "R.J. Miller" ],
      "venue" : "PVLDB, vol. 9, no. 3, pp. 108–119, 2015.",
      "citeRegEx" : "3",
      "shortCiteRegEx" : null,
      "year" : 2015
    }, {
      "title" : "Clio: Schema Mapping Creation and Data Exchange",
      "author" : [ "R. Fagin", "L.M. Haas", "M.A. Hernández", "R.J. Miller", "L. Popa", "Y. Velegrakis" ],
      "venue" : "Conceptual Modeling: Foundations and Applications - Essays in Honor of John Mylopoulos, 2009, pp. 198–236.",
      "citeRegEx" : "4",
      "shortCiteRegEx" : null,
      "year" : 2009
    } ],
    "referenceMentions" : [ {
      "referenceID" : 0,
      "context" : "In this appendix we provide additional supplementary material to “A Collective, Probabilistic Approach to Schema Mapping” [1].",
      "startOffset" : 122,
      "endOffset" : 125
    }, {
      "referenceID" : 0,
      "context" : "(9) of [1].",
      "startOffset" : 7,
      "endOffset" : 10
    }, {
      "referenceID" : 0,
      "context" : "We use a reduced candidate set C = {θ1, θ3} (Figure 1(d) in [1]) and the data in Figure 1(b)-(c) in [1], but omit the leader relation.",
      "startOffset" : 60,
      "endOffset" : 63
    }, {
      "referenceID" : 0,
      "context" : "We use a reduced candidate set C = {θ1, θ3} (Figure 1(d) in [1]) and the data in Figure 1(b)-(c) in [1], but omit the leader relation.",
      "startOffset" : 100,
      "endOffset" : 103
    }, {
      "referenceID" : 0,
      "context" : "(9) of [1].",
      "startOffset" : 7,
      "endOffset" : 10
    }, {
      "referenceID" : 0,
      "context" : "(9) of [1] {} 4 0 0 4 {θ1} 31/3 1 3 71/3 {θ3} 2 2 4 8 {θ1, θ3} 2 3 7 12",
      "startOffset" : 7,
      "endOffset" : 10
    }, {
      "referenceID" : 0,
      "context" : "We provide additional details of the scenario generation process discussed in Section VI-A of [1].",
      "startOffset" : 94,
      "endOffset" : 97
    }, {
      "referenceID" : 1,
      "context" : "We used seven iBench primitives [2], [3]: CP copies a source relation to the target, changing its name.",
      "startOffset" : 32,
      "endOffset" : 35
    }, {
      "referenceID" : 2,
      "context" : "We used seven iBench primitives [2], [3]: CP copies a source relation to the target, changing its name.",
      "startOffset" : 37,
      "endOffset" : 40
    }, {
      "referenceID" : 0,
      "context" : "Table I of [1]), we introduce additional correspondences as follows.",
      "startOffset" : 11,
      "endOffset" : 14
    }, {
      "referenceID" : 3,
      "context" : "For every selected target relation T , we randomly select a source relation S from those of the iBench primitive invocations not involving T (so Clio [4] can generate MG as part of C).",
      "startOffset" : 150,
      "endOffset" : 153
    }, {
      "referenceID" : 0,
      "context" : "Section III-C of [1]), we restrict data instance modifications to non-certain errors and non-certain unexplained tuples (with respect to MG).",
      "startOffset" : 17,
      "endOffset" : 20
    }, {
      "referenceID" : 0,
      "context" : "(4) of [1] is NP-hard.",
      "startOffset" : 7,
      "endOffset" : 10
    }, {
      "referenceID" : 0,
      "context" : "(4) of [1], i.",
      "startOffset" : 7,
      "endOffset" : 10
    }, {
      "referenceID" : 0,
      "context" : "(4) of [1] is one of them, and a polynomial time solution for mapping selection with full st tgds can thus be used to find a candidate solution that can be verified or rejected in polynomial time to answer SET COVER.",
      "startOffset" : 7,
      "endOffset" : 10
    }, {
      "referenceID" : 0,
      "context" : "(9) of [1] coincides with the one in Eq.",
      "startOffset" : 7,
      "endOffset" : 10
    }, {
      "referenceID" : 0,
      "context" : "(4) of [1] if all candidates are full, and thus is NPhard as well.",
      "startOffset" : 7,
      "endOffset" : 10
    } ],
    "year" : 2017,
    "abstractText" : "We extend the running example from the main paper to illustrate objective Eq. (9) of [1]. We use a reduced candidate set C = {θ1, θ3} (Figure 1(d) in [1]) and the data in Figure 1(b)-(c) in [1], but omit the leader relation. A universal solution Kθ1 of I contains the task tuples (BigData, Bob, Null1) and (ML, Alice, Null2), while a Kθ3 contains the task tuples (BigData, Bob, Null3) and (ML, Alice, Null4) and the org tuples (Null3, IBM) and (Null4, SAP).",
    "creator" : "dvips(k) 5.996 Copyright 2016 Radical Eye Software"
  }
}