{
  "name" : "1506.08581.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : null,
    "authors" : [ ],
    "emails" : [ "kmakantasis@isc.tuc.gr;", "adoulam@cs.ntua.gr;", "ndoulam@cs.ntua.gr" ],
    "sections" : [ {
      "heading" : "1. INTRODUCTION",
      "text" : "Pixels values of infrared frames correspond to the relative differences in the amount of thermal energy emitted or reflected from objects in the scene. Due to this fact, infrared cameras are equally applicable for both day and night scenarios, while at the same time, compared to visual-optical cameras, are less affected by changing illumination or background texture. Furthermore, infrared imagery eliminates any privacy issues as people being depicted in the scene can not be identified [13]. These features make infrared cameras prime candidate for persistent video surveillance systems.\nAlthough, infrared imagery can alleviate several problems associated with visual-optical videos, it has its own unique challenges such as a) low signal-to-noise ratio (noisy data) and b) almost continuous pixel values that model objects’ temperature. Both issues complicate pixel responses modeling. An example of raw thermal responses is presented in Figure 1, where pixel values are floating point numbers ranging from 293 to 299 Kelvin degrees. Due to this peculiarity most of conventional computer vision techniques, that successfully used for visual-optical data, can not be applied straightforward on thermal imagery.\nFor many high-level vision based applications, either they use visual-optical videos [4,21,24,25] or infrared data [16,17,26], the task of background subtraction constitutes a key component, as this is one of the most common methods for locating moving objects, facilitating search space reduction and visual attention modeling.\nBackground subtraction techniques applied on visual-optical videos model the color properties of depicted objects [3, 15] and can be classified into three main categories [10]: basic background modeling [19, 28], statistical background modeling [11, 27] and background estimation [20, 23]. The most used methods are the statistical ones due to their robustness to critical situations. In order to statistically represent the background, a probability distribution is used to model the history of pixel values intensity over time. Towards this direction, the work of Stauffer and Grimson [22], is one of the best known approaches.\nar X\niv :1\n50 6.\n08 58\n1v 1\n[ cs\n.C V\n] 2\n9 Ju\nIt uses a Gaussian mixture model, with fixed number of components, for a per-pixel density estimate. Similar to this approach, Makantasis et al. in [18] propose a Student-t mixture model for background modeling, taking advantage of Student-t distribution compactness and robustness to noise and outliers. The works of [29] and [30] extend the method of [22] by introducing a rule based on a user defined threshold to estimate the number of components. However, this rule is application dependent and not directly derived from the data. Haines and Xiang in [14] address this drawback by using a Dirichlet process mixture model. Due to the computational cost of their method, the authors propose a GPU implementation. All of the aforementioned techniques present the drawback that objects’ color properties are highly affected by scene illumination, making the same object to look completely different under different lighting or weather conditions.\nAlthough, thermal imagery can provide a challenging alternative for addressing the aforementioned difficulty, there exist few works for thermal data. The authors of [7–9] exploit contour saliency to extract foreground objects. Initially, they utilize a unimodal background modeling technique to detect regions of interest and then exploit the halo effect of thermal data for extracting foreground objects. However unimodal background modeling is not usually capable of capturing background dynamics. Baf et al. in [10] present a fuzzy statistical method for background subtraction to incorporate uncertainty into the mixture of Gaussians. However, this method requires a predefined number of components making this approach to be application dependent. Elguebaly and Bouguila in [12] propose a finite asymmetric generalized Gaussian mixture model for object detection. Again this method requires a predefined maximum number of components, presenting therefore limitations when this technique is applied on uncontrolled environments. Dai et al. in [5] propose a method for pedestrian detection and tracking using infrared imagery. This method consists of a background subtraction technique that exploits a two-layer representation (one for foreground and one for background) of infrared frame sequences. However, the assumption made is that the foreground is restricted to moving objects, a consideration which is not sufficient for dynamically changing environments. One way to handle the aforementioned difficulties is to introduce a background model, the parameters and the structure of which are directly estimated from the data, while at the same time it takes into account the specific properties of infrared imagery."
    }, {
      "heading" : "1.1. Our contribution",
      "text" : "This work presents background modeling able to provide a per pixel density estimate, taking into account the special characteristics of infrared imagery, such as low signal-to-noise ratio. Our method exploits a Gaussian mixture model with unknown number of components. The advantage of such a model is that its own parameters and structure can be directly estimated from the data, allowing dynamic model adaptation to uncontrolled and changing environments.\nAn important issue in the proposed Gaussian mixture modeling concerns learning the model parameters. In our method, this is addressed using a variational inference framework to correspond the functional structure of the model with real data distri-\nbutions obtained from the infrared images. Then, the Expectation-Maximization (EM) algorithm is adopted to fit the outcome of variational inference to real measurements. Updating procedures are incorporated to allow dynamic model adaptation to the forthcoming infrared data. Our updating method avoids of using heuristics by considering existing knowledge accumulated from previous data distributions and then it compensates this knowledge with current measurements.\nOur overall strategy exploits a Bayesian framework to estimate all the parameters of the mixture model and thus avoiding over/under fitting issues. To compensate computational challenges arising from the non a priori known nature of the mixture model, we utilize conjugate priors and thus we derive analytical equations for model estimation. In this way, we avoid the need of any sampling method, which are computationally and memory inefficient. This selection makes our system suitable for online and real-time applications.\nThis paper is organized as follows: Section 2 formulates the Bayesian framework for mixture modeling. In Section 3 we present the procedure to analytically derive the solutions for estimating the distributions of model parameters. Section 4 describes the EM algorithm along with setting the priors and parameters initialization. Section 5 discusses the online updating mechanism and Section 6 presents the background subtraction task. In Section 7 experimental results are given and Section 8 concludes this work."
    }, {
      "heading" : "2. GAUSSIAN MIXTURE MODELING",
      "text" : "In this section we formulate the Bayesian framework adopted in this paper to analytically estimate all the parameters of the proposed Gaussian mixture model. For this reason, in section 2.1 we briefly describe the basic theory behind Gaussian mixture model, while in section 2.2 we describe the introduction of conjugate priors that assist us in yielding analytical model estimations as in Section 3."
    }, {
      "heading" : "2.1. Model fundamentals",
      "text" : "The Gaussian mixture distribution can be seen as a linear superposition of Gaussian functional components,\np(x|$,µ, τ ) = K∑ k=1 $kN (x|µk, τ−1k ) (1)\nwhere the parameters {$k}Kk=1 must satisfy 0 ≤ $k ≤ 1 for every k and ∑K k=1$k = 1 and K is the number of Gaussian components. In the proposed mixture modeling, variable K can take any natural value up to infinity. However, it is highly recommended to set the upper bound for K less than the cardinality of the dataset, i.e. the number of observed samples. By introducing a K-dimensional binary latent variable z, such as ∑K k=1 zk = 1 and p(zk = 1) = $k, the distribution p(x) can be defined in terms of a marginal distribution p(z) and a conditional distribution p(x|z) as follows\np(x|$,µ, τ ) = ∑ z p(z|$)p(x|z,µ, τ ) (2)\nwhere p(z|$) and and p(x|z) are in the form of\np(z|$) = K∏ k=1 $zkk (3)\np(x|z,µ, τ ) = K∏ k=1 N (x|µk, τ−1k ) zk (4)\nwhere µ = {µk}Kk=1 and τ = {τk}Kk=1, correspond to the mean values and precisions of Gaussian components. By introducing latent variables and transforming the Gaussian mixture distribution into the form of (2), we are able to exploit the EM algorithm for fitting our model to the observed data, as shown in Section 4.\nIf we have in our disposal a set X = {x1, ..., xN} of observed data we will also have a set Z = {z1, ...,zN} of latent variables. Each zn will be a K-dimensional binary vector, such as ∑K k=1 znk = 1, and, in order to take into consideration the whole dataset of N samples, the distributions of (3) and (4) will be transformed to\np(Z|$) = N∏ n=1 K∏ k=1 $znkk (5)\np(X|Z,µ, τ ) = N∏ n=1 K∏ k=1 N (xn|µk, τ−1k ) znk (6)"
    }, {
      "heading" : "2.2. Conjugate priors",
      "text" : "To avoid computational problems in estimating the parameters and the structure of the proposed Gaussian model, we introduce conjugate priors, over the model parameters µ, τ and$, that allow us to yield analytical solutions. This way the need of using sampling methods is prevented. Introduction of priors implies the use of a Bayesian framework for the analysis.\nLet us denote as Y = {Z,$,µ, τ} the set which contains all model latent variables and parameters and as q(Y ) its distribution. Then, our goal is to estimate q(Y ) which maximizes model evidence p(X).\nq(Y ) : max ln p(X) (7)\nwhere in (7) we used the logarithm of p(X) for calculus purposes. For maximizing (7) we need to define the distribution over Y , that is, p(Z|$) from (5), p($) and p(µ, τ ).\nDue to the fact that p(Z|$) is a Multinomial distribution, its conjugate prior is a Dirichlet distribution over the mixing coefficients$\np($) = Γ(Kλ0)\nΓ(λ0)K K∏ k=1 $λ0−1k (8)\nwhere Γ(·) is the Gamma function. Parameter λ0 has a physical interpretation; the smaller the value of this parameter is, the larger is the influence of the data rather than the prior on the posterior distribution p(Z|$). In order to introduce uninformative priors and not prefer a specific component against the other, we choose to use a single parameter λ0 for the Dirichlet distribution, instead of a vector with different values for each mixing coefficient.\nSimilarly, the conjugate prior of (4) takes the form of a Gaussian-Gamma distribution, because both µ and τ are unknown. Subsequently, the joint distribution of parameters µ and τ can be modeled as\np(µ, τ ) = p(µ|τ )p(τ ) (9a)\n= K∏ k=1 N (µk|m0, (β0τk)−1)Gam(τk|a0, b0) (9b)\nwhere Gam(·) denotes the Gamma distribution. In order to not express any specific preference about the form of the Gaussian components through the introduction of\npriors, we use uninformative priors by setting the values of hyperparameters m0, β0, a0 and b0 to appropriate values as shown in Section 4.\nHaving defined the parametric form of observed data, latent variables and parameters distributions, our goal is to approximate the posterior distribution p(Y |X) and the model evidence p(X), where Y = {Z,$,µ, τ} is the set with distribution q(Y ), which contains all model latent variables and parameters. Based on the Bayes rule, which states that p(X)p(Y |X) = p(X,Y ) the logarithm of distribution p(X) can be expressed as\nln p(X) = ∫ q(Y ) ln p(X,Y )\nq(Y ) dY − (10a) − ∫ q(Y ) ln\np(Y |X) q(Y ) dY\n= L(q) +KL(q||p) (10b)\nwhere KL(q||p) is the Kullback-Leibler divergence between q(Y ) and p(Y |X) distributions and L(q) is the lower bound of ln p(X). Since KL(q||p) is a non negative quantity, equals to zero only if q(Y ) is equal to p(Y |X), maximization of ln p(X) is equivalent to minimizing of KL(q||p). For minimizing KL(q||p) and estimating p(X) we exploit the EM algorithm, as shown in Section 4.\nBy making the assumption, based on variational inference, that the distribution q(Y ) can be factorized over M disjoint sets such as q(Y ) = ∏M i=1 qi(Yi), as shown in [1], the optimal solution q ∗ j (Yj) corresponds to the minimization of KL(q||p) is given by ln q∗j (Yj) = Ei6=j [ln p(X,Y )] + C (11)\nwhere Ei6=j [ln p(X,Y )] is the expectation of the joint distribution over all variables Yj for j 6= i and C is a constant. P (X,Y ) is modeled through (12).\nIn the following, we present the analytical solution for the optimal distributions q∗j (Yj) for model parameters and latent variables, i.e. the optimal distributions q∗(Z), q∗($), q∗(τ ) and q∗(µ|τ )."
    }, {
      "heading" : "3. OPTIMAL MODEL PARAMETER DISTRIBUTIONS",
      "text" : "According to (5), (6), (8) and (9), the joint distribution of all random variables can be factorized as follows\np(X,Z,$,µ, τ ) =p(X|Z,µ, τ )p(Z|$)\np($)p(µ|τ )p(τ ) (12)\nX corresponds to the set of the observed variables. All proofs are given in Appendix A."
    }, {
      "heading" : "3.1. Optimal q∗(Z) distribution",
      "text" : "Using (11) and the factorized form of (12) the distribution of the optimized factor q∗(Z) is given by a Multinomial distribution of the form\nq∗(Z) = N∏ n=1 K∏ k=1 ( ρnk∑K j=1 ρnj )znk = (13a)\n= N∏ n=1 K∏ k=1 rznknk (13b)\nas ρnk we have denote the quantity\nρnk = exp\n( E [ ln$k ] + 1 2 E [ ln τk ] − 1 2 ln 2π−\n− 1 2 Eµ,τ\n[ (xn − µk)2τk ]) (14) The expected value E[znk] of q∗(Z) is equal to rnk."
    }, {
      "heading" : "3.2. Optimal q∗($) distribution",
      "text" : "Using (12) and (11) the distribution of the optimized factor q∗($) is given a Dirichlet distribution of the form\nq∗($) = Γ( ∑K i=1 λi)∏K\nj=1 Γ(λj) K∏ k=1 $λk−1k (15)\nλk is equal to Nk + λ0, where Nk = ∑N n=1 rnk represents the proportion of data that belong to the k-th component."
    }, {
      "heading" : "3.3. Optimal q∗(µk|τk) distribution",
      "text" : "Similarly, the distribution of the optimized factor q∗(µk, τk) is given by a Gaussian distribution of the form\nq∗(µk|τk) = N (µk|mk, (βkτ)−1) (16)\nwhere the parameters mk and βk are given by\nβk = β0 +Nk (17a)\nmk = 1\nβk\n( β0m0 +Nkx̄k ) (17b)\nwhere x̄k is equal to 1Nk ∑N n=1 rnkxn represents the centroid of the data that belong to the k-th component."
    }, {
      "heading" : "3.4. Optimal q∗(τk) distribution",
      "text" : "After the estimation of q∗(µk|τk), distribution of the optimized factor q∗(τk) is given by a Gamma distribution of the following form\nq∗(τk) = Gam(τk|ak, bk) (18)\nwhile the parameters ak and bk are given by the following relations\nak = a0 + Nk 2\n(19a)\nbk = b0 + 1\n2\n( Nkσk +\nβ0Nk β0 +Nk\n( x̄k −m0 )2) (19b)\nwhere σk = 1Nk ∑N n=1(xn − x̄k)2."
    }, {
      "heading" : "4. DISTRIBUTION PARAMETERS OPTIMIZATION",
      "text" : "After the approximation of random variables distributions, we will use the EM algorithm in order to find optimal values for model parameters, i.e. maximize (10). In order to use the EM algorithm, we have to initialize priors hyperparameters λ0, a0, b0, m0 and β0 and the model parameters $k, µk, τk, βk, ak, bk and λk (see Section 3).\nThe parameter λ0 can be interpreted as the effective prior number of observations associated with each component. In order to introduce an uninformative prior for $, we set the parameter λ0 equal to N/K, suggesting that the same number of observations is associated to each component. Parameters a0 and b0 (positive values due to Gamma distribution) were set to the value of 10−3. Our choice is justified by the fact that the results of updating equations (19a) and (19b) are primarily affected by the data and not by the prior when the values for a0 and b0 are close to zero. The mean values of the components are described by conditional Normal distribution with means m0 and precisions β0τk. We introduce an uninformative prior by setting the value for m0 to the mean of the observed data and the parameter β0 = b0a0v0 , where v0 is the variance of the observed data.\nThe convergence of EM algorithm is facilitated by initializing the parameters $k, µk, τk and βk using the k-means. To utilize k-means, the number of clusters, corresponding to the Gaussian components, should be a priori known. Since we create a mixture model, the number of Gaussian components should be less or equal to the number of observed data. For this reason we set the number of clusters Kmax to a value smaller or equal to the number of observations. If we have no clue about the number of classes we can set Kmax to equal N . If we denote as N̂k the number of observation that belong to k-th cluster, then we can set the value of parameter µk to equal the centroid of k-th cluster, the parameter $k to equal the proportion of observations for the k-th cluster, the parameter τk to equal v̂−1k , where vk stands for the variance of the data of the k-th cluster and the parameter βk to equal N̂−1k . Having initialized the parameters $k, µk, τk and βk, we can exploit the formula for the expected value of a Gamma distribution to initialize the parameters ak and bk to values τk and one respectively. Finally, the initialization of $k allows us to initialize the parameter λk, which can be interpreted as the effective number of observations associated with each Gaussian component, to the value N$k.\nAfter the initialization of model parameters and priors hyperparameters, the EM algorithm can be used to minimize KL(q||p) of (10). During the E step, rnk is calculated given the initial/current values of all the parameters of the model. Using (13b) rnk is given by\nrnk ∝ $̃k τ̃k1/2 exp ( − ak\n2bk\n( xn −mk )2 − 1 2βk ) (20)\nDue to the fact that q∗($) is a Dirichlet distribution and q∗(τk) is a Gamma distribution, $̃k and τ̃k will be given by\nln $̃k ≡ E [ ln$k ] = Ψ(λk)−Ψ ( K∑ k=1 λk ) (21a)\nln τ̃k ≡ E [ ln τk ] = Ψ(ak)− ln bk (21b)\nwhere Ψ(·) is the digamma function.\nDuring the M step, we keep fixed the value for variables rnk (the value that was calculated during the E step), and we re-calculate the values for model parameters using (15), (17) and (19). The steps E and M are repeated sequentially untill the values for model parameters are not changing anymore. As shown in [2] convergence of EM algorithm is guaranteed because bound is convex with respect to each of the factors q(Z), q($), q(µ|τ ) and q(τ ).\nDuring model training the mixing coefficient for some of the components takes value very close to zero. Components with mixing coefficient less than 1/N are removed (we require each component to model at least one observed sample) and thus after training the model has automatically determined the right number of Gaussian components."
    }, {
      "heading" : "5. ONLINE UPDATING MECHANISM",
      "text" : "Having described how our model fits to N observed data, in this section we present the mechanism that permits our model to automatically adapt to new observed data. We use no heuristic rules but statistics based on the observed data.\nLet us denote as xnew a new observed sample. Then, there are two cases; either the new observed sample is successfully modeled by our trained model, or not. To estimate if a new sample is successfully modeled, we find the closest component to the new sample. As a distance metric between components and the new sample, we use the Mahalanobis distance, since this is reliable distance measure between a point and a distribution.\nThe closest component c to the new sample is the one that presents the minimum Mahalanobis distance Dk\nc = arg min k Dk = arg min k\n√ (xnew − µk)2τk (22)\nThe probability of the new sample to belong to c\np(xnew|µc, τc) = N (xnew|µc, τ−1c ) (23)\nwhere µc and τc stand for the closest component mean value and precision respectively.\nLet us denote as Ω the initially observed dataset. Then, we can assume that the probability to observe the new sample xnew is given by\np(xnew|e) = Ne N U(xnew|xnew − e, xnew + e) (24)\nwhere Ne = ∣∣{xi ∈ Ω : xnew − e ≤ xi ≤ xnew + e}∣∣ and U(xnew|xnew − e, xnew + e) is a Uniform distribution with lower and upper bounds to equal xnew − e and xnew + e respectively. Equation (24) suggests that the probability to observe xnew is related to the proportion of data that have already been observed around xnew. By increasing the neighborhood around xnew, i.e. increasing the value of e, the quantity U(xnew|xnew − e, xnew + e) is decreasing, while the value of Ne is increasing.\nUpon arrival of a new sample xnew, we can estimate the optimal range around xnew that maximizes (24) as\n= arg max e p(xnew|e) (25)\nThen, if p(xnew|µc, τc) ≥ p(xnew| ) the new observed sample xnew can sufficiently represented by our model. Otherwise, a new Gaussian component must be created.\nFor model updating, we need to define the binary variable o, called ownership and associated with the Gaussian components, as\nok = 1, if k = c0, otherwise (26) where we recall that c represents the index of the closest component and k is the index of k-th component.\nWhen the new observed sample is successfully modeled, the parameters for the Gaussian components are updated using the following the leader [6] approach described as\n$k ← $k + 1\nN\n( ok −$k ) (27a)\nµk ← µk + ok (xnew − µk $kN + 1 ) (27b)\nσ2k ← σ2k + ok ( $kN(xnew − µk)2\n($kN + 1)2 − σ\n2 k\n$kN + 1\n) (27c)\nwhere σ2k is equal to τ −1 k .\nWhen the new observed sample cannot be modeled by the existing components, a new component is created with mixing coefficient $new, mean value µnew and standard deviation σnew, the parameters of which are given as\n$new = 1\nN , µnew = xnew , σ\n2 new = (2 )2 − 1 12\n(28)\nFrom (28), we see that the mixing coefficient for the new component is equal to 1/N since it models only one sample (the new observed one), its mean value equals the value of the new sample and its variance the variance the Uniform distribution, whose the lower and upper bounds are xnew− and xnew + respectively. When a new component is created the values for the parameters for all the other components remain unchanged except mixing coefficients $, which are normalized to sum N−1N . After each adaptation of the system to new observed samples, either they modeled by the trained model or not, the mixing coefficients of the components are normalized to sum to one.\nFigure 2 presents the adaptation of our model (first row) and the model presented in [29] (second row) to new observed data. To evaluate the quality of the adaptation of the models, we used a toy dataset with 100 observations. Observed data were generated from two Normal distributions with mean values 16 and 50 and standard deviations 1.5 and 2.0 respectively. The initially trained models are presented in the left column. Then, we generated 25 new samples form a Normal distribution with mean value 21 and standard deviation 1.0. Our model creates a new component and successfully fits the data. On the contrary, the model of [29] is not able to capture the statistical relations of the new observations and fails to separate the data generated from distributions with mean values 16 and 21 (middle column). The quality of our adaptation mechanism becomes more clear in the right column, which presents the adaptation of both models after 50 new observations.\nAlgorithm 1: Overview of Background Subtraction 1: capture N frames 2: create N -length history for each pixel 3: initialize parameters (see Section 5) 4: until convergence (training phase: Section 4) 5: compute rnk using (20) 6: recompute parameters using (15), (17) and (19) 7: for each new captured frame 8: classify each pixel as foreground or background (see Section 6) 9: update background model (see Section 5)"
    }, {
      "heading" : "6. BACKGROUND SUBTRACTION",
      "text" : "In this section we utilize our model for background subtraction. We initially capture N frames used to create an infrared responses history for each pixel. These histories act as observed data and used to train a model for each pixel. To classify a pixel of a new captured frame as background or foreground, we compute the probability its value to be represented by the mixture model. If this value is larger than a threshold the pixel is classified as background, otherwise it is classified as foreground. The threshold can be defined in relation to the parameters of the mixture, in order to be dynamically adapted. For example, we can define the threshold to be equal to µc ± νσc where ν is a scalar defining a confidence interval. The overview of the background subtraction algorithm is shown in Algorithm 1."
    }, {
      "heading" : "7. EXPERIMENTAL RESULTS",
      "text" : "For evaluating our algorithm, we used the Ohio State University (OSU) thermal datasets and a dataset captured at Athens International Airport (AIA) during Evacuate1 European funding project. OSU datasets contain frames that have been captured using a thermal camera and have been converted to grayscale images. In contrast, the AIA dataset contains raw thermal frames whose pixel values correspond to the real temperature of objects.\nOSU datasets [7–9] are widely used for benchmarking algorithms for pedestrian detection and tracking in infrared imagery. Videos were captured under different illumination and weather conditions. AIA dataset was captured using a Flir A315 camera at different Airside Corridors and the Departure Level. Totally, 10 video sequences were captured, with frame dimensions\n1http://www.evacuate.eu/\n320 × 240 pixels of total duration 32051 frames, at 7.5fps, that is, about 1h and 12mins. During experimentation process we used the sequence captured at the Departure Level Entrance 3 which provides a panoramic view of the space. The other sequences at corridors, due to narrow space perspective and the fact that videos were captured by mounting the camera at human height level, are inappropriate for testing background subtraction algorithms.\nWe compared our method with the method presented by Zivkovic in [29] (MOG), which is one of the most robust and widely used background subtraction technique, and with the method for extracting the regions of interest presented in [8,9] (SBG) used for thermal data. To conduct the comparison we utilized the objective metrics of recall, precision and F1 score on a pixel wise manner. Figures 3 visually present the performance of the three methods. As is observed, our method outperforms both MOG and SBG on all datasets. While MOG and SBG perform satisfactory on grayscale frames of OSU datasets, their performance collapses when they applied on AIA dataset, which contains actual thermal responses. Regarding OSU datasets, MOG algorithm while presents high precision it yields very low recall values, i.e. the pixels that have been classified as foreground are indeed belong to the foreground class, but a lot of pixels that in fact belong to background have been misclassified. SBG algorithm seems to suffer by the opposite problem. Regarding AIA dataset, our method significantly outperforms both methods. In particular, while MOG and SBG algorithms present relative high precision, their recall values are under 0.2. Figure 4(a) presents average precision, recall and F1 score per dataset and per algorithm for all frames examined to give an objective evaluation. In Figure 4(b) presents the best and worst case in terms of precision, recall and F1 score among all frames examined.\nRegarding computational cost, the main load of our algorithm is in the implementation of EM optimization. In all experiments conducted, the EM optimization converges within 10 iterations. Practically, the time required to apply our method is similar to the time requirements of Zivkovic’s method making it suitable for real-time applications."
    }, {
      "heading" : "8. CONCLUSIONS",
      "text" : "This paper presents a background subtraction method applicable to thermal imagery, based on Gaussian mixture modeling with unknown number. We analytically derive the solutions that describe the parameters of the model and we use the EM optimization to estimate their values, avoid sampling algorithms and high computational cost. Due to its low computational cost and the real-time operation, our method is suitable for real-world applications."
    }, {
      "heading" : "A. APPENDIX",
      "text" : "Using (11) and (12) the logarithm of q∗(Z) is given by\nln q∗(Z) =E$[ln p(Z|$)]+\n+ Eµ,τ [ln p(X|Z,µ, τ )] + C (29)\nsubstituting (5) and (6) into (29) we get\nln q∗(Z) = N∑ n=1 K∑ k=1 znk ( E [ ln$k ] + 1 2 E [ ln τk ] −\n− 1 2 ln 2π − 1 2 Eµ,τ\n[ (xn − µk)2τk ]) + C ⇒\nUsing (12) and (11) the logarithm of q∗($,µ, τ ) is\nln q∗($,µ, τ ) = EZ [ ln p(X|Z,µ, τ )+\n+ ln p(Z|$)+ + ln p($) + ln p(µ, τ ) ] + C = (31a)\n= N∑ n=1 K∑ k=1 E [ znk ] lnN (xn|µk, τ−1k )+\n+ EZ [ ln p(Z|$) ]\n+ ln p($) + K∑ k=1 ln p(µk, τk) + C (31b)\nDue to the fact that there is no term in (31b) that contains parameters from both sets {$} and {µ, τ}, the distribution q∗($,µ, τ ) can be factorized as q($,µ, τ ) = q($) ∏K k=1 q(µk, τk). The distribution for q\n∗($) is derived using only those terms of (31b) that depend on the variable$. Therefore the logarithm of q($) is given by\nln q∗($) = EZ [ ln p(Z|$) ] + ln p($) + C = (32a)\n= K∑ k=1 ln$ ( ∑N n=1 rnk+λ0−1) k + C = (32b)\n= K∑ k=1 ln$ (Nk+λ0−1) k + C (32c)\nWe have made use of E[znk] = rnk, and we have denote as Nk = ∑N n=1 rnk. (32c) suggests that q\n∗($) is a Dirichlet distribution with hyperparameters λ = {Nk + λ0}Kk=1.\nUsing only those terms of (31b) that depend on variables µ and τ , the logarithm of q∗(µk, τk) is given by\nln q∗(µk, τk) = lnN (µk|m0, (β0τk)1)+\n+ lnGam(τk|a0, b0)+\n+ N∑ n=1 E [ znk ] lnN (xn|µk, τ−1k ) + C =\n= −β0τk 2 (µk −m0)2 + 1 2 ln(β0τk)+\n+ (a0 − 1) ln τk − b0τk−\n− 1 2 N∑ n=1 E [ znk ] (xn − µk)2τk+\n+ 1\n2 ( N∑ n=1 E [ znk ]) ln(β0τk) + C (33)\nFor the estimation of q∗(µk|τk), we use (33) and keep only those factors that depend on µk.\nln q∗(µk|τk) = − β0τk\n2\n( µk −m0 )2− − 1\n2 N∑ n=1 E [ znk ]( xn − µk )2 τk = (34a)\n= −1 2 µ2k\n( β0 +Nk ) τk+\n+ µkτk ( β0m0 +Nkx̄k ) + C ⇒ (34b)\nq∗(µk|τk) = N (µk|mk, (βkτ)−1) (34c)\nwhere x̄k = 1Nk ∑N n=1 rnkxn, βk = β0 +Nk and mk = 1 βk (β0m0 +Nkx̄k).\nAfter the estimation of q∗(µk|τk), logarithm of the optimized the distribution q∗(τk) is given by\nln q∗(τk) = ln q ∗(µk, τk)− ln q∗(µk|τk) = (35a)\n= ( a0 + Nk 2 − 1 ) ln τk−\n− 1 2 τk\n( β0 ( µk −m0 )2 +\n+ 2b0 + N∑ n=1 rnk ( xn − µk )2− − βk ( µk −mk )2) + C ⇒ (35b)\nq∗(τk) = Gam(τk|ak, bk) (35c)\nThe parameters ak and bk are given by\nak = a0 + Nk 2\n(36a)\nbk = b0 + 1\n2\n( Nkσk +\nβ0Nk β0 +Nk\n( x̄k −m0 )2) (36b)\nwhere σk = 1Nk ∑N n=1(xn − x̄k)2."
    }, {
      "heading" : "B. REFERENCES",
      "text" : "[1] C. Bishop. Pattern Recognition and Machine Learning (Information Science and Statistics). Springer, Oct. 2007. [2] S. Boyd and L. Vandenberghe. Convex Optimization. Cambridge University Press, Mar. 2004. [3] S. Brutzer, B. Hoferlin, and G. Heidemann. Evaluation of background subtraction techniques for video surveillance. In 2011 IEEE\nConference on Computer Vision and Pattern Recognition (CVPR), pages 1937–1944, June 2011.\n[4] S.-C. S. Cheung and C. Kamath. Robust background subtraction with foreground validation for urban traffic video. EURASIP Journal\non Advances in Signal Processing, 2005(14):726261, Aug. 2005.\n[5] C. Dai, Y. Zheng, and X. Li. Pedestrian detection and tracking in infrared imagery using shape and appearance. Computer Vision and\nImage Understanding, 106(23):288–299, May 2007.\n[6] S. Dasgupta and D. Hsu. On-line estimation with the multivariate gaussian distribution. In Proceedings of the 20th Annual Conference\non Learning Theory, COLT’07, pages 278–292, Berlin, Heidelberg, 2007. Springer-Verlag.\n[7] J. Davis and V. Sharma. Fusion-based background-subtraction using contour saliency. In IEEE Computer Society Conference on\nComputer Vision and Pattern Recognition - Workshops, 2005. CVPR Workshops, pages 11–11, June 2005.\n[8] J. W. Davis and V. Sharma. Robust background-subtraction for person detection in thermal imagery. In Proceedings of the 2004\nConference on Computer Vision and Pattern Recognition Workshop (CVPRW’04) Volume 8 - Volume 08, CVPRW ’04, pages 128–, Washington, DC, USA, 2004. IEEE Computer Society. [9] J. W. Davis and V. Sharma. Background-subtraction in thermal imagery using contour saliency. International Journal of Computer\nVision, 71(2):161–181, Feb. 2007.\n[10] F. El Baf, T. Bouwmans, and B. Vachon. Fuzzy statistical modeling of dynamic backgrounds for moving object detection in infrared\nvideos. In IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops, 2009. CVPR Workshops 2009, pages 60–65, June 2009. [11] A. Elgammal, D. Harwood, and L. Davis. Non-parametric model for background subtraction. In D. Vernon, editor, Computer Vision\nECCV 2000, number 1843 in Lecture Notes in Computer Science, pages 751–767. Springer Berlin Heidelberg, Jan. 2000.\n[12] T. Elguebaly and N. Bouguila. Finite asymmetric generalized gaussian mixture models learning for infrared object detection. Computer\nVision and Image Understanding, 117(12):1659–1671, Dec. 2013.\n[13] R. Gade, A. Jorgensen, and T. Moeslund. Long-term occupancy analysis using graph-based optimisation in thermal imagery. In 2013\nIEEE Conference on Computer Vision and Pattern Recognition (CVPR), pages 3698–3705, June 2013.\n[14] T. Haines and T. Xiang. Background subtraction with DirichletProcess mixture models. IEEE Transactions on Pattern Analysis and\nMachine Intelligence, 36(4):670–683, Apr. 2014.\n[15] S. Herrero and J. Bescs. Background subtraction techniques: Systematic evaluation and comparative analysis. In Proceedings of the\n11th International Conference on Advanced Concepts for Intelligent Vision Systems, ACIVS ’09, pages 33–42, Berlin, Heidelberg, 2009. Springer-Verlag. [16] K. Jungling and M. Arens. Feature based person detection beyond the visible spectrum. In IEEE Computer Society Conference on\nComputer Vision and Pattern Recognition Workshops, 2009. CVPR Workshops 2009, pages 30–37, June 2009.\n[17] L. Latecki, R. Miezianko, and D. Pokrajac. Tracking motion objects in infrared videos. In IEEE Conference on Advanced Video and\nSignal Based Surveillance, 2005. AVSS 2005, pages 99–104, Sept. 2005.\n[18] K. Makantasis, A. Doulamis, and N. Matsatsinis. Student-t background modeling for persons’ fall detection through visual cues. In\n2012 13th International Workshop on Image Analysis for Multimedia Interactive Services (WIAMIS), pages 1–4, May 2012.\n[19] N. J. B. McFarlane and C. P. Schofield. Segmentation and tracking of piglets in images. Machine Vision and Applications, 8(3):187–193,\nMay 1995.\n[20] S. Messelodi, C. M. Modena, N. Segata, and M. Zanin. A kalman filter based background updating algorithm robust to sharp illumination\nchanges. In F. Roli and S. Vitulano, editors, Image Analysis and Processing ICIAP 2005, number 3617 in Lecture Notes in Computer Science, pages 163–170. Springer Berlin Heidelberg, Jan. 2005. [21] F. Porikli. Achieving real-time object detection and tracking under extreme conditions. Journal of Real-Time Image Processing,\n1(1):33–40, Mar. 2006.\n[22] C. Stauffer and W. Grimson. Adaptive background mixture models for real-time tracking. In Computer Vision and Pattern Recognition,\n1999. IEEE Computer Society Conference on., volume 2, pages –252 Vol. 2, 1999.\n[23] K. Toyama, J. Krumm, B. Brumitt, and B. Meyers. Wallflower: principles and practice of background maintenance. In The Proceedings\nof the Seventh IEEE International Conference on Computer Vision, 1999, volume 1, pages 255–261 vol.1, 1999.\n[24] O. Tuzel, F. Porikli, and P. Meer. Human detection via classification on riemannian manifolds. In IEEE Conference on Computer Vision\nand Pattern Recognition, 2007. CVPR ’07, pages 1–8, June 2007.\n[25] O. Tuzel, F. Porikli, and P. Meer. Pedestrian detection via classification on riemannian manifolds. IEEE Transactions on Pattern Analysis\nand Machine Intelligence, 30(10):1713–1727, Oct. 2008.\n[26] W. Wang, J. Zhang, and C. Shen. Improved human detection and classification in thermal images. In 2010 17th IEEE International\nConference on Image Processing (ICIP), pages 2313–2316, Sept. 2010.\n[27] C. Wren, A. Azarbayejani, T. Darrell, and A. Pentland. Pfinder: real-time tracking of the human body. IEEE Transactions on Pattern\nAnalysis and Machine Intelligence, 19(7):780–785, July 1997.\n[28] J. Zheng, Y. Wang, N. Nihan, and M. Hallenbeck. Extracting roadway background image: Mode-based approach. Transportation\nResearch Record: Journal of the Transportation Research Board, 1944:82–88, Jan. 2006.\n[29] Z. Zivkovic. Improved adaptive gaussian mixture model for background subtraction. In Proceedings of the 17th International Conference\non Pattern Recognition, 2004. ICPR 2004, volume 2, pages 28–31 Vol.2, Aug. 2004.\n[30] Z. Zivkovic and F. van der Heijden. Efficient adaptive density estimation per image pixel for the task of background subtraction. Pattern\nRecognition Letters, 27(7):773–780, May 2006."
    } ],
    "references" : [ {
      "title" : "Pattern Recognition and Machine Learning (Information Science and Statistics)",
      "author" : [ "C. Bishop" ],
      "venue" : "Springer, Oct.",
      "citeRegEx" : "1",
      "shortCiteRegEx" : null,
      "year" : 2007
    }, {
      "title" : "Convex Optimization",
      "author" : [ "S. Boyd", "L. Vandenberghe" ],
      "venue" : "Cambridge University Press, Mar.",
      "citeRegEx" : "2",
      "shortCiteRegEx" : null,
      "year" : 2004
    }, {
      "title" : "Evaluation of background subtraction techniques for video surveillance",
      "author" : [ "S. Brutzer", "B. Hoferlin", "G. Heidemann" ],
      "venue" : "2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pages 1937–1944, June",
      "citeRegEx" : "3",
      "shortCiteRegEx" : null,
      "year" : 2011
    }, {
      "title" : "Robust background subtraction with foreground validation for urban traffic video",
      "author" : [ "S.-C.S. Cheung", "C. Kamath" ],
      "venue" : "EURASIP Journal on Advances in Signal Processing, 2005(14):726261, Aug.",
      "citeRegEx" : "4",
      "shortCiteRegEx" : null,
      "year" : 2005
    }, {
      "title" : "Pedestrian detection and tracking in infrared imagery using shape and appearance",
      "author" : [ "C. Dai", "Y. Zheng", "X. Li" ],
      "venue" : "Computer Vision and Image Understanding, 106(23):288–299, May",
      "citeRegEx" : "5",
      "shortCiteRegEx" : null,
      "year" : 2007
    }, {
      "title" : "On-line estimation with the multivariate gaussian distribution",
      "author" : [ "S. Dasgupta", "D. Hsu" ],
      "venue" : "Proceedings of the 20th Annual Conference on Learning Theory, COLT’07, pages 278–292, Berlin, Heidelberg,",
      "citeRegEx" : "6",
      "shortCiteRegEx" : null,
      "year" : 2007
    }, {
      "title" : "Fusion-based background-subtraction using contour saliency",
      "author" : [ "J. Davis", "V. Sharma" ],
      "venue" : "IEEE Computer Society Conference on Computer Vision and Pattern Recognition - Workshops, 2005. CVPR Workshops, pages 11–11, June",
      "citeRegEx" : "7",
      "shortCiteRegEx" : null,
      "year" : 2005
    }, {
      "title" : "Robust background-subtraction for person detection in thermal imagery",
      "author" : [ "J.W. Davis", "V. Sharma" ],
      "venue" : "Proceedings of the 2004 Conference on Computer Vision and Pattern Recognition Workshop (CVPRW’04) Volume 8 - Volume 08, CVPRW ’04, pages 128–, Washington, DC, USA,",
      "citeRegEx" : "8",
      "shortCiteRegEx" : null,
      "year" : 2004
    }, {
      "title" : "Background-subtraction in thermal imagery using contour saliency",
      "author" : [ "J.W. Davis", "V. Sharma" ],
      "venue" : "International Journal of Computer Vision, 71(2):161–181, Feb.",
      "citeRegEx" : "9",
      "shortCiteRegEx" : null,
      "year" : 2007
    }, {
      "title" : "Fuzzy statistical modeling of dynamic backgrounds for moving object detection in infrared videos",
      "author" : [ "F. El Baf", "T. Bouwmans", "B. Vachon" ],
      "venue" : "IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops, 2009. CVPR Workshops 2009, pages 60–65, June",
      "citeRegEx" : "10",
      "shortCiteRegEx" : null,
      "year" : 2009
    }, {
      "title" : "Non-parametric model for background subtraction",
      "author" : [ "A. Elgammal", "D. Harwood", "L. Davis" ],
      "venue" : "D. Vernon, editor, Computer Vision ECCV 2000, number 1843 in Lecture Notes in Computer Science, pages 751–767. Springer Berlin Heidelberg, Jan.",
      "citeRegEx" : "11",
      "shortCiteRegEx" : null,
      "year" : 2000
    }, {
      "title" : "Finite asymmetric generalized gaussian mixture models learning for infrared object detection",
      "author" : [ "T. Elguebaly", "N. Bouguila" ],
      "venue" : "Computer Vision and Image Understanding, 117(12):1659–1671, Dec.",
      "citeRegEx" : "12",
      "shortCiteRegEx" : null,
      "year" : 2013
    }, {
      "title" : "Long-term occupancy analysis using graph-based optimisation in thermal imagery",
      "author" : [ "R. Gade", "A. Jorgensen", "T. Moeslund" ],
      "venue" : "2013 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pages 3698–3705, June",
      "citeRegEx" : "13",
      "shortCiteRegEx" : null,
      "year" : 2013
    }, {
      "title" : "Background subtraction with DirichletProcess mixture models",
      "author" : [ "T. Haines", "T. Xiang" ],
      "venue" : "IEEE Transactions on Pattern Analysis and Machine Intelligence, 36(4):670–683, Apr.",
      "citeRegEx" : "14",
      "shortCiteRegEx" : null,
      "year" : 2014
    }, {
      "title" : "Background subtraction techniques: Systematic evaluation and comparative analysis",
      "author" : [ "S. Herrero", "J. Bescs" ],
      "venue" : "Proceedings of the 11th International Conference on Advanced Concepts for Intelligent Vision Systems, ACIVS ’09, pages 33–42, Berlin, Heidelberg,",
      "citeRegEx" : "15",
      "shortCiteRegEx" : null,
      "year" : 2009
    }, {
      "title" : "Feature based person detection beyond the visible spectrum",
      "author" : [ "K. Jungling", "M. Arens" ],
      "venue" : "IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops, 2009. CVPR Workshops 2009, pages 30–37, June",
      "citeRegEx" : "16",
      "shortCiteRegEx" : null,
      "year" : 2009
    }, {
      "title" : "Tracking motion objects in infrared videos",
      "author" : [ "L. Latecki", "R. Miezianko", "D. Pokrajac" ],
      "venue" : "IEEE Conference on Advanced Video and Signal Based Surveillance, 2005. AVSS 2005, pages 99–104, Sept.",
      "citeRegEx" : "17",
      "shortCiteRegEx" : null,
      "year" : 2005
    }, {
      "title" : "Student-t background modeling for persons’ fall detection through visual cues",
      "author" : [ "K. Makantasis", "A. Doulamis", "N. Matsatsinis" ],
      "venue" : "2012 13th International Workshop on Image Analysis for Multimedia Interactive Services (WIAMIS), pages 1–4, May",
      "citeRegEx" : "18",
      "shortCiteRegEx" : null,
      "year" : 2012
    }, {
      "title" : "Segmentation and tracking of piglets in images",
      "author" : [ "N.J.B. McFarlane", "C.P. Schofield" ],
      "venue" : "Machine Vision and Applications, 8(3):187–193, May",
      "citeRegEx" : "19",
      "shortCiteRegEx" : null,
      "year" : 1995
    }, {
      "title" : "A kalman filter based background updating algorithm robust to sharp illumination changes",
      "author" : [ "S. Messelodi", "C.M. Modena", "N. Segata", "M. Zanin" ],
      "venue" : "F. Roli and S. Vitulano, editors, Image Analysis and Processing ICIAP 2005, number 3617 in Lecture Notes in Computer Science, pages 163–170. Springer Berlin Heidelberg, Jan.",
      "citeRegEx" : "20",
      "shortCiteRegEx" : null,
      "year" : 2005
    }, {
      "title" : "Achieving real-time object detection and tracking under extreme conditions",
      "author" : [ "F. Porikli" ],
      "venue" : "Journal of Real-Time Image Processing, 1(1):33–40, Mar.",
      "citeRegEx" : "21",
      "shortCiteRegEx" : null,
      "year" : 2006
    }, {
      "title" : "Adaptive background mixture models for real-time tracking",
      "author" : [ "C. Stauffer", "W. Grimson" ],
      "venue" : "Computer Vision and Pattern Recognition, 1999. IEEE Computer Society Conference on., volume 2, pages –252 Vol. 2,",
      "citeRegEx" : "22",
      "shortCiteRegEx" : null,
      "year" : 1999
    }, {
      "title" : "Wallflower: principles and practice of background maintenance",
      "author" : [ "K. Toyama", "J. Krumm", "B. Brumitt", "B. Meyers" ],
      "venue" : "The Proceedings of the Seventh IEEE International Conference on Computer Vision, 1999, volume 1, pages 255–261 vol.1,",
      "citeRegEx" : "23",
      "shortCiteRegEx" : null,
      "year" : 1999
    }, {
      "title" : "Human detection via classification on riemannian manifolds",
      "author" : [ "O. Tuzel", "F. Porikli", "P. Meer" ],
      "venue" : "IEEE Conference on Computer Vision and Pattern Recognition, 2007. CVPR ’07, pages 1–8, June",
      "citeRegEx" : "24",
      "shortCiteRegEx" : null,
      "year" : 2007
    }, {
      "title" : "Pedestrian detection via classification on riemannian manifolds",
      "author" : [ "O. Tuzel", "F. Porikli", "P. Meer" ],
      "venue" : "IEEE Transactions on Pattern Analysis and Machine Intelligence, 30(10):1713–1727, Oct.",
      "citeRegEx" : "25",
      "shortCiteRegEx" : null,
      "year" : 2008
    }, {
      "title" : "Improved human detection and classification in thermal images",
      "author" : [ "W. Wang", "J. Zhang", "C. Shen" ],
      "venue" : "2010 17th IEEE International Conference on Image Processing (ICIP), pages 2313–2316, Sept.",
      "citeRegEx" : "26",
      "shortCiteRegEx" : null,
      "year" : 2010
    }, {
      "title" : "Pfinder: real-time tracking of the human body",
      "author" : [ "C. Wren", "A. Azarbayejani", "T. Darrell", "A. Pentland" ],
      "venue" : "IEEE Transactions on Pattern Analysis and Machine Intelligence, 19(7):780–785, July",
      "citeRegEx" : "27",
      "shortCiteRegEx" : null,
      "year" : 1997
    }, {
      "title" : "Extracting roadway background image: Mode-based approach",
      "author" : [ "J. Zheng", "Y. Wang", "N. Nihan", "M. Hallenbeck" ],
      "venue" : "Transportation Research Record: Journal of the Transportation Research Board, 1944:82–88, Jan.",
      "citeRegEx" : "28",
      "shortCiteRegEx" : null,
      "year" : 2006
    }, {
      "title" : "Improved adaptive gaussian mixture model for background subtraction",
      "author" : [ "Z. Zivkovic" ],
      "venue" : "Proceedings of the 17th International Conference on Pattern Recognition, 2004. ICPR 2004, volume 2, pages 28–31 Vol.2, Aug.",
      "citeRegEx" : "29",
      "shortCiteRegEx" : null,
      "year" : 2004
    }, {
      "title" : "Efficient adaptive density estimation per image pixel for the task of background subtraction",
      "author" : [ "Z. Zivkovic", "F. van der Heijden" ],
      "venue" : "Pattern Recognition Letters,",
      "citeRegEx" : "30",
      "shortCiteRegEx" : "30",
      "year" : 2006
    } ],
    "referenceMentions" : [ {
      "referenceID" : 12,
      "context" : "Furthermore, infrared imagery eliminates any privacy issues as people being depicted in the scene can not be identified [13].",
      "startOffset" : 120,
      "endOffset" : 124
    }, {
      "referenceID" : 3,
      "context" : "For many high-level vision based applications, either they use visual-optical videos [4,21,24,25] or infrared data [16,17,26], the task of background subtraction constitutes a key component, as this is one of the most common methods for locating moving objects, facilitating search space reduction and visual attention modeling.",
      "startOffset" : 85,
      "endOffset" : 97
    }, {
      "referenceID" : 20,
      "context" : "For many high-level vision based applications, either they use visual-optical videos [4,21,24,25] or infrared data [16,17,26], the task of background subtraction constitutes a key component, as this is one of the most common methods for locating moving objects, facilitating search space reduction and visual attention modeling.",
      "startOffset" : 85,
      "endOffset" : 97
    }, {
      "referenceID" : 23,
      "context" : "For many high-level vision based applications, either they use visual-optical videos [4,21,24,25] or infrared data [16,17,26], the task of background subtraction constitutes a key component, as this is one of the most common methods for locating moving objects, facilitating search space reduction and visual attention modeling.",
      "startOffset" : 85,
      "endOffset" : 97
    }, {
      "referenceID" : 24,
      "context" : "For many high-level vision based applications, either they use visual-optical videos [4,21,24,25] or infrared data [16,17,26], the task of background subtraction constitutes a key component, as this is one of the most common methods for locating moving objects, facilitating search space reduction and visual attention modeling.",
      "startOffset" : 85,
      "endOffset" : 97
    }, {
      "referenceID" : 15,
      "context" : "For many high-level vision based applications, either they use visual-optical videos [4,21,24,25] or infrared data [16,17,26], the task of background subtraction constitutes a key component, as this is one of the most common methods for locating moving objects, facilitating search space reduction and visual attention modeling.",
      "startOffset" : 115,
      "endOffset" : 125
    }, {
      "referenceID" : 16,
      "context" : "For many high-level vision based applications, either they use visual-optical videos [4,21,24,25] or infrared data [16,17,26], the task of background subtraction constitutes a key component, as this is one of the most common methods for locating moving objects, facilitating search space reduction and visual attention modeling.",
      "startOffset" : 115,
      "endOffset" : 125
    }, {
      "referenceID" : 25,
      "context" : "For many high-level vision based applications, either they use visual-optical videos [4,21,24,25] or infrared data [16,17,26], the task of background subtraction constitutes a key component, as this is one of the most common methods for locating moving objects, facilitating search space reduction and visual attention modeling.",
      "startOffset" : 115,
      "endOffset" : 125
    }, {
      "referenceID" : 2,
      "context" : "Background subtraction techniques applied on visual-optical videos model the color properties of depicted objects [3, 15] and can be classified into three main categories [10]: basic background modeling [19, 28], statistical background modeling [11, 27] and background estimation [20, 23].",
      "startOffset" : 114,
      "endOffset" : 121
    }, {
      "referenceID" : 14,
      "context" : "Background subtraction techniques applied on visual-optical videos model the color properties of depicted objects [3, 15] and can be classified into three main categories [10]: basic background modeling [19, 28], statistical background modeling [11, 27] and background estimation [20, 23].",
      "startOffset" : 114,
      "endOffset" : 121
    }, {
      "referenceID" : 9,
      "context" : "Background subtraction techniques applied on visual-optical videos model the color properties of depicted objects [3, 15] and can be classified into three main categories [10]: basic background modeling [19, 28], statistical background modeling [11, 27] and background estimation [20, 23].",
      "startOffset" : 171,
      "endOffset" : 175
    }, {
      "referenceID" : 18,
      "context" : "Background subtraction techniques applied on visual-optical videos model the color properties of depicted objects [3, 15] and can be classified into three main categories [10]: basic background modeling [19, 28], statistical background modeling [11, 27] and background estimation [20, 23].",
      "startOffset" : 203,
      "endOffset" : 211
    }, {
      "referenceID" : 27,
      "context" : "Background subtraction techniques applied on visual-optical videos model the color properties of depicted objects [3, 15] and can be classified into three main categories [10]: basic background modeling [19, 28], statistical background modeling [11, 27] and background estimation [20, 23].",
      "startOffset" : 203,
      "endOffset" : 211
    }, {
      "referenceID" : 10,
      "context" : "Background subtraction techniques applied on visual-optical videos model the color properties of depicted objects [3, 15] and can be classified into three main categories [10]: basic background modeling [19, 28], statistical background modeling [11, 27] and background estimation [20, 23].",
      "startOffset" : 245,
      "endOffset" : 253
    }, {
      "referenceID" : 26,
      "context" : "Background subtraction techniques applied on visual-optical videos model the color properties of depicted objects [3, 15] and can be classified into three main categories [10]: basic background modeling [19, 28], statistical background modeling [11, 27] and background estimation [20, 23].",
      "startOffset" : 245,
      "endOffset" : 253
    }, {
      "referenceID" : 19,
      "context" : "Background subtraction techniques applied on visual-optical videos model the color properties of depicted objects [3, 15] and can be classified into three main categories [10]: basic background modeling [19, 28], statistical background modeling [11, 27] and background estimation [20, 23].",
      "startOffset" : 280,
      "endOffset" : 288
    }, {
      "referenceID" : 22,
      "context" : "Background subtraction techniques applied on visual-optical videos model the color properties of depicted objects [3, 15] and can be classified into three main categories [10]: basic background modeling [19, 28], statistical background modeling [11, 27] and background estimation [20, 23].",
      "startOffset" : 280,
      "endOffset" : 288
    }, {
      "referenceID" : 21,
      "context" : "Towards this direction, the work of Stauffer and Grimson [22], is one of the best known approaches.",
      "startOffset" : 57,
      "endOffset" : 61
    }, {
      "referenceID" : 17,
      "context" : "in [18] propose a Student-t mixture model for background modeling, taking advantage of Student-t distribution compactness and robustness to noise and outliers.",
      "startOffset" : 3,
      "endOffset" : 7
    }, {
      "referenceID" : 28,
      "context" : "The works of [29] and [30] extend the method of [22] by introducing a rule based on a user defined threshold to estimate the number of components.",
      "startOffset" : 13,
      "endOffset" : 17
    }, {
      "referenceID" : 29,
      "context" : "The works of [29] and [30] extend the method of [22] by introducing a rule based on a user defined threshold to estimate the number of components.",
      "startOffset" : 22,
      "endOffset" : 26
    }, {
      "referenceID" : 21,
      "context" : "The works of [29] and [30] extend the method of [22] by introducing a rule based on a user defined threshold to estimate the number of components.",
      "startOffset" : 48,
      "endOffset" : 52
    }, {
      "referenceID" : 13,
      "context" : "Haines and Xiang in [14] address this drawback by using a Dirichlet process mixture model.",
      "startOffset" : 20,
      "endOffset" : 24
    }, {
      "referenceID" : 6,
      "context" : "The authors of [7–9] exploit contour saliency to extract foreground objects.",
      "startOffset" : 15,
      "endOffset" : 20
    }, {
      "referenceID" : 7,
      "context" : "The authors of [7–9] exploit contour saliency to extract foreground objects.",
      "startOffset" : 15,
      "endOffset" : 20
    }, {
      "referenceID" : 8,
      "context" : "The authors of [7–9] exploit contour saliency to extract foreground objects.",
      "startOffset" : 15,
      "endOffset" : 20
    }, {
      "referenceID" : 9,
      "context" : "in [10] present a fuzzy statistical method for background subtraction to incorporate uncertainty into the mixture of Gaussians.",
      "startOffset" : 3,
      "endOffset" : 7
    }, {
      "referenceID" : 11,
      "context" : "Elguebaly and Bouguila in [12] propose a finite asymmetric generalized Gaussian mixture model for object detection.",
      "startOffset" : 26,
      "endOffset" : 30
    }, {
      "referenceID" : 4,
      "context" : "in [5] propose a method for pedestrian detection and tracking using infrared imagery.",
      "startOffset" : 3,
      "endOffset" : 6
    }, {
      "referenceID" : 0,
      "context" : "By making the assumption, based on variational inference, that the distribution q(Y ) can be factorized over M disjoint sets such as q(Y ) = ∏M i=1 qi(Yi), as shown in [1], the optimal solution q ∗ j (Yj) corresponds to the minimization of KL(q||p) is given by ln q∗ j (Yj) = Ei6=j [ln p(X,Y )] + C (11) where Ei6=j [ln p(X,Y )] is the expectation of the joint distribution over all variables Yj for j 6= i and C is a constant.",
      "startOffset" : 168,
      "endOffset" : 171
    }, {
      "referenceID" : 1,
      "context" : "As shown in [2] convergence of EM algorithm is guaranteed because bound is convex with respect to each of the factors q(Z), q($), q(μ|τ ) and q(τ ).",
      "startOffset" : 12,
      "endOffset" : 15
    }, {
      "referenceID" : 5,
      "context" : "When the new observed sample is successfully modeled, the parameters for the Gaussian components are updated using the following the leader [6] approach described as",
      "startOffset" : 140,
      "endOffset" : 143
    }, {
      "referenceID" : 28,
      "context" : "Second row: updating of model presented in [29].",
      "startOffset" : 43,
      "endOffset" : 47
    }, {
      "referenceID" : 28,
      "context" : "Figure 2 presents the adaptation of our model (first row) and the model presented in [29] (second row) to new observed data.",
      "startOffset" : 85,
      "endOffset" : 89
    }, {
      "referenceID" : 28,
      "context" : "On the contrary, the model of [29] is not able to capture the statistical relations of the new observations and fails to separate the data generated from distributions with mean values 16 and 21 (middle column).",
      "startOffset" : 30,
      "endOffset" : 34
    }, {
      "referenceID" : 6,
      "context" : "OSU datasets [7–9] are widely used for benchmarking algorithms for pedestrian detection and tracking in infrared imagery.",
      "startOffset" : 13,
      "endOffset" : 18
    }, {
      "referenceID" : 7,
      "context" : "OSU datasets [7–9] are widely used for benchmarking algorithms for pedestrian detection and tracking in infrared imagery.",
      "startOffset" : 13,
      "endOffset" : 18
    }, {
      "referenceID" : 8,
      "context" : "OSU datasets [7–9] are widely used for benchmarking algorithms for pedestrian detection and tracking in infrared imagery.",
      "startOffset" : 13,
      "endOffset" : 18
    }, {
      "referenceID" : 28,
      "context" : "We compared our method with the method presented by Zivkovic in [29] (MOG), which is one of the most robust and widely used background subtraction technique, and with the method for extracting the regions of interest presented in [8,9] (SBG) used for thermal data.",
      "startOffset" : 64,
      "endOffset" : 68
    }, {
      "referenceID" : 7,
      "context" : "We compared our method with the method presented by Zivkovic in [29] (MOG), which is one of the most robust and widely used background subtraction technique, and with the method for extracting the regions of interest presented in [8,9] (SBG) used for thermal data.",
      "startOffset" : 230,
      "endOffset" : 235
    }, {
      "referenceID" : 8,
      "context" : "We compared our method with the method presented by Zivkovic in [29] (MOG), which is one of the most robust and widely used background subtraction technique, and with the method for extracting the regions of interest presented in [8,9] (SBG) used for thermal data.",
      "startOffset" : 230,
      "endOffset" : 235
    } ],
    "year" : 2015,
    "abstractText" : "We propose a Gaussian mixture model for background subtraction in infrared imagery. Following a Bayesian approach, our method automatically estimates the number of Gaussian components as well as their parameters, while simultaneously it avoids over/under fitting. The equations for estimating model parameters are analytically derived and thus our method does not require any sampling algorithm that is computationally and memory inefficient. The pixel density estimate is followed by an efficient and highly accurate updating mechanism, which permits our system to be automatically adapted to dynamically changing operation conditions. Experimental results and comparisons with other methods show that our method outperforms, in terms of precision and recall, while at the same time it keeps computational cost suitable for real-time applications.",
    "creator" : "LaTeX with hyperref package"
  }
}