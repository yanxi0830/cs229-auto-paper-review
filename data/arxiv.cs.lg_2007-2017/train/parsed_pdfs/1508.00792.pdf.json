{
  "name" : "1508.00792.pdf",
  "metadata" : {
    "source" : "META",
    "title" : "Fixed-point algorithms for learning determinantal point processes",
    "authors" : [ "Zelda Mariet", "Suvrit Sra" ],
    "emails" : [ "ZELDA@CSAIL.MIT.EDU", "SUVRIT@MIT.EDU" ],
    "sections" : [ {
      "heading" : "1. Introduction",
      "text" : "Determinantal point processes (DPPs) arose in statistical mechanics, where they were originally used to model fermions (Macchi, 1975). Recently, they have witnessed substantial interest in a variety of machine learning applications (Kulesza, 2013; Kulesza and Taskar, 2012).\nOne of the key features of DPPs is their ability to model the notion of diversity while respecting quality, a concern that underlies the broader task of subset selection where balancing quality with diversity is a well-known issue—see e.g., document summarization (Lin and Bilmes, 2012), object retrieval (Affandi et al., 2014), recommender systems (Zhou et al., 2010), and sensor placement (Krause et al., 2008).\nDPPs are also interesting in their own right: they have various combinatorial, probabilistic, and analytic properties, while involving a fascinating set of open problems (Lyons, 2003; Hough et al., 2006; Kulesza, 2013).\nWithin machine learning DPPs have found good use—see\nProceedings of the 32nd International Conference on Machine Learning, Lille, France, 2015. JMLR: W&CP volume 37. Copyright 2015 by the author(s).\nfor instance (Gillenwater et al., 2014); (Kulesza and Taskar, 2011b); (Kulesza and Taskar, 2011a); (Affandi et al., 2014); (Affandi et al., 2103); (Affandi et al., 2013); (Gillenwater et al., 2012). For additional references and material we refer the reader to the survey (Kulesza and Taskar, 2012).\nOur paper is motivated by the recent work of Gillenwater et al. (2014), who made notable progress on the task of learning a DPP kernel from data. This task is conjectured to be NP-Hard (Kulesza, 2013, Conjecture 4.1). Gillenwater et al. (2014) presented a carefully designed EM-style procedure, which, unlike several previous approaches (e.g., (Kulesza and Taskar, 2011b;a; Affandi et al., 2014)) learns a full DPP kernel nonparameterically.\nOne main observation of Gillenwater et al. (2014) is that applying projected gradient ascent to the DPP log-likelihood usually results in degenerate estimates (because it involves projection onto the set {X : 0 X I}). Hence one may wonder if instead we could apply more sophisticated manifold optimization techniques (Absil et al., 2009; Boumal et al., 2014). While this idea is attractive, and indeed applicable, e.g., via the excellent MANOPT toolbox (Boumal et al., 2014), empirically it turns out to be computationally too demanding; the EM strategy of Gillenwater et al. (2014) is more practical.\nWe depart from both EM and manifold optimization to develop a new learning algorithm that (a) is simple, yet powerful; and (b) yields essentially the same log-likelihood values as the EM approach while running significantly faster. In particular, our algorithm runs an order of magnitude faster on larger problems.\nThe key innovation of our approach is a derivation via a fixed-point view, which by construction ensures positive definiteness at every iteration. Its convergence analysis involves an implicit bound-optimization iteration to ensure monotonic ascent.1 A pleasant byproduct of the fixed-point approach is that it avoids any eigenvalue/vector computations, enabling a further savings in running time.\n1The convergence analysis in this version of the paper improves upon our original submission, in that our proof is now constructive and requires weaker assumptions.\nar X\niv :1\n50 8.\n00 79\n2v 1\n[ cs\n.L G\n] 4\nA ug\n2 01\n5"
    }, {
      "heading" : "1.1. Background and problem setup",
      "text" : "Without loss of generality we assume that the ground set of N items is {1, 2, . . . , N}, which we denote by Y . A (discrete) DPP on Y is a probability measure P on 2Y (the set of all subsets of Y) such that for any Y ⊆ Y , the probability P(Y ) verifies P(Y ) ∝ det(LY ); here LY denotes the principal submatrix of the DPP kernel L induced by indices in Y . Intuitively, the diagonal entry Lii of the kernel matrix L captures some notion of the importance of item i, whereas an off-diagonal entry Lij = Lji measures similarity between items i and j. This intuitive notion provides further motivation for seeking DPPs with non-diagonal kernels when there is implicit interaction between the observed items.\nThe normalization constant for the measure P follows upon observing that ∑ Y⊆Y det(LY ) = det(L+ I). Thus,\nP(Y ) = det(LY ) det(L+ I) , Y ⊆ Y. (1.1)\nDPPs can also be given an alternative representation through a marginal kernel K that captures for a random Y ∼ P and every A ⊆ Y , the marginal probability\nP(A ⊆ Y ) = det(KA). (1.2)\nIt is easy to verify thatK = L(L+I)−1, which also implies that K and L have the same eigenvectors and differ only in their eigenvalues. It can also be shown (Kulesza, 2013) that P(Y ) = |det(K − IY c)|, where IY c is a partial N × N identity matrix with diagonal entries in Y zeroed out.\nBoth parameterizations (1.1) and (1.2) of the DPP probability are useful: Gillenwater et al. (2014) used a formulation in terms of K; we prefer (1.1) as it aligns better with our algorithmic approach."
    }, {
      "heading" : "1.2. Learning the DPP Kernel",
      "text" : "The learning task aims to fit a DPP kernel (either L or equivalently the marginal kernel K) consistent with a collection of observed subsets. Suppose we obtain as training data n subsets (Y1, . . . , Yn) of the ground setY . The task is to maximize the likelihood of these observations. Two equivalent formulations of this maximization task may be considered:\nmax L 0 ∑n i=1 log det(LYi)− n log det(I + L), (1.3)\nmax 0 K I ∑n i=1 log ( |det(K − IY ci )| ) . (1.4)\nWe will use formulation (1.3) in this paper. Gillenwater et al. (2014) used (1.4) and exploited its structure to derive a somewhat intricate EM-style method for optimizing it. Both (1.3) and (1.4) are nonconvex and difficult optimize.\nFor instance, using projected gradient on (1.4) may seem tempting, but projection ends up yielding degenerate (diagonal and rank-deficient) solutions which is undesirable when trying to capture interaction between observations—indeed, this criticism motivated Gillenwater et al. (2014) to derive the EM algorithm.\nWe approach problem (1.3) from a different viewpoint (which also avoids projection) and as a result obtain a new optimization algorithm for estimating L. This algorithm, its analysis, and empirical performance are the subject of the remainder of the paper."
    }, {
      "heading" : "2. Optimization algorithm",
      "text" : "The method that we derive has two key components: (i) a fixed-point view that helps obtain an iteration that satisfies the crucial positive definiteness constraint L 0 by construction; and (ii) an implicit bound optimization based analysis that ensures monotonic ascent. The resulting algorithm is vastly simpler than the previous EM-style approach of Gillenwater et al. (2014).\nIf |Y | = k, then for a suitable N × k indicator matrix U we can write LY = U∗LU , which is also known as a compression (U∗ denotes the Hermitian transpose). We write U∗i LUi interchangeably with LYi , implicitly assuming suitable indicator matrices Ui such that U∗i Ui = I|Yi|. To reduce clutter, we will drop the subscript on the identity matrix, its dimension being clear from context.\nDenote by φ(L) the objective function in (1.3). Assume for simplicity that the constraint set is open, i.e., L 0. Then any critical point of the log-likelihood must satisfy\n∇φ(L) = 0, or equivalently∑n i=1 Ui (U ∗ i LUi) −1 U∗i − n (I + L) −1 = 0. (2.1)\nAny (strictly) positive definite solution to the nonlinear matrix equation (2.1) is a candidate locally optimal solution.\nWe solve this matrix equation by developing a fixed-point iteration. In particular, define\n∆ := 1n ∑n i=1 Ui (U ∗ i LUi) −1 U∗i − (I + L)−1,\nwith which we may equivalently write (2.1) as\n∆ + L−1 = L−1. (2.2)\nEquation (2.2) suggests the following iteration\nL−1k+1 ← L −1 k + ∆k, k = 0, 1, . . . . (2.3)\nA priori there is no reason for iteration (2.3) to be valid (i.e., converge to a stationary point). But we write it in this form to highlight its crucial feature: starting from an initial L0 0, it generates positive definite iterates (Prop. 2.1).\nProposition 2.1. Let L0 0. Then, the sequence {Lk}k≥1 generated by (2.3) remains positive definite.\nProof. The proof is by induction. It suffices to show that\nL 0 =⇒ L−1 + ∆ 0.\nSince I + L L, from the order inversion property of the matrix inverse map it follows that L−1 (I + L)−1. Now adding the matrix 1n ∑ i=1 Ui (U ∗ i LUi) −1 U∗i 0 we obtain the desired inequality by definition of ∆.\nA quick experiment reveals that iteration (2.3) does not converge to a local maximizer of φ(L). To fix this defect, we rewrite the key equation (2.2) in a different manner:\nL = L+ L∆L. (2.4)\nThis equation is obtained by multiplying (2.2) on the left and right by L. Therefore, we now consider the iteration\nLk+1 ← Lk + Lk∆kLk, k = 0, 1, . . . . (2.5)\nProp. 2.1 in combination with the fact that congruence preserves positive definiteness (i.e., if X 0, then Z∗XZ 0 for any complex matrix Z), implies that if L0 0, then the sequence {Lk}k≥1 obtained from iteration (2.5) is also positive definite. What is more remarkable is that contrary to iteration (2.3), the sequence generated by (2.5) monotonically increases the log-likelihood.\nWhile monotonicity is not apparent from our intuitive derivation above, it becomes apparent once we recognize an implicit change of variables that seems to underlie our method."
    }, {
      "heading" : "2.1. Convergence Analysis",
      "text" : "Theorem 2.2. Let Lk be generated via (2.5). Then, the sequence {φ(Lk)}k≥0 is monotonically increasing.\nBefore proving Theorem 2.2 we need the following lemma.\nLemma 2.3. Let U ∈ CN×k (k ≤ N ) such that U∗U = I . The map g(S) := log det(U∗S−1U) is convex on the set of positive definite matrices.\nProof. Since g is continuous it suffices to establish midpoint convexity. Consider therefore, X,Y 0 and let\nX#Y = X1/2(X−1/2Y X−1/2)1/2X1/2\nbe their geometric mean. The operator inequality X#Y X+Y\n2 is well-known (Bhatia, 2007, Thm. 4.1.3). Hence,( X+Y\n2 )−1 (X#Y )−1 = X−1#Y −1 U∗ ( X+Y\n2 )−1 U U∗(X−1#Y −1)U (U∗X−1U)#(U∗Y −1U),\nwhere equality follows from (Bhatia, 2007, Thm. 4.1.3), and the final inequality follows from (Bhatia, 2007, Thm. 4.1.5)2 Since log det is monotonic on positive definite matrices and since det(A#B) = √ detA √ detB, it then follows that\nlog det ( U∗ ( X+Y\n2 )−1 U ) ≤ 12 log det(U ∗X−1U)\n+ 12 log det(U ∗Y −1U),\nwhich proves the lemma.\nNow we are ready to prove Theorem 2.2.\nProof (Thm. 2.2). The key insight is to consider S = L−1 instead of L; this change is only for the analysis—the actual iteration that we implement is still (2.5).3\nWriting ψ(S) := φ(L), we see that ψ(S) equals\n1 n ∑ i log det(U∗i S −1Ui)− log det(S−1 + I)\n= log det(S) + 1n ∑ i log det(U∗i S −1Ui)\n− log det(I + S). Let h(S) = 1n ∑ i log det(U ∗ i S −1Ui)−log det(I+S), and f(S) = log det(S). Clearly, f is concave in S, while h is convex is S; the latter from Lemma 2.3 and the fact that − log det(I + S) is convex. This observation allows us to invoke iterative bound-optimization (an idea that underlies EM, CCCP, and other related algorithms).\nIn particular, we construct an auxiliary function ξ so that\nψ(S) ≥ ξ(S,R), ∀S,R 0, ψ(S) = ξ(S, S), ∀S 0.\nAs in (Yuille and Rangarajan, 2003), we select ξ by exploiting the convexity of h: as h(S) ≥ h(R)+〈∇h(R), S −R〉, we simply set\nξ(S,R) := f(S) + h(R) + 〈∇h(R) |S −R〉 .\nGiven an iterate Sk, we then obtain Sk+1 by solving\nSk+1 := argmaxS 0 ξ(S, Sk), (2.6)\nwhich clearly ensures monotonicity: ψ(Sk+1) ≥ ψ(Sk).\nSince (2.6) has an open set as a constraint and ξ(S, ·) is strictly concave, to solve (2.6) it suffices to solve the necessary condition ∇Sξ(S, Sk) = 0. This amounts to\nS−1 = (I + Sk) −1 + 1n ∑ i S−1k Ui(U ∗ i S −1 k Ui) −1U∗i S −1 k .\nRewriting in terms of L we immediately see that with Lk+1 = Lk + Lk∆kLk, φ(Lk+1) ≥ φ(Lk) (the inequality is strict unless Lk+1 = Lk).\n2For an explicit proof see (Sra and Hosseini, 2015, Thm. 8). 3Our previous proof was based on viewing iteration (2.5) as a scaled-gradient-like iteration. However, we find the present version more transparent for proving monotonicity.\nTheorem 2.2 shows that iteration (2.5) is well-defined (positive definiteness was established by Prop. 2.1). The fixedpoint formulation (2.5) actually suggests a broader iteration, with an additional step-size a:\nLk+1 = Lk + aLk∆kLk. (2.7)\nAbove we showed that for a = 1 ascent is guaranteed. Empirically, a > 1 often works well; Prop. A.1 presents an easily computable upper bound on feasible a. We conjecture that for all feasible values a ≥ 1, iteration (2.5) is guaranteed to increase the log-likelihood.\nMoreover, all previous calculations can be redone in the context where L = F ∗WF for a fixed feature matrix F in order to learn the weight matrix W (under the assumption that S∗S is invertible), making our approach also useful in the context of feature-based DPP learning.\nPseudocode of our resulting learning method is presented in Algorithms 1 and 2. For simplicity, we recommend using a fixed value of a (which can be set at initialization).\nAlgorithm 1 Picard Iteration Input: Matrix L, training set T , step-size a > 0. for i = 1 to maxIter do L←− FixedPointMap(L, T , a) if stop(L, T , i) then\nbreak end if\nend for return L\nAlgorithm 2 FixedPointMap Input: Matrix L, training set T , step-size a > 0 Z ←− 0 for Y in T do ZY = ZY + L −1 Y\nend for return L+ aL(Z/|T | − (L+ I)−1)L"
    }, {
      "heading" : "2.2. Iteration cost and convergence speed",
      "text" : "The cost of each iteration of our algorithm is dominated by the computation of ∆, which costs a total ofO( ∑n i=1 |Yi|3+ N3) = O(nκ3 + N3) arithmetic operations, where κ = maxi |Yi|; the O(|Yi|3) cost comes from the time required to compute the inverse L−1Yi , while the N\n3 cost stems from computing (I + L)−1. Moreover, additional N3 costs arise when computing L∆L.\nIn comparison, each iteration of the method of Gillenwater et al. (2014) costs O(nNκ2 + N3), which is comparable to, though slightly greater than O(nκ3 +N3) as N ≥ κ. In applications where the sizes of the sampled subsets satisfy κ N , the difference can be more substantial. Moreover, we do not need any eigenvalue/vector computations to implement our algorithm.\nFinally, our iteration also runs slightly faster than the KAscent iteration, which costs O(nN3). Additionally, similarly to EM, our algorithm avoids the projection step necessary in the K-Ascent algorithm (which ensures K ∈ {X : 0 X I}). As shown in (Gillenwater et al., 2014), avoiding this step helps learn non-diagonal matrices.\nWe note in passing that similar to EM, assuming a nonsingular local maximum, we can also obtain a local linear rate of convergence. This follows by relating iteration (2.5) to scaled-gradient methods (Bertsekas, 1999, §1.3) (except that we have an implicit PSD constraint)."
    }, {
      "heading" : "3. Experimental results",
      "text" : "We compare performance of our algorithm, referred to as Picard iteration4, against the EM algorithm presented in Gillenwater et al. (2014). We experiment on both synthetic5 and real-world data.\nFor real-world data, we use the baby registry test on which results are reported in (Gillenwater et al., 2014). This dataset consists in 111, 006 sub-registries describing items across 13 different categories; this dataset was obtained by collecting baby registries from amazon.com, all containing between 5 and 100 products, and then splitting each registry into subregistries according to which of the 13 categories (such as “feeding”, “diapers”, “toys”, etc.) each product in the registry belongs to. (Gillenwater et al., 2014) provides a more in-depth description of this dataset.\nThese sub-registries are used to learn a DPP capable of providing recommendations for these products: indeed, a DPP is well-suited for this task as it provides sets of products in a category that are popular yet diverse enough to all be of interest to a potential customer."
    }, {
      "heading" : "3.1. Implementation details",
      "text" : "We measure convergence by testing the relative change |φ(Lk+1)−φ(Lk)|\n|φ(Lk)| ≤ ε. We used a tighter convergence criterion for our algorithm (εpic = 0.5·εem) to account for the fact that the distance between two subsequent log-likelihoods tends to be smaller for the Picard iteration than for EM.\nThe parameter a for Picard was set at the beginning of each experiment and never modified as it remained valid throughout each test6. In EM, the step size was initially\n4Our nomenclature stems from the usual name for such iterations in fixed-point theory (Granas and Dugundji, 2003).\n5The figures and tables for the synthetic results have been modified to include some minor corrections: in particular, Tables 1 and 2 now show the runtime to 99%. The runtimes were initially to final convergence, but erroneously reported to be to 95%.\n6Although it was not necessary in our experiments, if the parameter a becomes invalid, it can be halved until it reaches 1.\nset to 1 and halved when necessary, as per the algorithm described in (Gillenwater et al., 2014); we used the code of Gillenwater et al. (2014) for our EM implementation7."
    }, {
      "heading" : "3.2. Synthetic tests",
      "text" : "In each experiment, we sample n training sets from a base DPP of size N , then learn the DPP using EM and the Picard iteration. We initialize the learning process with a random positive definite matrix L0 (or K0 for EM) drawn from the same distribution as the true DPP kernel.\nSpecifically, we used two matrix distributions to draw the true kernel and the initial matrix values from:\n• BASIC: We draw the coefficients of a matrix M from the uniform distribution over [ 0, √ 2 ] , then return L =\nMM> conditioned on its positive definiteness.\n• WISHART: We draw L from a Wishart distribution with N degrees of freedom and an identity covariance matrix, and rescale it with a factor 1N .\nFigures 1, 2 and 3 show the log-likelihood as a function of time for different parameter values when both the true DPP kernel and the initial matrixL0 were drawn from the BASIC distribution. Tables 1 and 2 show the final log-likelihood and the time necessary for each method to reach 99% of the optimal log likelihood for both distributions and parameters n = 5000, a = 5.\nAs shown in Figure 1, the difference in time necessary for both methods to reach a good approximation of the final likelihood (as defined by best final likelihood) grows drastically as the size N of the set of all elements {1, 2, . . . , N} increases. Figure 2 illustrates the same phenomenon when N is kept constant and n increases.\nFinally, the influence of the parameter a on convergence speed is illustrated in Figure 38. Increasing a noticeably increases Picard’s convergence speed, as long as the matrices remain positive definite during the Picard iteration.\nThe greatest strength of the Picard iteration lies in its initial rapid convergence: the log-likelihood increases significantly faster for the Picard iteration than for EM. Although for small datasets EM sometimes performs better, our algorithm provides substantially better results in shorter timeframes when dealing with larger datasets.\nOverall, our algorithm converges to 99% of the optimal loglikelihood (defined as the maximum of the log-likelihoods returned by each algorithm) significantly faster than the EM\n7These experiments were run with MATLAB, on a Linux Mint system, using 16GB of RAM and an i7-4710HQ CPU @ 2.50GHz.\n8In the cases where a > 1, a safeguard was added to check that the matrices returned by our algorithm were positive definite.\nalgorithm for both distributions, particularly when dealing with large values of N .\nThus, the Picard iteration is preferable when dealing with large ground sets; it is also very well-suited to cases where larger amounts of training data are available."
    }, {
      "heading" : "3.3. Baby registries experiment",
      "text" : "We tested our implementation on all 13 product categories in the baby registry dataset, using two different initializations: • the aforementioned Wishart distribution • the data-dependent moment matching initialization\n(MM) described in (Gillenwater et al., 2014)\nIn each case, 70% of the baby registries in the product category were used for training; 30% served as test. The results presented in Figures 4 and 5 are averaged over 5 learning trials, each with different initial matrices; the parameter a was set equal to 1.3 for all iterations.\nSimilarly to its behavior on synthetic datasets, the Picard iteration provides overall significantly shorter runtimes when dealing with large matrices and training sets. As shown in Table 3, the final log-likelihoods are very close (on the order 10−2 to 10−4) to those attained by the EM algorithm.\nUsing a moments-matching initialization leaves Picard’s runtimes overall unchanged (a notable exception being the ‘gear’ category). However, EM’s runtime decreases drastically with this initialization, although it remains significantly longer than Picard’s in most categories.\nThe final log-likelihoods are also closer when using moments-matching initialization (see Table 3)."
    }, {
      "heading" : "4. Conclusions and future work",
      "text" : "We approached the problem of maximum-likelihood estimation of a DPP kernel from a different angle: we analyzed the stationarity properties of the cost function and used them\nto obtain a novel fixed-point Picard iteration. Experiments on both simulated and real data showed that for a range of ground set sizes and number of samples, our Picard iteration runs remarkably faster that the previous best approach, while being extremely simple to implement. In particular, for large ground set sizes our experiments show that our algorithm cuts down runtime to a fraction of the previously optimal EM runtimes.\nWe presented a theoretical analysis of the convergence properties of the Picard iteration, and found sufficient conditions for its convergence. However, our experiments reveal that the Picard iteration converges for a wider range of stepsizes (parameter a in the iteration and plots) than currently accessible to our theoretical analysis. It is a part of our future work to develop more complete convergence theory, especially because of its strong empirical performance.\nIn light of our results, another line of future work is to apply fixed-point analysis to other DPP learning tasks."
    }, {
      "heading" : "ACKNOWLEDGMENTS",
      "text" : "Suvrit Sra is partly supported by NSF grant: IIS-1409802."
    }, {
      "heading" : "A. Bound on a",
      "text" : "Proposition A.1. Let L, Ui, and ∆ be as defined above; set Z = 1n ∑ i Ui (U ∗ i LUi) −1 U∗i . Define the constant\nγ := max{λmin(LZ), 1/λmax(I + L)}. (A.1)\nThen, 0 ≤ γ ≤ 1 and for a ≤ (1− γ)−1 the update\nL′ ← L+ aL∆L\nensures that L′ is also positive definite.\nProof. Let Z = 1n ∑n i=1 Ui (U ∗ i LUi) −1 U∗i .\nTo ensure L+ aL∆L 0 we equivalently show\nL−1 + a (\n1 n n∑ i=1 Ui (U ∗ i LUi) −1 U∗i − (L+ I) −1 ) 0\n=⇒ I + aL1/2ZL1/2 aL (L+ I)−1\n=⇒ (1− a)I + a(I + L)−1 + aL1/2ZL1/2 0 (as L(L+ I)−1 = I − (I + L)−1)\n=⇒ (1− a) + aλmin((I + L)−1 + L1/2ZL1/2) > 0.\nThis inequality can be numerically optimized to find the largest feasible value of a. The simpler bound in question can be obtained by noting that\nλmin((I + L) −1 + L1/2ZL1/2)\n≥ max{λmin(LZ), 1/λmax(I + L)} = γ.\nThus, we have the easily computable bound for feasible a:\na ≤ 1 1− γ .\nClearly, by construction γ ≥ 0. To see why γ ≤ 1, observe that (I + L) ≺ I , so that λmin((I + L)−1) < 1. Further, block-matrix calculations show that Z L−1, whereby λmin(L 1/2ZL1/2) ≤ λmin(I) = 1."
    } ],
    "references" : [ {
      "title" : "Optimization algorithms on matrix manifolds",
      "author" : [ "P.-A. Absil", "R. Mahony", "R. Sepulchre" ],
      "venue" : null,
      "citeRegEx" : "Absil et al\\.,? \\Q2009\\E",
      "shortCiteRegEx" : "Absil et al\\.",
      "year" : 2009
    }, {
      "title" : "Nyström approximation for large-scale Determinantal Point Processes",
      "author" : [ "R. Affandi", "A. Kulesza", "E. Fox", "B. Taskar" ],
      "venue" : "In Artificial Intelligence and Statistics (AISTATS),",
      "citeRegEx" : "Affandi et al\\.,? \\Q2013\\E",
      "shortCiteRegEx" : "Affandi et al\\.",
      "year" : 2013
    }, {
      "title" : "Learning the parameters of Determinantal Point Process kernels",
      "author" : [ "R. Affandi", "E. Fox", "R. Adams", "B. Taskar" ],
      "venue" : "In International Conference on Machine Learning,",
      "citeRegEx" : "Affandi et al\\.,? \\Q2014\\E",
      "shortCiteRegEx" : "Affandi et al\\.",
      "year" : 2014
    }, {
      "title" : "Nonlinear Programming",
      "author" : [ "D.P. Bertsekas" ],
      "venue" : "Athena Scientific, second edition,",
      "citeRegEx" : "Bertsekas.,? \\Q1999\\E",
      "shortCiteRegEx" : "Bertsekas.",
      "year" : 1999
    }, {
      "title" : "Positive Definite Matrices",
      "author" : [ "R. Bhatia" ],
      "venue" : null,
      "citeRegEx" : "Bhatia.,? \\Q2007\\E",
      "shortCiteRegEx" : "Bhatia.",
      "year" : 2007
    }, {
      "title" : "Manopt, a Matlab toolbox for optimization on manifolds",
      "author" : [ "N. Boumal", "B. Mishra", "P.-A. Absil", "R. Sepulchre" ],
      "venue" : "Journal of Machine Learning Research,",
      "citeRegEx" : "Boumal et al\\.,? \\Q2014\\E",
      "shortCiteRegEx" : "Boumal et al\\.",
      "year" : 2014
    }, {
      "title" : "Near-optimal MAP inference for Determinantal Point Processes",
      "author" : [ "J. Gillenwater", "A. Kulesza", "B. Taskar" ],
      "venue" : "In Advances in Neural Information Processing Systems (NIPS),",
      "citeRegEx" : "Gillenwater et al\\.,? \\Q2012\\E",
      "shortCiteRegEx" : "Gillenwater et al\\.",
      "year" : 2012
    }, {
      "title" : "Expectation-Maximization for learning Determinantal Point Processes",
      "author" : [ "J. Gillenwater", "A. Kulesza", "E. Fox", "B. Taskar" ],
      "venue" : "In Advances in Neural Information Processing Systems (NIPS),",
      "citeRegEx" : "Gillenwater et al\\.,? \\Q2014\\E",
      "shortCiteRegEx" : "Gillenwater et al\\.",
      "year" : 2014
    }, {
      "title" : "Determinantal processes and independence",
      "author" : [ "J.B. Hough", "M. Krishnapur", "Y. Peres", "B. Virág" ],
      "venue" : "Probability Surveys,",
      "citeRegEx" : "Hough et al\\.,? \\Q2006\\E",
      "shortCiteRegEx" : "Hough et al\\.",
      "year" : 2006
    }, {
      "title" : "Near-optimal sensor placements in Gaussian processes: theory, efficient algorithms and empirical studies",
      "author" : [ "A. Krause", "A. Singh", "C. Guestrin" ],
      "venue" : "Journal of Machine Learning Research (JMLR),",
      "citeRegEx" : "Krause et al\\.,? \\Q2008\\E",
      "shortCiteRegEx" : "Krause et al\\.",
      "year" : 2008
    }, {
      "title" : "Learning with Determinantal Point Processes",
      "author" : [ "A. Kulesza" ],
      "venue" : "PhD thesis, University of Pennsylvania,",
      "citeRegEx" : "Kulesza.,? \\Q2013\\E",
      "shortCiteRegEx" : "Kulesza.",
      "year" : 2013
    }, {
      "title" : "k-DPPs: Fixed-size Determinantal Point Processes",
      "author" : [ "A. Kulesza", "B. Taskar" ],
      "venue" : "In International Conference on Maachine Learning (ICML),",
      "citeRegEx" : "Kulesza and Taskar.,? \\Q2011\\E",
      "shortCiteRegEx" : "Kulesza and Taskar.",
      "year" : 2011
    }, {
      "title" : "Learning Determinantal Point Processes",
      "author" : [ "A. Kulesza", "B. Taskar" ],
      "venue" : "In Uncertainty in Artificial Intelligence (UAI),",
      "citeRegEx" : "Kulesza and Taskar.,? \\Q2011\\E",
      "shortCiteRegEx" : "Kulesza and Taskar.",
      "year" : 2011
    }, {
      "title" : "Determinantal Point Processes for machine learning, volume 5",
      "author" : [ "A. Kulesza", "B. Taskar" ],
      "venue" : "Foundations and Trends in Machine Learning,",
      "citeRegEx" : "Kulesza and Taskar.,? \\Q2012\\E",
      "shortCiteRegEx" : "Kulesza and Taskar.",
      "year" : 2012
    }, {
      "title" : "Learning mixtures of submodular shells with application to document summarization",
      "author" : [ "H. Lin", "J. Bilmes" ],
      "venue" : "In Uncertainty in Artificial Intelligence (UAI),",
      "citeRegEx" : "Lin and Bilmes.,? \\Q2012\\E",
      "shortCiteRegEx" : "Lin and Bilmes.",
      "year" : 2012
    }, {
      "title" : "Determinantal probability measures",
      "author" : [ "R. Lyons" ],
      "venue" : "Publications Mathématiques de l’Institut des Hautes Études Scientifiques,",
      "citeRegEx" : "Lyons.,? \\Q2003\\E",
      "shortCiteRegEx" : "Lyons.",
      "year" : 2003
    }, {
      "title" : "The coincidence approach to stochastic point processes",
      "author" : [ "O. Macchi" ],
      "venue" : "Advances in Applied Probability,",
      "citeRegEx" : "Macchi.,? \\Q1975\\E",
      "shortCiteRegEx" : "Macchi.",
      "year" : 1975
    }, {
      "title" : "Conic geometric optimization on the manifold of positive definite matrices",
      "author" : [ "S. Sra", "R. Hosseini" ],
      "venue" : "SIAM Journal on Optimization,",
      "citeRegEx" : "Sra and Hosseini.,? \\Q2015\\E",
      "shortCiteRegEx" : "Sra and Hosseini.",
      "year" : 2015
    }, {
      "title" : "The concave-convex procedure",
      "author" : [ "A.L. Yuille", "A. Rangarajan" ],
      "venue" : "Neural Comput.,",
      "citeRegEx" : "Yuille and Rangarajan.,? \\Q2003\\E",
      "shortCiteRegEx" : "Yuille and Rangarajan.",
      "year" : 2003
    }, {
      "title" : "Solving the apparent diversity-accuracy dilemma of recommender systems",
      "author" : [ "T. Zhou", "Z. Kuscsik", "J.-G. Liu", "M. Medo", "J.R. Wakeling", "Y.-C. Zhang" ],
      "venue" : "Proceedings of the National Academy of Sciences,",
      "citeRegEx" : "Zhou et al\\.,? \\Q2010\\E",
      "shortCiteRegEx" : "Zhou et al\\.",
      "year" : 2010
    } ],
    "referenceMentions" : [ {
      "referenceID" : 16,
      "context" : "Determinantal point processes (DPPs) arose in statistical mechanics, where they were originally used to model fermions (Macchi, 1975).",
      "startOffset" : 119,
      "endOffset" : 133
    }, {
      "referenceID" : 10,
      "context" : "Recently, they have witnessed substantial interest in a variety of machine learning applications (Kulesza, 2013; Kulesza and Taskar, 2012).",
      "startOffset" : 97,
      "endOffset" : 138
    }, {
      "referenceID" : 13,
      "context" : "Recently, they have witnessed substantial interest in a variety of machine learning applications (Kulesza, 2013; Kulesza and Taskar, 2012).",
      "startOffset" : 97,
      "endOffset" : 138
    }, {
      "referenceID" : 14,
      "context" : ", document summarization (Lin and Bilmes, 2012), object retrieval (Affandi et al.",
      "startOffset" : 25,
      "endOffset" : 47
    }, {
      "referenceID" : 2,
      "context" : ", document summarization (Lin and Bilmes, 2012), object retrieval (Affandi et al., 2014), recommender systems (Zhou et al.",
      "startOffset" : 66,
      "endOffset" : 88
    }, {
      "referenceID" : 19,
      "context" : ", 2014), recommender systems (Zhou et al., 2010), and sensor placement (Krause et al.",
      "startOffset" : 29,
      "endOffset" : 48
    }, {
      "referenceID" : 9,
      "context" : ", 2010), and sensor placement (Krause et al., 2008).",
      "startOffset" : 30,
      "endOffset" : 51
    }, {
      "referenceID" : 15,
      "context" : "DPPs are also interesting in their own right: they have various combinatorial, probabilistic, and analytic properties, while involving a fascinating set of open problems (Lyons, 2003; Hough et al., 2006; Kulesza, 2013).",
      "startOffset" : 170,
      "endOffset" : 218
    }, {
      "referenceID" : 8,
      "context" : "DPPs are also interesting in their own right: they have various combinatorial, probabilistic, and analytic properties, while involving a fascinating set of open problems (Lyons, 2003; Hough et al., 2006; Kulesza, 2013).",
      "startOffset" : 170,
      "endOffset" : 218
    }, {
      "referenceID" : 10,
      "context" : "DPPs are also interesting in their own right: they have various combinatorial, probabilistic, and analytic properties, while involving a fascinating set of open problems (Lyons, 2003; Hough et al., 2006; Kulesza, 2013).",
      "startOffset" : 170,
      "endOffset" : 218
    }, {
      "referenceID" : 7,
      "context" : "for instance (Gillenwater et al., 2014); (Kulesza and Taskar, 2011b); (Kulesza and Taskar, 2011a); (Affandi et al.",
      "startOffset" : 13,
      "endOffset" : 39
    }, {
      "referenceID" : 2,
      "context" : ", 2014); (Kulesza and Taskar, 2011b); (Kulesza and Taskar, 2011a); (Affandi et al., 2014); (Affandi et al.",
      "startOffset" : 67,
      "endOffset" : 89
    }, {
      "referenceID" : 1,
      "context" : ", 2103); (Affandi et al., 2013); (Gillenwater et al.",
      "startOffset" : 9,
      "endOffset" : 31
    }, {
      "referenceID" : 6,
      "context" : ", 2013); (Gillenwater et al., 2012).",
      "startOffset" : 9,
      "endOffset" : 35
    }, {
      "referenceID" : 13,
      "context" : "For additional references and material we refer the reader to the survey (Kulesza and Taskar, 2012).",
      "startOffset" : 73,
      "endOffset" : 99
    }, {
      "referenceID" : 2,
      "context" : ", (Kulesza and Taskar, 2011b;a; Affandi et al., 2014)) learns a full DPP kernel nonparameterically.",
      "startOffset" : 2,
      "endOffset" : 53
    }, {
      "referenceID" : 0,
      "context" : "Hence one may wonder if instead we could apply more sophisticated manifold optimization techniques (Absil et al., 2009; Boumal et al., 2014).",
      "startOffset" : 99,
      "endOffset" : 140
    }, {
      "referenceID" : 5,
      "context" : "Hence one may wonder if instead we could apply more sophisticated manifold optimization techniques (Absil et al., 2009; Boumal et al., 2014).",
      "startOffset" : 99,
      "endOffset" : 140
    }, {
      "referenceID" : 5,
      "context" : ", via the excellent MANOPT toolbox (Boumal et al., 2014), empirically it turns out to be computationally too demanding; the EM strategy of Gillenwater et al.",
      "startOffset" : 35,
      "endOffset" : 56
    }, {
      "referenceID" : 0,
      "context" : ", 2014); (Kulesza and Taskar, 2011b); (Kulesza and Taskar, 2011a); (Affandi et al., 2014); (Affandi et al., 2103); (Affandi et al., 2013); (Gillenwater et al., 2012). For additional references and material we refer the reader to the survey (Kulesza and Taskar, 2012). Our paper is motivated by the recent work of Gillenwater et al. (2014), who made notable progress on the task of learning a DPP kernel from data.",
      "startOffset" : 68,
      "endOffset" : 339
    }, {
      "referenceID" : 0,
      "context" : ", 2014); (Kulesza and Taskar, 2011b); (Kulesza and Taskar, 2011a); (Affandi et al., 2014); (Affandi et al., 2103); (Affandi et al., 2013); (Gillenwater et al., 2012). For additional references and material we refer the reader to the survey (Kulesza and Taskar, 2012). Our paper is motivated by the recent work of Gillenwater et al. (2014), who made notable progress on the task of learning a DPP kernel from data. This task is conjectured to be NP-Hard (Kulesza, 2013, Conjecture 4.1). Gillenwater et al. (2014) presented a carefully designed EM-style procedure, which, unlike several previous approaches (e.",
      "startOffset" : 68,
      "endOffset" : 512
    }, {
      "referenceID" : 0,
      "context" : ", 2014); (Kulesza and Taskar, 2011b); (Kulesza and Taskar, 2011a); (Affandi et al., 2014); (Affandi et al., 2103); (Affandi et al., 2013); (Gillenwater et al., 2012). For additional references and material we refer the reader to the survey (Kulesza and Taskar, 2012). Our paper is motivated by the recent work of Gillenwater et al. (2014), who made notable progress on the task of learning a DPP kernel from data. This task is conjectured to be NP-Hard (Kulesza, 2013, Conjecture 4.1). Gillenwater et al. (2014) presented a carefully designed EM-style procedure, which, unlike several previous approaches (e.g., (Kulesza and Taskar, 2011b;a; Affandi et al., 2014)) learns a full DPP kernel nonparameterically. One main observation of Gillenwater et al. (2014) is that applying projected gradient ascent to the DPP log-likelihood usually results in degenerate estimates (because it involves projection onto the set {X : 0 X I}).",
      "startOffset" : 68,
      "endOffset" : 760
    }, {
      "referenceID" : 0,
      "context" : "Hence one may wonder if instead we could apply more sophisticated manifold optimization techniques (Absil et al., 2009; Boumal et al., 2014). While this idea is attractive, and indeed applicable, e.g., via the excellent MANOPT toolbox (Boumal et al., 2014), empirically it turns out to be computationally too demanding; the EM strategy of Gillenwater et al. (2014) is more practical.",
      "startOffset" : 100,
      "endOffset" : 365
    }, {
      "referenceID" : 10,
      "context" : "It can also be shown (Kulesza, 2013) that P(Y ) = |det(K − IY c)|, where IY c is a partial N × N identity matrix with diagonal entries in Y zeroed out.",
      "startOffset" : 21,
      "endOffset" : 36
    }, {
      "referenceID" : 6,
      "context" : "2) of the DPP probability are useful: Gillenwater et al. (2014) used a formulation in terms of K; we prefer (1.",
      "startOffset" : 38,
      "endOffset" : 64
    }, {
      "referenceID" : 6,
      "context" : "Gillenwater et al. (2014) used (1.",
      "startOffset" : 0,
      "endOffset" : 26
    }, {
      "referenceID" : 6,
      "context" : "Gillenwater et al. (2014) used (1.4) and exploited its structure to derive a somewhat intricate EM-style method for optimizing it. Both (1.3) and (1.4) are nonconvex and difficult optimize. For instance, using projected gradient on (1.4) may seem tempting, but projection ends up yielding degenerate (diagonal and rank-deficient) solutions which is undesirable when trying to capture interaction between observations—indeed, this criticism motivated Gillenwater et al. (2014) to derive the EM algorithm.",
      "startOffset" : 0,
      "endOffset" : 476
    }, {
      "referenceID" : 6,
      "context" : "The resulting algorithm is vastly simpler than the previous EM-style approach of Gillenwater et al. (2014). If |Y | = k, then for a suitable N × k indicator matrix U we can write LY = U∗LU , which is also known as a compression (U∗ denotes the Hermitian transpose).",
      "startOffset" : 81,
      "endOffset" : 107
    }, {
      "referenceID" : 18,
      "context" : "As in (Yuille and Rangarajan, 2003), we select ξ by exploiting the convexity of h: as h(S) ≥ h(R)+〈∇h(R), S −R〉, we simply set ξ(S,R) := f(S) + h(R) + 〈∇h(R) |S −R〉 .",
      "startOffset" : 6,
      "endOffset" : 35
    }, {
      "referenceID" : 7,
      "context" : "As shown in (Gillenwater et al., 2014), avoiding this step helps learn non-diagonal matrices.",
      "startOffset" : 12,
      "endOffset" : 38
    }, {
      "referenceID" : 5,
      "context" : "In comparison, each iteration of the method of Gillenwater et al. (2014) costs O(nNκ + N), which is comparable to, though slightly greater than O(nκ +N) as N ≥ κ.",
      "startOffset" : 47,
      "endOffset" : 73
    }, {
      "referenceID" : 7,
      "context" : "For real-world data, we use the baby registry test on which results are reported in (Gillenwater et al., 2014).",
      "startOffset" : 84,
      "endOffset" : 110
    }, {
      "referenceID" : 7,
      "context" : "(Gillenwater et al., 2014) provides a more in-depth description of this dataset.",
      "startOffset" : 0,
      "endOffset" : 26
    }, {
      "referenceID" : 6,
      "context" : "We compare performance of our algorithm, referred to as Picard iteration4, against the EM algorithm presented in Gillenwater et al. (2014). We experiment on both synthetic5 and real-world data.",
      "startOffset" : 113,
      "endOffset" : 139
    }, {
      "referenceID" : 7,
      "context" : "set to 1 and halved when necessary, as per the algorithm described in (Gillenwater et al., 2014); we used the code of Gillenwater et al.",
      "startOffset" : 70,
      "endOffset" : 96
    }, {
      "referenceID" : 6,
      "context" : "set to 1 and halved when necessary, as per the algorithm described in (Gillenwater et al., 2014); we used the code of Gillenwater et al. (2014) for our EM implementation7.",
      "startOffset" : 71,
      "endOffset" : 144
    }, {
      "referenceID" : 7,
      "context" : "We tested our implementation on all 13 product categories in the baby registry dataset, using two different initializations: • the aforementioned Wishart distribution • the data-dependent moment matching initialization (MM) described in (Gillenwater et al., 2014)",
      "startOffset" : 237,
      "endOffset" : 263
    } ],
    "year" : 2017,
    "abstractText" : "Determinantal point processes (DPPs) offer an elegant tool for encoding probabilities over subsets of a ground set. Discrete DPPs are parametrized by a positive semidefinite matrix (called the DPP kernel), and estimating this kernel is key to learning DPPs from observed data. We consider the task of learning the DPP kernel, and develop for it a surprisingly simple yet effective new algorithm. Our algorithm offers the following benefits over previous approaches: (a) it is much simpler; (b) it yields equally good and sometimes even better local maxima; and (c) it runs an order of magnitude faster on large problems. We present experimental results on both real and simulated data to illustrate the numerical performance of our technique.",
    "creator" : "LaTeX with hyperref package"
  }
}