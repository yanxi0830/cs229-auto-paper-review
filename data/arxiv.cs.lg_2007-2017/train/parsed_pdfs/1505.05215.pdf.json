{
  "name" : "1505.05215.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "Learning with a Drifting Target Concept",
    "authors" : [ "Steve Hanneke", "Varun Kanade" ],
    "emails" : [ "steve.hanneke@gmail.com", "varun.kanade@ens.fr", "yangli@us.ibm.com" ],
    "sections" : [ {
      "heading" : null,
      "text" : "ar X\niv :1\n50 5.\n05 21\n5v 1\n[ cs\n.L G\n] 2\n0 M"
    }, {
      "heading" : "1 Introduction",
      "text" : "Much of the work on statistical learning has focused on learning settings in which the concept to be learned is static over time. However, there are many application areas where this is not the case. For instance, in the problem of face recognition, the concept to be learned actually changes over time as each individual’s facial features evolve over time. In this work, we study the problem of learning with a drifting target concept. Specifically, we consider a statistical learning setting, in which data arrive i.i.d. in a stream, and for each data point, the learner is required to predict a label for the data point at that time. We are then interested in obtaining low error rates for these predictions. The target labels are generated from a function known to reside in a given concept space, and at each time t the target function is allowed to change by at most some distance ∆t: that is, the probability the new target function disagrees with the previous target function on a random sample is at most ∆t.\nThis framework has previously been studied in a number of articles. The classic works of [HL91,HL94,BH96,Lon99,BBDK00] and [BL97] together provide a general analysis of a very-much related setting. Though the objectives in these works are specified slightly differently, the results established there are easily translated into our present framework, and we summarize many of the relevant results from this literature in Section 3.\nWhile the results in these classic works are general, the best guarantees on the error rates are only known for methods having no guarantees of computational efficiency. In a more recent effort, the work of [CMEDV10] studies this problem in the specific context of learning a homogeneous linear separator, when all the ∆t values are identical. They propose a polynomial-time algorithm (based on the modified Perceptron algorithm of [DKM09]), and prove a bound on the number of mistakes it makes as a function of the number of samples, when the data distribution satisfies a certain condition called “λ-good” (which generalizes a useful property of the uniform distribution on the origin-centered unit sphere). However, their result is again worse than that obtainable by the known computationally-inefficient methods.\nThus, the natural question is whether there exists a polynomial-time algorithm achieving roughly the same guarantees on the error rates known for the inefficient methods. In the present work, we resolve this question in the case of learning homogeneous linear separators under the uniform distribution, by proposing a polynomial-time algorithm that indeed achieves roughly the same bounds on the error rates known for the inefficient methods in the literature. This represents the main technical contribution of this work.\nWe also study the interesting problem of adaptivity of an algorithm to the sequence of ∆t values, in the setting where ∆t may itself vary over time. Since the values ∆t might typically not be accessible in practice, it seems important to have learning methods having no explicit dependence on the sequence ∆t. We propose such a method below, and prove that it achieves roughly the same bounds on the error rates known for methods in the literature which require direct access to the ∆t values. Also in the context of variable ∆t sequences, we discuss conditions on the sequence ∆t necessary and sufficient for there to exist a learning method guaranteeing a sublinear rate of growth of the number of mistakes.\nWe additionally study an active learning extension to this framework, in which, at each time, after making its prediction, the algorithm may decide whether or not to request access to the label assigned to the data point at that time. In addition to guarantees on the error rates (for all times, including those for which the label was not observed), we are also interested in bounding the number of labels we expect the algorithm to request, as a function of the number of samples encountered thus far."
    }, {
      "heading" : "2 Definitions and Notation",
      "text" : "Formally, in this setting, there is a fixed distribution P over the instance space X , and there is a sequence of independent P-distributed unlabeled data X1, X2, . . .. There is also a concept space C, and a sequence of target functions h∗ = {h∗1, h∗2, . . .} in C. Each t has an associated target label Yt = h∗t (Xt). In this context, a (passive) learning algorithm is required, on each round t, to pro-\nduce a classifier ĥt based on the observations (X1, Y1), . . . , (Xt−1, Yt−1), and we denote by Ŷt = ĥt(Xt) the corresponding prediction by the algorithm for\nthe label of Xt. For any classifier h, we define ert(h) = P(x : h(x) 6= h∗t (x)). We also say the algorithm makes a “mistake” on instance Xt if Ŷt 6= Yt; thus, ert(ĥt) = P(Ŷt 6= Yt|(X1, Y1), . . . , (Xt−1, Yt−1)).\nFor notational convenience, we will suppose the h∗t sequence is chosen independently from the Xt sequence (i.e., h ∗ t is chosen prior to the “draw” of X1, X2, . . . ∼ P), and is not random. In each of our results, we will suppose h∗ is chosen from some set S of sequences in C. In particular, we are interested in describing the sequence h∗ in terms of the magnitudes of changes in h∗t from one time to the next. Specifically, for any sequence ∆ = {∆t}∞t=2 in [0, 1], we denote by S∆ the set of all sequences h∗ in C such that, ∀t ∈ N, P(x : ht(x) 6= ht+1(x)) ≤ ∆t+1.\nThroughout this article, we denote by d the VC dimension of C [VC71], and we suppose C is such that 1 ≤ d < ∞. Also, for any x ∈ R, define Log(x) = ln(max{x, e}).\n3 Background: (ǫ, S)-Tracking Algorithms\nAs mentioned, the classic literature on learning with a drifting target concept is expressed in terms of a slightly different model. In order to relate those results to our present setting, we first introduce the classic setting. Specifically, we consider a model introduced by [HL94], presented here in a more-general form inspired by [BBDK00]. For a set S of sequences {ht}∞t=1 in C, and a value ǫ > 0, an algorithm A is said to be (ǫ, S)-tracking if ∃tǫ ∈ N such that, for any choice of h∗ ∈ S, ∀T ≥ tǫ, the prediction ŶT produced by A at time T satisfies\nP\n( ŶT 6= YT ) ≤ ǫ.\nNote that the value of the probability in the above expression may be influenced by {Xt}Tt=1, {h∗t }Tt=1, and any internal randomness of the algorithm A.\nThe focus of the results expressed in this classical model is determining sufficient conditions on the set S for there to exist an (ǫ, S)-tracking algorithm, along with bounds on the sufficient size of tǫ. These conditions on S typically take the form of an assumption on the drift rate, expressed in terms of ǫ. Below, we summarize several of the strongest known results for this setting."
    }, {
      "heading" : "3.1 Bounded Drift Rate",
      "text" : "The simplest, and perhaps most elegant, results for (ǫ, S)-tracking algorithms is for the set S of sequences with a bounded drift rate. Specifically, for any ∆ ∈ [0, 1], define S∆ = S∆, where ∆ is such that ∆t+1 = ∆ for every t ∈ N. The study of this problem was initiated in the original work of [HL94]. The best known general results are due to [Lon99]: namely, that for some ∆ǫ = Θ(ǫ2/d), for every ǫ ∈ (0, 1], there exists an (ǫ, S∆)-tracking algorithm for all values of ∆ ≤ ∆ǫ.4 This refined an earlier result of [HL94] by a logarithmic 4 In fact, [Lon99] also allowed the distribution P to vary gradually over time. For simplicity, we will only discuss the case of fixed P .\nfactor. [Lon99] further argued that this result can be achieved with tǫ = Θ(d/ǫ). The algorithm itself involves a beautiful modification of the one-inclusion graph prediction strategy of [HLW94]; since its specification is somewhat involved, we refer the interested reader to the original work of [Lon99] for the details."
    }, {
      "heading" : "3.2 Varying Drift Rate: Nonadaptive Algorithm",
      "text" : "In addition to the concrete bounds for the case h∗ ∈ S∆, [HL94] additionally present an elegant general result. Specifically, they argue that, for any ǫ > 0, and any m = Ω (\nd ǫLog 1 ǫ\n) , if ∑m i=1 P(x : h∗i (x) 6= h∗m+1(x)) ≤ mǫ/24, then for ĥ = argminh∈C ∑m i=1 1[h(Xi) 6= Yi], P(ĥ(Xm+1) 6= h∗m+1(Xm+1)) ≤ ǫ.5 This result immediately inspires an algorithm A which, at every time t, chooses a value mt ≤ t−1, and predicts Ŷt = ĥt(Xt), for ĥt = argminh∈C ∑t−1 i=t−mt 1[h(Xi) 6= Yi]. We are then interested in choosing mt to minimize the value of ǫ obtainable via the result of [HL94]. However, that method is based on the values P(x : h∗i (x) 6= h∗t (x)), which would typically not be accessible to the algorithm. However, suppose instead we have access to a sequence ∆ such that h∗ ∈ S∆. In this case, we could approximate P(x : h∗i (x) 6= h∗t (x)) by its upper bound ∑t j=i+1 ∆j . In this case, we are interested choosing mt to minimize the smallest value of ǫ such that\n∑t−1 i=t−mt ∑t j=i+1 ∆j ≤ mtǫ/24 and mt = Ω ( d ǫLog 1 ǫ )\n. One can easily verify that this minimum is obtained at a value\nmt = Θ\n\nargmin m≤t−1\n1\nm\nt−1 ∑\ni=t−m\nt ∑\nj=i+1\n∆j + dLog(m/d)\nm\n\n ,\nand via the result of [HL94] (applied to the sequenceXt−mt , . . . , Xt) the resulting algorithm has\nP\n( Ŷt 6= Yt ) ≤ O\n\n min 1≤m≤t−1\n1\nm\nt−1 ∑\ni=t−m\nt ∑\nj=i+1\n∆j + dLog(m/d)\nm\n\n . (1)\nAs a special case, if every t has ∆t = ∆ for a fixed value ∆ ∈ [0, 1], this result recovers the bound √\nd∆Log(1/∆), which is only slightly larger than that obtainable from the best bound of [Lon99]. It also applies to far more general and more intersting sequences ∆, including some that allow periodic large jumps (i.e.,∆t = 1 for some indices t), others where the sequence∆t converges to 0, and so on. Note, however, that the algorithm obtaining this bound directly depends on the sequence∆. One of the contributions of the present work is to remove this requirement, while maintaining essentially the same bound, though in a slightly different form.\n5 They in fact prove a more general result, which also applies to methods approximately minimizing the number of mistakes, but for simplicity we will only discuss this basic version of the result."
    }, {
      "heading" : "3.3 Computational Efficiency",
      "text" : "[HL94] also proposed a reduction-based approach, which sometimes yields computationally efficient methods, though the tolerable ∆ value is smaller. Specifically, given any (randomized) polynomial-time algorithmA that produces a classifier h ∈ C with ∑mt=1 1[h(xt) 6= yt] = 0 for any sequence (x1, y1), . . . , (xm, ym) for which such a classifier h exists (called the consistency problem), they propose a polynomial-time algorithm that is (ǫ, S∆)-tracking for all values of ∆ ≤ ∆′ǫ, where ∆′ǫ = Θ ( ǫ2\nd2Log(1/ǫ)\n)\n. This is slightly worse (by a factor of dLog(1/ǫ))\nthan the drift rate tolerable by the (typically inefficient) algorithm mentioned above. However, it does sometimes yield computationally-efficient methods. For instance, there are known polynomial-time algorithms for the consistency problem for the classes of linear separators, conjunctions, and axis-aligned rectangles."
    }, {
      "heading" : "3.4 Lower Bounds",
      "text" : "[HL94] additionally prove lower bounds for specific concept spaces: namely, linear separators and axis-aligned rectangles. They specifically argue that, for C a concept space\nBASICn = {∪ni=1[i/n, (i+ ai)/n) : a ∈ [0, 1]n}\non [0, 1], under P the uniform distribution on [0, 1], for any ǫ ∈ [0, 1/e2] and ∆ǫ ≥ e4ǫ2/n, for any algorithm A, and any T ∈ N, there exists a choice of h∗ ∈ S∆ǫ such that the prediction ŶT produced by A at time T satisfies P ( ŶT 6= YT ) > ǫ. Based on this, they conclude that no (ǫ, S∆ǫ)-tracking algorithm exists. Furthermore, they observe that the space BASICn is embeddable in many commonly-studied concept spaces, including halfspaces and axis-aligned rectangles in Rn, so that for C equal to either of these spaces, there also is no (ǫ, S∆ǫ)-tracking algorithm."
    }, {
      "heading" : "4 Adapting to Arbitrarily Varying Drift Rates",
      "text" : "This section presents a general bound on the error rate at each time, expressed as a function of the rates of drift, which are allowed to be arbitrary. Mostimportantly, in contrast to the methods from the literature discussed above, the method achieving this general result is adaptive to the drift rates, so that it requires no information about the drift rates in advance. This is an appealing property, as it essentially allows the algorithm to learn under an arbitrary sequence h∗ of target concepts; the difficulty of the task is then simply reflected in the resulting bounds on the error rates: that is, faster-changing sequences of target functions result in larger bounds on the error rates, but do not require a change in the algorithm itself."
    }, {
      "heading" : "4.1 Adapting to a Changing Drift Rate",
      "text" : "Recall that the method yielding (1) (based on the work of [HL94]) required access to the sequence ∆ of changes to achieve the stated guarantee on the expected number of mistakes. That method is based on choosing a classifier to predict Ŷt by minimizing the number of mistakes among the previous mt samples, where mt is a value chosen based on the ∆ sequence. Thus, the key to modifying this algorithm to make it adaptive to the ∆ sequence is to determine a suitable choice of mt without reference to the ∆ sequence. The strategy we adopt here is to use the data to determine an appropriate value m̂t to use. Roughly (ignoring logarithmic factors for now), the insight that enables us to achieve this feat is that, for the mt used in the above strategy, one can show that ∑t−1\ni=t−mt 1[h ∗ t (Xi) 6= Yi] is roughly Õ(d), and that making the prediction Ŷt with any h ∈ C with roughly Õ(d) mistakes on these samples will suffice to obtain the stated bound on the error rate (up to logarithmic factors). Thus, if we replace mt with the largest value m for which minh∈C ∑t−1\ni=t−m 1[h(Xi) 6= Yi] is roughly Õ(d), then the above observation implies m ≥ mt. This then implies that, for ĥ = argminh∈C ∑t−1 i=t−m 1[h(Xi) 6= Yi], we have that ∑t−1 i=t−mt 1[ĥ(Xi) 6= Yi] is also roughly Õ(d), so that the stated bound on the error rate will be achieved\n(aside from logarithmic factors) by choosing ĥt as this classifier ĥ. There are a few technical modifications to this argument needed to get the logarithmic factors to work out properly, and for this reason the actual algorithm and proof below are somewhat more involved. Specifically, consider the following algorithm (the value of the universal constant K ≥ 1 will be specified below).\n0. For T = 1, 2, . . .\n1. Let m̂T =max\n{\nm∈{1, . . . , T−1} : min h∈C max m′≤m\n∑T−1 t=T−m′\n1[h(Xt) 6=Yt] dLog(m′/d)+Log(1/δ) < K\n}\n2. Let ĥT = argmin h∈C max m′≤m̂T\n∑T−1 t=T−m′\n1[h(Xt) 6=Yt] dLog(m′/d)+Log(1/δ)\nNote that the classifiers ĥt chosen by this algorithm have no dependence on ∆, or indeed anything other than the data {(Xi, Yi) : i < t}, and the concept space C.\nTheorem 1. Fix any δ ∈ (0, 1), and let A be the above algorithm. For any sequence ∆ in [0, 1], for any P and any choice of h∗ ∈ S∆, for every T ∈ N\\{1}, with probability at least 1− δ,\nerT\n(\nĥT\n)\n≤ O\n\n min 1≤m≤T−1\n1\nm\nT−1 ∑\ni=T−m\nT ∑\nj=i+1\n∆j + dLog(m/d) + Log(1/δ)\nm\n\n .\nBefore presenting the proof of this result, we first state a crucial lemma, which follows immediately from a classic result of [Vap82,Vap98], combined with the fact (from [Vid03], Theorem 4.5) that the VC dimension of the collection of sets {{x : h(x) 6= g(x)} : h, g ∈ C} is at most 10d.\nLemma 1. There exists a universal constant c ∈ [1,∞) such that, for any class C of VC dimension d, ∀m ∈ N, ∀δ ∈ (0, 1), with probability at least 1− δ, every h, g ∈ C have\n∣ ∣ ∣ ∣ ∣ P(x : h(x) 6= g(x))− 1 m m ∑\nt=1\n1[h(Xt) 6= g(Xt)] ∣ ∣ ∣ ∣\n∣\n≤ c\n√ √ √ √ ( 1\nm\nm ∑\nt=1\n1[h(Xt) 6= g(Xt)] ) dLog(m/d) + Log(1/δ)\nm\n+ c dLog(m/d) + Log(1/δ)\nm .\nWe are now ready for the proof of Theorem 1. For the constant K in the algorithm, we will choose K = 145c2, for c as in Lemma 1.\nProof (Proof of Theorem 1). Fix any T ∈ N with T ≥ 2, and define\nm∗T = max\n{\nm ∈ {1, . . . , T − 1} : ∀m′ ≤ m,\nT−1 ∑\nt=T−m′ 1[h∗T (Xt) 6= Yt] < K(dLog(m′/d) + Log(1/δ))\n}\n.\nNote that\nT−1 ∑\nt=T−m∗T\n1[h∗T (Xt) 6= Yt] ≤ K(dLog(m∗T /d) + Log(1/δ)), (2)\nand also note that (since h∗T ∈ C) m̂T ≥ m∗T , so that (by definition of m̂T and ĥT )\nT−1 ∑\nt=T−m∗T\n1[ĥT (Xt) 6= Yt] ≤ K(dLog(m∗T /d) + Log(1/δ))\nas well. Therefore,\nT−1 ∑\nt=T−m∗T\n1[h∗T (Xt) 6= ĥT (Xt)] ≤ T−1 ∑\nt=T−m∗T\n1[h∗T (Xt) 6= Yt] + T−1 ∑\nt=T−m∗T\n1[Yt 6= ĥT (Xt)]\n≤ 2K(dLog(m∗T /d) + Log(1/δ)).\nThus, by Lemma 1, for each m ∈ N, with probability at least 1 − δ/(6m2), if m∗T = m, then\nP(x : ĥT (x) 6= h∗T (x)) ≤ (2K + c √ 2K + c) dLog(m∗T /d) + Log(6(m ∗ T ) 2/δ)\nm∗T .\nFurthermore, since Log(6(m∗T ) 2) ≤ √ 2KdLog(m∗T /d), this is at most\n2(K + c √ 2K) dLog(m∗T /d) + Log(1/δ)\nm∗T .\nBy a union bound (over values m ∈ N), we have that with probability at least 1−∑∞m=1 δ/(6m2) ≥ 1− δ/3,\nP(x : ĥT (x) 6= h∗T (x)) ≤ 2(K + c √ 2K) dLog(m∗T /d) + Log(1/δ)\nm∗T .\nLet us denote\nm̃T = argmin m∈{1,...,T−1}\n1\nm\nT−1 ∑\ni=T−m\nT ∑\nj=i+1\n∆j + dLog(m/d) + Log(1/δ)\nm .\nNote that, for any m′ ∈ {1, . . . , T − 1} and δ ∈ (0, 1), if m̃T ≥ m′, then\nmin m∈{1,...,T−1}\n1\nm\nT−1 ∑\ni=T−m\nT ∑\nj=i+1\n∆j + dLog(m/d) + Log(1/δ)\nm\n≥ min m∈{m′,...,T−1}\n1\nm\nT−1 ∑\ni=T−m\nT ∑\nj=i+1\n∆j = 1\nm′\nT−1 ∑\ni=T−m′\nT ∑\nj=i+1\n∆j ,\nwhile if m̃T ≤ m′, then\nmin m∈{1,...,T−1}\n1\nm\nT−1 ∑\ni=T−m\nT ∑\nj=i+1\n∆j + dLog(m/d) + Log(1/δ)\nm\n≥ min m∈{1,...,m′}\ndLog(m/d) + Log(1/δ)\nm =\ndLog(m′/d) + Log(1/δ)\nm′ .\nEither way, we have that\nmin m∈{1,...,T−1}\n1\nm\nT−1 ∑\ni=T−m\nT ∑\nj=i+1\n∆j + dLog(m/d) + Log(1/δ)\nm\n≥ min\n\n\n\ndLog(m′/d) + Log(1/δ)\nm′ , 1 m′\nT−1 ∑\ni=T−m′\nT ∑\nj=i+1\n∆j\n\n\n\n. (3)\nFor any m ∈ {1, . . . , T − 1}, applying Bernstein’s inequality (see [BLM13], equation 2.10) to the random variables 1[h∗T (Xi) 6= Yi]/d, i ∈ {T−m, . . . , T−1}, and again to the random variables −1[h∗T (Xi) 6= Yi]/d, i ∈ {T −m, . . . , T − 1}, together with a union bound, we obtain that, for any δ ∈ (0, 1), with probability\nat least 1− δ/(3m2),\n1\nm\nT−1 ∑\ni=T−m P(x : h∗T (x) 6= h∗i (x))\n−\n√ √ √ √ ( 1\nm\nT−1 ∑\ni=T−m P(x : h∗T (x) 6= h∗i (x))\n)\n2 ln(3m2/δ)\nm\n< 1\nm\nT−1 ∑\ni=T−m 1[h∗T (Xi) 6= Yi]\n< 1\nm\nT−1 ∑\ni=T−m P(x : h∗T (x) 6= h∗i (x))\n+ max\n\n\n\n√\n(\n1 m ∑T−1 i=T−m P(x : h∗T (x) 6= h∗i (x))\n)\n4 ln(3m2/δ) m\n(4/3) ln(3m2/δ) m\n. (4)\nThe left inequality implies that\n1\nm\nT−1 ∑\ni=T−m P(x :h∗T (x) 6= h∗i (x)) ≤ max\n{\n2\nm\nT−1 ∑\ni=T−m 1[h∗T (Xi) 6= Yi],\n8 ln(3m2/δ)\nm\n}\n.\nPlugging this into the right inequality in (4), we obtain that\n1\nm\nT−1 ∑\ni=T−m 1[h∗T (Xi) 6= Yi] <\n1\nm\nT−1 ∑\ni=T−m P(x : h∗T (x) 6= h∗i (x))\n+ max\n\n\n\n√ √ √ √ ( 1\nm\nT−1 ∑\ni=T−m 1[h∗T (Xi) 6= Yi]\n)\n8 ln(3m2/δ)\nm ,\n√ 32 ln(3m2/δ)\nm\n\n\n\n.\nBy a union bound, this holds simultaneously for all m ∈ {1, . . . , T − 1} with probability at least 1 −∑T−1m=1 δ/(3m2) > 1 − (2/3)δ. Note that, on this event, we obtain\n1\nm\nT−1 ∑\ni=T−m P(x : h∗T (x) 6= h∗i (x)) >\n1\nm\nT−1 ∑\ni=T−m 1[h∗T (Xi) 6= Yi]\n−max\n\n\n\n√ √ √ √ ( 1\nm\nT−1 ∑\ni=T−m 1[h∗T (Xi) 6= Yi]\n)\n8 ln(3m2/δ)\nm ,\n√ 32 ln(3m2/δ)\nm\n\n\n\n.\nIn particular, taking m = m∗T , and invoking maximality of m ∗ T , if m ∗ T < T − 1, the right hand side is at least\n(K − 6c √ K) dLog(m∗T /d) + Log(1/δ)\nm∗T .\nSince 1m ∑T−1 i=T−m ∑T j=i+1 ∆j ≥ 1m ∑T−1 i=T−m P(x : h∗T (x) 6= h∗i (x)), taking K = 145c2, we have that with probability at least 1− δ, if m∗T < T − 1, then\n10(K + c √ 2K) min\nm∈{1,...,T−1}\n1\nm\nT−1 ∑\ni=T−m\nT ∑\nj=i+1\n∆j + dLog(m/d) + Log(1/δ)\nm\n≥ 10(K + c √ 2K)min\n\n\n\ndLog(m∗T /d) + Log(1/δ)\nm∗T ,\n1\nm∗T\nT−1 ∑\ni=T−m∗T\nT ∑\nj=i+1\n∆j\n\n\n\n≥ 10(K + c √ 2K) dLog(m∗T /d) + Log(1/δ)\nm∗T\n≥ P(x : ĥT (x) 6= h∗T (x)).\nFurthermore, if m∗T = T−1, then we trivially have (on the same 1−δ probability event as above)\n10(K + c √ 2K) min\nm∈{1,...,T−1}\n1\nm\nT−1 ∑\ni=T−m\nT ∑\nj=i+1\n∆j + dLog(m/d) + Log(1/δ)\nm\n≥ 10(K + c √ 2K) min\nm∈{1,...,T−1}\ndLog(m/d) + Log(1/δ)\nm\n= 10(K + c √ 2K) dLog((T − 1)/d) + Log(1/δ) T − 1 = 10(K + c √ 2K) dLog(m∗T /d) + Log(1/δ)\nm∗T ≥ P(x : ĥT (x) 6= h∗T (x)).\n⊓⊔"
    }, {
      "heading" : "4.2 Conditions Guaranteeing a Sublinear Number of Mistakes",
      "text" : "One immediate implication of Theorem 1 is that, if the sum of ∆t values grows sublinearly, then there exists an algorithm achieving an expected number of mistakes growing sublinearly in the number of predictions. Formally, we have the following corollary.\nCorollary 1. If ∑T t=1 ∆t = o(T ), then there exists an algorithm A such that, for every P and every choice of h∗ ∈ S∆,\nE\n[\nT ∑\nt=1\n1\n[ Ŷt 6= Yt ]\n]\n= o(T ).\nProof. For every T ∈ N with T ≥ 2, let\nm̃T = argmin 1≤m≤T−1\n1\nm\nT−1 ∑\ni=T−m\nT ∑\nj=i+1\n∆j + dLog(m/d) + Log(1/δT )\nm ,\nand define δT = 1 m̃T . Then consider running the algorithm A from Theorem 1, except that in choosing m̂T and ĥT for each T , we use the above value δT in place of δ. Then Theorem 1 implies that, for each T , with probability at least 1− δT ,\nerT (ĥT ) ≤ O\n\n min 1≤m≤T−1\n1\nm\nT−1 ∑\ni=T−m\nT ∑\nj=i+1\n∆j + dLog(m/d) + Log(1/δT )\nm\n\n .\nSince erT (ĥT ) ≤ 1, this implies that\nP\n( ŶT 6= YT ) = E [ erT (ĥT ) ]\n≤ O\n\n min 1≤m≤T−1\n1\nm\nT−1 ∑\ni=T−m\nT ∑\nj=i+1\n∆j + dLog(m/d) + Log(1/δT )\nm\n\n+ δT\n= O\n\n min 1≤m≤T−1\n1\nm\nT−1 ∑\ni=T−m\nT ∑\nj=i+1\n∆j + dLog(m/d) + Log(m)\nm\n\n ,\nand since x 7→ xLog(m/x) is nondecreasing for x ≥ 1, Log(m) ≤ dLog(m/d), so that this last expression is\nO\n\n min 1≤m≤T−1\n1\nm\nT−1 ∑\ni=T−m\nT ∑\nj=i+1\n∆j + dLog(m/d)\nm\n\n .\nNow note that, for any t ∈ N and m ∈ {1, . . . , t− 1},\n1\nm\nt−1 ∑\ns=t−m\nt ∑\nr=s+1\n∆r ≤ 1\nm\nt−1 ∑\ns=t−m\nt ∑\nr=t−m+1 ∆r =\nt ∑\nr=t−m+1 ∆s. (5)\nLet βt(m) = max { ∑t r=t−m+1∆r, dLog(m/d) m } , and note that ∑t\nr=t−m+1∆r + dLog(m/d)\nm ≤ 2βt(m). Thus, combining the above with (5), linearity of expectations, and the fact that the probability of a mistake on a given round is at most 1, we obtain\nE\n[\nT ∑\nt=1\n1\n[ Ŷt 6= Yt ]\n]\n= O\n(\nT ∑\nt=1\nmin m∈{1,...,t−1}\nβt(m) ∧ 1 ) .\nFixing any M ∈ N, we have that for any T > M , T ∑\nt=1\nmin m∈{1,...,t−1}\nβt(m) ∧ 1 ≤ M + T ∑\nt=M+1\nβt(M) ∧ 1\n≤ M + T ∑\nt=M+1\n1\n[\ndLog(M/d)\nM ≥\nt ∑\nr=t−M+1 ∆r\n]\ndLog(M/d)\nM\n+ T ∑\nt=M+1\n1\n[\nt ∑\nr=t−M+1 ∆r >\ndLog(M/d)\nM\n]\n≤ M + dLog(M/d) M T +\nT ∑\nt=M+1\nM\ndLog(M/d)\nt ∑\nr=t−M+1 ∆r\n= dLog(M/d)\nM T + gM (T ),\nwhere gM is a function satisfying gM (T ) = o(T ) (holding M fixed). Since this is true of any M ∈ N, we have that\nlim T→∞\n1\nT\nT ∑\nt=1\nmin m∈{1,...,t−1} βt(m) ∧ 1 ≤ lim M→∞ lim T→∞\ndLog(M/d)\nM +\ngM (T )\nT\n= lim M→∞\ndLog(M/d)\nM = 0,\nso that E [\n∑T t=1 1\n[ Ŷt 6= Yt ]] = o(T ), as claimed. ⊓⊔\nFor many concept spaces of interest, the condition ∑T\nt=1 ∆t = o(T ) in Corollary 1 is also a necessary condition for any algorithm to guarantee a sublinear number of mistakes. For simplicity, we will establish this for the class of homogeneous linear separators on R2, with P the uniform distribution on the unit circle, in the following theorem. This can easily be extended to many other spaces, including higher-dimensional linear separators or axis-aligned rectangles in Rk, by embedding an analogous setup into those spaces.\nTheorem 2. If X = {x ∈ R2 : ‖x‖ = 1}, P is Uniform(X ), and C = {x 7→ 21[w · x ≥ 0] − 1 : w ∈ R2, ‖w‖ = 1} is the class of homogeneous linear separators, then for any sequence ∆ in [0, 1], there exists an algorithm A such that E [\n∑T t=1 1\n[ Ŷt 6= Yt ]]\n= o(T ) for every choice of h∗ ∈ S∆ if and only if ∑T\nt=1 ∆t = o(T ).\nProof. The “if” part follows immediately from Corollary 1. For the “only if” part, suppose ∆ is such that\n∑T t=1 ∆t 6= o(T ). It suffices to argue that for any\nalgorithm A, there exists a choice of h∗ ∈ S∆ for which E [ ∑T t=1 1 [ Ŷt 6= Yt ]]\n6= o(T ). Toward this end, fix any algorithm A. We proceed by the probabilistic\nmethod, constructing a random sequence h∗ ∈ S∆. Let B1, B2, . . . be independent Bernoulli(1/2) random variables (also independent from the unlabeled data X1, X2, . . .). We define the sequence h\n∗ inductively. For simplicity, we will represent each classifier in polar coordinates, writing hφ (for φ ∈ R) to denote the classifier that, for x = (x1, x2), classifies x as hφ(x) = 21[x1 cos(φ)+x2 sin(φ) ≥ 0]− 1; note that hφ = hφ+2π for every φ ∈ R. As a base case, start by defining a function h∗0 = h0, and letting φ0 = 0. Now for any t ∈ N, supposing h∗t−1 is already defined to be hφt−1 , we define φt = φt−1 + min{∆t, 1/2}πBt, and h∗t = hφt . Note that P(x : h∗t (x) 6= h∗t−1(x)) = min{∆t, 1/2} for every t ∈ N, so that this inductively defines a (random) choice of h∗ ∈ S∆.\nFor each t ∈ N, let Yt = h∗t (Xt). Now fix any algorithm A, and consider the sequence Ŷt of predictions the algorithm makes for points Xt, when the target sequence h∗ is chosen as above. Then note that, for any t ∈ N, since Ŷt and Bt are independent,\nP\n( Ŷt 6= Yt ) ≥ E [ P ( Ŷt 6= Yt ∣ ∣ ∣ Ŷt, φt−1 )]\n≥ E [ 1\n2 P ( hφt−1+min{∆t,1/2}π(Xt) 6= hφt−1−min{∆t,1/2}π(Xt) ∣ ∣φt−1 )\n]\n.\nFurthermore, since min{∆t, 1/2}π ≤ π/2, the regions {x : hφt−1+min{∆t,1/2}π(x) 6= hφt−1(x)} and {x : hφt−1−min{∆t,1/2}π(x) 6= hφt−1(x)} have zero-probability overlap (indeed, are disjoint if ∆t < 1/2), the above equals min{∆t, 1/2}.\nBy Fatou’s lemma, linearity of expectations, and the law of total expectation, we have that\nE\n[\nlim sup T→∞\n1 T E\n[\nT ∑\nt=1\n1[Ŷt 6= Yt] ∣ ∣ ∣ ∣\n∣\nh∗ ]]\n≥ lim sup T→∞\n1\nT\nT ∑\nt=1\nP\n( Ŷt 6= Yt )\n≥ lim sup T→∞\n1\nT\nT ∑\nt=1\nmin{∆t, 1/2}.\nSince ∑T t=1 ∆t 6= o(T ), the rightmost expression is strictly greater than zero. Thus, it must be that, with probility strictly greater than 0,\nlim sup T→∞\n1 T E\n[\nT ∑\nt=1\n1[Ŷt 6= Yt] ∣ ∣ ∣ ∣\n∣\nh∗ ] > 0.\nIn particular, this implies that there exists a (nonrandom) choice of the sequence h∗ ∈ S∆ for which E [ ∑T t=1 1 [ Ŷt 6= Yt ]]\n6= o(T ). Since this holds for any choice of the algorithm A, this completes the proof. ⊓⊔"
    }, {
      "heading" : "5 Polynomial-Time Algorithms for Linear Separators",
      "text" : "In this section, we suppose ∆t = ∆ for every t ∈ N, for a fixed constant ∆ > 0, and we consider the special case of learning homogeneous linear separators in\nRk under a uniform distribution on the origin-centered unit sphere. In this case, the analysis of [HL94] mentioned in Section 3.3 implies that it is possible to achieve a bound on the error rate that is Õ(d √ ∆), using an algorithm that runs in time poly(d, 1/∆, log(1/δ)) (and independent of t) for each prediction. This also implies that it is possible to achieve expected number of mistakes among T predictions that is Õ(d √ ∆)×T . [CMEDV10]6 have since proven that a variant of the Perceptron algorithm is capable of achieving an expected number of mistakes Õ((d∆)1/4)× T .\nBelow, we improve on this result by showing that there exists an efficient algorithm that achieves a bound on the error rate that is Õ( √ d∆), as was possible with the inefficient algorithm of [HL94,Lon99] mentioned in Section 3.1. This leads to a bound on the expected number of mistakes that is Õ( √ d∆) × T . Furthermore, our approach also allows us to present the method as an active learning algorithm, and to bound the expected number of queries, as a function of the number of samples T , by Õ( √ d∆) × T . The technique is based on a modification of the algorithm of [HL94], replacing an empirical risk minimization step with (a modification of) the computationally-efficient algorithm of [ABL13].\nFormally, define the class of homogeneous linear separators as the set of classifiers hw : R\nd → {−1,+1}, for w ∈ Rd with ‖w‖ = 1, such that hw(x) = sign(w · x) for every x ∈ Rd."
    }, {
      "heading" : "5.1 An Improved Guarantee for a Polynomial-Time Algorithm",
      "text" : "We have the following result.\nTheorem 3. When C is the space of homogeneous linear separators (with d ≥ 4) and P is the uniform distribution on the surface of the origin-centered unit sphere in Rd, for any fixed ∆ > 0, for any δ ∈ (0, 1/e), there is an algorithm that runs in time poly(d, 1/∆, log(1/δ)) for each time t, such that for any h∗ ∈ S∆, for every sufficiently large t ∈ N, with probability at least 1− δ,\nert(ĥt) = O\n( √\n∆d log\n(\n1\nδ\n)\n)\n.\nAlso, running this algorithm with δ = √ ∆d∧1/e, the expected number of mistakes among the first T instances is O (√ ∆d log (\n1 ∆d\n) T ) . Furthermore, the algorithm\ncan be run as an active learning algorithm, in which case, for this choice of δ, the expected number of labels requested by the algorithm among the first T instances is O (√ ∆d log3/2 (\n1 ∆d\n) T ) .\n6 This work in fact studies a much broader model of drift, which in fact allows the distribution P to vary with time as well. However, this Õ((d∆)1/4) × T result can be obtained from their more-general theorem by calculating the various parameters for this particular setting.\nWe first state the algorithm used to obtain this result. It is primarily based on a margin-based learning strategy of [ABL13], combined with an initialization step based on a modified Perceptron rule from [DKM09,CMEDV10]. For τ > 0 and x ∈ R, define ℓτ (x) = max { 0, 1− xτ }\n. Consider the following algorithm and subroutine; parameters δk, mk, τk, rk, bk, α, and κ will all be specified in the context of the proof; we suppose M = ∑⌈log2(1/α)⌉\nk=0 mk.\nAlgorithm: DriftingHalfspaces 0. Let h̃0 be an arbitrary classifier in C 1. For i = 1, 2, . . . 2. h̃i ← ABL(M(i− 1), h̃i−1)\nSubroutine: ModPerceptron(t, h̃) 0. Let wt be any element of R\nd with ‖wt‖ = 1 1. For m = t+ 1, t+ 2, . . . , t+m0 2. Choose ĥm = h̃ (i.e., predict Ŷm = h̃(Xm) as the prediction for Ym) 3. Request the label Ym 4. If hwm−1(Xm) 6= Ym 5. wm ← wm−1 − 2(wm−1 ·Xm)Xm 6. Else wm ← wm−1 7. Return wt+m0\nSubroutine: ABL(t, h̃) 0. Let w0 be the return value of ModPerceptron(t, h̃) 1. For k = 1, 2, . . . , ⌈log2(1/α)⌉ 2. Wk ← {} 3. For s = t+\n∑k−1 j=0 mj + 1, . . . , t+ ∑k j=0 mj\n4. Choose ĥs = h̃ (i.e., predict Ŷs = h̃(Xs) as the prediction for Ys) 5. If |wk−1 ·Xs| ≤ bk−1, Request label Ys and let Wk ← Wk ∪{(Xs, Ys)} 6. Find vk ∈ Rd with ‖vk − wk−1‖ ≤ rk, 0 < ‖vk‖ ≤ 1, and\n∑\n(x,y)∈Wk ℓτk(y(vk · x)) ≤ inf v:‖v−wk−1‖≤rk\n∑\n(x,y)∈Wk ℓτk(y(v · x)) + κ|Wk|\n7. Let wk = 1\n‖vk‖vk 8. Return hw⌈log2(1/α)⌉−1\nBefore stating the proof, we have a few additional lemmas that will be needed. The following result for ModPerceptron was proven by [CMEDV10].\nLemma 2. Suppose ∆ < 1512 . Consider the values wm obtained during the execution of ModPerceptron(t, h̃). ∀m ∈ {t + 1, . . . , t + m0}, P(x : hwm(x) 6= h∗m(x)) ≤ P(x : hwm−1(x) 6= h∗m(x)). Furthermore, letting c1 = π 2\nd·400·215 , if P(x : hwm−1(x) 6= h∗m(x)) ≥ 1/32, then with probability at least 1/64, P(x : hwm(x) 6= h∗m(x)) ≤ (1− c1)P(x : hwm−1(x) 6= h∗m(x)).\nThis implies the following.\nLemma 3. Suppose ∆ ≤ π2400·227(d+ln(4/δ)) . For m0 = max{⌈128(1/c1) ln(32)⌉, ⌈512 ln(4δ )⌉}, with probability at least 1 − δ/4, ModPerceptron(t, h̃) returns a vector w with P(x : hw(x) 6= h∗t+m0+1(x)) ≤ 1/16. Proof. By Lemma 2 and a union bound, in general we have\nP(x : hwm(x) 6= h∗m+1(x)) ≤ P(x : hwm−1(x) 6= h∗m(x)) +∆. (6)\nFurthermore, if P(x : hwm−1(x) 6= h∗m(x)) ≥ 1/32, then wth probability at least 1/64,\nP(x : hwm(x) 6= h∗m+1(x)) ≤ (1− c1)P(x : hwm−1(x) 6= h∗m(x)) +∆. (7)\nIn particular, this implies that the number N of values m ∈ {t+ 1, . . . , t+m0} with either P(x : hwm−1(x) 6= h∗m(x)) < 1/32 or P(x : hwm(x) 6= h∗m+1(x)) ≤ (1− c1)P(x : hwm−1(x) 6= h∗m(x)) +∆ is lower-bounded by a Binomial(m, 1/64) random variable. Thus, a Chernoff bound implies that with probability at least 1− exp{−m0/512} ≥ 1− δ/4, we have N ≥ m0/128. Suppose this happens.\nSince ∆m0 ≤ 1/32, if any m ∈ {t + 1, . . . , t + m0} has P(x : hwm−1(x) 6= h∗m(x)) < 1/32, then inductively applying (6) implies that P(x : hwt+m0 (x) 6= h∗t+m0+1(x)) ≤ 1/32+∆m0 ≤ 1/16. On the other hand, if all m ∈ {t+1, . . . , t+ m0} have P(x : hwm−1(x) 6= h∗m(x)) ≥ 1/32, then in particular we have N values ofm ∈ {t+1, . . . , t+m0} satisfying (7). Combining this fact with (6) inductively, we have that\nP(x : hwt+m0 (x) 6= h ∗ t+m0+1(x)) ≤ (1 − c1) NP(x : hwt(x) 6= h∗t+1(x)) +∆m0\n≤ (1− c1)(1/c1) ln(32)P(x : hwt(x) 6= h∗t+1(x)) +∆m0 ≤ 1\n32 +∆m0 ≤\n1\n16 .\n⊓⊔ Next, we consider the execution of ABL(t, h̃), and let the sets Wk be as in that execution. We will denote by w∗ the weight vector with ‖w∗‖ = 1 such that h∗t+m0+1 = hw∗ . Also denote by M1 = M −m0.\nThe proof relies on a few results proven in the work of [ABL13], which we summarize in the following lemmas. Although the results were proven in a slightly different setting in that work (namely, agnostic learning under a fixed joint distribution), one can easily verify that their proofs remain valid in our present context as well.\nLemma 4. [ABL13] Fix any k ∈ {1, . . . , ⌈log2(1/α)⌉}. For a universal constant c7 > 0, suppose bk−1 = c721−k/ √ d, and let zk = √\nr2k/(d− 1) + b2k−1. For a universal constant c1 > 0, if ‖w∗ − wk−1‖ ≤ rk, ∣\n∣ ∣ ∣ ∣ ∣ E\n\n\n∑\n(x,y)∈Wk\nℓτk(|w∗ · x|) ∣ ∣ ∣wk−1, |Wk|\n\n− E\n\n\n∑\n(x,y)∈Wk\nℓτk(y(w ∗ · x))\n∣ ∣ ∣wk−1, |Wk|\n\n\n∣ ∣ ∣ ∣ ∣ ∣\n≤ c1|Wk| √ 2k∆M1 zk τk .\nLemma 5. [BL13] For any c > 0, there is a constant c′ > 0 depending only on c (i.e., not depending on d) such that, for any u, v ∈ Rd with ‖u‖ = ‖v‖ = 1, letting σ = P(x : hu(x) 6= hv(x)), if σ < 1/2, then\nP ( x : hu(x) 6= hv(x) and |v · x| ≥ c′ σ√ d ) ≤ cσ.\nThe following is a well-known lemma concerning concentration around the equator for the uniform distribution (see e.g., [DKM09,BBZ07,ABL13]); for instance, it easily follows from the formulas for the area in a spherical cap derived by [Li11].\nLemma 6. For any constant C > 0, there are constants c2, c3 > 0 depending only on C (i.e., independent of d) such that, for any w ∈ Rd with ‖w‖ = 1, ∀γ ∈ [0, C/ √ d],\nc2γ √ d ≤ P (x : |w · x| ≤ γ) ≤ c3γ √ d.\nBased on this lemma, [ABL13] prove the following.\nLemma 7. [ABL13] For X ∼ P, for any w ∈ Rd with ‖w‖ = 1, for any C > 0 and τ, b ∈ [0, C/ √ d], for c2, c3 as in Lemma 6,\nE\n[ ℓτ (|w∗ ·X |) ∣ ∣ ∣|w ·X | ≤ b ] ≤ c3τ c2b .\nThe following is a slightly stronger version of a result of [ABL13] (specifically, the size of mk, and consequently the bound on |Wk|, are both improved by a factor of d compared to the original result).\nLemma 8. Fix any δ ∈ (0, 1/e). For universal constants c4, c5, c6, c7, c8, c9, c10 ∈ (0,∞), for an appropriate choice of κ ∈ (0, 1) (a universal constant), if α = c9 √ ∆d log ( 1 κδ ) , for every k ∈ {1, . . . , ⌈log2(1/α)⌉}, if bk−1 = c721−k/ √ d, τk = c82 −k/ √ d, rk = c102 −k, δk = δ/(⌈log2(4/α)⌉−k)2, and mk = ⌈ c5 2k κ2 d log ( 1 κδk )⌉ , and if P(x : hwk−1(x) 6= hw∗(x)) ≤ 2−k−3, then with probability at least 1 − (4/3)δk, |Wk| ≤ c6 1κ2 d log ( 1 κδk ) and P(x : hwk(x) 6= hw∗(x)) ≤ 2−k−4.\nProof. By Lemma 6, and a Chernoff and union bound, for an appropriately large choice of c5 and any c7 > 0, letting c2, c3 be as in Lemma 6 (with C = c7∨(c8/2)), with probability at least 1− δk/3,\nc2c72 −kmk ≤ |Wk| ≤ 4c3c72−kmk. (8)\nThe claimed upper bound on |Wk| follows from this second inequality. Next note that, if P(x : hwk−1(x) 6= hw∗(x)) ≤ 2−k−3, then\nmax{ℓτk(y(w∗ · x)) : x ∈ Rd, |wk−1 · x| ≤ bk−1, y ∈ {−1,+1}} ≤ c11 √ d\nfor some universal constant c11 > 0. Furthermore, since P(x : hwk−1(x) 6= hw∗(x)) ≤ 2−k−3, we know that the angle between wk−1 and w∗ is at most 2−k−3π, so that\n‖wk−1 − w∗‖ = √ 2− 2wk−1 · w∗ ≤ √ 2− 2 cos(2−k−3π)\n≤ √ 2− 2 cos2(2−k−3π) = √ 2 sin(2−k−3π) ≤ 2−k−3π √ 2.\nFor c10 = π √ 22−3, this is rk. By Hoeffding’s inequality (under the conditional distribution given |Wk|), the law of total probability, Lemma 4, and linearity of conditional expectations, with probability at least 1− δk/3, for X ∼ P ,\n∑\n(x,y)∈Wk\nℓτk(y(w ∗ · x)) ≤ |Wk|E\n[ ℓτk(|w∗ ·X |) ∣ ∣ ∣wk−1, |wk−1 ·X | ≤ bk−1 ]\n+ c1|Wk| √ 2k∆M1 zk τk + √ |Wk|(1/2)c211d ln(3/δk). (9)\nWe bound each term on the right hand side separately. By Lemma 7, the first term is at most |Wk| c3τkc2bk−1 = |Wk| c3c8 2c2c7 . Next,\nzk τk =\n√\nc2102 −2k/(d− 1) + 4c272−2k/d\nc82−k/ √ d\n≤ √ 2c210 + 4c 2 7\nc8 ,\nwhile 2k ≤ 2/α so that the second term is at most\n√ 2c1 √ 2c210 + 4c 2 7\nc8 |Wk|\n√\n∆m\nα .\nNoting that\nM1 =\n⌈log2(1/α)⌉ ∑\nk′=1\nmk′ ≤ 32c5 κ2 1 α d log\n(\n1\nκδ\n)\n, (10)\nwe find that the second term on the right hand side of (9) is at most\n√\nc5 c9 8c1 κ\n√\n2c210 + 4c 2 7\nc8 |Wk|\n√\n∆d log ( 1 κδ )\nα2 =\n8c1 √ c5\nκ\n√\n2c210 + 4c 2 7\nc8c9 |Wk|.\nFinally, since d ln(3/δk) ≤ 2d ln(1/δk) ≤ 2κ 2 c5 2−kmk, and (8) implies 2−kmk ≤\n1 c2c7 |Wk|, the third term on the right hand side of (9) is at most\n|Wk| c11κ√ c2c5c7 .\nAltogether, we have\n∑\n(x,y)∈Wk\nℓτk(y(w ∗ · x)) ≤ |Wk|\n(\nc3c8 2c2c7 + 8c1\n√ c5\nκ\n√\n2c210 + 4c 2 7\nc8c9 + c11κ√ c2c5c7\n)\n.\nTaking c9 = 1/κ 3 and c8 = κ, this is at most\nκ|Wk| ( c3 2c2c7 + 8c1 √ c5 √ 2c210 + 4c 2 7 + c11√ c2c5c7 ) .\nNext, note that because hwk(x) 6= y ⇒ ℓτk(y(vk · x)) ≥ 1, and because (as proven above) ‖w∗ − wk−1‖ ≤ rk,\n|Wk|erWk(hwk) ≤ ∑\n(x,y)∈Wk\nℓτk(y(vk · x)) ≤ ∑\n(x,y)∈Wk\nℓτk(y(w ∗ · x)) + κ|Wk|.\nCombined with the above, we have\n|Wk|erWk(hwk) ≤ κ|Wk| ( 1 + c3\n2c2c7 + 8c1\n√ c5 √ 2c210 + 4c 2 7 + c11√ c2c5c7\n)\n.\nLet c12 = 1 + c3\n2c2c7 + 8c1\n√ c5 √ 2c210 + 4c 2 7 + c11√ c2c5c7 . Furthermore,\n|Wk|erWk(hwk) = ∑\n(x,y)∈Wk\n1[hwk(x) 6= y]\n≥ ∑\n(x,y)∈Wk\n1[hwk(x) 6= hw∗(x)] − ∑\n(x,y)∈Wk\n1[hw∗(x) 6= y].\nFor an appropriately large value of c5, by a Chernoff bound, with probability at least 1− δk/3,\nt+ ∑k\nj=0 mj ∑\ns=t+ ∑k−1\nj=0 mj+1\n1[hw∗(Xs) 6= Ys] ≤ 2e∆M1mk + log2(3/δk).\nIn particular, this implies\n∑\n(x,y)∈Wk\n1[hw∗(x) 6= y] ≤ 2e∆M1mk + log2(3/δk),\nso that ∑\n(x,y)∈Wk\n1[hwk(x) 6= hw∗(x)] ≤ |Wk|erWk(hwk) + 2e∆M1mk + log2(3/δk).\nNoting that (10) and (8) imply\n∆M1mk ≤ ∆ 32c5 κ2\nd log ( 1 κδ )\nc9\n√\n∆d log ( 1 κδ )\n2k\nc2c7 |Wk| ≤ 32c5 c2c7c9κ2\n√\n∆d log\n(\n1\nκδ\n)\n2k|Wk|\n= 32c5\nc2c7c29κ 2 α2k|Wk| =\n32c5κ 4\nc2c7 α2k|Wk| ≤\n32c5κ 4\nc2c7 |Wk|,\nand (8) implies log2(3/δk) ≤ 2κ 2 c2c5c7 |Wk|, altogether we have\n∑\n(x,y)∈Wk\n1[hwk(x) 6= hw∗(x)] ≤ |Wk|erWk(hwk) + 64ec5κ\n4\nc2c7 |Wk|+\n2κ2\nc2c5c7 |Wk|\n≤ κ|Wk| ( c12 + 64ec5κ 3\nc2c7 +\n2κ\nc2c5c7\n)\n.\nLetting c13 = c12+ 64ec5 c2c7 + 2c2c5c7 , and noting κ ≤ 1, we have ∑ (x,y)∈Wk 1[hwk(x) 6= hw∗(x)] ≤ c13κ|Wk|.\nLemma 1 (applied under the conditional distribution given |Wk|) and the law of total probability imply that with probability at least 1− δk/3,\n|Wk|P ( x : hwk(x) 6= hw∗(x) ∣ ∣ ∣|wk−1 · x| ≤ bk−1 )\n≤ ∑\n(x,y)∈Wk\n1[hwk(x) 6= hw∗(x)] + c14 √ |Wk|(d log(|Wk|/d) + log(1/δk)),\nfor a universal constant c14 > 0. Combined with the above, and the fact that (8) implies log(1/δk) ≤ κ 2\nc2c5c7 |Wk| and\nd log(|Wk|/d) ≤ d log\n\n\n8c3c5c7 log (\n1 κδk\n)\nκ2\n\n\n≤ d log ( 8c3c5c7 κ3δk ) ≤ 3 log(8max{c3, 1}c5)c5d log ( 1 κδk ) ≤ 3 log(8max{c3, 1})κ22−kmk ≤ 3 log(8max{c3, 1})\nc2c7 κ2|Wk|,\nwe have\n|Wk|P ( x : hwk(x) 6= hw∗(x) ∣ ∣ ∣|wk−1 · x| ≤ bk−1 )\n≤ c13κ|Wk|+ c14\n√\n|Wk| ( 3 log(8max{c3, 1}) c2c7 κ2|Wk|+ κ2 c2c5c7 |Wk| )\n= κ|Wk|\n\nc13 + c14\n√\n3 log(8max{c3, 1}) c2c7 + 1 c2c5c7\n\n .\nThus, letting c15 =\n(\nc13 + c14\n√\n3 log(8max{c3,1}) c2c7 + 1c2c5c7\n)\n, we have\nP ( x : hwk(x) 6= hw∗(x) ∣ ∣ ∣|wk−1 · x| ≤ bk−1 ) ≤ c15κ. (11)\nNext, note that ‖vk − wk−1‖2 = ‖vk‖2 + 1 − 2‖vk‖ cos(πP(x : hwk(x) 6= hwk−1(x))). Thus, one implication of the fact that ‖vk−wk−1‖ ≤ rk is that ‖vk‖2 +\n1−r2k 2‖vk‖ ≤ cos(πP(x : hwk(x) 6= hwk−1(x))); since the left hand side is positive, we have P(x : hwk(x) 6= hwk−1(x)) < 1/2. Additionally, by differentiating, one can easily verify that for φ ∈ [0, π], x 7→ √\nx2 + 1− 2x cos(φ) is minimized at x = cos(φ), in which case √\nx2 + 1− 2x cos(φ) = sin(φ). Thus, ‖vk − wk−1‖ ≥ sin(πP(x : hwk(x) 6= hwk−1(x))). Since ‖vk − wk−1‖ ≤ rk, we have sin(πP(x : hwk(x) 6= hwk−1(x))) ≤ rk. Since sin(πx) ≥ x for all x ∈ [0, 1/2], combining this with the fact (proven above) that P(x : hwk(x) 6= hwk−1(x)) < 1/2 implies P(x : hwk(x) 6= hwk−1(x)) ≤ rk.\nIn particular, we have that both P(x : hwk(x) 6= hwk−1(x)) ≤ rk and P(x : hw∗(x) 6= hwk−1(x)) ≤ 2−k−3 ≤ rk. Now Lemma 5 implies that, for any universal constant c > 0, there exists a corresponding universal constant c′ > 0 such that\nP ( x : hwk(x) 6= hwk−1(x) and |wk−1 · x| ≥ c′ rk√ d ) ≤ crk\nand\nP ( x : hw∗(x) 6= hwk−1(x) and |wk−1 · x| ≥ c′ rk√ d ) ≤ crk,\nso that (by a union bound)\nP ( x : hwk(x) 6= hw∗(x) and |wk−1 · x| ≥ c′ rk√ d )\n≤ P ( x : hwk(x) 6= hwk−1(x) and |wk−1 · x| ≥ c′ rk√ d ) + P (\nx : hw∗(x) 6= hwk−1(x) and |wk−1 · x| ≥ c′ rk√ d\n)\n≤ 2crk.\nIn particular, letting c7 = c ′c10/2, we have c′ rk√ d = bk−1. Combining this with (11), Lemma 6, and a union bound, we have that\nP (x : hwk(x) 6= hw∗(x)) ≤ P (x : hwk(x) 6= hw∗(x) and |wk−1 · x| ≥ bk−1) + P (x : hwk(x) 6= hw∗(x) and |wk−1 · x| ≤ bk−1)\n≤ 2crk + P ( x : hwk(x) 6= hw∗(x) ∣ ∣ ∣ |wk−1 · x| ≤ bk−1 ) P (x : |wk−1 · x| ≤ bk−1) ≤ 2crk + c15κc3bk−1 √ d = ( 25cc10 + c15κc3c72 5 ) 2−k−4.\nTaking c = 126c10 and κ = 1 26c3c7c15 , we have P(x : hwk(x) 6= hw∗(x)) ≤ 2−k−4, as required. By a union bound, this occurs with probability at least 1− (4/3)δk. ⊓⊔\nProof (Proof of Theorem 3). We begin with the bound on the error rate. If ∆ > π2\n400·227(d+ln(4/δ)) , the result trivially holds, since then 1 ≤ 400·2 27 π2 √ ∆(d+ ln(4/δ)). Otherwise, suppose ∆ ≤ π2400·227(d+ln(4/δ)) .\nFix any i ∈ N. Lemma 3 implies that, with probability at least 1 − δ/4, the w0 returned in Step 0 of ABL(M(i − 1), h̃i−1) satisfies P(x : hw0(x) 6= h∗M(i−1)+m0+1(x)) ≤ 1/16. Taking this as a base case, Lemma 8 then inductively implies that, with probability at least\n1− δ 4 −\n⌈log2(1/α)⌉ ∑\nk=1\n(4/3) δ 2(⌈log2(4/α)⌉ − k)2 ≥ 1− δ 2\n(\n1 + (4/3)\n∞ ∑\nℓ=2\n1\nℓ2\n)\n≥ 1−δ,\nevery k ∈ {0, 1, . . . , ⌈log2(1/α)⌉} has\nP(x : hwk(x) 6= h∗M(i−1)+m0+1(x)) ≤ 2 −k−4, (12)\nand furthermore the number of labels requested during ABL(M(i − 1), h̃i−1) total to at most (for appropriate universal constants ĉ1, ĉ2)\nm0 +\n⌈log2(1/α)⌉ ∑\nk=1\n|Wk| ≤ ĉ1\n\nd+ ln\n(\n1\nδ\n)\n+\n⌈log2(1/α)⌉ ∑\nk=1\nd log\n(\n(⌈log2(4/α)⌉ − k)2 δ\n)\n\n\n≤ ĉ2d log ( 1\n∆d\n)\nlog\n(\n1\nδ\n)\n.\nIn particular, by a union bound, (12) implies that for every k ∈ {1, . . . , ⌈log2(1/α)⌉}, every\nm ∈\n\n\n\nM(i− 1) + k−1 ∑\nj=0\nmj + 1, . . . ,M(i− 1) + k ∑\nj=0\nmj\n\n\n\nhas\nP(x : hwk−1(x) 6= h∗m(x)) ≤ P(x : hwk−1(x) 6= h∗M(i−1)+m0+1(x)) + P(x : h ∗ M(i−1)+m0+1(x) 6= h ∗ m(x))\n≤ 2−k−3 +∆M.\nThus, noting that\nM =\n⌈log2(1/α)⌉ ∑\nk=0\nmk = Θ\n\nd+ log\n(\n1\nδ\n)\n+\n⌈log2(1/α)⌉ ∑\nk=1\n2kd log (⌈log2(1/α)⌉ − k δ )\n\n\n= Θ\n(\n1 α d log\n(\n1\nδ\n))\n= Θ\n( √\nd ∆ log\n(\n1\nδ\n)\n)\n,\nwith probability at least 1− δ,\nP(x : hw⌈log2(1/α)⌉−1(x) 6= h ∗ Mi(x)) ≤ O (α+∆M) = O\n( √\n∆d log\n(\n1\nδ\n)\n)\n.\nIn particular, this implies that, with probability at least 1− δ, every t ∈ {Mi+ 1, . . . ,M(i+ 1)− 1} has\nert(ĥt) ≤ P(x : hw⌈log2(1/α)⌉−1(x) 6= h ∗ Mi(x)) + P(x : h∗Mi(x) 6= h∗t (x))\n≤ O ( √ ∆d log ( 1\nδ\n)\n)\n+∆M = O\n( √\n∆d log\n(\n1\nδ\n)\n)\n,\nwhich completes the proof of the bound on the error rate. Setting δ = √ ∆d, and noting that 1[Ŷt 6= Yt] ≤ 1, we have that for any t > M ,\nP\n( Ŷt 6= Yt ) = E [ ert(ĥt) ] ≤ O ( √ ∆d log ( 1\nδ\n)\n)\n+ δ = O\n( √\n∆d log\n(\n1\n∆d\n)\n)\n.\nThus, by linearity of the expectation,\nE\n[\nT ∑\nt=1\n1\n[ Ŷt 6= Yt ]\n] ≤ M +O ( √ ∆d log ( 1\n∆d\n)\nT\n)\n= O\n( √\n∆d log\n(\n1\n∆d\n)\nT\n)\n.\nFurthermore, as mentioned, with probability at least 1− δ, the number of labels requested during the execution of ABL(M(i− 1), h̃i−1) is at most\nO\n(\nd log\n(\n1\n∆d\n)\nlog\n(\n1\nδ\n))\n.\nThus, since the number of labels requested during the execution of ABL(M(i− 1), h̃i−1) cannot exceed M , letting δ = √ ∆d, the expected number of requested labels during this execution is at most\nO\n( d log2 ( 1\n∆d\n)) + √ ∆dM ≤ O ( d log2 ( 1\n∆d\n))\n+O\n(\nd\n√\nlog\n(\n1\n∆d\n)\n)\n= O\n( d log2 ( 1\n∆d\n))\n.\nThus, by linearity of the expectation, the expected number of labels requested among the first T samples is at most\nO\n( d log2 ( 1\n∆d\n)⌈\nT\nM\n⌉)\n= O (√ ∆d log3/2 ( 1\n∆d\n)\nT\n)\n,\nwhich completes the proof. ⊓⊔\nRemark: The original work of [CMEDV10] additionally allowed for some number K of “jumps”: times t at which ∆t = 1. Note that, in the above algorithm, since the influence of each sample is localized to the predictors trained within that\n“batch” of M instances, the effect of allowing such jumps would only change\nthe bound on the number of mistakes to Õ (√ d∆T + √\nd ∆K\n)\n. This compares\nfavorably to the result of [CMEDV10], which is roughly O ( (d∆)1/4T + d 1/4 ∆3/4 K ) . However, the result of [CMEDV10] was proven for a more general setting, allowing distributions P that are not uniform (though they do require a relation between the angle between any two separators and the probability mass they disagree on, similar to that holding for the uniform distribution, which seems to require that the distributions approximately retain some properties of the uniform distribution). It is not clear whether Theorem 3 can be generalized to this larger family of distributions."
    }, {
      "heading" : "6 General Results for Active Learning",
      "text" : "As mentioned, the above results on linear separators also provide results for the number of queries in active learning. One can also state quite general results on the expected number of queries and mistakes achievable by an active learning algorithm. This section provides such results, for an algorithm based on the the well-known strategy of disagreement-based active learning. Throughout this section, we suppose h∗ ∈ S∆, for a given ∆ ∈ (0, 1]: that is, P(x : h∗t+1(x) 6= h∗t (x)) ≤ ∆ for all t ∈ N.\nFirst, we introduce a few definitions. For any set H ⊆ C, define the region of disagreement\nDIS(H) = {x ∈ X : ∃h, g ∈ H s.t. h(x) 6= g(x)}. The analysis in this section is centered around the following algorithm. The Active subroutine is from the work of [Han12] (slightly modified here), and is a variant of the A2 (Agnostic Acive) algorithm of [BBL06]; the appropriate values of M and T̂k(·) will be discussed below.\nAlgorithm: DriftingActive 0. For i = 1, 2, . . . 1. Active(M(i− 1))\nSubroutine: Active(t) 0. Let ĥ0 be an arbitrary element of C, and let V0 ← C 1. Predict Ŷt+1 = ĥ0(Xt+1) as the prediction for the value of Yt+1 2. For k = 0, 1, . . . , log2(M/2) 3. Qk ← {} 4. For s = 2k + 1, . . . , 2k+1 5. Predict Ŷs = ĥk(Xs) as the prediction for the value of Ys 6. If Xs ∈ DIS(Vk) 7. Request the label Ys and let Qk ← Qk ∪ {(Xs, Ys)} 8. Let ĥk+1 = argminh∈Vk ∑\n(x,y)∈Qk 1[h(x) 6= y] 9. Let Vk+1 ← {h ∈ Vk : ∑\n(x,y)∈Qk 1[h(x) 6= y]− 1[ĥk+1(x) 6= y] ≤ T̂k}\nAs in the DriftingHalfspaces algorithm above, this DriftingActive algorithm proceeds in batches, and in each batch runs an active learning algorithm designed to be robust to classification noise. This robustness to classification noise translates into our setting as tolerance for the fact that there is no classifier in C that perfectly classifies all of the data. The specific algorithm employed here maintains a set Vk ⊆ C of candidate classifiers, and requests the labels of samples Xs for which there is some disagreement on the classification among classifiers in Vk. We maintain the invariant that there is a low-error classifier contained in Vk at all times, and thus the points we query provide some information to help us determine which among these remaining candidates has low error rate. Based on these queries, we periodically (in Step 9) remove from Vk those classifiers making a relatively excessive number of mistakes on the queried samples, relative to the minimum among classifiers in Vk. All predictions are made with an element of Vk. 7\nWe prove an abstract bound on the number of labels requested by this algorithm, expressed in terms of the disagreement coefficient [Han07], defined as follows. For any r ≥ 0 and any classifier h, define B(h, r) = {g ∈ C : P(x : g(x) 6= h(x)) ≤ r}. Then for r0 ≥ 0 and any classifier h, define the disagreement coefficient of h with respect to C under P :\nθh(r0) = sup r>r0 P(DIS(B(h, r))) r .\nUsually, the disagreement coefficient would be used with h equal the target concept; however, since the target concept is not fixed in our setting, we will make use of the worst-case value of the disagreement coefficient: θC(r0) = suph∈C θh(r0). This quantity has been bounded for a variety of spaces C and distributions P (see e.g., [Han07,EYW12,BL13]). It is useful in bounding how quickly the region DIS(Vk) collapses in the algorithm. Thus, since the probability the algorithm requests the label of the next instance is P(DIS(Vk)), the quantity θC(r0) naturally arises in characterizing the number of labels we expect this algorithm to request. Specifically, we have the following result.8\nTheorem 4. For an appropriate universal constant c1 ∈ [1,∞), if h∗ ∈ S∆ for some ∆ ∈ (0, 1], then taking M = ⌈\nc1\n√\nd ∆\n⌉\n2\n, and T̂k = log2(1/ √ d∆)+22k+2e∆,\nand defining ǫ∆ = √ d∆Log(1/(d∆)), the above DriftingActive algorithm makes an expected number of mistakes among the first T instances that is\nO (ǫ∆Log(d/∆)T ) = Õ (√ d∆ ) T\nand requests an expected number of labels among the first T instances that is\nO (θC(ǫ∆)ǫ∆Log(d/∆)T ) = Õ ( θC( √ d∆) √ d∆ ) T."
    }, {
      "heading" : "7 One could alternatively proceed as in DriftingHalfspaces, using the final classifier from the previous batch, which would also add a guarantee on the error rate achieved at all sufficiently large t.",
      "text" : "8 Here, we define ⌈x⌉2 = 2 ⌈log2(x)⌉, for x ≥ 1.\nThe proof of Theorem 4 relies on an analysis of the behavior of the Active subroutine, characterized in the following lemma.\nLemma 9. Fix any t ∈ N, and consider the values obtained in the execution of Active(t). Under the conditions of Theorem 4, there is a universal constant c2 ∈ [1,∞) such that, for any k ∈ {0, 1, . . . , log2(M/2)}, with probability at least 1 − 2 √ d∆, if h∗t+1 ∈ Vk, then h∗t+1 ∈ Vk+1 and suph∈Vk+1 P(x : h(x) 6=\nh∗t+1(x)) ≤ c22−kdLog(c1/ √ d∆).\nProof. By a Chernoff bound, with probability at least 1− √ d∆,\n2k+1 ∑\ns=2k+1\n1[h∗t+1(Xs) 6= Ys] ≤ log2(1/ √ d∆) + 22k+2e∆ = T̂k.\nTherefore, if h∗t+1 ∈ Vk, then since every g ∈ Vk agrees with h∗t+1 on those points Xs /∈ DIS(Vk), in the update in Step 9 defining Vk+1, we have\n∑\n(x,y)∈Qk\n1[h∗t+1(x) 6= y]− 1[ĥk+1(x) 6= y]\n=\n2k+1 ∑\ns=2k+1\n1[h∗t+1(Xs) 6= Ys]− min g∈Vk\n2k+1 ∑\ns=2k+1\n1[g(Xs) 6= Ys]\n≤ 2k+1 ∑\ns=2k+1\n1[h∗t+1(Xs) 6= Ys] ≤ T̂k,\nso that h∗t+1 ∈ Vk+1 as well. Furthermore, if h∗t+1 ∈ Vk, then by the definition of Vk+1, we know every h ∈ Vk+1 has\n2k+1 ∑\ns=2k+1\n1[h(Xs) 6= Ys] ≤ T̂k + 2k+1 ∑\ns=2k+1\n1[h∗t+1(Xs) 6= Ys],\nso that a triangle inequality implies\n2k+1 ∑\ns=2k+1\n1[h(Xs) 6= h∗t+1(Xs)] ≤ 2k+1 ∑\ns=2k+1\n1[h(Xs) 6= Ys] + 1[h∗t+1(Xs) 6= Ys]\n≤ T̂k + 2 2k+1 ∑\ns=2k+1\n1[h∗t+1(Xs) 6= Ys] ≤ 3T̂k.\nLemma 1 then implies that, on an additional event of probability at least 1 −√ d∆, every h ∈ Vk+1 has\nP(x : h(x) 6= h∗t+1(x))\n≤ 2−k3T̂k + c2−k √ 3T̂k(dLog(2k/d) + Log(1/ √ d∆))\n+ c2−k(dLog(2k/d) + Log(1/ √ d∆))\n≤ 2−k3 log2(1/ √ d∆) + 2k12e∆+ c2−k √ 6 log2(1/ √ d∆)dLog(c1/ √ d∆)\n+ c2−k √ 22k24e∆dLog(c1/ √ d∆) + 2c2−kdLog(c1/ √ d∆)\n≤ 2−k3 log2(1/ √ d∆) + 12ec1 √ d∆+ 3c2−k √ dLog(c1/ √ d∆)\n+ √ 24ec √ d∆Log(c1/ √ d∆) + 2c2−kdLog(c1/ √ d∆),\nwhere c is as in Lemma 1. Since √ d∆ ≤ 2c1d/M ≤ c1d2−k, this is at most\n( 5 + 12ec21 + 3c+ √ 24ecc1 + 2c ) 2−kdLog(c1/ √ d∆).\nLetting c2 = 5+12ec 2 1+3c+ √ 24ecc1+2c, we have the result by a union bound.\n⊓⊔\nWe are now ready for the proof of Theorem 4.\nProof (Proof of Theorem 4). Fix any i ∈ N, and consider running Active(M(i− 1)). Since h∗M(i−1)+1 ∈ C, by Lemma 9, a union bound, and induction, with probability at least 1 − 2 √ d∆ log2(M/2) ≥ 1− 2 √ d∆ log2(c1 √\nd/∆), every k ∈ {0, 1, . . . , log2(M/2)} has\nsup h∈Vk\nP(x : h(x) 6= h∗M(i−1)+1(x)) ≤ c221−kdLog(c1/ √ d∆). (13)\nThus, since ĥk ∈ Vk for each k, the expected number of mistakes among the predictions ŶM(i−1)+1, . . . , ŶMi is\n1 +\nlog2(M/2) ∑\nk=0\n2k+1 ∑\ns=2k+1\nP(ĥk(XM(i−1)+s) 6= YM(i−1)+s)\n≤ 1 + log2(M/2) ∑\nk=0\n2k+1 ∑\ns=2k+1\nP(h∗M(i−1)+1(XM(i−1)+s) 6= YM(i−1)+s)\n+\nlog2(M/2) ∑\nk=0\n2k+1 ∑\ns=2k+1\nP(ĥk(XM(i−1)+s) 6= h∗M(i−1)+1(XM(i−1)+s))\n≤ 1 +∆M2 + log2(M/2) ∑\nk=0\n2k ( c22 1−kdLog(c1/ √ d∆) + 2 √ d∆ log2(M/2) )\n≤ 1 + 4c21d+ 2c2dLog(c1/ √ d∆) log2(2c1 √ d/∆) + 4c1d log2(c1 √ d/∆)\n= O (dLog(d/∆)Log(1/(d∆))) .\nFurthermore, (13) implies the algorithm only requests the label YM(i−1)+s for s ∈ {2k+1, . . . , 2k+1} if XM(i−1)+s ∈ DIS(B(h∗M(i−1)+1, c221−kdLog(c1/ √ d∆))), so that the expected number of labels requested among YM(i−1)+1, . . . , YMi is at most\n1 +\nlog2(M/2) ∑\nk=0\n2k ( E[P(DIS(B(h∗M(i−1)+1, c221−kdLog(c1/ √ d∆))))]\n+2 √ d∆ log2(c1 √ d/∆) )\n≤ 1 + θC ( 4c2dLog(c1/ √ d∆)/M ) 2c2dLog(c2/ √ d∆) log2(2c1 √ d/∆)\n+ 4c1d log2(c1 √ d/∆)\n= O (\nθC\n(√ d∆Log(1/(d∆)) ) dLog(d/∆)Log(1/(d∆)) ) .\nThus, the expected number of mistakes among indices 1, . . . , T is at most\nO\n(\ndLog(d/∆)Log(1/(d∆))\n⌈\nT\nM\n⌉) = O (√ d∆Log(d/∆)Log(1/(d∆))T ) ,\nand the expected number of labels requested among indices 1, . . . , T is at most\nO\n(\nθC\n(√ d∆Log(1/(d∆)) ) dLog(d/∆)Log(1/(d∆)) ⌈ T\nM\n⌉)\n= O (\nθC\n(√ d∆Log(1/(d∆)) )√ d∆Log(d/∆)Log(1/(d∆))T ) .\n⊓⊔"
    } ],
    "references" : [ {
      "title" : "The power of localization for efficiently learning linear separators with noise",
      "author" : [ "ABL13. P. Awasthi", "M.-F. Balcan", "P.M. Long" ],
      "venue" : null,
      "citeRegEx" : "Awasthi et al\\.,? \\Q2013\\E",
      "shortCiteRegEx" : "Awasthi et al\\.",
      "year" : 2013
    }, {
      "title" : "Learning changing concepts by exploiting the structure of change",
      "author" : [ "BBDK00. P.L. Bartlett", "S. Ben-David", "S.R. Kulkarni" ],
      "venue" : "Machine Learning,",
      "citeRegEx" : "Bartlett et al\\.,? \\Q2000\\E",
      "shortCiteRegEx" : "Bartlett et al\\.",
      "year" : 2000
    }, {
      "title" : "Agnostic active learning",
      "author" : [ "BBL06. M.F. Balcan", "A. Beygelzimer", "J. Langford" ],
      "venue" : "In Proc. of the 23rd International Conference on Machine Learning,",
      "citeRegEx" : "Balcan et al\\.,? \\Q2006\\E",
      "shortCiteRegEx" : "Balcan et al\\.",
      "year" : 2006
    }, {
      "title" : "Margin based active learning",
      "author" : [ "BBZ07. M.-F. Balcan", "A. Broder", "T. Zhang" ],
      "venue" : "In Proceedings of the 20 Conference on Learning Theory,",
      "citeRegEx" : "Balcan et al\\.,? \\Q2007\\E",
      "shortCiteRegEx" : "Balcan et al\\.",
      "year" : 2007
    }, {
      "title" : "On the complexity of learning from drifting distributions",
      "author" : [ "R.D. Barve", "P.M. Long" ],
      "venue" : "In Proceedings of the ninth annual conference on Computational learning theory,",
      "citeRegEx" : "Barve and Long.,? \\Q1996\\E",
      "shortCiteRegEx" : "Barve and Long.",
      "year" : 1996
    }, {
      "title" : "On the complexity of learning from drifting distributions",
      "author" : [ "BL97. R.D. Barve", "P.M. Long" ],
      "venue" : "Inf. Comput.,",
      "citeRegEx" : "Barve and Long.,? \\Q1997\\E",
      "shortCiteRegEx" : "Barve and Long.",
      "year" : 1997
    }, {
      "title" : "Active and passive learning of linear separators under log-concave distributions",
      "author" : [ "BL13. M.-F. Balcan", "P.M. Long" ],
      "venue" : "In Proceedings of the 26 Conference on Learning Theory,",
      "citeRegEx" : "Balcan and Long.,? \\Q2013\\E",
      "shortCiteRegEx" : "Balcan and Long.",
      "year" : 2013
    }, {
      "title" : "Concentration Inequalities",
      "author" : [ "S. Boucheron", "G. Lugosi", "P. Massart" ],
      "venue" : null,
      "citeRegEx" : "Boucheron et al\\.,? \\Q2013\\E",
      "shortCiteRegEx" : "Boucheron et al\\.",
      "year" : 2013
    }, {
      "title" : "Regret minimization with concept drift",
      "author" : [ "CMEDV10. K. Crammer", "Y. Mansour", "E. Even-Dar", "J. Wortman Vaughan" ],
      "venue" : "In COLT,",
      "citeRegEx" : "Crammer et al\\.,? \\Q2010\\E",
      "shortCiteRegEx" : "Crammer et al\\.",
      "year" : 2010
    }, {
      "title" : "Analysis of perceptron-based active learning",
      "author" : [ "S. Dasgupta", "A. Kalai", "C. Monteleoni" ],
      "venue" : "Journal of Machine Learning Research,",
      "citeRegEx" : "Dasgupta et al\\.,? \\Q2009\\E",
      "shortCiteRegEx" : "Dasgupta et al\\.",
      "year" : 2009
    }, {
      "title" : "Active learning via perfect selective classification",
      "author" : [ "EYW12. R. El-Yaniv", "Y. Wiener" ],
      "venue" : "Journal of Machine Learning Research,",
      "citeRegEx" : "El.Yaniv and Wiener.,? \\Q2012\\E",
      "shortCiteRegEx" : "El.Yaniv and Wiener.",
      "year" : 2012
    }, {
      "title" : "A bound on the label complexity of agnostic active learning",
      "author" : [ "Han07. S. Hanneke" ],
      "venue" : "In Proceedings of the 24 International Conference on Machine Learning,",
      "citeRegEx" : "Hanneke.,? \\Q2007\\E",
      "shortCiteRegEx" : "Hanneke.",
      "year" : 2007
    }, {
      "title" : "Activized learning: Transforming passive to active with improved label complexity",
      "author" : [ "Han12. S. Hanneke" ],
      "venue" : "Journal of Machine Learning Research,",
      "citeRegEx" : "Hanneke.,? \\Q2012\\E",
      "shortCiteRegEx" : "Hanneke.",
      "year" : 2012
    }, {
      "title" : "Tracking drifting concepts using random examples",
      "author" : [ "HL91. D.P. Helmbold", "P.M. Long" ],
      "venue" : "In COLT, pages",
      "citeRegEx" : "Helmbold and Long.,? \\Q1991\\E",
      "shortCiteRegEx" : "Helmbold and Long.",
      "year" : 1991
    }, {
      "title" : "Tracking drifting concepts by minimizing disagreements",
      "author" : [ "HL94. D.P. Helmbold", "P.M. Long" ],
      "venue" : "Machine Learning,",
      "citeRegEx" : "Helmbold and Long.,? \\Q1994\\E",
      "shortCiteRegEx" : "Helmbold and Long.",
      "year" : 1994
    }, {
      "title" : "Predicting {0, 1}-functions on randomly drawn points",
      "author" : [ "HLW94. D. Haussler", "N. Littlestone", "M. Warmuth" ],
      "venue" : "Information and Computation,",
      "citeRegEx" : "Haussler et al\\.,? \\Q1994\\E",
      "shortCiteRegEx" : "Haussler et al\\.",
      "year" : 1994
    }, {
      "title" : "Concise formulas for the area and volume of a hyperspherical cap",
      "author" : [ "Li11. S. Li" ],
      "venue" : "Asian Journal of Mathematics and Statistics,",
      "citeRegEx" : "Li.,? \\Q2011\\E",
      "shortCiteRegEx" : "Li.",
      "year" : 2011
    }, {
      "title" : "The complexity of learning according to two models of a drifting environment",
      "author" : [ "Lon99. P.M. Long" ],
      "venue" : "Machine Learning,",
      "citeRegEx" : "Long.,? \\Q1999\\E",
      "shortCiteRegEx" : "Long.",
      "year" : 1999
    }, {
      "title" : "Estimation of Dependencies Based on Empirical Data",
      "author" : [ "Vap82. V. Vapnik" ],
      "venue" : null,
      "citeRegEx" : "Vapnik.,? \\Q1982\\E",
      "shortCiteRegEx" : "Vapnik.",
      "year" : 1982
    }, {
      "title" : "Statistical Learning Theory",
      "author" : [ "Vap98. V. Vapnik" ],
      "venue" : null,
      "citeRegEx" : "Vapnik.,? \\Q1998\\E",
      "shortCiteRegEx" : "Vapnik.",
      "year" : 1998
    } ],
    "referenceMentions" : [ ],
    "year" : 2015,
    "abstractText" : "We study the problem of learning in the presence of a drifting target concept. Specifically, we provide bounds on the error rate at a given time, given a learner with access to a history of independent samples labeled according to a target concept that can change on each round. One of our main contributions is a refinement of the best previous results for polynomial-time algorithms for the space of linear separators under a uniform distribution. We also provide general results for an algorithm capable of adapting to a variable rate of drift of the target concept. Some of the results also describe an active learning variant of this setting, and provide bounds on the number of queries for the labels of points in the sequence sufficient to obtain the stated bounds on the error rates.",
    "creator" : "LaTeX with hyperref package"
  }
}