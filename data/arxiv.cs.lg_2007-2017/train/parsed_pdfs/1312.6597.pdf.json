{
  "name" : "1312.6597.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "Co-Multistage of Multiple Classifiers for Imbalanced Multiclass Learning",
    "authors" : [ ],
    "emails" : [ ],
    "sections" : [ {
      "heading" : "1 Introduction",
      "text" : "Many real-world classification tasks, such as email analysis [1,2,3], fraud detection [4], medical diagnostics [5,6], face recognition, discrimination aware classification [7], text classification [8,9,10], and species distribution [11] can have a highly skewed or imbalanced class distributions datasets. Theoretically, a dataset is defined to have a imbalanced distribution when at least one class has an unequal number of instances relative to others. However, the community restricts the definition of imbalanced to datasets showing high or extreme imbalanced rates. High imbalanced rates are the overarching issue for supervised machine learning algorithms. The first reported work focused on the multiclass imbalance problem [12], extended the G-mean metric [13] to multiclass problem. While previous work [14,15] on cost-sensitive learning for multiclass settings addresses the problem of multiclass imbalance, the cost matrix was already available or manually created for a two-class scenario based on the nature of the problem. This manual definition does not scale well to the multiple-class case, where manually finding cost values is a hard task.\nRecently, a review of imbalanced class problems [16] proposed a taxonomy for ensemble approaches to imbalanced binary class classification. Here, it is generalized to include multiclass classification and data pre-processing. As a result, it identifies three broad methodologies used to approach class imbalanced learning: Data Processing, Cost-Sensitive, and Hybrid. The data preprocessing techniques explored include resampling techniques to balance the class distribution. Among the resampling techniques are undersampling methods (e.g.: random undersampling), oversampling (e.g: random oversampling, SMOTE [17], and SMOTE variations such as MSMOTE [18], BorderLine-SMOTE [19]), and a combination of both (e.g.: SPIDER [20]) AdaCost [21], AdaC1,2,3 [12,22] are\nar X\niv :1\n31 2.\n65 97\nv2 [\ncs .L\nG ]\n2 4\nJa n\n20 14\n2 examples of cost-sensitive learning based on boosting. These methods are the state-of-art multiclass imbalanced learning. There are also cost-sensitive rule base systems [23]. The Hybrid category includes a combination of Boosting, Bagging, or both, with one or more data preprocessing techniques, e.g.: SMOTEBoost [24], SMOTEBagging [25], EasyEnsemble [26], and BalanceCascade [26].\nThe contributions of this work include two new models to deal with two different distributive classes topologies and a new evaluation metric. Both topologies have imbalanced multiclass data distribution. The number of imbalanced classes defines the difference between them. While CMC model assumes only one imbalance class, the CMC-M model is dedicated for data with several imbalance classes. With the second stochastic model, we improved imbalanced multiclass classification of datasets with multiple skewed majority classes. Since it extends the first model, it was called Co-Multistage of Multiple Classifiers for Multiple Skewed Classes (CMC-M ). It combines 1 binary view with 3 multiclass views of the data using 4 multistage ensemble classifiers [27].\nIn this document, the next section describes the CMC ; Section 3 presents the CMC-M ; Section 4 details the experimental setup with the respective results. The conclusions end the document.\n2 CMC : Co-Multistage of Multiple C lassifiers for Imbalanced Multiclass Learning\nCo-Multistage of Multiple Classifiers (CMC) is a new stochastic architectural model composed of 2 state-layers: binary and multiclass classification. Each layer has one multistage of multiple Classifiers (see Figure 1). Both layers have latent variables β and φ over classifiers to determine their activation in the multistage. We organized the layers in terms of complexity, i.e.: the first layer is the binary classifier which relaxes the problem to identify the majority class and then the second layer is multiclass classifier to identify primary the minority classes. As a result, the first layer is similar to the cascade learning framework for phishing detection [28], which is a binary classification problem. While the second layer is an extension of the cascade framework to multiclass classification problems.\nBefore applying the CMC method, it is necessary to generate two representations of the data in two label spaces (binary and multiclass). One keeps the original multiclass label space, while the other is binary. In the binary space (majority class vs. minority classes), all minority classes instances are relabeled to the minority class cluster label.\nThese two data representations are used to train two multistage classifiers. Each multistage classifier is an ensemble of individual classifiers [27,29]. At every stage, the classifier confidence or probability of the most likely class is compared with the latent variable threshold. If it is greater or equal, the process stops. Otherwise, the classifier at the next stage is applied to the instance. During training, all classifiers from both multistage classifiers can be trained in parallel. However, at classification time the binary multistage classifier is called first to decide whether it is a majority class. If the binary classifier is confident that it is\n3\na majority class, the classification stops, otherwise it continues to the multi-class multistage classifier.\nCMC assumes the following generative process for each label Y in a set of instances D and described by a set of features X:\n1. Choose βi ∈ ]0, 1], where i ∈ {1, ..., N} and N is the number of stages in the binary classification (default value is 1). 2. Choose Φi ∈ ]0, 1], where i ∈ {1, ..., Z} and Z is the number of stages in the multiclass classification (default value is 1). 3. For each label Yl, where l ∈ {1, ..., D} and D is the number of instances. (a) Choose Bi,l according to Equation 1; (b) Choose Mi,l according to Equa-\ntion 2; (c) Choose a label Yl to Equation 3\nP (B|X,β) = P (Bi,l|Xl) ∼ Bernoulli(βi) (1)\nwhere P (Bi,l|Xl) ≥ βi ∧(i = 1 ∨ P (Bi−1,l|Xl) < βi)\nP (M |X,Φ) = P (Mi,l|Xl) ∼Multinomial(Φi) (2)\nwhere P (Mi,l|Xl) ≥ Φi ∧ (i = 1 ∨ P (Mi−1,l|Xl) < Φi)\nYl = argmax c\n(P (Y | Xl,Mi,l, Φi, Bi,l, βi))\n= argmax c ({ P (B|X,β) if P (Bi,ζ) > P (Bi,ξ) P (M |X,Φ) otherwise ) (3)\nIn this work, we use the variables, e.g.: B and M , to represent both the probability distributions of the multistage classifiers and the classifiers. The dashed\n4 arrow in Figure 1 represents prevalence of the distribution of the parent variable over the child when a given a priori condition occurs (P (Bi,ζ) > P (Bi,ξ)). ζ represents the index of the majority class from the Bernoulli distribution generated by the binary multistage classifier B. Similarly, ξ is the index of the minority classes cluster from the same Bernoulli distribution.\n3 CMC-M : Co-Multistage of Multiple C lassifiers for Multiple Skewed Classes\nCo-Multistage of Multiple Classifiers for Multiple skewed classes (CMC-M ) is a new stochastic model to support datasets with multiple majority-skewed classes. CMC-M is an extended version of the CMC model, introduced in Section 2.\nAs Figure 2 shows, CMC-M is made of two layers containing four multistage ensemble of multiple classifiers. Both layers have latent variables (β, ξt) over classifiers to determine their activation in the multistage. The main differences between CMC and the CMC-M frameworks are the inclusion of two extra multistage classifiers on the top layer and the activation of bottom layer multistage classifier. The activation of the bottom layer classifier (M3) occurs when there is a disagreement in the quorum of the 3 top layer classifiers (B, M1, M2). More precisely when their probability distributions do not agree on the allocation of more probability mass to either a majority or minority class (Eq. 5).\nThe top layer requires three transformations of the label space. The first label transformation is to adapt for the binary classifier, that classifies an instance into majority or minority class. We cluster the labels into majority class and minority class clusters. Because the majority classes are skewed, they can be\n5 trivially identified by comparing with the expected optimal balance distribution for each class ( |D||Ȳ | where D is the set of instances and Y the set of labels).\nIn addition, the two multistage multiclass classifiers with reduced label space help in the decision. While one classifier generates a probability distribution for the majority class cluster and each minority class, the other classifier generates a probability distribution for the minority class cluster and each majority class. At the bottom layer is the default multistage multi-class classifier without changes in the label space (all labels). The bottom layer classifier distribution is used to recover from disagreements at the top layer.\nFormally, the CMC-M can be viewed as a generative process for each label Y in a set of instances D described by a set of features X:\n1. Choose βi ∈ ]0, 1], where i ∈ {1, ..., N} and N is the number of stages in the binary classification of majority cluster vs. minority cluster. The default value for βi is 1. 2. Choose ξti ∈ ]0, 1], where i ∈ {1, ..., Zj}, Zj is the number of stages in the multiclass classification, and j index the type multiclass classifier. Repeat the process for all j ∈ 1, 2, 3,. When t equals one, ξ1i are variables over the multiclass classification of the majority classes cluster versus each minority class. j equal to two defines the multiclass classification of the minority classes cluster vs each majority class. Finally, j equals to three shows the multiclass classification with all classes. 3. For each label Yl, where l ∈ {1, ..., D} and D is the number of instances. (a) Choose Bi,l based on Equation 1; (b) Choose M t i,l, for all t ∈ {1, 2, 3}\nbased on Equation 4; (c) Choose label Yl according to Equation 5.\nP (M t|X,φ) = P (M ti,l|X) ∼ Multinomial(ξti) (4)\nwhere P (M ti,l|Xl) ≥ ξti ∧(i = 1 ∨ P (Mi−1,l|Xl) < ξti)\nYl = argmax c (P (Y |X,M t, ξt, B, β)) = argmax c   P (M1|X, ξ1) if P (Bi,ζ) > P (Bi,φ) ∧P (M1i,γ) > P (M2i,Ω) P (M2|X, ξ2) if P (Bi,ζ) < P (Bi,φ) ∧P (M1i,γ) < P (M2i,Ω)\nP (M3|X, ξ3) otherwise  (5)\nAgain, to simplify the notation, we used the variables B, M1, M2, M3, to represent the probability distributions of both the multistage classifiers and the classifiers distributions. In addition, in Fig. 2 the dashed arrows represent the prevalence of distribution of the parent variable over the child under the conditions described in Eq. 5. ζ represents the index of the majority class from the Bernoulli distribution generated by the binary multistage classifier B. Similarly\n6 φ is the index of the minority classes cluster from the same Bernoulli distribution. While, γ and Ω are the indexes of the majority and minority class cluster distribution generated by the multinomial multistage classifiers M1 and M2."
    }, {
      "heading" : "4 Experimental Setup",
      "text" : "The classification results of the various algorithms are calculated using 80% of the dataset for training and 20% for testing. The initial evaluation included two datasets where the state-of-art cost sensitive method AdaC2 was performed. However the characteristics of the 2 UCI datasets did not allow to extensively stress our methods in the presence of a higher number of classes, namely skewed majority classes. For this purpose, we added three extra datasets from text classification tasks.\nBoth CMC and CMC-M have multistage ensemble of multiple individual classifiers. All classifier follow an architecture made of three classifiers with default parameters values, except the first. The sequence of classifiers in the multistage ensembles follows one heuristic. It starts with the simplest/weakest classifier and continues till the most complex/strongest. The current order was determined experiments by evaluating each heterogeneous classifier individually. The classifiers heterogeneity also improves imbalanced classification [30].\nThe first classifier is a Random Forest (RF) with 100 trees. The second corresponds to the SMO SVM with polynomial kernel and logistic probabilistic models. The last classifier is the ensemble of the previous two classifiers. It selects the classifier with higher probability or confidence value. There are several reasons that justify choosing both RF and SVM as base multistage classifiers. In the literature, it is not rare to find SVMs as the best performing supervised classifiers (specially in large feature spaces, e.g.: > 1000 features per instances). Furthermore, they explore the whole feature space by introducing support vectors that describe the hyperplanes. Such hyperplanes divide the data by maximizing the distance between examples of different classes. Conversely, the RF selects random subsets of features to avoid the overfitting problem. Random feature selections is the simplest feature selection method [31,32,33,7]. The runtime complexity of both architectures is in the worst case the complexity of the SMO classifier O(L · n), where is n is the training sample size and L is the average number of (candidate) support vectors."
    }, {
      "heading" : "4.1 Datasets",
      "text" : "We started our evaluation with two publicly available datasets at the UCI ML Repository to compare our work with the state-of-art [12]. The Car Evaluation dataset is one of the most popular datasets in the UCI ML Repository. It contains 1728 instances described by 6 nominal ordered attributes. The NewThyroid dataset was built to predict patients’ thyroid level class. This corresponds to three classes: euthyroidism (normal), hypothyroidism, and hyperthyroidism. This is a small dataset with 215 examples of patients, each described\n7 by five attributes. The normal class corresponds to the most frequent class, with 69.77%. But these datasets hardly captures the several skewed majority classes problem. As a result, we included 4 extra datasets from text classification task. Data sets fbis, tr21, and news3 are derived from the TREC-5/6/7. The features included were stemmed word counts and stopword words were removed. Finally, we built our own large dataset using ACE 2005 dataset and 27 events classes1 to show the weakness of G-mean and propose alternatives. This dataset has 1 very skew class, no event, and several classes with few instances per class (< 50 instances)."
    }, {
      "heading" : "4.2 Results",
      "text" : "First, we evaluated CMC on two UCI datasets to compare with state-of-art methods [12]: Adaboost.M1 over decision tree C4.5 as weak classifier and AdaC2.M1 over C4.5 (cost-sensitive baseline). The cost setups of AdaC2 (short for AdaC2.M1) are predicted by a Genetic Algorithm. The results of C4.5 were also included to complement the baseline information. In addition to the cost-sensitive baseline, we also report the combination of our new CMC and CMC-M methods with preprocessing methods, as they benefit some classifier, e.g.: SVM [34,35]. For this purpose, we selected all minority classes and oversampled them using SMOTE with the default proposed configuration of 5 nearest neighbors and a new instance per each minority classes instance. This means that we increased by a factor of two the number of minority classes instances. Then, we undersampled the dataset to 90% of the original size with bias to a balanced distribution by randomly subsampling with replacement. In general the undersampling to 90% of the original size yields better results than other resampling percentages in our preliminary experiments with one skewed class. Even so, 90% is suboptimal value when there is 2 or more skewed class, e.g.: undersampling to 79% of the fbis dataset yielded better results than the performance of CMC-M with 90% undersampling (F1-Macro: 0.621, G-Mean: 0.626). However, fine tuning the undersampling G-mean metric [13] yielded very small improvements. The first dataset used in our evaluation is the Car evaluation. It has one majority class (unacceptable), which is the condition necessary to apply our CMC model. Table 1 reports the experiments on Car dataset. The combination of undersampling with CMC, (CMC (U.)) improved G-Mean by 10.3% points, while the SMOTE lowers the results by 2%. The interpretation of why SMOTE lowers the results in some datasets is on the decision region for the minority class that can actually become smaller and more specific as the number of minority samples increases. But at the same time it is also prone to learn incorrect boundaries when the new synthetic samples are incorrectly labeled as minority instances. Furthermore, Gmean of CMC (U.) is 5.1% points higher than the best baseline model AdaC2 with cost vector [0.541, 0.823, 0754, 1.000]. Also, the smallest minority class (very good) is fully identified without any error (F1 = 100%). The New-Thyroid dataset has less one class than Cars and one skewed majority class (normal).\n1 http://to.disclose.after.review.process\n8\nTable 1 shows that undersampling improved CMC G-Mean values by + 1.3% and 6.8%. While oversampled CMC (O.) reduces the G-mean results by 3.3%. However, despite the reduction of performance cause by SMOTE oversampling, these results are still above the best baseline (+ 2.1%) AdaC2 (cost vector: [0.421, 0.626, 1.000]). The rationale for the results of CMC (O.U.) (CMC with SMOTE oversampling and undersampling) and CMC (without sampling preprocessing) being about the same is justified by two reasons. First, it is the small size of the data that limits the application of the oversampling leading to the generation of bad data points and limiting the undersampling gains. Consequently, we opted to analyze the performance of CMC-M in two additional datasets from TREC evaluation. These datasets have two or more skewed majority classes, a larger number of classes and features. In addition, we included, a third dataset with one majority class, tr21 ) to analyze the performance of CMC with more classes and a larger feature space.\nFor the remaining datasets Adabost.M1 was selected as baseline method. Both AdaC2 and C4.5 were replaced with the results of the two classifiers used by the multistage classifier. This reduces redundancy of including C4.5 results and the unavailability of standard AdaC2 implementation.\nAfter comparing the results on Tables 2, 1, we find that CMC (U.) has again the best overall performance. The tr21 is another dataset with one imbalanced class (class label 251 corresponds to 68.8% of the dataset). Both the Random Forest (RF) and the Adaboost.M1 baselines failed to identify one class. As a result, G-Mean values were equal to 0.000. Another interesting results drawn from Table 2 are the absolute improvements of F1 (+5.9%) of CMC (O.U.) over CMC. These results are justified by improvements of precision of some of the minority classes. These improvements are obtained at the expense of misclassifying and reducing the recall of other less frequent minority classes as the lower G-Mean (-4.6%) indicates. The following tables 3 and 4 were generated\n9 using 2 datasets with multiple skewed classes to enabled a better understanding of both CMC-M and CMC methods.\nWith the 4 majority classes and 13 minority classes, it was expectable that CMC-M outperformed CMC on fbis as observed. To clarify this assumption, we shall note that only three majority classes are skewed, with a representation of 20.5%, 15.7%, and 14.5% of the fbis dataset. The fourth majority class is slightly skewed with representation of 7.7% of the fbis dataset and the average class representation is 5.9%. The slightly skewness of the fourth majority class is not taken into account by our methods.\nThe data sparsity is frequently found in supervised learning tasks with large number of features, such as text classification. The fbis dataset with a feature set made of 2000 is a example of a text classification sparse dataset. Naturally, oversampling methods are more useful in the presence of data sparsity because they will fill empty spaces. Otherwise, those classification spaces would be empty and lead to misclassification. At the same time, undersampling of the majority classes in large feature spaces can reinforces the data sparsity because undersampling of the majority classes explores the removal of redundancy which might not not exist in small/medium datasets (e.g.: < 1,000,000 instances). The consequence is the reduction of the classifier performance, unless the classes are very easily separable and the dataset distribution becomes balanced. Based on these assumptions, it is not surprising to observe that CMC-M (O.) outperforms CMCM with regard to G-Mean improving it 0.6%. The results of CMC-M (U.) and CMC-M (O.U.) confirmed again the previous assumptions about the prejudicial effect of undersampling to datasets with large number of classes and features. The poor performance of CMC-M (O.U.) might be justified by the combination of two side effects of both oversampling and undersampling. First is the inclusion of some new incorrectly classified minority classes instances, and removal of known and non-redundant majority class instances, mislead the classifiers into identifying less precise decision boundaries. The last dataset used in our\nexperiments was news3. With nearly 10,000 instances and 27,000 features has five times more instances and about fourteen times more features than the fbis dataset. At the same time, the number of classes is 44, that makes it the dataset with largest number of classes used in our evaluation. From the 44 classes, we identified 15 majority classes(2.3% of the dataset). But, only 3 classes of the 15 majority classes are above for example twice the average number of instances per class with 5.9%, 7.3%, and 5.1% of the dataset. Thus, we believe that it would be useful to have a more fine-grained distinction of classes distribution than just two\n10\ntypes: majority and minority class found in the literature allow. For example, a ternary categorization made of majority (|yi| > 2 × Ȳ ), minority (|yi| < 14 Ȳ ), intermediate (14 Ȳ < |Yi| < 2 × Ȳ ) classes. Still, we assumed the 15 most frequent classes as majority classes and the remaining as minority classes in our experiments using the news3. Table 4 shows the results of those experiments. Those results confirmed that undersampling reduced CMC-M overall performance by 4.4%. At the same time, we also observed another expectable results about oversampling. As the number of features, instances, and classes grows, it is hard to generate new points because they need to be at the same time relevant, correctly labeled, and should not collide with other classes data points. However, these properties are not guaranteed by oversampling techniques, such as SMOTE. Therefore, we did not observe improvements of applying oversampling before CMC-M in this dataset. Indeed, the G-mean differences between CMC-M (O.) and CMC-M were found not to be statistically significant. However, both versions of CMC-M are statistically significative better than the baselines. The\nCMC improves the recall on the ACE dataset at the expense of losing some precision at the detection of the majority classe(s) - in this case the no-event. But CMC (O.U.) enabled us to detect 26 event classes, where the baseline methods\nonly detect 2 and 19 . Translating to SG-Mean = ( ∏n i=1Ri + δ) 1 n , δ > 0 - smooth G-Mean with δ = 0.001) improvement of about 183 and 6 times more."
    }, {
      "heading" : "5 Conclusions",
      "text" : "In this paper, we presented 2 new stochastic models to increase the robustness of imbalanced multiclass learning. These 2 models explore different classes topologies. The first model, CMC, improves imbalanced multiclass learning with one\n11\nskew majority class state-of-art. The literature does not provide a clear distinction between majority and minority classes for imbalanced multiclass classification. One of the possible reasons for this gap is in focus on the binary case as 3 recent surveys about imbalanced learning [16,36,37] claim. Another justification is that most research works focused on datasets with few classes, where a precise distinction between majority classes and minority classes is not necessary. Thus, in this work, we formally defined the distinction between majority class (|yi| > Ȳ ) and minority class (|yi| ≤ Ȳ ) as a class whose number of instances is higher or lower than the average Another contribution of this work is the creation of imbalanced multiclass learning models for datasets having small and large number of both classes and features. For example, the CMC-M was designed for imbalanced multiclass learning of large number of classes.\nThe overall absolute improvements (G-Mean) of the CMC combined with undersampling over the best baseline (AdaC2 ) ranged between +5% and +7%. A small percentage of undersampling based on random majority class selection bias towards the balanced distribution with replacement, clearly helps the CMC model. Caused by the reduction of the imbalanced distribution towards the unique majority class. However, the undersampling effect is not always beneficial. For instance, it reduces the CMC-M performance in the presence of several majority classes. This reduction occurs because undersampling of the majority classes in large feature spaces can reinforces the data sparsity because undersampling of the majority classes explores the removal of redundancy which might not not exist in small/medium datasets. The consequence is the reduction of the classifier performance, unless the classes are very easily separable and the dataset distribution becomes balanced. The reduction of performance of the classifier is also observable internally in the reduction of agreement between binary classifier and two top layer multi-class classifiers.\nFinally, SMOTE improves CMC-M results for small datasets, such as fbis, but it should not be used for large datasets, e.g.: new3, unless there are classes with very few instances e.g.: ACE 2005. Namely for datasets with classes with few instances, it is possible to observe a recall values equal to zero. Therefore, we have also proposed a new evaluation metric SG-Mean.\nIn future work, we will investigate the expansion of the CMC-M architecture to include a ternary representation of classes distribution."
    } ],
    "references" : [ {
      "title" : "On effective e-mail classification via neural networks,",
      "author" : [ "B. Cui", "A. Mondal", "J. Shen", "G. Cong", "K.-L. Tan" ],
      "venue" : "Database and Exp. Systems Appl.,",
      "citeRegEx" : "1",
      "shortCiteRegEx" : "1",
      "year" : 2005
    }, {
      "title" : "Promail: Using progressive email social network for spam detection,",
      "author" : [ "C.-Y. Tseng", "J.-W. Huang", "M.-S. Chen" ],
      "venue" : "Advances in KDD Mining,",
      "citeRegEx" : "2",
      "shortCiteRegEx" : "2",
      "year" : 2007
    }, {
      "title" : "Link spam target detection using page farms,",
      "author" : [ "B. Zhou", "J. Pei" ],
      "venue" : "TKDD,",
      "citeRegEx" : "3",
      "shortCiteRegEx" : "3",
      "year" : 2009
    }, {
      "title" : "Mining impact-targeted activity patterns in imbalanced data,",
      "author" : [ "L. Cao", "Y. Zhao", "C. Zhang" ],
      "venue" : "IEEE TKDE, vol. 20,",
      "citeRegEx" : "4",
      "shortCiteRegEx" : "4",
      "year" : 2008
    }, {
      "title" : "Test strategies for cost-sensitive decision trees,",
      "author" : [ "S. Sheng", "C.X. Ling", "Q. Yang" ],
      "venue" : null,
      "citeRegEx" : "5",
      "shortCiteRegEx" : "5",
      "year" : 2006
    }, {
      "title" : "Discrimination-aware classification for imbalanced datasets,",
      "author" : [ "G. Ristanoski", "W. Liu", "J. Bailey" ],
      "venue" : null,
      "citeRegEx" : "7",
      "shortCiteRegEx" : "7",
      "year" : 2013
    }, {
      "title" : "Automatic web-page classification by using machine learning methods,",
      "author" : [ "M. Tsukada", "T. Washio", "H. Motoda" ],
      "venue" : "Web Intelligence: R.D.,",
      "citeRegEx" : "8",
      "shortCiteRegEx" : "8",
      "year" : 2001
    }, {
      "title" : "Text classification without labeled negative documents,",
      "author" : [ "G.P.C. Fung", "J.X. Yu", "H. Lu", "P.S. Yu" ],
      "venue" : null,
      "citeRegEx" : "9",
      "shortCiteRegEx" : "9",
      "year" : 2005
    }, {
      "title" : "A balanced ensemble approach to weighting classifiers for text classification,",
      "author" : [ "G.P.C. Fung", "J. Yu", "H. Wang", "D. Cheung", "H. Liu" ],
      "venue" : null,
      "citeRegEx" : "10",
      "shortCiteRegEx" : "10",
      "year" : 2006
    }, {
      "title" : "Species distribution modeling and prediction: A class imbalance problem,",
      "author" : [ "R. Johnson", "N. Chawla", "J. Hellmann" ],
      "venue" : "CIDU,",
      "citeRegEx" : "11",
      "shortCiteRegEx" : "11",
      "year" : 2012
    }, {
      "title" : "Boosting for learning multiple classes with imbalanced class distribution,",
      "author" : [ "Y. Sun", "M. Kamel", "Y. Wang" ],
      "venue" : "in Proc. of ICDM’06",
      "citeRegEx" : "12",
      "shortCiteRegEx" : "12",
      "year" : 2006
    }, {
      "title" : "Addressing the curse of imbalanced training sets: one-sided selection,",
      "author" : [ "M. Kubat", "S. Matwin" ],
      "venue" : "in Proc. of ICML,",
      "citeRegEx" : "13",
      "shortCiteRegEx" : "13",
      "year" : 1997
    }, {
      "title" : "An iterative method for multi-class costsensitive learning,",
      "author" : [ "N. Abe", "B. Zadrozny", "J. Langford" ],
      "venue" : "in Proc. of ACM SIGKDD. ACM,",
      "citeRegEx" : "14",
      "shortCiteRegEx" : "14",
      "year" : 2004
    }, {
      "title" : "On multi-class cost-sensitive learning,",
      "author" : [ "Z. Zhou", "X. Liu" ],
      "venue" : "Proceedings of the National Conference on Artificial Intelligence,",
      "citeRegEx" : "15",
      "shortCiteRegEx" : "15",
      "year" : 2006
    }, {
      "title" : "Smote: Synthetic minority oversampling technique,",
      "author" : [ "N. Chawla", "K. Bowyer", "L. Hall", "W. Kegelmeyer" ],
      "venue" : "JAIR, vol",
      "citeRegEx" : "17",
      "shortCiteRegEx" : "17",
      "year" : 2002
    }, {
      "title" : "MSMOTE: Improving classification performance when training data is imbalanced,",
      "author" : [ "S. Hu", "Y. Liang", "L. Ma", "Y. He" ],
      "venue" : "in WCSE’09. IEEE,",
      "citeRegEx" : "18",
      "shortCiteRegEx" : "18",
      "year" : 2009
    }, {
      "title" : "Borderline-smote: A new over-sampling method in imbalanced data sets learning,",
      "author" : [ "H. Han", "W.-Y. Wang", "B.-H. Mao" ],
      "venue" : "Adv. in Intell. Computing,",
      "citeRegEx" : "19",
      "shortCiteRegEx" : "19",
      "year" : 2005
    }, {
      "title" : "Selective pre-processing of imbalanced data for improving classification performance,",
      "author" : [ "J. Stefanowski", "S. Wilk" ],
      "venue" : "Data Ware. and K.D., pp",
      "citeRegEx" : "20",
      "shortCiteRegEx" : "20",
      "year" : 2008
    }, {
      "title" : "Adacost: misclassification costsensitive boosting,",
      "author" : [ "W. Fan", "S.J. Stolfo", "J. Zhang", "P.K. Chan" ],
      "venue" : "in ICML,",
      "citeRegEx" : "21",
      "shortCiteRegEx" : "21",
      "year" : 1999
    }, {
      "title" : "Cost-sensitive boosting for classification of imbalanced data,",
      "author" : [ "Y. Sun", "M.S. Kamel", "A.K. Wong", "Y. Wang" ],
      "venue" : "Pattern Recognition,",
      "citeRegEx" : "22",
      "shortCiteRegEx" : "22",
      "year" : 2007
    }, {
      "title" : "An imbalanced data rule learner,",
      "author" : [ "C.H. Nguyen", "T. Ho" ],
      "venue" : null,
      "citeRegEx" : "23",
      "shortCiteRegEx" : "23",
      "year" : 2005
    }, {
      "title" : "Smoteboost: Improving prediction of the minority class in boosting,",
      "author" : [ "N. Chawla", "A. Lazarevic", "L. Hall", "K. Bowyer" ],
      "venue" : "PKDD",
      "citeRegEx" : "24",
      "shortCiteRegEx" : "24",
      "year" : 2003
    }, {
      "title" : "Diversity analysis on imbalanced data sets by using ensemble models,",
      "author" : [ "S. Wang", "X. Yao" ],
      "venue" : "IEEE Symposium CIDM ’09,",
      "citeRegEx" : "25",
      "shortCiteRegEx" : "25",
      "year" : 2009
    }, {
      "title" : "Exploratory undersampling for class-imbalance learning,",
      "author" : [ "X. Liu", "J. Wu", "Z. Zhou" ],
      "venue" : "IEEE TSMC, Part B,",
      "citeRegEx" : "26",
      "shortCiteRegEx" : "26",
      "year" : 2009
    }, {
      "title" : "Multistage pattern recognition with reject option,",
      "author" : [ "P. Pudil", "J. Novovicova", "S. Blaha", "J. Kittler" ],
      "venue" : "Proceedings of 11th IAPR. IEEE,",
      "citeRegEx" : "27",
      "shortCiteRegEx" : "27",
      "year" : 1992
    }, {
      "title" : "Toward a phish free world,",
      "author" : [ "G. Xiang" ],
      "venue" : "Ph.D. dissertation,",
      "citeRegEx" : "28",
      "shortCiteRegEx" : "28",
      "year" : 2013
    }, {
      "title" : "Building multiclass classifiers for remote homology detection and fold recognition,",
      "author" : [ "H. Rangwala", "G. Karypis" ],
      "venue" : "BMC bioinformatics,",
      "citeRegEx" : "29",
      "shortCiteRegEx" : "29",
      "year" : 2006
    }, {
      "title" : "An empirical study of applying ensembles of heterogeneous classifiers on imperfect data,",
      "author" : [ "K.-W. Hsu", "J. Srivastava" ],
      "venue" : "ser. PAKDD’09,",
      "citeRegEx" : "30",
      "shortCiteRegEx" : "30",
      "year" : 2010
    }, {
      "title" : "Active feature selection using classes,",
      "author" : [ "H. Liu", "L. Yu", "M. Dash", "H. Motoda" ],
      "venue" : "Advances in Knowledge Discovery and Data Mining,",
      "citeRegEx" : "31",
      "shortCiteRegEx" : "31",
      "year" : 2003
    }, {
      "title" : "A novel recommendation method based on rough set and integrated feature mining,",
      "author" : [ "V. Tseng", "J.-H. Su", "B.-W. Wang", "C.-Y. Hsiao" ],
      "venue" : "ICICIC",
      "citeRegEx" : "32",
      "shortCiteRegEx" : "32",
      "year" : 2008
    }, {
      "title" : "An effective attribute clustering approach for feature selection and replacement.",
      "author" : [ "T.-P. Hong", "P.-C. Wang", "Y.-C. Lee" ],
      "venue" : "Cybernetics and Systems,",
      "citeRegEx" : "33",
      "shortCiteRegEx" : "33",
      "year" : 2009
    }, {
      "title" : "Boosting prediction accuracy on imbalanced datasets with svm ensembles,",
      "author" : [ "Y. Liu", "A. An", "X. Huang" ],
      "venue" : "Advances in KDD Mining,",
      "citeRegEx" : "34",
      "shortCiteRegEx" : "34",
      "year" : 2006
    }, {
      "title" : "A study of the behavior of several methods for balancing machine learning training data,",
      "author" : [ "G. Batista", "R.C. Prati", "M.C. Monard" ],
      "venue" : "SIGKDD Explor. N.,",
      "citeRegEx" : "35",
      "shortCiteRegEx" : "35",
      "year" : 2004
    }, {
      "title" : "Learning from imbalanced data,",
      "author" : [ "H. He", "E.A. Garcia" ],
      "venue" : "IEEE TKDE,",
      "citeRegEx" : "36",
      "shortCiteRegEx" : "36",
      "year" : 2009
    }, {
      "title" : "Classification of imbalanced data: A review,",
      "author" : [ "Y. Sun", "A.K. Wong", "S.K. Mohamed" ],
      "venue" : "Inter. Journal of Pattern Recog. and A.I.,",
      "citeRegEx" : "37",
      "shortCiteRegEx" : "37",
      "year" : 2009
    } ],
    "referenceMentions" : [ {
      "referenceID" : 0,
      "context" : "Many real-world classification tasks, such as email analysis [1,2,3], fraud detection [4], medical diagnostics [5,6], face recognition, discrimination aware classification [7], text classification [8,9,10], and species distribution [11] can have a highly skewed or imbalanced class distributions datasets.",
      "startOffset" : 61,
      "endOffset" : 68
    }, {
      "referenceID" : 1,
      "context" : "Many real-world classification tasks, such as email analysis [1,2,3], fraud detection [4], medical diagnostics [5,6], face recognition, discrimination aware classification [7], text classification [8,9,10], and species distribution [11] can have a highly skewed or imbalanced class distributions datasets.",
      "startOffset" : 61,
      "endOffset" : 68
    }, {
      "referenceID" : 2,
      "context" : "Many real-world classification tasks, such as email analysis [1,2,3], fraud detection [4], medical diagnostics [5,6], face recognition, discrimination aware classification [7], text classification [8,9,10], and species distribution [11] can have a highly skewed or imbalanced class distributions datasets.",
      "startOffset" : 61,
      "endOffset" : 68
    }, {
      "referenceID" : 3,
      "context" : "Many real-world classification tasks, such as email analysis [1,2,3], fraud detection [4], medical diagnostics [5,6], face recognition, discrimination aware classification [7], text classification [8,9,10], and species distribution [11] can have a highly skewed or imbalanced class distributions datasets.",
      "startOffset" : 86,
      "endOffset" : 89
    }, {
      "referenceID" : 4,
      "context" : "Many real-world classification tasks, such as email analysis [1,2,3], fraud detection [4], medical diagnostics [5,6], face recognition, discrimination aware classification [7], text classification [8,9,10], and species distribution [11] can have a highly skewed or imbalanced class distributions datasets.",
      "startOffset" : 111,
      "endOffset" : 116
    }, {
      "referenceID" : 5,
      "context" : "Many real-world classification tasks, such as email analysis [1,2,3], fraud detection [4], medical diagnostics [5,6], face recognition, discrimination aware classification [7], text classification [8,9,10], and species distribution [11] can have a highly skewed or imbalanced class distributions datasets.",
      "startOffset" : 172,
      "endOffset" : 175
    }, {
      "referenceID" : 6,
      "context" : "Many real-world classification tasks, such as email analysis [1,2,3], fraud detection [4], medical diagnostics [5,6], face recognition, discrimination aware classification [7], text classification [8,9,10], and species distribution [11] can have a highly skewed or imbalanced class distributions datasets.",
      "startOffset" : 197,
      "endOffset" : 205
    }, {
      "referenceID" : 7,
      "context" : "Many real-world classification tasks, such as email analysis [1,2,3], fraud detection [4], medical diagnostics [5,6], face recognition, discrimination aware classification [7], text classification [8,9,10], and species distribution [11] can have a highly skewed or imbalanced class distributions datasets.",
      "startOffset" : 197,
      "endOffset" : 205
    }, {
      "referenceID" : 8,
      "context" : "Many real-world classification tasks, such as email analysis [1,2,3], fraud detection [4], medical diagnostics [5,6], face recognition, discrimination aware classification [7], text classification [8,9,10], and species distribution [11] can have a highly skewed or imbalanced class distributions datasets.",
      "startOffset" : 197,
      "endOffset" : 205
    }, {
      "referenceID" : 9,
      "context" : "Many real-world classification tasks, such as email analysis [1,2,3], fraud detection [4], medical diagnostics [5,6], face recognition, discrimination aware classification [7], text classification [8,9,10], and species distribution [11] can have a highly skewed or imbalanced class distributions datasets.",
      "startOffset" : 232,
      "endOffset" : 236
    }, {
      "referenceID" : 10,
      "context" : "The first reported work focused on the multiclass imbalance problem [12], extended the G-mean metric [13] to multiclass problem.",
      "startOffset" : 68,
      "endOffset" : 72
    }, {
      "referenceID" : 11,
      "context" : "The first reported work focused on the multiclass imbalance problem [12], extended the G-mean metric [13] to multiclass problem.",
      "startOffset" : 101,
      "endOffset" : 105
    }, {
      "referenceID" : 12,
      "context" : "While previous work [14,15] on cost-sensitive learning for multiclass settings addresses the problem of multiclass imbalance, the cost matrix was already available or manually created for a two-class scenario based on the nature of the problem.",
      "startOffset" : 20,
      "endOffset" : 27
    }, {
      "referenceID" : 13,
      "context" : "While previous work [14,15] on cost-sensitive learning for multiclass settings addresses the problem of multiclass imbalance, the cost matrix was already available or manually created for a two-class scenario based on the nature of the problem.",
      "startOffset" : 20,
      "endOffset" : 27
    }, {
      "referenceID" : 14,
      "context" : "g: random oversampling, SMOTE [17], and SMOTE variations such as MSMOTE [18], BorderLine-SMOTE [19]), and a combination of both (e.",
      "startOffset" : 30,
      "endOffset" : 34
    }, {
      "referenceID" : 15,
      "context" : "g: random oversampling, SMOTE [17], and SMOTE variations such as MSMOTE [18], BorderLine-SMOTE [19]), and a combination of both (e.",
      "startOffset" : 72,
      "endOffset" : 76
    }, {
      "referenceID" : 16,
      "context" : "g: random oversampling, SMOTE [17], and SMOTE variations such as MSMOTE [18], BorderLine-SMOTE [19]), and a combination of both (e.",
      "startOffset" : 95,
      "endOffset" : 99
    }, {
      "referenceID" : 17,
      "context" : ": SPIDER [20]) AdaCost [21], AdaC1,2,3 [12,22] are ar X iv :1 31 2.",
      "startOffset" : 9,
      "endOffset" : 13
    }, {
      "referenceID" : 18,
      "context" : ": SPIDER [20]) AdaCost [21], AdaC1,2,3 [12,22] are ar X iv :1 31 2.",
      "startOffset" : 23,
      "endOffset" : 27
    }, {
      "referenceID" : 10,
      "context" : ": SPIDER [20]) AdaCost [21], AdaC1,2,3 [12,22] are ar X iv :1 31 2.",
      "startOffset" : 39,
      "endOffset" : 46
    }, {
      "referenceID" : 19,
      "context" : ": SPIDER [20]) AdaCost [21], AdaC1,2,3 [12,22] are ar X iv :1 31 2.",
      "startOffset" : 39,
      "endOffset" : 46
    }, {
      "referenceID" : 20,
      "context" : "There are also cost-sensitive rule base systems [23].",
      "startOffset" : 48,
      "endOffset" : 52
    }, {
      "referenceID" : 21,
      "context" : ": SMOTEBoost [24], SMOTEBagging [25], EasyEnsemble [26], and BalanceCascade [26].",
      "startOffset" : 13,
      "endOffset" : 17
    }, {
      "referenceID" : 22,
      "context" : ": SMOTEBoost [24], SMOTEBagging [25], EasyEnsemble [26], and BalanceCascade [26].",
      "startOffset" : 32,
      "endOffset" : 36
    }, {
      "referenceID" : 23,
      "context" : ": SMOTEBoost [24], SMOTEBagging [25], EasyEnsemble [26], and BalanceCascade [26].",
      "startOffset" : 51,
      "endOffset" : 55
    }, {
      "referenceID" : 23,
      "context" : ": SMOTEBoost [24], SMOTEBagging [25], EasyEnsemble [26], and BalanceCascade [26].",
      "startOffset" : 76,
      "endOffset" : 80
    }, {
      "referenceID" : 24,
      "context" : "It combines 1 binary view with 3 multiclass views of the data using 4 multistage ensemble classifiers [27].",
      "startOffset" : 102,
      "endOffset" : 106
    }, {
      "referenceID" : 25,
      "context" : "As a result, the first layer is similar to the cascade learning framework for phishing detection [28], which is a binary classification problem.",
      "startOffset" : 97,
      "endOffset" : 101
    }, {
      "referenceID" : 24,
      "context" : "Each multistage classifier is an ensemble of individual classifiers [27,29].",
      "startOffset" : 68,
      "endOffset" : 75
    }, {
      "referenceID" : 26,
      "context" : "Each multistage classifier is an ensemble of individual classifiers [27,29].",
      "startOffset" : 68,
      "endOffset" : 75
    }, {
      "referenceID" : 27,
      "context" : "The classifiers heterogeneity also improves imbalanced classification [30].",
      "startOffset" : 70,
      "endOffset" : 74
    }, {
      "referenceID" : 28,
      "context" : "Random feature selections is the simplest feature selection method [31,32,33,7].",
      "startOffset" : 67,
      "endOffset" : 79
    }, {
      "referenceID" : 29,
      "context" : "Random feature selections is the simplest feature selection method [31,32,33,7].",
      "startOffset" : 67,
      "endOffset" : 79
    }, {
      "referenceID" : 30,
      "context" : "Random feature selections is the simplest feature selection method [31,32,33,7].",
      "startOffset" : 67,
      "endOffset" : 79
    }, {
      "referenceID" : 5,
      "context" : "Random feature selections is the simplest feature selection method [31,32,33,7].",
      "startOffset" : 67,
      "endOffset" : 79
    }, {
      "referenceID" : 10,
      "context" : "We started our evaluation with two publicly available datasets at the UCI ML Repository to compare our work with the state-of-art [12].",
      "startOffset" : 130,
      "endOffset" : 134
    }, {
      "referenceID" : 10,
      "context" : "First, we evaluated CMC on two UCI datasets to compare with state-of-art methods [12]: Adaboost.",
      "startOffset" : 81,
      "endOffset" : 85
    }, {
      "referenceID" : 31,
      "context" : ": SVM [34,35].",
      "startOffset" : 6,
      "endOffset" : 13
    }, {
      "referenceID" : 32,
      "context" : ": SVM [34,35].",
      "startOffset" : 6,
      "endOffset" : 13
    }, {
      "referenceID" : 11,
      "context" : "However, fine tuning the undersampling G-mean metric [13] yielded very small improvements.",
      "startOffset" : 53,
      "endOffset" : 57
    }, {
      "referenceID" : 33,
      "context" : "One of the possible reasons for this gap is in focus on the binary case as 3 recent surveys about imbalanced learning [16,36,37] claim.",
      "startOffset" : 118,
      "endOffset" : 128
    }, {
      "referenceID" : 34,
      "context" : "One of the possible reasons for this gap is in focus on the binary case as 3 recent surveys about imbalanced learning [16,36,37] claim.",
      "startOffset" : 118,
      "endOffset" : 128
    } ],
    "year" : 2014,
    "abstractText" : "In this work, we propose two stochastic architectural models (CMC and CMC-M ) with two layers of classifiers applicable to datasets with one and multiple skewed classes. This distinction becomes important when the datasets have a large number of classes. Therefore, we present a novel solution to imbalanced multiclass learning with several skewed majority classes, which improves minority classes identification. This fact is particularly important for text classification tasks, such as event detection. Our models combined with preprocessing sampling techniques improved the classification results on 6 well-known datasets. Finally, we have also introduced a new metric SG-Mean to overcome the multiplication by zero limitation of G-Mean.",
    "creator" : "LaTeX with hyperref package"
  }
}