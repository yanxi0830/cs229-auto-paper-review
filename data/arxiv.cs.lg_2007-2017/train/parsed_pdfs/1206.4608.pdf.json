{
  "name" : "1206.4608.pdf",
  "metadata" : {
    "source" : "META",
    "title" : "A Hybrid Algorithm for Convex Semidefinite Optimization",
    "authors" : [ "Sören Laue" ],
    "emails" : [ "soeren.laue@uni-jena.de" ],
    "sections" : [ {
      "heading" : "1. Introduction",
      "text" : "We consider the following unconstrained semidefinite optimization problem:\nmin f(X) s.t. X 0 , (1)\nwhere f(X) : Rn×n → R is a convex and differentiable function over the cone of positive semidefinite matrices. Many machine learning problems can be cast as a semidefinite optimization problem. Prominent examples include sparse PCA (d’Aspremont et al., 2007), distance metric learning (Xing et al., 2002), nonlinear dimensionality reduction (Weinberger et al., 2006), multiple kernel learning (Lanckriet et al., 2004), multitask learning (Obozinski et al., 2010), and matrix completion (Srebro et al., 2004).\nWe provide an algorithm that solves general large-scale unconstrained semidefinite optimization problems efficiently. The idea to our algorithm is a hybrid approach: we combine the algorithm of Hazan (2008) with a standard quasi-Newton algorithm. The algorithm achieves convergence to the global optimum with very good running time. It can be readily used for a\nAppearing in Proceedings of the 29 th International Conference on Machine Learning, Edinburgh, Scotland, UK, 2012. Copyright 2012 by the author(s)/owner(s).\nvariety of machine learning problems and we demonstrate its efficiency on three different tasks: matrix completion, metric learning, and sparse PCA. Another advantage of the algorithm is its simplicity, as it can be implemented in less than 30 lines of Matlab code."
    }, {
      "heading" : "1.1. Related Work",
      "text" : "A constrained version of Problem 1 is called a semidefinite program (SDP) if function f as well as the constraints are linear. Semidefinite programs have gained a lot of attention in recent years, since many NP-hard problems can be relaxed into SDPs and many machine learning problems can be modeled as SDPs.\nThe most widely known implementations of SDP solvers are interior point methods. They provide highaccuracy solutions in polynomial time. However, since the running time is a low-order polynomial in the dimension n they do not scale well to medium and large problems that often occur in machine learning. On the other hand, the high accuracy of their solutions is typically not needed as the input data is often noisy. Among other methods, proximal methods have been employed to solve SDPs in order to circumvent the large running time of interior point methods. They achieve better running times at the expense of less accurate solutions. Examples include (Nesterov, 2007; Nemirovski, 2004) and (Arora et al., 2005) where the multiplicative weights update rule is employed.\nThe algorithm of (Arora et al., 2005) has been randomized by (Garber & Hazan, 2011) based on the same idea as in (Grigoriadis & Khachiyan, 1995) to achieve sublinear running time. Another randomized algorithm has appeared in (Kleiner et al., 2010). Furthermore, alternating direction methods have been proposed to solve SDPs (Wen et al., 2010).\nAnother line of algorithms for solving SDPs are FrankWolfe type algorithms such as (Hazan, 2008). This approach is also known as sparse greedy approximation and these algorithms have the advantage that they produce sparse solutions (Clarkson, 2008) which, for SDPs, corresponds to low-rank solutions. Low-rank\nsolutions are very appealing since they can drastically reduce the computational effort. Instead of storing a low-rank positive semidefinite matrix X ∈ Rn×n one just stores a matrix V ∈ Rn×k where X = V V T , with k being the rank of X. Matrix-vector multiplications, for instance, can be done in O(nk) instead of O(n2).\nThere have also been nonlinear approaches to linear SDPs, however, without general convergence guarantees (Burer & Monteiro, 2003). In some special cases (matrix completion problems where it is assumed that the data is indeed generated by a low rank matrix and the restricted isometry property holds) convergence guarantees have been shown. In general, the problem of solving an SDP with a low-rank constraint is NP-hard (Goemans & Williamson, 1995).\nOrganization of the Paper Section 2 describes our algorithm while in Section 3 we provide experimental results on three different machine learning problems. We compare our algorithm against a standard interior point method and against algorithms that are specifically designed for each of the individual problems. Section 4 provides theoretical guarantees for the running time and for the convergence to the global optimal solution."
    }, {
      "heading" : "2. The Hybrid Algorithm",
      "text" : "Our algorithm is summarized in pseudo-code in Algorithm 1.\nAlgorithm 1 Hybrid Algorithm Input: Smooth, convex function f : Rn×n → R Output: Approximate solution of Problem 1 Initialize X0 = 0, V0 = 0 repeat\nIncrease rank by 1 using Hazan update: Compute vi = ApproxEV(−∇f(ViV Ti ), ε̃). Solve\nminα,β f(α · ViV Ti + β · vivTi ) s. t. α, β ≥ 0.\nSet Vi+1 = [ √ α · Vi, √ β · vi].\nRun nonlinear update: Improve Vi+1 by finding a local minimum of f(V V T ) wrt. V starting with Vi+1.\nuntil Approximation guarantee has been reached\nThe notation [Vi, vi] used in Algorithm 1 stands for the horizontal concatenation of matrix Vi and column vector vi. The function ApproxEV returns an approximate eigenvector to the largest eigenvalue:\ngiven a square matrix M it returns a vector vi = ApproxEV(M, ε̃) of unit length that satisfies vTi Mvi ≥ λmax(M) − ε̃, where λmax(M) denotes the largest eigenvector of matrix M .\nOur algorithm runs in iterations. Each iteration consists of two steps: a rank-1 update and a subsequent nonlinear improvement of the current solution. The rank-1 update step follows a Frank-Wolfe type approach. A linear approximation to function f at the current iterate Xi is minimized over the cone of semidefinite matrices. The minimum is attained at viv T i where vi = λmax(−∇f(Xi)) is the vector to the largest eigenvalue of −∇f(Xi). Then the next iterate Xi+1 is a linear combination of the current iterate Xi = ViV Ti and viv T i such that it minimizes f .\nIn the second step, the nonlinear update step, the current solution Xi+1 = Vi+1V Ti+1 is further improved by minimizing function f(V V T ) with respect to V . Note that this function is no longer convex with respect to V . Hence, we can only expect to find a local minimum. Our analysis however shows, that this is sufficient to still converge to the global optimal solution of Problem 1. In fact, it is even not necessary to find a local minimum, any improvement will work.\nIn Section 4 we will prove that after at most O( 1ε ) many iterations Algorithm 1 will return a solution that is ε-close to the global optimal solution."
    }, {
      "heading" : "3. Applications and Experiments",
      "text" : "We have implemented our hybrid algorithm in Matlab exactly as described in Algorithm 1. For the nonlinear update we use minFunc (Schmidt) which implements the limited memory BFGS algorithm. The twovariable optimization problem in the rank-1 update is also solved using minFunc. We use the default settings of minFunc. The approximate eigenvector computation is done using the Matlab function eigs. We ran all experiments in single-thread mode on a 2.50GHz CPU."
    }, {
      "heading" : "3.1. Matrix Completion",
      "text" : "In this section we consider the matrix completion problem used for collaborative filtering. Given a matrix Y where only a few entries have been observed the goal is to complete this matrix by finding a low-complexity matrix X which approximates the given entries of Y as good as possible. Low complexity can be achieved for instance by a low rank or by small trace norm. Also different error norms can be considered depending on the specific application. For instance, the l1-norm in combination with the trace-norm regularization leads\nto the robust PCA approach for matrix completion with low rank (Candès et al., 2011). Here, we use the l2-norm and the rank constraint as a measure of complexity. Hence, the matrix completion problem becomes the following optimization problem:\nmin ∑\n(i,j)∈Ω(Xij − Yij)2 s.t. rank(X) ≤ k , (2)\nwhere Ω is the set of all given entries of Y . Note that Problem (2) is NP-hard (Gillis & Glineur, 2011). However, we can still attempt to find a good solution to it by using our hybrid algorithm. Problem (2) can be transformed into the following equivalent semidefinite optimization problem:\nmin ∑\n(i,j)∈Ω̂(X̂ij − Ŷij)2\ns.t. rank(X̂) ≤ k X̂ 0 ,\n(3)\nwhere X̂ = (\nV X XT W\n) and Ŷ = ( 0 Y Y T 0 ) ,\nand X̂ is a positive semidefinite matrix. V and W are suitable symmetric matrices. Hence, the matrix completion Problem (2) for an input matrix Y ∈ Rm×n can be cast into a semidefinite optimization problem over matrices X ∈ R(m+n)×(m+n).\nWe compare our algorithm to a state-of-the-art solver GECO (Shalev-Shwartz et al., 2011) which was specifi-\ncally designed for solving large-scale matrix minimization problems with a low-rank constraint. We follow the experimental setting of (Shalev-Shwartz et al., 2011). We use three standard matrix completion datasets: MovieLens100k, MovieLens1M, and MovieLens10M. The dimensions of the three datasets are 943 × 1682, 6040 × 3706, and 69878 × 10677 respectively and they contain 105, 106, and 107 movie ratings from 1 to 5. The task is to predict a movie rating for user i and movie j. We used the datasets without any normalization1 and split them randomly such that for each user 80% of the ratings went into training data and 20% into test data.\nOur algorithm minimizes the training error much faster than GECO and at the same time also needs a much smaller rank. As a result we also achieve an optimal test error much faster and with a smaller rank than GECO. Table 1 reports the test root-mean-square error (RMSE) as well as the rank where it was achieved and the running times. Both rows for GECO in Table 1 reflect the same runs. The first row shows the statistics where the test error reaches the minimum. However, since GECO slows down a lot with the rank we also added intermediate results when the test error is approaching the minimum. As it can be observed our algorithm achieves the same or better test error by requiring only a fraction of the time needed by GECO.\n1We noticed that normalization had no impact on the results.\nBoth algorithms need quasi-linear time in the number of ratings and hence can be used to solve large scale matrix factorization problems. Note however, that for our algorithm the runtime per iteration scales linearly with the rank k whereas GECO needs O(k6). This behavior slows down GECO considerably, which can be seen in Figure 1."
    }, {
      "heading" : "3.2. Metric Learning",
      "text" : "The second problem we approach is the metric learning problem. We are given a labeled dataset X = (xi, yi)i. Let S be a set containing all pairs of indices (i, j) whose data points xi and xj are similar to each other, i.e. its labels yi and yj are equal; let the set S̄ contain all indices of data points that are dissimilar to each other. For a given semidefinite matrix A, the Mahalanobis distance between xi and xj is defined as dA(i, j) = √ (xi − xj)TA(xi − xj). The metric learning problem is that of finding a positive semidefinite matrix A, such that under the induced Mahalanobis distance, points that are similar are close to each other and points that are dissimilar are far apart. This problem can be cast as a semidefinite optimization problem(Xing et al., 2002):\nmin ∑\n(i,j)∈S dA(i, j) 2 s.t. ∑\n(i,j)∈S̄ dA(i, j) ≥ 1 A 0.\n(4)\nNote that the 1 in the inequality constraint in Problem (4) can be changed to any arbitrary positive constant. This constraint is just to ensure that not all points are mapped onto the same point. Problem (4) does not fit into our framework. However, we can transform it into the following equivalent unconstrained semidefinite problem:\nmin ∑\n(i,j)∈S dA(i, j) 2 − λ ∑ (i,j)∈S̄ dA(i, j)\ns. t. A 0. (5)\nProblem (5) is just the Lagrangian of Problem (4). Since the 1 in the inequality constrained was chosen arbitrary we can also choose any positive constant for λ. In our experiments we set it to 1.\nWe follow the experimental setting of (Kleiner et al., 2010). We compared our approach against an interior point method implemented in SeDuMi (Sturm, 1999) (via CVX (Grant & Boyd, 2011)) and the algorithm of (Xing et al., 2002) which is a projected gradient approach and was specifically designed to solve the above SDP. We could not directly compare our algorithm to that of (Kleiner et al., 2010) as the code was not available. However, the authors show that it performs similarly to (Xing et al., 2002).\nAs a measure of quality for a given solution A we define:\nQ(A) = 1 ξ · ∑ i ∑ j:(i,j)∈S ∑ l:(i,l)∈S̄ 1[dA(i, j) < dA(i, l))],\nwhere 1[.] is the indicator function and ξ =∑ i ∑ j:(i,j)∈S ∑ l:(i,l)∈S̄ 1 is a normalization factor. In essence Q captures how many points with the same label are mapped closer to each other than points with different labels.\nWe initially apply metric learning to the UCI ionosphere dataset which contains 351 labeled data points in dimension 34. The results of this experiment are shown in Figure 2. As it can be seen, our hybrid algorithm achieves the optimal value almost instantly. The projected gradient descent algorithm (PG) needs about 20 times as long to achieve a solution of comparable quality. Since the interior point method (IP) scales very badly with the number of data points, we only ran it on a sub-sample of size 4*34=136. On this dataset, our method achieves the same function value as IP: 5.47e-05, while requiring only 0.28 seconds as opposed to 1513 seconds that IP needs. PG achieves a function value of 5.50e-05 in 88 seconds.\nFollowing (Kleiner et al., 2010), we ran a second set of experiments on synthetic data in order to measure the dependence on the dimension d. We sampled points from Rd as follows: We define two sets of cluster centers C1 = {(−1, 1), (−1,−1)} and C2 = {(1,−1), (1, 1)} and apply a random rotation to both sets. We then sample each data point from a uniform Gaussian distribution N (0, Id). The first two coordinates of each data point are replaced by one of the cluster centers and the label of this data point is set accordingly to either 1 or 2. Finally, a small perturbation drawn from N (0, 0.25I2) is added to the first two coordinates. The results are depicted in Table 2, which shows the running times for the various algorithms until a quality measure of Q > 0.99 has been reached.\nOur algorithm achieves the same optimal function values as the interior point method, while requiring less\ntime than the PG method. For larger dimensions we plot the results in Figure 3. As it can be observed, our algorithm is considerably faster than PG on these larger dimensions. We omit the IP method here, as this scales badly with increased dimension."
    }, {
      "heading" : "3.3. Sparse PCA",
      "text" : "As a third problem we consider the sparse principal component analysis problem (sparse PCA). For a given covariance matrix A ∈ Rn×n, sparse PCA tries to find a sparse vector x that maximizes xTAx, i.e. a sparse principal component of A. This problem can be relaxed into the following SDP (d’Aspremont et al., 2007):\nmin ρ ∑\n(i,j) |Xij | −A •X s. t. Tr(X) = 1\nX 0, (6)\nwhere A•X denotes Tr(ATX). In a subsequent rounding step the largest eigenvector of the solution to Problem (6) is returned as the solution vector x. The parameter ρ controls the tradeoff between the sparsity of x and the explained variance xTAx.\nProblem (6) is not in form (1). However, one can easily transform it into an unconstrained semidefinite problem by defining the functions g(X) = XTr(X) and f(X) = ρ ∑ (i,j) |Xij | − A •X. Hence, Problem (6) is equivalent to min f(g(X))\nX 0. (7)\nNote that f(g(X)) is again a convex function over\nthe set of semidefinite matrices without the zero matrix. However, f(g(X)) is not smooth. Smoothness of f(g(X)) can be achieved either by implicitly smoothing it, e.g. using Nesterov’s smoothing technique (Nesterov, 2005) or by explicitly smoothing it and replacing the absolute function |.| with the scaled Huber-loss HM . The Huber-loss is defined as:\nHM (x) = { x2 if |x| ≤M 2M |x| −M2 if |x| > M\nBy appropriate scaling one can achieve an arbitrary small difference between |x| and HM (x). We obtain a smooth, convex function fHM by replacing the absolute function with the Huber-loss in function f . In our experiments we set M = 10−6 such that functions fHM and f differ only marginally from each other.\nWe again follow the experimental setting of (Kleiner et al., 2010) and we compare to an interior point method and to a state-of-the-art algorithm, the DSPCA algorithm (d’Aspremont et al., 2007) which is specifically designed to solve Problem (6). We used the colon cancer data set which contains 2000 microarray readings from 62 subjects. We randomly sampled readings in order to vary the dimension d. As standard with this task, we normalized the data to mean 0 and standard deviation 1. We set ρ = 0.2 in Problem (6) to obtain sparse solutions for all d.\nTable 3 reports the running time, the function value at convergence, the sparsity of the solution and the\ncaptured variance for these data sets. As mentioned above, we ran our algorithm on the function fHM , however we report the function value f(X) for the original formulation (6). The solutions of our algorithm are basically identical to those of the interior point method. However, it needs only a fraction of the time spent by the interior point method. The DSPCA algorithm provides accurate solutions within short time even with increasing dimension, however our algorithm is still considerably faster, especially for large dimensions."
    }, {
      "heading" : "4. Analysis",
      "text" : ""
    }, {
      "heading" : "4.1. The Duality Gap",
      "text" : "In this section we provide a duality gap for Problem (1) and analyze the running time of Algorithm 1. Let Problem (1) have finite optimal solution denoted by f∗ obtained at X∗. Let t be an upper bound on the trace norm Tr(X∗). Such a trace bound always exists if f∗ > −∞. Then the optimization Problem (1) is equivalent to:\nmin f(X) s. t. Tr(X) ≤ t\nX 0 (8)\nIn order to simplify some technicalities in the proof we change Problem (8) into:\nmin f̂(X̂) s. t. Tr(X̂) = t\nX̂ 0. (9)\nProblems (8) and Problem (9) are equivalent if we define\nf̂(X̂) := f(X),\nwhere\nX̂ = ( X 0 0 t′ ) and t′ = t − Tr(X) ≥ 0. Note that X̂ is positive semidefinite whenever X is positive semidefinite. This transformation is only done here for simplifying the analysis of Algorithm 1. It does not alter Algorithm 1.\nWe denote by St := {X ∈ Rn×n |X 0, Tr(X) = t} the set of all positive semidefinite matrices with trace constraint t.\nHence, we have that Problem (1) is equivalent to\nmin f(X), s. t. X ∈ St. (10)\nBy convexity of f , we have the following linearization, for any X,Y ∈ St:\nf(Y ) ≥ ∇f(X) • (Y −X) + f(X).\nThis allows us to define the Wolfe-dual of (10) for any fixed matrix X ∈ St as follows,\nω(X) := min Y ∈St ∇f(X) • (Y −X) + f(X)\n= f(X)− max Y ∈St −∇f(X) • (Y −X)\nand the duality gap as\ng(X) := f(X)− ω(X) = max\nY ∈St −∇f(X) • (Y −X).\nBy the definition of the objective function f , the gradient ∇f(X) is always a symmetric matrix and therefore has real eigenvalues, which will be important in the following.\nLemma 1. The duality gap can be written as\ng(X) = t · λmax (−∇f(X)) +∇f(X) •X.\nProof. We will prove the claim by showing that for any symmetric matrix G ∈ Rn×n, one can equivalently reformulate the linear optimization problem maxY ∈St G • Y as follows:\nmax Y ∈St G • Y = max G • n∑ i=1 αiuiu T i\n= max n∑ i=1 αi(G • uiuTi ),\nwhere the latter maximization is taken over unit vectors ui ∈ Rn, ‖ui‖ = 1, for 1 ≤ i ≤ n, and real coefficients αi ≥ 0, with ∑n i=1 αi = t.\nFor Y ∈ St let Y = UTU be its Cholesky factorization. Let αi be the squared norms of the rows of U , and let ui be the row vectors of U , scaled to unit length. From the observation Tr(Y ) = Tr(UTU) = Tr(UUT ) = ∑ i αi = t it follows that any Y ∈ St can be written as a convex combination of rank-1 matrices Y = ∑n i=1 αiuiu T i with unit vectors ui ∈ Rn.\nIt follows\nmax Y ∈St G • Y = max n∑ i=1 αi(G • uiuTi )\n= max n∑ i=1 αiu T i Gui\n= t · max v∈Rn,‖v‖=1 G • vvT\n= t · max v∈Rn,‖v‖=1 vTGv\n= t · λmax (G) ,\nwhere the last equality is the variational characterization of the largest eigenvalue.\nFinally, both claims follow by plugging in −∇f(X) for G.\nBy construction the duality gap g(X) is always an upper bound on the primal error h(X) = f(X)− f(X∗). This can also be used as a stopping criterion in Algorithm 1. If g(X) ≤ ε then f(X) is an ε-approximation to the optimal solution."
    }, {
      "heading" : "4.2. Runtime and Convergence Analysis",
      "text" : "In this section we will show that after at most O( 1ε ) iterations Algorithm 1 returns a solution that is an ε-approximation to the global optimal solution. The proof is along the lines of (Clarkson, 2008) and (Hazan, 2008). However, we improve by lowering the needed accuracy for the eigenvector computation from O(ε2) to O(ε). This in turn lowers the computational effort for a eigenvector computation from O( 1ε ) to O( 1√ ε ) per iteration when using the Lanczos method.\nLet the curvature constant Cf be defined as follows:\nCf :=\nsup X,Z∈St,α∈[0,1] Y=X+α(Z−X)\n1 α2 (f(Y )− f(X)− (Y −X) • ∇f(X)) .\nThe curvature constant is a measure of how much the function f(X) deviates from a linear approximation in X, and hence can be seen as an upper bound on the relative Bregman divergence induced by f . Now we can prove the following theorem.\nTheorem 2. For each i ≥ 1, the iterate Xi of Algorithm 1 satisfies f(Xi) − f(X∗) ≤ ε, where f(X∗) is the optimal value for the minimization Problem (1), and ε = 8Cfi+2 .\nProof. We have Xi = ViV Ti . Let the sequence αi = 2 i+2 . For each iteration of Hazan’s rank-1 update, we have that\nf(Xi+1) = min\nα,β≥0 f(α · ViV Ti + β · vivTi )\n≤ f((1− αi) · ViV Ti + αit · vivTi ) = f(Xi + αi(t · vivTi −Xi)) ≤ f(Xi) + αi(t · vivTi −Xi) • ∇f(Xi) + α2iCf(11)\nwhere the first inequality follows from choosing α = 1 − αi and β = αi · t and the last inequality follows\nfrom the definition of the curvature constant Cf . Furthermore,\n(t · vivTi −X) • ∇f(Xi) = (Xi − t · vivTi ) • (−∇f(Xi)) = Xi • (−∇f(Xi))− t · vTi (−∇f(Xi))vi ≤ −Xi • ∇f(Xi)− t · (λmax(−∇f(Xi))− ε̃) ≤ −g(Xi) + t · ε̃ ≤ −g(Xi) + αi · Cf .\nThe last inequality follows from setting ε̃ to a value at most αi·Cft within Algorithm 1. Hence, Inequality (11) evaluates to\nf(Xi+1) ≤ f(Xi)− αig + α2iCf + α2iCf = f(Xi)− αig(Xi) + 2α2iCf . (12)\nSubtracting f(X∗) on both sides of Inequality (12), and denoting the current primal error by h(Xi) = f(Xi)− f(X∗), we get\nh(Xi+1) ≤ h(Xi)− αig(Xi) + 2α2iCf , (13)\nwhich by using the fact that the duality gap g(Xi) is always an upper bound on the primal error h(Xi) gives\nh(Xi+1) ≤ h(Xi)− αih(Xi) + 2α2iCf . (14)\nThe claim of this theorem is that the primal error h(Xi) = f(Xi) − f(X∗) is small after a sufficiently large number of iterations. Indeed, we will show by induction that h(Xi) ≤ 8Cfi+2 . In the first iteration (i = 0), we know from (14) that the claim holds, because of the choice of α0 = 1.\nAssume now that h(Xi) ≤ 8Cfi+2 holds. Using αi = 2 i+2 in Inequality (14) we can now bound h(Xi+1) as follows:\nh(Xi+1) ≤ h(Xi)(1− αi) + 2α2iCf\n≤ 8Cf i+ 2\n( 1− 2\ni+ 2\n) +\n8Cf (i+ 2)2\n≤ 8Cf i+ 2 − 8Cf (i+ 2)2\n≤ 8Cf i+ 1 + 2 .\nSo far we only considered the progress made by Algorithm 1 trough the rank-1 update. Running the nonlinear improvement on f(ViV Ti ) in each iteration only improves the primal error h(Xi) in each iteration. Hence, the claim of the theorem follows.\nWe can set ε̃ = ε4t throughout Algorithm 1. This will ensure ε̃ ≤ αi·Cft as needed by the analysis of the algorithm."
    }, {
      "heading" : "5. Discussion",
      "text" : "We have provided an algorithm that optimizes convex, smooth functions over the cone of positive semidefinite matrices. It can be readily used for a variety of machine learning problems, as many of these fall into this framework or can be equivalently transformed into such a problem. In this paper we have performed experiments on three of such problems and we have shown that our algorithm significantly outperformes state-of-the-art solvers without the need of tuning it to any of the specific tasks. Additionally, the algorithm proposed has the advantage of being very simple, and it comes with the guarantee to always converge to the global optimal solution. In the future, we plan to implement our algorithm in C++ for further speedups."
    }, {
      "heading" : "Acknowledgements",
      "text" : "The author would like to thank Georgiana Dinu and Joachim Giesen for useful discussions on the topic. This work was supported by the Deutsche Forschungsgemeinschaft (DFG) under grant GI-711/3-2."
    } ],
    "references" : [ {
      "title" : "Fast algorithms for approximate semidefinite programming using the multiplicative weights update method",
      "author" : [ "Arora", "Sanjeev", "Hazan", "Elad", "Kale", "Satyen" ],
      "venue" : "In FOCS,",
      "citeRegEx" : "Arora et al\\.,? \\Q2005\\E",
      "shortCiteRegEx" : "Arora et al\\.",
      "year" : 2005
    }, {
      "title" : "A nonlinear programming algorithm for solving semidefinite programs via low-rank factorization",
      "author" : [ "Burer", "Samuel", "Monteiro", "Renato D.C" ],
      "venue" : "Math. Program.,",
      "citeRegEx" : "Burer et al\\.,? \\Q2003\\E",
      "shortCiteRegEx" : "Burer et al\\.",
      "year" : 2003
    }, {
      "title" : "Robust principal component analysis",
      "author" : [ "Candès", "Emmanuel J", "Li", "Xiaodong", "Ma", "Yi", "Wright", "John" ],
      "venue" : "J. ACM,",
      "citeRegEx" : "Candès et al\\.,? \\Q2011\\E",
      "shortCiteRegEx" : "Candès et al\\.",
      "year" : 2011
    }, {
      "title" : "Coresets, sparse greedy approximation, and the Frank-Wolfe algorithm",
      "author" : [ "Clarkson", "Kenneth L" ],
      "venue" : "In SODA,",
      "citeRegEx" : "Clarkson and L.,? \\Q2008\\E",
      "shortCiteRegEx" : "Clarkson and L.",
      "year" : 2008
    }, {
      "title" : "A direct formulation of sparse PCA using semidefinite programming",
      "author" : [ "d’Aspremont", "Alexandre", "El Ghaoui", "Laurent", "Jordan", "Michael I", "Lanckriet", "Gert R. G" ],
      "venue" : "SIAM Review,",
      "citeRegEx" : "d.Aspremont et al\\.,? \\Q2007\\E",
      "shortCiteRegEx" : "d.Aspremont et al\\.",
      "year" : 2007
    }, {
      "title" : "Approximating semidefinite programs in sublinear time",
      "author" : [ "Garber", "Dan", "Hazan", "Elad" ],
      "venue" : "In NIPS,",
      "citeRegEx" : "Garber et al\\.,? \\Q2011\\E",
      "shortCiteRegEx" : "Garber et al\\.",
      "year" : 2011
    }, {
      "title" : "Low-rank matrix approximation with weights or missing data is NP-hard",
      "author" : [ "Gillis", "Nicolas", "Glineur", "François" ],
      "venue" : "SIAM J. Matrix Analysis Applications,",
      "citeRegEx" : "Gillis et al\\.,? \\Q2011\\E",
      "shortCiteRegEx" : "Gillis et al\\.",
      "year" : 2011
    }, {
      "title" : "Improved approximation algorithms for maximum cut and satisfiability problems using semidefinite programming",
      "author" : [ "Goemans", "Michel X", "Williamson", "David P" ],
      "venue" : "J. ACM,",
      "citeRegEx" : "Goemans et al\\.,? \\Q1995\\E",
      "shortCiteRegEx" : "Goemans et al\\.",
      "year" : 1995
    }, {
      "title" : "CVX: Matlab software for disciplined convex programming, version 1.21",
      "author" : [ "Grant", "Michael", "Boyd", "Stephen" ],
      "venue" : "http: //cvxr.com/cvx,",
      "citeRegEx" : "Grant et al\\.,? \\Q2011\\E",
      "shortCiteRegEx" : "Grant et al\\.",
      "year" : 2011
    }, {
      "title" : "A sublinear-time randomized approximation algorithm for matrix games",
      "author" : [ "Grigoriadis", "Michael D", "Khachiyan", "Leonid G" ],
      "venue" : "Operations Research Letters,",
      "citeRegEx" : "Grigoriadis et al\\.,? \\Q1995\\E",
      "shortCiteRegEx" : "Grigoriadis et al\\.",
      "year" : 1995
    }, {
      "title" : "Sparse approximate solutions to semidefinite programs",
      "author" : [ "Hazan", "Elad" ],
      "venue" : "In LATIN,",
      "citeRegEx" : "Hazan and Elad.,? \\Q2008\\E",
      "shortCiteRegEx" : "Hazan and Elad.",
      "year" : 2008
    }, {
      "title" : "Random conic pursuit for semidefinite programming",
      "author" : [ "Kleiner", "Ariel", "Rahimi", "Ali", "Jordan", "Michael I" ],
      "venue" : "In NIPS,",
      "citeRegEx" : "Kleiner et al\\.,? \\Q2010\\E",
      "shortCiteRegEx" : "Kleiner et al\\.",
      "year" : 2010
    }, {
      "title" : "Learning the kernel matrix with semidefinite programming",
      "author" : [ "Lanckriet", "Gert R. G", "Cristianini", "Nello", "Bartlett", "Peter", "Ghaoui", "Laurent El", "Jordan", "Michael I" ],
      "venue" : "Journal of Machine Learning Research,",
      "citeRegEx" : "Lanckriet et al\\.,? \\Q2004\\E",
      "shortCiteRegEx" : "Lanckriet et al\\.",
      "year" : 2004
    }, {
      "title" : "Prox-method with rate of convergence O(1/t) for variational inequalities with lipschitz continuous monotone operators and smooth convex-concave saddle point problems",
      "author" : [ "Nemirovski", "Arkadi" ],
      "venue" : "SIAM Journal on Optimization,",
      "citeRegEx" : "Nemirovski and Arkadi.,? \\Q2004\\E",
      "shortCiteRegEx" : "Nemirovski and Arkadi.",
      "year" : 2004
    }, {
      "title" : "Smooth minimization of non-smooth functions",
      "author" : [ "Nesterov", "Yurii" ],
      "venue" : "Math. Program.,",
      "citeRegEx" : "Nesterov and Yurii.,? \\Q2005\\E",
      "shortCiteRegEx" : "Nesterov and Yurii.",
      "year" : 2005
    }, {
      "title" : "Smoothing technique and its applications in semidefinite optimization",
      "author" : [ "Nesterov", "Yurii" ],
      "venue" : "Math. Program.,",
      "citeRegEx" : "Nesterov and Yurii.,? \\Q2007\\E",
      "shortCiteRegEx" : "Nesterov and Yurii.",
      "year" : 2007
    }, {
      "title" : "Joint covariate selection and joint subspace selection for multiple classification problems",
      "author" : [ "Obozinski", "Guillaume", "Taskar", "Ben", "Jordan", "Michael I" ],
      "venue" : "Statistics and Computing,",
      "citeRegEx" : "Obozinski et al\\.,? \\Q2010\\E",
      "shortCiteRegEx" : "Obozinski et al\\.",
      "year" : 2010
    }, {
      "title" : "Large-scale convex minimization with a low-rank constraint",
      "author" : [ "Schmidt", "Shai", "Gonen", "Alon", "Shamir", "Ohad" ],
      "venue" : "In ICML,",
      "citeRegEx" : "Schmidt et al\\.,? \\Q2011\\E",
      "shortCiteRegEx" : "Schmidt et al\\.",
      "year" : 2011
    }, {
      "title" : "Maximum-margin matrix factorization",
      "author" : [ "Srebro", "Nathan", "Rennie", "Jason D. M", "Jaakkola", "Tommi" ],
      "venue" : "In NIPS,",
      "citeRegEx" : "Srebro et al\\.,? \\Q2004\\E",
      "shortCiteRegEx" : "Srebro et al\\.",
      "year" : 2004
    }, {
      "title" : "Using sedumi 1.02, a MATLAB toolbox for optimization over symmetric cones",
      "author" : [ "Sturm", "Jos F" ],
      "venue" : "Optimization Methods and Software,",
      "citeRegEx" : "Sturm and F.,? \\Q1999\\E",
      "shortCiteRegEx" : "Sturm and F.",
      "year" : 1999
    }, {
      "title" : "Graph laplacian regularization for largescale semidefinite programming",
      "author" : [ "Weinberger", "Kilian Q", "Sha", "Fei", "Zhu", "Qihui", "Saul", "Lawrence K" ],
      "venue" : "In NIPS,",
      "citeRegEx" : "Weinberger et al\\.,? \\Q2006\\E",
      "shortCiteRegEx" : "Weinberger et al\\.",
      "year" : 2006
    }, {
      "title" : "Alternating direction augmented lagrangian methods for semidefinite programming",
      "author" : [ "Wen", "Zaiwen", "Goldfarb", "Donald", "Yin", "Wotao" ],
      "venue" : "Math. Prog. Comp.,",
      "citeRegEx" : "Wen et al\\.,? \\Q2010\\E",
      "shortCiteRegEx" : "Wen et al\\.",
      "year" : 2010
    }, {
      "title" : "Distance metric learning, with application to clustering with side-information",
      "author" : [ "Xing", "Eric P", "Ng", "Andrew Y", "Jordan", "Michael I", "Russell", "Stuart" ],
      "venue" : "In NIPS,",
      "citeRegEx" : "Xing et al\\.,? \\Q2002\\E",
      "shortCiteRegEx" : "Xing et al\\.",
      "year" : 2002
    } ],
    "referenceMentions" : [ {
      "referenceID" : 4,
      "context" : "Prominent examples include sparse PCA (d’Aspremont et al., 2007), distance metric learning (Xing et al.",
      "startOffset" : 38,
      "endOffset" : 64
    }, {
      "referenceID" : 22,
      "context" : ", 2007), distance metric learning (Xing et al., 2002), nonlinear dimensionality reduction (Weinberger et al.",
      "startOffset" : 34,
      "endOffset" : 53
    }, {
      "referenceID" : 20,
      "context" : ", 2002), nonlinear dimensionality reduction (Weinberger et al., 2006), multiple kernel learning (Lanckriet et al.",
      "startOffset" : 44,
      "endOffset" : 69
    }, {
      "referenceID" : 12,
      "context" : ", 2006), multiple kernel learning (Lanckriet et al., 2004), multitask learning (Obozinski et al.",
      "startOffset" : 34,
      "endOffset" : 58
    }, {
      "referenceID" : 16,
      "context" : ", 2004), multitask learning (Obozinski et al., 2010), and matrix completion (Srebro et al.",
      "startOffset" : 28,
      "endOffset" : 52
    }, {
      "referenceID" : 18,
      "context" : ", 2010), and matrix completion (Srebro et al., 2004).",
      "startOffset" : 31,
      "endOffset" : 52
    }, {
      "referenceID" : 4,
      "context" : "Prominent examples include sparse PCA (d’Aspremont et al., 2007), distance metric learning (Xing et al., 2002), nonlinear dimensionality reduction (Weinberger et al., 2006), multiple kernel learning (Lanckriet et al., 2004), multitask learning (Obozinski et al., 2010), and matrix completion (Srebro et al., 2004). We provide an algorithm that solves general large-scale unconstrained semidefinite optimization problems efficiently. The idea to our algorithm is a hybrid approach: we combine the algorithm of Hazan (2008) with a standard quasi-Newton algorithm.",
      "startOffset" : 39,
      "endOffset" : 522
    }, {
      "referenceID" : 0,
      "context" : "Examples include (Nesterov, 2007; Nemirovski, 2004) and (Arora et al., 2005) where the multiplicative weights update rule is employed.",
      "startOffset" : 56,
      "endOffset" : 76
    }, {
      "referenceID" : 0,
      "context" : "The algorithm of (Arora et al., 2005) has been randomized by (Garber & Hazan, 2011) based on the same idea as in (Grigoriadis & Khachiyan, 1995) to achieve sublinear running time.",
      "startOffset" : 17,
      "endOffset" : 37
    }, {
      "referenceID" : 11,
      "context" : "Another randomized algorithm has appeared in (Kleiner et al., 2010).",
      "startOffset" : 45,
      "endOffset" : 67
    }, {
      "referenceID" : 21,
      "context" : "Furthermore, alternating direction methods have been proposed to solve SDPs (Wen et al., 2010).",
      "startOffset" : 76,
      "endOffset" : 94
    }, {
      "referenceID" : 2,
      "context" : "to the robust PCA approach for matrix completion with low rank (Candès et al., 2011).",
      "startOffset" : 63,
      "endOffset" : 84
    }, {
      "referenceID" : 22,
      "context" : "This problem can be cast as a semidefinite optimization problem(Xing et al., 2002):",
      "startOffset" : 63,
      "endOffset" : 82
    }, {
      "referenceID" : 11,
      "context" : "We follow the experimental setting of (Kleiner et al., 2010).",
      "startOffset" : 38,
      "endOffset" : 60
    }, {
      "referenceID" : 22,
      "context" : "We compared our approach against an interior point method implemented in SeDuMi (Sturm, 1999) (via CVX (Grant & Boyd, 2011)) and the algorithm of (Xing et al., 2002) which is a projected gradient approach and was specifically designed to solve the above SDP.",
      "startOffset" : 146,
      "endOffset" : 165
    }, {
      "referenceID" : 11,
      "context" : "We could not directly compare our algorithm to that of (Kleiner et al., 2010) as the code was not available.",
      "startOffset" : 55,
      "endOffset" : 77
    }, {
      "referenceID" : 22,
      "context" : "However, the authors show that it performs similarly to (Xing et al., 2002).",
      "startOffset" : 56,
      "endOffset" : 75
    }, {
      "referenceID" : 11,
      "context" : "Following (Kleiner et al., 2010), we ran a second set of experiments on synthetic data in order to measure the dependence on the dimension d.",
      "startOffset" : 10,
      "endOffset" : 32
    }, {
      "referenceID" : 4,
      "context" : "This problem can be relaxed into the following SDP (d’Aspremont et al., 2007): min ρ ∑ (i,j) |Xij | −A •X s.",
      "startOffset" : 51,
      "endOffset" : 77
    }, {
      "referenceID" : 11,
      "context" : "We again follow the experimental setting of (Kleiner et al., 2010) and we compare to an interior point method and to a state-of-the-art algorithm, the DSPCA algorithm (d’Aspremont et al.",
      "startOffset" : 44,
      "endOffset" : 66
    }, {
      "referenceID" : 4,
      "context" : ", 2010) and we compare to an interior point method and to a state-of-the-art algorithm, the DSPCA algorithm (d’Aspremont et al., 2007) which is specifically designed to solve Problem (6).",
      "startOffset" : 108,
      "endOffset" : 134
    } ],
    "year" : 2012,
    "abstractText" : "We present a hybrid algorithm for optimizing a convex, smooth function over the cone of positive semidefinite matrices. Our algorithm converges to the global optimal solution and can be used to solve general largescale semidefinite programs and hence can be readily applied to a variety of machine learning problems. We show experimental results on three machine learning problems. Our approach outperforms state-of-the-art algorithms.",
    "creator" : "LaTeX with hyperref package"
  }
}