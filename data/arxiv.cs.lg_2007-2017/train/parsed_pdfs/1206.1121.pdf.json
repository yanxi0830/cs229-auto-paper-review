{
  "name" : "1206.1121.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "Comparison of the C4.5 and a Naive Bayes Classifier for the Prediction of Lung Cancer Survivability",
    "authors" : [ "George Dimitoglou", "James A. Adams", "Carol M. Jim" ],
    "emails" : [ "dimitoglou@cs.hood.edu" ],
    "sections" : [ {
      "heading" : null,
      "text" : "Index Terms—Data mining, mining methods and algorithms, text mining\n——————————  ——————————"
    }, {
      "heading" : "1 INTRODUCTION",
      "text" : "The proliferation of computing technologies in every aspect  of modern life, has substantially increased the volume of data  being collected and stored. The availability of these massive  data sets introduces the challenge of having to analyze, un derstand and use the data. Using   data mining techniques,  data can be classified to bring forward interesting patterns or  serve as a predictor for future trends.  Numerous algorithmic  techniques have been developed to extract information and  discern  patterns   that  may  be  useful   for  decision   support.  Such techniques are routinely applied in various areas and  problems     ranging   from   business,  marketing   and  money  fraud detection,   to   security  surveillance,   scientific   research  and health care.  This paper uses the Surveillance, Epidemiology and End Res ults  (SEER) dataset [24],  to compare the predictive effective ness of two algorithmic techniques.  It uses lung cancer sur vivability as the objective criterion to assess how well each  technique is able to predict patient survivability given a set of  historical data. This type of analysis is not unique, in fact it  was inspired by a similar analysis on breast cancer survivab ility techniques [2]. The particular  disease was selected because of   its  severity.  Lung cancer is one of the most prevalent and the most deadly  type of cancer. It manifests as an uncontrolled cell growth in  lung  tissues.  Both  sexes  are  susceptible,  with  men  having  higher probability (1 in 13) of developing the disease in a life time   than  women  (1  in  16).  These  probabilities  include  smokers  and  nonsmokers  alike  with  smokers  being  at  a  much  higher  risk.  Smoking  has  been  identified  as  the  greatest contributing cause [3, 12, 22] but exposure to asbes tos [6, 16] and radon gas [5] have also been linked with the in cidence of the disease. \nIn  the United  States, while  lung  cancer  diagnosis  comes  second to prostate cancer for men and breast cancer for wo men, it is the leading cause of cancer death across the sexes.  In 2006, lung cancer diagnoses accounted for 196,454 patients  of all new cancer patients and lung cancer mortality accoun\nted  for  approximately  29%  of  all  cancerrelated  deaths  (158,599 patients) [25].  These mortality rates remained stable  in 2010  indicating that more people die of  lung cancer  than  of colon, breast, and prostate cancer combined [1].\nDeveloping   treatments   and   better   understanding   the  characteristics of the disease is almost exclusively based on  clinical and  biological research. However, the abundance of  cancer research related data provides new opportunities to  develop data and statisticsdriven that may complement the  traditional research approaches. \nOne of the most  interesting and challenging areas is sur vivability  or disease  outcome prediction.   This  area  lends  itself  well for analysis using data mining techniques. With surviv al  analysis, diseasespecific historical data is examined and  analyzed over a certain period of time to develop a prognos is.\nThe  increased  interest  in  health  informatics  to  provide  more effective health care and the abundance of computing  power, massive  data  storage  capacity  and  the  development  of  automated  tools,  has  allowed   the  collection  of  large  volumes  of  medical  data.  As  a   result,  methods  and  tech niques   from the  computing sciences   related  to  knowledge  discovery   and   data  mining   have   become   very   useful   in  identifying patterns and analyzing relationships in the data  that may lead to better disease outcome prediction [7, 8, 23,  26]. This type of pattern analysis can be used in the develop ment of patient survivability prediction models. It is the pre valence and serious effects of  lung cancer and how well  ex isting data lends itself for data mining that provided the mo tivation to select this subject as the platform for the compar ison of the two algorithmic techniques. \nOne of the special aspects of our study is the volume and  authenticity  of  the  experimentation  dataset.   We used data  provided the SEER program,    one of the most comprehens ive  sources  on  cancer  incidence  and  survival  in  the  U.S.  provided by the National Cancer Institute.   For the analysis,  we  used  two  different  classification  algorithms:  the  Naive \n————————————————\n• George Dimitoglou is with the Department of Computer Science at Hood College, Frederick, MD 21701, USA. Email: dimitoglou@cs.hood.edu • James A. Adams is with Marriott International, Bethesda, MD 20817, USA. • Carol M. Jim is with the School of Engineering & Applied Science at The George Washington University, Washington, DC 20052, USA.\nBayes and J48, an implementation of the C4.5 algorithm. The following section contains a brief overview of the rel evant algorithms and prediction models. Section 3 provides a  detailed description of the data and preprocessing activities.  Section 4 describes survivability in the context of the specific  SEER dataset and it  is followed by Section 5 which presents  the experimentation and results. The final sections provide a  discussion  of  the  results  along  with  some  conclusions  and  areas for future work."
    }, {
      "heading" : "2 ALGORITHMS AND PREDICTION MODELS",
      "text" : "To develop a prediction model, classifiers are the data mining  algorithm of choice. The basic premise is based on treating a  collection of cases as input, each belonging to a small number  of classes described by a fixed set of attributes [17]. The clas sifier's  output  is  the prediction of  the  class  to which  a new  case belongs. The accuracy of  the prediction varies depend ing on the classifier and the types of attributes and classes in  the dataset. Classification may be viewed as mapping from a  set of attributes to a particular class [17]. For the data  analys is,  two  classification  techniques were used,  the Naive Bayes  and the open source version of the C4.5 statistical classifier.  "
    }, {
      "heading" : "2.1 Naive Bayes",
      "text" : "The Naive Bayes algorithm is a simple probabilistic classi fier  that  calculates  a  set  of  probabilities  by  counting  the  frequency and combinations of values in a given data set. \nThe probability of a specific feature in the data appears  as a member in the set of probabilities and is derived by  calculating  the  frequency  of  each  feature  value within  a  class of a training data set. The  training dataset  is a sub set,  used  to  train  a  classifier  algorithm  by  using  known  values to predict future, unknown values.  \nThe algorithm uses Bayes theorem [15] and assumes all  attributes to be independent   given the value of  the class  variable.   This  conditional  independence  assumption  rarely  holds  true  in  realworld   applications,  hence  the  characterization as Naive yet  the algorithm  tends  to per form well and  learn rapidly in various supervised classi fication problems [18]. \nThis  \"naivety\" allows  the algorithm to easily construct  classifications  out  of  large data  sets without  resorting  to  complicated iterative parameter estimation schemes. "
    }, {
      "heading" : "2.2 J48",
      "text" : "J48  is  an  implementation  of  C4.5  [20]  which  is  the  suc cessor of the ID3 algorithm [19]. ID3 is based on inductive  logic programming methods, constructing a decision tree  based  on  a  training  set  of  data  and  using  an  entropy  measure to determine which features of the training cases  are important  to populate the leaves of the tree.  \nThe algorithm first identifies  the dominant attribute of  the training set and sets it as the root of the tree. Second, it  creates  a  leaf   for  each  of  the  possible  values  the  root  can \ntake. Then, for each of the leaves it repeats the process using  the training set data classified by this leaf [18]. The core func tion of the algorithm is determining the most appropriate at tribute to best partition the data into various classes. The ID3  algorithm [21] uses entropy and information gain [29],   bor rowed from information theory,  to measure  the  impurity of  the data items. \nSmaller  entropy  values  indicate  full  membership  of  the  data to a single class while higher entropy values indicate ex istence of more classes the data should belong to.   Informa tion gain [29] measures the decrease of the weighted average  entropy of  the  attributes  compared with  the  entropy of  the  complete  dataset.  Therefore,  the  attributes  with  higher  in formation  gain  are  better  classification  candidates  for  data  items. One limitation of ID3 is its sensitivity to features with  a large population of values. C4.5, an ID3 extension, was de veloped  to address  this  limitation by  finding high accuracy  hypotheses, based on pruning the rules issued from the con structed  tree  during  the   leaf  population  phase.  However,  C4.5 is computationally more intensive, in terms of time and  space complexity. \nThe  comparison  of  the  two  techniques in the literature,  Naive  Bayes  and  J48,   does  not  render  conclusive  results.  Various  studies  in different domains have  found each  tech nique performing differently than the other. For example,  in  the  context  of  intrusion  detection  systems,  one  study  [10]  found  J48 performing better than another similar study [16],  while studies in the prediction of acute cystitis and  nephritis  [14]  and  the  classification  of  arrhythmia  data  [23]  the  per formance of Naive Bayes was superior. Similarly, in the con text of spam email identification [27], J48   performed better  in  terms  of  accuracy  of  overall  classification  despite  the  widespread use of Bayesianbased span filtering techniques."
    }, {
      "heading" : "3 DATA",
      "text" : ""
    }, {
      "heading" : "2.4 Data Description",
      "text" : "The data used in this study was acquired from the SEER  database.   We  used  version  3.4.10  of  the  open  source  toolkit  Weka  to  Environment  for  Knowledge  Analysis  (WEKA) [13] to determine the accuracy of two algorithms  in predicting lung cancer survivability.   The data used in  the  experiments  is  sourced  from  the  RESPIR  incidence  data files included in three SEER datasets (Table 1).\nDIMITOGLOU: COMPARISON OF THE C4.5 AND NAIVE BAYES CLASSIFIERS FOR THE PREDICTION OF LUNG CANCER SURVIVABILITY 3\nThere is a total of 481,432 records in the dataset.  It con tains  records  of  patients  diagnosed  between  19732004.  However,  due  to  the   modification  and  addition  of  data  fields, records prior to 1988 were removed for our study. \nThe  remaining  records  were  filtered  to  include  only  those  that  contain  the  Extent  of  Disease  (EOD)  10digit  coding system. This coding system provides detailed, rel evant and useful information, such as tumor size, number  of positive nodes, number of primaries and other quanti fiers that greatly enrich the dataset.   The effect of this fil ter was  to  restrict  the  dataset  to  records  containing  dia gnoses  only  between  the  complete  years  in  the  dataset  (19882003).  "
    }, {
      "heading" : "2.5 Preprocessing Activities",
      "text" : "The  records  in  the  dataset  are  not  diseasespecific  so  they  include multiple  cancer  types  and  disease  profiles.  To prepare the data for mining numerous preprocessing  activities were performed.   Figure  1  depicts  the prepro cessing  workflow.   It  is  divided  in  four  interconnected  stages with the overall objective to ensure that data is ap propriate, complete and well formatted. The  input  to  the  preprocessing workflow  is  the  source,  unprocessed, “raw”, data files. \nThe  first  phase  (Phase  I)  comprises  of  two  activities.  The  first  activity  is  to   perform  a  structural  consistency  check to ensure that field names and record structures are  homogeneous between different source files.   It is not un common  for  different   year  data  sets  to  have  different  fields due to changes in the data collection methodology.  The  second  activity  is  to  identify  anomalous  data  ele ments such as missing values and erroneous data.  For ex ample, empty fields may often be denoted by leaving the  field  blank,  labeling  it  as  “null”  or  having  a  designation  such as “N/A” or “0”.  While any label to indicate a miss ing  value  is  acceptable,  the  convention  followed  in  the  data must be identified and confirmed. \nPhase  II  examines  the  data  with  respect  to  relevancy  and  completeness.   Checking  for  relevancy  ensures  that  pertinent information is included to accomplish the study  objective.   For  example,  data  not  containing  any  explicit  information about the patient's type of cancer.\nIn this case, the data has to be further processed to de termine if a synthesis of multiple fields can help to derive  and  substitute  the missing  information.   If  it  is  not  pos sible,  the  dataset  may  be  deemed  inappropriate  and  be  discarded. Another result from this phase is to ensure that  data granularity is sufficient for the study objective.  If the \nobjective  is  to  identify  individual patientbased  relation ships but the collection only provides  information at  the  group  level,  then  the data would not have  the necessary  granularity and should be discarded.\nIn the third phase, the data is examined for qualitative  consistency.   The  objective  is  to  ensure  the  dataset  as  a  whole is meaningful and useful.  For example, when min ing for the onset time of prostate cancer, a type of cancer  appearing  exclusively  on male  patients,  qualitative  con sistency may  indicate  that  the  data  includes  female  pa tients.   Such inclusion pollutes the dataset and will most  likely  skew  the  results.   Similarly,  extraneous ages,  such  as patients over 120 years of age or younger than 0 years  of age, would be indicators of questionable entries in the  dataset.  \nThe fourth phase requires data fields to be codified us ing different types of values (ex. ordinal, categorical, etc.).  Some of  the  fields  can be  immediately used  for  analysis  while others must be normalized to provide more mean ingful numeric ranges or to better identify described con ditions.   The final preprocessing task is related to expec ted format and syntax modifications required by the data  mining algorithms and software. \nIn each of the four stages, it is possible that some data  may be deemed incomplete or too coarse for mining.   In  such  cases  the  data  may  be  discarded,  unless  the  dis carded set significantly impacts the integrity of the data set.   It  is  also  possible  that  the  mining  algorithms  can  handle anomalous conditions by labeling or ignoring cer tain data.\n2.6 Metadata The SEER data  is welldescribed providing item descrip tions, codes, and coding instructions. However,  the data set  includes  incidence  records  for  all  possible  cancer  types, treatments and death causes along with a wealth of  nonidentifiable patient information. \nAfter  the data  is preprocessed,  certain data elements  present  themselves  with  interesting  information  while  others  become  candidates  for  omission.  In  the  next  two  sections,  a  brief  description  of  the  data  elements  is  provided, followed by a postprocessing filtering.  \nWhile this process is iterative after each preprocessing  phase, here we present  the final  result of  the endtoend  preprocessing. \nThe  following  data  elements  were  included  in  the  SEER dataset: Age. Patient age at initial lung cancer diagnosis.\nRace. Patient race described using one of seven categories:  White, Black, American  Indian/Alaskan Native, Asian  or Pa cific Islander, Other Unspecified and Unknown. Marital Status. Patient marital status (Single, Married, Sep arated, Divorced, Widowed and Unknown) at the time of dia gnosis for the reportable tumor.  Primary Site Code. Tumor location in the body, as classi fied by the International Classification of Diseases for On cology (ICDO3) [9] for topography codes.  Histologic  Type.  Tumor  morphology  using  178  distinct  ICDO3 codes. Behavior Code. Indicates if tumor is malignant.  Tumor Size. Indicates the tumor size.   Grade.  Subjective  description  of  tumor's  appearance  between visits. Extension  of  Tumor.  Farthest  documented  extension  of  tumor away from the primary site. Lymph  Node  Involvement.  (Binary  value).    Indicates  if  the tumor involves Lymph Node chains. Site  Specific  Surgery  Code.  Describes  body  and  organ  locations that could have been operated on. Radiation. Radiation therapy method on first treatment.  Stage of Cancer. Physical location and spread.   Radiation sequence with Surgery. Sequence of adminis tering  radiation  such  as  presurgery,  postsurgery  and  pre/postsurgery radiation. Survival Code. Denotes if patient has survived. A  set  of  \"survival codes\" was created to identify classes of surviv ing patients.   Survival Time Recode  expresses  the  survival  time  in months, Vital  Status Recode  indicates  if  patient  is  alive and Death Code indicates the recorded cause of death  based on ICD10 [28].\n2.7 Filtering Mining algorithms assume the data to be noisefree.   The  output  of  particularly  the  third  preprocessing  phase  (qualitative consistency checks), reveals a number of inter esting characteristics in the data.\nFor  example,  there  are  two  fields  that  are  eliminated  from the dataset. The Behavior Code indicates if a tumor is  malignant.  In our dataset,  the majority  (99.9%) of  the  re cords  are  identified  as  malignant  and  the  remaining  (00.1%) contain a null value. This  field  is not meaningful  for our particular study because unlike other cancer types,  lung  cancers,  are  assumed  to  be malignant  for  all  cases.  Similarly,  it  is  questionable  how  meaningful  the  Grade  field  is.  It  holds  a  codified,  subjective  description  of  the  tumor's appearance between physician visits. While there  is  ordering  of  the  possible  values  (Table  2)  yet  it  is  un known how much worse  (or  better)  the  different  grades  vary between each other. \nA  preliminary  analysis  indicates  that  almost   half  (48.36%)  of  all  the  data  fall  in  the  Grade  IV  category.  Within this category, approximately half of the entries are  recorded as not available (N/A).\nTherefore,   the  Grade   field   is  discarded because   it   is  populated by subjective observational data.   In addition,  the   unclear   demarcation   of   categories   and   information  unavailability would increase the noise in the data rather  provide a meaningful discriminatory attribute.\nTwo other fields require special attention. The Primary  Site Code contains 28 distinct codes to describe the incid ence of cancer. Not all of the codes are applicable so only  the  records  with  codes  identifying  lung  cancer  (C340 C343, C348C349) are preserved. \nThe Age  field  on  the  other  hand,  has  values  ranging  from  1  to  106.   This  is  a  very wide  value  spread which  may  generate  many,  nonsignificant  data  points.  As  the  significance  of  age  ordinality  becomes  a  concern,  it  is  probably not very meaningful  to differentiate between a  24year old and a 25year old patient. To address this, the  data is discretized into an 8binary scale format with the  following  entries:  (024),  (2534),  (3544),  (4554),  (5564),  (6574), (7584), >= 85."
    }, {
      "heading" : "2.8 Preliminary Statistical Analysis Results",
      "text" : "At  this stage a number of statistical measures and counts  are applied to identify if there are any interesting patterns  simply by measuring the  frequency of occurrence of cer tain elements and events in the data. Early results for the  Tumor Size keyword indicate a trend of surviving patient  records  having  this  attribute  with  a  value  of  less  than  40mm.\nAnother  interesting  observation  can  be  made  about  the  Site  Specific  Surgery  Code  which  describes  the  body  and  organ  locations  that  could  have  been  operated  on.  The majority (95%) of  the  records are  identified as Lung  and Bronchus and the remaining as Pleura and Trachea, Me diastinum, and Other respiratory organs. \nOn  the  treatment  side,  the  keyword  Radiation,  indic ates the method of radiation therapy performed as part of  the  first  treatment.  While  there  are  almost  ten  possible  categories,  92%  of  the  records  in  the  dataset  are  in  cat egories  under  Diagnosed  at  Autopsy  and  Beam  Radiation.  The  remaining  categories  are:  Radioactive  Implants,  Ra dioisotopes,  Combination  Treatment,   No  Method  Specified,  Patient  Refused  Therapy,  Radiation  Recommended  and  Un known If Administered.\nWhile none of the above measurements can lead to any  conclusions about  the correlation of  tumor size and sur vivability or, surgery location and treatment options, they \nDIMITOGLOU: COMPARISON OF THE C4.5 AND NAIVE BAYES CLASSIFIERS FOR THE PREDICTION OF LUNG CANCER SURVIVABILITY 5\noffer an alternative perspective on the data. Perhaps these  findings  could  prove  useful  during  an  association  rule  learning  experiment  either  as  a  validation  or  reenforce ment mechanism."
    }, {
      "heading" : "3 SURVIVABILITY",
      "text" : "Survival  rates and  statistics  indicate  the percentage of  patients who manage to survive from cancer for a specific  amount of time, typically five years (60 months). Survival  must be determined as causespecific survival, represent ing survival from lung cancer and not any other cause.\nThe  ICD10 Death Code designation plays  a  significant  role  in  this  determination  as  patient  records  indicating  failure  to  survive  due  to  causes  other  than  lung  cancer  must  be  eliminated.   This  assumes  the  data  contains  a  single, accurate, diseasespecific cause of death code. It is  often  hard  to  depend  on  such  variable  particularly with  cancer patients, as the cause of death may often be attrib uted to a different site due to to metastasis, instead of the  primary  site.  In  addition,  the  survival  rates  are  often  vague  in specifying whether a patient  is still undergoing  treatment and if the patient has achieved full or partial re mission. \nALGOTITHM 1 DETERMINING SURVIVAL STATUS.\n1 2 3 4 5 6 7 8 9 10 11 12 DeathCode   ⇐ (from ICD − 10 designation) if (SurvivalTimeRecode >= 60 months)   ∧     (VitalStatusRecode = \"alive\" ) then        Survived   ⇐ true; else if (SurvivalTimeRecode < 60 months)   ∧            (cause   ∈ DeathCode) then        Survived   ⇐ false; else if SurvivalCode = null then        remove record; else {Survived = inconclusive;}        remove record; end if\nIt is   therefore necessary to derive a \"survived\" flag for  each patient record. This flag is derived using Algorithm  1 and taking into account the Death Code field with the pa tient's reported status (VitalStatusRecode) and the reported  survival time (SurvivalTimeRecode). \nAny  records  that  contain  a  null  value  in  the  survival  code  after  applying  the  above  algorithm  are  removed.  Table 3 shows the number of instances and the respective  percentage  of  patients  who  survived  after  being  dia\ngnosed with lung cancer."
    }, {
      "heading" : "2.9 Survival Time",
      "text" : "There is an interesting pattern in the data when compar ing the median survival time (MST) in months from year  to year.   The MST is very stable from year to year, gradu ally increasing, as expected.   However. between the years  1999 and 2000, there is a dramatic decrease.\nFig. 2. Median survival time (in months) per year.\nThe median number of survived months in the 16year  range  is  constant  for  the  first  seven  years, gradually  in creases between year eight and twelve, and then dramat ically decreases each year by approximately 33%  through  the end of the dataset (Figure 2).  \nThe increase in survival rate, which goes against the  data in Fig. 2, could be justified with the introduction of a  revolutionary  treatment  and very early prediction after  year 2000.  Most likely, this decrease is due to a major in crease in the number of patient records (Table 4).\nAfter further investigation, we discovered that this de cline coincides with coding differences between the mul tiple SEER reporting sites.  In 2000, a new SEER reporting  site  was   introduced,   collecting   data   from  densely   and  highly populated areas of   the U.S.   including California  and New Jersey.  \nFig. 3. Number of diagnosed patients (in thousands).\nThe data from these reporting sites increased the num\nber of records (Table 4) and along with the use of different  coding  standards  may explain     the  MST decline   in  the  data.   \nRegional trends or anomalies may also be another con tributing factor so further examination is warranted in or der to use the specific data segment with confidence. As a  result, data after 1999 were discarded from the study. \nTABLE 4 MEDIAN SURVIVAL TIME AND NUMBER OF PATIENTS PER YEAR OF DIAGNOSIS (1988-2003).\nYear  Median Survival (months) Number of Patients\n1988 7 11,148\n1989 7  11,405\n1990 7 11,726\n1991 7 12,069\n1992 7 16,734\n1993 7 16,764\n1994 7 16,856\n1995 8 17,276\n1996 8 17,530\n1997 8 17,743\n1998 8 18,226\n1999 9 18,395\n2000 6 32,198\n2001 6 31,666\n2002 5 29,959\n2003 4 26,244\nAnother  aspect  of  survivability  is  the  survival  length  By  setting a limit, patient records can be classified in two surviv al categories: shortterm and longterm.   This limit, found by  the median survival rate, indicates  the number of patients in  a year  diagnosed within  twelve months. To implement this  threshold and identify longterm survivability, Rule1 (Table  5) is used to identify a longterm survivor and classify the pa tient as a \"survivor\".\nJust by applying this rule, 135,878 (30.23%) entries of  the  449,446  total  patient  records were discarded due to  insuffi cient  information that forbid us  to properly classify patients  as survived or as not survived.  \nWhile Rule1 establishes meaningful constraints for long term survivability, it is very strict and discriminating for the  short and midterm.\nThis is  because the median survival time is consistently  less than a year, and in the early years of the data, it is fairly  consistent so that 3540% of patients survive longer than a  year, albeit this number significantly decreases after 2000. \nTo address these issues, we established additional rules to  improve the determination of survivability (Table 5)."
    }, {
      "heading" : "4 EXPERIMENTATION",
      "text" : "The purpose  of  this  study  is  to  test  the  accuracy  of  two  learning  algorithms  (Naive  Bayes  and  J48)  in  predicting  survivability  of  patients  diagnosed  with  lung  cancer.  After preprocessing, the data is ready to be processed by  the two algorithms."
    }, {
      "heading" : "19881992  5 1993",
      "text" : ""
    }, {
      "heading" : "19921998  7 1999",
      "text" : ""
    }, {
      "heading" : "19881997  10 1998",
      "text" : "Three  experimentation  executions  were  performed,  each under a common scenario: using  a variable number  of  sequential years  as  a  training dataset,  attempt  to pre dict  the  accuracy  of  lung  cancer  incidence  for  a   sub sequent year (target year). \nThen,  to  determine  the  level  of  accuracy  for  each  al gorithm, compare the predicted outcomes with the target  data.   Several datasets are used, identified by the number  of years of training and target data (Table 6). "
    }, {
      "heading" : "2.10 Execution",
      "text" : "The Naive Bayes algorithm was executed over each one,  five, seven and ten year Training Data date ranges producing  correctly classified instances ranging from 88.27% to 92.38%  (Table 7).    For each experiment, we obtained the Correctly  Classified   Instances   (CCI),   the   Incorrectly   Classified   In stances   (ICI)   the   Kappa   statistic   (κ)   and   the   rootmean squareerror   (RMSE).     The   CCI   is   the   sample   accuracy  without any chance corrections and it is expressed as a per\nDIMITOGLOU: COMPARISON OF THE C4.5 AND NAIVE BAYES CLASSIFIERS FOR THE PREDICTION OF LUNG CANCER SURVIVABILITY 7\ncentage of correctly classified instances. The Kappa statistic is  a   chancecorrected   measure   and   reflects   the   agreement  between the classifications and the true classes. Values over  zero   indicate   that   the   classifier   is   performing   better   than  chance.  The  RMSE  measures   the  differences  between  pre dicted or estimated values against observed values.\nTABLE 7: DETAILED EXPERIMENT RESULTS FOR THE NAIVE BAYES ALGORITHM.\n5 years 7 years 10 years\nCCI 14,577 (92.38%) 15,175  (88.27%)\n15,208  (89.13%)\nICI 1,203 (7.62%) 2,017  (11.73%) 1,855  (10.87%)\nκ 0.49100 0.53610 0.51360 RMSE 0.24710 0.30750 0.29770\nTotal 15,780 17,192 17,063\nThe  J48  algorithm  was  also  executed  over  the  same  Training Data date  ranges and produced correctly classi fied instances ranging from 89.63% to 94.44% (Table 8). \nComparing the overall accuracy of the two algorithms,  it  seems  that  both  algorithms  performed  fairly  well,  achieving approximately a 90% correct classification rate.  The  J48  algorithm  consistently  performed  slightly  better  than the Naive Bayes algorithm in successfully predicting  the correct survivability outcome (Table 9).\nFor all executions,  the values of the  kappa statistic in dicate the strength of the classifier's stability and in our  experimentation, both algorithms perform well.  Similarly, \nusing the RMSE, the    low  error  rate  of both algorithms  can serve as an indirect measure of effectiveness. "
    }, {
      "heading" : "5 DISCUSSION",
      "text" : ""
    }, {
      "heading" : "5.1 Classification Results",
      "text" : "The  objective  of  the  experiments  was  to  compare  the  strength  of  the  two  techniques  in  survivability  prediction  of  patients diagnosed with  lung cancer. While an approximately  90% overall correct classification accuracy is achieved, there is  an unexpected result.\nFor  both  the  Naive  Bayes  and the J48  algorithm,  the  5 year  training  dataset  produces  a  higher  accuracy  rate  than  the  7year and 10year training datasets. In fact, the 5year  training dataset outperforms and is  slightly more accurate  than  the  accuracy  provided   from  the  7  year   and  10year  training data sets. It would be expected to have a higher pre diction accuracy with more training data but this is not the  case. There are two possible factors at play. First, the difference  in the number of patient records between the three data sets is  not proportional.  The  5year  training  set  includes 15,780  lung  cancer  patient  records  and  the  7year  training  set  includes  17,192. This is a difference of 1,412 (an 8.94% increase) of patient  records. On  the  other  hand,  the  10year  training  set  includes  17,063  lung  cancer patient  records, which  is  a  0.75% decrease  (129  patients)  than  the  the  7year  data  set.   So  the  difference  between the 5year and 7year data set is not significantly dif ferent. Second,  it is likely that the larger training data set may  contain  inconsistencies  due  to  changes  in  the  data  collection  processes  and  locations. The 5year  training  set  contains data  primarily from one SEER reporting location.  In 1992, a second  SEER  reporting  location began  collecting data, which was  in cluded  in  the  bulk  of  the  dataset  for  the  7 year  and  10year  studies.  "
    }, {
      "heading" : "7 CONCLUSION & FUTURE WORK",
      "text" : "This study examines the ability of data mining and machine  learning methods  to  accurately  predict  the  survivability  of  patients  diagnosed  with  lung  cancer.   Survivability  is  defined as someone who lives beyond a 5year period.  \nGenerally, we achieve an approximate prediction accuracy  around  90%  using  either  the  Naive  Bayes  or   the    J48  al gorithm.     As a result of this study, a treating physician  can  theoretically collect a handful of medical measurements such  as tumor size and location, treatment options, patient’s back ground, etc., and predict with a fairly high degree of accur acy whether the patient is likely to live for five or more years.\nConsidering the high mortality rate (>90%) of the patients  in  the study,  it seems reasonable and useful  to examine  the  survivability  of  patients  over  a  shorter  time  period,  for ex ample, between twelve and eighteen months.   In light of the  findings and observations of  the study,  future  research will  be  focused on examining regional  trends and  the  impact of  location on survivability.  More in depth analysis can also be  performed by  comparing  survivability  results with data  re lated  to  regional medical  insurance  carriers,  state  laws  that  affect  the  medical  insurance  industry,  and  other  external  factors.\nIn this paper, we compared the effectiveness of the Naive  Bayes classification algorithm and the J48 implementation of  the C4.5 decision tree algorithm in the prediction of surviv ability for a specific disease.\nFrom the results, the Naive Bayes technique remained true  to its reputation and its portrayal in the literature: it is robust,  easy to interpret, it often does surprisingly well but may not  be the best classifier in any particular application [15]. In this  case,  Naive   Bayes   performed   consistently  worse   than   J48.  Yet, its simplicity and fairly competitive performance make it  an appealing alternative. Overall, both are viable and useful  algorithms and the  performance  differences  between  them  were marginal. More work will be done to investigate if these  marginal differences exist due to the way the algorithms are  implemented or due to inherent characteristics in the data."
    }, {
      "heading" : "ACKNOWLEDGMENT",
      "text" : "The authors wish to thank SEER and the National Cancer In stitute for the data. \nREFERENCES\n[1] American Cancer Society, Cancer Facts & Figures. American Cancer  Society, Atlanta,  GA, 2010, URL: http://www.cancer.org/research/.\n[2] Bellaachia, A., Guven, E. Predicting Breast Cancer Survivability using  Data Mining Techniques, Ninth Workshop on Mining Scientific and  Engineering Datasets in conjunction with the Sixth SIAM International  Conference on Data Mining (SDM 2006), Saturday, April 22, 2006. \n[3] Biesalski,  H  K  and  Bueno  de  Mesquita,  B  and  Chesson,  A  and  Chytil, F and Grimble, R and Hermus, R J and Kohrle, J and Lotan,  R  and Norpoth,  K  and  Pastorino, U  and  Thurnham, D,  European  Consesus  Statement  on  Lung  Cancer:  risk  factors  and  prevention.  Lung Cancer Panel.. CA Cancer J  Clin, 48, 3, 16776; discussion 1646,  URL:  http://www.biomedsearch.com/nih/EuropeanCon sensusStatementLungCancer/9594919.html.\n[4] Catelinois, Olivier and Rogel, Agnes and Laurier, Dominique and Bil lon,  Solenne  and Hemon, Denis  and Verger,  Pierre  and Tirmarche,  Margot, 2006, Lung cancer attributable   to indoor radon exposure in  France: impact of the risk models and uncertainty analysis., Environ mental Health Perspectives, 114 (9), 13616.\n[5] Darnton, Andrew J and McElvenny, Damien M and Hodgson, John  T, 2006, Estimating the number of asbestosrelated lung cancer deaths  in Great Britain from 1980 to 2000.   The Annals of occupational hy giene, 50 (1), 2938.\n[6] Dechang  Chen,  Kai  Xing,  Donald  Henson,  Li  Sheng,  Arnold  M.  Schwartz, and Xiuzhen  Cheng. 2008. A Clustering Approach in De veloping Prognostic Systems of Cancer Patients. In Proceedings of the  2008 Seventh International Conference on Machine Learning and Ap plications  (ICMLA  ’08).  IEEE  Computer  Society,  Washington,  DC,  USA,  723728.\n[7] Dursun Delen  and Nainish  Patil.  2006.  Knowledge  Extraction  from  Prostate Cancer Data. In Proceedings of the 39th Annual Hawaii In ternational Conference on System Sciences  (HICSS ’06), Vol. 5. IEEE  Computer Society, Washington, DC, USA, 92.2.\n[8] Fritz,  A,  Jack,  A  Percy,C  Sobin,  L  Parkin,  D.M..(eds.)  International  classification of diseases for oncology (ICD O). 3d ed. Geneva: World  Health Organization, 2000.\n[9] Gandhi, G M and Srivatsa,  S.K.  (2010). Classification Algorithms  in  Comparing Classifier Categories to Predict the Accuracy of the Net work Intrusion Detection  A Machine Learning Approach. Advances \nin Computational Sciences and Technology, 3 (3), 321 334. [10] García, V.,  Sanchez, J., Mollinenda, R. (2008)  \"An Empirical Study of \nthe Behavior of Classifiers on Imbalanced and Overlapped Data Sets\",  Lecture Notes in Computer Science, Volume 4756, Progress in Pattern  Recognition, Image Analysis and Applications, Pages 397406.\n[11] Hackshaw, AK and Law, MR and Wald, NJ. 1997. The accumulated  evidence on  lung cancer and environmental  tobacco smoke. British  Medical Journal, 315 (7114), 980988.\n[12] Hall M and Eibe F and Holmes G and Pfahringer B and Reutemann  P and Witten I H. 2009. The WEKA Data Mining Software: An Up date; SIGKDD Explorations, 11 (1).\n[13] Kowsalya, R. Sasikala, G, Sangeetha Priya J. 2010. Acute Cystitis and  Acute  Nephritis  Prediction  Using  Machine  Learning  Techniques.  Global Journal of Computer Science and Technology, 10 (8), 1416.\n[14] Lavesson,  Niklas  and  Davidson,  Paul.  2004.  A  multidimensional  measure  function  for   classifier performance.  In Proceedings  of  the  2nd IEEE International Conference on Intelligent Systems, June 2004 ,  pp.508513.\n[15] O’Reilly, Katherine M A and Mclaughlin, Anne Marie and Beckett,  William S and Sime, Patricia  J. 2007. Asbestosrelated  lung disease.,  American Family Physician, 75 (5), 6838.\n[16] Panda M and Patra M R. 2008. A Comparative Study of Data Min ing Algorithms  for Network  Intrusion Detection.  In Proceedings of  the 2008 First  International Conference on Emerging Trends  in En gineering  and  Technology  (ICETET  ’08).  IEEE  Computer  Society,  Washington, DC, USA, 504507.\n[17] Panda M and Patra M R.  2007. Network  Intrusion Detection using  Naive Bayes, International journal of Computer Science and Network  Security, DecˆAZ302007, pp.258263.\n[18] Peddabachigari, S., Abraham, A., Grosan, G., Thomas, J.. 2007. Model ing intrusion detection system using hybrid intelligent systems. J. Netw.  Comput. Appl. 30, 1 (January 2007), 114132. \n[19] Quinlan R J. 1990. Decision Trees and Decision Making. IEEE Trans action on System Man  Cyber, March/April 1990, 20(2).\n[20] Quinlan  R  J.  1993.  C4.5:  Programs  for Machine  Learning. Morgan  Kaufmann Publishers Inc., San Francisco, CA, USA.\n[21] Quinlan  R  J.  1996.  Improved  use  of  continuous  attributes  in  C4.5.  Journal of Artificial Intelligence Research, 4:7790, 1996.\n[22] Samet  J M and Wiggins C L  and Humble C G  and Pathak D R.  1998. Cigarette smoking and lung cancer in New Mexico. The Amer ican Review of Respiratory Disease\n[23] Soman, T. and Bobbie, P.O. 2005, Classification of Arrhythmia Using  Machine Learning Techniques. WSEAS Transactions on Computers,  Vol.4, issue 6, June 2005, pp. 548552.\n[24] Surveillance,  Epidemiology,  and  End  Results  (SEER)  Program  (www.seer.cancer.gov)  Research  Data  (19732004),  National  Cancer  Institute,  DCCPS,  Surveillance  Research  Program,  Cancer  Statistics  Branch, released April 2010, based on the November 2009   submis sion.\n[25] U.S.  Cancer  Statistics  Working  Group.  2010.  United  States  Cancer  Statistics:  19992006  Incidence and Mortality Webbased Report. At lanta (GA): Department of Health and Human Services, Centers for  Disease Control and Prevention, and National Cancer Institute; 2010.  URL: ”http://www.cdc.gov/uscs”.\n[26] Yanwei  Xing,  Jie  Wang,  Zhihong  Zhao,  and  and  Yonghong  Gao.  2007. Combination Data Mining Methods with New Medical Data to  Predicting Outcome  of Coronary Heart Disease.  In  Proceedings  of  the 2007 International Conference on Convergence Information Tech nology (ICCIT ’07).  IEEE Computer Society, Washington, DC, USA,  868872.\nDIMITOGLOU: COMPARISON OF THE C4.5 AND NAIVE BAYES CLASSIFIERS FOR THE PREDICTION OF LUNG CANCER SURVIVABILITY 9\n[27] Youn S. and McLeod D. 2006. A Comparative Study for Email Classi fication, Proceedings of International Joint Conferences on Computer,  Information, System Sciences, and Engineering (CISSE’06), Bridgeport  CT, December 2006.\n[28] World Health Organization. 19921994. International Statistical Classi fication of Dis eases and Related Health Problems (ICD10), 10th Re vision. 3 vols. Geneva: WHO.\n[29] Witten Ian H and Frank Eibe. 2005. Data Mining: Practical Machine  Learning  Tools  and  Techniques.  The  Morgan  Kaufmann  Series  in  Data  Management  Systems.  2nd  Ed.  Morgan  Kaufmann,  2005.  1988;137(5):11103.\nGeorge Dimitoglou is Associate Professor of computer science at Hood College. He holds a doctorate in computer science from The George Washington University. He is a member of the IEEE, the ACM and the Mathematical Association of America.\nJames A. Adams is Sr. Systems Analyst with Marriott International. He holds a M.S. in computer science from Hood College where he received the 2008 Departmental Scholar Award.\nCarol A. Jim is a doctoral student in computer science at The George Washington University. She holds a B.S. in mathematics and computer science and a M.S. in computer science from Hood College where she received the 2010 Departmental Scholar Award."
    } ],
    "references" : [ {
      "title" : "Predicting Breast Cancer Survivability using Data Mining Techniques, Ninth Workshop on Mining Scientific and Engineering Datasets in conjunction with the Sixth SIAM International Conference on Data Mining (SDM",
      "author" : [ "A. Bellaachia", "E. Guven" ],
      "venue" : null,
      "citeRegEx" : "2",
      "shortCiteRegEx" : "2",
      "year" : 2006
    }, {
      "title" : "Lung cancer attributable to indoor radon exposure in France: impact of the risk models and uncertainty analysis",
      "author" : [ "Catelinois", "Olivier", "Rogel", "Agnes", "Laurier", "Dominique", "Bil­ lon", "Solenne", "Hemon", "Denis", "Verger", "Pierre", "Tirmarche", "Margot" ],
      "venue" : "Environ­ mental Health Perspectives,",
      "citeRegEx" : "4",
      "shortCiteRegEx" : "4",
      "year" : 2006
    }, {
      "title" : "Estimating the number of asbestos­related lung cancer deaths in Great Britain",
      "author" : [ "Darnton", "Andrew J", "McElvenny", "Damien M", "Hodgson", "John T" ],
      "venue" : "The Annals of occupational hy­ giene,",
      "citeRegEx" : "5",
      "shortCiteRegEx" : "5",
      "year" : 2006
    }, {
      "title" : "A Clustering Approach in De­ veloping Prognostic Systems of Cancer Patients",
      "author" : [ "Dechang Chen", "Kai Xing", "Donald Henson", "Li Sheng", "Arnold M. Schwartz", "Xiuzhen Cheng" ],
      "venue" : "In Proceedings of the 2008 Seventh International Conference on Machine Learning and Ap­ plications (ICMLA ’08)",
      "citeRegEx" : "6",
      "shortCiteRegEx" : "6",
      "year" : 2008
    }, {
      "title" : "Knowledge Extraction from Prostate Cancer Data",
      "author" : [ "Dursun Delen", "Nainish Patil" ],
      "venue" : "In Proceedings of the 39th Annual Hawaii In­ ternational Conference on System Sciences (HICSS ’06),",
      "citeRegEx" : "7",
      "shortCiteRegEx" : "7",
      "year" : 2006
    }, {
      "title" : "Classification Algorithms in Comparing Classifier Categories to Predict the Accuracy of the Net­ work Intrusion Detection ­ A Machine Learning Approach",
      "author" : [ "G M Gandhi", "S.K. Srivatsa" ],
      "venue" : "Advances  in Computational Sciences and Technology,",
      "citeRegEx" : "9",
      "shortCiteRegEx" : "9",
      "year" : 2010
    }, {
      "title" : "An Empirical Study of the Behavior of Classifiers on Imbalanced and Overlapped Data Sets\", Lecture Notes in Computer Science, Volume 4756, Progress in Pattern Recognition, Image Analysis and Applications, Pages 397­406",
      "author" : [ "V. García", "J. Sanchez", "R. Mollinenda" ],
      "venue" : null,
      "citeRegEx" : "10",
      "shortCiteRegEx" : "10",
      "year" : 2008
    }, {
      "title" : "The accumulated evidence on lung cancer and environmental tobacco smoke",
      "author" : [ "AK Hackshaw", "MR Law", "Wald", "NJ" ],
      "venue" : "British Medical Journal,",
      "citeRegEx" : "11",
      "shortCiteRegEx" : "11",
      "year" : 1997
    }, {
      "title" : "The WEKA Data Mining Software: An Up­",
      "author" : [ "M Hall", "F Eibe", "G Holmes", "B Pfahringer", "P Reutemann", "H. Witten I" ],
      "venue" : "date; SIGKDD Explorations,",
      "citeRegEx" : "12",
      "shortCiteRegEx" : "12",
      "year" : 2009
    }, {
      "title" : "Acute Cystitis and Acute Nephritis Prediction Using Machine Learning Techniques",
      "author" : [ "Kowsalya", "G R. Sasikala", "Sangeetha Priya J" ],
      "venue" : "Global Journal of Computer Science and Technology,",
      "citeRegEx" : "13",
      "shortCiteRegEx" : "13",
      "year" : 2010
    }, {
      "title" : "A multidimensional measure function for classifier performance",
      "author" : [ "Lavesson", "Niklas", "Davidson", "Paul" ],
      "venue" : "In Proceedings of the 2nd IEEE International Conference on Intelligent Systems,",
      "citeRegEx" : "14",
      "shortCiteRegEx" : "14",
      "year" : 2004
    }, {
      "title" : "Asbestos­related lung disease",
      "author" : [ "O’Reilly", "Katherine M A", "Mclaughlin", "Anne Marie", "Beckett", "William S", "Sime", "Patricia J" ],
      "venue" : "American Family Physician,",
      "citeRegEx" : "15",
      "shortCiteRegEx" : "15",
      "year" : 2007
    }, {
      "title" : "A Comparative Study of Data Min­ ing Algorithms for Network Intrusion Detection",
      "author" : [ "M Panda", "R. Patra M" ],
      "venue" : "In Proceedings of the 2008 First International Conference on Emerging Trends in En­ gineering and Technology (ICETET ’08)",
      "citeRegEx" : "16",
      "shortCiteRegEx" : "16",
      "year" : 2008
    }, {
      "title" : "Network Intrusion Detection using Naive Bayes, International journal of Computer Science and Network Security, DecˆAZ30­2007, pp.258­263",
      "author" : [ "M Panda", "R. Patra M" ],
      "venue" : null,
      "citeRegEx" : "17",
      "shortCiteRegEx" : "17",
      "year" : 2007
    }, {
      "title" : "Model­ ing intrusion detection system using hybrid intelligent systems",
      "author" : [ "S. Peddabachigari", "A. Abraham", "G. Grosan", "Thomas" ],
      "venue" : "J. Netw. Comput. Appl. 30,",
      "citeRegEx" : "18",
      "shortCiteRegEx" : "18",
      "year" : 2007
    }, {
      "title" : "Decision Trees and Decision Making",
      "author" : [ "J. Quinlan R" ],
      "venue" : "IEEE Trans­ action on System Man Cyber,",
      "citeRegEx" : "19",
      "shortCiteRegEx" : "19",
      "year" : 1990
    }, {
      "title" : "Improved use of continuous attributes in C4.5",
      "author" : [ "J. Quinlan R" ],
      "venue" : "Journal of Artificial Intelligence Research,",
      "citeRegEx" : "21",
      "shortCiteRegEx" : "21",
      "year" : 1996
    }, {
      "title" : "Cigarette smoking and lung cancer in New Mexico. The Amer­ ican Review of Respiratory Disease",
      "author" : [ "M Samet J", "L Wiggins C", "G Humble C", "R. Pathak D" ],
      "venue" : null,
      "citeRegEx" : "22",
      "shortCiteRegEx" : "22",
      "year" : 1998
    }, {
      "title" : "Classification of Arrhythmia Using Machine Learning Techniques",
      "author" : [ "T. Soman", "P.O. Bobbie" ],
      "venue" : "WSEAS Transactions on Computers,",
      "citeRegEx" : "23",
      "shortCiteRegEx" : "23",
      "year" : 2005
    }, {
      "title" : "Combination Data Mining Methods with New Medical Data to Predicting Outcome of Coronary Heart Disease",
      "author" : [ "Yanwei Xing", "Jie Wang", "Zhihong Zhao", "Yonghong Gao" ],
      "venue" : "In Proceedings of the 2007 International Conference on Convergence Information Tech­ nology (ICCIT ’07)",
      "citeRegEx" : "26",
      "shortCiteRegEx" : "26",
      "year" : 2007
    }, {
      "title" : "A Comparative Study for Email Classi­ fication",
      "author" : [ "S. Youn", "D. McLeod" ],
      "venue" : "Proceedings of International Joint Conferences on Computer,",
      "citeRegEx" : "27",
      "shortCiteRegEx" : "27",
      "year" : 2006
    }, {
      "title" : "Data Mining: Practical Machine Learning Tools and Techniques",
      "author" : [ "Witten Ian H", "Frank Eibe" ],
      "venue" : "James A. Adams is Sr. Systems Analyst with Marriott International. He holds a M.S. in computer science from Hood College where he received the 2008 Departmental Scholar Award. Carol A. Jim is a doctoral student in computer science at The George Washington University. She holds a B.S. in mathematics and computer science and a M.S. in computer science from Hood College where she received the 2010 Departmental Scholar Award",
      "citeRegEx" : "29",
      "shortCiteRegEx" : "29",
      "year" : 2005
    } ],
    "referenceMentions" : [ {
      "referenceID" : 0,
      "context" : "This type of analysis is not unique, in fact it was inspired by a similar analysis on breast cancer survivab­ ility techniques [2].",
      "startOffset" : 127,
      "endOffset" : 130
    }, {
      "referenceID" : 8,
      "context" : "Smoking  has  been  identified  as  the greatest contributing cause [3, 12, 22] but exposure to asbes­ tos [6, 16] and radon gas [5] have also been linked with the in­ cidence of the disease.",
      "startOffset" : 68,
      "endOffset" : 79
    }, {
      "referenceID" : 17,
      "context" : "Smoking  has  been  identified  as  the greatest contributing cause [3, 12, 22] but exposure to asbes­ tos [6, 16] and radon gas [5] have also been linked with the in­ cidence of the disease.",
      "startOffset" : 68,
      "endOffset" : 79
    }, {
      "referenceID" : 3,
      "context" : "Smoking  has  been  identified  as  the greatest contributing cause [3, 12, 22] but exposure to asbes­ tos [6, 16] and radon gas [5] have also been linked with the in­ cidence of the disease.",
      "startOffset" : 107,
      "endOffset" : 114
    }, {
      "referenceID" : 12,
      "context" : "Smoking  has  been  identified  as  the greatest contributing cause [3, 12, 22] but exposure to asbes­ tos [6, 16] and radon gas [5] have also been linked with the in­ cidence of the disease.",
      "startOffset" : 107,
      "endOffset" : 114
    }, {
      "referenceID" : 2,
      "context" : "Smoking  has  been  identified  as  the greatest contributing cause [3, 12, 22] but exposure to asbes­ tos [6, 16] and radon gas [5] have also been linked with the in­ cidence of the disease.",
      "startOffset" : 129,
      "endOffset" : 132
    }, {
      "referenceID" : 4,
      "context" : "As  a   result,  methods  and  tech­ niques   from the  computing sciences   related  to  knowledge discovery   and   data  mining   have   become   very   useful   in identifying patterns and analyzing relationships in the data that may lead to better disease outcome prediction [7, 8, 23, 26].",
      "startOffset" : 280,
      "endOffset" : 294
    }, {
      "referenceID" : 18,
      "context" : "As  a   result,  methods  and  tech­ niques   from the  computing sciences   related  to  knowledge discovery   and   data  mining   have   become   very   useful   in identifying patterns and analyzing relationships in the data that may lead to better disease outcome prediction [7, 8, 23, 26].",
      "startOffset" : 280,
      "endOffset" : 294
    }, {
      "referenceID" : 19,
      "context" : "As  a   result,  methods  and  tech­ niques   from the  computing sciences   related  to  knowledge discovery   and   data  mining   have   become   very   useful   in identifying patterns and analyzing relationships in the data that may lead to better disease outcome prediction [7, 8, 23, 26].",
      "startOffset" : 280,
      "endOffset" : 294
    }, {
      "referenceID" : 13,
      "context" : "The basic premise is based on treating a collection of cases as input, each belonging to a small number of classes described by a fixed set of attributes [17].",
      "startOffset" : 154,
      "endOffset" : 158
    }, {
      "referenceID" : 13,
      "context" : "Classification may be viewed as mapping from a set of attributes to a particular class [17].",
      "startOffset" : 87,
      "endOffset" : 91
    }, {
      "referenceID" : 11,
      "context" : "The algorithm uses Bayes theorem [15] and assumes all attributes to be independent   given the value of  the class variable.",
      "startOffset" : 33,
      "endOffset" : 37
    }, {
      "referenceID" : 14,
      "context" : "This  conditional  independence  assumption rarely  holds  true  in  real­world   applications,  hence  the characterization as Naive yet  the algorithm  tends  to per­ form well and  learn rapidly in various supervised classi­ fication problems [18].",
      "startOffset" : 246,
      "endOffset" : 250
    }, {
      "referenceID" : 15,
      "context" : "5  [20]  which  is  the  suc­ cessor of the ID3 algorithm [19].",
      "startOffset" : 58,
      "endOffset" : 62
    }, {
      "referenceID" : 14,
      "context" : "Then, for each of the leaves it repeats the process using the training set data classified by this leaf [18].",
      "startOffset" : 104,
      "endOffset" : 108
    }, {
      "referenceID" : 16,
      "context" : "The ID3 algorithm [21] uses entropy and information gain [29],   bor­ rowed from information theory,  to measure  the  impurity of the data items.",
      "startOffset" : 18,
      "endOffset" : 22
    }, {
      "referenceID" : 21,
      "context" : "The ID3 algorithm [21] uses entropy and information gain [29],   bor­ rowed from information theory,  to measure  the  impurity of the data items.",
      "startOffset" : 57,
      "endOffset" : 61
    }, {
      "referenceID" : 21,
      "context" : "Informa­ tion gain [29] measures the decrease of the weighted average entropy of  the  attributes  compared with  the  entropy of  the complete  dataset.",
      "startOffset" : 19,
      "endOffset" : 23
    }, {
      "referenceID" : 6,
      "context" : "For example,  in the  context  of  intrusion  detection  systems,  one  study  [10] found  J48 performing better than another similar study [16], while studies in the prediction of acute cystitis and  nephritis [14]  and  the  classification  of  arrhythmia  data  [23]  the  per­ formance of Naive Bayes was superior.",
      "startOffset" : 79,
      "endOffset" : 83
    }, {
      "referenceID" : 12,
      "context" : "For example,  in the  context  of  intrusion  detection  systems,  one  study  [10] found  J48 performing better than another similar study [16], while studies in the prediction of acute cystitis and  nephritis [14]  and  the  classification  of  arrhythmia  data  [23]  the  per­ formance of Naive Bayes was superior.",
      "startOffset" : 140,
      "endOffset" : 144
    }, {
      "referenceID" : 10,
      "context" : "For example,  in the  context  of  intrusion  detection  systems,  one  study  [10] found  J48 performing better than another similar study [16], while studies in the prediction of acute cystitis and  nephritis [14]  and  the  classification  of  arrhythmia  data  [23]  the  per­ formance of Naive Bayes was superior.",
      "startOffset" : 211,
      "endOffset" : 215
    }, {
      "referenceID" : 18,
      "context" : "For example,  in the  context  of  intrusion  detection  systems,  one  study  [10] found  J48 performing better than another similar study [16], while studies in the prediction of acute cystitis and  nephritis [14]  and  the  classification  of  arrhythmia  data  [23]  the  per­ formance of Naive Bayes was superior.",
      "startOffset" : 265,
      "endOffset" : 269
    }, {
      "referenceID" : 20,
      "context" : "Similarly, in the con­ text of spam e­mail identification [27], J48   performed better in  terms  of  accuracy  of  overall  classification  despite  the widespread use of Bayesian­based span filtering techniques.",
      "startOffset" : 58,
      "endOffset" : 62
    }, {
      "referenceID" : 9,
      "context" : "10  of  the  open  source toolkit  Weka  to  Environment  for  Knowledge  Analysis (WEKA) [13] to determine the accuracy of two algorithms in predicting lung cancer survivability.",
      "startOffset" : 90,
      "endOffset" : 94
    }, {
      "referenceID" : 5,
      "context" : "Tumor location in the body, as classi­ fied by the International Classification of Diseases for On­ cology (ICD­O­3) [9] for topography codes.",
      "startOffset" : 117,
      "endOffset" : 120
    }, {
      "referenceID" : 11,
      "context" : "From the results, the Naive Bayes technique remained true to its reputation and its portrayal in the literature: it is robust, easy to interpret, it often does surprisingly well but may not be the best classifier in any particular application [15].",
      "startOffset" : 243,
      "endOffset" : 247
    } ],
    "year" : 2012,
    "abstractText" : "Numerous data mining techniques have been developed to extract information and identify patterns and predict trends from large data sets. In this study, two classification techniques, the J48 implementation of the C4.5 algorithm and a Naive Bayes classifier are applied to predict lung cancer survivability from an extensive data set with fifteen years of patient records. The purpose of the project is to verify the predictive effectiveness of the two techniques on real, historical data. Besides the performance outcome that renders J48 marginally better than the Naive Bayes technique, there is a detailed description of the data and the required pre-processing activities. The performance results confirm expectations while some of the issues that appeared during experimentation, underscore the value of having domain-specific understanding to leverage any domain-specific characteristics inherent in the data.",
    "creator" : "Writer"
  }
}