{
  "name" : "1706.05123.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : null,
    "authors" : [ ],
    "emails" : [ "wxu@caltech.edu", "stalzer@caltech.edu" ],
    "sections" : [ {
      "heading" : null,
      "text" : "ar X\niv :1\n70 6.\n05 12\n3v 1\n[ cs\n.L G\n] 1\n6 Ju\nn 20"
    }, {
      "heading" : "1 Introduction",
      "text" : "Data driven discovery, which involves finding meaning and patterns in data, has been experiencing significant progress in quantifying behaviors, complexity, and relationships among data sets [1]. In various subjects, such as physics, chemistry, and finance, there exist relationships between various parameters. These relationships can be discovered by proofs, conjecture, or approximated using assumptions via the scientific method. The scientific method has been the mainstay of understanding the laws that govern the universe. The method is based on observations that provide data in order to develop theories to predict future observations. It often starts with a mathematical hypothesis which is then verified by seeing how well the observed data fits a hypothesized model. However, the scientific method is rarely applied in the converse, formulating a plausible mathematical hypothesis using data. Algorithms are developed to autonomously discover these relationships using sets of data alone, organized into input and output data. This is accomplished by proposing a series of candidate equations, plugging in the values of the data set into each equation, and determining how well the data fits each equation, typically using least squared methods. Notable progress has been made in applying different approaches [2].\nDespite the progresses, challenges still exist. One problem with existing approaches is that without any assumptions on the relationship’s format, arriving at the desired candidate equation is computationally slow. To address this, there are various algorithms that enumerate through these candidates. These algorithms must use some method of quantifying equation complexity in order to organize its enumeration and ensure every candidate equation of that complexity is written. One such method is the representation of an equation as a tree, where the nodes represent operators, the leaves represent data, and the complexity calculated as the sum of nodes and leaves [3]. However, this still means that the number of candidates increases exponentially with respect to complexity, meaning any brute-force algorithm causes high complexity equations to take an unreasonable amount of time to reach and verify against the data [4].\nThe second problem is about constants. Many natural relationships have constants as part of their equations. An algorithm that enumerates through candidate equations does not take into account its constants. The Pareto frontier technique can be used to calculate these constants for the candidate equations. However, this method only gives you an approximation of the constants. In addition, this method does not explicitly rule out any candidate equations, as it accepts candidate equations and constants with a squared residual within a bound [3]. The sparsity of a given data set can also be used to bound the coefficients of the desired compact law [5]. To the knowledge of the authors, there is currently no algorithm that explicitly rejects candidate equations that cannot be fitted with constants to the data, and also explicitly finds constants that allow candidate equations to be fitted to the data.\nThe third problem is on narrowing down the enumeration for the candidate equations. Bruteforce methods lead to an unacceptable program run time [6]. To combat this, algorithms have employed genetic algorithms and neural networks to introduce speed-ups in the program. Genetic algorithms introduce slight mutations in a candidate equation to single out operators and constants that fit the data well [7]. Mutated equations that are promising, through some metric, generate equations with similar attributes, some with further mutations. This process is repeated until a candidate equation is found that can fit the data [8].\nTo combat the challenges, various approaches have been proposed. Machine learning based on the Neural Networks has shown its effective way in developing relationships using high through-\nput experimental data in novel ways [9]. It is recognized that, for many applications, it is far easier to train a system using desired input-output examples than enumerating rules to obtain the desired response. Although convergence to the desired input-output relationships can be achieved via intensive and extensive training, there are no methods to prove that these machine learning algorithms converge onto a natural law based on the data [10].\nA new and prospective area of data-driven discovery is the development of automated science. Automated science involves creating algorithms that analyze data sets in order to create compact laws governing that data. A compact law refers to mathematically explicit description or equation that exactly describes the data [11]. Among recent advances, one approach is based on statistical and model driven methods, for example, the use of Bayesian probabilistic methods and Markov models [12] as the basis of an intelligent system [13], and the expectation maximization algorithm, which converges to a maximum likelihood estimate based on incomplete data [14]. Linear algebraic methods are applied to this field in order to improve run time and ensure convergence to a compact law. One such method is the use of randomized algorithms to decompose and diagonalize sparse matrices. As a result, this can be used to approximate a time dependent system, such as the Maxwell equations, using a Markov model, and thus approximate a system’s behavior over time [15]. In addition, the use of proper orthogonal decomposition on some sets of data can identify linearly dependent data sets to quickly classify bifurcation regimes in non-linear dynamical systems [16]. Further, a method of using a library of functions acting on a sparse vector of constants. The resulting linear equation is then evaluated according to the data. This method was used to re-derive the equations governing the chaotic Lorentz system and fluid vortex shedding behind an obstacle [17]. However, this method relies on separating data into independent and dependent variables. The independent variables are used to construct the function library and generate the compact law governing the dependent variables. Not all data can be cleanly separated into dependent and independent variables, so a method of incorporating all variables into a compact law is needed.\nIn this paper, we develop an innovative approach in discovering compact laws. We propose a novel algebraic equation formulation such that constant determination and candidate equation verification can be explicitly solved with low computational time. The algebraic formulation allows us to represent the evolution of equation candidates in an explicit mathematical manner. We also derive general methods for searching through a family of candidate equations and verifying them with respect to the data. The searching algorithms are defined conventionally and using a finite field to improve running time. The assumption of our approach on the compact law is that it is in some general format and incorporates only constants and variables related to the provided data. There are no assumptions on the data. We show that there is guaranteed convergence toward a valid equation candidate. Thus, for a specific type of compact theory, the discovery can be computationally efficient and mathematically precise. The proposed approach may have implications in many fields of data science, such as re-deriving natural laws of Physics, speculating in finance, and modeling chaotic, non-linear systems.\nThe paper is organized as follows. In section 2, algebraic formulation is proposed for discovering equation candidates in a data set. An algorithm format to determine and verify if a candidate equation fits the data with respect to constants is presented. Proof of theorems for equation validation is shown in section 3. In section 4, search algorithms are proposed in finding candidate equations. We show the algorithm based on finite field sieve has improved performance over the exhaustive search algorithm. In section 5, numerical results are presented using the proposed approach to re-derive the van der Waals equation from raw data, followed by concluding remarks in section 6."
    }, {
      "heading" : "2 Algebraic Formulation",
      "text" : ""
    }, {
      "heading" : "2.1 Virtual Experiment Setup",
      "text" : "Suppose we are presented with some data set, which are the inputs and outputs of some number of experiments. However, we do not know what data are the inputs and outputs. For each category of the data, every data entry must correspond to an experiment. We can organize the data set in the format of a virtual experiment, as in a set of categories of data that relate to one another. Denote a set of n characters representing the categories of our inputs/outputs for the virtual experiment as\nF = {F1, . . . , Fn} (1)\nas the set of n characters representing the categories of our inputs/outputs. For example, consider a virtual experiment that allows us to re-derive the classical force laws. This experiment involves two particles on a plane, some distance apart. Particle one has mass, charge, and velocity, while the other is a fixed mass and charge. Both are in a uniform magnetic field perpendicular to the plane. The set of input categories would be the masses of the two particles, m1,m2, the charges of the two particles, q1, q2, the distance between the two particles, r, the velocity of the first particle, v1, and the strength of the magnetic field, B. This is denoted as\nF = {m1,m2, q1, q2, r, v1, B, a}.\nAs a result, the data sets which we will fit our force law equations onto will be of the form\n{m1,t,m2,t, q1,t, q2,t, rt, v1,t, Bt, at}, 1 ≤ t ≤ r.\nThe data from the force law experiment may be separated into input and output categories. However, given a data set, we need not assume whether each data category is an input or an output to discover an equation that describes the data. We can generalize the equations to only be in terms of the data set categories and constants, regardless of whether those categories are inputs or outputs."
    }, {
      "heading" : "2.2 Equation Search Algorithm Format",
      "text" : "We define an equation search algorithm as a search algorithm that enumerates through equation candidates of a certain format, verifies them, and returns those that describe the data. The format for algebraic equation candidates, outputs of our search algorithm, will be of the form\n0 = A1 + · · ·+As (2)\nwhere all Ai, 1 ≤ i ≤ s is in the form\nAi = F f1 1 . . . F fn n , fj ∈ Z+ ∪ {0}, 1 ≤ j ≤ n, (3)\nand for ∀Ai, Ai 6= A1, . . . , Ai−1, Ai+1, . . . under permutation of the elements of F . This format includes all possible algebraic equations involving elements of F under constants. Let expression Ai evaluated with values F1,t, . . . , Fn,t be denoted as Ai,t. We then define how an equation candidate is determined to describe the data set.\nDefinition 1. Define a “valid equation candidate” of size s and degree d as an equation such that for all r experiments, there exists a unique k2, . . . , ks ∈ R such that for each experiment t,\n0 = A1,t + k2A2,t + · · · + ksAs,t, (4)\nand the maximum exponent of any Fj of all Al is d.\nA valid equation candidate for the force laws [18] described in section 2.1 is 0 = m1m2 + q1q2 + q1v1Br 2 +m1ar 2."
    }, {
      "heading" : "2.3 Determination of Constants",
      "text" : "Suppose we have some equation candidate\n0 = A1 + · · ·+As.\nWe then evaluate this equation for the r virtual experiments, obtaining the numerical values of all Fj , and thus Ai. As a result, we can evaluate for the constants k2, . . . , ks by solving the resulting matrix equation\n\n  −A1,1 ...\n−A1,r\n\n  =\n\n  A2,1 . . . As,1 ... . . . ...\nA2,r . . . As,r\n\n \n\n  k2 ... ks\n\n  . (5)\nEquation (5) is equivalent to the matrix equation\n\n  0 ... 0\n\n  =\n\n  A2,1 . . . As,1 ... . . . ...\nA2,r . . . As,r\n\n \n\n  k2 ... ks\n\n  −\n\n  −A1,1 ...\n−A1,r\n\n  . (6)\nDefinition 2. Let a data matrix of equation candidate\n0 = A1 + · · ·+As.\nwith r experiments be defined as\n\n  A2,1 . . . As,1 ... . . . ...\nA2,r . . . As,r\n\n  (7)\nDefinition 3. Let A∗ denote the conjugate transpose of A such that if\nA =\n\n  A2,1 . . . As,1 ... . . . ...\nA2,r . . . As,r\n\n  ,\nA∗ =\n\n  A2,1 . . . A2,r ... . . . ...\nAs,1 . . . As,r\n\n  . (8)\nwhere Ai,j is defined as the complex conjugate of Ai,j .\nDefinition 4. The Moore-Penrose left pseudoinverse of A ∈ M(m,n,R) is defined as A+ ∈ M(n,m,R),m, n ∈ Z+ such that\nA+A = I, (9)\nthe n× n identity matrix [19]. If the columns of A are linearly independent, then the Moore-Penrose left pseudoinverse is calculated as\nA+ = (A∗A)−1A∗ (10)\nsuch that A+A = ((A∗A)−1A∗)A = (A∗A)−1(A∗A) = I ([19], Theorem 2)."
    }, {
      "heading" : "3 Equation Validation",
      "text" : ""
    }, {
      "heading" : "3.1 Theorems",
      "text" : "We show that the equation validation question (Definition 1) is equivalent to a linear algebra question.\nTheorem 1. If s ≥ 2, s ∈ Z+, The Moore-Penrose left pseudoinverse A+ of data matrix\nA =\n\n  A2,1 . . . As,1 ... . . . ...\nA2,r . . . As,r\n\n \ncan be computed and (AA+ − I)~b = ~0 if and only if its corresponding equation candidate\n0 = A1 + · · ·+As\nis valid.\nProof. If the equation candidate\n0 = A1 + · · ·+As\nis valid, then by definition 1, the definition of the candidate equation being valid, there exists a unique vector\n~k =\n\n  k2 ... ks\n\n  , k2, . . . , ks ∈ R such that\n\n  0 ... 0\n\n  =\n\n  A2,1 . . . As,1 ... . . . ...\nA2,r . . . As,r\n\n \n\n  k2 ... ks\n\n  −\n\n  −A1,1 ...\n−A1,r\n\n  . (11)\nThus, if we define\n~b =\n\n  −A1,1 ...\n−A1,r\n\n  , (12)\nwe obtain the relationship\nA~k = ~b. (13)\nAs a result, the least squares problem min|A~k−~b| has a unique solution, and so the columns of A are linearly independent ([26], 2.4). From (definition 4), we see that if the columns of A are linearly independent, A∗A is invertible, and so the Moore-Penrose left pseudoinverse can be computed as A+ = (A∗A)−1A∗ (10). As a result, multiplying both sides of (13) by A+ gives us\nA+A~k = A+~b,\nand using (9) yields\n~k = A+~b. (14)\nSubstituting (14) in (13) and subtracting ~b from both sides obtains\n(AA+ − I)~b = ~0. (15)\nAssume the Moore-Penrose left pseudoinverse of data matrix A can be computed as A+ and (AA+ − I)~b = ~0. We then have equation\n(AA+ − I)~b = AA+~b−~b = ~0. (16)\nSubstituting A+~b = ~k in (16) yields the desired result\nA~k −~b = ~0.\nWe also see that we obtain some ~k ∈ Rs−1.\nAs a result, there exists a unique k2, . . . , ks such that for all experiments t, 1 ≤ t ≤ r,\n0 = A1,t + k2A2,t + · · · + ksAs,t,\nso by definition 1, the equation candidate\n0 = A1 + · · ·+As\nis valid.\nWe then show some theorems and corollaries that follow immediately from theorem 1.\nTheorem 2. For Fi ∈ F,A1, Fi = 0 is valid if and only if 0 = A1 is valid.\nProof. If there ∃Fi ∈ F,A1 such that Fi = 0 is valid, Fi,1, . . . , Fi,r = 0. Evaluating yields A1,1, . . . , A1,r = 0, and so A1 = 0 is valid. If A1 = 0 is valid, then assume string A1 = B1A ′\n1, where B1 ∈ F . Since R is a field, and all fields are integral domains [27], either B1,1, . . . , B1,r = 0 or A ′ 1,1, . . . , A ′\n1,r = 0. If B1 ∈ F , then B1 = 0 is valid. Else, A ′\n1 = 0 is valid, and so we repeat the previous procedure until we obtain ∃Bi ∈ F,A1 such that Bi = 0 is valid, or A ′\n1 = 1 = 0 is valid, which is false in a field by definition.\nCorollary 1. If r < s− 1, 0 = A1 + · · ·+As cannot be valid.\nProof. If r < s − 1, then there are more columns than rows in the candidate equation’s data matrix\nA =\n\n  A2,1 . . . As,1 ... . . . ...\nA2,r . . . As,r\n\n  ,\nand so the columns of A are not linearly independent. Thus, A∗A is not invertible ([28], Theorem 3), and so A+ cannot be computed. By theorem 1, 0 = A1 + · · · +As cannot be valid.\nCorollary 2. If data matrix A is square and invertible, its corresponding candidate equation is valid.\nProof. If A is square and invertible, we have A+A = I = AA+. As a result, (AA+ − I)~b = [0]~b = ~0. By theorem 1, the corresponding candidate equation is valid.\nCorollary 3. The equation (AA+ − I)~b = ~0 is valid if and only if 1.~b is the eigenvalue, eigenvector pair of matrix AA+.\nProof. Assume (AA+ − I)~b = ~0. As a result, since ~b 6= ~0 because of our equation candidate format, ‖AA+ − I‖ = 0, and so ~b must be an eigenvector of AA+ − I. Assume ~b is an eigenvector of AA+ − I. Thus, by definition, AA+~b = ~b, and so AA+~b − ~b = (AA+ − I)~b = ~0.\nNext we see that by re-expressing equation validation and constant determination as linear algebraic operations, the computational complexity of the validation question (definition 1) can be determined."
    }, {
      "heading" : "3.2 Computational Complexity",
      "text" : "We describe this problem as validating an equation candidate in the family of equation candidates involving elements of F , |F | = n, of size at most s, and of degree at most d that satisfies the data of r experiments. We assume that all additive and multiplicative operations are floating point operations. Evaluating each equation Aj,k, 1 ≤ j ≤ s − 1, 1 ≤ k ≤ r, takes nd. Thus, constructing the matrix equation A will take O(rsdn) time. As a result, determining whether a given equation candidate is valid involves calculating A∗A, determining the existence of (A∗A)−1, calculating AA+, and the value of (AA+ − I)~b. These operations are done in O(rs2), O(s3), O(rs2), and O(rs) time respectively, where s is the size of the equation candidate and r is the number of experiments. By (corollary 1), we see that r ≥ s− 1. Thus, if\nt = max(dn, r), (17)\nthe running time of checking whether an equation candidate is valid is O(tr2). We can now develop a search algorithm that applies this algorithm repeatedly to many different candidate equations to find one that is valid."
    }, {
      "heading" : "4 Equation Candidate Search",
      "text" : ""
    }, {
      "heading" : "4.1 Exhaustive Search Algorithm",
      "text" : "We have demonstrated an algorithm that can verify whether a given candidate equation is valid. However, the second half of the problem of deriving algebraic equations that fit our data set is a\nsearch algorithm that finds valid equation candidates in a certain family of candidate equations. Referring to [20], we can denote this problem as finding a valid equation candidate in the family of equation candidates involving elements of F , |F | = n, of size at most s, and of degree at most d that satisfies the data of r experiments, where r ≥ s − 1 (cor 1). We also bound d such that d ≤ r/n.\nWe describe an exhaustive search algorithm for this problem as follows.\n1. Begin by finding all valid equation candidates of size 1. This simply entails finding all Fi ∈ F such that Fi,t = 0 for each experiment t.\n2. Then find all valid equation candidates of size 2. This is begun by enumerating through all A1 = F f1 1 . . . F fn n , 0 ≤ fj ≤ d, 1 ≤ j ≤ n, and no Fj is such that Fj,t = 0 for each\nexperiment t. For each A1 we generate, we choose each A2 generated as above such that A1 6= A2. We then obtain a list of all possible equation candidates of the form A1 +A2 = 0.\n3. For each candidate A1 +A2 = 0, we apply (1) to verify the equation candidate is valid.\n4. To find all valid equation candidates of size k ≤ s, for each instance of A1+ · · ·+Ak−1 = 0, we add an instance of Ak generated as in step 2 such that Ak 6= A1, . . . , Ak−1,\n5. Repeat the inductive step until you generate all candidate equations of size at most s.\nTo generate each Ai, it requires at most n d steps. Since dn ≤ r, from (17), we see that t = r. Thus, to check the validity of all candidate equations of size at most s, the number of steps is\nnr +\ns ∑\ni=2\nnidtr2 ≈ ndstr2 ≤ n rsn r3 = ( n 1 n )rs r3. (18)\nCombining (18) with the fact that e 1 e ≥ x 1x for all x ∈ R yields (\nn 1 n\n)rs r3 ≤ ( e 1 e )rs r3. (19)\nUsing (18) and (19), we see that the time complexity of this algorithm is eO(1)rs. One drawback of this exhaustive search algorithm is that, in order to enumerate through all equations, the exponents of each variable of each additive term must be enumerated through as well. Using a property of finite fields, there is a method to find all valid equation candidates without parsing through all exponents of a variable."
    }, {
      "heading" : "4.2 Finite Field Sieve Algorithm",
      "text" : ""
    }, {
      "heading" : "4.2.1 Introduction to Finite Fields",
      "text" : "We will explain some relevant properties of finite fields [21]. A finite field of order p is some set Fp such that |Fp| = p, and two operations +, ∗ that satisfy some properties: For all s1, s2, s3 ∈ Fp,\n1. s1 ∗ s2, s1 + s2 ∈ Fp.\n2. (s1 + s2) + s3 = s1 + (s2 + s3).(s1 ∗ s2) ∗ s3 = s1 ∗ (s2 ∗ s3)\n3. s1 + s2 = s2 + s1, s1 ∗ s2 = s2 ∗ s1.\n4. There exists a unique 0, 1 ∈ Fp such that 0 + s1 = s1,1 ∗ s1 = s1.\n5. There exists a unique s3, s4 such that s3 + s1 = 0 and s4 ∗ s1 = 1.\n6. s1 ∗ (s2 + s3) = s1 ∗ s2 + s1 ∗ s3. One important property of a finite field is the order of an element s ∈ Fp. This is defined as the least exponent d ∈ Z+ such that sd = 1. In a finite field where p is prime, every non-zero element in Fp order 1 or a divisor of p− 1."
    }, {
      "heading" : "4.2.2 Algorithm Preliminaries",
      "text" : "Assume we have some valid equation candidate of some degree d. If the data in our data sets are of some finite field Fp, where p is prime, then each Ai = F f1 1 . . . F fn n in our candidate is congruent to F f ′ 1\n1 . . . F f ′ n n , where f ′1 = f1 mod p-1, . . . , f ′ n = fn mod p-1. As a result, if a\nverification algorithm can be performed in a finite field, we can bound the exponents of the family of equation candidates to be searched through. We then show that, through a modified validation algorithm, it is possible to obtain a set of equation candidates such that one of those is a valid equation candidate.\nTheorem 3. Let there exists a homomorphism\nϕ : Q → Z/pZ, (20)\nwhere p is prime, and let each Fj ∈ Q, 1 ≤ j ≤ n. Also, let each F ′j = ϕ(Fj), 1 ≤ j ≤ n, and\nA′i = F ′f1 1 . . . F ′fn n , fj ∈ Z+ ∪ {0}, 1 ≤ j ≤ n. (21)\nIf A1 + · · · + As = 0 is a valid equation candidate, then there exists a solution ~x′ ∈ (Z/pZ)s−1 such that\n\n \nA′2,1 . . . A ′ s,1\n... . . . ... A′2,r . . . A ′ s,r\n\n  ~x′ =\n\n  −A′1,1 ...\n−A′1,r\n\n  . (22)\nProof. Let A be the equation matrix of A1 + · · ·+As and\n~b =\n\n  −A1,1 ...\n−A1,r\n\n  .\nWe see that if there exists a unique ~x ∈ Qs−1 such that A~x − ~b = ~0, then ∃k ∈ Z+, the least common denominator of all entries of A and ~b such that k ( A~x−~b ) = k~0 = ~0, with\nkA ∈ Zr,s−1, k~b ∈ Zr. We then see that ∃~x′ = k~x mod p such that kA~x′ − k~b = ~0 mod p. Define homomorphisms φ : Q → kQ, φ(q) = kq, and Φ : Z → Z/pZ, Φ(kq) = kq mod p. Thus, we can define ϕ : Q → Z/pZ as ϕ(q) = Φ(φ(q)). Thus, we have that Φ(φ(A~x −~b)) = ϕ(A)ϕ(~x) − ϕ(~b) = Φ(φ(~0)) = ~0, so there exists ϕ(~x) such that ϕ(A)ϕ(~x) = ϕ(~b).\nWe can modify the algorithm in (1) for solving a linear system A~x = ~b over a finite field in O(tr2) time if such a solution exists, where the dimensions of A are r× s [22]. As a result, there exists a polynomial time algorithm to ”validate” the equation over the finite field."
    }, {
      "heading" : "4.2.3 Algorithm Description",
      "text" : "We will outline an algorithm to search for valid equation candidates of size at most s and degree at most d that satisfies the data of r experiments, where r ≥ s− 1. Let p ≤ √ d be some prime. In addition, bound d such that d ≤ r/n. Assume that all elements of our data set are floating point numbers and all operations are floating point operations.\n1. Multiply each entry in the data set by a common denominator 10k, k ∈ Z+.\n2. Take the modulo 3 of all elements in the data set and place all values in a duplicate data set D3.\n3. Perform the exhaustive search algorithm in section 4.1 on equation candidates of size s, degree at most 3 − 1 = 2, that satisfies the data in D3 of the r experiments. For the verification algorithm, use (1), but modified to apply to finite fields [22], to write down the validated equation candidates in F3 in some list EqF3.\n4. Repeat steps 2 and 3 for a finite field of order 5, order 7, . . . , p.\n5. Take equation candidates of size at most s and degree d such that, upon taking modulo 3 of each exponent, yields an equation candidate in EqF3, taking modulo 5 of each exponent, yields an equation candidate in EqF5, . . . , taking modulo p of each exponent, yields an equation candidate in EqFp, and write them down in FFV .\n6. Validate the equation candidates in FFV using the original data set and the algorithm denoted in 1 to obtain the valid equation candidates.\nTo multiply entry in the data set by a common denominator 10k, k ∈ Z+ takes nr operations. Taking the modulo p of each operation takes nrO(1) operations. Since dn ≤ r, from (17), we see that t = r. We then see that p ≤ √ d ≤ √\nr/n. Thus, using (18) and (19), checking the validity of all candidate equations of size at most p is approximately\nn √ r n r3) ≈ eO(1) √ rs. (23)\nTo find all equation candidates in FFV involves first finding equation candidates in EqF3 equivalent to, with respect to modulo 3 of the exponents, equation candidates in EqF5, with respect to modulo 5 of the exponents, and so on, and placing them in FFV ′. This is accomplished by solving n linear equations, at most p times, on at most n3s equation candidates. This takes n3s+1O(d2)p. This shows that |FFV ′| = k is approximately constant. We also must take into account that the exponents of those equation candidates in FFV ′ are in modulo p. For each exponent, there are p possible exponents because p ≤ √ d. As a result, there are k (ns)p equation candidates in FFV that we must validate using the algorithm denoted in 1. Thus, using (18) and (19), the running time is\nk (ns)p r3 ≈ eO(1)s √ rr3. (24)\nThus, adding the running times of (23) and (24) yields the running time of the Finite Field Sieve, which is\neO(1) √ rs. (25)"
    }, {
      "heading" : "5 Numerical Results",
      "text" : "Equation candidates for the van der Waals equation of state [23], (\nP + a ( n\nV\n)2 )(\nV n − b\n)\n= RT =⇒\nPV 3 − bnPV 2 + an2V − abn3 −RnV 2T = PV 3 + k2nPV 2 + k3n 2V + k4n 3 + k5nV 2T = 0,\n(26)\nwere generated and verified using simulated data. The pressure P , volume V , and number of moles n for 20 different virtual experiments were generated randomly. The van der Waals coefficients a = 2.45×10−2, b = 2.661×10−5 were values for hydrogen, the gas constant R was set as 8.3145. For each experiment, the temperature T was calculated. The set of inputs and outputs that compose our candidate equations is L∪F = {P, V, n, T}. The data points are recorded in Table 1. We searched in the family of algebraic equation candidates\nof additive size 5 and exponent order 5. The exhaustive search and finite field sieve methods were used to generate candidate equations and apply their respective search methods to find the valid equation candidates. For various valid and invalid candidates related to the van der Waals equation, the existence of the Moore-Penrose inverse and validity of the subsequent equation (AA+ − I)~b = 0 for each of their corresponding data matrices was verified in Julia. In determining the existence of the Moore-Penrose inverse, Gaussian elimination is applied to the matrix A∗A. In turning the matrix into row echelon form, if the algorithm detects a diagonal entry that is within some bound ǫ = 0.0001 of zero, the matrix is determined to be not invertible. If all diagonal entries are outside that bound, the matrix is considered left invertible. The left Moore-Penrose pseudoinverse is calculated as (A∗A)−1A∗. (A∗A)−1 is calculated by performing the same Gauss-Jordan operations in reducing matrix A∗A to reduced row echelon form to the identity matrix. In determining the validity of some equation candidate, we compute, based on the values of the equation matrix A, pseudoinverse A+, and ~b, the vector\n~b′ = AA+~b. (27)\nConstruct some vector ~c using (27), such that\n~c[i] = ~b[i]− ~b′[i]\n~b[i] , 1 ≤ i ≤ dim(~b). (28)\nAfter the construction of ~c from (28), if the result of ‖~c‖ is within some bound ǫ = 0.0001 of zero, the associated candidate equation is judged as valid. If the equation is outside the bound, the equation candidate is judged as not valid. Below is a selection of outputs by the exhaustive search algorithm.\n... PV + PV T +NT =⇒ k2 = 2.3142 k3 = −2.1348 PV + PV T +NT 2 =⇒ k2 = 1.7452 k3 = −1.3145 ... PV 3 + bnPV 2 + n2V + n3 + nV 2T =⇒ k2 = −2.661 × 10−5 k3 = 2.45 × 10−2 k4 = 6.51935 × 10−7 k5 = −8.3145\nIn applying the exhaustive search and finite field sieve, both algorithms yielded the same valid equation PV 3 + nPV 2 + n2V + n3 + nV 2T when ǫ = 0.0001. Both algorithms also rejected all other equation candidates in our search family of equations."
    }, {
      "heading" : "6 Concluding Remarks",
      "text" : "We have demonstrated a novel approach in deriving compact laws from a data set. In this approach, an algebraic model is derived to verify whether a certain algebraic equation fits the data set. With this model, we solve the problem of determining constants for equations with additive terms. We have also developed algorithms to parse through a family of algebraic equations, one by exhaustive search and the other based on the finite field sieve, which is more efficient. In addition, we prove that both algorithms are guaranteed to converge in finding an equation that describes a data set if the equation belongs to the family in which the algorithms are applied.\nThe devised algebraic equation verification algorithm runs in O(tr2) time. r is the number of experiments done, and t = max(dn, r), with d being the number of additive terms of the candidate, and m,n being the number of input and output variables in the data. We have proved that the question of equation validation with respect to constants is exactly the question of the existence of the pseudoinverse A+ and the calculation of (AA+ − I)~b (Theorem 1). A numerical method was devised to determine whether a pseudoinverse exists with respect to a bound. Another method was used to determine whether (AA+ − I)~b is within some bound of ~0 using squared residuals. This algorithm succeeded in validating the van der Waals equation and calculating its constants, while rejecting all other equation candidates. The exhaustive search algorithm runs in eO(1)rs time, where r is the number of experiments in the data and s is the maximum number of additive terms in the family of equations to be searched. The finite field sieve algorithm improves on our exhaustive search algorithm by converting our data into elements of a finite field to reduce the number of equations needed to be searched. This algorithm runs in eO(1) √ rs time, which makes the algorithm run in sub-exponential time with respect to the number of experiments. Both algorithms searched through the same family of algebraic equations relating to the van der Waals equation and converged on the valid equation.\nThe proposed approach transforms the problem of deriving meaning from data into formulating a linear algebra model and finding equations that fit the data. Such a formulation allows the finding of equation candidates in an explicit mathematical manner. For a certain type of compact theory, our approach assures convergence, with the discovery being computationally efficient\nand mathematically precise. However, several limitations exist. One is that not all natural laws are in algebraic form. For example, for an RLC circuit [24], which includes exponents, sinusoids, and complex numbers, applying our algorithms to data of this type would yield a Taylor approximation of the equation, which may not be accurate for larger values. Another lies in the fact that the Finite Field Sieve algorithm is still relatively slow due to it being exponential with respect to the maximum number of additive terms to be searched through. These problems may limit the algorithm’s effectiveness on certain data sets. To improve this approach, further work includes finding a mathematical analogue of this process applicable to vectors. Currently, all vector algebraic equations must be found component-wise. In addition, applying certain transforms (e.g., Fourier or Laplace) on exponential, logarithmic, or sinusoidal equation candidates may expand the number of data types that can fit an equation.\nWe believe the most promising direction is determining a search algorithm based on linear algebra such that valid candidate equations can be discovered with high probability. This is due to the candidate equation evolution dependent on multiplication by diagonal matrices, which do not change a matrice’s eigenvector space [25]. There are several potential search criterion that are worthy of study to use as a tool for supervised training. This may lead to a probabilistic algorithm that runs in polynomial time. This re-expression of the problem of derivation of natural laws from data into a linear algebra model creates enormous potential for refining constant evaluation, search, and learning algorithms."
    }, {
      "heading" : "7 Materials",
      "text" : "The Julia code is available with this pre-print on arXiv. The code is distributed under a Creative Commons Attribution 4.0 International Public License. If you use this work please attribute to Wenqing Xu and Mark Stalzer, Deriving compact laws based on algebraic formulation of a data set, arXiv, 2017."
    }, {
      "heading" : "8 Acknowledgements",
      "text" : "This research was funded by the Gordon and Betty Moore Foundation through Grant GBMF4915 to the Caltech Center for Data-Driven Discovery.\nThis researched was conducted as the named Caltech SURF program of Dr. Jane Chen."
    } ],
    "references" : [ {
      "title" : "A preliminary review of influential works in data-driven discovery,",
      "author" : [ "M. Stalzer", "C. Mentzel" ],
      "venue" : "SpringerPlus, vol. 5,",
      "citeRegEx" : "1",
      "shortCiteRegEx" : "1",
      "year" : 2016
    }, {
      "title" : "Building predictive models via feature synthesis,",
      "author" : [ "I. Arnaldo", "U.-M. O’Reilly", "K. Veeramachaneni" ],
      "venue" : "Proceedings of the 2015 Annual Conference on Genetic and Evolutionary Computation,",
      "citeRegEx" : "2",
      "shortCiteRegEx" : "2",
      "year" : 2015
    }, {
      "title" : "Distilling free-form natural laws from experimental data,",
      "author" : [ "M. Schmidt", "H. Lipson" ],
      "venue" : "Science, vol",
      "citeRegEx" : "3",
      "shortCiteRegEx" : "3",
      "year" : 2009
    }, {
      "title" : "Mining our reality,",
      "author" : [ "T.M. Mitchell" ],
      "venue" : "Science, vol. 326,",
      "citeRegEx" : "4",
      "shortCiteRegEx" : "4",
      "year" : 2009
    }, {
      "title" : "and S",
      "author" : [ "H. Schaeffer", "R. Caflisch", "C.D. Hauck" ],
      "venue" : "Osher, “Sparse dynamics for partial differential equations,” Proceedings of the National Academy of Sciences, vol. 110, no. 17, pp. 6634–6639",
      "citeRegEx" : "5",
      "shortCiteRegEx" : null,
      "year" : 2013
    }, {
      "title" : "Model emergent dynamics in complex systems",
      "author" : [ "A.J. Roberts" ],
      "venue" : "SIAM",
      "citeRegEx" : "6",
      "shortCiteRegEx" : null,
      "year" : 2014
    }, {
      "title" : "and R",
      "author" : [ "R. Kune", "P.K. Konugurthi", "A. Agarwal", "R.R. Chillarige" ],
      "venue" : "Buyya, “Genetic algorithm based data-aware group scheduling for big data clouds,” in 2014 IEEE/ACM International Symposium on Big Data Computing (BDC), pp. 96–104, IEEE",
      "citeRegEx" : "7",
      "shortCiteRegEx" : null,
      "year" : 2014
    }, {
      "title" : "Machine learning: Trends",
      "author" : [ "M. Jordan", "T. Mitchell" ],
      "venue" : "perspectives, and prospects,” Science, vol. 349, no. 6245, pp. 255–260",
      "citeRegEx" : "9",
      "shortCiteRegEx" : null,
      "year" : 2015
    }, {
      "title" : "and R",
      "author" : [ "J. Snoek", "H. Larochelle" ],
      "venue" : "P. Adams, “Practical Bayesian optimization of machine learning algorithms,” in Advances in neural information processing systems, pp. 2951–2959",
      "citeRegEx" : "10",
      "shortCiteRegEx" : null,
      "year" : 2012
    }, {
      "title" : "and L",
      "author" : [ "W. La Cava", "K. Danai" ],
      "venue" : "Spector, “Inference of compact nonlinear dynamic models by epigenetic local search,” Engineering Applications of Artificial Intelligence, vol. 55, pp. 292– 306",
      "citeRegEx" : "11",
      "shortCiteRegEx" : null,
      "year" : 2016
    }, {
      "title" : "Probabilistic machine learning and artificial intelligence,",
      "author" : [ "Z. Ghahramani" ],
      "venue" : "Nature, vol. 521,",
      "citeRegEx" : "12",
      "shortCiteRegEx" : "12",
      "year" : 2015
    }, {
      "title" : "Probabilistic Reasoning in Intelligent Systems: Networks of Plausible Inference",
      "author" : [ "J. Pearl" ],
      "venue" : "San Francisco, CA, USA: Morgan Kaufmann Publishers Inc.",
      "citeRegEx" : "13",
      "shortCiteRegEx" : null,
      "year" : 1988
    }, {
      "title" : "and D",
      "author" : [ "A.P. Dempster", "N.M. Laird" ],
      "venue" : "B. Rubin, “Maximum likelihood from incomplete data via the EM algorithm,” Journal of the Royal Statistical Society. Series B (methodological), pp. 1–38",
      "citeRegEx" : "14",
      "shortCiteRegEx" : null,
      "year" : 1977
    }, {
      "title" : "and J",
      "author" : [ "A. Lucas", "M. Stalzer" ],
      "venue" : "Feo, “Parallel implementation of fast randomized algorithms for low rank matrix decomposition,” Parallel Processing Letters, vol. 24, no. 01, p. 1450004",
      "citeRegEx" : "15",
      "shortCiteRegEx" : null,
      "year" : 2014
    }, {
      "title" : "and J",
      "author" : [ "S.L. Brunton", "J.H. Tu", "I. Bright" ],
      "venue" : "N. Kutz, “Compressive sensing and low-rank libraries for classification of bifurcation regimes in nonlinear dynamical systems,” SIAM Journal on Applied Dynamical Systems, vol. 13, no. 4, pp. 1716–1732",
      "citeRegEx" : "16",
      "shortCiteRegEx" : null,
      "year" : 2014
    }, {
      "title" : "and J",
      "author" : [ "S.L. Brunton", "J.L. Proctor" ],
      "venue" : "N. Kutz, “Discovering governing equations from data by sparse identification of nonlinear dynamical systems,” Proceedings of the National Academy of Sciences, vol. 113, no. 15, pp. 3932–3937",
      "citeRegEx" : "17",
      "shortCiteRegEx" : null,
      "year" : 2016
    }, {
      "title" : "Classical mechanics: A modern perspective",
      "author" : [ "V. Barger", "M.G. Olsson" ],
      "venue" : "vol. 2. McGraw- Hill New York",
      "citeRegEx" : "18",
      "shortCiteRegEx" : null,
      "year" : 1995
    }, {
      "title" : "A generalized inverse for matrices,",
      "author" : [ "R. Penrose" ],
      "venue" : "Mathematical Proceedings of the Cambridge Philosophical society,",
      "citeRegEx" : "19",
      "shortCiteRegEx" : "19",
      "year" : 1955
    }, {
      "title" : "On the enumeration of sentences by compactness,",
      "author" : [ "M. Stalzer" ],
      "venue" : null,
      "citeRegEx" : "20",
      "shortCiteRegEx" : "20",
      "year" : 2017
    }, {
      "title" : "Introduction to finite fields and their applications",
      "author" : [ "R. Lidl", "H. Niederreiter" ],
      "venue" : "Cambridge University Press",
      "citeRegEx" : "21",
      "shortCiteRegEx" : null,
      "year" : 1994
    }, {
      "title" : "Solving sparse linear equations over finite fields,",
      "author" : [ "D. Wiedemann" ],
      "venue" : "IEEE transactions on information theory,",
      "citeRegEx" : "22",
      "shortCiteRegEx" : "22",
      "year" : 1986
    }, {
      "title" : "Konynenburg, “Static properties of solutions. van der waals and related models for hydrocarbon mixtures,",
      "author" : [ "R.L. Scott", "P.H. van" ],
      "venue" : "Discussions of the Faraday society,",
      "citeRegEx" : "23",
      "shortCiteRegEx" : "23",
      "year" : 1970
    }, {
      "title" : "Electrical characteristics of transistors",
      "author" : [ "R.L. Pritchard" ],
      "venue" : "McGraw-Hill",
      "citeRegEx" : "24",
      "shortCiteRegEx" : null,
      "year" : 1967
    }, {
      "title" : "Applied linear algebra",
      "author" : [ "B. Noble", "J.W. Daniel" ],
      "venue" : "vol. 3. Prentice-Hall New Jersey",
      "citeRegEx" : "25",
      "shortCiteRegEx" : null,
      "year" : 1988
    }, {
      "title" : "Numerically efficient methods for solving least squares problems,",
      "author" : [ "D.Q. Lee" ],
      "venue" : null,
      "citeRegEx" : "26",
      "shortCiteRegEx" : "26",
      "year" : 2012
    }, {
      "title" : "Abstract algebra",
      "author" : [ "D.S. Dummit", "R.M. Foote" ],
      "venue" : "vol. 3. Wiley Hoboken",
      "citeRegEx" : "27",
      "shortCiteRegEx" : null,
      "year" : 2004
    }, {
      "title" : "The generalized Moore-Penrose inverse,",
      "author" : [ "K.M. Prasad", "R. Bapat" ],
      "venue" : "Linear Algebra and its Applications,",
      "citeRegEx" : "28",
      "shortCiteRegEx" : "28",
      "year" : 1992
    } ],
    "referenceMentions" : [ {
      "referenceID" : 0,
      "context" : "Data driven discovery, which involves finding meaning and patterns in data, has been experiencing significant progress in quantifying behaviors, complexity, and relationships among data sets [1].",
      "startOffset" : 191,
      "endOffset" : 194
    }, {
      "referenceID" : 1,
      "context" : "Notable progress has been made in applying different approaches [2].",
      "startOffset" : 64,
      "endOffset" : 67
    }, {
      "referenceID" : 2,
      "context" : "One such method is the representation of an equation as a tree, where the nodes represent operators, the leaves represent data, and the complexity calculated as the sum of nodes and leaves [3].",
      "startOffset" : 189,
      "endOffset" : 192
    }, {
      "referenceID" : 3,
      "context" : "However, this still means that the number of candidates increases exponentially with respect to complexity, meaning any brute-force algorithm causes high complexity equations to take an unreasonable amount of time to reach and verify against the data [4].",
      "startOffset" : 251,
      "endOffset" : 254
    }, {
      "referenceID" : 2,
      "context" : "In addition, this method does not explicitly rule out any candidate equations, as it accepts candidate equations and constants with a squared residual within a bound [3].",
      "startOffset" : 166,
      "endOffset" : 169
    }, {
      "referenceID" : 4,
      "context" : "The sparsity of a given data set can also be used to bound the coefficients of the desired compact law [5].",
      "startOffset" : 103,
      "endOffset" : 106
    }, {
      "referenceID" : 5,
      "context" : "Bruteforce methods lead to an unacceptable program run time [6].",
      "startOffset" : 60,
      "endOffset" : 63
    }, {
      "referenceID" : 6,
      "context" : "Genetic algorithms introduce slight mutations in a candidate equation to single out operators and constants that fit the data well [7].",
      "startOffset" : 131,
      "endOffset" : 134
    }, {
      "referenceID" : 7,
      "context" : "put experimental data in novel ways [9].",
      "startOffset" : 36,
      "endOffset" : 39
    }, {
      "referenceID" : 8,
      "context" : "Although convergence to the desired input-output relationships can be achieved via intensive and extensive training, there are no methods to prove that these machine learning algorithms converge onto a natural law based on the data [10].",
      "startOffset" : 232,
      "endOffset" : 236
    }, {
      "referenceID" : 9,
      "context" : "A compact law refers to mathematically explicit description or equation that exactly describes the data [11].",
      "startOffset" : 104,
      "endOffset" : 108
    }, {
      "referenceID" : 10,
      "context" : "Among recent advances, one approach is based on statistical and model driven methods, for example, the use of Bayesian probabilistic methods and Markov models [12] as the basis of an intelligent system [13], and the expectation maximization algorithm, which converges to a maximum likelihood estimate based on incomplete data [14].",
      "startOffset" : 159,
      "endOffset" : 163
    }, {
      "referenceID" : 11,
      "context" : "Among recent advances, one approach is based on statistical and model driven methods, for example, the use of Bayesian probabilistic methods and Markov models [12] as the basis of an intelligent system [13], and the expectation maximization algorithm, which converges to a maximum likelihood estimate based on incomplete data [14].",
      "startOffset" : 202,
      "endOffset" : 206
    }, {
      "referenceID" : 12,
      "context" : "Among recent advances, one approach is based on statistical and model driven methods, for example, the use of Bayesian probabilistic methods and Markov models [12] as the basis of an intelligent system [13], and the expectation maximization algorithm, which converges to a maximum likelihood estimate based on incomplete data [14].",
      "startOffset" : 326,
      "endOffset" : 330
    }, {
      "referenceID" : 13,
      "context" : "As a result, this can be used to approximate a time dependent system, such as the Maxwell equations, using a Markov model, and thus approximate a system’s behavior over time [15].",
      "startOffset" : 174,
      "endOffset" : 178
    }, {
      "referenceID" : 14,
      "context" : "In addition, the use of proper orthogonal decomposition on some sets of data can identify linearly dependent data sets to quickly classify bifurcation regimes in non-linear dynamical systems [16].",
      "startOffset" : 191,
      "endOffset" : 195
    }, {
      "referenceID" : 15,
      "context" : "This method was used to re-derive the equations governing the chaotic Lorentz system and fluid vortex shedding behind an obstacle [17].",
      "startOffset" : 130,
      "endOffset" : 134
    }, {
      "referenceID" : 16,
      "context" : "A valid equation candidate for the force laws [18] described in section 2.",
      "startOffset" : 46,
      "endOffset" : 50
    }, {
      "referenceID" : 17,
      "context" : "The Moore-Penrose left pseudoinverse of A ∈ M(m,n,R) is defined as A+ ∈ M(n,m,R),m, n ∈ Z+ such that AA = I, (9) the n× n identity matrix [19].",
      "startOffset" : 138,
      "endOffset" : 142
    }, {
      "referenceID" : 17,
      "context" : "If the columns of A are linearly independent, then the Moore-Penrose left pseudoinverse is calculated as A = (A∗A)−1A∗ (10) such that A+A = ((A∗A)−1A∗)A = (A∗A)−1(A∗A) = I ([19], Theorem 2).",
      "startOffset" : 173,
      "endOffset" : 177
    }, {
      "referenceID" : 24,
      "context" : "(13) As a result, the least squares problem min|A~k−~b| has a unique solution, and so the columns of A are linearly independent ([26], 2.",
      "startOffset" : 129,
      "endOffset" : 133
    }, {
      "referenceID" : 25,
      "context" : "Since R is a field, and all fields are integral domains [27], either B1,1, .",
      "startOffset" : 56,
      "endOffset" : 60
    }, {
      "referenceID" : 26,
      "context" : "Thus, A∗A is not invertible ([28], Theorem 3), and so A+ cannot be computed.",
      "startOffset" : 29,
      "endOffset" : 33
    }, {
      "referenceID" : 18,
      "context" : "Referring to [20], we can denote this problem as finding a valid equation candidate in the family of equation candidates involving elements of F , |F | = n, of size at most s, and of degree at most d that satisfies the data of r experiments, where r ≥ s − 1 (cor 1).",
      "startOffset" : 13,
      "endOffset" : 17
    }, {
      "referenceID" : 19,
      "context" : "1 Introduction to Finite Fields We will explain some relevant properties of finite fields [21].",
      "startOffset" : 90,
      "endOffset" : 94
    }, {
      "referenceID" : 20,
      "context" : "We can modify the algorithm in (1) for solving a linear system A~x = ~b over a finite field in O(tr2) time if such a solution exists, where the dimensions of A are r× s [22].",
      "startOffset" : 169,
      "endOffset" : 173
    }, {
      "referenceID" : 20,
      "context" : "For the verification algorithm, use (1), but modified to apply to finite fields [22], to write down the validated equation candidates in F3 in some list EqF3.",
      "startOffset" : 80,
      "endOffset" : 84
    }, {
      "referenceID" : 21,
      "context" : "12 Wenqing (William) Xu 5 Numerical Results Equation candidates for the van der Waals equation of state [23],",
      "startOffset" : 104,
      "endOffset" : 108
    }, {
      "referenceID" : 22,
      "context" : "For example, for an RLC circuit [24], which includes exponents, sinusoids, and complex numbers, applying our algorithms to data of this type would yield a Taylor approximation of the equation, which may not be accurate for larger values.",
      "startOffset" : 32,
      "endOffset" : 36
    }, {
      "referenceID" : 23,
      "context" : "This is due to the candidate equation evolution dependent on multiplication by diagonal matrices, which do not change a matrice’s eigenvector space [25].",
      "startOffset" : 148,
      "endOffset" : 152
    } ],
    "year" : 2017,
    "abstractText" : "In various subjects, there exist compact and consistent relationships between input and output parameters. Discovering the relationships, or namely compact laws, in a data set is of great interest in many fields, such as physics, chemistry, and finance. While data discovery has made great progress in practice thanks to the success of machine learning in recent years, the development of analytical approaches in finding the theory behind the data is relatively slow. In this paper, we develop an innovative approach in discovering compact laws from a data set. By proposing a novel algebraic equation formulation, we convert the problem of deriving meaning from data into formulating a linear algebra model and searching for relationships that fit the data. Rigorous proof is presented in validating the approach. The algebraic formulation allows the search of equation candidates in an explicit mathematical manner. Searching algorithms are also proposed for finding the governing equations with improved efficiency. For a certain type of compact theory, our approach assures convergence and the discovery is computationally efficient and mathematically precise. 2 Wenqing (William) Xu",
    "creator" : "LaTeX with hyperref package"
  }
}