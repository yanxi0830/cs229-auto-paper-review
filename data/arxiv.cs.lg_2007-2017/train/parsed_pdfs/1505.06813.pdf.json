{
  "name" : "1505.06813.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "Surrogate Functions for Maximizing Precision at the Top",
    "authors" : [ "Purushottam Kar", "Harikrishna Narasimhan", "Prateek Jain" ],
    "emails" : [ "t-purkar@microsoft.com", "harikrishna@csa.iisc.ernet.in", "prajain@microsoft.com", "Precision@k", "(prec@k),", "prec@k.", "prec@k.", "prec@k", "prec@k", "prec@k", "prec@k.", "Precision@k,", "Precision@k", "(prec@k)", "prec@k", "prec@k", "prec@k,", "prec@k" ],
    "sections" : [ {
      "heading" : null,
      "text" : "The most notable of these is the lack of a convex upper bounding surrogate for prec@k. We also lack scalable perceptron and stochastic gradient descent algorithms for optimizing this performance measure. In this paper we make key contributions in these directions. At the heart of our results is a family of truly upper bounding surrogates for prec@k. These surrogates are motivated in a principled manner and enjoy attractive properties such as consistency to prec@k under various natural margin/noise conditions.\nThese surrogates are then used to design a class of novel perceptron algorithms for optimizing prec@k with provable mistake bounds. We also devise scalable stochastic gradient descent style methods for this problem with provable convergence bounds. Our proofs rely on novel uniform convergence bounds which require an in-depth analysis of the structural properties of prec@k and its surrogates. We conclude with experimental results comparing our algorithms with state-of-the-art cutting plane and stochastic gradient algorithms for maximizing prec@k."
    }, {
      "heading" : "1 Introduction",
      "text" : "Ranking a given set of points or labels according to their relevance forms the core of several real-life learning systems. For instance, in classification problems with a rare-class as is the case in spam/anomaly detection, the goal is to rank the given emails/events according to their likelihood of being from the rare-class (spam/anomaly). Similarly, in multilabel classification problems, the goal is to rank the labels according to their likelihood of being relevant to a data point Tsoumakas and Katakis [2007].\nThe ranking of items at the top is of utmost importance in these applications and several performance measures, such as Precision@k, Average Precision and NDCG have been designed to promote accuracy at top of ranked lists. Of these, the Precision@k (prec@k) measure is especially popular in a variety of domains. Informally, prec@k counts the number of relevant items in the top-k positions of a ranked list and is widely used in domains such as binary classification Joachims [2005], multi-label classification Prabhu and Varma [2014] and ranking Le and Smola [2007].\nGiven its popularity, prec@k has received attention from algorithmic, as well as learning theoretic perspectives. However, there remain specific deficiencies in our understanding of this performance measure. In fact, to the best of our knowledge, there is only one known convex surrogate function for prec@k, namely, the struct-SVM surrogate due to Joachims [2005] which, as we reveal in this work, is not an upper bound on prec@k in general, and need not recover an optimal ranking even in strictly separable settings.\nOur aim in this paper is to develop efficient algorithms for optimizing prec@k for ranking problems with binary relevance levels. Since the intractability of binary classification in the agnostic setting Guruswami and Raghavendra [2009] extends to prec@k, our goal would be to exploit natural notions of benign-ness usually observed in natural distributions to overcome such intractability results. ∗ Work done while H.N. was an intern at Microsoft Research India, Bangalore.\nar X\niv :1\n50 5.\n06 81\n3v 1\n[ st\nat .M\nL ]\n2 6\nM ay\n2 01"
    }, {
      "heading" : "1.1 Our Contributions",
      "text" : "We make several contributions in this paper that both, give deeper insight into the prec@k performance measure, as well as provide scalable techniques for optimizing it.\nPrecision@k margin: motivated by the success of margin-based frameworks in classification settings, we develop a family of margin conditions appropriate for the prec@k problem. Recall that the prec@k performance measure counts the number of relevant items at the top k positions of a ranked list. The simplest of our margin notions, that we call the weak (k, γ)-margin, is said to be present if a privileged set of k relevant items can be separated from all irrelevant items by a margin of γ. This is the least restrictive margin condition that allows for a perfect ranking w.r.t prec@k. Notably, it is much less restrictive than the binary classification notion of margin which requires all relevant items to be separable from all irrelevant items by a certain margin. We also propose two other notions of margin suited to our perceptron algorithms.\nSurrogate functions for prec@k: we design a family of three novel surrogates for the prec@k performance measure. Our surrogates satisfy two key properties. Firstly they always upper bound the prec@k performance measure so that optimizing them promotes better performance w.r.t prec@k. Secondly, these surrogates satisfy conditional consistency in that they are consistent w.r.t. prec@k under some noise condition. We show that there exists a one-one relationship between the three prec@k margin conditions mentioned earlier and these three surrogates so that each surrogate is consistent w.r.t. prec@k under one of the margin conditions. Moreover, our discussion reveals that the three surrogates, as well as the three margin conditions, lie in a concise hierarchy.\nPerceptron and SGD algorithms: using insights gained from the previous analyses, we design two perceptronstyle algorithms for optimizing prec@k. Our algorithms can be shown to be a natural extension of the classical perceptron algorithm for binary classification Rosenblatt [1958]. Indeed, akin to the classical perceptron, both our algorithms enjoy mistake bounds that reduce to crisp convergence bounds under the margin conditions mentioned earlier. We also design a mini-batch-style stochastic gradient descent algorithm for optimizing prec@k.\nLearning theory: in order to prove convergence bounds for the SGD algorithm, and online-to-batch conversion bounds for our perceptron algorithms, we further study prec@k and its surrogates and prove uniform convergence bounds for the same. These are novel results and require an in-depth analysis into the involved structure of the prec@k performance measure and its surrogates. However, with these results in hand, we are able to establish crisp convergence bounds for the SGD algorithm, as well as generalization bounds for our perceptron algorithms.\nPaper Organization: Section 2 presents the problem formulation and sets up the notation. Section 3 introduces three novel surrogates and margin conditions for prec@k and reveals the interplay between these with respect to consistency to prec@k. Section 4 presents two perceptron algorithms for prec@k and their mistake bounds, as well as a mini-batch SGD-based algorithm. Section 5 discusses uniform convergence bounds for our surrogates and their application to convergence and online-to-batch conversion bounds for our the perceptron and SGD-style algorithms. We conclude with empirical results in Section 6."
    }, {
      "heading" : "1.2 Related Work",
      "text" : "There has been much work in the last decade in designing algorithms for bipartite ranking problems. While the earlier methods for this problem, such as RankSVM, focused on optimizing pair-wise ranking accuracy Herbrich et al. [2000], Joachims [2002], Freund et al. [2003], Burges et al. [2005], of late, there has been enormous interest in performance measures that promote good ranking performance at the top portion of the ranked list, and in ranking methods that directly optimize these measures Clémençon and Vayatis [2007], Rudin [2009], Agarwal [2011], Boyd et al. [2012], Narasimhan and Agarwal [2013a,b], Li et al. [2014].\nIn this work, we focus on one such evaluation measure – Precision@k, which is widely used in practice. The only prior algorithms that we are aware of that directly optimize this performance measure are a structural SVM based cutting plane method due to Joachims [2005], and an efficient stochastic implementation of the same due to Kar et al. [2014]. However, as pointed out earlier, the convex surrogate used in these methods is not well-suited for prec@k.\nIt is also important to note that the bipartite ranking setting considered in this work is different from other popular forms of ranking such as subset or list-wise ranking settings, which arise in several information retrieval applications, where again there has been much work in optimizing performance measures that emphasize on accuracy at the top (e.g. NDCG) Valizadegan et al. [2009], Cao et al. [2007], Yue et al. [2007], Le and Smola [2007], Chakrabarti et al. [2008],\nYun et al. [2014]. There has also been some recent work on perceptron style ranking methods for list-wise ranking problems Chaudhuri and Tewari [2014], but these methods are tailored to optimize the NDCG and MAP measures, which are different from the prec@k measure that we consider here. Other less related works include online ranking algorithms for optimizing ranking measures in an adversarial setting with limited feedback Chaudhuri and Tewari [2015]."
    }, {
      "heading" : "2 Problem Formulation and Notation",
      "text" : "We will be presented with a set of labeled points (xi, yi), . . . , (xn, yn), where xi ∈ X and yi ∈ {0, 1}. We shall use X to denote the entire dataset, X+ and X− to denote the set of positive and negatively (null) labeled points, and y ∈ {0, 1}n to denote the label vector. z = (x, y) shall denote a labeled data point. Our results readily extend to multi-label and ranking settings but for sake of simplicity, we focus only on bipartite ranking problems, where the goal is to rank (a subset of) positive examples above the negative ones.\nGiven n labeled data points z1, . . . , zn and a scoring function s : X → R, let σs ∈ Sn be the permutation that sorts points according to the scores given by s i.e. s(xσs(i)) ≥ s(xσs(j)) for i ≤ j. The Precision@k measure for this scoring function can then be expressed as:\nprec@k(s; z1, . . . , zn) = k∑ i=1 (1− yσs(i)). (1)\nNote that the above is a “loss” version of the performance measure which penalizes any top-k ranked data points that have a null label. For simplicity, we will use the abbreviated notation prec@k(s) := prec@k(s; z1, . . . , zn). We will also use the shorthand si = s(xi). For any label vectors y′,y′′ ∈ {0, 1}n, we define\n∆(y′,y′′) = n∑ i=1 (1− y′i)y′′i ,\nK(y′,y′′) = n∑ i=1 y′iy ′′ i .\n(2)\nLet n+(y′) = K(y′,y′) = ‖y′‖1 denote the number of positives in the label vector y′ and n+ = n+(y) denote the number of actual positives. Let y(s,k) be the label vector that assigns the label 1 only to the top k ranked items according to the scoring function s. That is, y(s,k)i = 1 if if σ −1 s (i) ≤ k and 0 otherwise. It is easy to verify that for any scoring function s, ∆(y,y(s,k)) = prec@k(s)."
    }, {
      "heading" : "3 A Family of Novel Surrogates for prec@k",
      "text" : "As prec@k is a non-convex loss function that is hard to optimize directly, it is natural to seek surrogate functions that act as a good proxy for prec@k. There will be two properties that we shall desire of such a surrogate:\n1. Upper Bounding Property: the surrogate should upper bound the prec@k loss function, so that minimizing the surrogate promotes small prec@k loss.\n2. Conditional Consistency: under some regularity assumptions, optimizing the surrogate should yield an optimal solution for prec@k as well.\nMotivated by the above requirements, we develop a family of surrogates which upper bound the prec@k loss function and are consistent to it under certain margin/noise conditions. We note that the results of Calauzènes et al. [2012] that negate the possibility of consistent convex surrogates for ranking performance measures do not apply to our results since they are neither stated for prec@k, nor do they negate the possibility of conditional consistency.\nIt is notable that the seminal work of Joachims [2005] did propose a convex surrogate for prec@k, that we refer to as `structprec@k(·). However, as the discussion below shows, this surrogate is not even an upper bound on prec@k let alone be consistent to it. Understanding the reasons for the failure of this surrogate would be crucial in designing our own."
    }, {
      "heading" : "3.1 The Curious Case of `structprec@k(·)",
      "text" : "The `structprec@k(·) surrogate is a part of a broad class of surrogates called struct-SVM surrogates that are designed for structured output prediction problems that can have exponentially large output spaces Joachims [2005]. Given a set of n labeled data points, `structprec@k(·) is defined as\nmax ŷ∈{0,1}n ‖ŷ‖1=k\n{ ∆(y, ŷ) +\nn∑ i=1 (ŷi − yi) si\n} . (3)\nThe above surrogate penalizes a scoring function if there exists a set of k points with large scores (i.e. the second term is large) which are actually negatives (i.e. the first term is large). However, since the candidate labeling ŷ is restricted to labeling just k points as positive whereas the true label vector y has n+ positives, in cases where n+ > k, a non-optimal candidate labeling ŷ can exploit the remaining n+ − k labels to hide the high scoring negative points, thus confusing the surrogate function. This indicates that this surrogate may not be an upper bound to prec@k. We refer the reader to Appendix A for an explicit example where, not only does this surrogate not upper bound prec@k, but more importantly, minimizing `structprec@k(·) does not produce a model that is optimal for prec@k, even in separable settings where all positives points are separated from negatives by a margin.\nIn the sequel, we shall propose three surrogates, all of which are consistent with prec@k under various noise/margin conditions. The surrogates, as well as the noise conditions, will be shown to form a hierarchy."
    }, {
      "heading" : "3.2 The Ramp Surrogate `rampprec@k(·)",
      "text" : "The key to maximizing prec@k in a bipartite ranking setting is to select a subset of k relevant items and rank them at the top k positions. This can happen iff the top ranked k relevant items are not outranked by any irrelevant item. Thus, a surrogate must penalize a scoring function that assigns scores to irrelevant items that are higher than those of the top ranked relevant items. Our ramp surrogate `rampprec@k(s) implicitly encodes this strategy:\nmax ‖ŷ‖1=k\n{ ∆(y, ŷ) +\nn∑ i=1 ŷisi } − max ‖ỹ‖1=k K(y,ỹ)=k n∑ i=1 ỹisi\n︸ ︷︷ ︸ (P )\n. (4)\nThe term (P ) contains the sum of scores of the k highest scoring positives. Note that `rampprec@k(·) is similar to the “ramp” losses for binary classification Do et al. [2008]. We now show that `rampprec@k(·) is indeed an upper bounding surrogate for prec@k.\nClaim 1. For any k ≤ n+ and scoring function s, we have `rampprec@k(s) ≥ prec@k(s). Moreover, if ` ramp prec@k(s) ≤ ξ for a given scoring function s, then there necessarily exists a set S ⊂ [n] of size at most k such that for all ‖ŷ‖1 = k, we have ∑ i∈S si ≥ ∑n i=1 ŷisi + ∆(y, ŷ)− ξ.\nProofs for this section are deferred to Appendix B. We can show that this surrogate is conditionally consistent as well. To do so, we introduce the notion of weak (k, γ)-margin.\nDefinition 2 (Weak (k, γ)-margin). A set of n labeled data points satisfies the weak (k, γ)-margin condition if for some scoring function s and set S+ ⊆ X+ of size k,\nmin i∈S+ si − max j:yj=0 sj ≥ γ.\nMoreover, we say that the function s realizes this margin. We abbreviate the weak (k, 1)-margin condition as simply the weak k-margin condition.\nClearly, a dataset has a weak (k, γ)-margin iff there exist some k positive points that substantially outrank all negatives. Note that this notion of margin is strictly weaker than the standard notion of margin for binary classification as it allows all but those k positives to be completely mingled with the negatives. Moreover, this seems to be one of the most natural notions of margin for prec@k. The following lemma establishes that `rampprec@k(·) is indeed consistent w.r.t. prec@k under the weak k-margin condition.\nClaim 3. For any scoring function s that realizes the weak k-margin over a dataset, `rampprec@k(s) = prec@k(s) = 0.\nThis suggests that `rampprec@k(·) is not only a tight surrogate, but tight at the optimal scoring function, i.e. prec@k(s) = 0; this along with upper bounding property implies consistency. However, it is also a non-convex function due to the term (P ). To obtain convex surrogates, we perform relaxations on this term by first rewriting it as follows:\n(P ) = n∑ i=1 yisi − min ỹ y\n‖ỹ‖1=n+−k\nn∑ i=1 ỹisi\n︸ ︷︷ ︸ (Q)\n, (5)\nwhere ỹ y implies that yi = 0 ⇒ ỹi = 0. Thus, to convexify the surrogate `rampprec@k(·), we need to design a convex upper bound on (Q). Notice that the term (Q) contains the sum of the scores of the n+ − k lowest ranked positive data points. This can be readily upper bounded in several ways which give us different surrogate functions."
    }, {
      "heading" : "3.3 The Max Surrogate `maxprec@k(·)",
      "text" : "An immediate convex upper bound on (Q) is obtained by replacing the sum of scores of the n+ − k lowest ranked positives with those of the highest ranked ones as follows: (Q) ≤ max ỹ (1−ŷ)·y\n‖ỹ‖1=n+−k\n∑n i=1 ỹisi, which gives us the\n`maxprec@k(s) surrogate defined below:\nmax ‖ŷ‖1=k ∆(y, ŷ) + n∑ i=1\n(ŷi − yi)si + max ỹ (1−ŷ)·y ‖ỹ‖1=n+−k\nn∑ i=1 ỹisi  . (6) The above surrogate, being a point-wise maximum over convex functions, is convex, as well as an upper bound on prec@k(s) since it upper bounds `rampprec@k(s). This surrogate can also be shown to be consistent w.r.t. prec@k under the strong γ-margin condition defined below for γ = 1.\nDefinition 4 (Strong γ-margin). A set of n labeled data points satisfies the γ-strong margin condition if for some scoring function s, mini:yi=1 si −maxj:yj=0 sj ≥ γ.\nWe notice that the strong margin condition is actually the standard notion of binary classification margin and hence much stronger than the weak (k, γ)-margin condition. It also does not incorporate any elements of the prec@k problem. This leads us to look for tighter convex relaxations to the term (Q) that we do below."
    }, {
      "heading" : "3.4 The Avg Surrogate `avgprec@k(·)",
      "text" : "A tighter upper bound on (Q) can be obtained by replacing (Q) by the average score of the false negatives. Define C(ŷ) = n+−K(y,ŷ)n+−k and consider the relaxation (Q) ≤ 1 C(ŷ) ∑n i=1(1 − ŷi)yisi. Combining this with (4), we get a new convex surrogate `avgprec@k(s) defined as: max ‖ŷ‖1=k { ∆(y, ŷ) + n∑ i=1 si(ŷi − yi) + 1 C(ŷ) n∑ i=1 (1− ŷi)yisi } . (7) We refer the reader to Appendix B.4 for a proof that `avgprec@k(·) is an upper bounding surrogate. It is notable that for k = n+ (i.e. for the PRBEP measure), the surrogate ` avg prec@k(·) recovers Joachims’ original surrogate `structprec@k(·). To establish conditional consistency of this surrogate, consider the following notion of margin:\nDefinition 5 ((k, γ)-margin). A set of n labeled data points satisfies the (k, γ)-margin condition if for some scoring function s, we have, for all sets S+ ⊆ X+ of size n+ − k + 1,\n1 n+ − k + 1 ∑ i∈S+ si − max j:yj=0 sj ≥ γ.\nMoreover, we say that the function s realizes this margin. We abbreviate the (k, 1)-margin condition as simply the k-margin condition.\nWe can now establish the consistency of `avgprec@k(·) under the k-margin condition. See Appendix B.5 for a proof.\nClaim 6. For any scoring function s that realizes the k-margin over a dataset, `avgprec@k(s) = prec@k(s) = 0.\nWe note that the (k, γ)-margin condition is strictly weaker than the strong γ-margin condition (Definition 4) since it still allows a non negligible fraction of the positive points to be assigned a lower score than those assigned to negatives. On the other hand, the (k, γ)-margin condition is strictly stronger than the weak (k, γ)-margin condition (Definition 2). The weak k-margin condition only requires one set of k-positives to be separated from the negatives, whereas the above margin condition at least requires the average of all positives to be separated from the negatives.\nAs Figure 1 demonstrates, the three surrogates presented above, as well as their corresponding margin conditions, fall in a neat hierarchy. We will now use these surrogates to formulate two perceptron algorithms with mistake bounds with respect to these margin conditions."
    }, {
      "heading" : "4 Perceptron & SGD Algorithms for prec@k",
      "text" : "We now present perceptron-style algorithms for maximizing the prec@k performance measure in bipartite ranking settings. Our algorithms work with a stream of binary labeled points and process them in mini-batches of a predetermined size b. Mini-batch methods have recently gained popularity and have been used to optimize ranking loss functions such as `structprec@k(·) as well Kar et al. [2014]. It is useful to note that the requirement for mini-batches goes away in ranking and multi-label classification settings, for our algorithms can be applied to individual data points in those settings (e.g. individual queries in ranking settings).\nAt every time instant t, our algorithms receive a batch of b points Xt = [ x1t , . . . ,x b t ] and rank these points using the existing model. Let ∆t denote the prec@k loss (equation 1) at time t. If ∆t = 0 i.e. all top k ranks are occupied by positive points, then the model is not updated. Otherwise, the model is updated using the false positives and negatives. For sake of simplicity, we will only look at linear models in this paper. Depending on the kind of updates we make, we get two variants of the perceptron rule for prec@k.\nOur first algorithm, PERCEPTRON@K-AVG, updates the model using a combination of all the false positives and negatives (see Algorithm 1). The effect of the update is a very natural one – it explicitly boosts the scores of the positive points that failed to reach the top ranks, and attenuates the scores of the negative points that got very high scores. It is interesting to note that in the limiting case of k = 1 and unit batch length (i.e. b = 1), the PERCEPTRON@K-AVG update reduces to that of the standard perceptron algorithm Rosenblatt [1958], Minsky and Papert [1988] for the choice ŷt = sign(st). Thus, our algorithm can be seen as a natural extension of the classical perceptron algorithm.\nAlgorithm 1 PERCEPTRON@K-AVG Input: Batch length b\n1: w0 ← 0, t← 0 2: while stream not exhausted do 3: t← t+ 1 4: Receive b data points Xt = [ x1t , . . . ,x b t ] , yt ∈ {0, 1}b 5: Calculate st = wt−1Xt and let ŷt = y(st,k) 6: ∆t ← ∆(yt, ŷt) 7: if ∆t = 0 then 8: wt ← wt−1 9: else\n10: Dt ← ∆t‖yt‖1−K(yt,ŷt) 11: wt ← wt−1 − ∑ i∈[b](1− yi)ŷi · x i t {false positives}\n12: wt ← wt +Dt · ∑ i∈[b](1− ŷi)yi · x i t {false negatives} 13: end if 14: end while 15: return wt\nAlgorithm 2 PERCEPTRON@K-MAX 10: St ← FN(s,∆t) 11: wt ← wt−1 − ∑ i∈[b](1− yi)ŷi · x i t {false positives}\n12: wt ← wt + ∑ i∈St x i t {top ranked false negatives}\nThe next lemma establishes that, similar to the classical perceptron Novikoff [1962], PERCEPTRON@K-AVG also enjoys a mistake bound. Our mistake bound is stated in the most general agnostic setting with the hinge loss function replaced with our surrogate `avgprec@k(s). All proofs in this section are deferred to Appendix C.\nTheorem 7. Suppose ∥∥xit∥∥ ≤ R for all t, i. Let ∆CT = ∑Tt=1 ∆t be the cumulative mistake value observed when\nAlgorithm 1 is executed for T batches. Also, for any w, let L̂avgT (w) = ∑T t=1 ` avg prec@k(w;Xt,yt). Then we have\n∆CT ≤ min w\n( ‖w‖ ·R · √ 4k + √ L̂avgT (w) )2 .\nSimilar to the classical perceptron mistake bound Novikoff [1962], the above bound can also be reduced to a simpler convergence bound in separable settings.\nCorollary 8. Suppose a unit norm w∗ exists such that the scoring function s : x 7→ x>w∗ realizes the (k, γ)-margin condition for all the batches, then Algorithm 1 guarantees the mistake bound: ∆CT ≤ 4kR 2 γ2 .\nThe above result assures that, as datasets become “easier” in the sense that their (k, γ)-margin becomes larger, PERCEPTRON@K-AVG will converge to an optimal hyperplane at a faster rate. It is important to note there that the (k, γ)-margin condition is strictly weaker than the standard classification margin condition. Hence for several datasets, PERCEPTRON@K-AVG might be able to find a perfect ranking while at the same time, it might be impossible for standard binary classification techniques to find any reasonable classifier in poly-time Guruswami and Raghavendra [2009].\nWe note that PERCEPTRON@K-AVG performs updates with all the false negatives in the mini-batches. This raises the question as to whether sparser updates are possible as such updates would be slightly faster as well as, in high dimensional settings, ensure that the model is sparser. To this end we design the PERCEPTRON@K-MAX algorithm (Algorithm 2). PERCEPTRON@K-MAX differs from PERCEPTRON@K-AVG in that it performs updates using only a few of the top ranked false negatives. More specifically, for any scoring function s and m > 0, define:\nFN(s,m) = arg max S⊂X+t ,|S|=m ∑ i∈S ( 1− y(s,k)i ) yisi\nAlgorithm 3 SGD@K-AVG Input: Batch length b, step lengths ηt, feasible setW Output: A model w̄ ∈ W\n1: w0 ← 0, t← 0 2: while stream not exhausted do 3: t← t+ 1 4: Receive b data points Xt = [ x1t , . . . ,x b t ] , yt ∈ {0, 1}b 5: Set gt ∈ ∂w`avgprec@k(wt−1;Xt,yt) {See Algorithm 4} 6: wt ← ΠW [wt−1 − ηt · gt] {project onto setW} 7: end while 8: return w̄ = 1\nt ∑t τ=1 wτ\nAlgorithm 4 Subgradient calculation for `avgprec@k(·) Input: A model win, n data points X,y, parameter k Output: A subgradient g ∈ ∂w`avgprec@k(win;X,y)\n1: Sort pos. and neg. points separately in dec. order of scores assigned by win i.e. s+1 ≥ . . . ≥ s+n+ and s − 1 ≥ . . . ≥ s−n− 2: for k′ = 0→ k do 3: Dk′ ← k−k ′\nn+−k′ 4: ∆k′ ← k − k′ −Dk′ ∑n+ i=k′+1 s + i + ∑k−k′ i=1 s − i\n5: gk′ ← ∑k−k′ i=1 x − i −Dk′ ∑n+ i=k′+1 x + i 6: end for 7: k∗ ← arg maxk′ ∆k′ 8: return gk∗\nas the set of the m top ranked false negatives. PERCEPTRON@K-MAX makes updates only for false positives in the set FN(s,∆t). Note that ∆t can significantly smaller than the total number of false negatives if k n+. PERCEPTRON@K-MAX also enjoys a mistake bound but with respect to the `maxprec@k(·) surrogate.\nTheorem 9. Suppose ∥∥xit∥∥ ≤ R for all t, i. Let ∆CT = ∑Tt=1 ∆t be the cumulative observed mistake value when\nAlgorithm 2 is executed for T batches. Also, for any w, let L̂maxT (w) = ∑T t=1 ` max prec@k(w;Xt,yt). Then we have\n∆CT ≤ min w\n( ‖w‖ ·R · √ 4k + √ L̂maxT (w) )2 .\nSimilar to PERCEPTRON@K-AVG, we can give a simplified mistake bound in situations where the separability condition specified by Definition 4 is satisfied.\nCorollary 10. Suppose a unit norm w∗ exists such that the scoring function s : x 7→ x>w∗ realizes the strong γ-margin condition for all the batches, then Algorithm 2 guarantees the mistake bound: ∆CT ≤ 4kR 2 γ2 .\nAs the strong γ-margin condition is exactly the same as the standard notion of margin for binary classification, the above bound is no stronger than the one for the classical perceptron. However, in practice, we observe that PERCEPTRON@K-MAX at times outperforms even PERCEPTRON@K-AVG, even though the latter has a tighter mistake bound. This suggests that our analysis of PERCEPTRON@K-MAX might not be optimal and fails to exploit latent structures that might be present in the data.\nStochastic Gradient Descent for Optimizing prec@k. We now extend our algorithmic repertoire to include a stochastic gradient descent (SGD) algorithm for the prec@k performance measure. SGD methods are known to be very successful at optimizing large-scale empirical risk minimization (ERM) problems as they require only a few passes over the data to achieve optimal statistical accuracy.\nHowever, SGD methods typically require access to cheap gradient estimates which are difficult to obtain for nonadditive performance measures such as prec@k. This has been noticed before by several previous works Kar et al.\n[2014], Narasimhan et al. [2015] who propose to use mini-batch methods to overcome this problem Kar et al. [2014]. By combining the `avgprec@k(·) surrogate with mini-batch-style processing, we design SGD@K-AVG (Algorithm 3), a scalable SGD algorithm for optimizing prec@k. The algorithm uses mini-batches to update the current model using gradient descent steps. The subgradient calculation for this surrogate turns out to be non-trivial and is detailed in Algorithm 4.\nThe task of analyzing this algorithm is made non-trivial by the fact that the gradient estimates available to SGD@K-AVG via Algorithm 4 are far from being unbiased. The luxury of having unbiased gradient estimates is crucially exploited by standard SGD analyses but unfortunately, unavailable to us. To overcome this hurdle, we propose a uniform convergence based proof that, in some sense, bounds the bias in the gradient estimates.\nIn the following section, we present this, and many other generalization and online-to-batch conversion bounds with applications to our perceptron and SGD algorithms."
    }, {
      "heading" : "5 Generalization Bounds",
      "text" : "In this section, we discuss novel uniform convergence (UC) bounds for our proposed surrogates. We will use these UC bounds along with the mistake bounds in Theorems 7 and 9 to prove two key results – 1) online-to-batch conversion bounds for the PERCEPTRON@K-AVG and PERCEPTRON@K-MAX algorithms and, 2) a convergence guarantee for the SGD@K-AVG algorithm.\nTo better present our generalization and convergence bounds, we use normalized versions of prec@k and the surrogates. To do so we write k = κ · n+ for some κ ∈ (0, 1] and define, for any scoring function s, its prec@κ loss as:\nprec@κ(s; z1, . . . , zn) = 1\nκn+ ∆(y,y(s,κn+)).\nWe will also normalize the surrogate functions `rampprec@κ(·), `maxprec@κ(·), and ` avg prec@κ(·) by dividing by k = κ · n+.\nDefinition 11 (Uniform Convergence). A performance measure Ψ : W × (X × {0, 1})n 7→ R+ exhibits uniform convergence with respect to a set of predictorsW if for some α(b, δ) = poly ( 1 b , log 1 δ ) , for a sample ẑ1, . . . , ẑb of size b chosen i.i.d. (or uniformly without replacement) from an arbitrary population z1, . . . , zn, we have w.p. 1− δ,\nsup w∈W\n|Ψ(w; z1, . . . , zn)−Ψ(w; ẑ1, . . . , ẑb)| ≤ α(b, δ)\nWe now state our UC bounds for prec@κ and its surrogates. We refer the reader to Appendix D for proofs.\nTheorem 12. The loss function prec@κ(·), as well as the surrogates `rampprec@κ(·), ` avg prec@κ(·) and `maxprec@κ(·), all exhibit uniform convergence at the rate α(b, δ) = O (√\n1 b log 1 δ\n) .\nRecently, Kar et al. [2014] also established a similar result for the `structprec@k(·) surrogate. However, a very different proof technique is required to establish similar results for `maxprec@κ(·) and ` avg prec@κ(·), partly necessitated by the terms in these surrogates which depend, in a complicated manner, on the positives predicted by the candidate labeling ŷ. Nevertheless, the above results allow us to establish strong online-to-batch conversion bounds for PERCEPTRON@KAVG and PERCEPTRON@K-MAX, as well as convergence rates for the SGD@K-AVG method. In the following we shall assume that our data streams are composed of points chosen i.i.d. (or u.w.r.) from some fixed population Z .\nTheorem 13. Suppose an algorithm, when fed a random stream of data points, in T batches of length b each, generates an ensemble of models w1, . . . ,wT which together suffer a cumulative mistake value of ∆CT . Then, with probability at least 1− δ, we have\n1\nT T∑ t=1 prec@κ(wt;Z) ≤ ∆ C T bT +O\n(√ 1\nb log\nT\nδ\n) .\nThe proof of this theorem follows from Theorem 12 which guarantees that w.p. 1− δ, prec@κ(wt;Z) ≤ ∆t/b+ O (√\n1 b log 1 δ\n) for all t. Combining this with the mistake bound from Theorem 7 ensures the following generalization\nguarantee for the ensemble generated by Algorithm 1.\nCorollary 14. Let w1, . . . ,wT be the ensemble of classifiers returned by the PERCEPTRON@K-AVG algorithm on a random stream of data points and batch length b. Then, with probability at least 1− δ, for any w∗ we have\n1\nT T∑ t=1 prec@κ(wt;Z) ≤ (√ `avgprec@κ(w ∗;Z) + C )2 ,\nwhere C = O ( ‖w∗‖R √ 1 T + 4 √ 1 b log T δ ) .\nA similar statement holds for the PERCEPTRON@K-MAX algorithm with respect to the `maxprec@κ(·) surrogate as well. Using the results from Theorem 12, we can also establish the convergence rate of the SGD@K-AVG algorithm.\nTheorem 15. Let w̄ be the model returned by Algorithm 3 when executed on a stream with T batches of length b. Then with probability at least 1− δ, for any w∗ ∈ W , we have\n`avgprec@κ(w̄;Z) ≤ ` avg prec@κ(w ∗;Z) +O\n(√ 1\nb log\nT\nδ\n) +O (√ 1\nT\n)\nThe proof of this Theorem can be found in Appendix E."
    }, {
      "heading" : "6 Experiments",
      "text" : "We shall now evaluate our methods on several benchmark datasets for binary classification problems with a rare-class.\nDatasets: We evaluated our methods on 7 publicly available benchmark datasets: a) PPI, b) KDD Cup 2008, c) Letter, d) Adult, e) IJCNN, f) Covertype, and g) Cod-RNA. All datasets exhibit moderate to severe label imbalance with the KDD Cup dataset having just 0.61% positives.\nMethods: We compared both perceptron algorithms, SGD@K-AVG, as well as an SGD solver for the `maxprec@k(·) surrogate, with the cutting plane-based SVMPerf solver of Joachims [2005]. We also compare against stochastic\n1PMB solver of Kar et al. [2014]. The perceptron and SGD methods were given a maximum of 25 passes over the data with a batch length of 500. All methods were implemented in C. We used 70% of the data for training and the rest for testing. All results are averaged over 5 random train-test splits.\nOur experiments reveal three interesting insights into the problem of prec@k maximization – 1) using tighter surrogates for optimization routines is indeed beneficial, 2) the presence of a stochastic solver cannot always compensate for the use of a suboptimal surrogate, and 3) mini-batch techniques, applied with perceptron or SGD-style methods, can offer rapid convergence to accurate models.\nWe first timed all the methods on prec@κ maximization tasks for κ = 0.25 on various datasets (see Figure 2). Of all the methods, the cutting plane method (SVMPerf) was found to be the most expensive computationally. On the other hand, the perceptron and stochastic gradient methods, which make frequent but cheap updates, were much faster at identifying accurate solutions.\nWe also observed that PERCEPTRON@K-AVG and SGD@K-AVG, which are based on the tight `avgprec@k(·) surrogate, were the most consistent at converging to accurate solutions whereas PERCEPTRON@K-MAX and SGD@K-MAX, which are based on the loose `maxprec@k(·) surrogate, showed large deviations in performance across tasks. Also, 1PMB and SVMPerf, which are based on the non upper-bounding `structprec@k(·) surrogate, were frequently found to converge to suboptimal solutions.\nThe effect of working with a tight surrogate is also clear from Figure 3 (a), (b) where the algorithms working with our novel surrogates were found to consistently outperform the SVMPerf method which works with the `structprec@k(·) surrogate. For these experiments, SVMPerf was allowed a runtime of up to 50× of what was given to our methods after which it was terminated.\nFinally, to establish the stability of our algorithms, we ran, both the perceptron, as well as the SGD algorithms with varying batch lengths (see Figure 3 (c)-(e)). We found the algorithms to be relatively stable to the setting of the batch length. To put things in perspective, all methods registered a relative variation of less than 5% in accuracies across batch lengths spanning an order of magnitude or more. We present additional experimental results in Appendix F."
    }, {
      "heading" : "Acknowledgments",
      "text" : "HN thanks support from a Google India PhD Fellowship."
    }, {
      "heading" : "A Structural SVM Surrogate for prec@k",
      "text" : "The structural SVM surrogate for prec@k for a set of n points {(x1, y1), . . . , (xn, yn)} ∈ (Rd × {0, 1})n and model w ∈ Rd can be written as `structprec@k(w):\nmax ŷ∈{0,1}n ‖ŷ‖1=k\n{ 1 + n∑ i=1 ŷi ( 1 n w>xi − 1 k yi ) − 1 n n∑ i=1 yiw >xi } .\nWe shall now give a simple setting where this surrogate produces a suboptimal model. Consider a set of 6 points in R × {0, 1}: {(−1, 1), (−1, 1), (−2, 1), (−3, 0), (−3, 0), (−3, 0)}, and suppose we are interested in Prec@1. Note that the optimum model that maximizes prec@1 on these points has a positive sign. We will now show that the model w∗ ∈ R that maximizes the above structural SVM surrogate on these points has a negative sign. On the contrary, let us assume that w∗ has a positive sign, and arrive at a contradiction; we shall consider the following two cases:\n(i) w∗ > 32 . It can be verified that\n`structprec@k(w ∗) = 1 +\n( 1\n6 (−w∗)− 1\n) − 1\n6 (−w∗ +−w∗ +−2w∗)\n= 1\n2 w∗\nOn the other hand, for the model w′ = −w∗, we have\n`structprec@k(w ′) = 1 +\n( 1\n6 (−3w′)− 0\n) − 1\n6 (−w′ +−w′ +−2w′)\n= 1 +\n( 1\n6 (3w∗)− 0\n) − 1\n6 (w∗ + w∗ + 2w∗)\n= 1− 1 6 w∗ < `structprec@k(w ∗),\nwhere the last step follows from w∗ > 32 ; clearly, w ∗ is not optimal for the structural SVM surrogate, and hence a contradiction. (i) w∗ ≤ 32 . Here we have\n`structprec@k(w ∗) = 1 +\n( 1\n6 (−3w∗)− 0\n) − 1\n6 (−w∗ +−w∗ +−2w∗)\n= 1 + 1\n6 w∗.\nFor w′ = −w∗,\n`structprec@k(w ′) = 1 +\n( 1\n6 (−3w′)− 0\n) − 1\n6 (−w′ +−w′ +−2w′)\n= 1 +\n( 1\n6 (3w∗)− 0\n) − 1\n6 (w∗ + w∗ + 2w∗)\n= 1− 1 6 w∗ < `structprec@k(w ∗).\nHere again, we have a contradiction. Notice that this surrogate can take negative values (when w < −6 for example) whereas prec@k is a positive valued function. This clearly indicates that this surrogate cannot upper bound prec@k. More specifically, notice that for w < 0, we have prec@k(w) = 1, however, the above analysis demonstrates cases when `structprec@k(w) < 1 which gives an explicit example that this surrogate is not even an upper bounding surrogate."
    }, {
      "heading" : "B Proofs of Claims from Section 3",
      "text" : ""
    }, {
      "heading" : "B.1 Proof of Claim 1",
      "text" : "Claim 1. For any k ≤ n+ and scoring function s, we have\n`rampprec@k(s) ≥ prec@k(s).\nMoreover, if for some scoring function s, we have `rampprec@k(s) ≤ ξ, then there necessarily exists a set S ⊂ [n] of size at most k such that for all ‖ŷ‖ = k, we have\n∑ i∈S si ≥ n∑ i=1 ŷisi + ∆(y, ŷ)− ξ.\nProof. Let ŷ = y(s,k) so that we have ∆(y, ŷ) = prec@k(s). Then we have\n`rampprec@k(s) = max‖ŷ‖1=k\n{ ∆(y, ŷ) +\nn∑ i=1 ŷisi } − max ‖ỹ‖1=k K(y,ỹ)=k n∑ i=1 ỹisi\n≥ ∆(y, ŷ) + n∑ i=1 ŷisi − max ‖ỹ‖1=k K(y,ỹ)=k n∑ i=1 ỹisi\n= ∆(y, ŷ) + max ‖ỹ‖1=k n∑ i=1 ỹisi − max ‖ỹ‖1=k K(y,ỹ)=k n∑ i=1 ỹisi\n≥ ∆(y, ŷ),\nwhere the third step follows from the definition of ŷ. This proves the first claim. For the second claim, suppose for some scoring function s, we have `rampprec@k(s) ≤ ξ. Then if we consider S∗ to be the set of k-highest ranked positive points, then we have\n∑ i∈S∗ si = max ‖ỹ‖1=k K(y,ỹ)=k n∑ i=1 ỹisi ≥ max ‖ŷ‖1=k\n{ ∆(y, ŷ) +\nn∑ i=1 ŷisi\n} − ξ ≥\nn∑ i=1 ŷisi + ∆(y, ŷ)− ξ,\nwhich proves the claim."
    }, {
      "heading" : "B.2 Proof of Claim 3",
      "text" : "Claim 3. For any scoring function s that realizes the weak k-margin over a dataset we have,\n`rampprec@k(s) = prec@k(s) = 0.\nProof. Consider a scoring function s that satisfies the weak k-margin condition and any ŷ such that ‖ŷ‖1 = k. Based on the prec@k accuracy of ŷ, we have the following two cases\nCase 1 (K(y, ŷ) = k): In this case we have\n∆(y, ŷ) + n∑ i=1 ŷisi − max ‖ỹ‖1=k K(y,ỹ)=k n∑ i=1 ỹisi = 0 + n∑ i=1 ŷisi − max ‖ỹ‖1=k K(y,ỹ)=k n∑ i=1 ỹisi ≤ 0,\nwhere the first step follows since K(y, ŷ) = k and the second step follows since ‖ŷ‖1 = k, as well as K(y, ŷ) = k.\nCase 2 (K(y, ŷ) = k′ < k): In this case let S∗ be the set of k top ranked positive points according to the scoring function s. Also let S∗1 be the set of k ′(= K(y, ŷ)) top ranked positives and let S∗2 = S ∗\\S∗1 . Then we have\n∆(y, ŷ) + n∑ i=1 ŷisi − max ‖ỹ‖1=k K(y,ỹ)=k n∑ i=1 ỹisi = ∆(y, ŷ) + n∑ i=1\nŷiyisi︸ ︷︷ ︸ (A) +\nn∑ i=1 ŷi(1− yi)si − max ‖ỹ‖1=k K(y,ỹ)=k n∑ i=1 ỹisi\n≤ ∆(y, ŷ) + ∑ i∈S∗1 si + n∑ i=1\nŷi(1− yi)si︸ ︷︷ ︸ (B) − max ‖ỹ‖1=k K(y,ỹ)=k\nn∑ i=1 ỹisi\n≤ ∆(y, ŷ) + ∑ i∈S∗1 si + ∑ i∈S∗2 si − (k − k′)− max ‖ỹ‖1=k K(y,ỹ)=k n∑ i=1 ỹisi\n= k − k′ + ∑ i∈S∗ si − (k − k′)− max ‖ỹ‖1=k K(y,ỹ)=k n∑ i=1 ỹisi\n= 0,\nwhere the second step follows since the term (A) consists of k′ true positives the third step follows since the term (B) contains k − k′ false positives i.e. negatives and the k-margin condition, the fourth step follows since ∆(y, ŷ) = k −K(y, ŷ) and the fifth step follows since by the definition of the set S∗, we have∑\ni∈S∗ si = max\n‖ỹ‖1=k K(y,ỹ)=k\nn∑ i=1 ỹisi.\nIn both cases, we have shown the surrogate to be non-positive. Since the performance measure prec@k cannot take negative values, this, along with the upper bounding property implies that prec@k(s) = 0 as well. This finishes the proof."
    }, {
      "heading" : "B.3 A Useful Supplementary Lemma",
      "text" : "Lemma 16. Given a set of n real numbers x1 . . . xn and any two integers k ≤ k′ ≤ n, we have\nmin |S|=k\n1\nk ∑ i∈S xi ≤ min |S′|=k′ 1 k′ ∑ j∈S′ xj\nProof. The above is obviously true if k = k′ so we assume that k′ > k. Without loss of generality assume that the set is ordered in ascending order i.e. x1 ≤ x2 ≤ . . . ≤ xn. Thus, the above statement is equivalent to showing that\n1\nk k∑ i=1 xi ≤ 1 k′ k′∑ j=1 xj ⇔ ( 1 k − 1 k′ ) k∑ i=1 xi ≤ 1 k′ k′∑ j=k+1 xj ⇔ 1 k k∑ i=1 xi ≤ 1 k′ − k k′∑ j=k+1 xj ,\nwhere the last inequality is true since k− k′ > 0 and the left hand side is the average of numbers which are all smaller than the numbers whose average forms the right hand side. This proves the lemma."
    }, {
      "heading" : "B.4 Proof of the Upper-bounding Property for the `avgprec@k(·) Surrogate",
      "text" : "Claim 17. For any k ≤ n+ and scoring function s, we have\n`avgprec@k(s) ≥ prec@k(s).\nMoreover, for linear scoring functions i.e. s(xi) = w>xi for w ∈ W , the surrogate `avgprec@k(w) is convex in w.\nProof. We use the fact observed before that for any scoring function, we have ∆(y,y(s,k)) = prec@k(s). We start off by showing the second part of the claim. Recall the definition of the surrogate `avgprec@k(s)\n`avgprec@k(w) = max‖ŷ‖1=k\n{ ∆(y, ŷ) +\nn∑ i=1 (ŷi − yi) ·w>xi + 1 C(ŷ) n∑ i=1 (1− ŷi)yi ·w>xi\n}\nFor sake of simplicity, for any ŷ ∈ {0, 1}n, define\n∆(s, ŷ) = ∆(y, ŷ) + n∑ i=1 si(ŷi − yi) + 1 C(ŷ) n∑ i=1 (1− ŷi)yisi.\nThe convexity of `avgprec@k(w) follows from the observation that the inner term in the maximization is linear (hence convex) in w and the max function is convex and increasing. We now move on to prove the first part. For sake of convenience ỹ = y(s,k). Note that ‖ỹ‖1 = k by definition. This gives us\n`avgprec@k(s) = max‖ŷ‖1=k ∆(s, ŷ) ≥ ∆(s, ỹ)\n= ∆(y, ỹ) + n∑ i=1 si(ỹi − yi) + 1 C(ỹ) n∑ i=1 (1− ỹi)yisi\n= ∆(y, ỹ) + n∑ i=1 si(ỹi(1− yi)− yi(1− ỹi)) + n+ − k n+ −K(y, ỹ) n∑ i=1 (1− ỹi)yisi\n= ∆(y, ỹ) + n∑ i=1\nỹi(1− yi)si︸ ︷︷ ︸ (A)\n− k −K(y, ỹ) n+ −K(y, ỹ) n∑ i=1\n(1− ỹi)yisi︸ ︷︷ ︸ (B) .\nNow define m = minỹi=1 yi=0 si and M = maxỹi=0 yi=1 si. This gives us\n(A) = n∑ i=1 ỹi(1− yi)si ≥ m n∑ i=1 ỹi(1− yi) = ∆(y, ỹ) ·m,\nand\n(B) = k −K(y, ỹ) n+ −K(y, ỹ) n∑ i=1 (1− ỹi)yisi ≤ k −K(y, ỹ) n+ −K(y, ỹ) n∑ i=1 (1− ỹi)yiM = (k −K(y, ỹ)) ·M = ∆(y, ỹ) ·M.\nHowever, by definition of ỹ = y(s,k), we have\nm ≥ min ỹ=1 si ≥ max ỹ=0 si ≥M.\nThus we have\n`avgprec@k(s) ≥ ∆(y, ỹ) + (A)− (B) ≥ ∆(y, ỹ)(1 +m−M) ≥ ∆(y, ỹ) = prec@k(s)"
    }, {
      "heading" : "B.5 Proof of Claim 6",
      "text" : "Claim 6. For any scoring function s that realizes the k-margin over a dataset we have,\n`avgprec@k(s) = prec@k(s) = 0.\nProof. We shall prove that for any ŷ such that ‖ŷ‖1 = k, under the k-margin condition, we have ∆(s, ŷ) = 0. This will show us that `avgprec@k(s) = max‖ŷ‖1=k ∆(s, ŷ) = 0. Using Claim 17 and the fact that prec@k(s) ≥ 0 will then prove the claimed result. We will analyze two cases in order to do this\nCase 1 (K(y, ŷ) = k): In this case the labeling ŷ is able to identify k relevant points correctly and thus we have C(ŷ) = 1 and we have\n∆(s, ŷ) = ∆(y, ŷ) + n∑ i=1 si(ŷi − yi) + n∑ i=1 (1− ŷi)yisi\nNow, since K(y, ŷ) = k, we have ∆(y, ŷ) = 0 which means for all i such that ŷi = 1, we also have yi = 1. Thus, we have ŷi = ŷiyi. Thus,\n∆(s, ŷ) = 0 + n∑ i=1 si(ŷi − yi) + n∑ i=1 (yi − ŷiyi)si = n∑ i=1 si(ŷi − yi) + n∑ i=1 (yi − ŷi)si = 0\nCase 2 (K(y, ŷ) = k′ < k): In this case, ŷ contains false positives. Thus we have\n∆(s, ŷ) = ∆(y, ŷ) + n∑ i=1 si(ŷi − yi) + n+ − k n+ − k′ n∑ i=1 (1− ŷi)yisi\n= ∆(y, ŷ) + n∑ i=1 ŷi(1− yi)si − k − k′ n+ − k′ n∑ i=1 yi(1− ŷi)si\n= (k − k′)  1k − k′∆(y, ŷ)︸ ︷︷ ︸ (A) + 1 k − k′ n∑ i=1 ŷi(1− yi)si︸ ︷︷ ︸ (B) − 1 n+ − k′ n∑ i=1 yi(1− ŷi)si︸ ︷︷ ︸ (C)  Now we have, by definition, (A) = 1. We also have\n(B) = 1 k − k′ n∑ i=1 ŷi(1− yi)si ≤ max j:yj=0 sj ,\nas well as\n(C) = 1 n+ − k′ n∑ i=1 yi(1− ŷi)si\n≥ min S+⊆X+\n|S+|=n+−k′\n1 n+ − k′ ∑ i∈S+ yi(1− ŷi)si\n≥ min S+⊆X+\n|S+|=n+−k+1\n1 n+ − k + 1 ∑ i∈S+ yi(1− ŷi)si,\nwhere the last step follows from Lemma 16 and the fact that k′ ≤ k − 1 in this case analysis. Then we have\n∆(s, ŷ) = (k−k′)((A)+(B)−(C)) ≤ (k−k′) 1 + max j:yj=0 sj − min S+⊆X+\n|S+|=n+−k+1\n1 n+ − k + 1 ∑ i∈S+ yi(1− ŷi)si  ≤ 0 where the last step follows because s realizes the k-margin. Having exhausted all cases, we establish the claim."
    }, {
      "heading" : "C Proofs from Section 4",
      "text" : ""
    }, {
      "heading" : "C.1 Proof of Theorem 7",
      "text" : "Theorem 7. Suppose ∥∥xit∥∥ ≤ R for all t, i. Let ∆CT = ∑Tt=1 ∆t be the cumulative observed mistake values when Algorithm 1 is run. Also, for any predictor w, let L̂T (w) = ∑T t=1 ` avg prec@k(w;Xt,yt). Then we have\n∆CT ≤ min w\n( ‖w‖ ·R · √ 4k + √ L̂T (w) )2 .\nProof. We will prove the theorem using two lemmata that we state below.\nLemma 18. For any time step t, we have\n‖wt‖2 ≤ ‖wt−1‖2 + 4kR2∆t\nLemma 19. For any fixed w ∈ W , define Pt := 〈wt,w〉. Then we have\nPt ≥ Pt−1 + ∆t − `avgprec@k(w;Xt,yt).\nUsing Lemmata 18 and 19, we can establish the mistake bound as follows. A repeated application of Lemma 19 tells us that\nPT ≥ T∑ t=1 ∆t − T∑ t=1 `avgprec@k(w;Xt,yt) = ∆ C t − L̂T (w).\nIn case the right hand side is negative, we already have the result with us. In case it is positive, we can now analyze further using the Cauchy-Schwartz inequality, and a repeated application of Lemma 18. Starting from the above we have\n∆CT ≤ PT + L̂T (w) = 〈wT ,w〉+ L̂T (w) ≤ ‖wT ‖ ‖w‖+ L̂T (w)\n≤ ‖w‖ √\n4kR2 ·∆CT + L̂T (w),\nwhich gives us the desired result upon solving the quadratic inequality. We now prove the lemmata below. Note that in the following discussion, we have, for sake of brevity, used the notation ŷ = ŷt = y(wt−1,k).\nProof of Lemma 18. For time steps where ∆t = 0, the result obviously holds since wt = wt−1. For analyzing other time steps, let vt = Dt · ∑ i∈[b](1− ŷi)yi · xit − ∑ i∈[b](1− yi)ŷi · xit so that wt = wt−1 + vt. This gives us\n‖wt‖2 = ‖wt−1‖2 + 2 〈wt−1,vt〉+ ‖vt‖2 .\nLet si = w>t−1x i t. Then we have\n〈wt−1,vt〉 = Dt · ∑ i∈[b] (1− ŷi)yisi − ∑ i∈[b] (1− yi)ŷisi\n= ∆t  1 ‖yt‖1 −K(yt, ŷt) ∑ i∈[b]\n(1− ŷi)yisi︸ ︷︷ ︸ (A)\n− 1 ∆t ∑ i∈[b]\n(1− yi)ŷisi︸ ︷︷ ︸ (B)  More specifically, we use the fact that the inequality (x− l)2 ≤ cx has a solution x ≤ ( √ l + √ c)2 whenever x, l, c ≥ 0 and x ≥ l.\n≤ 0,\nwhere the last step follows since (A) is the average of scores given to the false negatives and (B) is the average of scores given to the false positives and by the definition of ŷt, since false negatives are assigned scores less than false positives, we have (A) ≤ (B). We also have\n‖vt‖2 = ∆2t ∥∥∥∥∥∥ 1‖yt‖1 −K(yt, ŷt) · ∑ i∈[b] (1− ŷi)yi · xit − 1 ∆t ∑ i∈[b] (1− yi)ŷi · xit ∥∥∥∥∥∥ 2\n≤ 4∆2tR2 ≤ 4kR2∆t,\nsince ∆t ≤ k. Combining the two gives us the desired result.\nProof of Lemma 19. We prove the result using two cases. For sake of convenience, we will refer to yt and ŷt as y and ŷ respectively.\nCase 1 (∆t = 0): In this case Pt = Pt−1 since the model is not updated. However, since `avgprec@k(w) ≥ prec@k(w) ≥ 0 for all w ∈ W (by Claim 17), we still get\nPt ≥ Pt−1 − `avgprec@k(w;Xt,yt),\nas required. Case 2 (∆t > 0): In this case we use the update to wt−1 to evaluate the update to Pt−1. For sake of convenience, let us use the notation si = w>xit. Also note that in Algorithm 1, Dt = 1− 1C(ŷ) .\nPt = Pt−1 − ∑ i∈[b] (1− yi)ŷisi +Dt · ∑ i∈[b] (1− ŷi)yisi\n= Pt−1 − ∑ i∈[b] (1− yi)ŷisi + ( 1− 1 C(ŷ) )∑ i∈[b] (1− ŷi)yisi\n= Pt−1 − ∑ i∈[b] (ŷi − yi)si + 1 C(ŷ) ∑ i∈[b] (1− ŷi)yisi  ︸ ︷︷ ︸\n(Q)\n≥ Pt−1 + ∆t − `avgprec@k(w;Xt,yt),\nwhere the last step follows from the definition of `avgprec@k(·) which gives us\n∆t + (Q) = ∆(y, ŷ) + ∑ i∈[b] (ŷi − yi)si + 1 C(ŷ) ∑ i∈[b] (1− ŷi)yisi\n≤ max ‖ŷ‖1=k ∆(y, ŷ) + ∑ i∈[b] si(ŷi − yi) + 1 C(ŷ) ∑ i∈[b] (1− ŷi)yisi  = `avgprec@k(s) = ` avg prec@k(w;Xt,yt)\nThis concludes the proof of the mistake bound."
    }, {
      "heading" : "C.2 Proof of Theorem 9",
      "text" : "Theorem 9. Suppose ∥∥xit∥∥ ≤ R for all t, i. Let ∆CT = ∑Tt=1 ∆t be the cumulative observed mistake values when Algorithm 2 is run. Also, for any predictor w, let L̂maxT (w) = ∑T t=1 ` max prec@k(w;Xt,yt). Then we have\n∆CT ≤ min w\n( ‖w‖ ·R · √ 4k + √ L̂maxT (w) )2 .\nProof. As before, we will prove this theorem in two parts. Lemma 18 will continue to hold in this case as well. However, we will need a modified form of Lemma 19 that we prove below. As before, we will use the notation ŷ = ŷt = y (wt−1,k).\nLemma 20. For any fixed w ∈ W , define Pt := 〈wt,w〉. Then we have\nPt ≥ Pt−1 + ∆t − `maxprec@k(w;Xt,yt).\nUsing Lemmata 18 and 20, the theorem follows as before. All that remains now is to prove Lemma 20.\nProof of Lemma 20. We prove the result using two cases as before. For sake of convenience, we will refer to yt and ŷt as y and ŷ respectively.\nCase 1 (∆t = 0): In this case Pt = Pt−1 since the model is not updated. However, since `maxprec@k(w) ≥ prec@k(w) ≥ 0 for all w ∈ W (by Claim 1), we still get\nPt ≥ Pt−1 − `maxprec@k(w;Xt,yt),\nas required. Case 2 (∆t > 0): In this case we use the update to wt−1 to evaluate the update to Pt−1. For sake of convenience, let us use the notation si = w>xit. Also note that the set St := FN(w t−1,∆t) contains the false negatives in the top ∆t positions as ranked by wt−1.\nPt = Pt−1 − ∑ i∈[b] (1− yi)ŷisi + ∑ i∈St (1− ŷi)yisi\n= Pt−1 − ∑ i∈[b] (1− yi)ŷisi − ∑ i∈[b] yiŷisi + ∑ i∈[b] yiŷisi + ∑ i∈St (1− ŷi)yisi\n= Pt−1 − ∑ i∈[b] ŷisi + ∑ i∈[b] yiŷisi + ∑ i∈St (1− ŷi)yisi\n= Pt−1 − ∑ i∈[b] (ŷi − yi)si + ∑ i∈[b] (1− ŷi)yisi − ∑ i∈St (1− ŷi)yisi  ≥ Pt−1 −\n∑ i∈[b] (ŷi − yi)si + max ỹ (1−ŷ)·y ‖ỹ‖1=n+−k n∑ i=1 ỹisi  ︸ ︷︷ ︸\n(Q)\n≥ Pt−1 + ∆t − `maxprec@k(w;Xt,yt),\nwhere the last step follows from the definition of `avgprec@k(·) which gives us\n∆t + (Q) = ∆t + ∑ i∈[b] (ŷi − yi)si + max ỹ (1−ŷ)·y ‖ỹ‖1=n+−k n∑ i=1 ỹisi\n≤ max ‖ŷ‖1=k ∆t + ∑ i∈[b] (ŷi − yi)si + max ỹ (1−ŷ)·y ‖ỹ‖1=n+−k n∑ i=1 ỹisi  = `maxprec@k(s) = ` max prec@k(w;Xt,yt)\nThis concludes the proof of the theorem."
    }, {
      "heading" : "D Proof of Theorem 12",
      "text" : "Our proof of Theorem 12 crucially utilizes the following two lemmas that helps in exploiting the structure in our surrogate functions. The first basic lemma states that the pointwise supremum of a set of Lipschitz functions is also Lipschitz.\nLemma 21. Let f1, . . . , fm be m real valued functions fi : Rn → R such that every fi is 1-Lipschitz with respect to the ‖·‖∞ norm. Then the function\ng(v) = max i∈[m] fi(v)\nis 1-Lipschitz with respect to the ‖·‖∞ norm too.\nThe second lemma establishes the convergence of additive estimates over the top of ranked lists. The abstract nature of the result would allow us to apply it to a wide variety of situations and would be crucial to our analyses.\nLemma 22. Let V be a universe with a total order established on it and let v1, . . . ,vn be a population of n items arranged in decreasing order. Let v̂1, . . . , v̂b be a sample chosen i.i.d. (or without replacement) from the population and arranged in decreasing order as well. Then for any fixed h : V → [−1, 1] and κ ∈ (0, 1], we have, with probability at least 1− δ over the choice of the samples,∣∣∣∣∣∣ 1dκne dκne∑ i=1 h(vi)− 1 dκbe dκbe∑ i=1 h(v̂i) ∣∣∣∣∣∣ ≤ 4 √ log 2δ κb\nTheorem 12. The performance measure prec@κ(·), as well as the surrogates `rampprec@κ(·), ` avg prec@κ(·) and `maxprec@κ(·), all exhibit uniform convergence at the rate α(b, δ) = O (√\n1 b log 1 δ\n) .\nWe will prove the four parts of the theorem in three separate subsections below. We shall consider a population z1, . . . , zn and a sample of size b ẑ1, . . . , ẑb chosen uniformly at random with (i.e. i.i.d.) or without replacement. We shall let p and p̂ denote the fraction of positives in the population and the sample respectively. In the following, we shall reserve the notation ŷ for the label vector in the sample and shall use the notation ỹ to denote candidate labellings in the definition of the surrogate."
    }, {
      "heading" : "D.1 A Uniform Convergence Bound for the prec@κ(·) Performance Measure",
      "text" : "We note that a point-wise convergence result for prec@κ(·) follows simply from Lemma 22. To see this, given a population z1, . . . , z)n and a fixed model w ∈ W , construct a parallel population using the transformation vi ← (w>xi,yi) ∈ R2. We order these tuples according to their first component, i.e. along the scores and use h(vi) = 1− yi. Let the population be arranged such that v1 v2 . . .. Then this gives us\nk∑ i=1 h(vi) = k∑ i=1 (1− yi) = prec@k(y,y(w,k)) = prec@k(w).\nThus, the application of Lemma 22 gives us the following result\nLemma 23. For any fixed model w ∈ W , with probability at least 1− δ over the choice of b samples, we have\n|prec@κ(w; z1, . . . , zn)− prec@κ(w; ẑ1, . . . , ẑb)| ≤ O\n(√ 1\nb log\n1\nδ\n) .\nTo prove the uniform convergence result, we will, in some sense, require a uniform version of Lemma 22. To do so we fix some notation. For any fixed κ > 0, and for any w ∈ W , we will define vw as the largest real number v such that\nn∑ i=1 I [ w>xi ≥ v ] = κpn\nSimilarly, we will define v̂w as the largest real number v such that\nb∑ i=1 I [ w>x̂i ≥ v ] = κp̂b\nUsing this notation we can redefine prec@κ(·) on the population, as well as the sample, as\nprec@κ(w; z1, . . . , zn) := 1\nκpn n∑ i=1 I [ w>x ≥ vw ] · I [yi = 0]\nprec@κ(w; ẑ1, . . . , ẑb) := 1\nκp̂b b∑ i=1 I [ w>x ≥ v̂w ] · I [ŷi = 0]\nWe can now write\nsup w∈W\n|prec@κ(w; z1, . . . , zn)− prec@κ(w; ẑ1, . . . , ẑb)|\n= sup w∈W ∣∣∣∣∣ 1κpn n∑ i=1 I [ w>x ≥ vw ] · I [yi = 0]− 1 κp̂b b∑ i=1 I [ w>x ≥ v̂w ] · I [ŷi = 0] ∣∣∣∣∣ ≤ sup\nw∈W ∣∣∣∣∣ 1κpn n∑ i=1 I [ w>x ≥ vw ] · I [yi = 0]− 1 κp̂b b∑ i=1 I [ w>x ≥ vw ] · I [ŷi = 0] ∣∣∣∣∣ + sup\nw∈W ∣∣∣∣∣ 1κp̂b b∑ i=1 I [ w>x ≥ vw ] · I [ŷi = 0]− 1 κp̂b b∑ i=1 I [ w>x ≥ v̂w ] · I [ŷi = 0] ∣∣∣∣∣ ≤ sup\nw∈W,t∈R ∣∣∣∣∣ 1κpn n∑ i=1 I [ w>x ≥ t ] · I [yi = 0]− 1 κp̂b b∑ i=1 I [ w>x ≥ t ] · I [ŷi = 0] ∣∣∣∣∣︸ ︷︷ ︸ (A)\n+ sup w∈W ∣∣∣∣∣ 1κp̂b b∑ i=1 I [ w>x ≥ vw ] · I [ŷi = 0]− 1 κp̂b b∑ i=1 I [ w>x ≥ v̂w ] · I [ŷi = 0] ∣∣∣∣∣︸ ︷︷ ︸ (B)\nNow, using a standard VC-dimension based uniform convergence argument over the class of thresholded classifiers, we get the following result: with probability at least 1− δ\n(A) ≤ O\n(√ 1\nb\n( log 1\nδ + dVC(W) · log b\n)) = Õ (√ 1\nb log\n1\nδ\n) ,\nwhere dVC(W) is the VC-dimension of the set of classifiersW . Moving on to bound the second term, we can use an argument similar to the one used to prove Lemma 22 to show that\n(B) ≤ sup w∈W ∣∣∣∣∣ 1κp̂b b∑ i=1 I [ w>x ≥ vw ] − 1 κp̂b b∑ i=1 I [ w>x ≥ v̂w ]∣∣∣∣∣ ≤ sup\nw∈W ∣∣∣∣∣ 1κp̂b b∑ i=1 I [ w>x ≥ vw ] − κ ∣∣∣∣∣ ≤ sup\nw∈W ∣∣∣∣∣ 1κp̂b b∑ i=1 I [ w>x ≥ vw ] − 1 κpn n∑ i=1 I [ w>x ≥ vw ]∣∣∣∣∣\n≤ Õ\n(√ 1\nb log\n1\nδ\n) ,\nwhere the last step follows from a standard VC-dimension based uniform convergence argument as before. This establishes the following uniform convergence result for the prec@k(·) performance measure\nTheorem 24. We have, with probability at least 1− δ over the choice of b samples,\nsup w∈W\n|prec@κ(w; z1, . . . , zn)− prec@κ(w; ẑ1, . . . , ẑb)| ≤ Õ\n(√ 1\nb log\n1\nδ\n) ."
    }, {
      "heading" : "D.2 A Uniform Convergence Bound for the `rampprec@κ(·) Surrogate",
      "text" : "We first recall the form of the (normalized) surrogate below - note that this is a non-convex surrogate. Also recall that k = κ · n+(y).\n`rampprec@κ(w; z1, . . . , zn) = max‖ỹ‖1=k\n{ ∆(y, ỹ)\nk +\n1\nk n∑ i=1 ỹiw >xi } ︸ ︷︷ ︸\nΨ1(w; z1,...,zn)\n− max ‖ỹ‖1=k K(y,ỹ)=k\n1\nk n∑ i=1 ỹiw >xi\n︸ ︷︷ ︸ Ψ2(w; z1,...,zn)\nWe will now show that both the functions Ψ1(·), as well as Ψ2(·), exhibit uniform convergence. This shall suffice to prove that `rampprec@κ(·) exhibits uniform convergence. To do so we shall show that the two functions exhibit pointwise convergence and that they are Lipschitz. This will allow a standard L∞ covering number argument Zhang [2002] to give us the required uniform convergence results."
    }, {
      "heading" : "D.2.1 A Uniform Convergence Result for Ψ1(·)",
      "text" : "We have\nΨ1(w; z1, . . . , zn) = max ‖ỹ‖1=κpn\n{ 1\nκpn n∑ i=1 ỹi(w >xi − yi)\n} + 1\nΨ1(w; ẑ1, . . . , ẑb) = max ‖ỹ‖1=κp̂b\n{ 1\nκp̂b b∑ i=1 ỹi(w >x̂i − ŷi)\n} + 1\nAn application of Corollary 29 indicates that Ψ1(·) is Lipschitz i.e.\n|Ψ1(w; z1, . . . , zn)−Ψ1(w′; z1, . . . , zn)| ≤ O (‖w −w′‖2) .\nThus, all that remains is to prove pointwise convergence. We decompose the error as follows\n|Ψ1(w; z1, . . . , zn)−Ψ1(w; ẑ1, . . . , ẑb)| ≤ ∣∣∣∣∣Ψ1(w; z1, . . . , zn)− max‖ỹ‖1=κpb { 1 κpb b∑ i=1 ỹi(w >x̂i − ŷi) } + 1 ∣∣∣∣∣︸ ︷︷ ︸ (A)\n+ ∣∣∣∣∣ max‖ỹ‖1=κpb { 1 κpb b∑ i=1 ỹi(w >x̂i − ŷi) } + 1−Ψ1(w; ẑ1, . . . , ẑb) ∣∣∣∣∣︸ ︷︷ ︸ (B)\nAn application of Lemma 22 using vi = w>x̂i − ŷi and h(·) as the identity function shows us that\n(A) ≤ O\n( 1\nκp\n√ 1\nb log\n1\nδ\n) .\nTo bound the residual term (B), notice that an application of the Hoeffding’s inequality tells us that with probability at least 1− δ |p− p̂| ≤ √ 1\n2b log\n2 δ ,\nwhich lets us bound the residual as follows. Assume, for sake of simplicity, that the sample data points have been ordered in decreasing order of the quantity w>x̂i − yi as well as that ∣∣w>x∣∣ ≤ 1 for all x. (B) =\n∣∣∣∣∣ max‖ỹ‖1=κpb { 1 κpb b∑ i=1 ỹi(w >x̂i − ŷi) } − max ‖ỹ‖1=κp̂b { 1 κp̂b b∑ i=1 ỹi(w >x̂i − ŷi) }∣∣∣∣∣ =\n∣∣∣∣∣ 1κpb κpb∑ i=1 (w>x̂i − ŷi)− 1 κp̂b κp̂b∑ i=1 (w>x̂i − ŷi) ∣∣∣∣∣ ≤ ∣∣∣∣∣∣ κmin{p,p̂}b∑\ni=1\n( 1\nκpb − 1 κp̂b\n) (w>x̂i − ŷi) ∣∣∣∣∣∣+ ∣∣∣∣∣∣ 1κmax {p, p̂} b κmax{p,p̂}b∑ i=κmin{p,p̂}b+1 (w>x̂i − ŷi) ∣∣∣∣∣∣ ≤ 2 κb ∣∣∣∣p− p̂pp̂ ∣∣∣∣ · κmin {p, p̂} b+ 2κmax {p, p̂} b · κ |p− p̂| b\n= 2 |p− p̂| · (\nmin {p, p̂} pp̂ + 1 max {p, p̂} ) ≤ √ 1\n2b log\n2 δ · 2 max {p, p̂} ≤ 2 p\n√ 1\n2b log\n2\nδ\nThis establishes that for any fixed w ∈ W , with probability at least 1− δ, we have\n|Ψ1(w; z1, . . . , zn)−Ψ1(w; ẑ1, . . . , ẑb)| ≤ O\n(√ 1\nb log\n1\nδ\n)\nwhich concludes the uniform convergence proof."
    }, {
      "heading" : "D.2.2 A Uniform Convergence Result for Ψ2(·)",
      "text" : "The proof follows similarly here with a direct application of Corollary 29 showing us that Ψ2(·) is Lipschitz and an application of Lemma 22 along with the observation that |p− p̂| ≤ √ 1 2b log 2 δ similar to the discussion used above concluding the point-wise convergence proof. The above two part argument establishes the following uniform convergence result for the `rampprec@κ(·) performance measure\nTheorem 25. We have, with probability at least 1− δ over the choice of b samples,\nsup w∈W\n∣∣∣`rampprec@κ(w; z1, . . . , zn)− `rampprec@κ(w; ẑ1, . . . , ẑb)∣∣∣ ≤ O (√ 1\nb log\n1\nδ\n) ."
    }, {
      "heading" : "D.3 A Uniform Convergence Bound for the `avgprec@κ(·) Surrogate",
      "text" : "This will be the most involved of the four bounds, given the intricate nature of the surrogate. We will prove this result using a series of partial results which we state below. As before, for any w ∈ W and any ỹ, we define\n∆(w, ỹ) := 1\nκpn\n( ∆(y, ỹ) +\nn∑ i=1 (ỹi − yi)w>xi + 1 C(ỹ) n∑ i=1 (1− ỹi)yiw>xi\n)\n∆̂(w, ỹ) := 1\nκp̂b\n( ∆(ŷ, ỹ) +\nn∑ i=1 (ỹi − ŷi)w>x̂i + 1 C(ỹ) n∑ i=1 (1− ỹi)ŷiw>x̂i\n)\nRecall that we are using ŷ to denote the true labels of the sample points and ỹ to denote the candidate labellings while defining the surrogates. We also define, for any β ∈ [0, 1], the following quantities\n∆(w, β) := max ‖ỹ‖1=κpn K(y,ỹ)=βpn\n{∆(w, ỹ)}\n∆̂(w, β) := max ‖ỹ‖1=κp̂b K(ŷ,ỹ)=βp̂b\n{ ∆̂(w, ỹ) } Note that β denotes a target true positive rate and consequently, can only take values between 0 and κ. Given the above, we claim the following lemmata\nLemma 26. For every w and any β, β′ ∈ [0, κ], we have\n|∆(w, β)−∆(w, β′)| ≤ O (|β − β′|) .\nLemma 27. For any fixed β, we have, with probability at least 1− δ over the choice of the sample\nsup w∈W ∣∣∣∆(w, β)− ∆̂(w, β)∣∣∣ ≤ O(√1 b log 1 δ ) .\nUsing the above two lemmata as given, we can now prove the desired uniform convergence result for the `avgprec@κ(·) surrogate:\nTheorem 28. With probability at least 1− δ over the choice of the samples, we have\nsup w∈W\n∣∣∣`avgprec@κ(w; z1, . . . , zn)− `avgprec@κ(w; ẑ1, . . . , ẑb)∣∣∣ ≤ Õ (√ 1\nb log\n1\nδ\n) .\nProof. We note that given the definitions of ∆(w, β) and ∆̂(w, β), we can redefine the performance measure as follows\n`avgprec@κ(w; z1, . . . , zn) = max β∈[0,κ] ∆(w, β)\nWe now note that for the population, the set of achievable values of true positive rates i.e. β is\nB = { 0, 1\nκpn ,\n2\nκpn , . . . , κpn− 1 κpn , 1\n} ,\nwhich correspond, respectively, to classifiers for which the number of true positives equals {0, 1, 2 . . . κpn− 1, κpn}. Similarly, the set of achievable values of true positive rates i.e. β for the sample is\nB̂ = { 0, 1\nκp̂b ,\n2\nκp̂b , . . . , κp̂b− 1 κp̂b , 1\n} .\nClearly, for any β ∈ B, there exists a πB̂(β) ∈ B̂ such that∣∣πB̂(β)− β∣∣ ≤ 1κp̂b . Given this, let us define\nβ∗(w) = arg max β∈[0,κ] ∆(w, β)\nβ̂∗(w) = arg max β̂∈[0,κ] ∆̂(w, β̂)\nWe shall assume, for the sake of simplicity, that s|n so that B̂ ⊂ B. This gives us the following set of inequalities for any w ∈ W:\n∆(w, β∗(w)) ≤ ∆(w, πB̂(β ∗(w))) + ∣∣β∗(w)− πB̂(β∗(w))∣∣ ≤ ∆̂(w, πB̂(β\n∗(w))) + sup w∈W ∣∣∣∆(w, πB̂(β∗(w)))− ∆̂(w, πB̂(β∗(w)))∣∣∣+ 1κp̂b ≤ ∆̂(w, πB̂(β\n∗(w))) + sup w∈W,β̂∈B̂ ∣∣∣∆(w, β̂)− ∆̂(w, β̂)∣∣∣+ 1 κp̂b\n≤ ∆̂(w, πB̂(β ∗(w))) +O\n(√ 1\nb log\nb\nδ\n) + 1\nκp̂b\n≤ ∆̂(w, β̂∗(w)) +O\n(√ 1\nb log\nb\nδ\n) + 1\nκp̂b ,\nwhere the first step follows from Lemma 26, the third step follows since πB̂(β ∗(w)) ∈ B̂, the fourth step follows from an application of the union bound with Lemma 27 over the set of elements in B̂ and noting ∣∣∣B̂∣∣∣ ≤ O (b), and the last\nstep follows from the optimality of β̂∗(w). Similarly we can write, for any w ∈ W ,\n∆̂(w, β̂∗(w)) ≤ ∆(w, β̂∗(w)) +O\n(√ 1\nb log\nb\nδ\n)\n≤ ∆(w, β∗(w)) +O\n(√ 1\nb log\nb\nδ\n) ,\nwhere the first step uses Lemma 27 with a union bound over elements in B̂ and the fact that β̂∗(w) ∈ B̂ ⊂ B (note that this assumption is not crucial to the argument – indeed, even if β̂∗(w) /∈ B, we would only incur an extra O ( 1 n ) error by an application of Lemma 26 since given the granularity of B, we would always be able to find a value in B that is no more than O ( 1 n ) far from β̂∗(w)), and the last step uses the optimality of β∗(w). Thus, we can write\nsup w∈W ∣∣∣`avgprec@κ(w; z1, . . . , zn)− `avgprec@κ(w; ẑ1, . . . , ẑb)∣∣∣ = sup w∈W ∣∣∣∆(w, β∗(w))− ∆̂(w, β̂∗(w))∣∣∣ ≤ O (√ 1\nb log\nb\nδ\n) + 1\nκp̂b\n≤ Õ\n(√ 1\nb log\n1\nδ\n) ,\nsince p̂ ≥ Ω (1) with probability at least 1 − δ. Thus, all we are left is to prove Lemmata 26 and 27 which we do below. To proceed with the proofs, we first write the form of ∆(w, β) for a fixed w and β and simplify the expression for ease of further analysis. We shall assume, for sake of simplicity, that βpn, κpn, βp̂b, and κp̂b are all integers.\n∆(w, β) = max ‖ỹ‖1=κpn K(y,ỹ)=βpn\n{ 1\nκpn\n( ∆(y, ỹ) +\nn∑ i=1 (ỹi − yi)w>xi + 1 C(ỹ) n∑ i=1 (1− ỹi)yiw>xi\n)}\n= 1− β κ − 1 κpn ( κ− β 1− β ) n∑ i=1\nyiw >xi︸ ︷︷ ︸\nA(w,β)\n+ max ‖ỹ‖1=κpn K(y,ỹ)=βpn\n{ 1\nκpn n∑ i=1 ỹi ( 1− 1− κ 1− β · yi ) w>xi } ︸ ︷︷ ︸\nB(w,β)\nWe can similarly define Â(w, β) and B̂(w, β) for the samples.\nProof of Lemma 26. We have, by the above simplification,\n|∆(w, β)−∆(w, β′)| = 1 κ |β − β′|+ |A(w, β)−A(w, β′)|+ |B(w, β)−B(w, β′)| ,\nas well as, assuming without loss of generality, that ∣∣w>x∣∣ ≤ 1 for all w and x,\n|A(w, β)−A(w, β′)| ≤ ∣∣∣∣κ− β1− β − κ− β′1− β′ ∣∣∣∣ · ∣∣∣∣∣ 1κpn n∑ i=1 yiw >xi ∣∣∣∣∣ ≤ (1− κ) |β − β\n′| κ(1− β)(1− β′) ≤ 1 κ(1− κ) |β − β′| ,\nwhere the last step follows since β, β′ ≤ κ. To analyze the third term i.e. |B(w, β)−B(w, β′)|, we analyze the nature of the assignment ỹ which defines B(w, β). Clearly ỹ must assign βpn positives and (κ − β)pn negatives a label of 1 and the rest, a label of 0. Since it is supposed to maximize the scores thus obtained, it clearly assigns the top ranked (κ − β)pn negatives a label of 1. As far as positives are concerned, β < κ, we have ( 1− 1−κ1−β ) ≥ 0 which means that the βpn top ranked positives will get assigned a label of 1. To formalize this, let us set some notation. Let s+1 ≥ s + 2 ≥ . . . ≥ s+pn denote the scores of the positive points arranged in descending order. Similarly, let s−1 ≥ s − 2 ≥ . . . ≥ s − (1−p)n denote the scores of the negative points arranged in descending order. Given this notation, we can rewrite B(w, β) as follows:\nB(w, β) = 1\nκpn (κ− β 1− β ) βpn∑ i=1 s+i + (κ−β)pn∑ i=1 s−i  . Thus, assuming without loss of generality that\n∣∣s+i ∣∣ , ∣∣s−i ∣∣ ≤ 1, we have, |B(w, β)−B(w, β′)| = 1\nκpn ∣∣∣∣∣∣ ( κ− β 1− β ) βpn∑ i=1 s+i + (κ−β)pn∑ i=1 s−i − ( κ− β′ 1− β′ ) β′pn∑ i=1 s+i − (κ−β′)pn∑ i=1 s−i ∣∣∣∣∣∣ ≤ 1 κpn ∣∣∣∣∣∣ ( κ− β 1− β ) βpn∑ i=1 s+i − ( κ− β′ 1− β′ ) β′pn∑ i=1 s+i ∣∣∣∣∣∣+ 1κpn ∣∣∣∣∣∣ (κ−β)pn∑ i=1 s−i − (κ−β′)pn∑ i=1 s−i\n∣∣∣∣∣∣ ≤ ∣∣∣∣κ− β1− β − κ− β′1− β′ ∣∣∣∣ · ∣∣∣∣∣∣∣ 1 κpn min{β,β′}pn∑ i=1 s+i ∣∣∣∣∣∣∣+ 1 κpn κ−max {β, β′} 1−max {β, β′} |β − β′| pn+ |β − β ′| pn κpn\n≤ 1 κ(1− κ)\n|β − β′| min {β, β ′} pn\nκpn +\n1\nκ κ−max {β, β′} 1−max {β, β′} |β − β′|+ |β − β ′| κ\n≤ 2 κ(1− κ) |β − β′| ,\nwhere the last step uses the fact that 0 ≤ β, β′ ≤ κ. This tells us that\n|∆(w, β)−∆(w, β′)| ≤ 4− κ κ(1− κ) |β − β′| ,\nwhich finishes the proof.\nProof of Lemma 27. We will prove the theorem by showing that the terms A(w, β) and B(w, β) exhibit uniform convergence.\nIt is easy to see that A(w, β) exhibits uniform convergence since it is a simple average of population scores. The only thing to be taken care of is that A(w, β) contains p in the normalization whereas Â(w, β) contains p̂. However, since p and p̂ are very close with high probability, an argument similar to the one used in the proof of Theorem 25 can be used to conclude that with probability at least 1− δ, we have\nsup w∈W ∣∣∣A(w, β)− Â(w, β)∣∣∣ ≤ O(√1 b log 1 δ ) .\nTo prove uniform convergence for B(w, β) we will use our earlier method of showing that this function exhibits pointwise convergence and that this function is Lipschitz with respect to w. The Lipschitz property of B(w, β) is evident from an application of Corollary 29. To analyze its pointwise convergence property\nThus the function B(w, β), as analyzed in the proof of Lemma 26, is composed by sorting the positives and negatives separately and taking the top few positions in each list and adding the scores present therein. This allows an application of Lemma 22, as used in the proof of Theorem 25, separately to the positive and negative lists, to conclude the pointwise convergence bound for B(w, β).\nThis concludes the proof of the uniform convergence bound for `avgprec@κ(·)."
    }, {
      "heading" : "D.4 Proof of Lemma 21",
      "text" : "Lemma 21. Let f1, . . . , fm be m real valued functions fi : Rn → R such that every fi is 1-Lipschitz with respect to the ‖·‖∞ norm. Then the function\ng(v) = max i∈[m] fi(v)\nis 1-Lipschitz with respect to the ‖·‖∞ norm too.\nProof. Fix v,v′ ∈ Rn. The premise guarantees us that for any i ∈ [m], we have\n|fi(v)− fi(v′)| ≤ ‖v − v′‖∞ .\nNow let g(v) = fi(v) and g(v′) = fj(v′). Then we have\ng(v)− g(v′) = fi(v)− fj(v′) ≤ fi(v)− fi(v′) ≤ ‖v − v′‖∞ ,\nsince fj(v′) ≥ fi(v′). Similarly we have g(v′)− g(v) ≤ ‖v − v′‖∞. This completes the proof.\nThe following corollary would be most useful in our subsequent analyses.\nCorollary 29. Let Ψ :W → R be a function defined as follows\nΨ(w) = max ŷ∈{0,1}n ‖ŷ‖1=k\n1\nk\n∑ ŷi(w >xi − ci),\nwhere ci are constants independent of w and we assume without loss of generality that ‖xi‖2 ≤ 1 for all i. Then Ψ(·) is 1- Lipschitz with respect to the L2 norm i.e. for all w,w′ ∈ W\n|Ψ(w)−Ψ(w′)| ≤ ‖w −w′‖2 .\nProof. Note that for any ŷ such that ‖ŷ‖1 = k, the function fŷ(v) = 1 k ∑ ŷi(vi − ci) is 1-Lipschitz with respect to the ‖·‖∞ norm. Thus if we define Φ(v) = max\n‖ŷ‖1=k fŷ(v),\nthen an application of Lemma 21 tells us that Φ(·) is 1-Lipschitz with respect to the ‖·‖∞ norm as well. Also note that if we define\nv(w) = ( w>x1 − c1, . . . ,w>xn − cn ) ,\nthen we have Ψ(w) = Φ(v(w))\nWe now note that by an application of Cauchy-Schwartz inequality, and the fact that ‖xi‖2 ≤ 1 for all i, we have\n‖v(w)− v(w′)‖∞ ≤ ‖w −w ′‖2\nThus we have\n|Ψ(w)−Ψ(w′)| = |Φ(v(w))− Φ(v(w′))| ≤ ‖v(w)− v(w′)‖∞ ≤ ‖w −w ′‖2\nwhich gives us the desired result."
    }, {
      "heading" : "D.5 Proof of Lemma 22",
      "text" : "Lemma 22. Let V be a universe with a total order established on it and let v1, . . . ,vn be a population of n items arranged in decreasing order. Let v̂1, . . . , v̂b be a sample chosen i.i.d. (or without replacement) from the population and arranged in decreasing order as well. Then for any fixed h : V → [−1, 1] and κ ∈ (0, 1], we have, with probability at least 1− δ over the choice of the samples,∣∣∣∣∣∣ 1dκne dκne∑ i=1 h(vi)− 1 dκbe dκbe∑ i=1 h(v̂i) ∣∣∣∣∣∣ ≤ 4 √ log 2δ κb\nProof. We will assume, for sake of simplicity, that κn and κb are both integers so that there are no rounding off issues. Let v∗n := vκn and v ∗ b := v̂κb denote the elements at the bottom of the κ-th fraction of the top in the sorted population and sample lists (recall that the population and the sample lists are sorted in descending order). Also let T(v) := I [v v∗n] and T̂(v) := I [v v∗b ] (note that I [E] is the indicator variable for the event E) so that we have∣∣∣∣∣ 1κn κn∑ i=1 h(vi)− 1 κb κb∑ i=1 h(v̂i) ∣∣∣∣∣ = ∣∣∣∣∣ 1κn n∑ i=1 T(vi) · h(vi)− 1 κb b∑ i=1 T̂(v̂i) · h(v̂i)\n∣∣∣∣∣ ≤\n∣∣∣∣∣ 1κn n∑ i=1 T(vi) · h(vi)− 1 κb b∑ i=1 T(v̂i) · h(v̂i) ∣∣∣∣∣+ ∣∣∣∣∣ 1κb b∑ i=1 ( T(v̂i)− T̂(v̂i) ) · h(v̂i) ∣∣∣∣∣ ≤ 2 √ log 2δ κb + ∣∣∣∣∣ 1κb b∑ i=1 ( T(v̂i)− T̂(v̂i) ) · h(v̂i)\n∣∣∣∣∣︸ ︷︷ ︸ (A) ,\nwhere the third step follows from Bernstein’s inequality (which holds in situations with sampling without replacement as well Boucheron et al. [2004]) since |T(v) · h(v)| ≤ 1 for all v and we have assumed b ≥ 1κ log 2 δ . Now if v ∗ n v∗b , then we have T̂(v) ≥ T(v) for all v. On the other hand if v∗b v∗n, then we have T̂(v) ≤ T(v) for all v. This means that since |h(v)| ≤ 1 for all v, we have\n(A) ≤ ∣∣∣∣∣ 1κb b∑ i=1 ( T(v̂i)− T̂(v̂i) )∣∣∣∣∣ = ∣∣∣∣∣ 1κb b∑ i=1 T(v̂i)− 1 ∣∣∣∣∣ ≤ 2 √ log 2δ κb ,\nwhere the second step follows since 1κb ∑b i=1 T̂(v̂i) = 1 by definition and the last step follows from another application of Bernstein’s inequality. This completes the proof."
    }, {
      "heading" : "D.6 A Uniform Convergence Bound for the `maxprec@κ(·) Surrogate",
      "text" : "Having proved a generalization bound for the `avgprec@κ(·) surrogate, we note that similar techniques, that involve partitioning the candidate label space into labels that have a fixed true positive rate β, and arguing uniform convergence for each partition, can be used to prove a generalization bound for the `maxprec@κ(·) surrogate as well. We postpone the details of the argument to a later version of the paper."
    }, {
      "heading" : "E Proof of Theorem 15",
      "text" : "Theorem 15. Let w̄ be the model returned by Algorithm 3 when executed on a stream with T batches of length b. Then with probability at least 1− δ, for any w∗ ∈ W , we have\n`avgprec@κ(w̄;Z) ≤ ` avg prec@κ(w ∗;Z) +O\n(√ 1\nb log\nT\nδ\n) +O (√ 1\nT\n)\nProof. The proof of this theorem closely follows that of Theorems 7 and 8 in Kar et al. [2014]. More specifically, Theorem 6 from Kar et al. [2014] ensures that any convex loss function demonstrating uniform convergence would ensure a result of the kind we are trying to prove. Since Theorem 12 confirms that `avgprec@κ(·) exhibits uniform convergence, the proof follows.\nF Additional Empirical Results"
    } ],
    "references" : [ {
      "title" : "The Infinite Push: A new support vector ranking algorithm that directly optimizes accuracy at the absolute top of the list",
      "author" : [ "S. Agarwal" ],
      "venue" : "In 11th SIAM International Conference on Data Mining (SDM),",
      "citeRegEx" : "Agarwal.,? \\Q2011\\E",
      "shortCiteRegEx" : "Agarwal.",
      "year" : 2011
    }, {
      "title" : "Concentration inequalities",
      "author" : [ "Stphane Boucheron", "Gbor Lugosi", "Olivier Bousquet" ],
      "venue" : "In Advanced Lectures in Machine Learning,",
      "citeRegEx" : "Boucheron et al\\.,? \\Q2004\\E",
      "shortCiteRegEx" : "Boucheron et al\\.",
      "year" : 2004
    }, {
      "title" : "Accuracy at the top",
      "author" : [ "Stephen Boyd", "Corinna Cortes", "Mehryar Mohri", "Ana Radovanovic" ],
      "venue" : "In 26th Annual Conference on Neural Information Processing Systems (NIPS),",
      "citeRegEx" : "Boyd et al\\.,? \\Q2012\\E",
      "shortCiteRegEx" : "Boyd et al\\.",
      "year" : 2012
    }, {
      "title" : "Learning to rank using gradient descent",
      "author" : [ "C. Burges", "T. Shaked", "E. Renshaw", "A. Lazier", "M. Deeds", "N. Hamilton", "G. Hullender" ],
      "venue" : "In 22nd International Conference on Machine Learning (ICML),",
      "citeRegEx" : "Burges et al\\.,? \\Q2005\\E",
      "shortCiteRegEx" : "Burges et al\\.",
      "year" : 2005
    }, {
      "title" : "On the (Non-)existence of Convex, Calibrated Surrogate Losses for Ranking",
      "author" : [ "Clément Calauzènes", "Nicolas Usunier", "Patrick Gallinari" ],
      "venue" : "In 26th Annual Conference on Neural Information Processing Systems (NIPS),",
      "citeRegEx" : "Calauzènes et al\\.,? \\Q2012\\E",
      "shortCiteRegEx" : "Calauzènes et al\\.",
      "year" : 2012
    }, {
      "title" : "Learning to rank: from pairwise approach to listwise approach",
      "author" : [ "Zhe Cao", "Tao Qin", "Tie-Yan Liu", "Ming-Feng Tsai", "Hang Li" ],
      "venue" : "In 24th International Conference on Machine learning (ICML),",
      "citeRegEx" : "Cao et al\\.,? \\Q2007\\E",
      "shortCiteRegEx" : "Cao et al\\.",
      "year" : 2007
    }, {
      "title" : "Structured Learning for Non-Smooth Ranking Losses",
      "author" : [ "Soumen Chakrabarti", "Rajiv Khanna", "Uma Sawant", "Chiru Bhattacharyya" ],
      "venue" : "In 14th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (KDD),",
      "citeRegEx" : "Chakrabarti et al\\.,? \\Q2008\\E",
      "shortCiteRegEx" : "Chakrabarti et al\\.",
      "year" : 2008
    }, {
      "title" : "Perceptron-like algorithms and generalization bounds for learning to rank",
      "author" : [ "Sougata Chaudhuri", "Ambuj Tewari" ],
      "venue" : "CoRR, abs/1405.0591,",
      "citeRegEx" : "Chaudhuri and Tewari.,? \\Q2014\\E",
      "shortCiteRegEx" : "Chaudhuri and Tewari.",
      "year" : 2014
    }, {
      "title" : "Online ranking with top-1 feedback",
      "author" : [ "Sougata Chaudhuri", "Ambuj Tewari" ],
      "venue" : "In 18th International Conference on Artificial Intelligence and Statistics (AISTATS),",
      "citeRegEx" : "Chaudhuri and Tewari.,? \\Q2015\\E",
      "shortCiteRegEx" : "Chaudhuri and Tewari.",
      "year" : 2015
    }, {
      "title" : "Ranking the best instances",
      "author" : [ "Stéphan Clémençon", "Nicolas Vayatis" ],
      "venue" : "The Journal of Machine Learning Research,",
      "citeRegEx" : "Clémençon and Vayatis.,? \\Q2007\\E",
      "shortCiteRegEx" : "Clémençon and Vayatis.",
      "year" : 2007
    }, {
      "title" : "Tighter Bounds for Structured Estimation",
      "author" : [ "Chuong B. Do", "Quoc Le", "Choon Hui Teo", "Olivier Chapelle", "Alex Smola" ],
      "venue" : "In 22nd Annual Conference on Neural Information Processing Systems (NIPS),",
      "citeRegEx" : "Do et al\\.,? \\Q2008\\E",
      "shortCiteRegEx" : "Do et al\\.",
      "year" : 2008
    }, {
      "title" : "An efficient boosting algorithm for combining preferences",
      "author" : [ "Y. Freund", "R. Iyer", "R.E. Schapire", "Y. Singer" ],
      "venue" : "Journal of Machine Learning Research,",
      "citeRegEx" : "Freund et al\\.,? \\Q2003\\E",
      "shortCiteRegEx" : "Freund et al\\.",
      "year" : 2003
    }, {
      "title" : "Hardness of learning halfspaces with noise",
      "author" : [ "Venkatesan Guruswami", "Prasad Raghavendra" ],
      "venue" : "SIAM J. Comput.,",
      "citeRegEx" : "Guruswami and Raghavendra.,? \\Q2009\\E",
      "shortCiteRegEx" : "Guruswami and Raghavendra.",
      "year" : 2009
    }, {
      "title" : "Large margin rank boundaries for ordinal regression",
      "author" : [ "R. Herbrich", "T. Graepel", "K. Obermayer" ],
      "venue" : "Advances in Large Margin Classifiers,",
      "citeRegEx" : "Herbrich et al\\.,? \\Q2000\\E",
      "shortCiteRegEx" : "Herbrich et al\\.",
      "year" : 2000
    }, {
      "title" : "Optimizing search engines using clickthrough data",
      "author" : [ "T. Joachims" ],
      "venue" : "In 8th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (KDD),",
      "citeRegEx" : "Joachims.,? \\Q2002\\E",
      "shortCiteRegEx" : "Joachims.",
      "year" : 2002
    }, {
      "title" : "A Support Vector Method for Multivariate Performance Measures",
      "author" : [ "Thorsten Joachims" ],
      "venue" : "In 22nd International Conference on Machine Learning (ICML),",
      "citeRegEx" : "Joachims.,? \\Q2005\\E",
      "shortCiteRegEx" : "Joachims.",
      "year" : 2005
    }, {
      "title" : "Online and stochastic gradient methods for nondecomposable loss functions",
      "author" : [ "Purushottam Kar", "Harikrishna Narasimhan", "Prateek Jain" ],
      "venue" : "In 28th Annual Conference on Neural Information Processing Systems (NIPS),",
      "citeRegEx" : "Kar et al\\.,? \\Q2014\\E",
      "shortCiteRegEx" : "Kar et al\\.",
      "year" : 2014
    }, {
      "title" : "Direct optimization of ranking measures",
      "author" : [ "Quoc V. Le", "Alexander J. Smola" ],
      "venue" : "arXiv preprint arXiv:0704.3359,",
      "citeRegEx" : "Le and Smola.,? \\Q2007\\E",
      "shortCiteRegEx" : "Le and Smola.",
      "year" : 2007
    }, {
      "title" : "Top rank optimization in linear time",
      "author" : [ "Nan Li", "Rong Jin", "Zhi-Hua Zhou" ],
      "venue" : "In 28th Annual Conference on Neural Information Processing Systems (NIPS),",
      "citeRegEx" : "Li et al\\.,? \\Q2014\\E",
      "shortCiteRegEx" : "Li et al\\.",
      "year" : 2014
    }, {
      "title" : "Perceptrons: An Introduction to Computational Geometry",
      "author" : [ "Marvin Lee Minsky", "Seymour Papert" ],
      "venue" : null,
      "citeRegEx" : "Minsky and Papert.,? \\Q1988\\E",
      "shortCiteRegEx" : "Minsky and Papert.",
      "year" : 1988
    }, {
      "title" : "A Structural SVM Based Approach for Optimizing Partial AUC",
      "author" : [ "Harikrishna Narasimhan", "Shivani Agarwal" ],
      "venue" : "In 30th International Conference on Machine Learning (ICML),",
      "citeRegEx" : "Narasimhan and Agarwal.,? \\Q2013\\E",
      "shortCiteRegEx" : "Narasimhan and Agarwal.",
      "year" : 2013
    }, {
      "title" : "Optimizing Non-decomposable Performance Measures: A Tale of Two Classes",
      "author" : [ "Harikrishna Narasimhan", "Purushottam Kar", "Prateek Jain" ],
      "venue" : "In 32nd International Conference on Machine Learning (ICML),",
      "citeRegEx" : "Narasimhan et al\\.,? \\Q2015\\E",
      "shortCiteRegEx" : "Narasimhan et al\\.",
      "year" : 2015
    }, {
      "title" : "On convergence proofs on perceptrons",
      "author" : [ "A.B.J. Novikoff" ],
      "venue" : "In Proceedings of the Symposium on the Mathematical Theory of Automata,",
      "citeRegEx" : "Novikoff.,? \\Q1962\\E",
      "shortCiteRegEx" : "Novikoff.",
      "year" : 1962
    }, {
      "title" : "Fastxml: a fast, accurate and stable tree-classifier for extreme multi-label learning",
      "author" : [ "Yashoteja Prabhu", "Manik Varma" ],
      "venue" : "In 20th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining,",
      "citeRegEx" : "Prabhu and Varma.,? \\Q2014\\E",
      "shortCiteRegEx" : "Prabhu and Varma.",
      "year" : 2014
    }, {
      "title" : "The perceptron: A probabilistic model for information storage and organization in the brain",
      "author" : [ "Frank Rosenblatt" ],
      "venue" : "Psychological Review,",
      "citeRegEx" : "Rosenblatt.,? \\Q1958\\E",
      "shortCiteRegEx" : "Rosenblatt.",
      "year" : 1958
    }, {
      "title" : "The p-norm push: A simple convex ranking algorithm that concentrates at the top of the list",
      "author" : [ "C. Rudin" ],
      "venue" : "Journal of Machine Learning Research,",
      "citeRegEx" : "Rudin.,? \\Q2009\\E",
      "shortCiteRegEx" : "Rudin.",
      "year" : 2009
    }, {
      "title" : "Multi-Label Classification: An Overview",
      "author" : [ "Grigorios Tsoumakas", "Ioannis Katakis" ],
      "venue" : "International Journal of Data Warehousing and Mining,",
      "citeRegEx" : "Tsoumakas and Katakis.,? \\Q2007\\E",
      "shortCiteRegEx" : "Tsoumakas and Katakis.",
      "year" : 2007
    }, {
      "title" : "Learning to rank by optimizing NDCG measure",
      "author" : [ "Hamed Valizadegan", "Rong Jin", "Ruofei Zhang", "Jianchang Mao" ],
      "venue" : "In 26th Annual Conference on Neural Information Processing Systems (NIPS),",
      "citeRegEx" : "Valizadegan et al\\.,? \\Q2009\\E",
      "shortCiteRegEx" : "Valizadegan et al\\.",
      "year" : 2009
    }, {
      "title" : "A support vector method for optimizing average precision",
      "author" : [ "Y. Yue", "T. Finley", "F. Radlinski", "T. Joachims" ],
      "venue" : "In 30th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR),",
      "citeRegEx" : "Yue et al\\.,? \\Q2007\\E",
      "shortCiteRegEx" : "Yue et al\\.",
      "year" : 2007
    }, {
      "title" : "Ranking via robust binary classification",
      "author" : [ "Hyokun Yun", "Parameswaran Raman", "S Vishwanathan" ],
      "venue" : "In 28th Annual Conference on Neural Information Processing Systems (NIPS),",
      "citeRegEx" : "Yun et al\\.,? \\Q2014\\E",
      "shortCiteRegEx" : "Yun et al\\.",
      "year" : 2014
    }, {
      "title" : "Covering Number Bounds of Certain Regularized Linear Function Classes",
      "author" : [ "Tong Zhang" ],
      "venue" : "Journal of Machine Learning Research,",
      "citeRegEx" : "Zhang.,? \\Q2002\\E",
      "shortCiteRegEx" : "Zhang.",
      "year" : 2002
    } ],
    "referenceMentions" : [ {
      "referenceID" : 21,
      "context" : "Similarly, in multilabel classification problems, the goal is to rank the labels according to their likelihood of being relevant to a data point Tsoumakas and Katakis [2007]. The ranking of items at the top is of utmost importance in these applications and several performance measures, such as Precision@k, Average Precision and NDCG have been designed to promote accuracy at top of ranked lists.",
      "startOffset" : 145,
      "endOffset" : 174
    }, {
      "referenceID" : 13,
      "context" : "Informally, prec@k counts the number of relevant items in the top-k positions of a ranked list and is widely used in domains such as binary classification Joachims [2005], multi-label classification Prabhu and Varma [2014] and ranking Le and Smola [2007].",
      "startOffset" : 155,
      "endOffset" : 171
    }, {
      "referenceID" : 13,
      "context" : "Informally, prec@k counts the number of relevant items in the top-k positions of a ranked list and is widely used in domains such as binary classification Joachims [2005], multi-label classification Prabhu and Varma [2014] and ranking Le and Smola [2007].",
      "startOffset" : 155,
      "endOffset" : 223
    }, {
      "referenceID" : 13,
      "context" : "Informally, prec@k counts the number of relevant items in the top-k positions of a ranked list and is widely used in domains such as binary classification Joachims [2005], multi-label classification Prabhu and Varma [2014] and ranking Le and Smola [2007]. Given its popularity, prec@k has received attention from algorithmic, as well as learning theoretic perspectives.",
      "startOffset" : 155,
      "endOffset" : 255
    }, {
      "referenceID" : 13,
      "context" : "Informally, prec@k counts the number of relevant items in the top-k positions of a ranked list and is widely used in domains such as binary classification Joachims [2005], multi-label classification Prabhu and Varma [2014] and ranking Le and Smola [2007]. Given its popularity, prec@k has received attention from algorithmic, as well as learning theoretic perspectives. However, there remain specific deficiencies in our understanding of this performance measure. In fact, to the best of our knowledge, there is only one known convex surrogate function for prec@k, namely, the struct-SVM surrogate due to Joachims [2005] which, as we reveal in this work, is not an upper bound on prec@k in general, and need not recover an optimal ranking even in strictly separable settings.",
      "startOffset" : 155,
      "endOffset" : 621
    }, {
      "referenceID" : 12,
      "context" : "Since the intractability of binary classification in the agnostic setting Guruswami and Raghavendra [2009] extends to prec@k, our goal would be to exploit natural notions of benign-ness usually observed in natural distributions to overcome such intractability results.",
      "startOffset" : 74,
      "endOffset" : 107
    }, {
      "referenceID" : 10,
      "context" : "Our algorithms can be shown to be a natural extension of the classical perceptron algorithm for binary classification Rosenblatt [1958]. Indeed, akin to the classical perceptron, both our algorithms enjoy mistake bounds that reduce to crisp convergence bounds under the margin conditions mentioned earlier.",
      "startOffset" : 118,
      "endOffset" : 136
    }, {
      "referenceID" : 6,
      "context" : "While the earlier methods for this problem, such as RankSVM, focused on optimizing pair-wise ranking accuracy Herbrich et al. [2000], Joachims [2002], Freund et al.",
      "startOffset" : 110,
      "endOffset" : 133
    }, {
      "referenceID" : 6,
      "context" : "While the earlier methods for this problem, such as RankSVM, focused on optimizing pair-wise ranking accuracy Herbrich et al. [2000], Joachims [2002], Freund et al.",
      "startOffset" : 110,
      "endOffset" : 150
    }, {
      "referenceID" : 5,
      "context" : "[2000], Joachims [2002], Freund et al. [2003], Burges et al.",
      "startOffset" : 25,
      "endOffset" : 46
    }, {
      "referenceID" : 1,
      "context" : "[2003], Burges et al. [2005], of late, there has been enormous interest in performance measures that promote good ranking performance at the top portion of the ranked list, and in ranking methods that directly optimize these measures Clémençon and Vayatis [2007], Rudin [2009], Agarwal [2011], Boyd et al.",
      "startOffset" : 8,
      "endOffset" : 29
    }, {
      "referenceID" : 1,
      "context" : "[2003], Burges et al. [2005], of late, there has been enormous interest in performance measures that promote good ranking performance at the top portion of the ranked list, and in ranking methods that directly optimize these measures Clémençon and Vayatis [2007], Rudin [2009], Agarwal [2011], Boyd et al.",
      "startOffset" : 8,
      "endOffset" : 263
    }, {
      "referenceID" : 1,
      "context" : "[2003], Burges et al. [2005], of late, there has been enormous interest in performance measures that promote good ranking performance at the top portion of the ranked list, and in ranking methods that directly optimize these measures Clémençon and Vayatis [2007], Rudin [2009], Agarwal [2011], Boyd et al.",
      "startOffset" : 8,
      "endOffset" : 277
    }, {
      "referenceID" : 0,
      "context" : "[2005], of late, there has been enormous interest in performance measures that promote good ranking performance at the top portion of the ranked list, and in ranking methods that directly optimize these measures Clémençon and Vayatis [2007], Rudin [2009], Agarwal [2011], Boyd et al.",
      "startOffset" : 256,
      "endOffset" : 271
    }, {
      "referenceID" : 0,
      "context" : "[2005], of late, there has been enormous interest in performance measures that promote good ranking performance at the top portion of the ranked list, and in ranking methods that directly optimize these measures Clémençon and Vayatis [2007], Rudin [2009], Agarwal [2011], Boyd et al. [2012], Narasimhan and Agarwal [2013a,b], Li et al.",
      "startOffset" : 256,
      "endOffset" : 291
    }, {
      "referenceID" : 0,
      "context" : "[2005], of late, there has been enormous interest in performance measures that promote good ranking performance at the top portion of the ranked list, and in ranking methods that directly optimize these measures Clémençon and Vayatis [2007], Rudin [2009], Agarwal [2011], Boyd et al. [2012], Narasimhan and Agarwal [2013a,b], Li et al. [2014]. In this work, we focus on one such evaluation measure – Precision@k, which is widely used in practice.",
      "startOffset" : 256,
      "endOffset" : 343
    }, {
      "referenceID" : 0,
      "context" : "[2005], of late, there has been enormous interest in performance measures that promote good ranking performance at the top portion of the ranked list, and in ranking methods that directly optimize these measures Clémençon and Vayatis [2007], Rudin [2009], Agarwal [2011], Boyd et al. [2012], Narasimhan and Agarwal [2013a,b], Li et al. [2014]. In this work, we focus on one such evaluation measure – Precision@k, which is widely used in practice. The only prior algorithms that we are aware of that directly optimize this performance measure are a structural SVM based cutting plane method due to Joachims [2005], and an efficient stochastic implementation of the same due to Kar et al.",
      "startOffset" : 256,
      "endOffset" : 613
    }, {
      "referenceID" : 0,
      "context" : "[2005], of late, there has been enormous interest in performance measures that promote good ranking performance at the top portion of the ranked list, and in ranking methods that directly optimize these measures Clémençon and Vayatis [2007], Rudin [2009], Agarwal [2011], Boyd et al. [2012], Narasimhan and Agarwal [2013a,b], Li et al. [2014]. In this work, we focus on one such evaluation measure – Precision@k, which is widely used in practice. The only prior algorithms that we are aware of that directly optimize this performance measure are a structural SVM based cutting plane method due to Joachims [2005], and an efficient stochastic implementation of the same due to Kar et al. [2014]. However, as pointed out earlier, the convex surrogate used in these methods is not well-suited for prec@k.",
      "startOffset" : 256,
      "endOffset" : 694
    }, {
      "referenceID" : 0,
      "context" : "[2005], of late, there has been enormous interest in performance measures that promote good ranking performance at the top portion of the ranked list, and in ranking methods that directly optimize these measures Clémençon and Vayatis [2007], Rudin [2009], Agarwal [2011], Boyd et al. [2012], Narasimhan and Agarwal [2013a,b], Li et al. [2014]. In this work, we focus on one such evaluation measure – Precision@k, which is widely used in practice. The only prior algorithms that we are aware of that directly optimize this performance measure are a structural SVM based cutting plane method due to Joachims [2005], and an efficient stochastic implementation of the same due to Kar et al. [2014]. However, as pointed out earlier, the convex surrogate used in these methods is not well-suited for prec@k. It is also important to note that the bipartite ranking setting considered in this work is different from other popular forms of ranking such as subset or list-wise ranking settings, which arise in several information retrieval applications, where again there has been much work in optimizing performance measures that emphasize on accuracy at the top (e.g. NDCG) Valizadegan et al. [2009], Cao et al.",
      "startOffset" : 256,
      "endOffset" : 1192
    }, {
      "referenceID" : 0,
      "context" : "[2005], of late, there has been enormous interest in performance measures that promote good ranking performance at the top portion of the ranked list, and in ranking methods that directly optimize these measures Clémençon and Vayatis [2007], Rudin [2009], Agarwal [2011], Boyd et al. [2012], Narasimhan and Agarwal [2013a,b], Li et al. [2014]. In this work, we focus on one such evaluation measure – Precision@k, which is widely used in practice. The only prior algorithms that we are aware of that directly optimize this performance measure are a structural SVM based cutting plane method due to Joachims [2005], and an efficient stochastic implementation of the same due to Kar et al. [2014]. However, as pointed out earlier, the convex surrogate used in these methods is not well-suited for prec@k. It is also important to note that the bipartite ranking setting considered in this work is different from other popular forms of ranking such as subset or list-wise ranking settings, which arise in several information retrieval applications, where again there has been much work in optimizing performance measures that emphasize on accuracy at the top (e.g. NDCG) Valizadegan et al. [2009], Cao et al. [2007], Yue et al.",
      "startOffset" : 256,
      "endOffset" : 1211
    }, {
      "referenceID" : 0,
      "context" : "[2005], of late, there has been enormous interest in performance measures that promote good ranking performance at the top portion of the ranked list, and in ranking methods that directly optimize these measures Clémençon and Vayatis [2007], Rudin [2009], Agarwal [2011], Boyd et al. [2012], Narasimhan and Agarwal [2013a,b], Li et al. [2014]. In this work, we focus on one such evaluation measure – Precision@k, which is widely used in practice. The only prior algorithms that we are aware of that directly optimize this performance measure are a structural SVM based cutting plane method due to Joachims [2005], and an efficient stochastic implementation of the same due to Kar et al. [2014]. However, as pointed out earlier, the convex surrogate used in these methods is not well-suited for prec@k. It is also important to note that the bipartite ranking setting considered in this work is different from other popular forms of ranking such as subset or list-wise ranking settings, which arise in several information retrieval applications, where again there has been much work in optimizing performance measures that emphasize on accuracy at the top (e.g. NDCG) Valizadegan et al. [2009], Cao et al. [2007], Yue et al. [2007], Le and Smola [2007], Chakrabarti et al.",
      "startOffset" : 256,
      "endOffset" : 1230
    }, {
      "referenceID" : 0,
      "context" : "[2005], of late, there has been enormous interest in performance measures that promote good ranking performance at the top portion of the ranked list, and in ranking methods that directly optimize these measures Clémençon and Vayatis [2007], Rudin [2009], Agarwal [2011], Boyd et al. [2012], Narasimhan and Agarwal [2013a,b], Li et al. [2014]. In this work, we focus on one such evaluation measure – Precision@k, which is widely used in practice. The only prior algorithms that we are aware of that directly optimize this performance measure are a structural SVM based cutting plane method due to Joachims [2005], and an efficient stochastic implementation of the same due to Kar et al. [2014]. However, as pointed out earlier, the convex surrogate used in these methods is not well-suited for prec@k. It is also important to note that the bipartite ranking setting considered in this work is different from other popular forms of ranking such as subset or list-wise ranking settings, which arise in several information retrieval applications, where again there has been much work in optimizing performance measures that emphasize on accuracy at the top (e.g. NDCG) Valizadegan et al. [2009], Cao et al. [2007], Yue et al. [2007], Le and Smola [2007], Chakrabarti et al.",
      "startOffset" : 256,
      "endOffset" : 1251
    }, {
      "referenceID" : 0,
      "context" : "[2005], of late, there has been enormous interest in performance measures that promote good ranking performance at the top portion of the ranked list, and in ranking methods that directly optimize these measures Clémençon and Vayatis [2007], Rudin [2009], Agarwal [2011], Boyd et al. [2012], Narasimhan and Agarwal [2013a,b], Li et al. [2014]. In this work, we focus on one such evaluation measure – Precision@k, which is widely used in practice. The only prior algorithms that we are aware of that directly optimize this performance measure are a structural SVM based cutting plane method due to Joachims [2005], and an efficient stochastic implementation of the same due to Kar et al. [2014]. However, as pointed out earlier, the convex surrogate used in these methods is not well-suited for prec@k. It is also important to note that the bipartite ranking setting considered in this work is different from other popular forms of ranking such as subset or list-wise ranking settings, which arise in several information retrieval applications, where again there has been much work in optimizing performance measures that emphasize on accuracy at the top (e.g. NDCG) Valizadegan et al. [2009], Cao et al. [2007], Yue et al. [2007], Le and Smola [2007], Chakrabarti et al. [2008],",
      "startOffset" : 256,
      "endOffset" : 1278
    }, {
      "referenceID" : 7,
      "context" : "There has also been some recent work on perceptron style ranking methods for list-wise ranking problems Chaudhuri and Tewari [2014], but these methods are tailored to optimize the NDCG and MAP measures, which are different from the prec@k measure that we consider here.",
      "startOffset" : 104,
      "endOffset" : 132
    }, {
      "referenceID" : 7,
      "context" : "There has also been some recent work on perceptron style ranking methods for list-wise ranking problems Chaudhuri and Tewari [2014], but these methods are tailored to optimize the NDCG and MAP measures, which are different from the prec@k measure that we consider here. Other less related works include online ranking algorithms for optimizing ranking measures in an adversarial setting with limited feedback Chaudhuri and Tewari [2015].",
      "startOffset" : 104,
      "endOffset" : 437
    }, {
      "referenceID" : 4,
      "context" : "We note that the results of Calauzènes et al. [2012] that negate the possibility of consistent convex surrogates for ranking performance measures do not apply to our results since they are neither stated for prec@k, nor do they negate the possibility of conditional consistency.",
      "startOffset" : 28,
      "endOffset" : 53
    }, {
      "referenceID" : 4,
      "context" : "We note that the results of Calauzènes et al. [2012] that negate the possibility of consistent convex surrogates for ranking performance measures do not apply to our results since they are neither stated for prec@k, nor do they negate the possibility of conditional consistency. It is notable that the seminal work of Joachims [2005] did propose a convex surrogate for prec@k, that we refer to as `struct prec@k(·).",
      "startOffset" : 28,
      "endOffset" : 334
    }, {
      "referenceID" : 14,
      "context" : "1 The Curious Case of `struct prec@k(·) The `struct prec@k(·) surrogate is a part of a broad class of surrogates called struct-SVM surrogates that are designed for structured output prediction problems that can have exponentially large output spaces Joachims [2005]. Given a set of n labeled data points, `struct prec@k(·) is defined as",
      "startOffset" : 250,
      "endOffset" : 266
    }, {
      "referenceID" : 10,
      "context" : "Note that ` prec@k(·) is similar to the “ramp” losses for binary classification Do et al. [2008]. We now show that ` prec@k(·) is indeed an upper bounding surrogate for prec@k.",
      "startOffset" : 80,
      "endOffset" : 97
    }, {
      "referenceID" : 16,
      "context" : "Mini-batch methods have recently gained popularity and have been used to optimize ranking loss functions such as `struct prec@k(·) as well Kar et al. [2014]. It is useful to note that the requirement for mini-batches goes away in ranking and multi-label classification settings, for our algorithms can be applied to individual data points in those settings (e.",
      "startOffset" : 139,
      "endOffset" : 157
    }, {
      "referenceID" : 16,
      "context" : "Mini-batch methods have recently gained popularity and have been used to optimize ranking loss functions such as `struct prec@k(·) as well Kar et al. [2014]. It is useful to note that the requirement for mini-batches goes away in ranking and multi-label classification settings, for our algorithms can be applied to individual data points in those settings (e.g. individual queries in ranking settings). At every time instant t, our algorithms receive a batch of b points Xt = [ xt , . . . ,x b t ] and rank these points using the existing model. Let ∆t denote the prec@k loss (equation 1) at time t. If ∆t = 0 i.e. all top k ranks are occupied by positive points, then the model is not updated. Otherwise, the model is updated using the false positives and negatives. For sake of simplicity, we will only look at linear models in this paper. Depending on the kind of updates we make, we get two variants of the perceptron rule for prec@k. Our first algorithm, PERCEPTRON@K-AVG, updates the model using a combination of all the false positives and negatives (see Algorithm 1). The effect of the update is a very natural one – it explicitly boosts the scores of the positive points that failed to reach the top ranks, and attenuates the scores of the negative points that got very high scores. It is interesting to note that in the limiting case of k = 1 and unit batch length (i.e. b = 1), the PERCEPTRON@K-AVG update reduces to that of the standard perceptron algorithm Rosenblatt [1958], Minsky and Papert [1988] for the choice ŷt = sign(st).",
      "startOffset" : 139,
      "endOffset" : 1489
    }, {
      "referenceID" : 16,
      "context" : "Mini-batch methods have recently gained popularity and have been used to optimize ranking loss functions such as `struct prec@k(·) as well Kar et al. [2014]. It is useful to note that the requirement for mini-batches goes away in ranking and multi-label classification settings, for our algorithms can be applied to individual data points in those settings (e.g. individual queries in ranking settings). At every time instant t, our algorithms receive a batch of b points Xt = [ xt , . . . ,x b t ] and rank these points using the existing model. Let ∆t denote the prec@k loss (equation 1) at time t. If ∆t = 0 i.e. all top k ranks are occupied by positive points, then the model is not updated. Otherwise, the model is updated using the false positives and negatives. For sake of simplicity, we will only look at linear models in this paper. Depending on the kind of updates we make, we get two variants of the perceptron rule for prec@k. Our first algorithm, PERCEPTRON@K-AVG, updates the model using a combination of all the false positives and negatives (see Algorithm 1). The effect of the update is a very natural one – it explicitly boosts the scores of the positive points that failed to reach the top ranks, and attenuates the scores of the negative points that got very high scores. It is interesting to note that in the limiting case of k = 1 and unit batch length (i.e. b = 1), the PERCEPTRON@K-AVG update reduces to that of the standard perceptron algorithm Rosenblatt [1958], Minsky and Papert [1988] for the choice ŷt = sign(st).",
      "startOffset" : 139,
      "endOffset" : 1515
    }, {
      "referenceID" : 22,
      "context" : "The next lemma establishes that, similar to the classical perceptron Novikoff [1962], PERCEPTRON@K-AVG also enjoys a mistake bound.",
      "startOffset" : 69,
      "endOffset" : 85
    }, {
      "referenceID" : 21,
      "context" : "Similar to the classical perceptron mistake bound Novikoff [1962], the above bound can also be reduced to a simpler convergence bound in separable settings.",
      "startOffset" : 50,
      "endOffset" : 66
    }, {
      "referenceID" : 12,
      "context" : "Hence for several datasets, PERCEPTRON@K-AVG might be able to find a perfect ranking while at the same time, it might be impossible for standard binary classification techniques to find any reasonable classifier in poly-time Guruswami and Raghavendra [2009]. We note that PERCEPTRON@K-AVG performs updates with all the false negatives in the mini-batches.",
      "startOffset" : 225,
      "endOffset" : 258
    }, {
      "referenceID" : 20,
      "context" : "[2014], Narasimhan et al. [2015] who propose to use mini-batch methods to overcome this problem Kar et al.",
      "startOffset" : 8,
      "endOffset" : 33
    }, {
      "referenceID" : 16,
      "context" : "[2015] who propose to use mini-batch methods to overcome this problem Kar et al. [2014]. By combining the ` prec@k(·) surrogate with mini-batch-style processing, we design SGD@K-AVG (Algorithm 3), a scalable SGD algorithm for optimizing prec@k.",
      "startOffset" : 70,
      "endOffset" : 88
    }, {
      "referenceID" : 16,
      "context" : "Recently, Kar et al. [2014] also established a similar result for the `struct prec@k(·) surrogate.",
      "startOffset" : 10,
      "endOffset" : 28
    }, {
      "referenceID" : 14,
      "context" : "Methods: We compared both perceptron algorithms, SGD@K-AVG, as well as an SGD solver for the `max prec@k(·) surrogate, with the cutting plane-based SVMPerf solver of Joachims [2005]. We also compare against stochastic",
      "startOffset" : 166,
      "endOffset" : 182
    }, {
      "referenceID" : 16,
      "context" : "1PMB solver of Kar et al. [2014]. The perceptron and SGD methods were given a maximum of 25 passes over the data with a batch length of 500.",
      "startOffset" : 15,
      "endOffset" : 33
    }, {
      "referenceID" : 30,
      "context" : "This will allow a standard L∞ covering number argument Zhang [2002] to give us the required uniform convergence results.",
      "startOffset" : 55,
      "endOffset" : 68
    }, {
      "referenceID" : 1,
      "context" : "where the third step follows from Bernstein’s inequality (which holds in situations with sampling without replacement as well Boucheron et al. [2004]) since |T(v) · h(v)| ≤ 1 for all v and we have assumed b ≥ 1 κ log 2 δ .",
      "startOffset" : 126,
      "endOffset" : 150
    }, {
      "referenceID" : 16,
      "context" : "The proof of this theorem closely follows that of Theorems 7 and 8 in Kar et al. [2014]. More specifically, Theorem 6 from Kar et al.",
      "startOffset" : 70,
      "endOffset" : 88
    }, {
      "referenceID" : 16,
      "context" : "The proof of this theorem closely follows that of Theorems 7 and 8 in Kar et al. [2014]. More specifically, Theorem 6 from Kar et al. [2014] ensures that any convex loss function demonstrating uniform convergence would ensure a result of the kind we are trying to prove.",
      "startOffset" : 70,
      "endOffset" : 141
    } ],
    "year" : 2015,
    "abstractText" : "The problem of maximizing precision at the top of a ranked list, often dubbed Precision@k (prec@k), finds relevance in myriad learning applications such as ranking, multi-label classification, and learning with severe label imbalance. However, despite its popularity, there exist significant gaps in our understanding of this problem and its associated performance measure. The most notable of these is the lack of a convex upper bounding surrogate for prec@k. We also lack scalable perceptron and stochastic gradient descent algorithms for optimizing this performance measure. In this paper we make key contributions in these directions. At the heart of our results is a family of truly upper bounding surrogates for prec@k. These surrogates are motivated in a principled manner and enjoy attractive properties such as consistency to prec@k under various natural margin/noise conditions. These surrogates are then used to design a class of novel perceptron algorithms for optimizing prec@k with provable mistake bounds. We also devise scalable stochastic gradient descent style methods for this problem with provable convergence bounds. Our proofs rely on novel uniform convergence bounds which require an in-depth analysis of the structural properties of prec@k and its surrogates. We conclude with experimental results comparing our algorithms with state-of-the-art cutting plane and stochastic gradient algorithms for maximizing prec@k.",
    "creator" : "LaTeX with hyperref package"
  }
}