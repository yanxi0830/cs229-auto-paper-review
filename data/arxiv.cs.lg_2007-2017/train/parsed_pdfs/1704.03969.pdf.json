{
  "name" : "1704.03969.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : null,
    "authors" : [ "Shaodan Ma", "Yik-Chung Wu", "Soummya Kar", "José M. F. Moura" ],
    "emails" : [ ],
    "sections" : [ {
      "heading" : null,
      "text" : "ar X\niv :1\n70 4.\n03 96\n9v 1\n[ cs\n.L G\n] 1\n3 A\npr 2\ndistributed estimation in large-scale networks such as the smart grid, communication networks, and social networks, where local measurements/observations are scattered over a wide geographical area. However, the convergence of Gaussian BP is still an open issue. In this paper, we consider the convergence of Gaussian BP, focusing in particular on the convergence of the information matrix. We show analytically that the exchanged message information matrix converges for arbitrary positive semidefinite initial value, and its distance to the unique positive definite limit matrix decreases exponentially fast.\nIndex Terms— graphical model, belief propagation,\nlarge-scale networks, Markov random field."
    }, {
      "heading" : "1. INTRODUCTION",
      "text" : "In large-scale linear parameter estimation with Gaussian measurements, Gaussian Belief Propagation (BP) [1] provides an efficient distributed way to compute the marginal distribution of the unknown variables, and it has been adopted in a variety of topics ranging from distributed power state estimation [2] in smart grid, distributed beamforming [3] and synchronization [4, 5] in wireless communication networks, fast solver for system of linear equations [6], distributed rate control in ad-hoc networks [7], factor analyzer network [8], sparse Bayesian learning [9], to peer-to-peer rating in social networks [10]. It has been shown that Gaussian BP computes the optimal centralized estimator if it converges [11].\nAlthough with great empirical success, the major challenge that hinders Gaussian BP to realize its full potential is the lack of theoretical guarantees of convergence in loopy networks. Sufficient convergence conditions for Gaussian BP have been developed in [1,12–14] when the underlying Gaussian distribution is expressed in terms of pairwise connections between scalar variables (also known as Markov random field (MRF)). These works focus on the convergence analysis\nThis work is partially supported by NSF grant # CCF1513936.\nof Gaussian BP for computing the marginal distribution of a joint distribution with pairwise factors. However, the iterative equations for Gaussian BP on MRFs are different from that for distributed estimation problems such as in [2–9,15], where high order factors (non-pairwise) and vector-valued variables are involved. Therefore, these existing conditions and analysis methods are not applicable to distributed estimation problems. In this paper, we study the convergence analysis of Gaussian BP for distributed parameter estimation focusing on the convergence of message information matrix. We show analytically that, with arbitrary positive semidefinite matrix initialization, the message information matrix being exchanged among nodes converges and its distance to the unique positive definite limit matrix decreases exponentially.\nNote that distributed estimation based on the consensus+ innovations philosophy proposed in [16, 17] (see also the related family of diffusion algorithms [18]) converges to the optimal centralized estimator under the assumption of global observability of the (aggregate) sensing model and connectivity of the inter-agent communication network. In particular, these algorithms allow the communication or message exchange network to be different from the physical coupling network and the former could be arbitrary with cycles (as long as it is connected). The results in [16, 17] imply that the unknown variables x can be reconstructed completely at each node in the network. For large-scale networks with high dimensional x, it may be impractical to reconstruct x at every node. In [19, section 3.4], the author developed approaches to address this problem, where each node can reconstruct a set of unknown variables that should be larger than the set of variables that influence its local measurement. This paper studies a different distributed estimation problem when each node estimates only its own unknown variables under pairwise independence condition of the unknown variables; this leads to lower dimensional data exchanges between neighbors."
    }, {
      "heading" : "2. COMPUTATION MODEL",
      "text" : "Consider a general connected network ofM nodes, with V = {1, . . . ,M} denoting the set of nodes, and ENet ⊂ V × V as\nthe set of all undirect communication links in the network, i.e., if i and j are within the communication range, (i, j) ∈ ENet. At every node n ∈ V , the local observations are in the form of yn = ∑ i∈n∪I(n)An,ixi + zn, where I(n) denotes the set of direct neighbors of node n (i.e., all nodes i with (n, i) ∈ ENet), An,i is a known coefficient matrix with full column rank, xi is the local unknown parameter at node iwith dimension Ni × 1, and with the prior distribution p(xi) ∼ N (xi|0,Wi), and zn is the additive noise with distribution zn ∼ N (zn|0,Rn). It is assumed that p(xi, xj) = p(xi)p(xj) and p(zi, zj) = p(zi)p(zj) for i 6= j. The goal is to estimate xi, based on yn, p(xi) and p(zn).\nThe Gaussian BP algorithm can be derived over the corresponding factor graph to compute the estimate of xn for all n ∈ V [20]. It involves two kinds of messages: One is the message from a variable node xj to its neighboring factor node fn, defined as\nm (ℓ) j→fn (xj) = p(xj) ∏\nfk∈B(j)\\fn\nm (ℓ−1) fk→j (xj), (1)\nwhere B(j) denotes the set of neighbouring factor nodes of xj , andm (ℓ−1) fk→j\n(xj) is the message from fk to xj at time l−1. The second type of message is from a factor node fn to a neighboring variable node xi, defined as\nm (ℓ) fn→i (xi) =\n∫ · · · ∫ fn × ∏\nj∈B(fn)\\i\nm (ℓ) j→fn (xj) d{xj}j∈B(fn)\\i,\n(2)\nwhere B(fn) denotes the set of neighboring variable nodes of fn. The process iterates between equations (1) and (2). At each iteration l, the approximate marginal distribution, also named belief, on xi is computed locally at xi as\nb (ℓ) BP (xi) = p(xi)\n∏\nfn∈B(i)\nm (ℓ) fn→i (xi). (3)\nIt can be shown [20] that the general expression for the\nmessage from variable node to factor node is\nm (ℓ) j→fn (xj) ∝ exp { − 1\n2 ||xj − v\n(ℓ) j→fn || C\n(ℓ) j→fn\n} , (4)\nwhere C (ℓ) j→fn and v (ℓ) j→fn are the message covariance matrix and mean vector received at variable node j at the l-th iteration, with\n[ C\n(ℓ) j→fn ]−1 = W−1j +\n∑\nfk∈B(j)\\fn\n[ C\n(ℓ−1) fk→j\n]−1 . (5)\nFurthermore, the message from factor node to variable node is given by [20]\nm (ℓ) fn→i (xi) ∝ exp { − 1\n2 ||xi − v\n(ℓ) fn→i || C\n(ℓ) fn→i\n} , (6)\nwhere C (ℓ−1) fk→j and v (ℓ−1) fk→j are the message covariance matrix and mean vector received at variable node j at the l− 1 iteration with\n[C (ℓ) fn→i ]−1 =ATn,i [ Rn + ∑\nj∈B(fn)\\i\nAn,jC (ℓ) j→fn ATn,j ]−1 An,i. (7)\nThe following lemma shown in [20] indicates that setting\nthe initial message covariances [C (0) fn→i ]−1 0 for all n, i ∈ V guarantees [C (ℓ) j→fn ]−1 ≻ 0 for l ≥ 1.\nLemma 1. Let the initial messages at factor node fk be in Gaussian function forms with covariance [C (0) fk→j ]−1 0 for all k ∈ V and j ∈ B(fk). Then [C (ℓ) j→fn ]−1 ≻ 0 and [C (ℓ) fk→j ]−1 ≻ 0 for all l ≥ 1 with j ∈ V and fn, fk ∈ B(j). Furthermore, in this case, all the messages m (ℓ) j→fn (xj) and m (ℓ) fk→j (xi) exist and are in Gaussian form.\nFor this factor graph based approach, according to the message updating procedure (4) and (6), message exchange is only needed between neighboring nodes. For example, the messages transmitted from node n to its neighboring node i are m (ℓ) fn→i (xi) and m (ℓ) n→fi\n(xn). Thus, the message passing scheme given in (1) and (2) automatically conforms with the network topology. Furthermore, if the messages m (ℓ) j→fn (xj) and m (ℓ) fn→i\n(xi) exist for all l (which can be achieved using Lemma 1), the messages are Gaussian, therefore only the correspondingmean vectors and informationmatrices (inverse of covariance matrices) are needed to be exchanged.\nFinally, if the BP messages exist, according to the definition of belief in (3), b (ℓ) BP (xi) at iteration l is computed as [20]\nb (ℓ) BP (xi) = p(xi)\n∏\nfn∈B(i)\nm (ℓ) fn→i (xi) ∝ N ( xi|µ (ℓ) i ,P (ℓ) i ) ,\n(8)\nwith P (ℓ) i = [ W−1i + ∑ fn∈B(i) [ C (ℓ) fn→i ]−1]−1 , and µ (ℓ) i = P (ℓ) i [∑ fn∈B(i) [ C (ℓ) fn→i ]−1 v (ℓ) fn→i ] . The iterative computation terminates when message (4) or message (6) converges to a fixed value or the maximum number of iterations is reached."
    }, {
      "heading" : "3. CONVERGENCE OF INFORMATION MATRICES",
      "text" : "The challenge of deploying the BP algorithm for large-scale networks is determining whether it will converge. In particular, it is generally known that if the factor graph contains cycles, the BP algorithm may diverge. Thus, determining convergence conditions for the BP algorithm is very important. Sufficient conditions for the convergence of Gaussian BP with scalar variable in loopy graphs are available in [1, 12, 14]. However, they are derived based on pairwise graphs with local functions that only involve two variables. This is in sharp\ncontrast to the model considered in this paper, where the fn involves high-order interactions between vector variables, and thus the convergence results in [1,12,14] cannot be applied to the factor graph based vector-form Gaussian BP.\nDue to the recursively updating property of m (ℓ) j→fn (xj)\nand m (ℓ) fn→i\n(xi) in (4) and (6), the message evolution can be simplified by combining these two kinds of messages into one. By substituting [ C\n(ℓ) j→fn\n]−1 in (5) into (7), the updat-\ning of the message covariancematrix inverse, named message information matrix in the following, can be denoted as\n[ C\n(ℓ) fn→i ]−1 =ATn,i [ Rn + ∑\nj∈B(fn)\\i\nAn,j [ W−1j\n+ ∑\nfk∈B(j)\\fn\n[ C\n(ℓ−1) fk→j ]−1]−1 ATn,j ]−1 An,i\n,Fn→i ( { [ C\n(ℓ−1) fk→j ]−1 }(fk,j)∈B̃(fn,i) ) ,\nwhere B̃(fn, i) = {(fk, j)|j ∈ B(fn)\\i, fk ∈ B(j)\\fn}. Observing that C (ℓ) fn→i in (9) is independent of v (ℓ) j→fn and v (ℓ) fn→i in (4) and (6), we can focus on the convergence property of [C (ℓ) fn→i\n]−1 alone. To consider the updates of all message information matrices, we introduce the following definitions. Let C(ℓ−1) , Bdiag({[C (ℓ−1) fn→i\n]−1}n∈V,i∈B(fn)) be a block diagonal matrix with diagonal blocks being the message information matrices in the network at time l − 1 with index arranged in ascending order first on n and then on i. Using the definition of C(ℓ−1), the term ∑\nfk∈B(j)\\fn [C (ℓ−1) fk→j ]−1 in (9)\ncan be written as Ξn,jC (ℓ−1) Ξ T n,j , where Ξn,j is for selecting appropriate components from C(ℓ−1) to form the summation. Further, define Hn,i = [{An,j}j∈B(fn)\\i], Ψn,i = Bdiag({W−1j }j∈B(fn)\\i) andKn,i=Bdiag({Ξn,j}j∈B(fn)\\i), all with component blocks arranged with ascending order on j. Then (9) can be written as\n[C (ℓ) fn→i ]−1 =ATn,i { Rn +Hn,i[Ψn,i +Kn,i(I|B(fn)|−1\n⊗ C(ℓ−1))KTn,i] −1HTn,i }−1 An,i.\n(9)\nNow, we define the functionF , {F1→k, . . . ,Fn→i, . . . , Fn→M} that satisfies C (ℓ) = F(C(ℓ−1)). Then, by stacking[\nC (ℓ) fn→i\n]−1 on the left side of (9) for all n and i as the block\ndiagonal matrix C(ℓ), we obtain\nC(ℓ) = AT { Ω+H[Ψ+K(Iϕ ⊗ C (ℓ−1))KT ]−1HT }−1 A,\n, F(C(ℓ−1)), (10)\nwhere A, H, Ψ, and K are block diagonal matrices with block elements An,i, Hn,i, Ψn,i, and Kn,i, respectively, arranged in ascending order, first on n and then on i (i.e., the same order as [C (ℓ) fn→i ]−1 in C(ℓ)). Furthermore, ϕ =\n∑M n=1 |B(fn)|(|B(fn)| − 1) and Ω is a block diagonal matrix with diagonal blocks I|B(fn)| ⊗ Rn with ascending order on n. We first present properties of the updating operator F(·), with the proof given in [20].\nProperty 1. The updating operator F(·) satisfies the following properties:\nP 1.1: F(C(ℓ)) F(C(ℓ−1)), if C(ℓ) C(ℓ−1) 0. P 1.2: αF(C(ℓ)) ≻ F(αC(ℓ)) andF(α−1C(ℓ)) ≻ α−1F(C(ℓ)), if C(ℓ) ≻ 0 and α > 1. P 1.3: DefineU , ATΩ−1A andL , AT [ Ω+HΨ−1HT ]−1 A.\nWith arbitrary C(0) 0, F(C(ℓ)) is bounded by U F(C(ℓ)) L ≻ 0 for l ≥ 1. In this paper, X Y (X ≻ Y) means that X− Y is positive semidefinite (definite). Based on the above properties of F(·), we can establish the convergence property for the information matrices. The following theorem establishes that there exists a unique fixed point for the mappingF(·). The proof is omitted due to space restrictions; it is provided in [20].\nTheorem 1. With C(0) 0, there exists a unique positive definite fixed point for the mapping F(·).\nLemma 1 states that with arbitrary positive semidefinite (p.s.d.) initial message information matrices, the message information matrices will be kept as positive definite (p.d.) at every iteration. On the other hand, Theorem 1 indicates that there exists a unique fixed point for the mapping F . Next, we will show that with arbitrary initial value C(0) 0, C(ℓ) converges to a unique p.d. matrix.\nTheorem 2. The matrix sequence {C(ℓ)}l=0,1,... defined by (10) converges to a unique positive definite matrix for any initial covariance matrix C(0) 0.\nProof. With arbitrary initial value C(0) 0, following P 1.3, we have U C(1) L ≻ 0. On the other hand, according to Theorem 1, (10) has a unique fixed point C∗ ≻ 0. Notice that we can always choose a scalar α > 1 such that\nαC∗ C(1) L. (11)\nApplying F(·) to (11) l times, and using P 1.1, we have\nF l(αC∗) F l+1(C(0)) F l(L), (12)\nwhere F l(X) denotes applying F on X for l times. We start from the left inequality in (12). Following the fixed point definition, αC∗ = αF(C∗). Then, according to P 1.2, αC∗ ≻ F(αC∗). Applying F again gives F(αC∗) ≻ F2(αC∗). Applying F(·) repeatedly, we can obtain F2(αC∗) ≻ F3(αC∗) ≻ F4(αC∗), etc. Thus F l(αC∗) is a decreasing sequence with respect to the partial order induced by the cone of p.s.d. matrices as l increases. Furthermore,\nsince F(·) is bounded below by L, F l(αC∗) is convergent. Finally, since there exists only one fixed point for F(·), liml→∞ F l(αC\n∗) = C∗. On the other hand, for the right hand side of (12), as F(·) L, we have F(L) L. Applying F repeatedly gives F2(L) F(L), F3(L) F2(L), etc. So, F l(L) is an increasing sequence (with respect to the partial order induced by the cone of p.s.d. matrices). Since F(·) is upper bounded by U, F l(L) is a convergent sequence. Again due to the unique fixed point, we have liml→∞ F l(L) = C ∗. Finally, taking the limit with respect to l on (12) we have liml→∞ F l(C (0)) = C∗, for arbitrary initial C(0) 0.\nAccording to Theorem 2, the covariance matrix C (ℓ) fn→i converges if all initial information matrices are p.s.d., i.e.,[ C\n(0) fn→i ]−1 0 for all i ∈ V and fn ∈ B(i). Notice that, for the pairwise model, the information matrix does not necessarily converge for all initial non-negative value (in the scalar variable case) as shown in [12,13]. Moreover, due to the computation of [C (ℓ) fn→i\n]−1 being independent of the local observations yn, as long as the network topology does not change, the converged value [C∗fn→i] −1 can be precomputed offline and stored at each node, and there is no need to re-compute [C∗fn→i] −1 even if yn varies.\nAnother fundamental question is how fast the convergence is, and this is the focus of the discussion below. Since the convergence of a dynamic system is often studied with the part metric [21], in the following, we start by introducing the part metric.\nDefinition 1. Part (Birkhoff) Metric [21]: For arbitrary matrices X and Y with the same dimension, if there exists α ≥ 1 such that αX Y α−1X, X and Y are called the parts, and d(X,Y) , inf{logα : αX Y α−1X, α ≥ 1} defines a metric called the part metric.\nNext, we will show that {C(ℓ)}l=1,.. converges at a geometric rate with respect to the part metric in C, which is constructed as\nC = {C(ℓ)|U C(ℓ) C∗+ǫI}∪{C(ℓ)|C∗−ǫI C(ℓ) L},\nwhere ǫ > 0 is a scalar and can be arbitrarily small.\nTheorem 3. With the initial covariance matrix set to be an arbitrary p.s.d. matrix, i.e., [C (0) fn→i ]−1 0, the sequence {C(ℓ)}l=0,1,... converges at a geometric rate with respect to the part metric in C.\nProof. Consider two matrices C(ℓ) ∈ C, and C∗ 6∈ C, according to Definition 1, we have d(C(ℓ),C∗) , inf{logα : αC(ℓ) C∗ α−1C(ℓ)}. Since d(C(ℓ),C∗) is the smallest number satisfying αC(ℓ) C∗ α−1C(ℓ), this is equivalent to\nexp{d(C(ℓ),C∗)}C(ℓ) C∗ exp{−d(C(ℓ),C∗)}C(ℓ). (13)\nApplying P 1.1 to (13), we have exp{d(C(ℓ),C∗)}F(C(ℓ) F(C∗) exp{−d(C(ℓ),C∗)}F(C(ℓ)). Then applying P 1.2 and considering that exp{d(C(ℓ),C∗)} > 1 and exp{−d(C(ℓ),C∗)} < 1, we obtain\nexp{d(C(ℓ),C∗)}F(C(ℓ)) ≻ F(C∗) ≻ exp{−d(C(ℓ),C∗)}F(C(ℓ)). (14)\nNotice that, for arbitrary p.d. matricesX andY, ifX−kY ≻ 0 then, by definition that, we have xTXx − kxTYx > 0. Then there must exist o > 0 that is small enough such that xTXx− (k + o)xTYx > 0 or equivalently X ≻ (k + o)Y. Thus, as exp (·) is a continuous function, there must exist some△d > 0 such that\nexp{−△d + d(C(ℓ),C∗)}F(C(ℓ)) ≻ F(C∗) ≻ exp{△d− d(C(ℓ),C∗)}F(C(ℓ)). (15)\nNow, using the definition of part metric, (15) is equivalent to\n−△d + d(C(ℓ),C∗) ≥ d(F(C(ℓ)),F(C∗)). (16)\nHence, we obtain d(F(C(ℓ)),F(C∗)) < d(C(ℓ),C∗). This result holds for anyC(ℓ) ∈ C, d(F(C(ℓ)),F(C∗)) < cd(C(ℓ),C∗), where c = supCl∈C d(F(Cl),F(C∗)) d(Cl,C∗) < 1. Consequently, we have d(C(ℓ),C∗) < cld(C(0),C∗). Thus the sequence {C(ℓ)}l=1,... converges at a geometric rate with respect to the part metric.\nIt is useful to have an estimate of the convergence rate of C(ℓ) in terms of the more standard inducedmatrix norms. According to [22, Lemma 2.3], the convergence rate of ||C(0) − C∗|| is dominated by that of d(C(0),C∗), where || · || is a monotone norm defined on the p.s.d. cone, with || · ||2 and || · ||F being examples of such matrix norms [23, 2.2-10]. More specifically,\n(2 exp{d(C(ℓ),C∗)} − exp{−d(C(ℓ),C∗)} − 1)\n×min{||C(ℓ)||, ||C∗||} ≥ ||C(ℓ) − C∗||. (17)\nThe physical meaning of Theorem 3 is that the sequence {C(ℓ)}l=1,... converges at a geometric rate (the distance between C(ℓ) and C∗ decreases exponentially) before C(ℓ) enters C∗’s neighborhood, which can be chosen arbitrarily small."
    }, {
      "heading" : "4. CONCLUSION",
      "text" : "This paper has established the convergence of the exchanged message information matrix of Gaussian belief propagation (BP) for distributed estimation. We have shown analytically that, with arbitrary positive semidefinite initial value, the information matrix converges to a unique positive definite matrix at geometric rate. The convergence guaranteed property and fast convergence rate of the message information matrix pave the way for the convergence analysis of the Gaussian BP message mean vector."
    }, {
      "heading" : "5. REFERENCES",
      "text" : "[1] Y. Weiss and W. T. Freeman, “Correctness of belief\npropagation in Gaussian graphical models of arbitrary topology,” Neural Computation, vol. 13, no. 10, pp. 2173–2200, Mar. 2001.\n[2] Y. Hu, A. Kuh, T. Yang, and A. Kavcic, “A belief propa-\ngation based power distribution system state estimator,” IEEE Comput. Intell. Mag., vol. 6, no. 3, pp. 36–46, Aug 2011.\n[3] B. L. Ng, J. Evans, S. Hanly, and D. Aktas, “Distributed\ndownlink beamforming with cooperative base stations,” IEEE Trans. Inf. Theory, vol. 54, no. 12, pp. 5491–5499, Dec 2008.\n[4] J. Du and Y.-C. Wu, “Distributed clock skew and offset\nestimation in wireless sensor networks: Asynchronous algorithm and convergence analysis,” IEEE Trans. Wireless Commun., vol. 12, no. 11, pp. 5908–5917, Nov 2013.\n[5] ——, “Network-wide distributed carrier frequency off-\nsets estimation and compensation via belief propagation,” IEEE Trans. Signal Process., vol. 61, no. 23, pp. 5868–5877, 2013.\n[6] O. Shental, P. Siegel, J. Wolf, D. Bickson, and D. Dolev,\n“Gaussian belief propagation solver for systems of linear equations,” in 2008 IEEE International Symposium on Information Theory (ISIT 2008), July 2008, pp. 1863–1867.\n[7] G. Zhang, W. Xu, and Y. Wang, “Fast distributed\nrate control algorithm with QoS support in ad-hoc,” in 2010 IEEE Global Telecommunications Conference (GLOBECOM 2010).\n[8] B. J. Frey, “Local probability propagation for factor\nanalysis,” in Neural Information Processing Systems (NIPS), Dec 1999, pp. 442–448.\n[9] X. Tan and J. Li, “Computationally efficient sparse\nBayesian learning via belief propagation,” IEEE Trans. Signal Process., vol. 58, no. 4, pp. 2010–2021, April 2010.\n[10] D. Bickson and D. Malkhi, “A unifying framework for\nrating users and data items in peer-to-peer and social networks,” Peer-to-Peer Networking and Applications (PPNA) Journal, vol. 1, no. 2, pp. 93–103, 2008.\n[11] Y. Weiss and W. Freeman, “On the optimality of solu-\ntions of the max-product belief-propagation algorithm in arbitrary graphs,” IEEE Trans. Inf. Theory, vol. 47, no. 2, pp. 736–744, Feb. 2001.\n[12] D. M. Malioutov, J. K. Johnson, and A. S. Willsky,\n“Walk-sums and belief propagation in Gaussian graphical models,” Journal of Machine Learning Research, vol. 7, no. 2, pp. 2031–2064, Feb. 2006.\n[13] C. C. Moallemi and B. V. Roy, “Convergence of min-\nsum message passing for quadratic optimization,” IEEE Trans. Inf. Theory, vol. 55, no. 5, pp. 2413–2423, 2009.\n[14] Q. Su and Y.-C. Wu, “On convergence conditions of\nGaussian belief propagation,” IEEE Trans. Signal Process., vol. 63, no. 5, pp. 1144–1155, March 2015.\n[15] F. Lehmann, “Iterative mitigation of intercell interfer-\nence in cellular networks based on Gaussian belief propagation,” IEEE Trans. Veh. Technol., vol. 61, no. 6, pp. 2544–2558, July 2012.\n[16] S. Kar and J. M. F. Moura, “Consensus+innovations dis-\ntributed inference over networks: cooperation and sensing in networked systems,” IEEE Signal Process. Mag., vol. 30, no. 3, pp. 99–109, 2013.\n[17] S. Kar, J. M. F. Moura, and H. Poor, “Distributed linear\nparameter estimation: asymptotically efficient adaptive strategies,” SIAM Journal on Control and Optimization, vol. 51, no. 3, pp. 2200–2229, 2013.\n[18] F. S. Cattivelli and A. H. Sayed, “Diffusion LMS strate-\ngies for distributed estimation,” IEEE Trans. Signal Process., vol. 58, no. 3, pp. 1035–1048, 2010.\n[19] S. Kar, “Large scale networked dynamical systems: Dis-\ntributed inference,” Ph.D. dissertation, Carnegie Mellon University, Pittsburgh, PA, Department of Electrical and Computer Engineering, June 2010.\n[20] J. Du, S. Ma, Y.-C. Wu, S. Kar, and J. M. F.\nMoura, “Convergence analysis of distributed inference with vector-valued Gaussian belief propagation,” submitted to Journal of Machine Learning Research [Preprint Available]: https://users.ece.cmu.edu/∼soummyak/GBP convergence.\n[21] I. Chueshov, Monotone Random Systems Theory and\nApplications. New York: Springer, 2002.\n[22] U. Krause and R. Nussbaum, “A limit set trichotomy\nfor self-mappings of normal cones in Banach spaces,” Nonlinear Analysis, Theory, Methods&Applications, vol. 20, no. 7, pp. 855–870, 1993.\n[23] P. G. Ciarlet, Introduction to Numerical Linear Algebra\nand Optimisation. Cambridge University Press, 1989."
    } ],
    "references" : [ {
      "title" : "Correctness of belief propagation in Gaussian graphical models of arbitrary topology",
      "author" : [ "Y. Weiss", "W.T. Freeman" ],
      "venue" : "Neural Computation, vol. 13, no. 10, pp. 2173–2200, Mar. 2001.",
      "citeRegEx" : "1",
      "shortCiteRegEx" : null,
      "year" : 2001
    }, {
      "title" : "A belief propagation based power distribution system state estimator",
      "author" : [ "Y. Hu", "A. Kuh", "T. Yang", "A. Kavcic" ],
      "venue" : "IEEE Comput. Intell. Mag., vol. 6, no. 3, pp. 36–46, Aug 2011.",
      "citeRegEx" : "2",
      "shortCiteRegEx" : null,
      "year" : 2011
    }, {
      "title" : "Distributed downlink beamforming with cooperative base stations",
      "author" : [ "B.L. Ng", "J. Evans", "S. Hanly", "D. Aktas" ],
      "venue" : "IEEE Trans. Inf. Theory, vol. 54, no. 12, pp. 5491–5499, Dec 2008.",
      "citeRegEx" : "3",
      "shortCiteRegEx" : null,
      "year" : 2008
    }, {
      "title" : "Distributed clock skew and offset estimation in wireless sensor networks: Asynchronous algorithm and convergence analysis",
      "author" : [ "J. Du", "Y.-C. Wu" ],
      "venue" : "IEEE Trans. Wireless Commun., vol. 12, no. 11, pp. 5908–5917, Nov 2013.",
      "citeRegEx" : "4",
      "shortCiteRegEx" : null,
      "year" : 2013
    }, {
      "title" : "Network-wide distributed carrier frequency offsets estimation and compensation via belief propagation",
      "author" : [ "——" ],
      "venue" : "IEEE Trans. Signal Process., vol. 61, no. 23, pp. 5868–5877, 2013.",
      "citeRegEx" : "5",
      "shortCiteRegEx" : null,
      "year" : 2013
    }, {
      "title" : "Gaussian belief propagation solver for systems of linear equations",
      "author" : [ "O. Shental", "P. Siegel", "J. Wolf", "D. Bickson", "D. Dolev" ],
      "venue" : "2008 IEEE International Symposium on Information Theory (ISIT 2008), July 2008, pp. 1863–1867.",
      "citeRegEx" : "6",
      "shortCiteRegEx" : null,
      "year" : 2008
    }, {
      "title" : "Fast distributed rate control algorithm with QoS support in ad-hoc",
      "author" : [ "G. Zhang", "W. Xu", "Y. Wang" ],
      "venue" : "2010 IEEE Global Telecommunications Conference (GLOBECOM 2010).",
      "citeRegEx" : "7",
      "shortCiteRegEx" : null,
      "year" : 2010
    }, {
      "title" : "Local probability propagation for factor analysis",
      "author" : [ "B.J. Frey" ],
      "venue" : "Neural Information Processing Systems (NIPS), Dec 1999, pp. 442–448.",
      "citeRegEx" : "8",
      "shortCiteRegEx" : null,
      "year" : 1999
    }, {
      "title" : "Computationally efficient sparse Bayesian learning via belief propagation",
      "author" : [ "X. Tan", "J. Li" ],
      "venue" : "IEEE Trans. Signal Process., vol. 58, no. 4, pp. 2010–2021, April 2010.",
      "citeRegEx" : "9",
      "shortCiteRegEx" : null,
      "year" : 2010
    }, {
      "title" : "A unifying framework for rating users and data items in peer-to-peer and social networks",
      "author" : [ "D. Bickson", "D. Malkhi" ],
      "venue" : "Peer-to-Peer Networking and Applications (PPNA) Journal, vol. 1, no. 2, pp. 93–103, 2008.",
      "citeRegEx" : "10",
      "shortCiteRegEx" : null,
      "year" : 2008
    }, {
      "title" : "On the optimality of solutions of the max-product belief-propagation algorithm in arbitrary graphs",
      "author" : [ "Y. Weiss", "W. Freeman" ],
      "venue" : "IEEE Trans. Inf. Theory, vol. 47, no. 2, pp. 736–744, Feb. 2001.",
      "citeRegEx" : "11",
      "shortCiteRegEx" : null,
      "year" : 2001
    }, {
      "title" : "Walk-sums and belief propagation in Gaussian graphical models",
      "author" : [ "D.M. Malioutov", "J.K. Johnson", "A.S. Willsky" ],
      "venue" : "Journal of Machine Learning Research, vol. 7, no. 2, pp. 2031–2064, Feb. 2006.",
      "citeRegEx" : "12",
      "shortCiteRegEx" : null,
      "year" : 2006
    }, {
      "title" : "Convergence of minsum message passing for quadratic optimization",
      "author" : [ "C.C. Moallemi", "B.V. Roy" ],
      "venue" : "IEEE Trans. Inf. Theory, vol. 55, no. 5, pp. 2413–2423, 2009.",
      "citeRegEx" : "13",
      "shortCiteRegEx" : null,
      "year" : 2009
    }, {
      "title" : "On convergence conditions of Gaussian belief propagation",
      "author" : [ "Q. Su", "Y.-C. Wu" ],
      "venue" : "IEEE Trans. Signal Process., vol. 63, no. 5, pp. 1144–1155, March 2015.",
      "citeRegEx" : "14",
      "shortCiteRegEx" : null,
      "year" : 2015
    }, {
      "title" : "Iterative mitigation of intercell interference in cellular networks based on Gaussian belief propagation",
      "author" : [ "F. Lehmann" ],
      "venue" : "IEEE Trans. Veh. Technol., vol. 61, no. 6, pp. 2544–2558, July 2012.",
      "citeRegEx" : "15",
      "shortCiteRegEx" : null,
      "year" : 2012
    }, {
      "title" : "Consensus+innovations distributed inference over networks: cooperation and sensing in networked systems",
      "author" : [ "S. Kar", "J.M.F. Moura" ],
      "venue" : "IEEE Signal Process. Mag., vol. 30, no. 3, pp. 99–109, 2013.",
      "citeRegEx" : "16",
      "shortCiteRegEx" : null,
      "year" : 2013
    }, {
      "title" : "Distributed linear parameter estimation: asymptotically efficient adaptive strategies",
      "author" : [ "S. Kar", "J.M.F. Moura", "H. Poor" ],
      "venue" : "SIAM Journal on Control and Optimization, vol. 51, no. 3, pp. 2200–2229, 2013.",
      "citeRegEx" : "17",
      "shortCiteRegEx" : null,
      "year" : 2013
    }, {
      "title" : "Diffusion LMS strategies for distributed estimation",
      "author" : [ "F.S. Cattivelli", "A.H. Sayed" ],
      "venue" : "IEEE Trans. Signal Process., vol. 58, no. 3, pp. 1035–1048, 2010.",
      "citeRegEx" : "18",
      "shortCiteRegEx" : null,
      "year" : 2010
    }, {
      "title" : "Large scale networked dynamical systems: Distributed inference",
      "author" : [ "S. Kar" ],
      "venue" : "Ph.D. dissertation, Carnegie Mellon University, Pittsburgh, PA, Department of Electrical and Computer Engineering, June 2010.",
      "citeRegEx" : "19",
      "shortCiteRegEx" : null,
      "year" : 2010
    }, {
      "title" : "Convergence analysis of distributed inference with vector-valued Gaussian belief propagation",
      "author" : [ "J. Du", "S. Ma", "Y.-C. Wu", "S. Kar", "J.M.F. Moura" ],
      "venue" : "submitted to Journal of Machine Learning Research [Preprint Available]: https://users.ece.cmu.edu/∼soummyak/GBP convergence.",
      "citeRegEx" : "20",
      "shortCiteRegEx" : null,
      "year" : 0
    }, {
      "title" : "Monotone Random Systems Theory and Applications",
      "author" : [ "I. Chueshov" ],
      "venue" : "New York: Springer,",
      "citeRegEx" : "21",
      "shortCiteRegEx" : "21",
      "year" : 2002
    }, {
      "title" : "A limit set trichotomy for self-mappings of normal cones in Banach spaces",
      "author" : [ "U. Krause", "R. Nussbaum" ],
      "venue" : "Nonlinear Analysis, Theory, Methods&Applications, vol. 20, no. 7, pp. 855–870, 1993.",
      "citeRegEx" : "22",
      "shortCiteRegEx" : null,
      "year" : 1993
    }, {
      "title" : "Introduction to Numerical Linear Algebra and Optimisation",
      "author" : [ "P.G. Ciarlet" ],
      "venue" : null,
      "citeRegEx" : "23",
      "shortCiteRegEx" : "23",
      "year" : 1989
    } ],
    "referenceMentions" : [ {
      "referenceID" : 0,
      "context" : "In large-scale linear parameter estimation with Gaussian measurements, Gaussian Belief Propagation (BP) [1] provides an efficient distributed way to compute the marginal distribution of the unknown variables, and it has been adopted in a variety of topics ranging from distributed power state estimation [2] in smart grid, distributed beamforming [3] and synchronization [4, 5] in wireless communication networks, fast solver for system of linear equations [6], distributed rate control in ad-hoc networks [7], factor analyzer network [8], sparse Bayesian learning [9], to peer-to-peer rating in social networks [10].",
      "startOffset" : 104,
      "endOffset" : 107
    }, {
      "referenceID" : 1,
      "context" : "In large-scale linear parameter estimation with Gaussian measurements, Gaussian Belief Propagation (BP) [1] provides an efficient distributed way to compute the marginal distribution of the unknown variables, and it has been adopted in a variety of topics ranging from distributed power state estimation [2] in smart grid, distributed beamforming [3] and synchronization [4, 5] in wireless communication networks, fast solver for system of linear equations [6], distributed rate control in ad-hoc networks [7], factor analyzer network [8], sparse Bayesian learning [9], to peer-to-peer rating in social networks [10].",
      "startOffset" : 304,
      "endOffset" : 307
    }, {
      "referenceID" : 2,
      "context" : "In large-scale linear parameter estimation with Gaussian measurements, Gaussian Belief Propagation (BP) [1] provides an efficient distributed way to compute the marginal distribution of the unknown variables, and it has been adopted in a variety of topics ranging from distributed power state estimation [2] in smart grid, distributed beamforming [3] and synchronization [4, 5] in wireless communication networks, fast solver for system of linear equations [6], distributed rate control in ad-hoc networks [7], factor analyzer network [8], sparse Bayesian learning [9], to peer-to-peer rating in social networks [10].",
      "startOffset" : 347,
      "endOffset" : 350
    }, {
      "referenceID" : 3,
      "context" : "In large-scale linear parameter estimation with Gaussian measurements, Gaussian Belief Propagation (BP) [1] provides an efficient distributed way to compute the marginal distribution of the unknown variables, and it has been adopted in a variety of topics ranging from distributed power state estimation [2] in smart grid, distributed beamforming [3] and synchronization [4, 5] in wireless communication networks, fast solver for system of linear equations [6], distributed rate control in ad-hoc networks [7], factor analyzer network [8], sparse Bayesian learning [9], to peer-to-peer rating in social networks [10].",
      "startOffset" : 371,
      "endOffset" : 377
    }, {
      "referenceID" : 4,
      "context" : "In large-scale linear parameter estimation with Gaussian measurements, Gaussian Belief Propagation (BP) [1] provides an efficient distributed way to compute the marginal distribution of the unknown variables, and it has been adopted in a variety of topics ranging from distributed power state estimation [2] in smart grid, distributed beamforming [3] and synchronization [4, 5] in wireless communication networks, fast solver for system of linear equations [6], distributed rate control in ad-hoc networks [7], factor analyzer network [8], sparse Bayesian learning [9], to peer-to-peer rating in social networks [10].",
      "startOffset" : 371,
      "endOffset" : 377
    }, {
      "referenceID" : 5,
      "context" : "In large-scale linear parameter estimation with Gaussian measurements, Gaussian Belief Propagation (BP) [1] provides an efficient distributed way to compute the marginal distribution of the unknown variables, and it has been adopted in a variety of topics ranging from distributed power state estimation [2] in smart grid, distributed beamforming [3] and synchronization [4, 5] in wireless communication networks, fast solver for system of linear equations [6], distributed rate control in ad-hoc networks [7], factor analyzer network [8], sparse Bayesian learning [9], to peer-to-peer rating in social networks [10].",
      "startOffset" : 457,
      "endOffset" : 460
    }, {
      "referenceID" : 6,
      "context" : "In large-scale linear parameter estimation with Gaussian measurements, Gaussian Belief Propagation (BP) [1] provides an efficient distributed way to compute the marginal distribution of the unknown variables, and it has been adopted in a variety of topics ranging from distributed power state estimation [2] in smart grid, distributed beamforming [3] and synchronization [4, 5] in wireless communication networks, fast solver for system of linear equations [6], distributed rate control in ad-hoc networks [7], factor analyzer network [8], sparse Bayesian learning [9], to peer-to-peer rating in social networks [10].",
      "startOffset" : 506,
      "endOffset" : 509
    }, {
      "referenceID" : 7,
      "context" : "In large-scale linear parameter estimation with Gaussian measurements, Gaussian Belief Propagation (BP) [1] provides an efficient distributed way to compute the marginal distribution of the unknown variables, and it has been adopted in a variety of topics ranging from distributed power state estimation [2] in smart grid, distributed beamforming [3] and synchronization [4, 5] in wireless communication networks, fast solver for system of linear equations [6], distributed rate control in ad-hoc networks [7], factor analyzer network [8], sparse Bayesian learning [9], to peer-to-peer rating in social networks [10].",
      "startOffset" : 535,
      "endOffset" : 538
    }, {
      "referenceID" : 8,
      "context" : "In large-scale linear parameter estimation with Gaussian measurements, Gaussian Belief Propagation (BP) [1] provides an efficient distributed way to compute the marginal distribution of the unknown variables, and it has been adopted in a variety of topics ranging from distributed power state estimation [2] in smart grid, distributed beamforming [3] and synchronization [4, 5] in wireless communication networks, fast solver for system of linear equations [6], distributed rate control in ad-hoc networks [7], factor analyzer network [8], sparse Bayesian learning [9], to peer-to-peer rating in social networks [10].",
      "startOffset" : 565,
      "endOffset" : 568
    }, {
      "referenceID" : 9,
      "context" : "In large-scale linear parameter estimation with Gaussian measurements, Gaussian Belief Propagation (BP) [1] provides an efficient distributed way to compute the marginal distribution of the unknown variables, and it has been adopted in a variety of topics ranging from distributed power state estimation [2] in smart grid, distributed beamforming [3] and synchronization [4, 5] in wireless communication networks, fast solver for system of linear equations [6], distributed rate control in ad-hoc networks [7], factor analyzer network [8], sparse Bayesian learning [9], to peer-to-peer rating in social networks [10].",
      "startOffset" : 612,
      "endOffset" : 616
    }, {
      "referenceID" : 10,
      "context" : "It has been shown that Gaussian BP computes the optimal centralized estimator if it converges [11].",
      "startOffset" : 94,
      "endOffset" : 98
    }, {
      "referenceID" : 0,
      "context" : "Sufficient convergence conditions for Gaussian BP have been developed in [1,12–14] when the underlying Gaussian distribution is expressed in terms of pairwise connections between scalar variables (also known as Markov random field (MRF)).",
      "startOffset" : 73,
      "endOffset" : 82
    }, {
      "referenceID" : 11,
      "context" : "Sufficient convergence conditions for Gaussian BP have been developed in [1,12–14] when the underlying Gaussian distribution is expressed in terms of pairwise connections between scalar variables (also known as Markov random field (MRF)).",
      "startOffset" : 73,
      "endOffset" : 82
    }, {
      "referenceID" : 12,
      "context" : "Sufficient convergence conditions for Gaussian BP have been developed in [1,12–14] when the underlying Gaussian distribution is expressed in terms of pairwise connections between scalar variables (also known as Markov random field (MRF)).",
      "startOffset" : 73,
      "endOffset" : 82
    }, {
      "referenceID" : 13,
      "context" : "Sufficient convergence conditions for Gaussian BP have been developed in [1,12–14] when the underlying Gaussian distribution is expressed in terms of pairwise connections between scalar variables (also known as Markov random field (MRF)).",
      "startOffset" : 73,
      "endOffset" : 82
    }, {
      "referenceID" : 1,
      "context" : "However, the iterative equations for Gaussian BP on MRFs are different from that for distributed estimation problems such as in [2–9,15], where high order factors (non-pairwise) and vector-valued variables are involved.",
      "startOffset" : 128,
      "endOffset" : 136
    }, {
      "referenceID" : 2,
      "context" : "However, the iterative equations for Gaussian BP on MRFs are different from that for distributed estimation problems such as in [2–9,15], where high order factors (non-pairwise) and vector-valued variables are involved.",
      "startOffset" : 128,
      "endOffset" : 136
    }, {
      "referenceID" : 3,
      "context" : "However, the iterative equations for Gaussian BP on MRFs are different from that for distributed estimation problems such as in [2–9,15], where high order factors (non-pairwise) and vector-valued variables are involved.",
      "startOffset" : 128,
      "endOffset" : 136
    }, {
      "referenceID" : 4,
      "context" : "However, the iterative equations for Gaussian BP on MRFs are different from that for distributed estimation problems such as in [2–9,15], where high order factors (non-pairwise) and vector-valued variables are involved.",
      "startOffset" : 128,
      "endOffset" : 136
    }, {
      "referenceID" : 5,
      "context" : "However, the iterative equations for Gaussian BP on MRFs are different from that for distributed estimation problems such as in [2–9,15], where high order factors (non-pairwise) and vector-valued variables are involved.",
      "startOffset" : 128,
      "endOffset" : 136
    }, {
      "referenceID" : 6,
      "context" : "However, the iterative equations for Gaussian BP on MRFs are different from that for distributed estimation problems such as in [2–9,15], where high order factors (non-pairwise) and vector-valued variables are involved.",
      "startOffset" : 128,
      "endOffset" : 136
    }, {
      "referenceID" : 7,
      "context" : "However, the iterative equations for Gaussian BP on MRFs are different from that for distributed estimation problems such as in [2–9,15], where high order factors (non-pairwise) and vector-valued variables are involved.",
      "startOffset" : 128,
      "endOffset" : 136
    }, {
      "referenceID" : 8,
      "context" : "However, the iterative equations for Gaussian BP on MRFs are different from that for distributed estimation problems such as in [2–9,15], where high order factors (non-pairwise) and vector-valued variables are involved.",
      "startOffset" : 128,
      "endOffset" : 136
    }, {
      "referenceID" : 14,
      "context" : "However, the iterative equations for Gaussian BP on MRFs are different from that for distributed estimation problems such as in [2–9,15], where high order factors (non-pairwise) and vector-valued variables are involved.",
      "startOffset" : 128,
      "endOffset" : 136
    }, {
      "referenceID" : 15,
      "context" : "Note that distributed estimation based on the consensus+ innovations philosophy proposed in [16, 17] (see also the related family of diffusion algorithms [18]) converges to the optimal centralized estimator under the assumption of global observability of the (aggregate) sensing model and connectivity of the inter-agent communication network.",
      "startOffset" : 92,
      "endOffset" : 100
    }, {
      "referenceID" : 16,
      "context" : "Note that distributed estimation based on the consensus+ innovations philosophy proposed in [16, 17] (see also the related family of diffusion algorithms [18]) converges to the optimal centralized estimator under the assumption of global observability of the (aggregate) sensing model and connectivity of the inter-agent communication network.",
      "startOffset" : 92,
      "endOffset" : 100
    }, {
      "referenceID" : 17,
      "context" : "Note that distributed estimation based on the consensus+ innovations philosophy proposed in [16, 17] (see also the related family of diffusion algorithms [18]) converges to the optimal centralized estimator under the assumption of global observability of the (aggregate) sensing model and connectivity of the inter-agent communication network.",
      "startOffset" : 154,
      "endOffset" : 158
    }, {
      "referenceID" : 15,
      "context" : "The results in [16, 17] imply that the unknown variables x can be reconstructed completely at each node in the network.",
      "startOffset" : 15,
      "endOffset" : 23
    }, {
      "referenceID" : 16,
      "context" : "The results in [16, 17] imply that the unknown variables x can be reconstructed completely at each node in the network.",
      "startOffset" : 15,
      "endOffset" : 23
    }, {
      "referenceID" : 19,
      "context" : "The Gaussian BP algorithm can be derived over the corresponding factor graph to compute the estimate of xn for all n ∈ V [20].",
      "startOffset" : 121,
      "endOffset" : 125
    }, {
      "referenceID" : 19,
      "context" : "It can be shown [20] that the general expression for the message from variable node to factor node is",
      "startOffset" : 16,
      "endOffset" : 20
    }, {
      "referenceID" : 19,
      "context" : "Furthermore, the message from factor node to variable node is given by [20]",
      "startOffset" : 71,
      "endOffset" : 75
    }, {
      "referenceID" : 19,
      "context" : "The following lemma shown in [20] indicates that setting",
      "startOffset" : 29,
      "endOffset" : 33
    }, {
      "referenceID" : 19,
      "context" : "tion of belief in (3), b (l) BP (xi) at iteration l is computed as [20]",
      "startOffset" : 67,
      "endOffset" : 71
    }, {
      "referenceID" : 0,
      "context" : "Sufficient conditions for the convergence of Gaussian BP with scalar variable in loopy graphs are available in [1, 12, 14].",
      "startOffset" : 111,
      "endOffset" : 122
    }, {
      "referenceID" : 11,
      "context" : "Sufficient conditions for the convergence of Gaussian BP with scalar variable in loopy graphs are available in [1, 12, 14].",
      "startOffset" : 111,
      "endOffset" : 122
    }, {
      "referenceID" : 13,
      "context" : "Sufficient conditions for the convergence of Gaussian BP with scalar variable in loopy graphs are available in [1, 12, 14].",
      "startOffset" : 111,
      "endOffset" : 122
    }, {
      "referenceID" : 0,
      "context" : "contrast to the model considered in this paper, where the fn involves high-order interactions between vector variables, and thus the convergence results in [1,12,14] cannot be applied to the factor graph based vector-form Gaussian BP.",
      "startOffset" : 156,
      "endOffset" : 165
    }, {
      "referenceID" : 11,
      "context" : "contrast to the model considered in this paper, where the fn involves high-order interactions between vector variables, and thus the convergence results in [1,12,14] cannot be applied to the factor graph based vector-form Gaussian BP.",
      "startOffset" : 156,
      "endOffset" : 165
    }, {
      "referenceID" : 13,
      "context" : "contrast to the model considered in this paper, where the fn involves high-order interactions between vector variables, and thus the convergence results in [1,12,14] cannot be applied to the factor graph based vector-form Gaussian BP.",
      "startOffset" : 156,
      "endOffset" : 165
    }, {
      "referenceID" : 19,
      "context" : "We first present properties of the updating operator F(·), with the proof given in [20].",
      "startOffset" : 83,
      "endOffset" : 87
    }, {
      "referenceID" : 19,
      "context" : "The proof is omitted due to space restrictions; it is provided in [20].",
      "startOffset" : 66,
      "endOffset" : 70
    }, {
      "referenceID" : 11,
      "context" : "Notice that, for the pairwise model, the information matrix does not necessarily converge for all initial non-negative value (in the scalar variable case) as shown in [12,13].",
      "startOffset" : 167,
      "endOffset" : 174
    }, {
      "referenceID" : 12,
      "context" : "Notice that, for the pairwise model, the information matrix does not necessarily converge for all initial non-negative value (in the scalar variable case) as shown in [12,13].",
      "startOffset" : 167,
      "endOffset" : 174
    }, {
      "referenceID" : 20,
      "context" : "Since the convergence of a dynamic system is often studied with the part metric [21], in the following, we start by introducing the part metric.",
      "startOffset" : 80,
      "endOffset" : 84
    }, {
      "referenceID" : 20,
      "context" : "Part (Birkhoff) Metric [21]: For arbitrary matrices X and Y with the same dimension, if there exists α ≥ 1 such that αX Y αX, X and Y are called the parts, and d(X,Y) , inf{logα : αX Y αX, α ≥ 1} defines a metric called the part metric.",
      "startOffset" : 23,
      "endOffset" : 27
    } ],
    "year" : 2017,
    "abstractText" : "Gaussian belief propagation (BP) has been widely used for distributed estimation in large-scale networks such as the smart grid, communication networks, and social networks, where local measurements/observations are scattered over a wide geographical area. However, the convergence of Gaussian BP is still an open issue. In this paper, we consider the convergence of Gaussian BP, focusing in particular on the convergence of the information matrix. We show analytically that the exchanged message information matrix converges for arbitrary positive semidefinite initial value, and its distance to the unique positive definite limit matrix decreases exponentially fast.",
    "creator" : "LaTeX with hyperref package"
  }
}