{
  "name" : "1305.0208.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : null,
    "authors" : [ "Mehryar Mohri", "Afshin Rostamizadeh" ],
    "emails" : [ ],
    "sections" : [ {
      "heading" : null,
      "text" : "ar X\niv :1\n30 5.\n02 08\nv2 [\ncs .L\nG ]\n2 3\nJu l 2\n01 3"
    }, {
      "heading" : "1 Introduction",
      "text" : "The Perceptron algorithm belongs to the broad family of on-line learning algorithms (see Cesa-Bianchi and Lugosi [2006] for a survey) and admits a large number of variants. The algorithm learns a linear separator by processing the training sample in an on-line fashion, examining a single example at each iteration [Rosenblatt, 1958]. At each round, the current hypothesis is updated if it makes a mistake, that is if it incorrectly classifies the new training point processed. The full pseudocode of the algorithm is provided in Figure 1. In what follows, we will assume that w0 = 0 and η = 1 for simplicity of presentation, however, the more general case also allows for similar guarantees which can be derived following the same methods we are presenting. This paper briefly surveys some existing mistake bounds for the Perceptron algorithm and introduces new ones which can be used to derive generalization bounds in a stochastic setting. A mistake bound is an upper bound on the number of updates, or the number of mistakes, made by the Perceptron algorithm when processing a sequence of training examples. Here, the bound will be expressed in terms of the performance of any linear separator, including the best. Such mistake bounds can be directly used to derive generalization guarantees for a combined hypothesis, using existing on-line-to-batch techniques."
    }, {
      "heading" : "2 Separable case",
      "text" : "The seminal work of Novikoff [1962] gave the first margin-based bound for the Perceptron algorithm, one of the early results in learning theory and probably one of the first based on the notion of margin. Assuming that the data is separable with some margin ρ, Novikoff showed that the number of mistakes made by the Perceptron algorithm can be bounded as a function of the normalized margin ρ/R, where R is the radius of the sphere containing the training instances. We start with a Lemma that can be used to prove Novikoff’s theorem and that will be used throughout.\nLemma 1. Let I denote the set of rounds at which the Perceptron algorithm makes an update when processing a sequence of training instances x1, . . . ,xT ∈ RN . Then, the following inequality holds: ∥∥∥ ∑\nt∈I\nytxt ∥∥∥ ≤\n√∑\nt∈I\n‖xt‖2 .\nProof. The inequality holds using the following sequence of observations,\n∥∥∥ ∑\nt∈I\nytxt ∥∥∥ = ∥∥∥ ∑\nt∈I\n(wt+1 −wt) ∥∥∥ (definition of updates)\n= ‖wT+1‖ (telescoping sum, w0 = 0)\n=\n√∑\nt∈I\n‖wt+1‖2 − ‖wt‖2 (telescoping sum, w0 = 0)\n=\n√∑\nt∈I\n‖wt + ytxt‖2 − ‖wt‖2 (definition of updates)\n= √√√√ ∑\nt∈I 2 ytwt · xt︸ ︷︷ ︸ ≤0 +‖xt‖2\n≤ √∑\nt∈I\n‖xt‖2 .\nThe final inequality uses the fact that an update is made at round t only when the current hypothesis makes a mistake, that is, yt(wt ·xt) ≤ 0. ⊓⊔\nThe lemma can be used straightforwardly to derive the following mistake bound for the separable setting.\nTheorem 1 ([Novikoff, 1962]). Let x1, . . . ,xT ∈ RN be a sequence of T points with ‖xt‖ ≤ r for all t ∈ [1, T ], for some r > 0. Assume that\nthere exist ρ > 0 and v ∈ RN , v 6= 0, such that for all t ∈ [1, T ], ρ ≤ yt(v·xt)\n‖v‖ . Then, the number of updates made by the Perceptron algorithm\nwhen processing x1, . . . ,xT is bounded by r 2/ρ2.\nProof. Let I denote the subset of the T rounds at which there is an update, and let M be the total number of updates, i.e., |I | = M . Summing up the inequalities yields:\nMρ ≤ v ·∑t∈I ytxt ‖v‖ ≤ ∥∥∥ ∑\nt∈I\nytxt ∥∥∥ ≤ √∑\nt∈I\n‖xt‖2 ≤ √ Mr2,\nwhere the second inequality holds by the Cauchy-Schwarz inequality, the third by Lemma 1 and the final one by assumption. Comparing the leftand right-hand sides gives √ M ≤ r/ρ, that is, M ≤ r2/ρ2. ⊓⊔"
    }, {
      "heading" : "3 Non-separable case",
      "text" : "In real-world problems, the training sample processed by the Perceptron algorithm is typically not linearly separable. Nevertheless, it is possible to give a margin-based mistake bound in that general case in terms of the radius of the sphere containing the sample and the margin-based loss of an arbitrary weight vector. We present two different types of bounds: first, a bound that depends on the L1-norm of the vector of ρ-margin hinge losses, or the vector of more general losses that we will describe, next a bound that depends on the L2-norm of the vector of margin losses, which extends the original results presented by Freund and Schapire [1999].\n3.1 L1-norm mistake bounds\nWe first present a simple proof of a mistake bound for the Perceptron algorithm that depends on the L1-norm of the losses incurred by an arbitrary weight vector, for a general definition of the loss function that covers the ρ-margin hinge loss. The family of admissible loss functions is quite general and defined as follows.\nDefinition 1 (γ-admissible loss function). A γ-admissible loss function φγ : R → R+ satisfies the following conditions: 1. The function φγ is convex.\n2. φγ is non-negative: ∀x ∈ R, φγ(x) ≥ 0. 3. At zero, the φγ is strictly positive: φγ(0) > 0. 4. φγ is γ-Lipschitz: |φγ(x)− φγ(y)| ≤ γ|x− y|, for some γ > 0.\nThese are mild conditions satisfied by many loss functions including the hinge-loss, the squared hinge-loss, the Huber loss and general p-norm losses over bounded domains.\nTheorem 2. Let I denote the set of rounds at which the Perceptron algorithm makes an update when processing a sequence of training instances x1, . . . ,xT ∈ RN . For any vector u ∈ RN with ‖u‖ ≤ 1 and any γ-admissible loss function φγ, consider the vector of losses incurred by u: Lφγ (u) = [ φγ(yt(u · xt)) ] t∈I\n. Then, the number of updates MT = |I | made by the Perceptron algorithm can be bounded as follows:\nMT ≤ inf γ>0,‖u‖≤1\n1\nφγ(0) ‖Lφγ (u)‖1 +\nγ\nφγ(0)\n√∑\nt∈I\n‖xt‖2 . (1)\nIf we further assume that ‖xt‖ ≤ r for all t ∈ [1, T ], for some r > 0, this implies\nMT ≤ inf γ>0,‖u‖≤1\n( γr\nφγ(0) +\n√ ‖Lφγ (u)‖1\nφγ(0)\n)2 . (2)\nProof. For all γ > 0 and u with ‖u‖ ≤ 1, the following statements hold. By convexity of φγ we have\n1 MT ∑ t∈I φγ(ytu · xt) ≥ φγ(u · z), where\nz = 1 MT ∑ t∈I ytxt. Then, by using the Lipschitz property of φγ we have,\nφγ(u · z) = φγ(u · z)− φγ(0) + φγ(0) = − ∣∣φγ(0)− φγ(u · z) ∣∣+ φγ(0)\n≥ −γ|u · z|+ φγ(0) .\nCombining the two inequalities above and multiplying both sides by MT implies\nMφγ(0) ≤ ∑\nt∈I\nφγ(ytu · xt) + γ ∣∣∣ ∑\nt∈I\nytu · xt ∣∣∣ .\nFinally, using the Cauchy-Schwartz inequality and Lemma 1 yields\n∣∣∣ ∑\nt∈I\nytu · xt ∣∣∣ = ∣∣∣u · (∑\nt∈I\nytxt )∣∣∣ ≤ ‖u‖ ∥∥∥ ∑\nt∈I\nytxt ∥∥∥ ≤\n√∑\nt∈I\n‖xt‖2 ,\nwhich completes the proof of the first statement after re-arranging terms. If it is further assumed that ‖xt‖ ≤ r for all t ∈ I , then this implies Mφγ(0)−r √ M−∑t∈I φγ(ytu·xt) ≤ 0. Solving this quadratic expression\nin terms of √ M proves the second statement. ⊓⊔\nIt is straightforward to see that the ρ-margin hinge loss φρ(x) = (1 − x/ρ)+ is (1/ρ)-admissible with φρ(0) = 1 for all ρ, which gives the following corollary.\nCorollary 1. Let I denote the set of rounds at which the Perceptron algorithm makes an update when processing a sequence of training instances x1, . . . ,xT ∈ RN . For any ρ > 0 and any u ∈ RN with ‖u‖ ≤ 1, consider the vector of ρ-hinge losses incurred by u: Lρ(u) = [ (1 − yt(u·xt) ρ )+ ] t∈I\n. Then, the number of updates MT = |I | made by the Perceptron algorithm can be bounded as follows:\nMT ≤ inf ρ>0‖u‖≤1 ‖Lρ(u)‖1 +\n√∑ t∈I ‖xt‖2\nρ . (3)\nIf we further assume that ‖xt‖ ≤ r for all t ∈ [1, T ], for some r > 0, this implies\nMT ≤ inf ρ>0,‖u‖≤1\n( r\nρ +\n√ ‖Lρ(u)‖1 )2 . (4)\nThe mistake bound (3) appears already in Cesa-Bianchi et al. [2004] but we could not find its proof either in that paper or in those it references for this bound. Another application of Theorem 2 is to the squared-hinge loss φρ(x) = (1 − x/ρ)2+. Assume that ‖x‖ ≤ r, then the inequality ‖y(u · x)‖ ≤ ‖u‖‖x‖ ≤ r implies that the derivative of the hinge-loss is also bounded, achieving a maximum absolute value |φ′ρ(r)| = | 2ρ ( rρ − 1)| ≤ 2rρ2 . Thus, the ρ-margin squared hinge loss is (2r/ρ2)-admissible with φρ(0) = 1 for all ρ. This leads to the following corollary.\nCorollary 2. Let I denote the set of rounds at which the Perceptron algorithm makes an update when processing a sequence of training instances x1, . . . ,xT ∈ RN with ‖xt‖ ≤ r for all t ∈ [1, T ]. For any ρ > 0 and any u ∈ RN with ‖u‖ ≤ 1, consider the vector of ρ-margin squared hinge losses incurred by u: Lρ(u) = [ (1− yt(u·xt)\nρ )2+ ] t∈I . Then, the num-\nber of updates MT = |I | made by the Perceptron algorithm can be bounded as follows:\nMT ≤ inf ρ>0‖u‖≤1\n‖Lρ(u)‖1 + 2r\n√∑ t∈I ‖xt‖2\nρ2 . (5)\nThis also implies\nMT ≤ inf ρ>0,‖u‖≤1\n( 2r2\nρ2 +\n√ ‖Lρ(u)‖1 )2 . (6)\nTheorem 2 can be similarly used to derive mistake bounds in terms of other admissible losses.\n3.2 L2-norm mistake bounds\nThe original results of this section are due to Freund and Schapire [1999]. Here, we extend their proof to derive finer mistake bounds for the Perceptron algorithm in terms of the L2-norm of the vector of hinge losses of an arbitrary weight vector at points where an update is made.\nTheorem 3. Let I denote the set of rounds at which the Perceptron algorithm makes an update when processing a sequence of training instances x1, . . . ,xT ∈ RN . For any ρ > 0 and any u ∈ RN with ‖u‖ ≤ 1, consider the vector of ρ-hinge losses incurred by u: Lρ(u) = [ (1 − yt(u·xt) ρ )+ ] t∈I\n. Then, the number of updates MT = |I | made by the Perceptron algorithm can be bounded as follows:\nMT ≤ inf ρ>0,‖u‖≤1\n\n ‖Lρ(u)‖2\n2 + √√√√‖Lρ(u)‖22 4 + √∑ t∈I ‖xt‖2 ρ   2 . (7)\nIf we further assume that ‖xt‖ ≤ r for all t ∈ [1, T ], for some r > 0, this implies\nMT ≤ inf ρ>0,‖u‖≤1\n( r\nρ + ‖Lρ(u)‖2\n)2 . (8)\nProof. We first reduce the problem to the separable case by mapping each input vector xt ∈ RN to a vector in x′t ∈ RN+T as follows:\nxt =\n\n xt,1 ...\nxt,N\n  7→ x′t = [ xt,1 . . . xt,N 0 . . . 0 ∆︸︷︷︸\n(N + t)th component\n0 . . . 0 ]⊤\n,\nwhere the first N components of x′t coincide with those of x and the only other non-zero component is the (N + t)th component which is set to ∆, a parameter ∆ whose value will be determined later. Define lt by lt = (1 − ytu·xtρ )1t∈I . Then, the vector u is replaced by the vector u ′ defined by\nu′ = [ u1 Z . . . uN Z y1l1ρ ∆Z . . . yT lT ρ ∆Z ]⊤ .\nThe first N components of u′ are equal to the components of u/Z and the remaining T components are functions of the labels and hinge losses. The normalization factor Z is chosen to guarantee that ‖u′‖ = 1: Z =√\n1 + ρ2‖Lρ(u)‖2\n∆2 . Since the additional coordinates of the instances are\nnon-zero exactly once, the predictions made by the Perceptron algorithm for x′t, t ∈ [1, T ] coincide with those made in the original space for xt, t ∈ [1, T ]. In particular, a change made to the additional coordinates of w′ does no affect any subsequent prediction. Furthermore, by definition of u′ and x′t, we can write for any t ∈ I :\nyt(u ′ · x′t) = yt (u · xt Z +∆ ytltρ Z∆ )\n= ytu · xt\nZ +\nltρ\nZ\n≥ ytu · xt Z + ρ− yt(u · xt) Z = ρ Z ,\nwhere the inequality results from the definition of lt. Summing up the inequalities for all t ∈ I and using Lemma 1 yields MT ρZ ≤ ∑ t∈I yt(u\n′ · x′t) ≤ √∑ t∈I ‖x′t‖2. Substituting the value of Z and re-writing in terms of x implies:\nM2T ≤ ( 1 ρ2 + ‖Lρ(u)‖2 ∆2 )( R2 +MT∆ 2 )\n= R2\nρ2 + R2‖Lρ(u)‖2 ∆2 + MT∆ 2 ρ2 +MT ‖Lρ(u)‖2 ,\nwhere R = √∑\nt∈I ‖xt‖2. Now, solving for ∆ to minimize this bound gives ∆2 =\nρ‖Lρ(u)‖R√ MT and further simplifies the bound\nM2T ≤ R2\nρ2 + 2\n√ MT ‖Lρ(u)‖R\nρ +MT ‖Lρ(u)‖2\n= (R ρ + √ MT ‖Lρ(u)‖2 )2 .\nSolving the second-degree inequality MT − √ MT ‖Lρ(u)‖2−Rρ ≤ 0 proves the first statement of the theorem. The second theorem is obtained by first bounding R with r √ MT and then solving the second-degree inequality. ⊓⊔"
    }, {
      "heading" : "3.3 Discussion",
      "text" : "One natural question this survey raises is the respective quality of the L1- and L2-norm bounds. The comparison of (4) and (8) for the ρ-margin hinge loss shows that, for a fixed ρ, the bounds differ only by the following two quantities:\nmin ‖u‖≤1 ‖Lρ(u)‖1 = min ‖u‖≤1\n∑\nt∈I\n(1− yt ( u · xt)/ρ ) +\nmin ‖u‖≤1 ‖Lρ(u)‖22 = min ‖u‖≤1\n∑\nt∈I\n(1− yt ( u · xt)/ρ )2 + .\nThese two quantities are data-dependent and in general not comparable. For a vector u for which the individual losses (1− yt ( u · xt)) are all less than one, we have ‖Lρ(u)‖22 ≤ ‖Lρ(u)‖1, while the contrary holds if the individual losses are larger than one."
    }, {
      "heading" : "4 Generalization Bounds",
      "text" : "In this section, we consider the case where the training sample processed is drawn according to some distribution D. Under some mild conditions on the loss function, the hypotheses returned by an on-line learning algorithm can then be combined to define a hypothesis whose generalization error can be bounded in terms of its regret. Such a hypothesis can be determined via cross-validation Littlestone [1989] or using the online-tobatch theorem of Cesa-Bianchi et al. [2004]. The latter can be combined with any of the mistake bounds presented in the previous section to derive generalization bounds for the Perceptron predictor. Given δ > 0, a sequence of labeled examples (x1, y1), . . . , (yT , xT ), a sequence of hypotheses h1, . . . , hT , and a loss function L, define the penalized risk minimizing hypothesis as ĥ = hi∗ with\ni∗ = argmin i∈[1,T ]\n1\nT − i+ 1\nT∑\nt=i\nL(ythi(xt)) +\n√ log T (T+1)\nδ\n2(T − i+ 1) .\nThe following theorem gives a bound on the expected loss of ĥ on future examples.\nTheorem 4 (Cesa-Bianchi et al. [2004]). Let S be a labeled sample ((x1, y1), . . . , (xT , yT )) drawn i.i.d. according to D, L a loss function bounded by one, and h1, . . . , hT the sequence of hypotheses generated by an on-line algorithm A sequentially processing S. Then, for any δ > 0, with probability at least 1− δ, the following holds:\nE (x,y)∼D [L(yĥ(x))] ≤ 1 T\nT∑\ni=1\nL(yihi(xi)) + 6\n√ 1\nT log\n2(T + 1)\nδ . (9)\nNote that this theorem does not require the loss function to be convex. Thus, if L is the zero-one loss, then the empirical loss term is precisely the average number of mistakes made by the algorithm. Plugging in any of the mistake bounds from the previous sections then gives us a learning guarantee with respect to the performance of the best hypothesis as measured by a margin-loss (or any γ-admissible loss if using Theorem 2). Let ŵ denote the weight vector corresponding to the penalized risk minimizing Perceptron hypothesis chosen from all the intermediate hypotheses generated by the algorithm. Then, in view of Theorem 2, the following corollary holds.\nCorollary 3. Let I denote the set of rounds at which the Perceptron algorithm makes an update when processing a sequence of training instances x1, . . . ,xT ∈ RN . For any vector u ∈ RN with ‖u‖ ≤ 1 and any γ-admissible loss function φγ, consider the vector of losses incurred by u: Lφγ (u) = [ φγ(yt(u · xt)) ] t∈I\n. Then, for any δ > 0, with probability at least 1− δ, the following generalization bound holds for the penalized risk minimizing Perceptron hypothesis ŵ:\nPr (x,y)∼D\n[y(ŵ · x) < 0]\n≤ inf γ>0,‖u‖≤1 ‖Lφγ (u)‖1 φγ(0)T\n+ γ √∑ t∈I ‖xt‖2\nφγ(0)T + 6\n√ 1\nT log\n2(T + 1)\nδ .\nAny γ-admissible loss can be used to derive a more explicit form of this bound in special cases, in particular the hinge loss or the squared hinge loss. Using Theorem 3, we obtain the following L2-norm generalization bound.\nCorollary 4. Let I denote the set of rounds at which the Perceptron algorithm makes an update when processing a sequence of training instances x1, . . . ,xT ∈ RN . For any ρ > 0 and any u ∈ RN with ‖u‖ ≤ 1, consider the vector of ρ-hinge losses incurred by u: Lρ(u) = [ (1 − yt(u·xt) ρ )+ ] t∈I\n. Then, for any δ > 0, with probability at least 1 − δ, the following generalization bound holds for the penalized risk minimizing\nPerceptron hypothesis ŵ:\nPr (x,y)∼D\n[y(ŵ · x) < 0]\n≤ inf ρ>0,‖u‖≤1\n1\nT\n\n ‖Lρ(u)‖2\n2 + √√√√‖Lρ(u)‖22 4 + √∑ t∈I ‖xt‖2 ρ   2\n+ 6\n√ 1\nT log\n2(T + 1)\nδ ."
    }, {
      "heading" : "5 Kernel Perceptron algorithm",
      "text" : "The Perceptron algorithm of Figure 1 can be straightforwardly extended to define a non-linear separator using a positive definite kernel K [Aizerman et al., 1964]. Figure 2 gives the pseudocode of that algorithm known as the kernel Perceptron algorithm. The classifier sgn(h) learned by the algorithm is defined by h : x 7→ ∑Tt=1 αtytK(xt, x). The results of the previous sections apply similarly to the kernel perceptron algorithm with ‖xt‖2 replaced with K(xt, xt). In particular, the quantity √∑\nt∈I ‖xt‖2 appearing in several of the learning guarantees can be replaced with the familiar trace Tr[K] of the kernel matrix K = [K(xi, xj)]i,j∈I over the set of points at which an update is made, which is a standard term appearing in margin bounds for kernel-based hypothesis sets."
    } ],
    "references" : [ {
      "title" : "Theoretical foundations of the potential function method in pattern recognition learning",
      "author" : [ "Mark A. Aizerman", "E.M. Braverman", "Lev I. Rozonoèr" ],
      "venue" : "Automation and Remote Control,",
      "citeRegEx" : "Aizerman et al\\.,? \\Q1964\\E",
      "shortCiteRegEx" : "Aizerman et al\\.",
      "year" : 1964
    }, {
      "title" : "Prediction, Learning, and Games",
      "author" : [ "Nicolò Cesa-Bianchi", "Gabor Lugosi" ],
      "venue" : null,
      "citeRegEx" : "Cesa.Bianchi and Lugosi.,? \\Q2006\\E",
      "shortCiteRegEx" : "Cesa.Bianchi and Lugosi.",
      "year" : 2006
    }, {
      "title" : "On the generalization ability of on-line learning algorithms",
      "author" : [ "Nicolò Cesa-Bianchi", "Alex Conconi", "Claudio Gentile" ],
      "venue" : "IEEE Transactions on Information Theory,",
      "citeRegEx" : "Cesa.Bianchi et al\\.,? \\Q2004\\E",
      "shortCiteRegEx" : "Cesa.Bianchi et al\\.",
      "year" : 2004
    }, {
      "title" : "Large margin classification using the perceptron algorithm",
      "author" : [ "Yoav Freund", "Robert E. Schapire" ],
      "venue" : "Machine Learning,",
      "citeRegEx" : "Freund and Schapire.,? \\Q1999\\E",
      "shortCiteRegEx" : "Freund and Schapire.",
      "year" : 1999
    }, {
      "title" : "From on-line to batch learning",
      "author" : [ "Nick Littlestone" ],
      "venue" : "In COLT,",
      "citeRegEx" : "Littlestone.,? \\Q1989\\E",
      "shortCiteRegEx" : "Littlestone.",
      "year" : 1989
    }, {
      "title" : "On convergence proofs on perceptrons",
      "author" : [ "Albert B.J. Novikoff" ],
      "venue" : "In Proceedings of the Symposium on the Mathematical Theory of Automata,",
      "citeRegEx" : "Novikoff.,? \\Q1962\\E",
      "shortCiteRegEx" : "Novikoff.",
      "year" : 1962
    }, {
      "title" : "The perceptron: A probabilistic model for information storage and organization in the brain",
      "author" : [ "Frank Rosenblatt" ],
      "venue" : "Psychological Review,",
      "citeRegEx" : "Rosenblatt.,? \\Q1958\\E",
      "shortCiteRegEx" : "Rosenblatt.",
      "year" : 1958
    } ],
    "referenceMentions" : [ {
      "referenceID" : 6,
      "context" : "The algorithm learns a linear separator by processing the training sample in an on-line fashion, examining a single example at each iteration [Rosenblatt, 1958].",
      "startOffset" : 142,
      "endOffset" : 160
    }, {
      "referenceID" : 1,
      "context" : "The Perceptron algorithm belongs to the broad family of on-line learning algorithms (see Cesa-Bianchi and Lugosi [2006] for a survey) and admits a large number of variants.",
      "startOffset" : 89,
      "endOffset" : 120
    }, {
      "referenceID" : 5,
      "context" : "The seminal work of Novikoff [1962] gave the first margin-based bound for the Perceptron algorithm, one of the early results in learning theory and probably one of the first based on the notion of margin.",
      "startOffset" : 20,
      "endOffset" : 36
    }, {
      "referenceID" : 6,
      "context" : "Perceptron algorithm [Rosenblatt, 1958].",
      "startOffset" : 21,
      "endOffset" : 39
    }, {
      "referenceID" : 5,
      "context" : "Theorem 1 ([Novikoff, 1962]).",
      "startOffset" : 11,
      "endOffset" : 27
    }, {
      "referenceID" : 3,
      "context" : "We present two different types of bounds: first, a bound that depends on the L1-norm of the vector of ρ-margin hinge losses, or the vector of more general losses that we will describe, next a bound that depends on the L2-norm of the vector of margin losses, which extends the original results presented by Freund and Schapire [1999].",
      "startOffset" : 306,
      "endOffset" : 333
    }, {
      "referenceID" : 2,
      "context" : "The mistake bound (3) appears already in Cesa-Bianchi et al. [2004] but we could not find its proof either in that paper or in those it references for this bound.",
      "startOffset" : 41,
      "endOffset" : 68
    }, {
      "referenceID" : 3,
      "context" : "2 L2-norm mistake bounds The original results of this section are due to Freund and Schapire [1999]. Here, we extend their proof to derive finer mistake bounds for the Perceptron algorithm in terms of the L2-norm of the vector of hinge losses of an arbitrary weight vector at points where an update is made.",
      "startOffset" : 73,
      "endOffset" : 100
    }, {
      "referenceID" : 3,
      "context" : "Such a hypothesis can be determined via cross-validation Littlestone [1989] or using the online-tobatch theorem of Cesa-Bianchi et al.",
      "startOffset" : 57,
      "endOffset" : 76
    }, {
      "referenceID" : 2,
      "context" : "Such a hypothesis can be determined via cross-validation Littlestone [1989] or using the online-tobatch theorem of Cesa-Bianchi et al. [2004]. The latter can be combined with any of the mistake bounds presented in the previous section to derive generalization bounds for the Perceptron predictor.",
      "startOffset" : 115,
      "endOffset" : 142
    }, {
      "referenceID" : 2,
      "context" : "Theorem 4 (Cesa-Bianchi et al. [2004]).",
      "startOffset" : 11,
      "endOffset" : 38
    }, {
      "referenceID" : 0,
      "context" : "The Perceptron algorithm of Figure 1 can be straightforwardly extended to define a non-linear separator using a positive definite kernel K [Aizerman et al., 1964].",
      "startOffset" : 139,
      "endOffset" : 162
    } ],
    "year" : 2013,
    "abstractText" : "We present a brief survey of existing mistake bounds and introduce novel bounds for the Perceptron or the kernel Perceptron algorithm. Our novel bounds generalize beyond standard margin-loss type bounds, allow for any convex and Lipschitz loss function, and admit a very simple proof.",
    "creator" : "dvips(k) 5.991 Copyright 2011 Radical Eye Software"
  }
}