{
  "name" : "1610.05120.pdf",
  "metadata" : {
    "source" : "META",
    "title" : "Lazifying Conditional Gradient Algorithms",
    "authors" : [ "Gábor Braun", "Sebastian Pokutta" ],
    "emails" : [ "gabor.braun@gatech.edu", "sebastian.pokutta@gatech.edu", "daniel.zink@gatech.edu" ],
    "sections" : [ {
      "heading" : null,
      "text" : "ar X\niv :1\n61 0.\n05 12\n0v 1\n[ cs\n.D S]\n1 7\nConditional gradient algorithms (also often called Frank-Wolfe algorithms) are popular due to their simplicity of only requiring a linear optimization oracle and more recently they also gained significant traction for online learning. While simple in principle, inmany cases the actual implementation of the linear optimization oracle is costly. We show a general method to lazify various conditional gradient algorithms, which in actual computations leads to several orders of magnitude of speedup in wall-clock time. This is achieved by using a faster separation oracle instead of a linear optimization oracle, relying only on few linear optimization oracle calls."
    }, {
      "heading" : "1 Introduction",
      "text" : "Convex optimization is an important technique both from a theoretical and an applications perspective. Standard gradient descent based methods are widely used due to their simplicity and easy applicability to many real-world problems. To maintain feasibility, typically a projection step is required, which is potentially computationally expensive, especially for complex feasible regions in very large dimensions. Hence projectionfree methods gained a lot of attention recently, in particular the Frank-Wolfe algorithm [Frank and Wolfe, 1956] (also known as conditional gradient descent [Levitin and Polyak, 1966]; see also [Jaggi, 2013] for an overview) and its online version [Hazan and Kale, 2012]. These methods eschew the projection step and rather use a linear optimization oracle to stay within the feasible region. While convergence rates and regret bounds are often suboptimal, in many cases the gain due to only having to solve a single linear optimization problem over the feasible region in every iteration still leads to significant computational advantages (see e.g., [Hazan and Kale, 2012, Section 5]). This led to conditional gradients algorithms being often used for e.g., online optimization andmore generallymachine learning, especially because they also naturally generate sparse distributions over the extreme points of the feasible region. Further increasing the relevance of these methods, it was shown recently in Garber and Hazan [2013], Lacoste-Julien and Jaggi [2015], Garber and Meshi [2016] that conditional gradient methods often achieve linear convergence.\nUnfortunately, for complex feasible regions even solving the linear optimization problem might be timeconsuming. To significantly reduce the cost of oracle calls while maintaining identical convergence rates up to small constant factors, we replace the linear optimization oracle by a (weak) separation oracle, see Oracle 1, which approximately solves a separation problem within a multiplicative factor. Note that, weak\nseparation is significantly weaker than approximate minimization; the latter has been already considered in Jaggi [2013]. A (weak) separation oracle can be realized by a single call to a linear optimization oracle, however with two important differences. It allows for caching and early termination: Previous solutions are cached, and first it is verified whether any of the cached solutions satisfy a separation condition. The linear optimization oracle is called only when none of the cached solutions satisfy the condition, and it is stopped as soon as a satisfactory solution is found. We call this technique lazy optimization. We provide conditional gradient algorithms employing the weak separation oracle instead of a linear optimization oracle for the algorithms in [Hazan and Kale, 2012, Garber and Meshi, 2016, Garber and Hazan, 2013] with convergence rates summarized in Table 1. These bounds are identical to their linear optimization counterparts up to a small constant factor. Complementing the theoretical analysis we report computational results demonstrating effectiveness of our approach via a significant reduction in running time compared to their linear optimization counterparts.\nOracle 1Weak Separation Oracle LPsepP(c, x, Φ, K) Require: c ∈ Rn linear objective, x ∈ P point, K ≥ 1 accuracy, Φ > 0 objective value; Ensure: Either (1) y ∈ P vertex with c(x − y) > Φ/K, or (2) false: c(x − z) ≤ Φ for all z ∈ P.\nRelated Work\nIn the offline setting we mimick the same setups as in Garber and Hazan [2013], Garber and Meshi [2016] respectively. In the online setup we mimick the setup of Hazan and Kale [2012]. Combinatorial convex optimization has been investigated in a long line of works (see e.g., [Kalai and Vempala, 2005, Audibert et al., 2013, Neu and Bartók, 2013]), see [Hazan, 2016] for an exhaustive overview. It is important to note that our regret bounds hold in the structured online learning setting (see e.g., [Cohen and Hazan, 2015, Gupta et al., 2016]) for arbitrary convex functions.\nContribution\nThe main technical contribution of this paper is a new approach, whereby instead of finding the optimal solution, the oracle is used only to find a good enough solution or a certificate that such a solution does not exist, both ensuring the desired convergence rate of the conditional gradient algorithms.\nOur contribution can be summarized as follows: Lazifying approach. We provide a general method to lazify conditional gradient algorithms. For this we replace the linear optimization oracle with a weak separation oracle, which allows us to reuse feasible solutions from previous oracle calls, so that in many cases the oracle call can be skipped. In fact, once a simple representation of the underlying feasible region is learned no further oracle calls are needed.\nLazified conditional gradient algorithms. We exemplify our approach by providing lazy versions of the conditional gradient methods in [Hazan and Kale, 2012, Garber and Hazan, 2013, Garber and Meshi, 2016]\nComputational experiments. We demonstrate computational superiority by extensive comparisons of the weak separation based versions with their original versions. In all cases we report significant speedups in wall-clock time often of several orders of magnitude.\nIn all cases, we maintain identical convergence rates as in the case with a linear optimization oracle up\nto (small!) constant factors. We summarize the bounds for convenience in Table 1."
    }, {
      "heading" : "2 Preliminaries",
      "text" : "Let ‖·‖ be an arbitrary norm on Rn, and let ‖·‖∗ denote the dual norm of ‖·‖. A function f is L-Lipschitz if | f (y)− f (x)| ≤ L‖y − x‖ for all x, y ∈ dom f . A convex function f is smooth with curvature at most C if f (γy + (1 − γ)x) ≤ f (x) + γ∇ f (x)(y − x) + Cγ2/2 for all x, y ∈ dom f and 0 ≤ γ ≤ 1. A function f is S-strongly convex if f (y)− f (x) ≥ ∇ f (x)(y− x) + S2 ‖y − x‖ 2 for all x, y ∈ dom f . Unless otherwise stated Lipschitz continuity and strong convexity will be measured in the norm ‖·‖. Moreover, let Br (x) := {y | ‖x − y‖ ≤ r} be the ball around x with radius r with respect to ‖.‖.\nIn the following, P will denote the feasible region, a polytope and the vertices of P will be denoted by v1, . . . , vN."
    }, {
      "heading" : "3 Lazy Offline Conditional Gradients",
      "text" : "We will first show how the Frank-Wolfe style algorithms in Garber and Hazan [2013] and Garber and Meshi [2016] can be lazified by means of a weak separation oracle as given in Oracle 1. Note that the two cases in Oracle 1 are not mutually exclusive: the oracle might return an y ∈ P with c(x − y) > Φ/K, while still c(x − z) ≤ Φ for all z ∈ P. In this section ‖·‖ denotes the ℓ2-norm."
    }, {
      "heading" : "3.1 Lazy Conditional Gradient: a basic example",
      "text" : "We start with lazifying the simplest Conditional Gradent algorithm, adapting the argument of the non-lazy version from Jaggi [2013]. While the vanilla version has suboptimal convergence rate O(1/T), its simplicity makes it an illustrative example of the main idea of lazification. The lazy algorithm (Algorithm 1) maintains an upper bound Φt on the convergence rate, guiding its eagerness for progress when searching for an improving vertex vt. The step size γt is chosen to (approximately)minimize Φt in Line 2; roughlyΦt−1/KC.\nTheorem 3.1. (C.f., [Jaggi, 2013, Theorem 1].) Assume f is convex and smooth with curvature C. Then Algorithm 1 with γt = 2(K2+1) K(t+K2) has convergence rate\nf (xt)− f (x∗) ≤ 2 max{C, Φ0}(K2 + 1)\nt + K2 , (1)\nwhere x∗ is a minimum point of f over P.\nProof. We prove by induction that\nf (xt)− f (x∗) ≤ Φt−1 ≤ Φt−1.\nAlgorithm 1 Lazy Conditional Gradients (LCG) Require: smooth convex f function with curvature C, x1 ∈ P start vertex, LPsepP weak linear separation oracle, accuracy K > 1, initial upper bound Φ0 Ensure: xt points in P 1: for t = 1 to T − 1 do 2: Φt ← Φt−1+ Cγ2t 2\n1+ γt K\n3: vt ← LPsepP(∇ f (xt), xt, Φt, K) 4: if vt = false then 5: xt+1 ← xt 6: Φt ← Φt 7: else\n8: xt+1 ← (1 − γt)xt + γtvt 9: Φt ← Φt−1 − ( f (xt)− f (xt+1)) 10: end if 11: end for\nwith Φ0 := Φ0. The claim is clear for t = 1 by the choice of Φ0. Assuming the claim is true for t, we prove it for t + 1. We distinguish two cases depending on the return value of the weak separation oracle in Line 3.\nWhen the oracle returns an improving solution vt, which we call the positive case, then ∇ f (xt)(xt − vt) ≥ Φt/K, which is used in the second inequality below. The first inequality follows by smoothness of f :\nΦt − Φt−1 = f (xt+1)− f (xt) ≤ γt∇ f (xt)(vt − xt) + Cγ2t\n2 ≤ −γt\nΦt\nK + Cγ2t 2 = Φt − Φt−1, (2)\nhence Φt ≤ Φt. By Line 9 and the induction hypothesis, we clearly have\nf (xt+1)− f (x∗) ≤ f (xt+1)− f (xt) + Φt−1 = Φt.\nWhen the oracle returns no improving solution, then in particular ∇ f (xt)(xt − x∗) ≤ Φt, hence by Line 5\nf (xt+1)− f (x∗) = f (xt)− f (x∗) ≤ ∇ f (xt)(xt − x∗) ≤ Φt = Φt. (3) Finally, using the specific values of γt we prove the upper bound\nΦt−1 ≤ 2 max{C, Φ0}(K2 + 1)\nt + K2 (4)\nby induction on t. The claim is obvious for t = 1. The inductional step is an easy computation relying on the definition of Φt on Line 2:\nΦt = Φt−1 +\nCγ2t 2\n1 + γtK ≤ Φt−1 +\nCγ2t 2\n1 + γtK ≤\n2 max{C,Φ0}(K2+1) t+K2 + max{C,Φ0}γ2t 2\n1 + γtK\n= 2 max{C, Φ0}(K2 + 1) 1 + γt2K (\n1 + γtK )\n(t + K2) ≤ 2 max{C, Φ0}(K 2 + 1) t + 1 + K2 .\n(5)\nHere the last inequality follows from t ≥ 1 and the concrete choice of γt."
    }, {
      "heading" : "3.2 Lazy Pairwise Conditional Gradients",
      "text" : "In this section we provide a lazy variant (Algorithm 2) of the Pairwise Conditional Gradient algorithm from Garber and Meshi [2016], using separation instead of linear optimization. We make identical assumptions: the feasible region is a 0/1 polytope given in the form P = {x ∈ Rn | x ≥ 0, Ax = b}.\nAlgorithm 2 Lazy Pairwise Conditional Gradients (LPCG)\nRequire: polytope P, smooth and S-strongly convex function f with curvature C, accuracy K > 1, ηt nonincreasing step-sizes Ensure: xt points 1: x1 ∈ P arbitrary and Φ0 ≥ f (x1)− f (x∗) 2: for t = 1, . . . , T do 3: define ∇̃ f (xt) ∈ Rm as follows:\n∇̃ f (xt)i := { ∇ f (xt)i if xt > 0 −∞ if xt = 0\n4: Φt ← 2Φt−1+η 2 t C\n2+ ηt\nK∆t\n5: ct ← ( ∇ f (xt),−∇̃ f (xt) ) 6: (v+t , v − t ) ← LPsepP×P ( ct, (xt, xt), Φt ∆t , K ) 7: if (v+t , v − t ) = false then 8: xt+1 ← xt 9: else\n10: η̃t ← max{2−δ | δ ∈ Z≥0, 2−δ ≤ ηt} 11: xt+1 ← xt + η̃t(v+t − v−t ) 12: end if 13: end for\nObserve that Algorithm 2 calls the linear separation oracle LPsep on the cartesian product of P with itself. Choosing the objective function as in Line 5 allows us to simultaneously find an improving direction and an away-step direction.\nTheorem 3.2. Let x∗ be a minimum point of f in P, and Φ0 an upper bound of f (x1) − f (x∗). Furthermore, let M1 := √ S 8 card(x∗) , M2 := KC/2, κ := min{ M1 2M2 , 1/ √ Φ0}, ηt := κ √\nΦt−1 and ∆t := √\n2 card(x∗)Φt−1 S , then Algorithm 2 has convergence rate\nf (xt+1)− f (x∗) ≤ Φt ≤ Φ0 ( 1 + B\n1 + 2B\n)t\n,\nwhere B := κ · M12K .\nWe recall a technical lemma for the proof.\nLemma 3.3 ([Garber and Meshi, 2016, Lemma 2]). Let x, y ∈ P. There exists vertices vi of P such that x = ∑ki=1 λivi and y = ∑ k i=1 (λi − γi) vi + ( ∑ k i=1 γi )\nz with γi ∈ [0, λi], z ∈ P and ∑ki=1 γi ≤ √\ncard(y)‖x − y‖.\nProof of Theorem 3.2. The feasibility of the iterates xt is ensured by Line 10 and the monotonicity of the sequence {ηt}t≥1 with the same argument as in [Garber and Meshi, 2016, Lemma 1 and Observation 2].\nWe first show by induction that\nf (xt+1)− f (x∗) ≤ Φt. For t = 0 we have Φ0 ≥ f (x1)− f (x∗). Now assume the statement for some t ≥ 0. In the negative case (Line 8), we use the guarantee of Oracle 1 to get\nct((xt, xt)− (z1, z2)) ≤ Φt\n∆t\nfor all z1, z2 ∈ P, which is equivalent to (as ct(xt, xt) = 0)\n∇̃ f (xt)z2 −∇ f (xt)z1 ≤ Φt\n∆t\nand therefore\n∇ f (xt)(z̃2 − z1) ≤ Φt\n∆t , (6)\nfor all z̃2, z1 ∈ P with supp(z̃2) ⊆ supp(xt). We further use Lemma 3.3 to write xt = ∑ki=1 λivi and x∗ = ∑ki=1(λi − γi)vi + ∑ki=1 γiz with γi ∈ [0, λi], z ∈ P and ∑ki=1 γi ≤ √ card(x∗)‖xt − x∗‖ ≤ √\n2 card(x∗)Φt−1 S = ∆t, using the induction hypothesis and the strong convexity in the second inequality.\nThen\nf (xt+1)− f (x∗) = f (xt)− f (x∗) ≤ ∇ f (xt)(xt − x∗) = k\n∑ i=1\nγi(vi − z) · ∇ f (xt) ≤ Φt,\nwhere we used Equation 6 for the last inequality.\nFor the positive case (Lines 10 and 11) we get, using first smoothness of f , then ηt/2 < η̃t ≤ ηt and ∇ f (xt)(v+t − v−t ) ≤ −Φt/(∆tK), and finally the definition of Φt:\nf (xt+1)− f (x∗) = f (xt)− f (x∗) + f (xt + η̃t(v+t − v−t ))− f (xt)\n≤ Φt−1 + η̃t∇ f (xt)(v+t − v−t ) + η̃2t C\n2\n≤ Φt−1 − ηt 2 · Φt ∆tK +\nη2t C\n2 = Φt.\nPlugging in the values of ηt and ∆t to the definition of Φt gives the desired bound.\nΦt = 2Φt−1 + η2t C\n2 + ηtK∆t = Φt−1\n1 + κ2 M2/K\n1 + κM1/K ≤ Φt−1\n1 + B\n1 + 2B ≤ Φ0\n(\n1 + B\n1 + 2B\n)t\n."
    }, {
      "heading" : "3.3 Lazy Local Conditional Gradients",
      "text" : "In this sectionwe provide a lazy version (Algorithm3) of the conditional gradient algorithmfromGarber and Hazan [2013]. Let P ⊆ Rn be any polytope, D denote an upper bound on the ℓ2-diameter of P, and µ ≥ 1 be the affine invariant of P from Garber and Hazan [2013]. As the algorithm is not affine invariant by nature, we need a non-invariant version of smoothness: Recall that a convex function f is β-smooth if f (y)− f (x) ≤ ∇ f (x)(y − x) + β‖y − x‖2/2.\nAlgorithm 3 Lazy Local Conditional Gradients (LLCG)\nRequire: feasible polytope P, β-smooth and S-strongly convex function f , parameters K, S, β, µ; diameter D Ensure: xt points 1: x1 ∈ P arbitrary and Φ0 ≥ f (x1)− f (x∗) 2: α ← S\n2Kβnµ2\n3: for t = 1, . . . , T do 4: Φt ← Φt−1+ β 2 α 2 min{nµ2r2t ,D2} 1+α/K 5: rt ← √ 2Φt−1 S 6: pt ← LLPsepP (∇ f (xt), xt, rt, Φt, K) 7: if pt = false then 8: xt+1 ← xt 9: else\n10: xt+1 ← xt + α(pt − xt) 11: end if 12: end for\nAs an intermediary step, we first implement a local weak separation oracle in Algorithm4, a local version of Oracle 1, analogously to the local linear optimization oracle in Garber and Hazan [2013]. To this end, we recall a technical lemma from Garber and Hazan [2013].\nLemma 3.4. [Garber and Hazan, 2013, Lemma 7] Let P ⊆ Rn be a polytope and v1, . . . , vN be its vertices. Let x, y ∈ P and x = ∑Ni=1 λivi a convex combination of the vertices of P. Then there are numbers 0 ≤ γi ≤ λi and z ∈ P satisfying\ny − x = − ∑ i∈[N] γivi +\n\n ∑ i∈[N] γi\n\n z (7)\n∑ i∈[N]\nγi ≤ √ nµ\nD ‖x − y‖. (8)\nNow we prove the correctness of the weak local separation algorithm.\nLemma 3.5. Algorithm 4 is correct. In particular LLPsepP(c, x, r, Φ, K)\n(i) returns either an y ∈ P with ‖x − y‖ ≤ √nµr and c(x − y) > Φ/K,\n(ii) or establishes c(x − z) ≤ Φ for all z ∈ P ∩ Br (x).\nAlgorithm 4Weak Local Separation LLPsepP(c, x, r, Φ, K) Require: c ∈ Rn linear objective, x ∈ P point, r > 0 radius, Φ > 0 objective value Ensure: Either (1) y ∈ P with ‖x − y‖ ≤ √nµr and c(x − y) > Φ/K, or (2) false: c(x − z) ≤ Φ for all\nz ∈ P ∩ Br (x). 1: ∆ ← min {√ nµ\nD r, 1 }\n2: Decompose x: x = ∑Mj=1 λjvj, λj > 0, ∑j λj = 1. 3: Sort vertices: i1, . . . , iM cvi1 ≥ · · · ≥ cviM . 4: k ← min{k : ∑kj=1 λi j ≥ ∆} 5: p− ← ∑k−1j=1 λi jvi j + ( ∆ − ∑k−1j=1 λi j ) vik 6: v∗ ← LPsepP ( c, p− ∆ , Φ ∆ ) 7: if v∗ = false then 8: return false 9: else\n10: return y ← x − p− + ∆v∗ 11: end if\nProof. We first consider the case when the algorithm exits in Line 10. Observe that y ∈ P since y is a convex combination of vertices of P. Moreover by construction of y we can write y = ∑Mj=1(λi j − γj)vi j + ∆v∗ with ∆ = ∑Mj=1 γj ≤ √ nµ D r. Therefore\n‖x − y‖ = ∥ ∥ ∥\n∥ ∥\nM\n∑ j=1\nγjvi j − ∆v ∗ ∥ ∥ ∥ ∥\n∥\n≤ M\n∑ j=1\nγj‖vi j − v ∗‖\n≤ √ nµr.\nFinally using the guarantee of LPsepP we get\nc(x − y) = ∆c ( p− ∆ − v∗ ) ≥ Φ K .\nIf the algorithm exits in Line 8, we use Lemma 3.4 to decompose any y ∈ P ∩ Br (x) in the following way:\ny = N\n∑ i=1\n(λi − γi)vi + ( N\n∑ i=1 γi\n)\nz,\nwith z ∈ P and ∑Ni=1 γi ≤ √ nµ D ‖x − y‖ ≤ ∆. Since ∑Ni=1 λi = 1 ≥ ∆, there are numbers γi ≤ η−i ≤ λi with ∑ N i=1 η − i = ∆. Let\np̃− := N\n∑ i=1\nη−i vi, (9)\np̃+ := y − x + p̃− = N\n∑ i=1\n(η−i − γi)vi + N\n∑ i=1 γiz, (10)\nso that p̃+/∆ ∈ P. To bound the function value we first observe that the choice of p− in the algorithm assures that cu ≤ cp− for all u = ∑Ni=1 ηivi with ∑Ni=1 ηi = ∆ and all ηi ≥ 0. In particular, cp̃− ≤ cp−. The function value of the positive part p̃+ can be bounded with the guarantee of LPsepP:\nc\n(\np− ∆ − p̃+ ∆\n)\n≤ Φ ∆ ,\ni.e., c(p− − p̃+) ≤ Φ. Finally combining these bounds gives\nc(x − y) = c ( p̃− − p̃+) ≤ c(p− − p̃+) ≤ Φ\nas desired.\nWe are ready to examine the Conditional Gradient Algorithm based on LLPsepP:\nTheorem 3.6. Algorithm 3 converges with the following rate:\nf (xt+1)− f (x∗) ≤ Φt ≤ Φ0 ( 1 + α/(2K)\n1 + α/K\n)t\n.\nProof. The proof is similar to the proof of Theorem 3.2. We prove this rate by induction. For t = 0 the choice of Φ0 guarantees that f (x1)− f (x∗) ≤ Φ0. Now assume the theorem holds for t ≥ 0. With strong convexity and the induction hypothesis we get\n‖xt − x∗‖2 ≤ 2 S ( f (xt)− f (x∗)) ≤ 2 S Φt−1 = r2t ,\ni.e., x∗ ∈ P ∩ Brt (xt). In the negative case, i.e., when pt = false, then case (ii) of Lemma 3.5 applies:\nf (xt+1)− f (x∗) = f (xt)− f (x∗) ≤ ∇ f (xt)(xt − x∗) ≤ Φt.\nIn the positive case, i.e., when Line 10 is executed, we get the same inequality via:\nf (xt+1)− f (x∗) ≤ Φt−1 + α∇ f (xt)(pt − xt) + β\n2 α2‖x − pt‖2\n≤ Φt−1 − α Φt\nK +\nβ 2 α2 min{nµ2r2t , D2}\n= Φt.\nTherefore using the definition of α and rt we get the desired bound:\nΦt ≤ Φt−1 +\nβ 2 α 2r2t nµ 2\n1 + α/K = Φt−1\n(\n1 + α/(2K)\n1 + α/K\n) ≤ Φ0 ( 1 + α/(2K)\n1 + α/K\n)t\n."
    }, {
      "heading" : "4 Lazy Online Conditional Gradients",
      "text" : "In this section we lazify the online conditional gradient algorithm of Hazan and Kale [2012] over arbitrary polytopes P = {x ∈ Rn | Ax ≤ b}, resulting in Algorithm 5. We slightly improve constant factors by replacing [Hazan and Kale, 2012, Lemma 3.1] with a better estimation via solving a quadratic inequality arising from strong convexity. In this section the norm ‖·‖ can be arbitrary.\nAlgorithm 5 Lazy Online Conditional Gradients (LOCG) Require: ft functions, x1 ∈ P start vertex, LPsepP weak linear separation oracle, parameters K, C, b, S, s; diameter D Ensure: xt points 1: for t = 1 to T − 1 do 2: ∇t ← ∇ ft(xt) 3: if t = 1 then 4: h1 ← min{‖∇1‖∗ D, 2 ‖∇1‖∗2 /S} 5: else\n6: ht ← Φt−1 + min { ‖∇t‖∗ D, ‖∇t‖ ∗2\nSt1−s + 2\n√\n‖∇t‖∗2 2St1−s\n(\n‖∇t‖∗2 2St1−s + Φt−1\n)\n}\n7: end if\n8: Φt ← ht+\nCt1−bγ2t 2(1−b)\n1+ γt K\n9: vt ← LPsepP(∑ti=1 ∇ fi(xt), xt, Φt, K) 10: if vt = false then 11: xt+1 ← xt 12: else 13: xt+1 ← (1 − γt)xt + γtvt 14: Φt ← ht − ∑ti=1 fi(xt) + ∑ti=1 fi(xt+1) 15: end if 16: end for\nTheorem 4.1. Let 0 ≤ b, s < 1. Let K > 1 be an accuracy parameter. Assume ft is L-Lipschitz, and smooth with curvature at most Ct−b. Let D := maxy1,y2∈P‖y1 − y2‖ denote the diameter of P in norm ‖·‖. Then the following hold for the points xt computed by Algorithm 5 where x ∗ T is the minimizer of ∑ T t=1 ft:\n(i) With the choice\nγt = t −(1−b)/2,\nthe xt satisfy\n1\nT\nT\n∑ t=1\n( ft(xT)− ft(x∗T)) ≤ AT−(1−b)/2, (11)\nwhere\nA := CK\n2(1 − b) + L(K + 1)D.\n(ii) Moreover, if all the ft are St −s-strongly convex, then with the choice\nγt = t (b+s−2)/3,\nthe xt satisfy\n1\nT\nT\n∑ t=1\n( ft(xT)− ft(x∗T)) ≤ AT−(2(1+b)−s)/3, (12)\nwhere\nA := 2\n(\n(K + 1)(K + 2) L2\nS +\nCK\n2(1− b)\n)\n.\nProof. We prove only Claim (ii), as the proof of Claim (i) is similar and simpler. Let FT := ∑ T t=1 ft. Furthermore, let hT := AT 1−(2(1+b)−s)/3 be T times the right-hand side of Equation (12). In particular, FT is ST-strongly convex, and smooth with curvature at most CFT where\nCFT := CT1−b 1 − b ≥ C T\n∑ t=1\nt−b, ST := ST1−s ≤ S T\n∑ t=1\nt−s. (13)\nWe prove Ft(xt) − Ft(x∗t ) ≤ ht ≤ ht by induction on t. The case t = 1 is clear. Let Φt denote the value of Φt in Line 8, while we reserve Φt to denote its value as used in Line 6. We start by showing Ft(xt+1)− Ft(x∗t ) ≤ Φt ≤ Φt. We distinguish two cases depending on vt from Line 9. If vt is false, then Φt = Φt and the weak separation oracle asserts maxy∈P ∇Ft(xt)(xt − y) ≤ Φt, which combined with the convexity of Ft provides\nFt(xt+1)− Ft(x∗t ) = Ft(xt)− Ft(x∗t ) ≤ ∇Ft(xt)(xt − xt∗) ≤ Φt = Φt.\nOtherwise vt is a vertex of P, then Line 14 and the induction hypothesis provides Ft(xt+1) − Ft(x∗t ) ≤ ht + Ft(xt+1)− Ft(xt) = Φt. To prove Φt ≤ Φt, we apply the smoothness of Ft followed by the inequality provided by the choice of vt:\nFt(xt+1)− Ft(xt)− CFt γ\n2 t\n2 ≤ ∇Ft(xt)(xt+1 − xt) = γt∇Ft(xt)(vt − xt) ≤ − γtΦt K .\nRearranging provides the inequality below.\nΦt = ht + Ft(xt+1)− Ft(xt) ≤ ht − γtΦt\nK +\nCFt γ 2 t\n2 = Φt.\nFor later use, we bound the difference between ht and Φt using the value of parameters, ht ≤ ht, and γt ≤ 1:\nht − Φt ≥ ht − ht +\nCFt γ 2 t\n2\n1 + γtK =\nhtγt K −\nCFt γ 2 t\n2 1 + γtK ≥\nhtγt K −\nCFt γ 2 t\n2\n1 + 1K =\nA − CK 2(1−b)\nK + 1 t[2s−(1+b)]/3.\nWe now apply Ft(xt+1)− Ft(x∗t ) ≤ Φt, together with convexity of ft+1, and the minimality Ft(x∗t ) ≤ Ft(x∗t+1) of x ∗ t , followed by strong convexity of Ft+1:\nFt+1(xt+1)− Ft+1(x∗t+1) ≤ (Ft(xt+1)− Ft(x∗t )) + ( ft+1(xt+1)− ft+1(x∗t+1)) ≤ Φt + ‖∇t+1‖∗ · ‖xt+1 − x∗t+1‖\n≤ Φt + ‖∇t+1‖∗ √ 2\nSt+1 (Ft+1(xt+1)− Ft+1(x∗t+1)).\n(14)\nSolving the quadratic inequality provides\nFt+1(xt+1)− Ft+1(x∗t+1) ≤ Φt + ‖∇t+1‖∗2\nSt+1 + 2\n√ √ √ √\n‖∇t+1‖∗2 2St+1 ( ‖∇t+1‖∗2 2St+1 + Φt ) . (15)\nFrom Equation (14), ignoring the last line, we also obtain Ft+1(xt+1)− Ft+1(x∗t+1) ≤ Φt + ‖∇t+1‖ ∗ D via the estimate ‖xt+1 − x∗t+1‖ ≤ D. Thus Ft+1(xt+1)− Ft+1(x∗t+1) ≤ ht+1, by Line 6, as claimed. Nowwe estimate the right-hand side of Equation (15) by using the actual value of parameters, the estimate ‖∇t+1‖∗ ≤ L and the inequality s + b ≤ 2. Actually, we estimate a proxy for the right-hand side. Note that A was chosen to satisfy the second inequality.\nL2\nSt+1 + 2\n√\nL2\n2St+1 ht ≤\nL2\nSt1−s + 2\n√\nL2\n2St1−s ht ≤\nL2\nS t[2s−(1+b)]/3 + 2\n√\nL2\n2St1−s ht\n=\n(\nL2\nS +\n√\n2 L2\nS A\n) t[2s−(1+b)]/3 ≤ A − CK\n2(1−b) K + 1 t[2s−(1+b)]/3\n≤ ht − Φt ≤ ht − Φt.\nIn particular, L 2 2St+1 + Φt ≤ ht hence combining with Equation (15) we obtain\nht+1 ≤ Φt + L2\nSt+1 + 2\n√\nL2\n2St+1\n(\nL2\n2St+1 + Φt\n)\n≤ Φt + L2\nSt+1 + 2\n√\nL2\n2St+1 ht\n≤ ht ≤ ht+1."
    }, {
      "heading" : "4.1 Stochastic and Adversarial Versions",
      "text" : "Complementing the offline algorithms from Section 3, we will now derive various versions from the online case. The presented cases here are similar to those in Hazan and Kale [2012] and thus we state them without proof.\nFor stochastic cost functions ft, we obtain bounds from Theorem 4.1 (i) similar to [Hazan and Kale, 2012, Theorems 4.1 and 4.3] (with δ replaced by δ/T in the bound to correct an inaccuracy in the original argument). The proof is analogous and hence omitted, but note that ‖y1 − y2‖2 ≤ √ ‖y1 − y2‖1‖y1 − y2‖∞ ≤ √\nk for all y1, y2 ∈ P. Corollary 4.2. Let ft be convex functions sampled i.i.d. with expectation E [ ft] = f ∗, and δ > 0. Assume that the ft are L-Lipschitz in the 2-norm.\n(i) If all the ft are smooth with curvature at most C, then Algorithm 5 applied to the ft (with b = 0) yields with probability 1 − δ\nT\n∑ t=1\nf ∗(xt)− min x∈P\nT\n∑ t=1\nf ∗(x) ≤ O ( C √ T + Lk √ nT log(nT2/δ) log T ) . (16)\n(ii) Without any smoothness assumption, Algorithm 5 (applied to smoothenings of the ft) provides with probability 1 − δ\nT\n∑ t=1\nf ∗(xt)− min x∈P\nT\n∑ t=1\nf ∗(x) ≤ O (√ nLkT2/3 + Lk √ nT log(nT2/δ) log T ) . (17)\nSimilar to [Hazan and Kale, 2012, Theorem 4.4], from Theorem 4.1 (ii) we obtain the following regret\nbound for adversarial cost functions with an analogous proof.\nCorollary 4.3. For any L-Lipschitz convex cost functions ft, Algorithm 5 applied to the functions f̃t(x) := ∇ ft(xt)x + 2L√ k t−1/4‖x − x1‖22 (with b = s = 1/4, C = L √ k, S = L/ √ k, and Lipschitz constant 3L) achieving regret T\n∑ t=1\nft(xt)− min x∈P\nT\n∑ t=1\nft(x) ≤ O(L √ kT3/4) (18)\nwith at most T calls to the weak separation oracle.\nNote that the gradient of the f̃t are easily computed via the formula∇ f̃t(x) = ∇ ft(xt) + 4Lt−1/4(x − x1)/ √ k, particularly because the gradient of the ft need not be recomputed, so that we obtain a weak separation-based stochastic gradient descent algorithm, where we only have access to the ft through a stochastic gradient oracle, while retaining all the favorable properties of the Frank-Wolfe algorithm with a convergence rate O(T−1/4) (c.f., Garber and Hazan [2013])."
    }, {
      "heading" : "5 Experiments",
      "text" : "We implemented and compared Algorithm 2 (LPCG) to the Pairwise Conditional Gradient Algorithm (PCG) in Garber and Meshi [2016] and we also implemented and compared Algorithm 5 (LOCG) to the Online Frank-WolfeAlgorithm (OCG) ofHazan and Kale [2012]. We did not implement the variant in Garber and Hazan [2013] as for the cases considered here the variant in Garber and Meshi [2016] is more efficient; our method applies to both though as shown earlier.\nWe implemented all algorithms in Python 2.7 with critical functions cythonized for performance, employing Numpy and MKL for arithmetic operations. We used these packages from the Anaconda 2.5 distribution.\nWe used Gurobi 6.5 [Gurobi Optimization, 2016] as a black box solver for the weak separation oracle, using a callback function to stop the optimization as soon as a good enough feasible solution has been found. We have used K = 1.1 as multiplicative factor for the weak separation oracle. The parameters for Gurobi were kept at their default settings except for enforcing the time limit of the tests and setting the acceptable duality gap to 10%, allowing Gurobi to terminate early avoiding the expensive proof of optimality. This is a significant speedup in favour of non-lazy algorithms at the cost of accuracy, while neutral to lazy optimization due to the callback. Without this modification, the non-lazy optimizing algorithms were unable to complete even a single iteration for almost all considered problems here, due to the hard optimality proof.\nThe linear optimization oracle over P × P for LPCG was implemented by calling the respective oracle over P twice: once for either component.\nAll experiments were performed on a 16-core machine with Intel Xeon E5-2630 v3 @ 2.40GHz CPUs and 128GB of main memory. While our code does not explicitly use multiple threads, both Gurobi and the numerical libraries use multiple threads internally.\nContrary to the non-lazy version, the lazy algorithms depend on the initial upper bound Φ0. Hence, in the initial phase, the lazy algorithms perform a binary search for Φ0: starting from a conservative initial value, using the update rule Φ0 ← Φ0/2 until the separation oracle returns an improvement for the first time. Obviously, this initial phase is also included in wall-clock time."
    }, {
      "heading" : "5.1 Computational results",
      "text" : "We performed computational tests on a large variety of different polytopes and loss functions. We considered polytopes where the underlying optimization problem is easy (spanning trees), and where it is NP-hard (Maximum Cut, Traveling Salesman Problem, Quadratic Unconstrained Boolean Optimization [Dash, 2013], as well as various instances from MIPLIB [Achterberg et al., 2006, Koch et al., 2011]). Note that in real-world examples state-of-the art solvers like Gurobi or CPLEX can solve these NP-hard problems in reasonable time, and hence enabling real-world learning over complex structure.\nWe tested two types of loss functions: random linear functions cx + b with c ∈ [−1,+1]n and b ∈ [0, 1] and quadratic functions of the form ‖b − x‖22 with b ∈ [0, 1]n, similar to those in [Hazan and Kale, 2012]. For online algorithms, each experiment used a random sequence of 100 different random loss functions.\nWe used various time limits for the experiments. The time limit was enforced separately for the main\ncode, and the oracle code, so in some cases the actual time used can be larger.\nWe will now present the complete set of results for various polytopes. Every figure contains two columns, each reporting one experiment. The first row reports loss in wall-clock time (including time spent by the oracle), the second row contains loss in the number of iterations, and the third one the cumulative number of calls to the optimization oracle for the lazy algorithm. Red line denotes the non-lazy algorithm, and other colors denote lazy optimization.\nWhile we found convergence rates in the number of iterations quite similar (as expected!), we consistently observe a significant speedup in wall-clock time. In particular for many large-scale or hard combinatorial problems, lazy algorithms performed several thousand iterations whereas the non-lazy versions completed only a handful of iterations due to the large time spent for solving the linear optimization problem to optimality. Actually, the observed cache hit rate was in most cases at least 90%, and often even above 99%, leading to a significant overall speedup."
    }, {
      "heading" : "5.1.1 Online Results",
      "text" : "For online conditional gradient algorithms, in every figure the left column uses linear loss functions, the right one uses quadratic loss functions over the same polytope.\nWe used the flow-based formulation for Hamiltonian cycles in graphs, i.e., the traveling salesman problem (TSP) for graphs with 11 and 16 nodes (Figures 1 and 2). While relatively small, the oracle problem can be solved in reasonable time for these instances. For the maximumcut problemwe used the standard formulation of the cut polytope for graphs with 23 and 28 nodes (Figures 3 and 4). Another set of NP-hard instances we tested our algorithm on are the quadratic unconstrained boolean optimization (QUBO) instances defined on Chimera graphs [Dash, 2013], which are available athttp://researcher.watson.ibm.com/researcher/files/us-sanjeebd/chimera-data.zip. The instances are relatively hard albeit their rather small size (Figure 5 and 6). We also performed tests on a path instance from http://lime.cs.elte.hu/~kpeter/data/mcf/netgen/ that were generated with the netgen graph generator (Figure 7). Most of these instances are very large-scale minimum cost flow instances with several hundreds of thousands nodes in the underlying graphs, therefore solving still takes considerable time despite the problem being in P. We tested the MIPLIB [Achterberg et al., 2006, Koch et al., 2011]) instances eil33-2 (Figure 8) and air04 (Figure 9). For the spanning tree problem, we used the well-known extended formulation with O(n3) inequalities for an n-node graph. We considered graphs with 10 and 25 nodes (Figures 10 and 11).\nWe observed that while OCG and LOCG converge comparably in the number of iterations, the lazy LOCG performed significantly more iterations; for hard problems, where linear optimization is costly, and convergence requires a large number of iterations, this leaded LOCG converging much faster in wall-clock time. In extreme cases OCG could not complete even a single iteration. This is due to LOCG only requiring\nsome good enough solution, whereas OCG requires a (near) optimal one, which is reflected in faster oracle calls for LOCG."
    }, {
      "heading" : "5.1.2 Offline Results",
      "text" : "We tested the Pairwise ConditionalGradient AlgorithmonMIPLIB instanceseil33-2, air04, eilB101, nw04, disctom, m100n500k4r1 (Figures 12, 13 and 14) with quadratic loss functions only, as linear optimization immediately finds the optimum of a linear loss function. As we inherit structural restrictions of PCG on the feasible region, the problem repertoire is limited in this case.\nSimilarly to the online case, we observe a significant speedup of LPCG compared to PCG, due to the\nspeedier iteration of the lazy algorithm LPCG."
    }, {
      "heading" : "5.2 Performance improvements, parameter sensitivity, and tuning",
      "text" : ""
    }, {
      "heading" : "5.2.1 Effect of caching",
      "text" : "Asmentioned before, lazy algorithms have two improvements: caching and early termination. Herewe depict the effect of caching in Figure 15, comparing OCG (no caching, no early termination), LOCG (caching and early termination) and LOCG (only early termination). We did not include a caching OCG variant, because caching without early termination does not make much sense: in each iteration a new linear optimization problem has to be solved; previous solutions can hardly be reused as they are unlikely to be optimal for the new linear optimization problem."
    }, {
      "heading" : "5.2.2 Effect of rate amplification",
      "text" : "A major difference between the lazy and non-lazy algorithms is that lazy algorithms converge at a given rate, which is controlled via setting the Φt in Line 8 of Algorithm 5, Line 4 of Algorithm 3, and Line 4 of Algorithm 2. In contrast, the non-lazy algorithms can in principle converge faster as they are parameter free and ‘adjust’ automatically to the underlying function family. However, we are free to choose a more aggressive rate that we might try to prove with lazy algorithms. This can be done by simply scaling Φt with an additional term t−α, right before passing it into the weak separation routine, where α is an adjustment coefficient of the converge rate.\nWe have considered rate amplification only for the online algorithm LOCG, where subexponential con-\nvergence rates leave much room for improvement. We considered the following two possibilities.\nFirst, by choosing a more aggressive but feasible rate of convergence, LOCG will converge at that rate. Note that this rate can be strictly better than the rate achievable by OCG. It is an open question, whether the optimal rate is always achievable via LOCG by a suitable choice of α; we suspect the answer to be in the negative.\nIf the chosen rate is infeasible, i.e., we decrease Φt too fast by having chosen α too large, LOCG will converge to a suboptimal solution. This is expected and reasonable as the weak separation routine fails to produce an improving solution matching the proposed rate and as such returns the last point.\nWe depict the effect of various choices for α in Figure 16. One might argue that the sensitivity to α is undesirable. Therefore, second, we tested a simple dynamical adjustment of α, leading to an overall very smooth and consistent convergence behavior while using an amplified rate. We started with a value α = 1 and whenever in k consecutive calls to the weak separation routine no improving solution is found, we update α ← (1 − ε)α with ε = 0.1. (The values for α and ε are arbitrary.) Similarly, whenever in k consecutive calls to the weak separation routine an improving solution\nis returned, we update α ← (1 + ε)α. This dynamic rate adjustment only depends on k and ε and is rather stable in k. Smaller k values lead to a more agile control, larger values of k to a more conservative one. We depict an example in Figure 17."
    } ],
    "references" : [ {
      "title" : "Regret in online combinatorial optimization",
      "author" : [ "J.-Y. Audibert", "S. Bubeck", "G. Lugosi" ],
      "venue" : "Mathematics of Operations Research,",
      "citeRegEx" : "Audibert et al\\.,? \\Q2013\\E",
      "shortCiteRegEx" : "Audibert et al\\.",
      "year" : 2013
    }, {
      "title" : "Following the perturbed leader for online structured learning",
      "author" : [ "A. Cohen", "T. Hazan" ],
      "venue" : "In Proceedings of the 32nd International Conference on Machine Learning",
      "citeRegEx" : "Cohen and Hazan.,? \\Q2015\\E",
      "shortCiteRegEx" : "Cohen and Hazan.",
      "year" : 2015
    }, {
      "title" : "A note on QUBO instances defined on",
      "author" : [ "S. Dash" ],
      "venue" : "Chimera graphs. preprint arXiv:1306.1202,",
      "citeRegEx" : "Dash.,? \\Q2013\\E",
      "shortCiteRegEx" : "Dash.",
      "year" : 2013
    }, {
      "title" : "An algorithm for quadratic programming",
      "author" : [ "M. Frank", "P. Wolfe" ],
      "venue" : "Naval research logistics quarterly,",
      "citeRegEx" : "Frank and Wolfe.,? \\Q1956\\E",
      "shortCiteRegEx" : "Frank and Wolfe.",
      "year" : 1956
    }, {
      "title" : "A linearly convergent conditional gradient algorithm with applications to online and stochastic optimization",
      "author" : [ "D. Garber", "E. Hazan" ],
      "venue" : "arXiv preprint arXiv:1301.4666,",
      "citeRegEx" : "Garber and Hazan.,? \\Q2013\\E",
      "shortCiteRegEx" : "Garber and Hazan.",
      "year" : 2013
    }, {
      "title" : "Linear-memory and decomposition-invariant linearly convergent conditional gradient algorithm for structured polytopes",
      "author" : [ "D. Garber", "O. Meshi" ],
      "venue" : "arXiv preprint,",
      "citeRegEx" : "Garber and Meshi.,? \\Q2016\\E",
      "shortCiteRegEx" : "Garber and Meshi.",
      "year" : 2016
    }, {
      "title" : "Solving combinatorial games using products, projections and lexicographically optimal bases",
      "author" : [ "S. Gupta", "M. Goemans", "P. Jaillet" ],
      "venue" : "arXiv preprint arXiv:1603.00522,",
      "citeRegEx" : "Gupta et al\\.,? \\Q2016\\E",
      "shortCiteRegEx" : "Gupta et al\\.",
      "year" : 2016
    }, {
      "title" : "Introduction to online convex optimization",
      "author" : [ "E. Hazan" ],
      "venue" : "Foundations and Trends in Optimization,",
      "citeRegEx" : "Hazan.,? \\Q2016\\E",
      "shortCiteRegEx" : "Hazan.",
      "year" : 2016
    }, {
      "title" : "Projection-free online learning",
      "author" : [ "E. Hazan", "S. Kale" ],
      "venue" : "arXiv preprint arXiv:1206.4657,",
      "citeRegEx" : "Hazan and Kale.,? \\Q2012\\E",
      "shortCiteRegEx" : "Hazan and Kale.",
      "year" : 2012
    }, {
      "title" : "Revisiting Frank–Wolfe: Projection-free sparse convex optimization",
      "author" : [ "M. Jaggi" ],
      "venue" : "In Proceedings of the 30th International Conference on Machine Learning",
      "citeRegEx" : "Jaggi.,? \\Q2013\\E",
      "shortCiteRegEx" : "Jaggi.",
      "year" : 2013
    }, {
      "title" : "Efficient algorithms for online decision problems",
      "author" : [ "A. Kalai", "S. Vempala" ],
      "venue" : "Journal of Computer and System Sciences,",
      "citeRegEx" : "Kalai and Vempala.,? \\Q2005\\E",
      "shortCiteRegEx" : "Kalai and Vempala.",
      "year" : 2005
    }, {
      "title" : "Mathematical Programming Computation, 3(2):103–163, 2011",
      "author" : [ "T. Koch", "T. Achterberg", "E. Andersen", "O. Bastert", "T. Berthold", "R.E. Bixby", "E. Danna", "G. Gamrath", "A.M. Gleixner", "S. Heinz", "A. Lodi", "H. Mittelmann", "T. Ralphs", "D. Salvagnin", "D.E. Steffy", "K. Wolter. MIPLIB" ],
      "venue" : "doi: 10.1007/s12532-011-0025-9. URL http://mpc.zib.de/index.php/MPC/article/view/56/28.",
      "citeRegEx" : "Koch et al\\.,? 2010",
      "shortCiteRegEx" : "Koch et al\\.",
      "year" : 2010
    }, {
      "title" : "On the global linear convergence of Frank–Wolfe optimization variants",
      "author" : [ "S. Lacoste-Julien", "M. Jaggi" ],
      "venue" : "Advances in Neural Information Processing Systems,",
      "citeRegEx" : "Lacoste.Julien and Jaggi.,? \\Q2015\\E",
      "shortCiteRegEx" : "Lacoste.Julien and Jaggi.",
      "year" : 2015
    }, {
      "title" : "Constrained minimization methods",
      "author" : [ "E.S. Levitin", "B.T. Polyak" ],
      "venue" : "USSR Computational mathematics and mathematical physics,",
      "citeRegEx" : "Levitin and Polyak.,? \\Q1966\\E",
      "shortCiteRegEx" : "Levitin and Polyak.",
      "year" : 1966
    } ],
    "referenceMentions" : [ {
      "referenceID" : 3,
      "context" : "Hence projectionfree methods gained a lot of attention recently, in particular the Frank-Wolfe algorithm [Frank and Wolfe, 1956] (also known as conditional gradient descent [Levitin and Polyak, 1966]; see also [Jaggi, 2013] for an overview) and its online version [Hazan and Kale, 2012].",
      "startOffset" : 105,
      "endOffset" : 128
    }, {
      "referenceID" : 13,
      "context" : "Hence projectionfree methods gained a lot of attention recently, in particular the Frank-Wolfe algorithm [Frank and Wolfe, 1956] (also known as conditional gradient descent [Levitin and Polyak, 1966]; see also [Jaggi, 2013] for an overview) and its online version [Hazan and Kale, 2012].",
      "startOffset" : 173,
      "endOffset" : 199
    }, {
      "referenceID" : 9,
      "context" : "Hence projectionfree methods gained a lot of attention recently, in particular the Frank-Wolfe algorithm [Frank and Wolfe, 1956] (also known as conditional gradient descent [Levitin and Polyak, 1966]; see also [Jaggi, 2013] for an overview) and its online version [Hazan and Kale, 2012].",
      "startOffset" : 210,
      "endOffset" : 223
    }, {
      "referenceID" : 8,
      "context" : "Hence projectionfree methods gained a lot of attention recently, in particular the Frank-Wolfe algorithm [Frank and Wolfe, 1956] (also known as conditional gradient descent [Levitin and Polyak, 1966]; see also [Jaggi, 2013] for an overview) and its online version [Hazan and Kale, 2012].",
      "startOffset" : 264,
      "endOffset" : 286
    }, {
      "referenceID" : 3,
      "context" : "Hence projectionfree methods gained a lot of attention recently, in particular the Frank-Wolfe algorithm [Frank and Wolfe, 1956] (also known as conditional gradient descent [Levitin and Polyak, 1966]; see also [Jaggi, 2013] for an overview) and its online version [Hazan and Kale, 2012]. These methods eschew the projection step and rather use a linear optimization oracle to stay within the feasible region. While convergence rates and regret bounds are often suboptimal, in many cases the gain due to only having to solve a single linear optimization problem over the feasible region in every iteration still leads to significant computational advantages (see e.g., [Hazan and Kale, 2012, Section 5]). This led to conditional gradients algorithms being often used for e.g., online optimization andmore generallymachine learning, especially because they also naturally generate sparse distributions over the extreme points of the feasible region. Further increasing the relevance of these methods, it was shown recently in Garber and Hazan [2013], Lacoste-Julien and Jaggi [2015], Garber and Meshi [2016] that conditional gradient methods often achieve linear convergence.",
      "startOffset" : 106,
      "endOffset" : 1048
    }, {
      "referenceID" : 3,
      "context" : "Hence projectionfree methods gained a lot of attention recently, in particular the Frank-Wolfe algorithm [Frank and Wolfe, 1956] (also known as conditional gradient descent [Levitin and Polyak, 1966]; see also [Jaggi, 2013] for an overview) and its online version [Hazan and Kale, 2012]. These methods eschew the projection step and rather use a linear optimization oracle to stay within the feasible region. While convergence rates and regret bounds are often suboptimal, in many cases the gain due to only having to solve a single linear optimization problem over the feasible region in every iteration still leads to significant computational advantages (see e.g., [Hazan and Kale, 2012, Section 5]). This led to conditional gradients algorithms being often used for e.g., online optimization andmore generallymachine learning, especially because they also naturally generate sparse distributions over the extreme points of the feasible region. Further increasing the relevance of these methods, it was shown recently in Garber and Hazan [2013], Lacoste-Julien and Jaggi [2015], Garber and Meshi [2016] that conditional gradient methods often achieve linear convergence.",
      "startOffset" : 106,
      "endOffset" : 1081
    }, {
      "referenceID" : 3,
      "context" : "Hence projectionfree methods gained a lot of attention recently, in particular the Frank-Wolfe algorithm [Frank and Wolfe, 1956] (also known as conditional gradient descent [Levitin and Polyak, 1966]; see also [Jaggi, 2013] for an overview) and its online version [Hazan and Kale, 2012]. These methods eschew the projection step and rather use a linear optimization oracle to stay within the feasible region. While convergence rates and regret bounds are often suboptimal, in many cases the gain due to only having to solve a single linear optimization problem over the feasible region in every iteration still leads to significant computational advantages (see e.g., [Hazan and Kale, 2012, Section 5]). This led to conditional gradients algorithms being often used for e.g., online optimization andmore generallymachine learning, especially because they also naturally generate sparse distributions over the extreme points of the feasible region. Further increasing the relevance of these methods, it was shown recently in Garber and Hazan [2013], Lacoste-Julien and Jaggi [2015], Garber and Meshi [2016] that conditional gradient methods often achieve linear convergence.",
      "startOffset" : 106,
      "endOffset" : 1106
    }, {
      "referenceID" : 5,
      "context" : "separation is significantly weaker than approximate minimization; the latter has been already considered in Jaggi [2013]. A (weak) separation oracle can be realized by a single call to a linear optimization oracle, however with two important differences.",
      "startOffset" : 108,
      "endOffset" : 121
    }, {
      "referenceID" : 7,
      "context" : ", 2013, Neu and Bartók, 2013]), see [Hazan, 2016] for an exhaustive overview.",
      "startOffset" : 36,
      "endOffset" : 49
    }, {
      "referenceID" : 2,
      "context" : "Related Work In the offline setting we mimick the same setups as in Garber and Hazan [2013], Garber and Meshi [2016] respectively.",
      "startOffset" : 68,
      "endOffset" : 92
    }, {
      "referenceID" : 2,
      "context" : "Related Work In the offline setting we mimick the same setups as in Garber and Hazan [2013], Garber and Meshi [2016] respectively.",
      "startOffset" : 68,
      "endOffset" : 117
    }, {
      "referenceID" : 2,
      "context" : "Related Work In the offline setting we mimick the same setups as in Garber and Hazan [2013], Garber and Meshi [2016] respectively. In the online setup we mimick the setup of Hazan and Kale [2012]. Combinatorial convex optimization has been investigated in a long line of works (see e.",
      "startOffset" : 68,
      "endOffset" : 196
    }, {
      "referenceID" : 4,
      "context" : "We will first show how the Frank-Wolfe style algorithms in Garber and Hazan [2013] and Garber and Meshi [2016] can be lazified by means of a weak separation oracle as given in Oracle 1.",
      "startOffset" : 59,
      "endOffset" : 83
    }, {
      "referenceID" : 4,
      "context" : "We will first show how the Frank-Wolfe style algorithms in Garber and Hazan [2013] and Garber and Meshi [2016] can be lazified by means of a weak separation oracle as given in Oracle 1.",
      "startOffset" : 59,
      "endOffset" : 111
    }, {
      "referenceID" : 9,
      "context" : "1 Lazy Conditional Gradient: a basic example We start with lazifying the simplest Conditional Gradent algorithm, adapting the argument of the non-lazy version from Jaggi [2013]. While the vanilla version has suboptimal convergence rate O(1/T), its simplicity makes it an illustrative example of the main idea of lazification.",
      "startOffset" : 164,
      "endOffset" : 177
    }, {
      "referenceID" : 5,
      "context" : "2 Lazy Pairwise Conditional Gradients In this section we provide a lazy variant (Algorithm 2) of the Pairwise Conditional Gradient algorithm from Garber and Meshi [2016], using separation instead of linear optimization.",
      "startOffset" : 146,
      "endOffset" : 170
    }, {
      "referenceID" : 4,
      "context" : "3 Lazy Local Conditional Gradients In this sectionwe provide a lazy version (Algorithm3) of the conditional gradient algorithmfromGarber and Hazan [2013]. Let P ⊆ Rn be any polytope, D denote an upper bound on the l2-diameter of P, and μ ≥ 1 be the affine invariant of P from Garber and Hazan [2013].",
      "startOffset" : 130,
      "endOffset" : 154
    }, {
      "referenceID" : 4,
      "context" : "3 Lazy Local Conditional Gradients In this sectionwe provide a lazy version (Algorithm3) of the conditional gradient algorithmfromGarber and Hazan [2013]. Let P ⊆ Rn be any polytope, D denote an upper bound on the l2-diameter of P, and μ ≥ 1 be the affine invariant of P from Garber and Hazan [2013]. As the algorithm is not affine invariant by nature, we need a non-invariant version of smoothness: Recall that a convex function f is β-smooth if f (y)− f (x) ≤ ∇ f (x)(y − x) + β‖y − x‖/2.",
      "startOffset" : 130,
      "endOffset" : 300
    }, {
      "referenceID" : 4,
      "context" : "As an intermediary step, we first implement a local weak separation oracle in Algorithm4, a local version of Oracle 1, analogously to the local linear optimization oracle in Garber and Hazan [2013]. To this end, we recall a technical lemma from Garber and Hazan [2013].",
      "startOffset" : 174,
      "endOffset" : 198
    }, {
      "referenceID" : 4,
      "context" : "As an intermediary step, we first implement a local weak separation oracle in Algorithm4, a local version of Oracle 1, analogously to the local linear optimization oracle in Garber and Hazan [2013]. To this end, we recall a technical lemma from Garber and Hazan [2013]. Lemma 3.",
      "startOffset" : 174,
      "endOffset" : 269
    }, {
      "referenceID" : 7,
      "context" : "In this section we lazify the online conditional gradient algorithm of Hazan and Kale [2012] over arbitrary polytopes P = {x ∈ Rn | Ax ≤ b}, resulting in Algorithm 5.",
      "startOffset" : 71,
      "endOffset" : 93
    }, {
      "referenceID" : 7,
      "context" : "The presented cases here are similar to those in Hazan and Kale [2012] and thus we state them without proof.",
      "startOffset" : 49,
      "endOffset" : 71
    }, {
      "referenceID" : 4,
      "context" : ", Garber and Hazan [2013]).",
      "startOffset" : 2,
      "endOffset" : 26
    }, {
      "referenceID" : 4,
      "context" : "We implemented and compared Algorithm 2 (LPCG) to the Pairwise Conditional Gradient Algorithm (PCG) in Garber and Meshi [2016] and we also implemented and compared Algorithm 5 (LOCG) to the Online Frank-WolfeAlgorithm (OCG) ofHazan and Kale [2012].",
      "startOffset" : 103,
      "endOffset" : 127
    }, {
      "referenceID" : 4,
      "context" : "We implemented and compared Algorithm 2 (LPCG) to the Pairwise Conditional Gradient Algorithm (PCG) in Garber and Meshi [2016] and we also implemented and compared Algorithm 5 (LOCG) to the Online Frank-WolfeAlgorithm (OCG) ofHazan and Kale [2012]. We did not implement the variant in Garber and Hazan [2013] as for the cases considered here the variant in Garber and Meshi [2016] is more efficient; our method applies to both though as shown earlier.",
      "startOffset" : 103,
      "endOffset" : 248
    }, {
      "referenceID" : 4,
      "context" : "We did not implement the variant in Garber and Hazan [2013] as for the cases considered here the variant in Garber and Meshi [2016] is more efficient; our method applies to both though as shown earlier.",
      "startOffset" : 36,
      "endOffset" : 60
    }, {
      "referenceID" : 4,
      "context" : "We did not implement the variant in Garber and Hazan [2013] as for the cases considered here the variant in Garber and Meshi [2016] is more efficient; our method applies to both though as shown earlier.",
      "startOffset" : 36,
      "endOffset" : 132
    }, {
      "referenceID" : 2,
      "context" : "We considered polytopes where the underlying optimization problem is easy (spanning trees), and where it is NP-hard (Maximum Cut, Traveling Salesman Problem, Quadratic Unconstrained Boolean Optimization [Dash, 2013], as well as various instances from MIPLIB [Achterberg et al.",
      "startOffset" : 203,
      "endOffset" : 215
    }, {
      "referenceID" : 8,
      "context" : "We tested two types of loss functions: random linear functions cx + b with c ∈ [−1,+1]n and b ∈ [0, 1] and quadratic functions of the form ‖b − x‖22 with b ∈ [0, 1]n, similar to those in [Hazan and Kale, 2012].",
      "startOffset" : 187,
      "endOffset" : 209
    }, {
      "referenceID" : 2,
      "context" : "Another set of NP-hard instances we tested our algorithm on are the quadratic unconstrained boolean optimization (QUBO) instances defined on Chimera graphs [Dash, 2013], which are available athttp://researcher.",
      "startOffset" : 156,
      "endOffset" : 168
    } ],
    "year" : 2017,
    "abstractText" : "Conditional gradient algorithms (also often called Frank-Wolfe algorithms) are popular due to their simplicity of only requiring a linear optimization oracle and more recently they also gained significant traction for online learning. While simple in principle, inmany cases the actual implementation of the linear optimization oracle is costly. We show a general method to lazify various conditional gradient algorithms, which in actual computations leads to several orders of magnitude of speedup in wall-clock time. This is achieved by using a faster separation oracle instead of a linear optimization oracle, relying only on few linear optimization oracle calls.",
    "creator" : "LaTeX with hyperref package"
  }
}