{
  "name" : "1704.02239.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "Échantillonnage de signaux sur graphes via des processus déterminantaux",
    "authors" : [ "Nicolas TREMBLAY", "Simon BARTHELMÉ", "Pierre-Olivier AMBLARD" ],
    "emails" : [ "prenom.nom@gipsa-lab.fr" ],
    "sections" : [ {
      "heading" : "1 Introduction",
      "text" : "Étant donnée une certaine classe de signaux, échantillonner consiste à mesurer un signal un nombre de fois suffisant pour une certaine tâche, e.g. à des fins de reconstruction. Pour les signaux définis sur des graphes, une classe de régularité souvent utilisée est celle des signaux à bande limitée k (cf la définition 1). Dans ce contexte, il existe deux types de méthodes d’échantillonnage : i) celles qui calculent les k premiers modes de Fourier du graphe et cherchent via des heuristiques k nœuds qui les discriminent tous [2], ii) celles qui s’affranchissent de ce calcul, et qui soit cherchent un nombre de nœuds proche de k et résolvent des problèmes combinatoires qui ne passent pas à l’échelle [3], soit s’autorisent un nombre de nœuds de l’ordre de O(k log k) et permettent de passer à l’échelle via un échantillonnage iid adapté au graphe [4], soit via des marches aléatoires sur graphe spécifiques [5]. Contributions. Nous proposons une méthode basée sur les processus ponctuels déterminantaux (PPD) [6], des processus aléatoires connus pour favoriser la diversité des échantillons. Nous adaptons un algorithme d’échantillonnage de PPD, et montrons comment cet algorithme peut être utilisé dans le cadre de l’échantillonnage des signaux à bande limitée sur graphe."
    }, {
      "heading" : "2 Notations et objectif",
      "text" : "Les matrices sont en majuscule, e.g. K ; les vecteurs en minuscules et en gras, e.g. x ; les ensembles en cursive, e.g. A ; KA,B est la restriction de K aux lignes (resp. colonnes) indexées par les éléments deA (resp. B) ; enfin : KA = KA,A. On note δs le vecteur dont les entrées sont nulles sauf en s, et In la matrice identité de dimension n. Soit G un graphe composé de N nœuds interconnectés selon la matrice d’adjacence W ∈\nRN×N tel que Wij = Wji > 0 représente le poids associé au lien connectant i à j. Notons D la matrice diagonale des degrés : on a Dii = ∑ j Wij . Le laplacien associé à G s’écrit L = D−W ∈ RN×N , il est semi-défini positif et se diagonalise en L = UΛUᵀ, où U = (u1|u2| . . . |uN ) ∈ RN×N est la matrice de ses vecteurs propres et Λ = diag(λ1, λ2, . . . , λN ) ∈ RN×N la matrice diagonale de ses valeurs propres, rangées dans l’ordre croissant 0 = λ1 6 λ2 6 . . . 6 λN . Par analogie au traitement du signal discret classique, ui est considéré comme le i-ème mode de Fourier du graphe [7]. Pour k ∈ N∗, on définit Uk = (u1| . . . |uk) ∈ RN×k la concaténation des k premiers modes de Fourier du graphe. Un signal à bande limitée se définit alors :\nDéfinition 1 (Signal à bande limitée k). Un signal x ∈ RN défini sur les nœuds d’un graphe G est à bande limitée k ∈ N∗ si x ∈ span(Uk), i.e., ∃ α ∈ Rk tel que x = Ukα.\nEn notant m le nombre de mesures, échantillonner consiste à choisir un ensemble de m nœuds A = {s1, . . . , sm}. Notons M = (δs1 |δs2 | . . . |δsm)ᵀ ∈ Rm×N la matrice de mesure associée : le signal x ∈ RN mesuré en A s’écrit\ny = Mx+ n ∈ Rm, (1) où n ∈ Rm est un bruit de mesure. Étant donné que x est supposé être à bande limitée k, on le reconstruit à partir de sa mesure y en calculant xrec = Uk(MUk)†y, où (MUk)† est le pseudo-inverse de Moore-Penrose de MUk ∈ Rm×k. Notons σ1 6 . . . 6 σk les valeurs singulières de MUk. Le signal x est parfaitement reconstructible (au bruit près) à partir de y si UᵀkM ᵀMUk est inversible, i.e., si σ21 > 0. Dans ce cas :\nxrec = Uk(U ᵀ kM ᵀMUk) −1UᵀkM ᵀy (2)\n= x+ Uk(U ᵀ kM ᵀMUk) −1UᵀkM ᵀn. (3)\nar X\niv :1\n70 4.\n02 23\n9v 2\n[ cs\n.D S]\n5 J\nul 2\nAlgorithm 1 Échantillonner un m-PPD à noyau K [8, Sec 2.4] Entrée : K,m S ← ∅, définir p0 = diag(K) ∈ RN p← p0 for n = 1, . . . ,m do :\n· Tirer sn avec probabilité P(s) = p(s)/ ∑\ni p(i) · S ← S ∪ {sn} · Mettre à jour p : ∀i p(i) = p0(i)− KᵀS,iK−1S KS,i\nend for Sortie : A ← S.\nParmi tous les choix possibles deA (et donc de M) qui vérifient σ21 > 0, lesquels sont optimaux? Il existe plusieurs définitions d’optimalité [5], nous nous intéressons ici à la suivante :\nAMV = arg max A s.t. |A|=k k∏ i=1 σ2i , (4)\noù “MV” signifie “volume maximal” : en effet, en maximisant le produit des valeurs singulières, on maximise le déterminant de UᵀkM\nᵀMUk, c’est-à-dire le volume formé par les k lignes échantillonnées de Uk. TrouverAMV est NP-complet [1]. Notre objectif est de s’en approcher, c’est-à-dire : trouver un ensemble de taille k (comme AMV) ou proche de k tel qu’on ait la meilleure reconstruction possible des signaux à bande limitée k."
    }, {
      "heading" : "3 Processus déterminantaux",
      "text" : "Notons [N ] l’ensemble des sous-ensembles de {1, . . . , N} et K ∈ RN×N une matrice semi-définie positive (SDP). On convient que det(∅) = 1. Définition 2 (m-PPD). Considérons un processus ponctuel, i.e., un processus qui tire aléatoirement un ensemble A ∈ [N ]. Ce processus est un m-PPD à noyau K si : i) P(A) = 0, pour tout A tel que |A| 6= m. ii) P(A) = 1Z det(KA), pour tout A tel que |A| = m, où Z est la constante de normalisation.\nProposition 1. Si K est un noyau de projection, i.e., K = XXᵀ avec X ∈ RN×d et XᵀX = Id, et si d > m, alors l’algorithme 1 échantillonne un m-PPD à noyau K. Démonstration. Notons Sn (resp. pn(i)) l’ensemble des n échantillons obtenus (resp. la valeur de p(i)) à l’issue de l’étape n de la boucle de l’algorithme 1. On a : Sn = Sn−1 ∪ {sn}. En utilisant le complément de Schur, on a : ∀n ∈ [1,m] ,∀i, det ( KSn−1∪{i} ) = ( Ki,i − KᵀSn−1,iK −1 Sn−1KSn−1,i ) det ( KSn−1\n) = pn−1(i) det ( KSn−1 ) . (5)\nÀ partir de (5), et sachant que i) K est SDP : ∀S, det(KS) > 0, ii) d > m, on peut montrer que pn(i) > 0 et ∑ i pn(i) 6= 0, c’est-à-dire qu’à chaque itération de la boucle, la probabilité P(s) est bien définie. La boucle étant répétée m fois, la sortie de l’algorithme, notée A, est nécessairement de taille m, en accord avec le point i) de la Déf. 2. Enfin, montrons que P(A) est conforme au point ii). Par construction de A :\nP(A) = m∏ l=1 P(sl|s1, s2, . . . , sl−1) = m∏ l=1 pl−1(sl)∑N i=1 pl−1(i) . (6)\nAlgorithm 2 Échantillonner un m-PPD, algorithme équivalent Entrée : K = [k1, . . . ,kN ],m S ← ∅, définir p = diag(K) ∈ RN for n = 1, . . . ,m do :\n· Tirer sn avec probabilité P(s) = p(s)/ ∑\ni p(i) · S ← S ∪ {sn} · Calculer fn = ksn − ∑n−1 l=1 flfl(sn)\n· Normaliser fn ← fn/ √ fn(sn)\n· Mettre à jour p : ∀i p(i)← p(i)− fn(i)2 end for Sortie : A ← S.\nOr, en écrivant (5) pour i = sn, et en itérant, on obtient :∏m l=1 pl−1(sl) = det(KA). Reste à montrer que le dénominateur de (6) ne dépend pas des échantillons choisis. C’est là où l’hypothèse d’un noyau de projection est essentielle. On a :\n∀l ∈ [1,m], N∑ i=1 pl−1(i) = N∑ i=1 p0(i)− N∑ i=1 KᵀSl−1,iK −1 Sl−1KSl−1,i\nOn a ∑N\ni=1 p0(i) = Tr(XX ᵀ) = Tr(XᵀX) = d. De plus, soit M\nla matrice de mesure associée à Sl−1 : N∑ i=1 KᵀSl−1,iK −1 Sl−1KSl−1,i = Tr ( XXᵀMᵀ(MXXᵀMᵀ)−1MXXᵀ ) = Tr ( (MXXᵀMᵀ)−1MXXᵀXXᵀM ) = Tr(Il−1) = l − 1,\npar invariance de la trace aux permutations circulaires. Ainsi :\nP(A) = 1 Z det(KA) avec Z = m∏ l=1 d− l + 1, (7)\nce qui termine la preuve.\nAMV, l’ensemble à approcher, est l’ensemble le plus probable du m-PPD (avec m = k) à noyau Kk = UkU ᵀ k . Si nous avons les ressources pour calculer Uk, une première stratégie d’échantillonnage est donc l’Alg. 1 appliqué à Kk. Dans le cas contraire, nous proposons dans la suite un nouvel algorithme d’échantillonnage de m-PPD, de complexité inférieure d’un facteurm, qui permet d’appliquer des techniques d’approximation polynomiale, évitant ainsi toute étape de diagonalisation."
    }, {
      "heading" : "4 Approximation via des filtres sur graphe",
      "text" : ""
    }, {
      "heading" : "4.1 Réécriture de l’algorithme d’échantillonnage",
      "text" : "Proposition 2. L’algorithme 2 est équivalent à l’algorithme 1 : il échantillonne aussi un m-PPD à noyau de projection K. Démonstration. Considérons Sn,Sn−1, pn(i) définis comme précédemment et montrons que les pn(i) dans les boucles des deux algorithmes sont égaux. Dans l’Alg. 2 : pn(i) = pn−1(i)− fn(i) 2 = p0(i) − ∑n l=1 fl(i) 2 (où les {fi} sont définis dans l’algorithme ; notamment : f1 = ks1 ). En comparant avec pn(i) obtenu dans l’Alg. 1, il suffit de montrer que :\n∀n∀i n∑\nl=1\nfl(i) 2 = KᵀSn,iK −1 Sn KSn,i. (8)\nNous allons montrer plus généralement que :\n∀n∀i, j n∑\nl=1\nfl(i)fl(j) = K ᵀ Sn,iK −1 Sn KSn,j . (9)\nPour ce faire, nous proposons une récurrence. Initialisation. C’est vrai pour n = 1, où Sn est réduit à {s1} : ∀i, j KᵀSn,iK −1 Sn KSn,j = Ks1,iKs1,j/Ks1,s1 = f1(i)f1(j).\nHypothèse. Supposons que (9) est vraie à l’étape n− 1. Récurrence. Montrons qu’elle est également vraie à l’étape n. En utilisant l’identité de Woodbury sur K−1Sn , on montre que :\nKᵀSn,iK −1 Sn KSn,j = K ᵀ Sn−1,iK −1 Sn−1KSn−1,j +\nzn(i)zn(j)\nzn(sn) ,\noù zn(i) = Ksn,i − KᵀSn−1,snK −1 Sn−1KSn−1,i. En remplaçant KᵀSn−1,iK −1 Sn−1KSn−1,j par ∑n−1 l=1 fl(i)fl(j) grâce à l’hypothèse, il nous reste à montrer que :\n∀i, j fn(i)fn(j) = zn(i)zn(j)\nzn(sn) . (10)\nOr, par construction dans l’Algorithme 2, fn(i) s’écrit :\n∀i fn(i) = Ksn,i − ∑n−1 l=1 fl(i)fl(sn)√\nKsn − ∑n−1 l=1 fl(sn) 2 . (11)\nEn utilisant une seconde fois l’hypothèse (2), on montre que :\n∀i fn(i) = zn(i)√ zn(sn) , (12)\nce qui prouve (10) et termine la preuve.\nL’algorithme 2 est un algorithme général pour échantillonner unm-PPD à noyau de projection. Sa complexité est enO(Nm2), alors que la complexité de l’algorithme 1 est en O(Nm3). Notons que des idées similaires pour réduire la complexité d’un facteur m existent dans la littérature (par exemple dans [9]) mais sous des formes un peu cachées, et, à notre connaissance, n’ont jamais été vraiment explicitées dans le cas discret."
    }, {
      "heading" : "4.2 Approcher l’échantillonnage d’un PPD",
      "text" : "Nous allons voir que la manière dont l’algorithme 2 fait appel à K permet de tirer profit d’approximations polynomiales usuellement utilisées lors d’opérations de filtrage sur graphe. Rappelons que nous considérons le m-PPD associé au noyau Kk. Or : Kk = Uhk(Λ)Uᵀ, où hk(Λ) = diag(hk(λ1), . . . , hk(λN )) et hk(λ) est tel que hk(λ) = 1 si λ 6 λk et hk(λ) = 0 sinon. En traitement du signal sur graphes, Kk est un filtre passe-bas idéal de fréquence de coupure λk. Approximation polynomiale. [7] Considérons le polynôme de Tchebychev h̃k de degré r qui approche au mieux hk :\n∀λ ∈ [0, λN ] h̃k(λ) = r∑\nl=1\nαlλ l ' hk(λ).\nOn a : Kk ' Uh̃k(Λ)Uᵀ = r∑\nl=1\nαlUΛ lUᵀ = r∑ l=1 αlL l = h̃k(L).\nFiltrage rapide sur graphe. On ne calcule jamais explicitement h̃k(L) qui est en général dense de taille N × N . En revanche, étant donné un signal x défini sur le graphe, le signal filtré par hk, Kkx, est approché par h̃k(L)x = ∑r l=1 αlL lx,\nAlgorithm 3 Échantillonnage approché d’un m-PPD à noyau K = hk(L)\nEntrée : L, hk(λ), r, m Calculer λN , la plus grande valeur propre de L Calculer le polynôme h̃k de degré r approchant hk sur [0, λN ] Estimer p = diag(h̃k(L)) ∈ RN comme vu dans la Sec. 4.2 for n = 1, . . . ,m do :\n· Tirer sn ← argmax(p) · Calculer fn = h̃k(L)δsn − ∑n−1 l=1 flfl(sn)\n· Normaliser fn ← fn/ √ fn(sn)\n· Mettre à jour p(i)← p(i)− fn(i)2 end for Output : A = {s1, . . . , sm}\nqui se calcule via r multiplications matrice-vecteur si bien que le nombre d’opérations nécessaires pour filtrer un signal est de l’ordre de r|E| où |E| est le nombre de liens du graphe. Estimation de la diagonale de Kk. Soit R ∈ RN×n une matrice contenant n signaux aléatoires gaussiens de moyenne nulle et de variance 1/n. Notons que :\nE (∥∥∥δᵀi h̃k(L)R∥∥∥2) = δᵀi h̃k(L)E(RRᵀ)h̃k(L)δi (13) = δᵀi (h̃k(L)) 2δi ' δᵀi K2kδi = Kk(i, i) (14)\nLa ième valeur de la diagonale de Kk, p0(i), est donc approchée par la norme de la ième ligne de h̃k(L)R, i.e. :\np0(i) ' ∥∥∥δᵀi h̃k(L)R∥∥∥2 , (15)\net, via le lemme de Johnson-Lindenstrauss, on montre qu’un nombre de signaux aléatoires n = O(logN) est suffisant pour avoir une estimation convenable avec haute probabilité [10]. Algorithme d’approximation. On souhaite approcher l’algorithme 2 avec entrée Kk sans avoir à calculer Uk. Pour ce faire, on suit l’algorithme 3 en lui donnant comme entrée 1 L, hk(λ), r = 50 etm le nombre d’échantillons souhaité. Au lieu d’accéder directement à la diagonale d’un noyau K connu, on l’estime à l’aide de l’équation (15). Puis, au lieu d’accéder aux colonnes ks directement, on les estime via le filtrage rapide associé : ks ' h̃k(L)δs. Au vu des erreurs d’approximation successives, l’écart entre les {fl} calculés au cours des algorithmes 2 et 3 ne cesse de s’accroı̂tre au fur et à mesure de la boucle. Pour stabiliser l’algorithme 3 : i) le nouvel échantillon est celui qui maximise p (mise à part l’estimation de la diagonale de K, l’algorithme n’est donc plus aléatoire) ; ii) et on s’autorise m > k (ce qui n’a pas de sens pour l’algorithme 2 appliqué à Kk qui est de rang k). Aussi, en pratique, on fait quelques modifications mineures : i) après la mise à jour de p, on force p(si) = 0 pour tous les échantillons si déjà choisis ; ii) lors de la normalisation de fn, si fn(sn) 6 0 à cause de l’approximation, alors on normalise fn par √ ‖fn‖ /N . Ces choix sont cependant arbitraires : une comparaison rigoureuse des différentes possibilités de stabilisation fera l’objet de travaux futurs.\n1. pour avoir hk(λ), il faut λk , que nous estimons en suivant [4, Sec. 4.2]."
    }, {
      "heading" : "5 Simulations",
      "text" : "Trois graphes. Nous considérons le graphe routier du Minnesota (N = 2642), le graphe correspondant au maillage 3D d’un objet (graphe “Bunny” avecN = 2503), et une réalisation d’un graphe aléatoire avec communautés issue du modèle stochastique par blocs (MSB) avec N = 1000, 10 communautés de même taille et de paramètre de structure = c/4, où c correspond à la limite où les structures en communautés ne sont plus détectables ; et plus est petit, plus la structure en communautés est forte. Voir par exemple [5, sec. 4] pour des détails sur ; [4, Fig. 1] pour des illustrations des deux premiers graphes. Pour générer les signaux à bande limitée. Dans tous ces exemples, nous choisissons k = 10. Chaque signal x à bande limitée k est généré en calculant Uk, puis en calculant x = Ukα où α ∈ Rk est tiré aléatoirement selon une gaussienne G(0, 1), puis en normalisant x pour qu’il soit de norme 1. Les différentes méthodes d’échantillonnage comparées. On compare 5 méthodes d’échantillonnage : i) l’échantillonnage iid uniforme sans remise, ii) l’échantillonnage iid selon p = diag(Kk) sans remise (comme dans [4]), iii) la même stratégie mais avec une distribution p ' diag(Kk) estimée via (15), iv) l’échantillonnage dépendant en suivant l’algorithme 3, et v) l’échantillonnage selon le PPD idéal, c’est-à-dire en suivant l’algorithme 1 avec la légère modification qu’à chaque itération de la boucle on tire l’échantillon qui maximise la probabilité (cela donne de meilleures performances de reconstruction dans les cas testés). Les quatre premières méthodes peuvent échantillonner un nombre quelconque de nœudsm ; la dernière échantillonne nécessairement k nœuds. Le bruit de mesure n ∈ Rm est tiré selon une Gaussienne de moyenne nulle et d’écart-type σ, et est ajouté à la mesure du signal, comme dans (1). On fixe σ = 10−3. Reconstruction des signaux échantillonnés. Quelle que soit la méthode choisie, on reconstruit les signaux avec (2), c’està-dire avec la connaissance de Uk. Il existe des moyens de reconstruction qui ne nécessitent pas Uk (voir [4]) ; mais nous souhaitons ici comparer exclusivement l’échantillonnage. Discussion des résultats. La Fig. 1 montre que notre méthode approche la performance du PPD à noyau Kk plus rapidement que les autres, dès m = O(k). Pour le graphe du Minnesota, à petit m, notre performance est moindre. Ceci dit, nous retrouvons une meilleure performance pour d’autres choix de k. De nombreuses expériences ont été menées sur d’autres réalisations du MSB, avec d’autres valeurs de k (différentes de k = 10 choisie ici), et σ, et des communautés de taille hétérogène : nous trouvons toujours des comportements similaires."
    }, {
      "heading" : "6 Conclusion",
      "text" : "Nous proposons l’algorithme 2, une réécriture moins coûteuse de l’algorithme 1 d’échantillonnage dem-DPP à noyau de projection. Dans les cas où le noyau est de la forme K = hk(L) où L est une matrice diagonalisable (de préférence parcimonieuse), nous proposons l’algorithme 3 qui, via des approximations polynomiales, permet d’approcher l’échantillonnage du m-PPD associé à K sans jamais calculer explicitement K, potentiellement dense, et en évitant tout calcul de diagonalisation de L. Nous illustrons avec succès l’intérêt de cet algorithme pour l’échantillonnage de signaux sur graphe à bande limitée. Remerciements. Ce travail a été en partie soutenu par le LabEx PERSYVAL-Lab (ANR-11-LABX-0025-01), l’ANR GenGP (ANR-16-CE23-0008), le LIA CNRS/Melbourne Univ Geodesic. Références [1] A. Çivril, M. Magdon-Ismail. On selecting a maximum volume submatrix of a matrix and related problems. Theoretical Computer Science, no. 47, vol. 410, p. 4801–4811, 2009. [2] S. Chen, R. Varma, A. Sandryhaila, J. Kovacevic. Discrete Signal Processing on Graphs : Sampling Theory. IEEE Transactions on Signal Processing, no. 24, vol. 63, p. 6510–6523, 2015. [3] A. Anis, A. Gadde, A. Ortega. Efficient Sampling Set Selection for Bandlimited Graph Signals Using Graph Spectral Proxies. IEEE Transactions on Signal Processing, no. 14, vol. 64, p. 3775–3789, 2016. [4] G. Puy, N. Tremblay, R. Gribonval, P. Vandergheynst. Random sampling of bandlimited signals on graphs. Applied and Computational Harmonic Analysis, in press, 2016. [5] N. Tremblay, P-0. Amblard, S. Barthelmé. Graph sampling with determinantal processes. arXiv preprint, 1703.01594, 2017. [6] A. Kulesza, B. Taskar, Determinantal point processes for machine learning. Found. and Trends in Mach. Learn., no. 2, vol. 5, p. 123–286, 2012. [7] D. Shuman, S. Narang, P. Frossard, A. Ortega, P. Vandergheynst, The emerging field of signal processing on graphs : Extending highdimensional data analysis to networks and other irregular domains. IEEE Signal Processing Magazine, no. 3, vol. 30, p. 83–98, 2013. [8] R. Bardenet, A. Hardy, Monte Carlo with determinantal point processes. arXiv preprint, 1605.00361, 2016. [9] F. Lavancier, J. Moller, E. Rubak, Determinantal point process models and statistical inference. Journal of the Royal Statistical Society : Series B (Statistical Methodology), no. 4, vol. 77, p. 853–877, 2015 [10] N. Tremblay, G. Puy, R. Gribonval, P. Vandergheynst. Accelerated spectral clustering using graph filtering of random signals. ICASSP, 2016."
    } ],
    "references" : [ {
      "title" : "On selecting a maximum volume submatrix of a matrix and related problems",
      "author" : [ "A. Çivril", "M. Magdon-Ismail" ],
      "venue" : "Theoretical Computer Science, no. 47, vol. 410, p. 4801–4811",
      "citeRegEx" : "1",
      "shortCiteRegEx" : null,
      "year" : 2009
    }, {
      "title" : "Discrete Signal Processing on Graphs : Sampling Theory",
      "author" : [ "S. Chen", "R. Varma", "A. Sandryhaila", "J. Kovacevic" ],
      "venue" : "IEEE Transactions on Signal Processing, no. 24, vol. 63, p. 6510–6523",
      "citeRegEx" : "2",
      "shortCiteRegEx" : null,
      "year" : 2015
    }, {
      "title" : "Efficient Sampling Set Selection for Bandlimited Graph Signals Using Graph Spectral Proxies",
      "author" : [ "A. Anis", "A. Gadde", "A. Ortega" ],
      "venue" : "IEEE Transactions on Signal Processing, no. 14, vol. 64, p. 3775–3789",
      "citeRegEx" : "3",
      "shortCiteRegEx" : null,
      "year" : 2016
    }, {
      "title" : "Random sampling of bandlimited signals on graphs",
      "author" : [ "G. Puy", "N. Tremblay", "R. Gribonval", "P. Vandergheynst" ],
      "venue" : "Applied and Computational Harmonic Analysis, in press",
      "citeRegEx" : "4",
      "shortCiteRegEx" : null,
      "year" : 2016
    }, {
      "title" : "P-0",
      "author" : [ "N. Tremblay" ],
      "venue" : "Amblard, S. Barthelmé. Graph sampling with determinantal processes. arXiv preprint, 1703.01594",
      "citeRegEx" : "5",
      "shortCiteRegEx" : null,
      "year" : 2017
    }, {
      "title" : "Determinantal point processes for machine learning",
      "author" : [ "A. Kulesza", "B. Taskar" ],
      "venue" : "Found. and Trends in Mach. Learn., no. 2, vol. 5, p. 123–286",
      "citeRegEx" : "6",
      "shortCiteRegEx" : null,
      "year" : 2012
    }, {
      "title" : "The emerging field of signal processing on graphs : Extending highdimensional data analysis to networks and other irregular domains",
      "author" : [ "D. Shuman", "S. Narang", "P. Frossard", "A. Ortega", "P. Vandergheynst" ],
      "venue" : "IEEE Signal Processing Magazine, no. 3, vol. 30, p. 83–98",
      "citeRegEx" : "7",
      "shortCiteRegEx" : null,
      "year" : 2013
    }, {
      "title" : "Monte Carlo with determinantal point processes",
      "author" : [ "R. Bardenet", "A. Hardy" ],
      "venue" : "arXiv preprint, 1605.00361",
      "citeRegEx" : "8",
      "shortCiteRegEx" : null,
      "year" : 2016
    }, {
      "title" : "Determinantal point process models and statistical inference",
      "author" : [ "F. Lavancier", "J. Moller", "E. Rubak" ],
      "venue" : "Journal of the Royal Statistical Society : Series B (Statistical Methodology),",
      "citeRegEx" : "9",
      "shortCiteRegEx" : "9",
      "year" : 2015
    }, {
      "title" : "Accelerated spectral clustering using graph filtering of random signals",
      "author" : [ "N. Tremblay", "G. Puy", "R. Gribonval", "P. Vandergheynst" ],
      "venue" : "ICASSP",
      "citeRegEx" : "10",
      "shortCiteRegEx" : null,
      "year" : 2016
    } ],
    "referenceMentions" : [ {
      "referenceID" : 1,
      "context" : "Dans ce contexte, il existe deux types de méthodes d’échantillonnage : i) celles qui calculent les k premiers modes de Fourier du graphe et cherchent via des heuristiques k nœuds qui les discriminent tous [2], ii) celles qui s’affranchissent de ce calcul, et qui soit cherchent un nombre de nœuds proche de k et résolvent des problèmes combinatoires qui ne passent pas à l’échelle [3], soit s’autorisent un nombre de nœuds de l’ordre de O(k log k) et permettent de passer à l’échelle via un échantillonnage iid adapté au graphe [4], soit via des marches aléatoires sur graphe spécifiques [5].",
      "startOffset" : 205,
      "endOffset" : 208
    }, {
      "referenceID" : 2,
      "context" : "Dans ce contexte, il existe deux types de méthodes d’échantillonnage : i) celles qui calculent les k premiers modes de Fourier du graphe et cherchent via des heuristiques k nœuds qui les discriminent tous [2], ii) celles qui s’affranchissent de ce calcul, et qui soit cherchent un nombre de nœuds proche de k et résolvent des problèmes combinatoires qui ne passent pas à l’échelle [3], soit s’autorisent un nombre de nœuds de l’ordre de O(k log k) et permettent de passer à l’échelle via un échantillonnage iid adapté au graphe [4], soit via des marches aléatoires sur graphe spécifiques [5].",
      "startOffset" : 381,
      "endOffset" : 384
    }, {
      "referenceID" : 3,
      "context" : "Dans ce contexte, il existe deux types de méthodes d’échantillonnage : i) celles qui calculent les k premiers modes de Fourier du graphe et cherchent via des heuristiques k nœuds qui les discriminent tous [2], ii) celles qui s’affranchissent de ce calcul, et qui soit cherchent un nombre de nœuds proche de k et résolvent des problèmes combinatoires qui ne passent pas à l’échelle [3], soit s’autorisent un nombre de nœuds de l’ordre de O(k log k) et permettent de passer à l’échelle via un échantillonnage iid adapté au graphe [4], soit via des marches aléatoires sur graphe spécifiques [5].",
      "startOffset" : 528,
      "endOffset" : 531
    }, {
      "referenceID" : 4,
      "context" : "Dans ce contexte, il existe deux types de méthodes d’échantillonnage : i) celles qui calculent les k premiers modes de Fourier du graphe et cherchent via des heuristiques k nœuds qui les discriminent tous [2], ii) celles qui s’affranchissent de ce calcul, et qui soit cherchent un nombre de nœuds proche de k et résolvent des problèmes combinatoires qui ne passent pas à l’échelle [3], soit s’autorisent un nombre de nœuds de l’ordre de O(k log k) et permettent de passer à l’échelle via un échantillonnage iid adapté au graphe [4], soit via des marches aléatoires sur graphe spécifiques [5].",
      "startOffset" : 588,
      "endOffset" : 591
    }, {
      "referenceID" : 5,
      "context" : "Nous proposons une méthode basée sur les processus ponctuels déterminantaux (PPD) [6], des processus aléatoires connus pour favoriser la diversité des échantillons.",
      "startOffset" : 82,
      "endOffset" : 85
    }, {
      "referenceID" : 6,
      "context" : "Par analogie au traitement du signal discret classique, ui est considéré comme le i-ème mode de Fourier du graphe [7].",
      "startOffset" : 114,
      "endOffset" : 117
    }, {
      "referenceID" : 4,
      "context" : "Parmi tous les choix possibles deA (et donc de M) qui vérifient σ 1 > 0, lesquels sont optimaux? Il existe plusieurs définitions d’optimalité [5], nous nous intéressons ici à la suivante :",
      "startOffset" : 142,
      "endOffset" : 145
    }, {
      "referenceID" : 0,
      "context" : "TrouverAMV est NP-complet [1].",
      "startOffset" : 26,
      "endOffset" : 29
    }, {
      "referenceID" : 8,
      "context" : "Notons que des idées similaires pour réduire la complexité d’un facteur m existent dans la littérature (par exemple dans [9]) mais sous des formes un peu cachées, et, à notre connaissance, n’ont jamais été vraiment explicitées dans le cas discret.",
      "startOffset" : 121,
      "endOffset" : 124
    }, {
      "referenceID" : 6,
      "context" : "[7] Considérons le polynôme de Tchebychev h̃k de degré r qui approche au mieux hk :",
      "startOffset" : 0,
      "endOffset" : 3
    }, {
      "referenceID" : 9,
      "context" : "et, via le lemme de Johnson-Lindenstrauss, on montre qu’un nombre de signaux aléatoires n = O(logN) est suffisant pour avoir une estimation convenable avec haute probabilité [10].",
      "startOffset" : 174,
      "endOffset" : 178
    }, {
      "referenceID" : 3,
      "context" : "On compare 5 méthodes d’échantillonnage : i) l’échantillonnage iid uniforme sans remise, ii) l’échantillonnage iid selon p = diag(Kk) sans remise (comme dans [4]), iii) la même stratégie mais avec une distribution p ' diag(Kk) estimée via (15), iv) l’échantillonnage dépendant en suivant l’algorithme 3, et v) l’échantillonnage selon le PPD idéal, c’est-à-dire en suivant l’algorithme 1 avec la légère modification qu’à chaque itération de la boucle on tire l’échantillon qui maximise la probabilité (cela donne de meilleures performances de reconstruction dans les cas testés).",
      "startOffset" : 158,
      "endOffset" : 161
    }, {
      "referenceID" : 3,
      "context" : "Il existe des moyens de reconstruction qui ne nécessitent pas Uk (voir [4]) ; mais nous souhaitons ici comparer exclusivement l’échantillonnage.",
      "startOffset" : 71,
      "endOffset" : 74
    }, {
      "referenceID" : 0,
      "context" : "[1] A.",
      "startOffset" : 0,
      "endOffset" : 3
    }, {
      "referenceID" : 1,
      "context" : "[2] S.",
      "startOffset" : 0,
      "endOffset" : 3
    }, {
      "referenceID" : 2,
      "context" : "[3] A.",
      "startOffset" : 0,
      "endOffset" : 3
    }, {
      "referenceID" : 3,
      "context" : "[4] G.",
      "startOffset" : 0,
      "endOffset" : 3
    }, {
      "referenceID" : 4,
      "context" : "[5] N.",
      "startOffset" : 0,
      "endOffset" : 3
    }, {
      "referenceID" : 5,
      "context" : "[6] A.",
      "startOffset" : 0,
      "endOffset" : 3
    }, {
      "referenceID" : 6,
      "context" : "[7] D.",
      "startOffset" : 0,
      "endOffset" : 3
    }, {
      "referenceID" : 7,
      "context" : "[8] R.",
      "startOffset" : 0,
      "endOffset" : 3
    }, {
      "referenceID" : 8,
      "context" : "[9] F.",
      "startOffset" : 0,
      "endOffset" : 3
    }, {
      "referenceID" : 9,
      "context" : "853–877, 2015 [10] N.",
      "startOffset" : 14,
      "endOffset" : 18
    } ],
    "year" : 2017,
    "abstractText" : "We consider the problem of sampling k-bandlimited graph signals, i.e., linear combinations of the first k graph Fourier modes. We know that a set of k nodes embedding all k-bandlimited signals always exists, thereby enabling their perfect reconstruction after sampling. Unfortunately, to exhibit such a set, one needs to partially diagonalize the graph Laplacian, which becomes prohibitive at large scale. We propose a novel strategy based on determinantal point processes that side-steps partial diagonalisation and enables reconstruction with only O(k) samples.",
    "creator" : "LaTeX with hyperref package"
  }
}