{
  "name" : "1505.06812.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "Optimizing Non-decomposable Performance Measures: A Tale of Two Classes",
    "authors" : [ "Harikrishna Narasimhan", "Purushottam Kar" ],
    "emails" : [ "harikrishna@csa.iisc.ernet.in", "t-purkar@microsoft.com", "prajain@microsoft.com" ],
    "sections" : [ {
      "heading" : null,
      "text" : "In this paper we reveal that for two large families of performance measures that can be expressed as functions of true positive/negative rates, it is indeed possible to implement point stochastic updates. The families we consider are concave and pseudo-linear functions of TPR, TNR which cover several popularly used performance measures such as F-measure, G-mean and H-mean.\nOur core contribution is an adaptive linearization scheme for these families, using which we develop optimization techniques that enable truly point-based stochastic updates. For concave performance measures we propose SPADE, a stochastic primal dual solver; for pseudo-linear measures we propose STAMP, a stochastic alternate maximization procedure. Both methods have crisp convergence guarantees, demonstrate significant speedups over existing methods - often by an order of magnitude or more, and give similar or more accurate predictions on test data."
    }, {
      "heading" : "1 Introduction",
      "text" : "Learning applications with binary classification problems involving severe label imbalance abound, often accompanied with specific requirements in terms of false positive, or negative rates. Examples included spam classification, anomaly detection, and medical applications. Class imbalance is also often introduced as a result of the reduction of a problem to binary classification, such as in multi-class problems Bishop [2006] and multi-label problems due to extreme label sparsity Hsu et al. [2009].\nTraditional performance measures such as misclassification rate are ill-suited in such situations as it is usually trivial to optimize them by constantly predicting the majority class. Instead, the performance measures of choice in such cases are those that perform a more holistic evaluation over the entire data. Naturally, these performance measures are non-decomposable over the dataset and cannot be cannot be expressed as a sum of errors on individual data points. Popular examples include F-measure, G-mean, H-mean etc.\nA consistent effort directed at optimizing these performance measures has, over the years, resulted in the development of two broad approaches - 1) surrogate based approaches (e.g. SVMPerf Joachims et al. [2009]) that design convex surrogates for these performance measures, and 2) indirect approaches which include cost-sensitive classification-based approaches Parambath et al. [2014] which solve weighted classification problems, and plug-in approaches Koyejo et al. [2014], Narasimhan et al. [2014] which rely on consistent estimates of class probabilities. ∗ Work done while H.N. was an intern at Microsoft Research India, Bangalore.\nar X\niv :1\n50 5.\n06 81\n2v 1\n[ st\nat .M\nL ]\n2 6\nM ay\nBoth these approaches are known to work fairly well on small datasets but do not scale very well to large ones, especially those large enough to not even fit in memory. SVMPerf-style approaches, which employ cutting plane methods do not scale well. On the other hand, plug-in approaches first need to solve a class probability estimation problem optimally and then tune a threshold. This two-stage approach prevents the method from exploiting better classifiers to automatically obtain better thresholds. Moreover, for multi-class problems with C classes, jointly estimating C parameters can take time exponential in C.\nFor large datasets, streaming methods such as stochastic gradient descent Shalev-Shwartz et al. [2011] that take only a few passes over the entire data are preferable. However, traditional SGD techniques cannot handle nondecomposable losses. Recently, Kar et al. [2014] proposed optimizing SVMPerf-style surrogates using SGD techniques. Although their method is generic, allowing optimization of performance measures such as F-measure and partial AUC, they require maintaining a large buffer to compute online gradient estimates that can be prohibitive.\nMotivated by the state of the art, we develop novel methods for optimizing two broad families of non-decomposable performance measures. Our methods incorporate truly point-wise updates, i.e. do not require a buffer, and require only a few passes over data. At an intuitive level, at the core of our work are adaptive linearization strategies for these performance measures, which make these measures amenable to SGD-style point-wise updates. Moreover, our linearizations are able to feed off the improvements made in learning a better classifier, resulting in faster convergence.\nWe consider two classes of performance measures Concave Performance Measures (see Table 1): These measures can be written as concave functions of true positive (TPR) and negative (TNR) rates and include G-mean, H-mean etc. We exploit the dual structure of these functions via their Fenchel dual to linearize them in terms of the TPR, TNR variables. Our method then, in parallel, tunes the dual variables in this linearization and maximizes the weighted TPR-TNR combination. These updates are done in an online fashion using stochastic mirror descent steps.\nPseudo-linear Performance Measures (see Table 2): These measures can be written as fractional linear functions of TPR, TNR and include F-measure and the Jaccard coefficient. These functions need not be concave and the techniques outlined above do not apply. Instead, we exploit the pseudo-linear structure to linearize the function and develop a technique to alternately optimize the combination weights and the classifier model via stochastic updates. Although such “alternate-maximization” strategies in general need not converge even to a local optima, we show that our strategy converges to an -approximate global optimum after log ( 1 ) batch updates orO(1/ 2) stochastic updates.\nFinally, we present an empirical validation of our methods. Our experiments reveal that for a range of performance measures in both classes, our methods can be significantly faster than either plug-in or SVMPerf-style methods, as well as give higher or comparable accuracies."
    }, {
      "heading" : "2 Related Works",
      "text" : "As noted in Section 1, existing methods for optimizing performance measures that we study can be divided into surrogate-based approaches and indirect approaches based on cost-sensitive classification or plug-in methods. A third approach applicable to certain performance measures is the decision-theoretic method that learns a class probability estimate and computes predictions that maximize the expected value of the performance measure on a test set Lewis [1995], Ye et al. [2012]. In addition to these there exist methods dedicated to specific performance measures.\nFor instance Parambath et al. [2014] focus on optimizing F-measure by exploiting the pseudo-linearity of the function along with a cross validation-based strategy. Our STAMP method, on the other hand uses an alternating maximization strategy that does not require cross validation which considerably improves training time (see Figure 3). It is important to note that these performance measures have also been studied in multi-label settings where these no longer remain non-decomposable. For instance, Dembczyński et al. [2013] study plug-in style methods for maximizing F-measure in multi-label settings whereas works such as Koyejo et al. [2014], Narasimhan et al. [2014], Ye et al. [2012] study plug-in approaches for the same problem in the more challenging binary classification setting.\nHistorically, online learning algorithms have played a key role in designing solvers for large-scale batch problems. However, for non-decomposable loss functions, defining an online learning framework and providing efficient algorithms with small regret itself is challenging. Rakhlin et al. [2011] propose a generic method for such loss functions; however the algorithms proposed therein run in exponential time. Kar et al. [2014] also study such measures with the\naim of designing stochastic gradient-style methods. However, their methods require a large buffer to be maintained, which causes them to have poorer convergence guarantees and in practice be slower than our methods.\nBy exploiting the special structure in our function classes, we are able to do away with such requirements. Our methods make use of standard online convex optimization primitives Zinkevich [2003]. However, their application requires special care in order to avoid divergent behavior."
    }, {
      "heading" : "3 Problem Setting",
      "text" : "Let X ⊂ Rd denote the instance space and Y = {−1,+1} the label space, with some distribution D over X × Y . Let p := Pr\n(x,y)∼D [y = +1] denote the proportion of positives in the population. Let T = {(x1, y1), . . . , (xT , yT )}\ndenote a sample of training points sampled i.i.d. from D. For sake of simplicity we shall present our algorithms and analyses for a set of linear modelsW ⊆ Rd. Let RX and RW denote the radii of the domain X and hypothesis class W respectively.\nWe consider performance measures that can be expressed in terms of the true positive and negative rates of a classifier. To represent these measures, we shall use the notion of a reward function r that assigns a reward r(y, ŷ) to a prediction ŷ ∈ R when the true label is y ∈ Y . We will use\nr+(w;x, y) = 1\np · r(y,w>x) · 1(y = 1)\nr−(w;x, y) = 1\n1− p · r(y,w>x) · 1(y = −1)\nto calculate rewards on positive and negative points. Since E (x,y) Jr+(w; x, y)K = E (x,y)\nq r(y,w>x)|y = 1 y , setting\nr0−1(y, ŷ) = 1 (yŷ > 0) gives us E (x,y) Jr+(w; x, y)K = TPR(w). For sake of convenience, we will use P (w) = E\n(x,y) Jr+(w;x, y)K and N(w) = E (x,y) Jr−(w;x, y)K to denote population averages of the reward functions. We shall assume that our reward functions are concave, Lr-Lipschitz, and take values in a bounded range [−Br, Br]."
    }, {
      "heading" : "4 Concave Performance Measures",
      "text" : "The first class of performance measures we analyze are concave performance measures. These measures can be written as concave functions of the TPR and TNR i.e.\nPΨ(w) = Ψ (P (w), N(w))\nfor some concave link function Ψ : R2 → R. A large number of popular performance measures fall in this family since these measures are relevant in situations with severe label imbalance or in situations where cost-sensitive classification is required such as detection theory Vincent [1994]. Table 1 gives a list of such performance measures along with some of their relevant properties and references to works that utilize these performance measures.\nWe shall find it convenient to define the (concave) Fenchel conjugate of the link functions for our performance measures. For any concave function Ψ and α, β ∈ R, define\nΨ∗(α, β) = inf u,v∈R {αu+ βv −Ψ(u, v)} .\nBy the concavity of Ψ, we have, for any u, v ∈ R,\nΨ(u, v) = inf α,β∈R\n{αu+ βv −Ψ∗(α, β)} .\nWe shall use the notation Ψ to denote, both the link function, as well as the performance measure it induces.\nAlgorithm 1 SPADE: Stochastic PrimAl-Dual mEthod Input: Primal/dual step sizes ηt, η′t, feasible setsW,A Output: Classifier w ∈ W\n1: w0 ← 0, t← 1 2: while data stream has points do 3: Receive data point (xt, yt) 4: /* Perform primal ascent */ 5: if yt > 0 then 6: wt+1 ← ΠW ( wt + ηt · αt∇wr+(wt;xt, yt)\n) 7: else 8: wt+1 ← ΠW ( wt + ηt · βt∇wr−(wt;xt, yt)\n) 9: end if\n10: /* Perform dual descent */ 11: (a, b)← (αt, βt)− η′t · ∇(α,β)Ψ∗(αt, βt) 12: if yt > 0 then 13: a← a− η′t · r+(wt;xt, yt) 14: else 15: b← b− η′t · r−(wt;xt, yt) 16: end if 17: (αt+1, βt+1)← ΠA((a, b)) 18: t← t+ 1 19: end while 20: return w = 1\nt ∑t τ=1 wτ"
    }, {
      "heading" : "4.1 A Stochastic Primal-dual Method for Optimizing Concave Performance Measures",
      "text" : "We now present a novel online stochastic method for optimizing the class of concave performance measures. The\nuse of stochastic gradient techniques for these measures presents specific challenges due to the non-decomposable nature of these measures which makes it difficult to obtain cheap, unbiased estimates of the gradient using a single point. Recent works Kar et al. [2013, 2014] have tried to resolve this issue by looking at mini-batch methods or by using a buffer to maintain a sketch of the stream. However, such techniques bring in a bias into the learning algorithm in the form of buffer size or mini batch length which results in slower convergence. Indeed, the 1PMB method of Kar et al. [2014] is only able to guarantee a −4 √ T rate of convergence, whereas SGD techniques are usually able to guarantee −2 √ T rates. This is indicative of suboptimal performance and our experiments confirm this (see Figure 3).\nHere we show that for the class of concave performance measures, such workarounds are not necessary. To this end we present the SPADE algorithm (Algorithm 1) which exploits the dual structure of the performance measures to obtain efficient point updates which do not require the use of mini-batches or online buffers. SPADE is able to offer convergence guarantees identical to those that stochastic methods offer for additive performance measures such as least squares, without the presence of any algorithmic bias.\nLetW ⊂ X and AΨ ⊂ R2 be convex regions within the model and dual spaces respectively, and ΠW and ΠAΨ denote projection operators for these. Table 1 lists the relevant dual regions for the performance measures listed therein."
    }, {
      "heading" : "4.2 Convergence Analysis for SPADE",
      "text" : "This section presents a convergence analysis for the SPADE algorithm. The convergence proof is formally stated in Theorem 4. Apart from demonstrating the utility of the algorithm, the proof also sheds light on the choice of algorithm parameters, such as primal/dual feasible regions.\nWe shall work with performance measures that are monotonically increasing in the true positive and negative rates of the classifier i.e. if u ≥ u′, v ≥ v′ then Ψ(u, v) ≥ Ψ(u′, v′). This is a natural assumption and is satisfied by all performance measures considered here (see Table 1). We now introduce two useful concepts.\nDefinition 1 (Stable Performance Measure). A performance measure Ψ will be called δ-stable if for some function δ : R→ R, we have for all u, v ∈ R and ∈ R+,\nΨ (u+ , v + ) ≤ Ψ(u, v) + δ( ).\nTable 1 lists the stability parameters of all the concave performance measures. Clearly, a performance measure has a linear stability parameter i.e. δ( ) ≤ L · iff its corresponding link function is Lipschitz. We now define the notion of a sufficient dual region for a performance measure\nDefinition 2 (Sufficient Dual Region). For any link function Ψ, define its sufficient dual region AΨ ⊆ R2 to be the minimal set such that for all (u, v) ∈ R2, we have\nΨ(u, v) = inf (α,β)∈AΨ\n{αu+ βv −Ψ∗(α, β)} .\nThe reason for defining this quantity will become clear in a moment. A closer look at Algorithm 1 indicates that it is performing online gradient descent steps with the dual variables. Clearly, for this procedure to have statistical convergence properties, the magnitude of the updates must be bounded in some sense otherwise the learning procedure may diverge. This motivates the projection step in Step 17. However, in order for the updated dual variables to be informative about the current primal function value, the projection step must be done in a way that does not distort the link function. The notion of a sufficient dual region formally captures the notion of such a projection step.\nHaving said that, there is no apriori guarantee that the sufficient region for a given performance measure would be bounded, in which case this entire exercise counts for naught. However, the following lemma, by closely linking the stability properties of a performance measure with the size of its sufficient dual region, shows that for well-behaved link functions, this will not be the case .\nLemma 3. The stability parameter of a performance measure Ψ(·) can be written as δ( ) ≤ LΨ · iff its sufficient dual region is bounded in a ball of radius LΨ.\nThe proof of this result follows from elementary manipulations and can be found in Appendix A. In some sense this result can be seen as a realization of the well known connection between the Fenchel dual of a function and its Lipschitz properties.\nTo simplify the initial analysis, we shall first concentrate on performance measures whose link functions are Lipschitz. It is easy to see that these are exactly the performance measures whose gradients do not diverge within any compact region of the real plane. Of the performance measures listed in Table 1, all measures except G-mean have associated link functions that are Lipschitz. Subsequently, we shall address the more involved case of non-Lipschitz performance measures such as G-mean as well.\nTheorem 4. Suppose we are given a stream of random samples (x1, y1), . . . , (xT , yT ) drawn from a distribution D over X × Y . Let Ψ(·) be a concave, Lipschitz link function. Let Algorithm 1 be executed with a dual feasible set A ⊇ AΨ, ηt = 1/ √ t and η′t = 1/ √ t. Then, the average model w = 1T ∑T t=1 wt output by the algorithm satisfies, with probability at least 1− δ,\nPΨ(w) ≥ sup w∗∈W PΨ(w∗)−O\n( δΨ (√ 1\nT log\n1\nδ\n)) .\nWe refer the reader to Appendix B for a proof and explicit constants. The proof closely analyzes the primal ascent and dual descent steps, tying them together using the Fenchel dual of Ψ."
    }, {
      "heading" : "4.3 The Case of non-Lipschitz Link Functions",
      "text" : "Non-Lipschitz link functions, such as the one used in the G-mean performance measure, pose a particular challenge to the previous analysis. Owing to their non-Lipschitz nature, their sufficient dual region is unbounded. Indeed as Table 1 indicates, the sufficient region for ΨG-mean extends indefinitely along both coordinate axes. More precisely, what happens is that the gradients of the ΨG-mean function diverge as either u → 0, or v → 0. This poses a stumbling block for the proof of Theorem 4 since the regret and online-to-batch conversion results used therein fail.\nA natural way to solve this problem is to ensure that the reward functions r+, r− always assign rewards that are bounded away from zero. More specifically, for some > 0, we have r+(w;x, y), r−(w;x, y) ≥ for all w ∈ W and x ∈ X . For this restricted reward region, one can show, using Lemma 3, that the sufficient dual region can be restricted to a ball of radius O (√ 1/ )\n. The above discussion suggests that we regularize the reward function i.e. at each time step t, we add a small value (t) to the original reward function. However, the amount of regularization remains to be decided since over regularization could cause our resulting excess risk bound to be vacuous with respect to the original reward function. It turns out that setting (t) ≈ 1\nt1/4 strikes a fine balance between regularization and fidelity to the original reward\nfunction - this seems intuitive since the regularization becomes milder and milder as learning progresses. The following extension of Theorem 4 formalizes this statement.\nTheorem 5. Suppose we have the problem setting in Theorem 4 with the ΨG-mean performance measure being optimized for. Consider a modification to Algorithm 1 wherein the reward functions are changed to r+t (·) = r+(·) + (t), and r−t (·) = r−(·) + (t) for (t) = 1t1/4 . Then, the average model w = 1 T ∑T t=1 wt output by the algorithm satisfies, with probability at least 1− δ,\nPΨG-mean(w) ≥ sup w∗∈W\nPΨG-mean(w∗)− Õ ( 1\nT 1/4\n) .\nThe proof of this theorem can be found in Appendix C. We note here that primal dual frameworks have been utilized before in diverse areas such as distributed optimization Jaggi et al. [2014] and multi-objective optimization Mahdavi et al. [2013]. However, these works simply assume the functions involved therein to be Lipschitz and/or smooth and do not address cases where they fail to be so. Theorem 5 on the other hand, is able to recover a non-trivial, albeit weaker, statement even for locally Lipschitz functions."
    }, {
      "heading" : "5 Pseudo-linear Performance Measures",
      "text" : "The second class of performance measures we analyze are pseudo-linear performance measures. These measures have a fractional linear function as the link function and can be written as follows:\nP(a,b)(w) = a0 + a1 · P (w) + a2 ·N(w) b0 + b1 · P (w) + b2 ·N(w) ,\nAlgorithm 2 AMP: Alternate Maximization Procedure Input: Performance measure P(a,b), feasible setW , tolerance Output: An -optimal classifier w ∈ W\n1: Construct valuation function V(a,b) 2: w0 ← 0, t← 1 3: while vt > vt−1 + do 4: wt+1 ← arg maxw∈W V(a,b)(w, vt) 5: vt+1 ← arg maxv>0 v such that V(a,b)(wt+1, v) ≥ v 6: t← t+ 1 7: end while 8: return wt\nfor some weighing coefficients a,b. Several popularly used performance measures, most notably the F-measure, can be represented as pseudo-linear functions. Table 2 enumerates some popular pseudo-linear performance measures as well as their properties.\nWe note that these performance measures are usually represented in literature using the entries of the confusion matrix. However, for the sake of our analysis, we shall find it useful to represent them in terms of the true positive and true negative rates. To do so, we shall use p to denote the proportion of positives in the population and θ = 1−pp to denote the label skew."
    }, {
      "heading" : "5.1 Alternate-maximization for Optimizing Pseudo-linear Performance Measures",
      "text" : "Pseudo-linear functions are named so since their level sets can be defined using linear half-spaces. More specifically, every pseudo-linear function Ψ over Rd has an associated “level-finder” function a : R → Rd and b : R → R such that Ψ(v) ≥ t iff 〈v, a(t)〉 ≥ b(t). We refer the reader to Parambath et al. [2014] for a more relaxed introduction to these functions and their properties. For our purposes, however, it suffices to notice that this property immediately points toward a cost-sensitive method to optimize these performance measures.\nThis fact was noticed by Parambath et al. [2014] who exploited this to develop a cost-sensitive classification method for optimizing the F-measure by simply searching for the best weights with which to perform cost-sensitive classification. However, we notice that instead of performing such a brute force search, one can adaptively tune the weights to better and better values and obtain much faster convergence. To develop this intuition, we first define the notion of a valuation function below.\nDefinition 6 (Valuation Function). The valuation function of a performance measure P(a,b), for a classifier w ∈ W , and at a level v ∈ R is defined as\nV(a,b)(w, v) := c+ (α− vγ) · P (w) + (β − vδ) ·N(w),\nwhere c = a0b0 , α = a1 b0 , β = a2b0 , γ = b1 b0 , δ = b2b0 .\nThe following well-known lemma closely links the valuation function to the performance measure.\nLemma 7. For any performance measure P(a,b), w ∈ W and v ∈ R we have P(a,b)(w) ≥ v iff V(a,b)(w, v) ≥ v. Moreover, in such a situation we say that classifier w has achieved valuation at level v.\nLemma 7 indicates that the performance of a classifier is intimately linked to its valuation. This suggests a natural alternate maximization approach wherein we alternate between posing a challenge level to the classifier and training a classifier to achieve that level. The resulting algorithm AMP is detailed in Algorithm 2. Note that using Lemma 7, step 5 in the algorithm can be executed simply by setting vt+1 = P(a,b)(wt+1). Thus, in a very natural manner, the current classifier challenges the next classifier to beat its own performance. It turns out that this approach results in rapid convergence as outlined in the following theorem.\nTheorem 8. Let Algorithm 2 be executed with a performance measure P(a,b) and reward functions that offer values in the range [0,m). Let P∗ := supw∈W P(a,b)(w). Also let ∆t = P∗ −P(a,b)(wt) be the excess error for the model wt generated at time t. Then there exists a value η(m) < 1 such that ∆t ≤ ∆0 · η(m)t.\nAlgorithm 3 STAMP: STochastic Alt-Max Procedure Input: Feasible setW , Step sizes ηt, epoch lengths se, s′e Output: Classifier w ∈ W\n1: v ← 0, t← 0, e← 0,w0 ← 0 2: repeat 3: /* Model optimization stage */ 4: w̃← we 5: while t < se do 6: Receive sample (x, y) 7: w̃← w̃ + ηt∇w ( (1− ve\n2 )r+(w̃;x, y) + ve 2 r−(w̃;x, y) ) 8: t← t+ 1 9: end while\n10: t← 0, e← e+ 1,we+1 ← w̃ 11: /* Challenge level estimation stage */ 12: v+ ← 0, v− ← 0 13: while t < s′e do 14: Receive sample (x, y) 15: vy ← vy + ry(we;x, y) 16: t← t+ 1 17: end while 18: t← 0, ve ← 2v+2+v+−v− 19: until stream is exhausted 20: return we\nThe proof of this theorem can be found in Appendix D. Table 2 gives values for the convergence rates of all the pseudo-linear performance measures, as well as the allowed range of values that the reward functions can take for those measures. This is important since performance measures such as the F-measure diverge if the reward function values approach 2. Other performance measures like the Gower-Legendre measure do not impose any such restrictions. Note that the above result shows that Algorithm 2 will always terminate in O ( log 1 ) steps.\nAt this point it would be apt to make a historical note. Pseudo-linear functions have enjoyed a fair amount of interest in the optimization community Schaible [1976], Dinkelbach [1967], Jagannathan [1966] within the sub-field of fractional programming. Of the many methods that have been developed to optimize these functions, the DinkelbachJagannathan (DJ) procedure Dinkelbach [1967], Jagannathan [1966] is of specific interest to us. It turns out that the AMP method can be seen as performing DJ-style updates over parameterized spaces (the parameter being the model w). It is known (for instance see Schaible [1976]) that the DJ process is able to offer a linear convergence rates. Our proof of Theorem 8, which was obtained independently, can then be seen as giving a similar result in the parameterized setting.\nHowever, we wish to move one step further and optimize these performance measures in an online stochastic manner. To this end, we observe that the AMP algorithm can be executed in an online fashion by using stochastic updates to train the intermediate models. The resulting algorithm STAMP, is presented in Algorithm 3. However, this algorithm is much harder to analyze because unlike AMP which has the luxury of offering exact updates, STAMP offers inexact, even noisy updates. Indeed, even existing works in the optimization community (for example Schaible [1976]) do not seem to have analyzed DJ-style methods with noisy updates.\nOur next contribution hence, is an analysis of the convergence rate offered by the AMP algorithm when neither of the two maximizations is carried out exactly. For the sake of simplicity, we present the STAMP algorithm and its analysis for the case of F1 measure. Suppose at each time step, for some t ≥ 0, δt, we have\nV (wt+1, vt) = max w∈W\nV (w, vt)− t\nvt = F (wt) + δt,\nthen for some η < 1, we have\n∆T ≤ ηT∆0 + T−1∑ i=0 ηT−i (|δt|+ t)\nAs a corollary we present a convergence analysis for the STAMP algorithm in Theorem 9.\nTheorem 9. Let Algorithm 3 be executed with a performance measure P(a,b) and reward functions with range [0,m). Let η = η(m) be the rate of convergence guaranteed for P(a,b) by the AMP algorithm. Set the epoch lengths to se, s ′ e = Õ ( 1 η2e ) . Then after e = log 1\nη\n( 1 log 2 1 ) epochs, we can ensure with probability at least 1 − δ that\nP∗ − P(a,b)(we) ≤ . Moreover the number of samples consumed till this point is at most Õ ( 1 2 ) .\nThe convergence analysis for noisy AMP can be found in Appendix E. The proof of this theorem can be found in Appendix F. Both results require a fine grained analysis of how errors accumulate throughout the learning process."
    }, {
      "heading" : "6 Experimental Results",
      "text" : "We shall now compare our methods with the state-of-the-art on various performance measures and datasets.\nDatasets: We evaluated our methods on 5 publicly available benchmark datasets: a) PPI, b) KDD Cup 2008, c) IJCNN, d) Covertype, e) MNIST. All datasets exhibited moderate to severe label imbalance with the KDD Cup 2008 dataset having just 0.61% positives.\nMethods: We instantiated the SPADE algorithm (Algorithm 1) on the Q-mean and Min-TPR/TNR performance measures. We also instantiated the STAMP method (Algorithm 3) on F1-measure and the JAC coefficient. In both\ncases we compared to the SVMPerf method Joachims et al. [2009] and plug-in method Koyejo et al. [2014] specialized to these measures. For the sake of reference, we also compared to the standard logistic regression method for (unweighted) binary classification. Additionally for F1-measure, we also compared to the 1PMB stochastic gradient descent method proposed recently by Kar et al. [2014]. All methods were implemented in C.\nParameters: We used 70% of the dataset for training and the rest for testing. Tunable parameters, including thresholds for the plug-in approaches, were cross-validated on a validation set. All results reported here were averaged over 5 random train-test splits. We used hinge-loss based reward functions for our methods. STAMP was executed by setting the challenge level to the actual F-measure/JAC at each stage. We used a state of the art LBFGS solver to implement the plug-in methods and used standard implementations of the SVMPerf algorithm. Since our methods are able to take a single pass over the data very rapidly, SPADE was allowed to run for 25 passes over the data and STAMP was allowed 25 passes with an initial epoch length of 100 which was doubled after every iteration. The SVMPerf algorithm was allowed a runtime of up to 50× of that given to our method after which it was terminated. The LBFGS solver was always allowed to run till convergence.\nFigures 1 and 2 compare the SPADE method with the baseline methods for the Q-mean and Min-TPR/TNR measures. In general, SPADE was found to offer comparable or superior accuracies with greatly accelerated convergence as compared to other methods. On the IJCNN and Covtype datasets, SPADE outperformed every other method by about 2-3%. As SPADE is a stochastic first order method, it is expected to rapidly find out a fairly accurate solution. Indeed, the method was found to offer greatly accelerated convergence without fail. For instance, on the MNIST dataset, SPADE found out the best solution as much as 60× faster than any other method whereas on the KDD Cup and PPI datasets it was 12× and 2× faster respectively. The SVMPerf method, on the other hand, was found to be extremely slow in general and require at least an order of magnitude time more than SPADE to find reasonably accurate solutions. It is also notable that in all cases, simple binary classification gave very poor accuracies due to the severe label imbalance in these datasets.\nFigures 3 and 4 report the performance of the STAMP method applied to pseudo-linear functions. Similar to the concave measures, STAMP was found to provide competitive accuracies as compared to the baseline methods but require at least 3−4× less computational time. Interestingly, for the F1-measure, the 1PMB method, which is another\nstochastic gradient descent-based method, was found to struggle to obtain accuracies similar to that of STAMP or else offer much slower convergence. We suspect two main reasons for the suboptimal behavior of this other stochastic method. Firstly these results confirm the adverse effect of the dependence on an in-memory buffer on these methods. It is notable that this dependence causes even the theoretical convergence rates for these methods to be weaker as was noted earlier in the discussion. Secondly, we note that both SVMPerf and 1PMB optimize the same “struct-SVM” style surrogate for the F-measure Kar et al. [2014]. This surrogate has been observed to give poor accuracies when compared to plug-in methods in several previous works Koyejo et al. [2014], Narasimhan et al. [2014]. STAMP on the other hand, works directly with F-measure in a manner similar to, but faster than, the plug-in methods which might explain its better performance."
    }, {
      "heading" : "Acknowledgements",
      "text" : "HN thanks support from a Google India PhD Fellowship."
    }, {
      "heading" : "A Proof of Lemma 3",
      "text" : "Lemma 3. The stability parameter of a performance measure Ψ(·) can be written as δ( ) ≤ LΨ · iff its sufficient dual region is bounded in a ball of radius Θ (LΨ).\nProof. Let us denote primal variables using the notation x = (u, v) and dual variables using the notation θ = (α, β). The proof follows from the fact that any value of θ for which Ψ∗(θ) = −∞ can be safely excluded from the sufficient dual region.\nFor proving the result in one direction suppose Ψ is stable with δ( ) = L for some L > 0. Now consider some θ ∈ R2 such that ‖θ‖2 ≥ L. Now set xC = −C · θ. Then we have\nΨ∗(θ) = inf x {〈θ,x〉 −Ψ(x)}\n≤ inf C>0 {〈θ,xC〉 −Ψ(xC)}\n= inf C>0\n{ −C ‖θ‖22 −Ψ(xC) } ≤ inf C>0 { −C ‖θ‖22 −Ψ(0) + CL ‖θ‖∞\n} ≤ inf C>0 { −C ‖θ‖22 −Ψ(0) + CL ‖θ‖2\n} = inf C>0 {−C ‖θ‖2 (‖θ‖2 − L)} −Ψ(0)\n≤ inf C>0 {−C ‖θ‖2 −Ψ(0)}\n= −∞\nThus, we can conclude that no dual vector with norm greater than L can be a part of the sufficient dual region. This shows that the sufficient dual region is bounded inside a ball of radius L. For proving the result in the other direction, suppose the dual sufficient region is indeed bounded in a ball of radius R. Consider two points x1,x2 such that\nθ∗1 = arg min θ∈AΨ {〈θ,x1〉 −Ψ∗(θ)} θ∗2 = arg min θ∈AΨ {〈θ,x2〉 −Ψ∗(θ)}\nNow define f(θ,x) := 〈θ,x〉 −Ψ∗(θ) so that, by the above definition, f(θ∗1,x1) = Ψ(x1) and f(θ ∗ 2,x2) = Ψ(x2). Now we have\nΨ(x1) = f(θ ∗ 1,x1) ≤ f(θ ∗ 2,x1)\n≤ f(θ∗2,x2) + |〈θ ∗ 2,x1 − x2〉| = Ψ(x2) + |〈θ∗2,x1 − x2〉| ≤ Ψ(x2) +R ‖x1 − x2‖2 ,\nwhere the fourth step follows from the norm bound on θ∗2. Similarly we have\nΨ(x2) ≤ Ψ(x1) +R ‖x1 − x2‖2\nThis establishes the result."
    }, {
      "heading" : "B Proof of Theorem 4",
      "text" : "Theorem 4. Suppose we are given a stream of random samples (x1, y1), . . . , (xT , yT ) drawn from a distribution D over X × Y . Let Ψ(·) be a concave, Lipschitz link function. Let Algorithm 1 be executed with a dual feasible set\nA ⊇ AΨ, ηt = 1/ √ t and η′t = 1/ √ t. Then, the average model w = 1T ∑T t=1 wt output by the algorithm satisfies, with probability at least 1− δ,\nPΨ(w) ≥ sup w∗∈W PΨ(w∗)− δΨ (√ 2B2r T log 1 δ ) − ( L2Ψ + 4B 2 r ) 1 2 √ T − ( L2ΨL 2 r +R 2 W ) 1 2 √ T − √ 2L2ΨB 2 r T log 1 δ .\nProof. For this proof we shall assume that Ψ is LΨ-Lipschitz so that its sufficient dual region can be bounded by an application of Lemma 3. Notice that the updates for (α, β) can be written as follows:\n(αt+1, βt+1)← ΠAΨ ( (αt, βt)− ηt∇(α,β)`dt (αt, βt) ) ,\nwhere\n`dt (α, β) = { αr+(wt;xt, yt)−Ψ∗(α, β) if yt > 0 βr−(wt;xt, yt)−Ψ∗(α, β) if yt < 0\nwhich can be interpreted as simple gradient descent with `t. Moreover, since Ψ∗ is concave, `dt is convex with respect to (α, β) for every t. Note that the terms r+(wt;xt, yt) and r−(wt;xt, yt) do not involve α, β and hence act as arbitrary bounded positive constants for this part of the analysis.\nNote that by Lemma 3, we have the radius of AΨ bounded by LΨ. Also, since Ψ is a monotone function, by a similar argument, Ψ∗(α, β) can be shown to be a Ψ(Br, Br)-Lipschitz function. For all the performance measures considered, we have Ψ(Br, Br) ≤ Br. Thus, `dt (α, β) is a 2Br-Lipschitz function. Hence, using a standard GIGAstyle analysis Zinkevich [2003] on the (descent) updates on αt and βt in Algorithm 1, we have (for ηt = 1√t )\n1\nT T∑ t=1 [ αtr +(wt; xt, yt) + βtr −(wt; xt, yt) − Ψ∗(αt, βt) ] ≤ inf\n(α,β)∈A { 1 T T∑ t=1 [ αr+(wt; xt, yt) + βr −(wt; xt, yt) − Ψ∗(α, β) ]} + ( L2Ψ + 4B 2 r ) 1 2 √ T\n= inf (α,β)∈A\n{ α 1\nT T∑ t=1 r+(wt; xt, yt) + β 1 T T∑ t=1 r−(wt; xt, yt) − Ψ∗(α, β) } + ( L2Ψ + 4B 2 r ) 1 2 √ T\n= Ψ\n( 1\nT T∑ t=1 r+(wt; xt, yt), 1 T T∑ t=1 r−(wt; xt, yt) ) + ( L2Ψ + 4B 2 r ) 1 2 √ T ,\nwhere the last step follows from Fenchel conjugacy. Further, noting that Ext,yt q r+(wt; xt, yt) ∣∣x1:t−1, y1:t−1y = P (wt), and Ext,yt qr−(wt; xt, yt) ∣∣x1:t−1, y1:t−1y = N(wt), we use the standard online-batch conversion bounds Cesa-Bianchi et al. [2001] to the loss functions r+ and r− individually to obtain w.h.p.\n1\nT T∑ t=1 r+(wt; xt, yt) ≤ T∑ t=1 P (wt) + √ 2B2r T log 1 δ\n1\nT T∑ t=1 r−(wt; xt, yt) ≤ T∑ t=1 N(wt) + √ 2B2r T log 1 δ\nBy monotonicity of Ψ, we get\n1\nT T∑ t=1 [ αtr +(wt; xt, yt) + βtr −(wt; xt, yt) − Ψ∗(αt, βt) ] ≤ Ψ ( 1\nT T∑ t=1 P (wt) + √ 2B2r T log 1 δ , 1 T T∑ t=1 N(wt) + √ 2B2r T log 1 δ ) + ( L2Ψ + 4B 2 r ) 1 2 √ T\n≤ Ψ ( 1\nT T∑ t=1 P (wt), 1 T T∑ t=1 N(wt) ) + δΨ (√ 2B2r T log 1 δ ) + ( L2Ψ + 4B 2 r ) 1 2 √ T\n≤ Ψ ( r̄+ ( 1\nT T∑ t=1 wt ) , r̄− ( 1 T T∑ t=1 wt )) + δΨ (√ 2B2r T log 1 δ ) + ( L2Ψ + 4B 2 r ) 1 2 √ T\n= Ψ ( P (w), N(w) ) + δΨ (√ 2B2r T log 1 δ ) + ( L2Ψ + 4B 2 r ) 1 2 √ T , (1)\nwhere the second inequality follows from stability of Ψ, and the third inequality follows from concavity of r̄+ and r̄−, Jensen’s inequality, and stability of Ψ.\nSimilarly, the update to w can be written as\nwt+1 ← ΠW (wt − η′t∇w` p t (wt)) ,\nwhere ΠW is the projection operator for the domainW and\n`pt (w) = { −αtr+(w;xt, yt) + Ψ∗(αt, βt) if yt > 0 −βtr−(w;xt, yt) + Ψ∗(αt, βt) if yt < 0\nSince r+, r− are concave and the term Ψ∗(αt, βt) does not involve w, ` p t is convex in w for all t. Also, we can show that `pt (w) is an (LΨ · Lr)-Lipschitz function. Hence, applying a standard GIGA analysis Zinkevich [2003] to the (ascent) update on wt in Algorithm 1 (with η′t = 1√ t ), we have for any w∗ ∈ W ,\n1\nT T∑ t=1 [ αtr +(wt;xt, yt) + βtr −(wt;xt, yt) − Ψ∗(αt, βt) ] ≥ 1\nT T∑ t=1 [ αtr +(w∗;xt, yt) + βtr −(w∗;xt, yt) − Ψ∗(αt, βt) ] − ( L2ΨL 2 r +R 2 W ) 1 2 √ T .\nAgain, observing that by linearity of expectation, we have\nExt,yt q αtr +(w∗;xt, yt) + βtr −(w∗;xt, yt) ∣∣x1:t−1, y1:t−1y = αtP (w∗) + βtN(w∗), which gives us, through an online-batch conversion argument Cesa-Bianchi et al. [2001] w.h.p,\n1\nT T∑ t=1 [ αtr +(wt;xt, yt) + βtr − t (wt;xt, yt) − Ψ∗(αt, βt) ] ≥ 1\nT T∑ t=1 [ αtP (w ∗) + βtN(w ∗) ] − 1 T T∑ t=1 Ψ∗(αt, βt) − √ 2L2ΨB 2 r T log 1 δ − ( L2ΨL 2 r +R 2 W ) 1 2 √ T\n≥ 1 T T∑ t=1 [ αtP (w ∗) + βtN(w ∗) ] − Ψ∗ ( 1 T T∑ t=1 αt, 1 T T∑ t=1 βt ) − √ 2L2ΨB 2 r T log 1 δ − ( L2ΨL 2 r +R 2 W ) 1 2 √ T\n= ᾱP (w∗) + β̄N(w∗) − Ψ∗(ᾱ, β̄) − √ 2L2ΨB 2 r\nT log\n1 δ − ( L2ΨL 2 r +R 2 W ) 1 2 √ T\n≥ inf α,β\n{ αP (w∗) + βN(w∗) − Ψ∗(α, β) } − √ 2L2ΨB 2 r\nT log\n1 δ − ( L2ΨL 2 r +R 2 W ) 1 2 √ T\n= Ψ ( P (w∗), N(w∗) ) − √ 2L2ΨB 2 r\nT log\n1 δ − ( L2ΨL 2 r +R 2 W ) 1 2 √ T , (2)\nwhere the second step follows from concavity of Ψ and Jensen’s inequality, in the third step ᾱ = 1T ∑T t=1 αt and\nβ̄ = 1T ∑T t=1 βt, and the last step follows from Fenchel conjugacy.\nCombining Eq. (1) and (2) gives us the desired result."
    }, {
      "heading" : "C Proof of Theorem 5",
      "text" : "Theorem 5. Suppose we have the problem setting in Theorem 4 with the ΨG-mean performance measure being optimized for. Consider a modification to Algorithm 1 wherein the reward functions are changed to r+t (·) = r+(·) + (t), and r−t (·) = r−(·) + (t) for (t) = 1t1/4 . Then, the average model w = 1 T ∑T t=1 wt output by the algorithm satisfies, with probability at least 1− δ,\nPΨG-mean(w) ≥ sup w∗∈W\nPΨG-mean(w∗)− Õ ( 1\nT 1/4\n) .\nProof. Suppose Ψ(u + , v + ) ≤ Ψ(u, v) + δΨ( ) as before. Let r+t (·) = r+(·) + (t), and r−t (·) = r−(·) + (t). Let us make all updates with respect to r+t , r − t . Let r( ) be the radius of the sufficient dual domain A for a given\nregularization . Also let ̄ = 1T ∑T i=1 (t). We will assume throughout that (t) = O(1). Then we have:\n1\nT T∑ t=1 [ αtr + t (wt; xt, yt) + βtr − t (wt; xt, yt) − Ψ∗(αt, βt) ] ≤ inf\n(α,β)∈A { 1 T T∑ t=1 [ αr+t (wt; xt, yt) + βr − t (wt; xt, yt) − Ψ∗(α, β) ]} + O ( r(̄)√ T )\n= inf (α,β)∈A\n{ α 1\nT T∑ t=1 r+(wt; xt, yt) + ̄ + β 1 T T∑ t=1 r−(wt; xt, yt) + ̄ − Ψ∗(α, β) } + O ( r(̄)√ T )\n= Ψ\n( 1\nT T∑ t=1 r+(wt; xt, yt) + ̄, 1 T T∑ t=1 r−(wt; xt, yt) + ̄ ) + O ( r(̄)√ T ) (3)\n= Ψ\n( 1\nT T∑ t=1 r+(wt; xt, yt), 1 T T∑ t=1 r−(wt; xt, yt) ) + δΨ(̄) + O ( r(̄)√ T ) We can now use online to batch conversion bounds Cesa-Bianchi et al. [2001], and monotonicity of Ψ to get\n1\nT T∑ t=1 [ αtr +(wt; xt, yt) + βtr −(wt; xt, yt) − Ψ∗(αt, βt) ] ≤ Ψ ( P (w), N(w) ) + δΨ ( Õ (\n1√ T\n)) + δΨ(̄) + O ( r(̄)√ T ) , (4)\nFor the primal updates, we get, for any w∗ ∈ W ,\n1\nT T∑ t=1 [ αtr + t (wt;xt, yt) + βtr − t (wt;xt, yt) − Ψ∗(αt, βt) ] ≥ 1\nT T∑ t=1 [ αtr + t (w ∗;xt, yt) + βtr − t (w ∗;xt, yt) − Ψ∗(αt, βt) ] − Õ ( r(̄)√ T )\n= 1\nT T∑ t=1 [ αtr +(w∗;xt, yt) + βtr −(w∗;xt, yt) − Ψ∗(αt, βt) ] + 1 T T∑ t=1 (t)(αt + βt) − Õ ( r(̄)√ T )\n≥ 1 T T∑ t=1 [ αtr +(w∗;xt, yt) + βtr −(w∗;xt, yt) − Ψ∗(αt, βt) ] − Õ ( r(̄)√ T ) ,\nsince (t), αt, βt ≥ 0. Again using an online-batch conversion argument Cesa-Bianchi et al. [2001] we get w.h.p,\n1\nT T∑ t=1 [ αtr +(wt;xt, yt) + βtr − t (wt;xt, yt) − Ψ∗(αt, βt) ] ≥ Ψ ( P (w∗), N(w∗) ) − Õ ( r(̄)√ T ) . (5)\nCombining Eq. (4) and (5) gives us\nΨ ( P (w), N(w) ) ≥ Ψ ( P (w∗), N(w∗) ) − Õ ( r(̄)√ T ) − δΨ ( Õ ( 1√ T )) − δΨ(̄)\nFor G-mean, δΨ(x) = √ x, and by an application of Lemma 3,we have r( ) = O(1/ √ ). Thus we have\nΨ ( P (w), N(w) ) ≥ Ψ ( P (w∗), N(w∗) ) − Õ ( 1√ T ̄ ) − Õ ( 1 4 √ T ) − √ ̄\nFor ̄ = O (\n1 4√ T\n) , we get\nΨ ( P (w), N(w) ) ≥ Ψ ( P (w∗), N(w∗) ) − Õ\n( 1\n4 √ T ) This can be achieved with (t) = 14√t ."
    }, {
      "heading" : "D Proof of Theorem 8",
      "text" : "Theorem 8. Let Algorithm 2 be executed with a performance measure P(a,b) and reward functions that offer values in the range [0,m). Let P∗ := supw∈W P(a,b)(w). Also let ∆t = P∗ −P(a,b)(wt) be the excess error for the model wt generated at time t. Then there exists a value η(m) < 1 such that for ∆t ≤ ∆0 · η(m)t.\nProof. In order to be generic in its treatment, the proof will require the following regularity conditions on the performance measure\n1. b0 6= 0\n2. α− P(w) · γ ≥ 0 for all w ∈ W\n3. β − P(w) · δ ≥ 0 for all w ∈ W\n4. −1 < f ≤ γ · P (w) + δ ·N(w) ≤ g for all w ∈ W\nDefine et := V (wt+1, vt)−vt. Then we can state the following lemmata which together yield the convergence bound proof.\nLemma 10. et1+f ≥ P ∗ − vt\nProof. Assume that for some w∗, P(w∗) = vt + et + e′ where e′ > 0. Then we have\nV (w∗, vt) =\n( et\n1 + f + e′\n) (1 + γ · P (w∗) + δ ·N(w∗))− et\n≥ (\net 1 + f\n+ e′ ) (1 + f)− et\n= e′(1 + f) > 0,\nwhich contradicts the fact that no classifier can achieve a valuation greater than vt + et at level vt, thus proving the desired result.\nLemma 11. For any w that achieves V (w, v) = v + e such that e ≥ 0, we have\nP(w) ≥ v + e g + 1\nProof. Let v′ = v + eg+1 . We will show that V (w, v ′) ≥ v′ which will establish the result by pseudo-linearity. We have\nV (w, v′)− v′ = c+ (α− v′γ) · P (w) + (β − v′δ) ·N(w)− v′\n= c+ (α− vγ) · P (w) + (β − vδ) ·N(w)− v′ − e g + 1 (γ · P (w) + δ ·N(w)) = v + e− v′ − e g + 1 (γ · P (w) + δ ·N(w)) ≥ v + e− v′ − ge g + 1 = 0,\nwhere we have used the bounds on γ · P (w) + δ ·N(w) and the fact that 1 + g > 0.\nGiven the above results we can establish the convergence bound. More specifically, we can show the following: let ∆t = P∗ − P(wt). Then we have\n∆t+1 ≤ g − f g + 1 ·∆t\nTo see this, consider the following ∆t+1 = P∗ − P(wt+1) ≤ P∗ − ( vt +\net g + 1\n) ≤ P∗ − ( vt +\n(1 + f)(P∗ − vt) g + 1 ) = P∗ − ( P(wt) +\n(1 + f)(P∗ − P(wt)) g + 1\n) = ∆t − 1 + f\ng + 1 ·∆t = g − f g + 1 ·∆t,\nwhich proves the result. Notice that Table 2 gives the rates of convergence for the different performance measures by calculating bounds on the value of g−fg+1 for those performance measures."
    }, {
      "heading" : "E An analysis of the AMP Algorithm under Inexact Maximizations",
      "text" : "For this and the next section, we will, for the sake of simplicity, we will focus only on the F-measure for β = 1 and p = 1/2 so that θ = 1. For this setting, the F-measure looks like the following: F (P,N) = 2P2+P−N , and the valuation function looks like V (w, v) = (1− v/2) · P (w) + v/2 ·N(w). We shall denote the performance measure as F (w), and its optimal value as F ∗. We will assume that the reward functions give bounded rewards in the range [0,m).\nSo far we assumed that Step 4 in the Algorithm AMP gave us wt+1 such that\nV (wt+1, vt) = max w∈W V (w, vt)\nNow we will only assume that wt+1 satisfies\nV (wt+1, vt) = max w∈W\nV (w, vt)− t\nWe also assume that the level vt is only approximated in Step 5 of AMP, i.e. using Lemma 7 we have\nvt = F (wt) + δt\nwhere δt is a signed real number. Given these approximations, we can prove the following results\nLemma 12. The following hold for the setting described above\n1. If δt ≤ 0 then et ≥ 0 2. If δt > 0 then et ≥ −δt ( 1 + m2 )\n3. If F ∗ < vt (which can happen only if δt > 0), then et < 0\n4. If et < 0 then F ∗ < vt\n5. We have (a) If et ≥ 0, then et ≥ ( 2−m 2 ) (F ∗ − vt).\n(b) If et < 0, then et ≥ ( 2+m 2 ) (F ∗ − vt).\n6. If V (w, v) = v + e, then\n(a) If e ≥ 0 then F (w) ≥ v + 2e2+m (b) If e < 0 then F (w) ≥ v + 2e2−m\nProof. We give the proof in parts\n1. If δt ≤ 0 then this means that there exists a w such that F (w) ≥ vt. The result then follows from pseudo linearity.\n2. vt = F (wt) + δt gives us, by pseudo linearity of F-measure, (1− vt/2) · P (wt) + vt/2 ·N(wt) = vt − δt ( 1 + P (wt)−N(wt)\n2\n) ≥ vt − δt ( 1 + m\n2\n) .\nThe bound on et now follows from its definition.\n3. Suppose et ≥ 0 then by pseudo linearity of F-measure, we have, for some w, V (w, vt) ≥ vt which means F (w) ≥ vt which contradicts the assumption.\n4. Suppose there exists w∗ with F (w∗) = vt + e′ with e′ ≥ 0 then we have (1− vt/2) · P (w∗) + vt/2 ·N(w∗) = vt + e′ ( 1 + P (w∗)−N(w∗)\n2\n) ≥ 0,\nwhich contradicts the fact that et < 0.\n5. Part (a) is simply Lemma 10. For part (b), we will prove that F ∗ ≤ vt + 2et2+m . Since 2\n2+m > 0, the result will follow. Assume the contrapositive that some w∗ achieves F (w∗) = vt + 2et2+m + e\n′ for some e′ > 0. Using the pseudo linearity of F-measure (and using the shorthand v′ = vt + 2et2+m + e ′), this can be expressed as\n(1− v′/2) · P (w∗) + v′/2 ·N(w∗) = v′\nwhere for some e′ > 0. Then we have\n(1− vt/2) · P (w∗) + vt/2 ·N(w∗)− vt − et = v′ − vt − et + 1\n2\n( 2et\n2 +m + e′\n) (P (w∗)−N(w∗))\n= 2et\n2 +m + e′ − et +\n1\n2\n( 2et\n2 +m + e′\n) (P (w∗)−N(w∗))\n≥ 2et 2 +m + e′ − et + m 2\n( 2et\n2 +m + e′ ) = e′ ( 1 + m\n2\n) + et ( 2\n2 +m − 1 + m 2 +m ) = e′ ( 1 + m\n2\n) > 0,\nwhere we have assumed that e′ is chosen small enough so that 2et2+m + e ′ < 0 still and used the fact that P (w∗)−N(w∗) ≤ m.\n6. Part (a) is simply Lemma 11. To prove part (b), we let v′ = v + 2e2−m , then we have\n(1− v ′\n2 ) · P (w) + v\n′\n2 ·N(w)− v′ = (1− v 2 ) · P (w) + v 2 ·N(w)− v′ + e 2−m (N(w)− P (w))\n≥ (1− v 2 ) · P (w) + v 2 ·N(w)− v′ + me 2−m\n= v + e− ( v + 2e\n2−m\n) + me\n2−m\n= e ( 1− 2\n2−m +\nm\n2−m ) = 0,\nwhere the second inequality follows since N(w) − P (w) ≤ m and e < 0 by using the bounds on the reward functions. This proves the result.\nE.1 Convergence analysis We have the following cases with us\n1. Case 1 (δt ≤ 0): In this case we are setting vt to a value less than the F-measure of the current classifier. This should hurt performance - we know that vt = F (wt) + δt which gives us, on applying part (a) of the previous lemma using F ∗ − vt = ∆t − δt, the following\net ≥ 2−m\n2 (∆t − δt).\nNote that we are guaranteed that et ≥ 0 in this case. Now since the maximization in step 4 is also carried our approximately, we have V (wt+1, vt) = vt + et − t. Now we have two sub cases\n(a) Case 1.1 ( t ≤ et): In this case we can apply part 6(a) of the previous lemma to get the following result\n∆t+1 ≤ 2m\n2 +m ∆t −\n2m\n2 +m δt + 2 t 2m\n(b) Case 1.2 ( t > et): In this case we are actually making negative progress in the maximization step (since we have V (wt+1, vt) ≤ vt) and we can only invoke Lemma 5.6(b) to get\n∆t+1 ≤ 2 t\n2−m\nNote that the above result should not be interpreted as a one shot step to a very good classifier. The above result holds along with the condition that t > et. Thus the performance of the classifier is lower bounded by et which depends on how far the current classifier is from the best.\n2. Case 2 (δt > 0): In this case we are setting vt to the value higher than the F-measure of the current classifier. This can mislead the classifier and results in the following two sub-cases\n(a) Case 2.1 (F ∗ ≥ vt): In this case we are still setting vt to a legitimate value, i.e. one that is a valid Fmeasure for some classifier in the hypothesis class. This can only benefit the next optimization stage (in fact if we set vt = F ∗, then we would obtain the best classifier in this very iteration!). In this case et ≥ 0 and we can use the analyses of Cases 1.1 and 1.2.\n(b) Case 2.2 (F ∗ < vt): In this case we are setting vt to an illegal value, one that is an unachievable value of F-measure. Consequently, using part 3 of the previous lemma, et < 0 and using part(b) of the previous lemma we get\net ≥ 2 +m\n2 (∆t − δt),\nwhich, upon applying part 6(b) of the previous lemma (since et − t ≤ et < 0) will give us\n∆t+1 ≤ 2m\n2−m (δt −∆t) + 2 t 2−m\n≤ 2m 2−m δt + 2 t 2−m\nWe can combine the cases together as follows ∆t+1 ≤ max { 1 {δ ≤ 0} · { 2m\n2 +m ∆t −\n2m\n2 +m δt + 2 t 2 +m\n} ,1 { t > et} ·\n2 t 2−m\n,1 {δ > 0} · { 2m\n2−m δt + 2 t 2−m }} ≤ max { 2m\n2 +m ∆t +\n2m\n2 +m |δt|+ 2 t 2 +m ,1 { t > et} · 2 t 2−m , 2m 2−m |δt|+ 2 t 2−m } ≤ 2m\n2 +m ∆t +\n2m\n2−m |δt|+ 2 t 2−m\nIf we let η = 2m2+m , η ′ = 2m2−m , and ξt = |δt|+ t/m, then this gives us\n∆t+1 ≤ η∆t + η′ξt,\nwhich gives us\n∆T ≤ ηT∆0 + η′ η · T−1∑ i=0 ηT−iξi\nThis concludes our analysis."
    }, {
      "heading" : "F Proof of Theorem 9",
      "text" : "Theorem 9. Let Algorithm 3 be executed with a performance measure P(a,b) and reward functions with range [0,m). Let η = η(m) be the rate of convergence guaranteed for P(a,b) by the AMP algorithm. Set the epoch lengths to se, s ′ e = Õ ( 1 η2e ) . Then after e = log 1\nη\n( 1 log 2 1 ) epochs, we can ensure with probability at least 1 − δ that\nP∗ − P(a,b)(we) ≤ . Moreover the number of samples consumed till this point is at most Õ ( 1 2 ) .\nProof. Using Hoeffding’s inequality, standard regret and online-to-batch guarantees Cesa-Bianchi et al. [2001], Zinkevich [2003], we can ensure that, if the stream lengths for the Model optimization stage and Challenge level estimation stage procedures are se and s′e respectively, then for some fixed c > 0 that is independent of the stream length, we have\n|δt| ≤ c · √ log 1δ s′e , | t| ≤ c √ log 1δ se\nLet T = log 1 η\n( 1 log 2 1 ) and se = ( 2c m )2 ( 1 η )2e log Tδ and s ′ e = 4c 2 ( 1 η )2e log Tδ - this gives us, for each e, with\nprobability at least 1− δ/T , ξe ≤ ηe\nThus, using a union bound, with probability at least 1− δ, we have, by the discussion in the previous section,\n∆T ≤ ηT∆0 + η′\nη T−1∑ i=0 ηT−iξi ≤ ηT∆0 + η′ η TηT\n≤ ∆0 log−2 1 + η′\nη log 1 η\n( 1\nlog2\n1 ) log−2 1\n≤ ( ∆0 + η′\nη log 1η\n) ,\nwhere the last step follows from the fact that for any < 1/e2, we have\nlog\n( 1\nlog2\n1 ) ≤ log2 1\nLet d = ( ∆0 + η′\nη log 1η\n) so that we can later set ′ = /d, and s = 4c2 ( 1 + 1m2 ) so that se + s′e = s ( 1 η )2e log Tδ .\nThe total number of samples required can then be calculated as\nT∑ e=1 se + s ′ e = s log T δ T∑ e=1 ( 1 η )2e = s log T δ 1 1− η2 ( 1 η2 )T ≤ s log T δ 1 1− η2 1 2 log4 1\nThis gives the number of samples required as O ( 1\n2 log4\n1 ( log log 1 + log 1\nδ\n)) ,\nto get an -accurate solution with confidence 1− δ."
    } ],
    "references" : [ {
      "title" : "Pattern Recognition and Machine Learning",
      "author" : [ "Christopher M. Bishop" ],
      "venue" : null,
      "citeRegEx" : "Bishop.,? \\Q2006\\E",
      "shortCiteRegEx" : "Bishop.",
      "year" : 2006
    }, {
      "title" : "On the Generalization Ability of On-Line Learning Algorithms",
      "author" : [ "Nicoló Cesa-Bianchi", "Alex Conconi", "Claudio Gentile" ],
      "venue" : "In 15th Annual Conference on Neural Information Processing Systems (NIPS),",
      "citeRegEx" : "Cesa.Bianchi et al\\.,? \\Q2001\\E",
      "shortCiteRegEx" : "Cesa.Bianchi et al\\.",
      "year" : 2001
    }, {
      "title" : "Evaluation of Classifiers for an Uneven Class Distribution Problem",
      "author" : [ "Sophia Daskalaki", "Ioannis Kopanas", "Nikolaos Avouris" ],
      "venue" : "Applied Artificial Intelligence,",
      "citeRegEx" : "Daskalaki et al\\.,? \\Q2006\\E",
      "shortCiteRegEx" : "Daskalaki et al\\.",
      "year" : 2006
    }, {
      "title" : "Optimizing the F-Measure in Multi-Label Classification: Plug-in Rule Approach versus Structured Loss Minimization",
      "author" : [ "Krzysztof Dembczyński", "Arkadiusz Jachnik", "Wojciech Kotlowski", "Willem Waegeman", "Eyke Hüllermeier" ],
      "venue" : "In 30th International Conference on Machine Learning (ICML),",
      "citeRegEx" : "Dembczyński et al\\.,? \\Q2013\\E",
      "shortCiteRegEx" : "Dembczyński et al\\.",
      "year" : 2013
    }, {
      "title" : "On Nonlinear Fractional Programming",
      "author" : [ "Werner Dinkelbach" ],
      "venue" : "Management Science,",
      "citeRegEx" : "Dinkelbach.,? \\Q1967\\E",
      "shortCiteRegEx" : "Dinkelbach.",
      "year" : 1967
    }, {
      "title" : "Multi-Label Prediction via Compressed Sensing",
      "author" : [ "Daniel Hsu", "Sham Kakade", "John Langford", "Tong Zhang" ],
      "venue" : "In 23rd Annual Conference on Neural Information Processing Systems (NIPS),",
      "citeRegEx" : "Hsu et al\\.,? \\Q2009\\E",
      "shortCiteRegEx" : "Hsu et al\\.",
      "year" : 2009
    }, {
      "title" : "On Some Properties of Programming Problems in Parametric Form Pertaining to Fractional Programming",
      "author" : [ "R. Jagannathan" ],
      "venue" : "Management Science,",
      "citeRegEx" : "Jagannathan.,? \\Q1966\\E",
      "shortCiteRegEx" : "Jagannathan.",
      "year" : 1966
    }, {
      "title" : "Communication-Efficient Distributed Dual Coordinate Ascent",
      "author" : [ "Martin Jaggi", "Virginia Smith", "Martin Takác", "Jonathan Terhorst", "Sanjay Krishnan", "Thomas Hofmann", "Michael I. Jordan" ],
      "venue" : "In 28th Annual Conference on Neural Information Processing Systems (NIPS),",
      "citeRegEx" : "Jaggi et al\\.,? \\Q2014\\E",
      "shortCiteRegEx" : "Jaggi et al\\.",
      "year" : 2014
    }, {
      "title" : "Cutting-plane training of structural SVMs",
      "author" : [ "Thorsten Joachims", "Thomas Finley", "Chun-Nam John Yu" ],
      "venue" : "Machine Learning,",
      "citeRegEx" : "Joachims et al\\.,? \\Q2009\\E",
      "shortCiteRegEx" : "Joachims et al\\.",
      "year" : 2009
    }, {
      "title" : "On the Generalization Ability of Online Learning Algorithms for Pairwise Loss Functions",
      "author" : [ "Purushottam Kar", "Bharath K Sriperumbudur", "Prateek Jain", "Harish Karnick" ],
      "venue" : "In 30th International Conference on Machine Learning (ICML),",
      "citeRegEx" : "Kar et al\\.,? \\Q2013\\E",
      "shortCiteRegEx" : "Kar et al\\.",
      "year" : 2013
    }, {
      "title" : "Online and Stochastic Gradient Methods for Nondecomposable Loss Functions",
      "author" : [ "Purushottam Kar", "Harikrishna Narasimhan", "Prateek Jain" ],
      "venue" : "In 28th Annual Conference on Neural Information Processing Systems (NIPS),",
      "citeRegEx" : "Kar et al\\.,? \\Q2014\\E",
      "shortCiteRegEx" : "Kar et al\\.",
      "year" : 2014
    }, {
      "title" : "Learning without default: a study of one-class classification and the low-default portfolio problem",
      "author" : [ "Kenneth Kennedy", "Brian Mac Namee", "Sarah Jane Delany" ],
      "venue" : "In International Conference on Artificial Intelligence and Cognitive Science (ICAICS),",
      "citeRegEx" : "Kennedy et al\\.,? \\Q2010\\E",
      "shortCiteRegEx" : "Kennedy et al\\.",
      "year" : 2010
    }, {
      "title" : "Consistent Binary Classification with Generalized Performance Metrics",
      "author" : [ "Oluwasanmi O. Koyejo", "Nagarajan Natarajan", "Pradeep K. Ravikumar", "Inderjit S. Dhillon" ],
      "venue" : "In 28th Annual Conference on Neural Information Processing Systems (NIPS),",
      "citeRegEx" : "Koyejo et al\\.,? \\Q2014\\E",
      "shortCiteRegEx" : "Koyejo et al\\.",
      "year" : 2014
    }, {
      "title" : "Evaluating and optimizing autonomous text classification systems",
      "author" : [ "D.D. Lewis" ],
      "venue" : "In 18th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR),",
      "citeRegEx" : "Lewis.,? \\Q1995\\E",
      "shortCiteRegEx" : "Lewis.",
      "year" : 1995
    }, {
      "title" : "A Quadratic Mean based Supervised Learning Model for Managing Data Skewness",
      "author" : [ "W. Liu", "S. Chawla" ],
      "venue" : "In 11th SIAM International Conference on Data Mining (SDM),",
      "citeRegEx" : "Liu and Chawla.,? \\Q2011\\E",
      "shortCiteRegEx" : "Liu and Chawla.",
      "year" : 2011
    }, {
      "title" : "Stochastic Convex Optimization with Multiple Objectives",
      "author" : [ "Mehrdad Mahdavi", "Tianbao Yang", "Rong Jin" ],
      "venue" : "In 27th Annual Conference on Neural Information Processing Systems (NIPS),",
      "citeRegEx" : "Mahdavi et al\\.,? \\Q2013\\E",
      "shortCiteRegEx" : "Mahdavi et al\\.",
      "year" : 2013
    }, {
      "title" : "Introduction to Information Retrieval",
      "author" : [ "C.D. Manning", "P. Raghavan", "H. Schütze" ],
      "venue" : null,
      "citeRegEx" : "Manning et al\\.,? \\Q2008\\E",
      "shortCiteRegEx" : "Manning et al\\.",
      "year" : 2008
    }, {
      "title" : "On the Statistical Consistency of Plug-in Classifiers for Non-decomposable Performance Measures",
      "author" : [ "Harikrishna Narasimhan", "Rohit Vaish", "Shivani Agarwal" ],
      "venue" : "In 28th Annual Conference on Neural Information Processing Systems (NIPS),",
      "citeRegEx" : "Narasimhan et al\\.,? \\Q2014\\E",
      "shortCiteRegEx" : "Narasimhan et al\\.",
      "year" : 2014
    }, {
      "title" : "Optimizing F-Measures by Cost-Sensitive Classification",
      "author" : [ "Shameem Puthiya Parambath", "Nicolas Usunier", "Yves Grandvalet" ],
      "venue" : "In 28th Annual Conference on Neural Information Processing Systems (NIPS),",
      "citeRegEx" : "Parambath et al\\.,? \\Q2014\\E",
      "shortCiteRegEx" : "Parambath et al\\.",
      "year" : 2014
    }, {
      "title" : "Online Learning: Beyond Regret",
      "author" : [ "Alexander Rakhlin", "Karthik Sridharan", "Ambuj Tewari" ],
      "venue" : "In 24th Annual Conference on Learning Theory (COLT),",
      "citeRegEx" : "Rakhlin et al\\.,? \\Q2011\\E",
      "shortCiteRegEx" : "Rakhlin et al\\.",
      "year" : 2011
    }, {
      "title" : "Fractional Programming. II, on Dinkelbach’s Algorithm",
      "author" : [ "Siegfried Schaible" ],
      "venue" : "Management Science,",
      "citeRegEx" : "Schaible.,? \\Q1976\\E",
      "shortCiteRegEx" : "Schaible.",
      "year" : 1976
    }, {
      "title" : "Pegasos: primal estimated sub-gradient solver for SVM",
      "author" : [ "Shai Shalev-Shwartz", "Yoram Singer", "Nathan Srebro", "Andrew Cotter" ],
      "venue" : "Math. Program.,",
      "citeRegEx" : "Shalev.Shwartz et al\\.,? \\Q2011\\E",
      "shortCiteRegEx" : "Shalev.Shwartz et al\\.",
      "year" : 2011
    }, {
      "title" : "A systematic analysis of performance measures for classification tasks",
      "author" : [ "Marina Sokolova", "Guy Lapalme" ],
      "venue" : "Information Processing & Management,",
      "citeRegEx" : "Sokolova and Lapalme.,? \\Q2009\\E",
      "shortCiteRegEx" : "Sokolova and Lapalme.",
      "year" : 2009
    }, {
      "title" : "An Introduction to Signal Detection and Estimation",
      "author" : [ "P.H. Vincent" ],
      "venue" : null,
      "citeRegEx" : "Vincent.,? \\Q1994\\E",
      "shortCiteRegEx" : "Vincent.",
      "year" : 1994
    }, {
      "title" : "Optimizing F-Measures: A Tale of Two Approaches",
      "author" : [ "Nan Ye", "Kian Ming A. Chai", "Wee Sun Lee", "Hai Leong Chieu" ],
      "venue" : "In 29th International Conference on Machine Learning (ICML),",
      "citeRegEx" : "Ye et al\\.,? \\Q2012\\E",
      "shortCiteRegEx" : "Ye et al\\.",
      "year" : 2012
    }, {
      "title" : "Online Convex Programming and Generalized Infinitesimal Gradient Ascent",
      "author" : [ "Martin Zinkevich" ],
      "venue" : "In 20th International Conference on Machine Learning (ICML),",
      "citeRegEx" : "Zinkevich.,? \\Q2003\\E",
      "shortCiteRegEx" : "Zinkevich.",
      "year" : 2003
    } ],
    "referenceMentions" : [ {
      "referenceID" : 0,
      "context" : "Class imbalance is also often introduced as a result of the reduction of a problem to binary classification, such as in multi-class problems Bishop [2006] and multi-label problems due to extreme label sparsity Hsu et al.",
      "startOffset" : 141,
      "endOffset" : 155
    }, {
      "referenceID" : 0,
      "context" : "Class imbalance is also often introduced as a result of the reduction of a problem to binary classification, such as in multi-class problems Bishop [2006] and multi-label problems due to extreme label sparsity Hsu et al. [2009]. Traditional performance measures such as misclassification rate are ill-suited in such situations as it is usually trivial to optimize them by constantly predicting the majority class.",
      "startOffset" : 141,
      "endOffset" : 228
    }, {
      "referenceID" : 0,
      "context" : "Class imbalance is also often introduced as a result of the reduction of a problem to binary classification, such as in multi-class problems Bishop [2006] and multi-label problems due to extreme label sparsity Hsu et al. [2009]. Traditional performance measures such as misclassification rate are ill-suited in such situations as it is usually trivial to optimize them by constantly predicting the majority class. Instead, the performance measures of choice in such cases are those that perform a more holistic evaluation over the entire data. Naturally, these performance measures are non-decomposable over the dataset and cannot be cannot be expressed as a sum of errors on individual data points. Popular examples include F-measure, G-mean, H-mean etc. A consistent effort directed at optimizing these performance measures has, over the years, resulted in the development of two broad approaches - 1) surrogate based approaches (e.g. SVMPerf Joachims et al. [2009]) that design convex surrogates for these performance measures, and 2) indirect approaches which include cost-sensitive classification-based approaches Parambath et al.",
      "startOffset" : 141,
      "endOffset" : 968
    }, {
      "referenceID" : 0,
      "context" : "Class imbalance is also often introduced as a result of the reduction of a problem to binary classification, such as in multi-class problems Bishop [2006] and multi-label problems due to extreme label sparsity Hsu et al. [2009]. Traditional performance measures such as misclassification rate are ill-suited in such situations as it is usually trivial to optimize them by constantly predicting the majority class. Instead, the performance measures of choice in such cases are those that perform a more holistic evaluation over the entire data. Naturally, these performance measures are non-decomposable over the dataset and cannot be cannot be expressed as a sum of errors on individual data points. Popular examples include F-measure, G-mean, H-mean etc. A consistent effort directed at optimizing these performance measures has, over the years, resulted in the development of two broad approaches - 1) surrogate based approaches (e.g. SVMPerf Joachims et al. [2009]) that design convex surrogates for these performance measures, and 2) indirect approaches which include cost-sensitive classification-based approaches Parambath et al. [2014] which solve weighted classification problems, and plug-in approaches Koyejo et al.",
      "startOffset" : 141,
      "endOffset" : 1143
    }, {
      "referenceID" : 0,
      "context" : "Class imbalance is also often introduced as a result of the reduction of a problem to binary classification, such as in multi-class problems Bishop [2006] and multi-label problems due to extreme label sparsity Hsu et al. [2009]. Traditional performance measures such as misclassification rate are ill-suited in such situations as it is usually trivial to optimize them by constantly predicting the majority class. Instead, the performance measures of choice in such cases are those that perform a more holistic evaluation over the entire data. Naturally, these performance measures are non-decomposable over the dataset and cannot be cannot be expressed as a sum of errors on individual data points. Popular examples include F-measure, G-mean, H-mean etc. A consistent effort directed at optimizing these performance measures has, over the years, resulted in the development of two broad approaches - 1) surrogate based approaches (e.g. SVMPerf Joachims et al. [2009]) that design convex surrogates for these performance measures, and 2) indirect approaches which include cost-sensitive classification-based approaches Parambath et al. [2014] which solve weighted classification problems, and plug-in approaches Koyejo et al. [2014], Narasimhan et al.",
      "startOffset" : 141,
      "endOffset" : 1233
    }, {
      "referenceID" : 0,
      "context" : "Class imbalance is also often introduced as a result of the reduction of a problem to binary classification, such as in multi-class problems Bishop [2006] and multi-label problems due to extreme label sparsity Hsu et al. [2009]. Traditional performance measures such as misclassification rate are ill-suited in such situations as it is usually trivial to optimize them by constantly predicting the majority class. Instead, the performance measures of choice in such cases are those that perform a more holistic evaluation over the entire data. Naturally, these performance measures are non-decomposable over the dataset and cannot be cannot be expressed as a sum of errors on individual data points. Popular examples include F-measure, G-mean, H-mean etc. A consistent effort directed at optimizing these performance measures has, over the years, resulted in the development of two broad approaches - 1) surrogate based approaches (e.g. SVMPerf Joachims et al. [2009]) that design convex surrogates for these performance measures, and 2) indirect approaches which include cost-sensitive classification-based approaches Parambath et al. [2014] which solve weighted classification problems, and plug-in approaches Koyejo et al. [2014], Narasimhan et al. [2014] which rely on consistent estimates of class probabilities.",
      "startOffset" : 141,
      "endOffset" : 1259
    }, {
      "referenceID" : 19,
      "context" : "For large datasets, streaming methods such as stochastic gradient descent Shalev-Shwartz et al. [2011] that take only a few passes over the entire data are preferable.",
      "startOffset" : 74,
      "endOffset" : 103
    }, {
      "referenceID" : 9,
      "context" : "Recently, Kar et al. [2014] proposed optimizing SVMPerf-style surrogates using SGD techniques.",
      "startOffset" : 10,
      "endOffset" : 28
    }, {
      "referenceID" : 9,
      "context" : "A third approach applicable to certain performance measures is the decision-theoretic method that learns a class probability estimate and computes predictions that maximize the expected value of the performance measure on a test set Lewis [1995], Ye et al.",
      "startOffset" : 233,
      "endOffset" : 246
    }, {
      "referenceID" : 9,
      "context" : "A third approach applicable to certain performance measures is the decision-theoretic method that learns a class probability estimate and computes predictions that maximize the expected value of the performance measure on a test set Lewis [1995], Ye et al. [2012]. In addition to these there exist methods dedicated to specific performance measures.",
      "startOffset" : 233,
      "endOffset" : 264
    }, {
      "referenceID" : 9,
      "context" : "A third approach applicable to certain performance measures is the decision-theoretic method that learns a class probability estimate and computes predictions that maximize the expected value of the performance measure on a test set Lewis [1995], Ye et al. [2012]. In addition to these there exist methods dedicated to specific performance measures. For instance Parambath et al. [2014] focus on optimizing F-measure by exploiting the pseudo-linearity of the function along with a cross validation-based strategy.",
      "startOffset" : 233,
      "endOffset" : 387
    }, {
      "referenceID" : 3,
      "context" : "For instance, Dembczyński et al. [2013] study plug-in style methods for maximizing F-measure in multi-label settings whereas works such as Koyejo et al.",
      "startOffset" : 14,
      "endOffset" : 40
    }, {
      "referenceID" : 3,
      "context" : "For instance, Dembczyński et al. [2013] study plug-in style methods for maximizing F-measure in multi-label settings whereas works such as Koyejo et al. [2014], Narasimhan et al.",
      "startOffset" : 14,
      "endOffset" : 160
    }, {
      "referenceID" : 3,
      "context" : "For instance, Dembczyński et al. [2013] study plug-in style methods for maximizing F-measure in multi-label settings whereas works such as Koyejo et al. [2014], Narasimhan et al. [2014], Ye et al.",
      "startOffset" : 14,
      "endOffset" : 186
    }, {
      "referenceID" : 3,
      "context" : "For instance, Dembczyński et al. [2013] study plug-in style methods for maximizing F-measure in multi-label settings whereas works such as Koyejo et al. [2014], Narasimhan et al. [2014], Ye et al. [2012] study plug-in approaches for the same problem in the more challenging binary classification setting.",
      "startOffset" : 14,
      "endOffset" : 204
    }, {
      "referenceID" : 3,
      "context" : "For instance, Dembczyński et al. [2013] study plug-in style methods for maximizing F-measure in multi-label settings whereas works such as Koyejo et al. [2014], Narasimhan et al. [2014], Ye et al. [2012] study plug-in approaches for the same problem in the more challenging binary classification setting. Historically, online learning algorithms have played a key role in designing solvers for large-scale batch problems. However, for non-decomposable loss functions, defining an online learning framework and providing efficient algorithms with small regret itself is challenging. Rakhlin et al. [2011] propose a generic method for such loss functions; however the algorithms proposed therein run in exponential time.",
      "startOffset" : 14,
      "endOffset" : 604
    }, {
      "referenceID" : 3,
      "context" : "For instance, Dembczyński et al. [2013] study plug-in style methods for maximizing F-measure in multi-label settings whereas works such as Koyejo et al. [2014], Narasimhan et al. [2014], Ye et al. [2012] study plug-in approaches for the same problem in the more challenging binary classification setting. Historically, online learning algorithms have played a key role in designing solvers for large-scale batch problems. However, for non-decomposable loss functions, defining an online learning framework and providing efficient algorithms with small regret itself is challenging. Rakhlin et al. [2011] propose a generic method for such loss functions; however the algorithms proposed therein run in exponential time. Kar et al. [2014] also study such measures with the",
      "startOffset" : 14,
      "endOffset" : 737
    }, {
      "referenceID" : 25,
      "context" : "Our methods make use of standard online convex optimization primitives Zinkevich [2003]. However, their application requires special care in order to avoid divergent behavior.",
      "startOffset" : 71,
      "endOffset" : 88
    }, {
      "referenceID" : 23,
      "context" : "A large number of popular performance measures fall in this family since these measures are relevant in situations with severe label imbalance or in situations where cost-sensitive classification is required such as detection theory Vincent [1994]. Table 1 gives a list of such performance measures along with some of their relevant properties and references to works that utilize these performance measures.",
      "startOffset" : 233,
      "endOffset" : 248
    }, {
      "referenceID" : 20,
      "context" : "Min (Vincent [1994]) min{P,N} X X {α+ β = 1} ∩ R+ 0 H-mean (Kennedy et al.",
      "startOffset" : 5,
      "endOffset" : 20
    }, {
      "referenceID" : 10,
      "context" : "Min (Vincent [1994]) min{P,N} X X {α+ β = 1} ∩ R+ 0 H-mean (Kennedy et al. [2010]) 2PN P+N X X 4 {√ α+ √ β ≥ √ 2 } ∩ B(0, 2) 0 Q-mean (Liu and Chawla [2011]) 1− √ (1−P )2+(1−N)2 2 X X { α + β ≤ 1/2 } ∩ R+ 1 G-mean (Daskalaki et al.",
      "startOffset" : 60,
      "endOffset" : 82
    }, {
      "referenceID" : 10,
      "context" : "Min (Vincent [1994]) min{P,N} X X {α+ β = 1} ∩ R+ 0 H-mean (Kennedy et al. [2010]) 2PN P+N X X 4 {√ α+ √ β ≥ √ 2 } ∩ B(0, 2) 0 Q-mean (Liu and Chawla [2011]) 1− √ (1−P )2+(1−N)2 2 X X { α + β ≤ 1/2 } ∩ R+ 1 G-mean (Daskalaki et al.",
      "startOffset" : 60,
      "endOffset" : 157
    }, {
      "referenceID" : 2,
      "context" : "[2010]) 2PN P+N X X 4 {√ α+ √ β ≥ √ 2 } ∩ B(0, 2) 0 Q-mean (Liu and Chawla [2011]) 1− √ (1−P )2+(1−N)2 2 X X { α + β ≤ 1/2 } ∩ R+ 1 G-mean (Daskalaki et al. [2006]) √ PN X 7 3 √ {αβ ≥ 1/4} ∩ R+ 0",
      "startOffset" : 140,
      "endOffset" : 164
    }, {
      "referenceID" : 9,
      "context" : "Recent works Kar et al. [2013, 2014] have tried to resolve this issue by looking at mini-batch methods or by using a buffer to maintain a sketch of the stream. However, such techniques bring in a bias into the learning algorithm in the form of buffer size or mini batch length which results in slower convergence. Indeed, the 1PMB method of Kar et al. [2014] is only able to guarantee a −4 √ T rate of convergence, whereas SGD techniques are usually able to guarantee −2 √ T rates.",
      "startOffset" : 13,
      "endOffset" : 359
    }, {
      "referenceID" : 7,
      "context" : "We note here that primal dual frameworks have been utilized before in diverse areas such as distributed optimization Jaggi et al. [2014] and multi-objective optimization Mahdavi et al.",
      "startOffset" : 117,
      "endOffset" : 137
    }, {
      "referenceID" : 7,
      "context" : "We note here that primal dual frameworks have been utilized before in diverse areas such as distributed optimization Jaggi et al. [2014] and multi-objective optimization Mahdavi et al. [2013]. However, these works simply assume the functions involved therein to be Lipschitz and/or smooth and do not address cases where they fail to be so.",
      "startOffset" : 117,
      "endOffset" : 192
    }, {
      "referenceID" : 18,
      "context" : "We refer the reader to Parambath et al. [2014] for a more relaxed introduction to these functions and their properties.",
      "startOffset" : 23,
      "endOffset" : 47
    }, {
      "referenceID" : 18,
      "context" : "We refer the reader to Parambath et al. [2014] for a more relaxed introduction to these functions and their properties. For our purposes, however, it suffices to notice that this property immediately points toward a cost-sensitive method to optimize these performance measures. This fact was noticed by Parambath et al. [2014] who exploited this to develop a cost-sensitive classification method for optimizing the F-measure by simply searching for the best weights with which to perform cost-sensitive classification.",
      "startOffset" : 23,
      "endOffset" : 327
    }, {
      "referenceID" : 18,
      "context" : "Pseudo-linear functions have enjoyed a fair amount of interest in the optimization community Schaible [1976], Dinkelbach [1967], Jagannathan [1966] within the sub-field of fractional programming.",
      "startOffset" : 93,
      "endOffset" : 109
    }, {
      "referenceID" : 4,
      "context" : "Pseudo-linear functions have enjoyed a fair amount of interest in the optimization community Schaible [1976], Dinkelbach [1967], Jagannathan [1966] within the sub-field of fractional programming.",
      "startOffset" : 110,
      "endOffset" : 128
    }, {
      "referenceID" : 4,
      "context" : "Pseudo-linear functions have enjoyed a fair amount of interest in the optimization community Schaible [1976], Dinkelbach [1967], Jagannathan [1966] within the sub-field of fractional programming.",
      "startOffset" : 110,
      "endOffset" : 148
    }, {
      "referenceID" : 4,
      "context" : "Pseudo-linear functions have enjoyed a fair amount of interest in the optimization community Schaible [1976], Dinkelbach [1967], Jagannathan [1966] within the sub-field of fractional programming. Of the many methods that have been developed to optimize these functions, the DinkelbachJagannathan (DJ) procedure Dinkelbach [1967], Jagannathan [1966] is of specific interest to us.",
      "startOffset" : 110,
      "endOffset" : 329
    }, {
      "referenceID" : 4,
      "context" : "Pseudo-linear functions have enjoyed a fair amount of interest in the optimization community Schaible [1976], Dinkelbach [1967], Jagannathan [1966] within the sub-field of fractional programming. Of the many methods that have been developed to optimize these functions, the DinkelbachJagannathan (DJ) procedure Dinkelbach [1967], Jagannathan [1966] is of specific interest to us.",
      "startOffset" : 110,
      "endOffset" : 349
    }, {
      "referenceID" : 4,
      "context" : "Pseudo-linear functions have enjoyed a fair amount of interest in the optimization community Schaible [1976], Dinkelbach [1967], Jagannathan [1966] within the sub-field of fractional programming. Of the many methods that have been developed to optimize these functions, the DinkelbachJagannathan (DJ) procedure Dinkelbach [1967], Jagannathan [1966] is of specific interest to us. It turns out that the AMP method can be seen as performing DJ-style updates over parameterized spaces (the parameter being the model w). It is known (for instance see Schaible [1976]) that the DJ process is able to offer a linear convergence rates.",
      "startOffset" : 110,
      "endOffset" : 563
    }, {
      "referenceID" : 4,
      "context" : "Pseudo-linear functions have enjoyed a fair amount of interest in the optimization community Schaible [1976], Dinkelbach [1967], Jagannathan [1966] within the sub-field of fractional programming. Of the many methods that have been developed to optimize these functions, the DinkelbachJagannathan (DJ) procedure Dinkelbach [1967], Jagannathan [1966] is of specific interest to us. It turns out that the AMP method can be seen as performing DJ-style updates over parameterized spaces (the parameter being the model w). It is known (for instance see Schaible [1976]) that the DJ process is able to offer a linear convergence rates. Our proof of Theorem 8, which was obtained independently, can then be seen as giving a similar result in the parameterized setting. However, we wish to move one step further and optimize these performance measures in an online stochastic manner. To this end, we observe that the AMP algorithm can be executed in an online fashion by using stochastic updates to train the intermediate models. The resulting algorithm STAMP, is presented in Algorithm 3. However, this algorithm is much harder to analyze because unlike AMP which has the luxury of offering exact updates, STAMP offers inexact, even noisy updates. Indeed, even existing works in the optimization community (for example Schaible [1976]) do not seem to have analyzed DJ-style methods with noisy updates.",
      "startOffset" : 110,
      "endOffset" : 1327
    }, {
      "referenceID" : 8,
      "context" : "cases we compared to the SVMPerf method Joachims et al. [2009] and plug-in method Koyejo et al.",
      "startOffset" : 40,
      "endOffset" : 63
    }, {
      "referenceID" : 8,
      "context" : "cases we compared to the SVMPerf method Joachims et al. [2009] and plug-in method Koyejo et al. [2014] specialized to these measures.",
      "startOffset" : 40,
      "endOffset" : 103
    }, {
      "referenceID" : 8,
      "context" : "cases we compared to the SVMPerf method Joachims et al. [2009] and plug-in method Koyejo et al. [2014] specialized to these measures. For the sake of reference, we also compared to the standard logistic regression method for (unweighted) binary classification. Additionally for F1-measure, we also compared to the 1PMB stochastic gradient descent method proposed recently by Kar et al. [2014]. All methods were implemented in C.",
      "startOffset" : 40,
      "endOffset" : 393
    }, {
      "referenceID" : 9,
      "context" : "Secondly, we note that both SVMPerf and 1PMB optimize the same “struct-SVM” style surrogate for the F-measure Kar et al. [2014]. This surrogate has been observed to give poor accuracies when compared to plug-in methods in several previous works Koyejo et al.",
      "startOffset" : 110,
      "endOffset" : 128
    }, {
      "referenceID" : 9,
      "context" : "Secondly, we note that both SVMPerf and 1PMB optimize the same “struct-SVM” style surrogate for the F-measure Kar et al. [2014]. This surrogate has been observed to give poor accuracies when compared to plug-in methods in several previous works Koyejo et al. [2014], Narasimhan et al.",
      "startOffset" : 110,
      "endOffset" : 266
    }, {
      "referenceID" : 9,
      "context" : "Secondly, we note that both SVMPerf and 1PMB optimize the same “struct-SVM” style surrogate for the F-measure Kar et al. [2014]. This surrogate has been observed to give poor accuracies when compared to plug-in methods in several previous works Koyejo et al. [2014], Narasimhan et al. [2014]. STAMP on the other hand, works directly with F-measure in a manner similar to, but faster than, the plug-in methods which might explain its better performance.",
      "startOffset" : 110,
      "endOffset" : 292
    } ],
    "year" : 2015,
    "abstractText" : "Modern classification problems frequently present mild to severe label imbalance as well as specific requirements on classification characteristics, and require optimizing performance measures that are non-decomposable over the dataset, such as F-measure. Such measures have spurred much interest and pose specific challenges to learning algorithms since their non-additive nature precludes a direct application of well-studied large scale optimization methods such as stochastic gradient descent. In this paper we reveal that for two large families of performance measures that can be expressed as functions of true positive/negative rates, it is indeed possible to implement point stochastic updates. The families we consider are concave and pseudo-linear functions of TPR, TNR which cover several popularly used performance measures such as F-measure, G-mean and H-mean. Our core contribution is an adaptive linearization scheme for these families, using which we develop optimization techniques that enable truly point-based stochastic updates. For concave performance measures we propose SPADE, a stochastic primal dual solver; for pseudo-linear measures we propose STAMP, a stochastic alternate maximization procedure. Both methods have crisp convergence guarantees, demonstrate significant speedups over existing methods often by an order of magnitude or more, and give similar or more accurate predictions on test data.",
    "creator" : "LaTeX with hyperref package"
  }
}