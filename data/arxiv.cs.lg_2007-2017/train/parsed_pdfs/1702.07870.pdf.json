{
  "name" : "1702.07870.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "Online Learning with Many Experts",
    "authors" : [ "Alon Cohen", "Shie Mannor" ],
    "emails" : [ ],
    "sections" : [ {
      "heading" : null,
      "text" : "ar X\niv :1\n70 2.\n07 87\n0v 1\n[ cs\n.L G\n] 2\n5 Fe\nb 20\n17\n? NT q, where N is the empirical ǫ-covering number of the\nsequence of loss functions generated by the environment. In addition, we present a hedging procedure that allows us to find the optimal ǫ in hindsight.\nFinally, we discuss a few interesting applications of our algorithm. We show how our algorithm is applicable in the approximately low rank experts model of Hazan et al., 2016, and discuss the case of experts with bounded variation, in which there is a surprisingly large gap between the regret bounds obtained in the statistical and online settings."
    }, {
      "heading" : "1 Introduction",
      "text" : "In this paper we study the well known problem of prediction with expert advice, that can be seen as a game between a learner and an environment. At each round t “ 1, 2, . . . , T , a learner randomly decides to take the advice of an expert It from a predetermined set X of experts. Simultaneously, the environment chooses a loss function ℓt : X ÞÑ r´1, 1s and afterwards the learner incurs ℓtpItq, the loss associated with that expert.\nThe goal of the learner throughout the T rounds of the game is to minimize her expected regret, defined as the expected difference between her cumulative loss and the cumulative loss of the best fixed expert in hindsight:\nRT “ E « Tÿ\nt“1\nℓtpItq ´ inf iPX\nTÿ\nt“1\nℓtpiq ff ,\nwhere the expectation is taken over the random choices of the learner. A fundamental result in the field of online learning states that, in the worst case, the best strategy for the learner incurs Op ? T logKq regret in the worst case (Cesa-Bianchi et al., 1997), where K is the number of experts. However, in many natural problems the number of experts may be extremely large, possibly infinite, albeit their advices may be highly ”correlated”. In an extreme case, their advices may even be grouped together in a small number of clusters.\nAs a motivating application consider the problem of investment portfolio selection over a given set of stocks. These stocks may be categorized by a small number of parameters and each parameter may have a small number of possible values, but the overall number of combinations of these parameters can be very large. Thus every expert may advise on a different portfolio, but the portfolios themselves may give similar revenues due to the correlation resulted by the overlap in parametrization between the different stocks.\nAnother possible application is when the experts themselves arise from a reduction between another online learning problem and prediction with expert advice. This can occur, for example, in online supervised learning (Ben-David et al., 2009), adaptive algorithms (van Erven and Koolen,\n2016) and algorithms for tracking problems (György et al., 2005), in which the resulting number of experts can easily become exponentially large in the parameters of the problem.\nOur goal is to take advantage of such structure in order to achieve lower regret. In particular, we hope to be able to obtain regret bounds that are independent of the number of experts. We do so by constructing a cover of the sequence of loss functions generated by the environment. Namely, we find a small set of experts S such at least one of them has a similar cumulative loss as the best expert in hindsight.\nOur results are motivated by the stochastic case, in which the loss functions are sampled i.i.d. from a fixed distribution. In this case, a vast literature in the field of statistical machine learning shows that the regret is controlled by the covering number of the problem, giving a regret rate ofOpǫT` ? T logNq whereN is the ǫ-covering number (Shalev-Shwartz and Ben-David, 2014). Additionally, this bound is attained by a simple successive ERM algorithm that is oblivious to the structure of the problem (Hazan et al., 2016).\nQuite disappointingly, this is hardly the case in online learning, as even in extremely simple cases it is not possible to achieve logarithmic dependence on the covering number. This is due to the fact that as the game progresses the learner reveals more and more about the structure of the experts. However at any point in the game, this structure may develop in an exponentially large number of ways, depending on the whim of the environment and unbeknownst to the learner. In fact, in this setting any learner cannot do better that ΩpT q regret in the worst case (for example, if the number of experts is exponential in T ), and yet against benign environments we can expect better performance."
    }, {
      "heading" : "1.1 Our contributions",
      "text" : "In this work we study the problem of prediction with expert advice when the number of experts is very large and even possibly infinite. We show an online learning algorithm that can obtain a regret bound of rOpǫT `N pǫ, LT q` a TN pǫ, LT qq for a parameter ǫ, where LT “ pℓ1, ℓ2, . . . , ℓT q is the sequence of loss functions generated by the environment and N pǫ, LT q is the ǫ-covering number of LT under the infinity-norm. The algorithm does so by iteratively constructing a packing of the experts on LT as it is gradually revealed to the learner.\nAdditionally, we regard several applications and extensions of our algorithm. We explain how to find the optimal ǫ automatically without any prior knowledge and discuss a few applications of our algorithm. In particular, we discuss the case of binary losses and an application of our algorithm to the low rank expert model. We also consider the interesting case of experts with bounded variation, in which it is possible to achieve a regret bound independent on the number of experts in the stochastic case. Surprisingly, the case of the online setting is drastically different."
    }, {
      "heading" : "1.2 Related work",
      "text" : "Covering and packing (Rogers, 1964) in compact metric spaces is a common discretization tool used in many fields of statistics. These include machine learning (Vapnik, 1998), empirical processes (Pollard, 1990) and information theory (Roman, 1992). Additionally, papers in a few different topics are related to ours.\nOnline combinatorial optimization. Online combinatorial optimization (Koolen et al., 2010) is a subset of online learning in which the learner’s predictions form different kinds of combinatorial objects. These include the well known online shortest path problem (Takimoto and Warmuth, 2003), permutations (Helmbold and Warmuth, 2009) and many more.\nFor example, in the online shortest path problem, each expert corresponds to a path in a predetermined graph. At each round the environment sets losses to the edges of the graph, and the loss that corresponds to a path is simply the sum of the losses along the edges of the path.\nIn this case, even though the number of experts may be exponential in the number of vertices and edges of the graph, the losses of the experts are well structured. Indeed, if two paths share many of their edges then we can expect their losses to be similar.\nQuantile bounds. Quantile bounds (Chaudhuri et al., 2009; Chernov and Vovk, 2010) are bounds of the form Op a T logp1{ǫqq on the regret against the worst of a 1{ǫ-fraction of the ”leading” experts, in which by leading we mean experts with least cumulative loss. However, these methods cannot guarantee nontrivial regret against every expert without sufficient prior knowledge over the environment.1\nBranching experts. A conceptually similar setting to ours is that of branching experts (Gofer et al., 2013), in which the learner starts from a small number of experts, and where at any point in the game every expert can split into an arbitrary number of experts. This, for example, can be used to model a setting in which K potential experts are in fact only k distinct experts, but these k are not known by the learner in advance. In this case the authors prove that a regret of Θp ? kT q is tight (assuming k ă log2N). Note that this is comparable to\nΘp ? T log kq obtained in the stochastic setting. This setting is different to ours since: first, they assume that the number of experts is finite but may be very large; Secondly, the experts themselves branch whenever their losses differ, whereas our algorithm is oblivious to this information. All our algorithm needs to know is if there is some expert that is not covered by our current packing. However, note that their lower bound of Ωp ? kT q is still applicable in our case.\nLow rank experts. Hazan et al. (2016) consider the case where the losses of the experts reside in some unknown d-dimensional linear subspace. This is a special case of our setting in which the learning algorithm is much simpler and more intuitive. In particular they show a Opd ? T q regret bound in this setting.\nSimulatable experts. In the simulatable experts model (Cesa-Bianchi et al., 1999), the learner knows in advance the advices of all of the experts, as she attempts to learn a binary sequence chosen by the environment. At each round, the learner predicts a binary value at random and suffer a loss according to the absolute loss.\nThis model is one of improper learning, in the sense that the learner predicts a binary bit at each round rather than following the advice of a single expert. This allows the authors to obtain a tight characterization of the regret in terms of the Rademacher complexity of the expert class. As such, their bounds are very different than ours.\nSequential Rademacher complexity. Sequential Rademacher complexity (Rakhlin et al., 2010) is a useful tool for obtaining regret bounds. However, unlike the classic Rademacher Complexity of statistical learning theory, it is often difficult to use. This is added to the fact that the regret bounds obtained using this method are non-algorithmic in nature.\nAdaptive online algorithms. Most of the work previously done in prediction with expert advice revolves around attempting to improve the dependence on T under different assumptions. These include algorithms that can adapt to data that varies slowly (Cesa-Bianchi et al., 2007; Chiang et al., 2012; Hazan and Kale, 2010; Rakhlin and Sridharan, 2013), as well as algorithms that can adapt to stochastic i.i.d. losses (De Rooij et al., 2014; Sani et al., 2014). However, in our work we aim to improve the dependence on K even at the cost of possibly hindering the dependence on T .\n1More specifically, if the experts can be embedded into some function space, one needs to know the embedding\na-priori."
    }, {
      "heading" : "2 Preliminaries and Main Results",
      "text" : "In this section we provide some preliminary information, discussing the Exponential Weights algorithm as well as defining the notions of covering and packing. Thereafter, we give our main results."
    }, {
      "heading" : "2.1 Exponential weights",
      "text" : "Algorithm 1 Exponential Weights\nParameters: Number of experts K. Set: w1piq “ 1 for all i “ 1, 2, . . . ,K. for t = 1,2,. . . do\nDefine distribution pt by ptpiq 9 wtpiq. Predict It „ pt and suffer loss ℓtpItq. Set: ηt “ a 8 logpKq{t.\nUpdate: wt`1piq “ wtpiq expp´ηtℓtpiqq for all i “ 1, 2, . . . ,K. end for\nExponential Weights (Littlestone and Warmuth, 1989; Vovk, 1995; Cesa-Bianchi et al., 1997), also named Hedge and Randomized Weighted Majority, is a celebrated algorithm for prediction with expert advice for a finite number of experts. The variant that we give here, depicted in Algorithm 1, has an adaptive learning rate and therefore the algorithm does not need to know the length of the game T in advance.\nThe algorithm assigns a weight for each expert that is initially set to 1. In each round, the algorithm chooses an expert at random from a distribution that is proportional to the weights of the experts, after which the weight of each expert is decreased according to her loss.\nWe have the following guarantee on the regret of the algorithm.\nLemma 1 (Cesa-Bianchi and Lugosi, 2006, Theorem 2.3). The expected regret of Algorithm 1 satisfies RT ď 4 ? T logK."
    }, {
      "heading" : "2.2 Covering and packing",
      "text" : "A cover of a sequence of loss functions is a small finite subset of experts, such that, intuitively, for any expert we can find an expert in the cover with similar losses.\nDefinition 1 (Cover). An ǫ-cover of a sequence of loss functions LT “ pℓ1, ℓ2, . . . , ℓT q is a subset of experts S that satisfies the following: for every expert i (not necessarily in S) there is an expert j P S such that for all t “ 1, 2, . . . , T we have |ℓtpiq ´ ℓtpjq| ď ǫ. The ǫ-covering number of LT , denoted N pǫ, LT q, is the size of the smallest ǫ-cover of LT .\nAn important implication of the definition is that the covering number is monotonically decreasing in ǫ. The following definition is in some sense the dual of a cover.\nDefinition 2 (Packing). An ǫ-packing of a sequence of loss functions LT “ pℓ1, ℓ2, . . . , ℓT q is a subset of experts S that satisfies the following: for every different experts i, j P S there is a t P rT s such that |ℓtpiq ´ ℓtpjq| ą ǫ. The ǫ-packing number of LT , denoted Ppǫ, LT q, is the size of the largest ǫ-packing of LT .\nThis next lemma is a well known result about duality between covering and packing, however for completeness we shall provide its proof in Appendix A.1.\nLemma 2. For any sequence of loss functions LT we have Pp2ǫ, LT q ď N pǫ, LT q ď Ppǫ, LT q."
    }, {
      "heading" : "2.3 Main results",
      "text" : "We now state the main results of the paper. Our first result shows that there is an algorithm that obtains a regret bound that depends on the empirical covering number of the sequence of loss functions generated by the environment, with no direct dependence on the number of experts.\nTheorem 3. Let 0 ă ǫ ď 1. Suppose that the environment generates a sequence of loss functions LT “ pℓ1, ℓ2, . . . , ℓT q. Algorithm 2 described in Section 3 attains an expected regret of\nRT “ rO ´ ǫT `N pǫ, LT q ` a TN pǫ, LT q ¯\nUnlike Algorithm 1, our algorithm is applicable even when the number of experts is infinite. Nonetheless, note that if the number of experts is, say K, then the bound above becomes meaningful when N pǫ, LT q ă logK. Finally, the bound of Theorem 3 is tight due to a matching lower bound found in Gofer et al. (2013, Lemma 10).\nOur next result handles the case where the optimal accuracy ǫ is not known in advance. Luckily, there is a simple procedure that can guarantee the same regret bound as if the optimal ǫ is known.\nCorollary 4. Suppose that the environment generates a sequence LT “ pℓ1, ℓ2, . . . , ℓT q of loss functions. There exists an online learning algorithm, described in Section 4, whose regret is bounded as follows.\nRT “ inf 0ăǫď1\nrO ´ ǫT `N pǫ, LT q ` a TN pǫ, LT q ¯\nAdditionally, in Section 5 we consider a number of applications of our algorithm. We remark on the case of binary losses, we show an application of our algorithm to the setting of low rank experts, discuss the case of losses from a sparse dictionary and consider the case of experts with bounded variation. For a sequence of loss functions ℓ1, ℓ2, . . . , ℓT , let us define the variation of expert i as\nV piq “ T´1ÿ\nt“1\n|ℓt`1piq ´ ℓtpiq| .\nWe show that when the variation of all experts is at most V , even though in the stochastic i.i.d case it is possible to obtain Op ? V T q regret, this hardly the case in the online setting. In particular, even if V “ Op1q and the losses are binary — the loss of every expert only changes once during the game — the regret still grows with the number of experts in the worst case."
    }, {
      "heading" : "3 Algorithm",
      "text" : "Our algorithm is depicted in Algorithm 2. The algorithm starts with a set S containing one expert, and gradually builds a 2ǫ-packing of experts on the sequence of loss functions generated by the environment. Namely, whenever there is an expert whose loss is more that 2ǫ away from all of the experts in S, the algorithm adds her to S.\nThis produces two guarantees for us. The first, is that when S is not updated, the loss of any expert not in S is at most 2ǫ apart from the loss of one of the experts in S. Second, as our regret bound will depend on the size of S, Lemma 2 entails that by the end of the game, the size of S is at most that of an ǫ-cover of the sequence.\nAdditionally, when S is not updated the algorithm behaves exactly the same as Algorithm 1. Nonetheless whenever S is updated, the algorithm performs a restart: it resets the weights of the experts as well as the learning rate ηt accordingly.\nAlgorithm 2 Exponential Weights for Many Experts\nParameters: Number of rounds T , accuracy ǫ P p0, 1s. Set: τ1 “ 0, r “ 1,K1 “ 1, w1p1q “ 1 and let S contain an arbitrary expert. for t = 1,2,. . . ,T do\nDefine distribution pt by ptpiq 9 wtpiq. Predict It „ pt and suffer loss ℓtpItq. while some expert j has |ℓtpjq ´ ℓtpiq| ą 2ǫ for all i P S do\nAdd j to S. end while if experts were added during this round then Let Kr`1 “ |S| be current number of experts. Set: wt`1piq “ 1 for all i P S (perform a restart), τr`1 Ð t, r Ð r ` 1. else\nSet: ηt “ a\n8 logpKrq{pt´ τrq. Update: wt`1piq “ wtpiq expp´ηtℓtpiqq for all i P S.\nend if\nend for Set: τr`1 “ T ` 1."
    }, {
      "heading" : "3.1 Analysis",
      "text" : "Proof of Theorem 3. First note that Algorithm 2 acts in p phases between restarts. This means that during each phase the algorithm behaves exactly like Algorithm 1 with the Kr “ |S| chosen experts.\nFor any expert i, consider the sequence i1, i2, . . . , ip of experts that cover i in each of the phases, namely within each phase r we have |ℓtpirq´ ℓtpiq| ď 2ǫ. Note that Tr “ τr`1´ τr is the length of the r’th phase, then by Lemma 1 the regret of the algorithm during this phase with respect to ir is:\nRr ď 4 a Tr logKr .\nAdditionally, during the phase the loss of expert i is at most 2ǫ away from that of expert ir, and in-between phases we have a single round in which the instantaneous regret is at most 2. Therefore, the regret of Algorithm 2 with respect to i is bounded as follows:\nE\n« Tÿ\nt“1\nℓtpItq ´ ℓtpiq ff “ E » —– pÿ\nr“1\nτr`1´1ÿ\nt“τr`1\nℓtpItq ´ ℓtpiq ` pÿ\nr“2 ℓτrpItq ´ ℓτrpiqlooooooomooooooon ď2\nfi ffifl\nď pÿ\nr“1\nE\n« τr`1´1ÿ\nt“τr`1\nℓtpItq ´ ℓtpiq ff ` 2p , (1)\nand for each r we have\nE\n« τr`1´1ÿ\nt“τr`1\nℓtpItq ´ ℓtpiq ff “ E « τr`1´1ÿ\nt“τr`1\nℓtpItq ´ ℓtpirq ff\nlooooooooooooooomooooooooooooooon “Rr\n` τr`1´1ÿ\nt“τr`1 ℓtpirq ´ ℓtpiqloooooomoooooon ď2ǫ\nď Rr ` 2ǫpτr`1 ´ τrq .\nSumming over all r “ 1, 2, . . . , p we get pÿ\nr“1\nRr ` ǫpτr`1 ´ τrq ď pÿ\nr“1\n2 a Tr logKr ` 2ǫpτp`1 ´ τ1q\nď 4\ngffe pÿ\nr“1\nTr\ngffe pÿ\nr“1\nlogKr ` 2ǫT\nď 8 a TKp logKp ` 2ǫT , (2)\nwhere the second inequality is by the Cauchy-Schwartz inequality and since K1,K2, . . . ,Kp is an increasing sequence. The third inequality is since řp r“1 Tr ď T and since řp r“1 logKr ď 2Kp logKp by Lemma 10 (technical). Finally, we notice that the Kp experts in S at end of the game form a 2ǫ-packing of the sequence ℓ1, ℓ2, . . . , ℓT . Indeed, let i, j P S be two experts, suppose that i is added to S before j, and let t be the round in which j is added to S. Then by the definition of the algorithm, we must have |ℓtpiq ´ ℓtpjq| ą 2ǫ. Thus by Lemma 2 we have Kp ď N . In addition, whenever the algorithm performs a restart it adds at least one expert to S, and therefore we have p ď Kp. Combining these facts with Eq. (1) and with Eq. (2) gives the desired result."
    }, {
      "heading" : "4 Tuning ǫ Automatically",
      "text" : "In this section we prove Corollary 4. Suppose that we do not know what the optimal ǫ is in advance. Looking at the regret bound of Theorem 3, we have a tradeoff — choosing a smaller ǫ may decrease the ǫT term but may increase the covering number N pǫ, LT q. We would like to tune ǫ to be the best possible in hindsight.\nIn this case we can run R “ rlog2 T s copies of our algorithm with exponentially decreasing accuracy parameters; for each algorithm r “ 1, 2, . . . , R we set ǫr “ 2´r`1. By treating these R algorithms themselves as experts, we can run a copy of Algorithm 1, such that whenever it chooses an algorithm r, we play the action chosen by algorithm r on this round. For this procedure we have the following analysis.\nProof of Corollary 4. Let Lr be the cumulative loss of algorithm r, let L be the cumulative loss of our procedure and L‹ be the cumulative loss of the best expert in hindsight. Then by Lemma 1 and Theorem 3 the regret of this procedure is bounded as follows.\nE rL´ L‹s “ E „ˆ\nL´ min rPrRs Lr\n˙ ` ˆ min rPrRs Lr ´ L‹ ˙\nď E „ L´ min\nrPrRs Lr\n ` min\nrPrRs E rLr ´ L‹s\nď 4 a\nT log log T ` min rPrRs ! 4 ¨ 2´rT ` 2N p2´r`1, LT q ` 8 a TN p2´r`1, LT q logN p2´r`1, LT q ) ,\nwhere the first inequality is due to Jensen’s inequality. To complete the proof, we will show that\nmin rPrRs\n! 4 ¨ 2´rT ` 2N p2´r`1, LT q ` 8 a TN p2´r`1, LT q logN p2´r`1, LT q )\nď inf 0ăǫď1\n! 4ǫT ` 2N pǫ, LT q ` 8 a TN pǫ, LT q logN pǫ, LT q ) ` 2 .\nIndeed, consider any ǫ P p0, 1s. If ǫ ą 2´R`1, then let r‹ be maximal such that 2´r‹`1 ě ǫ. In particular we have 2´r ‹ ă ǫ. We get\nmin rPrRs\n! 4 ¨ 2´rT ` 2N p2´r`1, LT q ` 8 a TN p2´r`1, LT q logN p2´r`1, LT q ) ď 4 ¨ 2´r‹T ` 2N p2´r‹`1, LT q ` 8 a\nTN p2´r‹`1, LT q logN p2´r‹`1, LT q ď 4ǫT ` 2N pǫ, LT q ` 8 a TN pǫ, LT q logN pǫ, LT q ,\nwhere we have used the fact that the covering number is monotonically decreasing in ǫ. On the other hand, if ǫ ď 2´R`1 then\nmin rPrRs\n! 4 ¨ 2´rT ` 2N p2´r`1, LT q ` 8 a TN p2´r`1, LT q logN p2´r`1, LT q ) ď 4 ¨ 2´RT ` 2N p2´R`1, LT q ` 8 b\nTN p2´R`1, LT q logN p2´R`1, LT q ď 2` 2N pǫ, LT q ` 8 a TN pǫ, LT q logN pǫ, LT q ,\nthus reaching the desired conclusion."
    }, {
      "heading" : "5 Applications",
      "text" : "In this section we discuss a number of applications of Algorithm 2. First, we discuss the case of binary losses in which we can attain a regret bound that depends on the number of experts with distinct sequences of losses. We then discuss an application of our algorithm to the low rank experts model and a generalization of it in the form of experts whose losses are acquired from a sparse dictionary. Finally, we approach the interesting case of experts with bounded variation, in which we show a large gap between the regret of the stochastic and the online settings."
    }, {
      "heading" : "5.1 Binary losses",
      "text" : "Consider a setting in which the losses of the experts are binary, namely -1 or 1. In this case, we can obtain a regret bound that depends on the number experts with distinct sequences of losses, without paying for an additional term that depends linearly on T . The following is a direct consequence of Theorem 3.\nCorollary 5. Let N “ N p0, LT q be the 0-covering number of sequence LT “ pℓ1, ℓ2, . . . , ℓT q of binary loss functions generated by the environment. Then the regret of the Algorithm 2 satisfies\nRT ď N ` 8 a TN logN ."
    }, {
      "heading" : "5.2 Low rank experts",
      "text" : "Suppose that the number of experts K is finite but very large. Let L P r´1, 1sTˆK be the losses arranged in a matrix obtained in hindsight, and consider the model of Hazan et al. (2016) in which the environment plays a strategy in which the ǫ-approximate rank of L is d. The approximate rank of a matrix L is defined as follows:\nǫ-rankpLq “ min rankpL1q : }L1 ´ L}8 ď ǫ ( ,\nnamely it is the lowest rank of any matrix that ǫ-approximates L entry-wise. Under this setting, Hazan et al. (2016) give an online learning algorithm that gives Opd ? T q regret if L is of (0-)rank d. For the case of ǫ-approximate rank, the authors give a regret bound of Op ? dT ` ǫ ? T logKq for the stochastic case, and leave the problem of obtaining a similar bound in the online case as an open issue. In this section, we show an application of our algorithm to this latter setting, described by the following corollary.\nCorollary 6. Let 0 ă ǫ ď 1{4. Suppose that T ď K and ǫ-rankpLq ď d, then Algorithm 2 applied to this setting with accuracy 4ǫ gives a regret bound of\nRT “ rO ˆ ǫT ` pc{ǫqd ` b pc{ǫqdT ˙ ,\nfor an absolute constant c.\nNote that the bound above is only meaningful if it happens that ωpT´1{dq ď ǫ ď op1q. The bound hints on an exponential decay in the dependence on the approximate rank d between the stochastic and online cases. Whether this gap can be removed using nontrivial algorithmic techniques remains an open issue and an interesting direction for future research.\nLet us turn to prove Corollary 6, but in order to do so we shall need the following theorem.\nTheorem 7 (Alon et al., 2013, Theorem 3.2). Let A be an KˆK matrix with entries in r´1, 1s and ǫ-rankpAq “ d. Let ∆ be the pK ´ 1q-dimensional probability simplex. There is a finite set S Ď RK such that @x P ∆, Dx̃ P S : }Ax´Ax̃}8 ď 2ǫ , and |S| “ Op1{ǫqd.\nWe shall now continue with the proof of the corollary.\nProof of Corollary 6. Consider an application of Algorithm 2 with accuracy 4ǫ in our problem, for which by Theorem 3 it suffices to bound the covering number N p4ǫ, LT q.\nConsider padding the loss matrix L P r´1, 1sTˆK with K ´ T rows of zero entries, in order to obtain a K ˆK matrix whose ǫ-rank remains d. Since we can represent each expert i by a standard basis vector ei P RK , the vector Lei represents the losses of expert i. Thus, we can apply Theorem 7 to L and acquire a set S Ď RK of size Op1{ǫqd with the following property:\n@i P rKs, Dx̃ P S : }Lei ´ Lx̃}8 ď 2ǫ .\nLet R be a maximal 4ǫ-packing of LT . By Lemma 2 we have N pLT , 4ǫq ď |R| so that it suffices to show a one-to-one mapping π : R ÞÑ S, that would imply |R| ď |S|. Indeed, define π as follows: for each i P R let πpiq “ argminx̃PS }Lei ´ Lx̃}8 breaking ties arbitrarily. To show that it is one-to-one, let i, j P R such that πpiq “ πpjq, then\n}Lei ´ Lej}8 ď }Lei ´ Lπpiq}8 ` }Lπpjq ´ Lej}8 ď 2ǫ` 2ǫ “ 4ǫ .\nSince R is a 4ǫ-packing it must be the case that i “ j, as required."
    }, {
      "heading" : "5.3 Losses from a sparse dictionary",
      "text" : "Sparse dictionary learning (Elad and Aharon, 2006), also known as sparse coding, is a widely used tool in machine learning, neuroscience and signal processing. Given an unlabeled dataset, this method approximates each data point by a linear combination of a small number of vectors from a set, called a dictionary. This modeling is motivated by the empirical success (Aharon et al., 2006; Lee et al., 2007), as well as evidence that, for example, the neurons of the V1 optical cortex use similar representations (Olshausen and Field, 1997). In the following we assume that the environment plays a strategy in which the losses of the experts can be approximated by such a sparse representation.\nFormally, let the environment play a strategy that satisfies the following. Suppose that the loss matrix L P r´1, 1sTˆK can be approximated by a decomposition D ¨ V , namely that it satisfies }L´D ¨ V }8 ď ǫ. Here D, the dictionary, is a T ˆ n matrix whose rows have 1-norm of at most 1. The matrix V is an nˆK matrix in which each column i, associated with expert\ni, is a k-sparse2 vector vi such that }vi}8 ď 1. Note that both matrices D and V are unknown to the learner and chosen by the environment in an adversarial manner.\nThis assumption entails that there is an approximate sparse representation for the losses of each expert. Indeed, the vector of losses of expert i is ǫ-approximated by Dvi, and since vi is k-sparse, Dvi is a linear combination of at most k of the columns of D. The dictionary D can be over-complete, which means that n ě T and that its columns are not necessarily orthogonal. This allows the vectors Dvi to lie in different, yet possibly overlapping, k-dimensional subspaces of RT . As such this setting is a generalization of the low rank experts model of the previous section.\nIn this setting we have the following guarantee for our algorithm.\nCorollary 8. Suppose that 0 ă ǫ ď 1{4. Algorithm 2 applied to the setting above with accuracy 4ǫ gives a regret bound of\nRT “ rO ˆ ǫT ` p2n{ǫqk ` b p2n{ǫqkT ˙ .\nIn particular, note that the bound is meaningful when ωpnT´1{kq ď ǫ ď op1q.\nProof of Corollary 8. Once again, in view of Theorem 3 it suffices to bound the covering number N p4ǫ, LT q. As in the proof of Corollary 6, associate with each expert i the standard basis vector ei P RK and recall that Lei P r´1, 1sT is the vector of losses associated with expert i. Let i, j be any two experts, then we have\n}Lei ´ Lej}8 ď }Lei ´Dvi}8looooooomooooooon ďǫ `}Dvi ´Dvj}8looooooomooooooon ď}vi´vj}8 `}Dvj ´ Lej}8looooooomooooooon ďǫ\nď }vi ´ vj}8 ` 2ǫ ,\nwhere the last inequality is by our assumption that the rows of D have 1-norm of at most 1. Therefore, it suffices to 2ǫ-cover S, the set of all k-sparse vectors v that satisfy }v}8 ď 1 .\nThe set S is a union of ` n k ˘ k-dimensional cubes of the form r´1, 1sk . By a well known result on covering numbers, each such cube can be covered by at most p1 ` 1{ǫqk ď p2{ǫqk cubes of the form r´2ǫ, 2ǫsk. This entails that N pǫ, LT q ď ` n k ˘ p2{ǫqk ď p2n{ǫqk, and plugging the latter into the bound Theorem 3 gives the desired result."
    }, {
      "heading" : "5.4 Experts with bounded variation",
      "text" : "For this section, let us assume that the variation of all of the experts is bounded by V . Well known results about the covering numbers of functions of bounded variation (Bartlett et al., 1994) show that in the stochastic i.i.d case, it is possible to learn such functions while suffering only rOp ? V T q regret. However, the situation is drastically different in the online case.\nFor motivation consider the case of binary losses, then V {2 is a bound on the number of times the loss of an expert changes from -1 to 1 or vice versa, during the T rounds of the game. Therefore, the number of experts with distinct losses is 2 řV {2\ni“0 ` T´1 i ˘ “ OpT V {2q. This entails\nthat by Corollary 5, we have the a guarantee of rOpT V {2q on the regret of Algorithm 2, which is trivial even for V “ 2! This leaves us with the following problem: does there exists an algorithm for online learning that attains rOp ? V T q regret when the variation of all experts is bounded by V ? We answer this question negatively. First note that the interesting regime is when T ă logK, otherwise we can obtain a tight Θp ? V logKq bound of Hazan and Kale (2010). However, if T ă logK, even if V “ Op1q we cannot expect the desired regret bound, as shown in the following result.\n2A k-sparse vector is one that has at most k nonzero entries.\nTheorem 9. Suppose T ă log2K and that V piq ď 2 for every expert i. Then there is a randomized environment that forces any learner to obtain a regret of at least T in expectation.\nProof. Our construction is as following. We start from setting the loss of all experts to -1. At each round, we pick a subset of experts whose loss was -1 so far, set it to 1 and it will stay 1 for the remainder of the game. This will make sure that the variation of all experts is indeed at most 2.\nOn the first round we pick half of the experts uniformly at random and set their loss to 1. Therefore, on the first round, the loss of any learner is exactly 0 in expectation. In the second round, we pick half of the experts whose loss was -1 in the first round and set their loss to 1. Once again, any learner must suffer a loss of at least 0 in expectation on the second round. We keep doing so for the T rounds of the game.\nThus, the expected regret of the learner is at least T since her expected loss is at least 0, but there is at least one expert with a cumulative loss of ´T ."
    }, {
      "heading" : "6 Discussion and Open Problems",
      "text" : "In this work we have shown an algorithm that obtains a regret bound that is independent of the number of experts. This dependence is replaced by a certain covering number that governs the complexity of the observed sequence of loss functions. We have also shown how to automatically tune the accuracy parameter of our algorithm. Finally, we have presented a number of applications of our algorithm, that include binary losses, low rank experts and experts with bounded variation.\nUnfortunately for many important applications, the covering number used by our algorithm can typically be very large. Given that ideally we would like to choose ǫ “ op1q, it is an interesting direction for future work to try and to find a simple way to quantify which classes of environments produce small covering numbers for such values of ǫ. In addition, comparing our result to that of Hazan et al. (2016) in their setting, our bound is exponentially worse in the dimension of the loss matrix. It remains an open problem to find an algorithm that has a tight regret bound in both cases.\nAnother interesting direction to explore is the connection between our setting and online compression. Indeed, by setting the losses into a matrix L P r´1, 1sTˆK our problem is equivalent to approximating this matrix with a small number of columns in an online fashion. Therefore any guarantee provided by an online compression algorithm that solves this problem, implies an improvement in guarantee over the regret."
    }, {
      "heading" : "A Additional Proofs",
      "text" : "A.1 Proof of Lemma 2\nProof of Lemma 2. For the lower bound let S be a 2ǫ-packing of ℓ and V be an ǫ-cover of ℓ. Define the following distance function between experts:\ndpi, jq “ max tPrT s |ℓtpiq ´ ℓtpjq| .\nNow, we define a mapping π : S ÞÑ V by πpiq “ argminjPV dpi, jq (breaking ties arbitrarily), namely for every expert i P S we take πpiq to be the expert in V that is closest to i according to d.\nNote that it suffices for us to show that π is one-to-one as this will show that |S| ď |V |. Indeed, suppose i, j P S are such that πpiq “ πpjq and i ‰ j. In particular we have |ℓtpiq ´ ℓtpπpiqq| ď ǫ and |ℓtpjq ´ ℓtpπpjqq| ď ǫ for all t P rT s, and therefore\n|ℓtpiq ´ ℓtpjq| ď |ℓtpiq ´ ℓtpπpiqq| ` |ℓtpπpjqq ´ ℓtpjq| ď 2ǫ .\nHowever, there exists t P rT s such that |ℓtpiq ´ ℓtpjq| ą 2ǫ, thus reaching contradiction. We now turn to prove the upper bound. Let S be a maximal ǫ-packing, which we will show is also an ǫ-cover. Suppose otherwise, then there is an expert i such that for every j P S we have dpi, jq ą ǫ. In particular i R S.\nConsider the set S1 “ S Y tiu obtained by adding i to S. This set is also an ǫ-packing therefore reaching a contradiction.\nA.2 Technical Lemma\nLemma 10. Let 1 “ a1 ă a2 ă . . . ă an be a sequence of n natural numbers. Then, nÿ\ni“1\nlog ai ď 2an log an .\nProof. Consider the convex function fpxq “ x logpxq ´ x. Then for any i “ 1, 2, . . . , n ´ 1 we have fpai`1q ´ fpaiq ě f 1paiqpai`1 ´ aiq “ logpaiqpai`1 ´ aiq ě log ai . Summing,\nn´1ÿ\ni“1\nlog ai ď n´1ÿ\ni“1\nfpai`1q ´ fpaiq “ fpanq ´ fpa1q\n“ pan logpanq ´ anq ´ pa1 log a1 ´ a1q ď an log an ,\nand thus nÿ\ni“1\nlog ai ď an log an ` log an ď 2an log an ."
    } ],
    "references" : [ {
      "title" : "rmk-svd: An algorithm for designing overcomplete dictionaries for sparse representation",
      "author" : [ "M. Aharon", "M. Elad", "A. Bruckstein" ],
      "venue" : "IEEE Transactions on signal processing,",
      "citeRegEx" : "Aharon et al\\.,? \\Q2006\\E",
      "shortCiteRegEx" : "Aharon et al\\.",
      "year" : 2006
    }, {
      "title" : "The approximate rank of a matrix and its algorithmic applications: approximate rank",
      "author" : [ "N. Alon", "T. Lee", "A. Shraibman", "S. Vempala" ],
      "venue" : "In Proceedings of the forty-fifth annual ACM symposium on Theory of computing,",
      "citeRegEx" : "Alon et al\\.,? \\Q2013\\E",
      "shortCiteRegEx" : "Alon et al\\.",
      "year" : 2013
    }, {
      "title" : "Fat-shattering and the learnability of realvalued functions",
      "author" : [ "P.L. Bartlett", "P.M. Long", "R.C. Williamson" ],
      "venue" : "In Proceedings of the seventh annual conference on Computational learning theory,",
      "citeRegEx" : "Bartlett et al\\.,? \\Q1994\\E",
      "shortCiteRegEx" : "Bartlett et al\\.",
      "year" : 1994
    }, {
      "title" : "Agnostic online learning",
      "author" : [ "S. Ben-David", "D. Pál", "S. Shalev-Shwartz" ],
      "venue" : "In COLT,",
      "citeRegEx" : "Ben.David et al\\.,? \\Q2009\\E",
      "shortCiteRegEx" : "Ben.David et al\\.",
      "year" : 2009
    }, {
      "title" : "How to use expert advice",
      "author" : [ "N. Cesa-Bianchi", "G. Lugosi" ],
      "venue" : "Journal of the ACM (JACM),",
      "citeRegEx" : "Cesa.Bianchi and Lugosi,? \\Q1997\\E",
      "shortCiteRegEx" : "Cesa.Bianchi and Lugosi",
      "year" : 1997
    }, {
      "title" : "Prediction with advice of unknown number of experts",
      "author" : [ "A. Chernov", "V. Vovk" ],
      "venue" : null,
      "citeRegEx" : "Chernov and Vovk.,? \\Q2009\\E",
      "shortCiteRegEx" : "Chernov and Vovk.",
      "year" : 2009
    }, {
      "title" : "Sparse coding with an overcomplete basis set: A strategy",
      "author" : [ "B.A. Olshausen", "D.J. Field" ],
      "venue" : "Computer Science,",
      "citeRegEx" : "Olshausen and Field.,? \\Q1989\\E",
      "shortCiteRegEx" : "Olshausen and Field.",
      "year" : 1989
    }, {
      "title" : "Statistical learning theory, volume 1",
      "author" : [ "V.N. Vapnik" ],
      "venue" : "Advances in Neural Information Processing Systems,",
      "citeRegEx" : "Vapnik.,? \\Q1998\\E",
      "shortCiteRegEx" : "Vapnik.",
      "year" : 1998
    } ],
    "referenceMentions" : [ {
      "referenceID" : 3,
      "context" : "This can occur, for example, in online supervised learning (Ben-David et al., 2009), adaptive algorithms (van Erven and Koolen,",
      "startOffset" : 59,
      "endOffset" : 83
    }, {
      "referenceID" : 7,
      "context" : "These include machine learning (Vapnik, 1998), empirical processes (Pollard, 1990) and information theory (Roman, 1992).",
      "startOffset" : 31,
      "endOffset" : 45
    }, {
      "referenceID" : 0,
      "context" : "This modeling is motivated by the empirical success (Aharon et al., 2006; Lee et al., 2007), as well as evidence that, for example, the neurons of the V1 optical cortex use similar representations (Olshausen and Field, 1997).",
      "startOffset" : 52,
      "endOffset" : 91
    }, {
      "referenceID" : 2,
      "context" : "Well known results about the covering numbers of functions of bounded variation (Bartlett et al., 1994) show that in the stochastic i.",
      "startOffset" : 80,
      "endOffset" : 103
    }, {
      "referenceID" : 2,
      "context" : "Well known results about the covering numbers of functions of bounded variation (Bartlett et al., 1994) show that in the stochastic i.i.d case, it is possible to learn such functions while suffering only r Op ? V T q regret. However, the situation is drastically different in the online case. For motivation consider the case of binary losses, then V {2 is a bound on the number of times the loss of an expert changes from -1 to 1 or vice versa, during the T rounds of the game. Therefore, the number of experts with distinct losses is 2 řV {2 i“0 ` T ́1 i ̆ “ OpT V {2q. This entails that by Corollary 5, we have the a guarantee of r OpT V {2q on the regret of Algorithm 2, which is trivial even for V “ 2! This leaves us with the following problem: does there exists an algorithm for online learning that attains r Op ? V T q regret when the variation of all experts is bounded by V ? We answer this question negatively. First note that the interesting regime is when T ă logK, otherwise we can obtain a tight Θp ? V logKq bound of Hazan and Kale (2010). However, if T ă logK, even if V “ Op1q we cannot expect the desired regret bound, as shown in the following result.",
      "startOffset" : 81,
      "endOffset" : 1056
    } ],
    "year" : 2017,
    "abstractText" : "We study the problem of prediction with expert advice when the number of experts in question may be extremely large or even infinite. We devise an algorithm that obtains a tight regret bound of r OpǫT `N ` ? NT q, where N is the empirical ǫ-covering number of the sequence of loss functions generated by the environment. In addition, we present a hedging procedure that allows us to find the optimal ǫ in hindsight. Finally, we discuss a few interesting applications of our algorithm. We show how our algorithm is applicable in the approximately low rank experts model of Hazan et al., 2016, and discuss the case of experts with bounded variation, in which there is a surprisingly large gap between the regret bounds obtained in the statistical and online settings.",
    "creator" : "LaTeX with hyperref package"
  }
}