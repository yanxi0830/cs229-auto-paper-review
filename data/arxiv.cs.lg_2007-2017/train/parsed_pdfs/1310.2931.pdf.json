{
  "name" : "1310.2931.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "Feedback Detection for Live Statistical Predictors",
    "authors" : [ "Stefan Wager", "Nick Chamandy", "Omkar Muralidharan", "Amir Najmi" ],
    "emails" : [ "amir}@google.com" ],
    "sections" : [ {
      "heading" : "1 Introduction",
      "text" : "When statistical predictors are deployed in a live production environment, feedback loops can become a concern. Predictive models are usually tuned using training data that has not been influenced by the predictor itself; thus, most real-world statistical predictors cannot account for the effect they themselves have on their environment. Consider the following caricatured example: A search engine wants to train a simple classifier that predicts whether a search result is good or bad. This classifier is trained on historical data, and learns that high click-through rate (CTR) has a positive association with goodness. Problems may arise if the search engine deploys the classifier, and starts featuring search results that are predicted to be good: promoting the search result may lead to a higher CTR, which in turn leads to higher goodness predictions, which then causes the result to be featured even more.\nIf we knew beforehand all the channels through which statistical feedback can occur, then detecting feedback would not be too difficult. For example, in the context of the above example, if we knew that feedback could only occur through some changes to the search result page that were directly triggered by our model, then we could estimate feedback by running some small experiments where we turn off these triggering rules. However, in large industrial systems where networks of classifiers all feed into each other, we can no longer hope to understand a-priori all the ways in which feedback may occur. We need a method that lets us detect feedback from sources we might not have even known to exist.\nThis paper proposes a fully automatic method for detecting statistical feedback loops that does not require modeling the feedback mechanism. Our method relies on artificially inserting a small amount of noise into the predictions made by a model, and then measuring the effect of this noise on future predictions made by the model. If future model predictions\nar X\niv :1\n31 0.\n29 31\nv1 [\nst at\n.M E\n] 1\n0 O\nincrease when we add artificial noise to the current ones, then our system has a feedback problem.\nTo understand how random noise can enable us to detect feedback, suppose that we have a model with predictions ŷ in which tomorrow’s prediction ŷ(t+1) has a linear feedback dependence on today’s prediction ŷ(t): if we increase ŷ(t) by δ, then ŷ(t+1) increases by β δ for some β ∈ R. Intuitively, we should be able to fit this slope β by perturbing ŷ(t) with a small amount of noise ν ∼ N ( 0, σ2ν ) and then regressing the new ŷ(t+1) against the noise; the reason least squares should work here is that the noise ν is independent of all other variables by construction. The main contribution of this paper will be to turn this simple estimation idea into a general procedure that can be used to detect feedback in realistic problems.\nIn order to define a rigorous procedure we need to have a precise notion of what we mean by feedback. We begin in Section 2 by defining statistical feedback in terms of a potential outcomes model. Once we have a firm handle on what we mean by feedback, the mathematical problem of feedback detection falls into the scope of classical statistics. As we verify in Section 4, the simplest case where feedback is a linear function of past predictions in fact reduces to linear regression; in Section 5 we generalize our approach to non-linear feedback functions. In Sections 2.1 and 3 we show how to use our ideas in practice, and use our method to estimate the magnitude of feedback in a predictive model currently in use at an internet company."
    }, {
      "heading" : "1.1 Counterfactuals and Causal Inference",
      "text" : "Feedback detection is a problem in causal inference. A model suffers from feedback if the predictions it makes today affect the predictions it will make tomorrow. We are thus interested in discovering a causal relationship between today’s and tomorrow’s predictions; simply detecting a correlation is not enough. The distinction between causal and associational inference is acute in the case of feedback: today’s and tomorrow’s predictions are almost always strongly correlated with each other, but this correlation by no means implies any causal relationship.\nIn order to discover causal relationships between consecutive predictions, we need to use some form of randomized experimentation. In our case, we add a small amount of random noise to our predictions. Because the noise fully artificial, we can reasonably ask counterfactual questions of the type: “How would tomorrow’s predictions have changed if we added more/less noise to the predictions today?” The noise acts as an independent instrument that lets us detect feedback.\nWe frame our analysis in terms of a potential outcomes model that asks how the world would have changed had we altered a treatment; in our case, the treatment is the random noise we add to our predictions. This formalism, often called the Rubin causal model [Holland, 1986], is regularly used for understanding causal inference [Angrist et al., 1996, Efron and Feldman, 1991, Imbens and Angrist, 1994]."
    }, {
      "heading" : "1.2 Related Work",
      "text" : "The interaction between models and the systems they attempt to describe has been extensively studied across many fields. Models can have different kinds of feedback effects on their environments. At one extreme of the spectrum, models can become self-fulfilling prophecies: for example, models that predict economic growth may in fact cause economic growth by\ninstilling market confidence [Merton, 1948, Ferraro et al., 2005]. At the other end, models may distort the phenomena they seek to describe and therefore become invalid. A classical example of this is a concern that any metric used to regulate financial risk may become invalid as soon as it is widely used, because actors in the financial market may attempt to game the metric to avoid regulation [Danıelsson, 2002].\nMuch of the work on model feedback in fields like finance, education, or macro-economic theory has focused on negative results: there is an emphasis on understanding when feedback can happen and promoting awareness about how feedback can interact with policy decisions, but there does not appear to be much focus on actually fitting feedback. This emphasis on negative results is understandable as causal inference is difficult, especially at the scale of whole societies.\nThe problem we address in this paper lets us get stronger results. In our setup, we are able to closely control the interaction between our model and the outside world, and conduct randomized experiments by perturbing our model. This enables us to get positive results, and to accurately estimate the effect of feedback. We are not aware of much prior work in terms of quantitative feedback detection. Akaike [1968] showed how to fit cross-component feedback in a system with many components; however, he did not add artificial noise to the system, and so was unable to detect feedback of a single component on itself."
    }, {
      "heading" : "2 Feedback Detection for Statistical Predictors",
      "text" : "Suppose that we have a model that makes predictions ŷ (t) i in time periods t = 1, 2, ... for examples i = 1, ..., n. The predictive model itself is taken as given; our goal is to understand feedback effects between consecutive pairs of predictions ŷ (t) i and ŷ (t+1) i .\nFeedback and potential outcomes Statistical feedback is defined in terms of counterfactual reasoning: we want to know what would have happened to ŷ (t+1) i had ŷ (t) i been different. We use potential outcomes notation [e.g., Rubin, 2005] to distinguish between counterfactuals: let ŷ (t+1) i [yi] be the predictions our model would have made at time t + 1 if we had published yi as our time-t prediction. In practice we only get to observe ŷ (t+1) i [yi] for a single yi; all other values of ŷ (t+1) i [yi] are counterfactual.\nWe also consider ŷ (t+1) i [∅], the prediction our model would have made at time t + 1 if the model never many any of its predictions public and so had not had the chance to affect its environment. With this notation, we define feedback as\nfeedback (t) i = ŷ (t+1) i [ŷ (t) i ]− ŷ (t+1) i [∅], (1)\ni.e., the difference between the predictions our model actually made and the predictions it would have made had it not had the chance to affect its environment by broadcasting predictions in the past. Thus, statistical feedback is a difference in potential outcomes.\nAn additive feedback model In order to get a handle on feedback as defined above, we assume that feedback enters the model additively:\nŷ (t+1) i [yi] = ŷ (t+1) i [∅] + f (yi) , (2)\nwhere f is a feedback function, and yi is the prediction published at time t. In other words, we assume that the predictions made by our model at time t+ 1 are the sum of the\nprediction the model would have made if there were no feedback, plus a feedback term that only depends on the previous prediction made by the model. Our goal is to fit the feedback function f .\nArtificial noising for feedback detection The relationship between ŷ (t) i and ŷ (t+1) i can be influenced by many things, such as trends, mean reversion, random fluctuations, as well as feedback. In order to isolate the effect of feedback, we need add some noise to the system to create a situation that resembles a randomized experiment.\nIdeally, we might hope to sometimes turn our predictive system off in order to get estimates of ŷ (t) i [∅]. However, old predictive models are often deeply integrated into large software systems, and it may not be clear what the correct system behavior would be if we turned the predictor off. To side step this concern, we randomize our system by adding artificial noise to predictions: at time t, instead of deploying the prediction ŷ (t) i , we deploy\ny̌ (t) i = ŷ (t) i + ν (t) i , where ν (t) i iid∼ N (3)\nis artificial noise drawn from some distribution N . Because the noise ν (t) i is fully independent from everything else, it puts us in a randomized experimental setup that allows us to detect feedback as a causal effect. If the time t + 1 prediction ŷ (t+1) i is affected by ν (t) i , then our system must have feedback because the only way ν (t) i can influence ŷ (t+1) i is through the interaction between our model predictions and the surrounding environment at time t.\nLocal average treatment effect In practice, we want the noise ν (t) i to be small enough that it does not disturb the regular operation of the predictive model too much. Thus, our experimental setup allows us to measure feedback as a local average treatment effect [Imbens and Angrist, 1994], where the artificial noise ν (t) i acts as a continuous treatment. Provided our additive model (2) holds, we can then piece together these local treatment effects into a single global feedback function f ."
    }, {
      "heading" : "2.1 Methodology",
      "text" : "If we are able to insert artificial noise into our predictions as in (3) and willing to make the additive assumption (2), then we can fit general non-linear feedback functions f by performing two carefully designed spline regressions. We postpone a more thorough theoretical analysis of our methods until Sections 4 and 5; this section shows how to fit feedback in practice.\n1. At time t, compute model predictions ŷ (t) i and draw noise terms ν (t) i iid∼ N for some noise distribution N . Deploy predictions y̌\n(t) i = ŷ (t) i + ν (t) i in the live system.\n2. Fit a non-parametric least-squares regression of ŷ (t+1) i [ŷ (t) i +ν (t) i ] ∼ µ\n( ŷ\n(t) i\n) to learn the\nfunction µ (y) := E [ ŷ\n(t+1) i [ŷ (t) i +ν (t) i ] ∣∣∣ ŷ(t)i = y] . (4) We use the R formula notation, where a ∼ g(b) means that we want to learn a function g(b) that predicts a.\n3. Set up the non-parametric least-squares regression problem\nŷ (t+1) i [ŷ (t) i +ν (t) i ]− µ\n( ŷ\n(t) i\n) ∼ f ( ŷ\n(t) i + ν (t) i ) − ϕN ∗ f ( ŷ (t) i ) , (5)\nwhere the goal is to learn f . Here, ϕN is the density of ν (t) i , and ∗ denotes convolution.\nThe resulting function f(y) is our estimate of feedback: If we make a prediction y̌ (t) i at time t, then our time t+ 1 prediction will be boosted by f(y̌ (t) i ). The above equation only depends on ŷ (t) i , ν (t) i , and ŷ (t+1) i [ŷ (t) i +ν (t) i ], which are all quantities that can be observed in the context of an experiment with noised predictions. In Appendix A we show how to carry out the steps outlined above in R.\nNon-identifiability of the intercept As we only fit f using the differences in (5), the intercept of f is not identifiable. We fix the intercept (rather arbitrarily) by setting the average fitted feedback over all training examples to 0.\nChoice of noising distribution Adding noise to deployed predictions often has a cost that may depend on the shape of the noise distribution N . A good choice of N should reflect this cost. For example, if the practical cost of adding noise only depends on the largest amount of noise we ever add, then it may be a good idea to draw ν (t) i uniformly at random from {±ε} for some ε > 0. In this paper, however, we always assume for simplicity of exposition that we draw noise from a Gaussian distribution ν\n(t) i ∼ N (0, σ2ν); we write\nϕσν for the corresponding noise density in (5).\nNon-parametric regression A simple way to fit the non-parametric regressions (4) and (5) is to constrain both µ and f to be functions of the form\nµ(y) = βµ · bµ(y) and f(y) = βf · bf (y), (6)\nwhere bµ, bf : R → Rpµ , Rpf are some basis expansions of our choice; the goal is then to learn βµ and βf . With this construction, (4) and (5) become pµ- and pf -dimensional linear regression problems that can be solved using standard software such as lm in R. As shown in Theorem 3, this approach consistently recovers the best possible feedback function of the form (6).\nChoice of basis In order for to get useful estimates of f , we need to choose the basis functions bµ(y) and bf (y) in (6) carefully. In our applications, we focused on classification problems where ŷ is a log-odds estimate\nŷ = log\n[ π̂\n1− π̂ ] for the probability π̂ of some event of interest. For such examples, we built both bµ(y) and bf (y) as natural splines with knots uniformly spread out on ŷ ∈ [−3, 3], as well as a jump at ŷ = 0. The reason for these choices is that we are most interested in fitting feedback near the even-odds decision boundary ŷ = 0. Other applications way require different choices of b."
    }, {
      "heading" : "3 Experiments",
      "text" : "We begin with a collection of simulation experiments, the results of which are presented in Figure 1. These examples are all logistic regression examples with additive feedback in log-odds space. In the plots, the y-axis shows feedback in log-odds space, whereas the x-axis shows deployed predictions in probability space.\nThe simulations all had n = 100, 000 (old prediction, new prediction) pairs; all the predictions had natural noise with standard error σ = 0.5. We added Gaussian noise with σν = 0.25 to the deployed predictions, and fit both the trend µ(·) and the feedback function f(·) as the sum of a natural spline with df = 3 degrees of freedom and knots spread evenly over [−3, 3], and a jump at zero log-odds (i.e., x = 0.5). The dashed lines show the different feedback functions f used in each example.\nIn order to mimic real datasets, we made our simulation highly imbalanced: There were many strong predictions for the negative class, but less so for the positive class. This is why our model performed better near x = 0 than near x = 1.\nAs emphasized earlier, the intercept of the feedback function f is not identifiable from our experiments. We fixed the intercept by setting the average fitted feedback over all training examples to 0. Since all our training sets were heavily imbalanced, this effectively amounted to setting feedback to 0 at x = 0.1\nAs we see from Figure 1, our method accurately fits the feedback function in all six examples, including the null case with no feedback. The error bars depict standard asymptotic error bars produced by the R function lm when fitting (5)."
    }, {
      "heading" : "3.1 Real-World Example",
      "text" : "The original motivation for this research was to develop methodology for detecting feedback in real-world systems. Here, we present results from a pilot study, where we added signal to historical data that we believe should emulate actual feedback.\nThe model in question is a logistic regression classifier. We added feedback to historical\ndata according to to half a dozen rules of the form “if a (t) i is high and y̌ (t) i > 0, then increase a (t+1) i by a random amount”; here y̌ (t) i is the time-t prediction deployed by our system (in log-odds space) and a (t) i is some feature with a positive coefficient. These feedback generation rules do not obey the additive assumption (2). Thus our model is misspecified in the sense that there is no function f such that a current prediction y̌ (t) i increased the log-odds of the next prediction by f(y̌ (t) i ), and so this example can be taken as a stretch case for our method. Our dataset had on the order of 100,000 rows, half of which were used for fitting the model itself and half of which were used for feedback simulation. We generated data for 5 simulated time periods, adding noise with σν = 0.1 at each step, and fit feedback using the same basis as in the above example. The “true feedback” curve was obtained by fitting a spline regression to (2) by looking at the unobservable ŷ (t+1) i [∅]; we used a df = 5 natural spline with knots evenly spread out on [−9, 3] in log-odds space plus a jump at 0. For the real classifier we want to understand, we have fairly strong reasons to believe that if the feedback function has jumps, then there should be a jump at the even odds\n1The plots that do not hit the (0, 0) point are missing a sharp spike at the left-most end; the plot ends at x = logit(−3) ≈ 0.05.\nthreshold. Assuming that we know a-priori where to look for jumps does not seem to be too big a problem for the practical applications we have considered.\nResults are shown in Figure 2. Although the fit is not perfect, we appear to have successfully detected the shape of feedback. The error bars for estimated feedback were obtained using a non-parametric bootstrap [Efron and Tibshirani, 1993] for which we resampled pairs of (current, next) predictions. It appears that in case of model misspecification, the parametric error bars that worked well in the simulation studies from Figure 1 break down and become anti-conservative; this is why we resorted to using a bootstrap here.\nThis simulation suggests that our method can be used to accurately detect feedback on scales that may affect real world systems. Knowing that we can detect feedback is reassuring from an engineering point of view. On a practical level, the feedback curve shown in Figure 2 may not be too big a concern yet : the average feedback is well within the noise level of the classifier. But in large-scale systems the ways in which a model interacts with its environment is always changing, and it is entirely plausible that some innocuous-looking change in the future would increase the amount of feedback. Our methodology provides us with a way to continuously monitor how feedback is affected by changes to the system, and can alert us to changes that cause problems."
    }, {
      "heading" : "4 Linear Feedback",
      "text" : "We now turn to a theoretical analysis of the methods presented in Section 2. We begin with an analysis of linear feedback problems; the linear setup allows us to convey the main insights with less technical overhead. We discuss the non-linear case in Section 5.\nSuppose that we have some natural process x(1), x(2), ... and a predictive model of the form ŷ = w · x. (Suppose for notational convenience that x includes the constant, and the intercept term is folded into w.) For our purposes, w is fixed and known; for example, w may have been set by training on historical data. At some point, we ship a system that starts broadcasting the predictions ŷ = w · x, and there is a concern that the act of broadcasting the ŷ may perturb the underlying x(t) process. Our goal is to detect any such feedback. Following earlier notation we write\nx (t+1) i [ŷ (t) i ] and ŷ (t+1) i [ŷ (t) i ] = w · x (t+1) i [ŷ (t) i ]\nfor the time t+ 1 variables perturbed by feedback, and\nx (t+1) i [∅] and ŷ (t+1) i [∅] = w · x (t+1) i [∅]\nfor the counterparts we would have observed without any feedback.\nIn this setup, any effect of ŷ (t) i on x (t+1) i [ŷ (t) i ] is feedback. A simple way to constrain this\nrelationship is using a linear model\nx (t+1) i [ŷ (t) i ] = x (t) i [∅] + γ ŷ (t) i . (7)\nIn other words, we assume that x (t+1) i [ŷ (t) i ] is perturbed by an amount that scales linearly with ŷ (t) i . Given this simple model, we find that\nŷ (t+1) i [ŷ (t) i ] = ŷ (t+1) i [∅] + w · γ ŷ (t) i , and so f(y) = β y (8)\nwith β = w · γ; f is the feedback function from (2) we want to fit. We cannot work with (8) directly, because ŷ\n(t+1) i [∅] is not observed. In order to get\naround this problem, we add artificial noise to our predictions: at time t, we publish predictions y̌ (t) i = ŷ (t) i + ν (t) i instead of the raw predictions ŷ (t) i . As argued in Section 2, this method lets us detect feedback because ŷ (t+1) i can only depend on ν (t) i through a feedback mechanism, and so any relationship between ŷ (t+1) i and ν (t) i must be a symptom of feedback."
    }, {
      "heading" : "4.1 A Simple Regression Approach",
      "text" : "With the linear feedback model (8), the effect of ν (t) i on ŷ (t+1) i is\nŷ (t+1) i [ŷ (t) i +ν (t) i ] = ŷ (t+1) i [ŷ (t) i ] + β ν (t) i . (9)\nThis relationship suggests that we should be able to recover β by regressing ŷ (t+1) i against the added noise ν (t) i . The following result confirms this intuition.\nTheorem 1. Suppose that (8) holds, and that we add noise ν (t) i to our time t predictions. If we estimate β using linear least squares\nβ̂ = Ĉov\n[ ŷ\n(t+1) i [ŷ (t) i +ν (t) i ], ν (t) i ] V̂ar [ ν\n(t) i ] , (10) then\n√ n ( β̂ − β ) ⇒ N 0, Var [ ŷ (t+1) i [ŷ (t) i ] ] σ2ν  , (11) where σ2ν = Var [ ν (t) i ] and n is the number of examples to which we applied our predictor.\nProof. Because ν (t) i is fully artificial noise, we know a-priori that ν (t) i and ŷ (t+1) i [ŷ (t) i ] are independent. Thus, we can treat ŷ (t+1) i [ŷ (t) i ] as a homoscedastic noise term for our regression, and (11) follows immediately from standard results.\nTheorem 1 gives us a baseline understanding for the difficulty of the feedback detection problem: the precision of our feedback estimates scales as the ratio of the artificial noise σ2ν to natural noise. Note that the proof of Theorem 1 assumes that we only used predictions from a single time period t + 1 to fit feedback, and that the raw predictions ŷ (t+1) i [ŷ (t) i ] are all independent. If we relax these assumptions we get a regression problem with correlated errors, and need to be more careful with technical conditions.\nRemark: Artificial noise as an instrumental variable Our result from Theorem 1 is a special case of instrumental variables regression [e.g., Angrist et al., 1996], where ν\n(t) i\nacts an instrument. To make this connection explicit, we can write our problem as\nŷ (t+1) i [ŷ (t) i +ν (t) i ] = β · y̌ (t) i + ε (t) i + c and (12) y̌ (t) i = ν (t) i + ŷ (t) i , where (13)\nε (t) i =\n( ŷ\n(t+1) i [∅]− E\n[ ŷ\n(t+1) i [∅]\n]) and c = E [ ŷ\n(t+1) i [∅]\n] .\nIn general, the main concern in an application of instrumental variables is that the “exclusion restriction” needs to hold, which in our case is a requirement that ν (t) i needs to be independent of ε (t) i . Here, we constructed ν (t) i randomly, so the exclusion restriction trivially holds. Moreover, in a typical instrumental variables approach we would need to estimate the slope of the first-stage relationship between ν (t) i and y̌ (t) i ; in our case, however, we know a-priori that this slope is 1. This lets us avoid technical complications of the type discussed by Staiger and Stock [1997]."
    }, {
      "heading" : "4.2 Efficiency and Conditioning",
      "text" : "The simple regression model (10) treats the term ŷ (t+1) i [ŷ (t) i ] as noise. This is quite wasteful: if we know ŷ (t) i we usually have a fairly good idea of what ŷ (t+1) i [ŷ (t) i ] should be, and not using this information needlessly inflates the noise. Suppose that we knew the function\nµ(y) := E [ ŷ\n(t+1) i [ŷ (t) i ] ∣∣∣ ŷ(t)i = y] . (14)\nThen, we could write (9) as\nŷ (t+1) i [ŷ (t) i +ν (t) i ] = µ\n( ŷ\n(t) i\n) + ( ŷ\n(t+1) i [ŷ (t) i ]− µ\n( ŷ\n(t) i\n)) + β ν\n(t) i ,\nwhere µ(ŷ (t) i ) is a known offset. Extracting this known offset improves the precision of our estimate for β̂.\nTheorem 2. Under the conditions of Theorem 1 suppose that the function µ from (14) is known and that the ŷ (t+1) i are all independent of each other conditional on ŷ (t) i . Then, given the information available at time t, the estimate\nβ̂∗ = Ĉov\n[ ŷ\n(t+1) i [ŷ (t) i +ν (t) i ]− µ\n( ŷ\n(t) i\n) , ν\n(t) i ] V̂ar [ ν\n(t) i ] , (15) has asymptotic distribution.\n√ n ( β̂∗ − β ) ⇒ N 0, E [ Var [ ŷ (t+1) i [ŷ (t) i ] ∣∣∣ ŷ(t)i ]] σ2ν  . (16) Moreover, if the variance of\nη (t) i = ŷ (t+1) i [ŷ (t) i ]− µ(ŷ (t) i )\ndoes not depend on ŷ (t) i , then β̂ ∗ is the best linear unbiased estimator of β.\nProof. The η (t) i are independent of the ν (t) i , and so (16) follows from an argument analogous to the one that led to (11). If the η (t) i are still homoscedastic after conditioning on ŷ (t) i then, because the η (t) i are mean-zero by construction, the fact that β̂\n∗ is the best linear unbiased estimator of β follows directly from an application of the Gauss-Markov theorem where we treat ν (t) i as fixed and η (t) i as random [see Lehmann and Casella, 1998, p. 184].\nTheorem 2 extends the general result from above that the precision with which we can estimate feedback scales as the ratio of artificial noise to natural noise. The reason why β̂∗ is more efficient than β̂ is that we managed to condition away some of the natural noise, and reduced the variance of our estimate for β by\nVar [ µ ( ŷ\n(t) i\n)] = Var [ ŷ\n(t+1) i [ŷ (t) i ]\n] − E [ Var [ ŷ\n(t+1) i [ŷ (t) i ] ∣∣∣ ŷ(t)i ]] ; in other words, the variance reduction we get from β̂∗ directly matches the amount of variability we can explain away by conditioning.\nThe estimator (15) is not practical as stated, because it requires knowledge of the unknown function µ and is restricted to the case of linear feedback. In the next section, we generalize this estimator into one that does not require prior knowledge of µ and can handle non-linear feedback; this will lead us to the method presented in Section 2."
    }, {
      "heading" : "5 Fitting Non-Linear Feedback",
      "text" : "Suppose now that we have the same setup as in the previous section, except that now feedback has a non-linear dependence on y, and we replace (7) with\nx (t+1) i [ŷ (t) i ] = x (t+1) i [∅] + f(x)\n( ŷ\n(t) i\n) ,\nwhere f(x) is some feedback function in x-space. Our prediction model now becomes\nŷ (t+1) i [ŷ (t) i ] = ŷ (t+1) i [∅] + f\n( ŷ\n(t) i\n) (17)\nwhere f(·) = β · f(x)(·). When we add noise ν (t) i to the predictions in (17), we only affect the feedback term f(·):\nŷ (t+1) i [ŷ (t) i +ν (t) i ]− ŷ (t+1) i [ŷ (t) i ] = f\n( ŷ\n(t) i + ν (t) i\n) − f ( ŷ\n(t) i\n) . (18)\nThus, by adding artificial noise ν (t) i , we are able to cancel out the nuisance terms, and isolate the feedback function f that we want to estimate.\nWe cannot use (18) in practice, though, as we can only observe one of ŷ (t+1) i [ŷ (t) i +ν (t) i ] or\nŷ (t+1) i [ŷ (t) i ] in reality; the other one is counterfactual. We can get around this problem by conditioning on ŷ (t) i as in Section 4.2. Let\nµ (y) = E [ ŷ\n(t+1) i [ŷ (t) i +ν (t) i ] ∣∣∣ ŷ(t)i = y] (19) = t (y) + ϕσν ∗ f (y) ,\nwhere t (y) = E [ ŷ\n(t+1) i [∅] ∣∣∣ ŷ(t)i = y] is a term that captures trend effects that are not due to feedback. The ∗ denotes convolution:\nϕσν ∗ f (y) = E [ f ( ŷ (t) i + ν (t) i ) ∣∣∣ ŷ(t)i = y] with ν(t)i ∼ N (0, σ2ν) . Using the conditional mean function µ we can write our expression of interest as\nŷ (t+1) i [ŷ (t) i +ν (t) i ]− µ\n( ŷ\n(t) i\n) = f ( ŷ\n(t) i + ν (t) i ) − ϕσν ∗ f ( ŷ (t) i ) + η (t) i , (20)\nwhere η (t) i := ŷ (t+1) i [∅]− t\n( ŷ\n(t) i\n) .\nThe left-hand side can be measured, as it only depends on ŷ (t+1) i [ŷ (t) i +ν (t) i ] and ŷ (t) i . Meanwhile, conditional on ŷ (t) i , the first two terms on the right-hand side only depend on ν (t) i , while η (t) i is independent of ν (t) i and mean-zero. The upshot is that we can treat (20) as a regression problem where η (t) i is noise.\nIn practice, we do not know µ and also need to estimate it from an auxiliary nonparametric least-squares problem\nŷ (t+1) i [ŷ (t) i +ν (t) i ] ∼ µ\n( ŷ\n(t) i\n) , (21)\nwhere we again used the notation a ∼ g(b) to mean that we want to learn a function g(b) that predicts a."
    }, {
      "heading" : "5.1 A Pragmatic Approach",
      "text" : "There are many possible approaches to solving the non-parametric system of equations (20) for f [e.g., Hastie et al., 2009, Chapter 5]. Here, we take a pragmatic approach, and constrain ourselves to solutions of the form\nµ̂(y) = β̂µ · bµ(y) and f̂(y) = β̂f · bf (y), (22)\nwhere bµ : R → Rpµ and bf : R → Rpf are predetermined basis expansions; the basis bf should not contain an intercept term. This approach transforms our problem into an ordinary least-squares problem, and works well in terms of producing reasonable feedback estimates in real-world problems. In Section 6.3 we suggest a more general approach as a topic for further research.\nUnder the assumption that (22) in fact holds for some values βµ and βf , the result below shows that we can recover βf by least-squares regression. We provide a proof of this result, as well as a more detailed outline for how to set up the linear regression problem, in Appendix A.\nTheorem 3. Suppose that βµ and βf are defined as above, and that we have an unbiased estimator β̂µ of βµ with variance\nVµ = Var [ β̂µ ] .\nThen, if we fit βf by least squares using (20) as described in Appendix A, the resulting estimate β̂f is unbiased and has variance\nVar [ β̂f ] = ( XᵀfXf )−1 Xᵀf ( VY +XµVµX ᵀ µ ) Xf ( XᵀfXf )−1 , (23)\nwhere the design matrices Xµ and Xf are defined as\nXµ =  ... bᵀµ ( ŷ (t) i\n) ...\n and Xf = \n...\nbᵀf\n( ŷ\n(t) i + ν (t) i ) − (ϕσν ∗ bf ) ᵀ ( ŷ (t) i ) ...  (24) and VY is a diagonal matrix with (VY )ii = Var [ ŷ (t+1) i [ŷ (t) i ]\n∣∣∣ ŷ(t)i ]. In the case where (22) is misspecified, we can obtain a similar result using methods due\nto Huber [1967] and White [1980].\nIn practice, we can treat β̂µ as known since fitting µ(·) is usually easier than fitting f(·): estimating µ(·) is just a smoothing problem whereas estimating f(·) requires fitting differences. If in addition we treat the errors η\n(t) i in (20) as roughly homoscedatic, (23)\nreduces to\nVar [ β̂f ] ≈\nE [ Var [ ŷ\n(t+1) i [ŷ (t) i ] ∣∣∣ ŷ(t)i ]] n Var [si] , (25)\nwhere si = bf\n( ŷ\n(t) i + ν (t) i ) − ϕσν ∗ bf ( ŷ (t) i ) .\nThis simplified form again shows that the precision of our estimate of f(·) scales roughly as the ratio of the variance of the artificial noise ν\n(t) i to the variance of the natural noise."
    }, {
      "heading" : "6 Extensions and Further Work",
      "text" : "In this section, we discuss some possible extensions to the work presented in this paper."
    }, {
      "heading" : "6.1 Feedback Removal",
      "text" : "If we detect feedback in a real-world system, we can try to identify the root causes of the feedback and fix the problem by removing the feedback loop. That being said, a natural follow-up question to our research is whether we can automatically remove feedback. In the context of the linear feedback model (8), we incur an expected squared-error loss of\n˜̀= β2 E [( ŷ\n(t) i )2] from completely ignoring the feedback problem. Meanwhile, if we use the maximum likelihood estimate β̂ to correct feedback, we suffer a loss\n`σν = Var [ β̂ ] E [( ŷ (t) i )2] + σ2ν ,\nwhere the first term comes from our errors in estimating β̂ and the second comes from the extra noise we needed to inject into the system in order to detect the feedback.\nAn interesting topic for further research would be to find how to optimally set the scale σν of the artificial noise under various utility assumptions, and to understand the potential failure modes of feedback removal under model misspecification. In order to remove feedback, we would also need to have some way of dealing with the intercept term."
    }, {
      "heading" : "6.2 Covariate-Dependent Feedback",
      "text" : "Our analysis was presented in the context of the additive feedback model\nŷ (t+1) i [y̌ (t) i ] = ŷ (t+1) i [∅] + f\n( y̌\n(t) i\n) .\nIn practice, however, we may want to let feedback depend on some other covariates z\nŷ (t+1) i [y̌ (t) i ] = ŷ (t+1) i [∅] + f\n( y̌\n(t) i , z (t) i\n) ;\nfor example, we may want to slice feedback by geographic region. One particularly interesting but challenging extension would be to make feedback depend on the unperturbed prediction ŷ (t) i [∅]:\nŷ (t+1) i [y̌ (t) i ] = ŷ (t+1) i [∅] + f\n( y̌\n(t) i , ŷ (t) i [∅]\n) .\nFor example, if ŷ is a prediction for how good a search result is, we might assume that search results that are actually good (ŷ[∅] 0) have a different feedback response from those that are terrible (ŷ[∅] 0). The challenge here is that ŷ[∅] is unobserved, and so we need to have it act on f via proxies. Developing a formalism that lets f depend on ŷ[∅] in a useful way while allowing for consistent estimation seems like a promising pathway for further work."
    }, {
      "heading" : "6.3 Penalized Regression",
      "text" : "The key technical challenge in implementing our method for feedback detection is solving the spline equation (20). In Section 5.1 we proposed a pragmatic approach that enabled us to get good feedback estimates in many examples. However, it should be possible to devise more general methods for fitting f . The equation (20) is linear in f , and so any strictly convex penalty function L : A → R over some convex subset A ⊆ {R → R} of real valued functions on R leads to a well-defined estimator f̂ through the convex optimization problem\nf̂L = argminf∈A\n{∑( ŷ\n(t+1) i [ŷ (t) i +ν (t) i ]− µ\n( ŷ\n(t) i\n) − f ( ŷ\n(t) i + ν (t) i\n) (26)\n+ ϕσν ∗ f ( ŷ (t) i ))2 + L(f) } .\nIn the context of smoothing splines, a popular choice is to use\nL(f) = λ ∫ R ‖f ′′(x)‖2 dx\nand make A be the set on which this integral is well-defined. There is an extensive literature on non-parametric regression problems constrained by smoothness penalties [e.g., Evgeniou et al., 2000, Girosi et al., 1995, Green and Silverman, 1994, Hastie and Tibshirani, 1990, Wahba, 1990]; presumably, similar approaches should also give us smoothing spline solutions to (20)."
    }, {
      "heading" : "7 Conclusion",
      "text" : "We proposed a randomization scheme that can be used to detect feedback in real-world statistical systems. Our method involves adding noise to the predictions made by the system; this noise puts us in a randomized experimental setup that lets us measure feedback as a causal effect. In general, the scale of the artificial noise required to detect feedback is smaller than the scale of the natural predictor noise; thus, we can deploy our feedback detection method without disturbing our system of interest too much. The method does not require us to make hypotheses about the mechanism through which feedback may propagate; thus, it can be used to continuously monitor statistical systems and alert us if any changes to the system lead to an increase in feedback."
    }, {
      "heading" : "Acknowledgements",
      "text" : "The authors are grateful to Alex Blocker, Randall Lewis, and Brad Efron for helpful suggestions and interesting conversations."
    }, {
      "heading" : "A Fitting Non-Linear Feedback by Ordinary Least Squares",
      "text" : "Regression\nCarrying out the fitting procedure outlined in Section 2.1 is straight-forward using standard R functions if we are willing to construct µ(·) and f(·) using pre-specified basis expansions\nµ̂(y) = β̂µ · bµ(y) and f̂(y) = β̂f · bf (y)\nas in (22). We first need to construct the design matrices\nXµ =  ... bᵀµ ( ŷ (t) i\n) ...\n and Xf = \n...\nbᵀf\n( ŷ\n(t) i + ν (t) i ) − (ϕσν ∗ bf ) ᵀ ( ŷ (t) i ) ...  from (24). Constructing Xµ just involves choosing a basis function; however, evaluating\nγi = (ϕσν ∗ bf ) ᵀ ( ŷ (t) i ) for each row of Xf can be computationally intensive if we are not careful. In particular, evaluating γi by numerical integration separately for each i can be painfully slow. A more efficient way to compute γi is to evaluate (ϕσν ∗ bf ) (y) over a grid of y-values in a single pass using the fast Fourier transform (e.g., by using convolve in R), and then to linearly interpolate the result onto the real line (e.g., using approxfun).\nOnce we have computed these design matrices, we can estimate β̂µ and β̂f by solving the linear regression problems\nY ∼ Xµβ̂µ (27)\nand ( Y −Xµβ̂µ ) ∼ Xf β̂f , (28)\nwhere Y is just a vector with entries ŷ (t+1) i [ŷ (t) i +ν (t) i ]. Notice that this whole procedure only requires knowledge of Xµ, Xf , and the noised new predictions ŷ (t+1) i [ŷ (t) i +ν (t) i ]; we never reference the counterfactual predictions ŷ (t+1) i [ŷ (t) i ] or unobservable predictions ŷ (t+1) i [∅].\nIn practice, most of the errors in our procedure come from the difference equation (28) and not from the conditional mean regression (27). Thus, when our model is well-specified and the additivity assumption (2) holds, we can get good estimates for the accuracy of f by looking at the parametric standard error estimates provided by lm from fitting (28); this is what we did for the simulations presented in Figure 1. In case of model misspecification, however, parametric confidence intervals can break down and it is better to use non-parametric methods such as the bootstrap. We used a non-parametric bootstrap for the logs simulation presented in Section 3.1.\nProof of Theorem 3. Given the regression problem described above, (23) follows directly from standard results on heteroscedastic linear regression [Huber, 1967, White, 1980]. Note\nthat our theoretical result assumes that β̂µ and β̂f are trained on independent data sets."
    } ],
    "references" : [ {
      "title" : "On the use of a linear model for the identification of feedback systems",
      "author" : [ "Hirotugu Akaike" ],
      "venue" : "Annals of the Institute of statistical mathematics,",
      "citeRegEx" : "Akaike.,? \\Q1968\\E",
      "shortCiteRegEx" : "Akaike.",
      "year" : 1968
    }, {
      "title" : "Compliance as an explanatory variable in clinical trials",
      "author" : [ "Bradley Efron", "David Feldman" ],
      "venue" : null,
      "citeRegEx" : "Efron and Feldman.,? \\Q2002\\E",
      "shortCiteRegEx" : "Efron and Feldman.",
      "year" : 2002
    }, {
      "title" : "Regularization networks and",
      "author" : [ "press", "1993. Theodoros Evgeniou", "Massimiliano Pontil", "Tomaso Poggio" ],
      "venue" : null,
      "citeRegEx" : "press et al\\.,? \\Q1993\\E",
      "shortCiteRegEx" : "press et al\\.",
      "year" : 1993
    } ],
    "referenceMentions" : [ {
      "referenceID" : 0,
      "context" : "Akaike [1968] showed how to fit cross-component feedback in a system with many components; however, he did not add artificial noise to the system, and so was unable to detect feedback of a single component on itself.",
      "startOffset" : 0,
      "endOffset" : 14
    } ],
    "year" : 2017,
    "abstractText" : "A statistical predictor that is deployed in a live production system may perturb the features it uses to make predictions. Such a feedback loop can occur, for example, when a model that predicts a certain type of behavior ends up causing the behavior it predicts, thus creating a self-fulfilling prophecy. This paper analyzes statistical feedback detection as a causal inference problem, and proposes a local randomization scheme that can be used to detect feedback in real-world problems. We apply our method to a predictive model currently in use at an internet company.",
    "creator" : "LaTeX with hyperref package"
  }
}