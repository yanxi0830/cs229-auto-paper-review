{
  "name" : "1606.04145.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : null,
    "authors" : [ "Maria-Florina Balcan", "Tuomas Sandholm", "Ellen Vitercik" ],
    "emails" : [ "ninamf@cs.cmu.edu.", "sandholm@cs.cmu.edu.", "vitercik@cs.cmu.edu." ],
    "sections" : [ {
      "heading" : "1 Introduction",
      "text" : "Multi-item, multi-bidder auctions have been studied extensively in economics, operations research, and computer science. In a combinatorial auction (CA) [Cramton et al., 2006], the bidders may submit bids on bundles of goods, rather than on individual items alone, and thereby they may fully express their complex valuation functions. Notably, these functions may be non-additive due to the presence of complementary or substitutable goods for sale. There are many important and practical applications of CAs, ranging from the US government’s wireless spectrum license auctions to sourcing auctions, through which companies coordinate the procurement and distribution of equipment, materials and supplies [Cramton et al., 2006].\nOne of the most important and tantalizing open questions in computational economics is the design of optimal auctions, that is, auctions that maximize the seller’s expected revenue [Vohra, 2001]. In the standard economic model, it is assumed that the bidders’ valuations are drawn from an underlying distribution and that the mechanism designer has perfect information about this distribution. Astonishingly, even with this strong assumption, the optimal CA design problem is\n∗Authors’ addresses: Carnegie Mellon University, School of Computer Science. Email: {ninamf,sandholm,vitercik}@cs.cmu.edu.\nar X\niv :1\n60 6.\n04 14\n5v 1\n[ cs\n.L G\n] 1\n3 Ju\nn 20\n16\nunsolved even for auctions with just two distinct items for sale and two bidders. A monumental advance in the study of optimal auction design was the characterization of the optimal 1-item auction [Myerson, 1981]. In that auction, the winner and the payment are determined not based on the bids, but rather on virtual valuations which are transformations of the bids in a way that makes weak bidders (i.e., bidders who are likely to have low valuations) artificially more competitive. That auction was later extended to the case of selling multiple copies of the same item [Maskin and Riley, 1989]. However, the characterization of revenue-maximizing multi-item auctions has been obtained only for special cases of the two-item two-bidder setting [Avery and Hendershott, 2000, Armstrong, 2000].\nWhile it might be surprising that the revenue-maximizing CA is unknown, we observe that this is actually what one should expect once one views the problem through a computational lens. Conitzer and Sandholm proved that the problem of finding a revenue-maximizing CA (among all deterministic CAs with discrete types) is NP-complete [Conitzer and Sandholm, 2004]. Therefore, it is unlikely that a concise characterization of revenue-maximizing CAs (among deterministic CAs) can even exist 1.\nIn recent years, a novel approach known as automated mechanism design (AMD) has been adopted to attack the revenue-maximizing auction design problem [Conitzer and Sandholm, 2002, Sandholm, 2003]. In one strand of AMD research, the support of the distribution of the bidders’ valuations is discretized and the input to the design algorithm is a probability for each support point [Conitzer and Sandholm, 2002, Sandholm, 2003, Conitzer and Sandholm, 2004]. This has the challenge that the input is doubly exponential in the number of items. In an independent-privatevalues setting, the number of support points is nk2 m , where n is the number of bidders, k is the number of discrete value levels a bidder can assign to a bundle, and m is the number of items. This is because each of the 2m bundles can take any of k values. With correlated valuations, the prior has k2 nm support points. Therefore, that strand is not scalable [Conitzer and Sandholm, 2003], and it is unlikely that such priors are available in practical applications. In contrast, in the most scalable strand of AMD research, algorithms have been developed which take samples from the bidders’ valuation distributions as input, optimize over a rich class of auctions, and return an auction which is high-performing over the sample [Likhodedov and Sandholm, 2004, Likhodedov and Sandholm, 2005, Sandholm and Likhodedov, 2015]. AMD algorithms have yielded deterministic mechanisms with the highest known revenues in the contexts used for empirical evaluations [Sandholm and Likhodedov, 2015]. This approach relaxes the unrealistic assumption that the mechanism designer has perfect information about the bidders’ valuation distribution.\nHowever, until now, there was no formal characterization of the number of samples required to guarantee that the empirical revenue of the designed mechanism on the samples is close to its expected revenue on the underlying, unknown distribution over bidder valuations. In this paper, we provide that missing link. We present tight sample complexity guarantees over an extensive hierarchy of expressive CA families. These are the most commonly used auction families in AMD. The classes in the hierarchy are based on the classic VCG mechanism [Vickrey, 1961, Clarke, 1971, Groves, 1973], which is a generalization of the well-known second-price, or Vickrey, singleitem auction. The auctions we consider achieve significantly higher revenue than the VCG baseline by weighting bidders (multiplicatively increasing all of their bids) and boosting outcomes (additively increasing the liklihood that a particular outcome will be the result of the auction).\nA major strength of our results is their applicability to any algorithm that determines the optimal auction over the sample, a nearly optimal approximation, or any other black box procedure.\n1It is well known that randomization can increase revenue beyond that of the best deterministic CA. In this paper we focus on deterministic CAs because randomized CAs 1) have ex post fairness problems that can be unpalatable to bidders, 2) are harder for bidders and auctioneers to understand, and 3) are not used in practice, to our knowledge.\nTherefore, they apply to any automated mechanism design algorithm, optimal or not. One of the key challenges in deriving these general sample complexity bounds is that to do so, we must develop deep insights into how changes to the auction parameters (the bidder weights and allocation boosts) effect the outcome of the auction (who wins which items and how much each bidder pays) and thereby the revenue of the auction. In our context, we show that the functions which determine the outcome of an auction are highly complex, consisting of multi-stage optimization procedures.\nTherefore, the function classes we consider are much more challenging than those commonly found in machine learning contexts. Typically, for well-understood classes of functions used in machine learning, such as linear separators or other smooth curves in Euclidean spaces, there is a simple mapping from the parameters of a specific hypothesis to its prediction on a given example and a close connection between the distance in the parameter space between two parameter vectors and the distance in function space between their associated hypotheses. Roughly speaking, it is necessary to understand this connection in order to determine how many significantly different hypotheses there are over the full range of parameters. In our context, due to the inherent complexity of the classes we consider, connecting the parameter space to the space of revenue functions requires a much more delicate analysis. Indeed, the key technical part of our work involves understanding this connection from a learning theoretic perspective. For the more general classes in the hierarchy, we use Rademacher complexity to derive our bounds, and for the auction classes with more combinatorial structure, we exploit that structure to prove pseudo-dimension bounds. Therefore, this work is both of practical importance since we fill a fundamental gap in AMD, and of learning theoretical interest, as our sample complexity analysis requires a deep understanding of the structure of the revenue function classes we consider."
    }, {
      "heading" : "1.1 The Hierarchy of Deterministic Combinatorial Auctions",
      "text" : "Early work in automated mechanism design approached the mechanism design problem as an integer program or linear program [Conitzer and Sandholm, 2002, Sandholm, 2003, Conitzer and Sandholm, 2004, Conitzer and Sandholm, 2003]. Then a more scalable approach emerged where the design focuses on a parameterized family of CA mechanisms. In that approach, the design of a high-revenue CA is conducted via an algorithmic search for a good parameter vector within the family [Likhodedov and Sandholm, 2004, Likhodedov and Sandholm, 2005, Sandholm and Likhodedov, 2015]. Under this view, there is a hierarchy of CA families which we will now describe, and which is depicted in Figure 1. We define these families formally in Section 2.\nThe most general family in the hierarchy of deterministic combinatorial auctions that we study is affine maximizer auctions (AMAs) [Roberts, 1979]. It contains the VCG mechanism as a special\ncase, as well auctions that achieve higher expected revenue than the VCG by weighting bidders and boosting allocations. In particular, if the weight of a bidder is increased, any bid she submits will be increased multiplicatively by that amount. If an allocation is boosted by adding a monetary preference to it, the chance that it will be the AMA allocation is increased. The parameters of an AMA are the coefficients in these bidder weightings and allocation boostings.\nIn the classes below AMAs in the hierarchy, more constraints are added to these transformations, thereby decreasing the flexibility of the auctions. For example, the class of virtual valuation combinatorial auctions (VVCAs) [Likhodedov and Sandholm, 2004] consists of AMAs with a restricted set of allowable allocation boosts; the structure is such that the parameters can be thought of as affine transformation parameters of each bidder’s valuation function—hence the name of the family. Meanwhile, in a λ-auction [Jehiel et al., 2007], any allocation boost is valid, but no bidder is weighted more than any other. In a mixed bundling auction (MBA) [Jehiel et al., 2007], the only allowed allocation boosts are for those wherein a single bidder receives all of the items in the auction. These auctions can be supplemented with reserve prices, which yields the family of mixed bundling auction with reserve prices (MBARPs) [Tang and Sandholm, 2012]."
    }, {
      "heading" : "1.2 Summary of Results and Techniques",
      "text" : "For each family in the hierarchy, we prove strong upper bounds on the number of samples required to guarantee that with high probability, for any auction in the family, the expected revenue of the auction is close to the average revenue over the samples. In learning-theoretic terms, these are called uniform convergence sample complexity bounds and they have the nice feature that they apply to any procedure one might use to optimize over the samples, such as an algorithm that returns the optimal auction over the sample or a nearly optimal approximation, as well as any other black box procedure. Note that given any two auction families such that one of them is a subset of the other, the uniform convergence sample complexity bound for the smaller family is always upper bounded by the uniform convergence sample complexity bound of the larger one. Therefore the sample complexity results we obtain for AMAs immediately apply to its subfamilies. For these subfamilies, however, we exploit their unique structures and thus derive even better upper bounds.\nWe will now summarize our main results a bit more formally. Let A be a fixed class of auctions (e.g. AMAs or VVCAs) and define revA(~v) to be the revenue of an auction A ∈ A on a vector of bidder valuations ~v. Given a distribution D, E~v∼D[revA(~v)] is the expected revenue of the auction on a vector of bidder valuations drawn at random from D. Moreover, given a sample S = { ~v1, . . . , ~vN\n} of bidder valuations, 1N ∑N i=1 revA ( ~vi )\nis the average revenue of A over the sample. Now, we define the sample complexity of uniform convergence over A as follows.\nDefinition 1 (Sample complexity of uniform convergence over A). We say that N( , δ,A) is the sample complexity of uniform convergence over A if for any , δ ∈ (0, 1), if S = { ~v1, . . . , ~vN } is a sample of size N ≥ N( , δ,A) drawn at random from D, with probability at least 1 − δ, for all auctions A ∈ A,\n∣∣∣ 1N ∑Ni=1 revA (~vi)− E~v∼D [revA(~v)]∣∣∣ ≤ . In other words, the sample complexity of uniform convergence over A is the sufficient number of samples such that uniformly for all auctions in that class, the expected revenue over the distribution is close to the average revenue over the sample.\nIn Theorem 1, we bound the sample complexity of uniform convergence for the classes of AMAs, VVCAs, and λ-auctions, and we prove lower bounds with near-tight dependence on the number of bidders n and the number of items m. We go on to prove tighter upper bounds for the restricted classes of MBAs and MBARPs in Theorems 2 and 3.\nThese upper bounds immediately imply that for any algorithm that outputs the auction A that achieves maximum average revenue over its input samples, we can guarantee that the expected revenue of A is close to the expected revenue of the best auction with respect to the actual— unknown—distribution. In particular, for a fixed class of auctions A, suppose that Â is the auction that maximizes average revenue over the samples S and A∗ is the auction that maximizes expected revenue with respect to the distribution D. The sample complexity of uniform convergence over A is sufficient to ensure that with high probability, the expected revenue of Â is close to the expected revenue of A∗. In other words, we can guarantee that if we learn the best auction over the sample, then it will achieve almost maximal revenue with respect to the best auction in that class.\nWe are now ready to present our main results. For a fixed class of auctions and domain X over the bidders’ valuation functions, let revA be the corresponding revenue function of an auction A in that class, where revA : X → [0, U ] for some U ∈ R.\nTheorem 1. The sample complexity of uniform convergence over the classes of n-bidder, m-item AMAs, VVCAs, and λ-Auctions is\nN = Õ\n([ U\nnm √ m ( U + nm/2 )]2) .\nMoreover, for λ-Auctions, N = Ω (nm) and for VVCAs, N = Ω (2m).\nWe prove Theorem 1 by splitting the complex AMA revenue function into n + 1 simpler and economically coherent pieces: the maximum weighted social welfare without any one bidders participation and the amount of revenue subtracted out to ensure the resulting auction is strategy-proof (defined in Section 2. We analyze these simpler functions using Rademacher complexity, a tool from learning theory, and combine these analyses using compositional properties of Rademacher complexity to bound the sample complexity of the function class as a whole.\nTheorem 2. The sample complexity of uniform convergence over the class of n-bidder, m-item MBARPs with item-specific reserve prices is\nN = O\n(( U )2( m3 log n log U + log 1\nδ\n)) .\nTheorem 3. The sample complexity of uniform convergence over the class of n-bidder, m-item MBAs is\nN = O\n(( U )2( log U + log 1\nδ\n)) .\nTo prove Theorems 2 and 3, we characterize the mapping from the MBA (and MBARP) parameter space to the revenue of the associated auctions on an arbitrary bidding instance. We then use these structural insights to prove bounds on the pseudo-dimension of these revenue functions, another learning-theoretic tool which allows us to derive strong sample complexity bounds.\nIn our bounds, we observe the usual dependence on U , which is necessary when analyzing the sample complexity of learning over real-valued functions because it measures the extent to which a single example can influence the average function value over the sample.\nWe note that it might not always be computationally feasible to solve for the best auction over S for the given auction family. Rather, we may only be able to design an auction A within the family that has average revenue over S that is within a (1 + α) multiplicative factor of the\nrevenue-maximizing auction over S within the family. Nonetheless, in Theorem 4 we prove that with slightly more samples, we can ensure that the expected revenue of A is close to being with a (1 +α) multiplicative factor of the expected revenue of the optimal auction within the family with respect to the real—unknown—distribution D. We prove a similar bound for an additive factor approximation as well. Formally, we prove the following result, which holds very generally for any function class H with domain X and for any arbitrary loss function ` : H ×X → [−c, c] for some c ∈ R.\nTheorem 4. Let S = {x1, . . . , xN} be a sample drawn from D and , δ ∈ (0, 1) be given. Suppose that N is sufficiently large to ensure that with probability at least 1 − δ/2, for any h ∈ H, E x∼D [` (h, x)]− 1N ∑N i=1 ` (h, xi) < .\nSuppose h∗ ∈ H is a function that minimizes expected loss with respect to the distribution, ĥ is a function that minimizes average loss over the sample S, and h̃ ∈ H is a function such that the average loss of ĥ over S is within an additive ρ factor of the average loss of h̃ over S. In other words, 1N ∑N i=1 ` ( h̃, xi ) − 1N ∑N i=1 ` ( ĥ, xi ) ≤ ρ for some ρ > 0. Then with probability at least 1−δ,\nE x∼D\n[ ` ( h̃, x )] − E x∼D [` (h∗, x)] ≤ + c √ ln(4/δ) 2N + ρ.\nMeanwhile, if 1N ∑N i=1 ` ( h̃, xi ) ≤ (1 + α) 1N ∑N i=1 ` ( ĥ, xi ) for some α ∈ [0, 1), then\nE x∼D\n[ ` ( h̃, x )] − E x∼D [` (h∗, x)] ≤ + (1 + α) ( c √ ln(4/δ) 2N ) + α E x∼D [` (h∗, x)] .\nMoreover, both bounds are tight in the worst case.\nFor any class of auctions A and corresponding set of revenue functions HA = {revA | A ∈ A}, this result can be instantiated by setting the loss function such that ` (revA, ~v) = −revA (~v), and therefore by minimizing loss, we are maximizing revenue. The proof of Theorem 4 can be found in Appendix A."
    }, {
      "heading" : "1.3 Additional Related Research",
      "text" : "In prior research, most analyses of the revenue achieved by the classes that make up the hierarchy of deterministic CAs have been empirical [Sandholm, 2003, Likhodedov and Sandholm, 2004, Likhodedov and Sandholm, 2005, Tang and Sandholm, 2012, Sandholm and Likhodedov, 2015]. However, from a theoretical standpoint, Roberts, when introducing the class of AMAs [Roberts, 1979], proved that they are the only ex post strategy-proof mechanisms over unrestricted domains of valuations2. Lavi et al. went on to prove that under certain natural assumptions, every incentive compatible CA is almost3 an affine maximizer.\nIn the intersection of learning theory and mechanism design, the sample complexity of revenue maximization has been studied primarily in the single-item or the more general single-dimensional\n2A mechanism is ex post strategy-proof if truthful bidding is an ex post Nash equilibrium in which all bidders always receive nonnegative utility. By ex post Nash equilibrium, we mean that for each player, no matter the valuations of the other players but given that they are bidding truthfully, that player will maximize her utility if she bids truthfully as well.\n3A mechanism is an almost affine maximizer if it is an affine maximizer for sufficiently high valuations [Lavi et al., 2003]. Lavi et al. conjecture that the “almost” qualifier is merely technical, and can be removed in future research.\nsettings [Elkind, 2007, Cole and Roughgarden, 2014, Huang et al., 2015, Medina and Mohri, 2014, Morgenstern and Roughgarden, 2015, Roughgarden and Schrijvers, 2015, Devanur et al., 2016], as well as some multi-dimensional settings which are reducible to the single-bidder setting [Morgenstern and Roughgarden, 2016]. In contrast, the combinatorial settings that we study are much more complex since the revenue functions consist of multi-stage optimization procedures that cannot be reduced to a single-bidder setting. The complexity intrinsic to the multi-item setting is explored by Dughmi et al., who show that for a single unit-demand bidder, when the bidder’s values for the items may be correlated, Ω(2m) samples are required to determine a constant-factor approximation to the optimal auction [Dughmi et al., 2014].\nLearning theory tools such as pseudo-dimension and Rademacher complexity have been used to prove strong guarantees in auction settings [Medina and Mohri, 2014, Morgenstern and Roughgarden, 2015, Morgenstern and Roughgarden, 2016]. These authors have analyzed certain classes of piecewise linear revenue functions and shown that few samples are needed to learn over these specific classes. In a similar direction, bounds on the sample complexity of welfare-optimal item pricings have been developed [Feldman et al., 2015, Hsu et al., 2016].\nDespite the inherent complexity of designing high-revenue CAs, Morgenstern and Roughgarden use linear separability as a tool to prove that certain simple classes of multi-parameter auctions have small sample complexity, such as sequential auctions with item and bundle pricings and secondprice item auctions with reserve prices [Morgenstern and Roughgarden, 2016]. In particular, they show that bounding the sample complexity of these sequential auctions can be reduced to the single-buyer setting. In contrast, the hierarchy we study consists of VCG-based mechanisms, as opposed to sequential auctions. These VCG-based revenue function classes are more versatile than item pricing auctions because they allow the mechanism designer many more degrees of freedom than the number of items. Moreover, even the simpler auction classes we consider pose a unique challenge because the parameters defining the auctions interact in non-intuitive ways with the multi-stage optimization procedures which define the revenue functions we work with, unlike item pricings, which are simple by design. Our function classes therefore require us to understand the specific form of the weighted VCG payment rule and its interaction with the parameter space. Thus, our context and techniques diverge from those in [Morgenstern and Roughgarden, 2016].\nEarlier work of Balcan et al. addressed sample complexity results for revenue maximization in unrestricted supply settings [Balcan et al., 2008]. The settings considered by Balcan et al. are significantly simpler to analyze since in the unrestricted supply settings, the hypothesis classes are straightforward to analyze from a learning theory perspective and the revenue function decomposes additively among bidders.\nFinally, there is a wealth of work on characterizing the optimal CA for restricted settings and designing mechanisms which achieve high, if not optimal revenue in specific contexts. The simplicity of Myerson’s optimal single-item auction might lead one to hope that the optimal multi-item auction could be so elegantly characterizable [Myerson, 1981]. Recent work has made considerable progress toward this end (e.g. [Alaei et al., 2013, Bhalgat et al., 2013, Bhattacharya et al., 2010, Cai et al., 2012b, Cai et al., 2012a, Cai et al., 2013, Daskalakis et al., 2014, Kleinberg and Weinberg, 2012]) but there is still relatively little known about optimal multi-item auction design. The problem has also garnered significant interest from a more applied perspective, resulting in significant advances from the artificial intelligence and machine learning communities (e.g. [Parkes and Ungar, 2000, Lahaie, 2011, Wurman and Wellman, 2000, Parkes et al., 2004, Amin et al., 2013, Mohri and Munoz, 2014, Mohri and Munoz, 2015]).\nRevenue-maximizing mechanism design complements an active research area in theoretical computer science which strives to answer the question: can simple mechanisms achieve near-optimal revenue? This question was posed by Hartline and Roughgarden, who left the precise definition\nof a simple mechanism open for interpretation [Hartline and Roughgarden, 2009]. Recently, Morgenstern and Roughgarden proposed an auction class’s pseudo-dimension as a formal means of defining simplicity [Morgenstern and Roughgarden, 2015, Morgenstern and Roughgarden, 2016]. In particular, Morgenstern and Roughgarden complemented pseudo-dimension bounds with known approximation guarantees for the corresponding simple auction classes [Morgenstern and Roughgarden, 2016]. See [Morgenstern and Roughgarden, 2016] and references therein for descriptions of these guarantees."
    }, {
      "heading" : "2 Preliminaries",
      "text" : "In the following section, we explain the basic mechanism design problem, fix notation, and then describe the hierarchy of combinatorial auction families we study."
    }, {
      "heading" : "2.1 Mechanism design background",
      "text" : "We consider the problem of selling m heterogeneous goods to n bidders. This means that there are 2m different bundles of goods, B = {b1, . . . , b2m}. Each bidder i ∈ [n] is associated with a set-wise valuation function over the bundles, vi : B → R. We assume that the bidders’ valuations are drawn from a distribution D.\nEvery auction is defined by an allocation function and a payment function. The allocation function determines which bidders receive which items based on their bids and the payment function determines how much the bidders need to pay based on their bids and the allocation. It is up to the mechanism designer to determine which allocation and payment functions should be used. In our context, the two functions are fixed based on the samples from D before the bidders submit their bids.\nEach auction family that we consider has a design based on the classic Vickrey-Clarke-Groves mechanism (VCG). The VCG mechanism, which we describe below, is the canonical strategy-proof mechanism, which means that every bidder’s dominant strategy is to bid truthfully. In other words, for every Bidder i, no matter the bids made by the other bidders, Bidder i maximizes her expected utility (her value for her allocation minus the price she pays) by bidding her true value. Therefore, we describe the VCG mechanism assuming that the bids equal the bidders’ true valuations.\nThe VCG mechanism allocates the items such that the social welfare of the bidders, that is, the sum of each bidder’s value for the items she wins, is maximized. Intuitively, each winning bidder then pays her bid minus a “rebate” equal to the increase in welfare attributable to her presence in the auction. This form of the payment function is crucial to ensuring that the auction is strategy-proof. More concretely, the allocation of the VCG mechanism is the disjoint set of subsets (b∗1, . . . , b ∗ n) ⊆ B that maximizes ∑ vi (b ∗ i ). Meanwhile, let ( b−i1 , . . . , b −i n ) be the disjoint set\nof subsets that maximizes ∑\nj 6=i vj ( b−ij ) . Then Bidder i must pay ∑ j 6=i [ vj ( b−ij ) − vj ( b∗j )] =\nvi (b ∗ i ) − [∑ vj ( b∗j ) − ∑ j 6=i vj ( b−ij )] . In the special case where there is one item for sale, the VCG mechanism is known as the second price, or Vickrey, auction, where the highest bidder wins the item and pays the second highest bid. We note that every auction in the classes we study is strategy-proof, so we may assume that the bids equal the bidders’ valuations."
    }, {
      "heading" : "2.1.1 Notation",
      "text" : "We study auctions with n bidders and m items. We refer to the bundle of all m items as the grand bundle. In total, there are (n + 1)m possible allocations, which we denote as the vectors\nO = { ~o1, . . . , ~o(n+1)m } . Each allocation vector ~oi can be written as (oi,1, . . . , oi,n), where oi,j = b` ∈ B denotes the bundle of items allocated to Bidder j in allocation ~oi. We use the notation ~v1 = (v1 (b1) , . . . , v1 (b2m)) and ~v = (~v1, . . . , ~vn) to denote a vector of bidder valuation functions. We say that revA(~v) is the revenue of an auction A on the valuation vector ~v. Denoting the payment of any one bidder under auction A given valuation vector ~v as pi,A (~v), we have that revA(~v) = ∑n i=1 pi,A (~v)."
    }, {
      "heading" : "2.1.2 Auction classes",
      "text" : "We now give formal definitions of the CA families in the hierarchy we study. See Figure 1 for the hierarchical organization of the auction classes, together with the papers which introduced each family.\nAffine maximizer auctions (AMAs). An AMA A is defined by a set of weights per bidder (w1, . . . , wn) ⊂ R>0 and boosts per allocation ( λ (~o1) , . . . , λ ( ~o(n+1)m )) ⊂ R. An auction A uniquely\ncorresponds to a set of these parameters, so we write A = ( w1, . . . , wn, λ (~o1) , . . . , λ ( ~o(n+1)m )) . To simplify notation, we write λi = λ (~oi) interchangeably. These parameters allow the mechanism designer to multiplicatively boost any bidder’s bids by their corresponding weight and to increase the likelihood that any one allocation is returned as the output of an auction. More concretely, the allocation of an AMA A, is ~o∗ = argmax~oi∈O {∑n j=1wjvj (oi,j) + λ (~oi) } . The payment function of A has the same form as the VCG payment rule, with the parameters factored in to ensure that the auction remains strategy-proof. In particular, for all j ∈ [n], the payments are pj,A (~v) =\n1 wj [∑ 6̀=j w`v` (o−j,`) + λ (~o−j)− ∑ ` 6=j w`v` (o ∗ ` )− λ (~o∗) ] , where ~o−j =\nargmax~oi∈O {∑ 6̀=j w`v` (oi,`) + λ (~oi) } . We assume that Hw ≤ wi ≤ Hw, λi ≤ Hλ, and vi (b`) ≤ Hv for some Hw, Hw, Hλ, Hv ∈ R≥0. Virtual valuation combinatorial auctions (VVCAs). VVCAs are a subset of AMAs. The defining characteristic of a VVCA is that each λ (~oj) is split into n terms such that λ (~oj) =∑n\ni=1 λi (~oj) where λi (~oj) = ci,b for all allocations ~oj that give Bidder i exactly bundle b ∈ B. λ-auctions. λ-auctions are the subclass of AMAs where wi = 1 for all i ∈ [n]. Mixed bundling auctions (MBAs). The class of MBAs is parameterized by a constant c ≥ 0 which can be seen as a discount for any bidder who receives the grand bundle. Formally, the cMBA is the λ-auction with λ(~o) = c if some bidder receives the grand bundle in allocation ~o and 0 otherwise.\nMixed bundling auctions with reserve prices (MBARPs). MBARPs are identical to MBAs though with reserve prices. In a single-item VCG auction (i.e. second price auction) with a reserve price, the item is only sold if the highest bidder’s bid exceeds the reserve price, and the winner must pay the maximum of the second highest bid and the reserve price. To generalize this intuition to the multi-item case, we enlarge the set of agents to include the seller, who is now Bidder 0 and whose valuation for a set of items is the set’s reserve price. Working in this expanded set of agents, the bidder weights are all 1 and the λ terms are the same as in the standard MBA setup. Importantly, the seller makes no payments, no matter her allocation. More formally, given a vector of valuation functions ~v, the MBARP allocation is ~o∗ = argmax~o∈O ∑n i=0 vi (oi) + λ (~o) . For each i ∈ {1, . . . , n}, Bidder i’s payment is\npA,i(~v) = ∑\nj∈{0,...,n}\\{i}\nvj (o−i,j) + λ (~o−i)− ∑\nj∈{0,...,n}\\{i}\nvj ( o∗j ) − λ (~o∗) ,\nwhere ~o−i = argmax\n~o∈O ∑ j∈{0,...,n}\\{i} vj (oj) + λ (~o) ."
    }, {
      "heading" : "2.2 Computational learning theory background",
      "text" : "To derive the upper bounds in Theorems 1 through 3, we use two learning-theoretic tools which quantify the “complexity” of a class of functions: Rademacher complexity and pseudo-dimension. We define these concepts generally for a class of functions H with domain X and distribution D over X. Further, we define ` to be an arbitrary loss function mapping H ×X to [−c, c] for some c ∈ R. To simplify notation, we let F := ` ◦ H := {x 7→ `(h, x) | h ∈ H}."
    }, {
      "heading" : "2.2.1 Rademacher Complexity",
      "text" : "First, we formally define Rademacher complexity, which is somewhat technical, and then provide a more intuitive notion of the quantity that it measures.\nDefinition 2 (Empirical Rademacher complexity). The empirical Rademacher complexity of F with respect to the sample S = {x1, . . . , xN} is defined as: R̂S(F) = E~σ [ supf∈F 1 N ∑N i=1 σi · f (xi) ] , where ~σ = (σ1, . . . , σN ) >, with σis independent uniform random variables taking values in {−1, 1}. The random variables σi are called Rademacher variables.\nDefinition 3 (Rademacher complexity). For any integer N ≥ 1, the Rademacher complexity of F is the expectation of the empirical Rademacher complexity over all samples of size N drawn according to D, i.e. RN (F) = ES∼DN [ R̂S(F) ] .\nIntuitively, the supremum measures, for a given sample S and Rademacher vector ~σ, the maximum correlation between f(xi) and σi over all f ∈ F . Taking the expectation over ~σ, we can then say that the empirical Rademacher complexity of F measures the ability of functions from F (when applied to a fixed sample S) to fit random noise. The Rademacher complexity of F therefore measures the expected noise-fitting-ability of F over all data sets S ∈ XN that could be drawn according to the distribution D.\nWe are able to derive strong sample complexity bounds by using Rademacher complexity. For example, given a sample S of size N , for any f ∈ F , we can bound the difference between the average value of f over S and the expected value of f with respect to D. Formally, with probability at least 1− δ, for all f ∈ F ,\nE x∼D [f(x)]− 1 N N∑ i=1 f (xi) ≤ 2RN (F) + c √ 2 ln(2/δ) N . (1)\nMoreover, for a sample S, suppose ĥ ∈ H is the hypothesis that minimizes average loss over S and h∗ is the hypothesis that minimizes expected loss with respect to the distribution D. Then recalling that F := ` ◦ H, we can guarantee that with probability at least 1− δ,\nE x∼D\n[ ` ( ĥ, x )] − E x∼D [` (h∗, x)] ≤ 2R̂S(F) + 5c √ 2 ln(8/δ) N ."
    }, {
      "heading" : "2.2.2 Pseudo-Dimension",
      "text" : "The pseudo-dimension of a class of functions F is another means of analyzing the complexity of F , and thereby deriving useful sample complexity bounds. To define pseudo-dimension, let S = {x1, . . . , xN} be a sample drawn from D and let ( z1, . . . , zN ) ∈ RN be a set of targets. We say\nthat ( z1, . . . , zN ) witnesses the shattering of S by F if for all T ⊆ S, there exists some function fT ∈ F such that for all xi ∈ T , fT (xi) ≤ zi and for all xi 6∈ T , fT (xi) > zi. If there exists some ~r that witnesses the shattering of S by F , then we say that S is shatterable by F . Finally, the pseudo-dimension dF of F is the size of the largest set that is shatterable by F .4\nBy bounding the pseudo-dimension of a class of functions, we can then bound the number of samples N required to ensure that the average value of a function over the sample is close to its expected value with respect to D.\nTheorem 5 (e.g. [Mohri et al., 2012]). Let F be a family of real-valued functions such that Pdim(F) = dF and that every f ∈ F has a range bounded by c. Then, for any δ > 0, with probability at least 1− δ over the choice of a sample S of size N , the following inequality holds for all f ∈ F :\nE x∼D [f(x)] ≤ 1 N ∑ x∈S f(x) + c\n√ 2d log eNdF\nN + c √ log 1δ 2N .\nAs will be exemplified in the present paper, it can be more natural to derive sample complexity results via either pseudo-dimension or Rademacher complexity depending on the structure of the function class. Although the two measurements seem far removed, they can be connected both conceptually and mathematically through the learning theoretic concept of covering numbers. In particular, R̂S(F) = Õ (√ dF/N ) . For completeness, we describe this connection in more detail in Appendix B."
    }, {
      "heading" : "3 The Sample Complexity of AMA Revenue Maximization",
      "text" : "We begin with the most general family in the CA hierarchy, affine maximizer auctions. In Section 3.1, we bound the Rademacher complexity of the class of n-bidder, m-item AMA revenue functions F . We set our loss function to be ` (revA, ~v) = −revA (~v) for any revA ∈ F and any vector of bidder valuations ~v. Therefore, the empirical loss minimizer is the revenue function of the auction with the maximum revenue over the sample S and the revenue function with the smallest expected loss corresponds to the best auction with respect to the underlying distribution. By bounding the sample complexity of uniform convergence N over the class of AMAs, we may guarantee that if\nS = { ~v1, . . . , ~vN ′ } is a set of samples drawn from the underlying distribution D of size at least N ,\nthen with probability at least 1− δ, for any AMA A, ∣∣∣ 1N ′ ∑N ′i=1 revA (~vi)− E~v∼D [revA (~v)]∣∣∣ < ."
    }, {
      "heading" : "3.1 Upper Bounds on Sample Complexity for AMAs, VVCAs, and λ-Auctions",
      "text" : "The AMA revenue function, defined in Section 2, can be summarized as a multi-stage optimization procedure: determine the weighted-optimal allocation and then compute the n different payments, each of which requires a separate optimization procedure. In this way, the class of AMA revenue\n4Note that the pseudo-dimension of F is simply the VC dimension of the set of “below-the-graph” indicator functions BF = {(x, z) 7→ sgn (f(x)− z) | f ∈ F} [Anthony and Bartlett, 2009].\nfunctions is unlike the well-understood, commonly found function classes in machine learning contexts. Luckily, we are able to decompose the revenue functions into small components, each of which is easier to analyze on its own, and then combine our results to prove the following theorem about this class of revenue functions as a whole. Theorem 6. Let F be the set of n-bidder, m-item AMA revenue functions revA such that A =( w1, . . . , wn, λ1, . . . , λ(n+1)m ) , Hw ≤ |wi| ≤ Hw, |λi| ≤ Hλ. Then\nRN (F) = O\n( nm+2 (HwHv +Hλ)\nHw\n√ m log n\nN\n( nĤv (nHw +Hλ)\nHw + √ nm logN\n)) ,\nwhere Ĥv = max {Hv, 1}.\nProof. First, we describe how we split each revenue function into smaller, easier to analyze atoms, which together allow us to bound the Rademacher complexity of the class of AMA revenue functions. To this end, it is well-known (e.g. [Mohri et al., 2012]) that if every function f in a class F can be written as the summation of two functions g and h from classes G and H, respectively, then RN (F) ≤ RN (G) +RN (H). Therefore, we split each revenue function into n+ 1 components such that the sum of these components equals the revenue function.\nWith this objective in mind, let ~o∗A(~v) = argmax~oi∈O {∑n j=1wjvj (oi,j) + λi } and φA,−j(~v) =\nmax~oi∈O {∑ 6̀=j w`v` (oi,`) + λi } . Then we can write\nrevA(~v) = n∑ j=1 1 wj φA,−j(~v)− (n+1)m∑ i=1  n∑ j=1 1 wj ∑ `6=j w`v`(oi,`) + λi 1~oi=~o∗A(~v). We can now split revA into n+ 1 simpler functions: revA,j(~v) =\n1 wj φA,−j(~v) for j ∈ [n] and\nrevA,n+1(~v) = − (n+1)m∑ i=1  n∑ j=1 1 wj ∑ ` 6=j w`v` (oi,`) + λi 1~oi=~o∗A(~v), so revA(~v) = ∑n+1 j=1 revA,j(~v). Intuitively, for j ∈ [n], revA,j is a weighted version of what the social welfare would be if Bidder j had not participated in the auction, whereas revA,n+1(~v) measures the amount of revenue subtracted to ensure that the resulting auction is strategy-proof.\nAs to be expected, bounding the Rademacher complexity of each smaller class of functions Lj = { revA,j | ( w1, . . . , wn, λ1, . . . , λ(n+1)m ) , Hw ≤ |wi| ≤ Hw, |λi| ≤ Hλ } for j ∈ [n+ 1] is simpler than bounding the Rademacher complexity the class of revenue functions itself and, if F is the set of all n-bidder, m-item AMA revenue functions, then RN (F) ≤ ∑n+1 j=1 RN (Lj). In Lemma 6 and Lemma 7 of Section C, we obtain bounds on RN (Lj) for j ∈ [n+ 1] which lead us to our bound on RN (F).\nUsing these tools, we are now ready to derive the proof of the main sample complexity result stated in Theorem 1 in the introduction.\nTheorem 1. The sample complexity of uniform convergence over the classes of n-bidder, m-item AMAs, VVCAs, and λ-Auctions is\nN = Õ\n([ U\nnm √ m ( U + nm/2 )]2) .\nMoreover, for λ-Auctions, N = Ω (nm) and for VVCAs, N = Ω (2m).\nProof. For the upper bound, we bound the right-hand-side of Equation 1 by , using the bound on RN (F) from Theorem 6, and solve for N , using the well-known inequality lnx ≤ αx− lnα− 1 for all x, α > 0. We also use the fact that if U is the maximum revenue achievable by an AMA in the setting at hand, then we may write U = nHw (nHwHv +Hλ). The lower bounds follow from Theorem 8 and 9."
    }, {
      "heading" : "3.2 Lower Bound on Sample Complexity for λ-Auctions",
      "text" : "In this section, we show that it is not possible to learn over the set of λ-auction revenue functions under an arbitrary distribution with subexponential sample complexity. Since λ-auctions are a subset of AMAs, this lower bound applies to AMAs as well. In particular, we prove Theorem 8, which states that no algorithm can learn over the class of n-bidder, m-item λ-auction revenue functions with sample complexity o (nm). This holds even when the bidders’ valuation functions are additive.\nTo prove Theorem 8, we construct a set V of n-bidder, m-item valuation functions taking values in {0, 1} where, under each valuation function, each bidder is interested in a specific subset of items, and these subsets are all pairwise disjoint. Moreover, |V | = nm − n. The high level idea is to show that for any subset H of V , there exists a λ-auction that has high revenue over valuation functions in H, but low revenue on the valuation functions in V \\H. Theorem 7 describes V in more detail. Now suppose that the distribution over the bidders’ valuation functions is the uniform distribution over V . This means that if a learning algorithm’s input samples consist of only a small subset of V , then we cannot guarantee that any output revenue function will achieve average revenue over the sample which is close to its expected revenue over the distribution, as we require. This immediately implies hardness for learning over the uniform distribution on V . See Theorem 8 for the formal proof.\nWe now present Theorem 7, wherein we describe the set V of valuation functions which we will use to prove Theorem 8.\nTheorem 7. For any n,m ≥ 2 and any γ ∈ (0, 1), there exists a set of N = nm − n n-bidder, m-item additive valuation functions V = { ~v1, . . . , ~vN } such that for any H ⊆ V , there exists a λ-auction AH with revenue 0 on ~v i if ~vi 6∈ H and revenue at least 2− 2γ on ~vi otherwise.\nProof. We define the set V = { ~v1, . . . , ~vN } of n-bidder, m-item additive valuation functions, where\n~vj = ( vj1({1}), . . . , v j 1({m}), . . . , v j n({1}) . . . , vjn({m}) ) , with N = nm − n. Recall that every allocation vector ~oj is written as (oj,1, . . . , oj,n) where oj,1, . . . , oj,n are disjoint subsets of the m items being auctioned. First, let ôj be the allocation where Bidder j receives all m items. Next, let õ1, . . . , õN be a fixed ordering of the n\nm − n allocations where all m goods are allocated except {ô1, . . . , ôn}. Let the bundles allocated to the n bidders in õ` be (õ`,1, . . . , õ`,n) and let N` be the set of bidders who are allocated some item in allocation õ`. In other words, N` = {j | õ`,j 6= ∅}. For a sanity check, notice that ⋃n i=1 õ`,i is the grand bundle.\nWe will now define the valuation vectors { ~v1, . . . , ~vN } in terms of this set of special allocations\n{õ1, . . . , õN}. Specifically, we define ~v` for ` ∈ [N ] as follows. If i 6∈ N` (i.e. õ`,j = ∅), set v`i ({j}) = 0 for all j ∈ [m]. Otherwise, set\nv`i ({j}) = { 0 if j 6∈ õ`,i 1 if j ∈ õ`,i .\nWe proceed to prove that for any subset H ⊆ V , there exists a λ-auction with 0 revenue on all valuation functions in V \\H and at least 2− 2γ revenue on all valuation functions in H. To define\nthis λ-auction, we set the λ terms such that\nλ (~oj) =\n{ 0 if ~oj = õ` for some ~v\n` ∈ H 1− γ otherwise .\nLemma 1. If ~v` ∈ H, then the revenue on ~v` is at least 2− 2γ.\nProof of Lemma 1. First, note that ∑n\ni=1 v ` i (õ`,i) + λ (õ`) = m, and for all allocations ~oj 6= õ`,∑n\ni=1 v ` i (oj,i) + λ (~oj) ≤ m− 1 + 1− γ < m. Therefore, the λ-auction allocation is õ`.\nIn order to analyze the revenue of this λ-auction, we must understand the payments of each bidder, which means that we must investigate what the outcome of this λ-auction would be without any one bidder’s participation. To this end, suppose i ∈ N`, so Bidder i is allocated some item in õ`, i.e. õ`,i 6= ∅. Then ∑ j 6=i v ` j (õ`,j) +λ (õ`) = m−|õ`,i| because Bidder i’s valuation for the bundle õ`,i is exactly |õ`,i|. By construction, no bidder receives all m items in õ`, so we know that there exists some i′ ∈ N`, i′ 6= i. With this fact in mind, let ~o−i be the allocation where all bidders in N` are allocated the same items as they are in õ` and Bidder i receives the empty set. This is one possible allocation of the λ-auction without Bidder i’s participation, and therefore the social welfare of the other bidders will be at least as high under this allocation as it would be in the true allocation of the λ-auction without Bidder i’s participation. By construction, λ (~o−i) = 1 − γ. Therefore, ∑ ` 6=i v ` j (o−i,j) + λ (~o−i) = m − |õ`,i| + 1 − γ which means that Bidder i must pay at least (m− |õ`,i|+ 1− γ) − (m− |õ`,i|) = 1 − γ. We know that |N`| ≥ 2, i.e. there are at least 2 bidders who receive a non-empty bundle and therefore must pay at least 1 − γ, so the revenue of this λ-auction is at least 2− 2γ.\nLemma 2. If ~v` 6∈ H, then the revenue on ~v` is 0.\nProof of Lemma 2. First, note that ∑n\ni=1 v ` i (õ`,i) + λ (õ`) = m + 1 − γ, and for all allocations ~oj 6= õ`, ∑n i=1 v ` i (~oj,i) +λ (~oj) ≤ m−1 + 1−γ < m, so the λ-auction allocation is õ`. Now, suppose\ni ∈ N`. Then ∑ j 6=i v ` j (õ`,j) + λ (õ`) = m − |õ`,i| + 1 − γ. Since Bidder i is the only bidder with nonzero valuations for the items in õ`,i under ~v `, any allocation ~o−i without his participation will\nhave social welfare at most ∑\nj 6=i v ` j (o−i,j) + λ (~o−i) ≤ m− |õ`,i|+ 1− γ. Therefore, Bidder i pays\nnothing. Of course, for any Bidder i 6∈ N`, her presence in the auction makes no difference on the resulting allocation because her valuation function under ~v` is 0 on all items, so she pays nothing as well. Therefore, the revenue on ~v` is 0.\nPutting Lemmas 1 and 2 together, we have the desired result.\nWe now use Theorem 7 to prove Theorem 8.\nTheorem 8. Let ALG be an arbitrary learning algorithm that uses only a polynomial number of training samples drawn i.i.d. from the underlying distribution and produces a λ-auction. For any ∈ (0, 1), there exists a distribution D and a λ-auction A∗ such that, with probability 1 (over the draw of the set of training samples S),\n1 |S| ∑ ~v∈S revA∗ (~v)− E ~v∼D [revA∗ (~v)] > .\nProof. Let γ = 1 − and let V be the set of valuation functions proven to exist in Theorem 7 corresponding to γ (i.e. for any H ⊆ V , there exists a λ-auction AH with revenue 0 on ~v if ~v ∈ H and revenue at least 2− 2γ on ~v otherwise). Let D be the uniform distribution on V .\nSuppose that ALG uses a set S of ` ≤ nc samples, where c is a constant. Of course, S ⊆ V , so let A∗ be the λ-auction with 0 revenue on every valuation function not in the sample and revenue at least 2− 2γ on every valuation function in the sample. We know that A∗ exists due to Theorem 7.\nNotice that the average empirical revenue of A∗ on S is at least 2 − 2γ. Meanwhile, the probability, on a random draw ~v ∼ D that revA∗ (~v) is 0 is exactly the probability that ~v 6∈ S. Given that the set of training examples has measure n c\nnm−n < 1 2 , we have that\n1 |S| ∑ ~v∈S revA∗ (~v)− E ~v∼D [revA∗ (~v)] ≥ 2− 2γ − (2− 2γ) P ~v∼D [~v ∈ S]\n> 2− 2γ − (1− γ) = 1− γ = ,\nas desired."
    }, {
      "heading" : "3.3 Lower Bound on Sample Complexity for VVCAs",
      "text" : "In this section, we prove that it is not possible to learn over the set of VVCA revenue function under and arbitrary distribution with subexponential sample complexity. In particular, we prove that no algorithm can learn over the class of n-bidder, m-item VVCA revenue functions with sample complexity o (2m). This holds even when the bidders’ valuation functions are additive.\nThe format of this proof similar to that of Theorem 8. Namely, we construct a set V of n-bidder, m-item valuation functions such that |V | = 2m − 2. We then show that for any subset H of V , there exists a VVCA that has high revenue over valuation functions in H, but low revenue on the valuation functions in V \\H. The set V is described in more detail in Theorem 9. As described in Theorem 8, this immediately implies hardness for learning over the uniform distribution on V . Given the parallel proof structure, we present Theorem 9 and refer the reader to Theorem 8 to see how it implies hardness for learning.\nTheorem 9. For any m ≥ 2 and any γ ∈ (0, 1), there exists a set of N = 2m− 2 2-bidder additive valuation functions V = {~v1, . . . , ~vN} such that for any H ⊆ V , there exists a VVCA with revenue 0 on ~vi if ~vi ∈ V and revenue 1− γ on ~vi if ~vi 6∈ V .\nProof. We define the set V = {~v1, . . . , ~vN} of 2-bidder valuation functions, where ~vj = (vj1({1}), . . . , v j 1({m}), v j 2({1}) . . . , v j 2({m})), with N = 2m − 2. Recall that every allocation vector ~oj can be written as (oj,1, oj,2) where oj,1 and oj,2 are disjoint subsets of the m items being auctioned. In order to define the valuation functions in V , we define b̃1, . . . , b̃N to be a arbitrary, fixed ordering of all subsets of [m] except the empty set and the grand bundle. In other words, b̃1, . . . , b̃N is an ordering of 2\n[m] \\ {∅, [m]}. We will define each valuation function in V in terms of this ordering. In particular, let õ` = (b̃ c `, b̃`) be the allocation where Bidder 1 receives b̃ c ` and Bidder 2 receives b̃`. Finally, let ~v ` for ` ∈ [N ] be defined as follows.\nv`1({i}) = { 1 if i ∈ b̃c` 0 otherwise\nand\nv`2({i}) = { 1 if i ∈ b̃` 0 otherwise .\nClearly, if w1 = w2 = 1 and λ1(~o) = λ2(~o) = 0 for all ~o ∈ O, then the VVCA allocation on any ~v` ∈ S is the one in which Bidder 2 receives b̃c` and Bidder 1 receives b̃`. This has a social welfare of m, whereas any other allocation has a social welfare at most m− 1.\nWe claim that for any H ⊆ V , there exists a VVCA with revenue 0 on ~vi if ~vi ∈ H and revenue 1 − γ on ~vi if ~vi 6∈ H. The VVCA has bidder weights w1 = w2 = 1, and for all ~v` ∈ H, we set λ1(õ`) = c1,b̃c` = c2,b̃` = λ2(õ`) = 0. Otherwise, we set λi(~o) = (1− γ)/2 for each i ∈ {1, 2}. Lemma 3. If ~v` ∈ H, then the revenue on ~v` is 1− γ.\nProof of Lemma 3. First, note that v1(b̃ c `) + v2(b̃`) + λ1(õ`) + λ2(õ`) = m, and for all allocations ~oj 6= õ`, v1(oj,1) + v2(oj,2) +λ1(~oj) +λ2(~oj) ≤ m− 1 + 1− γ. Therefore, the VVCA allocation is õ`. However, this is neither Bidder 1 nor Bidder 2’s favorite weighted allocation, since v1(b̃ c `)+λ1(õ`) = |b̃c`| < v1([m])+c1,[m] = |b̃c`|+(1−γ)/2 and v2(b̃`)+λ2(õ`) = |b̃`| < v2([m])+c2,[m] = |b̃`|+(1−γ)/2. This follows from the fact that b̃` 6= [m] and b̃c` 6= [m] for all ` ∈ [N ], it must be that λ1([m]) = λ2([m]) = (1− γ)/2.\nSince |b̃c`| and |b̃`| are Bidder 1 and 2’s highest valuations for any allocation, respectively, and because (1 − γ)/2 is the highest value of any λ term, v1([m]) + c1,[m] and v2([m]) + c2,[m] are the maximum weighted valuation that either bidder has for any allocation under this VVCA. Therefore, the revenue of this VVCA on ~v` is |b̃`|+ |b̃c`|+ 1− γ − |b̃`| − |b̃c`| = 1− γ.\nLemma 4. If ~v` 6∈ H, then the revenue on that valuation function pair is 0.\nProof of Lemma 4. First, note that v1(b̃ c `) + v2(b̃`) + λ1(õ`) + λ2(õ`) = m + 1 − γ, and for all allocations ~oj 6= õ`, v1(oj,1) + v2(oj,2) + λ1(~oj) + λ2(~oj) ≤ m− 1 + 1− γ < m+ 1− γ, so the AMA allocation is õ`. Moreover, v1(b̃ c `)+λ1(õ`) = |b̃c`|+(1−γ)/2 ≥ v1(oj,1)+λ1(~oj) and v2(b̃`)+λ2(õ`) = |b̃`| + (1 − γ)/2 ≥ v2(oj,2) + λ2(~oj) for all allocations ~oj ∈ O. Therefore, both bidders receive one of their favorite weighted allocations, so the revenue is 0."
    }, {
      "heading" : "4 Sample Complexity of MBA Revenue Maximization",
      "text" : "Fortunately, these negative sample complexity results are not the end of the story. We do achieve polynomial sample complexity upper bounds for the important classes of mixed bundling auctions (MBAs) and mixed bundling auctions with reserve prices (MBARPs). We derive these sample complexity bounds by analyzing the pseudo-dimensions of these classes of auctions. In this section, we present our results in increasing complexity, beginning with the class of n-bidder, m-item MBAs, which we show has a pseudo-dimension of 2. We build on the proof of this result to show that the class of n-bidder, m-item MBARPs has a pseudo-dimension of O ( m3 log n ) .\nWe note that when we analyze the class of MBARPs, we assume additive reserve prices, rather than bundle reserve prices. In other words, each item has its own reserve price, and the reserve price of a bundle is the sum of its components’ reserve prices, as opposed to each bundle having its own reserve price. We have good reason to make this restriction; in Section 4.2, we prove that an exponential number of samples are required to learn over the class of MBARPs with bundle reserve prices.\nBefore we prove our sample complexity results, we fix some notation. For any c-MBA, let revc (~v) be its revenue on ~v, which is determined in the exact same way as the general AMA revenue function with the λ terms set as described in Section 2.\nWe will use the following result regarding the structure of revc (~v) in order to derive our pseudodimension results.\nLemma 5. There exists c∗ ∈ [0,∞) such that rev~v(c) is non-decreasing on the interval [0, c∗] and non-increasing on the interval (c∗,∞).\nProof. We will show that rev~v can be decomposed into simple components, each of which can be easily analyzed on its own, and by combining these analyses, we prove the lemma statement. To this end, recall that under the VCG mechanism, each winning bidder pays her bid minus a “rebate” equal to the increase in welfare attributable to her presence in the auction. In a cMBA, each winning bidder pays the boosted version of this amount. In other words, suppose ~o∗ is the resulting allocation of a certain c-MBA A and ~o−i is the boosted social-welfare maximizing allocation without Bidder i’s participation. More explicitly, ~o∗ = max~oj { ∑n i=1 vi (oj,i) + λ (~oj)}\nand ~o−i = max~oj {∑ k 6=i vk (oj,k) + λ (~oj) } , where λ (~oj) is set according to the MBA allocation boosting rule for all ~oj . Then Bidder i pays\npi,~v (c) = vi (o ∗ i )−  n∑ j=1 vj ( o∗j ) + λ (~o∗)− ∑ j 6=i vj (o−i,j) + λ (~o−i)  , where c is the parameter of the c-MBA, factored into the λ terms. This means that\nrev~v(c) = n∑ i=1 pi,~v (c) = (1− n) n∑ i=1 vi (o ∗ i )− nλ (~o∗) + n∑ i=1 ∑ j 6=i vj (o−i,j) + λ (~o−i) .\nThe revenue function can be split into n+ 1 functions:\nfi,~v(c) = ∑ j 6=i vj (o−i,j) + λ (~o−i) for i ∈ {1, . . . , n}\nand\ng~v(c) = (1− n) n∑ i=1 vi (o ∗ i )− nλ (~v∗) .\nWe claim that fi,~v(c) is continuous for all i, whereas g~v(c) has at most one discontinuity. This means that rev~v(c) = ∑n i=1 fi,~v(c) + g~v(c) has at most one discontinuity as well. Moreover, the\nslope of ∑n\ni=1 fi,~v(c) is between zero and n, whereas the slope of g~v(c) is zero until its discontinuity, and then is −n. Therefore, the slope of rev~v(c) is at least zero before its discontinuity and at most zero after its discontinuity. This is enough to prove the lemma statement.\nTo see why these properties are true for the functions fi,~v(c), first let ~o 1 −i be the VCG allocation\nwithout Bidder i’s participation. In other words, ~o1−i = max~oj {∑ k 6=i vk (oj,k) } . If one bidder is allocated the grand bundle in outcome ~o1−i, then this allocation will only be more valuable as c grows, so ~o1−i = max~oj {∑ k 6=i vk (oj,k) + λ (~oj)\n} for all values of c, which means that fi,~v(c) =∑\nj 6=i vj ( o1−i,j ) + λ ( ~o1−i ) = ∑ j 6=i vj ( o1−i,j ) + c for all values of c as well. Clearly, in this case,\nfi,~v(c) is increasing and continuous. Otherwise, there exists some value ci such that∑ j 6=i vj ( o1−i,j ) + λ ( ~o1−i ) = ∑ j 6=i vj ( o1−i,j ) ≥ max k 6=i {vk ([m])}+ c if c ≤ ci\n∑ j 6=i vj ( o1−i,j ) < max k 6=i {vk ([m])}+ c if c > ci.\nThis means that ~o1−i is the allocation of the c-MBA without Bidder i’s participation for c ≤ ci, and the allocation of the c-MBA without Bidder i’s participation for c > ci is the one where the highest bidder for the grand bundle (excluding Bidder i) wins the grand bundle. Therefore,\nfi,~v(c) =\n{∑ j 6=i vj ( o1−i,j ) if c ≤ ci\nmaxk 6=i {vk ([m])}+ c if c > ci.\nNotice that ∑\nj 6=i vj ( o1−i,j ) = maxk 6=i {vk ([m])} + ci, so fi,~v(c) is continuous. Finally, it is clear\nthat the slope of each fi,~v(c) is between 0 and 1, so the slope of ∑n\ni=1 fi,~v(c) is between 0 and n. Similarly, let ~o1 be the allocation of the VCG mechanism run on ~v. Then there exists some c∗ such that ~o1 is the allocation of the c-MBA for c ≤ c∗ and the allocation of the c-MBA for c > ci is the one where the highest bidder for the grand bundle wins the grand bundle. More explicitly,\nn∑ i=1 vi ( o1i ) + λ ( ~o1 ) = n∑ i=1 vi ( o1i ) ≥ max {vk ([m])}+ c if c ≤ c∗\nn∑ i=1 vi ( o1i ) < max {vk ([m])}+ c if c > c∗.\nTherefore,\ng~v(c) =\n{ (1− n) ∑n i=1 vi ( o1i )\nif c ≤ c∗\n(1− n) max {vk ([m])} − nc if c > c∗.\nTherefore, g~v(c) has at most one discontinuity, which falls at c ∗. Moreover, the slope of g~v(c) is 0 for c < c∗ and −n for c > c∗. As described, these properties of fi,~v(c) and g~v(c) are enough to show that the lemma statement holds.\nThe form of rev~v(c) as described in Lemma 5 is depicted in Figure 2.\nTheorem 10. The pseudo-dimension of the class of n-bidder, m-item MBAs is 2.\nProof. First, we show that the pseudo-dimension of the class of n-bidder, m-item MBAs is at most 2. Let S = { ~v1, . . . , ~vN } of size N be a set of n-bidder valuation functions that can be shattered by a set C of 2N MBAs. This means that there exist N witnesses z1, . . . , zN such that each MBA in C induces a binary labeling of the samples ~vj of S (whether the revenue of the MBA on ~vj is at least zj or strictly less than zj). Since S is shatterable, we can thus label S in every possible way using MBAs in C.\nNow, fix one sample ~vi ∈ S and consider rev~vi(c). From Lemma 5, we know that there exists c∗i ∈ [0,∞), such that rev~vi(c) is non-decreasing on the interval [0, c∗i ] and non-increasing on the interval (c∗i ,∞). Therefore, there exist two thresholds t1i ∈ [0, c∗i ] and t2i ∈ (c∗i ,∞) ∪ {∞} such that rev~vi(c) is below its threshold for c ∈ [0, t1i ), above its threshold for c ∈ (t1i , t2i ), and below its threshold for c ∈ (t2i ,∞). Now, merge these thresholds for all N samples on the real line and consider the interval (t1, t2) between two adjacent thresholds. The binary labeling of the samples in S on this interval is fixed. In other words, for any sample ~vj ∈ S, rev~vj (c) is either at least zj or strictly less than zj for all c ∈ (t1, t2). There are at most 2N + 1 intervals between adjacent thresholds, so at most 2N + 1 different binary labelings of S. Since we assumed S is shatterable, it must be that 2N ≤ 2N + 1, so N ≤ 2.\nFinally, we show that the pseudo-dimension of the class of n-bidder, m-item MBAs is at least 2 by constructing a set S = { ~v1, ~v2 } that can be shattered by the set of MBAs. To construct this sample S, let\nv11 (bi) = v 1 2 (bi) = { 0 if |bi| < bm/2c 3 if bm/2c ≤ |bi| and v21 (bi) = v 2 2 (bi) =  0 if |bi| < bm/2c 3 if bm/2c ≤ |bi| < m 4 if |bi| = m.\nFinally, let Bidders 3 through n have all-zero valuations in both ~v1 and ~v2. Now, let z1 = 3 and z2 = 4. We define four MBAs parameterized by the coefficients c1 = 0, c2 = 1.5, c3 = 2.5, c4 = 2. It is easy to check that this set of MBAs shatters S, witnessed by z1 and z2. For example, see Table 1.\nWe may now use this result to prove Theorem 3.\nTheorem 3. The sample complexity of uniform convergence over the class of n-bidder, m-item MBAs is\nN = O\n(( U )2( log U + log 1\nδ\n)) .\nProof. This follows from Theorem 5 and Theorem 10."
    }, {
      "heading" : "4.1 Mixed Bundling Auctions with Reserve Prices (MBARPs)",
      "text" : "In Section 4.2, we show that exponentially-many samples are required to learn an optimal setting of the MBA parameter c and reserve prices if we allow for bundle-specific reserve prices. Therefore, we restrict our attention to item-specific reserve prices. In this case, each MBARP is parameterized by m+ 1 values (c, r1, . . . , rm), where ri is the reserve price for the i\nth good. For a fixed valuation function vector ~v = (v1 (b1) , . . . , v1 (b2m) , . . . , vn (b1) , . . . , vn (b2m)), we can analyze the MBARP revenue function on ~v as a mapping rev~v : Rm+1 → R, where rev~v (c, r1, . . . , rm) is the revenue of the MBARP parameterized by (c, r1, . . . , rm) on ~v.\nTheorem 11. The psuedo-dimension of the class of n-bidder, m-item MBARPs with item-specific reserve prices is O ( m3 log n ) .\nProof. Let S = { ~v1, . . . , ~vN } of size N be a set of n-bidder valuation function samples that can be shattered by a set C of 2N MBARPs. This means that there exist N witnesses z1, . . . , zN such that each MBARP in C induces a binary labeling of the samples ~vj in S (whether the revenue of the MBARP on ~vj is greater than zj or at most zj). Since S is shatterable, we can thus label S in every possible way using MBARPs in C.\nThis proof is similar to the proof of Theorem 10, where we split the real line into a set of intervals I such that for any I ∈ I, the binary labeling of S by the c-MBA revenue function was fixed for all c ∈ I. In the case of MBARPs, however, the domain is Rm+1, so we cannot split the domain into intervals in the same way. Instead, we show that we can split the domain into cells such that the binary labeling of S by the MBARP revenue function is fixed as we range over parameters in a single cell. In this way, we show that N = O ( m3 log n ) .\nNow, fix ~vt ∈ S. First, for each T ⊆ [m], let OT be the set of allocations where exactly the elements of T are allocated, and let\n~oT = argmax ~o∈OT { n∑ i=1 vti (oi) } .\nNotice that regardless of the reserve prices, if T comprises of the items allocated in the allocation of an MBARP, then ~oT will be the allocation. After all, if (r1, . . . , rm) are the reserve prices of an arbitrary MBARP, then it will always be the case that\nn∑ i=1 vti ( oTi ) + ∑ j 6∈T rj ≥ n∑ i=1 vti ( o′i ) + ∑ j 6∈T rj\nfor any allocation ~o′ ∈ OT by definition of ~oT . Now, consider an MBARP parameterized by (c, r1, . . . , rm). The allocation will be\n~oT = argmax  n∑ i=1 vti ( o [m] i ) + c,  n∑ i=1 vti ( oTi ) + ∑ j 6∈T rj  T 6=[m]  . For any T ⊆ [m], let R~vtT be the subset of Rm+1 such that if an MBARP is parameterized by\n(c, r1, . . . , rm) ∈ R~v t T , then the allocation of the MBARP on ~v t is ~oT . This means that if T 6= [m]\nn∑ i=1 vti ( oTi ) + ∑ j 6∈T rj ≥ n∑ i=1 vti ( oT ′ i ) + ∑ j 6∈T ′ rj ∀T ′ 6∈ {T, [m]} and\nn∑ i=1 vti ( oTi ) + ∑ j 6∈T rj ≥ n∑ i=1 vti ( o [m] i ) + c.\nIn other words, (c, r1, . . . , rm) ∈ R~v t T if and only if it falls in the intersection of 2 m − 1 halfspaces:∑\nj 6∈T rj − ∑ j 6∈T ′ rj ≥ n∑ i=1 vti ( oT ′ i ) − vti ( oTi )\n∀T ′ 6∈ {T, [m]}\n∑ j 6∈T rj − c ≥ n∑ i=1 vti ( o [m] i ) − vti ( oTi ) .\nSimilarly, if T = [m], it is not hard to see that we can write R~v t T as the intersection of 2 m − 1 halfspaces. We can also analyze the allocation of an MBARP parameterized by (c, r1, . . . , rm) without Bidder i’s participation for any i ∈ [n], which we need to do in order to analyze the revenue function. To this end, for all T ⊆ [m], let OT−i be the set of all allocations where exactly the elements of T are allocated to all of the bidders except i, and let\n~oT−i = argmax ~o∈OT−i ∑ j 6=i vtj (oj)  . Again, regardless of the reserve prices, if T consists of the items allocated by an MBARP without Bidder i’s participation, then ~oT−i will be the allocation. Now, for an MBARP parameterized by (c, r1, . . . , rm) without Bidder i’s participation, the allocation will be\n~oT−i = argmax  ∑ j 6=i vtj ( o [m]−i j ) + c, ∑ j 6=i vtj ( o T−i j ) + ∑ `6∈T r`  T 6=[m]  . For any T ⊆ [m], let R~vtT−i be the subset of R m+1 such that if an MBARP is parameterized by\n(c, r1, . . . , rm) ∈ R~v t\nT−i , then the allocation of the MBARP without Bidder i’s partitipation on ~v is\n~oT−i . This means that if T 6= [m], then just as before, (c, r1, . . . , rm) ∈ R~v t\nT−i if and only if it falls in\nthe intersection of 2m − 1 halfspaces:∑ 6̀∈T r` − ∑ 6̀∈T ′ r` ≥ ∑ j 6=i vj ( o T ′−i j ) − ∑ j 6=i vj ( o T−i j ) ∀T ′ 6∈ {T, [m]}\n∑ 6̀∈T r` − c ≥ ∑ j 6=i vj ( o [m]−i j ) − ∑ j 6=i vj ( o T−i j ) .\nSimilarly, if T = [m], we can write R~vT−i as the intersection of 2 m − 1 halfspaces. Clearly, { R~v t\nT } T⊆[m] partition Rm+1, since there will always be some allocation of an MBARP\nparameterized by an arbitrary point in Rm+1. Similarly, { R~v t\nT−i } T⊆[m] partition Rm+1 for every\ni ∈ [n]. Now, suppose\n(c, r1, . . . , rm) ∈ R~v t\nT 0\n⋂ R~v t\nT 1−1\n⋂ · · · ⋂ R~v t\nTn−n = R\nfor some T 0, T 1, . . . , Tn ⊆ [m]. We show that rev~vt (c, r1, . . . , rm) is linear on R by splitting the analysis into four cases.\n1. If T 0, T 1, . . . , Tn 6= [m] we can write\nrev~vt (c, r1, . . . , rm) = n∑ i=1 ∑ j 6=i ( vtj ( o T i−i j ) − vtj ( oT 0 j )) + ∑ `6∈T i r` − ∑ ` 6∈T 0 r`  . (2) 2. If T 0 6= [m] and T i = [m] for some i ∈ {1, . . . , n}, then we replace the summand of Equation 2\nindexed by i with ∑ j 6=i ( vtj ( o T i−i j ) − vtj ( oT 0 j )) + c− ∑ `6∈T 0 r`.\n3. If T 0 = [m] and T1, . . . , Tn 6= [m], then\nrev~vt (c, r1, . . . , rm) = n∑ i=1 ∑ j 6=i ( vtj ( o T i−i j ) − vtj ( oT 0 j )) + ∑ ` 6∈T i r` − c  . (3) 4. If T 0 = [m] and T i = [m] for some i ∈ {1, . . . , n}, then we replace the summand of Equation 3\nindexed by i with ∑ j 6=i ( vtj ( o T i−i j ) − vtj ( oT 0 j )) .\nIn all of these cases, rev~vt (c, r1, . . . , rm) is a linear function over\n(c, r1, . . . , rm) ∈ R~v t\nT 0\n⋂ R~v t\nT 1−1\n⋂ · · · ⋂ R~v t\nTn−n = R.\nTo summarize, we fixed ~vt ∈ S and introduced n+1 partitions of Rm+1. Each partition is made up of 2m cells and each cell is defined as the intersection of 2m − 1 halfspaces. If we restrict the domain of the revenue function to the intersection of any n + 1 cells, one from each of the n + 1 partitions, then the revenue function on that restricted domain is linear and therefore, there is one subregion where rev~vt (c, r1, . . . , rm) exceeds its target revenue and one subregion where it does not.\nOne generous upper bound on the number of different regions induced by taking the intersection of any n+ 1 cells, one from each of the n+ 1 partitions, is the number of different regions induced by the (n + 1)2m (2m − 1) total hyperplanes. This is at most (m + 1) ((n+ 1)2m (2m − 1))m+1 ≤ (m+ 1) ((n+ 1)4m)m+1 because the number of regions induced by k hyperplanes in Rd is at most∑d\ni=1 ( k i ) ≤ dkd. Again, if we restrict the domain of the revenue function to any of these induced regions, the revenue function will be linear. As we saw in cases (1)-(4) of our case analysis, depending on the region, the revenue function will take a specific linear form. For a given region R, denote this specific linear form of the revenue function on by R as rev~vj |R. With this in mind, we define one more hyperplane per region: rev~vj |R > zj . In total, this contributes at most (m + 1) ((n+ 1)4m)m+1 more hyperplanes, since this is the maximum number of induced regions on Rm+1. We are therefore left with at most α = (m+ 1) ((n+ 1)4m)m+1 + (n+ 1)2m (2m − 1) = O ( mnm8m 2 )\ntotal hyperplanes per valuation vector function ~vj ∈ S. If we merge all of the N sets of α hyperplanes, Rm+1 will be split into at most (m+ 1)(Nα)m+1 regions, each of which induces a specific binary labeling of S (whether or not ~vj exceeds its target revenue). Therefore, it must be that 2N ≤ (m + 1)(Nα)m+1, so N = O(m logα) = O ( m3 log n ) .\nWe may now use this result to prove Theorem 2.\nTheorem 2. The sample complexity of uniform convergence over the class of n-bidder, m-item MBARPs with item-specific reserve prices is\nN = O\n(( U )2( m3 log n log U + log 1\nδ\n)) .\nProof. This follows from Theorem 5 and Theorem 11."
    }, {
      "heading" : "4.2 Bundle Reserve Prices Lower Bound",
      "text" : "In this section, we justify our choice to concentrate on MBARPs with item-specific reserve prices. In particular, we prove that no algorithm can learn over the class of n-bidder, m-item MBARP revenue functions with bundle-specific reserve prices using sample complexity o (4m/ √ m).\nAs in the proof of Theorem 8, we construct a special set V of valuation functions. In this case, V is a set of single-bidder, m-item valuation functions and |V | = Ω (4m/ √ m). We then show that for any subset H of V , there exists a setting of the bundle reserve prices that has high revenue over valuation functions in H, but low revenue on the valuation functions in V \\H. We describe V more formally in Theorem 12. As we show in Remark 1, this construction can trivially be extended to a set of n-bidder, m-item valuation functions of the same size. Then, as in Theorem 8, this immediately implies hardness for learning over the uniform distribution on V . We provide the construction of V and, given the parallel proof structure, we refer the reader to Theorem 8 to see how this implies hardness of learning.\nWe now present the construction of the set of valuation functions V . Theorem 12. For any m ≥ 2, there exists a set of N = Ω (\n4m√ m\n) single-bidder, m-item valuation\nfunction vectors V = { ~v1, . . . , ~vN } such that for any H ⊆ V , there exists a set of monotone bundle reserve prices such that the resulting auction has revenue 0 on ~vi if ~vi ∈ H and revenue 1 − γ on ~vi if ~vi 6∈ H, for any γ ∈ (0, 1).\nProof. We define the set V = { ~v1, . . . , ~vN } of single-bidder valuation functions, where ~vj =(\nvj1 (b1) , . . . , v j 1 (b2m) ) . Assume for now that m is even, and let b̃1, . . . , b̃N be a fixed ordering\nof the subsets of 2[m] of size m/2, so N = Ω (\n4m√ m\n) . Let ~v` for ` ∈ [N ] be defined as follows.\nv`1 (bi) =  0 if |bi| < m/2 1 if bi = b̃`\n0 if |bi| = m/2 and bi 6= b̃` 1 if |bi| > m/2\n.\nWe claim that for any H ⊆ V , there exists a set of monotone bundle reserve prices {r (b1) , . . . , r (b2m)} such that the resulting auction has 0 revenue on all valuation functions ~vi such that ~vi 6∈ H and 1− γ revenue on all valuation functions ~vi ∈ H. The reserve prices are defined as follows:\nv0 (bi) = r (bi) =  0 if |bi| < m/2 1− γ if bi = b̃c` and ~v` 6∈ H 0 if bi = b̃ c ` and ~v\n` ∈ H 1− γ |bi| > m/2\n.\nRegardless of whether or not ~v` is in H, ( b̃`, b̃ c ` ) = argmax~o∈O { v0 (o0) + v ` 1 (o1) } and 1 − γ =\nmaxbi∈2[m] {v0 (bi)}. Therefore, Bidder 1 pays\n1− γ − v0 ( b̃c` ) = { 1− γ if ~v` ∈ H 0 if ~v` 6∈ H .\nRemark 1. For any m ≥ 2, n ≥ 1, there exists a set of N = Ω (4m/ √ m) n-bidder valuation function vectors V = { ~v1, . . . , ~vN } such that for any H ⊆ V , there exists a set of monotone bundle reserve prices such that the resulting auction has revenue 0 on ~vi if ~vi 6∈ H and revenue 1 − on ~vi if ~vi ∈ H.\nThis follows simply by setting v`1 as in the proof of Theorem 12 and setting v ` j (bi) = 0 for all\n` ∈ [N ], i ∈ [2m] , j 6= 1."
    }, {
      "heading" : "5 Conclusion",
      "text" : "In this paper, we proved strong bounds on the sample complexity of uniform convergence for the well-studied and standard auction families that constitute the hierarchy of deterministic combinatorial auctions. We thereby answered a crucial question in the study of (automated) mechanism design: how to relate the performance of the mechanisms in the search space over the input samples to their expectation over the underlying—unknown—distribution. Specifically, for a fixed class of auctions, we determine the sample complexity necessary to ensure that with high probability, for any auction in that class, the average revenue over the sample is close to the expected revenue with respect to the underlying, unknown distribution over bidders’ valuations. Our bounds apply to any algorithm that finds an optimal or approximately optimal auction over an input sample, and therefore to any automated mechanism design algorithm. Moreover, our results and analyses are of interest from a learning theoretic perspective because the function classes which make up the hierarchy of deterministic combinatorial auctions diverge significantly from well-understood hypothesis classes typically found in machine learning.\nAcknowledgments. This work was supported in part by NSF grants CCF-1451177, CCF1422910, a Sloan Research Fellowship, and a Microsoft Research Faculty Fellowship."
    }, {
      "heading" : "A Proofs from Section 1",
      "text" : "Proof of Theorem 4. First, let = 2RN (H) + c √ 2 ln(4/δ) N . For ease of notation, for any h ∈ H, let LS(h) = 1 N ∑N i=1 ` (h, xi) and LD(h) = Ex∼D[`(h, x)]. Suppose that h∗ is the optimal hypothesis in H (i.e. it minimizes LD(h), the expected loss over the distribution D), ĥ is the empirical risk minimizer (i.e. it minimizes LS(h), the average loss over the sample S), and h̃ is a hypothesis such that LS ( h̃ ) − LS ( ĥ ) ≤ ρ for some ρ > 0. Then with probability at least 1− δ,\nLD ( h̃ ) − ≤ LS ( h̃ )\n(4) ≤ LS ( ĥ ) + ρ (5)\n≤ LS (h∗) + ρ (6) ≤ LD (h∗) + c √ 2 ln(4/δ)\n2N + ρ. (7)\nInequality 4 follows from Equation standard Rademacher complexity uniform convergence bounds: with probability at least 1−δ/2, LD ( h̃ ) −LS ( h̃ ) ≤ (see, for example, [Shalev-Shwartz and Ben-\nDavid, 2014]). Inequality 5 follows from the fact that LS ( h̃ ) ≤ LS ( ĥ ) + ρ. Inequality 6 follows\nbecause ĥ is the empirical risk minimizer (i.e. it minimizes LS(h)). Finally, inequality 7 is a result, again, of Hoeffding’s inequality, which guarantees that with probability at least 1 − δ/2, LS (h ∗) ≤ LD (h∗) + c √ 2 ln(4/δ) 2N .\nRearranging, we get that\nLD ( h̃ ) − LD (h∗) ≤ + c √ 2 ln(4/δ)\n2N + ρ,\nas claimed. Next, suppose that h̃ is a hypothesis such that LS ( h̃ ) ≤ (1 + α)LS ( ĥ ) . We similarly can deduce that with probability at least 1− δ,\nLD ( h̃ ) − ≤ LS ( h̃ )\n(8) ≤ (1 + α)LS ( ĥ ) (9)\n≤ (1 + α)LS (h∗) (10)\n≤ (1 + α) ( LD (h ∗) + c √ 2 ln(4/δ)\n2N\n) . (11)\nRearranging, we get that\nLD ( h̃ ) ≤ + (1 + α)LD (h∗) + (1 + α)c √ 2 ln(4/δ)\n2N ,\nwhich means that\nLD ( h̃ ) − LD (h∗) ≤ + (1 + α)c √ 2 ln(4/δ)\n2N + αLD (h\n∗) ,\nas desired. We remark that inequalities 4-11 could be tight in the worst case, so both bounds are tight."
    }, {
      "heading" : "B Connection between pseudo-dimension and Rademacher com-",
      "text" : "plexity\nIn order to show that R̂S(F) = Õ (√ dF/N ) , we connect Rademacher complexity to pseudodimension by way of the learning-theoretic concept of covering numbers, which are defined as follows.\nDefinition 4 (Coverage number). Let A ⊂ RN be a set of vectors. We define Np(r,A) to be the cardinality of the smallest set A′ ⊂ RN such that for all a ∈ A, there exists a′ ∈ A′ such that ||a− a′||p ≤ r. We say that such an A′ r−covers A in the `p norm.\nAlong with pseudo-dimension and Rademacher complexity, coverage numbers are another tool for measuring the richness of a class of functions, and thereby deriving sample complexity bounds. We can relate the above definition to a class of functions F by defining\nNp(r,F , N) = max{Np(r,F|S) | S ∈ XN},\nwhere for S = (x1, . . . , xN ) ∈ XN , F|S = {(f(x1), . . . , f(xN ) | f ∈ F}. Notice that F|S ⊂ RN .\nClaim 1. Let F be a class of real-valued functions with pseudo-dimension dF and range in [0, c] for some c ∈ R, and let S = {x1, . . . , xN} be a sample of size N . Then\nR̂S(F) ≤ 6c̄\nN\n(√ dF log eNc c̄dF + 2 √ dF ) ,\nwhere c̄ = maxf∈F √∑N i=1 f(xi) 2.\nProof. Let S be a subset of X of size N , and let A = F|S . By definition, N2(r,A) ≤ N2(r,F , N) and from Lemma 10.5 of [Anthony and Bartlett, 2009], which states that N2(r\n′,F ′, N ′) ≤ N∞(r′,F ′, N ′) for any F ′, r′, and N ′, we know that N2(r,A) ≤ N∞(r,F , N). [Anthony and Bartlett, 2009] also prove that for any F ′, r′, and N ′, where F ′ has pseudo-dimenion dF ′ and maps to the bounded interval [0, c′] for some c′ ∈ R, N∞(r′,F ′, N ′) is upper bounded by ∑dF′ i=1 ( N ′ i ) ( c′ r′ )i , which, in turn,\nis less than ( eN ′c′\nr′dF′\n)dF′ for N ′ ≥ dF ′ . Putting this all together, for our original function class, we\ncan guarantee that\nN2(r,A) ≤ ( eNc\nrdF )dF for N ≥ dF .\nWe use this fact to bound the empirical Rademacher complexity of F by calling on Lemma 27.5 of [Shalev-Shwartz and Ben-David, 2014], which states that for any A′ ⊆ RN ′ , if there are α, β > 0 such that for any k ≥ 1, √ log(N2(c̄2−k), A′)) ≤ α+ βk, then\nR(A′) = 1 N ′ Eσ [ sup a∈A′ N ′∑ i=1 σiai ] ≤ 6c̄ N ′ (α+ 2β),\nwhere c̄ = minā maxa∈A′ ||a− ā||2. For our set A = F|S , let ā be a minimizer of the objective function given in the definition of c̄. Since Rademacher complexity is invariant under translation,5 we can analyze the Rademacher complexity assuming that ā = 0. Moreover, since A = F|S , we know that c̄ = maxa∈A ||a||2 = maxf∈F √∑N i=1 f(xi)\n2. Now we derive the required α, β as follows.√\nlog(N2(c̄2−k, A)) ≤ √ log(N∞(c̄2−k,F , N))\n≤ √ dF log eNc\nc̄2−kdF\n= √ dF log eNc2k\nc̄dF\n= √ dF ( log eNc\nc̄dF + log 2k ) ≤ √ dF log eNc c̄dF + √ dFk\n≤ √ dF log eNc c̄dF + √ dFk.\nTherefore α = √ dF log\neNc c̄dF\nand β = √ dF , so\nR(F|S) = RS(F) ≤ 6c̄\nN\n(√ dF log eNc c̄dF + 2 √ dF ) .\n5For all D ⊆ RN , b ∈ RN , R(D) = R({d + b | d ∈ D})."
    }, {
      "heading" : "C Proofs from Section 3.1",
      "text" : "Here, we provide the lemmas referred to in the proof of Theorem 6. In particular, we bound the Rademacher complexity of the function classes consisting of the simpler components we broke the AMA revenue function into: revA,1, . . . , revA,n+1. Recall that\nrevA,j(~v) = 1\nwj φA,−j(~v),\nwhere\nφA,−j(~v) = max ~oi∈O ∑ `6=j w`v`(oi,`) + λi  and\nLj = {revA,j | A = (w1, . . . , wn, λ1, . . . , λ(n+1)m), Hw ≤ |wi| ≤ Hw, |λi| ≤ Hλ}.\nIt is helpful to note that revA,j is a weighted version of what the social welfare would have been if Bidder j had not participated in the auction. In Lemma 6, we bound the Rademacher complexity of Lj for j ∈ [n].\nTo complete the analysis, we need to analyze the Rademacher complexity of Ln+1, where\nLn+1 = {revA,n+1 | A = (w1, . . . , wn, λ1, . . . , λ(n+1)m), Hw ≤ |wi| ≤ Hw, |λi| ≤ Hλ},\nrevA,n+1(~v) = − (n+1)m∑ i=1  n∑ j=1 1 wj ∑ ` 6=j w`v`(oi,`) + λi 1~oi=~o∗A(~v), and\n~o∗A(~v) = argmax ~oi∈O  n∑ j=1 wjvj(oi,j) + λi  , As noted in the main body of the paper, revA,n+1 is the amount of revenue subtracted out in order to ensure that the resulting auction is strategy-proof. We bound the Rademacher complexity of Ln+1 in Lemma 7.\nThese bounds can then be combined as described in the proof of Theorem 6.\nLemma 6. For j ∈ [n],\nRN (Lj) = O\n( nmĤv(nHw +Hλ)\nHw\n√ m log n\nN\n) .\nProof. Let\nΦj = {φA,−j | A = (w1, . . . , wn, λ1, . . . , λ(n+1)m), Hw ≤ |wi| ≤ Hw, |λi| ≤ Hλ}.\nNow, we can write each function ∑\n`6=j w`v`(oi,`) + λi as a linear function h i A,j from Rn2 m+1 to\nR as follows. Let hiA,j(~v, 1) = (~v, 1) · ~aiA,j , where\n~aiA,j [`] =  wt if ` = 2 m(t− 1) + σ(i, t) and t 6= j λi if ` = n2 m + 1\n0 otherwise\n.\nNotice that ||(~v, 1)||∞ ≤ max{Hv, 1} = Ĥv and ||~aiA,j ||1 ≤ nHw +Hλ. Let\nHij = { hiA,j | A = (w1, . . . , wn, λ1, . . . , λ(n+1)m), Hw ≤ |wi| ≤ Hw, |λi| ≤ Hλ } .\nUsing the L1-norm Rademacher complexity bound for linear functions, we have that for all i ∈ [2m],\nRN (Hi1) ≤ Ĥv(nHw +Hλ) √ 2 log(n2m + 1)\nN .\nNow, for two hypothesis sets H and H ′ of functions mapping from X to R,\nRN ( { max(h, h′) | h ∈ H,h′ ∈ H ′ } ) ≤ RN (H) +RN (H ′), (12)\nwhere max(h, h′) denotes the function x 7→ max(h(x), h′(x)) [Mohri et al., 2012]. Therefore,\nRN (Φj) ≤ (n+ 1)mRN (H1j ) ≤ (n+ 1)mĤv(nHw +Hλ) √ 2 log(n2m + 1)\nN ,\nwhich means that,\nRN (Lj) = 1\nHw RN (Φj) ≤\n(n+ 1)mĤv(nHw +Hλ)\nHw\n√ 2 log(n2m + 1)\nN\n= O\n( nmĤv(nHw +Hλ)\nHw\n√ m log n\nN\n) .\nLemma 7.\nRN (Ln+1) = O\n( nm+2 (HwHv +Hλ)\nHw\n√ m log n\nN\n( nĤv (nHw +Hλ)\nHw + √ nm logN\n)) .\nProof. We use the following lemma, which is similar to Lemma 3 in [DeSalvo et al., 2015], to bound the Rademacher complexity of\nLn+1 = {revA,n+1 | A = (w1, . . . , wn, λ1, . . . , λ(n+1)m), Hw ≤ |wi| ≤ Hw, |λi| ≤ Hλ}.\nLemma 8. Let F be a family of functions mapping X to [−c, c], let G be a a family of functions mapping X to {0, 1}, and let H = {fg | f ∈ F , g ∈ G}. Then\nRN (H) ≤ (c+ 1)(RN (F) +RN (G)).\nProof of Lemma 8. Notice that for any f ∈ F , g ∈ G, we have that fg = 14 [(f + g) 2 − (f − g)2]. For x ∈ [−c, c+ 1], the function x 7→ 14x 2 is 12(c+ 1)-Lipschitz. The same holds for x ∈ [−c− 1, c]. Therefore, by Talagrand’s lemma (e.g. [Mohri et al., 2012]), we have that\nR̂S(H) ≤ 1\n2 (c+ 1)[R̂S(F + G) + R̂S(F − G)] ≤ (c+ 1)(R̂S(F) + R̂S(G)).\nTherefore, RN (H) ≤ (c+ 1)(RN (F) +RN (G)).\nTo use Lemma 8, we first define a set of functions for each i ∈ [(n+ 1)m]\nFi = { fA,i | A = (w1, . . . , wn, λ1, . . . , λ(n+1)m), Hw ≤ |wj | ≤ Hw, |λj | ≤ Hλ } ,\nwhere\nfA,i(~v) = n∑ j=1 1 wj ∑ `6=j w`v`(oi,`) + λi.\nAs in the proof of Lemma 6, we can write each fA,i as a linear function from Rn2 m+1 to R as\nfollows. Let hA,i(~v, 1) = (~v, 1) · ~aA,i, where\n~aA,i[`] =  wt ∑ s 6=t 1 ws if ` = 2m(t− 1) + σ(i, t) λi ∑n i=1 1 wi if ` = n2m + 1\n0 otherwise\n.\nThen fA,i(~v) = hA,i(~v, 1). As before, we have that ||(~v, 1)||∞ ≤ max{Hv, 1} = Ĥv. Moreover, ||~aA,i||1 ≤ nHw (nHw +Hλ).\nUsing the L1-norm Rademacher complexity bound for linear functions, we have that\nRN (Fi) ≤ nĤv Hw (nHw +Hλ)\n√ 2 log(n2m + 1)\nN . (13)\nNow, we define a set of functions Gi for each i ∈ [(n+ 1)m] as\nGi = { gA,i | A = (w1, . . . , wn, λ1, . . . , λ(n+1)m), Hw ≤ |wj | ≤ Hw, |λj | ≤ Hλ } ,\nwhere gA,i(~v) = 1 if and only if i = ~o ∗ A(~v), i.e.\ngA,i(~v) = 1 if i = argmaxi∈[(n+1)m] {∑n j=1wjvj(oi,j) + λi } 0 otherwise .\nNotice that we can also write each function gA,i(~v) as an intersection of (n+1) m−1 binary-valued\nfunctions {c`}, where ` ∈ [(n+ 1)m] \\ {i}, as follows.\nc`(~v) =\n{ 1 if ∑n j=1wjvj(oi,j) + λi ≥ ∑n j=1wjvj(o`,j) + λ`\n0 otherwise . (14)\nIndeed, c`(~v) = 1 for all ` 6= i if and only if gA,i(~v) = 1, i.e.\ni = argmax i∈[(n+1)m]  n∑ j=1 wjvj(oi,j) + λi  . Each function c` can be written as a linear separator over Rn2 m , so the VC dimension of {c`} is n2m + 1. This allows us to use Lemma 3.2.3 from [Blumer et al., 1989] to bound the VC dimension of Gi.\nLemma 9 (Lemma 3.2.3 from [Blumer et al., 1989]). Let C be a concept class of finite VC dimension d ≥ 1. For all s ≥ 1, let Cs{∩si=1ci | ci ∈ C, 1 ≤ i ≤ s}. Then for all s ≥ 1, the VC dimension of Cs is less than 2ds log(3s).\nTherefore, the VC dimension of Gi is less than 2(n2m+1)(n+1)m log(3·(n+1)m) = O(mnm log n). By Corollary 3.1 in [Mohri et al., 2012], we have that\nRN (Gi) = O\n(√ mnm log n logN\nN\n) . (15)\nPutting Equations (13) and (15) together with Lemma 8, we conclude that ifHi = {fA,igA,i | fA,i ∈ Fi, gA,i ∈ Gi}, then\nRN (Hi) = O\n(( n2(HwHv +Hλ)\nHw\n)( nĤv Hw (nHw +Hλ) √ m log n N + √ mnm log n logN N )) .\nThis follows from Lemma 8, since the range of any function in Fi is [0, n(n− 1)(HwHv +Hλ)/Hw]. Finally, since\nrevA,n+1(~v) = − (n+1)m∑ i=1 fA,i(~v)gA,i(~v),\nwe have that\nRN (Ln+1)\n= O ( nm ( n2(HwHv +Hλ)\nHw\n)( nĤv Hw (nHw +Hλ) √ m log n N + √ mnm log n logN N )) .\nBy rearranging terms, we get the desired result."
    } ],
    "references" : [ {
      "title" : "The simple economics of approximately optimal auctions",
      "author" : [ "Alaei et al", "S. 2013] Alaei", "H. Fu", "N. Haghpanah", "J. Hartline" ],
      "venue" : "In Proceedings of the Annual Symposium on Foundations of Computer Science (FOCS)",
      "citeRegEx" : "al. et al\\.,? \\Q2013\\E",
      "shortCiteRegEx" : "al. et al\\.",
      "year" : 2013
    }, {
      "title" : "Learning prices for repeated auctions with strategic buyers",
      "author" : [ "Amin et al", "K. 2013] Amin", "A. Rostamizadeh", "U. Syed" ],
      "venue" : "In Proceedings of the Annual Conference on Neural Information Processing Systems (NIPS),",
      "citeRegEx" : "al. et al\\.,? \\Q2013\\E",
      "shortCiteRegEx" : "al. et al\\.",
      "year" : 2013
    }, {
      "title" : "Neural Network Learning: Theoretical Foundations",
      "author" : [ "Anthony", "Bartlett", "M. 2009] Anthony", "P. Bartlett" ],
      "venue" : null,
      "citeRegEx" : "Anthony et al\\.,? \\Q2009\\E",
      "shortCiteRegEx" : "Anthony et al\\.",
      "year" : 2009
    }, {
      "title" : "Bundling and optimal auctions of multiple products",
      "author" : [ "Avery", "Hendershott", "C. 2000] Avery", "T. Hendershott" ],
      "venue" : "Review of Economic Studies,",
      "citeRegEx" : "Avery et al\\.,? \\Q2000\\E",
      "shortCiteRegEx" : "Avery et al\\.",
      "year" : 2000
    }, {
      "title" : "Reducing mechanism design to algorithm design via machine learning",
      "author" : [ "Balcan et al", "2008] Balcan", "M.-F", "A. Blum", "J. Hartline", "Y. Mansour" ],
      "venue" : "Journal of Computer and System Sciences,",
      "citeRegEx" : "al. et al\\.,? \\Q2008\\E",
      "shortCiteRegEx" : "al. et al\\.",
      "year" : 2008
    }, {
      "title" : "Optimal auctions via the multiplicative weight method",
      "author" : [ "Bhalgat et al", "A. 2013] Bhalgat", "S. Gollapudi", "K. Munagala" ],
      "venue" : "In Proceedings of the ACM Conference on Economics and Computation (EC),",
      "citeRegEx" : "al. et al\\.,? \\Q2013\\E",
      "shortCiteRegEx" : "al. et al\\.",
      "year" : 2013
    }, {
      "title" : "Budget constrained auctions with heterogeneous items",
      "author" : [ "Bhattacharya et al", "S. 2010] Bhattacharya", "G. Goel", "S. Gollapudi", "K. Munagala" ],
      "venue" : "In Proceedings of the Annual Symposium on Theory of Computing (STOC),",
      "citeRegEx" : "al. et al\\.,? \\Q2010\\E",
      "shortCiteRegEx" : "al. et al\\.",
      "year" : 2010
    }, {
      "title" : "Learnability and the Vapnik-Chervonenkis dimension",
      "author" : [ "Blumer et al", "A. 1989] Blumer", "A. Ehrenfeucht", "D. Haussler", "M.K. Warmuth" ],
      "venue" : "Journal of the ACM,",
      "citeRegEx" : "al. et al\\.,? \\Q1989\\E",
      "shortCiteRegEx" : "al. et al\\.",
      "year" : 1989
    }, {
      "title" : "Optimal multi-dimensional mechanism design: Reducing revenue to welfare maximization",
      "author" : [ "Cai et al", "Y. 2012a] Cai", "C. Daskalakis", "M. Weinberg" ],
      "venue" : "In Proceedings of the Annual Symposium on Foundations of Computer Science (FOCS)",
      "citeRegEx" : "al. et al\\.,? \\Q2012\\E",
      "shortCiteRegEx" : "al. et al\\.",
      "year" : 2012
    }, {
      "title" : "An algorithmic characterization of multi-dimensional mechanisms",
      "author" : [ "Cai et al", "Y. 2012b] Cai", "C. Daskalakis", "S.M. Weinberg" ],
      "venue" : "In Proceedings of the Annual Symposium on Theory of Computing (STOC),",
      "citeRegEx" : "al. et al\\.,? \\Q2012\\E",
      "shortCiteRegEx" : "al. et al\\.",
      "year" : 2012
    }, {
      "title" : "Reducing revenue to welfare maximization: Approximation algorithms and other generalizations",
      "author" : [ "Cai et al", "Y. 2013] Cai", "C. Daskalakis", "S.M. Weinberg" ],
      "venue" : "In Annual ACM-SIAM Symposium on Discrete Algorithms (SODA),",
      "citeRegEx" : "al. et al\\.,? \\Q2013\\E",
      "shortCiteRegEx" : "al. et al\\.",
      "year" : 2013
    }, {
      "title" : "The sample complexity of revenue maximization",
      "author" : [ "Cole", "Roughgarden", "R. 2014] Cole", "T. Roughgarden" ],
      "venue" : "In Proceedings of the Annual Symposium on Theory of Computing (STOC),",
      "citeRegEx" : "Cole et al\\.,? \\Q2014\\E",
      "shortCiteRegEx" : "Cole et al\\.",
      "year" : 2014
    }, {
      "title" : "Complexity of mechanism design",
      "author" : [ "Conitzer", "Sandholm", "V. 2002] Conitzer", "T. Sandholm" ],
      "venue" : "In Proceedings of the 18th Annual Conference on Uncertainty in Artificial Intelligence (UAI),",
      "citeRegEx" : "Conitzer et al\\.,? \\Q2002\\E",
      "shortCiteRegEx" : "Conitzer et al\\.",
      "year" : 2002
    }, {
      "title" : "Applications of automated mechanism design",
      "author" : [ "Conitzer", "Sandholm", "V. 2003] Conitzer", "T. Sandholm" ],
      "venue" : "In UAI-03 workshop on Bayesian Modeling Applications,",
      "citeRegEx" : "Conitzer et al\\.,? \\Q2003\\E",
      "shortCiteRegEx" : "Conitzer et al\\.",
      "year" : 2003
    }, {
      "title" : "Self-interested automated mechanism design and implications for optimal combinatorial auctions",
      "author" : [ "Conitzer", "Sandholm", "V. 2004] Conitzer", "T. Sandholm" ],
      "venue" : "In Proceedings of the ACM Conference on Electronic Commerce (ACM-EC),",
      "citeRegEx" : "Conitzer et al\\.,? \\Q2004\\E",
      "shortCiteRegEx" : "Conitzer et al\\.",
      "year" : 2004
    }, {
      "title" : "Combinatorial Auctions",
      "author" : [ "Cramton et al", "P. 2006] Cramton", "Y. Shoham", "R. Steinberg" ],
      "venue" : null,
      "citeRegEx" : "al. et al\\.,? \\Q2006\\E",
      "shortCiteRegEx" : "al. et al\\.",
      "year" : 2006
    }, {
      "title" : "The complexity of optimal mechanism design",
      "author" : [ "Daskalakis et al", "C. 2014] Daskalakis", "A. Deckelbaum", "C. Tzamos" ],
      "venue" : "In Annual ACM-SIAM Symposium on Discrete Algorithms (SODA),",
      "citeRegEx" : "al. et al\\.,? \\Q2014\\E",
      "shortCiteRegEx" : "al. et al\\.",
      "year" : 2014
    }, {
      "title" : "Learning with deep cascades",
      "author" : [ "DeSalvo et al", "G. 2015] DeSalvo", "M. Mohri", "U. Syed" ],
      "venue" : "In Proceedings of the Annual Conference on Learning Theory (ALT),",
      "citeRegEx" : "al. et al\\.,? \\Q2015\\E",
      "shortCiteRegEx" : "al. et al\\.",
      "year" : 2015
    }, {
      "title" : "The sample complexity of auctions with side information",
      "author" : [ "Devanur et al", "N.R. 2016] Devanur", "Z. Huang", "Psomas", "C.-A" ],
      "venue" : "In Proceedings of the Annual Symposium on Theory of Computing (STOC)",
      "citeRegEx" : "al. et al\\.,? \\Q2016\\E",
      "shortCiteRegEx" : "al. et al\\.",
      "year" : 2016
    }, {
      "title" : "Sampling and representation complexity of revenue maximization",
      "author" : [ "Dughmi et al", "S. 2014] Dughmi", "L. Han", "N. Nisam" ],
      "venue" : "In International Workshop On Internet And Network Economics (WINE),",
      "citeRegEx" : "al. et al\\.,? \\Q2014\\E",
      "shortCiteRegEx" : "al. et al\\.",
      "year" : 2014
    }, {
      "title" : "Combinatorial auctions via posted prices",
      "author" : [ "Feldman et al", "M. 2015] Feldman", "N. Gravin", "B. Lucier" ],
      "venue" : "In Annual ACM-SIAM Symposium on Discrete Algorithms (SODA)",
      "citeRegEx" : "al. et al\\.,? \\Q2015\\E",
      "shortCiteRegEx" : "al. et al\\.",
      "year" : 2015
    }, {
      "title" : "Simple versus optimal mechanisms",
      "author" : [ "Hartline", "Roughgarden", "J.D. 2009] Hartline", "T. Roughgarden" ],
      "venue" : "In Proceedings of the ACM Conference on Economics and Computation (EC),",
      "citeRegEx" : "Hartline et al\\.,? \\Q2009\\E",
      "shortCiteRegEx" : "Hartline et al\\.",
      "year" : 2009
    }, {
      "title" : "Do prices coordinate markets",
      "author" : [ "Hsu et al", "J. 2016] Hsu", "J. Morgenstern", "R. Rogers", "A. Roth", "R. Vohra" ],
      "venue" : "Proceedings of the Annual Symposium on Theory of Computing (STOC)",
      "citeRegEx" : "al. et al\\.,? \\Q2016\\E",
      "shortCiteRegEx" : "al. et al\\.",
      "year" : 2016
    }, {
      "title" : "Making the most of your samples",
      "author" : [ "Huang et al", "Z. 2015] Huang", "Y. Mansour", "T. Roughgarden" ],
      "venue" : "In Proceedings of the ACM Conference on Economics and Computation (EC),",
      "citeRegEx" : "al. et al\\.,? \\Q2015\\E",
      "shortCiteRegEx" : "al. et al\\.",
      "year" : 2015
    }, {
      "title" : "Mixed bundling auctions",
      "author" : [ "Jehiel et al", "P. 2007] Jehiel", "M. Meyer-Ter-Vehn", "B. Moldovanu" ],
      "venue" : "Journal of Economic Theory,",
      "citeRegEx" : "al. et al\\.,? \\Q2007\\E",
      "shortCiteRegEx" : "al. et al\\.",
      "year" : 2007
    }, {
      "title" : "Matroid prophet inequalities",
      "author" : [ "Kleinberg", "Weinberg", "R. 2012] Kleinberg", "S.M. Weinberg" ],
      "venue" : "In Proceedings of the Annual Symposium on Theory of Computing (STOC),",
      "citeRegEx" : "Kleinberg et al\\.,? \\Q2012\\E",
      "shortCiteRegEx" : "Kleinberg et al\\.",
      "year" : 2012
    }, {
      "title" : "Towards a characterization of truthful combinatorial auctions",
      "author" : [ "Lavi et al", "R. 2003] Lavi", "A. Mu’Alem", "N. Nisan" ],
      "venue" : "In Proceedings of the Annual Symposium on Foundations of Computer Science (FOCS),",
      "citeRegEx" : "al. et al\\.,? \\Q2003\\E",
      "shortCiteRegEx" : "al. et al\\.",
      "year" : 2003
    }, {
      "title" : "Methods for boosting revenue in combinatorial auctions",
      "author" : [ "Likhodedov", "Sandholm", "A. 2004] Likhodedov", "T. Sandholm" ],
      "venue" : "In Proceedings of the National Conference on Artificial Intelligence (AAAI),",
      "citeRegEx" : "Likhodedov et al\\.,? \\Q2004\\E",
      "shortCiteRegEx" : "Likhodedov et al\\.",
      "year" : 2004
    }, {
      "title" : "Approximating revenue-maximizing combinatorial auctions",
      "author" : [ "Likhodedov", "Sandholm", "A. 2005] Likhodedov", "T. Sandholm" ],
      "venue" : "In Proceedings of the National Conference on Artificial Intelligence (AAAI),",
      "citeRegEx" : "Likhodedov et al\\.,? \\Q2005\\E",
      "shortCiteRegEx" : "Likhodedov et al\\.",
      "year" : 2005
    }, {
      "title" : "Optimal multi-unit auctions",
      "author" : [ "Maskin", "Riley", "E. 1989] Maskin", "J. Riley" ],
      "venue" : "The Economics of Missing Markets, Information, and Games,",
      "citeRegEx" : "Maskin et al\\.,? \\Q1989\\E",
      "shortCiteRegEx" : "Maskin et al\\.",
      "year" : 1989
    }, {
      "title" : "Learning theory and algorithms for revenue optimization in second price auctions with reserve",
      "author" : [ "Medina", "Mohri", "A.M. 2014] Medina", "M. Mohri" ],
      "venue" : "In International Conference on Machine Learning (ICML),",
      "citeRegEx" : "Medina et al\\.,? \\Q2014\\E",
      "shortCiteRegEx" : "Medina et al\\.",
      "year" : 2014
    }, {
      "title" : "Optimal regret minimization in postedprice auctions with strategic buyers",
      "author" : [ "Mohri", "Munoz", "M. 2014] Mohri", "A. Munoz" ],
      "venue" : "In Proceedings of the Annual Conference on Neural Information Processing Systems (NIPS),",
      "citeRegEx" : "Mohri et al\\.,? \\Q2014\\E",
      "shortCiteRegEx" : "Mohri et al\\.",
      "year" : 2014
    }, {
      "title" : "Revenue optimization against strategic buyers",
      "author" : [ "Mohri", "Munoz", "M. 2015] Mohri", "A. Munoz" ],
      "venue" : "In Proceedings of the Annual Conference on Neural Information Processing Systems (NIPS),",
      "citeRegEx" : "Mohri et al\\.,? \\Q2015\\E",
      "shortCiteRegEx" : "Mohri et al\\.",
      "year" : 2015
    }, {
      "title" : "Foundations of Machine Learning",
      "author" : [ "Mohri et al", "M. 2012] Mohri", "A. Rostamizadeh", "A. Talwalkar" ],
      "venue" : null,
      "citeRegEx" : "al. et al\\.,? \\Q2012\\E",
      "shortCiteRegEx" : "al. et al\\.",
      "year" : 2012
    }, {
      "title" : "On the pseudo-dimension of nearly optimal auctions",
      "author" : [ "Morgenstern", "Roughgarden", "J. 2015] Morgenstern", "T. Roughgarden" ],
      "venue" : "In Proceedings of the Annual Conference on Neural Information Processing Systems (NIPS),",
      "citeRegEx" : "Morgenstern et al\\.,? \\Q2015\\E",
      "shortCiteRegEx" : "Morgenstern et al\\.",
      "year" : 2015
    }, {
      "title" : "Learning simple auctions",
      "author" : [ "Morgenstern", "Roughgarden", "J. 2016] Morgenstern", "T. Roughgarden" ],
      "venue" : "In Conference on Learning Theory (COLT)",
      "citeRegEx" : "Morgenstern et al\\.,? \\Q2016\\E",
      "shortCiteRegEx" : "Morgenstern et al\\.",
      "year" : 2016
    }, {
      "title" : "Iterative combinatorial auctions: Theory and practice",
      "author" : [ "Parkes", "Ungar", "D. 2000] Parkes", "L. Ungar" ],
      "venue" : "In Proceedings of the National Conference on Artificial Intelligence (AAAI),",
      "citeRegEx" : "Parkes et al\\.,? \\Q2000\\E",
      "shortCiteRegEx" : "Parkes et al\\.",
      "year" : 2000
    }, {
      "title" : "Approximately efficient online mechanism design",
      "author" : [ "Parkes et al", "D.C. 2004] Parkes", "D. Yanovsky", "S.P. Singh" ],
      "venue" : "In Proceedings of the Annual Conference on Neural Information Processing Systems (NIPS),",
      "citeRegEx" : "al. et al\\.,? \\Q2004\\E",
      "shortCiteRegEx" : "al. et al\\.",
      "year" : 2004
    }, {
      "title" : "Ironing in the dark",
      "author" : [ "Roughgarden", "Schrijvers", "T. 2015] Roughgarden", "O. Schrijvers" ],
      "venue" : "arXiv preprint arXiv:1511.06918",
      "citeRegEx" : "Roughgarden et al\\.,? \\Q2015\\E",
      "shortCiteRegEx" : "Roughgarden et al\\.",
      "year" : 2015
    }, {
      "title" : "Automated design of revenue-maximizing combinatorial auctions",
      "author" : [ "Sandholm", "Likhodedov", "T. 2015] Sandholm", "A. Likhodedov" ],
      "venue" : "Operations Research,",
      "citeRegEx" : "Sandholm et al\\.,? \\Q2015\\E",
      "shortCiteRegEx" : "Sandholm et al\\.",
      "year" : 2015
    }, {
      "title" : "Understanding Machine Learning: From Theory to Algorithms",
      "author" : [ "Shalev-Shwartz", "Ben-David", "S. 2014] Shalev-Shwartz", "S. Ben-David" ],
      "venue" : null,
      "citeRegEx" : "Shalev.Shwartz et al\\.,? \\Q2014\\E",
      "shortCiteRegEx" : "Shalev.Shwartz et al\\.",
      "year" : 2014
    }, {
      "title" : "Mixed-bundling auctions with reserve prices",
      "author" : [ "Tang", "Sandholm", "P. 2012] Tang", "T. Sandholm" ],
      "venue" : "In International Conference on Autonomous Agents and Multi-Agent Systems (AAMAS)",
      "citeRegEx" : "Tang et al\\.,? \\Q2012\\E",
      "shortCiteRegEx" : "Tang et al\\.",
      "year" : 2012
    }, {
      "title" : "AkBA: A progressive, anonymous-price combinatorial auction",
      "author" : [ "Wurman", "Wellman", "P. 2000] Wurman", "M. Wellman" ],
      "venue" : "In Proceedings of the ACM Conference on Electronic Commerce (ACM-EC),",
      "citeRegEx" : "Wurman et al\\.,? \\Q2000\\E",
      "shortCiteRegEx" : "Wurman et al\\.",
      "year" : 2000
    } ],
    "referenceMentions" : [ ],
    "year" : 2016,
    "abstractText" : "The design of revenue-maximizing combinatorial auctions, i.e. multi-item auctions over bundles of goods, is one of the most fundamental problems in computational economics, unsolved even for two bidders and two items for sale. In the traditional economic models, it is assumed that the bidders’ valuations are drawn from an underlying distribution and that the auction designer has perfect knowledge of this distribution. Despite this strong and oftentimes unrealistic assumption, it is remarkable that the revenue-maximizing combinatorial auction remains unknown. In recent years, automated mechanism design has emerged as one of the most practical and promising approaches to designing high-revenue combinatorial auctions. The most scalable automated mechanism design algorithms take as input samples from the bidders’ valuation distribution and then search for a high-revenue auction in a rich auction class. In this work, we provide the first sample complexity analysis for the standard hierarchy of deterministic combinatorial auction classes used in automated mechanism design. In particular, we provide tight sample complexity bounds on the number of samples needed to guarantee that the empirical revenue of the designed mechanism on the samples is close to its expected revenue on the underlying, unknown distribution over bidder valuations, for each of the auction classes in the hierarchy. In addition to helping set automated mechanism design on firm foundations, our results also push the boundaries of learning theory. In particular, the hypothesis functions used in our contexts are defined through multi-stage combinatorial optimization procedures, rather than simple decision boundaries, as are common in machine learning.",
    "creator" : "LaTeX with hyperref package"
  }
}