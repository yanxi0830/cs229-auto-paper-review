{
  "name" : "1512.05244.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "Learning Games and Rademacher Observations Losses",
    "authors" : [ "Richard Nock" ],
    "emails" : [ "richard.nock@nicta.com.au" ],
    "sections" : [ {
      "heading" : null,
      "text" : "ar X\niv :1\n51 2.\n05 24\n4v 1\n[ cs\n.L G\n] 1\n6 D\nec 2"
    }, {
      "heading" : "1 Introduction",
      "text" : "A recent result has shown that minimising the popular logistic loss over examples in supervised learning is equivalent to the minimisation of the exponential loss over sufficient statistics about the class known as Rademacher observations (rados, (Nock et al., 2015)), for the same classifier. In short, we fit a classifier over data that is different from examples, and the same classifier generalizes well to new observations. It is known that sufficient statistics carry the intractability of certain processes that would otherwise be easy with data (Montanari, 2014). In the case of rados, such a computational caveat turns out to be a big advantage as privacy is becoming crucial (Enserink & Chin, 2015). Indeed, rados allow to protect data not just from a computational complexity standpoint, but also from geometric, algebraic and statistical standpoints (Nock et al., 2015), while still allowing to learn accurate classifiers.\nTwo key problems remain: learning from rados can compete experimentally with learning from examples, but there is a gap to reduce for rados to be not just a good material to learn from in a privacy setting, but also a serious alternative to learning from examples at large, yielding new avenues to supervised learning.\n1\nSecond, theoretically speaking, it is crucial to understand if this equivalence holds only for the logistic and exponential losses, or if it can be generalised and shed new light on losses and their minimisation.\nIn this paper, we provide answers to these two questions, with four main contributions. Our first contribution is to show that this generalization indeed holds: other example losses admit equivalent losses in the rado world, meaning in particular that their minimiser classifier is the same, regardless of the dataset of examples. The technique we use exploits a two-player zero sum game representation of convex losses, that has been very useful to analyse boosting algorithms (Schapire, 2003; Telgarsky, 2012), with one key difference: payoffs are non-linear convex, eventually non-differentiable. These also resemble the entropic dual losses (Reid et al., 2015), with the difference that we do not enforce conjugacy over the simplex. The conditions of the game are slightly different for examples and rados. We provide necessary and sufficient conditions for the resulting losses over examples and rados to be equivalent. Informally, equivalence happens iff the convex functions of the games satisfy a symmetry relationship and the weights satisfy a linear system of equations. We give four cases of this equivalence. It turns out that the losses involved bear popular names in different communities, even when not all of them are systematically used as losses per se: exponential, logistic, square, mean-variance, ReLU, linear Hinge, and unhinged losses (Nair & Hinton, 2010; Gentile & Warmuth, 1998; Nock & Nielsen, 2008; Telgarsky, 2012; Vapnik, 1998; van Rooyen et al., 2015) (and many others).\nOur second contribution came unexpectedly through this equivalence. Regularizing a loss is common in machine learning (Bach et al., 2011). We show a sufficient condition for the equivalence under which regularizing the example loss is equivalent to regularizing the rados in the rado loss, i.e. making a Minkowski sum of the rado set with a classifier-based set. This property is independent of the regularizer, and holds for all four cases of equivalence.\nThird, we propose a boosting algorithm, Ω-R.ADABOOST, that learns a classifier from rados using the exponential regularized rado loss, with regularization choice belonging to the ridge, lasso, ℓ∞, or the recently coined SLOPE (Bogdan et al., 2015). Experiments display that Ω-R.ADABOOST is all the better vs ADABOOST (unregularized and ℓ1-regularized) as the domain gets larger, and is able to learn both accurate and sparse classifiers, making it a good contender for supervised learning at large on big domains. From a theoretical standpoint, we show that for any of these four regularizations, Ω-R.ADABOOST is a boosting algorithm — thus, through our first contribution, Ω-R.ADABOOST is an efficient proxy to boost the regularized logistic loss over examples using whichever of the four regularizers, and by extension, any linear combination of them (e.g., for elastic net regularization (Zou & Hastie, 2005)). We are not aware of any regularized logistic loss formal boosting algorithm with such a wide spectrum of regularizers.\nOur fourth contribution is a direct application of our findings to ε-differential privacy (DP). We protect directly the examples, granting the property that all subsequent stages are DP as well. We show theoretically that a most popular mechanism (Dwork & Roth, 2014) used to protect examples in rados amounts to a surrogate form of regularization of the clean examples’ loss; furthermore, the amount of noise can be commensurate to the one for a direct protection of examples. In other words, since rados’ norm may be much larger than examples’ (e.g. on big domains), we can expect noise to be much less damaging if learning from protected rados, and afford tiny budgets (e.g. ε ≈ 10−4) at little cost in accuracy. Experiments validate this intuition.\nThe rest of this paper is as follows. §2, 3 and 4 respectively present the equivalence between example and rado losses, its extension to regularized learning and Ω-R.ADABOOST. §5, 6 and 7 respectively present differential privacy vs regularized rado losses, detail experiments, and conclude. In order not to laden the paper’s body, an appendix, starting page 15 of this draft, contains the proofs and additional theoretical and experimental results.\n2"
    }, {
      "heading" : "2 Games and equivalent example/rado losses",
      "text" : "We first start by defining and analysing our general two players game setting. To avoid notational load, we shall not put immediately the learning setting at play, considering for the moment that the learner fits a general vector z ∈ Rm, which depends both on data (examples or rados) and classifier. Let [m] .= {1, 2, ...,m} and Σm .= {−1, 1}m, for m > 0. Let ϕe : R → R and ϕr : R → R two convex and lower-semicontinuous generators. We define functions Le : Rm × Rm → R and Lr : R2m × Rm → R:\nLe(p,z) . =\n∑\ni∈[m]\npizi + µe ∑\ni∈[m]\nϕe(pi) , (1)\nLr(q,z) . =\n∑\nI⊆[m]\nqI ∑\ni∈I\nzi + µr ∑\nI⊆[m]\nϕr(qI) , (2)\nwhere µe,µr > 0 do not depend on z. For the notation to be meaningful, the coordinates in q are assumed (wlog) to be in bijection with 2[m]. The dependence of both problems in their respective generators is implicit and shall be clear from context. The adversary’s goal is to fit\np∗(z) . = arg min\np∈Rm Le(p,z) , (3)\nq∗(z) . = arg min\nq∈H2m Lr(q,z) , (4)\nwith H2 m . = {q ∈ R2m : 1⊤q = 1}, so as to attain\nL∗e (z) . = Le(p ∗(z),z) , (5) L∗r (z) . = Lr(q ∗(z),z) , (6)\nand let ∂L∗e (z) and ∂L ∗ r (z) denote their subdifferentials. We view the learner’s task as the problem of maximising the corresponding problems in eq. (5) (with examples) or (6) (with rados), or equivalently minimising negative the corresponding function, then called a loss function. The question of when these two problems are equivalent from the learner’s standpoint motivates the following definition.\nDefinition 1 Two generators ϕe, ϕr are said proportionate iff for any m > 0, there exists (µe,µr) such that\nL∗e (z) = L ∗ r (z) + b ,∀z ∈ Rm . (7)\n(b does not depend on z) ∀m ∈ N∗, let\nGm . =\n[ 0 ⊤ 2m−1 1 ⊤ 2m−1\nGm−1 Gm−1\n]\n(∈ {0, 1}m×2m ) (8)\nif m > 1, and G1 . = [0 1] otherwise (zd denotes a vector in Rd). Each column of Gm is the binary indicator vector for the edge vectors summed in a rado; wlog, we let these to give the bijection between 2[m] and coordinates of q(∗)(z).\nTheorem 2 ϕe, ϕr are proportionate iff the optimal solutions p∗(z) and q∗(z) to eqs (3) and (4) satisfy\np∗(z) ∈ ∂L∗r (z) , (9) Gmq ∗(z) ∈ ∂L∗e (z) . (10)"
    }, {
      "heading" : "In the case where ϕe, ϕr are differentiable, they are proportionate iff p∗(z) = Gmq∗(z).",
      "text" : "3\n(Proof in Appendix, Subsection 9.1) Theorem 2 gives a necessary and sufficient condition for two generators to be proportionate. It does not say how to construct one from the other, if possible. We now show that it is indeed possible and prune the search space: if ϕe is proportionate to some ϕr, then it has to be a “symmetrized” version of ϕr, according to the following definition.\nDefinition 3 Let ϕr such that dom(ϕr) ⊇ (0, 1). We call ϕs(r)(z) .= ϕr(z) + ϕr(1 − z) the symmetrisation of ϕr.\nLemma 4 If ϕe and ϕr are proportionate, then ϕe(z) = (µr/µe) · ϕs(r)(z) + (b/µe), where b appears in eq. (7).\n(Proof in Appendix, Subsection 9.2) To summarize, ϕe and ϕr are proportionate iff (i) they meet the structural property that ϕe is (proportional to) the symmetrized version of ϕr (according to Definition 3), and (ii) the optimal solutions p∗(z) and q∗(z) to problems (1) and (2) satisfy the conditions of Theorem 2. Depending on the direction, we have two cases to craft proportionate generators. First, if we have ϕr, then necessarily ϕe ∝ ϕs(r) so we merely have to check Theorem 2. Second, if we have ϕe, then it matches Definition 31. In this case, we have to find ϕr = f + g where g(z) = −g(1 − z) and ϕe(z) = f(z) + f(1− z).\nWe now come back to L∗e (z), L ∗ r (z) as defined in Definition 1, and make the connection with example and rado losses. In the next definition, an e-loss ℓe(z) is a function defined over the coordinates of z, and a r-loss ℓr(z) is a function defined over the subsets of sums of coordinates. Functions can depend on other parameters as well.\nDefinition 5 Suppose e-loss ℓe(z) and r-loss ℓr(z) are such that there exist (i) fe : R → R and fr(z) : R → R both strictly increasing and such that ∀z ∈ Rm,\n− L∗e (z) = fe (ℓe(z)) , (11) −L∗r (z) = fr (ℓr(z)) . (12)\nThen the couple (ℓe, ℓr) is called a couple of equivalent example-rado losses.\nHereafter, we just write ϕs instead of ϕs(r).\nLemma 6 ϕr(z) . = z log z − z is proportionate to ϕe .= ϕs = z log z + (1 − z) log(1 − z) − 1, whenever µe = µr.\n(Proof in Appendix, Subsection 9.3)\nCorollary 7 The following example and rado losses are equivalent for any µ > 0:\nℓe(z,µ) = ∑\ni∈[m]\nlog\n(\n1 + exp\n(\n− 1 µ · zi\n))\n, (13)\nℓr(z,µ) = ∑\nI⊆[m]\nexp\n(\n− 1 µ · ∑\ni∈I\nzi\n)\n. (14)\n(Proof in Appendix, Subsection 9.4)\nLemma 8 ϕr(z) . = (1/2)·z2 is proportionate to ϕe .= ϕs = (1/2)·(1−2z(1−z)) whenever µe = µr/2m−1.\n1Alternatively, −ϕe is permissible (Kearns & Mansour, 1999).\n4\n(Proof in Appendix, Subsection 9.5)\nCorollary 9 The following example and rado losses are equivalent, for any µ > 0:\nℓe(z,µ) = ∑\ni∈[m]\n(\n1− 1 µ · zi\n)2\n, (15)\nℓr(z,µ) = − ( EI [ 1\nµ · ∑\ni∈I\nzi\n] − µ · VI [ 1\nµ · ∑\ni∈I\nzi\n])\n, (16)\nwhere EI[X(I)] and VI[X(I)] denote the expectation and variance of X wrt uniform weights on I ⊆ [m].\n(Proof in Appendix, Subsection 9.6) We now investigate cases of non differentiable proportionate generators, the first of which is self-proportionate (ϕe = ϕr). We let χA(z) be the indicator function: χA(z) . = 0 if z ∈ A (and +∞ otherwise), convex since A = [0, 1] is convex.\nLemma 10 ϕr(z) . = χ[0,1](z) is self-proportionate,∀µe ,µr.\n(Proof in Appendix, Subsection 9.7)\nCorollary 11 The following example and rado losses are equivalent, for any µe,µr:\nℓe(z,µe) = ∑\ni∈[m]\nmax\n{\n0,− 1 µe\n· zi } , (17)\nℓr(z,µr) = max\n{\n0, max I⊆[m]\n{\n− 1 µr · ∑\ni∈I\nzi\n}}\n. (18)\n(Proof in Appendix, Subsection 9.8)\nLemma 12 ϕr(z) . = χ[ 12m , 1 2 ] (z) is proportionate to ϕe . = ϕs = χ{ 12}(z), for any µe,µr.\n(Proof in Appendix, Subsection 9.9)\nCorollary 13 The following example and rado losses are equivalent, for any µe,µr:\nℓe(z,µe) = ∑\ni\n− 1 µe · zi , (19)\nℓr(z,µr) = EI\n[\n− 1 µr · ∑\ni∈I\nzi\n]\n. (20)\n(Proof in Appendix, Subsection 9.10) Table 1 summarizes the four equivalent example and rado losses."
    }, {
      "heading" : "3 Learning with (rado) regularized losses",
      "text" : "We now plug the learning setting. The learner is given a set of examples S = {(xi, yi), i = 1, 2, ...,m} where xi ∈ Rd, yi ∈ Σ1 (for i = 1, 2, ...,m). It returns a classifier h : Rd → R from a predefined set H. Let zi(h) . = yh(xi) and define z(h) as the corresponding vector in Rm, which we plug in the losses of Table 1 to obtain the corresponding example and rado losses. Losses simplify conveniently when H\n5\nconsists of linear classifiers, h(x) . = θ⊤x for some θ ∈ Θ ⊆ Rd. In this case, the example loss can be described using edge vectors Se . = {yi · xi, i = 1, 2, ...,m} since zi = θ⊤(yi · xi), and the rado loss can be described using rademacher observations (Nock et al., 2015), since ∑\ni∈I zi = θ ⊤πσ for σi = yi iff i ∈ I\n(and −yi otherwise) and πσ .= (1/2) · ∑ i(σi + yi) · xi. Let us define S∗r . = {πσ ,σ ∈ Σm} the set of all rademacher observations. We rewrite any couple of equivalent example and rado losses as ℓe(Se,θ) and ℓr(S ∗ r ,θ) respectively\n2 , omitting parameters µe and µr, assumed to be fixed beforehand for the equivalence to hold (see Table 1). Let us regularize the example loss, so that the learner’s goal is to minimize\nℓe(Se,θ,Ω) . = ℓe(Se,θ) + Ω(θ) , (21)\nwith Ω a regularizer (Bach et al., 2011). The following shows that when fe in eq. (11) is linear, there is a rado-loss equivalent to this regularized loss, regardless of Ω.\nTheorem 14 Suppose H contains linear classifiers. Let (ℓe(Se,θ), ℓr(S∗r ,θ)) be any couple of equivalent example-rado losses such that fe in eq. (11) is linear:\nfe(z) = ae · z + be , (22)\nfor some ae > 0, be ∈ R. Then for any regularizer Ω(.), the regularized example loss ℓe(Se,θ,Ω) is equivalent to rado loss ℓr(S∗,Ω,θr ,θ) computed over regularized rados:\nS∗,Ω,θr . = S∗r ⊕ {−Ω̃(θ) · θ} , (23)\nwhere ⊕ is Minkowski sum and Ω̃(θ) .= ae·Ω(θ)/‖θ‖22 if θ 6= 0 (and 0 otherwise, assuming wlog Ω(0) = 0).\n(Proof in Appendix, Subsection 9.11) Theorem 14 applies to all rado losses (I-IV) in Table 1. The effect of regularization on rados is intuitive from the margin standpoint: assume that a “good” classifier θ is one that ensures lowerbounded inner products θ⊤z ≥ τ for some margin threshold τ . Then any good classifier on a regularized rado πσ shall actually meet, over examples,\n∑\ni:yi=σi\nθ⊤(yi · xi) ≥ τ + ae · Ω(θ) . (24)\nNotice that ineq (24) ties an ”accuracy” of θ (edges, left hand-side) and its sparsity (right-hand side). One important question is the way the minimisation of the regularized rado loss impacts the minimisation of the regularized examples loss when one subsamples the rados, and learns θ from some Sr ⊆ S∗r with eventually\n2To prevent notational overload, we blend the notions of (pointwise) loss and (samplewise) risk, as just “losses”.\n6\n|Sr| ≪ |S∗r |. We give an answer for the log-loss (Nock et al., 2015) (row I in Table 1), and for this objective define the Ω-regularized exp-rado-loss computed over Sr, with |Sr| = n and ω > 0 user-fixed:\nℓexpr (Sr,θ,Ω)\n. =\n1 n · ∑\nj∈[n]\nexp\n( −θ⊤ ( πj −ω · Ω(θ)\n‖θ‖22 · θ\n))\n, (25)\nwhenever θ 6= 0 (otherwise, we discard the factor depending on ω in the formula). We assume that Ω is a norm, and let ℓexpr (Sr,θ) denote the unregularized loss (ω = 0 in eq. (25)), and we let ℓ log e (Se,θ,Ω) . = (1/m) ∑ i log ( 1 + exp ( −θ⊤(yi · xi) )) +Ω(θ) denote the Ω-regularized log-loss. Notice that we normalize losses. We define the open ball BΩ(0, r) . = {x ∈ Rd : Ω(x) < r} and r⋆π . = (1/m) · maxS∗r Ω⋆(πσ), where Ω⋆ is the dual norm of Ω. The following Theorem is a direct application of Theorem 3 in (Nock et al., 2015), and shows mild conditions on Sr ⊆ S∗r for the minimization of ℓexpr (Sr,θ,Ω) to indeed yield that of ℓloge (Se,θ,Ω).\nTheorem 15 Assume Θ ⊆ B‖.‖2(0, rθ), with rθ > 0. Let ̺(θ) . = (supθ′∈Θmaxπσ∈S∗r exp(−θ′⊤πσ))/ℓexpr (S∗r ,θ). Then if m is sufficiently large, ∀δ > 0, there is probability ≥ 1− δ over the sampling of Sr that any θ ∈ Θ satisfies:\nℓloge (Se,θ,Ω) ≤ log 2 + (1/m) · log ℓexpr (Sr,θ,Ω)\n+O\n(\n̺(θ) mβ · √ rθr⋆π n + d nm log n dδ\n)\n,\nas long as ω ≥ um for some constant u > 0."
    }, {
      "heading" : "4 Boosting with (rado) regularized losses",
      "text" : "Ω-R.ADABOOST presents our approach to learning with rados regularized with regularizer Ω to minimise loss ℓexpr (Sr,θ,Ω) in eq. (25). Classifier θt is defined as θt . = ∑t t′=1 αι(t′) · 1ι(t′), where 1k is the kth canonical basis vector. Frameboxes highlight the differences with RADOBOOST (Nock et al., 2015). The expected edge rt used to compute αt in eq. (27) is based on the following basis assignation:\nrι(t) ← 1\nπ∗ι(t)\nn∑\nj=1\nwtjπjι(t) (∈ [−1, 1]) . (32)\nThe computation of rt is eventually tweaked by the weak learner, as displayed in Algorithm Ω-WL. We investigate four choices for Ω. For each of them, we prove the boosting ability of Ω-R.ADABOOST (Γ is symmetric positive definite, Sd is the symmetric group of order d, |θ| is the vector whose coordinates are the absolute values of the coordinates of θ):\nΩ(θ) =\n \n\n‖θ‖1 .= |θ|⊤1 Lasso ‖θ‖2Γ . = θ⊤Γθ Ridge ‖θ‖∞ .= maxk |θk| ℓ∞ ‖θ‖Φ .= maxM∈Sd(M|θ|)⊤ξ SLOPE\n(33)\n(Bach et al., 2011; Bogdan et al., 2015; Duchi & Singer, 2009; Su & Candès, 2015). The coordinates of ξ in SLOPE are ξk . = Φ−1(1 − kq/(2d)) where Φ−1(.) is the quantile of the standard normal distribution and q ∈ (0, 1); thus, the largest coordinates (in absolute value) of θ are more penalized. We now establish the boosting ability of Ω-R.ADABOOST. We give no direction for Step 1 in Ω-WL, which is consistent with the definition of a weak learner in the boosting theory: all we require from the weak learner is |r.| no smaller than some weak learning threshold γWL > 0.\n7\nAlgorithm 1 Ω-R.ADABOOST Input rados Sr . = {π1,π2, ...,πn}; T ∈ N∗; ω ∈ R+; γ ∈ (0, 1);\nStep 1 : let θ0 ← 0, w0 ← (1/n)1 ; Step 2 : for t = 1, 2, ..., T\nStep 2.1 : call the weak learner\n(ι(t), rt) ← Ω-WL(Sr,wt,γ,ω,θt−1) ; (26)\nStep 2.2 : let\nαι(t) ← 1\n2π∗ι(t) log 1 + rt 1− rt ; (27)\nδt ← ω · (Ω(θt)− Ω(θt−1)) ; (28)\nStep 2.3 : for j = 1, 2, ..., n\nwtj ← w(t−1)j\nZt · exp\n( −αtπjι(t) + δt ) ; (29)\nReturn θT ;\nDefinition 16 Fix any constant γWL ∈ (0, 1). Ω-WL is said to be a γWL-Weak Learner iff the feature ι(t) it picks at iteration t satisfies |rι(t)| ≥ γWL, for any t = 1, 2, ..., T .\nWe also provide an optional step for the weak learner in Ω-WL, which we exploit in the experimentations, which gives a total preference order on features to optimise further the convergence of Ω-R.ADABOOST.\nTheorem 17 (boosting with ridge). Take Ω(.) = ‖.‖2Γ. Fix any 0 < a < 1/5, and suppose that ω and the number of iterations T of Ω-R.ADABOOST are chosen so that\nω < (2amin k max j\nπ2jk)/(TλΓ) , (34)\nwhere λΓ > 0 is the largest eigenvalue of Γ. Then there exists some γ > 0 (depending on a, and given to Ω-WL) such that for any fixed 0 < γWL < γ, if Ω-WL is a γWL-Weak Learner, then Ω-R.ADABOOST returns at the end of the T boosting iterations a classifier θT which meets:\nℓexpr (Sr,θT , ‖.‖2Γ) ≤ exp(−aγ2WLT/2) . (35)\nFurthermore, if we fix a = 1/7, then we can fix γ = 0.98, and if we consider a = 1/10, then we can fix γ = 0.999.\n(Proof in Appendix, Subsection 9.12) Two remarks are in order. First, the cases a = 1/7, 1/10 show that Ω-WL can still obtain large edges in eq. (32), so even a “strong” weak learner might fit in for Ω-WL, without clamping edges. Second, the right-hand side of ineq. (34) may be very large if we consider that\n8\nAlgorithm 2 Ω-WL, for Ω ∈ {‖.‖1, ‖.‖2Γ, ‖.‖∞, ‖.‖Φ} Input set of rados Sr . = {π1,π2, ...,πn}; weights w ∈ △n; parameters γ ∈ (0, 1), ω ∈ R+; classifier\nθ ∈ Rd; Step 1 : pick weak feature ι∗ ∈ [d];\nOptional — use preference order:\nι ι′ ⇔ |rι| − δι ≥ |rι′ | − δι′ ; (30) (δι . = ω · (Ω(θ + αι · 1ι)− Ω(θ)))\n// rι is given in (32), αι is given in (27)\nStep 2 : if Ω = ‖.‖2Γ then\nr∗ ← { rι∗ if rι∗ ∈ [−γ,γ] sign (rι∗) · γ otherwise ; (31)\nelse r∗ ← rι∗ ; Return (ι∗, r∗);\nmink maxj π 2 jk may be proportional to m 2. So the constraint on ω is in fact loose, and ω may easily meet the constraint of Thm 15.\nTheorem 18 (boosting with lasso or ℓ∞). Take Ω(.) ∈ {‖.‖1, ‖.‖∞}. Suppose Ω-WL is a γWL-Weak Learner for some γWL > 0. Suppose ∃0 < a < 3/11 s. t. ω satisfies:\nω = aγWL min k max j\n|πjk| . (36)\nThen Ω-R.ADABOOST returns at the end of the T boosting iterations a classifier θT which meets:\nℓexpr (Sr,θT ,Ω) ≤ exp(−T̃γ2WL/2) , (37)\nwhere\nT̃ . =\n{ aγWLT if Ω = ‖.‖1\n(T − T∗) + aγWL · T∗ if Ω = ‖.‖∞ , (38)\nand T∗ is the number of iterations where the feature computing the ℓ∞ norm was updated3.\n(Proof in Appendix, Subsection 9.13) We finally investigate the SLOPE choice. The Theorem is proven for ω = 1 in Ω-R.ADABOOST, for two reasons: it matches the original definition (Bogdan et al., 2015) and furthermore it unveils an interesting connection between boosting and the SLOPE properties (Su & Candès, 2015).\nTheorem 19 (boosting with SLOPE). Take Ω(.) = ‖.‖Φ. Suppose wlog |θTk| ≥ |θT (k+1)|,∀k, and fix ω = 1. Let\na . = min { 3γWL 11 , Φ−1(1− q/(2d)) mink maxj |πjk| } . (39)\n3If several features match this criterion, T∗ is the total number of iterations for all these features.\n9\nAlgorithm 3 DP-RADOS Input rados Sr . = {π1,π2, ...,πn}; budget ε > 0;\nStep 1 : let SDPr ← ∅; Step 2 : for j = 1, 2, ..., n\nStep 2.1 : sample zj as zjk ∼ Lap(z|nre/ε) ,∀k; Step 2.2 : SDPr ← SDPr ∪ {πj + zj};\nReturn SDPr ;\nSuppose (i) Ω-WL is a γWL-Weak Learner for some γWL > 0, and (ii) the q-value is chosen to meet:\nq ≥ 2 ·max k\n{( 1− Φ ( 3γWL 11 ·max j |πjk| ))/( k d )} .\nThen classifier θT returned by Ω-R.ADABOOST at the end of the T boosting iterations satisfies:\nℓexpr (Sr,θT , ‖.‖Φ) ≤ exp(−aγ2WLT/2) . (40)\n(Proof in Appendix, Subsection 9.14) Constraint (ii) on q is interesting in the light of the properties of SLOPE (Bogdan et al., 2015; Su & Candès, 2015). Modulo some assumptions, SLOPE yields a control the false discovery rate (FDR) — that is, sparsity errors, negligible coefficients in the ”true” linear model θ∗ that are actually found significant in the learned θ —. Constraint (ii) links the ”small” achievable FDR (upperbounded by q) to the ”boostability” of the data: the fact that each feature k can be chosen by the weak learner for a ”large” γWL, or has maxj |πjk| large, precisely flags potential significant features, thus reducing the risk of sparsity errors, and allowing small q, which is constraint (ii). Using the second order approximation of normal quantiles (Su & Candès, 2015), a sufficient condition for (ii) is that, for some constant K ,\nγWL min j max j\n|πjk| ≥ K · √ log d+ log q−1 ; (41)\nbut minj maxj |πjk| is proportional to m, so ineq. (41), and thus (ii), may hold even for small samples and q-values.\nWe can now have a look at the regularized log-loss of θT over examples, as depicted in Theorem 15, and show that it is guaranteed a monotonic decrease with T , with high probability, for any applicable choice of regularization, since we get indeed that the regularized log-loss of θT output by Ω-R.ADABOOST, computed on examples, satisfies with high probability ℓloge (Se,θ,Ω) ≤ log 2 − κ · T + τ(m), with τ(m) → 0 when m → ∞, and κ does not depend on T . Hence, Ω-R.ADABOOST is an efficient proxy to boost the regularized log-loss over examples, using whichever of the ridge, lasso, ℓ∞ or SLOPE regularization, establishing the first boosting algorithm for this last choice. Notice finally that we can also choose any linear combinations of the regularizers and still keep the formal boosting property, thereby extending our results e.g., to the popular elastic nets regularization (Zou & Hastie, 2005)."
    }, {
      "heading" : "5 Regularized losses and differential privacy",
      "text" : "We show here that the standard differential privacy (DP) mechanism (Dwork & Roth, 2014) to protect examples in rados — not investigated in (Nock et al., 2015) —, amounts to a surrogate form of randomized regularization over clean examples. We let Lap(z|b) .= (1/2b) exp(−|z|/b) denote the pdf of the Laplace distribution. Algorithm DP-RADOS states the protection mechanism. Let us define two training samples Se and S′e as being neighbours, noted Se ≈ S′e, iff they differ from one example. We show how the Laplace\n10\nmechanism of DP-RADOS can give ε-DP, and furthermore the minimisation of a rado-loss over protected rados resembles the minimisation of an optimistic bound on a regularization of the equivalent example loss over clean examples. We make the assumption that any two edge vectors e,e′ satisfy ‖e−e′‖1 ≤ re, which is ensured e.g. if all examples belong to a ℓ1-ball of diameter re.\nTheorem 20 DP-RADOS delivers ε-differential privacy. Furthermore, pick (Ω,Ω⋆) any couple of dual norms and assume Sr = S∗r (|Sr| = 2m). Then ∀θ, ℓexpr (S∗,DPr ,θ) ≤ exp{m·ℓloge (Se,θ, (1/m) ·maxj Ω⋆(zj) · Ω)}. (Proof in Appendix, Subsection 9.15)"
    }, {
      "heading" : "6 Experiments",
      "text" : "We have implemented Ω-WL using the order suggested to retrieve the topmost feature in the order. Hence, the weak learner returns the feature maximising |rι| − δι. The rationale for this comes from the proofs of Theorems 17 — 19, showing that ∏\nt exp(−(r2ι(t)/2−δι(t))) is an upperbound on the exponential regularized rado-loss. We do not clamp the weak learner for Ω(.) = ‖.‖2Γ, so the weak learner is restricted to the framebox in Ω-WL4. We have tested two types of random rados, the plain random rados (Nock et al., 2015), and class-wise rados, for which we first pick a class at random and then sample a subset of its examples to compute one rado (and repeat for n rados). The supplementary information (Appendix, Section 10) provides the complete experiments, whose summary is given here.\nExperiments I: (regularized) rados vs examples The objective of these experiments is to evaluate ΩR.ADABOOST as a contender for supervised learning per se. We compared Ω-R.ADABOOST to ADABOOST/ℓ1-ADABOOST (Schapire & Singer, 1999; Xi et al., 2009). All algorithms are run for a total of\n4the values for ω that we test, in {10−u, u ∈ {0, 1, 2, 3, 4, 5}}, are very small with respect to the upperbound in ineq. (34) given the number of boosting iterations (T = 1000), and would yield on most domains a maximal γ ≈ 1.\n11\nT = 1000 iterations, and at the end of the iterations, the classifier in the sequence that minimizes the empirical loss is kept. Notice therefore that rado-based classifiers are evaluated on the training set which computes the rados (in a privacy setting, the learner send the sequence of classifiers to the data handler, which then selects the best according to its training sample). To obtain very sparse solutions for ℓ1-ADABOOST, we pick its ω (β in (Xi et al., 2009)) in {10−4, 1, 104}. The results we give, in Table 2, report only the lowest error of all of ADABOOST variants. The Appendix (Subsection 10.1) details the support results, that are summarized in Table 2. Experiments support several key observations. First, regularizing consistently reduces the test error of Ω-R.ADABOOST, by more than 15% on Magic, and 20% on Kaggle. Second, Ω-R.ADABOOST is able to obtain both very sparse and accurate classifiers (Magic, Hardware, Marketing, Kaggle). Third, with the sole exception of domain Banknote, Ω-R.ADABOOST competes or beats ADABOOST on all domains, and is all the better as the domain gets bigger. Fourth, it is important to have several choices of regularizers at hand. Fifth, as already remarked (Nock et al., 2015), significantly subsampling rados (e.g. Marketing, Kaggle) still yields very accurate classifiers. Finally, regularization in Ω-R.ADABOOST successfully reduces sparsity to learn more accurate classifiers on several domains (Transfusion, Banknote, Winered, Magic, Marketing), achieving efficient adaptive sparsity control.\nExperiments II: differential privacy We have tested DP-RADOS for a fixed number of rados of n = 100. Such a small number of rados has three advantages: (i) the privacy budget does not blow up, (ii) accurate classifiers can still be learned with a small number of rados (Nock et al., 2015), (iii) with such a small number of rados, we are within the reach of additional privacy guarantees (Nock et al., 2015). We have compared with ADABOOST, trained over a subset of n = 100 (protected) examples, randomly sampled out of the full training fold. To make sure that this does not impair the algorithm just because the sample is too small, we compute the test error for very large values of ε as a baseline. Last, for tight comparisons, we use the same set of random vectors z to protect the rados and the examples. This choice is justified and discussed at the end of the proof of Theorem 20 (Appendix, Subsection 9.15). Yet, as we shall see, the results are exceedingly in favor of Ω-R.ADABOOST in this case. To give a more balanced picture, we chose to compute an “approximate” example-equivalent privacy budget εa = εa(ε, n,m) for ADABOOST and n examples, which we fix to be\nεa . = n · ln\n(\n1 + exp(ε/n) − 1\nm\n)\n. (42)\nWe always have εa < ε. The “optimal” DP picture of ADABOOST shall thus be representable as a stretching of its curves in between the figures for εa and ε. We insist on the fact that the noise for ε is conservative but always safe, while computing ε from εa would sometimes fail to provide εa-DP (Appendix, Subsection 9.15).\nTable 3 presents the results obtained for three big domains (m indicated in parenthesis), in which we have run unregularized algorithms for a fixed number of T = 1000 iterations, keeping the last classifier θ1000 for testing. GaussNLin is a d = 2 simulated domain, non linearly separable but for which the optimal linear classifier has error < 2%. The results are a clear advocacy in favor of using rados against examples for the straight DP protection: with plain random rados, test errors that compete with clean data can be observed for privacy budget ε ≈ 10−4, that is, more than a hundred times smaller than most reported studies (Hsu et al., 2014). In comparison, ADABOOST’s results, even plotted against the weak protection budget εa, are very significantly worse. Finally, on UCI domains SuSy and Higgs, non-trivial protections (typically, ε ∈ [0.01, 1]) allow to beat classification on clean data, as witnessed by a 6%+ test error reduction for Higgs. In addition to “coming for free” (Wang et al., 2015) in machine learning, DP may thus also be a worthwhile companion to improve learning.\n12"
    }, {
      "heading" : "7 Conclusion",
      "text" : "We have shown that the equivalence between the log loss over examples and the exponential loss over rados, as shown in (Nock et al., 2015), can be generalized to other losses via a principled representation of a loss function in a two-player zero-sum game. Furthermore, we have shown that this equivalence extends to regularized losses, where the regularization in the rado loss is performed over the rados themselves with Minkowski sums. Because regularization with rados has such a simple form, it is relatively easy to derive efficient learning algorithms working with various forms of regularization, as exemplified with ridge, lasso, ℓ∞ and SLOPE regularizations in a formal boosting algorithm that we introduce, Ω-R.ADABOOST. Experiments confirm that this freedom in the choice of regularization is a clear strength of the algorithm, and that regularization dramatically improves the performances over non-regularized rado learning. ΩR.ADABOOST efficiently controls sparsity, and may be a worthy contender for supervised learning at large outside the privacy framework. Experiments also display that SLOPE regularization tends to achieve top performances, and call for an extension to rados of the formal sparsity results already known (Su & Candès, 2015)."
    }, {
      "heading" : "8 Acknowledgments",
      "text" : "Thanks are also due to Stephen Hardy and Giorgio Patrini for many stimulating discussions and feedback on the subject. NICTA is funded by the Australian Government through the Department of Communications and the Australian Research Council through the ICT Center of Excellence Program."
    }, {
      "heading" : "Appendix — Table of contents",
      "text" : "Proofs Pg 16 Proof of Theorem 2 Pg 16 Proof of Lemma 4 Pg 18 Proof of Lemma 6 Pg 19 Proof of Corollary 7 Pg 20 Proof of Lemma 8 Pg 21 Proof of Corollary 9 Pg 22 Proof of Lemma 10 Pg 24 Proof of Corollary 11 Pg 24 Proof of Lemma 12 Pg 25 Proof of Corollary 13 Pg 25 Proof of Theorem 14 Pg 25 Proof of Theorem 17 Pg 26 Proof of Theorem 18 Pg 28 Proof of Theorem 19 Pg 30 Proof of Theorem 20 Pg 31\nAdditional Experiments Pg 33 Supports for rados (complement to Table 2) Pg 33 Experiments on class-wise rados Pg 33 Test errors and supports for rados (comparison last vs best empirical classifier) Pg 33\n15"
    }, {
      "heading" : "9 Proofs",
      "text" : ""
    }, {
      "heading" : "9.1 Proof of Theorem 2",
      "text" : "We split the proof in two parts, the first concerning the case where both generators are differentiable since some of the derivations shall be used hereafter, and then the case where they are not. Remark that because of Lemma 4, we do not have to cover the case where just one of the two generators would be differentiable. Case 1: ϕe, ϕr are differentiable. We show in this case that being proportionate is equivalent to having:\np∗(z) = Gmq ∗(z) . (43)\nSolving eqs. (3) and (4) bring respectively:\np∗i (z) = ϕ ′ e −1\n(\n− 1 µe\n· zi ) , (44)\nq∗I (z) = ϕ ′ r −1\n(\n− 1 µr · ∑\ni∈I\nzi + λ\nµr\n)\n, (45)\nwhere λ is picked so that q∗(z) ∈ H2m , that is,\n∑\nI⊆[m]\nϕ′r −1\n(\n− 1 µr · ∑\ni∈I\nzi + λ\nµr\n)\n= 1 . (46)\nWe obtain\nL∗e (z) = −µe ∑\ni∈[m]\nϕ⋆e\n(\n− 1 µe\n· zi ) , (47)\nL∗r (z) = λ− µr ∑\nI⊆[m]\nϕr ⋆\n(\n− 1 µr · ∑\ni∈I\nzi + λ\nµr\n)\n, (48)\nwhere ϕ⋆(z) . = supz′{zz′ − ϕ(z′)} denotes the convex conjugate of ϕ. It follows from eq. (47) that:\n∂\n∂zi L∗e (z) = ϕ ⋆ e ′\n(\n− 1 µe\n· zi )\n= ϕ′e −1\n(\n− 1 µe\n· zi )\n(49)\n= p∗i (z) , (50)\n16\nwhere eq. (49) follows from properties of ϕ⋆. We also have\n∂\n∂zi L∗r (z)\n=\n\n1− ∑\nI⊆[m]\nϕ′r −1\n\n− 1 µr · ∑\nj∈I\nzj + λ\nµr\n\n\n\n · ∂λ ∂zi\n+ ∑\nI⊆[m]:i∈I\nϕ′r −1\n\n− 1 µr · ∑\nj∈I\nzj + λ\nµr\n\n\n= ∂λ\n∂zi\n+ ∑\nI⊆[m]\n(\n1i∈I − ∂λ\n∂zi\n)\nϕ′r −1\n\n− 1 µr · ∑\nj∈I\nzj + λ\nµr\n\n\n= ∂λ\n∂zi +\n∑\nI⊆[m]\n(\n1i∈I − ∂λ\n∂zi\n)\n· q∗I (z)\n= ∂λ\n∂zi ·\n\n1− ∑\nI⊆[m]\nq∗I (z)\n\n + ∑\nI⊆[m]\n1i∈I · q∗I (z)\n= ∑\nI⊆[m]\n1i∈I · q∗I (z) , (51)\nsince q∗(z) ∈ H2m . Now suppose ϕe and ϕr proportionate. It comes that there exists (µe,µr) such that the gradients of eq. (7) yield ∇L∗e (z) = ∇L∗r (z), and from eqs. (50) and (51) we obtain p∗(z) = Gmq∗(z). Reciprocally, having p∗(z) = Gmq∗(z) for some ϕe, ϕr and µe,µr > 0 implies as well ∇L∗e (z) = ∇L∗r (z) from eqs. (50) and (51), and therefore eq. (7) holds as well. This ends the proof of Case 1 for Theorem 2.\nCase 2: ϕe, ϕr are not differentiable. To simplify the statement and proofs, we assume that µe = µr = 1. We define the following problems\nLe(z) . = inf p∈Rm z⊤p+ ϕe(p) , (52) Lr(z) . = inf\nq∈H2m z⊤Gmq + ϕr(q) , (53)\nwhere ϕe : Rm → R and ϕr : R2 m → R are convex. Recall that ∂Le and ∂Lr are their subdifferentials, and p(z) and q(z) the arguments of the infima, assuming without loss of generality that they are finite. We now show that being proportionate is equivalent to having, for any z,\np(z) ∈ ∂Lr(z) , (54) Gmq(z) ∈ ∂Le(z) . (55)\nThis property is an immediate consequence of the following property, which we shall in fact show:\np(z) ∈ ∂Le(z) , (56) Gmq(z) ∈ ∂Lr(z) . (57)\n17\nGranted all (54—57) hold, Eq. (43) of Theorem 2 follows whenever subgradients are singletons. To see why the statement of the Theorem follows from (54–55), if the functions are proportionate, then their subdifferentials match from Definition 1 and we immediately get (54) and (55) from (56) and (57). If, on the other hand, we have both (54) and (55), then we get from (56) and (57) that ∂Le(z) ∩ ∂Lr(z) 6= ∅,∀z and so 0 ∈ ∂(Le(z) − Lr(z)), yieding the fact that the epigraphs of Le(z) and Lr(z) match by a translation of some b that does not depend on z, and by extension, the fact that ϕe and ϕr meet Definition 1 and are proportionate.\nTo show (56), we first remark that −z′ ∈ ∂ϕe(p(z′)) for any z′ because of the definition of p in (52). So, from the definition of subdifferentials, for any z,\nϕe(p(z ′)) + (−z′)⊤(p(z)− p(z′)) ≤ ϕe(p(z)) .\nReorganising and substracting z⊤p(z) to both sides, we get\n−ϕe(p(z′))− z′⊤p(z′) ≥ −ϕe(p(z))− z⊤p(z) + (−p(z))⊤(z′ − z) ,\nwhich shows that −p(z) ∈ ∂ − (ϕe(p(z)) + z⊤p(z)), and so p(z) ∈ ∂Le(z). We then tackle (57). We show that there exists λ ∈ R such that λ · 12m − G⊤mz ∈ ∂ϕr(q(z)) at the optimal q(z). Suppose it is not the case. Then because of the definition of subgradients, for any λ ∈ R, there exists q ∈ H2m, q 6= q(z) such that\nϕr(q(z)) + (λ · 12m − G⊤mz)⊤(q − q(z)) > ϕr(q) .\nReorganising and using the fact that q, q∗ ∈ H2 m , we get ϕr(q(z)) + z⊤Gmq(z) > ϕr(q) + z⊤Gmq, contradicting the optimality of q(z). Consider any z′ and its corresponding optimal q(z′). Since λ′ · 12m − G⊤mz ∈ ∂ϕr(q(z)) for some λ′ ∈ R, we get from the definition of subgradients that\nϕr(q(z))\n≥ ϕr(q(z′)) + (λ′ · 12m − G⊤mz′)⊤(q(z) − q(z′)) .\nReorganising and using the fact that q(z), q(z′) ∈ H2m , we get\n−(ϕr(q(z′)) + z′⊤Gmq(z′)) ≥ −(ϕr(q(z)) + z⊤Gmq(z))\n+(−Gmq(z))⊤(z′ − z) , (58)\nshowing that −Gmq(z) ∈ ∂ − (ϕr(q(z)) + z⊤Gmq(z)), and so Gmq(z) ∈ ∂Lr(z)."
    }, {
      "heading" : "9.2 Proof of Lemma 4",
      "text" : "Take m = 1, and replace z by real z1. We have Le(p, z1) = pz1+ϕe(z1) and Lr(q, z) = q{1}z1+ϕr(q{1})+ ϕr(q∅). Remark that we can drop the constraint q ∈ H2 since then q∅ = 1− q{1}. So we get\nL∗r (q) = min q∈R qz1 + µrϕr(q) + µrϕr(1− q)\n= min q∈R qz1 + µrϕs(r)(q) = −µrϕ⋆s(r) (\n− 1 µr\n· z1 ) ,\n18\nwhereas\nL∗e (p) = −µeϕ⋆r (\n− 1 µe\n· z1 ) ,\nand since ϕe and ϕr are proportionate, then\nϕ⋆r\n(\n− 1 µe\n· z1 ) = µr\nµe · ϕ⋆s(r)\n(\n− 1 µr\n· z1 )\n− b µe . (59)\nWe then make the variable change z . = −z1/µe and get\nϕ⋆e (z) = µr\nµe · ϕ⋆s(r)\n( µe\nµr · z\n)\n− b µe , (60)\nwhich yields, since ϕe, ϕr, and by extension ϕs(r), are all convex and lower-semicontinuous,\nϕe(z) = µr\nµe · ϕs(r)(z) +\nb\nµe , (61)\nas claimed."
    }, {
      "heading" : "9.3 Proof of Lemma 6",
      "text" : "We use the fact that whenever ϕ is differentiable, ϕ⋆(z) . = z ·ϕ′−1(z)−ϕ(ϕ′−1(z)). We have ϕ′r(z) = log z, ϕ′r −1(z) = exp z = ϕ⋆r (z). Therefore, the Lagrange multiplier λ in (46) is\nλ = −µr · log\n\n ∑\nI⊆[m]\nexp\n(\n− 1 µr · ∑\ni∈I\nzi\n)\n , (62)\nwhich yields from (54):\nq∗I (z) = exp\n(\n− 1 µr ·∑i∈I zi )\n∑ J⊆[m] exp ( − 1 µr ·∑j∈J zj ) ,∀I ⊆ [m] .\nOn the other hand, we also have ϕ′s(z) = log(z/(1 − z)), ϕ′s−1(z) = exp(z)/(1 + exp(z)) and ϕ⋆s (z) = 1 + log(1 + exp(z)), which yields from (94):\np∗i (z) = exp\n(\n− 1 µe\n· zi )\n1 + exp (\n− 1 µe\n· zi ) ,∀i ∈ [m] . (63)\n19\nWe then check that for any i ∈ [m], we indeed have ∑\nI⊆[m]\n1i∈I · q∗I (z)\n= ∑\nI⊆[m]\n1i∈I · exp\n(\n− 1 µr ·∑i′∈I zi′ )\n∑ J⊆[m] exp ( − 1 µr ·∑j∈J zj )\n= exp\n(\n− 1 µe\n· zi ) · ∑\nJ⊆[m]\\{i} exp ( − 1 µr ·∑j∈I zj )\n∑ J⊆[m] exp ( − 1 µr ·∑j∈J zj )\n= exp\n(\n− 1 µe\n· zi )\n· c( 1 + exp (\n− 1 µe\n· zi )) · c\n= exp\n(\n− 1 µr\n· zi )\n1 + exp (\n− 1 µr\n· zi ) , (64)\nwith c . =\n∑ J⊆[m]\\{i} exp ( − 1 µr ·∑j∈I zj ) . We check that eq. (64) equals eq. (63) whenever µe = µr.\nHence eq. (43) holds. We conclude that ϕr and ϕe = ϕs are proportionate whenever µe = µr."
    }, {
      "heading" : "9.4 Proof of Corollary 7",
      "text" : "Consider ϕr(z) . = z log z − z and ϕe = ϕs. We obtain from eq. (47):\n−L∗e (z)\n= fe\n  ∑\ni∈[m]\nlog\n(\n1 + exp\n(\n− 1 µe\n· zi ))\n\n ,\nwith fe(z) = µe ·z+µem. We have also ϕ⋆r (z) = exp(z), and so using λ in eq. (62) and eq. (48), we obtain\n−L∗r (z)\n= µr · log\n\n ∑\nI⊆[m]\nexp\n(\n− 1 µr · ∑\ni∈I\nzi\n)\n\n+µr · exp ( λ\nµr\n)\n· ∑\nI⊆[m]\nexp\n(\n− 1 µr · ∑\ni∈I\nzi\n)\n= µr · log\n  ∑\nI⊆[m]\nexp\n(\n− 1 µr · ∑\ni∈I\nzi\n)\n\n+µr · ∑\nI⊆[m] exp ( − 1 µr ·∑i∈I zi )\n∑ I⊆[m] exp ( − 1 µr ·∑i∈I zi ) ︸ ︷︷ ︸\n=1\n= fr\n  ∑\nI⊆[m]\nexp\n(\n− 1 µr · ∑\ni∈I\nzi\n)\n ,\n20\nwith fr(z) = µr · log z+µr. We get from Lemma 6 that the following example and rado risks are equivalent whenever µe = µr:\nℓe(z,µe) = ∑\ni∈[m]\nlog\n(\n1 + exp\n(\n− 1 µe\n· zi )) , (65)\nℓr(z,µr) = ∑\nI⊆[m]\nexp\n(\n− 1 µr · ∑\ni∈I\nzi\n)\n, (66)\nfrom which we get the statement of the Corollary by fixing µ = µe = µr."
    }, {
      "heading" : "9.5 Proof of Lemma 8",
      "text" : "We proceed as in the proof of Lemma 6. We have ϕ′r(z) = z, ϕ ′ r −1(z) = z and ϕ⋆r (z) = ϕr(z). Therefore, the Lagrange multiplier λ in (46) is\nλ = µr\n2m +\n1 2m · ∑\nI⊆[m]\n∑\ni∈I\nzi (67)\n= µr\n2m +\n1 2 · ∑\ni∈[m]\nzi , (68)\nsince any i belongs exactly to half of the subsets of [m]. We obtain:\nq∗I (z) = 1 2m − 1 µr · ∑\ni∈I\nzi + 1 2µr · ∑\ni∈[m]\nzi ,∀I ⊆ [m] .\nOn the other hand, we also have ϕ′s(z) = 2z−1, ϕ′s−1(z) = (1+z)/2 and ϕ⋆s (z) = −(1/4)+(1/4)·(1+z)2 , which yields from (94):\np∗i (z) = 1 2 · ( 1− 1 µe · zi ) ,∀i ∈ [m] . (69)\n21\nWe then check that for any i ∈ [m], we have ∑\nI⊆[m]\n1i∈I · q∗I (z)\n= ∑\nI⊆[m]\n1i∈I ·\n\n 1 2m − 1 µr · ∑\ni∈I\nzi + 1 2µr · ∑\ni∈[m]\nzi\n\n\n= 1 2 − 1 µr · ∑\nI⊆[m]\n1i∈I · ∑\ni∈I\nzi + 2m−2 µr · ∑\ni∈[m]\nzi\n= 1 2 − 2\nm−1\nµr · zi −\n1 µr ·\n∑\nI⊆[m]\\{i}\n∑\ni∈I\nzi\n+ 2m−2 µr · ∑\ni∈[m]\nzi\n= 1 2 − 2\nm−1\nµr · zi −\n2m−2\nµr ·\n∑\ni∈[m]\\{i}\nzi\n+ 2m−2 µr · ∑\ni∈[m]\nzi\n= 1 2 − 2\nm−1\nµr · zi +\n2m−2\nµr · zi\n= 1\n2\n(\n1− 2 m−1\nµr · zi\n)\n. (70)\nWe check that eq. (70) equals eq. (69) whenever µe = µr/2m−1. Hence eq. (43) holds. We conclude that ϕr is proportionate to ϕe = ϕs whenever µe = µr/2m−1."
    }, {
      "heading" : "9.6 Proof of Corollary 9",
      "text" : "Consider ϕr(z) . = (1/2) · z2 and ϕe = ϕs. We obtain from eq. (47):\n−L∗e (z)\n= fe\n\n ∑\ni∈[m]\n(\n1− 1 µe\n· zi )2\n\n ,\n22\nwith fe(z) = (µe/4) · z + (µem/4). We have also ϕ⋆r (z) = (1/2) · z2, and so using eq. (48) and λ in eq. (67), we obtain\n−L∗r (z)\n= − µr 2m − 1 2m · ∑\nI⊆[m]\n∑\ni∈I\nzi\n+ 1\n2µr\n∑\nI⊆[m]\n  ∑\ni∈I\nzi − µr 2m − 1 2m · ∑\nI⊆[m]\n∑\ni∈I\nzi\n\n\n2\n= − µr 2m − 1 2m · ∑\nI⊆[m]\n∑\ni∈I\nzi + µr\n2m+1\n− 1 2m · ∑\nI⊆[m]\n  ∑\ni∈I\nzi − 1 2m · ∑\nI⊆[m]\n∑\ni∈I\nzi\n\n\n︸ ︷︷ ︸\n=0\n+ 1\n2µr\n∑\nI⊆[m]\n  ∑\ni∈I\nzi − 1 2m · ∑\nI⊆[m]\n∑\ni∈I\nzi\n\n\n2\n= − µr 2m+1 − 1 2m · ∑\nI⊆[m]\n∑\ni∈I\nzi\n+ 2m−1 µr · 1 2m · ∑\nI⊆[m]\n  ∑\ni∈I\nzi − 1 2m · ∑\nI⊆[m]\n∑\ni∈I\nzi\n\n\n2\n= − µr 2m+1\n−EI∼[m] [ ∑\ni∈I\nzi\n]\n+ 2m−1\nµr · VI∼[m]\n[ ∑\ni∈I\nzi\n]\n= − µr 2m+1\n+ µr\n2m−1 ·\n\n−\n\n EI∼[m]\n[ 2m−1\nµr ·∑i∈I zi\n]\n− µr2m−1 · VI∼[m] [ 2m−1 µr ∑ i∈I zi ]\n\n\n\n\n= fr\n\n−\n\n EI∼[m]\n[ 2m−1\nµr ·∑i∈I zi\n]\n− µr 2m−1 · VI∼[m] [ 2m−1 µr ∑ i∈I zi ]\n\n\n\n , (71)\n23\nwith fr(z) = (µr/2m−1) · z − (µr/2m+1). Therefore, it comes from Lemma 8 that the following example and rado risks are equivalent whenever µe = µr/2m−1:\nℓe(z,µe) = ∑\ni∈[m]\n(\n1− 1 µe\n· zi )2 ,\nℓr(z,µr) = − ( EI [ 2m−1\nµr · ∑\ni∈I\nzi\n]\n− µr 2m−1\n· VI [ 2m−1\nµr · ∑\ni∈I\nzi\n])\n.\nThere remains to fix µ . = µe = µr/2 m−1 to obtain the statement of the Corollary."
    }, {
      "heading" : "9.7 Proof of Lemma 10",
      "text" : "Define △d as the d-dimensional probability simplex. Then it comes with that choice of ϕr(qI): min\nq∈H2m Lr(q,z)\n= min q∈△2m\n∑\nI⊆[m]\nqI ∑\ni∈I\nzi\n=\n{ 0 if ∑\ni∈I zi > 0,∀I 6= ∅ ,∑ i:zi<0 zi otherwise , (72)\nsince whenever no zi is negative, the minimum is achieved by putting all the mass (1) on q∅, and when some are negative, the minimum is achieved by putting all the mass on the smallest over all I of ∑\ni∈I zi, which is the one which collects all the indexes of the negative coordinates in z.\nOn the other hand, remark that fixing ϕe . = ϕs still yields ϕe(z) = χ[0,1](z) = ϕr(z), yet this time we\nhave the following on Le(p,z):\nmin p∈Rm Lr(q,z) = min p∈[0,1]m\n∑\ni∈[m]\npizi\n= −µe · ∑\ni∈[m]\nmax\n{\n0,− 1 µe\n· zi } , (73)\nsince the optimal choice for p∗i is to put 1 only when zi is negative. We obtain p ∗(z) = Gmq ∗(z) for any choice of µe,µr, and so ϕr(z) is self-proportionate for any µe,µr. This ends the proof of Lemma 10."
    }, {
      "heading" : "9.8 Proof of Corollary 11",
      "text" : "We obtain from Lemma 10 that −L∗r (z) = fr(ℓr(z,µr)) with fr(z) = µr · z and:\nℓr(z,µr) = max\n{\n0, max I⊆[m]\n{\n− 1 µr · ∑\ni∈I\nzi\n}}\n. (74)\nOn the other hand, it comes from eq. (73) that −L∗e (z) = fr(ℓe(z,µe)) with fe(z) = µe · z and:\nℓe(z,µe) = ∑\ni∈[m]\nmax\n{\n0,− 1 µe\n· zi } . (75)\nThis concludes the proof of Corollary 11.\n24"
    }, {
      "heading" : "9.9 Proof of Lemma 12",
      "text" : "The choice of\nϕr(z) = χ[ 12m , 1 2 ] (z) , (76)\nunder the constraint that q ∈ H2m , enforces q∗ I = 1/2m,∀I ⊆ [m]. Furthermore, fixing ϕe .= ϕs indeed yields\nϕe = χ[ 12m , 1 2 ] (z) + χ[ 12m , 1 2 ] (1− z)\n= χ{ 12}(z) , (77)\nwhich enforces p∗i = 1/2, ∀i. Since each i belongs to exactly 2m−1 subsets of [m], we obtain p∗(z) = Gmq ∗(z), for any µe,µr, and so ϕr is proportionate to ϕe = ϕs for any µe,µr."
    }, {
      "heading" : "9.10 Proof of Corollary 13",
      "text" : "We obtain from Lemma 12 that −L∗r (z) = fr(ℓr(z,µr)) with fr(z) = z and:\nℓr(z,µr) = EI\n[\n− 1 µr · ∑\ni∈I\nzi\n]\n.\nOn the other hand, it comes from eq. (73) that −L∗e (z) = fr(ℓe(z,µe)) with fe(z) = (1/2) · z and:\nℓe(z,µe) = ∑\ni\n− 1 µe · zi .\nThis concludes the proof of Corollary 11."
    }, {
      "heading" : "9.11 Proof of Theorem 14",
      "text" : "The key to the poof is the constraint q ∈ Hm in eq. (4). Since fe(z) = ae · z + be, we have L∗e (z) = ae · (ℓe(z) +ω) + be − ae ·ω for any ω ∈ R. It follows from eq. (7) that ae · (ℓe(z) +ω) + be − ae ·ω = L∗r (z) + b = ∑ I⊆[m] q ∗ I ∑ i∈I zi + µr ∑ I⊆[m] ϕr(q ∗ I ) + b, and so\nae · (ℓe(z) +ω) + be\n= −\n   min q∈Hm   ∑\nI⊆[m]\nqI ∑\ni∈I\nzi + µr ∑\nI⊆[m]\nϕr(qI)\n\n − aeω\n \n\n+b\n= − min q∈Hm\n\n ∑\nI⊆[m]\nqI\n( ∑\ni∈I\nzi − aeω ) + µr ∑\nI⊆[m]\nϕr(qI)\n\n\n+b ,\nsince q ∈ Hm and ae,ω, a are not a function of q. We thus get ae · (ℓe(z) +ω) + be = ar · fr ( ℓ̃r(z) ) + br, where ℓ̃r(z) equals ℓr(z) in which each ∑ i∈I zi is replaced by ∑\ni∈I zi − aeω. For zi = θ⊤(yi · xi) and ω = Ω(θ), we obtain that whenever θ 6= 0, ∀I ⊆ [m],\n∑\ni∈I\nzi + aeω = θ ⊤\n(\nπσ − aeΩ(θ)\n‖θ‖22 · θ\n)\n, (78)\nfor σi = yi iff i ∈ I (and −yi otherwise), and the statement of the Theorem follows.\n25"
    }, {
      "heading" : "9.12 Proof of Theorem 17",
      "text" : "The proof of the Theorem contains two parts, the first of which follows ADABOOST’s exponential convergence rate proof, and the second departs from this proof to cover Ω-R.ADABOOST.\nWe use the fact that αι(t)πjι(t) = αι(t) · 1⊤ι(t)πj = (θT − θT−1)⊤πj to unravel the weights as:\nwTj\n= w(T−1)j\nZT · exp\n( −αι(T )πjι(T ) + δT )\n= w(T−1)j\nZT · exp ( −(θT − θT−1)⊤πj +ω · (‖θT ‖22 − ‖θT−1‖22) )\n= w(T−1)j\nZT · exp ( −θ⊤T (πj −ω · θT ) +θ⊤T−1 (πj −ω · θT−1) )\n= w0\n∏T t=1 Zt\n· exp (\n−θ⊤T (πj −ω · θT ) +θ⊤0 (πj −ω · θ0)\n)\n(79)\n= w0\n∏T t=1 Zt\n· exp ( −θ⊤T (πj −ω · θT ) ) , (80)\nsince the sums telescope in eq. (79) when we unravel the weight update and θ0 = 0. We therefore get\nℓexpr (Sr,θ, ‖.‖22) = T∏\nt=1\nZt , (81)\nas in the classical ADABOOST analysis (Schapire & Singer, 1999). This time however, we have, letting π̃jι(t) . = πjι(t)/π∗ι(t) ∈ [−1, 1] and α̃ι(t) . = π∗ι(t) · αt for short,\nZt+1\n= ∑\nj∈[n]\nwtj · exp ( −αι(t)πjι(t) + δt )\n= exp(δt) · ∑\nj∈[n]\nwtj · exp ( −αι(t)πjι(t) )\n= exp(δt) · ∑\nj∈[n]\nwtj · exp ( −α̃ι(t)π̃jι(t) )\n≤ exp(δt) 2\n· ∑\nj∈[n]\nwtj · ( (1 + π̃jι(t)) · exp ( −α̃ι(t) )\n+(1− π̃jι(t)) · exp ( α̃ι(t) )\n)\n(82)\n= exp(δt) · √ 1− r2t (83)\n= exp\n(\nω · (‖θt‖22 − ‖θt−1‖22)− 1\n2 ln\n1\n1− r2t\n)\n.\nThis is where our proof follows a different path from ADABOOST’s: in eq. (83), we do not upperbound the √\n1− r2t term, so it can absorb more easily the new exp(δt) factor which appears because of regularization. Ineq. (82) holds because of the convexity of exp, and eq. (83) is an equality when rt < γ. If rt > γ is\n26\nclamped to rt ← γ by the weak learner in (31), then we have instead the derivation ∑\nj∈[n]\nwtj · ( (1 + π̃jι(t)) · exp ( −α̃ι(t) )\n+(1− π̃jι(t)) · exp ( α̃ι(t) )\n)\n= (1 + rt) · √ 1− γ 1 + γ + (1− rt) · √ 1 + γ\n1− γ ≤ 2 √ 1− γ2 , (84)\nsince function in (84) is decreasing on rt > 0. If rt < −γ is clamped to rt ← −γ, we get the same conclusion as in ineq (84) because this time α̃ι(t) = (1/2) · ln((1 − γ)/(1 + γ)). Summarising, whether rt has been clamped or not by the weak learner in (31), we get\nZt+1\n≤ exp ( ω · (‖θt‖22 − ‖θt−1‖22)− 1\n2 ln\n1\n1− r2t\n)\n, (85)\nwith the additional fact that |rt| ≤ γ. For any feature index k ∈ [d], let Fk ⊆ [T ] the iteration indexes for which ι(t) = k. Letting λΓ (> 0) the largest eigenvalue of Γ , we obtain:\nT∏\nt=1\nZt\n≤ exp ( ω · ‖θT ‖2Γ − ∑\nt\n1 2 log 1\n1− r2t\n)\n≤ exp ( ωλΓ · ‖θT ‖22 − ∑\nt\n1 2 log 1\n1− r2t\n)\n= exp\n −1 2 · ∑\nk∈[d]\nΛk\n\n , (86)\nWith\nΛk . = log 1 ∏\nt:ι(t)∈Fk (1− r2t )\n−ωλΓ 2π2∗k log2 ∏\nt:ι(t)∈Fk\n( 1 + rt 1− rt ) . (87)\nSince ( ∑u l=1 al) 2 ≤ u∑ul=1 a2l and mink maxj |πjk| ≤ |π∗k|, Λk satisfies:\nΛk ≥ ∑\nt:ι(t)∈Fk\n{\nlog 1\n1− r2t\n−TkωλΓ 2M2 log2 1 + rt 1− rt\n}\n, (88)\nwith Tk . = |Fk| and M .= mink maxj |πjk|. For any a > 0, let\nfa(z) . =\n1 az2 · ( log 1 1− z2 − a · log 2 1 + z 1− z ) − 1 .\n27\nIt satisfies\nfa(z) ≈0 ( 1\na − 5\n)\n+\n( 1\n2a − 8 3\n)\n· z2\n+\n( 1\n3a − 92 45\n)\n· z4 + o(z4) . (89)\nSince fa(z) is continuous for any a 6= 0, ∀0 < a < 1/5, ∃z∗(a) > 0 such that fa(z) ≥ 0,∀z ∈ [0, z∗]. So, for any such a < 1/5 and any ω satisfying ω < (2aM2)/(TkλΓ), as long as each rt ≤ z∗(a), we shall obtain\nΛk ≥ a ∑\nt:ι(t)∈Fk\nr2t . (90)\nThere remains to tune γ ≤ z∗(a), and remark that if we fix a = 1/7, then numerical calculations reveal that z∗(a) > 0.98, and if a = 1/10 then numerical calculations give z∗(a) > 0.999, completing the statement of Theorem 17."
    }, {
      "heading" : "9.13 Proof of Theorem 18",
      "text" : "We consider the case Ω(.) = ‖.‖∞, from which we shall derive the case Ω(.) = ‖.‖1. We proceed as in the proof of Theorem 17, with the main change that we have now δt = ω · (‖θt‖∞ − ‖θt−1‖∞), so in place of Λk in ineq . (86) we have to use, letting k∗ any feature that gives the ℓ∞ norm,\nΛk . =\n \n\n∑\nt:ι(t)∈Fk log 1\n1−r2 t\n− ω π∗k\n∣ ∣ ∣ ∑\nt:ι(t)∈Fk log 1+rt1−rt\n∣ ∣ ∣ if k = k∗ ∑\nt:ι(t)∈Fk log 1\n1−r2 t\notherwise\n. (91)\nIt also comes\nΛk∗\n≥ ∑\nt:ι(t)∈Fk∗\n{\nlog 1 1− r2t − ω π∗k∗ log 1 + |rt| 1− |rt|\n}\n≥ ∑\nt:ι(t)∈Fk∗\n{\nlog 1 1− r2t − ω M log 1 + |rt| 1− |rt|\n}\n, (92)\nwith M . = mink maxj |πjk|. Let us analyze Λk∗ and define for any b > 0\ngb(z) . = log\n1 1− z2 − b · log 1 + z 1− z\n− ( −2bz + z2 − 2bz 3\n3\n)\n. (93)\nInspecting gb shows that gb(0) = 0, g′b(0) = 0 and gb(z) is convex over [0, 1) for any b ≤ 3, which shows that gb(z) ≥ 0, ∀z ∈ [0, 1), ∀b ≤ 3, and so, after dividing by bz2 and reorganising, yields in these cases:\n1 bz2 · ( log 1 1− z2 − b · log 1 + z 1− z ) − 1\n≥ (\n−2 z +\n( 1\nb − 1\n)\n− 2z 3\n)\n. (94)\n28\nHence, both functions being continuous on (0, 1), the function in the left-hand side zeroes before the one in the right-hand side (when this one does on (0, 1)). The zeroes of the polynomial\npb(z) . = −2z\n2\n3 +\n( 1\nb − 1\n)\nz − 2 (95)\nexist iff b ≤ √ 3/(4 + √ 3), in which case any z ∈ [0, 1) must satisfy\nz ≥ 3 4 ·\n\n 1\nb − 1−\n√ ( 1\nb − 1\n)2\n− 16 3\n\n (96)\nto guarantee that pb(z) ≥ 0. Whenever this happens, we shall have from (94):\nlog 1 1− z2 − b · log 1 + z 1− z ≥ bz 2 . (97)\nSince Ω-WL is a γWL-weak learner, if we can guarantee that the right-hand side of ineq. (96) is no more than γWL, then there is nothing more to require from the weak learner to have ineq. (97) — and therefore to have Λk∗ ≥ bγ2WL · |Fk∗ |. This yields equivalently the following constraint on b:\nb ≤ 8γWL 3\n16γ2WL 9 + 8γWL 3 + 16 3\n. (98)\nSince γWL ≤ 1, ineq (98) ensured as long as\nb ≤ 8γWL 3\n16 9 + 8 3 + 16 3\n= 3γWL 11 , (99)\nwhich also guarantees b ≤ √ 3/(4 + √ 3). So, letting T∗ . = |Fk∗ | and recollecting\nb . =\nω\nmink maxj |πjk| (100)\nfrom eq. (92), we obtain from ineqs (92) and (97):\nΛk∗ ≥ ωT∗γ\n2 WL\nmink maxj |πjk| . (101)\nWe need to ensure ω ≤ 3mink maxj |πjk|γWL/11 from ineq . (99), which holds if we pick it according to eq. (36). In this case, we finally obtain\nΛk∗ ≥ (aγWLT∗) · γ2WL . (102) Now, since log(1/(1 − x2)) ≥ x2, we also have for k 6= k∗ in eq. (91),\nΛk = ∑\nt:ι(t)∈Fk\nlog 1\n1− r2t\n≥ ∑\nt:ι(t)∈Fk\nr2t\n≥ |Fk|γ2WL ,∀k 6= k∗ . (103) So, we finally obtain from eq. (84) and ineq. (86),\nℓexpr (Sr,θ, ‖.‖22) ≤ exp ( − T̃γ 2 WL\n2\n)\n, (104)\nwith T̃ . = (T − T∗) + aγWL · T∗, as claimed when Ω(.) = ‖.‖∞. The case Ω = ‖.‖1 follows form the fact that all Λk match the bound of Λk∗ .\n29"
    }, {
      "heading" : "9.14 Proof of Theorem 19",
      "text" : "We use the proof of Theorem 18, since when Ω(.) = ‖.‖Φ, eq. (91) becomes\nΛk . =\n∑\nt:ι(t)∈Fk\nlog 1\n1− r2t (105)\n− ξk π∗k ∣ ∣ ∣ ∣ ∣ ∣ ∑\nt:ι(t)∈Fk\nlog 1 + rt 1− rt ∣ ∣ ∣ ∣ ∣ ∣\n≥ ∑\nt:ι(t)∈Fk\n{\nlog 1 1− r2t − ξk maxj |πjk| log 1 + |rt| 1− |rt|\n}\n, (106)\nassuming without loss of generality that the classifier at iteration T , θT , satisfies |θTk| ≥ |θT (k+1)| for k = 1, 2, ..., d − 1. We recall that ξk .= Φ−1(1 − kq/(2d)) where Φ−1(.) is the quantile of the standard normal distribution and q ∈ (0, 1) is the user-fixed q-value. The constraint b ≤ 3γWL/11 from ineq. (99) now has to hold with\nb = bk . = ξk maxj |πjk| . (107)\nNow, fix\na . = min { 3γWL 11 , Φ−1(1− q/(2d)) mink maxj |πjk| } . (108)\nRemark that\nξk . = Φ−1\n(\n1− kq 2d\n)\n≥ Φ−1 ( 1− q 2d ) ≥ amin k′ max j |πjk′ | . (109)\nSuppose q is chosen such that\nξk ≤ 3γWL 11 ·max j |πjk| ,∀k ∈ [d] . (110)\nThis ensures bk ≤ 3γWL/11 (∀k ∈ [d]) in ineq. (99), while ineq. (109) ensures\nΛk ≥ bk ∑\nt:ι(t)∈Fk\nr2t (111)\n≥ ξk mink′ maxj |πjk′ | · ∑\nt:ι(t)∈Fk\nr2t (112)\n≥ a|Fk|γ2WL . (113)\nIneq. (111) holds because of ineqs (106) and (97). Ineq. (113) holds because of the weak learning assumption and ineq. (110). So, we obtain, under the weak learning assumption,\nℓexpr (Sr,θ, ‖.‖Φ) ≤ exp ( −aTγ 2 WL\n2\n)\n. (114)\n30\nEnsuring ineq. (110) is done if, after replacing ξk by its expression and reorganising, we can ensure\nq ≥ 2 ·max k qN,k qD,k , (115)\nwith\n(0, 1) ∋ qN,k .= 1−Φ ( 3γWL 11 ·max j |πjk| ) , (116)\n(0, 1] ∋ qD,k .= k\nd . (117)\n(118)"
    }, {
      "heading" : "9.15 Proof of Theorem 20",
      "text" : "Suppose wlog that the example index on which Se and S′e differ is m, and let em and e ′ m denote the two distinct edge vectors of the neighbouring datasets. For n = 1, let π denote a rado created from first picking uniformly at random I ∈ 2m and then using DP-RADOS on the singleton Sr .= {πI} with:\nπI . =\n∑\ni∈I\nyi · xi . (119)\nLet a(Se) . =\n∑\nI′⊆[m−1] µ(π|π1 = πI′ , S = Se), where µ(π|.) is the density of the singleton output of DP-RADOS, and b(Se) . = ∑ I′⊆[m],m∈I µ(π|π1 = πI′ , S = Se). We have:\nµ(π|Se) µ(π|S′e) = a(Se) + b(Se) a(S′e) + b(S ′ e)\n= a(Se) + b(Se)\na(Se) + b(S′e) (120)\n≤ max { b(Se) b(S′e) , b(S′e) b(Se) } . (121)\nEq. (120) follows from the fact that when I′ ⊆ [m− 1], µ(π|π1 = πI′ , S = Se) = µ(π|π1 = πI′ , S = S′e). Now, for any fixed I′ ⊆ [m] such that m ∈ I′, we have\nµ(π|π1 = πI′ , S = Se) . = ( ε\n2re\n)d\nexp(−ε · ‖πI′ − π‖1/re)\n=\n( ε\n2re\n)d\nexp(−ε · ‖π′I′ − π+ em − e′m‖1/re) (122)\n≤ ( ε\n2re\n)d\nexp\n(\n− ε re\n· ‖π′I′ − π‖1 )\n︸ ︷︷ ︸ . =µ(π|π1=πI′ ,S=S ′ e) · exp ( ε\nre · ‖em − e′m‖1\n)\n= exp\n( ε\nre · ‖em − e′m‖1\n)\n·µ(π|π1 = πI′ , S = S′e) .\n31\nwhere π′ I′ . = πI′ − em + e′m in eq. (122) is the rado that is created from the same I′ but using S′e and its potentially different example e′m. The inequality holds because of the triangle inequality. Since ‖em − e′m‖1 ≤ re by assumption, we get µ(π|π1 = πI′ , S = Se) ≤ exp(ε) · µ(π|π1 = πI′ , S = S′e), and so, summing over all I′ ⊆ [m] such that m ∈ I′, we get b(Se)/b(S′e) ≤ exp(ε). Furthermore, we also have by symmetry b(S′e)/b(Se) ≤ exp(ε). So the delivery of one rado is ε-differentially private. The composition Theorem (Dwork & Roth, 2014) achieves the proof of the first point of Theorem 20. To prove the second point, we first define the (unregularized) log-loss,\nℓloge (Se,θ) . =\n1 m · ∑\ni\nlog ( 1 + exp ( −θ⊤(yi · xi) )) . (123)\nWe exploit the following inequalities that hold for the log-loss and exp-rado loss:\n1\nm · log ℓexpr (S∗,DPr ,θ)\n= 1 m · log 1 2m\n∑\nσ∈Σm\nexp ( −θ⊤ (πσ + zσ) )\n≤ 1 m\n· log (( 1\n2m\n∑\nσ∈Σm\nexp ( −θ⊤πσ ) ) · ( ∑\nσ∈Σm\nexp ( −θ⊤zσ ) ))\n(124)\n= 1 m · log 1 2m\n∑\nσ∈Σm\nexp ( −θ⊤πσ ) + 1\nm · log\n∑\nσ∈Σm\nexp ( −θ⊤zσ )\n= log 2 + 1 m · log 1 2m\n∑\nσ∈Σm\nexp ( −θ⊤πσ ) + 1 m · log 1 2m ∑\nσ∈Σm\nexp ( −θ⊤zσ )\n≤ log 2 + 1 m · log 1 2m\n∑\nσ∈Σm\nexp ( −θ⊤πσ ) + 1\nm max σ\nθ⊤zσ\n≤ log 2 + 1 m · log 1 2m\n∑\nσ∈Σm\nexp ( −θ⊤πσ ) + 1\nm max σ\nΩ⋆(zσ)Ω(θ) (125)\n= ℓloge (Se,θ) + 1\nm max σ\nΩ⋆(zσ)Ω(θ) (126)\n= ℓloge\n(\nSe,θ, (1/m) ·max σ\nΩ⋆(zσ) · Ω ) ,\nwhere ineq. (124) comes from the fact that ∑ i aibi ≤ ( ∑ i ai)( ∑\ni bi) when all ai, bi ≥ 0, ineq. (125) is Cauchy-Schwartz and eq. (126) is Lemma 2 in (Nock et al., 2015).\nRemarks on εa: let us explain why the protection of examples using the same noise level as rados is conservative but in fact necessary in the worst case, considering for simplicity the protection of a single rado / example. The proof of Theorem 20 exploits a conservative upperbound for the likelihood ratio:\nµ(π|Se) µ(π|S′e) = a(Se) + b(Se) a(Se) + b(S′e) ≤ max\n{ b(Se)\nb(S′e) , b(S′e) b(Se)\n}\n, (127)\nand then upperbounds the max by exp ε to get the DP requirement. The same strategy can be used to protect the example, but the bound is sometimes more conservative in this case. Indeed, whereas one examples participates in generating half the total number of DP rados, one example participates in only 1/m of the\n32\ngeneration of DP examples. For a single DP example e, the equality in (127) becomes µ(e|Se)/µ(e|S′e) = (a′(Se) + b ′(Se)/(a ′(Se) + b ′(S′e) with a ′(Se) . = (1 − (1/m)) · µ(e|Se\\{em}) and:\nb′(Se) . =\n1\nm · µ(e|{em}) , b′(S′e) . =\n1\nm · µ(e|{e′m}) . (128)\nLet u . = µ(e|{e′m})/µ(e|S′e\\{e′m}) (= µ(e|{e′m})/µ(e|Se\\{em})). If we use the same amount of protection as for one rado, then we get\nµ(e|Se) µ(e|S′e) ≤ fu(ε) , (129)\nwhere ε is the rado privacy budget and\nfu(ε) . = (m− 1) + u exp(ε) m− 1 + u . (130)\nfu(ε) is always < exp(ε), so if we use this exp(ε) bound to pick the noise level, then we are in fact putting more protection over examples than necessary (remember that the protection is also conservative for rados, but to a lesser extent). However, this choice would not be so bad in the worst case since limu→∞ fu(ε) = exp(ε). To summarise, without constraints on u, and to be sure to meet the DP requirements in any case, we would err on the conservative side, as we did for rados in ineq. (121), and pick εe = ε, i.e. the same amount of noise for examples. Yet, as we explain in the body of the paper, the results are exceedingly in favor of Ω-R.ADABOOST in this case. To give a more balanced picture, we chose to compute an “approximate” privacy budget εe = εa for n examples, which we simply fix to be εa . = n · ln(fu .=1(ε/n)) (< ε) where ε is the privacy budget for n rados. So, we have\nεa = n · ln ( 1 + exp(ε/n) − 1\nm\n)\n. (131)\nAgain, when u > 1, fixing ε = εa to protect examples would fail to achieve ε-differential privacy. Nevertheless, one can reasonably consider that the “optimal” differentially private picture of ADABOOST shall thus be representable as a stretching of its curves in between the figures for εa and ε."
    }, {
      "heading" : "10 Additional experiments",
      "text" : ""
    }, {
      "heading" : "10.1 Supports for rados (complement to Table 2)",
      "text" : "Table 4 in this Appendix provides the supports used to summarize Table 2.\n10.2 Experiments on class-wise rados\nTables 5 and 6 provide the test errors and supports for Ω-R.ADABOOST when trained with class-wise rados, that is, rados that sum examples of the same class. The experiments do not display that class-wise rados allow for a better training of Ω-R.ADABOOST, as test errors are on par with Ω-R.ADABOOST trained with plain random rados (see Table 2)."
    }, {
      "heading" : "10.3 Test errors and supports for rados (comparison last vs best empirical classifier)",
      "text" : "In the paper’s main experiments, the classifier kept out of the sequence, for both ADABOOST and ΩR.ADABOOST, is the best empirical classifier, that is, the classifier which minimizes the empirical risk\n33\nout of the training sample. This setting makes sense if the objective is just the minimization of the test error without any constraint, and it is also applicable in a privacy setting where the data and the learner are distant parties (in this case, the learner sends the sequence of classifiers θ1,θ2, ...,θT to the party holding the data, which can then select the best in the sequence). Yet, one may wonder how the algorithms compare when the classifier returned is just the last one in the sequence, that is, θT .\nTables 7 and 8 provide errors and supports comparing the versions of Ω-R.ADABOOST when the best empirical classifier is selected (⋆), or when the last classifier in the sequence is kept (†). They are therefore subsuming Tables 2 (for test errors) and 4 (for supports).\nThe intuition tells that not selecting the classifier in the sequence produced (†) should produce either no better, or eventually worse results than when selecting the classifier to keep from the sequence θ0,θ1, ...,θT . The results display that it is the case, for both ADABOOST and Ω-R.ADABOOST, and the phenomenon is more visible as the domain size increases. The degradation for Ω-R.ADABOOST appears to be significantly worse than that for ADABOOST on three domains, Fertility, Firmteacher and Kaggle, since not selecting the classifier using the training data incurs an increase of 8% and more on the test error for these domains. However, for the majority of the domains, the variation in test error does not exceed 1%, and on three domains (Winewhite, Smartphone, Eeg), the absence of selection of the classifier actually does not increase the test error at all.\nTherefore, even when not marginal, the fact that the test error significantly increases only on a minority of the domains for Ω-R.ADABOOST calls for a rather domain-specific selection procedure of the classifier in the sequence, rather than an all-purpose selection procedure. Furthermore, on domains for which not selecting the classifier produces the worst results, such a more efficient selection procedure of the classifier might actually be bypassed by a more careful crafting of the rados, since when class-wise random rados are used (results not shown), picking the last classifier for domain Kaggle reduces the test error by approximately 10% compared to random rados (the test error drops to 32.68±10.9 instead of 42.41±9.32 for SLOPE). Such a specific crafting of rados is an interesting and non trivial problem that deserves further attention.\n34\n35\n36\n37\n38\n39\n40"
    } ],
    "references" : [ {
      "title" : "Optimization with sparsity-inducing penalties",
      "author" : [ "F. Bach", "R. Jenatton", "J. Mairal", "G. Obozinski" ],
      "venue" : "Foundations and Trends in Machine Learning,",
      "citeRegEx" : "Bach et al\\.,? \\Q2011\\E",
      "shortCiteRegEx" : "Bach et al\\.",
      "year" : 2011
    }, {
      "title" : "SLOPE – adaptive variable selection via convex optimization",
      "author" : [ "M Bogdan", "E. van den Berg", "C. Sabatti", "W. Su", "Candès", "E.-J" ],
      "venue" : "Annals of Applied Statistics,",
      "citeRegEx" : "Bogdan et al\\.,? \\Q2015\\E",
      "shortCiteRegEx" : "Bogdan et al\\.",
      "year" : 2015
    }, {
      "title" : "Efficient learning using forward-backward splitting",
      "author" : [ "Duchi", "J.-C", "Y. Singer" ],
      "venue" : "In NIPS*22,",
      "citeRegEx" : "Duchi et al\\.,? \\Q2009\\E",
      "shortCiteRegEx" : "Duchi et al\\.",
      "year" : 2009
    }, {
      "title" : "The algorithmic foudations of differential privacy",
      "author" : [ "C. Dwork", "A. Roth" ],
      "venue" : "Foundations and Trends in Theoretical Computer Science,",
      "citeRegEx" : "Dwork and Roth,? \\Q2014\\E",
      "shortCiteRegEx" : "Dwork and Roth",
      "year" : 2014
    }, {
      "title" : "Linear hinge loss and average margin",
      "author" : [ "C. Gentile", "M. Warmuth" ],
      "venue" : "In NIPS*11,",
      "citeRegEx" : "Gentile and Warmuth,? \\Q1998\\E",
      "shortCiteRegEx" : "Gentile and Warmuth",
      "year" : 1998
    }, {
      "title" : "Differential privacy: An economic method for choosing epsilon",
      "author" : [ "J. Hsu", "M. Gaboardi", "A. Haeberlen", "S. Khanna", "A. Narayan", "Pierce", "B.-C", "A. Roth" ],
      "venue" : "In Proc. of the 27 IEEE CSFS,",
      "citeRegEx" : "Hsu et al\\.,? \\Q2014\\E",
      "shortCiteRegEx" : "Hsu et al\\.",
      "year" : 2014
    }, {
      "title" : "On the boosting ability of top-down decision tree learning algorithms",
      "author" : [ "M.J. Kearns", "Y. Mansour" ],
      "venue" : "J. Comp. Syst. Sc.,",
      "citeRegEx" : "Kearns and Mansour,? \\Q1999\\E",
      "shortCiteRegEx" : "Kearns and Mansour",
      "year" : 1999
    }, {
      "title" : "Computational implications of reducing data to sufficient statistics",
      "author" : [ "A. Montanari" ],
      "venue" : "Technical Report 201412, Stanford U.,",
      "citeRegEx" : "Montanari,? \\Q2014\\E",
      "shortCiteRegEx" : "Montanari",
      "year" : 2014
    }, {
      "title" : "Rectified linear units improve restricted boltzmann machines",
      "author" : [ "V. Nair", "G. Hinton" ],
      "venue" : "ICML, pp",
      "citeRegEx" : "Nair and Hinton,? \\Q2010\\E",
      "shortCiteRegEx" : "Nair and Hinton",
      "year" : 2010
    }, {
      "title" : "On the efficient minimization of classification-calibrated surrogates",
      "author" : [ "R. Nock", "F. Nielsen" ],
      "venue" : "In NIPS*21,",
      "citeRegEx" : "Nock and Nielsen,? \\Q2008\\E",
      "shortCiteRegEx" : "Nock and Nielsen",
      "year" : 2008
    }, {
      "title" : "Generalized mixability via entropic duality",
      "author" : [ "Reid", "M.-D", "Frongillo", "R.-M", "Williamson", "R.-C", "Mehta", "N.-A" ],
      "venue" : "In 28 th COLT, pp",
      "citeRegEx" : "Reid et al\\.,? \\Q2015\\E",
      "shortCiteRegEx" : "Reid et al\\.",
      "year" : 2015
    }, {
      "title" : "The boosting approach to machine learning: An overview",
      "author" : [ "Schapire", "R.-E" ],
      "venue" : "Notes in Statistics,",
      "citeRegEx" : "Schapire and R..E.,? \\Q2003\\E",
      "shortCiteRegEx" : "Schapire and R..E.",
      "year" : 2003
    }, {
      "title" : "Improved boosting algorithms using confidence-rated predictions",
      "author" : [ "R.E. Schapire", "Y. Singer" ],
      "venue" : "MLJ,",
      "citeRegEx" : "Schapire and Singer,? \\Q1999\\E",
      "shortCiteRegEx" : "Schapire and Singer",
      "year" : 1999
    }, {
      "title" : "SLOPE is adaptive to unkown sparsity and asymptotically minimax",
      "author" : [ "W. Su", "Candès", "E.-J" ],
      "venue" : "CoRR, abs/1503.08393,",
      "citeRegEx" : "Su et al\\.,? \\Q2015\\E",
      "shortCiteRegEx" : "Su et al\\.",
      "year" : 2015
    }, {
      "title" : "A primal-dual convergence analysis of boosting",
      "author" : [ "M. Telgarsky" ],
      "venue" : "JMLR, 13:561–606,",
      "citeRegEx" : "Telgarsky,? \\Q2012\\E",
      "shortCiteRegEx" : "Telgarsky",
      "year" : 2012
    }, {
      "title" : "Learning with symmetric label noise: The importance of being unhinged",
      "author" : [ "B. van Rooyen", "A. Menon", "Williamson", "R.-C" ],
      "venue" : "In NIPS*28,",
      "citeRegEx" : "Rooyen et al\\.,? \\Q2015\\E",
      "shortCiteRegEx" : "Rooyen et al\\.",
      "year" : 2015
    }, {
      "title" : "Privacy for free: Posterior sampling and stochastic gradient Monte Carlo",
      "author" : [ "Wang", "Y.-X", "S.E. Fienberg", "Smola", "A.-J" ],
      "venue" : null,
      "citeRegEx" : "Wang et al\\.,? \\Q2015\\E",
      "shortCiteRegEx" : "Wang et al\\.",
      "year" : 2015
    }, {
      "title" : "Speed and sparsity of regularized boosting",
      "author" : [ "Xi", "Y.-T", "Xiang", "Z.-J", "Ramadge", "P.-J", "Schapire", "R.-E" ],
      "venue" : "AISTATS, pp",
      "citeRegEx" : "Xi et al\\.,? \\Q2009\\E",
      "shortCiteRegEx" : "Xi et al\\.",
      "year" : 2009
    }, {
      "title" : "Regularization and variable selection via the elastic net",
      "author" : [ "H. Zou", "T. Hastie" ],
      "venue" : "Journal of the Royal Statistical Society B,",
      "citeRegEx" : "Zou and Hastie,? \\Q2005\\E",
      "shortCiteRegEx" : "Zou and Hastie",
      "year" : 2005
    } ],
    "referenceMentions" : [ {
      "referenceID" : 7,
      "context" : "It is known that sufficient statistics carry the intractability of certain processes that would otherwise be easy with data (Montanari, 2014).",
      "startOffset" : 124,
      "endOffset" : 141
    }, {
      "referenceID" : 14,
      "context" : "The technique we use exploits a two-player zero sum game representation of convex losses, that has been very useful to analyse boosting algorithms (Schapire, 2003; Telgarsky, 2012), with one key difference: payoffs are non-linear convex, eventually non-differentiable.",
      "startOffset" : 147,
      "endOffset" : 180
    }, {
      "referenceID" : 10,
      "context" : "These also resemble the entropic dual losses (Reid et al., 2015), with the difference that we do not enforce conjugacy over the simplex.",
      "startOffset" : 45,
      "endOffset" : 64
    }, {
      "referenceID" : 14,
      "context" : "It turns out that the losses involved bear popular names in different communities, even when not all of them are systematically used as losses per se: exponential, logistic, square, mean-variance, ReLU, linear Hinge, and unhinged losses (Nair & Hinton, 2010; Gentile & Warmuth, 1998; Nock & Nielsen, 2008; Telgarsky, 2012; Vapnik, 1998; van Rooyen et al., 2015) (and many others).",
      "startOffset" : 237,
      "endOffset" : 361
    }, {
      "referenceID" : 0,
      "context" : "Regularizing a loss is common in machine learning (Bach et al., 2011).",
      "startOffset" : 50,
      "endOffset" : 69
    }, {
      "referenceID" : 1,
      "context" : "ADABOOST, that learns a classifier from rados using the exponential regularized rado loss, with regularization choice belonging to the ridge, lasso, l∞, or the recently coined SLOPE (Bogdan et al., 2015).",
      "startOffset" : 182,
      "endOffset" : 203
    }, {
      "referenceID" : 0,
      "context" : "= le(Se,θ) + Ω(θ) , (21) with Ω a regularizer (Bach et al., 2011).",
      "startOffset" : 46,
      "endOffset" : 65
    }, {
      "referenceID" : 0,
      "context" : "(Bach et al., 2011; Bogdan et al., 2015; Duchi & Singer, 2009; Su & Candès, 2015).",
      "startOffset" : 0,
      "endOffset" : 81
    }, {
      "referenceID" : 1,
      "context" : "(Bach et al., 2011; Bogdan et al., 2015; Duchi & Singer, 2009; Su & Candès, 2015).",
      "startOffset" : 0,
      "endOffset" : 81
    }, {
      "referenceID" : 1,
      "context" : "ADABOOST, for two reasons: it matches the original definition (Bogdan et al., 2015) and furthermore it unveils an interesting connection between boosting and the SLOPE properties (Su & Candès, 2015).",
      "startOffset" : 62,
      "endOffset" : 83
    }, {
      "referenceID" : 1,
      "context" : "14) Constraint (ii) on q is interesting in the light of the properties of SLOPE (Bogdan et al., 2015; Su & Candès, 2015).",
      "startOffset" : 80,
      "endOffset" : 120
    }, {
      "referenceID" : 17,
      "context" : "Table 2: Best result of ADABOOST/l1-ADABOOST (Schapire & Singer, 1999; Xi et al., 2009), vs ΩR.",
      "startOffset" : 45,
      "endOffset" : 87
    }, {
      "referenceID" : 17,
      "context" : "ADABOOST to ADABOOST/l1-ADABOOST (Schapire & Singer, 1999; Xi et al., 2009).",
      "startOffset" : 33,
      "endOffset" : 75
    }, {
      "referenceID" : 17,
      "context" : "To obtain very sparse solutions for l1-ADABOOST, we pick its ω (β in (Xi et al., 2009)) in {10−4, 1, 104}.",
      "startOffset" : 69,
      "endOffset" : 86
    }, {
      "referenceID" : 5,
      "context" : "The results are a clear advocacy in favor of using rados against examples for the straight DP protection: with plain random rados, test errors that compete with clean data can be observed for privacy budget ε ≈ 10−4, that is, more than a hundred times smaller than most reported studies (Hsu et al., 2014).",
      "startOffset" : 287,
      "endOffset" : 305
    }, {
      "referenceID" : 16,
      "context" : "In addition to “coming for free” (Wang et al., 2015) in machine learning, DP may thus also be a worthwhile companion to improve learning.",
      "startOffset" : 33,
      "endOffset" : 52
    }, {
      "referenceID" : 17,
      "context" : "Table 7: Best result of ADABOOST/l1-ADABOOST Schapire & Singer (1999); Xi et al. (2009), vs Ω-R.",
      "startOffset" : 71,
      "endOffset" : 88
    }, {
      "referenceID" : 17,
      "context" : "Table 7: Best result of ADABOOST/l1-ADABOOST Schapire & Singer (1999); Xi et al. (2009), vs Ω-R.ADABOOST (with or without regularization, trained with n = m random rados (above bold horizontal line) / n = 10000 rados (below bold horizontal line)), according to the expected true error of θT , when the classifier θT returned is the last classifier of the sequence (”†”; θT = θ1000), or when it is the classifier minimizing the empirical risk in the sequence (””; θT = θ≤1000). Table shows the best result over all ωs, as well as the difference between the worst and best (∆). Shaded cells display the best result of Ω-R.ADABOOST. All domains but Kaggle are UCI Bache & Lichman (2013). 39",
      "startOffset" : 71,
      "endOffset" : 684
    } ],
    "year" : 2015,
    "abstractText" : "It has recently been shown that supervised learning with the popular logistic loss is equivalent to optimizing the exponential loss over sufficient statistics about the class: Rademacher observations (rados). We first show that this unexpected equivalence can actually be generalized to other example / rado losses, with necessary and sufficient conditions for the equivalence, exemplified on four losses that bear popular names in various fields: exponential (boosting), mean-variance (finance), Linear Hinge (on-line learning), ReLU (deep learning), and unhinged (statistics). Second, we show that the generalization unveils a surprising new connection to regularized learning, and in particular a sufficient condition under which regularizing the loss over examples is equivalent to regularizing the rados (with Minkowski sums) in the equivalent rado loss. This brings simple and powerful rado-based learning algorithms for sparsity-controlling regularization, that we exemplify on a boosting algorithm for the regularized exponential rado-loss, which formally boosts over four types of regularization, including the popular ridge and lasso, and the recently coined SLOPE — we obtain the first proven boosting algorithm for this last regularization. Through our first contribution on the equivalence of rado and example-based losses, ΩR.ADABOOST appears to be an efficient proxy to boost the regularized logistic loss over examples using whichever of the four regularizers (and any linear combination of them, e.g., for elastic net regularization). We are not aware of any regularized logistic loss formal boosting algorithm with such a wide spectrum of regularizers. Experiments display that regularization consistently improves performances of rado-based learning, and may challenge or beat the state of the art of example-based learning even when learning over small sets of rados. Finally, we connect regularization to ε-differential privacy, and display how tiny budgets (e.g. ε < 10) can be afforded on big domains while beating (protected) example-based learning.",
    "creator" : "gnuplot 4.6 patchlevel 5"
  }
}