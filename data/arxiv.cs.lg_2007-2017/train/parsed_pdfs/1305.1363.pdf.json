{
  "name" : "1305.1363.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "One-Pass AUC Optimization",
    "authors" : [ "Wei Gao", "Rong Jin", "Shenghuo Zhu", "Zhi-Hua Zhou" ],
    "emails" : [ "gaow@lamda.nju.edu.cn", "rongjin@cse.msu.edu", "zsh@nec-labs.com", "zhouzh@lamda.nju.edu.cn" ],
    "sections" : [ {
      "heading" : null,
      "text" : "ar X\niv :1\n30 5.\n13 63\nv2 [\nKeywords: AUC optimization, learning to rank, large-scale learning, random projection, square loss"
    }, {
      "heading" : "1. Introduction",
      "text" : "AUC (Area Under ROC curve) (Metz, 1978; Hanley and McNeil, 1983) is an important performance measure that has been widely used in many tasks (Provost et al., 1998; Cortes and Mohri, 2004; Liu et al., 2009; Flach et al., 2011). Many algorithms have been developed to optimize AUC based on surrogate losses (Herschtal and Raskutti, 2004; Joachims, 2006; Rudin and Schapire, 2009; Kotlowski et al., 2011; Zhao et al., 2011).\nIn this work, we focus on AUC optimization that requires only one pass of training examples. This is particularly important for applications involving big data or streaming\nc© Gao, Jin, Zhu and Zhou.\ndata in which a large volume of data come in a short time period, making it infeasible to store the entire data set in memory before an optimization procedure is applied. Although many online learning algorithms have been developed to find the optimal solution of some performance measures by only scanning the training data once (Cesa-Bianchi and Lugosi, 2006), few effort addresses one-pass AUC optimization.\nUnlike the classical classification and regression problems where the loss function can be calculated on a single training example, AUC is measured by the losses defined over pairs of instances from different classes, making it challenging to develop algorithms for one-pass optimization. An online AUC optimization algorithm was proposed very recently by Zhao et al. (2011). It is based on the idea of reservoir sampling, and achieves a solid regret bound by only storing √ T instances, where T is the number of training examples. Ideally, for one-pass approaches, it is crucial that the storage required by the learning process should be independent from the amount of training data, because it is often quite difficult to expect how many data will be received in those applications.\nIn this work, we propose a regression-based algorithm for one-pass AUC optimization in which a square loss is used to measure the ranking error between two instances from different classes. The main advantage of using the square loss lies in the fact that it only needs to store the first and second-order statistics for the received training examples. Consequently, the storage requirement is reduced to O(d2), where d is the dimension of data, independent from the number of training examples. To deal with high-dimensional data, we develop a randomized algorithm that approximates the covariance matrix of d × d by a low-rank matrix. We show, both theoretically and empirically, the effectiveness of our proposal algorithm by comparing to state-of-the-art algorithms for AUC optimization.\nSection 2 introduces some preliminaries. Sections 3 proposes the OPAUC (One Pass AUC) framework, and Section 4 provides theoretical analysis and Section 5 presents detailed proofs. Section 6 summaries our experimental results. Section 7 concludes with future work."
    }, {
      "heading" : "2. Preliminaries",
      "text" : "We denote by X ∈ Rd an instance space and Y = {+1,−1} the label set, and let D denote an unknown (underlying) distribution over X ×Y. A training sample of n+ positive instances and n− negative ones\nS = {(x+1 ,+1), (x+2 ,+1), . . . , (x+n+ ,+1), (x−1 ,−1), (x−2 ,−1), . . . , (x−n− ,−1)}\nis drawn identically and independently according to distribution D, where we do not fix n+ and n− before the training sample is chosen. Let f : X → R be a real-valued function. Then, the AUC of function f on the sample S is defined as\nn+∑\ni=1\nn−∑\nj=1\nI[f(x+i ) > f(x − j )] + 1 2 I[f(x + i ) = f(x − j )]\nn+n−\nwhere I[·] is the indicator function which returns 1 if the argument is true and 0 otherwise. Direct optimization of AUC often leads to an NP-hard problem as it can be cast into a combinatorial optimization problem. In practice, it is approximated by a convex optimiza-\ntion problem that minimizes the following objective function\nL(w) = λ 2 |w|2 +\nn+∑\ni=1\nn−∑\nj=1\nℓ ( w⊤(x+i − x−j ) )\n2n+n− (1)\nwhere ℓ is a convex loss function and λ is the regularization parameter that controls the model complexity. Notice that each loss term ℓ(w⊤(x+i − x−j )) involves two instances from different classes; therefore, it is difficult to extend online learning algorithms for one-pass AUC optimization without storing all the training instances. Zhao et al. (2011) addressed this challenge by exploiting the reservoir sampling technique."
    }, {
      "heading" : "3. The OPAUC Approach",
      "text" : "To address the challenge of one-pass AUC optimization, we propose to use the square loss in Eq. (1), that is,\nL(w) = λ 2 |w|2 +\nn+∑\ni=1\nn−∑\nj=1\n(1−w⊤(x+i − x−j ))2 2n+n− . (2)\nThe main advantage of using the square loss lies in the fact that it is sufficient to store the first and second-order statistics of training examples for optimization, leading to a memory requirement of O(d2), which is independent from the number of training examples. Another advantage is that the square loss is consistent with AUC, as will be shown by Theorem 1 (Section 4). In contrast, loss functions such as hinge loss are proven to be inconsistent with AUC (Gao and Zhou, 2012).\nAs aforementioned, the classical online setting cannot be applied to one-pass AUC optimization because, even if the optimization problem of Eq. (2) has a closed form, it requires going through the training examples multiple times. To address this challenge, we modify the overall loss L(w) in Eq. (2) (with a little variation) as a sum of losses for individual training instance ∑T t=1 Lt(w), where\nLt(w) = λ\n2 |w|2 +\n∑t−1 i=1 I[yi 6= yt](1− yt(xt − xi)⊤w)2\n2|{i ∈ [t− 1] : yiyt = −1}| for sequence St = {(x1, y1), . . . , (xt, yt)}. It is noteworthy that Lt(w) is an unbiased estimation to L(w) for i.i.d. sequence St. For notational simplicity, we denote by X+t and X−t the sets of positive and negative instances in the sequence St, respectively, and we further denote by T+t and T − t their respective cardinalities. Also, we set Lt(w) = 0 for T+t T−t = 0.\nIf yt = 1, we calculate the gradient as\n∇Lt(w) = λw + xtx⊤t w − xt + ∑\ni : yi=−1\nxi + (xix ⊤ i − xix⊤t − xtx⊤i )w\nT−t . (3)\nIt is easy to observe that\nc−t = ∑\ni : yi=−1\nxi\nT−t and S−t =\n∑\ni : yi=−1\nxix ⊤ i − c−t [c−t ]⊤\nT−t\nAlgorithm 1 The OPAUC Algorithm Input: The regularization parameter λ > 0 and stepsizes {ηt}Tt=1. Initialization: Set T+0 = T − 0 = 0, c + 0 = c − 0 = 0, w0 = 0 and Γ + 0 = Γ − 0 = [0]d×u for some u > 0\n1: for t = 1, 2, . . . , T do 2: Receive a training example (xt, yt) 3: if yt = +1 then 4: T+t = T + t−1 + 1 and T − t = T − t−1; 5: c+t = c + t−1 +\n1 T+t (xt − c+t−1) and c−t = c−t−1; 6: Update Γ+t and Γ − t = Γ − t−1; 7: Calculate the gradient ĝt(wt−1) 8: else 9: T−t = T − t−1 + 1 and T + t = T + t−1;\n10: c−t = c − t−1 + 1 T−t (xt − c−t−1) and c+t = c+t−1; 11: Update Γ−t and Γ + t = Γ + t−1; 12: Calculate the gradient ĝt(wt−1) 13: end if 14: wt = wt−1 − ηtĝt(wt−1) 15: end for\ncorrespond to the mean and covariance matrix of negative class, respectively; thus, Eq. (3) can be further simplified as\n∇Lt(w) = λw − xt + c−t + (xt − c−t )(xt − c−t )⊤w + S−t w. (4) In a similar manner, we calculate the following gradient for yt = −1:\n∇Lt(w) = λw + xt − c+t + (xt − c+t )(xt − c+t )⊤w + S+t w (5) where\nc+t = ∑\ni : yi=1\nxi\nT+t and S+t =\n∑\ni : yi=1\nxix ⊤ i − c+t [c+t ]⊤\nT+t\nare the covariance matrix and mean of positive class, respectively. The storage cost for keeping the class means (c+t and c − t ) and covariance matrices (S + t−1 and S−t−1) is O(d 2). Once we get the gradient ∇Lt(w), by theory of stochastic gradient descent, the solution can be updated by\nwt+1 = wt − ηt∇Lt(wt) where ηt is the stepsize for the t-th iteration.\nAlgorithm 1 highlights the key steps of the proposed algorithm. We initialize Γ−0 = Γ+0 = [0]d×d, where u = d. At each iteration, we set Γ + t = S + t and Γ − t = S − t , and update Γ+t (Line 6) and Γ − t (Line 11), respectively, by using the following equations\nΓ+t = Γ + t−1 +\nxtx⊤t −Γ + t−1\nT+t + c+t−1[c + t−1] ⊤ − c+t [c+t ]⊤,\nΓ−t = Γ − t−1 +\nxtx⊤t −Γ − t−1\nT−t + c−t−1[c − t−1] ⊤ − c−t [c−t ]⊤.\nFinally, the stochastic gradient ĝt(wt−1) of Lines 7 and 12 in Algorithm 1 are given by ∇Lt(wt−1) that are calculated by Eqs. (4) and (5), respectively. Dealing with High-Dimensional Data. One limitation of the approach in Algorithm 1 is that the storage cost of the two covariance matrices S+t and S − t is O(d\n2), making it unsuitable for high-dimensional data. We tackle this by developing a randomized algorithm that approximates the covariance matrices by low-rank matrices. We are motivated by the observation that S+t and S − t can be written, respectively, as\nS+t = 1 T+t ( X+t − c+t 1⊤T+t ) IT+t ( X+t − c+t 1T+t )⊤ ,\nS−t = 1\nT−t ( X−t − c−t 1⊤T−t ) IT−t ( X−t − c−t 1T−t )⊤ ,\nwhere It is an identity matrix of size t×t and 1t is an all-one vector of size t. To approximate S+t and S − t , we approximate the identify matrix It by a matrix of rank τ ≪ d. To this end, we randomly sample ri ∈ Rτ , i = 1, . . . , t from a Gaussian distribution N (0, Iτ ), and approximate It by RtR ⊤ t , where Rt = 1 τ (r1, . . . , rt)\n⊤ ∈ Rt×τ . We further divide Rt into two matrices where R+t ∈ RT + t ×τ and R−t ∈ RT − t ×τ that contain the subset of the rows in Rt corresponding to all the positive and negative instances received before the t-th iteration, respectively. Therefore, the covariance matrices S+t and S − t can be approximated, respectively, by\nŜ+t = 1\nT+t Z+t [Z + t ]\n⊤ − ĉ+t−1[ĉ+t−1]⊤ and Ŝ−t = 1\nT−t Z−t [Z − t ] ⊤ − ĉ−t−1[ĉ−t−1]⊤\nwhere\nZ+t = X + t R + t , ĉ + t = c + t 1 ⊤ T+t R+t /T + t Z−t = X − t R − t , ĉ − t = c − t 1\n⊤ T−t R−t /T − t .\nBased on approximate covariance matrix Ŝ±t , the approximation algorithm essentially tries to minimize ∑T t=1 L̂t(w), where\nL̂t(w) = w⊤(c−t−1 − xt) + 1\n2 (1 +w⊤Ŝ−t w) +\nλ 2 |w|2 + 1 2 w⊤(xt − c−t−1)(xt − c−t−1)⊤w (6)\nif yt = 1; otherwise,\nL̂t(w) = w⊤(xt − c+t−1) + 1\n2 (1 +w⊤Ŝ+t w) +\nλ 2 |w|2 + 1 2 w⊤(xt − c+t−1)(xt − c+t−1)⊤w. (7)\nFurther, we have the following recursive formulas:\nZ+t = Z + t−1 + xtr ⊤ t I[yt = +1]/\n√ m, (8)\nZ−t = Z − t−1 + xtr ⊤ t I[yt = −1]/\n√ m. (9)\nIt is important to notice that we do not need to calculate and store the approximate covariance matrices Ŝ+t and Ŝ − t explicitly. Instead, we only need to maintain matrices Z + t and\nZ−t in memory. This is because the stochastic gradient ĝt(w) based on the approximate covariance matrices can be computed directly from Z+t and Z − t . More specifically, ĝt(w) is computed as\nĝt(w) = c − t−1−xt+λw+(xt−c−t−1)(xt−c−t−1)⊤w+ ( Z−t [Z − t ] ⊤/T−t − ĉ−t−1[ĉ−t−1]⊤ ) w (10)\nfor yt = 1; otherwise\nĝt(w) = xt−c+t−1+λw+(xt−c+t−1)(xt−c+t−1)⊤w+ ( Z+t [Z + t ] ⊤/T+t − ĉ+t−1[ĉ+t−1]⊤ ) w. (11)\nWe require a memory of O(τd) instead of O(d2) to calculate ĝt(w) by using the trick A[A]⊤w = A([A]⊤w), where A ∈ Rd×1 or Rd×τ .\nTo implement the approximate approach, we initialize Γ−0 = Γ + 0 = [0]d×τ in Algorithm 1,\nwhere u = τ . At each iteration, we set Γ+t = Z + t and Γ − t = Z − t , and compute the gradient ĝt(wt−1) of Lines 7 and 12 in Algorithm 1 by Eqs. (10) and (11), respectively. Γ + t and Γ − t are updated by Eqs. (8) and (9), respectively.\nRemark. An alternative approach for the high-dimensional case is through the random projection (Johnstone, 2006; Hsu et al., 2012). Let H ∈ Rd×τ be a random Gaussian matrix, where τ ≪ d. By performing random projection using H, we compute a lowdimensional representation for each instance xt as x̂t = H\n⊤xt ∈ Rτ and will only maintain covariance matrices of size τ × τ in memory. Despite that it is computationally attractive, this approach performs significantly worse than the randomized low-rank approximation algorithm, according to our empirical study. This may owe to the fact that the random projection approach is equivalent to approximating S±t = IdS ± t Id by HH ⊤S±t HH ⊤, which replaces both the left and right identity matrices of S±t withHH ⊤. In contrast, our proposed approach only approximates one identity matrix in S±t , making it more reliable for tackling high-dimensional data."
    }, {
      "heading" : "4. Main Theoretical Result",
      "text" : "In this section, we present the main theoretical results for our proposed algorithm. The following theorem shows the consistency of square loss, and the detailed proof is deferred in Section 5.1.\nTheorem 1 For square loss ℓ(t) = (1− t)2, the surrogate loss Ψ(f,x,x′) = ℓ(f(x)−f(x′)) is consistent with AUC.\nDefine w∗ as w∗ = argmin\nw\n∑\nt\nLt(w).\nWe are in the position to present the following convergence rate for Algorithm 1 when the full covariance matrices are provided, and the detailed proof is deferred in Section 5.2 Theorem 2 For ‖xt‖ ≤ 1 (t ∈ [T ]), ‖w∗‖ ≤ B and TL∗ ≥ ∑T\nt=1 Lt(w∗), we have ∑\nt Lt(wt)− ∑ t Lt(w∗) ≤ 2κB2 +B √ 2κTL∗,\nwhere κ = 4 + λ and ηt = 1/(κ + √ (κ2 + κTL∗/B2).\nThis theorem presents an O(1/T ) convergence rate for the OPAUC algorithm if the distribution is separable, i.e., L∗ = 0, and an O(1/ √ T ) convergence rate for general case. Compared to the online AUC optimization algorithm (Zhao et al., 2011), which achieves at most O(1/ √ T ) convergence rate, our proposed algorithm clearly reduce the regret. The faster convergence rate of our proposed algorithm owes to the smoothness of the square loss, an important property that has been explored by some studies of online learning (Rakhlin et al., 2012) and generalization error bound analysis (Srebro et al., 2010).\nRemark: The bound in Theorem 2 does not explicitly explore the strongly convexity of Lt(w), which can lead to an O(1/T ) convergence rate. Instead, we focus on exploiting the smoothness of the loss function, since we did not introduce a bounded domain for w. Due to the regularizer λ|w|2/2, we have |w∗| ≤ 1/λ, and it is reasonable to restrict wt by |wt| ≤ 1/λ, leading to a regret bound of O(lnT/[λ3T ]) by applying the standard stochastic gradient descent with ηt = 1/[λt]. This bound is preferred only when λ = Ω(T\n−1/6), a scenario which rarely occurs in empirical study. This problem may also be addressable by exploiting the epoch gradient method (Nocedal and Wright, 1999), a subject of our future study.\nWe now consider the case when covariance matrices are approximated by low-rank matrices. Note that the low-rank approximation is accurate only if the eigenvalues of covariance matrices follow a skewed distribution. To capture the skewed eigenvalue distribution, we introduce the concept of effective numerical rank (Hansen, 1987) that generalizes the rank of matrix:\nDefinition 3 For a positive constant µ > 0 and semi-positive definite matrix M ∈ Rd×d of eigenvalues {νi}, the effective numerical rank w.r.t. µ is defined to be r(M,µ) =∑d\ni=1 νi/(µ+ νi).\nIt is evident that the effective numerical rank is upper bounded by the true rank, i.e., r(M,µ) ≤ rank(M). To further see how the concept of effective numerical rank captures the skewed eigenvalue distribution, consider a PSD matrix M of full rank with ∑d i=k νi ≤ µ for small k. It is easy to verify that r(M,µ) ≤ k, i.e., M can be well approximated by a matrix of rank k.\nDefine the effective numerical rank for a set of matrices {Mt}Tt=1 as r ( {Mt}Tt=1, µ ) = max\n1≤t≤T r(Mt, µ).\nUnder the assumption that the effective numerical rank for the set of covariance matrices {S±t }Tt=1 is small (i.e., S±t can be well approximated by low-rank matrices), the following theorem gives the convergence rate for |∑t L̂t(wt) − ∑ t Lt(w∗)|, where L̂t(wt) are given by Eqs. (6) and (7).\nTheorem 4 Let r = r({S±t }Tt=1, λ) be the effective numerical rank for the sequence of covariance matrices {S±t }Tt=1. For 0 < δ < 1, 0 < ǫ ≤ 1/2, |w∗| ≤ B, ‖xt‖ ≤ 1 (t ∈ [T ]) and TL∗ ≥ ∑Tt=1 Lt(w∗), we have with probability at least 1− δ,∣∣∣\n∑ t ( L̂t(wt)− Lt(w∗) )∣∣∣ ≤ 2ǫTL∗ + 2κB2 +B √ 2κTL∗\nprovided τ ≥ 32rλ ǫ2 log 2dTδ , where κ = 4 + λ and ηt = 1/(κ + √ (κ2 + κTL∗/B2).\nThe detailed proof is presented in Section 5.3. For the separable distribution L∗ = 0, we also obtain an O(1/T ) convergence rate when the covariance matrices are approximated by low-rank matrices. Compared with Theorem 2, Theorem 4 introduces an additional term 2ǫL∗ in the bound when using the approximate covariance matrices, and it is noteworthy that the approximation does not significantly increase the bound of Theorem 2 if 2ǫTL∗ ≤ B √ 2(4 + λ)TL∗, i.e., ǫ ≤ B √ 2(λ+ 4)/TL∗. This implies that the approximate algorithm will achieve similar performance as the one using the full covariance matrices provided τ = Ω(rλT (log d + log T )/(λ + 4)). When λ = O(1/T ), this requirement is reduced to τ = Ω(r[log d+ log T ]), a logarithmic dependence on dimension d."
    }, {
      "heading" : "5. Proofs",
      "text" : "In this section, we present detailed proofs for our main theorems."
    }, {
      "heading" : "5.1 Proof of Theorem 1",
      "text" : "Let X = {x1,x2, . . . ,xn} with instance-marginal probability pi = Pr[xi] and conditional probability ξi = Pr[y = +1|xi], and we denote by the expected risk\nRΨ(f) = C0 + ∑\ni 6=j\npipj (ξi(1− ξj)ℓ(f(xi)− f(xj)) + ξj(1− ξi)ℓ(f(xj)− f(xi)))\nwhere ℓ(t) = (1− t)2 and C0 is a constant with respect to f(xi) (1 ≤ i ≤ n). According to the analysis of (Gao and Zhou, 2012), it suffices to prove that, for every optimal solution f , i.e., RΨ(f) = inff ′ RΨ(f\n′), we have f(xi) > f(xj) if ξi > ξj. If X = {x1,x2}, then minimizing Rφ(f) gives the optimal solution f = (f(x1), f(x2))\nsuch that f(x1)− f(x2) = sgn(ξ(x1)− ξ(x2)) for ξ(x1) 6= ξ(x2),\nwhich shows the consistency of least square loss. For X = {x1,x2, · · · ,xn} with n ≥ 3, if ξi(1 − ξi) = 0 for every 1 ≤ i ≤ n, then minimizing RΨ(f) gives the optimal solution f = (f1, f2, · · · , fn) such that fj = fi + 1 for every ξi = 1 and ξj = −1,\nwhich shows the consistency of least square loss. If X = {x1,x2, · · · ,xn} with n ≥ 3, and there exists some i0 s.t. ξi0(1− ξi0) 6= 0, then the subgradient conditions give optimal solution such that ∑\nk 6=i\npk(ξi + ξk − 2ξiξk)(f(xi)− f(xk)) = ∑\nk 6=i\npk(ξi − ξk) for each 1 ≤ i ≤ n.\nSolving the above n linear equations, we obtain the optimal solution f = (f1, f2, . . . , fn), i.e.,\nf(xi)− f(xj) = (ξi − ξj) ∏ k 6=i,j ∑n l=1 pl(ξl + ξk − 2ξlξk)∑\nsi≥0 s1+···+sn=n−2\nps11 · · · psnn Γ(s1, s2, · · · , sn)\nwhere Γ is a polynomial in ξ[k1] + ξ[k2] − 2ξ[k1]ξ[k2] for 1 ≤ k1, k2 ≤ n. In the following, we will derive the specific expression for Γ(s1, s2, · · · , sn). Denote by A = {i : si ≥ 1} and B = {i : si = 0} = {b1, b2, · · · , b|B|}.\n• If |A| = 1, i.e., A = {i1} for some 1 ≤ i1 ≤ n, then\nΓ(s1, s2, · · · , sn) = ∏\nk∈B\n(ξi1 + ξk − 2ξi1ξk).\n• If |A| = 2, i.e., A = {i1, i2} for some 1 ≤ i1, i2 ≤ n, then we denote by\nA1 = {si1 ⊙ i1} ⋃ {si2 ⊙ i2}\nwhere {sik ⊙ ik} denotes the multi-set {ik, ik, . . . , ik} of size sik for k = 1, 2. It is clear that |B| = |A1| = n − 2. Further, we denote by G(A1) the set of all permutations of A1. Therefore, we have\nΓ(s1, s2, · · · , sn) = (ξi1 + ξi2 − 2ξi1ξi2) ∑\nπ=π1···πn−2∈G(A1)\nn−2∏\nk=1\n(ξπi + ξbi − 2ξπiξbi).\n• If |A| > 2, then, for i1 6= i2 ∈ A, we denote by the multi-set\nA1(i1, i2) = {si1 ⊙ i1} ⋃ {si2 ⊙ i2} ⋃\n  ⋃\nk∈A\\{i1,i2}\n{(sk − 1)⊙ k}   ,\nand it is easy to derive |A1| = |B|. Further, we denote by G(A \\ {i1, i2}) and G(A1) the set of all permutations of A \\ {i1, i2} and A1, respectively. Therefore, we set\nΓ1(i1, i2,A) = ∑\nπ=π1π2···π|A|−2∈G(A\\{i1,i2})\n(ξi1 + ξπ1 − 2ξi1ξπ1)(ξπ1 + ξπ2 − 2ξπ1ξπ2)\n× · · · × (ξπ|A|−3 + ξπ|A|−2 − 2ξπ|A|−3ξπ|A|−2)(ξπ|A|−2 + ξi2 − 2ξi2ξπ|A|−2),\nand we have\nΓ(s1, s2, · · · , sn) = ∑\ni1 6=i2 i1,i2∈A\nΓ1(i1, i2,A) ∑\nπ=π1π2...π|B|∈G(A1)\n|B|∏\nk=1\n(ξπk + ξbk − 2ξπkξbk)\nwhere B = {b1, b2, . . . , b|B|}.\nSince there exist some i0 s.t. ξi0(1− ξi0) 6= 0, we have ∏\nk 6=i,j ∑n l=1 pl(ξl + ξk − 2ξlξk)∑\nsi≥0 s1+···+sn=n−2\nps11 · · · psnn Γ(s1, s2, · · · , sn) > 0.\nTherefore, it is evident that f(xi) > f(xj) if ξi > ξj, and this theorem follows as desired."
    }, {
      "heading" : "5.2 Proof of Theorem 2",
      "text" : "This proof is motivated from (Shalev-Shwartz, 2007; Srebro et al., 2010). Recall\nLt(w) = λ\n2 |w|2 +\n∑t−1 i=1 I[yi 6= yt](1− yt(xt − xi)⊤w)2\n2|{i ∈ [t− 1] : yi 6= yt}| .\nFor |w∗| ≤ B and convex Lt(w), we have\nLt(wt)− Lt(w∗) ≤ ∇Lt(wt)⊤(wt −w∗). (12)\nIt is easy to derive that ∇Lt(wt) equals to\nλwt − ∑t−1\ni=1 I[yi 6= yt](1 − yt(xt − xi)⊤wt)yt(xt − xi) |{i ∈ [t− 1] : yi 6= yt}| ,\nand therefore, for any w and |xi| ≤ 1\n|∇Lt(wt)−∇Lt(w)| ≤ (4 + λ)|wt −w|.\nDenote by\nwt∗ = argmin w\nLt(wt),\nwhich implies that ∇Lt(wt∗) = 0 for convex and smooth Lt. Based on (Nesterov, 2003, Theorem 2.1.5), we have\n|∇Lt(wt)|2 = |∇Lt(wt)−∇Lt(wt∗)|2 ≤ 2(λ+ 4)Lt(wt) (13)\nwhere the inequality holds from Lt(wt∗) ≥ 0 and ∇Lt(wt∗) = 0. Moreover, we have\n|wt+1−w∗|2 = |wt−ηt∇Lt(wt)−w∗|2 = |wt−w∗|2−2ηt∇Lt(wt)⊤(wt−w∗)+η2t |∇Lt(wt)|2,\nand this yields that, by using Eqs. (12) and (13),\n(1− (4 + λ)ηt)Lt(wt)− Lt(w∗) ≤ 1\n2ηt |wt −w∗|2 −\n1\n2ηt |wt+1 −w∗|2.\nSumming over t = 0, . . . , T − 1 and rearranging, we obtain T−1∑\nt=0\n(1− (4 + λ)ηt)Lt(wt)− T−1∑\nt=0\nLt(w∗)\n≤ 1 2η0 |w0 −w∗|2 − 1 2ηT−1 |wT −w∗|2 +\nT−2∑\ni=1\n( 1 2ηi+1 − 1 2ηi )|wi −w∗|2.\nBy setting ηt = η, we have\n1\n2η0 |w0 −w∗|2 −\n1\n2ηT−1 |wT −w∗|2 ≤\n1\n2η |w∗|2 ≤\nB2\n2η\nfrom w0 = 0 and |w∗| ≤ B, and we further get T−1∑\nt=0\nLt(wt)− T−1∑\nt=0\nLt(w∗) ≤ 1\n1− (4 + λ)η\n( B2\n2η + (4 + λ)η\nT−1∑\nt=0\nLt(w∗) )\n≤ 1 1− (4 + λ)η\n( B2\n2η + (4 + λ)ηTL∗\n) .\nThis theorem holds by putting\nη = 1\n4 + λ+ √ (4 + λ)2 + (4 + λ)TL∗/B2\ninto the above formula and using the formula √ a+ b ≤ √a+ √ b."
    }, {
      "heading" : "5.3 Proof of Theorem 4",
      "text" : "Before the detailed proof of Theorem 4, we begin with some useful results:\nLemma 5 Let S1 = diag(s1i) and S2 = diag(s2i) be two d× d diagonal matrices such that s1i 6= 0 and s21i + s22i = 1 for all i. For a Gaussian random matrix R ∈ Rd×τ , we set Z = S1S1 + S2RR ⊤S2 and r = ∑ i s 2 2i, and the followings hold\nPr[λ1(Z) ≥ 1 + ǫ] ≤ d exp(−τǫ2/32r) and Pr[λp(Z) ≤ 1− ǫ] ≤ d exp(−τǫ2/32r), where λk(Z) denotes the k-th largest eigenvalue of matrix Z.\nProof This proof technique is motivated from (Gittens and Tropp, 2011) by adding a bias matrix. Let g(θ) = θ 2\n2−2θ . Then, we have\nPr[λ1(M) ≥ 1 + ǫ] ≤ inf\nθ>0 tr exp\n{ θ ( S1S1 + E[S2RR ⊤S2]− (1 + ǫ)I ) + g(θ)E[(S2RR ⊤S2) 2]/τ }\n≤ inf θ>0 tr exp{−θǫ+ 8g(θ)tr(S22)S22} ≤ inf θ>0 d exp{−θǫ+ 8rg(θ)} ≤ d exp(−τǫ2/32r).\nIn a similar manner,\nPr[λp(M) ≤ 1− ǫ] ≤ inf\nθ>0 tr exp\n{ θ ( S1S1 + E[S2RR ⊤S2]− (1− ǫ)I ) + g(θ)E[(S2RR ⊤S2) 2]/τ }\n≤ inf θ>0 d exp{−θǫ+ 8rg(θ)} ≤ d exp(−τǫ2/32r).\nThis completes the proof.\nLet M ∈ Rd×d be a positive semi-definite (PSD) matrix with effective numerical rank r(M,µ) for µ > 0. We define two matrices K and K̂, respectively, as\nK := µId +M and K̂ := µId +M −1/2RR⊤M−1/2,\nwhere R ∈ Rd×m is a (Gaussian) random matrix. Based on Lemma 5, we have the following theorem that bounds the difference between K − K̂:\nLemma 6 Let r(M,µ) be the numerical rank for µ > 0 and PSD matrix M . Then, for δ > 0 and ǫ > 0, the following holds with probability at least 1− δ\n‖I −K−1/2K̂K−1/2‖2 ≤ ǫ, where ‖Z‖2 measures the spectral norm of matrix Z, provided\nτ ≥ 32r(M,µ) ǫ2 log(2d/δ).\nProof Let M = Udiag(σ2i )V ⊤ be the singular value decomposition of M . We define\nS1 = diag\n(√ µ\nσ21 + µ , . . . ,\n√ µ\nσ2d + µ\n) and S2 = diag   σ1√\nσ21 + µ , . . . , σd√ σ2d + µ\n  .\nIt is easy to observe that\nZ = K−1/2K̂K−1/2 = U(S21 + S2V ⊤RR⊤V )U⊤ = U(S21 + S2R̂R̂ ⊤)U⊤\nwhere R̂ = V ⊤R ∈ Rd×τ is a also Gaussian random matrix because V is an orthonormal matrix. Parameter r in Lemma 5 is given by\nr =\nd∑\ni=1\ns22,i =\nd∑\ni=1\nσ2i σ2i + µ = r(M,µ).\nUsing Lemma 5, the followings hold with a probability at least 1− δ,\nλmax (Z) = ‖K−1/2K̂K−1/2‖2 ≤ 1 + ǫ and λmin(Z) = λd ( K−1/2K̂K−1/2 ) ≥ 1− ǫ,\nwhich yields that ‖Z − I‖ ≤ ǫ provided\nτ ≥ 32r ǫ2 log 2d δ .\nThis lemma follows as desired.\nRecall that\nL̂t(w) = λ\n2 |w|2 +w⊤(c−t−1 − xt) +\n1 2 + 1 2\n( w⊤(xt − c−t−1)(xt − c−t−1)⊤w +w⊤Ŝ−t w )\nif yt = 1; otherwise,\nL̂t(w) = λ\n2 |w|2 +w⊤(xt − c+t−1) +\n1 2 + 1 2\n( w⊤(xt − c+t−1)(xt − c+t−1)⊤w +w⊤Ŝ+t w ) .\nWe further define ŵ∗ as the optimal solution that minimizes the loss based on approximate covariance matrices, i.e.\nŵ∗ = argmin w\nT∑\nt=1\nL̂t(w).\nBased on Lemma 6, the following theorem gives an upper bound for |∑t L̂t(ŵ∗) −∑ t Lt(w∗)|.\nTheorem 7 Let r({S±t }Tt=1, λ) be the effective numerical rank for the set of covariance matrices S±t , t = 1, . . . , T with respect to the regularization parameter λ. Then, for any 0 < δ and 0 < ǫ ≤ 1/2, the followings hold with probability at least 1− δ\n|ŵ∗ −w∗| ≤ 2ǫ|w∗| (14)∣∣∣ ∑ t L̂t(ŵ∗)− ∑ t Lt(w∗) ∣∣∣ ≤ 2ǫ ∑ tLt(w∗) (15)\nprovided that\nτ ≥ 32r(S, λ) ǫ2 log 2d δT\nProof We first rewrite L(w) = ∑Tt=1 Lt(w) as\nL(w) = 1 2 +w⊤a+ 1 2 w⊤ (A1 +A2)w\nwhere\na = T∑\nt=1\nI[yt = 1] ( c−t−1 − xt ) + I[yt = −1] ( c+t−1 − xt )\nT\nA1 = λId + 1\nT\nT∑\nt=1\n( I[yt = 1]S − t−1 + I[yt = −1]S+t−1 )\nA2 = 1\nT\nT∑\nt=1\nI[yt = 1](xt − c−t )(xt − c−t )⊤ + 1\nT\nT∑\nt=1\nI[yt = −1](xt − c+t )(xt − c+t )⊤.\nSimilarly, we rewrite L̂(w) = ∑Tt=1 L̂t(w) as\nL̂(w) = 1 2 +w⊤a+ 1 2 w⊤\n( Ã1 +A2 ) w\nwhere\nÃ1 = λId+ 1\nT\nT∑\nt=1\nI[yt = 1][S − t−1] 1/2RtR ⊤ t [S − t−1]\n1/2+ 1\nT\nT∑\nt=1\nI[yt = −1][S+t−1]1/2RtR⊤t [S+t−1]1/2.\nThe optimal solutions for minimizing L(w) and L̂(w) are given, respectively, by\nw∗ = (A1 +A2) −1a and ŵ∗ = (Ã1 +A2) −1a.\nDefine ∆ = I −A−1/21 Ã1A −1/2 1 and write Ã1 in terms of ∆ as\nÃ1 = A1 −A1/21 ∆A 1/2 1\nUsing Lemma 6, it holds that ǫId ∆ ǫId with probability at least 1− δT , and therefore\n(1− ǫ)(A1 +A2) Ã1 +A2 (1 + ǫ)(A1 +A2)\nDenote by Ω = (A1 +A2) 1/2(A1 +A2) −1(A1 +A2)\n1/2 − I, and according to previous analysis, we have\n|Ω| ≤ ǫ 1− ǫ ≤ 2ǫ (16)\nfor ǫ < 1/2. Therefore,\n|ŵ∗ −w∗| = ∣∣∣ ( (Ã1 +A2) −1 − (A1 +A2)−1 ) a ∣∣∣\n= |(A1 +A2)−1/2Ω(A1 +A2)−1/2a| ≤ 2ǫ|(A1 +A2)−1a| ≤ 2ǫ|w∗|\nand ∣∣∣L̂(w∗)− L(w∗)\n∣∣∣ = 3 2 ∣∣∣a⊤ ( (Ã1 +A2) −1 − (A1 +A2)−1 ) a ∣∣∣\n= 3\n2\n∣∣∣a⊤ ( (A1 +A2) −1/2Ω(A1 +A2) −1/2 ) a ∣∣∣\n≤ 2ǫ ∣∣∣∣ 3\n2 a⊤(A1 +A2) −1a\n∣∣∣∣ ≤ 2ǫ ∣∣∣∣ 1\n2 +\n3 2 a⊤(A1 +A2) −1a ∣∣∣∣ = 2ǫL(w∗).\nThis theorem follows as desired.\nProof of Theorem 4: For |w∗| ≤ B, L(w∗) ≤ TL∗, and 0 < ǫ ≤ 1/2, we have\n|ŵ∗| ≤ |w∗|+ |ŵ∗ −w∗| ≤ 2B (17)\nfrom Eq. (14), and we further have\nL̂∗(ŵ∗) ≤ L(w∗) + |L̂∗(ŵ∗)− L(w∗)| ≤ 2L(w∗) ≤ 2TL∗ (18)\nfrom Eq. (15). Therefore, we have ∣∣∣∣∣ ∑\nt\nL̂(wt)− ∑\nt\nL(w∗) ∣∣∣∣∣ ≤ ∑\nt\nL̂(wt)− ∑\nt\nL(ŵ∗) + ∣∣∣∣∣ ∑\nt\nL̂(ŵ∗)− ∑\nt\nL(w∗) ∣∣∣∣∣ . (19)\nWe use Theorem 1 (in the main paper) to bound the first term in the above by combining Eqs. (17) and (18), and the second term can be bounded by Eq. (15). This completes the proof as desired."
    }, {
      "heading" : "6. Experiments",
      "text" : "We evaluate the performance of OPAUC on benchmark datasets and high-dimensional datasets in Sections 6.1 and 6.2, respectively. Then, we study the parameter influence in Section 6.3."
    }, {
      "heading" : "6.1 Comparison on Benchmark Data",
      "text" : "We conduct our experiments on sixteen benchmark datasets1,2,3 as summarized in Table 1. Some datasets have been used in previous studies on AUC optimization, whereas the other are large ones requiring one-pass procedure. The features have been scaled to [−1, 1] for all datasets. Multi-class datasets have been transformed into binary ones by randomly partitioning classes into two groups, where each group contains the same number of classes.\n1. http://www.sigkdd.org/kddcup/ 2. http://www.ics.uci.edu/˜mlearn/MLRepository.html 3. http://www.csie.ntu.edu.tw/˜cjlin/libsvmtools/\nIn addition to state-of-the-art online AUC approachesOAMseq andOAMgra (Zhao et al., 2011), we also compare with:\n• online Uni-Exp: An online learning algorithm which optimizes the (weighted) univariate exponential loss (Kotlowski et al., 2011);\n• online Uni-Squ: An online learning algorithm which optimizes the (weighted) univariate square loss;\n• SVM-perf: A batch learning algorithm which directly optimizes AUC (Joachims, 2005);\n• batch SVM-OR: A batch learning algorithm which optimizes the pairwise hinge loss (Joachims, 2006);\n• batch LS-SVM: A batch learning algorithm which optimizes the pairwise square loss;\n• batch Uni-Log: A batch learning algorithm which optimizes the (weighted) univariate logistic loss (Kotlowski et al., 2011);\n• batch Uni-Squ: A batch learning algorithm which optimizes the (weighted) univariate square loss.\nAll experiments are performed with Matlab 7 on a node of computational cluster with 16 CPUs (Intel Xeon Due Core 3.0GHz) running RedHat Linux Enterprise 5 with 48GB main memory. For batch algorithms, due to memory limit, 8,000 training examples are randomly chosen if training data size exceeds 8,000, whereas only 2,000 training examples are used for the epsilon dataset because of its high dimension.\nFive-fold cross-validation is executed on training sets to decide the learning rate ηt ∈ 2[−12:10] for online algorithms, the regularized parameter λ ∈ 2[−10:2] for OPAUC and λ ∈ 2[−10:10] for batch algorithms. For OAMseq and OAMgra, the buffer sizes are fixed to be 100 as recommended in (Zhao et al., 2011). For univariate approaches, the weights (i.e., class ratios) are chosen as done in (Kotlowski et al., 2011).\nThe performances of the compared methods are evaluated by five trials of 5-fold cross validation, where the AUC values are obtained by averaging over these 25 runs. Table 2 shows that OPAUC is significant better than the other four online algorithms OAMseq, OAMgra, online Uni-Exp and online Uni-Squ, particularly for large datasets. The win/tie/loss counts show that OPAUC is clearly superior to these online algorithms, as it wins for most times and never loses. Table 3 shows shows that OPAUC is highly competitive to the other five batch learning algorithms; this is impressive because these batch algorithms require storing the whole training dataset whereas OPAUC does not store training data. Additionally, batch LS-SVM which optimizes the square loss is comparable to the other batch algorithms, verifying our argument that square loss is effective for AUC optimization.\nWe also compare the running time of OPAUC and the online algorithms OAMseq, OAMgra, online Uni-Exp and online Uni-Squ, and the average CPU time (in seconds) are shown in Figure 1. As expected, online Uni-Squ and online Uni-Exp takes the least time cost because they optimize on single-instance (univariate) loss, whereas the other algorithms work by optimizing pairwise loss. On most datasets, the running time of OPAUC is competitive to OAMseq and OAMgra, except on the mnist and epsilon datasets which have the highest dimension in Table 1."
    }, {
      "heading" : "6.2 Comparison on High-Dimensional Data",
      "text" : "Next, we study the performance of using low-rank matrices to approximate the full covariance matrices, denoted by OPAUCr. Six datasets4,5 with nearly or more than 50,000 features are used, as summarized in Table 4. The news20.binary dataset contains two classes, different from news20 dataset. The original news20 and sector are multi-class datesets; in our experiments, we randomly group the multiple classes into two meta-classes each containing the same number of classes, and we also use the sector.lvr dataset which regards the largest class as positive whereas the union of other classes as negative. The original ecml2012 and rcv1v2 are multi-label datasets; in our experiments, we only consider the label with the largest population, and remove the features in ecml2012 dataset that take zero values for all instances.\nBesides the online algorithms OAMseq, OAMgra, online Uni-Exp and online Uni-Squ, we also evaluate three variants of OPAUC to study the effectiveness of approximating full covariance matrices with low-rank matrices:\n• OPAUCf: Randomly selects 1, 000-dim features and then works with full covariance matrices;\n4. http://www.csie.ntu.edu.tw/˜cjlin/libsvmtools/ 5. http://www.ecmlpkdd2012.net/discovery-challenge\n• OPAUCrp: Projects into a 1, 000-dim feature space by Random Projection, and then works with full covariance matrices;\n• OPAUCpca: Projects into a 1, 000-dim feature space obtained by Principle Component Analysis, and then works with full covariance matrices.\nSimilar to Section 5.1, five-fold cross validation is executed on training sets to decide the learning rate ηt ∈ 2[−12:10] and the regularization parameter λ ∈ 2[−10:2]. Due to memory and computational limit, the buffer sizes are set to 50 for OAMseq and OAMgra, and the rank τ of OPAUCr is also set to 50. The performances of the compared methods are evaluated by five trials of 5-fold cross validation, where the AUC values are obtained by averaging over these 25 runs.\nThe comparison results are summarized in Table 5 and the average running time is shown in Figure 2. These results clearly show that our approximate OPAUCr approach is superior to the other compared methods. Compared with OAMseq and OAMgra, the running time costs are comparable whereas the performance of OPAUCr is better. Online Uni-Squ and Uni-Exp are more efficient than OPAUCr because it optimizes univariate loss, but the performance of OPAUCr is highly competitive or better, except on rcv1v2, the only dataset with less than 50,000 features. Compared with the three variants, OPAUCf and OPAUCrp are more efficient, but with much worse performances. OPAUCpca achieves a better performance on rcv1v2, but it is worse on datasets with more features; particularly, on the two datasets with the largest number of features, OPAUCpca cannot return results even after running out 106 seconds (almost 11.6 days). Our approximate OPAUCr approach is significantly better than all the other methods (if they return results) on the two datasets\nwith the largest number of features: news.binary with more than 1 million features, and ecml2012 with nearby 100 thousands features. These observations validate the effectiveness of the low-rank approximation used by OPAUCr for handling high-dimensional data."
    }, {
      "heading" : "6.3 Parameter Influence",
      "text" : "We study the influence of parameters in this section. Figure 3 shows that stepsize ηt should not be set to values bigger than 1, whereas there is a relatively big range between [2−12, 2−4] where OPAUC achieves good results. Figures 4 shows that OPAUC is not sensitive to the value of regularization parameter λ given that it is not set with a big value. Figure 5 shows that OPAUCr is not sensitive to the values of rank τ , and it works well even when τ = 50; this verifies Theorem 4 that a relatively small τ value suffices to lead to a good approximation performance. Figure 6 compares studies the influence of the iterations for OPAUC, OAMseq and OAMgra, and it is observable that OPAUC convergence faster than the other two algorithms, which verifies our theoretical argument in Section 4."
    }, {
      "heading" : "7. Conclusion",
      "text" : "In this paper, we study one-pass AUC optimization that requires going through the training data only once, without storing the entire dataset. Here, a big challenge lies in the fact that AUC is measured by a sum of losses defined over pairs of instances from different classes. We propose the OPAUC approach, which employs a square loss and requires the storing of only the first and second-statistics for the received training examples. A nice property of OPAUC is that its storage requirement is O(d2), where d is the dimension of data, independent from the number of training examples. To handle high-dimensional data, we develop an approximate strategy by using low-rank matrices. The effectiveness of our proposed approach is verified both theoretically and empirically. In particular, the performance of OPAUC is significantly better than state-of-the-art online AUC optimization approaches, even highly competitive to batch learning approaches; the approximate OPAUC is significantly better than all compared methods on large datasets with one hundred thousands or even more than one million features. An interesting future issue is to develop one-pass AUC optimization approaches not only with a performance comparable to batch approaches, but also with an efficiency comparable to univariate loss optimization approaches."
    } ],
    "references" : [ {
      "title" : "Prediction, learning, and games",
      "author" : [ "N. Cesa-Bianchi", "G. Lugosi" ],
      "venue" : null,
      "citeRegEx" : "Cesa.Bianchi and Lugosi.,? \\Q2006\\E",
      "shortCiteRegEx" : "Cesa.Bianchi and Lugosi.",
      "year" : 2006
    }, {
      "title" : "AUC optimization vs. error rate minimization",
      "author" : [ "C. Cortes", "M. Mohri" ],
      "venue" : "In Advances in Neural Information Processing Systems",
      "citeRegEx" : "Cortes and Mohri.,? \\Q2004\\E",
      "shortCiteRegEx" : "Cortes and Mohri.",
      "year" : 2004
    }, {
      "title" : "A coherent interpretation of AUC as a measure of aggregated classification performance",
      "author" : [ "P.A. Flach", "J. Hernández-Orallo", "C.F. Ramirez" ],
      "venue" : "In Proceedings of the 28th International Conference on Machine Learning,",
      "citeRegEx" : "Flach et al\\.,? \\Q2011\\E",
      "shortCiteRegEx" : "Flach et al\\.",
      "year" : 2011
    }, {
      "title" : "On the consistency of AUC optimization",
      "author" : [ "W. Gao", "Z.-H. Zhou" ],
      "venue" : "CoRR, 1208.0645v3,",
      "citeRegEx" : "Gao and Zhou.,? \\Q2012\\E",
      "shortCiteRegEx" : "Gao and Zhou.",
      "year" : 2012
    }, {
      "title" : "Tail bounds for all eigenvalues of a sum of random matrices",
      "author" : [ "Alex Gittens", "Joel A. Tropp" ],
      "venue" : "CoRR, abs/1104.4513v2,",
      "citeRegEx" : "Gittens and Tropp.,? \\Q2011\\E",
      "shortCiteRegEx" : "Gittens and Tropp.",
      "year" : 2011
    }, {
      "title" : "A method of comparing the areas under receiver operating characteristic curves derived from the same cases",
      "author" : [ "J.A. Hanley", "B.J. McNeil" ],
      "venue" : null,
      "citeRegEx" : "Hanley and McNeil.,? \\Q1983\\E",
      "shortCiteRegEx" : "Hanley and McNeil.",
      "year" : 1983
    }, {
      "title" : "Rank-Deficient and Discrete Ill-Posed Problems: Numerical Aspects of Linear Inversion",
      "author" : [ "P.C. Hansen" ],
      "venue" : "Society for Industrial and Applied Mathematics,",
      "citeRegEx" : "Hansen.,? \\Q1987\\E",
      "shortCiteRegEx" : "Hansen.",
      "year" : 1987
    }, {
      "title" : "Optimising area under the ROC curve using gradient descent",
      "author" : [ "A. Herschtal", "B. Raskutti" ],
      "venue" : "In Proceedings of the 21st International Conference on Machine Learning, Alberta,",
      "citeRegEx" : "Herschtal and Raskutti.,? \\Q2004\\E",
      "shortCiteRegEx" : "Herschtal and Raskutti.",
      "year" : 2004
    }, {
      "title" : "Random design analysis of ridge regression",
      "author" : [ "D. Hsu", "S. Kakade", "T. Zhang" ],
      "venue" : "In Proceedings of the 25th Annual Conference on Learning Theory,",
      "citeRegEx" : "Hsu et al\\.,? \\Q2012\\E",
      "shortCiteRegEx" : "Hsu et al\\.",
      "year" : 2012
    }, {
      "title" : "A support vector method for multivariate performance measures",
      "author" : [ "T. Joachims" ],
      "venue" : "In Proceedings of the 22nd International Conference on Machine Learning,",
      "citeRegEx" : "Joachims.,? \\Q2005\\E",
      "shortCiteRegEx" : "Joachims.",
      "year" : 2005
    }, {
      "title" : "Training linear svms in linear time",
      "author" : [ "T. Joachims" ],
      "venue" : "In Proceedings of the 12th ACM SIGKDD international conference on Knowledge Discovery and Data Mining,",
      "citeRegEx" : "Joachims.,? \\Q2006\\E",
      "shortCiteRegEx" : "Joachims.",
      "year" : 2006
    }, {
      "title" : "High dimensional statistical inference and random matrices",
      "author" : [ "I. Johnstone" ],
      "venue" : "In Proceedings of the International Congress of Mathematicians,",
      "citeRegEx" : "Johnstone.,? \\Q2006\\E",
      "shortCiteRegEx" : "Johnstone.",
      "year" : 2006
    }, {
      "title" : "Bipartite ranking through minimization of univariate loss",
      "author" : [ "W. Kotlowski", "K. Dembczynski", "E. Hüllermeier" ],
      "venue" : "In Proceedings of the 28th International Conference on Machine Learning,",
      "citeRegEx" : "Kotlowski et al\\.,? \\Q2011\\E",
      "shortCiteRegEx" : "Kotlowski et al\\.",
      "year" : 2011
    }, {
      "title" : "Exploratory undersampling for class-imbalance learning",
      "author" : [ "X.-Y. Liu", "J. Wu", "Z.-H. Zhou" ],
      "venue" : "IEEE Trans. Systems, Man, and Cybernetics - B,",
      "citeRegEx" : "Liu et al\\.,? \\Q2009\\E",
      "shortCiteRegEx" : "Liu et al\\.",
      "year" : 2009
    }, {
      "title" : "Basic principles of ROC analysis",
      "author" : [ "C.E. Metz" ],
      "venue" : "Seminars in Nuclear Medicine,",
      "citeRegEx" : "Metz.,? \\Q1978\\E",
      "shortCiteRegEx" : "Metz.",
      "year" : 1978
    }, {
      "title" : "Introductory lectures on convex optimization: A basic course",
      "author" : [ "Y. Nesterov" ],
      "venue" : null,
      "citeRegEx" : "Nesterov.,? \\Q2003\\E",
      "shortCiteRegEx" : "Nesterov.",
      "year" : 2003
    }, {
      "title" : "The case against accuracy estimation for comparing induction algorithms",
      "author" : [ "F.J. Provost", "T. Fawcett", "R. Kohavi" ],
      "venue" : "In Proceedings of the 15th International Conference on Machine Learning,",
      "citeRegEx" : "Provost et al\\.,? \\Q1998\\E",
      "shortCiteRegEx" : "Provost et al\\.",
      "year" : 1998
    }, {
      "title" : "Making gradient descent optimal for strongly convex stochastic optimization",
      "author" : [ "A. Rakhlin", "O. Shamir", "K. Sridharan" ],
      "venue" : "In Proceedings of the 29th International Conference on Machine Learning,",
      "citeRegEx" : "Rakhlin et al\\.,? \\Q2012\\E",
      "shortCiteRegEx" : "Rakhlin et al\\.",
      "year" : 2012
    }, {
      "title" : "Margin-based ranking and an equivalence between AdaBoost and RankBoost",
      "author" : [ "C. Rudin", "R.E. Schapire" ],
      "venue" : "Journal of Machine Learning Research,",
      "citeRegEx" : "Rudin and Schapire.,? \\Q2009\\E",
      "shortCiteRegEx" : "Rudin and Schapire.",
      "year" : 2009
    }, {
      "title" : "Online Learning: Theory, Algorithms, and Applications",
      "author" : [ "S. Shalev-Shwartz" ],
      "venue" : "PhD thesis, Hebrew University of Jerusalem,",
      "citeRegEx" : "Shalev.Shwartz.,? \\Q2007\\E",
      "shortCiteRegEx" : "Shalev.Shwartz.",
      "year" : 2007
    }, {
      "title" : "Smoothness, low noise and fast rates",
      "author" : [ "N. Srebro", "K. Sridharan", "A. Tewari" ],
      "venue" : "In Advances in Neural Information Processing Systems",
      "citeRegEx" : "Srebro et al\\.,? \\Q2010\\E",
      "shortCiteRegEx" : "Srebro et al\\.",
      "year" : 2010
    }, {
      "title" : "Online AUC maximization",
      "author" : [ "P. Zhao", "S. Hoi", "R. Jin", "T. Yang" ],
      "venue" : "In Proceedings of the 28th International Conference on Machine Learning,",
      "citeRegEx" : "Zhao et al\\.,? \\Q2011\\E",
      "shortCiteRegEx" : "Zhao et al\\.",
      "year" : 2011
    } ],
    "referenceMentions" : [ {
      "referenceID" : 14,
      "context" : "Introduction AUC (Area Under ROC curve) (Metz, 1978; Hanley and McNeil, 1983) is an important performance measure that has been widely used in many tasks (Provost et al.",
      "startOffset" : 40,
      "endOffset" : 77
    }, {
      "referenceID" : 5,
      "context" : "Introduction AUC (Area Under ROC curve) (Metz, 1978; Hanley and McNeil, 1983) is an important performance measure that has been widely used in many tasks (Provost et al.",
      "startOffset" : 40,
      "endOffset" : 77
    }, {
      "referenceID" : 16,
      "context" : "Introduction AUC (Area Under ROC curve) (Metz, 1978; Hanley and McNeil, 1983) is an important performance measure that has been widely used in many tasks (Provost et al., 1998; Cortes and Mohri, 2004; Liu et al., 2009; Flach et al., 2011).",
      "startOffset" : 154,
      "endOffset" : 238
    }, {
      "referenceID" : 1,
      "context" : "Introduction AUC (Area Under ROC curve) (Metz, 1978; Hanley and McNeil, 1983) is an important performance measure that has been widely used in many tasks (Provost et al., 1998; Cortes and Mohri, 2004; Liu et al., 2009; Flach et al., 2011).",
      "startOffset" : 154,
      "endOffset" : 238
    }, {
      "referenceID" : 13,
      "context" : "Introduction AUC (Area Under ROC curve) (Metz, 1978; Hanley and McNeil, 1983) is an important performance measure that has been widely used in many tasks (Provost et al., 1998; Cortes and Mohri, 2004; Liu et al., 2009; Flach et al., 2011).",
      "startOffset" : 154,
      "endOffset" : 238
    }, {
      "referenceID" : 2,
      "context" : "Introduction AUC (Area Under ROC curve) (Metz, 1978; Hanley and McNeil, 1983) is an important performance measure that has been widely used in many tasks (Provost et al., 1998; Cortes and Mohri, 2004; Liu et al., 2009; Flach et al., 2011).",
      "startOffset" : 154,
      "endOffset" : 238
    }, {
      "referenceID" : 7,
      "context" : "Many algorithms have been developed to optimize AUC based on surrogate losses (Herschtal and Raskutti, 2004; Joachims, 2006; Rudin and Schapire, 2009; Kotlowski et al., 2011; Zhao et al., 2011).",
      "startOffset" : 78,
      "endOffset" : 193
    }, {
      "referenceID" : 10,
      "context" : "Many algorithms have been developed to optimize AUC based on surrogate losses (Herschtal and Raskutti, 2004; Joachims, 2006; Rudin and Schapire, 2009; Kotlowski et al., 2011; Zhao et al., 2011).",
      "startOffset" : 78,
      "endOffset" : 193
    }, {
      "referenceID" : 18,
      "context" : "Many algorithms have been developed to optimize AUC based on surrogate losses (Herschtal and Raskutti, 2004; Joachims, 2006; Rudin and Schapire, 2009; Kotlowski et al., 2011; Zhao et al., 2011).",
      "startOffset" : 78,
      "endOffset" : 193
    }, {
      "referenceID" : 12,
      "context" : "Many algorithms have been developed to optimize AUC based on surrogate losses (Herschtal and Raskutti, 2004; Joachims, 2006; Rudin and Schapire, 2009; Kotlowski et al., 2011; Zhao et al., 2011).",
      "startOffset" : 78,
      "endOffset" : 193
    }, {
      "referenceID" : 21,
      "context" : "Many algorithms have been developed to optimize AUC based on surrogate losses (Herschtal and Raskutti, 2004; Joachims, 2006; Rudin and Schapire, 2009; Kotlowski et al., 2011; Zhao et al., 2011).",
      "startOffset" : 78,
      "endOffset" : 193
    }, {
      "referenceID" : 0,
      "context" : "Although many online learning algorithms have been developed to find the optimal solution of some performance measures by only scanning the training data once (Cesa-Bianchi and Lugosi, 2006), few effort addresses one-pass AUC optimization.",
      "startOffset" : 159,
      "endOffset" : 190
    }, {
      "referenceID" : 0,
      "context" : "Although many online learning algorithms have been developed to find the optimal solution of some performance measures by only scanning the training data once (Cesa-Bianchi and Lugosi, 2006), few effort addresses one-pass AUC optimization. Unlike the classical classification and regression problems where the loss function can be calculated on a single training example, AUC is measured by the losses defined over pairs of instances from different classes, making it challenging to develop algorithms for one-pass optimization. An online AUC optimization algorithm was proposed very recently by Zhao et al. (2011). It is based on the idea of reservoir sampling, and achieves a solid regret bound by only storing √ T instances, where T is the number of training examples.",
      "startOffset" : 160,
      "endOffset" : 615
    }, {
      "referenceID" : 21,
      "context" : "Zhao et al. (2011) addressed this challenge by exploiting the reservoir sampling technique.",
      "startOffset" : 0,
      "endOffset" : 19
    }, {
      "referenceID" : 3,
      "context" : "In contrast, loss functions such as hinge loss are proven to be inconsistent with AUC (Gao and Zhou, 2012).",
      "startOffset" : 86,
      "endOffset" : 106
    }, {
      "referenceID" : 11,
      "context" : "An alternative approach for the high-dimensional case is through the random projection (Johnstone, 2006; Hsu et al., 2012).",
      "startOffset" : 87,
      "endOffset" : 122
    }, {
      "referenceID" : 8,
      "context" : "An alternative approach for the high-dimensional case is through the random projection (Johnstone, 2006; Hsu et al., 2012).",
      "startOffset" : 87,
      "endOffset" : 122
    }, {
      "referenceID" : 21,
      "context" : "Compared to the online AUC optimization algorithm (Zhao et al., 2011), which achieves at most O(1/ √ T ) convergence rate, our proposed algorithm clearly reduce the regret.",
      "startOffset" : 50,
      "endOffset" : 69
    }, {
      "referenceID" : 17,
      "context" : "The faster convergence rate of our proposed algorithm owes to the smoothness of the square loss, an important property that has been explored by some studies of online learning (Rakhlin et al., 2012) and generalization error bound analysis (Srebro et al.",
      "startOffset" : 177,
      "endOffset" : 199
    }, {
      "referenceID" : 20,
      "context" : ", 2012) and generalization error bound analysis (Srebro et al., 2010).",
      "startOffset" : 48,
      "endOffset" : 69
    }, {
      "referenceID" : 6,
      "context" : "To capture the skewed eigenvalue distribution, we introduce the concept of effective numerical rank (Hansen, 1987) that generalizes the rank of matrix: Definition 3 For a positive constant μ > 0 and semi-positive definite matrix M ∈ Rd×d of eigenvalues {νi}, the effective numerical rank w.",
      "startOffset" : 100,
      "endOffset" : 114
    }, {
      "referenceID" : 3,
      "context" : "According to the analysis of (Gao and Zhou, 2012), it suffices to prove that, for every optimal solution f , i.",
      "startOffset" : 29,
      "endOffset" : 49
    }, {
      "referenceID" : 19,
      "context" : "2 Proof of Theorem 2 This proof is motivated from (Shalev-Shwartz, 2007; Srebro et al., 2010).",
      "startOffset" : 50,
      "endOffset" : 93
    }, {
      "referenceID" : 20,
      "context" : "2 Proof of Theorem 2 This proof is motivated from (Shalev-Shwartz, 2007; Srebro et al., 2010).",
      "startOffset" : 50,
      "endOffset" : 93
    }, {
      "referenceID" : 4,
      "context" : "Proof This proof technique is motivated from (Gittens and Tropp, 2011) by adding a bias matrix.",
      "startOffset" : 45,
      "endOffset" : 70
    }, {
      "referenceID" : 21,
      "context" : "In addition to state-of-the-art online AUC approachesOAMseq andOAMgra (Zhao et al., 2011), we also compare with: • online Uni-Exp: An online learning algorithm which optimizes the (weighted) univariate exponential loss (Kotlowski et al.",
      "startOffset" : 70,
      "endOffset" : 89
    }, {
      "referenceID" : 12,
      "context" : ", 2011), we also compare with: • online Uni-Exp: An online learning algorithm which optimizes the (weighted) univariate exponential loss (Kotlowski et al., 2011); • online Uni-Squ: An online learning algorithm which optimizes the (weighted) univariate square loss; • SVM-perf: A batch learning algorithm which directly optimizes AUC (Joachims, 2005); • batch SVM-OR: A batch learning algorithm which optimizes the pairwise hinge loss (Joachims, 2006); • batch LS-SVM: A batch learning algorithm which optimizes the pairwise square loss; • batch Uni-Log: A batch learning algorithm which optimizes the (weighted) univariate logistic loss (Kotlowski et al.",
      "startOffset" : 137,
      "endOffset" : 161
    }, {
      "referenceID" : 9,
      "context" : ", 2011); • online Uni-Squ: An online learning algorithm which optimizes the (weighted) univariate square loss; • SVM-perf: A batch learning algorithm which directly optimizes AUC (Joachims, 2005); • batch SVM-OR: A batch learning algorithm which optimizes the pairwise hinge loss (Joachims, 2006); • batch LS-SVM: A batch learning algorithm which optimizes the pairwise square loss; • batch Uni-Log: A batch learning algorithm which optimizes the (weighted) univariate logistic loss (Kotlowski et al.",
      "startOffset" : 179,
      "endOffset" : 195
    }, {
      "referenceID" : 10,
      "context" : ", 2011); • online Uni-Squ: An online learning algorithm which optimizes the (weighted) univariate square loss; • SVM-perf: A batch learning algorithm which directly optimizes AUC (Joachims, 2005); • batch SVM-OR: A batch learning algorithm which optimizes the pairwise hinge loss (Joachims, 2006); • batch LS-SVM: A batch learning algorithm which optimizes the pairwise square loss; • batch Uni-Log: A batch learning algorithm which optimizes the (weighted) univariate logistic loss (Kotlowski et al.",
      "startOffset" : 280,
      "endOffset" : 296
    }, {
      "referenceID" : 12,
      "context" : ", 2011); • online Uni-Squ: An online learning algorithm which optimizes the (weighted) univariate square loss; • SVM-perf: A batch learning algorithm which directly optimizes AUC (Joachims, 2005); • batch SVM-OR: A batch learning algorithm which optimizes the pairwise hinge loss (Joachims, 2006); • batch LS-SVM: A batch learning algorithm which optimizes the pairwise square loss; • batch Uni-Log: A batch learning algorithm which optimizes the (weighted) univariate logistic loss (Kotlowski et al., 2011); • batch Uni-Squ: A batch learning algorithm which optimizes the (weighted) univariate square loss.",
      "startOffset" : 483,
      "endOffset" : 507
    }, {
      "referenceID" : 21,
      "context" : "For OAMseq and OAMgra, the buffer sizes are fixed to be 100 as recommended in (Zhao et al., 2011).",
      "startOffset" : 78,
      "endOffset" : 97
    }, {
      "referenceID" : 12,
      "context" : ", class ratios) are chosen as done in (Kotlowski et al., 2011).",
      "startOffset" : 38,
      "endOffset" : 62
    } ],
    "year" : 2013,
    "abstractText" : "AUC is an important performance measure and many algorithms have been devoted to AUC optimization, mostly by minimizing a surrogate convex loss on a training data set. In this work, we focus on one-pass AUC optimization that requires going through the training data only once without storing the entire training dataset, where conventional online learning algorithms cannot be applied directly because AUC is measured by a sum of losses defined over pairs of instances from different classes. We develop a regression-based algorithm which only needs to maintain the first and second-order statistics of training data in memory, resulting a storage requirement independent from the size of training data. To efficiently handle high-dimensional data, we develop a randomized algorithm that approximates the covariance matrices by low-rank matrices. We verify, both theoretically and empirically, the effectiveness of the proposed algorithm.",
    "creator" : "LaTeX with hyperref package"
  }
}