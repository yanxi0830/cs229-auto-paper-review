{
  "name" : "1406.7447.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "Unimodal Bandits without Smoothness",
    "authors" : [ "Richard Combes", "Alexandre Proutière" ],
    "emails" : [ ],
    "sections" : [ {
      "heading" : null,
      "text" : "√ T log(T )) and O( √ log(T )/T ),\nrespectively, when the time horizon T grows large. These scalings are achieved without the knowledge of ξ and C. Our algorithm is based on asymptotically optimal sequential statistical tests used to successively trim an interval that contains the best arm with high probability. To our knowledge, the SP algorithm constitutes the first sequential arm selection rule that achieves a regret and optimization error scaling as O( √ T ) and O(1/ √ T ), respectively, up to a logarithmic factor for non-smooth expected reward functions, as well as for smooth functions with unknown smoothness."
    }, {
      "heading" : "1 Introduction",
      "text" : "This paper considers the problem of stochastic unimodal optimization with bandit feedback which is a generalization of the classical multi-armed bandit problem solved by Lai and Robbins [19]. The problem is defined by a continuous and unimodal expected reward function µ defined on the interval [0, 1]. For this problem, we consider algorithms that repeatedly select an arm x ∈ [0, 1], and get a noisy reward of mean µ(x). The performance of an algorithm is characterized by its regret and its optimization error up to time horizon T (the number of observed noisy rewards). The regret is the difference between the average cumulative reward one would obtain if the function µ was known, i.e., T supx∈[0,1] µ(x), and the actual average cumulative reward achieved under the algorithm. The optimization error is the difference between supx∈[0,1] µ(x) and the expected reward of the arm selected at time T . Known lower bounds for the regret and optimization error scale as Ω( √ T ) (for linear reward functions) and Ω(1/ √ T ) (for quadratic reward functions), respectively. Our objective is to devise an algorithm whose regret and optimization error scale as O( √ T ) and O(1/ √ T ) up to a logarithmic factor for a large class of unimodal and continuous reward functions. Such an algorithm would hence be order-optimal. Importantly we merely make any assumption on the smoothness of the reward function – the latter can even be non-differentiable. This contrasts with all existing work investigating similar continuum-armed bandit problems, and where strong assumptions are made on the structure and smoothness of the reward function. These structure and smoothness are known to the decision maker, and are explicitly used in the design of efficient algorithms. ∗Supelec, France, mail: richard.combes@supelec.fr †KTH, Sweden, mail: alepro@kth.se\nar X\niv :1\n40 6.\n74 47\nv2 [\ncs .L\nG ]\n6 M\nar 2\n01 5\nWe propose Stochastic Pentachotomy (SP), an algorithm for which we derive finite-time upper bounds on regret and optimization error. In particular, we show that its regret and optimization error scale as O( √ T log(T )) and O( √ log(T )/T ) for any unimodal and continuous reward function µ that behaves as µ(x) = µ(x?) − C|x − x?|ξ locally around its maximizer x? for some ξ, C > 0. These scalings are achieved without the knowledge of ξ or C, i.e., without the knowledge of the smoothness of µ. The SP algorithm consists in successively narrowing an interval in [0, 1] while ensuring that the arm with the highest mean reward remains in this interval with high probability. The narrowing subroutine is a sequential test that takes as input an interval and samples a few arms in the interior of this interval until it gathers enough information to actually reduce the interval. We investigate a general class of such sequential tests. In particular, we provide a (finite time) lower bound of their expected sampling complexity given some guaranteed minimax risk, and design a sequential test that matches this lower bound. This optimal test is used in the SP algorithm. Interestingly, we show that to be efficient, a sequential test needs to sample at least three arms in the interior of the interval to reduce. This implies that a stochastic version of the celebrated Golden section search algorithm cannot achieve a reasonably low regret or optimization error over a large class of reward functions. Indeed such an algorithm would sample only two arms in the interval to reduce. We illustrate the performance of our algorithms using numerical experiments and compare its regret to that of existing algorithms that leverage the smoothness and structure of the reward function.\nTo our knowledge, SP is the first algorithm for continuous unimodal bandit problems that is orderoptimal for a large class of expected reward functions: Its regret and optimization error scale asO( √ T log(T ))\nand O( √\nlog(T )/T ) for non-smooth reward functions, as well as for smooth functions with unknown smoothness.\nRelated work. Stochastic bandit problems with a continuous set of arms have recently received a lot of attention. Various kinds of structured reward functions have been explored, i.e., linear [10], Lipschitz [2], [17], [5], and convex [1], [22]. In these papers, the knowledge of the structure greatly helps the design of efficient algorithms (e.g. for Lipschitz bandits, except in [6], the Lipschitz constant is assumed to be known). More importantly, the smoothness or regularity of the reward function near its maximizer is also assumed to be known and leveraged in the algorithms. Indeed, most existing algorithms use a discretization of the set of arms that depends on this smoothness, and this is crucial to guarantee a regret scaling as O( √ T ). As discussed in [5], [4], without the knowledge of the smoothness, these algorithms would yield a much higher regret (e.g. scaling as O(T 2/3) for the algorithm proposed in [4]). Unimodal bandits with a continuous set of arms have been addressed in [9], [24]. In [9], the author shows that Kiefer-Wolfowitz (KW) stochastic approximation algorithm achieves a regret of the order of O( √ T ) under some strong regularity assumptions on the reward function (strong convexity). LSE, the algorithm proposed in [24], has a regret that scales as O( √ T log(T )), but requires the knowledge of the smoothness of the reward function. LSE is a stochastic version of the Golden section search algorithm, and iteratively eliminates subsets of arms based on PAC-bounds derived after appropriate sampling. By design, under LSE, the sequence of parameters used for the PAC bounds is pre-defined, and in particular does not depend of the observed rewards. As a consequence, LSE may explore too much sub-optimal parts of the set of arms. Our algorithm exploits more adaptive sequential statistical tests to remove subsets of arms, and yields a lower regret even without the knowledge of the smoothness of the reward function. A naive way to address continuous-armed bandit problems consists in discretizing the set of arms, and in applying efficient discrete bandit algorithms. This method was introduced in [18], and revisited in [7] in the case of unimodal rewards. To get a regret scaling as O( √ T log(T )) using this method, the reward function needs to be smooth and the discretization should depend on the smoothness of the function near its maximizer.\nOur problem is related to stochastic derivative-free optimization problems where the goal is to get close to the maximizer of the reward function as quickly as possible, see e.g. [23], [14], and references therein. However, as explained in [1], minimizing regret and optimization error constitute different ob-\njectives. Finally, it is worth mentioning papers investigating the design of sampling strategies to identify the best arm in multi-armed bandit problems, see e.g. [21], [11], [3], [15], [13]. These strategies apply to finite sets of arms, but resemble our sequential statistical tests used to reduce the interval containing the best arm. We believe that our analysis (e.g. we derive finite-time lower bounds for the expected sampling complexity of a set of tests), and our proof techniques are novel."
    }, {
      "heading" : "2 Problem Formulation and Notation",
      "text" : "We consider continuous bandit problems where the set of arms is the interval [0, 1], and where the expected reward µ is a continuous and unimodal function of the arm. More precisely, there exists x? such that x 7→ µ(x) is strictly increasing (resp. decreasing) in [0, x?] (resp. in [x?, 1]). We denote by U the set of such functions. Define µ? = µ(x?).\nTime proceeds in rounds indexed by n = 1, 2, . . .. When arm x is selected in round n, the observed rewardXn(x) is a random variable whose expectation is µ(x) and whose distribution is ν(µ(x)), where ν refers to an exponential family of distributions with one parameter (e.g Bernoulli, exponential, Gaussian, ...). We assume that the rewards (Xn(x), n ≥ 1) are i.i.d., and are independent across arms. At each round, a decision rule or algorithm selects an arm depending on the arms chosen in earlier rounds, and the corresponding observed rewards. Let xπ(n) denote the arm selected in round n under the algorithm π. The set Π of all possible algorithms consists of sequential decision rules π such that for any n ≥ 2, xπ(n) is Fπn−1-measurable where Fπn is the σ-algebra generated by (xπ(s), Xs(xπ(s)), s = 1, . . . , n). The performance of an algorithm π ∈ Π with time horizon T is characterized by its regret Rπ(T ) and optimization error Eπ(T ) defined as Rπ(T ) = Tµ?− ∑T n=1 E[µ(xπ(n))] and Eπ(T ) = µ?−E[µ(xπ(T ))]. Our objective is to devise an algorithm minimizing these performance metrics. Importantly, the only information available to the decision maker about the reward function µ is that µ ∈ U . In particular, the smoothness of µ around x? remains unknown – actually µ could well not be differentiable, e.g. µ(x) = µ? − |x− x?|ξ for ξ ∈ (0, 1).\nNotation. In what follows, for any α, β, we denote by KL (α, β) the Kullback-Leibler divergence between distributions ν(α) and ν(β). When α, β ∈ [0, 1], and when ν(·) is the family of Bernoulli distributions, this KL divergence is denoted by KL2(α, β) = KL (α, β) = α log(αβ ) + (1−α) log( 1−α 1−β )."
    }, {
      "heading" : "3 Stochastic Polychotomy Algorithms",
      "text" : "We present here a family of sequential arm selection rules, referred to as Stochastic Polychotomy (SP). These algorithms consist in successively narrowing an interval in [0, 1] while ensuring that the best arm x? remains in this interval with high probability. Under the SP algorithms, the set of rounds is divided into phases, where each phase consists in running a subroutine narrowing the interval containing the best arm. The narrowing subroutine used the SP algorithms, and referred to as ITK (Interval Trimming withK sampled arms), starts with an interval I = [x, x] and K arms x1, . . . , xK with x ≤ x1 < . . . < xK ≤ x. It samples these K arms until a decision is taken to reduce the interval I and to output interval I ′ equal to either I1 = [x,max{xk : xk < x}] or I2 = [min{xk : xk > x}, x]. The subroutine ITK is described in details in the next subsection, and its outcome is illustrated in Figure 1.\nThe pseudo-code of the Stochastic Pentachotomy algorithm, an example of SP algorithm, is presented in Algorithm 1. It uses the narrowing subroutine IT3 exploiting samples from three arms in the interior of the input interval. IT3 splits the input interval into five parts (hence the name ”Pentachotomy”), and outputs a trimmed interval (referred to as I ′ in the pseudo-code) and its running time (expressed in number of rounds, and referred to as ` in the pseudo-code). The subroutine IT3 takes as input an interval, a time horizon (equal to the remaining number of rounds in the bandit problem), as well as a parameter controlling its risk, defined as the probability that the subroutine outputs an interval that does not contain\nAlgorithm 1 The Stochastic Pentachotomy algorithm Input parameters: time horizon T and confidence parameter γ > 1/2. Initialization: I ← [0, 1] and s← T . While s > 0:\nRun IT3(I, s, T−γ) and let (I ′, `) be its output, I ← I ′, s← s− `.\nthe arm with the highest reward. In the Stochastic Pentachotomy algorithm, the risk parameter in IT3 is always taken equal to T−γ where γ > 1/2. This choice will ensure that the regret of the algorithm has an optimal scaling in T . Note that LSE, the stochastic version of Golden section search algorithm, belongs to the family of SP algorithms (for LSE, K = 4, x1 = x, and x4 = x).\n3.1 ITK: Asymptotically Optimal Sequential Tests for Interval Trimming The narrowing subroutines used in each phase of SP algorithms can be interpreted as sequential tests whose final decision is to trim a specific part of the input interval. The ITK subroutine belongs to the following generic family T of sequential tests. Sequential Tests for Interval Trimming. A sequential test χ ∈ T takes as inputs (i) an interval I = [x, x] ⊂ [0, 1], and K arms to sample from x1, . . . , xK with x ≤ x1 < . . . < xK ≤ x, and (ii) a time horizon s that represents the maximum number of samples the test can gather. In round n ≤ s, the sequential test decides either to terminate and to output a reduced interval I1 = [x,max{xk : xk < x}] or I2 = [min{xk : xk > x}, x], or to acquire a new sample from one of the arms x1, . . . , xK . The successive decisions taken under sequential test χ are represented by Sχ(n) ∈ {0, 1, 2}. For n ≤ s, if Sχ(n) = 1, the sequential test terminates and outputs the interval I1. Similarly if Sχ(n) = 2, χ terminates and outputs I2. When Sχ(n) = 0 and n < s, the sequential test further samples an arm xχ(n) in {x1, . . . , xK}. Finally, if Sχ(s) = 0, we say that the test does not terminate, and it outputs the initial interval I . The sequential test is adapted in the sense that xχ(n) and Sχ(n) are Fχn−1-measurable. We denote by Sχ ∈ {0, 1, 2} the final outcome of the test χ. The length of a sequential test χ is defined as Lχ = inf{n ≤ s : Sχ(n) 6= 0} if the test terminates and Lχ = s otherwise. χ also outputs its length.\nITK Subroutine. To specify our sequential test χ =ITK , we introduce the following notation. Define the sets of functions Bu = {µ ∈ U : x? /∈ Iu}, u ∈ {1, 2}. We also introduce for any u ∈ {1, 2}, the function iu : RK+ → R with\niu(µ1, . . . , µK) = inf λ∈Bu K∑ k=1 KL (µk, λ(xk)).\nWe further denote by tχk (n) = ∑n∨Lχ n′=1 1{xχ(n′) = xk} the number of times arm xk is sampled up to time n and before the test χ terminates. Finally, we define the empirical average reward of arm xk up to round n ≤ Lχ as:\nµ̂k(n) = 1\ntχk (n) n∑ n′=1 Xn′(xk)1{xχ(n) = xk},\nif tχk (n) > 0 and µ̂k(n) = 0 otherwise. Let µ̂(n) = (µ̂1(n), . . . , µ̂K(n)) and t̄ χ(n) = min1≤k≤K t χ k (n). χ =ITK samples K arms in the interior of I = [x, x], i.e., x < x1 < . . . < xK < x. To simplify the presentation, we assume that for k = 1, . . . ,K, xk = x + k(x − x)/(K + 1). This assumption is not crucial, and our analysis remains valid for any choice of arms provided that they lie in the interior of I .\nThe sequential test χ =ITK has inputs I and s, as any other test in T . However χ takes an additional input ζ > 0, used to control its risk. Now ITK(I, s, ζ) is defined as follows.\nDefine F (f, s,K) = eK+1−f (fdf log(s)e/K)K ,\nand let f(s, ζ) ≥ K + 1 be such that F (f(s, ζ), s,K) ≤ ζ (the precise choice of f(s, ζ) is free). The test proceeds as follows: For any n ≤ s:\n(i) If there exists u ∈ {1, 2} such that t̄χ(n)iu(µ̂(n)) ≥ f(s, ζ), then Sχ(n) = u, i.e., χ terminates and its final output is Sχ = u (ties are broken arbitrarily if both conditions t̄χ(n)iu(µ̂(n)) ≥ f(s, ζ) for u = 1, 2 hold).\n(ii) Otherwise Sχ(n) = 0, and χ samples arm xχ(n) = x1+(n mod K).\nThe sequential test χ outputs the interval ISχ where I0 = [x, x], I1 = [x, xK ] and I2 = [x1, x], and its length Lχ.\nThe performance (i.e. the minimax risk and length) of ITK will be analysed in Section 4. In view of the results derived in Sections 4 and 5, ITK is asymptotically optimal among the sequential tests in T . The design of ITK (e.g. the use of functions iu, u ∈ {1, 2}) is actually motivated by the fundamental performance limits of tests in T derived in Section 5.\nRemark 1 In the following sections, we will mainly consider the case where the risk ζ = s−γ with γ > 0. In this case, one may choose f(s, s−γ) = f(s) := γ log(s) + 3K log(log(s)) + C, where C > 0 is independent of s and γ."
    }, {
      "heading" : "3.2 IT′3: A Computationally Efficient Sequential Test",
      "text" : "Next we present IT′3, a sequential test which is computationally simpler than IT3. IT ′ 3 is not asymptotically optimal, but its implementation is much simpler than that of IT3. Its rationale involves calculating an explicit lower bound of functions iu, u ∈ {1, 2}, and hence IT′3 does not require us to compute iu. For ≥ 0, we define the function KL?, : R2 → R as:\nKL?, (µ1, µ2) = 1{µ1 < µ2} [ KL ( µ1 + ,\nµ1 + µ2 2\n− ) + KL ( µ2 − ,\nµ1 + µ2 2 +\n)] .\nand KL?(µ1, µ2) = KL?,0(µ1, µ2). The sequential test χ′ = IT′3 with inputs I , s and ζ is defined by: for any n ≤ s,\n(i) If t̄χ ′ (n)KL?(µ̂1(n), µ̂2(n)) ≥ f(s, ζ), then Sχ ′ (n) = 1, i.e., χ′ terminates and its final output is\nSχ ′ = 1. Similarly if t̄χ ′ (n)KL?(µ̂3(n), µ̂2(n)) ≥ f(s, ζ), then Sχ ′ (n) = 2.\n(ii) Otherwise Sχ ′ (n) = 0, and χ′ samples arm xχ ′ (n) = x1+(n mod 3)."
    }, {
      "heading" : "4 Performance Analysis of the Stochastic Pentachotomy Algorithm",
      "text" : "In this section, we analyze the performance of the Stochastic Pentachotomy algorithm. To this aim, we first study how the interval trimming subroutines ITK (for K ≥ 3) and IT′3 perform.\n4.1 Minimax Risk and Length of ITK Let χ ∈ T be a sequential test for interval trimming. For any µ ∈ U , the risk αχ(µ) of χ is the probability that χ outputs an interval that does not contain the optimal arm, i.e, αχ(µ) = ∑2 u=1 1{µ ∈ Bu}Pµ[Sχ = u]. The minimax risk of χ is then defined as αχ = supµ∈U α χ(µ). Observe that a test that does not terminate (almost surely) has a risk equal to 0, but then its length would be maximal. The analysis of the performance of a test hence consists in characterizing the trade-off between its risk and its length. The next theorem provides upper bounds of the minimax risk of ITK , as well as of the number of times arms are sampled before the test terminates.\nTheorem 4.1 Let K ≥ 3 and I ⊂ [0, 1]. (i) For any s ≥ 1, the minimax risk of ITK(I, s, ζ) is smaller than ζ. (ii) Let γ > 0, u ∈ {1, 2} and k ∈ 1, . . . ,K. For all µ ∈ U \\Bu, the test χ =ITK(I, s, s−γ) satisfies:\nlim sup s→∞ Eµ[tχk (s)] log(s) ≤ γ iu(µ(x1), . . . , µ(xK)) .\nThe above theorem provides asymptotic guarantees on the length of ITK . Next, we provide a finitetime analysis of the length of IT3 and IT′3, and we also derive an upper bound of the minimax risk of IT′3.\nFinite-time analysis of IT3 and IT′3. The next theorem provides explicit upper bounds on the expected length of IT3 and IT′3. A high-probability upper-bound on the test length is also provided. This result relies on an explicit lower bound of iu(µ1, µ2, µ3). Theorem 4.2 will be instrumental in the regret analysis of the Stochastic Pentachotomy algorithm. We restrict the analysis to Bernoulli rewards. This is mainly for simplicity, and the proof techniques can be extended to sub-Gaussian rewards with straightforward modifications.\nTheorem 4.2 Consider I ⊂ [0, 1], γ > 0 and tests χ ∈ {IT3(I, s, s−γ), IT′3(I, s, s−γ)}. (i) χ has minimax risk less than s−γ . (ii) Define m = 1 if x? ∈ [x2, x] and m = 3 otherwise. Define δ = (µ(x2)− µ(xm))/2. Then, we have that for all 0 < < δ/2, for all k = 1, 2, 3 and all s ≥ 1:\nEµ[tχk (s)] ≤ f(s) KL?, (µ(xm), µ(x2)) + 2 −2.\n(iii) We have the following inequalities:\n(a) Pµ[tχk (s) ≥ 8f(s)δ −2] ≤ 2e−f(s)\n(b) Eµ[tχk (s)] ≤ 32 + f(s)\nδ2\n(c) lim sup s→∞ Eµ[tχk (s)] log(s) ≤ γ KL?(µ(xm), µ(x2)) .\nRecall that f(s) := γ log(s) + 9 log(log(s)) + C, see Remark 1."
    }, {
      "heading" : "4.2 Regret Upper Bounds of the SP algorithm",
      "text" : "Next, we analyze the regret of the Stochastic Pentachotomy algorithm. We refer to as SP’ the algorithm using the narrowing subroutines IT′3 (instead of IT3 for SP). Recall that the successive narrowing subroutines IT3, the risk is always chosen equal to T−γ , as specified in Algorithm 1. We first derive an upper bound valid for all µ ∈ U and all time horizon T . We then specify the bound when µ behaves as µ(x) = µ(x?) − C|x − x?|ξ locally around its maximizer x? for some ξ, C > 0. To simplify the presentation, our bounds are stated and proved for Bernoulli rewards, but the analysis can be extended to other exponential families of distributions.\nLet µ ∈ U . For any ∆ > 0, define the following functions, which will be used to state our regret upper bound:\ngµ(∆) = µ ? −max(µ(x? −∆), µ(x? + ∆))\nhµ(∆) = min\n{ min\nx∈[x?,x?+∆/4] (µ(x)− µ(x+ ∆/4)), min x∈[x?−∆/4,x?] (µ(x)− µ(x−∆/4)) } Theorem 4.3 Let ψ = 3/4. Under Algorithm π = SP or π = SP’, for all µ ∈ U , all T ≥ 1, and all N ≥ 1, the regret satisfies:\nRπ(T ) ≤ µ?NT 1−γ + Tgµ(ψN ) + 3(f(T ) + 32) N−1∑ N ′=0 gµ(ψ N ′)hµ(ψ N ′)−2.\nWe now make the regret upper bound of Theorem 4.3 explicit by considering a particular class of unimodal functions.\nDefinition 4.4 For given 0 < C1 ≤ C2 < ∞, we define U(C1, C2) the set of all unimodal functions µ ∈ U for which there exists ξ > 0 such that:\n(P1) µ(x)− µ(y) ≥ C1(|x? − y|ξ − |x? − x|ξ) for all 0 ≤ y ≤ x ≤ x? and x? ≤ x ≤ y ≤ 1.\n(P2) |µ? − µ(x)| ≤ C2|x? − x|ξ for all x ∈ [0, 1].\nNote that for any µ ∈ U such that |µ? − µ(x)| ∼x→x? C|x? − x|ξ with C > 0, there exists C1 > 0 suitably small and C2 < ∞ suitably large such that µ ∈ U(C1, C2). Also note that if µ ∈ U is differentiable on [0, 1] \\ {x?}, with C1|x? − x|ξ−1 ≤ |µ′(x)| ≤ C2|x? − x|ξ−1, then µ ∈ U(C1, C2).\nTheorem 4.5 Assume that the algorithm π = SP or π = SP’is parametrized by γ > 1/2. For all µ ∈ U(C1, C2), the regret satisfies:\nRπ(T ) ≤ 2ψ −3ξ/2C2 C1aξ\n√ 3T (f(T ) + 32)\nψ−ξ − 1 + µ?T 1−γ\nlog(TC1ψ −ξ)\nξ log(1/ψ) = O(\n√ T log(T )).\nwhere aξ = 4−ξ min(1, 2ξ − 1), and where ξ is the parameter associated with µ in Definition 4.4.\nTheorem 4.5 states that SP and SP’ are order-optimal for all reward functions in U(C1, C2) (with arbitrary C1 and C2). They achieve a regret scaling as O( √ T log(T )) without the knowledge of the behaviour of the reward function around its maximizer. Although the regret upper bound of Theorem 4.5 is stated for reward functions in class U(C1, C2), we emphasize again that C1, C2 and ξ are not input parameters of the algorithms."
    }, {
      "heading" : "4.3 Optimization error of the SP algorithm",
      "text" : "We conclude this section by deriving an upper bound on the optimization error of algorithms SP and SP’.\nTheorem 4.6 Let ψ = 3/4. Assume that the algorithm π = SP or π = SP’is parametrized by γ > 1/2. For all µ ∈ U(C1, C2), the optimization error under π satisfies:\nEπ(T ) ≤ C2 C1aξ\n√ 24f(T )\nT (ψ−2ξ − 1) +\n3T−γµ? log(TC1ψ −ξ)\nξ log(1/ψ) = O(\n√ log(T )/T ),\nwith aξ = 4−ξ min(1, 2ξ − 1), and where ξ is the parameter associated with µ in Definition 4.4."
    }, {
      "heading" : "5 Fundamental Performance Limits for Interval Trimming Subroutines",
      "text" : "The next theorem provides a lower bound on the expected number of times each arm xk, k = 1, . . . ,K must be sampled under any sequential test with given minimax risk. The lower bound is valid for any time horizon s, which contrasts with the asymptotic lower bounds usually derived in the bandit literature (see e.g. [19]). The proof of this lower bound relies on an elegant information-theoretic argument that exploits the log-sum inequality to derive lower bounds of KL divergence numbers.\nTheorem 5.1 Let χ ∈ T be a sequential test for interval trimming with minimax risk α. Let µ ∈ U , and u ∈ {1, 2}. Let β = Pµ[Sχ = u]. If α ≤ β, then\ninf λ∈Bu K∑ k=1 Eµ[tχk (s)]KL (µ(xk), λ(xk)) ≥ KL2(β, α).\nFrom the above result, we deduce Corollary 5.2 stating that any sequential test with time horizon s and with minimax risk s−γ , for γ ∈ (0, 1], has a length that scales at least as γ log(s) as s grows large. Note that the sequential tests ITK match these lower bound and are hence asymptotically optimal.\nCorollary 5.2 Let γ ∈ (0, 1], u ∈ {1, 2}, and µ ∈ U . Consider a sequence (indexed by s) of sequential tests χs with time horizon s and minimax risk αχs = s−γ , such that lims→∞ Pµ[Sχs = u] = β > 0. Then: lim infs→∞ infλ∈Bu ∑K k=1 Eµ[tχsk (s)] log(s) KL (µ(xk), λ(xk)) ≥ γβ.\nAnother consequence of Theorem 5.1 is presented in Corollary 5.3. The latter states that it is impossible to construct a sequential test that samples at most two arms in the interior of I , that terminates before the time horizon s with probability larger than 1/2 and that has a minimax risk strictly less than 1/4. Note that if a test terminates before s with probability less than 1/2, its expected length is at least s/2. Such a test would be useless in bandit problems since running it with time horizon s = T would incur a regret linearly growing with T .\nCorollary 5.3 Consider the family of sequential tests running on the interval I = [x, x], and arms x = x1 < x2 < x3 < x4 = x. There exists µ ∈ U , such that for any sequential test χ of this family with arbitrary finite time horizon s and minimax risk α < 1/4, we have Pµ[Sχ 6= 0] ≤ 1/2 (i.e., the test does not terminate before s with probability 1/2).\nRecall that Kiefer’s Golden section search algorithm [16] uses two points in the interior of the interval to reduce. Hence, the above corollary implies that it is impossible to construct a stochastic version of this algorithm that performs well without additional assumptions on the smoothness and structure of the reward function. Actually, LSE, proposed in [24], is a stochastic version of the Golden section search algorithm, but to analyze its regret, additional assumptions on the structure of the reward function are made (its minimal slope and smoothness).\nCorollary 5.3 is a direct consequence of Theorem 5.1: the choice of the reward function µ used in Corollary 5.3 is illustrated in Figure 2, and the result is obtained by considering a sequence (indexed by > 0) of unimodal functions λ ∈ B1. An efficient test must distinguish between µ and λ based on the reward samples at x1, x2, x3, x4. By letting → 0, we see that under such a test, the number of samples from x3 must be arbitrary large."
    }, {
      "heading" : "6 Numerical Experiments",
      "text" : "In this section, we briefly explore the performance of SP′ (using parameter γ = 0.6), and compare it to that of two other algorithms, namely KL-UCB(δ) and KW. KL-UCB(δ) consists in applying the KLUCB algorithm [12] to the discrete set of arms {0, δ, 2δ, . . . , 1}. KW is the algorithm proposed in [9]. The performance of LSE [24] is not reported here, since it is generally outperformed by KL-UCB(δ), as shown in [7].\nWe consider two reward functions satisfying our assumptions with ξ = 1/2 and ξ = 2, respectively. More precisely, µ(x) = 1 − (2|1/2 − x|)ξ for x ∈ [0, 1]. The first function is not differentiable at its maximizer, whereas the second function is just quadratic. Note that KW should then perform well for the quadratic rewards (there the regret scales as O( √ T ) [9]), but there is not guarantee that it would do well for the non-differentiable reward functions. For KL-UCB(δ), the optimal discretization step δ depends on the smoothness of the reward function, and is set to (log(T )/ √ T )1/ξ.\nIn Figure 3, we present the regret of the various algorithms (averaged over 10 independent runs). Observe that without the knowledge of the smoothness of the function, SP′ is able to significantly outperform the two other algorithms. As expected, KW does not perform well when ξ = 1/2, but outperforms KL-UCB(δ) for ξ = 2.\nFigure 4 presents a graphical illustration of a typical run of SP′ with reward function µ(x) = 1 − (2|1/2 − x|)ξ, ξ = 0.5 (left), and ξ = 2 (right), time horizon T = 106 and γ = 0.6. We represent the shape of µ and the successive intervals returned by IT′3, starting at the bottom of the y-axis. The thickness of the segments is an increasing function of the length of IT′3. In both cases, we observe that the successive intervals contain the optimal arm x?. When the search interval gets narrower (we are closer to the peak), the intervals get thicker since the duration of the test increases when the separation between arms {x1, x2, x3} decreases. Also remark that when the expected reward function is flatter (here ξ = 2), the algorithm tends to spend more time on each given interval. Additional numerical experiments are presented in Appendix."
    }, {
      "heading" : "7 Conclusion",
      "text" : "In this paper, we have presented the first order-optimal algorithms for one-dimensional continuous unimodal bandit problems that do not explicitly take into account the structure or the smoothness of the expected reward function. In some sense, the proposed algorithm learns and adapts its sequential decisions to the smoothness of the function. Future work will be devoted to applying the techniques used to\ndevise our algorithms to other structured bandits with continuum set of arms (i.e., Lipschitz or convex bandits). We also would like to extend our analysis to the case where the set of arms lies in a space of higher dimension."
    }, {
      "heading" : "A Additional numerical experiments",
      "text" : "Figure 5 compares the regret of the various algorithms for a triangular reward function µ(x) = 1 − (2|1/2 − x|), and illustrates a typical run of the SP′ algorithm for such a reward function with time horizon T = 106 and γ = 0.6."
    }, {
      "heading" : "B Proofs",
      "text" : ""
    }, {
      "heading" : "B.1 Proof of Theorem 4.1",
      "text" : "Proof of (i) (Minimax risk). Let µ ∈ U , and consider the test χ =ITK . By definition, its risk is:\nαχ(µ) = 2∑ u=1 1{µ ∈ Bu}Pµ[Sχ = u].\nIf µ /∈ B1 ∪ B2, then αχ(µ) = 0 so that the risk is indeed smaller than ζ. Now we assume that µ ∈ Bu and we derive an upper bound of Pµ[Sχ = u]. By definition of ITK , the event Sχ = u implies that there exists n ≤ s such that t̄χ(n)iu(µ̂(n)) ≥ f(s, ζ). Using the following two facts: (a) µ ∈ Bu and (b) tχk (n) ≥ t̄χ(n), we have\nf(s, ζ) ≤ t̄χ(n)is(µ̂(n)) = t̄χ(n) inf λ∈Bu K∑ k=1 KL (µ̂k(n), λ(xk))\n(a) ≤ t̄χ(n) K∑ k=1 KL (µ̂k(n), µ(xk)) (b) ≤ K∑ k=1 tχk (n)KL (µ̂k(n), µ(xk)).\nTherefore we have proven that:\nαχ(µ) ≤ Pµ [ sup n≤s K∑ k=1 tχk (n)KL (µ̂k(n), µ(xk)) ≥ f(s, ζ) ]\nApplying Theorem B.4 (presented at the end of the appendix) with δ := f(s, ζ), we obtain:\nαχ(µ) ≤ eK+1−f(s,ζ)(f(s, ζ)df(s, ζ) log(s)e/K)K ≤ ζ.\nThe above inequality holds for all µ ∈ U , and hence the minimax risk satisfies αχ ≤ ζ, which concludes the proof of (i).\nProof of (ii) (Expected length). We now consider 1 ≤ k ≤ K and we derive an upper bound of Eµ[tχk (s)]. Fix > 0, and define t0 = (1 + )f(s, ζ)/iu(µ(x1), . . . , µ(xK)). Introduce the following two sets of rounds:\nA = {1 ≤ n ≤ s : x(n) = xk, t χ (n) ≤ t0}, B = {1 ≤ n ≤ s : x(n) = xk, t χ (n) ≥ t0}.\nWe have tχk (s) ≤ |A|+ |B|. Furthermore, in each round n ∈ A, t χ k (n) is incremented, therefore |A| ≤ t0. Now let n ∈ B. By design of ITK , this implies that: t0 ≤ t̄χ(n) and t̄χ(n)iu(µ̂(n)) ≤ f(s, ζ). Therefore:\nt0iu(µ̂(n)) ≤ f(s, ζ),\nand thus: iu(µ̂(n)) ≤ iu(µ(x1), . . . , µ(xK))/(1 + ). (1)\nNow one can verify that the function (λ1, . . . , λK) 7→ ∑K k=1 KL (µ(xk), λk) attains its infimum on Bu. By continuity of KL in its second argument, there must exist λ? ∈ Bu such that:\niu(µ(x1), . . . , µ(xK)) = K∑ k=1 KL (µ(xk), λ?(xk)).\nLet η > 0 such that we have |µ̂k(n)− µ(xk)| ≤ η for all k. Since λ? ∈ Bu, this implies that:\niu(µ̂(n)) = inf λ∈Bu K∑ k=1 KL (µ̂k(n), λ(xk)) ≤ K∑ k=1 KL (µ̂k(n), λ?(xk)). (2)\nSince |µ̂k(n)− µ(xk)| ≤ η for all k, the r.h.s. of (2) tends to iu(µ(x1), . . . , µ(xK)) < iu(µ(x1), . . . , µ(xK))/(1 + ) as η → 0. Hence the inequality (1) cannot hold for arbitrary small η.\nHence, there exists η0 such that n ∈ B implies maxk |µ̂k(n) − µ(xk)| ≥ η0. Note that η0 might depend on and µ(x1), . . . , µ(xK). Using Lemma B.5, we get E[|B|] = o(log(s)).\nTherefore we have:\nE[tχk (s)] ≤ (1 + )f(s, ζ)\niu(µ(x1), . . . , µ(xK)) + o(log(s)).\nAs noted in remark 1, when considering ζ = s−γ , we may use f(s, ζ) = γ log(s) + o(log(s)), hence:\nlim sup s→∞ E[tχk (s)] log(s) ≤ (1 + )γ iu(µ(x1), . . . , µ(xK)) .\nSince the above inequality holds for all > 0, we obtain the announced result:\nlim sup s→∞ E[tχk (s)] log(s) ≤ γ iu(µ(x1), . . . , µ(xK)) .\nwhich concludes the proof of (ii)."
    }, {
      "heading" : "B.2 Proof of Theorem 4.2",
      "text" : "We start by proving Lemma B.1 which shows that iu can be lower bounded by the KL? function.\nLemma B.1 Consider Bernoulli rewards. Define m = 1 if u = 1 and m = 3 otherwise. Then we have for all u ∈ {1, 2}:\niu(µ(x1), µ(x2), µ(x3)) ≥ KL ?(µ(xm), µ(x2)).\nProof. We only prove the statement for u = 1, as the case u = 2 follows by symmetry. By a slight abuse of notation we denote µ(xk) and λ(xk) by µk and λk respectively.\nFirst note that if µ2 < µ1, we have KL?(µ1, µ2) = 0 and the statement holds because iu(µ(x1), µ(x2), µ(x3)) ≥ 0, since the KL divergence is positive.\nNow consider the case µ2 ≥ µ1. We have the inequality:\ni1(µ1, µ2, µ3) = inf λ∈B1 3∑ k=1 KL (µk, λk) ≥ inf λ∈B1 2∑ k=1 KL (µk, λk).\nDefine function φ : [0, 1]2 → R by φ(λ1, λ2) = ∑2 k=1 KL (µk, λk). Define the set Λ = {(λ1, λ2) : λ1 ≥ λ2}. Consider λ ∈ B1, then x 7→ λ(x) attains its maximum in [x, x1], and since λ is unimodal we must have λ1 ≥ λ2. Therefore:\ni1(µ1, µ2, µ3) ≥ min (λ1,λ2)∈Λ φ(λ1, λ2). (3)\nConsider (λ?1, λ ? 2) ∈ arg min(λ1,λ2)∈Λ φ(λ1, λ2). We are going to prove that we must have λ?1 = λ?2. Consider two subcases (a) 0 ≤ λ?2 ≤ µ1 and (b) µ1 ≤ λ?2 ≤ 1. In case (a) we must have λ?1 = µ1 since λ1 7→ KL (µ1, λ1) attains its minimum at µ1. In turn we must have λ?2 = µ1 = λ?1 since λ1 7→ KL (µ1, λ1) is decreasing for λ1 ≤ µ1 ≤ µ2. In case (b), we must have λ?1 = λ?2 because λ1 7→ KL (µ1, λ1) is increasing for λ1 ≥ λ?2 ≥ µ1. In both cases we have proven that λ?1 = λ?2.\nDefine function φ̃(λ) = φ(λ, λ), from the reasoning above we have that:\nmin (λ1,λ2)∈Λ φ(λ1, λ2) = min λ∈[0,1] φ̃(λ).\n• If µ1 = µ2 = 0, then φ(0, 0) = 0 so that the optimum is λ? = 0.\n• If µ1 = µ2 = 1, then φ(1, 1) = 0, so that the optimum is λ? = 1.\n• Otherwise, denote by φ̃′ the first derivative of φ̃. We have:\nφ̃′(λ) = 2− (µ1 + µ2) 1− λ − µ1 + µ2 λ .\nand φ̃′(0+) = −∞ and φ̃′(1−) = +∞ so that φ̃ attains its maximum in the interior of [0, 1]. Solving for φ̃′(λ?) = 0 we obtain the unique solution λ? = (µ1 + µ2)/2.\nWe observe that in the three above cases, the optimum is λ? = (µ1 + µ2)/2. We have proven the announced inequality:\ni1(µ(x1), . . . , µ(xK)) ≥ min (λ1,λ2)∈Λ φ(λ1, λ2) = min λ∈[0,1] φ̃(λ) = φ̃((µ1 + µ2)/2) = KL?(µ1, µ2).\nProof of Theorem 4.2. (i) Minimax risk of IT3. The minimax risk of IT3 is upper bounded by ζ by Theorem 4.1.\n(i)’ Minimax risk of χ =IT′3. Let µ ∈ Bu, let us upper bound Pµ[Sχ = u]. Without loss of generality consider u = 1 and a time instant n ≤ s such that Sχ(n) = 1. By definition of IT’3 this implies that t̄χ(n)KL?(µ̂1(n), µ̂2(n)) ≥ f(s, ζ). We deduce that:\nf(s, ζ) ≤ t̄χ(n)KL?(µ̂1(n), µ̂2(n)) (a)\n≤ t̄χ(n)i1(µ̂1(n), . . . , µ̂K(n))\n= t̄χ(n) inf λ∈B1 K∑ k=1 KL (µ̂k(n), λ(xk))\n(b) ≤ t̄χ(n) K∑ k=1 KL (µ̂k(n), µ(xk))\n(c) ≤ K∑ k=1 tχk (n)KL (µ̂k(n), µ(xk)).\nwhere we have used (a) Lemma B.1, (b) the fact that µ ∈ B1 (c) the fact that t̄χ(n) ≤ tχk (n) for all k. Applying theorem B.4 once again:\nαχ(µ) ≤ P [ sup n≤s K∑ k=1 tχk (n)KL (µ̂k(n), µ(xk)) ≥ f(s, ζ) ] ≤ ζ\nwhich proves that αχ(µ) ≤ ζ for all µ ∈ U and concludes the proof of (i)’. (ii) Expected duration of χ =IT3. The proof of (ii) for IT′3 follows by the same arguments. By a slight abuse of notation we denote µ(xk) by µk. Without loss of generality, consider µ such that x? ∈ [x2, x]. Therefore we have that µ2 > µ1 since µ is unimodal. Fix 0 < < δ/2, and define t0 = f(s, ζ)/KL?, (µ1, µ2). Introduce the two sets of instants:\nA = {1 ≤ n ≤ s : x(n) = xk, t̄χ(n) ≤ t0} , B = {n ≥ 1 : x(n) = xk, max k′∈{1,2} |µ̂k′(n)− µk′ | ≥ }.\nWe prove that x(n) = xk implies that n ∈ A∪B. Consider n such that t̄χ(n) ≥ t0 and |µ̂k′(n)−µk′ | ≤ , k′ ∈ {1, 2}. Since < δ/2 ≤ (µ2 − µ1)/4 we have:\nµ̂1(n) ≤ µ1 + ≤ (µ1 + µ2)/2− ≤ (µ̂1(n) + µ̂2(n))/2 µ̂2(n) ≥ µ2 − ≥ (µ1 + µ2)/2 + ≥ (µ̂1(n) + µ̂2(n))/2\nso that KL ?(µ̂1(n), µ̂2(n)) ≥ KL ?, (µ1, µ2). Applying Lemma B.1, we have:\nt̄(n)i1(µ̂(n)) ≥ t̄χ(n)KL ?(µ̂1(n), µ̂2(n)) ≥ t0KL ?, (µ1, µ2) = f(s).\nTherefore we cannot have x(n) = xk. We have proven that tχk (s) ≤ |A| + |B|. Furthermore, at each instant n ∈ A, t̄χ(n) is incremented, therefore |A| ≤ t0. Let us upper bound the expected size of B. Decompose B = B1 ∪B2, with:\nBk ′ = {n ≥ 1 : x(n) = xk, |µ̂k′(n)− µk′ | ≥ }.\nLet n ∈ Bk′ and define a = ∑ n′≤n 1{n′ ∈ Bk\n′} so that n is the a-th instant of Bk′ . Then we have that tχk′(n) ≥ a and applying [8][Lemma 2.2] we have that for k′ ∈ {1, 2}, E[|Bk\n′ |] ≤ −2. Therefore E[|B|] ≤ 2 −2. So statement (ii) is proven:\nEµ[tχk (s)] ≤ t0 + 2 −2 =\nf(s)\nKL?, (µ(x1), µ(x2)) + 2 −2.\n(iii) Further bounds on the duration of χ =IT3. The proof of (iii) for IT′3 follows by the same arguments. To establish the announced inequalities, we will use the following fact: from Pinsker’s inequality KL (α, β) ≥ 2(α− β)2 for all (α, β) ∈ [0, 1]2, so that:\nKL ?, (µ1, µ2) ≥ 4((µ2 − µ1)/2− 2 )2 ≥ 4(δ − 2 )2,\nIn particular for = δ/4 we have KL ?, (µ1, µ2) ≥ δ2. Inequality (a). Define t0 = 8f(s)δ−2 and n0 = 3t0. By design of IT3, for all k we have t χ k (n0) = t0. Set\n= δ/4. If both µ̂1(n0) ≤ µ1 + and µ̂2(n0) ≥ µ2 − then we have:\nt̄χ(n0)KL ?(µ̂1(n0), µ̂2(n0)) ≥ t0KL ?, (µ1, µ2) ≥ 8f(s)δ−2δ2 = 8f(s) > f(s).\nso that IT3 must terminate at time n0 or before. Hence, applying Hoeffding’s inequality:\nPµ[tχk (s) ≥ t0] ≤ P[µ̂k(n0) ≥ µ1 + ] + P[µ̂2(n0) ≤ µ2 − ] ≤ 2e −2t0 2 = 2e−f(s).\nwhich is the announced result. Inequality (b). Once again setting = δ/4, and using both KL ?, (µ2, µ1) ≥ δ2 and statement (ii), we obtain the second claim:\nEµ[tχk (s)] ≤ f(s) + 32\nδ2\nInequality (c). By statement (ii), and using the fact that f(s) = γ log(s) + o(log(s)), for all > 0, we have:\nlim sup s→∞ Eµ[tχk (s)] log(s) ≤ γ KL?, (µ(x1), µ(x2)) ,\nso that letting → 0 in the above expression yields:\nlim sup s→∞ Eµ[tχk (s)] log(s) ≤ γ KL?(µ(x1), µ(x2)) ,\nwhich concludes the proof of statement (iii)."
    }, {
      "heading" : "B.3 Proof of Theorem 4.3",
      "text" : "Fix N throughout the proof. We introduce the following notations. The algorithm proceeds in phases, each phase corresponding to a call of IT3 (or IT′3) subroutine. We define I\nN ′ the interval output after the N ′-th call of IT3, with I0 = [0, 1]. We define τN ′ the duration of the N ′-th call of IT3. Define the event:\nA = ∩NN ′=0{x? ∈ IN ′ },\nwhich corresponds to sample paths where the first N -th calls of IT3 have returned an interval containing the optimal arm x?. We denote by Ac the complement of A.\nThe regret due to sample paths in Ac is upper bounded by µ?TP[Ac]. The regret due to the N ′-th phase for sample paths inA is upper bounded by E[τN ′1{A}(µ?−minx∈IN′ µ(x))]. This is true because the N ′-th phase has duration τN ′ , and during that phase only arms in IN ′ are sampled so that the regret of a sample in IN ′\nis upper bounded by µ? −minx∈IN′ µ(x). Therefore the regret admits the following upper bound:\nRπ(T ) ≤ µ?TP[Ac] + ∑ N ′≥0 E[τN ′ 1{A}(µ? − min x∈IN′ µ(x))].\nConsider a sample path in A, and N ′ ≤ N , then we have |IN ′ | ≤ ψN ′ and x? ∈ IN ′ . Therefore µ?−minx∈IN′ µ(x) ≤ gµ(ψN ′ ) by definition of gµ. Similarly, consider a sample path inA, andN ′ > N . Then we have IN ′ ⊂ IN , |IN | ≤ ψN and x? ∈ IN . Therefore:\nµ? − min x∈IN′ µ(x) ≤ µ? − min x∈IN µ(x) ≤ gµ(ψN ),\nand the regret satisfies:\nRπ(T ) ≤ µ?TP[Ac] + N∑\nN ′=0\ngµ(ψ N ′)E[τN ′ 1{A}] + gµ(ψN ) ∑ N ′>N E[τN ′ 1{A}]\n≤ µ?TP[Ac] + N∑\nN ′=0\ngµ(ψ N ′)E[τN ′ 1{A}] + gµ(ψN )E[ ∑ N ′>N τN ′ ],\n≤ µ?TP[Ac] + N∑\nN ′=0\ngµ(ψ N ′)E[τN ′ 1{A}] + Tgµ(ψN ),\nwhere we have used the fact that ∑ N ′>N τ N ′ ≤ ∑ N ′≥0 τ\nN ′ = T . We now upper bound the probability of event Ac. Since x? ∈ I0 = [0, 1], the occurrence of Ac\nimplies that there exists N ′ < N such that x? ∈ IN ′ and x? 6∈ IN ′+1 so that we have the inclusion:\nAc ⊂ ∪N−1N ′=0{x ? ∈ IN ′ , x? /∈ IN ′+1}.\nSince the event {x? ∈ IN ′ , x? /∈ IN ′+1} corresponds to an incorrect decision taken under IT3, we have P[x? ∈ IN ′ , x? /∈ IN ′+1] ≤ T−γ , because of Theorem 4.2. Using a union bound we obtain the upper bound:\nP[Ac] ≤ N−1∑ N ′=0 P[x? ∈ IN ′ , x? /∈ IN ′+1] ≤ NT−γ .\nThe regret upper bound becomes:\nRπ(T ) ≤ µ?NT 1−γ + Tgµ(ψN ) + N∑\nN ′=0\ngµ(ψ N ′)E[τN ′ 1{A}].\nFinally, from Theorem 4.2, we have that E[τN ′1{A}] ≤ 3(f(T ) + 32)(δ(IN ′))−2 (we sample from 3 arms) where δ(IN ′ ) is the quantity δ defined in the statement of Theorem 3, when the interval considered by IT3 is IN ′ . Since we are considering a sample path in A, and N ′ ≤ N we have once again that |IN ′ | ≤ ψN ′ and x? ∈ IN ′ so that δ(IN ′) ≥ hµ(ψN ′ ) by definition of hµ. Therefore: E[τN ′ 1{A}] ≤ 3(f(T ) + 32)(hµ(ψ N ′))−2. We obtain finally:\nRπ(T ) ≤ µ?NT 1−γ + Tgµ(ψN ) + 3(f(T ) + 32) N∑\nN ′=0\ngµ(ψ N ′)(hµ(ψ N ′))−2,\nwhich is the announced result and concludes the proof."
    }, {
      "heading" : "B.4 Proof of Theorem 4.5",
      "text" : "To prove Theorem 4.5, we use the following intermediate result.\nProposition 1 For all µ ∈ U(C1, C2): (a) gµ(∆) ≤ C2∆ξ; (b) hµ(∆) ≥ C1aξ∆ξ, with aξ = 4−ξ min(1, 2ξ − 1)\nProof. (a) By definition of gµ and since µ ∈ U(C1, C2), we have:\ngµ(∆) = µ ? −min(µ(x? −∆), µ(x? + ∆)) ≤ C2∆ξ.\n(b) Consider x such that x? ≤ x ≤ x? + ∆/4. Since since µ ∈ U(C1, C2), we have:\nµ(x)− µ(x+ ∆/4) ≥ C1((x+ ∆/4− x?)ξ − (x− x?)ξ).\nFix ∆, and define the function l(x) = (x+ ∆/4− x?)ξ − (x− x?)ξ. Its first derivative is:\nl′(x) = ξ((x+ ∆/4− x?)ξ−1 − (x− x?)ξ−1).\nTherefore the function x 7→ l(x) on interval [x?, x?+ ∆/4] is increasing if ξ ≥ 1 and decreasing if ξ < 1 so we get the lower bound:\nmin x∈[x?,x?+∆/4]\nµ(x)− µ(x+ ∆/4) ≥\n{ C1l(x ?) = C1(∆/4) ξ if ξ ≥ 1\nC1l(x ? + ∆/4) = C1(2 ξ − 1)(∆/4)ξ if ξ < 1\nso that hµ(∆) ≥ C1 min(1, 2ξ − 1)(∆/4)ξ as announced. Let us now prove Theorem 4.5. From Theorem 4.3, we can decompose the regret upper bound into three terms:\nRπ(T ) ≤ r1(T ) + r2(T ) + r3(T ) r1(T ) = µ ?NT 1−γ\nr2(T ) = Tgµ(ψ N )\nr3(T ) = 3(γ log(T ) + 32) N∑ N ′=0 gµ(ψ N ′)(hµ(ψ N ′))−2.\nWe proceed to upper bound each term. The first term r1(T ) is explicit. By Proposition 1, the second term is upper bounded as: r2(T ) ≤ TC2ψξN . As for the third term r3(T ), by Proposition 1, we have that gµ(ψ N ′) ≤ C2ψξN ′ and hµ(ψN ′ ) ≥ C1aξψξN ′ , so that:\nN∑ N ′=0 gµ(ψ N ′)(hµ(ψ N ′))−2 ≤ N∑ N ′=0 C2(C1aξ) −2ψ−ξN ′ ≤ C2ψ −ξ(N+1) C21a 2 ξ(ψ −ξ − 1) .\nFinally, we get:\nRπ(T ) ≤ µ?NT 1−γ + TC2ψξN + 3(f(T ) + 32)C2ψ\n−ξ(N+1)\nC21a 2 ξ(ψ −ξ − 1)\nDefine M ≥ 0 (not necessarily an integer) such that the last two terms in the r.h.s. of the above inequality are equal:\nC2Tψ ξM =\n3(f(T ) + 32)C2ψ −ξ(M+1)\nC21a 2 ξ(ψ −ξ − 1)\n.\nWe have that:\nψ−2ξM = TC21a 2 ξ(ψ −ξ − 1)\n3(f(T ) + 32)ψ−ξ ≤ TC21\nsince aξ ≤ 1, ψ−ξ − 1 ≤ ψ−ξ and f(T ) ≥ 1. Taking logarithms we deduce that:\nM ≤ log(TC1) ξ log(1/ψ) .\nNow set N ≡ dMe for the remainder of the proof. We obtain the announced upper bound:\nRπ(T ) ≤ µ?(M + 1)T 1−γ + TC2ψξM + ψ−ξ 3(f(T ) + 32)C2ψ\n−ξ(M+1)\nC21a 2 ξ(ψ −ξ − 1) ≤ µ?T 1−γ ( log(TC1)\nξ log(1/ψ) + 1\n) + (1 + ψ−ξ)TC2ψ ξM\n≤ µ?T 1−γ log(TC1ψ −ξ)\nξ log(1/ψ) + 2ψ−3ξ/2C2 C1aξ\n√ 3T (f(T ) + 32)\nψ−ξ − 1 .\nThis concludes the proof."
    }, {
      "heading" : "B.5 Proof of Theorem 4.6",
      "text" : "The proof proceeds along the same lines as the proof of Theorem 4.5. Define M ≥ 0 such that:\n24f(T )ψ−2ξ(M+1)\na2ξC 2 1 (ψ\n−2ξ − 1) = T.\nLet us first upper bound M . We have that:\nψ−2ξ(M+1) = C21a 2 ξT (ψ −2ξ − 1) 24f(T ) ≤ C21Tψ−2ξ.\nusing the fact that aξ ≤ 1, f(T ) ≥ 1 and ψ−2ξ − 1 ≤ ψ−2ξ. Hence, taking logarithms:\nM ≤M + 1 ≤ log(TC1ψ −ξ)\nξ log(1/ψ) .\nWe now fix N = bMc for the remainder of the proof. Once again the algorithm proceeds in phases, each phase corresponding to a call to IT3 (or IT′3). We define I\nN ′ the interval output by the N ′-th call of IT3, with I0 = [0, 1]. We define τN ′ the duration of the N ′-th call of IT3. We define two events:\nA = ∩NN ′=0{x? ∈ IN ′ }, B = ∩NN ′=0{τN ′ ≤ 24f(T )hµ(ψN ′ )−2}\nA corresponds to sample paths where the first N -th calls of IT3 have returned an interval containing the optimal arm x?. B corresponds to sample paths where the firstN -th calls to IT3 have not lasted more than their “typical length” (as prescribed by Theorem 4.2). The optimization error can hence be decomposed according to the occurrence of A and B:\nEπ(T ) = E[(µ? − µ(x(T ))1{A ∩B}] + E[(µ? − µ(x(T ))1{(A ∩B)c}] ≤ E[(µ? − µ(x(T ))1{A ∩B}] + µ?E[1{(A ∩B)c}] ≤ E[(µ? − µ(x(T ))1{A ∩B}] + µ?(P[Ac] + P[Bc ∩A]).\nWe will establish two facts:\n(a) P[Ac] + P[Bc ∩A] ≤ 3MT−γ\n(b) (µ? − µ(x(T ))1{A ∩B} ≤ C2ψξ(M+1) a.s.\nIf (a) and (b) hold we have that:\nEπ(T ) ≤ C2ψξ(M+1) + 3µ?MT−γ ≤ C2 C1aξ\n√ 24f(T )\nT (ψ−2ξ − 1) +\n3T−γµ? log(TC1ψ −ξ)\nξ log(1/ψ) .\nwhich is precisely the announced result. Fact (a) From Theorem 4.2, statement (i), we know that P[Ac] ≤ NT−γ since the risk of IT3 is upper bounded by T−γ . Furthermore, from Theorem 4.2, statement (iii a), we know that P[Bc ∩ A] ≤ 2NT−γ since test IT3 applied to an interval of size ψN ′ that contains the optimal arm has length greater than 24f(T )hµ(ψN ′ )−2 with probability less than 2e−f(T ) ≤ 2T−γ . Hence P[Ac] + P[Bc ∩ A] ≤ 3NT−γ ≤ 3MT−γ as announced. Fact (b) Let us prove that if B occurs, then the first N -th calls to IT3 terminate before the time horizon T . Indeed, if B occurs, applying Proposition 1, one has:\nN∑ N ′=0 τN ′ ≤ 24f(T ) N∑ N ′=0 hµ(ψ N ′)−2 ≤ 24f(T ) a2ξC 2 1 N∑ N ′=0 ψ−2ξN ′\n≤ 24f(T )ψ −2ξ(N+1)\na2ξC 2 1 (ψ\n−2ξ − 1) ≤ 24f(T )ψ\n−2ξ(M+1)\na2ξC 2 1 (ψ\n−2ξ − 1) = T\nso that the first N tests do terminate before T . Furthermore, if A occurs, the N -th test returns an arm x such that |x− x?| ≤ ψM+1. In turn, by proposition 1, one has |µ? − µ(x)| ≤ gµ(ψM+1) ≤ C2ψξ(M+1). Hence we have proven that, if both A and B occur one has (µ? − µ(x(T )) ≤ C2ψξ(M+1), so that (µ? − µ(x(T ))1{A ∩B} ≤ C2ψξ(M+1) a.s. as announced. This concludes the proof."
    }, {
      "heading" : "B.6 Proof of Theorem 5.1",
      "text" : "We work with a given sequential test χ throughout the proof and we omit the superscript χ for clarity. Without loss of generality, let u = 1. We work with a fixed parameter λ ∈ B1. We denote by Y (s) = (X1(x(1)), . . . , Xs(x(s))) the observed rewards from round 1 to round s. We denote by Ps and Qs the probability distribution of Y (s) under µ and λ respectively. From Lemma B.3 (stated and proved at the end of the appendix), we have:\nKL (Ps||Qs) = K∑ k=1 E[tk(s)]KL (µ(xk), λ(xk)). (4)\nConsider the event S = 1. Since the sequential test χ has minimax risk smaller than α, and λ ∈ B1, we have Pλ[S = 1] ≤ α. Recall that by assumption Pµ[S = 1] = β and α ≤ β. Now S is a function of Y (s). Using Lemma B.2 (stated at the end of the appendix):\nKL (Ps||Qs) ≥ KL2(Pµ[S(s) = 1],Pλ[S(s) = 1]) ≥ KL2(β, α). (5)\nwhere we have used the fact that α 7→ KL2(β, α) is decreasing for α ≤ β. Putting (4) and (5) together, we obtain:\nK∑ k=1 E[tk(s)]KL (µ(xk), λ(xk)) ≥ KL2(β, α).\nTaking the infimum over λ ∈ B1, we obtain the claimed result:\ninf λ∈B1 K∑ k=1 E[tk(s)]KL (µ(xk), λ(xk)) ≥ KL2(β, α)."
    }, {
      "heading" : "B.7 Proof of Corollary 5.2",
      "text" : "Let us denote βs = Pµ[Ss = 1], where Ss is the final decision taken under test χs. Since βs →s→∞ β > 0 there exists s0 such that for all s ≥ s0 we have βs ≥ s−γ . Since χs has minimax risk α = s−γ , for all s ≥ s0, applying Theorem 5.1, we obtain:\ninf λ∈B1 K∑ k=1 E[tk(s)]KL (µ(xk), λ(xk)) ≥ KL2(βs, α) = KL2(βs, s−γ). (6)\nNow by definition of KL2, we have that:\nKL2(βs, s−γ) = βs log(βs) + βsγ log(s) + (1− βs) log(1− βs) + (1− βs) log(1− s−γ).\nSince βs →s→∞ β > 0, we have that KL2(βs, s−γ) ∼s→∞ γβ log(s). Letting s→∞ in (6) we have:\nlim inf s→∞ inf λ∈B1 K∑ k=1 Eµ[tk(s)] log(s) KL (µ(xk), λ(xk)) ≥ γβ,\nwhich concludes the proof."
    }, {
      "heading" : "B.8 Proof of Corollary 5.3",
      "text" : "The proof is constructive: we exhibit a function µ such that Pµ[Sχ 6= 0] ≥ 1/2. Without loss of generality we consider interval I = [0, 1]. Consider the function µ(x) = 1−2|1/2−x|. µ is clearly unimodal, with x? = 1/2 and µ? = 1.\nWe proceed by contradiction. Consider a test χ such that Pµ[Sχ 6= 0] ≥ 1/2. Since Sχ ∈ {0, 1, 2}, there exists u ∈ {1, 2} such that Pµ[Sχ = u] ≥ 1/4. Without loss of generality consider u = 1. Let > 0, and define the function λ which is linear on intervals {[x1, x2], [x2, x3], [x2, (x3 + x4)/2], [(x3 + x4)/2, x4] with λ(xk) = µ(xk), k 6= 3 and λ(x3) = µ(x2) + , and λ((x3 + x4)/2) = 1. One can check that λ is unimodal, and attains its maximum in [x3, x4]. We recall that α < 1/4 and applying Theorem 5.1, we obtain the following inequality:\nK∑ k=1 Eµ[tk(s)]KL (µ(xk), λ(xk)) ≥ KL2(1/4, α).\nSince KL (µ(xk), λ(xk)) = KL (µ(xk), µ(xk)) = 0, for k 6= 3, and t3(s) ≤ s we obtain:\nsKL (µ(x3), µ(x3) + ) ≥ KL2(1/4, α). (7)\nSince α < 1/4 we have that KL2(1/4, α) > 0. On the other hand 7→ KL (µ(x3), µ(x3) + ) is continuous, and KL (µ(x3), µ(x3)) = 0. Therefore inequality (7) cannot hold for all > 0. This is a contradiction and proves that a test χ as considered here cannot exist, which concludes the proof."
    }, {
      "heading" : "B.9 Technical results",
      "text" : "Lemma B.2 gives a lower bound of the KL divergence of probability measures using the KL divergence between two Bernoulli distributions.\nLemma B.2 Let P and Q be two probability measures on a probability space (Ω,F ,P). Assume that P and Q are both absolutely continuous with respect to measure m(dx). Then:\nKL (P ||Q) ≥ sup A∈F KL2(P (A), Q(A)).\nProof. The proof is based on the log-sum inequality. We recall the derivation of the log-sum inequality here. Consider f(x) = x log(x). We have that f ′′(x) = 1/x, so that f is convex. We define p, q the densities of P,Q with respect to measure m. Then for all A ∈ F :∫\nA\nlog\n( p(x)\nq(x)\n) p(x)m(dx) = ∫ A f ( p(x) q(x) ) q(x)m(dx)\n= Q(A) ∫ A f ( p(x) q(x) ) q(x) Q(A) m(dx)\n(a) ≥ Q(A)f (∫\nA\np(x)\nq(x)\nq(x)\nQ(A) m(dx) ) = Q(A)f ( P (A)\nQ(A)\n) = P (A) log ( P (A)\nQ(A)\n) .\nand (a) holds because of Jensen’s inequality. Applying the reasoning above to A and Ac = Ω \\A:\nKL (P ||Q) = ∫\nΩ\nlog\n( p(x)\nq(x)\n) p(x)m(dx)\n= ∫ A log ( p(x) q(x) ) p(x)m(dx) + ∫ Ac log ( p(x) q(x) ) p(x)m(dx)\n≥ P (A) log ( P (A)\nQ(A)\n) + P (Ac) log ( P (Ac)\nQ(Ac) ) = P (A) log ( P (A)\nQ(A)\n) + (1− P (A)) log ( 1− P (A) 1−Q(A) ) = KL2(P (A), Q(A)).\nSo for all A we have: KL (P ||Q) ≥ KL2(P (A), Q(A)),\nand taking the supremum over A ∈ F concludes the proof. Lemma B.3 evaluates the KL divergence between sample paths of a given test under two different parameters. The proof follows from a straightforward conditioning argument and is omitted here.\nLemma B.3 We denote by Y (s) = (X1(x(1)), . . . , Xs(x(s))) the observed rewards from time 1 to s. Consider µ, λ ∈ U , and denote by Ps and Qs the probability distribution of Y (s) under µ and λ respectively. Then we have:\nKL (Ps||Qs) = K∑ k=1 E[tk(s)]KL (µ(xk), λ(xk)).\nTheorem B.4 is a concentration inequality for sums of KL divergences. It was derived derived in [20], and is stated here for completeness.\nTheorem B.4 [20] For all δ ≥ (K + 1) and s ≥ 1 we have:\nP [ sup n≤s K∑ k=1 tk(n)KL (µ̂k(n), µ(xk)) ≥ δ ] ≤ eK+1−δ ( dδ log(s)eδ K )K . (8)\nLemma B.5 is a technical result showing that the expected number of times the empirical mean of i.i.d. variables deviates by more than δ from its expectation is o(log(n)), n being the time horizon.\nLemma B.5 Let {Xn}n≥1 be a family of i.i.d. random variables with common expectation µ and finite second moment. Define µ̂(n) = (1/n) ∑n n′=1Xn′ . For δ > 0 define\nDδ(s) = ∑s n=1 1{|µ̂(n)− µ| ≥ δ}. Then we have that for all δ:\nE[Dδ(s)] log(s) →s→∞ 0.\nProof. We define v2 = E[(X1 − µ)2] the variance. Using the fact that {Xn}n≥1 are independent, we have that E[(µ̂(n)− µ)2] = v2/n. Applying Chebychev’s inequality we have that:\nP[|µ̂(n)− µ| ≥ δ] ≤ E[(µ̂(n)− µ) 2]\nδ2 =\nv2\nnδ2 .\nTherefore, we recognize the harmonic series:\nE[Dδ(s)] = s∑\nn=1\nP[|µ̂(n)− µ| ≥ δ] ≤ v 2\nδ2 s∑ n=1 1 n ≤ v 2(log(s) + 1) δ2 ,\nso that sups E[Dδ(s)]/ log(s) <∞. Applying the law of large numbers, we have that µ̂(n)→n→∞ µ a.s., so that |µ̂(n)− µ| occurs only finitely many times a.s. Hence supsD δ(s) <∞ a.s and Dδ(s)/ log(s)→ 0 a.s.\nWe have proven that sups E[Dδ(s)]/ log(s) <∞ andDδ(s)/ log(s)→ 0 a.s. so applying Lebesgue’s dominated convergence theorem we get the announced result:\nE[Dδ(s)] log(s) →s→∞ 0,\nwhich concludes the proof."
    } ],
    "references" : [ ],
    "referenceMentions" : [ ],
    "year" : 2015,
    "abstractText" : "<lb>We consider stochastic bandit problems with a continuous set of arms and where the expected re-<lb>ward is a continuous and unimodal function of the arm. No further assumption is made regarding<lb>the smoothness and the structure of the expected reward function. For these problems, we propose<lb>the Stochastic Pentachotomy (SP) algorithm, and derive finite-time upper bounds on its regret and<lb>optimization error. In particular, we show that, for any expected reward function μ that behaves as<lb>μ(x) = μ(x)− C|x− x| locally around its maximizer x for some ξ, C > 0, the SP algorithm is<lb>order-optimal. Namely its regret and optimization error scale as O(<lb>√<lb>T log(T )) and O(<lb>√<lb>log(T )/T ),<lb>respectively, when the time horizon T grows large. These scalings are achieved without the knowledge<lb>of ξ and C. Our algorithm is based on asymptotically optimal sequential statistical tests used to suc-<lb>cessively trim an interval that contains the best arm with high probability. To our knowledge, the SP<lb>algorithm constitutes the first sequential arm selection rule that achieves a regret and optimization error<lb>scaling as O(<lb>√<lb>T ) and O(1/<lb>√<lb>T ), respectively, up to a logarithmic factor for non-smooth expected<lb>reward functions, as well as for smooth functions with unknown smoothness.",
    "creator" : "LaTeX with hyperref package"
  }
}