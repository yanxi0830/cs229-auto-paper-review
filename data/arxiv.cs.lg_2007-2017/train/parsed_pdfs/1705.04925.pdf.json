{
  "name" : "1705.04925.pdf",
  "metadata" : {
    "source" : "META",
    "title" : "Convergence Analysis of Proximal Gradient with Momentum for Nonconvex Optimization",
    "authors" : [ "Qunwei Li", "Yi Zhou", "Yingbin Liang", "Pramod K. Varshney" ],
    "emails" : [ "<qli33@syr.edu>." ],
    "sections" : [ {
      "heading" : "1. Introduction",
      "text" : "Many problems in machine learning, data mining, and signal processing can be formulated as the following\n1Syracuse University, NY, USA. Correspondence to: Qunwei Li <qli33@syr.edu>.\nProceedings of the 34 th International Conference on Machine Learning, Sydney, Australia, 2017. JMLR: W&CP. Copyright 2017 by the author(s).\nAlgorithm 1 APG\nInput: y1 = x1 = x0, t1 = 1, t0 = 0, η < 1 L . for k = 1, 2, · · · do yk = xk +\ntk−1−1 tk\n(xk − xk−1). xk+1 = proxηg(yk − η∇f(yk)).\ntk+1 =\n√ 4t2k+1+1\n2 . end for\ncomposite minimization problem\nmin x∈Rd F (x) = f(x) + g(x). (P)\nTypically, f : Rd → R captures the loss of data fitting and can be written as f = 1n ∑n l=1 fl with each fl corresponding to the loss of one sample. The second term g : Rd → R is the regularizer that promotes desired structures on the solution based on prior knowledge of the problem.\nIn practice, many problems of (P) are formulated, either naturally or intensionally, into a convex model to guarantee the tractability of algorithms. In particular, such convex problems can be efficiently minimized by many first-order algorithms, among which the accelerated proximal gradient (APG) method (also referred to as FISTA (Beck & Teboulle, 2009b)) is proven to be the best for minimizing such class of convex functions. We present one of its basic forms in Algorithm 1. Compared to the usual proximal gradient step, the APG algorithm takes an extra linear extrapolation step for acceleration. It has been shown (Beck & Teboulle, 2009b) that the APG method reduces the function value gap at a rate of O(1/k2) where k denotes the number of iterations. This convergence rate meets the theoretical lower bound of first-order gradient methods for minimizing smooth convex functions. The reader can refer to (Tseng, 2010) for other variants of APG.\nAlthough convex problems are tractable and can be globally minimized, many applications naturally require to solve nonconvex optimization problems of (P). Recently, several variants of the APG method have been proposed for nonconvex problems, and two\nar X\niv :1\n70 5.\n04 92\n5v 1\n[ cs\n.L G\n] 1\n4 M\nay 2\n01 7\nAlgorithm 2 Monotone APG (mAPG)\nInput: y1 = x1 = x0, t1 = 1, t0 = 0, η < 1 L . for k = 1, 2, · · · do yk = xk +\ntk−1 tk (zk − xk) + tk−1−1tk (xk − xk−1). zk+1 = proxηg(yk − η∇f(yk)). vk+1 = proxηg(xk − η∇f(xk)).\ntk+1 =\n√ 4t2k+1+1\n2 . if F (zk+1) ≤ F (vk+1) then\nxk+1 = zk+1, else if F (vk+1) ≤ F (zk+1) then\nxk+1 = vk+1. end if\nend for\nAlgorithm 3 APG non-convex problem (APGnc)\nInput: y1 = x0, βk = k k+3 , η < 1 L . for k = 1, 2, · · · do xk = proxηg(yk − η∇f(yk)). vk = xk + βk(xk − xk−1). if F (xk) ≤ F (vk) then\nyk+1 = xk, else if F (vk) ≤ F (xk) then\nyk+1 = vk. end if\nend for\nmajor ones are presented in Algorithm 2 and Algorithm 3, respectively. The major difference to the original APG is that the modified methods only accept the new iterate when the corresponding function value is sufficiently decreased, which leads to a more stable convergence behavior. In particular, (Li & Lin, 2015) analyzed mAPG (Algorithm 2) by exploiting the Kurdyka- Lojasiewicz (K L) property, which is a local geometrical structure very generally held by a large class of nonconvex objective functions, and has been successfully exploited to characterize the asymptotic convergence behavior of many first order methods. It was shown in (Li & Lin, 2015) that mAPG achieves the O(1/k2) convergence rate for convex problems of (P), and converges to a critical point at sublinear and linear rates under different cases of the KL property for nonconvex problems. Despite the desirable convergence rate, mAPG requires two proximal steps, which doubles the computational complexity of the original APG. In comparison, the APGnc (Algorithm 3) requires only one proximal step, and hence computes faster than mAPG in each iteration. However, the analysis of APGnc in (Yao & Kwok, 2016) does not exploit the KL property and no convergence rate of the function value is established. Hence, there is still\nno formal theoretical comparison of the overall performance (which depends on both computation per iteration and convergence rate) between mAPG and APGnc. It is unclear whether the computational saving per iteration in APGnc is at the cost of lower convergence rate.\nThe goal of this paper is to provide a comprehensive analysis of the APGnc algorithm under the KL framework, thus establishing a rigorous comparison between mAPG and APGnc and formally justifying the overall advantage of APGnc."
    }, {
      "heading" : "1.1. Main Contributions",
      "text" : "This paper provides the convergence analysis of APGnc type algorithms for nonconvex problems of (P) under the KL framework as well as the inexact situation. We also study the stochastic variance reduced APGnc algorithm and its inexact situation. Our analysis requires novel technical treatments to exploit the K L property due to the joint appearance of the following ingredients in the algorithms including momentum terms, inexact errors, and stochastic variance reduced gradients. Our contributions are summarized as follows.\nFor APGnc applied to nonconvex problems of (P), we show that the limit points of the sequences generated by APGnc are critical points of the objective function. Then, by exploiting different cases of the KurdykaLojasiewicz property of the objective function, we establish the linear and sub-linear convergence rates of the function value sequence generated by APGnc. Our results formally show that APGnc (with one proximal map per iteration) achieves the same convergence properties as well as the convergence rates as mAPG (with two proximal maps per iteration) for nonconvex problems, thus establishing its overall computational advantage.\nWe further propose an APGnc+ algorithm, which is an improved version of APGnc by adapting the momentum stepsize (see Algorithm 4), and shares the same theoretical convergence rate as APGnc but numerically performs better than APGnc.\nFurthermore, we study the inexact APGnc in which the computation of the gradient and the proximal mapping may have errors. We show that the algorithm still achieves the convergence rate at the same order as the exact case as long as the inexactness is properly controlled. We also explicitly characterize the impact of errors on the constant factors that affect the convergence rate.\nTo facilitate the solution to large-scale optimization\nproblems, we study the stochastic variance reduced APGnc (SVRG-APGnc), and show that such an algorithm achieves linear convergence rate under a certain case of the K L property. We further analyze the inexact SVRG-APGnc and show that it also achieves the linear convergence under the same K L property as long as the error in the proximal mapping is bounded properly. This is the first analysis of the SVRG proximal algorithm with momentum that exploits the K L structure to establish linear convergence rate for nonconvex programming.\nOur numerical results further corroborate the theoretic analysis. We demonstrate that APGnc/APGnc+ outperforms APG and mAPG for nonconvex problems in both exact and inexact cases, and in both deterministic and stochastic variants of the algorithms. Furthermore, APGnc+ outperforms APGnc due to properly chosen momentum stepsize."
    }, {
      "heading" : "1.2. Comparison to Related Work",
      "text" : "APG algorithms: The original accelerated gradient method for minimizing a single smooth convex function dates back to (Nesterov, 1983), and is further extended as APG in the composite minimization framework in (Beck & Teboulle, 2009b; Tseng, 2010). While these APG variants generate a sequence of function values that may oscillate, (Beck & Teboulle, 2009a) proposed another variant of APG that generates a non-increasing sequence of function values. Then, (Li & Lin, 2015) further proposed an mAPG that generates a sufficiently decreasing sequence of function values, and established the asymptotic convergence rates under the K L property. Recently, (Yao & Kwok, 2016) proposed APGnc, which is a more efficient version of APG for nonconvex problems, but the analysis only characterizes fixed points and did not exploit the K L property to characterize the convegence rate. Our study establishes the convergence rate analysis of APGnc under the K L property.\nNonconvex optimization under K L: The K L property (Bolte et al., 2007) is an extension of the Lojasiewicz gradient inequality ( Lojasiewicz, 1965) to the nonsmooth case. Many first-order descent methods, under the K L property, can be shown to converge to a critical point (Attouch & Bolte, 2009; Attouch et al., 2010; Bolte et al., 2014) with different types of asymptotic convergence rates. (Li & Lin, 2015) and our paper focuses on the first-order algorithms with momentum, and respectively analyze mAPG and APGnc by exploiting the K L property.\nInexact algorithms under K L: (Attouch et al., 2013; Frankel et al., 2015) studied the inexact prox-\nimal algorithm under the K L property. This paper studies the inexact proximal algorithm with momentum (i.e., APGnc) under the K L property. While (Yao & Kwok, 2016) also studied the inexact APGnc, the analysis did not exploit the K L property to characterize the convergence rate.\nNonconvex SVRG: SVRG was first proposed in (Johnson & Zhang, 2013), to accelerate the stochastic gradient method for strongly convex objective functions, and was studied for the convex case in (Zhu & Yuan, 2016). Recently, SVRG was further studied for smooth nonconvex optimization in Reddi et al. (2016a). Then in (Reddi et al., 2016b), the proximal SVRG was proposed and studied for nonsmooth and nonconvex optimization. Our paper further incorporates SVRG for the proximal gradient with momentum in the nonconvex case. Furthermore, we exploit a certain K L property in our analysis that is very different from the PL property exploited in (Reddi et al., 2016a), and requires special technical treatment in convergence analysis."
    }, {
      "heading" : "2. Preliminaries and Assumptions",
      "text" : "In this section, we first introduce some technical definitions that are useful later on, and then describe the assumptions on the problem (P) that we take in this paper.\nThroughout this section, h : Rd → (−∞,+∞] is an extended real-valued function that is proper, i.e., its domain domh := {x ∈ Rd : h(x) < ∞} is nonempty, and is closed, i.e., its sublevel sets {x ∈ Rd : h(x) ≤ α} are closed for all α ∈ R. Note that a proper and closed function h can be nonsmooth and nonconvex, hence we consider the following generalized notion of derivative.\nDefinition 1 (Subdifferential, (Rockafellar & Wets, 1997)). The Frechét subdifferential ∂̂h of h at x ∈ domh is the set of u ∈ Rd such that\nlim inf z6=x,z→x\nh(z)−h(x)−u>(z−x) ‖z−x‖ ≥ 0,\nwhile the (limiting) subdifferential ∂h at x ∈ domh is the graphical closure of ∂̂h:\n{u : ∃(xk, h(xk))→ (x, h(x)), ∂̂h(xk) 3 uk → u}.\nIn particular, this generalized derivative reduceds to ∇h when h is continuously differentiable, and reduces to the usual subdifferential when h is convex.\nDefinition 2 (Critical point). A point x ∈ Rd is a critical point of h iff 0 ∈ ∂h(x).\nDefinition 3 (Distance). The distance of a point x ∈ Rd to a closed set Ω ⊆ Rd is defined as:\ndistΩ(x) := miny∈Ω ‖y − x‖. (1)\nDefinition 4 (Proximal map, e.g. (Rockafellar & Wets, 1997)). The proximal map of a point x ∈ Rd under a proper and closed function h with parameter η > 0 is defined as:\nproxηh(x) := argminz h(z) + 1 2η‖z− x‖ 2, (2)\nwhere ‖ · ‖ is the Euclidean l2 norm.\nWe note that when h is convex, the corresponding proximal map is the minimizer of a strongly convex function, i.e., a singleton. But for nonconvex h, the proximal map can be set-valued, in which case proxηh(x) stands for an arbitrary element from that set. The proximal map is a popular tool to handle the nonsmooth part of the objective function, and is the key component of proximal-like algorithms (Beck & Teboulle, 2009b; Bolte et al., 2014).\nDefinition 5 (Uniformized K L property, (Bolte et al., 2014)). Function h is said to satisfy the uniformized K L property if for every compact set Ω ⊂ domh on which h is constant, there exist ε, λ > 0 such that for all x̄ ∈ Ω and all x ∈ {x ∈ Rd : distΩ(x) < ε} ∩ [x : h(x̄) < h(x) < h(x̄) + λ], one has\nϕ′ (h(x)− h(x̄)) · dist∂h(x)(0) ≥ 1, (3)\nwhere the function ϕ : [0, λ) → R+ takes the form ϕ(t) = cθ t θ for some constants c > 0, θ ∈ (0, 1].\nThe above definition is a modified version of the original K L property (Bolte et al., 2010; Kurdyka, 1998), and is more convenient for our analysis later. The K L property is a generalization of the Lojasiewicz gradient inequality to nonsmooth functions (Bolte et al., 2007), and it is a powerful tool to analyze a class of first-order descent algorithms (Attouch & Bolte, 2009; Attouch et al., 2010; Bolte et al., 2014). In particular, the class of semi-algebraic functions satisfy the above K L property. This function class covers most objective functions in real applications, for instance, all lp where p ≥ 0 and is rational, real polynomials, rank, etc. For a more detailed discussion and a list of examples of K L functions, see (Bolte et al., 2014) and (Attouch et al., 2010).\nWe adopt the following assumptions on the problem (P) in this paper.\nAssumption 1. Regarding the functions f, g (and F = f + g) in (P)\n1. They are proper and lower semicontinous; infx∈Rd F (x) > −∞; the sublevel set {x ∈ Rd : F (x) ≤ α} is bounded for all α ∈ R; 2. They satisfy the uniformized K L property; 3. Function f is continuously differentiable and the\ngradient ∇f is L-Lipschitz continuous.\nNote that the sublevel set of F is bounded when either f or g has bounded sublevel set, i.e., f(x) or g(x) → +∞ as ‖x‖ → +∞. Of course, we do not assume convexity on either f or g, and the K L property serves as an alternative in this general setting."
    }, {
      "heading" : "3. Main Results",
      "text" : "In this section, we provide our main results on the convergence analysis of APGnc and SVRG-APGnc as well as inexact variants of these algorithms. All proofs of the theorems are provided in supplemental materials."
    }, {
      "heading" : "3.1. Convergence Analysis",
      "text" : "In this subsection, we characterize the convergence of APGnc. Our first result characterizes the behavior of the limit points of the sequence generated by APGnc.\nTheorem 1. Let Assumption 1.{1,3} hold for the problem (P). Then with stepsize η < 1L , the sequence {xk} generated by APGnc satisfies\n1. {xk} is a bounded seuqence; 2. The set of limit points Ω of {xk} forms a compact\nset, on which the objective function F is constant; 3. All elements of Ω are critical points of F .\nTheorem 1 states that the sequence {xk} generated by APGnc eventually approaches a compact set (i.e., a closed and bounded set in Rd) of critical points, and the objective function remains constant on it. Here, approaching critical points establishes the first step for solving general nonconvex problems. Moreover, the compact set Ω meets the requirements of the uniform K L property, and hence provides a seed to exploit the K L property around it. Next, we further utilize the K L property to establish the asymptotic convergence rate for APGnc. In the following theorem, θ is the parameter in the uniformized K L property via the function ϕ that takes the form ϕ(t) = cθ t\nθ for some c > 0, θ ∈ (0, 1]. Theorem 2. Let Assumption 1.{1,2,3} hold for the problem (P). Let F (x) ≡ F ∗ for all x ∈ Ω (the set of limit points), and denote rk := F (xk) − F ∗. Then with stepsize η < 1L , the sequence {rk} satisfies for k0 large enough\n1. If θ = 1, then rk reduces to zero in finite steps;\n2. If θ ∈ [ 12 , 1), then rk ≤ ( c2d1 1+c2d1 )k−k0rk0 ; 3. If θ ∈ (0, 12 ), then rk ≤ ( c (k−k0)d2(1−2θ) ) 1 1−2θ ,\nwhere d1 = ( 1 η + L) 2/( 12η − L 2 ) and d2 = min{ 12cd1 , c 1−2θ (2 2θ−1 2θ−2 − 1)r2θ−1k0 }.\nTheorem 2 characterizes three types of convergence behaviors of APGnc, depending on θ that parameterizes the K L property that the objective function satisfies. An illustrative example for the first kind (θ = 1) can take a form similar to F (x) = |x| for x ∈ R around the critical points. The function is ‘sharp’ around its critical point x = 0 and thus the iterates slide down quickly onto it within finite steps. For the second kind (θ ∈ [ 12 , 1)), example functions can take a form similar to F (x) = x2 around the critical points. That is, the function is strongly convex-like and hence the convergence rate is typically linear. Lastly, functions of the third kind are ‘flat’ around its critical points and thus the convergence is slowed down to sub-linear rate. We note that characterizing the value of θ for a given function is a highly non-trivial problem that takes much independent effort (Kurdyka & Spodzieja, 2011; Li & Kei, 2016). Nevertheless, K L property provides a general picture of the asymptotic convergence behaviors of APGnc."
    }, {
      "heading" : "3.2. APGnc with Adaptive Momentum",
      "text" : "The original APGnc sets the momentum parameter βk = k k+3 , which can be theoretically justified only for convex problems. We here propose an alternative choice of the momentum stepsize that is more intuitive for nonconvex problems, and refer to the resulting algorithm as APGnc+ (See Algorithm 4). The idea is to enlarge the momentum β to further exploit the opportunity of acceleration when the extrapolation step vk achieves a lower function value. Since the proofs of Theorem 1 and Theorem 2 do not depend on the exact value of the momentum stepsize, APGnc and APGnc+ have the same order-level convergence rate. However, we show in Section 4 that APGnc+ improves upon APGnc numerically."
    }, {
      "heading" : "3.3. Inexact APGnc",
      "text" : "We further consider inexact APGnc, in which computation of the proximal gradient step may be inexact, i.e.,\nxk = prox k ηg(yk − η(∇f(yk) + ek)),\nwhere ek captures the inexactness of computation of ∇f(yk), and k captures the inexactness of evaluation\nAlgorithm 4 APGnc with adaptive momentum (APGnc+)\nInput: y1 = x0, β, t ∈ (0, 1), η < 1L . for k = 1, 2, · · · do\nxk = proxηg(yk − η∇f(yk)). vk = xk + βk(xk − xk−1). if F (xk) ≤ F (vk) then\nyk+1 = xk, β ← tβ. else if F (vk) ≤ F (xk) then\nyk+1 = vk, β ← min{βt , 1}. end if\nend for\nof the proximal map as given by\nx = prox ηg(y)\n= {u | g(u) + 12η‖u− y‖ 2\n≤ + g(v) + 12η‖v − y‖ 2, ∀v ∈ Rd}. (4)\nThe inexact proximal algorithm has been studied in (Attouch et al., 2013) for nonconvex functions under the K L property. Our study here is the first treatment of inexact proximal algorithms with momentum (i.e., APG-like algorithms). Furthermore, previous studies addressed only the inexactness of gradient computation for nonconvex problems, but our study here also includes the inexactness of the proximal map for nonconvex problems requiring only g to be convex as the second case we specify below.\nWe study the following two cases.\n1. g is convex; 2. g is nonconvex, and = 0.\nIn the first case, ∂g(x) reduces to the usual subdifferential of convex functions, and the inexactness naturally induces the following -subdifferential\n∂ g(x) = {u | g(y) ≥ g(x) + 〈y − x,u〉 − , ∀y ∈ Rd}.\nMoreover, since the K L property utilizes the information of ∂F , we then need to characterize the perturbation of ∂g under the inexactness . This leads to the following definition. Definition 6. For any x ∈ Rd, let u′ ∈ ∂ g(x) such that ∇f(x) + u′ has the minimal norm. Then the perturbation between ∂g and ∂ g is defined as ξ := dist∂g(x)(u ′).\nThe following theorem states that for nonconvex functions, as long as the inexactness parameters ek, k and ξk are properly controlled, then the inexact APGnc converges at the same order-level rate as the corresponding exact algorithm.\nTheorem 3. Consider the above two cases for inexact APGnc under Assumption 1.{1,2,3}. If for all k ∈ N\n‖ek‖ ≤ γ‖xk − yk‖, (5) k ≤ δ‖xk − yk‖2, (6) ξk ≤ λ‖xk − yk‖, (7)\nthen all the statements in Theorem 1 remain true and the convergence rates in Theorem 2 remain at the same order with the constants d1 = ( 1 η +L+C) 2/( 12η − L 2 − C), where C > 0 depends on γ, δ and λ, and d2 = min{ 12cd1 , c 1−2θ (2 2θ−1 2θ−2 − 1)r2θ−1k0 }. Correspondingly, a smaller stepsize η < 12C+L should be used.\nIt can be seen that, due to the inexactness, the constant factor d1 in Theorem 2 is enlarged, which further leads to a smaller d2 in Theorem 2. Hence, the corresponding convergence rates are slower compared to the exact case, but remain at the same order."
    }, {
      "heading" : "3.4. Stochastic Variance Reduced APGnc",
      "text" : "In this subsection, we study the stochastic variance reduced APGnc algorithm, referred to as SVRG-APGnc. The main steps are presented in Algorithm 5. The major difference from APGnc is that the single proximal gradient step is replaced by a loop of stochastic proximal gradient steps using variance reduced gradients.\nDue to the stochastic nature of the algorithm, the iterate sequence may not stably stay in the local K L region, and hence the standard K L approach fails. We then focus on the analysis of the special but important case of the global K L property with θ = 12 . In fact, if g = 0, the K L property in such a case reduces to the well known Polyak- Lojasiewicz (PL) inequality studied in (Karimi et al., 2016). Various nonconvex problems have been shown to satisfy this property such as quadratic phase retrieval loss function (Zhou et al., 2016) and neural network loss function (Hardt & Ma, 2016). The following theorem characterizes the convergence rate of SVRG-APGnc under the K L property with θ = 12 . Theorem 4. Let η = ρ/L, where ρ < 1/2 and satisfies 4ρ2m2 + ρ ≤ 1. If the problem (P) satisfies the K L property globally with θ = 1/2, then the sequence {yk} generated by Algorithm 5 satisfies\nE [F (yk)− F ∗] ≤ ( d d+1 )k (F (y0)− F ∗) , (8)\nwhere d = c2(L+ 1η ) 2 +ηL2m\n1 2η−L\n, and F ∗ is the optimal func-\ntion value.\nHence, SVRG-APGnc also achieves the linear convergence rate under the K L property with θ = 12 . We\nAlgorithm 5 SVRG-APGnc\nInput: y0 = x 0 0, βk = k k+3 ,m, η < 1 2mL . for k = 0, 1, 2, · · · do x0k = yk,gk = ∇f(yk). for t = 0, 1, · · · ,m− 1 do\nsample ξ from {1, 2, · · · , n}. vtk = ∇fξ(xtk)−∇fξ(yk) + gk. xt+1k = proxηg(x t k − ηvtk).\nend for zk = x m k + βk(x m k − xmk−1). if F (xmk ) ≤ F (zk) then yk+1 = x m k , else if F (zk) ≤ F (xmk ) then yk+1 = zk.\nend if end for\nnote that Theorem 4 differs from the linear convergence result established in (Reddi et al., 2016b) for the SVRG proximal gradient in two folds: (1) we analyze proximal gradient with momentum but (Reddi et al., 2016b) studied proximal gradient algorithm; (2) the K L property with θ = 12 here is different from the generalized PL inequality for composite functions adopted by (Karimi et al., 2016). In order to exploit the K L property, our analysis of the convergence rate requires novel treatments of bounds, which can be seen in the proof of Theorem 4 in ??."
    }, {
      "heading" : "3.5. Inexact SVRG-APGnc",
      "text" : "We further study the inexact SVRG-APGnc algorithm, and the setting of inexactness is the same as that in Section 3.3. Here, we focus on the case where g is convex and ek = 0. The following theorem characterizes the convergence rate under such an inexact case.\nTheorem 5. Let g be convex and consider only the inexactness in the proximal map. Assume the K L property is globally satisfied with θ = 1/2. Set η = ρ/L where ρ < 1/2 and satisfies 8ρ2m2 + ρ ≤ 1. Assume\nthat m−1∑ t=0 3E [ tk] ≤ α m−1∑ t=0 E [ ‖x̄t+1k − xtk‖2 ] for some α > 0, and define x̄t+1k = proxηg(x t k−η∇f(xtk)). Then the sequence {yk} satisfies\nE [F (yk)− F ∗] ≤ ( d d+1 )k (F (y0)− F ∗) , (9)\nwhere d = C2(L+ 1η ) 2 +2ηL2m+ 12η\n1 2η−L−α\n, and F ∗ is the optimal\nfunction value.\nThe convergence analysis for stochastic methods in inexact case has never been addressed before. To incor-\nporate the K L property in deriving the convergence rate, we use a reference sequence generated by exact proximal mapping. Even though this sequence is not actually generated by the algorithm, we can reach to the convergence rate by analyzing the relation between the reference sequence and the actual sequence generated by the algorithm.\nCompared to the exact case, the convergence rate remains at the same order, i.e., the linear convergence, but the convergence is slower due to the larger parameter d caused by the error parameter α."
    }, {
      "heading" : "4. Experiments",
      "text" : "In this section, we compare the efficiency of APGnc and SVRG-APGnc with other competitive methods via numerical experiments. In particular, we focus on the non-negative principle component analysis (NNPCA) problem, which can be formulated as\nmin x≥0 −1 2 xT ( n∑ i=1 ziz T i ) x + γ‖x‖2. (10)\nIt can be equivalently written as\nmin x −1 2 xT ( n∑ i=1 ziz T i ) x + γ‖x‖2 + 1{x≥0}. (11)\nHere, f corresponds to the first two terms, and g is the indicator of the nonnegative orthant, i.e., 1{x≥0}. This problem is nonconvex due to the negative sign and satisfies Assumption 1. In particular, it satisfies the K L property since it is quadratic.\nFor the experiment, we set n = 2000, γ = 10−3 and randomly generate the samples zi from normal distribution. All samples are then normalized to have unit norm. The initialization is randomly generated, and is applied to all the methods. We then compare the function values versus the number of effective passes through n samples."
    }, {
      "heading" : "4.1. Comparison among APG variants",
      "text" : "We first compare among the deterministic APG-like methods in Algorithms 2 - 4 and the standard proximal gradient method. The original APG in Algorithm 1 is not considered since it is not a descent method and does not have convergence guarantee in nonconvex cases. We use a fixed step size η = 0.05/L, where\nL is the spectral norm of the sample matrix n∑ i=1 ziz T i . We set t = 1/2 for APGnc+. The results are shown in Figures 1 and 2. In Figure 1 (a), we show the performance comparison of the methods when there is no error in gradient or proximal calculation. One can see that APGnc and APGnc+ outperform all other APG variants. In particular, APGnc+ performs the best with our adaptive momentum strategy, justifying its empirical advantage. We note that the mAPG requires two passes over all samples at each iteration, and is, therefore, less data efficient compared to other APG variants.\nWe further study the inexact case in Figure 1 (b), where we introduce the proximal error k = 1 100k3 at the kth iteration. One can see that inexact APGnc+ and inexact APGnc also outperform other two inexact algorithms. Furthermore, in Figure 2 (a) and (b), we compare exact and inexact algorithms respectively for APGnc+ and APGnc. It can been that even with a reasonable amount of inexactness, both methods converge comparably to their corresponding exact methods. Although initially the function value drops faster in exact algorithms, both exact and inexact algorithms converge to the optimal point almost at the same time. Such a fact demonstrates the robustness of the algorithms."
    }, {
      "heading" : "4.2. Comparison among SVRG-APG variants",
      "text" : "We then compare the performance among SVRGAPGnc, SVRG-APGnc+ and the original proximal\nSVRG methods, and pick the stepsize η = 1/8mL with m = n. The results are presented in Figures 3 and 4. In the error free case in Figure 3 (a), one can see that SVRG-AGPnc+ method outperforms the others due to the adaptive momentum, and the SVRG-APGnc method also performs better than the original proximal SVRG method.\nFor the inexact case, we set the proximal error as k = min( 1100k3 , 10\n−7). One can see from Figure 3 (b) that the performance is degraded compared to the exact case, and converges to a different local minimum. In this result, all the methods are no longer monotone due to the inexactness and the stochastic nature of SVRG. Nevertheless, the SVRG-APGnc+ still yields the best performance.\nWe also compare the results corresponding to SVRGAPGnc+ and SVRG-APGnc, with and without the proximal error, in Figure 4 (a) and (b), respectively. It is clear that the SVRG-based algorithms are much more sensitive to the error comparing with APG-based ones. Even though the error is set to be smaller than in the inexact case with APG-based methods, one can observe more significant performance gaps than those in Figure 2."
    }, {
      "heading" : "5. Conclusion",
      "text" : "In this paper, we provided comprehensive analysis of the convergence properties of APGnc as well as its inexact and stochastic variance reduced forms by exploiting the K L property. We also proposed an improved algorithm APGnc+ by adapting the momentum parameter. We showed that APGnc shares the same convergence guarantee and the same order of convergence rate as the mAPG, but is computationally more efficient and more amenable to adaptive momentum. In order to exploit the K L property for accelerated algorithms in the situations with inexact errors and/or with stochastic variance reduced gradients, we developed novel convergence analysis techniques, which can be useful for exploring other algorithms for nonconvex problems."
    } ],
    "references" : [ {
      "title" : "On the convergence of the proximal algorithm for nonsmooth functions involving analytic features",
      "author" : [ "H. Attouch", "J. Bolte" ],
      "venue" : "Mathematical Programming,",
      "citeRegEx" : "Attouch and Bolte,? \\Q2009\\E",
      "shortCiteRegEx" : "Attouch and Bolte",
      "year" : 2009
    }, {
      "title" : "Convergence of descent methods for semi-algebraic and tame problems: proximal algorithms, forward-backward splitting, and regularized Gauss-Seidel methods",
      "author" : [ "H. Attouch", "J. Bolte", "B. Svaiter" ],
      "venue" : "Mathematical Programming,",
      "citeRegEx" : "Attouch et al\\.,? \\Q2013\\E",
      "shortCiteRegEx" : "Attouch et al\\.",
      "year" : 2013
    }, {
      "title" : "Fast gradient-based algorithms for constrained total variation image denoising and deblurring problems",
      "author" : [ "A. Beck", "M. Teboulle" ],
      "venue" : "Transactions on Image Processing,",
      "citeRegEx" : "Beck and Teboulle,? \\Q2009\\E",
      "shortCiteRegEx" : "Beck and Teboulle",
      "year" : 2009
    }, {
      "title" : "A fast iterative shrinkagethresholding algorithm for linear inverse problems",
      "author" : [ "A. Beck", "M. Teboulle" ],
      "venue" : "SIAM Journal of Image Science.,",
      "citeRegEx" : "Beck and Teboulle,? \\Q2009\\E",
      "shortCiteRegEx" : "Beck and Teboulle",
      "year" : 2009
    }, {
      "title" : "The Lojasiewicz inequality for nonsmooth subanalytic functions with applications to subgradient dynamical systems",
      "author" : [ "J. Bolte", "A. Daniilidis", "A. Lewis" ],
      "venue" : "SIAM Journal on Optimization,",
      "citeRegEx" : "Bolte et al\\.,? \\Q2007\\E",
      "shortCiteRegEx" : "Bolte et al\\.",
      "year" : 2007
    }, {
      "title" : "Proximal alternating linearized minimization for nonconvex and nonsmooth problems",
      "author" : [ "J. Bolte", "S. Sabach", "M. Teboulle" ],
      "venue" : "Mathematical Programming,",
      "citeRegEx" : "Bolte et al\\.,? \\Q2014\\E",
      "shortCiteRegEx" : "Bolte et al\\.",
      "year" : 2014
    }, {
      "title" : "Splitting methods with variable metric for kurdyka– lojasiewicz functions and general convergence rates",
      "author" : [ "P. Frankel", "G. Garrigos", "J. Peypouquet" ],
      "venue" : "Journal of Optimization Theory and Applications,",
      "citeRegEx" : "Frankel et al\\.,? \\Q2015\\E",
      "shortCiteRegEx" : "Frankel et al\\.",
      "year" : 2015
    }, {
      "title" : "Identity matters in deep learning",
      "author" : [ "M. Hardt", "T. Ma" ],
      "venue" : "Arxiv preprint,",
      "citeRegEx" : "Hardt and Ma,? \\Q2016\\E",
      "shortCiteRegEx" : "Hardt and Ma",
      "year" : 2016
    }, {
      "title" : "Accelerating stochastic gradient descent using predictive variance reduction",
      "author" : [ "R. Johnson", "T. Zhang" ],
      "venue" : "In Advances in Neural Information Processing Systems,",
      "citeRegEx" : "Johnson and Zhang,? \\Q2013\\E",
      "shortCiteRegEx" : "Johnson and Zhang",
      "year" : 2013
    }, {
      "title" : "Linear convergence of gradient and proximal-gradient methods under the Polyak- Lojasiewicz condition. Machine Learning and Knowledge Discovery in Databases",
      "author" : [ "H. Karimi", "J. Nutini", "M. Schmidt" ],
      "venue" : "European Conference,",
      "citeRegEx" : "Karimi et al\\.,? \\Q2016\\E",
      "shortCiteRegEx" : "Karimi et al\\.",
      "year" : 2016
    }, {
      "title" : "On gradients of functions definable in o-minimal structures",
      "author" : [ "K. Kurdyka" ],
      "venue" : "Annales de l’institut Fourier,",
      "citeRegEx" : "Kurdyka,? \\Q1998\\E",
      "shortCiteRegEx" : "Kurdyka",
      "year" : 1998
    }, {
      "title" : "Calculus of the exponent of Kurdyka- Lojasiewicz inequality and its applications to linear convergence of first-order methods",
      "author" : [ "G. Li", "T. Kei" ],
      "venue" : "ArXiv preprint,",
      "citeRegEx" : "Li and Kei,? \\Q2016\\E",
      "shortCiteRegEx" : "Li and Kei",
      "year" : 2016
    }, {
      "title" : "Accelerated proximal gradient methods for nonconvex programming",
      "author" : [ "H. Li", "Z. Lin" ],
      "venue" : "In Advances in Neural Information Processing Systems,",
      "citeRegEx" : "Li and Lin,? \\Q2015\\E",
      "shortCiteRegEx" : "Li and Lin",
      "year" : 2015
    }, {
      "title" : "A method of solving a convex programming problem with convergence rateO(1/k)",
      "author" : [ "Y. Nesterov" ],
      "venue" : "Soviet Mathematics Doklady,",
      "citeRegEx" : "Nesterov,? \\Q1983\\E",
      "shortCiteRegEx" : "Nesterov",
      "year" : 1983
    }, {
      "title" : "Stochastic variance reduction for nonconvex optimization",
      "author" : [ "S. Reddi", "A. Hefny", "S. Sra", "B. Poczos", "A. Smola" ],
      "venue" : "ArXiv preprint,",
      "citeRegEx" : "Reddi et al\\.,? \\Q2016\\E",
      "shortCiteRegEx" : "Reddi et al\\.",
      "year" : 2016
    }, {
      "title" : "Proximal stochastic methods for nonsmooth nonconvex finitesum optimization",
      "author" : [ "S. Reddi", "S. Sra", "B. Poczos", "A. Smola" ],
      "venue" : "In Advances in Neural Information Processing Systems",
      "citeRegEx" : "Reddi et al\\.,? \\Q2016\\E",
      "shortCiteRegEx" : "Reddi et al\\.",
      "year" : 2016
    }, {
      "title" : "Convergence rates of inexact proximal-gradient methods for convex optimization",
      "author" : [ "M. Schmidt", "N.L. Roux", "F.R. Bach" ],
      "venue" : "In Advances in Neural Information Processing Systems",
      "citeRegEx" : "Schmidt et al\\.,? \\Q2011\\E",
      "shortCiteRegEx" : "Schmidt et al\\.",
      "year" : 2011
    }, {
      "title" : "Approximation accuracy, gradient methods, and error bound for structured convex optimization",
      "author" : [ "P. Tseng" ],
      "venue" : "Mathematical Programming,",
      "citeRegEx" : "Tseng,? \\Q2010\\E",
      "shortCiteRegEx" : "Tseng",
      "year" : 2010
    }, {
      "title" : "URL https://arxiv",
      "author" : [ "Q. Yao", "Kwok", "J.T. More efficient accelerated proximal algorithm for nonconvex problems. ArXiv preprint", "December" ],
      "venue" : "org/abs/1612.09069.",
      "citeRegEx" : "Yao et al\\.,? 2016",
      "shortCiteRegEx" : "Yao et al\\.",
      "year" : 2016
    }, {
      "title" : "Geometrical properties and accelerated gradient solvers of non-convex phase retrieval",
      "author" : [ "Y. Zhou", "H. Zhang", "Y. Liang" ],
      "venue" : "The 54th Annual Allerton Conference,",
      "citeRegEx" : "Zhou et al\\.,? \\Q2016\\E",
      "shortCiteRegEx" : "Zhou et al\\.",
      "year" : 2016
    }, {
      "title" : "Improved SVRG for nonstrongly-convex or sum-of-non-convex objectives",
      "author" : [ "Z. Zhu", "Y. Yuan" ],
      "venue" : "In International Conference on Machine Learning,",
      "citeRegEx" : "Zhu and Yuan,? \\Q2016\\E",
      "shortCiteRegEx" : "Zhu and Yuan",
      "year" : 2016
    } ],
    "referenceMentions" : [ {
      "referenceID" : 17,
      "context" : "The reader can refer to (Tseng, 2010) for other variants of APG.",
      "startOffset" : 24,
      "endOffset" : 37
    }, {
      "referenceID" : 13,
      "context" : "APG algorithms: The original accelerated gradient method for minimizing a single smooth convex function dates back to (Nesterov, 1983), and is further extended as APG in the composite minimization framework in (Beck & Teboulle, 2009b; Tseng, 2010).",
      "startOffset" : 118,
      "endOffset" : 134
    }, {
      "referenceID" : 17,
      "context" : "APG algorithms: The original accelerated gradient method for minimizing a single smooth convex function dates back to (Nesterov, 1983), and is further extended as APG in the composite minimization framework in (Beck & Teboulle, 2009b; Tseng, 2010).",
      "startOffset" : 210,
      "endOffset" : 247
    }, {
      "referenceID" : 4,
      "context" : "Nonconvex optimization under K L: The K L property (Bolte et al., 2007) is an extension of the Lojasiewicz gradient inequality ( Lojasiewicz, 1965) to the nonsmooth case.",
      "startOffset" : 51,
      "endOffset" : 71
    }, {
      "referenceID" : 5,
      "context" : "Many first-order descent methods, under the K L property, can be shown to converge to a critical point (Attouch & Bolte, 2009; Attouch et al., 2010; Bolte et al., 2014) with different types of asymptotic convergence rates.",
      "startOffset" : 103,
      "endOffset" : 168
    }, {
      "referenceID" : 1,
      "context" : "Inexact algorithms under K L: (Attouch et al., 2013; Frankel et al., 2015) studied the inexact proximal algorithm under the K L property.",
      "startOffset" : 30,
      "endOffset" : 74
    }, {
      "referenceID" : 6,
      "context" : "Inexact algorithms under K L: (Attouch et al., 2013; Frankel et al., 2015) studied the inexact proximal algorithm under the K L property.",
      "startOffset" : 30,
      "endOffset" : 74
    }, {
      "referenceID" : 14,
      "context" : "Recently, SVRG was further studied for smooth nonconvex optimization in Reddi et al. (2016a). Then in (Reddi et al.",
      "startOffset" : 72,
      "endOffset" : 93
    }, {
      "referenceID" : 5,
      "context" : "The proximal map is a popular tool to handle the nonsmooth part of the objective function, and is the key component of proximal-like algorithms (Beck & Teboulle, 2009b; Bolte et al., 2014).",
      "startOffset" : 144,
      "endOffset" : 188
    }, {
      "referenceID" : 5,
      "context" : "Definition 5 (Uniformized K L property, (Bolte et al., 2014)).",
      "startOffset" : 40,
      "endOffset" : 60
    }, {
      "referenceID" : 10,
      "context" : "The above definition is a modified version of the original K L property (Bolte et al., 2010; Kurdyka, 1998), and is more convenient for our analysis later.",
      "startOffset" : 72,
      "endOffset" : 107
    }, {
      "referenceID" : 4,
      "context" : "The K L property is a generalization of the Lojasiewicz gradient inequality to nonsmooth functions (Bolte et al., 2007), and it is a powerful tool to analyze a class of first-order descent algorithms (Attouch & Bolte, 2009; Attouch et al.",
      "startOffset" : 99,
      "endOffset" : 119
    }, {
      "referenceID" : 5,
      "context" : ", 2007), and it is a powerful tool to analyze a class of first-order descent algorithms (Attouch & Bolte, 2009; Attouch et al., 2010; Bolte et al., 2014).",
      "startOffset" : 88,
      "endOffset" : 153
    }, {
      "referenceID" : 5,
      "context" : "For a more detailed discussion and a list of examples of K L functions, see (Bolte et al., 2014) and (Attouch et al.",
      "startOffset" : 76,
      "endOffset" : 96
    }, {
      "referenceID" : 1,
      "context" : "The inexact proximal algorithm has been studied in (Attouch et al., 2013) for nonconvex functions under the K L property.",
      "startOffset" : 51,
      "endOffset" : 73
    }, {
      "referenceID" : 9,
      "context" : "In fact, if g = 0, the K L property in such a case reduces to the well known Polyak- Lojasiewicz (PL) inequality studied in (Karimi et al., 2016).",
      "startOffset" : 124,
      "endOffset" : 145
    }, {
      "referenceID" : 19,
      "context" : "Various nonconvex problems have been shown to satisfy this property such as quadratic phase retrieval loss function (Zhou et al., 2016) and neural network loss function (Hardt & Ma, 2016).",
      "startOffset" : 116,
      "endOffset" : 135
    }, {
      "referenceID" : 9,
      "context" : ", 2016b) studied proximal gradient algorithm; (2) the K L property with θ = 12 here is different from the generalized PL inequality for composite functions adopted by (Karimi et al., 2016).",
      "startOffset" : 167,
      "endOffset" : 188
    } ],
    "year" : 2017,
    "abstractText" : "In many modern machine learning applications, structures of underlying mathematical models often yield nonconvex optimization problems. Due to the intractability of nonconvexity, there is a rising need to develop efficient methods for solving general nonconvex problems with certain performance guarantee. In this work, we investigate the accelerated proximal gradient method for nonconvex programming (APGnc) (Yao & Kwok, 2016). The method compares between a usual proximal gradient step and a linear extrapolation step, and accepts the one that has a lower function value to achieve a monotonic decrease. In specific, under a general nonsmooth and nonconvex setting, we provide a rigorous argument to show that the limit points of the sequence generated by APGnc are critical points of the objective function. Then, by exploiting the KurdykaLojasiewicz (K L) property for a broad class of functions, we establish the linear and sub-linear convergence rates of the function value sequence generated by APGnc. We further propose a stochastic variance reduced APGnc (SVRGAPGnc), and establish its linear convergence under a special case of the K L property. We also extend the analysis to the inexact version of these methods and develop an adaptive momentum strategy that improves the numerical performance.",
    "creator" : "LaTeX with hyperref package"
  }
}