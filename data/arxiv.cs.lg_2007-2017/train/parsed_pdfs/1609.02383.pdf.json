{
  "name" : "1609.02383.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "Improved Optimistic Mirror Descent for Sparsity and Curvature",
    "authors" : [ "Parameswaran Kamalaruban" ],
    "emails" : [ "kamalaruban.parameswaran@data61.csiro.au" ],
    "sections" : [ {
      "heading" : null,
      "text" : "ar X\niv :1\n60 9.\n02 38\n3v 1\n[ cs\n.L G\n] 8\nS ep\n2 01\nOnline Convex Optimization plays a key role in large scale machine learning. Early approaches to this problem were conservative, in which the main focus was protection against the worst case scenario. But recently several algorithms have been developed for tightening the regret bounds in easy data instances such as sparsity, predictable sequences, and curved losses. In this work we unify some of these existing techniques to obtain new update rules for the cases when these easy instances occur together. First we analyse an adaptive and optimistic update rule which achieves tighter regret bound when the loss sequence is sparse and predictable. Then we explain an update rule that dynamically adapts to the curvature of the loss function and utilizes the predictable nature of the loss sequence as well. Finally we extend these results to composite losses.\n1 Introduction\nThe Online Convex Optimization (OCO) problem plays a key role in machine learning as it has interesting theoretical implications and important practical applications especially in the large scale setting where computational efficiency is the main concern. [15] provides a detailed analysis of the OCO problem setting and discusses several applications of this paradigm - online regression, prediction with expert advice, and online ranking.\nGiven a convex set Ω ⊆ Rn and a set F of convex functions, the OCO problem can be formulated as a repeated game between a learner and an adversary. At each time step t ∈ [T ], the learner chooses a point xt ∈ Ω, then the adversary reveals the loss function ft ∈ F , and the learner suffers a loss of ft(xt). The learner’s goal is to minimize the regret which is given by\nR(T ) :=\nT ∑\nt=1\nft(xt)− inf x∈Ω\nT ∑\nt=1\nft(x).\nThere are two main classes of minimax optimal update rules for the OCO problem, namely Follow The Regularized Leader (FTRL) and Mirror Descent. In this work we consider the latter class. Given a strongly convex function ψ and a learning rate η > 0, standard mirror descent update is given by\nxt+1 = inf x∈Ω\nη〈gt, xt〉+ Bψ(x, xt), (1)\nwhere gt ∈ ∂ft(xt) and Bψ(·, ·) is Bregman divergence (formally defined later). It is well understood that the minimax optimal algorithms achieve a regret bound of O( √ T ), which cannot be improved for arbitrary sequences of convex losses [17]. But in practice there are several easy data instances such as sparsity, predictable sequences and curved losses, in which much tighter regret bounds are achievable. Even though minimax analysis gives robust algorithms, they are overly conservative on easy data. Now we consider some of the existing algorithms that automatically adapt to the easy data to learn faster while being robust to worst case as well.\n[6] replaces the single static regularizer in the standard mirror descent update 1 by a data dependent sequence of regularizers. This is a fully adaptive approach as it doesn’t require any prior knowledge about the bound on the term given by\n∑T t=1 ‖gt‖ 2 to construct the regularizers. Further for a particular choice of\nregularizer sequence they achieved a regret bound of the form O\n(\nmax t\n‖xt − x∗‖∞ ∑n i=1\n√\n∑T t=1 g 2 t,i\n)\n, which\nis better than the minimax optimal bound when the gradients of the losses are sparse and the prediction space is box-shaped.\n[4, 14] have shown that an optimistic prediction g̃t+1 of the next gradient gt+1 at time t can be used to achieve tighter regret bounds in the case where the loss functions are generated by some predictable process e.g. i.i.d losses with small variance and slowly changing gradients. For the general convex losses, the regret\nbound of this optimistic approach is O\n(\n√\n∑T t=1 ‖gt − g̃t‖ 2 ∗\n)\n. But this is a non-adaptive approach since one\nrequires knowledge of the upper bound on ∑T t=1 ‖gt − g̃t‖ 2 ∗ to set the optimal value for the learning rate. Instead we can employ the standard doubling trick to obtain similar bound with slightly worst constants. Online optimization with curved losses (strong-convex, exp-concave, mixable etc.) is easier than linear losses. When the loss functions are uniformly exp-concave or strongly convex, O(logT ) regret bounds are achieved with appropriate choice of regularizers [7, 9]. But this bound will become worse when the uniform lower bound on the convexity parameters is much smaller. In that case [9] proposed an algorithm that can adapt to the convexity of the loss functions, and achieves O( √ T ) regret bounds for arbitrary convex losses and O(logT ) for uniformly strong-convex losses. Even though [11] has shown equivalence between mirror descent and a variant of FTRL (namely FTRLProx) algorithms with adaptive regularizers, no such mapping is available between optimistic mirror descent and optimistic FTRL updates. Recently [12] have combined adaptive FTRL and optimistic FTRL updates to achieve tighter regret bounds for sparse and predictable sequences. In section 3 we extend this unification to obtain adaptive and optimistic mirror descent updates. We obtained a factor of √ 2 improvement in the regret bound compared to that of [12], because in their regret analysis they could not apply the strong FTRL lemma from [11].\nIn section 4 we consider the adaptive and optimistic mirror descent update with strongly convex loss functions. In this case we achieve tighter logarithmic regret bound without a priori knowledge about the lower bound on the strong-convexity parameters, in similar spirit of [9]. We also explain a curvature adaptive optimistic algorithm that interpolates the results for general convex losses and strongly-convex losses.\nIn practice the original convex optimization problem itself can have a regularization term associated with the constraints of the problem and generally it is not preferable to linearize those regularization terms. In section 5 we extend all our results to such composite objectives as well.\nThe main contributions of this paper are:\n• An adaptive and optimistic mirror descent update that achieves tighter regret bounds for sparse and predictable sequences (Section 3).\n• Improved optimistic mirror descent algorithm that adapts to the curvature of the loss functions (Section 4).\n• Extension of the unified update rules to the composite objectives (Section 5).\nOmitted proofs are given in the appendix.\n2 Notation and Background\nWe use the following notation throughout. For n ∈ Z+, let [n] := {1, ..., n}. The ith element of a vector x ∈ Rn is denoted by xi ∈ R, and for a time dependent vector xt ∈ Rn, the ith element is xt,i ∈ R. The inner product between two vectors x, y ∈ Rn is written as 〈x, y〉. The gradient of a differentiable function f at x ∈ Rn is denoted by ∇f(x) or f ′(x). A superscript T , AT denotes transpose of the matrix or vector A.\nAlgorithm 1 Adaptive and Optimistic Mirror Descent\nInput: regularizers r0, r1 ≥ 0. Initialize: x1, x̂1 = 0 ∈ Ω. for t = 1 to T do Predict x̂t, observe ft, and incur loss ft(x̂t). Compute gt ∈ ∂ft(x̂t) and g̃t+1(g1, ..., gt). Construct rt+1 s.t. r0:t+1 is 1-strongly convex w.r.t. ‖·‖(t+1). Update\nxt+1 = argmin x∈Ω\n〈gt, x〉+ Br0:t(x, xt), (2)\nx̂t+1 = argmin x∈Ω\n〈g̃t+1, x〉+ Br0:t+1(x, xt+1). (3)\nend for\nGiven x ∈ Rn, A = diag(x) is the n× n matrix with entries Ai,i = xi , i ∈ [n] and Ai,j = 0 for i 6= j. For a symmetric positive definite matrix A ∈ Sn++, we have that ∀x 6= 0, xTAx > 0. If A−B ∈ Sn++, then we write A ≻ B. The square root of A ∈ Sn++ is the unique matrix X ∈ Sn++ such that XX = A and it is denoted as A 1 2 . We use the compressed summation notation Ha:b as shorthand for ∑b s=aHs, where Hs can be a scalar, vector, matrix, or function. Given a norm ‖·‖, its dual norm is defined as follows ‖y‖∗ := sup x:‖x‖≤1 〈x, y〉. For a time varying norm ‖·‖(t), its dual norm is written as ‖·‖(t),∗. The dual norm of the Mahalanobis norm ‖x‖A := √ xTAx is given by ‖y‖A−1 = √\nyTA−1y. Given a convex set Ω ⊆ Rn and a convex function f : Ω → R, ∂f(x) denotes the sub-differential of f at x which is defined as ∂f(x) := {g : f(y) ≥ f(x) + 〈g, y − x〉, ∀y ∈ Ω}. A function f : Ω → R is α-strongly convex with respect to a general norm ‖·‖ if for all x, y ∈ Ω\nf(x) ≥ f(y) + 〈g, x− y〉+ α 2 ‖x− y‖2 , g ∈ ∂f(y).\nBregman divergence with respect to a differentiable function g is defined as follows\nBg(x, y) := g(x)− g(y)− 〈∇g(y), x− y〉.\nObserve that the function g is α-strongly convex with respect to ‖·‖ if and only if for all x, y ∈ Ω : Bg(x, y) ≥ α 2 ‖x− y‖ 2 . In this paper we use the following properties of Bregman divergences\n• Linearity: Bαψ+βφ(x, y) = αBψ(x, y) + βBφ(x, y).\n• Generalized triangle inequality: Bψ(x, y) + Bψ(y, z) = Bψ(x, z) + 〈x− y,∇ψ(z)−∇ψ(y)〉.\nThe following proposition [16, 1] is handy in deriving explicit update rules for mirror descent algorithms that we have presented in this work.\nProposition 1. Suppose ψ is strictly convex and differentiable, and y satisfies the condition ∇ψ(y) = ∇ψ(u)− g. Then\nargmin x∈Ω {〈g, x〉+ Bψ(x, u)} = argmin x∈Ω Bψ(x, y).\n3 Adaptive and Optimistic Mirror Descent\nWhen the sequences are predictable [4] proposed that making an optimistic prediction of xt+1 at time t itself using the optimistic prediction g̃t+1(g1, ..., gt) of the next sub-gradient gt+1. For the optimistic\nprediction choices of g̃t+1 = 1 t ∑t s=1 gs and g̃t+1 = gt, we obtain the variance bound [8] and the path length bound [4] respectively. Given a 1-strongly convex function ψ, and a learning rate η > 0, the optimistic mirror descent update can be given by two stage updates as follows\nxt+1 = argmin x∈Ω\nη〈gt, xt〉+ Bψ(x, xt)\nx̂t+1 = argmin x∈Ω\nη〈g̃t+1, xt〉+ Bψ(x, xt+1).\nAdaptive and Optimistic mirror descent update is obtained by replacing the static regularizer ψ by a sequence of data dependent regularizers rt’s, which are chosen such that r0:t is 1-strongly convex with respect to ‖·‖(t). The unified update is given in Algorithm 1. Note that the regularizer rt+1 is constructed at time t (based on the data observed only up to time t) and is used in the second stage update (3). Also observe that by setting g̃t = 0 for all t in Algorithm 1 we recover a slightly modified adaptive mirror descent update given by xt+1 = argmin\nx∈Ω 〈gt, xt〉+ Br0:t(x, xt), where rt can depend only on g1, ..., gt−1.\nThe following lemma is a generalization of Lemma 5 from [4] for time varying norms, which gives a bound on the instantaneous linear regret of Algorithm 1.\nLemma 2. The instantaneous linear regret of Algorithm 1 w.r.t. any x∗ ∈ Ω can be bounded as follows\n〈x̂t − x∗, gt〉 ≤ Br0:t(x∗, xt)− Br0:t(x∗, xt+1) + 12 ‖gt − g̃t‖ 2 (t),∗ .\nProof. Consider\n〈gt, x̂t − x∗〉 = 〈gt − g̃t, x̂t − xt+1〉+ 〈g̃t, x̂t − xt+1〉+ 〈gt, xt+1 − x∗〉. (4)\nBy the fact that 〈a, b〉 ≤ ‖a‖ ‖b‖∗ ≤ 12 ‖a‖ 2 + 12 ‖b‖ 2 ∗, we have\n〈gt − g̃t, x̂t − xt+1〉 ≤ 12 ‖x̂t − xt+1‖ 2 (t) + 1 2 ‖gt − g̃t‖ 2 (t),∗ .\nThe first-order optimality condition [2] for x∗ = argmin x∈Ω 〈g, x〉+ Bψ(x, y) is given by\n〈x∗ − z, g〉 ≤ Bψ(z, y)− Bψ(z, x∗)− Bψ(x∗, y), ∀z ∈ Ω.\nBy applying the above condition for (3) and (2) we have respectively\n〈x̂t − xt+1, g̃t〉 ≤ Br0:t(xt+1, xt)− Br0:t(xt+1, x̂t)− Br0:t(x̂t, xt), 〈xt+1 − x∗, gt〉 ≤ Br0:t(x∗, xt)− Br0:t(x∗, xt+1)− Br0:t(xt+1, xt).\nThus by (4) we have\n〈gt, x̂t − x∗〉 ≤ 12 ‖x̂t − xt+1‖ 2 (t) + 1 2 ‖gt − g̃t‖ 2 (t),∗ + Br0:t(x∗, xt)− Br0:t(x∗, xt+1)− Br0:t(xt+1, x̂t) ≤ 12 ‖gt − g̃t‖ 2 (t),∗ + Br0:t(x∗, xt)− Br0:t(x∗, xt+1)\nwhere the second inequality is due to 1-strong convexity of r0:t w.r.t. ‖·‖(t).\nThe following lemma is already proven by [4] and used in the proof of our Theorem 8.\nLemma 3. For Algorithm 1 we have, ‖x̂t − xt+1‖(t) ≤ ‖gt − g̃t‖(t),∗.\nThe following regret bound holds for Algorithm 1 with a sequence of general convex functions ft’s:\nTheorem 4. The regret of Algorithm 1 w.r.t. any x∗ ∈ Ω is bounded by T ∑\nt=1\nft(x̂t)− ft(x∗) ≤ 12 T ∑\nt=1\n‖gt − g̃t‖2(t),∗ + T ∑\nt=1\nBrt(x∗, xt) + Br0(x∗, x1)− Br0:T (x∗, xT+1).\nProof. Consider\nT ∑\nt=1\nft(x̂t)− ft(x∗)\n≤ T ∑\nt=1\n〈gt, x̂t − x∗〉\n≤ T ∑\nt=1\n1 2 ‖gt − g̃t‖ 2 (t),∗ + Br0:t(x∗, xt)− Br0:t(x∗, xt+1),\nwhere the first inequality is due to the convexity of ft and the second one is due to Lemma 2. Then the following simplification of the sum of Bregman divergence terms completes the proof.\nT ∑\nt=1\nBr0:t(x∗, xt)− Br0:t(x∗, xt+1)\n= Br0(x∗, x1)− Br0:T (x∗, xT+1) + T ∑\nt=1\nBrt(x∗, xt)\nNow we analyse the performance of Algorithm 1 with specific choices of regularizer sequences. First we recover the non-adaptive optimistic mirror descent [4] and its regret bound as a corollary of Theorem 4.\nCorollary 5. Given 1-strongly convex (w.r.t. ‖·‖) function ψ, define Rmax(x∗) := maxx∈Ω Bψ(x∗, x) − minx∈Ω Bψ(x∗, x). If rt’s are given by r0(x) = 1ηψ(x) (for η > 0) and rt(x) = 0, ∀t ≥ 1, then the regret of Algorithm 1 w.r.t. any x∗ ∈ Ω is bounded as follows\nT ∑\nt=1\nft(x̂t)− ft(x∗) ≤ η\n2\nT ∑\nt=1\n‖gt − g̃t‖2∗ + 1 η Rmax(x∗).\nFurther if ∑T t=1 ‖gt − g̃t‖ 2 ∗ ≤ Q, then by choosing η =\n√\n2Rmax(x∗) Q , we have\nT ∑\nt=1\nft(x̂t)− ft(x∗) ≤ √ 2Rmax(x∗)Q.\nProof. For the given choice of regularizers, we have r0:t(x) = 1 η ψ(x) and Br0:t(x, y) = 1ηBψ(x, y). Since r0:t is 1-strongly convex w.r.t. 1√ η ‖·‖, we have ‖·‖(t) = 1√η ‖·‖ and ‖·‖(t),∗ = √ η ‖·‖∗. Then the corollary directly follows from Theorem 4.\nIn this non-adaptive case we need to know an upper bound of ∑T t=1 ‖gt − g̃t‖ 2 ∗ in advance to choose the optimal value for η. Instead we can employ the standard doubling trick to obtain similar bounds with slightly worst constants.\nBy leveraging the techniques from [6] we can adaptively construct regularizers based on the observed data. The following corollary describes a regularizer construction scheme for Algorithm 1 which is fully adaptive and achieves a regret guarantee that holds at anytime.\nCorollary 6. Given Ω ⊆ ×ni=1[−Ri, Ri], let\nG0 = 0 (5)\nG1 = γ 2I s.t. γ2I < (gt − g̃t)(gt − g̃t)T , ∀t (6)\nGt = (gt−1 − g̃t−1)(gt−1 − g̃t−1)T , ∀t ≥ 2 (7)\nQ1:t = diag\n(\n1\nR1 , ...,\n1\nRn\n)\ndiag (G1:t) 1 2 .\nIf rt’s are given by r0 (x) = 0 and rt (x) = 1 2 √ 2 ‖x‖2Qt , then the regret of Algorithm 1 w.r.t. any x ∗ ∈ Ω is bounded by\nT ∑\nt=1\nft(x̂t)− ft(x∗) ≤ 2 √ 2 n ∑\ni=1\nRi\n√ √ √ √γ2 + T−1 ∑\nt=1\n(gt,i − g̃t,i)2.\nProof. By letting η = √ 2 for the given sequence of regularizers, we get r0:t (x) = 1 2η ‖x‖ 2 Q1:t . Since r0:t is 1-strongly convex w.r.t. 1√ η ‖·‖Q1:t , we have ‖·‖(t) = 1√ η ‖·‖Q1:t and ‖·‖(t),∗ = √ η ‖·‖Q−1 1:t . By using the facts that diag (α1, ..., αn) 1 2 = diag (√ α1, ..., √ αn )\nand diag (β1, ..., βn) · diag (γ1, ..., γn) = diag (β1γ1, ..., βnγn), the (i, i)-th entry of the diagonal matrix Q1:t can be given as\n(Q1:t)ii = 1\nRi\n√ √ √ √diag ( γ2I + t−1 ∑\ns=1\n(gs − g̃s)(gs − g̃s)T )\nii\n= 1\nRi\n√ √ √ √γ2 + t−1 ∑\ns=1\n(gs,i − g̃s,i)2.\nNow by Theorem 4 the regret bound of Algorithm 1 with this choice of regularizer sequence can be given as follows\nT ∑\nt=1\nft(x̂t)− ft(x∗) ≤ 12 T ∑\nt=1\n‖gt − g̃t‖2(t),∗ + T ∑\nt=1\nBrt(x∗, xt).\nConsider\n1 2\nT ∑\nt=1\n‖gt − g̃t‖2(t),∗\n= 12\nT ∑\nt=1\nη ‖gt − g̃t‖2Q−1 1:t\n= η\n2\nT ∑\nt=1\nn ∑\ni=1\n(gt,i − g̃t,i)2 (Q1:t)−1ii\n= η\n2\nT ∑\nt=1\nn ∑\ni=1\n(gt,i − g̃t,i)2 Ri √\nγ2 + ∑t−1 s=1 (gs,i − g̃s,i) 2\n≤ η 2\nn ∑\ni=1\nRi\nT ∑\nt=1\n(gt,i − g̃t,i)2 √\n∑t s=1 (gs,i − g̃s,i) 2\n≤ η n ∑\ni=1\nRi\n√ √ √ √ T ∑\nt=1\n(gt,i − g̃t,i)2\n≤ η n ∑\ni=1\nRi\n√ √ √ √γ2 + T−1 ∑\nt=1\n(gt,i − g̃t,i)2,\nwhere the first and third inequalities are due to the fact that γ2 ≥ (gt,i − g̃t,i)2 for all t ∈ [T ], and the second inequality is due to the fact that for any non-negative real numbers a1, a2, ..., an : ∑n i=1 ai √ ∑\ni j=1 aj ≤\n2 √ ∑n i=1 ai. Also observing that\nT ∑\nt=1\nBrt(x∗, xt)\n=\nT ∑\nt=1\n1\n2η ‖x∗ − xt‖2Qt\n= 1\n2η\nT ∑\nt=1\nn ∑\ni=1\n(x∗i − xt,i)2 (Qt)ii\n≤ 1 2η\nn ∑\ni=1\n(2Ri) 2 T ∑\nt=1\n(Qt)ii\n= 2\nη\nn ∑\ni=1\nR2i (Q1:T )ii\n= 2\nη\nn ∑\ni=1\nRi\n√ √ √ √γ2 + T−1 ∑\nt=1\n(gt,i − g̃t,i)2\ncompletes the proof.\nThe regret bound obtained in the above corollary is much tighter than that of [6] and [4] when the sequence of loss functions are sparse and predictable. Since we are using per-coordinate learning rates implicitly we get better bounds for the case where only certain coordinates of the gradients are accurately predictable as well. Even when the loss sequence is completely unpredictable, the above bound is not much worse than a constant factor of the bound in [6].\nBy using Proposition 1 we can derive explicit forms of the update rules given by (2) and (3) with regularizers constructed in Corollary 6. For yt+1 = xt − √ 2Q−11:t gt and ŷt+1 = xt+1 − √ 2Q−11:t+1g̃t+1, the updates (2) and (3) can be given as xt+1 = argmin x∈Ω 1 2 ‖x− yt+1‖ 2 Q1:t and x̂t+1 = argmin x∈Ω 1 2 ‖x− ŷt+1‖ 2 Q1:t+1 respectively. The next corollary explains a regularizer construction method with full matrix learning rates, which is an extension of Corollary 6. But this approach is computationally not preferable, especially in high dimensions, as it costs O(n2) per round of operations.\nCorollary 7. Define D := sup x,y∈Ω\n‖x− y‖2. Let Q1:t = (G1:t) 1 2 , where Gt’s are given by (5),(6) and (7). If\nrt’s are given by r0 (x) = 0 and rt (x) = 1√ 2D ‖x‖2Qt , then the regret of Algorithm 1 w.r.t. any x ∗ ∈ Ω is bounded by T ∑\nt=1\nft(x̂t)− ft(x∗) ≤ √ 2D tr (Q1:T ) .\n4 Optimistic Mirror Descent with Curved Losses\nThe following theorem provides a regret bound of Algorithm 1 for the case where ft is Ht-strongly convex with respect to some general norm ‖·‖. Since this theorem is an extension of Theorem 2.1 from [9] for the Optimistic Mirror Descent, this inherits the properties mentioned there such as : rt’s can be chosen without the knowledge of uniform lower bound on Ht’s, and O(logT ) bound can be achieved even when some Ht ≤ 0 as long as H1:t\nt > 0.\nTheorem 8. Let ft is Ht-strongly convex w.r.t. ‖·‖ and Ht ≤ γ for all t ∈ [T ]. If rt’s are given by r0(x) = 0, r1(x) = γ 4 ‖x‖ 2 , and rt(x) = Ht−1 4 ‖x‖ 2 for all t ≥ 2, then the regret of Algorithm 1 w.r.t. any x∗ ∈ Ω is bounded by T ∑\nt=1\nft(x̂t)− ft(x∗) ≤ 3 T ∑\nt=1\n‖gt − g̃t‖2∗ H1:t + γ 4 ‖x∗ − x1‖2 .\nProof. For the given choice of regularizers, we have r0:t(x) = H1:t−1+γ 4 ‖x‖ 2 and Br0:t(x, y) = H1:t−1+γ4 ‖x− y‖ 2. Since r0:t is 1-strongly convex w.r.t. √ H1:t−1+γ 2 ‖·‖, we have ‖·‖(t) = √ H1:t−1+γ 2 ‖·‖ and ‖·‖(t),∗ = √ 2 H1:t−1+γ\n‖·‖∗. Thus for any x∗ ∈ Ω we have\nft(x̂t)− ft(x∗)\n≤ 〈gt, x̂t − x∗〉 − Ht 2 ‖x̂t − x∗‖2\n≤ 12 ‖gt − g̃t‖ 2 (t),∗ + Br0:t(x∗, xt)− Br0:t(x∗, xt+1)−\nHt\n2 ‖x̂t − x∗‖2\n= ‖gt − g̃t‖2∗ H1:t−1 + γ + H1:t−1 + γ 4 ‖x∗ − xt‖2 − H1:t−1 + γ 4 ‖x∗ − xt+1‖2 − Ht 2 ‖x̂t − x∗‖2 ,\nwhere the first inequality is due to the strong convexity of ft, and the second inequality is due to Lemma 2. Observe that\nT ∑\nt=1\nH1:t−1 + γ\n4\n{ ‖x∗ − xt‖2 − ‖x∗ − xt+1‖2 }\n=\nT ∑\nt=1\n‖x∗ − xt+1‖2 { H1:t + γ 4 − H1:t−1 + γ 4 } + γ 4 ‖x∗ − x1‖2 − H1:T + γ 4 ‖x∗ − xT+1‖2\n≤ T ∑\nt=1\nHt\n4 ‖x∗ − xt+1‖2 +\nγ 4 ‖x∗ − x1‖2 ,\nand\nT ∑\nt=1\nHt\n4 ‖x∗ − xt+1‖2 −\nHt\n2 ‖x̂t − x∗‖2\n= T ∑\nt=1\nHt\n4\n{ ‖x∗ − x̂t + x̂t − xt+1‖2 − 2 ‖x∗ − x̂t‖2 }\n≤ T ∑\nt=1\nHt\n2 ‖x̂t − xt+1‖2\n≤ T ∑\nt=1\nH1:t−1 + γ\n2 ‖x̂t − xt+1‖2\n≤ 2 T ∑\nt=1\n‖gt − g̃t‖2∗ H1:t−1 + γ ,\nwhere the first inequality is obtained by applying the triangular inequality of norms the fact that (a+ b)2 ≤ 2a2 + 2b2, the second inequality is due to the facts that Ht ≤ γ and H1:t−1 ≥ 0, and the third inequality is due to Lemma 3.\nNow by summing up the instantaneous regrets and using the above observation we get\nT ∑\nt=1\nft(x̂t)− ft(x∗) ≤ 3 T ∑\nt=1\n‖gt − g̃t‖2∗ H1:t−1 + γ + γ 4 ‖x∗ − x1‖2\n≤ 3 T ∑\nt=1\n‖gt − g̃t‖2∗ H1:t + γ 4 ‖x∗ − x1‖2 ,\nwhere the last inequality is due to the fact that Ht ≤ γ.\nIn the above theorem if Ht ≥ H > 0 and ‖gt − g̃t‖∗ ≤ 1 (w.l.o.g) for all t, then it obtain a regret bound of the form O ( log ∑T\nt=1 ‖gt − g̃t‖ 2 ∗\n)\n. When H is small, however, this guaranteed regret can still be large.\nNow instead of running Algorithm 1 on the observed sequence of ft’s, we use the modified sequence of loss functions of the form\nf̃t(x) := ft(x) + λt\n2 ‖x− x̂t‖2 , λt ≥ 0, (8)\nwhich is already considered in [5] for the non-optimistic mirror descent case. Given ft is Ht-strongly convex with respect to ‖·‖, f̃t is (Ht + λt)-strongly convex. Also note that ∂f̃t(x̂t) = ∂ft(x̂t) because the gradient of ‖x− x̂t‖2 is 0 when evaluated at x̂t [5]. Thus in the updates (2) and (3) the terms gt and g̃t+1 remain unchanged, only the regularizers rt’s will change appropriately. By applying Theorem 8 for the modified sequence of losses given by (8) we obtain the following corollary.\nCorollary 9. Let 2R = sup x,y∈Ω\n‖x− y‖. Also let ft be Ht-strongly convex w.r.t. ‖·‖, Ht ≤ γ, and λt ≤ δ,\nfor all t ∈ [T ]. If Algorithm 1 is performed on the modified functions f̃t’s with the regularizers rt’s given by r0(x) = 0, r1(x) = γ+δ 4 ‖x‖ 2 , and rt(x) = Ht−1+λt−1 4 ‖x‖ 2 for all t ≥ 2, then for any sequence λ1, ..., λT ≥ 0, we get T ∑\nt=1\nft(x̂t)− ft(x∗) ≤ 2R2λ1:T + 3 T ∑\nt=1\n‖gt − g̃t‖2∗ H1:t + λ1:t + γ + δ 4 ‖x∗ − x1‖2 .\nIn the above corollary if we consider the two terms that depend on λt’s, the first term increases and the second term deceases with the increase of λt’s. Based on the online balancing heuristic approach [9], the positive solution of 2R2λ1:t = 3 ‖gt−g̃t‖2∗ H1:t+λ1:t is given by\nλt =\n√\n(H1:t + λ1:t−1) 2 + 6‖gt−g̃t‖2∗ R2\n− (H1:t + λ1:t−1) 2 .\nThe resulting algorithm with the above choice of λt is given in Algorithm 2. By using the Lemma 3.1 from [9] we obtain the following regret bound for Algorithm 2.\nTheorem 10. The regret of Algorithm 2 on the sequence of ft’s with curvature Ht ≥ 0 is bounded by\nT ∑\nt=1\nft(x̂t)− ft(x∗) ≤ γ + δ 4 ‖x∗ − x1‖2 + 2 inf\nλ∗ 1 ,...,λ∗ T\n{\n2R2λ∗1:T + 3 T ∑\nt=1\n‖gt − g̃t‖2∗ H1:t + λ∗1:t\n}\n.\nAlgorithm 2 Curvature Adaptive and Optimistic Mirror Descent\nInput: r0(x) = 0 and r1(x) = γ+δ 4 ‖x‖ 2. Initialize: x1, x̂1 = 0 ∈ Ω. for t = 1 to T do Predict x̂t, observe ft, and incur loss ft(x̂t). Compute gt ∈ ∂ft(x̂t) and g̃t+1(g1, ..., gt).\nCompute λt =\n√\n(H1:t+λ1:t−1) 2+\n6‖gt−g̃t‖ 2 ∗\nR2 −(H1:t+λ1:t−1)\n2\nDefine rt+1(x) = Ht+λt 4 ‖x‖ 2 . Update\nxt+1 = argmin x∈Ω\n〈gt, x〉+ Br0:t(x, xt),\nx̂t+1 = argmin x∈Ω\n〈g̃t+1, x〉+ Br0:t+1(x, xt+1).\nend for\nThus the Algorithm 2 achieves a regret bound which is competitive with the bound achievable by the best offline choice of parameters λt’s. From the above theorem we obtain the following two corollaries which show\nthat Algorithm 2 achieves intermediate rates between O\n(\n√\n∑T t=1 ‖gt − g̃t‖ 2 ∗\n)\nand O ( log ∑T\nt=1 ‖gt − g̃t‖ 2 ∗\n)\ndepending on the curvature of the losses.\nCorollary 11. For any sequence of convex loss functions ft’s, the bound on the regret of Algorithm 2 is\nO\n(\n√\n∑T t=1 ‖gt − g̃t‖ 2 ∗\n)\n.\nProof. Let λ∗1 = √ ∑T t=1 ‖gt − g̃t‖ 2 ∗, and λ ∗ t = 0 for all t > 1.\n2R2λ∗1:T + 3 T ∑\nt=1\n‖gt − g̃t‖2∗ H1:t + λ∗1:t\n= 2R2\n√ √ √ √ T ∑\nt=1\n‖gt − g̃t‖2∗ + 3 T ∑\nt=1 ‖gt − g̃t‖2∗ 0 + √\n∑T t=1 ‖gt − g̃t‖ 2 ∗\n= ( 2R2 + 3 )\n√ √ √ √ T ∑\nt=1\n‖gt − g̃t‖22.\nCorollary 12. Suppose ‖gt − g̃t‖∗ ≤ 1 (w.l.o.g) and Ht ≥ H > 0 for all t ∈ [T ]. Then the bound on the regret of Algorithm 2 is O (\nlog ∑T t=1 ‖gt − g̃t‖ 2 ∗\n)\n.\nProof. Set λ∗t = 0 for all t.\n2R2λ∗1:T + 3 T ∑\nt=1\n‖gt − g̃t‖2∗ H1:t + λ∗1:t = 0 + 3 T ∑\nt=1\n‖gt − g̃t‖2∗ Ht+ 0\n= O\n(\nlog\nT ∑\nt=1\n‖gt − g̃t‖2∗\n)\n,\nAlgorithm 3 Adaptive and Optimistic Mirror Descent with Composite Losses\nInput: regularizers r0, r1 ≥ 0, composite losses {ψt}t where ψt ≥ 0. Initialize: x1, x̂1 = 0 ∈ Ω. for t = 1 to T do Predict x̂t, observe ft, and incur loss ft(x̂t) + ψt(x̂t). Compute gt ∈ ∂ft(x̂t) and g̃t+1(g1, ..., gt). Construct rt+1 s.t. r0:t+1 is 1-strongly convex w.r.t. ‖·‖(t+1). Update\nxt+1 = argmin x∈Ω\n〈gt, x〉+ ψt(x) + Br0:t(x, xt), (9)\nx̂t+1 = argmin x∈Ω\n〈g̃t+1, x〉+ ψt+1(x) + Br0:t+1(x, xt+1). (10)\nend for\nwhere the last inequality is due to the fact that if at ≤ 1 for all t ∈ [T ], then ∑T t=1 at t ≤ O\n(\nlog ∑T\nt=1 at\n)\n.\nThe results obtained here can be extended to the applications discussed in [5, 13] to obtain much tighter results.\n5 Composite Losses\nHere we consider the case when observed loss function ft is composed with some non-negative (possibly non-smooth) convex regularizer term ψt to impose certain constraints on the original problem. In this case we generally do not want to linearize the additional regularizer term, thus in the update rules given by (2) and (3) we include ψt and ψt+1 respectively without linearizing them. This extension is presented in Algorithm 3.\nThe following lemma provides a bound on the instantaneous regret of Algorithm 3.\nLemma 13. The instantaneous regret of Algorithm 3 w.r.t. any x∗ ∈ Ω can be bounded as follows\n{ft(x̂t) + Ψt(x̂t)} − {ft(x∗) + Ψt(x∗)} ≤ 12 ‖gt − g̃t‖ 2 (t),∗ + Br0:t(x∗, xt)− Br0:t(x∗, xt+1).\nProof. The instantaneous regret of the algorithm can be bounded as below using the convexity of ft\n{ft(x̂t) + Ψt(x̂t)} − {ft(x∗) + Ψt(x∗)} ≤ 〈gt, x̂t − x∗〉+ {Ψt(x̂t)−Ψt(x∗)} .\nNow consider 〈gt, x̂t − x∗〉 = 〈gt − g̃t, x̂t − xt+1〉+ 〈g̃t, x̂t − xt+1〉+ 〈gt, xt+1 − x∗〉. (11)\nBy the fact that 〈a, b〉 ≤ ‖a‖ ‖b‖∗ ≤ 12 ‖a‖ 2 + 12 ‖b‖ 2 ∗, we have\n〈gt − g̃t, x̂t − xt+1〉 ≤ 12 ‖x̂t − xt+1‖ 2 (t) + 1 2 ‖gt − g̃t‖ 2 (t),∗\nThe first-order optimality condition for x∗ = argmin x∈Ω 〈g, x〉+ f(x) + Bψ(x, y) and for z ∈ Ω,\n〈x∗ − z, g〉 ≤ 〈z − x∗, f ′(x∗)〉+ Bψ(z, y)− Bψ(z, x∗)− Bψ(x∗, y).\nBy applying the above condition for (10) and (9) we have respectively\n〈x̂t − xt+1, g̃t〉 ≤ 〈Ψ′t(x̂t), xt+1 − x̂t〉+ Br0:t(xt+1, xt)− Br0:t(xt+1, x̂t)− Br0:t(x̂t, xt)\n〈xt+1 − x∗, gt〉 ≤ 〈Ψ′t(xt+1), x∗ − xt+1〉+ Br0:t(x∗, xt)− Br0:t(x∗, xt+1)− Br0:t(xt+1, xt). Thus by (11) we have\n〈gt, x̂t − x∗〉+ {Ψt(x̂t)−Ψt(x∗)} ≤ 12 ‖x̂t − xt+1‖ 2 (t) + 1 2 ‖gt − g̃t‖ 2 (t),∗ + Br0:t(x∗, xt)− Br0:t(x∗, xt+1)− Br0:t(xt+1, x̂t)\n+ Ψt(x̂t)−Ψt(x∗) + 〈Ψ′t(x̂t), xt+1 − x̂t〉+ 〈Ψ′t(xt+1), x∗ − xt+1〉 ≤ 12 ‖gt − g̃t‖ 2 (t),∗ + Br0:t(x∗, xt)− Br0:t(x∗, xt+1)\n+ Ψt(x̂t) + 〈Ψ′t(x̂t), xt+1 − x̂t〉+ 〈Ψ′t(xt+1), x∗ − xt+1〉 −Ψt(x∗) ≤ 12 ‖gt − g̃t‖ 2 (t),∗ + Br0:t(x∗, xt)− Br0:t(x∗, xt+1)\n+ Ψt(xt+1) + 〈Ψ′t(xt+1), x∗ − xt+1〉 −Ψt(x∗) ≤ 12 ‖gt − g̃t‖ 2 (t),∗ + Br0:t(x∗, xt)− Br0:t(x∗, xt+1) + Ψt(x∗)−Ψt(x∗) = 12 ‖gt − g̃t‖ 2 (t),∗ + Br0:t(x∗, xt)− Br0:t(x∗, xt+1)\nwhere the second inequality is due to 1-strong convexity of r0:t w.r.t. ‖·‖(t), and the third and fourth inequalities are due to the convexity of Ψt at x̂t and xt+1 respectively.\nFrom the above lemma we can observe that the instantaneous regret of Algorithm 3 is exactly equal to that of the non-composite version (Algorithm 1). Thus all the improvements that we discussed in the previous sections for the non-composite case are also applicable to composite losses as well.\n6 Discussion\nWe present adaptive variants of optimistic mirror descent which improve the existing regret bounds when some of the easy data instances occur together. Algorithms that we have discussed in this paper achieve regret guarantees that hold at any time.\nWe also note that the regret bounds given in this work can be converted into convergence bounds for batch stochastic problems using online-to-batch conversion techniques [3, 10].\nAs in Theorem 8, we can obtain regret bound for the case when the loss function ft is βt-convex (which is broader class than exp-concave losses) as well. But for the resulting bound we cannot apply Lemma 3.1 from [9] to obtain a near optimal closed form solution of λt.\nReferences\n[1] Amir Beck and Marc Teboulle. Mirror descent and nonlinear projected subgradient methods for convex optimization. Operations Research Letters, 31(3):167–175, 2003.\n[2] Stephen Boyd and Lieven Vandenberghe. Convex optimization. Cambridge university press, 2004.\n[3] Nicolo Cesa-Bianchi, Alex Conconi, and Claudio Gentile. On the generalization ability of on-line learning algorithms. Information Theory, IEEE Transactions on, 50(9):2050–2057, 2004.\n[4] Chao-Kai Chiang, Tianbao Yang, Chia-Jung Lee, Mehrdad Mahdavi, Chi-Jen Lu, Rong Jin, and Shenghuo Zhu. Online optimization with gradual variations. 2012.\n[5] Chuong B Do, Quoc V Le, and Chuan-Sheng Foo. Proximal regularization for online and batch learning. In Proceedings of the 26th Annual International Conference on Machine Learning, pages 257–264. ACM, 2009.\n[6] John Duchi, Elad Hazan, and Yoram Singer. Adaptive subgradient methods for online learning and stochastic optimization. The Journal of Machine Learning Research, 12:2121–2159, 2011.\n[7] Elad Hazan, Amit Agarwal, and Satyen Kale. Logarithmic regret algorithms for online convex optimization. Machine Learning, 69(2-3):169–192, 2007.\n[8] Elad Hazan and Satyen Kale. Extracting certainty from uncertainty: Regret bounded by variation in costs. Machine learning, 80(2-3):165–188, 2010.\n[9] Elad Hazan, Alexander Rakhlin, and Peter L Bartlett. Adaptive online gradient descent. In Advances in Neural Information Processing Systems, pages 65–72, 2007.\n[10] ShamMKakade and Ambuj Tewari. On the generalization ability of online strongly convex programming algorithms. In Advances in Neural Information Processing Systems, pages 801–808, 2009.\n[11] H Brendan McMahan. Analysis techniques for adaptive online learning. arXiv preprint arXiv:1403.3465, 2014.\n[12] Mehryar Mohri and Scott Yang. Accelerating optimization via adaptive prediction. arXiv preprint arXiv:1509.05760, 2015.\n[13] Francesco Orabona, Luo Jie, and Barbara Caputo. Online-batch strongly convex multi kernel learning. In Computer Vision and Pattern Recognition (CVPR), 2010 IEEE Conference on, pages 787–794. IEEE, 2010.\n[14] Alexander Rakhlin and Karthik Sridharan. Online learning with predictable sequences. arXiv preprint arXiv:1208.3728, 2012.\n[15] Shai Shalev-Shwartz. Online learning and online convex optimization. Foundations and Trends R© in Machine Learning, 4(2):107–194, 2011.\n[16] Nati Srebro, Karthik Sridharan, and Ambuj Tewari. On the universality of online mirror descent. In Advances in neural information processing systems, pages 2645–2653, 2011.\n[17] Martin Zinkevich. Online convex programming and generalized infinitesimal gradient ascent. 2003.\nA Proofs\nProof. (Proposition 1) Observe that\nargmin x∈Ω\nBψ(x, y)\n= argmin x∈Ω\nψ(x) − ψ(y)− 〈∇ψ(y), x− y〉\n= argmin x∈Ω\nψ(x) − 〈∇ψ(y), x〉\n= argmin x∈Ω\nψ(x) − 〈∇ψ(u)− g, x〉\n= argmin x∈Ω\n〈g, x〉+ ψ(x) − ψ(u)− 〈∇ψ(u), x− u〉\n= argmin x∈Ω\n〈g, x〉+ Bψ(x, u).\nProof. (Lemma 3) Since r0:t is 1-strongly convex w.r.t. ‖·‖(t) we have\nBr0:t(x̂t, xt+1) = r0:t(x̂t)− r0:t(xt+1)− 〈∇r0:t(xt+1), x̂t − xt+1〉 ≥ 12 ‖x̂t − xt+1‖ 2 (t) ,\nand\nBr0:t(xt+1, x̂t) = r0:t(xt+1)− r0:t(x̂t)− 〈∇r0:t(x̂t), xt+1 − x̂t〉 ≥ 12 ‖xt+1 − x̂t‖ 2 (t) .\nAdding these two bounds, we obtain\n‖x̂t − xt+1‖2(t) ≤ 〈∇r0:t(x̂t)−∇r0:t(xt+1), x̂t − xt+1〉. (12)\nSuppose yt+1 and ŷt satisfy the conditions ∇r0:t(yt+1) = ∇r0:t(xt) − gt and ∇r0:t(ŷt) = ∇r0:t(xt) − g̃t respectively. Then by applying Proposition 1 to the updates in (3) and (2) of Algorithm 1, we obtain\nxt+1 = argmin x∈Ω\nBr0:t(x, yt+1)\nx̂t = argmin x∈Ω\nBr0:t(x, ŷt).\nBy applying the first order optimality condition for the above two optimization statements, we have\n〈∇r0:t(xt+1)−∇r0:t(yt+1), x̂t − xt+1〉 ≥ 0 〈∇r0:t(x̂t)−∇r0:t(ŷt), xt+1 − x̂t〉 ≥ 0,\nrespectively. Combining these two bounds, we obtain\n〈∇r0:t(ŷt)−∇r0:t(yt+1), x̂t − xt+1〉 ≥ 〈∇r0:t(x̂t)−∇r0:t(xt+1), x̂t − xt+1〉.\nBy combining the above result with (12), we obtain\n‖x̂t − xt+1‖2(t) ≤ 〈∇r0:t(ŷt)−∇r0:t(yt+1), x̂t − xt+1〉 ≤ ‖∇r0:t(ŷt)−∇r0:t(yt+1)‖(t),∗ ‖x̂t − xt+1‖(t) ,\nby a generalized Cauchy-Schwartz inequality. Dividing both sides by ‖x̂t − xt+1‖(t), we have\n‖x̂t − xt+1‖(t) ≤ ‖∇r0:t(ŷt)−∇r0:t(yt+1)‖(t),∗ = ‖(∇r0:t(xt)− g̃t)− (∇r0:t(xt)− gt)‖(t),∗ = ‖gt − g̃t‖(t),∗ .\nProof. (Corollary 7) By letting η = D√ 2 for the given sequence of regularizers, we get r0:t (x) = 1 2η ‖x‖ 2 Q1:t . Since r0:t is 1-strongly convex w.r.t. 1√ η ‖·‖Q1:t , we have ‖·‖(t) = 1√ η ‖·‖Q1:t and ‖·‖(t),∗ = √ η ‖·‖Q−1 1:t . By Theorem 4 the regret bound of Algorithm 1 with this choice of regularizer sequence can be given as follows\nT ∑\nt=1\nft(x̂t)− ft(x∗) ≤ 12 T ∑\nt=1\n‖gt − g̃t‖2(t),∗ + T ∑\nt=1\nBrt(x∗, xt).\nConsider\n1 2\nT ∑\nt=1\n‖gt − g̃t‖2(t),∗\n= 12\nT ∑\nt=1\nη ‖gt − g̃t‖2Q−1 1:t\n= η\n2\nT ∑\nt=1\n(gt − g̃t)Q−11:t (gt − g̃t) T\n= η\n2\nT ∑\nt=1\n(gt − g̃t) ( γ2I +G2:t )− 12 (gt − g̃t)T\n≤ η 2\nT ∑\nt=1\n(gt − g̃t) (G2:t+1)− 1 2 (gt − g̃t)T\n≤ η tr ( G 1 2 2:T+1 )\n≤ η tr ( ( γ2I +G2:T ) 1 2 )\n= η tr (Q1:T ) ,\nwhere the first inequality is due to the facts that γ2I < Gt+1 and A < B < 0 ⇒ A 1 2 < B 1 2 and B−1 < A−1,\nthe second inequality is due to the fact that ∑T t=1 a T t\n(\n∑t s=1 asa T s )−12 at ≤ tr ( ∑T t=1 ata T t ) (see Lemma 10\nfrom [6]), and the third inequality is due to the fact that γ2I < GT+1. Also observing that\nT ∑\nt=1\nBrt(x∗, xt)\n=\nT ∑\nt=1\n1\n2η ‖x∗ − xt‖2Qt\n≤ 1 2η\nT ∑\nt=1\n‖x∗ − xt‖22 λmax (Qt)\n≤ 1 2η\nT ∑\nt=1\n‖x∗ − xt‖22 tr (Qt)\n≤ 1 2η\nT ∑\nt=1\nD2tr (Qt)\n= D2\n2η tr (Q1:T ) .\ncompletes the proof.\nB Mirror Descent with β-convex losses\nGiven a convex set Ω ⊆ Rn and β > 0, a function f : Ω → R is β-convex, if for all x, y ∈ Ω\nf(x) ≥ f(y) + 〈g, x− y〉+ β ‖x− y‖2ggT , g ∈ ∂f(y).\nAlgorithm 4 Adaptive Mirror Descent\nInput: regularizers r0 ≥ 0. Initialize: x1 = 0 ∈ Ω. for t = 1 to T do Predict xt, observe ft, and incur loss ft(xt). Compute gt ∈ ∂ft(xt). Construct rt s.t. r0:t is 1-strongly convex w.r.t. ‖·‖(t). Update\nxt+1 = argmin x∈Ω\n〈gt, x〉+ Br0:t(x, xt). (13)\nend for\nLemma 14. The instantaneous linear regret of Algorithm 4 w.r.t. any x∗ ∈ Ω can be bounded as follows\n〈xt − x∗, gt〉 ≤ Br0:t(x∗, xt)− Br0:t(x∗, xt+1) + 12 ‖gt‖ 2 (t),∗ .\nProof. By the first-order optimality condition for (13) we have,\n〈x− xt+1, gt +∇r0:t(xt+1)−∇r0:t(xt)〉 ≥ 0 (14)\nConsider\n〈xt − x∗, gt〉 = 〈xt+1 − x∗, gt〉+ 〈xt − xt+1, gt〉 ≤ 〈x∗ − xt+1,∇r0:t(xt+1)−∇r0:t(xt)〉+ 〈xt − xt+1, gt〉 = Br0:t(x∗, xt)− Br0:t(x∗, xt+1)− Br0:t(xt+1, xt) + 〈xt − xt+1, gt〉 ≤ Br0:t(x∗, xt)− Br0:t(x∗, xt+1)− Br0:t(xt+1, xt) + 12 ‖xt − xt+1‖ 2 (t) + 1 2 ‖gt‖ 2 (t),∗ ≤ Br0:t(x∗, xt)− Br0:t(x∗, xt+1) + 12 ‖gt‖ 2 (t),∗ ,\nwhere the first inequality is due to (14), the second equality is due to the fact that 〈∇ψ(a)−∇ψ(b), c− a〉 = Bψ(c, b)−Bψ(c, a)−Bψ(a, b), the second inequality is due to the fact that 〈a, b〉 ≤ ‖a‖ ‖b‖∗ ≤ 12 ‖a‖ 2 + 12 ‖b‖ 2 ∗, and the third inequality is due to the 1-strong convexity of r0:t w.r.t. ‖·‖(t).\nTheorem 15. Let ft is βt-convex, ∀t ∈ [T ]. If rt’s are given by\nrt(x) = ‖x‖2ht , where h0 = In×n and ht = βtgtg T t for t ≥ 1, (15)\nthen the regret of Algorithm 4 w.r.t. any x∗ ∈ Ω is bounded by T ∑\nt=1\nft(xt)− ft(x∗) ≤ 1\n4\nT ∑\nt=1\n‖gt‖2h−1 0:t + ‖x∗ − x1‖22 .\nProof. For the choice of regularizer sequence {rt} given by (15), we have r0:t(x) = ‖x‖2h0:t and Br0:t(x, y) = 1 2 (√ 2 ‖x− y‖h0:t )2 . Since r0:t is 1-strongly convex w.r.t. √ 2 ‖·‖h0:t , we have ‖·‖(t) = √ 2 ‖·‖h0:t and ‖·‖(t),∗ = 1√ 2 ‖·‖h−1 0:t .\nFor any x∗ ∈ Ω\nft(xt)− ft(x∗)\n≤ 〈gt, xt − x∗〉 − βt ‖x∗ − xt‖2gtgTt ≤ Br0:t(x∗, xt)− Br0:t(x∗, xt+1) + 12 ‖gt‖ 2 (t),∗ − ‖x∗ − xt‖ 2 βtgtg T t = ‖x∗ − xt‖2h0:t − ‖x ∗ − xt+1‖2h0:t − ‖x ∗ − xt‖2ht + 1 2 ‖gt‖ 2 (t),∗ ,\nwhere the first inequality is due to the βt-convexity of ft(·), and the second inequality is due to Lemma 14. By summing all the instantaneous regrets we get\nT ∑\nt=1\nft(xt)− T ∑\nt=1\nft(x ∗)\n≤ T ∑\nt=1\n{\n‖x∗ − xt‖2h0:t − ‖x ∗ − xt‖2h0:t−1 − ‖x ∗ − xt‖2ht } + ‖x∗ − x1‖2h0 − ‖x ∗ − xT+1‖2h0:T + 1 2\nT ∑\nt=1\n‖gt‖2(t),∗\n≤ ‖x∗ − x1‖22 + 1\n4\nT ∑\nt=1\n‖gt‖2h−1 0:t .\nNow instead of running Algorithm 4 on the observed sequence of ft’s, we use the modified sequence of loss functions of the form f̃t(x) := ft(x) + λtg(x), λt ≥ 0, (16) where g(x) is 1-convex. By following the proof of Theorem 15 for the modified sequence of losses given by (16) we obtain the following corollary.\nTheorem 16. Let g(x) be a 1-convex function, A2 = sup x∈Ω g(x) and B = sup x∈Ω ‖g′(x)‖(g′(x)g′(x)T )−1 . Also let ft be βt-convex (βt ≥ 0), ∀t ∈ [T ]. If Algorithm 4 is performed on the modified functions f̃t’s with the regularizers rt’s given by\nrt(x) = ‖x‖2ht , where h0 = In×n, and ht = βtgtg T t + λtg ′(xt)g ′(xt) T , for t ≥ 1, (17)\nthen for any sequence λ1, ..., λT ≥ 0, we get T ∑\nt=1\nft(xt)− ft(x∗) ≤ ( A2 + B2\n2\n)\nλ1:T + 1 2\nT ∑\nt=1\n‖gt‖2h−1 0:t + ‖x∗ − x1‖22 .\nProof. Since ft is βt-convex and g is 1-convex, for any x ∗ ∈ Ω we have\n{ft(xt) + λtg(xt)} − {ft(x∗) + λtg(x∗)} = ft(xt)− ft(x∗) + λt {g(xt)− g(x∗)} ≤ 〈gt, xt − x∗〉 − βt ‖x∗ − xt‖2gtgTt + λt { 〈g′(xt), xt − x∗〉 − ‖x∗ − xt‖2g′(xt)g′(xt)T } = 〈gt + λtg′(xt), xt − x∗〉 − ‖x∗ − xt‖2βtgtgTt +λtg′(xt)g′(xt)T .\nBy following the similar steps from the proof of Theorem 15 we get\nT ∑\nt=1\nft(xt) + λtg(xt)− { T ∑\nt=1\nft(x ∗) + λtg(x ∗)\n}\n≤ 1 4\nT ∑\nt=1\n‖gt + λtg′(xt)‖2h−1 0:t + ‖x∗ − x1‖22 .\nBy using the facts that ‖x+ y‖2A ≤ 2 ‖x‖ 2 A+2 ‖y‖ 2 A, h0:t < ht < λtg ′(xt)g′(xt) T , and ‖g′(xt)‖(g′(xt)g′(xt)T )−1 ≤ B, we have\nT ∑\nt=1\nft(xt) + λtg(xt)− { T ∑\nt=1\nft(x ∗) + λtg(x ∗)\n}\n≤ 12 T ∑\nt=1\n{\n‖gt‖2h−1 0:t + λ2t ‖g′(xt)‖ 2 h −1 0:t\n}\n+ ‖x∗ − x1‖22\n≤ 12 T ∑\nt=1\n{\n‖gt‖2h−1 0:t + λ2t ‖g′(xt)‖ 2 (λtg′(xt)g′(xt)T ) −1\n}\n+ ‖x∗ − x1‖22\n≤ 12 T ∑\nt=1\n‖gt‖2h−1 0:t\n+ B2\n2 λ1:T + ‖x∗ − x1‖22 .\nBy neglecting the g(xt) terms in the L.H.S. and using the fact that g(x ∗) ≤ A2 we get\nT ∑\nt=1\nft(xt) ≤ T ∑\nt=1\nft(x ∗) +A2λ1:T + 1 2\nT ∑\nt=1\n‖gt‖2h−1 0:t + ‖x∗ − x1‖22 + B2 2 λ1:T .\nBut we cannot apply Lemma 3.1 from [9] for the above regret bound to obtain a near optimal closed form solution to λt. One could employ an optimization algorithm to find the optimal λt."
    } ],
    "references" : [ {
      "title" : "Mirror descent and nonlinear projected subgradient methods for convex optimization",
      "author" : [ "Amir Beck", "Marc Teboulle" ],
      "venue" : "Operations Research Letters,",
      "citeRegEx" : "1",
      "shortCiteRegEx" : "1",
      "year" : 2003
    }, {
      "title" : "On the generalization ability of on-line learning algorithms",
      "author" : [ "Nicolo Cesa-Bianchi", "Alex Conconi", "Claudio Gentile" ],
      "venue" : "Information Theory, IEEE Transactions on,",
      "citeRegEx" : "3",
      "shortCiteRegEx" : "3",
      "year" : 2004
    }, {
      "title" : "Online optimization with gradual variations",
      "author" : [ "Chao-Kai Chiang", "Tianbao Yang", "Chia-Jung Lee", "Mehrdad Mahdavi", "Chi-Jen Lu", "Rong Jin", "Shenghuo Zhu" ],
      "venue" : null,
      "citeRegEx" : "4",
      "shortCiteRegEx" : "4",
      "year" : 2012
    }, {
      "title" : "Proximal regularization for online and batch learning",
      "author" : [ "Chuong B Do", "Quoc V Le", "Chuan-Sheng Foo" ],
      "venue" : "In Proceedings of the 26th Annual International Conference on Machine Learning,",
      "citeRegEx" : "5",
      "shortCiteRegEx" : "5",
      "year" : 2009
    }, {
      "title" : "Adaptive subgradient methods for online learning and stochastic optimization",
      "author" : [ "John Duchi", "Elad Hazan", "Yoram Singer" ],
      "venue" : "The Journal of Machine Learning Research,",
      "citeRegEx" : "6",
      "shortCiteRegEx" : "6",
      "year" : 2011
    }, {
      "title" : "Logarithmic regret algorithms for online convex optimization",
      "author" : [ "Elad Hazan", "Amit Agarwal", "Satyen Kale" ],
      "venue" : "Machine Learning,",
      "citeRegEx" : "7",
      "shortCiteRegEx" : "7",
      "year" : 2007
    }, {
      "title" : "Extracting certainty from uncertainty: Regret bounded by variation in costs",
      "author" : [ "Elad Hazan", "Satyen Kale" ],
      "venue" : "Machine learning,",
      "citeRegEx" : "8",
      "shortCiteRegEx" : "8",
      "year" : 2010
    }, {
      "title" : "Adaptive online gradient descent",
      "author" : [ "Elad Hazan", "Alexander Rakhlin", "Peter L Bartlett" ],
      "venue" : "In Advances in Neural Information Processing Systems,",
      "citeRegEx" : "9",
      "shortCiteRegEx" : "9",
      "year" : 2007
    }, {
      "title" : "On the generalization ability of online strongly convex programming algorithms",
      "author" : [ "ShamMKakade", "Ambuj Tewari" ],
      "venue" : "In Advances in Neural Information Processing Systems,",
      "citeRegEx" : "10",
      "shortCiteRegEx" : "10",
      "year" : 2009
    }, {
      "title" : "Analysis techniques for adaptive online learning",
      "author" : [ "H Brendan McMahan" ],
      "venue" : "arXiv preprint arXiv:1403.3465,",
      "citeRegEx" : "11",
      "shortCiteRegEx" : "11",
      "year" : 2014
    }, {
      "title" : "Accelerating optimization via adaptive prediction",
      "author" : [ "Mehryar Mohri", "Scott Yang" ],
      "venue" : "arXiv preprint arXiv:1509.05760,",
      "citeRegEx" : "12",
      "shortCiteRegEx" : "12",
      "year" : 2015
    }, {
      "title" : "Online-batch strongly convex multi kernel learning",
      "author" : [ "Francesco Orabona", "Luo Jie", "Barbara Caputo" ],
      "venue" : "In Computer Vision and Pattern Recognition (CVPR),",
      "citeRegEx" : "13",
      "shortCiteRegEx" : "13",
      "year" : 2010
    }, {
      "title" : "Online learning with predictable sequences",
      "author" : [ "Alexander Rakhlin", "Karthik Sridharan" ],
      "venue" : "arXiv preprint arXiv:1208.3728,",
      "citeRegEx" : "14",
      "shortCiteRegEx" : "14",
      "year" : 2012
    }, {
      "title" : "Online learning and online convex optimization",
      "author" : [ "Shai Shalev-Shwartz" ],
      "venue" : "Foundations and Trends R  © in Machine Learning,",
      "citeRegEx" : "15",
      "shortCiteRegEx" : "15",
      "year" : 2011
    }, {
      "title" : "On the universality of online mirror descent",
      "author" : [ "Nati Srebro", "Karthik Sridharan", "Ambuj Tewari" ],
      "venue" : "In Advances in neural information processing systems,",
      "citeRegEx" : "16",
      "shortCiteRegEx" : "16",
      "year" : 2011
    } ],
    "referenceMentions" : [ {
      "referenceID" : 13,
      "context" : "[15] provides a detailed analysis of the OCO problem setting and discusses several applications of this paradigm - online regression, prediction with expert advice, and online ranking.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 4,
      "context" : "[6] replaces the single static regularizer in the standard mirror descent update 1 by a data dependent sequence of regularizers.",
      "startOffset" : 0,
      "endOffset" : 3
    }, {
      "referenceID" : 2,
      "context" : "[4, 14] have shown that an optimistic prediction g̃t+1 of the next gradient gt+1 at time t can be used to achieve tighter regret bounds in the case where the loss functions are generated by some predictable process e.",
      "startOffset" : 0,
      "endOffset" : 7
    }, {
      "referenceID" : 12,
      "context" : "[4, 14] have shown that an optimistic prediction g̃t+1 of the next gradient gt+1 at time t can be used to achieve tighter regret bounds in the case where the loss functions are generated by some predictable process e.",
      "startOffset" : 0,
      "endOffset" : 7
    }, {
      "referenceID" : 5,
      "context" : "When the loss functions are uniformly exp-concave or strongly convex, O(logT ) regret bounds are achieved with appropriate choice of regularizers [7, 9].",
      "startOffset" : 146,
      "endOffset" : 152
    }, {
      "referenceID" : 7,
      "context" : "When the loss functions are uniformly exp-concave or strongly convex, O(logT ) regret bounds are achieved with appropriate choice of regularizers [7, 9].",
      "startOffset" : 146,
      "endOffset" : 152
    }, {
      "referenceID" : 7,
      "context" : "In that case [9] proposed an algorithm that can adapt to the convexity of the loss functions, and achieves O( √ T ) regret bounds for arbitrary convex losses and O(logT ) for uniformly strong-convex losses.",
      "startOffset" : 13,
      "endOffset" : 16
    }, {
      "referenceID" : 9,
      "context" : "Even though [11] has shown equivalence between mirror descent and a variant of FTRL (namely FTRLProx) algorithms with adaptive regularizers, no such mapping is available between optimistic mirror descent and optimistic FTRL updates.",
      "startOffset" : 12,
      "endOffset" : 16
    }, {
      "referenceID" : 10,
      "context" : "Recently [12] have combined adaptive FTRL and optimistic FTRL updates to achieve tighter regret bounds for sparse and predictable sequences.",
      "startOffset" : 9,
      "endOffset" : 13
    }, {
      "referenceID" : 10,
      "context" : "We obtained a factor of √ 2 improvement in the regret bound compared to that of [12], because in their regret analysis they could not apply the strong FTRL lemma from [11].",
      "startOffset" : 80,
      "endOffset" : 84
    }, {
      "referenceID" : 9,
      "context" : "We obtained a factor of √ 2 improvement in the regret bound compared to that of [12], because in their regret analysis they could not apply the strong FTRL lemma from [11].",
      "startOffset" : 167,
      "endOffset" : 171
    }, {
      "referenceID" : 7,
      "context" : "In this case we achieve tighter logarithmic regret bound without a priori knowledge about the lower bound on the strong-convexity parameters, in similar spirit of [9].",
      "startOffset" : 163,
      "endOffset" : 166
    }, {
      "referenceID" : 14,
      "context" : "The following proposition [16, 1] is handy in deriving explicit update rules for mirror descent algorithms that we have presented in this work.",
      "startOffset" : 26,
      "endOffset" : 33
    }, {
      "referenceID" : 0,
      "context" : "The following proposition [16, 1] is handy in deriving explicit update rules for mirror descent algorithms that we have presented in this work.",
      "startOffset" : 26,
      "endOffset" : 33
    }, {
      "referenceID" : 2,
      "context" : "3 Adaptive and Optimistic Mirror Descent When the sequences are predictable [4] proposed that making an optimistic prediction of xt+1 at time t itself using the optimistic prediction g̃t+1(g1, .",
      "startOffset" : 76,
      "endOffset" : 79
    }, {
      "referenceID" : 6,
      "context" : "prediction choices of g̃t+1 = 1 t ∑t s=1 gs and g̃t+1 = gt, we obtain the variance bound [8] and the path length bound [4] respectively.",
      "startOffset" : 89,
      "endOffset" : 92
    }, {
      "referenceID" : 2,
      "context" : "prediction choices of g̃t+1 = 1 t ∑t s=1 gs and g̃t+1 = gt, we obtain the variance bound [8] and the path length bound [4] respectively.",
      "startOffset" : 119,
      "endOffset" : 122
    }, {
      "referenceID" : 2,
      "context" : "The following lemma is a generalization of Lemma 5 from [4] for time varying norms, which gives a bound on the instantaneous linear regret of Algorithm 1.",
      "startOffset" : 56,
      "endOffset" : 59
    }, {
      "referenceID" : 2,
      "context" : "The following lemma is already proven by [4] and used in the proof of our Theorem 8.",
      "startOffset" : 41,
      "endOffset" : 44
    }, {
      "referenceID" : 2,
      "context" : "First we recover the non-adaptive optimistic mirror descent [4] and its regret bound as a corollary of Theorem 4.",
      "startOffset" : 60,
      "endOffset" : 63
    }, {
      "referenceID" : 4,
      "context" : "By leveraging the techniques from [6] we can adaptively construct regularizers based on the observed data.",
      "startOffset" : 34,
      "endOffset" : 37
    }, {
      "referenceID" : 4,
      "context" : "The regret bound obtained in the above corollary is much tighter than that of [6] and [4] when the sequence of loss functions are sparse and predictable.",
      "startOffset" : 78,
      "endOffset" : 81
    }, {
      "referenceID" : 2,
      "context" : "The regret bound obtained in the above corollary is much tighter than that of [6] and [4] when the sequence of loss functions are sparse and predictable.",
      "startOffset" : 86,
      "endOffset" : 89
    }, {
      "referenceID" : 4,
      "context" : "Even when the loss sequence is completely unpredictable, the above bound is not much worse than a constant factor of the bound in [6].",
      "startOffset" : 130,
      "endOffset" : 133
    }, {
      "referenceID" : 7,
      "context" : "1 from [9] for the Optimistic Mirror Descent, this inherits the properties mentioned there such as : rt’s can be chosen without the knowledge of uniform lower bound on Ht’s, and O(logT ) bound can be achieved even when some Ht ≤ 0 as long as H1:t t > 0.",
      "startOffset" : 7,
      "endOffset" : 10
    }, {
      "referenceID" : 3,
      "context" : "Now instead of running Algorithm 1 on the observed sequence of ft’s, we use the modified sequence of loss functions of the form f̃t(x) := ft(x) + λt 2 ‖x− x̂t‖ , λt ≥ 0, (8) which is already considered in [5] for the non-optimistic mirror descent case.",
      "startOffset" : 205,
      "endOffset" : 208
    }, {
      "referenceID" : 3,
      "context" : "Also note that ∂f̃t(x̂t) = ∂ft(x̂t) because the gradient of ‖x− x̂t‖ is 0 when evaluated at x̂t [5].",
      "startOffset" : 96,
      "endOffset" : 99
    }, {
      "referenceID" : 7,
      "context" : "Based on the online balancing heuristic approach [9], the positive solution of 2Rλ1:t = 3 ‖gt−g̃t‖2∗ H1:t+λ1:t is given by λt = √",
      "startOffset" : 49,
      "endOffset" : 52
    }, {
      "referenceID" : 7,
      "context" : "1 from [9] we obtain the following regret bound for Algorithm 2.",
      "startOffset" : 7,
      "endOffset" : 10
    } ],
    "year" : 2016,
    "abstractText" : "Online Convex Optimization plays a key role in large scale machine learning. Early approaches to this problem were conservative, in which the main focus was protection against the worst case scenario. But recently several algorithms have been developed for tightening the regret bounds in easy data instances such as sparsity, predictable sequences, and curved losses. In this work we unify some of these existing techniques to obtain new update rules for the cases when these easy instances occur together. First we analyse an adaptive and optimistic update rule which achieves tighter regret bound when the loss sequence is sparse and predictable. Then we explain an update rule that dynamically adapts to the curvature of the loss function and utilizes the predictable nature of the loss sequence as well. Finally we extend these results to composite losses.",
    "creator" : "LaTeX with hyperref package"
  }
}