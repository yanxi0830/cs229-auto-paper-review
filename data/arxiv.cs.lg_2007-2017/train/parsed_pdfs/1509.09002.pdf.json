{
  "name" : "1509.09002.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "Convergence of Stochastic Gradient Descent for PCA",
    "authors" : [ "Ohad Shamir" ],
    "emails" : [ "ohad.shamir@weizmann.ac.il" ],
    "sections" : [ {
      "heading" : null,
      "text" : "ar X\niv :1\n50 9.\n09 00\n2v 2\n[ cs\n.L G\n] 4\nJ an\n2 01"
    }, {
      "heading" : "1 Introduction",
      "text" : "Principal component analysis (PCA) [20, 11] is a fundamental tool in data analysis and visualization, designed to find the subspace of largest variance in a given dataset (a set of points in Euclidean space). We focus on a simple stochastic setting, where the data x1,x2, . . . ∈ Rd is assumed to be drawn i.i.d. from an unknown underlying distribution, and our goal is to find a direction of approximately maximal variance. This can be written as the optimization problem\nmin w:‖w‖=1\n−w⊤E[xx⊤]w, (1)\nor equivalently, finding an approximate leading eigenvector of the covariance matrix E[xx⊤]. The conceptually simplest method for this task, given m sampled points x1, . . . ,xm, is to construct the empirical covariance matrix 1m ∑m i=1 xix ⊤ i , and compute its leading eigenvector by an eigendecomposition. Based on concentration of measure arguments, it is not difficult to show that this would result in an O( √\n1/m)-optimal solution to Eq. (1). Unfortunately, the runtime of this method is O(md2 + d3). In large-scale applications, both m and d might be huge, and even forming the d × d covariance matrix, let alone performing an eigendecomposition, can be computationally prohibitive. A standard alternative to exact eigendecomposition is iterative methods, such as power iterations or the Lanczos method, which require performing multiple products of a vector with the empirical covariance matrix. Although this doesn’t require computing and storing the matrix explicitly, it still requires multiple passes over the data, whose number may scale with eigengap parameters of the matrix or the target accuracy [14, 16]. Recently, new randomized algorithms for this problem were able to significantly reduce the required number of passes, while maintaining the ability to compute high-accuracy solutions [25, 24, 8, 12].\nIn this work, we consider the efficacy of algorithms which perform a single pass over the data, and in particular, stochastic gradient descent (SGD). For solving Eq. (1), SGD corresponds to initializing at some unit vector w0, and then at each iteration t perform a stochastic gradient step with respect to xtx⊤t (which is an unbiased estimate of E[xx⊤]), followed by a projection to the unit sphere:\nwt := (I + ηxtx ⊤ t )wt−1 , wt := wt/‖wt‖.\nHere, η is a step size parameter. In the context of PCA, this is also known as Oja’s method [18, 19]. The algorithm is highly efficient in terms of memory and runtime per iteration, requiring storage of a single d-dimensional vector, and performing only vector-vector and a vector-scalar products in each iteration.\nIn the world of convex stochastic optimization and learning, SGD has another remarkable property: Despite it being a simple, one-pass algorithm, it is essentially (worst-case) statistically optimal, attaining the same statistical estimation error rate as exact empirical risk minimization [5, 23, 22]. Thus, it is quite natural to ask whether SGD also performs well for the PCA problem in Eq. (1), compared to statistically optimal but computationally heavier methods.\nThe study of SGD (or variants thereof) for PCA has gained interest in recent years, with some notable examples including [1, 3, 2, 15, 10, 7, 12]. While experimentally SGD appears to perform reasonably well, its theoretical analysis has proven difficult, due to the non-convex nature of the objective function in Eq. (1). Remarkably, despite this non-convexity, finite-time convergence guarantees have been obtained under an eigengap assumption – namely, that the difference between the largest and 2nd-largest eigenvalues of E[xx⊤] are separated by some fixed value λ > 0. For example, [7] require O(d/λ2ǫ) iterations to ensure with high probability that one of the iterates is ǫ-optimal. [12] require O(1/λ2 + 1/λǫ) iterations, provided we begin close enough to an optimal solution.\nNevertheless, one may ask whether the eigengap assumption is indeed necessary, if our goal is simply to find an approximately optimal solution of Eq. (1). Intuitively, if E[xx⊤] has two equal (or near equal) top eigenvalues, then we may still expect to get a solution which lies close to the subspace of these two top eigenvalues, and approximately minimizes Eq. (1), with the runtime not dependent on any eigengap. Unfortunately, existing results tell us nothing about this regime, and not just for minor technical reasons: These results are based on tracking the geometric convergence of the SGD iterates wt to a leading eigenvector of the covariance matrix. When there is no eigengap, there is also no single eigenvector to converge to, and such a geometric approach does not seem to work. Getting an eigengap-free analysis has also been posed as an open problem in [10]. We note that while there are quite a few other single-pass, eigengap-free methods for this problem, such as [28, 29, 17, 6, 9, 13], their memory and runtime-per iteration requirements are much higher than SGD, often O(d2) or worse.\nIn this work, we study the convergence of SGD for PCA, using a different technique that those employed in previous works, with the following main results:\n• We provide the first (to the best of our knowledge) SGD convergence guarantee which does not pose an eigengap assumption. Roughly speaking, we prove that if the step size is chosen appropriately, then after T iterations starting from random initialization, with positive probability, SGD returns an Õ( √\np/T )-optimal1 solution of Eq. (1), where p is a parameter depending on how the algorithm is initialized:\n– If the algorithm is initialized from a warm-start point w0 such that 1〈v,w0〉2 ≤ O(1) for some leading eigenvector v of the covariance matrix, then p = O(1).\n1Throughout, we use O, Ω to hide constants, and Õ, Ω̃ to hide constants and logarithmic factors.\n– Under uniform random initialization on the unit Euclidean sphere, p = O(d), where d is the dimension.\n– Using a more sophisticated initialization (requiring the usage of the first O(d) iterations, but no warm-start point), p = Õ(nA), where nA is the numerical rank of the covariance matrix. The numerical rank is a relaxation of the standard notion of rank, is always at most d and can be considered a constant under some mild assumptions.\n• In the scenario of a positive eigengap λ > 0, and using a similar proof technique, we prove an SGD convergence guarantee of O(p/λT ) (where p is as above) with positive probability. This guarantee is optimal in terms of dependence on T, λ, and in particular, has better dependence on λ compared to all previous works on SGD-like methods we are aware of (1/λ as opposed to 1/λ2).\nUnfortunately, a drawback of our guarantees is that they only hold with rather low probability: Ω(1/p), which can be small if p is large. Formally, this can be overcome by repeating the algorithm Õ(p) times, which ensures that with high probability, at least one of the outputs will be close to optimal. However, we suspect that these low probabilities are an artifact of our proof technique, and resolving it is left to future work."
    }, {
      "heading" : "2 Setting",
      "text" : "We use bold-faced letters to denote vectors, and capital letters to denote matrices. Given a matrix M , we let ‖M‖ denote its spectral norm, and ‖M‖F its Frobenius norm.\nWe now present the formal problem setting, in a somewhat more general way than the PCA problem considered earlier. Specifically, we study the problem of solving\nmin w∈Rd:‖w‖=1\n−w⊤Aw, (2)\nwhere d > 1 and A is a positive semidefinite matrix, given access to a stream of i.i.d. positive semidefinite matrices Ãt where E[Ãt] = A (e.g. xtx⊤t in the PCA case). Notice that the gradient of Eq. (2) at a point w equals 2Aw, with an unbiased stochastic estimate being 2Ãtw. Therefore, applying SGD to Eq. (2) reduces to the following: Initialize at some unit-norm vector w0, and for t = 1, . . . , T , perform wt = (I + ηÃt)wt−1,wt = wt/‖wt‖, returning wT . In fact, for the purpose of the analysis, it is sufficient to consider a formally equivalent algorithm, which only performs the projection to the unit sphere at the end:\n• Initialize by picking a unit norm vector w0\n• For t = 1, . . . , T , perform wt = (I + ηÃt)wt−1\n• Return wT‖wT ‖ It is easy to verify that the output of this algorithm is mathematically equivalent to the original SGD algorithm, since the stochastic gradient step amounts to multiplying wt−1 by a matrix independent of wt−1, and the projection just amounts to re-scaling. In both cases, we can write the algorithm’s output in closed form as\n(\n∏1 t=T (I + ηÃt)\n)\nw0 ∥ ∥ ∥ (\n∏1 t=T (I + ηÃt)\n)\nw0\n∥ ∥ ∥\n."
    }, {
      "heading" : "3 Convergence Without an Eigengap Assumption",
      "text" : "Our main result is the following theorem, which analyzes the performance of SGD for solving Eq. (2).\nTheorem 1. Suppose that\n• For some leading eigenvector v of A, 1〈v,w0〉2 ≤ p for some p (assumed to be ≥ 8 for simplicity).\n• For some b ≥ 1, both ‖Ãt‖‖A‖ and ‖Ãt−A‖ ‖A‖ are at most b with probability 1.\nIf we run the algorithm above for T iterations with η = 1 b √ pT (assumed to be ≤ 1), then with probability at least 1cp , the returned w satisfies\n1− w ⊤Aw ‖A‖ ≤ c\n′ log(T )b √ p√\nT ,\nwhere c, c′ are positive numerical constants.\nThe proof and an outline of its main ideas appears in Subsection 5.1 below. Note that this is a multiplicative guarantee on the suboptimality of Eq. (2), since we normalize by ‖A‖, which is the largest magnitude Eq. (2) can attain. By multiplying both sides by ‖A‖, we can convert this to an additive bound of the form\n‖A‖ −w⊤Aw ≤ c′ log(T )b ′√p√\nT ,\nwhere b′ is a bound on max { ‖Ãt‖, ‖Ãt −A‖ } . Also, note that the choice of η in the theorem is not crucial, and similar bounds (with different c, c′) can be shown for other η = Θ(1/b √ pT ).\nThe value of p in the theorem depends on how the initial point w0 is chosen. One possibility, of course, is if we can initialize the algorithm from a “warm-start” point w0 such that 1〈v,w0〉2 ≤ O(1), in which case the bound in the theorem becomes O(log(T )/ √ T ) with probability Ω(1). Such a w0 may be given by some other algorithm, or alternatively, if we are interested in analyzing SGD in the regime where it is close to one of the leading eigenvectors.\nOf course, such an assumption is not always relevant, so let us turn to consider the performance without such a “warm-start”. For example, the simplest and most common way to initialize w0 is by picking it uniformly at random from the unit sphere. In that case, for any v, 〈v,w0〉2 = Θ(1/d) with high constant probability2 , so the theorem above applies with p = O(d):\nCorollary 1. If w0 is chosen uniformly at random from the unit sphere in Rd, then Thm. 1 applies with p = O(d), and the returned w satisfies, with probability at least Ω(1/d),\n1− w ⊤Aw ‖A‖ ≤ O\n( log(T )b √ d√\nT\n)\n,\n2One way to see this is by assuming w.l.o.g. that v = e1 and noting that the distribution of w0 is the same as w/‖w‖ where w has a standard Gaussian distribution, hence 〈v,w0〉2 = w21/ ∑ j w2j , and by using standard concentration tools it can be shown that the numerator is Θ(1) and the denominator is Θ(d) with high probability.\nWhile providing some convergence guarantee, note that the probability of success is low, scaling down linearly with d. One way to formally solve this is to repeat the algorithm Ω(d) times, which ensures that with high probability, at least one output will succeed (and finding it can be done empirically by testing the outputs on a validation set). However, it turns out that by picking w0 in a smarter way, we can get a bound where the d factors are substantially improved.\nSpecifically, we consider the following method, parameterized by number of iterations T0, which are implemented before the main algorithm above:\n• Sample w from a standard Gaussian distribution on Rd\n• Let w0 = 0.\n• For t = 1, . . . , T0, let w0 := w0 + 1T0 Ãtw\n• Return w0 := w0‖w0‖ .\nEssentially, instead of initializing from a random point w, we initialize from\nÃw\n‖Ãw‖ , where Ã =\n1\nT0\nT0 ∑\nt=1\nÃt.\nSince Ã is a mean of T0 random matrices with mean A, this amounts to performing a single approximate power iteration. Recently, it was shown that a single exact power iteration can improve the starting point of stochastic methods for PCA [24]. The method above extends this idea to a purely streaming setting, where we only have access to stochastic approximations of A.\nThe improved properties of w0 with this initialization is formalized in the following lemma (where ‖A‖F denotes the Frobenius norm of A):\nLemma 1. The following holds for some numerical constants c, c′ > 0: For w0 as defined above, if T0 ≥ cdb2 log(d), then with probability at least 710 − 2d − exp(−d/8),\n1\n〈v,w0〉2 ≤ c′ log(d)nA,\nwhere nA = ‖A‖2F ‖A‖2 is the numerical rank of A.\nThe proof is provided in Subsection 5.2. Combining this with Thm. 1, we immediately get the following corollary:\nCorollary 2. If w0 is initialized as described above, then Thm. 1 applies with p = O(log(d)nA), and the returned w satisfies, with probability at least Ω(1/nA log(d)),\n1− w ⊤Aw ‖A‖ ≤ O\n(\nlog(T )b √\nlog(d)nA√ T\n)\n,\nThe improvement of Corollary 2 compared to Corollary 1 depends on how much smaller is nA, the numerical rank of A, compared to d. We argue that in most cases, nA is much smaller, and often can be thought of as a moderate constant, in which case Corollary 2 provides an Õ (\nb√ T\n)\nerror bound with\nprobability Ω̃(1), at the cost of Õ(db2) additional iterations at the beginning. Specifically:\n• nA is always in [1, d], and in particular, can never be larger than d.\n• nA is always upper bounded by the rank of A, and is small even if A is only approximately low rank. For example, if the spectrum of A has polynomial decay i−α where α > 1, then nA will be a constant independent of d. Moreover, to begin with, PCA is usually applied in situations where we hope A is close to being low rank.\n• When Ãt is of rank 1 (which is the case, for instance, in PCA, where Ãt equals the outer product of the t-th datapoint xt), we have nA ≤ b2, where we recall that b upper bounds the scaled spectral norm of Ãt. In machine learning application, the data norm is often assumed to be bounded, hence b is not too large. To see why this holds, note that for rank 1 matrices, the spectral and Frobenius norms coincide, hence\nnA = (‖A‖F ‖A‖\n)2\n=\n(\n‖E[Ã1]‖F ‖A‖\n)2\n≤ ( E [ ‖Ã1‖F ‖A‖\n])2\n=\n(\nE\n[\n‖Ã1‖ ‖A‖\n])2\n≤ b2,\nwhere we used Jensen’s inequality.\nSimilar to Corollary 1, we can also convert the bound of Corollary 2 into a high-probability bound, by repeating the algorithm Õ(nA) times."
    }, {
      "heading" : "4 Convergence under an Eigengap Assumption",
      "text" : "Although our main interest so far has been the convergence of SGD without any eigengap assumptions, we show in this section that our techniques also imply new bounds for PCA with an eigengap assumptions, which in certain aspects are stronger than what was previously known.\nSpecifically, we consider the same setting as before, but where the ratio s1−s2s1 , where s1, s2 are the leading singular values of the covariance matrix A is assumed to be strictly positive and lower bounded by some fixed λ > 0. Using this assumption and a proof largely similar to that of Thm. 1, we have the following theorem:\nTheorem 2. Under the same conditions as Thm. 1, suppose furthermore that\n• The top two eigenvalues of A have a gap λ‖A‖ > 0\n• log 2(T )b2p λT ≤\nlog(T )b √ p√\nT\nIf we run the algorithm above for T > 1 iterations with η = log(T )λT (assumed to be ≤ 1), then with probability at least 1cp , the returned w satisfies\n1− w ⊤Aw ‖A‖ ≤ c ′ log 2(T )b2p λT ,\nwhere c, c′ are positive numerical constants.\nThe proof appears in Subsection 5.3. Considering first the technical conditions of the theorem, we\nnote that assuming log 2(T )b2p λT ≤\nlog(T )b √ p√\nT simply amounts to saying that T is sufficiently large so that the\nO ( log2(T )b2p λT ) bound provided by Thm. 2 is better than the O (\nlog(T )b √ p√\nT\n)\nbound provided by Thm. 1, by\nmore than a constant. This is the interesting regime, since otherwise we might as well choose η as in Thm. 1 and get a better bound without any eigengap assumptions. Moreover, as in Thm. 1, a similar proof would hold if the step size is replaced by c log(T )/λT for some constant c ≥ 1.\nAs in Thm. 1, we note that p can be as large as d under random initialization, but this can be improved to the numerical rank of A using an approximate power iteration, or by analyzing the algorithm starting from a warm-start point w0 for which 1〈v,w0〉2 ≤ O(1) for a leading eigenvector v of A. Also, note that under an eigengap assumption, if 1 − w⊤Aw‖A‖ goes to 0 with the number of iterations T , it must hold that 〈v,w〉2 goes to 1 for a leading eigenvector of A, so the analysis with p = O(1) is also relevant for analyzing SGD for sufficiently large T , once we’re sufficiently close to the optimum.\nComparing the bound to previous bounds in the literature for SGD-like methods (which all assume an eigengap, e.g. [3, 10, 7, 12]), an interesting difference is that the dependence on the eigengap λ is only 1/λ, as opposed to 1/λ2 or worse. Intuitively, we are able to improve this dependence since we track the suboptimality directly, as opposed to tracking how wT converges to a leading eigenvector, say in terms of the Euclidean norm. This has an interesting parallel in the analysis of SGD for λ-strongly convex functions, where the suboptimality of wT decays as Õ(1/λT ), although E[‖wT − w∗‖2] can only be bounded by O(1/λ2T ) (compare for instance Lemma 1 in [21] and Theorem 1 in [26]). Quite recently, Jin et al. ([12]) proposed another streaming algorithm which does have only 1/λ dependence (at least for sufficiently large T ), and a high probability convergence rate which is even asymptotically optimal in some cases. However, their formal analysis is from a warm-start point (which implies p = O(1) in our notation), whereas the analysis here applies to any starting point. Moreover, the algorithm in [12] is different and more complex, whereas our focus here is on the simple and practical SGD algorithm. Finally, we remark that although an O(1/λT ) convergence rate is generally optimal (using any algorithm), we do not know whether the dependence on b and p in the convergence bound of Thm. 2 for SGD is optimal, or whether it can be improved."
    }, {
      "heading" : "5 Proofs",
      "text" : ""
    }, {
      "heading" : "5.1 Proof of Thm. 1",
      "text" : "To simplify things, we will assume that we work in a coordinate system where A is diagonal, A = diag(s1, . . . , sd), where s1 ≥ s2 ≥ . . . ≥ sd ≥ 0, and s1 is the eigenvalue corresponding to v. This is without loss of generality, since the algorithm and the theorem conditions are invariant to the choice of coordinate system. Moreover, since the objective function in the theorem is invariant to ‖A‖, we shall assume that ‖A‖ = s1 = 1. Under these assumptions, the theorem’s conditions reduce to:\n• 1 w20,1 ≤ p, for some p ≥ 8\n• b ≥ 1 is an upper bound on ‖Ãt‖, ‖Ãt −A‖\nLet ǫ ∈ (0, 1) be a parameter to be determined later. The proof works by lower bounding the probability of the objective function (which under the assumption ‖A‖ = 1, equals 1 − w⊤Aw) being suboptimal by at most ǫ. This can be written as\nPr\n( w ⊤ T (I −A)wT ‖wT ‖2 ≤ ǫ ) ,\nor equivalently,\nPr ( w ⊤ T ((1− ǫ)I −A)wT ≤ 0 ) .\nLetting VT = w ⊤ T ((1− ǫ)I −A)wT ,\nwe need to lower bound Pr(VT ≤ 0). In analyzing the convergence of stochastic gradient descent, a standard technique to bound such probabilities is via a martingale analysis, showing that after every iteration, the objective function decreases by a certain amount. Unfortunately, due to the non-convexity of the objective function here, the amount of decrease at iteration t critically depends on the current iterate wt, and in the worst case may even be 0 (e.g. if wt is orthogonal to the leading eigenvector, and there is no noise). Moreover, analyzing the evolution of wt is difficult, especially without eigengap assumptions, where there isn’t necessarily some fixed direction which wt converges to. Hence, we are forced to take a more circuitous route.\nIn a nutshell, the proof is composed of three parts. First, we prove that if ǫ and the step size η are\nchosen appropriately, then E[VT ] ≤ −Ω̃ ( (1 + η)2T ǫp ) . If we could also prove a concentration result, namely that VT is not much larger than its expectation, this would imply that Pr(VT ≤ 0) is indeed large. Unfortunately, we do not know how to prove such concentration. However, it turns out that it is possible to prove that VT is not much smaller than its expected value: More precisely, that VT ≥ −Õ ( (1 + η)2T ǫ ) with high probability. We then show that given such a high-probability lower bound on VT , and a bound on its expectation, we can produce an upper bound on VT which holds with probability Ω̃(1/p), hence leading to the result stated in the theorem.\nWe begin with a preliminary technical lemma:\nLemma 2. For any ǫ, η ∈ (0, 1), and integer k ≥ 0,\nmax s∈[0,1]\n(1 + ηs)k(1− ǫ− s) ≤ 1 + 2(1 + η(1 − ǫ)) k\nη(k + 1) .\nProof. The result trivially holds for k = 0, so we will assume k > 0 from now. Let\nf(s) = (1 + ηs)k(1− ǫ− s).\nDifferentiating f and setting to zero, we have\nkη(1 + ηs)k−1(1− ǫ− s)− (1 + ηs)k = 0 ⇔ kη(1− ǫ− s) = 1 + ηs\n⇔ kη(1− ǫ)− 1 kη + η = s ⇔ s = k(1 − ǫ)− 1/η k + 1 .\nLet sc = k(1−ǫ)−1/η\nk+1 denote this critical point, and consider two cases:\n• sc /∈ [0, 1]: In that case, f has no critical points in the domain, hence is maximized at one of the domain endpoints, with a value of at most\nmax{f(0), f(1)} = max{1− ǫ,−ǫ(1 + η)k} ≤ 1.\n• sc ∈ [0, 1]: In that case, we must have k(1− ǫ)− 1η ≥ 0, and the value of f at sc is (\n1 + ηk(1 − ǫ)− 1\nk + 1\n)k (\n1− ǫ− k(1− ǫ)− 1/η k + 1\n)\n=\n(\n1 + ηk(1 − ǫ)− 1\nk + 1\n)k (\n1− ǫ+ 1η k + 1\n)\n≤ (1 + η(1− ǫ))k ( 1 + 1η k + 1 )\n≤ 2 (1 + η(1 − ǫ)) k\nη(k + 1) .\nThe maximal value of f is either the value above, or the maximal value of f at the domain endpoints, which we already showed to be most 1. Overall, the maximal value f can attain is at most\nmax\n{\n1, 2 (1 + η(1− ǫ))k\nη(k + 1)\n}\n≤ 1 + 2 (1 + η(1− ǫ)) k\nη(k + 1) .\nCombining the two cases, the result follows.\nUsing this lemma, we now prove that VT = w⊤T ((1 − ǫ)I −A)wT has a large negative expected value. To explain the intuition, note that if we could have used the exact A instead of the stochastic approximations Ãt in deriving wT , then we would have\nw ⊤ T ((1 − ǫ)I −A)wT = w⊤0 (I + ηA)T ((1− ǫ)I −A)(I + ηA)Tw0\n= d ∑\nj=1\n(1 + ηsj) 2T (1− ǫ− sj)w20,j\n≤ 1 p (1 + ηs1)\n2T (1− ǫ− s1) + d ∑\nj=2\n(1 + ηsj) 2T (1− ǫ− sj)w20,j\n≤ 1 p (1 + ηs1) 2T (1− ǫ− s1) +\n\n\nd ∑\nj=2\nw20,j\n\n max s∈[0,1]\n(1 + ηs)2T (1− ǫ− s),\nwhich by the assumptions s1 = 1 and 1 = ‖w0‖2 = ∑d j=1w 2 0,j is at most\n− ǫ p (1 + η)2T + max s∈[0,1] (1 + ηs)2T (1− ǫ− s).\nApplying Lemma 2 and picking η, ǫ appropriately, it can be shown that the above is at most −Ω (\nǫ p (1 + η)\n2T )\n.\nUnfortunately, this calculation doesn’t apply in practice, since we use the stochastic approximations Ãt instead of A. However, using more involved calculations, we prove in the lemma below that the expectation is still essentially the same, provided ǫ, η are chosen appropriately.\nLemma 3. If η = 1b √ 1 pT ≤ 1 and ǫ = c\nlog(T )b √ p√\nT ≤ 1 for some sufficiently large constant c, then it holds\nthat E[VT ] ≤ − (1 + η)2T ǫ\n4p .\nProof. To simplify notation, define for all t = 1, . . . , T the matrices\nCt0 = I + ηA , C t 1 = η(Ãt −A).\nNote that Ct0 is deterministic whereas C t 1 is random and zero-mean. Moreover, ‖Ct0‖ ≤ 1+η and ‖Ct1‖ ≤ ηb.\nBy definition of the algorithm, we have the following:\nVT = w ⊤ T ((1 − ǫ)I −A)wT\n= w⊤0\n(\nT ∏\nt=1\n(\nI + ηÃt\n)\n) ((1− ǫ)I −A) ( 1 ∏\nt=T\n(\nI + ηÃt\n)\n)\nw0\n= w⊤0\n(\nT ∏\nt=1\n(\nCt0 + C t 1\n)\n) ((1− ǫ)I −A) ( 1 ∏\nt=T\n(\nCt0 + C t 1\n)\n)\nw0\n= ∑\n(i1,...,iT )∈{0,1}T\n∑\n(j1,...,jT )∈{0,1}T w\n⊤ 0\n(\nT ∏\nt=1\nCtit\n) ((1 − ǫ)I −A) ( 1 ∏\nt=T\nCtjt\n)\nw0.\nSince C11 , . . . , C T 1 are independent and zero-mean, the expectation of each summand in the expression above is non-zero only if it = jt for all t. Therefore,\nE\n[\nw ⊤ T ((1 − ǫ)I −A)wT\n]\n= ∑\n(i1,...,iT )∈{0,1}T E\n[\nw ⊤ 0\n(\nT ∏\nt=1\nCtit\n) ((1− ǫ)I −A) ( 1 ∏\nt=T\nCtit\n)\nw0\n]\n.\nWe now decompose this sum according to what is the largest value of t for which it = 1 (hence Ctit = C t 1). The intuition for this, as will be seen shortly, is that Lemma 2 allows us to attain tighter bounds on the summands when t is much smaller than T . Formally, we can rewrite the expression above as\nE\n[\nw0\n(\nT ∏\nt=1\nCt0\n) ((1− ǫ)I −A) ( 1 ∏\nt=T\nCt0\n)\nw0\n]\n+\nT−1 ∑\nk=0\n∑\n(i1,...,ik)∈{0,1}k E\n[\nw0\n(\nk ∏\nt=1\nCtit\n)\nCk+11\n(\nT ∏\nt=k+2\nCt0\n) ((1 − ǫ)I −A) ( k+2 ∏\nt=T\nCt0\n)\nCk+11\n(\n1 ∏\nt=k\nCtit\n)\nw0\n]\n.\nSince Ct0 = I+ηA is diagonal and the same for all t, and ((1−ǫ)I−A) is diagonal as well, we can simplify the above to\nw0(C 1 0 ) 2T ((1 − ǫ)I −A)w0\n+\nT−1 ∑\nk=0\n∑\n(i1,...,ik)∈{0,1}k E\n[\nw0\n(\nk ∏\nt=1\nCtit\n)\nCk+11 (C 1 0 ) 2(T−k−1)((1 − ǫ)I −A)Ck+11\n(\n1 ∏\nt=k\nCtit\n)\nw0\n]\n.\nUsing the fact that the spectral norm is sub-multiplicative, and that for any symmetric matrix B, v⊤Bv ≤ ‖v2‖λmax(B), where λmax(B) denotes the largest eigenvalue of B, we can upper bound the above by\n≤ w0(C10 )2T ((1 − ǫ)I −A)w0\n+ T−1 ∑\nk=0\n∑\n(i1,...,ik)∈{0,1}k E\n[ ‖w0‖2 ( k ∏\nt=1\n‖Ctit‖2 ) ‖Ck+11 ‖2λmax ( (C10 ) 2(T−k−1)((1 − ǫ)I −A) ) ] .\nSince ‖w0‖ = 1, and ‖Ct0‖ ≤ (1 + η), ‖Ct1‖ ≤ ηb, this is at most w0(C 1 0 ) 2T ((1− ǫ)I −A)w0\n+\nT−1 ∑\nk=0\n∑\n(i1,...,ik)∈{0,1}k\n(\n(1 + η)2(k− ∑k t=1 it)(ηb)2 ∑k t=1 it ) (ηb)2λmax ( (C10 ) 2(T−k−1)((1 − ǫ)I −A) )\n= w0(C 1 0 ) 2T ((1− ǫ)I −A)w0\n+\nT−1 ∑\nk=0\n( (1 + η)2 + (ηb)2 )k (ηb)2λmax\n(\n(C10 ) 2(T−k−1)((1− ǫ)I −A)\n)\n= w0(I + ηA) 2T ((1− ǫ)I −A)w0\n+ (ηb)2 T−1 ∑\nk=0\n( (1 + η)2 + (ηb)2 )k\nλmax\n( (I + ηA)2(T−k−1)((1− ǫ)I −A) )\n(3)\nRecalling that A = diag(s1, . . . , sd) with s1 = 1, that ‖w0‖2 = ∑d j=1w 2 0,j = 1, and that w 2 0,1 ≥ 1p , the first term in Eq. (3) equals\nw0(I + ηA) 2T ((1− ǫ)I −A)w0 =\nd ∑\nj=1\n(1 + ηsj) 2T (1− ǫ− sj)w0,j\n= (1 + η)(−ǫ)w20,1 + d ∑\nj=2\n(1 + ηsj) 2T (1− ǫ− sj)w20,j\n≤ −(1 + η)2T ǫ p + max s∈[0,1] (1 + ηs)2T (1− ǫ− s).\nApplying Lemma 2, and recalling that η ≤ 1, we can upper bound the above by\n− (1 + η)2T ǫ p + 1 + 2 (1 + η(1− ǫ))2T η(2T + 1)\n= (1 + η)2T\n\n  − ǫ p + (1 + η)−2T + 2\n(\n1+η(1−ǫ) 1+η\n)2T\nη(2T + 1)\n\n \n≤ (1 + η)2T (\n− ǫ p + (1 + η)−2T +\n( 1− 12ηǫ ) )2T\nηT\n)\n. (4)\nAs to the second term in Eq. (3), again using the fact that A = diag(s1, . . . , sd), we can upper bound it by\n(ηb)2 T−1 ∑\nk=0\n( (1 + η)2 + (ηb)2 )k\nmax s∈[0,1]\n(1 + ηs)2(T−k−1)(1− ǫ− s).\nApplying Lemma 2, and recalling that η ≤ 1, this is at most\n(ηb)2 T−1 ∑\nk=0\n( (1 + η)2 + (ηb)2 )k\n(\n1 + 2 (1 + η(1 − ǫ))2(T−k−1)\nη(2(T − k)− 1)\n)\n= (ηb)2(1 + η)2T T−1 ∑\nk=0\n(\n1 +\n(\nηb\n1 + η\n)2 )k\n\n  (1 + η)−2(T−k) + 2\n(\n1+η(1−ǫ) 1+η\n)2(T−k)\nη(2(T − k)− 1)\n\n \n≤ (ηb)2(1 + η)2T T−1 ∑\nk=0\n( 1 + (ηb)2 )k\n(\n(1 + η)−2(T−k) + 2\n( 1− 12ηǫ )2(T−k) η(2(T − k)− 1) ) .\nUpper bounding ( 1 + (ηb)2 )k by ( 1 + (ηb)2 )T , and rewriting the sum in terms of k instead of T − k, we get\n(ηb)2(1 + η)2T ( 1 + (ηb)2 )T\nT ∑\nk=1\n(\n(1 + η)−2k + 2\n( 1− 12ηǫ )2k\nη(2k − 1)\n)\n.\nSince k ≥ 1, we have 12k−1 = 2k2k−1 12k ≤ 2 12k , so the above is at most\n(ηb)2(1 + η)2T ( 1 + (ηb)2 )T\nT ∑\nk=1\n(\n(1 + η)−2k + 4\nη\n( 1− 12ηǫ )2k\n2k\n)\n≤ (ηb)2(1 + η)2T ( 1 + (ηb)2 )T\n( ∞ ∑\nk=1\n(1 + η)−2k + 4\nη\n∞ ∑\nk=1\n( 1− 12ηǫ )k\nk\n)\n= (ηb)2(1 + η)2T ( 1 + (ηb)2 )T\n(\n1 (1 + η)2 − 1 − 4 η log\n(\n1 2 ηǫ\n))\n≤ (ηb)2(1 + η)2T ( 1 + (ηb)2 )T\n(\n1\n2η +\n4 η log\n(\n2\nηǫ\n))\n= ηb2(1 + η)2T ( 1 + (ηb)2 )T\n(\n1 2 + 4 log\n(\n2\nηǫ\n))\n.\nRecalling that this is an upper bound on the second term in Eq. (3), and combining with the upper bound in Eq. (4) on the first term, we get overall a bound of\n(1 + η)2T\n(\n− ǫ p + (1 + η)−2T +\n( 1− 12ηǫ )2T\nηT + ηb2\n( 1 + (ηb)2 )T\n(\n1 2 + 4 log\n(\n2\nηǫ\n))\n)\n. (5)\nWe now argue that under suitable choices of η, ǫ, the expression above is −Ω((1+ η)2T (ǫ/p). For example, this is satisfied if η = 1\nb √ pT\n, and we pick ǫ = c log(T )b √ p√\nT for some sufficiently large constant c. Under these\nchoices, the expression inside the main parentheses above becomes\n−c log(T )b√ pT +\n(\n1 + 1\nb √ pT\n)−2T +b √ p\nT\n(\n1− c log(T ) 2T\n)2T\n+ b√ pT\n(\n1 + 1\npT\n)T (1\n2 + 4 log\n(\n2T\nc log(T )\n))\n.\nUsing the facts that (1− a/t)t ≤ exp(−a) for all positive t, a such that a/t < 1, and that c log(T )/2T < 1 by the assumption that ǫ ≤ 1, the above is at most\n− c log(T )b√ pT + b√ pT\n( p exp(−c log(T )) + exp(1/p) ( 1\n2 + 4 log\n(\n2T\nc log(T )\n)))\n+\n(\n1 + 1\nb √ pT\n)−2T\n= c log(T )b√\npT\n(\n−1 + p c log(T )T c + exp(1/p) c log(T )\n(\n1 2 + 4 log\n(\n2T\nc log(T )\n)))\n+\n(\n1 + 1\nb √ pT\n)−2T .\nNote that p, b ≥ 1 by assumption, and that we can assume T ≥ p (by the assumption that ǫ ≤ 1). Therefore, picking c sufficiently large ensures that the above is at most\nc log(T )b√\npT\n(\n−1 2\n)\n+\n(\n1 + 1\nb √ pT\n)−2T .\nThe second term is exponentially small in T , and in particular can be verified to be less than 14c log(T )b√ pT in the regime where ǫ = c log(T )b √ p√\nT is at most 1 (assuming c is large enough). Overall, we get a bound of\n−c log(T )b√ pT · 14 = − ǫ4p . Plugging this back into Eq. (5), the result follows.\nHaving proved an upper bound on E[VT ], we now turn to prove a high-probability lower bound on VT . The proof is based on relating VT to ‖wT ‖2, and then performing a rather straightforward martingale analysis of log(‖wT ‖2).\nLemma 4. Suppose that Ãt is positive semidefinite for all t, and Pr(‖Ãt‖ ≤ b) = 1. Then for any δ ∈ (0, 1), we have with probability at least 1− δ that\nVT > − exp ( ηb √ T log(1/δ) + (b2 + 3)Tη2 ) (1 + η)2T ǫ.\nProof. Since I −A is a positive semidefinite matrix, we have\nVT = w ⊤ T ((1 − ǫ)I −A)wT ≥ −ǫ‖wT ‖2.\nThus, it is sufficient to prove that\n‖wT ‖2 < exp ( ηb √ T log(1/δ) + (b2 + 3)Tη2 ) (1 + η)2T . (6)\nThe proof goes through a martingale argument. We have\nlog(‖wT ‖2) = log ( T−1 ∏\nt=0\n‖wt+1‖2 ‖wt‖2\n)\n= T−1 ∑\nt=0\nlog (‖wt+1‖2 ‖wt‖2 )\n=\nT−1 ∑\nt=0\nlog\n(\n‖(I + ηÃt)wt‖2 ‖wt‖2\n)\n=\nT−1 ∑\nt=0\nlog\n(\n1 +\n(\n‖(I + ηÃt)wt‖2 ‖wt‖2 − 1 )) .\nNote that since Ãt is positive semidefinite, we always have (1 + ηb)‖wt‖2 ≥ ‖(I + ηÃt)wt‖2 ≥ ‖wt‖2, and therefore each summand is of the form log(1+at) where at ∈ [0, ηb]. Using the identity log(1+a) ≤ a for any non-negative a, we can upper bound the above by\nT−1 ∑\nt=0\n(\n‖(I + ηÃt)wt‖2 ‖wt‖2 − 1 ) . (7)\nBased on the preceding discussion, this is a sum of random variables bounded in [0, ηb], and the expectation of the t-th summand over Ãt, conditioned on Ã1, . . . , Ãt−1, equals\nw ⊤ t E\n[\n(I + ηÃt) ⊤(I + ηÃt)\n]\nwt\n‖wt‖2 − 1\n= w\n⊤ t\n( (I + ηA)2 + η2 ( Ã⊤t Ãt −A2 )) wt\n‖wt‖2 − 1\n≤ w ⊤ t (I + ηA) 2 wt\n‖wt‖2 + η2\nw ⊤ t Ã ⊤ t Ãtwt\n‖wt‖2 − 1\n≤ ‖(I + ηA)2‖+ η2‖Ã⊤t Ãt‖ − 1 ≤ (1 + η)2 + η2‖Ãt‖2 − 1 ≤ 2η + (b2 + 1)η2.\nUsing Azuma’s inequality, it follows that with probability at least 1− δ, Eq. (7) is at most\nT ( 2η + (b2 + 1)η2 ) + ηb √ T log(1/δ).\nCombining the observations above, and the fact that log(1+ z) ≥ z− z2 for any z ≥ 0, we get that with probability at least 1− δ,\nlog(‖wT ‖2) < 2Tη + (b2 + 1)Tη2 + ηb √ T log(1/δ)\n= ηb √ T log(1/δ) + (b2 + 3)Tη2 + 2T (η − η2) ≤ ηb √ T log(1/δ) + (b2 + 3)Tη2 + 2T log(1 + η),\nand therefore ‖wT ‖2 < exp ( ηb √ T log(1/δ) + (b2 + 3)Tη2 ) (1 + η)2T ,\nwhich establishes Eq. (6) and proves the lemma.\nWe now have most of the required components to prove Thm. 1. First, we showed in Lemma 3 that if\nη = 1b\n√\n1 pT , then\nE[VT ] ≤ −(1 + η)2T ǫ\n4p . (8)\nfor ǫ = O(b log(T ) √ p/T ). Using the same step size η, Lemma 4 implies that\nPr\n( VT ≤ − exp ( √ log(1/δ)\np +\n1 + 3/b2\np\n)\n(1 + η)2T ǫ\n)\n≤ δ,\nand since we assume b ≥ 1 (hence 1 + 3/b2 ≤ 4), this implies that\nPr\n(\n− VT exp(4/p)(1 + η)2T ǫ\n≥ exp ( √ log(1/δ)\np\n))\n≤ δ. (9)\nNow, define the non-negative random variable\nRT = max\n{\n0,− VT exp(4/p)(1 + η)2T ǫ\n}\n,\nand note that by its definition, E[RT ] ≥ E [\n− VT exp(4/p)(1+η)2T ǫ\n]\nand Pr\n( RT ≥ exp ( √ log(1/δ) p )) equals\nPr\n(\n− VT exp(4/p)(1+η)2T ǫ\n≥ exp ( √\nlog(1/δ) p\n))\n. Using Eq. (8) and Eq. (9), this implies that\nE[RT ] ≥ 1\n4p exp(4/p) , Pr\n( RT ≥ exp ( √ log(1/δ)\np\n))\n≤ δ.\nTo summarize the development so far, we defined a non-negative random variable RT , which is bounded with high probability, yet its expectation is at least Ω(1/p). The following lemma shows that for a bounded non-negative random variable with “large” expectation, the probability of it being on the same order as its expectation cannot be too small:\nLemma 5. Let X be a non-negative random variable such that for some α, β ∈ [0, 1], we have E[X] ≥ α, and for any δ ∈ (0, 1],\nPr ( X ≥ exp ( β √ log(1/δ) )) ≤ δ.\nThen\nPr ( X > α\n2\n) ≥ α− exp\n(\n− 2 β2\n)\n15 .\nBefore proving the lemma, let us show to use it to prove Thm. 1. Applying it on the random variable\nRT , which satisfies the lemma conditions with α = 14p exp(4/p) , β = √ 1 p , we have\n1\n15\n(\n1\n4p exp(4/p) − exp (−2p)\n) ≤ Pr ( RT > 1\n8p exp(4/p)\n)\n= Pr\n(\nmax\n{\n0,− VT exp(4/p)(1 + η)2T ǫ\n}\n> 1\n8p exp(4/p)\n)\n= Pr\n(\n− VT exp(4/p)(1 + η)2T ǫ > 1 8p exp(4/p)\n)\n= Pr\n(\nVT ≤ − (1 + η)2T ǫ\n8p\n)\n≤ Pr (VT ≤ 0)\n1 15\n(\n1 4p exp(4/p) − exp (−2p)\n)\ncan be verified to be at least 1100p for any p ≥ 8, hence we obtained\nPr(VT ≤ 0) ≥ 1\n100p .\nAs discussed at the beginning of the proof, VT ≤ 0 implies that\nwT (I −A)wT ‖wT ‖2 ≤ ǫ,\nwhere ǫ = c log(T )b √ p√\nT is the value chosen in Lemma 3, and the theorem is established.\nAll that remains now is to prove Lemma 5. To explain the intuition, suppose that X in the lemma was actually at most 1 with probability 1, rather than just bounded with high probability. Then we would have\nα ≤ E[X] = Pr ( X ≥ α 2 ) E [ X|X ≥ α 2 ] + Pr ( X < α 2 ) E [ X|X ≤ α 2 ]\n≤ Pr ( X ≥ α 2 ) · 1 + Pr ( X < α 2 ) · α 2 = Pr (\nX ≥ α 2 ) + ( 1− Pr ( X ≥ α 2 )) α 2 ,\nwhich implies that\nα ≤ ( 1− α 2 ) Pr ( X ≥ α 2 ) + α 2 =⇒ Pr ( X ≥ α 2 ) ≥ α/2 1− α/2 ≥ α 2 .\nTherefore, X is at least one-half its expectation lower bound (α) with probability at least α/2. The proof of Lemma 5, presented below, follows the same intuition, but uses a more delicate analysis since X is actually only upper bounded with high probability.\nProof of Lemma 5. Inverting the bound in the lemma, we have that for any z ∈ [1,∞),\nPr(X ≥ z) ≤ exp(−(log(z)/β)2).\nNow, let r2 > r1 > 0, be parameters to be chosen later. We have\nE[X] =\n∫ ∞\nz=0 Pr(X > z)dz =\n∫ r1\nz=0 Pr(X > z)dz +\n∫ r2\nz=r1\nPr(X > z)dz +\n∫ ∞\nz=r2\nPr(X > z)dz\n≤ r1 + (r2 − r1) Pr(X > r1) + ∫ ∞\nz=r2\nexp(−(log(z)/β)2)dz (10)\nPerforming the variable change y = (log(z)/β)2 (which implies z = exp(β √ y) and dy = 2 √ y\nexp(β √ y)dz), we\nget ∫ ∞\nz=r2\nexp(−(log(z)/β)2)dz = ∫ ∞\ny= ( log(r2) β )2\n1\n2 √ y exp(β\n√ y − y)dy\n≤ β 2 log(r2)\n∫ ∞\ny= (\nlog(r2) β\n)2 exp(β\n√ y − y)dy.\nSuppose that we choose r2 ≥ exp(2β2). Then log(r2)2β ≥ β, which implies that for any y in the integral above, 12 √ y ≥ β, and therefore β√y − y ≤ 12y − y = −12y. As a result, we can upper bound the above by\nβ\n2 log(r2)\n∫ ∞\ny= ( log(r2) β\n)2 exp\n(\n−1 2 y\n)\ndy = β\nlog(r2) exp\n(\n− log 2(r2)\n2β2\n)\n.\nPlugging this upper bound back into Eq. (10), extracting Pr(X > r1), and using the assumption E[X] ≥ α, we get that\nPr(X > r1) ≥ α− r1 − βlog(r2) exp\n(\n− log 2(r2) 2β2\n)\nr2 − r1 .\nChoosing r1 = α/2 and r2 = exp(2) (which ensures r2 ≥ exp(2β2) as assumed earlier, since β ≤ 1), we get\nPr ( X > α\n2\n) ≥ α− β exp\n(\n− 2 β2\n)\n2 exp(2)− α .\nSince β, α ≤ 1, and 2 exp(2) < 15, this can be simplified to\nPr ( X > α\n2\n) ≥ α− exp\n( − 2β2 )\n15 ."
    }, {
      "heading" : "5.2 Proof of Lemma 1",
      "text" : "Define ∆ = ‖Ã − A‖. Also, let s1 ≥ s2 ≥ . . . ≥ sd ≥ 0 be the d eigenvalues of A, with eigenvectors v1, . . . ,vd, where we assume that v = v1. Using the facts (x+ y)2 ≤ 2x2 + 2y2 and ‖v1‖ = 1, we have\n1\n〈v1,w0〉2 = ‖Ãw‖2 〈v1, Ãw〉2 = ‖Aw + (Ã−A)w‖2 (\n〈v1, Aw〉+ 〈v1, (Ã−A)w〉 )2\n≤ 2‖Aw‖ 2 + 2‖(Ã−A)w‖2 〈v1, Aw〉2 + 2〈v1, Aw〉〈v1, (Ã−A)w〉 ≤ 2‖Aw‖ 2 + 2‖w‖2∆2 〈v1, Aw〉2 − 2|〈v1, Aw〉|‖w‖∆ ,\nwhere we implicitly assume that ∆ is sufficiently small for the denominator to be positive (eventually, we will pick T0 large enough to ensure this).\nRecall that v1, . . . ,vd forms an orthonormal basis for Rd, so w = ∑d i=1 vi〈vi,w〉. Therefore, we can write the above as\n2 (\n∑d i=1 sivi〈vi,w〉\n)2 + 2‖w‖2∆2\n(s1〈v1,w〉)2 − 2|s1〈v1,w〉|‖w‖∆ =\n2 ∑d i=1 s 2 i 〈vi,w〉2 + 2‖w‖2∆2\ns21〈v1,w〉2 − 2|s1〈v1,w〉|‖w‖∆\n≤ 2 ( ∑d i=1 s 2 i ) ( maxi〈vi,w〉2 ) + 2‖w‖2∆2\ns21〈v1,w〉2 − 2|s1〈v1,w〉|‖w‖∆ .\nTo simplify notation, since w is drawn from a standard Gaussian distribution, which is rotationally invariant, we can assume without loss of generality that (v1, . . . ,vd) = (e1, . . . , ed), the standard basis, so the above reduces to\n2 (\n∑d i=1 s 2 i\n)\nmaxi w 2 i + 2‖w‖2∆2\ns21w 2 1 − 2|s1w1|‖w‖∆\n.\nRecall that ∆ = ‖Ã − A‖, where Ã is the average of T0 independent random matrices with mean A, and spectral norm at most ‖A‖b. Using a Hoeffding matrix bound (e.g. [27]), and the fact that ‖A‖ = s1, it follows that with probability at least 1− δ,\n∆ ≤ ‖A‖b √ 8 log(d/δ)\nT0 = s1\n√\n8b2 log(d/δ)\nT0 .\nPlugging into the above, we get an upper bound of\n2 (\n∑d i=1 s 2 i\n)\nmaxi w 2 i + ‖w‖2s21 16b2 log(d/δ) T0\ns21w 2 1 − 2s21|w1|‖w‖\n√\n8b2 log(d/δ) T0\n,\nholding with probability at least 1 − δ. Dividing both numerator and denominator by s21, and recalling that nA = ‖A‖2F ‖A‖2 = ∑d i=1 s 2 i\ns21 , the above equals\n2nAmaxi w 2 i + ‖w‖2 16b2 log(d/δ) T0\nw21 − 2|w1|‖w‖ √ 8b2 log(d/δ) T0\n= 2nAmaxiw\n2 i + ‖w‖2 16b2 log(d/δ) T0\n|w1| ( |w1| − 2‖w‖ √\n8b2 log(d/δ) T0\n) . (11)\nBased on standard Gaussian concentration arguments, it holds that\nPr\n(\nw21 ≤ 1\n8\n)\n≤ 3 10 , Pr\n(\nmax i\nw2i ≥ 18 log(d) ) ≤ 1 d , Pr ( ‖w‖ ≥ √ 2d ) ≤ exp ( −d 8 ) .\n(see for instance the proof of Lemma 1 in [24], and Corollary 2.3 in [4]). Combining the above with a union bound, it holds that with probability at least 1− δ − 310 − 1d − exp(−d/8), Eq. (11) is at most\n36 log(d)nA + 32db2 log(d/δ)\nT0\n1 8\n(\n1 8 − 2\n√ 2 √\n8db2 log(d/δ) T0\n) .\nRecalling that this is an upper bound on 1〈v1,w0〉2 , picking δ = 1/d for simplicity, and slightly simplifying, we showed that with probability at least 710 − 2d − exp(−d/8),\n1\n〈v1,w0〉2 ≤\n36 log(d)nA + 64b2 log(d)\nT0\n1 8\n(\n1 8 − 8\n√ 2 √\ndb2 log(d) T0\n) .\nSince nA ≥ 1, then by picking T0 ≥ cdb2 log(d) for a sufficiently large constant c, we get that 1〈v1,w0〉2 ≤ c′ log(d)nA for a numerical constant c′, as required."
    }, {
      "heading" : "5.3 Proof of Thm. 2",
      "text" : "The proof is very similar to that of Thm. 1, using some of the same lemmas, and other lemmas having slight differences to take advantage of the eigengap assumption. Below, we focus on the differences, referring to parts of the proof of Thm. 1 where necessary.\nFirst, as in the proof of Thm. 1, we assume that we work in a coordinate system where A is diagonal, A = diag(s1, . . . , sd), where s1 ≥ s2 ≥ . . . ≥ sd ≥ 0, and s1 is the eigenvalue corresponding to v. By the eigengap assumption, we can assume that s2, . . . , sd are all at most 1 − λ for some strictly positive λ ∈ (0, 1]. Under these assumptions, the theorem’s conditions reduce to:\n• 1 w20,1 ≤ p, for some p ≥ 8\n• b ≥ 1 is an upper bound on ‖Ãt‖, ‖Ãt −A‖,\nand as in the proof of Thm. 1, it is enough to lower bound Pr(VT ≤ 0) where\nVT = w ⊤ T ((1− ǫ)I −A)wT .\nWe begin by a technical lemma, which bounds a certain quantity appearing later in the proofs:\nLemma 6. Under the conditions of Thm. 2,\nlog2(T )b2\nλ2T ≤ 1 p ≤ 1.\nProof. By the assumption log 2(T )b2p λT ≤\nlog(T )b √ p√\nT , it follows that log(T )b λ √ T ≤ 1√p , and the result follows by squaring both sides.\nWe now continue by presenting the following variant of Lemma 3:\nLemma 7. Under the conditions of Thm. 2, if we pick η = log(T )λT ≤ 1 and ǫ = c log2(T )b2p\nλT for some sufficiently large numerical constant c, then\nE[VT ] ≤ − (1 + η)2T ǫ\n4p .\nProof. By the exact same proof as in Lemma 3 (up till Eq. (3)), we have\nE[VT ] = E[w ⊤ T ((1− ǫ)I −A)wT ]\n≤ w0(I + ηA)2T ((1− ǫ)I −A)w0\n+ (ηb)2 T−1 ∑\nk=0\n( (1 + η)2 + (ηb)2 )k\nλmax\n( (I + ηA)2(T−k−1)((1− ǫ)I −A) )\n(12)\nRecalling that A = diag(s1, . . . , sd) with s1 = 1, that ‖w0‖2 = ∑d j=1w 2 0,j = 1, and that w 2 0,1 ≥ 1p , the first\nterm in Eq. (3) equals\nw0(I + ηA) 2T ((1 − ǫ)I −A)w0 =\nd ∑\nj=1\n(1 + ηsj) 2T (1− ǫ− sj)w20,j\n= (1 + η)(−ǫ)w20,1 + d ∑\nj=2\n(1 + ηsj) 2T (1− ǫ− sj)w20,j\n≤ −(1 + η)2T ǫ p + max s∈[0,1−λ] (1 + ηs)2T (1− ǫ− s) ≤ −(1 + η)2T ǫ p + (1 + η(1 − λ))2T ≤ (1 + η)2T (\n− ǫ p +\n(\n1− ηλ 1 + η\n)2T )\n≤ (1 + η)2T (\n− ǫ p +\n(\n1− ηλ 2\n)2T )\n, (13)\nwhere we used the assumption that η ≤ 1. As to the second term in Eq. (12), upper bounding it in exactly the same way as in the proof of Lemma 3 (without using the eigengap assumption), we get an upper bound of\nηb2(1 + η)2T ( 1 + (ηb)2 )T\n(\n1 2 + 4 log\n(\n2\nηǫ\n))\n.\nCombining this with Eq. (13), and plugging back to Eq. (12), we get that\nE[VT ] ≤ (1 + η)2T (\n− ǫ p +\n(\n1− ηλ 2\n)2T\n+ ηb2 ( 1 + (ηb)2 )T\n(\n1 2 + 4 log\n(\n2\nηǫ\n))\n)\n. (14)\nPicking η = log(T )λT , and ǫ = c log2(T )b2p λT for some constant c ≥ 2, the above equals\n(1+η)2T\n(\n−c log 2(T )b2\nλT +\n(\n1− log(T ) 2T\n)2T\n+ b2 log(T )\nλT\n(\n1 + b2 log2(T )\nλ2T 2\n)T ( 1\n2 + 4 log\n(\n2λ2T 2\nc log3(T )b2p\n))\n)\n.\nUsing the facts that (1 + a/t)t ≤ exp(a) for all positive t, a, that c log3(T )b2p ≥ 2, and that λ ≤ 1, the above is at most\n(1 + η)2T ( −c log 2(T )b2\nλT +\n1 T +\nb2 log(T )\nλT exp\n(\nb2 log2(T )\nλ2T\n)(\n1 2 + 4 log ( T 2 )\n))\n.\nBy Lemma 6, b 2 log2(T ) λ2T ≤ 1, so the above is at most\n(1 + η)2T ( −c log 2(T )b2\nλT +\n1 T +\nb2 log(T )\nλT exp(1)\n(\n1 2 + 8 log (T )\n))\n≤ (1 + η)2T b 2 log2(T )\nλT\n(\n−c+ λ b2 log2(T ) + exp(1)\n(\n1\n2 log(T ) + 8\n))\n.\nClearly, for large enough c, the expression in the main parenthesis above is at most −c/4, so we get an upper bound of\n−(1 + η)2T cb 2 log2(T ) 4λT = − (1 + η)2T ǫ 4p ,\nfrom which the result follows.\nRather similar to the proof of Thm. 1, we now define the non-negative random variable\nRT = max\n{\n0,− VT exp((b2 + 3)Tη2)(1 + η)2T ǫ\n}\n.\nBy Lemma 7,\nE[RT ] ≥ E [ − VT exp((b2 + 3)Tη2)(1 + η)2T ǫ ] ≥ 1 4p exp((b2 + 3)Tη2) ,\nand by Lemma 4,\nPr ( RT ≥ exp ( ηb √ T log(1/δ) )) ≤ δ.\nTherefore, applying Lemma 5 on RT , with α = 14p exp((b2+3)Tη2) (which is in [0, 1]) and with β = ηb √ T (which can be verified to be in [0, 1] by the fact that η = log(T )λT and Lemma 6), we get that\nPr\n(\nRT > 1\n8p exp((b2 + 3)Tη2)\n)\n≥ 1 15\n(\n1\n4p exp((b2 + 3)Tη2) − exp\n(\n− 2 η2b2T\n))\n. (15)\nBy definition of RT , the left hand side of this inequality is at most\n= Pr\n(\nmax\n{\n0,− VT exp((b2 + 3)Tη2)(1 + η)2T ǫ\n}\n> 1\n8p exp((b2 + 3)Tη2)\n)\n= Pr\n(\n− VT exp((b2 + 3)Tη2)(1 + η)2T ǫ > 1 8p exp((b2 + 3)Tη2)\n)\n= Pr\n(\nVT ≤ − (1 + η)2T ǫ\n8p\n)\n≤ Pr (VT ≤ 0) ,\nand the right hand side of Eq. (15) (by definition of η, the assumption b ≥ 1, and Lemma 6) equals\n1\n15\n\n\n1\n4p exp ( (b2+3) log2(T ) λ2T\n) − exp ( − 2λ 2T\nb2 log2(T )\n)\n\n\n≥ 1 15\n\n\n1\n4p exp ( 4b2 log2(T ) λ2T\n) − 1 exp ( 2 λ 2T\nb2 log2(T )\n)\n\n\n≥ 1 15\n\n\n1\n4p exp (\n4 p\n) − 1 exp (2p))\n\n ,\nwhich can be verified to be at least 1100p for any p ≥ 8. Plugging these bounds back to Eq. (15), we obtained\nPr(VT ≤ 0) ≥ 1\n100p .\nBy definition of VT , VT ≤ 0 implies that\nwT (I −A)wT ‖wT ‖2 ≤ ǫ,\nwhere ǫ = c log 2(T )b2p λT is the value chosen in Lemma 7, and the theorem is established."
    }, {
      "heading" : "Acknowledgments",
      "text" : "This research is supported in part by an FP7 Marie Curie CIG grant, the Intel ICRI-CI Institute, and Israel Science Foundation grant 425/13. We thank Ofer Zeitouni for several illuminating discussions."
    } ],
    "references" : [ {
      "title" : "Stochastic optimization for PCA and PLS",
      "author" : [ "R. Arora", "A. Cotter", "K. Livescu", "N. Srebro" ],
      "venue" : "2012 50th Annual Allerton Conference on Communication, Control, and Computing,",
      "citeRegEx" : "1",
      "shortCiteRegEx" : null,
      "year" : 2012
    }, {
      "title" : "Stochastic optimization of PCA with capped MSG",
      "author" : [ "R. Arora", "A. Cotter", "N. Srebro" ],
      "venue" : "NIPS,",
      "citeRegEx" : "2",
      "shortCiteRegEx" : null,
      "year" : 2013
    }, {
      "title" : "The fast convergence of incremental PCA",
      "author" : [ "A. Balsubramani", "S. Dasgupta", "Y. Freund" ],
      "venue" : "NIPS,",
      "citeRegEx" : "3",
      "shortCiteRegEx" : null,
      "year" : 2013
    }, {
      "title" : "Measure concentration lecture notes",
      "author" : [ "A. Barvinok" ],
      "venue" : "http://www.math.lsa.umich.edu/ ̃barvinok/total7",
      "citeRegEx" : "4",
      "shortCiteRegEx" : null,
      "year" : 2005
    }, {
      "title" : "The tradeoffs of large scale learning",
      "author" : [ "Olivier Bousquet", "Léon Bottou" ],
      "venue" : "In Advances in neural information processing systems,",
      "citeRegEx" : "5",
      "shortCiteRegEx" : "5",
      "year" : 2008
    }, {
      "title" : "Online principal components analysis",
      "author" : [ "C. Boutsidis", "D. Garber", "Z. Karnin", "E. Liberty" ],
      "venue" : "SODA,",
      "citeRegEx" : "6",
      "shortCiteRegEx" : null,
      "year" : 2015
    }, {
      "title" : "Global convergence of stochastic gradient descent for some nonconvex matrix problems",
      "author" : [ "C. De Sa", "K. Olukotun", "C. Ré" ],
      "venue" : "ICML,",
      "citeRegEx" : "7",
      "shortCiteRegEx" : null,
      "year" : 2015
    }, {
      "title" : "Fast and simple pca via convex optimization",
      "author" : [ "D. Garber", "E. Hazan" ],
      "venue" : "arXiv preprint arXiv:1509.05647,",
      "citeRegEx" : "8",
      "shortCiteRegEx" : null,
      "year" : 2015
    }, {
      "title" : "Online learning of eigenvectors",
      "author" : [ "D. Garber", "E. Hazan", "T. Ma" ],
      "venue" : "ICML,",
      "citeRegEx" : "9",
      "shortCiteRegEx" : null,
      "year" : 2015
    }, {
      "title" : "The noisy power method: A meta algorithm with applications",
      "author" : [ "M. Hardt", "E. Price" ],
      "venue" : "NIPS,",
      "citeRegEx" : "10",
      "shortCiteRegEx" : null,
      "year" : 2014
    }, {
      "title" : "Analysis of a complex of statistical variables into principal components",
      "author" : [ "H. Hotelling" ],
      "venue" : "Journal of educational psychology, 24(6):417,",
      "citeRegEx" : "11",
      "shortCiteRegEx" : null,
      "year" : 1933
    }, {
      "title" : "Robust shift-and-invert preconditioning: Faster and more sample efficient algorithms for eigenvector computation",
      "author" : [ "C. Jin", "S. Kakade", "C. Musco", "P. Netrapalli", "A. Sidford" ],
      "venue" : "arXiv preprint arXiv:1510.08896,",
      "citeRegEx" : "12",
      "shortCiteRegEx" : null,
      "year" : 2015
    }, {
      "title" : "Pca with gaussian perturbations",
      "author" : [ "W. Kotłowski", "M. Warmuth" ],
      "venue" : "arXiv preprint arXiv:1506.04855,",
      "citeRegEx" : "13",
      "shortCiteRegEx" : null,
      "year" : 2015
    }, {
      "title" : "Estimating the largest eigenvalue by the power and lanczos algorithms with a random start",
      "author" : [ "J. Kuczynski", "H. Wozniakowski" ],
      "venue" : "SIAM journal on matrix analysis and applications, 13(4):1094–1122,",
      "citeRegEx" : "14",
      "shortCiteRegEx" : null,
      "year" : 1992
    }, {
      "title" : "Memory limited, streaming PCA",
      "author" : [ "I. Mitliagkas", "C. Caramanis", "P. Jain" ],
      "venue" : "NIPS,",
      "citeRegEx" : "15",
      "shortCiteRegEx" : null,
      "year" : 2013
    }, {
      "title" : "Stronger approximate singular value decomposition via the block lanczos and power methods",
      "author" : [ "C. Musco", "C. Musco" ],
      "venue" : "arXiv preprint arXiv:1504.05477,",
      "citeRegEx" : "16",
      "shortCiteRegEx" : null,
      "year" : 2015
    }, {
      "title" : "Online pca with optimal regrets",
      "author" : [ "J. Nie", "W. Kotłowski", "M. Warmuth" ],
      "venue" : "Algorithmic Learning Theory, pages 98–112. Springer,",
      "citeRegEx" : "17",
      "shortCiteRegEx" : null,
      "year" : 2013
    }, {
      "title" : "Simplified neuron model as a principal component analyzer",
      "author" : [ "E. Oja" ],
      "venue" : "Journal of mathematical biology, 15(3):267–273,",
      "citeRegEx" : "18",
      "shortCiteRegEx" : null,
      "year" : 1982
    }, {
      "title" : "On stochastic approximation of the eigenvectors and eigenvalues of the expectation of a random matrix",
      "author" : [ "E. Oja", "J. Karhunen" ],
      "venue" : "Journal of mathematical analysis and applications, 106(1):69–84,",
      "citeRegEx" : "19",
      "shortCiteRegEx" : null,
      "year" : 1985
    }, {
      "title" : "Liii",
      "author" : [ "K. Pearson" ],
      "venue" : "on lines and planes of closest fit to systems of points in space. The London, Edinburgh, and Dublin Philosophical Magazine and Journal of Science, 2(11):559–572,",
      "citeRegEx" : "20",
      "shortCiteRegEx" : null,
      "year" : 1901
    }, {
      "title" : "Making gradient descent optimal for strongly convex stochastic optimization",
      "author" : [ "A. Rakhlin", "O. Shamir", "K. Sridharan" ],
      "venue" : "ICML,",
      "citeRegEx" : "21",
      "shortCiteRegEx" : null,
      "year" : 2012
    }, {
      "title" : "Understanding Machine Learning: From Theory to Algorithms",
      "author" : [ "S. Shalev-Shwartz", "S. Ben-David" ],
      "venue" : "Cambridge University Press,",
      "citeRegEx" : "22",
      "shortCiteRegEx" : null,
      "year" : 2014
    }, {
      "title" : "Stochastic convex optimization",
      "author" : [ "S. Shalev-Shwartz", "O. Shamir", "N. Srebro", "K. Sridharan" ],
      "venue" : "COLT,",
      "citeRegEx" : "23",
      "shortCiteRegEx" : null,
      "year" : 2009
    }, {
      "title" : "Fast stochastic algorithms for svd and pca: Convergence properties and convexity",
      "author" : [ "O. Shamir" ],
      "venue" : "arXiv preprint arXiv:1507.08788,",
      "citeRegEx" : "24",
      "shortCiteRegEx" : null,
      "year" : 2015
    }, {
      "title" : "A stochastic PCA and SVD algorithm with an exponential convergence rate",
      "author" : [ "O. Shamir" ],
      "venue" : "ICML,",
      "citeRegEx" : "25",
      "shortCiteRegEx" : null,
      "year" : 2015
    }, {
      "title" : "Stochastic gradient descent for non-smooth optimization: Convergence results and optimal averaging schemes",
      "author" : [ "O. Shamir", "T. Zhang" ],
      "venue" : "ICML,",
      "citeRegEx" : "26",
      "shortCiteRegEx" : null,
      "year" : 2013
    }, {
      "title" : "User-friendly tail bounds for sums of random matrices",
      "author" : [ "J. Tropp" ],
      "venue" : "Foundations of Computational Mathematics, 12(4):389–434,",
      "citeRegEx" : "27",
      "shortCiteRegEx" : null,
      "year" : 2012
    }, {
      "title" : "Online variance minimization",
      "author" : [ "M. Warmuth", "D. Kuzmin" ],
      "venue" : "Learning theory, pages 514–528. Springer,",
      "citeRegEx" : "28",
      "shortCiteRegEx" : null,
      "year" : 2006
    }, {
      "title" : "Randomized online pca algorithms with regret bounds that are logarithmic in the dimension",
      "author" : [ "M. Warmuth", "D. Kuzmin" ],
      "venue" : "Journal of Machine Learning Research, 9(10):2287–2320,",
      "citeRegEx" : "29",
      "shortCiteRegEx" : null,
      "year" : 2008
    } ],
    "referenceMentions" : [ {
      "referenceID" : 9,
      "context" : "This also partially resolves an open problem posed in [10].",
      "startOffset" : 54,
      "endOffset" : 58
    }, {
      "referenceID" : 19,
      "context" : "1 Introduction Principal component analysis (PCA) [20, 11] is a fundamental tool in data analysis and visualization, designed to find the subspace of largest variance in a given dataset (a set of points in Euclidean space).",
      "startOffset" : 50,
      "endOffset" : 58
    }, {
      "referenceID" : 10,
      "context" : "1 Introduction Principal component analysis (PCA) [20, 11] is a fundamental tool in data analysis and visualization, designed to find the subspace of largest variance in a given dataset (a set of points in Euclidean space).",
      "startOffset" : 50,
      "endOffset" : 58
    }, {
      "referenceID" : 13,
      "context" : "Although this doesn’t require computing and storing the matrix explicitly, it still requires multiple passes over the data, whose number may scale with eigengap parameters of the matrix or the target accuracy [14, 16].",
      "startOffset" : 209,
      "endOffset" : 217
    }, {
      "referenceID" : 15,
      "context" : "Although this doesn’t require computing and storing the matrix explicitly, it still requires multiple passes over the data, whose number may scale with eigengap parameters of the matrix or the target accuracy [14, 16].",
      "startOffset" : 209,
      "endOffset" : 217
    }, {
      "referenceID" : 24,
      "context" : "Recently, new randomized algorithms for this problem were able to significantly reduce the required number of passes, while maintaining the ability to compute high-accuracy solutions [25, 24, 8, 12].",
      "startOffset" : 183,
      "endOffset" : 198
    }, {
      "referenceID" : 23,
      "context" : "Recently, new randomized algorithms for this problem were able to significantly reduce the required number of passes, while maintaining the ability to compute high-accuracy solutions [25, 24, 8, 12].",
      "startOffset" : 183,
      "endOffset" : 198
    }, {
      "referenceID" : 7,
      "context" : "Recently, new randomized algorithms for this problem were able to significantly reduce the required number of passes, while maintaining the ability to compute high-accuracy solutions [25, 24, 8, 12].",
      "startOffset" : 183,
      "endOffset" : 198
    }, {
      "referenceID" : 11,
      "context" : "Recently, new randomized algorithms for this problem were able to significantly reduce the required number of passes, while maintaining the ability to compute high-accuracy solutions [25, 24, 8, 12].",
      "startOffset" : 183,
      "endOffset" : 198
    }, {
      "referenceID" : 17,
      "context" : "In the context of PCA, this is also known as Oja’s method [18, 19].",
      "startOffset" : 58,
      "endOffset" : 66
    }, {
      "referenceID" : 18,
      "context" : "In the context of PCA, this is also known as Oja’s method [18, 19].",
      "startOffset" : 58,
      "endOffset" : 66
    }, {
      "referenceID" : 4,
      "context" : "In the world of convex stochastic optimization and learning, SGD has another remarkable property: Despite it being a simple, one-pass algorithm, it is essentially (worst-case) statistically optimal, attaining the same statistical estimation error rate as exact empirical risk minimization [5, 23, 22].",
      "startOffset" : 289,
      "endOffset" : 300
    }, {
      "referenceID" : 22,
      "context" : "In the world of convex stochastic optimization and learning, SGD has another remarkable property: Despite it being a simple, one-pass algorithm, it is essentially (worst-case) statistically optimal, attaining the same statistical estimation error rate as exact empirical risk minimization [5, 23, 22].",
      "startOffset" : 289,
      "endOffset" : 300
    }, {
      "referenceID" : 21,
      "context" : "In the world of convex stochastic optimization and learning, SGD has another remarkable property: Despite it being a simple, one-pass algorithm, it is essentially (worst-case) statistically optimal, attaining the same statistical estimation error rate as exact empirical risk minimization [5, 23, 22].",
      "startOffset" : 289,
      "endOffset" : 300
    }, {
      "referenceID" : 0,
      "context" : "The study of SGD (or variants thereof) for PCA has gained interest in recent years, with some notable examples including [1, 3, 2, 15, 10, 7, 12].",
      "startOffset" : 121,
      "endOffset" : 145
    }, {
      "referenceID" : 2,
      "context" : "The study of SGD (or variants thereof) for PCA has gained interest in recent years, with some notable examples including [1, 3, 2, 15, 10, 7, 12].",
      "startOffset" : 121,
      "endOffset" : 145
    }, {
      "referenceID" : 1,
      "context" : "The study of SGD (or variants thereof) for PCA has gained interest in recent years, with some notable examples including [1, 3, 2, 15, 10, 7, 12].",
      "startOffset" : 121,
      "endOffset" : 145
    }, {
      "referenceID" : 14,
      "context" : "The study of SGD (or variants thereof) for PCA has gained interest in recent years, with some notable examples including [1, 3, 2, 15, 10, 7, 12].",
      "startOffset" : 121,
      "endOffset" : 145
    }, {
      "referenceID" : 9,
      "context" : "The study of SGD (or variants thereof) for PCA has gained interest in recent years, with some notable examples including [1, 3, 2, 15, 10, 7, 12].",
      "startOffset" : 121,
      "endOffset" : 145
    }, {
      "referenceID" : 6,
      "context" : "The study of SGD (or variants thereof) for PCA has gained interest in recent years, with some notable examples including [1, 3, 2, 15, 10, 7, 12].",
      "startOffset" : 121,
      "endOffset" : 145
    }, {
      "referenceID" : 11,
      "context" : "The study of SGD (or variants thereof) for PCA has gained interest in recent years, with some notable examples including [1, 3, 2, 15, 10, 7, 12].",
      "startOffset" : 121,
      "endOffset" : 145
    }, {
      "referenceID" : 6,
      "context" : "For example, [7] require O(d/λ2ǫ) iterations to ensure with high probability that one of the iterates is ǫ-optimal.",
      "startOffset" : 13,
      "endOffset" : 16
    }, {
      "referenceID" : 11,
      "context" : "[12] require O(1/λ2 + 1/λǫ) iterations, provided we begin close enough to an optimal solution.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 9,
      "context" : "Getting an eigengap-free analysis has also been posed as an open problem in [10].",
      "startOffset" : 76,
      "endOffset" : 80
    }, {
      "referenceID" : 27,
      "context" : "We note that while there are quite a few other single-pass, eigengap-free methods for this problem, such as [28, 29, 17, 6, 9, 13], their memory and runtime-per iteration requirements are much higher than SGD, often O(d2) or worse.",
      "startOffset" : 108,
      "endOffset" : 130
    }, {
      "referenceID" : 28,
      "context" : "We note that while there are quite a few other single-pass, eigengap-free methods for this problem, such as [28, 29, 17, 6, 9, 13], their memory and runtime-per iteration requirements are much higher than SGD, often O(d2) or worse.",
      "startOffset" : 108,
      "endOffset" : 130
    }, {
      "referenceID" : 16,
      "context" : "We note that while there are quite a few other single-pass, eigengap-free methods for this problem, such as [28, 29, 17, 6, 9, 13], their memory and runtime-per iteration requirements are much higher than SGD, often O(d2) or worse.",
      "startOffset" : 108,
      "endOffset" : 130
    }, {
      "referenceID" : 5,
      "context" : "We note that while there are quite a few other single-pass, eigengap-free methods for this problem, such as [28, 29, 17, 6, 9, 13], their memory and runtime-per iteration requirements are much higher than SGD, often O(d2) or worse.",
      "startOffset" : 108,
      "endOffset" : 130
    }, {
      "referenceID" : 8,
      "context" : "We note that while there are quite a few other single-pass, eigengap-free methods for this problem, such as [28, 29, 17, 6, 9, 13], their memory and runtime-per iteration requirements are much higher than SGD, often O(d2) or worse.",
      "startOffset" : 108,
      "endOffset" : 130
    }, {
      "referenceID" : 12,
      "context" : "We note that while there are quite a few other single-pass, eigengap-free methods for this problem, such as [28, 29, 17, 6, 9, 13], their memory and runtime-per iteration requirements are much higher than SGD, often O(d2) or worse.",
      "startOffset" : 108,
      "endOffset" : 130
    }, {
      "referenceID" : 23,
      "context" : "Recently, it was shown that a single exact power iteration can improve the starting point of stochastic methods for PCA [24].",
      "startOffset" : 120,
      "endOffset" : 124
    }, {
      "referenceID" : 2,
      "context" : "[3, 10, 7, 12]), an interesting difference is that the dependence on the eigengap λ is only 1/λ, as opposed to 1/λ2 or worse.",
      "startOffset" : 0,
      "endOffset" : 14
    }, {
      "referenceID" : 9,
      "context" : "[3, 10, 7, 12]), an interesting difference is that the dependence on the eigengap λ is only 1/λ, as opposed to 1/λ2 or worse.",
      "startOffset" : 0,
      "endOffset" : 14
    }, {
      "referenceID" : 6,
      "context" : "[3, 10, 7, 12]), an interesting difference is that the dependence on the eigengap λ is only 1/λ, as opposed to 1/λ2 or worse.",
      "startOffset" : 0,
      "endOffset" : 14
    }, {
      "referenceID" : 11,
      "context" : "[3, 10, 7, 12]), an interesting difference is that the dependence on the eigengap λ is only 1/λ, as opposed to 1/λ2 or worse.",
      "startOffset" : 0,
      "endOffset" : 14
    }, {
      "referenceID" : 20,
      "context" : "This has an interesting parallel in the analysis of SGD for λ-strongly convex functions, where the suboptimality of wT decays as Õ(1/λT ), although E[‖wT − w∗‖2] can only be bounded by O(1/λ2T ) (compare for instance Lemma 1 in [21] and Theorem 1 in [26]).",
      "startOffset" : 228,
      "endOffset" : 232
    }, {
      "referenceID" : 25,
      "context" : "This has an interesting parallel in the analysis of SGD for λ-strongly convex functions, where the suboptimality of wT decays as Õ(1/λT ), although E[‖wT − w∗‖2] can only be bounded by O(1/λ2T ) (compare for instance Lemma 1 in [21] and Theorem 1 in [26]).",
      "startOffset" : 250,
      "endOffset" : 254
    }, {
      "referenceID" : 11,
      "context" : "([12]) proposed another streaming algorithm which does have only 1/λ dependence (at least for sufficiently large T ), and a high probability convergence rate which is even asymptotically optimal in some cases.",
      "startOffset" : 1,
      "endOffset" : 5
    }, {
      "referenceID" : 11,
      "context" : "Moreover, the algorithm in [12] is different and more complex, whereas our focus here is on the simple and practical SGD algorithm.",
      "startOffset" : 27,
      "endOffset" : 31
    }, {
      "referenceID" : 0,
      "context" : "For any ǫ, η ∈ (0, 1), and integer k ≥ 0, max s∈[0,1] (1 + ηs)(1− ǫ− s) ≤ 1 + 2 + η(1 − ǫ)) k η(k + 1) .",
      "startOffset" : 48,
      "endOffset" : 53
    }, {
      "referenceID" : 0,
      "context" : "Let sc = k(1−ǫ)−1/η k+1 denote this critical point, and consider two cases: • sc / ∈ [0, 1]: In that case, f has no critical points in the domain, hence is maximized at one of the domain endpoints, with a value of at most max{f(0), f(1)} = max{1− ǫ,−ǫ(1 + η)} ≤ 1.",
      "startOffset" : 85,
      "endOffset" : 91
    }, {
      "referenceID" : 0,
      "context" : "• sc ∈ [0, 1]: In that case, we must have k(1− ǫ)− 1 η ≥ 0, and the value of f at sc is",
      "startOffset" : 7,
      "endOffset" : 13
    }, {
      "referenceID" : 0,
      "context" : " max s∈[0,1] (1 + ηs) (1− ǫ− s), which by the assumptions s1 = 1 and 1 = ‖w0‖ = ∑d j=1w 2 0,j is at most − ǫ p (1 + η) + max s∈[0,1] (1 + ηs) (1− ǫ− s).",
      "startOffset" : 8,
      "endOffset" : 13
    }, {
      "referenceID" : 0,
      "context" : " max s∈[0,1] (1 + ηs) (1− ǫ− s), which by the assumptions s1 = 1 and 1 = ‖w0‖ = ∑d j=1w 2 0,j is at most − ǫ p (1 + η) + max s∈[0,1] (1 + ηs) (1− ǫ− s).",
      "startOffset" : 128,
      "endOffset" : 133
    }, {
      "referenceID" : 0,
      "context" : "j=2 (1 + ηsj) 2T (1− ǫ− sj)w 0,j ≤ −(1 + η) ǫ p + max s∈[0,1] (1 + ηs) (1− ǫ− s).",
      "startOffset" : 56,
      "endOffset" : 61
    }, {
      "referenceID" : 0,
      "context" : "k=0 ( (1 + η) + (ηb) k max s∈[0,1] (1 + ηs)2(T−k−1)(1− ǫ− s).",
      "startOffset" : 29,
      "endOffset" : 34
    }, {
      "referenceID" : 0,
      "context" : "Let X be a non-negative random variable such that for some α, β ∈ [0, 1], we have E[X] ≥ α, and for any δ ∈ (0, 1], Pr (",
      "startOffset" : 66,
      "endOffset" : 72
    }, {
      "referenceID" : 26,
      "context" : "[27]), and the fact that ‖A‖ = s1, it follows that with probability at least 1− δ, ∆ ≤ ‖A‖b √",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 23,
      "context" : "(see for instance the proof of Lemma 1 in [24], and Corollary 2.",
      "startOffset" : 42,
      "endOffset" : 46
    }, {
      "referenceID" : 3,
      "context" : "3 in [4]).",
      "startOffset" : 5,
      "endOffset" : 8
    }, {
      "referenceID" : 0,
      "context" : "Therefore, applying Lemma 5 on RT , with α = 1 4p exp((b2+3)Tη2) (which is in [0, 1]) and with β = ηb √ T (which can be verified to be in [0, 1] by the fact that η = log(T ) λT and Lemma 6), we get that Pr (",
      "startOffset" : 78,
      "endOffset" : 84
    }, {
      "referenceID" : 0,
      "context" : "Therefore, applying Lemma 5 on RT , with α = 1 4p exp((b2+3)Tη2) (which is in [0, 1]) and with β = ηb √ T (which can be verified to be in [0, 1] by the fact that η = log(T ) λT and Lemma 6), we get that Pr (",
      "startOffset" : 138,
      "endOffset" : 144
    } ],
    "year" : 2016,
    "abstractText" : "We consider the problem of principal component analysis (PCA) in a streaming stochastic setting, where our goal is to find a direction of approximate maximal variance, based on a stream of i.i.d. data points in R. A simple and computationally cheap algorithm for this is stochastic gradient descent (SGD), which incrementally updates its estimate based on each new data point. However, due to the non-convex nature of the problem, analyzing its performance has been a challenge. In particular, existing guarantees rely on a non-trivial eigengap assumption on the covariance matrix, which is intuitively unnecessary. In this paper, we provide (to the best of our knowledge) the first eigengap-free convergence guarantees for SGD in the context of PCA. This also partially resolves an open problem posed in [10]. Moreover, under an eigengap assumption, we show that the same techniques lead to new SGD convergence guarantees with better dependence on the eigengap.",
    "creator" : "LaTeX with hyperref package"
  }
}