{
  "name" : "1701.04271.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "Fast Rates for Empirical Risk Minimization of Strict Saddle Problems",
    "authors" : [ "Alon Gonen", "S. Shalev-Shwartz", "GONEN SHALEV-SHWARTZ" ],
    "emails" : [ "ALONGNN@CS.HUJI.AC.IL", "SHAIS@CS.HUJI.AC.IL" ],
    "sections" : [ {
      "heading" : null,
      "text" : "ar X\niv :1\n70 1.\n04 27\n1v 4\n[ cs\n.L G\n] 4\nJ un\n2 01\nminimizing non-convex risks that admit the strict saddle property. Recent progress in non-convex optimization has yielded efficient algorithms for minimizing such functions. Our results imply that these efficient algorithms are statistically stable and also generalize well. In particular, we derive fast rates which resemble the bounds that are often attained in the strongly convex setting. We specify our bounds to Principal Component Analysis and Independent Component Analysis. Our results and techniquesmay pave the way for statistical analyses of additional strict saddle problems."
    }, {
      "heading" : "1. Introduction",
      "text" : "Stability analysis is a central tool in statistical learning theory (Bousquet and Elisseeff (2002)). Roughly speaking, a learning algorithm is stable if a slight change in the input of the algorithm does not change its output much. It was shown (Shalev-Shwartz et al. (2010); Mukherjee et al. (2006)) that stability characterizes learnability, and in particular, stability is equivalent to the estimation error of empirical risk minimization.\nStability analysis has been mostly carried out in the context of convex risk minimization. More concretely, some form of strong convexity is often assumed (e.g., exp-concavity in Koren and Levy (2015); Gonen and Shalev-Shwartz (2016)). The crux of the technique is to show that minima of two similar strongly convex (and Lipschitz/smooth) functions must be close ((Shalev-Shwartz and Ben-David, 2014, Section 13.3)).\nIn this paper we address the non-convex setting while restricting our attention to recently studied “nice” non-convex problems. Namely, we will consider non-convex functions which satisfy the strict saddle property (a.k.a. ridable or X -functions, see Sun et al. (2015)). Roughly speaking, a strict saddle function has no spurious local minimum and its saddle points are strict, in the sense that second-order information suffices for identifying a descent direction. We also assume that the restriction of the function to a certain neighborhood of each of its minima is strongly convex.\nMany important non-convex problems such as Principal Component Analysis (PCA), complete\ndictionary recovery (Sun et al. (2015)), tensor decomposition, ICA (Ge et al. (2015), Anandkumar et al. (2016)) and matrix completion (Ge et al. (2016); Bhojanapalli et al. (2016)) are strict-saddle. Furthermore, there exist efficient empirical risk minimizers (ERM) for these problems (e.g., SGD and Cubic Regularization, see Section 9)."
    }, {
      "heading" : "2. Our contribution",
      "text" : "We consider the problem of minimizing a risk of the form\nF (w) = Ez∼D[f(w, z)] (1)\nc© 2017 A. Gonen & S. Shalev-Shwartz.\nwhere for every z ∈ Z , f(·, z) is a twice continuously differentiable loss function defined over the closed set W ⊆ Rd. Given an i.i.d. sample S = (z1, . . . , zd) ∼ Dn, the output of an ERM algorithm is1\nŵ ∈ argmin w∈W\n{\nF̂ (w) = 1\nn\nn∑\ni=1\nfzi(w)\n}\n, (2)\nThe sample complexity of ERM is the minimal size of a sample S for whichE[F (ŵ)]−minw∈W F (w⋆) ≤ ǫ.2 We make the following assumptions on the loss functions:\n(A1) For each z, f(·, z) is ρ-Lipschitz. (A2) For each z, f(·, z) is twice continuously differentiable and\n(∀w ∈ W) (∀i ∈ [d]) |λi(∇2f(w, z))| ≤ β1 .\n(A3) For each z, the Hessian of f(·, z) is β2-Lipschitz.\nWhile for each example of strict saddle objective listed above one may construct a dedicated sample complexity analysis, the goal of this paper is to provide a systematic unified approach, which emphasizes the geometric structure of the objective.\nWe distinguish between two cases. First, we consider the case where the empirical risk is strict saddle (with high probability) and prove stability and sample complexity bounds that depend solely on the strict saddle parameters of the empirical risk and the Lipschitz constants. In particular, the bound is dimensionality independent.\nTheorem 1 Let ǫ ∈ (0, 1). Suppose that that the empirical risk is (α, γ, τ)-strict saddle with high probability (see Section 3.2). Then the sample complexity of every ERM hypothesis is at most max {\nβ1 γ , ρ τ , 2ρ2 αǫ\n}\n.\nIn some applications it may be easier to prove that F itself is strict saddle. Under the additional assumption that W is bounded, we are able to prove the next theorem.\nTheorem 2 Suppose that F (Equation (1)) is (α, γ, τ)-strict saddle. The sample complexity is at most Õ ( d (\nρ τ2 + β1 γ2 + β1αǫ\n))\n.3\nRemark 3 The proof of this theorem actually reveals something stronger. Suppose we do not require all local minima of F to be optimally global and consider the family of empirical risk local minimizers. The same upper bound on the number of samples stated in Theorem 2 also suffices for ensuring that the value, F (ŵ), associated with the output of any such algorithm is ǫ-close to the value of some local minimum of F .\nWe note that our bounds scale with 1/ǫ. In the literature, such bounds are often referred to as fast rates, because standard concentration bounds typically scale with 1/ǫ2 (e.g., standard VCdimension bounds in the agnostic setting ((Shalev-Shwartz and Ben-David, 2014, Theorem 6.8)).\n1. We always assume the existence of a minima. 2. Alternatively, given ǫ and δ ∈ (0, 1), we ask for the minimal size of a sample S for which F (ŵ)−minw∈W F (w ⋆) ≤\nǫ with probability at least 1− δ.\n3. The Õ notation hides polylogarithmic dependencies."
    }, {
      "heading" : "2.1. Applications",
      "text" : ""
    }, {
      "heading" : "2.1.1. PCA",
      "text" : "In Section 6 we apply Theorem 1 to a stochastic formulation of Principal Component Analysis (PCA). Our goal is to approximately recover the leading eigenvector of the correlation matrix E[xx⊤], where x is drawn according to some unknown distribution D with bounded support. The standard measure of success is given by the non-convex objective min‖w‖=1−w⊤E[xx⊤]w. It is known that the sample complexity of ERM for this problem is Ω(1/ǫ2) (Blanchard et al. (2007); Gonen et al. (2016)).\nBetter bounds can be achieved under eigengap assumptions: there exists a gap, denoted G1,2, between the two leading eigenvalues of E[xx⊤]. We can use the matrix Bernstein inequality to show that given an i.i.d. sample of size n = Ω(log(d/δ)/G21,2), with probability at least 1 − δ, a gap of the same order also appears in the empirical correlation matrix. We then show that if such a gap exists, then the empirical risk is strict-saddle, where the parameters are inversely proportional to G1,2. This allows us to deduce a bound of order 1/(n ·G1,2) on the stability and the generalization error. We summarize the above in the next theorem.\nTheorem 4 The sample complexity of PCA is Õ\n(\n1 G2 1,2 + 1ǫ·G1,2\n)\n.\nThis bound is superior to the general Õ(1/ǫ2) bound if ǫ = o(G1,2). One can claim that establishing the strict-saddle parameters of the empirical risk already requires statistical tools which usually already yield generalization bounds. Indeed, in the above example, one can use the matrix Bernstein inequality to show that Õ(1/ǫ22) examples suffice in order to ensure that the expected distance between the true correlation matrix and the empirical correlation matrix (in operator norm) is at most ǫ. It is then straightforward to establish the standard 1/ǫ2 bound on the generalization error. However, here we rely on Bernstein inequality only in order to ensure that the gap in E[xx⊤] appears also in the empirical correlation matrix. Consequently, we are able to prove a better bound (in a wide regime)."
    }, {
      "heading" : "2.1.2. ICA",
      "text" : "In Section 6 we apply Theorem 2 to a stochastic formulation of Independent Component Analysis (ICA). Let A be an orthonormal linear transformation. Suppose that x is uniform on {±1}d and let y = Ax. Our goal is to recover the matrix A using the observations y. As was shown in Ge et al. (2015), this problem can be reduced to tensor decomposition. Moreover, the latter can be formulated as a strict saddle objective of the form (1), which can be efficiently minimized using SGD. Theorem 5 The sample complexity of ICA as formulated above is Õ ( poly(d) + d 5/2\nǫ\n)\n.\nThis result is meaningful in the regime where d is small and we are interested in a high accuracy solution."
    }, {
      "heading" : "2.2. Our approach",
      "text" : "As we discussed above, most of the literature on stability analysis presumes some notion of strong convexity. Strict saddle objectives resemble strongly convex functions in the following sense: it is provided that the restriction of the objective to a small neighborhood around any local minimum is\nstrongly convex. However, there are several major differences. First, as opposed to strongly convex functions, there may exists several minima. More importantly, there are regions of the domain where the function is non-convex.\nOur analysis essentially reduces to the strongly convex setting by excluding the other scenarios listed in Definition 8. Namely, we provide bounds on how many examples are needed in order to ensure that a minimizer corresponding to a slight change in the input must be in a strongly convex region around a local minimum w⋆. There is one more subtlety we need to tackle; we are not guaranteed that the minimizer of the (unmodified) empirical risk coincides with w⋆. However, as we shall see, since we deal with average stability and since all local minima are global, we may assume that this is the case w.l.o.g."
    }, {
      "heading" : "3. Preliminaries",
      "text" : ""
    }, {
      "heading" : "3.1. Stability and generalization error",
      "text" : "Definition 6 Let (z1, . . . , zn) ∼ Dn and let ŵ be an ERM (see Equation (2)). For every i ∈ [n], let ŵi ∈ argminw 1n−1 ∑\nj 6=i fj(w) and let ∆i = fi(ŵi)− fi(ŵ).4 We say that the ERM algorithm is on average stable with stability rate ǫstab : N → R>0 if\n∆ := E\n[\n1\nn\nn∑\ni=1\n∆i\n]\n≤ ǫstab(n) .\nHere and in the sequel, the expectation is taken both over the randomness of the algorithm and the draw of (z1, . . . , zn).\nFor (z1, . . . , zn) ∼ Dn, we define the generalization error of ERM by ǫgen(n) = E[F̂ (ŵ)− F (ŵ)]. The next lemma relates the stability rate to the generalization error (see (Shalev-Shwartz and Ben-David, 2014, Theorem 13.2)).\nLemma 7 For every n,\nES∼Dn−1 [L(ŵ)− L(w⋆)] ≤ ES∼Dn [∆(S)]\nTherefore, for every n, ǫgen(n) = ǫstab(n)."
    }, {
      "heading" : "3.2. Strict saddle functions",
      "text" : "Due to their similarity to local extrema, saddle points raise a fundamental challenge to optimization algorithms. Intuitively, the easier saddle points are those for which second-order inrormation reveals a clear descent direction. The following definition due to Sun et al. (2015); Ge et al. (2015) captures this idea.\nDefinition 8 A twice continuously differentiable function F̂ : Rd → R is called (α, γ, τ)-strict saddle, if it has no spurious local minimum, and for any point x ∈ Rd at least one of the following conditions holds:\n1. ‖∇F̂ (w))‖ ≥ τ 4. We do not assume uniqueness. The definition applies to any arbitrary rule for picking minimizers.\n2. λmin(∇2F̂ (w)) ≤ −γ\n3. There exists ν > 0 and a local minimum w⋆ with ‖w − w⋆‖ ≤ ν, such that the restriction of F̂ to 2ν-neighborhood of w⋆ is α-strongly convex.5\nRemark 9 The requirement that every local minimum is globally optimal can be relaxed. Namely, for a desired accuracy ǫ > 0, we may require that every local minimum is ǫ/2-optimal. Extending our analysis to handle this case is straightforward.\nWhile Ge et al. (2015); Sun et al. (2015) also require a lower bound on the magnitude of ν (which appears in the last condition), it turns out that this quantity does not play any role in our analysis."
    }, {
      "heading" : "4. Stability Bounds for Strict Saddle Empirical Risks: Unconstrained Setting",
      "text" : "In this section we consider the unconstrained setting (i.e., W = Rd). Our main result (Theorem 1) follows from the following theorem.\nTheorem 10 Let δ ∈ (0, 1). Suppose that that the empirical risk F̂ is (α, γ, τ)-strict saddle (Definition 8) with probability at least 1 − δ. If n > max { ρ τ , β1 γ } , then with probability at least 1− δ, the expected generalization error and stability rate of ERM are bounded by\nǫgen(n) = ǫstab(n) ≤ 2ρ2\nαn .\nThe proof reduces to the strongly convex case by bounding the number of examples that are needed in order to exclude the first two scenarios listed in Definition 8. Throughout the rest of this section we assume that F̂ is (α, γ, τ)-strict saddle.\nLemma 11 Let n > ρ/τ and (z1, . . . , zn) ∈ Zn. Then for any i ∈ [n], ‖∇F̂ (ŵi)‖ ≤ τ .\nProof Since ŵi minimizes 1 n\n∑\nj 6=i fj(w), we have that\nĝ−i := 1\nn\n∑\nj 6=i\n∇fj(ŵi) = 0 .\nTherefore, using the triangle inequality and the Lipschitzness of each fi, we obtain\n‖∇F̂ (ŵi)‖ ≤ ‖ĝ−i‖+ 1\nn ‖∇fi(ŵi)‖ ≤ 0 + ρ/n < τ .\nThe proof of the next lemma has the same flavor.\nLemma 12 Let n > β1/γ and (z1, . . . , zn) ∈ Zn. Then for any i ∈ [n], λmin(∇2F̂ (ŵi)) > −γ. 5. That is, for all w in this neighborhood, ∇2F (w) αI\nProof By second-order conditions, Ĥ−i := 1 n\n∑\nj 6=i∇2fj(ŵi) is positive semidefinite. Therefore, for all nonzero v ∈ Rd\nv⊤∇2F̂ (ŵi)v v⊤v = v⊤Ĥ−iv v⊤v + 1 n v⊤∇2fi(ŵi)v v⊤v ≥ 0− β1/n > −γ .\nIt follows that for n > max{ρ/τ, β1/γ}, we only need to consider the third scenario listed in Definition 8.\nLemma 13 For n > max{ρ/τ, β1/γ}. Then,\nǫgen(n) = ǫstab(n) = 2ρ2\nαn .\nProof Let (z1, . . . , zn) ∈ Zn for n > max{ρ/τ, β1/γ} and fix some i ∈ [n]. According to the previous two lemmas, ŵi lies in a neighborhood around a local minimum w̄ such that the restriction of F̂ to this neighborhood is strongly convex. The crucial part is that since all the local minima are global, for the sake of upper bounding the stability we may assume w.l.o.g. that ŵ = w̄. Indeed, the stability looks at the empirical risk of ŵ, which is equal to the empirical risk of w̄ (here we can also allow an approximation error of order ǫ, see Remark 9). From here the proof follows along the lines of the standard proof in the Lipschitz and strongly convex case (e.g., see (Gonen and Shalev-Shwartz, 2016, Lemma 3)). We provide the details for completeness.\nFix some i ∈ [n]. By elementary properties of strongly convex functions, we have\nF̂ (ŵi)− F̂ (ŵ) ≥ α\n2 ‖ŵi − ŵ‖2\nOn the other hand, since ŵi minimizes the loss w ∈ W 7→ 1n ∑ j 6=i fj(w), the suboptimality of ŵi w.r.t. the objective F̂ is controlled by its suboptimality w.r.t. fi, i.e.\nF̂ (ŵi)− F̂ (ŵ) ≤ 1\nn ∆i\nUsing Lipschitzness of fi, we have ∆i ≤ ρ‖ŵi − ŵ‖\nCombining the above, we obtain\n∆2i ≤ ρ2‖ŵi − ŵ‖2 ≤ 2ρ2\nα (F̂ (ŵi)− F̂ (ŵ)) ≤\n2ρ2 αn ∆i\nDividing by∆i (we can assume w.l.o.g. that ∆i > 0) we conclude the proof.\nThis concludes the proof of Theorem 10."
    }, {
      "heading" : "5. Stability Bounds for Strict Saddle Empirical Risks: Constrained Setting",
      "text" : "We now consider the case where W is described using equality constraints:\nW = {w ∈ Rd : ci(w) = 0, i = 1, . . . ,m} ,\nwhere for each i, ci(w) is twice continuously differentiable."
    }, {
      "heading" : "5.1. First and second-order conditions",
      "text" : "In this part we recall basic facts on first and second-order conditions in the constrained setting (see for example Borwein and Lewis (2010)). We introduce the Lagrangian L̂ : Rd × Rm → R:\nL̂(w, λ) = F̂ (w) +\nm∑\ni=1\nλici(w) .\nWe call a vector λ ∈ Rm a Lagrange multiplier for w ∈ W if w is a critical point of L̂(·, λ). A vector w ∈ W satisfies the linear independence constraint qualification (LICQ) condition if the set {∇ci(w) : i ∈ [m]} is linearly independent. Theorem 14 (KKT conditions) If w ∈ W is a local minimum of F̂ and LICQ holds at w, then there exists a Lagrange multiplier λ for w.\nNote that λ can be found analytically using\nλ(w) = −(C(w))†∇F̂ (w) ,\nwhere C is the matrix whose columns are ∇c1(w), . . . ,∇cm(w). In the sequel we often use the notation\nL̂(w) = L̂(w, λ(w)), ∇L̂(w) = ∇wL̂(w, λ(w)), ∇2L̂(w) = ∇2wwL̂(w, λ(w)) .\nThe tangent space at any point w ∈ W is defined by T (w) = {v ∈ Rd : (∀i ∈ [m]) v⊤∇ci(w) = 0}. Following this notation, we observe that ∇L̂(w) is simply the projection of ∇L̂(w) onto the tangent space T (w). In particular, Theorem 14 provides conditions under which this projection vanishes. The next theorem extends the standard second-order conditions to our setting.\nTheorem 15 (Second-order necessary conditions) If w ∈ W is a local minimum of L̂ and the set {∇ci(w) : i ∈ [m]} is linearly independent, then for all v ∈ T (w),\nv⊤∇2L̂(w)v ≥ 0 ."
    }, {
      "heading" : "5.2. Strict saddle property in the constrained setting",
      "text" : "We now provide a definition of the strict saddle property in the constrained setting.\nDefinition 16 A twice continuously differentiable function F̂ : W → R with constrains ci(w) and associated Lagrangian L is called (α, γ, τ)-strict saddle if it has no spurious local minimum, and for any point w ∈ W at least one of the following conditions holds:\n1. ‖∇L̂(w)‖ ≥ τ\n2. There exists a unit vector v ∈ T (w) s.t. v⊤∇2L(w)v ≤ −γ\n3. There exists a local minimum w⋆ such that\n‖∇L(w)‖2 2α ≥ L̂(w)− L̂(w⋆) ≥ α 2 ‖w − w⋆‖2\nWhile our last condition is slightly different from its counterparts in Ge et al. (2015); Sun et al. (2015), we argue that it is often easier to establish the condition stated here (e.g., see Appendix B).6\n6. Actually, it seems that our condition is also required in the proof of Ge et al. (2015)[Lemma 34] (see equation 121)."
    }, {
      "heading" : "5.3. Analysis in the constrained setting",
      "text" : "Throughout the section we prove that Theorem 1 holds also in the constrained setting. We assume that W is described using m equality constraints of the form ci(w) = 0 and that the LICQ holds for all w ∈ W .\nAs in the constrained setting, we first bound the number of examples that are needed in order to\nexclude the two first scenarios listed in Definition 16.\nLemma 17 Let n > ρ/τ and (z1, . . . , zm) ∈ Zn. Then for any i ∈ [n], ‖∇L̂(ŵi)‖ ≤ τ .\nProof Since ŵi minimizes the risk w.r.t. 1 n\n∑\nj 6=i fj(w), we have that\ng̃−i = 1\nn\n∑\nj 6=i\n∇fj(ŵi)− m∑\ns=1\nλs(ŵi)∇cs(w) = 0 .\nTherefore, using the triangle inequality, we obtain\n‖∇L̂(ŵi)‖ ≤ ‖g̃−i‖+ 1\nn ‖∇fi(ŵi)‖ ≤ ρ/n < τ .\nLemma 18 Let n > β1/γ and (z1, . . . , zm) ∈ Zn. Then for any i ∈ [n] and v ∈ T (ŵi) v⊤∇2(L̂(ŵi))v ≥ −γ. Proof By second-order conditions, when restricted to T (ŵi), H̃−i := 1n ∑ j 6=i∇2fj(ŵi)+ ∑m\ns=1 λs(w)∇2cs(w) is positive semidefinite. Therefore, for every (nonzero) v ∈ T (ŵi),\nv⊤∇2L̂(ŵi)v v⊤v ≥ v ⊤H̃−iv v⊤v + 1 n v⊤∇2fi(ŵi)v v⊤v ≥ 0− β1/n > −γ .\nIt follows that for n > max{ρ/τ, β1/γ}, we only need to consider the third scenario listed in Definition 16. The proof of the next lemma is almost identical to the proof of Lemma 13 and is therefore given in the appendix (Appendix C).\nLemma 19 For n > max{ρ/τ, β1/γ} we have:\nǫgen(n) = ǫstab(n) ≤ 2ρ2\nαn ."
    }, {
      "heading" : "6. Application to PCA",
      "text" : "Consider the following stochastic formulation of PCA. Let D be a distribution over Z ⊆ Rd. We are interested in minimizing the objective\nF (w) = 1\n2 Ez∼D[‖z − ww⊤z‖2]\nover all possible unit vectors w ∈ Rd. We assume for simplicity that Z is contained in the Euclidean unit ball. It is well known that the minimum is the leading eigenvector of the positive definite matrix E[zz⊤]. As we shall see, this problem becomes strict saddle once we make the following standard assumption:\n(A4) There is a positive gap, denoted G1,2, between the two leading eigenvalues of E[xx ⊤].\nGiven a sample (z1, . . . , zn) ∼ Dn, let us denote by A = 1n ∑n i=1 ziz ⊤ i . The empirical risk is given by\nF̄ (w) = 1\n2n\nn∑\ni=1\n‖zi − ww⊤zi‖2\nOne can easily see that an equivalent objective is given by\nF̂ (w) = −1 2 w⊤Aw .\nHence, the empirical risk admits exactly two (local and global) minima, namely u and −u, where u is the leading eigenvector of A.\nWe now would like to show that for sufficiently large n, the empirical risk is strict saddle. The first step should be to translate our eigengap assumption on E[zz⊤] to a similar assumption on A. The following lemma, which follows from a simple application of the Matrix Bernstein inequality (Tropp (2015)[Section 1.6.3]), shows that for sufficiently large n, the eigengap between the two leading eigenvalues of A is Ω(G1,2). Lemma 20 Let δ ∈ (0, 1). For n = Ω (\nlog(d/δ) G2\n1,2\n)\n, we have that with probability at least 1− δ,\n‖A− E[xx⊤]‖ ≤ G1,2/2 =: G\nIt follows that with probability at least 1 − δ, the gap between the leading eigenvalues of A is at least G.\nThe following theorem implies Theorem 4. Theorem 21 For any δ ∈ (0, 1), if the sample size n is Ω (\nlog(d/δ) G2\n1,2\n)\n, then with probability at\nleast 1 − δ, the PCA objective satisfies the conditions in Definition 16 with τ, γ, α ∈ Ω(G1,2). Consequently, for any n = Ω (\nlog(d/δ) G2\n1,2\n)\n,\nǫgen(n) = ǫstab(n) ≤ 4\nn ·G1,2 .\nProof (idea) Critical points of the Lagrangian correspond to eigenvectors of A (where we refer to the zero vector as an eigenvector as well). We show that if the gradient at some point w is small, then w either belongs to a strongly convex region around the leading eigenvector or to a strict saddle neighborhood of another eigenvector (or 0).\nThe proof is given in Appendix A."
    }, {
      "heading" : "7. Sample Complexity Bounds for Strict Saddle Expected Risks",
      "text" : "In some cases it may be easier to establish the strict saddle property of the expected risk (Equation (1)). We now assume that F is (α, τ, γ)-strict saddle. We consider the constrained setting and denote the Lagrangian of F by L. We add the following boundedness assumption:\n(A4) The set W is contained in {w : ‖w‖ ≤ B}.\nThe proof of Theorem 2 is given in Appendix C. Below we give the main idea.\nProof (idea) of Theorem 2 We use Matrix Bernstein inequality together with covering to show that with high probability, points with large gradient do not form minima of F̂ . Similar argument shows that strict saddle points of F do not become minima of L̂. Then, we can restrict ourselves to strongly convex regions of F and show that any w with F (w) −minw′∈W F (w′) > ǫ can not be a minimum of F̂ ."
    }, {
      "heading" : "8. Application to ICA Through Tensor Decomposition",
      "text" : "A p-order tensor is a p-dimensional array. Here we focus on 4-order tensors. For a tensor T ∈ R d4 and indices i1, . . . , i4 ∈ [d], we denote the (i1, . . . , i4)-th entry of T by Ti1,...,i4 . Every ddimensional vector a induces a rank-one 4-order tensor, denoted a⊗4, where a⊗4i1,i2,i3,i4 is ai1ai2ai3ai4 . We can present the tensor T using a multilinear form. Given vectors u, v, z, w ∈ Rd, we define\nT (u, v, z, w) = ∑\ni1,i2,i3,i4\nTi1,...,i4ui1vi2zi3wi4\nThe tensor T has an orthogonal decomposition if it can be written as\nT = d∑\ni=1\na⊗4i . (3)\nIn case that such decomposition exists, it is unique up to a permutation of the ai’s and sign flips. A central problem in machine learning is to compute the tensor decomposition of a given tensor T (Anandkumar et al. (2014)). While we have exponentially many equivalent solutions, the average of two solutions does not form a solution. Hence, any reasonable formulation of this problem must be non-convex. Luckily, as was shown in Ge et al. (2015), there exists a strict saddle formulation of this problem.\nFor simplicity, we consider the problem of finding one component (one can proceed and find all\nthe components using deflation). Consider the following objective:\nmax ‖u‖=1 T (u, u, u, u) . (4)\nLemma 22 (Ge et al. (2015)) Suppose that T admits a Tensor decomposition as in (3). The only local minima of (4) are ±ai. Furthermore, the objective (4) is (α, γ, τ)-strict saddle with α = Ω(1), γ = 7/d and τ = 1/poly(d). Last, for p = 1, 2, 3, the magnitude of the p-th order derivative of this objective is O( √ d).\nAlthough our definition of strict saddle functions in the constrained setting is slightly different from its counterpart in Ge et al. (2015), it is not hard to show that Lemma 22 still holds (see Appendix B).\nIn applications, we often have access to T only through a stochastic oracle. Following Ge et al. (2015), we consider the following formulation of ICA. Let A be an orthonormal linear transformation. Suppose that x is uniform on {±1}d and denote by y = Ax. Our goal is to recover the matrix A using the observations y. It turns out that ICA reduces to tensor decomposition. Namely, define Z ∈ Rd4 by\n(∀i ∈ [d]) Z(i, i, i, i) = 3, (∀i 6= j) Z(i, i, j, j) = Z(i, j, j, i) = Z(i, j, i, j) = 1 , where all other entries of Z are zero.\nLemma 23 The expectation 12E[Z − y⊗4] is equal to T , where the vectors participating in the decomposition of T correspond to columns of A.\nFollowing the lemma, we can rewrite (4) as the following expected risk:\nmax ‖u‖=1 E\n[ 1\n2\n( Z − y⊗4\n) ]\n(u, u, u, u) . (5)\nFurthermore, as was shown in Ge et al. (2015), one can efficiently compute a stochastic gradient and use SGD to optimize this objective. Using Lemma 22 and Theorem 2, we conclude that the sample complexity of extracting a single column of A is Õ ( poly(d) + d 3/2\nǫ\n)\n. The sample complexity of\nextracting all the columns is Õ ( poly(d) + d 5/2\nǫ\n)\n."
    }, {
      "heading" : "9. Related Work",
      "text" : ""
    }, {
      "heading" : "9.1. Efficient ERM for Strict Saddle Functions",
      "text" : "There is a growing interest in developing efficient algorithms for minimization of strict saddle functions. We mention two central approaches. Intuitively, one can escape from a saddle point by moving in the direction of the eigenvector corresponding to the minimal eigenvalue. This intuition has been made precise by Nesterov and Polyak (Nesterov and Polyak (2006)). More surprisingly, in Ge et al. (2015) it was shown that a variant of SGD also converges to a local minimum. Recent improvements in terms of runtime are given in Agarwal et al. (2016); Levy (2016)."
    }, {
      "heading" : "9.2. Stability of SGD",
      "text" : "Recently, Hardt et al. (2015) analyzed the stability of the SGD algorithm both in a convex and nonconvex setting. As we mentioned above, in our setting, SGD forms an empirical risk minimizer. Our bounds on the stability rate of SGD in this setting improve over the (more general) bounds of Hardt et al. (2015). In particular, our bounds imply that SGD can be trained for arbitrarily long time."
    }, {
      "heading" : "9.3. Generalization Bounds using SGD",
      "text" : "It is known that one can obtain generalization bounds directly using SGD (Shalev-Shwartz and Ben-David (2014)[Chapter 14]). Hence, the time complexity bound of Ge et al. (2015) translates into identical sample complexity bound. However, their bounds, which scale with 1/ǫ4, are inferior to our bounds when high accuracy is desired."
    }, {
      "heading" : "9.4. Fast rates for PCA",
      "text" : "Generalization bounds for stochastic PCA have been studied in Bousquet and Elisseeff (2002); Gonen et al. (2016). Both works prove an upper bound of 1/ √ n on the generalization error in the general case. The latter work (which also considers the challenge of partial information) establishes a matching lower bound. The former work also considers the case of a positive eigengap between the leading eigenvalues of E[xx⊤]7 and establishes fast rates similar to our bounds using Local Rademacher complexities. We believe that these techniques are much more involved than our techniques and lack any geometric interpretation."
    }, {
      "heading" : "Acknowledgments",
      "text" : "We thank Kfir Levy for bringing Remark 3 into our attention. We also thank Nati Srebro for helpful discussions.\n7. More generally, these works consider the task of approximating the k leading eigenvectors. It is not hard to extend\nour results to this task as well."
    }, {
      "heading" : "Appendix A. PCA Is Strict Saddle: Complete Proof",
      "text" : "This section is devoted to the proof of Theorem 21. Let us start with some basic calculations. The gradient and the Hessian of F̂ (w) are given by\n∇F̂ (w) = −Aw, ∇2F̂ (w) = −A .\nIt is apparent that both the domain and the the objective are not convex. The following lemma is immediate.\nLemma 24 The restriction of F̂ to the unit sphere in Rd is 1-Lipschitz and 1-smooth.\nLetting c(w) = 12(‖w‖2 − 1), the Lagrangian is given by\nL̂(w, λ) = F̂ (w) + λc(w) = −1 2 w⊤Aw + λ 2 (‖w‖2 − 1) .\nIt follows that\nλ(w) = w⊤Aw .\nTherefore, the gradient and the Hessian of L̂(w) are given by\n∇L̂(w) = (λ(w)I −A)w, ∇2L̂(w) = (λ(w)I −A)\nNote also that LICQ trivially holds at any point w ∈ W . Proof (of Theorem 21) Let w be a unit vector in Rd and suppose that ‖∇f(w)‖ ≤ τ = cG for some constant c ∈ (0, 1/32). We show that w satisfies either the second or the third condition in Definition 16.\nFirst step (setup): Let w = ∑d\ni=1 αiui be the decomposition of w according to the eigenbasis of A. Note that by the optimality of u1, λ ≤ λ1. Also, by assumption\nτ2 ≥ ‖(λI −A)w‖2 = w⊤ d∑\ni=1\n(λ− λi)2uiu⊤i w = d∑\ni=1\nα2i (λ− λi)2 . (6)\nSecond step (bounding the mass of distant eigenvalues): Note that ‖α‖2 = 1, hence the vector α2 = (α21, . . . , α2d) can be seen as a probability vector. We next apply Markov’s inequality in order to bound the mass of eigenvalues located far from λ. For every t = 0, 1, . . ., define It = {i ∈ [d] : |λ− λi| ≤ 2tτ} . We claim that for every t,\n∑\ni/∈It\nα2i ≤ 2−2t . (7)\nIndeed, for t = 0 the bound is trivial and for t ≥ 1 we apply (6) to otbain\nτ2 ≥ ∑\ni/∈It\nα2i (λ− λi)2 ≥ 22tτ2 ∑\ni/∈It\nα2i .\nBy rearranging, we conclude the claim.\nThird step (the strongly convex case): Consider the case where 1 ∈ I4. It follows that\nλ1 − 16cG = λ1 − 24τ ≤ λ = d∑\ni=1\nα2iλi ≤ α21λ1 + d∑\ni=2\nα2i (λ1 −G) = λ1 −G d∑\ni=2\nα2i ,\nwhere the last equality uses the fact that ∑d\ni=1 α 2 i = 1. Hence, ∑d i=2 α 2 i ≤ 16c, so\nα21 ≥ (1− 16c) ≥ 1/2 ⇒ ∑\ni≥2\nα2i ≤ 1/2 . (8)\nWe now show that F̂ (w) − F̂ (u1) ≥ G4 ‖w − u1‖2. First we calculate the distance between w and u1:\n‖w − u1‖2 = (α1 − 1)2 + ∑\ni≥2\nα2i = d∑\ni=1\nα2i + 1− 2α1 = 2(1 − α1) . (9)\nSince w and u1 are feasible, F̂ (w) = L̂(w) and F̂ (u1) = L̂(u1). Since L̂ is quadratic and u1 is optimal (hence ∇L̂(u1) = 0), we have\nF̂ (w) = F̂ (u1)+〈∇L̂(u1), w−u1〉+ 1\n2 (w−u1)⊤∇2L̂(u1)(w−u1) = L̂(u1)+\n1 2 (w−u1)⊤∇2L̂(u)(w−u1)\nIt is left to bound the quadratic term from below. Since 0 ≤ λ1 − λ ≤ 16cG for c ∈ (0, 1/32),\nλ1 − λ ≤ G/2 ⇒ (∀i ≥ 2) λ− λi ≥ G/2 . (10)\nTherefore,\n1 2 (w − u1)⊤∇2L̂(u)(w − u1) = (α1 − 1)2(λ1 − λ1) +\n∑\ni≥2\nα2i (λ1 − λi)\n≥ G ∑\ni≥2\nα2i ≥ G(−(α1 − 1)2 + ∑\ni≥2\nα2i )\n= G\n2 (\nd∑\ni=1\nα2i − 2α21 + 2α1 − 1) = G\n2 (2α1 − 2α21)\n= G\n2 2α1(1− α1) =︸︷︷︸\n(9)\nG 2 α1‖w − u1‖2\n≥ ︸︷︷︸\n(8)\nG 4 ‖w − u1‖2 ,\nWe deduce that\nF̂ (w)− F̂ (u1) ≥ G\n4 ‖w − u1‖2 .\nOn the other hand,\n1 2 (w − u1)⊤∇2L̂(u)(w − u1) =\n∑\ni≥2 α2i (λ− λi + λ1 − λ) ≤︸︷︷︸ 8,10\n∑\ni≥2\nα2i (λ− λi + λ1 − λ)\n+ α21(λ− λi)− ∑\ni≥2\nα2i (λ1 − λ) = ∑\ni≥2\nα2i (λ− λi)\n≤ ︸︷︷︸\n10\n∑\ni≥2\nα2i (λ− λi)2/(G/2) ≤ ∑\ni≥1\nα2i (λ− λi)2/(G/2)\n= ‖∇L(w)‖2 2(G/4) .\nFourth step (the strict saddle case): Consider the case where 1 /∈ I4. We construct a vector v ∈ T (w) such that v ⊤∇2L̂(w)v\n‖v‖2 is propor-\ntional to −G. Let v = u1 − α1w\nNote that v is perpendicular to w, hence v ∈ T (w). Also note that\nv = (1− α21)u1 − α1 ∑\ni≥2\nαiui\nHence,\nv⊤∇2L̂(w)v = (1− α21)(λ− λ1) + ∑\ni≥2\nα2i (λ− λi) .\nWe bound each of the terms in the RHS. Using (7) we upper bound α21 by 2 −8. Since λ ≤ λ1, we have\n(1− α21)(λ− λ1) ≤ − 255\n256 · 16τ ≤ −15τ .\nOn the other hand, denoting Jt = It \\ ⋃t−1 s=0 Is, we have\n∑\nj≥2\nα2j (λ− λj) ≤ ∑\nj≥1\nα2j |λ− λj | = ∞∑\nt=0\n∑\nj∈Jt\nα2j |λ− λi| ≤ ∞∑\nt=0\n∑\nj∈Jt\nα2j2 tτ\n=≤ τ ∞∑\nt=0\n2−2t2t = 2τ ,\nwhere the last inequality follows from (7). Note also that ‖v‖ ≤ 2. Overall, we obtain that\nv⊤∇2L̂(w)v ‖v‖2 ≤ −13τ/2 ≤ −6cG ."
    }, {
      "heading" : "Appendix B. ICA is Strict Saddle: Establishing Strong Convexity",
      "text" : "Our notion of strong convexity in Definition 16 is slightly different from its counterpart in Ge et al. (2015). We now show that Lemma 22 holds using our definitions.\nLet w ∈ W . To simplify the presentation, we assume that ai = ei for all i (alternatively, we could do a change of coordinates to w, which does not affect the structure of the problem). Denote\nτ0 = (10d) −4, τ = 4τ20 , D = 2dτ0, I(w) = {i ∈ [d] : |wi| > τ0}\nSuppose that ‖∇L(w)‖ ≤ τ , where L is the Lagrangian associated with the expected risk F . It was shown in Ge et al. (2015) that if |I(w)| ≥ 2, then w is a strict saddle point. Hence, it is left to consider the case where |I(w)| = 1. Assume w.l.o.g. that I(w) = {1}.\nLemma 25 The suboptimality of w w.t.t. the minimum e1 is bounded below by\nF (w) − F (e1) ≥ 1\n4 ‖w − e1‖2 .\nProof Since w is a unit vector,\n1 ≥ w21 = 1− ∑\ni≥2\nw2i ≥ 1− dτ20\nThe squared distance between w and the local minimum e1 is at most\n‖w − e1‖2 = (1− w1)2 + ∑\ni≥2\nw2i ≤ 2dτ20 ≤ D2 .\nLet c(w) = 12(‖w‖2 − 1). Since c(w) = c(e1) = 0, using the 1-smoothness of c we obtain\n0 = c(w) ≤ c(e1) +∇c(e1)⊤(w − e1) + 1\n2 ‖w − e1‖2 = e1(w − e1) .\nHence,\n(1− w1)2 = (e⊤1 (e1 − w))2 ≤ 1\n4 ‖w − e1‖4 ≤\n1 4 ‖w − e1‖2 (11)\nAs Ge et al. (2015) show, The Hessian of L at e1 is a diagonal matrix with 4 on the diagonals except for the first diagonal entry whose value is −8. Since F (w) = L(w) and F (e1) = L(e1),\nF (w) = F (w1) +∇L(e1)⊤ ︸ ︷︷ ︸\n=0\n(w − e1) + 1\n2 (w − e1)⊤∇2L(w′)(w − e1)\nfor some w′ that lies on the line between w and e1. Note that\n1 2 (w − e1)⊤∇2L(w′)(w − e1) = 1\n2 (w − e1)⊤∇2L(e1)(w − e1) +\n1 2 (w − e1)⊤(∇2L(w′)−∇2L(e1))(w − e1) .\nUsing (11), we bound the first term in the RHS by\n(w − e1)⊤∇2L(e1)(w − e1) = −8(1− w1)2 + 4 ∑\ni≥2\nw2i = 4((1 −w1)2 + ∑\ni≥2\nw2i )− 12(1 − w1)2\n≥ 4‖w − u1‖2 − 3‖w − u1‖2 = ‖w − u1‖2\nUsing the O( √ d)-Lipschitzness of the Hessian and the fact that ‖w′ − e1‖ ≤ D, the second term is bounded by\n(w − e1)⊤(∇2L(w′)−∇2L(e1))(w − e1) ≤ ‖w − e1‖2‖w′ − e1‖ √ d ≤ 1\n2 ‖w − e1‖2 .\nAll in all,\nF (w) − F (e1) ≥ 1\n4 ‖w − e1‖2 .\nLemma 26 The suboptimality of w w.t.t. the minimum e1 is bounded above by\nF (w) − F (e1) ≤ O(‖∇L(w)‖2) .\nProof Using the previous lemma and the Lipschitzness of the Hessian, one can easily show that\nF (e1) ≥ F (w) +∇L(w)⊤(e1 − w) + c\n2 ‖e1 − w‖2\nfor some constant c ∈ (0, 1). The RHS is at most\nmin z∈Rd F (w) +∇L(w)⊤(z − w) + c 2 ‖z − w‖2\nThe minimum is attained at z = w− c−1∇L(w). The desired inequality follows by substitution."
    }, {
      "heading" : "Appendix C. Omitted Proofs",
      "text" : "Proof (of Lemma 19) According to the previous two lemmas, ŵi lies in neighborhood around a local minimum w⋆ such that the restriction of F̂ to this neighborhood is strongly convex. As in the unconstrained setting we may assume w.l.o.g. that ŵ = w⋆.\nFix some i ∈ [n]. By assumption\nF̂ (ŵi)− F̂ (ŵ) = L̂(ŵi)− L̂(ŵ) ≥ α\n2 ‖ŵi − ŵ‖2\nOn the other hand, since ŵi minimizes the loss w ∈ W 7→ 1n ∑ j 6=i fj(w), the suboptimality of ŵi w.r.t. the objective F̂ is controlled by its suboptimality w.r.t. fi, i.e.\nF̂ (ŵi)− F̂ (ŵ) ≤ 1\nn ∆i\nUsing Lipschitzness of fi, we have ∆i ≤ ρ‖ŵi − ŵ‖\nCombining the above, we obtain\n∆2i ≤ ρ2‖ŵi − ŵ‖2 ≤ 2ρ2\nα (F̂ (ŵi)− F̂ (ŵ)) ≤\n2ρ2 αn ∆i\nDividing by∆i (we can assume w.l.o.g. that ∆i > 0) we conclude the proof.\nProof (of Lemma 20) The first part is a direct application of Bernstein inequality (Tropp (2015)[Section 1.6.3]). It is left to prove that if A,B are positive semidefinite and ‖A − B‖ ≤ ǫ, then for all i, |λi(A) − λi(B)| ≤ ǫ. Indeed,\nλi(B) = max dim(V )=i min v∈V\nv⊤Bv\nv⊤v\n= max dim(V )=i min v∈V v⊤Av + v⊤(B −A)v v⊤v\n≤ max dim(V )=i min v∈V\nv⊤Av\nv⊤v +max v∈V v⊤(B −A)v v⊤v\n= λi(A) + ǫ .\nAnalogous proof shows that λi(A) ≤ λi(B) + ǫ.\nProof (of Theorem 2) Recall that the Lagrangian of F̂ is denoted by L̂. We first show that with high probability, points with large gradient do not form minima of F̂ . Similar argument shows that strict saddle points of L do not become minima of F̂ . Then, we can restrict ourselves to strongly convex regions of L and show that any w with F (w)−minw′∈W F (w′) > ǫ can not be a minimum of F̂ .\nFix some point w ∈ W with ‖∇L(w)‖ ≥ τ . Using matrix Bernstein inequality, we deduce that if n = Ω(ρ log(d/δ)/τ2)), then ‖∇L̂(w)‖ ≥ τ/2. Also, using Property A2, we have that for any u ∈ W with ‖u − w‖ ≤ r1 := min{ τ4β1 , 1}, ‖∇L̂(u)‖ ≥ τ/4. Since W is bounded we can cover W using (4B/r1)d balls of radius r1 (for example, see the proof of Matoušek (2002)[Lemma 13.11.1]). By applying the union bound we deduce that if n = Ω(dρ log(dB/(r1δ)/τ\n2), then with probability at least 1− δ, all points w with ‖∇L(w)‖ ≥ τ satisfy ‖∇L̂(w)‖ ≥ τ/4.\nWe next fix some pointw ∈ W for which there exists a unit vector v ∈ T (w)with v⊤(∇2L(w))v ≤ −γ. Using matrix Bernstein inequality, we deduce that if n = Ω(β1 log(d/δ)/γ2), then v⊤∇2L(w)v ≤ −γ/2. Also, using Property A3, we have that for any u ∈ W with ‖u− w‖ ≤ r2 := min{ γ4β2 , 1}, there exists v ∈ T (u)with v⊤∇2L(u)v. SinceW is bounded, we can coverW using (4B/r2)d balls of radius r2. By applying the union bound, we obtain that a sample of size n = Ω(dβ1 log(dB/(r2δ))/γ\n2) ensures that with probability at least 1− δ, γ-strict saddle points of F are γ/2-strict saddle of F̂ .\nIn particular, using Theorem 14 and Theorem 15 we deduce that strict saddle points of F and points with large gradient do not form local minima of L̂.\nConsider now vectors w ∈ W which belong to a strongly convex region around some minimum of F , denoted w⋆. Suppose that F (w) − F (w⋆) > ǫ. By strong convexity, ‖∇L(w)‖2 ≥ 2αǫ.\nUsing concentration and covering as above, we conclude that for n = Ω(β1 log(dB/(r1δ))/(αǫ)), then with probability at least 1− δ, ‖∇L̂(w)‖2 ≥ αǫ, hence w is not a local minimum of F̂ ."
    } ],
    "references" : [ {
      "title" : "Finding local minima for nonconvex optimization in linear time",
      "author" : [ "Naman Agarwal", "Zeyuan Allen-Zhu", "Brian Bullins", "Elad Hazan", "Tengyu Ma" ],
      "venue" : "arXiv preprint arXiv:1611.01146,",
      "citeRegEx" : "Agarwal et al\\.,? \\Q2016\\E",
      "shortCiteRegEx" : "Agarwal et al\\.",
      "year" : 2016
    }, {
      "title" : "Homotopy method for tensor principal component analysis",
      "author" : [ "Anima Anandkumar", "Yuan Deng", "Rong Ge", "Hossein Mobah" ],
      "venue" : "arXiv preprint arXiv:1610.09322,",
      "citeRegEx" : "Anandkumar et al\\.,? \\Q2016\\E",
      "shortCiteRegEx" : "Anandkumar et al\\.",
      "year" : 2016
    }, {
      "title" : "Tensor decompositions for learning latent variable models",
      "author" : [ "Animashree Anandkumar", "Rong Ge", "Daniel Hsu", "Sham M Kakade", "Matus Telgarsky" ],
      "venue" : "Journal of Machine Learning Research,",
      "citeRegEx" : "Anandkumar et al\\.,? \\Q2014\\E",
      "shortCiteRegEx" : "Anandkumar et al\\.",
      "year" : 2014
    }, {
      "title" : "Global optimality of local search for low rank matrix recovery",
      "author" : [ "Srinadh Bhojanapalli", "Behnam Neyshabur", "Nathan Srebro" ],
      "venue" : "arXiv preprint arXiv:1605.07221,",
      "citeRegEx" : "Bhojanapalli et al\\.,? \\Q2016\\E",
      "shortCiteRegEx" : "Bhojanapalli et al\\.",
      "year" : 2016
    }, {
      "title" : "Statistical properties of kernel principal component analysis",
      "author" : [ "Gilles Blanchard", "Olivier Bousquet", "Laurent Zwald" ],
      "venue" : "Machine Learning,",
      "citeRegEx" : "Blanchard et al\\.,? \\Q2007\\E",
      "shortCiteRegEx" : "Blanchard et al\\.",
      "year" : 2007
    }, {
      "title" : "Convex analysis and nonlinear optimization: theory and examples",
      "author" : [ "Jonathan M Borwein", "Adrian S Lewis" ],
      "venue" : "Springer Science & Business Media,",
      "citeRegEx" : "Borwein and Lewis.,? \\Q2010\\E",
      "shortCiteRegEx" : "Borwein and Lewis.",
      "year" : 2010
    }, {
      "title" : "Stability and generalization",
      "author" : [ "Olivier Bousquet", "André Elisseeff" ],
      "venue" : "The Journal of Machine Learning Research,",
      "citeRegEx" : "Bousquet and Elisseeff.,? \\Q2002\\E",
      "shortCiteRegEx" : "Bousquet and Elisseeff.",
      "year" : 2002
    }, {
      "title" : "Escaping from saddle points-online stochastic gradient descent for tensor decomposition",
      "author" : [ "Rong Ge", "Furong Huang", "Chi Jin", "Yang Yuan" ],
      "venue" : "In Proceedings of The 29th Conference on Learning Theory,",
      "citeRegEx" : "Ge et al\\.,? \\Q2015\\E",
      "shortCiteRegEx" : "Ge et al\\.",
      "year" : 2015
    }, {
      "title" : "Matrix completion has no spurious local minimum",
      "author" : [ "Rong Ge", "Jason D Lee", "Tengyu Ma" ],
      "venue" : "In Advances in Neural Information Processing Systems,",
      "citeRegEx" : "Ge et al\\.,? \\Q2016\\E",
      "shortCiteRegEx" : "Ge et al\\.",
      "year" : 2016
    }, {
      "title" : "Average stability is invariant to data preconditioning. implications to exp-concave empirical risk minimization",
      "author" : [ "Alon Gonen", "Shai Shalev-Shwartz" ],
      "venue" : "arXiv preprint arXiv:1601.04011,",
      "citeRegEx" : "Gonen and Shalev.Shwartz.,? \\Q2016\\E",
      "shortCiteRegEx" : "Gonen and Shalev.Shwartz.",
      "year" : 2016
    }, {
      "title" : "Subspace learning with partial information",
      "author" : [ "Alon Gonen", "Dan Rosenbaum", "Yonina C Eldar", "Shai Shalev-Shwartz" ],
      "venue" : "Journal of Machine Learning Research,",
      "citeRegEx" : "Gonen et al\\.,? \\Q2016\\E",
      "shortCiteRegEx" : "Gonen et al\\.",
      "year" : 2016
    }, {
      "title" : "Train faster, generalize better: Stability of stochastic gradient descent",
      "author" : [ "Moritz Hardt", "Benjamin Recht", "Yoram Singer" ],
      "venue" : "arXiv preprint arXiv:1509.01240,",
      "citeRegEx" : "Hardt et al\\.,? \\Q2015\\E",
      "shortCiteRegEx" : "Hardt et al\\.",
      "year" : 2015
    }, {
      "title" : "Fast rates for exp-concave empirical risk minimization",
      "author" : [ "Tomer Koren", "Kfir Levy" ],
      "venue" : "In Advances in Neural Information Processing Systems,",
      "citeRegEx" : "Koren and Levy.,? \\Q2015\\E",
      "shortCiteRegEx" : "Koren and Levy.",
      "year" : 2015
    }, {
      "title" : "The power of normalization: Faster evasion of saddle points",
      "author" : [ "Kfir Y Levy" ],
      "venue" : "arXiv preprint arXiv:1611.04831,",
      "citeRegEx" : "Levy.,? \\Q2016\\E",
      "shortCiteRegEx" : "Levy.",
      "year" : 2016
    }, {
      "title" : "Learning theory: stability is sufficient for generalization and necessary and sufficient for consistency of empirical risk minimization",
      "author" : [ "Sayan Mukherjee", "Partha Niyogi", "Tomaso Poggio", "Ryan Rifkin" ],
      "venue" : "Advances in Computational Mathematics,",
      "citeRegEx" : "Mukherjee et al\\.,? \\Q2006\\E",
      "shortCiteRegEx" : "Mukherjee et al\\.",
      "year" : 2006
    }, {
      "title" : "Cubic regularization of newton method and its global performance",
      "author" : [ "Yurii Nesterov", "Boris T Polyak" ],
      "venue" : "Mathematical Programming,",
      "citeRegEx" : "Nesterov and Polyak.,? \\Q2006\\E",
      "shortCiteRegEx" : "Nesterov and Polyak.",
      "year" : 2006
    }, {
      "title" : "Understanding Machine Learning: From Theory to Algorithms",
      "author" : [ "Shai Shalev-Shwartz", "Shai Ben-David" ],
      "venue" : null,
      "citeRegEx" : "Shalev.Shwartz and Ben.David.,? \\Q2014\\E",
      "shortCiteRegEx" : "Shalev.Shwartz and Ben.David.",
      "year" : 2014
    }, {
      "title" : "Learnability, stability and uniform convergence",
      "author" : [ "Shai Shalev-Shwartz", "Ohad Shamir", "Nathan Srebro", "Karthik Sridharan" ],
      "venue" : "The Journal of Machine Learning Research,",
      "citeRegEx" : "Shalev.Shwartz et al\\.,? \\Q2010\\E",
      "shortCiteRegEx" : "Shalev.Shwartz et al\\.",
      "year" : 2010
    }, {
      "title" : "When are nonconvex problems not scary",
      "author" : [ "Ju Sun", "Qing Qu", "John Wright" ],
      "venue" : "arXiv preprint arXiv:1510.06096,",
      "citeRegEx" : "Sun et al\\.,? \\Q2015\\E",
      "shortCiteRegEx" : "Sun et al\\.",
      "year" : 2015
    }, {
      "title" : "An introduction to matrix concentration inequalities",
      "author" : [ "Joel A Tropp" ],
      "venue" : "arXiv preprint arXiv:1501.01571,",
      "citeRegEx" : "Tropp.,? \\Q2015\\E",
      "shortCiteRegEx" : "Tropp.",
      "year" : 2015
    } ],
    "referenceMentions" : [ {
      "referenceID" : 3,
      "context" : "Introduction Stability analysis is a central tool in statistical learning theory (Bousquet and Elisseeff (2002)).",
      "startOffset" : 82,
      "endOffset" : 112
    }, {
      "referenceID" : 3,
      "context" : "Introduction Stability analysis is a central tool in statistical learning theory (Bousquet and Elisseeff (2002)). Roughly speaking, a learning algorithm is stable if a slight change in the input of the algorithm does not change its output much. It was shown (Shalev-Shwartz et al. (2010); Mukherjee et al.",
      "startOffset" : 82,
      "endOffset" : 288
    }, {
      "referenceID" : 3,
      "context" : "Introduction Stability analysis is a central tool in statistical learning theory (Bousquet and Elisseeff (2002)). Roughly speaking, a learning algorithm is stable if a slight change in the input of the algorithm does not change its output much. It was shown (Shalev-Shwartz et al. (2010); Mukherjee et al. (2006)) that stability characterizes learnability, and in particular, stability is equivalent to the estimation error of empirical risk minimization.",
      "startOffset" : 82,
      "endOffset" : 313
    }, {
      "referenceID" : 3,
      "context" : "Introduction Stability analysis is a central tool in statistical learning theory (Bousquet and Elisseeff (2002)). Roughly speaking, a learning algorithm is stable if a slight change in the input of the algorithm does not change its output much. It was shown (Shalev-Shwartz et al. (2010); Mukherjee et al. (2006)) that stability characterizes learnability, and in particular, stability is equivalent to the estimation error of empirical risk minimization. Stability analysis has been mostly carried out in the context of convex risk minimization. More concretely, some form of strong convexity is often assumed (e.g., exp-concavity in Koren and Levy (2015); Gonen and Shalev-Shwartz (2016)).",
      "startOffset" : 82,
      "endOffset" : 657
    }, {
      "referenceID" : 3,
      "context" : "Introduction Stability analysis is a central tool in statistical learning theory (Bousquet and Elisseeff (2002)). Roughly speaking, a learning algorithm is stable if a slight change in the input of the algorithm does not change its output much. It was shown (Shalev-Shwartz et al. (2010); Mukherjee et al. (2006)) that stability characterizes learnability, and in particular, stability is equivalent to the estimation error of empirical risk minimization. Stability analysis has been mostly carried out in the context of convex risk minimization. More concretely, some form of strong convexity is often assumed (e.g., exp-concavity in Koren and Levy (2015); Gonen and Shalev-Shwartz (2016)).",
      "startOffset" : 82,
      "endOffset" : 690
    }, {
      "referenceID" : 3,
      "context" : "Introduction Stability analysis is a central tool in statistical learning theory (Bousquet and Elisseeff (2002)). Roughly speaking, a learning algorithm is stable if a slight change in the input of the algorithm does not change its output much. It was shown (Shalev-Shwartz et al. (2010); Mukherjee et al. (2006)) that stability characterizes learnability, and in particular, stability is equivalent to the estimation error of empirical risk minimization. Stability analysis has been mostly carried out in the context of convex risk minimization. More concretely, some form of strong convexity is often assumed (e.g., exp-concavity in Koren and Levy (2015); Gonen and Shalev-Shwartz (2016)). The crux of the technique is to show that minima of two similar strongly convex (and Lipschitz/smooth) functions must be close ((Shalev-Shwartz and Ben-David, 2014, Section 13.3)). In this paper we address the non-convex setting while restricting our attention to recently studied “nice” non-convex problems. Namely, we will consider non-convex functions which satisfy the strict saddle property (a.k.a. ridable or X -functions, see Sun et al. (2015)).",
      "startOffset" : 82,
      "endOffset" : 1143
    }, {
      "referenceID" : 3,
      "context" : "Introduction Stability analysis is a central tool in statistical learning theory (Bousquet and Elisseeff (2002)). Roughly speaking, a learning algorithm is stable if a slight change in the input of the algorithm does not change its output much. It was shown (Shalev-Shwartz et al. (2010); Mukherjee et al. (2006)) that stability characterizes learnability, and in particular, stability is equivalent to the estimation error of empirical risk minimization. Stability analysis has been mostly carried out in the context of convex risk minimization. More concretely, some form of strong convexity is often assumed (e.g., exp-concavity in Koren and Levy (2015); Gonen and Shalev-Shwartz (2016)). The crux of the technique is to show that minima of two similar strongly convex (and Lipschitz/smooth) functions must be close ((Shalev-Shwartz and Ben-David, 2014, Section 13.3)). In this paper we address the non-convex setting while restricting our attention to recently studied “nice” non-convex problems. Namely, we will consider non-convex functions which satisfy the strict saddle property (a.k.a. ridable or X -functions, see Sun et al. (2015)). Roughly speaking, a strict saddle function has no spurious local minimum and its saddle points are strict, in the sense that second-order information suffices for identifying a descent direction. We also assume that the restriction of the function to a certain neighborhood of each of its minima is strongly convex. Many important non-convex problems such as Principal Component Analysis (PCA), complete dictionary recovery (Sun et al. (2015)), tensor decomposition, ICA (Ge et al.",
      "startOffset" : 82,
      "endOffset" : 1588
    }, {
      "referenceID" : 3,
      "context" : "Introduction Stability analysis is a central tool in statistical learning theory (Bousquet and Elisseeff (2002)). Roughly speaking, a learning algorithm is stable if a slight change in the input of the algorithm does not change its output much. It was shown (Shalev-Shwartz et al. (2010); Mukherjee et al. (2006)) that stability characterizes learnability, and in particular, stability is equivalent to the estimation error of empirical risk minimization. Stability analysis has been mostly carried out in the context of convex risk minimization. More concretely, some form of strong convexity is often assumed (e.g., exp-concavity in Koren and Levy (2015); Gonen and Shalev-Shwartz (2016)). The crux of the technique is to show that minima of two similar strongly convex (and Lipschitz/smooth) functions must be close ((Shalev-Shwartz and Ben-David, 2014, Section 13.3)). In this paper we address the non-convex setting while restricting our attention to recently studied “nice” non-convex problems. Namely, we will consider non-convex functions which satisfy the strict saddle property (a.k.a. ridable or X -functions, see Sun et al. (2015)). Roughly speaking, a strict saddle function has no spurious local minimum and its saddle points are strict, in the sense that second-order information suffices for identifying a descent direction. We also assume that the restriction of the function to a certain neighborhood of each of its minima is strongly convex. Many important non-convex problems such as Principal Component Analysis (PCA), complete dictionary recovery (Sun et al. (2015)), tensor decomposition, ICA (Ge et al. (2015), Anandkumar et al.",
      "startOffset" : 82,
      "endOffset" : 1634
    }, {
      "referenceID" : 1,
      "context" : "(2015), Anandkumar et al. (2016)) and matrix completion (Ge et al.",
      "startOffset" : 8,
      "endOffset" : 33
    }, {
      "referenceID" : 1,
      "context" : "(2015), Anandkumar et al. (2016)) and matrix completion (Ge et al. (2016); Bhojanapalli et al.",
      "startOffset" : 8,
      "endOffset" : 74
    }, {
      "referenceID" : 1,
      "context" : "(2015), Anandkumar et al. (2016)) and matrix completion (Ge et al. (2016); Bhojanapalli et al. (2016)) are strict-saddle.",
      "startOffset" : 8,
      "endOffset" : 102
    }, {
      "referenceID" : 4,
      "context" : "It is known that the sample complexity of ERM for this problem is Ω(1/ǫ2) (Blanchard et al. (2007); Gonen et al.",
      "startOffset" : 75,
      "endOffset" : 99
    }, {
      "referenceID" : 4,
      "context" : "It is known that the sample complexity of ERM for this problem is Ω(1/ǫ2) (Blanchard et al. (2007); Gonen et al. (2016)).",
      "startOffset" : 75,
      "endOffset" : 120
    }, {
      "referenceID" : 7,
      "context" : "As was shown in Ge et al. (2015), this problem can be reduced to tensor decomposition.",
      "startOffset" : 16,
      "endOffset" : 33
    }, {
      "referenceID" : 16,
      "context" : "The following definition due to Sun et al. (2015); Ge et al.",
      "startOffset" : 32,
      "endOffset" : 50
    }, {
      "referenceID" : 7,
      "context" : "(2015); Ge et al. (2015) captures this idea.",
      "startOffset" : 8,
      "endOffset" : 25
    }, {
      "referenceID" : 7,
      "context" : "While Ge et al. (2015); Sun et al.",
      "startOffset" : 6,
      "endOffset" : 23
    }, {
      "referenceID" : 7,
      "context" : "While Ge et al. (2015); Sun et al. (2015) also require a lower bound on the magnitude of ν (which appears in the last condition), it turns out that this quantity does not play any role in our analysis.",
      "startOffset" : 6,
      "endOffset" : 42
    }, {
      "referenceID" : 5,
      "context" : "First and second-order conditions In this part we recall basic facts on first and second-order conditions in the constrained setting (see for example Borwein and Lewis (2010)).",
      "startOffset" : 150,
      "endOffset" : 175
    }, {
      "referenceID" : 7,
      "context" : "While our last condition is slightly different from its counterparts in Ge et al. (2015); Sun et al.",
      "startOffset" : 72,
      "endOffset" : 89
    }, {
      "referenceID" : 7,
      "context" : "While our last condition is slightly different from its counterparts in Ge et al. (2015); Sun et al. (2015), we argue that it is often easier to establish the condition stated here (e.",
      "startOffset" : 72,
      "endOffset" : 108
    }, {
      "referenceID" : 7,
      "context" : "While our last condition is slightly different from its counterparts in Ge et al. (2015); Sun et al. (2015), we argue that it is often easier to establish the condition stated here (e.g., see Appendix B). 6. Actually, it seems that our condition is also required in the proof of Ge et al. (2015)[Lemma 34] (see equation 121).",
      "startOffset" : 72,
      "endOffset" : 296
    }, {
      "referenceID" : 19,
      "context" : "The following lemma, which follows from a simple application of the Matrix Bernstein inequality (Tropp (2015)[Section 1.",
      "startOffset" : 97,
      "endOffset" : 110
    }, {
      "referenceID" : 1,
      "context" : "A central problem in machine learning is to compute the tensor decomposition of a given tensor T (Anandkumar et al. (2014)).",
      "startOffset" : 98,
      "endOffset" : 123
    }, {
      "referenceID" : 1,
      "context" : "A central problem in machine learning is to compute the tensor decomposition of a given tensor T (Anandkumar et al. (2014)). While we have exponentially many equivalent solutions, the average of two solutions does not form a solution. Hence, any reasonable formulation of this problem must be non-convex. Luckily, as was shown in Ge et al. (2015), there exists a strict saddle formulation of this problem.",
      "startOffset" : 98,
      "endOffset" : 347
    }, {
      "referenceID" : 7,
      "context" : "Lemma 22 (Ge et al. (2015)) Suppose that T admits a Tensor decomposition as in (3).",
      "startOffset" : 10,
      "endOffset" : 27
    }, {
      "referenceID" : 7,
      "context" : "Although our definition of strict saddle functions in the constrained setting is slightly different from its counterpart in Ge et al. (2015), it is not hard to show that Lemma 22 still holds (see Appendix B).",
      "startOffset" : 124,
      "endOffset" : 141
    }, {
      "referenceID" : 7,
      "context" : "Although our definition of strict saddle functions in the constrained setting is slightly different from its counterpart in Ge et al. (2015), it is not hard to show that Lemma 22 still holds (see Appendix B). In applications, we often have access to T only through a stochastic oracle. Following Ge et al. (2015), we consider the following formulation of ICA.",
      "startOffset" : 124,
      "endOffset" : 313
    }, {
      "referenceID" : 7,
      "context" : "Furthermore, as was shown in Ge et al. (2015), one can efficiently compute a stochastic gradient and use SGD to optimize this objective.",
      "startOffset" : 29,
      "endOffset" : 46
    }, {
      "referenceID" : 11,
      "context" : "This intuition has been made precise by Nesterov and Polyak (Nesterov and Polyak (2006)).",
      "startOffset" : 40,
      "endOffset" : 88
    }, {
      "referenceID" : 6,
      "context" : "More surprisingly, in Ge et al. (2015) it was shown that a variant of SGD also converges to a local minimum.",
      "startOffset" : 22,
      "endOffset" : 39
    }, {
      "referenceID" : 0,
      "context" : "Recent improvements in terms of runtime are given in Agarwal et al. (2016); Levy (2016).",
      "startOffset" : 53,
      "endOffset" : 75
    }, {
      "referenceID" : 0,
      "context" : "Recent improvements in terms of runtime are given in Agarwal et al. (2016); Levy (2016).",
      "startOffset" : 53,
      "endOffset" : 88
    }, {
      "referenceID" : 11,
      "context" : "Stability of SGD Recently, Hardt et al. (2015) analyzed the stability of the SGD algorithm both in a convex and nonconvex setting.",
      "startOffset" : 27,
      "endOffset" : 47
    }, {
      "referenceID" : 11,
      "context" : "Stability of SGD Recently, Hardt et al. (2015) analyzed the stability of the SGD algorithm both in a convex and nonconvex setting. As we mentioned above, in our setting, SGD forms an empirical risk minimizer. Our bounds on the stability rate of SGD in this setting improve over the (more general) bounds of Hardt et al. (2015). In particular, our bounds imply that SGD can be trained for arbitrarily long time.",
      "startOffset" : 27,
      "endOffset" : 327
    }, {
      "referenceID" : 14,
      "context" : "Generalization Bounds using SGD It is known that one can obtain generalization bounds directly using SGD (Shalev-Shwartz and Ben-David (2014)[Chapter 14]).",
      "startOffset" : 106,
      "endOffset" : 142
    }, {
      "referenceID" : 7,
      "context" : "Hence, the time complexity bound of Ge et al. (2015) translates into identical sample complexity bound.",
      "startOffset" : 36,
      "endOffset" : 53
    }, {
      "referenceID" : 6,
      "context" : "Fast rates for PCA Generalization bounds for stochastic PCA have been studied in Bousquet and Elisseeff (2002); Gonen et al.",
      "startOffset" : 81,
      "endOffset" : 111
    }, {
      "referenceID" : 6,
      "context" : "Fast rates for PCA Generalization bounds for stochastic PCA have been studied in Bousquet and Elisseeff (2002); Gonen et al. (2016). Both works prove an upper bound of 1/ √ n on the generalization error in the general case.",
      "startOffset" : 81,
      "endOffset" : 132
    } ],
    "year" : 2017,
    "abstractText" : "We derive bounds on the sample complexity of empirical risk minimization (ERM) in the context of minimizing non-convex risks that admit the strict saddle property. Recent progress in non-convex optimization has yielded efficient algorithms for minimizing such functions. Our results imply that these efficient algorithms are statistically stable and also generalize well. In particular, we derive fast rates which resemble the bounds that are often attained in the strongly convex setting. We specify our bounds to Principal Component Analysis and Independent Component Analysis. Our results and techniquesmay pave the way for statistical analyses of additional strict saddle problems.",
    "creator" : "LaTeX with hyperref package"
  }
}