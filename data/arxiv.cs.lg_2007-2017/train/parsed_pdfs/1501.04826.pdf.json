{
  "name" : "1501.04826.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : null,
    "authors" : [ "José L. Balcázar" ],
    "emails" : [ ],
    "sections" : [ {
      "heading" : null,
      "text" : "ar X\niv :1\n50 1.\n04 82\n6v 1\n[ cs\n.L O\n] 2\n0 Ja\nWe study a natural variant of the implicational fragment of propositional logic. Its formulas are pairs of conjunctions of positive literals, related together by an implicational-like connective; the semantics of this sort of implication is defined in terms of a threshold on a conditional probability of the consequent, given the antecedent: we are dealing with what the data analysis community calls confidence of partial implications or association rules. Existing studies of redundancy among these partial implications have characterized so far only entailment from one premise and entailment from two premises. Here, we provide an alternative view of this entailment in terms of linear programming duality. This view allows us to characterize exactly the cases of entailment from arbitrary numbers of premises, to obtain decision algorithms of better complexity, and to prove that the confidence threshold is, actually, intrinsic to each set of premises and antecedent of the conclusion."
    }, {
      "heading" : "1 Introduction",
      "text" : "The quite deep issue of how to represent human knowledge in a way that is most useful for applications has been present in research for decades now. Often, knowledge representation is necessary in a context of incomplete information, whereby inductive processes are required in addition. As a result, two facets that are common to a great number of works in knowledge representation, and particularly more so in contexts of inductive inference, machine learning, or data analysis, are logic and probability.\nAdding probability-based mechanisms to already expressive logics enhances their expressiveness and usefulness, but pays heavy prices in terms of computational difficulty. Even without probability, certain degrees of expressivity and computational feasibility are known to be incompatible, and this is reflected in the undecidability results for many logics. In other cases, the balance between expressivity and feasibility hinges on often open complexitytheoretic statements. To work only within logics known to be polynomially tractable may imply serious expressiveness limitations.\nLiterally hundreds of studies have explored this difficult balance. Even limiting ourselves somewhat to the machine learning perspective, we could mention a large number of references such as those cited in the book [1], for one.\nBoth in machine learning and in data mining, one particularly well-studied knowledge representation mechanism is given by relaxed implication connectives: a relatively natural abstract concept which can be made concrete in various ways. The common idea is to relax the semantics of the implication connective so as to allow for exceptions, a feature actually mandatory in all applications in data analysis or machine learning. However, this can be done in any of a number of ways; and each form of endowing relaxed implications with a precise meaning yields a different notion with, often, very different properties. See the survey [2].\nThis paper focuses on one of the simplest forms of relaxed implication, endowed with its most natural semantics: the one given by conditional probability. Syntactically, these partial implications are pairs of conjunctions of positive propositional literals. For sets X and Y of propositional variables, we write the corresponding implication as X → Y . Now, instead of the classical semantics, whereby a model satisfies the implication if it either fails the antecedent or fulfills the consequent, we want to quantify exceptions; hence, instead of individual propositional models, our semantic structures are, then, so-called “transactional datasets”, that is, multisets of propositional models. By mere counting, we find, on each dataset, a frequentist probability for X and Y seen as conjunctions (or, equivalently, as events): then, the meaning of the implication is simply that the conditional probability of the consequent, given the antecedent, exceeds some fixed threshold, here denoted γ ∈ (0, 1). In application-aware works, very often that quantity, the frequentist conditional probability, is called confidence of the partial implication. We also use this name here.\nThis probabilistic version of implications has been proposed in different research communities. For instance, [3] introduced them as “partial implications”; much later, [4] defined “association rules” (see also [5] and the survey [6]): these are partial implications that impose the additional condition that the consequent is a single propositional variable, and where additional related parameters are used to assess their interest.\nActually, confidence does not seem to be the best choice in practice for the meaning of a partial implication, as discussed e.g. in [2]. However, it is clearly the most natural choice and the obvious step to start the logical study of partial implications, many other preferable options being themselves, actually, variations or sophistications of confidence.\nMotivated by practical issues, several works have analyzed notions of redundancy among partial implications: two proposals in [7] and [8] turned out to be equivalent among them and were, in turn, as described in [9], equivalent to the natural notion of logical entailment of one partial implication by another (modulo minor details such as allowing or disallowing empty antecedents or consequents). This entailment means that any dataset in which the premise reaches confidence at least γ must assign confidence at least γ as well to the conclusion.\nThe contributions of [9] that are relevant to the present paper are chiefly syntactic characterizations of one partial implication entailing another, and of two partial implications entailing another. Further details are provided below; for the time being, we simply indicate\nthat, whereas the case of one premise is quite natural, the case of two premises is quite complex. For perspective, let’s briefly consider here the case of transitivity. In contrast with full implications, which obey it, here transitivity fails: it is not difficult to see that, if X → Y has confidence over γ, and Y → Z as well, still most occurrences of Y could be without X , leaving low or even zero confidence for X → Z. Even if we consider X → Y and XY → Z, the probabilities multiply together and leave just γ2 < γ as provable threshold. (Cf. [9])\nA tempting intuition is to generalize the observation and jump to the statement that no nontrivial consequence follows from two partial implications; however, this statement is wrong, and an explicit example of proper entailment from two premises is given in the same reference and restated below in Section 3.\nBesides offering this observation, [9] goes beyond, and generalizes the example into a precise characterization of when a partial implication is entailed by two partial implications. The proof is not deep, using just basic set-theoretic constructions; but it is long, cumbersome, and of limited intuitive value. Attempts at generalizing it directly to more than two premises rapidly reach unmanageable difficulties, among which the most important one is the lack of hints at a crucial property that we will explain below in Section 6.1.\nHere, we identify an alternative, quite different approach, that turns out to be successful in finding the right generalization. Our main new ingredient is a characterization of when k partial implications entail another one, in terms of a natural linear program associated to the entailment, and its dual. More precisely, our main results are:\n1) we provide a characterization of when k partial implications entail another one in terms of linear programming and its duality theory;\n2) for low enough values of the confidence threshold γ, we use this characterization to show that k partial implications never entail nontrivially another one;\n3) for high enough values of γ, we use it also to provide a characterization of the cases in which k partial implications entail another one, but this one purely in terms of elementary Boolean algebraic conditions among the sets of attributes that make the partial implications;\n4) for the intermediate values of γ, we explain how to compute the exact threshold, if any, at which a specific set of k partial implications entails another one.\nThe characterizations in points 1) and 3) above provide algorithms to decide if a given entailment holds. More concretely, under very general conditions including the case that γ is large, the first characterization gives an algorithm that is polynomial in the number of premises k, but exponential in the number of attributes n; and the second reverses the situation: it gives an algorithm that is polynomial in n but exponential in k. This may sound surprising since the proof of the second characterization is based on the first; but it merely reflects the fact that, in our proof of the second characterization, the theory of linear programming was just used as a technical tool.\nAt any rate, the second characterization also shows that the decision problem for entailments at large γ is in NP, and this does not seem to follow from the linear programming characterization by itself (since the program is exponentially big in n), let alone the definition of entailment (since the number of datasets on n attributes is infinite). We discuss this in Section 8."
    }, {
      "heading" : "2 Preliminaries and notation",
      "text" : "We use the terms propositional variable and attribute interchangeably. Thus, attributes take Boolean values, true or false. For a fixed set of propositional variables or attributes, we use the terms truth-assignment, propositional model, and transaction interchangeably. Thus, a transaction is simply a subset of attributes, those that would be set to true if we thought of it as a truth-assignment. Typically, our set of attributes is simply [n] := {1, . . . , n}, for a natural number n, so transactions are subsets of [n]. Fix now such a set of attributes.\nIf Z is a transaction and X is a set of attributes, we say that Z covers X if X ⊆ Z. A data-set is a multi-set of transactions: formally, a mapping from the set of all transactions to the natural numbers. If D is a data-set and X is a set of attributes, we write CD[X ] for the number of transactions in D that cover X , counted with multiplicity.\nA partial or probabilistic implication is made of a pair of finite subsets X and Y of attributes. We write them as X → Y . If X and Y are sets of attributes, we write XY to denote their union X ∪ Y . This is fully custumary and very convenient notation in this context. Let X → Y be a partial implication with all its attributes in [n]. If D is a dataset on the set of attributes [n], and γ is a real parameter in the interval [0, 1], we write D |=γ X → Y if either CD[X ] = 0, or else CD[XY ]/CD[X ] ≥ γ. Thus, if we think of D as specifying the probability distribution on the set of transactions that assigns probabilities proportionally to their multiplicity in D, then D |=γ X → Y if and only if the conditional probability of Y given X is at least γ.\nIf X0 → Y0, . . . , Xk → Yk are partial implications, we write\nX1 → Y1, . . . , Xk → Yk |=γ X0 → Y0 (1)\nif for every data-set D for which D |=γ Xi → Yi holds for every i ∈ [k], it also holds that D |=γ X0 → Y0. Note that the symbol |=γ is overloaded much in the same way that the symbol |= is overloaded in propositional logic. In case (1) holds, we say that the entailment holds, or that the set X1 → Y1, . . . , Xk → Yk entails X0 → Y0 at confidence level γ. If Σ is a set of partial implications for which Σ |=γ X0 → Y0 holds but Γ |=γ X0 → Y0 does not hold for any proper subset Γ ⊂ Σ, then we say that the entailment holds properly. Note that entailments without premises vacuously hold properly when they hold. The real number γ is often referred to as the confidence parameter.\nA linear program (LP) is the following optimization problem: min{cTx : Ax ≥ b, x ≥ 0}, where x is a vector of n real variables, b and c are vectors in Rm and Rn, respectively, and A is a matrix in Rm×n. The program is feasible if there exists an x ∈ Rn such that Ax ≥ b and x ≥ 0. The program is unbounded if there exist feasible solutions with arbitrarily small values of the objective function cTx. If the goal were max instead of min, unboundedness would refer to arbitrarily large values of the objective function. The dual LP is max{bTy : ATy ≤ c, y ≥ 0}, where y is a vector of m real variables. Both LPs together are called a primal-dual pair. The duality theorem of linear programming states that exactly one of the following holds: either both primal and dual are infeasible, or one is unbounded and the other is infeasible, or both are feasible and have optimal points with the same optimal value. See [10][Corollary 25 and Theorem 23]."
    }, {
      "heading" : "3 Entailment with up to two premises",
      "text" : "We review here the results from [9] on entailments among partial implications with one or two premises. The study there starts with a detailed comparison of entailment as defined in Section 2 with the notions of redundancy among partial implications previously considered in the literature. Here we go directly to the point and consider entailment as defined in Section 2 from the start.\nFor this section and most of the paper we assume that the confidence parameter γ is strictly positive; otherwise everything holds everywhere, and strictly below 1; otherwise we fall back to classical implication. The case of zero premises, i.e. tautological partial implications, trivializes to the classical case: |=γ X0 → Y0 if and only if Y0 ⊆ X0, at any positive confidence level γ. The first interesting case is thus the entailment from one partial implication X1 → Y1 to another X0 → Y0. If X0 → Y0 is tautological by itself, there is nothing else to say. Otherwise, entailment is still characterized by a simple Boolean algebraic condition on the sets X0, Y0, X1, and Y1 as stated in the following theorem:\nTheorem 1 ([9]). Let γ be a confidence parameter in (0, 1) and let X0 → Y0 and X1 → Y1 be two partial implications. Then the following are equivalent:\n1. X1 → Y1 |=γ X0 → Y0,\n2. either Y0 ⊆ X0, or X1 ⊆ X0 and X0Y0 ⊆ X1Y1.\nNote that the second statement is independent of γ. This shows that entailment at confidence γ below 1 differs from classical entailment. An example shows this equally well: although it is obvious that A → B classically entails AC → BC, the entailment fails badly when both the premise and the conclusion are considered as partial implications at some confidence γ in (0, 1): any data-set with many ocurrences of AB, only one occurrence of AC, and none at all of BC, ruins everything. Of course, what fails is that X0Y0 is not included in X1Y1.\nThe case of two partial implications entailing a third was also solved in [9]. The starting point for that study was a specific example of a non-trivial entailment:\nA → BC, A → BD |=1/2 ACD → B. (2)\nIndeed, this entailment holds true at any γ in the interval [1/2, 1). This is often found counterintuitive. The intuition of many is that combining two partial implications that only guarantee the threshold γ would lead to arithmetic operations leading to values unavoidably below γ. Classical transitivity as discussed in the introduction is a good example. However, this intuition is incorrect, as (2) shows. The good news is that a similar statement, when appropriately generalized, covers all the cases of entailment from two partial implication premises. We omit the proof of (2) as it follows from the next theorem, which will be generalized in our main result.\nTheorem 2 ([9]). Let γ be a confidence parameter in (0, 1) and let X0 → Y0, X1 → Y1 and X2 → Y2 be three partial implications. If γ ≥ 1/2, then the following are equivalent:\n1. X1 → Y1, X2 → Y2 |=γ X0 → Y0,\n2. either Y0 ⊆ X0, or Xi ⊆ X0 and X0Y0 ⊆ XiYi for some i ∈ {1, 2}, or all seven inclusions below hold simultaneously:\n(a) X1 ⊆ X2Y2 and X2 ⊆ X1Y1, (b) X1 ⊆ X0 and X2 ⊆ X0, (c) X0 ⊆ X1X2Y1Y2. (d) Y0 ⊆ X0Y1 and Y0 ⊆ X0Y2,\nIndeed, the characterization is even tighter than what this statement suggests: whenever γ < 1/2, it can be shown that entailment from two premises holds only if it holds from one or zero premises. This was also proved in [9], thus fully covering all cases of entailment with two premises and all confidence parameters γ. Note, finally, that all conditions stated in the theorem are easy to check by an algorithm running in time O(n), where n is the number of attributes, if the sets are given as bit vectors, say.\nThe proof of Theorem 2 in [9] is rather long and somewhat involved, although it uses only elementary Boolean algebraic manipulation. For instance, several different counterexamples to the entailment are built ad-hoc depending on which of the seven set-inclusion conditions fail. Its intuition-building value is, however, pretty limited, and a generalization to the case of more than two premises remained ellusive. A somewhat subtle point about Theorem 2 is that the seven inclusion conditions alone do not characterize proper entailment (even if γ ≥ 1/2, that is): they are only necessary conditions for that. But when these necessary conditions for proper entailment are disjuncted with the necessary and sufficient conditions for improper entailment, what results is an if and only if characterization of entailment. That is why the theorem is stated as it is, with the two escape clauses at the beginning of part 2. Our main result will have a similar flavour, but with fewer cases to consider.\nBefore we move on to larger numbers of premises, one more comment is in order. Among the seven set-inclusion conditions in the statement of Theorem 2, those in the first item X1 ⊆ X2Y2 and X2 ⊆ X1Y1 are by far the least intuitive. Discovering the right generalization of this turned out to be the key to getting our results. This is discussed in Sections 6.1 and 6.3. Before that, however, we need to discuss a characterization of entailment in terms of linear programming duality. Interestingly, LP will end up disappearing altogether from the statement that generalizes Theorem 2; its use will merely be a (useful) technical detour."
    }, {
      "heading" : "4 Entailment in terms of LP duality",
      "text" : "The goal in this section is to characterize the valid entailments of the form\nX1 → Y1, . . . , Xk → Yk |=γ X0 → Y0, (3)\nwhere each Xi → Yi is a partial implication on the set of attributes [n]. Before we state the characterization, we want to give some intuition for what to expect. At the same time we introduce some notation and terminology."
    }, {
      "heading" : "4.1 LP characterization",
      "text" : "Following standard usage in full implications (see e.g. [11]), we say that a transaction Z ⊆ [n] covers X → Y if X ⊆ Z, and that it violates it if X ⊆ Z but Y 6⊆ Z. If Z covers X → Y without violating it, that is, XY ⊆ Z, we say that Z witnesses X → Y . For each partial implication X → Y and each transaction Z we define a weight wZ(X → Y ) that, intuitively, measures the extent to which Z witnesses X → Y . Moreover, since we are aiming to capture confidence level γ we assign the weight proportionally:\nwZ(X → Y ) = 1− γ if Z witnesses X → Y, wZ(X → Y ) = −γ if Z violates X → Y, wZ(X → Y ) = 0 if Z does not cover X → Y.\nWith these weights in hand we give a quantitative interpretation to the entailment in (3). First note that the weights are defined in such a way that, as long as γ > 0, a transaction Z satisfies the implication X → Y interpreted classically if and only if wZ(X → Y ) ≥ 0. With this in mind the entailment in (3) interpreted classically would read as follows: for all Z, whenever all weights on the left are non-negative, the weight on the right is also nonnegative. Of course, a sufficient condition for this to hold would be that the weights on the right are bounded below by some non-negative linear combination of the weights on the left, uniformly over Z. What the characterization below says is that this sufficient condition for classical entailment is indeed necessary and sufficient for entailment at confidence level γ, if the weights are chosen proportionally to γ as above. Formally:\nTheorem 3. Let γ be a confidence parameter in [0, 1] and let X0 → Y0, . . . , Xk → Yk be a set of partial implications. The following are equivalent:\n1. X1 → Y1, . . . , Xk → Yk |=γ X0 → Y0\n2. There is a vector λ = (λ1, . . . , λk) of real non-negative components such that for all Z ⊆ [n]\nk ∑\ni=1\nλi · wZ(Xi → Yi) ≤ wZ(X0 → Y0) (4)\nWe develop the proof of this theorem below. The aspect of the inequalities in the statement of the characterization might easily suggest to the reader that indeed linear programming techniques are at play. Subsequent study of the properties of the components of the vector λ will lead us in a later section to reach a precise characterization of entailment from any number of premises, assuming the threshold γ to be high enough. Steps towards understanding the rather complex situation for lower γ are provided later.\nTowards the proof of Theorem 3, let us state a useful lemma. This gives an alternative understanding of the weights wZ(X → Y ) than the one given above:\nLemma 4. Let γ be a confidence parameter in [0, 1], let X → Y be a partial implication, let D be a transaction multiset, and for each Z ⊆ [n] let xZ be the multiplicity of Z in D, that is, the number of times that Z appears (as a complete transaction) in D. Then, D |=γ X → Y if and only if ∑\nZ⊆[n]wZ(X → Y ) · xZ ≥ 0.\nProof. Let U denote the set of transactions in D that cover X → Y , let V denote those that violate X → Y , and W those that witness X → Y . Observe that U = V ∪W and that this union is a partition. By definition, D |=γ X → Y means that either ∑\nZ∈U xZ = 0, or else ( ∑\nZ∈W xZ ) / ( ∑ Z∈U xZ ) ≥ γ. Recalling that V ∪W = U is a partition, this is equivalent to ∑\nZ∈W xZ ≥ γ · ( ∑ Z∈W xZ + ∑ Z∈V xZ ) . Rearranging we get ∑ Z∈W(1−γ)·xZ− ∑\nZ∈V γ ·xZ ≥ 0, from which the result follows by recalling that wZ(X → Y ) = 1− γ for each Z ∈ W and wZ(X → Y ) = −γ for each Z ∈ V, and that wZ(X → Y ) = 0 for every other Z.\nWith this lemma in hand we can prove Theorem 3.\nProof of Theorem 3. The statement of Lemma 4 leads to a natural linear program: for every Z let xZ be a non-negative real variable, impose on these variables the inequalities from Lemma 4 for X1 → Y1 through Xk → Yk, and check if the corresponding inequality for X0 → Y0 can be falsified by minimizing its left-hand side:\nP : min ∑\nZ⊆[n]wZ(X0 → Y0) · xZ\ns.t. ∑\nZ⊆[n]wZ(Xi → Yi) · xZ ≥ 0 all i ∈ [k],\nxZ ≥ 0 all Z.\nThe dual D of P has one non-negative variable yi for every i ∈ [k] and one inequality constraint for each non-negative variable xZ . Since the objective function of D would just be the trivial constant function 0 we write it directly as a linear programming feasibility problem:\nD: ∑\ni∈[k]wZ(Xi → Yi) · yi ≤ wZ(X0 → Y0) all Z,\ny1, . . . , yk ≥ 0\nNote that this is really the characterization statement in the theorem that we are trying to prove, with yi in place of λi. Thus, the theorem will be proved if we show that the following are equivalent:\n(1) X1 → Y1, . . . , Xk → Yk |=γ X0 → Y0,\n(2) the primal P is feasible and bounded below,\n(3) the dual D is feasible.\n(1) ⇒ (2). We prove the contrapositive. Assume that P is unbounded below; it is certainly feasible since the all-zero vector satisfies all constraints. Let x be a feasible solution with ∑\nZ⊆[n]wZ(X0 → Y0) · xZ < 0. Since the rationals are dense in the reals and linear maps are surely continuous, we may assume that x has rational components with a positive common denominator N , while preserving feasibility and a negative value for the objective function. Then N ·x is still a feasible solution and its components are natural numbers. Let D be the transaction multiset that has N · xZ copies of Z for every Z ⊆ [n]. By feasibility we have ∑\nZ⊆[n]wZ(Xi → Yi) ·N · xZ ≥ 0 and therefore D |=γ Xi → Yi for every i ∈ [k] by\nLemma 4. On the other hand ∑\nZ⊆[n]wZ(X0 → Y0) · N · xZ < 0 from which it follows that\nD 6|=γ X0 → Y0, again by Lemma 4. (2) ⇒ (3). This is a direct consequence of the duality theorem for linear programming: if P is feasible and bounded below, D is feasible; see the preliminaries and the references there.\n(3) ⇒ (1). Assume D is feasible and let y be a feasible solution. Let D be a transaction multiset such that D |=γ Xi → Yi for every i ∈ [k]. For every Z ⊆ [n], let xZ be the number of times that Z appears (alone, as a complete transaction) in D. By dual feasibility of y and positivity of xZ we get\n∑\nZ⊆[n]\nwZ(X0 → Y0) · xZ ≥ ∑\nZ⊆[n]\n(\n∑\ni∈[k]\nwZ(Xi → Yi) · yi ) · xZ .\nDistributing, exchanging the order of summation, and refactoring, the right-hand side reads\n∑\ni∈[k]\nyi · ( ∑\nZ⊆[n]\nwZ(Xi → Yi) · xZ ) .\nNote that this is non-negative since the yi are non-negative and ∑ Z⊆[n]wZ(Xi → Yi) ·xZ ≥ 0 for every i ∈ [k] by the assumption on D and Lemma 4. This proves that ∑\nZ⊆[n]wZ(X0 →\nY0) · xZ ≥ 0, from which D |=γ X0 → Y0 follows by one more call to Lemma 4."
    }, {
      "heading" : "4.2 Properties of the LP characterization",
      "text" : "Whenever an entailment as in (3) holds properly, the characterization in Theorem 3 gives a good deal of information about the inclusion relationships that the sets satisfy, and about the values that the λi can take. In this section we discuss this. Note that, from now on, the confidence parameter γ is in (0, 1) instead of [0, 1].\nLemma 5. Let γ be a confidence parameter in (0, 1) and let X0 → Y0, . . . , Xk → Yk be a set of partial implications with k ≥ 1. Assume that the entailment X1 → Y1, . . . , Xk → Yk |=γ X0 → Y0 holds properly. In particular, Y0 6⊆ X0. Let λ = (λ1, . . . , λk) denote any vector as promised to exist by Theorem 3 for this entailment. The following hold:\n1. λi > 0 for every i ∈ [k].\n2. X0Y0 ⊆ X1Y1 · · ·XkYk. 3. ∑\ni∈[k] λi ≤ 1.\n4. Xi ⊆ X0 for every i ∈ [k].\n5. XiYi 6⊆ X0 for every i ∈ [k]. 6. ∑\ni∈[k] λi = 1.\n7. Y0 ⊆ X0Yi for every i ∈ [k].\nProof. The order in which we state them is the one that we deem best to follow smoothly the flow of proofs, as some of them are proved jointly and/or depend on previous ones. In what follows, for every Z, define:\nUZ = {i ∈ [k] : Z covers Xi → Yi},\nVZ = {i ∈ [k] : Z violates Xi → Yi},\nWZ = {i ∈ [k] : Z witnesses Xi → Yi}.\nNote that UZ = VZ ∪WZ and that this union is a partition. 1. For every i ∈ [k], if λi = 0, then the inequalities in (4) reduce to the same inequalities for the entailment without the i-th premise, and the remaining λj would still be a solution. Then, by Theorem 3 itself the entailment would not be proper, as premise i could be removed without affecting its validity.\n2. Consider the inequality in (4) for Z = X1Y1 · · ·XkYk. Obviously Z witnesses every Xi → Yi, so WZ = [k]. Assume for contradiction that X0Y0 6⊆ X1Y1 · · ·XkYk. Then the inequality reads either −γ ≥ (1 − γ) · ∑\ni∈[k] λi or 0 ≥ (1 − γ) · ∑\ni∈[k] λi, and both cases are impossible since the right-side is strictly positive by the previous item and the fact that γ < 1. Therefore X0Y0 ⊆ X1Y1 · · ·XkYk.\n3. Considering still the same inequality, we know now that it reads 1 − γ ≥ (1 − γ) · ∑\ni∈[k] λi. From this we conclude that ∑ i∈[k] λi ≤ 1 since γ < 1.\n4, 5 and 6. Now consider the inequality in (4) for Z = X0. As the entailment is proper we have Y0 6⊆ X0 = Z and therefore Z violates X0 → Y0. So the inequality reads −γ ≥ (1− γ) · ∑\ni∈WZ λi − γ ·\n∑\ni∈VZ λi. As λi ≥ 0 we get −γ ≥ −γ ·\n∑\ni∈VZ λi and therefore\n∑\ni∈VZ λi ≥ 1 since γ > 0. But also\n∑\ni∈[k] λi ≤ 1 from which it follows that VZ = [k] since each λi is strictly positive. Thus Z violates every Xi → Yi, so Xi ⊆ Z = X0 and XiYi 6⊆ Z = X0 for every i. Also ∑ i∈[k] λi = 1 follows.\n7. For every i ∈ [k], consider the inequality in (4) for Z = X0Yi. We proved in item 4 that Xi ⊆ X0. It follows that XiYi ⊆ X0Yi = Z and thus i ∈ WZ . Now assume for contradiction that Y0 6⊆ Z. Then Z violates X0 → Y0 and the inequality reads −γ ≥ (1− γ) · ∑\nj∈WZ λj − γ ·\n∑\nj∈VZ λj . Since i ∈ WZ and λj ≥ 0 for every j ∈ [k], the right-hand\nside of this inequality is at least (1 − γ) · λi − γ · ∑ j∈[k]\\{i} λj = λi − γ · ∑ j∈[k] λj. But this is strictly bigger than −γ since λi > 0 by item 1 and ∑\nj∈[k] λi ≤ 1 by item 3. This contradiction proves that the assumption Y0 6⊆ Z was wrong. Thus Y0 ⊆ Z = X0Yi."
    }, {
      "heading" : "5 Low thresholds",
      "text" : "As it turns out, if the confidence parameter γ is too low, then there cannot be any entailment as in (3) that does not already follow from one of its premises. In such a case the characterization follows from known ones. This is what the next theorem states:\nTheorem 6. Let γ be a confidence parameter in (0, 1) and let X0 → Y0, . . . , Xk → Yk be a set of partial implications with k ≥ 1. If γ < 1/k, then the following are equivalent:\n1. X1 → Y1, . . . , Xk → Yk |=γ X0 → Y0,\n2. Xi → Yi |=γ X0 → Y0 for some i ∈ [k],\n3. either Y0 ⊆ X0, or Xi ⊆ X0 and X0Y0 ⊆ XiYi for some i ∈ [k].\nProof. The equivalence between 2. and 3. follows from the characterization of entailments with one premise. We prove the equivalence between 1. and 2., and for that we just need to argue the implication 1. to 2. since the other one is obvious. Assume 1. and let L ⊆ [k] be minimal under set inclusion so that {Xi → Yi : i ∈ L} |=γ X0 → Y0. If |L| ≤ 1 we already have what we want. Assuming |L| ≥ 2 we prove γ ≥ 1/k; this will prove the theorem.\nLet λ = (λi : i ∈ L) be a solution to the inequalities in (4) for {Xi → Yi : i ∈ L} |=γ X0 → Y0 as per Theorem 3. By the minimality of L, the entailment {Xi → Yi : i ∈ L} |=γ X0 → Y0 is proper. As γ is in the interval (0, 1) and |L| ≥ 1 (indeed ≥ 2), Lemma 5 applies to {Xi → Yi : i ∈ L} |=γ X0 → Y0 and says that Xi ⊆ X0 for every i ∈ L, by part 4. Consequently, by the fact that |L| ≥ 2, the minimality of L, and the characterization of entailment with at most one premise (Theorem 1), we have X0Y0 6⊆ XiYi for every i ∈ L. Now, for fixed i ∈ L, let us look at the inequality in (4) for Z = XiYi. The above says that Z does not witness X0 → Y0 so wZ(X0 → Y0) ≤ 0. Of course Z witnesses Xi → Yi, so wZ(Xi → Yi) = 1 − γ. Any other weight is at least −γ. Therefore, the inequality implies the following: 0 ≥ λi · (1 − γ) − γ · ∑ j∈L\\{i} λj = λi − γ · ∑ j∈L λj. By Lemma 5, part 3, we have ∑\nj∈L λj ≤ 1. We conclude that λi ≤ γ, and this holds for every i ∈ L. Adding over i ∈ L we get ∑\ni∈L λi ≤ γ · |L|, and the left-hand side is 1 by Lemma 5, part 6. Thus γ ≥ 1/|L| ≥ 1/k and the theorem is proved."
    }, {
      "heading" : "6 High thresholds",
      "text" : "The goal of this section is to characterize entailments from k partial implications when the confidence parameter γ is large enough, and our proofs will show that (k − 1)/k is enough. Ideally, the characterization should make it easy to decide if an entailment holds, or at least easier than solving the linear program given by Theorem 3. We come quite close to that. Before we get into the characterization, let us first discuss the key new concept on which it rests."
    }, {
      "heading" : "6.1 Enforcing homogeneity",
      "text" : "We say that a set of partial implications X1 → Y1, . . . , Xk → Yk enforces homogeneity if for every Z the following holds:\nif for all i ∈ [k] either Xi 6⊆ Z or XiYi ⊆ Z holds, then either Xi 6⊆ Z holds for all i ∈ [k]\nor XiYi ⊆ Z holds for all i ∈ [k].\nIn words, enforcing homogeneity means that every Z that does not violate any Xi → Yi, either witnesses them all, or does not cover any of them. Note that this definition does not\ndepend on any confidence parameter. For economy of words, sometimes we refer to a set of partial implications that enforces homogeneity as being nice.\nNote also that the empty set of partial implications vacuously enforces homogeneity; in fact, sets with less than two elements are trivially nice.\nHomogeneity sounds like a very strong requirement. However, as the following lemma shows, it is at the heart of proper entailments.\nLemma 7. Let X1 → Y1, . . . , Xk → Yk be a set of partial implications with k ≥ 1. If there exists a partial implication X0 → Y0 and a confidence parameter γ in the interval (0, 1) for which the entailment X1 → Y1, . . . , Xk → Yk |=γ X0 → Y0 holds properly, then X1 → Y1, . . . , Xk → Yk enforces homogeneity.\nProof. Fix X0 → Y0 and γ as in the statement of the lemma. We must show that if Z does not violate Xi → Yi for any i ∈ [k], then either Z witnesses all of them, or Z does not cover any of them. Fix Z that does not violate Xi → Yi for any i ∈ [k]. In particular, for every i ∈ [k], either Z does not cover Xi → Yi, or Z witnesses Xi → Yi. Thus wZ(Xi → Yi) ≥ 0 for every i ∈ [k]. If Z does not cover Xj → Yj for any j ∈ [k] we are done. Assume then that Z covers Xj → Yj for some j ∈ [k]. Since it does not violate it, it witnesses it, which means that wZ(Xj → Yj) = 1− γ.\nNow let us take a solution λ = (λ1, . . . , λk) as promised by Theorem 3, and let us consider the inequality in (4) for our fixed Z. This inequality reads wZ(X0 → Y0) ≥ ∑ i∈[k] λi · wZ(Xi → Yi). Since we proved that wZ(Xi → Yi) ≥ 0 for every i ∈ [k], the right-hand side is at least λj ·wZ(Xj → Yj), which is λj · (1− γ), for the j from the previous paragraph. Now, by Lemma 5.1 we have λj > 0 because the entailment is proper. Putting all this together we get wZ(X0 → Y0) > 0, so Z witnesses X0 → Y0. Thus X0Y0 ⊆ Z. But we also know that Xi ⊆ X0 for every i ∈ [k] by Lemma 5.4. Thus Xi ⊆ Z for every i ∈ [k]. Since Z does not violate Xi → Yi for any i ∈ [k], it must then be that Z witnesses Xi → Yi for every i ∈ [k]. Precisely what we were trying to prove.\nThe next lemma in this section characterizes nicety. For a partial implication X → Y , let X ⇒ Y denote its classical counterpart. Naturally, we write Z |= X ⇒ Y if either X 6⊆ Z or XY ⊆ Z, i.e. if Z satisfies the implication classically. Also, in the context of classical implications, we use |= to denote classical entailment.\nLemma 8. Let X1 → Y1, . . . , Xk → Yk be a set of partial implications and let U = X1Y1 · · ·XkYk. Then, the following are equivalent:\n1. X1 → Y1, . . . , Xk → Yk enforces homogeneity,\n2. X1 ⇒ Y1, . . . , Xk ⇒ Yk |= Xi ⇒ U , all i ∈ [k].\nProof. Assume X1 → Y1, . . . , Xk → Yk enforces homogeneity. Let Z |= Xi ⇒ Yi for all i ∈ [k]. Then, by homogeneity, either Xi 6⊆ Z for all i ∈ [k], and then it also holds Z |= Xi ⇒ U for all i ∈ [k], or XiYi ⊆ Z for all i ∈ [k] so that U ⊆ Z, and Z |= Xi ⇒ U for all i ∈ [k] as well. Therefore, X1 ⇒ Y1, . . . , Xk ⇒ Yk entail every Xi ⇒ U .\nConversely, assume that X1 ⇒ Y1, . . . , Xk ⇒ Yk entail every Xi ⇒ U and let Z |= Xi ⇒ Yi for all i ∈ [k], hence Z |= Xi ⇒ U for all i ∈ [k]. Then either U ⊆ Z and we are done, or, else, the only way to satisfy all these classical implications is by falsifying all the premises, so that Xi 6⊆ Z for all i ∈ [k]. Therefore we have proved that X1 → Y1, . . . , Xk → Yk enforces homogeneity.\nThis characterization is quite useful. Look at the set of three partial implications B → ACH,C → AD,D → AB on the attributes A,B,C,D,H . By the lemma this set enforces homogeneity, but any of its two-element subsets fails to do so. Note also that condition 2. in the lemma can be decided efficiently by testing the unsatisfiability of all the propositional Horn formulas of the form (X1 ⇒ Y1) ∧ · · · ∧ (Xk ⇒ Yk) ∧Xj ∧ ¬A as j ranges over [k] and A ranges over the attributes in U ."
    }, {
      "heading" : "6.2 Main result for high threshold",
      "text" : "We are ready to state and prove the characterization theorem for γ ≥ (k − 1)/k.\nTheorem 9. Let γ be a confidence parameter in (0, 1) and let X0 → Y0, . . . , Xk → Yk be a set of partial implications with k ≥ 1. If γ ≥ (k − 1)/k, then the following are equivalent:\n1. X1 → Y1, . . . , Xk → Yk |=γ X0 → Y0,\n2. there is a set L ⊆ [k] such that {Xi → Yi : i ∈ L} |=γ X0 → Y0 holds properly,\n3. either Y0 ⊆ X0, or there is a non-empty L ⊆ [k] such that the following conditions hold:\n(a) {Xi → Yi : i ∈ L} enforces homogeneity, (b) ⋃\ni∈L Xi ⊆ X0 ⊆ ⋃ i∈L XiYi,\n(c) Y0 ⊆ X0 ∪ ⋂ i∈L Yi.\nProof. That 1. implies 2. is clear: the family of all sets L ⊆ [k] for which the entailment {Xi → Yi : i ∈ L} |=γ X0 → Y0 holds is non-empty, as 1. says that [k] belongs to it. Since it is finite it has minimal elements. Let L be one of them.\nFrom 2. to 3., the index set L will be the same in both statements, unless L = ∅, in which case Y0 ⊆ X0 must hold and we are done. Assume then that L is not empty. Part (a) we get automatically from Lemma 7 since {Xi → Yi : i ∈ L} properly entails X0 → Y0 at γ, which is in the interval (0, 1). Now we prove (b). By Theorem 3, let λ = (λi : i ∈ L) be a solution to the inequalities in (4) for the entailment {Xi → Yi : i ∈ L} |=γ X0 → Y0. From the fact that this entailment is proper and the assumptions that |L| ≥ 1 and γ ∈ (0, 1), we are allowed to call Lemma 5. The first inclusion in (b) follows from that lemma, part 4. The second inclusion in (b) also follows from that lemma, part 2. Finally, for (c) we just refer to part 7 and straightforward distributivity.\nFor the implication from 3. to 1. we proceed as follows. If Y0 ⊆ X0 there is nothing to prove since then the entailment is trivial. Assume then that L is non-empty and satisfies (a), (b), and (c). By Theorem 3 it suffices to show that the inequalities in (4) for the entailment {Xi → Yi : i ∈ L} |=γ X0 → Y0 have a solution λ = (λi : i ∈ L) with non-negative\ncomponents. Let ℓ = |L| and set λi = 1/ℓ for i ∈ L. Recall that L is not empty so ℓ ≥ 1 and this is well-defined. For fixed Z, we prove that the inequality in (4) for this Z is satisfied by these λi. In the following, let X = ⋃ i∈L Xi and Y = ⋂\ni∈L Yi. We distinguish cases according to whether X ⊆ Z.\nFirst assume that X 6⊆ Z. Then, by the first inclusion in (b), X0 6⊆ Z so Z does not cover X0 → Y0 and wZ(X0 → Y0) = 0. Also, there exists j ∈ L such that Xj 6⊆ Z. If XiYi 6⊆ Z for every i ∈ L, then Z does not witness any Xi → Yi, so wZ(Xi → Yi) ≤ 0 for every i ∈ L. Whence ∑\ni∈L λi · wZ(Xi → Yi) is non-positive and then bounded by wZ(X0 → Y0) = 0 as required. Hence, suppose now that there exists i ∈ L such that XiYi ⊆ Z. We also have a j ∈ L such that Xj 6⊆ Z. Thus Z witnesses Xi → Yi and fails to cover Xj → Yj , and both i and j are in L. As {Xi → Yi : i ∈ L} enforces homogeneity, this means that Z violates Xh → Yh for some h ∈ L. For that h we have wZ(Xh → Yh) = −γ. The rest of weights are at most 1− γ and therefore ∑\ni∈L λi · wZ(Xi → Yi) is bounded above by\n− 1\nℓ · γ +\nℓ− 1\nℓ · (1− γ) =\nℓ− 1\nℓ − γ.\nSince ℓ ≤ k, this is at most (k− 1)/k− γ. In turn, this is non-positive and then bounded by wZ(X0 → Y0) = 0 by the assumption that γ ≥ (k − 1)/k. This proves that the inequalities corresponding to these Z’s are satisfied.\nAssume now instead X ⊆ Z. In this case Z covers Xi → Yi for every i ∈ L. Thus we split L into two sets, L = V ∪W , where V is the set of indices i ∈ L such that Z violates Xi → Yi, and W is the set of indices i ∈ L such that Z witnesses Xi → Yi. Of course wZ(Xi → Yi) = −γ for every i ∈ V and wZ(Xi → Yi) = 1− γ for every i ∈ W . We consider three subcases.\n1. If W = ∅, then every Xi → Yi with i ∈ L is violated and then, using that the λi’s add up to 1, ∑\ni∈L λi · wZ(Xi → Yi) = −γ · ∑\ni∈L λi = −γ ≤ wZ(X0 → Y0); i.e. the inequality holds.\n2. If W = L, then every Xi → Yi with i ∈ L is witnessed. Using (b) we get X0 ⊆ ⋃\ni∈L XiYi ⊆ Z, and the non-emptiness of L applied to (c) ensures the existence of some i ∈ L for which Y0 ⊆ X0 ∪ Y ⊆ X0 ∪ Yi ⊆ Z. Thus X0 → Y0 is also witnessed and ∑\ni∈L λi ·wZ(Xi → Yi) = (1− γ) · ∑\ni∈L λi = 1− γ = wZ(X0 → Y0); i.e. the inequality holds. 3. We consider now the general case where W 6= ∅ and W 6= L. The fact that W 6= ∅ ensures that there is some i ∈ L such that Yi ⊆ Z. Condition (c) then ensures that Y0 ⊆ X0 ∪ Y ⊆ X0 ∪ Yi for this i. Altogether X0 → Y0 is either witnessed or uncovered according to whether X0 ⊆ Z. In both cases wZ(X0 → Y0) ≥ 0. To complete the proof, let us split ∑\ni∈L λi · wZ(Xi → Yi) as follows:\n1 ℓ · (1− γ) · |W | − 1 ℓ · γ · (|L| − |W |).\nThe fact that W 6= L implies |W | ≤ |L| − 1 = ℓ− 1. Therefore this is at most\n1 ℓ · (|W | − γ · |L|) ≤ ℓ− 1 ℓ − γ ≤ k − 1 k − γ ≤ 0 ≤ wZ(X0 → Y0).\nIn the middle inequalities we used the fact that ℓ ≤ k and the assumption that γ ≥ (k−1)/k. We proved what we want; i.e. the inequality holds.\nThis closes the cycle of implications and the theorem is proved."
    }, {
      "heading" : "6.3 Other properties of nicety",
      "text" : "Enforcing homogeneity turned out to play a key role in the main result about the case of high confidence threshold. In this section we collect a few additional observations about it. The first one is quite trivial: sets of less than two partial implications are trivially nice. This does say, however, that every set of partial implications has some nice subset. The case k = 2 is a bit more interesting. Nicety corresponds exactly to the mysterious conditions in Theorem 2; cf. the discussion in Section 3.\nLemma 10. A set of two partial implications X1 → Y1, X2 → Y2 enforces homogeneity if and only of both X1 ⊆ X2Y2 and X2 ⊆ X1Y1 hold.\nProof. Assume X1 6⊆ X2Y2. Then Z = X2Y2 |= X1 ⇒ Y1 and Z |= X2 ⇒ Y2, but this does not happen homogenously. The same holds if X2 6⊆ X1Y1 by symmetry. Conversely, if both inclusions hold, consider any Z such that Z |= X1 ⇒ Y1 and Z |= X2 ⇒ Y2. If X1 6⊆ Z, then X2Y2 6⊆ Z either, hence X2 6⊆ Z is the only way to satisfy the second implication; by symmetry, we obtain X1 6⊆ Z if and only if X2 6⊆ Z. Thus homogeneity holds.\nFinally, a recurrent situation concerns sets of partial implications with a common lefthand side. The next lemma says that every such set is nice.\nLemma 11. Every set of partial implications of the form X → Y1, . . . , X → Yk enforces homogeneity.\nProof. This is a direct application of Lemma 8."
    }, {
      "heading" : "7 Intervening thresholds",
      "text" : "The rest of the values of γ require ad-hoc consideration in terms of the actual partial implications involved. We start by defining what will end up being the critical confidence threshold for a given entailment."
    }, {
      "heading" : "7.1 Critical threshold",
      "text" : "Let Σ = {X1 → Y1, . . . , Xk → Yk} be a set of partial implications with k ≥ 1 and all its attributes in [n], and let X ⊆ [n]. Define:\nγ∗ = γ∗(Σ, X) := inf λ max Z\n∑\ni∈WZ λi\n∑\ni∈VZ∪WZ λi\n(5)\nwhere\n1. Z ranges over all subsets of [n] with X 6⊆ Z,\n2. VZ = {i ∈ [k] : Z violates Xi → Yi},\n3. WZ = {i ∈ [k] : Z witnesses Xi → Yi}, 4. λ ranges over vectors (λ1, . . . , λk) of non-negative reals such that ∑ i∈[k] λi = 1,\nand, by convention any occurrence of 0/0 in the definition of γ∗ is taken as 0, and a vacuous maximum is taken as 0. Note that this last case occurs only if X = ∅ since otherwise there is always the possibility of taking Z = ∅. Note also that since all λi are non-negative, the only way the denominator can be zero is by making the numerator also zero. It should be pointed out that the convention about 0/0 is not an attempt to repair a discontinuity; in general, the discontinuities of the rational functions inside the max are not repairable. A final comment on the definition is that we required k ≥ 1. This ensures that the inf is not vacuous, which in turn implies 0 ≤ γ∗ ≤ 1: the lower bound is obvious, and for the upper bound just take λi = 1/k for every i ∈ [k], which is well-defined when k ≥ 1.\nObserve that γ∗ is defined for a set of partial inequalities and a single set X of attributes. Typically X will be the left-hand side of another partial inequality X0 → Y0, but γ\n∗(Σ, X0) is explicitly defined not to depend on Y0. For later reference let us also point out that, with the notation VZ andWZ from above, the inequalities in (4) for an entailment X1 → Y1, . . . , Xk → Yk |=γ X0 → Y0 can be written as wZ(X0 → Y0) ≥ (1 − γ) · ∑\ni∈WZ λi − γ ·\n∑\ni∈VZ λi. It is\nnot the first time we use this sort of notation."
    }, {
      "heading" : "7.2 Characterization for all thresholds",
      "text" : "The main result of this section is a characterization theorem in the style of Theorem 9 that captures all possible confidence parameters.\nTheorem 12. Let γ be a confidence parameter in (0, 1) and let X0 → Y0, . . . , Xk → Yk be a set of partial implications with k ≥ 1. The following are equivalent:\n1. X1 → Y1, . . . , Xk → Yk |=γ X0 → Y0,\n2. there is a set L ⊆ [k] such that {Xi → Yi : i ∈ L} |=γ X0 → Y0 holds properly,\n3. either Y0 ⊆ X0, or there is a non-empty L ⊆ [k] such that the following conditions hold:\n(a) {Xi → Yi : i ∈ L} enforces homogeneity, (b) ⋃\ni∈L Xi ⊆ X0 ⊆ ⋃ i∈L XiYi,\n(c) Y0 ⊆ X0 ∪ ⋂ i∈L Yi, (d) γ ≥ γ∗({Xi → Yi : i ∈ L}, X0).\nProof. That 1. implies 2. is clear, as in Theorem 9. From 2. to 3., we may assume that L is non-empty as in Theorem 9. Let λ = (λ1, . . . , λk) be a vector of non-negative reals that satisfy the inequalities in (4) as per Theorem 3. Then properties (a), (b), and (c) just follow from Lemma 5 in the same way as in Theorem 3. It remains to argue (d). To see this\nfirst note that for every Z such that X0 6⊆ Z we have wZ(X0 → Y0) = 0 and therefore the inequality in (4) for this Z reads as 0 ≥ (1− γ) · ∑\ni∈WZ λi − γ ·\n∑\ni∈VZ . Rearranging we get\nγ ≥ ( ∑ i∈WZ λi ) / ( ∑ i∈VZ∪WZ λi )\n, where 0/0 is interpreted as 0. In particular, the maximum of the right-hand side over all Z such that X0 6⊆ Z is bounded by γ, and thus γ\n∗ is also bounded by γ. Note that this also covers the case of empty X0 since in that case the max in γ∗ is vacuous, which we conveyed to define as 0.\nNow we prove that 3. implies 1. Assuming (a) through (d), it is enough to find a solution to the inequalities in (4) for the entailment {Xi → Yi : i ∈ L} |=γ X0 → Y0. What we show is that for every positive real ǫ > 0 there is a vector λ = (λi : i ∈ L) with non-negative real components such that the following inequality holds uniformly for every Z ⊆ [n]:\n∑\ni∈L\nλi · wZ(Xi → Yi) ≤ wZ(X0 → Y0) + ǫ. (6)\nBy basic real analysis this will be enough. Fix then a positive real ǫ > 0 and let λ = (λi : i ∈ L) be such that the max in the definition of γ\n∗ is at most γ∗ + ǫ. For fixed Z, we prove (6) by cases:\n1. First assume that X0Y0 ⊆ Z. Then, Z witnesses X0 → Y0 and wZ(X0 → Y0) = 1− γ. The left-hand side in (6) can be written as (1 − γ) · ∑\ni∈WZ λi − γ ·\n∑\ni∈VZ λi. Using λi ≥ 0\nand ∑ i∈L λi = 1 this is at most (1 − γ) · ∑\ni∈L λi = (1 − γ) = wZ(X0 → Y0), which in turn is at most the right-hand side in (6); i.e. the inequality holds.\n2. From now on, we assume that X0Y0 6⊆ Z. For this case assume additionally that X0 ⊆ Z. In particular Y0 6⊆ Z and Z violates X0 → Y0, so wZ(X0 → Y0) = −γ. By (b) we have Xi ⊆ X0, whereas, by (c) we know that Y0 ⊆ X0Yi for every i ∈ L. Since X0 ⊆ Z and Y0 6⊆ Z, this means that Xi ⊆ Z but Yi 6⊆ Z for every i ∈ L. It follows that Z violates Xi → Yi and wZ(Xi → Yi) = −γ for every i ∈ L. Using ∑\ni∈L λi = 1, the left-hand side in (6) is −γ · ∑\ni∈L λi = −γ = wZ(X0 → Y0), which is at most the right-hand side in (6); i.e. the inequality holds.\n3. Given the previous cases, we can assume now X0 6⊆ Z, so Z does not cover X0 → Y0 and wZ(X0 → Y0) = 0. The choice of (λi : i ∈ L) implies that the ratio inside the max in the definition of γ∗ is at most γ∗+ǫ for our Z; since we are in the case X0 6⊆ Z, the ratio for our Z is in the max. By (d) it is also at most γ+ǫ. It follows that (γ+ǫ)· ∑\ni∈VZ∪WZ λi ≥\n∑\ni∈WZ λi by\nnon-negativity of the λi. Rearranging we get (1−γ)· ∑\ni∈WZ λi−γ ·\n∑\ni∈VZ λi ≤ ǫ·\n∑\ni∈VZ∪WZ λi.\nSince λi ≥ 0 and ∑\ni∈L λi ≤ 1, the right-hand side is at most ǫ, which is precisely wZ(X0 → Y0) + ǫ since Z does not cover X0 → Y0 and wZ(X0 → Y0) = 0. This is the right-hand side in (6); i.e. the inequality holds.\nThis closes the cycle of implications and the proof."
    }, {
      "heading" : "7.3 An interesting example",
      "text" : "In view of the characterization theorems obtained so far, one may wonder if the critical γ of any entailment among partial implications is of the form (k − 1)/k. This was certainly the case for k = 1 and k = 2, and Theorems 9 and 12 may sound as hints that this could be the\ncase. In this section we refute this for k = 3 in a strong way: we compute γ∗ for a specific entailment for k = 3 to find out that it is the unique real solution of the equation\n1− γ + (1− γ)2/γ + (1− γ)3/γ2 = 1. (7)\nNumerically [12], the unique real solution is\nγc ≈ 0.56984 . . . .\nConsider the following 5-attribute entailment for a generic confidence parameter γ:"
    }, {
      "heading" : "B → ACH, C → AD, D → AB |=γ BCDH → A.",
      "text" : "Let us compute its γ∗(Σ, X) where Σ is the left-hand side, and X = BCDH . In other words, we want to determine a triple λ = (λ1, λ2, λ3) that minimizes\nmax Z\n∑\ni∈WZ λi\n∑\ni∈VZ∪WZ λi\nas Z ranges over the sets that do not include X = BCDH , and subject to the constraints that λ1, λ2, λ3 ≥ 0 and λ1 + λ2 + λ3 = 1. There are 2\n5 = 32 possible Z’s out of which two (ABCDH and BCDH) contain X and therefore do not contribute to the maximum. Some others give value 0 to the ratio and therefore do not contribute to the maximum either. Note that if either |Z| ≤ 2, or |Z| = 3 and A 6∈ Z, then WZ = ∅, so the numerator is 0 and hence the ratio is also 0 (recall the convention that 0/0 is 0). Thus, the only sets Z that can contribute non-trivially to the maximum are those of cardinality 4 or 3 that contain the attribute A. There are four Z of the first type (ABCD, ABCH , ABDH and ACDH) and six Z of the second type (ABC, ABD, ABH , ACD, ACH and ADH). The corresponding ratios are\nλ2 + λ3 λ1 + λ2 + λ3 , λ1 λ1 + λ2 , λ3 λ1 + λ3 , λ2 λ2 + λ3 ,\n0\nλ1 + λ2 , λ3 λ1 + λ3 , 0 λ1 , λ2 λ2 + λ3 , 0 λ2 , 0 λ3 .\nThose with 0 numerator cannot contribute to the maximum so, removing those as well as duplicates, we are left with\nλ2 + λ3 λ1 + λ2 + λ3 , λ1 λ1 + λ2 , λ3 λ1 + λ3 , λ2 λ2 + λ3 .\nSince all λi are non-negative, the first dominates the third and we are left with three ratios:\nλ2 + λ3 λ1 + λ2 + λ3 , λ1 λ1 + λ2 , λ2 λ2 + λ3 . (8)\nWe claim that a λc that satisfies the constraints and minimizes the maximum of the three terms in (8) is\nλc,1 = 1− γc λc,2 = (1− γc)\n2/γc λc,3 = (1− γc) 3/γ2c\nwhere γc is the unique real solution of the equation in (7). Clearly this choice of λc satisfies the constraints of non-negativity, and they add up to one precisely because their sum is the left-hand side in (7). By plugging in, note also that this λc makes all three terms in (8) equal to γc; that is,\nλc,2 + λc,3 λc,1 + λc,2 + λc,3 = λc,1 λc,1 + λc,2 = λc,2 λc,2 + λc,3 = γc. (9)\nFor later reference, let us note that the left-hand side of (7) is a strictly decreasing function of γ in the interval (0, 1) (e.g. differentiate it, or just plot it) and therefore\n1− γ0 + (1− γ0) 2/γ0 + (1− γ0) 3/γ20 > 1 (10)\nwhenever 0 < γ0 < γc. In order to see that λc minimizes the maximum of the three terms in (8) suppose for contradiction that λ satisfies the constraints and achieves a smaller maximum, say 0 < γ0 < γc. Since γ0 is the maximum of the three terms in (8) we have\nγ0 ≥ (λ2 + λ3)/(λ1 + λ2 + λ3) γ0 ≥ λ1/(λ1 + λ2) γ0 ≥ λ2/(λ2 + λ3).\nUsing λ1, λ2, λ3 ≥ 0 and λ1 + λ2 + λ3 = 1, and rearranging, we get\nλ1 ≥ 1− γ0 λ2 ≥ λ1 · (1− γ0)/γ0 ≥ (1− γ0)\n2/γ0 λ3 ≥ λ2 · (1− γ0)/γ0 ≥ (1− γ0) 3/γ20 .\nAdding all three inequalities we get\nλ1 + λ2 + λ3 ≥ 1− γ0 + (1− γ0) 2/γ0 + (1− γ0) 3/γ20 .\nBut this is a contradiction: the left-hand side is 1 since λ satisfies the constraints, and the right-hand side is strictly bigger than 1 by (10). This proves the claim.\nFinally, this example also shows that for γ midway through 1/k and (k−1)/k, the vector solution to the inequalities in (4) could be very non-uniform. In this example with γ = γc, the solution is λc ≈ (0.43016, 0.32472, 0.24512). In contrast, for γ ≥ (k − 1)/k, the proof of Theorem 9 shows that it is always possible to take λi = 1/|L| for i ∈ L and λi = 0 for i ∈ [k] \\ L. In this case, the vector (λ1, λ2, λ3) = (1/3, 1/3, 1/3) works for γ ≥ 2/3, but fails otherwise. To see that it fails when γ < 2/3, take the inequality for Z = ABCD in (4).\nBy the way, it is easy to check that conditions (a), (b) and (c) hold for this example, thus Theorem 12 says that γc ≈ 0.56984 is the smallest confidence at which the entailment holds."
    }, {
      "heading" : "8 Closing remarks",
      "text" : "Our study gives a useful handle on entailments among partial or probabilistic implications. The very last comment of the previous section is a good illustration of its power. However, there are a few questions that arose and were not fully answered by our work.\nFor the forthcoming discussion, let us take γ = (k − 1)/k for concreteness. The linear programming characterization in Theorem 3 gives an algorithm to decide if entailment holds that is polynomial in k, the number of premises, but exponential in n, the number of attributes. This is due to the dimensions of the matrix that defines the dual LP: this is a 2n×k matrix of rational numbers in the order of 1/k (for our fixed γ = (k − 1)/k). On the other hand, the characterization theorem in Theorem 9 reverses the situation: there the algorithm is polynomial in n but exponential in k. In order to see this, first note that condition (a) can be solved by running O(nk) Horn satisfiability tests of size O(nk) each, as discussed at the end of Section 6.1. Second, conditions (b) and (c) are really straightforward to check if the sets are given as bit-vectors, say. So far we spent time polynomial in both n and k in checking the conditions of the characterization. The exponential in k blow-up comes, however, from the need to pass to a subset L ⊆ [k], as potentially there are 2k many of those sets to check. It does show, however, that the general problem in the case of γ ≥ (k−1)/k is in NP. This does not seem to follow from the linear programming characterization by itself, let alone the definition of entailment. But is it NP-hard? Or is there an algorithm that is polynomial in both k and n?\nIt is tempting to think that the search over subsets of [k] can be avoided when we start with a proper entailment. And indeed, this is correct. However, we do not know if this gives a characterization of proper entailment. In other words, we do not know if conditions (a), (b) and (c), by themselves, guarantee proper entailment. The proof of the direction 3. to 1. in Theorem 9 does not seem to give this, and we suspect that it does not. If they did, we would get an algorithm to check for proper entailment that is polynomial in both n and k.\nFrom a wider and less theoretical prespective, it would be very interesting to find reallife situations in problems of data analysis, say, in which partial implications abound, but many are redundant. In such situations, our characterization and algorithmic results could perhaps be useful for detecting and removing such redundancies, thus producing outputs of better quality for the final user. This was one of the original motivations for the work in [9], and our continuation here."
    } ],
    "references" : [ {
      "title" : "Interestingness measures for data mining: A survey",
      "author" : [ "L. Geng", "H.J. Hamilton" ],
      "venue" : "ACM Comput. Surv., vol. 38, no. 3, 2006.",
      "citeRegEx" : "2",
      "shortCiteRegEx" : null,
      "year" : 2006
    }, {
      "title" : "Implications partielles dans un contexte",
      "author" : [ "M. Luxenburger" ],
      "venue" : "Mathématiques et Sciences Humaines, vol. 29, pp. 35–55, 1991. 20",
      "citeRegEx" : "3",
      "shortCiteRegEx" : null,
      "year" : 1991
    }, {
      "title" : "Mining association rules between sets of items in large databases",
      "author" : [ "R. Agrawal", "T. Imielinski", "A.N. Swami" ],
      "venue" : "SIGMOD Conference, P. Buneman and S. Jajodia, Eds. ACM Press, 1993, pp. 207–216.",
      "citeRegEx" : "4",
      "shortCiteRegEx" : null,
      "year" : 1993
    }, {
      "title" : "Fast discovery of association rules",
      "author" : [ "R. Agrawal", "H. Mannila", "R. Srikant", "H. Toivonen", "A.I. Verkamo" ],
      "venue" : "Advances in Knowledge Discovery and Data Mining. AAAI/MIT Press, 1996, pp. 307–328.",
      "citeRegEx" : "5",
      "shortCiteRegEx" : null,
      "year" : 1996
    }, {
      "title" : "Association mining",
      "author" : [ "A. Ceglar", "J.F. Roddick" ],
      "venue" : "ACM Comput. Surv., vol. 38, no. 2, 2006.",
      "citeRegEx" : "6",
      "shortCiteRegEx" : null,
      "year" : 2006
    }, {
      "title" : "A new approach to online generation of association rules",
      "author" : [ "C.C. Aggarwal", "P.S. Yu" ],
      "venue" : "IEEE Transactions on Knowledge and Data Engineering, vol. 13, no. 4, pp. 527–540, 2001.",
      "citeRegEx" : "7",
      "shortCiteRegEx" : null,
      "year" : 2001
    }, {
      "title" : "Representative association rules",
      "author" : [ "M. Kryszkiewicz" ],
      "venue" : "Proc. of the 2nd Pacific-Asia Conference on Knowledge Discovery and Data Mining (PAKDD), ser. Lecture Notes in Artificial Intelligence, X. Wu, K. Ramamohanarao, and K. B. Korb, Eds., vol. 1394. Springer-Verlag, 1998, pp. 198–209.",
      "citeRegEx" : "8",
      "shortCiteRegEx" : null,
      "year" : 1998
    }, {
      "title" : "Redundancy, deduction schemes, and minimum-size bases for association rules",
      "author" : [ "J.L. Balcázar" ],
      "venue" : "Logical Methods in Computer Science, vol. 6, no. 2:3, pp. 1–33, 2010.",
      "citeRegEx" : "9",
      "shortCiteRegEx" : null,
      "year" : 2010
    }, {
      "title" : "Learning conjunctions of Horn clauses",
      "author" : [ "D. Angluin", "M. Frazier", "L. Pitt" ],
      "venue" : "Machine Learning, vol. 9, pp. 147–164, 1992.",
      "citeRegEx" : "11",
      "shortCiteRegEx" : null,
      "year" : 1992
    } ],
    "referenceMentions" : [ {
      "referenceID" : 0,
      "context" : "See the survey [2].",
      "startOffset" : 15,
      "endOffset" : 18
    }, {
      "referenceID" : 1,
      "context" : "For instance, [3] introduced them as “partial implications”; much later, [4] defined “association rules” (see also [5] and the survey [6]): these are partial implications that impose the additional condition that the consequent is a single propositional variable, and where additional related parameters are used to assess their interest.",
      "startOffset" : 14,
      "endOffset" : 17
    }, {
      "referenceID" : 2,
      "context" : "For instance, [3] introduced them as “partial implications”; much later, [4] defined “association rules” (see also [5] and the survey [6]): these are partial implications that impose the additional condition that the consequent is a single propositional variable, and where additional related parameters are used to assess their interest.",
      "startOffset" : 73,
      "endOffset" : 76
    }, {
      "referenceID" : 3,
      "context" : "For instance, [3] introduced them as “partial implications”; much later, [4] defined “association rules” (see also [5] and the survey [6]): these are partial implications that impose the additional condition that the consequent is a single propositional variable, and where additional related parameters are used to assess their interest.",
      "startOffset" : 115,
      "endOffset" : 118
    }, {
      "referenceID" : 4,
      "context" : "For instance, [3] introduced them as “partial implications”; much later, [4] defined “association rules” (see also [5] and the survey [6]): these are partial implications that impose the additional condition that the consequent is a single propositional variable, and where additional related parameters are used to assess their interest.",
      "startOffset" : 134,
      "endOffset" : 137
    }, {
      "referenceID" : 0,
      "context" : "in [2].",
      "startOffset" : 3,
      "endOffset" : 6
    }, {
      "referenceID" : 5,
      "context" : "Motivated by practical issues, several works have analyzed notions of redundancy among partial implications: two proposals in [7] and [8] turned out to be equivalent among them and were, in turn, as described in [9], equivalent to the natural notion of logical entailment of one partial implication by another (modulo minor details such as allowing or disallowing empty antecedents or consequents).",
      "startOffset" : 126,
      "endOffset" : 129
    }, {
      "referenceID" : 6,
      "context" : "Motivated by practical issues, several works have analyzed notions of redundancy among partial implications: two proposals in [7] and [8] turned out to be equivalent among them and were, in turn, as described in [9], equivalent to the natural notion of logical entailment of one partial implication by another (modulo minor details such as allowing or disallowing empty antecedents or consequents).",
      "startOffset" : 134,
      "endOffset" : 137
    }, {
      "referenceID" : 7,
      "context" : "Motivated by practical issues, several works have analyzed notions of redundancy among partial implications: two proposals in [7] and [8] turned out to be equivalent among them and were, in turn, as described in [9], equivalent to the natural notion of logical entailment of one partial implication by another (modulo minor details such as allowing or disallowing empty antecedents or consequents).",
      "startOffset" : 212,
      "endOffset" : 215
    }, {
      "referenceID" : 7,
      "context" : "The contributions of [9] that are relevant to the present paper are chiefly syntactic characterizations of one partial implication entailing another, and of two partial implications entailing another.",
      "startOffset" : 21,
      "endOffset" : 24
    }, {
      "referenceID" : 7,
      "context" : "[9]) A tempting intuition is to generalize the observation and jump to the statement that no nontrivial consequence follows from two partial implications; however, this statement is wrong, and an explicit example of proper entailment from two premises is given in the same reference and restated below in Section 3.",
      "startOffset" : 0,
      "endOffset" : 3
    }, {
      "referenceID" : 7,
      "context" : "Besides offering this observation, [9] goes beyond, and generalizes the example into a precise characterization of when a partial implication is entailed by two partial implications.",
      "startOffset" : 35,
      "endOffset" : 38
    }, {
      "referenceID" : 7,
      "context" : "We review here the results from [9] on entailments among partial implications with one or two premises.",
      "startOffset" : 32,
      "endOffset" : 35
    }, {
      "referenceID" : 7,
      "context" : "Otherwise, entailment is still characterized by a simple Boolean algebraic condition on the sets X0, Y0, X1, and Y1 as stated in the following theorem: Theorem 1 ([9]).",
      "startOffset" : 163,
      "endOffset" : 166
    }, {
      "referenceID" : 7,
      "context" : "The case of two partial implications entailing a third was also solved in [9].",
      "startOffset" : 74,
      "endOffset" : 77
    }, {
      "referenceID" : 7,
      "context" : "Theorem 2 ([9]).",
      "startOffset" : 11,
      "endOffset" : 14
    }, {
      "referenceID" : 7,
      "context" : "This was also proved in [9], thus fully covering all cases of entailment with two premises and all confidence parameters γ.",
      "startOffset" : 24,
      "endOffset" : 27
    }, {
      "referenceID" : 7,
      "context" : "The proof of Theorem 2 in [9] is rather long and somewhat involved, although it uses only elementary Boolean algebraic manipulation.",
      "startOffset" : 26,
      "endOffset" : 29
    }, {
      "referenceID" : 8,
      "context" : "[11]), we say that a transaction Z ⊆ [n] covers X → Y if X ⊆ Z, and that it violates it if X ⊆ Z but Y 6⊆ Z.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 7,
      "context" : "This was one of the original motivations for the work in [9], and our continuation here.",
      "startOffset" : 57,
      "endOffset" : 60
    } ],
    "year" : 2017,
    "abstractText" : "We study a natural variant of the implicational fragment of propositional logic. Its formulas are pairs of conjunctions of positive literals, related together by an implicational-like connective; the semantics of this sort of implication is defined in terms of a threshold on a conditional probability of the consequent, given the antecedent: we are dealing with what the data analysis community calls confidence of partial implications or association rules. Existing studies of redundancy among these partial implications have characterized so far only entailment from one premise and entailment from two premises. Here, we provide an alternative view of this entailment in terms of linear programming duality. This view allows us to characterize exactly the cases of entailment from arbitrary numbers of premises, to obtain decision algorithms of better complexity, and to prove that the confidence threshold is, actually, intrinsic to each set of premises and antecedent of the conclusion.",
    "creator" : "LaTeX with hyperref package"
  }
}