{
  "name" : "1206.6420.pdf",
  "metadata" : {
    "source" : "META",
    "title" : "Distributed Parameter Estimation via Pseudo-likelihood",
    "authors" : [ "Qiang Liu", "Alexander Ihler" ],
    "emails" : [ "qliu1@uci.edu", "ihler@ics.uci.edu" ],
    "sections" : [ {
      "heading" : "1. Introduction",
      "text" : "Wireless sensor networks are becoming ubiquitous, with applications including ecological monitoring, health care, and smart homes. Traditional centralized approaches to machine learning are not well-suited to sensor networks, due to the sensors’ restrictive resource constraints. Sensors have limited local computing, memory, and power, and their wireless communication is expensive in terms of power consumption. These constraints make centralized data collection and processing difficult. Fault-tolerance and robustness are also critical features.\nGraphical models are a natural framework for distributed inference in sensor networks (e.g., Cetin et al., 2007). However, most learning algorithms are not distributed, requiring centralized data processing and storage. In this work, we provide a general framework for distributed parameter estimation, based on combining local and inexpensive estimators.\nAppearing in Proceedings of the 29 th International Conference on Machine Learning, Edinburgh, Scotland, UK, 2012. Copyright 2012 by the author(s)/owner(s).\nThis paper is organized as follows. Section 2 sets up background on graphical models for sensor networks and learning algorithms. In Section 3, we propose a framework for distributed learning based on intelligently combining results from disjoint local estimators. We give theoretic analysis in Section 4 and experiments in Section 5. We discuss related work in Section 6 and finally conclude the paper in Section 7."
    }, {
      "heading" : "2. Background",
      "text" : ""
    }, {
      "heading" : "2.1. Graphical models for sensor networks",
      "text" : "Consider a graphical model of a random vector x = [x1, . . . , xp] in exponential family form,\np(x|θ) = exp(θTu(x)− logZ(θ)), (1)\nwhere θ = {θα}α∈I and u(x) = {uα(xα)}α∈I are vectors of the same size, and θTu(x) is their inner product. I is a set of variable indexes and uα(xα) are local sufficient statistics. Z(θ) is the partition function, which normalizes the distribution. The distribution is associated with a Markov graph G = (V,E), with node i ∈ V denoting a variable xi and edge (ij) ∈ E representing that xi and xj co-appear in some α, that is, {i, j} ⊂ α. Let βi = {α ∈ I|i ∈ α} be the set of α that includes i. In pairwise graphical models, I = E ∪ V .\nTo model a sensor network, we represent the i-th sensor’s measurement by xi, and assume that the communication links between sensors are identical to the Markov graph G, that is, sensor i and j have communication link if and only if (ij) ∈ E. Assume that n independent samples X = [x1, . . . , xn] are drawn from a true distribution p(x|θ∗). Due to memory and communication constraints on sensors, the data are stored locally within the network: each sensor stores only data measured by itself and its neighbors, that is, XA(i) = [x 1 A(i), . . . , x n A(i)], where A(i) = {i} ∪ N (i) and N (i) is the neighborhood of node i. The goal is to design a distributed algorithm for estimating the true θ∗, with minimum communication and low, balanced local computational costs at the sensor nodes.\nNotation. Unless specified otherwise, we take E(·), var(·), and cov(·) to mean the expectation, variance,\nand covariance matrix under the true distribution p(x|θ∗). For a likelihood function `(θ;x), ∇`(θ) and ∇2`(θ) denote the gradient and Hessian matrix w.r.t. θ, where we suppress the dependence of `(θ, x) on x for compactness. We use “hat” accents to denote empirical average estimates, e.g., ˆ̀(θ,X) = 1n ∑n k=1 `(θ, x k)."
    }, {
      "heading" : "2.2. M-estimators",
      "text" : "M-estimators are a broad class of parameter estimators; an M-estimator with criterion function `(θ;x) is\nθ̂ = arg max θ\nˆ̀(θ;X).\nIn this paper we assume that `(θ, x) is continuous differentiable and has a unique maximum. If E[∇`(θ∗)] = 0, then under mild conditions standard asymptotic statistics (van der Vaart, 1998) show that θ̂ is asymptotically consistent and normal, that is, √ n(θ̂− θ∗) N (0, V ), with asymptotic variance (Godambe, 1960)\nV = H−TJH−1,\nwhere J = var(∇`(θ∗)) is the Fisher information matrix and H = −E(∇2`(θ∗)) is the expected Hessian matrix. ` is said to be information-unbiased (Lindsay, 1988) if J = H. In this case, we have V = H−1 = J−1, i.e., the asymptotic variance equals the inverse Fisher information matrix or Hessian matrix. Let s be a random vector with s = H−1∇`(θ∗, x). An important intuition for asymptotic analysis is that θ̂ ≈ θ∗ + 1√\nn s\nat the large sample limit, so that the asymptotic variance can be rewritten as V = var(s).\nEmpirically, one can assess the quality of an Mestimator by estimating its asymptotic covariance; this can be done by approximating the E(·) and var(·) with their empirical counterparts, and θ∗ with θ̂, e.g., the asymptotic variance is estimated by V̂ = Ĥ−1ĴĤ−1, where Ĵ = 1n ∑n k=1(∇`(θ̂;xk))(∇`(θ̂;xk))T and Ĥ =\n− 1n ∑n k=1∇2`(θ̂;xk). If ` is information-unbiased, only the Fisher information J need be calculated, avoiding calculating the second derivatives. In practice, these variance estimators perform well only when the parameter dimension is much smaller than the sample size; they are usually not directly applicable to practically sized problems. In this work, we show that by splitting the global estimator into low-dimensional local estimators, we can use covariance estimation on the local estimators to provide important information for combining them."
    }, {
      "heading" : "2.3. MLE and MPLE",
      "text" : "The maximum likelihood estimator (MLE) is the most well-known M-estimator; it maximizes the likelihood,\n`mle(θ;x) = log p(x|θ).\nThe MLE is asymptotically consistent and normal, and achieves the Cramér-Rao lower bound (is asymptotically at least as efficient as any unbiased estimator). Unfortunately, the MLE is often difficult to compute, because the likelihood involves the partition function Z(θ), which is hard to evaluate for general graphical models (Wainwright & Jordan, 2008).\nThe maximum pseudo-likelihood estimator (MPLE) (Besag, 1975) provides a computationally efficient alternative to MLE. The pseudo-likelihood is defined as\n`mple(θ;x) = p∑ i=1 log p(xi|xN (i); θβi), (2)\nwhere due to the Markov property, each conditional likelihood component only depends on θβi , the parameters incident to i, and on XA(i), the data available to sensor i. MPLE remains asymptotically consistent and normal, but is usually statistically less efficient than MLE – a sacrifice for computational efficiency. However, cases exist in which the MPLE is also statistically more favorable than MLE, e.g., when the model is misspecified (e.g., Liang & Jordan, 2008).\nThere is a weaker version of MPLE, well known in sparse learning (e.g., Ravikumar et al., 2010), that disjointly maximizes the single conditional likelihood (CL) components in MPLE, and then combines the overlapping components using some simple method such as averaging. Very recently, the disjoint MPLE has started to attract attention in distributed estimation (Wiesel & Hero, 2012), by observing that the conditional likelihoods define local estimators well suited to distributed computing.\nOur work. We address the problem of distributed parameter learning within a paradigm motived by MPLE and disjoint MPLE, in which the sensor nodes locally calculate their own inexpensive local estimators, whose results are communicated to nearby sensors and combined. We provide a more general framework for combining the local estimators, including weighted linear combinations, a max-voting method, and more advanced joint optimization methods. Powered by asymptotic analysis, we propose efficient methods to set optimal weights for the linear and max combination methods, and provide a comprehensive comparison of the proposed algorithms. Surprisingly, we show that the simple linear and max combination methods, when leveraged by well-chosen weights, are able to outperform joint optimization in some cases. In particular, the max-voting method performs well on “degree-unbounded” graph structures, such as stars or scale free networks, that are difficult for many existing methods. In addition, we show that the joint\nMPLE can be recast into a sequence of disjoint MPLE combinations via the alternating direction method of multipliers (ADMM), and we show that, once it is initialized properly, interrupting the iterative algorithm at any point provides “correct” estimates; this leads to an any-time algorithm that can flexibly trade off performance and resources, and is robust to interruptions such as sensor failure. Finally we provide extensive simulation to illustrate our theoretical results."
    }, {
      "heading" : "3. A Distributed Paradigm",
      "text" : "For each sensor i, let `ilocal(θβi ;xA(i)) be a criterion function that depends only on local data XA(i) and the parameter sub-vector θβi . This defines a M-estimator that is efficient to compute locally by sensor i,\nθ̂iβi = arg max θβi ˆ̀i local(θβi ;XA(i)). (3)\nWe assume that E(∇`ilocal(θ∗β)) = 0 and that (3) has a unique maximum, which guarantee that θ̂iβi is asymptotically consistent and normal under standard technical conditions. Further, assume ∪iβi = I, so that each parameter component is covered by at least one local estimator and a valid global estimator can be constructed by combining them.\nAlthough our results apply more generally, in this work we mainly take `ilocal(θβi ;xA(i)) = log p(xi|xN (i); θβi), which satisfies the conditions listed above. Moreover, such `ilocal(θβi) are information unbiased, i.e., V i local= (J ilocal) −1 =(Hilocal) −1. One can estimate the asymptotic variance by V̂ ilocal = (Ĵ i local)\n−1, where Ĵ ilocal involves calculating the covariance of the gradient statistics and is efficient once |βi| is relatively small.\nIf a parameter θα is shared by multiple sensors, performance can be boosted by combining their information. We propose two types of consensus methods, generalizing disjoint MPLE and MPLE respectively."
    }, {
      "heading" : "3.1. One-Step Consensus.",
      "text" : "For each parameter θα, let θ̂α = {θ̂iα|i ∈ α} be the collection of estimates given by the sensors incident to α. The goal is to construct a combined estimator θ̂α as a function of θ̂α. Probably the simplest method is averaging, i.e., θ̂α = 1 |α| ∑ i∈α θ̂ i α. Unfortunately, as we show in the sequel, this simple approach usually performs poorly, in part because it weights all the estimators equally and the worst estimator may greatly degrade the overall performance. Thus, it would be helpful to weight the estimators by their quality.\nLet ŵiα, as a function of XA(i) and θ̂ i local, be an empirical measure of the quality of the i-th local estimator\nfor estimating parameter θα – for example, ŵ i could be a function of V̂ ilocal.We introduce two methods to combine the estimators based on weight ŵi:\nlinear consensus: θ̂linearα = ∑ i∈α ŵiαθ̂ i α/ ∑ i∈α ŵiα, (4)\nmax consensus:\nθ̂maxα = θ̂ i0 α , where ŵ i0 α ≥ ŵiα for all i ∈ α, (5)\nwhere the linear consensus takes a soft combination of the local estimators, while the max consensus votes on the best one. It should be noted that the max consensus can be treated as a special linear consensus whose weights are taken be to be zero, except on one local estimator. However, as we show later, the max consensus has some attractive properties making it an efficient algorithm for many problems.\nWe prove that linear and max consensus are asymptotically consistent and normal, and provide their asymptotic variance. We also discuss the optimal setting of the weights, in the sense of minimizing the asymptotic mean square error. Remarkably, we show that the optimum weights, particularly for the max consensus, are surprisingly easy to estimate, making one-step methods competitive to more advanced consensus methods."
    }, {
      "heading" : "3.2. Joint Optimization via ADMM",
      "text" : "A more principled way to ensure consensus is to solve a joint optimization problem,\nmax θiβi ,θ̄ n∑ i=1 ˆ̀i local(θ i βi |XA(i)) s.t. θ i βi = θ̄βi for all i (6)\nwhere we maximize the sum of ˆ̀ilocal under the constraint that all the local estimators should be consistent with a global θ̄; this exactly recovers the joint MPLE method in (2) when `ilocal are the conditional likelihoods. In this section, we derive a distributed algorithm for (6) that can be treated as an iterative version of the linear consensus introduced above.\nOur algorithm is based on the alternating direction method of multipliers (ADMM), which is well suited to distributed convex optimization (Boyd et al., 2011), particularly distributed consensus (Bertsekas & Tsitsiklis, 1989).\nFor notation, let f i(θiβi) = −ˆ̀ i local(θ i βi |XA(i)). We introduce an augmented Lagrangian function for (6),\np∑ i=1 { f i(θiβi) + λ i βi T (θiβi − θ̄βi) + ∑ α∈βi ρiα 2 |θiα − θ̄α|2 } ,\nwhere λiβi are Lagrange multipliers of the same size as θiβi and ρ i βi\nare positive penalty constants. Performing an alternating direction procedure on the augmented Lagrangian yields the ADMM algorithm:\nθiβi ← arg min{f i(θiβi) + λ i βi T θiβi + ∑ α∈βi ρiα 2 ||θiα − θ̄α||2}\nθ̄α ← ∑ i∈α ρiαθ i α/ ∑ i∈α ρiα, ∀α ∈ I λiα ← λiα + ρiα(θiα − θ̄α), ∀α ∈ βi,\nThis update has an intuitive statistical interpretation. First, θiβi can be treated as a posterior MAP estimation of the parameter subject to a Gaussian prior with mean (θ̄βi − λiβi/ρ i βi ), which biases the estimate towards the average value; θ̄ is then re-evaluated by taking a linear consensus of the local estimators. Thus, the joint optimization can be recast into a sequence of linear consensus steps. Given this connection, it is reasonable to set ρiα to be the weights of linear consensus, that is, ρiα = ŵ i α and initialize θ̄ to be the corresponding one-step estimator. Since linear consensus estimators are asymptotically consistent, we have\nTheorem 3.1. If we set θ̄ to be asymptotically consistent and λiβi = 0 in the initial step of ADMM, then θ̄ remains asymptotically consistent at every iteration.\nTherefore, one can interrupt the algorithm and fetch a “correct” answer at any iteration, giving a flexible anytime framework that can not only save on computation and communication, but is also robust to accidental failures, such as battery depletion."
    }, {
      "heading" : "4. Asymptotic Analysis",
      "text" : "In this section, we give an asymptotic analysis of our methods, by which we provide methods to optimally set the weights of linear and max consensus. For notational convenience, we embed the local estimator θ̂iβi = arg max ˆ̀i local(θβi , X) into a (possibly degenerate) estimator of the whole parameter vector θ̂i = arg max ˆ̀i(θ,X), by setting θ̂iα = 0 for α /∈ βi. Denote by V i the asymptotic variance of the extended estimator, with V ilocal on its βi × βi sub-matrix and zero otherwise. Similarly, let Hi extend Hilocal, and s i extend siβi def = Hilocal\n−1∇`ilocal(θ∗βi). Our results will reflect the intuition that θ̂i ≈ θ∗ + 1√\nn si at the large\nsample limit.\nFor our results, we generalize to a matrix extension of the linear consensus (4), defined as\nθ̂matrix = ( ∑ i Ŵ i)−1 ∑ i Ŵ iθ̂i, (7)\nwhere Ŵ i are matrix weights that are non-zero only on the βi × βi sub-matrices; we require that ( ∑ i Ŵ i)−1 is invertible. Note that the matrix extension is not directly suitable for distributed implementation, since it involves a global matrix inverse, but it will provide performance bounds for linear and max consensus and has close connection to joint optimization estimators. Theorem 4.1 (Linear Consensus). Assume Ŵ i p→\nW i and ∑ iW i is an invertible matrix. Then θ̂matrix in (7) is asymptotically consistent and normal, with an asymptotic variance of var [ ( ∑ iW i)−1 ∑ iW isi ] .\nAssume H = ∑ iH i is invertible, then the joint op-\ntimization consensus θ̂joint = arg max ∑ i ˆ̀ i(θ, x) is a non-degenerate estimator of the full parameter vector θ. It turns out θ̂joint is asymptotically equivalent to a matrix linear consensus with weights Ŵ i = Ĥi: Corollary 4.2. θ̂matrix in (7) with Ŵ i = Ĥi has asymptotic variance of var[( ∑ iH i)−1 ∑ i∇`i(θ∗)], which is the same as that of θ̂joint.\nFor max consensus estimators, we have Theorem 4.3. The θ̂max in (5) is asymptotically consistent. Further, for any α ∈ I, if ŵiα p→ wiα and wi0α > maxi∈α,i 6=i0 w i α, then θ̂ max α is asymptotically normal, with asymptotic variance equal to V i0α,α."
    }, {
      "heading" : "4.1. Optimal Choice of Weights",
      "text" : "In this section, we consider the problem of choosing the optimal weights, in the sense of minimizing the asymptotic mean square error (MSE). Note that E(||θ̂ − θ∗||2) → 1n trV as n → +∞, where tr(V ) is the trace of the asymptotic covariance matrix, and so the problem can be reformed to minimize tr(V ). In the following, we discuss the optimal weights for the linear and max consensus separately.\nWeights for Max Consensus. The greedy nature of max consensus makes optimal weights relatively easy:\nProposition 4.4. For the max consensus estimator θ̂max as defined in (5), the weight wiα = 1/V i α,α achieves minimum least square error asymptotically.\nIn practice, we can estimate the optimal weights simply by ŵiα = 1/V̂ i α,α, which makes max consensus feasible in practice.\nWeights for Linear Consensus. By Theorem 4.1, the optimal weights for matrix linear consensus solve\nmin W i tr[var( ∑ i W isi ) ] s.t.\n∑ i W i = 1, (8)\nwhere W i are non-zero only on the βi × βi submatrix and 1 denotes the identity matrix of the same size\nas W i. Solving (8) is difficult in general, but if si are pairwise independent and θ̂i are information-unbiased, the weights W i = Hi, asymptotically equivalent to θ̂joint as shown in Corollary 4.2, achieves optimality.\nProposition 4.5. Assume θ̂i are informationunbiased. If cov(si, sj) = 0 for all i 6= j, then θ̂joint achieves the optimum MSE as defined in (8).\nThis implies that if the estimators are independent or weakly correlated, the joint optimization estimator θ̂joint is guaranteed to perform no worse than the linear and max consensus methods (both suboptimal to the best matrix consensus). However, in the case that the local estimators are strongly correlated (usually the case in practice), there is the chance that linear or max consensus, with properly chosen weights, can outperform the joint optimization method.\nOn the other hand, when W i in (8) are constrained to be diagonal matrices, reducing to a set of vector weights wiα, the optimization becomes easier. Let wα = {wiα}i∈α and Vα be an |α| × |α| matrix with V ijα = cov(s i α, s j α), i.e., Vα is the covariance matrix between the local estimators on parameter θα. Then,\nProposition 4.6. For linear consensus estimator θ̂linear as defined in (4), the weights wα = V −1 α e, where e is a column vector of all ones, achieves the minimum asymptotic least square error.\nIn other words, the optimal vector weights for linear consensus equal the column sums of V −1α . In practice, these weights can be estimated by ŵα = V̂ −1 α e, where V̂ ijα = 1 n ∑n k=1 s i α(x\nk) · sjα(xk), and skα(xk) = (Ĥi)−1∇`i(θ̂i;xk). In the sensor network setting, calculating V ijα requires a secondary communication step in which the sensors pass {siα(xk)}nk=1 to their neighbors. Note that this communication step may be expensive if the number of data n is large (although one can pass a subset of samples to get a rougher estimate).\nIt is interesting to compare to the optimal weights for max consensus in Proposition 4.4, where no communication step is required. This is because max consensus fundamentally ignores the correlation structure, while linear consensus must account for it. Some further useful insights arise by considering the cases of extremely weak or strong correlations.\nProposition 4.7. If cov(si, sj) = 0, ∀i 6= j, then the θ̂linear as defined in (4) achieves the lowest asymptotic MSE with weights wiα = 1/V i α,α.\nThis suggests that ŵiα = 1/V̂ i α,α, which is optimal for max consensus selection, might also be a reasonable choice for linear consensus. However, the independence assumption is always violated in practice. To\nsee what happens when the estimators are strongly correlated, consider the opposite extreme, in which the local estimators are deterministically correlated:\nProposition 4.8. If si (i = 1, . . . , p) are deterministically positively correlated, i.e., there exists a random vector s0, and constants viα ≥ 0, such that siα = viαs0α, then the optimal vector weights {wiα} for linear consensus, under the constraint wiα ≥ 0, is wiα = 1 if viα ≤ vjα for any j ∈ α and wiα = 0 if otherwise.\nSince linear consensus with 0-1 weights reduces to max consensus, this result suggests that the optimal max consensus is not much worse than the optimal linear consensus when the estimators are strongly positively correlated. In practice, we find that the local estimators defined by conditional likelihoods are always positively correlated, justifying max consensus in practice."
    }, {
      "heading" : "4.2. Illustration on One Parameter Case",
      "text" : "In this section, we illustrate our asymptotic results in a toy example, providing intuitive comparison of our algorithms. Assume θ is a scale parameter, estimated by two information-unbiased estimators θ̂i = arg max `i(θ) (i = 1, 2). Let hi = −E(∇2`i(θ∗)) and si = (hi)−1∇f i(θ∗); then the asymptotic variance is vi = (hi)−1 = var(si). Let v12 = cov(s1, s2) be the correlation of the two estimators.\nLinear consensus with uniform weights: θ̂linUnif = 1 2 (θ̂ 1 + θ̂2); the asymptotic variance is:\nvar (s1 + s2\n2\n) = 1\n4 (v1 + v2 + 2v12).\nLinear consensus with Hessian weights wi = hi: θ̂linHessian = (ĥ1 + ĥ2)−1(ĥ1θ̂1 + ĥ2θ̂2). By Corollary 4.2, the asymptotic variance of θ̂linHessian is the same as that of θ̂joint = arg maxθ ∑ i ˆ̀i(θ), which is:\nvar(h1s1 + h2s2) = v1v2(v1 + v2 + 2v12)\n(v1 + v2)2 .\nLinear consensus with optimal weights θ̂linOpt: By Proposition 4.6, the optimal weights for linear consensus are w1 ∗ = v 2−v12\nv1+v2−v12 and w 2∗ = v 2−v12 v1+v2−v12 . The\nasymptotic variance is\nvar(w1 ∗ s1 + w2 ∗ s2) =\nv1v2 − v12\nv1 + v2 − 2v12 .\nMax consensus with optimal weights θ̂maxOpt. By Proposition 4.4, for max consensus the weights wi = hi are optimal. The asymptotic variance is min{v1, v2}.\nClaim 4.9. In the toy case, we have θ̂linOpt θ̂joint(= θ̂linHessian) θ̂linUnif and θ̂linOpt θ̂maxOpt, where θ̂a θ̂b means MSE(θ̂a) ≤ MSE(θ̂b) asymptotically.\nProof. θ̂joint θ̂linUnif is shown by the arithmeticgeometric mean inequality, and the rest since θ̂linHessian and θ̂maxOpt are special forms of linear consensus.\nHowever, θ̂linUnif or θ̂joint are not necessarily inferior or superior to θ̂maxOpt. Their relative performance depends on the correlation and the quality (variance) of the two local estimators. Let ρ12 = v12/ √ v1v2 be the correlation coefficient of the estimators, and γ=min{v1/v2, v2/v1} the ratio of their variances. Claim 4.10. In the toy case, θ̂joint(= θ̂linHessian) θ̂maxOpt if and only if ρ12 ≤ 12 √ γ(γ + 1). Similarly, θ̂linUnif θ̂maxOpt if and only if ρ12 ≤ 12√γ (3γ − 1);\nSee Fig. 1 for illustration; this highlights the relative performance of max vs. linear consensus. While θ̂linHessian and θ̂linUnif tend to work better when the local estimators perform similarly (γ ≈ 1) or when the local estimators have low or even negative correlations, θ̂maxOpt tends to work well when one local estimator is much better than the others (γ 1) or when the local estimators are strongly positively correlated. This robustness makes max consensus useful for learning in difficult graphs, such as scale free graphs, for which standard methods often perform poorly (Ravikumar et al., 2010; Liu & Ihler, 2011). Fig. 1(b) illustrates how the values of γ and ρ12 are changed by varying the local potentials in a binary two-node model. Basically, θ̂maxOpt tends to work better when the magnitudes of the local potentials differ greatly, i.e., when the model is heteroskedastic."
    }, {
      "heading" : "5. Experiments",
      "text" : "In this section, we test our algorithms on both small models (for which the asymptotic variance can be exactly calculated) and larger models of more practical size. We use a pairwise Ising model p(x) ∝ exp( ∑ (ij)∈E θijxixj + ∑ i∈V θixi), xi ∈ {−1, 1}, with random true parameters generated by\nθij ∼ N (0, σpair) and θi ∼ N (0, σsingleton). We test the Joint-MPLE, and the linear consensus with uniform weights (Linear-Uniform), with diagonal weights ŵiα = 1/V̂ i α,α (Linear-Diagonal) and with the optimum vector weights given in Proposition 4.6 (Linear-Opt). We also test the max consensus with diagonal weights (Max-Diagonal(Opt)), which is optimal for max consensus (Proposition 4.4). We quantify the algorithms either by exactly calculated asymptotic efficiency, defined as tr(V )/tr(Vmle), or empirically by the MSE ||θ̂ − θ∗||2 calculated on simulated datasets."
    }, {
      "heading" : "5.1. Small Models",
      "text" : "Two small graphs are considered: star graphs and grids, which have opposite topological properties. For these small models, we estimate the pairwise parameters θij with known singleton parameters θi.\nStar graphs. A star graph has an unbalanced degree distribution, peaked at the center node. There has been theoretical and empirical work showing that such degree-unbounded graphs are harder to learn than more regular graphs (e.g., Liu & Ihler, 2011). From our perspective, the difficulty arises because the local estimators of high-degree nodes tend to deteriorate the overall performance. As we suggest in Section 4, the max consensus method is suitable for such graphs, as it can identify and discard the bad estimators.\nThe simulation supports this expectation. In Fig. 2(a), as degree increases, the variance of the local estimator of the center node increases quickly compared to the leaves (averaged). Fig. 2(b) shows the exact (solid lines) and empirical (dashed) asymptotic efficiencies of the algorithms on star graphs of different sizes. Linear-Uniform performs worst, since it fails to discount the influence of the worst estimator. Joint-MPLE and Linear-Diagonal perform better but still deteriorate as degree increases, since they downweight the worse estimators, but only to some extent. In contrast, Max-Diagonal is robust to the increasing degree, and can identify and discard the worst estimators. As theoretically predicted, Linear-Opt outperforms Max-Diagonal, but only slightly in this case. Note Linear-Opt is more costly than Max-Diagonal due to the extra communication step. The exact and empirical values in Fig. 2(b) match closely, showing the correctness of our theoretical analysis.\nIn Fig. 2(c) we show the effect of singleton potentials. The performance of one-step consensus methods generally decreases with higher magnitude singleton potentials, while the Joint-MPLE stays the same. Intuitively, this is because the local estimators are not able to jointly infer the local potentials, causing prob-\nlems when those local potentials dominate. Since our analysis is mainly asymptotic, we evaluate how the algorithms perform for small sample sizes in Fig. 2(d). As can be seen, the finite sample performance is essentially consistent with the asymptotic analysis.\n4×4 Grid. The algorithms’ performance on grids have the opposite trends; see Fig. 3(a). Joint-MPLE performs best, while max-Diagonal performs relatively poorly. This is because grids have balanced degree, and all the local estimators perform equally well. We check the finite sample performance of the algorithms in Fig. 3(b), which again shows similar trends to our asymptotic results. Finally, we show the convergence of ADMM in Fig. 3(c), illustrating that our initialization increases the convergence speed greatly."
    }, {
      "heading" : "5.2. Larger Models",
      "text" : "We also test our algorithms on larger graphs, including a 100-node scale free network generated via the Barabási-Albert model (Barabási & Albert, 1999) and a 100-node Euclidean graph generated by connecting nearby sensors (distance ≤ .15) uniformly placed on the [0, 1]× [0, 1] plane; see Fig. 4. On these models, we estimate both the singleton and pairwise parameters. In Fig. 4(a)-(b) we see trends similar to their smaller analogues, the star graph and 4×4 grid, verifying that our analysis remains useful on models of larger sizes."
    }, {
      "heading" : "6. Related Work",
      "text" : "A very recent, independently developed work (Wiesel & Hero, 2012) adopts a similar, but less general approach for Gaussian covariance estimation. They propose a similar linear consensus approach (using only uniform weights) and a similar parallel algorithm for joint MPLE, but do not discuss max consensus or lin-\near consensus with general weights, and do not provide a comprehensive theoretical analysis. Another recent work (Eidsvik et al., 2010) uses composite likelihood for parallel computing on spatial data. Bradley & Guestrin (2011) gave a sample complexity analysis for MPLE and disjoint MPLE, which may be extensible to our algorithms.\nAnother line of work approximates MLE by estimating the partition function with variational algorithms (e.g., Wainwright, 2006; Sutton & McCallum, 2009). These methods can perform well at prediction tasks even with a “wrong” model, and can take a messagepassing form potentially suitable to distributed settings. However, in terms of parameter estimation, these methods introduce a bias due to the approximate inference that is hard to estimate or control."
    }, {
      "heading" : "7. Conclusion",
      "text" : "In this work, we present a general framework for distributed parameter learning. We show that the smart one-step consensus methods of the local estimators, especially those that exploit local second-order information, are both computationally efficient and statistically competitive with iterative methods using joint optimization. Particularly, we show that the max combination method is well suited to scale-free networks, a well-identified problem for existing methods. Our theory of combining estimators is quite general, and can be applied to other contexts to boost statistical performance. Future directions include considering model misspecification, finite sample complexity analysis and extension to high-dimensional structure learning.\nAcknowledgements. Work supported in part by NSF IIS-1065618 and a Microsoft Research Fellowship."
    } ],
    "references" : [ {
      "title" : "Emergence of scaling in random networks",
      "author" : [ "Barabási", "A.-L", "R. Albert" ],
      "venue" : "Science, 286(5439):509–512,",
      "citeRegEx" : "Barabási et al\\.,? \\Q1999\\E",
      "shortCiteRegEx" : "Barabási et al\\.",
      "year" : 1999
    }, {
      "title" : "Parallel and distributed computation: numerical methods",
      "author" : [ "D. Bertsekas", "J. Tsitsiklis" ],
      "venue" : null,
      "citeRegEx" : "Bertsekas and Tsitsiklis,? \\Q1989\\E",
      "shortCiteRegEx" : "Bertsekas and Tsitsiklis",
      "year" : 1989
    }, {
      "title" : "Statistical analysis of non-lattice data",
      "author" : [ "J. Besag" ],
      "venue" : "J. Royal Stat. Soc. D,",
      "citeRegEx" : "Besag,? \\Q1975\\E",
      "shortCiteRegEx" : "Besag",
      "year" : 1975
    }, {
      "title" : "Distributed optimization and statistical learning via the alternating direction method of multipliers",
      "author" : [ "S. Boyd", "N. Parikh", "E. Chu", "B. Peleato", "J. Eckstein" ],
      "venue" : "Found. Trends in Machine Learn.,",
      "citeRegEx" : "Boyd et al\\.,? \\Q2011\\E",
      "shortCiteRegEx" : "Boyd et al\\.",
      "year" : 2011
    }, {
      "title" : "An asymptotic analysis of generative, discriminative, and pseudolikelihood estimators",
      "author" : [ "J.K. Bradley", "C. Guestrin" ],
      "venue" : "In AISTATS,",
      "citeRegEx" : "Bradley and Guestrin,? \\Q2011\\E",
      "shortCiteRegEx" : "Bradley and Guestrin",
      "year" : 2011
    }, {
      "title" : "Graphical models and fusion in sensor networks",
      "author" : [ "M. Cetin", "L. Chen", "J. Fisher III", "A. Ihler", "O. Kreidl", "R. Moses", "M. Wainwright", "J. Williams", "A. Willsky" ],
      "venue" : "Wireless Sensor Networks,",
      "citeRegEx" : "Cetin et al\\.,? \\Q2007\\E",
      "shortCiteRegEx" : "Cetin et al\\.",
      "year" : 2007
    }, {
      "title" : "Estimation and prediction in spatial models with block composite likelihoods using parallel computing",
      "author" : [ "J. Eidsvik", "B.A. Shaby", "B.J. Reich", "M. Wheeler", "J. Niemi" ],
      "venue" : null,
      "citeRegEx" : "Eidsvik et al\\.,? \\Q2010\\E",
      "shortCiteRegEx" : "Eidsvik et al\\.",
      "year" : 2010
    }, {
      "title" : "An asymptotic analysis of generative, discriminative, and pseudolikelihood estimators",
      "author" : [ "P. Liang", "M.I. Jordan" ],
      "venue" : "In ICML, pp",
      "citeRegEx" : "Liang and Jordan,? \\Q2008\\E",
      "shortCiteRegEx" : "Liang and Jordan",
      "year" : 2008
    }, {
      "title" : "Composite likelihood methods",
      "author" : [ "B.G. Lindsay" ],
      "venue" : "Contemporary Mathematics,",
      "citeRegEx" : "Lindsay,? \\Q1988\\E",
      "shortCiteRegEx" : "Lindsay",
      "year" : 1988
    }, {
      "title" : "Learning scale free networks by reweighted L1 regularization",
      "author" : [ "Q. Liu", "A. Ihler" ],
      "venue" : "In AISTATS, pp",
      "citeRegEx" : "Liu and Ihler,? \\Q2011\\E",
      "shortCiteRegEx" : "Liu and Ihler",
      "year" : 2011
    }, {
      "title" : "Highdimensional Ising model selection using L1-regularized logistic regression",
      "author" : [ "P. Ravikumar", "M.J. Wainwright", "J. Lafferty" ],
      "venue" : "Ann. Stat.,",
      "citeRegEx" : "Ravikumar et al\\.,? \\Q2010\\E",
      "shortCiteRegEx" : "Ravikumar et al\\.",
      "year" : 2010
    }, {
      "title" : "Piecewise training for structured prediction",
      "author" : [ "C. Sutton", "A. McCallum" ],
      "venue" : "Mach. Learn.,",
      "citeRegEx" : "Sutton and McCallum,? \\Q2009\\E",
      "shortCiteRegEx" : "Sutton and McCallum",
      "year" : 2009
    }, {
      "title" : "Estimating the wrong graphical model: Benefits in the computation-limited setting",
      "author" : [ "M. Wainwright" ],
      "venue" : "J. Machine Learn. Res.,",
      "citeRegEx" : "Wainwright,? \\Q2006\\E",
      "shortCiteRegEx" : "Wainwright",
      "year" : 2006
    }, {
      "title" : "Graphical models, exponential families, and variational inference",
      "author" : [ "M. Wainwright", "M. Jordan" ],
      "venue" : "Found. Trends Mach. Learn.,",
      "citeRegEx" : "Wainwright and Jordan,? \\Q2008\\E",
      "shortCiteRegEx" : "Wainwright and Jordan",
      "year" : 2008
    }, {
      "title" : "Distributed covariance estimation in Gaussian graphical models",
      "author" : [ "A. Wiesel", "A.O. Hero" ],
      "venue" : "IEEE Trans. Sig. Proc.,",
      "citeRegEx" : "Wiesel and Hero,? \\Q2012\\E",
      "shortCiteRegEx" : "Wiesel and Hero",
      "year" : 2012
    } ],
    "referenceMentions" : [ {
      "referenceID" : 8,
      "context" : "` is said to be information-unbiased (Lindsay, 1988) if J = H.",
      "startOffset" : 37,
      "endOffset" : 52
    }, {
      "referenceID" : 2,
      "context" : "The maximum pseudo-likelihood estimator (MPLE) (Besag, 1975) provides a computationally efficient alternative to MLE.",
      "startOffset" : 47,
      "endOffset" : 60
    }, {
      "referenceID" : 3,
      "context" : "Our algorithm is based on the alternating direction method of multipliers (ADMM), which is well suited to distributed convex optimization (Boyd et al., 2011), particularly distributed consensus (Bertsekas & Tsitsiklis, 1989).",
      "startOffset" : 138,
      "endOffset" : 157
    }, {
      "referenceID" : 10,
      "context" : "This robustness makes max consensus useful for learning in difficult graphs, such as scale free graphs, for which standard methods often perform poorly (Ravikumar et al., 2010; Liu & Ihler, 2011).",
      "startOffset" : 152,
      "endOffset" : 195
    }, {
      "referenceID" : 6,
      "context" : "Another recent work (Eidsvik et al., 2010) uses composite likelihood for parallel computing on spatial data.",
      "startOffset" : 20,
      "endOffset" : 42
    }, {
      "referenceID" : 6,
      "context" : "Another recent work (Eidsvik et al., 2010) uses composite likelihood for parallel computing on spatial data. Bradley & Guestrin (2011) gave a sample complexity analysis for MPLE and disjoint MPLE, which may be extensible to our algorithms.",
      "startOffset" : 21,
      "endOffset" : 135
    } ],
    "year" : 2012,
    "abstractText" : "Estimating statistical models within sensor networks requires distributed algorithms, in which both data and computation are distributed across the nodes of the network. We propose a general approach for distributed learning based on combining local estimators defined by pseudo-likelihood components, encompassing a number of combination methods, and provide both theoretical and experimental analysis. We show that simple linear combination or max-voting methods, when combined with second-order information, are statistically competitive with more advanced and costly joint optimization. Our algorithms have many attractive properties including low communication and computational cost and “any-time” behavior.",
    "creator" : "LaTeX with hyperref package"
  }
}