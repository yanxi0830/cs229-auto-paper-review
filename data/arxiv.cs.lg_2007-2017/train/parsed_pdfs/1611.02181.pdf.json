{
  "name" : "1611.02181.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "Using Social Dynamics to Make Individual Predictions: Variational Inference with a Stochastic Kinetic Model",
    "authors" : [ "Zhen Xu", "Wen Dong" ],
    "emails" : [ "zxu8@buffalo.edu", "wendong@buffalo.edu", "srihari@buffalo.edu" ],
    "sections" : [ {
      "heading" : "1 Introduction",
      "text" : "The field of social dynamics is concerned primarily with interactions among individuals and the resulting group behaviors. Research in social dynamics models the temporal evolution of social systems via the interactions of the individuals within these systems [8]. For example, opinion dynamics can model the opinion state transitions of an entire population in an election scenario [3], and epidemic dynamics can predict disease outbreaks ahead of time [9]. While traditional socialdynamics models focus primarily on the macroscopic effects of social systems, often we instead wish to know the answers to more specific questions. Given the movement and behavior history of a subject with Ebola, can we tell how many people should be tested or quarantined? City-size quarantine is not necessary, but family-size quarantine is insufficient. We aim to model a method to evaluate the paths of illness transmission and the risks of infection for individuals, so that limited medical resources can be most efficiently distributed.\nThe rapid growth of both social networks and sensor networks offers an unprecedented opportunity to collect abundant data at the individual level. From these data we can extract temporal interactions among individuals, such as meeting or taking the same class. To take advantage of this opportunity, we model social dynamics from an individual perspective. Although such an approach has considerable potential, in practice it is difficult to model the dynamic interactions and handle the costly computations when a large number of individuals are involved. In this paper, we introduce an\n29th Conference on Neural Information Processing Systems (NIPS 2016), Barcelona, Spain.\nar X\niv :1\n61 1.\n02 18\n1v 1\n[ st\nat .M\nL ]\n7 N\nov 2\nevent-based model into social systems to characterize their temporal evolutions and make tractable inferences on the individual level.\nOur research on the temporal evolutions of social systems is related to dynamic Bayesian networks and continuous time Bayesian networks [12, 17, 20]. Traditionally, a coupled hidden Markov model is used to capture the interactions of components in a system [2], but this model does not consider dynamic interactions. However, a stochastic kinetic model is capable of successfully describing the interactions of molecules (such as collisions) in chemical reactions [11, 21], and is widely used in many fields such as chemistry and cell biology [1, 10]. We introduce this model into social dynamics and use it to focus on individual behaviors.\nA challenge in capturing the interactions of individuals is that in social dynamics the state space grows exponentially with the number of individuals, which makes exact inference intractable. To resolve this we must apply approximate inference methods. One class of these involves sampling-based methods. Rao and Teh introduce a Gibbs sampler based on local updates [19], while Murphy and Russell introduce Rao-Blackwellized particle filtering for dynamic Bayesian networks [16]. However, sampling-based methods sometimes mix slowly and require a large number of samples/particles. To demonstrate this issue, we offer empirical comparisons with two major sampling methods in Section 4. An alternative class of approximations is based on variational inference. Opper and Sanguinetti apply the variational mean field approach to factor a Markov jump process [18], and Cohn and El-Hay further improve its efficiency by exploiting the structure of the target network [4]. A problem is that in an event-based model such as a stochastic kinetic model (SKM), the variational mean field is not applicable when a single event changes the states of two individuals simultaneously. Here, we use a general expectation propagation principle [13] to design our algorithm.\nThis paper makes three contributions: First, we introduce the discrete event model into social dynamics and make tractable inferences on both individual behaviors and collective effects. To this end, we apply the stochastic kinetic model to define adaptive transition probabilities that characterize the dynamic interaction patterns in social systems. Second, we design an efficient variational inference algorithm whose computation complexity grows linearly with the number of individuals. As a result, it scales very well in large social systems. Third, we conduct experiments on epidemic dynamics to demonstrate that our algorithm can track the transmission of epidemics and predict the probability of infection for each individual. Further, we demonstrate that the proposed method is more efficient than sampling while nonetheless achieving high accuracy.\nThe remainder of this paper is organized as follows. In Section 2, we briefly review the coupled hidden Markov model and the stochastic kinetic model. In Section 3, we propose applying a variational algorithm with the stochastic kinetic model to make tractable inferences in social dynamics. In Section 4, we detail empirical results from applying the proposed algorithm to our epidemic data along with the proximity data collected from sensor networks. Section 5 concludes."
    }, {
      "heading" : "2 Background",
      "text" : ""
    }, {
      "heading" : "2.1 Coupled Hidden Markov Model",
      "text" : "A coupled hidden Markov model (CHMM) captures the dynamics of a discrete time Markov process that joins a number of distinct hidden Markov models (HMMs), as shown in Figure 2.1(a). xt = (x\n(1) t , . . . , x (M) t ) defines the hidden states of all HMMs at time t, and x (m) t is the hidden state of\nHMM m at time t. yt = (y (1) t , . . . , y (M) t ) are observations of all HMMs at time t, and y (m) t is the observation of HMM m at time t. P (xt|xt−1) are transition probabilities, and P (yt|xt) are emission probabilities for CHMM. Given hidden states, all observations are independent. As such, P (yt|xt) = ∏ m P (y (m) t |x (m) t ), where P (y (m) t |x (m) t ) is the emission probability for HMM m at time t. The joint probability of CHMM can be defined as follows:\nP (x1,...,T ,y1,...,T ) = T∏ t=1 P (xt|xt−1)P (yt|xt). (1)\nFor a CHMM that contains M HMMs in a binary state, the state space is 2M , and the state transition kernel is a 2M × 2M matrix. In order to make exact inferences, the classic forward-backward algorithm sweeps a forward/filtering pass to compute the forward statistics αt(xt) = P (xt|y1,...,t)\nand a backward/smoothing pass to estimate the backward statistics βt(xt) = P (yt+1,...,T |xt)\nP (yt+1,...,T |y1,...,t) . Then it can estimate the one-slice statistics γt(xt) = P (xt|y1,...,T ) = αt(xt)βt(xt) and two-slice statistics ξt(xt−1,xt) = P (xt−1,xt|y1,...,T ) = αt−1(xt−1)P (xt|xt−1)P (yt|xt)βt(xt)P (yt|y1,...,t−1) . Its complexity grows exponentially with the number of HMM chains. In order to make tractable inferences, certain factorizations and approximations must be applied. In the next section, we introduce a stochastic kinetic model to lower the dimensionality of transition probabilities."
    }, {
      "heading" : "2.2 The Stochastic Kinetic Model",
      "text" : "A stochastic kinetic model describes the temporal evolution of a chemical system with M species X = {X1, X2, · · · , XM} driven by V events (or chemical reactions) parameterized by rate constants c = (c1, . . . , cV ). An event (chemical reaction) k has a general form as follows:\nr1X1 + · · ·+ rMXM ck−→ p1X1 + · · ·+ pMXM .\nThe species on the left are called reactants, and rm is the number ofmth reactant molecules consumed during the reaction. The species on the right are called products, and pm is the number ofmth product molecules produced in the reaction. Species involved in the reaction (rm > 0) without consumption or production (rm = pm) are called catalysts. At any specific time t, the populations of the species is xt = (x (1) t , . . . , x (M) t ). An event k happens with rate hk(xt, ck), determined by the rate constant and the current population state [21]:\nhk(xt, ck) =ckgk(xt) = ck M∏ m=1 g (m) k (x (m) t ). (2)\nThe form of gk(xt) depends on the reaction. In our case, we adopt the product form∏M m=1 g (m) k (x (m) t ), which represents the total number of ways that reactant molecules can be selected to trigger event k [21]. Event k changes the populations by ∆k = xt − xt−1. The probability that event k will occur during time interval (t, t+ dt] is hk(xt, ck)dt. We assume at each discrete time step that no more than one event will occur. This assumption follows the linearization principle in the literature [17], and is valid when the discrete time step is small. We treat each discrete time step as a unit of time, so that hk(xt, ck) represents the probability of an event.\nIn epidemic modeling, for example, an infection event vi has the form S + I ci−→ 2I , such that a susceptible individual (S) is infected by an infectious individual (I) with rate constant ci. If there is only one susceptible individual (type m = 1) and one infectious individual (type m = 2) involved in this event, hi(xt, ci) = ci, ∆i = [−1 1]T and P (xt − xt−1 = ∆i) = P (xt|xt−1, vi) = ci. In a traditional hidden Markov model, the transition kernel is typically fixed. In comparison, SKM is better at capturing dynamic interactions in terms of the events with rates dependent on reactant populations, as shown in Eq.(2)."
    }, {
      "heading" : "3 Variational Inference with the Stochastic Kinetic Model",
      "text" : "In this section, we define the likelihood of the entire sequence of hidden states and observations for an event-based model, and derive a variational inference algorithm and parameter-learning algorithm."
    }, {
      "heading" : "3.1 Likelihood for Event-based Model",
      "text" : "In social dynamics, we use a discrete time Markov model to describe the temporal evolutions of a set of individuals x(1), . . . , x(M) according to a set of V events. To cope with dynamic interactions, we introduce the SKM and express the state transition probabilities in terms of event probabilities, as shown in Figure 2.1(b). We assume at each discrete time step that no more than one event will occur. Let v1, . . . , vT be a sequence of events, x1, . . . ,xT a sequence of hidden states, and y1, . . . ,yT a set of observations. Similar to Eq.(1), the likelihood of the entire sequence is as follows:\nP (x1,...,T ,y1,...,T , v1,...,T ) = T∏ t=1 P (xt, vt|xt−1)P (yt|xt), where (3)\nP (xt, vt|xt−1) = { ck · gk (xt−1) · δ(xt − xt−1 ≡∆k) if vt = k (1− ∑ k ckgk (xt−1)) · δ(xt − xt−1 ≡ 0) if vt = ∅ .\nP (xt, vt|xt−1) is the event-based transition kernel. δ(xt − xt−1 ≡ ∆k) is 1 if the previous state is xt−1 and the current state is xt = xt−1 + ∆k, and 0 otherwise. ∆k is the effect of event vk. ∅ represents an auxiliary event, meaning that there is no event. Substituting the product form of gk, the transition kernel can be written as follows:\nP (xt, vt = k|xt−1) = ck ∏ m g (m) k (x (m) t−1) · ∏ m δ(x (m) t − x (m) t−1 ≡ ∆ (m) k ), (4)\nP (xt, vt = ∅|xt−1) = (1− ∑ k ck ∏ m g (m) k (x (m) t−1)) · ∏ m δ(x (m) t − x (m) t−1 ≡ 0), (5)\nwhere δ(x(m)t − x (m) t−1 ≡ ∆ (m) k ) is 1 if the previous state of an individual m is x (m) t−1 and the current state is x(m)t = x (m) t−1 + ∆ (m) k , and 0 otherwise."
    }, {
      "heading" : "3.2 Variational Inference for Stochastic Kinetic Model",
      "text" : "As noted in Section 2.1, exact inference in social dynamics is intractable due to the formidable state space. However, we can approximate the posterior distribution P (x1,...,T , v1,...,T |y1,...,T ) using an approximate distribution within the exponential family. The inference algorithm minimizes the KL divergence between these two distributions, which can be formulated as an optimization problem [13]:\nMinimize: ∑\nt,xt−1,xt,vt\nξ̂(xt−1,xt, vt) · log ξ̂(xt−1,xt, vt)\nP (xt, vt|xt−1)P (yt|xt) (6)\n− ∑ t,xt ∏ m γ̂ (m) t (x (m) t ) log ∏ m γ̂ (m) t (x (m) t )\nSubject to: ∑ vt,xt−1,{xt\\x(m)t } ξ̂(xt−1,xt, vt) = γ̂ (m) t (x (m) t ), for all t,m, x (m) t ,\n∑ vt,{xt−1\\x(m)t−1},xt ξ̂(xt−1,xt, vt) = γ̂ (m) t−1(x (m) t−1), for all t,m, x (m) t−1,\n∑ x\n(m) t\nγ̂ (m) t (x (m) t ) = 1, for all t,m.\nThe objective function is the Bethe free energy, composed of average energy and Bethe entropy approximation [22]. ξ̂(xt−1,xt, vt) is the approximate two-slice statistics and γ̂(m)(x (m) t ) is the approximate one-slice statistics for each individual m. They form the approximate distribution over which to minimize the Bethe free energy. The ∑ t,xt−1,xt,vt is an abbreviation for summing over\nt, xt−1, xt, and vt. ∑ {xt\\x(m)t } is the sum over all individuals in xt except x (m) t . We use similar abbreviations below. The first two sets of constraints are marginalization conditions, and the third\nis normalization conditions. To solve this constrained optimization problem, we first define the Lagrange function using Lagrange multipliers to weight constraints, then take the partial derivatives with respect to ξ̂(xt−1,xt, vt), and γ̂(m)(x (m) t ). The dual problem is to find the approximate forward statistics α̂(m)t−1(x (m) t−1) and backward statistics β̂ (m) t (x (m) t ) in order to maximize the pseudo-likelihood function. The duality is between minimizing Bethe free energy and maximizing pseudo-likelihood. The fixed-point solution for the primal problem is as follows1:\nξ̂(x (m) t−1, x (m) t , vt) =\n1\nZt ∑ m′ 6=m,x(m\n′) t−1 ,x (m′) t\nP (xt,vt|xt−1)· ∏ m α̂ (m) t−1(x (m) t−1)· ∏ m P (y (m) t |x (m) t )· ∏ m β̂ (m) t (x (m) t ). (7)\nξ̂(x (m) t−1, x (m) t , vt) is the two-slice statistics for an individual m, and Zt is the normalization constant. Given the factorized form of P (xt, vt|xt−1) in Eqs. (4) and (5), everything in Eq. (7) can be written in a factorized form. After reformulating the term relevant to the individual m, ξ̂(x(m)t−1, x (m) t , vt) can be shown neatly as follows:\nξ̂t(x (m) t−1, x (m) t , vt) =\n1\nZt P̂ (x\n(m) t , vt|x (m) t−1) · α̂ (m) t−1(x (m) t−1)P (y (m) t |x (m) t )β̂ (m) t (x (m) t ), (8)\nwhere the marginalized transition kernel P̂ (x(m)t , vt|x (m) t−1) for the individual m can be defined as:\nP̂ (x (m) t , vt = k|x (m) t−1) = ckg (m) k (x (m) t−1) ∏ m′ 6=m g̃ (m′) k,t−1 · δ(x (m) t − x (m) t−1 ≡ ∆ (m) k ), (9)\nP̂ (x (m) t , vt = ∅|x (m) t−1) = 1−∑ k ckg (m) k (x (m) t−1) ∏ m′ 6=m ĝ (m′) k,t−1  δ(x(m)t − x(m)t−1 ≡ 0), (10) g̃\n(m′) k,t−1= ∑ x (m′) t −x (m′) t−1 ≡∆ (m′) k α (m′) t−1 (x (m′) t−1 )P (y (m′) t |x (m′) t )β (m′) t (x (m′) t )g (m′) k (x (m′) t−1 ) /∑ x (m′) t −x (m′) t−1 ≡0 α (m′) t−1 (x (m′) t−1 )P (y (m′) t |x (m′) t )β (m′) t (x (m′) t ),\nĝ (m′) k,t−1= ∑ x (m′) t −x (m′) t−1 ≡0 α(x (m′) t−1 )P (y (m′) t |x (m′) t )β (m′) t (x (m′) t )g (m′) k (x (m′) t−1 ) /∑ x (m′) t −x (m′) t−1 ≡0 α (m′) t−1 (x (m′) t−1 )P (y (m′) t |x (m′) t )β (m′) t (x (m′) t ),\nIn the above equations, we consider the mean field effect by summing over the current and previous states of all the other individualsm′ 6= m. The marginalized transition kernel considers the probability of event k on the individual m given the context of the temporal evolutions of the other individuals. Comparing Eqs. (9) and (10) with Eqs. (4) and (5), instead of multiplying g(m\n′) k (x (m′) t−1 ) for individual\nm′ 6= m, we use the expected value of g(m ′)\nk with respect to the marginal probability distribution of x (m′) t−1 .\nComplexity Analysis: In our inference algorithm, the most computation-intensive step is the marginalization in Eqs. (9)-(10). The complexity is O(MS2), where M is the number of individuals and S is the state space of a single individual. The complexity of the entire algorithm is therefore O(MS2TN), where T is the number of time steps and N is the number of iterations until convergence. As such, the complexity of our algorithm grows only linearly with the number of individuals; it offers excellent scalability when the number of tracked individuals becomes large."
    }, {
      "heading" : "3.3 Parameter Learning",
      "text" : "In order to learn the rate constant ck, we maximize the expected log likelihood. In a stochastic kinetic model, the probability of a sample path is given in Eq. (3). The expected log likelihood over the posterior probability conditioned on the observations y1, . . . ,yT takes the following form:\nlogP (x1,...,T ,y1,...,T , v1,...,T ) = ∑ t,xt−1,xt,vt ξ̂t(xt−1,xt, vt) · log(P (xt, vt|xt−1)P (yt|xt)).\nξ̂t (xt−1,xt, vt) is the approximate two-slice statistics defined in Eq. (6). Maximizing this expected log likelihood by setting its partial derivative over the rate constants to 0 gives the maximum expected log likelihood estimation of these rate constants.\nck =\n∑ t,xt−1,xt\nξ̂t(xt−1,xt, vt = k)∑ t,xt−1,xt ξ̂t(xt−1,xt, vt = ∅)gk(xt−1) ≈\n∑ t ∑ xt−1,xt\nξ̂t(xt−1,xt, vt = k)∑ t ∏ m ∑ x\n(m) t−1\nγ̂ (m) t−1(x (m) t−1)g (m) k (x (m) t−1)\n. (11)\n1The derivations for the optimization problem and its solution are shown in the Supplemental Material.\nAs such, the rate constant for event k is the expected number of times that this event has occurred divided by the total expected number of times this event could have occurred.\nTo summarize, we provide the variational inference algorithm below.\nAlgorithm: Variational Inference with a Stochastic Kinetic Model\nGiven the observations y(m)t for t = 1, . . . , T and m = 1, . . . ,M , find x (m) t , vt and rate constants ck for k = 1, . . . , V .\nLatent state inference. Iterate through the following forward and backward passes until convergence, where P̂ (x(m)t , vt|x (m) t−1) is given by Eqs. (9) and (10).\n• Forward pass. For t = 1, . . . , T and m = 1, . . . ,M , update α̂(m)t (x (m) t ) according to\nα̂ (m) t (x (m) t )←\n1\nZt ∑ x\n(m) t−1,vt\nα̂ (m) t−1(x (m) t−1)P̂ (x (m) t , vt|x (m) t−1)P (y (m) t |x (m) t ).\n• Backward pass. For t = T, . . . , 1 and m = 1, . . . ,M , update β̂(m)t−1(x (m) t−1) according to\nβ̂ (m) t−1(x (m) t−1)←\n1\nZt ∑ x\n(m) t ,vt\nβ̂ (m) t (x (m) t )P̂ (x (m) t , vt|x (m) t−1)P (y (m) t |x (m) t ).\nParameter estimation. Iterate through the latent state inference (above) and rate constants estimate of ck according to Eq. (11), until convergence."
    }, {
      "heading" : "4 Experiments on Epidemic Applications",
      "text" : "In this section, we evaluate the performance of variational inference with a stochastic kinetic model (VISKM) algorithm of epidemic dynamics, with which we predict the transmission of diseases and the health status of each individual based on proximity data collected from sensor networks."
    }, {
      "heading" : "4.1 Epidemic Dynamics",
      "text" : "In epidemic dynamics, Gt = (M, Et) is a dynamic network, where each node m ∈ M is an individual in the network, and Et = {(mi,mj)} is a set of edges in Gt representing that individuals mi and mj have interacted at a specific time t. There are two possible hidden states for each individual m at time t, x(m)t ∈ {0, 1}, where 0 indicates the susceptible state and 1 the infectious state. y(m)t ∈ {0, 1} represents the presence or absence of symptoms for individual m at time t. P (y\n(m) t |x (m) t ) represents the observation probability. We define three types of events in epidemic applications: (1) A previously infectious individual recovers and becomes susceptible again: I c1−→ S. (2) An infectious individual infects a susceptible individual in the network: S + I c2−→ 2I . (3) A susceptible individual in the network is infected by an outside infectious individual: S c3−→ I . Based on these events, the transition kernel can be defined as follows:\nP (x (m) t = 0|x (m) t−1 = 1) = c1, P (x (m) t = 1|x (m) t−1 = 1) = 1− c1,\nP (x (m) t =0|x (m) t−1 =0) = (1− c3)(1− c2)Cm,t , P (x (m) t =1|x (m) t−1 =0) = 1− (1− c3)(1− c2)Cm,t , where Cm,t = ∑ m′:(m′,m)∈Et δ(x (m′) t ≡ 1) is the number of possible infectious sources for individual m at time t. Intuitively, the probability of a susceptible individual becoming infected is 1 minus the probability that no infectious individuals (inside or outside the network) infected him. When the probability of infection is very small, we can approximate P (x(m)t = 1|x (m) t−1 = 0) ≈ c3+c2 ·Cm,t."
    }, {
      "heading" : "4.2 Experimental Results",
      "text" : "Data Explanation: We employ two data sets of epidemic dynamics. The real data set is collected from the Social Evolution experiment [5]. This study records “common cold” symptoms of 65 students living in a university residence hall from January 2009 to April 2009, tracking their locations and proximities using mobile phones. In addition, the students took periodic surveys regarding their health status and personal interactions. The synthetic data set was collected on the Dartmouth College campus from April 2001 to June 2004, and contains the movement history of 13,888 individuals [15]. We synthesized disease transmission along a timeline using the popular susceptible-infectioussusceptible (SIS) epidemiology model [14], then applied the VISKM to calibrate performance. We selected this data set because we want to demonstrate that our model works on data with a large number of people over a long period of time.\nEvaluation Metrics and Baseline Algorithms: We select the receiver operating characteristic (ROC) curve as our performance metric because the discrimination thresholds of diseases vary. We first compare the accuracy and efficiency of VISKM with Gibbs sampling (Gibbs) and particle filtering (PF) on the Social Evolution data set [6, 7].2 Both Gibbs sampling and particle filtering iteratively sample the infectious and susceptible latent state sequences and the infection and recovery events conditioned on these state sequences. Gibbs-Prediction-10000 indicates 10,000 iterations of Gibbs sampling with 1000 burn-in iterations for the prediction task. PF-Smoothing-1000 similarly refers to 1000 iterations of particle filtering for the smoothing task. All experiments are performed on the same computer.\nIndividual State Inference: We infer the probabilities of a hidden infectious state for each individual at different times under different scenarios. There are three tasks: 1. Prediction: Given an individual’s past health and current interaction patterns, we predict the current infectious latent state. Figure 2(a) compares prediction performance among the different approximate inference methods. 2. Smoothing: Given an individual’s interaction patterns and past health with missing periods, we infer the infectious latent states during these missing periods. Figure 2(b) compares the performance of the three inference methods. 3. Expansion: Given the health records of a portion (∼ 10%) of the population, we estimate the individual infectious states of the entire population before medically inspecting them. For example, given either a group of volunteers willing to report their symptoms or the symptom data of patients who came to hospitals, we determine the probabilities that the people near these individuals also became or will become infected. This information helps the government or aid agencies to efficiently distribute limited medical resources to those most in need. Figure 2(c) compares the performance of the different methods. From the above three graphs, we can see that all three methods identify the infectious states in an accurate way. However, VISKM outperforms Gibbs sampling and particle filtering in terms of area under the ROC curve for all three tasks. VISKM has an advantage in the smoothing task because the backward pass helps to infer the missing states using subsequent observations. In addition, the performance of Gibbs and PF improves as the number of samples/particles increases.\nFigure 2(d) shows the performance of the three tasks on the Dartmouth data set. We do not apply the same comparison because it takes too much time for sampling. From the graph, we can see that VISKM infers most of the infectious moments of individuals in an accurate way for a large social system. In addition, the smoothing results are slightly better than the prediction results because we can leverage observations from both directions. The expansion case is relatively poor, because we use only very limited information to derive the results; however, even in this case the ROC curve has good discriminating power to differentiate between infectious and susceptible individuals.\nCollective Statistics Inference: After determining the individual results, we aggregate them to approximate the total number of infected individuals in the social system as time evolves. This offers a collective statistical summary of the spread of disease in one area as in traditional research, which typically scales the sample statistics with respect to the sample ratio. Figures 2(e) and (f) show that given 20% of the Social Evolution data and 10% of the Dartmouth data, VISKM estimates the collective statistics better than the other methods.\nEfficiency and Scalability: Table 1 shows the running time of different algorithms for the Social Evolution data on the same computer. From the table, we can see that Gibbs sampling runs slightly longer than PF, but they are in the same scale. However, VISKM requires much less computation time.\n2Code and data are available at http://cse.buffalo.edu/~wendong/.\nIn addition, the computation time of VISKM grows linearly with the number of individuals, which validates the complexity analysis in Section 3.2. Thus, it offers excellent scalability for large social systems. In comparison, Gibbs sampling and PF grow super linearly with the number of individuals, and roughly linearly with the number of samples.\nSummary: Our proposed VISKM achieves higher accuracy in terms of area under ROC curve and collective statistics than Gibbs sampling or particle filtering (within 10,000 iterations). More importantly, VISKM is more efficient than sampling with much less computation time. Additionally, the computation time of VISKM grows linearly with the number of individuals, demonstrating its excellent scalability for large social systems."
    }, {
      "heading" : "5 Conclusions",
      "text" : "In this paper, we leverage sensor network and social network data to capture temporal evolution in social dynamics and infer individual behaviors. In order to define the adaptive transition kernel, we introduce a stochastic dynamic mode that captures the dynamics of complex interactions. In addition, in order to make tractable inferences we propose a variational inference algorithm the computation complexity of which grows linearly with the number of individuals. Large-scale experiments on epidemic dynamics demonstrate that our method effectively captures the evolution of social dynamics and accurately infers individual behaviors. More accurate collective effects can be also derived through the aggregated results. Potential applications for our algorithm include the dynamics of emotion, opinion, rumor, collaboration, and friendship."
    }, {
      "heading" : "6 Appendix",
      "text" : ""
    }, {
      "heading" : "6.1 Derivation of the optimization problem in Eq.(6)",
      "text" : "Let P (x1,...,T , v1,...,T |y1,...,T ) be the exact posterior. Our goal is to approximate this posterior by a distribution Q(x1,...,T , v1,...,T ) in the exponential family that minimizes the KL divergence between these two distributions:\nKL(Q(x1,...,T , v1,...,T )|P (x1,...,T , v1,...,T |y1,...,T )) = ∑\nx1,...,T ,v1,...,T\nQ(x1,...,T , v1,...,T ) log[ Q(x1,...,T , v1,...,T ) · P (y1,...,T ) P (x1,...,T ,y1,...,T , v1,...,T ) ]\n= ∑\nx1,...,T ,v1,...,T\nQ(x1,...,T , v1,...,T ) logQ(x1,...,T , v1,...,T )\n− T∑ t=1 ∑ x1,...,T ,v1,...,T Q(x1,...,T , v1,...,T ) logP (xt,yt, vt|xt−1). (12)\nIn the first step, we apply the definition of conditional probability and KL-divergence. In the second, we omit P (y1,...,T ) because it is a constant in this optimization problem. In addition, we decompose P (x1,...,T ,y1,...,T , v1,...,T ) = ∏T t=1 P (xt,yt, vt|xt−1).\nWe then define the approximate two-slice statistics ξ̂(xt−1,xt, vt) and one-slice statistics γ̂(xt). Both are in the exponential family. In this context, we have M individuals in the system and the mean-field approximation can be shown as γ̂(xt) = ∏N m=1 γ̂ (m)(x (m) t ), where γ̂ (m)(x (m) t ) is the approximate one-slice statistics for individual m. Given the observation that Q(x1,...,T , v1,...,T ) can be expressed as a product of two-slice statistics divided by a product of one-slice statistics, then\nQ(x1,...,T , v1,...,T ) = ∏T t=1 ξ̂(xt−1,xt, vt)∏T−1\nt=1 γ̂(xt) =\n∏T t=1 ξ̂(xt−1,xt, vt)∏T−1\nt=1 ∏M m=1 γ̂ (m)(x (m) t ) . (13)\nIf we substitute Eq. (13) into Eq. (12), the objective function becomes the following:∑ x1,...,T ,v1,...,T Q(x1,...,T , v1,...,T ) log ∏T t=1 ξ̂(xt−1,xt, vt)∏T−1 t=1 ∏ m γ̂ (m)(x (m) t )\n− T∑ t=1 ∑ x1,...,T ,v1,...,T Q(x1,...,T , v1,...,T ) logP (xt,yt, vt|xt−1)\n= ∑\nt,xt−1,xt,vt\nξ̂(xt−1,xt, vt) log ξ̂(xt−1,xt, vt)\nP (xt,yt, vt|xt−1) − ∑ t,xt ∏ m γ̂(m)(x (m) t ) log ∏ m γ̂(m)(x (m) t ). (14)\nThis objective function is subject to marginalization and normalization constraints:∑ vt,xt−1,{xt\\x(m)t } ξ̂(xt−1,xt, vt) = γ̂ (m) t (x (m) t ), for all t,m, x (m) t ,\n∑ vt,{xt−1\\x(m)t−1},xt ξ̂(xt−1,xt, vt) = γ̂ (m) t−1(x (m) t−1), for all t,m, x (m) t−1,\n∑ x\n(m) t\nγ̂ (m) t (x (m) t ) = 1, for all t,m.\n∑ {xt\\x(m)t } refers to the sum over all values of xt except x (m) t ."
    }, {
      "heading" : "6.2 Derivation of the inference algorithm from Eq.(8) to Eq.(10)",
      "text" : "The optimization problem derived from Eq. (14) along with the constraints can be shown as follows:∑ t,xt−1,xt,vt ξ̂(xt−1,xt, vt) log ξ̂(xt−1,xt, vt) P (xt,yt, vt|xt−1) − ∑ t,xt ∏ m γ̂ (m) t (x (m) t ) log ∏ m γ̂ (m) t (x (m) t ) (15)\nsubject to:∑ vt,xt−1,{xt\\x(m)t } ξ̂(xt−1,xt, vt) = γ̂ (m) t (x (m) t ), for all t,m, x (m) t ,\n∑ vt,{xt−1\\x(m)t−1},xt ξ̂(xt−1,xt, vt) = γ̂ (m) t−1(x (m) t−1), for all t,m, x (m) t−1,\n∑ x\n(m) t\nγ̂ (m) t (x (m) t ) = 1, for all t,m.\nWe apply the method of Lagrange multipliers to solve this, which begins with forming the Lagrange function to be optimized:\nL = ∑ t,xt−1,xt,vt ξ̂(xt−1,xt, vt) log ξ̂(xt−1,xt, vt) P (xt,yt, vt|xt−1) − ∑ t,xt ∏ m γ̂ (m) t (x (m) t ) log ∏ m γ̂ (m) t (x (m) t ) (16)\n+ ∑\nt,m,x (m) t\nλ (m) t (x (m) t ) ∑ vt,xt−1,{xt\\x(m)t } γ̂ (m) t (x (m) t )− ξ̂(xt−1,xt, vt)  + ∑\nt,m,x (m) t−1\nµ (m) t−1(x (m) t−1) ∑ vt,{xt−1\\x(m)t−1},xt γ̂ (m) t−1(x (m) t−1)− ξ̂(xt−1,xt, vt)  . + ∑\nt,m,x (m) t\nν(x (m) t ) ∑ x\n(m) t\nγ̂ (m) t (x (m) t )− 1  We then set the partial derivatives of Eq. (16) over ξ̂(xt−1,xt, vt) to 0, which results in the following:\n∂L\n∂ξ̂(xt−1,xt, vt) = log\nξ̂(xt−1,xt, vt)\nP (xt,yt, vt|xt−1) + 1− ∑ m λ (m) t (x (m) t )− ∑ m µ (m) t−1(x (m) t−1) set = 0\n⇒ ξ̂(xt−1,xt, vt) ∝ exp (∑ m µ (m) t−1(x (m) t−1) ) P (xt,yt, vt|xt−1) exp (∑ m λ (m) t (x (m) t ) ) ,\nAs such, we see that α̂(m)t−1(x (m) t−1) = exp(µ (m) t−1(x (m) t−1)) is associated with the forward probabilities and β̂(m)t (x (m) t ) = exp(λ (m) t (x (m) t )) with the backward probabilities, with γ̂ (m) t (x (m) t ) = α̂ (m) t (x (m) t )β̂ (m) t (x (m) t ). We can determine the two-slice statistics for an individual m by marginalizing the other individuals m′ 6= m:\nξ̂(x (m) t−1, x (m) t , vt) = ∑ m′ 6=m,x(m\n′) t−1 ,x (m′) t\nξ̂(xt−1,xt, vt)\n∝ ∑ m′ 6=m,x(m\n′) t−1 ,x (m′) t\nP (xt, vt|xt−1) · ∏ m α̂ (m) t−1(x (m) t−1) · ∏ m P (y (m) t |x (m) t ) · ∏ m β̂ (m) t (x (m) t ).\nThe above is the same as in Eq. (7)."
    }, {
      "heading" : "6.3 Derivation of the parameter-learning algorithm",
      "text" : "From Eq.(3), the log-likelihood of the entire sequence can be shown as this:\nlogP (x1,...,T ,y1,...,T , v1,...,T ) = T∑ t=1 logP (xt, vt|xt−1) + T∑ t=1 logP (yt|xt), where (17)\nP (xt, vt|xt−1) = { ck · gk (xt−1) · δ(xt − xt−1 ≡∆k) if vt = k (1− ∑ k ckgk (xt−1)) · δ(xt − xt−1 ≡ 0) if vt = ∅ .\nThe probabilities for state transition can be shown as the probabilities of a set of events. The expected log likelihood over the posterior probability conditioned on the observations y1, . . . ,yT takes the following form:\nEP (x1,...,T ,v1,...,T |y1,...,T ) (logP (x1,...,T ,y1,...,T , v1,...,T )) (18) = ∑ t,xt−1,xt,vt ξ̂t(xt−1,xt, vt) · log (P (xt, vt|xt−1)P (yt|xt))\n= ∑ t,xt−1,xt ξ̂t(xt−1,xt, vt = v) · log (P (xt, vt = v|xt−1)P (yt|xt))\n+ ∑ t,xt−1,xt ξ̂t(xt−1,xt, vt = ∅) · log (P (xt, vt = ∅|xt−1)P (yt|xt))\nAt a given time t, there are two possible cases: vt = v, where v ∈ {1, · · · , V }, and vt = ∅. The derivatives with respect to ck can be shown as follows:\n∂ logP (xt, vt = k|xt−1) ∂ck = 1\nck ∂ logP (xt, vt = ∅|xt−1)\n∂ck = −gk(xt−1) 1− ∑ k ckgk(xt−1)\nNote that here we do not detail δ(xt − xt−1 ≡∆k) and δ(xt − xt−1 ≡ 0) explicitly, because when calculating the derivatives of expected log likelihood in Eq.(18) these terms will be contained in ξ̂t(xt−1,xt, vt = k) and ξ̂t(xt−1,xt, vt = ∅). Next we take the derivative of expected log likelihood with respect to ck:\nEP (x1,...,T ,v1,...,T |y1,...,T ) (logP (x1,...,T ,y1,...,T , v1,...,T ))\n∂ck (19)\n= ∑ t,xt−1,xt ξ̂t(xt−1,xt, vt = k) 1 ck − ∑ t,xt−1,xt, ξ̂t(xt−1,xt, vt = ∅) gk(xt−1) 1− ∑ k ckgk(xt−1)\nBecause we assume that the auxiliary event dominates when the time step is small, we approximate 1−∑ k ckgk(xt) ≈ 1 and ∑ xt ξ̂t(xt−1,xt, vt = ∅) ≈ γ̂t−1(xt−1). After applying this approximation and setting the derivative to 0, the result is as follows:\nck =\n∑ t ∑ xt−1,xt\nξ̂t(xt−1,xt, vt = k)∑ t ∑ xt−1,xt ξ̂t(xt−1,xt, vt = ∅)gk(xt−1) (20)\n≈ ∑ t ∑ xt−1,xt\nξ̂t(xt−1,xt, vt = k)∑ t ∑ xt−1 γ̂t−1(xt−1)gk(xt−1)\n=\n∑ t ∑ xt−1,xt\nξ̂t(xt−1,xt, vt = k)∑ t ∏ m ∑ x\n(m) t−1\nγ̂ (m) t−1(x (m) t−1)g (m) k (x (m) t−1)\n."
    } ],
    "references" : [ {
      "title" : "Stochastic kinetic analysis of developmental pathway bifurcation in phage λ-infected escherichia coli cells",
      "author" : [ "Adam Arkin", "John Ross", "Harley H McAdams" ],
      "venue" : "Genetics, 149(4):1633–1648,",
      "citeRegEx" : "1",
      "shortCiteRegEx" : "1",
      "year" : 1998
    }, {
      "title" : "Coupled hidden markov models for complex action recognition",
      "author" : [ "Matthew Brand", "Nuria Oliver", "Alex Pentland" ],
      "venue" : "In Proc. of CVPR,",
      "citeRegEx" : "2",
      "shortCiteRegEx" : "2",
      "year" : 1997
    }, {
      "title" : "Statistical physics of social dynamics",
      "author" : [ "Claudio Castellano", "Santo Fortunato", "Vittorio Loreto" ],
      "venue" : "Reviews of modern physics,",
      "citeRegEx" : "3",
      "shortCiteRegEx" : "3",
      "year" : 2009
    }, {
      "title" : "Mean field variational approximation for continuous-time bayesian networks",
      "author" : [ "Ido Cohn", "Tal El-Hay", "Nir Friedman", "Raz Kupferman" ],
      "venue" : "The Journal of Machine Learning Research,",
      "citeRegEx" : "4",
      "shortCiteRegEx" : "4",
      "year" : 2010
    }, {
      "title" : "Modeling the co-evolution of behaviors and social relationships using mobile phone data",
      "author" : [ "Wen Dong", "Bruno Lepri", "Alex Sandy Pentland" ],
      "venue" : "In Proc. of the 10th International Conference on Mobile and Ubiquitous Multimedia,",
      "citeRegEx" : "5",
      "shortCiteRegEx" : "5",
      "year" : 2011
    }, {
      "title" : "Graph-coupled hmms for modeling the spread of infection",
      "author" : [ "Wen Dong", "Alex Pentland", "Katherine A Heller" ],
      "venue" : "In Proc. of UAI,",
      "citeRegEx" : "6",
      "shortCiteRegEx" : "6",
      "year" : 2012
    }, {
      "title" : "A tutorial on particle filtering and smoothing",
      "author" : [ "Arnaud Doucet", "Adam M Johansen" ],
      "venue" : "Fifteen years later. Handbook of Nonlinear Filtering,",
      "citeRegEx" : "7",
      "shortCiteRegEx" : "7",
      "year" : 2009
    }, {
      "title" : "Modelling disease outbreaks in realistic urban social",
      "author" : [ "Stephen Eubank", "Hasan Guclu", "VS Anil Kumar", "Madhav V Marathe", "Aravind Srinivasan", "Zoltan Toroczkai", "Nan Wang" ],
      "venue" : "networks. Nature,",
      "citeRegEx" : "9",
      "shortCiteRegEx" : "9",
      "year" : 2004
    }, {
      "title" : "Stochastic simulation of chemical kinetics",
      "author" : [ "Daniel T Gillespie" ],
      "venue" : "Annu. Rev. Phys. Chem.,",
      "citeRegEx" : "10",
      "shortCiteRegEx" : "10",
      "year" : 2007
    }, {
      "title" : "Bayesian parameter inference for stochastic biochemical network models using particle markov chain monte carlo",
      "author" : [ "Andrew Golightly", "Darren J Wilkinson" ],
      "venue" : "Interface focus,",
      "citeRegEx" : "11",
      "shortCiteRegEx" : "11",
      "year" : 2011
    }, {
      "title" : "Dynamic probabilistic models for latent feature propagation in social networks",
      "author" : [ "Creighton Heaukulani", "Zoubin Ghahramani" ],
      "venue" : "In Proc. of ICML,",
      "citeRegEx" : "12",
      "shortCiteRegEx" : "12",
      "year" : 2013
    }, {
      "title" : "Expectation propagation for approximate inference in dynamic bayesian networks",
      "author" : [ "Tom Heskes", "Onno Zoeter" ],
      "venue" : "In Proc. of UAI,",
      "citeRegEx" : "13",
      "shortCiteRegEx" : "13",
      "year" : 2002
    }, {
      "title" : "Modeling infectious diseases in humans and animals",
      "author" : [ "Matt J Keeling", "Pejman Rohani" ],
      "venue" : null,
      "citeRegEx" : "14",
      "shortCiteRegEx" : "14",
      "year" : 2008
    }, {
      "title" : "CRAWDAD data set dartmouth/campus (v. 2007-02-08)",
      "author" : [ "David Kotz", "Tristan Henderson", "Ilya Abyzov", "Jihwang Yeo" ],
      "venue" : null,
      "citeRegEx" : "15",
      "shortCiteRegEx" : "15",
      "year" : 2007
    }, {
      "title" : "Rao-blackwellised particle filtering for dynamic bayesian networks. In Sequential Monte Carlo methods in practice, pages 499–515",
      "author" : [ "Kevin Murphy", "Stuart Russell" ],
      "venue" : null,
      "citeRegEx" : "16",
      "shortCiteRegEx" : "16",
      "year" : 2001
    }, {
      "title" : "Continuous time bayesian networks",
      "author" : [ "Uri Nodelman", "Christian R Shelton", "Daphne Koller" ],
      "venue" : "In Proc. of UAI,",
      "citeRegEx" : "17",
      "shortCiteRegEx" : "17",
      "year" : 2002
    }, {
      "title" : "Variational inference for markov jump processes",
      "author" : [ "Manfred Opper", "Guido Sanguinetti" ],
      "venue" : "In Proc. of NIPS, pages 1105–1112,",
      "citeRegEx" : "18",
      "shortCiteRegEx" : "18",
      "year" : 2008
    }, {
      "title" : "Fast MCMC sampling for markov jump processes and continuous time bayesian networks",
      "author" : [ "V. Rao", "Y.W. Teh" ],
      "venue" : "In Proc. of UAI,",
      "citeRegEx" : "19",
      "shortCiteRegEx" : "19",
      "year" : 2011
    }, {
      "title" : "Learning non-stationary dynamic bayesian networks",
      "author" : [ "Joshua W Robinson", "Alexander J Hartemink" ],
      "venue" : "The Journal of Machine Learning Research,",
      "citeRegEx" : "20",
      "shortCiteRegEx" : "20",
      "year" : 2010
    }, {
      "title" : "Stochastic modeling for systems biology",
      "author" : [ "Darren J Wilkinson" ],
      "venue" : "CRC press,",
      "citeRegEx" : "21",
      "shortCiteRegEx" : "21",
      "year" : 2011
    }, {
      "title" : "Understanding belief propagation and its generalizations",
      "author" : [ "Jonathan S Yedidia", "William T Freeman", "Yair Weiss" ],
      "venue" : "Exploring artificial intelligence in the new millennium,",
      "citeRegEx" : "22",
      "shortCiteRegEx" : "22",
      "year" : 2003
    } ],
    "referenceMentions" : [ {
      "referenceID" : 2,
      "context" : "For example, opinion dynamics can model the opinion state transitions of an entire population in an election scenario [3], and epidemic dynamics can predict disease outbreaks ahead of time [9].",
      "startOffset" : 118,
      "endOffset" : 121
    }, {
      "referenceID" : 7,
      "context" : "For example, opinion dynamics can model the opinion state transitions of an entire population in an election scenario [3], and epidemic dynamics can predict disease outbreaks ahead of time [9].",
      "startOffset" : 189,
      "endOffset" : 192
    }, {
      "referenceID" : 10,
      "context" : "Our research on the temporal evolutions of social systems is related to dynamic Bayesian networks and continuous time Bayesian networks [12, 17, 20].",
      "startOffset" : 136,
      "endOffset" : 148
    }, {
      "referenceID" : 15,
      "context" : "Our research on the temporal evolutions of social systems is related to dynamic Bayesian networks and continuous time Bayesian networks [12, 17, 20].",
      "startOffset" : 136,
      "endOffset" : 148
    }, {
      "referenceID" : 18,
      "context" : "Our research on the temporal evolutions of social systems is related to dynamic Bayesian networks and continuous time Bayesian networks [12, 17, 20].",
      "startOffset" : 136,
      "endOffset" : 148
    }, {
      "referenceID" : 1,
      "context" : "Traditionally, a coupled hidden Markov model is used to capture the interactions of components in a system [2], but this model does not consider dynamic interactions.",
      "startOffset" : 107,
      "endOffset" : 110
    }, {
      "referenceID" : 9,
      "context" : "However, a stochastic kinetic model is capable of successfully describing the interactions of molecules (such as collisions) in chemical reactions [11, 21], and is widely used in many fields such as chemistry and cell biology [1, 10].",
      "startOffset" : 147,
      "endOffset" : 155
    }, {
      "referenceID" : 19,
      "context" : "However, a stochastic kinetic model is capable of successfully describing the interactions of molecules (such as collisions) in chemical reactions [11, 21], and is widely used in many fields such as chemistry and cell biology [1, 10].",
      "startOffset" : 147,
      "endOffset" : 155
    }, {
      "referenceID" : 0,
      "context" : "However, a stochastic kinetic model is capable of successfully describing the interactions of molecules (such as collisions) in chemical reactions [11, 21], and is widely used in many fields such as chemistry and cell biology [1, 10].",
      "startOffset" : 226,
      "endOffset" : 233
    }, {
      "referenceID" : 8,
      "context" : "However, a stochastic kinetic model is capable of successfully describing the interactions of molecules (such as collisions) in chemical reactions [11, 21], and is widely used in many fields such as chemistry and cell biology [1, 10].",
      "startOffset" : 226,
      "endOffset" : 233
    }, {
      "referenceID" : 17,
      "context" : "Rao and Teh introduce a Gibbs sampler based on local updates [19], while Murphy and Russell introduce Rao-Blackwellized particle filtering for dynamic Bayesian networks [16].",
      "startOffset" : 61,
      "endOffset" : 65
    }, {
      "referenceID" : 14,
      "context" : "Rao and Teh introduce a Gibbs sampler based on local updates [19], while Murphy and Russell introduce Rao-Blackwellized particle filtering for dynamic Bayesian networks [16].",
      "startOffset" : 169,
      "endOffset" : 173
    }, {
      "referenceID" : 16,
      "context" : "Opper and Sanguinetti apply the variational mean field approach to factor a Markov jump process [18], and Cohn and El-Hay further improve its efficiency by exploiting the structure of the target network [4].",
      "startOffset" : 96,
      "endOffset" : 100
    }, {
      "referenceID" : 3,
      "context" : "Opper and Sanguinetti apply the variational mean field approach to factor a Markov jump process [18], and Cohn and El-Hay further improve its efficiency by exploiting the structure of the target network [4].",
      "startOffset" : 203,
      "endOffset" : 206
    }, {
      "referenceID" : 11,
      "context" : "Here, we use a general expectation propagation principle [13] to design our algorithm.",
      "startOffset" : 57,
      "endOffset" : 61
    }, {
      "referenceID" : 19,
      "context" : "An event k happens with rate hk(xt, ck), determined by the rate constant and the current population state [21]: hk(xt, ck) =ckgk(xt) = ck M ∏",
      "startOffset" : 106,
      "endOffset" : 110
    }, {
      "referenceID" : 19,
      "context" : "In our case, we adopt the product form ∏M m=1 g (m) k (x (m) t ), which represents the total number of ways that reactant molecules can be selected to trigger event k [21].",
      "startOffset" : 167,
      "endOffset" : 171
    }, {
      "referenceID" : 15,
      "context" : "This assumption follows the linearization principle in the literature [17], and is valid when the discrete time step is small.",
      "startOffset" : 70,
      "endOffset" : 74
    }, {
      "referenceID" : 11,
      "context" : "The inference algorithm minimizes the KL divergence between these two distributions, which can be formulated as an optimization problem [13]: Minimize: ∑",
      "startOffset" : 136,
      "endOffset" : 140
    }, {
      "referenceID" : 20,
      "context" : "The objective function is the Bethe free energy, composed of average energy and Bethe entropy approximation [22].",
      "startOffset" : 108,
      "endOffset" : 112
    }, {
      "referenceID" : 4,
      "context" : "The real data set is collected from the Social Evolution experiment [5].",
      "startOffset" : 68,
      "endOffset" : 71
    }, {
      "referenceID" : 13,
      "context" : "The synthetic data set was collected on the Dartmouth College campus from April 2001 to June 2004, and contains the movement history of 13,888 individuals [15].",
      "startOffset" : 155,
      "endOffset" : 159
    }, {
      "referenceID" : 12,
      "context" : "We synthesized disease transmission along a timeline using the popular susceptible-infectioussusceptible (SIS) epidemiology model [14], then applied the VISKM to calibrate performance.",
      "startOffset" : 130,
      "endOffset" : 134
    }, {
      "referenceID" : 5,
      "context" : "We first compare the accuracy and efficiency of VISKM with Gibbs sampling (Gibbs) and particle filtering (PF) on the Social Evolution data set [6, 7].",
      "startOffset" : 143,
      "endOffset" : 149
    }, {
      "referenceID" : 6,
      "context" : "We first compare the accuracy and efficiency of VISKM with Gibbs sampling (Gibbs) and particle filtering (PF) on the Social Evolution data set [6, 7].",
      "startOffset" : 143,
      "endOffset" : 149
    } ],
    "year" : 2016,
    "abstractText" : "Social dynamics is concerned primarily with interactions among individuals and the resulting group behaviors, modeling the temporal evolution of social systems via the interactions of individuals within these systems. In particular, the availability of large-scale data from social networks and sensor networks offers an unprecedented opportunity to predict state-changing events at the individual level. Examples of such events include disease transmission, opinion transition in elections, and rumor propagation. Unlike previous research focusing on the collective effects of social systems, this study makes efficient inferences at the individual level. In order to cope with dynamic interactions among a large number of individuals, we introduce the stochastic kinetic model to capture adaptive transition probabilities and propose an efficient variational inference algorithm the complexity of which grows linearly — rather than exponentially— with the number of individuals. To validate this method, we have performed epidemic-dynamics experiments on wireless sensor network data collected from more than ten thousand people over three years. The proposed algorithm was used to track disease transmission and predict the probability of infection for each individual. Our results demonstrate that this method is more efficient than sampling while nonetheless achieving high accuracy.",
    "creator" : "LaTeX with hyperref package"
  }
}