{
  "name" : "1003.0691.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "Statistical and Computational Tradeoffs in Stochastic Composite Likelihood",
    "authors" : [ "Joshua V Dillon" ],
    "emails" : [ "jvdillon@gatech.edu" ],
    "sections" : [ {
      "heading" : null,
      "text" : "ar X\niv :1\n00 3.\n06 91\nv1 [\ncs .L\nG ]"
    }, {
      "heading" : "1 Introduction",
      "text" : "Maximum likelihood estimation is by far the most popular point estimation technique in machine learning and statistics. Assuming that the data consists of n, m-dimensional vectors\nD = (X(1), . . . , X(n)), X(i) ∈ Rm, (1)\nand is sampled iid from a parametric distribution pθ0 with θ0 ∈ Θ ⊂ Rr, a maximum likelihood estimator (mle) θ̂mln is a maximizer of the loglikelihood function\nℓn(θ ;D) =\nn ∑\ni=1\nlog pθ(X (i)) (2)\nθ̂mln = argmax θ∈Θ ℓn(θ ;D). (3)\nThe use of the mle is motivated by its consistency1, i.e. θ̂mln → θ0 as n → ∞ with probability 1 [6]. The consistency property ensures that as the number n of samples grows, the estimator will converge to the true parameter θ0 governing the data generation process.\n∗To whom correspondence should be addressed. Email: jvdillon@gatech.edu 1The consistency θ̂mln → θ0 with probability 1 is sometimes called strong consistency in order to differentiate it from the\nweaker notion of consistency in probability P (|θ̂mln − θ0| < ǫ) → 0.\nAn even stronger motivation for the use of the mle is that it has an asymptotically normal distribution with mean vector θ0 and variance matrix (nI(θ0))\n−1. More formally, we have the following convergence in distribution as n → ∞ [6]\n√ n (θ̂mln − θ0) N(0, I−1(θ0)), (4)\nwhere I(θ) is the r × r Fisher information matrix\nI(θ) = E pθ{∇ log pθ(X)(∇ log pθ(X))⊤} (5)\nwith ∇f representing the r × 1 gradient vector of f(θ) with respect to θ. The convergence (4) is especially striking since according to the Cramer-Rao lower bound, the asymptotic variance (nI(θ0))\n−1 of the mle is the smallest possible variance for any estimator. Since it achieves the lowest possible asymptotic variance, the mle (and other estimators which share this property) is said to be asymptotically efficient.\nThe consistency and asymptotic efficiency of the mle motivate its use in many circumstances. Unfortunately, in some situations the maximization or even evaluation of the loglikelihood (2) and its derivatives is impossible due to computational considerations. For instance this is the situation in many high dimensional exponential family distributions, including Markov random fields whose graphical structure contains cycles. This has lead to the proposal of alternative estimators under the premise that a loss of asymptotic efficiency is acceptable–in return for reduced computational complexity.\nIn contrast to asymptotic efficiency, we view consistency as a less negotiable property and prefer to avoid inconsistent estimators if at all possible. This common viewpoint in statistics is somewhat at odds with recent advances in the machine learning literature promoting non-consistent estimators, for example using variational techniques [9]. Nevertheless, we feel that there is a consensus regarding the benefits of having consistent estimators over non-consistent ones.\nIn this paper, we propose a family of estimators, for use in situations where the computation of the mle is intractable. In contrast to many previously proposed approximate estimators, our estimators are statistically consistent and admit a precise quantification of both computational complexity and statistical accuracy through their asymptotic variance. Due to the continuous parameterization of the estimator family, we obtain an effective framework for achieving a predefined problem-specific balance between computational tractability and statistical accuracy. We also demonstrate that in some cases reduced computational complexity may in fact act as a regularizer, increasing robustness and therefore accomplishing both reduced computation and increased accuracy. This “win-win” situation conflicts with the conventional wisdom stating that moving from the mle to pseudo-likelihood and other related estimators result in a computational win but a statistical loss. Nevertheless we show that this occurs in some practical situations.\nFor the sake of concreteness, we focus on the case of estimating the parameters associated with Markov random fields. In this case, we provide a detailed discussion of the accuracy–complexity tradeoff. We include experiments on both simulated and real world data for several models including the Boltzmann machine, conditional random fields, and the Boltzmann linear chain model."
    }, {
      "heading" : "2 Related Work",
      "text" : "There is a large body of work dedicated to tractable learning techniques. Two popular categories are Markov chain Monte Carlo (MCMC) and variational methods. MCMC is a general purpose technique for approximating expectations and can be used to approximate the normalization term and other intractable portions of the loglikelihood and its gradient [4]. Variational methods are techniques for conducting inference and learning based on tractable bounds [9].\nDespite the substantial work on MCMC and variational methods, there are little practical results concerning the convergence and approximation rate of the resulting parameter estimators. Variational techniques are sometimes inconsistent and it is hard to analyze their asymptotic statistical behavior. In the case of MCMC, a number of asymptotic results exist [4], but since MCMC plays a role inside each gradient descent or EM iteration it is hard to analyze the asymptotic behavior of the resulting parameter estimates. An advantage\nof our framework is that we are able to directly characterize the asymptotic behavior of the estimator and relate it to the amount of computational savings.\nOur work draws on the composite likelihood method for parameter estimation proposed by [13] which in turn generalized the pseudo likelihood of [2]. A selection of more recent studies on pseudo and composite likelihood are [1, 11, 20, 18, 7]. Most of the recent studies in this area examine the behavior of the pseudo or composite likelihood in a particular modeling situation. We believe that the present paper is the first to systematically examine statistical and computational tradeoffs in a general quantitative framework. Possible exceptions are [22] which is an experimental study on texture generation, [21] which is focused on inference rather than parameter estimation, and [12] which compares discriminative and generative risks."
    }, {
      "heading" : "3 Stochastic Composite Likelihood",
      "text" : "In many cases, the absence of a closed form expression for the normalization term prevents the computation of the loglikelihood (2) and its derivatives thereby severely limiting the use of the mle. A popular example is Markov random fields, wherein the computation of the normalization term is often intractable (see Section 6 for more details). In this paper we propose alternative estimators based on the maximization of a stochastic variation of the composite likelihood.\nWe denote multiple samples using superscripts and individual dimensions using subscripts. Thus X (r) j refers to the j-dimension of the r sample. Following standard convention we refer to random variables (RV) using uppercase letters and their corresponding values using lowercase letters. We also use the standard notations for extracting a subset of the dimensions of a random variable\nXS def = {Xi : i ∈ S}, X−j def= {Xi : i 6= j}. (6)\nWe start by reviewing the pseudo loglikelihood function [2] associated with the data D (1),\npℓn(θ ;D) def =\nn ∑\ni=1\nm ∑\nj=1\nlog pθ(X (i) j |X (i) −j). (7)\nThe maximum pseudo likelihood estimator (mple) θ̂mpln is consistent i.e., θ̂ mpl n → θ0 with probability 1, but possesses considerably higher asymptotic variance than the mle’s (nI(θ0)) −1. Its main advantage is that it does not require the computation of the normalization term as it cancels out in the probability ratio defining conditional distributions\npθ(Xj |X−j) = pθ(Xj |{Xk : k 6= j}) = pθ(X) ∑\nxj pθ(X1, . . . , Xj−1, Xj = xj , Xj+1, . . . , Xm)\n. (8)\nThe mle and mple represent two different ways of resolving the tradeoff between asymptotic variance and computational complexity. The mle has low asymptotic variance but high computational complexity while the mple has higher asymptotic variance but low computational complexity. It is desirable to obtain additional estimators realizing alternative resolutions of the accuracy complexity tradeoff. To this end we define the stochastic composite likelihood whose maximization provides a family of consistent estimators with statistical accuracy and computational complexity spanning the entire accuracy-complexity spectrum.\nStochastic composite likelihood generalizes the likelihood and pseudo likelihood functions by constructing an objective function that is a stochastic sum of likelihood objects. We start by defining the notion ofm-pairs and likelihood objects and then proceed to stochastic composite likelihood.\nDefinition 1. An m-pair (A,B) is a pair of sets A,B ⊂ {1, . . . ,m} satisfying A 6= ∅ = A∩B. The likelihood object associated with an m-pair (A,B) and X is Sθ(A,B) def = log pθ(XA|XB) where XS is defined in (6). The composite loglikelihood function [13] is a collection of likelihood objects defined by a finite sequence of m-pairs (A1, B1), . . . , (Ak, Bk)\ncℓn(θ ;D) def =\nn ∑\ni=1\nk ∑\nj=1\nlog pθ(X (i) Aj |X(i)Bj ). (9)\nThere is a certain lack of flexibility associated with the composite likelihood framework as each likelihood object is either selected or not for the entire sample X(1), . . . , X(n). There is no allowance for some objects to be selected more frequently than others. For example, available computational resources may allow the computation of the loglikelihood for 20% of the samples, and the pseudo-likelihood for the remaining 80%. In the case of composite likelihood if we select the full-likelihood component (or the pseudo-likelihood or any other likelihood object) then this component is applied to all samples indiscriminately.\nIn SCL, different likelihood objects Sθ(Aj , Bj) may be selected for different samples with the possibility of some likelihood objects being selected for only a small fraction of the data samples. The selection may be non-coordinated, in which case each component is selected or not independently of the other components. Or it may be coordinated in which case the selection of one component depends on the selection of the other ones. For example, we may wish to avoid selecting a pseudo likelihood component for a certain sample X(i) if the full likelihood component was already selected for it. Another important advantage of stochastic selection is that the discrete parameterization of (9) defined by the sequence (A1, B1), . . . , (Ak, Bk) is less convenient for theoretical analysis. Each component is either selected or not, turning the problem of optimally selecting components into a hard combinatorial problem. The stochastic composite likelihood, which is defined below, enjoys continuous parameterization leading to more convenient optimization techniques and convergence analysis.\nDefinition 2. Consider a finite sequence of m-pairs (A1, B1), . . . , (Ak, Bk), a dataset D = (X (1), . . . , X(n)), β ∈ Rk+, and m iid binary random vectors Z(1), . . . , Z(m) iid∼ P (Z) with λj def= E (Zj) > 0. The stochastic composite loglikelihood (scl) is\nscℓn(θ ;D) def =\n1\nn\nn ∑\ni=1\nmθ(X (i), Z(i)), where (10)\nmθ(X,Z) def =\nk ∑\nj=1\nβjZj log pθ(XAj |XBj ). (11)\nIn other words, the scl is a stochastic extension of (9) where for each sample X(i), i = 1, . . . , n, the likelihood objects S(A1, B1), . . . , S(Ak, Bk) are either selected or not, depending on the values of the binary random variables Z (i) 1 , . . . , Z (i) m and weighted by the constants β1, . . . , βm. Note that Z (i) j may in general depend on Z (i) r but not on Z (l) r or on X(i).\nWhen we focus on examining different models for P (Z) we sometimes parameterize it, for example by λ i.e., Pλ(Z). This reuse of λ (it is also used in Definition 2) is a notational abuse. We accept it, however, as in most of the cases that we consider λ1, . . . , λk from Definition 2 either form the parameter vector for P (Z) or are part of it.\nSome illustrative examples follow.\nIndependence. Factorizing Pλ(Z1, . . . , Zk) = ∏ j Pλj (Zj) leads to Z (i) j ∼ Ber(λj) with complete indepen-\ndence among the indicator variables. For each sample X(i), each likelihood object S(Aj , Bj) is selected or not independently with probability λj .\nMultinomial. A multinomial model Z ∼ Mult(1, λ) implies that for each sample Z(i) a multivariate Bernoulli experiment is conducted with precisely one likelihood object being selected depending on the selection probabilities λ1, . . . , λk.\nProduct of Multinomials. A product of multinomials is formed by a partition of the dimensions to l disjoint subsets {1, . . . ,m} = C1 ∪ · · ·Cl where ZCi ∼ Mult(1, (λj : j ∈ Ci)) i.e.,\nP (Z) =\nc ∏\ni=1\nPi ({Zj : j ∈ Ci}) , where Pi is Mult(1, (λj : j ∈ Cl)).\nLoglinear Models. The distribution P (Z) follows a hierarchical loglinear model [3]. This case subsumes the other cases above.\nIn analogy to the mle and the mple, the maximum scl estimator (mscle) θ̂msln estimates θ0 by maximizing the scl function. In contrast to the loglikelihood and pseudo loglikelihood functions, the scl function and its maximizer are random variables that depend on the indicator variables Z(1), . . . , Z(n) in addition to the data D. As such, its behavior should be summarized by examining the limit n → ∞. Doing so eliminates the dependency on particular realizations of Z(1), . . . , Z(n) in favor of the the expected frequencies λj = E P (Z)Zj which are non-random constants.\nThe statistical accuracy and computational complexity of the msl estimator are continuous functions of the parameters (β, λ) (components weights and selection probabilities respectively) which vary continuously throughout their domain (λ, β) ∈ Λ × Rk+. Choosing appropriate values of (λ, β) retrieves the special cases of mle, mple, maximum composite likelihood with each selection being associated with a distinct statistical accuracy and computational complexity. The scl framework allows selections of many more values of (λ, β) realizing a wide continuous spectrum of estimators, each resolving the accuracy-complexity tradeoff differently.\nWe include below a demonstration of the scl framework in a simple low dimensional case. In the following sections we discuss in detail the statistical behavior of the mscle and its computational complexity. We conclude the paper with several experimental studies."
    }, {
      "heading" : "3.1 Boltzmann Machine Example",
      "text" : "Before proceeding we illustrate the SCL framework using a simple example involving a Boltzmann machine [9]. We consider in detail three SCL policies: full likelihood (FL), pseudo-likelihood (PL), and a stochastic combination of first and second order pseudo-likelihood with the first order components (p(Xi|X−i)) selected with probability λ and the second order components (p(Xi, Xj |X{i,j}c)) with probability 1− λ.\nDenoting the number of (binary) graph nodes bym, the number of examples by n, the computational com-\nplexity of the FL function (FLOP2 counts) isO\n((\nm 2\n)\n(2m + n)\n)\n(loglikelihood) andO\n(\n(\nm 2\n)2\n2m + n\n(\nm 2\n)\n)\n(loglikelihood gradient). The exponential growth in m prevents such computations for large graphs. The k-order PL function offers a practical alternative to FL (1-order PL correspond to the traditional pseudo-likelihood and 2-order is its analog with second order components p(X{i,j}|X{i,j}c)). The complexity of computing the corresponding SCL function is O ((\nm 2\n)((\nm k\n)\n2k + n\n))\n(for the objective function)\nand O\n(\n(\nm k\n)(\nm 2\n)2\n2k + n\n(\nm 2\n)\n)\n(for the gradient). The slower complexity growth of the k-order PL\n(polynomial in m instead of exponential) is offset by its reduced statistical accuracy, which we measure using the normalized asymptotic variance\neff(θ̂n) = det(Asymp Var(θ̂n))\ndet(Asymp Var(θ̂mlen )) (12)\nwhich is bounded from below by 1 (due to Cramer Rao lower bound) and its deviation from 1 reflects its inefficiency relative to the MLE.\nThe MLE thus achieves the best accuracy but it is computationally intractable. The first order and second order PL have higher asymptotic variance but are easier to compute. The SCL framework enables adding many more estimators filling in the gaps between ML, 1-order PL, 2-order PL, etc.\nWe illustrate three SCL functions in the context of a simple Boltzmann machine (five binary nodes, fourteen samples X(1), . . . , X(14), θtrue = (−1,−1,−1,−1,−1, 1, 1, 1, 1, 1)) in Figure 1. The top box refers to the full likelihood policy. For each of the fourteen samples, the FL component is computed and their\n2FLOP stands for the number of floating point operations.\naggregation forms the SCL function which in this case equals the loglikelihood. The selection of the FL component for each sample is illustrated using a diamond box. The numbers under the boxes reflect the FLOP counts needed to compute the components and the total complexity associated with computing the entire SCL or loglikelihood is listed on the right. As mentioned above, the normalized asymptotic variance (12) is 1.\nThe pseudo-likelihood function (7) is illustrated in the second box where each row correspond to one of the five PL components. As each of the five PL component is selected for each of the samples we have diamond boxes covering the entire 5 × 14 array. The shade of the diamond boxes reflects the complexity required to compute them enabling an easy comparison to the FL components in the top of the figure (note how the FL boxes are much darker than the PL boxes). The numbers at the bottom of each column reflect the FLOP marginal count for each of the fourteen samples and the numbers to the right of the rows reflect the FLOP marginal count for each of the PL components. In this case the FLOP count is less than half the FLOP count of the FL in top box (this reduction in complexity obtained by replacing FL with PL will increase dramatically for graphs with more than 5 nodes) but the asymptotic variance is 83% higher3.\nThe third SCL policy reflects a stochastic combination of first and second order pseudo likelihood components. Each first order component is selected with probability λ and each second order component is selected with probability 1−λ. The result is a collection of 5 1-order PL components and 10 2-order components with only some of them selected for each of the fourteen samples. Again diamond boxes correspond to selected components which are shaded according to their FLOP complexity. The per-component FLOP marginals and per example FLOP marginals are listed as the bottom row and right-most column. The total complexity is somewhere between FL and PL and the asymptotic variance is reduced from the PL’s 183% to 148%.\nAdditional insight may be gained at this point by considering Figure 3 which plots several SCL estimators as points in the plane whose x and y coordinates correspond to normalized asymptotic variance and computational complexity respectively. We turn at this point to considering the statistical properties of the SCL estimators."
    }, {
      "heading" : "4 Consistency and Asymptotic Variance of θ̂msln",
      "text" : "A nice property of the SCL framework is enabling mathematical characterization of the statistical properties of the estimator θ̂msln . In this section we examine the conditions for consistency of the mscle and its asymptotic distribution and in the next section we consider robustness. The propositions below constitute novel generalizations of some well-known results in classical statistics. Proofs may be found in Appendix A. For simplicity, we assume that X is discrete and pθ(x) > 0.\nDefinition 3. A sequence ofm-pairs (A1, B1), . . . , (Ak, Bk) ensures identifiability of pθ if the map {pθ(XAj |XBj ) : j = 1, . . . , k} 7→ pθ(X) is injective. In other words, there exists only a single collection of conditionals {pθ(XAj |XBj ) : j = 1, . . . , k} that does not contradict the joint pθ(X).\nProposition 1. Let Θ ⊂ Rr be an open set, pθ(x) > 0 and continuous and smooth in θ, and (A1, B1), . . . , (Ak, Bk) be a sequence of m-pairs for which {(Aj , Bj) : ∀j such that λj > 0} ensures identifiability. Then the sequence of SCL maximizers is strongly consistent i.e.,\nP (\nlim n→∞ θ̂n = θ0\n)\n= 1. (13)\nThe above proposition indicates that to guarantee consistency, the sequence of m-pairs needs to satisfy Definition 3. It can be shown that a selection equivalent to the pseudo likelihood function, i.e.,\nS = {(A1, B1), . . . , (Am, Bm)} where Ai = {i}, Bi = {1, . . . ,m} \\Ai (14)\nensure identifiability and consequently the consistency of the mscle estimator. Furthermore, every selection of m-pairs that subsumes S in (14) similarly guarantees identifiability and consistency.\n3The asymptotic variance of SCL functions is computed using formulas derived in the next section\nThe sample runs for the policies are illustrated by placing a diamond box in table entries corresponding to selected likelihood objects (rows corresponding to likelihood objects and columns to X(1), . . . , X(14)). The FLOP counts of each likelihood object determines the shade of the diamond boxes while the total FLOP counts per example and per likelihood objects are displayed as table marginals (bottom row and right column for each policy). We also display the total FLOP count and the normalized asymptotic variance (12).\nEven in the simple case of 5 nodes, FL is the most complex policy with PL requiring a third of the FL computation. 0.7PL+0.3PL2 is somewhere in between. The situation is reversed for the estimation accuracy-FL achieves the lowest possible normalized asymptotic variance of 1, PL is almost twice that, and 0.7PL+0.3PL2 somewhere in the middle. The SCL framework spans the accuracy-complexity spectrum. Choosing the right λ value obtains an estimator that is suits available computational resources and required accuracy.\nThe proposition below establishes the asymptotic normality of the mscle θ̂n. The asymptotic variance enables the comparison of scl functions with different parameterizations (λ, β).\nProposition 2. Making the assumptions of Proposition 1 as well as convexity of Θ ⊂ Rr we have the following convergence in distribution\n√ n(θ̂msln − θ0) N (0,ΥΣΥ) (15)\nwhere\nΥ−1 = k ∑\nj=1\nβjλjVar θ0(∇Sθ0(Aj , Bj)) (16)\nΣ = Var θ0\n\n\nk ∑\nj=1\nβjλj∇Sθ0(Aj , Bj)\n\n . (17)\nThe notation Var θ0(Y ) represents the covariance matrix of the random vector Y under pθ0 while the notations\np→ , in the proof below denote convergences in probability and in distribution [6]. ∇ represents the gradient vector with respect to θ.\nWhen θ is a vector the asymptotic variance is a matrix. To facilitate comparison between different estimators we follow the convention of using the determinant, and in some cases the trace, to measure the statistical accuracy. See [16] for some heuristic arguments for doing so. Figures 1,2,3 provide the asymptotic variance for some SCL estimators and describe how it can be used to gain insight into which estimator to use.\nThe statistical accuracy of the SCL estimator depends on β (weight parameters) and λ (selection parameter). It is thus desirable to use the results in this section in determining what values of β, λ to use. Directly using the asymptotic variance is not possible in practice as it depends on the unknown quantity θ0. However, it is possible to estimate the asymptotic variance using the training data. We describe this in Section 7."
    }, {
      "heading" : "5 Robustness of θ̂msln",
      "text" : "We observed in our experiments (see Section 8) that the SCL estimator sometimes performs better on a heldout test set than did the maximum likelihood estimator. This phenomenon seems to be in contradiction to the fact that the asymptotic variance of the MLE is lower than that of the SCL maximizer. This is explained by the fact that in some cases the true model generating the data does not lie within the parametric family {pθ : θ ∈ Θ} under consideration. For example, many graphical models (HMM, CRF, LDA, etc.) make conditional independence assumptions that are often violated in practice. In such cases the SCL estimator acts as a regularizer achieving better test set performance than the non-regularized MLE. We provide below a theoretical account of this phenomenon using the language of m-estimators and statistical robustness. Our notation follows the one in [19].\nWe assume that the model generating the data is outside the model family P (X) 6∈ {pθ : θ ∈ Θ} and we augment mθ(X,Z) in (11) with\nψθ(X,Z) def = ∇mθ(X,Z)\nψ̇θ(X,Z) def = ∇2mθ(X,Z) (matrix of second order derivatives)\nΨn(θ) def =\n1\nn\nn ∑\ni=1\nψθ(X (i), Z(i)).\nProposition 3 below generalizes the consistency result by asserting that θ̂n → θ0 where θ0 is the point on {pθ : θ ∈ Θ} that is closest to the true model P , as defined by\nθ0 = argmax θ∈Θ\nM(θ) where M(θ) def = −\nk ∑\nj=1\nβjλjD(P (XAj |XBj )||pθ(XAj |XBj )), (18)\nor equivalently, θ0 satisfies\nE P (X)E P (Z)ψθ0(X,Z) = 0. (19)\nWhen the scl function reverts to the loglikelihood function, θ0 becomes the KL projection of the true model P onto the parametric family {pθ : θ ∈ Θ}. Proposition 3. Assuming the conditions in Proposition 1 as well as supθ:‖θ−θ0‖≥ǫ M(θ) < M(θ0) for all ǫ > 0 we have θ̂msln → θ0 as n → ∞ with probability 1. The added condition maintains that θ0 is a well separated maximum point of M . In other words it asserts that only values close to θ0 may yield a value of M that is close to the maximum M(θ0). This condition is satisfied in the case of most exponential family models.\nProposition 4. Assuming the conditions of Proposition 2 as well as E P (X)E P (Z)‖ψθ0(X,Z)‖2 < ∞, E P (X)E P (Z)ψ̇θ0(X) exists and is non-singular, |Ψ̈ij | = |∂2ψθ(x)/∂θiθj | < g(x) for all i, j and θ in a neighborhood of θ0 for some integrable g, we have\n√ n(θ̂n − θ0) = −(E P (X)E P (Z)ψ̇θ0)−1\n1√ n\nn ∑\ni=1\nψθ0(X (i), Z(i)) + oP (1) (20)\nor equivalently\nθ̂n = θ0 − (E P (X)E P (Z)ψ̇θ0)−1 1\nn\nn ∑\ni=1\nψθ0(X (i), Z(i)) + oP\n(\n1√ n\n)\n. (21)\nAbove, fn = oP (gn) means fn/gn converges to 0 with probability 1.\nCorollary 1. Assuming the conditions specified in Proposition 4 we have √ n(θ̂n − θ0) N(0, (E P (X)E P (Z)ψ̇θ0)−1(E P (X)E P (Z)ψθ0ψ⊤θ0)(E P (X)E P (Z)ψ̇θ0)−1). (22)\nEquation (21) means that asymptotically, θ̂n behaves as θ0 plus the average of iid RVs. As mentioned in [19] this fact may be used to obtain a convenient expression for the asymptotic influence function, which measures the effect of adding a new observation to an existing large dataset. Neglecting the remainder in (20) we have\nI(x, z) def= θ̂n(X(1), . . . , X(n−1), x, Z(1), . . . , Z(n−1), z)− θ̂n−1(X(1), . . . , X(n−1), Z(1), . . . , Z(n−1))\n≈ −(E P (X)E P (Z)ψ̇θ0)−1 ( 1\nn\nn−1 ∑\ni=1\nψθ0(X (i), Z(i)) +\n1 n ψθ0(w, z)− 1 n− 1\nn−1 ∑\ni=1\nψθ0(X (i), Z(i))\n)\n= −(E P (X)E P (Z)ψ̇θ0)−1 1\nn ψθ0(w, z) + (E P (X)E P (Z)ψ̇θ0)\n−1 1\nn(n− 1)\nn−1 ∑\ni=1\nψθ0(X (i), Z(i))\n= − 1 n (E P (X)E P (Z)ψ̇θ0) −1ψθ0(w, z) + oP\n(\n1\nn\n)\n. (23)\nCorollary 1 and Equation 23 measure the statistical behavior of the estimator when the true distribution is outside the model family. In these cases it is possible that a computationally efficient SCL maximizer will result in higher statistical accuracy as well. This “win-win” situation of improving in both accuracy and complexity over the MLE is confirmed by our experiments in Section 8."
    }, {
      "heading" : "6 Stochastic Composite Likelihood for Markov Random Fields",
      "text" : "Markov random fields (MRF) are some of the more popular statistical models for complex high dimensional data. Approaches based on pseudo likelihood and composite likelihood are naturally well-suited in this case due to the cancellation of the normalization term in the probability ratios defining conditional distributions. More specifically, a MRF with respect to a graph G = (V,E), V = {1, . . . ,m} with a clique set C is given by the following exponential family model\nPθ(x) = exp\n(\n∑\nC∈C\nθCfC(xC)− logZ(θ) ) ,\nZ(θ) = ∑\nx\nexp\n(\n∑\nC∈C\nθcfC(xC)\n)\n. (24)\nThe primary bottlenecks in obtaining the maximum likelihood are the computations logZ(θ) and ∇ logZ(θ). Their computational complexity is exponential in the graph’s treewidth and for many cyclic graphs, such as the Ising model or the Boltzmann machine, it is exponential in |V | = m.\nIn contrast, the conditional distributions that form the composite likelihood of (24) are given by (note the cancellation of Z(θ))\nPθ(xA|xB) =\n∑\nx′ (A∪B)c\nexp ( ∑\nC∈C θCfC((xA, xB, x ′ (A∪B)c)C)\n)\n∑\nx′ (A∪B)c\n∑\nx′′ A\nexp\n(\n∑\nC∈C\nθCfC((x′′A, xB , x ′ (A∪B)c)C)\n) . (25)\nwhose computation is substantially faster. Specifically, The computation of (25) depends on the size of the sets A and (A ∪ B)c and their intersections with the cliques in C. In general, selecting small |Aj | and Bj = (Aj)\nc leads to efficient computation of the composite likelihood and its gradient. For example, in the case of |Aj | = l, |Bj| = m − l with l ≪ m we have that k ≤ m!/(l!(m − l)!) and the complexity of computing the cℓ(θ) function and its gradient may be shown to require time that is at most exponential in l and polynomial in m."
    }, {
      "heading" : "7 Automatic Selection of β",
      "text" : "As Proposition 2 indicates, the weight vector β and selection probabilities λ play an important role in the statistical accuracy of the estimator through its asymptotic variance. The computational complexity, on the other hand, is determined by λ independently of β. Conceptually, we are interested in resolving the accuracycomplexity tradeoff jointly for both β, λ before estimating θ by maximizing the scl function. However, since the computational complexity depends only on λ we propose the following simplified problem: Select λ based on available computational resources, and then given λ, select the β (and θ) that will achieve optimal statistical accuracy.\nSelecting β that minimizes the asymptotic variance is somewhat ambiguous as ΥΣΥ in Proposition 2 is an r×r positive semidefinite matrix. A common solution is to consider the determinant as a one dimensional measure of the size of the variance matrix4, and minimize\nJ(β) = log det(ΥΣΥ) = log detΣ + 2 log detΥ. (26)\nA major complication with selecting β based on the optimization of (26) is that it depends on the true parameter value θ0 which is not known at training time. This may be resolved, however, by noting that (26) is composed of covariance matrices under θ0 which may be estimated using empirical covariances over\n4See [16] for a heuristic discussion motivating this measre.\nthe training set. To facilitate fast computation of the optimal β we also propose to replace the determinant in (26) with the product of the digaonal elements. Such an approximation is motivated by Hadamard’s inequality (which states that for symmetric matrices det(M) ≤ ∏i Mii) and by Geršgorin’s circle theorem (see below). This approximation works well in practice as we observe in the experiments section. We also note that the procedure described below involves only simple statisics that may be computed on the fly and does not contribute significant additional computation (nor do they require significant memory).\nMore specifically, we denote K(ij) = Cov θ0(∇Sθ0(Ai, Bi),∇Sθ0(Aj , Bj)) with entries K(ij)st , and approximate the log det terms in (26) using\nlog detΥ = − log det k ∑\nj=1\nβjλjK (jj) ≈ −\nr ∑\nl=1\nlog\nk ∑\nj=1\nβjλjK (jj) ll (27)\nlog detΣ = log detVar θ0\n\n\nk ∑\nj=1\nβjλj∇Sθ0(Aj , Bj)\n\n = log det\nk ∑\ni=1\nk ∑\nj=1\nβiλiβjλjK (ij)\n≈ r ∑\nl=1\nlog k ∑\ni=1\nk ∑\nj=1\nβiλiβjλjK (ij) ll . (28)\nWe denote (assuming A is a n× n matrix) for i ∈ {1, . . . , n}, Ri(A) = ∑ j 6=i |Aij | and let D(Aii, Ri(A)) (Di where unambiguous) be the closed disc centered at Aii with radius Ri(A). Such a disc is called a Geršgorin disc. The result below states that for matrices that are close to diagonal, the eigenvalues are close to the diagonal elements making our approximation accurate.\nTheorem 1 (Geršgorin’s circle theorem e.g., [8]). Every eigenvalue of A lies within at least one of the Geršgorin discs D(Aii, Ri(A)). Furthermore, if the union of k discs is disjoint from the union of the remaining n− k discs, then the former union contains exactly k and the latter n− k eigenvalues of A.\nThe following algorithm solves for θ, β jointly using alternating optimization. The second optimization problem with respect to β is done using the approximation above and may be computed without much additional computation. In practice we found that such an approach lead to a selection of β that is close to the optimal β (see Sec. 8.3 and Figures 14, 20 for results).\nAlgorithm 1 Calculate θ̂msl\nRequire: X , β0, and γ 1: i ← 1 2: β ← β0 3: while i < MAXITS do 4: θ ← argmin scℓ(X,λ, β) 5: if converged then 6: return θ 7: else\n8: β ← argminJ (X,λ, θ, γ) 9: i ← i+ 1\n10: end if\n11: end while 12: return false"
    }, {
      "heading" : "8 Experiments",
      "text" : "We demonstrate the asymptotic properties of θ̂msln and explore the complexity-accuracy tradeoff for three different models-Boltzmann machine, linear Boltzmann MRF and conditional random fields. In terms of\ndatasets, we consider synthetic data as well as datasets from sentiment prediction and text chunking domains."
    }, {
      "heading" : "8.1 Toy Example: Boltzmann Machines",
      "text" : "We illustrate the improvement in asymptotic variance of the mscle associated with adding higher order likelihood components with increasing probabilities in context of the Boltzmann machine\npθ(x) = exp\n\n\n∑\ni<j\nθijxixj − logψ(θ)\n\n , x ∈ {0, 1}m. (29)\nTo be able to accurately compute the asymptotic variance we use m = 5 with θ being a ( 5 2 ) dimensional vector with half the components +1 and half −1. Since the asymptotic variance of θ̂msln is a matrix we summarize its size using either its trace or determinant.\nFigure 2 displays the asymptotic variance, relative to the minimal variance of the mle, for the cases of full likelihood (FL), pseudo likelihood (|Aj | = 1) PL1, stochastic combination of pseudo likelihood and 2nd order pseudo likelihood (|Aj | = 2) components αPL2 + (1 − α)PL1, stochastic combination of 2nd order pseudo likelihood and 3rd order pseudo likelihood (|Aj | = 3) components αPL3 + (1 − α)PL2, and stochastic combination of 3rd order pseudo likelihood and 4th order pseudo likelihood (|Aj | = 4) components αPL4 + (1− α)PL3.\nThe graph demonstrates the computation-accuracy tradeoff as follows: (a) pseudo likelihood is the fastest but also the least accurate, (b) full likelihood is the slowest but the most accurate, (c) adding higher order components reduces the asymptotic variance but also requires more computation, (d) the variance reduces with the increase in the selection probability α of the higher order component, and (e) adding 4th order components brings the variance very close the lower limit and with each successive improvement becoming smaller and smaller according to a law of diminishing returns.\nFigure 3 displays the asymptotic accuracy and complexity for different SCL policies for m = 9. We see how taking different linear combinations of pseudo likelihood orders spans a continuous spectrum of accuracy-complexity resolutions. The lower part of the diagram is the boundary of the achievable region (the optimal but unachievable place is the bottom left corner). SCL policies that lie to the right and top of that boundary may be improved by selecting a policy below and to the left of it."
    }, {
      "heading" : "8.2 Local Sentiment Prediction",
      "text" : "Our first real world dataset experiment involves local sentiment prediction using a conditional MRF model. The dataset consisted of 249 movie review documents having an average of 30.5 sentences each with an\naverage of 12.3 words from a 12633 word vocabulary. Each sentence was manually labeled as one of five sentimental designations: very negative, negative, objective, positive, or very positive. As described in [15] (where more infomration may be found) we considered the task of predicting the local sentiment flow within these documents using regularized conditional random fields (CRFs) (see Figure 4 for a graphical diagram of the model in the case of four sentences).\nFigure 5 shows the contour plots of train and test loglikelihood as a function of the scl parameters: weight β and selection probability λ. The likelihood components were mixtures of full and pseudo (|Aj | = 1) likelihood (rows 1,3) and pseudo and 2nd order pseudo (|Aj | = 2) likelihood (rows 2,4). Aj identifies a set of labels corresponding to adjacent sentences over which the probabilistic query is evaluated. Results were averaged over 100 cross validation iterations with 50% train-test split. We used BFGS quasi-Newton method for maximizing the regularized scl functions. The figure demonstrates how the train loglikelihood increases with increasing the weight and selection probability of full likelihood in rows 1,3 and of 2nd order pseudo likelihood in rows 2,4. This increase in train loglikelihood is also correlated with an increase in computational complexity as higher order likelihood components require more computation. Note however, that the test set behavior in the third and fourth rows shows an improvement in prediction accuracy associated with decreasing the influence of full likelihood in favor of pseudo likelihood. The fact that this happens for weak regularization σ2 = 10 indicates that lower order pseudo likelihood has a regularization effect which improves\nprediction accuracy when the model is not regularized enough. We have encountered this phenomenon in other experiments as well and we will discuss it further in the following subsections.\nFigure 6 displays the complexity and negative loglikelihoods (left:train, right:test) of different scl estimators, sweeping through λ and β, as points in a two dimensional space. The shaded area near the origin is unachievable as no scl estimator can achieve high accuracy and low computation at the same time. The optimal location in this 2D plane is the curved boundary of the achievable region with the exact position on that boundary depending on the required solution of the computation-accuracy tradeoff."
    }, {
      "heading" : "8.3 Text Chunking",
      "text" : "This experiment consists of using sequential MRFs to divide sentences into “text chunks,” i.e., syntactically correlated sub-sequences, such as noun and verb phrases. Chunking is an crucial step towards full parsing. For example5, the sentence:\nHe reckons the current account deficit will narrow to only # 1.8 billion in September.\ncould be divided as:\n[NP He ] [VP reckons ] [NP the current account deficit ] [VP will narrow ] [PP to ] [NP only # 1.8 billion ] [PP in ] [NP September ].\nwhere NP, VP, and PP indicate noun phrase, verb phrase, and prepositional phrase. We used the publicly available CoNLL-2000 shared task dataset. It consists of labeled partitions of a subset of the Wall Street Journal (WSJ) corpus. Our training sets consisted of sampling 100 sentences without replacement from the the CoNLL-2000 training set (211,727 tokens from WSJ sections 15-18). The test set was the same as the CoNLL-2000 testing partition (47,377 tokens from WSJ section 20). Each of the possible 21,589 tokens, i.e., words, numbers, punctuation, etc., are tagged by one of 11 chunk types and an O label indicating the token is not part of any chunk. Chunk labels are prepended with flags indicating that the token begins (B-) or is inside (I-) the phrase. Figure 7 lists all labels and respective frequencies. In addition to labeled tokens, the dataset contains a part-of-speech (POS) column. These tags were automatically generated by the Brill tagger and must be incorporated into any model/feature set accordingly.\nIn the following, we explore this task using various scl selection polices on two related, but fundamentally different sequential MRFs: Boltzmann chain MRFs and CRFs."
    }, {
      "heading" : "8.3.1 Boltzmann Chain MRF",
      "text" : "Boltzmann chains are a generative MRF that are closely related to hidden Markov models (HMM). See [14] for a discussion on the relationship between Boltzmann chain MRFs and HMMs. We consider SCL components of the form P(X2, Y2|Y1, Y3), P(X2, X3, Y2, Y3|Y1, Y4) which we refer to as first and second order pesudo likelihood (with higher order components generalizing in a straightforward manner).\nThe nature of the Boltzmann chain constrains our feature set to only encode the particular token present at each position, or time index. In doing so we avoid having to model additional dependencies across time steps and dramatically reduce computational complexity. Although scl is precisely motivated by high treewidth graphs, we wish to include the full likelihood for demonstrative purposes–in practice, this is often not possible. Although POS tags are available we do not include them in these features since the dependence they share on neighboring tokens and other POS tags is unclear. For these reasons our time-sliced feature vector, xi, has only a single-entry one and cardinality matching the size of the vocabulary (21,589 tokens).\nAs is common practice, we curtail overfitting through a L2 regularizer, exp{− 12σ2 ||θ||22}, which is is strong when σ2 is small and weak when σ2 is large. We consider σ2 a hyper-parameter and select it through crossvalidation, unless noted otherwise. More often though, we show results for several representative σ2 to demonstrate the roles of λ and β in θ̂msln .\nFigures 10 and 11 depict train and test negative log-likelihood, i.e., perplexity, for the scl estimator θ̂msl100 with a pseudo/full likelihood selection policy (PL1/FL). As is our convention, weight β and selection\n5Taken from the CoNLL-2000 shared task site, http://www.cnts.ua.ac.be/conll2000/chunking/ .\n15\nprobability λ correspond to the higher order component, in this case full likelihood. The lower order pseudo likelihood component is always selected and has weight 1−β. As expected the test set perplexity dominates the train-set perplexity. As was the situation in Sec. 8.2, we note that the lower order component serves to regularize the full-likelihood, as evident by the abnormally large σ2.\nWe next demonstrate the effect of using a 1st order/2nd order pseudo likelihood selection policy (PL1/PL2). Recall, our notion of pseudo likelihood never entails conditioning on x, although in principle it could. Figures 12 and 13 show how the policy responds to varying both λ and β. Figure 9 depicts the empirical tradeoff between accuracy and complexity. Figure 14 highlights the effectiveness of the β heuristic. See captions for additional comments."
    }, {
      "heading" : "8.3.2 CRFs",
      "text" : "Conditional random fields are the discriminative counterpart of Boltzmann chains (cf. Figures 4 and 8). Since x is not jointly modeled with y, we are free to include features with non-independence across time steps without significantly increasing the computational complexity. Here our notion of pseudo likelihood is more traditional, e.g., P(Y2|Y1, Y, 3, X2) and P(Y2, Y3|Y1, Y, 4, X2, X3) are valid 1st and 2nd order pseudo likelihood components.\nWe employ a subset of the features outlined in [17] which proved competitive for the CoNLL-2000 shared task. Our feature vector was based on seven feature categories, resulting in a total of 273,571 binary features (i.e., ∑\ni fi(xt) = 7). The feature categories consisted of word unigrams, POS unigrams, word bigrams (forward and backward), and POS bigrams (forward and backward) as well as a stopword indicator (and its complement) as defined by [10]. The set of possible feature/label pairs is much larger than our set–we use only those features supported by the CoNLL-2000 dataset, i.e., those which occur at least once. Thus we modeled 297,041 feature/label pairs and 847 transitions for a total of 297,888 parameters. As before, we use the L2 regularizer, exp{− 12σ2 ||θ||22}, which is is stronger when σ2 is small and weak when σ2 is large.\nWe demonstrate learning on two selection policies: pseudo/full likelihood (Figures 16 and 17) and 1st/2nd order pseudo likelihood (Figures 18 and 19). In both selection polices we note a significant difference from the Boltzmann chain, β has less impact on both train and test perplexity. Intuitively, this seems reasonable as the component likelihood range and variance are constrained by the conditional nature of CRFs. Figure 15 demonstrates the empirical accuracy/complexity tradeoff and Figure 20 depicts the effectiveness of the β heuristic. See captions for further comments.\nIn comparing these results to PL1/FL, we note that the test set contours exhibit less perplexity for larger areas. In particular, perplexity is lower at smaller λ values, meaning a computational saving over PL1/FL at a given level of accuracy.\nPL1/PL2 outperforms PL1/FL test perplexity at σ2 = 5000 and continues to show improvement with weaker regularizers. This is perhaps surprising since the previous policy includes FL as a special case, i.e., (λ, β) = (1, 1). We speculate that the regularizer’s indirect connection to the training samples precludes it from preventing certain types of overfitting. See Sec. 8.4 for more discussion.\nFor the PL1/PL2 policy the heuristic closely matched the optimal (all bottom row points are on diagonal). The heuristic out-performed the optimal on the test set and had slightly higher perplexity on the training set. It is a positive result, albeit somewhat surprising, and is attributable to either coarseness in the grid or improved generalization by accounting for variability in θ̂msl."
    }, {
      "heading" : "8.4 Complexity/Regularization Win-Win",
      "text" : "It is interesting to contrast the test loglikelihood behavior in the case of mild and stronger L2 regularization. In the case of weaker or no regularization, the test loglikelihood shows different behavior than the train loglikelihood. Adding a lower order component such as pseudo likelihood acts as a regularizer that prevents overfitting. Thus, in cases that are prone to overfitting reducing higher order likelihood components improves both performance as well as complexity. This represents a win-win situation in contrast to the classical view where the mle has the lowest variance and adding lower order components reduces complexity but increases the variance.\nIn Figure 5 we note this phenomenon when comparing σ2 = 1 to σ2 = 10 across the selection policies PL1/FL and PL1/PL2. That is, the weaker regularization and more restrictive selection policy, i.e., PL1/PL2, is able to achieve comparable test set perplexity.\nFor the text chunking experiments, we observe a striking win-win when using the Boltzmann chain MRF, Figures 10 and 12. Notice that as regularization is decreased (comparing from left to right), the contours are pulled closer to the x-axis. This means that we are achieving the same perplexity at reduced levels of\ncomputational complexity. The CRF however, only exhibits the win-win to a minor extent. We delve deeper into why this is might be the case in the following section."
    }, {
      "heading" : "8.5 λ, σ2 Interplay",
      "text" : "Throughout these experiments we fixed σ2 and either swept over (λ, β) or used the heuristic to evaluate (λ, β(λ)). Motivated by the sometimes weak win-win (cf. Section 8.4) we now consider how the optimal σ2 changes as a function of λ. In Figure 21 we used the β heuristic to evaluate train and test perplexity over a (λ, σ2) grid. We used CRFs and the text chunking task as outlined in Section 8.3.2.\nFor the PL1/FL policy, we observe that for small enough λ the optimal σ2, i.e., the σ2 with smallest test perplexity, has considerable range. At some point there are enough samples of the higher-order component to stabilize the choice of regularizer, noting that it is still weaker than the optimal full likelihood regularizer. Conversely, the PL1/PL2 regularizer has an essentially constant optimal regularizer which is relatively much weaker.\nAs a result, we believe that the lack of win-win for the chunking CRF follows from two effects. In the case of the PL1/FL policy the contour plots are misleading since there is no single σ2 that performs well across all λ ∈ [0, 1]. For the PL1/PL2 there is simply little change in regularization necessary across λ."
    }, {
      "heading" : "9 Discussion",
      "text" : "The proposed estimator family facilitates computationally efficient estimation in complex graphical models. In particular, different (β, λ) parameterizations of the stochastic composite likelihood enables the resolution of the complexity-accuracy tradeoff in a domain and problem specific manner. The framework is generally suited for Markov random fields, including conditional graphical models and is theoretically motivated. When the model is prone to overfit, stochastically mixing lower order components with higher order ones acts as a regularizer and results in a win-win situation of improving test-set accuracy and reducing computational complexity at the same time.\nAlthough we cannot directly compare CRFs to its generative counterpart, we observe some strikingly different trends. It is immediately clear that the CRF is less sensitive to the relative weighting of components than is the Boltzmann chain. This is partially attributable to a smaller range of the objective–the CRF is already conditional hence the per-component perplexity range is reduced.\nPerhaps more evidently here than above, we note that the significance of a particular β is less than that of the Boltzmann chain. However, for large enough σ2, the optimal β 6= 1. This indicates the dual role of PL1 as a regularizer. Moreover, the left panel calls attention to the interplay between β, λ, and σ2. See Sec. 8.5 for more discussion.\nReferences\n[1] B. Arnold and D. Strauss. Pseudolikelihood estimation: some examples. Sankhya B, 53:233–243, 1991.\nAlthough increasing λ only brings minor improvement to both the training and testing perplexities, it is worth noting that the test perplexity meets that of the PL1/FL. Still though, the overall lack of resolution here suggests that smaller values of λ would better span a range of perplexities and at reduced computational cost.\n[2] J. Besag. Spatial interaction and the statistical analysis of lattice systems (with discussion). J Roy Statist Soc B, 36(2):192–236, 1974.\n[3] Y. Bishop, S. Fienberg, and P. Holland. Discrete multivariate analysis: theory and practice. MIT press,\nThe optimal and heuristic β match train and test perplexities for both policies. The actual β value however does not seem to match as well as the Boltzmann chain. However, if we note the flatness of the β grid (cf. Fig. 17 and 19) this result is unsurprising and can be disregarded as an indication of the heuristic’s performance.\n1975.\n[4] R. Casella and C. Robert. Monte Carlo Statistical Methods. Springer Verlag, second edition, 2004.\n[5] T. M. Cover and J. A. Thomas. Elements of Information Theory. John Wiley & Sons, second edition, 2005.\n[6] T. S. Ferguson. A Course in Large Sample Theory. Chapman & Hall, 1996.\n[7] N. Hjort and C. Varin. ML, PL, and QL in markov chain models. Scand J Stat, 35(1):64–82, 2008.\n[8] R. Horn and C. R. Johnson. Matrix Analysis. Cambridge University Press, 1990.\n[9] M. I. Jordan, Z. Ghahramani, T. S. Jaakkola, and L. K. Saul. An introduction to variational methods for graphical models. Machine Learning, 37(2):183–233, 1999.\n[10] D. Lewis, Y. Yang, T. Rose, and F. Li. RCV1: A new benchmark collection for text categorization research. Journal of Machine Learning Research, 5:361–397, 2004.\n[11] G. Liang and B. Yu. Maximum pseudo likelihood estimation in network tomography. IEEE T Signal Proces, 51(8):2043–2053, 2003.\n[12] P. Liang and M. I. Jordan. An asymptotic analysis of generative, discriminative, and pseudolikelihood estimators. In Proc. of the International Conference on Machine Learning, 2008.\n[13] B. G. Lindsay. Composite likelihood methods. Contemporary Mathematics, 80:221–239, 1988.\n[14] D. J. C. MacKay. Equivalence of linear boltzmann chains and hidden markov models. Neural Computation, 8(1):178–181, 1996.\n[15] Y. Mao and G. Lebanon. Isotonic conditional random fields and local sentiment flow. In Advances in Neural Information Processing Systems 19, pages 961–968, 2007.\n[16] R. J. Serfling. Approximation Theorems of Mathematical Statistics. John Wiley, 1980.\n[17] F. Sha and F. Pereira. Shallow parsing with conditional random fields. Proceedings of HLT-NAACL, pages 213–220, 2003.\n[18] C. Sutton and A. McCallum. Piecewise pseudolikelihood for efficient training of conditional random fields. In Proc. of the International Conference on Machine Learning, 2007.\n[19] A. W. van der Vaart. Asymptotic Statistics. Cambridge University Press, 1998.\n[20] C. Varin and P. Vidoni. A note on composite likelihood inference and model selection. Biometrika, 92:519–528, 2005.\n[21] E. P. Xing, M. I. Jordan, and S. Russell. A generalized mean field algorithm for variational inference in exponential families. In Proc. of Uncertainty in Artificial Intelligence, 2003.\n[22] S.-C. Zhu and X. Liu. Learning in Gibbsian fields: How accurate and how fast can it be? IEEE T Pattern Anal, 24(7):1001–1006, 2002."
    }, {
      "heading" : "A Proofs",
      "text" : "The proofs below generalize the classical consistency and asymptotic efficiency of the mle [6] and the corresponding results for m-estimators [19]. They follow similar lines as the proofs in [6] and [19], with the necessary modifications due to the stochasticity of the scl function. We assume below that pθ(X) > 0 and that X is a discrete and finite RV.\nThe following lemma generalizes Shannon’s inequality [5] for the KL divergence. We will use it to prove consistency of the SCL estimator.\nLemma 2. Let (A1, B1), . . . , (Ak, Bk) be a sequence of m-pairs that ensures identifiability of pθ, θ ∈ Θ and α1, . . . , αk positive constants. Then\nk ∑\nj=1\nαk D(pθ(XAj |XBj ) || pθ′(XAj |XBj )) ≥ 0 (30)\nwhere equality holds iff θ = θ′.\nProof The inequality follows from applying Jensen’s inequality for each conditional KL divergence\n−D(pθ(XAj |XBj ) || pθ′(XAj |XBj )) = E pθ log pθ′(XAj |XBj ) pθ(XAj |XBj ) ≤ logEpθ pθ′(XAj |XBj ) pθ(XAj |XBj )\n= log 1 = 0.\nFor equality to hold we need each term to be 0 which follows only if pθ(XAj |XBj ) ≡ pθ′(XAj |XBj ) for all j which, assuming identifiability, holds iff θ = θ′.\nProposition 1. Let Θ ⊂ Rr be an open set, pθ(x) > 0 and continuous and smooth in θ, and (A1, B1), . . . , (Ak, Bk) be a sequence ofm-pairs for which {(Aj , Bj) : ∀j such that λj > 0} ensures identifiability. Then the sequence of SCL maximizers is strongly consistent i.e.,\nP (\nlim n→∞ θ̂n = θ0\n)\n= 1. (31)\nProof The scl function, modified slightly by a linear combination with a term that is constant in θ is\nscℓ′(θ) = 1\nn\nn ∑\ni=1\nk ∑\nj=1\nβj\n(\nZij log pθ(X (i) Aj |X(i)Bj )− λj log pθ0(X (i) Aj |X(i)Bj ) ) .\nBy the strong law of large numbers, the above expression converges as n → ∞ to its expectation\nµ(θ) = − k ∑\nj=1\nβjλj D(pθ0(XAj |XBj ) || pθ(XAj |XBj )).\nIf we restrict ourselves to the compact set S = {θ : c1 ≤ ‖θ − θ0‖ ≤ c2} then\nsup θ∈S sup Z\n∣ ∣ ∣\nk ∑\nj=1\nZjβj log pθ(XAj |XBj )− λjβj log pθ0(XAj |XBj ) ∣ ∣ ∣ < K(x) < ∞ (32)\nwhere K(x) is a function satisfying EK(X) < ∞. As a result, the conditions for the uniform strong law of large numbers [6] hold on S leading to\nP\n{\nlim n→∞ sup θ∈S\n|scl′(θ) − µ(θ)| = 0 } = 1. (33)\nBy Proposition 2, µ(θ) is non-positive and is zero iff θ = θ0. Since the function µ(θ) is continuous it attains its negative supremum on the compact S: supθ∈S µ(θ) < 0. Combining this fact with (33) we have that there exists N such that for all n > N the scl maximizers on S achieves strictly negative values of scℓ′(θ) with probability 1. However, since scℓ′(θ) can be made to achieve values arbitrarily close to zero under θ = θ0, we have that θ̂ msl n 6∈ S for n > N . Since c1, c2 were chosen arbitrarily θ̂msln → θ0 with probability 1.\nProposition 2. Making the assumptions of Proposition 1 as well as convexity of Θ ⊂ Rr we have the following convergence in distribution\n√ n(θ̂msln − θ0) N (0,ΥΣΥ) (34)\nwhere\nΥ−1 =\nk ∑\nj=1\nβjλjVar θ0(∇Sθ0(Aj , Bj)) (35)\nΣ = Var θ0\n\n\nk ∑\nj=1\nβjλj∇Sθ0(Aj , Bj)\n\n . (36)\nThe notation Var θ0(Y ) represents the covariance matrix of the random vector Y under pθ0 while the notations\np→ , in the proof below denote convergences in probability and in distribution [6]. Proof By the mean value theorem and convexity of Θ there exists η ∈ (0, 1) for which θ′ = θ0+η(θ̂msln −θ0) and ∇scℓn(θ̂msln ) = ∇scℓn(θ0) +∇2scℓn(θ′)(θ̂msln − θ0) where ∇f(θ) and ∇2f(θ) are the r × 1 gradient vector and r × r matrix of second order derivatives of f(θ). Since θ̂n maximizes the scl, ∇scℓn(θ̂msln ) = 0 and\n√ n(θ̂msln − θ0) = − √ n(∇2scℓn(θ′))−1∇scℓn(θ0). (37)\nBy Proposition 1 we have θ̂msln p→ θ0 which implies that θ′ p→ θ0 as well. Furthermore, by the law of large numbers and the fact that if Wn p→ W then g(Wn) p→ g(W ) for continuous g,\n(∇2scℓn(θ′))−1 p→ (∇2scℓn(θ0))−1 (38)\np→\n\n\nk ∑\nj=1\nβjλjE θ0∇2Sθ0(Aj , Bj)\n\n\n−1\n= −\n\n\nk ∑\nj=1\nβjλjVar θ0(∇Sθ0(Aj , Bj))\n\n\n−1\n.\nFor the remaining term in (37) we have\n√ n∇scℓn(θ0) = k ∑\nj=1\nβj √ n 1\nn\nn ∑\ni=1\nWij\nwhere the random vectorsWij = Zij∇ log pθ(X(i)Aj |X (i) Bj ) have expectation 0 and variance matrix Var θ0(Wij) = λjVar θ0(∇Sθ0(Aj , Bj)). By the central limit theorem\n√ n 1\nn\nn ∑\ni=1\nWij N (0, λjVar θ0(∇Sθ0(Aj , Bj))) .\nThe sum √ n∇scℓn(θ0) = ∑k j=1 βj √ n 1n ∑n i=1 Wij is asymptotically Gaussian as well with mean zero since it converges to a sum of Gaussian distributions with mean zero. Since in the general case the random variables √ n 1n ∑n i=1 Wij , j = 1, . . . , k are correlated, the asymptotic variance matrix of √ n∇scℓn(θ0) needs to account for cross covariance terms leading to\n√ n∇scℓn(θ0) N\n\n0,Var θ0\n\n\nk ∑\nj=1\nβjλj∇Sθ0(Aj , Bj)\n\n\n\n . (39)\nWe finish the proof by combining (37), (38) and (39) using Slutsky’s theorem.\nRecall our notation for the case that the true model P 6∈ {pθ : θ ∈ Θ}.\nψθ(X,Z) def = ∇mθ(X,Z) (40)\nψ̇θ(X,Z) def = ∇2mθ(X,Z) (matrix of second order derivatives) (41)\nΨn(θ) def =\n1\nn\nn ∑\ni=1\nψθ(X (i), Z(i)). (42)\nProposition 3. Assuming the conditions in Proposition 1 as well as supθ:‖θ−θ0‖≥ǫM(θ) < M(θ0) for all ǫ > 0 we have θ̂msln → θ0 as n → ∞ with probability 1.\nProof We assert\nP\n{\nlim n→∞ sup θ∈S\n|scl′(θ) − µ(θ)| = 0 } = 1. (43)\non the compact set S = {θ : c1 ≤ ‖θ− θ0‖ ≤ c2} as in the proof of Proposition 1. We proceed similarly along the lines of Proposition 1, with the necessary modification due to the fact that the true model is outside the parametric family.\nSince the function µ(θ) is continuous it attains its negative supremum on the compact S: supθ∈S µ(θ) < µ(θ0) ≥ 0. Combining this fact with (43) we have that there exists N such that for all n > N the scl maximizers on S achieves strictly negative values of scℓ′(θ) with probability 1.\nHowever, since scℓ′(θ) can be made to achieve values arbitrarily close to µ(θ0) as θ̂n → θ0, we have that θ̂msln 6∈ S for n > N . Since c1, c2 were chosen arbitrarily θ̂msln → θ0 with probability 1.\nProposition 4. Assuming the conditions of Proposition 2 as well as E P (X)E P (Z)‖ψθ0(X,Z)‖2 < ∞, E P (X)E P (Z)ψ̇θ0(X) exists and is non-singular, |Ψ̈ij | = |∂2ψθ(x)/∂θiθj | < g(x) for all i, j and θ in a neighborhood of θ0 for some integrable g, we have\n√ n(θ̂n − θ0) = −(E P (X)E P (Z)ψ̇θ0)−1\n1√ n\nn ∑\ni=1\nψθ0(X (i), Z(i)) + oP (1) (44)\nor equivalently\nθ̂n = θ0 − (E P (X)E P (Z)ψ̇θ0)−1 1\nn\nn ∑\ni=1\nψθ0(X (i), Z(i)) + oP\n(\n1√ n\n)\n. (45)\nProof By Taylor’s theorem there exists a random vector θ̃n on the line segment between θ0 and θ̂n for which\n0 = Ψn(θ̂n) = Ψn(θ0) + Ψ̇n(θ0)(θ̂n − θ0) + 1\n2 (θ̂n − θ0)⊤Ψ̈n(θ̃n)(θ̂n − θ0).\nwhich we re-arrange as\n√ nΨ̇n(θ0)(θ̂n − θ0) + √ n 1\n2 (θ̂n − θ0)⊤Ψ̈n(θ̃n)(θ̂n − θ0) = −\n√ nΨn(θ̂n) (46) = −√nΨn(θ0) + oP (1) (47)\nwhere the second equality follows from the fact that θ̂n p→ θ0 and continuous functions preserves converges in probability. Since Ψ̇n(θ0) converges by the law of large numbers to E P (X)E P (Z)ψ̇θ(X,Z) and Ψ̈n(θ̃n) converges to a matrix of bounded values in the neighborhood of θ0 (for large n), the lhs of (46) is\n√ n ( E P (X)E P (Z)ψ̇θ(X,Z) + oP (1) + 1\n2 (θ̂n − θ0)OP (1)\n)\n(θ̂n − θ0)\n= √ n(E P (X)E P (Z)ψ̇θ(X,Z) + oP (1))(θ̂n − θ0) (48)\nsince θ̂n − θ0 = oP (1) and oP (1)Op(1) = oP (1) (the notation OP (1) denotes stochastically bounded and it applies to Ψ̈n(θ̃n) as described above). Putting it together we have\n√ n(E P (X)E P (Z)ψ̇θ(X,Z) + oP (1))(θ̂n − θ0) = − √ nΨn(θ0) + oP (1).\nSince the matrix E P (X)E P (Z)ψ̇θ(X,Z)+ oP (1) converges to a non-singular matrix, multiplying the equation above by its inverse finishes the proof.\nCorollary 1. Assuming the conditions specified in Proposition 4 we have\n√ n(θ̂n − θ0) N(0, (E P (X)E P (Z)ψ̇θ0)−1(E P (X)E P (Z)ψθ0ψ⊤θ0)(E P (X)E P (Z)ψ̇θ0)−1). (49)\nProof Equation (22) follows from (20) by noticing that due to the central limit theorem Ψn(θ0) (as it is an average of n iid RVs with expectation 0)\n√ n · 1\nn\nn ∑\ni=1\nψθ0(X (i), Z(i)) N(0,E P (X)E P (Z)ψθ0ψ ⊤ θ0).\nSubstituting this in the right hand side of (20) and accounting for the modified variance due to the matrix inverse results in (22)."
    } ],
    "references" : [ ],
    "referenceMentions" : [ ],
    "year" : 2013,
    "abstractText" : "<lb>Maximum likelihood estimators are often of limited practical use due to the intensive computation<lb>they require. We propose a family of alternative estimators that maximize a stochastic variation of the<lb>composite likelihood function. Each of the estimators resolve the computation-accuracy tradeoff differ-<lb>ently, and taken together they span a continuous spectrum of computation-accuracy tradeoff resolutions.<lb>We prove the consistency of the estimators, provide formulas for their asymptotic variance, statistical<lb>robustness, and computational complexity. We discuss experimental results in the context of Boltzmann<lb>machines and conditional random fields. The theoretical and experimental studies demonstrate the ef-<lb>fectiveness of the estimators when the computational resources are insufficient. They also demonstrate<lb>that in some cases reduced computational complexity is associated with robustness thereby increasing<lb>statistical accuracy.<lb>",
    "creator" : "LaTeX with hyperref package"
  }
}