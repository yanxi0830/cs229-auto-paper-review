{
  "name" : "1303.3754.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "A Last-Step Regression Algorithm for Non-Stationary Online Learning",
    "authors" : [ "Edward Moroshko", "Koby Crammer" ],
    "emails" : [ ],
    "sections" : [ {
      "heading" : null,
      "text" : "The goal of a learner in standard online learning is to maintain an average loss close to the loss of the best-performing single function in some class. In many real-world problems, such as rating or ranking items, there is no single best target function during the runtime of the algorithm, instead the best (local) target function is drifting over time. We develop a novel last-step minmax optimal algorithm in context of a drift. We analyze the algorithm in the worst-case regret framework and show that it maintains an average loss close to that of the best slowly changing sequence of linear functions, as long as the total of drift is sublinear. In some situations, our bound improves over existing bounds, and additionally the algorithm suffers logarithmic regret when there is no drift. We also build on the H∞ filter and its bound, and develop and analyze a second algorithm for drifting setting. Synthetic simulations demonstrate the advantages of our algorithms in a worst-case constant drift setting."
    }, {
      "heading" : "1 Introduction",
      "text" : "We consider the on-line learning problems, in which a learning algorithm predicts real numbers given inputs in a sequence of trials. An example of such a problem is to predict a stock’s prices given input about the current state of the stock-market. In general, the goal of the algorithm is to achieve an average loss that is not much larger compared to the loss one suffers if it had always chosen to predict according to the best-performing single function from some class of functions.\nIn the past half a century, many algorithms were proposed (a review can be found in a comprehensive book on\nAppearing in Proceedings of the 16th International Conference on Artificial Intelligence and Statistics (AISTATS) 2013, Scottsdale, AZ, USA. Volume XX of JMLR: W&CP XX. Copyright 2013 by the authors.\nthe topic [10]) for this problem, some of which are able to achieve an average loss arbitrarily close to that of the best function in retrospect. Furthermore, such guarantees hold even if the input and output pairs are chosen in a fully adversarial manner with no distributional assumptions.\nCompeting with the best fixed function might not suffice for some problems. In many real-world applications, the true target function is not fixed, but is slowly drifting over time. Consider a function designed to rate movies for recommender systems given some features. Over time a rate of a movie may change as more movies are released or the season changes. Furthermore, the very own personal-taste of a user may change as well.\nWith such properties in mind, we develop new learning algorithms designed to work with target drift. The goal of an algorithm is to maintain an average loss close to that of the best slowly changing sequence of functions, rather than compete well with a single function. We focus on problems for which this sequence consists only of linear functions. Some previous algorithms [27, 1, 22, 25] designed for this problem are based on gradient descent, with additional control on the norm (or Bregman divergence) of the weight-vector used for prediction [25], or the number of inputs used to define it [7].\nWe take a different route and derive an algorithm based on the last-step min-max approach proposed by Forster [17] and later used [34] for online density estimation. On each iteration the algorithm makes the optimal min-max prediction with respect to a quantity called regret, assuming it is the last iteration. Yet, unlike previous work, it is optimal when a drift is allowed. As opposed to the derivation of the last-step min-max predictor for a fixed vector, the resulting optimization problem is not straightforward to solve. We develop a dynamic program (a recursion) to solve this problem, which allows to compute the optimal last-step minmax predictor. We analyze the algorithm in the worst-case regret framework and show that the algorithm maintains an average loss close to that of the best slowly changing sequence of functions, as long as the total drift is sublinear in the number of rounds T . Specifically, we show that if the total amount of drift is Tν (for ν = o(1)) the cumulative regret is bounded by Tν1/3 + log(T ). When the inar X\niv :1\n30 3.\n37 54\nv1 [\ncs .L\nG ]\n1 5\nM ar\n2 01\n3\nstantaneous drift is close to constant, this improves over a previous bound of Vaits and Crammer [35] of an algorithm named ARCOR that showed a bound of Tν1/4 log(T ). Additionally, when no drift is introduced (stationary setting) our algorithm suffers logarithmic regret, as for the algorithm of Forster [17]. We also build on the H∞ adaptive filter, which is min-max optimal with respect to a filtering task, and derive another learning algorithm based on the same min-max principle. We provide a regret bound for this algorithm as well, and relate the two algorithms and their respective bounds. Finally, synthetic simulations show the advantages of our algorithms when a close to constant drift is allowed."
    }, {
      "heading" : "2 Problem Setting",
      "text" : "We focus on the regression task evaluated with the squared loss. Our algorithms are designed for the online setting and work in iterations (or rounds). On each round an online algorithm receives an input-vector xt ∈ Rd and predicts a real value ŷt ∈ R. Then the algorithm receives a target label yt ∈ R associated with xt, uses it to update its prediction rule, and then proceeds to the next round.\nOn each round, the performance of the algorithm is evaluated using the squared loss, `t(alg) = ` (yt, ŷt) = (ŷt − yt)2. The cumulative loss suffered over T iterations is, LT (alg) = ∑T t=1 `t(alg). The goal of the algorithm is to have low cumulative loss compared to predictors from some class. A large body of work is focused on linear prediction functions of the form f(x) = x>u where u ∈ Rd is some weight-vector. We denote by `t(u) = ( x>t u− yt\n)2 the instantaneous loss of a weight-vector u.\nWe focus on algorithms that are able to compete against sequences of weight-vectors, (u1, . . . ,uT ) ∈ Rd×· · ·×Rd, where ut is used to make a prediction for the tth example (xt, yt). We define the cumulative loss of such set by LT ({ut}) = ∑T t `t(ut) and the regret of an algorithm by\nRT ({ut}) = ∑T t (yt − ŷt)2 − LT ({ut}) . The goal of the algorithm is to have a low-regret, and formally to have RT ({ut}) = o(T ), that is, the average loss suffered by the algorithm will converge to the average loss of the best linear function sequence (u1 . . .uT ).\nClearly, with no restriction or penalty over the set {ut} the right term of the regret can easily be zero by setting, ut = xt(yt/ ‖xt‖2), which implies `t(ut) = 0 for all t. Thus, in the analysis below we incorporate the total drift of the weight-vectors defined to be,\nV=VT ({ut})= T−1∑ t=1 ‖ut − ut+1‖2 , ν=ν({ut})= V T , (1)\nwhere ν is the average drift . Below we bound the regret with, RT ({ut}) ≤ O ( T 2 3V 1 3 + log(T ) ) =\nO ( Tν 1 3 + log(T ) ) . Next, we develop an explicit form of\nthe last-step min-max algorithm with drift."
    }, {
      "heading" : "3 Algorithm",
      "text" : "We define the last-step minmax predictor ŷT to be1,\narg min ŷT max yT [ T∑ t=1 (yt − ŷt)2\n− min u1,...,uT QT (u1, . . . ,uT )\n] , (2)\nwhere we define\nQt (u1, . . . ,ut) =b ‖u1‖2 + c t−1∑ s=1 ‖us+1 − us‖2\n+ t∑ s=1 ( ys − u>s xs )2 , (3)\nfor some positive constants b, c. The last optimization problem can also be seen as a game where the algorithm chooses a prediction ŷt to minimize the last-step regret, while an adversary chooses a target label yt to maximize it. The first term of (2) is the loss suffered by the algorithm while Qt (u1, . . . ,ut) defined in (3) is a sum of the loss suffered by some sequence of linear functions (u1, . . . ,ut), a penalty for consecutive pairs that are far from each other, and for the norm of the first to be far from zero.\nWe first solve recursively the inner optimization problem minu1,...,ut Qt (u1, . . . ,ut), for which we define an auxiliary function,\nPt (ut) = min u1,...,ut−1 Qt (u1, . . . ,ut) , (4)\nwhich clearly satisfies,\nmin u1,...,ut Qt (u1, . . . ,ut) = min ut Pt(ut) . (5)\nWe start the derivation of the algorithm with a lemma, stating a recursive form of the function-sequence Pt(ut).\nLemma 1. For t = 2, 3, . . .\nP1(u1) = Q1(u1)\nPt (ut) = min ut−1\n( Pt−1 (ut−1) + c ‖ut − ut−1‖2\n+ ( yt − u>t xt )2) .\n1yT and ŷT serve both as quantifiers (over the min and max operators, respectively), and as the optimal arguments of this optimization problem.\nThe proof appears in App. B.1. Using Lem. 1 we write explicitly the function Pt(ut).\nLemma 2. The following equality holds\nPt (ut) = u > t Dtut − 2u>t et + ft , (6)\nwhere,\nD1 = bI + x1x > 1 , Dt = ( D−1t−1 + c −1I )−1 + xtx > t (7)\ne1 = y1x1 , et = ( I + c−1Dt−1 )−1 et−1 + ytxt (8)\nf1 = y 2 1 , ft = ft−1 − e>t−1 (cI + Dt−1) −1 et−1 + y 2 t . (9)\nNote that Dt ∈ Rd×d is a positive definite matrix, et ∈ Rd×1 and ft ∈ R.\nThe proof appears in App. B.2. From Lem. 2 we conclude, by substituting (6) in (5), that,\nmin u1,...,ut Qt (u1, . . . ,ut)\n= min ut\n( u>t Dtut − 2u>t et + ft ) = −e>t D−1t et + ft .\n(10)\nSubstituting (10) back in (2) we get that the last-step minmax predictor ŷT is given by,\narg min ŷT max yT [ T∑ t=1 (yt − ŷt)2 + e>TD−1T eT − fT ] . (11)\nSince eT depends on yT we substitute (8) in the second term of (11),\ne>TD −1 T eT =(( I + c−1DT−1 )−1 eT−1 + yTxT )> D−1T((\nI + c−1DT−1 )−1 eT−1 + yTxT ) . (12)\nSubstituting (12) and (9) in (11) and omitting terms not depending explicitly on yT and ŷT we get,\nŷT = arg min ŷT max yT\n[ (yT − ŷT )2 + y2Tx>TD−1T xT\n+ 2yTx > TD −1 T ( I + c−1DT−1 )−1 eT−1 − y2T ] = arg min\nŷT max yT\n[ ( x>TD −1 T xT ) y2T + ŷ 2 T (13)\n+ 2yT ( x>TD −1 T ( I + c−1DT−1 )−1 eT−1 − ŷT )] .\nThe last equation is strictly convex in yT and thus the optimal solution is not bounded. To solve it, we follow an approach used by Forster in a different context [17]. In order to make the optimal value bounded, we assume that the adversary can only choose labels from a bounded set\nyT ∈ [−Y, Y ]. Thus, the optimal solution of (13) over yT is given by the following equation, since the optimal value is yT ∈ {+Y,−Y },\nŷT = arg min ŷT\n[ ( x>TD −1 T xT ) Y 2 + ŷ2T\n+ 2Y ∣∣∣x>TD−1T (I + c−1DT−1)−1 eT−1 − ŷT ∣∣∣ ] .\nThis problem is of a similar form to the one discussed by Forster [17], from which we get the optimal solution, ŷT = clip ( x>TD −1 T ( I + c−1DT−1 )−1 eT−1, Y ) , where for y > 0 we define clip(x, y) = sign(x) min{|x|, y}. The optimal solution depends explicitly on the bound Y , and as its value is not known, we thus ignore it, and define the output of the algorithm to be,\nŷT = x > TD −1 T ( I + c−1DT−1 )−1 eT−1 . (14)\nWe call the algorithm LASER for last step adaptive regressor algorithm, and it is summarized in Fig. 1. Clearly, for c = ∞ the LASER algorithm reduces to the AAR algorithm of Vovk [36], or the last-step min-max algorithm of Forster [17]. See also the work of Azoury and Warmuth [2]. The algorithm can be combined with Mercer kernels as it employs only sums of inner- and outer-products of its inputs. This algorithm can be seen also as a forward algorithm [2]: The predictor of (14) can be seen as the optimal linear model obtained over the same prefix of length T − 1 and the new input xT with fictional-label yT = 0. Specifically, from (8) we get that if yT = 0, then eT = ( I + c−1DT−1 )−1 eT−1. The prediction of the optimal predictor defined in (10) is x>T uT = x > TD −1 T eT = ŷT , where ŷT was defined in (14)."
    }, {
      "heading" : "4 Analysis",
      "text" : "We now analyze the performance of the algorithm in the worst-case setting, starting with the following technical lemma.\nLemma 3. For all t the following statement holds,\nD′t−1D −1 t xtx > t D −1 t D ′ t−1 −D−1t−1 + D′t−1 ( D−1t D ′ t−1 + c −1I ) 0\nwhere D′t−1 = ( I + c−1Dt−1 )−1 .\nThe proof appears in App. B.3. We next bound the cumulative loss of the algorithm,\nTheorem 4. Assume the labels are bounded supt |yt| ≤ Y for some Y ∈ R. Then the following bound holds,"
    }, {
      "heading" : "Parameters: 0 < b < c",
      "text" : "Initialize: Set D0 = (bc)/(c − b) I ∈ Rd×d and e0 = 0 ∈ Rd For t = 1, . . . , T do • Receive an instance xt • Compute Dt = ( D−1t−1 + c −1I )−1 + xtx > t (7)\n( )−1"
    }, {
      "heading" : "Output: eT , DT",
      "text" : "LT (LASER) ≤ min u1,...,uT\n[ b ‖u1‖2 + cVT ({ut})\n+ LT ({ut}) ] + Y 2\nT∑ t=1 x>t D −1 t xt .\nProof. Fix t. A long algebraic manipulation yields,\n(yt − ŷt)2 + min u1,...,ut−1 Qt−1 (u1, . . . ,ut−1)\n− min u1,...,ut Qt (u1, . . . ,ut)\n= (yt − ŷt)2 + 2ytx>t D−1t D′t−1et−1\n+e>t−1 [ −D−1t−1+D′t−1 ( D−1t D ′ t−1+c −1I )] et−1\n+ y2t x > t D −1 t xt − y2t . (15)\nSubstituting the specific value of the predictor ŷt = x>t D −1 t D ′ t−1et−1 from (14), we get that (15) equals to,\nŷ2t + y 2 t x > t D −1 t xt + e > t−1 [ −D−1t−1\n+ D′t−1 ( D−1t D ′ t−1 + c −1I ) ] et−1\n=e>t−1D ′ t−1D −1 t xtx > t D −1 t D ′ t−1et−1 + e > t−1 [ −D−1t−1\n+ D′t−1 ( D−1t D ′ t−1 + c −1I ) ] et−1 + y 2 t x > t D −1 t xt\n=e>t−1 [ D′t−1D −1 t xtx > t D −1 t D ′ t−1 −D−1t−1 (16)\n+ D′t−1 ( D−1t D ′ t−1 + c −1I ) ] et−1 + y 2 t x > t D −1 t xt .\nParameters: 1 < a , 0 < b, c Initialize: Set P0 = b−1I ∈ Rd×d and w0 = 0 ∈ Rd For t = 1, . . . , T do • Receive an instance xt • Output prediction ŷt = x>t wt−1 • Receive the correct label yt • Compute P̃t = ( P−1t−1 + (a− 1)xtx>t\n)−1 • Update wt = wt−1 + aP̃t(yt − ŷt)xt • Update Pt = P̃t + c−1I"
    }, {
      "heading" : "Output: wT , PT",
      "text" : "Figure 2: An H∞ algorithm for online regression.\nUsing Lem. 3 we upper bound (16) with, y2t x > t D −1 t xt ≤ Y 2x>t D −1 t xt . Finally, summing over t ∈ {1, . . . , T} gives the desired bound,\nT∑ t=1 (yt − ŷt)2 − min u1,...,uT\n[ b ‖u1‖2 + c\nT−1∑ t=1 ‖ut+1 − ut‖2\n+ T∑ t=1 ( yt − u>t xt\n)2]\n= LT (LASER)− min u1,...,uT\n[ b ‖u1‖2+cVT ({ut}) + LT ({ut}) ]\n≤ Y 2 T∑ t=1 x>t D −1 t xt\nIn the next lemma we further bound the right term of Thm. 4. This type of bound is based on the usage of the covariance-like matrix D.\nLemma 5.\nT∑ t=1 x>t D −1 t xt ≤ ln ∣∣∣∣1bDT ∣∣∣∣+ c−1 T∑ t=1 Tr (Dt−1) . (17)\nProof. Similar to the derivation of Forster [17] (details omitted due to lack of space),\nx>t D −1 t xt ≤ ln |Dt|∣∣Dt − xtx>t ∣∣ = ln |Dt|∣∣∣(D−1t−1 + c−1I)−1∣∣∣ = ln\n|Dt| |Dt−1| ∣∣(I + c−1Dt−1)∣∣ = ln\n|Dt| |Dt−1|\n+ ln ∣∣(I + c−1Dt−1)∣∣ .\nand because ln ∣∣ 1 bD0 ∣∣ ≥ 0 we get ∑Tt=1 x>t D−1t xt ≤ ln ∣∣ 1 bDT\n∣∣ + ∑Tt=1 ln ∣∣(I + c−1Dt−1)∣∣ ≤ ln ∣∣ 1bDT ∣∣ + c−1 ∑T t=1 Tr (Dt−1) .\nAt first sight it seems that the right term of (17) may grow super-linearly with T , as each of the matrices Dt grows with t. The next two lemmas show that this is not the case, and in fact, the right term of (17) is not growing too fast, which will allow us to obtain a sub-linear regret bound. Lem. 6 analyzes the properties of the recursion of D defined in (7) for scalars, that is d = 1. In Lem. 7 we extend this analysis to matrices.\nLemma 6. Define f(λ) = λβ/ (λ+ β) + x2 for β, λ ≥ 0 and some x2 ≤ γ2. Then: (1) f(λ) ≤ β + γ2 (2) f(λ) ≤\nλ+ γ2 (3) f(λ) ≤ max { λ, 3γ2+ √ γ4+4γ2β\n2\n} .\nThe proof appears in App. B.6. We build on Lem. 6 to bound the maximal eigenvalue of the matrices Dt. Lemma 7. Assume ‖xt‖2 ≤ X2 for some X . Then, the eigenvalues of Dt (for t ≥ 1), denoted by λi (Dt), are upper bounded by maxi λi (Dt) ≤ max { 3X2+ √ X4+4X2c 2 , b+X 2 } .\nProof. By induction. From (7) we have that λi(D1) ≤ b + X2 for i = 1, . . . , d. We proceed with a proof for some t. For simplicity, denote by λi = λi(Dt−1) the ith eigenvalue of Dt−1 with a corresponding eigenvector vi. From (7) we have,\nDt = ( D−1t−1 + c −1I )−1 + xtx > t\n( D−1t−1 + c −1I )−1 + I ‖xt‖2\n= d∑ i viv > i ( λic λi + c + ‖xt‖2 ) . (18)\nPlugging Lem. 6 in (18) we get, Dt ∑d i viv > i max { 3X2+ √ X4+4X2c 2 , b+X 2 }\n= max { 3X2+ √ X4+4X2c 2 , b+X 2 } I .\nFinally, equipped with the above lemmas we prove the main result of this section.\nCorollary 8. Assume ‖xt‖2 ≤ X2, |yt| ≤ Y . Then,\nLT (LASER) ≤ b ‖u1‖2 + LT ({ut}) + Y 2 ln ∣∣∣∣1bDT ∣∣∣∣ +c−1Y 2Tr (D0) + cV\n+c−1Y 2Tdmax\n{ 3X2 + √ X4 + 4X2c\n2 , b+X2\n} .\n(19)"
    }, {
      "heading" : "Furthermore, set b = εc for some 0 < ε < 1.",
      "text" : "Denote by µ = max { 9/8X2, (b+X2) 2\n8X2\n} and M =\nmax { 3X2, b+X2 }\n. If V ≤ T √ 2Y 2dX µ3/2 (low drift) then\nby setting\nc = (√ 2TY 2dX/V )2/3\n(20)\nwe have,\nLT (LASER) ≤ b ‖u1‖2 + 3 (√ 2Y 2dX )2/3 T 2/3V 1/3\n+ ε\n1− ε Y 2d+ LT ({ut}) + Y 2 ln ∣∣∣∣1bDT ∣∣∣∣ . (21)\nThe proof appears in Sec. A.1. A few remarks are in order. First, when the total drift V = 0 goes to zero, we set c = ∞ and thus we have Dt = bI + ∑t s=1 xsx > s used in recent algorithms [36, 17, 21, 9]. In this case the algorithm reduces to the algorithm by Forster [17] (which is also the Aggregating Algorithm for Regression of Vovk [36]), with the same logarithmic regret bound (note that the last term of (21) is logarithmic in T , see the proof of Forster [17]). See also the work of Azoury and Warmuth [2]. Second, substituting V = Tν we get that the bound depends on the average drift as T 2/3(Tν)1/3 = Tν1/3. Clearly, to have a sublinear regret we must have ν = o(1). Third, Vaits and Crammer [35] recently proposed an algorithm, called ARCOR, for the same setting. The regret of ARCOR depends on the total drift as √ TV ′ log(T ), where their definition of total drift is a sum of the Euclidean differences V ′ = ∑T−1 t ‖ut+1−ut‖, rather than the squared norm. When the instantaneous drift ‖ut+1 − ut‖ is constant, this notion of total drift is related to our average drift, V ′ = T √ ν. Therefore, in this case the bound of ARCOR [35] is ν1/4T log(T ) which is worse than our bound, both since it has an additional log(T ) factor (as opposed to our additive log term) and since ν = o(1). Therefore we expect that our algorithm will perform better than ARCOR [35] when the instantaneous drift is approximately constant. Indeed, the synthetic simulations described in Sec. 6 further support this conclusion. Fourth, Herbster and Warmuth [22] developed shifting bounds for general gradient descent algorithms with projection of the weight-vector using the Bregman divergence. In their bounds, there is a factor greater than 1 multiplying the term LT ({ut}), leading to a small regret only when the data is close to be realizable with linear models. Yet, their bounds have better dependency on d, the dimension of the inputs x. Busuttil and Kalnishkan [6] developed a variant of the Aggregating Algorithm [20] for the non-stationary setting. However, to have sublinear regret they require a strong assumption on the drift V = o(1), while we require only V = o(T ). Fifth, if V ≥ T Y\n2dM µ2 then by setting c =\n√ Y 2dMT/V\nwe have,\nLT (LASER) ≤ b ‖u1‖2 + 2 √ Y 2dTMV\n+ ε\n1− ε Y 2d+ LT ({ut}) + Y 2 ln ∣∣∣∣1bDT ∣∣∣∣ (22)\n(See App. B.5 for details). The last bound is linear in T and can be obtained also by a naive algorithm that outputs ŷt = 0 for all t."
    }, {
      "heading" : "5 An H∞ Algorithm for Online Regression",
      "text" : "Adaptive filtering is an active and well established area of research in signal processing. Formally, it is equivalent to online learning. On each iteration t the filter receives an input xt ∈ Rd and predicts a corresponding output ŷt. It then receives the true desired output yt and updates its internal model. Many adaptive filtering algorithms employ linear models, that is, at time t they output ŷt = w>t xt. For example, a well known online learning algorithm [37] for regression, which is basically a gradient-descent algorithm with the squared-loss, is known as the least mean-square (LMS) algorithm in the adaptive filtering literature [31].\nOne possible difference between adaptive filtering and online learning can be viewed in the interpretation of algorithms, and as a consequence, of their analysis. In online learning, the goal of an algorithm is to make predictions ŷt, and the predictions are compared to the predictions of some function from a known class (e.g. linear, parameteized by u). Thus, a typical online performance bound relates the quality of the algorithm’s predictions with the quality of some function’s g(x) = u>x predictions, using some non-negative loss measure `(w>t xt, yt). Such bounds often have the following shape,\nalgorithm loss with respect to observation︷ ︸︸ ︷∑ t `(w>t xt, yt) ≤ A function u loss︷ ︸︸ ︷∑ t `(u>xt, yt) +B,\nfor some multiplicative-factor A and an additive factor B.\nAdaptive filtering is similar to the realizable setting in machine learning, where it is assumed the existence of some filter and the goal is to recover it using noisy observations. Often it is assumed that the output is a corrupted version of the output of some function, y = f(x) + n, with some noise n. Thus a typical bound relates the quality of an algorithm’s predictions with respect to the target filter u and the amount of noise in the problem,\nalgorithm loss with respect to a reference︷ ︸︸ ︷∑ t `(w>t xt,u >xt) ≤ A amount of noise︷ ︸︸ ︷∑ t `(u>xt, yt) +B .\nThe H∞ filters (see e.g. papers by Simon [33, 32]) are a family of (robust) linear filters developed based on a min-max approach, like LASER, and analyzed in the worst case setting. These filters are reminiscent of the celebrated Kalman filter [23], which was motivated and analyzed in a stochastic setting with Gaussian noise. A pseudocode of one such filter we modified to online linear regression appears in Fig. 2. Theory of H∞ filters states [33, Section 11.3] the following bound on its performance as a filter.\nTheorem 9. Assume the filter is executed with parameters a > 1 and b, c > 0. Then, for all input-output pairs (xt, yt) and for all reference vectors ut the following bound holds on the filter’s performance, ∑T t=1 ( x>t wt − x>t ut\n)2 ≤ aLT ({ut}) + b ‖u1‖2 + cVT ({ut}) .\nFrom the theorem we establish a regret bound for the H∞ algorithm to online learning.\nCorollary 10. Fix α > 0. The total squared-loss suffered by the algorithm is bounded by\nLT (H∞) ≤ (1 + 1/α+ (1 + α) a)LT ({ut}) (23) + (1 + α) b ‖u1‖2 + (1 + α) cVT ({ut}) .\nProof. Using a bound of Hassibi and Kailath [4, Lemma 4] we have that for all α > 0, ( yt − x>t wt )2 ≤( 1 + 1α ) ( yt − x>t ut )2 + (1 + α) [ x>t (wt − ut) ]2 . Plugging back into the theorem and collecting the terms we get the desired bound.\nThe bound holds for any α > 0. We plug α =√ LT ({ut})/ ( aLT ({ut}) + cV + b ‖u1‖2 ) in (23) to\nget,\nLT (H∞) ≤ (1 + a)LT ({ut}) + cV + b ‖u1‖2\n+ 2 √( aLT ({ut}) + cV + b ‖u1‖2 ) LT ({ut})\n≤ (1 + a+ 2 √ a)LT ({ut}) + cV + b ‖u1‖2\n+ 2 √( cV + b ‖u1‖2 ) LT ({ut}) .\nIntuitively, we expect the H∞ algorithm to perform better when the data is close to linear, that is when LT ({ut}) is small, as, conceptually, it was designed to minimize a loss with respect to weights {ut}. On the other hand, LASER is expected to perform better when the data is hard to predict with linear models, as it is not motivated from this assumption. Indeed, the bounds reflect these observations.\nComparing the last bound with (21) we note a few differences. First, the factor (1 + a+ 2 √ a) ≥ 4 of LT ({ut}) is worse for H∞ than for LASER, which is a unit. Second, LASER has worse dependency in the drift T 2/3V 1/3, while forH∞ it is about cV +2 √ cV LT ({ut}). Third, the\nH∞ has an additive factor ∼ √ LT ({ut}), while LASER has an additive logarithmic factor, at most.\nHence, the bound of the H∞ based algorithm is better when the cumulative loss LT ({ut}) is small. In this case, 4LT ({ut}) is not a large quantity, and as all the other quantities behave like √ LT ({ut}), they are small as well. On the other hand, if LT ({ut}) is large, and is linear in T , the first term of the bound becomes dominant, and thus the factor of 4 for the H∞ algorithm makes its bound\nhigher than that of LASER. Both bounds were obtained from a min-max approach, either directly (LASER) or viareduction from filtering (H∞). The bound of the former is lower in hard problems. Kivinen et al. [26] proposed another approach for filtering with a bound depending on∑ t ‖ut−ut−1‖ and not the sum of squares as we have both for LASER and the H∞-based algorithm."
    }, {
      "heading" : "6 Simulations",
      "text" : "We evaluate the LASER and H∞ algorithms on four synthetic datasets. We set T = 2000 and d = 20. For all datasets, the inputs xt ∈ R20 were generated such that the first ten coordinates were grouped into five groups of size two. Each such pair was drawn from a 45◦ rotated Gaussian distribution with standard deviations 10 and 1. The remaining 10 coordinates were drawn from independent Gaussian distributions N (0, 2). The first synthetic dataset was generated using a sequence of vectors ut ∈ R20 for which the only non-zero coordinates are the first two, where their values are the coordinates of a unit vector that is rotating with a constant rate (linear drift). Specifically, we have ‖ut‖ = 1 and the instantaneous drift ‖ut − ut−1‖ is constant. The second synthetic dataset was generated using a sequence of vectors ut ∈ R20 for which the only non-zero coordinates are the first two. This vector in R2 is of unit norm ‖ut‖ = 1 and rotating in a rate of t−1 (sublinear drift). In addition every 50 time-steps the two-dimensional vector defined above was “embedded” in different pair of coordinates of the reference vector ut, for the first 50 steps it were coordinates 1, 2, in the next 50 examples, coordinates 3, 4, and so on.\nThis change causes a switch in the reference vector ut. For the first two datasets we set yt = x>t ut (linear data). The third and fourth datasets are the same as first and second except we set yt = x>t ut + nt where nt ∼ N (0, 0.05) (noisy data).\nWe compared six algorithms: NLMS (normalized least mean square) [3, 5] which is a state-of-the-art first-order algorithm, AROWR (AROW for Regression) [14], ARCOR [35], CR-RLS [11, 30], LASER and H∞. The algorithms’ parameters were tuned using a single random sequence. We repeat each experiment 100 times reporting the mean cumulative square-loss. The results are summarized in Fig. 3 (best viewed in color).\nFor the first and third datasets (left plots of Fig. 3) we observe the superior performance of the LASER algorithm over previous approaches. LASER has a good tracking ability, fast learning rate and it is designed to perform well in severe conditions like linear drift.\nFor the second and fourth datasets (right plots of Fig. 3), where we have sublinear drift level, we get that ARCOR outperforms LASER since it is especially designed for sublinear amount of data drift, yet, H∞ outperforms ARCOR when there is no noise (top-right plot).\nFor the third and fourth datasets (bottom plots of Fig. 3), where we added noise to labels, the performance of H∞ degrades, as expected from our discussion in Sec. 5."
    }, {
      "heading" : "7 Related Work",
      "text" : "The problem of performing online regression was studied for more than fifty years in statistics, signal processing and machine learning. We already mentioned the work of Widrow and Hoff [37] who studied a gradient descent algorithm for the squared loss. Many variants of the algorithm were studied since then. A notable example is the normalized least mean squares algorithm (NLMS) [5, 3] that adapts to the input’s scale.\nThere exists a large body of work on this problem proposed by the machine learning community, which clearly cannot be covered fully here. We refer the reader to a encyclopedic book in the subject [10]. Gradient descent based algorithms for regression with the squared loss were proposed by Cesa-Bianchi et al. [8] about two decades ago. These algorithms were generalized and extended by Kivinen and Warmuth [24] using additional regularization functions.\nAn online version of the ridge regression algorithm in the worst-case setting was proposed and analyzed by Foster [18]. A related algorithm called Aggregating Algorithm (AA) was studied by Vovk [20], and later applied to the problem of linear regression with square loss [36]. The recursive least squares (RLS) [21] is a similar algorithm proposed for adaptive filtering. Both algorithms make use\nof second order information, as they maintain a weightvector and a covariance-like positive semi-definite (PSD) matrix used to re-weight the input. The eigenvalues of this covariance-like matrix increase with time t, a property which is used to prove logarithmic regret bounds.\nThe derivation of our algorithm shares similarities with the work of Forster [17] and the work of Moroshko and Crammer [29]. These algorithms are motivated from the last-step min-max predictor. While the algorithms of Forster [17] and Moroshko and Crammer [29] are designed for the stationary setting, our work is primarily designed for the nonstationary setting. Moroshko and Crammer [29] also discussed a weak variant of the non-stationary setting, where the complexity is measured by the total distance from a reference vector ū, rather than the total distance of consecutive vectors (as in this paper), which is more relevant to non-stationary problems. Note also that Moroshko and Crammer [29] did not derive algorithms for the nonstationary setting, but just show a bound of the weighted min-max algorithm (designed for the stationary setting) in the weak non-stationary setting.\nOur work is mostly close to a recent algorithm [35] called ARCOR. This algorithm is based on the RLS algorithm with an additional projection step, and it controls the eigenvalues of a covariance-like matrix using scheduled resets. The Covariance Reset RLS algorithm (CR-RLS) [11, 30, 19] is another example of an algorithm that resets a covariance matrix but every fixed amount of data points, as opposed to ARCOR that performs these resets adaptively. All of these algorithms that were designed to have numerically stable computations, perform covariance reset from time to time. Our algorithm, LASER, is simpler as it does not involve these steps, and it controls the increase of the eigenvalues of the covariance matrix D implicitly rather than explicitly by “averaging” it with a fixed diagonal matrix (see (7)). The Kalman filter [23] and the H∞ algorithm (e.g. [33]) designed for filtering take a similar approach, yet the exact algebraic form is different (Fig. 1 vs. Fig. 2).\nARCOR also controls explicitly the norm of the weight vector, which is used for its analysis, by projecting it into a bounded set, as was also proposed by Herbster and Warmuth [22]. Other approaches to control its norm are to shrink it multiplicatively [25] or by removing old examples [7]. Some of these algorithms were designed to have sparse functions in the kernel space (e.g. [13, 15]). Note that our algorithm LASER is simpler as it does not perform any of these operation explicitly. Finally, few algorithms that employ second order information were recently proposed for classification [9, 14, 12], and later in the online convex programming framework [16, 28]."
    }, {
      "heading" : "8 Summary and Conclusions",
      "text" : "We proposed a novel algorithm for non-stationary online regression designed and analyzed with the squared loss. The algorithm was developed from the last-step minmax predictor for non-stationary problems, and we showed an exact recursive form of its solution. We also described an algorithm based on the H∞ filter, that is motivated from a min-max approach as well, yet for filtering, and bounded its regret. Simulations showed its superior performance in a worst-case (close to a constant per iteration) drift.\nAn interesting future direction is to extend the algorithm for general loss functions rather than the squared loss. Currently, to implement the algorithm we need to perform either matrix inversion or eigenvector decomposition, we like to design a more efficient version of the algorithm. Additionally, for the algorithm to perform well, the amount of drift V or a bound over it are used by the algorithm. An interesting direction is to design algorithms that automatically detect the level of drift, or are invariant to it."
    }, {
      "heading" : "A Proofs",
      "text" : ""
    }, {
      "heading" : "A.1 Proof of Corollary 8",
      "text" : "Proof. Plugging Lem. 5 in Thm. 4 we have for all (u1 . . .uT ),\nLT (LASER) ≤ b ‖u1‖2 + cV + LT ({ut})\n+ Y 2 ln ∣∣∣∣1bDT ∣∣∣∣+ c−1Y 2 T∑\nt=1\nTr (Dt−1) .\nUsing Lem. 7 we bound the RHS and get\nLT (LASER) ≤ b ‖u1‖2 + LT ({ut}) + Y 2 ln ∣∣∣∣1bDT ∣∣∣∣ +c−1Y 2Tr (D0) + cV\n+c−1Y 2Tdmax\n{ 3X2 + √ X4 + 4X2c\n2 , b+X2\n} .\nThe term c−1Y 2Tr (D0) does not depend on T , because c−1Y 2Tr (D0) = c −1Y 2d bcc−b = ε 1−εY 2d . To show (21), note that V ≤ T √ 2Y 2dX µ3/2 ⇔ µ ≤ (√ 2Y 2dXT V )2/3 =\nc . We thus have that ( 3X2 + √ X4 + 4X2c ) /2 ≤(\n3X2 + √ 8X2c ) /2 ≤ √ 8X2c, and we get a bound on\nthe right term of (19),\nmax {( 3X2 + √ X4 + 4X2c ) /2, b+X2 } ≤\nmax {√ 8X2c, b+X2 } ≤ 2X √ 2c .\nUsing this bound and plugging the value of c from (20) we bound (19) and conclude the proof, (√ 2TY 2dX\nV\n)2/3 V + Y 2Td2X √√√√2(√2TY 2dX V )−2/3 = 3 (√ 2TY 2dX )2/3 V 1/3 ."
    }, {
      "heading" : "SUPPLEMENTARY MATERIAL",
      "text" : ""
    }, {
      "heading" : "B.1 Proof of Lem. 1",
      "text" : "Proof. We calculate\nPt (ut) = min u1,...,ut−1\n( b ‖u1‖2 + c\nt−1∑ s=1 ‖us+1 − us‖2\n+ t∑ s=1 ( ys − u>s xs\n)2)\n= min ut−1 min u1,...,ut−2\n( b ‖u1‖2 + c\nt−2∑ s=1 ‖us+1 − us‖2\n+ t−1∑ s=1 ( ys − u>s xs )2 + c ‖ut − ut−1‖2\n+ ( yt − u>t xt\n)2)\n= min ut−1\n( Pt−1 (ut−1) + c ‖ut − ut−1‖2\n+ ( yt − u>t xt\n)2)"
    }, {
      "heading" : "B.2 Proof of Lem. 2",
      "text" : "Proof. By definition, P1 (u1) = Q1 (u1) = b ‖u1‖2 +( y1 − u>1 x1 )2 = u>1 ( bI + x1x > 1 ) u1 − 2y1u>1 x1 + y21 , and indeed D1 = bI + x1x>1 , e1 = y1x1, and f1 = y 2 1 . We proceed by induction, assume that, Pt−1 (ut−1) = u>t−1Dt−1ut−1 − 2u>t−1et−1 + ft−1. Applying Lem. 1\nwe get,\nPt (ut) = min ut−1\n( u>t−1Dt−1ut−1 − 2u>t−1et−1 + ft−1\n+ c ‖ut − ut−1‖2 + ( yt − u>t xt\n)2)\n= min ut−1\n( u>t−1 (cI + Dt−1)ut−1\n− 2u>t−1 (cut + et−1) + ft−1 + c ‖ut‖ 2\n+ ( yt − u>t xt )2) =− (cut + et−1)> (cI + Dt−1)−1 (cut + et−1)\n+ ft−1 + c ‖ut‖2 + ( yt − u>t xt )2 =u>t ( cI + xtx > t − c2 (cI + Dt−1) −1 ) ut\n− 2u>t [ c (cI + Dt−1) −1 et−1 + ytxt ] − e>t−1 (cI + Dt−1) −1 et−1 + ft−1 + y 2 t\nUsing Woodbury identity we continue to develop the last equation,\n=u>t ( cI + xtx > t\n−c2 [ c−1I− c−2 ( D−1t−1 + c −1I )−1]) ut\n− 2u>t [( I + c−1Dt−1 )−1 et−1 + ytxt ] − e>t−1 (cI + Dt−1) −1 et−1 + ft−1 + y 2 t\n=u>t (( D−1t−1 + c −1I )−1 + xtx > t ) ut\n− 2u>t [( I + c−1Dt−1 )−1 et−1 + ytxt ] − e>t−1 (cI + Dt−1) −1 et−1 + ft−1 + y 2 t ,\nand indeed Dt = ( D−1t−1 + c −1I )−1 + xtx > t ,\net = ( I + c−1Dt−1 )−1 et−1 + ytxt and, ft = ft−1 − e>t−1 (cI + Dt−1) −1 et−1 + y 2 t , as desired."
    }, {
      "heading" : "B.3 Proof of Lem. 3",
      "text" : "Proof. We first use the Woodbury equation to get the following two identities\nD−1t = [( D−1t−1 + c −1I )−1 + xtx > t ]−1 = D−1t−1 + c −1I\n− ( D−1t−1 + c −1I ) xtx > t ( D−1t−1 + c −1I )\n1 + x>t ( D−1t−1 + c −1I ) xt\nand ( I + c−1Dt−1 )−1 = I− c−1 ( D−1t−1 + c −1I )−1\nMultiplying both identities with each other we get, D−1t ( I + c−1Dt−1 )−1 = [ D−1t−1 + c −1I\n− ( D−1t−1 + c −1I ) xtx > t ( D−1t−1 + c −1I )\n1 + x>t ( D−1t−1 + c −1I ) xt\n][ I\n− c−1 ( D−1t−1 + c −1I )−1 ]\n= D−1t−1 − ( D−1t−1 + c −1I ) xtx > t D −1 t−1\n1 + x>t ( D−1t−1 + c −1I ) xt\n(24)\nand, similarly, we multiply the identities in the other order and get, (\nI + c−1Dt−1 )−1 D−1t\n= D−1t−1 − D−1t−1xtx > t\n( D−1t−1 + c −1I )\n1 + x>t ( D−1t−1 + c −1I ) xt\n(25)\nFinally, from (24) we get,( I + c−1Dt−1 )−1 D−1t xtx > t D −1 t ( I + c−1Dt−1 )−1 −D−1t−1 + ( I + c−1Dt−1 )−1 [ D−1t ( I + c−1Dt−1\n)−1 +c−1I\n] = ( I + c−1Dt−1 )−1 D−1t xtx > t D −1 t ( I + c−1Dt−1\n)−1 −D−1t−1\n+ [ I− c−1 ( D−1t−1 + c −1I )−1] [ D−1t−1 + c −1I − ( D−1t−1 + c −1I ) xtx > t D −1 t−1\n1 + x>t ( D−1t−1 + c −1I ) xt ] We develop the last equality and use (24) and (25) in the second equality below,\n= ( I + c−1Dt−1 )−1 D−1t xtx > t D −1 t ( I + c−1Dt−1 )−1 −D−1t−1 + D −1 t−1 − D−1t−1xtx > t D −1 t−1\n1 + x>t ( D−1t−1 + c −1I ) xt\n= [ D−1t−1 − D−1t−1xtx > t ( D−1t−1 + c −1I )\n1 + x>t ( D−1t−1 + c −1I ) xt ] xtx > t[\nD−1t−1 − ( D−1t−1 + c −1I ) xtx > t D −1 t−1\n1 + x>t ( D−1t−1 + c −1I ) xt\n]\n− D−1t−1xtx > t D −1 t−1 1 + x>t ( D−1t−1 + c −1I ) xt\n= − x>t ( D−1t−1 + c −1I ) xtD −1 t−1xtx > t D −1 t−1(\n1 + x>t ( D−1t−1 + c −1I ) xt )2 0"
    }, {
      "heading" : "B.4 Derivations for Thm. 4",
      "text" : "(yt − ŷt)2 + min u1,...,ut−1 Qt−1 (u1, . . . ,ut−1)\n− min u1,...,ut Qt (u1, . . . ,ut)\n= (yt − ŷt)2 − e>t−1D−1t−1et−1 + ft−1 + e>t D −1 t et − ft = (yt − ŷt)2 − e>t−1D−1t−1et−1 + e>t−1 (cI + Dt−1) −1 et−1 − y2t\n+ (( I + c−1Dt−1 )−1 et−1 + ytxt )> D−1t((\nI + c−1Dt−1 )−1 et−1 + ytxt ) where the last equality follows (8). We proceed to develop the last equality,\n= (yt − ŷt)2 − e>t−1D−1t−1et−1 + e>t−1 (cI + Dt−1) −1 et−1 − y2t\n+ e>t−1 ( I + c−1Dt−1 )−1 D−1t ( I + c−1Dt−1 )−1 et−1\n+ 2ytx > t D −1 t ( I + c−1Dt−1 )−1 et−1 + y 2 t x > t D −1 t xt\n= (yt − ŷt)2 + e>t−1 ( −D−1t−1+(\nI + c−1Dt−1 )−1 [ D−1t ( I + c−1Dt−1 )−1 +c−1I ]) et−1 + 2ytx > t D −1 t ( I + c−1Dt−1 )−1 et−1\n+ y2t x > t D −1 t xt − y2t .\nB.5 Details for the bound (22)\nTo show the bound (22), note that, V ≥ T Y 2dM µ2 ⇔ µ ≥√\nTY 2dM V = c . We thus have that the right term of (19) is\nupper bounded as follows,\nmax\n{ 3X2 + √ X4 + 4X2c\n2 , b+X2 } ≤max { 3X2, √ X4 + 4X2c, b+X2\n} ≤max { 3X2, √ 2X2, √ 8X2c, b+X2\n} = √ 8X2 max\n{ 3X2√ 8X2 , √ c, b+X2√ 8X2 }\n= √ 8X2 √√√√max{ (3X2)2 8X2 , c, (b+X2) 2 8X2 } = √ 8X2 √ max {µ, c} ≤ √ 8X2 √ µ = M .\nUsing this bound and plugging c = √ Y 2dMT/V\nwe bound (19), √\nY 2dMT V V + 1√ Y 2dMT\nV\nTdY 2M =\n2 √ Y 2dMTV ."
    }, {
      "heading" : "B.6 Proof of Lem. 6",
      "text" : "Proof. For the first property of the lemma we have that f(λ) = λβ/ (λ+ β) + x2 ≤ β × 1 + x2. The second property follows from the symmetry between β and λ. To prove the third property we decompose the function as, f(λ) = λ− λ 2\nλ+β + x 2. Therefore, the function is bounded\nby its argument f(λ) ≤ λ if, and only if, − λ 2\nλ+β + x 2 ≤ 0.\nSince we assume x2 ≤ γ2, the last inequality holds if, −λ2+γ2λ+γ2β ≤ 0, which holds for λ ≥ γ 2+ √ γ4+4γ2β\n2 .\nTo conclude. If λ ≥ γ 2+ √ γ4+4γ2β\n2 , then f(λ) ≤ λ. Otherwise, by the second property, we have, f(λ) ≤ λ + γ2 ≤ γ2+ √ γ4+4γ2β\n2 + γ 2 =\n3γ2+ √ γ4+4γ2β\n2 , as required."
    } ],
    "references" : [ {
      "title" : "Tracking the best disjunction",
      "author" : [ "P. Auer", "M. Warmuth" ],
      "venue" : "Electronic Colloquium on Computational Complexity (ECCC),",
      "citeRegEx" : "1",
      "shortCiteRegEx" : "1",
      "year" : 2000
    }, {
      "title" : "Relative loss bounds for on-line density estimation with the exponential family of distributions",
      "author" : [ "K. Azoury", "M. Warmuth" ],
      "venue" : "Machine Learning,",
      "citeRegEx" : "2",
      "shortCiteRegEx" : "2",
      "year" : 2001
    }, {
      "title" : "Analysis of the normalized lms algorithm with gaussian inputs",
      "author" : [ "N.J. Bershad" ],
      "venue" : "IEEE Transactions on Acoustics, Speech, and Signal Processing,",
      "citeRegEx" : "3",
      "shortCiteRegEx" : "3",
      "year" : 1986
    }, {
      "title" : "Performance of adaptive estimation algorithms in dependent random environments",
      "author" : [ "R.R. Bitmead", "B.D.O. Anderson" ],
      "venue" : "IEEE Trans. on Automatic Control,",
      "citeRegEx" : "5",
      "shortCiteRegEx" : "5",
      "year" : 1980
    }, {
      "title" : "Online regression competitive with changing predictors",
      "author" : [ "S. Busuttil", "Y. Kalnishkan" ],
      "venue" : "In ALT,",
      "citeRegEx" : "6",
      "shortCiteRegEx" : "6",
      "year" : 2007
    }, {
      "title" : "Tracking the best hyperplane with a simple budget perceptron",
      "author" : [ "G. Cavallanti", "N. Cesa-Bianchi", "C. Gentile" ],
      "venue" : "Machine Learning,",
      "citeRegEx" : "7",
      "shortCiteRegEx" : "7",
      "year" : 2007
    }, {
      "title" : "Worst case quadratic loss bounds for on-line prediction of linear functions by gradient descent",
      "author" : [ "N. Ceas-Bianchi", "P.M. Long", "M.K. Warmuth" ],
      "venue" : "IEEE Tran. on NN,",
      "citeRegEx" : "8",
      "shortCiteRegEx" : "8",
      "year" : 1996
    }, {
      "title" : "A second-order perceptron algorithm",
      "author" : [ "N. Cesa-Bianchi", "A. Conconi", "C. Gentile" ],
      "venue" : "Siam Journal of Commutation,",
      "citeRegEx" : "9",
      "shortCiteRegEx" : "9",
      "year" : 2005
    }, {
      "title" : "Prediction, Learning, and Games",
      "author" : [ "N. Cesa-Bianchi", "G. Lugosi" ],
      "venue" : null,
      "citeRegEx" : "10",
      "shortCiteRegEx" : "10",
      "year" : 2006
    }, {
      "title" : "Application of the least squares algorithm to the observer design for linear time-varying systems",
      "author" : [ "M.-S. Chen", "J.-Y. Yen" ],
      "venue" : "Automatic Control, IEEE Tran. on,",
      "citeRegEx" : "11",
      "shortCiteRegEx" : "11",
      "year" : 1999
    }, {
      "title" : "Confidenceweighted linear classification for text categorization",
      "author" : [ "K. Crammer", "M. Dredze", "F. Pereira" ],
      "venue" : "J. Mach. Learn. Res.,",
      "citeRegEx" : "12",
      "shortCiteRegEx" : "12",
      "year" : 2012
    }, {
      "title" : "Online classification on a budget",
      "author" : [ "K. Crammer", "J. Kandola", "Y. Singer" ],
      "venue" : "In NIPS,",
      "citeRegEx" : "13",
      "shortCiteRegEx" : "13",
      "year" : 2003
    }, {
      "title" : "Adaptive regularization of weighted vectors",
      "author" : [ "K. Crammer", "A. Kulesza", "M. Dredze" ],
      "venue" : "In Advances in Neural Information Processing Systems",
      "citeRegEx" : "14",
      "shortCiteRegEx" : "14",
      "year" : 2009
    }, {
      "title" : "The forgetron: A kernel-based perceptron on a fixed budget",
      "author" : [ "O. Dekel", "S. Shalev-shwartz", "Y. Singer" ],
      "venue" : "In NIPS",
      "citeRegEx" : "15",
      "shortCiteRegEx" : "15",
      "year" : 2005
    }, {
      "title" : "Adaptive subgradient methods for online learning and stochastic optimization",
      "author" : [ "J. Duchi", "E. Hazan", "Y. Singer" ],
      "venue" : "In COLT,",
      "citeRegEx" : "16",
      "shortCiteRegEx" : "16",
      "year" : 2010
    }, {
      "title" : "On relative loss bounds in generalized linear regression",
      "author" : [ "J. Forster" ],
      "venue" : "In Fundamentals of Computation Theory (FCT),",
      "citeRegEx" : "17",
      "shortCiteRegEx" : "17",
      "year" : 1999
    }, {
      "title" : "Prediction in the worst case",
      "author" : [ "D. Foster" ],
      "venue" : "The Annals of Statistics,",
      "citeRegEx" : "18",
      "shortCiteRegEx" : "18",
      "year" : 1991
    }, {
      "title" : "Logical covariance matrix reset in self-tuning control",
      "author" : [ "S. Goodhart", "K. Burnham", "D. James" ],
      "venue" : null,
      "citeRegEx" : "19",
      "shortCiteRegEx" : "19",
      "year" : 1991
    }, {
      "title" : "Aggregating strategies",
      "author" : [ "V.G.Vovk" ],
      "venue" : "Proceedings of the Third Annual Workshop on Computational Learning Theory,",
      "citeRegEx" : "20",
      "shortCiteRegEx" : "20",
      "year" : 1990
    }, {
      "title" : "Recursive least squares",
      "author" : [ "M. Hayes" ],
      "venue" : "In Statistical Digital Signal Processing and Modeling,",
      "citeRegEx" : "21",
      "shortCiteRegEx" : "21",
      "year" : 1996
    }, {
      "title" : "Tracking the best linear predictor",
      "author" : [ "M. Herbster", "M. Warmuth" ],
      "venue" : "JMLR, 1:281–309,",
      "citeRegEx" : "22",
      "shortCiteRegEx" : "22",
      "year" : 2001
    }, {
      "title" : "A new approach to linear filtering and prediction problems",
      "author" : [ "R.E. Kalman" ],
      "venue" : "Transactions of the ASME– Journal of Basic Engineering,",
      "citeRegEx" : "23",
      "shortCiteRegEx" : "23",
      "year" : 1960
    }, {
      "title" : "Exponential gradient versus gradient descent for linear predictors",
      "author" : [ "J. Kivinen", "M.K.Warmuth" ],
      "venue" : "Information and Computation,",
      "citeRegEx" : "24",
      "shortCiteRegEx" : "24",
      "year" : 1997
    }, {
      "title" : "Online learning with kernels",
      "author" : [ "J. Kivinen", "A. Smola", "R. Williamson" ],
      "venue" : "In NIPS,",
      "citeRegEx" : "25",
      "shortCiteRegEx" : "25",
      "year" : 2001
    }, {
      "title" : "The pnorm generalization of the lms algorithm for adaptive filtering",
      "author" : [ "J. Kivinen", "M.K. Warmuth", "B. Hassibi" ],
      "venue" : "In Proc. 13th IFAC Symposium on System Identification,",
      "citeRegEx" : "26",
      "shortCiteRegEx" : "26",
      "year" : 2003
    }, {
      "title" : "The weighted majority algorithm",
      "author" : [ "N. Littlestone", "M.K. Warmuth" ],
      "venue" : "Inf. Comput.,",
      "citeRegEx" : "27",
      "shortCiteRegEx" : "27",
      "year" : 1994
    }, {
      "title" : "Adaptive bound optimization for online convex optimization",
      "author" : [ "H.B. McMahan", "M.J. Streeter" ],
      "venue" : "In COLT,",
      "citeRegEx" : "28",
      "shortCiteRegEx" : "28",
      "year" : 2010
    }, {
      "title" : "Weighted last-step min-max algorithm with improved sub-logarithmic regret",
      "author" : [ "E. Moroshko", "K. Crammer" ],
      "venue" : "In The 23nd International Conference on Algorithmic Learning Theory, ALT",
      "citeRegEx" : "29",
      "shortCiteRegEx" : "29",
      "year" : 2012
    }, {
      "title" : "Modified least squares algorithm incorporating exponential resetting and forgetting",
      "author" : [ "M. Salgado", "G. Goodwin", "R. Middleton" ],
      "venue" : "International J. of Control,",
      "citeRegEx" : "30",
      "shortCiteRegEx" : "30",
      "year" : 1988
    }, {
      "title" : "Adaptive Filters",
      "author" : [ "A.H. Sayed" ],
      "venue" : null,
      "citeRegEx" : "31",
      "shortCiteRegEx" : "31",
      "year" : 2008
    }, {
      "title" : "A game theory approach to constrained minimax state estimation",
      "author" : [ "D. Simon" ],
      "venue" : "IEEE Transactions on Signal Processing,",
      "citeRegEx" : "32",
      "shortCiteRegEx" : "32",
      "year" : 2006
    }, {
      "title" : "Optimal State Estimation: Kalman, H Infinity, and Nonlinear Approaches",
      "author" : [ "D. Simon" ],
      "venue" : "Wiley- Interscience,",
      "citeRegEx" : "33",
      "shortCiteRegEx" : "33",
      "year" : 2006
    }, {
      "title" : "The last-step minimax algorithm",
      "author" : [ "E. Takimoto", "M. Warmuth" ],
      "venue" : "In ALT,",
      "citeRegEx" : "34",
      "shortCiteRegEx" : "34",
      "year" : 2000
    }, {
      "title" : "Re-adapting the regularization of weights for non-stationary regression",
      "author" : [ "N. Vaits", "K. Crammer" ],
      "venue" : "In ALT,",
      "citeRegEx" : "35",
      "shortCiteRegEx" : "35",
      "year" : 2011
    }, {
      "title" : "Competitive on-line statistics",
      "author" : [ "V. Vovk" ],
      "venue" : "International Statistical Review,",
      "citeRegEx" : "36",
      "shortCiteRegEx" : "36",
      "year" : 2001
    }, {
      "title" : "Adaptive switching circuits. In Institute of Radio Engineers, Western Electronic Show and Convention",
      "author" : [ "B. Widrow", "M.E. Hoff" ],
      "venue" : "Convention Record, Part",
      "citeRegEx" : "37",
      "shortCiteRegEx" : "37",
      "year" : 1960
    } ],
    "referenceMentions" : [ {
      "referenceID" : 8,
      "context" : "the topic [10]) for this problem, some of which are able to achieve an average loss arbitrarily close to that of the best function in retrospect.",
      "startOffset" : 10,
      "endOffset" : 14
    }, {
      "referenceID" : 25,
      "context" : "Some previous algorithms [27, 1, 22, 25] designed for this problem are based on gradient descent, with additional control on the norm (or Bregman divergence) of the weight-vector used for prediction [25], or the number of inputs used to define it [7].",
      "startOffset" : 25,
      "endOffset" : 40
    }, {
      "referenceID" : 0,
      "context" : "Some previous algorithms [27, 1, 22, 25] designed for this problem are based on gradient descent, with additional control on the norm (or Bregman divergence) of the weight-vector used for prediction [25], or the number of inputs used to define it [7].",
      "startOffset" : 25,
      "endOffset" : 40
    }, {
      "referenceID" : 20,
      "context" : "Some previous algorithms [27, 1, 22, 25] designed for this problem are based on gradient descent, with additional control on the norm (or Bregman divergence) of the weight-vector used for prediction [25], or the number of inputs used to define it [7].",
      "startOffset" : 25,
      "endOffset" : 40
    }, {
      "referenceID" : 23,
      "context" : "Some previous algorithms [27, 1, 22, 25] designed for this problem are based on gradient descent, with additional control on the norm (or Bregman divergence) of the weight-vector used for prediction [25], or the number of inputs used to define it [7].",
      "startOffset" : 25,
      "endOffset" : 40
    }, {
      "referenceID" : 23,
      "context" : "Some previous algorithms [27, 1, 22, 25] designed for this problem are based on gradient descent, with additional control on the norm (or Bregman divergence) of the weight-vector used for prediction [25], or the number of inputs used to define it [7].",
      "startOffset" : 199,
      "endOffset" : 203
    }, {
      "referenceID" : 5,
      "context" : "Some previous algorithms [27, 1, 22, 25] designed for this problem are based on gradient descent, with additional control on the norm (or Bregman divergence) of the weight-vector used for prediction [25], or the number of inputs used to define it [7].",
      "startOffset" : 247,
      "endOffset" : 250
    }, {
      "referenceID" : 15,
      "context" : "We take a different route and derive an algorithm based on the last-step min-max approach proposed by Forster [17] and later used [34] for online density estimation.",
      "startOffset" : 110,
      "endOffset" : 114
    }, {
      "referenceID" : 32,
      "context" : "We take a different route and derive an algorithm based on the last-step min-max approach proposed by Forster [17] and later used [34] for online density estimation.",
      "startOffset" : 130,
      "endOffset" : 134
    }, {
      "referenceID" : 33,
      "context" : "stantaneous drift is close to constant, this improves over a previous bound of Vaits and Crammer [35] of an algorithm named ARCOR that showed a bound of Tν log(T ).",
      "startOffset" : 97,
      "endOffset" : 101
    }, {
      "referenceID" : 15,
      "context" : "Additionally, when no drift is introduced (stationary setting) our algorithm suffers logarithmic regret, as for the algorithm of Forster [17].",
      "startOffset" : 137,
      "endOffset" : 141
    }, {
      "referenceID" : 15,
      "context" : "To solve it, we follow an approach used by Forster in a different context [17].",
      "startOffset" : 74,
      "endOffset" : 78
    }, {
      "referenceID" : 15,
      "context" : "This problem is of a similar form to the one discussed by Forster [17], from which we get the optimal solution, ŷT = clip ( xTD −1 T ( I + cDT−1 )−1 eT−1, Y ) , where for y > 0 we define clip(x, y) = sign(x) min{|x|, y}.",
      "startOffset" : 66,
      "endOffset" : 70
    }, {
      "referenceID" : 34,
      "context" : "Clearly, for c = ∞ the LASER algorithm reduces to the AAR algorithm of Vovk [36], or the last-step min-max algorithm of Forster [17].",
      "startOffset" : 76,
      "endOffset" : 80
    }, {
      "referenceID" : 15,
      "context" : "Clearly, for c = ∞ the LASER algorithm reduces to the AAR algorithm of Vovk [36], or the last-step min-max algorithm of Forster [17].",
      "startOffset" : 128,
      "endOffset" : 132
    }, {
      "referenceID" : 1,
      "context" : "See also the work of Azoury and Warmuth [2].",
      "startOffset" : 40,
      "endOffset" : 43
    }, {
      "referenceID" : 1,
      "context" : "This algorithm can be seen also as a forward algorithm [2]: The predictor of (14) can be seen as the optimal linear model obtained over the same prefix of length T − 1 and the new input xT with fictional-label yT = 0.",
      "startOffset" : 55,
      "endOffset" : 58
    }, {
      "referenceID" : 15,
      "context" : "Similar to the derivation of Forster [17] (details omitted due to lack of space),",
      "startOffset" : 37,
      "endOffset" : 41
    }, {
      "referenceID" : 34,
      "context" : "First, when the total drift V = 0 goes to zero, we set c = ∞ and thus we have Dt = bI + ∑t s=1 xsx > s used in recent algorithms [36, 17, 21, 9].",
      "startOffset" : 129,
      "endOffset" : 144
    }, {
      "referenceID" : 15,
      "context" : "First, when the total drift V = 0 goes to zero, we set c = ∞ and thus we have Dt = bI + ∑t s=1 xsx > s used in recent algorithms [36, 17, 21, 9].",
      "startOffset" : 129,
      "endOffset" : 144
    }, {
      "referenceID" : 19,
      "context" : "First, when the total drift V = 0 goes to zero, we set c = ∞ and thus we have Dt = bI + ∑t s=1 xsx > s used in recent algorithms [36, 17, 21, 9].",
      "startOffset" : 129,
      "endOffset" : 144
    }, {
      "referenceID" : 7,
      "context" : "First, when the total drift V = 0 goes to zero, we set c = ∞ and thus we have Dt = bI + ∑t s=1 xsx > s used in recent algorithms [36, 17, 21, 9].",
      "startOffset" : 129,
      "endOffset" : 144
    }, {
      "referenceID" : 15,
      "context" : "In this case the algorithm reduces to the algorithm by Forster [17] (which is also the Aggregating Algorithm for Regression of Vovk [36]), with the same logarithmic regret bound (note that the last term of (21) is logarithmic in T , see the proof of Forster [17]).",
      "startOffset" : 63,
      "endOffset" : 67
    }, {
      "referenceID" : 34,
      "context" : "In this case the algorithm reduces to the algorithm by Forster [17] (which is also the Aggregating Algorithm for Regression of Vovk [36]), with the same logarithmic regret bound (note that the last term of (21) is logarithmic in T , see the proof of Forster [17]).",
      "startOffset" : 132,
      "endOffset" : 136
    }, {
      "referenceID" : 15,
      "context" : "In this case the algorithm reduces to the algorithm by Forster [17] (which is also the Aggregating Algorithm for Regression of Vovk [36]), with the same logarithmic regret bound (note that the last term of (21) is logarithmic in T , see the proof of Forster [17]).",
      "startOffset" : 258,
      "endOffset" : 262
    }, {
      "referenceID" : 1,
      "context" : "See also the work of Azoury and Warmuth [2].",
      "startOffset" : 40,
      "endOffset" : 43
    }, {
      "referenceID" : 33,
      "context" : "Third, Vaits and Crammer [35] recently proposed an algorithm, called ARCOR, for the same setting.",
      "startOffset" : 25,
      "endOffset" : 29
    }, {
      "referenceID" : 33,
      "context" : "Therefore, in this case the bound of ARCOR [35] is νT log(T ) which is worse than our bound, both since it has an additional log(T ) factor (as opposed to our additive log term) and since ν = o(1).",
      "startOffset" : 43,
      "endOffset" : 47
    }, {
      "referenceID" : 33,
      "context" : "Therefore we expect that our algorithm will perform better than ARCOR [35] when the instantaneous drift is approximately constant.",
      "startOffset" : 70,
      "endOffset" : 74
    }, {
      "referenceID" : 20,
      "context" : "Fourth, Herbster and Warmuth [22] developed shifting bounds for general gradient descent algorithms with projection of the weight-vector using the Bregman divergence.",
      "startOffset" : 29,
      "endOffset" : 33
    }, {
      "referenceID" : 4,
      "context" : "Busuttil and Kalnishkan [6] developed a variant of the Aggregating Algorithm [20] for the non-stationary setting.",
      "startOffset" : 24,
      "endOffset" : 27
    }, {
      "referenceID" : 18,
      "context" : "Busuttil and Kalnishkan [6] developed a variant of the Aggregating Algorithm [20] for the non-stationary setting.",
      "startOffset" : 77,
      "endOffset" : 81
    }, {
      "referenceID" : 35,
      "context" : "For example, a well known online learning algorithm [37] for regression, which is basically a gradient-descent algorithm with the squared-loss, is known as the least mean-square (LMS) algorithm in the adaptive filtering literature [31].",
      "startOffset" : 52,
      "endOffset" : 56
    }, {
      "referenceID" : 29,
      "context" : "For example, a well known online learning algorithm [37] for regression, which is basically a gradient-descent algorithm with the squared-loss, is known as the least mean-square (LMS) algorithm in the adaptive filtering literature [31].",
      "startOffset" : 231,
      "endOffset" : 235
    }, {
      "referenceID" : 31,
      "context" : "papers by Simon [33, 32]) are a family of (robust) linear filters developed based on a min-max approach, like LASER, and analyzed in the worst case setting.",
      "startOffset" : 16,
      "endOffset" : 24
    }, {
      "referenceID" : 30,
      "context" : "papers by Simon [33, 32]) are a family of (robust) linear filters developed based on a min-max approach, like LASER, and analyzed in the worst case setting.",
      "startOffset" : 16,
      "endOffset" : 24
    }, {
      "referenceID" : 21,
      "context" : "These filters are reminiscent of the celebrated Kalman filter [23], which was motivated and analyzed in a stochastic setting with Gaussian noise.",
      "startOffset" : 62,
      "endOffset" : 66
    }, {
      "referenceID" : 24,
      "context" : "[26] proposed another approach for filtering with a bound depending on ∑ t ‖ut−ut−1‖ and not the sum of squares as we have both for LASER and the H∞-based algorithm.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 2,
      "context" : "We compared six algorithms: NLMS (normalized least mean square) [3, 5] which is a state-of-the-art first-order algorithm, AROWR (AROW for Regression) [14], ARCOR [35], CR-RLS [11, 30], LASER and H∞.",
      "startOffset" : 64,
      "endOffset" : 70
    }, {
      "referenceID" : 3,
      "context" : "We compared six algorithms: NLMS (normalized least mean square) [3, 5] which is a state-of-the-art first-order algorithm, AROWR (AROW for Regression) [14], ARCOR [35], CR-RLS [11, 30], LASER and H∞.",
      "startOffset" : 64,
      "endOffset" : 70
    }, {
      "referenceID" : 12,
      "context" : "We compared six algorithms: NLMS (normalized least mean square) [3, 5] which is a state-of-the-art first-order algorithm, AROWR (AROW for Regression) [14], ARCOR [35], CR-RLS [11, 30], LASER and H∞.",
      "startOffset" : 150,
      "endOffset" : 154
    }, {
      "referenceID" : 33,
      "context" : "We compared six algorithms: NLMS (normalized least mean square) [3, 5] which is a state-of-the-art first-order algorithm, AROWR (AROW for Regression) [14], ARCOR [35], CR-RLS [11, 30], LASER and H∞.",
      "startOffset" : 162,
      "endOffset" : 166
    }, {
      "referenceID" : 9,
      "context" : "We compared six algorithms: NLMS (normalized least mean square) [3, 5] which is a state-of-the-art first-order algorithm, AROWR (AROW for Regression) [14], ARCOR [35], CR-RLS [11, 30], LASER and H∞.",
      "startOffset" : 175,
      "endOffset" : 183
    }, {
      "referenceID" : 28,
      "context" : "We compared six algorithms: NLMS (normalized least mean square) [3, 5] which is a state-of-the-art first-order algorithm, AROWR (AROW for Regression) [14], ARCOR [35], CR-RLS [11, 30], LASER and H∞.",
      "startOffset" : 175,
      "endOffset" : 183
    }, {
      "referenceID" : 35,
      "context" : "We already mentioned the work of Widrow and Hoff [37] who studied a gradient descent algorithm for the squared loss.",
      "startOffset" : 49,
      "endOffset" : 53
    }, {
      "referenceID" : 3,
      "context" : "A notable example is the normalized least mean squares algorithm (NLMS) [5, 3] that adapts to the input’s scale.",
      "startOffset" : 72,
      "endOffset" : 78
    }, {
      "referenceID" : 2,
      "context" : "A notable example is the normalized least mean squares algorithm (NLMS) [5, 3] that adapts to the input’s scale.",
      "startOffset" : 72,
      "endOffset" : 78
    }, {
      "referenceID" : 8,
      "context" : "We refer the reader to a encyclopedic book in the subject [10].",
      "startOffset" : 58,
      "endOffset" : 62
    }, {
      "referenceID" : 6,
      "context" : "[8] about two decades ago.",
      "startOffset" : 0,
      "endOffset" : 3
    }, {
      "referenceID" : 22,
      "context" : "These algorithms were generalized and extended by Kivinen and Warmuth [24] using additional regularization functions.",
      "startOffset" : 70,
      "endOffset" : 74
    }, {
      "referenceID" : 16,
      "context" : "An online version of the ridge regression algorithm in the worst-case setting was proposed and analyzed by Foster [18].",
      "startOffset" : 114,
      "endOffset" : 118
    }, {
      "referenceID" : 18,
      "context" : "A related algorithm called Aggregating Algorithm (AA) was studied by Vovk [20], and later applied to the problem of linear regression with square loss [36].",
      "startOffset" : 74,
      "endOffset" : 78
    }, {
      "referenceID" : 34,
      "context" : "A related algorithm called Aggregating Algorithm (AA) was studied by Vovk [20], and later applied to the problem of linear regression with square loss [36].",
      "startOffset" : 151,
      "endOffset" : 155
    }, {
      "referenceID" : 19,
      "context" : "The recursive least squares (RLS) [21] is a similar algorithm proposed for adaptive filtering.",
      "startOffset" : 34,
      "endOffset" : 38
    }, {
      "referenceID" : 15,
      "context" : "The derivation of our algorithm shares similarities with the work of Forster [17] and the work of Moroshko and Crammer [29].",
      "startOffset" : 77,
      "endOffset" : 81
    }, {
      "referenceID" : 27,
      "context" : "The derivation of our algorithm shares similarities with the work of Forster [17] and the work of Moroshko and Crammer [29].",
      "startOffset" : 119,
      "endOffset" : 123
    }, {
      "referenceID" : 15,
      "context" : "While the algorithms of Forster [17] and Moroshko and Crammer [29] are designed for the stationary setting, our work is primarily designed for the nonstationary setting.",
      "startOffset" : 32,
      "endOffset" : 36
    }, {
      "referenceID" : 27,
      "context" : "While the algorithms of Forster [17] and Moroshko and Crammer [29] are designed for the stationary setting, our work is primarily designed for the nonstationary setting.",
      "startOffset" : 62,
      "endOffset" : 66
    }, {
      "referenceID" : 27,
      "context" : "Moroshko and Crammer [29] also discussed a weak variant of the non-stationary setting, where the complexity is measured by the total distance from a reference vector ū, rather than the total distance of consecutive vectors (as in this paper), which is more relevant to non-stationary problems.",
      "startOffset" : 21,
      "endOffset" : 25
    }, {
      "referenceID" : 27,
      "context" : "Note also that Moroshko and Crammer [29] did not derive algorithms for the nonstationary setting, but just show a bound of the weighted min-max algorithm (designed for the stationary setting) in the weak non-stationary setting.",
      "startOffset" : 36,
      "endOffset" : 40
    }, {
      "referenceID" : 33,
      "context" : "Our work is mostly close to a recent algorithm [35] called ARCOR.",
      "startOffset" : 47,
      "endOffset" : 51
    }, {
      "referenceID" : 9,
      "context" : "The Covariance Reset RLS algorithm (CR-RLS) [11, 30, 19] is another example of an algorithm that resets a covariance matrix but every fixed amount of data points, as opposed to ARCOR that performs these resets adaptively.",
      "startOffset" : 44,
      "endOffset" : 56
    }, {
      "referenceID" : 28,
      "context" : "The Covariance Reset RLS algorithm (CR-RLS) [11, 30, 19] is another example of an algorithm that resets a covariance matrix but every fixed amount of data points, as opposed to ARCOR that performs these resets adaptively.",
      "startOffset" : 44,
      "endOffset" : 56
    }, {
      "referenceID" : 17,
      "context" : "The Covariance Reset RLS algorithm (CR-RLS) [11, 30, 19] is another example of an algorithm that resets a covariance matrix but every fixed amount of data points, as opposed to ARCOR that performs these resets adaptively.",
      "startOffset" : 44,
      "endOffset" : 56
    }, {
      "referenceID" : 21,
      "context" : "The Kalman filter [23] and the H∞ algorithm (e.",
      "startOffset" : 18,
      "endOffset" : 22
    }, {
      "referenceID" : 31,
      "context" : "[33]) designed for filtering take a similar approach, yet the exact algebraic form is different (Fig.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 20,
      "context" : "ARCOR also controls explicitly the norm of the weight vector, which is used for its analysis, by projecting it into a bounded set, as was also proposed by Herbster and Warmuth [22].",
      "startOffset" : 176,
      "endOffset" : 180
    }, {
      "referenceID" : 23,
      "context" : "Other approaches to control its norm are to shrink it multiplicatively [25] or by removing old examples [7].",
      "startOffset" : 71,
      "endOffset" : 75
    }, {
      "referenceID" : 5,
      "context" : "Other approaches to control its norm are to shrink it multiplicatively [25] or by removing old examples [7].",
      "startOffset" : 104,
      "endOffset" : 107
    }, {
      "referenceID" : 11,
      "context" : "[13, 15]).",
      "startOffset" : 0,
      "endOffset" : 8
    }, {
      "referenceID" : 13,
      "context" : "[13, 15]).",
      "startOffset" : 0,
      "endOffset" : 8
    }, {
      "referenceID" : 7,
      "context" : "Finally, few algorithms that employ second order information were recently proposed for classification [9, 14, 12], and later in the online convex programming framework [16, 28].",
      "startOffset" : 103,
      "endOffset" : 114
    }, {
      "referenceID" : 12,
      "context" : "Finally, few algorithms that employ second order information were recently proposed for classification [9, 14, 12], and later in the online convex programming framework [16, 28].",
      "startOffset" : 103,
      "endOffset" : 114
    }, {
      "referenceID" : 10,
      "context" : "Finally, few algorithms that employ second order information were recently proposed for classification [9, 14, 12], and later in the online convex programming framework [16, 28].",
      "startOffset" : 103,
      "endOffset" : 114
    }, {
      "referenceID" : 14,
      "context" : "Finally, few algorithms that employ second order information were recently proposed for classification [9, 14, 12], and later in the online convex programming framework [16, 28].",
      "startOffset" : 169,
      "endOffset" : 177
    }, {
      "referenceID" : 26,
      "context" : "Finally, few algorithms that employ second order information were recently proposed for classification [9, 14, 12], and later in the online convex programming framework [16, 28].",
      "startOffset" : 169,
      "endOffset" : 177
    } ],
    "year" : 2013,
    "abstractText" : "The goal of a learner in standard online learning is to maintain an average loss close to the loss of the best-performing single function in some class. In many real-world problems, such as rating or ranking items, there is no single best target function during the runtime of the algorithm, instead the best (local) target function is drifting over time. We develop a novel last-step minmax optimal algorithm in context of a drift. We analyze the algorithm in the worst-case regret framework and show that it maintains an average loss close to that of the best slowly changing sequence of linear functions, as long as the total of drift is sublinear. In some situations, our bound improves over existing bounds, and additionally the algorithm suffers logarithmic regret when there is no drift. We also build on the H∞ filter and its bound, and develop and analyze a second algorithm for drifting setting. Synthetic simulations demonstrate the advantages of our algorithms in a worst-case constant drift setting.",
    "creator" : "LaTeX with hyperref package"
  }
}