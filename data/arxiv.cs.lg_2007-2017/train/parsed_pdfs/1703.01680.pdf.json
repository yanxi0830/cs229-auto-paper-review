{
  "name" : "1703.01680.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "Multi-Objective Non-parametric Sequential Prediction",
    "authors" : [ "Guy Uziel" ],
    "emails" : [ ],
    "sections" : [ {
      "heading" : null,
      "text" : "ar X\niv :1\n70 3.\n01 68\n0v 3\n[ cs\n.L G\nOnline-learning research has mainly been focusing on minimizing one objective function. In many real-world applications, however, several objective functions have to be considered simultaneously. Recently, an algorithm for dealing with several objective functions in the i.i.d. case has been presented. In this paper, we extend the multi-objective framework to the case of stationary and ergodic processes, thus allowing dependencies among observations. We first identify an asymptomatic lower bound for any prediction strategy and then present an algorithm whose predictions achieve the optimal solution while fulfilling any continuous and convex constraining criterion."
    }, {
      "heading" : "1 Introduction",
      "text" : "In the traditional online learning setting, and in particular in sequential prediction under uncertainty, the learner is evaluated by a single loss function that is not completely known at each iteration [9]. When dealing with multiple objectives, since it is impossible to simultaneously minimize all of the objectives, one objective is chosen as the main function to minimize, leaving the others to be bound by pre-defined thresholds. Methods for dealing with one objective function can be transformed to deal with several objective functions by giving each objective a pre-defined weight. The difficulty, however, lies in assigning an appropriate weight to each objective in order to keep the objectives below a given threshold. This approach is very problematic in real world applications, where the player is required to to satisfy certain constraints. For example, in online portfolio selection [16, 7], the player may want to maximize wealth while keeping the risk (i.e., variance) contained below a certain threshold. Another example is the Neyman-Pearson (NP) classification paradigm (see, e.g., [22]) (which extends the objective in classical binary classification) where the goal is to learn a classifier achieving low type II error whose type I error is kept below a given threshold.\nRecently, [19] presented an algorithm for dealing with the case of one main objective and fully-known constraints. In a subsequent work, [20] proposed a framework for\ndealing with multiple objectives in the stochastic i.i.d. case, where the learner does not have full information about the objective functions. They proved that if there exists a solution that minimizes the main objective function while keeping the other objectives below given thresholds, then their algorithm will converge to the optimal solution.\nIn this work, we study online prediction with multiple objectives but now consider the challenging general case where the unknown underlying process is stationary and ergodic, thus allowing observations to depend on each other arbitrarily. We consider a non-parametric approach, which has been applied successfully in various application domains. For example, in online portfolio selection, [14, 12], [13], and [17] proposed non-parametric online strategies that guarantee, under mild conditions, the best possible outcome. Another interesting example in this regard is the work on time-series prediction by [5], [11], and [6]. A common theme to all these results is that the asymptotically optimal strategies are constructed by combining the predictions of many simple experts. The algorithm presented in this paper utilizes as a sub-routine the Weak Aggregating Algorithm of [24], and [15] to handle multiple objectives. While we discuss here the case of only two objective functions, our theorems can be extended easily to any fixed number of functions.\nOutline The paper is organized as follows: In Section 2, we define themulti-objective optimization framework under a jointly stationary and ergodic process. In Section 3, we identify an asymptotic lower-bound for any prediction strategy. In Section 4, we present Algorithm 1, which asymptotically achieves an optimal feasible solution."
    }, {
      "heading" : "2 Problem Formulation",
      "text" : "We consider the following prediction game. Let X , [−D,D]d ⊂ Rd be a compact observation space where D > 0. At each round, n = 1, 2, . . ., the player is required to make a prediction yn ∈ Y , where Y ⊂ Rm is a compact and convex set, based on past observations, Xn−11 , (x1, . . . , xn−1) and, xi ∈ X (X01 is the empty observation). After making the prediction yn, the observation xn is revealed and the player suffers two losses, u(yn, xn) and c(yn, xn), where u and c are real-valued continuous functions and convex w.r.t. their first argument. We view the player’s prediction strategy as a sequence S , {Sn}∞n=1 of forecasting functions Sn : X (n−1) → Y; that is, the player’s prediction at round n is given by Sn(X n−1 1 ). Throughout the paper we assume that x1, x2, . . . are realizations of random variables X1, X2, . . . such that the stochastic process (Xn) ∞ −∞ is jointly stationary and ergodic and P(Xi ∈ X ) = 1. The player’s goal is to play the game with a strategy that minimizes the average u-loss, 1 N ∑N i=1 u(S(X i−1 1 ), xi), while keeping the average c-loss 1 N ∑N i=1 c(S(X i−1 1 ), xi) bounded below a prescribed threshold γ. Formally, we define the following:\nDefinition 1 (γ-boundedness). A prediction strategy S will be called γ-bounded if\nlim sup N→∞\n(\n1\nN\nN ∑\ni=1\nc(Si(X i−1 1 ), Xi)\n)\n≤ γ\nalmost surely. The set of all γ-bounded strategies will be denoted Sγ .\nDefinition 2 (γ-feasible process). We say that the stationary and ergodic process {Xi}∞−∞ is γ-feasible w.r.t. the functions u and c, if for P∞, the regular conditional probability distribution of X0 given F∞ (the σ-algebra generated by the infinite past X−1, X−2, . . .), and for a threshold γ > 0, if there exists some y\n′ ∈ Y such that EP∞ [c(y ′, X0)] < γ.\nIf γ-feasibility holds, then we will denote by y∗∞ (y ∗ ∞ is not necessarily unique) the\nsolution to the following minimization problem:\nminimize y∈Y EP∞ [u(y,X0)] subject to EP∞ [c(y,X0)] ≤ γ, (1)\n(1) and we define the γ-feasible optimal value as\nV∗ = E [EP∞ [u(y∗∞, X0)]] a.s.\nNote that problem (1) is a convex minimization problem over Y , which in turn is a compact and convex subset of Rm. Therefore, the problem is equivalent to finding the saddle point of the Lagrangian function [3], namely,\nmin y∈Y max λ∈R+\nL(y, λ),\nwhere the Lagrangian is\nL(y, λ) , (EP∞ [u(y,X0)] + λ (EP∞ [c(y,X0)]− γ)) .\nWe denote the optimal dual by λ∗∞ and assume that λ ∗ ∞ is unique. Moreover, we set a constant 1 λmax such that λmax > λ ∗ ∞, and set Λ , [0, λmax]. We also define the instantaneous Lagrangian function as\nl(y, λ, x) , u(y, x) + λ (c(y, x)− γ) . (2)\nIn Brief, we are seeking a strategy S ∈ Sγ that is as good as any other γ-bounded strategy, in terms of the average u-loss, when the underlying process is γ-feasible. Such a strategy will be called γ-universal."
    }, {
      "heading" : "3 Optimallity of V∗",
      "text" : "In this section, we prove that the average u-loss of any γ-bounded prediction strategy cannot be smaller than V∗, the γ-feasible optimal value. This result is a generalization of the well-known result of [1] regarding the best possible outcome under a single objective. Before stating and proving this optimallity result, we state one known lemma and state and prove two lemmas that will be used repeatedly in this paper. The first lemma is known as Breiman’s generalized ergodic theorem. The second and the third lemmas concern the continuity of the saddle point w.r.t. the probability distribution.\n1This can be done, for example, by imposing some regularity conditions on the constraint function (see,\ne.g., [20]).\nLemma 1 (Ergodicity, [8]). Let X = {Xi}∞−∞ be a stationary and ergodic process. For each positive integer i, let Ti denote the operator that shifts any sequence by i places to the left. Let f1, f2, . . . be a sequence of real-valued functions such that limn→∞ fn(X) = f(X) almost surely, for some function f . Assume thatE supn |fn(X)| < ∞. Then,\nlim n→∞\n1\nn\nn ∑\ni=1\nfi(T i X) = Ef(X)\nalmost surely.\nLemma 2 (Continuity andMinimax). LetY,Λ,X be compact real spaces. l : Y ×Λ×X → R be a continuous function. Denote by P(X ) the space of all probability measures on X (equipped with the topology of weak-convergence). Then the following function L∗ : P(X ) → R is continuous\nL∗(Q) = inf y∈Y sup λ∈Λ EQ [l(y, λ, x)] . (3)\nMoreover, for any Q ∈ P(X ),\ninf y∈Y sup λ∈Λ EQ [l(y, λ, x)] = sup λ∈Λ inf y∈Y EQ [l(y, λ, x)] .\nProof. Y,Λ,X are compact, implying that the function l (y, λ, x) is bounded. Therefore, the function L : Y × Λ × P(X ) → R, defined as\nL (y, λ,Q) = EQ [l (y, λ, x)] , (4)\nis continuous. By applying Proposition 7.32 from [4], we have that supλ∈Λ EQ [l(y, λ,X)] is continuous inQ×Y . Again applying the same proposition, we get the desired result. The last part of the lemma follows directly from Fan’s minimax theorem [10].\nLemma 3 (Continuity of the optimal selection). Let Y,Λ,X be compact real spaces, and let L be as defined in Equation (4). Then, there exist two measurable selection functions hX ,hλ such that\nhy(Q) ∈ argmin y∈Y\n(\nmax λ∈Λ L(y, λ,Q)\n)\n,\nhλ(Q) ∈ argmax λ∈Λ\n(\nmin y∈Y L(y, λ,Q)\n)\nfor any Q ∈ P(X ). Moreover, let L∗ be as defined in Equation (3). Then, the set\nGr(L∗) , {(u∗, v∗,Q) | u∗ ∈ hy(Q), v∗ ∈ hλ(Q),Q ∈ P(X )},\nis closed in Y × Λ× P(X ).\nProof. The first part of the proof follows immediately from the minimax measurable theorem of [21] due to the compactness of Y,Λ,X and the properties of the loss function L. The proof of the second part is similar to the one presented in Theorem 3 of [2]. In order to show that Gr(L∗) is closed, it is enough to show that if (i) Qn → Q∞ in P(X ); (ii) un → u∞ in Y; (iii) vn → v∞ in Λ and (iv) un ∈ hy(Qn), vn ∈ hλ(Qn) for all n, then,\nu∞ ∈ hy(Q∞), v∞ ∈ hλ(Q∞).\nThe function L(y, λ,Q), as defined in Equation (4), is continuous. Therefore,\nlim n→∞ L(un, vn,Qn) = L(u∞, v∞,Q∞).\nIt remains to show that u∞ ∈ hy(Q∞) and v∞ ∈ hλ(Q∞). From the optimality of un and vn, we obtain\nL(u∞, v∞,Q∞) = lim n→∞ L(un, vn,Qn) = lim n→∞\nL∗(Qn). (5)\nFinally, from the continuity of L∗ (Lemma 2), we get\n(5) = L∗( lim n→∞ Qn) = L ∗(Q∞),\nwhich gives the desired result.\nCorollary 1. Under the conditions of Lemma 3. Define Ln(y, λ,Q) = L(y, λ,Q) + ||y||2−||λ||2\nn and denote hyLn(Qn), h λ Ln (Qn) to be the measurable selection functions of\nLn. If Qn → Q∞ weakly in P(X ) and un ∈ hyLn(Qn), vn ∈ hλLn(Qn), then\nLn(un, vn,Qn) → L(u∞, v∞,Q∞)\nalmost surely for u∞ ∈ hy(Q∞) and v∞ ∈ hλ(Q∞). Proof. Denote ûn ∈ hy(Q∞) and v̂n ∈ hλ(Q∞)\n|Ln(un, vn,Qn)− L(u∞, v∞,Q∞)| ≤ |Ln(un, vn,Qn)− L(ûn, v̂n,Qn)|+ |L(ûn, v̂n,Qn)− L(u∞, v∞,Q∞)|. (6)\nNote that for every n and for constant E > 0,\nmin y∈Y max λ∈Λ\nL(y, λ,Q)− ||λmax|| 2\nn ≤ min y∈Y max λ∈Λ Ln(y, λ,Q)\n= min y∈Y max λ∈Λ\n(\nEQ [l(y, λ,X)] + ||y||2 − ||λ||2\nn\n)\n≤ min y∈Y max λ∈Λ\nL(y, λ,Q) + E\nn .\nThus, for some constantC, |Ln(un, vn,Qn)−L(u∞, v∞,Q∞)| < Cn and fromLemma 3, the last summand also converges to 0 as n approaches∞, we get the desired result, and clearly, if hy(Q∞) and h\nλ(Q∞) are singletons, then, the only accumulation point of {(vn, un)}∞n=1 is (v∞, u∞).\nThe importance of Lemma 3 stems from the fact that it proves the continuity properties of the multi-valued correspondences Q → hy(Q) and Q → hλ(Q). This leads to the knowledge that if for the limiting distribution,Q∞, the optimal set is a singleton, then Q → hy(Q) and Q → hλ(Q) are continuous in Q∞. We are now ready to prove the optimality of V∗.\nTheorem 1 (Optimality of V∗). Let {Xi}∞−∞ be a γ-feasible process. Then, for any strategy S ∈ Sγ , the following holds a.s.\nlim inf N→∞\n1\nN\nN ∑\ni=1\nu(S(X i−11 ), Xi) ≥ V∗.\nProof. For any given strategy S ∈ Sγ , we will look at the following sequence:\n1\nN\nN ∑\ni=1\nl(S(X i−11 ), λ̃ ∗ i , Xi). (7)\nwhere λ̃∗i ∈ hλ(PXi|Xi−11 ) Observe that\n(7) = 1\nN\nN ∑\ni=1\nE\n[\nl(S(X i−11 ), λ̃ ∗ i , Xi) | X i−11\n] − 1 N\nN ∑\ni=1\n(l(S(X i−11 ), λ̃ ∗ i , Xi)\n−E [\nl(S(X i−11 ), λ̃ ∗ i , X) | X i−11\n]\n).\nSince Ai = l(S(X i−1 1 ), λ̃ ∗ i , Xi)−E\n[\nl(S(X i−11 ), λ̃ ∗ i , Xi) | X i−11\n]\nis a martingale dif-\nference sequence, the last summand converges to 0 a.s., by the strong law of large numbers (see, e.g., [23]). Therefore,\nlim inf N→∞\n1\nN\nN ∑\ni=1\nl(S(X i−11 ), λ̃ ∗ i , Xi) = lim inf\nN→∞\n1\nN\nN ∑\ni=1\nE\n[\nl(S(X i−11 ), λ̃ ∗ i , Xi) | X i−11\n]\n≥ lim inf N→∞\n1\nN\nN ∑\ni=1\nmin y∈Y() E\n[ l(y, λ̃∗i , Xi) | X i−11 ] , (8)\nwhere the minimum is taken w.r.t. all the σ(X i−11 )-measurable functions. Because the process is stationary, we get for λ̂∗i ∈ hλ(PX0|X−11−i),\n(8) = lim inf N→∞\n1\nN\nN ∑\ni=1\nmin y∈Y() E\n[ l(y, λ̂∗i , X0) | X−11−i ]\n(9)\n= lim inf N→∞\n1\nN\nN ∑\ni=1\nL∗(PX0|X−11−i ). (10)\nUsing Levy’s zero-one law, PX0|X−11−i → P∞ weakly as i approaches ∞ and from Lemma 2 we know that L∗ is continuous. Therefore, we can apply Lemma 1 and get\nthat a.s.\n(10) = E [L∗(P∞)] = E [EP∞ [l (y ∗ ∞, λ ∗ ∞, X0)]] = E [L (y∗∞, λ∗∞, X0)] . (11)\nNote also, that due to the complementary slackness condition of the optimal solution, i.e., λ∗∞(EP∞ [c(y ∗ ∞, X0)]− γ) = 0, we get\n(11) = E [EP∞ [u (y ∗ ∞, X0)]] = V∗.\nFrom the uniqueness of λ∗∞, and using Lemma 3 λ̂ ∗ i → λ∗∞ as i approaches∞. Moreover, since l is continuous on a compact set, l is also uniformly continuous. Therefore, for any given ǫ > 0, there exists δ > 0, such that if |λ′ − λ| < δ, then\n|l(y, λ′, x)− l(y, λ, x)| < ǫ\nfor any y ∈ Y and x ∈ X . Therefore, there exists i0 such that if i > i0 then |l(y, λ̂∗i , x)− l(y, λ∗∞, x)| < ǫ for any y ∈ Y and x ∈ X . Thus,\nlim inf N→∞\n1\nN\nN ∑\ni=1\nl(S(X i−11 ), λ ∗ ∞, Xi)− lim inf\nN→∞\n1\nN\nN ∑\ni=1\nl(S(X i−11 ), λ̂ ∗ i , Xi)\n= lim inf N→∞\n1\nN\nN ∑\ni=1\nl(S(X i−11 ), λ ∗ ∞, Xi) + lim sup\nN→∞\n1\nN\nN ∑\ni=1\n−l(S(X i−11 ), λ̂∗i , Xi)\n≥ lim inf N→∞\n1\nN\nN ∑\ni=1\nl(S(X i−11 ), λ̂ ∗ i , Xi)−\n1\nN\nN ∑\ni=1\nl(S(X i−11 ), λ ∗ ∞, Xi) ≥ −ǫ a.s.,\nand since ǫ is arbitrary,\nlim inf N→∞\n1\nN\nN ∑\ni=1\nl(S(X i−11 ), λ ∗ ∞, Xi) ≥ lim inf\nN→∞\n1\nN\nN ∑\ni=1\nl(S(X i−11 ), λ̂ ∗ i , Xi).\nTherefore we can conclude that\nlim inf N→∞\n1\nN\nN ∑\ni=1\nl(S(X i−11 ), λ ∗ ∞, Xi) ≥ V∗ a.s.\nWe finish the proof by noticing that since S ∈ Sγ , then by definition\nlim sup N→∞\n1\nN\nN ∑\ni=1\nc(S(X i−11 ), Xi) ≤ γ a.s.\nand since λ∗∞ is non negative, we will get the desired result.\nThe above lemma also provides the motivation to find the saddle point of the Lagrangian L. Therefore, for the reminder of the paper we will use the loss function l as defined in Equation 2.\nAlgorithm 1 Minimax Histogram Based Aggregation (MHA)\nInput: Countable set of experts {Hk,h} , y0 ∈ Y λ0 ∈ Λ, initial probability {αk,h}, For n = 0 to∞ Play yn, λn. Nature reveals xn Suffer loss l(yn, λn, xn). Update the cumulative loss of the experts\nlk,hy,n ,\nn ∑\ni=0\nl(yik,h, λi, xi) l k,h λ,n ,\nn ∑\ni=0\nl(yi, λ i k,h, xi)\nUpdate experts’ weights\nwy,(k,h)n , αk,h exp\n(\n− 1√ n lk,hy,n\n)\np y,(k,h) n+1 ,\nw y,(k,h) n+1\n∑∞ h=1 ∑∞ k=1 w y,(k,h) n+1\nUpdate experts’ weights w λ,(k,h) n+1\nw λ,(k,h) n+1 , αk,h exp\n(\n1√ n lk,hλ,n\n)\np λ,(k,h) n+1 =\nw λ,(k,h) n+1\n∑∞ h=1 ∑∞ k=1 w λ,(k,h) n+1\nChoose yn+1 and λn+1 as follows\nyn+1 = ∑\nk,h\np y,(k,h) n+1 y n+1 k,h λn+1 =\n∑\nk,h\np λ,(k,h) n+1 λ n+1 k,h\nEnd For"
    }, {
      "heading" : "4 Minimax Histogram Based Aggregation",
      "text" : "We are now ready to present our algorithmMinimax Histogram based Aggregation (MHA) and prove that its predictions are as good as the best strategy. By Theorem 1 we can restate our goal: find a prediction strategy S ∈ Sγ such that for any γ-feasible process {Xi}∞−∞ the following holds:\nlim N→∞\n1\nN\nN ∑\ni=1\nu(S(X i−11 ), Xi) = V∗ a.s.\nSuch a strategy will be called γ-universal. We do so by maintaining a countable set of\nexperts {Hk,h}, where an expertHk,l will output a pair (yik,l, λik,l) ∈ Y×Λ at round i. Our algorithm outputs at round i a pair (yi, λi) ∈ Y ×Λ where the sequence of predictions y1, y2, . . . tries to minimize the average loss 1 N ∑N i=1 l(y, λi, xi) and the sequence of predictions λ1, λ2, . . . tries to maximize the average loss 1 N ∑N i=1 l(yi, λ, xi). Each of yi and λi is the aggregation of predictions y i k,l and λ i k,l, k, l = 1, 2, . . . , respectively. In order to ensure that the performance of MHA will be as good as any other expert for both the y and the λ predictions, we apply the Weak Aggregating Algorithm of [24], and [15] twice simultaneously. In Theorem 2 we prove that there exists a countable set of experts whose selection of points converges to the optimal solution. Then, in Theorem 3 we prove that MHA applied on the experts defined in Theorem 2 generates a sequence of predictions that is γ-bounded and as good as any other strategy w.r.t. any γ-feasible process.\nTheorem 2. Assume that {Xi}∞−∞ is a γ-feasible process. Then, it is possible to construct a countable set of experts {Hk,h} for which\nlim k→∞ lim h→∞ lim n→∞\n1\nN\nN ∑\ni=1\nl(yik,h, λ i k,h, Xi) = V∗ a.s.,\nwhere (yik,h, λ i k,h) are the predictions made by expert Hk,h at round i. Proof. We start by defining a countable set of experts {Hk,h} as follow: For h = 1, 2, . . ., let Ph = {Ah,j | j = 1, 2, ...,mh} be a sequence of finite partitions of X such that: (i) any cell of Ph+1 is a subset of a cell of Ph for any h. Namely, Ph+1 is a refinement of Ph; (ii) for a set A, if diam(A) = supx,y∈A ||x − y|| denotes the diameter of A, then for any sphere B centered at the origin,\nlim h→∞ max j:Ah,j∩B 6=∅ diam(Ah,j) = 0.\nDefine the corresponding quantizer qh(x) = j, if x ∈ Ah,j . Thus, for any n and Xn1 , we define Qh(X n 1 ) as the sequence qh(x1), . . . , qh(xn). For expert Hk,h, we define for k > 0, a k-long string of positive integers, denoted by w, the following set,\nB w,(1,n−1) k,h , {xi | k < i < n, Qh(X i−1i−k) = w}.\nWe define also\nhyk,h(X n−1 1 , w) , argmin\ny∈Y\n\n  max λ∈Λ\n1\n|Bw,(1,n−1)k,h |\n∑\nxi∈B w,(1,n−1) k,h\nlk,l,n(y, λ, xi)\n\n \nhλk,h(X n−1 1 , w) , argmax\nλ∈Λ\n\n  min y∈Y\n1\n|Bw,(1,n−1)k,h |\n∑\nxi∈B w,(1,n−1) k,h\nlk,l,n(y, λ, xi)\n\n \nfor\nlk,h,n(y, λ, x) , l(y, λ, x) + ( ||y||2 − ||λ||2 )\n(\n1 n + 1 h + 1 k\n)\nand we will set hyk,h(X n−1 1 , w) = y0 and h λ k,h(X n−1 1 , w) = λ0 for arbitrary (y0, λ0) ∈ Y × Λ if Bw,(1,n−1)k,h is empty. Using the above, we define the predictions of Hk,h to be:\nHyk,h(X n−1 1 ) = h y k,h(X n−1 1 , Q(X n−1 n−k)), n = 1, 2, 3.... Hλk,h(X n−1 1 ) = h λ k,h(X n−1 1 , Q(X n−1 n−k)), n = 1, 2, 3....\nWewill add two experts: H0,0 whose predictions are always (y0, λmax) andH−1,−1 whose predictions are always (y0, 0).\nFixing k, h > 0 andw, we will define a (random)measureP (k.h) j,w that is the measure\nconcentrated on the set B w,(0,1−j) k,h , defined by\nP (k,h) j,w (A) =\n∑\nXi∈B w,(0,1−j) k,h\n1A(Xi)\n|Bw,(0,1−j)k,h | ,\nwhere 1A denotes the indicator function of the set A ⊂ X . If the above set Bwk,h is empty, then let P\n(k,h) j,w (A) = δ(x ′) be the probability measure concentrated on arbitrary vector x′ ∈ X .\nIn other words, P (k.h) j,w (A) is the relative frequency of the the vectors amongX1−j+k, . . . , X0\nthat fall in the set A. Applying Lemma 1 twice, it is straightforward to prove that for all w, w.p. 1\nP (k,h) j,w →\n{\nPX0|Gl(X−1 −k\n)=w P(Gl(X −1 −k) = w) > 0\nδ(x′) otherwise\nweakly as j → ∞, where PX0|Gl(X−1 −k )=w denotes the distribution of the vector X0 conditioned on the event Gl(X −1 −k) = w. To see this, let f be a bounded continuous function. Then,\n∫\nf(x)P (k,h) j,w (dx) =\n1 |1−j+k|\n∑\nXi∈B w,(0,1−j) k,h\nf(Xi)\n1 |1−j+k| |B w,(0,1−j) k,h |\n→ E\n[\nf(X0)1Gl(X−1 −k\n)=w(X0) ]\nP(Gl(X −1 −k) = w)\n= E [ f(X0) | Gl(X−1−k) = w ] ,\nand in case P(||X−1−k − s|| ≤ c/l) = 0, then w.p. 1, P (k,h) j,w is concentrated on x ′ for all j. We will denote the limit distribution of P (k,h) j,w by P ∗(k,h) w .\nBy definition, (\nhyk,h(X −1 1−n, w), h λ k,h(X −1 1−n, w)\n)\nis the minimax of ln,k,h w.r.t.\nP (k,h) j,w . The sequence of functions ln,k,h converges uniformly as n approaches∞ to\nlk,h(y, λ, x) = l(y, λ, x) + ( ||y||2 − ||λ||2 )\n(\n1 h + 1 k\n)\n.\nNote also that for any fixed Q, Lk,h(y, λ,Q) = EQ [lk,h(y, λ,X)] is strictly convex in y and strictly concave in λ, and therefore, has a unique saddle-point (see, e.g., [18]). Therefore, since w is arbitrary, and following a Corollary 1 of Lemma 3, we get that a.s.\nynk,h → y∗k,h λnk,h → λ∗k,h,\nwhere (\ny∗k,h, λ ∗ k,h\n)\nis the minimax of Lk,h w.r.t. P ∗(k,h)\nX −1 −k\n. Thus, we can apply Lemma 1\nand conclude that as N approaches∞,\n1\nN\nN ∑\ni=1\nl(yik,h, λ i k,h, Xi) → E\n[\nl(y∗k,h, λ ∗ k,h, X0)\n]\n.\na.s.. We now evaluate\nlim h→∞\nE [ l(y∗k,h, λ ∗ k,h, X0) ] .\nUsing the properties of the partition Ph (see, e.g., [11, 13]), we get that\nP ∗(k,h)\nX −1 −k → P{X0|X−1 −k}\nweakly as h → ∞. Moreover, the sequence of functions lk,h converges uniformly as h approaches∞\nlk(y, λ, x) = l(y, λ, x) + ||y||2 − ||λ||2\nk .\nNote also, that for any fixed Q, Lk(y, λ,Q) = EQ [lk(y, λ,X)] is strictly convexconcave, and therefore, has a unique saddle point. Accordingly, by applying Corollary 1 again, we get that a.s.\ny∗k,h → y∗k λ∗k,h → λ∗k,\nwhere (y∗k, λ ∗ k) is the minimax of Lk w.r.t. P{X0|X−1 −k}. Therefore, as h approaches∞,\nl(y∗k,h, λ ∗ k,h, X0) → l (y∗k, λ∗k, X0)\na.s.. Thus, by Lebesgue’s dominated convergence,\nlim h→∞\nE [ l(y∗k,h, λ ∗ k,h, X0) ] = E [l (y∗k, λ ∗ k, X0)] .\nNotice that for anyQ ∈ P(X ), the distance between the saddle point of Lk w.r.t. Q and the the saddle point of L w.r.t. Q converges to 0 as k approaches∞. To see this, notice that\nmin y∈Y max λ∈Λ\nL(y, λ,Q)− ||λmax|| 2\nk ≤ min y∈Y max λ∈Λ Lk(y, λ,Q)\n≤ min y∈Y max λ∈Λ\nL(y, λ,Q) + E\nk\nfor some constant E, since Y is bounded. The last part in our proof will be to show that if (ŷ∗k, λ̂ ∗ k) is the minimax of L w.r.t. P{X0|X−1 −k}, then as k approaches ∞,\nE\n[ l (\nŷ∗k, λ̂ ∗ k, X0\n)]\nwill converge a.s. to V∗ and so E [l (y∗k, λ∗k, X0)]. To show this, we will use the sub-martingale convergence theorem twice. First, we\ndefine Zk as\nZk , min y∈Y() E\n[\nmax λ∈Λ()\nE [ l (y, λ,X0) | X−1−∞ ] | X−1−k ] ,\nwhere the minimum is taken w.r.t. all σ(X−1−k)-measurable strategies and the maximum is taken w.r.t. all σ(X−1−∞)-measurable strategies. Notice that Zk is a super-martingale. We can see this by using the tower property of conditional expectations,\nE[Zk+1 | X−1−k ] = E [ E [ Zk+1 | X−1−k−1 ] | X−1−k ]\nand since Zk+1 is the optimal choice in Y w.r.t. to X−1−k−1,\n≤ E [ E[Zk | X−1−k−1] | X−1−k ] = E[Zk | X−1−k ] = Zk.\nNote also that E[Zk] is uniformly bounded. Therefore, we can apply the supermartingale convergence theorem and get that Zk → Z∞ a.s., where,\nZ∞ = E [ l(y∗∞, λ ∗ ∞, X0) | X−1−∞ ] = V∗,\nand by using Lebesgue’s dominated convergence theorem, alsoE[Zk] → E[Z∞] = V∗. Using the same arguments, Z ′k, defined as\nZ ′k , max λ∈Λ() E\n[\nmin y∈Y()\nE [ l (y, λ,X0) | X−1−∞ ] | X−1−k ] ,\nwhere the maximum is taken w.r.t. all σ(X−1−k)-measurable strategies and the minimum is taken w.r.t. all σ(X−1−∞)-measurable strategies, is a sub-martingale that also converges a.s. to Z∞ and thus E[Z ′ k] → E[Z∞] = V∗.\nWe conclude the proof by noticing that the following relation holds for any k,\nE[Z ′k] = E\n[\nmax λ∈Λ() E\n[\nmin y∈Y()\nE [ l (y, λ,X0) | X−1−∞ ] | X−1−k ]]\n≤ E [\nmax λ∈Λ() E\n[\nE\n[ l (\nŷ∗k, λ,X0\n) | X−1−∞ ] | X−1−k ]\n]\n= E\n[\nmax λ∈Λ() E\n[ l (\nŷ∗k, λ,X0\n) | X−1−k ]\n]\n= E [ l (\nŷ∗k, λ̂ ∗ k, X0\n)]\n,\nand using similar arguments we can show that also\nE\n[ l (\nŷ∗k, λ̂ ∗ k, X0\n)]\n≤ E[Zk],\nand since both E[Zk] and E[Z ′ k] converge to V∗, we get the desired result.\nBefore stating the main theorem regarding MHA, we now state and prove the fol-\nlowing lemma, which is used in the proof of the main result regarding MHA.\nLemma 4. Let {Hk,h} be a countable set of experts as defined in the proof of Theorem 2. Then, the following relation holds a.s.:\ninf k,h lim sup n→∞\n1\nN\nN ∑\ni=1\nl ( yik,h, λi, Xi ) ≤ V∗\n≤ sup k,h lim inf n→∞\n1\nN\nN ∑\ni=1\nl ( yi, λ i k,h, Xi ) ,\nwhere (yi, λi) are the predictions of MHA when applied on {Hk,h}. Proof. Set\nf(y,Q) , max λ∈Λ EQ [l (y, λ,X0)] .\nWe will start from the LHS,\ninf k,h lim sup n→∞\n1\nN\nN ∑\ni=1\nl ( yik,h, λi, Xi ) , (12)\nand similarly to Lemma 1, by using the strong law of large numbers we can write\n(12) = inf k,h lim sup n→∞\n1\nN\nN ∑\ni=1\nE [ l ( yik,h, λi, X0 ) | X−11−i ]\n≤ inf k,h lim sup n→∞\n1\nN\nN ∑\ni=1\nf(yik,h,PX0|X−11−i ) a.s. (13)\nFor fixed k, h > 0, from the proof of Theorem (2), yik,h → y∗k,h a.s. as i approaches ∞, and from Levy’s zero-one law also PX0|X−11−i → P∞ weakly. From Lemma 2 we know that f is continuous, therefore, we can apply Lemma 1 and get that\n(13) = inf k,h\nE [ E [ f(y∗k,h,P∞) ]] ≤ lim k→∞ lim l→∞ E [ f(y∗k,h,P∞) ] . (14)\nFrom the uniqueness of the saddle point and from the proof of Theorem (2), for\nfiked k > 0, lim h→∞\ny∗k,h → y∗k a.s.. Thus, from the continuity of f we get that\nlim h→∞\nf(y∗k,h,P∞) → f(y∗k,P∞)\nand again by Lebesgue’s dominated convergence,\n(14) = lim k→∞ E [f(y∗k,P∞)] = lim k→∞ E\n[\nmax λ∈Λ\nEP∞ [l (y ∗ k, λ,X0)]\n]\n. (15)\nNow, from Theorem 2 we know that every accumulation point of the sequence {y∗k} is in the optimal set\nargmin y∈Y\n(\nmax λ∈Λ EP∞ [l (y, λ,X0)]\n)\n.\nTherefore a.s.\nlim k→∞ max λ∈Λ\nEP∞ [l (y ∗ k, λ,X0)] → EP∞ [l (y∗∞, λ∗∞, X0)] ,\nand using Lebesgue’s dominated convergence,\n(15) = E [EP∞ [l (y ∗ ∞, λ ∗ ∞, X0)]] = V∗.\nUsing similar arguments, we can show the second part of the lemma.\nWe are now ready to state and prove the optimality of MHA.\nTheorem 3 (Optimality of MHA). Let (yi, λi) be the predictions generated by MHA when applied on {Hk,h} as defined in the proof of Theorem 2. Then, for any γ-feasible process {Xi}∞−∞: MHA is a γ-bounded and γ-universal strategy.\nProof. We first show that\nlim N→∞\n1\nN\nN ∑\ni=1\nl(yi, λi, Xi) = V∗ a.s. (16)\nApplying Lemma 5 in [15], we know that the x updates guarantee that for every expert Hk,h,\n1\nN\nN ∑\ni=1\nl(yi, λi, xi) ≤ 1\nN\nN ∑\ni=1\nl(yik,h, λi, xi) + Ck,h√ N\n(17)\n1\nN\nN ∑\ni=1\nl(yi, λi, xi) ≥ 1\nN\nN ∑\ni=1\nl(yi, λ i k,h, xi)− C′k,h√ N , (18)\nwhere Ck,h, C ′ k,h > 0 are some constants independent of N . In particular, using\nEquation (17),\n1\nN\nN ∑\ni=1\nl(yi, λi, xi) ≤ inf k,h\n(\n1\nN\nN ∑\ni=1\nl(yik,h, λi, xi) + Ck,h√ N\n)\n.\nTherefore, we get\nlim sup N→∞\n1\nN\nN ∑\ni=1\nl(yi, λi, xi)\n≤ lim sup N→∞ inf k,h\n(\n1\nN\nN ∑\ni=1\nl(yik,h, λi, xi) + Ck,h√ N\n)\n≤ inf k,h lim sup N→∞\n(\n1\nN\nN ∑\ni=1\nl(yik,h, λi, xi) + Ck,h√ N\n)\n≤ inf k,h lim sup N→∞\n(\n1\nN\nN ∑\ni=1\nl(yik,h, λi, xi)\n)\n, (19)\nwhere in the last inequality we used the fact that lim sup is sub-additive. Using Lemma (4), we get that\n(19) ≤ V∗\n≤ sup k,h lim inf n→∞\n1\nN\nN ∑\ni=1\nl ( yi, λ i k,h, Xi ) . (20)\nUsing similar arguments and using Equation (18) we can show that\n(20) ≤ lim inf N→∞\n1\nN\nN ∑\ni=1\nl(yi, λi, xi).\nSummarizing, we have\nlim sup N→∞\n1\nN\nN ∑\ni=1\nl(yi, λi, xi) ≤ V∗ ≤ lim inf N→∞\n1\nN\nN ∑\ni=1\nl(yi, λi, xi).\nTherefore, we can conclude that a.s.\nlim N→∞\n1\nN\nN ∑\ni=1\nl(yi, λi, Xi) = V∗.\nTo show that MHA is indeed a γ-bounded strategy and to shorten the notation, we will denote g(y, λ, x) , λ(c(y, x)− γ). First, from Equation (18) applied on the expertH0,0, we get that:\nlim sup N→∞\n1\nN\nN ∑\ni=1\ng(yi, λmax, x) ≤ lim sup N→∞\n1\nN\nN ∑\ni=1\ng(yi, λi, x). (21)\nMoreover, since l is uniformly continuous, for any given ǫ > 0, there exists δ > 0, such that if |λ′ − λ| < δ, then\n|l(y, λ′, x)− l(y, λ, x)| < ǫ\nfor any y ∈ Y and x ∈ X . We also know that\nlim k→∞ lim h→∞ lim i→∞\nλik,h = λ ∗ ∞.\nTherefore, there exist k0, h0, i0 such that |λik0,h0 − λ∗∞| < δ for any i > i0. Since limk→∞ λ ∗ k = λ ∗ ∞ there exists k0 such that |λ∗k0−λ∗∞| < δ 3 . Note that limh→∞ λ ∗ k0,h = λ∗k0 , so there exists h0 such that |λ∗k0,h0 − λ∗k0 | < δ 3 . Finally, since limi→∞ λ i k0,l0 = λ∗k0,l0 , there exists i0 such that if i > i0, then |λik0,l0 − λ∗k0,l0 | < δ 3 . Combining all the above, we get that for k0, h0, i0 if i > i0, then\n|λik0,h0 − λ ∗ ∞| < |λik0,h0 − λ ∗ k0,h0 |+ |λik0,h0 − λ ∗ k0 |+ |λ∗k0 − λ ∗ ∞| < δ.\nTherefore,\nlim sup N→∞\n(\n1\nN\nN ∑\ni=1\nl(yi, λ ∗ ∞, xi)−\n1\nN\nN ∑\ni=1\nl(yi, λi, xi)\n)\n≤\nlim sup N→∞\n(\n1\nN\nN ∑\ni=1\nl(yi, λ ∗ ∞, xi)−\n1\nN\nN ∑\ni=1\nl(yi, λ i k0,h0 , xi)\n)\n+\nlim sup N→∞\n(\n1\nN\nN ∑\ni=1\nl(yi, λ i k0,h0 , xi)− 1\nN\nN ∑\ni=1\nl(yi, λi, xi)\n)\n(22)\nFrom the uniform continuity we also learn that the first summand is bounded above by ǫ, and from Equation (18), we get that the last summand is bounded above by 0. Thus,\n(22) ≤ ǫ,\nand since ǫ is arbitrary, we get that\nlim sup N→∞\n(\n1\nN\nN ∑\ni=1\nl(yi, λ ∗ ∞, xi)−\n1\nN\nN ∑\ni=1\nl(yi, λi, xi)\n)\n≤ 0.\nThus,\nlim sup N→∞\n1\nN\nN ∑\ni=1\nl(yi, λ ∗ ∞, Xi) ≤ V∗,\nand from Theorem 1 we can conclude that\nlim N→∞\n1\nN\nN ∑\ni=1\nl(yi, λ ∗ ∞, Xi) = V∗.\nTherefore, we can deduce that\nlim sup N→∞\n1\nN\nN ∑\ni=1\ng(yi, λi, xi)− lim sup N→∞\n1\nN\nN ∑\ni=1\ng(yi, λ ∗ ∞, xi) =\nlim sup N→∞\n1\nN\nN ∑\ni=1\ng(yi, λi, xi) + lim inf N→∞\n1\nN\nN ∑\ni=1\n−g(yi, λ∗∞, xi)\n≤ lim sup N→∞\n1\nN\nN ∑\ni=1\ng(yi, λi, xi)− 1\nN\nN ∑\ni=1\ng(yi, λ ∗ ∞, xi)\n= lim sup N→∞\n1\nN\nN ∑\ni=1\nl(yi, λi, xi)− 1\nN\nN ∑\ni=1\nl(yi, λ ∗ ∞, xi) = 0,\nwhich results in\nlim sup N→∞\n1\nN\nN ∑\ni=1\ng(yi, λi, xi) ≤ lim sup N→∞\n1\nN\nN ∑\ni=1\ng(yi, λ ∗ ∞, xi).\nCombining the above with Equation (21), we get that\nlim sup N→∞\n1\nN\nN ∑\ni=1\ng(yi, λmax, xi)\n≤ lim sup N→∞\n1\nN\nN ∑\ni=1\ng(yi, λ ∗ ∞, xi).\nSince 0 ≤ λ∗∞ < λmax, we get that MHA is γ-bounded. This also implies that\nlim sup N→∞\n1\nN\nN ∑\ni=1\nλi(c(yi, xi)− γ) ≤ 0.\nNow, if we apply Equation (18) on the expertH−1,−1, we get that\nlim inf N→∞\n1\nN\nN ∑\ni=1\nλi(c(yi, xi)− γ) ≥ 0.\nThus,\nlim N→∞\n1\nN\nN ∑\ni=1\nλi(c(yi, xi)− γ) = 0,\nand using Equation (16), we get that MHA is also γ-universal."
    }, {
      "heading" : "5 Concluding Remarks",
      "text" : "In this paper, we introduced theMinimax HistogramAggregation (MHA) algorithm for multiple-objective sequential prediction. We considered the general setting where the unknown underlying process is stationary and ergodic., and given that the underlying process is γ-feasible, we extended the well-known result of [1] regarding the asymptotic lower bound of prediction with a single objective, to the case of multi-objectives. We proved that MHA is a γ-bounded strategy whose predictions also converge to the optimal solution in hindsight.\nIn the proofs of the theorems and lemmas above, we used the fact that the initial weights of the experts, αk,h, are strictly positive thus implying a countably infinite expert set. In practice, however, one cannot maintain an infinite set of experts. Therefore, it is customary to apply such algorithms with a finite number of experts (see [14, 12, 13, 17]). Despite the fact that in the proof we assumed that the observation set X is known a priori, the algorithm can also be applied in the case that X is unknown by applying the doubling trick. For a further discussion on this point, see [11]. In our proofs, we relied on the compactness of the set X . It will be interesting to see whether the universality of MHA can be sustained under unbounded processes as well. A very interesting open question would be to identify conditions allowing for finite sample bounds when predicting with multiple objectives."
    } ],
    "references" : [ {
      "title" : "The strong law of large numbers for sequential decisions under uncertainty",
      "author" : [ "P.H. Algoet" ],
      "venue" : "IEEE Transactions on Information Theory, 40(3):609–633,",
      "citeRegEx" : "1",
      "shortCiteRegEx" : null,
      "year" : 1994
    }, {
      "title" : "Asymptotic optimality and asymptotic equipartition properties of log-optimum investment",
      "author" : [ "P.H. Algoet", "T.M. Cover" ],
      "venue" : "The Annals of Probability, pages 876–898,",
      "citeRegEx" : "2",
      "shortCiteRegEx" : null,
      "year" : 1988
    }, {
      "title" : "Optimization iii",
      "author" : [ "A. Ben-Tal", "A. Nemirovsky" ],
      "venue" : "Lecture Notes,",
      "citeRegEx" : "3",
      "shortCiteRegEx" : null,
      "year" : 2012
    }, {
      "title" : "Stochastic optimal control: The discrete time case, volume 23",
      "author" : [ "D. Bertsekas", "S. Shreve" ],
      "venue" : "Academic Press New York,",
      "citeRegEx" : "4",
      "shortCiteRegEx" : null,
      "year" : 1978
    }, {
      "title" : "Nonparametric sequential prediction of time series",
      "author" : [ "G. Biau", "K. Bleakley", "L. Györfi", "G. Ottucsák" ],
      "venue" : "Journal of Nonparametric Statistics, 22(3):297–317,",
      "citeRegEx" : "5",
      "shortCiteRegEx" : null,
      "year" : 2010
    }, {
      "title" : "Sequential quantile prediction of time series",
      "author" : [ "G. Biau", "B. Patra" ],
      "venue" : "IEEE Transactions on Information Theory, 57(3):1664–1674,",
      "citeRegEx" : "6",
      "shortCiteRegEx" : null,
      "year" : 2011
    }, {
      "title" : "Online Computation and Competitive Analysis",
      "author" : [ "A. Borodin", "R. El-Yaniv" ],
      "venue" : "Cambridge University Press,",
      "citeRegEx" : "7",
      "shortCiteRegEx" : null,
      "year" : 2005
    }, {
      "title" : "The individual ergodic theorem of information theory",
      "author" : [ "L. Breiman" ],
      "venue" : "The Annals of Mathematical Statistics, 28(3):809–811,",
      "citeRegEx" : "8",
      "shortCiteRegEx" : null,
      "year" : 1957
    }, {
      "title" : "Prediction, Learning, and Games",
      "author" : [ "N. Cesa-Bianchi", "G. Lugosi" ],
      "venue" : "Cambridge University Press,",
      "citeRegEx" : "9",
      "shortCiteRegEx" : null,
      "year" : 2006
    }, {
      "title" : "Minimax theorems",
      "author" : [ "K. Fan" ],
      "venue" : "Proceedings of the National Academy of Sciences, 39(1):42–47,",
      "citeRegEx" : "10",
      "shortCiteRegEx" : null,
      "year" : 1953
    }, {
      "title" : "Strategies for sequential prediction of stationary time series",
      "author" : [ "L. Györfi", "G. Lugosi" ],
      "venue" : "InModeling uncertainty, pages 225–248. Springer,",
      "citeRegEx" : "11",
      "shortCiteRegEx" : null,
      "year" : 2005
    }, {
      "title" : "Nonparametric kernel-based sequential investment strategies",
      "author" : [ "L. Györfi", "G. Lugosi", "F. Udina" ],
      "venue" : "Mathematical Finance, 16(2):337–357,",
      "citeRegEx" : "12",
      "shortCiteRegEx" : null,
      "year" : 2006
    }, {
      "title" : "Nonparametric prediction",
      "author" : [ "L. Györfi", "D. Schäfer" ],
      "venue" : "Advances in learning theory: methods, models and applications, 339:354,",
      "citeRegEx" : "13",
      "shortCiteRegEx" : null,
      "year" : 2003
    }, {
      "title" : "Kernel-based semi-log-optimal empirical portfolio selection strategies",
      "author" : [ "L. Györfi", "A. Urbán", "I. Vajda" ],
      "venue" : "International Journal of Theoretical and Applied Finance, 10(03):505–516,",
      "citeRegEx" : "14",
      "shortCiteRegEx" : null,
      "year" : 2007
    }, {
      "title" : "The weak aggregating algorithm and weak mixability",
      "author" : [ "Y. Kalnishkan", "M. Vyugin" ],
      "venue" : "International Conference on Computational Learning Theory, pages 188–203. Springer,",
      "citeRegEx" : "15",
      "shortCiteRegEx" : null,
      "year" : 2005
    }, {
      "title" : "Online portfolio selection: A survey",
      "author" : [ "B. Li", "S.C.H. Hoi" ],
      "venue" : "ACM Computing Surveys (CSUR), 46(3):35,",
      "citeRegEx" : "16",
      "shortCiteRegEx" : null,
      "year" : 2014
    }, {
      "title" : "Corn: Correlation-driven nonparametric learning approach for portfolio selection",
      "author" : [ "B. Li", "S.C.H Hoi", "V. Gopalkrishnan" ],
      "venue" : "ACM Transactions on Intelligent Systems and Technology (TIST), 2(3):21,",
      "citeRegEx" : "17",
      "shortCiteRegEx" : null,
      "year" : 2011
    }, {
      "title" : "Nash equilibrium computation in subnetwork zero-sum games with switching communications",
      "author" : [ "Y. Lou", "Y. Hong", "L. Xie", "G. Shi", "K. Johansson" ],
      "venue" : "IEEE Transactions on Automatic Control, 61(10):2920–2935,",
      "citeRegEx" : "18",
      "shortCiteRegEx" : null,
      "year" : 2016
    }, {
      "title" : "Trading regret for efficiency: online convex optimization with long term constraints",
      "author" : [ "M. Mahdavi", "R. Jin", "T. Yang" ],
      "venue" : "Journal of Machine Learning Research, 13(Sep):2503–2528,",
      "citeRegEx" : "19",
      "shortCiteRegEx" : null,
      "year" : 2012
    }, {
      "title" : "Stochastic convex optimization with multiple objectives",
      "author" : [ "M. Mahdavi", "T. Yang", "R. Jin" ],
      "venue" : "Advances in Neural Information Processing Systems, pages 1115– 1123,",
      "citeRegEx" : "20",
      "shortCiteRegEx" : null,
      "year" : 2013
    }, {
      "title" : "Measurable selection theorems for minimax stochastic optimization problems",
      "author" : [ "A. Nowak" ],
      "venue" : "SIAM Journal on Control and Optimization, 23(3):466–476,",
      "citeRegEx" : "21",
      "shortCiteRegEx" : null,
      "year" : 1985
    }, {
      "title" : "Neyman-pearson classification, convexity and stochastic constraints",
      "author" : [ "P. Rigollet", "X. Tong" ],
      "venue" : "Journal of Machine Learning Research, 12(Oct):2831–2855,",
      "citeRegEx" : "22",
      "shortCiteRegEx" : null,
      "year" : 2011
    }, {
      "title" : "Almost sure convergence, vol",
      "author" : [ "W. Stout" ],
      "venue" : "24 of probability and mathematical statistics,",
      "citeRegEx" : "23",
      "shortCiteRegEx" : null,
      "year" : 1974
    }, {
      "title" : "Competing with stationary prediction strategies",
      "author" : [ "V. Vovk" ],
      "venue" : "International Conference on Computational Learning Theory, pages 439–453. Springer,",
      "citeRegEx" : "24",
      "shortCiteRegEx" : null,
      "year" : 2007
    } ],
    "referenceMentions" : [ {
      "referenceID" : 8,
      "context" : "1 Introduction In the traditional online learning setting, and in particular in sequential prediction under uncertainty, the learner is evaluated by a single loss function that is not completely known at each iteration [9].",
      "startOffset" : 219,
      "endOffset" : 222
    }, {
      "referenceID" : 15,
      "context" : "For example, in online portfolio selection [16, 7], the player may want to maximize wealth while keeping the risk (i.",
      "startOffset" : 43,
      "endOffset" : 50
    }, {
      "referenceID" : 6,
      "context" : "For example, in online portfolio selection [16, 7], the player may want to maximize wealth while keeping the risk (i.",
      "startOffset" : 43,
      "endOffset" : 50
    }, {
      "referenceID" : 21,
      "context" : ", [22]) (which extends the objective in classical binary classification) where the goal is to learn a classifier achieving low type II error whose type I error is kept below a given threshold.",
      "startOffset" : 2,
      "endOffset" : 6
    }, {
      "referenceID" : 18,
      "context" : "Recently, [19] presented an algorithm for dealing with the case of one main objective and fully-known constraints.",
      "startOffset" : 10,
      "endOffset" : 14
    }, {
      "referenceID" : 19,
      "context" : "In a subsequent work, [20] proposed a framework for",
      "startOffset" : 22,
      "endOffset" : 26
    }, {
      "referenceID" : 13,
      "context" : "For example, in online portfolio selection, [14, 12], [13], and [17] proposed non-parametric online strategies that guarantee, under mild conditions, the best possible outcome.",
      "startOffset" : 44,
      "endOffset" : 52
    }, {
      "referenceID" : 11,
      "context" : "For example, in online portfolio selection, [14, 12], [13], and [17] proposed non-parametric online strategies that guarantee, under mild conditions, the best possible outcome.",
      "startOffset" : 44,
      "endOffset" : 52
    }, {
      "referenceID" : 12,
      "context" : "For example, in online portfolio selection, [14, 12], [13], and [17] proposed non-parametric online strategies that guarantee, under mild conditions, the best possible outcome.",
      "startOffset" : 54,
      "endOffset" : 58
    }, {
      "referenceID" : 16,
      "context" : "For example, in online portfolio selection, [14, 12], [13], and [17] proposed non-parametric online strategies that guarantee, under mild conditions, the best possible outcome.",
      "startOffset" : 64,
      "endOffset" : 68
    }, {
      "referenceID" : 4,
      "context" : "Another interesting example in this regard is the work on time-series prediction by [5], [11], and [6].",
      "startOffset" : 84,
      "endOffset" : 87
    }, {
      "referenceID" : 10,
      "context" : "Another interesting example in this regard is the work on time-series prediction by [5], [11], and [6].",
      "startOffset" : 89,
      "endOffset" : 93
    }, {
      "referenceID" : 5,
      "context" : "Another interesting example in this regard is the work on time-series prediction by [5], [11], and [6].",
      "startOffset" : 99,
      "endOffset" : 102
    }, {
      "referenceID" : 23,
      "context" : "The algorithm presented in this paper utilizes as a sub-routine the Weak Aggregating Algorithm of [24], and [15] to handle multiple objectives.",
      "startOffset" : 98,
      "endOffset" : 102
    }, {
      "referenceID" : 14,
      "context" : "The algorithm presented in this paper utilizes as a sub-routine the Weak Aggregating Algorithm of [24], and [15] to handle multiple objectives.",
      "startOffset" : 108,
      "endOffset" : 112
    }, {
      "referenceID" : 2,
      "context" : "Therefore, the problem is equivalent to finding the saddle point of the Lagrangian function [3], namely, min y∈Y max λ∈R+ L(y, λ), where the Lagrangian is L(y, λ) , (EP∞ [u(y,X0)] + λ (EP∞ [c(y,X0)]− γ)) .",
      "startOffset" : 92,
      "endOffset" : 95
    }, {
      "referenceID" : 0,
      "context" : "This result is a generalization of the well-known result of [1] regarding the best possible outcome under a single objective.",
      "startOffset" : 60,
      "endOffset" : 63
    }, {
      "referenceID" : 19,
      "context" : ", [20]).",
      "startOffset" : 2,
      "endOffset" : 6
    }, {
      "referenceID" : 7,
      "context" : "Lemma 1 (Ergodicity, [8]).",
      "startOffset" : 21,
      "endOffset" : 24
    }, {
      "referenceID" : 3,
      "context" : "32 from [4], we have that supλ∈Λ EQ [l(y, λ,X)] is continuous inQ×Y .",
      "startOffset" : 8,
      "endOffset" : 11
    }, {
      "referenceID" : 9,
      "context" : "The last part of the lemma follows directly from Fan’s minimax theorem [10].",
      "startOffset" : 71,
      "endOffset" : 75
    }, {
      "referenceID" : 20,
      "context" : "The first part of the proof follows immediately from the minimax measurable theorem of [21] due to the compactness of Y,Λ,X and the properties of the loss function L.",
      "startOffset" : 87,
      "endOffset" : 91
    }, {
      "referenceID" : 1,
      "context" : "The proof of the second part is similar to the one presented in Theorem 3 of [2].",
      "startOffset" : 77,
      "endOffset" : 80
    }, {
      "referenceID" : 22,
      "context" : ", [23]).",
      "startOffset" : 2,
      "endOffset" : 6
    }, {
      "referenceID" : 23,
      "context" : "In order to ensure that the performance of MHA will be as good as any other expert for both the y and the λ predictions, we apply the Weak Aggregating Algorithm of [24], and [15] twice simultaneously.",
      "startOffset" : 164,
      "endOffset" : 168
    }, {
      "referenceID" : 14,
      "context" : "In order to ensure that the performance of MHA will be as good as any other expert for both the y and the λ predictions, we apply the Weak Aggregating Algorithm of [24], and [15] twice simultaneously.",
      "startOffset" : 174,
      "endOffset" : 178
    }, {
      "referenceID" : 17,
      "context" : ", [18]).",
      "startOffset" : 2,
      "endOffset" : 6
    }, {
      "referenceID" : 10,
      "context" : ", [11, 13]), we get that P ∗(k,h) X −1 −k → P{X0|X−1 −k} weakly as h → ∞.",
      "startOffset" : 2,
      "endOffset" : 10
    }, {
      "referenceID" : 12,
      "context" : ", [11, 13]), we get that P ∗(k,h) X −1 −k → P{X0|X−1 −k} weakly as h → ∞.",
      "startOffset" : 2,
      "endOffset" : 10
    }, {
      "referenceID" : 14,
      "context" : "Applying Lemma 5 in [15], we know that the x updates guarantee that for every expert Hk,h,",
      "startOffset" : 20,
      "endOffset" : 24
    } ],
    "year" : 2017,
    "abstractText" : "Online-learning research has mainly been focusing on minimizing one objective function. In many real-world applications, however, several objective functions have to be considered simultaneously. Recently, an algorithm for dealing with several objective functions in the i.i.d. case has been presented. In this paper, we extend the multi-objective framework to the case of stationary and ergodic processes, thus allowing dependencies among observations. We first identify an asymptomatic lower bound for any prediction strategy and then present an algorithm whose predictions achieve the optimal solution while fulfilling any continuous and convex constraining criterion.",
    "creator" : "LaTeX with hyperref package"
  }
}