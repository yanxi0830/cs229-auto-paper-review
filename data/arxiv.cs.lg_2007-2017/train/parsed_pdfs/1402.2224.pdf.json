{
  "name" : "1402.2224.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "Characterizing the Sample Complexity of Private Learners",
    "authors" : [ "Amos Beimel", "Kobbi Nissim Uri Stemmer" ],
    "emails" : [ "beimel@cs.bgu.ac.il", "kobbi@cs.bgu.ac.il", "stemmer@cs.bgu.ac.il" ],
    "sections" : [ {
      "heading" : null,
      "text" : "ar X\niv :1\n40 2.\n22 24\nv1 [\ncs .C\nR ]\n1 0\nFe b\nWe give a combinatorial characterization of the sample size sufficient and necessary to privately learn a class of concepts. This characterization is analogous to the well known characterization of the sample complexity of non-private learning in terms of the VC dimension of the concept class. We introduce the notion of probabilistic representation of a concept class, and our new complexity measure RepDim corresponds to the size of the smallest probabilistic representation of the concept class.\nWe show that any private learning algorithm for a concept class C with sample complexity m implies RepDim(C) = O(m), and that there exists a private learning algorithm with sample complexity m = O(RepDim(C)). We further demonstrate that a similar characterization holds for the database size needed for privately computing a large class of optimization problems and also for the well studied problem of private data release.\n∗A preliminary version of this paper appeared in [4]. Research partially supported by the Israel Science Foundation (grants No. 938/09 and 2761/12) and by the Frankel Center for Computer Science.\nContents"
    }, {
      "heading" : "1 Introduction 1",
      "text" : "1.1 Related Work . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1 1.2 Our Results . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2"
    }, {
      "heading" : "2 Preliminaries 4",
      "text" : "2.1 Preliminaries from Privacy . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 4 2.2 Preliminaries from Learning Theory . . . . . . . . . . . . . . . . . . . . . . . . . . . 4 2.3 Private Learning . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5 2.4 The Exponential Mechanism . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5 2.5 Concentration Bounds . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 6"
    }, {
      "heading" : "3 The Sample Complexity of Private Learners 6",
      "text" : "3.1 Equivalence of (α, β)-Probabilistic Representation and Private Learning . . . . . . . 7"
    }, {
      "heading" : "4 From a Probabilistic Representation to a Deterministic Representation 14",
      "text" : ""
    }, {
      "heading" : "5 Probabilistic Representation for Privately Solving Optimization Problems 17",
      "text" : "5.1 Exact 3SAT . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 21"
    }, {
      "heading" : "6 Extensions 21",
      "text" : "6.1 (ǫ, δ)-Differential Privacy . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 21 6.2 Probabilistic Representation Using a Hypothesis Class . . . . . . . . . . . . . . . . . 22\n7 A Probabilistic Representation for Points 24"
    }, {
      "heading" : "1 Introduction",
      "text" : "Motivated by the observation that learning generalizes many of the analyses applied to large collections of data, Kasiviswanathan el al. [17] defined in 2008 private learning as a combination of probably approximately correct (PAC) learning [20] and differential privacy [12]. A PAC learner is given a collection of labeled examples (sampled according to an unknown probability distribution and labeled according to an unknown concept) and generalizes the labeled examples into a hypothesis h that should predict with high accuracy the labeling of fresh examples taken from the same unknown distribution and labeled with the same unknown concept.\nThe privacy requirement is that the choice of h preserves differential privacy of sample points. Intuitively this means that this choice should not be significantly affected by any particular sample. Differential privacy is increasingly accepted as a standard for rigorous privacy and recent research has shown that differentially private variants exists to many analyses. We refer the reader to surveys of Dwork [10, 11].\nThe sample complexity required for learning a concept class C determines the amount of labeled data needed for learning a concept c ∈ C. It is well known that the sample complexity of learning a concept class C (non-privately) is proportional to a complexity measure of the class C knowns as the VC-dimension [21, 7, 14]. Kasiviswanathan et al. [17] proved that a private learner exists for every finite concept class. The proof is via a generic construction that exhibits sample complexity logarithmic in the size of the concept class. The VC-dimension of a concept class is bounded by this quantity (and significantly lower for some interesting concept classes), and hence the results of [17] left open the possibility that the sample complexity of private learning may be significantly higher than that of non-private learning.\nIn analogy to the characterization of the sample complexity of (non-private) PAC learners via the VC-dimension, we give a combinatorial characterization of the sample size sufficient and necessary for private PAC learners. Towards obtaining this characterization, we introduce the notion of probabilistic representation of a concept class. We note that our characterization, as the VC-dimension characterization, ignores the computation required by the learner. Some of our algorithms are, however, computationally efficient."
    }, {
      "heading" : "1.1 Related Work",
      "text" : "We start with a short description of prior work on the sample complexity of private learning. To simplify the exposition, we ignore dependencies on the error, confidence and privacy parameters by considering them constants for this and the following section. The dependency on these parameters would be made explicit in the later sections of the paper.\nRecall that the sample complexity of non-private learners for a class of functions C is proportional to the VC-dimension of the class [7, 14] – a combinatorial measure of the class that is equal to the size of the largest set of inputs that is shattered by the class. This characterization, as ours, ignores the computation required by the learner.\nKasiviswanathan et al. [17] showed, informally, that every finite concept class C can be learned privately (ignoring computational complexity). Their construction is based on the exponential mechanism of McSherry and Talwar [18], and the O(ln |C|) bound on sample complexity results from the union bound argument used in the analysis of the exponential mechanism. Computationally efficient learners were shown to exist by Blum et al. [5] for all concept classes that can be efficiently learned in the statistical queries model. Kasiviswanathan et al. [17] showed an example of a concept\nclass – the class of parity functions – that is not learnable in the statistical queries model but can be learned privately and efficiently. These positive results suggest that many “natural” computational learning tasks that are efficiently learned non-privately can be learned privately and efficiently.\nBeimel et al. [3] studied the sample complexity of private learning. They examined the concept class of point functions POINTd where each concept evaluates to one on exactly one point of the domain and to zero otherwise. Note that the VC-dimension of POINTd is one. Beimel et al. proved lower bounds on the sample complexity of properly and privately learning the class POINTd (and related classes), implying that the VC dimension of a class does not characterize the sample complexity of private proper learning. On the other hand, they observed that the sample complexity can be improved for improper private learners whenever there exists a smaller hypothesis class H that represents C in the sense that for every concept c ∈ C and for every distribution on the examples, there is a hypothesis h ∈ H that is close to c. Using the exponential mechanism to choose among the hypotheses in H instead of C, the sample complexity is reduced to ln |H| (this is why the size of the representation H is defined to be ln |H|). For some classes this can dramatically improve the sample complexity, e.g., for the class POINTd (defined in Example 3.2), the sample complexity is improved from O(ln | POINTd |) = O(d) to O(ln d). Using other techniques, Beimel et al. showed that the sample complexity of learning POINTd can be reduced even further to O(1), hence showing the largest possible gap between proper and non proper private learning. Such a gap does not exists for non-private learning.\nChaudhuri and Hsu [8] studied the sample complexity needed for private learning infinite concept classes when the data is drawn from a continuous distribution. They showed that under these settings there exists a simple concept class for which any proper learner that uses a finite number of examples and guarantees differential privacy fails to satisfy accuracy guarantee for at least one data distribution. This implies that the results of Kasiviswanathan et al. [17] do not extend to infinite hypothesis classes. Interestingly, our results imply an improper private algorithm for an infinite extension of the class POINT (that is, a class over the natural numbers of all boolean functions that return 1 on exactly one number).\nChaudhuri and Hsu [8] also study learning algorithms that are only required to protect the privacy of the labels (and do not necessarily protect the privacy of the examples themselves). They prove upper bounds and lower bounds on the sample complexity of such algorithms. In particular, they prove a lower bound on the sample complexity using the doubling dimension of the disagreement metric of the hypothesis class with respect to the unlabeled data distribution. This result does not imply our characterization as the privacy requirement in protecting the labels is much weaker than protecting the sample point and the label.\nA line of research (started in [19]) that is very relevant to our paper is boosting learning algorithms, that is, taking learning algorithms that have a big classification error and producing a learning algorithm with small error. Dwork et al. [13] show how to privately boost accuracy, that is, given a private learning algorithms that have a big classification error, they produce a private learning algorithm with small error. In Lemma 3.18, we show how to boost the accuracy α for probabilistic representations. This gives an alternative private boosting, whose proof is simpler. However, as it uses the exponential mechanism, it is (generally) not computationally efficient."
    }, {
      "heading" : "1.2 Our Results",
      "text" : "Beimel et al. [3] showed how to use a representation of a class to privately learn it. We make an additional step in improving the sample complexity by considering a probabilistic representation\nof a concept class C. Instead of one collection H representing C, we consider a list of collections H1, . . . ,Hr such that for every c ∈ C and every distribution on the examples, if we sample a collection Hi from the list, then with high probability there is a hypothesis h ∈ Hi that is close to c. To privately learn C, the learning algorithm first samples i ∈ {1, . . . , r} and then uses the exponential mechanism to select a hypothesis from Hi. This reduces the sample complexity to O(maxi ln |Hi|); the size of the probabilistic representation is hence defined to be maxi ln |Hi|.\nWe show that for POINTd there exists a probabilistic representation of size O(1). This results in a private learning algorithm with sample complexity O(1), matching a different private algorithm for POINTd presented in [3]. Our new algorithm offers some improvement in the sample complexity compared to the algorithm of [3] when considering the learning and privacy parameters. Furthermore, our algorithm can be made computationally efficient without making any computational hardness assumptions, while the efficient version in [3] assumes the existence of one-way functions. Finally, it is conceptually simpler and in particular it avoids the sub-sampling technique used in [3].\nOne can ask if there are private learning algorithms with smaller sample complexity than the size of the smallest probabilistic representation. We show that the answer is no — the size of the smallest probabilistic representation is a lower bound on the sample complexity. Thus, the size of the smallest probabilistic representation of a class C, which we call the representation dimension and denote by RepDim(C), characterizes (up to constants) the sample size necessary and sufficient for privately learning the class C. We also show that for concepts defined over a finite domain, the difference between the sizes of the best deterministic and probabilistic representation is bounded. Namely, that if C is a concept class over the domain {0, 1}d, then there exists a deterministic representation of C of size O(RepDim(C) + ln d). Thus, for classes whose smallest deterministic representation is of size ω(ln d), the size of the smallest deterministic representation characterizes the sample complexity of private learning of the class.\nThe notion of probabilistic representation applies not only to private learning, but also to optimization problems. We consider a scenario where there is a domain X, a database S of m records, each taken from the domain X, a set of solutions F , and a quality function q : X∗ ×F → [0, 1] that we wish to maximize. If the exponential mechanism is used for (approximately) solving the problem, then the size of the database should be Ω(ln |F|) in order to achieve a reasonable approximation. Using our notions of a representation of F and of a probabilistic representation of F , one can reduce the size of the minimal database without paying too much in the quality of the solution. Interestingly, a similar notion to representation, called “solution list algorithms”, was considered in [2] for constructing secure protocols for search problems while leaking only a few bits on the input. Curiously, their notion of leakage is very different from that of differential privacy.\nWe give two examples of such optimization problems. First, an example inspired by [2]: each record in the database is a clause with exactly 3 literals and we want to find an assignment satisfying at least 7/8 fraction of the clauses while protecting the privacy of the clauses. A construction of [2] yields a deterministic representation for this problem where the size of the database can be much smaller. Using a probabilistic representation, we can give a good assignment even for databases of constant size. This example is a simple instance of a scenario, where each individual has a preference on the solution and we want to choose a solution maximizing the number of individuals whose preference are met, while protecting the privacy of the preference. Another example of optimization is sanitization, where given a database we want to publish a synthetic database, which gives a similar utility as the original database while protecting the privacy of the individual records of the database. Using our techniques, we study the minimal database size for which sanitization\ngives reasonable performance with respect to a given family of queries.\nOpen Problem. We still do not know the relation between this dimension and the VC dimension. By Sauer’s Lemma, if C is a concept class over {0, 1}d, then the number of functions in C is at most exp(d·VC(C)). By [17], there is a private learning algorithm for C whose sample size is O(d·VC(C)), thus, the probabilistic representation dimension of C is O(d ·VC(C)). We do not know if there is a class C such that RepDim(C) ≫ VC(C). A candidate for such separation appears in [1]."
    }, {
      "heading" : "2 Preliminaries",
      "text" : "Notation. We use Oγ(g(n)) as a shorthand for O(h(γ) · g(n)) for some non-negative function h. Given a set B of cardinality r, and a distribution P on {1, 2, . . . , r}, we use the notation b ∈P B to denote a random element of B chosen according to P."
    }, {
      "heading" : "2.1 Preliminaries from Privacy",
      "text" : "A database is a vector S = (z1, . . . , zm) over a domain X, where each entry zi ∈ S represents information contributed by one individual. Databases S1 and S2 are called neighboring if they differ in exactly one entry. An algorithm preserves differential privacy if neighboring databases induce nearby outcome distributions. Formally,\nDefinition 2.1 (Differential Privacy [12]). A randomized algorithm A is ǫ-differentially private if for all neighboring databases S1, S2, and for all sets F of outputs,\nPr[A(S1) ∈ F ] ≤ exp(ǫ) · Pr[A(S2) ∈ F ]. (1)\nThe probability is taken over the random coins of A.\nAn immediate consequence of the definition is that for any two databases S1, S2 ∈ X m, and for\nall sets F of outputs, Pr[A(S1) ∈ F ] ≥ exp(−ǫm) · Pr[A(S2) ∈ F ]."
    }, {
      "heading" : "2.2 Preliminaries from Learning Theory",
      "text" : "Let Xd = {0, 1} d. A concept c : Xd → {0, 1} is a function that labels examples taken from the domain Xd by either 0 or 1. A concept class C over Xd is a class of concepts mapping Xd to {0, 1}. PAC learning algorithms are given examples sampled according to an unknown probability distribution D over Xd, and labeled according to an unknown target concept c ∈ C. The generalization error of a hypothesis h : Xd → {0, 1} is defined as\nerrorD(c, h) = Pr x∈DXd [h(x) 6= c(x)].\nFor a labeled sample S = (xi, yi) m i=1, the empirical error of h is\nerrorS(h) = 1\nm |{i : h(xi) 6= yi}|.\nDefinition 2.2. An α-good hypothesis for c and D is a hypothesis h such that errorD(c, h) ≤ α.\nDefinition 2.3 (PAC Learning [20]). Algorithm A is an (α, β)-PAC learner for a concept class C over Xd using hypothesis class H and sample size m if for all concepts c ∈ C, all distributions D on Xd, given an input of m samples S = (z1, . . . , zm), where zi = (xi, c(xi)) and xi are drawn i.i.d. from D, algorithm A outputs a hypothesis h ∈ H satisfying\nPr[errorD(c, h) ≤ α] ≥ 1− β.\nThe probability is taken over the random choice of the examples in S according to D and the coin tosses of the learner A.\nDefinition 2.4. An algorithm satisfying Definition 2.3 with H ⊆ C is called a proper PAC learner; otherwise it is called an improper PAC learner."
    }, {
      "heading" : "2.3 Private Learning",
      "text" : "As a private learner is a PAC learner, its outcome hypothesis should also be a good predictor of labels. Hence, the privacy requirement from a private learner is not that an application of the hypothesis h on a new sample (pertaining to an individual) should leak no information about the sample.\nDefinition 2.5 (Private PAC Learning [17]). Let A be an algorithm that gets an input S = (z1, . . . , zm). Algorithm A is an (α, β, ǫ)-PPAC learner for a concept class C over Xd using hypothesis class H and sample size m if\nPrivacy. Algorithm A is ǫ-differentially private (as formulated in Definition 2.1);\nUtility. Algorithm A is an (α, β)-PAC learner for C using H and sample size m (as formulated in Definition 2.3)."
    }, {
      "heading" : "2.4 The Exponential Mechanism",
      "text" : "We next describe the exponential mechanism of McSherry and Talwar [18]. We present its private learning variant; however, it can be used in more general scenarios. The goal here is to chooses a hypothesis h ∈ H approximately minimizing the empirical error. The choice is probabilistic, where the probability mass that is assigned to each hypothesis decreases exponentially with its empirical error.\nInputs: a privacy parameter ǫ, a hypothesis class H, and m labeled samples S = (xi, yi) m i=1.\n1. ∀h ∈ H define q(S, h) = |{i : h(xi) = yi}|.\n2. Randomly choose h ∈ H with probability\nexp (ǫ · q(S, h)/2)∑ f∈H exp (ǫ · q(S, f)/2) .\nProposition 2.6. Denote ê , minf∈H{errorS(f)}. The probability that the exponential mechanism outputs a hypothesis h such that errorS(h) > ê+∆ is at most |H| · exp(−ǫ∆m/2). Moreover, The exponential mechanism is ǫ differentially private."
    }, {
      "heading" : "2.5 Concentration Bounds",
      "text" : "Let X1, . . . ,Xn be independent random variables where Pr[Xi = 1] = p and Pr[Xi = 0] = 1 − p for some 0 < p < 1. Clearly, E[ ∑ iXi] = pn. Chernoff and Hoeffding bounds show that the sum is concentrated around this expected value:\nPr [∑\ni Xi > (1 + δ)pn\n] ≤ exp ( −pnδ2/3 ) for δ > 0,\nPr [∑\ni Xi < (1− δ)pn\n] ≤ exp ( −pnδ2/2 ) for 0 < δ < 1,\nPr [∣∣∣ ∑\ni Xi − pn\n∣∣∣ > δ ] ≤ 2 exp ( −2δ2/n ) for δ ≥ 0.\nThe first two inequalities are known as the multiplicative Chernoff bounds [9], and the last inequality is known as the Hoeffding bound [16]."
    }, {
      "heading" : "3 The Sample Complexity of Private Learners",
      "text" : "In this section we present a combinatorial measure of a concept class C that characterizes the sample complexity necessary and sufficient for privately learning C. The measure is a probabilistic representation of the class C. We start with the notation of deterministic representation from [3].\nDefinition 3.1 ([3]). A hypothesis class H is an α-representation for a class C if for every c ∈ C and every distribution D on Xd there exists a hypothesis h ∈ H such that errorD(c, h) ≤ α.\nExample 3.2 (POINTd). For j ∈ Xd, define cj : Xd → {0, 1} as cj(x) = 1 if x = j, and cj(x) = 0 otherwise. Define POINTd = {cj}j∈Xd . In [3] it was shown that for α < 1/2, every α-representation for POINTd must be of cardinality at least d, and that an α-representation Hd for POINTd exists where |Hd| = O(d/α 2).\nThe above representation can be used for non-private learning, by taking a big enough sample and finding a hypothesis h ∈ Hd minimizing the empirical error. For private learning it was shown in [3] that a sample of size Oα,β,ǫ(log |Hd|) suffices, with a learner that employs the exponential mechanism to choose a hypothesis from Hd.\nDefinition 3.3. For a hypothesis class H we denote size(H) = ln |H|. We define the Deterministic Representation Dimension of a concept class C as\nDRepDim(C) = min { size(H) : H is a 1\n4 -representation for C\n} .\nRemark 3.4. Choosing 14 is arbitrary; we could have chosen any (smaller than 1 2) constant.\nExample 3.5. By the results of [3], stated in the previous example, DRepDim(POINTd) = θ(ln(d)).\nWe are now ready to present the notion of a probabilistic representation. The idea behind this notion is that we have a list of hypothesis classes, such that for every concept c and distribution D, if we sample a hypothesis class from the list, then with high probability it contains a hypothesis that is close to c.\nDefinition 3.6. Let P be a distribution over {1, 2, . . . , r}, and let H = {H1,H2, . . . ,Hr} be a family of hypothesis classes (every Hi ∈ H is a set of boolean functions). We say that (H ,P) is an (α, β)-probabilistic representation for a class C if for every c ∈ C and every distribution D on Xd:\nPr P [∃h ∈ Hi s.t. errorD(c, h) ≤ α] ≥ 1− β.\nThe probability is over randomly choosing a set Hi ∈P H .\nRemark 3.7. As we will see in Section3.1, the existence of such a probabilistic representation (H ,P) for a concept class C implies the existence of a private learning algorithm for C with sample complexity that depends on the cardinality of the hypothesis classes Hi ∈ H . The sample complexity will not depend on r = |H |. Nevertheless, in Section 4 we will see that there always exists a probabilistic representation in which r is bounded.\nExample 3.8 (POINTd). In Section 7 we construct for every α and every β a pair (H ,P) that (α, β)-probabilistically represents the class POINTd, where H contains all the sets of at most 4 α ln(1/β) boolean functions.\nDefinition 3.9. Let H = {H1,H2, . . . ,Hr} be a family of hypothesis classes. We denote |H | = r, and size(H ) = max{ ln |Hi| : Hi ∈ H }. We define the Representation Dimension of a concept class C as\nRepDim(C) = min    size(H ) : ∃P s.t. (H ,P) is a (14 , 1 4)-probabilistic\nrepresentation for C\n   .\nRemark 3.10. Choosing α = β = 14 is arbitrary; we could have chosen any two (smaller than 1 2) constants.\nExample 3.11 (POINTd). The size of the probabilistic representation mentioned in Example 3.8 is ln( 4α ln(1/β)). Placing α = β = 1 4 , we see that the Representation Dimension of POINTd is constant."
    }, {
      "heading" : "3.1 Equivalence of (α, β)-Probabilistic Representation and Private Learning",
      "text" : "We now show that RepDim(C) characterizes the sample complexity of private learners. We start by showing in Lemma 3.12 that an (α, β)-probabilistic representation of C implies a private learning algorithm whose sample complexity is the size of the representation. We then show in Lemma 3.16 that if there is a private learning algorithm with sample complexity m, then there is probabilistic representation of C of size O(m); this lemma implies that RepDim(C) is a lower bound on the sample complexity. Recall that RepDim(C) is the size of the smallest probabilistic representation for α = β = 1/4. Thus, to complete the proof we show in Lemma 3.18 that a probabilistic representation with α = β = 1/4 implies a probabilistic representation for arbitrary α and β.\nLemma 3.12. If there a exists pair (H ,P) that (α, β)-probabilistically represents a class C, then for every ǫ there exists an algorithm A that (6α, 4β, ǫ)-PPAC learns C with a sample size m =\nO (\n1 αǫ(size(H ) + ln( 1 β ))\n) .\nProof. Let (H ,P) be an (α, β)-probabilistic representation for the class C, and consider the following algorithm A:\nInputs: S = (xi, yi) m i=1, and a privacy parameter ǫ.\n1. Randomly choose Hi ∈P H . 2. Choose h ∈ Hi using the exp. mechanism with ǫ.\nBy the properties of the exponential mechanism, A is ǫ-differentially private. We will show that with sample size m = O (\n1 αǫ(size(H ) + ln( 1 β ))\n) , algorithm A is a (6α, 4β)-PAC learner for C. Fix\nsome c ∈ C and D, and define the following 3 good events:\nE1 Hi chosen in step 1 contains at least one hypothesis h s.t. errorS(h) ≤ 2α.\nE2 For every h ∈ Hi s.t. errorS(h) ≤ 3α, it holds that errorD(c, h) ≤ 6α\nE3 The exponential mechanism chooses an h such that errorS(h) ≤ α+minf∈Hi {errorS(f)}.\nWe first show that if those 3 good events happen, algorithm A returns a 6α-good hypothesis. Event E1 ensures the existence of a hypothesis f ∈ Hi s.t. errorS(f) ≤ 2α. Thus, event E1 ∩ E3 ensures algorithm A chooses (using the exponential mechanism) a hypothesis h ∈ Hi s.t. errorS(h) ≤ 3α. Event E2 ensures therefore that this h obeys errorD(c, h) ≤ 6α.\nWe will now show that those 3 events happen with high probability. As (H ,P) is an (α, β)probabilistic representation for the class C, the chosen Hi contains a hypothesis h s.t. errorD(c, h) ≤ α with probability at least 1− β; by the Chernoff bound with probability at least 1− exp(−mα/3) this hypothesis has empirical error at most 2α. Event E1 happens with probability at least (1 − β)(1 − exp(−mα/3)) > 1− (β + exp(−mα/3)), which is at least (1− 2β) for m ≥ 3α ln(1/β).\nUsing the Chernoff bound, the probability that a hypothesis h s.t. errorD(c, h) > 6α has empirical error ≤ 3α is less than exp(−mα3/4). Using the union bound, the probability that there is such a hypothesis inHi is at most |Hi|·exp(−mα3/4). Therefore, Pr[E2] ≥ 1−|Hi|·exp(−mα3/4). For m ≥ 43α (ln( |Hi| β )), this probability is at least (1− β).\nThe exponential mechanism ensures that the probability of event E3 is at least 1 − |Hi| ·\nexp(−ǫαm/2) (see Section 2.4), which is at least (1− β) for m ≥ 2αǫ ln( |Hi| β ).\nAll in all, by setting m = 3αǫ(size(H ) + ln( 1 β )) we ensure that the probability of A failing to\noutput a 6α-good hypothesis is at most 4β.\nWe will demonstrate the above lemma with two examples:\nExample 3.13 (Efficient learner for POINTd). As described in Example 3.8, there exists an (H ,P) that (α/6, β/4)-probabilistically represents the class POINTd, where size(H ) = Oα,β,ǫ(1). By Lemma 3.12, there exists an algorithm that (α, β, ǫ)-PPAC learns C with sample size m = Oα,β,ǫ(1).\nThe existence of an algorithm with sample complexity O(1) was already proven in [3]. Moreover, assuming the existence of oneway functions, their learner is efficient. Our constructions yields an efficient learner, without assumptions. To see this, consider again algorithm A presented in the above proof, and note that as size(H ) is constant, step 2 could be done in constant time. Step 1 can be done efficiently as we can efficiently sample a set Hi ∈P H . In Claim 7.1 we initially construct a probabilistic representation in which the description of every hypothesis is exponential in d. The representation is than revised using pairwise independence to yield a representation in which every hypothesis h has a short description, and given x the value h(x) can be computed efficiently.\nExample 3.14 (POINTN). Consider the class POINTN, which is exactly like POINTd, only over the natural numbers. By results of [8, 3], it is impossible to properly PPAC learn the class POINTN. Our construction can yield an (inefficient) improper private learner for POINTN with Oα,β,ǫ(1) samples. The details are deferred to Section 7.\nThe next lemma shows that a private learning algorithm implies a probabilistic representation. This lemma can be used to lower bound the sample complexity of private learners.\nLemma 3.15. If there exists an algorithm A that (α, 12 , ǫ)-PPAC learns a concept class C with a sample size m, then there exists a pair (H ,P) that (α, 1/4)-probabilistically represents the class C such that size(H ) = O (mǫ).\nProof. Let A be an (α, 12 , ǫ)-PPAC learner for a class C using hypothesis class F whose sample size is m. For a target concept c ∈ C and a distribution D on Xd, we define G as the set of all hypotheses h ∈ F such that errorD(c, h) ≤ α. Fix some c ∈ C and a distribution D on Xd. As A is an (α, 12)-PAC learner, PrD,A [A(S) ∈ G] ≥ 1 2 , where the probability is over A’s randomness and over sampling the examples in S (according to D). Therefore, there exists a database S of m samples such that PrA [A(S) ∈ G] ≥ 1 2 , where the probability is only over the randomness of A. As A is ǫ-differentially private, PrA [ A(~0) ∈ G ] ≥ e−mǫ · PrA [A(S) ∈ G] ≥ 1 2e −mǫ, where ~0 is a\ndatabase with m zeros.1 That is, PrA [ A(~0) /∈ G ] ≤ 1− 12e −mǫ. Now, consider a set H containing the outcomes of 2 ln(4)emǫ executions of A(~0). The probability that H does not contain an α-good hypothesis is at most (1 − 12e −mǫ)2 ln(4)e mǫ ≤ 14 . Thus, H = {H ⊆ F : |H| ≤ 2 ln(4)e mǫ}, and P, the distribution induced by A(~0), are an (α, 1/4)-probabilistic representation for class C. It follows that size(H ) = max{ ln |H| : H ∈ H } = ln(2 ln(4)) +mǫ.\nThe above lemma yields a lower bound of Ω ( 1 ǫ RepDim(C) ) on the sample complexity of private learners for a concept class C. To see this, fix α ≤ 14 and let A be an (α, 1 2 , ǫ)-PPAC learner for C with sample size m. By the above lemma, there exists a pair (H ,P) that (α, 1/4)-probabilistically represents C s.t. size(H ) = ln(2 ln(4))+mǫ. Therefore, by definition, RepDim(C) ≤ ln(2 ln(4))+mǫ. Thus, m ≥ 1ǫ (RepDim(C) − ln(2 ln(4))) = Ω ( 1 ǫ RepDim(C) ) .\nIn order to refine this lower bound (and incorporate α in it), we will need a somewhat stronger version of this lemma:\nLemma 3.16. Let α ≤ 1/4. If there exists an algorithm A that (α, 12 , ǫ)-PPAC learns a concept class C with a sample size m, then there exists a pair (H ,P) that (1/4, 1/4)-probabilistically represents the class C such that size(H ) = O (mǫα).\nProof. Let A be an (α, 12 , ǫ)-PPAC learner for the class C using hypothesis class F whose sample size is m. Without loss of generality, we can assume that m ≥ 3 ln(4)4α (since A can ignore part of the sample). For a target concept c ∈ C and a distribution D on Xd, we define\nGαD = {h ∈ F : errorD(c, h) ≤ α}.\nFix some c ∈ C and a distribution D on Xd, and define the following distribution D̃ on Xd:\nPr D̃ [x] =\n{ 1− 4α+ 4α · PrD[x], x = 0 d.\n4α · PrD[x], x 6= 0 d.\n1Choosing ~0 is arbitrary; we could have chosen any database.\nNote that for every x ∈ Xd,\nPr D̃ [x] ≥ 4α · Pr D [x]. (2)\nAs A is an (α, 12)-PAC learner, it holds that\nPr D̃,A\n[ A(S) ∈ Gα\nD̃\n] ≥ 1\n2 ,\nwhere the probability is over A’s randomness and over sampling the examples in S (according to D̃). In addition, by inequality (2), every hypothesis h with errorD(c, h) > 1/4 has error strictly greater than α under D̃:\nerrorD̃(c, h) ≥ 4α · errorD(c, h) > α.\nSo, every α-good hypothesis for c and D̃ is a 14 -good hypothesis for c and D. That is, G α D̃ ⊆ G 1/4 D . Therefore, Pr D̃,A [ A(S) ∈ G 1/4 D ] ≥ 12 .\nWe say that a database S of m labeled examples is good if the unlabeled example 0d appears in S at least (1 − 8α)m times. Let S be a database constructed by taking m i.i.d. samples from D̃, labeled by c. By the Chernoff bound, S is good with probability at least 1− exp(−4αm/3). Hence,\nPr D̃,A\n[ (A(S) ∈ G\n1/4 D ) ∧ (S is good)\n] ≥ 1\n2 − exp(−4αm/3) ≥\n1 4 .\nTherefore, there exists a database Sgood of m samples that contains the unlabeled sample 0 d\nat least (1 − 8α)m times, and PrA [ A(Sgood) ∈ G 1/4 D ] ≥ 14 , where the probability is only over the randomness of A. All of the examples in Sgood (including the example 0 d) are labeled by c.\nFor σ ∈ {0, 1}, denote by ~0σ a database containing m copies of the example 0 d labeled as σ. As A is ǫ-differentially private, and as the target concept c labels the example 0d by either 0 or 1, for at least one σ ∈ {0, 1} it holds that\nPr A [A(~0σ) ∈ G 1/4 D ] ≥ exp(−8αǫm) · PrA\n[ A(Sgood) ∈ G 1/4 D ]\n≥ exp(−8αǫm) · 1/4. (3)\nThat is, PrA[A(~0σ) /∈ G 1/4 D ] ≤ 1 − 1 4e −8αǫm. Now, consider a set H containing the outcomes of 4 ln(4)e8αǫm executions of A(~00), and the outcomes of 4 ln(4)e 8αǫm executions of A(~01). The probability that H does not contain a 14 -good hypothesis for c and D is at most (1− 1 4e −8αǫm)4 ln(4)e 8αǫm\n≤ 1 4 . Thus, H = { H ⊆ F : |H| ≤ 2 · 4 ln(4)e8αǫm } , and P, the distribution induced by A(~00) and A(~01), are a (1/4, 1/4)-probabilistic representation for the class C. Note that the value c(0 d) is unknown, and can be either 0 or 1. Therefore the construction uses the two possible values (one of them correct).\nIt holds that size(H ) = max{ ln |H| : H ∈ H } = ln(8 ln(4)) + 8αǫm = O (mǫα).\nLemma 3.18 shows how to construct a probabilistic representation for an arbitrary α and β from a probabilistic representation with α = β = 1/4; in other words we boost α and β. The proof\nof this lemma is combinatorial. It allows us to start with a private learning algorithm with constant α and β, move to a representation, use the combinatorial boosting, and move back to a private algorithm with small α and β. This should be contrasted with the private boosting of [13] which is algorithmic and more complicated (however, the algorithm of Dwork et al. [13] is computationally efficient).\nWe first show how to construct a probabilistic representation for arbitrary β from a probabilistic representation with β = 1/4.\nClaim 3.17. For every concept class C and for every β, there exists a pair (H ,P) that (1/4, β)probabilistically represents C where size(H ) ≤ RepDim(C) + ln ln(1/β).\nProof. Let β < 1/4, and let (H 0,P0) be a (14 , 1 4 )- probabilistic representation for C with size(H 0) = RepDim(C) , k0 (that is, for every H 0 i ∈ H 0 it holds that |H0i | ≤ e k0). Denote H 0 = {H01,H 0 2, . . . ,H 0 r}, and consider the following family of hypothesis classes:\nH 1 = { H0i1 ∪ · · · ∪ H 0 iln(1/β) : 1 ≤ i1 ≤ · · · ≤ iln(1/β) ≤ r } .\nNote that for every H1i ∈ H 1 it holds that |H1i | ≤ ln(1/β)e k0 and so size(H 1) , k1 ≤ k0 + ln ln(1/β). We will now show an appropriate distribution P1 on H 1 s.t. (H 1,P1) is a (14 , β)probabilistic representation for C. To this end, consider the following process for randomly choosing an H1 ∈ H 1:\n1. Denote M = ln(1/β) 2. For i = 1, . . . ,M :\nRandomly choose H0i ∈P0 H 0.\n3. Return H1 = ⋃M\ni=1 H 0 i .\nThe above process induces a distribution on H 1, denoted as P1. As H 0 is a (14 , 1 4 )-probabilistic\nrepresentation for C, we have that\nPr P1\n[ ∄h ∈ H1 s.t. errorD(c, h) ≤ 1/4 ] =\n= M∏\ni=1\nPr P0\n[ ∄h ∈ H0i s.t. errorD(c, h) ≤ 1/4 ] ≤\n≤\n( 1\n4\n)M ≤ β.\nLemma 3.18. For every concept class C, every α, and every β, there exists (H ,P) that (α, β)probabilistically represents C where\nsize(H ) = O ( ln( 1\nα ) ·\n( RepDim(C) + ln ln ln( 1\nα ) + ln ln(\n1 β ) )) .\nProof. Let C be a concept class, and let (H 1,P1) be a (14 , β/T )-probabilistic representation for C (where T will be set later). By Claim 3.17, such a representation exists with size(H 1) , k1 ≤ RepDim(C) + ln ln(T/β). We use H 1 and P1 to create an (α, β)- probabilistic representation for C. We begin with two notations:\n1. For T hypotheses h1, . . . , hT we denote by majh1,...,hT the majority hypothesis. That is, majh1,...,hT (x) = 1 if and only if |{hi : hi(x) = 1}| ≥ T/2.\n2. For T hypothesis classes H1, . . . ,HT we denote MAJ(H1, . . . ,HT ) = { majh1,...,hT : ∀1≤i≤T hi ∈ Hi } .\nConsider the following family of hypothesis classes:\nH = { MAJ(Hi1 , . . . ,HiT ) : Hi1 , . . . ,HiT ∈ H 1 } .\nMoreover, denote the distribution on H induced by the following random process as P:\nFor j = 1, . . . , T : Randomly choose Hij ∈P1 H 1 Return MAJ(Hi1 , . . . ,HiT ).\nNext we show that (H ,P) is an (α, β)-probabilistic representation for C: For a fixed pair of a target concept c and a distribution D, randomly choose Hi1 , . . . ,HiT ∈P1 H\n1. We now show that with probability at least (1−β) the set MAJ(Hi1 , . . . ,HiT ) contains at least one α-good hypothesis for c,D.\nTo this end, denote D1 = D and consider the following thought experiment, inspired by the Adaboost Algorithm of [15]:\nFor t = 1. . . . , T :\n1. Fail if Hit does not contain a 1 4 -good hypothesis for c,Dt. 2. Denote by ht ∈ Hit a 1 4 -good hypothesis for c,Dt.\n3. Dt+1(x) = { 2Dt(x), if ht(x) 6= c(x).( 1− errorDt(c,ht)\n1−errorDt (c,ht)\n) Dt(x), otherwise.\nNote that as D1 is a probability distribution on Xd; the same is true for D2,D3, . . . ,DT . As (H 1,P1) is a (14 , β/T )-probabilistic representation for C, the failure probability of every iteration is at most β/T . Thus (using the union bound), with probability at least (1−β) the whole thought experiment will succeed, and in this case we show that the error of hfin = majh1,...,hT is at most α.\nConsider the set R = {x : hfin(x) 6= c(x)} ⊆ Xd. This is the set of points on which at least T/2 of h1, . . . , hT err. Next consider the partition of R to the following sets:\nRt = { x ∈ R : ( ht(x) 6= c(x) ) ∧ ( ∀i>t hi(x) = c(x) )} .\nThat is, Rt contains the points x ∈ R on which ht is last to err. Clearly Dt(Rt) ≤ 1/4, as Rt is a\nsubset of the set of points on which ht errs. Moreover,\nDt(Rt) ≥ D1(Rt) · 2 T/2 · ( 1− errorDt(c, ht)\n1− errorDt(c, ht)\n)t−T/2\n≥ D1(Rt) · 2 T/2 · ( 1− 1/4\n1− 1/4\n)t−T/2\n≥ D1(Rt) · 2 T/2 · ( 1− 1/4\n1− 1/4\n)T/2\n= D(Rt) ·\n( 4\n3\n)T/2 ,\nso,\nD(Rt) ≤ Dt(Rt) ·\n( 4\n3\n)−T/2 ≤ 1\n4 ·\n( 4\n3\n)−T/2 .\nFinally,\nerrorD(c, hfin) = D(R) = T∑\nt=T/2\nD(Rt) ≤\n≤ T 2 · 1 4 ·\n( 4\n3\n)−T/2 = T\n8 ·\n( 4\n3\n)−T/2 .\nChoosing T = 14 ln( 2α ), we get that errorD(c, hfin) ≤ α. Hence, (H ,P) is an (α, β)-probabilistic\nrepresentation for C. Moreover, for every Hi ∈ H we have that |Hi| ≤ ( ek1 )T , and so\nsize(H ) ≤ k1 · T ≤ ( RepDim(C) + ln ln(T/β) ) T = O ( ln( 1\nα ) ·\n( RepDim(C) + ln ln ln( 1\nα ) + ln ln(\n1 β ) )) .\nThe next theorem states the main result of this section – RepDim characterizes the sample complexity of private learning.\nTheorem 3.19. Let C be a concept class. Θ̃β\n( RepDim(C)\nαǫ\n) samples are necessary and sufficient for\nthe private learning of the class C.\nProof. Fix some α ≤ 1/4, β ≤ 1/2, and ǫ. By Lemma 3.18, there exists a pair (H ,P) that (α6 , β 4 )-represent class C, where size(H ) = O ( ln(1/α) · ( RepDim(C) + ln ln ln(1/α) + ln ln(1/β) )) . Therefore, by Lemma 3.12, there exists an algorithm A that (α, β, ǫ)-PPAC learns the class C with a sample size\nm = Oβ\n( 1\nαǫ ln(\n1 α ) ·\n( RepDim(C) + ln ln ln( 1\nα )\n)) .\nFor the lower bound, let A be an (α, β, ǫ)-PPAC learner for the class C with a sample size m, where α ≤ 1/4 and β ≤ 1/2. By Lemma 3.16, there exists an (H ,P) that (14 , 1 4)- probabilistically\nrepresents the class C and size(H ) = ln(8)+ln ln(4)+8αǫm. Therefore, by definition, RepDim(C) ≤ ln(8 ln(4)) + 8αǫm. Thus,\nm ≥ 1 8αǫ · ( RepDim(C)− ln(8 ln(4)) ) = Ω\n( RepDim(C)\nαǫ\n) ."
    }, {
      "heading" : "4 From a Probabilistic Representation to a Deterministic Repre-",
      "text" : "sentation\nIn this section we will establish a connection between the (probabilistic) representation dimension of a class and its deterministic representation dimension.\nObservation 4.1. Let (H ,P) be an (α, β)-probabilistic representation for a concept class C. Then, B = ⋃ Hi∈H Hi is an α-representation of C.\nProof. As (H ,P) is an (α, β)-probabilistic representation for C, for every c and every D\nPr P [∃h ∈ Hi s.t errorD(c, h) ≤ α] ≥ 1− β > 0.\nThe probability is over choosing a set Hi ∈P H . In particular, for every c and every D there exists an Hi ∈ H that contains an α-good hypothesis.\nThe simple construction in Observation 4.1 may result in a very large deterministic representation. For example, in Claim 7.1 we show an (H ,P) that (α, β)- probabilistically represents the class POINTd, where H contains all the sets of at most 4 α ln(\n1 β ) boolean functions. While⋃\nHi∈H Hi = 2 Xd is indeed an α-representation for POINTd, it is extremely over-sized. We will show that it is not necessary to take the union of all the Hi’s in H in order to get an α-representation for C. As (H ,P) is an (α, β)-probabilistic representation, for every c and every D, with probability at least 1 − β a randomly chosen Hi ∈P H contains an α-good hypothesis. The straight forward strategy here is to first boost β as in Claim 3.17, and then use the union bound over all possible c ∈ C and over all possible distributions D on Xd. Unfortunately, there are infinitely many such distributions, and the proof will be somewhat more complicated.\nDefinition 4.2. Let H = {H1,H2, . . . ,Hr} be a family of hypothesis classes, and P be a distribution over {1, . . . , r}. We will denote the following non private algorithm as Learner(H ,P,m, γ):\nInput: a sample S = (xi, yi) m i=1.\n1. Randomly choose Hi ∈P H . 2. If for every h ∈ Hi errorS(h) > γ, then fail. 3. Return h ∈ Hi minimizing errorS(h).\nWe will say that Learner(H ,P,m, γ) is β-successful for a class C over Xd, if for every c ∈ C and every distribution D on Xd, given an input sample drawn i.i.d. according to D and labeled by c, algorithm Learner fails with probability at most β.\nClaim 4.3. If (H ,P) is an (α, β)-probabilistic representation for a class C, then, for m ≥ 3 α ln(1/β), algorithm Learner(H ,P,m, 2α) is 2β-successful for C.\nProof. We will show that with probability at least 1 − 2β, the set Hi (chosen in Step 1) contains at least one hypothesis h s.t. errorS(h) ≤ 2α. As (H ,P) is an (α, β)-probabilistic representation for class C, the chosen Hi will contain a hypothesis h s.t. errorD(c, h) ≤ α with probability at least 1−β; by the Chernoff bound with probability at least 1−exp(−mα/3) this hypothesis has empirical error at most 2α. The set Hi contains a hypothesis h s.t. errorS(h) ≤ 2α with probability at least (1−β)(1−exp(−mα/3)) > 1−(β+exp(−mα/3)), which is at least (1−2β) for m ≥ 3α ln(1/β).\nClaim 4.4. Let H be a family of hypothesis classes, and P a distribution on it. Let γ, β and m be such that m ≥ 4γ (size(H ) + ln( 1 β )). If Learner(H ,P,m, γ) is β-successful for a class C over Xd, then there exists Ĥ ⊆ H and a distribution P̂ on it, s.t. Learner(Ĥ , P̂ ,m, γ) is a (2γ, 3β)-PAC\nlearner for C and ∣∣∣Ĥ ∣∣∣ = d·mβ2 .\nProof. For every input S = (xi, yi) m i=1, denote by pS the probability of Learner(H ,P,m, γ) failing on step 2 (the probability is only over the choice of Hi ∈P H in the first step). As Learner(H ,P,m, γ) is β-successful,\nPr P,D\n[ Learner(H ,P,m, γ) fails ] = ∑\nS\nPr D [S] · pS ≤ β.\nConsider the following process, denoted by Proc, for randomly choosing a multiset H̃ of size t (t will be set later):\nFor i = 1, . . . , t : Randomly choose Hi ∈P H Return H̃ = (H1,H2, ...,Ht).\nDenote by Ut the uniform distribution on {1, 2, . . . , t}. As before, for every input S = (xi, yi) m i=1, denote by p̃S the probability of Learner(H̃ ,Ut,m, γ) failing on its second step (again, the probability is only over the choice of Hi ∈Ut H̃ in the first step). Using those notations:\nPr Ut,D\n[ Learner(H̃ ,Ut,m, γ) fails ] = ∑\nS\nPr D [S] · p̃S.\nFix a sample S. As the choice of Hi ∈Ut H̃ is uniform,\np̃S =\n∣∣∣ { Hi ∈ H̃ : ∀h ∈ Hi errorS(h) > γ }∣∣∣ ∣∣∣H̃ ∣∣∣ .\nUsing the Hoeffding bound,\nPr Proc\n[ |p̃S − pS| ≥ β ] ≤ 2e−2tβ 2 .\nThe probability is over choosing the multiset H̃ . There are at most 2m(d+1) samples of size m (as every entry in the sample is an element of Xd, concatenated with a label bit). Using the union bound over all possible samples S,\nPr Proc\n[ ∃S s.t. |p̃S − pS | ≥ β ] ≤ 2m(d+1) · 2 · e−2tβ 2 .\nFor t ≥ m·d β2 the above probability is strictly less than 1. This means that for t = m·d β2 there exists a multiset Ĥ such that |p̂S − pS | ≤ β for every sample S. We will show that for this Ĥ , Learner(Ĥ ,Ut,m, γ) is a (2γ, 3β)-PAC learner. Fix a target concept c ∈ C and a distribution D on Xd. Define the following two good events:\nE1 Learner(Ĥ ,Ut,m, γ) outputs a hypothesis h such that errorS(h) ≤ γ.\nE2 For every h ∈ Hi s.t. errorS(h) ≤ γ, it holds that errorD(c, h) ≤ 2γ.\nNote that if those two events happen, Learner(Ĥ ,Ut,m, γ) returns a 2γ-good hypothesis for c and D. We will show that those two events happen with high probability. We start by bounding the failure probability of Learner(Ĥ ,Ut,m, γ).\nPr Ut,D\n[ Learner(Ĥ ,Ut,m, γ) fails ]\n= ∑\nS\nPr D [S] · p̂S\n≤ ∑\nS\nPr D [S] · (pS + β)\n= Pr P,D\n[ Learner(H ,P,m, γ) fails ] + β ≤ 2β.\nWhen Learner(Ĥ ,Ut,m, γ) does not fail, it returns a hypothesis h with empirical error at most γ. Thus, Pr[E1] ≥ 1− 2β.\nUsing the Chernoff bound, the probability that a hypothesis h with errorD(c, h) > 2γ has empirical error ≤ γ is less than exp(−mγ/4). Using the union bound, the probability that there is such a hypothesis in Hi is at most |Hi| · exp(−mγ/4). Therefore, Pr[E2] ≥ 1− |Hi| · exp(−mγ/4). For m ≥ 4γ ln( |Hi| β ), this probability is at least (1− β).\nAll in all, the probability of Learner(H ,P,m, γ) failing to output a 2γ-good hypothesis is at most 3β.\nTheorem 4.5. If there exists a pair (H ,P) that (α, β)-probabilistically represents a class C over\nXd (where |H | might be very big), then there exists a pair (Ĥ , P̂) that (4α, 6β)-probabilistically represents C, where Ĥ ⊆ H , and\n∣∣∣Ĥ ∣∣∣ = 3d\n4αβ2\n( size(H ) + ln( 1\nβ )\n) .\nProof. Let (H ,P) be an (α, β)-probabilistic representation for a class C. Set m = 3α(size(H ) + ln( 1β )). By Claim 4.3, Learner(H ,P,m, 2α) is 2β-successful for class C. By Claim 4.4, there exists an Ĥ ⊆ H and a distribution P̂ on it, such that Learner(Ĥ , P̂ ,m, 2α) is a (4α, 6β)-PAC learner\nfor C and ∣∣∣Ĥ ∣∣∣ = d·m4β2 = 3d4αβ2 (size(H ) + ln( 1β )). Assume towards contradiction that (Ĥ , P̂) does not (4α, 6β)-represent C. So, there exist a concept c ∈ C and a distribution D s.t., with probability strictly greater than 6β, a randomly chosen Hi ∈P̂ Ĥ does not contain a 4α-good hypothesis for c,D. Therefore, for those c and D, Learner(Ĥ , P̂ ,m, 2α) will fail to return a 4α-good hypothesis with probability strictly greater than 6β.\nTheorem 4.6. For every class C over Xd there exists a 1 4-representation B such that size(B) = O(ln(d) + RepDim(C)).\nProof. By Lemma 3.18, there exists a pair (H ,P) that ( 116 , 1 12)-probabilistically represents C such that size(H ) = O(RepDim(C)). Using Theorem 4.5, there exists a pair (Ĥ , P̂) that (14 , 1 2)- probabilistically represents C, such that size(Ĥ ) = size(H ) and\n∣∣∣Ĥ ∣∣∣ = O (d · size(H )) .\nWe can now use Observation 4.1 and construct the set B = ⋃\nHi∈ Ĥ Hi which is a 1 4 -representation\nfor the class C. In addition,\n|B| = O (∣∣∣Ĥ ∣∣∣ · esize(H ) ) = O ( d · size(H ) · esize(H ) ) .\nThus, size(B) = ln |B| = O (ln(d) + RepDim(C)).\nCorollary 4.7. For every concept class C over Xd, DRepDim(C) = O(ln(d) + RepDim(C)).\nCorollary 4.8. There exists a constant N s.t. for every concept class C over Xd where DRepDim(C) ≥ N log(d), the sample complexity that is necessary and sufficient for privately learning C is Θα,β(DRepDim(C))."
    }, {
      "heading" : "5 Probabilistic Representation for Privately Solving Optimiza-",
      "text" : "tion Problems\nThe notion of probabilistic representation applies not only to private learning, but also to a broader task of optimization problems. We consider the following scenario:\nDefinition 5.1. An optimization problem OPT over a universe X and a set of solutions F is defined by a quality function q : X∗ × F → [0, 1]. Given a database S, the task is to choose a solution f ∈ F such that q(S, f) is maximized.\nNotation. We will refer to the optimization problem defined by a quality function q as OPTq.\nDefinition 5.2. An α-good solution for a database S is a solution s such that q(S, s) ≥ maxf∈F{q(S, f)}− α.\nGiven an optimization problem OPTq, one can use the exponential mechanism to choose a solution s ∈ F . In general, this method achieves a reasonable solution only for databases of size Ω(log |F|/ǫ). To see this, consider a case where there exists a database S of m records such that exactly one solution t ∈ F has a quality of q(S, t) = 1, and every other f ∈ F has a quality of q(S, f) = 1/2. The probability of the exponential mechanism choosing t is:\nPr[t is chosen] = exp(ǫm/2)\n(|F| − 1) · exp(ǫm/4) + exp(ǫm/2) .\nUnless\nm ≥ 4ǫ ln(|F| − 1) = Ω( 1 ǫ ln |F|), (4)\nthe above probability is strictly less than 1/2. Using our notations of probabilistic representation, it might be possible to reduce the necessary database size.\nConsider using the exponential mechanism for choosing a solution s, not out of F , but rather from a smaller set of solutions B. Roughly speaking, the factor of ln |F| in requirement (4) will now be replaced with ln |B|, which corresponds to size of the representation. Therefore, the database size m should be at least ln |B|/ǫ. So m needs to be bigger than the size of the representation by at least a factor of 1/ǫ.\nIn the following analysis we will denote this required gap, i.e., m/ ln |B|, as ∆. We will see that the existence of a private approximation algorithm implies a probabilistic representation with 1 < ∆ ≈ 1ǫ , and that a probabilistic representation with ∆ > 1 implies a private approximation algorithm. Bigger ∆ corresponds to better privacy; however, it might be harder to achieve.\nDefinition 5.3. Let OPTq be an optimization problem over a universe X and a set of solutions F . Let B be a set of solutions, and denote size(B) = ln |B|. We say that B is an α-deterministic representation of OPTq for databases of m elements if for every S ∈ X\nm there exists a solution s ∈ B such that q(S, s) ≥ maxf∈F{q(S, f)} − α.\nDefinition 5.4. Let B be an α-deterministic representation of OPTq for databases of m elements. Denote ∆ , msize(B) . If ∆ > 1, then we say that the ratio of B is ∆.\nAn α-deterministic representation B with ratio ∆ is required to support all the databases of m = ∆ · size(B) elements. That is, for every S ∈ Xm, the set B is required to contain at least one α-good solution.\nFix S ∈ Xm. Intuitively, ∆ controls the ratio between m and number of bits needed to represent an α-good solution for S. As B contains an α-good solution for S, and assuming B is publicly known, this solution could be represented with ln |B| = size(B) = m/∆ bits.\nDefinition 5.5. Let OPTq be an optimization problem over a universe X and a set of solutions F . Let P be a distribution over {1, 2, . . . , r}, and let B = {B1,B2, . . . ,Br} be a family of solution sets for OPTq. We denote size(B) = max{ ln |Bi| : Bi ∈ B }. We say that (B,P) is an (α, β)probabilistic representation of OPTq for databases of m elements if for every S ∈ X m:\nPr P\n[ ∃s ∈ Bi s.t. q(S, s) ≥ max\nf∈F {q(S, f)} − α\n] ≥ 1− β.\nDefinition 5.6. Let (B,P) be an (α, β)-probabilistic representation of OPTq for databases of m elements. Denote ∆ , msize(B) . If ∆ > 1, then we say that the ratio of the representation is ∆. Definition 5.7. An optimization problem OPTq is bounded if ∣∣∣|S1| · q(S1, f)− |S2| · q(S2, f)\n∣∣∣ ≤ 1 for every solution f and every two neighboring databases S1, S2.\nWe are interested in approximating bounded optimization problems, while guaranteeing differential privacy:\nDefinition 5.8. Let OPTq be a bounded optimization problem over a universe X and a set of solutions F . An algorithm A is an (α, β, ǫ)-private approximation algorithm for OPTq with a database of m records if:\n1. Algorithm A is ǫ-differentially private (as formulated in Definition 2.1);\n2. For every S ∈ Xm, algorithm A outputs with probability at least (1−β) a solution s such that q(S, s) ≥ maxf∈F{q(S, f)} − α.\nExample 5.9 (Sanitization). Consider a class of predicates C over X. A database S contains points taken from X. A predicate query Qc for c ∈ C is defined as Qc(S) = 1 |S| · |{xi ∈ S : c(xi) = 1}|. Blum et al. [6] defined a sanitizer (or data release mechanism) as a differentially private algorithm that, on input a database S, outputs another database Ŝ with entries taken from X. A sanitizer A is (α, β)-useful for predicates in the class C if for every database S it holds that\nPr A\n[ ∀c ∈ C ∣∣Qc(S)−Qc(Ŝ) ∣∣ ≤ α ] ≥ 1− β.\nThis scenario can be viewed as a bounded optimization problem: The solutions are sanitized databases. For an input database S and and a sanitized database Ŝ, the quality function is\nq(S, Ŝ) = 1−max c∈C\n{ |Qc(S)−Qc(Ŝ)| } .\nTo see that this optimization problem is bounded, note that for every two neighboring databases S1, S2 of m elements, and every c ∈ C it holds that |Qc(S1) − Qc(S2)| ≤ 1 m . Therefore, for every sanitized database f ,\nm · |q(S1, f)− q(S2, f)| = m · ∣∣∣∣maxc∈C {|Qc(S1)−Qc(f)|} −maxc∈C {|Qc(S2)−Qc(f)|} ∣∣∣∣ ≤ 1\nThe next two lemmas establish an equivalence between a private approximation algorithm and a probabilistic representation for a bounded optimization problem.\nLemma 5.10. Let OPTq be a bounded optimization problem over a universe X. If there exists a pair (B,P) that (α, β)-probabilistically represents OPTq for databases of m elements, s.t. the ratio of (B,P) is ∆ > 1, then for every α̂, β̂, ǫ satisfying\n∆ ≥ 2\nǫα̂\n( 1 + ln(1/β̂)\nsize(B)\n) ,\nthere exists an ( (α+ α̂), (β + β̂), ǫ ) -approximation algorithm for OPTq with a database of size m.\nProof. Consider the following algorithm A:\nInputs: a database S ∈ Xm, and a privacy parameter ǫ.\n1. Randomly choose Bi ∈P B.\n2. Choose s ∈ Bi using the exponential mechanism, that is, with probability\nexp(ǫ ·m · q(S, s)/2)∑ f∈Bi exp(ǫ ·m · q(S, f)/2) .\nBy the properties of the exponential mechanism, A is ǫ-differentially private. Fix a database S ∈ Xm, and define the following 2 bad events:\nE1 The set Bi chosen in step 1 does not contain a solution s s.t. q(S, s) ≥ maxf∈F{q(S, f)} −α.\nE2 The solution s chosen in step 2 is such that q(S, s) < maxt∈Bi q(S, t)− α̂.\nNote that if those two bad events do not occur, algorithm A outputs a solution s such that q(S, s) ≥ maxf∈F{q(S, f)}−α− α̂. As (B,P) is an (α, β)-probabilistic representation of OPTq for databases of size m, event E1 happens with probability at most β. By the properties of the exponential mechanism, the probability of event E2 is bounded by |Bi| · exp(−ǫmα̂/2). As m = ∆size(B), this probability is at most\nPr[E2] ≤ size(B) · exp(−ǫmα̂/2)\n= size(B) · exp(−ǫ∆size(B)α̂/2)\n≤ size(B) · exp ( − ( 1 + ln(1/β̂)\nsize(B)\n) size(B) )\n= size(B) · exp(− size(B)− ln(1/β̂)) = β̂.\nTherefore, algorithm A outputs an (α+α̂)-good solution with probability at least (1−β−β̂).\nLemma 5.11. Let OPTq be an optimization problem. If there exists an (α, β, ǫ)-private approximation algorithm for OPTq with a database of m records, then for every β̂ satisfying\n∆ , m\nln( 11−β ) + ln ln( 1 β̂ ) +m · ǫ\n> 1,\nthere exists a pair (B,P) that (α, β̂)-probabilistically represents OPTq for databases of m elements, where the ratio of the representation is ∆.\nProof. Let A be an (α, β, ǫ)-private approximation algorithm for OPTq, with a sample size m. Fix an arbitrary input database S ∈ Xm. Define G as the set of all solutions s, possibly outputted by A, such that q(S, s) ≥ maxf∈F{q(S, f)} − α. As A is an (α, β, ǫ)-approximation algorithm,\nPrA [A(S) ∈ G] ≥ 1−β. As A is ǫ-differentially private, PrA\n[ A(~0) ∈ G ] ≥ (1−β)e−mǫ, where ~0 is a\ndatabase withm zeros. That is, PrA\n[ A(~0) /∈ G ] ≤ 1−(1−β)e−mǫ. Now, consider a set B containing\nthe outcomes of Γ , 11−β ln( 1 β̂ )emǫ executions of A(~0). The probability that B does not contain a solutions s ∈ G is at most (1−(1−β)e−mǫ)Γ ≤ β̂. Thus, B = {B ⊆ support(A) : |B| ≤ Γ}, and P, the distribution induced by A(~0), are an (α, β̂)-probabilistic representation of OPTq for databases with m elements. Moreover, the ratio of the representation is\nm\nsize(B) =\nm\nmax{ ln |B| : B ∈ B }\n= m\nln( 11−β ) + ln ln( 1 β̂ ) +mǫ\n= ∆."
    }, {
      "heading" : "5.1 Exact 3SAT",
      "text" : "Consider the following bounded optimization problem, denoted as OPTE3SAT: The universe X is the set of all possible clauses with exactly 3 different literals over n variables, and the set of solutions F is the set of all possible 2n assignments. Given a database S = (σ1, σ2, . . . , σm) containing m E3CNF clauses, the quality of an assignment a ∈ F is\nq(S, a) = |{i : a(σi) = 1}|\nm .\nAiming at the (very different) objective of secure protocols for search problems, Beimel et al. [2] defined the notation of solution-list algorithms, which corresponds to our notation of deterministic representation. We next rephrase their results using our notations.\nR1 For every α > 0 and every ∆ > 1, there exists a set B that (α + 1/8)-deterministically represents OPTE3SAT for databases of size m = O ( ∆(ln ln(n) + ln(1/α) ) ), and a ratio of ∆.\nR2 Let α < 1/2 and ∆ > 1. For every set B that α- deterministically represents OPTE3SAT for databases of size m with a ratio of ∆, it holds that m = Ω ( ln ln(n) ) .\nUsing (R1) and a deterministic version of Lemma 5.10, for every α, β, ǫ > 0, there exists an( (1/8 + α), β, ǫ ) - approximation algorithm for OPTE3SAT with a database of m = Oα,β,ǫ(ln ln(n)) clauses. By (R2), this is the best possible using a deterministic representation. We can reduce the necessary database size, using a probabilistic representation. Fix a clause with three different literals. If we pick an assignment at random, then with probability at least 7/8 it satisfies the clause. Now, fix any exact 3CNF formula. If we pick an assignment at random, then the expected fraction of satisfied clauses is at least 7/8. Moreover, for every 0 < α < 7/8, the fraction of satisfied clauses is at least (7/8 − α) with probability at least αα+1/8 . So, if we pick t = ln(1/β)ln(α+1/8)+ln(1/α) random assignments, the probability that none of them will satisfy at least (7/8 − α)m clauses is at most (\nα α+1/8\n)t = β. So, for every ∆ > 1,\nB = {B : B is a set of at most t assignments},\nand P, the distribution induced on B by randomly picking t assignments, are an ( (1/8 + α), β ) - probabilistic representation of OPTE3SAT for databases of size ∆ · ln(t) and a ratio of ∆. By Lemma 5.11, for every ǫ there exists an ( (1/8 + α), β, ǫ ) -approximation algorithm for OPTE3SAT with a database of m = oα,β,ǫ(1) clauses."
    }, {
      "heading" : "6 Extensions",
      "text" : ""
    }, {
      "heading" : "6.1 (ǫ, δ)-Differential Privacy",
      "text" : "The notation of ǫ-differential privacy was generalized to (ǫ, δ)-differential privacy, where the requirement in inequality (1) is changed to\nPr[A(S1) ∈ F ] ≤ exp(ǫ) · Pr[A(S2) ∈ F ] + δ.\nThe proof of Lemma 3.16 remains valid even if algorithm A is only (ǫ, δ)-differential private for\nδ ≤ 18e −8αǫm(1− e−ǫ). (5)\nTo see this, note that inequality (3) changes to\nPr A\n[ A(~0) ∈ G ] ≥\n≥ ((( Pr A [A(S) ∈ G] · e−ǫ − δ ) e−ǫ − δ ) · · · ) e−ǫ − δ\n≥ 1\n4 e−8αǫm − δ\n( 8αm−1∑\ni=0\ne−iǫ\n)\n≥ 1\n4 e−8αǫm − δ\n( 1\n1− e−ǫ\n) ≥ 1\n8 e−8αǫm.\nThe rest of the proof remains almost intact (only minor changes in the constants). With that in mind, we see that the lower bound showed in Theorem 3.19 for ǫ-differentially private (that is, with δ = 0) learners also applies for (ǫ, δ)-differentially private learners satisfying inequality (5). That\nis, every such learner for a class C must use Ω ( RepDim(C)\nαǫ\n) samples.\nWhen using (ǫ, δ)-differential privacy, δ should be negligible in the security parameter, that is, in d – the representation length of elements in Xd. Therefore, using (ǫ, δ)-differential privacy instead of ǫ-differential privacy cannot reduce the sample complexity for PPAC learning a concept class C whenever RepDim(C) = O (log(d))."
    }, {
      "heading" : "6.2 Probabilistic Representation Using a Hypothesis Class",
      "text" : "We will now consider a generalization of our representation notations that can be useful when considering PPAC learners that use a specific hypothesis class. In particular, those notation can be useful when considering proper-PPAC learners, that is, a learner that learns a class C using a hypothesis class B ⊆ C.\nDefinition 6.1. We define the α-Deterministic Representation Dimension of a concept class C using a hypothesis class B as\nDRepDimα(C,B) = min   size(H) : H ⊆ B is an α-representation for class C    .\nNote that DRepDim 1 4 (C, 2Xd) = DRepDim(C). The dependency on α in the above definition is necessary: if C is not contained in B then for every small enough α, the hypothesis class B itself does not α-represents C (and therefore no subset H ⊆ B can α-represent C). Moreover, when considering the notations of representation using a hypothesis class, our boosting technique for α does not work (as the boosting uses more complex hypotheses).\nExample 6.2. Beimel et al. [3] showed that for every α < 1, every subset H ( POINTd does not α-represent the class POINTd. Therefore, DRepDimα(POINTd, POINTd) = θ(d) for every α < 1.\nDefinition 6.3. A pair (H ,P) is an (α, β)-probabilistic representation for a concept class C using a hypothesis class B if:\n1. (H ,P) is an (α, β)-probabilistic representation for the class C, as formulated in Definition 3.6.\n2. Every Hi ∈ H is a subset of B.\nNote that whenever B = 2Xd , this definition is identical to Definition 3.6. Using this general notation, we can restate Lemma 3.12 and Lemma 3.16 as follows:\nLemma 6.4. If there exists a pair (H ,P) that (α, β)- probabilistically represents a class C using a hypothesis class B, then for every ǫ and every γ there exists an algorithm A that (α+γ, 3β, ǫ)-PPAC learns C using B and a sample size m = O((size(H ) + ln( 1β ))max{ 1 γǫ , 1 γ2 }).\nNote that in the above lemma the resulting algorithm A has accuracy (α+ γ) as opposed to 6α in lemma 3.12, where γ is arbitrary. While in section 3 we did not mind the multiplicative factor of 6 in the accuracy parameter (as we could boost it back), replacing it with an additive factor of γ might be of value in this section as our boosting technique for the accuracy parameter does not work here. As an example, consider a representation with α = 110 . Without boosting capabilities, this change makes the difference between the ability to generate an algorithm with α = 610 , or an algorithm with α = 110 + 1 1000 .\nProof. Let (H ,P) be an (α, β)-probabilistic representation for class C using a hypothesis class B, and consider the following algorithm A:\nInputs: S = (xi, yi) m i=1, and a privacy parameter ǫ.\n1. Randomly choose Hi ∈P H . 2. Choose h ∈ Hi using the exp. mechanism with ǫ.\nFirst note that the support of A is indeed (a subset of) B. By the properties of the exponential mechanism, A is ǫ-differentially private. Fix some c ∈ C and D, and define the following 3 good events:\nE1 Hi chosen in step 1 contains at least one hypothesis h s.t. errorD(h) ≤ α.\nE2 For every h ∈ Hi it holds that |errorS(h)− errorD(c, h)| ≤ γ 3 .\nE3 The exponential mechanism chooses an h such that errorS(h) ≤ γ 3 +minf∈Hi {errorS(f)}.\nNote that if those 3 good events happen, algorithm A returns an (α+ γ)-good hypothesis. We will now show that those 3 events happen with high probability.\nAs (H ,P) is an (α, β)-probabilistic representation for the class C, event E1 happens with probability at least 1− β.\nUsing the Hoeffding bound, event E2 happens with probability at leat 1 − 2|Hi| exp(− 2 9γ 2m).\nFor m ≥ 9 2γ2 ln(2|Hi|β ), this probability is at leat 1− β.\nThe exponential mechanism ensures that the probability of event E3 is at least 1 − |Hi| ·\nexp(−ǫγm/6) (see Section 2.4), which is at least (1− β) for m ≥ 6γǫ ln( |Hi| β ).\nAll in all, by setting m = 6(size(H ) + ln( 2β ))max{ 1 γ2 , 1γǫ} we ensure that the probability of A\nfailing to output an (α+ γ)-good hypothesis is at most 3β.\nLemma 6.5. If there exists an algorithm A that (α, 12 , ǫ)-PPAC learns a concept class C using a hypothesis class B and a sample size m, then there exists a pair (H ,P) that (α, 1/4)-probabilistically represents the class C using the hypothesis class B where size(H ) = O (mǫ).\nThe proof of Lemma 6.5 is identical to the proof of Lemma 3.15.\nDefinition 6.6. We define the α-Probabilistic Representation Dimension of a concept class C using a hypothesis class B as\nRepDimα(C,B) = min    size(H ) : ∃P s.t. (H ,P) is an (α, 14)-prob. representation for C using B    .\nExample 6.7. Beimel et al. [3] showed that for every α < 1, every proper-PPAC learner for POINTd requires Ω((d+log(1/β))/(ǫα)) labled examples. Using Lemma 6.4, we get that RepDimα(POINTd, POINTd) = Ω(d).\nWe still do not know the relation between the representation dimension of a concept class and its VC dimension. However, the above example shows a strong separation between the VC dimension of the class POINTd and RepDimα(POINTd, POINTd)."
    }, {
      "heading" : "7 A Probabilistic Representation for Points",
      "text" : "Example 3.8 states the existence of a constant size probabilistic representation for the class POINTd. We now give the construction.\nClaim 7.1. There exists an (α, β)-probabilistic representation for POINTd of size ln(4/α)+ln ln(1/β). Furthermore, each hypothesis h in each Hi has a short description and given x, the value h(x) can be computed efficiently.\nProof. Consider the following set of hypothesis classes\nH = { H ⊆ 2Xd : |H| ≤ 4\nα ln(\n1 β )\n} .\nThat is, H ∈ H if H contains at most 4α ln( 1 β ) boolean functions. We will show an appropriate distribution P s.t. (H ,P) is an (α, β)-probabilistic representation of the class POINTd. To this end, fix a target concept cj ∈ POINTd and a distribution D on Xd (remember that j is the unique point on which cj(j) = 1). We need to show how to randomly choose an H ∈R H such that with probability at least (1 − β) over the choice of H, there will be at least one h ∈ H such that errorD(cj , h) ≤ α. Consider the following process for randomly choosing an H ∈ H :\n1. Denote M = 4α ln( 1 β ) 2. For i = 1, . . . ,M construct hypothesis hi as follows: For each x ∈ Xd (independently):\nLet hi(x) = 1 with probability α/2, and hi(x) = 0 otherwise.\n3. Return H = {h1, h2, . . . , hM}.\nThe above process induces a distribution on H , denoted as P. We will next analyze the probability that the returned H does not contain an α-good hypothesis. We start by fixing some i and analyzing the expected error of hi, conditioned on the event that hi(j) = 1. The probability is taken over the random coins used to construct hi.\nE hi\n[ errorD(cj , hi) ∣∣∣ hi(j) = 1 ] =\n= E hi\n[ E\nx∈D\n[ ∣∣cj(x)− hi(x) ∣∣ ] ∣∣∣ hi(j) = 1 ]\n= E x∈D [ E hi [ ∣∣cj(x)− hi(x) ∣∣ ∣∣∣ hi(j) = 1 ]] ≤ α 2 .\nUsing Markov’s Inequality,\nPr hi\n[ errorD(cj , hi) ≥ α ∣∣∣∣ hi(j) = 1 ] ≤ 1\n2 .\nSo, the probability that hi is α-good for cj and D is:\nPr hi [errorD(cj , hi) ≤ α] ≥\n≥ Pr hi [hi(j) = 1] · Pr hi\n[ errorD(cj , hi) ≤ α ∣∣∣∣ hi(j) = 1 ]\n≥ α 2 · 1 2 = α 4 .\nThus, the probability that H fails to contain an α-good hypothesis is at most ( 1− α4 )M , which is less than β for our choice of M . This concludes the proof that (H ,P) is an (α, β)-probabilistic representation for POINTd.\nWhen a hypothesis hi() was constructed in the above random process, the value of hi(x) was independently drawn for every x ∈ Xd. This results in a hypothesis whose description size is O(2\nd), which in turn, will result in a non efficient learning algorithm. We next construct hypotheses whose description is short. To achieve this goal, we note that in the above analysis we only care about the probability that hi(x) = 0 given that hi(j) = 1. Thus, we can choose the values of hi in a pairwise independent way, e.g., using a random polynomial of degree 2. The size of the description in this case is O(d).\nObservation 7.2. Consider the class POINTN, defined in Example 3.14. The above construction can be adjusted to yield an (inefficient) improper private learner for POINTN with Oα,β,ǫ(1) samples. The only adjustments necessary are in the construction of the (α, β)-probabilistic representation. Specifically, we need to specify how to randomly draw a boolean function h over the natural numbers, such that for every x ∈ N the probability of h(x) = 1 is α/2, and the values of h on every two distinct points in N are independent. This can be done easily, as a random real number could be interpreted as a random function over N."
    } ],
    "references" : [ {
      "title" : "Bounds on the sample complexity for private learning and private data release",
      "author" : [ "A. Beimel", "H. Brenner", "S.P. Kasiviswanathan", "K. Nissim" ],
      "venue" : "Machine learning",
      "citeRegEx" : "1",
      "shortCiteRegEx" : null,
      "year" : 2013
    }, {
      "title" : "Private approximation of search problems",
      "author" : [ "A. Beimel", "P. Carmi", "K. Nissim", "E. Weinreb" ],
      "venue" : "SIAM J. Comput., 38(5):1728–1760",
      "citeRegEx" : "2",
      "shortCiteRegEx" : null,
      "year" : 2008
    }, {
      "title" : "Bounds on the sample complexity for private learning and private data release",
      "author" : [ "A. Beimel", "S.P. Kasiviswanathan", "K. Nissim" ],
      "venue" : "TCC, volume 5978 of LNCS, pages 437–454. Springer",
      "citeRegEx" : "3",
      "shortCiteRegEx" : null,
      "year" : 2010
    }, {
      "title" : "Characterizing the sample complexity of private learners",
      "author" : [ "A. Beimel", "K. Nissim", "U. Stemmer" ],
      "venue" : "ITCS, pages 97–110",
      "citeRegEx" : "4",
      "shortCiteRegEx" : null,
      "year" : 2013
    }, {
      "title" : "Practical privacy: The SuLQ framework",
      "author" : [ "A. Blum", "C. Dwork", "F. McSherry", "K. Nissim" ],
      "venue" : "PODS, pages 128–138. ACM",
      "citeRegEx" : "5",
      "shortCiteRegEx" : null,
      "year" : 2005
    }, {
      "title" : "A learning theory approach to non-interactive database privacy",
      "author" : [ "A. Blum", "K. Ligett", "A. Roth" ],
      "venue" : "STOC, pages 609–618. ACM",
      "citeRegEx" : "6",
      "shortCiteRegEx" : null,
      "year" : 2008
    }, {
      "title" : "Learnability and the Vapnik- Chervonenkis dimension",
      "author" : [ "A. Blumer", "A. Ehrenfeucht", "D. Haussler", "M.K. Warmuth" ],
      "venue" : "ACM, 36(4):929–965",
      "citeRegEx" : "7",
      "shortCiteRegEx" : null,
      "year" : 1989
    }, {
      "title" : "Sample complexity bounds for differentially private learning",
      "author" : [ "K. Chaudhuri", "D. Hsu" ],
      "venue" : "COLT, 19:155–186",
      "citeRegEx" : "8",
      "shortCiteRegEx" : null,
      "year" : 2011
    }, {
      "title" : "A measure of asymptotic efficiency for tests of a hypothesis based on the sum of observations",
      "author" : [ "H. Chernoff" ],
      "venue" : "Ann. Math. Statist., 23:493–507",
      "citeRegEx" : "9",
      "shortCiteRegEx" : null,
      "year" : 1952
    }, {
      "title" : "The differential privacy frontier",
      "author" : [ "C. Dwork" ],
      "venue" : "O. Reingold, editor, TCC, volume 5444 of LNCS, pages 496–502. Springer",
      "citeRegEx" : "10",
      "shortCiteRegEx" : null,
      "year" : 2009
    }, {
      "title" : "A firm foundation for private data analysis",
      "author" : [ "C. Dwork" ],
      "venue" : "Commun. of the ACM, 54(1):86–95",
      "citeRegEx" : "11",
      "shortCiteRegEx" : null,
      "year" : 2011
    }, {
      "title" : "Calibrating noise to sensitivity in private data analysis",
      "author" : [ "C. Dwork", "F. McSherry", "K. Nissim", "A. Smith" ],
      "venue" : "S. Halevi and T. Rabin, editors, TCC, volume 3876 of LNCS, pages 265–284. Springer",
      "citeRegEx" : "12",
      "shortCiteRegEx" : null,
      "year" : 2006
    }, {
      "title" : "Boosting and differential privacy",
      "author" : [ "C. Dwork", "G.N. Rothblum", "S.P. Vadhan" ],
      "venue" : "FOCS, pages 51–60",
      "citeRegEx" : "13",
      "shortCiteRegEx" : null,
      "year" : 2010
    }, {
      "title" : "A general lower bound on the number of examples needed for learning",
      "author" : [ "A. Ehrenfeucht", "D. Haussler", "M.J. Kearns", "L.G. Valiant" ],
      "venue" : "Inf. Comput., 82(3):247–261",
      "citeRegEx" : "14",
      "shortCiteRegEx" : null,
      "year" : 1989
    }, {
      "title" : "A decision-theoretic generalization of on-line learning and an application to boosting",
      "author" : [ "Y. Freund", "R.E. Schapire" ],
      "venue" : "Journal of Computer and System Sciences, 55(1):119 – 139",
      "citeRegEx" : "15",
      "shortCiteRegEx" : null,
      "year" : 1997
    }, {
      "title" : "Probability inequalities for sums of bounded random variables",
      "author" : [ "W. Hoeffding" ],
      "venue" : "Journal of the American Statistical Association, 58(301):13–30",
      "citeRegEx" : "16",
      "shortCiteRegEx" : null,
      "year" : 1963
    }, {
      "title" : "What can we learn privately? SIAM J",
      "author" : [ "S.P. Kasiviswanathan", "H.K. Lee", "K. Nissim", "S. Raskhodnikova", "A. Smith" ],
      "venue" : "Comput., 40(3):793–826",
      "citeRegEx" : "17",
      "shortCiteRegEx" : null,
      "year" : 2011
    }, {
      "title" : "Mechanism design via differential privacy",
      "author" : [ "F. McSherry", "K. Talwar" ],
      "venue" : "FOCS, pages 94–103. IEEE",
      "citeRegEx" : "18",
      "shortCiteRegEx" : null,
      "year" : 2007
    }, {
      "title" : "The strength of weak learnability",
      "author" : [ "R.E. Schapire" ],
      "venue" : "Mach. Learn., 5(2):197–227",
      "citeRegEx" : "19",
      "shortCiteRegEx" : null,
      "year" : 1990
    }, {
      "title" : "A theory of the learnable",
      "author" : [ "L.G. Valiant" ],
      "venue" : "Communications of the ACM, 27:1134–1142",
      "citeRegEx" : "20",
      "shortCiteRegEx" : null,
      "year" : 1984
    }, {
      "title" : "On the uniform convergence of relative frequencies of events to their probabilities",
      "author" : [ "V.N. Vapnik", "A.Y. Chervonenkis" ],
      "venue" : "Theory of Probability and its Applications, 16:264",
      "citeRegEx" : "21",
      "shortCiteRegEx" : null,
      "year" : 1971
    } ],
    "referenceMentions" : [ {
      "referenceID" : 16,
      "context" : "defined private learning as a combination of PAC learning and differential privacy [17].",
      "startOffset" : 83,
      "endOffset" : 87
    }, {
      "referenceID" : 3,
      "context" : "A preliminary version of this paper appeared in [4].",
      "startOffset" : 48,
      "endOffset" : 51
    }, {
      "referenceID" : 16,
      "context" : "[17] defined in 2008 private learning as a combination of probably approximately correct (PAC) learning [20] and differential privacy [12].",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 19,
      "context" : "[17] defined in 2008 private learning as a combination of probably approximately correct (PAC) learning [20] and differential privacy [12].",
      "startOffset" : 104,
      "endOffset" : 108
    }, {
      "referenceID" : 11,
      "context" : "[17] defined in 2008 private learning as a combination of probably approximately correct (PAC) learning [20] and differential privacy [12].",
      "startOffset" : 134,
      "endOffset" : 138
    }, {
      "referenceID" : 9,
      "context" : "We refer the reader to surveys of Dwork [10, 11].",
      "startOffset" : 40,
      "endOffset" : 48
    }, {
      "referenceID" : 10,
      "context" : "We refer the reader to surveys of Dwork [10, 11].",
      "startOffset" : 40,
      "endOffset" : 48
    }, {
      "referenceID" : 20,
      "context" : "It is well known that the sample complexity of learning a concept class C (non-privately) is proportional to a complexity measure of the class C knowns as the VC-dimension [21, 7, 14].",
      "startOffset" : 172,
      "endOffset" : 183
    }, {
      "referenceID" : 6,
      "context" : "It is well known that the sample complexity of learning a concept class C (non-privately) is proportional to a complexity measure of the class C knowns as the VC-dimension [21, 7, 14].",
      "startOffset" : 172,
      "endOffset" : 183
    }, {
      "referenceID" : 13,
      "context" : "It is well known that the sample complexity of learning a concept class C (non-privately) is proportional to a complexity measure of the class C knowns as the VC-dimension [21, 7, 14].",
      "startOffset" : 172,
      "endOffset" : 183
    }, {
      "referenceID" : 16,
      "context" : "[17] proved that a private learner exists for every finite concept class.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 16,
      "context" : "The VC-dimension of a concept class is bounded by this quantity (and significantly lower for some interesting concept classes), and hence the results of [17] left open the possibility that the sample complexity of private learning may be significantly higher than that of non-private learning.",
      "startOffset" : 153,
      "endOffset" : 157
    }, {
      "referenceID" : 6,
      "context" : "Recall that the sample complexity of non-private learners for a class of functions C is proportional to the VC-dimension of the class [7, 14] – a combinatorial measure of the class that is equal to the size of the largest set of inputs that is shattered by the class.",
      "startOffset" : 134,
      "endOffset" : 141
    }, {
      "referenceID" : 13,
      "context" : "Recall that the sample complexity of non-private learners for a class of functions C is proportional to the VC-dimension of the class [7, 14] – a combinatorial measure of the class that is equal to the size of the largest set of inputs that is shattered by the class.",
      "startOffset" : 134,
      "endOffset" : 141
    }, {
      "referenceID" : 16,
      "context" : "[17] showed, informally, that every finite concept class C can be learned privately (ignoring computational complexity).",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 17,
      "context" : "Their construction is based on the exponential mechanism of McSherry and Talwar [18], and the O(ln |C|) bound on sample complexity results from the union bound argument used in the analysis of the exponential mechanism.",
      "startOffset" : 80,
      "endOffset" : 84
    }, {
      "referenceID" : 4,
      "context" : "[5] for all concept classes that can be efficiently learned in the statistical queries model.",
      "startOffset" : 0,
      "endOffset" : 3
    }, {
      "referenceID" : 16,
      "context" : "[17] showed an example of a concept",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 2,
      "context" : "[3] studied the sample complexity of private learning.",
      "startOffset" : 0,
      "endOffset" : 3
    }, {
      "referenceID" : 7,
      "context" : "Chaudhuri and Hsu [8] studied the sample complexity needed for private learning infinite concept classes when the data is drawn from a continuous distribution.",
      "startOffset" : 18,
      "endOffset" : 21
    }, {
      "referenceID" : 16,
      "context" : "[17] do not extend to infinite hypothesis classes.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 7,
      "context" : "Chaudhuri and Hsu [8] also study learning algorithms that are only required to protect the privacy of the labels (and do not necessarily protect the privacy of the examples themselves).",
      "startOffset" : 18,
      "endOffset" : 21
    }, {
      "referenceID" : 18,
      "context" : "A line of research (started in [19]) that is very relevant to our paper is boosting learning algorithms, that is, taking learning algorithms that have a big classification error and producing a learning algorithm with small error.",
      "startOffset" : 31,
      "endOffset" : 35
    }, {
      "referenceID" : 12,
      "context" : "[13] show how to privately boost accuracy, that is, given a private learning algorithms that have a big classification error, they produce a private learning algorithm with small error.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 2,
      "context" : "[3] showed how to use a representation of a class to privately learn it.",
      "startOffset" : 0,
      "endOffset" : 3
    }, {
      "referenceID" : 2,
      "context" : "This results in a private learning algorithm with sample complexity O(1), matching a different private algorithm for POINTd presented in [3].",
      "startOffset" : 137,
      "endOffset" : 140
    }, {
      "referenceID" : 2,
      "context" : "Our new algorithm offers some improvement in the sample complexity compared to the algorithm of [3] when considering the learning and privacy parameters.",
      "startOffset" : 96,
      "endOffset" : 99
    }, {
      "referenceID" : 2,
      "context" : "Furthermore, our algorithm can be made computationally efficient without making any computational hardness assumptions, while the efficient version in [3] assumes the existence of one-way functions.",
      "startOffset" : 151,
      "endOffset" : 154
    }, {
      "referenceID" : 2,
      "context" : "Finally, it is conceptually simpler and in particular it avoids the sub-sampling technique used in [3].",
      "startOffset" : 99,
      "endOffset" : 102
    }, {
      "referenceID" : 0,
      "context" : "We consider a scenario where there is a domain X, a database S of m records, each taken from the domain X, a set of solutions F , and a quality function q : X∗ ×F → [0, 1] that we wish to maximize.",
      "startOffset" : 165,
      "endOffset" : 171
    }, {
      "referenceID" : 1,
      "context" : "Interestingly, a similar notion to representation, called “solution list algorithms”, was considered in [2] for constructing secure protocols for search problems while leaking only a few bits on the input.",
      "startOffset" : 104,
      "endOffset" : 107
    }, {
      "referenceID" : 1,
      "context" : "First, an example inspired by [2]: each record in the database is a clause with exactly 3 literals and we want to find an assignment satisfying at least 7/8 fraction of the clauses while protecting the privacy of the clauses.",
      "startOffset" : 30,
      "endOffset" : 33
    }, {
      "referenceID" : 1,
      "context" : "A construction of [2] yields a deterministic representation for this problem where the size of the database can be much smaller.",
      "startOffset" : 18,
      "endOffset" : 21
    }, {
      "referenceID" : 16,
      "context" : "By [17], there is a private learning algorithm for C whose sample size is O(d·VC(C)), thus, the probabilistic representation dimension of C is O(d ·VC(C)).",
      "startOffset" : 3,
      "endOffset" : 7
    }, {
      "referenceID" : 0,
      "context" : "A candidate for such separation appears in [1].",
      "startOffset" : 43,
      "endOffset" : 46
    }, {
      "referenceID" : 11,
      "context" : "1 (Differential Privacy [12]).",
      "startOffset" : 24,
      "endOffset" : 28
    }, {
      "referenceID" : 19,
      "context" : "3 (PAC Learning [20]).",
      "startOffset" : 16,
      "endOffset" : 20
    }, {
      "referenceID" : 16,
      "context" : "5 (Private PAC Learning [17]).",
      "startOffset" : 24,
      "endOffset" : 28
    }, {
      "referenceID" : 17,
      "context" : "We next describe the exponential mechanism of McSherry and Talwar [18].",
      "startOffset" : 66,
      "endOffset" : 70
    }, {
      "referenceID" : 8,
      "context" : "The first two inequalities are known as the multiplicative Chernoff bounds [9], and the last inequality is known as the Hoeffding bound [16].",
      "startOffset" : 75,
      "endOffset" : 78
    }, {
      "referenceID" : 15,
      "context" : "The first two inequalities are known as the multiplicative Chernoff bounds [9], and the last inequality is known as the Hoeffding bound [16].",
      "startOffset" : 136,
      "endOffset" : 140
    }, {
      "referenceID" : 2,
      "context" : "We start with the notation of deterministic representation from [3].",
      "startOffset" : 64,
      "endOffset" : 67
    }, {
      "referenceID" : 2,
      "context" : "1 ([3]).",
      "startOffset" : 3,
      "endOffset" : 6
    }, {
      "referenceID" : 2,
      "context" : "In [3] it was shown that for α < 1/2, every α-representation for POINTd must be of cardinality at least d, and that an α-representation Hd for POINTd exists where |Hd| = O(d/α 2).",
      "startOffset" : 3,
      "endOffset" : 6
    }, {
      "referenceID" : 2,
      "context" : "For private learning it was shown in [3] that a sample of size Oα,β,ǫ(log |Hd|) suffices, with a learner that employs the exponential mechanism to choose a hypothesis from Hd.",
      "startOffset" : 37,
      "endOffset" : 40
    }, {
      "referenceID" : 2,
      "context" : "By the results of [3], stated in the previous example, DRepDim(POINTd) = θ(ln(d)).",
      "startOffset" : 18,
      "endOffset" : 21
    }, {
      "referenceID" : 2,
      "context" : "The existence of an algorithm with sample complexity O(1) was already proven in [3].",
      "startOffset" : 80,
      "endOffset" : 83
    }, {
      "referenceID" : 7,
      "context" : "By results of [8, 3], it is impossible to properly PPAC learn the class POINTN.",
      "startOffset" : 14,
      "endOffset" : 20
    }, {
      "referenceID" : 2,
      "context" : "By results of [8, 3], it is impossible to properly PPAC learn the class POINTN.",
      "startOffset" : 14,
      "endOffset" : 20
    }, {
      "referenceID" : 12,
      "context" : "This should be contrasted with the private boosting of [13] which is algorithmic and more complicated (however, the algorithm of Dwork et al.",
      "startOffset" : 55,
      "endOffset" : 59
    }, {
      "referenceID" : 12,
      "context" : "[13] is computationally efficient).",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 14,
      "context" : "To this end, denote D1 = D and consider the following thought experiment, inspired by the Adaboost Algorithm of [15]: For t = 1.",
      "startOffset" : 112,
      "endOffset" : 116
    }, {
      "referenceID" : 0,
      "context" : "An optimization problem OPT over a universe X and a set of solutions F is defined by a quality function q : X∗ × F → [0, 1].",
      "startOffset" : 117,
      "endOffset" : 123
    }, {
      "referenceID" : 5,
      "context" : "[6] defined a sanitizer (or data release mechanism) as a differentially private algorithm that, on input a database S, outputs another database Ŝ with entries taken from X.",
      "startOffset" : 0,
      "endOffset" : 3
    }, {
      "referenceID" : 1,
      "context" : "[2] defined the notation of solution-list algorithms, which corresponds to our notation of deterministic representation.",
      "startOffset" : 0,
      "endOffset" : 3
    }, {
      "referenceID" : 2,
      "context" : "[3] showed that for every α < 1, every subset H ( POINTd does not α-represent the class POINTd.",
      "startOffset" : 0,
      "endOffset" : 3
    }, {
      "referenceID" : 2,
      "context" : "[3] showed that for every α < 1, every proper-PPAC learner for POINTd requires Ω((d+log(1/β))/(ǫα)) labled examples.",
      "startOffset" : 0,
      "endOffset" : 3
    } ],
    "year" : 2014,
    "abstractText" : "In 2008, Kasiviswanathan et al. defined private learning as a combination of PAC learning and differential privacy [17]. Informally, a private learner is applied to a collection of labeled individual information and outputs a hypothesis while preserving the privacy of each individual. Kasiviswanathan et al. gave a generic construction of private learners for (finite) concept classes, with sample complexity logarithmic in the size of the concept class. This sample complexity is higher than what is needed for non-private learners, hence leaving open the possibility that the sample complexity of private learning may be sometimes significantly higher than that of non-private learning. We give a combinatorial characterization of the sample size sufficient and necessary to privately learn a class of concepts. This characterization is analogous to the well known characterization of the sample complexity of non-private learning in terms of the VC dimension of the concept class. We introduce the notion of probabilistic representation of a concept class, and our new complexity measure RepDim corresponds to the size of the smallest probabilistic representation of the concept class. We show that any private learning algorithm for a concept class C with sample complexity m implies RepDim(C) = O(m), and that there exists a private learning algorithm with sample complexity m = O(RepDim(C)). We further demonstrate that a similar characterization holds for the database size needed for privately computing a large class of optimization problems and also for the well studied problem of private data release. A preliminary version of this paper appeared in [4]. Research partially supported by the Israel Science Foundation (grants No. 938/09 and 2761/12) and by the Frankel Center for Computer Science.",
    "creator" : "LaTeX with hyperref package"
  }
}