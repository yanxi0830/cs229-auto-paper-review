{
  "name" : "1611.01688.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "Oracle-Efficient Learning and Auction Design",
    "authors" : [ "Miroslav Dudı́k", "Nika Haghtalab", "Haipeng Luo", "Robert E. Schapire", "Vasilis Syrgkanis", "Jennifer Wortman Vaughan" ],
    "emails" : [ "mdudik@microsoft.com", "nhaghtal@cs.cmu.edu", "haipeng@microsoft.com", "schapire@microsoft.com", "vasy@microsoft.com", "jenn@microsoft.com" ],
    "sections" : [ {
      "heading" : null,
      "text" : "Our learning algorithm is a generalization of the classic FTPL algorithm of Kalai and Vempala [27], playing at every iteration the historically best-performing action after adding some perturbation to the performance of each of its actions. The crux of our design is adding perturbations in a manner that leads to oracle-efficiency. We reduce this to designing a translation matrix, which translates a low dimensional vector with independent noise components into a high dimensional vector of perturbations on the learner’s action space. Our approach generalizes prior work on oracle-efficient online learning [11, 22, 27, 35], ranging from online combinatorial optimization, learning in simultaneous auctions, and contextual learning.\nOur auction-design framework considers an auctioneer learning an optimal auction rule in an online manner, every day observing an adversarially chosen vector of valuations. The auctioneer’s goal is to achieve revenue that competes with the revenue of the optimal auction in hindsight among those in some target class. We give oracle-efficient learning results for: (1) VCG auctions with bidder-specific reserves in single-parameter settings with matroid constraints, (2) envy-free item pricing in multi-item auctions with unlimited supply, and (3) s-level auctions of Morgenstern and Roughgarden [28] for singleitem settings. The last result implies good regret against the optimal overall auction when valuations are coming from a fast mixing Markov chain, that is independent across bidders. We also extend our results to the case when the learner observes side information on the bidders before running the auction (contextual learning).\nWe present additional extensions to contextual learning and learning with approximate oracles, implemented by FPTAS or Maximal-in-Range algorithms. We provide further applications in online welfare maximization in multi-unit auctions and in no-regret learning in simultaneous item auctions, answering an open question from prior work.\n∗Microsoft Research, New York, mdudik@microsoft.com †Computer Science Department, Carnegie Mellon University, nhaghtal@cs.cmu.edu ‡Microsoft Research, New York, haipeng@microsoft.com §Microsoft Research, New York, schapire@microsoft.com ¶Microsoft Research, New England, vasy@microsoft.com ‖Microsoft Research, New York, jenn@microsoft.com\nar X\niv :1\n61 1.\n01 68\n8v 1\n[ cs\n.L G\n] 5\nN ov\n2 01"
    }, {
      "heading" : "1 Introduction",
      "text" : "Online learning is increasingly playing a major role in the adaptive optimization of computer systems, from the design of online marketplaces [2, 5, 7, 33] to the optimization of routing schemes in communication networks [1]. The environments in these applications are constantly evolving in a non-stationary manner, requiring continued adaptation of these systems. Online learning robustly addresses this challenge by assuming that the environment is adversarial. The design of online learning algorithms for these settings has a long and distinguished history, starting from the seminal work of Freund and Schapire [15] and dating back to the very early work of Hannan [18] and Blackwell [4]. There are known learning rules that are information-theoretically optimal, with tight bounds on the improvement of solution quality as a function of the number of iterations of learning. However, the majority of online learning rules are computationally inefficient when the action space of the learner is exponential in the natural representation of the learning problem.\nThere is a line of research that addresses the design of computationally efficient online learning algorithms, primarily by reducing the online learning problem to an offline optimization problem, see e.g. [1, 22, 25, 27]. However, such reductions have found success only in limited albeit important settings, including online linear optimization, where the learner’s action space is the power-set of some ground elements and the objective of the learner is a linear function of these elements [27]. However, a vast array of problems faced by online learning systems, particularly in online market design, is highly non-linear and more complex than online linear optimization.\nMotivated by such applications, we address the design of oracle-efficient online learning algorithms in a general online learning setting with arbitrary learner objectives. Such algorithms are computationally efficient assuming access to an oracle for the corresponding offline optimization problem. From the recent work of Hazan and Koren [23], we know that, unlike the stochastic i.i.d. settings, oracle-efficient learning in adversarial environments is not achievable without further conditions on the learning problem. Hence, a primary contribution of our work is to give sufficient conditions on which problems are efficiently learnable online, and in particular, learnable via a generic algorithm that we introduce under the name Generalized Follow-the-Perturbed-Leader (Generalized FTPL). Our algorithm is a significant generalization of prior approaches that worked only for specific settings, including the work of Kalai and Vempala [27] on online linear optimization, Hazan and Kale [22] on online submodular minimization, Daskalakis and Syrgkanis [11] on online learning in simultaneous second-price auctions, and Syrgkanis et al. [35] on adversarial contextual learning. Our sufficient conditions draw a strong connection between the notion of a universal identification set of Goldman et al. [16] and oracle-efficient learnability. Hence, our approach unifies and extends prior approaches to oracle-efficient learning.\nThe second main contribution of our work is to introduce a new framework for the problem of adaptive market design for revenue maximization and to demonstrate the power of our oracle-efficient algorithm by numerous applications in this framework. In our new online optimal auction design framework, at each iteration, a learner adaptively designs an auction rule for the allocation of a set of resources to a fresh set of players from a population.1 The goal of the learner is to achieve average revenue at least as large as the revenue of the optimal auction from some target class. Unlike the standard approach to optimal auction design, initiated by the seminal work of Myerson [29], our approach is devoid of any assumptions about a prior distribution on the valuations of the players for the resources at sale. Instead, similar in nature to an agnostic approach in learning theory, we incorporate prior knowledge in the form of a target class of auction schemes that we want to compete with. A special case of our framework is the recent work of Roughgarden and Wang [33], which considers online learning over the class of single-item second-price auctions with bidder-specific reserves and gives an algorithm which achieves good regret with respect to a constant factor\n1Equivalently the set of players at each iteration can be the same as long as players are not forward looking and only optimize their utility from the current iteration.\nof the optimal revenue in hindsight. We go well beyond this specific setting and show that our Generalized FTPL algorithm can be used to optimize over several standard classes of auction rules which are known to approximate very well the optimal auctions in static stochastic environments. Examples include:\n– the class of Vickrey-Clarkes-Groves (VCG) mechanisms with player-specific reserve prices in singledimensional matroid auction settings, which are known to be a 2-approximation to the optimal mechanism in i.i.d. settings under some regularity conditions [21]; – the class of single-item s-level auctions introduced by Morgenstern and Roughgarden [28], who showed that these auctions approximate, to an arbitrary accuracy, the Myerson auction [29], which is known to be optimal for the Bayesian independent private value setting; and – the class of envy-free item pricing mechanisms in combinatorial markets with unlimited supply, which has been widely studied in the static Bayesian setting [2, 17].\nWe present several extensions of our main results, including: (1) learning with side information (often referred to as contextual learning); (2) constant-factor approximate oracles, provided, e.g., by Maximal-inRange (MIR) algorithms [30]; and (3) regret bounds with respect to stronger benchmarks for the case in which the environment is not completely adversarial but rather follows a fast mixing Markov process.\nThe contextual-learning extension is of particular interest to online auction design because it allows the learner to use any side information known about the bidders before they place their bids, to improve the auction. Although, typically, no two sets of bidders in the population are identical, the learner can utilize the side information to design a common treatment for bidders that are similar under some fixed representation, that is to generalize across a population. This is exactly achieved through the framework of contextual learning. While our optimality results, like much of the prior work, rely on the assumption that the bidders are either myopic or are different at each iteration, this assumption is in practice substantially less severe for contextual learning. The contextual learning algorithm can broaden the pool of bidders by including bidders from multiple markets, which reduces the probability that the exact same bidder will be used in the learning process multiple times and be overly influential in the choices of the algorithm. This in turn reduces ratchet effects where bidders identify that the auctioneer is learning and seek to strategically distort the information they provide so as to gain in the future.\nThe extension to the Markovian setting implies that under stochastic conditions on the process that generates the valuations of bidders, our online algorithm for s-level auctions has an average revenue that is at least as large as the revenue of the optimal Myerson auction for the stationary distribution of the Markov process, extending prior work that only gave such guarantees in i.i.d. settings [10, 12, 28, 32].\nFinally, we provide further applications of our work in the context of online combinatorial optimization with MIR approximate oracles, and in the context of no-regret learning for bid optimization in simultaneous second-price auctions. In the former application, we give a polynomial time online learning algorithm for online welfare maximization in multi-unit auctions, that achieves 2-approximate regret by invoking the MIR approximation algorithm of Dobzinski and Nisan [13] as an offline oracle. With the latter application, we solve an open problem raised in the recent work of Daskalakis and Syrgkanis [11] who offered efficient learning algorithms only for the weaker benchmark of no-envy learning, rather than no-regret learning, in simultaneous second price auctions."
    }, {
      "heading" : "2 Overview of Main Results and Techniques",
      "text" : ""
    }, {
      "heading" : "2.1 Oracle-Efficient Learning and the Generalized FTPL",
      "text" : "We consider the general setting of online learning, where at each iteration t ∈ {1, . . . , T}, the learner picks an action xt from some finite set X and the adversary picks an action yt from some set Y . The learner receives a reward of f(xt, yt). The goal of the learner is to choose an action at every iteration in such a way that his average reward is close to the reward of the best fixed action in hindsight, minimizing his average\nregret:\nAVERAGE-REGRET = max x∈X\n1\nT T∑ t=1 (f(x, yt)− f(xt, yt)) . (1)\nIn particular, we seek algortihms for which this regret vanishes to zero as the time horizon T goes to infinity, at a rate that is polynomial in the representation of the learning problem and inversely polynomial with T .2 Typically, the regret rate that we strive for depends only logarithmically on the size of the set of available learner actions X .\nIgnoring computational efficiency constraints, the exponential weights algorithm of Freund and Schapire [15] achieves a regret rate of O( √ log |X |/T ), which, absent any structure on the reward function, is information-theoretically optimal. However, this algorithm is computationally inefficient, as at every iteration, it updates a weight for each action in the learner’s action space, thereby requiring time linear in |X |. The action spaces we work with are frequently combinatorial, so the linear dependence in |X | is prohibitive. Can we achieve similar regret rates with computation that is polynomial in log |X | and T ?\nClearly this cannot be achieved without some restrictions on the reward structure. We adopt the common assumption that the learner has access to an oracle for the offline learning problem. Given a distribution over adversary actions represented as a uniform distribution over a set S = {y1, . . . , yt}, the oracle finds the best learner action for the distribution, i.e.,\nOPT(S) = max x∈X t∑ τ=1 f(x, yτ ) (2)\nThe oracle is essentially solving the hindsight problem: given a history of adversary actions, find the best action for the learner in hindsight.\nWhy oracle-efficient learning? The assumption of an offline oracle is the minimal assumption needed to argue that the online problem is efficiently learnable. The offline problem (or, possibly, an FPTAS for the offline problem) is a weaker problem than the online learning problem, because standard online-to-batch reductions [6, 11] can turn a polynomial-time online learning algorithm into a polynomial-time additiveapproximation scheme for the offline problem.3 Hence, whatever assumptions are needed for an efficient online learning algorithm to exist, the same assumptions imply the existence of a computationally efficient oracle for the corresponding offline problem. Thus, under those assumptions, our algorithm would also be computationally efficient, implying that restricting the design of computationally efficient learning algorithms to oracle-efficient algorithms is without any loss of generality. An oracle-efficient algorithm can also be viewed as a reduction from the offline to the online problem, providing conditions under which the online problem is not only as hard, but also as easy as the offline problem, thereby offering a computational equivalence between online and offline optimization.\nIn addition to fundamental theoretical importance, oracle-efficient algorithms are advantageous from a practical viewpoint. For example, if one has already developed and implemented a Bayesian optimization procedure which optimizes against a static stochastic environment, then our algorithm offers a black-box transformation of that procedure into an adaptive optimization algorithm with provable learning guarantees in non-stationary, non-stochastic environments. Even if the existing Bayesian optimization system does not run in worst-case polynomial time, but is rather a well-performing fast heuristic, an oracle-efficient algorithm will leverage any expert domain knowledge that went into designing the heuristic to perform well for the problem at hand.\n2For simplicity of exposition, we talk abstractly here, deferring a formal definition of what it means to be polynomial in the representation of the problem until later, because different learning problems have different parameters of interest.\n3As we show in the appendix, our results extend under the weaker assumption of a polynomial-time additive-approximation scheme for the offline problem.\nGeneralized FTPL with Low-Dimensional Noise. With access to an oracle, a natural first attempt to design an online learner would be to use the Follow-the-Leader (FTL) algorithm. This algorithm simply invokes the oracle at every iteration and plays the best action in hindsight. In a stochastic environment, i.e., when the adversary’s actions are drawn i.i.d. from some distribution at each iteration, such an approach works and offers regret rates on the order O(log |X |/ √ T ) by a simple application of the Rademacher complexity of finite hypotheses classes [34]. However, the lack of randomness in this algorithm leads to very high regret in adversarial environments. A seminal paper of Kalai and Vempala [27] showed that a slight modification of this algorithm leads to good regret. At a high level, this modification perturbs the performance of each action x ∈ X by some random amount x drawn from a high-variance distribution, before choosing the best action in hindsight. However, even though this algorithm has good regret, it is computationally inefficient as it requires putting a perturbation on the performance of each one of the actions available to the learner. Moreover, this algorithm does not leverage the existence of the offline oracle, as the perturbed optimization problem is not a problem that the oracle is able to solve.\nDaskalakis and Syrgkanis [11] introduced the approach of adding randomness to the FTL algorithm by augmenting the observed history with “fake” historical samples of adversary actions. The oracle is then invoked on the resulting perturbed history of adversary actions. However, they did not give any general way of generating such perturbations of the history or any general conditions under which this approach leads to good regret or computational efficiency when the set of adversary’s actions is large. Our work exactly fills in this missing piece.\nPerturbation Translation Matrices. Our results bridge the gap between these two approaches. We construct perturbations on each individual action of the learner by coupling the randomness across different actions. We generate a small number N of independent perturbations α = (α1, . . . , αN ) drawn from a highly dispersed distribution. In most applications, N is logarithmic in |X |. We then define the perturbation on the performance of each learner action x to be a weighted combination of these independent perturbations. In this way, we construct a perturbation translation matrix Γ (for simplicity assume entries in [0, 1]), which translates the short N -dimensional perturbation vector into a long |X |-dimensional one, i.e., the perturbation on action x is x = α · Γx. By sampling the low dimensional noise vector α, we avoid the exponential computation of drawing a separate perturbation term for each action of the learner, while at the same time exploiting the idea that high variance noise added on each action of the learner leads to good regret. We term this algorithm Generalized FTPL.\nGeneralized FTPL has low regret if the translation matrix Γ satisfies an admissibility criterion: the main property required from Γ is that its rows are (sufficiently) distinct. Thus each action’s perturbation uses a different weighted combination of the low dimensional noise. We show that any such matrix leads to vanishing regret, with regret rates that are more concretely captured in the following theorem (see Theorem 3.5 for a formal version):\nInformal Theorem 1. A translation matrix is (κ, δ)-admissible if any two rows of the matrix are distinct, the number of different values within a column is at most κ and the minimum non-zero difference between any two values within a column is at least δ. Generalized FTPL with a (κ, δ)-admissible matrix achieves regret of O(N √ Tκ/δ).\nOracle-based Implementability. To complete the construction of an oracle-efficient algorithm, we need the property that these induced action-level perturbations can be simulated by a perturbation of the history, i.e., that there exists a distribution of adversary actions that induces the same randomness as the one induced by x = α · Γx. This is captured by the implementability criterion, which states that each column of the translation matrix essentially corresponds to a scaled version of the expected reward of the learner on some distribution of adversary actions (see Theorem 3.11 for a formal statement).\nInformal Theorem 2. A translation matrix is implementable if each column corresponds to a scaled version of the expected reward of the learner against some small-supported distribution of actions of the adversary. Generalized FTPL with an implementable and (κ, δ)-admissible translation matrix can be implemented in an oracle-efficient manner, with running time polynomial in N , T , κ/δ, and in the size of the distribution implementing the translation matrix, when represented by a sequence of atoms.\nDesign Approach. Thus we get that a sufficient condition for oracle-efficient learnability is the existence of an admissible and implementable translation matrix, with small N,κ and 1/δ. For some learning problems, it is easier to construct a trivially implementable translation matrix and then argue about its admissibility; for others, it is easier to start with a trivially admissible matrix and argue about its implementability. Below we describe examples of each, exhibiting the versatility of our conditions.\nThe first case, when implementability is immediate, is when each column corresponds to the reward of the learner on some particular adversary action. The admissibility translates to a natural condition: the reward of the adversary under any two actions x, x′ ∈ X must be different for at least one of theN adversary actions that are associated with the columns of Γ. Therefore, to construct an admissible and implementable matrix Γ, it suffices to identify a small numberN of adversary actions that have this differentiating property.\nCorollary 1. If there exists a small set of adversary actions such that any two learner’s actions yield a different reward on at least one of these adversary actions and such that the number of different reward levels for each of these actions in the set is small, then the learning problem is oracle-efficient and learnable with the Generalized FTPL algorithm.\nA special case in which this holds is captured by the notion of a universal identification sequence defined by Goldman et al. [16]. This notion applies when the learner is choosing binary functions from some input space and the adversary is choosing realizations of the input variables, with the learner collecting a reward only if the output of his function on the adversary’s input is 1. Another special case of this differentiating property arises in contextual learning. In contextual learning, the learner chooses a policy that maps a domain of contextual information into one of K actions, with the adversary picking both the contextual information and the reward of each action. The learner needs to compete with the optimal policy in a given policy class. A separator [11] is a small set of contexts such that any two policies in the policy class choose different actions on at least one context from the set. The existence of a separator implies an admissible and implementable translation matrix.\nInstead of beginning the design with implementability, we can begin with admissibility. One interesting special case of an admissible matrix is when the rows of matrix Γ contain a binary representation of some parameterization of the actions of the learner. The number of columns of the matrix is then logarithmic in the number of actions of the learner. However, such a matrix may or may not be implementable.\nCorollary 2. If any linear functions on some binary vector representation of the learner’s actions, can be implemented with a distribution of adversary actions, then the learning problem is oracle-efficient and learnable with the Generalized FTPL algorithm.\nThis condition is perhaps easiest to understand when the learner’s actions are a power-set over a set of K ground elements, i.e., X = {0, 1}K . This is the case for online combinatorial optimization in which the adversary picks a combinatorial function vt at every iteration and the learner receives reward vt(xt). The perturbations of our algorithm essentially correspond to adding an independent perturbation on each of the ground elements, or equivalently, adding a fake additive function to the history, whose value for each ground element is drawn independently from some distribution. If the adversary is picking functions from a class that includes additive ones, then the latter perturbations are by definition implementable. This approach was leveraged by Hazan and Kale [22] for online submodular minimization. Their approach is a special case of ours, but our work extends beyond combinatorial optimization. For instance, in subsequent sections,\nwe show that a translation matrix consisting of binary encodings of reserve prices in auctions yields an oracle-efficient online learning algorithm for revenue maximization."
    }, {
      "heading" : "2.2 Main Application: Online Optimal Auction Design",
      "text" : "As a main application of our oracle-efficient learning algorithm, we consider an online learning version of the classical market design problem of optimally selling a single item (or multiple items) to a set of interested buyers so as to maximize revenue. Traditional optimal auction theory assumes that the valuations of the players are drawn from a population distribution which is known, thereby leading to a Bayesian optimization problem. The knowledge of the distribution by the seller is a rather harsh assumption and recent work in algorithmic mechanism design [10, 12, 28, 32] relaxes this assumption by solely assuming access to a set of samples from the distribution. In this work we take a completely distribution-free and adversarial approach, introducing the setting of online optimal auction design.\nIn many applications of optimal auction theory, in particular in electronic marketplaces, the seller does not sell the item once, but rather repeatedly sells the item to a population of buyers, with a few arriving at each auction. Hence, the seller can optimize his auction design in an online manner, using historical data consisting of observed valuations. The goal of the seller is to leverage the historical data and pick an auction at each iteration so as to compete with the optimal auction from some target class. For instance, in a sponsored-search auction setting, the auctioneer can use historical data from past auctions in a sub-market to decide what reserve price to set for a new impression that arrives in that sub-market. In a setting like eBay, the system can use historical bid data from auctions of similar goods to decide what reserve price to recommend to a new seller.\nMotivated by such online auction optimization settings we consider the following optimal auction model. An auctioneer is repeatedly selling a set of resources for T time-steps. On each day t a set of n bidders arrive with a vector of valuations/bids vt ∈ Vn. Prior to observing the bids, the auctioneer commits to an auction at from a class of truthful auctions A that he is interested in. Unlike classical optimal auction design, we make no assumptions about the process which generates the valuations of players on each day. We consider the case where these valuations are chosen by an adversary.\nThe goal of the learner is to achieve an average revenue over time, that, in hindsight, is very close to the revenue that would have been achieved by the best fixed mechanism in classA, if that mechanism was at all time-steps, i.e., the learner aims to achieve small average regret:\nAVERAGE-REGRET = max a∈A\n1\nT T∑ t=1 Rev(a,vt)− 1 T T∑ t=1 Rev(at,vt). (3)\nWe apply our oracle-efficient algorithm and design online learning algorithms for the aforementioned setting assuming access to an offline oracle. In the context of revenue maximization, the learner’s action space is the set of target auctions A, the adversary’s action space is the set of valuation vectors Vn. Finally, the offline oracle is a Bayesian revenue maximization oracle which computes the optimal auction within a class of auctionsA, for any correlated distribution of valuations given as a uniform distribution over a set of valuation vectors: {v1, . . . ,vk}.\nWe construct oracle-efficient online learning algorithms for three optimal auction classes, mentioned in Section 1, which have been well studied in the Bayesian optimal auction literature. For each of these auction settings, we show how to construct a translation matrix that is admissible and implementable.\nExample: Second-Price with Bidder-Specific Reserves. To give a hint at our techniques we briefly describe our construction for one very special case of our online optimal auction design, the case of secondprice auctions with bidder-specific reserves, in which the auctioneer ignores bidders below their reserve price and allocates to the highest remaining bidder, charging him the maximum of his reserve and the\nsecond highest remaining bid. Thus the learner needs to pick at each iteration a reserve price for each bidder. For simplicity assume that each reserve price comes from a discretized grid of m + 1 possible levels R = {0, 1/m, 2/m, . . . , 1} and valuations are upper bounded by 1. Thus the action space of the learner is of size (m + 1)n, which is prohibitively large. Our construction yields an oracle-efficient algorithm which runs in time poly(n,m, T ), ignoring oracle computation, and yields regret O(n log(m)/ √ T ).\nWe present here a simpler translation matrix which yields regret O(n ·m2/ √ T ). We use the approach implied by our Corollary 1 and find a set of special bid profiles such that any two auctions in the class achieve different revenue in at least one of these bid profiles. It is easy to find such a set: for each bidder i, consider all the bid profiles where he bids some level h ∈ R and every other bidder bids 0. For any two different auctions in the class of second-price auctions with a reserve, the revenue must be different in at least one of these bids: if the auctions differ on the reserve price of bidder i, with one auction having reserve r and the other having reserve r′, then a bid profile which submits a bid level h ∈ (r, r′] for bidder i and a zero bid on everyone else, will yield different revenue in the two auctions. Thus we have constructed a translation matrix where each column corresponds to the revenue of the auction under the associated bid from one of these N = n · (m+ 1) bids. Moreover, observe that for each of these special bid profiles the revenue of any auction takes at most m + 1 different values and the minimum non-zero difference in the revenue of two auctions is 1/m. Thus invoking the Informal Theorems 1 and 2 we get that there exists an oracle-efficient no-regret algorithm which runs in time poly(n,m, T ), ignoring oracle computation, and achieves average regret O(nm2/ √ T ).\nMarkovian adversaries and competing with overall optimal. Another class of auctions that we analyze is the recently introduced class of level auctions [28]. A level auction is a generalization of bidder-specific reserves, where each bidder now has multiple associated reserves which categorize his bid into a set of buckets that are then used for allocating the good. Morgenstern and Roughgarden [28] showed that these auctions, for large enough number of buckets, provide an arbitrarily accurate approximation to the overall optimal Myerson auction in the Bayesian single-item auction setting, where the value of each bidder is drawn from an independent distribution. Our learning results imply oracle-efficient regret bounds of O(n2m2/ √ T ). If the valuation of each player is drawn independently in each round from some fixed distribution, then standard online-to-batch reduction implies that the revenue of the online learning algorithm is close to the overall optimal single-shot auction, i.e., the Myerson auction. We generalize this reasoning and show that we get such strong optimality guarantee also when the valuations of players are drawn at each iteration from a fast-mixing Markov process, which is independent across players. For both of these setting, our results give an oracle-efficient algorithm with regret O(n2/3/T 1/6) to the overall optimal (by optimizing over the value of m). This is the first result on competing with a Myerson optimal auction for non-iid distributions, unlike prior work [10, 12, 28, 32] which assumes i.i.d. samples."
    }, {
      "heading" : "3 Generalized FTPL and Oracle-Efficient Online Learning",
      "text" : "In this section, we introduce a general Follow-the-Perturbed-Leader (FTPL) algorithm. We then describe the conditions under which this algorithm efficiently reduces online learning to offline optimization.\nWe consider the following online learning problem. On each round t = 1, . . . , T , a learner chooses an action xt from a finite set X , and an adversary chooses an action yt from set Y , which is not necessarily finite. The learner then observes yt and receives a payoff f(xt, yt) ∈ [0, 1], where the function f is fixed and known to the learner. The goal of the learner is to obtain low expected regret with respect to the best action in hindsight, i.e., to minimize\nREGRET := E [ max x∈X T∑ t=1 f(x, yt)− T∑ t=1 f(xt, yt) ] ,\nwhere the expectation is over the randomness of the learner. To simplify exposition, we assume that the ad-\nversary is oblivious, i.e., that the sequence y1, . . . , yT is chosen up front without knowledge of the learner’s realized actions. Our results generalize to adaptive adversaries using standard techniques [11, 24].\nOur algorithm broadly follows the FTPL scheme of Kalai and Vempala [27]. In the original FTPL scheme of Kalai and Vempala [27], at every iteration the algorithm adds a perturbation to the historical cumulative payoff of each possible action of the learner and then picks the action with the largest perturbed historical payoff. The perturbation on each action is independently drawn from a highly dispersed distribution, such as an exponential distribution with standard deviation of order √ T . Applying this approach to the general learning setting above is computationally inefficient when the action space of the learner X is exponential in some succinct representation of the learning setting.\nFor online combinatorial optimization with either additive [27] or submodular [22] objectives, it has been shown that one does not need to add a perturbation on each set, but adding a perturbation on each item suffices to lead to no-regret. However, this approach is specific to these settings and it was not even known before our work whether the approach extends to online combinatorial optimization with arbitrary objectives. We show how to bypass the exponential perturbation problem for the general online learning setting.\nOur goal is to create perturbations that can be succinctly passed on to an offline optimization oracle. In particular, we seek to generate perturbations that can be simulated by augmenting the history with a polynomial number of fake samples as proposed in Daskalakis and Syrgkanis [11]. To generate such perturbations, we begin by drawing a random vector α ∈ RN of some small size N , with components αj drawn independently from some dispersed distribution D. The payoff of each of the learner’s action is perturbed by a linear combination of these independent variables, as prescribed by a non-negative translation matrix Γ of size |X | ×N , i.e., the vector of perturbations on all the |X | actions of the learner is given by the vector Γα. Letting Γx denote the row of Γ corresponding to x, on each round t, the algorithm outputs the action x that maximizes ∑t−1 τ=1 f(x, yτ ) +α ·Γx. See Algorithm 1 for a full specification. For non-oblivious adversaries, a fresh random vector α is drawn in each round. In this section we analyze the properties of the matrix Γ to guarantee that the Generalized FTPL algorithm both achieves a small regret and its perturbations can be efficiently transformed into fake samples. Together these properties give rise to efficient reductions of online learning to offline optimization.\nAlgorithm 1: Generalized FTPL\nInput: non-negative matrix Γ ∈ R|X |×N+ , distribution D Draw αj ∼ D for j = 1, . . . , N . for t = 1, . . . , T do\nChoose action xt = arg max x∈X [ t−1∑ τ=1 f(x, yτ ) + α · Γx ] .\nObserve yt and receive payoff f(xt, yt). end for"
    }, {
      "heading" : "3.1 Regret Analysis",
      "text" : "To analyze the Generalized FTPL algorithm, we first bound its regret by the sum of a stability term and perturbation term in the following lemma. While this approach is standard [27], we include a proof in Appendix A for completeness.\nLemma 3.1 (FTPL Lemma). For the Generalized FTPL algorithm,\nREGRET ≤ E [ T∑ t=1 f(xt+1, yt)− f(xt, yt) ] + E [ α · (Γx1 − Γx∗) ] (4)\nwhere x∗ = arg maxx∈X ∑T t=1 f(x, yt).\nThe first term measures the stability: how much our decision changes from round to round. The second term measures the strength of perturbation: how much the perturbation amount differs between the best action and the initial action. To bound the stability term, we require that the matrix Γ be admissible and the distribution D be dispersed in the following sense:\nDefinition 3.2 ((κ, δ)-Admissible Translation Matrix). A translation matrix Γ is admissible if its rows are distinct. It is (κ, δ)-admissible if it is admissible and also:\n1. the number of distinct elements within each column is at most κ, 2. distinct elements within each column differ by at least δ.\nDefinition 3.3 ((ρ, L)-Dispersed Distribution). A distribution D on the real line is (ρ, L)-dispersed if for any interval of length L, the probability measure placed by D on this interval is at most ρ.\nIn the next lemma, we bound the stability term in Equation (4) by showing that with high probability, for all rounds t, we have xt+1 = xt. Since all rows of an admissible matrix Γ are distinct, it suffices to show that the probability that Γxt+1 6= Γxt is small. We prove this for each coordinate Γxt+1j separately, by showing that it is only possible to have Γxt+1j 6= Γxtj when the random variable αj falls in a small interval, which happens with only small probability for a sufficiently dispersed distribution D. Note that any admissible matrix is (κ, δ)-admissible for some choices of κ and δ. The magnitudes of κ and δ and the number of columns of Γ determine how large the stability term can get.\nLemma 3.4. Consider the Generalized FTPL algorithm with a (κ, δ)-admissible matrix Γ with N columns and a (ρ, 1/δ)-dispersed distribution D. Then,\nE [ T∑ t=1 f(xt+1, yt)− f(xt, yt) ] ≤ 2TNκρ.\nProof. Fix any t ≤ T . The bulk of the proof will establish that, with high probability, Γxt+1 = Γxt , which by admissibility implies that xt+1 = xt and therefore f(xt+1, yt)− f(xt, yt) = 0.\nFix any j ≤ N . We first show that Γxt+1j = Γxtj with high probability. Let V denote the set of values that appear in the jth column of Γ. For any value v ∈ V , let xv be the action that maximizes the perturbed profit, ignoring the perturbation of column j itself, among those whose Γ entry in the jth column equals v:\nxv := arg max x∈X : Γxj=v  t−1∑ τ=1 f(x, yτ ) + ∑ j′ 6=j αj′Γxj′  = arg max x∈X : Γxj=v [ t−1∑ τ=1 f(x, yτ ) + α · Γx − αjv ] .\nFor any v, v′ ∈ V , define\n∆vv′ = ( t−1∑ τ=1 f(xv, yτ ) + α · Γxv − αjv ) − ( t−1∑ τ=1 f(xv ′ , yτ ) + α · Γxv′ − αjv ′ ) .\nNote that xv and ∆vv′ are independent of αj , as we removed the payoff perturbation corresponding to αj . If Γxtj = v, then by the optimality of xt on the perturbed profit, we have αj(v\n′ − v) ≤ ∆vv′ for all v′ ∈ V . Suppose Γxt+1j 6= v. Then there is some v′ ∈ V which yields a better perturbed profit in the next round, i.e.,\nt−1∑ τ=1 f(xv ′ , yτ ) + f(x v′ , yt) + α · Γxv′ ≥ t−1∑ τ=1 f(xv, yτ ) + f(x v, yt) + α · Γxv .\nRearranging, we obtain for this same v′ that\n∆vv′ ≤ αj(v′ − v) + f(xv ′ , yt)− f(xv, yt) ≤ αj(v′ − v) + 1.\nIf v′ > v, then\nαj ≥ ∆vv′ − 1 v′ − v ≥ min v̂∈V, v̂>v ∆vv̂ − 1 v̂ − v\nand so αj(v − v) + 1 ≥ ∆vv where v is the value of v̂ minimizing the expression on the right. Thus, in this case we have 0 ≤ ∆vv − αj(v − v) ≤ 1. Similarly, if v′ < v, then\nαj ≤ ∆vv′ − 1 v′ − v ≤ max v̂∈V, v̂<v ∆vv̂ − 1 v̂ − v\nand so αj(v − v) + 1 ≥ ∆vv where v is the value maximizing the expression on the right. In this case we have 0 ≤ ∆vv − αj(v − v) ≤ 1. Putting this all together, we have\nPr [ Γxt+1j 6= Γxtj ∣∣ αk, k 6= j] ≤ Pr [ ∃v ∈ V : 0 ≤ ∆vv − αj(v − v) ≤ 1 or 0 ≤ ∆vv − αj(v − v) ≤ 1\n∣∣∣ αk, k 6= j] ≤ ∑ v∈V ( Pr [ αj ∈ [ ∆vv−1 v−v , ∆vv v−v\n] ∣∣∣∣ αk, k 6= j]+ Pr[αj ∈ [−∆vvv−v , −∆vv+1v−v ] ∣∣∣∣ αk, k 6= j]) ≤ 2κρ.\nThe last line follows from the fact that v− v ≥ δ and v− v ≥ δ, the fact that D is (ρ, 1/δ)-dispersed, and a union bound.\nSince this bound does not depend on the values of the αj , we can remove the conditioning and bound Pr[Γxt+1j 6= Γxtj ] ≤ 2κρ. Taking a union bound over all j ≤ N , we then have that, by admissibility, Pr [xt+1 6= xt] = Pr [ Γxt+1 6= Γxt ] ≤ 2Nκρ, which implies the result.\nTo bound the regret, it remains to bound the perturbation term in Equation (4). This bound is specific to the distribution D. Many distribution families, including uniform, Gaussian, Laplacian, discrete uniform, exponential etc., with appropriately set variance, will lead to a sublinear regret. Here we present a concrete regret analysis for the case of a uniform distribution supported on [0, 1/η], for η ≈ 1/ √ T :\nTheorem 3.5. Let Γ be a (κ, δ)-admissible matrix with N columns and γ = maxx,j Γxj and let D be the uniform distribution on [0, 1/η] for η = √ γδ/(2Tκ). Then the regret of the Generalized FTPL algorithm can be bounded as REGRET ≤ 2N √ 2Tκγ/δ.\nThe proof of Theorem 3.5 follows immediately from Lemmas 3.1 and 3.4 with ρ = η/δ."
    }, {
      "heading" : "3.2 Oracle-Efficient Online Learning",
      "text" : "The Generalized FTPL algorithm requires the ability to optimize the perturbed objective over the learner’s action set in order to find xt at each round t. However, to achieve online-to-offline reduction, we need to create offline optimization problems of the same type as the underlying online problem. Namely, we need to reduce to optimization of the cumulative payoff over some data set consisting of adversary’s actions. An algorithm solving such offline optimization problems will be called an offline oracle. If each optimization step of the Generalized FTPL can be efficiently transformed into a sequence of oracle calls, we will say that the Generalized FTPL algorithm is oracle-efficient.\nIn this section, we derive the criterion that allows us to solve the optimization of the perturbed objective by a single oracle call. We achieve this by transforming the perturbation into a (weighted) set of adversary’s actions, which are then passed to the oracle alongside all of the actual adversary’s actions.\nAs a result of this construction, we immediately get that the online learning problem can be solved efficiently whenever there is an efficient offline oracle and the Generalized FTPL is oracle-efficient.\nWe now define the offline oracle and oracle-efficient online learning more formally.\nDefinition 3.6 (Offline Oracle). An offline oracle OPT is any algorithm that receives as input a weighted set of adversary actions S = {(w`, y`)}`∈L, wk ∈ R+, yk ∈ Y , and returns\nOPT(S) ∈ arg max x∈X ∑ (w,y)∈S wf(x, y).\nDefinition 3.7 (Mass of a Data Set). The mass of a weighted dataset S, denoted ‖S‖, is the maximum of its cardinality and its sum of weights, ‖S‖ := max { |S|, ∑ (w,y)∈S w } .\nDefinition 3.8 (Oracle-Efficient Online Learning). We say that an online learning algorithm is oracleefficient with the per-round complexity g(T) if in each round it makesO(g(T )) calls to an offline oracle, each on a dataset with the mass O(g(T )), and its per-round running time, excluding oracle calls, is O(g(T )).\nNote that unlike the oracle of [23], which accepts a distribution, we do not require the weights to sum to one. This is without loss of generality since as we show in Appendix C the two oracle classes are essentially equivalent, as we show that any oracle efficient algorithm that uses a fractionally weighted oracle can be implemented with an integral oracle with an arbitrarily small increase in regret. For now, we mention that the reason why we introduced the mass of a dataset in the definition of oracle-efficiency is that we anticipate reductions to integral oracles, which typically expect unweighted inputs, obtained by replicating each example according to its weight. Thus the mass of a weighted data set is the natural problem size for integral oracles.\nWe next provide the criterion on the pair (Γ, D), which allows us to transform the perturbed objective into a weighted dataset, thus achieving oracle-efficiency of the Generalized FTPL:\nDefinition 3.9. The pair (Γ, D) is implementable, with complexity Ng(T ), if there exists an algorithm, running in time O(g(T )), which takes j ≤ N and αj ∈ supp(D) as input, and returns a weighted dataset, denoted as Sj(αj), as output. The dataset Sj(αj) must have a mass O(g(T )) and implement the perturbation αj in the following sense:\nfor all x, x′ ∈ X : αj(Γxj − Γx′j) = ∑\n(w,y)∈Sj(αj)\nw ( f(x, y)− f(x′, y) ) .\nThis definition implies that the perturbation in the total utility described by the random vector α can be imitated by appending a “fake history”, consisting of the union of sets Sj(αj), to the actual history of the game. While the actual value of a payoff for a given action x on such dataset might not agree with the perturbed objective, the difference of payoffs for any two actions x and x′ agrees with the difference on the perturbed objective, and this suffices to find xt.\nOne simple but powerful example of implementability is when the perturbations αj are non-negative and each column of Γ corresponds to some adversary action yj :\nExample 3.10. Consider any D with supp(D) ⊆ R+. Suppose that for each j ≤ N , there exists some yj ∈ Y such that Γxj = f(x, yj). Then (Γ, D) is implementable using the map Sj(αj) = {(αj , yj)}.\nAlgorithm 2: Oracle-Based Generalized FTPL Input: positive |X | ×N , an implementable (Γ, D), an offline oracle OPT Draw αj ∼ D for j = 1, . . . , N . for t = 1, . . . , T do\nSet S = {(1, y1), . . . , (1, yt−1)} ∪ ⋃ j≤N Sj(αj). Set xt = OPT(S). Observe yt and receive payoff f(xt, yt).\nend for\nUsing implementable (Γ, D) gives rise to an oracle-efficient variant of the Generalized FTPL, provided in Algorithm 2. Theorem 3.11, with a proof in Appendix B, shows that the output of this algorithm is equivalent to the output of Generalized FTPL, and therefore the same regret guarantees hold. This result can guide the choice of Γ and D to obtain oracle-efficient no-regret algorithms.\nTheorem 3.11. If (Γ, D) is implementable with complexity g(N,T ) then Algorithm 2 is an oracle-efficient implementation of Algorithm 1 with per-round complexity O(T + g(N,T ))."
    }, {
      "heading" : "4 Online Auction Design",
      "text" : "In this section, we apply the general techniques developed in Section 3 to obtain efficient oracle-based no-regret algorithms for several common auction classes.\nConsider a mechanism design setting where a seller wants to decide the allocation of resources to a set of n bidders. An allocation of a bidder is a subset in {0, 1}k from some number of elements k and the seller has some feasibility constraints on the allocations across bidders. Each bidder i ∈ [n] has a combinatorial valuation function vi ∈ V , where V ⊆ ({0, 1}k → [0, 1]). A special case of the setting is that of multi-item auctions for k heterogeneous items, where each element is an item and the feasibility constraint simply states that no item is allocated to more than one bidder. Another special case is that of service based environments where each bidder’s allocation is in {0, 1} and the seller has some constraints on which bidders to serve, i.e. assign an allocation of 1. Auction a takes as input the bid profile b consisting of reported values for each bidder, and returns both the allocation of bidder i, qi(b) ∈ {0, 1}k and the price pi(b) that this bidder is charged; we allow sets qi(b) to overlap across bidders i.\nWe consider bidders with quasilinear utilities: the utility of bidder i is vi(qi(b)) − pi(b). For an auction a with price function p(·), we denote by Rev(a,b) the revenue of the auction for bid profile b, i.e., Rev(a,b) = ∑ i∈[n] pi(b).\nFor single-parameter service based environments (a special case of which are single-item auctions), we slightly simplify notation and use vi ∈ [0, 1] to denote the value of bidder i for being served.\nIn this work, we only consider truthful auctions, where each bidder i maximizes his utility by reporting his true valuation vi, irrespective of what other bidders report. Since we limit attention to truthful auctions, we make the assumption that b = v and refer to v as the bid profile throughout the rest of this section.\nFixing a class of (truthful) auctions A and a set of possible valuations V , we consider the problem in which on each round t = 1, . . . , T , a learner chooses an auction at ∈ A while an adversary chooses a bid profile vt ∈ Vn. The learner then observes vt and receives revenue Rev(at,vt). The goal of the learner is to obtain low expected regret with respect to the best auction from A in hindsight. That is, we would like to guarantee that\nREGRET = E [ max a∈A T∑ t=1 Rev(a,vt)− T∑ t=1 Rev(at,vt) ] ≤ o(T )poly(n, k).\nWe require our online algorithm to be oracle-efficient, assuming access to an offline optimization oracle that takes as an input a weighted set of bid profiles, S = {(w`,v`)}`∈L and returns the auction that maximizes the revenue on S, i.e., arg maxa∈A ∑ (w,v)∈S wRev(a,v).\nUsing the language of oracle-based online learning developed in Section 3, the learner’s action corresponds to the choice of auction, the adversary’s action corresponds to the choice of bid profile, the payoff of the learner corresponds to the revenue generated by the auction, and we assume access to an offline optimization oracle OPT. These correspondences are summarized in the following table.\nAuction Setting Oracle-Based Learning Equivalent Auctions at ∈ A Learner actions xt ∈ X Bid/valuation profiles vt ∈ Vn Adversary actions yt ∈ Y Revenue function Rev Payoff function f\nFor several of the auction classes we consider, such as multi-item or multi-unit auctions, the revenue of an auction on a bid profile is in range [0, R] for R > 1. In order to use the results of Section 3, we implicitly re-scale all the revenue functions and Γ, by dividing them by R, before applying Theorem 3.5. Note that, while the admissibility condition also scales, the scaling of γ = maxa,j Γa,j keeps the regret of the normalized problem at O(N √ Tκγ/δ), according to Theorem 3.5. We then scale up to get a regret\nbound that isR times the regret for the normalized problem, i.e.,O(RN √ Tκγ/δ). This re-scaling increases the runtime by a factor of R, as when both the revenues and matrix Γ are scaled, the implementability map Sj(αj) remains the same, and the support of the distribution (corresponding to 1/η in Theorem 3.5) increases by a factor of R.\nWe now derive results for VCG auctions with bidder-specific reserves, envy-free item-pricing auctions, and level auctions. We defer the definition of each auction class to its respective subsection."
    }, {
      "heading" : "4.1 VCG with Bidder-Specific Reserves",
      "text" : "In this section, we consider a standard class of auctions, VCG auctions with bidder-specific reserve prices, which we define more formally below and denote by I. These auctions are known to approximately maximize the revenue when the bidder valuations are drawn independently (but not necessarily identically) from some distribution [21]. Recently, Roughgarden and Wang [33] considered this class I in an online learning framework. They provided a computationally efficient algorithm whose total revenue is at least 1/2 of the best revenue among auctions in I, plus a term that is o(T ). We apply the techniques from Section 3 to generate an oracle-efficient online algorithm with low additive regret to the optimal auction in the class I, without any loss in multiplicative factors.\nWe go beyond single-item auctions and consider a general single-parameter setting. In these environments, each bidder has one piece of private valuation for receiving a service, i.e., being included in the set of winning bidders. We allow for some combinations of bidders to be served simultaneously, and let S ⊆ 2n be the family of feasible sets, i.e., sets of bidders that can be served simultaneously. We assume that it is possible for any bidder to be the sole bidder served, i.e., that {i} ∈ S for all i, and that it is possible that no bidder is served, i.e., ∅ ∈ S.4 Examples of such environments include single-item single-unit auctions (for which S contains only singletons and the empty set), single-item s-unit auctions (for which S contains any subset of size at most s), and combinatorial auctions with single-minded bidders. In the last case, we begin with some set of original items, define the service as receiving the desired bundle of items, and let S contain any subset of bidders seeking disjoint sets of original items.\nWe consider the class of VCG auctions with bidder-specific reserves. In a basic VCG auction, an allocation q∗ is chosen to maximize social welfare, that is, maximize ∑n i=1 vi(q ∗ i ). Each bidder who is served is\nthen charged the externality he imposes on others, pi(v) = maxq ∑ i′ 6=i vi′(qi′)− ∑ i′ 6=i vi′(q ∗ i′), which can\n4A more common and stronger assumption used in previous work [21, 33] is that S is a downward closed matroid.\nbe shown to equal the minimum bid at which he would be served. Such auctions are known to be truthful. The most common example is the second-price auction for the single-item single-unit case in which the bidder with the highest bid receives the item and pays the second highest bid. VCG auctions with reserves, which maintain the property of truthfulness, are defined as follows.\nDefinition 4.1 (VCG auctions with bidder-specific reserves). A VCG auction with bidder-specific reserves is specified by a vector r of reserve prices for each bidder. As a first step, all bidders whose bids are below their reserves (that is, bidders i for which vi < ri) are removed from the auction. If no bidders remain, the item is not allocated. Otherwise, the basic VCG auction is run on the remaining bidders to determine the allocation. Each bidder who is served is charged the larger of his reserve and his VCG payment.\nFixing the set S of feasible allocations, we denote by I the class of all VCG auctions with bidder-specific reserves. With a slight abuse of notation we write r ∈ I to denote the auction with reserve prices r. To apply the results from Section 3, which require a finite action set for the learner, we limit attention to the finite set of auctions Im ⊆ I consisting of those auctions in which the reserve price for each bidder is an integer multiple of 1/m. As we show below, the best auction in this class yields almost as high revenue as the best auction in I for common choices of S.\nWe show how to design a matrix Γ and distribution D for this problem that are admissible and implementable. As a warmup, suppose we use the |Im| × n matrix Γ with Γri = Rev(r, ei) for all r ∈ Im and i ∈ [n]. That is, the ith column of Γ corresponds to the revenue of each auction on a bid profile in which bidder i has valuation 1 and all others have valuation 0. Let D be defined as in Theorem 3.5. By definition, (Γ, D) is implementable. Moreover, Rev(r, ei) = ri so any two rows of Γ are indeed different and Γ is (m, 1/m)-admissible. By Theorem 3.5, there is an oracle-efficient implementation of the Generalized FTPL with regret that is polynomial in m. In what follows, we design another translation matrix more carefully, and obtain the regret that is polynomial log(m).\nConstruction of Γ: Let ΓVCG be an |Im| × (ndlogme) binary matrix, where the ith collection of dlogme columns correspond to the binary encoding of each auction’s reserve price for bidder i. More formally, for any i ≤ n and a bit position β ≤ dlogme, ΓVCGrj is the βth bit of (the integer) mri, where j = (i − 1)dlogme + β. The next lemma shows that this choice of ΓVCG is admissible and that (ΓVCG, D) is implementable for any D over R.\nLemma 4.2. ΓVCG is (2, 1)-admissible. If D is supported on a subset of [−αmax, αmax], then (ΓVCG, D) is implementable with complexity poly(n,m,αmax).\nProof. In the interest of readability, we drop the superscript and write Γ for ΓVCG in this proof. For any r, row Γr corresponds to the binary encoding of r1, . . . , rn. Therefore, for any two different auctions r 6= r′, Γr 6= Γr′ . Since Γ is a binary matrix, this implies that Γ is (2, 1)-admissible. Next, we prove that (Γ, D) is implementable. Pick i ≤ n and β ≤ dlogme, and the associated column index j. We will construct the set Sj(αj) which implements the perturbation αj . The set Sj(αj) includes exactly the m profiles in which only the bidder i has non-zero valuation, denoted as vh := (h/m)ei for h ≤ m. To determine their weights wh, we use the definition of implementability. In particular, the weights must satisfy:\n∀ r, r′ ∈ Im, αj ( Γrj − Γr′j ) = ∑ h≤m wh ( Rev(r,vh)− Rev(r′,vh) ) .\nIn the above equation, Γrj and Γr′j encode the βth bit of ri and r′i, respectively, so the left-hand side is independent of the reserve prices for bidders i′ 6= i. Moreover, Rev(r,vh) = ri1(h≥mri), so the right-hand side of the above equation is also independent of the reserve prices for bidders i′ 6= i. Let kβ be the βth\nbit of integer k. That is, Γrj = (mri)β . Substituting k = mri and k′ = mr′i, the above equation can be reformulated as\n∀k, k′ ∈ {1, . . . ,m}, αj ( kβ − k′β ) = ∑ h≤m wh ( k m 1(h≥k) − k′ m 1(h≥k′) ) . (5)\nWe next recursively derive the weights wh, and show that they are non-negative and satisfy Equation (5). To begin, let wm = max {\n0, max k\n[ αjm ( kβ − (k − 1)β )]} ,\nand for all k = m,m− 1, . . . , 2, define\nwk−1 = 1\nk − 1 ( m∑ h=k wh − αjm ( kβ − (k − 1)β )) .\nBy definition, wm ≥ 0. Assume that for all h ≥ k, wh ≥ 0. Then\nwk−1 ≥ 1\nk − 1\n( wm − αjm ( kβ − (k − 1)β )) ≥ 0.\nTherefore all weights are non-negative. Furthermore, by rearranging the definition of wk−1, we have\nαj ( kβ − (k − 1)β ) = 1\nm ( m∑ h=k wh − (k − 1)wk−1 ) = 1 m ( k m∑ h=k wh − (k − 1) m∑ h=k−1 wh )\n= ∑ h≤m wh ( k m 1(h≥k) − k − 1 m 1(h≥k−1) ) .\nEquation (5) is proved for a particular pair k > k′ by summing the above expression for αj ( sβ − (s− 1)β ) over all s ∈ (k′, k] and canceling telescoping terms, and if k = k′, the statement holds regardless of the weights chosen.\nThis shows that (Γ, D) is implementable. It remains to argue the complexity. The running time of the construction of the weights is clearly poly(n,m) and the cardinality of Sj(αj) is m. The remaining piece is bounding the sum of weights as poly(n,m,αmax), which we defer to Appendix D.2.\nThe next theorem follows immediately from Lemma 4.2, Theorem 3.5, and the fact that the maximum revenue is at most R.\nTheorem 4.3. Consider the online auction design problem for the class of VCG auctions with bidder-specific reserves, Im. LetR = maxr,v Rev(r,v) and letD be the uniform distribution as described in Theorem 3.5. Then, the Oracle-Based Generalized FTPL algorithm with ΓVCG and D is oracle-efficient with complexity poly(n,m, T ) and has regret\nE [ max r∈Im T∑ t=1 Rev(r,vt)− T∑ t=1 Rev(rt,vt) ] ≤ O(n log(m)R √ T ).\nNote that in general, R is bounded by the number of bidders that can be served simultaneously, which is at most n.\nNow let us return to the infinite class I of all VCG auctions with reserve prices ri ∈ [0, 1]. We show Im is a finite “cover” for this class when the family of feasible sets S is the set of all subsets of size at most s, corresponding to single-item single-unit auctions (when s = 1) or more general single-item s-unit auctions.\nConsider any vector of reserves r ∈ I and let r′ ∈ Im be the vector obtained by rounding each reserve price down to the nearest multiple of 1/m. If vi > ri, then vi > r′i, so any bidder who would have been included in the basic VCG auction using reserves r is still included with r′. This can only increase the number of bidders who are serviced and therefore pay a charge. It is not hard to see, and we prove in Appendix D.1, that each bidder’s payment can decrease by at most 1/m. That is,\nmax r∈I T∑ t=1 Rev(r,vt)− max r∈Im T∑ t=1 Rev(r,vt) ≤ Ts m . (6)\nSetting m = √ T and using Theorem 4.3, we obtain the following result for the class of auctions I.\nTheorem 4.4. Consider the online auction design problem for the class of VCG auctions with bidderspecific reserves, I, in s-unit auctions. Let D be the uniform distribution as described in Theorem 3.5. Then, the Oracle-Based Generalized FTPL algorithm with ΓVCG and D is oracle-efficient with complexity poly(n, T ) and has regret efficient oracle-based online algorithm with regret\nE [ max r∈I T∑ t=1 Rev(r,vt)− T∑ t=1 Rev(rt,vt) ] ≤ O(ns log(T ) √ T )."
    }, {
      "heading" : "4.2 Envy-free Item Pricing",
      "text" : "In this section, we consider envy-free item pricing [17] in an environment with k heterogeneous items with a supply of s` ≥ 0 units for each item ` ≤ k.\nDefinition 4.5 (Envy-free Item-Pricing Auction). An envy-free item-pricing auction for k heterogeneous items, given supply s` for ` = 1, . . . , k is defined by a vector of prices a, where a` is the price of item `. The mechanism considers bidders i = 1, . . . , n in order and allocates to bidder i the bundle qi ∈ {0, 1}k that maximizes vi(qi)−a ·qi, among all feasible bundles, i.e., bundles that can be composed from the remaining supplies. Bidder i is then charged the price a · qi.\nExamples of such environments include unit-demand bidders in unlimited supply setting and singleminded bidders in unlimited supply setting, such as hypergraph pricing, where bidders seek hyper-edges in a hypergraph, and its variant the highway problem, where bidders seek hyperedges between sets of contiguous vertices [2, 17]. We will describe some of these problems in more detail later on.\nWe represent by Pm the class of all such envy-free item pricing auctions where a` is a multiple of 1/m for all `. Next, we discuss the construction of an implementable and admissible pair (Γ, D). Consider a bid profile where one bidder has value v for bundle e` and all other bidders have value 0 for all bundles. The revenue of auction a on such a bid profile is a`1(v≥a`). Note the similarity to the case of VCG auctions with bidder-specific reserve prices r, where bid profiles with a single non-zero valuation vi and revenue ri1(vi≥ri) were used to create an implementable construction for Γ. We show that a similar construction works for Pm.\nConstruction of Γ: Let ΓIP be a |Pm| × (kdlogme) binary matrix, where the `th collection of dlogme columns correspond to the binary encoding of auction’s price for item `. More formally, for any ` ≤ k and β ≤ dlogme, ΓIPaj is the βth bit of (the integer) ma`, where j = (`− 1)dlogme+β. Next, we show that ΓIP is admissible and (ΓIP, D) is implementable for any D with a bounded support. The proof of the following lemma is equivalent to that of Lemma 4.2 and appears in Appendix D.3 for completeness.\nLemma 4.6. ΓIP is (2, 1)-admissible. If D is supported on a subset of [−αmax, αmax], then (ΓIP, D) is implementable with complexity poly(k,m, αmax).\nOur main theorem follows immediately from Lemma 4.6, Theorem 3.5, and the fact that the revenue of the mechanism at every step is at most R. In general, R is at most n.\nTheorem 4.7. Consider the online auction design problem for the class of envy-free item pricing auctions, Pm. Let R = maxa,v Rev(a,v) and let D be the uniform distribution as described in Theorem 3.5. Then, the Oracle-Based Generalized FTPL algorithm with ΓIP and D is oracle-efficient with complexity poly(n, k,m, T ) and has regret\nE [ max a∈Pm T∑ t=1 Rev(a,vt)− T∑ t=1 Rev(at,vt) ] ≤ O ( kR log(m) √ T ) .\nConsider the class of all envy-free item-pricing auctions where a` ∈ [0, 1] is a real number and denote this class by P . We show that Pm is a discrete “cover” for P when there is an unlimited supply of all items (s` =∞ for all `) and the bidders have single-minded or unit-demand valuations.\nIn the single-minded setting, each bidder i is interested in one particular bundle of items q̂i. That is, vi(qi) = 0 for all qi 6= q̂i. Consider any vector of prices a ∈ P and let a′ ∈ Pm be the vector obtained by rounding each price down to the nearest multiple of 1/m. Since the price of every bundle is reduced, any bidder i who received bundle q̂i in auction a, also receives q̂i in auction a\n′. So, the revenue of the mechanism reduces by at most nk/m. That is,\nmax a∈P T∑ t=1 Rev(a,vt)− max a∈Pm T∑ t=1 Rev(a,vt) ≤ Tnk m .\nThe following result is an immediate consequence of the above discretization for the choice ofm = √ T ,\nthe fact that R ≤ n for single-minded bidders, and Theorem 4.7.\nTheorem 4.8. Consider the online auction design problem for the class of envy-free item pricing auctions, P , with single-minded bidders. Let D be the uniform distribution as described in Theorem 3.5. Then, the Oracle-Based Generalized FTPL algorithm with ΓIP andD is oracle-efficient with complexity poly(k, n, T ) and has regret\nE [ max a∈P T∑ t=1 Rev(a,vt)− T∑ t=1 Rev(at,vt) ] ≤ O ( nk log(T ) √ T ) .\nIn the unit-demand setting, each bidder i has valuation vi(e`) for item `, and wishes to purchase at most one item, i.e., item arg max` (vi(e`)− a`). We show that for any a ∈ P there is a′ ∈ Pm such that for any valuation profile v, Rev(a,v) − Rev(a′,v) ≤ O(nk/m). At a high level, we choose a′ as discounted prices such that items with higher prices are discounted at higher rates. It is not hard to see that under this condition, no bidder purchases a less expensive item in auction a′. So, the loss in the revenue of the auction is bounded by the discount on the items. Using this intuition, it is sufficient to find a′ ∈ Pm such that a` ≥ a′` ≥ a` − O(1/m) for all ` ≤ k, and a` − a′` > a`′ − a′`′ when a` > a`′ . In the next lemma, we provide one such mapping between a and a′ ∈ Pm that has an additive approximation guarantee. Hartline and Koltun [20] also provided a discretization of P that has multiplicative approximation guarantee, but using a discretized set different from Pm.\nLemma 4.9. For any a ∈ P there is a′ ∈ Pm, such that for any valuation profile v, Rev(a,v) − Rev(a′,v) ≤ nk/m.\nProof. For ease of exposition, let = 1/m. Without loss of generality, assume a1 ≤ a2 ≤ · · · ≤ ak. We next derive the desired a′. To begin, let a′1 be the largest multiple of less than or equal to a1. For ` = 2, . . . , k, let a′` be the largest multiple of less than or equal to a` such that a` − a′` ≥ a`−1 − a′`−1. Note that a′` is well defined, since we can begin by considering a′` = a ′ `−1 and then increase by until the condition is violated. This construction means that pricing of items with a larger ` is more attractive in a′ than it was\nin a. Thus, no bidder that prefers an item ` under a, would prefer any item `′ < ` under a′. Therefore, the revenue obtained from the bidder i who prefers ` under a is at least a′` under a ′, which implies the bound\nRev(a,v)− Rev(a′,v) ≤ nmax `≤k (a` − a′`).\nTo complete the proof, we argue by induction that a` − a′` ≤ ` . This clearly holds for ` = 1. For ` ≥ 2, the definition of a′`, in the absence of discretization to , would yield a ′ ` = a` − (a`−1 − a′`−1). With the discretization, we have\na′` ≥ a` − (a`−1 − a′`−1)− ≥ a` − (`− 1) − = a` − ` ,\nwhere we used the inductive hypothesis at `− 1.\nFor a choice of m = √ T , the fact that R ≤ n, and Theorem 4.7 we have the following result for the\nclass of auctions P .\nTheorem 4.10. Consider the online auction design problem for the class of envy-free item pricing auctions, P , with unit-demand bidders. Let D be the uniform distribution as described in Theorem 3.5. Then, the Oracle-Based Generalized FTPL algorithm with ΓIP andD is oracle-efficient with complexity poly(n, k, T ) and has regret\nE [ max a∈P T∑ t=1 Rev(a,vt)− T∑ t=1 Rev(at,vt) ] ≤ O ( nk log(T ) √ T ) ."
    }, {
      "heading" : "4.3 Level Auctions",
      "text" : "We consider the class of level auctions introduced by Morgenstern and Roughgarden [28]. These auctions can achieve (1− )-approximate revenue maximization, when the valuations of the bidders are drawn independently (but not necessarily identically) from a distribution [28], approximating the Myerson’s optimal auction [29]. Using our tools, we derive oracle-efficient no-regret algorithms for this auction class.\nThe s-level auctions realize a single-item single-unit allocation as follows:\nDefinition 4.11. An s-level auction θ is defined by s thresholds for each bidder i, 0 ≤ θi0 ≤ · · · ≤ θis−1 ≤ 1. For any bid profile v, we let bθi (vi) denote the index b of the largest threshold θ i b ≤ vi, or −1 if vi < θi0. If vi < θi0 for all i, the item is not allocated. Otherwise, the item goes to the bidder with the largest index bθi (vi), breaking ties in favor of bidders with smaller i. The winner pays the price equal to the minimum bid that it could have submitted and still won the item.\nWhen it is clear from the context, we suppress the notation of θ in bθi (vi). We consider two classes of s-level auctions, Rs,m and Ss,m, where Rs,m is the set of all auctions described by Definition 4.11 with thresholds that are multiples of 1/m and Ss,m ⊆ Rs,m is the set of s-level auctions such that the thresholds for each i are distinct.\nLet us first consider Ss,m and construct an admissible and implementable pair (Γ, D). Consider the bid profile in which the only non-zero bids are vn = `/m, for some 0 ≤ ` ≤ m, and vi = 1, for one bidder i < n. Note that bidder i wins the item in any such profile and pays θib for b = max{0, bn(vn)}. Consider matrix Γ whose columns correspond to the revenue of auctions in Ss,m on such bid profiles, with an additional column corresponding to the bid profile en. Clearly, (Γ, D) is implementable when supp(D) ⊆ R+. As for admissibility, take θ ∈ Ss,m and the corresponding row Γθ. Note that as vn = `/m increases for ` = 0, . . . ,m, there is an increase in bn(`/m) = −1, 0, . . . , s − 1, possibly skipping the initial −1. Once bn(vn) reaches 0 and then increases to s−1, so does the revenue of θ, i.e., θibn(vn). Since any two consecutive thresholds of θ are different, the thresholds of θib, for b ≥ 0, and θnb , for b ≥ 1, can be reconstructed by\nanalyzing the revenue of the auction and the values of vn at which the revenue changes. The remaining threshold θn0 is recovered by the bid profile v = en. This shows that any two rows of Γ are different and Γ is admissible. This reasoning is summarized in the following construction and the corresponding lemma, whose proof appears in Appendix D.4.\nConstruction of Γ: For i ∈ {1, . . . , n − 1} and ` ∈ {0, . . . ,m}, let vi,` = ei + (`/m)en. Let V = {vi,`}i,`∪{en}. Let ΓSL be the matrix of size |Ss,m|× |V | with entries indexed by (θ,v) ∈ Ss,m×V , such that ΓSLθ,v = Rev(θ,v).\nLemma 4.12. Let D be a distribution supported on a subset of [0, αmax]. Then (ΓSL, D) is implementable with complexity poly(n,m,αmax) and ΓSL is (m+ 1, 1/m)-admissible.\nOur next theorem is an immediate consequence of the implementability of (ΓSL, D) and Theorem 3.5.\nTheorem 4.13. Consider the online auction design problem for the class of s-level auctions with no repeated thresholds, Ss,m. Let D be the uniform distribution as described in Theorem 3.5. Then, the Oracle-Based Generalized FTPL algorithm with ΓSL and D is oracle-efficient with complexity poly(n,m, T ) and has regret\nE [ max\nθ∈Ss,m T∑ t=1 Rev(θ,vt)− T∑ t=1 Rev(θt,vt)\n] ≤ O(nm2 √ T ).\nNext, we consider the class of auctions Rs,m and construct an admissible and implementable pair (Γ, D). As a warm-up, we demonstrate how the structure of Rs,m differs from Ss,m and argue that ΓSL is not admissible forRs,m. Take v such that vi = 1 and vn is some multiple of 1/m. Similarly as before, as vn increases there is also an increase in bn(vn) and the revenue θibn(vn). However, the thresholds of bidder n are no longer distinct, so bn(vn) can skip certain values, and as a result θib is not revealed for all b. In addition, when the thresholds of bidder i are not distinct, we have that even when bn(vn) strictly increases, there might be no increase in the revenue, and as a result θnb cannot be reconstructed.\nTo identify an admissible construction for Γ, we first analyze the structure of auctions in Rs,m. Let Bib(θ) denote the set of all bids vi such that b θ i (vi) = b; we refer to such sets as buckets, since they partition i’s valuations. Given a bucket Bib(θ), we define its competing bucket as any B i′ b′(θ) such that either i\n′ < i and b′ = b− 1 or i′ > i and b′ = b. Note that the payment of a winning bidder i is θib if another bidder’s bid falls into a competing bucket of Bib(θ). By definition, B i b(θ) = ∅ when θib = θib+1. The next lemma, whose proof appears in Appendix D.5, shows that we can restrict our attention to auctions for which empty buckets satisfy a strong structural property:\nLemma 4.14. Let Rs,m ⊆ Rs,m be the set of auctions θ with the following property: Every non-empty bucket Bib(θ) with b ≥ 1 has a non-empty competing bucket. Then, for any θ ∈ Rs,m, there is θ\n′ ∈ Rs,m, such that\n∀v ∈ [0, 1]n, Rev(θ,v) = Rev(θ′,v).\nLemma 4.14 implies that any no-regret algorithm for the classRs,m is also a no-regret algorithm for the classRs,m. So, it suffices to analyze the class of auctionsRs,m.\nNext, we construct an admissible and implementable pair (Γ, D) for Rs,m, by considering revenue of auctions on bid profiles in which the only non-zero bids are vi = 1 and vi′ that is a multiple of 1/m. We show that for any two θ,θ′ ∈ Rs,m, there is one such bid profile where the revenues of these auctions differ. At a high level, we prove this by taking θib 6= θ′ib with a non-empty bucket Bib(θ) and showing that there is a bid vi′ in one of the competing buckets that enforces two different prices θib 6= θib. This is further formalized in the construction below and Lemma 4.15, whose proof appears in Appendix D.6.\nConstruction of Γ: Let V be the set of all bid profiles vi,i′,` = ei + (`/m)ei′ for i 6= i′ ∈ {1, . . . , n} and ` ∈ {0, . . . ,m}. Let ΓRL be a |Rs,m| × |V | matrix with entries indexed by (θ,v) ∈ Rs,m × V , such that ΓRLθ,v = Rev(θ,v).\nLemma 4.15. Let D be a distribution supported on a subset of [0, αmax]. Then, (ΓRL, D) is implementable with the complexity poly(n,m,αmax) and ΓRL is (m+ 1, 1/m)-admissible.\nThe next theorem is a direct consequence of Lemmas 4.15 and 4.14.\nTheorem 4.16. Consider the online auction design problem for the class of s-level auctions with repeated thresholds, Rs,m. Let D be the uniform distribution as described in Theorem 3.5. Then, the Oracle-Based Generalized FTPL algorithm with ΓRL and D is oracle-efficient with complexity poly(n,m, T ) and has regret\nE [ max\nθ∈Rs,m T∑ t=1 Rev(θ,vt)− T∑ t=1 Rev(θt,vt)\n] ≤ O(n2m2 √ T )."
    }, {
      "heading" : "5 Stochastic Adversaries and Stronger Benchmarks",
      "text" : "So far our results apply to general adversaries, where the sequence of adversary actions are arbitrary and where we showed that the payoff of the learner is at least as large as the payoff of the best action in hindsight. Can we make stronger statements about the average payoff of a no-regret learning algorithm when we impose distributional assumptions on the sequence of the adversary?\nWe start with the easier setting where the actions of the learner are drawn i.i.d. and then we analyze the slightly more complex setting where the actions of the learner follow a fast-mixing Markov chain. For both settings we show that the average payoff of the learning algorithm is as large as the optimal expected payoff, in expectation over the i.i.d. distribution in the i.i.d. setting and over the stationary distribution in the Markovian setting.\nWhen applied to the online optimal auction setting, combining these results with approximate optimality results of simple auctions such as s-level auctions or VCG with bidder-specific reserves, we get that the average revenue of our online learning algorithms compete with the revenue achieved by the unrestricted optimal auction for these distributional settings and not only with the best auction within the class over which our algorithms were learning."
    }, {
      "heading" : "5.1 Stochastic Adversaries",
      "text" : "I.I.D. Adversary One extreme case is to assume that the adversary’s action yt at each iteration is drawn independently and identically from the same unknown distribution F . This leads to the i.i.d. learning setting. An easy application of the Chernoff-Hoeffding bound yields that for such a learning setting, the average payoff of a no-regret learner is at least as large as the best payoff one could achieve in expectation over the distribution F .\nLemma 5.1. Suppose that y1, . . . , yT are i.i.d. draws from a distribution F . Then for any no-regret learning algorithm, with probability at least 1− δ,\n1\nT T∑ t=1 Ext [f(xt, yt)] ≥ sup x∈X Ey∼F [f(x, y)]− √ log(2/δ) 2T − REGRET T . (7)\nProof. Let x∗ = arg supx∈X Ey∼F [f(x, y)]. By the definition of regret we have that for any y1, . . . , yT ,\nT∑ t=1 Ext [f(xt, yt)] ≥ sup x∈X T∑ t=1 f(x, yt)− REGRET ≥ T∑ t=1 f(x∗, yt)− REGRET. (8)\nObserve that the random variables Zt = f(x∗, yt) are drawn i.i.d. with expected value Ey∼F [f(x∗, y)] and are bounded in [0, 1]. Hence, by the Hoeffding bound, we get that with probability at least 1− 2e−2T 2 :\n1\nT T∑ t=1 f(x∗, yt) ≥ Ey∼F [f(x∗, y)]− . (9)\nBy setting = √\nlog(2/δ) 2T and combining the two bounds we get the result.\nMarkovian Adversary Suppose that the choice of the adversary yt follows a stationary and reversible Markov process based on some transition matrix P (y, y′) with a stationary distribution F . Moreover, consider the case where the set Y is finite. For any Markov chain, the spectral gap γ is defined as the difference between the first and the second largest eigenvalue of the transition matrix P (the first eigenvalue always being 1). We will assume that this gap is bounded away from zero. The spectral gap of a Markov chain is strongly related with its mixing time. In this work we will specifically use the following result of Paulin [31], which is a Bernstein concentration inequality for sums of dependent random variables that are the outcome of a stationary Markov chain with spectral gap bounded away from zero. A Markov chain y1, . . . , yT is stationary if y1 ∼ F , where F is the stationary distribution. For simplicity, we focus on stationary chains, though similar results hold for non-stationary chains (see Paulin [31] and references therein).\nTheorem 5.2 (Paulin [31], Theorem 3.8). LetX1, . . . , Xz be a stationary and reversible Markov chain on a state space Ω, with stationary distribution F and spectral gap γ. Let g : Ω→ [0, 1] and Sz = 1z ∑z i=1 g(Xi). Then\nPr[|Sz − EX∼F [g(X)]| > ] ≤ 2 exp ( − zγ 2\n4 + 10\n) . (10)\nLemma 5.3. Suppose that y1, . . . , yT are a stationary and reversible Markov chain based on a transition matrix P , with stationary distribution F and with spectral gap γ. Then for any no-regret learning algorithm, with probability at least 1− δ:\n1\nT T∑ t=1 Ext [f(xt, yt)] ≥ sup x∈X Ey∼F [f(x, y)]−\n√ 14 log(2/δ)\nγT − REGRET T . (11)\nProof. Let x∗ = arg supx∈X Ey∼F [f(x, y)]. By the definition of regret we have that for any sequence y1, . . . , yT ,\nT∑ t=1 Ext [f(xt, yt)] ≥ sup x∈X T∑ t=1 f(x, yt)− REGRET ≥ T∑ t=1 f(x∗, yt)− REGRET. (12)\nSince y1, . . . , yT are a Markov chain, by applying Theorem 5.2 to this chain and to the function f(x∗, ·), we obtain that with probability at least 1− 2 exp ( − Tγ 2\n4+10\n) ,\n1\nT T∑ t=1 f(x∗, yt) ≥ Ey∼F [f(x∗, y)]− . (13)\nIf we set = √\n14 log(2/δ) γT then we have, either > 1, in which case the inequality is trivial, since f(x, y) ∈ [0, 1], or if ≤ 1, then = √\n14 log(2/δ) γT ≥\n√ (4+10 ) log(2/δ)\nγT , which implies that the inequality holds with probability 1− δ.\nExample 5.4 (Sticky Markov Chain). Consider a Markov chain where at every iteration yt is equal to yt−1 with some probability ρ ≥ 1/2 and with the remaining probability (1 − ρ) it is drawn independently from some fixed distribution F . It is easy to see that the stationary distribution of this chain is equal to F . We can bound the spectral gap of this Markov chain by Cheeger’s bound. The Cheeger constant for a finite state, reversible Markov chain is defined as\nΦ = min S⊆Ω:F (S)≤1/2\n∑ x∈S ∑ y∈Sc F (x)P (x, y)\nF (S) = min S⊆Ω:F (S)≤1/2\n∑ x∈S ∑ y∈Sc F (x)(1− ρ)F (y)\nF (S)\n= min S⊆Ω:F (S)≤1/2\n(1− ρ)F (S) · F (S c)\nF (S) = min S⊆Ω:F (S)≤1/2 (1− ρ)F (Sc) ≥ 1− ρ 2\nMoreover, by the Cheeger bound [8] we know that γ ≥ Φ22 ≥ (1−ρ)2\n4 . Thus we get that for such a sequence of adversary actions, with probability 1− δ,\n1\nT T∑ t=1 Ext [f(xt, yt)] ≥ sup x∈X Ey∼F [f(x, y)]− 2 1− ρ\n√ 14 log(2/δ)\nT − REGRET T (14)"
    }, {
      "heading" : "5.2 Implications for Online Optimal Auction Design",
      "text" : "Consider the online optimal auction design problem for a single item and n bidders. Suppose that the adversary who picks the valuation vectors v1, . . . ,vT , is Markovian and that the stationary distribution F of the chain is independent across players, i.e., the stationary distribution is a product distribution F = F1 × . . .× Fn.\nThen we know that the optimal auction for this setting is what is known as Myerson’s auction [29], which translates the players’ values based on some monotone function φ, known as the ironed virtual value function and then allocates the item to the bidder with the highest virtual value, charging payments so that the mechanism is dominant strategy truthful.\nA recent result of Morgenstern and Roughgarden [28] shows that level auctions approximate Myerson’s auction in terms of revenue. In particular, if distributions Fi are bounded in [1, H], then the class of s-level auctions with s = Ω(1 + log1+ H), where the thresholds can be any real numbers, achieves expected revenue at least (1 − ) of the expected optimal revenue of Myerson’s auction. We prove and use a similar result for s-level auctions that uses the discretized set Rs,m. That is, when s = O(1/ ) and m = O(1/ ), we have\nmax θ∈Rs,m\nEv∼F [Rev(θ,v)] ≥ OPT(F )− . (15)\nThe proof of this equation appears in Appendix E. Combining the results in this section with the aforementioned results we get the following theorem:\nTheorem 5.5 (Competing with Overall Optimal). Consider the online optimal auction design problem for a single item among n bidders, where the sequence of valuation vectors v1, . . . ,vT , is Markovian, following a stationary and reversible Markov process, with a stationary distribution F = F1 × . . . × Fn that is a product distribution across bidders, and with a spectral gap of γ > 0. Then the oracle-efficient online learning algorithm which optimizes over the set of s-level auctions Rs,m with s = O(T 1/6n−2/3) and with a discretization of the threshold levels of size m = O(T 1/6n−2/3), guarantees, with probability at least 1− δ, average expected revenue at least:\n1\nT T∑ t=1 Eθt [Rev(θt,vt)] ≥ OPT(F )− 1 m −\n√ 14 log(2/δ)\nγT −O ( m2n2√ T ) ≥ OPT(F )−O ( n2/3 T 1/6 ) , (16)\nwhere OPT(F ) is the optimal revenue achievable by any dominant strategy truthful mechanism for valuation vector distribution F .\nExample 5.6 (Valuation Shocks). Consider the setting where valuations of players in the beginning of time are drawn from some product distribution F = F1× . . .×Fn. Then at every iteration with some probability ρ the valuations of all players remain the same as in the previous iteration, while with some probability 1− ρ, there is a shock in the market and the valuations of the players are re-drawn from distribution F . As we analyzed in the previous section, the spectral gap of the Markov chain defined by this setting is at least γ ≥ (1−ρ) 2\n4 . Thus we get a regret bound which depends inversely proportionally with the quantity 1− ρ. Hence, our online learning algorithm achieves revenue that is close to the optimal revenue achievable by any dominant strategy truthful mechanism for the distribution F . However, it achieves this guarantee even if the valuations of the players are not drawn i.i.d. at every iteration and even if the learner does not know the distribution F or when the valuations of the players are going to be re-drawn or what the rate ρ of shocks in the markets is."
    }, {
      "heading" : "6 Contextual Online Learning (Side Information)",
      "text" : "We now consider a generalization of the online optimal auction setting, where at every iteration the learner also observes contextual information. The context σt at each iteration comes from some abstract context space Σ. In this setting the learner wants to use such contextual information to improve his performance. Specifically, the goal of the learner is to compete with a set of policies Π, where a policy is a mapping from a context σt to an auction π(σt).\nGiven a class of auctions A, a set of possible valuations V , a policy class Π and an unknown sequence of bid profiles and contexts (σ1,v1), . . . , (σT ,vT ) ∈ Σ × Vn, our goal is to provide an online algorithm that picks a policy πt ∈ Π at every time step and achieves a revenue that is close to the revenue of the best policy π ∈ Π in hindsight. That is,\nE [ max π∈Π T∑ t=1 Rev(π(σt),vt)− T∑ t=1 Rev(πt(σt),vt) ] ≤ o(T )."
    }, {
      "heading" : "6.1 Non-Contextual to Contextual Learning for Separable Policies",
      "text" : "We will give a reduction from a non-contextual setting to a contextual one in the general learning setting rather than a specific analysis for the auction setting. Hence, we consider the learning setting of Section 3 in which the learner has an action space X , the adversary has an action space Y and the payoff function of the learner is given by f(x, y) for each x ∈ X and y ∈ Y .\nWe will then consider the contextual version of this setting, where the learner also observes contextual information σ ∈ Σ, and picks a policy π ∈ Π where Π is a subset of the mappings from a context σ to an action x ∈ X . The action space of the adversary is a context σ ∈ Σ and an action y ∈ Y . Then the payoff of the learner is given by:\nfc(π, (σ, y)) = f(πt(σ), yt) (17)\nwhile the regret of any algorithm is given by:\nREGRET = E [ max π∈Π T∑ t=1 f(π(σt), yt)− T∑ t=1 f(πt(σt), yt) ] .\nThe offline oracle assumption now asks for an algorithm that takes as input a distribution over contexts and adversary actions and returns the best policy in the policy space for this distribution.\nThe contextual learning setting is another instance of the general learning setting, with learner action space Xc = Π ⊆ (Σ → X ), adversary action space Yc = Σ × Y and payoff function fc(xc, yc) as defined above. Moreover, a contextual offline oracle is an offline oracle for this new learning setting.\nIf we are given an admissible and implementable matrix Γ in the original learning setting, then we show how to construct an admissible and implementable matrix Γc for the contextual learning. For this reduction we will use the notion of a separator of the policy space, defined in [35].\nDefinition 6.1 (Separator). A set S ⊆ Σ of contexts is a separator for a policy space Π, if for any two policies π, π′ ∈ Π, there exists a context σ ∈ S such that π(σ) 6= π′(σ).\nDefinition 6.2 (Contextual S-extension of a matrix Γ). For any matrix |X | × N matrix Γ, we define its contextual S-extension ΓS as an |Π| × (|S| · N) matrix, where each column jc is associated with a pair (σ, j) for σ ∈ S and j ∈ [N ] and such that the value of ΓS at coordinates (π, (σ, j)) is equal to the entry of matrix Γ at coordinates (π(σ), j), i.e.,\nΓSπ,(σ,j) = Γπ(σ)j . (18)\nLemma 6.3 (Contextual Admissibility). If Γ is a (κ, δ)-admissible matrix for a learning setting and S is a separator for the policy Π, then the contextual S-extension Γc is a (κ, δ)-admissible matrix for the contextual learning setting.\nProof. First we argue that ΓS has distinct rows. We will show that for any two rows π, π′, there exists a column (σ, j) on which they differ. Since S is a separator, there must exist one σ∗ ∈ S on which π(σ∗) 6= π′(σ∗). Now by the admissibility of the original matrix Γ, we know that for any two x, x′ ∈ X , there exists a column j of the original matrix such that Γx,j 6= Γx′,j . Applying the latter for π(σ∗), π′(σ∗) ∈ X , we get that there exists a j∗, such that Γπ(σ∗),j∗ 6= Γπ′(σ∗),j∗ . By the definition of Γc, the latter implies that Γcπ,(σ∗,j∗) 6= Γπ′,(σ∗,j∗). Thus the two rows π, π\n′ of matrix Γ differ at column (σ∗, j∗). Now we argue that the quantities κ, δ (as defined in Definition 3.2), for the matrix ΓS are the same as the quantities for matrix Γ. We remind the reader that κ is the maximum number of distinct elements that appear in a column and δ is the minimum non-zero absolute difference between any two elements of a column. The reason that these quantities don’t change is that they depend only on the set of values that appear in a column and not of the actual vector of values. Moreover, the set of quantities that appear in column (σ, j) of matrix ΓS , is a subset of the set of quantities that appear in column j of matrix Γ. Since by taking a subset of the column we cannot increase the number of distinct elements and the minimum non-zero absolute difference of any two elements in the set, we conclude that ΓS is also (κ, δ)-admissible.\nLemma 6.4 (Contextual Implementability). If a pair (Γ, D) of a translation matrix and a distribution is implementable in the original learning setting, then the pair (ΓS , D) is implementable in the contextual learning setting.\nProof. The intuition of the proof is as follows: if we know that we can simulate every column in Γ with a sequence of polynomially many weighted inputs {(y, wy)}, then we can simulate each column of Γc associated with context σ ∈ S and column i of Γ, by a sequence of weighted contextual inputs {(σ, y, wy)}, which is essentially a contextually annotated copy of the sequence of inputs we used to simulate column i of Γ. We now show this intuition more formally.\nImplementability in the original setting implies that for any column i ∈ {1, . . . , N} of matrix Γ there exists a constant ci such that for any α ∈ supp(D) there exist weights {wi,αy }y∈Y such that |{y : wi,αy > 0}| ≤ poly(N,T ) and α (Γxi − ci) = ∑ y∈Y w i,α y f(x, y) and for all x ∈ X .\nIn the contextual learning setting we need to argue that for any column (σ, i) ∈ S × [N ] of matrix ΓS there exists a constant r(σ,i) such that for any α ∈ supp(D) there exist weights {w (σ,i),α (σ′,y) }(σ′,y)∈Σ×Y , such that |{(σ′, y) : w(σ,i),α(σ′,y) > 0}| ≤ poly(N,T ) and for all π ∈ Π\nα(Γcπ,(σ,i) − r(σ,i)) = ∑\n(σ′,y)∈Σ×Y\nw (σ,i),α (σ′,y) fc(π, (σ\n′, y)) ≡ ∑\n(σ′,y)∈Σ×Y\nw (σ,i),α (σ′,y) f(π(σ ′), y).\nThe construction of such weights is straightforward: for each y ∈ Y , set w(σ,i),α(σ,y) = w i,α y and for σ′ 6= σ set w (σ,i),α (σ′,y) = 0. Moreover, we set r(σ,i) = ci Now observe that:\nα(Γcπ,(σ,i) − r(σ,i)) = α(Γπ(σ),i − ci) = ∑ y∈Y wi,αy f(π(σ), y) = ∑ (σ′,y)∈Σ×Y w (σ,i),α (σ′,y) f(π(σ ′), y).\nThe latter completes the proof.\nGiven the above two lemmas we can now invoke Theorem 3.5 applied to the contextual setting and get the result:\nCorollary 6.5. Let Γ be a (κ, δ)-admissible matrix with N columns and γ = maxi,j Γij and let D be the uniform distribution on [0, 1/η] for η = √ γδ/(2Tκ). Then the regret of the Generalized FTPL algorithm applied to the contextual setting and with the contextual extension ΓS of matrix Γ with respect to a separator S of size d, achieves regret:\nREGRET ≤ 2Nd √ 2Tκγ/δ.\nMoreover, assuming access to a contextual offline oracle, the latter algorithm can be implemented efficiently in time poly(N, d, T ).\nIn the context of online binary classification where the features are vectors of boolean variables, [35] presents a set of examples of policy spaces that are separable. To portray the applicability of our contextual theorem, we present an example of a policy space for an auction problem that is also separable.\nExample 6.6 (ORs of Boolean Features). Consider the case where each feature vector σ is a boolean vector in {0, 1}r. Moreover, consider the case of online optimal auction design over single-item second price auctions with bidder specific reserves. An example of a policy space that is separable is a policy that resembles an A/B testing over reserve prices. The auctioneer splits his reserve prices into two disjoint setsA and B (for instance, A could be a set of vectors of low reserve prices, below some threshold, and B is a set of vectors of high reserves prices). Then the set of policies is as follows: for each context σ = (σ1, . . . , σr) take the OR of a subset of the boolean coordinates. If the OR evaluates to 1, then pick some vector of bidder specific reserve prices from set A and if the OR is 0 then pick any vector of reserve prices from set B. The whole set of policies is then generated by picking which subset of the coordinates to use for the OR function and which vector of reserves from A to output on 1 and which vector of reserves from B to output on 0. By running our contextual online learning algorithm over such a policy space, the auctioneer can learn which of the boolean coordinates are indicative of a high valuation for the players and when any one of them is 1 it will place a high reserve price, optimizing also over the exact vector of reserves within a high regime. Otherwise it will find an optimal vector of reserves from a low regime.\nObserve that the set of r boolean vectors that are 1 on only one coordinate, plus the all-zero boolean vector, is a separator for this policy space. Consider any two set of different policies π, π′. If they use the same OR function, then they must differ in which vector of reserves they use from A or B. Thus they must be outputting a different action at some of the boolean vectors of the separator. If they differ in the OR function, then suppose that one includes coordinate j and the other doesn’t. Then on the boolean vector which is 1 on only coordinate j, the one policy evaluates to 1 and picks a reserve vector from set A, while the other evaluates to 0 and picks a reserve vector from set B which has to be different, since A and B are disjoint. Thus the size of the separator for this class of policies is of order O(r), while the size of the policy space is exponential in r.\nSimilar analysis can be done when the policy is using the AND of boolean features rather than the OR."
    }, {
      "heading" : "6.2 Transductive Contextual Setting",
      "text" : "We now consider the case where the learner knows a priori the set of contexts that could potentially arise, i.e., we assume that he knows that all contexts σ1, . . . , σT come from a set S, which we will refer to as the transductive set. We do not require that he knows the multiplicity of each context or the sequence under which contexts arrive. However, we do allow the set S to be of size as large as T .\nIn this setting, ignoring some technical details, we could treat the transductive set S as a separator set from the last section. However, by doing so, the regret guarantee that we would derive from the analysis of the previous section grows super-linearly in T , when the size of the set S is of Θ(T ). Thus in order to guarantee sub-linear regret in the transductive setting we need a tighter analysis. To achieve this we will leverage the fact that in the transductive setting S is the whole set of contexts that will arise, which is a stronger property than being a separator. This will allow us to prove a stronger stability lemma than the one that would arise from invoking Lemma 3.4 for the contextual learning setting. Moreover, we will use a perturbation distribution D that has mean zero, leading to cancellations in the cumulative error term, that make that term not grow linearly with the size of S but rather as the square root of the size of S. The combination of these two improvements leads to sub-linear regret even when |S| = Θ(T ).\nWe will still assume that we have a (κ, δ)-admissible translation matrix Γ for the non-contextual problem and a (ρ, 1/δ)-dispersed distributionD, such that (Γ, D) is implementable in the non-contextual setting. The algorithm that we will analyze is the Generalized FTPL algorithm in the contextual learning setting, with the contextual extension ΓS of matrix Γ (where S is the transductive set) and with the same distribution D.\nWe first show an improved stability property of this algorithm. Even though the number of columns of matrix ΓS is |S| ·N we can show that the stability of the algorithm does not depend on |S|.\nLemma 6.7. Consider the Generalized FTPL algorithm in the contextual learning setting with translation matrix the contextual extension ΓS of a (κ, δ)-admissible matrix Γ with N columns and with a (ρ, 1/δ)dispersed distribution D. Then,\nE [ T∑ t=1 fc(πt+1, (σt, yt))− fc(πt, (σt, yt)) ] ≤ 2TNκρ.\nProof. We will show that for each t ≤ T ,\nE[fc(πt+1, (σt, yt))− fc(πt, (σt, yt))] ≤ 2Nκρ. (19)\nSince fc(π, (σt, yt)) = f(π(σt), yt) and since f(x, y) ∈ [0, 1], it suffices to show that Pr[πt+1(σt) 6= πt(σt)] ≤ 2Nκρ.\nObserve that if πt+1(σt) 6= πt(σt) then it must be that Γπt+1(σt),i 6= Γπt(σt),i, for some i ∈ [N ], by the admissibility of matrix Γ in the non-contextual setting. Thus we need to show that the probability that there exists an i such that Γπt+1(σt),i 6= Γπt(σt),i is at most 2Nκρ. By the union bound it suffices to show that for any given i, the probability that Γπt+1(σt),i 6= Γπt(σt),i is at most 2κρ.\nThe proof of this fact then follows identical arguments as in the proof of the non-contextual stability Lemma 3.4 and we omit it for succinctness.\nFinally, we also show that if one uses a mean-zero Gaussian distribution D with sufficiently high variance, then the error term that is accumulated grows as the square root of the number of columns of the contextual matrix, rather than linearly. The proof of this requires a more detailed analysis of the Gaussian noise, and can be found in the appendix. Combining the two improvements we get the following theorem (see Appendix F for the proof).\nTheorem 6.8. Let Γ be a (κ, δ)-admissible matrix with N columns and γ = maxi,j Γij and let D = U [−ν, ν]. Then the regret of the Generalized FTPL algorithm in the transductive contextual learning setting with translation matrix ΓS and with the same distribution D can be bounded as\nREGRET ≤ 2TNκ νδ\n+ 2γν √ 2N |S| ln |X |.\nFor ν = √ TκN 1 4\n√ δγ(2|S| ln |X |) 1 4\nthe above bound becomes O ( N 3 4 (|S| ln |X |) 1 4 √ Tκγ δ ) . Since |S| ≤ T , the latter\nis O ( (NT ) 3 4 (ln |X |) 1 4 √ κγ δ ) .\nObserve that our application on VCG auctions with bidder-specific reserves and on envy-free item pricing continue to hold even for perturbation distributions D that have support on the negative part of the real line. Thus the results for those applications immediately extend to the transductive contextual setting by invoking the theorem above."
    }, {
      "heading" : "7 Approximate Oracles and Approximate Regret",
      "text" : "As we saw, the Oracle-Based Generalized FTPL algorithm requires an oracle to choose the optimal learner’s action xt at time step t against a set of adversary’s actions. In this section, we extend our main results regarding the Oracle-Based Generalized FTPL algorithm to work with oracles that only return approximately optimal actions for the learner. An offline approximation oracle is defined formally as follows:\nDefinition 7.1 (Offline Approximation Oracle). An offline approximation oracle for set of learner’s actions X and function f , C-OPT(f,X ) where C ≤ 1, is any algorithm that receives as input a weighted set of adversary actions S = {(w`, y`)}`∈L, wk ∈ R+, yk ∈ Y , and returns x ∈ X , such that∑\n(w,y)∈S\nwf(x, y) ≥ C max x∈X ∑ (w,y)∈S wf(x, y).\nAs discussed earlier, access to a (1 − )-approximate oracle is needed for achieving no-regret results. That is, using standard online-to-batch reductions [6, 11], one can turn a polynomial time online no-regret algorithm into a polynomial time additive approximation scheme for the offline problem. So, when the best approximation for a problem is obtained through a C-optimization oracle, there is no hope for achieving no-regret results. Instead Kakade et al. [26] introduced an alternative measure of regret, called C-REGRET, for competing with offline approximation algorithm. Formally, the C-REGRET of an online maximization problem is defined as\nC-REGRET = C max a∈A\n1\nT T∑ t=1 f(x, yt)− E\n[ 1\nT T∑ t=1 f(xt, yt)\n] .\nWe consider several types of approximation oracles, such as (1− )-approximate oracle (e.g., FPTAS algorithms), approximation through relaxation of the objective, and approximation oracles that stem from Maximal-in-Range (MIR) algorithms. We show that a natural extension of the Oracle-Based Generalized FTPL algorithm,, with approximation oracle, displayed below, obtains vanishing REGRET or C-REGRET.\n(1− )-Approximation Oracle We show that any FPTAS approximation algorithm is sufficient for achieving the main results of our paper. In particular, we can extend the analysis of Theorem 3.5, and the stability lemma (Lemma 3.1) to work with (1− )-approximation while incurring an additional regret of T . For the choice of = O(1/ √ T ) this is truly a no-regret algorithm. This theorem is also the basis for handling working with the weaker integral oracle and its proof is deferred to section C.\nAlgorithm 3: Approximate Oracle-Based Generalized FTPL Input: positive |X | ×N and an implementable (Γ, D) and an offline approximation oracle C-OPT Draw αj ∼ D for j = 1, . . . , N . for t = 1, . . . , T do\nSet S ← {(1, y1), . . . , (1, yt−1)} ∪ ⋃ j≤N Sj(αj). Set xt = C-OPT(f,X )(S). Observe yt and receive payoff f(xt, yt).\nend for\nTheorem 7.2. Let Γ be a (κ, δ)-admissible matrix with N columns and γ = maxx,j Γxj and let D be the uniform distribution on [0, 1/η] for η = √ γδ/(2Tκ). Furthermore, assume (Γ, D) is implementable with complexity g(N,T ). Then, Algorithm 3 with a (1− )-OPT oracle is oracle-efficient with per-round complexity O(T + g(N,T )) and regret of\nREGRET ≤ 2N √ 2Tκγ/δ + T.\nApproximation through Relaxation\nAnother large class of approximation algorithms achieve their approximation guarantees by (exactly) optimizing a relaxation of the objective functions. More formally, if there is a function F : X × Y → R, such that Cf(x, y) ≤ F (x, y) ≤ f(x, y) and there is an offline approximation oracle OPT(F,X ), then any online algorithm for F is also online algorithm with vanishingC-REGRET for f . This result is more formally stated below.\nTheorem 7.3. Let F be a functions such that for any x ∈ X and y ∈ Y , f(x, y) ≥ F (x, y) ≥ Cf(x, y), Let ΓF be a (κ, δ)-admissible matrix with N columns and γ = maxx,j Γxj and let D be the uniform distribution on [0, 1/η] for η = √ γδ/(2Tκ). Furthermore, assume (ΓF , D) is implementable for function F with complexity g(N,T ) then Algorithm 3 is oracle-efficient with per-round complexity O(T + g(N,T )) and regret of\nC-REGRET ≤ 2N √ 2Tκγ/δ.\nA similar observation was made by Balcan and Blum [2] regarding approximation algorithms that use linear optimization as a relaxation and therefore can be efficiently optimized by the standard FTPL algorithm of Kalai and Vempala [27]. Our work extends this observation to any relaxation of function f that has an FPTAS and an admissible and implementable translation matrix.\nRoughgarden and Wang [33] as a Relaxation. The approach of Roughgarden and Wang [33] for achieving a 1/2-regret for single-item second price auctions with bidder-specific reserves, falls exactly in the relaxation approximation framework. They give a relaxed objective which admits a polynomial time offline oracle and which is always within a factor 2 from the original objective. Then they run an oracle based online learning algorithm for the relaxed objective. However, in their case the relaxed objective corresponds to an online linear optimization problem and can be solved with the standard FTPL algorithm of Kalai and Vempala [27]. The theorem above shows that the same approach extends even if the relaxed objective does not reduce to an online linear optimization problem but to a problem that can be tackled by our Generalized FTPL.\nApproximation by Maximal-in-Range Algorithms\nAnother interesting class of approximation algorithms is Maximal-in-Range (MIR) algorithms. An MIR algorithm commits to a set of feasible solutions X ′ ⊆ X independently of the input to the algorithm and\noutputs the best solution x ∈ X ′. That is, an MIRC-approximation algorithm forms an approximation oracle C-OPT(f,X )(S) = OPT(f,X ′)(S) for any S. Consider an MIR approximation algorithm and ΓX translation matrix and distribution D such that ΓX is admissible for X and (ΓX , D) is implementable. Clearly, ΓX restricted to the set of rows in X ′ is also admissible and implementable for any X ′ ⊆ X . In fact ΓX ′ is (κ′, δ′) admissible for κ′ ≤ κ and 1δ′ ≤ 1 δ . Thus even better regret guarantees could be achievable if one uses the smaller admissibility quantities of matrix ΓX ′ . Therefore, an MIR C-approximation algorithm leads to an efficient online algorithm with vanishing C-REGRET. More formally we have:\nTheorem 7.4. Let ΓX be a (κ, δ)-admissible matrix with N columns and γ = maxx,j Γxj and let D be the uniform distribution on [0, 1/η] for η = √ γδ/(2Tκ). Furthermore, assume (ΓX , D) is implementable with complexity g(N,T ). Then Algorithm 3 used with any MIR approximation algorithm C-OPT is an efficient algorithm with per-round complexity O(T + g(N,T )) and regret of\nC-REGRET ≤ 2N √ 2Tκγ/δ.\nFurthermore, setting the oracle specific, η = √ γδ′/(2Tκ′), gives a stronger regret bound of 2N √ 2Tκ′γ/δ′."
    }, {
      "heading" : "8 Additional Applications and Connections",
      "text" : "In this section, we discuss an application of our oracle efficient learning approach to the problem of online welfare maximization in multi-unit auctions, to no-regret learning in simultaneous second price auctions and discuss the connections between our notions of admissibility and implementability with other statistical measures of complexity from learning theory."
    }, {
      "heading" : "8.1 Polynomial Algorithm for Online Welfare Maximization in Multi-Unit Auctions",
      "text" : "In this section, we consider single-item multi-unit auctions that has 1/2-approximation Maximal-in-Range (MIR) algorithm. We show how the results of Section 7 can be applied to this problem to achieve a truly polynomial time online algorithm with vanishing 12 -REGRET.\nWe consider an online learning variant of an n-bidder multi-unit environment, better modeled as a set of k identical items. Each bidder i has a monotonic valuation function vi : [k]→ [0, 1]. In other words, bidder i has marginal valuation µi(`) for receiving the `th item and the total utility of bidder i for receiving the qith items is vi(qi) = ∑qi s=1 µi(s). The goal is to find an allocation q that maximized the total welfare in time polynomial in n and log(k). In the online learning setting, every day t a fresh set of bidders arrives with some new valuation vti and the learner commits to an allocation of the units to the players, prior to seeing the valuations. The goal of the learner is to pick an allocation each day that competes with the best in hindsight.\nIt is not hard to see that the offline welfare maximization problem in this setting corresponds to the Knapsack problem, where each player has a valuation equal to the average value in hindsight, i.e. 1t ∑t τ=1 v τ i (·). So, dynamic programming can be used to compute a welfare-maximizing allocation in time polynomial in n and k. Dobzinski and Nisan [13] introduced a 1/2-approximation MIR algorithm for this problem. At a high level, the algorithm proceeds by dividing the set of items to k/n2 bundles of the same size.5 Then the MIR algorithm chooses the best allocation from the set of allocations (range of the algorithm) where all the items in one bundle are allocated to the same bidders. This algorithm is effectively solving a knapsack problem over n2 items and can be implemented in time polynomial in n and log(k).\nWe show how to construct a matrix ΓMU that is admissible and implementable for unrestricted n-bidder k-unit auctions. We then use the theorem 7.4 from Section 7 to obtain an online algorithm with vanishing 1 2 -REGRET that runs in time poly(n, T, log k).\nLet ΓMU be a matrix with n columns, such that for any allocation q and any column j, ΓMUq,j = qj/k. Clearly, for any q 6= q′ we have ΓMUq 6= ΓMUq . So, ΓMU is (k + 1, 1k )-admissible. Moreover, observe that\n5If k is not a multiple of n2, one can add extra items with marginal value of 0 to all bidders.\nthe matrix ΓMU ′\nrestricted to the range of the 1/2 approximation algorithm of Dobzinski and Nisan [13] has much better admissibility constants. In particular, the number of different entries within each column is at most κ′ = n2 + 1, since each player receives allocations that are multiples of k/n2 and there are at most n2 + 1 such multiples. Moreover, the minimum non-zero difference of the column entries, between any two such bundled allocations, is at least δ′ ≥ k\nn2 1 k = 1 n2\n. Therefore matrix ΓMU ′ is ( n2 + 1, 1\nn2\n) -admissible.\nLet D be any distribution over [0, αmax]. It is not hard to see that (ΓMU, D) is also implementable. For any column j, consider the bid profile vj where bidder j’s marginal valuation for any item is 1/k and all other bidders have 0 valuation for any number of items. That is, µj(s) = 1/k and µi(s) = 0 for all s and i 6= j. The welfare of any allocation on this bid profile is the utility of bidder j, which is the qj/k = ΓMUq . Therefore, (ΓMU, D) is implementable using the map Sj(αj) = {(αj ,vj)}. Therefore, also (ΓMU ′ , D) is implementable. The next theorem is a direct consequence of the above discussion.\nTheorem 8.1. Consider the problem of welfare maximization in k-unit auctions. Let D be the uniform distribution on [0, 1/η] for η = √ δ′/(2Tκ′) = √ 1\n2Tn2(n2+1) . Then, for any sequence of valuation func-\ntions v1, . . . ,vT , the Generalized FTPL algorithm with matrix ΓMU, distribution D and oracle the 1/2- aproximate MIR algorithm of [13], runs in per-round time poly(n, T ), plays the sequence of allocations q1, . . . ,qT , and has 1/2-REGRET\n1 2 -REGRET = 1 2\n( 1\nT max q∈Zn T∑ t=1 n∑ i=1 vti(qi)\n) −E [ 1\nT T∑ t=1 n∑ i=1 vti(q t i)\n] ≤ n·2n √ 2T (n2 + 1)n2 ≤ O(n4 √ T ).\nThe extra factor of n in the latter bound as compared to that implied by Theorem 7.4, is due to the fact that the maximum welfare in this problem is upper bounded by n and not 1. So we need to scale-down the valuations before applying the theorem by dividing by n and then scale up again to get the regret for the un-normalized problem."
    }, {
      "heading" : "8.2 Oracle Efficient No-Regret Learning in Simultaneous Second Price Auctions",
      "text" : "In this section, we answer an open problem raised by Daskalakis and Syrgkanis [11] regarding the existence of an oracle-based no-regret algorithm for optimal bidding in Simultaneous Second-Price Auctions. We show that our Oracle-Based Generalized FTPL algorithm used with an appropriate implementable and admissible translation matrix can be used to obtain such an algorithm.\nA Simultaneous Second-Price Auction (SiSPA) [3, 9, 14] is a mechanism for allocating k items to n bidders. Each bidder i ≤ n submits k simultaneous bids denoted by a vector of bids bi. The mechanism allocates each item using a second-price auction based on the bids solely submitted for this item, while breaking ties in favor of bidders with larger indices. For each item j, the winner is charged θj , the second highest bid for that item. Each bidder i has a fixed combinatorial valuation function vi : {0, 1}k → [0, 1] over bundles of items. Then, the total utility of bidder i who is allocated the bundle qi ∈ {0, 1}k is vi(qi)−θ ·qi, where θ is the vector of second largest bids across all items.\nWe consider the problem of optimal bidding in a SiSPA from the perspective of the first bidder. Hereafter, we drop the indices of the players from the notation. From this perspective, the utility of the bidder only depends on its bid b and the the threshold vector θ of the second largest bids. The online optimal bidding problem is defined as follows.\nDefinition 8.2 (Online Bidding in SiSPAs [35]). At each time step t, the player picks a bid vector bt and an adversary picks a threshold vector θt. The player wins the bundle of items q(bt,θt), with qj(bt,θt) = 1(btj>θtj) and gets the utility\nu(bt,θt) = v ( q(bt,θt) ) − θt · q.\nWe consider this problem under the no-overbidding condition that requires that for any bundle q, the sum of bids over items in q does not exceed the bidder’s valuation for q, i.e., bt · q ≤ v(q), for all q ∈ {0, 1}k. Similar no-overbidding assumptions are used in the previous work to prove that no-regret learning in second-price auctions has good welfare guarantees [9, 14].\nWe consider the online bidding problem where for any q, the valuation v(q) is a multiple of 1/m and for any item j ≤ k, bj is a multiple of 1/m. We represent by Bm the class of all such bid vectors that satisfy the no-overbidding condition for v(·). Note that the assumption on the valuation function is not restrictive. That is, for any valuation function v(·), one can round down its values to the closest multiple of 1/m, while losing at most 1/m utility. Moreover, a similar discretization for the bid vectors was used by Daskalakis and Syrgkanis [35] for studying offline and online optimal bidding in SiSPAs.\nNext, we show how to construct an implementable and admissible translation matrix for Bm. Let ΓIB be a matrix with k columns and |Bm| rows that are equal to bid vectors, i.e., ΓIBb = b. This immediately yields admissibility with κ = m + 1 and δ = 1/m, because of the discretization of bids. Next, we show that for any D with a bounded non-negative support, (ΓIB, D) is also implementable. At a high level, to implement the jth perturbation, we consider threshold vectors in which θj = `/m for ` = 0, 1, . . . ,m − 1, and all other thresholds are set to the highest level. In such threshold vectors, the bidder can win at most one item, item j. Furthermore, whenever the bidder wins item j, its utility is independent of the bid vector, as it only depends on the valuation v(ej) and the entry θj of the threshold vector. So, there are weights such that the total contribution of weighted threshold vectors towards the utility of any winning bid is the same across all `. Since bid bj wins item j for all `/m < bj , then the total utility of playing bj against this weighted set of threshold vectors is proportional to bj = ΓIBbj . This implies that (Γ\nIB, D) is implementable. The next lemma formalizes this discussion.\nLemma 8.3. Let D be a distribution supported on a subset of [0, αmax]. Then (ΓIB, D) is implementable with complexity poly(αmax,m, k), and ΓIB is (m+ 1, 1/m)-admissible.\nProof. We argued the admissibility above, so it suffices to show implementability. The dataset Sj(αj) will contain threshold vectors where all but the jth thresholds are set to 1. Specifically, for ` = 0, 1, . . . ,m− 1, let θ` = (`/m)ej + ∑ j′ 6=j ej′ . Note that the utility of playing bid b against θ` is u(b,θ`) = ( v(ej) −\n`/m ) 1(bj>`/m). We set the weight corresponding to θ` to\nw` =\n{ αj m · 1 v(ej)−`/m if `/m < v(ej)\n0 otherwise.\nSince bj ≤ v(ej) for any b, we have\nm−1∑ `=0 w` u(b,θ`) = m−1∑ `=0 αj m · 1 v(ej)− `/m · ( v(ej)− `/m ) 1(bj>`/m)\n= m−1∑ `=0 αj m 1(bj>`/m) = mbj−1∑ `=0 αj m = αjbj = αjΓ IB bj .\nThus, indeed {(w`,v`)}` implements αj . This set can be clearly generated in time poly(k,m), its cardinality is m and its sum of weights is at most αmaxm, since each weight w` is at most αmax. Therefore, (ΓIB, D) is implementable with complexity poly(k,m, αmax).\nThe next theorem is a direct consequence of Lemma 8.3.\nTheorem 8.4. Consider the problem of Online Bidding in SiSPAs. Let D be the uniform distribution as described in Theorem 3.5. Then, the Oracle-Based Generalized FTPL algorithm with ΓIB and D is oracleefficient with complexity poly(k,m, T ) and has regret\nE [ max b∈Bm T∑ t=1 u(b,θt)− T∑ t=1 u(bt,θt) ] ≤ O(km √ T )."
    }, {
      "heading" : "8.3 Universal Identification Sequences",
      "text" : "There is an interesting connection between our definitions of admissibility and implementability and a statistical measure of complexity from learning theory, called the Universal Identification Sequences.\nDefinition 8.5 (Universal Identification Sequences [16]). Consider a domain Z and a class of functions F such that for all f ∈ F , f : Z → {0, 1}. A sequence of unlabeled instances S = {z} is said to distinguish function f ∈ F if f is the only function that is consistent with the labeling on S produced by f . A sequence of unlabeled instances S = {z} is called a universal identification sequence if it distinguishes every f ∈ F .\nAny universal identification sequence ofF can be used to construct a translation matrix that is admissible and implementable. Consider a matrix ΓF , whose rows are indexed by F and columns are indexed by S, such that ΓFfz = f(z) for any f ∈ F and z ∈ S. By the definition of universal identification sequence for any two functions, f, f ′ ∈ F there is z ∈ S, such that f(z) 6= f ′(z), i.e., ΓFf 6= ΓFf ′ . As a results ΓF is (2, 1)-admissible. Moreover, the columns of ΓF correspond to the value of functions applied to z ∈ S. Therefore, (ΓF , D) is implementable for any D over R+. That is, the length of a universal identification sequence is an upper bound on the number of columns needed to create a translation matrix that is admissible and implementable for a class of binary functions. Examples of function classes with polynomial-length universal identification sequences include logarithmic-depth read-once majority formulas and logarithmicdepth read-once positive NAND formulas [16]. The next corollary is a direct consequence of Theorems 3.5 and Theorems 3.11.\nCorollary 8.6. Consider a domain Z and a class of binary functions F with a universal identification sequence of length d. Then, there is an efficient oracle-based online algorithm with regret\nE [ max f∈F T∑ t=1 f(zt)− T∑ t=1 ft(zt) ] ≤ O(d √ T ).\nOur Oracle-Based Generalized FTPL algorithm goes beyond the use of binary functions and universal identification sequences. In particular, we applied our results to obtain no-regret algorithms for several commonly studied classes of auctions (the revenue of which are real-valued functions). Furthermore, we introduced implementable translation matrices where each column corresponds to a complex weighted set of adversary’s actions, rather than, columns that correspond to individual adversary’s actions."
    }, {
      "heading" : "Acknowledgments",
      "text" : "We would like to thank Avrim Blum for helpful discussions and pointers regarding the universal identification sequences."
    }, {
      "heading" : "A Proof of Lemma 3.1",
      "text" : "We begin by stating a variant of the standard Be-the-Leader Lemma [27] that has been modified to include the perturbation specified by the matrix Γ.\nLemma A.1 (Be-the-Leader Lemma). Under Generalized FTPL, for any x ∈ X ,\nT∑ t=1 f(xt+1, yt) + α · Γx1 ≥ T∑ t=1 f(x, yt) + α · Γx.\nProof. For T = 1 the inequality holds trivially. Assume that the claim holds for some T . Then, for all x\nT+1∑ t=1 f(xt+1, yt) + α · Γx1 = T∑ t=1 f(xt+1, yt) + f(xT+2, yT+1) + α · Γx1\n≥ T∑ t=1 f(xT+2, yt) + α · ΓxT+2 + f(xT+2, yT+1) (by induction hypothesis)\n= T+1∑ t=1 f(xT+2, yt) + α · ΓxT+2\n≥ T+1∑ t=1 f(x, yt) + α · Γx. (by optimality of xT+2)\nLet x∗ = arg maxx∈X ∑T t=1 f(x, yt). Then by the lemma above,\nREGRET = E [ T∑ t=1 f(x∗, yt)− T∑ t=1 f(xt, yt) ]\n= E [ T∑ t=1 f(x∗, yt)− T∑ t=1 f(xt+1, yt) ] + E [ T∑ t=1 f(xt+1, yt)− T∑ t=1 f(xt, yt) ]\n≤ E [α · (Γx1 − Γx∗)] + E [ T∑ t=1 f(xt+1, yt)− T∑ t=1 f(xt, yt) ] ."
    }, {
      "heading" : "B Proof of Theorem 3.11",
      "text" : "To show that the Oracle-Based FTPL procedure (Algorithm 2) implements Generalized FTPL (Algorithm 1), it suffices to show that at each round t,\narg max x∈X [ t−1∑ τ=1 f(x, yτ ) + α · Γx ] = OPT(S) = arg max x∈X ∑ (w,y)∈S wf(x, y). (20)\nConsider any x, x′ ∈ X . Then, from the definition of S and by implementability,\n∑ (w,y)∈S wf(x, y)− ∑ (w,y)∈S wf(x′, y) = t−1∑ τ=1 [ f(x, yτ )− f(x′, yτ ) ] + ∑ j≤N ∑ (w,y)∈Sj(αj) w [ f(x, y)− f(x′, y) ]\nAlgorithm 4: Oracle-Based Generalized -FTPL with Integral Oracle Input: positive |X | ×N , an implementable (Γ, D), an oracle INTOPT, precision parameter Draw αj ∼ D for j = 1, . . . , N . for t = 1, . . . , T do\nSet S = {(1, y1), . . . , (1, yt−1)} ∪ ⋃ j≤N Sj(αj).\nSet S′ = {(⌊ w|S| / ⌋ , y ) : (w, y) ∈ S }\n. Set xt = INTOPT(S′). Observe yt and receive payoff f(xt, yt).\nend for\n= t−1∑ τ=1 [ f(x, yτ )− f(x′, yτ ) ] + ∑ j≤N αj(Γxj − Γx′j)\n= ( t−1∑ τ=1 f(x, yτ ) + α · Γx ) − ( t−1∑ τ=1 f(x′, yτ ) + α · Γx′ ) ,\nwhich immediately yields Equation (20). Also, by implementability, the running time to construct the set S is at most T + g(N,T ), and its mass is at most T + g(N,T ). Since there is only one oracle call per round, we get the per-round complexity of T + g(N,T ).\nC Integral Oracles We now study how online learning can be reduced to a more restrictive class of offline optimization oracles, which only allow the weights that are positive integers:\nDefinition C.1 (Integral Offline Oracle). An integral offline oracle INTOPT receives as input a set of adversary actions with non-negative integer weights S = {(w`, y`)}`∈L, w` ∈ N, y` ∈ Y , and returns\nINTOPT(S) ∈ arg max x∈X ∑ (w,y)∈S wf(x, y).\nIntegral oracles can be implemented by algorithms that optimize over unweighted data sets, by replicating each example according to its weight. A natural input size for such algorithms is the size of the data set (including the replicates). This exactly coincides with the mass of S defined in the previous section.\nWe will show that online learning can be efficiently reduced to offline optimization with INTOPT oracles under the same conditions as studied in the previous section. Thus, while the rest of paper assumes realweighted oracles, the results are also valid when we only have access to an integral oracle.\nAt the crux of our approach is a construction of an approximate real-weighted oracle from an integral oracle. It turns out that such an approximate oracle, with a suitably chosen precision parameter , is all that is required for no-regret learning with the Generalized FTPL algorithm.\nLemma C.2 (Integral Offline Oracle to Approximate Offline Oracle). Given an integral offline oracle INTOPT and any precision parameter > 0, one can construct an approximate offline oracle OPT′ which receives as input a weighted set of adversary actions S = {(w`, y`)}`∈L, w` ∈ R+, and returns OPT′(S) ∈ X such that ∀x ∈ X , ∑\n(w,y)∈S\nwf(OPT′(S), y) ≥ ∑\n(w,y)∈S\nwf(x, y)− .\nThis approximate oracle is implemented by a single oracle call to INTOPT(S′) on the dataset\nS′ = {(⌊ w|S| / ⌋ , y ) : (w, y) ∈ S } .\nThis lemma is proved in Appendix C.1. The construction of the set S′ gives rise to a variant of the Generalized FTPL algorithm, presented in Algorithm 4. This algorithm can be analyzed similarly as the Generalized FTPL to prove the regret bound essentially identical to the bound of Theorem 3.5. The algorithm is also oracle-efficient under implementability. Both results are summarized in the following theorem:\nTheorem C.3. Let Γ be a (κ, δ)-admissible matrix with N columns and γ = maxx,j Γxj and let D be the uniform distribution on [0, 1/η] for η = √ γδ/(2Tκ). If = 1√\nT , then the regret of Algorithm 4 can be\nbounded as REGRET ≤ O(N √ 2Tκγ/δ).\nFurthermore, if (Γ, D) is implementable with complexity g(N,T ) then Algorithm 4 is oracle-efficient with respect to INTOPT, with per-round complexity poly(T, g(N,T ), 1/ ).\nFor the proof of regret bound, see Appendix C.2. The oracle efficiency result follows from Theorem 3.11, using the fact that within the reduction from real-weighted to integral oracle, the mass of the dataset S′ is bounded as ‖S′‖ ≤ ‖S‖2/ .\nC.1 Proof of Lemma C.2 Proof of Lemma C.2. Let δ = /|S|. Thus, elements (w, y) ∈ S are transformed into (bw/δc, y) ∈ S′. To show the approximate optimality, we use the fact that 0 ≤ a − bac ≤ 1 for any a ≥ 0, so we have 0 ≤ w − δbw/δc ≤ δ and thus for any x ∈ X ,∑\n(w,y)∈S\nwf(OPT′(S), y) ≥ δ ∑\n(w,y)∈S\nbw/δcf(OPT′(S), y)\n= δ ∑\n(w′,y)∈S′ w′f(INTOPT(S′), y) (by construction)\n≥ δ ∑\n(w′,y)∈S′ w′f(x, y) (by the property of INTOPT)\n≥ ∑\n(w,y)∈S\nwf(x, y)− ∑\n(w,y)∈S\nδ\n= ∑\n(w,y)∈S\nwf(x, y)− .\nC.2 Approximate Oracles Approximate oracles, with a precision error , give rise to the Generalized -FTPL algorithm shown in Algorithm 5. The analysis of Section 3.1 can be generalized to obtain the following result:\nTheorem C.4. Let Γ be a (κ, δ)-admissible matrix with N columns and γ = maxx,j Γxj and let D be the uniform distribution on [0, 1/η] for η = √ γδ/(2Tκ). If = 1√\nT , then the regret of the Generalized -FTPL\nalgorithm can be bounded as REGRET ≤ O(N √ 2Tκγ/δ).\nThe proof of this theorem is a direct application of the generalized version of Lemma 3.1 and 3.4. Details are given in the following subsections.\nAlgorithm 5: Generalized -FTPL\nInput: non-negative matrix Γ ∈ R|X |×N+ , distribution D Draw αj ∼ D for j = 1, . . . , N for t = 1, . . . , T do\nChoose xt such that for all x ∈ X ,\nt−1∑ τ=1 f(xt, yτ ) + α · Γxt ≥ t−1∑ τ=1 f(x, yτ ) + α · Γx −\nObserve yt and receive payoff f(xt, yt) end for\nC.3 Approximate Generalized FTPL Lemma Lemma C.5 ( -FTPL Lemma). For the Generalized -FTPL algorithm,\nREGRET ≤ E [ T∑ t=1 f(xt+1, yt)− f(xt, yt) ] + E [α · (Γx1 − Γx∗)] + T (21)\nwhere x∗ = arg maxx∈X ∑T t=1 f(x, yt).\nWe first prove an approximate variant of Be-the-Leader Lemma.\nLemma C.6 (Be-the-Approximate-Leader Lemma). Under Generalized -FTPL, for any x ∈ X , T∑ t=1 f(xt+1, yt) + α · Γx1 ≥ T∑ t=1 f(x, yt) + α · Γx − T.\nProof. For T = 1 the inequality holds trivially, by the definition of approximate leader. Assume that the claim holds for some T . Then, for all x\nT+1∑ t=1 f(xt+1, yt) + α · Γx1 = T∑ t=1 f(xt+1, yt) + α · Γx1 + f(xT+2, yT+1)\n≥ T∑ t=1 f(xT+2, yt) + α · ΓxT+2 − T + f(xT+2, yT+1)\n(by induction hypothesis)\n= T+1∑ t=1 f(xT+2, yt) + α · ΓxT+2 − T\n≥ T+1∑ t=1 f(x, yt) + α · Γx − (T + 1), (by approximate optimality of xT+2)\nproving the lemma. Proof of Lemma C.5. Let x∗ = arg maxx∈X ∑T t=1 f(x, yt). Then by Be-the-Approximate-Leader Lemma,\nREGRET = E [ T∑ t=1 f(x∗, yt)− T∑ t=1 f(xt, yt) ]\n= E [ T∑ t=1 f(x∗, yt)− T∑ t=1 f(xt+1, yt) ] + E [ T∑ t=1 f(xt+1, yt)− T∑ t=1 f(xt, yt) ]\n≤ E [α · (Γx1 − Γx∗)] + E [ T∑ t=1 f(xt+1, yt)− T∑ t=1 f(xt, yt) ] + T.\nC.4 The Stability Lemma For Approximate Generalized FTPL Lemma C.7. Consider the Generalized -FTPL algorithm with a (κ, δ)-admissible matrix Γ withN columns and a ( ρ, 1+2 δ ) -dispersed distribution D. Then,\nE [ T∑ t=1 f(xt+1, yt)− f(xt, yt) ] ≤ 2TNκρ.\nProof. Fix any t ≤ T . The bulk of the proof will establish that, with high probability, Γxt+1 = Γxt , which by admissibility implies that xt+1 = xt and therefore f(xt+1, yt)− f(xt, yt) = 0.\nFix any j ≤ N . We first show that Γxt+1j = Γxtj with high probability. Let V denote the set of values that appear in the jth column of Γ. For any value v ∈ V , let xv be the action that maximizes the perturbed profit among those whose Γ entry in the jth column equals v:\nxv := arg max x∈X : Γxj=v [ t−1∑ τ=1 f(x, yτ ) + α · Γx − αjv ] .\nFor any v, v′ ∈ V , define\n∆vv′ = ( t−1∑ τ=1 f(xv, yτ ) + α · Γxv − αjv ) − ( t−1∑ τ=1 f(xv ′ , yτ ) + α · Γxv′ − αjv ′ ) .\nNote that xv and ∆vv′ are independent of αj , as we removed the payoff perturbation corresponding to αj . If Γxtj = v, then by the -optimality of xt on the perturbed profit, we have αj(v\n′ − v) − ≤ ∆vv′ for all v′ ∈ V . Suppose Γxt+1j 6= v. Then there is some v′ ∈ V which yields a better perturbed profit, up to , in the next round, i.e.,\nt−1∑ τ=1 f(xv ′ , yτ ) + f(x v′ , yt) + α · Γxv′ ≥ t−1∑ τ=1 f(xv, yτ ) + f(x v, yt) + α · Γxv − .\nRearranging, we obtain for this same v′ that\n∆vv′ ≤ αj(v′ − v) + f(xv ′ , yt)− f(xv, yt) + ≤ αj(v′ − v) + 1 + .\nIf v′ > v, then\nαj ≥ ∆vv′ − 1−\nv′ − v ≥ min v̂∈V, v̂>v ∆vv̂ − 1− v̂ − v\nand so αj(v − v) + 1 + ≥ ∆vv where v is the value of v̂ minimizing the expression on the right. Thus, in this case we have − ≤ ∆vv − αj(v − v) ≤ 1 + . Similarly, if v′ < v, then\nαj ≤ ∆vv′ − 1−\nv′ − v ≤ max v̂∈V, v̂<v ∆vv̂ − 1− v̂ − v\nand so αj(v − v) + 1 + ≥ ∆vv where v is the value maximizing the expression on the right. In this case we have − ≤ ∆vv − αj(v − v) ≤ 1 + . Putting this all together, we have\nPr [ Γxt+1j 6= Γxtj ∣∣ αk, k 6= j] ≤ Pr [ ∃v ∈ V : − ≤ ∆vv − αj(v − v) ≤ 1 + or − ≤ ∆vv − αj(v − v) ≤ 1 +\n∣∣∣ αk, k 6= j] ≤ ∑ v∈V ( Pr [ αj ∈ [ ∆vv−1− v−v , ∆vv+ v−v\n] ∣∣∣∣ αk, k 6= j]+ Pr[αj ∈ [−∆vv− v−v , −∆vv+1+ v−v ] ∣∣∣∣ αk, k 6= j]) ≤ 2κρ.\nThe last line follows from the fact that v − v ≥ δ and v − v ≥ δ, the fact that D is ( ρ, 1+2 δ ) -dispersed, and a union bound. Since this bound does not depend on the values of the αj , we can remove the conditioning and bound Pr[Γxt+1j 6= Γxtj ] ≤ 2κρ. Taking a union bound over all j ≤ N , we then have that, by admissibility, Pr [xt+1 6= xt] = Pr [ Γxt+1 6= Γxt ] ≤ 2Nκρ, which implies the result."
    }, {
      "heading" : "D Omitted Proofs From Applications to Online Auction Design",
      "text" : "D.1 Proof of Equation (6) Consider any vector of reserves r ∈ I and let r′ ∈ Im be the vector obtained by rounding each reserve price down to the nearest multiple of 1/m. If vi > ri, then vi > r′i, so any bidder who would have been included in the basic VCG auction using reserves r is still included with r′. This can only increase the number of bidders who are serviced and therefore pay a charge.\nNow consider the amount that serviced bidder i is charged. This is the maximum of ri and the highest bid of a bidder in the basic VCG auction who was not serviced (or 0 if all bidders were serviced); let b denote this highest unserviced bids in the basic VCG auction under r, and similarly let b′ denote such a bit under r′. Since the set of bidders entering the basic VCG auction increases from r to r′, we must have b′ ≥ b.\nLet U be the set of bidders serviced under r, and U ′ the set under r′. The difference in revenue is∑ i∈U max{ri, b} − ∑ i∈U ′ max{r′i, b′}\n= ∑\ni∈U∩U ′ (max{ri, b} −max{r′i, b′}) + ∑ i∈U\\U ′ max{ri, b} − ∑ i′∈U ′\\U max{r′i′ , b′}. (22)\nWe begin by analyzing the last two terms. For any i ∈ U \\ U ′ and i′ ∈ U ′ \\ U ,\nr′i′ + 1/m > ri′ > vi′ ≥ vi > ri,\nwhere vi′ ≥ vi follows, because i enters the basic VCG auction for r′, but is not allocated the item. Therefore,\nmax{r′i′ , b′} ≥ max { ri − 1/m, b } ≥ max{ri, b} − 1/m.\nSince |U \\ U ′| ≤ |U ′ \\ U |, we can pick V ⊆ U ′ \\ U such that |V | = |U \\ U ′| and obtain∑ i∈U\\U ′ max{ri, b} − ∑ i′∈U ′\\U max{r′i′ , b′} ≤ ∑ i∈U\\U ′ max{ri, b} − ∑ i′∈V max{r′i′ , b′} ≤ |U \\ U ′| m .\nNote that each term in the first sum of Equation (22) is at most 1/m, because max{r′i, b′} ≥ max { ri − 1/m, b } ≥ max{ri, b} − 1/m.\nThus, we have\nRev(r,v)− Rev(r′,v) ≤ |U ∩ U ′| m + |U \\ U ′| m ≤ s m .\nThis yields the approximation result\nmax r∈I T∑ t=1 Rev(r,vt)− max r∈Im T∑ t=1 Rev(r,vt) ≤ Ts m . (23)\nD.2 Omitted Part of the Proof of Lemma 4.2 We need to show that the sum of weights in any set Sj(αj) is bounded by poly(n,m,αmax). Recall that\nwm = max {\n0, max k\n[ αjm ( kβ − (k − 1)β )]} ,\nand for all k = m,m− 1, . . . , 2,\nwk−1 = 1\nk − 1 ( m∑ h=k wh − αjm ( kβ − (k − 1)β )) .\nBy definition, wm ≤ mαmax. We can also bound wk−1 as\nwk−1 ≤ 1\nk − 1 ( m∑ h=k wh +mαmax ) ≤ 1 k − 1 ( m−1∑ h=k wh + 2mαmax ) ,\nso\n(k − 1)wk−1 ≤ m−1∑ h=k wh + 2mαmax.\nSumming over k = 2, . . . ,m, yields\nm∑ k=2 (k − 1)wk−1 ≤ m−1∑ h=2 (h− 1)wh + 2(m− 1)mαmax,\nand subtracting the sum on the right-hand side yields\nm∑ k=2 wk−1 ≤ 2(m− 1)mαmax,\nso ∑m\nk=1wk ≤ (2m2 − 2m+m)αmax. D.3 Proof of Lemma 4.6 We will argue that the setting here is isomorphic to the setting in the proof of Lemma 4.2, so we can directly apply the result of analysis of ΓVCG. The isomorphism from the VCG setting to IP setting maps bidders i in VCG to items ` in IP, and reserve price vectors r to price vectors a. We therefore assume that n in VCG equals k in IP, and the values of m in both settings are equal. Then, indeed ΓVCG equals ΓIP.\nNext we need to show how to construct Sj(αj) in the IP setting. Assume that j corresponds to the bidder i and the bit β in VCG setting, and the item ` and the bit β in IP setting. In VCG, we considered the bid profiles vh = (h/m)ei, and the revenue of any auction r is\nRevVCG(r,vh) = ri1(h≥mri).\nIn IP setting, we consider profiles v′h of combinatorial valuations over bundles q ∈ {0, 1}k, in which all bidders have values zero on all bundles and one bidder has value h/m for bundle e` and zero on all other bundles.6 In this case, we have\nRevIP(a,v′h) = ai1(h≥mai).\nThus, both the translation matrices ΓVCG and ΓIP as well as the revenue functions RevVCG and RevIP are isomorphic (given these choices of the profiles). Therefore, we can set the weights w′h in IP setting equal to the weights wh in VCG setting and obtain admissibility and implementability with the same constants and complexity.\nD.4 Proof of Lemma 4.12 Since ΓIPθ,v = Rev(θ,v), for any α ≥ 0, Sv(α) = {(αv,v)}. Furthermore, the mass of dataset Sv(α) is poly(n,m,αmax). So, (Γ, D) is implementable with complexity poly(n,m,αmax).\nTake any two different auctions θ and θ′. We show that ΓIPθ 6= ΓIPθ′ . Let b be the smallest level at which there is i ∈ [n] such that θib 6= θ′ib and among such i choose the largest. There are three cases:\n1. i 6= n: Consider the bid profile vi,` for ` = mθnb . By the choice of i and the fact that i 6= n, we have that bθn(v i,` n ) = bθ ′ n (v i,` n ) = b. On the other hand, bθi (v i,` i ) = s − 1 ≥ b. Therefore, bidder i wins the\nitem in both auctions and pays the bth threshold. So, Rev(θ,vi,`) = θib 6= θ′ib = Rev(θ ′,vi,`).\n2. i = n and b ≥ 1: WLOG, assume that θnb < θ′nb . Let ` = mθnb and consider v1,`. Then bθn(v 1,` n ) = b\nand bθ ′ n (v 1,` n ) = b′ for some b′ < b. So, bidder 1 wins the item in both auctions and pays the threshold that corresponds to the nth bidder’s level. Therefore, Rev(θ,v1,`) = θ1b 6= θ1b′ = Rev(θ ′,v1,`). 3. i = n and b = 0: Consider bid profile en. In this profile, bidder n wins and pays the absolute reserve price. Therefore, Rev(θ, en) = θn0 6= θ′n0 = Rev(θ′, en).\nTherefore, ΓIPθ 6= ΓIPθ′ . Since any element of Γ IP is a multiple of 1/m then ΓIP is (m+ 1, 1m)-admissible. D.5 Proof of Lemma 4.14 We say that two auction θ and θ′ are equivalent if for all v, Rev(θ,v) = Rev(θ′,v). In what follows, for any θ ∈ Rs,m we construct θ′ ∈ Rs,m, such that θ and θ′ are equivalent.\nWhen θ ∈ Ss,m, then θ has no empty buckets. That is, for all i and b, θib ∈ Bib(θ). So, the claim holds trivially for θ′ = θ.\nLet θ be an auction such that for some i and b, Bib(θ) 6= ∅ but all of its competing buckets are empty. Consider auction θ′ with thresholds θ′ib = θ i b+1 and θ ′i′ b′ = θ i′ b′ for all i\n′ 6= i or b′ 6= b. We show that θ and θ′ are equivalent. Consider any bid profile v. There are two cases: 1) vi 6∈ Bib(θ); 2) vi ∈ Bib(θ).\nCase 1: If vi 6∈ Bib(θ), then it is easy to see that bθi (vi) = bθ ′ i (vi) so the winner remains the same. As a result the payment would remain the same if i is not the winner. When i is the winner, since all of the competing buckets ofBib(θ) are empty, the payment of bidder i is not at level b, so the payment of bidder i also remains the same. Therefore, Rev(θ,v) = Rev(θ′,v).\nCase 2: If vi ∈ Bib, then bθ ′ i (vi) = b θ i (vi) − 1. Let i′ be any bidder that appears after bidder i in the sorted list of the bid level. Since all competing buckets ofBib are empty, it must be that either i < i ′ and bθi′(vi′) < b or i > i′ and bθi (vi′) < b− 1. In either case, position of i in the sorted list remains the same in θ ′. Consider the following three cases: 1. Bidder i is the winner: Let i′ be the runner up bidder. As described above, i is still the first in the\ndecreasing order of bid levels. So, i wins the item in θ′. Moreover, because the competing buckets of 6 Note that a simple variation of this bid profile can be used in settings where the valuations need to satisfy additional assumptions, such as (sub-)additivity or free disposal. In such cases, we can use a similar bid profile where one bidder has valuation h/m for any bundle that includes item ` and all other valuations are 0.\nBib(θ) are empty, the payment of bidder i in θ is at a threshold with level below ≤ b− 1, which is the same in both auctions. Therefore, Rev(θ,v) = Rev(θ′,v). 2. i′ 6= iwins the item and i is the runner up: As described above, i is still the runner up in the decreasing order of bid levels in θ′. There are two cases:\n(a) If i′ < i, then Rev(θ,v) = θi ′ b . Note that B i′ b−1 = ∅, so, θi ′ b−1 = θ i′ b . So, Rev(θ,v) = θ i′ b =\nθi ′ b−1 = Rev(θ ′,v). (b) If i′ > i, then Rev(θ,v) = θi\n′ b+1. Note that B i′ b = ∅, so, θi ′ b = θ i′ b+1. So, Rev(θ,v) = θ i′ b+1 =\nθi ′ b = Rev(θ ′,v). So, the revenue remains the same.\n3. If i is not the winner or the runner up: As described above i is not the winner or the runner up in θ′, either. So, the winner and the revenue are not affected.\nTherefore, Rev(θ,v) = Rev(θ′,v) for all v. Furthermore, the thresholds in θ′ are all equal or larger than the corresponding thresholds in θ, with one threshold being strictly larger. So repeating the above process for other buckets that violate the claim of the lemma will eventually halt. This proves the lemma.\nD.6 Proof of Lemma 4.15 In the interest of readability, we drop the superscript and write Γ for ΓRL in this proof.\nSince Γθ,v = Rev(θ,v), it is immediately clear that (Γ, D) can be implemented by dataset Sv(αv) = {(αv,v)}. Furthermore, the mass of Sv(αv) is poly(n,m,αmax). So, (Γ, D) is implementable with complexity poly(n,m,αmax).\nNext, we show that for any two θ and θ′, Γθ 6= Γθ′ . Let b be the smallest integer for which there exists i ∈ [n], such that θib 6= θ′ib . Choose i as the largest bidder for which θib 6= θ′ib . If b = 0: Then Rev(θ, ei) = θ i 0 6= θ′i0 = Rev(θ′, ei). So, Γθ 6= Γθ′ .\nIf b > 0, then the (b− 1)th bucket is non-empty in one of the auctions — WLOG, let that be auction θ. This implies that θib > θ ′i b . By the structure ofRs,m, there is a non-empty competing bucket.\nIf the non-empty competing bucket is Bi ′ b−1(θ) for i ′ > i, then consider the bid profile vi ′,i,` for ` = mθ′ib . Since B i′ b−1(θ) 6= ∅ and i was the largest bidder for which the thresholds differ, we have that Bi ′ b−1(θ ′) 6= ∅ and θib = θ′ib 6= θib−1 = θib−1. Furthermore, bθi (v i′,i,` i ) < b and b θ′ i (v i′,i,` i ) ≥ b. So, i′ wins the item and pays the level of bidder < b in θ and ≥ b in θ′, which are different. So, Rev(θ,vi′,i,`) 6= Rev(θ′,vi\n′,i,`). The case where the non-empty competing bucket is Bi ′ b−2(θ) for i ′ < i is similar. Therefore, Γθ 6= Γθ′ . Since any element of Γ is a multiple of 1/m, then Γ is (m+ 1, 1m)-admissible."
    }, {
      "heading" : "E Proof of Equation 15",
      "text" : "We use ideas similar to the ones discussed by Morgenstern and Roughgarden [28] and Devanur et al. [12] to show that Rs,m, the class of s-level auctions on a discrete grid, approximates the revenue of Myerson auction within an additive value of O( ) for appropriate parameters m = O(1/ ) and s = O(1/ ).\nLet m = 1/(2 ) and s = 1/ . First, let F ′ be a product distribution obtained by rounding down each v ∼ F to the closest odd multiple of . We show that OPT(F ′) ≥ OPT(F ) − 2 . Let M be the optimal Myerson auction for F and let M ′ be the following mechanism for allocating items to v′ ∼ F ′: Take v such that 1 − Fi(vi) = 1 − F ′i (v′i) for all i ∈ [n] and allocate the item according to the outcome of mechanism M on v. Charge the winner the minimum value above which it would remain a winner.\nTo analyze the revenue of M ′, consider any vector of quantiles q ∈ [0, 1]n and let v and v′ be the values in F and F ′ corresponding to these quantiles, i.e., 1 − Fi(vi) = 1 − F ′i (v′i) = qi for all i ∈ [n]. Note that, allocation of M on v is the same as the allocation of M ′ on v′. Moreover, the quantiles of the payments are the same in both mechanisms. So, for any such quantile the payment in F and F ′ differ by at most 2 . This prove that OPT(F ′) ≥ OPT(F )− 2 .\nNext, we show that there is θ ∈ R1/ ,∞ such that Ev∼F ′ [Rev(θ,v)] ≥ OPT(F ′)− . For each i, let φ′i(·) be the ironed virtual valuation function for bidder i with respect to F ′i . These φ ′ i are monotone functions and can be made into strictly increasing functions by removing an arbitrary small fraction of the distribution and losing an arbitrarily small fraction of the revenue. Let θ be such that θib = φ\n−1(b ) for b ∈ {0, 1, . . . , s−1}. Next, we show that for any v, Rev(θ,v) ≥ OPT(F ′)− .\nConsider v ∼ F ′ and let i∗ and i′ be the winners in θ and the Myerson optimal auctions respectively. Since in s-threshold and Myerson optimal auctions the allocations only depend on the ironed virtual values and not the values themselves, we have that7\nEv∼F ′ [Rev(θ,v)] = Ev∼F ′ [φi∗(vi∗)] and OPT(F ′) = Ev∼F ′ [φi′(vi′)].\nNow, consider the winners i∗ and i′. Note that if i∗ was the unique bidder at the highest bucket under θ (there were no ties to be broken lexicographically), then i∗ also has the highest virtual valuation, so i∗ = i′. On the other hand, if i′ was tied with i∗, then φi′(vi′)− φi∗(vi∗) ≤ . So, overall we have\nEv∼F ′ [Rev(θ,v)] = Ev∼F ′ [φi∗(vi∗)] ≥ Ev∼F ′ [φi′(vi′)]− = OPT(F ′)− .\nNow we show how to round the thresholds of θ ∈ R1/ ,∞ to θ′ ∈ R1/ ,1/ , without losing a large fraction of the revenue. For any θ, and for any θi ∈ [(2j − 1) , (2j + 1) ), let θ′i = 2j . By construction F ′ is only supported on odd multiples of . So, the allocation remains the same for any v ∈ supp(F ′) under θ and θ′. And the payment reduces by at most . So,\nEv∼F ′ [Rev(θ′,v)] ≥ Ev∼F ′ [Rev(θ,v)].\nMoreover, since each bid profiles in F maps to bid profile with smaller bids in F ′, we\nEv∼F [Rev(θ′,v)] ≥ Ev∼F ′ [Rev(θ′,v)] ≥ Ev∼F ′ [Rev(θ,v)]− ≥ OPT(F ′)− 2 ≥ OPT(F )− 4 .\nThis proves the claim."
    }, {
      "heading" : "F Proof of Theorem 6.8",
      "text" : "Using Lemma 6.7, we have\nE [ T∑ t=1 f(xt, yt)− f(xt+1, yt) ] ≤ 2TNκ ·max s∈R Pr [ Z ∈ [s, s+ 1δ ] ] ≤ 2TNκ 1 2δν\nwhere Z ∼ U [−ν, ν]. It remains to bound the term E [∑ σ∈S ∑N j=1 ασ,j(Γ S x∗,(σ,j) − Γ S x1,(σ,j) ) ] , which is at most\n2E max x ∑ σ∈S N∑ j=1 ασ,jΓx,(σ,j)  . Let βx = ∑ σ∈S ∑N j=1 ασ,jΓx,(σ,j). We therefore have for any λ > 0,\nE [ max x βx ] = 1λ ln ( exp ( λE [ max x βx ])) ≤ 1λ ln ( E [ exp ( λmax\nx βx\n)]) (Jensen’s inequality)\n≤ 1λ ln (∑ x E [exp (λβx)] ) 7See further discussion on this by Hartline [19] and Morgenstern and Roughgarden [28].\n≤ 1λ ln ∑ x ∏ σ,j E [ exp ( λασ,jΓx,(σ,j) )] ≤ 1λ ln ∑ x ∏ σ,j exp ( ν2γ2λ2 2\n) (Hoeffding’s lemma for bounded r.v.) =\nln |X | λ + ν2γ2N |S|λ 2\n= √ 2N |S| ln |X |νγ. (by picking the optimal λ)\nCombining the stability and the error bound above and invoking Lemma 3.1, completes the proof."
    } ],
    "references" : [ {
      "title" : "Online linear optimization and adaptive routing",
      "author" : [ "B. Awerbuch", "R. Kleinberg" ],
      "venue" : "J. Comput. Syst. Sci.,",
      "citeRegEx" : "1",
      "shortCiteRegEx" : "1",
      "year" : 2008
    }, {
      "title" : "Approximation algorithms and online mechanisms for item pricing",
      "author" : [ "Balcan", "M.-F", "A. Blum" ],
      "venue" : "In Proceedings of the 7th ACM Conference on Economics and Computation (EC),",
      "citeRegEx" : "2",
      "shortCiteRegEx" : "2",
      "year" : 2006
    }, {
      "title" : "Welfare guarantees for combinatorial auctions with item bidding",
      "author" : [ "K. Bhawalkar", "T. Roughgarden" ],
      "venue" : "In Proceedings of the 22nd Annual ACM-SIAM Symposium on Discrete Algorithms (SODA),",
      "citeRegEx" : "3",
      "shortCiteRegEx" : "3",
      "year" : 2011
    }, {
      "title" : "An analog of the minimax theorem for vector payoffs",
      "author" : [ "D. Blackwell" ],
      "venue" : "Pacific J. Math.,",
      "citeRegEx" : "4",
      "shortCiteRegEx" : "4",
      "year" : 1956
    }, {
      "title" : "Near-optimal online auctions",
      "author" : [ "A. Blum", "J.D. Hartline" ],
      "venue" : "In Proceedings of the 16th Annual ACM-SIAM Symposium on Discrete Algorithms (SODA),",
      "citeRegEx" : "5",
      "shortCiteRegEx" : "5",
      "year" : 2005
    }, {
      "title" : "On the generalization ability of on-line learning algorithms",
      "author" : [ "N. Cesa-Bianchi", "A. Conconi", "C. Gentile" ],
      "venue" : "IEEE Trans. Inf. Theor.,",
      "citeRegEx" : "6",
      "shortCiteRegEx" : "6",
      "year" : 2006
    }, {
      "title" : "Regret minimization for reserve prices in second-price auctions",
      "author" : [ "N. Cesa-Bianchi", "C. Gentile", "Y. Mansour" ],
      "venue" : "In Proceedings of the 24th Annual ACM-SIAM Symposium on Discrete Algorithms (SODA),",
      "citeRegEx" : "7",
      "shortCiteRegEx" : "7",
      "year" : 2013
    }, {
      "title" : "A lower bound for the smallest eigenvalue of the Laplacian",
      "author" : [ "J. Cheeger" ],
      "venue" : null,
      "citeRegEx" : "8",
      "shortCiteRegEx" : "8",
      "year" : 1969
    }, {
      "title" : "Bayesian combinatorial auctions",
      "author" : [ "G. Christodoulou", "A. Kovács", "M. Schapira" ],
      "venue" : "In Proceedings of theInternational Colloquium on Automata, Languages and Programming (ICALP),",
      "citeRegEx" : "9",
      "shortCiteRegEx" : "9",
      "year" : 2008
    }, {
      "title" : "The sample complexity of revenue maximization",
      "author" : [ "R. Cole", "T. Roughgarden" ],
      "venue" : "In Proceedings of the 46th Annual ACM Symposium on Theory of Computing (STOC),",
      "citeRegEx" : "10",
      "shortCiteRegEx" : "10",
      "year" : 2014
    }, {
      "title" : "Learning in auctions: Regret is hard, envy is easy",
      "author" : [ "C. Daskalakis", "V. Syrgkanis" ],
      "venue" : "In Proceedings of the 57th Symposium on Foundations of Computer Science (FOCS)",
      "citeRegEx" : "11",
      "shortCiteRegEx" : "11",
      "year" : 2016
    }, {
      "title" : "The sample complexity of auctions with side information",
      "author" : [ "N.R. Devanur", "Z. Huang", "Psomas", "C.-A" ],
      "venue" : "In Proceedings of the 48th Annual ACM Symposium on Theory of Computing (STOC),",
      "citeRegEx" : "12",
      "shortCiteRegEx" : "12",
      "year" : 2016
    }, {
      "title" : "Mechanisms for multi-unit auctions",
      "author" : [ "S. Dobzinski", "N. Nisan" ],
      "venue" : "In Proceedings of the 8th ACM Conference on Economics and Computation (EC),",
      "citeRegEx" : "13",
      "shortCiteRegEx" : "13",
      "year" : 2007
    }, {
      "title" : "Simultaneous auctions are (almost) efficient",
      "author" : [ "M. Feldman", "H. Fu", "N. Gravin", "B. Lucier" ],
      "venue" : "In Proceedings of the 45th Annual ACM Symposium on Theory of Computing (STOC),",
      "citeRegEx" : "14",
      "shortCiteRegEx" : "14",
      "year" : 2013
    }, {
      "title" : "A desicion-theoretic generalization of on-line learning and an application to boosting",
      "author" : [ "Y. Freund", "R.E. Schapire" ],
      "venue" : "In European conference on computational learning theory,",
      "citeRegEx" : "15",
      "shortCiteRegEx" : "15",
      "year" : 1995
    }, {
      "title" : "Exact identification of read-once formulas using fixed points of amplification functions",
      "author" : [ "S.A. Goldman", "M.J. Kearns", "R.E. Schapire" ],
      "venue" : "SIAM Journal on Computing,",
      "citeRegEx" : "16",
      "shortCiteRegEx" : "16",
      "year" : 1993
    }, {
      "title" : "On profit-maximizing envy-free pricing",
      "author" : [ "V. Guruswami", "J.D. Hartline", "A.R. Karlin", "D. Kempe", "C. Kenyon", "F. McSherry" ],
      "venue" : "In Proceedings of the16th Annual ACM-SIAM Symposium on Discrete Algorithms (SODA),",
      "citeRegEx" : "17",
      "shortCiteRegEx" : "17",
      "year" : 2005
    }, {
      "title" : "Approximation to bayes risk in repeated play. Contributions to the Theory of Games, 3:97–139",
      "author" : [ "J. Hannan" ],
      "venue" : null,
      "citeRegEx" : "18",
      "shortCiteRegEx" : "18",
      "year" : 1957
    }, {
      "title" : "Mechanism design and approximation",
      "author" : [ "J.D. Hartline" ],
      "venue" : "Book draft. October,",
      "citeRegEx" : "19",
      "shortCiteRegEx" : "19",
      "year" : 2013
    }, {
      "title" : "Near-optimal pricing in near-linear time",
      "author" : [ "J.D. Hartline", "V. Koltun" ],
      "venue" : "In Workshop on Algorithms and Data Structures,",
      "citeRegEx" : "20",
      "shortCiteRegEx" : "20",
      "year" : 2005
    }, {
      "title" : "Simple versus optimal mechanisms",
      "author" : [ "J.D. Hartline", "T. Roughgarden" ],
      "venue" : "In Proceedings of the 10th ACM Conference on Economics and Computation (EC),",
      "citeRegEx" : "21",
      "shortCiteRegEx" : "21",
      "year" : 2009
    }, {
      "title" : "Online submodular minimization",
      "author" : [ "E. Hazan", "S. Kale" ],
      "venue" : "Journal of Machine Learning Research,",
      "citeRegEx" : "22",
      "shortCiteRegEx" : "22",
      "year" : 2012
    }, {
      "title" : "The computational power of optimization in online learning",
      "author" : [ "E. Hazan", "T. Koren" ],
      "venue" : "In Proceedings of the 48th Annual ACM Symposium on Theory of Computing (STOC). ACM",
      "citeRegEx" : "23",
      "shortCiteRegEx" : "23",
      "year" : 2016
    }, {
      "title" : "Adaptive online prediction by following the perturbed leader",
      "author" : [ "M. Hutter", "J. Poland" ],
      "venue" : "Journal of Machine Learning Research,",
      "citeRegEx" : "24",
      "shortCiteRegEx" : "24",
      "year" : 2005
    }, {
      "title" : "From batch to transductive online learning",
      "author" : [ "S. Kakade", "A.T. Kalai" ],
      "venue" : "In Proceedings of the 18th Annual Conference on Neural Information Processing Systems (NIPS),",
      "citeRegEx" : "25",
      "shortCiteRegEx" : "25",
      "year" : 2005
    }, {
      "title" : "Playing games with approximation algorithms",
      "author" : [ "S.M. Kakade", "A.T. Kalai", "K. Ligett" ],
      "venue" : "SIAM Journal on Computing,",
      "citeRegEx" : "26",
      "shortCiteRegEx" : "26",
      "year" : 2009
    }, {
      "title" : "Efficient algorithms for online decision problems",
      "author" : [ "A. Kalai", "S. Vempala" ],
      "venue" : "Journal of Computer and System Sciences,",
      "citeRegEx" : "27",
      "shortCiteRegEx" : "27",
      "year" : 2005
    }, {
      "title" : "On the pseudo-dimension of nearly optimal auctions",
      "author" : [ "J.H. Morgenstern", "T. Roughgarden" ],
      "venue" : "In Proceedings of the 29th Annual Conference on Neural Information Processing Systems (NIPS),",
      "citeRegEx" : "28",
      "shortCiteRegEx" : "28",
      "year" : 2015
    }, {
      "title" : "Optimal auction design",
      "author" : [ "R.B. Myerson" ],
      "venue" : "Mathematics of operations research,",
      "citeRegEx" : "29",
      "shortCiteRegEx" : "29",
      "year" : 1981
    }, {
      "title" : "Computationally feasible vcg mechanisms",
      "author" : [ "N. Nisan", "A. Ronen" ],
      "venue" : "J. Artif. Int. Res.,",
      "citeRegEx" : "30",
      "shortCiteRegEx" : "30",
      "year" : 2007
    }, {
      "title" : "Concentration inequalities for Markov chains by Marton couplings and spectral methods. ArXiv e-prints",
      "author" : [ "D. Paulin" ],
      "venue" : null,
      "citeRegEx" : "31",
      "shortCiteRegEx" : "31",
      "year" : 2012
    }, {
      "title" : "Ironing in the dark",
      "author" : [ "T. Roughgarden", "O. Schrijvers" ],
      "venue" : "In Proceedings of the17th ACM Conference on Economics and Computation (EC),",
      "citeRegEx" : "32",
      "shortCiteRegEx" : "32",
      "year" : 2016
    }, {
      "title" : "Minimizing regret with multiple reserves",
      "author" : [ "T. Roughgarden", "J.R. Wang" ],
      "venue" : "In Proceedings of the 17th ACM Conference on Economics and Computation (EC),",
      "citeRegEx" : "33",
      "shortCiteRegEx" : "33",
      "year" : 2016
    }, {
      "title" : "Understanding Machine Learning: From Theory to Algorithms",
      "author" : [ "S. Shalev-Shwartz", "S. Ben-David" ],
      "venue" : null,
      "citeRegEx" : "34",
      "shortCiteRegEx" : "34",
      "year" : 2014
    } ],
    "referenceMentions" : [ {
      "referenceID" : 26,
      "context" : "Our learning algorithm is a generalization of the classic FTPL algorithm of Kalai and Vempala [27], playing at every iteration the historically best-performing action after adding some perturbation to the performance of each of its actions.",
      "startOffset" : 94,
      "endOffset" : 98
    }, {
      "referenceID" : 10,
      "context" : "Our approach generalizes prior work on oracle-efficient online learning [11, 22, 27, 35], ranging from online combinatorial optimization, learning in simultaneous auctions, and contextual learning.",
      "startOffset" : 72,
      "endOffset" : 88
    }, {
      "referenceID" : 21,
      "context" : "Our approach generalizes prior work on oracle-efficient online learning [11, 22, 27, 35], ranging from online combinatorial optimization, learning in simultaneous auctions, and contextual learning.",
      "startOffset" : 72,
      "endOffset" : 88
    }, {
      "referenceID" : 26,
      "context" : "Our approach generalizes prior work on oracle-efficient online learning [11, 22, 27, 35], ranging from online combinatorial optimization, learning in simultaneous auctions, and contextual learning.",
      "startOffset" : 72,
      "endOffset" : 88
    }, {
      "referenceID" : 27,
      "context" : "We give oracle-efficient learning results for: (1) VCG auctions with bidder-specific reserves in single-parameter settings with matroid constraints, (2) envy-free item pricing in multi-item auctions with unlimited supply, and (3) s-level auctions of Morgenstern and Roughgarden [28] for singleitem settings.",
      "startOffset" : 278,
      "endOffset" : 282
    }, {
      "referenceID" : 1,
      "context" : "1 Introduction Online learning is increasingly playing a major role in the adaptive optimization of computer systems, from the design of online marketplaces [2, 5, 7, 33] to the optimization of routing schemes in communication networks [1].",
      "startOffset" : 157,
      "endOffset" : 170
    }, {
      "referenceID" : 4,
      "context" : "1 Introduction Online learning is increasingly playing a major role in the adaptive optimization of computer systems, from the design of online marketplaces [2, 5, 7, 33] to the optimization of routing schemes in communication networks [1].",
      "startOffset" : 157,
      "endOffset" : 170
    }, {
      "referenceID" : 6,
      "context" : "1 Introduction Online learning is increasingly playing a major role in the adaptive optimization of computer systems, from the design of online marketplaces [2, 5, 7, 33] to the optimization of routing schemes in communication networks [1].",
      "startOffset" : 157,
      "endOffset" : 170
    }, {
      "referenceID" : 32,
      "context" : "1 Introduction Online learning is increasingly playing a major role in the adaptive optimization of computer systems, from the design of online marketplaces [2, 5, 7, 33] to the optimization of routing schemes in communication networks [1].",
      "startOffset" : 157,
      "endOffset" : 170
    }, {
      "referenceID" : 0,
      "context" : "1 Introduction Online learning is increasingly playing a major role in the adaptive optimization of computer systems, from the design of online marketplaces [2, 5, 7, 33] to the optimization of routing schemes in communication networks [1].",
      "startOffset" : 236,
      "endOffset" : 239
    }, {
      "referenceID" : 14,
      "context" : "The design of online learning algorithms for these settings has a long and distinguished history, starting from the seminal work of Freund and Schapire [15] and dating back to the very early work of Hannan [18] and Blackwell [4].",
      "startOffset" : 152,
      "endOffset" : 156
    }, {
      "referenceID" : 17,
      "context" : "The design of online learning algorithms for these settings has a long and distinguished history, starting from the seminal work of Freund and Schapire [15] and dating back to the very early work of Hannan [18] and Blackwell [4].",
      "startOffset" : 206,
      "endOffset" : 210
    }, {
      "referenceID" : 3,
      "context" : "The design of online learning algorithms for these settings has a long and distinguished history, starting from the seminal work of Freund and Schapire [15] and dating back to the very early work of Hannan [18] and Blackwell [4].",
      "startOffset" : 225,
      "endOffset" : 228
    }, {
      "referenceID" : 0,
      "context" : "[1, 22, 25, 27].",
      "startOffset" : 0,
      "endOffset" : 15
    }, {
      "referenceID" : 21,
      "context" : "[1, 22, 25, 27].",
      "startOffset" : 0,
      "endOffset" : 15
    }, {
      "referenceID" : 24,
      "context" : "[1, 22, 25, 27].",
      "startOffset" : 0,
      "endOffset" : 15
    }, {
      "referenceID" : 26,
      "context" : "[1, 22, 25, 27].",
      "startOffset" : 0,
      "endOffset" : 15
    }, {
      "referenceID" : 26,
      "context" : "However, such reductions have found success only in limited albeit important settings, including online linear optimization, where the learner’s action space is the power-set of some ground elements and the objective of the learner is a linear function of these elements [27].",
      "startOffset" : 271,
      "endOffset" : 275
    }, {
      "referenceID" : 22,
      "context" : "From the recent work of Hazan and Koren [23], we know that, unlike the stochastic i.",
      "startOffset" : 40,
      "endOffset" : 44
    }, {
      "referenceID" : 26,
      "context" : "Our algorithm is a significant generalization of prior approaches that worked only for specific settings, including the work of Kalai and Vempala [27] on online linear optimization, Hazan and Kale [22] on online submodular minimization, Daskalakis and Syrgkanis [11] on online learning in simultaneous second-price auctions, and Syrgkanis et al.",
      "startOffset" : 146,
      "endOffset" : 150
    }, {
      "referenceID" : 21,
      "context" : "Our algorithm is a significant generalization of prior approaches that worked only for specific settings, including the work of Kalai and Vempala [27] on online linear optimization, Hazan and Kale [22] on online submodular minimization, Daskalakis and Syrgkanis [11] on online learning in simultaneous second-price auctions, and Syrgkanis et al.",
      "startOffset" : 197,
      "endOffset" : 201
    }, {
      "referenceID" : 10,
      "context" : "Our algorithm is a significant generalization of prior approaches that worked only for specific settings, including the work of Kalai and Vempala [27] on online linear optimization, Hazan and Kale [22] on online submodular minimization, Daskalakis and Syrgkanis [11] on online learning in simultaneous second-price auctions, and Syrgkanis et al.",
      "startOffset" : 262,
      "endOffset" : 266
    }, {
      "referenceID" : 15,
      "context" : "[16] and oracle-efficient learnability.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 28,
      "context" : "Unlike the standard approach to optimal auction design, initiated by the seminal work of Myerson [29], our approach is devoid of any assumptions about a prior distribution on the valuations of the players for the resources at sale.",
      "startOffset" : 97,
      "endOffset" : 101
    }, {
      "referenceID" : 32,
      "context" : "A special case of our framework is the recent work of Roughgarden and Wang [33], which considers online learning over the class of single-item second-price auctions with bidder-specific reserves and gives an algorithm which achieves good regret with respect to a constant factor Equivalently the set of players at each iteration can be the same as long as players are not forward looking and only optimize their utility from the current iteration.",
      "startOffset" : 75,
      "endOffset" : 79
    }, {
      "referenceID" : 20,
      "context" : "settings under some regularity conditions [21]; – the class of single-item s-level auctions introduced by Morgenstern and Roughgarden [28], who showed that these auctions approximate, to an arbitrary accuracy, the Myerson auction [29], which is known to be optimal for the Bayesian independent private value setting; and – the class of envy-free item pricing mechanisms in combinatorial markets with unlimited supply, which has been widely studied in the static Bayesian setting [2, 17].",
      "startOffset" : 42,
      "endOffset" : 46
    }, {
      "referenceID" : 27,
      "context" : "settings under some regularity conditions [21]; – the class of single-item s-level auctions introduced by Morgenstern and Roughgarden [28], who showed that these auctions approximate, to an arbitrary accuracy, the Myerson auction [29], which is known to be optimal for the Bayesian independent private value setting; and – the class of envy-free item pricing mechanisms in combinatorial markets with unlimited supply, which has been widely studied in the static Bayesian setting [2, 17].",
      "startOffset" : 134,
      "endOffset" : 138
    }, {
      "referenceID" : 28,
      "context" : "settings under some regularity conditions [21]; – the class of single-item s-level auctions introduced by Morgenstern and Roughgarden [28], who showed that these auctions approximate, to an arbitrary accuracy, the Myerson auction [29], which is known to be optimal for the Bayesian independent private value setting; and – the class of envy-free item pricing mechanisms in combinatorial markets with unlimited supply, which has been widely studied in the static Bayesian setting [2, 17].",
      "startOffset" : 230,
      "endOffset" : 234
    }, {
      "referenceID" : 1,
      "context" : "settings under some regularity conditions [21]; – the class of single-item s-level auctions introduced by Morgenstern and Roughgarden [28], who showed that these auctions approximate, to an arbitrary accuracy, the Myerson auction [29], which is known to be optimal for the Bayesian independent private value setting; and – the class of envy-free item pricing mechanisms in combinatorial markets with unlimited supply, which has been widely studied in the static Bayesian setting [2, 17].",
      "startOffset" : 479,
      "endOffset" : 486
    }, {
      "referenceID" : 16,
      "context" : "settings under some regularity conditions [21]; – the class of single-item s-level auctions introduced by Morgenstern and Roughgarden [28], who showed that these auctions approximate, to an arbitrary accuracy, the Myerson auction [29], which is known to be optimal for the Bayesian independent private value setting; and – the class of envy-free item pricing mechanisms in combinatorial markets with unlimited supply, which has been widely studied in the static Bayesian setting [2, 17].",
      "startOffset" : 479,
      "endOffset" : 486
    }, {
      "referenceID" : 29,
      "context" : ", by Maximal-inRange (MIR) algorithms [30]; and (3) regret bounds with respect to stronger benchmarks for the case in which the environment is not completely adversarial but rather follows a fast mixing Markov process.",
      "startOffset" : 38,
      "endOffset" : 42
    }, {
      "referenceID" : 9,
      "context" : "settings [10, 12, 28, 32].",
      "startOffset" : 9,
      "endOffset" : 25
    }, {
      "referenceID" : 11,
      "context" : "settings [10, 12, 28, 32].",
      "startOffset" : 9,
      "endOffset" : 25
    }, {
      "referenceID" : 27,
      "context" : "settings [10, 12, 28, 32].",
      "startOffset" : 9,
      "endOffset" : 25
    }, {
      "referenceID" : 31,
      "context" : "settings [10, 12, 28, 32].",
      "startOffset" : 9,
      "endOffset" : 25
    }, {
      "referenceID" : 12,
      "context" : "In the former application, we give a polynomial time online learning algorithm for online welfare maximization in multi-unit auctions, that achieves 2-approximate regret by invoking the MIR approximation algorithm of Dobzinski and Nisan [13] as an offline oracle.",
      "startOffset" : 237,
      "endOffset" : 241
    }, {
      "referenceID" : 10,
      "context" : "With the latter application, we solve an open problem raised in the recent work of Daskalakis and Syrgkanis [11] who offered efficient learning algorithms only for the weaker benchmark of no-envy learning, rather than no-regret learning, in simultaneous second price auctions.",
      "startOffset" : 108,
      "endOffset" : 112
    }, {
      "referenceID" : 14,
      "context" : "Ignoring computational efficiency constraints, the exponential weights algorithm of Freund and Schapire [15] achieves a regret rate of O( √ log |X |/T ), which, absent any structure on the reward function, is information-theoretically optimal.",
      "startOffset" : 104,
      "endOffset" : 108
    }, {
      "referenceID" : 5,
      "context" : "The offline problem (or, possibly, an FPTAS for the offline problem) is a weaker problem than the online learning problem, because standard online-to-batch reductions [6, 11] can turn a polynomial-time online learning algorithm into a polynomial-time additiveapproximation scheme for the offline problem.",
      "startOffset" : 167,
      "endOffset" : 174
    }, {
      "referenceID" : 10,
      "context" : "The offline problem (or, possibly, an FPTAS for the offline problem) is a weaker problem than the online learning problem, because standard online-to-batch reductions [6, 11] can turn a polynomial-time online learning algorithm into a polynomial-time additiveapproximation scheme for the offline problem.",
      "startOffset" : 167,
      "endOffset" : 174
    }, {
      "referenceID" : 33,
      "context" : "from some distribution at each iteration, such an approach works and offers regret rates on the order O(log |X |/ √ T ) by a simple application of the Rademacher complexity of finite hypotheses classes [34].",
      "startOffset" : 202,
      "endOffset" : 206
    }, {
      "referenceID" : 26,
      "context" : "A seminal paper of Kalai and Vempala [27] showed that a slight modification of this algorithm leads to good regret.",
      "startOffset" : 37,
      "endOffset" : 41
    }, {
      "referenceID" : 10,
      "context" : "Daskalakis and Syrgkanis [11] introduced the approach of adding randomness to the FTL algorithm by augmenting the observed history with “fake” historical samples of adversary actions.",
      "startOffset" : 25,
      "endOffset" : 29
    }, {
      "referenceID" : 0,
      "context" : "In this way, we construct a perturbation translation matrix Γ (for simplicity assume entries in [0, 1]), which translates the short N -dimensional perturbation vector into a long |X |-dimensional one, i.",
      "startOffset" : 96,
      "endOffset" : 102
    }, {
      "referenceID" : 15,
      "context" : "[16].",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 10,
      "context" : "A separator [11] is a small set of contexts such that any two policies in the policy class choose different actions on at least one context from the set.",
      "startOffset" : 12,
      "endOffset" : 16
    }, {
      "referenceID" : 21,
      "context" : "This approach was leveraged by Hazan and Kale [22] for online submodular minimization.",
      "startOffset" : 46,
      "endOffset" : 50
    }, {
      "referenceID" : 9,
      "context" : "The knowledge of the distribution by the seller is a rather harsh assumption and recent work in algorithmic mechanism design [10, 12, 28, 32] relaxes this assumption by solely assuming access to a set of samples from the distribution.",
      "startOffset" : 125,
      "endOffset" : 141
    }, {
      "referenceID" : 11,
      "context" : "The knowledge of the distribution by the seller is a rather harsh assumption and recent work in algorithmic mechanism design [10, 12, 28, 32] relaxes this assumption by solely assuming access to a set of samples from the distribution.",
      "startOffset" : 125,
      "endOffset" : 141
    }, {
      "referenceID" : 27,
      "context" : "The knowledge of the distribution by the seller is a rather harsh assumption and recent work in algorithmic mechanism design [10, 12, 28, 32] relaxes this assumption by solely assuming access to a set of samples from the distribution.",
      "startOffset" : 125,
      "endOffset" : 141
    }, {
      "referenceID" : 31,
      "context" : "The knowledge of the distribution by the seller is a rather harsh assumption and recent work in algorithmic mechanism design [10, 12, 28, 32] relaxes this assumption by solely assuming access to a set of samples from the distribution.",
      "startOffset" : 125,
      "endOffset" : 141
    }, {
      "referenceID" : 27,
      "context" : "Another class of auctions that we analyze is the recently introduced class of level auctions [28].",
      "startOffset" : 93,
      "endOffset" : 97
    }, {
      "referenceID" : 27,
      "context" : "Morgenstern and Roughgarden [28] showed that these auctions, for large enough number of buckets, provide an arbitrarily accurate approximation to the overall optimal Myerson auction in the Bayesian single-item auction setting, where the value of each bidder is drawn from an independent distribution.",
      "startOffset" : 28,
      "endOffset" : 32
    }, {
      "referenceID" : 9,
      "context" : "This is the first result on competing with a Myerson optimal auction for non-iid distributions, unlike prior work [10, 12, 28, 32] which assumes i.",
      "startOffset" : 114,
      "endOffset" : 130
    }, {
      "referenceID" : 11,
      "context" : "This is the first result on competing with a Myerson optimal auction for non-iid distributions, unlike prior work [10, 12, 28, 32] which assumes i.",
      "startOffset" : 114,
      "endOffset" : 130
    }, {
      "referenceID" : 27,
      "context" : "This is the first result on competing with a Myerson optimal auction for non-iid distributions, unlike prior work [10, 12, 28, 32] which assumes i.",
      "startOffset" : 114,
      "endOffset" : 130
    }, {
      "referenceID" : 31,
      "context" : "This is the first result on competing with a Myerson optimal auction for non-iid distributions, unlike prior work [10, 12, 28, 32] which assumes i.",
      "startOffset" : 114,
      "endOffset" : 130
    }, {
      "referenceID" : 0,
      "context" : "The learner then observes yt and receives a payoff f(xt, yt) ∈ [0, 1], where the function f is fixed and known to the learner.",
      "startOffset" : 63,
      "endOffset" : 69
    }, {
      "referenceID" : 10,
      "context" : "Our results generalize to adaptive adversaries using standard techniques [11, 24].",
      "startOffset" : 73,
      "endOffset" : 81
    }, {
      "referenceID" : 23,
      "context" : "Our results generalize to adaptive adversaries using standard techniques [11, 24].",
      "startOffset" : 73,
      "endOffset" : 81
    }, {
      "referenceID" : 26,
      "context" : "Our algorithm broadly follows the FTPL scheme of Kalai and Vempala [27].",
      "startOffset" : 67,
      "endOffset" : 71
    }, {
      "referenceID" : 26,
      "context" : "In the original FTPL scheme of Kalai and Vempala [27], at every iteration the algorithm adds a perturbation to the historical cumulative payoff of each possible action of the learner and then picks the action with the largest perturbed historical payoff.",
      "startOffset" : 49,
      "endOffset" : 53
    }, {
      "referenceID" : 26,
      "context" : "For online combinatorial optimization with either additive [27] or submodular [22] objectives, it has been shown that one does not need to add a perturbation on each set, but adding a perturbation on each item suffices to lead to no-regret.",
      "startOffset" : 59,
      "endOffset" : 63
    }, {
      "referenceID" : 21,
      "context" : "For online combinatorial optimization with either additive [27] or submodular [22] objectives, it has been shown that one does not need to add a perturbation on each set, but adding a perturbation on each item suffices to lead to no-regret.",
      "startOffset" : 78,
      "endOffset" : 82
    }, {
      "referenceID" : 10,
      "context" : "In particular, we seek to generate perturbations that can be simulated by augmenting the history with a polynomial number of fake samples as proposed in Daskalakis and Syrgkanis [11].",
      "startOffset" : 178,
      "endOffset" : 182
    }, {
      "referenceID" : 26,
      "context" : "While this approach is standard [27], we include a proof in Appendix A for completeness.",
      "startOffset" : 32,
      "endOffset" : 36
    }, {
      "referenceID" : 22,
      "context" : "Note that unlike the oracle of [23], which accepts a distribution, we do not require the weights to sum to one.",
      "startOffset" : 31,
      "endOffset" : 35
    }, {
      "referenceID" : 0,
      "context" : "Each bidder i ∈ [n] has a combinatorial valuation function vi ∈ V , where V ⊆ ({0, 1}k → [0, 1]).",
      "startOffset" : 89,
      "endOffset" : 95
    }, {
      "referenceID" : 0,
      "context" : "For single-parameter service based environments (a special case of which are single-item auctions), we slightly simplify notation and use vi ∈ [0, 1] to denote the value of bidder i for being served.",
      "startOffset" : 143,
      "endOffset" : 149
    }, {
      "referenceID" : 20,
      "context" : "These auctions are known to approximately maximize the revenue when the bidder valuations are drawn independently (but not necessarily identically) from some distribution [21].",
      "startOffset" : 171,
      "endOffset" : 175
    }, {
      "referenceID" : 32,
      "context" : "Recently, Roughgarden and Wang [33] considered this class I in an online learning framework.",
      "startOffset" : 31,
      "endOffset" : 35
    }, {
      "referenceID" : 20,
      "context" : "Each bidder who is served is then charged the externality he imposes on others, pi(v) = maxq ∑ i′ 6=i vi′(qi′)− ∑ i′ 6=i vi′(q ∗ i′), which can A more common and stronger assumption used in previous work [21, 33] is that S is a downward closed matroid.",
      "startOffset" : 204,
      "endOffset" : 212
    }, {
      "referenceID" : 32,
      "context" : "Each bidder who is served is then charged the externality he imposes on others, pi(v) = maxq ∑ i′ 6=i vi′(qi′)− ∑ i′ 6=i vi′(q ∗ i′), which can A more common and stronger assumption used in previous work [21, 33] is that S is a downward closed matroid.",
      "startOffset" : 204,
      "endOffset" : 212
    }, {
      "referenceID" : 0,
      "context" : "Now let us return to the infinite class I of all VCG auctions with reserve prices ri ∈ [0, 1].",
      "startOffset" : 87,
      "endOffset" : 93
    }, {
      "referenceID" : 16,
      "context" : "2 Envy-free Item Pricing In this section, we consider envy-free item pricing [17] in an environment with k heterogeneous items with a supply of s` ≥ 0 units for each item ` ≤ k.",
      "startOffset" : 77,
      "endOffset" : 81
    }, {
      "referenceID" : 1,
      "context" : "Examples of such environments include unit-demand bidders in unlimited supply setting and singleminded bidders in unlimited supply setting, such as hypergraph pricing, where bidders seek hyper-edges in a hypergraph, and its variant the highway problem, where bidders seek hyperedges between sets of contiguous vertices [2, 17].",
      "startOffset" : 319,
      "endOffset" : 326
    }, {
      "referenceID" : 16,
      "context" : "Examples of such environments include unit-demand bidders in unlimited supply setting and singleminded bidders in unlimited supply setting, such as hypergraph pricing, where bidders seek hyper-edges in a hypergraph, and its variant the highway problem, where bidders seek hyperedges between sets of contiguous vertices [2, 17].",
      "startOffset" : 319,
      "endOffset" : 326
    }, {
      "referenceID" : 0,
      "context" : "Consider the class of all envy-free item-pricing auctions where a` ∈ [0, 1] is a real number and denote this class by P .",
      "startOffset" : 69,
      "endOffset" : 75
    }, {
      "referenceID" : 19,
      "context" : "Hartline and Koltun [20] also provided a discretization of P that has multiplicative approximation guarantee, but using a discretized set different from Pm.",
      "startOffset" : 20,
      "endOffset" : 24
    }, {
      "referenceID" : 27,
      "context" : "3 Level Auctions We consider the class of level auctions introduced by Morgenstern and Roughgarden [28].",
      "startOffset" : 99,
      "endOffset" : 103
    }, {
      "referenceID" : 27,
      "context" : "These auctions can achieve (1− )-approximate revenue maximization, when the valuations of the bidders are drawn independently (but not necessarily identically) from a distribution [28], approximating the Myerson’s optimal auction [29].",
      "startOffset" : 180,
      "endOffset" : 184
    }, {
      "referenceID" : 28,
      "context" : "These auctions can achieve (1− )-approximate revenue maximization, when the valuations of the bidders are drawn independently (but not necessarily identically) from a distribution [28], approximating the Myerson’s optimal auction [29].",
      "startOffset" : 230,
      "endOffset" : 234
    }, {
      "referenceID" : 0,
      "context" : "Then, for any θ ∈ Rs,m, there is θ ′ ∈ Rs,m, such that ∀v ∈ [0, 1], Rev(θ,v) = Rev(θ′,v).",
      "startOffset" : 60,
      "endOffset" : 66
    }, {
      "referenceID" : 0,
      "context" : "with expected value Ey∼F [f(x∗, y)] and are bounded in [0, 1].",
      "startOffset" : 55,
      "endOffset" : 61
    }, {
      "referenceID" : 30,
      "context" : "In this work we will specifically use the following result of Paulin [31], which is a Bernstein concentration inequality for sums of dependent random variables that are the outcome of a stationary Markov chain with spectral gap bounded away from zero.",
      "startOffset" : 69,
      "endOffset" : 73
    }, {
      "referenceID" : 30,
      "context" : "For simplicity, we focus on stationary chains, though similar results hold for non-stationary chains (see Paulin [31] and references therein).",
      "startOffset" : 113,
      "endOffset" : 117
    }, {
      "referenceID" : 30,
      "context" : "2 (Paulin [31], Theorem 3.",
      "startOffset" : 10,
      "endOffset" : 14
    }, {
      "referenceID" : 0,
      "context" : "Let g : Ω→ [0, 1] and Sz = 1 z ∑z i=1 g(Xi).",
      "startOffset" : 11,
      "endOffset" : 17
    }, {
      "referenceID" : 0,
      "context" : "If we set = √ 14 log(2/δ) γT then we have, either > 1, in which case the inequality is trivial, since f(x, y) ∈ [0, 1], or if ≤ 1, then = √ 14 log(2/δ) γT ≥ √ (4+10 ) log(2/δ) γT , which implies that the inequality holds with probability 1− δ.",
      "startOffset" : 112,
      "endOffset" : 118
    }, {
      "referenceID" : 7,
      "context" : "Moreover, by the Cheeger bound [8] we know that γ ≥ Φ2 2 ≥ (1−ρ)2 4 .",
      "startOffset" : 31,
      "endOffset" : 34
    }, {
      "referenceID" : 28,
      "context" : "Then we know that the optimal auction for this setting is what is known as Myerson’s auction [29], which translates the players’ values based on some monotone function φ, known as the ironed virtual value function and then allocates the item to the bidder with the highest virtual value, charging payments so that the mechanism is dominant strategy truthful.",
      "startOffset" : 93,
      "endOffset" : 97
    }, {
      "referenceID" : 27,
      "context" : "A recent result of Morgenstern and Roughgarden [28] shows that level auctions approximate Myerson’s auction in terms of revenue.",
      "startOffset" : 47,
      "endOffset" : 51
    }, {
      "referenceID" : 0,
      "context" : "Since fc(π, (σt, yt)) = f(π(σt), yt) and since f(x, y) ∈ [0, 1], it suffices to show that Pr[πt+1(σt) 6= πt(σt)] ≤ 2Nκρ.",
      "startOffset" : 57,
      "endOffset" : 63
    }, {
      "referenceID" : 5,
      "context" : "That is, using standard online-to-batch reductions [6, 11], one can turn a polynomial time online no-regret algorithm into a polynomial time additive approximation scheme for the offline problem.",
      "startOffset" : 51,
      "endOffset" : 58
    }, {
      "referenceID" : 10,
      "context" : "That is, using standard online-to-batch reductions [6, 11], one can turn a polynomial time online no-regret algorithm into a polynomial time additive approximation scheme for the offline problem.",
      "startOffset" : 51,
      "endOffset" : 58
    }, {
      "referenceID" : 25,
      "context" : "[26] introduced an alternative measure of regret, called C-REGRET, for competing with offline approximation algorithm.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 1,
      "context" : "A similar observation was made by Balcan and Blum [2] regarding approximation algorithms that use linear optimization as a relaxation and therefore can be efficiently optimized by the standard FTPL algorithm of Kalai and Vempala [27].",
      "startOffset" : 50,
      "endOffset" : 53
    }, {
      "referenceID" : 26,
      "context" : "A similar observation was made by Balcan and Blum [2] regarding approximation algorithms that use linear optimization as a relaxation and therefore can be efficiently optimized by the standard FTPL algorithm of Kalai and Vempala [27].",
      "startOffset" : 229,
      "endOffset" : 233
    }, {
      "referenceID" : 32,
      "context" : "Roughgarden and Wang [33] as a Relaxation.",
      "startOffset" : 21,
      "endOffset" : 25
    }, {
      "referenceID" : 32,
      "context" : "The approach of Roughgarden and Wang [33] for achieving a 1/2-regret for single-item second price auctions with bidder-specific reserves, falls exactly in the relaxation approximation framework.",
      "startOffset" : 37,
      "endOffset" : 41
    }, {
      "referenceID" : 26,
      "context" : "However, in their case the relaxed objective corresponds to an online linear optimization problem and can be solved with the standard FTPL algorithm of Kalai and Vempala [27].",
      "startOffset" : 170,
      "endOffset" : 174
    }, {
      "referenceID" : 0,
      "context" : "Each bidder i has a monotonic valuation function vi : [k]→ [0, 1].",
      "startOffset" : 59,
      "endOffset" : 65
    }, {
      "referenceID" : 12,
      "context" : "Dobzinski and Nisan [13] introduced a 1/2-approximation MIR algorithm for this problem.",
      "startOffset" : 20,
      "endOffset" : 24
    }, {
      "referenceID" : 12,
      "context" : "the matrix ΓMU ′ restricted to the range of the 1/2 approximation algorithm of Dobzinski and Nisan [13] has much better admissibility constants.",
      "startOffset" : 99,
      "endOffset" : 103
    }, {
      "referenceID" : 12,
      "context" : ",vT , the Generalized FTPL algorithm with matrix ΓMU, distribution D and oracle the 1/2aproximate MIR algorithm of [13], runs in per-round time poly(n, T ), plays the sequence of allocations q1, .",
      "startOffset" : 115,
      "endOffset" : 119
    }, {
      "referenceID" : 10,
      "context" : "2 Oracle Efficient No-Regret Learning in Simultaneous Second Price Auctions In this section, we answer an open problem raised by Daskalakis and Syrgkanis [11] regarding the existence of an oracle-based no-regret algorithm for optimal bidding in Simultaneous Second-Price Auctions.",
      "startOffset" : 154,
      "endOffset" : 158
    }, {
      "referenceID" : 2,
      "context" : "A Simultaneous Second-Price Auction (SiSPA) [3, 9, 14] is a mechanism for allocating k items to n bidders.",
      "startOffset" : 44,
      "endOffset" : 54
    }, {
      "referenceID" : 8,
      "context" : "A Simultaneous Second-Price Auction (SiSPA) [3, 9, 14] is a mechanism for allocating k items to n bidders.",
      "startOffset" : 44,
      "endOffset" : 54
    }, {
      "referenceID" : 13,
      "context" : "A Simultaneous Second-Price Auction (SiSPA) [3, 9, 14] is a mechanism for allocating k items to n bidders.",
      "startOffset" : 44,
      "endOffset" : 54
    }, {
      "referenceID" : 0,
      "context" : "Each bidder i has a fixed combinatorial valuation function vi : {0, 1}k → [0, 1] over bundles of items.",
      "startOffset" : 74,
      "endOffset" : 80
    }, {
      "referenceID" : 8,
      "context" : "Similar no-overbidding assumptions are used in the previous work to prove that no-regret learning in second-price auctions has good welfare guarantees [9, 14].",
      "startOffset" : 151,
      "endOffset" : 158
    }, {
      "referenceID" : 13,
      "context" : "Similar no-overbidding assumptions are used in the previous work to prove that no-regret learning in second-price auctions has good welfare guarantees [9, 14].",
      "startOffset" : 151,
      "endOffset" : 158
    }, {
      "referenceID" : 15,
      "context" : "5 (Universal Identification Sequences [16]).",
      "startOffset" : 38,
      "endOffset" : 42
    }, {
      "referenceID" : 15,
      "context" : "Examples of function classes with polynomial-length universal identification sequences include logarithmic-depth read-once majority formulas and logarithmicdepth read-once positive NAND formulas [16].",
      "startOffset" : 195,
      "endOffset" : 199
    } ],
    "year" : 2017,
    "abstractText" : "We consider the design of online learning algorithms in a general learning setting, with the goal of obtaining computationally efficient no-regret algorithms, when given access to an oracle for the offline optimization version of the problem. We present an algorithm that we call Generalized Follow-thePerturbed-Leader (Generalized FTPL) and provide conditions under which it achieves vanishing regret and is efficiently implementable with an oracle. Our second main contribution is the introduction of a new online adversarial auction-design framework for revenue maximization and an application of our oracle-efficient learning results to the adaptive optimization of auctions. Our learning algorithm is a generalization of the classic FTPL algorithm of Kalai and Vempala [27], playing at every iteration the historically best-performing action after adding some perturbation to the performance of each of its actions. The crux of our design is adding perturbations in a manner that leads to oracle-efficiency. We reduce this to designing a translation matrix, which translates a low dimensional vector with independent noise components into a high dimensional vector of perturbations on the learner’s action space. Our approach generalizes prior work on oracle-efficient online learning [11, 22, 27, 35], ranging from online combinatorial optimization, learning in simultaneous auctions, and contextual learning. Our auction-design framework considers an auctioneer learning an optimal auction rule in an online manner, every day observing an adversarially chosen vector of valuations. The auctioneer’s goal is to achieve revenue that competes with the revenue of the optimal auction in hindsight among those in some target class. We give oracle-efficient learning results for: (1) VCG auctions with bidder-specific reserves in single-parameter settings with matroid constraints, (2) envy-free item pricing in multi-item auctions with unlimited supply, and (3) s-level auctions of Morgenstern and Roughgarden [28] for singleitem settings. The last result implies good regret against the optimal overall auction when valuations are coming from a fast mixing Markov chain, that is independent across bidders. We also extend our results to the case when the learner observes side information on the bidders before running the auction (contextual learning). We present additional extensions to contextual learning and learning with approximate oracles, implemented by FPTAS or Maximal-in-Range algorithms. We provide further applications in online welfare maximization in multi-unit auctions and in no-regret learning in simultaneous item auctions, answering an open question from prior work. ∗Microsoft Research, New York, mdudik@microsoft.com †Computer Science Department, Carnegie Mellon University, nhaghtal@cs.cmu.edu ‡Microsoft Research, New York, haipeng@microsoft.com §Microsoft Research, New York, schapire@microsoft.com ¶Microsoft Research, New England, vasy@microsoft.com ‖Microsoft Research, New York, jenn@microsoft.com ar X iv :1 61 1. 01 68 8v 1 [ cs .L G ] 5 N ov 2 01 6",
    "creator" : "LaTeX with hyperref package"
  }
}