{
  "name" : "1411.1119.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "Projecting Markov Random Field Parameters for Fast Mixing",
    "authors" : [ "Xianghang Liu", "Justin Domke" ],
    "emails" : [ "xianghang.liu@nicta.com.au", "justin.domke@nicta.com.au" ],
    "sections" : [ {
      "heading" : "1 Introduction",
      "text" : "Exact inference in Markov Random Fields (MRFs) is generally intractable, motivating approximate algorithms. There are two main classes of approximate inference algorithms: variational methods and Markov chain Monte Carlo (MCMC) algorithms [13].\nAmong variational methods, mean-field approximations [9] are based on a “tractable” family of distributions, such as the fully-factorized distributions. Inference finds a distribution in the tractable set to minimize the KL-divergence from the true distribution. Other methods, such as loopy belief propagation (LBP), generalized belief propagation [14] and expectation propagation [10] use a less restricted family of target distributions, but approximate the KL-divergence. Variational methods are typically fast, and often produce high-quality approximations. However, when the variational approximations are poor, estimates can be correspondingly worse.\nMCMC strategies, such as Gibbs sampling, simulate a Markov chain whose stationary distribution is the target distribution. Inference queries are then answered by the samples drawn from the Markov chain. In principle, MCMC will be arbitrarily accurate if run long enough. The principal difficulty is that the time for the Markov chain to converge to its stationary distribution, or the “mixing time”, can be exponential in the number of variables.\nThis paper is inspired by a recent hybrid approach for Ising models [3]. This approach minimizes the divergence from the true distribution to one in a tractable family. However, the tractable family is a “fast mixing” family where Gibbs sampling is guaranteed to quickly converge to the stationary distribution. They observe that an Ising model will be fast mixing if the spectral norm of a matrix containing the absolute values of all interactions strengths is controlled. An algorithm projects onto this fast mixing parameter set in the Euclidean norm, and projected gradient descent (PGD) can minimize various divergence measures. This often leads to inference results that are better than either simple variational methods or univariate Gibbs sampling (with a limited time budget). However, this approach is limited to Ising models, and scales poorly in the size of the model, due to the difficulty of projecting onto the spectral norm.\n1\nar X\niv :1\n41 1.\n11 19\nv3 [\ncs .L\nG ]\n1 2\nN ov\nThe principal contributions of this paper are, first, a set of sufficient conditions to guarantee that univariate Gibbs sampling on an MRF will be fast-mixing (Section 4), and an algorithm to project onto this set in the Euclidean norm (Section 5). A secondary contribution of this paper is considering an alternative matrix norm (the induced ∞-norm) that is somewhat looser than the spectral norm, but more computationally efficient. Following previous work [3], these ideas are experimentally validated via a projected gradient descent algorithm to minimize other divergences, and looking at the accuracy of the resulting marginals. The ability to project onto a fast-mixing parameter set may also be of independent interest. For example, it might be used during maximum likelihood learning to ensure that the gradients estimated through sampling are more accurate."
    }, {
      "heading" : "2 Notation",
      "text" : "We consider discrete pairwise MRFs with n variables, where the i-th variable takes values in {1, ..., Li}, E is the set of edges, and θ are the potentials on each edge. Each edge in E is an ordered pair (i, j) with i ≤ j. The parameters are a set of matrices θ := {θij |θij ∈ RLi×Lj ,∀(i, j) ∈ E}. When i > j, and (j, i) ∈ E , we let θij denote the transpose of θji. The corresponding distribution is\np(x; θ) = exp  ∑ (i,j)∈E θij(xi, xj)−A(θ)  , (1) where A(θ) := log ∑ x exp (∑ (i,j)∈E θ ij(xi, xj) ) is the log-partition function, and θij(xi, xj)\ndenotes the entry in the xi-th row and xj-th column of θij . It is easy to show that any parametrization of a pairwise MRF can be converted into this form. “Self-edges” (i, i) can be included in E if one wishes to explicitly represent univariate terms.\nIt is sometimes convenient to work with the exponential family representation p(x; θ) = exp{f(x) · θ −A(θ)}, (2)\nwhere f(x) is the sufficient statistics for configuration x. If these are indicator functions for all configurations of all pairs in E , then the two representations are equivalent."
    }, {
      "heading" : "3 Background Theory on Rapid Mixing",
      "text" : "This section reviews background on mixing times that will be used later in the paper. Definition 1. Given two finite distributions p and q, the total variation distance ‖ · ‖TV is defined as ‖p(X)− q(X)‖TV = 12 ∑ x |p(X = x)− q(X = x)|.\nNext, one must define a measure of how fast a Markov chain converges to the stationary distribution. Let the state of the Markov chain after t iterations be Xt. Given a constant , this is done by finding some number of iterations τ( ) such that the induced distribution p(Xt|X0 = x) will always have a distance of less than from the stationary distribution, irrespective of the starting state x. Definition 2. Let {Xt} be the sequence of random variables corresponding to running Gibbs sampling on a distribution p. The mixing time τ( ) is defined as τ( ) = min{t : d(t) < }, where d(t) = maxx ‖P(Xt|X0 = x)− p(X)‖TV is the maximum distance at time t when considering all possible starting states x.\nNow, we are interested in when Gibbs sampling on a distribution p can be shown to have a fast mixing time. The central property we use is the dependency of one variable on another, defined informally as how much the conditional distribution over Xi can be changed when all variables other than Xj are the same. Definition 3. Given a distribution p, the dependency matrix R is defined by\nRij = max x,x′:x−j=x′−j\n‖p(Xi|x−i)− p(Xi|x′−i)‖TV .\nHere, the constraint x−j = x′−j indicates that all variables in x and x ′ are identical except xj . The central result on rapid mixing is given by the following Theorem, due to Dyer et al. [5], generalizing the work of Hayes [7]. Informally, it states that if ‖R‖ < 1 for any sub-multiplicative norm ‖ · ‖, then mixing will take on the order of n lnn iterations, where n is the number of variables.\n2\nTheorem 4. [5, Lemma 17] If ‖ · ‖ is any sub-multiplicative matrix norm and ||R|| < 1, the mixing time of univariate Gibbs sampling on a system with n variables with random updates is bounded by τ( ) ≤ n1−‖R‖ ln ( ‖1n‖ ‖1Tn‖ ) .\nHere, ‖1n‖ denotes the same matrix norm applied to a matrix of ones of size n × 1, and similarly for 1Tn . In particular, if ‖ · ‖ induced by a vector p-norm, then ‖1n‖ ‖1Tn‖ = n. Since this result is true for a variety of norms, it is natural to ask, for a given matrix R, which norm will give the strongest result. It can be shown that for symmetric matrices (such as the dependency matrix), the spectral norm ‖ · ‖2 is always superior. Theorem 5. [5, Lemma 13] If A is a symmetric matrix and ‖ · ‖ is any sub-multiplicative norm, then ‖A‖2 ≤ ‖A‖.\nUnfortunately, as will be discussed below, the spectral norm can be more computationally expensive than other norms. As such, we will also consider the use of the ∞-norm ‖ · ‖∞. This leads to additional looseness in the bound in general, but is limited in some cases. In particular if R = rG whereG is the adjacency matrix for some regular graph with degree d, then for all induced p-norms, ‖R‖ = rd, since ‖R‖ = maxx 6=0 ‖Rx‖/‖x| = rmaxx 6=0 ‖Gx‖/‖x‖ = r‖Go‖/‖o‖ = rd, where o is a vector of ones. Thus, the extra looseness from using, say, ‖ · ‖∞ instead of ‖ · ‖2 will tend to be minimal when the graph is close to regular, and the dependency is close to a constant value. For irregular graphs with highly variable dependency, the looseness can be much larger."
    }, {
      "heading" : "4 Dependency for Markov Random Fields",
      "text" : "In order to establish that Gibbs sampling on a given MRF will be fast mixing, it is necessary to compute (a bound on) the dependency matrix R, as done in the following result. The proof of this result is fairly long, and so it is postponed to the Appendix. Note that it follows from several bounds on the dependency that are tighter, but less computationally convenient. Theorem 6. The dependency matrix for a pairwise Markov random field is bounded by\nRij(θ) ≤ max a,b\n1 2 ‖θij·a − θ ij ·b‖∞.\nHere, θij·a indicates the a−th column of θij . Note that the MRF can include univariate terms as selfedges with no impact on the dependency bound, regardless of the strength of the univariate terms. It can be seen easily that from the definition of R (Definition 3), for any i the entry Rii for self-edges (i, i) should always be zero. One can, without loss of generality, set each column of θii to be the same, meaning that Rii = 0 in the above bound."
    }, {
      "heading" : "5 Euclidean Projection Operator",
      "text" : "The Euclidean distance between two MRFs parameterized respectively by ψ and θ is ‖θ − ψ‖2 :=∑ (i,j)∈E ‖θij − ψij‖2F . This section considers projecting a given vector ψ onto the fast mixing set or, formally, finding a vector θ with minimum Euclidean distance to ψ, subject to the constraint that a norm ‖ · ‖∗ applied to the bound on the dependency matrix R is less than some constant c. Euclidean projection is considered because, first, it is a straightforward measure of the closeness between two parameters and, second, it is the building block of the projected gradient descent for projection in other distance measures. To begin with, we do not specify the matrix norm ‖ · ‖∗, as it could be any sub-multiplicative norm (Section 3).\nThus, in principle, we would like to find θ to solve\nprojc(ψ) := argmin θ:‖R(θ)‖∗≤c\n‖θ − ψ‖2. (3)\nUnfortunately, while convex, this optimization turns out to be somewhat expensive to solve, due to a lack of smoothness Instead, we introduce a matrix Z, and constrain that Zij ≥ Rij(θ), where Rij(θ) is the bound on dependency in Thm 6 (as an equality). We add an extra quadratic term\n3\nα‖Z − Y ‖2F to the objective, where Y is an arbitrarily given matrix and α > 0 is trade-off between the smoothness and the closeness to original problem (3). The smoothed projection operator is\nprojC(ψ, Y ) := argmin (θ,Z)∈C ‖θ − ψ‖2 + α‖Z − Y ‖2F , C = {(θ, Z) : Zij ≥ Rij(θ), ‖Z‖∗ ≤ c}. (4)\nIf α = 0, this yields a solution that is identical to that of Eq. 3. However, when α = 0, the objective in Eq. 4 is not strongly convex as a function of Z, which results in a dual function which is nonsmooth, meaning it must be solved with a method like subgradient descent, with a slow convergence rate. In general, of course, the optimal point of Eq. 4 is different to that of Eq. 3. However, the main usage of the Euclidean projection operator is the projection step in the projected gradient descent algorithm for divergence minimization. In these tasks the smoothed projection operator can be directly used in the place of the non-smoothed one without changing the final result. In situations when the exact Euclidean projection is required, it can be done by initializing Y1 arbitrarily and repeating (θk+1, Yk+1)← projC(ψ, Yk), for k = 1, 2, . . . until convergence."
    }, {
      "heading" : "5.1 Dual Representation",
      "text" : "Theorem 7. Eq. 4 has the dual representation maximize σ,φ,∆,Γ g(σ, φ,∆,Γ)\nsubject to σij(a, b, c) ≥ 0, φij(a, b, c) ≥ 0, ∀(i, j) ∈ E , a, b, c , (5)\nwhere\ng(σ, φ,∆,Γ) = min Z h1(Z;σ, φ,∆,Γ) + min θ h2(θ;σ, φ)\nh1(Z;σ, φ,∆,Γ) = −tr(ZΛT ) + I(‖Z‖∗ ≤ c) + α‖Z − Y ‖2F\nh2(θ;σ, φ) = ‖θ − ψ‖2 + 1\n2 ∑ i,j∈E ∑ a,b,c ( σij(a, b, c)− φij(a, b, c) ) (θijc,a − θ ij c,b),\nin which Λij := ∆ijDij + Γ̂ij + ∑ a,b,c σij(a, b, c) + φij(a, b, c), where Γ̂ij :={\nΓij if (i, j) ∈ E −Γij if (j, i) ∈ E , and D is an indicator matrix with Dij = 0 if (i, j) ∈ E or (j, i) ∈ E , and Dij = 1 otherwise. The dual variables σij and φij are arrays of size Lj ×Li×Li for all pairs (i, j) ∈ E while ∆ and Γ are of size n× n.\nThe proof of this is in the Appendix. Here, I(·) is the indicator function with I(x) = 0 when x is true and I(x) =∞ otherwise. Being a smooth optimization problem with simple bound constraints, Eq. 5 can be solved with LBFGS-B [2]. For a gradient-based method like this to be practical, it must be possible to quickly evaluate g and its gradient. This is complicated by the fact that g is defined in terms of the minimization of h1 with respect to Z and h2 with respect to θ. We discuss how to solve these problems now. We first consider the minimization of h2. This is a quadratic function of θ and can be solved analytically via the condition that ∂∂θh2(θ;σ, φ) = 0. The closed form solution is\nθijc,a = ψ ij c,a −\n1\n4 [∑ b σij(a, b, c)− ∑ b σij(b, a, c)− ∑ b φij(a, b, c) + ∑ b φij(b, a, c) ] ∀(i, j) ∈ E , 1 ≤ a, c ≤ m.. The time complexity is linear in the size of ψ. Minimizing h1 is more involved. We assume to start that there exists an algorithm to quickly project a matrix onto the set {Z : ‖Z‖∗ ≤ c}, i.e. to solve the optimization problem of\nmin ‖Z‖∗≤c\n‖Z −A‖2F . (6)\nThen, we observe that arg minZ h1 is equal to\narg min Z −tr(ZΛT ) + I(‖Z‖∗ ≤ c) + α‖Z − Y ‖2F = arg min‖Z‖∗≤c ‖Z − (Y + 1 2α Λ)‖2F .\n4\nFor different norms ‖ · ‖∗, the projection algorithm will be different and can have a large impact on efficiency. We will discuss in the followings sections the choices of ‖ · ‖∗ and an algorithm for the ∞-norm. Finally, once h1 and h2 have been solved, the gradient of g is (by Danskin’s theorem [1])\n∂g\n∂∆ij =−DijẐij ,\n∂g\n∂Γij =Ẑji − Ẑij ,\n∂g\n∂σij(a, b, c) =\n1 2 (θ̂ijc,a − θ̂ ij c,b)− Ẑij ,\n∂g\n∂φij(a, b, c) =− ∂σij(a,b,c)g,\nwhere Ẑ and θ̂ represent the solutions to the subproblems."
    }, {
      "heading" : "5.2 Spectral Norm",
      "text" : "When ‖·‖∗ is set to the spectral norm, i.e. the largest singular value of a matrix, the projection in Eq. 6 can be performed by thresholding the singular values of A [3]. Theoretically, using spectral norm will give a tighter bound on Z than other norms (Section 3). However, computing a full singular value decomposition can be impractically slow for a graph with a large number of variables."
    }, {
      "heading" : "5.3 ∞-norm",
      "text" : "Here, we consider setting ‖ · ‖∗ to the ∞-norm, ‖A‖∞ = maxi ∑ j |Aij |, which measures the maximum l1 norm of the rows of A. This norm has several computational advantages. Firstly, to project a matrix onto a ∞-norm ball {A : ‖A∞‖ ≤ c}, we can simply project each row ai of the matrix onto the l1-norm ball {a : ‖a‖1 ≤ c}. Duchi et al. [4] provide a method linear in the number of nonzeros in a and logarithmic in the length of a. Thus, if Z is an n × n, matrix, Eq. 6 for the ∞-norm can be solved in time n2 and, for sufficiently sparse matrices, in time n log n. A second advantage of the∞-norm is that (unlike the spectral norm) projection in Eq. 6 preserves the sparsity of the matrix. Thus, one can disregard the matrix D and dual variables ∆ when solving the optimization in Theorem 7. This means that Z itself can be represented sparsely, i.e. we only need variables for those (i, j) ∈ E . These simplifications significantly improve the efficiency of projection, with some tradeoff in accuracy."
    }, {
      "heading" : "6 Projection in Divergences",
      "text" : "In this section, we want to find a distribution p(x; θ) in the fast mixing family closest to a target distribution p(x;ψ) in some divergence D(ψ, θ). The choice of divergence depends on convenience of projection, the approximate family and the inference task. We will first present a general algorithmic framework based on projected gradient descent (Algorithm 1), and then discuss the details of several previously proposed divergences [11, 3]."
    }, {
      "heading" : "6.1 General algorithm framework for divergence minimization",
      "text" : "The problem of projection in divergences is formulated as\nmin θ∈C̄ D(ψ, θ), (7)\nD(·, ·) is some divergence measure, and C̄ := {θ : ∃Z, s.t.(θ, Z) ∈ C}, where C is the feasible set in Eq. 4. Our general strategy for this is to use projected gradient descent to solve the optimization\nmin (θ,Z)∈C D(ψ, θ), (8)\nusing the joint operator to project onto C described in Section 5. For different divergences, the only difference in projection algorithm is the evaluation of the gradient ∇θD(ψ, θ). It is clear that if (θ∗, Z∗) is the solution of Eq. 8, then θ∗ is the solution of 7.\n6.2 Divergences\n5\nAlgorithm 1 Projected gradient descent for divergence projection Initialize (θ1, Z1), k ← 1. repeat θ′ ← θk − λ∇θD(ψ, θk) (θk+1, Zk+1)← projC(θ′, Zk) k ← k + 1\nuntil convergence\nIn this section, we will discuss the different choices of divergences and corresponding projection algorithms."
    }, {
      "heading" : "6.2.1 KL-divergence",
      "text" : "The KL-divergence KL(ψ‖θ) :=∑ x p(x;ψ) log p(x;ψ) p(x;θ) is arguably the optimal divergence for marginal inference because it strives to preserve the marginals of p(x; θ) and p(x;ψ). However, projection in KL-divergence is intractable here because the evaluation of the gradient ∇θKL(ψ‖θ) requires the marginals of distribution ψ."
    }, {
      "heading" : "6.2.2 Piecewise KL-divergence",
      "text" : "One tractable surrogate of KL(ψ‖θ) is the piecewise KL-divergence [3] defined over some tractable subgraphs. Here, D(ψ, θ) := maxT∈T KL(ψT ‖θT ), where T is a set of low-treewidth subgraphs. The gradient can be evaluated as ∇θD(ψ, θ) = ∇θKL(ψT∗‖θT∗) where T ∗ = arg maxT∈T KL(ψT ‖θT ). For any T in T , KL(ψT ‖θT ) and its gradient can be evaluated by the junction-tree algorithm."
    }, {
      "heading" : "6.2.3 Reversed KL-divergence",
      "text" : "The “reversed” KL-divergence KL(θ‖ψ) is minimized by mean-field methods. In general KL(θ‖ψ) is inferior to KL(ψ‖θ) for marginal inference since it tends to underestimate the support of the distribution [11]. Still, it often works well in practice. ∇θKL(θ‖ψ) can computed as ∇θKL(θ‖ψ) = ∑ x p(x; θ)(θ − ψ) ·\nf(x) ( f(x) − µ(θ) ) , which can be approxi-\nmated by samples generated from p(x; θ) [3]. In implementation, we maintain a “pool” of samples, each of which is updated by a single Gibbs step after each iteration of Algorithm 1."
    }, {
      "heading" : "7 Experiments",
      "text" : "The experiments below take two stages: first, the parameters are projected (in some divergence) and then we compare the accuracy of sampling with the resulting marginals. We focus on this second aspect. However, we provide a comparison of the computation time for various projection algorithms in Table 1, and when comparing the accuracy of sampling with a given amount of time, provide two\n6\ncurves for sampling with the original parameters, where one curve has an extra amount of sampling effort roughly approximating the time to perform projection in the reversed KL divergence.\n7.1 Synthetic MRFs\nOur first experiment follows that of [8, 3] in evaluating the accuracy of approximation methods in marginal inference. In the experiments, we approximate randomly generated MRF models with rapid-mixing distributions using the projection algorithms described previously. Then, the marginals of fast mixing approximate distributions are estimated by running a Gibbs chain on each distribution. These are compared against exact marginals as computed by the junction tree algorithm. We use the mean absolute difference of the marginals |p(Xi = 1)− q(Xi = 1)| as the accuracy measure. We compare to Naive mean-field (MF), Gibbs sampling on original parameters (Gibbs), and Loopy belief propagation (LBP). Many other methods have been compared against a similar benchmark [6, 8].\nWhile our methods are for general MRFs, we test on Ising potentials because this is a standard benchmark. Two graph topologies are used: two-dimensional 16 × 16 grids and 10 node random graphs, where each edge is independently present with probability pe ∈ {0.3, 0.5, 0.7}. Node parameters θi are uniform from [−dn, dn] with fixed field strength dn = 1.0. Edge parameters θij are uniform from [−de, de] or [0, de] to obtain mixed or attractive interactions respectively, with interaction strengths de ∈ {0, 0.5, . . . , 4}. Figure 1 shows the average marginal error at different interaction strengths. Error bars show the stan-\ndard error normalized by the number of samples, which can be interpreted as a 68.27% confidence interval. We also include time-accuracy comparisons in Figure 2. All results are averaged over 50 random trials. We run Gibbs long enough ( 106 samples) to get a fair comparison in terms of running time.\nExcept where otherwise stated, parameters are projected onto the ball {θ : ‖R(θ)‖∞ ≤ c}, where c = 2.5 is larger than the value of c = 1 suggested by the proofs above. Better results are obtained by using this larger constraint set, presumably because of looseness in the bound. For piecewise projection, grids use simple vertical and horizontal chains of treewidth either one or two. For random graphs, we randomly generate spanning trees until all edges are covered. Gradient descent uses a fixed step size of λ = 0.1. A Gibbs step is one “systematic-scan” pass over all variables between. The reversed KL divergence maintains a pool of 500 samples, each of which is updated by a single Gibbs step in each iteration.\nWe wish to compare the trade-off between computation time and accuracy represented by the choice between the use of the ∞ and spectral norms. We measure the running time on 16 × 16 grids in Table 1, and compare the accuracy in Figure 3.\nThe appendix contains results for a three-state Potts model on an 8×8 grid, as a test of the multivariate setting. Here, the intractable divergence KL(ψ‖θ) is included for reference, with the projection computed with the help of the junction tree algorithm for inference.\n7\n7.2 Berkeley binary image denoising\nThis experiment evaluates various methods for denoising binary images from the Berkeley segmentation dataset downscaled from 300 × 200 to 120 × 80. The images are binarized by setting Yi = 1 if pixel i is above the average gray scale in the image, and Yi = −1. The noisy image X is created by setting: Xi = Yi+12 i(1 − t 1.25 i ) + 1−Yi 2 t 1.25 i , in which ti is sampled uniformly from [0, 1]. For inference purposes, the conditional distribution Y is modeled as P (Y |X) ∝ exp ( β ∑ ij YiYj + α 2 ∑ i(2Xi − 1)Yi ) , where the pairwise strength β > 0 encourages smoothness. On this attractive-only Ising potential, the Swendsen-Wang method [12] mixes rapidly, and so we use the resulting samples to estimate the ground truth. The parameters α and β are heuristically chosen to be 0.5 and 0.7 respectively.\nFigure 4 shows the decrease of average marginal error. To compare running time, Euclidean and K(θ‖ψ) projection cost approximately the same as sampling 105 and 4.8× 105 samples respectively. Gibbs sampling on the original parameter converges very slowly. Sampling the approximate distributions from our projection algorithms converge quickly in less than 104 samples."
    }, {
      "heading" : "8 Conclusions",
      "text" : "We derived sufficient conditions on the parameters of an MRF to ensure fast-mixing of univariate Gibbs sampling, along with an algorithm to project onto this set in the Euclidean norm. As an example use, we explored the accuracy of samples obtained by projecting parameters and\nthen sampling, which is competitive with simple variational methods as well as traditional Gibbs sampling. Other possible applications of fast-mixing parameter sets include constraining parameters during learning."
    }, {
      "heading" : "Acknowledgments",
      "text" : "NICTA is funded by the Australian Government through the Department of Communications and the Australian Research Council through the ICT Centre of Excellence Program.\n8"
    }, {
      "heading" : "9 Appendix",
      "text" : ""
    }, {
      "heading" : "9.1 Proof of MRF Dependency Bound",
      "text" : "This section gives a proof of the bound on the dependency matrix stated in Section 4 above.\nTo start with, we observe the conditional distribution of a single variable xi when all others are fixed, which is easy to calculate. Lemma 8. The conditional probability of one variable given all others is\np(Xi = ·|X−i = x−i) = sig  ∑ k∈N(i) θik·xk  , where sig is the “multivariate sigmoid” defined as (v) = exp(v)/1T exp(v), and N(i) is the set of indices that are in a pair with i.\nNow, to compute the influence matrix, we must consider what configuration of all the variables other than xi and xj will allow a change in xj to induce the greatest change in xi (Definition 3). Lemma 9. The dependency matrix is given by\nRij = max x,y:x−j=y−j\n1 2 ‖sig(θij·xj + s)− sig(θ ij ·yj + s)‖1\ns = ∑\nk∈N(i)\\j\nθik·xk\nProof. Using the previous Lemma inside the definition of the dependency matrix (Definition 3) gives that\nRij = max x,y:x−j=y−j\n‖p(Xi = ·|x−i)− p(Xi = ·|y−i)‖TV\n= max x,y:x−j=y−j\n1 2 ‖sig( ∑ k∈N(i) θik·xk)− sig( ∑ k∈N(i) θik·yk)‖1.\nSubstituting the definition of s inside each of the sig() terms gives the result.\nWhile the previous Lemma bounds the dependency, it is not in a very convenient form. Hence, the rest of this section will apply a series of relaxations to obtain more convenient upper-bounds. The first of these is obtained by letting s be an arbitrary vector, rather than determined by θ and x.\nLemma 10. The dependency matrix for an MRF is bounded by\nRij ≤ max xj ,yj max s\n1 2 ‖sig(θij·xj + s)− sig(θ ij ·yj + s)‖1.\nThe following Lemma will be needed in what follows. Lemma 11. For vectors x, y, s,\nmax s ‖sig(x+ s)− sig(y + s)‖1 = 2|2a− 1|,\nwhere a = σ (\n1 2 range(y − x) ) . Here, range(z) is defined as maxi zi −min zi.\nNow, applying this Lemma to the previous result on the dependency matrix gives the following Theorem. Theorem 12. The dependency matrix for an MRF is bounded by\nRij ≤ 1\n4 max a,b |range(θij·a − θ ij ·b )|.\n10\nProof. The previous result gives us the bound\nRij ≤ max a,b |2σ(1 2 range(θij·a − θ ij ·b )− 1|.\nUsing the easily-proven fact that |2σ( 12x)− 1| ≤ 1 4 |x| gives the result.\nCorollary 13. The dependency matrix for an MRF is bounded by\nRij ≤ max a,b\n1 4 ‖θij·a − θ ij ·b‖1, Rij ≤ max a,b 1 2 ‖θij·a − θ ij ·b‖∞.\nProof. This follows immediately from the observations that |range(x)| ≤ ‖x‖1 and that |range(x)| ≤ 2‖x‖∞."
    }, {
      "heading" : "9.2 Proof of Dual Representation for Euclidean Projection Operator",
      "text" : "This section gives a proof of the main result of Section 5.1, as stated below.\nTheorem 14. The projection operator\nprojC(ψ, Y ) := argmin (θ,Z)∈C ‖θ − ψ‖2 + α‖Z − Y ‖2F , C = {(θ, Z) : Zij ≥ Rij(θ), ‖Z‖∗ ≤ c} (9)\nhas the dual representation of\nmaximize σ,φ,∆,Γ g(σ, φ,∆,Γ) subject to σij(a, b, c) ≥ 0, φij(a, b, c) ≥ 0, ∀(i, j) ∈ E , a, b, c , (10)\nwhere\ng(σ, φ,∆,Γ) = min Z h1(Z;σ, φ,∆,Γ) + min θ h2(θ;σ, φ)\nh1(Z;σ, φ,∆,Γ) = −tr(ZΛT ) + I(‖Z‖∗ ≤ c) + α‖Z − Y ‖2F\nh2(θ;σ, φ) = ‖θ − ψ‖2 + 1\n2 ∑ i,j∈E ∑ a,b,c ( σij(a, b, c)− φij(a, b, c) ) (θijc,a − θ ij c,b),\nin which Λij := ∆ijDij + Γ̂ij + ∑ a,b,c σij(a, b, c) + φij(a, b, c), where Γ̂ij :={\nΓij if (i, j) ∈ E −Γij if (j, i) ∈ E , and D is an indicator matrix with Dij = 0 if (i, j) ∈ E or (j, i) ∈ E , and Dij = 1 otherwise. The dual variables σij and φij are arrays of size Lj ×Li×Li for all pairs (i, j) ∈ E while ∆ and Γ are of size n× n.\nProof. Firstly, we observe that the minimization in Eq. 9 is equivalent to\nminimize θ,Z ‖θ − ψ‖2 + α‖Z − Y ‖2F\nsubject to ‖Z‖∗ ≤ c Zij = Zji, ∀(i, j) ∈ E\nZij ≥ max 1≤a,b≤m\n1 2 ‖θij.a − θ ij .b‖∞,∀(i, j) ∈ E\nDijZij = 0, 1 ≤ i, j ≤ n.\n(11)\n11\nNow, consider the Lagrangian of this problem,\nL(θ, Z, σ, φ,∆,Γ) := ‖θ − ψ‖2 + α‖Z − Y ‖2F + I(‖Z‖∗ ≤ c) − ∑\n(i,j)∈E ∑ a,b,c σij(a, b, c) ( Zij − 1 2 (θijc,a − θ ij c,b) ) − ∑ (i,j)∈E ∑ a,b,c φij(a, b, c) ( Zij + 1 2 (θijc,a − θ ij c,b) )\n− ∑ i,j ∆ijDijZij − ∑ (i,j)∈E Γij(Zij − Zji).\nHere, Γ, ∆, σij and φij , 1 ≤ i, j ≤ n are dual variables and ∑ i,j denotes ∑ 1≤i,j≤n for simplicity of notation. Here, note that L is independent of Γij , σij and φij for (i, j) 6∈ E . For convenience, one can simply set these to zero.\nIt is straightforward to verify that the problem in Eq. 11 is convex and Slater’s conditions hold. Thus, by strong duality we have the the solution of Eq. 11 is equal to\nmin θ,Z max σ≥0,φ≥0,∆,Γ L(θ, Z, σ, φ,∆,Γ) = max σ≥0,φ≥0,∆,Γ g(σ, φ,∆,Γ),\nwhere we define the dual function\ng(σ, φ,∆,Γ) = min θ,Z L(θ, Z, σ, φ,∆,Γ).\nFinally, by a simple manipulation of terms, we can see that\ng(σ, φ,∆,Γ) = min Z h1(Z;σ, φ,∆,Γ) + min θ h2(θ;σ, φ)\nh1(Z;σ, φ,∆,Γ) = −tr(ZΛT ) + I(||Z||∗ ≤ c) + α||Z − Y ||2F\nh2(θ;σ, φ) = ‖θ − ψ‖2 + 1\n2 ∑ i,j∈E ∑ a,b,c ( σij(a, b, c)− φij(a, b, c) ) (θijc,a − θ ij c,b)."
    }, {
      "heading" : "9.3 Additional Experimental Results",
      "text" : "The rest of the appendix contains extra experimental results that could not fit in the main paper.\n12\n13"
    } ],
    "references" : [ {
      "title" : "Nonlinear Programming",
      "author" : [ "Dimitri Bertsekas" ],
      "venue" : "Athena Scientific,",
      "citeRegEx" : "1",
      "shortCiteRegEx" : "1",
      "year" : 2004
    }, {
      "title" : "A limited memory algorithm for bound constrained optimization",
      "author" : [ "Richard H. Byrd", "Peihuang Lu", "Jorge Nocedal", "Ciyou Zhu" ],
      "venue" : "SIAM J. Sci. Comput.,",
      "citeRegEx" : "2",
      "shortCiteRegEx" : "2",
      "year" : 1995
    }, {
      "title" : "Projecting Ising model parameters for fast mixing",
      "author" : [ "Justin Domke", "Xianghang Liu" ],
      "venue" : "In NIPS,",
      "citeRegEx" : "3",
      "shortCiteRegEx" : "3",
      "year" : 2013
    }, {
      "title" : "Efficient projections onto the l1-ball for learning in high dimensions",
      "author" : [ "John C. Duchi", "Shai Shalev-Shwartz", "Yoram Singer", "Tushar Chandra" ],
      "venue" : "In ICML,",
      "citeRegEx" : "4",
      "shortCiteRegEx" : "4",
      "year" : 2008
    }, {
      "title" : "Matrix norms and rapid mixing for spin systems",
      "author" : [ "Martin E. Dyer", "Leslie Ann Goldberg", "Mark Jerrum" ],
      "venue" : "Ann. Appl. Probab.,",
      "citeRegEx" : "5",
      "shortCiteRegEx" : "5",
      "year" : 2009
    }, {
      "title" : "Approximate inference using conditional entropy decompositions",
      "author" : [ "Amir Globerson", "Tommi Jaakkola" ],
      "venue" : "In UAI,",
      "citeRegEx" : "6",
      "shortCiteRegEx" : "6",
      "year" : 2007
    }, {
      "title" : "A simple condition implying rapid mixing of single-site dynamics on spin systems",
      "author" : [ "Thomas P. Hayes" ],
      "venue" : "In FOCS,",
      "citeRegEx" : "7",
      "shortCiteRegEx" : "7",
      "year" : 2006
    }, {
      "title" : "Convergent message-passing algorithms for inference over general graphs with convex free energies",
      "author" : [ "Tamir Hazan", "Amnon Shashua" ],
      "venue" : "In UAI,",
      "citeRegEx" : "8",
      "shortCiteRegEx" : "8",
      "year" : 2008
    }, {
      "title" : "Probabilistic Graphical Models: Principles and Techniques",
      "author" : [ "D. Koller", "N. Friedman" ],
      "venue" : null,
      "citeRegEx" : "9",
      "shortCiteRegEx" : "9",
      "year" : 2009
    }, {
      "title" : "Expectation propagation for approximate bayesian inference",
      "author" : [ "Thomas Minka" ],
      "venue" : "In UAI,",
      "citeRegEx" : "10",
      "shortCiteRegEx" : "10",
      "year" : 2001
    }, {
      "title" : "Divergence measures and message passing",
      "author" : [ "Thomas Minka" ],
      "venue" : "Technical report,",
      "citeRegEx" : "11",
      "shortCiteRegEx" : "11",
      "year" : 2005
    }, {
      "title" : "Nonuniversal critical dynamics in monte carlo simulations",
      "author" : [ "Robert H. Swendsen", "Jian-Sheng Wang" ],
      "venue" : "Phys. Rev. Lett.,",
      "citeRegEx" : "12",
      "shortCiteRegEx" : "12",
      "year" : 1987
    }, {
      "title" : "Graphical models, exponential families, and variational inference",
      "author" : [ "Martin Wainwright", "Michael Jordan" ],
      "venue" : "Found. Trends Mach. Learn.,",
      "citeRegEx" : "13",
      "shortCiteRegEx" : "13",
      "year" : 2008
    }, {
      "title" : "Constructing free energy approximations and generalized belief propagation algorithms",
      "author" : [ "Jonathan Yedidia", "William Freeman", "Yair Weiss" ],
      "venue" : "IEEE Transactions on Information Theory,",
      "citeRegEx" : "14",
      "shortCiteRegEx" : "14",
      "year" : 2005
    } ],
    "referenceMentions" : [ {
      "referenceID" : 12,
      "context" : "There are two main classes of approximate inference algorithms: variational methods and Markov chain Monte Carlo (MCMC) algorithms [13].",
      "startOffset" : 131,
      "endOffset" : 135
    }, {
      "referenceID" : 8,
      "context" : "Among variational methods, mean-field approximations [9] are based on a “tractable” family of distributions, such as the fully-factorized distributions.",
      "startOffset" : 53,
      "endOffset" : 56
    }, {
      "referenceID" : 13,
      "context" : "Other methods, such as loopy belief propagation (LBP), generalized belief propagation [14] and expectation propagation [10] use a less restricted family of target distributions, but approximate the KL-divergence.",
      "startOffset" : 86,
      "endOffset" : 90
    }, {
      "referenceID" : 9,
      "context" : "Other methods, such as loopy belief propagation (LBP), generalized belief propagation [14] and expectation propagation [10] use a less restricted family of target distributions, but approximate the KL-divergence.",
      "startOffset" : 119,
      "endOffset" : 123
    }, {
      "referenceID" : 2,
      "context" : "This paper is inspired by a recent hybrid approach for Ising models [3].",
      "startOffset" : 68,
      "endOffset" : 71
    }, {
      "referenceID" : 2,
      "context" : "Following previous work [3], these ideas are experimentally validated via a projected gradient descent algorithm to minimize other divergences, and looking at the accuracy of the resulting marginals.",
      "startOffset" : 24,
      "endOffset" : 27
    }, {
      "referenceID" : 4,
      "context" : "[5], generalizing the work of Hayes [7].",
      "startOffset" : 0,
      "endOffset" : 3
    }, {
      "referenceID" : 6,
      "context" : "[5], generalizing the work of Hayes [7].",
      "startOffset" : 36,
      "endOffset" : 39
    }, {
      "referenceID" : 1,
      "context" : "5 can be solved with LBFGS-B [2].",
      "startOffset" : 29,
      "endOffset" : 32
    }, {
      "referenceID" : 0,
      "context" : "Finally, once h1 and h2 have been solved, the gradient of g is (by Danskin’s theorem [1]) ∂g ∂∆ij =−DijẐij , ∂g ∂Γij =Ẑji − Ẑij ,",
      "startOffset" : 85,
      "endOffset" : 88
    }, {
      "referenceID" : 2,
      "context" : "6 can be performed by thresholding the singular values of A [3].",
      "startOffset" : 60,
      "endOffset" : 63
    }, {
      "referenceID" : 3,
      "context" : "[4] provide a method linear in the number of nonzeros in a and logarithmic in the length of a.",
      "startOffset" : 0,
      "endOffset" : 3
    }, {
      "referenceID" : 10,
      "context" : "We will first present a general algorithmic framework based on projected gradient descent (Algorithm 1), and then discuss the details of several previously proposed divergences [11, 3].",
      "startOffset" : 177,
      "endOffset" : 184
    }, {
      "referenceID" : 2,
      "context" : "We will first present a general algorithmic framework based on projected gradient descent (Algorithm 1), and then discuss the details of several previously proposed divergences [11, 3].",
      "startOffset" : 177,
      "endOffset" : 184
    }, {
      "referenceID" : 2,
      "context" : "2 Piecewise KL-divergence One tractable surrogate of KL(ψ‖θ) is the piecewise KL-divergence [3] defined over some tractable subgraphs.",
      "startOffset" : 92,
      "endOffset" : 95
    }, {
      "referenceID" : 10,
      "context" : "In general KL(θ‖ψ) is inferior to KL(ψ‖θ) for marginal inference since it tends to underestimate the support of the distribution [11].",
      "startOffset" : 129,
      "endOffset" : 133
    }, {
      "referenceID" : 2,
      "context" : "∇θKL(θ‖ψ) can computed as ∇θKL(θ‖ψ) = ∑ x p(x; θ)(θ − ψ) · f(x) ( f(x) − μ(θ) ) , which can be approximated by samples generated from p(x; θ) [3].",
      "startOffset" : 142,
      "endOffset" : 145
    }, {
      "referenceID" : 7,
      "context" : "Our first experiment follows that of [8, 3] in evaluating the accuracy of approximation methods in marginal inference.",
      "startOffset" : 37,
      "endOffset" : 43
    }, {
      "referenceID" : 2,
      "context" : "Our first experiment follows that of [8, 3] in evaluating the accuracy of approximation methods in marginal inference.",
      "startOffset" : 37,
      "endOffset" : 43
    }, {
      "referenceID" : 5,
      "context" : "Many other methods have been compared against a similar benchmark [6, 8].",
      "startOffset" : 66,
      "endOffset" : 72
    }, {
      "referenceID" : 7,
      "context" : "Many other methods have been compared against a similar benchmark [6, 8].",
      "startOffset" : 66,
      "endOffset" : 72
    }, {
      "referenceID" : 0,
      "context" : "25 i , in which ti is sampled uniformly from [0, 1].",
      "startOffset" : 45,
      "endOffset" : 51
    }, {
      "referenceID" : 11,
      "context" : "On this attractive-only Ising potential, the Swendsen-Wang method [12] mixes rapidly, and so we use the resulting samples to estimate the ground truth.",
      "startOffset" : 66,
      "endOffset" : 70
    }, {
      "referenceID" : 0,
      "context" : "References [1] Dimitri Bertsekas.",
      "startOffset" : 11,
      "endOffset" : 14
    }, {
      "referenceID" : 1,
      "context" : "[2] Richard H.",
      "startOffset" : 0,
      "endOffset" : 3
    }, {
      "referenceID" : 2,
      "context" : "[3] Justin Domke and Xianghang Liu.",
      "startOffset" : 0,
      "endOffset" : 3
    }, {
      "referenceID" : 3,
      "context" : "[4] John C.",
      "startOffset" : 0,
      "endOffset" : 3
    }, {
      "referenceID" : 4,
      "context" : "[5] Martin E.",
      "startOffset" : 0,
      "endOffset" : 3
    }, {
      "referenceID" : 5,
      "context" : "[6] Amir Globerson and Tommi Jaakkola.",
      "startOffset" : 0,
      "endOffset" : 3
    }, {
      "referenceID" : 6,
      "context" : "[7] Thomas P.",
      "startOffset" : 0,
      "endOffset" : 3
    }, {
      "referenceID" : 7,
      "context" : "[8] Tamir Hazan and Amnon Shashua.",
      "startOffset" : 0,
      "endOffset" : 3
    }, {
      "referenceID" : 8,
      "context" : "[9] D.",
      "startOffset" : 0,
      "endOffset" : 3
    }, {
      "referenceID" : 9,
      "context" : "[10] Thomas Minka.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 10,
      "context" : "[11] Thomas Minka.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 11,
      "context" : "[12] Robert H.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 12,
      "context" : "[13] Martin Wainwright and Michael Jordan.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 13,
      "context" : "[14] Jonathan Yedidia, William Freeman, and Yair Weiss.",
      "startOffset" : 0,
      "endOffset" : 4
    } ],
    "year" : 2014,
    "abstractText" : "Markov chain Monte Carlo (MCMC) algorithms are simple and extremely powerful techniques to sample from almost arbitrary distributions. The flaw in practice is that it can take a large and/or unknown amount of time to converge to the stationary distribution. This paper gives sufficient conditions to guarantee that univariate Gibbs sampling on Markov Random Fields (MRFs) will be fast mixing, in a precise sense. Further, an algorithm is given to project onto this set of fast-mixing parameters in the Euclidean norm. Following recent work, we give an example use of this to project in various divergence measures, comparing univariate marginals obtained by sampling after projection to common variational methods and Gibbs sampling on the original parameters.",
    "creator" : "LaTeX with hyperref package"
  }
}