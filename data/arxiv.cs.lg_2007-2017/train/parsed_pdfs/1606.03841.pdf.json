{
  "name" : "1606.03841.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "Efficient Learning with a Family of Nonconvex Regularizers by Redistributing Nonconvexity",
    "authors" : [ "Quanming Yao", "James T. Kwok" ],
    "emails" : [ "QYAOAA@CSE.UST.HK", "JAMESK@CSE.UST.HK" ],
    "sections" : [ {
      "heading" : "1. Introduction",
      "text" : "Risk minimization is fundamental to machine learning. It admits a tradeoff between the empirical loss and regularization as:\nmin x F (x) ≡ f(x) + g(x), (1)\nwhere x is the model parameter, f is the loss and g is the regularizer. The choice of regularizers is important and application-specific, and is often the crux to obtain good prediction performance. Popular examples include the sparsity-inducing regularizers, which have been commonly used in image processing (Beck and Teboulle, 2009; Mairal et al., 2009; Jenatton et al., 2011) and highdimensional feature selection (Tibshirani et al., 2005; Jacob et al., 2009; Liu and Ye, 2010); and the low-rank regularizer in matrix and tensor learning, with good empirical performance on tasks such as recommender systems (Candès and Recht, 2009; Mazumder et al., 2010) and visual data analysis (Liu et al., 2013; Lu et al., 2014).\nMost of these regularizers are convex. Well-known examples include the `1-regularizer for sparse coding (Donoho, 2006), and the nuclear norm regularizer in low-rank matrix learning\nc©— Quanming Yao and James T. Kwok.\nar X\niv :1\n60 6.\n03 84\n1v 3\n[ m\nat h.\nO C\n] 1\n3 Fe\n(Candès and Recht, 2009). Besides having nice theoretical guarantees, convex regularizers also allow easy optimization. Popular optimization algorithms in machine learning include the proximal algorithm (Parikh and Boyd, 2013), Frank-Wolfe (FW) algorithm (Jaggi, 2013), the alternating direction method of multipliers (ADMM) (Boyd et al., 2011), stochastic gradient descent and its variants (Bottou, 1998; Xiao and Zhang, 2014). Many of these are efficient, scalable, and have sound convergence properties.\nHowever, convex regularizers often lead to biased estimation. For example, in sparse coding, the solution obtained by the `1-regularizer is often not as sparse and accurate (Zhang, 2010b). In lowrank matrix learning, the estimated rank obtained with the nuclear norm regularizer is often much higher (Mazumder et al., 2010). To alleviate this problem, a number of nonconvex regularizers have been recently proposed (Geman and Yang, 1995; Fan and Li, 2001; Candès et al., 2008; Zhang, 2010a; Trzasko and Manduca, 2009). As can be seen from Table 1, they are all (i) nonsmooth at zero, which encourage a sparse solution; and (ii) concave, which place a smaller penalty than the `1-regularizer on features with large magnitudes. Empirically, these nonconvex regularizers usually outperform convex regularizers.\nEven with a convex loss, the resulting nonconvex problem is much harder to optimize. One can use general-purpose nonconvex optimization solvers such as the concave-convex procedure (Yuille and Rangarajan, 2002). However, the subproblem in each iteration can be as expensive as the original problem, and the concave-convex procedure is thus often slow in practice (Gong et al., 2013; Zhong and Kwok, 2014).\nRecently, the proximal algorithm has also been extended for nonconvex problems. Examples include the NIPS (Sra, 2012), IPiano (Ochs et al., 2014), UAG (Ghadimi and Lan, 2016), GIST (Gong et al., 2013), IFB (Bot et al., 2016), and nmAPG (Li and Lin, 2015). Specifically, NIPS, IPiano and UAG allow f in (1) to be Lipschitz smooth (possibly nonconvex) but g has to be convex; while GIST, IFB and nmAPG further allow g to be nonconvex. The current state-of-the-art is nmAPG. However, efficient computation of the underlying proximal operator is only possible for simple nonconvex regularizers. When the regularizer is complicated, such as the nonconvex versions of the fused lasso and overlapping group lasso regularizers (Zhong and Kwok, 2014),\nthe corresponding proximal step has to be solved numerically and is again expensive. Another approach is by using the proximal average (Zhong and Kwok, 2014), which computes and averages the proximal step of each underlying regularizer. However, because the proximal step is only approximate, convergence is usually slower than typical applications of the proximal algorithm (Li and Lin, 2015).\nWhen f is smooth, there are endeavors to extend other algorithms from convex to nonconvex optimization. For the global consensus problem, standard ADMM converges only when g is convex (Hong et al., 2016). When g is nonconvex, convergence of ADMM is only established for problems of the form minx,y f(x) + g(y) : y = Ax, where matrix A has full row rank (Li and Pong, 2015). The convergence of ADMM in more general cases is an open issue. More recently, the stochastic variance reduced gradient (SVRG) algorithm (Johnson and Zhang, 2013), which is a variant of the popular stochastic gradient descent with reduced variance in the gradient estimates, has also been extended for problems with nonconvex f . However, the regularizer g is still required to be convex (Reddi et al., 2016a; Zhu and Hazan, 2016).\nSometimes, it is desirable to have a nonsmooth loss f . For example, the absolute loss is more robust to outliers than the square loss, and has been popularly used in applications such as image denoising (Yan, 2013), robust dictionary learning (Zhao et al., 2011) and robust PCA (Candès et al., 2011). The resulting optimization problem becomes more challenging. When both f and g are convex, ADMM is often the main optimization tool for problem (1) (He and Yuan, 2012). However, when either f or g is nonconvex, ADMM no longer guarantees convergence. Besides a nonconvex g, we may also want to use a nonconvex loss f , such as `0-norm (Yan, 2013) and capped-`1 norm (Sun et al., 2013), as they are more robust to outliers and can obtain better performance. However, when f is nonsmooth and nonconvex, none of the above-mentioned algorithms (i.e., proximal algorithms, FW algorithms, ADMM, and SVRG) can be used. As a last resort, one can use more general nonconvex optimization approaches such as convex concave programming (CCCP) (Yuille and Rangarajan, 2002). However, they are slow in general.\nIn this paper, we first consider the case where the loss function f is smooth (possibly nonconvex) and the regularizer g is nonconvex. We propose to handle nonconvex regularizers by reusing the abundant repository of efficient convex algorithms originally designed for convex regularizers. The key is to shift the nonconvexity associated with the nonconvex regularizer to the loss function, and transform the nonconvex regularizer to a familiar convex regularizer. To illustrate the practical usefulness of this convexification scheme, we show how it can be used with popular optimization algorithms in machine learning. For example, for the proximal algorithm, the resultant proximal step can be much easier after transformation. Specifically, for the nonconvex tree-structured lasso and nonconvex sparse group lasso, we show that the corresponding proximal steps have closedform solutions on the transformed problems, but not on the original ones. For the nonconvex total variation problem, though there is no closed-form solution for the proximal step before and after the transformation, we show that the proximal step is still cheaper and easier for optimization after the transformation. To allow further speedup, we propose a proximal algorithm variant that allows the use of inexact proximal steps with convex g when it has no closed-form proximal step solution. For the FW algorithm, we consider its application to nonconvex low-rank matrix learning problems, and propose a variant with guaranteed convergence to a critical point of the nonconvex problem. For SVRG in stochastic optimization and ADMM in consensus optimization, we show that these algorithms have convergence guarantees on the transformed problems but not on the original ones.\nWe further consider the case where f is also nonconvex and nonsmooth (and g is nonconvex). We demonstrate that problem (1) can be transformed to an equivalent problem with a smooth loss and convex regularizer using our proposed idea. However, as the proximal step with the transformed regularizer has to be solved numerically and exact proximal step is required, usage with the proximal algorithm may not be efficient. We show that this problem can be addressed by the proposed inexact proximal algorithm. Finally, in the experiments, we demonstrate the above-mentioned advantages of optimizing the transformed problems instead of the original ones on various tasks, and show that running algorithms on the transformed problems can be much faster than the state-of-art on the original ones.\nThe rest of the paper is organized as follows. Section 2 provides a review on the related works. The main idea for problem transformation is presented in Section 3, and its usage with various algorithms are discussed in Section 4. Experimental results are shown in Section 5, and the last section gives some concluding remarks. All the proofs are in Appendix A. Note that this paper extends a shorter version published in the proceedings of the International Conference of Machine Learning (Yao and Kwok, 2016)."
    }, {
      "heading" : "Notation",
      "text" : "We denote vectors and matrices by lowercase and uppercase boldface letters, respectively. For a vector x ∈ Rd, ‖x‖2 = ( ∑d i=1 |xi|2)1/2 is its `2-norm, Diag(x) returns a diagonal matrixX ∈ Rd×d with Xii = xi. For a matrix X ∈ Rm×n (where m ≤ n without loss of generality), its nuclear norm is ‖X‖∗ = ∑m i=1 σi(X), where σi(X)’s are the singular values of X , and its Frobenius norm\nis ‖X‖F = √∑m\ni=1 ∑n j=1X 2 ij , and ‖X‖∞ = maxi,j |Xij |. For a square matrix X , X ∈ S+\nindicates it is a positive semidefinite. For two matrices X and Y , 〈X,Y 〉 = ∑\ni,j XijYij . For a smooth function f , ∇f(x) is its gradient at x. For a convex but nonsmooth f , ∂f(x) = {u : f(y) ≥ f(x) + 〈u, y − x〉} is its subdifferential at x, and g ∈ ∂f(x) is a subgradient."
    }, {
      "heading" : "2. Related Works",
      "text" : "In this section, we review some popular algorithms for solving (1). Here, f is assumed to be Lipschitz smooth."
    }, {
      "heading" : "2.1 Convex-Concave Procedure (CCCP)",
      "text" : "The convex-concave procedure (CCCP) (Yuille and Rangarajan, 2002; Lu, 2012) is a popular and general solver for (1). It assumes thatF can be decomposed as a difference of convex (DC) functions (Hiriart-Urruty, 1985), i.e., F (x) = F̃ (x) + F̂ (x) where F̃ is convex and F̂ is concave. In each CCCP iteration, F̂ is linearized at xt, and xt+1 is generated as\nxt+1 = arg min x F̃ (x) + F̂ (xt)− (x− xt)>st, (2)\nwhere st ∈ ∂[−F̂ (xt)] is a subgradient. Note that as the last two terms are linear, (2) is a convex problem and can be easier than the original problem F .\nHowever, CCCP is expensive as (2) needs to be exactly solved. Sequential convex programming (SCP) (Lu, 2012) improves its efficiency when F is in form of (1). It assumes that f is L-Lipschitz smooth (possibly nonconvex); while g can be nonconvex, but admits a DC decomposition as g(x) =\nς̃(x) + ς̂(x). It then generates xt+1 as\nxt+1 = arg min x f(xt) + (x− xt)>∇f(xt) +\nL 2 ‖x− xt‖22 + ς̃(x) + ς̂(xt)− (x− xt)>st\n= arg min x\n1 2 ‖x− xt − st + 1 L ∇f(xt)‖22 + ς̃(x), (3)\nwhere st ∈ ∂ (−ς̂(xt)). When ς̃ is simple, (3) has a closed-form solution, and SCP can be faster than CCCP. However, its convergence is still slow in general (Gong et al., 2013; Zhong and Kwok, 2014; Li and Lin, 2015)."
    }, {
      "heading" : "2.2 Proximal Algorithm",
      "text" : "The proximal algorithm (Parikh and Boyd, 2013) has been popularly used for optimization problems of the form in (1). Let f be convex and L-Lipschitz smooth, and g is convex. The proximal algorithm generates iterates {xt} as\nxt+1 = arg min x f(xt) + (x− xt)>∇f(xt) +\nL 2 ‖x− xt‖22 + g(x)\n= prox 1 L g\n( xt − 1\nL ∇f(xt)\n) ,\nwhere proxg(z) ≡ arg minx 12‖x − z‖ 2 2 + g(x) is the proximal step, The proximal algorithm converges at a rate of O(1/T ). This can be further accelerated to O(1/T 2) by modifying the generation of {xt} as (Beck, 2009; Nesterov, 2013):\nyt = xt + αt−1 − 1\nαt (xt − xt−1),\nxt+1 = prox 1 L g\n( yt − 1\nL ∇f(yt)\n) ,\nwhere α0 = α1 = 1 and αt+1 = 12( √\n4α2t + 1 + 1). Recently, the proximal algorithm has been extended to nonconvex optimization. In particular, NIPS (Sra, 2012), IPiano (Ochs et al., 2014) and UAG (Ghadimi and Lan, 2016) allow f to be nonconvex, while g is still required to be convex. GIST (Gong et al., 2013), IFB (Bot et al., 2016) and nmAPG (Li and Lin, 2015) further remove this restriction and allow g to be nonconvex. It is desirable that the proximal step has a closed-form solution. This is true for many convex regularizers such as the lasso regularier (Tibshirani, 1996), tree-structured lasso regularizer (Liu and Ye, 2010; Jenatton et al., 2011) and sparse group lasso regularizer (Jacob et al., 2009). However, when g is nonconvex, such solution only exists for some simple g, e.g., nonconvex lasso regularizer (Gong et al., 2013), and usually do not exist for more general cases, e.g., nonconvex tree-structured lasso regularizer (Zhong and Kwok, 2014).\nOn the other hand, Zhong and Kwok (2014) used proximal average (Bauschke et al., 2008) to handle complicate g which is in the form g(x) = ∑K i=1 µigi(x), where each gi has a simple proximal step. The iterates are generated as\nxt+1 = K∑ i=1 µi · proxµi L gi ( xt − 1 L ∇f(xt) ) / K∑ i=1 µi.\nEach of the constituent proximal steps proxµi L gi (·) can be computed inexpensively, and thus the per-iteration complexity is low. It only converges to an approximate solution to proxg(z), but an approximation guarantee is provided. However, empirically, the convergence can be slow."
    }, {
      "heading" : "2.3 Frank-Wolfe (FW) Algorithm",
      "text" : "The FW algorithm (Frank and Wolfe, 1956) is used for solving optimization problems of the form\nmin x f(x) : x ∈ C, (4)\nwhere f is Lipschitz-smooth and convex, and C is a compact convex set. Recently, it has been popularly used in machine learning (Jaggi, 2013). In each iteration, the FW algorithm generates the next iterate xt+1 as\nst = arg min s∈C\ns>∇f(xt), (5)\nγt = arg min γ∈[0,1]\nf((1− γ)xt + γst), (6)\nxt+1 = (1− γt)xt + γtst. (7)\nHere, (5) is a linear subproblem which can often be easily solved; (6) performs line search, and the next iterate xt+1 is generated from a convex combination of xt and st in (7). The FW algorithm has a convergence rate of O(1/T ) (Jaggi, 2013).\nIn this paper, we will focus on using the FW algorithm to learn a low-rank matrix X ∈ Rm×n. Without loss of generality, we assume that m ≤ n. Let σi(X)’s be the singular values of X . The nuclear norm of X , ‖X‖∗ = ∑m i=1 σi(X), is the tightest convex envelope of rank(X), and is often used as a low-rank regularizer (Candès and Recht, 2009). The low-rank matrix learning problem can be written as\nmin X\nf(X) + µ‖X‖∗, (8)\nwhere f is the loss. For example, in matrix completion (Candès and Recht, 2009),\nf(X) = 1\n2 ‖PΩ(X −O)‖2F , (9)\nwhere O is the observed incomplete matrix, Ω ∈ {0, 1}m×n contains indices to the observed entries in O, and [PΩ(A)]ij = Aij if Ωij = 1, and 0 otherwise.\nThe FW algorithm for this nuclear norm regularized problem is shown in Algorithm 1 (Zhang et al., 2012). Let the iterate at the tth iteration be Xt. As in (5), the following linear subproblem has to be solved (Jaggi, 2013):\nmin S:‖S‖∗≤1\n〈S,∇f(Xt)〉. (10)\nThis can be obtained from the rank-one SVD of ∇f(Xt) (step 3). Similar to (6), line search is performed at step 4. As a rank-one matrix is added intoXt in each iteration, it is convenient to write Xt as\nt∑ i=1 uiv > i = UtV > t , (11)\nwhere Ut = [u1, . . . , ut] and Vt = [v1, . . . , vt]. The FW algorithm has a convergence rate of O(1/T ) (Jaggi, 2013). To make it empirically faster, Algorithm 1 also performs optimization at step 6 (Laue, 2012; Zhang et al., 2012). Substituting ‖X‖∗ = minX=UV > 12 ( ‖U‖2F + ‖V ‖2F ) (Srebro et al., 2004) into (8), we have the following local optimization problem:\nmin U,V\nf(UV >) + µ\n2 (‖U‖2F + ‖V ‖2F ). (12)\nThis can be solved by standard solvers such as L-BFGS (Nocedal and Wright, 2006).\nAlgorithm 1 Frank-Wolfe algorithm for problem (8) with f convex (Zhang et al., 2012). 1: U1 = [ ] and V1 = [ ]; 2: for t = 1 . . . T do 3: [ut, st, vt] = rank1SVD(∇f(Xt)); 4: [αt, βt] = arg minα≥0,β≥0 f(αXt + βutv > t ) + µ(α‖Xt‖∗ + β);\n5: Ūt = [√ αtUt; √ βtut ] and V̄t = [√ αtVt; √ βtvt ] ; 6: obtain [Ut+1, Vt+1] from (12), using Ūt and V̄t for warm-start; // Xt+1 = Ut+1V >t+1 7: end for 8: return UT+1 and VT+1."
    }, {
      "heading" : "2.4 Alternating Direction Method of Multipliers (ADMM)",
      "text" : "ADMM is a simple but powerful algorithm first introduced in the 1970s (Glowinski and Marroco, 1975). Recently, it has been popularly used in diverse fields such as machine learning, data mining and image processing (Boyd et al., 2011). It can be used to solve optimization problems of the form\nmin x,y f(x) + g(y) : Ax+By = c, (13)\nwhere f, g are convex functions, and A,B (resp. c) are constant matrices (resp. vector) of appropriate sizes. Consider the augmented Lagrangian L(x, y, u) = f(x) + g(y) + u>(Ax + By − c) + τ2‖Ax + By − c‖ 2 2, where u is the vector of Lagrangian multipliers, and τ > 0 is a penalty parameter. At the tth iteration of ADMM, the values of x, y and u are updated as\nxt+1 = arg min x L(x, yt, ut), (14) yt+1 = arg min y L(xt+1, y, ut), (15) ut+1 = ut + τ(Axt+1 +Byt+1 − c).\nBy minimizing L(x, y, uk) w.r.t. x and y in an alternating manner ((14) and (15)), ADMM can more easily decompose the optimization problem when f, g are separable.\nIn this paper, we will focus a special case of (13), namely, the consensus optimization problem:\nmin y,x1,...,xM M∑ i=1 fi(x i) + g(y) : x1 = · · · = xM = y, (16)\nHere, each fi is Lipschitz-smooth, xi is the variable in the local objective fi, and y is the global consensus variable. This type of problems is often encountered in machine learning, signal\nprocessing and wireless communication (Bertsekas and Tsitsiklis, 1989; Boyd et al., 2011). For example, in regularized risk minimization, y is the model parameter, fi is the regularized risk functional defined on data subset i, and g is the regularizer. When fi is smooth and g is convex, ADMM converges to a critical point of (16) (Hong et al., 2016). However, when g is nonconvex, its convergence is still an open issue."
    }, {
      "heading" : "3. Shifting Nonconvexity from Regularizer to Loss",
      "text" : "In recent years, a number of nonconvex regularizers have been proposed. Examples include the Geman penalty (GP) (Geman and Yang, 1995), log-sum penalty (LSP) (Candès et al., 2008) and Laplace penalty (Trzasko and Manduca, 2009). In general, learning with nonconvex regularizers is much more difficult than learning with convex regularizers. In this section, we show how to move the nonconvex component from the nonconvex regularizers to the loss function. Existing algorithms can then be reused to learn with the convexified regularizers.\nFirst, we make the following standard assumptions on (1).\nA1. F is bounded from below and lim‖x‖2→∞ F (x) =∞; A2. f is L-Lipschitz smooth (i.e., ‖∇f(x)−∇f(y)‖2 ≤ L‖x− y‖2), but possibly nonconvex.\nLet κ be a function that is concave, non-decreasing, ρ-Lipschitz smooth with κ′ nondifferentiable at finite points, and κ(0) = 0. With the exception of the capped-`1 norm penalty (Zhang, 2010a) and `0-norm regularizer, all regularizers in Table 1 satisfy requirements on κ. We consider g of the following forms.\nC1. g(x) = ∑K\ni=1 µigi(x), where µi ≥ 0,\ngi(x) = κ(‖Aix‖2), (17)\nand Ai is a matrix. When κ is the identity function, g(x) reduces to the convex regularizer∑K i=1 µi‖Aix‖2. By using different Ai’s, g becomes various structured sparsity regularizers such as the group lasso (Jacob et al., 2009), fused lasso (Tibshirani et al., 2005), and graphical lasso (Jacob et al., 2009).\nC2. g(X) = µ ∑m\ni=1 κ(σi(X)), where X is a matrix and µ ≥ 0. When κ is the identity function, g reduces to the nuclear norm.\nFirst, consider g in C1. Rewrite each nonconvex gi in (17) as\ngi(x) = ḡi(x) + κ0‖Aix‖2, (18)\nwhere κ0 = κ′(0), and ḡi(x) = κ(‖Aix‖2) − κ0‖Aix‖2. Obviously, κ0‖Aix‖2 is convex but nonsmooth. The following shows that ḡi, though nonconvex, is concave and Lipschitz smooth. In the sequel, a function with a bar on top (e.g., f̄ ) denotes that it is smooth; whereas a function with breve (e.g., ğ) denotes that it may be nonsmooth.\nProposition 1 κ(‖z‖2)− κ0‖z‖2 is concave and 2ρ-Lipschitz smooth.\nCorollary 2 ḡi is concave and Lipschitz smooth with modulus L̄i = 2ρ‖Ai‖F .\nCorollary 3 g(x) can be decomposed as ḡ(x) + ğ(x), where ḡ(x) ≡ ∑K\ni=1 µiḡi(x) is concave and Lipschitz-smooth, while ğ(x) ≡ κ0 ∑K i=1 µi‖Aix‖2 is convex but nonsmooth.\nRemark 4 When Ai = Diag(ei), where ei is the unit vector for dimension i, ‖Aix‖2 = |xi| and\ng(x) = d∑ i=1 µiκ(‖Aix‖2) = d∑ i=1 µiκ(|xi|). (19)\nUsing Corollary 3, g can be decomposed as ḡ(x) + ğ(x), where ḡ(x) ≡ ∑d\ni=1 µi(κ(|xi|)− κ0|xi|) is concave and 2ρ-Lipschitz smooth, while ğ(x) ≡ κ0 ∑d i=1 µi|xi| is convex and nonsmooth. When d = 1 and µ1 = 1, an illustration of g(x) = κ(|x|), ḡ(x) = κ(|x|) − κ0|x| and ğ(x) = κ0|x| for the various nonconvex regularizers is shown in Figure 1. When κ is the identity function and µ1 = · · · = µm = µ, g in (19) reduces to the lasso regularizer µ‖x‖1.\nUsing Corollary 3, problem (1) can then be rewritten as\nmin x f̄(x) + ğ(x), (20)\nwhere f̄(x) ≡ f(x) + ḡ(x). Note that f̄ (which can be viewed as an augmented loss) is Lipschitz smooth while ğ (viewed as a convexified regularizer) is convex but possibly nonsmooth. In other words, nonconvexity is shifted from the regularizer g to the loss f , while ensuring that the augmented loss is smooth.\nWhen X is a matrix, similar to Corollary 3, the following Proposition 5 holds for g in C2.\nProposition 5 Any g in C2 can be decomposed as ḡ(X) + ğ(X), where\nḡ(X) ≡ µ m∑ i=1 κ(σi(X))− µκ0‖X‖∗ (21)\nis concave and 2ρ-Lipschitz smooth, while ğ(X) ≡ κ0‖X‖∗ is convex and nonsmooth.\nSince ḡ is concave and ğ is convex, the nonconvex regularizer g = ğ− (−ḡ) can be viewed as a difference of convex functions (DC) (Hiriart-Urruty, 1985). Lu (2012); Gong et al. (2013); Zhong and Kwok (2014) also relied on DC decompositions of the nonconvex regularizer. However, they do not utilize this in the computational procedures, while we use the DC decomposition to simplify the regularizers. As will be seen, though the DC decomposition of a nonconvex function is not unique in general, the particular one proposed here is crucial for efficient optimization."
    }, {
      "heading" : "4. Example Use Cases",
      "text" : "In this section, we provide concrete examples to show how the proposed convexification scheme can be used with various optimization algorithms. An overview is summarized in Table 2."
    }, {
      "heading" : "4.1 Proximal Algorithms",
      "text" : "In this section, we provide example applications on using the proximal algorithm for nonconvex structured sparse learning. The proximal algorithm has been commonly used for learning with convex regularizers (Parikh and Boyd, 2013). With a nonconvex regularizer, the underlying proximal step becomes much more challenging. Gong et al. (2013); Li and Lin (2015) and Bot et al. (2016) extended proximal algorithm to simple nonconvex g, but cannot handle more complicated nonconvex regularizers such as the tree-structured lasso regularizer (Liu and Ye, 2010; Schmidt et al., 2011), sparse group lasso regularizer (Jacob et al., 2009) and total variation regularizer (Nikolova, 2004). Using the proximal average (Bauschke et al., 2008), Zhong and Kwok (2014) can handle nonconvex regularizers of the form g = ∑K i=1 µigi, where each gi is simple. However, the solutions obtained are only approximate. General nonconvex optimization techniques such as the concave-convex procedure (CCCP) (Yuille and Rangarajan, 2002) or its variant sequential convex programming (SCP) (Lu, 2012) can also be used, though they are slow in general (Gong et al., 2013; Zhong and Kwok, 2014).\nUsing the proposed transformation, one only needs to solve the proximal step of a standard convex regularizer instead of that of a nonconvex regularizer. This allows reuse of existing solutions for the proximal step and is much less expensive. As proximal algorithms have the same\nconvergence guarantee for convex and nonconvex f (Gong et al., 2013; Li and Lin, 2015), solving the transformed problem can be much faster. The following gives some specific examples."
    }, {
      "heading" : "4.1.1 NONCONVEX SPARSE GROUP LASSO",
      "text" : "In sparse group lasso, the feature vector x is divided into groups. Assume that group Gj contains dimensions in x that group j contains. Let [ xGj ] i\n= xi if i ∈ Gj , and 0 otherwise. Given training samples {(a1, y1), . . . , (aN , yN )}, (convex) sparse group lasso is formulated as (Jacob et al., 2009):\nmin x N∑ i=1 `(yi, a > i x) + λ‖x‖1 + K∑ j=1 µj‖xGj‖2, (22)\nwhere ` is a smooth loss, and K is the number of (non-overlapping) groups. For the nonconvex extension, the regularizer becomes\ng(x) = λ d∑ i=1 κ(|xi|) + K∑ j=1 µjκ(‖xGj‖2). (23)\nUsing Corollary 3 and Remark 4, the convexified regularizer is ğ(x) = κ0(λ‖x‖1 +∑K j=1 µj‖xGj‖2). Its proximal step can be easily computed by the algorithm in (Yuan et al., 2011). Specifically, the proximal operator of ğ can be obtained by computing proxµj‖·‖2(proxλ‖·‖1(xGj )) for each group separately. This can then be used with any proximal algorithm that can handle nonconvex objectives (as f̄ is nonconvex). In particular, we will adopt the state-of-the-art nonmontonic APG (nmAPG) algorithm (Li and Lin, 2015) (shown in Algorithm 2). Note that nmAPG cannot be directly used with the nonconvex regularizer g in (23), as the corresponding proximal step has no inexpensive closed-form solution.\nAs mentioned in Section 3, the proposed decomposition of the nonconvex regularizer g can be regarded as a DC decomposition, which is not unique in general. For example, we might try to add a quadratic term to convexify the nonconvex regularizer. Specifically, we can decompose g(x) in (23) as ς̃(x) + ς̂(x), where\nς̃(x) = λ d∑ i=1 ( κ(|xi|) + ρ 2 x2i ) + K∑ j=1 µj ( κ(‖xGj‖2) + ρ 2 ‖xGj‖22 ) , (24)\nand ς̂(x) = −ρ2 ∑K\nj=1(µj + λ)‖xGj‖22. It can be easily shown that ς̂ is concave, and Proposition 6 shows that ς̃ is convex. Thus, F can be transformed as F (x) = f̄(x) + ς̃(x), where f̄(x) = f(x) + ς̂(x) is Lipschitz-smooth, and ς̃ is convex but nonsmooth. However, the proximal step associated with ς̃ has no simple closed-form solution.\nProposition 6 κ(‖ · ‖2) + ρ2‖ · ‖ 2 2 is convex."
    }, {
      "heading" : "4.1.2 NONCONVEX TREE-STRUCTURED GROUP LASSO",
      "text" : "In (convex) tree-structured group lasso (Liu and Ye, 2010; Jenatton et al., 2011), the dimensions in x are organized as nodes in a tree, and each group corresponds to a subtree. The regularizer is of the form ∑K j=1 λj‖xGj‖2. Interested readers are referred to (Liu and Ye, 2010) for details.\nAlgorithm 2 Nonmonotonic APG (nmAPG) (Li and Lin, 2015). 1: Initialize z1 = x1 = x0, α0 = 0, α1 = 1, η ∈ [0, 1), c1 = F (x1), q1 = 1, and stepsize τ > L̄, δ ∈ (0, τ − L̄);\n2: for t = 1, . . . , T do 3: yt = xt +\nαt−1 αt (zt − xt) + αt−1−1αt (xt − xt−1); 4: zt+1 = prox 1\nτ ğ(yt − 1 τ∇f̄(yt));\n5: if F (zt+1) ≤ ct − δ2‖zt+1 − yt‖ 2 2 then 6: xt+1 = zt+1; 7: else 8: vt+1 = prox 1\nτ ğ(xt − 1 τ∇f̄(xt));\n9: xt+1 = { zt+1 F (zt+1) ≤ F (vt+1) vt+1 otherwise ;\n10: end if 11: αt+1 = 1 2( √\n4α2t + 1 + 1); 12: qt+1 = ηqt + 1; 13: ct+1 =\nηqtct+F (xt+1) qt+1 ; 14: end for 15: return xT+1;\nFor the nonconvex extension, g(x) becomes ∑K\nj=1 λjκ(‖xGj‖2). Again, there is no closedform solution of its proximal step. On the other hand, the convexified regularizer is ğ(x) ≡ κ0 ∑K\nj=1 λj‖xGj‖2. As shown in (Liu and Ye, 2010), its proximal step can be computed efficiently by processing all the groups once in some appropriate order."
    }, {
      "heading" : "4.1.3 NONCONVEX TOTAL VARIATION (TV) REGULARIZER",
      "text" : "In an image, nearby pixels are usually strongly correlated. The TV regularizer captures such behavior by assuming that changes between nearby pixels are small. Given an image X ∈ Rm×n, the TV regularizer is defined as TV(X) = ‖DvX‖1 + ‖XDh‖1 (Nikolova, 2004), Dv =−1 1. . . . . .\n−1 1\n ∈ R(m−1)×m and Dh =  −1 1 . . . . . . −1\n1  ∈ Rn×(n−1) are the horizontal and vertical partial derivative operators, respectively. Thus, it is popular on image processing problems, such as image denoising and deconvolution (Nikolova, 2004; Beck and Teboulle, 2009).\nAs in previous sections, the nonconvex extension of TV regularizer can be defined as\nm−1∑ i=1 m∑ j=1 κ (∣∣∣[DvX]ij∣∣∣)+ n∑ i=1 n−1∑ j=1 κ (∣∣∣[XDh]ij∣∣∣) . (25)\nAgain, it is not clear how its proximal step can be efficiently computed. However, with the proposed transformation, the transformed problem is\nmin X f̄(X) + µκ0TV(X),\nwhere µ is the regularization parameter, f̄(X) = f(X) + µ ∑m−1\ni=1 ∑m j=1(κ(|[DvX]ij |) −\nκ0|[DvX]ij |)+µ ∑n\ni=1 ∑n−1 j=1 (κ(|[XDh]ij |)−κ0|[XDh]ij |) is concave and Lipschitz smooth. One\nthen only needs to compute the proximal step of the standard TV regularizer. However, unlike the proximal steps in Sections 4.1.1 and 4.1.2, the proximal step of the TV regularizer has no closed-form solution and needs to be solved iteratively. In this case, Schmidt et al. (2011) showed that using inexact proximal steps can make proximal algorithms faster. However, they only considered the situation where both f and g are convex. In the following, we extend nmAPG (Algorithm 2), which can be used with nonconvex objectives, to allow for inexact proximal steps (steps 5 and 9 of Algorithm 3). However, Lemma 2 of (Li and Lin, 2015), which is key to the convergence of nmAPG, no longer holds dues to inexact proximal step. To fix this problem, in step 6 of Algorithm 3, we use F (Xt) instead of ct in Algorithm 2. Besides, we also drop the comparison of F (Zt+1) and F (Vt+1) (originally in step 9 of Algorithm 2).\nAlgorithm 3 Inexact nmAPG. 1: Initialize Z̃1 = X1 = X0, α0 = 0, α1 = 1 and stepsize τ > L̄, δ ∈ (0, τ − L̄); 2: for t = 1, . . . , T do 3: choose tolerance t; 4: Yt = Xt +\nαt−1 αt (Zt −Xt) + αt−1−1αt (Xt −Xt−1); 5: Z̃t+1 = approximate prox 1\nτ ğ(Yt − 1 τ∇f̄(Yt)), with inexactness ϑt+1 ≤ t;\n6: if F (Z̃t+1) ≤ F (Xt)− δ2‖Z̃t+1 − Yt‖ 2 F then 7: Xt+1 = Z̃t+1; 8: else 9: Xt+1 = approximate prox 1\nτ ğ(Xt − 1 τ∇f̄(Xt)), with inexactness ϑt+1 ≤ t;\n10: end if 11: αt+1 = 1 2( √\n4α2t + 1 + 1); 12: end for 13: return XT+1;\nInexactness of the proximal step can be controlled as follows. Let P = X − 1τ∇f̄(X), and h(X) ≡ 12‖X − P‖ 2 F + 1 τ ğ(X) be the objective in prox 1τ ğ(P ). As ğ(X) = κ0TV(X) is convex, h is also convex. Let X̃ be an inexact solution of this proximal step. The inexactness h(X̃) − h(prox 1\nτ ğ(P )) is upper-bounded by the duality gap ϑ ≡ h(X̃) − D(W̃ ), where D is the dual of\nh, and W̃ is the corresponding dual variable. In step 5 (resp. step 9) of Algorithm 3, we solve the proximal step until its duality gap ϑt+1 is smaller than a given threshold t. The following Theorem shows convergence of Algorithm 3. Theorem 7 Let ∑∞\nt=1 t < ∞. The sequence {Xt} generated from Algorithm 3 has at least one limit point, and every limit point is also a critical point of (1).\nIf the proximal step is exact, ‖Vt − prox 1 τ ğ(Vt − 1 τ∇f̄(Vt))‖ 2 F can be used to measure how far Vt is from a critical point (Gong et al., 2013; Ghadimi and Lan, 2016). In Algorithm 3, the proximal step is inexact, and Xt+1 is an inexact solution to prox 1\nτ ğ(Vt − 1 τ∇f̄(Vt)), where Vt = Yt if step 7\nis executed, and Vt = Xt if step 9 is executed. As Xt+1 converges to a critical point of (1), we\npropose using dt ≡ ‖Xt+1 − Vt‖2F to measure how far Xt+1 is from a critical point. The following Proposition shows a O(1/T ) convergence rate on mint=1,...,T dt.\nProposition 8 (i) limt→∞ dt = 0; and (ii) mint=1,...,T dt converges to zero at a rate of O(1/T ).\nNote that the (exact) nmAPG in Algorithm 2 cannot handle the nonconvex g in (25) efficiently, as the corresponding proximal step has no closed-form solutions but has to be solved exactly. Even the proposed inexact nmAPG (Algorithm 3) cannot be directly used with nonconvex g. As the dual of the nonconvex proximal step is difficult to derive and the optimal duality gap is nonzero in general, the proximal step’s inexactness cannot be easily controlled."
    }, {
      "heading" : "4.2 Frank-Wolfe Algorithm",
      "text" : "In this section, we use the Frank-Wolfe algorithm to learn a low-rank matrix X ∈ Rm×n for matrix completion as reviewed in Section 2.3. The nuclear norm regularizer in (8) may over-penalize top singular values. Recently, there is growing interest to replace this with nonconvex regularizers (Lu et al., 2014, 2015; Yao et al., 2015; Gui et al., 2016). Hence, instead of (8), we consider\nmin X f(X) + µ m∑ i=1 κ(σi(X)). (26)\nWhen κ is the identity function, (26) reduces to (8). Note that the FW algorithm cannot be directly used on (8), as its linear subproblem in (10) then becomes minS:∑mi=1 κ(σi(S))≤1〈S,∇f(Xt)〉, which is difficult to osolve.\nUsing Proposition 5, problem (26) is transformed into\nmin X\nf̄(X) + µ̄‖X‖∗, (27)\nwhere\nf̄(X) = f(X) + ḡ(X), ḡ(X) = µ m∑ i=1 (κ(σi(X))− κ0σi(X)), (28)\nand µ̄ = µκ0. This only involves the standard nuclear norm regularizer. However, Algorithm 1 still cannot be used as f̄ in (28) is no longer convex. A FW variant allowing nonconvex f̄ is proposed in (Bredies et al., 2009). However, condition 1 in (Bredies et al., 2009) requires g to satisfy lim‖X‖F→∞ g(X) ‖X‖F =∞. Such condition does not hold with g(X) = ‖X‖∗ in (27) as\n‖X‖∗ ‖X‖F =\n√ ( ∑m\ni=1 σi) 2∑m\ni=1 σ 2 i\n≤\n√ m ∑m\ni=1 σ 2 i∑m\ni=1 σ 2 i\n= √ m <∞.\nIn the following, we propose a nonconvex FW variant (Algorithm 4) for the transformed problem (27). It is similar to Algorithm 1, but with three important modifications. First, ḡ(X) in (28) depends on the singular values of X , which cannot be directly obtained from the UV > factorization in (11). Instead, we use the low-rank factorization\nX = UBV >, (29)\nwhere U ∈ Rm×k, V ∈ Rn×k are orthogonal and B ∈ Sk×k+ is positive semidefinite.\nAlgorithm 4 Frank-Wolfe algorithm for solving the nonconvex problem (27). 1: U1 = [ ], B1 = [ ] and V1 = [ ]; 2: for t = 1 . . . T do 3: [ut, st, vt] = rank1SVD(∇f̄(Xt)); 4: obtain αt and βt from (32); 5: [Ūt, B̄t, V̄t] = warmstart(Ut, ut, Vt, vt, Bt, αt, βt); 6: obtain [Ut+1, Bt+1, Vt+1] from (33), using Ūt, B̄t and V̄t for warm-start;\n// Xt+1 = Ut+1Bt+1V >t+1 7: end for 8: return UT+1, BT+1 and VT+1.\nThe second problem is that line search in Algorithm 1 is inefficient in general when operated on a nonconvex f̄ . Specifically, step 4 in Algorithm 1 then becomes\n[αt, βt] = arg min α≥0,β≥0\nf̄(αXt + βutv > t ) + µ̄(α‖Xt‖∗ + β). (30)\nTo solve (30), we have to compute ∂f̄(S)∂α and ∂f̄(S) ∂β , where S = αXt + βutv > t . As shown in Proposition 9, this requires the SVD of S and can be expensive.\nProposition 9 Let the SVD of S be USDiag([σ1(S), . . . , σm(S)])V >S . Then\n∂f̄(S)\n∂α = α〈Xt,∇f̄(S)〉, and\n∂f̄(S)\n∂β = βu>t ∇f̄(S)vt,\nwhere∇f̄(S) = ∇f(S) + µUSDiag(w)V >S , and w = [κ′(σi(S))− κ0] ∈ Rm.\nCorollary 10 For X in (29), let the SVD of B be UBDiag([σ1(B), . . . , σk(B)])V >B . Then, ∇f̄(X) = ∇f(X) + µ̄(UUB)Diag(w)(V VB)>, where w = [κ′(σi(B))− κ0] ∈ Rk.\nAlternatively, as S is a rank one updates of Xt, one can perform incremental update on SVD, which takes O((m+ n)t2) time (Golub and Van Loan, 2012). However, every time α, β are changed, this incremental SVD has to be recomputed, and is thus inefficient.\nTo alleviate this problem, we approximate f̄(S) by the upper bound as\nf̄(S) = f̄(Xt + (α− 1)Xt + βutv>t )\n≤ f̄(Xt) + 〈(α− 1)Xt + βutv>t ,∇f̄(Xt)〉+ L̄ 2 ‖(α− 1)Xt + βutv>t ‖2F . (31)\nAs (ut, vt) is obtained from the rank-1 SVD of∇f̄(Xt), we have ‖utv>t ‖F = 1 and u>t ∇f̄(Xt)vt = st. Moreover, Xt = UtBtV >t , and so ‖Xt‖F = ‖Bt‖F and ‖Xt‖∗ = Tr (Bt). Substituting these and the upper bound (31) into (30), we obtain a simple quadratic program:\nminα≥0,β≥0 (α− 1)2L̄\n2 ‖Bt‖2F + (α− 1)βL̄(u>t Ut)Bt(V >t vt) +\nβ2L̄\n2 + βst\n+α〈Bt, U>t ∇f̄(Xt)Vt〉+ µ̄(α‖Bt‖∗ + β). (32)\nNote that the objective in (32) is convex, as the RHS in (31) is convex and the last term from (30) is affine. Moreover, using Corollary 10, 〈Bt, U>t ∇f̄(Xt)Vt〉 in (32) can be obtained as\n〈Bt, U>t ∇f̄(Xt)Vt〉 = 〈Bt, U>t ∇f(Xt)Vt〉+ µ̄ t∑ i=1 σi(Bt)(κ ′(σi(Bt))− κ0).\nInstead of requiring SVD onXt, it only requires SVD onBt (which is of size t×t at the tth iteration of Algorithm 4). As the target matrix is supposed to be low-rank, t m. Hence, all the coefficients in (32) can be obtained in O((m + n)t2 + ‖Ω‖1t) time. Besides, (32) is a quadratic program with only two variables, and thus can be very efficiently solved.\nThe third modification is that with f̄ instead of f , (12) can no longer be used for local optimization, as ḡ(X) in (28) depends on the singular values of X . On the other hand, with the decomposition of X in (29) and Proposition 11 below, (27) can be rewritten as\nminU,B,V f(UBV >) + ḡ(B) + µ̄Tr (B) (33)\ns.t. U>U = I, V >V = I,B ∈ S+. (34)\nThis can be efficiently solved using matrix optimization techniques on the Grassmann manifold (Ngo and Saad, 2012).\nProposition 11 For orthogonal matrices U and V , ḡ(UBV >) = ḡ(B).\nIn Algorithm 4, step 5 is used to warm-start (33), and the procedure is shown in Algorithm 5. It expresses Xt = αtUt−1Bt−1V >t−1 + βtutv > t obtained in step 4 to the form UtBtV > t so that the orthogonal constraints on Ut, Vt in (34) are satisfied.\nAlgorithm 5 warmstart(Ut, ut, Vt, vt, Bt, αt, βt). 1: [Ūt, RŪt ] = QR([Ut, ut]); // QR denotes the QR factorization 2: [V̄t , RV̄t ] = QR([Vt, vt]);\n3: B̄t = RŪt\n[ αtBt 0\n0 βt\n] R> V̄t ;\n4: return Ūt, B̄t and V̄t;\nExisting analysis for the FW algorithm cannot be used on this nonconvex problem. The following Theorem shows convergence of Algorithm 4 to a critical point of (8).\nTheorem 12 If (8) has a rank-r critical point, then Algorithm 4 converges to a critical point of (8) after r iterations."
    }, {
      "heading" : "4.3 Alternating Direction Method of Multipliers (ADMM)",
      "text" : "In this section, we consider using ADMM on the consensus optimization problem (16). When all the fi’s and g are convex, ADMM has a convergence rate of O(1/T ) (He and Yuan, 2012). Recently, ADMM has been extended to problems where g is convex but fi’s are nonconvex (Hong et al., 2016). However, when g is nonconvex, such as when a nonconvex regularizer is used in regularized risk minimization, the convergence of ADMM is still an open reseach problem.\nUsing the proposed transformation, we can decompose a nonconvex g as ḡ + ğ, where ḡ is concave and Lipschitz-smooth, while ğ is convex but possibly nonsmooth. Problem (16) can then be rewritten as\nmin y,x1,...,xM M∑ i=1 f̄i(x i) + ğ(y) : x1 = · · · = xM = y, (35)\nwhere f̄i(x) = fi(x)+ 1M ḡ(x). Let p i be the dual variable for the constraint xi = y. The augmented Lagrangian for (35) is\nL ( y, x1, . . . , xM , p1, . . . , pM ) = ğ(y) + M∑ i=1 f̄i(x i) + (pi)>(xi − y) + τ 2 ‖xi − y‖22. (36)\nUsing (14) and (15), we have the following update equations at iteration t:\nxit+1 = arg min xi f̄i(x i) + (pit)\n>(xi − yt) + τ\n2 ‖xi − yt‖22,\nyt+1 = arg min y\n1\n2 ∥∥∥∥∥y − M∑ i=1 ( xit + 1 τ pit )∥∥∥∥∥ 2\n2\n+ 1\nτ ğ(y) = prox 1 τ ğ ( M∑ i=1 xit + 1 τ pit ) . (37)\nAs in previous sections, the proximal step in (37), which is associated with the convex ğ, is usually easier to compute than the proximal step associated with the original nonconvex g. Moreover, since ğ is convex, convergence results in Theorem 2.4 of (Hong et al., 2016) can now be applied. Specifically, the sequence {yt, {xit}} generated by the ADMM procedure converges to a critical point of (35)."
    }, {
      "heading" : "4.4 Stochastic Variance Reduced Gradient",
      "text" : "Variance reduction methods have been commonly used to speed up the often slow convergence of stochastic gradient descent (SGD). Examples are stochastic variance reduced gradient (SVRG) (Johnson and Zhang, 2013) and its proximal extension Prox-SVRG (Xiao and Zhang, 2014). They can be used for the following optimization problem\nmin x N∑ i=1 `(yi, a > i x) + g(x), (38)\nwhere {(a1, y1), . . . , (aN , yN )} are the training samples, ` is a smooth convex loss function, and g is a convex regularizer. Recently, Prox-SVRG is also extended for nonconvex objectives. Reddi et al. (2016a) and Zhu and Hazan (2016) considered smooth nonconvex ` but without g. This is further extended to the case of smooth ` and convex nonsmooth g in (Reddi et al., 2016b). However, convergence is still unknown for the more general case where the regularizer g is also nonconvex.\nUsing the proposed transformation, (38) can be rewritten as\nmin x N∑ i=1 ( `(yi, a > i x) + 1 N ḡ(x) ) + ğ(x),\nwhere ` + 1N ḡ is smooth and ğ is convex. As a result, convergence results in (Reddi et al., 2016b) can now be applied."
    }, {
      "heading" : "4.5 With OWL-QN",
      "text" : "In this section, we consider OWL-QN (Andrew and Gao, 2007) and its variant mOWL-QN (Gong and Ye, 2015b), which are efficient algorithms for the `1-regularization problem\nmin x f(x) + µ‖x‖1. (39)\nRecently, Gong and Ye (2015a) proposed a nonconvex generalization for (39), in which the standard `1 regularizer is replaced by the nonconvex g(x) = µ ∑d i=1 κ(|xi|):\nmin x f(x) + µ d∑ i=1 κ(|xi|). (40)\nGong and Ye (2015a) proposed a sophisticated algorithm (HONOR) which involves a combination of quasi-Newton and gradient descent steps. Though the algorithm is similar to OWL-QN and mOWL-QN, the convergence analysis in (Gong and Ye, 2015b) cannot be directly applied as the regularizer is nonconvex. Instead, a non-trivial extension was developed in (Gong and Ye, 2015a).\nHere, by convexifying the nonconvex regularizer, (40) can be rewritten as\nmin x f̄(x) + µκ0‖x‖1, (41)\nwhere f̄(x) = f(x) + ḡ(x), and ḡ(x) = µ ∑d\ni=1(κ(|xi|)−κ0|xi|). It is easy to see that the analysis in (Gong and Ye, 2015b) can be extended to handle smooth but nonconvex f̄ . Thus, mOWL-QN is still guaranteed to converge to a critical point.\nAs demonstrated in previous sections, other DC decompositions of g are not as useful. For example, with the one in Proposition 6, we obtain the convex regularizer ς̆(x) = ρµ2 ‖x‖ 2 2 +\nµ ∑d\ni=1 κ(|xi|). However, mOWL-QN can no longer be applied, as it works only with the `1- regularizer.\nProblem (40) can be solved by either (i) directly using HONOR, or (ii) using mOWL-QN on the transformed problem (41). We believe that the latter approach is computationally more efficient. In (40), the Hessian depends on both terms in the objective, as the second-order derivative of κ is not zero in general. However, HONOR constructs the approximate Hessian using only information from f , and thus ignores the curvature information due to ∑d i=1 κ(|xi|). On the other hand, the Hessian in (41) depends only on f̄ , as the Hessian due to ‖x‖1 is zero (Andrew and Gao, 2007), and mOWL-QN now extracts Hessian from f̄ . Hence, optimizing (41) with mOWL-QN is potentially faster, as all the second-order information is utilized. This will be verified empirically in Section 5.4."
    }, {
      "heading" : "4.6 Nonsmooth and Nonconvex Loss",
      "text" : "In many applications, besides having nonconvex regularizers, the loss function may also be nonconvex and nonsmooth. Thus, neither f nor g in (1) is convex, smooth. The optimization problem becomes even harder, and many existing algorithms cannot be used. In particular, the proximal algorithm requires f in (1) to be smooth (possibly nonconvex) (Gong et al., 2013; Li and Lin, 2015; Bot et al., 2016). The FW algorithm requires f in (4) to be smooth and convex (Jaggi, 2013). For the ADMM, it allows f in the consensus problem to be smooth, but g has to be convex (Hong et al., 2016). For problems of the form minx,z f(y) + g(y) : y = Ax, ADMM requires A to have full row-rank (Li and Pong, 2015). As will be seen, it is not satisfied for problems considered\nin this section. CCCP (Yuille and Rangarajan, 2002) and smoothing (Chen, 2012) are more general and can still be used, but are usually very slow.\nIn this section, we consider two application examples, and show how they can be efficiently solved with the proposed transformation."
    }, {
      "heading" : "4.6.1 TOTAL VARIATION IMAGE DENOISING",
      "text" : "Using the `1 loss and TV regularizer introduced in Section 4.1.3, consider the following optimization problem:\nmin X ‖Y −X‖1 + µTV(X), (42)\nwhere Y ∈ Rm×n is a given corrupted image, and X is the target image to be recovered. The use of nonconvex loss and regularizer often produce better performance (Yan, 2013). Thus, we consider the following nonconvex extension:\nmin X m∑ i=1 n∑ j=1 κ (∣∣∣[Y −X]ij∣∣∣)+ µm−1∑ i=1 m∑ j=1 κ (∣∣∣[DvX]ij∣∣∣)+ µ n∑ i=1 n−1∑ j=1 κ (∣∣∣[XDh]ij∣∣∣) , (43)\nwhere both the loss and regularizer are nonconvex and nonsmooth. As discussed above, this can be solved by CCCP and smoothing. However, as will be experimentally demonstrated in Section 5.5, their convergence is slow.\nUsing the proposed transformation on both the loss and regularizer, problem (43) can be transformed to the following problem:\nmin X\nf̄(X) + κ0‖X − Y ‖1 + κ0µTV(X), (44)\nwhere\nf̄(X) = m∑ i=1 n∑ j=1 κ (∣∣∣[Y −X]ij∣∣∣)− κ0‖Y −X‖1\n+ µ m−1∑ i=1 m∑ j=1 κ (∣∣∣[DvX]ij∣∣∣)− κ0‖DvX‖1 + n∑ i=1 n−1∑ j=1 κ (∣∣∣[XDh]ij∣∣∣)− κ0‖XDh‖1  is smooth and nonconvex. As (44) is not a consensus problem, the method in (Hong et al., 2016) cannot be used. To use the ADMM algorithm in (Li and Pong, 2015), extra variables and constraints Zv = DvX and Zh = XDh have to be imposed. However, the full row-rank condition in (Li and Pong, 2015) does not hold.\nIn this section, we consider the proximal algorithm. Given some Z, the proximal step in (44) is\narg min X\n1 2 ‖X − Z‖2F + 1 τ (‖X − Y ‖1 + µTV(X)) , (45)\nwhere τ is the stepsize. Though this has no closed-form solution, ‖X − Y ‖1 + µTV(X) in (45) is convex and one can thus monitor inexactness of the proximal step via the duality gap. Thus, we can\nuse the proposed inexact nmAPG algorithm in Algorithm 3 for (44). It can be shown that the dual of (45) is\nminW,P,Q 1 2τ ‖W + µD>v P + µQD>h ‖2F − 〈Z,W 〉 − µ〈DvZ,P 〉 − µ〈ZDh, Q〉+ 〈Y,W 〉\ns.t. ‖W‖∞ ≤ 1, ‖P‖∞ ≤ 1 and ‖Q‖∞ ≤ 1, (46)\nand the primal variable can be recovered as X = Z − 1τ (W + µD > v P + µQD > h ). By substituting the obtained X into (45) and {W,P,Q} into (46), the duality gap can be computed in O(mn) time. As (46) is a smooth and convex problem, both accelerated gradient descent (Nesterov, 2013) and L-BFGS (Nocedal and Wright, 2006) can be applied. Algorithm 3 is then guaranteed to converge to a critical point of (43) (Theorem 7 and Proposition 8).\nNote that it is more advantageous to transform both the loss and regularizer in (44). If only the regularizer in (43) is transformed, we obtain\nf̄TV(X) + m∑ i=1 n∑ j=1 κ (∣∣∣[Y −X]ij∣∣∣)+ κ0µTV(X), (47)\nwhere\nf̄TV(X) = µ m−1∑ i=1 m∑ j=1 κ (∣∣∣[DvX]ij∣∣∣)− κ0‖DvX‖1 + n∑ i=1 n−1∑ j=1 κ (∣∣∣[XDh]ij∣∣∣)− κ0‖XDh‖1  is nonconvex. The corresponding proximal step for (47) is\narg min X\n1 2 ‖X − Z‖2F + 1 τ  m∑ i=1 n∑ j=1 κ (∣∣∣[Y −X]ij∣∣∣)+ κ0µTV(X)  . (48) While the proximal steps in both (45) and (48) have no closed-form solution, working with (45) is more efficient. As (45) is convex, its dual can be efficiently solved with methods such as accelerated gradient descent and L-BFGS. In contrast, (48) is nonconvex, its duality gap is nonzero, and so can only be solved in the primal with slower methods like CCCP and smoothing. Besides, one can only use the more expensive nmAPG (Algorithm 2) but not the proposed inexact proximal algorithm."
    }, {
      "heading" : "4.6.2 ROBUST SPARSE CODING",
      "text" : "The second application is robust sparse coding, which has been popularly used in face recognition (Yang et al., 2011), image analysis (Lu et al., 2013) and background modeling (Zhao et al., 2011). Given an observed signal y ∈ Rm, the goal is to seek a robust sparse representation x ∈ Rd of y based on the dictionary D ∈ Rm×d (which is assumed to be fixed here). Mathematically, it is formulated as the following optimization problem:\nmin x ‖y −Dx‖1 + µ‖x‖1.\nIts nonconvex extension is:\nmin x m∑ j=1 κ(|[y −Dx]j |) + µ d∑ i=1 κ(|xi|). (49)\nUsing the proposed transformation, problem (49) becomes\nmin x f̄(x) + κ0‖y −Dx‖1 + µκ0‖x‖1, (50)\nwhere\nf̄(x) = µ d∑ j=1 κ(|xj |)− κ0µ‖x‖1 + m∑ j=1 κ(|[y −Dx]j |)− κ0‖y −Dx‖1\nis smooth and nonconvex. Again, we use the inexact nmAPG algorithm in Algorithm 3. The proximal step for (50) is\narg min x\n1 2 ‖x− z‖22 + 1 τ (‖y −Dx‖1 + µ‖x‖1), (51)\nwhere τ is the stepsize and z is given. As in Section 4.6.1, ‖y −Dx‖1 + µ‖x‖1 in (51) is convex, and one can monitor inexactness of the proximal step by the duality gap. The dual of (51) is\nmin p,q\n1\n2τ ‖D>p+ µq‖22 − p>Dz − µq>z : ‖p‖∞ ≤ 1, ‖q‖∞ ≤ 1. (52)\nAs in (46), this can be solved with L-BFGS or accelerated gradient descent. The primal variable can be recovered as x = z − 1τ (D\n>p+ µq), and the duality gap can be checked in O(md) time. If only the regularizer is transformed, we obtain\nmin x m∑ j=1 κ(|[y −Dx]j |) + f̄RSC(x) + κ0µ‖x‖1, (53)\nwhere f̄RSC(x) = µ ∑d j=1 κ(|xj |)− κ0µ‖x‖1. The corresponding proximal step is\narg min x\n1 2 ‖x− z‖22 + m∑ j=1 κ(|[y −Dx]j |) + κ0µ‖x‖1, (54)\nwhich still involve the nonconvex function κ. As in Section 4.6.1, (52) is easier to solve than (54)."
    }, {
      "heading" : "5. Experiments",
      "text" : "In this section, we perform experiments on using the proposed procedure with (i) proximal algorithms (Sections 5.1 and 5.2); (ii) Frank-Wolfe algorithm (Section 5.3); (iii) comparision with HONOR (Section 5.4) and (vi) image denoising (Section 5.5). Experiments are performed on a PC with Intel i7 CPU and 32GB memory. All algorithms are implemented in Matlab."
    }, {
      "heading" : "5.1 Nonconvex Sparse Group Lasso",
      "text" : "In this section, we perform experiments on the nonconvex sparse group lasso model in Section 4.1.1. For simplicity, assume that µ1 = · · · = µK = µ. Using the square loss, (22) becomes\nmin x\n1 2 ‖y −A>x‖22+λ d∑ i=1 κ(|xi|)+µ K∑ j=1 κ(‖xGj‖2), (55)\nwhere A = [a1, . . . , aN ]. In this experiment, we use the LSP regularizer in Table 1 (with θ = 0.5) as κ(·). The synthetic data set is generated as follows. Let d = 10000. The ground-truth parameter x̄ ∈ R10000 is divided into 100 non-overlapping groups: {1, . . . , 100}, {101, . . . , 200}, . . . , {9901, . . . , 10000} (Figure 2). We randomly set 75% of the groups to zero. In each nonzero group, we randomly set 25% of its features to zero, and generate the nonzero features from the standard normal distribution N (0, 1). The whole data set has 20, 000 samples, and entries of the input matrix A ∈ R10000×20000 are generated from N (0, 1). The ground-truth output is ȳ = A>x̄. This is then corrupted by random Gaussian noise in N (0, 0.05) to produce y = ȳ + .\nThe proposed algorithm will be called N2C (Nonconvex-to-Convex). The proximal step of the convexified regularizer ğ(x) = κ0(λ‖x‖1 + ∑K j=1 µj‖xGj‖2) is obtained using the algorithm in (Yuan et al., 2011). The nmAPG algorithm (Algorithm 2) in (Li and Lin, 2015) is used for optimization. This will be compared with the following state-of-the-art algorithms:\n1. SCP: Sequential convex programming (Lu, 2012), in which the LSP regularizer is decomposed following (24).\n2. GIST (Gong et al., 2013): Since the nonconvex regularizer is not separable, the associated proximal operator has no closed-form solution. Instead, we use SCP (with warm-start) to solve it numerically.\n3. GD-PAN (Zhong and Kwok, 2014): It performs gradient descent with proximal average (Bauschke et al., 2008) of the nonconvex regularizers. Closed-form solutions for the proximal operator of each regularizer are obtained separately, and then averaged.\n4. nmAPG with the original nonconvex regularizer: As in GIST, the proximal step is solved numerically by SCP.\n5. As a baseline, we also compare with the FISTA (Beck, 2009) algorithm, which solves the convex sparse group lasso model (with κ removed from (55)).\nWe do not compare with the concave-convex procedure (Yuille and Rangarajan, 2002), which has been shown to be slow (Gong et al., 2013; Zhong and Kwok, 2014).\nWe use 50% of the data for training, another 25% as validation set to tune λ, µ in (55), and the rest for testing. The stepsize is fixed at τ = σ1(A>A). For performance evaluation, we use the (i) testing root-mean-squared error (RMSE) on the predictions; (ii) absolute error between the obtained parameter x̂ with ground-truth x̄: ABS = ‖x̂ − x̄‖1/d; and (iii) CPU time. To reduce statistical variability, the experimental results are averaged over 5 repetitions.\nResults are shown in Table 3. As can be seen, all the nonconvex models obtain better errors (RMSE and ABS) than the convex FISTA. As for the training speed, N2C is the fastest. SCP, GIST, nmAPG and N2C targets the original problem (1), and they have the same recovery performance. GD-PAN solves an approximate problem in each of its iterations, and its error is slightly worse than the other nonconvex algorithms on this data set.\nFigure 3 shows convergence of the objective with time and iterations for a typical run. SCP, GIST, nmAPG and N2C all converge towards the same objective value. GD-PAN can only approximate the original problem. Thus, it converges to an objective value which is larger than others. nmAPG and N2C are based on the state-of-the-art proximal algorithm (Algorithm 2. Both require nearly the same number of iterations for convergence (Figure 3(a)). However, as N2C has cheap closed-form solution for its proximal step, it is much faster when measured in terms of time (Figure 3(b)). Overall, N2C, which uses acceleration and inexpensive proximal step, is the fastest."
    }, {
      "heading" : "5.2 Nonconvex Tree-Structured Group Lasso",
      "text" : "In this section, we perform experiments on the nonconvex tree-structured group lasso model in Section 4.1.2. We use the face data set JAFFE1, which contains 213 images with seven facial expressions: anger, disgust, fear, happy, neutral, sadness and surprise. Following (Liu and Ye, 2010), we resize each image from 256 × 256 to 64 × 64. Their tree structure, which is based on pixel neighborhoods, is also used here. The total number of groups K is 85.\nSince our goal is only to demonstrate usefulness of the proposed convexification scheme, we focus on the binary classification problem “anger vs not-anger” (with 30 anger images and 183 nonanger images). The logistic loss is used, which is more appropriate for classification. Given training samples {(a1, y1), . . . , (aN , yN )}, the optimization problem is then\nmin x N∑ i=1 wi log(1 + exp(−yi · a>i x)) + µ K∑ i=1 λiκ(‖xGi‖2),\n1. http://www.kasrl.org/jaffe.html\nwhere κ(·) is the LSP regularizer (with θ = 0.5),, wi’s are weights (set to be the reciprocal of the size of sample i’s class) used to alleviate class imbalance, and λi = 1/ √ ‖Gi‖1 as in (Liu and Ye, 2010). We use 60% of the data for training, 20% for validation and the rest for testing. For the proposed N2C algorithm, the proximal step of the convexified regularizer is obtained as in (Liu and Ye, 2010).\nAs in Section 5.1, it is compared with SCP, GIST, GD-PAN, nmAPG, and FISTA. The stepsize η is obtained by line search. For performance evaluation, we use (i) the testing accuracy; (ii) solution sparsity (i.e., percentage of nonzero elements); and (iii) CPU time. To reduce statistical variability, the experimental results are averaged over 5 repetitions.\nResults are shown in Table 4. As can be seen, all nonconvex models have similar testing accuracies, and they again outperform the convex model. Moreover, solutions from the nonconvex models are sparser. Overall, N2C is the fastest and has the sparsest solution.\nFigure 4 shows convergence of the algorithms versus CPU time and number of iterations. As can be seen, N2C is the fastest. GIST is the slowest, as it does not utilize acceleration and its proximal step is solved numerically which is expensive. GD-PAN converges to a less optimal solution due to its use of approximation. Moreover, as in Section 5.1, nmAPG and N2C show\nsimilar convergence behavior w.r.t. the number of iterations (Figure 4(b)), but N2C is much faster w.r.t. time (Figure 4(a))."
    }, {
      "heading" : "5.3 Nonconvex Low-Rank Matrix Completion",
      "text" : "In this section, we perform experiments on nonconvex low-rank matrix completion (Section 4.2), with square loss in (26). The LSP regularizer is used, with θ = √ µ as in (Yao et al., 2015). We use the MovieLens data sets2 (Table 5), which have been commonly used for evaluating matrix completion (Hsieh and Olsen, 2014; Yao et al., 2015). They contain ratings {1, 2, . . . , 5} assigned by various users on movies.\nThe proposed Frank-Wolfe procedure (Algorithm 4), denoted N2C-FW, is compared with the following algorithms:\n1. FaNCL (Yao et al., 2015): This is a recent nonconvex matrix regularization algorithm. It is based on the proximal algorithm using efficient approximate SVD and automatic thresholding of singular values.\n2. LMaFit (Wen et al., 2012): It factorizes X as a product of low-rank matrices U ∈ Rm×k and V ∈ Rn×k. The nonconvex objective 12‖PΩ(UV\n> − O)‖2F is then minimized by alternating minimization on U and V using gradient descent.\n2. http://grouplens.org/datasets/movielens/\n3. Active subspace selection (denoted “active”) (Hsieh and Olsen, 2014): This solves the (convex) nuclear norm regularized problem (with κ being the identity function in (8)) by using the active row/column subspaces to reduce the optimization problem size.\nWe do not compare with IRNN (Lu et al., 2014) and GPG (Lu et al., 2015), which have been shown to be much slower than FaNCL (Yao et al., 2015).\nFollowing (Yao et al., 2015), we use 50% of the ratings for training, 25% for validation and the rest for testing. For performance evaluation, we use (i) the testing RMSE; and (ii) the recovered rank. To reduce statistical variability, the experimental results are averaged over 5 repetitions.\nResults are shown in Table 6. As can be seen, the nonconvex models (N2C-FW, FaNCL and LMaFit) achieve lower RMSEs than the convex model (active), with N2C-FW having the smallest RMSE. Moreover, the convex model needs a much higher rank than the nonconvex models, which agrees with the previous observations in (Mazumder et al., 2010; Yao et al., 2015). Thus, its running time is also much longer than the others. Figure 5 shows the convergence of the objective with CPU time. As the recovered matrixs rank for the nonconvex models are very low (2 to 9 in Table 6), N2C-FW is much faster than the others as it starts from a rank-one matrix and only increases its rank by one in each iteration. Though FaNCL uses singular value thresholding to truncate the SVD, it does not control the rank as directly as N2C-FW and so is still slower."
    }, {
      "heading" : "5.4 Comparison with HONOR",
      "text" : "In this section, we experimentally compare the proposed method with HONOR (Section 4.5) on the model in (40), using the logistic loss and LSP regularizer. Following (Gong and Ye, 2015a), we fix µ = 1 in (40), and θ in the LSP regularizer to 0.01µ. Experiments are performed on three large data sets, kdd2010a, kdd2010b and url 3 (Table 7). Both kdd2010a and kdd2010b are educational data sets, and the task is to predict students’ successful attempts to answer concepts related to algebra.\n3. https://www.csie.ntu.edu.tw/˜cjlin/libsvmtools/datasets/binary.html\nThe url data set contains a collection of websites, and the task is to predict whether a particular website is malicious. We compare\n1. running HONOR (Gong and Ye, 2015a) directly on (40). The threshold of the hybrid step in HONOR is set to 10−10, which yields the best empirical performance in (Gong and Ye, 2015a);\n2. running mOWL-QN (Gong and Ye, 2015b)) on the transformed problem (41).\nTo reduce statistical variability, the experimental results are averaged over 5 repetitions. As (40) and (41) have the same optimization objective, Figure 6 shows the convergence of the objective with CPU time. As can be seen, mOWL-QN converges faster than HONOR. This validates our claim that the curvature information of the nonconvex regularizer helps."
    }, {
      "heading" : "5.5 Image Denoising",
      "text" : "In this section, we perform experiments on total variation image denoising with nonconvex loss and nonconvex regularizer (as introduced in Section 4.6.1). The LSP function (with θ = 1) is used as κ in (43) on both the loss and regularizer. Eight popular images4 from (Dabov et al., 2007) are used (Figure 7). They are then corrupted by pepper-and-salt noise, with 10% of the pixels randomly set to 0 or 255 with equal probabilities.\nFor performance evaluation, we use the RMSE = √\n1 mn ∑m i=1 ∑n j=1(Xij − X̄ij)2, where X̄ ∈\nRm×n is the clean image, and X ∈ Rm×n is the recovered image. To tune µ, we pick the value\n4. http://www.cs.tut.fi/˜foi/GCF-BM3D/\nthat leads to the smallest RMSE on the first four images (boat, couple, fprint, hill). Denoising performance is then reported on the remaining images (house, lena, man, peppers).\nThe following algorithms will be compared:\n1. CCCP (Yuille and Rangarajan, 2002): Proposition 6 is used to construct DC decomposition for κ (Details are at Appendix B.1);\n2. Smoothing (Chen, 2012): The nonsmooth κ is smoothed, and then gradient descent is used (Details are at Appendix B.2);\n3. nmAPG (Li and Lin, 2015): This optimizes (47) with Algorithm 2, and the exact proximal step is solved numerically using CCCP;\n4. inexact-nmAPG: This optimizes (44) with Algorithm 3 (with t = 0.95t), and the inexact proximal step is solved numerically using L-BFGS.\n5. As a baseline, we also compare with ADMM (Boyd et al., 2011) with the convex formulation.\nTo reduce statistical variability, the experimental results are averaged over 5 repetitions. The RMSE results are shown in Table 8. As can be seen, the (convex) ADMM formulation leads to the highest RMSE, while CCCP, smoothing, nmAPG and inexact-nmAPG have the same RMSE which is lower than that of ADMM. This agrees with previous observations that nonconvex formulations can yield better performance than the convex ones. Timing results are shown in Table 9 and Figure 8. As can be seen, smoothing has low iteration complexity but suffers from slow convergence. CCCP and nmAPG both need to exactly solve a subproblem, and thus are also slow. The inexactnmAPG algorithm does not guarantee the objective value to be monotonically decreasing as iteration proceeds. As the inexactness is initially large, there is an initial spike in the objective. However, inexact-nmAPG then quickly converges, and is much faster than all the baselines."
    }, {
      "heading" : "6. Conclusion",
      "text" : "In this paper, we proposed a novel approach to learning with nonconvex regularizers. By moving the nonconvexity associated with the nonconvex regularizer to the loss, the nonconvex regularizer is convexified to become a familiar convex regularizer while the augmented loss is still Lipschitz smooth. This allows one to reuse efficient algorithms originally designed for convex regularizers\non the transformed problem. To illustrate usages with the proposed transformation, we plug it into many popular optimization algorithms. First, we consider the proximal algorithm, and showed that while the proximal step is expensive on the original problem, it becomes much easier on the transformed problem. We further propose an inexact proximal algorithm, which allows inexact update of proximal step when it does not have a closed-form solution. Second, we combine the proposed convexification scheme with the Frank-Wolfe algorithm on learning low-rank matrices, and showed that its crucial linear programming step becomes cheaper and more easily solvable. As no convergence results exist on this nonconvex problem, we designed a novel Frank-Wolfe algorithm based on the proposed transformation and with convergence guarantee. Third, when using with ADMM and SVRG, we showed that the existing convergence results can be applied on the transformed problem but not on the original one. We further extend the proposed transformation to handle nonconvex and nonsmooth loss functions, and illustrate its benefits on the total variation model and robust sparse coding. Finally, we demonstrate the empirical advantages of working with the transformed problems on various tasks with both synthetic and real-world data sets. Experimental results show that better performance can be obtained with nonconvex regularizers, and algorithms on the transformed problems run much faster than the state-of-the-art on the original problems."
    }, {
      "heading" : "Appendix A. Proofs",
      "text" : ""
    }, {
      "heading" : "A.1 Proposition 1",
      "text" : "Proof First, we introduce a few Lemmas.\nLemma 13 (Golub and Van Loan, 2012) For x 6= 0, the gradient of the `2-norm is ∇xi‖x‖2 = xi/‖x‖2.\nLet h(z) = κ(‖z‖2)− κ0‖z‖2.\nLemma 14\n∇zih(z) =\n{ κ′(‖z‖2)−κ0 ‖z‖2 zi if z 6= 0\n0 otherwise . (56)\nProof For z 6= 0, ‖z‖2 is differentiable (Lemma 13), and we obtain the first part of (56). For z = 0, let h̄i(z) = κ′(‖z‖2)−κ0 ‖z‖2 zi. Consider any ∆ with ‖∆‖2 = 1.\nlim α→0+ h̄i(0 + α∆) = lim α→0+ κ′(‖α∆‖2)− κ0 ‖α∆‖2 α∆i,\n= lim α→0+\n(κ′(α)− κ0)∆i = 0,\nas limα→0+ κ′(α)−κ0 = 0. Thus, h(z) is smooth at z = 0, and we obtain the second part of (56).\nLemma 15 (Eriksson et al., 2004) Let f : R → R be a differentiable function. (i) If its derivative f ′ is bounded, then f is Lipschitz-continuous with constant equal to the maximum value of |f ′|.\nLemma 16 (Eriksson et al., 2004) If a continuous function f : R→ R isL1-Lipschitz continuous in [a, b] and L2-Lipschitz continuous in [b, c] (where −∞ ≤ a < b < c ≤ ∞), then it is max(L1, L2)Lipschitz continuous in [a, c].\nLemma 17 Let z be an arbitrary vector, and ei be the unit vector with only its ith dimension equal to 1. Define ĥi(γ) =\nκ′(‖z+eiγ‖2)−κ0 ‖z+eiγ‖2 (zi + γ). Then, ĥ is 2ρ-Lipschitz continuous.\nProof Since κ′ is non-differentiable only at finite points, and let them be {α̂1, . . . , α̂k} where α̂1 < · · · < α̂k. We partition (−∞,∞) into intervals (−∞, α̂1] ∪ [α̂1, α̂2] ∪ · · · ∪ [α̂k,∞), such that κ′′ exists in each interval. Let w = z + eiγ. For any interval,\nĥ′i(γ) = κ′′(‖w‖2) ‖w‖2 (zi + γ) 2 +\n( 1− (zi + γ) 2\n‖w‖22 ) κ′(‖w‖2)− κ0 ‖w‖2 . (57)\nLet φ(α) = κ′(α) − κ0, where α ≥ 0. Note that φ(0) = 0. Moreover, φ(α) is ρ-Lipschitz continuous as κ is ρ-Lipschitz smooth. Thus,\n|φ(α)− φ(0)| = |κ′(α)− κ0| ≤ ρα,\nand so ∣∣κ′(‖w‖2)− κ0∣∣ ≤ ρ‖w‖2. (58) Note that (zi + γ)2 ≤ ‖w‖22, (57) can be written as∣∣∣ĥ′i(γ)∣∣∣ ≤ ∣∣∣∣κ′′(‖w‖2)‖w‖2 (zi + γ)2 ∣∣∣∣+ ∣∣∣∣(1− (zi + γ)2‖w‖22 ) κ′(‖w‖2)− κ0 ‖w‖2\n∣∣∣∣ ≤ ∣∣κ′′(‖w‖2)∣∣+ ∣∣∣∣κ′(‖w‖2)− κ0‖w‖2\n∣∣∣∣ ≤ 2ρ, where the last inequality is due to that κ is ρ-Lipschitz smooth and (58). Thus, |ĥ′i(γ)| ≤ 2ρ, and by Lemma 15, we have ĥi(γ) is 2ρ-Lipschitz continuous on any interval. Obviously ĥi is continuous, and we conclude that ĥi is also 2ρ-Lipschitz continuous by Lemma 16.\nFrom Lemma 17, ĥi is 2ρ-Lipschitz continuous. Thus, ∇h is 2ρ-Lipschitz continuous in each of its dimensions. For any x, y ∈ Rd,\n‖∇h(x)−∇h(y)‖22 = d∑ i=1 [∇xih(x)−∇yih(y)] 2\n≤ 4ρ2 d∑ i=1 (xi − yi)2 = 4ρ2‖x− y‖22,\nand hence h is 2ρ-Lipschitz smooth. Finally, we will show that h(z) is also concave.\nLemma 18 (Boyd and Vandenberghe, 2004) φ(x) = π(q(x)) is concave if π is concave, nonincreasing and q is convex.\nLet π(α) = κ(α) − κ0α, where α ≥ 0. Note that π is concave. Moreover, π(0) = 0 and π′(α) ≤ 0. Thus, π(α) is non-increasing on α ≥ 0. Next, let q(z) = ‖z‖2. Then, h(z) ≡ κ(‖z‖2)− κ0‖z‖2 = π(q(z)). As q is convex, h(z) is concave from Lemma 18."
    }, {
      "heading" : "A.2 Corollary 2",
      "text" : "Proof From Proposition 1 and definition of ḡi, we can see it is concave. Then, for any x, y,\n‖∇h(Aix)−∇h(Aiy)‖22 ≤ 4ρ2‖Aix−Aiy‖22 ≤ 4ρ2‖Ai‖2F ‖x− y‖22.\nThus, ḡi is 2ρ‖Ai‖F -Lipschitz smooth."
    }, {
      "heading" : "A.3 Corollary 3",
      "text" : "Proof It is easy to see that ğ(x) = κ0 ∑K\ni=1 µi‖Aix‖2 is convex but not smooth. Using Corollary 2, as each ḡi is concave and Lipschitz-smooth, ḡ is also concave and Lipschitz-smooth."
    }, {
      "heading" : "A.4 Proposition 5",
      "text" : "Proof First, we introduce a few lemmas.\nDefinition 19 (Bertsekas, 1999) A function f : Rm → R is absolute symmetric if f ([x1; . . . ;xm]) = f ([ |xπ(1)|; . . . ; |xπ(m)| ]) for any permutation π.\nLemma 20 (Lewis and Sendov, 2005) Let σ(X) = [σ1(X); . . . ;σm(X)] be the vector containing singular values of X . For an absolute symmetric function f : Rm → R, φ(X) ≡ f(σ(X)) is concave on X if and only if f is concave.\nFrom the definition of ḡ in (21),\nḡ(X) = µ̄ m∑ i=1 (κ(σi(X))− κ0‖X‖∗) = µ̄ m∑ i=1 (κ(σi(X))− κ0σi(X)) .\nLet\nh(x) = µ̄ m∑ i=1 (κ(|xi|)− κ0|xi|). (59)\nObviously, h is absolute symmetric. From Remark 4, h is concave. Thus, ḡ is also concave by Lemma 20.\nLemma 21 (Lewis and Sendov, 2005) Let the SVD of X be UDiag(σ(X))V >, where σ(X) = [σ1(X); . . . ;σm(X)], f : Rm → R be smooth and absolute symmetric, and φ(X) ≡ f(σ(X)). We have\n1. ∇φ(X) = UDiag(∇f(σ(X)))V >; and\n2. If f is L-Lipschitz smooth, then φ is also L-Lipschitz smooth.\nFrom Remark 4, h in (59) is 2ρ-Lipschitz smooth. Hence, from Lemma 21, ḡ(X) is also 2ρLipschitz smooth and∇ḡ(X) = UDiag(∇h(σ(X)))V >."
    }, {
      "heading" : "A.5 Proposition 6",
      "text" : "Proof First, we introduce the following lemma.\nLemma 22 (Boyd and Vandenberghe, 2004) φ(x) = π(q(x)) is convex if π is convex, nondecreasing and q is convex.\nLet q(x) = ‖x‖2, and π(α) = κ(α) + ρ2α 2 where α ≥ 0. Thus, φ(x) = π(q(x)) = κ(‖x‖2) + ρ2‖x‖ 2 2. Obviously, q is convex. For α ≥ β ≥ 0, 0 ≤ κ′(α) ≤ κ′(β). As κ is ρLipschitz smooth, κ′(β)−κ′(α) ≤ ρ(α−β). Thus, π′(α)−π′(β) = κ′(α)+ρα−κ′(β)−ρβ ≥ 0, i.e., π is convex. Besides, π′(0) = κ′(0) ≥ 0. Thus, π′(α) ≥ 0 and π is also non-decreasing. By Lemma 22, φ is also convex."
    }, {
      "heading" : "A.6 Theorem 7",
      "text" : "Proof First, we introduce a few lemmas.\nLemma 23 Let X̃ be an inexact solution of the proximal step minZ h(Z), where h(Z) = 12‖Z − (X − 1τ∇f̄(X))‖ 2 F + 1 τ ğ(Z). Let X̂ = arg minZ h(Z). If h(X̃)− h(X̂) ≤ , then\nF (X̃) ≤ F (X)− τ − L̄ 2 ‖X̃ −X‖2F + τ .\nProof Let φ(Z) = 〈Z −X,∇f(X)〉+ τ2‖Z −X‖ 2 F + ğ(Z). We have\nX̂ = arg min Z h(Z) = arg min Z φ(Z), (60) φ(Z) = τh(Z)− 1 τ ‖∇f̄(X)‖2F . (61)\nFrom (60), we have\nφ(X̂) = 〈X̂ −X,∇f(X)〉+ τ 2 ‖X̂ −X‖2F + ğ(X̂) ≤ ğ(X). (62)\nAs h(X̃)− h(X̂) ≤ , from (61) (note that ‖∇f̄(X)‖2F is a constant), we have\nφ(X̃)− φ(X̂) = τ(h(X̃)− h(X̂)) ≤ τ\nThen with (62), we have φ(X̃) ≤ τ + φ(X̂) ≤ ğ(X) + τ , i.e.,\n〈X̃ −X,∇f(X)〉+ τ 2 ‖X̃ −X‖2F + ğ(X̃) ≤ ğ(X) + τ . (63)\nAs f̄ is L̄-Lipschitz smooth,\nf̄(X̃) ≤ f̄(X) + 〈X̃ −X,∇f(X)〉+ L̄ 2 ‖X̃ −X‖2F .\nCombining with (63), we obtain\nf̄(X̃) + τ\n2 ‖X̃ −X‖22 + ğ(X̃) ≤ f̄(X) +\nL̄ 2 ‖X̃ −X‖2F + ğ(X) + τ .\nThus, F (X̃) ≤ F (X)− τ−L̄2 ‖X̃ −X‖ 2 F + τ .\nIf step 6 in Algorithm 3 is satisfied, Xt+1 = Z̃t+1, and\nF (Xt+1) ≤ F (Xt)− δ\n2 ‖Xt+1 − Yt‖2F . (64)\nOtherwise, step 9 is executed, and from Lemma 23, we have\nF (Xt+1) ≤ F (Xt)− τ − L̄\n2 ‖Xt+1 −Xt‖2F + τ t. (65)\nPartition Ω(T ) = {1, 2, . . . , T} into Ω1(T ) and Ω2(T ), such that step 7 is performed if t ∈ Ω1(T ); and execute step 9 otherwise. Combining (64) and (65), we have\nF (X1)− F (XT+1)\n≥ δ 2 ∑ t∈Ω1(T ) ‖Xt+1 − Yt‖2F + τ − L̄ 2 ∑ t∈Ω2(T ) ( ‖Xt+1 −Xt‖2F − τ t ) ,\n≥ δ 2 ∑ t∈Ω1(T ) ‖Xt+1 − Yt‖2F + τ − L̄ 2 ∑ t∈Ω2(T ) ‖Xt+1 −Xt‖2F − (τ − L̄)τ 2 ∑ t∈Ω2(T ) t\n≥ δ 2 ∑ t∈Ω1(T ) ‖Xt+1 − Yt‖2F + τ − L̄ 2 ∑ t∈Ω2(T ) ‖Xt+1 −Xt‖2F − (τ − L̄)τ 2 ∞∑ t=1 t\n≥ δ 2 ∑ t∈Ω1(T ) ‖Xt+1 − Yt‖2F − c1 + τ − L̄ 2 ∑ t∈Ω2(T ) ‖Xt+1 −Xt‖2F , (66)\nwhere c1 = (τ−L̄)τ\n2\n∑∞ t=1 t <∞ and c1 ≥ 0. From (66), we have\nF (X1)− inf X F (X) + c1 ≥ F (X1)− lim T→∞ F (XT+1) + c1\n≥ lim T→∞\nδ\n2 ∑ t∈Ω1(T ) ‖Xt+1 − Yt‖2F + τ − L̄ 2 ∑ t∈Ω2(T ) ‖Xt+1 −Xt‖2F ≡ c2. (67)\nFrom Assumption A1, c2 ≤ F (X1) − infX F (X) + c1 < ∞, thus c2 ≥ 0 is a finite constant. Let Ω∞1 = limT→∞Ω1(T ), and Ω ∞ 2 = limT→∞Ω2(T ). Consider the three cases:\n1. |Ω∞1 | is finite, and |Ω∞2 | is infinite. As |Ω∞2 | = ∞ and lim‖X‖F→∞ F (X) = ∞ from Assumption A1 and (67), we must have\nlim t∈Ω∞2 ,t→∞\n‖Xt+1 −Xt‖2F = 0.\nThus, there exists a limit point such that X∗ = limtj∈Ω∞2 ,tj→∞Xtj for a subsequence {Xtj} of {Xt}. Since limtj→∞ tj = 0, then\nlim tj∈Ω∞2 ,tj→∞ Xtj+1 = lim tj∈Ω∞2 ,tj→∞ prox 1 τ ğ(Xtj −\n1 τ ∇f̄(Xtj )).\nAs a result,\n0 ∈ lim tj∈Ω∞2 ,tj→∞\n1 τ ∇f̄(Xtj ) + (Xtj+1 −Xtj ) + 1 τ ∂ğ(Xtj+1).\nSince both limtj∈Ω∞2 ,tj→∞Xtj = limtj∈Ω∞2 ,tj→∞Xtj+1 = X∗, we then have ∇f̄(X∗) + ∂ğ(X∗) 3 0, and X∗ is a critical point of (1).\n2. |Ω∞1 | is infinite, and |Ω∞2 | is finite. As Ω∞1 is infinite and lim‖X‖F→∞ F (X) = ∞ from Assumption A1 and (67), we must have\nlim tj∈Ω∞1 ,tj→∞\n‖Xtj+1 − Ytj‖2F = 0.\nfor a subsequence {Xtj} of {Xt}. Thus, there must exist a limit point such that\nX∗ = lim tj∈Ω∞1 ,tj→∞ Xtj+1 = lim tj∈Ω∞1 ,tj→∞ Ytj . (68)\nAs limtj→∞ tj = 0, we have\n0 ∈ lim tj∈Ω∞1 ,tj→∞\n1 τ ∇f̄(Ytj ) + (Xtj+1 − Ytj ) + 1 τ ∂ğ(Xtj+1).\nFrom (68), thus we have∇f̄(X∗) + ∂ğ(X∗) 3 0 and X∗ is a critical point of (1).\n3. Both Ω∞1 and Ω ∞ 2 are infinite. From above two cases, we can see {Xt} is bounded and, the\nlimit points of {Xt} are also critical points either |Ω∞1 | or |Ω∞2 | is infinite. In the third case, both of them are infinite, thus any limit points of {Xt} are also critical points of (1).\nAs a result, {Xt} are bounded and its limits points are all critical points of (1)."
    }, {
      "heading" : "A.7 Proposition 8",
      "text" : "Proof From (67), we have\nδ\n2 ∑ t1∈Ω1(T ) ‖Xt1+1 − Yt1‖2F + τ − L̄ 2 ∑ t2∈Ω2(T ) ‖Xt2+1 −Xt2‖2F < c2, (69)\nwhere c2 ∈ (0,∞) is a positive constant. Let c3 = min( δ2 , τ−L̄\n2 ) and using the definition of Vt, (69) can be written as\nc3 T∑ t=1 ‖Xt+1 − Vt‖2F ≤ δ 2 ∑ t1∈Ω1(T ) ‖Xt1+1 − Yt1‖2F + τ − L̄ 2 ∑ t2∈Ω2(T ) ‖Xt2+1 −Xt2‖2F ≤ c2.\nSince c2 is finite, thus limt→∞ dt ≡ ‖Xt+1 − Vt‖2F = 0. Besides, we have\nmin t=1,...,T T∑ t=1 ‖Xt+1 − Vt‖2F ≤ 1 T T∑ t=1 ‖Xt+1 − Vt‖2F ≤ c2 c3T ."
    }, {
      "heading" : "A.8 Proposition 9",
      "text" : "Proof Note from (28) that ∇f̄(S) = ∇f(S) + ∇ḡ(S). Using the matrix chain rule, since S = αXt + βutv > t and ∂S ∂α = Xt, then\n∂f̄(S)\n∂α =\n〈 ∇f̄(S), ∂S\n∂α\n〉 = α〈Xt,∇f̄(S)〉.\nSimilarly, since ∂S∂β = utv > t\n∂f̄(S)\n∂β =\n〈 ∇f̄(S), ∂S\n∂β\n〉 = β 〈 utv > t ,∇f̄(S) 〉 = β ( u>t ∇f̄(S)vt ) .\nAs ḡ(S) = µ ∑m\ni=1 κ(σi(S))−µκ0σi(S), using Lemma 21,∇f̄(X) = ∇f(S) +µUSDiag(w)V >S and wi = κ′(σi(S))− κ0."
    }, {
      "heading" : "A.9 Corollary 10",
      "text" : "Proof Note that the SVD of X is (UUB)Diag([σ1(B), . . . , σk(B)])(V VB)>. Using Lemma 21,\n∇f̄(X) = ∇f(X) +∇ḡ(X) = ∇f(X) + µ(UUB)Diag(w)(V VB)>.\nwhere w ∈ Rk with wi = κ′(σi(B))− κ0."
    }, {
      "heading" : "A.10 Proposition 11",
      "text" : "Proof As ḡ(X) is defined on singular values of the input matrix X , we only need to show UBV > and B have exactly the same singular values. Let SVD of B = UBDiag(σ(B))V >B where σ(B) = [σ1(B), . . . , σm(B)]. As U and V are orthogonal, it is easy to see (UUB) Diag(σ(B)) (VBV )\n> is the SVD of X . Thus, the Proposition holds."
    }, {
      "heading" : "A.11 Theorem 12",
      "text" : "Proof We first introduce two propositions.\nProposition 24 (Mishra et al., 2013) For a square matrix X , let sym(X) = 12(X + X >). The first-order optimality conditions for (33) are\n∇f̄(X)V B − U sym(U>∇f̄(X)V B) = 0, (∇f̄(X))>UB − V sym(V >∇f̄(X)UB) = 0,\nsym(U>∇f̄(X)V ) + µ̄I = 0.\nProposition 25 If (27) has a critical point with rank-r, choose matrix size of U ∈ Rm×r, V ∈ Rn×r and B ∈ Sr×r+ , then any critical points of (33) is also a critical point of (27).\nProof Subdifferential of the nuclear norm can be obtained as (Watson, 1992)\n∂‖X‖∗ = {UV > +W : U>W = 0,WV = 0, ‖W‖∞ ≤ 1}, (70)\nwhere X = UBV >. Let X̂ = Û B̂V̂ > be a critical point of (33), we have sym(Û>∇f̄(X̂)V̂ ) + µ̄I = 0 dues to Proposition 24. From property of matrix norm, we have\nλ = ‖ sym(Û>∇f̄(X̂)V̂ )‖∞ ≤ ‖Û>∇f̄(X̂)V̂ ‖∞ ≤ ‖∇f̄(X̂)‖∞.\nThe equality holds only when∇f̄(X̂) = −µ̄Û V̂ > − µ̄Û⊥Σ̂⊥V̂ >⊥ where Û⊥ and V̂⊥ are orthogonal matrix with Û>Û⊥ = 0 and V̂ >V̂⊥ = 0, and Σ̂⊥ is a diagonal matrix with positive elements [Σ⊥]ii ≤ 1. Combining this fact with (70), we can see\n∇f̄(X̂) ∈ −µ̄∂‖X̂‖∗. (71)\nThen, for (27), if X∗ is a critical point then we have\n∇f̄(X∗) ∈ −µ̄∂‖X∗‖∗. (72)\nComparing (71) and (72), the difference is on rank of X̂ and X∗. As (27) has a critical point with rank-r a critical point of (33), X̂ is also a critical point of (27).\nIn Algorithm 4, the size of U , V and B are picked up as m × t, n × t and t × t. If (27) has a critical point with rank-r, then as iteration goes and t = r, from Proposition 25, Algorithm 4 will return a critical point of (27)."
    }, {
      "heading" : "Appendix B. Details in Section 5.5",
      "text" : ""
    }, {
      "heading" : "B.1 CCCP",
      "text" : "Using Proposition 6, we can decompose κ(|x|) = ς̂(x) + ς̃(x) where ς̂(x) = −ρ2x 2 is convex and ς̃(x) = κ(|x|) + ρ2x 2 is concave. We can apply above decomposition on κ into (43) and get a DC\ndecomposition as\nF̃ (X) = m∑ i=1 n∑ j=1 ς̃ ( [Y −X]ij ) + µ m−1∑ i=1 m∑ j=1 ς̃ ( [DvX]ij ) + µ n∑ i=1 n−1∑ j=1 ς̃ ( [XDh]ij ) ,\nF̂ (X) = m∑ i=1 n∑ j=1 ς̂ ( [Y −X]ij ) + µ m−1∑ i=1 m∑ j=1 ς̂ ( [DvX]ij ) + µ n∑ i=1 n−1∑ j=1 ς̂ ( [XDh]ij ) .\nThen, CCCP procedures at Section 2.1 can be applied."
    }, {
      "heading" : "B.2 Smoothing",
      "text" : "As LSP function is used as κ, a smoothed version of it can be obtained as κ̃λ(x) = β log (\n1 + hλ(x)θ ) where hλ(x) = { |x| if |x| ≥ λ x2\n2λ + λ 2 otherwise\n. Thus, (43) is smoothed as\nF̃λ(X) = m∑ i=1 n∑ j=1 κ̃λ ( [Y −X]ij ) + µ m−1∑ i=1 m∑ j=1 κ̃λ ( [DvX]ij ) + µ n∑ i=1 n−1∑ j=1 κ̃λ ( [XDh]ij ) .\nThen, gradient descent is used for optimization (Chen, 2012). Specifically, we need to minimize a sequence of subproblems {F̃λ1(X), F̃λ2(X), . . . } with λi = λ0 · νi, and using X from F̃λi−1(X) to warm start F̃λi(X). In the experiment, we set λ0 = 0.1 and ν = 0.95."
    } ],
    "references" : [ {
      "title" : "Scalable training of `1-regularized log-linear models",
      "author" : [ "G. Andrew", "J. Gao" ],
      "venue" : "In Proceedings of the 24th International Conference on Machine learning,",
      "citeRegEx" : "Andrew and Gao.,? \\Q2007\\E",
      "shortCiteRegEx" : "Andrew and Gao.",
      "year" : 2007
    }, {
      "title" : "The proximal average: Basic theory",
      "author" : [ "H. Bauschke", "R. Goebel", "Y. Lucet", "X. Wang" ],
      "venue" : "SIAM Journal on Optimization,",
      "citeRegEx" : "Bauschke et al\\.,? \\Q2008\\E",
      "shortCiteRegEx" : "Bauschke et al\\.",
      "year" : 2008
    }, {
      "title" : "Fast gradient-based algorithms for constrained total variation image denoising and deblurring problems",
      "author" : [ "A. Beck", "M. Teboulle" ],
      "venue" : "IEEE Transactions on Image Processing,",
      "citeRegEx" : "Beck and Teboulle.,? \\Q2009\\E",
      "shortCiteRegEx" : "Beck and Teboulle.",
      "year" : 2009
    }, {
      "title" : "A fast iterative shrinkage-thresholding algorithm for linear inverse problems",
      "author" : [ "A.M. Beck", "Teboulle" ],
      "venue" : "SIAM Journal on Imaging Sciences,",
      "citeRegEx" : "Beck and Teboulle.,? \\Q2009\\E",
      "shortCiteRegEx" : "Beck and Teboulle.",
      "year" : 2009
    }, {
      "title" : "Nonlinear Programming",
      "author" : [ "D.P. Bertsekas" ],
      "venue" : "Athena Scientific,",
      "citeRegEx" : "Bertsekas.,? \\Q1999\\E",
      "shortCiteRegEx" : "Bertsekas.",
      "year" : 1999
    }, {
      "title" : "Parallel and Distributed Computation",
      "author" : [ "D.P. Bertsekas", "J.N. Tsitsiklis" ],
      "venue" : "Numerical Methods. Prentice-Hall,",
      "citeRegEx" : "Bertsekas and Tsitsiklis.,? \\Q1989\\E",
      "shortCiteRegEx" : "Bertsekas and Tsitsiklis.",
      "year" : 1989
    }, {
      "title" : "An inertial forward-backward algorithm for the minimization of the sum of two nonconvex functions",
      "author" : [ "R.I. Bot", "E. Robert Csetnek", "S.C. László" ],
      "venue" : "EURO Journal on Computational Optimization,",
      "citeRegEx" : "Bot et al\\.,? \\Q2016\\E",
      "shortCiteRegEx" : "Bot et al\\.",
      "year" : 2016
    }, {
      "title" : "Online learning and stochastic approximations",
      "author" : [ "L. Bottou" ],
      "venue" : "On-line Learning in Neural Networks,",
      "citeRegEx" : "Bottou.,? \\Q1998\\E",
      "shortCiteRegEx" : "Bottou.",
      "year" : 1998
    }, {
      "title" : "Convex Optimization",
      "author" : [ "S. Boyd", "L. Vandenberghe" ],
      "venue" : null,
      "citeRegEx" : "Boyd and Vandenberghe.,? \\Q2004\\E",
      "shortCiteRegEx" : "Boyd and Vandenberghe.",
      "year" : 2004
    }, {
      "title" : "Distributed optimization and statistical learning via the alternating direction method of multipliers",
      "author" : [ "S. Boyd", "N. Parikh", "E. Chu", "B. Peleato", "J. Eckstein" ],
      "venue" : "Foundations and Trends in Machine Learning,",
      "citeRegEx" : "Boyd et al\\.,? \\Q2011\\E",
      "shortCiteRegEx" : "Boyd et al\\.",
      "year" : 2011
    }, {
      "title" : "A generalized conditional gradient method and its connection to an iterative shrinkage method",
      "author" : [ "K. Bredies", "D.A. Lorenz", "P. Maass" ],
      "venue" : "Computational Optimization and Applications,",
      "citeRegEx" : "Bredies et al\\.,? \\Q2009\\E",
      "shortCiteRegEx" : "Bredies et al\\.",
      "year" : 2009
    }, {
      "title" : "Exact matrix completion via convex optimization",
      "author" : [ "E.J. Candès", "B. Recht" ],
      "venue" : "Foundations of Computational Mathematics,",
      "citeRegEx" : "Candès and Recht.,? \\Q2009\\E",
      "shortCiteRegEx" : "Candès and Recht.",
      "year" : 2009
    }, {
      "title" : "Enhancing sparsity by reweighted `1 minimization",
      "author" : [ "E.J. Candès", "M.B. Wakin", "S. Boyd" ],
      "venue" : "Journal of Fourier Analysis and Applications,",
      "citeRegEx" : "Candès et al\\.,? \\Q2008\\E",
      "shortCiteRegEx" : "Candès et al\\.",
      "year" : 2008
    }, {
      "title" : "Robust principal component analysis",
      "author" : [ "E.J. Candès", "X. Li", "Yi Ma", "J. Wright" ],
      "venue" : "Journal of the ACM,",
      "citeRegEx" : "Candès et al\\.,? \\Q2011\\E",
      "shortCiteRegEx" : "Candès et al\\.",
      "year" : 2011
    }, {
      "title" : "Smoothing methods for nonsmooth, nonconvex minimization",
      "author" : [ "X. Chen" ],
      "venue" : "Mathematical Programming,",
      "citeRegEx" : "Chen.,? \\Q2012\\E",
      "shortCiteRegEx" : "Chen.",
      "year" : 2012
    }, {
      "title" : "Image denoising by sparse 3-D transformdomain collaborative filtering",
      "author" : [ "K. Dabov", "A. Foi", "V. Katkovnik", "K. Egiazarian" ],
      "venue" : "IEEE Transactions on Image Processing,",
      "citeRegEx" : "Dabov et al\\.,? \\Q2007\\E",
      "shortCiteRegEx" : "Dabov et al\\.",
      "year" : 2007
    }, {
      "title" : "Compressed sensing",
      "author" : [ "D.L. Donoho" ],
      "venue" : "IEEE Transactions on Information Theory,",
      "citeRegEx" : "Donoho.,? \\Q2006\\E",
      "shortCiteRegEx" : "Donoho.",
      "year" : 2006
    }, {
      "title" : "Applied Mathematics: Body and Soul: Volume 1: Derivatives and Geometry in IR3",
      "author" : [ "K. Eriksson", "F. Estep", "C. Johnson" ],
      "venue" : null,
      "citeRegEx" : "Eriksson et al\\.,? \\Q2004\\E",
      "shortCiteRegEx" : "Eriksson et al\\.",
      "year" : 2004
    }, {
      "title" : "Variable selection via nonconcave penalized likelihood and its oracle properties",
      "author" : [ "J. Fan", "R. Li" ],
      "venue" : "Journal of the American Statistical Association,",
      "citeRegEx" : "Fan and Li.,? \\Q2001\\E",
      "shortCiteRegEx" : "Fan and Li.",
      "year" : 2001
    }, {
      "title" : "An algorithm for quadratic programming",
      "author" : [ "M. Frank", "P. Wolfe" ],
      "venue" : "Naval Research Logistics,",
      "citeRegEx" : "Frank and Wolfe.,? \\Q1956\\E",
      "shortCiteRegEx" : "Frank and Wolfe.",
      "year" : 1956
    }, {
      "title" : "Nonlinear image recovery with half-quadratic regularization",
      "author" : [ "D. Geman", "C. Yang" ],
      "venue" : "IEEE Transactions on Image Processing,",
      "citeRegEx" : "Geman and Yang.,? \\Q1995\\E",
      "shortCiteRegEx" : "Geman and Yang.",
      "year" : 1995
    }, {
      "title" : "Accelerated gradient methods for nonconvex nonlinear and stochastic programming",
      "author" : [ "S. Ghadimi", "G. Lan" ],
      "venue" : "Mathematical Programming,",
      "citeRegEx" : "Ghadimi and Lan.,? \\Q2016\\E",
      "shortCiteRegEx" : "Ghadimi and Lan.",
      "year" : 2016
    }, {
      "title" : "Sur l’approximation, par éléments finis d’ordre un, et la résolution, par pénalisation-dualité d’une classe de problèmes de dirichlet non linéaires. Revue française d’automatique, informatique, recherche opérationnelle",
      "author" : [ "R. Glowinski", "A. Marroco" ],
      "venue" : "Analyse numérique,",
      "citeRegEx" : "Glowinski and Marroco.,? \\Q1975\\E",
      "shortCiteRegEx" : "Glowinski and Marroco.",
      "year" : 1975
    }, {
      "title" : "Matrix Computations",
      "author" : [ "G.H. Golub", "C.F. Van Loan" ],
      "venue" : null,
      "citeRegEx" : "Golub and Loan.,? \\Q2012\\E",
      "shortCiteRegEx" : "Golub and Loan.",
      "year" : 2012
    }, {
      "title" : "HONOR: Hybrid Optimization for NOn-convex Regularized problems",
      "author" : [ "P. Gong", "J. Ye" ],
      "venue" : "In Advances in Neural Information Processing Systems,",
      "citeRegEx" : "Gong and Ye.,? \\Q2015\\E",
      "shortCiteRegEx" : "Gong and Ye.",
      "year" : 2015
    }, {
      "title" : "A modified orthant-wise limited memory quasi-Newton method with convergence analysis",
      "author" : [ "P. Gong", "J. Ye" ],
      "venue" : "In Proceedings of the 32nd International Conference on Machine Learning,",
      "citeRegEx" : "Gong and Ye.,? \\Q2015\\E",
      "shortCiteRegEx" : "Gong and Ye.",
      "year" : 2015
    }, {
      "title" : "A general iterative shrinkage and thresholding algorithm for non-convex regularized optimization problems",
      "author" : [ "P. Gong", "C. Zhang", "Z. Lu", "J. Huang", "J. Ye" ],
      "venue" : "In Proceedings of the 30th International Conference on Machine Learning,",
      "citeRegEx" : "Gong et al\\.,? \\Q2013\\E",
      "shortCiteRegEx" : "Gong et al\\.",
      "year" : 2013
    }, {
      "title" : "Towards faster rates and oracle property for low-rank matrix estimation",
      "author" : [ "H. Gui", "J. Han", "Q. Gu" ],
      "venue" : "In Proceedings of the 33nd International Conference on Machine Learning,",
      "citeRegEx" : "Gui et al\\.,? \\Q2016\\E",
      "shortCiteRegEx" : "Gui et al\\.",
      "year" : 2016
    }, {
      "title" : "On the o(1/n) convergence rate of the douglas-rachford alternating direction method",
      "author" : [ "B. He", "X. Yuan" ],
      "venue" : "SIAM Journal on Numerical Analysis,",
      "citeRegEx" : "He and Yuan.,? \\Q2012\\E",
      "shortCiteRegEx" : "He and Yuan.",
      "year" : 2012
    }, {
      "title" : "Generalized differentiability, duality and optimization for problems dealing with differences of convex functions",
      "author" : [ "J.B. Hiriart-Urruty" ],
      "venue" : "Convexity and Duality in Optimization,",
      "citeRegEx" : "Hiriart.Urruty.,? \\Q1985\\E",
      "shortCiteRegEx" : "Hiriart.Urruty.",
      "year" : 1985
    }, {
      "title" : "Convergence analysis of alternating direction method of multipliers for a family of nonconvex problems",
      "author" : [ "M. Hong", "Z.-Q. Luo", "M. Razaviyayn" ],
      "venue" : "SIAM Journal on Optimization,",
      "citeRegEx" : "Hong et al\\.,? \\Q2016\\E",
      "shortCiteRegEx" : "Hong et al\\.",
      "year" : 2016
    }, {
      "title" : "Nuclear norm minimization via active subspace selection",
      "author" : [ "C.-J. Hsieh", "P. Olsen" ],
      "venue" : "In Proceedings of the 31st International Conference on Machine Learning,",
      "citeRegEx" : "Hsieh and Olsen.,? \\Q2014\\E",
      "shortCiteRegEx" : "Hsieh and Olsen.",
      "year" : 2014
    }, {
      "title" : "Group lasso with overlap and graph lasso",
      "author" : [ "L. Jacob", "G. Obozinski", "J.-P. Vert" ],
      "venue" : "In Proceedings of the 26th International Conference on Machine Learning,",
      "citeRegEx" : "Jacob et al\\.,? \\Q2009\\E",
      "shortCiteRegEx" : "Jacob et al\\.",
      "year" : 2009
    }, {
      "title" : "Revisiting Frank-Wolfe: Projection-free sparse convex optimization",
      "author" : [ "M. Jaggi" ],
      "venue" : "In Proceedings of the 30th International Conference on Machine Learning,",
      "citeRegEx" : "Jaggi.,? \\Q2013\\E",
      "shortCiteRegEx" : "Jaggi.",
      "year" : 2013
    }, {
      "title" : "Proximal methods for hierarchical sparse coding",
      "author" : [ "R. Jenatton", "J. Mairal", "G. Obozinski", "F. Bach" ],
      "venue" : "Journal of Machine Learning Research,",
      "citeRegEx" : "Jenatton et al\\.,? \\Q2011\\E",
      "shortCiteRegEx" : "Jenatton et al\\.",
      "year" : 2011
    }, {
      "title" : "Accelerating stochastic gradient descent using predictive variance reduction",
      "author" : [ "R. Johnson", "T. Zhang" ],
      "venue" : "In Advances in Neural Information Processing Systems,",
      "citeRegEx" : "Johnson and Zhang.,? \\Q2013\\E",
      "shortCiteRegEx" : "Johnson and Zhang.",
      "year" : 2013
    }, {
      "title" : "A hybrid algorithm for convex semidefinite optimization",
      "author" : [ "S. Laue" ],
      "venue" : "In Proceedings of the 29th International Conference on Machine Learning,",
      "citeRegEx" : "Laue.,? \\Q2012\\E",
      "shortCiteRegEx" : "Laue.",
      "year" : 2012
    }, {
      "title" : "Nonsmooth analysis of singular values",
      "author" : [ "A.S. Lewis", "H.S. Sendov" ],
      "venue" : "Part ii: Applications. SetValued Analysis,",
      "citeRegEx" : "Lewis and Sendov.,? \\Q2005\\E",
      "shortCiteRegEx" : "Lewis and Sendov.",
      "year" : 2005
    }, {
      "title" : "Global convergence of splitting methods for nonconvex composite optimization",
      "author" : [ "G. Li", "T.K. Pong" ],
      "venue" : "SIAM Journal on Optimization,",
      "citeRegEx" : "Li and Pong.,? \\Q2015\\E",
      "shortCiteRegEx" : "Li and Pong.",
      "year" : 2015
    }, {
      "title" : "Accelerated proximal gradient methods for nonconvex programming",
      "author" : [ "H. Li", "Z. Lin" ],
      "venue" : "In Advances in Neural Information Processing Systems,",
      "citeRegEx" : "Li and Lin.,? \\Q2015\\E",
      "shortCiteRegEx" : "Li and Lin.",
      "year" : 2015
    }, {
      "title" : "Moreau-Yosida regularization for grouped tree structure learning",
      "author" : [ "J. Liu", "J. Ye" ],
      "venue" : "In Advances in Neural Information Processing Systems,",
      "citeRegEx" : "Liu and Ye.,? \\Q2010\\E",
      "shortCiteRegEx" : "Liu and Ye.",
      "year" : 2010
    }, {
      "title" : "Tensor completion for estimating missing values in visual data",
      "author" : [ "J. Liu", "P. Musialski", "P. Wonka", "J. Ye" ],
      "venue" : "IEEE Transactions on Pattern Analysis and Machine Intelligence,",
      "citeRegEx" : "Liu et al\\.,? \\Q2013\\E",
      "shortCiteRegEx" : "Liu et al\\.",
      "year" : 2013
    }, {
      "title" : "Online robust dictionary learning",
      "author" : [ "C. Lu", "J. Shi", "J. Jia" ],
      "venue" : "In IEEE Conference on Computer Vision and Pattern Recognition,",
      "citeRegEx" : "Lu et al\\.,? \\Q2013\\E",
      "shortCiteRegEx" : "Lu et al\\.",
      "year" : 2013
    }, {
      "title" : "Generalized nonconvex nonsmooth low-rank minimization",
      "author" : [ "C. Lu", "J. Tang", "S. Yan", "Z. Lin" ],
      "venue" : "In Proceedings of the International Conference on Computer Vision and Pattern Recognition,",
      "citeRegEx" : "Lu et al\\.,? \\Q2014\\E",
      "shortCiteRegEx" : "Lu et al\\.",
      "year" : 2014
    }, {
      "title" : "Generalized singular value thresholding",
      "author" : [ "C. Lu", "C. Zhu", "C. Xu", "S. Yan", "Z. Lin" ],
      "venue" : "In Proceedings of the 29th AAAI Conference on Artificial Intelligence,",
      "citeRegEx" : "Lu et al\\.,? \\Q2015\\E",
      "shortCiteRegEx" : "Lu et al\\.",
      "year" : 2015
    }, {
      "title" : "Sequential convex programming methods for a class of structured nonlinear programming",
      "author" : [ "Z. Lu" ],
      "venue" : "Preprint arXiv:1210.3039,",
      "citeRegEx" : "Lu.,? \\Q2012\\E",
      "shortCiteRegEx" : "Lu.",
      "year" : 2012
    }, {
      "title" : "Online dictionary learning for sparse coding",
      "author" : [ "J. Mairal", "F. Bach", "J. Ponce", "G. Sapiro" ],
      "venue" : "In Proceedings of the 26th International Conference on Machine Learning,",
      "citeRegEx" : "Mairal et al\\.,? \\Q2009\\E",
      "shortCiteRegEx" : "Mairal et al\\.",
      "year" : 2009
    }, {
      "title" : "Spectral regularization algorithms for learning large incomplete matrices",
      "author" : [ "R. Mazumder", "T. Hastie", "R. Tibshirani" ],
      "venue" : "Journal of Machine Learning Research,",
      "citeRegEx" : "Mazumder et al\\.,? \\Q2010\\E",
      "shortCiteRegEx" : "Mazumder et al\\.",
      "year" : 2010
    }, {
      "title" : "Low-rank optimization with trace norm penalty",
      "author" : [ "B. Mishra", "G. Meyer", "F. Bach", "R. Sepulchre" ],
      "venue" : "SIAM Journal on Optimization,",
      "citeRegEx" : "Mishra et al\\.,? \\Q2013\\E",
      "shortCiteRegEx" : "Mishra et al\\.",
      "year" : 2013
    }, {
      "title" : "Gradient methods for minimizing composite functions",
      "author" : [ "Y. Nesterov" ],
      "venue" : "Mathematical Programming,",
      "citeRegEx" : "Nesterov.,? \\Q2013\\E",
      "shortCiteRegEx" : "Nesterov.",
      "year" : 2013
    }, {
      "title" : "Scaled gradients on Grassmann manifolds for matrix completion",
      "author" : [ "T. Ngo", "Y. Saad" ],
      "venue" : "In Advances in Neural Information Processing Systems,",
      "citeRegEx" : "Ngo and Saad.,? \\Q2012\\E",
      "shortCiteRegEx" : "Ngo and Saad.",
      "year" : 2012
    }, {
      "title" : "A variational approach to remove outliers and impulse noise",
      "author" : [ "M. Nikolova" ],
      "venue" : "Journal of Mathematical Imaging and Vision,",
      "citeRegEx" : "Nikolova.,? \\Q2004\\E",
      "shortCiteRegEx" : "Nikolova.",
      "year" : 2004
    }, {
      "title" : "iPiano: Inertial proximal algorithm for nonconvex optimization",
      "author" : [ "P. Ochs", "Y. Chen", "T. Brox", "T. Pock" ],
      "venue" : "SIAM Journal on Imaging Sciences,",
      "citeRegEx" : "Ochs et al\\.,? \\Q2014\\E",
      "shortCiteRegEx" : "Ochs et al\\.",
      "year" : 2014
    }, {
      "title" : "Stochastic variance reduction for nonconvex optimization",
      "author" : [ "S.J. Reddi", "A. Hefny", "S. Sra", "B. Póczos", "A.J. Smola" ],
      "venue" : "In Proceedings of the 33nd International Conference on Machine Learning,",
      "citeRegEx" : "Reddi et al\\.,? \\Q2016\\E",
      "shortCiteRegEx" : "Reddi et al\\.",
      "year" : 2016
    }, {
      "title" : "Fast stochastic methods for nonsmooth nonconvex optimization",
      "author" : [ "S.J. Reddi", "S. Sra", "B. Poczos", "A. Smola" ],
      "venue" : "In Advances in Neural Information Processing Systems,",
      "citeRegEx" : "Reddi et al\\.,? \\Q2016\\E",
      "shortCiteRegEx" : "Reddi et al\\.",
      "year" : 2016
    }, {
      "title" : "Convergence rates of inexact proximal-gradient methods for convex optimization",
      "author" : [ "M. Schmidt", "N.L. Roux", "F. Bach" ],
      "venue" : "In Advances in Neural Information Processing Systems,",
      "citeRegEx" : "Schmidt et al\\.,? \\Q2011\\E",
      "shortCiteRegEx" : "Schmidt et al\\.",
      "year" : 2011
    }, {
      "title" : "Scalable nonconvex inexact proximal splitting",
      "author" : [ "S. Sra" ],
      "venue" : "In Advances in Neural Information Processing Systems,",
      "citeRegEx" : "Sra.,? \\Q2012\\E",
      "shortCiteRegEx" : "Sra.",
      "year" : 2012
    }, {
      "title" : "Maximum-margin matrix factorization",
      "author" : [ "N. Srebro", "J. Rennie", "T.S. Jaakkola" ],
      "venue" : "In Advances in Neural Information Processing Systems,",
      "citeRegEx" : "Srebro et al\\.,? \\Q2004\\E",
      "shortCiteRegEx" : "Srebro et al\\.",
      "year" : 2004
    }, {
      "title" : "Robust principal component analysis via capped norms",
      "author" : [ "Q. Sun", "S. Xiang", "J. Ye" ],
      "venue" : "In Proceedings of the 19th International Conference on Knowledge Discovery and Data Mining,",
      "citeRegEx" : "Sun et al\\.,? \\Q2013\\E",
      "shortCiteRegEx" : "Sun et al\\.",
      "year" : 2013
    }, {
      "title" : "Regression shrinkage and selection via the lasso",
      "author" : [ "R. Tibshirani" ],
      "venue" : "Journal of the Royal Statistical Society. Series B,",
      "citeRegEx" : "Tibshirani.,? \\Q1996\\E",
      "shortCiteRegEx" : "Tibshirani.",
      "year" : 1996
    }, {
      "title" : "Sparsity and smoothness via the fused lasso",
      "author" : [ "R. Tibshirani", "M. Saunders", "S. Rosset", "J. Zhu", "K. Knight" ],
      "venue" : "Journal of the Royal Statistical Society: Series B,",
      "citeRegEx" : "Tibshirani et al\\.,? \\Q2005\\E",
      "shortCiteRegEx" : "Tibshirani et al\\.",
      "year" : 2005
    }, {
      "title" : "Highly undersampled magnetic resonance image reconstruction via homotopic-minimization",
      "author" : [ "J. Trzasko", "A. Manduca" ],
      "venue" : "IEEE Transactions on Medical Imaging,",
      "citeRegEx" : "Trzasko and Manduca.,? \\Q2009\\E",
      "shortCiteRegEx" : "Trzasko and Manduca.",
      "year" : 2009
    }, {
      "title" : "Characterization of the subdifferential of some matrix norms",
      "author" : [ "G.A. Watson" ],
      "venue" : "Linear Algebra and its Applications,",
      "citeRegEx" : "Watson.,? \\Q1992\\E",
      "shortCiteRegEx" : "Watson.",
      "year" : 1992
    }, {
      "title" : "Solving a low-rank factorization model for matrix completion by a nonlinear successive over-relaxation algorithm",
      "author" : [ "Z. Wen", "W. Yin", "Y. Zhang" ],
      "venue" : "Mathematical Programming Computation,",
      "citeRegEx" : "Wen et al\\.,? \\Q2012\\E",
      "shortCiteRegEx" : "Wen et al\\.",
      "year" : 2012
    }, {
      "title" : "A proximal stochastic gradient method with progressive variance reduction",
      "author" : [ "L. Xiao", "T. Zhang" ],
      "venue" : "SIAM Journal on Optimization,",
      "citeRegEx" : "Xiao and Zhang.,? \\Q2014\\E",
      "shortCiteRegEx" : "Xiao and Zhang.",
      "year" : 2014
    }, {
      "title" : "Restoration of images corrupted by impulse noise and mixed gaussian impulse noise using blind inpainting",
      "author" : [ "M. Yan" ],
      "venue" : "SIAM Journal on Imaging Sciences,",
      "citeRegEx" : "Yan.,? \\Q2013\\E",
      "shortCiteRegEx" : "Yan.",
      "year" : 2013
    }, {
      "title" : "Robust sparse coding for face recognition",
      "author" : [ "M. Yang", "L. Zhang", "J. Yang", "D. Zhang" ],
      "venue" : "In IEEE Conference on Computer Vision and Pattern Recognition,",
      "citeRegEx" : "Yang et al\\.,? \\Q2011\\E",
      "shortCiteRegEx" : "Yang et al\\.",
      "year" : 2011
    }, {
      "title" : "Efficient learning with a family of nonconvex regularizers by redistributing nonconvexity",
      "author" : [ "Q Yao", "J.T. Kwok" ],
      "venue" : "In Proceedings of the 33rd International Conference on Machine Learning,",
      "citeRegEx" : "Yao and Kwok.,? \\Q2016\\E",
      "shortCiteRegEx" : "Yao and Kwok.",
      "year" : 2016
    }, {
      "title" : "Fast low-rank matrix learning with nonconvex regularization",
      "author" : [ "Q. Yao", "J.T. Kwok", "W. Zhong" ],
      "venue" : "In Proceedings of IEEE International Conference on Data Mining,",
      "citeRegEx" : "Yao et al\\.,? \\Q2015\\E",
      "shortCiteRegEx" : "Yao et al\\.",
      "year" : 2015
    }, {
      "title" : "Efficient methods for overlapping group lasso",
      "author" : [ "L. Yuan", "J. Liu", "J. Ye" ],
      "venue" : "In Advances in Neural Information Processing Systems,",
      "citeRegEx" : "Yuan et al\\.,? \\Q2011\\E",
      "shortCiteRegEx" : "Yuan et al\\.",
      "year" : 2011
    }, {
      "title" : "The concave-convex procedure (CCCP)",
      "author" : [ "A.L. Yuille", "A. Rangarajan" ],
      "venue" : "In Advances in Neural Information Processing Systems,",
      "citeRegEx" : "Yuille and Rangarajan.,? \\Q2002\\E",
      "shortCiteRegEx" : "Yuille and Rangarajan.",
      "year" : 2002
    }, {
      "title" : "Nearly unbiased variable selection under minimax concave penalty",
      "author" : [ "C.H. Zhang" ],
      "venue" : "Annals of Statistics,",
      "citeRegEx" : "Zhang.,? \\Q2010\\E",
      "shortCiteRegEx" : "Zhang.",
      "year" : 2010
    }, {
      "title" : "Analysis of multi-stage convex relaxation for sparse regularization",
      "author" : [ "T. Zhang" ],
      "venue" : "Journal of Machine Learning Research,",
      "citeRegEx" : "Zhang.,? \\Q2010\\E",
      "shortCiteRegEx" : "Zhang.",
      "year" : 2010
    }, {
      "title" : "Accelerated training for matrix-norm regularization: A boosting approach",
      "author" : [ "X. Zhang", "D. Schuurmans", "Y.-L. Yu" ],
      "venue" : "In Advances in Neural Information Processing Systems,",
      "citeRegEx" : "Zhang et al\\.,? \\Q2012\\E",
      "shortCiteRegEx" : "Zhang et al\\.",
      "year" : 2012
    }, {
      "title" : "Background subtraction via robust dictionary learning",
      "author" : [ "C. Zhao", "X. Wang", "W.-K. Cham" ],
      "venue" : "EURASIP Journal on Image and Video Processing,",
      "citeRegEx" : "Zhao et al\\.,? \\Q2011\\E",
      "shortCiteRegEx" : "Zhao et al\\.",
      "year" : 2011
    }, {
      "title" : "Gradient descent with proximal average for nonconvex and composite regularization",
      "author" : [ "W. Zhong", "J.T. Kwok" ],
      "venue" : "In Proceedings of the 28th AAAI Conference on Artificial Intelligence,",
      "citeRegEx" : "Zhong and Kwok.,? \\Q2014\\E",
      "shortCiteRegEx" : "Zhong and Kwok.",
      "year" : 2014
    }, {
      "title" : "Variance reduction for faster non-convex optimization",
      "author" : [ "Z.A. Zhu", "E. Hazan" ],
      "venue" : "In Proceedings of the 33nd International Conference on Machine Learning,",
      "citeRegEx" : "Zhu and Hazan.,? \\Q2016\\E",
      "shortCiteRegEx" : "Zhu and Hazan.",
      "year" : 2016
    } ],
    "referenceMentions" : [ {
      "referenceID" : 2,
      "context" : "Popular examples include the sparsity-inducing regularizers, which have been commonly used in image processing (Beck and Teboulle, 2009; Mairal et al., 2009; Jenatton et al., 2011) and highdimensional feature selection (Tibshirani et al.",
      "startOffset" : 111,
      "endOffset" : 180
    }, {
      "referenceID" : 46,
      "context" : "Popular examples include the sparsity-inducing regularizers, which have been commonly used in image processing (Beck and Teboulle, 2009; Mairal et al., 2009; Jenatton et al., 2011) and highdimensional feature selection (Tibshirani et al.",
      "startOffset" : 111,
      "endOffset" : 180
    }, {
      "referenceID" : 34,
      "context" : "Popular examples include the sparsity-inducing regularizers, which have been commonly used in image processing (Beck and Teboulle, 2009; Mairal et al., 2009; Jenatton et al., 2011) and highdimensional feature selection (Tibshirani et al.",
      "startOffset" : 111,
      "endOffset" : 180
    }, {
      "referenceID" : 60,
      "context" : ", 2011) and highdimensional feature selection (Tibshirani et al., 2005; Jacob et al., 2009; Liu and Ye, 2010); and the low-rank regularizer in matrix and tensor learning, with good empirical performance on tasks such as recommender systems (Candès and Recht, 2009; Mazumder et al.",
      "startOffset" : 46,
      "endOffset" : 109
    }, {
      "referenceID" : 32,
      "context" : ", 2011) and highdimensional feature selection (Tibshirani et al., 2005; Jacob et al., 2009; Liu and Ye, 2010); and the low-rank regularizer in matrix and tensor learning, with good empirical performance on tasks such as recommender systems (Candès and Recht, 2009; Mazumder et al.",
      "startOffset" : 46,
      "endOffset" : 109
    }, {
      "referenceID" : 40,
      "context" : ", 2011) and highdimensional feature selection (Tibshirani et al., 2005; Jacob et al., 2009; Liu and Ye, 2010); and the low-rank regularizer in matrix and tensor learning, with good empirical performance on tasks such as recommender systems (Candès and Recht, 2009; Mazumder et al.",
      "startOffset" : 46,
      "endOffset" : 109
    }, {
      "referenceID" : 11,
      "context" : ", 2009; Liu and Ye, 2010); and the low-rank regularizer in matrix and tensor learning, with good empirical performance on tasks such as recommender systems (Candès and Recht, 2009; Mazumder et al., 2010) and visual data analysis (Liu et al.",
      "startOffset" : 156,
      "endOffset" : 203
    }, {
      "referenceID" : 47,
      "context" : ", 2009; Liu and Ye, 2010); and the low-rank regularizer in matrix and tensor learning, with good empirical performance on tasks such as recommender systems (Candès and Recht, 2009; Mazumder et al., 2010) and visual data analysis (Liu et al.",
      "startOffset" : 156,
      "endOffset" : 203
    }, {
      "referenceID" : 41,
      "context" : ", 2010) and visual data analysis (Liu et al., 2013; Lu et al., 2014).",
      "startOffset" : 33,
      "endOffset" : 68
    }, {
      "referenceID" : 43,
      "context" : ", 2010) and visual data analysis (Liu et al., 2013; Lu et al., 2014).",
      "startOffset" : 33,
      "endOffset" : 68
    }, {
      "referenceID" : 16,
      "context" : "Well-known examples include the `1-regularizer for sparse coding (Donoho, 2006), and the nuclear norm regularizer in low-rank matrix learning",
      "startOffset" : 65,
      "endOffset" : 79
    }, {
      "referenceID" : 20,
      "context" : "κ(α) κ′(α) κ0 ρ GP (Geman and Yang, 1995) βα θ+α βθ (θ+α)2 β θ 2β θ2 LSP (Candès et al.",
      "startOffset" : 19,
      "endOffset" : 41
    }, {
      "referenceID" : 12,
      "context" : "κ(α) κ′(α) κ0 ρ GP (Geman and Yang, 1995) βα θ+α βθ (θ+α)2 β θ 2β θ2 LSP (Candès et al., 2008) β log(1 + αθ ) β θ+α β θ β θ2",
      "startOffset" : 73,
      "endOffset" : 94
    }, {
      "referenceID" : 61,
      "context" : "MCP (Zhang, 2010a) { βα− α2 2θ α ≤ βθ 1 2θβ 2 α > βθ { β − αθ α ≤ βθ 0 α > βθ β 1θ Laplace (Trzasko and Manduca, 2009) β(1− exp(−αθ )) β θ exp ( −αθ ) β θ β θ2",
      "startOffset" : 91,
      "endOffset" : 118
    }, {
      "referenceID" : 18,
      "context" : "SCAD (Fan and Li, 2001)  βα α ≤ β −α2+2θβα−β2 2(θ−1) β < α ≤ θβ β2(1+θ) 2 α > θβ  β α ≤ β −α+θβ θ−1 β < α ≤ θβ 0 α > θβ β 1 θ−1",
      "startOffset" : 5,
      "endOffset" : 23
    }, {
      "referenceID" : 11,
      "context" : "(Candès and Recht, 2009).",
      "startOffset" : 0,
      "endOffset" : 24
    }, {
      "referenceID" : 33,
      "context" : "Popular optimization algorithms in machine learning include the proximal algorithm (Parikh and Boyd, 2013), Frank-Wolfe (FW) algorithm (Jaggi, 2013), the alternating direction method of multipliers (ADMM) (Boyd et al.",
      "startOffset" : 135,
      "endOffset" : 148
    }, {
      "referenceID" : 9,
      "context" : "Popular optimization algorithms in machine learning include the proximal algorithm (Parikh and Boyd, 2013), Frank-Wolfe (FW) algorithm (Jaggi, 2013), the alternating direction method of multipliers (ADMM) (Boyd et al., 2011), stochastic gradient descent and its variants (Bottou, 1998; Xiao and Zhang, 2014).",
      "startOffset" : 205,
      "endOffset" : 224
    }, {
      "referenceID" : 7,
      "context" : ", 2011), stochastic gradient descent and its variants (Bottou, 1998; Xiao and Zhang, 2014).",
      "startOffset" : 54,
      "endOffset" : 90
    }, {
      "referenceID" : 64,
      "context" : ", 2011), stochastic gradient descent and its variants (Bottou, 1998; Xiao and Zhang, 2014).",
      "startOffset" : 54,
      "endOffset" : 90
    }, {
      "referenceID" : 47,
      "context" : "In lowrank matrix learning, the estimated rank obtained with the nuclear norm regularizer is often much higher (Mazumder et al., 2010).",
      "startOffset" : 111,
      "endOffset" : 134
    }, {
      "referenceID" : 20,
      "context" : "To alleviate this problem, a number of nonconvex regularizers have been recently proposed (Geman and Yang, 1995; Fan and Li, 2001; Candès et al., 2008; Zhang, 2010a; Trzasko and Manduca, 2009).",
      "startOffset" : 90,
      "endOffset" : 192
    }, {
      "referenceID" : 18,
      "context" : "To alleviate this problem, a number of nonconvex regularizers have been recently proposed (Geman and Yang, 1995; Fan and Li, 2001; Candès et al., 2008; Zhang, 2010a; Trzasko and Manduca, 2009).",
      "startOffset" : 90,
      "endOffset" : 192
    }, {
      "referenceID" : 12,
      "context" : "To alleviate this problem, a number of nonconvex regularizers have been recently proposed (Geman and Yang, 1995; Fan and Li, 2001; Candès et al., 2008; Zhang, 2010a; Trzasko and Manduca, 2009).",
      "startOffset" : 90,
      "endOffset" : 192
    }, {
      "referenceID" : 61,
      "context" : "To alleviate this problem, a number of nonconvex regularizers have been recently proposed (Geman and Yang, 1995; Fan and Li, 2001; Candès et al., 2008; Zhang, 2010a; Trzasko and Manduca, 2009).",
      "startOffset" : 90,
      "endOffset" : 192
    }, {
      "referenceID" : 70,
      "context" : "One can use general-purpose nonconvex optimization solvers such as the concave-convex procedure (Yuille and Rangarajan, 2002).",
      "startOffset" : 96,
      "endOffset" : 125
    }, {
      "referenceID" : 26,
      "context" : "However, the subproblem in each iteration can be as expensive as the original problem, and the concave-convex procedure is thus often slow in practice (Gong et al., 2013; Zhong and Kwok, 2014).",
      "startOffset" : 151,
      "endOffset" : 192
    }, {
      "referenceID" : 75,
      "context" : "However, the subproblem in each iteration can be as expensive as the original problem, and the concave-convex procedure is thus often slow in practice (Gong et al., 2013; Zhong and Kwok, 2014).",
      "startOffset" : 151,
      "endOffset" : 192
    }, {
      "referenceID" : 56,
      "context" : "Examples include the NIPS (Sra, 2012), IPiano (Ochs et al.",
      "startOffset" : 26,
      "endOffset" : 37
    }, {
      "referenceID" : 52,
      "context" : "Examples include the NIPS (Sra, 2012), IPiano (Ochs et al., 2014), UAG (Ghadimi and Lan, 2016), GIST (Gong et al.",
      "startOffset" : 46,
      "endOffset" : 65
    }, {
      "referenceID" : 21,
      "context" : ", 2014), UAG (Ghadimi and Lan, 2016), GIST (Gong et al.",
      "startOffset" : 13,
      "endOffset" : 36
    }, {
      "referenceID" : 26,
      "context" : ", 2014), UAG (Ghadimi and Lan, 2016), GIST (Gong et al., 2013), IFB (Bot et al.",
      "startOffset" : 43,
      "endOffset" : 62
    }, {
      "referenceID" : 6,
      "context" : ", 2013), IFB (Bot et al., 2016), and nmAPG (Li and Lin, 2015).",
      "startOffset" : 13,
      "endOffset" : 31
    }, {
      "referenceID" : 39,
      "context" : ", 2016), and nmAPG (Li and Lin, 2015).",
      "startOffset" : 19,
      "endOffset" : 37
    }, {
      "referenceID" : 75,
      "context" : "When the regularizer is complicated, such as the nonconvex versions of the fused lasso and overlapping group lasso regularizers (Zhong and Kwok, 2014),",
      "startOffset" : 128,
      "endOffset" : 150
    }, {
      "referenceID" : 75,
      "context" : "Another approach is by using the proximal average (Zhong and Kwok, 2014), which computes and averages the proximal step of each underlying regularizer.",
      "startOffset" : 50,
      "endOffset" : 72
    }, {
      "referenceID" : 39,
      "context" : "However, because the proximal step is only approximate, convergence is usually slower than typical applications of the proximal algorithm (Li and Lin, 2015).",
      "startOffset" : 138,
      "endOffset" : 156
    }, {
      "referenceID" : 30,
      "context" : "For the global consensus problem, standard ADMM converges only when g is convex (Hong et al., 2016).",
      "startOffset" : 80,
      "endOffset" : 99
    }, {
      "referenceID" : 38,
      "context" : "When g is nonconvex, convergence of ADMM is only established for problems of the form minx,y f(x) + g(y) : y = Ax, where matrix A has full row rank (Li and Pong, 2015).",
      "startOffset" : 148,
      "endOffset" : 167
    }, {
      "referenceID" : 35,
      "context" : "More recently, the stochastic variance reduced gradient (SVRG) algorithm (Johnson and Zhang, 2013), which is a variant of the popular stochastic gradient descent with reduced variance in the gradient estimates, has also been extended for problems with nonconvex f .",
      "startOffset" : 73,
      "endOffset" : 98
    }, {
      "referenceID" : 76,
      "context" : "However, the regularizer g is still required to be convex (Reddi et al., 2016a; Zhu and Hazan, 2016).",
      "startOffset" : 58,
      "endOffset" : 100
    }, {
      "referenceID" : 65,
      "context" : "For example, the absolute loss is more robust to outliers than the square loss, and has been popularly used in applications such as image denoising (Yan, 2013), robust dictionary learning (Zhao et al.",
      "startOffset" : 148,
      "endOffset" : 159
    }, {
      "referenceID" : 74,
      "context" : "For example, the absolute loss is more robust to outliers than the square loss, and has been popularly used in applications such as image denoising (Yan, 2013), robust dictionary learning (Zhao et al., 2011) and robust PCA (Candès et al.",
      "startOffset" : 188,
      "endOffset" : 207
    }, {
      "referenceID" : 13,
      "context" : ", 2011) and robust PCA (Candès et al., 2011).",
      "startOffset" : 23,
      "endOffset" : 44
    }, {
      "referenceID" : 28,
      "context" : "When both f and g are convex, ADMM is often the main optimization tool for problem (1) (He and Yuan, 2012).",
      "startOffset" : 87,
      "endOffset" : 106
    }, {
      "referenceID" : 65,
      "context" : "Besides a nonconvex g, we may also want to use a nonconvex loss f , such as `0-norm (Yan, 2013) and capped-`1 norm (Sun et al.",
      "startOffset" : 84,
      "endOffset" : 95
    }, {
      "referenceID" : 58,
      "context" : "Besides a nonconvex g, we may also want to use a nonconvex loss f , such as `0-norm (Yan, 2013) and capped-`1 norm (Sun et al., 2013), as they are more robust to outliers and can obtain better performance.",
      "startOffset" : 115,
      "endOffset" : 133
    }, {
      "referenceID" : 70,
      "context" : "As a last resort, one can use more general nonconvex optimization approaches such as convex concave programming (CCCP) (Yuille and Rangarajan, 2002).",
      "startOffset" : 119,
      "endOffset" : 148
    }, {
      "referenceID" : 67,
      "context" : "Note that this paper extends a shorter version published in the proceedings of the International Conference of Machine Learning (Yao and Kwok, 2016).",
      "startOffset" : 128,
      "endOffset" : 148
    }, {
      "referenceID" : 70,
      "context" : "1 Convex-Concave Procedure (CCCP) The convex-concave procedure (CCCP) (Yuille and Rangarajan, 2002; Lu, 2012) is a popular and general solver for (1).",
      "startOffset" : 70,
      "endOffset" : 109
    }, {
      "referenceID" : 45,
      "context" : "1 Convex-Concave Procedure (CCCP) The convex-concave procedure (CCCP) (Yuille and Rangarajan, 2002; Lu, 2012) is a popular and general solver for (1).",
      "startOffset" : 70,
      "endOffset" : 109
    }, {
      "referenceID" : 29,
      "context" : "It assumes thatF can be decomposed as a difference of convex (DC) functions (Hiriart-Urruty, 1985), i.",
      "startOffset" : 76,
      "endOffset" : 98
    }, {
      "referenceID" : 45,
      "context" : "Sequential convex programming (SCP) (Lu, 2012) improves its efficiency when F is in form of (1).",
      "startOffset" : 36,
      "endOffset" : 46
    }, {
      "referenceID" : 26,
      "context" : "However, its convergence is still slow in general (Gong et al., 2013; Zhong and Kwok, 2014; Li and Lin, 2015).",
      "startOffset" : 50,
      "endOffset" : 109
    }, {
      "referenceID" : 75,
      "context" : "However, its convergence is still slow in general (Gong et al., 2013; Zhong and Kwok, 2014; Li and Lin, 2015).",
      "startOffset" : 50,
      "endOffset" : 109
    }, {
      "referenceID" : 39,
      "context" : "However, its convergence is still slow in general (Gong et al., 2013; Zhong and Kwok, 2014; Li and Lin, 2015).",
      "startOffset" : 50,
      "endOffset" : 109
    }, {
      "referenceID" : 49,
      "context" : "This can be further accelerated to O(1/T 2) by modifying the generation of {xt} as (Beck, 2009; Nesterov, 2013): yt = xt + αt−1 − 1 αt (xt − xt−1), xt+1 = prox 1 L g ( yt − 1 L ∇f(yt) ) ,",
      "startOffset" : 83,
      "endOffset" : 111
    }, {
      "referenceID" : 56,
      "context" : "In particular, NIPS (Sra, 2012), IPiano (Ochs et al.",
      "startOffset" : 20,
      "endOffset" : 31
    }, {
      "referenceID" : 52,
      "context" : "In particular, NIPS (Sra, 2012), IPiano (Ochs et al., 2014) and UAG (Ghadimi and Lan, 2016) allow f to be nonconvex, while g is still required to be convex.",
      "startOffset" : 40,
      "endOffset" : 59
    }, {
      "referenceID" : 21,
      "context" : ", 2014) and UAG (Ghadimi and Lan, 2016) allow f to be nonconvex, while g is still required to be convex.",
      "startOffset" : 16,
      "endOffset" : 39
    }, {
      "referenceID" : 26,
      "context" : "GIST (Gong et al., 2013), IFB (Bot et al.",
      "startOffset" : 5,
      "endOffset" : 24
    }, {
      "referenceID" : 6,
      "context" : ", 2013), IFB (Bot et al., 2016) and nmAPG (Li and Lin, 2015) further remove this restriction and allow g to be nonconvex.",
      "startOffset" : 13,
      "endOffset" : 31
    }, {
      "referenceID" : 39,
      "context" : ", 2016) and nmAPG (Li and Lin, 2015) further remove this restriction and allow g to be nonconvex.",
      "startOffset" : 18,
      "endOffset" : 36
    }, {
      "referenceID" : 59,
      "context" : "This is true for many convex regularizers such as the lasso regularier (Tibshirani, 1996), tree-structured lasso regularizer (Liu and Ye, 2010; Jenatton et al.",
      "startOffset" : 71,
      "endOffset" : 89
    }, {
      "referenceID" : 40,
      "context" : "This is true for many convex regularizers such as the lasso regularier (Tibshirani, 1996), tree-structured lasso regularizer (Liu and Ye, 2010; Jenatton et al., 2011) and sparse group lasso regularizer (Jacob et al.",
      "startOffset" : 125,
      "endOffset" : 166
    }, {
      "referenceID" : 34,
      "context" : "This is true for many convex regularizers such as the lasso regularier (Tibshirani, 1996), tree-structured lasso regularizer (Liu and Ye, 2010; Jenatton et al., 2011) and sparse group lasso regularizer (Jacob et al.",
      "startOffset" : 125,
      "endOffset" : 166
    }, {
      "referenceID" : 32,
      "context" : ", 2011) and sparse group lasso regularizer (Jacob et al., 2009).",
      "startOffset" : 43,
      "endOffset" : 63
    }, {
      "referenceID" : 26,
      "context" : ", nonconvex lasso regularizer (Gong et al., 2013), and usually do not exist for more general cases, e.",
      "startOffset" : 30,
      "endOffset" : 49
    }, {
      "referenceID" : 75,
      "context" : ", nonconvex tree-structured lasso regularizer (Zhong and Kwok, 2014).",
      "startOffset" : 46,
      "endOffset" : 68
    }, {
      "referenceID" : 1,
      "context" : "On the other hand, Zhong and Kwok (2014) used proximal average (Bauschke et al., 2008) to handle complicate g which is in the form g(x) = ∑K i=1 μigi(x), where each gi has a simple proximal step.",
      "startOffset" : 63,
      "endOffset" : 86
    }, {
      "referenceID" : 5,
      "context" : ", 2013), IFB (Bot et al., 2016) and nmAPG (Li and Lin, 2015) further remove this restriction and allow g to be nonconvex. It is desirable that the proximal step has a closed-form solution. This is true for many convex regularizers such as the lasso regularier (Tibshirani, 1996), tree-structured lasso regularizer (Liu and Ye, 2010; Jenatton et al., 2011) and sparse group lasso regularizer (Jacob et al., 2009). However, when g is nonconvex, such solution only exists for some simple g, e.g., nonconvex lasso regularizer (Gong et al., 2013), and usually do not exist for more general cases, e.g., nonconvex tree-structured lasso regularizer (Zhong and Kwok, 2014). On the other hand, Zhong and Kwok (2014) used proximal average (Bauschke et al.",
      "startOffset" : 14,
      "endOffset" : 707
    }, {
      "referenceID" : 19,
      "context" : "3 Frank-Wolfe (FW) Algorithm The FW algorithm (Frank and Wolfe, 1956) is used for solving optimization problems of the form",
      "startOffset" : 46,
      "endOffset" : 69
    }, {
      "referenceID" : 33,
      "context" : "Recently, it has been popularly used in machine learning (Jaggi, 2013).",
      "startOffset" : 57,
      "endOffset" : 70
    }, {
      "referenceID" : 33,
      "context" : "The FW algorithm has a convergence rate of O(1/T ) (Jaggi, 2013).",
      "startOffset" : 51,
      "endOffset" : 64
    }, {
      "referenceID" : 11,
      "context" : "The nuclear norm of X , ‖X‖∗ = ∑m i=1 σi(X), is the tightest convex envelope of rank(X), and is often used as a low-rank regularizer (Candès and Recht, 2009).",
      "startOffset" : 133,
      "endOffset" : 157
    }, {
      "referenceID" : 11,
      "context" : "For example, in matrix completion (Candès and Recht, 2009),",
      "startOffset" : 34,
      "endOffset" : 58
    }, {
      "referenceID" : 73,
      "context" : "The FW algorithm for this nuclear norm regularized problem is shown in Algorithm 1 (Zhang et al., 2012).",
      "startOffset" : 83,
      "endOffset" : 103
    }, {
      "referenceID" : 33,
      "context" : "As in (5), the following linear subproblem has to be solved (Jaggi, 2013): min S:‖S‖∗≤1 〈S,∇f(Xt)〉.",
      "startOffset" : 60,
      "endOffset" : 73
    }, {
      "referenceID" : 33,
      "context" : "The FW algorithm has a convergence rate of O(1/T ) (Jaggi, 2013).",
      "startOffset" : 51,
      "endOffset" : 64
    }, {
      "referenceID" : 36,
      "context" : "To make it empirically faster, Algorithm 1 also performs optimization at step 6 (Laue, 2012; Zhang et al., 2012).",
      "startOffset" : 80,
      "endOffset" : 112
    }, {
      "referenceID" : 73,
      "context" : "To make it empirically faster, Algorithm 1 also performs optimization at step 6 (Laue, 2012; Zhang et al., 2012).",
      "startOffset" : 80,
      "endOffset" : 112
    }, {
      "referenceID" : 57,
      "context" : "Substituting ‖X‖∗ = minX=UV > 1 2 ( ‖U‖F + ‖V ‖F ) (Srebro et al., 2004) into (8), we have the following local optimization problem:",
      "startOffset" : 51,
      "endOffset" : 72
    }, {
      "referenceID" : 73,
      "context" : "Algorithm 1 Frank-Wolfe algorithm for problem (8) with f convex (Zhang et al., 2012).",
      "startOffset" : 64,
      "endOffset" : 84
    }, {
      "referenceID" : 22,
      "context" : "4 Alternating Direction Method of Multipliers (ADMM) ADMM is a simple but powerful algorithm first introduced in the 1970s (Glowinski and Marroco, 1975).",
      "startOffset" : 123,
      "endOffset" : 152
    }, {
      "referenceID" : 9,
      "context" : "Recently, it has been popularly used in diverse fields such as machine learning, data mining and image processing (Boyd et al., 2011).",
      "startOffset" : 114,
      "endOffset" : 133
    }, {
      "referenceID" : 5,
      "context" : "processing and wireless communication (Bertsekas and Tsitsiklis, 1989; Boyd et al., 2011).",
      "startOffset" : 38,
      "endOffset" : 89
    }, {
      "referenceID" : 9,
      "context" : "processing and wireless communication (Bertsekas and Tsitsiklis, 1989; Boyd et al., 2011).",
      "startOffset" : 38,
      "endOffset" : 89
    }, {
      "referenceID" : 30,
      "context" : "When fi is smooth and g is convex, ADMM converges to a critical point of (16) (Hong et al., 2016).",
      "startOffset" : 78,
      "endOffset" : 97
    }, {
      "referenceID" : 20,
      "context" : "Examples include the Geman penalty (GP) (Geman and Yang, 1995), log-sum penalty (LSP) (Candès et al.",
      "startOffset" : 40,
      "endOffset" : 62
    }, {
      "referenceID" : 12,
      "context" : "Examples include the Geman penalty (GP) (Geman and Yang, 1995), log-sum penalty (LSP) (Candès et al., 2008) and Laplace penalty (Trzasko and Manduca, 2009).",
      "startOffset" : 86,
      "endOffset" : 107
    }, {
      "referenceID" : 61,
      "context" : ", 2008) and Laplace penalty (Trzasko and Manduca, 2009).",
      "startOffset" : 28,
      "endOffset" : 55
    }, {
      "referenceID" : 32,
      "context" : "By using different Ai’s, g becomes various structured sparsity regularizers such as the group lasso (Jacob et al., 2009), fused lasso (Tibshirani et al.",
      "startOffset" : 100,
      "endOffset" : 120
    }, {
      "referenceID" : 60,
      "context" : ", 2009), fused lasso (Tibshirani et al., 2005), and graphical lasso (Jacob et al.",
      "startOffset" : 21,
      "endOffset" : 46
    }, {
      "referenceID" : 32,
      "context" : ", 2005), and graphical lasso (Jacob et al., 2009).",
      "startOffset" : 29,
      "endOffset" : 49
    }, {
      "referenceID" : 29,
      "context" : "Since ḡ is concave and ğ is convex, the nonconvex regularizer g = ğ− (−ḡ) can be viewed as a difference of convex functions (DC) (Hiriart-Urruty, 1985).",
      "startOffset" : 129,
      "endOffset" : 151
    }, {
      "referenceID" : 28,
      "context" : "Since ḡ is concave and ğ is convex, the nonconvex regularizer g = ğ− (−ḡ) can be viewed as a difference of convex functions (DC) (Hiriart-Urruty, 1985). Lu (2012); Gong et al.",
      "startOffset" : 130,
      "endOffset" : 163
    }, {
      "referenceID" : 26,
      "context" : "Lu (2012); Gong et al. (2013); Zhong and Kwok (2014) also relied on DC decompositions of the nonconvex regularizer.",
      "startOffset" : 11,
      "endOffset" : 30
    }, {
      "referenceID" : 26,
      "context" : "Lu (2012); Gong et al. (2013); Zhong and Kwok (2014) also relied on DC decompositions of the nonconvex regularizer.",
      "startOffset" : 11,
      "endOffset" : 53
    }, {
      "referenceID" : 40,
      "context" : "(2016) extended proximal algorithm to simple nonconvex g, but cannot handle more complicated nonconvex regularizers such as the tree-structured lasso regularizer (Liu and Ye, 2010; Schmidt et al., 2011), sparse group lasso regularizer (Jacob et al.",
      "startOffset" : 162,
      "endOffset" : 202
    }, {
      "referenceID" : 55,
      "context" : "(2016) extended proximal algorithm to simple nonconvex g, but cannot handle more complicated nonconvex regularizers such as the tree-structured lasso regularizer (Liu and Ye, 2010; Schmidt et al., 2011), sparse group lasso regularizer (Jacob et al.",
      "startOffset" : 162,
      "endOffset" : 202
    }, {
      "referenceID" : 32,
      "context" : ", 2011), sparse group lasso regularizer (Jacob et al., 2009) and total variation regularizer (Nikolova, 2004).",
      "startOffset" : 40,
      "endOffset" : 60
    }, {
      "referenceID" : 51,
      "context" : ", 2009) and total variation regularizer (Nikolova, 2004).",
      "startOffset" : 40,
      "endOffset" : 56
    }, {
      "referenceID" : 1,
      "context" : "Using the proximal average (Bauschke et al., 2008), Zhong and Kwok (2014) can handle nonconvex regularizers of the form g = ∑K i=1 μigi, where each gi is simple.",
      "startOffset" : 27,
      "endOffset" : 50
    }, {
      "referenceID" : 70,
      "context" : "General nonconvex optimization techniques such as the concave-convex procedure (CCCP) (Yuille and Rangarajan, 2002) or its variant sequential convex programming (SCP) (Lu, 2012) can also be used, though they are slow in general (Gong et al.",
      "startOffset" : 86,
      "endOffset" : 115
    }, {
      "referenceID" : 45,
      "context" : "General nonconvex optimization techniques such as the concave-convex procedure (CCCP) (Yuille and Rangarajan, 2002) or its variant sequential convex programming (SCP) (Lu, 2012) can also be used, though they are slow in general (Gong et al.",
      "startOffset" : 167,
      "endOffset" : 177
    }, {
      "referenceID" : 26,
      "context" : "General nonconvex optimization techniques such as the concave-convex procedure (CCCP) (Yuille and Rangarajan, 2002) or its variant sequential convex programming (SCP) (Lu, 2012) can also be used, though they are slow in general (Gong et al., 2013; Zhong and Kwok, 2014).",
      "startOffset" : 228,
      "endOffset" : 269
    }, {
      "referenceID" : 75,
      "context" : "General nonconvex optimization techniques such as the concave-convex procedure (CCCP) (Yuille and Rangarajan, 2002) or its variant sequential convex programming (SCP) (Lu, 2012) can also be used, though they are slow in general (Gong et al., 2013; Zhong and Kwok, 2014).",
      "startOffset" : 228,
      "endOffset" : 269
    }, {
      "referenceID" : 24,
      "context" : "Gong et al. (2013); Li and Lin (2015) and Bot et al.",
      "startOffset" : 0,
      "endOffset" : 19
    }, {
      "referenceID" : 24,
      "context" : "Gong et al. (2013); Li and Lin (2015) and Bot et al.",
      "startOffset" : 0,
      "endOffset" : 38
    }, {
      "referenceID" : 5,
      "context" : "(2013); Li and Lin (2015) and Bot et al. (2016) extended proximal algorithm to simple nonconvex g, but cannot handle more complicated nonconvex regularizers such as the tree-structured lasso regularizer (Liu and Ye, 2010; Schmidt et al.",
      "startOffset" : 30,
      "endOffset" : 48
    }, {
      "referenceID" : 1,
      "context" : "Using the proximal average (Bauschke et al., 2008), Zhong and Kwok (2014) can handle nonconvex regularizers of the form g = ∑K i=1 μigi, where each gi is simple.",
      "startOffset" : 28,
      "endOffset" : 74
    }, {
      "referenceID" : 26,
      "context" : "convergence guarantee for convex and nonconvex f (Gong et al., 2013; Li and Lin, 2015), solving the transformed problem can be much faster.",
      "startOffset" : 49,
      "endOffset" : 86
    }, {
      "referenceID" : 39,
      "context" : "convergence guarantee for convex and nonconvex f (Gong et al., 2013; Li and Lin, 2015), solving the transformed problem can be much faster.",
      "startOffset" : 49,
      "endOffset" : 86
    }, {
      "referenceID" : 32,
      "context" : ", (aN , yN )}, (convex) sparse group lasso is formulated as (Jacob et al., 2009):",
      "startOffset" : 60,
      "endOffset" : 80
    }, {
      "referenceID" : 69,
      "context" : "Its proximal step can be easily computed by the algorithm in (Yuan et al., 2011).",
      "startOffset" : 61,
      "endOffset" : 80
    }, {
      "referenceID" : 39,
      "context" : "In particular, we will adopt the state-of-the-art nonmontonic APG (nmAPG) algorithm (Li and Lin, 2015) (shown in Algorithm 2).",
      "startOffset" : 84,
      "endOffset" : 102
    }, {
      "referenceID" : 40,
      "context" : "2 NONCONVEX TREE-STRUCTURED GROUP LASSO In (convex) tree-structured group lasso (Liu and Ye, 2010; Jenatton et al., 2011), the dimensions in x are organized as nodes in a tree, and each group corresponds to a subtree.",
      "startOffset" : 80,
      "endOffset" : 121
    }, {
      "referenceID" : 34,
      "context" : "2 NONCONVEX TREE-STRUCTURED GROUP LASSO In (convex) tree-structured group lasso (Liu and Ye, 2010; Jenatton et al., 2011), the dimensions in x are organized as nodes in a tree, and each group corresponds to a subtree.",
      "startOffset" : 80,
      "endOffset" : 121
    }, {
      "referenceID" : 40,
      "context" : "Interested readers are referred to (Liu and Ye, 2010) for details.",
      "startOffset" : 35,
      "endOffset" : 53
    }, {
      "referenceID" : 39,
      "context" : "Algorithm 2 Nonmonotonic APG (nmAPG) (Li and Lin, 2015).",
      "startOffset" : 37,
      "endOffset" : 55
    }, {
      "referenceID" : 40,
      "context" : "As shown in (Liu and Ye, 2010), its proximal step can be computed efficiently by processing all the groups once in some appropriate order.",
      "startOffset" : 12,
      "endOffset" : 30
    }, {
      "referenceID" : 51,
      "context" : "Given an image X ∈ Rm×n, the TV regularizer is defined as TV(X) = ‖DvX‖1 + ‖XDh‖1 (Nikolova, 2004), Dv = −1 1 .",
      "startOffset" : 82,
      "endOffset" : 98
    }, {
      "referenceID" : 51,
      "context" : "Thus, it is popular on image processing problems, such as image denoising and deconvolution (Nikolova, 2004; Beck and Teboulle, 2009).",
      "startOffset" : 92,
      "endOffset" : 133
    }, {
      "referenceID" : 2,
      "context" : "Thus, it is popular on image processing problems, such as image denoising and deconvolution (Nikolova, 2004; Beck and Teboulle, 2009).",
      "startOffset" : 92,
      "endOffset" : 133
    }, {
      "referenceID" : 39,
      "context" : "However, Lemma 2 of (Li and Lin, 2015), which is key to the convergence of nmAPG, no longer holds dues to inexact proximal step.",
      "startOffset" : 20,
      "endOffset" : 38
    }, {
      "referenceID" : 54,
      "context" : "In this case, Schmidt et al. (2011) showed that using inexact proximal steps can make proximal algorithms faster.",
      "startOffset" : 14,
      "endOffset" : 36
    }, {
      "referenceID" : 26,
      "context" : "If the proximal step is exact, ‖Vt − prox 1 τ ğ(Vt − 1 τ∇f̄(Vt))‖ 2 F can be used to measure how far Vt is from a critical point (Gong et al., 2013; Ghadimi and Lan, 2016).",
      "startOffset" : 129,
      "endOffset" : 171
    }, {
      "referenceID" : 21,
      "context" : "If the proximal step is exact, ‖Vt − prox 1 τ ğ(Vt − 1 τ∇f̄(Vt))‖ 2 F can be used to measure how far Vt is from a critical point (Gong et al., 2013; Ghadimi and Lan, 2016).",
      "startOffset" : 129,
      "endOffset" : 171
    }, {
      "referenceID" : 68,
      "context" : "Recently, there is growing interest to replace this with nonconvex regularizers (Lu et al., 2014, 2015; Yao et al., 2015; Gui et al., 2016).",
      "startOffset" : 80,
      "endOffset" : 139
    }, {
      "referenceID" : 27,
      "context" : "Recently, there is growing interest to replace this with nonconvex regularizers (Lu et al., 2014, 2015; Yao et al., 2015; Gui et al., 2016).",
      "startOffset" : 80,
      "endOffset" : 139
    }, {
      "referenceID" : 10,
      "context" : "A FW variant allowing nonconvex f̄ is proposed in (Bredies et al., 2009).",
      "startOffset" : 50,
      "endOffset" : 72
    }, {
      "referenceID" : 10,
      "context" : "However, condition 1 in (Bredies et al., 2009) requires g to satisfy lim‖X‖F→∞ g(X) ‖X‖F =∞.",
      "startOffset" : 24,
      "endOffset" : 46
    }, {
      "referenceID" : 50,
      "context" : "(34) This can be efficiently solved using matrix optimization techniques on the Grassmann manifold (Ngo and Saad, 2012).",
      "startOffset" : 99,
      "endOffset" : 119
    }, {
      "referenceID" : 28,
      "context" : "When all the fi’s and g are convex, ADMM has a convergence rate of O(1/T ) (He and Yuan, 2012).",
      "startOffset" : 75,
      "endOffset" : 94
    }, {
      "referenceID" : 30,
      "context" : "Recently, ADMM has been extended to problems where g is convex but fi’s are nonconvex (Hong et al., 2016).",
      "startOffset" : 86,
      "endOffset" : 105
    }, {
      "referenceID" : 30,
      "context" : "4 of (Hong et al., 2016) can now be applied.",
      "startOffset" : 5,
      "endOffset" : 24
    }, {
      "referenceID" : 35,
      "context" : "Examples are stochastic variance reduced gradient (SVRG) (Johnson and Zhang, 2013) and its proximal extension Prox-SVRG (Xiao and Zhang, 2014).",
      "startOffset" : 57,
      "endOffset" : 82
    }, {
      "referenceID" : 64,
      "context" : "Examples are stochastic variance reduced gradient (SVRG) (Johnson and Zhang, 2013) and its proximal extension Prox-SVRG (Xiao and Zhang, 2014).",
      "startOffset" : 120,
      "endOffset" : 142
    }, {
      "referenceID" : 53,
      "context" : "Reddi et al. (2016a) and Zhu and Hazan (2016) considered smooth nonconvex ` but without g.",
      "startOffset" : 0,
      "endOffset" : 21
    }, {
      "referenceID" : 53,
      "context" : "Reddi et al. (2016a) and Zhu and Hazan (2016) considered smooth nonconvex ` but without g.",
      "startOffset" : 0,
      "endOffset" : 46
    }, {
      "referenceID" : 0,
      "context" : "5 With OWL-QN In this section, we consider OWL-QN (Andrew and Gao, 2007) and its variant mOWL-QN (Gong and Ye, 2015b), which are efficient algorithms for the `1-regularization problem min x f(x) + μ‖x‖1.",
      "startOffset" : 50,
      "endOffset" : 72
    }, {
      "referenceID" : 0,
      "context" : "5 With OWL-QN In this section, we consider OWL-QN (Andrew and Gao, 2007) and its variant mOWL-QN (Gong and Ye, 2015b), which are efficient algorithms for the `1-regularization problem min x f(x) + μ‖x‖1. (39) Recently, Gong and Ye (2015a) proposed a nonconvex generalization for (39), in which the standard `1 regularizer is replaced by the nonconvex g(x) = μ ∑d i=1 κ(|xi|):",
      "startOffset" : 51,
      "endOffset" : 239
    }, {
      "referenceID" : 0,
      "context" : "On the other hand, the Hessian in (41) depends only on f̄ , as the Hessian due to ‖x‖1 is zero (Andrew and Gao, 2007), and mOWL-QN now extracts Hessian from f̄ .",
      "startOffset" : 95,
      "endOffset" : 117
    }, {
      "referenceID" : 26,
      "context" : "In particular, the proximal algorithm requires f in (1) to be smooth (possibly nonconvex) (Gong et al., 2013; Li and Lin, 2015; Bot et al., 2016).",
      "startOffset" : 90,
      "endOffset" : 145
    }, {
      "referenceID" : 39,
      "context" : "In particular, the proximal algorithm requires f in (1) to be smooth (possibly nonconvex) (Gong et al., 2013; Li and Lin, 2015; Bot et al., 2016).",
      "startOffset" : 90,
      "endOffset" : 145
    }, {
      "referenceID" : 6,
      "context" : "In particular, the proximal algorithm requires f in (1) to be smooth (possibly nonconvex) (Gong et al., 2013; Li and Lin, 2015; Bot et al., 2016).",
      "startOffset" : 90,
      "endOffset" : 145
    }, {
      "referenceID" : 33,
      "context" : "The FW algorithm requires f in (4) to be smooth and convex (Jaggi, 2013).",
      "startOffset" : 59,
      "endOffset" : 72
    }, {
      "referenceID" : 30,
      "context" : "For the ADMM, it allows f in the consensus problem to be smooth, but g has to be convex (Hong et al., 2016).",
      "startOffset" : 88,
      "endOffset" : 107
    }, {
      "referenceID" : 38,
      "context" : "For problems of the form minx,z f(y) + g(y) : y = Ax, ADMM requires A to have full row-rank (Li and Pong, 2015).",
      "startOffset" : 92,
      "endOffset" : 111
    }, {
      "referenceID" : 70,
      "context" : "CCCP (Yuille and Rangarajan, 2002) and smoothing (Chen, 2012) are more general and can still be used, but are usually very slow.",
      "startOffset" : 5,
      "endOffset" : 34
    }, {
      "referenceID" : 14,
      "context" : "CCCP (Yuille and Rangarajan, 2002) and smoothing (Chen, 2012) are more general and can still be used, but are usually very slow.",
      "startOffset" : 49,
      "endOffset" : 61
    }, {
      "referenceID" : 65,
      "context" : "The use of nonconvex loss and regularizer often produce better performance (Yan, 2013).",
      "startOffset" : 75,
      "endOffset" : 86
    }, {
      "referenceID" : 30,
      "context" : "As (44) is not a consensus problem, the method in (Hong et al., 2016) cannot be used.",
      "startOffset" : 50,
      "endOffset" : 69
    }, {
      "referenceID" : 38,
      "context" : "To use the ADMM algorithm in (Li and Pong, 2015), extra variables and constraints Zv = DvX and Zh = XDh have to be imposed.",
      "startOffset" : 29,
      "endOffset" : 48
    }, {
      "referenceID" : 38,
      "context" : "However, the full row-rank condition in (Li and Pong, 2015) does not hold.",
      "startOffset" : 40,
      "endOffset" : 59
    }, {
      "referenceID" : 49,
      "context" : "As (46) is a smooth and convex problem, both accelerated gradient descent (Nesterov, 2013) and L-BFGS (Nocedal and Wright, 2006) can be applied.",
      "startOffset" : 74,
      "endOffset" : 90
    }, {
      "referenceID" : 66,
      "context" : "2 ROBUST SPARSE CODING The second application is robust sparse coding, which has been popularly used in face recognition (Yang et al., 2011), image analysis (Lu et al.",
      "startOffset" : 121,
      "endOffset" : 140
    }, {
      "referenceID" : 42,
      "context" : ", 2011), image analysis (Lu et al., 2013) and background modeling (Zhao et al.",
      "startOffset" : 24,
      "endOffset" : 41
    }, {
      "referenceID" : 74,
      "context" : ", 2013) and background modeling (Zhao et al., 2011).",
      "startOffset" : 32,
      "endOffset" : 51
    }, {
      "referenceID" : 69,
      "context" : "The proximal step of the convexified regularizer ğ(x) = κ0(λ‖x‖1 + ∑K j=1 μj‖xGj‖2) is obtained using the algorithm in (Yuan et al., 2011).",
      "startOffset" : 119,
      "endOffset" : 138
    }, {
      "referenceID" : 39,
      "context" : "The nmAPG algorithm (Algorithm 2) in (Li and Lin, 2015) is used for optimization.",
      "startOffset" : 37,
      "endOffset" : 55
    }, {
      "referenceID" : 45,
      "context" : "SCP: Sequential convex programming (Lu, 2012), in which the LSP regularizer is decomposed following (24).",
      "startOffset" : 35,
      "endOffset" : 45
    }, {
      "referenceID" : 26,
      "context" : "GIST (Gong et al., 2013): Since the nonconvex regularizer is not separable, the associated proximal operator has no closed-form solution.",
      "startOffset" : 5,
      "endOffset" : 24
    }, {
      "referenceID" : 75,
      "context" : "GD-PAN (Zhong and Kwok, 2014): It performs gradient descent with proximal average (Bauschke et al.",
      "startOffset" : 7,
      "endOffset" : 29
    }, {
      "referenceID" : 1,
      "context" : "GD-PAN (Zhong and Kwok, 2014): It performs gradient descent with proximal average (Bauschke et al., 2008) of the nonconvex regularizers.",
      "startOffset" : 82,
      "endOffset" : 105
    }, {
      "referenceID" : 70,
      "context" : "We do not compare with the concave-convex procedure (Yuille and Rangarajan, 2002), which has been shown to be slow (Gong et al.",
      "startOffset" : 52,
      "endOffset" : 81
    }, {
      "referenceID" : 26,
      "context" : "We do not compare with the concave-convex procedure (Yuille and Rangarajan, 2002), which has been shown to be slow (Gong et al., 2013; Zhong and Kwok, 2014).",
      "startOffset" : 115,
      "endOffset" : 156
    }, {
      "referenceID" : 75,
      "context" : "We do not compare with the concave-convex procedure (Yuille and Rangarajan, 2002), which has been shown to be slow (Gong et al., 2013; Zhong and Kwok, 2014).",
      "startOffset" : 115,
      "endOffset" : 156
    }, {
      "referenceID" : 40,
      "context" : "Following (Liu and Ye, 2010), we resize each image from 256 × 256 to 64 × 64.",
      "startOffset" : 10,
      "endOffset" : 28
    }, {
      "referenceID" : 40,
      "context" : "5),, wi’s are weights (set to be the reciprocal of the size of sample i’s class) used to alleviate class imbalance, and λi = 1/ √ ‖Gi‖1 as in (Liu and Ye, 2010).",
      "startOffset" : 142,
      "endOffset" : 160
    }, {
      "referenceID" : 40,
      "context" : "For the proposed N2C algorithm, the proximal step of the convexified regularizer is obtained as in (Liu and Ye, 2010).",
      "startOffset" : 99,
      "endOffset" : 117
    }, {
      "referenceID" : 68,
      "context" : "The LSP regularizer is used, with θ = √ μ as in (Yao et al., 2015).",
      "startOffset" : 48,
      "endOffset" : 66
    }, {
      "referenceID" : 31,
      "context" : "We use the MovieLens data sets2 (Table 5), which have been commonly used for evaluating matrix completion (Hsieh and Olsen, 2014; Yao et al., 2015).",
      "startOffset" : 106,
      "endOffset" : 147
    }, {
      "referenceID" : 68,
      "context" : "We use the MovieLens data sets2 (Table 5), which have been commonly used for evaluating matrix completion (Hsieh and Olsen, 2014; Yao et al., 2015).",
      "startOffset" : 106,
      "endOffset" : 147
    }, {
      "referenceID" : 68,
      "context" : "FaNCL (Yao et al., 2015): This is a recent nonconvex matrix regularization algorithm.",
      "startOffset" : 6,
      "endOffset" : 24
    }, {
      "referenceID" : 63,
      "context" : "LMaFit (Wen et al., 2012): It factorizes X as a product of low-rank matrices U ∈ Rm×k and V ∈ Rn×k.",
      "startOffset" : 7,
      "endOffset" : 25
    }, {
      "referenceID" : 31,
      "context" : "Active subspace selection (denoted “active”) (Hsieh and Olsen, 2014): This solves the (convex) nuclear norm regularized problem (with κ being the identity function in (8)) by using the active row/column subspaces to reduce the optimization problem size.",
      "startOffset" : 45,
      "endOffset" : 68
    }, {
      "referenceID" : 43,
      "context" : "We do not compare with IRNN (Lu et al., 2014) and GPG (Lu et al.",
      "startOffset" : 28,
      "endOffset" : 45
    }, {
      "referenceID" : 44,
      "context" : ", 2014) and GPG (Lu et al., 2015), which have been shown to be much slower than FaNCL (Yao et al.",
      "startOffset" : 16,
      "endOffset" : 33
    }, {
      "referenceID" : 68,
      "context" : ", 2015), which have been shown to be much slower than FaNCL (Yao et al., 2015).",
      "startOffset" : 60,
      "endOffset" : 78
    }, {
      "referenceID" : 68,
      "context" : "Following (Yao et al., 2015), we use 50% of the ratings for training, 25% for validation and the rest for testing.",
      "startOffset" : 10,
      "endOffset" : 28
    }, {
      "referenceID" : 47,
      "context" : "Moreover, the convex model needs a much higher rank than the nonconvex models, which agrees with the previous observations in (Mazumder et al., 2010; Yao et al., 2015).",
      "startOffset" : 126,
      "endOffset" : 167
    }, {
      "referenceID" : 68,
      "context" : "Moreover, the convex model needs a much higher rank than the nonconvex models, which agrees with the previous observations in (Mazumder et al., 2010; Yao et al., 2015).",
      "startOffset" : 126,
      "endOffset" : 167
    }, {
      "referenceID" : 15,
      "context" : "Eight popular images4 from (Dabov et al., 2007) are used (Figure 7).",
      "startOffset" : 27,
      "endOffset" : 47
    }, {
      "referenceID" : 70,
      "context" : "CCCP (Yuille and Rangarajan, 2002): Proposition 6 is used to construct DC decomposition for κ (Details are at Appendix B.",
      "startOffset" : 5,
      "endOffset" : 34
    }, {
      "referenceID" : 14,
      "context" : "Smoothing (Chen, 2012): The nonsmooth κ is smoothed, and then gradient descent is used (Details are at Appendix B.",
      "startOffset" : 10,
      "endOffset" : 22
    }, {
      "referenceID" : 39,
      "context" : "nmAPG (Li and Lin, 2015): This optimizes (47) with Algorithm 2, and the exact proximal step is solved numerically using CCCP; 4.",
      "startOffset" : 6,
      "endOffset" : 24
    }, {
      "referenceID" : 9,
      "context" : "As a baseline, we also compare with ADMM (Boyd et al., 2011) with the convex formulation.",
      "startOffset" : 41,
      "endOffset" : 60
    }, {
      "referenceID" : 17,
      "context" : "Lemma 15 (Eriksson et al., 2004) Let f : R → R be a differentiable function.",
      "startOffset" : 9,
      "endOffset" : 32
    }, {
      "referenceID" : 17,
      "context" : "Lemma 16 (Eriksson et al., 2004) If a continuous function f : R→ R isL1-Lipschitz continuous in [a, b] and L2-Lipschitz continuous in [b, c] (where −∞ ≤ a < b < c ≤ ∞), then it is max(L1, L2)Lipschitz continuous in [a, c].",
      "startOffset" : 9,
      "endOffset" : 32
    }, {
      "referenceID" : 8,
      "context" : "Lemma 18 (Boyd and Vandenberghe, 2004) φ(x) = π(q(x)) is concave if π is concave, nonincreasing and q is convex.",
      "startOffset" : 9,
      "endOffset" : 38
    }, {
      "referenceID" : 4,
      "context" : "Definition 19 (Bertsekas, 1999) A function f : Rm → R is absolute symmetric if f ([x1; .",
      "startOffset" : 14,
      "endOffset" : 31
    }, {
      "referenceID" : 37,
      "context" : "Lemma 20 (Lewis and Sendov, 2005) Let σ(X) = [σ1(X); .",
      "startOffset" : 9,
      "endOffset" : 33
    }, {
      "referenceID" : 37,
      "context" : "Lemma 21 (Lewis and Sendov, 2005) Let the SVD of X be UDiag(σ(X))V >, where σ(X) = [σ1(X); .",
      "startOffset" : 9,
      "endOffset" : 33
    }, {
      "referenceID" : 8,
      "context" : "Lemma 22 (Boyd and Vandenberghe, 2004) φ(x) = π(q(x)) is convex if π is convex, nondecreasing and q is convex.",
      "startOffset" : 9,
      "endOffset" : 38
    }, {
      "referenceID" : 48,
      "context" : "Proposition 24 (Mishra et al., 2013) For a square matrix X , let sym(X) = 12(X + X >).",
      "startOffset" : 15,
      "endOffset" : 36
    }, {
      "referenceID" : 62,
      "context" : "Proof Subdifferential of the nuclear norm can be obtained as (Watson, 1992) ∂‖X‖∗ = {UV > +W : U>W = 0,WV = 0, ‖W‖∞ ≤ 1}, (70) where X = UBV >.",
      "startOffset" : 61,
      "endOffset" : 75
    } ],
    "year" : 2017,
    "abstractText" : "The use of convex regularizers allows for easy optimization, though they often produce biased estimation and inferior prediction performance. Recently, nonconvex regularizers have attracted a lot of attention and outperformed convex ones. However, the resultant optimization problem is much harder. In this paper, for a large class of nonconvex regularizers, we propose to move the nonconvexity from the regularizer to the loss. The nonconvex regularizer is then transformed to a familiar convex regularizer, while the resultant loss function can still be guaranteed to be smooth. Learning with the convexified regularizer can be performed by existing efficient algorithms originally designed for convex regularizers (such as the proximal algorithm, FrankWolfe algorithm, alternating direction method of multipliers and stochastic gradient descent). Extensions are made when the convexified regularizer does not have closed-form proximal step, and when the loss function is nonconvex, nonsmooth. Extensive experiments on a variety of machine learning application scenarios show that optimizing the transformed problem is much faster than running the state-of-the-art on the original problem.",
    "creator" : "LaTeX with hyperref package"
  }
}