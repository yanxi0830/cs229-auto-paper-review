{
  "name" : "1606.09333.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "Dimension-Free Iteration Complexity of Finite Sum Optimization Problems",
    "authors" : [ "Yossi Arjevani", "Ohad Shamir" ],
    "emails" : [ "yossi.arjevani@weizmann.ac.il", "ohad.shamir@weizmann.ac.il" ],
    "sections" : [ {
      "heading" : "1 Introduction",
      "text" : "Many machine learning tasks reduce to Finite Sum Minimization (FSM) problems of the form\nmin x∈Rd\nF (w) := 1\nn n∑ i=1 fi(w), (1)\nwhere fi are L-smooth and µ-strongly convex. In recent years, a major breakthrough was made when a linear convergence rate was established for this setting (SAG [16] and SDCA [18]), and since then, many methods have been developed to achieve better convergence rate. However, whereas a large body of literature is devoted for upper bounds, the optimal convergence rate with respect to the problem parameters is not quite settled.\nLet us discuss existing lower bounds for this setting, along with their shortcomings, in detail. One approach to obtain lower bounds for this setting is to consider the average of carefully handcrafted functions defined on n disjoint sets of variables. This approach was taken by Agarwal and Bottou [1] who derived a lower bound for FSM under the first-order oracle model (see Nemirovsky and Yudin [12]). In this model, optimization algorithms are assumed to access a given function by issuing queries to an external first-order oracle procedure. Upon receiving a query point in the problem domain, the oracle reports the corresponding function value and gradient. The construction used by Agarwal and Bottou consisted of n different quadratic functions which are adversarially determined based on the first-order queries being issued during the optimization process. The resulting bound in this case does not apply to stochastic algorithms, rendering it invalid for current state-of-the-art methods. Another instantiation of this approach was made by\nar X\niv :1\n60 6.\n09 33\n3v 1\n[ m\nat h.\nO C\n] 3\n0 Ju\nn 20\nLan [10] who considered n disjoint copies of a quadratic function proposed by Nesterov in [13, Section 2.1.2]. This technique is based on the assumption that any iterate generated by the optimization algorithm lies in the span of previously acquired gradients. This assumption is rather permissive and is satisfied by many first-order algorithms, e.g., SAG and SAGA [6]. However, the lower bound stated in the paper faces limitations in a few aspects. First, the validity of the derived bound is restricted to d/n iterations. In many datasets, even if d, n are very large, d/n is quite small. Accordingly, the admissible regime of the lower bound is often not very interesting. Secondly, it is not clear how the proposed construction can be expressed as a Regularized Loss Minimization (RLM) problem with linear predictors (see Section 4). This suggests that methods specialized in dual RLM problems, such as SDCA and accelerated proximal SDCA [19], can not be addressed by this bound. Thirdly, at least the formal theorem requires assumptions (such as querying in the span of previous gradients, or sampling from a fixed distribution over the individual functions), which are not met by some state-of-the-art methods, such as coordinate descent methods, SVRG [9] and without-replacements sampling algorithms [15].\nAnother relevant approach in this setting is to model the functional form of the update rules. This approach was taken by Arjevani et al. [3] where new iterates are assumed to be generated by a recurrent application of some fixed linear transformation. Although this method applies to SDCA and produces a tight lower bound of Ω̃((n+ 1/λ) ln(1/ )), its scope is rather limited. In recent work, Arjevani and Shamir [5] considerably generalized parts of this framework by introducing the class of first-order oblivious optimization algorithms, whose step sizes are scheduled regardless of the function under consideration, and deriving tight lower bounds for general smooth convex minimization problems (note that obliviousness rules out, e.g., quasi-Newton methods where gradients obtained at each iteration are multiplied by matrices which strictly depend on the function at hand, see Definition 2 below).\nIn this work, building upon the framework of oblivious algorithms, we take a somewhat more abstract point of view which allows us to easily incorporate coordinate-descent methods, as well as stochastic algorithms. Our framework subsumes the vast majority of optimization methods for machine learning problems, in particular, it applies to SDCA, accelerated proximal SDCA, SDCA without duality [17], SAG, SAGA, SVRG and acceleration schemes [7, 11]), as well as for a large number of methods for smooth convex optimization (i.e., FSM with n = 1), e.g., (stochastic) Gradient descent (GD), Accelerated Gradient Descent (AGD, [13]), the Heavy-Ball method (HB, [14]) and stochastic coordinate descent.\nUnder this structural assumption, we derive lower bounds for FSM (1), according to which the iteration complexity, i.e., the number of iterations required to obtain an -optimal solution in terms of function value, is at least1\nΩ̃(n+ √ n(κ− 1) ln(1/ )), (2)\nwhere κ denotes the condition number of F (w) (that is, the smoothness parameter over the strong convexity parameter). To the best of our knowledge, this is the first tight lower bound to address all the algorithms mentioned above. Moreover, our bound is dimension-free and thus apply to settings in machine learning which are not covered in the current literature (e.g., when n is Ω(d)). We also derive a dimension-free nearly-optimal lower bound for smooth convex optimization of\nΩ ( (L(δ − 2)/ )1/δ ) , δ ∈ (2, 4),\nwhich holds for any oblivious stochastic first-order algorithm. It should be noted that our lower bounds remain valid under any source of randomness which may be introduced into the optimization process (by the\n1Following standard conventions, here tilde notation hides logarithmic factors in the parameters of a given class of optimization problems, e.g., smoothness parameter and number of components.\noracle or by the optimization algorithm). In particular, our bounds hold in cases where the variance of the iterates produced by the algorithm converges to zero, a highly desirable property of optimization algorithms in this setting.\nTwo implications can be readily derived from this lower bound. First, obliviousness forms a real barrier for optimization algorithms, and whereas non-oblivious algorithms may achieve a super-linear convergence rate at latter stages of the optimization process (e.g., quasi-newton), or practically zero error after Θ(d) iterations (e.g. Center of Gravity method, MCG), oblivious algorithms are bound to linear convergence indefinitely, as demonstrated by Figure 1. We believe that this indicates that a major progress can be made in solving machine learning problems by employing non-oblivious methods for settings where d n. It should be further noted that another major advantage of non-oblivious algorithms is their ability to obtain optimal convergence rates without an explicit specification of the problem parameters (e.g., [5, Section 4.1]).\nSecondly, many practitioners have noticed that oftentimes sampling the individual functions without replacement at each iteration performs better than sampling with replacement (e.g., [18, 15], see also [8, 20]). The fact that our lower bound holds regardless of how the individual functions are sampled and is attained using with-replacement sampling (e.g., accelerated proximal SDCA), implies that, in terms of iteration complexity, one should expect to gain no more than log factors in the problem parameters when using one method over the other (it is noteworthy that when comparing with and without replacement samplings, apart from iteration complexity, other computational resources, such as limited communication in distributed settings [4], may significantly affect the overall runtime)."
    }, {
      "heading" : "2 Framework",
      "text" : ""
    }, {
      "heading" : "2.1 Motivation",
      "text" : "Due to difficulties which arise when studying the complexity of general optimization problems under discrete computational models, it is common to analyze the computational hardness of optimization algorithms by modeling the way a given algorithm interacts with the problem instances (without limiting its computational resources). In the seminal work of Nemirovsky and Yudin [12], it is shown that algorithms which access the\nfunction at hand exclusively by querying a first-order oracle require at least Ω̃ ( min { d, √ κ } ln(1/ ) ) , µ > 0 (3)\nΩ̃(min{d ln(1/ ), √ L/ }), µ = 0\noracle calls to obtain an -optimal solution (note that, here and throughout this section we refer to FSM problems with n = 1). This lower bound is tight and its dimension-free part is attained by Nesterov’s well-known accelerated gradient descent, and by MCG otherwise. The fact that this approach is based on information considerations alone is very appealing and renders it valid for any first-order algorithm. However, discarding the resources needed for executing a given algorithm, in particular the per-iteration cost (in time and space), the complexity boundaries drawn by this approach are too crude from a computational point of view. Indeed, the per-iteration cost of MCG, the only method known with oracle complexity of O(d ln(1/ )), is excessively high, rendering it prohibitive for high-dimensional problems.\nWe are thus led into the question of how well can a given optimization algorithm perform assuming that its per-iteration cost is constrained? Arjevani et al. [3, 5] adopted a more structural approach where instead of modeling how information regarding the function at hand is being collected, one models the update rules according to which iterates are being generated. Concretely, they proposed the framework of p-CLI optimization algorithms where, roughly speaking, new iterates are assumed to form linear combinations of the previous p iterates and gradients, and the coefficients of these linear combinations are assumed to be either stationary (i.e., remain fixed throughout the optimization process) or oblivious. Based on this structural assumption, they showed that the iteration complexity of minimizing smooth and strongly convex functions is Ω̃( √ κ ln(1/ )). The fact that this lower bound is stronger than (3), in the sense that it does not depend on the dimension, confirms that controlling the functional form of the update rules allows one to derive tighter lower bounds. The framework of p-CLIs forms the nucleus of our formulation below."
    }, {
      "heading" : "2.2 Definitions",
      "text" : "When considering lower bounds one must be very precise as to the scope of optimization algorithms to which they apply. Below, we give formal definitions for oblivious stochastic CLI optimization algorithms and iteration complexity (which serves as a crude proxy for their computational complexity).\nDefinition 1 (Class of Optimization Problems). A class of optimization problems is an ordered triple (F , I,O), where F is a family of functions defined over some linear space designated by domF , I is the side-information given prior to the optimization process and Of : domF ×Θ→ domF is a suitable oracle parametrized by some parameters set Θ, i.e., an external procedure which upon receiving x ∈ domF and θ ∈ Θ, returns some Of (θ) ∈ dom(F).\nFor example, in FSM, F contains functions as defined in (1), the side-information contains the smooth parameter L, the strong convexity parameter µ and the number of components n (although it carries a crucial effect on the iteration complexity, e.g., [5], in this work, we shall ignore the side-information and assume that all the parameters of the class are given). We shall assume that both first-order and coordinate-descent oracles (see 10,11 below) are allowed to be used during the optimization process. Formally, this is done by introducing an additional parameter which indicates which oracle is being addressed. This added degree of freedom does not violate our lower bounds.\nWe now turn to rigorously define CLI optimization algorithms. Note that, compared with the definition of first-order p-CLIs provided in [5], here, in order to handle coordinate-descent and first-order oracles in a unified manner, we base our formulation on general oracle procedures.\nDefinition 2 (CLI). An optimization algorithm is called a Canonical Linear Iterative (CLI) optimization algorithm over a class of optimization problems (F , I,O), if given an instance f ∈ F and initialization points {w(0)i }i∈J ⊆ dom(F), where J is some index set, it operates by iteratively generating points such that for any i ∈ J ,\nw (k+1) i ∈ ∑ j∈J Of ( w (k) j ; θ (k) ij ) , k = 0, 1, . . . (4)\nholds, where θ(k)ij ∈ Θ are parameters chosen, stochastically or deterministically, by the algorithm, possibly depending on the side-information. If the parameters do not depend on previously acquired oracle answers, we say that the given algorithm is oblivious. Lastly, algorithms with |J | ≤ p, for some p ∈ N, are denoted by p-CLI.\nNote that assigning different weights to different terms in (4) can be done through θ(k)ij ∈ Θ (e.g., oracle 10 below). This allows a succinct definition for obliviosity. Lastly, we define iteration complexity.\nDefinition 3 (Iteration Complexity). The iteration complexity of a given CLI w.r.t. a given problem class (F , I,O) is defined to be the minimal number of iterations K such that\nE[f(w(k)1 )− min w∈domF f(w)] < , ∀f ∈ F , k ≥ K\nwhere the expectation is taken over all the randomness introduced into the optimization process (choosing w\n(k) 1 merely serves as a convention and is not necessary for our bounds to hold)."
    }, {
      "heading" : "2.3 Proof Technique - Deriving Lower Bounds via Approximation Theory",
      "text" : "Consider the following parametrized class of L-smooth and µ-strongly convex optimization problems,\nmin x∈R\nfη(x) := ηw2\n2 − w, η ∈ [µ,L]. (5)\nClearly, the minimizer of fη are w∗(η) := 1/η, with norm bounded by 1/µ. For simplicity, we will consider a special case, namely, vanilla gradient descent (GD) with step size 1/L, which produces new iterates as follows\nw(k+1)(η) = w(k)(η)− 1 L f ′η(w\n(k)(η)) = (\n1− η L\n) w(k)(η) + 1\nL .\nSetting the initialization point to be w(0)(η) = 0, we derive an explicit expression for w(k)(η):\nw(k)(η) = 1\nL k−1∑ i=0 (−1)i ( k i+ 1 ) (η/L)i. (6)\nIt turns our that each w(k)(η) forms a univariate polynomial whose degree is at most k. Furthermore, since fη(w) are L-smooth µ-strongly convex for any η ∈ [µ,L], standard convergence analysis for GD (e.g., [13], Theorem 2.1.14) guarantees that |w(k)(η)− w∗(η)| ≤ (1− 2/(1 + κ)) k 2 |w∗(η)|, where κ denotes the condition number. Substituting Equation (6) for w(k)(η) yields\nmax η∈[µ,L] ∣∣∣∣∣ 1L k−1∑ i=0 (−1)i ( k i+ 1 ) (η/L)i − 1/η ∣∣∣∣∣ ≤ 1µ ( 1− 2 1 + κ ) k 2 .\nThus, we see that the faster the convergence rate of a given optimization algorithm is, the better the induced sequence of polynomials (w(k)(η))k≥0 approximate 1/η w.r.t. the maximum norm ‖ · ‖L∞([µ,L]) over [µ,L]. In Fig. 2, we compare the first 4 polynomials induced by GD and AGD. Not surprisingly, AGD polynomials approximates 1/η better than those of GD.\nNow, one may ask, assuming that iterates of a given optimization algorithm A for (5) can be expressed as polynomials sk(η) whose degree does not exceed the iteration number, just how fast can these iterates converge to the minimizer? Since the convergence rate is bounded from below by ‖sk(η)− 1/η‖L∞([µ,L]), we may address the following question instead:\nmin s(η)∈Pk ‖s(η)− 1/η‖L∞([µ,L]), (7)\nwhere Pk denotes the set of univariate polynomials whose degree does not exceed k. Problem (7) and other related settings are main topics of study in approximation theory. Accordingly, our technique for proving lower bounds makes an extensive use of tools borrowed from this area. Specifically, in a paper from 1899 [21] Chebyshev showed that\nmin s(η)∈Pk ∥∥∥∥s(η)− 1η − c ∥∥∥∥ L∞([−1,1]) ≥ (c− √ c2 − 1)k c2 − 1 , c > 1, (8)\nby which we derive the following theorem (see Appendix A.1 for a detailed proof). Theorem 1. The number of iterations required by A to get an -optimal solution is Ω̃( √ κ ln(1/ )).\nIn the following sections, we apply oblivious CLI on various parameterized optimization problems so that the resulting iterates are polynomials in the problem parameters. We then apply arguments similar to the above\nA similar reduction, from optimization problems to approximation problems, was used before in a few contexts to analyze the iteration complexity of deterministic CLIs (e.g., [5, Section 3], see also Conjugate Gradient convergence analysis [14]). But, what if we allow random algorithms? should we expect the same iteration complexity? To answer this, we use Yao’s minimax principle according to which the performance of a given stochastic optimization algorithm w.r.t. to its worst input are bounded from below by the performance of the best deterministic algorithm w.r.t. distributions over the input space. Thus, following a similar reduction one can show that the convergence rate of stochastic algorithms is bounded from below by\nmin s(η)∈Pk ∫ L µ |s(η)− 1/η| 1 L− µ dη. (9)\nThat is, a lower bound for the stochastic case can be attained by considering an approximation problem w.r.t. weighted L1 with the uniform distribution over [µ,L]. Other approximation problems considered in this work involve L2-norm and different distributions. We provide a schematic description of our proof technique in Scheme 2.1.\nSCHEME 2.1 FROM OPTIMIZATION PROBLEMS TO APPROXIMATION PROBLEMS GIVEN A CLASS OF FUNCTIONS F , A SUITABLE ORACLE O AND A SEQUENCE OF SETS OF FUNCTION Sk OVER SOME PARAMETERS SET H . CHOOSE A SUBSET OF FUNCTIONS {fη ∈ F|η ∈ H}, S.T. wk(η) ∈ Sk . COMPUTE THE MINIMIZER w∗(η) FOR ANY fη BOUND FROM BELOW THE BEST APPROXIMATION FOR w∗(η) W.R.T. Sk\nAND A NORM ‖ · ‖, I.E., min{‖s(η)−w∗(η)‖ | s(η) ∈ Sk}"
    }, {
      "heading" : "3 Lower Bound for Finite Sums Minimization Methods",
      "text" : "Having described our analytic approach, we now turn to present some concrete applications, starting with iteration complexity lower bounds in the context of FSM problems (1). In what follows, we derive a lower bound on the iteration complexity of oblivious (possibly stochastic) CLI algorithms equipped with first-order and coordinate-descent oracles for FSM. Strictly speaking, we focus on optimization algorithms equipped with both generalized first order oracle,\nO(w;A,B,C, j) = A∇fj(w) +Bw + C, A,B,C ∈ Rd×d, j ∈ [n], (10)\nand steepest coordinate-descent oracle\nO(w; i, j) = w + t∗ei, t∗ ∈ argmin t∈R fj(w1, . . . , wi−1, wi + t, wi+1, . . . , wd), j ∈ [n], (11)\nwhere ei denotes the i’th unit vector. We remark that coordinate-descent steps w.r.t. partial gradients can be implemented using (10) by setting A to be some principal minor of the unit matrix.It should be further noted that our results below hold for scenarios where the optimization algorithm is free to call a different oracle at different iterations.\nFirst, we sketch the proof of the lower bound for deterministic oblivious CLIs. Following Scheme 2.1, we restrict our attention to a parameterized subset of problems. We assume2 d > 1 and denote byHFSM the set of all (η1, . . . , ηn) ∈ Rn such that all the entries equal −(L− µ)/2, except for some j ∈ [n], for which ηj ∈ [−(L− µ)/2, (L− µ)/2]. Now, given η := (η1, . . . , ηn) ∈ HFSM we define\nFη(w) := 1\nn n∑ i=1 ( 1 2 w>Qηiw − q ) ,where (12)\nQηi :=  L+µ 2 ηi ηi L+µ 2 µ . . .\nµ\n , q :=  Rµ√ 2 Rµ√ 2\n0 ... 0\n .\nIt is easy to verify that the minimizers of (12) are\nw∗(η) =  Rµ√ 2 ( L+µ 2 + 1 n ∑n i=1 ηi ) , Rµ√ 2 ( L+µ 2 + 1 n ∑n i=1 ηi ) , 0, . . . , 0 > . (13)\nWe would like to show that the coordinates of the iterates of deterministic oblivious CLIs, which minimize Fη using first-order and coordinate-descent oracles, form multivariate polynomials in η of total degrees (the maximal sum of powers over all the terms) which does not exceed the iteration number. Indeed, if the coordinates of w(k)i (η) are multivariate polynomial in η of total degree at most k, then the coordinates of the vectors returned by both oracles\nFirst-order oracle: O(w(k)j ;A,B,C, j) = A(Qηjw (k) i − q) +Bw (k) i + C, (14) Coordinate-descent oracle: O(w(k)j ; i, j) = ( I − (1/(Qηj )ii)ei(Qηj )i,∗ ) w (k) i − qi/(Qηj )iiei,\nare multivariate polynomials of total degree of at most k + 1, as all the parameters (A,B,C, i and j) do not depend on η (due to obliviosity) and the rest of the terms (Qηj ,q, I, 1/(Qηj )ii, (Qηj )i,∗, ei and qi) are either linear in ηj or constants. Now, since the next iterates are generated simply by summing up all the oracle answers, they also form multivariate polynomials of total degree of at most k + 1. Thus, denoting the first coordinate of w(k)1 (η) by s(η) and using Inequality (8), we get the following bound\nmax η∈HFSM\n‖w(k)1 (η)−w ∗(η)‖ ≥ ∥∥∥∥∥∥s(η)− Rµ√2(L+µ2 + 1n∑ni=1 ηi) ∥∥∥∥∥∥ L∞([µ,L])\n(15)\n≥ Ω(1)\n √\nκ−1 n + 1− 1√ κ−1 n + 1 + 1 k/n, (16) where Ω(1) designates a constant which does not depend on k (but may depend on the problem parameters). Lastly, this implies that for any deterministic oblivious CLI and any iteration number, there exists some\n2Clearly, in order to derive a lower bound for coordinate-descent algorithms, we must assume d > 1. If only a first-order oracle is allowed, then the same lower bound as in Theorem 2 can be derived for d = 1.\nη ∈ HFSM such that the convergence rate of the algorithm, when applied on Fη, is bounded from below by Inequality (16). We note that, as opposed to other related lower bounds, e.g., [10], our proof is nonconstructive. As discussed in subsection 2.3, this type of analysis can be extended to stochastic algorithms by considering (15) w.r.t. other norms such as weighted L1-norm. We now arrive at the following theorem whose proof, including the corresponding logarithmic factors and constants, can be found in Appendix A.2.\nTheorem 2. The iteration complexity of oblivious (possibly stochastic) CLIs for FSM (1) equipped with first-order (10) and coordinate-descent oracles (11), is bounded from below by\nΩ̃(n+ √ n(κ− 1) ln(1/ )).\nThe lower bound stated in Theorem 2 is tight and is attained by, e.g., SAG combined with an acceleration scheme (e.g., [11]). Moreover, as mentioned earlier, our lower bound does not depend on the problem dimension (or equivalently, holds for any number of iterations, regardless of d and n), and covers coordinate descent methods with stochastic or deterministic coordinate schedule (in the special case where n = 1, this gives a lower bound for minimizing smooth and strongly convex functions by performing steepest coordinate descent steps). Also, our bound implies that using mini-batches for tackling FSM does not reduce the overall iteration complexity. Lastly, it is noteworthy that the n term in the lower bound above holds for any algorithm accompanied with an incremental oracle, which grants access to at most one individual function each time.\nWe also derive a nearly-optimal lower bound for smooth non-strongly convex functions for the more restricted setting of n = 1 and first-order oracle. The parameterized subset of functions we use (see Scheme 2.1) is gη(x) := η2 ‖x‖\n2 − Rηe>1 x, η ∈ (0, L]. The corresponding minimizer (as a function of η) is x∗(η) = Re1, and in this case we seek to approximate it w.r.t. L2-norm using k-degree univariate polynomials whose constant term vanishes. The resulting bound is dimension-free and improves upon other bounds for this setting (e.g. [5]) in that it applies to deterministic algorithms, as well as to stochastic algorithms (see A.3 for proof).\nTheorem 3. The iteration complexity of any oblivious (possibly stochastic) CLI forL-smooth convex functions equipped with a first-order oracle, is bounded from below by\nΩ ( (L(δ − 2)/ )1/δ ) , δ ∈ (2, 4)."
    }, {
      "heading" : "4 Lower Bound for Dual Regularized Loss Minimization with Linear Predictors",
      "text" : "The form of functions (12) discussed in the previous section does not readily adapt to general RLM problems with linear predictors, i.e.,\nmin w∈Rd\nP (w) := 1\nn n∑ i=1 φi(〈xi,w〉) + λ 2 ‖w‖2 , (17)\nwhere the loss functions φi are L-smooth and convex, the samples x1, . . . ,xn are d-dimensional vectors in Rd and λ is some positive constant. Thus, dual methods which exploit the added structure of this setting through the dual problem [18],\nmin α∈Rn\nD(α) = 1\nn n∑ i=1 φ∗i (−αi) + λ 2 ∥∥∥∥∥ 1λn n∑ i=1 xiαi ∥∥∥∥∥ 2 , (18)\nsuch as SDCA and accelerated proximal SDCA, are not covered by Theorem 2. Accordingly, in this section, we address the iteration complexity of oblivious (possibly stochastic) CLI algorithms equipped with dual RLM oracles:\nO(α; t, j) = α+ t∇jD(α)ej , t ∈ R, j ∈ [n], (19) O(α; j) = α+ t∗ej , t∗ = argmin\nt∈R D(α1, . . . , αj−1, αj + t, αj+1, . . . , αd), j ∈ [n],\nFollowing Scheme 2.1, we first describe the relevant parametrized subset of RLM problems. For the sake of simplicity, we assume that n is even (the proof for odd n holds mutatis mutandis). We denote by HRLM the set of all (ψ1, . . . , ψn/2) ∈ Rn/2 such that all entries are 0, except for some j ∈ [n/2], for which ψj ∈ [−π/2, π/2]. Now, given ψ ∈ HRLM, we set Pψ (defined in 17) as follows\nφi(w) = 1\n2 (w + 1)2, xψ,i = { cos(ψ(i+1)/2)ei + sin(ψ(i+1)/2)ei+1 i is odd ei o.w. .\nWe state below the corresponding lower bound, whose proof, including logarithmic factors and constants, can be found in Appendix A.4.\nTheorem 4. The iteration complexity of oblivious (possibly stochastic) CLIs for RLM (17) equipped with dual RLM oracles (19) is bounded from below by\nΩ̃(n+ √ nL/λ ln(1/ )).\nThis bound is tight w.r.t. the class of oblivious CLIs and is attained by accelerated proximal SDCA. As mentioned earlier, a tighter lower bound of Ω̃((n+ 1/λ) ln(1/ )) is known for SDCA [3], suggesting that a tighter bound might hold for the more restricted set of stationary CLIs (for which the oracle parameters remain fixed throughout the optimization process)."
    }, {
      "heading" : "A Proofs",
      "text" : ""
    }, {
      "heading" : "A.1 Proof of Theorem 1",
      "text" : "Proof According to the way A generates iterates, we have\n|x(k)(η)− x∗(η)| = |sk(η)− 1/η|, η ∈ [µ,L]\nfor some polynomial sk(η) of degree at most k. By Lemma 6, we have\nmin s(η)∈Pk ∥∥∥∥s(η)− 1η ∥∥∥∥ L∞([µ,L]) ≥ L− µ 2Lµ (√ κ− 1√ κ+ 1 )k ,\nwhere κ = L/µ. Thus,\n|x(k)(η)− x∗(η)| ≥ min s(η)∈Pk ∥∥∥∥s(η)− 1η ∥∥∥∥ L∞([µ,L]) ≥ L− µ 2Lµ (√ κ− 1√ κ+ 1 )k ≥ |x∗(η)|L− µ 2L (√ κ− 1√ κ+ 1 )k .\nNow, since fη is µ-strongly convex, we have,\nf(x(k)(η))− f(x∗(η))| ≥ µ 2 |x(k)(η)− x∗(η)|2\n≥ µ 2\n( |x∗(η)|L− µ\n2L (√ κ− 1√ κ+ 1 )k)2\n= µ\n2\n( |x∗(η)|L− µ\n2L )2(√κ− 1√ κ+ 1 )2k .\nHence, by Lemma 12, the minimal number of iterations required to get an -optimal solution is at least\n1\n4\n√ κ− 1 ( ln µ\n2 + 2 ln\n( |x∗(η)|L− µ\n2L\n) + ln(1/ ) ) ."
    }, {
      "heading" : "A.2 Proof of Theorem 2 - Finite Sums",
      "text" : "When dealing with multivariate polynomials it is convenient to define multi-indices i = (i1, . . . , in) ∈ Nn0 , where Nn0 is the set of all n-tuples of non-negative integers. In addition, with a slight abuse of notation, we define\nPnk := span { ηi | i ∈ Nn0 , |i| ≤ k } , (20)\nwhere we put ηi = ηi11 · · · ηinn and |i| = i1 + · · ·+ in. In words, Pnk is the set of all multivariate polynomials over n indeterminates whose total degree (the maximal sum of the degrees over all terms) is less than or equal to k. Lastly, given s(η) ∈ Pnk we define\nsi(ηi) := s −L− µ 2 , . . . ,−L− µ 2\n, ηi︸︷︷︸ i’th entry ,−L− µ 2 , . . . ,−L− µ 2\n .\nThis notation will come in handy in the main proof. The lemma below describes the functional form assumed by iterates produced by oblivious CLIs.\nLemma 1. When applied on (12) with suitable first-order and coordinate-descent oracles (as defined in 14), the coordinates of iterates produced by oblivious stochastic CLIs form multivariate polynomials in η with random real coefficients whose total degree does not exceed the iteration number.\nProof Let A be a oblivious stochastic CLI, and suppose we apply A on the class of problems (12) parameterized by η, using both first-order and coordinate-descent oracles as defined in 14. We use mathematical induction to show that for any k = 0, 1, . . . , the coordinate of the k’th iterate produced by such process can be expressed as a distribution over multivariate polynomials in η of degree at most k.\nAs the first iterate w(0)i is allowed to depend only on L, µ and n, the base case is trivial. That is, the coordinates of w(0)i form distributions over R = Pn0 which do not depend on η.\nFor the inductive step, assume that any coordinate of w(k)i (η) can be expressed as a distribution over Pnk . It is easy to see that for any w(k)i (η), the answers of both oracles,\nFirst-order oracle: O(w(k)i ;A,B,C, j) = A(Qηjw (k) i − q) +Bw (k) i + C, Coordinate-descent oracle: O(w(k)i ; i, j) = ( I − (1/(Qηj )ii)ei(Qηj )i,∗ ) w (k) i − qi/(Qηj )iiei,\nform a distribution over Pnk+1, as all the random quantities involved in the expressions (A,B,C, i and j) do not depend on η1, . . . , ηn (due to obliviosity) and the rest of the terms (I,Qηj , 1/(Qηj )ii, (Qηj )i,∗, ei, qi and q) are either linear in ηj or constants. Lastly, w (k+1) i are computed by simply summing up all the oracle answers, and as such, form again distributions over Pnk+1.\nProof [Theorem 2] Let A be a oblivious stochastic CLI. By Lemma 1 the first coordinate of w(k)1 (η) (the point returned by the algorithm at the k’th iteration) when applied on the class of problems (12) distributes according to some distributionD over Pnk . Thus, by Yao principle, since each polynomial in (Pnk )d represents a single deterministic algorithm, we have\nmax η∈H E w (k) 1 (η)∼D\n‖w(k)1 (η)−w ∗(η)‖ ≥ min s(η)∈(Pnk )d Eη∼U(H)‖s(η)−w∗(η)‖ (21)\nwhere U(H) denotes a distribution over H which corresponds to first drawing j ∼ U([n]) at random, and then setting the coordinates of η as follows{\nηi ∼ U([−(L− µ)/2, (L− µ)/2] i = j ηi = −L−µ2 , i 6= j . (22)\nFurthermore, it is easy to verify that the corresponding minimizers of (12) are\nw∗(η1, . . . , ηn) =\n( 1\nn n∑ i=1 Qηi\n)−1 q =  Rµ√ 2 ( L+µ 2 + 1 n ∑n i=1 ηi ) , Rµ√ 2 ( L+µ 2 + 1 n ∑n i=1 ηi ) , 0, . . . , 0 > .\n(23)\nWe now have,\nmin s(η)∈(Pnk )d Eη∼U(H)‖s(η)−w∗(η)‖ = min s(η)∈(Pnk )d Ei∼U([n])Eηi∼U([−L−µ2 ,L−µ2 ])‖s(η)−w ∗(η)‖\n≥ 1 n min s(η)∈Pnk n∑ j=1 E ηj∼U([−L−µ2 , L−µ 2 ]) ∣∣∣∣∣sj(ηj)− Rµ√2( 1n∑ni=1 ηi) + L+µ2 ) ∣∣∣∣∣\n≥ Rµ√ 2 min s(η)∈Pnk n∑ j=1 E ηj∼U([−L−µ2 , L−µ 2 ]) ∣∣∣∣∣sj(ηj)− 1ηj − (n− 1)L−µ2 + nL+µ2 ∣∣∣∣∣\n≥ Rµ√ 2 min s(η)∈Pnk n∑ j=1 ∫ L−µ 2 −L−µ 2 ∣∣∣∣∣sj(ηj)− 1ηj − (n− 1)L−µ2 + nL+µ2 ∣∣∣∣∣ 1L− µdηj\n≥ Rµ√ 2(L− µ) min s(η)∈Pnk n∑ j=1 ∫ L−µ 2 −L−µ 2 ∣∣∣∣∣sj(ηj)− 1ηj − (n− 1)L−µ2 + nL+µ2 ∣∣∣∣∣ dηj\n(24)\nwhere the first inequality follows by focusing on the first coordinate of s(η) − w∗(η). Now, set α = −(n− 1)L−µ2 + n\nL+µ 2 and note that√\n2α+ L− µ 2α+ µ− L = √√√√2(−(n− 1)L−µ2 + nL+µ2 ) + L− µ 2(−(n− 1)L−µ2 + n L+µ 2 ) + µ− L = √ κ− 1 n + 1.\nThus, by Lemma 8 (using the same value for α and noting that α > (L− µ)/2) yields\n∫ L−µ 2\n−L−µ 2 ∣∣∣∣∣sj(ηj)− 1ηj − (n− 1)L−µ2 + nL+µ2 ∣∣∣∣∣ dηj ≥  √ κ−1 n + 1− 1√ κ−1 n + 1 + 1 kj . where kj denotes the degree of sj(ηj). Plugging in this into Inequality (24) we get\nmax η∈H E w (k) 1 (η)∼D\n‖w(k)1 (η)−w ∗(η)‖ ≥ nRµ√\n2(L− µ) min\ns(η)∈Pnk\n1\nn n∑ j=1\n √\nκ−1 n + 1− 1√ κ−1 n + 1 + 1 kj . Since u 7→ ρu is a decreasing and convex function for any 1 > ρ > 0, we have\nnRµ√ 2(L− µ) min s(η)∈Pnk 1 n n∑ j=1\n √\nκ−1 n + 1− 1√ κ−1 n + 1 + 1\nkj ≥ nRµ√ 2(L− µ) min s(η)∈Pnk  √ κ−1 n + 1− 1√ κ−1 n + 1 + 1  1 n ∑n j=1 kj\n≥ nRµ√ 2(L− µ)\n √\nκ−1 n + 1− 1√ κ−1 n + 1 + 1\nk/n\nwhere the last inequality is due to the fact that s(η) ∈ Pnk which implies that ∑n j=1 kj ≤ k. Finally, we have,\nmax η∈H E w (k) 1 (η)∼D [Fη(w (k) 1 (η))− Fη(w ∗(η))] ≥ max η∈H E w (k) 1 (η)∼D\nµ 2 ‖w(k)1 (η)−w ∗(η)‖2\n≥ µ 2  nRµ√ 2(L− µ)  √\nκ−1 n + 1− 1√ κ−1 n + 1 + 1\nk/n  2\n= µ\n2\n( nRµ√\n2(L− µ)\n)2 √\nκ−1 n + 1− 1√ κ−1 n + 1 + 1\n2k/n\nwhere the first inequality follows by the µ-strong convexity of Fη and the second inequality follows by Jensen inequality. Using Lemma 12, we get that the iteration complexity of A is at least\n1\n4\n(√ n(κ− 1) ) (ln µ\n2 + 2 ln nRµ√ 2(L− µ) + ln(1/ )).\nThis, together with Theorem 5 below, concludes the proof.\nWe bound from below the number of iterations required to obtain a non-trivial accuracy.\nLemma 2. Let j ∈ [n], let ηj,1 ∈ H be a parameters vector whose all coordinates are − L−µ 2 and let ηj,2 ∈ H be a parameters vector whose all coordinates are − L−µ 2 , except for the j’th coordinate which we set to be L−µ2 . If κ > 3, then\n‖w∗(η1)−w∗(η2)‖ ≥ 2R\nn+ 2 .\nProof By Equation (13) we have\n‖w ∗ (η1)−w ∗ (η2) ‖ = √ 2 ∣∣∣∣∣∣ Rµ√2(L+µ2 + 1n∑ni=1(η1)i) − Rµ √ 2 ( L+µ 2 + 1 n ∑n i=1(η2)i ) ∣∣∣∣∣∣\n= Rµ ∣∣∣∣∣ 1L+µ 2 − L−µ 2 − 1 L+µ 2 − (n−1)(L−µ) 2n + L−µ 2n ∣∣∣∣∣ = Rµ ∣∣∣∣∣∣ L+µ 2 − (n−1)(L−µ) 2n + L−µ 2n − L+µ 2 + L−µ 2(\nL+µ 2 − L−µ 2 )( L+µ 2 − (n−1)(L−µ) 2n + L−µ 2n ) ∣∣∣∣∣∣\n= R ∣∣∣∣∣− (n−1)(L−µ) n + L−µ n + L− µ\nL+ µ− (n−1)(L−µ)n + L−µ n ∣∣∣∣∣ = 2R\n∣∣∣∣∣ L−µnL+ µ− (n−1)(L−µ)n + L−µn ∣∣∣∣∣\n= 2R ∣∣∣∣∣ 1nκ+1κ−1 − (n− 1) + 1 ∣∣∣∣∣\n= 2R ∣∣∣∣∣ 1nκ+1κ−1 − n+ 2 ∣∣∣∣∣\n≥ 2R n+ 2 ,\nwhere the last inequality follows from κ > 3.\nTheorem 5. The iteration complexity of any stochastic optimization algorithm (not necessarily CLI) which gathers information on Fη (with κ > 3) only by means of incremental oracles, i.e., oracles which upon receiving query return an answer which depends on not more than one individual function, is at least n.\nProof Let A be a stochastic optimization algorithm. According to Yao’s principle, we can bound from below the -optimality ofA after k < n iterations by estimating the -optimality of any deterministic algorithm w.r.t. to distribution D(H) overH defined by: draw j ∈ [n] and set η to be ηj,1 or ηj,2 as defined in Lemma 2 w.p. 1/2. Then,\nmax {ηj,i|j∈[n],i∈[2]}\nEA[Fηj,i(w (k) ( ηj,i ) )− Fηj,i(w ∗ (ηj,i))] ≥ min\ndeterministic algorithms E η∼D(H)[Fηj,i(w\n(k) ( ηj,i ) )− Fηj,i(w ∗ (ηj,i))] ≥ min\ndeterministic algorithms E η∼D(H)\nµ 2 ‖w(k)\n( ηj,i ) )−w∗ ( ηj,i ) ‖2\n≥ µ 2 min deterministic algorithms\n( E η∼D(H)‖w (k) ( ηj,i ) )−w∗ ( ηj,i ) ‖ )2\n≥ µ 2\n( R\n2n(n+ 2)\n)2 ,\nwhere the last inequality follows from Lemma 2. Thus, for sufficiently small , one must perform at least n iterations in order to obtain an -optimal solution."
    }, {
      "heading" : "A.3 Proof of Theorem 3 - Smooth Functions",
      "text" : "The following notation\nPk := {p ∈ Pk|p(0) = 0} (25)\nwill come in handy in subsequent proofs.\nLemma 3. When applied on\ngη(x) := η 2 ‖x‖2 −Rηe>1 x, η ∈ (0, L] (26)\nwith a first-order oracle (as defined in 10 with n = 1), the coordinates of iterates produced by oblivious stochastic CLIs whose is initialization iterate is x(0)i = 0 form polynomials in η with random real coefficients which vanishes at η = 0 and whose degree does not exceed the iteration number.\nProof Let A be a oblivious stochastic CLI, and suppose we apply A on the class of problems (26) parameterized by η, using a first-order. We use mathematical induction to show that for any k = 0, 1, . . . , the coordinate of the k’th iterate produced by such process can be expressed as a distribution over Pk.\nAs the first iterate x(0)i is assumed to be zero, the base case is trivial. For the inductive step, assume that any coordinate of x(k)i can be expressed as a distribution over Pk. It is easy to see that for any x (k) i , the answers of the first-order oracle,\nFirst-order oracle: O(x(k)i ;A,B,C) = A(ηx (k) i −Rηe1) +Bx (k) i + C,\nform a distribution over P0k+1, as the random quantities involved in the expressions (A,B and C) do no depend on η (due to obliviosity) and the rest of the terms (η and Rηei) are homogenous in η. Lastly, x (k+1) i are computed by simply summing up all the oracle answers, and as such, form again distributions over P0k+1.\nProof [Theorem 3] Let N be a oblivious stochastic CLI and let α ∈ (−1, 0). Our derivation of lower bounds for stochastic CLIs is established via Yao principle. Fix some k ∈ {0, 1, . . . }. By Lemma 3, x(k)1 (η) distributes according to some distribution D over (Pk)d. Thus, by Yao principle, since each polynomial in (Pk)d represents a single deterministic algorithm, we have\nmax η∈[0,L] E x (k) 1 (η)∼D gη(x (k) 1 (η))− gη(x ∗(η)) ≥ min s(η)∈(Pk)d Eη∼E([0,L])gη(s(η))− gη(x∗(η))\nwhere E([0, L], α) (abbr. E) denotes a distribution over (0, L] with a probability density function\npE(η) = (α+ 1)ηα\nLα+1 .\nWe have,\nmin s(η)∈(Pk)d Eη∼E [gη(s(η))− gη(x∗(η))] ≥ min s(η)∈Pk\nEη∼E [ η‖s(η)− x∗(η)‖2 ] ≥ min\ns(η)∈Pk Eη∼E\n[ η(s(η)−R)2 ] = R2 min\ns(η)∈Pk Eη∼E\n[ η(s(η)− 1)2 ] = R2(α+ 1)\nLα+1 min\ns(η)∈Pk ∫ L 0 η(s(η)− 1)2ηαdη\n= R2(α+ 1)\nLα+1 min\ns(η)∈Pk ∫ 1 0 Lη(s(Lη)− 1)2(Lη)αL dη\n= LR2(α+ 1) min s(η)∈Pk ∫ 1 0 η(s(η)− 1)2ηα dη\nwhere the first inequality follows by the fact that hη is η-strongly convex and the second inequality follows by focusing on the first coordinate of s(η)− x∗(η). Invoking Lemma 9 yields\nLR2(α+ 1) min s(η)∈Pk ∫ 1 0 η(s(η)− 1)2ηα dη = LR2(α+ 1) min s(η)∈Pk−1 ∫ 1 0 η(s(η)η − 1)2ηαdη,\n≥ LR 2(α+ 1)\ne2(k + 2)2(α+1)+2 .\nThus, in this case the iteration complexity is bound from below by\n2(α+1)+2\n√ LR2(α+ 1)\ne2 − 2."
    }, {
      "heading" : "A.4 Proof of Theorem 4 - Regularized Empirical Loss Minimization",
      "text" : "For ease of presentation, we assume that ‖xi‖ ≤ 1, φi take non-negative values and φi(0) ≤ 1. Furthermore, throughout the proof we assume that n is even and that L = 1 (the proof for odd n and general L > 0 holds mutatis mutandis). First, we give an explicit definition of the parametrized set of functions we will be focusing on, as well as the oracles under which our bounds hold. We denote byH the set of all (ψ1, . . . , ψn/2) ∈ Rn/2 such that all the entries are 0, except for some j ∈ [n/2], for which ψj ∈ [−π/2, π/2]. Now, given ψ ∈ H, we set\nφi(w) = 1 2 (w + 1)2 =⇒ φ∗i (u) = 1 2 u2 − u\nxψ,i = { cos(ψ(i+1)/2)ei + sin(ψ(i+1)/2)ei+1 i is odd ei o.w. .\nIn which case, the corresponding dual is:\nDψ(α) = 1 2n ‖α‖2 − 1 n 1 >α+ 1 2λn2 ‖Xψαi‖2 (27)\nwhere\nXψ := (xψ,1, . . . ,xψ,n) .\nEquivalently\nDψ = 1 2 α> ( 1 n I + 1 λn2 X>ψXψ ) α− 1 n 1 >α\nNote that\nQψ := 1\nn I +\n1\nλn2 X>ψXψ =\n1\nn  1 + 1λn\n1 λn sin(ψ1)\n1 λn sin(ψ1) 1 + 1 λn\n1 + 1λn 1 λn sin(ψ2)\n1 λn sin(ψ2) 1 + 1 λn\n. . .\n .\nNote that, all the eigenvalues of Qψ are bigger than 1. Therefore, Dψ is 1-strongly convex. We assume that the oracles at the algorithms’ disposal are the dual RLM oracles defined in (19),\nLastly, we will need the following definitions\nPnk,d(η1, η2, . . . , ηn) :=   p1(η1, η2, . . . , ηn)...\npd(η1, η2, . . . , ηn)\n ∣∣∣∣∣∣∣ p1, . . . , pd ∈ Pnk , ∂p1 + · · ·+ ∂pd ≤ k  (28) Qnk,d(ψ1, ψ2, . . . , ψn) :=   p1(sinψ1, sinψ2, . . . , sinψn)...\npd(sinψ1, sinψ2, . . . , sinψn)\n ∣∣∣∣∣∣∣ p1, . . . , pd ∈ Pnk,d  (29) to ease notation in subsequent proofs (where ∂p denotes the total degree of p and Pnk is defined in (20)). Thus, Qnk contains d-dimensional vectors whose entries are n-multivariate polynomials expressions in sinψ1, . . . , sinψn, such that the sum of the degrees of the d-polynomials does not exceed k. In addition, given t(ψ) ∈ Qnk,d we define\nti(ψi) := t 0, . . . , 0, ψi︸︷︷︸ i’th entry , 0, . . . , 0  , ∀i ∈ [d]. As usual, we start by stating the functional form assumed by iterates produced by this sort of optimization\nalgorithms.\nLemma 4. When applied on (27) with a dual RLM oracle (as defined in 19), the coordinates of iterates produced by oblivious stochastic CLIs form n multivariate polynomials expressions in sinψ1, . . . , sinψn/2 with random coefficients, such that the sum of the degrees of these polynomials does not exceed the iteration number.\nProof Let A be a oblivious stochastic CLI, and suppose we apply A on the class of problems (27) parameterized by ψ, using dual RLM oracles as defined in 19. We use mathematical induction to show that for any\nk = 0, 1, . . . , the coordinate of the k’th iterate produced by such process can be expressed as a distribution over polynomial expressions in sinψ1, . . . , sinψn/2 whose sum of degrees is less than or equal k.\nAs the first iterate α(0)i is allowed to depend only on n and λ, the base case is trivial. That is, α (0) i forms\na distribution over Rn = Qn/20,n which does not depend on sinψ1, . . . , sinψn/2. For the inductive step, assume that α(k)i can be expressed as a distribution over Q n/2 k,n . It is easy to see that for any α(k)i , the answer of the dual RLM oracle\nO(α(k)i ; t, `) = α+ te > ` (Qψα (k) i −\n1 n 1)e`, t ∈ R, j ∈ [n],\nO(α(k)i ; `) = ( I − 1\n(Qψ)`` e`(Qψ)`,∗\n) α(k) +\n1\nn(Qψ)`` e`\nare distributions over Qn/2k+1,n, as the only random quantity involved in the expressions t, ` does not depend on ψ (due to obliviosity), the only linear factor in sinψ` (i.e., e>` (Qψα− 1 n1)e`, e`(Qj,η)`,∗) ’touches’ α (k) i at exactly one entry and the rest of the terms (1/n1, I, 1/(Qj,η)`` and n) are constants (w.r.t. sinψ` ). Lastly, α\n(k+1) i are computed by simply summing up all the oracle answers, and as such, form again distributions\nover Qn/2k+1,n.\nProof [Theorem 4] Let A be a oblivious stochastic CLI. By Lemma 4 the coordinates of α(k)1 (the point returned by the algorithm at the k’th iteration) when applied on the class of problems (27) distributes according to some distribution D over (Qn/2k ) n. Furthermore, it is easy to verify that the corresponding minimizers of (27) are\nα∗(ψ) =\n( 1\nλn+1 λn + 1 λn sin(ψ1)\n, 1\nλn+1 λn + 1 λn sin(ψ1)\n, 1\nλn+1 λn + 1 λn sin(ψ2)\n, 1\nλn+1 λn + 1 λn sin(ψ2)\n, . . . ) .\n(30)\nα (k) 1 (ψ) distributes according to some distribution D over Q n/2 k,n . Thus, by Yao principle, since each polynomial in Qn/2k,n represents a single deterministic algorithm, we have\nmax ψ∈H E α (k) 1 (ψ)∼D\n‖α(k)1 (ψ)−α ∗(ψ)‖ ≥ min t(ψ)∈Qn/2k,n Eψ∼U(H)‖t(ψ)−α∗(ψ)‖ (31)\nwhere U(H) denotes a distribution overH which corresponds to of first drawing j ∼ U([n/2]) at random, and then drawing ψj according to distribution defined by the p.d.f. pψj (ψ) = cos(ψ)/2 over [−π/2, π/2]\n(for i 6= j we set ψi = 0 ). We now have,\nmin t(ψ)∈Qn/2k,n\nEψ∼U(H)‖t(ψ)−α∗(ψ)‖\n= min t(ψ)∈Qn/2k,n\nEj∼U([n/2])Eψj∼U([−π/2,π/2])‖t(ψ)−α ∗(ψ)‖\n= 2\nn n/2∑ j=1 min t(ψ)∈Qn/2k,n Eψj∼U([−π/2,π/2])‖t(ψ)−α ∗(ψ)‖\n≥ 2 n n/2∑ j=1 min t(ψ)∈Qn/2k,n Eψj∼U([−π/2,π/2]) ∣∣∣∣∣tj(ψj)− 1λn+1 λn + 1 λn sin(ψj) ∣∣∣∣∣ ≥ 1 n n/2∑ j=1 min t(ψ)∈Qn/2k,n ∫ π/2 −π/2 ∣∣∣∣∣tj(ψj)− 1λn+1 λn + 1 λn sin(ψj)\n∣∣∣∣∣ cosψj dψj = 1\nn n/2∑ j=1 min s(ψ)∈Qn/2k,n ∫ 1 −1 ∣∣∣∣∣sj(ηj)− 1λn+1 λn + 1 λnηj ∣∣∣∣∣ dηj = λ\nn/2∑ j=1 min s(ψ)∈Qn/2k,n ∫ 1 −1 ∣∣∣∣sj(ηj)− 1λn+ 1 + ηj ∣∣∣∣ dηj (32)\nwhere the first inequality follows by focusing on the j’th coordinate of s(ψ) − α∗(ψ) in each summand. Now, set α = 1 + λn,L = 3, µ = 1 and note that√\n2α+ L− µ 2α+ µ− L =\n√ 2λn+ 4\n2λn =\n√ λn+ 2\nλn =\n√ 2\nλn + 1\nThus, by Lemma 8, using the same value for α and noting that α > 1 = (L− µ)/2) yields\n∫ 1 −1 ∣∣∣∣sj(ηj)− 1λn+ 1 + ηj ∣∣∣∣ dηj ≥  √ 2 λn + 1− 1√ 2 λn + 1 + 1 kj\nwhere kj denotes the degree of sj(ηj). Plugging in this into Inequality (32) we get\nmax ψ∈H E α (k) 1 (ψ)∼D\n‖α(k)1 (ψ)−α ∗(ψ)‖ ≥ λ min\ns(ψ)∈Qn/2k,n n/2∑ j=1\n √\n2 λn + 1− 1√ 2 λn + 1 + 1 kj . Since u 7→ ρu is a decreasing and convex function for any 1 > ρ > 0, we have\nλ min s(ψ)∈Qn/2k,n n/2∑ j=1\n √\n2 λn + 1− 1√ 2 λn + 1 + 1 kj ≥ nλ/2 min s(ψ)∈Qn/2k,n  √ 2 λn + 1− 1√ 2 λn + 1 + 1  2 n ∑n/2 j=1 kj\n≥ nλ/2 min s(ψ)∈Qn/2k,n\n √\n2 λn + 1− 1√ 2 λn + 1 + 1\n 2k n\nwhere the last inequality is due to the fact that s(ψ) ∈ Qn/2k,n (sinψ) which implies that ∑n\nj=1 kj ≤ k. Finally, we have,\nmax ψ∈H E α (k) 1 (ψ)∼D [Dψ(α (k) 1 (ψ))−Dψ(α ∗(ψ))] ≥ max ψ∈H E α (k) 1 (ψ)∼D\n1 2 ‖α(k)1 (ψ)−α ∗(ψ)‖2\n≥ 1 2 ( max ψ∈H E α (k) 1 (ψ)∼D ‖α(k)1 (ψ)−α ∗(ψ)‖ )2\n≥ 1 2 nλ/2 min s(ψ)∈Qn/2k,n  √ 2 λn + 1− 1√ 2 λn + 1 + 1  2k n  2 ,\nwhere the first inequality follows by the 1-strong convexity of Dψ and the third inequality follows by Jensen inequality. Using Lemma 12, we get that the iteration complexity of A is at least\n1\n8\n√ 2n\nλ\n( ln n2λ2\n8 + ln(1/ )\n) .\nLastly, we bound from below the number of iterations required to obtain a non-trivial accuracy.\nLemma 5. Let j ∈ [n], let ψj,1 ∈ H be a parameters vector whose all coordinates are −π/2 and let ηψ,2 ∈ H be a parameters vector whose all coordinates are −π/2, except for the j’th coordinate which we set to be π/2. Then\n‖α∗(ψ1)−α∗(ψ2)‖ ≥ 2 √ 2\nλn+ 2\nProof By Equation (30) we have\n‖α∗(ψ1)−α∗(ψ2)‖ = √ 2\n( 1\nλn+1 λn − 1 λn − 1 λn+1 λn + 1 λn\n)\n= √ 2 ( 1− λn\nλn+ 2 ) = 2 √ 2\nλn+ 2 .\nTheorem 6. When applied on (27) ,the iteration complexity of oblivious stochastic CLI algorithms equipped with a dual RLM oracle Dψ is at least n/2.\nProof Let A be a stochastic optimization algorithm. By Lemma 4 the coordinates of α(k)1 (the point returned by the algorithm at the k’th iteration) when applied on the class of problems (27) distributes according to\nsome distribution D over (Qn/2k ) n. By Yao principle, since each polynomial in Qn/2k,n represents a single deterministic algorithm, we have\nmax ψ∈H E α (k) 1 (ψ)∼D\n‖α(k)1 (ψ)−α ∗(ψ)‖ ≥ min t(ψ)∈Qn/2k,n Eψ∼D(H)‖t(ψ)−α∗(ψ)‖ (33)\nwhere D(H) denotes a distribution overH which corresponds to the process of first drawing j ∼ U([n/2]) at random, and then set ψ to be ψj,1 or ψj,2 as defined in Lemma 5 with equal probability. Now, for k < n/2, there exists some j ∈ [n/2] such that t(ψ) does not depend on ψj . This yields,\nmax {ψj,i|j∈[n/2],i∈[2]}\nEA[Dψj,i(α (k) ( ψj,i ) )−Dψj,i(α ∗ (ψj,i))] ≥ min\ndeterministic algorithms E ψ∼D(H)[Dψj,i(α\n(k) ( ψj,i ) )−Dψj,i(α ∗ (ψj,i))] ≥ min\ndeterministic algorithms E ψ∼D(H)\n1 2 ‖α(k)\n( ψj,i ) )−α∗ ( ψj,i ) ‖2\n≥ 1 2 min deterministic algorithms ( E ψ∼D(H)‖α (k) ( ψj,i ) )−α∗ ( ψj,i ) ‖ )2\n≥ 1 2\n( 2 √ 2\nn(λn+ 2)\n)2 ,\nwhere the last inequality follows from Lemma 5. Thus, for sufficiently small , one must perform at least n/2 iterations in order to obtain an -optimal solution.\nA.5 Best polynomial approximation over closed intervals in R\nIn the following section we analyze the best polynomial approximation of some functions w.r.t. L∞, L1 and L2 norm, based on standard results from the approximation theory (see generally, Allan Pinkus. On L1-approximation, 1989; Theodore J Rivlin. An introduction to the approximation of functions, 2003; Ronald A DeVore and George G Lorentz. Constructive approximation, 1993; Naum Il’ich Akhiezer and Charles J Hyman. Theory of approximation. Translated by Charles J. Hyman. New York, 1956; Isidor Pavlovich Natanson. Constructive function theory, 1964)."
    }, {
      "heading" : "A.5.1 Approximation w.r.t. L∞",
      "text" : "Lemma 6. Let b > a > 0 and c > −a, then\nmin s(η)∈Pk ∥∥∥∥s(η)− 1η + c ∥∥∥∥ L∞([a,b]) ≥ 2(b− a) (b+ a+ 2c)2 − (b− a)2  √ b+c a+c − 1√ b+c a+c + 1 k .\nProof We have,\nmin s(η)∈Pk ∥∥∥∥s(η)− 1η + c ∥∥∥∥ L∞([a,b]) = min s(η)∈Pk ∥∥∥∥∥s ( a− b 2 η + a+ b 2 ) − 1 a−b 2 η + b+a 2 + c ∥∥∥∥∥ L∞([−1,1])\n= min s(η)∈Pk ∥∥∥∥∥s (η)− 1a−b 2 η + b+a+2c 2 ∥∥∥∥∥ L∞([−1,1])\n= 2\nb− a min\ns(η)∈Pk ∥∥∥∥∥b− a2 s (η)− b−a2a−b 2 η + b+a+2c 2 ∥∥∥∥∥ L∞([−1,1])\n= 2\nb− a min\ns(η)∈Pk ∥∥∥∥∥s (η) + 1η − b+a+2cb−a ∥∥∥∥∥ L∞([−1,1])\n= 2\nb− a min\ns(η)∈Pk ∥∥∥∥∥−s (η) + 1η − b+a+2cb−a ∥∥∥∥∥ L∞([−1,1])\n= 2\nb− a min\ns(η)∈Pk ∥∥∥∥∥s (η)− 1η − b+a+2cb−a ∥∥∥∥∥ L∞([−1,1])\nwhere we used the fact that Pk is invariant under pre-composition and post-composition with linear function in the second, fourth and fifth equalities. Now, since\nc > −a =⇒ b+ a+ 2c b− a > 1,\ncombining Inequality 8 with Lemma 10, yields\nmin s(η)∈Pk ∥∥∥∥∥s(η)− 1η − b+a+2cb−a ∥∥∥∥∥ L∞([−1,1]) ≥\n(( b+a+2c b−a ) − √( b+a+2c b−a )2 − 1 )k ( b+a+2c b−a )2 − 1\n= 1(\nb+a+2c b−a\n)2 − 1\n1− √ b+a+2c b−a −1 b+a+2c b−a +1\n1 +\n√ b+a+2c b−a −1\nb+a+2c b−a +1\n k\n(34)\nNoting that\nb+a+2c b−a − 1 b+a+2c b−a + 1 = b+ a+ 2c− (b− a) b+ a+ 2c+ b− a = a+ c b+ c ,\nwe get\nmin s(η)∈Pk ∥∥∥∥s(η)− 1η + c ∥∥∥∥ L∞([a,b]) ≥ 2 b− a 1( b+a+2c b−a )2 − 1  √ b+c a+c − 1√ b+c a+c + 1 k .\nAs,\n2 b− a 1(\nb+a+2c b−a\n)2 − 1 = 2 b− a (b− a)2 (b+ a+ 2c)2 − (b− a)2 = 2(b− a) (b+ a+ 2c)2 − (b− a)2\nwe get\nmin s(η)∈Pk ∥∥∥∥s(η)− 1η + c ∥∥∥∥ L∞([a,b]) ≥ 2(b− a) (b+ a+ 2c)2 − (b− a)2  √ b+c a+c − 1√ b+c a+c + 1 k ."
    }, {
      "heading" : "A.5.2 Approximation w.r.t. L1",
      "text" : "Let Uk(η) denote the k’th second order Chebyshev polynomial, i.e.,\nUk(η) := sin((k + 1) arccos η)√\n1− η2 (35)\n(To see why these are indeed polynomials, observe that Uk(η) are the derivative of Chebyshev polynomials of first order scaled by a factor of 1/k). The zeros of Uk(η) are ηj = cos( jπ k+1), j = 1, . . . , k. First, let us establish the orthogonality of sgn(Uk(η)) with respect to Pk−1 over [−1, 1]. Lemma 7. Let p(η) ∈ Pk−1, then ∫ 1\n−1 p(η)sgn(Uk(η)) dη = 0\nProof We integrate by substituting η = e iθ+e−iθ\n2 (= cos(θ)),∫ 1 −1 p(η)sgn(Uk(η)) dη η= e iθ+e−iθ 2= ∫ 0 π p ( eiθ + e−iθ 2 ) sgn ( Uk ( eiθ + e−iθ 2 ))( ieiθ − ie−iθ 2 ) dθ\n= ∫ π 0 p ( eiθ + e−iθ 2 ) sgn ( sin((k + 1)θ) sin(θ) )( ie−iθ − ieiθ 2 ) dθ\n= ∫ π 0 p ( eiθ + e−iθ 2 ) sgn (sin((k + 1)θ)) ( ie−iθ − ieiθ 2 ) dθ\n= 1\n2 ∫ π −π p ( eiθ + e−iθ 2 ) sgn (sin((k + 1)θ)) ( ie−iθ − ieiθ 2 ) dθ (36)\nwhere the last equality is due to the fact that the integrand is an even function in θ. Lastly, since for any j = 1, . . . , k we have∫ π\n−π e−ijθ sin((k + 1)θ)dθ = ∫ π+2π/(k+1) −π+2π/(k+1) e−ijθ sin((k + 1)θ)dθ\n= ∫ π −π e−ij(θ+2π/(k+1)) sin((k + 1)(θ + 2π/(k + 1)))dθ\n= e−2πij/(k+1) ∫ π −π e−ijθ sin((k + 1)θ)dθ,\nand since e−2πij/(k+1) 6= 1 for j = 1, . . . , k, it follows that∫ π −π e−ijθ sin((k + 1)θ)dθ = 0, j = 1, . . . , k.\nThis, together with the case where j = 0,∫ π −π sin((k + 1)θ)dθ = (− cos((k + 1)θ)/(k + 1)) ∣∣∣π −π = 0,\nimplies that all the terms in (36) vanish, thus concluding the proof.\nGiven µ < L (note that, here µ and L are allowed to take negative values), we define\nŨk(η) := Uk\n( 2η\nµ− L\n) .\nBy substituting η for (µ−L)η2 , we get the following corollary.\nCorollary 1. Let p(η) ∈ Pk−1, then ∫ L−µ 2\n−L−µ 2\np(η) sgn(Ũk(η)) dη = 0 (37)\nWe now use Corollary 1 to bound from below the best polynomial L1-approximation error w.r.t. 1/(η+α) over the interval [µ,L].\nLemma 8. Let p(η) ∈ Pk−1. Then, for any (L− µ)/2 < α we have\n∫ L−µ 2\n−L−µ 2\n|p(η)− 1/(η + α)|dη ≥\n √\n2α+L−µ 2α+µ−L − 1√ 2α+L−µ 2α+µ−L + 1 k . Proof First, note that the following two inequalities∫ L−µ\n2\n−L−µ 2\n|p(η)− 1/(η + α)|dη ≥ ∫ L−µ 2\n−L−µ 2\n(p(η)− 1/(η + α))sgn(Ũk(η))dη = − ∫ L−µ 2\n−L−µ 2 1/(η + α)sgn(Ũk(η))dη∫ L−µ 2\n−L−µ 2\n|p(η)− 1/(η + α)|dη ≥ ∫ L−µ 2\n−L−µ 2\n(p(η)− 1/(η + α))sgn(−Ũk(η))dη = ∫ L−µ 2\n−L−µ 2\n1/(η + α)sgn(Ũk(η))dη\nhold due to orthogonality condition (37) and the fact that sgn(·) is odd. Therefore,∫ L−µ 2\n−L−µ 2\n|p(η)− 1/(η + α)|dη ≥ ∣∣∣∣∣ ∫ L−µ 2\n−L−µ 2\n1/(η + α) sgn(Ũk(η))dη ∣∣∣∣∣ .\nSubstituting µ−L2 η for η, yields∣∣∣∣∣ ∫ L−µ 2\n−L−µ 2\n1/(η + α) sgn(Ũk(η))dη ∣∣∣∣∣ = ∣∣∣∣∣ ∫ −1 1 1 µ−L 2 η + α sgn(Uk(η)) µ− L 2 dη ∣∣∣∣∣ =\n∣∣∣∣∣ ∫ 1 −1 1 µ−L 2 η + α sgn(Uk(η)) L− µ 2 dη ∣∣∣∣∣ =\n∣∣∣∣∣ ∫ 1 −1\n1\n−η + 2αL−µ sgn(Uk(η))dη ∣∣∣∣∣ (38) Now, plugging in the definition of Uk(η) (see (35)) and applying Lemma 11, we get\n∫ 1 −1 sgn(sin(k arccos(η))) u− η dη ≥\n1− √ u−1 u+1\n1 + √\nu−1 u+1\nk\nfor any u > 1. Using this inequality with (38) where u = 2αL−µ , yields\n∫ L−µ 2\n−L−µ 2\n|p(η)− 1/(η + α)|dη ≥\n √\n2α+L−µ 2α+µ−L − 1√ 2α+L−µ 2α+µ−L + 1\nk ."
    }, {
      "heading" : "A.5.3 Approximation w.r.t. L2",
      "text" : "Lemma 9. For any α ∈ (−1, 0),\nmin s(η)∈Pk−1 ∫ 1 0 η(s(η)η − 1)2ηαdη ≥ 1 e2(k + 2)2(α+1)+2\nProof Rephrasing it equivalently as\nmin s(η)∈Pk−1 ∫ 1 0 (s(η)η 3+α 2 − η 1+α 2 )2dη,\nshows that this problem can be seen as a best L2-approximation for η 1+α 2 in the k-dimensional space spanned by gi = ηi+ 1+α 2 , i = 1, . . . , k (accordingly, g0 = η 1+α 2 ). By [2, Equation (3), p. 16], we have\nmin s(η)∈Pk−1 ∫ 1 0 (s(η)η 3+α 2 − η 1+α 2 )2dη,= detG(g0, g1, . . . , gn) detG(g1, . . . , gn)\nwhere G(·) is Gram matrix (whose entries are the inner products of its arguments). First, note that\n〈gi, gj〉 = ∫ 1 0 ηi+ 1+α 2 ηj+ 1+α 2 dη = ∫ 1 0 ηi+j+1+αdη =\n1\ni+ j + α+ 2 , i, j = 0, 1, . . . , k\nThus,\nG(g1, . . . , gk)i,j = 1\ni+ j + α+ 2 ,\nG(g0, . . . , gk)i,j = 1\ni+ j + α .\nIt follows that both matrices can be expressed as a Cauchy matrices, that is\nG(g1, . . . , gk)i,j = 1\nxi − yj ,\nG(g0, . . . , gk)i,j = 1\nui − vj .\nwhere xi = i+ α+ 1, yj = −j − 1, i, j ∈ [k] and ui = i+ α, vj = −j, i, j ∈ [k + 1]. The determinant of Cauchy matrix A defined by sequences wi, zj one has\ndetA =\n∏k i=2 ∏i−1 j=1(wi − wj)(zj − zi)∏k i=1 ∏k j=1(wi − zj)\nHence,\ndetG(g0, g1, . . . , gk)\ndetG(g1, . . . , gk) =\n∏k+1 i=2 ∏i−1 j=1(ui−uj)(vj−vi)∏k+1\ni=1 ∏k+1 j=1 (ui−vj)∏k\ni=2 ∏i−1 j=1(xi−xj)(yj−yi)∏k\ni=1 ∏k j=1(xi−yj)\n=\n∏k+1 i=2 ∏i−1 j=1(i−j)(−j−(−i))∏k+1\ni=1 ∏k+1 j=1 (i+α−(−j))∏k\ni=2 ∏i−1 j=1((i+1)−(j+1))((−j−1)−(−i−1))∏k i=1 ∏k j=1((i+α+1)−(−j−1))\n=\n∏k+1 i=2 ∏i−1 j=1(i−j)\n2∏k+1 i=1 ∏k+1 j=1 (i+j+α)∏k\ni=2 ∏i−1 j=1(i−j)2∏k\ni=1 ∏k j=1(i+j+α+2)\n=\n∏k+1 i=2 ∏i−1 j=1(i− j)2∏k+1\ni=1 ∏k+1 j=1(i+ j + α)\n∏k i=1 ∏k j=1(i+ j + α+ 2)∏k\ni=2 ∏i−1 j=1(i− j)2\n=\n∏k j=1(k + 1− j)2 ∏k i=1 ∏k j=1(i+ j + α+ 2)∏k+1\ni=1 ∏k+1 j=1(i+ j + α)\n=\n∏k j=1(k + 1− j)2 ∏k i=1 ∏k j=1((i+ α+ 1) + (j + 1))∏k+1\ni=1 ∏k+1 j=1((i+ α) + j)\n=\n∏k j=1(k + 1− j)2 ∏k+1 i=2 ∏k+1 j=2((i+ α) + j)∏k+1\ni=1 ∏k+1 j=1((i+ α) + j)\n= ∏k j=1(k + 1− j)2∏k+1\ni=1 (i+ α+ 1) ∏k+1 j=2(1 + α+ j)\n=\n∏k j=1 j\n2∏k+1 i=1 (i+ α+ 1) ∏k+1 j=2(1 + α+ j)\n= (α+ 2)\n∏k j=1 j\n2∏k+1 i=1 (i+ α+ 1) 2\n= (α+ 2)  k∏ j=1\nj\nj + α+ 1 2 1 (k + α+ 2)2\nTo estimate the middle term, we apply arguments similar to the integral test for infinite series. First, note that, k∏ j=1 j j + α+ 1 = exp ( k∑ i=1 ln j j + α+ 1 ) .\nNow, since for any α ∈ (−1, 0), it holds that x 7→ ln xx+α+1 is a monotone decreasing function (over x 6= α), it holds that\nk∑ i=1 ln j j + α+ 1 ≥ ∫ k+1 1 ln x x+ α+ 1 dx = ( x ln\nx\nα+ x+ 1 − (α+ 1) ln(α+ x+ 1) )∣∣∣∣k+1 1\nHence, k∏ j=1 j j + α+ 1 ≥ exp ( (k + 1) ln\nk + 1 α+ (k + 1) + 1 − (α+ 1) ln(α+ (k + 1) + 1)− ln 1 α+ 2 + (α+ 1) ln(α+ 2)\n)\n=\n( k + 1\nk + α+ 2\n)k+1 (k + α+ 2)−(α+1)(α+ 2)α+2\n≥ ( k + 1\nk + α+ 2\n)k+1 (k + α+ 2)−(α+1)\n= ( 1− α+ 1\nk + α+ 2\n)k+1 (k + α+ 2)−(α+1)\n= ( 1− 1\nk+1 α+1 + 1\n)k+1 (k + α+ 2)−(α+1).\nNow, by the following standard inequality\n1− 2 x+ 1 ≥ exp ( −2 x− 1 ) ,\nwe get,\n1− 1 k+1 α+1 + 1 = 1− 2 (2 k+1α+1 + 1) + 1 ≥ exp\n( −2\n(2 k+1α+1 + 1)− 1\n) = exp ( −1 k+1 α+1 ) = exp ( −(α+ 1) k + 1 ) therefore,\n(α+ 2)  k∏ j=1\nj\nj + α+ 1 2 1 (k + α+ 2)2 ≥ (α+ 2) ( exp ( −(α+ 1) k + 1 )k+1 (k + α+ 2)−(α+1) )2 1 (k + α+ 2)2\n= (α+ 2) exp (−2(α+ 1)) (k + α+ 2)−2(α+1)−2\n≥ (α+ 2) exp (−2(α+ 1)) (k + 2)−2(α+1)−2\nAll in all, we get\nmin s(η)∈Pk−1 ∫ 1 0 η(s(η)η − 1)2ηαdη ≥ 1 e2(k + 2)2(α+1)+2"
    }, {
      "heading" : "A.6 Technical Lemmas",
      "text" : "Lemma 10. For any u ≥ 1,\nu− √ u2 − 1 =\n1− √\nu−1 u+1 1 + √\nu−1 u+1\n.\nProof We have,\n1− √\nu−1 u+1 1 + √\nu−1 u+1\n=\n( 1− √ u−1 u+1 )2 1− u−1u+1 = (u+ 1) ( 1− √ u−1 u+1 )2 u+ 1− (u− 1) = (√ u+ 1− √ u− 1 )2 2\n= u+ 1− 2\n√ (u+ 1)(u− 1) + (u− 1)\n2 = u−\n√ u2 − 1\nLemma 11. For any u > 1,\n∫ 1 −1 sgn(sin(k arccos(η))) u− η dη ≥\n1− √ u−1 u+1\n1 + √\nu−1 u+1 k . Proof First, note that the function\nγ(x) := ln x+ 1 x− 1 − 1 x\ntakes non-negative for any x > 1, as\nγ′(x) = x− 1 x+ 1 x− 1− (x+ 1) (x− 1)2 + 1 x2 = x− 1 x+ 1 −2 (x− 1)2 + 1 x2\n≤ −2 (x− 1)2 + 1 x2 ≤ −1 (x− 1)2 < 0\nand limx→∞ γ(x) = 0. Therefore, by using identity (see Section F.31. in [2]), we get∫ 1 −1 sgn(sin(k arccos(η))) u− η dη = 2 ln (u+ √ u2 − 1)k + 1 (u+ √ u2 − 1)k − 1\n≥ (u− √ u2 − 1)k = 1− √ u−1 u+1\n1 + √\nu−1 u+1 k , where the last equality is due to Lemma 10.\nLemma 12. Let L > µ > 0, c > 0 and α ≥ 0. Then\n≥ c\n √\nL+α µ+α − 1√ L+α µ+α + 1\nk =⇒ k ≥ 1 2 (√ L+ α µ+ α − 1 ) (ln(c) + ln(1/ ))\nProof Note that the function\nδ(x) = ln √ x− 1√ x+ 1 + 2√ x− 1\ntakes non-negative values for x > 1, as\nδ′(x) = √ x+ 1√ x− 1 0.5x−1/2( √ x+ 1)− 0.5x−1/2( √ x− 1) ( √ x+ 1)2 − 1 (x− 1) √ x− 1\n= 1 (x− 1) √ x − 1 (x− 1) √ x− 1 < 0\nand limx→∞ δ(x) = 0. Thus, we obtained the following inequality √ x− 1√ x+ 1 ≥ exp ( −2√ x− 1 ) , x > 1,\nyields\nc\n √\nL+α µ+α − 1√ L+α µ+α + 1\nk ≥ c exp  −2k√\nL+α µ+α − 1  . Hence,\nln ≥ ln(c) + −2k√ L+α µ+α − 1\n=⇒ 2k√ L+α µ+α − 1 ≥ ln(c) + ln(1/ )\n=⇒ k ≥ 1 2\n(√ L+ α\nµ+ α − 1\n) (ln(c) + ln(1/ ))"
    } ],
    "references" : [ ],
    "referenceMentions" : [ ],
    "year" : 2016,
    "abstractText" : "<lb>Many canonical machine learning problems boil down to a convex optimization problem with a finite<lb>sum structure. However, whereas much progress has been made in developing faster algorithms for<lb>this setting, the inherent limitations of these problems are not satisfactorily addressed by existing lower<lb>bounds. Indeed, current bounds focus on first-order optimization algorithms, and only apply in the often<lb>unrealistic regime where the number of iterations is less than O(d/n) (where d is the dimension and n<lb>is the number of samples). In this work, we extend the framework of Arjevani et al. [3, 5] to provide<lb>new lower bounds, which are dimension-free, and go beyond the assumptions of current bounds, thereby<lb>covering standard finite sum optimization methods, e.g., SAG, SAGA, SVRG, SDCA without duality, as<lb>well as stochastic coordinate-descent methods, such as SDCA and accelerated proximal SDCA.",
    "creator" : "LaTeX with hyperref package"
  }
}