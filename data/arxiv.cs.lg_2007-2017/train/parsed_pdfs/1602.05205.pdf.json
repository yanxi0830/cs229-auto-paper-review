{
  "name" : "1602.05205.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "Primal-Dual Rates and Certificates",
    "authors" : [ "Celestine Dünner", "Simone Forte", "Martin Jaggi" ],
    "emails" : [ "CDU@ZURICH.IBM.COM", "FORTESIMONE90@GMAIL.COM", "TAKAC.MT@GMAIL.COM", "JAGGIM@INF.ETHZ.CH" ],
    "sections" : [ {
      "heading" : "1. Introduction",
      "text" : "The massive growth of available data has moved data analysis and machine learning to center stage in many industrial as well as scientific fields, ranging from web and sensor data to astronomy, health science, and countless other applications. With the increasing size of datasets, machine learning methods are limited by the scalability of the underlying optimization algorithms to train these models, which has spurred significant research interest in recent years.\nHowever, practitioners face a significant problem arising with the larger model complexity in large-scale machine learning and in particular deep-learning methods - it is increasingly hard to diagnose if the optimization algorithm used for training works well or not. With the optimization algorithms also becoming more complex (e.g. in a distributed setting), it can often be very hard to pin down if bad performance of a predictive model either comes from\nslow optimization, or from poor modeling choices. In this light, easily verifiable guarantees for the quality of an optimization algorithm are very useful — note that the optimum solution of the problem is unknown in most cases. For convex optimization problems, a primal-dual gap can serve as such a certificate. If available, the gap also serves as a useful stopping criterion for the optimizer.\nSo far, the majority of popular optimization algorithms for learning applications comes without a notion of primaldual gap. In this paper, we aim to change this for a relevant class of machine learning problems. We propose a primaldual framework which is algorithm-independent, and allows to equip existing algorithms with additional primaldual certificates as an add-on.\nOur approach is motivated by the recent analysis of SDCA (Shalev-Shwartz & Zhang, 2013). We extend their setting to the significantly larger class of convex optimization problems of the form\nmin α∈Rn f(Aα) + g(α)\nfor a given matrix A ∈ Rd×n, and f , g being convex functions, not necessarily continuous. This problem class includes the most prominent regression and classification methods as well as generalized linear models. We will formalize the setting in more details in Section 3, and highlight the associated dual problem, which has the same structure.\nContributions. The main contributions in this work can be summarized as follows:\n• Our new primal-dual framework is algorithmindependent, that is it allows users to equip existing algorithms with primal-dual certificates and convergence rates.\nar X\niv :1\n60 2.\n05 20\n5v 1\n[ cs\n.L G\n] 1\n6 Fe\n• Compared with the well-known duality setting of SDCA (Shalev-Shwartz & Zhang, 2013; 2014) which is restricted to strongly convex regularizers and finite sum optimization problems, our framework encompasses a significantly larger class of problems. We obtain new primal-dual convergence rates e.g. for the Lasso as well as many L1, Elastic-Net and grouplasso-regularized problems. The theory applies to any norm-regularized generalized linear model. • Moreover, the primal-dual guarantees for the class of ERM problems with Lipschitz loss from (ShalevShwartz & Zhang, 2013) (e.g. SVM) are valid only for some “average” iteration. We show, that the same rate of convergence can be achieved e.g. for accelerated SDCA, but without necessity of computing an average over last samples. • We introduce a new Lipschitzing trick allowing duality gaps which are globally defined, without modifying the original problems in the region of interest. Therefore, in contrast to existing methods adding a small strongly-convex (L2) term as e.g. in (ShalevShwartz & Zhang, 2014; Zhang & Lin, 2015), our approach leaves both the algorithms and the optima unaffected. • Our primal-dual theory captures a more precise notion of data-dependency compared with existing results (which relied on per-coordinate information only). To be precise, our shown convergence rate for the general algorithm is depending on the the spectral norm of the data, see also (Takáč et al., 2013; 2015)."
    }, {
      "heading" : "2. Related Work",
      "text" : "Linearized ADMM solvers. For the problem structure of our interest here, one of the most natural algorithms is the splitting method known as the Chambolle-Pock algorithm (also known as Primal-Dual Hybrid Gradient, or linearized ADMM) (Chambolle & Pock, 2010). While this algorithm can give rise to a duality gap, it is significantly less general compared to our framework. In each iteration, it requires a complete solution of the proximal operators of both f and g, which can be computationally expensive. Its convergence rate is sensitive to the used step-size (Goldstein et al., 2015). Our framework is not algorithm-specific, and holds for arbitrary iterate sequences. More recently, the SPDC method (Zhang & Lin, 2015) was proposed as a coordinatewise variant of the method of (Chambolle & Pock, 2010), for the case of strongly convex g.\nStochastic coordinate solvers. Coordinate descent/ascent methods have become state-of-the-art for many machine learning problems (Hsieh et al., 2008; Friedman et al., 2010). In recent years, theoretical convergence rate guarantees have been developed for the primal-only setting e.g. by (Nesterov, 2012; Richtárik & Takáč, 2014), as\nwell as more recently also for primal-dual guarantees, see e.g. (Lacoste-Julien et al., 2013; Shalev-Shwartz & Zhang, 2013; 2014). The influential Stochastic1 Dual Coordinate Ascent (SDCA) framework (Shalev-Shwartz & Zhang, 2013) was motivated by the L2 regularized SVM, where coordinate descent is very efficient on the dual SVM formulation, with every iteration only requiring access to a single datapoint (i.e. a column of the matrix A in our setup). In contrast to primal stochastic gradient descent (SGD) methods, the SDCA algorithm family is often preferred as it is free of learning-rate parameters, and has a fast linear (geometric) convergence rate. SDCA and recent extensions (Takáč et al., 2013; Shalev-Shwartz & Zhang, 2014; Qu et al., 2014; Shalev-Shwartz, 2015; Zhang & Lin, 2015) require g to be strongly convex.\nUnder the weaker assumption of weak strong convexity (Necoara, 2015), a linear rate for the primal-dual convergence of SDCA was recently shown by (Ma et al., 2015c).\nIn the Lasso literature, a similar trend in terms of solvers has been observed recently, but with the roles of primal and dual problems reversed. For those problems, coordinate descent algorithms on the primal formulation have become the state-of-the-art, as in GLMNET (Friedman et al., 2010) and extensions (Shalev-Shwartz & Tewari, 2011; Yuan et al., 2012; 2010). Despite the prototypes of both problem types—SVM for the L2-regularized case and Lasso for the L1-regularized case—being closely related (Jaggi, 2014), we are not aware of existing primal-dual guarantees for coordinate descent methods on unmodified L1-regularized problems.\nComparison to smoothing techniques. Existing techniques for bringing L1-regularized and related problems into a primal-dual setting compatible with SDCA do rely on the classical Nesterov-smoothing approach (also known as the excessive gap technique) (Nesterov, 2005; Tran-Dinh & Cevher, 2014b). By adding a small amount of L2 to the part g, the objective becomes strongly convex; see, e.g., (Nesterov, 2012; Richtárik & Takáč, 2014; ShalevShwartz & Zhang, 2014; Zhang & Lin, 2015). However, the appropriate strength of smoothing is difficult to tune for the user. It will depend on the accuracy level, and will influence the choice of algorithms. Also, it will change the iterates, the resulting convergence rate as well as the tightness of the resulting duality gap. The line of work of Tran-Dinh & Cevher (2014a; 2015) provides duality gaps for the smooth version of any convex objective. Furthermore, primal-dual convergence rates follow for the case of proximally tractable objectives (Tran-Dinh & Cevher, 2015) and also objectives having an efficient Fenchel-type operator (Yurtsever et al., 2015), where per iteration, the\n1Here ’stochastic’ refers to randomized selection of the active coordinate.\nproximal or Fenchel problems for f and g need to be solved to a sufficient level of accuracy. In contrast, our approach doesn’t assume proximal or Fenchel tractability, and preserves all solutions of the original L1-optimization. Our approach leaves the iterate sequences of arbitrary existing algorithms unchanged, which is desirable in practice, allows the reusability of well-tuned existing solvers, and removes the need of tuning another parameter.\nDistributed setting. For L1-optimization with datasets exceeding the memory capacity of a single computer, we study distributed schemes leveraging the Lipschitzing trick in (Smith et al., 2015; Forte, 2015)."
    }, {
      "heading" : "3. Setup and Primal-Dual Structure",
      "text" : "In this paper, we consider optimization problems of the following primal-dual structure. As we will see, the relationship between primal and dual objectives has many benefits, including computation of the duality gap, which allows us to have certificates for the approximation quality.\nWe consider the following pair of optimization problems, which are dual2 to each other:\nmin α∈Rn\n[ D(α) := f(Aα) + g(−α)\n] , (A)\nmin w∈Rd\n[ P(w) := f∗(w) + g∗(ATw) ] . (B)\nThe two problems are associated to a given data matrixA ∈ Rd×n, and the functions f : Rd → R and g : Rn → R are allowed to be arbitrary closed convex functions. Here α ∈ Rn and w ∈ Rd are the respective variable vectors. The relation of (A) and (B) is called Fenchel-Rockafellar Duality where the functions f∗, g∗ in formulation (B) are defined as the convex conjugates3 of their corresponding counterparts f, g in (A).\nThe two main powerful features of this general duality structure are first that it includes many more machine learning methods than more traditional duality notions, and secondly that the two problems are fully symmetric, when changing respective roles of f and g. In typical machine learning problems, the two parts typically play the roles of a data-fit (or loss) term as well as a regularization term. As we will see later, those two roles can be swapped, depending on the application.\nOptimality Conditions. The first-order optimality conditions for our pair of vectors w ∈ Rd,α ∈ Rn in problems (A) and (B) are given as\nw ∈ ∂f(Aα) , (1a) Aα ∈ ∂f∗(w) , (1b)\nATw ∈ ∂g(−α) , (2a) −α ∈ ∂g∗(ATw) (2b)\n2For a self-contained derivation see Appendix C. 3h∗(v) := maxu∈Rd v Tu− h(u).\nsee e.g. (Bauschke & Combettes, 2011, Proposition 19.18), when applying their theorem twice, swapping the roles of primal and dual problems. The stated optimality conditions are equivalent to α,w being a saddle-point of the Lagrangian, which is given as L(α,w) = f∗(w) − 〈Aα,w〉 − g(−α) if −α ∈ dom(g) and w ∈ dom(f∗).\nDuality Gap. From the definition of the dual problems in terms of the convex conjugates, we always have P(w) ≥ P(w?) ≥ −D(α?) ≥ −D(α), giving rise to the definition of the general duality gap G(w,α) := P(w)− (−D(α)).\nFor differentiable f , the duality gap can be used more conveniently: Given α ∈ Rn s.t. Aα ∈ dom(f) in the context of (A), a corresponding variable vector w ∈ Rd for problem (B) is given by the first-order optimality condition (1a) as\nw = w(α) := ∇f(Aα) . (3)\nUnder strong duality, we have P(w?) = −D(α?) and w(α?) = w?, where α? is an optimal solution of (A). This implies that the suboptimality P(w(α)) − P(w?) is always bounded above by the simpler duality gap function\nG(α):=P(w(α))−(−D(α))≥ P(w(α))− P(w?) (4) which hence acts as a certificate of the approximation quality of the variable vector α.\nAssumption 1. Throughout the paper we will assume that\n1. Strong duality holds, e.g., AT dom(f)∩ cont(g) 6= ∅, where cont(g) are the points where g is continuous; 2. The function f∗ is β-strongly convex with respect to the standard Euclidean norm.\nThose assumptions are satisfied for the majority of classic machine learning methods. Table 1 gives an overview over some popular examples, and explains how they are formulated either as problem (A) or (B)."
    }, {
      "heading" : "4. Primal-Dual Guarantees for Any",
      "text" : "Algorithm Solving (A)\nIn this section we state an important lemma, which will later allow us to transform a suboptimality guarantee of any algorithm into a duality gap guarantee, for optimization problems of the form specified in the previous section.\nLemma 1. Consider an optimization problem of the form (A). Let g be µ-strongly convex4 with convexity parameter µ ≥ 0 with respect to the norm ‖ · ‖ and let f be 1/β-smooth. Then, for any iterate α ∈ dom(D) and any s ∈ [0, 1], it holds that D(α)−D(α?) ≥ sG(α) (5)\n+ s 2 2 ( µ(1−s) s ‖u−α‖ 2 − 1β ‖A(u−α)‖ 2),\n4The case general convex case µ = 0 is explicitly allowed.\nwhere G(α) is a gap function defined in (4) and\n−u ∈ ∂g∗(ATw(α)). (6)"
    }, {
      "heading" : "4.1. Linear Convergence Rates",
      "text" : "In this section we assume that we are using an arbitrary optimization algorithm applied to problem (A). It is assumed that the algorithm produces a sequence of (possibly random) iterates {α(t)}∞t=0 such that there exists C ∈ (0, 1], D ≥ 0 such that\nE[D(α(t))−D(α?)] ≤ (1− C)t D. (7) In the next two theorems, we define σ to be the maximal eigenvalue of the matrix ATA.\n4.1.1. CASE I. STRONGLY CONVEX g\nLet us assume g is γ-strongly convex (γ > 0) with respect to the standard Euclidean norm (equivalently, its conjugate g∗ has Lipschitz continuous gradient with a constant 1/γ). The following theorem provides a linear convergence guarantee for any algorithm with given linear convergence rate for the suboptimality D(α)−D(α?). Theorem 2. Assume the function g is γ-strongly convex, and we are using a linearly convergent algorithm as defined in (7). Then, for any\nt ≥ T := 1C log D(σβ+γ) γ (8)\nit holds that E[G(α(t))] ≤ .\nFrom (7) we can obtain that after 1C log D iterations, we would have a point α(t) such that E[D(α(t))−D(α∗)] ≤ . Hence, comparing with (8) only few more iterations are needed to get the guarantees for duality gap. The rate (7) is achieved by most of the first order algorithms, including proximal gradient descent (Nesterov, 2013) or SDCA (Richtárik & Takáč, 2014) with C ∼ γ or accelerated SDCA (Lin et al., 2014) with C ∼ √γ.\n4.1.2. CASE II. GENERAL CONVEX g (OF BOUNDED SUPPORT)\nIn this section we will assume that g∗ is Lipschitz (in contrast to smooth as in Theorem 2) and show that the linear convergence rate is preserved. Theorem 3. Assume that the function g∗ is L-Lipschitz continuous on dom(g∗) w.r.t. the L2-norm and we are using a linearly convergent algorithm (7). Then, for any\nt ≥ T := 1C log 2Dmax{1,2σL2/ β}\n(9)\nit holds that E[G(α(t))] ≤ .\nIn (Wang & Lin, 2014), it was proven that feasible descent methods when applied to dual of SVM do improve the objective geometrically as in (7). Later, (Ma et al., 2015c)\nextended this to stochastic coordinate feasible descent algorithms (including SDCA). Using our new Theorem 3, we can therefore extend their results to linear convergence for the duality gap for the SVM application."
    }, {
      "heading" : "4.2. Sub-Linear Convergence Rates",
      "text" : "In this case we will focus only on general L-Lipschitz continuous functions g∗ (if g is strongly convex, then many existing algorithms are available and converge with a linear rate).\nWe will assume that we are applying some (possibly randomized) algorithm on optimization problem (A) which produces a sequence (of possibly random) iterates {α(t)}∞t=0 such that\nE[D(α(t))−D(α?)] ≤ CD(t) , (10)\nwhere D(t) is a function wich has usually a linear or quadratic growth (i.e. D(t) ∼ O(t) or D(t) ∼ O(t2)).\nThe following theorem will allow to equip existing algorithms with sub-linear convergence in suboptimality, as specified in (10), with duality gap convergence guarantees.\nTheorem 4. Assume the function g∗ is L-Lipschitz continuous w.r.t. the L2-norm and we are using a sub-linearly convergent algorithm as quantified by (10). Then, for any t ≥ 0 such that\nD(t) ≥ max{ 2CβσL2 , 2CσL2 β 2 }, (11)\nit holds that E[G(α(t))] ≤ .\nLet us comment on Theorem 4 just stated above. If D(t) ∼ O(t) then this shows a rate of O( −2). Let us note two important facts:\n1. The guarantee holds for the duality gap of the iterate α(t) and not for some averaged solution. 2. This results is consistent with a work (Hush et al., 2006) shown only for SVMs. Hence our result is much more general as it holds for any L-Lipschitz continuous convex function g∗ and any β-strongly convex function f∗.\nLet us make one more important remark. In (ShalevShwartz & Zhang, 2013) the authors showed that SDCA (when applied on L-Lipschitz continuous g∗) has D(t) ∼ O(t) and they also showed that an averaged solution (over few last iterates) needs only O( −1) iterations to have duality gap ≤ . However, as a direct consequence of our Theorem 4 we can show e.g. that FISTA (Beck & Teboulle, 2009) (aka. accelerated gradient descent algorithm) or APPROX (Fercoq & Richtárik, 2015)5 (a.k.a. accelerated coordinate descent algorithm) will need O( −1) iterations to\n5For APPROX it is required that g is separable, such as for SVM or logistic loss.\nproduce an iterate α such that G(α) ≤ . Indeed, e.g. for APPROX the functionD(t) = ((t−1)τ+2n)2 (where τ is the size of a mini-batch) and C is a constant which depends on α(0) and α? and τ . Hence, to obtain an iterate α(t) such that E[G(α(t))] ≤ it is sufficient to choose τ ≥ 1 such that t (11) ≥ 1− 2nτ + max{ 1 τ √ 2Cβ σL2 , L τ √ 2Cσ β } is satisfied."
    }, {
      "heading" : "5. Extending Duality to Non-Lipschitz Functions",
      "text" : ""
    }, {
      "heading" : "5.1. Lipschitzing Trick",
      "text" : "In this section we present a trick that allows to generalize our results of the previous section from Lipschitz functions g∗ to non-Lipschitz functions. The approach we propose, which we call the Lipschitzing trick, will make a convex function Lipschitz on the entire domain Rd, by modifying its conjugate dual to have bounded support. Formally, the modification is as follows: Let B ⊂ Rd be some closed, bounded convex set. We modify g : Rn → R by restricting its support to the set B, i.e.\nḡ(α) := { g(α) if α ∈ B +∞ otherwise . (12)\nBy definition, this function has bounded support, and hence, by Lemma 5, its conjugate function ḡ∗ is Lipschitz continuous.\nMotivation. We will apply this trick to the part g of optimization problems of the form (A) (such that g∗ will become Lipschitz). We want that this modification of the optimization problem will have no impact on the outcome of any optimization algorithm running on (A). Instead, the trick will only affects the convergence theory in that it allows us to present a strong primal-dual rate. In the following, we will discuss how this can indeed be achieved by imposing only very weak assumptions on the original problem (A), and any monotone optimization algorithm.\nThe modification is based on the following known duality of Lipschitzness and bounded support, as given in Lemma 5 below. We need the following definition: Definition 1 (B-Bounded Support). A function g : Rd → R has B-bounded support if its effective domain is bounded by B w.r.t. a norm ‖.‖, i.e.,\ng(u) < +∞ ⇒ ‖u‖ ≤ B . (13) Lemma 5 (Duality between Lipschitzness and L-Bounded Support, (Rockafellar, 1997, Corollary 13.3.3)). Given a proper convex function g, it holds that g isL-Lipschitz (w.r.t the L2-norm) if and only if g∗ has L-bounded support (w.r.t the L2-norm).\nHence we can state Theorem 6 generalizing previous results for Lipschitz functions g∗.\nTheorem 6. For an arbitrary optimization algorithm running on problem (A), let α(t) denote its iterate sequence. Assume there is some closed convex set B containing all these iterates. Then, the same optimization algorithm run on the modified problem — given by Lipschitzing of g∗ using B — would produce exactly the same iterate sequence. Furthermore, Theorem 3 as well as Theorem 4 give primaldual convergence guarantees for this algorithm (for L such that B is L-bounded). Corollary 7. Assume the objective of optimization problem (A) has bounded level sets. For α(t) being the iterate sequence of a monotone optimization algorithm on problem (A) we denote δt := D(α(t)) and let Bt be the δt-level set of D. Write Bt > 0 for a value such that Bt is Btbounded w.r.t. the L2-norm. Then, at any state t of the algorithm, the set Bt contains all future iterates and Theorem 6 applies for L := Bt."
    }, {
      "heading" : "5.2. Norm-Regularized Problems",
      "text" : "We now focus on some applications. First, we demonstrate how the Lipschitzing trick can be applied to find primaldual convergence rates for problems regularized by an arbitrary norm. We discuss in particular the Lasso problem and show how the suboptimality bound can be evaluated in practice. In a second part, we discuss the elastic net regularizer and show how it fits into our framework.\nWe consider a special structure of problem (A), namely\nmin θ∈Rp\n`(Xθ) + λ ‖θ‖ . (14)\nwhere ` is some convex non-negative loss function. We choose B to be the L2-norm ball of radius B. Note that for any monotone algorithm (initialized at θ = 0) applied to (14) we have ‖θ‖ ≤ 1λ`(0) for every iterate. Furthermore, at every iterate θ we can bound ‖θ+‖ ≤ 1 λ (`(Xθ) + λ ‖θ‖) for every furture iterate θ +.\nFrom the equivalence of norms we have ‖θ‖2 ≤ C‖θ‖ and hence convergence guarantees of Theorem 6 apply to the general class of norm regularized problems for B := C 1λ`(0). Remark 1. In case of least squares loss we can choose B := C 12λ‖b‖ 2 2 and for the logistic regression loss B := Cmλ log(2) is a save choice.\nDuality Gap. For any problem of the form (14) we can now determine the duality gap. We apply the Lipschitzing trick to g(−α) := λ‖α‖ as in (12), then the convex conjugate of ḡ is given by\nḡ∗(u) = 0 ‖u‖∗ ≤ λmax α:‖α‖2≤B uTα− λ‖α‖ else . (15)\nwhere ‖.‖∗ denotes the dual norm of ‖.‖. Hence, using the optimality condition (1a) we can write the duality gap of the modified problem as\nḠ(α) = (Aα)T∇f(Aα) + λ‖α‖+ ḡ∗(ATw(α)) (16) Remark 2. The original duality gap G(α) is only defined on the set { α : ‖ATw(α)‖∗ ≤ λ } , where for α ∈ B it is equivalent to Ḡ(α). But, in contrast to the unmodified duality gap, our new gap Ḡ(α) is defined on the entire space Rd.\n5.2.1. L1-REGULARIZED PROBLEMS\nWe consider the following special case of (14):\nmin θ∈Rp `(Xθ) + λ ‖θ‖1 , (17)\nwhere X ∈ Rm×p is the data matrix and ` is some nonnegative smooth function. In the following we will use our framework and the results established in the previous sections to give primal/dual convergence rates for any algorithm applied to (17). To do so, we map (17) to our setting (A) as proposed in row 1 of Table 1 where, A := X ∈ Rm×p and α := θ ∈ Rp.\nWe choose B to be the L2-norm ball of radius B := 1λ`(0). As we have seen in Section 5.2 B contains all iterates of any monotone algorithm (initialized at θ = 0) applied to (17) and hence the Lipschitzing trick with B can be applied without modifying the optimization (17). An illustration of this modification as well as the impact on its dual are illustrated in Figure 1.\nRemark 3. We just showed that Theorem 6 applies to the Lasso problem (17), for the 1λ`(0)-bounded set B.\nDuality Gap. The duality gap (16) for the modified Lasso problem can be computed at every iterate θ as\nḠ(θ) =(Xθ)T∇`(Xθ)\n+ ‖θ‖2 n∑ i=1 [∣∣XT:iw(θ)∣∣− λ]+ + λ‖θ‖1 (18)"
    }, {
      "heading" : "5.2.2. GROUP LASSO",
      "text" : "The group lasso is widely used in applications to capture more tailored notions of structured sparsity, as by sparsity in terms of disjoint groups of variables (Bach et al., 2011).\nThe group lasso regularizer is a norm on Rn, and is defined\nas g(α) = λ ∑ k ‖αGk‖2, for a fixed partition of the in-\ndices into disjoint groups, {1..n} = ⊎ k Gk, see e.g. (Boyd & Vandenberghe, 2004, Example 3.26).\nUsing the group lasso as regularizer in our general optimization setting is shown in row 6 of Table 1. For any existing algorithm running on the original group lasso objective, our Theorem 6 shows that by the Lipschitzing trick, our primal-dual convergence rates apply."
    }, {
      "heading" : "5.2.3. ELASTIC NET REGULARIZED PROBLEMS",
      "text" : "The second application we will discuss is elastic net regularization:\nmin θ∈Rp\n`(Xθ) + λ (η\n2 ‖θ‖22 + (1− η)‖θ‖1\n) , (19)\nfor fixed parameter η ∈ (0, 1], where X ∈ Rm×p is the data matrix and ` some smooth loss function.\nOur framework allows two different ways to solve problem (19), by either mapping it to formulation (A) as in row 2 of Table 1 or to (B) as suggested in row 3 of Table 1. In the first case θ is mapped to α and in the second case to w. As D consists of a strongly convex and a smooth term in both scenarios Theorem 2 gives strong convergence guarantees for either of these. The choice if a dual or primal optimization algorithm will be more beneficial in practice will depend on the application. We will discuss this choice in more detail for coordinate descent methods in Section 6.\nDuality Gap. For the elastic net problem in (19) we can compute the duality gap (4) as follows: G(θ) = (Xθ)T∇`(Xθ) + 12ηλ n∑ i=1\n[∣∣XT:iw∣∣− (1− η)λ]2+ + λ ( η 2‖θ‖ 2 2 + (1− η)‖θ‖1\n) for the derivation, see Appendix H.\nRemark 4. As η → 0 we approach the pure L1-case and this gap blows up as G(θ) → ∞. Comparing this to (18), we see that the Lipschitzing trick allows to get certificates even in cases where the duality gap of the unmodified problem is infinity."
    }, {
      "heading" : "6. Coordinate Descent Algorithms",
      "text" : "We now focus on a very important class of algorithms, that is coordinate descent methods. In this section, we show how our theory implies much more general primal-dual convergence guarantees for coordinate descent algorithms.\nPartially Separable Problems. A widely used subclass of optimization problems arises when one part of the objective becomes separable. Formally, this is expressed as g(α) =∑n i=1 gi(−αi) for univariate functions gi : R→ R for i ∈ [n]. Nicely in this case, the conjugate of g also separates\nAlgorithm 1 Coordinate descent on D(α) 1: Input: Data matrix A.\nStarting point α(0) := 0 ∈ Rn, w(0) = w(α(0)). 2: for t = 1, 2, . . . T do 3: Pick i ∈ [n] randomly 4: Find ∆αi minimizing D(α(t−1) + ei∆αi) 5: α(t) ← α(t−1) + ∆αiei 6: w(t) ← w(α(t)) 7: end for 8: Let ᾱ = 1T−T0 ∑T−1 t=T0 α(t)\nas g∗(y) = ∑ i g ∗ i (yi). Therefore, the two optimization problems (A) and (B) write as\nD(α) := f(Aα) + ∑ i gi(−αi) (SA)\nP(w) := f∗(w) + ∑ i g ∗ i (A T :iw) , (SB)\nwhere A:i ∈ Rd denotes the i-th column of A."
    }, {
      "heading" : "6.1. The Algorithm",
      "text" : "We consider the coordinate descent algorithm described in Algorithm 1. Initialize α(0) = 0 and then at each iteration, sample and update a random coordinate i ∈ [n] of the parameter vector α to iteratively minimize (SA). Finally, after T iterations output ᾱ, the average vector over the latest T −T0 iterates. The parameter T0 is some positive number smaller than T .\nAs we will show in the following section, coordinate descent on D(α) is not only an efficient optimizer of the objective D(α), but also provably reduces the duality gap. Therefore, the same algorithm will simultaneously optimize the dual objective P(w).\nRemark 5. Note that our Algorithm 1 recovers the widely used SDCA setting (Shalev-Shwartz & Zhang, 2014) as a special case, when we choose f∗ := λ2 ‖.‖ 2 2 in (SA)."
    }, {
      "heading" : "6.2. Primal-Dual Analysis for Coordinate Descent",
      "text" : "We first show linear primal-dual convergence rate of Algorithm 1 applied to (SA) for strongly convex gi. Later, we will generalize this result to also apply to the setting of general Lipschitz gi. This generalization together with the Lipschitzing trick will allow us to derive primal-dual convergence guarantees of coordinate descent for a much broader class of problems, including the Lasso problem.\nFor the following theorems we assume that the columns of the data matrix A are scaled such that ‖A:i‖ ≤ R for all i ∈ [n].\nTheorem 8. Consider Algorithm 1 applied to (SA). Let Assumption 1 hold. Then, if gi is µ-strongly convex for\nall i, it suffices to have a total number of iterations of T ≥ ( n+ nR 2\nµβ\n) log ([ n+ nR 2\nµβ\n] (0) D\nP ) to get G(α(T )) ≤ P . Moreover, to obtain an expected duality gap of G(ᾱ) ≤ P it suffices to have T > T0 with\nT0 ≥ ( n+ nR 2\nµβ\n) log ([ n+ nR 2\nµβ\n] (0) D\n(T−T0) P ) where (0)D is the initial suboptimality in D(α).\nTheorem 8 allows us to upper bound the duality gap, and hence the suboptimality, for every iterate α(T ), as well as the average iterate ᾱ output by Algorithm 1. In order to prove this result it was necessary to derive a lemma relating the average increase inD per coordinate descent step to the duality gap. This Lemma as well as the proof thereof can be found in Appendix I. In the following we loosen this result to apply to L-Lipschitz loss functions.\nTheorem 9. Consider Algorithm 1 applied to (SA). Let Assumption 1 hold. Then, if g∗i is L-Lipschitz for all i, it suffices to have a total number of iterations of\nT ≥ max { 0, n log (0) D β\n2L2R2n\n} + n+ 20n 2L2R2\nβ P\nto get G(ᾱ) ≤ P . Moreover, when t ≥ T0 with\nT0 = max\n{ 0, n log (0) D β\n2L2R2n\n} + 16n 2L2R2\npβ\nwe have the suboptimality bound of E[D(α(t))−D(α?)] ≤ P /2, where (0) D is the initial dual suboptimality. Remark 6. Theorem 9 shows that for Lipschitz g∗i , Algorithm 1 has O( −1) convergence rate in the dual suboptimality and O( −1) convergence rate in G(ᾱ). Comparing this result to Theorem 4 which suggests O( −2) convergence rate in G(α) for O( −1) convergent algorithms, we see that averaging the parameter vector crucially improves convergence in the case of non-smooth f .\nRemark 7. The convergence results for SDCA in (ShalevShwartz & Zhang, 2013) are consistent with our results and can be recovered as a special case of our analysis. See Corollary 18, 15, 19 in Appendix I."
    }, {
      "heading" : "6.3. Application to L1 and Elastic-Net Regularized Problems",
      "text" : "We now apply Algorithm 1 to the L1-regularized problems, as well as elastic net regularized problems. We state improved primal-dual convergence rates which are more taylored to the coordinate-wise setting.\nCoordinate Descent on L1-Regularized Problems.\nCorollary 10. We can use the Lipschitzing trick together with Theorem 9 to derive a primal-dual convergence re-\nsult for the Lasso problem (17). We find that the L1norm term has B-bounded support after applying the Lipschitzing trick as in (12) and hence the number of iterations needed on the Lasso problem to get a duality gap of G(ᾱ) ≤ P is\nT ≥ max { 0, p log β (0) D\n2B2R2p\n} + p+ 20p 2B2R2\nβ P\nRemark 8. We specify the different parameters of Corollary 10 for least squares loss as well as the logistic regression loss (defined in Table 1). Both are 1-smooth (f∗ is 1-strongly convex) and we have β := 1. The initial suboptimality (0)D can be upper bounded by 1 2‖b‖ 2 2 for the former and by m log(2) for the latter. The choice of B was discussed in Remark 1, where C = 1 for L1-regularization.\nCoordinate Descent on Elastic-Net Regularized Problems. In Section 5.2.3 we discussed how the elastic-net problem in (19) can be mapped to our setup. In the first scenario (row 2, Table 1) we note that the resulting problem is partially separable and an instance of (SA). In the second scenario we map (19) to (B) (row 3, Table 1). Assuming that the loss function `w is separable, this problem is an instance of (SB). The convergence guarantees when applying Algorithm 1 on the primal or on the dual are summarized in Corollary 11.\nIn the following, we express the scaling of the input data matrix X in constants R,P > 0 such that ‖X:i‖ ≤ R, i ∈ [p] and ‖Xj:‖ ≤ P, j ∈ [m]. Corollary 11. Consider Algorithm 1 for an elastic net regularized problem (19), running on either the primal or the dual. Then, to obtain a duality gap of G(α(T )) ≤ P , it suffices to have a total number of iterations of\nT ≥ (p+ pR 2 ληζ ) log([p+ pR2 ληζ ] (0) D P )\nfor coordinate descent on (19) and\nT ≥ (m+ mP 2 ληζ ) log([m+ mP 2 ληζ ] (0) D P )\nfor coordinate descent on the dual of (19).\nAccording to Corollary 11 the convergence rate is the same for both scenarios. The constants however depend on the dimensions of A – for m p the primal version is benefitial wheras for p m the dual version converges faster."
    }, {
      "heading" : "7. Numerical Experiments",
      "text" : "Here we illustrate the usefulness of our framework by showcasing it for two important applications, each one showing two algorithm examples for optimizing problem (A).\nLasso. The top row of Figure 2 shows the primal-dual convergence of Algorithm 1 (SDCA) as well as the accelerated\nvariant of SDCA (APPROX, Fercoq & Richtárik (2015)), both applied to the Lasso problem (A). We have applies the Lipschitzing trick as described in Section 5.1. This makes sure that w(α) will be always feasible for the modified dual (B), and hence the duality gap can be evaluated.\nSVM. It was shown in (Shalev-Shwartz & Zhang, 2013) that if SDCA is run on the dual SVM formulation, and we consider an ”average” solution (over last few iterates), then the duality gap evaluated at averaged iterates has a sub-linear convergence rate O(1/t). As a consequence of Theorem 4, we have that the APPROX algorithm (Fercoq & Richtárik, 2015) will provide the same sub-linear convergence in duality gap, but holding for the iterates themselves, not only for an average. On the bottom row of Figure 2 we compare SDCA with its accelerated variant on two benchmark datasets.6 We have chosen λ = 1/n."
    }, {
      "heading" : "8. Conclusions",
      "text" : "We have presented a general framework allowing to equip existing optimization algorithms with primal-dual certificates. For future research, it will be interesting to study more applications and algorithms fitting into the studied problem structure, including more cases of structured sparsity, and generalizations to matrix problems.\nAcknowledgments. We thank Michael P. Friedlander for fruitful discussions.\n6Available at https://www.csie.ntu.edu.tw/ ˜cjlin/libsvmtools/datasets/."
    }, {
      "heading" : "A. Basic Definitions",
      "text" : "Definition 2 (L-Lipschitz Continuity). A function h : Rd → R is L-Lipschitz continuous if ∀a, b ∈ Rd, we have\n|h(a)− h(b)| ≤ L‖a− b‖ . (20) Definition’ 1 (B-Bounded Support). A function h : Rd → R has B-bounded support if its effective domain is bounded by B w.r.t. a norm ‖.‖, i.e.,\nh(u) < +∞ ⇒ ‖u‖ ≤ L . (21) Definition 3. The δ-level set of a function h : Rd → R is defined as L(δ) := {x : h(x) ≤ δ}. Definition 4 (L-Smoothness). A function h : Rd → R is called L-smooth, for L > 0, if it is differentiable and its derivative is L-Lipschitz continuous, or equivalently\nh(u) ≤ h(w) + 〈∇h(w),u−w〉+ L 2 ‖u−w‖2 ∀u,w ∈ Rd . (22)\nDefinition 5 (µ-Strong Convexity). A function h : Rd → R is called µ-strongly convex, for µ ≥ 0, if\nh(u) ≥ h(w) + 〈∇h(w),u−w〉+ µ 2 ‖u−w‖2 ∀u,w ∈ Rd . (23)\nAnd analogously if the same holds for all subgradients, in the case of a general closed convex function h."
    }, {
      "heading" : "B. Convex Conjugates",
      "text" : "We recall some basic properties of convex conjugates, which we use in the paper.\nThe convex conjugate of a function f : Rd → R is defined as f∗(v) := max\nu∈Rd vTu− f(u) . (24)\nSome useful properties, see (Boyd & Vandenberghe, 2004, Section 3.3.2):\n• Double conjugate: (f∗)∗ = f if f is closed and convex. • Value Scaling: (for α > 0) f(v) = αg(v) ⇒ f∗(w) = αg∗(w/α) . • Argument Scaling: (for α 6= 0) f(v) = g(αv) ⇒ f∗(w) = g∗(w/α) . • Conjugate of a separable sum: f(v) = ∑ i φi(vi) ⇒ f∗(w) = ∑ i φ ∗ i (wi) .\nLemma’ 5 (Duality between Lipschitzness and L-Bounded Support, (Rockafellar, 1997, Corollary 13.3.3)). Given a proper convex function f , it holds that f is L-Lipschitz if and only if f∗ has L-bounded support.\nLemma 12 (Duality between Smoothness and Strong Convexity, (Kakade et al., 2009, Theorem 6)). Given a closed convex function f , it holds that f is µ-strongly convex w.r.t. the norm ‖.‖ if and only if f∗ is (1/µ)-smooth w.r.t. the dual norm ‖.‖∗. Lemma 13 (Conjugates of Indicator Functions and Norms).\ni) The conjugate of the indicator function ιC of a set C ⊂ Rn (not necessarily convex) is the support function of the set C, that is\nι∗C(x) = sup s∈C 〈s,x〉\nii) The conjugate of a norm is the indicator function of the unit ball of the dual norm.\nProof. (Boyd & Vandenberghe, 2004, Example 3.24 and 3.26)"
    }, {
      "heading" : "C. Primal-Dual Relationship",
      "text" : "The relation of the primal and dual problems (A) and (B) is a special case of the concept of Fenchel Duality. Using the combination with the linear map A as in our case, the relationship is called Fenchel-Rockafellar Duality, see e.g. (Borwein & Zhu, 2005, Theorem 4.4.2) or (Bauschke & Combettes, 2011, Proposition 15.18).\nFor completeness, we here illustrate this correspondence with a self-contained derivation of the duality.\nStarting with the formulation (A), we introduce a helper variable v ∈ Rd. The optimization problem (A) becomes: min α∈Rn f(v) + g(−α) such that v = Aα . (25)\nIntroducing dual variables w = [w1, . . . , wd], the Lagrangian is given by:\nL(α,v;w) := f(v) + g(−α) + wT (v −Aα) . The dual problem follows by taking the infimum with respect to α and v:\ninf α,v L(w,α,v) = inf α\n{ g(−α)−wTAα } + inf\nv\n{ f(v) + wTv } = − sup\nα\n{ wTAα− g(−α) } − sup\nv\n{ wTv − f(v) } = −f∗(ATw)− g∗(w) . (26)\nWe change signs and turn the maximization of the dual problem (26) into a minimization and thus we arrive at the dual formulation (B) as claimed:\nmin w∈Rd\n[ P(w) := f∗(ATw) + g∗(w) ] ."
    }, {
      "heading" : "D. Proof of Lemma 1",
      "text" : "The proof is partially motivated by proofs in (Ma et al., 2015b;a; Shalev-Shwartz & Zhang, 2013) but have a crucial unique steps and tricks.\nWe have\nD(α)−D(α?) = D(α)−min δα D(δα)\n= max δα\n( g(−α)− g(−α− δα) + f(Aα)− f(A(α + δα)) ) = max s∈[0,1] ( g(−α)− g(−α− s(u−α)) + f(Aα)− f(A(s(u−α) + α))\n) ≥ g(−α)− g(−α− s(u−α)) + f(Aα)− f(A(s(u−α) + α)). (27)\nNow, we can use the fact, that function f : Rd → R has Lipschitz continuous gradient with constant 1/β to obtain\nD(α)−D(α?) (27) ≥ g(−α)− g(−α− s(u−α)) + f(Aα)− f(Aα)− 〈∇f(Aα), As(u−α)〉 − 1\n2β ‖As(u−α)‖2\n= g(−α)− g(−α− s(u−α))− 〈∇f(Aα), As(u−α)〉 − 1 2β ‖As(u−α)‖2. (28)\nNow, we will use a strong convexity property of a function g to obtain\nD(α)−D(α?) (28) ≥ s ( g(−α)− g(−u)− 〈∇f(Aα), A(u−α)〉 ) ︸ ︷︷ ︸\nΛ\n+ s2\n2 (µ(1− s) s ‖u−α‖2 − 1 β ‖A(u−α)‖2 ) .\n(29)\nNow, let us examine the relation of the equation above with duality gap. We have\nG(α) = P(w(α))− (−D(α)) = g∗(ATw(α)) + g(−α) + f∗(w(α)) + f(Aα) = g∗(ATw(α)) + g(−α) + f∗(∇f(Aα)) + f(Aα) = g∗(ATw(α)) + g(−α) + 〈w(α), Aα〉 . (30)\nwhere we have used the w(α) = ∇f(Aα).\nNow, let us analyze the expression Λ from (29). We have\nΛ = g(−α) + 〈w(α), Aα〉 − g(−u)− 〈w(α), Au〉 . (31)\nNow, using the convex conjugate maximal property and (6) we have g(−u) = − 〈 u, ATw(α) 〉 − g∗(ATw(α)). (32)\nPlugging (32), (30) and (31) into (29) gives us\nD(α)−D(α?) ≥ sG(α) + s 2\n2 (µ(1− s) s ‖u−α‖2 − 1 β ‖A(u−α)‖2 ) .\nand (5) follows."
    }, {
      "heading" : "E. Proof of Theorem 2",
      "text" : "Let us upper-bound the second term in (5). We have\nγ(1−s) s ‖u−α‖ 2 − 1β ‖A(u−α)‖ 2 ≥ [ γ(1−s) s − σ\nβ\n] ‖u−α‖2.\nNow, if we choose s = γσ β+γ then\nγ\nγ + σβ E[G(α(t))]\n(5) ≤ E[D(α(t))−D(α?)] (7) ≤ (1− C)t D.\nAfter multiplying the equation above by σ β+γ\nγ and requiring RHS to be ≤ we will get σ β + γ\nγ (1− C)tD ≤ ,\nt ≥ log γ D(σβ+γ)\nlog(1− C) and (8) follows."
    }, {
      "heading" : "F. Proof of Theorem 3",
      "text" : "From Lemma 1 we have that\nsE[G(α(t))] (5) ≤ E[D(α(t))−D(α?) + s 2\n2β ‖A(u−α)‖ 2]\n(7) ≤ (1− C)t D + σ\nβ s2 2 E[‖u−α‖ 2]. (33)\nNow, because g∗ is L-Lipschitz, therefore g is L-bounded. Further using the relationship between Lipschitzness and the subgradient (Shalev-Shwartz & Singer, 2006, Lemma 2.6) we have for any u,α that ‖u−α‖2 ≤ 2L2. Therefore we can conclude that\nE[G(α(t))] (33) ≤ 1 s (1− C)tD + sσ β L2. (34)\nNow, let us choose s̄ = min{1, β2σL2 }. To have the RHS of (34) ≤ 2 it is enough to choose\nt ≥ T = log(s̄ 2D )\n(1− C) and (9) follows."
    }, {
      "heading" : "G. Proof of Theorem 4",
      "text" : "Using Lemma 1 we have that\nE[G(α(t))] (5) ≤ 1 s E[D(α(t))−D(α?)] + s 2 σ β L2 (10) ≤ 1 s C D(t) + s 2 σ β L2. (35)\nNow, by choosing s = √\nC D(t) 2β σL2\n(11) ∈ [0, 1] we obtain that\nE[G(α(t))] (35) ≤\n√ 2CσL2\nβD(t) . (36)\nIn order to have the RHS of the equation above ≤ we have that (11) has to be satisfied."
    }, {
      "heading" : "H. Duality Gap for Elastic Net Regularized Problems",
      "text" : "Consider the elastic net problem in (19). The conjugate dual of the elastic net regularizer is given in Lemma 20. Let V := { i : ∣∣XT:iw∣∣ > λ(1− η)}. Map (17) to (A), then the dual counterpart of (17) is given by:\nP(w) = `∗(w) + 12ηλ ∑ i∈V ( ∣∣XT:iw∣∣− (1− η)λ]+)2.\nForm the optimality condition (1a) we know that w(θ) = ∇`(Xθ) and hence G(θ) = (Xθ)T∇`(Xθ) + 12ηλ ∑ i∈V ( ∣∣XT:iw∣∣− (1− η)λ)2 + λ(η2‖θ‖22 + (1− η)‖θ‖1) .\nNote that by the symmetry of (A) and (B) the duality gap does not depend on whether we map (17) to (A) or (B). Hence, using optimality condition (2b), we can show the same result for the second scenario, where (17) is mapped to (A)."
    }, {
      "heading" : "I. Convergence Results for Coordinate Descent",
      "text" : "For the proof of Theorem 9 and Theorem 8 we will need the following Lemma, which we will proof in Section I.3.This lemma allows us to lower bound the expected per step increase in D for coordinate descent algorithms on D.\nLemma 14. Consider problem formulation (SB) and (SA). Let gi be µ-strongly convex with convexity parameter µ ≥ 0 with respect to the norm ‖.‖, ∀i ∈ [n] and let f∗ be β-strongly convex. Then for any iteration t and any s ∈ [0, 1], it holds that\nE[D(α(t−1))−D(α(t))] ≥ s n E[G(αt−1)]− s\n2F (t)\n2 , (37)\nwhere\nF (t) := 1\nn n∑ i=1 ( 1 β ‖A:i‖2 − (1− s)µ s ) E [ (u (t−1) i − α (t−1) i ) 2 ] , (38)\nand −u(t−1)i ∈ ∂g∗i (AT:iw(α(t−1))).\nI.1. Proof of Theorem 8\nTheorem’ 8. Consider Algorithm 1. Assume that gi is µ-strongly convex for all i and f∗ is β-strongly convex. Fruther scale the columns of A such that ‖A:i‖ ≤ R, i ∈ [n]. Then, to obtain a duality gap of E[G(α(T ))] ≤ P , it suffices to have a total number of iterations of\nT ≥ ( n+ nR2\nµβ\n) log ([ n+ nR2\nµβ\n] (0) D\nP\n) .\nMoreover, to obtain an expected duality gap of E[G(ᾱ)] ≤ P it suffices to have a T > T0 with T0 ≥ ( n+ nR2\nµβ\n) log ([ n+ nR2\nµβ\n] (0) D\n(T − T0) P\n) ,\nwhere (0)D is the initial dual suboptimality.\nThe proof of this theorem is motivated by proofs in (Shalev-Shwartz & Zhang, 2013) but generaliying their result in (Shalev-Shwartz & Zhang, 2013)[Theorem 5]. To prove Theorem 8 we apply Lemma 14 with s = µβR2+µβ ∈ [0, 1]. This\nchoice of s implies F (t) ≤ 0 ∀t as defined in (38). Hence,\nE[D(α(t−1))−D(α(t))] ≥ s n G(α(t−1)) = s n E[P(w(t−1)) +D(α(t−1))].\nLet (t)D denote the dual suboptimality (t) D := D(α (t))−D(α?). As (t−1)D ≤ P (w(t−1)) +D(α(t−1)) and D(α(t−1))− D(α(t)) =\n(t−1) D − (t) D , we obtain\nE[ (t)D ] ≤ (\n1− s n\n) E[ (t−1)D ] ≤ ( 1− s\nn\n)t E[ (0)D ] ≤ exp(−st/n)E[ (0) D ] ≤ exp ( − µβt n(R2 + µβ) ) E[ (0)D ].\nTo upper bound the expected suboptimality as E[ (t)D ] ≤ D we need\nt ≥ ( nR2\nµβ + n\n) log ( E[ (0)D ] D ) .\nNow observe that E[G(α(t−1))] ≤ n\ns E[ (t−1)D − (t) D ] ≤\nn s E[ (t−1)D ] (39)\nand hence with P ≥ ns (t) D we get a duality gap smaller than P . Therefore we require t ≥ ( nR2\nµβ + n\n) log (( n+ nR2\nµβ ) E[ 0D] P ) .\nThis proves the first part of Theorem 8 and the second part follows immediately if we sum (39) over t = T0, ..., T − 1.\nRemark 9. From Theorem 8 it follows that for T = 2T0 and T0 ≥ n+ nR 2\nµβ we need T ≥ 2 ( n+ nR2\nµβ\n) log( (0) D\nP )\nCorollary 15. We recover Theorem 5 in (Shalev-Shwartz & Zhang, 2013) as a special case of Theorem 8. Therefore, we consider their optimization objectives, namely\nP(w) := 1 n n∑ i=1 Φi(x T i w) + λ 2 ‖w‖2 (40)\nD(α) := −  1 n n∑ i=1 −Φ∗i (−αi)− λ 2 ∥∥∥∥∥ 1λn n∑ i=1 αixi ∥∥∥∥∥ 2  . (41)\nwhere xi are the columns of the data matrix X . We assume that Φ∗i (α) is γ-strongly convex for i ∈ [n]. We scale the columns of X such that ‖xi‖ ≤ 1. Hence, we find that\nT0 ≥ ( n+ 1\nγλ\n) log ([ n+ 1\nγλ\n] 1\nP (T − T0) ) iterations are sufficient to obtain a duality gap of E[P(w̄)− (−D(ᾱ))] ≤ P .\nProof. We consider (40) and (41) as a special case of the separable problems (SA) and (SB). We set gi(α) := 1nΦ ∗ i (α) and f∗(w) := λ2 ‖w‖ 2. In this case µ = 1nγ and β = λ. Defining A := 1 nX and using the assumption ‖xi‖ ≤ 1 we have R := 1n and using Φi(0) ≤ 1 we have (0) D ≤ 1and applying Theorem 8 to this setting concludes the proof.\nI.2. Proof of Theorem 9\nThis Theorem generalizes the results of (Shalev-Shwartz & Zhang, 2013, Theorem 2).\nTheorem’ 9. Consider the procedure SDCA with α(0) = 0. Assume that g∗i is L-Lipschitz for all i and f∗ is β-strongly convex. Further assume E[‖A:i‖] ≤ R. To obtain a duality gap of E[G(ᾱ)] ≤ P , it suffices to have a total number of iterations of\nT ≥ T0 + n+ n2\nP\n4L2R\nβ ≥ max{0, n log(0.5β(RL)−2n−1)}+ n+ 20n\n2L2R2\nβ P\nMoreover, when t ≥ T0, we have the suboptimality bound of E[D(α(t))−D(α∗)] ≤ P /2.\nWe rely on the following Lemma\nLemma 16. (Shalev-Shwartz & Zhang, 2013, Lemma 21) Let h : R→ R be an L-Lipschitz functions. Then, for any α, s.t. |α| > L we have that h∗(α) =∞.\nAs a direct corollary of Lemma 16 we have the following:\nLemma 17. Suppose that for all i, g∗i is L-Lipschitz. Let F (t) be as defined in Lemma 14 (with γ = 0) and assume E[‖ai‖] ≤ R ∀i. Then, F (t) ≤ 4L 2 β R 2 ∀t.\nProof. From, Lemma 17 we know |αi| ≤ L. By the relationship between Lipschitzness and the subgradient (ShalevShwartz & Singer, 2006, Lemma 2.6) we have |ui| ≤ L and thus, |αi − ui| ≤ 4L2, together with ‖A:i‖ ≤ R the bound on F (t) follows.\nRemark 10. In the case of Lasso we have gi(−αi) = λ|αi|. Using the Lipschitzing trick, we replace gi(·) by\nḡi(α) = { λ|α| : α ∈ [−B,B] +∞ : otherwise,\nwhich has B-bounded support. Hence, its conjugate\nḡ∗(x) = { 0 : x ∈ [−λ, λ] B(|x| − λ) : otherwise,\nis B-Lipschitz and Lemma 16 and Lemma 17 apply with L := B.\nNow, to prove Theorem 9, let F = maxt F (t) and recall that by Lemma 17 we can upper bound F by 4L 2 β R 2.\nFurthermore, our main Lemma 14 on the improvement per step tells us that\nE[D(α(t−1))−D(α(t))] ≥ s n E[G(α(t−1))]− s\n2\n2 F, (42)\nWith (t)D = D(α (t))−D(α?) ≤ G(α(t)) and D(α(t))−D(α(t−1)) = (t−1)D − (t) D , this implies\nE[ (t−1)D − (t) D ] ≥\ns n E[ (t−1)D ]−\ns2F\n2\nE[ (t−1)D ]− E[ (t) D ] ≥\ns n E[ (t−1)D ]−\ns2F\n2 E[ (t)D ] ≤ (\n1− s n\n) E[ (t−1)D ] + s2F\n2\nWe next show that with this inequality we can bound the dual suboptimality as\nE[ (t)D ] ≤ 2Fn2\n2n+ t− t0 (43) for t ≥ t0 = max { 0, n log ( 2 (0) D\nFn\n)} Indeed, let us choose s = 1,then at t = t0, we have\nE[ (t)D ] ≤ (\n1− 1 n\n)t e\n(0) D + t−1∑ i=0 ( 1− 1 n )i F 2\n≤ (\n1− 1 n\n)t e\n(0) D +\n1 1− (1− 1/n) F 2\n≤ e−t/ne(0)D + nF 2 ≤ Fn\nFor t > t0 we use an inductive argument. Suppose the claim holds for t− 1, therefore E[ (t)D ] ≤ (\n1− s n\n) e\n(t−1) D +\ns2F\n2 ≤ (\n1− s n ) 2Fn2 2n+ (t− 1)− t0 + s2F 2\nchoosing s = 2n2n+t−1−t0 ∈ [0, 1] yields E[ (t)D ] ≤ (\n1− 2 2n+ t− 1− t0\n) 2Fn2\n2n+ (t− 1)− t0 +\n( 2n\n2n+ t− 1− t0\n)2 F\n2\n= ( 1− 2\n2n+ t− 1− t0\n) 2Fn2\n2n+ (t− 1)− t0 +\n( 1\n2n+ t− 1− t0\n) 2Fn2\n2n+ t− 1− t0\n= ( 1− 1\n2n+ t− 1− t0\n) 2Fn2\n2n+ (t− 1)− t0\n= 2Fn2 (2n+ t− 1− t0) 2n+ t− 2− t0 2n+ t− 1− t0 ≤ 2Fn 2\n(2n+ t− t0) This proves the bound (43) on the suboptimality. To get a result on the duality gap we sum (42) over the interval t = T0 + 1, ..., T and obtain\nE[D(α(T0))−D(α(T ))] ≥ s n E\n[ T∑\nt=T0+1\nP (w(t−1)) +D(α(t−1)) ] − (T − T0) s2\n2 F,\nand rearranging terms we get\nE\n[ 1\nT − T0 T∑ t=T0+1 P (w(t−1)) +D(α(t−1)) ] ≤ n s(T − T0) E[D(α(T0))−D(α(T ))] + sn 2 F,\nNow if we choose w̄, ᾱ to be the average vectors over t ∈ {T0 + 1, T}, then the above implies\nE[G(ᾱ)] = E [P (w̄) +D(ᾱ)] ≤ n s(T − T0) E[D(α(T0))−D(α(T ))] + sn 2 F,\nIf T ≥ n+ T0 and T0 ≥ t0, we can set s = n/(T − T0) and combining this with (43) we obtain\nE[G(ᾱ)] = ≤ E[D(α(T0))−D(α(T ))] + Fn 2\n2(T − T0)\n≤ E[D(α(T0))−D(α(∗))] + Fn 2\n2(T − T0)\n≤ 2Fn 2\n2n+ t− t0 +\nFn2\n2(T − T0)\nA sufficient condition to upper bound the duality gap by P is that T0 ≥ 4Fn 2 P − 2n + t0 and T ≥ T0 + Fn 2 P which also implies E[D(α(T0))−D(α(∗))] ≤ P /2. Since we further require T0 ≥ t0 and T −T0 ≥ n, the overall number of required iterations has to satisfy\nT0 ≥ max{t0, 4Fn2\nP − 2n+ t0} and T − T0 ≥ max{n,\nFn2\nP }\nUsing Lemma 17 we can bound the total number of required iterations to reach a duality gap of P by\nT ≥ T0 + n+ n2\nP\n4L2R2\nβ\n≥ t0 + 4n2\nP\n4L2R2\nβ + n+\nn2\nP\n4L2R2\nβ\n≥ max { 0, n log ( (0) D β\n2nR2L2\n)} + n+ 20n2L2R2\nβ P\nwhich concludes the proof of Theorem 9.\nCorollary 18. We recover Theorem 2 in (Shalev-Shwartz & Zhang, 2013) as a special case of Theorem 9. Therefore, we consider the optimization objectives in (40) and (41). We assume that Φi(α) is M -Lipschitz for i ∈ [n] and Φi(0) ≤ 1. We scale the columns of X such that ‖xi‖ ≤ 1. Hence, we find that\nT ≥ T0 + n+ 4M2\nλ P\n≥ max{0, n log(0.5nλM−2)}+ n+ 20M 2\nλ P\niterations are sufficient to obtain a duality gap of E[G(ᾱ)] ≤ P .\nProof. We consider (40) and (41) as a special case (SB) and (SA). We set gi(α) := 1nΦ ∗ i (α) and f ∗(w) := λ2 ‖w‖ 2. Hence, g∗i (w Tai) = 1 nΦi(nw\nTai) is M -Lipschitz and we set L := M and β := λ We further use Lemma (Shalev-Shwartz & Zhang, 2013, Lemma 20) with Φi(0) ≤ 1 to bound the primal suboptimality as (0)D ≤ 1. Finally, by the assumption ‖xi‖ ≤ 1 and the definition A := 1nX we have R := 1 n and applying Theorem 9 to this setting concludes the proof.\nI.3. Proof of Lemma 14\nTo prove of Lemma 14 is motivated by the proof of (Shalev-Shwartz & Zhang, 2013, Lemma 19) but we adapt it to apply to a much more general setting. First note that the one step improvement in the dual objective can be written as\nD(α(t−1))−D(α(t)) = n∑ i=1 gi(−α(t−1)i ) + f(Aα (t−1))− [ n∑ i=1 gi(−α(t)i ) + f(Aα (t)) ] Note that in a single step of SDCA α(t−1) → α(t) only one dual coordinate is changed. Without loss of generality we assume this coordinate to be i. Writing v(α) = Aα, we find\nD(α(t−1))−D(α(t)) = [ gi(−α(t−1)i ) + f(v(α (t−1))) ]\n︸ ︷︷ ︸ (Γ)\n− [ gi(−α(t)i ) + f(v(α (t))) ]\n︸ ︷︷ ︸ (Λ) .\nIn the following, let us denote the columns of the matrix A by ai for i ∈ [n] for reasons of readability. Then, by definition of the update we have for all s ∈ [0, 1]:\n(Λ) = gi(−α(t)i ) + f(v(α (t)))\n= min ∆αi\n[ gi(−(α(t−1)i + ∆αi)) + f(v(α (t−1) + ei∆αi)) ]\n= min ∆αi\n[ gi(−(α(t−1)i + ∆αi)) + f ( v(α(t−1)) + ai∆αi )] ≤ [ gi(−(α(t−1)i + s(u (t−1) i − α (t−1) i ))) + f ( v(α(t−1)) + ais(u (t−1) i − α (t−1) i )\n)] where we chose ∆αi = s(u (t−1) i − α (t−1) i ) with −u (t−1) i ∈ ∂g∗i (aTi w(t−1)) for s ∈ [0, 1]. For the sake of simplicity we omit the superscripts and subscripts for the following calculations. Using µ-strong convexity of gi, namely\ng(−(α+ s(u− α))) = g(s(−u) + (1− s)(−α)) ≤ sg(−u) + (1− s)g(−α)− µ 2 s(1− s)(u− α)2,\nand 1β -smoothness of f\nf(v(α) + s(u− α)a) ≤ f(v(α)) + 〈∇f(v(α)), s(u− α)a〉+ 1 2β ‖s(u− α)a‖2\nwe find that\n(Λ) ≤ [ sg(−u) + (1− s)g(−α)− µ\n2 s(1− s)(u− α)2 ] + [ f(v(α)) + 〈∇f(v(α)), s(u− α)a〉+ 1\n2β ‖s(u− α)a‖2\n] .\nWe further note that from the optimality condition (1a) we have w(α) = ∇f(v(α)) and rearranging terms yields:\n(Λ) ≤ sg(−u)− sg(−α)− µ 2 s(1− s)(u− α)2\n+ g(−α) + f(v(α))︸ ︷︷ ︸ (Γ) +s(u− α)aTw(α) + 1 2β ‖s(u− α)a‖2.\nUsing this inequality to bound D(α(t−1))−D(α(t)) = (Γ)− (Λ) and again adding the superscripts and subscripts, yields\nD(α(t−1))−D(α(t)) ≥ −sgi(−u(t−1)i ) + sgi(−α (t−1) i )− su (t−1) i a T i w(α (t−1)) + sα (t−1) i a T i w(α (t−1))\n+ µ 2 s(1− s)(u(t−1)i − α (t−1) i ) 2 − 1 2β ‖s(u(t−1)i − α (t−1) i )ai‖ 2.\n(i) ≥ s [ g∗i (a T i w(α (t−1))) + gi(−α(t−1)i ) + α (t−1) i a T i w(α (t−1)) (44)\n+ µ 2 (1− s)(u(t−1)i − α (t−1) i ) 2 − s 2β ‖(u(t−1)i − α (t−1) i )ai‖ 2\n] .\nNote that for (i) we used the optimality condition (2b) which translates to−u ∈ ∂g∗(aTw) and yields g(−u) = −uaTw− g∗(aTw). Similarly, by again exploiting the primal-dual optimality condition we have f∗(∇f(v)) = vT∇f(v) − f(v) and hence we can write the duality gap as:\nG(α) = P(w)− (−D(α)) = n∑ i=1 g∗i (a T i w) + f ∗(w)−\n[ −\nn∑ i=1 gi(−αi)− f(Aα)\n]\n= n∑ i=1 [ g∗i (a T i w) + gi(−αi) ] + f∗(w) + f(Aα)\n= n∑ i=1 [ g∗i (a T i w) + gi(−αi) ] + (Aα)Tw\n= n∑ i=1 [ g∗i (a T i w) + gi(−αi) + αiaTi w ] using this we can write the expectation of (44) with respect to i as\nE [ D(α(t−1))−D(α(t)) ] ≥ s ( 1 n E [ G(α(t−1)) ]) − s 2 2 [ 1 n n∑ i=1 E [ (u (t−1) i − α (t−1) i ) 2 ]( 1 β ‖ai‖2 − (1− s)µ s )] ︸ ︷︷ ︸\nF (t)\n.\nAnd we have obtained that E [ D(α(t−1))−D(α(t)) ] ≥ s n E [ G(α(t−1)) ] − s 2 2 F (t). Corollary 19. We recover Lemma 19 in (Shalev-Shwartz & Zhang, 2013) as a special case of Lemma 14. Therefore we consider their pair of primal and dual optimization objectives, (40) and (41) where xi are the columns of the data matrix X . Assume that Φ∗i is γ-strongly convex for i ∈ [n], where we allow γ = 0. Then, for any t, any s ∈ [0, 1] and\n−û(t−1)i ∈ ∂Φi(xTi w(α(t−1))) we have\nE[−D(α(t))− (−D(α(t−1)))] (45)\n≥ s n E[P(θt−1)− (−D(αt−1))]− ( s n )2 F̂ (t) 2λ ,\nwhere\nF̂ (t) := 1\nn n∑ i=1 ( ‖xi‖2 − γ(1− s)λn s ) (46)\n· E [ (û\n(t−1) i − α (t−1) i )\n2 ] ,\nProof. We set gi(α) := 1nΦ ∗ i (α) and f ∗(w) := λ2 ‖w‖ 2. From the definition of strong convexity it immediately follows that µ = γn and β = λ. As our algorithm works for any data matrix A, we choose A := 1 nX and scale the input vectors xi, i.e. ai = xin before we feed ai into the algorithm. To conclude the proof we apply Lemma 14 to this setting and observe that\ng∗i (w Tai) = 1 nΦi(nw Tai) = 1 nΦi(w Txi). (47)\nwhich yields û(t−1)i = nu (t−1) i . Further note that the conjugate of f ∗ is given by f(v) = λ2 ∥∥v λ ∥∥2 and this leads to the dual-to-primal mapping\nw = ∇f(v(α)) = 1 λ v(α) = 1 λ n∑ i=1 aiαi = 1 λn n∑ i=1 xiαi."
    }, {
      "heading" : "J. Some Useful Pairs of Conjugate Functions",
      "text" : "Elastic Net.\nLemma 20 (Conjugate of the Elastic Net Regularizer). For η ∈ (0, 1], the elastic net function `∗i (α) := η 2α 2 + (1− η)|α| is the convex conjugate of\n`i(x) := 1 2η\n([ |x| − (1− η) ] + )2 ,\nwhere [.]+ is the positive part operator, [s]+ = s for s > 0, and zero otherwise. Furthermore, this ` is smooth, i.e. has Lipschitz continuous gradient with constant 1/η.\nProof. We start by applying the definition of convex conjugate, that is:\n`(x) = maxα∈R\n[ xα− ηα 2 2 − (1− η)|α| ] .\nWe now distinguish two cases for the optimal: α∗ ≥ 0, α∗ < 0. For the first case we get that\n`(x) = maxα∈R\n[ xα− ηα 2 2 − (1− η)α ] .\nSetting the derivative to 0 we get α∗ = x−(1−η)η . To satisfy α ∗ ≥ 0, we must have x ≥ 1− η. Replacing with α∗ we thus get: `(x) = α∗(x− 12ηα ∗ − (1− η)) = α∗ ( x− 12 (x− (1− η))− (1− η) ) =\n1 2α ∗ (x− (1− η)) = 12η (x− (1− η)) 2 .\nSimilarly we can show that for x ≤ −(1− η)\n`(x) = 12η (x+ (1− η)) 2 .\nFinally, by the fact that `(.) is convex, always positive, and `(−(1− η)) = `(1− η) = 0, it follows that `(x) = 0 for every x ∈ [−(1− η), 1− η].\nFor the smoothness properties, we consider the derivative of this function `(x) and see that `(x) is smooth, i.e. has Lipschitz\ncontinuous gradient with constant 1/η, assuming η > 0.\nGroup Lasso. The group lasso regularizer is a norm on Rn, and is defined as g(α) = λ ∑ k ‖αGk‖2,\nfor a fixed partition of the indices into disjoint groups, {1..n} = ⊎ k Gk. Here αGk ∈ R|g| denotes the part of the vector α with indices in the group g ⊆ [n]. Its dual norm is maxg∈G ‖α(g)‖2. Therefore, by Lemma 13, we obtain the conjugate g∗(y) = ι{y | maxg∈G ‖α(g)‖2≤λ}(y)\nSee e.g. (Boyd & Vandenberghe, 2004, Example 3.26).\nLogistic Loss. Lemma 21 (Conjugate and Smoothness of the Logistic Loss). The logistic classifier loss function f given as\nf(Aα) := d∑ j=1 log (1 + exp (−bjyTj α)) ,\nis the conjugate of f∗, which is given as:\nf(w) := d∑ j=1 ( (1 + wjbj) log (1 + wjbj)− wjbj log (−wjbj) ) , (48)\nwith the box constraint −wjbj ∈ [0, 1].\nFurthermore, f∗(w) is 1-strongly convex over its domain if the labels satisfy bj ∈ [−1, 1].\nK. More Numerical Experiments\n10 0\n10 2\n10 4\n10 6\n10 −15\n10 −10\n10 −5\n10 0\n10 5\n10 10\nrcv1−train Elastic Net\nEpochs\nD u\na lit\ny G\na p\nSDCA APPROX\n10 0\n10 1\n10 2\n10 3\n10 −8\n10 −6\n10 −4\n10 −2\n10 0\nrcv1−train Ridge Regression\nEpochs\nD u\na lit\ny G\na p\nSDCA APPROX\n10 0\n10 1\n10 2\n10 3\n10 −8\n10 −6\n10 −4\n10 −2\n10 0\nrcv1−train SVM Dual\nEpochs\nD u\na lit\ny G\na p\nSDCA APPROX\n10 0\n10 2\n10 4\n10 6\n10 −5\n10 0\n10 5\nrcv1−train Lasso\nEpochs\nD u\na lit\ny G\na p\nSDCA APPROX\n10 0\n10 2\n10 4\n10 6\n10 −5\n10 0\n10 5\nnews20 Elastic Net\nEpochs\nD u\na lit\ny G\na p\nSDCA APPROX\n10 0\n10 1\n10 2\n10 −8\n10 −6\n10 −4\n10 −2\n10 0\nnews20 Ridge Regression\nEpochs\nD u\na lit\ny G\na p\nSDCA APPROX\n10 0\n10 1\n10 2\n10 3\n10 −8\n10 −6\n10 −4\n10 −2\n10 0\nnews20 SVM Dual\nEpochs\nD u\na lit\ny G\na p\nSDCA APPROX\n10 0\n10 2\n10 4\n10 6\n10 −5\n10 0\n10 5\nnews20 Lasso\nEpochs\nD u\na lit\ny G\na p\nSDCA APPROX\n10 0\n10 1\n10 2\n10 3\n10 −5\n10 0\n10 5\nrcv1−test Elastic Net\nEpochs\nD u\na lit\ny G\na p\nSDCA APPROX\n10 0\n10 1\n10 2\n10 3\n10 −8\n10 −6\n10 −4\n10 −2\n10 0\nrcv1−test Ridge Regression\nEpochs\nD u\na lit\ny G\na p\nSDCA APPROX\n10 0\n10 1\n10 2\n10 3\n10 −8\n10 −6\n10 −4\n10 −2\n10 0\nrcv1−test SVM Dual\nEpochs\nD u\na lit\ny G\na p\nSDCA APPROX\n10 0\n10 1\n10 2\n10 3\n10 −5\n10 0\n10 5\n10 10\nrcv1−test Lasso\nEpochs\nD u\na lit\ny G\na p\nSDCA APPROX\n10 0\n10 5\n10 −5\n10 0\n10 5\n10 10\nreal−sim Elastic Net\nEpochs\nD u\na lit\ny G\na p\nSDCA APPROX\n10 0\n10 1\n10 2\n10 3\n10 −8\n10 −6\n10 −4\n10 −2\n10 0\nreal−sim Ridge Regression\nEpochs\nD u\na lit\ny G\na p\nSDCA APPROX\n10 0\n10 1\n10 2\n10 3\n10 −8\n10 −6\n10 −4\n10 −2\n10 0\nreal−sim SVM Dual\nEpochs\nD u\na lit\ny G\na p\nSDCA APPROX\n10 0\n10 5\n10 −5\n10 0\n10 5\nreal−sim Lasso\nEpochs\nD u\na lit\ny G\na p\nSDCA APPROX"
    } ],
    "references" : [ {
      "title" : "Optimization with Sparsity-Inducing Penalties",
      "author" : [ "Bach", "Francis", "Jenatton", "Rodolphe", "Mairal", "Julien", "Obozinski", "Guillaume" ],
      "venue" : "arXiv cs.LG,",
      "citeRegEx" : "Bach et al\\.,? \\Q2011\\E",
      "shortCiteRegEx" : "Bach et al\\.",
      "year" : 2011
    }, {
      "title" : "Convex Analysis and Monotone Operator Theory in Hilbert Spaces",
      "author" : [ "Bauschke", "Heinz H", "Combettes", "Patrick L" ],
      "venue" : "CMS Books in Mathematics",
      "citeRegEx" : "Bauschke et al\\.,? \\Q2011\\E",
      "shortCiteRegEx" : "Bauschke et al\\.",
      "year" : 2011
    }, {
      "title" : "A fast iterative shrinkagethresholding algorithm for linear inverse problems",
      "author" : [ "Beck", "Amir", "Teboulle", "Marc" ],
      "venue" : "SIAM journal on imaging sciences,",
      "citeRegEx" : "Beck et al\\.,? \\Q2009\\E",
      "shortCiteRegEx" : "Beck et al\\.",
      "year" : 2009
    }, {
      "title" : "Techniques of Variational Analysis and Nonlinear Optimization. Canadian Mathematical Society Books in Math",
      "author" : [ "J M Borwein", "Q. Zhu" ],
      "venue" : null,
      "citeRegEx" : "Borwein and Zhu,? \\Q2005\\E",
      "shortCiteRegEx" : "Borwein and Zhu",
      "year" : 2005
    }, {
      "title" : "Convex optimization",
      "author" : [ "Boyd", "Stephen P", "Vandenberghe", "Lieven" ],
      "venue" : null,
      "citeRegEx" : "Boyd et al\\.,? \\Q2004\\E",
      "shortCiteRegEx" : "Boyd et al\\.",
      "year" : 2004
    }, {
      "title" : "A First-Order PrimalDual Algorithm for Convex Problems with Applications to Imaging",
      "author" : [ "Chambolle", "Antonin", "Pock", "Thomas" ],
      "venue" : "Journal of Mathematical Imaging and Vision,",
      "citeRegEx" : "Chambolle et al\\.,? \\Q2010\\E",
      "shortCiteRegEx" : "Chambolle et al\\.",
      "year" : 2010
    }, {
      "title" : "Accelerated, Parallel, and Proximal Coordinate Descent",
      "author" : [ "Fercoq", "Olivier", "Richtárik", "Peter" ],
      "venue" : "SIAM Journal on Optimization,",
      "citeRegEx" : "Fercoq et al\\.,? \\Q2015\\E",
      "shortCiteRegEx" : "Fercoq et al\\.",
      "year" : 2015
    }, {
      "title" : "Distributed Optimization for Non-Strongly Convex Regularizers",
      "author" : [ "Forte", "Simone" ],
      "venue" : "Master’s thesis, ETH Zürich, September",
      "citeRegEx" : "Forte and Simone.,? \\Q2015\\E",
      "shortCiteRegEx" : "Forte and Simone.",
      "year" : 2015
    }, {
      "title" : "Regularization Paths for Generalized Linear Models via Coordinate Descent",
      "author" : [ "Friedman", "Jerome", "Hastie", "Trevor", "Tibshirani", "Robert" ],
      "venue" : "Journal of Statistical Software,",
      "citeRegEx" : "Friedman et al\\.,? \\Q2010\\E",
      "shortCiteRegEx" : "Friedman et al\\.",
      "year" : 2010
    }, {
      "title" : "Adaptive PrimalDual Splitting Methods for Statistical Learning and Image Processing",
      "author" : [ "Goldstein", "Tom", "Li", "Min", "Yuan", "Xiaoming" ],
      "venue" : "In NIPS 2015 - Advances in Neural Information Processing Systems",
      "citeRegEx" : "Goldstein et al\\.,? \\Q2015\\E",
      "shortCiteRegEx" : "Goldstein et al\\.",
      "year" : 2015
    }, {
      "title" : "A dual coordinate descent method for large-scale linear svm",
      "author" : [ "Hsieh", "Cho-Jui", "Chang", "Kai-Wei", "Lin", "Chih-Jen", "Keerthi", "S Sathiya", "Sundararajan", "Sellamanickam" ],
      "venue" : "In Proceedings of the 25th international conference on Machine learning,",
      "citeRegEx" : "Hsieh et al\\.,? \\Q2008\\E",
      "shortCiteRegEx" : "Hsieh et al\\.",
      "year" : 2008
    }, {
      "title" : "Qp algorithms with guaranteed accuracy and run time for support vector machines",
      "author" : [ "Hush", "Don", "Kelly", "Patrick", "Scovel", "Clint", "Steinwart", "Ingo" ],
      "venue" : "The Journal of Machine Learning Research,",
      "citeRegEx" : "Hush et al\\.,? \\Q2006\\E",
      "shortCiteRegEx" : "Hush et al\\.",
      "year" : 2006
    }, {
      "title" : "An Equivalence between the Lasso and Support Vector Machines. In Regularization, Optimization, Kernels, and Support Vector Machines, pp. 1–26",
      "author" : [ "Jaggi", "Martin" ],
      "venue" : null,
      "citeRegEx" : "Jaggi and Martin.,? \\Q2014\\E",
      "shortCiteRegEx" : "Jaggi and Martin.",
      "year" : 2014
    }, {
      "title" : "On the duality of strong convexity and strong smoothness: Learning applications and matrix regularization",
      "author" : [ "Kakade", "Sham M", "Shalev-Shwartz", "Shai", "Tewari", "Ambuj" ],
      "venue" : "Technical report, Toyota Technological Institute - Chicago,",
      "citeRegEx" : "Kakade et al\\.,? \\Q2009\\E",
      "shortCiteRegEx" : "Kakade et al\\.",
      "year" : 2009
    }, {
      "title" : "Block-Coordinate Frank-Wolfe Optimization for Structural SVMs",
      "author" : [ "Lacoste-Julien", "Simon", "Jaggi", "Martin", "Schmidt", "Mark", "Pletscher", "Patrick" ],
      "venue" : "In ICML 2013 - Proceedings of the 30th International Conference on Machine Learning,",
      "citeRegEx" : "Lacoste.Julien et al\\.,? \\Q2013\\E",
      "shortCiteRegEx" : "Lacoste.Julien et al\\.",
      "year" : 2013
    }, {
      "title" : "An accelerated proximal coordinate gradient method and its application to regularized empirical risk minimization",
      "author" : [ "Lin", "Qihang", "Lu", "Zhaosong", "Xiao" ],
      "venue" : null,
      "citeRegEx" : "Lin et al\\.,? \\Q2014\\E",
      "shortCiteRegEx" : "Lin et al\\.",
      "year" : 2014
    }, {
      "title" : "Distributed optimization with arbitrary local solvers",
      "author" : [ "Ma", "Chenxin", "Konečný", "Jakub", "Jaggi", "Martin", "Smith", "Virginia", "Jordan", "Michael I", "Richtárik", "Peter", "Takáč" ],
      "venue" : "arXiv preprint arXiv:1512.04039,",
      "citeRegEx" : "Ma et al\\.,? \\Q2015\\E",
      "shortCiteRegEx" : "Ma et al\\.",
      "year" : 2015
    }, {
      "title" : "Adding vs. averaging in distributed primal-dual optimization",
      "author" : [ "Ma", "Chenxin", "Smith", "Virginia", "Jaggi", "Martin", "Jordan", "Michael I", "Richtárik", "Peter", "Takáč" ],
      "venue" : "In 32th International Conference on Machine Learning,",
      "citeRegEx" : "Ma et al\\.,? \\Q2015\\E",
      "shortCiteRegEx" : "Ma et al\\.",
      "year" : 2015
    }, {
      "title" : "Linear convergence of the randomized feasible descent method under the weak strong convexity assumption",
      "author" : [ "Ma", "Chenxin", "Tappenden", "Rachael", "Takáč", "Martin" ],
      "venue" : null,
      "citeRegEx" : "Ma et al\\.,? \\Q2015\\E",
      "shortCiteRegEx" : "Ma et al\\.",
      "year" : 2015
    }, {
      "title" : "Linear convergence of first order methods under weak nondegeneracy assumptions for convex programming",
      "author" : [ "Necoara", "Ion" ],
      "venue" : null,
      "citeRegEx" : "Necoara and Ion.,? \\Q2015\\E",
      "shortCiteRegEx" : "Necoara and Ion.",
      "year" : 2015
    }, {
      "title" : "Efficiency of coordinate descent methods on hugescale optimization problems",
      "author" : [ "Nesterov", "Yu" ],
      "venue" : "SIAM Journal on Optimization,",
      "citeRegEx" : "Nesterov and Yu.,? \\Q2012\\E",
      "shortCiteRegEx" : "Nesterov and Yu.",
      "year" : 2012
    }, {
      "title" : "Gradient methods for minimizing composite functions",
      "author" : [ "Nesterov", "Yu" ],
      "venue" : "Mathematical Programming,",
      "citeRegEx" : "Nesterov and Yu.,? \\Q2013\\E",
      "shortCiteRegEx" : "Nesterov and Yu.",
      "year" : 2013
    }, {
      "title" : "Smooth minimization of non-smooth functions",
      "author" : [ "Nesterov", "Yurii" ],
      "venue" : "Mathematical Programming,",
      "citeRegEx" : "Nesterov and Yurii.,? \\Q2005\\E",
      "shortCiteRegEx" : "Nesterov and Yurii.",
      "year" : 2005
    }, {
      "title" : "Randomized Dual Coordinate Ascent with Arbitrary Sampling",
      "author" : [ "Qu", "Zheng", "Richtárik", "Peter", "Zhang", "Tong" ],
      "venue" : null,
      "citeRegEx" : "Qu et al\\.,? \\Q2014\\E",
      "shortCiteRegEx" : "Qu et al\\.",
      "year" : 2014
    }, {
      "title" : "Iteration complexity of randomized block-coordinate descent methods for minimizing a composite function",
      "author" : [ "Richtárik", "Peter", "Takáč", "Martin" ],
      "venue" : "Mathematical Programming,",
      "citeRegEx" : "Richtárik et al\\.,? \\Q2014\\E",
      "shortCiteRegEx" : "Richtárik et al\\.",
      "year" : 2014
    }, {
      "title" : "Convex analysis",
      "author" : [ "Rockafellar", "R Tyrrell" ],
      "venue" : null,
      "citeRegEx" : "Rockafellar and Tyrrell.,? \\Q1997\\E",
      "shortCiteRegEx" : "Rockafellar and Tyrrell.",
      "year" : 1997
    }, {
      "title" : "Online Learning meets Optimization in the Dual",
      "author" : [ "Shalev-Shwartz", "Shai", "Singer", "Yoram" ],
      "venue" : null,
      "citeRegEx" : "Shalev.Shwartz et al\\.,? \\Q2006\\E",
      "shortCiteRegEx" : "Shalev.Shwartz et al\\.",
      "year" : 2006
    }, {
      "title" : "Stochastic Methods for l1-regularized Loss Minimization",
      "author" : [ "Shalev-Shwartz", "Shai", "Tewari", "Ambuj" ],
      "venue" : null,
      "citeRegEx" : "Shalev.Shwartz et al\\.,? \\Q2011\\E",
      "shortCiteRegEx" : "Shalev.Shwartz et al\\.",
      "year" : 2011
    }, {
      "title" : "Stochastic Dual Coordinate Ascent Methods for Regularized Loss Minimization",
      "author" : [ "Shalev-Shwartz", "Shai", "Zhang", "Tong" ],
      "venue" : null,
      "citeRegEx" : "Shalev.Shwartz et al\\.,? \\Q2013\\E",
      "shortCiteRegEx" : "Shalev.Shwartz et al\\.",
      "year" : 2013
    }, {
      "title" : "Accelerated proximal stochastic dual coordinate ascent for regularized loss minimization",
      "author" : [ "Shalev-Shwartz", "Shai", "Zhang", "Tong" ],
      "venue" : "Mathematical Programming, Series",
      "citeRegEx" : "Shalev.Shwartz et al\\.,? \\Q2014\\E",
      "shortCiteRegEx" : "Shalev.Shwartz et al\\.",
      "year" : 2014
    }, {
      "title" : "L1-Regularized Distributed Optimization: A Communication-Efficient Primal-Dual Framework",
      "author" : [ "Smith", "Virginia", "Forte", "Simone", "Jordan", "Michael I", "Jaggi", "Martin" ],
      "venue" : null,
      "citeRegEx" : "Smith et al\\.,? \\Q2015\\E",
      "shortCiteRegEx" : "Smith et al\\.",
      "year" : 2015
    }, {
      "title" : "Mini-batch primal and dual methods for SVMs",
      "author" : [ "Takáč", "Martin", "Bijral", "Avleen", "Richtárik", "Peter", "Srebro", "Nathan" ],
      "venue" : "In In 30th International Conference on Machine Learning,",
      "citeRegEx" : "Takáč et al\\.,? \\Q2013\\E",
      "shortCiteRegEx" : "Takáč et al\\.",
      "year" : 2013
    }, {
      "title" : "Distributed mini-batch SDCA",
      "author" : [ "Takáč", "Martin", "Richtárik", "Peter", "Srebro", "Nathan" ],
      "venue" : null,
      "citeRegEx" : "Takáč et al\\.,? \\Q2015\\E",
      "shortCiteRegEx" : "Takáč et al\\.",
      "year" : 2015
    }, {
      "title" : "A Primal-Dual Algorithmic Framework for Constrained Convex Minimization",
      "author" : [ "Tran-Dinh", "Quoc", "Cevher", "Volkan" ],
      "venue" : null,
      "citeRegEx" : "Tran.Dinh et al\\.,? \\Q2014\\E",
      "shortCiteRegEx" : "Tran.Dinh et al\\.",
      "year" : 2014
    }, {
      "title" : "Constrained convex minimization via model-based excessive gap",
      "author" : [ "Tran-Dinh", "Quoc", "Cevher", "Volkan" ],
      "venue" : "In NIPS 2014 - Advances in Neural Information Processing Systems",
      "citeRegEx" : "Tran.Dinh et al\\.,? \\Q2014\\E",
      "shortCiteRegEx" : "Tran.Dinh et al\\.",
      "year" : 2014
    }, {
      "title" : "Splitting the Smoothed Primal-Dual Gap",
      "author" : [ "Tran-Dinh", "Quoc", "Cevher", "Volkan" ],
      "venue" : "Optimal Alternating Direction Methods",
      "citeRegEx" : "Tran.Dinh et al\\.,? \\Q2015\\E",
      "shortCiteRegEx" : "Tran.Dinh et al\\.",
      "year" : 2015
    }, {
      "title" : "Iteration complexity of feasible descent methods for convex optimization",
      "author" : [ "Wang", "Po-Wei", "Lin", "Chih-Jen" ],
      "venue" : "The Journal of Machine Learning Research,",
      "citeRegEx" : "Wang et al\\.,? \\Q2014\\E",
      "shortCiteRegEx" : "Wang et al\\.",
      "year" : 2014
    }, {
      "title" : "A Comparison of Optimization Methods and Software for Large-scale L1-regularized Linear Classification",
      "author" : [ "Yuan", "Guo-Xun", "Chang", "Kai-Wei", "Hsieh", "Cho-Jui", "Lin", "ChihJen" ],
      "venue" : "Journal of Machine Learning Research,",
      "citeRegEx" : "Yuan et al\\.,? \\Q2010\\E",
      "shortCiteRegEx" : "Yuan et al\\.",
      "year" : 2010
    }, {
      "title" : "An Improved GLMNET for L1-regularized",
      "author" : [ "Yuan", "Guo-Xun", "Ho", "Chia-Hua", "Lin", "Chih-Jen" ],
      "venue" : "Logistic Regression. JMLR,",
      "citeRegEx" : "Yuan et al\\.,? \\Q2012\\E",
      "shortCiteRegEx" : "Yuan et al\\.",
      "year" : 2012
    }, {
      "title" : "A Universal Primal-Dual Convex Optimization Framework",
      "author" : [ "Yurtsever", "Alp", "Dinh", "Quoc Tran", "Cevher", "Volkan" ],
      "venue" : "In NIPS 2015 - Advances in Neural Information Processing Systems",
      "citeRegEx" : "Yurtsever et al\\.,? \\Q2015\\E",
      "shortCiteRegEx" : "Yurtsever et al\\.",
      "year" : 2015
    }, {
      "title" : "Stochastic Primal-Dual Coordinate Method for Regularized Empirical Risk Minimization",
      "author" : [ "Zhang", "Yuchen", "Lin", "Xiao" ],
      "venue" : "In ICML 2015 - Proceedings of the 32th International Conference on Machine Learning,",
      "citeRegEx" : "Zhang et al\\.,? \\Q2015\\E",
      "shortCiteRegEx" : "Zhang et al\\.",
      "year" : 2015
    }, {
      "title" : "Proof of Lemma 1 The proof is partially motivated by proofs in (Ma et al., 2015b;a; Shalev-Shwartz & Zhang, 2013) but have a crucial unique steps and tricks",
      "author" : [ ],
      "venue" : null,
      "citeRegEx" : "D.,? \\Q2013\\E",
      "shortCiteRegEx" : "D.",
      "year" : 2013
    }, {
      "title" : "1and applying Theorem 8 to this setting concludes the proof. I.2",
      "author" : [ ],
      "venue" : "Proof of Theorem",
      "citeRegEx" : "≤,? \\Q2013\\E",
      "shortCiteRegEx" : "≤",
      "year" : 2013
    }, {
      "title" : "By the relationship between Lipschitzness and the subgradient (ShalevShwartz",
      "author" : [ "L. αi" ],
      "venue" : null,
      "citeRegEx" : "≤,? \\Q2006\\E",
      "shortCiteRegEx" : "≤",
      "year" : 2006
    } ],
    "referenceMentions" : [ {
      "referenceID" : 31,
      "context" : "To be precise, our shown convergence rate for the general algorithm is depending on the the spectral norm of the data, see also (Takáč et al., 2013; 2015).",
      "startOffset" : 128,
      "endOffset" : 154
    }, {
      "referenceID" : 9,
      "context" : "Its convergence rate is sensitive to the used step-size (Goldstein et al., 2015).",
      "startOffset" : 56,
      "endOffset" : 80
    }, {
      "referenceID" : 10,
      "context" : "Coordinate descent/ascent methods have become state-of-the-art for many machine learning problems (Hsieh et al., 2008; Friedman et al., 2010).",
      "startOffset" : 98,
      "endOffset" : 141
    }, {
      "referenceID" : 8,
      "context" : "Coordinate descent/ascent methods have become state-of-the-art for many machine learning problems (Hsieh et al., 2008; Friedman et al., 2010).",
      "startOffset" : 98,
      "endOffset" : 141
    }, {
      "referenceID" : 14,
      "context" : "(Lacoste-Julien et al., 2013; Shalev-Shwartz & Zhang, 2013; 2014).",
      "startOffset" : 0,
      "endOffset" : 65
    }, {
      "referenceID" : 31,
      "context" : "SDCA and recent extensions (Takáč et al., 2013; Shalev-Shwartz & Zhang, 2014; Qu et al., 2014; Shalev-Shwartz, 2015; Zhang & Lin, 2015) require g to be strongly convex.",
      "startOffset" : 27,
      "endOffset" : 135
    }, {
      "referenceID" : 23,
      "context" : "SDCA and recent extensions (Takáč et al., 2013; Shalev-Shwartz & Zhang, 2014; Qu et al., 2014; Shalev-Shwartz, 2015; Zhang & Lin, 2015) require g to be strongly convex.",
      "startOffset" : 27,
      "endOffset" : 135
    }, {
      "referenceID" : 8,
      "context" : "For those problems, coordinate descent algorithms on the primal formulation have become the state-of-the-art, as in GLMNET (Friedman et al., 2010) and extensions (Shalev-Shwartz & Tewari, 2011; Yuan et al.",
      "startOffset" : 123,
      "endOffset" : 146
    }, {
      "referenceID" : 38,
      "context" : ", 2010) and extensions (Shalev-Shwartz & Tewari, 2011; Yuan et al., 2012; 2010).",
      "startOffset" : 23,
      "endOffset" : 79
    }, {
      "referenceID" : 39,
      "context" : "Furthermore, primal-dual convergence rates follow for the case of proximally tractable objectives (Tran-Dinh & Cevher, 2015) and also objectives having an efficient Fenchel-type operator (Yurtsever et al., 2015), where per iteration, the Here ’stochastic’ refers to randomized selection of the active coordinate.",
      "startOffset" : 187,
      "endOffset" : 211
    }, {
      "referenceID" : 30,
      "context" : "For L1-optimization with datasets exceeding the memory capacity of a single computer, we study distributed schemes leveraging the Lipschitzing trick in (Smith et al., 2015; Forte, 2015).",
      "startOffset" : 152,
      "endOffset" : 185
    }, {
      "referenceID" : 15,
      "context" : "The rate (7) is achieved by most of the first order algorithms, including proximal gradient descent (Nesterov, 2013) or SDCA (Richtárik & Takáč, 2014) with C ∼ γ or accelerated SDCA (Lin et al., 2014) with C ∼ √γ.",
      "startOffset" : 182,
      "endOffset" : 200
    }, {
      "referenceID" : 11,
      "context" : "This results is consistent with a work (Hush et al., 2006) shown only for SVMs.",
      "startOffset" : 39,
      "endOffset" : 58
    }, {
      "referenceID" : 0,
      "context" : "GROUP LASSO The group lasso is widely used in applications to capture more tailored notions of structured sparsity, as by sparsity in terms of disjoint groups of variables (Bach et al., 2011).",
      "startOffset" : 172,
      "endOffset" : 191
    }, {
      "referenceID" : 41,
      "context" : "variant of SDCA (APPROX, Fercoq & Richtárik (2015)), both applied to the Lasso problem (A).",
      "startOffset" : 12,
      "endOffset" : 51
    } ],
    "year" : 2017,
    "abstractText" : "We propose an algorithm-independent framework to equip existing optimization methods with primal-dual certificates. Such certificates and corresponding rate of convergence guarantees are important for practitioners to diagnose progress, in particular in machine learning applications. We obtain new primal-dual convergence rates e.g. for the Lasso as well as many L1, Elastic-Net and group-lasso-regularized problems. The theory applies to any norm-regularized generalized linear model. Our approach provides efficiently computable duality gaps which are globally defined, without modifying the original problems in the region of interest.",
    "creator" : "LaTeX with hyperref package"
  }
}