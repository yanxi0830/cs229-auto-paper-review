{
  "name" : "1609.02664.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "Machine Learning with Guarantees using Descriptive Complexity and SMT Solvers",
    "authors" : [ "Charles Jordan", "Lukasz Kaiser" ],
    "emails" : [ "skip@ist.hokudai.ac.jp", "lukaszkaiser@gmail.com" ],
    "sections" : [ {
      "heading" : null,
      "text" : "ar X\niv :1\n60 9.\n02 66\n4v 1\n[ cs\n.L G\n] 9\nS ep\nIn this paper we introduce a logical approach to machine learning. Models are represented by tuples of logical formulas and inputs and outputs are logical structures. We present our framework together with several applications where we evaluate it using SAT and SMT solvers. We argue that this approach to machine learning is particularly suited to bridge the gap between efficiency and theoretical soundness.\nWe exploit results from descriptive complexity theory to prove strong theoretical guarantees for our approach. To show its applicability, we present experimental results including learning complexity-theoretic reductions rules for board games. We also explain how neural networks fit into our framework, although the current implementation does not scale to provide guarantees for real-world neural networks."
    }, {
      "heading" : "1. Introduction",
      "text" : "Machine learning has a long history in computer science. It includes techniques like neural networks, Bayesian models, genetic programming, inductive synthesis and many others. In various applications such as voice recognition, these methods are now used by over a billion people. Some machine learning methods give some guarantees of success, but they are usually dependent on a number of strong assumptions about the distribution of inputs or the existence of a model with a particular form. One would hope for much stronger theoretical guarantees of success, but no widely used machine learning methods provide them, so it is difficult to know when they will work.\nOne key question faced by any machine learning system is: what kind of models will it generate? In neural networks one asks whether the architecture is feed-forward or recurrent and how many layers it has. In genetic programming one asks for the program representation and which functions are built-in. In general, each machine learning system must make this choice. If the class of generated models or programs is too broad, it might be impossible to learn them efficiently. If it is too narrow, it might not suffice for the task at hand. To solve a different task, one might need a different kind of model. But is there an efficient systematic way to know the kind of model needed for a task?\n∗. Supported in part by Kakenhi Grant No. 15H00847, ‘Exploring the Limits of Computation (ELC)’.\nThere exists a number of reasonably broad machine learning methods. So one efficient way to apply machine learning to a new task is to try all of these techniques in turn. But what if they all fail? Since there are few theoretical guarantees, it is seldom clear whether the reason for the failure is the model, wrong parameters or simply a bug. On the other hand, there are systematic ways to explore the space of all models that come with strong guarantees. One can, for example, just enumerate all programs in a programming language of choice. Of course, this is too inefficient for any practical purpose.\nWe propose an efficient way to systematically explore the space of all models in given computational complexity class. It is based on findings from descriptive complexity where one studies how programs in different complexity classes, such as NL, P, or NP, can be characterized syntactically. Recent work (Crouch, Immerman, & Moss, 2010; Itzhaky, Gulwani, Immerman, & Sagiv, 2010; Jordan & Kaiser, 2013b) suggests that logical queries of various logics are a particularly good choice for such syntactic representations. Using logical queries allows us, on the one hand, to exploit results from descriptive complexity to get theoretical guarantees for our algorithms. On the other hand, it allows us to leverage recent advances in SAT, QBF and other SMT solvers to address more practical concerns. In general, learning correct models satisfying a given condition is not computable. We first introduce some restrictions on the size of structures and models that we look for and present an optimized algorithm for that restricted problem. Then, we show how to iterate these solutions to get reasonably efficient semi-decision procedures with strong theoretical guarantees.\nOne advantage of a machine learning approach with such strong guarantees is that it can give negative answers to certain questions. For example, our approach can sometimes prove that there is no model in a certain class that is sufficient for the given machine learning task. A main disadvantage is that this does not scale to large models. Still, it can be used to enrich our understanding of complexity theory and model classes, even when only applied on a small scale. For example, in Section 4.1 we show how our approach can be used to prove that certain reductions between complexity classes do not exist.\nThe rest of the paper is organized as follows. After introducing related work, we review the necessary background from logic in Section 2. We define our learning model and prove the main theorems in Section 3. In particular, Theorem 2 shows that if a model satisfying the specification exists and its computational complexity is in a given complexity class (e.g., NL, P, NP), then our approach is guaranteed to find it. Knowing the theoretical guarantees, we devote Section 4 to applications and experiments. While our technique cannot reach the scale of machine learning systems that come with no guarantees, we show results on learning a number of non-trivial tasks that require very different kinds of models. We also show how other machine learning techniques, such as neural networks, fit into our approach."
    }, {
      "heading" : "1.1 Related Work",
      "text" : "Machine learning and inductive synthesis (the subfield closest to our approach) have long histories; there is a tremendous amount of work that we do not cover. We refer the reader to (Gulwani, 2010; Kitzelmann, 2010) for a general perspective on inductive synthesis.\nMuch of our motivation comes from recent papers using ideas from descriptive complexity in inductive synthesis. For example, given a specification in an expressive logic (second-order), (Itzhaky et al., 2010) synthesized equivalent formulas in less expressive log-\nics which can be evaluated more efficiently. Automatically finding complexity-theoretic reductions between computational problems was first considered by (Crouch et al., 2010). They focused on quantifier-free reductions, a weak class of reduction defined by tuples of quantifier-free formulas.\nBoth problems are essentially the same – finding formulas in a particular form that satisfy desired properties. However, the implementations are separate and not publicly available. (Jordan & Kaiser, 2013b) compared a number of different approaches to reduction finding. In this paper, we introduce a more general approach – allowing the user to specify an outline of the desired formula and a specification that it must satisfy. We provide a freely available implementation that can be used to experiment with various synthesis problems.\nAnother source of motivation for this paper comes from recent successes (Heule, Kullmann, & Marek, 2016; Konev & Lisitsa, 2015) using logic solvers to resolve interesting problems in mathematics. In a similar fashion, determining the existence of formulas can resolve open questions and our approach gives a way to leverage modern solvers in new areas. In particular, recent progress on sequential and parallel QBF solvers suggests that this may be a promising approach to certain problems that do not have compact SAT encodings (assuming NP 6=PSPACE)."
    }, {
      "heading" : "2. Background in Logic and Descriptive Complexity",
      "text" : "In this section we briefly review the necessary background from descriptive complexity. For more details, see (Immerman, 1999) or Chapter 3 of (Grädel, Kolaitis, Libkin, Marx, Spencer, Vardi, Venema, & Weinstein, 2007) for an overview and background, or (Grädel & Meer, 1996) and (Grädel & Gurevich, 1998) for details on R-structures and their logics.\nThere are many possible representations of models or programs; in this paper, we focus on logical representations. One benefit of the logical approach is that we are able to treat structures such as graphs directly, instead of encoding them into words or numbers. This allows us to express many interesting models succinctly. Additionally, formulas have natural normal forms. These provide guidance for hypothesis spaces, and improve understandability of learned models. Also, it turns out that searching for logical formulas can be translated to inputs for SAT and SMT solvers in a natural way.\nHere, we consider models (programs) that transform given inputs into outputs and we represent these inputs and outputs as logical structures (for example, graphs or binary strings). Although graphs are the most common and suffice for many examples, they do not provide access to computation with real numbers. Metafinite structures (Grädel & Gurevich, 1998) are an extension of relational structures that was introduced to resolve issues of this kind. We use R-structures (Grädel & Meer, 1996), a particular kind of metafinite structures that provides limited access to computation with real numbers (of course, relational structures are available as a special case). This choice is not arbitrary – there are many deep connections between logics and complexity classes, and the relevant logics for R-structures maintain these connections (see below or (Grädel & Meer, 1996)).\nAn R-signature is a tuple of predicate symbols Ri with arities ai, constant symbols cj , and function symbols fi with arities bi:\nτ := (Ra11 , . . . , R ar r , c1, . . . , cs, f b1 1 , . . . , f bt t ) .\nA τ -structure A consists of a finite set U , called the universe, an ai-ary relation over U for each predicate symbol of τ , a definition – an element of U – for each constant symbol, and a definition mapping U bi to R for each function symbol:\n(U,R1 ⊆ U a1 , . . . , Rr ⊆ U ar , c1 ∈ U, . . . , cs ∈ U, f1 : U b1 → R, . . . , ft : U bt → R).\nWe always set n = |U | and identify U with the natural numbers {0, . . . , n − 1}. Signatures containing no function symbols are called relational signatures and the corresponding structures are called relational structures.\nMany models make use of function symbols on the finite part U of the structure, i.e., functions g : Uag → U . We can represent these using a predicate for the characteristic function. One can, in a similar fashion, represent predicates with function symbols for the characteristic function or represent constants with monadic predicates. We use the above definitions for simplicity.\nExample 1. The (relational) signature for directed graphs contains a single, binary predicate symbol E and so a directed graph consists of a finite set U of vertices and a binary edge relation. These graphs may contain loops. The R-signature for a complete weighted directed graph contains one binary function symbol e which maps pairs from U to their weights.\nWe denote the set of all τ -structures by Struc(τ) and the set of τ -structures with universe size n as Strucn(τ). We also use the notion of an R-modification of a structure A. We say that B is an R-modification of a structure A, written B ∼R A, if it has the same signature, universe, constants and relations – but it may differ on the values of its real-valued functions.\nOur models are built from formulas in various logics. Formulas of first-order logic over a signature τ are built in the following way. First, we fix a countable set of first-order variables xi – these range only over the finite part U of structures. Then, we fix an explicit enumeration of the set of algebraic real numbers and denote these constants ri. Using those, we define the set of atomic number terms t and first-order formulas ϕ by the following BNF grammar.\nt := ri | fi(x1, . . . , xbi) | t+ t | t− t | t · t | t/t | sgn(t) | ∑\nx\nt |χ(ϕ)\nϕ := xi = xj | xi = cj | xi < xj | xi < cj | Ri(x1, . . . , xai) | ¬ϕ |\nϕ ∨ ϕ | ϕ ∧ ϕ | ∃xi ϕ | ∀xi ϕ | t = t | t < t\nwhere xi are first-order variables and t are number terms. The semantics, given an assignment of the variables xi to elements ei of the structure, is defined in the natural way. We interpret sgn(a) as the sign of the real number a, i.e.\nsgn(a) =\n\n \n \n−1 if a < 0\n0 if a = 0\n1 if a > 0.\nThe sum ∑\nx t(x) is computed in the natural way: we compute t(x) for each assignment of x and add them. The term χ(ϕ) stands for the characteristic function of the formula ϕ,\ni.e., it is 1 if ϕ holds and 0 otherwise. We will often use the following abbreviation: ∑\nx1,...,xn :ϕ\nt := ∑\nx1\n∑\nx2\n· · · ∑\nxn\nχ(ϕ) · t .\nNote that the quantifiers are restricted to the finite part U of structures, and do not range over R. We use FO to refer to first-order logic on relational structures and FOR to refer to first-order logic on R-structures.\nExample 2. Consider the signature of weighted graphs, τw := (e 2). The first-order formula\n∀x, y, z (x 6= y ∧ x 6= z ∧ y 6= z) → (e(x, z) ≤ e(x, y) + e(y, z))\nholds exactly if the triangle inequality is satisfied by all triangles in the graph. Note that we use “≤” and “→”; formally these are abbreviations that can be rewritten according to our definition of FO.\nIn descriptive complexity it is very common to add additional numeric predicates to structures. Here, we use SUC(x, y) to mean y = x + 1 and insist that structures define this faithfully. Note that this can be defined using the ordering, equality and a first-order quantifier. However, we often consider fragments of first-order logic where quantifiers are restricted or not available, and having SUC(x, y) can be important in such situations."
    }, {
      "heading" : "2.1 Queries",
      "text" : "Single formulas can be used to define properties or decision problems, but in general we represent models as queries (also called interpretations). Queries map σ-structures to τ - structures, defining the universe, relations, constants and functions using logical formulas. A first-order query from σ-structures to τ -structures is an r + s+ t+ 2-tuple,\nq := (k, ϕ0, ϕ1, . . . , ϕr, ψ1, . . . , ψs, δ1, . . . , δt) .\nThe number k ∈ N is the dimension of the query. Each ϕi, ψj is a first-order formula over the signature σ. Let A be a σ-structure with universe UA. The formula ϕ0 has free variables x1, . . . , xk and defines the universe U of q(A),\nU := { (u1, . . . , uk) | ui ∈ U A, A |= ϕ0(u1, . . . , uk) } .\nThat is, the new universe consists of k-tuples of elements of the old universe, where ϕ0 determines which k-tuples are included.\nEach remaining ϕi has free variables x 1 1, . . . , x k 1 , x 1 2, . . . , x k ai and defines\nRi := {( (u11, . . . , u k 1), . . . , (u 1 ai , . . . , ukai) ) | A |= ϕi(u 1 1, . . . , u k ai ) } ∩ Uai .\nThat is, ϕi determines which of the ai-tuples of U are included in Ri. Next, each ψi has free variables x1, . . . , xk and defines ci as the lexicographically minimal (u1, . . . , uk) ∈ U such that A |= ψi(u1, . . . , uk). Finally, each δi is a number term that has free variables x11, . . . , x k 1 , x 1 2, . . . , x k bi . It defines\nfi\n(\n(u11, . . . , u k 1), . . . , (u 1 bi , . . . , ukbi)\n)\n:= δi(u 1 1, . . . , u k bi ) .\nFirst-order queries therefore transform σ-structures into τ -structures, and we write q(A) to represent the resulting τ -structure. The restriction to first-order logic here is not essential – given a logic L, we define L-queries in an analogous way.\nExample 3. Consider the (relational) vocabularies τS := (S 1) and τG := (E 2). We interpret τS-structures as binary strings where bit i is 1 if S(i), and τG-structures as graphs. The following first-order query gives a simple transformation from graphs to binary strings:\nqA := ( 2,⊤, E(x11, x 2 1) ) .\nGiven a graph with vertices U = {0, . . . , n − 1}, this query produces a binary string with bit positions labeled by pairs (i, j) ∈ U2. A bit (i, j) is 1 if E(i, j). Given that we always identify universes with subsets of the naturals, we re-label these pairs lexicographically and the resulting string is essentially the adjacency matrix of the input graph with rows concatenated.\nOne important property of queries is that they can be easily substituted when one needs to check a formula on the resulting structure. Given a τ → σ query q, imagine we need to check whether q(A) |= ϕ for some σ-formula ϕ. This can be done by replacing each relation Ri and function fj in ϕ by the appropriate definition from q and additionally guarding all quantifiers to only quantify elements satisfying ϕ0, the universe selection formula from q. Finally, we must add quantifiers for each constant, defining it as the minimal tuple satisfying its defining formula, and use these variables in place of the constant symbol. In this way, we get a new τ -formula ψ such that q(A) |= ϕ ⇐⇒ A |= ψ, as formulated in the following lemma, equivalent to e.g., Proposition 3.5 of (Immerman, 1999).\nLemma 1. Let q be a τ → σ query and ϕ a σ-formula. There exists a τ -formula q−1(ϕ) which satisfies, for all τ -structures A,\nq(A) |= ϕ ⇐⇒ A |= q−1(ϕ)."
    }, {
      "heading" : "2.2 Extensions of first-order logic",
      "text" : "So far, we have focused only on first-order logic. However, first-order logic on finite structures is often too limited from the computational perspective – it cannot express many interesting queries that are easy to compute. In fact, over relational structures with additional numeric predicates, the first-order definable properties correspond exactly to uniform AC0 (cf. (Immerman, 1999)). There are many known correspondences between logics and complexity classes; we introduce some of the relevant ones here.\nTo remove this limitation of FO, one extends it in various ways. One option is to allow quantifiers over relation and function symbols, resulting in second-order logic. We use SO to refer to second-order logic restricted to relational signatures and SOR to refer to second-order logic over R-signatures.\nFormally, formulas of SO (and SOR) are constructed in the same way as formulas of FO (FOR) but with the added quantifiers ∃Xϕ and ∀Xϕ, where X is a new relation symbol (or function symbol, in SOR) of a fixed arity r, so ϕ can now contain atoms (or terms, for function symbols) of the form X(x1, . . . , xr). In SOR it is also possible to introduce second-order variables inside terms using sup, i.e., if t is a SOR-term then so is supF t,\nwhere F ranges over all functions U r → R for a given universe U .1 Relational second-order variable X with arity r = 0 is called a bit-variable since the atom X can only be either true or false. Existential second-order logic is the fragment of second-order logic where all second-order quantifiers are existential (while first-order quantifiers are not restricted), and the sup operator is forbidden.\nExample 4. Consider the following existential SO formula on graphs:\n∃R,G,B ∀x, y ( R(x) ∨G(x) ∨B(x) ) ∧\n(E(x, y) → ¬ ((R(x) ∧R(y)) ∨ (G(x) ∧G(y)) ∨ (B(x) ∧B(y)))) .\nThis formula defines the well-known NP-complete problem of 3-colorability – each vertex is colored red, green or blue and adjacent vertices must have different colors. Note that multicolored vertices are allowed, a multicolored vertex can be colored any of its individual colors.\nAs this example indicates, second-order logic is very powerful; existential SO corresponds exactly to NP (Fagin, 1974). This implies that coNP is captured by universal SO, and that full SO captures the polynomial-time hierarchy. The situation is similar for R-structures, where existential SOR captures NPR (Grädel & Meer, 1996), a class analogous to NP for computations with reals that was defined by (Blum, Shub, & Smale, 1989).\nHowever, there is a large gap between uniform AC0 and NP and it is desirable to have logics corresponding to classes such as P. This is done by extending first-order logic with various operators. For example, the transitive closure operator allows us to write formulas of the form TC[x1, x2.ϕ(x1, x2)](y1, y2). This formula takes the transitive and reflexive closure of the (implicit) relation defined by ϕ(x1, x2) and evaluates it on (y1, y2). The least fixedpoint operator allows recursive definitions in formulas of the form LFP[R(x1, . . . , xk) = ϕ(R,x1, . . . , xk)](y1, . . . , yk), where R is a new relation symbol appearing only positively (i.e., under an even number of negations) in the inner formula ϕ. The result of this operator is defined as the least fixed-point of the operator R(x) → ϕ(R,x). The functional fixed-point is defined in a similar way over R-structures, see (Grädel & Meer, 1996) for details.\nExample 5. Consider the following formula on graphs augmented with constants s, t:\nTC[x, y.E(x, y)](s, t) .\nThis formula takes the transitive closure of the edge relation, and checks whether (s, t) is in the result. That is, it defines the well-known NL-complete problem of s, t-reachability.\nExample 6. Consider the following formula on weighted graphs augmented with constants s, t.\nTC[x, y.e(s, s) ≤ e(x, y)](s, t) .\n1. We need to introduce separate variable binding for formulas and terms because formulas and terms are distinct in our syntax. This can be avoided by using a term-only syntax where formulas are a special case, as done in, e.g., (Kaiser, Lang, Leßenich, & Löding, 2015). But our syntax allows to trivially decide when to apply propositional solvers rather than ones for the whole theory of the real field. The particular choice of sup simplifies some later proofs, and it can be defined in SOR. From a complexity-theoretic perspective it complicates the relationship between certain fragments and complexity classes; this could be avoided but is not relevant to our purposes.\nThis formula takes the transitive closure of the edge relation restricted to edges with weight at least e(s, s). If we call this value k, then the formula defines the property of allowing a k-flow from s to t that is never split over multiple edges.\nOver relational structures2, polynomial time is captured by least fixed-point logic (LFP) (Immerman, 1986; Vardi, 1982), and the same holds for PR and functional fixed-point (FFP) (Grädel & Meer, 1996). Although LFP is presumably more expressive than transitive closure logic (TC), TC captures all problems solvable in non-deterministic logarithmic space (NL) on relational structures (Immerman, 1987).\nOf course, one can also consider extending SO with these operators; the resulting logics capture well-known classes. See (Immerman, 1999) for an overview of logics capturing other complexity classes. All logics that we consider here are contained in SOR."
    }, {
      "heading" : "2.3 Outlines",
      "text" : "Given a logic L, we refer to the set of L-formulas which may contain certain placeholders as L-formula outlines. Intuitively, an outline fixes the structure of the formula but not the exact contents.\nTo be precise, we allow two kinds of placeholders. First, atoms a may be guarded by some Boolean guard3 Gi. Intuitively, the meaning of Gia is “a if Gi and false otherwise”. Boolean guards suffice for relational signatures. In the case of R-structures, formulas can contain real constants and it is desirable to learn these constants automatically. Thus, in addition to the Boolean guards, we allow real placeholders wi. Intuitively, they represent real number constants which must be found.\nMore formally, we define L-formula outlines as follows. We fix a countable set of Boolean guards {G1, . . .} and a countable set of real placeholders {w1, . . .}. Then, we define Lformula outlines exactly in the same recursive way as L-formulas and number terms, with the following two additional rules. First, for each outline ϕ and Boolean guard Gi, Giϕ is also an outline. Second, each wi is also a number term outline. Then, the set of formula outlines and number term outlines is built in the same way as formulas and terms are built.\nThe Boolean guards are intended to mean “a occurs here”, and given an instantiation of the guards I, we can instantiate an L-formula outline ψ to an L-formula ψI by replacing each Gia by a if Gi is true in I, and by false otherwise. Similarly, an instantiation I must assign an algebraic real number ri to each wi to make it a number term. We refer to queries containing L-formula outlines as L-query outlines. We omit L when it is clear from context, and use outline to refer to both query and formula outlines. Given an outline o, we write inst(o) for the set of formulas or queries obtainable as instantiations of o.\nNote that we do not allow the dimension of the query to be a placeholder, that leads quickly to undecidability. One could allow a finite upper-bound on the dimension, but this can be simulated by a finite set of outlines.\n2. Recall that our structures are always ordered. The existence of a logic capturing polynomial time on unordered structures is a major open question, cf. (Grohe, 2008). 3. We do not require that identical atoms share guards, that distinct atoms have different guards, or that all atoms are guarded.\nOutlines are in some sense the logical equivalent to program sketches (Solar-Lezama, Tancau, Bodik, Seshia, & Saraswat, 2006). They have advantages including immediate upper bounds on the complexity of synthesized formulas and clear normal forms.\nExample 7. Consider a structure with a single binary relation symbol E. An example outline of a formula defining a binary relation with variables x1, x2 without equality is:\nG1E(x1, x1) ∨G2E(x1, x2) ∨G3E(x2, x1) ∨G4E(x2, x2) .\nAllowing equality in addition, a bit more complex example that we will use for learning actual reductions is an outline defining a binary relation over a signature with constants s, t and binary relation E:\nϑ1 := ∨\na,b∈{s,t,x1,x2}\n(Gab1E(a, b) ∨Gab2¬E(a, b) ∨Gab3a = b ∨Gab4a 6= b) .\nWe can use this formula outline as part of a query outline, e.g.\nq1 := (k := 1, ϕ0 := ⊤, ϕ1 := ϑ1) ."
    }, {
      "heading" : "3. Learning Logical Queries",
      "text" : "In this section, we introduce our model of learning logical queries. The model consists of a learner giving candidate queries or hypotheses and a teacher (or verifier), which gives counter-examples or accepts the query. A learning task is characterized by a few parameters, first is the target class C.\nLet C ⊆ Struc(τ)×Struc(σ) be a binary relation on R-structures, and define the domain of C as dom(C) = {A | (A,B) ∈ C for some B}.\nIn our definition of the teacher and the learner, we distinguish between the relational part of a structure and its real-valued functions. Recall that a structure B is a R-modification of a structure A, B ∼R A, if it only differs in the values of the real-valued functions, but keeps the relational part intact. The restriction we put on the teacher and the learner with respect to R-modifications will become clear later, when we discuss termination of the learning process.\nDefinition 1. A C-teacher t is a function\nt : (τ → σ)-queries → (dom(C)× (SOR(τ)× SOR(σ)) ∗) ∪ {⊤}\nthat satisfies the following condition.\nt(q) =\n\n \n \n⊤ if {(A, q(A)) | A ∈ dom(C)} ⊆ C, (A, (ϕ1, ψ1), . . . A ∈ dom(C), (A, q(A)) 6∈ C, |= ∨iϕi, for each i ≤ l :\n. . . , (ϕl, ψl)) A′ ∼R A,A ′ |= ϕi ⇒ (B |= ψi ⇐⇒ (A ′, B) ∈ C)\nThat is, a teacher accepts a query q if for all A ∈ dom(C) we have (A, q(A)) ∈ C, and otherwise replies with a counter-example A. In addition to the counter-example, the teacher provides a sequence of formulas (ϕi, ψi) that defines the acceptable output on all\nR-modifications of A. Note the condition |= ∨iϕi requires that at least one ϕi holds on every structure. For relational signatures, the definition can be simplified to returning ⊤ or (A,ψ) since the only R-modification of a relational structure is the structure itself.\nFor R-structures, the requirement that the teacher specifies the correct behavior on all R-modifications implies that not all classes C have a teacher. In fact the teacher can only specify Boolean combinations of polynomial inequalities of real-valued functions from the structure. As a result, classes that use real numbers for advanced computations (e.g., encoding undecidable problems in the digits of the real numbers appearing there) do not have a teacher in this model. We accept this limitation as our motivation for R-structures is only to allow easy access to basic computations with quantities.\nOf course, in practice we generally restrict attention even more, to computable teachers and “reasonable” classes C. A natural extension would allow the teacher to return multiple (at least one) counter-examples A to an incorrect query, but we omit this possibility for clarity of presentation.\nExample 8. As a running example, we will trace the learning process for a reduction from (directed) s, t-reachability to strong connectedness. These properties can be defined in the following way.\nReach := TC[x, y.E(x, y)](s, t) AllReach := ∀x1, x2 (TC[y, z.E(y, z)](x1, x2)) ,\nand we write GReach = {A | A |= Reach} for the set of graphs satisfying Reach, and GAllReach, G¬Reach, and G¬AllReach analogously. The target class C is\n{(GReach, GAllReach)} ∪ {(G¬Reach, G¬AllReach)} .\nThe (general) teacher for such reductions is\nt(q) =\n\n \n \n⊤ if ∀A : A |= Reach ⇐⇒ q(A) |= AllReach\n(A, (Reach,AllReach)) where A |= Reach ∧ q(A) |= ¬AllReach\n(A, (¬Reach,¬AllReach)) where A |= ¬Reach ∧ q(A) |= AllReach .\nNote that in general, it is uncomputable to check whether A |= Reach ⇐⇒ q(A) |= AllReach for all A.\nNext, we define our learners. To shorten the definition, let us say that a query q is consistent with the series of examples (A1, (ϕ,ψ)1), . . . , (Am, (ϕ,ψ)m) iff, for each i ≤ m and each A′i ∼R Ai, it holds that if A ′ i |= ϕ j i then q(A ′ i) |= ψ j i . Note that this is exactly the requirement from the teacher definition above.\nDefinition 2. Let H be a class of logical queries. An H-learner L is a function that, given a sequence of examples e = (A1, (ϕ,ψ)1), . . . , (Am, (ϕ,ψ)m), satisfies\nL((A1, (ϕ,ψ)1), . . . , (Am, (ϕ,ψ)m)) =\n{\nh, h ∈ H, h is consistent with e,\n⊥, if no such h ∈ H exists .\nA learning task is specified by the pair (C,H). Note that our learners must always be consistent, and they return ⊥ iff there is no consistent query in the hypothesis space. The logic used in the query is determined by H. While Definitions 1 and 2 have some appeal from a theoretical perspective, in practice they have a number of disadvantages. In particular, we are interested in implementing our model and these definitions may not be computable, and even when they are, they still require a new implementation of the teacher and learner for each learning task. In the next subsections, we introduce a restricted and uniform learning model based on formula outlines. Restricted uniform learners and teachers have a number of practical advantages – for example, they are computable and the learning process is guaranteed to terminate."
    }, {
      "heading" : "3.1 Restricted Uniform Learner",
      "text" : "We begin by presenting restricted uniform learners. These are defined as outline learners, which are the following.\nDefinition 3. An outline learner is any H-learner such that H = inst(q) for some query outline q.\nExample 9. To complement the teacher defined in Example 8, we define an outline learner with H = inst(q1) using the outline q1 from Example 7.\nThe outline is uniform as it gives a compact representation of a hypothesis space, and can even enforce certain restrictions on the query. For example, outlines can require a query to generate an extension4 of the structure, which is useful when searching for models to give explicit isomorphisms or satisfying solutions to SAT instances.\nOutlines are also quite restricted. For example, for relational signatures, there are only finitely-many instantiations of a query outline. It is therefore possible to simply try them all and return a suitable one. However the following construction is preferable as it allows to use modern efficient SMT solvers.\nWe start the construction with a technical lemma that simplifies formula outlines for evaluation on structures of a fixed size. Intuitively, we build a formula ϕ|n that is in essence a QBF equivalent to ϕ on structures of size n.\nLemma 2. Let ϕ be a SOR formula outline over a signature σ and n ∈ N. For a structure A of size n, let Ac be an extension of A by the constants {0, . . . , n − 1} with constant i interpreted as element i. There exists a SOR formula outline ϕ|n over the signature σ ∪ {0, . . . , n− 1} such that all items below hold.\n(1) For all structures A with universe of size n and all instantiations I,\nA |= ϕI ⇐⇒ Ac |= ϕ|In.\n(2) The guards and real placeholders in ϕ|n are the same as in ϕ.\n(3) The size of ϕ|n is polynomial in n and the size of ϕ (for a fixed σ).\n4. An extension of a structure is formed by adding new predicates while leaving existing predicates unchanged.\n(4) There are no first-order quantifiers or sum terms in ϕ|n.\n(5) All relational second-order quantifiers in ϕ|n are over bit-variables.\nProof. The construction of ϕ|n from ϕ proceeds inductively. First order quantifiers are replaced by relational second-order bit variables. For sum terms ∑\nx t we first introduce a second-order function variable to define t and then replace ∑\nx t by an explicit sum over possible x. Finally, second order relational quantifiers are replaced by quantifying over all bits that the actual relations can address on a structure of size n.\nMore formally, we set ϕ|n = ϕ for all atomic formulas ϕ and t|n = t for constant terms t and real placeholders. We then define (¬ϕ)|n = ¬(ϕ|n), (ϕ ∨ ψ)|n = ϕ|n ∨ ψ|n, (ϕ ∧ ψ)|n = ϕ|n ∧ ψ|n, (t = s)|n = (t|n = s|n) and (t < s)|n = (t|n < s|n). For guarded formulas set (Giϕ)|n = Gi(ϕ|n). Analogously for terms: (s + t)|n = s|n + tn, (s − t)|n = s|n − tn, (s · t)|n = s|n · tn, (s/t)|n = s|n/tn, and sgn(t)|n = sgn(tn). For first-order quantifiers, we define:\n(∃xϕ)|n = ∃X0 . . . Xn−1 (exactly one(Xi) ∧ ϕ ′) .\nHere, exactly one(Xi) is the polynomial-size propositional formula stating that exactly one of the Xi is true, and ϕ\n′ is formed from ϕ|n by replacing each atom containing x, e.g. A(x, z), with\n\n\n∨\ni∈{0,...,n−1}\n(Xi ∧A(i, z))\n\n .\nFunction terms, e.g., f(x, y), are replaced with\nχ(X0)f(0, y) + χ(X1)f(1, y) + · · ·+ χ(Xn−1)f(n− 1, y) .\nFor sum terms we define the |n operation as follows:\n(\n∑\nx\nt(x)\n)\n|n = sup Ft\n\nχ (∀x t(x) = Ft(x)) |n · ∑\ni∈{0,...,n−1}\nFt(i)\n\n .\nNote that the summation on the right is an abbreviation and not a sum term – it is the linear-size explicit sum of the Ft(i).\nFinally a second-order relational quantifier is replaced by a series of quantifiers over bit-variables. For example, ∃Xϕ where X has arity 2, is replaced by\n∃X00X01 . . . X0nX10X11X12 . . . Xnn ϕ|n.\nThen, each atom X(x, y) in ϕ|n is replaced by ∨\ni,j∈{0,...,n−1}(x = i ∧ y = j ∧ Xij). The properties listed in the lemma follow directly from this construction.\nThe proof above was done directly for SOR formulas, but it also works for operators such as TC and LFP. One can convert them in various ways, for example they can be defined using second-order quantifiers. However – assuming the representation of formulas\ncan handle definitions efficiently – it is more efficient to define each stage of the induction in such operators in terms of the previous stage and define the initial stage using the given formula. For a structure of fixed size, such inductive definitions must halt after logarithmically (for TC) or polynomially (for LFP) many steps, so the converted formula size remains polynomial. The advantage of such conversion over using a second-order definition is that we minimize the number of variables introduced.\nLet us now use the above conversion to show how restricted uniform learners can be computed in practice.\nLemma 3. Assume that we are given a τ → σ SOR-query outline q and a sequence of m examples e = (A1, (ϕ,ψ)1), . . . , (Am, (ϕ,ψ)m) where each Ai is a finite τ -structure, each ϕ j i is a SOR(τ)-formula and each ψ j i is a SOR(σ)-formula. We can compute a q-learner, i.e., a function Lq satisfying:\nLq((A1, (ϕ,ψ)1), . . . , (Am, (ϕ,ψ)m)) =\n{\nh, h ∈ inst(q), h is consistent with e,\n⊥, if no such h ∈ H exists .\nProof. We will reduce the task of finding h to the task of model-checking a second-order {+, ·} formula β(q, e) using only second-order bit-variables over the real field (R,+, ·). Note that first-order quantifiers in this formula range over all real numbers, contrary to all formulas used elsewhere in this paper. Since second-order bit-variables can be simulated by first-order real-valued variables (e.g., by assuming the bitX is true iff the corresponding variable x = 0), one can convert β(q, e) to a first-order formula over (R,+, ·). Model-checking first-order formulas over the real field is known to be computable (Tarski, 1951) and efficient algorithms for this problem exist (Renegar, 1998). Importantly, SMT solvers can be applied to check β(q, e) directly. This is more efficient, since the nature of bit-variables can be utilized in the solver. We will also ensure that the size of β(q, e) is polynomial in the size of q and e and the maximum of the sizes of Ai.\nTo construct β(q, e), recall that, by definition, h is consistent with e iff for each i ≤ m and each A′i ∼R Ai, it holds that if A ′ i |= ϕ j i then h(A ′ i) |= ψ j i .\nRecall from Lemma 1 that qI(A′i) |= ψ j i is equivalent to A ′ i |= (q I)−1(ψji ). So the consistency condition above can be formulated as\nA′i |= ∧\nj\n(\nϕji → (q I)−1(ψji )\n)\n.\nRecall that the construction for q−1(ϕ) was just a substitution of the definitions from q into ϕ, so it also works when q is a query outline – only then q−1(ϕ) is a formula outline. Let therefore θi denote the formula outline that defines consistency with the i-th example:\nθi = ∧\nj\n(\nϕji → q −1(ψji )\n)\n.\nWe can now equivalently reformulate our task as computing Lq such that:\nLq((A1, (ϕ,ψ)1), . . . , (Am, (ϕ,ψ)m)) =\n{\nqI , A′i |= θ I i for all i ≤ m,A ′ i ∼R Ai, ⊥, if no such instantiation I exists .\nNow, since the size of each Ai (and so each A ′ i ∼R Ai) is known, as these structures are given, we can use Lemma 2 and instead of checking if A′i |= θi we can check if A ′ i |= θi||Ai|. Let θ′i = θi||Ai|. Since θi has no free variables, the construction from Lemma 2 provides a θ′i that uses no first-order variables at all, only constants appear in its atoms. Moreover, each relational atom, which now has the form R(i1, . . . , ir) for i1, . . . , ir ∈ {0, . . . , |Ai|}, has a known truth value in A′i – it’s the same as R(i1, . . . , ir) in Ai since A ′ i ∼R Ai. So we can remove those, and we are left only with Boolean guards Gi and number terms in which all function terms have constants in their variables, i.e, are of the form fj(i1, . . . , ir). Note that by Lemma 2 all relational second-order quantifiers in θ′i are already over bit-variables, but we still need to handle second-order quantifiers over real-valued function terms.\nLet θ′′i be the formula θ ′ i with each fj(i1, . . . , ir) replaced by a new variable named\nxi fj(i1,...,ir) . These variables now range over real numbers. Also, replace each second-order quantifier over a real-valued function term, e.g., ∀fj, by a string of first-order quantifiers over the corresponding newly introduced real variables for all occurrences containing fj , e.g., ∀xi\nfj(0) xi fj(1) xi fj(2) . Each term of the form supfj t is similarly replaced by supxifj (0)...x i fj(n) t. By Lemma 2 there are no sum terms in θ′i, and we leave terms of the form χ(ϕ) intact for the moment. We replace each guarded formula Giϕ by (Gi∧ϕ) and we will treat the guards Gi as free bit-variables. We also treat real placeholders as variables and all number-term functions (+,−, ·, etc.) as first-order functions. Note that now the formula θ′′i is in the signature {+,−, ·, /, sgn, <, ri} with additional sup and χ operators and uses only secondorder bit-variables. Note also that the condition that for all A′i ∼R Ai holds A ′ i |= θ I i is equivalent to\n(R,+,−, ·, /, sgn, <, ri) |= ∀xifj(i1,...,ir) (θ ′′ i ) I ,\nwhere the quantifier prefix ranges over all newly introduced variables xi fj(i1,...,ir) . Let us therefore construct the following {+,−, ·, /, sgn, <, ri}-formula:\nα(q, e) = ∧\ni=1,...,m\n∀xi fj(i1,...,ir) θ′′i .\nBy the previous construction and the above equivalence we have\nLq((A1, (ϕ,ψ)1), . . . , (Am, (ϕ,ψ)m)) =\n{\nqI , (R,+,−, ·, /, sgn, <, ri) |= α(q, e) I ,\n⊥, if no such instantiation I exists .\nWe will convert the formula α(q, e) constructed above to an equivalent formula over the first-order theory of (R,+, ·). First, let us remove the sup and χ operators. To that end, assume a supx r or χ(ψ) appears as a sub-term of t in an expression t = s (or t < s). Let t′ be the term t with the χ(ψ) or supx r sub-term replaced by a new variable z. In case of χ(ψ), we replace t = s by\n∃z ( (ψ → z = 1) ∧ (¬ϕ→ z = 0) ∧ (t′ = s) ) .\nIn case of supx r(x), we replace the expression t = s by\n∃z ( (∀x(r(x) ≤ z)) ∧ (∀z′(∀x(r(x) ≤ z) → z ≤ z′) ∧ (t′ = s) ) .\nAfter recurrently applying the replacement procedure above, we are left with a firstorder formula over −, /, sgn, <. Recall that −, /, sgn, < and all algebraic real numbers are definable in the real field using only · and +. We can thus write a {+, ·} formula α′(q, e) that is equivalent to α(q, e). Let now {G1, . . . , Gk} be the set of all Boolean guards in q and {w1, . . . , wl} the set of all real placeholders in this outline. Note that these are all free variables in α′(q, e). So we set\nβ(q, e) = ∃G1 . . . Gk ∃w1 . . . wl α ′(q, e) .\nBy the above construction, β(q, e) holds in the real field iff the assignment I of the leading existential variables provides the qI we are searching for. So we can use an SMT solver to solve β(q, e) and set Lq = ⊥ if it answers false and otherwise get the leading assignment I and set Lq = qI .\nThe formula β(q, e) constructed in the proof above is polynomial in the size of q, e and maxi |Ai| if one allows to use definitions inside formulas (which is allowed by all modern solvers). Note also that if we work only on relational signatures, then there are no realvalued variables or quantifiers in β(q, e). Thus, it is purely a quantified Boolean formula (QBF) and there has been much recent progress in efficient QBF solvers5. SAT solvers suffice for relational signatures when the entire system is existential. In many applications (see Section 4 for examples) we do not require full SOR and these more limited formalisms can offer better performance. An advantage of our approach is that in each application the complexity is clear from syntax and so one can automatically choose to use SAT or QBF solvers when possible."
    }, {
      "heading" : "3.2 Restricted Uniform Teacher",
      "text" : "Definition 4. Let C ⊆ Struc(τ)× Struc(σ) be a target class,\nPC = {(Φ1,Ψ1), . . . , (Φp,Ψp)}\nbe a finite set of formula pairs, and n ∈ N. We say that (PC , n) is a specification of C if all of the following items hold.\n(1) Each Φi is a second-order τ -formula and Ψi a second-order σ-formula.\n(2) For all A ∈ dom(C), the size of A’s universe is n.\n(3) dom(C) = {A | A ∈ Strucn(τ), A |= ∨\ni Φi}.\n(4) For A ∈ dom(C), (A,B) ∈ C iff\nB |= ∧\n{i|A|=Φi}\nΨi .\n5. See, e.g., the recent QBF (Lonsing, Seidl, & Van Gelder, 2016; Janota, Jordan, Klieber, Lonsing, Seidl, & Gelder, 2016) competitions.\nIntuitively, PC is a conjunction of implications that defines the class C, i.e, the acceptable behavior of the desired model q. Given an input structure A, if A |= Φi then we require q(A) |= Ψi. The restriction here to structures of size n is needed to guarantee that the teacher in the following definition is computable. One could similarly restrict attention to structures of size at most n. To specify problems without restricting the size, we say that PC above is a uniform unrestricted specification of C if all above items except for (2) and the restriction to Strucn in (3) hold (we will re-visit those in subsection 3.4).\nDefinition 5. A uniform restricted teacher is a C-teacher for a class C that has a specification S = ({(Φ1,Ψ1), . . . , (Φp,Ψp)}, n).\nNote that a uniform restricted teacher is only concerned with structures of size n. Also, recall that by Definition 1 it returns ⊤ iff {(A, q(A)) | A ∈ dom(C)} ⊆ C. Given the specification S, this condition is equivalent to saying that\nfor all A ∈ Strucn(τ), i ≤ p, A |= Φi =⇒ q(A) |= Ψi .\nOtherwise, the teacher is required to return a counter-example and a specification of what should be done on R-modifications of it: (A, (ϕ1, ψ1), . . . , (ϕl, ψl)). A uniform teacher can always return the full specification (Φ1,Ψ1), . . . , (Φp,Ψp) instead of a list suited to the specific counter-example. Still, we leave the possibility to return other formulas as it might improve the efficiency of learning. Note also that there may be multiple choices of a counterexample A. Any is acceptable, however the overall efficiency of learning may depend on the choice.\nExample 10. The teacher from Example 8 is nearly uniform – all that remains is to fix n as any finite value and restrict the teacher to graphs of size n. Then the teacher is uniform with specification\nTn := ({(Reach,AllReach), (¬Reach,¬AllReach)}, n) .\nWe will now show that uniform restricted teachers are computable. This is easy to prove for purely relational structures: there are only finitely-many relational structures of size n when the signature is fixed, and one can simply try them all. In practice the following construction is preferable.\nLemma 4. Let S = (PC , n) be a specification of the class C. There exists a computable uniform restricted C-teacher tS.\nProof. The proof is similar to that for Lemma 3, and we will again construct a second-order {+, ·} formula β(q) using only second-order bit-variables and check it over the real field (R,+, ·). Only this time the assignment of the leading existentially quantified variables will provide the counter-example structure A.\nBy definition of a uniform restricted teacher, it returns ⊤ iff for all structures A of size n and all i it holds that A |= Φi =⇒ q(A) |= Ψi. By Lemma 1 we can rewrite q(A) |= Ψi as A |= q−1(Ψi) so the whole condition becomes:\nA |= ∧\ni\n(\nΦi → q −1(Ψi)\n)\n.\nSince we are only concerned with structures of size n, let\nθ = ∧\ni\n(\nΦi → q −1(Ψi)\n)\n|n .\nOur task now is to find a structure A of size n that is a model of ¬θ, or return ⊤ if no such structure exists.\nTo this end, let again θ′ be the formula θ with each fj(i1, . . . , ir) replaced by a new variable named xi\nfj(i1,...,ir) that ranges over reals. Again, replace each second-order quantifier\nover a real-valued function term, e.g., ∀fj, by a string of first-order quantifiers over the corresponding newly introduced real variables containing fj, and similarly replace terms of the form supfj t by supxifj (0)...x i fj(n) t. Also, treat all number-term functions (+,−, ·, etc.) as first-order functions. Finally, replace each relational atom Rk(i1, . . . , ir) by a new secondorder bit-variable XRk(i1,...,ir). In this way, the constructed formula θ\n′ is in the signature {+,−, ·, /, sgn, <, ri} and uses only second-order bit-variables (and sup and χ operators). The condition that for some structure A of size n we have A |= ¬θ is equivalent to:\n(R,+,−, ·, /, sgn, <, ri) |= ∃XRk(i1,...,ir)∃x i fj(i1,...,ir) ¬θ′ ;\nthe quantifier prefix ranges over all newly introduced bit-variables XRk(i1,...,ir) and realvalued variables xi\nfj(i1,...,ir) .\nSimilarly as in the proof of Lemma 3, we use the fact that −, /, sgn, < and all algebraic real numbers are definable in the real field using only · and +, and that sup and χ can be defined as well. Substituting these definitions into the formula on the right-hand side above yields the {+, ·}-formula β(q) which we then solve using an SMT solver. If there is no solution, the teacher tS(q) returns ⊤. Otherwise, the SMT solver provides a witness for the outermost quantified variables XRk(i1,...,ir) and x i fj(i1,...,ir) . We construct the counterexample structure A of size n by putting (i1, . . . , ir) ∈ Rk if XRk(i1,...,ir) is set to true, and setting fj(i1, . . . , ir) = x\ni fj(i1,...,ir) (if some tuple is not quantified at all, we can set it to any\nnumber, e.g., 0). By the construction above, the reconstructed structure A satisfies ¬θ and is thus a counter-example, as required. So we set tS(q) = (A,PC) in this case.\nWhile a general learning task is defined by (C,H), a uniform restricted learning task is given by a specification and outline: ((PC , n), q).\nExample 11. To continue Example 8, our (uniform restricted) reduction learning task for structures of size n is (Tn, q1), where Tn is from Example 10 and q1 from Example 7. We will see in Example 12 in Subsection 4.1 that one can learn a correct reduction for this example, using the specification and techniques presented above."
    }, {
      "heading" : "3.3 Termination of Uniform Restricted Learning",
      "text" : "Let L be a learner and t a teacher. We define the sequence Lti of the interactions between L and t inductively as follows. We set Lt0 := L(), the hypothesis that L returns on an empty list of examples. If for some i we get Lti = ⊥ then the sequence is finished – there is no h ∈ H that satisfies the teacher. Else, let Ei := t(L t i) be the answer of the teacher to L t i. If\nEi = ⊤ the sequence L t i is finished, the last hypothesis was accepted. In the other case, set Lti+1 = L(E0, . . . , Ei). An outline learner is, essentially, a learner with a uniform hypothesis space and a uniform restricted teacher is a uniform way of producing correct counter-examples. In the proofs for Lemmas 3 and 4 we saw how to convert the main conditions of outline learners and uniform restricted teachers into model-checking on (R,+, ·). This can be solved, and so we can guarantee an alternating sequence of consistent hypotheses and counter-examples.\nOne concern is that we would like for the above sequence to terminate, i.e. to know after finite time whether there is an instantiation of the query outline that satisfies the teacher. While this is usually not achievable in the most general case, it is always guaranteed for outline learners and uniform restricted teachers.\nTheorem 1. Let S be a specification of a class C, tS the uniform restricted teacher from Lemma 4, and L an outline learner for some SOR-query outline q. All of the following items hold.\n(1) L is a consistent and conservative inst(q)-learner.\n(2) If tS(h) = ⊤ for some h ∈ inst(q) then the sequence L tS i is finite and its last element g\nsatisfies tS(g) = ⊤.\n(3) If there is no h ∈ inst(q) for which tS(h) = ⊤ then the sequence L tS i is finite and its\nlast element is ⊥.\nProof. The fact that L is a consistent and conservative inst(q)-learner, as well as the correctness of the sequence LtSi follows directly from the definitions. The only remaining thing is to show that the sequence LtSi is finite. But note that there are only finitely-many τ -structures of size n with different R-modifications. Given that each outline must hold on all previous counter-examples (by Definition 2) and each next example must be a counter-example (by Definition 1), the sequence must terminate after finitely-many steps.\nFor a given specification S and query outline q, we will write L(S, q) for the last element of the sequence LtSi considered above (which is well defined, since the sequence is finite).\nNote that the proof above relies on the condition we imposed on teachers and learners that all R-modifications of a structure are handled simultaneously in each step. It is easy to imagine a simpler learning definition, where in each step the teacher only has to respond with a single R-structure and a condition applicable only to this structure, not all of its R-modifications. The learner would then construct a hypothesis correct only for these structures.\nWe did not use this simple model exactly because learning might not terminate. Consider structures of size 1, i.e., with only one element 0, and only a single real-valued function f . Imagine an outline r > f(0) with a single real placeholder r. Intuitively, the learner seeks a number r greater than the value f(0) in the structure. For any finite sequence of examples A1, . . . , Am, the learner will easily find such an r = maxi≤m f\nAi(0)+1. But then, the teacher can respond with another example Am+1 where f(0) = r + 1. This would clearly result in an infinite learning sequence. Observe that the condition on R-modifications prevents this behavior: the learner will be forced to answer ⊥ already in the first step, as there is no r bigger than all numbers f(0)."
    }, {
      "heading" : "3.4 Unrestricted Uniform Learning",
      "text" : "In the previous two subsections we presented a restricted learning model that can exploit the efficiency of SMT solvers. Let us now show how to iterate the use of this model to get an unrestricted one. Theorems from descriptive complexity will provide strong guarantees for this unrestricted learning model. To this end, we need to say when a sequence of outlines covers a logic L.\nDefinition 6. Let Q = {q1, q2, . . .} be a sequence of query outlines in a signature σ and let L be a logic. We say that Q covers L if for every σ-outline q from L, we have inst(q) ⊆ ∪qi∈Qinst(qi) .\nThe definition above does not make any assumptions about computability of Q, but in practice we will only use sequences Q that are easily enumerable. It is the advantage of our logic approach that such sequences can easily be found by taking advantage of normal forms of formulas.\nFor example, consider a query outline qij that consists of i disjunctions of j conjunctions of guarded atoms or guarded negated atoms from the signature σ. The sequence Q0 = {q i j | i, j ∈ N} consists of all outlines of formulas in DNF. Since every quantifier-free formula can be converted to DNF, we know that Q0 covers all quantifier-free formulas. Similarly, we can construct Q1 by enumerating quantifier prefixes and putting them in front of formulas from Q0. Since every first-order formula has a prenex normal form, we get that Q1 covers FO. Putting a least fixed-point operator in front of formulas from Q1 gets us the set Q2 that covers LFP, because all LFP formulas have a normal form with just one LFP operator in the front. In the next section, we will show a few sequences of query outlines that worked well for practical applications.\nGiven a restricted specification S and a sequence of query outlines Q = {q1, q2, . . . }, we can run the restricted learning procedure and compute first L(S, q1). If it is not ⊥ then, by item (2) of Theorem 1, L(S, q1) is the solution for S. Otherwise, since L(S, q1) = ⊥, we proceed to consider q2, q3, and so on. If Q covers a logic L and S has a solution in L, then it will finally be found, since our procedure is complete. We write L(S,Q) = L(S, qi) for the smallest i for which L(S, qi) 6= ⊥ and L(S,Q) = ⊥ otherwise.\nConsider now an unrestricted specification PC of a class C, and let Sn = (PC , n) be its restriction to structures of size n. If q ∈ Q is the first query from Q that is an unrestricted solution for PC , then the sequence L(Si, Q) will stabilize on q from some i on. We only get a guarantee that it is correct on structures of size i and below, but in practice it seems that queries that are correct on moderately sized examples are usually correct in general (where “moderate” depends on the complexity of the query). In addition, the following theorem shows that if a solution exists in the complexity class we consider and we use a suitable sequence of query outlines, then we will eventually converge to a correct solution.\nTheorem 2. Let Q be a sequence of query outlines covering FO (FO(TC), FO(LFP), FFP, existential SO, existential SOR). Assume PC is an unrestricted specification of a class C and that there exists a solution f for C (i.e. (A, f(A)) ∈ C for all A) that is in the complexity class uniform-AC0 (NL, P, PR, NP, NPR). Then L((PC , i), Q) 6= ⊥ for each i and for some k holds\n(A,L((PC , l), Q)(A)) ∈ C for all A and l ≥ k,\ni.e., L((PC , l), Q) is a solution for C for all l ≥ k.\nProof. By theorems from descriptive complexity cited in Subsection 2.2, if C has a solution f in uniform-AC0 (NL, P, PR, NP, NPR), then there exists a query q in FO (FO(TC), FO(LFP), FFP, existential SO, existential SOR) that is also a solution for C. Since Q covers this logic, we know that there exists a solution qi ∈ Q.\nLet Sn = (PC , n). Since qi is a solution for the unrestricted class C, it is also a solution for Sn. So L(Sn, Q) 6= ⊥ since it will stop at qi at the latest. Also, for each j < i such that qj is not a solution for C, there exists a counter-example for qj of size nj. Let k = maxj<i nj. By Theorem 1 we will discard all false qj in L(Sl, l) for all l ≥ k, and thus return a generally correct solution.\nThe above theorem provides strong guarantees for our learning method: if a solution exists, even in a broadly-defined complexity class such as P or NP, then it will be found. The question remains whether this is a practical method. In the next section, we examine various learning tasks, look for reasonable teachers and outline sequences, and show that with modern SAT, QBF and SMT solvers this method can indeed be practically applied."
    }, {
      "heading" : "4. Applications",
      "text" : "As described above, the learning problem in our model consists of the specification of the teacher and the outline for the learner. For different learning tasks, it might be advantageous to choose different outlines. For example, some tasks might only require a very simple Boolean circuit to solve, while for other we might need the full power of polynomial time programs with loops and intermediate definitions. In this section we introduce a few parametrized classes of outlines with increasing computational power. With each class of outlines, we present a sample learning task that is well suited for this outline and discuss how the task is solved in our model.\nWe start with outlines for very simple quantifier-free first-order formulas. It turns out that even such basic outlines are useful: they are a good candidate for finding reductions, as we discuss in the next section. After that, we move to first-order outlines. These correspond to uniform AC0 circuits and we show that they can be used for learning patterns and rules on relational structures, and even rules for board games. Next, we discuss how threshold circuits can be encoded in our model. Threshold gates allow to build neural networks and we show how such networks can be represented in our model. Finally, we present outlines with fixed-point operators. Such outlines can encode complicated polynomial-time programs and are hard to learn. We present a few experiments where simple programs with loops and definitions are successfully learnt in our model.\nWe focus here on examining how these sample applications can be achieved in our model, in order to see that a variety of natural learning tasks can be modeled. Subsections 4.1 and 4.2 contain comparisons to existing, alternative approaches and show that our methods are competitive. Subsections 4.3 and 4.4 are primarily intended to show the range of our approach and do not contain exhaustive experimental results."
    }, {
      "heading" : "4.1 Learning Quantifier-Free First-Order Formulas",
      "text" : "Complexity-theoretic reductions are an important tool to determine the relative hardness of computational problems and other applications exist. For example, SAT solvers are now commonly used as general NP solvers and the necessary transformations are generally reductions. This naturally leads to the question of (automatically) learning and verifying reductions.\nLearning reductions was first considered by Crouch et al. (Crouch et al., 2010), and we have also (Jordan & Kaiser, 2013b) implemented, benchmarked and evaluated a number of different approaches to the problem.\nProblem In descriptive complexity, a reduction from the τ -property defined by ϕ to the σ-property defined by ψ is a (τ → σ)-query q that satisfies\nA |= ϕ ⇐⇒ q(A) |= ψ (1)\nfor all τ -structures A. Of course, reductions should have less computational power than the complexity classes they are used in and descriptive complexity usually focuses on weak classes of reductions, such as first-order reductions (i.e., first-order queries as reductions). Here, we study quantifier-free first-order reductions, an even weaker class that still suffices to capture important complexity classes. While polynomial time or logspace reductions are most common, such power is usually not necessary for reductions and only causes additional difficulties (Agrawal, 2011; Agrawal, Allender, Impagliazzo, Pitassi, & Rudich, 2001; Veith, 1998). Here we introduce learning reductions in the context of our model, see (Jordan & Kaiser, 2013b) for more details, other approaches and experimental comparisons.\nIn order to make finding quantifier-free reductions decidable, we restrict attention to a fixed size n, i.e., we require Formula (1) to hold only for structures of size at most n. Assume that we are searching for a dimension-k reduction from the τ -property defined by ϕ to the σ-property defined by ψ.\nLet P be the set of τ -structures of size at most n that satisfy ϕ, Q be the set of σstructures of size at most nk that satisfy ψ, and P and Q be their complements up to the size bounds. Our target class is C = (P ×Q)∪(P ×Q) – we want a query that maps positive instances to positive instances and negative instances to negative instances.\nOutline As an outline, we focus on reductions in which all formulas are in DNF with c conjunctions. We fix ϕ0 to be always true and the dimension k (so the new universe is the set of k-tuples of elements of the old universe). Finally, we have a number of parameters determining the atomic formulas that may occur – for example, whether to allow certain numeric predicates such as successor.\nTeacher When the teacher receives a candidate hypothesis q, it checks Formula (1), i.e.\nA |= ϕ =⇒ q(A) |= ψ ∧ A 6|= ϕ =⇒ q(A) 6|= ψ\nfor all structures A of size at most n. The teacher returns (A,ψ) if A |= ϕ and (A,¬ψ) otherwise.\nResults See (Jordan & Kaiser, 2013b) for an extended comparison of our approach using various SAT, QBF, ASP and BDD packages, along with the earlier system developed by Crouch et al. (Crouch et al., 2010). Here we present a short summary of the results.\nLearning quantifier-free reductions (with the restrictions described above) between problems in NP∩ coNP is essentially a Σ2p problem. Therefore it can be solved using a reasonablesized encoding and single call to either a QBF solver or ASP solver supporting disjunctive programs. We therefore compare our approach with modern QBF and ASP solvers.\nWe refer to (Jordan & Kaiser, 2013b) for precise details and an extended experimental comparison of various approaches to this problem. In particular, there we present an opensource implementation (DE6) of our approach specialized to reduction-finding. QBF and ASP instance generation is done using ReductionTest.native (part of Toss, see (Jordan & Kaiser, 2013a) for details)7.\nTable 1 considers a set of 48 decision problems in NL (including e.g. directed and undirected reachabililty, but also several simpler problems) and presents results for all 2304 = 482 reduction-finding problems constructed between these problems. These 48 decision problems are from the ReductionFinder implemented by Crouch et al. (Crouch et al., 2010) and therefore allow us to compare with ReductionFinder as well. However, ReductionFinder considers a slightly different class of reductions, generally resulting in somewhat simpler instances. A fair comparison is therefore difficult and ReductionFinder is included for completeness. The timeout was set to 120s in Table 1.\nWe see that our approach, along with the QBF solver rareqs, are the best among these choices. Interestingly, rareqs is an expansion-based QBF solver (Janota, Klieber, Marques-Silva, & Clarke, 2012) and so in this case it essentially functions like our approach by refining a series of hypotheses (abstractions) using counter-examples.\nWhile the parameters used in Table 1 result in comparatively easy instances, extended experiments with more difficult parameters give similar results, cf. (Jordan & Kaiser, 2013b). In addition, the teacher in Table 1 considers only counter-examples of size exactly n. Allowing counter-examples of size at most n greatly improves performance of our approach – very small counter-examples result in easy sub-problems that tell us a great deal about the space of possible solutions.\n6. Available at http://www-alg.ist.hokudai.ac.jp/~skip/de, configured as de-gms using GlueMiniSat 2.2.5 as solver. Equivalent functionality is available as part of Toss: http://toss.sf.net/ and a visual interface is also available at http://toss.sf.net/reduct.html 7. The input files used in this section are available at http://toss.sf.net/reductGen.html\nExample 12. We complete our running Example 8 here. Recall that the task was to find a reduction between two NL-complete problems: directed s, t-reachability (given a directed graph with labeled vertices s and t, determine whether t is reachable from s) and all-pairs reachability (determine if a directed graph is strongly connected). The problems were defined by these 2 formulas.\nReach := TC[x, y.E(x, y)](s, t) AllReach := ∀x1, x2 (TC[y, z.E(y, z)](x1, x2)) .\nWe were searching through the space of outlines as described above, and structures of increasing sizes. Our system finds the following correct reduction for outline q1 as in Example 7 and sizes n ≥ 3:\n(k := 1, ϕ0 := true, ϕ1 := x1 = s ∨ x2 = t ∨ E(x2, x1)) .\nThis reverses all edges in the original graph, adds directed edges from s to all vertices and also adds directed edges to t from all vertices. A similar reduction exists without reversing the edges – however the above is our actual output."
    }, {
      "heading" : "4.2 Learning First-Order Formulas",
      "text" : "Recently, a system was implemented (Kaiser, 2012) that represents board games as relational structures and learns their rules from observing example play videos. Fundamentally, the system works by computing minimal distinguishing formulas for sets of structures, e.g., formulas satisfied by structures representing winning positions and by none of the losing ones. We implement the computation of distinguishing formulas in our framework and compare the performance.\nProblem Let P and N be finite sets of τ -structures. We want to learn a formula ϕ without free variables such that A |= ϕ for all A ∈ P and for no A ∈ N . Unlike previous tasks, we want a minimal such formula, not just an arbitrary one.\nOutline and Teacher The outlines in this case are not quantifier-free any more, but they are built by adding quantifier prefixes to quantifer-free outlines similar to the ones used above. In this case, we start with a CNF formula with c clauses and k additional variables. Then, we quantify the k additional variables existentially. The final outline is then a disjunction of l such quantified CNF formulas, each with k added variables and at most c clauses. Moreover, to find minimal formulas we iterate through k, for each k we range l from 1 to k + 1, and c as well. The teacher is simple: given a formula ϕ it checks if A |= ϕ for all A ∈ P, and if not, it returns (A, true) for some A 6|= ϕ. Then, it checks if A 6|= ϕ for all A ∈ N and returns (A, false)8 if this is not the case for some A |= ϕ.\nResults We substituted our SAT-based learner for the procedure for computing distinguishing formulas used in (Kaiser, 2012). To replicate the experiments, we used the most recent revision of Toss9 and ran each experiment 3 times on a 4Ghz Intel i7-4790K processor.\n8. Here, “true” and “false” are satisfied by encoded Boolean structures. 9. Revision 1935 on Sourceforge, compiled with OCaml 4.02.1.\nSince the variance in time was negligible, we only report the mean running time.10 Comparing the results, the SAT-based approach appears to offer significantly better performance, even though it is more general and competes against a system hand-crafted specifically for this problem.\nBreakthrough Connect4 Gomoku Pawn-Whopping\nOriginal system 39s 14s 4s 473s SAT-based system 2s 5s 2s 130s\nWe use the same example plays for both systems – these examples were chosen by hand for the original system (Kaiser, 2012). But our SAT-based approach searches (faster) for formulas in more expressive logics, beyond reach for the original system. For this reason, the resulting formulas are not always correct – they are for Breakthrough and Gomoku, but not for Connect4 and Pawn-Whopping. It would be easy to overcome this by adding examples or changing the outline to match the more restrictive logics used by the original system."
    }, {
      "heading" : "4.3 Learning Threshold Circuits (Formulas with Reals)",
      "text" : "Let us now show how neural networks can be represented in our model. We will focus on deep convolutional networks, but the ideas generalize to other models easily.\nConvolutional neural networks share weights using sliding windows over the input vector and often alternate such shared-weights-layers with max-pooling layers which just compute maximum over a window to reduce the number of neurons and, more importantly, to capture different scales, e.g. in image recognition. In the convolutional layer, each neuron is a so called rectified linear unit. This means that each neuron multiplies its inputs by the respective weights, adds the result, subtracts another weight, and sends to its output the maximum of this result and 0.\n. . .\nwindow of 4\nw w w w. . .\nmax max. . .\nThe figure above sketches a convolutional network. We wrote w in each neuron to emphasise that the same weight vector is used in all neurons in this layer. For vision applications, the sliding window and max-pooling window can be 2D, e.g. 3 × 3. For classification, there is often a fully-connected layer before the output layer. All these can be encoded in our formalism in an analogous way, so we focus on 1D convolutional networks.\nThe input to a 1D network is a n-bit vector of real numbers. We represent it as a relational structure over U = {0, . . . , n− 1} with a unary function f0, such that f0(i) is the ith component of the input vector.\n10. To replicate, after getting Toss, do make Learn/LearnGameTest.native and then LearnGameTest.native -dir Learn/examples/ -f Breakthrough001, or Connect4001, etc. for the original results, and with -s to use our SAT solver technique.\nTo keep our reduction simple, let us assume our network has two convolutional layers with a window of size 3 and two maps each, with one max-pooling layer in between. The outline we provide for this network generalizes in an easy way to other network architectures.\nBy definition, the output of the ith neuron of the first map of the first convolutional layer, which we denote f11 (i), is given by\nf11 (i) = max(0, w 1 1 · f0(i) + w 1 2 · f0(i+ 1) + w 1 3 · f0(i+ 2)− w 1 0).\nIn our formalism, we can write max(0, t) as t ·χ(t > 0), so let us use max as a more readable shorthand. We can formalize the above as follows:\nf11 (x) = max\n\n0, ∑\ny,z:SUC(x,y)∧SUC(y,z)\nw11 · f0(x) + w 1 2 · f0(y) + w 1 3 · f0(z) −w 1 0\n\n .\nNote that w10, w 1 1, w 1 2, and w 1 3 are now the real placeholders of our outline. We define f21 analogously with w 2 i (i = 0,. . . ,3) and get the 2 maps of the first convolutional layer complete in this way.\nHowever, we must still construct the max-pooling and following layer, where there are fewer neurons due to the scaling effect of max-pooling. This is done by skipping every other element. Let us first define the max-pooling outputs:\nf im(x) = max\n\nf i1(x), ∑\ny:SUC(x,y)\nf i1(y)\n\n\nfor i = 1, 2. Let SUC2(x, y) := ∃z(SUC(x, z) ∧ SUC(z, y)). We create the second convolutional layer by skipping over every other element.\nf i2(x) = max\n(\n0, ∑\ny,z:SUC2(x,y)∧SUC2(y,z)\nw21 · f 1 m(x) + w 2 2 · f 1 m(y) + w 2 3 · f 1 m(z)+\nw24 · f 2 m(x) + w 2 5 · f 2 m(y) + w 2 6 · f 2 m(z)− w0\n)\n.\nNow, we can trivially make a query that selects even elements from our input structure and uses f12 and f 2 2 as functions. It represents exactly the output of the second convolutional layer in a network.\nAs we have seen, neural networks fit nicely into our model, in fact they correspond exactly to a specific syntactic class of formulas. But we observed a problem when experimenting with such encodings using the method presented in the proofs above: SMT solvers are generally not efficient when dealing with neural network problems of this kind. Similar issues have been previously reported (Pulina & Tacchella, 2012) and we are not aware of a fully satisfying solution at this time. Still, the approach we present can be adapted to make use of partial procedures, such as stochastic gradient descent, as part of the learner process."
    }, {
      "heading" : "4.4 Learning Polynomial-Time Programs",
      "text" : "In this section, we consider synthesizing programs for a given logical specification. Itzhaky et al. (Itzhaky et al., 2010) considered a similar problem, however they focused on synthesizing formulas in more specialized logics.\nProblem In program synthesis, we are given a specification and hope to find an efficient program satisfying it. For us, a specification is a way to verify whether the output q(A) is accepted for A. There are two major variations – either the output for each structure is unique (as in our example here), or there is a set of acceptable outputs (e.g., when finding some satisfying solution for SAT instances).\nIn our example here, we have a query s in an expressive logic (SO) and wish to find an equivalent query in a less-expressive logic. In particular, we consider the problem of identifying winning regions in finite games – i.e., directed graphs with a predicate V0(x) meaning that vertex x belongs to Player 0. Decidability requires restricting the size of the games to n, and we set C to be the set of pairs (A,B) such that A is a finite game of size at most n and B is the extension of A with the winning region identified in a new monadic predicate W .\nOutline Here, we re-use the outlines introduced for learning games, but with an added extension to least fixed-point formulas for added expressive power. We focus on least fixedpoint formulas, with a single LFP operator that is outermost11. We fix the arity a of the fixed-point predicate, and assume, as before, that the inner formula is a disjunction of l quantified CNF formulas with k variables and c clauses each. We use such an outline for exactly one selected relation W in the query, all others are set to identity.\nTeacher Assume that we have a SO query s that produces the desired extension with the winning region identified. Given a hypothesis q, the teacher can guess a game A of size at most n such that in q(A) the new relation W (x) is not equivalent to the region in s(A). Let a1, . . . , ak be the winning positions in s(A). The teacher then returns the pair (\nA,∀x (W (x) ↔ ∨ i(x = ai)) ) .\nExample Consider the case of identifying winning regions in finite reachability games. When the current vertex belongs to a player, that player chooses an outgoing edge and moves to a connected vertex. Player 1 loses if the play reaches a vertex that belongs to her and has no outgoing edge. Similarly, Player 0 loses if the play reaches a position where he must but cannot move, but also if the play becomes a cycle and goes on forever. The goal is to identify the vertices from which Player 0 has a winning strategy. That is, we want a formula ϕ(x) which holds exactly on the vertices for which Player 0 has a winning strategy.\nReachability games are positional, i.e., it suffices to consider strategies that depend only on the current position and not on the history of the game. Therefore, a strategy of Player 1 can be defined as a binary relation S1 that is a subset of the edges and that, for vertices of Player 0, contains all successors of the vertex as well. Then, x is winning for Player 1 (by S1) if all vertices reachable from x by S1 either belong to Player 0 or have an S1-successor. This\n11. This is a normal-form for fixed-point logics, although the arity of the fixed point may increase when we convert to it (see Corollary 4.11 in (Immerman, 1999)).\nis easily expressible using the TC operator and guessing the strategy leads to a second-order formula ϕ0(x) which holds exactly if x is winning for Player 0.\nIn reachability games, the following LFP formula defines the winning region for Player 0:\nLFP [ W (x) = {\n(¬∃x1 : (¬W (x1) ∧ E(x, x1)) ∧ ¬V0(x)) ∨\n∃x1 : (W (x1) ∧ E(x, x1) ∧ V0(x)) }] (x) .\nThe LFP operator recursively defines W (x), starting with the empty set and adding tuples that satisfy the formula on the right until a fixed-point is reached. Therefore, this formula says that a position x is winning for Player 0 if (a) it is the opponent’s move and all outgoing edges go to positions we win; or (b) it is Player 0’s move and there is an edge to a winning position.\nRecall that the fixed-point predicate is initially empty. Therefore, the winning positions after one iteration are the positions belonging to the opponent with no outgoing edges. Then, the winning region grows gradually until it is the attractor of those positions – which is correct. An equivalent, slightly longer formula is found by our program in less than a minute for n ≥ 3.12\nFurther work The LFP formula for reachability games can be written by hand, but our motivation for presenting this example is the hope to compute polynomial-time solvers for other games. In particular, weak parity games and parity games are also positional, so it is trivial to write a SO formula defining the winning region (as we did for reachability games). But the polynomial-time program for solving weak parity games is complicated, and the existence of a polynomial-time solver for full parity games (which is equivalent to the existence of an LFP formula) is a long-standing open problem.\nOur implementation can also search for other programs, e.g., for graph isomorphism, graph coloring or SAT. There are classes where these problems are in polynomial-time13."
    }, {
      "heading" : "5. Conclusions and Future Work",
      "text" : "Above, we introduced our machine learning approach and its implementation using modern SMT solvers. We prove that our approach comes with strong theoretical guarantees: as long as a model exists in a given complexity class (e.g., NL, P, NP), it will be found. Thanks to the efficiency of modern SAT and QBF solvers, our general procedure outperforms specialized approaches both in learning reductions (Crouch et al., 2010) and in learning from examples (Kaiser, 2012). We consider these early results promising and encourage further experimentation with our freely available implementation14.\nThere are many questions we leave unanswered. For example, there is a large variance in runtime depending on the precise series of counter-examples given by the teacher. We would like to know how to choose “good” counter-examples and whether randomness (Zeugmann, 2006) can help. We ask what outlines are “good”, how to choose them to find the desired\n12. To replicate, after getting Toss, do make Learn/LfpTest.native and then run it. 13. E.g., isomorphism of planar graphs, bounded-degree graphs, and graphs excluding a minor; k-SAT and\nk-coloring are NL-complete for k = 2 and NP-complete for k ≥ 3. 14. Available from http://toss.sf.net, see (Jordan & Kaiser, 2013b) for learning instructions.\nprograms quickly and to make them readable. We are interested in re-using sub-formulas found for one problem to speed up learning in another one, a form of knowledge transfer.\nFinally, efficiency of our approach in quantitative settings has been disappointing. It seems that at present SMT solvers are not suited for tasks such as verification or synthesis of neural networks. But SMT solvers are evolving and hopefully will improve in this regard. One could also use stochastic gradient descent directly in our learner. How to utilize such incomplete procedures efficiently remains an open question, but we hope that this work will motivate further studies on the boundary between SMT solvers and machine learning.\nAcknowledgements We appreciate the encouragement and support of Neil Immerman and Thomas Zeugmann, without whom this paper would not exist."
    } ],
    "references" : [ {
      "title" : "The isomorphism conjecture for constant depth reductions",
      "author" : [ "M. Agrawal" ],
      "venue" : "Journal of Computer and System Sciences, 77 (1), 3–13.",
      "citeRegEx" : "Agrawal,? 2011",
      "shortCiteRegEx" : "Agrawal",
      "year" : 2011
    }, {
      "title" : "Reducing the complexity of reductions",
      "author" : [ "M. Agrawal", "E. Allender", "R. Impagliazzo", "T. Pitassi", "S. Rudich" ],
      "venue" : "Computational Complexity,",
      "citeRegEx" : "Agrawal et al\\.,? \\Q2001\\E",
      "shortCiteRegEx" : "Agrawal et al\\.",
      "year" : 2001
    }, {
      "title" : "On a theory of computation and complexity over the real numbers: NP -completeness, recursive functions and universal machines",
      "author" : [ "L. Blum", "M. Shub", "S. Smale" ],
      "venue" : "Bull. Amer. Math. Soc. (N.S.),",
      "citeRegEx" : "Blum et al\\.,? \\Q1989\\E",
      "shortCiteRegEx" : "Blum et al\\.",
      "year" : 1989
    }, {
      "title" : "Finding reductions automatically",
      "author" : [ "M. Crouch", "N. Immerman", "J.E.B. Moss" ],
      "venue" : "In Fields of Logic and Computation – Essays Dedicated to Yuri Gurevich on the Occasion of His 70th Birthday,",
      "citeRegEx" : "Crouch et al\\.,? \\Q2010\\E",
      "shortCiteRegEx" : "Crouch et al\\.",
      "year" : 2010
    }, {
      "title" : "Generalized first-order spectra and polynomial-time recognizable sets",
      "author" : [ "R. Fagin" ],
      "venue" : "Complexity of Computation, SIAM-AMS Proceedings, Vol. 7, pp. 43–73.",
      "citeRegEx" : "Fagin,? 1974",
      "shortCiteRegEx" : "Fagin",
      "year" : 1974
    }, {
      "title" : "Metafinite model theory",
      "author" : [ "E. Grädel", "Y. Gurevich" ],
      "venue" : "Information and Computation,",
      "citeRegEx" : "Grädel and Gurevich,? \\Q1998\\E",
      "shortCiteRegEx" : "Grädel and Gurevich",
      "year" : 1998
    }, {
      "title" : "Descriptive Complexity Theory over the Real Numbers",
      "author" : [ "E. Grädel", "K. Meer" ],
      "venue" : "Mathematics of Numerical Analysis: Real Number Algorithms,",
      "citeRegEx" : "Grädel and Meer,? \\Q1996\\E",
      "shortCiteRegEx" : "Grädel and Meer",
      "year" : 1996
    }, {
      "title" : "The quest for a logic capturing PTIME",
      "author" : [ "M. Grohe" ],
      "venue" : "Proceedings, Twenty-Third Annual IEEE Symposium on Logic in Computer Science, LICS 2008, pp. 267–271.",
      "citeRegEx" : "Grohe,? 2008",
      "shortCiteRegEx" : "Grohe",
      "year" : 2008
    }, {
      "title" : "Dimensions in program synthesis",
      "author" : [ "S. Gulwani" ],
      "venue" : "Proceedings of the 12th International ACM SIGPLAN Symposium on Principles and Practice of Declarative Programming, PPDP ’10, pp. 13–24.",
      "citeRegEx" : "Gulwani,? 2010",
      "shortCiteRegEx" : "Gulwani",
      "year" : 2010
    }, {
      "title" : "Solving and verifying the boolean Pythagorean triples problem via cube-and-conquer",
      "author" : [ "M.J.H. Heule", "O. Kullmann", "V.W. Marek" ],
      "venue" : "In Theory and Applications of Satisfiability Testing, 19th International Conference,",
      "citeRegEx" : "Heule et al\\.,? \\Q2016\\E",
      "shortCiteRegEx" : "Heule et al\\.",
      "year" : 2016
    }, {
      "title" : "Relational queries computable in polynomial time",
      "author" : [ "N. Immerman" ],
      "venue" : "Inform. Control, 68, 86–104.",
      "citeRegEx" : "Immerman,? 1986",
      "shortCiteRegEx" : "Immerman",
      "year" : 1986
    }, {
      "title" : "Languages that capture complexity classes",
      "author" : [ "N. Immerman" ],
      "venue" : "SIAM J. Comput., 16 (4), 760–778.",
      "citeRegEx" : "Immerman,? 1987",
      "shortCiteRegEx" : "Immerman",
      "year" : 1987
    }, {
      "title" : "Descriptive Complexity",
      "author" : [ "N. Immerman" ],
      "venue" : "Springer-Verlag.",
      "citeRegEx" : "Immerman,? 1999",
      "shortCiteRegEx" : "Immerman",
      "year" : 1999
    }, {
      "title" : "A simple inductive synthesis methodology and its applications",
      "author" : [ "S. Itzhaky", "S. Gulwani", "N. Immerman", "M. Sagiv" ],
      "venue" : "In Proceedings of the 25th Annual ACM SIGPLAN Conference on Object-Oriented Programming,",
      "citeRegEx" : "Itzhaky et al\\.,? \\Q2010\\E",
      "shortCiteRegEx" : "Itzhaky et al\\.",
      "year" : 2010
    }, {
      "title" : "Solving QBF with counterexample guided refinement",
      "author" : [ "M. Janota", "W. Klieber", "J. Marques-Silva", "E. Clarke" ],
      "venue" : "In Theory and Applications of Satisfiability Testing, SAT 2012, 15th International Conference,",
      "citeRegEx" : "Janota et al\\.,? \\Q2012\\E",
      "shortCiteRegEx" : "Janota et al\\.",
      "year" : 2012
    }, {
      "title" : "Benchmarks from reduction finding",
      "author" : [ "C. Jordan", "L. Kaiser" ],
      "venue" : "International Workshop on Quantified Boolean Formulas",
      "citeRegEx" : "Jordan and Kaiser,? \\Q2013\\E",
      "shortCiteRegEx" : "Jordan and Kaiser",
      "year" : 2013
    }, {
      "title" : "Experiments with reduction finding",
      "author" : [ "C. Jordan", "L. Kaiser" ],
      "venue" : "In Theory and Applications of Satisfiability Testing, 16th International Conference,",
      "citeRegEx" : "Jordan and Kaiser,? \\Q2013\\E",
      "shortCiteRegEx" : "Jordan and Kaiser",
      "year" : 2013
    }, {
      "title" : "Learning games from videos guided by descriptive complexity",
      "author" : [ "L. Kaiser" ],
      "venue" : "Proceedings of the 26th Conference on Artificial Intelligence, AAAI-12, pp. 963–970.",
      "citeRegEx" : "Kaiser,? 2012",
      "shortCiteRegEx" : "Kaiser",
      "year" : 2012
    }, {
      "title" : "A unified approach to boundedness properties in MSO",
      "author" : [ "L. Kaiser", "M. Lang", "S. Leßenich", "C. Löding" ],
      "venue" : "In 24th EACSL Annual Conference on Computer Science Logic (CSL 2015),",
      "citeRegEx" : "Kaiser et al\\.,? \\Q2015\\E",
      "shortCiteRegEx" : "Kaiser et al\\.",
      "year" : 2015
    }, {
      "title" : "Inductive programming: A survey of program synthesis techniques",
      "author" : [ "E. Kitzelmann" ],
      "venue" : "Approaches and Applications of Inductive Programming, Third International Workshop, AAIP 2009, Edinburgh, UK, September 2009, Revised Papers, Vol. 5812 of Lecture Notes in Computer Science, pp. 50–73.",
      "citeRegEx" : "Kitzelmann,? 2010",
      "shortCiteRegEx" : "Kitzelmann",
      "year" : 2010
    }, {
      "title" : "Computer-aided proof of Erdős discrepancy properties",
      "author" : [ "B. Konev", "A. Lisitsa" ],
      "venue" : "Artificial Intelligence,",
      "citeRegEx" : "Konev and Lisitsa,? \\Q2015\\E",
      "shortCiteRegEx" : "Konev and Lisitsa",
      "year" : 2015
    }, {
      "title" : "The QBF Gallery: Behind the scenes",
      "author" : [ "F. Lonsing", "M. Seidl", "A. Van Gelder" ],
      "venue" : "Artificial Intelligence,",
      "citeRegEx" : "Lonsing et al\\.,? \\Q2016\\E",
      "shortCiteRegEx" : "Lonsing et al\\.",
      "year" : 2016
    }, {
      "title" : "Challenging SMT solvers to verify neural networks",
      "author" : [ "L. Pulina", "A. Tacchella" ],
      "venue" : "AI Commun.,",
      "citeRegEx" : "Pulina and Tacchella,? \\Q2012\\E",
      "shortCiteRegEx" : "Pulina and Tacchella",
      "year" : 2012
    }, {
      "title" : "Recent progress on the complexity of the decision problem for the reals",
      "author" : [ "J. Renegar" ],
      "venue" : "Quantifier Elimination and Cylindrical Algebraic Decomposition, Texts and Monographs in Symbolic Computation, pp. 220–241. Springer Vienna.",
      "citeRegEx" : "Renegar,? 1998",
      "shortCiteRegEx" : "Renegar",
      "year" : 1998
    }, {
      "title" : "Combinatorial sketching for finite programs",
      "author" : [ "A. Solar-Lezama", "L. Tancau", "R. Bodik", "S. Seshia", "V. Saraswat" ],
      "venue" : "In Proceedings of the 12th International Conference",
      "citeRegEx" : "Solar.Lezama et al\\.,? \\Q2006\\E",
      "shortCiteRegEx" : "Solar.Lezama et al\\.",
      "year" : 2006
    }, {
      "title" : "A Decision Method for Elementary Algebra and Geometry",
      "author" : [ "A. Tarski" ],
      "venue" : "University of California Press. Originally published as RAND Report R-109, 1948. Also available in Quantifier Elimination and Cylindrical Algebraic Decomposition, pp. 24–84, Springer 1998.",
      "citeRegEx" : "Tarski,? 1951",
      "shortCiteRegEx" : "Tarski",
      "year" : 1951
    }, {
      "title" : "The complexity of relational query languages",
      "author" : [ "M.Y. Vardi" ],
      "venue" : "Proceedings of the 14th Annual ACM Symposium on Theory of Computing, May 1982, San Francisco, California, USA, pp. 137–146.",
      "citeRegEx" : "Vardi,? 1982",
      "shortCiteRegEx" : "Vardi",
      "year" : 1982
    }, {
      "title" : "Succinct representation, leaf languages, and projection reductions",
      "author" : [ "H. Veith" ],
      "venue" : "Information and Computation, 142 (2), 207–236.",
      "citeRegEx" : "Veith,? 1998",
      "shortCiteRegEx" : "Veith",
      "year" : 1998
    }, {
      "title" : "From learning in the limit to stochastic finite learning",
      "author" : [ "T. Zeugmann" ],
      "venue" : "Theoret. Comput. Sci., 364 (1), 77–97.",
      "citeRegEx" : "Zeugmann,? 2006",
      "shortCiteRegEx" : "Zeugmann",
      "year" : 2006
    } ],
    "referenceMentions" : [ {
      "referenceID" : 8,
      "context" : "We refer the reader to (Gulwani, 2010; Kitzelmann, 2010) for a general perspective on inductive synthesis.",
      "startOffset" : 23,
      "endOffset" : 56
    }, {
      "referenceID" : 19,
      "context" : "We refer the reader to (Gulwani, 2010; Kitzelmann, 2010) for a general perspective on inductive synthesis.",
      "startOffset" : 23,
      "endOffset" : 56
    }, {
      "referenceID" : 13,
      "context" : "For example, given a specification in an expressive logic (second-order), (Itzhaky et al., 2010) synthesized equivalent formulas in less expressive log-",
      "startOffset" : 74,
      "endOffset" : 96
    }, {
      "referenceID" : 3,
      "context" : "Automatically finding complexity-theoretic reductions between computational problems was first considered by (Crouch et al., 2010).",
      "startOffset" : 109,
      "endOffset" : 130
    }, {
      "referenceID" : 12,
      "context" : "For more details, see (Immerman, 1999) or Chapter 3 of (Grädel, Kolaitis, Libkin, Marx, Spencer, Vardi, Venema, & Weinstein, 2007) for an overview and background, or (Grädel & Meer, 1996) and (Grädel & Gurevich, 1998) for details on R-structures and their logics.",
      "startOffset" : 22,
      "endOffset" : 38
    }, {
      "referenceID" : 12,
      "context" : "5 of (Immerman, 1999).",
      "startOffset" : 5,
      "endOffset" : 21
    }, {
      "referenceID" : 12,
      "context" : "(Immerman, 1999)).",
      "startOffset" : 0,
      "endOffset" : 16
    }, {
      "referenceID" : 4,
      "context" : "As this example indicates, second-order logic is very powerful; existential SO corresponds exactly to NP (Fagin, 1974).",
      "startOffset" : 105,
      "endOffset" : 118
    }, {
      "referenceID" : 10,
      "context" : "Over relational structures2, polynomial time is captured by least fixed-point logic (LFP) (Immerman, 1986; Vardi, 1982), and the same holds for PR and functional fixed-point (FFP) (Grädel & Meer, 1996).",
      "startOffset" : 90,
      "endOffset" : 119
    }, {
      "referenceID" : 26,
      "context" : "Over relational structures2, polynomial time is captured by least fixed-point logic (LFP) (Immerman, 1986; Vardi, 1982), and the same holds for PR and functional fixed-point (FFP) (Grädel & Meer, 1996).",
      "startOffset" : 90,
      "endOffset" : 119
    }, {
      "referenceID" : 11,
      "context" : "Although LFP is presumably more expressive than transitive closure logic (TC), TC captures all problems solvable in non-deterministic logarithmic space (NL) on relational structures (Immerman, 1987).",
      "startOffset" : 182,
      "endOffset" : 198
    }, {
      "referenceID" : 12,
      "context" : "See (Immerman, 1999) for an overview of logics capturing other complexity classes.",
      "startOffset" : 4,
      "endOffset" : 20
    }, {
      "referenceID" : 7,
      "context" : "(Grohe, 2008).",
      "startOffset" : 0,
      "endOffset" : 13
    }, {
      "referenceID" : 25,
      "context" : "Model-checking first-order formulas over the real field is known to be computable (Tarski, 1951) and efficient algorithms for this problem exist (Renegar, 1998).",
      "startOffset" : 82,
      "endOffset" : 96
    }, {
      "referenceID" : 23,
      "context" : "Model-checking first-order formulas over the real field is known to be computable (Tarski, 1951) and efficient algorithms for this problem exist (Renegar, 1998).",
      "startOffset" : 145,
      "endOffset" : 160
    }, {
      "referenceID" : 3,
      "context" : "(Crouch et al., 2010), and we have also (Jordan & Kaiser, 2013b) implemented, benchmarked and evaluated a number of different approaches to the problem.",
      "startOffset" : 0,
      "endOffset" : 21
    }, {
      "referenceID" : 0,
      "context" : "While polynomial time or logspace reductions are most common, such power is usually not necessary for reductions and only causes additional difficulties (Agrawal, 2011; Agrawal, Allender, Impagliazzo, Pitassi, & Rudich, 2001; Veith, 1998).",
      "startOffset" : 153,
      "endOffset" : 238
    }, {
      "referenceID" : 27,
      "context" : "While polynomial time or logspace reductions are most common, such power is usually not necessary for reductions and only causes additional difficulties (Agrawal, 2011; Agrawal, Allender, Impagliazzo, Pitassi, & Rudich, 2001; Veith, 1998).",
      "startOffset" : 153,
      "endOffset" : 238
    }, {
      "referenceID" : 3,
      "context" : "(Crouch et al., 2010).",
      "startOffset" : 0,
      "endOffset" : 21
    }, {
      "referenceID" : 3,
      "context" : "(Crouch et al., 2010) and therefore allow us to compare with ReductionFinder as well.",
      "startOffset" : 0,
      "endOffset" : 21
    }, {
      "referenceID" : 17,
      "context" : "2 Learning First-Order Formulas Recently, a system was implemented (Kaiser, 2012) that represents board games as relational structures and learns their rules from observing example play videos.",
      "startOffset" : 67,
      "endOffset" : 81
    }, {
      "referenceID" : 17,
      "context" : "Results We substituted our SAT-based learner for the procedure for computing distinguishing formulas used in (Kaiser, 2012).",
      "startOffset" : 109,
      "endOffset" : 123
    }, {
      "referenceID" : 17,
      "context" : "Breakthrough Connect4 Gomoku Pawn-Whopping Original system 39s 14s 4s 473s SAT-based system 2s 5s 2s 130s We use the same example plays for both systems – these examples were chosen by hand for the original system (Kaiser, 2012).",
      "startOffset" : 214,
      "endOffset" : 228
    }, {
      "referenceID" : 13,
      "context" : "(Itzhaky et al., 2010) considered a similar problem, however they focused on synthesizing formulas in more specialized logics.",
      "startOffset" : 0,
      "endOffset" : 22
    }, {
      "referenceID" : 12,
      "context" : "11 in (Immerman, 1999)).",
      "startOffset" : 6,
      "endOffset" : 22
    }, {
      "referenceID" : 3,
      "context" : "Thanks to the efficiency of modern SAT and QBF solvers, our general procedure outperforms specialized approaches both in learning reductions (Crouch et al., 2010) and in learning from examples (Kaiser, 2012).",
      "startOffset" : 141,
      "endOffset" : 162
    }, {
      "referenceID" : 17,
      "context" : ", 2010) and in learning from examples (Kaiser, 2012).",
      "startOffset" : 38,
      "endOffset" : 52
    }, {
      "referenceID" : 28,
      "context" : "We would like to know how to choose “good” counter-examples and whether randomness (Zeugmann, 2006) can help.",
      "startOffset" : 83,
      "endOffset" : 99
    } ],
    "year" : 2016,
    "abstractText" : "Machine learning is a thriving part of computer science. There are many efficient approaches to machine learning that do not provide strong theoretical guarantees, and a beautiful general learning theory. Unfortunately, machine learning approaches that give strong theoretical guarantees have not been efficient enough to be applicable. In this paper we introduce a logical approach to machine learning. Models are represented by tuples of logical formulas and inputs and outputs are logical structures. We present our framework together with several applications where we evaluate it using SAT and SMT solvers. We argue that this approach to machine learning is particularly suited to bridge the gap between efficiency and theoretical soundness. We exploit results from descriptive complexity theory to prove strong theoretical guarantees for our approach. To show its applicability, we present experimental results including learning complexity-theoretic reductions rules for board games. We also explain how neural networks fit into our framework, although the current implementation does not scale to provide guarantees for real-world neural networks.",
    "creator" : "dvips(k) 5.991 Copyright 2011 Radical Eye Software"
  }
}