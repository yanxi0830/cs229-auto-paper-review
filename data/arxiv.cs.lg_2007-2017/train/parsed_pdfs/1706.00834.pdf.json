{
  "name" : "1706.00834.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "Online Dynamic Programming",
    "authors" : [ "Holakou Rahmanian" ],
    "emails" : [ "holakou@ucsc.edu", "vishy@ucsc.edu", "manfred@ucsc.edu" ],
    "sections" : [ {
      "heading" : "1 Introduction",
      "text" : "Consider the following online learning game. In each round, the algorithm plays with a Binary Search Tree (BST) for a given set of n keys. Then the adversary reveals a set of probabilities for the n keys and their n+ 1 gaps, and the algorithm incurs a loss of average search cost. The goal is to predict with a sequence of BSTs minimizing regret which is the difference between the total loss of the algorithm and that of the single best BST chosen in hindsight.\nA natural approach to solve this problem is to keep track of a distribution on all possible BSTs over the trials of the game. However, if implemented naively, this approach will be impractical since it is intractable to maintain a weight vector of exponential size. Going beyond BSTs, this issue is common among all combinatorial objects with n components as the number of objects is typically exponential in n.\nThere has been much work on developing efficient algorithms that implicitly encode the weights over the set of combinatorial objects using concise representations. Such work includes k-sets [22], permutations [1, 12, 23] and paths [3, 7, 11, 16, 21]. There are also more general tools for learning combinatorial concepts. Follow the Perturbed Leader (FPL) [13] is a simple algorithm which adds random perturbation to the cumulative loss of each component, and then predicts with the combinatorial object with minimum perturbed loss. Component Hedge (CH) [15] and its extensions\nar X\niv :1\n70 6.\n00 83\n4v 2\n[ cs\n.L G\n] 7\nto submodular base polytopes [10, 19, 20] are powerful generic techniques which keep track of component-wise weights in the convex hull of the objects for prediction. Unfortunately the results of CH and its current extensions cannot be directly applied to problems like BST. This is because there is no polynomial characterization of the convex hull of BSTs in its original space.\nWe close this gap by exploiting the underlying dynamic programming algorithm which solves the BST optimization problem. Each BST problem is connected to two smaller BST problems once the root is decided. We “hedge” our bets on these localized decisions. Our method is general and applies to combinatorial objects whose optimization problem can be solved efficiently via a wide class of dynamic programming algorithms. Using the underlying graph of sub-problems in dynamic programming, we form a concise representation of the combinatorial objects by encoding them as sub-graphs. This graph representation allows us to extend both standard Hedge algorithm [9, 17] and Component Hedge to wide class of combinatorial objects like BST (see Section 5), Matrix-Chain Multiplication, Knapsack, Rod Cutting, and Weighted Interval Scheduling (see Appendix A).\nPaper Outline We start with online learning of paths as simple sub-graphs in Section 2. This section briefly describes the main two existing algorithms for the path problem: (1) path kernels – which is an efficient implementation of Hedge – and (2) Component Hedge. Section 3 introduces a new class of sub-graphs, namely k-multipaths, and generalizes algorithms in Section 2 for these combinatorial objects. In Section 4, we precisely define a class of combinatorial objects recognized by dynamic programming algorithms and their corresponding online prediction problem – namely dynamic programming games. Then we prove that these dynamic programming games reduce to online learning of k-multipaths. As an interesting example, we apply our method to the problem of online learning of binary search trees in Section 5 (due to space restriction, additional examples are discussed in Appendix A). Finally, Section 6 concludes with comparison to other algorithms and future work."
    }, {
      "heading" : "2 Background",
      "text" : "Perhaps the simplest algorithms in online learning are the well-known so-call “experts algorithms” like the Randomized Weighted Majority [17] or Hedge [9] algorithms. It keeps track of a probability vector over all experts and the weight wi of expert i is proportional to exp(−η L(i)), where L(i) is the cumulative loss of expert i through trials and η is a non-negative learning rate. In our application, we use the typically exponentially many combinatorial objects as the set of experts. Like [15], in order to make a clear distinction with Component Hedge, from now on in this paper we call this algorithm Expanded Hedge (EH)."
    }, {
      "heading" : "2.1 Learning Paths",
      "text" : "The online shortest path has been explored both in full information setting [15, 21] and various bandit settings [2, 3, 8, 11]. Concretely the problem in full information setting is as follows. Consider a directed acyclic graph (DAG) G = (V,E) with designated source node s ∈ V and sink node ω ∈ V . In each trial, the algorithm predicts with a path from s to ω. Then, for each edge e ∈ E, the adversary reveals a loss `e ∈ [0, 1]. The loss of the algorithm is given by the sum of the losses of the edges along the predicted path. The goal is to minimize the regret which is the difference between the total loss of the algorithm and that of the single best path chosen in hindsight. There are two main algorithms in the literature for this setting:"
    }, {
      "heading" : "2.1.1 Expanded Hedge on Paths",
      "text" : "Takimoto and Warmuth [21] developed an algorithmic approach, namely path kernels, to apply Expanded Hedge on path problem efficiently by exploiting the underlying structure of the paths. Basically, path kernels maintain a distribution of the paths by keeping the weights on the edges along the paths normalized. In each trial, the weight of each edge is updated multiplicatively by its associated exponentiated loss followed by normalization via weight pushing [18]. Finally, to sample from the distribution, starting from the source, we hop to the next node according to localized distribution over the out-going edges at each node. The regret bound is similar to the one of the Hedge algorithm [9]:\nTheorem 1 (Takimoto-Warmuth [21]). Given a DAG G = (V,E) with designated source node s ∈ V and sink node ω ∈ V , letN and L∗ be the number of paths in G from s to ω and the total loss of best path, respectively. Also let B be an upper bound on the loss of any path in each trial. Then, over T trials, EH guarantees:\nE[LEH]− L∗ ≤ B √ 2T logN +B logN"
    }, {
      "heading" : "2.1.2 Component Hedge on Paths",
      "text" : "Koolen, Warmuth and Kivinen [15] developed a generic framework called Component Hedge (CH) which results in efficient and effective online algorithm over combinatorial objects. When applied to the path problem, CH maintains a “usage” vector in a unit-flow polytope. In each trial, the weight of each component (i.e. edge) is updated multiplicatively by its associated exponentiated loss. Then the weight vector is projected back to the unit-flow polytope via relative entropy projection. To do projection, iterative Bregman projection [5] is used which basically enforces flow conservation at each node by setting input and output flow to their geometric average as it cycles through the vertices. Finally, to sample with the same expectation as the usage vector, the usage vector is decomposed into paths using a greedy approach which zeros out at least one edge in each iteration. The regret bound will no longer have an extra range factor: Theorem 2 (Koolen-Warmuth-Kivinen [15]). Given a DAG G = (V,E) with designated source node s ∈ V and sink node ω ∈ V , let D be the length the paths in G from s to ω against which the CH algorithm is compared. Also denote the total loss of the best path of length D by L∗. Then, over T trials, CH guarantees:\nE[LCH]− L∗ ≤ D √ 4T log |V |+ 2D log |V |\n3 Learning k-Multipaths\nWe now generalize the online shortest path problem from learning paths to learnig more complex subgraphs – namely k-multipaths. To do so, we also assume some additional structure in the underlying DAG which we call k-regularity. Definition 1 (k-Regular DAG). A DAG G = (V,E) is called k-regular if and only if it has following properties:\n(i) There exists one designated “source” node s ∈ V with no in-coming edges.\n(ii) There exists a set of “sink” nodes Ω ⊂ V which is the set of nodes with no out-going edges.\n(iii) For each vertex v ∈ V − Ω, the set of out-going edges from v (denoted by Ev) is partitioned into tuples of size k (or simply k-tuples) denoted by Fv = {E(1)v , . . . , E(dv)v } in which1⋃\ni∈[dv ]\nE(i)v = Ev, ∀ i, j ∈ [dv], i 6= j, E(i)v ∩ E(j)v = ∅, ∀i ∈ [dv], |E(i)v | = k\nDefinition 2 (k-Multipath). Given a k-regular DAG G = (V,E), let2 π ∈ N|E| in which πe is associated with e ∈ E. Define πin(v) := ∑ e:e=(u,v) πe and πout(v) := ∑ e:e=(v,u) πe. π is called a k-multipath if and only if it has the properties below:\n(i) πout(s) = k.\n(ii) For any two edges e and e′ belonging to the same k-tuple in G, πe = πe′ .\n(iii) For each vertex v ∈ V − Ω− {s}, πout(v) = k × πin(v).\nIntuitively, k-multipath is a more general version of k-ary trees in the sense that as k children are branching out of a given parent, some children may have already been explored from other branches. Similar to nodes, an edge can also visited more than once in a k-multipath. See Figure 1 for an example of 2-multipath in given 2-regular DAG.\n1For a positive integer j, [j] := {1, 2, . . . , j} 2N is the set of non-negative integers.\nk-Multipath Learning Problem Now let us define the problem of online learning of k-multipaths. Consider a k-regular DAG G with parameters as in Definition 1. At trial t, the algorithm predicts with a k-multipath π(t−1). Then, for each edge e ∈ E, the adversary reveals a loss `(t)e ∈ [0, 1]. The loss of the algorithm is given by π(t−1) · `(t). Observe that the online shortest path problem is a special case when |Ω| = k = 1. In the remainder of this section, we generalize the algorithms in 2.1.1 and 2.1.2 for online learning of k-multipaths.\n3.1 Expanded Hedge on k-Multipaths\nWe implement the Expanded Hedge efficiently over the problem of online learning of k-multipath by considering each k-multipath as an expert. Notice that each k-multipath can be generated by successively choosing a k-tuple out of out-going edges from a given node v ∈ V by starting from the source s until we reach sink nodes in Ω. With each k-tuple in the k-regular DAG, i.e. Ẽ ∈ F := ⋃ v∈V Fv , we associate a weight wẼ . We maintain a distribution W over k-multipaths by keeping the weights w ∈ R|F|+ along the k-tuples in k-multipaths normalized. Concretely the weight vector w has the properties below which is denoted by Φ throughout this paper:\nΦ1 : The weights are in product form, i.e. Wπ = ∏ Ẽ∈F (wẼ)\nπẼ in which πẼ is the common value in π among edges e ∈ Ẽ.\nΦ2 : The weights are locally normalized, i.e. ∑ Ẽ∈Fv wẼ = 1 for all v ∈ V − Ω.\nΦ3 : The total path weight is one, i.e. ∑ πWπ = 1.\nIfW has the Φ properties, one can sample fromW as follows. Starting from the source v = s, sample an outgoing k-tuple from Fv as the weights form a normalized distribution (See Φ2). Continue sampling k-tuples until the k-multipath is “fully grown” and reaches sink nodes in Ω. Because of Φ1, this is a valid sample drawn from W . Observe that πẼ indicates the number of times k-tuple Ẽ is sampled through this process. Assuming all k-multipaths π satisfy ‖π‖1 ≤ D̄, this can be done in O( D̄k × |V | k ). The updates for each k-multipath π according to Expanded Hedge are as follows:\nW (t)π ∝W (t−1)π exp(−ηπ · ` (t))\n= ∏ Ẽ∈F (w (t−1) Ẽ )πẼ  exp −η ∑ Ẽ∈F πẼ ∑ e∈Ẽ `(t)e  = ∏ Ẽ∈F w (t−1) Ẽ exp −η ∑ e∈Ẽ `(t)e  ︸ ︷︷ ︸\nŵ (t)\nẼ\n πẼ\nwhich basically indicates that in order to implement Expanded Hedge, the weight of each k-tuple Ẽ ∈ F can be updated multiplicatively with exponentiated loss associated with Ẽ, i.e. ŵ(t)\nẼ =\nw (t−1) Ẽ\nexp [ −η ∑ e∈Ẽ ` (t) e ] . Now we explore the efficient normalization of W (t).\nGeneralized Weight Pushing For efficient normalization, we generalize the weight pushing algorithm [18] for k-multipaths. Our goal is to find new k-tuple weights w(t)\nẼ such that Φ properties are satisfied and W (t)π ∝ ∏ Ẽ∈F (ŵ (t) Ẽ )πẼ . To do so, for each v ∈ V , we introduce Zv as the normalization constant if v was the source in G. Now the generalized weight pushing is as follows:\n1. For every v ∈ Ω, set Zv = 1. 2. Recursively find Zv for all v ∈ V − Ω via Zv = ∑ Ẽ∈Fv ŵ (t) Ẽ ∏ u:(v,u)∈Ẽ Zu.\n3. For each v ∈ V − Ω, for all Ẽ ∈ Fv , set w(t)Ẽ = ŵ (t) Ẽ\n∏ u:(v,u)∈Ẽ Zu\nZv\nSee Appendix B for the proof of correctness and efficiency of the generalized weight pushing algorithm.\nRegret Bound In order to use the regret bound of Expanded Hedge [9], we have to initialize W (0) to the uniform distribution. This can be done by setting all weights to one followed by generalized weight pushing. Note that Theorem 1 is a corollary of Theorem 3 if we set k = 1.\nTheorem 3. Given a k-regular DAG G with designated source node s and sink nodes Ω, let N and L∗ be the number of k-multipaths in G from s to Ω and the total loss of best k-multipath, respectively. Also let B be an upper bound on the loss of any k-multipath in each trial. Then, over T trials, EH guarantees\nE[LEH]− L∗ ≤ B √ 2T logN +B logN\n3.2 Component Hedge on k-Multipaths\nIn order to apply Component Hedge to the online learning of k-multipath, we associated a weight we with each edge e ∈ E. As briefly introduced in Section 2.1.2, CH consists of different modules. We discuss the modules of this algorithm introduced in [15] followed by the regret bound guarantees.\nk-Flow Polytope The polytope of k-multipaths (denoted by Ψ) can be obtained from Definition 2 by relaxing the integer constraint. For a given point w ∈ Ψ ⊂ R|E|+ , define win(v) := ∑ e:e=(u,v) we\nand wout(v) := ∑ e:e=(v,u) we. The constraints below on w characterizes the polytope Ψ:\n1. Root Outflow wout(s) = k.\n2. k-Flow Preservation For each vertex v ∈ V − Ω− {s}, wout(v) = k × win(v). 3. k-Tuple Equality For any two edges e and e′ belonging to the same k-tuple in G, we = we′ .\nRelative Entropy Projection In tth trial, after the multiplicative update of the weight vector by exponentiated loss (i.e. ∀e ∈ E, ŵ(t)e = w(t−1) e−η ` (t) e ), the weight vector is projected back to the polytope Ψ via relative entropy projection. Concretely:\nw(t) := arg min w∈Ψ ∆(w||ŵ(t)), where ∆(a||b) = ∑ i ai log ai bi + bi − ai\nTo do this projection, iterative Bregman projection [5] can be used which cycles through the constraints and project the point to each constraint iteratively. The details of the relative entropy projection to each constraint is shown in Appendix C. These projections have the following algebraic interpretations:\n1. Root Outflow Normalize the out-flow of s to k.\n2. k-Flow Preservation For a given vertex v ∈ V − Ω− {s} multiplicatively scale up/down the weights associated with in- and out-flow so that they will be proportionate to the k-to-1 weighted geometric average of the out- and in-flow, respectively.\n3. k-Tuple Equality Enforce equality by assigning the geometric average of each k-tuple to its components. This can be done simultaneously to all k-tuples in F .\nDecomposition First we find any k-multipath with non-zero weights on all edges. To do so, we keep choosing an out-going non-zero k-tuple from a given node v, starting from v = s, until we reach the sink nodes in Ω. Assuming all k-multipaths π satisfy ‖π‖1 ≤ D̄, this can be done inO( D̄k × |V | k ). Then we subtract that k-multipath, scaled by its minimum edge weight. This creates a new zero, maintains k-flow preservation and k-tuple equality constraints, and reduces the source’s outflow. After at most O( |V | 2\nk ) iterations the source has outflow zero. The total running time is O( D̄ |V |3 k3 ).\nRegret Bound The general regret bound for Component Hedge depends on the initial weight vector w(0) ∈ Ψ via ∆(π||w(0)) in which π is the k-multipath the algorithm is compared against. Instead of explicitly selectingw(0) in Ψ, we implicitly design the initial point by starting with a point w̃(0) ∈ R|E|+ and project it onto Ψ. This novel idea yields to regret guarantee below (see Appendix D for proof):\nTheorem 4. Given a k-regular DAG G = (V,E), let D be the upperbound for the 1-norm of the k-multipaths in G against which the algorithm is compared 3. Also denote the total loss of the best k-multipath by L∗. Assuming D ≤ |E|, then, over T trials, CH guarantees\nE[LCH]− L∗ ≤ D √ 8T log |V |+ 4D log |V | (1)\nMoreover, if the infinity-norm of the k-multipaths is one (i.e. π is a bit-vector), then: E[LCH]− L∗ ≤ D √ 4T log |V |+ 2D log |V | (2)\nNotice that by setting |Ω| = k = 1, all modules of path learning in [15] are recovered. Moroever, observe that Theorem 2 is a corollary of Theorem 4 since every path is represented as a bit vector."
    }, {
      "heading" : "4 Dynamic Programming Games",
      "text" : "In this section, we focus on the online learning of combinatorial objects which can be “recognized” by a dynamic programming algorithm – dynamic programming games. First we precisely define the problem and then show the its connection to k-multipath learning problem\nProblem Description Let P be a minimization 4 problem in Rn which can be solved efficiently via dynamic programming. The solution is a combinatorial object minimizing a given loss function. Denote V as the set of all subproblems v in dynamic programming which needs to be solved in order to eventually solve P iteratively in bottom-up fashion [6]. Also let Ω ⊂ V be the set of base/primitive subproblems. Assuming u, v ∈ V , we focus on the family of dynamic programming algorithm with the recurrence relation of the form below:\nOPT(v) = { LΩ(v) v ∈ Ω minU∈Hv [∑ u∈U OPT(u) + L(v, U) ] v ∈ V − Ω (3)\nsuch that these two conditions hold: (1) there exists k ∈ N such that |U | = k for all v and U ∈ Hv and (2) for all v, all U ’s in Hv are mutually exclusive. Note that L(v, U) : V × 2V → R+ and LΩ(v) : V → R+ encode the given loss function into dynamic programming recurrence relation. Also observe that every object can be recovered by choosing the “right” sequence of U ’s as we go through the recurrence relation.\nNow construct the online version of problem P – denoted by Ponline – by allowing the loss function to be changing over trials t = 1 . . . T . Concretely, instead of L(v, U) we use Lt(v, U) to reflect the online-ness of the problem. In each trial, the online algorithm predicts (perhaps randomly) with a combinatorial object recognized by problem P . Then the adversary reveals the structured loss vector which can be encoded to function Lt(v, U) according to the underlying dynamic programming algorithm. The goal is to minimize regret over the trials t = 1 . . . T .\n3D is usually in terms of k and |V |. 4Later in Appendix A we will provide maximization examples which can be solved with the same approach.\nReduction to Online Learning of k-Multipaths The dependency relations among the subproblems in dynamic programming algorithm can be encoded as a k-regular DAG G which can be constructed as follows. For each subproblem v ∈ V create a vertex. In particular set the source node s ∈ V and the set of sink nodes Ω ⊂ V to be the original problem (i.e. P) and the set of base/primitive subproblems, respectively. For every v ∈ V − Ω, for all U ∈ Hv and for all u ∈ U , draw an edge e = (v, u) with loss `e = 1k (Lt(v, U) + ∑ u∈U∩Ω LΩ(u)), that is, uniformly distribute\nthe “transition” loss Lt(v, U) and “end” loss ∑ u∈U∩Ω LΩ(u) to all edges from v to the members of U . Finally, for each v ∈ V − Ω, form the k-tuples out of the outgoing edges Ev according to Hv. Concretely Fv := { Ẽ | ∃U ∈ Hv s.t. Ẽ = {(v, u)|u ∈ U}\n} Every combinatorial object is a k-multipath π sourced at s with sinks in Ω. Moreover, the loss of that object is π · `. Now if the given loss function of the problem is in such way that `e ∈ [0, 1], we can apply both algorithms CH and EH and their corresponding regret guarantees in Theorems 3 and 4, respectively 5."
    }, {
      "heading" : "5 Online Learning of Binary Search Trees",
      "text" : "As an instantiation, let us now apply our method on an interesting combinatorial object recognized by dynamic programming. See Appendix A for more examples. Consider the online version of optimal binary search tree problem [6]. Concretely, we are given a sequence of n distinct keys K1 < K2 < . . . < Kn to build a binary search tree (BST). Moreover, we are also given n + 1 “dummy keys” D0, . . . , Dn indicating search failures and for all i ∈ [n] we have Di−1 < Ki < Di. In each trial t, the algorithm predicts with a BST γ(t). Then the adversary reveals the a probability vector `(t) = (p(t), q(t)) with p(t) ∈ [0, 1]n, q(t) ∈ [0, 1]n+1 and ∑n i=1 p (t) i + ∑n i=0 q (t) i = 1. For each i, p(t)i and q (t) i are the search probabilities for Ki and Di, respectively. The loss is defined as the expected cost of a search in the BST γ which is basically average depth 6 of the nodes in the BST:\nloss(t)γ = n∑ i=1 depthγ(Ki) · p (t) i + n∑ j=0 depthγ(Dj) · q (t) i"
    }, {
      "heading" : "5.1 Challenges of the Original Space",
      "text" : "As the loss is linear in terms of the depths of the keys in BST, it may sound natural to work with the space of depth sequences of the keys. Concretely, let γ ∈ N2n+1 be the vector of the depths of Ki’s and Dj’s of a BST. Now consider the convex hull of all γ’s in this space. To our knowledge, there is no well-known characterization of this polytope and we believe, if there is one, it will probably have exponentially many facets. This makes it impossible to directly apply CH-like algorithms to this problem in the original space. Furthermore, the algorithm of Suehiro et. al. [20] does not apply to this problem as the polytope is not a subset of a simplex, and consequently, cannot be characterized as submodular base polytope. Nevertheless, one can apply Follow the Perturbed Leader (FPT) [13] to this problem. Note that the expected search cost is bounded by B = n in each trial. Since ‖`(t)‖1 = 1 and ‖γ − γ′‖ < cn2 for some c, then we can obtain the regret bound below:\nE[LFPL]− L∗ ≤ 2 √ c n 3 2 √ T"
    }, {
      "heading" : "5.2 The Dynamic Programming Game",
      "text" : "We now go over the modules of the underlying dynamic programming game. We use the prefix “DP-” in our abbreviations to emphasize the use of the algorithm in the context of dynamic programming game rather than the original space. The optimal BST problem can be solved via dynamic\n5It is fairly straight-forward to see if `e ∈ [0, b] for some b, the regret bounds for CH and EH will scale up accordingly.\n6We assume the root has depth 1.\nprogramming [6] with the recurrence relation below:\nOPT(i, j) = { qi−1 j = i− 1 mini≤r≤j{OPT(i, r − 1) + OPT(r + 1, j) + ∑j a=i p (t) a + ∑j a=i−1 q (t) a } i ≤ j (4) in which OPT(i, j) indicates the expected search cost of optimal BST given the keys Ki, . . . ,Kj and dummy keys Di−1, . . . , Dj . Note that given the recurrence relation (4), we have k = 2 and s = (1, n). Moreover:\nV = {(i, j)|1 ≤ i ≤ n+ 1, i− 1 ≤ j ≤ n}, Ω = {(i, j)|j = i− 1} F(i,j) = {{((i, j), (i, r − 1)) , ((i, j), (r + 1, j))} | i ≤ r ≤ j}\nNote that the loss associated with each 2-tuple is upper-bounded by ∑n i=1 p (t) i + ∑n i=0 q (t) i = 1. Figure 2 illustrates the underlying 2-regular DAG and 2-multipaths associated with BSTs.\nRegret Bound It is well-known that the number of binary trees with n nodes is the nth Catalan number [6]. Therefore N = (2n)!n!(n+1)! ∈ (2\nn, 4n). Also note that the expected search cost is bounded by B = n in each trial. Thus using Theorem 3 we obtain:\nE[LDP-EH]− L∗ ≤ √ 2 ln(4)n 3 2 √ T + n2 ln(4)\nAdditionally, notice that each 2-multipath associated with a BST consists of exactly D = 2n edges. Also we have |V | = (n+1)(n+2)2 . Therefore using Theorem 4 we obtain:\nE[LDP-CH]− L∗ ≤ 4 √ 2n (log n) 1 2 √ T + 16n log n"
    }, {
      "heading" : "6 Conclusions and Future Work",
      "text" : "We developed a general framework for online learning of combinatorial objects whose offline optimization problems can be efficiently solved via a large class of dynamic programming algorithms.\nSeveral examples of such objects are discussed in the main body and Appendix of this paper. Table 1 shows the performance of EH and CH in our framework (denoted by the prefix “DP-”) on different problems. See the Appendix A for more details.\nIn Expanded Hedge, projections are exact (i.e. renormalizing a weight vector). In contrast, iterative Bregman projections are often used for algorithms like Component Hedge [12, 15]. These methods are known to converge to the exact projection theoretically [4, 5] and are reported to be empirically very efficient [15]. However, the iterative nature of the projection step necessitates an analysis such as the one in Appendix E to bound the additional loss incurred due to stopping short of full convergence.\nThere are still several instances that are not included in our class of dynamic programming algorithms. The notable examples of such dynamic programming algorithms are Viterbi algorithm for finding the most probable path in a graph, and variants of Cocke-Younger-Kasami (CYK) algorithm for parsing for stochastic context-free grammars. Extending our method to these dynamic programming algorithms can be an active area of future work."
    }, {
      "heading" : "Acknowledgments",
      "text" : "Holakou Rahmanian and Manfred K. Warmuth have been supported by NSF grant IIS-1619271."
    }, {
      "heading" : "A More Instantiations",
      "text" : "We apply our method on a few more instances of combinatorial objects recognized by dynamic programming .\nA.1 Matrix Chain Multiplication\nAssume a sequence A1, A2, . . . , An of n matrices to be multiplied and our goal is to compute the product A1 × A2 × . . . × An. Using the standard algorithm for multiplying pairs of matrices as a subroutine, we can find this product by a full parenthesizing which basically specifies the order which the matrices are multiplied together. Concretely, we say a product of matrices is fully parenthesized if it is either a single matrix or the multiplication of two fully parenthesized matrix products, surrounded by parentheses. For instance, there are five distinct ways of fully parenthesizing the product A1A2A3A4:\n(A1(A2(A3A4)))\n(A1((A2A3)A4))\n((A1A2)(A3A4))\n(((A1A2)A3)A4)\n((A1(A2A3))A4)\nNow consider the following online version of matrix-chain multiplication problem [6]. We are given a chain A1, A2, . . . , An of n matrices where for each i ∈ [n]. In each trial t, the algorithms predicts with a full parenthesizing of the product A1 ×A2 × . . .×An. Then the adversary reveals the dimensions of each Ai at trial t denoted by m (t) i−1 ×m (t) i . The loss is defined as the number of scalar multiplications in the matrix-chain product.\nThe Dynamic Programming Game We now go over the modules of the underlying dynamic programming game. The matrix-chain multiplication problem can be solved via dynamic programming [6] with the recurrence relation below:\nOPT(i, j) =\n{ 0 i = j\nmini≤k<j{OPT(i, k) + OPT(k + 1, j) +m(t)i−1m (t) k m (t) j } else\n(5)\nin which OPT(i, j) indicates minimum loss of the matrix product Ai . . . Aj . Note that given the recurrence relation (8), we have k = 2 and s = (1, n). The DAG G has the following properties:\nV = {(i, j)|1 ≤ i ≤ j ≤ n}, Ω = {(i, i)|1 ≤ i ≤ n} F(i,j) = {{((i, j), (i, k)) , ((i, j), (k + 1, j))} | i ≤ r ≤ j}\nAssuming that m(t)i < M for all i ∈ [n] and all t ∈ [T ], note that the loss associated with each 2-tuple is upper-bounded by M3. Figure 3 illustrates the underlying 2-regular DAG and 2-multipaths associated with full parenthesizing.\nRegret Bound It is well-known that the number of full parenthesizing of a sequence of n matrices is the nth Catalan number [6]. Therefore N = (2n)!n!(n+1)! ∈ (2\nn, 4n). Also note that the number of scalar multiplications in each full parenthesizing is bounded by B = (n− 1)M3 in each trial. Thus using Theorem 3 we obtain:\nE[LDP-EH]− L∗ = O(n 3 2 M3 √ T ) (6)\nAdditionally, notice that each 2-multipath associated with a full parenthesizing consists of exactly D = 2(n− 1) edges. Also we have |V | = n(n+1)2 . Therefore using Theorem 4 we obtain:\nE[LDP-CH]− L∗ = O(n (log n) 1 2 M3 √ T ) (7)\nA.2 Knapsack\nConsider the online version of knapsack problem [14]. Concretely, we are given a set of n items along with their weight/heaviness as a vector h ∈ Nn as well as the capacity of the knapsack C ∈ N. In each trial t, the algorithm predicts with a packing γ(t−1) ∈ {γ ∈ {0, 1}n|h · γ ≤ C} i.e. a subset of items whose total weight is at most the capacity of the knapsack. To make the problem interesting, we assume C and h are in such way that the number of feasible packings is O(2n). Then the adversary reveals a profit vector p(t) ∈ [0, 1]n in which the ith component – p(t)i – is the profit of the ith item at trial t. The gain is defined as the sum of the profits of the items in the knapsack which is γ(t−1) · p(t).\nChallenges of the Original Space As the gain is linear in the space of γ’s, it may sound natural to work with this space. Now consider the convex hull of {γ ∈ {0, 1}n|h · γ ≤ C}. To our knowledge, there is no well-known characterization of this polytope and we believe, if there is one, depending on C and h, it may have exponentially many facets. This makes it impossible to directly apply CH-like algorithms to this problem in the original space. Furthermore, the algorithm of Suehiro et. al. [20] does not apply to this problem as the polytope is not a subset of a simplex, and consequently, cannot be characterized as submodular base polytope.\nNevertheless, one can apply Follow the Perturbed Leader (FPT) [13] to this problem. Note that the profit is bounded by B = n in each trial. Since ‖`(t)‖1 ≤ n and ‖γ − γ′‖ ≤ n, then we can obtain the regret bound below:\nE[LFPL]− L∗ ≤ 2n 3 2 √ T\nThe Dynamic Programming Game We now go over the modules of the underlying dynamic programming game. The knapsack problem can be solved via dynamic programming [14] with the recurrence relation below:\nOPT(i, c) =  0 i = 0\nOPT(i− 1, c) c < hi max{OPT(i− 1, c), p(t)i + OPT(i− 1, c− hi)} else\n(8)\nin which OPT(i, c) indicates maximum profit given items 1, . . . , i and capacity c. Note that given the recurrence relation (8), we have k = 1 and s = (n,C). The DAG G has the following properties:\nV = {(i, c)|0 ≤ i ≤ n, 0 ≤ c ≤ C}, Ω = {(0, c)|0 ≤ c ≤ C} F(i,c) = {{((i, c), (i− 1, c))} , {((i, c), (i− 1, c− hi))}}\nThis is basically the online longest-path problem with several sink nodes. Note that the gain associated with each edge is upper-bounded by 1. Figure 4 illustrates the underlying DAG and paths associated with packings. We turn the problem into shortest-path problem by defining a loss for each edge e ∈ E as `e = 1− ge in which ge is the gain of e obtained from (8). Call this new DAG Ḡ. Observe that since all the paths contain n edges, the loss of each path π in Ḡ (denoted by LḠ) is directly connected to the gain of π in G (denoted by GG) by LḠ(π) = n−GG(π).\nRegret Bounds According to our initial assumption N = O(2n). Also note that loss of each path in each trial is bounded by B = n. Thus using Theorem 3 we obtain:\nG∗ − E[GDP-EH] = (nT − L∗)− (nT − E[LDP-EH]) = E[LDP-EH]− L∗\n= O(n 32 √ T )\nNotice that the number of vertices is |V | = nC and each path consists of D = n edges. Therefore using Theorem 4 we obtain:\nG∗ − E[GDP-CH] = (nT − L∗)− (nT − E[LDP-CH]) = E[LDP-CH]− L∗\n= O(n (log nC) 12 √ T )\nA.3 Rod Cutting\nConsider the online version of rod cutting problem [6]. A rod of length n is given. In each trial t, the algorithm predicts with a cutting γ(t−1), that is, it cuts up the rod into pieces. Mathematically speaking, γ(t−1) ∈ {γ ∈ Nn|γ · [1, 2, . . . , n] = n}. Then the adversary reveals a price vector p(t) ∈ [0, 1]n in which the ith component – p(t)i – is the price of the piece of length i at trial t. The gain is defined as the total sales in the trial which is γt−1 · pt. See Figure 5 as an example.\nChallenges of the Original Space As the gain is linear in the space of γ’s, it may sound natural to work with this space. Now consider the convex hull of {γ ∈ Nn|γ · [1, 2, . . . , n] = n}. To our knowledge, there is no well-known characterization of this polytope and we believe, if there is one, it will probably have exponentially many facets. This makes it impossible to directly apply CH-like algorithms to this problem in the original space. Furthermore, the algorithm of Suehiro et. al. [20] does not apply to this problem as the polytope is not a subset of a simplex, and consequently, cannot be characterized as submodular base polytope.\nNevertheless, one can apply Follow the Perturbed Leader (FPT) [13] to this problem. Note that the profit is bounded by B = n in each trial. Since ‖`(t)‖1 ≤ n and ‖γ − γ′‖ ≤ n, then we can obtain the regret bound below:\nE[LFPL]− L∗ ≤ 2n 3 2 √ T\nThe Dynamic Programming Game We now go over the modules of the underlying dynamic programming game. The rod cutting problem can be solved via dynamic programming [6] with the recurrence relation below:\nOPT(i) =\n{ 0 i = 0\nmax0≤j≤i{OPT (j) + p(t)j−i} i > 0 (9)\nin which OPT(i) indicates maximum profit given a rod of length i. Note that given the recurrence relation (9), we have k = 1 and s = n. The DAG G has the following properties:\nV = {i|0 ≤ i ≤ n}, Ω = {0} Fi = {{(i, j)} |0 ≤ j ≤ i}\nThis is basically the online longest-path problem with one sink node. Note that the gain associated with each edge is upper-bounded by 1. Figure 6 illustrates the underlying DAG and paths associated with cuttings. Similar to the knapsack problem, we turn this problem into shortest-path problem as well. In order to do so, we first need to modify the graph in a way that all paths have equal length of n (the length of the longest path) and the gain of each path remains fixed. Using the technique introduced in György et. al. [11], we can add O(n2) vertices and edges (with gain zero) to make all paths equi-length. Then, we define a loss for each edge e as `e = 1− ge in which ge is the gain of e. Call this new DAG Ḡ. Similar to the knapsack problem, we have LḠ(π) = n−GG(π) for all paths π.\nRegret Bounds Note that in both G and Ḡ, there are N = 2n−1 paths. Also note that loss of each path in each trial is bounded by B = n. Thus using Theorem 3 we obtain 7\nG∗ − E[GDP-EH] = (nT − L∗)− (nT − E[LDP-EH]) = E[LDP-EH]− L∗\n= O(n 32 √ T )\nNotice that the number of vertices in Ḡ is O(n2) and each path consists of D = n edges. Therefore using Theorem 4 we obtain:\nG∗ − E[GDP-CH] = (nT − L∗)− (nT − E[LDP-CH]) = E[LDP-CH]− L∗\n= O(n (log n) 12 √ T )\n7We are over-counting the number of cuttings. The number of possible cutting is called partition function which is approximately eπ √ 2n/3/4n √ 3 [6]. Thus if we naively apply EH algorithm in an inefficient way, we will get better regret bound by a factor of 4 √ n.\nA.4 Weighted Interval Scheduling\nConsider the online version of weighted interval scheduling problem [14]. We are given a set of n intervals I1, . . . , In on the real line. In each trial t, the algorithm predicts with a scheduling γ(t−1) ∈ {0, 1}n, that is a subset of non-overlapping intervals. Then the adversary reveals a profit vector p(t) ∈ [0, 1]n in which the ith component – p(t)i – is the profit of including Ii in the scheduling at trial t. The gain is defined as the total profit over chosen intervals in the scheduling in the trial which is γt−1 · pt. See Figure 7 as an example.\nChallenges of the Original Space As the gain is linear in the space of γ’s, it may sound natural to work with this space. Now consider the convex hull of {γ ∈ {0, 1}n|intervals i withγi = 1 don’t overlap}. To our knowledge, there is no well-known characterization of this polytope and we believe, if there is one, depending on the given intervals, it may have exponentially many facets. This makes it impossible to directly apply CH-like algorithms to this problem in the original space. Furthermore, the algorithm of Suehiro et. al. [20] does not apply to this problem as the polytope is not a subset of a simplex, and consequently, cannot be characterized as submodular base polytope.\nNevertheless, one can apply Follow the Perturbed Leader (FPT) [13] to this problem. Note that the profit is bounded by B = n in each trial. Since ‖`(t)‖1 ≤ n and ‖γ − γ′‖ < n, then we can obtain the regret bound below:\nE[LFPL]− L∗ ≤ 2n 3 2 √ T\nThe Dynamic Programming Game We now go over the modules of the underlying dynamic programming game. The weighted interval scheduling problem can be solved via dynamic programming [14]. Defining OPT(i) as the maximum profit given the intervals I1, . . . , Ii, the recurrence relation below holds:\nOPT(i) =\n{ 0 i = 0\nmax{OPT(i− 1),OPT(pred(i)) + p(t)i } i > 0 (10)\nin which\npred(i) := { 0 i = 1\nmax{j<i, Ii∩Ij=∅} j i > 1\nNote that given the recurrence relation (10), we have k = 1 and s = n. The DAG G has the following properties:\nV = {i|0 ≤ i ≤ n}, Ω = {0} Fi = {{(i, i− 1)} , {(i, pred(i))}}\nSimilar to rod cutting, this is also the online longest-path problem with one sink node. Note that the gain associated with each edge is upper-bounded by 1. Figure 8 illustrates the underlying DAG and paths associated with scheduling. Like the rod cutting problem, we modify the graph by adding O(n2) vertices and edges (with gain zero) to make all paths equi-length and change the gains into losses. Call this new DAG Ḡ. Again we have LḠ(π) = n−GG(π) for all paths π.\nRegret Bounds According to our initial assumption N = O(2n). Also note that loss of each path in each trial is bounded by B = n. Thus using Theorem 3 we obtain:\nG∗ − E[GDP-EH] = (nT − L∗)− (nT − E[LDP-EH]) = E[LDP-EH]− L∗\n= O(n 32 √ T )\nNotice that the number of vertices in Ḡ is O(n2) and each path consists of D = n edges. Therefore using Theorem 4 we obtain:\nG∗ − E[GDP-CH] = (nT − L∗)− (nT − E[LDP-CH]) = E[LDP-CH]− L∗\n= O(n (log n) 12 √ T )"
    }, {
      "heading" : "B Generalized Weight Pushing Correctness",
      "text" : "Lemma 5. The weights w(t) Ẽ generated by the generalized weight pushing satisfies the Φ properties and W (t)π ∝ ∏ Ẽ∈F (ŵ (t) Ẽ )πẼ . Moreover, the weights w(t) Ẽ can be computed in O(|E|) time.\nProof For all v ∈ V , Zv is defined as the normalization constant if v was the source in G. Concretely, let Pv be the set of all k-multipaths sourced from v and sinking at Ω. Then:\nZv = ∑ πv∈Pv W (t−1)πv exp [ −ηπv · `(t) ] For a sink node v ∈ Ω, the normalization constant is vacuously 1 since no normalization is needed. For other v ∈ V − Ω, we partition the summation by the starting k-tuple from v:\nZv = ∑ πv∈Pv W (t−1)πv exp [ −ηπv · `(t) ] = ∑ Ẽ∈Fv ∑ πv∈Pv\nstarts with Ẽ\nW (t−1)πv exp [ −ηπv · `(t) ]\nNow, we can factor out the weight and exponentiated loss associated with Ẽ ∈ Fv . Notice, excluding Ẽ from the k-multipath, we are left with k number of k-multipaths from all u’s such that (v, u) ∈ Ẽ:\nZv = ∑ Ẽ∈Fv ∑ πv∈Pv\nstarts with Ẽ\nW (t−1)πv exp [ −ηπv · `(t) ]\n= ∑ Ẽ∈Fv ( w (t−1) Ẽ )πẼ exp −η πẼ∑ e∈Ẽ `(t)e  ︸ ︷︷ ︸\nŵ (t)\nẼ\n∑ {πu}u:(v,u)∈Ẽ\ns.t.∀uπu∈Pu\n∏ u:(v,u)∈Ẽ W (t−1)πu exp [ −ηπu · `(t) ]\nObserve that since the πu’s are independent for different u’s, we can turn the sum of products into product of sums:\nZv = ∑ Ẽ∈Fv ( w (t−1) Ẽ )πẼ exp −η πẼ∑ e∈Ẽ `(t)e  ︸ ︷︷ ︸\nŵ (t)\nẼ\n∑ {πu}u:(v,u)∈Ẽ\ns.t.∀uπu∈Pu\n∏ u:(v,u)∈Ẽ W (t−1)πu exp [ −ηπu · `(t) ]\n= ∑ Ẽ∈Fv ŵ (t) Ẽ ∏ u:(v,u)∈Ẽ ∑ πu∈Pu W (t−1)πu exp [ −ηπu · `(t) ] ︸ ︷︷ ︸\nZu = ∑ Ẽ∈Fv ŵ (t) Ẽ ∏ u:(v,u)∈Ẽ Zu\nNow for each v ∈ V − Ω, for all Ẽ ∈ Fv, set w(t)Ẽ := ŵ (t) Ẽ\n∏ u:(v,u)∈Ẽ Zu\nZv and let W (t)π :=∏\nẼ∈F (w (t) Ẽ )πẼ . Φ1 becomes immediately true because of the definition of W (t) π . Φ2 is also\ntrue since: ∑ Ẽ∈Fv w (t) Ẽ = ∑ Ẽ∈Fv ŵ (t) Ẽ ∏ u:(v,u)∈Ẽ Zu Zv\n= 1\nZv ∑ Ẽ∈Fv ŵ (t) Ẽ ∏ u:(v,u)∈Ẽ Zu\n= 1\nZv × Zv = 1\nFor W (t)π , we can write :\nW (t)π = ∏ Ẽ∈F (w (t) Ẽ )πẼ = ∏ v∈V−Ω ∏ Ẽ∈Fv (w (t) Ẽ )πẼ\n= ∏\nv∈V−Ω ∏ Ẽ∈Fv\n( ŵ (t)\nẼ\n∏ u:(v,u)∈Ẽ Zu\nZv\n)πẼ\n=  ∏ v∈V−Ω ∏ Ẽ∈Fv ( ŵ (t) Ẽ )πẼ  ∏ v∈V−Ω ∏ Ẽ∈Fv (∏ u:(v,u)∈Ẽ Zu Zv )πẼ\nNotice that ∏ v∈V−Ω ∏ Ẽ∈Fv (∏ u:(v,u)∈Ẽ Zu Zv )πẼ telescopes along the k-tuples in the k-multipath. Therefore we obtain:\nW (t)π =  ∏ v∈V−Ω ∏ Ẽ∈Fv ( ŵ (t) Ẽ )πẼ  ∏ v∈V−Ω ∏ Ẽ∈Fv (∏ u:(v,u)∈Ẽ Zu Zv )πẼ =\n∏ Ẽ∈F ( ŵ (t) Ẽ )πẼ [∏v∈Ω Zv Zs ]\n= 1\nZs ∏ Ẽ∈F ( ŵ (t) Ẽ )πẼ\nwhich indicates that W (t)π ∝ ∏ Ẽ∈F (ŵ (t)\nẼ )πẼ . Finally Φ3 is true as well because:∑\nπ\nW (t)π = 1\nZs ∏ Ẽ∈F ( ŵ (t) Ẽ )πẼ = 1\nZs × Zs = 1\nRegarding the time complexity, we first focus on the the recurrence relation Zv =∑ Ẽ∈Fv ŵ (t) Ẽ ∏ u:(v,u)∈Ẽ Zu. Note that for each v ∈ V , Zv can be computed in O(|Ev|) in which Ev is the set of out-going edges from v. Thus the computation of all Zv’s takes O(|E|) time. Now observe that w(t)\nẼ for each Ẽ ∈ F can be found inO(k) time using w(t) Ẽ = ŵ (t) Ẽ\n∏ u:(v,u)∈Ẽ Zu\nZv . Hence\nthe computation of all w(t) Ẽ ’s takes O(|E|) time since |F| × k = |E|. Therefore the generalized weight pushing algorithm runs in O(|E|).\nC Relative Entropy Projection to k-Flow Polytope\nFormally, the projection w of a given point ŵ to constraint C is the solution to the following:\narg min w∈C ∑ e∈E w log ( we ŵe ) + ŵe − we\nC can be three different constraints. We use the method of Lagrange multipliers in all three cases. Observe that if k = 1, then the third constraint is non-existent and the updates in Koolen et. al. [15] are recovered.\nC.1 Root Outflow\nThe outflow from the root r must be k. Assume wr1 , . . . , wrs are the weights associated with the outgoing edges from the root. Then:\nL(w, λ) := ∑ e∈E we log ( we ŵe ) + ŵe − we − λ  s∑ j=1 wrj − k  ∂L ∂we = log we ŵe = 0 −→ we = ŵe ∀e ∈ E − {r1, . . . , rs}\n∂L\n∂wrj = log wrj ŵrj − λ = 0 −→ wrj = ŵrj exp(λ) (11)\n∂L ∂λ = s∑ j=1 wrj − k = 0 (12)\nCombining equations (11) and (12) results in normalizing wr1 , . . . , wrs , that is:\n∀j ∈ [s] wrj = k ŵrj∑s j′=1 ŵrj′\nC.2 k-Flow Preservation at Node v\nGiven any node v other than the root, the out-flow from the node v must be k times of the in-flow of that node. Assume w(in)v1 , . . . , w (in) va and w (out) v1 , . . . , w (out) vb are the weights associated with the\nincoming and outgoing edges from/to the node v, respectively. Then:\nL(w, λ) := ∑ e∈E w log ( we ŵe ) + ŵe − we − λ ( b∑ b′=1 w(out)vb′ − k a∑ a′=1 w(in)va′ ) ∂L ∂we = log we ŵe = 0 −→ we = ŵe ∀e non-adjacent to v\n∂L\n∂w (out) vb′\n= log w\n(out) vb′ ŵ (out) vb′ − λ = 0 −→ w(out)vb′ = ŵ (out) vb′ exp(λ) ∀b′ ∈ [b] (13)\n∂L\n∂w (in) va′\n= log w\n(in) va′ ŵ (in) va′ + kλ = 0 −→ w(in)va′ = ŵ (in) va′ exp(−kλ) ∀a′ ∈ [a] (14)\n∂L ∂λ = b∑ b′=1 w(out)vb′ − k a∑ a′=1 w(in)va′ = 0 (15)\nLetting β = exp(k), for all a′ ∈ [a] and all b′ ∈ [b], we can obtain the following by combining equations (13), (14) and (15):\nβ\n( b∑\nb′=1\nŵ(out)vb′\n) = k\nβk\n( a∑\na′=1\nŵ(in)va′\n) −→ β = k+1 √√√√k ∑aa′=1 ŵ(in)va′∑b b′=1 ŵ (out) vb′\nw(out)vb′ = ŵ (out) vb′\n( k ∑a a′′=1 ŵ\n(in) va′′∑b\nb′′=1 ŵ (out) vb′′\n) 1 k+1\n, w(in)va′ = ŵ (in) va′\n( 1\nk\n∑b b′′=1 ŵ\n(out) vb′′∑a\na′′=1 ŵ (in) va′′\n) k k+1\nThis indicates that to enforce the k-flow property at each node, the weights must be multiplicatively scaled up/down so that the out- and in-flow will be proportionate to the k-to-1 weighted geometric average of the out- and in-flow, respectively. Concretely:\nout-flow = k × in-flow = k+1 √ k ( ̂out-flow)k ( ̂in-flow)\nC.3 k-Tuple Equality\nLet F be the set of all k-tuples of edges the components of which must have equal weights. For a given tuple J ∈ F , let w(J)0 , . . . , w (J) k−1 be the weights. Assuming j\n− = j − 1(mod k) and j+ = j + 1(mod k) ,then:\nL(w, λ) := ∑ e∈E we log ( we ŵe ) + ŵe − we − ∑ J∈F k−1∑ j=0 λ (J) j (w (J) j − w (J) j− )\n∂L\n∂w (J) j\n= log w\n(J) j\nŵ (J) j\n− λ(J)j + λ (J) j+ = 0 −→ w (J) j = ŵ (J) j\neλ (J) j\ne λ (J) j+\n∀j ∈ {0, 1, . . . , k − 1} (16)\n∂L\n∂λ (J) j\n= w (J) j − w (J) j− = 0 −→ w (J) j = w (J) j− ∀j ∈ {0, 1, . . . , k − 1} (17)\nCombining equations (16) and (17), for all J ∈ F and for all j ∈ J , we can obtain:\n( w\n(J) j\n)k = k−1∏ j′=0 w (J) j′ = k−1∏ j′=0 ŵ (J) j′ −→ w (J) j = k √√√√k−1∏ j′=0 ŵ (J) j′\nwhich basically indicates that each weight must be assigned to the geometric average of the weights in its tuple.\nD CH Regret Bound on k-Multipaths\nProof According to Koolen, Warmuth and Kivinen [15], the regret bound of CH is: E[LCH]− L∗ ≤ √ 2L∗∆(π||w(0)) + ∆(π||w(0)) (18)\nin which π ∈ N|E| and L∗ are the best k-multipath and its loss, respectively. Let w̃(0) = 1|V |2 1 in which 1 ∈ R|E| is a vector of all ones. Now let the initial pointw(0) be the relative entropy projection of w̃(0) onto the k-flow prolytope8\nw(0) = arg min w∈P ∆(w||w̃(0))\nAssuming ‖π‖1 ≤ D ≤ |E|, we obtain:\n∆(π||w(0)) ≤ ∆(π||w̃(0)) Pythagorean Theorem = ∑ e∈E πe log πe w̃ (0) i + w̃ (0) i − πe\n= ∑ e∈E πe log 1 w̃ (0) i + πe log πe + w̃ (0) i − πe\n≤ ∑ e∈E πe(2 log |V |) + ∑ e∈E πe log πe + ∑ e∈E 1 |V |2 − ∑ e∈E πe (19)\n≤ D(2 log |V |) +D logD + |E| 1 |V |2 − ∑ e∈E πe\n≤ 4D log |V |\nThus, using inequality (18), the regret bound will be: E[LCH]− L∗ ≤ √ 8L∗D log |V |+ 4D log |V |\nNote that if ‖π‖∞ = 1, then ∑ e∈E πe log πe = 0, and consequently, the expression (19) can be bound as below:\n∆(π||w(0)) ≤ ∑ e∈E πe(2 log |V |) + ∑ e∈E πe log πe + ∑ e∈E 1 |V |2 − ∑ e∈E πe\n≤ D(2 log |V |) + |E| 1 |V |2 − ∑ e∈E πe\n≤ 2D log |V |\nAgain, using inequality (18), the regret bound will be: E[LCH]− L∗ ≤ √ 4L∗D log |V |+ 2D log |V |"
    }, {
      "heading" : "E Additional Loss with Approximate Projection",
      "text" : "First, let us define the notation . Given two vectors a and b, we say a b iff every element of a is less than or equal b.\nNow let us discuss approximate projection and additional loss. As we are working with in-exact projection, we propose a slightly different prediction algorithm for Component Hedge. Suppose, using iterative Bregman projections, we reached at ŵ ∈ R|F|+ which is -close to the exact projection w ∈ R|F|+ in 1-norm, that is ‖w − ŵ‖1 < . Then do the following steps for prediction:\n8This computation can be done as a pre-processing step.\n1. Set w̃ := ŵ + · 1 where 1 ∈ R|F|+ is a vector of all ones. 2. Apply decomposition procedure on w̃ and obtain Π. Since w̃ does not necessarily belongs\nto the polytope Ψ, the decomposition Π will not zero-out all the edges in w̃: w̃ ∑ π∈Π pπ · π = w̄\n3. Normalize and sample from decomposition Π.\nAccording to the definition, w̃ w. Thus w can be subtracted out from w̃ in the decomposition and we have w̄ w. Therefore:\nw w̄ w̃ = ŵ + · 1 (20)\nNow let z be the normalization constant for Π. Hence the expected prediction will be w̄/z. Note that since w̄ w and w ∈ Ψ, then z ≥ 1. Also notice that the weights of out-going k-tuple from the source s in w̃ are at most 2 greater than the ones in w which belongs to Φ. Thus the out-flow at s in w̃ is at most k + 2n . Therefore, since w̄ w̃, we have z ≤ 1 + 2nk . Now we establish a closeness property between the approximate projected vector and the expected prediction vector with approximate projection :\n‖w̄ z − ŵ‖1 ≤ ‖w̄ − ŵ‖1 + z − 1 z ‖w̄‖1\n≤ ‖w̄ − ŵ‖1 + 2n\nk ‖w̄‖1\n≤ |F|+ 2n k |F| = |F|(1 + 2n k ) (20)\nNext we establish closeness between the expected prediction vectors in exact and approximate projections:\n‖w̄ z −w‖1 ≤ ‖ w̄ z − ŵ‖1 + ‖ŵ −w‖1\n≤ |F|(1 + 2n k ) + = (1 + |F|+ 2n k |F|)\nNow we can compute the total expected loss using approximate projection:∥∥∥∥∥ T∑ t=1 w̄(t) z · `(t) ∥∥∥∥∥ 1 ≤ ∥∥∥∥∥ T∑ t=1 w(t) · `(t) ∥∥∥∥∥ 1 + ∥∥∥∥∥ T∑ t=1 ( w̄(t) z −w(t)) · `(t) ∥∥∥∥∥ 1\n≤ ∥∥∥∥∥ T∑ t=1 w(t) · `(t) ∥∥∥∥∥\n1\n+ T∑ t=1 ∥∥∥∥w̄(t)z −w(t) ∥∥∥∥ 2 · ∥∥∥`(t)∥∥∥ 2\n≤ ∥∥∥∥∥ T∑ t=1 w(t) · `(t) ∥∥∥∥∥\n1\n+ T × (1 + |F|+ 2n k |F|)×\n√ |F|\nSetting = 1 T (1+|F|+ 2nk |F|) √ |F| we add at most one unit to the expected cumulative loss with exact projection."
    } ],
    "references" : [ {
      "title" : "Improved bounds for online learning over the permutahedron and other ranking polytopes",
      "author" : [ "Nir Ailon" ],
      "venue" : "In AISTATS,",
      "citeRegEx" : "1",
      "shortCiteRegEx" : "1",
      "year" : 2014
    }, {
      "title" : "Regret in online combinatorial optimization",
      "author" : [ "Jean-Yves Audibert", "Sébastien Bubeck", "Gábor Lugosi" ],
      "venue" : "Mathematics of Operations Research,",
      "citeRegEx" : "2",
      "shortCiteRegEx" : "2",
      "year" : 2013
    }, {
      "title" : "Online linear optimization and adaptive routing",
      "author" : [ "Baruch Awerbuch", "Robert Kleinberg" ],
      "venue" : "Journal of Computer and System Sciences,",
      "citeRegEx" : "3",
      "shortCiteRegEx" : "3",
      "year" : 2008
    }, {
      "title" : "Legendre functions and the method of random bregman projections",
      "author" : [ "Heinz H Bauschke", "Jonathan M Borwein" ],
      "venue" : "Journal of Convex Analysis,",
      "citeRegEx" : "4",
      "shortCiteRegEx" : "4",
      "year" : 1997
    }, {
      "title" : "The relaxation method of finding the common point of convex sets and its application to the solution of problems in convex programming",
      "author" : [ "Lev M Bregman" ],
      "venue" : "USSR computational mathematics and mathematical physics,",
      "citeRegEx" : "5",
      "shortCiteRegEx" : "5",
      "year" : 1967
    }, {
      "title" : "Introduction to algorithms",
      "author" : [ "Thomas H.. Cormen", "Charles Eric Leiserson", "Ronald L Rivest", "Clifford Stein" ],
      "venue" : "MIT press Cambridge,",
      "citeRegEx" : "6",
      "shortCiteRegEx" : "6",
      "year" : 2009
    }, {
      "title" : "On-line learning algorithms for path experts with non-additive losses",
      "author" : [ "Corinna Cortes", "Vitaly Kuznetsov", "Mehryar Mohri", "Manfred Warmuth" ],
      "venue" : "In Conference on Learning Theory,",
      "citeRegEx" : "7",
      "shortCiteRegEx" : "7",
      "year" : 2015
    }, {
      "title" : "The price of bandit information for online optimization",
      "author" : [ "Varsha Dani", "Sham M Kakade", "Thomas P Hayes" ],
      "venue" : "In Advances in Neural Information Processing Systems,",
      "citeRegEx" : "8",
      "shortCiteRegEx" : "8",
      "year" : 2008
    }, {
      "title" : "A decision-theoretic generalization of on-line learning and an application to boosting",
      "author" : [ "Yoav Freund", "Robert E Schapire" ],
      "venue" : "Journal of computer and system sciences,",
      "citeRegEx" : "9",
      "shortCiteRegEx" : "9",
      "year" : 1997
    }, {
      "title" : "Solving combinatorial games using products, projections and lexicographically optimal bases",
      "author" : [ "Swati Gupta", "Michel Goemans", "Patrick Jaillet" ],
      "venue" : "arXiv preprint arXiv:1603.00522,",
      "citeRegEx" : "10",
      "shortCiteRegEx" : "10",
      "year" : 2016
    }, {
      "title" : "The on-line shortest path problem under partial monitoring",
      "author" : [ "András György", "Tamás Linder", "Gábor Lugosi", "György Ottucsák" ],
      "venue" : "Journal of Machine Learning Research,",
      "citeRegEx" : "11",
      "shortCiteRegEx" : "11",
      "year" : 2007
    }, {
      "title" : "Learning permutations with exponential weights",
      "author" : [ "David P Helmbold", "Manfred K Warmuth" ],
      "venue" : "The Journal of Machine Learning Research,",
      "citeRegEx" : "12",
      "shortCiteRegEx" : "12",
      "year" : 2009
    }, {
      "title" : "Efficient algorithms for online decision problems",
      "author" : [ "Adam Kalai", "Santosh Vempala" ],
      "venue" : "Journal of Computer and System Sciences,",
      "citeRegEx" : "13",
      "shortCiteRegEx" : "13",
      "year" : 2005
    }, {
      "title" : "Optimum follow the leader algorithm",
      "author" : [ "Dima Kuzmin", "Manfred K Warmuth" ],
      "venue" : "In Learning Theory,",
      "citeRegEx" : "16",
      "shortCiteRegEx" : "16",
      "year" : 2005
    }, {
      "title" : "The weighted majority algorithm",
      "author" : [ "Nick Littlestone", "Manfred K Warmuth" ],
      "venue" : "Information and computation,",
      "citeRegEx" : "17",
      "shortCiteRegEx" : "17",
      "year" : 1994
    }, {
      "title" : "Weighted automata algorithms. In Handbook of weighted automata, pages 213–254",
      "author" : [ "Mehryar Mohri" ],
      "venue" : null,
      "citeRegEx" : "18",
      "shortCiteRegEx" : "18",
      "year" : 2009
    }, {
      "title" : "Online decision-making in general combinatorial spaces",
      "author" : [ "Arun Rajkumar", "Shivani Agarwal" ],
      "venue" : "In Advances in Neural Information Processing Systems,",
      "citeRegEx" : "19",
      "shortCiteRegEx" : "19",
      "year" : 2014
    }, {
      "title" : "Online prediction under submodular constraints",
      "author" : [ "Daiki Suehiro", "Kohei Hatano", "Shuji Kijima", "Eiji Takimoto", "Kiyohito Nagano" ],
      "venue" : "In International Conference on Algorithmic Learning Theory,",
      "citeRegEx" : "20",
      "shortCiteRegEx" : "20",
      "year" : 2012
    }, {
      "title" : "Path kernels and multiplicative updates",
      "author" : [ "Eiji Takimoto", "Manfred K Warmuth" ],
      "venue" : "The Journal of Machine Learning Research,",
      "citeRegEx" : "21",
      "shortCiteRegEx" : "21",
      "year" : 2003
    }, {
      "title" : "Randomized online pca algorithms with regret bounds that are logarithmic in the dimension",
      "author" : [ "Manfred K Warmuth", "Dima Kuzmin" ],
      "venue" : "Journal of Machine Learning Research,",
      "citeRegEx" : "22",
      "shortCiteRegEx" : "22",
      "year" : 2008
    } ],
    "referenceMentions" : [ {
      "referenceID" : 8,
      "context" : "Our framework allows us to extend online learning algorithms like Hedge [9] and Component Hedge [15] to a significantly wider class of combinatorial objects than was possible before.",
      "startOffset" : 72,
      "endOffset" : 75
    }, {
      "referenceID" : 19,
      "context" : "Such work includes k-sets [22], permutations [1, 12, 23] and paths [3, 7, 11, 16, 21].",
      "startOffset" : 26,
      "endOffset" : 30
    }, {
      "referenceID" : 0,
      "context" : "Such work includes k-sets [22], permutations [1, 12, 23] and paths [3, 7, 11, 16, 21].",
      "startOffset" : 45,
      "endOffset" : 56
    }, {
      "referenceID" : 11,
      "context" : "Such work includes k-sets [22], permutations [1, 12, 23] and paths [3, 7, 11, 16, 21].",
      "startOffset" : 45,
      "endOffset" : 56
    }, {
      "referenceID" : 2,
      "context" : "Such work includes k-sets [22], permutations [1, 12, 23] and paths [3, 7, 11, 16, 21].",
      "startOffset" : 67,
      "endOffset" : 85
    }, {
      "referenceID" : 6,
      "context" : "Such work includes k-sets [22], permutations [1, 12, 23] and paths [3, 7, 11, 16, 21].",
      "startOffset" : 67,
      "endOffset" : 85
    }, {
      "referenceID" : 10,
      "context" : "Such work includes k-sets [22], permutations [1, 12, 23] and paths [3, 7, 11, 16, 21].",
      "startOffset" : 67,
      "endOffset" : 85
    }, {
      "referenceID" : 13,
      "context" : "Such work includes k-sets [22], permutations [1, 12, 23] and paths [3, 7, 11, 16, 21].",
      "startOffset" : 67,
      "endOffset" : 85
    }, {
      "referenceID" : 18,
      "context" : "Such work includes k-sets [22], permutations [1, 12, 23] and paths [3, 7, 11, 16, 21].",
      "startOffset" : 67,
      "endOffset" : 85
    }, {
      "referenceID" : 12,
      "context" : "Follow the Perturbed Leader (FPL) [13] is a simple algorithm which adds random perturbation to the cumulative loss of each component, and then predicts with the combinatorial object with minimum perturbed loss.",
      "startOffset" : 34,
      "endOffset" : 38
    }, {
      "referenceID" : 9,
      "context" : "to submodular base polytopes [10, 19, 20] are powerful generic techniques which keep track of component-wise weights in the convex hull of the objects for prediction.",
      "startOffset" : 29,
      "endOffset" : 41
    }, {
      "referenceID" : 16,
      "context" : "to submodular base polytopes [10, 19, 20] are powerful generic techniques which keep track of component-wise weights in the convex hull of the objects for prediction.",
      "startOffset" : 29,
      "endOffset" : 41
    }, {
      "referenceID" : 17,
      "context" : "to submodular base polytopes [10, 19, 20] are powerful generic techniques which keep track of component-wise weights in the convex hull of the objects for prediction.",
      "startOffset" : 29,
      "endOffset" : 41
    }, {
      "referenceID" : 8,
      "context" : "This graph representation allows us to extend both standard Hedge algorithm [9, 17] and Component Hedge to wide class of combinatorial objects like BST (see Section 5), Matrix-Chain Multiplication, Knapsack, Rod Cutting, and Weighted Interval Scheduling (see Appendix A).",
      "startOffset" : 76,
      "endOffset" : 83
    }, {
      "referenceID" : 14,
      "context" : "This graph representation allows us to extend both standard Hedge algorithm [9, 17] and Component Hedge to wide class of combinatorial objects like BST (see Section 5), Matrix-Chain Multiplication, Knapsack, Rod Cutting, and Weighted Interval Scheduling (see Appendix A).",
      "startOffset" : 76,
      "endOffset" : 83
    }, {
      "referenceID" : 14,
      "context" : "Perhaps the simplest algorithms in online learning are the well-known so-call “experts algorithms” like the Randomized Weighted Majority [17] or Hedge [9] algorithms.",
      "startOffset" : 137,
      "endOffset" : 141
    }, {
      "referenceID" : 8,
      "context" : "Perhaps the simplest algorithms in online learning are the well-known so-call “experts algorithms” like the Randomized Weighted Majority [17] or Hedge [9] algorithms.",
      "startOffset" : 151,
      "endOffset" : 154
    }, {
      "referenceID" : 18,
      "context" : "1 Learning Paths The online shortest path has been explored both in full information setting [15, 21] and various bandit settings [2, 3, 8, 11].",
      "startOffset" : 93,
      "endOffset" : 101
    }, {
      "referenceID" : 1,
      "context" : "1 Learning Paths The online shortest path has been explored both in full information setting [15, 21] and various bandit settings [2, 3, 8, 11].",
      "startOffset" : 130,
      "endOffset" : 143
    }, {
      "referenceID" : 2,
      "context" : "1 Learning Paths The online shortest path has been explored both in full information setting [15, 21] and various bandit settings [2, 3, 8, 11].",
      "startOffset" : 130,
      "endOffset" : 143
    }, {
      "referenceID" : 7,
      "context" : "1 Learning Paths The online shortest path has been explored both in full information setting [15, 21] and various bandit settings [2, 3, 8, 11].",
      "startOffset" : 130,
      "endOffset" : 143
    }, {
      "referenceID" : 10,
      "context" : "1 Learning Paths The online shortest path has been explored both in full information setting [15, 21] and various bandit settings [2, 3, 8, 11].",
      "startOffset" : 130,
      "endOffset" : 143
    }, {
      "referenceID" : 0,
      "context" : "Then, for each edge e ∈ E, the adversary reveals a loss `e ∈ [0, 1].",
      "startOffset" : 61,
      "endOffset" : 67
    }, {
      "referenceID" : 18,
      "context" : "1 Expanded Hedge on Paths Takimoto and Warmuth [21] developed an algorithmic approach, namely path kernels, to apply Expanded Hedge on path problem efficiently by exploiting the underlying structure of the paths.",
      "startOffset" : 47,
      "endOffset" : 51
    }, {
      "referenceID" : 15,
      "context" : "In each trial, the weight of each edge is updated multiplicatively by its associated exponentiated loss followed by normalization via weight pushing [18].",
      "startOffset" : 149,
      "endOffset" : 153
    }, {
      "referenceID" : 8,
      "context" : "The regret bound is similar to the one of the Hedge algorithm [9]:",
      "startOffset" : 62,
      "endOffset" : 65
    }, {
      "referenceID" : 18,
      "context" : "Theorem 1 (Takimoto-Warmuth [21]).",
      "startOffset" : 28,
      "endOffset" : 32
    }, {
      "referenceID" : 4,
      "context" : "To do projection, iterative Bregman projection [5] is used which basically enforces flow conservation at each node by setting input and output flow to their geometric average as it cycles through the vertices.",
      "startOffset" : 47,
      "endOffset" : 50
    }, {
      "referenceID" : 0,
      "context" : "Then, for each edge e ∈ E, the adversary reveals a loss ` e ∈ [0, 1].",
      "startOffset" : 62,
      "endOffset" : 68
    }, {
      "referenceID" : 15,
      "context" : "Generalized Weight Pushing For efficient normalization, we generalize the weight pushing algorithm [18] for k-multipaths.",
      "startOffset" : 99,
      "endOffset" : 103
    }, {
      "referenceID" : 8,
      "context" : "Regret Bound In order to use the regret bound of Expanded Hedge [9], we have to initialize W (0) to the uniform distribution.",
      "startOffset" : 64,
      "endOffset" : 67
    }, {
      "referenceID" : 4,
      "context" : "To do this projection, iterative Bregman projection [5] can be used which cycles through the constraints and project the point to each constraint iteratively.",
      "startOffset" : 52,
      "endOffset" : 55
    }, {
      "referenceID" : 5,
      "context" : "Denote V as the set of all subproblems v in dynamic programming which needs to be solved in order to eventually solve P iteratively in bottom-up fashion [6].",
      "startOffset" : 153,
      "endOffset" : 156
    }, {
      "referenceID" : 0,
      "context" : "Now if the given loss function of the problem is in such way that `e ∈ [0, 1], we can apply both algorithms CH and EH and their corresponding regret guarantees in Theorems 3 and 4, respectively 5.",
      "startOffset" : 71,
      "endOffset" : 77
    }, {
      "referenceID" : 5,
      "context" : "Consider the online version of optimal binary search tree problem [6].",
      "startOffset" : 66,
      "endOffset" : 69
    }, {
      "referenceID" : 0,
      "context" : "Then the adversary reveals the a probability vector ` = (p, q) with p ∈ [0, 1], q ∈ [0, 1] and ∑n i=1 p (t) i + ∑n i=0 q (t) i = 1.",
      "startOffset" : 72,
      "endOffset" : 78
    }, {
      "referenceID" : 0,
      "context" : "Then the adversary reveals the a probability vector ` = (p, q) with p ∈ [0, 1], q ∈ [0, 1] and ∑n i=1 p (t) i + ∑n i=0 q (t) i = 1.",
      "startOffset" : 84,
      "endOffset" : 90
    }, {
      "referenceID" : 17,
      "context" : "[20] does not apply to this problem as the polytope is not a subset of a simplex, and consequently, cannot be characterized as submodular base polytope.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 12,
      "context" : "Nevertheless, one can apply Follow the Perturbed Leader (FPT) [13] to this problem.",
      "startOffset" : 62,
      "endOffset" : 66
    }, {
      "referenceID" : 5,
      "context" : "programming [6] with the recurrence relation below:",
      "startOffset" : 12,
      "endOffset" : 15
    }, {
      "referenceID" : 5,
      "context" : "Regret Bound It is well-known that the number of binary trees with n nodes is the nth Catalan number [6].",
      "startOffset" : 101,
      "endOffset" : 104
    }, {
      "referenceID" : 11,
      "context" : "In contrast, iterative Bregman projections are often used for algorithms like Component Hedge [12, 15].",
      "startOffset" : 94,
      "endOffset" : 102
    }, {
      "referenceID" : 3,
      "context" : "These methods are known to converge to the exact projection theoretically [4, 5] and are reported to be empirically very efficient [15].",
      "startOffset" : 74,
      "endOffset" : 80
    }, {
      "referenceID" : 4,
      "context" : "These methods are known to converge to the exact projection theoretically [4, 5] and are reported to be empirically very efficient [15].",
      "startOffset" : 74,
      "endOffset" : 80
    }, {
      "referenceID" : 0,
      "context" : "References [1] Nir Ailon.",
      "startOffset" : 11,
      "endOffset" : 14
    }, {
      "referenceID" : 1,
      "context" : "[2] Jean-Yves Audibert, Sébastien Bubeck, and Gábor Lugosi.",
      "startOffset" : 0,
      "endOffset" : 3
    }, {
      "referenceID" : 2,
      "context" : "[3] Baruch Awerbuch and Robert Kleinberg.",
      "startOffset" : 0,
      "endOffset" : 3
    }, {
      "referenceID" : 3,
      "context" : "[4] Heinz H Bauschke and Jonathan M Borwein.",
      "startOffset" : 0,
      "endOffset" : 3
    }, {
      "referenceID" : 4,
      "context" : "[5] Lev M Bregman.",
      "startOffset" : 0,
      "endOffset" : 3
    }, {
      "referenceID" : 5,
      "context" : "[6] Thomas H.",
      "startOffset" : 0,
      "endOffset" : 3
    }, {
      "referenceID" : 6,
      "context" : "[7] Corinna Cortes, Vitaly Kuznetsov, Mehryar Mohri, and Manfred Warmuth.",
      "startOffset" : 0,
      "endOffset" : 3
    }, {
      "referenceID" : 7,
      "context" : "[8] Varsha Dani, Sham M Kakade, and Thomas P Hayes.",
      "startOffset" : 0,
      "endOffset" : 3
    }, {
      "referenceID" : 8,
      "context" : "[9] Yoav Freund and Robert E Schapire.",
      "startOffset" : 0,
      "endOffset" : 3
    }, {
      "referenceID" : 9,
      "context" : "[10] Swati Gupta, Michel Goemans, and Patrick Jaillet.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 10,
      "context" : "[11] András György, Tamás Linder, Gábor Lugosi, and György Ottucsák.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 11,
      "context" : "[12] David P Helmbold and Manfred K Warmuth.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 12,
      "context" : "[13] Adam Kalai and Santosh Vempala.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 13,
      "context" : "[16] Dima Kuzmin and Manfred K Warmuth.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 14,
      "context" : "[17] Nick Littlestone and Manfred K Warmuth.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 15,
      "context" : "[18] Mehryar Mohri.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 16,
      "context" : "[19] Arun Rajkumar and Shivani Agarwal.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 17,
      "context" : "[20] Daiki Suehiro, Kohei Hatano, Shuji Kijima, Eiji Takimoto, and Kiyohito Nagano.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 18,
      "context" : "[21] Eiji Takimoto and Manfred K Warmuth.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 19,
      "context" : "[22] Manfred K Warmuth and Dima Kuzmin.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 5,
      "context" : "Now consider the following online version of matrix-chain multiplication problem [6].",
      "startOffset" : 81,
      "endOffset" : 84
    }, {
      "referenceID" : 5,
      "context" : "The matrix-chain multiplication problem can be solved via dynamic programming [6] with the recurrence relation below:",
      "startOffset" : 78,
      "endOffset" : 81
    }, {
      "referenceID" : 5,
      "context" : "Regret Bound It is well-known that the number of full parenthesizing of a sequence of n matrices is the nth Catalan number [6].",
      "startOffset" : 123,
      "endOffset" : 126
    }, {
      "referenceID" : 0,
      "context" : "Then the adversary reveals a profit vector p ∈ [0, 1] in which the ith component – p i – is the profit of the ith item at trial t.",
      "startOffset" : 47,
      "endOffset" : 53
    }, {
      "referenceID" : 17,
      "context" : "[20] does not apply to this problem as the polytope is not a subset of a simplex, and consequently, cannot be characterized as submodular base polytope.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 12,
      "context" : "Nevertheless, one can apply Follow the Perturbed Leader (FPT) [13] to this problem.",
      "startOffset" : 62,
      "endOffset" : 66
    }, {
      "referenceID" : 1,
      "context" : "Figure 4: Example with C = 7 and h = [2, 3, 4].",
      "startOffset" : 37,
      "endOffset" : 46
    }, {
      "referenceID" : 2,
      "context" : "Figure 4: Example with C = 7 and h = [2, 3, 4].",
      "startOffset" : 37,
      "endOffset" : 46
    }, {
      "referenceID" : 3,
      "context" : "Figure 4: Example with C = 7 and h = [2, 3, 4].",
      "startOffset" : 37,
      "endOffset" : 46
    }, {
      "referenceID" : 5,
      "context" : "3 Rod Cutting Consider the online version of rod cutting problem [6].",
      "startOffset" : 65,
      "endOffset" : 68
    }, {
      "referenceID" : 0,
      "context" : "Then the adversary reveals a price vector p ∈ [0, 1] in which the ith component – p i – is the price of the piece of length i at trial t.",
      "startOffset" : 46,
      "endOffset" : 52
    }, {
      "referenceID" : 17,
      "context" : "[20] does not apply to this problem as the polytope is not a subset of a simplex, and consequently, cannot be characterized as submodular base polytope.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 12,
      "context" : "Nevertheless, one can apply Follow the Perturbed Leader (FPT) [13] to this problem.",
      "startOffset" : 62,
      "endOffset" : 66
    }, {
      "referenceID" : 5,
      "context" : "The rod cutting problem can be solved via dynamic programming [6] with the recurrence relation below: OPT(i) = { 0 i = 0 max0≤j≤i{OPT (j) + p j−i} i > 0 (9)",
      "startOffset" : 62,
      "endOffset" : 65
    }, {
      "referenceID" : 10,
      "context" : "[11], we can add O(n) vertices and edges (with gain zero) to make all paths equi-length.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 5,
      "context" : "The number of possible cutting is called partition function which is approximately e √ /4n √ 3 [6].",
      "startOffset" : 95,
      "endOffset" : 98
    }, {
      "referenceID" : 0,
      "context" : "Then the adversary reveals a profit vector p ∈ [0, 1] in which the ith component – p i – is the profit of including Ii in the scheduling at trial t.",
      "startOffset" : 47,
      "endOffset" : 53
    }, {
      "referenceID" : 17,
      "context" : "[20] does not apply to this problem as the polytope is not a subset of a simplex, and consequently, cannot be characterized as submodular base polytope.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 12,
      "context" : "Nevertheless, one can apply Follow the Perturbed Leader (FPT) [13] to this problem.",
      "startOffset" : 62,
      "endOffset" : 66
    } ],
    "year" : 2017,
    "abstractText" : "We consider the problem of repeatedly solving a variant of the same dynamic programming problem in successive trials. An instance of the type of problems we consider is to find the optimal binary search tree. At the beginning of each trial, the learner probabilistically chooses a tree with the n keys at the internal nodes and the n+ 1 gaps between keys at the leaves. It is then told the frequencies of the keys and gaps and is charged by the average search cost for the chosen tree. The problem is online because the frequencies can change between trials. The goal is to develop algorithms with the property that their total average search cost (loss) in all trials is close to the total loss of the best tree chosen in hind sight for all trials. The challenge, of course, is that the algorithm has to deal with exponential number of trees. We develop a methodology for tackling such problems for a wide class of dynamic programming algorithms. Our framework allows us to extend online learning algorithms like Hedge [9] and Component Hedge [15] to a significantly wider class of combinatorial objects than was possible before.",
    "creator" : "LaTeX with hyperref package"
  }
}