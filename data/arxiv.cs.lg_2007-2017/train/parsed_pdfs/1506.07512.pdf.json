{
  "name" : "1506.07512.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "Un-regularizing: approximate proximal point and faster stochastic algorithms for empirical risk minimization",
    "authors" : [ "Roy Frostig", "Rong Ge", "Sham M. Kakade", "Aaron Sidford" ],
    "emails" : [ "rf@cs.stanford.edu,", "rongge@microsoft.com,", "skakade@microsoft.com,", "sidford@mit.edu." ],
    "sections" : [ {
      "heading" : null,
      "text" : "To achieve this, we establish a framework based on the classical proximal point algorithm. Namely, we provide several algorithms that reduce the minimization of a strongly convex function to approximate minimizations of regularizations of the function. Using these results, we accelerate recent fast stochastic algorithms in a black-box fashion.\nEmpirically, we demonstrate that the resulting algorithms exhibit notions of stability that are advantageous in practice. Both in theory and in practice, the provided algorithms reap the computational benefits of adding a large strongly convex regularization term, without incurring a corresponding bias to the original problem."
    }, {
      "heading" : "1 Introduction",
      "text" : "A general optimization problem central to machine learning is that of empirical risk minimization (ERM): finding a predictor or regressor that minimizes a sum of loss functions defined by a data sample. We focus in part on the problem of empirical risk minimization of linear predictors: given a set of n data points ai, . . . , an ∈ Rd and convex loss functions φi : R→ R for i = 1, . . . , n, solve\nmin x∈Rn\nF (x), where F (x) def = n∑ i=1 φi(a T i x). (1)\nThis problem underlies supervised learning (e.g. the training of logistic regressors when φi(z) = log(1 + e−zbi), or their regularized form when φi(z) = log(1 + e −zbi) + γ2n‖x‖ 2 2 for a scalar γ > 0) and captures the widely-studied problem of linear least-squares regression when φi(z) = 1 2(z− bi)\n2. Over the past five years, problems such as (1) have received increased attention, with a recent burst of activity in the design of fast randomized algorithms. Iterative methods that randomly\n∗This is an extended and updated version of our conference paper that appeared in Proceedings of the 32nd\nInternational Conference on Machine Learning, Lille, France, 2015. JMLR: W&CP Volume 37. Email: rf@cs.stanford.edu, rongge@microsoft.com, skakade@microsoft.com, sidford@mit.edu.\nar X\niv :1\n50 6.\n07 51\n2v 1\n[ st\nat .M\nL ]\n2 4\nsample the φi have been shown to outperform standard first-order methods under mild assumptions (Bottou and Bousquet, 2008; Johnson and Zhang, 2013; Xiao and Zhang, 2014; Defazio et al., 2014; Shalev-Shwartz and Zhang, 2014).\nDespite the breadth of these recent results, their running time guarantees when solving the ERM problem (1) are sub-optimal in terms of their dependence on a natural notion of the problem’s condition number (See Section 1.1). This dependence can, however, significantly impact their guarantees on running time. High-dimensional problems encountered in practice are often poorly conditioned. In large-scale machine learning applications, the condition number of the ERM problem (1) captures notions of data complexity arising from variable correlation in high dimensions and is hence prone to be very large.\nMore specifically, among the recent randomized algorithms, each one either:\n1. Solves the ERM problem (1), under an assumption of strong convexity, with convergence that depends linearly on the problem’s condition number (Johnson and Zhang, 2013; Defazio et al., 2014).\n2. Solves only an explicitly regularized ERM problem, minx{F (x) + λr(x)} where the regularizer r is a known 1-strongly convex function and λ must be strictly positive, even when F is itself strongly convex. One such result is due to Shalev-Shwartz and Zhang (2014) and is the first to achieve acceleration for this problem, i.e. dependence only on the square root of the regularized problem’s condition number, which scales inversely with λ. Hence, taking small λ to solve the ERM problem (where λ = 0 in effect) is not a viable option.\nIn this paper we show how to bridge this gap via black-box reductions. Namely, we develop algorithms to solve the ERM problem (1) – under a standard assumption of strong convexity – through repeated, approximate minimizations of the regularized ERM problem minx{F (x) + λr(x)} for fairly large λ. Instantiating our framework with known randomized algorithms that solve the regularized ERM problem, we achieve accelerated running time guarantees for solving the original ERM problem.\nThe key to our reductions are approximate variants of the classical proximal point algorithm (PPA) (Rockafellar, 1976; Parikh and Boyd, 2014). We show how both PPA and the inner minimization procedure can then be accelerated and our analysis gives precise approximation requirements for either option. Furthermore, we show further practical improvements when the inner minimizer operates by a dual ascent method. In total, this provides at least three different algorithms for achieving an improved accelerated running time for solving the ERM problem (1) under the standard assumption of strongly convex F and smooth φi. (Table 1 summarizes our improvements in comparison to existing minimization procedures.)\nPerhaps the strongest and most general theoretical reduction we provide in this paper is encompassed by the following theorem which we prove in Section 3.\nTheorem 1.1 (Accelerated Approximate Proximal Point Algorithm). Let f : Rn → R be a µstrongly convex function and suppose that, for all x0 ∈ Rn, c > 0, λ > 0, we can compute a point xc (possibly random) such that\nEf(xc)−min x\n{ f(x) + λ\n2 ‖x− x0‖22 } ≤ 1 c [ f(x0)−min x { f(x) + λ 2 ‖x− x0‖22 }]\nin time Tc. Then given any x0, c > 0, λ ≥ 2µ, we can compute x1 such that\nEf(x1)−min x f(x) ≤ 1 c\n[ f(x0)−min\nx f(x) ] in time O ( T 4( 2λ+µ\nµ )3/2\n√ dλ/µe log c ) .\nThis theorem essentially states that we can use a linearly convergent algorithm for minimizing f(x) + λ‖x− x0‖22 in order to minimize f , while incurring a multiplicative overhead of only O( √ dλ/µepolylog(λ/µ)). Applying this theorem to previous state-of-the-art algorithms improves both the running time for solving (1), as well as the following more general ERM problem:\nmin x∈Rd n∑ i=1 ψi(x), where ψi : Rd → R. (2)\nProblem (2) is fundamental in the theory of convex optimization and covers ERM problems for multiclass and structured prediction.\nThere are a variety of additional extensions to the ERM problem to which some of our analysis easily applies. For instance, we could work in more general normed spaces, allow non-uniform smoothness of the φ, add an explicit regularizer, etc. However, to simplify exposition and comparison to related work, we focus on (1) and make clear the extensions to (2) in Section 3. These cases capture the core of the arguments presented and illustrate the generality of this approach.\nSeveral of the algorithmic tools and analysis techniques in this paper are similar in principle to (and sometimes appear indirectly in) work scattered throughout the machine learning and optimization literature – from classical treatments of error-tolerant PPA (Rockafellar, 1976; Guler, 1992) to the effective proximal term used by Accelerated Proximal SDCA Shalev-Shwartz and Zhang (2014) in enabling its acceleration.\nBy analyzing these as separate tools, and by bookkeeping the error requirements that they impose, we are able to assemble them into algorithms with improved guarantees. We believe that the presentation of Accelerated APPA (Algorithm 2) arising from this view simplifies, and clarifies in terms of broader convex optimization theory, the “outer loop” steps employed by Accelerated Proximal SDCA. More generally, we hope that disentangling the relevant algorithmic components into this general reduction framework will lead to further applications both in theory and in practice."
    }, {
      "heading" : "1.1 Formal setup",
      "text" : "We consider the ERM problem (1) in the following common setting:\nAssumption 1.2 (Regularity). Each loss function φi is L-smooth, i.e. for all x, y ∈ R,\nφ(y) ≤ φ(x) + φ′(x)(y − x) + L 2 (y − x)2,\nand the sum F is µ-strongly convex, i.e. for all x, y ∈ Rd,\nF (x) ≥ F (x) +∇F (x)T(y − x) + µ 2 ‖y − x‖22.\nWe let R def = maxi ‖ai‖2 and let A ∈ Rn×d be the matrix whose i’th row is aTi . We refer to\nκ def = dLR2/µe\nas the condition number of (1). Although many algorithms are designed for special cases of the ERM objective F where there is some known, exploitable structure to the problem, our aim is to study the most general case subject to Assumption 1.2. To standardize the comparison among algorithms, we consider the following generic model of interaction with F :\nAssumption 1.3 (Computational model). For any i ∈ [n] and x ∈ Rd, we consider two primitive operations:\n• For b ∈ R, compute the gradient of x 7→ φi(aTi x− b).\n• For b ∈ R, c ∈ Rd, minimize φi(aTi x) + b‖x− c‖22.\nWe refer to these operations, as well as to the evaluation of φi(a T i x), as single accesses to φi, and assume that these operations can be performed in O(d) time.\nNotation Denote [n] def = {1, . . . , n}. Denote the optimal value of a convex function by fopt = minx f(x), and, when f is clear from context, let x opt denote a minimizer. A point x′ is an\n-approximate minimizer of f if f(x′) − fopt ≤ . The Fenchel dual of a convex function f : Rk → R is f∗ : Rk → R defined by f∗(y) = supx∈Rk{〈y, x〉 − f(x)}. We use Õ(·) to hide factors polylogarithmic in n, L, µ, λ, and R, i.e. Õ(f) = O(fpolylog(n,L, µ, λ,R)).\nRegularization and duality Throughout the paper we let F : Rd → R denote a µ-strongly convex function. For certain results presented, F must in particular be the ERM problem (1), while other statements hold more generally. We make it clear on a case-by-case basis when F must have the ERM structure as in (1).\nBeginning in Section 1.3 and throughout the remainder of the paper, we frequently consider the function fs,λ(x), defined for all x, s ∈ Rd and λ > 0 by\nfs,λ(x) def = F (x) + λ2‖x− s‖ 2 2 (3)\nIn such context, we let xopts,λ def = argminx fs,λ(x) and we call\nκλ def = dLR2/λe\nthe regularized condition number. When F is indeed the ERM objective (1), certain algorithms for minimizing fs,λ operate in the regularized ERM dual. Namely, they proceed by decreasing the negative dual objective gs,λ : Rn → R, given by\ngs,λ(y) def = G(y) +\n1\n2λ ‖ATy‖22 − sTATy, (4)\nwhere G(y) def = ∑n\ni=1 φ ∗ i (yi). Similar to the above, we let y opt s,λ def = argminy gs,λ(y).\nTo make corresponding primal progress, dual-based algorithms make use of the dual-to-primal mapping, given by\nx̂s,λ(y) def = s− 1λA Ty, (5)\nand the primal-to-dual mapping, given entrywise by\n[ŷ(x)]i def =\n[ ∂φi(z)\n∂z ]∣∣∣∣ z=aTi x\n(6)\nfor i = 1, . . . , n. (See Appendix B for a derivation of these facts and further properties of the dual.)"
    }, {
      "heading" : "1.2 Running times and related work",
      "text" : "In Table 1 we compare our results with the running time of both classical and recent algorithms for solving the ERM problem (1) and linear least-squares regression. Here we briefly explain these running times and related work.\nEmpirical risk minimization In the context of the ERM problem, GD refers to canonical gradient descent on F , Accel. GD is Nesterov’s accelerated gradient decent (Nesterov, 1983, 2004), SVRG is the stochastic variance-reduced gradient of Johnson and Zhang (2013), SAG is the stochastic average gradient of Roux et al. (2012) and Defazio et al. (2014), SDCA is the stochastic dual coordinate ascent of Shalev-Shwartz and Zhang (2013), AP-SDCA is the Accelerated Proximal SDCA of Shalev-Shwartz and Zhang (2014) and APCG is the accelerated coordinate algorithm of Lin et al. (2014). The latter three algorithms are more restrictive in that they only solve the explicitly regularized problem F + λr, even if F is itself strongly convex (such algorithms run in time inversely proportional to λ).\nThe running times of the algorithms are presented based on the setting considered in this paper, i.e. under Assumptions 1.2 and 1.3. Many of the algorithms can be applied in more general settings\n(e.g. even if the function F is not strongly convex) and have different convergence guarantees in those cases. The running times are characterized by four parameters: d is the data dimension, n is the number of samples, κ = dLR2/µe is the condition number (for F + λr minimizers, the condition number κλ = dLR2/λe is used) and 0/ is the ratio between the initial and desired accuracy. Running times are stated per Õ-notation; factors that depend polylogarithmically on n, κ, and κλ are ignored.\nLinear least-squares regression For the linear least-squares regression problem, there is greater variety in the algorithms that apply. For comparison, Table 1 includes Moore-Penrose pseudoinversion – computed via naive matrix multiplication and inversion routines, as well as by their asymptotically fastest counterparts – in order to compute a closed-form solution via the standard normal equations. The table also lists algorithms based on the randomized Kaczmarz method (Strohmer and Vershynin, 2009; Needell et al., 2014) and their accelerated variant (Lee and Sidford, 2013), as well as algorithms based on subspace embedding (OSNAP) or row sampling (Nelson and Nguyen, 2013; Li et al., 2013; Cohen et al., 2015). Some Kaczmarz-based methods only apply to the more restrictive problem of solving a consistent system (finding x satisfying Ax = b) rather than minimize the squared loss ‖Ax− b‖22. The running times depend on the same four parameters n, d, κ, 0/ as before, except for computing the closed-form pseudoinverse, which for simplicity we consider “exact,” independent of initial and target errors 0/ .\nApproximate proximal point The key to our improved running times is a suite of approximate proximal point algorithms that we propose and analyze. We remark that notions of error-tolerance in the typical proximal point algorithm – for both its plain and accelerated variants – have been defined and studied in prior work (Rockafellar, 1976; Guler, 1992). However, these mainly consider the cumulative absolute error of iterates produced by inner minimizers, assuming that such a sequence is somehow produced. Since essentially any procedure of interest begins at some initial point – and has runtime that depends on the relative error ratio between its start and end – such a view does not yield fully concrete algorithms, nor does it yield end-to-end runtime upper bounds such as those presented in this paper.\nAdditional related work There is an immense body of literature on proximal point methods and alternating direction method of multipliers (ADMM) that are relevant to the approach in this paper; see Boyd et al. (2011); Parikh and Boyd (2014) for modern surveys. We also note that the independent work of Lin et al. (2015) contains results similar to some of those in this paper."
    }, {
      "heading" : "1.3 Main results",
      "text" : "All formal results in this paper are obtained through a framework that we develop for iteratively applying and accelerating various minimization algorithms. When instantiated with recentlydeveloped fast minimizers we obtain, under Assumptions 1.2 and 1.3, algorithms guaranteed to solve the ERM problem in time Õ(nd √ κ log(1/ )).\nOur framework stems from a critical insight of the classical proximal point algorithm (PPA) or proximal iteration: to minimize F (or more generally, any convex function) it suffices to iteratively minimize\nfs,λ(x) def = F (x) + λ2‖x− s‖ 2 2\nfor λ > 0 and proper choice of center s ∈ Rd. PPA iteratively applies the update\nx(t+1) ← argmin x fx(t),λ(x)\nand converges to the minimizer of F . The minimization in the update is known as the proximal operator (Parikh and Boyd, 2014), and we refer to it in the sequel as the inner minimization problem.\nIn this paper we provide three distinct approximate proximal point algorithms, i.e. algorithms that do not require full inner minimization. Each enables the use of existing fast algorithm as its inner minimizer, in turn yielding several ways to obtain our improved ERM running time:\n• In Section 2 we develop a basic approximate proximal point algorithm (APPA). The algorithm is essentially PPA with a relaxed requirement of inner minimization by only a fixed multiplicative constant in each iteration. Instantiating this algorithm with an accelerated, regularized ERM solver – such as APCG (Lin et al., 2014) – as its inner minimizer yields the improved accelerated running time for the ERM problem (1).\n• In Section 3 we develop Accelerated APPA. Instantiating this algorithm with SVRG (Johnson and Zhang, 2013) as its inner minimizer yields the improved accelerated running time for both the ERM problem (1) as well as the general ERM problem (2).\n• In Section 4 we develop Dual APPA: an algorithm whose approximate inner minimizers operate on the dual fs,λ, with warm starts between iterations. Dual APPA enables several inner minimizers that are a priori incompatible with APPA. Instantiating this algorithm with an accelerate, regularized ERM solver – such as APCG (Lin et al., 2014) – as its inner minimizer yields the improved accelerated running time for the ERM problem (1).\nEach of the three algorithms exhibits a slight advantage over the others in different regimes. APPA has by far the simplest and most straightforward analysis, and applies directly to any µstrongly convex function F (not only F given by (1)). Accelerated APPA is more complicated, but in many regimes is a more efficient reduction than APPA; it too applies to any µ-strongly convex function F and in turn proves Theorem 1.1.\nOur third algorithm, Dual APPA, is the least general in terms of the assumptions on which it relies. It is the only reduction we develop that requires the ERM structure of F . However, this algorithm is a natural choice in conjunction with inner minimizers that operate on a popular dual objective. In Section 5 we demonstrate moreover that this algorithm has properties that make it desirable in practice."
    }, {
      "heading" : "1.4 Paper organization",
      "text" : "The remainder of this paper is organized as follows. In Section 2, Section 3, and Section 4 we state and analyze the approximate proximal point algorithms described above. In Section 5 we discuss practical concerns and cover numerical experiments involving Dual APPA and related stochastic algorithms. In Appendix A we prove general technical lemmas used throughout the paper and in Appendix B we provide a derivation of regularized ERM duality and related technical lemmas."
    }, {
      "heading" : "2 Approximate proximal point algorithm (APPA)",
      "text" : "In this section we describe our approximate proximal point algorithm (APPA). This algorithm is perhaps the simplest, both in its description and in its analysis, in comparison to the others described in this paper. This section also introduces technical machinery that is used throughout the sequel.\nWe first present our formal abstraction of inner minimizers (Section 2.1), then we present our algorithm (Section 2.2), and finally we step through its analysis (Section 2.3)."
    }, {
      "heading" : "2.1 Approximate primal oracles",
      "text" : "To design APPA, we first quantify the error that can be tolerated of an inner minimizer, while accounting for the computational cost of ensuring such error. The abstraction we use is the following notion of inner approximation:\nDefinition 2.1. An algorithm P is a primal (c, λ)-oracle if, given x ∈ Rd, it outputs P(x) that is a ([fx,λ(x)− foptx,λ ]/c)-approximate minimizer of fx,λ in time TP . 1\nIn other words, a primal oracle is an algorithm initialized at x that reduces the error of fx,λ by a 1/c fraction, in time that depends on λ, and c, and regularity properties of F . Typical iterative first-order algorithms, such as those in Table 1, yield primal (c, λ)-oracles with runtimes TP that scale inversely in λ or √ λ, and logarithmically in c. For instance:\nTheorem 2.2 (SVRG as a primal oracle). SVRG (Johnson and Zhang, 2013) is a primal (c, λ)oracle with runtime complexity TP = O(ndmin{κ, κλ} log c) for both the ERM problem (1) and the general ERM problem (2).\nTheorem 2.3 (APCG as an accelerated primal oracle). Using APCG (Lin et al., 2014) we can obtain a primal (c, λ)-oracle with runtime complexity TP = Õ(nd √ κλ log c) for the ERM problem (1). 2\nProof. Corollary B.3 implies that, given a primal point x, we can obtain, in O(nd) time, a corresponding dual point y such that the duality gap fx,λ(x) + gx,λ(y) (and thus the dual error) is at most O(poly(κλ)) times the primal error. Lemma B.1 implies that decreasing the dual error by a factor O(poly(κλ)c) decreases the induced primal error by c. Therefore, applying APCG to the dual and performing the primal and dual mappings yield the theorem."
    }, {
      "heading" : "2.2 Algorithm",
      "text" : "Our Approximate Proximal Point Algorithm (APPA) is given by the following Algorithm 1.\n1When the oracle is a randomized algorithm, we require that expected error is the same, i.e. that the solution be -approximate in expectation.\n2AP-SDCA could likely also serve as a primal oracle with the same guarantees. However, the results in ShalevShwartz and Zhang (2014) are stated assuming initial primal and dual variables are zero. It is not directly clear how one can provide a generic relative decrease in error from this specific initial primal-dual pair.\nAlgorithm 1 Approximate PPA (APPA)\ninput x(0) ∈ Rd, λ > 0 input primal (2(λ+µ)µ , λ)-oracle P\nfor t = 1, . . . , T do x(t) ← P(x(t−1))\nend for output x(T )\nThe central goal of this section is to prove the following lemma, which guarantees a geometric convergence rate for the iterates produced in this manner\nLemma 2.4 (Contraction in APPA). For any c′ ∈ (0, 1), x ∈ Rd, and possibly randomized primal (λ+µc′µ , λ)-oracle P (possibly randomized) we have\nE[F (P(x))]− F opt ≤ λ+ c ′µ\nλ+ µ\n( F (x)− F opt ) . (7)\nThis lemma immediately implies the following running-time bounds for APPA.\nTheorem 2.5 (Un-regularizing in APPA). Given a primal (2(µ+λ)µ , λ)-oracle P, Algorithm 1 minimizes the general ERM problem (2) to within accuracy in time O(TPdλ/µe log( 0/ )).3\nCombining Theorem 2.5 and Theorem 2.3 immediately yields our desired running time for solving (1).\nCorollary 2.6. Instantiating Algorithm 1 with the Theorem 2.3 as the primal oracle and taking λ = µ yields the running time of Õ(nd √ κ log( 0/ )) for solving (1)."
    }, {
      "heading" : "2.3 Analysis",
      "text" : "This section gives a proof of Lemma 2.4. Throughout, no assumption is made on F aside from µ-strong convexity. Namely, we need not have F be smooth or at all differentiable.\nFirst, we consider the effect of an exact inner minimizer. Namely, we prove the following lemma relating the minimum of the inner problem fs,λ to F opt.\nLemma 2.7 (Relationship between minima). For all s ∈ Rd and λ ≥ 0\nfopts,λ − F opt ≤ λ\nµ+ λ\n( F (s)− F opt ) .\nProof. Let xopt = argminx F (x) and for all α ∈ [0, 1] let xα = (1 − α)s + αxopt. The µ-strong convexity of F implies that, for all α ∈ [0, 1],\nF (xα) ≤ (1− α)F (s) + αF (xopt)− α(1− α)µ\n2 ‖s− xopt‖22.\nConsequently, by the definition of fopts,λ ,\nfopts,λ ≤ F (xα) + λ\n2 ‖xα − s‖22 ≤ (1− α)F (s) + αF (xopt)− α(1− α)µ 2 ‖s− xopt‖22 + λα2 2 ‖s− xopt‖22\nChoosing α = µµ+λ yields the result.\n3When the oracle is a randomized algorithm, the expected accuracy is at most .\nThis immediately implies contraction for the exact PPA, as it implies that in every iteration of PPA the error in F decreases by a multiplicative λ/(λ+ µ). Using this we prove Lemma 2.4.\nProof of Lemma 2.4. Let x′ = P (x). By definition of primal oracle P we have\nfx,λ(x ′)− foptx,λ ≤\nc′µ\nλ+ µ\n( fx,λ(x)− foptx,λ ) .\nCombining this and Lemma 2.7 we have\nfx,λ(x ′)− F opt ≤ c\n′µ\nλ+ µ\n( fx,λ(x)− foptx,λ ) + λ\nµ+ λ\n( F (x)− F opt ) Using that clearly for all z we have F (z) ≤ fx,λ(z) we see that F (x′) ≤ fx,λ(x′) and F opt ≤ foptx,λ . Combining with the fact that fx,λ(x) = F (x) yields the result."
    }, {
      "heading" : "3 Accelerated APPA",
      "text" : "In this section we show how generically accelerate the APPA algorithm of Section 2. Accelerated APPA (Algorithm 2) uses inner minimizers more efficiently, but requires a smaller minimization factor when compared to APPA. The algorithm and its analysis immediately prove Theorem 1.1 and in turn yield another means by which we achieve the accelerated running time guarantees for solving (1).\nWe first present the algorithm and state its running time guarantees (Section 3.1), then prove the guarantees as part of analysis (Section 3.2)."
    }, {
      "heading" : "3.1 Algorithm",
      "text" : "Our accelerated APPA algorithm is given by Algorithm 2. In every iteration it still makes a single call to a primal oracle, but rather than requiring a fixed constant minimization the minimization factor depends polynomial on the ratio of λ and µ.\nAlgorithm 2 Accelerated APPA input x(0) ∈ Rd, µ > 0, λ > 2µ input primal (4ρ3/2, λ)-oracle P, where ρ = µ+2λµ\nDefine ζ = 2µ + 1 λ v(0) ← x(0) for t = 0, . . . , T − 1 do y(t) ← ( 1\n1+ρ−1/2\n) x(t) + ( ρ−1/2\n1+ρ−1/2\n) v(t)\nx(t+1) ← P(y(t)) g(t) ← λ(y(t) − x(t+1)) v(t+1) ← (1− ρ−1/2)v(t) + ρ−1/2 [ y(t) − ζg(t) ] end for\noutput x(T )\nThe central goal is to prove the following theorem regarding the running time of APPA.\nTheorem 3.1 (Un-regularizing in Accelerated APPA). Given a primal (4(2λ+µµ ) 3/2, λ)-oracle P for λ ≥ 2µ, Algorithm 2 minimizes the general ERM problem (2) to within accuracy in time O(TP √ dλ/µe log( 0/ )).\nThis theorem is essentially a restatement of Theorem 1.1 and by instantiating it with Theorem 2.2 we obtain the following.\nCorollary 3.2. Instantiating Theorem 3.1 with SVRG (Johnson and Zhang, 2013) as the primal oracle and taking λ = 2µ + LR2 yields the running time bound Õ(nd √ κ log( 0/ )) for the general ERM problem (2)."
    }, {
      "heading" : "3.2 Analysis",
      "text" : "Here we establish the convergence rate of Algorithm 2, Accelerated APPA, and prove Theorem 3.1. Note that as in Section 2 the results in this section use nothing about the structure of F other than strong convexity and thus they apply to the general ERM problem (2).\nWe remark that aspects of the proofs in this section bear resemblance to the analysis in ShalevShwartz and Zhang (2014), which achieves similar results in a more specialized setting.\nOur proof is split into the following parts.\n• In Lemma 3.3 we show that applying a primal oracle to the inner minimization problem gives us a quadratic lower bound on F (x).\n• In Lemma 3.4 we use this lower bound to construct a series of lower bounds for the main objective function f , and accelerate the APPA algorithm, comprising the bulk of the analysis.\n• In Lemma 3.5 we show that the requirements of Lemma 3.4 can be met by using a primal oracle that decreases the error by a constant factor.\n• In Lemma 3.6 we analyze the initial error requirements of Lemma 3.4.\nThe proof of Theorem 3.1 follows immediately from these lemmas.\nLemma 3.3. For x0 ∈ Rn and > 0 suppose that x+ is an -approximate solution to fx0,λ. Then for µ′ def = µ/2, g def = λ(x0 − x+), and all x ∈ Rn we have\nF (x) ≥ F (x+)− 1 2µ′ ‖g‖2 + µ\n′\n2 ∥∥∥∥x− (x0 − ( 1µ′ + 1λ ) g )∥∥∥∥2 2 − λ+ 2µ ′ µ′ .\nNote that as µ′ = µ/2 we are only losing a factor of 2 in the strong convexity parameter for our lower bound. This allows us to account for errors without sacrificing in our ultimate asymptotic convergence rates.\nProof. Since F is µ-strongly convex clearly fx0,λ is µ+ λ strongly convex, by Lemma A.1\nfx0,λ(x)− fx0,λ(x opt x0,λ ) ≥ µ+ λ 2 ‖x− xopt‖22. (8)\nBy Cauchy-Schwartz and Young’s Inequality we know that\nλ+ µ′\n2 ‖x− x+‖22 ≤\nλ+ µ′\n2\n( ‖x− xoptx0,λ‖ 2 2 + ‖x opt x0,λ − x+‖22 ) + µ′ 2 ‖x− xoptx0,λ‖ 2 2 + (λ+ µ′)2 2µ′ ‖xoptx0,λ − x +‖22,\nwhich implies\nµ+ λ\n2 ‖x− xoptx0,λ‖ 2 2 ≥\nλ+ µ′\n2 ‖x− x+‖22 −\nλ+ µ′\nµ′ · λ+ µ 2 ‖xoptx0,λ − x +‖22.\nOn the other hand, since fx0,λ(x +) ≤ fx0,λ(x opt x0,λ )+ by assumption we have λ+µ2 ‖x +−xopt‖22 ≤\nand therefore\nfx0,λ(x)− fx0,λ(x+) ≥ fx0,λ(x)− fx0,λ(x opt x0,λ )− ≥ µ+ λ 2 ‖x− xoptx0,λ‖ 2 2 −\n≥ λ+ µ ′\n2 ‖x− x+‖22 −\nλ+ µ′\nµ′ · λ+ µ 2 ‖xoptx0,λ − x +‖22 −\n≥ λ+ µ ′\n2 ‖x− x+‖22 −\nλ+ 2µ′\nµ′ .\nNow since\n‖x− x+‖22 = ‖x− x0 + 1\nλ g‖22 = ‖x− x0‖2 +\n2 λ 〈g, x− x0〉+ 1 λ2 ‖g‖22,\nand using the fact that fx0,λ(x) = F (x) + λ 2‖x− x0‖ 2 2, we have\nF (x) ≥F (x+) + [ 1\nλ +\nµ′\n2λ2\n] ‖g‖22 + ( 1 + µ′\nλ\n) 〈g, x− x0〉+ µ′\n2 ‖x− x0‖2 −\nλ+ 2µ′\nµ′ .\nThe right hand side of the above equation is a quadratic function. Looking at its gradient with respect to x we see that it obtains its minimum when x = x0− ( 1µ′ + 1 λ)g and has a minimum value of F (x+)− 12µ′ ‖g‖ 2 2 − λ+2µ′ µ′ .\nLemma 3.4. Suppose that in each iteration t we have ψt def = ψoptt +\nµ′ 2 ‖x− v (t)‖22 such that F (x) ≥\nψt(x) for all x. Let ρ def = µ ′+λ µ′ for λ ≥ 3µ ′, and let\n• y(t) def= (\n1 1+ρ−1/2\n) x(t) + ( ρ−1/2\n1+ρ−1/2\n) v(t),\n• E[fy(t),λ(x(t+1))]− f opt y(t),λ ≤ ρ\n−3/2\n4 (F (x (t))− ψoptt ),\n• g(t) def= λ(y(t) − x(t+1)),\n• v(t+1) def= (1− ρ−1/2)v(t) + ρ−1/2 [ y(t) − ( 1 µ′ + 1 λ ) g(t) ] .\nWe have\nE[F (x(t))− ψoptt ] ≤\n( 1− ρ −1/2\n2\n)t (F (x0)− ψopt0 ).\nProof. Regardless of how y(t) is chosen we know by Lemma 3.3 that for γ = 1 + µ ′\nλ and all x ∈ R n\nF (x) ≥ F (x(t+1))− 1 2µ′ ‖g(t)‖22+\nµ′\n2 ∥∥∥∥x− (y(t) − γµ′ g(t) )∥∥∥∥2\n2\n− λ+ 2µ ′\nµ′\n( fy(t),λ(x (t+1))− fopt y(t),λ ) . (9)\nThus, for β = 1− ρ−1/2 we can let\nψt+1(x) def = βψt(x) + (1− β) [ F (x(t+1))− 1\n2µ′ ‖g(t)‖22 +\nµ′ 2 ‖x−\n( y(t) − γ µ′ g(t) ) ‖22\n− λ+ 2µ ′\nµ′ (fy(t),λ(x\n(t+1))− fopt y(t),λ ) ] = β [ ψoptt + µ′\n2 ‖x− v(t)‖22\n] + (1− β) [ F (x(t+1))− 1\n2µ′ ‖g(t)‖22 +\nµ′ 2 ‖x−\n( y(t) − γ µ′ g(t) ) ‖22\n− λ+ 2µ ′\nµ′ (fy(t),λ(x\n(t+1))− fopt y(t),λ ) ] = ψoptt+1 + µ′\n2 ‖x− v(t+1)‖22.\nwhere in the last line we used Lemma A.3. Again, by Lemma A.3 we know that ψoptt+1 = βψt + (1− β) ( F (x(t+1))− 1\n2µ′ ‖g(t)‖22 −\nλ+ 2µ′\nµ′ (fy(t),λ(x\n(t+1))− fopt y(t),λ ) ) + β(1− β)µ ′\n2 ‖v(t) −\n( y(t) − γ µ′ g(t) ) ‖22\n≥ βψt + (1− β)F (x(t+1))− (1− β)2\n2µ′ ‖g(t)‖22 + β(1− β)γ\n〈 g(t), v(t) − y(t) 〉 − (1− β)(λ+ 2µ ′)\nµ′ (fy(t),λ(x\n(t+1))− fopt y(t),λ ).\nIn the second step we used the following fact:\n−1− β 2µ′ + β(1− β)µ ′ 2 · γ 2 µ′ = 1− β 2µ′ (−1 + βγ2) ≥ −(1− β) 2 2µ′ .\nFurthermore, expanding the term µ2‖(x− y (t)) + γµg (t)‖22 and instantiating x with x(t) in (9) yields\nF (x(t+1)) ≤ F (x(t))− 1 λ ‖g(t)‖22 + γ\n〈 g(t), y(t) − x(t) 〉 + λ+ 2µ′\nµ′ (fy(t),λ(x\n(t+1))− fopt y(t),λ ).\nConsequently we know\nF (x(t+1))− ψoptt+1 ≤ β[f(x (t))− ψoptt ] +\n[ (1− β)2\n2µ′ − β λ\n] ‖g(t)‖22 + γβ 〈 g(t), y(t) − x(t) − (1− β)(v(t) − y(t)) 〉 + (λ+ 2µ′)\nµ′ (fy(t),λ(x\n(t+1))− fopt y(t),λ )\nNote that we have chosen y(t) so that the inner product term equals 0, and we choose β = 1−ρ−1/2 ≥ 1 2 which ensures\n(1− β)2\n2µ′ − β λ ≤ 1 2(µ′ + λ) − 1 2λ ≤ 0.\nAlso, by assumption we know E[fy(t),λ(x(t+1))− f opt y(t),λ ] ≤ ρ\n−3/2\n4 (f(x (t))− ψoptt ), which implies\nE[F (x(t+1))− ψoptt+1] ≤\n( β + (λ+ 2µ′)\nµ′ · ρ −3/2 4 ) (F (x(t))− ψoptt ) ≤ (1− ρ−1/2/2)(F (x(t))− ψ opt t ).\nIn the final step we are using the fact that λ+2µ ′\nµ′ ≤ 2ρ and ρ ≥ 1.\nLemma 3.5. Under the setting of Lemma 3.4, we have fy(t),λ(x (t)) − fopt y(t),λ ≤ F (x(t)) − ψoptt . In particular, in order to achieve E[fy(t),λ(x(t+1))] ≤ ρ−3/2 8 (F (x (t))−ψoptt ) we only need an oracle that shrinks the function error by a factor of ρ −3/2\n8 (in expectation).\nProof. We know\nfy(t),λ(x (t))− f(x(t)) = λ\n2 ‖x(t) − y(t)‖22 =\nλ 2 · ρ\n−1\n(1 + ρ−1/2)2 ‖x(t) − v(t)‖22.\nWe will try to show the lower bound fopt y(t),λ is larger than ψoptt by the same amount. This is because for all x we have\nfy(t),λ(x) = F (x) + λ\n2 ‖x− y(t)‖22 ≥ ψ opt t +\nµ′ 2 ‖x− v(t)‖22 + λ 2 ‖x− y(t)‖22.\nThe right hand side is a quadratic function, whose optimal point is at x = µ ′v(t)+λy(t)\nµ′+λ and whose optimal value is equal to\nψoptt + λ\n2\n( µ′\nµ′ + λ\n)2 ‖v(t)−y(t)‖22+ µ′\n2\n( λ\nµ+ λ\n)2 ‖v(t)−y(t)‖22 = ψ opt t + µ′λ\n2(µ′ + λ) · 1 (1 + ρ−1/2)2 ‖x(t)−v(t)‖22.\nBy definition of ρ−1, we know µ ′λ\n2(µ′+λ) · 1 (1+ρ−1/2)2 ‖x(t)−v(t)‖22 is exactly equal to λ2 ·\nρ−1\n(1+ρ−1/2)2 ‖x(t)−\nv(t)‖22, therefore fy(t),λ(x(t))− f opt y(t),λ ≤ F (x(t))− ψoptt .\nRemark In the next lemma we show that moving to the regularized problem has the same effect on the primal function value and the lower bound. This is a result of the choice of β in the proof of Lemma 3.4. However, this does not mean that the choice of β is very fragile. We can choose any β′ that is between the current β and 1; the effect on this lemma will be that the increase in primal function becomes smaller than the increase in the lower bound (so the lemma continues to hold).\nLemma 3.6. Let ψopt0 = F (x (0)) − λ+2µ\n′\nµ′ (F (x (0)) − fopt), and v(0) = x(0), then ψ0 def = ψopt0 +\nµ′\n2 ‖x − v0‖ 2 is a valid lower bound for F . In particular when λ = LR2 then F (x(0)) − ψopt0 ≤\n2κ(F (x(0))− fopt).\nProof. This lemma is a direct corollary of Lemma 3.3 with x+ = x(0)."
    }, {
      "heading" : "4 Dual APPA",
      "text" : "In this section we develop Dual APPA (Algorithm 3), a natural approximate proximal point algorithm that operates entirely in the regularized ERM dual. Our focus here is on theoretical properties of Dual APPA; Section 5 later explores aspects of Dual APPA more in practice.\nWe first present an abstraction for dual-based inner minimizers (Section 4.1), then present the algorithm (Section 4.2), and finally step through its runtime analysis (Section 4.3)."
    }, {
      "heading" : "4.1 Approximate dual oracles",
      "text" : "Our primary goal in this section is to quantify how much objective function progress an algorithm needs to make in the dual problem, gs,λ (See Section 1.1) in order to ensure primal progress at a rate similar to that in APPA (Algorithm 1).\nHere, similar to Section 2.1, we formally define our requirements for an approximate dual-based inner dual minimize. In particular, we use the following notion of dual oracle.\nDefinition 4.1. An algorithm D is a dual (c, λ)-oracle if, given s ∈ Rd and y ∈ Rn, it outputs D(s, y) that is a ([gs,λ(y)− gopts,λ ]/c)-approximate minimizer of gs,λ in time TD. 4\nDual based algorithms for regularized ERM and variants of coordinate descent typically can be used as such a dual oracle. In particular we note that APCG is such a dual oracle.\nTheorem 4.2 (APCG as a dual oracle). APCG (Lin et al., 2014) is a dual (c, λ)-oracle with runtime complexity TD = Õ(nd √ κλ log c). 5"
    }, {
      "heading" : "4.2 Algorithm",
      "text" : "Our dual APPA is given by the following Algorithm 3.\nAlgorithm 3 Dual APPA input x(0) ∈ Rd, λ > 0 input dual (σ, λ)-oracle D (see Theorem 4.3 for σ) y(0) ← ŷ(x(0)) for t = 1, . . . , T do y(t) ← D(x(t−1), y(t−1)) x(t) ← x̂x(t−1),λ(y(t))\nend for output x(T )\nDual APPA (Algorithm 3) repeatedly queries a dual oracle while producing primal iterates via the dual-to-primal mapping (5) along the way. We show that it obtains the following running time bound:\nTheorem 4.3 (Un-regularizing in Dual APPA). Given a dual (σ, λ)-oracle D, where\nσ ≥ 80n2κ2λ max{κ, κλ}dλ/µe\nAlgorithm 3 minimizes the ERM problem (1) to within accuracy in time Õ(TDdλ/µe log( 0/ )).6\nCombining Theorem 4.3 and Theorem 4.2 immediately yields another way to achieve our desired running time for solving (1).\n4As in the primal oracle definition, when the oracle is a randomized algorithm, we require that its output be an expected -approximate solution.\n5As in Theorem 2.3, AP-SDCA could likely also serve as a dual oracle with the same guarantees, provided it is modified to allow for the more general primal-dual initialization.\n6As in Theorem 2.5, when the oracle is a randomized algorithm, the expected accuracy is at most .\nCorollary 4.4. Instantiating Theorem 4.3 with Theorem 4.2 as the dual oracle and taking λ = µ yields the running time bound Õ(nd √ κ log( 0/ )).\nWhile both this result and the results in Section 2 show that APCG can be used to achieve our fastest running times for solving (1), note that the algorithms they suggest are in fact different. In every invocation of APCG in Algorithm 1, we need to explicitly compute both the primal-to-dual and dual-to-primal mappings (in O(nd) time). However, here we only need to compute the primalto-dual mapping once upfront, in order to initialize the algorithm. Every subsequent invocation of APCG then only requires a single dual-to-primal mapping computation, which can often be streamlined. From a practical viewpoint, this can be seen as a natural “warm start” scheme for the dual-based inner minimizer."
    }, {
      "heading" : "4.3 Analysis",
      "text" : "Here we proves Theorem 4.3. We begin by bounding the error of the dual regularized ERM problem when the center of regularization changes. This characterizes the initial error at the beginning of each Dual APPA iteration.\nLemma 4.5 (Dual error after re-centering.). For all y ∈ Rn, x ∈ Rd, and x′ = x̂x(y) we have\ngx′,λ(y)− goptx′,λ ≤ 2(gx,λ(y)− g opt x,λ) + 4nκ\n[ F (x′)− F opt + F (x)− F opt ] In other words, the dual error gs,λ(y)− gopts,λ is bounded across a re-centering step by multiples\nof previous sub-optimality measurements (namely, dual error and gradient norm).\nProof. By the definition of gx,λ and x ′ we have, for all z,\ngx′,λ(z) = G(z) + 1 2λ ‖ATz‖2 − x′TATz = gx,λ(z)− (x′ − x)>ATz = gx,λ(z) + 1 λ yTAATz .\nFurthermore, since g is 1L -strongly convex we can invoke Lemma A.2 obtaining\ngx′,λ(y)− goptx′,λ ≤ 2 [ gx,λ(y)− goptx′,λ ] + L ∥∥∥∥ 1λAATy ∥∥∥∥2 2 .\nSince each row of A has `2 norm at most R we know that ‖Az‖22 ≤ nR2‖z‖22 and we know that by definition ATy = λ(x− x′). Combining these yields\ngx′,λ(y)− goptx′,λ ≤ 2 [ gx,λ(y)− goptx′,λ ] + nLR2‖x− x′‖22.\nFinally, since F is µ-strongly convex, by Lemma A.1, we have\n1 2 ‖x− x′‖22 ≤ ‖x′ − xopt‖22 + ‖x− xopt‖22 ≤ 2 µ\n[ F (x′)− F opt + F (x)− F opt ] .\nCombining and recalling the definition of κ yields the result.\nThe following lemma establishes the rate of convergence of the primal iterates {x(t)} produced over the course of Dual APPA, and in turn implies Theorem 4.3.\nLemma 4.6 (Convergence rate of Dual APPA). Let c′ ∈ (0, 1) be arbitrary and suppose that σ ≥ (40/c′)n2κ2λ max{κ, κλ}dλ/µe in Dual APPA (Algorithm 3). Then in every iteration t ≥ 1 of Dual APPA (Algorithm 3) the following invariants hold:\nF (x(t−1))− F opt ≤ ( λ+ c′µ\nλ+ µ\n)t−1 ( F (x(0))− F opt ) , and (10)\ngx(t−1),λ(y (t))− gopt x(t−1),λ ≤ ( λ+ c′µ\nλ+ µ\n)t−1 ( F (x(0))− F opt ) . (11)\nProof. For notational convenience we let r def = (λ+c ′µ λ+µ ), gt def = gx(t),λ, ft def = fx(t),λ, and t def = F (x(t))− F opt for all t ≥ 0. Thus, we wish to show that t−1 ≤ rt−1 0 (equivalent to (11)) and we wish to show that gt−1(y\n(t))− goptt−1 ≤ rt−1 0 (equivalent to (10)) for all t ≥ 1. By definition of a dual oracle we have, for all t ≥ 1,\ngt−1(y (t))− goptt−1 ≤\n1\nσ\n[ gt−1(yt−1)− goptt−1 ] , (12)\nby Lemma B.1 we have, for all t ≥ 1,\nft−1(x (t))− foptt−1 ≤ 2n 2κ2λ [ gt−1(y (t))− goptt−1 ] , (13)\nby Lemma 4.5 we know\ngt(y (t))− goptt ≤ 2 [ gt−1(y (t))− goptt ] + 4nκ( t + t−1), (14)\nand by Lemma 2.7 we know that for all t ≥ 1\nfoptt−1 − F opt ≤ λ\nµ+ λ t−1 (15)\nFurthermore, by Corollary B.3, the definition of y(0), and the facts that f0(x (0)) = F (x(0)) and ft(z) ≥ F (z) we have\ng0(y (0))− gopt0 ≤ 2κλ ( f0(x (0))− fopt0 ) ≤ 2κλ ( F (x(0))− F opt ) = 2κλ 0 (16)\nWe show that combining these and applying strong induction on t yields the desired result. We begin with our base cases. When t = 1 the invariant (11) holds immediately by definition. Furthermore, when t = 1 we see that the invariant (10) holds, since σ ≥ 2κλ and\ng0(y (1))− gopt0 ≤\n1 σ (g0(y (0))− gopt0 ) ≤ 2κλ σ\n( f0(x (0))− fopt0 ) ≤ 2κλ\nσ 0, (17)\nwere we used (12) and (16) respectively. Finally we show that invariant (11) holds for t = 2:\nF (x(1))− F opt ≤ f0(x(1))− fopt0 + f opt 0 − F opt (Since F (z) ≤ ft(z) for all t, z)\n≤ 2n2κ2λ(g0(y(1))− g opt 0 ) +\nλ\nµ+ λ 0 (Equations (13) and (15)) ≤ (\n4n2κ3λ σ + λ µ+ λ\n) 0 (Equation (17))\n≤ r 0 (Since σ ≥ 4nκ3λ/(c′λ/(µ+ λ)))\nNow consider t ≥ 3 for the second invariant (11). We show this holds assuming the invariants hold for all smaller t.\nF (x(t−1))− F opt ≤ ft−2(x(t−1))− foptt−2 + f opt t−2 − F opt (Since F (z) ≤ ft(z) for all t, z)\n≤ 2n2κ2λ(gt−2(yt−1)− g opt t−2) +\nλ\nµ+ λ t−2 (Equations (13) and (15))\n≤ 2n2κ2λ σ ( gt−2(yt−2)− goptt−2 ) + λ µ+ λ t−2 (Equation (12))\nFurthermore,\ngt−2(yt−2)− goptt−2 ≤ 2(gt−3(yt−2)− g opt t−3) + 4nκ [ t−2 + t−3] (Equation (17)) ≤ ( 2rt−2 + 4nκ(rt−1 + rt−2) ) 0 (Inductive hypothesis)\n≤ 10nκrt−1 0 (r ≤ 1 and κ ≥ 1)\nSince σ ≥ 20n2κ2λκ/(c′λ/(µ+ λ)) combining yields that\n2n2κ2λ σ ( gt−2(yt−2)− goptt−2 ) ≤ c ′µ µ+ λ rt−1 0\nand the result follows by the inductive hypothesis on t−2. Finally we show that invariant (10) holds for any t ≥ 2 given that it holds for all smaller t and invariant (11) holds for that t and all smaller t.\ngt−1(y (t))− goptt−1 ≤\n1 σ (gt−1(yt−1)− goptt−1) (Definition dual oracle.)\n≤ 1 σ\n[ 2(gx(t−2)(yt−1)− g opt x(t−2) ) + 4nκ [ t−1 + t−2] ] (Equation (14))\n≤ 1 σ\n[ 2rt−1 + 4nκ [ rt + rt−1 ]] 0 (Inductive hypothesis)\n≤ rt−1 0 (σ ≥ 8nκ)\nThe result then follows by induction."
    }, {
      "heading" : "5 Implementation",
      "text" : "In the following two subsections, respectively, we discuss implementation details and report on an empirical evaluation of the APPA framework."
    }, {
      "heading" : "5.1 Practical concerns",
      "text" : "While theoretical convergence rates lay out a broad-view comparison of the algorithms in the literature, we briefly remark on some of the finer-grained differences between algorithms, which inform their implementation or empirical behavior. To match the terminology used for SVRG in Johnson and Zhang (2013), we refer to a “stage” as a single step of APPA, i.e. the time spent executing the inner minimization of fx(t),λ or gx(t),λ (as in (3) and (4)).\nRe-centering overhead of Dual APPA vs. SVRG At the end of every one of its stages, SVRG pauses to compute an exact gradient by a complete pass over the dataset (costing Θ(nd) time during which n gradients are computed). Although an amortized runtime analysis hides this cost, this operation cannot be carried out in-step with the iterative updates of the previous stage, since the exact gradient is computed at a point that is only selected at the stage’s end.\nMeanwhile, if each stage in Dual APPA is initialized with a valid primal-dual pair for the inner problem, Dual APPA can update the current primal point together with every dual coordinate update, in time O(d), i.e. with negligible increase in the overhead of the update. When doing so, the corresponding data row remains fresh in cache and, unlike SVRG, no additional gradient need be computed.\nMoreover, initializing each stage with a valid such primal-dual pair can be done in only O(d) time. At the end of a stage where s was the center point, Dual APPA holds a primal-dual pair (x, y) where x = x̂s(y). The next stage is centered at x and the dual variables initialized at y, so it remains to set up a corresponding primal point x′ = x̂x(y) = x − 1λA\nTy. This can be done by computing x′ ← 2x− s, since we know that x− s = − 1λA Ty.\nDecreasing λ APPA and Dual APPA enjoy the nice property that, as long as the inner problems are solved with enough accuracy, the algorithm does not diverge even for large choice of λ. In practice this allows us to start with a large λ and make faster inner minimizations. If we heuristically observe that the function error is not decreasing rapidly enough, we can switch to a smaller λ. Figure 3 (Section 5.2) demonstrates this empirically. This contrasts with algorithm parameters such as step size choices in stochastic optimizers (that may still appear in inner minimization). Such parameters are typically more sensitive, and can suddenly lead to divergence when taken too large, making them less amenable to mid-run parameter tuning.\nStable update steps When used as inner minimizers, dual coordinate-wise methods such as SDCA typically provide a convenient framework in which to derive parameter updates with datadependent step sizes, or sometimes enables closed-form updates altogether (i.e. optimal solutions to each single-coordinate maximization sub-problem). For example, when Dual APPA is used together with SDCA to solve a problem of least-squares or ridge regression, the locally optimal SDCA updates can be performed efficiently in closed form. This decreases the number of algorithmic parameters requiring tuning, improves the overall the stability of the end-to-end optimizer and, in turn, makes it easier to use out of the box."
    }, {
      "heading" : "5.2 Empirical analysis",
      "text" : "We experiment with Dual APPA in comparison with SDCA, SVRG, and SGD on several binary classification tasks.\nBeyond general benchmarking, the experiments also demonstrate the advantages of the unordinary “bias-variance tradeoff” presented by approximate proximal iteration: the vanishing proximal term empirically provides advantages of regularization (added strong convexity, lower variance) at a bias cost that is less severe than with typical `2 regularization. Even if some amount of `2 shrinkage is desired, Dual APPA can place yet higher weight on its `2 term, enjoy improved speed and stability, and after a few stages achieve roughly the desired bias.\nDatasets In this section we show results for three binary classification tasks, derived from MNIST,7 CIFAR-10,8 and Protein:9 in MNIST we classify the digits {1, 2, 4, 5, 7} vs. the rest, and in CIFAR we classify the animal categories vs. the automotive ones. MNIST and CIFAR are taken under non-linear feature transformations that increase the problem scale significantly: we normalize the rows by scaling the data matrix by the inverse average `2 row norm. We then take take n/5 random Fourier features per the randomized scheme of Rahimi and Recht (2007). This yields 12K features for MNIST (60K training examples, 10K test) and 10K for CIFAR (50K training examples, 10K test). Meanwhile, Protein is a standard pre-featurized benchmark (75 features, ∼117K training examples, ∼30K test) that we preprocess minimally by row normalization and an appended affine feature, and whose train/test split we obtain by randomly holding out 20% of the original labeled data.\nAlgorithms Each algorithm is parameterized by a scalar value λ analogous to the λ used in proximal iteration: λ is the step size for SVRG, λt−1/2 is the decaying step size for SGD, and λ 2‖x‖ 2 2 is the ridge penalty for SDCA. (See Johnson and Zhang (2013) for a comparison of SVRG to a more thoroughly tuned SGD under different decay schemes.) We use Dual APPA (Algorithm 3) with SDCA as the inner minimizer. For the algorithms with a notion of a stage – i.e. Dual APPA’s time spent invoking the inner minimizer, SVRG’s period between computing exact gradients – we set the stage size equal to the dataset size for simplicity.10 SVRG is given an advantage in that we choose not to count its gradient computations when it computes the exact gradient between stages. All algorithms are initialized at x = 0. Each algorithm was run under λ = 10i for i = −8,−7, . . . , 8, and plots report the trial that best minimized the original ERM objective.\nConvergence and bias The proximal term in APPA introduces a vanishing bias for the problem (towards the initial point of x = 0) that provides a speedup by adding strong convexity to the problem. We investigate a natural baseline: for the purpose of minimizing the original ERM problem, how does APPA compare to solving one instance of a regularized ERM problem (using a single run of its inner optimizer)? In other words, to what extent does re-centering the regularizer over time help in solving the un-regularized problem? Intuitively, even if SDCA is run to convergence, some of the minimization is of the regularization term rather than the ERM term, hence one cannot weigh the regularization too heavily. Meanwhile, APPA can enjoy more ample strong convexity by placing a larger weight on its `2 term. This advantage is evident for MNIST and CIFAR in Figures 1 and 2: recalling that λ is the same strong convexity added both by APPA and by SDCA, we see that APPA takes λ at least an order of magnitude larger than SDCA does, to achieve faster and more stable convergence towards an ultimately lower final value.\nFigure 1 also shows dashed lines corresponding to the ERM performance of the least-squares fit and of fully-optimized ridge regression, using λ as that of the best APPA and SDCA runs. These appear in the legend as “ls(λ).” They indicate lower bounds on the ERM value attainable by any algorithm that minimizes the corresponding regularized ERM objective. Lastly, test set classification accuracy demonstrates the extent to which a shrinkage bias is statistically desirable.\n7http://yann.lecun.com/exdb/mnist/ 8http://www.cs.toronto.edu/∼kriz/cifar.html 9http://osmot.cs.cornell.edu/kddcup/datasets.html\n10Such a choice is justified by the observation that doubling the stage size does not have noticeable effect on the results discussed.\nIn the MNIST and CIFAR holdout, we want only the small bias taken explicitly by SDCA (and effectively achieved by APPA). In the Protein holdout, we want no bias at all (again effectively achieved by APPA).\nParameter sensitivity By solving only regularized ERM inner problems, SDCA and APPA enjoy a stable response to poor specification of the biasing parameter λ. Figure 3 plots the algorithms’ final value after 20 stages, against different choices of λ. Overestimating the step size in SGD or SVRG incurs a sharp transition into a regime of divergence. Meanwhile, APPA and SDCA always converge, with solution quality degrading more smoothly. APPA then exhibits an even better degradation as it overcomes an overaggressive biasing by the 20th stage."
    }, {
      "heading" : "Acknowledgments",
      "text" : "Part of this work took place while RF and AS were at Microsoft Research, New England, and another part while AS was visiting the Simons Institute for the Theory of Computing, UC Berkeley. This work was partially supported by NSF awards 0843915 and 1111109, NSF Graduate Research Fellowship (grant no. 1122374)."
    }, {
      "heading" : "A Technical lemmas",
      "text" : "In this section we provide several stand-alone technical lemmas we use throughout the paper. First we provide Lemma A.1 some common inequalities regarding smooth or strongly convex functions, then Lemma A.2 which shows the effect of adding a linear term to a convex function, and then Lemma A.3 a small technical lemma regarding convex combinations of quadratic functions.\nLemma A.1 (Standard bounds for smooth, strongly convex functions). Let f : Rk → R be differentiable function that obtains its minimal value at xopt.\nIf f is L-smooth then for all x ∈ Rk\n1\n2L ‖∇f(x)‖22 ≤ f(x)− f(xopt) ≤\nL 2 ‖x− xopt‖22 .\nIf f is µ-strongly convex the for all x ∈ Rk\nµ 2 ‖x− xopt‖22 ≤ f(x)− f(xopt) ≤ 1 2µ ‖∇f(x)‖22 .\nProof. Apply the definition of smoothness and strong convexity at the points x and xopt and minimize the resulting quadratic form.\nLemma A.2. Let f : Rn → R be a µ-strongly convex function and for all a, x ∈ Rn let fa(x) = f(x) + a>x. Then\nfa(x)− fopta ≤ 2(f(x)− fopt) + 1\nµ ‖a‖22\nProof. 11 Let xopt = argminx f(x). Since f is µ-strongly convex by Lemma A.1 we have f(x) ≥ f(xopt) + µ2‖x− x opt‖22 for all x. Consequently, for all x\nfopta ≥ f(x) + a>x ≥ f(xopt) + µ 2 ‖x− xopt‖22 + a>x ≥ fa(xopt) + a>(x− xopt) + µ 2 ‖x− xopt‖22\n11Note we could have also proved this by appealing to the gradient of f and Lemma A.1, however the proof here holds even if f is not differentiable.\nMinimizing with respect to x yields that fopta ≥ fa(xopt) − 12µ‖a‖ 2 2. Consequently, by Cauchy Schwarz, and Young’s Inequality we have\nfa(x)− fopta ≤ f(x)− fopt + a>(x− xopt) + 1\n2µ ‖a‖22 (18)\n≤ f(x)− fopt + 1 2µ ‖a‖22 + µ 2 ‖x− xopt‖22 + 1 2µ ‖a‖22 (19)\nApplying A.1 again yields the result.\nLemma A.3. Suppose that for all x we have\nf1(x) def = ψ1 +\nµ 2 ‖x− v1‖22 and f2(x) = ψ2 + µ 2 ‖x− v2‖22\nthen αf1(x) + (1− α)f2(x) = ψα + µ\n2 ‖x− vα‖22\nwhere vα = αv1 + (1− α)v2 and ψα = αψ1 + (1− α)ψ2 + µ\n2 α(1− α)‖v1 − v2‖22\nProof. Setting the gradient of αf1(x) + (1− α)f2(x) to 0 we know that vα must satisfy\nαµ (vα − v1) + (1− α)µ (vα − v2) = 0\nand thus vα = αv1 + (1− α)v2. Finally,\nψα = α [ ψ1 + µ\n2 ‖vα − v1‖22\n] + (1− α) [ ψ2 + µ\n2 ‖vα − v2‖22 ] = αψ1 + (1− α)ψ2 + µ\n2\n[ α(1− α)2‖v2 − v1‖22 + (1− α)α2‖v2 − v1‖22 ] = αψ1 + (1− α)ψ2 + µ\n2 α(1− α)‖v1 − v2‖22."
    }, {
      "heading" : "B Regularized ERM duality",
      "text" : "In this section we derive the dual (4) to the problem of computing proximal operator for the ERM objective (3) (Section B.1) and prove several bounds on primal and dual errors (Section B.2). Throughout this section we assume F is given by the ERM problem (1) and we make extensive use of the notation and assumptions in Section 1.1.\nB.1 Dual derivation\nWe can rewrite the primal problem, minx fs,λ(x), as\nmin x∈Rd,z∈Rn\n∑n i=1 φi(zi) + λ 2‖x− s‖ 2 2\nsubject to zi = a T i x, for i = 1, . . . , n\n.\nBy convex duality, this is equivalent to\nmin x,{zi} max y∈Rn n∑ i=1 φi(zi) + λ 2 ‖x− s‖22 + yT(Ax− z) = maxy minx,{zi} n∑ i=1 φi(zi) + λ 2 ‖x− s‖22 + yT(Ax− z)\nSince min zi {φi(zi)− yizi} = −max zi {yizi − φi(zi)} = −φ∗i (yi)\nand\nmin x\n{ λ\n2 ‖x− s‖22 + yTAx\n} = yTAs+ min\nx\n{ λ\n2 ‖x− s‖22 + yTA(x− s)\n} = yTAs− 1\n2λ ‖ATy‖22,\nit follows that the optimization problem is in turn equivalent to\n−min y n∑ i=1 φ∗i (yi) + 1 2λ ‖ATy‖22 − sTATy.\nThis negated problem is precisely the dual formulation. The first problem is a Lagrangian saddle-point problem, where the Lagrangian is defined as\nL(x, y, z) = n∑ i=1 φi(zi) + λ 2 ‖x− s‖22 + yT(Ax− z).\nThe dual-to-primal mapping (5) and primal-to-dual mapping (6) are implied by the KKT conditions under L, and can be derived by solving for x, y, and z in the system ∇L(x, y, z) = 0.\nThe duality gap in this context is defined as\ngaps,λ(x, y) def = fs,λ(x) + gs,λ(y). (20)\nStrong duality dictates that gaps,λ(x, y) ≥ 0 for all x ∈ Rd, y ∈ Rn, with equality attained when x is primal-optimal and y is dual-optimal.\nB.2 Error bounds\nLemma B.1 (Dual error bounds primal error). For all s ∈ Rd, y ∈ Rn, and λ > 0 we have\nfs,λ(x̂s,λ(y))− fopts,λ ≤ 2(nκλ) 2(gs,λ(y)− gopts,λ).\nProof. Because F is nR2L smooth, fs,λ is nR 2L+ λ smooth. Consequently, for all x ∈ Rd we have\nfs,λ(x)− fopts,λ ≤ nR2L+ λ\n2 ‖x− xopts,λ‖ 2 2\nSince we know that xopts,λ = s− 1 λA Tyopts,λ and ‖A Tz‖22 ≤ nR2‖z‖22 for all z ∈ Rn we have\nfs,λ(x̂x,λ(y))− fs,λ(xopts,λ ) ≤ nR2L+ λ 2 ‖s− 1 λ ATy − (s− 1 λ ATyopts,λ )‖ 2 2\n= nR2L+ λ\n2λ2 ‖y − yopts,λ ‖ 2 AAT\n≤ nR 2(nR2L+ λ)\n2λ2 ‖y − yopts,λ ‖ 2 2. (21)\nFinally, since each φ∗i is 1/L-strongly convex, G is 1/L-strongly convex and hence so is gs,λ. Therefore by Lemma A.1 we have\n1\n2L ‖y − yopts,λ ‖ 2 2 ≤ gs,λ(y)− gs,λ(y opt s,λ ). (22)\nSubstituting (22) in (21) and recalling that κλ ≥ 1 yields the result.\nLemma B.2 (Gap for primal-dual pairs). For all s, x ∈ Rd and λ > 0 we have\ngaps,λ(x, ŷ(x)) = 1\n2λ ‖∇F (x)‖22 +\nλ 2 ‖x− s‖22. (23)\nProof. To prove the first identity (23), let ŷ = ŷ(x) for brevity. Recall that\nŷi = φ ′ i(a T i x) ∈ argmax yi {xTaiyi − φ∗i (yi)} (24)\nby definition, and hence xTaiŷi − φ∗i (ŷi) = φi(aTi x). Observe that\ngaps,λ(x, ŷ) = n∑ i=1 ( φi(a T i x) + φ ∗ i (ŷi) ) − xTATŷ + 12λ‖A Tŷ‖2 + λ2‖x− s‖ 2\n= n∑ i=1 φi(aTi x) + φ∗i (ŷi)− xTaiŷi︸ ︷︷ ︸ =0 (by (24)) + 12λ‖ATŷ‖2 + λ2‖x− s‖2 = 12λ‖A Tŷ‖2 + λ2‖x− s‖ 2\n= 12λ‖ n∑ i=1 aiφ ′ i(a T i x)‖2 + λ2‖x− s‖ 2 = 12λ‖∇F (x)‖ 2 + λ2‖x− s‖ 2.\nCorollary B.3 (Initial dual error). For all s, x ∈ Rd and λ > 0 we have\ngx,λ(ŷ(x))− goptx,λ ≤ 2κλ ( fx,λ(x)− foptx,λ ) Proof. By Lemma B.2 we have\ngapx,λ(x, ŷ(x)) = 1\n2λ ‖∇F (x)‖22 +\nλ 2 ‖x− x‖22 = 1 2λ ‖∇F (x)‖22\nNow clearly ∇F (x) = ∇fx,λ(x). Furthermore, since fx,λ(x) is (nLR2 + λ)-smooth by Lemma A.1 we have ‖∇fx,λ(x)‖ ≤ 2(nLR2 + λ)(fx,λ(x)− foptx,λ ). Consequently,\ngx,λ(ŷ(x))− goptx,λ ≤ gapx,λ(x, ŷ(x)) ≤ 2(nLR2 + λ)\n2λ\n( fx,λ(x)− foptx,λ ) .\nRecalling the definition of κλ and the fact that 1 ≤ κλ yields the result."
    } ],
    "references" : [ {
      "title" : "The tradeoffs of large scale learning",
      "author" : [ "L. Bottou", "O. Bousquet" ],
      "venue" : "In Advances in Neural Information Processing Systems (NIPS),",
      "citeRegEx" : "Bottou and Bousquet.,? \\Q2008\\E",
      "shortCiteRegEx" : "Bottou and Bousquet.",
      "year" : 2008
    }, {
      "title" : "Distributed optimization and statistical learning via the alternating direction method of multipliers",
      "author" : [ "S. Boyd", "N. Parikh", "E. Chu", "B. Peleato", "J. Eckstein" ],
      "venue" : "Foundations and Trends in Machine Learning,",
      "citeRegEx" : "Boyd et al\\.,? \\Q2011\\E",
      "shortCiteRegEx" : "Boyd et al\\.",
      "year" : 2011
    }, {
      "title" : "Uniform sampling for matrix approximation",
      "author" : [ "M.B. Cohen", "Y.T. Lee", "C. Musco", "R. Peng", "A. Sidford" ],
      "venue" : "In Innovations in Theoretical Computer Science (ITCS),",
      "citeRegEx" : "Cohen et al\\.,? \\Q2015\\E",
      "shortCiteRegEx" : "Cohen et al\\.",
      "year" : 2015
    }, {
      "title" : "Saga: A fast incremental gradient method with support for non-strongly convex composite objectives",
      "author" : [ "A. Defazio", "F. Bach", "S. Lacoste-Julien" ],
      "venue" : "In Advances in Neural Information Processing Systems (NIPS),",
      "citeRegEx" : "Defazio et al\\.,? \\Q2014\\E",
      "shortCiteRegEx" : "Defazio et al\\.",
      "year" : 2014
    }, {
      "title" : "New proximal point algorithms for convex minimization",
      "author" : [ "O. Guler" ],
      "venue" : "SIAM Journal on Optimization,",
      "citeRegEx" : "Guler.,? \\Q1992\\E",
      "shortCiteRegEx" : "Guler.",
      "year" : 1992
    }, {
      "title" : "Accelerating stochastic gradient descent using predictive variance reduction",
      "author" : [ "R. Johnson", "T. Zhang" ],
      "venue" : "In Advances in Neural Information Processing Systems (NIPS),",
      "citeRegEx" : "Johnson and Zhang.,? \\Q2013\\E",
      "shortCiteRegEx" : "Johnson and Zhang.",
      "year" : 2013
    }, {
      "title" : "Efficient accelerated coordinate descent methods and faster algorithms for solving linear systems",
      "author" : [ "Y.T. Lee", "A. Sidford" ],
      "venue" : "In Foundations of Computer Science (FOCS),",
      "citeRegEx" : "Lee and Sidford.,? \\Q2013\\E",
      "shortCiteRegEx" : "Lee and Sidford.",
      "year" : 2013
    }, {
      "title" : "Iterative row sampling",
      "author" : [ "M. Li", "G.L. Miller", "R. Peng" ],
      "venue" : "In Foundations of Computer Science (FOCS),",
      "citeRegEx" : "Li et al\\.,? \\Q2013\\E",
      "shortCiteRegEx" : "Li et al\\.",
      "year" : 2013
    }, {
      "title" : "A universal catalyst for first-order optimization",
      "author" : [ "H. Lin", "J. Mairal", "Z. Harchaoui" ],
      "venue" : null,
      "citeRegEx" : "Lin et al\\.,? \\Q2015\\E",
      "shortCiteRegEx" : "Lin et al\\.",
      "year" : 2015
    }, {
      "title" : "An accelerated proximal coordinate gradient method",
      "author" : [ "Q. Lin", "Z. Lu", "L. Xiao" ],
      "venue" : "In Advances in Neural Information Processing Systems (NIPS),",
      "citeRegEx" : "Lin et al\\.,? \\Q2014\\E",
      "shortCiteRegEx" : "Lin et al\\.",
      "year" : 2014
    }, {
      "title" : "Stochastic gradient descent, weighted sampling, and the randomized kaczmarz algorithm",
      "author" : [ "D. Needell", "N. Srebro", "R. Ward" ],
      "venue" : "In Advances in Neural Information Processing Systems (NIPS),",
      "citeRegEx" : "Needell et al\\.,? \\Q2014\\E",
      "shortCiteRegEx" : "Needell et al\\.",
      "year" : 2014
    }, {
      "title" : "OSNAP: Faster numerical linear algebra algorithms via sparser subspace embeddings",
      "author" : [ "J. Nelson", "H.L. Nguyen" ],
      "venue" : "In Foundations of Computer Science (FOCS),",
      "citeRegEx" : "Nelson and Nguyen.,? \\Q2013\\E",
      "shortCiteRegEx" : "Nelson and Nguyen.",
      "year" : 2013
    }, {
      "title" : "A method of solving a convex programming problem with convergence rate O(1/k2)",
      "author" : [ "Y. Nesterov" ],
      "venue" : "Soviet Mathematics Doklady,",
      "citeRegEx" : "Nesterov.,? \\Q1983\\E",
      "shortCiteRegEx" : "Nesterov.",
      "year" : 1983
    }, {
      "title" : "Introductory Lectures on Convex Optimization: A Basic Course",
      "author" : [ "Y. Nesterov" ],
      "venue" : null,
      "citeRegEx" : "Nesterov.,? \\Q2004\\E",
      "shortCiteRegEx" : "Nesterov.",
      "year" : 2004
    }, {
      "title" : "Random features for large-scale kernel machines",
      "author" : [ "A. Rahimi", "B. Recht" ],
      "venue" : "In Advances in Neural Information Processing Systems (NIPS),",
      "citeRegEx" : "Rahimi and Recht.,? \\Q2007\\E",
      "shortCiteRegEx" : "Rahimi and Recht.",
      "year" : 2007
    }, {
      "title" : "Monotone operators and the proximal point algorithm",
      "author" : [ "R.T. Rockafellar" ],
      "venue" : "SIAM Journal on Control and Optimization,",
      "citeRegEx" : "Rockafellar.,? \\Q1976\\E",
      "shortCiteRegEx" : "Rockafellar.",
      "year" : 1976
    }, {
      "title" : "A stochastic gradient method with an exponential convergence rate for finite training sets",
      "author" : [ "N.L. Roux", "M. Schmidt", "F. Bach" ],
      "venue" : "In Advances in Neural Information Processing Systems (NIPS),",
      "citeRegEx" : "Roux et al\\.,? \\Q2012\\E",
      "shortCiteRegEx" : "Roux et al\\.",
      "year" : 2012
    } ],
    "referenceMentions" : [ {
      "referenceID" : 0,
      "context" : "sample the φi have been shown to outperform standard first-order methods under mild assumptions (Bottou and Bousquet, 2008; Johnson and Zhang, 2013; Xiao and Zhang, 2014; Defazio et al., 2014; Shalev-Shwartz and Zhang, 2014).",
      "startOffset" : 96,
      "endOffset" : 224
    }, {
      "referenceID" : 5,
      "context" : "sample the φi have been shown to outperform standard first-order methods under mild assumptions (Bottou and Bousquet, 2008; Johnson and Zhang, 2013; Xiao and Zhang, 2014; Defazio et al., 2014; Shalev-Shwartz and Zhang, 2014).",
      "startOffset" : 96,
      "endOffset" : 224
    }, {
      "referenceID" : 3,
      "context" : "sample the φi have been shown to outperform standard first-order methods under mild assumptions (Bottou and Bousquet, 2008; Johnson and Zhang, 2013; Xiao and Zhang, 2014; Defazio et al., 2014; Shalev-Shwartz and Zhang, 2014).",
      "startOffset" : 96,
      "endOffset" : 224
    }, {
      "referenceID" : 5,
      "context" : "Solves the ERM problem (1), under an assumption of strong convexity, with convergence that depends linearly on the problem’s condition number (Johnson and Zhang, 2013; Defazio et al., 2014).",
      "startOffset" : 142,
      "endOffset" : 189
    }, {
      "referenceID" : 3,
      "context" : "Solves the ERM problem (1), under an assumption of strong convexity, with convergence that depends linearly on the problem’s condition number (Johnson and Zhang, 2013; Defazio et al., 2014).",
      "startOffset" : 142,
      "endOffset" : 189
    }, {
      "referenceID" : 15,
      "context" : "The key to our reductions are approximate variants of the classical proximal point algorithm (PPA) (Rockafellar, 1976; Parikh and Boyd, 2014).",
      "startOffset" : 99,
      "endOffset" : 141
    }, {
      "referenceID" : 15,
      "context" : "Several of the algorithmic tools and analysis techniques in this paper are similar in principle to (and sometimes appear indirectly in) work scattered throughout the machine learning and optimization literature – from classical treatments of error-tolerant PPA (Rockafellar, 1976; Guler, 1992) to the effective proximal term used by Accelerated Proximal SDCA Shalev-Shwartz and Zhang (2014) in enabling its acceleration.",
      "startOffset" : 261,
      "endOffset" : 293
    }, {
      "referenceID" : 4,
      "context" : "Several of the algorithmic tools and analysis techniques in this paper are similar in principle to (and sometimes appear indirectly in) work scattered throughout the machine learning and optimization literature – from classical treatments of error-tolerant PPA (Rockafellar, 1976; Guler, 1992) to the effective proximal term used by Accelerated Proximal SDCA Shalev-Shwartz and Zhang (2014) in enabling its acceleration.",
      "startOffset" : 261,
      "endOffset" : 293
    }, {
      "referenceID" : 4,
      "context" : "Several of the algorithmic tools and analysis techniques in this paper are similar in principle to (and sometimes appear indirectly in) work scattered throughout the machine learning and optimization literature – from classical treatments of error-tolerant PPA (Rockafellar, 1976; Guler, 1992) to the effective proximal term used by Accelerated Proximal SDCA Shalev-Shwartz and Zhang (2014) in enabling its acceleration.",
      "startOffset" : 281,
      "endOffset" : 391
    }, {
      "referenceID" : 4,
      "context" : "GD is Nesterov’s accelerated gradient decent (Nesterov, 1983, 2004), SVRG is the stochastic variance-reduced gradient of Johnson and Zhang (2013), SAG is the stochastic average gradient of Roux et al.",
      "startOffset" : 121,
      "endOffset" : 146
    }, {
      "referenceID" : 4,
      "context" : "GD is Nesterov’s accelerated gradient decent (Nesterov, 1983, 2004), SVRG is the stochastic variance-reduced gradient of Johnson and Zhang (2013), SAG is the stochastic average gradient of Roux et al. (2012) and Defazio et al.",
      "startOffset" : 121,
      "endOffset" : 208
    }, {
      "referenceID" : 3,
      "context" : "(2012) and Defazio et al. (2014), SDCA is the stochastic dual coordinate ascent of Shalev-Shwartz and Zhang (2013), AP-SDCA is the Accelerated Proximal SDCA of Shalev-Shwartz and Zhang (2014) and APCG is the accelerated coordinate algorithm of Lin et al.",
      "startOffset" : 11,
      "endOffset" : 33
    }, {
      "referenceID" : 3,
      "context" : "(2012) and Defazio et al. (2014), SDCA is the stochastic dual coordinate ascent of Shalev-Shwartz and Zhang (2013), AP-SDCA is the Accelerated Proximal SDCA of Shalev-Shwartz and Zhang (2014) and APCG is the accelerated coordinate algorithm of Lin et al.",
      "startOffset" : 11,
      "endOffset" : 115
    }, {
      "referenceID" : 3,
      "context" : "(2012) and Defazio et al. (2014), SDCA is the stochastic dual coordinate ascent of Shalev-Shwartz and Zhang (2013), AP-SDCA is the Accelerated Proximal SDCA of Shalev-Shwartz and Zhang (2014) and APCG is the accelerated coordinate algorithm of Lin et al.",
      "startOffset" : 11,
      "endOffset" : 192
    }, {
      "referenceID" : 3,
      "context" : "(2012) and Defazio et al. (2014), SDCA is the stochastic dual coordinate ascent of Shalev-Shwartz and Zhang (2013), AP-SDCA is the Accelerated Proximal SDCA of Shalev-Shwartz and Zhang (2014) and APCG is the accelerated coordinate algorithm of Lin et al. (2014). The latter three algorithms are more restrictive in that they only solve the explicitly regularized problem F + λr, even if F is itself strongly convex (such algorithms run in time inversely proportional to λ).",
      "startOffset" : 11,
      "endOffset" : 262
    }, {
      "referenceID" : 10,
      "context" : "The table also lists algorithms based on the randomized Kaczmarz method (Strohmer and Vershynin, 2009; Needell et al., 2014) and their accelerated variant (Lee and Sidford, 2013), as well as algorithms based on subspace embedding (OSNAP) or row sampling (Nelson and Nguyen, 2013; Li et al.",
      "startOffset" : 72,
      "endOffset" : 124
    }, {
      "referenceID" : 6,
      "context" : ", 2014) and their accelerated variant (Lee and Sidford, 2013), as well as algorithms based on subspace embedding (OSNAP) or row sampling (Nelson and Nguyen, 2013; Li et al.",
      "startOffset" : 38,
      "endOffset" : 61
    }, {
      "referenceID" : 11,
      "context" : ", 2014) and their accelerated variant (Lee and Sidford, 2013), as well as algorithms based on subspace embedding (OSNAP) or row sampling (Nelson and Nguyen, 2013; Li et al., 2013; Cohen et al., 2015).",
      "startOffset" : 137,
      "endOffset" : 199
    }, {
      "referenceID" : 7,
      "context" : ", 2014) and their accelerated variant (Lee and Sidford, 2013), as well as algorithms based on subspace embedding (OSNAP) or row sampling (Nelson and Nguyen, 2013; Li et al., 2013; Cohen et al., 2015).",
      "startOffset" : 137,
      "endOffset" : 199
    }, {
      "referenceID" : 2,
      "context" : ", 2014) and their accelerated variant (Lee and Sidford, 2013), as well as algorithms based on subspace embedding (OSNAP) or row sampling (Nelson and Nguyen, 2013; Li et al., 2013; Cohen et al., 2015).",
      "startOffset" : 137,
      "endOffset" : 199
    }, {
      "referenceID" : 15,
      "context" : "We remark that notions of error-tolerance in the typical proximal point algorithm – for both its plain and accelerated variants – have been defined and studied in prior work (Rockafellar, 1976; Guler, 1992).",
      "startOffset" : 174,
      "endOffset" : 206
    }, {
      "referenceID" : 4,
      "context" : "We remark that notions of error-tolerance in the typical proximal point algorithm – for both its plain and accelerated variants – have been defined and studied in prior work (Rockafellar, 1976; Guler, 1992).",
      "startOffset" : 174,
      "endOffset" : 206
    }, {
      "referenceID" : 1,
      "context" : "Additional related work There is an immense body of literature on proximal point methods and alternating direction method of multipliers (ADMM) that are relevant to the approach in this paper; see Boyd et al. (2011); Parikh and Boyd (2014) for modern surveys.",
      "startOffset" : 197,
      "endOffset" : 216
    }, {
      "referenceID" : 1,
      "context" : "Additional related work There is an immense body of literature on proximal point methods and alternating direction method of multipliers (ADMM) that are relevant to the approach in this paper; see Boyd et al. (2011); Parikh and Boyd (2014) for modern surveys.",
      "startOffset" : 197,
      "endOffset" : 240
    }, {
      "referenceID" : 1,
      "context" : "Additional related work There is an immense body of literature on proximal point methods and alternating direction method of multipliers (ADMM) that are relevant to the approach in this paper; see Boyd et al. (2011); Parikh and Boyd (2014) for modern surveys. We also note that the independent work of Lin et al. (2015) contains results similar to some of those in this paper.",
      "startOffset" : 197,
      "endOffset" : 320
    }, {
      "referenceID" : 9,
      "context" : "Instantiating this algorithm with an accelerated, regularized ERM solver – such as APCG (Lin et al., 2014) – as its inner minimizer yields the improved accelerated running time for the ERM problem (1).",
      "startOffset" : 88,
      "endOffset" : 106
    }, {
      "referenceID" : 5,
      "context" : "Instantiating this algorithm with SVRG (Johnson and Zhang, 2013) as its inner minimizer yields the improved accelerated running time for both the ERM problem (1) as well as the general ERM problem (2).",
      "startOffset" : 39,
      "endOffset" : 64
    }, {
      "referenceID" : 9,
      "context" : "Instantiating this algorithm with an accelerate, regularized ERM solver – such as APCG (Lin et al., 2014) – as its inner minimizer yields the improved accelerated running time for the ERM problem (1).",
      "startOffset" : 87,
      "endOffset" : 105
    }, {
      "referenceID" : 5,
      "context" : "SVRG (Johnson and Zhang, 2013) is a primal (c, λ)oracle with runtime complexity TP = O(ndmin{κ, κλ} log c) for both the ERM problem (1) and the general ERM problem (2).",
      "startOffset" : 5,
      "endOffset" : 30
    }, {
      "referenceID" : 9,
      "context" : "Using APCG (Lin et al., 2014) we can obtain a primal (c, λ)-oracle with runtime complexity TP = Õ(nd √ κλ log c) for the ERM problem (1).",
      "startOffset" : 11,
      "endOffset" : 29
    }, {
      "referenceID" : 5,
      "context" : "1 with SVRG (Johnson and Zhang, 2013) as the primal oracle and taking λ = 2μ + LR2 yields the running time bound Õ(nd √ κ log( 0/ )) for the general ERM problem (2).",
      "startOffset" : 12,
      "endOffset" : 37
    }, {
      "referenceID" : 9,
      "context" : "APCG (Lin et al., 2014) is a dual (c, λ)-oracle with runtime complexity TD = Õ(nd √ κλ log c).",
      "startOffset" : 5,
      "endOffset" : 23
    }, {
      "referenceID" : 5,
      "context" : "To match the terminology used for SVRG in Johnson and Zhang (2013), we refer to a “stage” as a single step of APPA, i.",
      "startOffset" : 42,
      "endOffset" : 67
    }, {
      "referenceID" : 14,
      "context" : "We then take take n/5 random Fourier features per the randomized scheme of Rahimi and Recht (2007). This yields 12K features for MNIST (60K training examples, 10K test) and 10K for CIFAR (50K training examples, 10K test).",
      "startOffset" : 75,
      "endOffset" : 99
    }, {
      "referenceID" : 5,
      "context" : "(See Johnson and Zhang (2013) for a comparison of SVRG to a more thoroughly tuned SGD under different decay schemes.",
      "startOffset" : 5,
      "endOffset" : 30
    } ],
    "year" : 2015,
    "abstractText" : "We develop a family of accelerated stochastic algorithms that minimize sums of convex functions. Our algorithms improve upon the fastest running time for empirical risk minimization (ERM), and in particular linear least-squares regression, across a wide range of problem settings. To achieve this, we establish a framework based on the classical proximal point algorithm. Namely, we provide several algorithms that reduce the minimization of a strongly convex function to approximate minimizations of regularizations of the function. Using these results, we accelerate recent fast stochastic algorithms in a black-box fashion. Empirically, we demonstrate that the resulting algorithms exhibit notions of stability that are advantageous in practice. Both in theory and in practice, the provided algorithms reap the computational benefits of adding a large strongly convex regularization term, without incurring a corresponding bias to the original problem.",
    "creator" : "LaTeX with hyperref package"
  }
}