{
  "name" : "1306.3203.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "Bregman Alternating Direction Method of Multipliers",
    "authors" : [ "Huahua Wang", "Arindam Banerjee" ],
    "emails" : [ "huwang@cs.umn.edu", "banerjee@cs.umn.edu" ],
    "sections" : [ {
      "heading" : null,
      "text" : "ar X\niv :1\n30 6.\n32 03\nv1 [\nm at\nh. O\nC ]\n1 3\nJu n"
    }, {
      "heading" : "1 Introduction",
      "text" : "In recent years, the alternating direction method of multipliers (ADM or ADMM) [4] has been successfully applied in a broad spectrum of applications, ranging from image processing [11, 1, 13] to applied statistics and machine learning [23, 27, 20, 26]. The proof of global convergence of ADMM can be found in [12, 4]. Recently, it has been shown that ADMM converges at a rate of O(1/T ) [26, 16], where T is the number of iterations. For strongly convex functions, the dual objective of an accelerated version of ADMM can converge at a rate of O(1/T 2) [14]. Under suitable assumptions like strongly convex functions or a sufficiently small step size for the dual variable update, ADMM can achieve a linear convergence rate [8, 21]. For further understanding of ADMM, we refer the readers to the comprehensive review by [4] and references therein.\nIn particular, ADMM considers the problem of minimizing composite objective functions subject to an equality constraint:\nmin x∈X ,z∈Z f(x) + g(z) s.t. Ax+Bz = c , (1)\nwhere f and g are convex functions, A ∈ Rm×n1 ,B ∈ Rm×n2 , c ∈ Rm×1, x ∈ X ∈ Rn1×1, z ∈ Z ∈ Rn2×1, and X and Z are convex sets. f and g can be non-smooth functions, including indicator functions of convex sets. Many machine learning problems can be cast into the framework of\nminimizing a composite objective [22, 10], where f is a loss function such as hinge or logistic loss, and g is a regularizer, e.g., ℓ1 norm, ℓ2 norm, nuclear norm or total variation. The two functions usually have different structures and constraints because they have different tasks in data mining. Therefore, it is useful and sometimes necessary to split them and solve them separately, which is exactly the forte of ADMM.\nIn each iteration, ADMM updates splitting variables separately and alternatively by solving the augmented Lagrangian of (1), which is defined as follows:\nLρ(x, z,y) = f(x) + g(z) + 〈y,Ax+Bz− c〉+ ρ\n2 ‖Ax+Bz− c‖22, (2)\nwhere y ∈ Rm is dual variable, ρ > 0 is penalty parameter, and the quadratic penalty term is to penalize the violation of the equality constraint. ADMM consists of the following three updates:\nxt+1 = argmin x∈X\nf(x) + 〈yt,Ax+Bzt − c〉+ ρ\n2 ‖Ax+Bzt − c‖22 , (3)\nzt+1 = argmin z∈Z\ng(z) + 〈yt,Axt+1 +Bz− c〉+ ρ\n2 ‖Axt+1 +Bz− c‖22 , (4)\nyt+1 = yt + ρ(Axt+1 +Bzt+1 − c) . (5)\nSince the computational complexity of y update (5) is trivial, the computational complexity of ADMM lies in the x and z updates (3)-(4) which amount to solving proximal minimization problems using the quadratic penalty term. Inexact ADMM [4] and generalized ADMM [8] have also been proposed to solve the updates inexactly by linearizing the functions and adding additional quadratic terms. As far as we know, all existing ADMMs use quadratic penalty terms1.\nRecent work shows that replacing the quadratic penalty term by Bregman divergence could effectively exploit the structure of problems [6, 3, 10], particularly in clustering problems and exponential family distributions [2, 25]. Mirror descent algorithm (MDA) and composite objective mirror descent (COMID) [10] use Bregman divergence to replace the quadratic term in gradient descent or proximal gradient [7]. In particular, if the Bregman divergence is Kullback-Leibler (KL) divergence, MDA leads to exponentiated gradient or multiplicative update algorithms which performs better than additive update in gradient descent in some applications [18]. Proximal point method with D-functions (PMD) [6, 5] and Bregman proximal minimization (BPM) [19] generalize proximal point method by using Bregman divegence to replace the quadratic term. However, as pointed out by [4], “There is currently no proof of convergence known for ADMM with nonquadratic penalty terms.”\nIn this paper, we propose Bregman ADMM (BADMM) where Bregman divergences are used in ADMM updates and establish the global convergence for BADMM. In particular, we show the quadratic penalty term in the x and z updates (3)-(4) can be replaced by a Bregman divergence, which answers the question raised in [4]. Since functions (f and g) and constraints (X and Z) usually have different structures, we may not have efficient algorithms by simply using the same Bregman divergence in the x and z updates. To allow the use of different Bregman divergences in\n1An exception is online ADMM [26], where the x update keeps the quadratic penalty term ‖Ax +Bz − c‖2 2 and has an additional Bregman divergence.\nBADMM, we introduce additional Bregman divergences in the x and z updates. BADMM provides a unified framework for solving (1), which allows one to choose suitable Bregman divergence so that the x and z updates can be solved efficiently. BADMM includes ADMM and its variants as special cases. In particular, BADMM replaces all quadratic terms in generalized ADMM [8] with Bregman divergences. By choosing a proper Bregman divergence, we also show that inexact ADMM can be considered as a special case of BADMM. BADMM generalizes ADMM similar to how MDA generalizes gradient descent and how PMD generalizes proximal methods. In BADMM, the x and z updates can take the form of MDA or PMD. In particular, BADMM updates become alternating additive updates when using quadratic functions and alternating multiplicative updates when using KL divergence. More generally,\nA motivating example to use BADMM is minimization over doubly stochastic matrices. Classical methods like MDA include the full projection onto doubly stochastic matrices in each iteration, which require alternating projections like the Sinkhorn algorithm [24]. By splitting doubly stochastic matrix into row stochastic matrix and column stochastic matrix, we can use BADMM to solve it. When using quadratic penalty terms, the x and z updates require doing Euclidean projections onto the unit simplex [9]. When using KL divergence, BADMM leads to a projectionfree alternating multiplicative updates which amount to elementwise operation and can be done in parallel.\nThe rest of the paper is organized as follows. In Section 2, we propose Bregman ADMM and discuss several special cases of BADMM. In Section 3, we establish the convergence of BADMM. In Sections 4, we consider an illustrative application of minimization over doubly stochastic matrices, and conclude in Section 5."
    }, {
      "heading" : "2 Bregman Alternating Direction Method of Multipliers",
      "text" : "Let φ : Ω → R be a continuously differentiable and strictly convex function on the relative interior of a convex set Ω. Denote ∇φ(y) as the gradient of φ at y. We define Bregman divergence2 Bφ : Ω× ri(Ω) → R+ induced by φ as\nBφ(x,y) = φ(x)− φ(y)− 〈∇φ(y),x− y〉 .\nSince φ is convex, Bφ(x,y) ≥ 0 where the equality holds if and only if x = y. More details about Bregman divergence can be found in [6, 2]. Two of the most commonly used examples are squared Euclidean distance Bφ(x,y) = 12‖x− y‖22 and KL divergence Bφ(x,y) = ∑n i=1 xi log xi yi\n. Assuming Bφ(c −Ax,Bz) is well defined, we replace the quadratic penalty term in the aug-\nmented Lagrangian (2) by a Bregman divergence as follows:\nLφρ(x, z,y) = f(x) + g(z) + 〈y,Ax+Bz− c〉+ ρBφ(c−Ax,Bz). (6)\nUnfortunately, we can not derive Bregman ADMM (BADMM) updates by simply solvingLφρ(x, z,y) alternatingly as ADMM does because Bregman divergence is generally not symmetric. More\n2The definition of Bregman divergence has been generalized to nondifferentiable functions [19, 25].\nspecifically, given yt and zt, xt+1 can be obtained by solving Lφρ(x, zt,yt) as ADMM does. In other words, the quadratic penalty term 1\n2 ‖Ax+Bzt−c‖22 in (3) is replaced with Bφ(c−Ax,Bzt)\nin the x update of BADMM. However, we cannot get zt+1 by solving Lφρ(xt+1, z,yt), since Lφρ(xt+1, z,yt) contains the term Bφ(c−Axt+1,Bz) which is not convex in z. Instead, the z update of BADMM uses Bφ(Bz, c−Axt+1) to replace the quadratic penalty term 12‖Axt+1 +Bz− c‖22 in (3). It is worth noting that the same Bregman divergence Bφ is used in the x and z updates. To allow the use of different Bregman divergences, additional Bregman divergences are introduced in the x and z updates, which give more options for solving them efficiently. Therefore, we formally propose the following updates for BADMM:\nxt+1 = argmin x∈X\nf(x) + 〈yt,Ax+Bzt − c〉+ ρBφ(c−Ax,Bzt) + ρxBϕx(x,xt) , (7)\nzt+1 = argmin z∈Z\ng(z) + 〈yt,Axt+1 +Bz− c〉+ ρBφ(Bz, c−Axt+1) + ρzBϕz(z, zt) , (8)\nyt+1 = yt + τ(Axt+1 +Bzt+1 − c) . (9)\nwhere ρ > 0, τ > 0, ρx ≥ 0, ρz ≥ 0. Note that three Bregman divergences are used in BADMM. If all three of them are quadratic functions, Bregman ADMM reduces to generalized ADMM [8]. We allow the use of a different step size τ in the dual variable update [8, 21]. The global convergence for BADMM will be shown in Section 3.\nWe will discuss some special cases in two scenarios. In scenario 1 where ρx, ρz are zero, BADMM simply replaces the quadratic penalty term in ADMM by a single Bregman divergence. In this scenario, the x and z updates should be solved exactly. In scenario 2 where one or both of ρx, ρz are positive, we can choose different Bregman divergences in the x and z updates so that they can be solved inexactly. Compared to scenario 1, scenario 2 usually takes more iterations to converge but may be less expensive in solving the x and z updates. Since (7) and (8) are symmetric, the discussion below focuses on the x update, and can be applied for the z update. As a gentle reminder, the global convergence for BADMM in Section 3 automatically applies for the special cases considered here."
    }, {
      "heading" : "2.1 Scenario 1: Exact BADMM Update",
      "text" : "If ρx = ρz = 0, BADMM simply uses a single Bregman divergence to replace the quadratic penalty term in ADMM. This scenario is particularly useful when a single Bregman divergence φ can yield efficient algorithms for both the x and z updates.\nIn a special case, like consensus optimization [4], when A = −I,B = I, c = 0, (7) becomes\nxt+1 = argmin x∈X\nf(x) + 〈yt,−x+ zt〉+ ρBφ(x, zt) . (10)\nThis special case is similar to Case 2 in Scenario 2. Further, if f is a linear function and X is the unit simplex, we have multiplicative update when using KL divergence. If the z update is also a multiplicative update, we have alternating multiplicative updates. In Section 4, we will show the minimization over doubly stochastic matrices can be cast into this scenario."
    }, {
      "heading" : "2.2 Scenario 2: Inexact BADMM Update",
      "text" : "This scenario is particularly useful when it is expensive to solve the x update exactly in Scenario 1. Instead, we solve the x update inexactly by adding another Bregman divergence Bϕx . Since there are two Bregman divergences Bφ and Bϕx in the x update (7) and Bφ is also used in the z update, we set Bφ to be a quadratic term in this scenario, which is easy to be linearized and does not need any assumptions on A and B. Bregman divergence Bϕx can be be selected so that (7) can be solved efficiently.\nIn the following three special cases, we will show that the x update can be solved efficiently by linearizing some terms, say, ψx. Let Bψx be the Bregman divergence defined on ψx. We denote the sum of βxBψx and Bϕx as a new Bregman divegence Bϕ′x , i.e., Bϕ′x = Bϕx +βxBψx . Using the linearity of Bregman divergence, ϕ′x = ϕx + βxψx. In other words, we assume ϕx = ϕ ′ x − βxψx. The following three cases show such a choice of ϕx can solve (7) efficiently. Case 1: Linearization of function f 3 Assume f is continuously differentiable and strictly convex defined on the convex set X . Let ∇f(xt) be the gradient of f(x) at xt. Bregman divergence Bf 4 induced by f is defined as\nBf(x,xt) = f(x)− f(xt)− 〈∇f(xt),x− xt〉 , (11)\nwhich can be considered as high order residuals in Taylor expansion of f at xt. Therefore, the linearization of f(x) at xt can be done by removing Bf(x,xt) from f(x), i.e.,\nf(x)−Bf (x,xt) = f(xt) + 〈∇f(xt),x− xt〉 . (12)\nLet Bϕx(x,xt) = Bϕ′x(x,xt)− 1ρxBf (x,xt). Removing constant terms, (7) becomes\nxt+1 = argmin x∈X\n〈∇f(xt),x− xt〉+ 〈yt,Ax〉+ ρBφ(c−Ax,Bzt) + ρxBϕ′ x (x,xt) . (13)\nThis case is particularly useful when the difficulty of solving (3) is caused by f(x), e.g., when f is a logistic loss function.\nExample 1 Consider the following ADMM form sparse logistic regression problem [15, 4]:\nmin x\nl(x) + λ‖z‖1 , s.t. x = z (14)\nwhere l(x) is the logistic function. If we use ADMM to solve (14), the x update is as follows [4]:\nxt+1 = argmin x\nl(x) + 〈yt,x− zt〉+ ρ\n2 ‖x− zt‖22 , (15)\n3If f can be decomposed into a differentiable function and a nonsmooth function, we can simply linearize the differentiable part.\n4In general, f is not necessarily differentiable. Let f be relatively differentiable, xt ∈ ri(dom(f)) and f ′(xt) ∈ ∂f(xt). The generalized Bregman divegence is Bf (x,xt) = f(x)− f(xt)− 〈f ′(xt),x − xt〉 [25].\nwhich is an ℓ2 regularized logistic regression problem and requires a loop algorithm like L-BFGS to solve it. Instead, if we linearize l(x) at xt and set Bφ to be a quadratic function, we have\nxt+1 = argmin x\n〈∇l(xt),x− xt〉+ 〈yt,x− zt〉+ ρ\n2 ‖x− zt‖22 + ρx 2 ‖x− xt‖22 , (16)\nthe x update has a simple closed-form solution.\nCase 2: Linearization of the quadratic penalty term Set Bφ(c − Ax,Bzt) = 12‖Ax + Bzt − c‖22, which contains ‖Ax‖22. The linearization of the quadratic penalty term can be done by removing ‖Ax‖22 as follows:\n‖Ax+Bzt − c‖22 − ‖A(x− xt)‖22 = 2〈Axt +Bzt − c,Ax〉+ ‖Bzt − c‖22 − ‖Axt‖22 .\nLet Bϕx(x,xt) = Bϕ′x(x,xt)− ρ 2ρx ‖A(x− xt)‖22. Removing constant terms, (7) becomes\nxt+1 = argmin x∈X\nf(x) + 〈yt + ρ(Axt +Bzt − c),Ax〉+ ρxBϕ′ x (x,xt) . (17)\nCompared to (10) where A = −I,B = I and c = 0 in Scenario 1, (17) is more general. However, (17) requires the linearization of the quadratic penalty term and solving the z update inexactly.\nThis case mainly solves the problem caused by A, e.g., Ax makes x nonseparable. Several problems have been benefited from the linearization of quadratic term [8], e.g., f is ℓ1 loss function [15] and projection onto the unit simplex or ℓ1 ball [9].\nExample 2 Consider the following x update:\nxt+1 = argmin x\n〈b,x〉+ 〈yt,Ax− zt〉+ ρ\n2 ‖Ax− zt‖22 , s.t. xi ≥ 0,\nn ∑\ni=1\nxi = 1 , (18)\nwhere we assume f(x) = 〈b,x〉 is a linear function. (18) amounts to the Euclidean projection onto the unit simplex. If A = I, the projection can be done by an efficient algorithm [9]. In general, we do not have an efficient algorithm to solve (18). However, if we linearize the quadratic term and add KL divergence such that\nxt+1=argmin x\n〈b+ATyt+ρAT (Axt−zt),x〉+ρxKL(x,xt) , s.t. xi ≥ 0, n ∑\ni=1\nxi = 1 , (19)\nthe x update has a closed-form solution.\nCase 3: Mirror Descent In this case, we linearize both the function and the quadratic term. Let Bϕx(x,xt) = Bϕ′x(x,xt)− 1ρxBf(x,xt)− ρ 2ρx ‖A(x− xt)‖22. Combining the results in Case 1 and 2, (7) becomes\nxt+1 = argmin x∈X\n〈F (xt),x〉+ ρxBϕ′ x (x,xt) , (20)\nwhere F (xt) = ∇f(xt) +AT{yt + ρ(Axt +Bzt − c)}, which is the gradient of the objective in (3). (20) is a MDA-type update.\nExample 3 Consider the x update(18) for a logistic loss function:\nxt+1 = argmin x\nl(x) + 〈yt,Ax− zt〉+ ρ\n2 ‖Ax− zt‖22 , s.t. xi ≥ 0,\nn ∑\ni=1\nxi = 1 (21)\nwhere l(x) is the logistic function. We do not have an efficient algorithm for (21) by using the strategy either in Case 1 or Case 2. If we linearize the objective in (21) and add KL divergence, the x update has a closed-form solution.\nIf (8) can also be written in a similar MDA-type update, BADMM behaves like alternating mirror descent. If both Bregman divergences are quadratic function, BADMM leads to alternating additive updates. If both Bregman divergences are KL divergence and X ,Z are unit simplex, BADMM leads to alternating multiplicative updates. If one is quadratic function and the other is KL-divergence, we have alternating additive-multiplicative updates.\nThe three special cases depend on the decomposition Bϕx = Bϕ′x − βxBψx , where ψx is the term to be linearized. The nonnegativeness of Bϕx implies that Bϕ′x ≥ βxBψx . We now show this condition can be satisfied by assuming that ϕ′x is strongly convex and ψx has Lipschitz continuous gradient, which are generally used in MDA and COMID. Assume ψx is ν-strongly smooth w.r.t. a p-norm, i.e., ψx(u) ≤ ψx(v) + 〈∇ψx(v),u − v〉 + ν2‖u − v‖2p. According to the definition of Bregman divergence, Bψx(u,v) ≤ ν2‖u− v‖2p. If ϕ′x is βxν-strongly convex w.r.t. the p-norm, we have Bϕ′\nx (u,v) ≥ βxν 2 ‖u− v‖2p. Therefore, Bϕ′x ≥ βxBψx holds."
    }, {
      "heading" : "3 Convergence Analysis of BADMM",
      "text" : "In this section, we first discuss the assumptions required in the convergence analysis of BADMM. Then we establish the global convergence for BADMM. Finally, we show O(1/T ) convergence rate for the objective and residual of equality constraint.\nWe need the following assumption in establishing the convergence of BADMM:\nAssumption 1 (a) f : Rn1 → R ∪ {+∞} and g : Rn2 → R ∪ {+∞} are closed, proper and convex5. (b) An optimal solution exists. (c) The Bregman divergence Bφ is defined on an α-strongly convex function φ with respect to a p-norm ‖ · ‖2p, i.e., Bφ(u,v) ≥ α2‖u− v‖2p, where alpha > 0.\nWe start wth the Lagrangian of (1), which is defined as follows:\nL(x,y, z) = f(x) + g(z) + 〈y,Ax+Bz− c〉. (22) 5f is assumed to be relatively differentiable [25] when we define a generalied Bregman divegence Bf in Case 1 of\nScenario 2 in Section 2.\nAssume that {x∗, z∗,y∗} satisfies the KKT conditions of (22), i.e.,\n−ATy∗ ∈ ∂f(x∗) , (23) −BTy∗ ∈ ∂g(z∗) , (24)\nAx∗ +Bz∗ − c = 0 . (25)\n{x∗, z∗,y∗} is an optimal solution. The optimality conditions of (7) and (8) are\n−AT{yt + ρ(−∇φ(c−Axt+1) +∇φ(Bzt)} − ρx(∇ϕx(xt+1)−∇ϕx(xt)) ∈ ∂f(xt+1) , (26) −BT{yt + ρ(∇φ(Bzt+1)−∇φ(c−Axt+1)} − ρz(∇ϕz(zt+1)−∇ϕz(zt)) ∈ ∂g(zt+1) . (27)\nIf Axt+1+Bzt+1 = c, then yt+1 = yt. Therefore, (23) is satisfied if Axt+1+Bzt = c ,xt+1 = xt in (26). Similarly, (24) is satisfied if zt+1 = zt in (27). Overall, the KKT conditions (23)-(25) are satisfied if the following optimality conditions are satisfied:\nxt+1 − xt = 0 , zt+1 − zt = 0 , Axt+1 +Bzt − c = 0 , Axt+1 +Bzt+1 − c = 0 . (28)\nIn Scenario 1, ρx = ρz = 0 in (7) and (8), we have the following optimality conditions:\nAxt+1 +Bzt − c = 0 , Axt+1 +Bzt+1 − c = 0 , (29)\nwhich are a subset of conditions of (28). Define the residuals of optimality conditions (28) at (t+1) as:\nR(t+ 1)= ρx ρ Bϕx(xt+1,xt)+ ρz ρ Bϕz(zt+1,zt)+Bφ(c−Axt+1,Bzt)+γ‖Axt+1+Bzt+1−c‖22 , (30)\nwhere γ > 0. If R(t+1) = 0, the optimality conditions (28) and (29) are satisfied. It is sufficient to show the convergence of BADMM by showing R(t+1) converges to zero. We need the following lemma.\nLemma 1 Let the sequence {xt, zt,yt} be generated by Bregman ADMM (7)-(9). For any x∗, z∗ satisfying Ax∗ +Bz∗ = c, we have\nf(xt+1) + g(zt+1)− (f(x∗) + g(z∗)) ≤ −〈yt,Axt+1 +Bzt+1 − c〉 − ρ(Bφ(c−Axt+1,Bzt) +Bφ(Bzt+1, c−Axt+1)) + ρ(Bφ(Bz\n∗,Bzt)− Bφ(Bz∗,Bzt+1)) + ρx(Bϕx(x∗,xt)− Bϕx(x∗,xt+1)−Bϕx(xt+1,xt)) + ρz(Bϕz(z ∗, zt)− Bϕz(z∗, zt+1)− Bϕz(zt+1, zt)) . (31)\nProof: Using the convexity of f and its subgradient given in (26), we have\nf(xt+1)− f(x) ≤ 〈−AT{yt + ρ(−∇φ(c−Axt+1) +∇φ(Bzt)} − ρx(∇ϕx(xt+1)−∇ϕx(xt)),xt+1 − x〉 = −〈yt,A(xt+1 − x)〉+ ρ〈∇φ(c−Axt+1)−∇φ(Bzt),A(xt+1 − x)〉 − ρx〈∇ϕx(xt+1)−∇ϕx(xt),xt+1 − x〉 . (32)\nSetting x = x∗ and using Ax∗ +Bz∗ = c, we have\nf(xt+1)− f(x∗) ≤ −〈yt,Axt+1 +Bz∗ − c〉+ ρ〈∇φ(c−Axt+1)−∇φ(Bzt),Bz∗ − (c−Axt+1)〉 − ρx〈∇ϕx(xt+1)−∇ϕx(xt),xt+1 − x〉 = −〈yt,Axt+1 +Bz∗ − c〉+ ρ(Bφ(Bz∗,Bzt)− Bφ(Bz∗, c−Axt+1)−Bφ(c−Axt+1,Bzt)) + ρx(Bϕx(x ∗,xt)− Bϕx(x∗,xt+1)−Bϕx(xt+1,xt)) . (33)\nwhere the last equality uses the three point property of Bregman divergence, i.e.,\n〈∇φ(u)−∇φ(v),w− u〉 = Bφ(w,v)−Bφ(w,u)− Bφ(u,v) . (34)\nSimilarly, using the convexity of g and its subgradient given in (27), for any z,\ng(zt+1)− g(z) ≤ 〈−BT{yt + ρ(∇φ(Bzt+1)−∇φ(c−Axt+1)} − ρz(∇ϕz(zt+1)−∇ϕz(zt)), zt+1 − z〉 = −〈yt,B(zt+1 − z)〉+ ρ〈∇φ(Bzt+1)−∇φ(c−Axt+1),Bz−Bzt+1)〉 − ρz〈∇ϕz(zt+1)−∇ϕz(zt), zt+1 − z〉 = −〈yt,B(zt+1 − z)〉+ ρ {Bφ(Bz, c−Axt+1)− Bφ(Bz,Bzt+1)−Bφ(Bzt+1, c−Axt+1)} + ρz(Bϕz(z, zt)− Bϕz(z, zt+1)− Bϕz(zt+1, zt)) . (35)\nwhere the last equality uses the three point property of Bregman divergence (34). Set z = z∗ in (35). Adding (33) and (35) completes the proof.\nUnder Assumption 1(c), the following lemma shows that (30) is bounded by a telescoping series of D(w∗,wt)−D(w∗,wt+1), where D(w∗,wt) defines the distance from the current iterate wt = (xt, zt,yt) to a KKT point w∗ = (x∗, z∗,y∗) as follows:\nD(w∗,wt)= 1\n2τρ ‖y∗−yt‖22+Bφ(Bz∗,Bzt)+ ρx ρ Bϕx(x ∗,xt)+ ρz ρ Bϕz(z ∗, zt) . (36)\nLemma 2 Let the sequence {xt, zt,yt} be generated by Bregman ADMM (7)-(9) and {x∗, z∗,y∗} satisfying (23)-(25). Let the Assumption 1 hold. R(t + 1) and D(w∗,wt) are defined in (30) and (36) respectively. Set τ ≤ (ασ − 2γ)ρ, where σ = min{1, m 2p−1} and 0 < γ < ασ 2 . Then\nR(t + 1) ≤ D(w∗,wt)−D(w∗,wt+1) . (37)\nProof: Assume {x∗,y∗} satisfies (23). Since f is convex, then\nf(x∗)− f(xt+1) ≤ −〈ATy∗,x∗ − xt+1〉 = −〈y∗,Ax∗ −Axt+1〉 . (38)\nSimilarly, for convex function g and {z∗,y∗} satisfying (24), we have\ng(z∗)− g(zt+1) ≤ −〈BTy∗, z∗ − zt+1〉 = −〈y∗,Bz∗ −Bzt+1〉 . (39)\nAdding them together and using the fact that Ax∗ +Bz∗ = c, we have\nf(x∗) + g(z∗)− (f(xt+1) + g(zt+1)) ≤ 〈y∗,Axt+1 +Bzt+1 − c〉 . (40)\nAdding (40) and (31) together yields\n0 ≤ 〈y∗ − yt,Axt+1 +Bzt+1 − c〉 − ρ(Bφ(c−Axt+1,Bzt) +Bφ(Bzt+1, c−Axt+1)) + ρ(Bφ(Bz\n∗,Bzt)− Bφ(Bz∗,Bzt+1)) + ρx(Bϕx(x∗,xt)− Bϕx(x∗,xt+1)−Bϕx(xt+1,xt)) + ρz(Bϕz(z ∗, zt)− Bϕz(z∗, zt+1)− Bϕz(zt+1, zt)) . (41)\nUsing Axt+1 +Bzt+1 − c = 1τ (yt+1 − yt), the first term can be rewritten as\n〈y∗ − yt,Axt+1 +Bzt+1 − c〉 = 1\nτ 〈y∗ − yt,yt+1 − yt〉\n= 1\n2τ\n( ‖y∗ − yt‖22 − ‖y∗ − yt+1‖22 + ‖yt+1 − yt‖22 )\n= 1\n2τ\n( ‖y∗ − yt‖22 − ‖y∗ − yt+1‖22 )\n+ τ\n2 ‖Axt+1 +Bzt+1 − c‖22 . (42)\nPlugging into (41) and rearranging the terms, we have\n1\n2τ\n( ‖y∗ − yt‖22 − ‖y∗ − yt+1‖22 ) + ρ(Bφ(Bz ∗,Bzt)− Bφ(Bz∗,Bzt+1))\nρx(Bϕx(x ∗,xt)− Bϕx(x∗,xt+1)) + ρz(Bϕz(z∗, zt)− Bϕz(z∗, zt+1))\n≥ ρxBϕx(xt+1,xt) + ρzBϕz(zt+1, zt) + ρBφ(c−Axt+1,Bzt) + ρBφ(Bzt+1, c−Axt+1)− τ\n2 ‖Axt+1 +Bzt+1 − c‖22 . (43)\nDividing both sides by ρ and letting R(t + 1) and D(w∗,wt) be defined in (30) and (36) respectively, we have\nD(w∗,wt)−D(w∗,wt+1)≥R(t + 1)+Bφ(Bzt+1, c−Axt+1)−( τ\n2ρ + γ)‖Axt+1 +Bzt+1 − c‖22\n≥ R(t + 1) + α 2 ‖Axt+1 +Bzt+1 − c‖2p − ( τ 2ρ + γ)‖Axt+1 +Bzt+1 − c‖22 , (44)\nwhere the last inequality uses the Assumption 1(c). If 0 < p ≤ 2, ‖u‖p ≥ ‖u‖2. Set α2 ≥ τ2ρ + γ in (44), i.e., τ ≤ (α− 2γ)ρ. We can always find a γ < α 2 , thus (37) follows.\nIf p > 2, ‖u‖2 ≤ m 1 2 − 1 p ‖u‖p for any u ∈ Rm×1, so ‖u‖2p ≥ m 2 p −1‖u‖22. In (44), set α2m 2 p −1 ≥\nτ 2ρ + γ, i.e., τ ≤ (αm 2p−1 − 2γ)ρ. As long as γ < α 2 m 2 p −1, we have (37).\nRemark 1 (a) If 0 < p ≤ 2, then σ = 1 and τ ≤ (α−2γ)ρ. The case that 0 < p ≤ 2 includes two widely used Bregman divergences, i.e., Euclidean distance and KL divergence. For KL divergence in the unit simplex, we have α = 1, p = 1 in the Assumption 1 (c), i.e., KL(u,v) ≥ 1\n2 ‖u−v‖21 [3].\n(b) Since we often set Bφ to be a quadratic function (p = 2) in Scenario 2 in Section 2, the three special cases in Scenario 2 could choose step size τ = (α− 2γ)ρ.\n(c) If p > 2, the proof requires a sufficiently small step size τ , which may not be needed in practice. It would be interesting to see whether we can use a same τ = O(ρ) for any p > 0 using other proof techniques. In appendix A, under the assumption that yt is bounded, BADMM requires choosing a large step size τ = O( √ T ).\nThe following theorem establishes the global convergence for BADMM.\nTheorem 1 Let the sequence {xt, zt,yt} be generated by Bregman ADMM (7)-(9) and {x∗, z∗,y∗} satisfying (23)-(25). Let the Assumption 1 hold and τ, γ satisfy the conditions in Lemma 2. Then R(t+ 1) converges to zero and {xt, zt,yt} converges to a KKT point {x∗, z∗,y∗} of (1). Proof: Since R(t + 1) ≥ 0, (37) implies D(w∗,wt+1) ≤ D(w∗,wt). Therefore, D(w∗,wt) is monotonically nonincreasing and wt converges to a KKT point w∗. Summing (37) over t from 0 to ∞ yields\n∞ ∑\nt=0\nR(t+ 1) ≤ D(w∗,w0) . (45)\nSince R(t + 1) ≥ 0, R(t+ 1) → 0 as t → ∞, which completes the proof.\nRemark 2 Under the assumption that yt is bounded, R(t + 1) converges to zero when choosing ρx = ρz = c1 √ T , τ = c2 √ T , ρ = √ T for some positive constants c1, c2, which is shown in Theorem 3 on Appendix A.\nThe following theorem establishs a O(1/T ) convergence rate for the objective and residual of constraints in an ergodic sense.\nTheorem 2 Let the sequences {xt, zt,yt} be generated by Bregman ADMM (7),(8),(9). Let x̄T = 1 T ∑T t=1 xt, z̄T = 1 T ∑T t=1 zt. Set τ ≤ (ασ − 2γ)ρ, where σ = min{1, m 2 p −1} and 0 < γ < ασ 2 . For any (x∗, z∗,y∗) satisfying KKT conditions (23)-(25), we have\nf(x̄T ) + g(z̄T )− (f(x∗) + g(z∗)) ≤ D1 T , (46) γ‖Ax̄T +Bz̄T − c‖22 ≤ D(w∗,w0)\nT , (47)\nwhere D1 = 12τ ‖y0‖22 + ρBφ(Bz∗,Bz0) + ρxBϕx(x∗,x0) + ρzBϕz(z∗, z0). Proof: Using (9), we have\n−〈yt,Axt+1 +Bzt+1 − c〉 = − 1\nτ 〈yt,yt+1 − yt〉\n= − 1 2τ (‖yt+1‖22 − ‖yt‖22 − ‖yt+1 − yt‖22) = 1\n2τ (‖yt‖22 − ‖yt+1‖22) +\nτ 2 ‖Axt+1 +Bzt+1 − c‖22 . (48)\nPlugging into (31) and ignoring some negative terms yield\nf(xt+1) + g(zt+1)− (f(x∗) + g(z∗))\n≤ 1 2τ (‖yt‖22 − ‖yt+1‖22) + ρ(Bφ(Bz∗,Bzt)− Bφ(Bz∗,Bzt+1)) + ρx(Bϕx(x∗,xt)−Bϕx(x∗,xt+1))\n+ρz(Bϕz(z ∗, zt)−Bϕz(z∗, zt+1))−ρBφ(Bzt+1, c−Axt+1)+\nτ 2 ‖Axt+1+Bzt+1−c‖22 . (49)\nAssume Bφ(Bzt+1, c−Axt+1) ≥ α2‖Axt+1 +Bzt+1 − c‖2p. If 0 < p ≤ 2, using ‖u‖p ≤ ‖u‖2,\n−ρBφ(Bzt+1, c−Axt+1) + τ\n2 ‖Axt+1 +Bzt+1 − c‖22 ≤ − αρ− τ 2 ‖Axt+1 +Bzt+1 − c‖22 .\nSetting τ ≤ (α− 2γ)ρ, the last two terms on the right hand side of (49) can be removed. If p > 2, ‖u‖2 ≤ m 1 2 − 1 p‖u‖p for any u ∈ Rm×1, so ‖u‖2p ≥ m 2 p −1‖u‖22. Then\n−ρBφ(Bzt+1, c−Axt+1) + τ\n2 ‖Axt+1 +Bzt+1 − c‖22 ≤ −\nαρm 2 p −1 − τ 2 ‖Axt+1 +Bzt+1 − c‖22 .\nSetting τ ≤ (αm 2p−1 − 2γ)ρ, the last two terms on the right hand side of (49) can be removed. Summing over t from 0 to T − 1, we have the following telescoping sum\nT−1 ∑\nt=0\n[f(xt+1) + g(zt+1)− (f(x∗) + g(z∗))]\n≤ 1 2τ ‖y0‖22 + ρBφ(Bz∗,Bz0) + ρxBϕx(x∗,x0) + ρz(Bϕz(z∗, z0) . (50)\nDividing both sides by T and applying the Jensen’s inequality gives (46). Dividing both sides of (45) by T and applying the Jensen’s inequality yield (47).\nRemark 3 Under the assumption that yt is bounded, the objective converges at a rate of O(1/ √ T )\nwhen setting ρx, ρz, τ, ρ = O( √ T ), which is established in Theorem 4 in Appendix A."
    }, {
      "heading" : "4 Application: Doubly Stochastic Matrices",
      "text" : "In this section, as an illustrative example, we consider the problem of minimizing a loss function of a doubly stochastic matrix, which has been studied in spectral clustering [28] and learning permutations [17]. The class of n × n doubly stochastic matrices is a convex polytope known as the Birkhoff polytope Bn. In particular, we consider the following problem:\nmin 〈L,P〉 s.t. P ∈ Bn = {P|P ≥ 0, eTP = e,Pe = e} , (51)\nwhere 〈L,P〉 denotes Tr(LTP), L ∈ Rn×n is a loss matrix, Bn denotes the Birkhoff polytope and e is a column vector of ones.\nTo solve this problem, we can use MDA which has the following update:\nPt+1 = argminP∈Bn 〈L,P〉+ ρBφ(P,Pt) . (52)\nIn (52), simply choosing a Bregman divergence does not yield efficient projection onto the Birkhoff polytope. Since Bn contains the structure of the unit simplex (P ≥ 0, eTP = e), we use KL divergence in (52) which yields a multiplicative update. As a result, MDA leads to a double-loop algorithm which has the following two steps:\nP t+ 1 2\nij = P t ij exp(−\n1 ρ Lij) , P t+1 = ΠBn(P t+ 1 2 ) . (53)\nwhere ΠBn denotes the projection back onto Birkhoff polytope which can be solved using Sinkhorn algorithm [24, 17].\nThe projection in (53) requires a loop algorithm which normalizes columns and rows to 1 repeatedly and alternatingly until convergence. We now show this iterative step can be avoided using splitting variables. We split Bn into column stochastic matrices Bcn = {Pc|Pc ≥ 0, eTPc = e} and row stochastic matrices Brn = {Pr|Pr ≥ 0,Pre = e}. (51) can be rewritten in the following ADMM form:\nmin 〈L,Pc〉 s.t. Pc ∈ Bcn,Pr ∈ Brn,Pc = Pr . (54)\nWe can solve (54) using ADMM which has the following updates:\nPt+1c = argminPc∈Bcn〈L,Pc〉+ 〈Q t,Pc −Ptr〉+\nρ 2 ‖Pc −Ptr‖22 , (55)\nPt+1r = argminPr∈Brn〈Q t,Pt+1c −Pr〉+\nρ 2 ‖Pr −Pt+1c ‖22 , (56)\nQt+1 = Qt + ρ(Pt+1c −Pt+1r ) . (57)\nThe Euclidean projection onto the unit simplex in (55) and (56) can be done efficiently [9]. Replacing the quadratic term in (55) and (56) by KL divergence, we have the following BADMM algorithm:\nPt+1c = argminPc∈Bcn〈L,Pc〉+ 〈Q t,Pc −Ptr〉+ ρKL(Pc,Ptr) , (58) Pt+1r = argminPr∈Brn〈Q t,Pt+1c −Pr〉+ ρKL(Pr,Pt+1c ) , (59) Qt+1 = Qt + ρ(Pt+1c −Pt+1r ) . (60)\n(58) and (59) yield the following multiplicative updates :\nPt+1c,ij = Ptr,ij exp(− (L+Qt)ij ρ ) ∑n\ni=1P t r,ij exp(− (L+Qt)ij ρ\n) , Pt+1r,ij =\nPt+1c,ij exp(− Qt ij ρ )\n∑n i=1P t+1 c,ij exp(−\nQt ij ρ ) , (61)\nBoth updates in (61) can be done in O(n2). Besides the sum operation in (61) which can be done in O(log(n)), the multiplicative updates amount to elementwise operation which can be done in parallel. BADMM yields a single-loop alternating multiplicative updates.\nThe following experiment compares BADMM with ADMM and MDA in minimizing a linear function over doubly stochastic matrix. L ∈ Rn×n is randomly generated from uniform distribution. We set ρ = 0.5 in MDA, ADMM and BADMM. All algorithms are run 10 times for n = 100, 500 and the average results are reported. The running time is plotted in Figure 1(a). Since BADMM is projection-free, ADMM has two efficient projections and MDA does one projection, BDAMM is the fastest and MDA is slightly faster than ADMM. The objective value is plotted in Figure 1(b). The three methods have almost the same value. In all methods, the sum of rows of doubly stochastic matrices is always equal to 1. We plot the sum of columns of doubly stochastic matrix for n = 100 in Figure 1(c). The matrices in BADMM and ADMM are row stochastic and thus doubly stochastic. The matrix in MDA is still close to a doubly stochastic matrix but is worse than BADMM and ADMM, which may be because the Sinkhorn algorithm stops early (the maximum iteration is 1000). BDAMM runs much faster than MDA and ADMM while maintaining the same performance as them."
    }, {
      "heading" : "5 Conclusions",
      "text" : "In this paper, we have generalized the alternating direction method of multipliers(ADMM) to Bregman ADMM, similar to how mirror descent generalizes gradient descent. BADMM defines a unified framework for ADMM, generalized ADMM and inexact ADMM. BADMM behaves like alternating proximal point method with Bregman divergence or alternating mirror descent, including alternating additive updates and alternating multiplicative updates as special cases. We illustrate the potential advantage of BADMM on optimization over doubly stochastic matrices. While classical approaches require doing a projection onto the constraint set, BADMM gives a single-loop projection-free algorithm."
    }, {
      "heading" : "A Convergence of BADMM with Large Step Size",
      "text" : "Under the assumption that yt is bounded, the following theorem requires a large step size to establish the convergence of BADMM.\nTheorem 3 Let the sequences {xt, zt,yt} be generated by Bregman ADMM (7)-(9) and {x∗, z∗,y∗} satisfying (23)-(25). Let the Assumption 1 hold and ‖yt‖2 ≤ Dy. Setting ρx = ρz = c1 √ T , τ =\nc2 √ T and ρ = √ T for some positive constant c1, c2, then R(t+ 1) converges to zero.\nProof: Assuming ‖yt‖2 ≤ Dy and using (9), we have\n‖Axt+1 +Bzt+1 − c‖22 = 1\nτ 2 ‖yt+1 − yt‖22 ≤\n2\nτ 2 (‖yt+1‖22 + ‖yt‖22) ≤ 4D2y τ 2 . (62)\nPlugging into (44) and rearranging the terms yields\nR(t+ 1) ≤ D(w∗,wt)−D(w∗,wt+1) + ( τ\n2ρ + γ) 4D2y τ 2 . (63)\nSetting ρx = ρz = c1 √ T , τ = c2 √ T and ρ = √ T for some positive constant c1, c2, we have\nR(t+ 1) = c1Bϕx(xt+1,xt) + c1Bϕz(zt+1, zt) +Bφ(c−Axt+1,Bzt) + γ‖Axt+1 +Bzt+1 − c‖22 , (64)\nSumming (63) over t from 0 to T − 1, we have the following telescoping sum T−1 ∑\nt=0\nR(t+ 1) ≤ D(w∗,w0) + T−1 ∑\nt=0\n( τ\n2ρ + γ) 4D2y τ 2 = D(w∗,w0) + 4(c2/2 + γ)D 2 y c22 . (65)\nTherefore, R(t+ 1) → 0 as t → ∞. The following theorem establishs the convergence rate for the objective and residual of constraints in an ergodic sense.\nTheorem 4 Let the sequences {xt, zt,yt} be generated by Bregman ADMM (7)-(9). Let x̄T = 1 T ∑T t=1 xt, z̄T = 1 T ∑T\nt=1 zt. Let the Assumption 1 hold and ‖yt‖2 ≤ Dy. Set ρx = ρz = c1 √ T , τ = c2 √ T , ρ = √ T for some positive constants c1, c2. For any (x∗, z∗,y∗) satisfying KKT conditions (23)-(25), we have\nf(x̄T ) + g(z̄T )− (f(x∗) + g(z∗)) ≤ 2D2y\nc2 √ T\n+ ‖y0‖22\n2c2T √ T + D2√ T , (66)\nγ‖Ax̄T +Bz̄T − c‖22 ≤ D(w∗,w0)\nT +\n4(c2/2 + γ)D 2 y\nc22T , (67)\nwhere D2 = Bφ(Bz∗,Bz0) + c1(Bϕx(x ∗,x0) +Bϕz(z ∗, z0)).\nProof: Assuming ‖yt‖2 ≤ D2y and using (9), we have\n−〈yt,Axt+1 +Bzt+1 − c〉 = − 1\nτ 〈yt,yt+1 − yt〉 ≤\n1 τ (‖yt‖22 + ‖yt‖2 ∗ ‖yt+1‖2) ≤ 2D2y τ . (68)\nPlugging into (31) and ignoring some negative terms yield\nf(xt+1) + g(zt+1)− (f(x∗) + g(z∗))\n≤ 2D2y τ + ρ(Bφ(Bz ∗,Bzt)− Bφ(Bz∗,Bzt+1)) + ρx(Bϕx(x∗,xt)− Bϕx(x∗,xt+1)) + ρz(Bϕz(z ∗, zt)−Bϕz(z∗, zt+1)) . (69)\nSumming over t from 0 to T − 1, we have the following telescoping sum T−1 ∑\nt=0\n[f(xt+1) + g(zt+1)− (f(x∗) + g(z∗))]\n≤ T−1 ∑\nt=0\n2D2y τ + 1 2τ ‖y0‖22 + ρBφ(Bz∗,Bz0) + ρxBϕx(x∗,x0) + ρzBϕz(z∗, z0) .\nSetting ρx = ρz = c1 √ T , τ = c2 √ T , ρ = √ T , dividing both sides by T and applying the Jensen’s inequality yield (66). Dividing both sides of (65) by T and applying the Jesen’s inequality yield (67)."
    } ],
    "references" : [ ],
    "referenceMentions" : [ ],
    "year" : 2017,
    "abstractText" : "<lb>The mirror descent algorithm (MDA) generalizes gradient descent by using a Bregman di-<lb>vergence to replace squared Euclidean distance as a proximal function. In this paper, we simi-<lb>larly generalize the alternating direction method of multipliers (ADMM) to Bregman ADMM<lb>(BADMM), which uses Bregman divergences as proximal functions in updates. BADMM<lb>allows the use of different Bregman divergences for different variable updates and involves<lb>alternating MDA-style updates, including alternating additive and alternating multiplicative<lb>updates as special cases. BADMM provides a unified framework for ADMM and its variants,<lb>including generalized ADMM and inexact ADMM. We establish the global convergence for<lb>BADMM. We present promising preliminary empirical results for BADMM applied to opti-<lb>mization over doubly stochastic matrices.",
    "creator" : "dvips(k) 5.991 Copyright 2011 Radical Eye Software"
  }
}