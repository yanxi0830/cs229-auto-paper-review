{
  "name" : "1312.0048.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "Stochastic Optimization of Smooth Loss",
    "authors" : [ "Rong Jin" ],
    "emails" : [ "rongjin@cse.msu.edu" ],
    "sections" : [ {
      "heading" : null,
      "text" : "ar X\niv :1\n31 2.\n00 48\nv1 [\ncs .L\nG ]\n3 0\nN ov\n2 01\n3 JMLR: Workshop and Conference Proceedings vol 30 (2013) 1–6 Stochastic Optimization of Smooth Loss Rong Jin rongjin@cse.msu.edu Department of Computer Science and Engineering Michigan State University East Lansing, MI 48824, USA\nLet φ(z) be a smooth loss function, with |ℓ′(z)| ≤ L and |ℓ′(z)− ℓ′(z′)| ≤ γ|z − z′|. Let Ω = { w ∈ Rd : |w| ≤ R } be the solution domain. Let (xi, yi), i = 1, . . . , n be the sequence of i.i.d samples used for training, where xi ∈ Rd and yi ∈ {−1,+1}. Our goal is to find a solution ŵ with a good generalization performance. More specifically, let ℓ(w) be the expected loss for any solution w, i.e. ℓ(w) = E[ℓ(yw⊤x)]. Our goal is to minimize ℓ(w).\nA straightforward approach is to optimize ℓ(w) by stochastic optimization. Let w1 = 0 be the initial. At each iteration t, we receive a training example (xi, yi), and update the current solution wt by wt+1 = argminπΩ (wt − η∇ℓt(wt)) where η > 0 is the stepsize and ℓt(w) = φ(ytw\n⊤xt). The final solution ŵ will be the average of all the solutions, i.e. ŵ = ∑T t=1 wt/T . In (Srebro et al., 2010), the authors were able to show that a simple stochastic optimization method, with an appropriate choice of step size η, can achieves the following generalization error bound in expectation, i.e.\nE[ℓ(ŵ)] ≤ ℓ(w∗) +K ( t\nn +\n√ ℓ(w∗) t\nn\n)\nwhere t = γ|w∗|2. There are two limitations with the analysis in (Srebro et al., 2010). First, it shows a bound in expectation, not a high probability bound. Second, it requires the knowledge of ℓ(w∗) for tuning the step size in order to achieve the desired bound. In the draft presented in this work, we improve the analysis in (Srebro et al., 2010) by addressing these two limitations.\nFirst, let’s address the first limitation by showing a high probability bound. At each iteration, we have\nℓt(wt)− ℓt(w∗) ≤ |wt −w∗|2 2η − |wt+1 −w∗| 2 2η + η 2 |∇ℓt(wt)|2\n≤ |wt −w∗| 2 2η − |wt+1 −w∗| 2 2η + 2ηγℓt(wt)\nc© 2013 R. Jin.\nJin\nwhere in the last step, we use the property |φ′(ytw⊤t xt)|2 ≤ 4γφ(ytw⊤t xt). By adding the inequalities of all iterations and using the assumption η ≤ 1/[2γ], we have\nT∑\nt=1\nℓ(wt)− ℓ(w∗)) ≤\nR2 2η + 2ηγ\nT∑\nt=1\nℓ(wt) + (−2ηγ + 1) T∑\nt=1 ℓ(wt)− ℓt(wt) ︸ ︷︷ ︸\n:=AT\n+ T∑\nt=1 ℓt(w∗)− ℓt(w∗) ︸ ︷︷ ︸\n:=BT\nTo bound AT and BT , we need the following bound for martingales.\nTheorem 1 (Bernsteins inequality for martingales). Let X1, . . . ,Xn be a bounded martingale difference sequence with respect to the filtration F = (Fi)1≤i≤n and with ‖Xi‖ ≤ K. Let\nSi =\ni∑\nj=1\nXj\nbe the associated martingale. Denote the sum of the conditional variances by\nΣ2n =\nn∑\nt=1\nE [ X2t |Ft−1 ]\nThen for all constants t, ν > 0,\nPr [ max\ni=1,...,n Si > t and Σ\n2 n ≤ ν\n] ≤ exp ( − t 2\n2(ν +Kt/3)\n)\nand therefore,\nPr [ max\ni=1,...,n Si >\n√ 2νt+\n√ 2\n3 Kt and Σ2n ≤ ν\n] ≤ e−t\nUsing the above theorem, with a probability 1− e−t, we can bound BT by\nBT ≤ √ 2t\n3 C +\n√ 2tCℓ(w∗)T\nwhere C = LR + φ(0) and t = log(1/δ). To bound AT , we define martingale difference Xt = ℓ(wt)− ℓt(wt). Define the conditional variance Σ2T as\nΣ2T =\nT∑\nt=1\nEt [ X2t ] ≤ T∑\nt=1\nEt[ℓ 2 t (wt)] ≤ C\nT∑\nt=1\nℓ(wt) = CDT\nwhere DT := ∑T t=1 ℓ(wt). Using the Berstein inequality for martingale sum, we have\nPr ( AT ≥ 2 √ CDT τ + √ 2Cτ/3 )\n= Pr ( AT ≥ 2 √ CDT τ + √ 2Cτ/3,Σ2T ≤ CDT ) = Pr ( AT ≥ 2 √ CDT τ + √ 2Cτ/3,Σ2T ≤ CDT ,DT ≤ C )\n+\nm∑\ni=1\nPr ( AT ≥ 2 √ CDT τ + √ 2Cτ/3,Σ2T ≤ CDT , 2i−1C < DT ≤ 2iC )\n≤ Pr (DT ≤ C) + m∑\ni=1\nPr ( AT ≥ C √ 2i+1τ + √ 2Cτ/3,Σ2T ≤ C2i )\n≤ Pr (DT ≤ C) +me−τ\nwhere m = ⌈log2 T ⌉. As a result, we have\nPr ( AT ≤ 2 √ CDT t+ √ 2\n3 Ct\n) + Pr(DT ≤ C) ≥ 1− e−t\nwhere t = log(1/δ) + logm. Using the bounds for AT and BT , we have, with a probability 1− 2e−t,\n(1− 2ηγ)DT − ℓ(w∗)T ≤\nC + R2\n2η + (1− 2ηγ)\n( 2 √\nCDT t+\n√ 2\n3 Ct\n) + √ 2\n3 Ct+\n√ 2tCℓ(w∗)T\nwhere t = log(1/δ) + logm. Reorganizing the terms in the above inequality, we have\n(1− 2ηγ) ( DT − 2 √ CDT t ) − ℓ(w∗)T ≤ R2\n2η + Ct+\n√ 2tCℓ(w∗)T\nwhere t = log(1/δ) + logm + 1. It is easy to verify that DT − 2 √ CDT t is monotonically increasing when DT ≥ Ct. Hence, we have, with a probability 1− 2δ,\n(1− 2ηγ) ( ℓ(ŵ)− 2 √ Ct\nT ℓ(ŵ)\n) ≤ ℓ(w∗) + R2\n2ηT +\nCt\nT +\n√ 2Ct\nT ℓ(w∗)\nor\nℓ(ŵ)− ℓ(w∗) ≤ R2\n2ηT + 2ηγℓ(ŵ) +\n√ 2Ct\nT ℓ(w∗) + 2\n√ Ct\nT ℓ(ŵ) +\nCt\nT (1)\nBy setting η = R/2 √ γTℓ(ŵ), we have, with a probability 1− δ,\nℓ(ŵ)− ℓ(w∗) ≤ √ 2Ct\nT ℓ(w∗) + 2\n√ Ct\nT ℓ(ŵ) +\nCt\nT\nJin\nwhere t = log(1/δ) + logm + 1 + R2γ/C. Since ℓ(w∗) ≤ C and ℓ(ŵ) ≤ C, under the assumption T ≥ t, we have\nℓ(ŵ)− ℓ(w∗) ≤ Ct\nT + 4C\n√ t\nT ≤ 5C\n√ t\nT\nand therefore, with a probability 1− 2δ\nℓ(ŵ)− ℓ(w∗) ≤ 4 √ Ct\nT ℓ(w∗) + (2\n√ 5 + 1) Ct\nT\nThe above analysis allows us to derive a high probability bound for the proposed algorithm. It however does not resolve the problem of determining the appropriate step size η. We address this limitation by exploring the doubling trick. We divide the learning process intom epoches where the kth epoch is comprised of Tk training examples, with Tk = T12\nk−1. Let w1k, . . . ,w Tk k be the sequence of solutions generated by the kth epoch. Define\nDk = 1\nTk\nTk∑\ni=1\nℓ(wik)\nWe assume that, with a probability 1− δ, we have\nDk − ℓ(w∗) ≤ K ( Ct\nTk +\n√ Ct\nTk ℓ(w∗)\n)\nwhere t = log(1/δ) + logm+ 1 +R2γ/C. Define D̂k as\nD̂k = 1\nTk\nTk∑\ni=1\nℓik(w i k)\nwhere ℓik(w) = φ(y i kw ⊤xik). We note that D̂k can be computed from the kth epoch. We would like to bound D̂k −Dk as\n|D̂k −Dk| = 1\nTk\nT∑\ni=1\nℓik(w i k)− ℓ(wik)\nUsing the bound for AT , we have, with a probability 1− T 2\n|D̂k −Dk| ≤ 2 √ Ct\nTk Dk +\n√ 2\n3\nCt Tk\nor\nDk ≤ C\nT 3\nIn the second case, since E[D̂k] = Dk ≤ C/T 3, using the Markov inequality, we have, with a probability 1− T−2,\n|D̂k −Dk| ≤ C\nT\nCombining the above two statements, we have, with a probability 1− 2T−2\n|D̂k −Dk| ≤ 2 √ Ct\nTk Dk + 2\nCt Tk\nand consequentially,\n|D̂k −Dk| ≤ 6 (√ Ct\nTk D̂k +\nCt Tk\n)\nWe thus will use the following expression as the surrogate for ℓ(w∗)\nℓ̂k = D̂k + 6 (√ Ct\nTk D̂k +\nCt Tk\n)\nUsing ℓ̂k, we define the step size ηk+1 as\nηk+1 = R\n2 √ γTk+1ℓ̂k\nIt is easy to verify that with a probability 1−2T−2 (i) ℓ̂k ≥ Dk ≥ ℓ(w∗) and (ii) ℓ̂k−ℓ(w∗) ≤ (K + 6) (√ Ct Tk D̂k + CtTk ) . Using the bound in (1), we have\n(1−2ηγ)(Dk+1−ℓ(w∗)) ≤ R2\n2ηk+1Tk+1 +2ηk+1γℓ(w∗)+2\n√ Ct\nTk+1 ℓ(w∗)+2\n√ Ct\nTk+1 (Dk+1 − ℓ(w∗))+\nCt\nTk+1\nUsing the property ℓ̂k ≥ ℓ(w∗), we have\n2ηk+1γℓ(w∗) ≤ R √ γ\nTk+1 ℓ(w∗)\nWe also have\nR2\n2ηk+1Tk+1 = R\n√ γ\nTk+1 ℓ̂k ≤ R √√√√ γ Tk+1 (K + 6) [ Ct Tk + √ Ct Tk D̂k ]\nSince\nD̂k −Dk ≤ 2 √ Ct\nTk Dk + 2\nCt Tk\nand\nDk − ℓ(w∗) ≤ K ( Ct\nTk +\n√ Ct\nTk ℓ(w∗)\n)\nwe have\nD̂k ≤ ℓ(w∗) +K ( Ct\nTk +\n√ Ct\nTk ℓ(w∗)\n) + 2 Ct\nTk + 2\n√ K Ct\nTk + 4\n√ K Ct\nTk + 4\n√ K\n√ Ct\nTk ℓ(w∗)\nJin\nBy choosing sufficiently large K, we have\nD̂k ≤ ℓ(w∗) + 2K ( Ct\nTk +\n√ Ct\nTk ℓ(w∗)\n)\nHence,\nR2\n2ηk+1Tk+1 ≤ R\n√ 2γ(K + 6)Ct\nTk+1 + 2R2γ Tk+1 +2\n√ 2Ct\nTk+1 ℓ(w∗)+6\n√ 2K 2Ct\nTk+1 +4\n√ 2K\n√ 2Ct\nTk+1ℓ(w∗)\nBy choosing sufficiently large K, we have\nR2\n2ηk+1Tk+1 ≤ K 3\n( Ct\nTk+1 +\n√ Ct\nTk+1 ℓ(w∗)\n)\nWe thus have\n(1− 2ηγ)(Dk+1 − ℓ(w∗)) ≤ 2K\n3\n( Ct\nTk+1 +\n√ Ct\nTk+1 ℓ(w∗)\n)\nBy choosing η ≤ 1/[6γ], we have\nDk+1 − ℓ(w∗) ≤ K ( Ct\nTk+1 +\n√ Ct\nTk+1 ℓ(w∗)\n)\nReferences\nNathan Srebro, Karthik Sridharan, and Ambuj Tewari. Smoothness, low noise and fast rates. In NIPS, pages 2199–2207, 2010."
    } ],
    "references" : [ {
      "title" : "Smoothness, low noise and fast rates",
      "author" : [ "Nathan Srebro", "Karthik Sridharan", "Ambuj Tewari" ],
      "venue" : "In NIPS,",
      "citeRegEx" : "Srebro et al\\.,? \\Q2010\\E",
      "shortCiteRegEx" : "Srebro et al\\.",
      "year" : 2010
    } ],
    "referenceMentions" : [ {
      "referenceID" : 0,
      "context" : "In (Srebro et al., 2010), the authors were able to show that a simple stochastic optimization method, with an appropriate choice of step size η, can achieves the following generalization error bound in expectation, i.",
      "startOffset" : 3,
      "endOffset" : 24
    }, {
      "referenceID" : 0,
      "context" : "There are two limitations with the analysis in (Srebro et al., 2010).",
      "startOffset" : 47,
      "endOffset" : 68
    }, {
      "referenceID" : 0,
      "context" : "In the draft presented in this work, we improve the analysis in (Srebro et al., 2010) by addressing these two limitations.",
      "startOffset" : 64,
      "endOffset" : 85
    } ],
    "year" : 2013,
    "abstractText" : "Let φ(z) be a smooth loss function, with |l′(z)| ≤ L and |l′(z)− l′(z′)| ≤ γ|z − z′|. Let Ω = { w ∈ R : |w| ≤ R } be the solution domain. Let (xi, yi), i = 1, . . . , n be the sequence of i.i.d samples used for training, where xi ∈ R and yi ∈ {−1,+1}. Our goal is to find a solution ŵ with a good generalization performance. More specifically, let l(w) be the expected loss for any solution w, i.e. l(w) = E[l(ywx)]. Our goal is to minimize l(w). A straightforward approach is to optimize l(w) by stochastic optimization. Let w1 = 0 be the initial. At each iteration t, we receive a training example (xi, yi), and update the current solution wt by wt+1 = argminπΩ (wt − η∇lt(wt)) where η > 0 is the stepsize and lt(w) = φ(ytw xt). The final solution ŵ will be the average of all the solutions, i.e. ŵ = ∑T t=1 wt/T . In (Srebro et al., 2010), the authors were able to show that a simple stochastic optimization method, with an appropriate choice of step size η, can achieves the following generalization error bound in expectation, i.e.",
    "creator" : "LaTeX with hyperref package"
  }
}