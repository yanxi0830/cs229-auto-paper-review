{
  "name" : "0911.5708.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "LEARNING IN A LARGE FUNCTION SPACE: PRIVACY-PRESERVING MECHANISMS FOR SVM LEARNING",
    "authors" : [ "Benjamin I. P. Rubinstein", "Peter L. Bartlett", "Ling Huang", "Nina Taft" ],
    "emails" : [ ],
    "sections" : [ {
      "heading" : "1. Introduction",
      "text" : "The goal of a well-designed statistical database is to provide aggregate information about a database's entries while maintaining individual entries' privacy. These two goals of utility and privacy are inherently discordant. For a mechanism to be useful, its responses must closely resemble some target statistic of the database's entries. However to protect privacy, it is often necessary for the mechanism's response distribution to be `smoothed out', i.e., the mechanism must be randomized to reduce the individual entries' in uence on this distribution. It has been of key interest to the statistical database community to understand when the goals of utility and privacy can be e ciently achieved simultaneously (Dinur and Nissim, 2003; Barak et al., 2007; Dwork et al., 2007; Blum et al., 2008; Chaudhuri and Monteleoni, 2009; Kasiviswanathan et al., 2008). In this paper we consider the practical goal of private regularized empirical risk minimization (ERM) in Reproducing Kernel Hilbert Spaces for the special case of the Support Vector Machine (SVM). We adopt the strong notion of di erential privacy as formalized by Dwork (2006). Our e cient new mechanisms are shown to parametrize functions that are close to non-private SVM under the L∞-norm, with high probability. In our setting this notion of utility is stronger than closeness of risk (cf. Remark 3).\nWe employ a number of algorithmic and proof techniques new to di erential privacy. One of our new mechanisms borrows a technique from large-scale learning, in which regularized ERM is performed in a random feature space whose inner-product uniformly approximates the target feature space inner-product. This random feature space is constructed by viewing the target kernel as a probability measure in the Fourier domain. This technique enables the nite parametrization of responses from function classes with in nite VC dimension. To establish utility, we show that regularized ERM is relatively insensitive to perturbations of the kernel: not only does the technique of learning in a random RKHS enable nitely-encoded privacypreserving responses, but these responses well-approximate the responses of non-private SVM. Together these two techniques may prove useful in extending privacy-preserving mechanisms to learn in large function spaces. To prove di erential privacy, we borrow a proof technique from the area of algorithmic stability. We believe that stability may become a fruitful avenue for constructing new private mechanisms in the future, based on learning maps presently known to be stable.\nDate: December 1, 2009.\n1\nar X\niv :0\n91 1.\n57 08\nv1 [\ncs .L\nG ]\n3 0\nN ov\n2 00\n9\nOf particular interest, is the optimal di erential privacy of the SVM, which loosely speaking is the best level of privacy achievable by any accurate mechanism for SVM learning. Through our privacy-preserving mechanisms for the SVM, endowed with guarantees of utility, we upper bound optimal di erential privacy. We also provide lower bounds on the SVM's optimal di erential privacy, which are impossibility results for simultaneously achieving high levels of utility and privacy.\nThe remainder of this paper is organized as follows. After concluding this section with a summary of related work, we recall basic concepts of di erential privacy and SVM learning in Section 2. Sections 3 and 4 describe the new mechanisms for private SVM learning for nite-dimensional feature maps and (potentially in nite-dimensional) feature maps with translation-invariant kernels. Each mechanism is accompanied with proofs of privacy and utility bounds. Section 5 considers the special case of hinge loss and presents an upper bound on the SVM's optimal di erential privacy. A corresponding lower bound is then given in Section 6. We conclude the paper with several open problems.\n1.1. Related Work. There is a rich literature of prior work on di erential privacy in the theory community. The following sections summarize work related to our own, organized to contrast this work with our main contributions.\n1.1.1. Range Spaces Parametrizing Vector-Valued Statistics or Functions with Finite VC-dimension. Early work on private interactive mechanisms focused on approximating real- and vector-valued statistics (e.g., Dinur and Nissim, 2003; Blum et al., 2005; Dwork et al., 2006; Dwork, 2006; Barak et al., 2007). McSherry and Talwar (2007) rst considered private mechanisms with range spaces parametrizing sets more general than real-valued vectors, and used such di erentially private mappings for mechanism design. More related to our work are the private mechanisms for regularized logistic regression proposed and analyzed by Chaudhuri and Monteleoni (2009). There the mechanism's range space parametrizes the VC-dimension d + 1 class of linear hyperplanes in Rd. Kasiviswanathan et al. (2008) showed that discretized concept classes can be PAC learned or agnostically learned privately, albeit via an ine cient mechanism. Blum et al. (2008) showed that non-interactive mechanisms can privately release anonymized data such that utility is guaranteed over classes of predicate queries with polynomial VC dimension, when the domain is discretized. Dwork et al. (2009) more recently characterized when utility and privacy can be achieved by e cient non-interactive mechanisms. In this paper we consider e cient mechanisms for private SVM learning, whose range spaces parametrize real-valued functions (whose sign form trained classi ers). One case covered by our analysis is learning with a Gaussian kernel, which corresponds to learning over a class of in nite VC dimension.\n1.1.2. Practical Privacy-Preserving Learning (Mostly) via Subset-Sums. Most prior work in di erential privacy has focused on the deep analysis of mechanisms for relatively simple statistics (with histograms and contingency tables as explored by Blum et al. 2005 and Barak et al. 2007 respectively, as examples) and learning algorithms (e.g., interval queries and half-spaces as explored by Blum et al. 2008), or on constructing learning algorithms that can be decomposed into subset-sum operations (e.g., perceptron, k-NN, ID3 as described by Blum et al. 2005, and various recommender systems due to the work of McSherry and Mironov 2009). By contrast, we consider the practical goal of SVM learning, which does not decompose into subsetsums. It is also notable that our mechanisms run in polynomial time. The most related work to our own in this regard is due to Chaudhuri and Monteleoni (2009), although their results hold only for di erentiable loss, and nite feature mappings.\n1.1.3. The Privacy-Utility Trade-O . Like several prior studies, we consider the trade-o between privacy and utility. Barak et al. (2007) presented a mechanism for releasing contingency tables that guarantees di erential privacy and also guarantees a notion of accuracy: with high probability all marginals from the released table are close in L1-norm to the true table's marginals. As mentioned above, Blum et al. (2008) developed a private non-interactive mechanism that releases anonymized data such that all predicate queries in a VC-class take on similar values on the anonymized data and original data. In the work of Kasiviswanathan et al. (2008), utility corresponds to PAC learning: with high probability the response and target concepts are close, averaged over the underlying measure.\nA sequence of prior negative results have shown that any mechanism providing overly accurate responses cannot be private (Dinur and Nissim, 2003; Dwork et al., 2007; Dwork and Yekhanin, 2008). Dinur and Nissim (2003) showed that if noise of rate only o( √ n) is added to subset sum queries on a database of bits then an adversary can reconstruct a 1− o(1) fraction of the database. This is a threshold phenomenon that\nsays if accuracy is too small, privacy cannot be guaranteed at all. This result was more recently extended to allow for mechanisms that answer a small fraction of queries arbitrarily (Dwork et al., 2007). We show a similar negative result for the private SVM setting: any mechanism that is too accurate with respect to the SVM cannot guarantee strong levels of privacy.\n1.1.4. Connections between Stability, Robust Statistics, and Global Sensitivity. To prove di erential privacy, we borrow a proof technique from the area of algorithmic stability. In passing Kasiviswanathan et al. (2008) note the similarity between notions of algorithmic stability and di erential privacy, however do not exploit this. The connection between algorithmic stability and di erential privacy is qualitatively similar to the recent work of Dwork and Lei (2009) who demonstrated that robust estimators can serve as the basis for private mechanisms, by exploiting the limited in uence of outliers on such estimators."
    }, {
      "heading" : "2. Background & Definitions",
      "text" : "A database D is a sequence of n > 1 entries or rows (xi, yi) ∈ Rd × {−1, 1}, which are input point-label pairs or examples. We say that a pair of databases D1, D2 are neighbors if they di er on one entry. A mechanism M is a service trusted with access to a database D, that releases aggregate information about D while maintaining privacy of individual entries. By M(D) we mean the response of M on D. We assume that this is the only information released by the mechanism. Denote the range space ofM by TM . We adopt the following strong notion of di erential privacy due to Dwork (2006).\nDe nition 1. For any β > 0, a randomized mechanism M provides β-di erential privacy, if, for all neighboring databases D1, D2 and all responses t ∈ TM ,\nlog (\nPr (M(D1) = t) Pr (M(D2) = t)\n) ≤ β .\nThe probability in the de nition is over the randomization in M . For continuous TM we mean by this ratio a Radon-Nikodym derivative of the distribution of M(D1) with respect to the distribution of M(D2). If an adversary knows M and the rst n − 1 entries of D, she may simulate the mechanism with di erent choices for the missing example. If the mechanism's response distribution varies smoothly with her choice, the adversary will not be able to infer the true value of entry n by querying M . In the sequel we assume WLOG that each pair of neighboring databases di er on their last entry.\nIntuitively the more an `interesting'1 mechanism M is perturbed to guarantee di erential privacy, the less like M the resulting mechanism M̂ will become. The next de nition formalizes the notion of `likeness'.\nDe nition 2. Consider two mechanisms M̂ and M with the same domain and response spaces TM̂ , TM respectively. Let X be some set and let F be a space of real-valued functions on X that is parametrized by the response spaces: for every t ∈ TM̂ ∪ TM let ft ∈ F be some function. Finally assume F is endowed with norm ‖ · ‖F . Then for > 0 and 0 < δ < 1 we say that2 M̂ is ( , δ)-useful with respect to M if, for all databases D, Pr\n(∥∥∥fM̂(D) − fM(D)∥∥∥F ≤ ) ≥ δ. Typically M̂ will be a privacy-preserving version of M , that has been perturbed somehow. Usefulness means that not only does M̂ guarantee privacy of the training database, but that the aggregate information revealed about the database by M̂ is `close' to what would be revealed by the desired (but non-private) mechanism M . In the sequel we will take ‖ · ‖F to be the sup-norm over a subset M ⊆ Rd containing the data, which we denote by ‖f‖∞;M = supx∈M |f(x)|. It will also be convenient to use the notation ‖k‖∞;M = supx,y∈M |k(x,y)| for bivariate functions k(·, ·). Remark 3. In the sequel we develop privacy-preserving mechanisms that are useful with respect to the Support Vector Machine (see the next section for a brief introduction to the SVM). The SVM works to minimize the expected hinge-loss (i.e., risk in terms of the hinge-loss), which is a convex surrogate for the expected 0-1 loss. Since the hinge-loss is Lipschitz in the real-valued function output by the SVM, it follows that a mechanism M̂ having utility with respect to the SVM also has expected hinge-loss that is within\n1Examples of interesting properties include low risk, robustness to a small amount of malicious noise, etc. 2Note that we have chosen to overload the term ( , δ)-usefulness introduced by Blum et al. (2008) for non-interactive mechanisms that release anonymized data. Our de nition of usefulness is analogous for the present setting of privacy-preserving learning, where a single function is released.\nAlgorithm 1 SVM Inputs: database D = {(xi, yi)}ni=1 with xi ∈ Rd, yi ∈ {−1, 1}; kernel k : Rd × Rd → R; convex loss function `; parameter C > 0.\n(1) α? ← Solve the QP dual of Primal (2.1) (see e.g., the derivations by Bishop 2006); and (2) Return vector α?.\nof the SVM's hinge-loss with high probability. That is, ( , δ)-usefulness with respect to the sup-norm is stronger than guaranteed closeness of risk (absolute bounds on risk for regularized logistic regression are explored by Chaudhuri and Monteleoni 2009; Kasiviswanathan et al. 2008 consider the task of private PAC learning, which demands closeness of risk). We consider the hinge-loss further in Sections 5 and 6. Until then we work with arbitrary convex, Lipschitz losses.\nWe will see that the presented analysis does not simultaneously guarantee privacy at arbitrary levels and utility at arbitrary accuracy. The highest level of privacy guaranteed over all ( , δ)-useful mechanisms with respect to a target mechanism M , is quanti ed by the optimal di erential privacy for M . We de ne this notion for the SVM here, but the concept extends to any target mechanism of interest. We present upper and lower bounds on β( , δ, C, n, `, k) for the SVM in Sections 5 and 6 respectively.\nDe nition 4. For , C > 0, δ ∈ (0, 1), n > 1, loss function `(y, ŷ) convex in ŷ, and kernel k, the optimal di erential privacy for the SVM is the function\nβ( , δ, C, n, `, k) = inf M̂∈I sup (D1,D2)∈D sup t∈TM̂ log\nPr ( M̂(D1) = t ) Pr ( M̂(D2) = t )  ,\nwhere I is the set of all ( , δ)-useful mechanisms with respect to the SVM with parameter C, loss `, and kernel k; and D is the set of all pairs of neighboring databases with n entries.\n2.1. Background on Support Vector Machines. Soft-margin SVM learning corresponds to the convex Primal program\nmin w∈RF\n1 2 ‖w‖22 + C n n∑ i=1 ` (yi, fw(xi)) ,(2.1) where the xi ∈ Rd are training input points and the yi ∈ {−1, 1} are their training labels, n is the size of the training set, φ : Rd → RF is a feature mapping taking points in input space Rd to some (possibly in nite) F -dimensional feature space, `(y, ŷ) is a loss function convex in ŷ, and w is a hyperplane normal vector in feature space.\nWhen F is nite, predictions are made by taking the sign of f?(x) = fw?(x) = 〈φ(x),w?〉. We will refer to both fw(·) and sgn (fw(·)) as classi ers, with the exact meaning apparent from the context. When F is large and when inner-products in feature space may be computed quickly via an explicit representation of the kernel function k(x,y) = 〈φ(x), φ(y)〉, the solution may be more easily obtained via the dual. For example, see Program (5.1) in Section 5 for the dual formulation of the hinge-loss `(y, ŷ) = (1 − yŷ)+, which is the loss most commonly associated with soft-margin SVM. Other examples include the square loss (1 − yŷ)2 and logistic loss log (1 + exp (−yŷ)). The vector of maximizing dual variables α? returned by dualized SVM parametrizes the function f? = fα? as fα(·) = ∑m i=1 αiyik(·,xi).\nMore generally, the Support Vector Machine can be seen as performing regularized ERM in a Reproducing Kernel Hilbert Space (RKHS) H. The Representer Theorem (Kimeldorf and Wahba, 1971) states that the minimizing f? = arg minf∈H 12‖f‖ 2 H + C n ∑n i=1 `(yi, f(xi)) lies in the span of the functions k(·,xi) ∈ H. Indeed the above dual expansion shows that the coordinates in this subspace are given by the α?i yi. We de ne the mechanism SVM to be the dual optimization that responds with the vector α?, as described by Algorithm 1. For general information about SVMs see e.g., (Burges, 1998; Cristianini and Shawe-Taylor, 2000; Schölkopf and Smola, 2001; Bishop, 2006). We end this section with the de nition of an important class of kernels (see Table 1 for examples).\nDe nition 5. A kernel function of the form k(x,y) = g(x − y), for some function g, is called translationinvariant."
    }, {
      "heading" : "3. Mechanism for Finite Feature Maps",
      "text" : "As a rst step towards private SVM learning we begin by considering the simple case of nite F - dimensional feature maps. Algorithm 2 describes the PrivateSVM-Finite mechanism, which follows the usual pattern of preserving di erential privacy: after forming the primal solution to the SVM an F -dimensional vector the mechanism adds Laplace-distributed noise to the weight vector. Guaranteeing di erential privacy proceeds via the usual two-step process of calculating the L1-sensitivity of the SVM's weight vector, then showing that β-di erential privacy follows from sensitivity together with the choice of Laplace noise with scale equal to sensitivity divided by β.\nTo calculate sensitivity, we exploit the algorithmic stability of regularized ERM. Intuitively, stability corresponds to continuity of a learning map. Several notions of stability are known to lead to good generalization error bounds (Devroye and Wagner, 1979; Kearns and Ron, 1999; Bousquet and Elissee , 2002; Kutin and Niyogi, 2002), sometimes in cases where class capacity-based approaches such as VC theory do not apply. A learning map A is a function that maps a database D to a classi er fD; it is precisely the composition of a mechanism followed by the classi er parametrization mapping.3 A learning map A is said to have γ-uniform stability with respect to loss `(·, ·) if for all neighboring databases D,D′, the losses of the classi ers trained on D and D′ are close on all test examples ‖`(·,A(D))− `(·,A(D′))‖∞ ≤ γ (Bousquet and Elissee , 2002). Our rst lemma computes sensitivity by following the proof of (Schölkopf and Smola, 2001, Theorem 12.4) which establishes that SVM learning has uniform stability (a result due to Bousquet and Elissee 2002). For simplicity we restrict the proof of sensitivity to di erentiable loss functions in Lemma 6; the result remains the same for general convex loss functions. See Lemma 21 for an almost identical proof for subdi erentiable losses.\nLemma 6. Consider loss function `(y, ŷ) that is di erentiable, convex and L-Lipschitz in ŷ, and an RKHS H induced by nite F -dimensional feature mapping φ with bounded norm k(x,x) ≤ κ2 for all x ∈ Rd. Let wS ∈ RF be the minimizer of the following regularized empirical risk function for each database S = {(xi, yi)}ni=1\nRreg(w, S) = C\nn n∑ i=1 ` (yi, fw(xi)) + 1 2 ‖w‖22 .\nThen for every pair of neighboring databases D,D′ of n entries, ‖wD −wD′‖1 ≤ 4LCκ √ F/n.\nProof. For convenience we de ne Remp(w, S) = n−1 ∑n i=1 ` (yi, fw(xi)) for any database S, then the rstorder necessary KKT conditions imply\n∂wRreg(wD, D) = C∂wRemp(wD, D) + wD = 0(3.1) ∂wRreg(wD′ , D′) = C∂wRemp(wD′ , D′) + wD′ = 0 ,(3.2)\nwhere ∂w is the partial derivative operator with respect to w. De ne the auxiliary risk function\nR̃(w) = C〈∂wRemp(wD, D)− ∂wRemp(wD′ , D′), w −wD′〉+ 1 2 ‖w −wD′‖22 .\nIt is easy to see that R̃(w) is strictly convex in w and that R̃(wD′) = 0. And since by Equation (3.2)\n∂wR̃(w) = C∂wRemp(wD, D)− C∂wRemp(wD′ , D′) + w −wD′ = C∂wRemp(wD, D) + w ,\n3For example an SVM mechanism may return a weight vector w? or dual coe cients α? which in turn parametrizes the classi er f?. The SVM learning map takes the training database directly to the classi er.\nAlgorithm 2 PrivateSVM-Finite Inputs: database D = {(xi, yi)}ni=1 with xi ∈ Rd, yi ∈ {−1, 1}; nite feature map φ : Rd → RF and induced kernel k; convex loss function `; and parameters λ,C > 0.\n(1) α? ← Run Algorithm 1 on D with parameter C, kernel k, and loss `; (2) w̃← ∑n i=1 α ? i yiφ (xi); (3) µ← Draw i.i.d. sample of F scalars from Laplace (0, λ); and (4) Return ŵ = w̃ + µ\nit follows that R̃(w) is minimized at wD by Equation (3.1). Thus R̃(wD) ≤ 0. Next simplify the rst term of R̃(wD), scaled by n/C for simplicity:\nn〈∂wRemp(wD, D)− ∂wRemp(wD′ , D′), wD −wD′〉\n= n∑ i=1 〈∂w` (yi, fwD (xi))− ∂w` ( y′i, fwD′ (x ′ i) ) , wD −wD′〉\n= n−1∑ i=1 ( `′ (yi, fwD (xi))− `′ ( yi, fwD′ (xi) )) ( fwD (xi)− fwD′ (xi) ) +`′ (yn, fwD (xn)) ( fwD (xn)− fwD′ (xn) ) − `′ ( y′n, fwD′ (x ′ n) ) ( fwD (x ′ n)− fwD′ (x ′ n) )\n≥ `′ (yn, fwD (xn)) ( fwD (xn)− fwD′ (xn) ) − `′ ( y′n, fwD′ (x ′ n) ) ( fwD (x ′ n)− fwD′ (x ′ n) ) ,\nwhere `′(y, ŷ) = ∂ŷ`(y, ŷ). The second equality follows from ∂w`(y, fw(x)) = `′(y, fw(x))φ(x) and x′i = xi and y′i = yi for each i ∈ [n− 1], and the inequality follows from the di erentiability and convexity4 of ` in ŷ. Combined with R̃(wD) ≤ 0 this yields\nn\n2C ‖wD −wD′‖22 ≤ `′ ( y′n, fwD′ (x ′ n) ) ( fwD (x ′ n)− fwD′ (x ′ n) ) − `′ (yn, fwD (xn)) ( fwD (xn)− fwD′ (xn) ) ≤ 2L\n∥∥fwD − fwD′∥∥∞ ,(3.3) by the Lipschitz continuity of `. Now by the reproducing property and Cauchy-Schwartz inequality we can upper bound the classi er di erence's in nity norm by the Euclidean norm on the weight vectors: for each x ∣∣fwD (x)− fwD′ (x)∣∣ = |〈φ(x),wD −wD′〉|\n≤ ‖φ(x)‖2 ‖wD −wD′‖2 = √ k(x,x) ‖wD −wD′‖2 ≤ κ ‖wD −wD′‖2 .\nCombining this with Inequality (3.3) yields ‖wD−wD′‖2 ≤ 4LCκ/n. L1-based sensitivity then follows from the inequality ‖w‖1 ≤ √ F‖w‖2 for all w ∈ RF .\nWith the weight vector's sensitivity in hand, di erential privacy follows immediately from the proof technique established by Dwork et al. (2006).\nTheorem 7 (Privacy of PrivateSVM-Finite). For any β > 0, database D of size n, C > 0, loss function `(y, ŷ) that is convex and L-Lipschitz in ŷ, and nite F -dimensional feature map with kernel k(x,x) ≤ κ2 for all x ∈ Rd, PrivateSVM-Finite run on D with loss `, kernel k, noise parameter λ ≥ 4LCκ √ F/(βn) and regularization parameter C guarantees β-di erential privacy.\nThis rst main result establishes the usual kind of di erential privacy guarantee for the new PrivateSVMFinite algorithm. The more private the data, the more noise must be added. The more entries in the database, the less noise is needed to achieve the same level of privacy. Since the noise vector µ has exponential tails, standard tail bound inequalities quickly lead to ( , δ)-usefulness for PrivateSVM-Finite.\n4Namely for di erentiable convex f and any a, b ∈ R, (f ′(a)− f ′(b)) (a− b) ≥ 0.\nTheorem 8 (Utility of PrivateSVM-Finite). Consider any C > 0, n > 1, database D of n entries, arbitrary convex loss `, and nite F -dimensional feature mapping φ with kernel k and |φ(x)i| ≤ Φ for all x ∈ M and i ∈ [F ] for some Φ > 0 and M ⊆ Rd. For any > 0 and δ ∈ (0, 1), PrivateSVM-Finite run on D with loss `, kernel k, noise parameter 0 < λ ≤\n2Φ(F loge 2+loge 1δ ) , and regularization parameter C, is\n( , δ)-useful with respect to the SVM under the ‖ · ‖∞;M-norm. Proof. Our goal is to compare the SVM and PrivateSVM-Finite classi cations of any point x ∈M:∣∣∣fM̂(D)(x)− fM(D)(x)∣∣∣ = |〈ŵ, φ(x)〉 − 〈w̃, φ(x)〉| = |〈µ, φ(x)〉| ≤ ‖µ‖1 ‖φ(x)‖∞ ≤ Φ ‖µ‖1 .\nThe absolute value of a zero mean Laplace random variable with scale parameter λ is exponentially distributed with scale λ−1. Moreover the sum of q i.i.d. exponential random variables has Erlang q-distribution with the same scale parameter.5 Thus we have, for Erlang F -distributed random variable X and any t > 0,\n∀x ∈M, ∣∣∣fM̂(D)(x)− fM(D)(x)∣∣∣ ≤ ΦX\n⇒ ∀ > 0, Pr (∥∥∥fM̂(D) − fM(D)∥∥∥∞;M > ) ≤ Pr (X > /Φ)\n= Pr ( etX > et /Φ ) ≤ E [ etX ]\ne t/Φ .(3.4)\nHere we have employed the standard Cherno tail bound technique using Markov's inequality. The numerator of (3.4), the moment generating function of the Erlang F -distribution with parameter λ, is (1 − λt)−F for all t < λ−1. Together with the choice of t = (2λ)−1, this gives\nPr (∥∥∥fM̂(D) − fM(D)∥∥∥∞;M > ) ≤ (1− λt)−F e− t/Φ\n= 2F e− /(2λΦ)\n= exp (F loge 2− /(2λΦ)) . And provided that λ ≤ / ( 2Φ ( F loge 2 + loge 1 δ )) this probability is bounded by δ.\nOur second main result establishes that PrivateSVM-Finite is not only di erentially private, but that it releases a classi er that is similar to the SVM. Utility and privacy are competing properties, however, since utility demands that the noise not be too large."
    }, {
      "heading" : "4. Mechanism for Translation-Invariant Kernels",
      "text" : "Consider now the problem of privately learning in an RKHS H induced by an in nite dimensional feature mapping φ. As a mechanism's response must be nitely encodable, the primal parametrization seems less appealing as it did in PrivateSVM-Finite. It is natural to look to the SVM's dual solution as a starting point: the Representer Theorem (Kimeldorf and Wahba, 1971) states that the optimizing f? ∈ H must be in the span of the data a nite-dimensional subspace. While the coordinates in this subspace the α?i dual variables could be perturbed in the usual way to guarantee di erential privacy, the subspace's basis the data are also needed to parametrize f?. To side-step this apparent stumbling block, we take another approach by approximating H with a random RKHS Ĥ induced by a random nite-dimensional map φ̂. This then allows us to respond with a nite primal parametrization. Algorithm 3 summarizes the PrivateSVM mechanism.\nAs noted recently by Rahimi and Recht (2008), the Fourier transform p of the g function of a continuous positive-de nite translation-invariant kernel is a non-negative measure (Rudin, 1994). Rahimi and Recht\n5The Erlang q-distribution has density xq−1 exp(−x/λ) λq(q−1)! , CDF 1− e −x/λ Pq−1 j=0 (x/λ)j j! , expectation qλ and variance qλ2.\nAlgorithm 3 PrivateSVM Inputs: database D = {(xi, yi)}ni=1 with xi ∈ Rd, yi ∈ {−1, 1}; translation-invariant kernel k(x,y) = g(x− y) with Fourier transform p(ω) = 2−1 e−j〈ω,x〉g(x) dx; convex loss function `; parameters λ,C > 0 and d̂ ∈ N. (1) ρ1, . . . ,ρd̂ ←Draw i.i.d. sample of d̂ vectors in R d from p;\n(2) α̂← Run Algorithm 1 on D with parameter C, kernel k̂ induced by map (4.1), and loss `; (3) w̃← ∑n i=1 yiα̂iφ̂ (xi) where φ̂ is de ned in Equation (4.1); (4) µ← Draw i.i.d. sample of 2d̂ scalars from Laplace (0, λ); and (5) Return ŵ = w̃ + µ and ρ1, . . . ,ρd̂\n(2008) exploit this fact to construct a random nite-dimensional RKHS Ĥ by drawing d̂ vectors from p. These vectors ρ1, . . . ,ρd̂ de ne the following random 2d̂-dimensional feature map\nφ̂(·) = d̂−1/2 [ cos (〈ρ1, ·〉) , sin (〈ρ1, ·〉) , . . . , cos ( 〈ρd̂, ·〉 ) , sin ( 〈ρd̂, ·〉 )]T .(4.1) Inner-products in the random feature space approximate k(·, ·) uniformly, and to arbitrary precision depending on parameter d̂, as restated in Lemma 13. We denote the inner-product in the random feature space by k̂. Rahimi and Recht (2008) applied this approximation to large-scale learning (situations where n is large). Instead of employing non-linear SVM's dual solution which takes O(n2) time, the primal solution to linear SVM on φ̂ is used, as it takes time quadratic in d̂ to compute. For large-scale learning, good approximations can be found for d̂ n. Table 1 presents three important translation-invariant kernels and their transformations. PrivateSVM employs the same trick for translation-invariant kernels, but in a di erent setting. Here regularized ERM is performed in Ĥ, not to avoid complexity in n, but to provide a direct nite representation w̃ of the primal solution in the case of in nite dimensional feature spaces. After performing regularized ERM in Ĥ, appropriate Laplace noise is added to the primal solution w̃ to guarantee di erential privacy as before.\nPrivateSVM is computationally e cient. Algorithm 3 takes O(d̂) time to compute each entry of the kernel matrix, or a total time of O(d̂n2) on top of running dual SVM in the random feature space which is worst-case O(n3s) for the analytic solution (where ns ≤ n is the number of support vectors), and faster using numerical methods such as chunking (Burges, 1998). To achieve ( , δ)-usefulness wrt the hinge-loss SVM d̂ must be taken to be O ( d 4 ( log 1δ + log 1 )) (cf. Corollary 15). By comparison it takes O(dn2) to construct the kernel matrix for any translation-invariant kernel. As with the SVM and PrivateSVM-Finite, the response of Algorithm 3 can be used to make classi cations on future test points by constructing the classi er f̂?(·) = fŵ(·) = 〈ŵ, φ̂(·)〉. Unlike the previous mechanisms, however, PrivateSVM must include a parametrization of feature map φ̂ the sample {ρi} d̂ i=1 in its response. Of PrivateSVM's total response, only ŵ depends on database D. The ρi are data-independent vectors drawn from the transform p of the kernel, which we assume to be known by the adversary (to wit the adversary knows the mechanism itself, including k). Thus to establish di erential privacy we need only consider the data-dependent weight vector, fortunately we have already considered the similar case of PrivateSVM-Finite.\nCorollary 9 (Privacy of PrivateSVM). For any β > 0, database D of size n, C > 0, d̂ ∈ N, loss function `(y, ŷ) that is convex and L-Lipschitz in ŷ, and translation-invariant kernel k, PrivateSVM run on D with loss `, kernel k, noise parameter λ ≥ 22.5LC √ d̂/(βn), approximation parameter d̂, and regularization parameter C guarantees β-di erential privacy.\nProof. The result follows immediately from Theorem 7 since w̃ is the primal solution of SVM with kernel k̂, the response vector ŵ = w̃ + µ for i.i.d. Laplace µ, and k̂(x,x) = 1 for all x ∈ RD.\nThis result is surprising, in that PrivateSVM is able to guarantee privacy for regularized ERM over a function class of in nite VC-dimension, where the obvious way to return the learned classi er (responding with the dual variables and feature mapping) reveals all the entries corresponding to the support vectors, completely.\nLike PrivateSVM-Finite, PrivateSVM is useful with respect to the SVM. If we denote the function parametrized by intermediate weight vector w̃ by f̃ , then the same argument for the utility of PrivateSVMFinite establishes the high-probability proximity of f̃ and f?.\nLemma 10. Consider a run of Algorithms 1 and 3 with d̂ ∈ N, C > 0, convex loss and translation-invariant kernel. Denote by f̂? and f̃ the classi ers parametrized by weight vectors ŵ and w̃ respectively, where these vectors are related by ŵ = w̃ + µ with µ iid∼ Laplace(0, λ) in Algorithm 3. For any > 0 and δ ∈ (0, 1), if\n0 < λ ≤ min {\n24 loge 2 √ d̂ , √ d̂ 8 loge 2 δ\n} then\nPr (∥∥∥f̂? − f̃∥∥∥\n∞ ≤ 2\n) ≥ 1− δ\n2 .\nProof. As in the proof of Theorem 8 we can use the Cherno trick to show that, for Erlang 2d̂-distributed random variable X, the choice of t = (2λ)−1,and for any > 0\nPr (∥∥∥f̂? − f̃∥∥∥\n∞ > /2\n) ≤ E [ etX ]\ne t √ d̂/2\n≤ (1− λt)−2d̂ e− t √ d̂/2 = 22d̂e− √ d̂/(4λ)\n= exp ( d̂ loge 4− √ d̂/(4λ) ) .\nProvided that λ ≤ / ( 24 loge 2 √ d̂ ) this is bounded by exp ( − √ d̂/(8λ) ) . Moreover if λ ≤ √ d̂/ ( 8 loge 2 δ ) , then the claim follows.\nTo show a similar result for f? and f̃ , we exploit smoothness of the regularized ERM with respect to small changes in the RKHS itself. To the best of our knowledge, this kind of stability to the feature mapping has not been used before. We begin with a technical lemma that we will use to exploit the convexity of the regularized empirical risk functional.\nLemma 11. Let R be a functional on Hilbert space H satisfying R[f ] ≥ R[f?]+ a2‖f −f ?‖2H for some a > 0, f? ∈ H and all f ∈ H. Then R[f ] ≤ R[f?] + implies ‖f − f?‖Ĥ ≤ √ 2 a , for all > 0, f ∈ H.\nProof. By assumption and the antecedent\n‖f − f?‖2Ĥ ≤ 2 a (R[f ]−R[f?])\n≤ 2 a (R[f?] + −R[f?]) = 2 /a .\nTaking square roots of both sides yields the consequent.\nProvided that the kernel functions k and k̂ are uniformly close, the next lemma exploits insensitivity of regularized ERM to perturbations of the feature mapping to show that f? and f̃ are pointwise close. Lemma 22 re-proves this result for non-di erentiable loss functions.\nLemma 12. Let H be an RKHS with translation-invariant kernel k, and let Ĥ be the random RKHS corresponding to feature map (4.1) induced by k. Let C be a positive scalar and loss `(y, ŷ) be di erentiable, convex, and L-Lipschitz in ŷ. Consider the regularized empirical risk minimizers in each RKHS\nf? ∈ arg min f∈H\nC\nn n∑ i=1 `(yi, f(xi)) + 1 2 ‖f‖2H ,\ng? ∈ arg min g∈Ĥ\nC\nn n∑ i=1 `(yi, g(xi)) + 1 2 ‖g‖2Ĥ .\nLet M ⊆ Rd be any set containing x1, . . . ,xn. For any > 0, if the dual variables from both optimizations have L1-norms bounded by some Λ > 0 and ∥∥∥k − k̂∥∥∥\n∞;M ≤ min\n{ 1,\n2 22 “ Λ+2 √ (CL+Λ/2)Λ ”2 } then\n‖f? − g?‖∞;M ≤ /2. Proof. Denote the empirical risk functional by Remp[f ] = n−1 ∑n i=1 ` (yi, f(xi)) and the regularized empirical risk functional Rreg[f ] = C Remp[f ] + ‖f‖2/2, for the appropriate RKHS norm (either H or Ĥ). Let f? denote the regularized empirical risk minimizer in H, given by parameter vector α?, and let g? denote the regularized empirical risk minimizer in Ĥ given by parameter vector β?. Let gα? = ∑n i=1 α ? i yiφ̂(xi) and\nfβ? = ∑n i=1 β ? i yiφ(xi) denote the images of f ? and g? under the natural mapping between the spans of the data in RKHS's Ĥ and H respectively. We will rst show that these four functions have arbitrarily close regularized empirical risk in their respective RKHS, and then that this implies uniform proximity of the functions themselves. First observe that for any g ∈ Ĥ\nRĤreg[g] = C Remp[g] + 1 2 ‖g‖2Ĥ\n≥ C〈∂gRemp[g?], g − g?〉Ĥ + C Remp[g ?] + 1 2 ‖g‖2Ĥ\n= 〈∂gRĤreg[g?], g − g?〉Ĥ − 〈g ?, g − g?〉Ĥ + C Remp[g ?] + 1 2 ‖g‖2Ĥ = C Remp[g?] + 1 2 ‖g‖2Ĥ − 〈g ?, g − g?〉Ĥ = C Remp[g?] + 1 2 ‖g?‖2Ĥ + 1 2 ‖g‖2Ĥ − 1 2 ‖g?‖2Ĥ − 〈g ?, g − g?〉Ĥ\n= RĤreg[g ?] + 1 2 ‖g‖2Ĥ − 〈g ?, g〉Ĥ + 1 2 ‖g?‖2Ĥ\n= RĤreg[g ?] + 1 2 ‖g − g?‖2Ĥ ,\nThe inequality follows from the convexity of Remp[·]; the subsequent equality by ∂gRĤreg[g] = C ∂gRemp[g]+g; the third equality by ∂gR Ĥ reg[g\n?] = 0; and the remainder by gathering terms. With this, Lemma 11 states that for any g ∈ Ĥ and ′ > 0,\nRĤreg[g] ≤ RĤreg[g?] + ′ ⇒ ‖g − g?‖Ĥ ≤ √ 2 ′ .(4.2)\nNext we will show that the antecedent is true for g = gα? . Conditioned on {∥∥∥k − k̂∥∥∥\n∞;M ≤ ′\n} , for all\nx ∈M\n|f?(x)− gα?(x)| = ∣∣∣∣∣ n∑ i=1 α?i yi ( k(xi,x)− k̂(xi,x) )∣∣∣∣∣ ≤\nn∑ i=1 |α?i | ∣∣∣k(xi,x)− k̂(xi,x)∣∣∣\n≤ ′ ‖α?‖1 ≤ ′Λ ,(4.3)\nby the bound on ‖α?‖1. This and the Lipschitz continuity of the loss leads to∣∣∣RHreg[f?]−RĤreg[gα? ]∣∣∣ = ∣∣∣∣C Remp[f?]− C Remp[gα? ] + 12‖f?‖2H − 12‖gα?‖2Ĥ ∣∣∣∣\n≤ C n n∑ i=1 |` (yi, f?(xi))− ` (yi, gα?(xi))|+ 1 2 ∣∣∣α?′ (K− K̂)α?∣∣∣ ≤ C\nn n∑ i=1 L ‖f? − gα?‖∞;M + 1 2 ∣∣∣α?′ (K− K̂)α?∣∣∣ ≤ CL ‖f? − gα?‖∞;M + 1 2 ‖α?‖1 ∥∥∥(K− K̂)α?∥∥∥ ∞ ≤ CL ‖f? − gα?‖∞;M + 1 2 ‖α?‖21 ′ ≤ CL ′Λ + Λ2 ′/2\n= ( CL+\nΛ 2\n) Λ ′ .\nSimilarly, ∣∣∣RĤreg[g?]−RHreg[fβ? ]∣∣∣ ≤ (CL+Λ/2)Λ ′ by the same argument. And since RHreg[fβ? ] ≥ RHreg[f?] and RĤreg[gα? ] ≥ RĤreg[g?] we have proved that RĤreg[gα? ] ≤ RHreg[f?]+(CL+Λ/2)Λ ′ ≤ RHreg[fβ? ]+(CL+Λ/2)Λ ′ ≤ RĤreg[g ?] + 2(CL+ Λ/2)Λ ′. And by implication (4.2),\n‖gα? − g?‖Ĥ ≤ 2\n√( CL+\nΛ 2\n) Λ ′ .(4.4)\nNow k̂(x,x) = 1 for each x ∈ Rd implies |gα?(x)− g?(x)| = 〈 gα? − g?, k̂(x, ·) 〉 Ĥ\n≤ ‖gα? − g?‖Ĥ √ k̂(x,x) = ‖gα? − g?‖Ĥ ,\nThis combines with Inequality (4.4) to yield\n‖gα? − g?‖∞;M ≤ 2\n√( CL+\nΛ 2\n) Λ ′ .\nTogether with Inequality (4.3) this nally implies that ‖f? − g?‖∞;M ≤ ′Λ + 2 √ (CL+ Λ/2) Λ ′, con-\nditioned on event A ′ = {∥∥∥k − k̂∥∥∥\n∞ ≤ ′\n} . For desired accuracy > 0, conditioning on event A ′ with\n′ = min { / [ 2 ( Λ + 2 √ (CL+ Λ/2) Λ )] , 2/ [ 2 ( Λ + 2 √ (CL+ Λ/2) Λ )]2}\nyields bound ‖f? − g?‖∞;M ≤ /2: if ′ ≤ 1 then /2 ≥ √ ′ ( Λ + 2 √ (CL+ Λ/2) Λ ) ≥ ′Λ + 2 √ (CL+ Λ/2) Λ ′ provided that ′ ≤\n2/ [ 2 ( Λ + 2 √ (CL+ Λ/2) Λ )]2 . Otherwise if ′ > 1 then we have /2 ≥ ′ ( Λ + 2 √ (CL+ Λ/2) Λ ) ≥\n′Λ+2 √ (CL+ Λ/2) Λ ′ provided ′ ≤ / [ 2 ( Λ + 2 √ (CL+ Λ/2) Λ )] . Since for any H > 0, min { H,H2 } ≥\nmin { 1, H2 } , the result follows.\nWe now recall the result due to Rahimi and Recht (2008) that establishes the non-asymptotic uniform convergence of the kernel functions required by the previous Lemma (i.e., an upper bound on the probability of event A ′).\nLemma 13 (Rahimi and Recht 2008, Claim 1). For any > 0, δ ∈ (0, 1), translation-invariant kernel k and compact setM⊂ Rd, if d̂ ≥ 4(d+2) 2 loge\n( 28(σpdiam(M))2\nδ 2\n) , then Algorithm 3's random feature mapping φ̂\nde ned in Equation (4.1) satis es Pr (∥∥∥k̂ − k∥∥∥ ∞ < ) ≥ 1− δ, where σ2p = E [〈ω,ω〉] is the second moment of the Fourier transform p of k's g function.\nCombining these ingredients establishes utility for PrivateSVM.\nTheorem 14 (Utility of PrivateSVM). Consider any database D, compact set M ⊂ Rd containing D, convex loss `, translation-invariant kernel k, and scalars C, > 0 and δ ∈ (0, 1). Suppose the SVM with loss `, kernel k and parameter C has dual variables with L1-norm bounded by Λ. Then Algorithm 3 run on D with\nloss `, kernel k, parameters d̂ ≥ 4(d+2)θ( ) loge ( 29(σpdiam(M))2 δθ( ) ) where θ( ) = min { 1,\n4 24 “ Λ+2 √ (CL+Λ/2)Λ ”4 } ,\nλ ≤ min {\n24 loge 2 √ d̂ , √ d̂ 8 loge 2 δ\n} and C is ( , δ)-useful with respect to Algorithm 1 run on D with loss `, kernel\nk and parameter C, wrt the ‖ · ‖∞;M-norm.\nProof. Lemma's 12 and 10 combined via the triangle inequality, with Lemma 13, together establish the result as follows. De ne A to be the conditioning event regarding the approximation of k by k̂, denote the events in Lemma's 12 and 8 by B and C (beware we are overloading C with the regularization parameter; its meaning will be apparent from the context), and the target event in the theorem by D.\nA = ∥∥∥k̂ − k∥∥∥∞;M < min 1, 222„Λ+2q(CL+ Λ2 )Λ«2  \nB = {∥∥∥f? − f̃∥∥∥\n∞;M ≤ /2\n} C = {∥∥∥f̂? − f̃∥∥∥ ∞ ≤ /2 } D = {∥∥∥f? − f̂?∥∥∥ ∞;M ≤ }\nThe claim is a bound on Pr(D). By the triangle inequality events B and C together imply D. Second note that event C is independent of A and B. Thus Pr(D | A) ≥ Pr(B ∩ C | A) = Pr(B | A) Pr(C) ≥ 1 · (1 − δ/2), for su ciently small λ. Finally Lemma 13 bounds Pr(A) as follows: provided that d̂ ≥\n4(d + 2) loge ( 29 (σpdiam(M))2 / (δθ( )) ) /θ( ) where θ( ) = min { 1, 4/ [ 2 ( Λ + 2 √ (CL+ Λ/2) Λ )]4} we\nhave Pr(A) ≥ 1− δ/2. Together this yields Pr(D) = Pr(D | A) Pr(A) ≥ (1− δ/2)2 ≥ 1− δ.\nAgain we see that utility and privacy place competing constraints on the level of noise λ. Next we will use these interactions to upper-bound the optimal di erential privacy of the SVM."
    }, {
      "heading" : "5. Hinge-Loss and an Upper Bound on Optimal Differential Privacy",
      "text" : "We begin by `plugging' hinge loss `(y, ŷ) = (1 − yŷ)+ into the main results on privacy and utility of the previous section (similar computations can be done for PrivateSVM-Finite and other convex loss functions). The following is the dual formulation of hinge-loss SVM learning:\nmax α∈Rn\nn∑ i=1 αi − 1 2 n∑ i=1 n∑ j=1 αiαjyiyjk(xi,xj)(5.1)\ns.t. 0 ≤ αi ≤ C\nn ∀i ∈ [n] .\nCorollary 15. Consider any database D of size n, scalar C > 0, and translation-invariant kernel k. For any β > 0 and d̂ ∈ N, PrivateSVM run on D with hinge loss, noise parameter λ ≥ 2 2.5C √ d̂\nβn , approximation\nparameter d̂, and regularization parameter C, guarantees β-di erential privacy. Moreover for any compact setM⊂ Rd containing D, and scalars > 0 and δ ∈ (0, 1), PrivateSVM run on D with hinge loss, kernel k, noise parameter λ ≤ min {\n24 loge 2 √ d̂ , √ d̂ 8 loge 2 δ } , approximation parameter d̂ ≥ 4(d+2)θ( ) loge ( 29(σpdiam(M))2 δθ( ) ) with θ( ) = min { 1, 4\n212C4\n} , and regularization parameter C, is ( , δ)-useful wrt hinge-loss SVM run on D\nwith kernel k, and parameter C.\nProof. The rst result follows from Theorem 7 and the fact that hinge-loss is convex and 1-Lipschitz on R: i.e., ∂ŷ` = 1[1 ≥ yŷ] ≤ 1. The second result follows almost immediately from Theorem 14. For hinge-loss we have that feasible αi's are bounded by C/n (and so Λ = C) by the dual's box constraints and that L = 1,\nimplying we take θ( ) = min { 1, 4\n24C4(1+ √ 6)4\n} . This is bounded by the stated θ( ).\nCombining the competing requirements on noise level λ upper-bounds optimal di erential privacy of hinge-loss SVM.\nTheorem 16. The optimal di erential privacy for hinge-loss SVM learning on translation-invariant kernel k is bounded by β( , δ, C, n, `, k) = O (\n1 3n √ log 1δ ( log 1 + log 2 1 δ )) .\nProof. Consider hinge loss in Corollary 15. Privacy places a lower bound of β ≥ 22.5C √ d̂/(λn) for any chosen λ, which we can convert to a lower bound on β in terms of and δ as follows. For small , we have\nθ( ) = 42−12C−4 and so to achieve ( , δ)-usefulness we must take d̂ = O (\n1 4 loge ( 1 δ 4 )) . There are two\ncases for utility, if λ = / ( 24 loge ( 2 √ d̂ )) then β = O (√ d̂ loge √ d̂\nn\n) = O ( 1 3n √ log 1δ ( log 1 + log 2 1 δ )) .\nOtherwise we are in the second case, with λ = √ d̂\n8 loge 2 δ\nyielding β = O (\n1 n log 1 δ\n) which is dominated by the\nrst case as ↓ 0.\nA natural question arises from this discussion: given any mechanism that is ( , δ)-useful with respect to hinge SVM, for how small a β can we possibly hope to guarantee β-di erential privacy? In other words, what lower bounds exist for the optimal di erential privacy for the SVM?\n6. Lower Bounding Optimal Differential Privacy\nTo lower bound β for any ( , δ)-useful mechanism, we rst establish a negative sensitivity result for the SVM, by constructing two neighboring databases on which SVM classi ers di er. Lemma 17. For any C > 0, n > 1 and 0 < < √ C\n2n , there exists a pair of neighboring databases D1, D2 on n entries, such that the functions f?1 , f ? 2 parametrized by SVM run with parameter C, linear kernel, and hinge loss on D1, D2 respectively, satisfy ‖f?1 − f?2 ‖∞ > 2 .\nProof. We construct the two databases on the line as follows. Let 0 < m < M be scalars to be chosen later. Both databases share negative examples x1 = . . . = xbn/2c = −M and positive examples xbn/2c+1 = . . . = xn−1 = M . Each database has xn = M −m, with yn = −1 for D1 and yn = 1 for D2. In what follows we use subscripts to denote an example's parent database, so (xi,j , yi,j) is the jth example from Di. Consider the result of running primal SVM on each database\nw?1 = arg min w∈R 1 2 w2 + C n n∑ i=1 (1− y1,iwx1,i)+\nw?2 = arg min w∈R 1 2 w2 + C n n∑ i=1 (1− y2,iwx2,i)+ .\nEach optimization is strictly convex and unconstrained, so the optimizing w?1 , w ? 2 are characterized by the\nrst-order KKT conditions 0 ∈ ∂wfi(w) for fi being the objective function for learning on Di, and ∂w denoting the subdi erential operator. Now for each i ∈ [2]\n∂wfi(w) = w − C\nn n∑ j=1 yi,jxi,j 1̃ [1− yi,jwxi,j ] ,\nwhere\n1̃[x] =  {0} , if x < 0 [0, 1] , if x = 0 {1} , if x > 0\nis the subdi erential of (x)+. Thus for each i ∈ [2], w?i ∈ Cn ∑n j=1 yi,jxi,j 1̃ [1− yi,jw?i xi,j ] which is equivalent to\nw?1 ∈ CM(n− 1) n 1̃ [ 1 M − w?1 ] + C(m−M) n 1̃ [ w?1 − 1 m−M ] w?2 ∈\nCM(n− 1) n\n1̃ [\n1 M − w?2\n] + C(M −m) n 1̃ [ 1 M −m − w?2 ] .\nThe RHSs of these conditions correspond to decreasing piecewise-constant functions, and the conditions are met when the corresponding functions intersect with the diagonal y = x line, as shown in Figure 6. If C(M(n−2)+m)\nn < 1 M then w ? 1 = C(M(n−2)+m) n . And if C(Mn−m) n < 1 M then w ? 2 = C(Mn−m) n . So provided that\n1 M > C(Mn−m) n = max\n{ C(M(n−2)+m)\nn , C(Mn−m) n } , we have |w?1 − w?2 | = 2Cn |M −m|. So taking M = 2n C\nand m = n C , this implies\n‖f?1 − f?2 ‖∞ ≥ |f ? 1 (1)− f?2 (1)|\n= |w?1 − w?2 | = 2 ,\nprovided < √ C\n2n .\nTheorem 18 (Lower bound on optimal di erential privacy for hinge loss SVM). For any C > 0, n > 1, δ ∈ (0, 1) and ∈ ( 0, √ C\n2n\n) , the optimal di erential privacy for the hinge-loss SVM with linear kernel is\nlower-bounded by loge 1−δ δ . In other words, for any C, β > 0 and n > 1 if a mechanism M̂ is ( , δ)-useful and β-di erentially private then either ≥ √ C\n2n or δ ≥ exp(−β).\nProof. Consider ( , δ)-useful mechanism M̂ with respect to SVM learning mechanism M with parameter C > 0, hinge loss and linear kernel on n training examples, where δ > 0 and √ C\n2n > > 0. By Lemma 17 there exists a pair of neighboring databasesD1, D2 on n entries, such that ‖f?1−f?2 ‖∞ > 2 where f?i = fM(Di) for each i ∈ [2]. Let f̂i = fM̂(Di) for each i ∈ [2]. Then by the utility of M̂ ,\nPr ( f̂1 ∈ B∞ (f?1 ) ) ≥ 1− δ ,(6.1)\nPr ( f̂2 ∈ B∞ (f?1 ) ) ≤ Pr ( f̂2 /∈ B∞ (f?2 ) ) < δ .(6.2)\nLet P̂1 and P̂2 be the distributions of M̂(D1) and M̂(D2) respectively so that P̂i(t) = Pr ( M̂(Di) = t ) .\nThen by Inequalities (6.1) and (6.2) ET∼P1 [ dP2(T ) dP1(T ) ∣∣∣∣ T ∈ B∞ (f?1 )] = B∞ (f?1 ) dP2(t) dP1(t)dP1(t)\nB∞ (f?1 ) dP1(t)\n≤ δ 1− δ .\nThus there exists a t such that log Pr(M̂(D1)=t) Pr(M̂(D2)=t) ≥ log 1−δ δ .\nThe same technique can be extended to prove a stronger lower bound. First we construct a set of N > 1 neighboring databases having SVM images that are a 2 -packing. To achieve this for any N we move from linear to RBF kernel.\nLemma 19. For any C > 0, n > C, 0 < < C4n , and 0 < σ < √ 1 2 loge 2 there exists a set of N = ⌊ 2 σ √ 2 loge 2 ⌋ pairwise-neighboring databases {Di}Ni=1 on n examples, such that the functions f?i parametrized by hinge-loss SVM run on Di with parameter C and RBF kernel with parameter σ, satisfy\n∥∥f?i − f?j ∥∥∞ > 2 for each i 6= j.\nProof. Construct N > 1 pairwise neighboring databases each on n examples in R2 as follows. Each database i has n − 1 negative examples xi,1 = . . . = xi,n−1 = 0, and database Di has positive example xi,n = (cos θi, sin θi) where θi = 2πiN . Consider the result of running SVM with hinge loss and RBF kernel on each Di. For each database k(xi,s,xi,t) = 1 and k(xi,s,xi,n) = exp ( − 12σ2 ) =: γ for all s, t ∈ [n− 1] . Notice that the range space of γ is (0, 1). Since the inner-products and labels are database-independent, the SVM dual variables are also database-independent. Each involves solving\nmax α∈Rn\nα′1− 1 2 α′ ( 1 −γ −γ 1 ) α\ns.t. 0 ≤ α ≤ C n 1\nBy symmetry α?1 = . . . = α ? n−1, so we can reduce this to the equivalent program on two variables:\nmax α∈R2\nα′ ( n− 1\n1\n) − 1 2 α′ ( (n− 1)2 −γ(n− 1) −γ(n− 1) 1 ) α\ns.t. 0 ≤ α ≤ C n 1\nConsider rst the unconstrained program. In this case the necessary rst-order KKT condition is that 0 = ( n− 1\n1\n) − (\n(n− 1)2 −γ(n− 1) −γ(n− 1) 1\n) α? .\nThis implies\nα? = (\n(n− 1)2 −γ(n− 1) −γ(n− 1) 1\n)−1( n− 1\n1 ) =\n1 (n− 1)2(1− γ2)\n( 1 γ(n− 1) γ(n− 1) (n− 1)2 )( n− 1 1 ) =\n1 (n− 1)2(1− γ)(1 + γ)\n( 1 γ(n− 1) γ(n− 1) (n− 1)2 )( n− 1 1 ) =\n1 (n− 1)2(1− γ)(1 + γ) ( (n− 1)(1 + γ) (n− 1)2(1 + γ) ) = ( 1 (n−1)(1−γ) 1\n1−γ\n) .\nSince this solution is strictly positive, it follows that at most two (upper) constraints can be active. Thus four cases are possible: the solution lies in the interior of the feasible set, or one or both upper box-constraints hold with equality. Noting that 1(n−1)(1−γ) ≤ 1 1−γ it follows that α ? is feasible i 11−γ ≤ C n . This is equivalent to C ≥ 11−γn > n, since γ ∈ (0, 1). This corresponds to under-regularization. If both constraints hold with equality we have α? = Cn 1, which is always feasible.\nIn the case where the rst constraint holds with equality α?1 = C n , the second dual variable is found by\noptimizing\nα?2 = max α2∈R\nα′ ( n− 1\n1\n) − 1 2 α′ ( (n− 1)2 −γ(n− 1) −γ(n− 1) 1 ) α\n= max α2∈R C(n− 1) n + α2 − 1 2\n(( C(n− 1)\nn\n)2 − 2Cγ(n− 1)\nn α2 + α22\n)\n= max α2∈R −1 2 α22 + α2\n( 1 +\nCγ(n− 1) n\n) ,\nimplying α?2 = 1 + Cγ n−1 n . This solution is feasible provided 1 + Cγ n−1 n ≤ C n i n ≤ C(1+γ) 1+Cγ . Again this corresponds to under-regularization. Finally in the case where the second constraint holds with equality α?2 = C n , the rst dual is found by optimizing\nα?2 = max α1∈R\nα′ ( n− 1\n1\n) − 1 2 α′ ( (n− 1)2 −γ(n− 1) −γ(n− 1) 1 ) α\n= max α1∈R\n(n− 1)α1 + C n − 1 2\n( (n− 1)2α21 − 2Cγ\nn− 1 n α1 + C2 n2 ) = max\nα2∈R −1 2 (n− 1)2α21 + α1\n( 1 + Cγ\nn\n) ,\nimplying α?1 = 1+Cγn (n−1)2 . This is feasible provided 1+Cγn (n−1)2 ≤ C n . Passing back to the program on n variables, by the invariance of the duals to the database, for any pair Di, Dj\n|fi (xi,n)− fj (xi,n)| = α?n (1− k (xi,n,xj,n)) ≥ α?n (\n1−max q 6=i\nk (xi,n,xq,n) ) .\nNow a simple argument shows that this maximum is equal to γ4 exp ( sin2 πN ) for all i. The maximum objective is optimized when |q− i| = 1. In this case |θi − θq| = 2πN . The norm ‖xi,n − xq,n‖ = 2 sin |θi−θq| 2 = 2 sin π N by\nbasic geometry. Thus k (xi,n,xq,n) = exp ( −‖xi,n−xq,n‖ 2\n2σ2\n) = exp ( − 2σ2 sin 2 π N ) = γ4 exp ( sin2 πN ) as claimed.\nNotice that N ≥ 2 so the second term is in (1, e], while the rst term is in (0, 1). In summary we have shown that for any i 6= j\n|fi (xi,n)− fj (xi,n)| ≥ ( 1− exp ( − 2 σ2 sin2 π N )) α?n .\nAssume γ < 12 . If n > C then n > C 2 > (1 − γ)C in which implies case 1 is infeasible. Similarly since Cγ n−1n > 0, n > C implies 1 +Cγ n−1 n > 1 > C n which implies case 3 is infeasible. Thus provided that γ < 1 2 and n > C we have that either case 2 or case 4 must hold. In both cases α?n = C n giving\n|fi (xi,n)− fj (xi,n)| ≥ ( 1− exp ( − 2 σ2 sin2 π N )) C n .\nProvided that σ ≤ √\n2 log 2 sin π N we have\n( 1− exp ( − 2σ2 sin 2 π N )) C n ≥ ( 1− 12 ) C n = C 2n . Now for small x we\ncan take the linear approximation sinx ≥ xπ/2 for x ∈ [0, π/2]. If N ≥ 2 then sin π N ≥ 2 N . Thus in this case we can take σ ≤ √\n2 log 2 2 N to imply |fi (xi,n)− fj (xi,n)| ≥ C 2n . This bound on σ in turn implies the following bound on γ: γ = exp ( − 12σ2 ) ≤ exp ( −N 2 loge 2 24 ) . Thus taking N > 4, in conjunction with σ ≤ √ 2 log 2 2 N\nimplies γ ≤ 12 . Rather than selecting N which bounds σ, we can choose N in terms of σ. σ ≤ √ 2 log 2 2 N is\nimplied by N = 2σ √ 2 loge 2 . So for small σ we can construct more databases leading to the desired separation.\nFinally, N > 4 implies that we must constrain σ < √\n1 2 loge 2 .\nIn summary, if n > C and σ < √\n1 2 loge 2 then |fi (xi,n)− fj (xi,n)| ≥ C2n for each i 6= j ∈ [N ] where N = ⌊\n2 σ\n√ 2\nloge 2\n⌋ . Moreover if ≤ C4n then for any i 6= j this implies ‖fi − fj‖∞ ≥ 2 as claimed.\nTheorem 20 (Strong lower bound on optimal di erential privacy for hinge loss). For C > 0, n > C, δ ∈ (0, 1), ∈ ( 0, n4C ) , and σ < √ 1 2 loge 2 the optimal di erential privacy for the hinge SVM with RBF kernel having parameter σ is lower-bounded by loge (1−δ)(N−1) δ , where N = ⌊ 2 σ √ 2\nloge 2\n⌋ . That is, under these\nconditions, all mechanisms that are ( , δ)-useful wrt hinge SVM with RBF kernel for any σ do not achieve di erential privacy at any level.\nProof. Consider ( , δ)-useful mechanism M̂ with respect to hinge SVM learning mechanism M with parameter C > 0 and RBF kernel with parameter 0 < σ < √ 1\n2 loge 2 on n training examples, where δ > 0 and\nn 4C > > 0. Let N = ⌊ 2 σ √ 2\nloge 2\n⌋ > 4. By Lemma 19 there exist pairwise neighboring databases D1, . . . , DN\nof n entries, such that {f?i } N i=1 is an -packing wrt the L∞-norm, where f ? i = fM(Di). So by the utility of M̂ , for each i ∈ [N ]\nPr ( f̂i ∈ B∞ (f?i ) ) ≥ 1− δ ,(6.3) ∑\nj 6=1\nPr ( f̂1 ∈ B∞ ( f?j )) ≤ Pr ( f̂1 /∈ B∞ (f?1 ) ) < δ ,\n⇒ ∃j 6= 1, Pr ( f̂1 ∈ B∞ ( f?j )) < δ\nN − 1 .(6.4) Let P̂1 and P̂j be the distributions of M̂(D1) and M̂(Dj) respectively so that for each, P̂i(t) = Pr ( M̂(Di) = t ) .\nThen by Inequalities (6.3) and (6.4) ET∼Pj [ dP1(T ) dPj(T ) ∣∣∣∣ T ∈ B∞ (f?j )] = B∞ (f?j ) dP1(t) dPj(t)dPj(t)\nB∞ (f?j ) dPj(t)\n≤ δ (1− δ)(N − 1) .\nThus there exists a t such that log Pr(M̂(Dj)=t) Pr(M̂(D1)=t) ≥ log (1−δ)(N−1) δ .\nNote that n > C is a weak condition, since C should grow like √ n for universal consistency. Also note that this negative result is consistent with our upper bound on optimal di erential privacy: σ a ects σp, increasing the upper bounds as σ ↓ 0."
    }, {
      "heading" : "7. Conclusion & Open Problems",
      "text" : "We have presented a pair of new mechanisms for private SVM learning. In each case we have established di erential privacy via the algorithmic stability of regularized empirical risk minimization. To achieve utility under in nite-dimensional feature mappings, we perform regularized ERM in a random Reproducing Kernel Hilbert Space whose kernel approximates the target RKHS kernel. This trick, borrowed from large-scale learning, permits the mechanism to privately respond with a nite representation of a maximum-margin hyperplane classi er. We then established the high-probability, pointwise similarity between the resulting function and the SVM classi er through a new smoothness result of regularized ERM with respect to perturbations of the RKHS. The bounds on di erential privacy and utility combine to upper bound the optimal di erential privacy of SVM learning for hinge-loss. This quantity is the optimal level of privacy among all mechanisms that are ( , δ)-useful with respect to the hinge-loss SVM. Finally, we derived a lower bound on this quantity which established that any mechanism that is too accurate with respect to the hinge SVM with RBF kernel, with any non-trivial probability, cannot be β-di erentially private for small β. The lower bounds explicitly depend on the variance of the RBF kernel.\nAn interesting open problem is to derive lower bounds holding for moderate to large . Another direction for future research is to extend our mechanisms to other kernel methods. Finally, a general connection between algorithmic stability and global sensitivity would immediately suggest a number of practical privacypreserving learning mechanisms."
    }, {
      "heading" : "Acknowledgments",
      "text" : "We thank Ali Rahimi for helpful discussions relating to this research. We gratefully acknowledge the support of the NSF through grant DMS-0707060, and the support of the Siebel Scholars Foundation."
    }, {
      "heading" : "Appendix A. Proofs for Subdifferentiable Loss Functions",
      "text" : "The main results were stated in terms of non-di erentiable convex loss functions so that they would hold for the hinge loss, however the proofs in the main text applied to di erentiable loss functions only. For completeness we now re-prove the appropriate lemma's for subdi erentiable loss functions of which general convex loss functions are a special case.\nIn each case the proofs for subdi erentiable loss are essentially identical to the di erentiable loss proofs: we discuss only the arguments that change when generalizing to non-di erentiable loss functions. Previously ∂w referred to the gradient operator, now it refers to the subdi erential operator. The subscript reminds us that we are viewing the operand as a function of w only. Similarly other subscripts extend the notion of other partial derivatives. Previously there was a unique gradient at each point, now there may be many subgradients, making up the subdi erential set at a point. As we are dealing with sets of subgradients, we use the shorthand that for sets S, T , vector v and scalar a that: S + T = {g + h | g ∈ S, h ∈ T}, aS = {ag | g ∈ S}, S+v = {g + v | g ∈ S}, 〈S,v〉 = {〈g,v〉 | g ∈ S} and S ≥ T means g ≥ h for all (g, h) ∈ S×T .\nLemma 21 generalizes Lemma 6 on the sensitivity of the SVM primal weight vector, to general (i.e., subdi erentiable) convex loss functions.\nLemma 21. Consider loss function `(y, ŷ) that is convex and L-Lipschitz in ŷ, and RKHS H induced by nite F -dimensional feature mapping φ with bounded kernel k(x,x) ≤ κ2 for all x ∈ Rd. Let wS ∈ RF be the minimizer of the following regularized empirical risk function for each database S = {(xi, yi)}ni=1\nRreg(w, S) = C\nn n∑ i=1 ` (yi, fw(xi)) + 1 2 ‖w‖22 .\nThen for every pair of neighboring databases D,D′ of n entries, ‖wD −wD′‖1 ≤ 4LCκ √ F/n.\nProof. For convenience we de ne Remp(w, S) = n−1 ∑n i=1 `(yi, fw(xi) for any training set S, then the rstorder necessary KKT conditions imply\n0 ∈ ∂wRreg(wD, D) = C∂wRemp(wD, D) + wD ,(A.1) 0 ∈ ∂wRreg(wD′ , D′) = C∂wRemp(wD′ , D′) + wD′ .(A.2)\nDe ne the auxiliary risk function\nR̃(w) = C〈∂wRemp(wD, D)− ∂wRemp(wD′ , D′), w −wD′〉+ 1 2 ‖w −wD′‖22 .\nIt is easy to see that R̃(w) is strictly convex in w and that R̃(wD′) = {0}. And by Equation (A.2)\nC∂wRemp(wD, D) + w ∈ C∂wRemp(wD, D)− C∂wRemp(wD′ , D′) + w −wD′ = ∂wR̃(w) ,\nwhich combined with Equation (A.1) implies 0 ∈ ∂wR̃(wD), so that R̃(w) is minimized at wD. Thus there exists some non-positive r ∈ R̃(wD). Next simplify the rst term of R̃(wD), scaled by n/C for notational\nconvenience:\nn〈∂wRemp(wD, D)− ∂wRemp(wD′ , D′), w −wD′〉\n= n∑ i=1 〈∂w` (yi, fwD (xi))− ∂w` ( y′i, fwD′ (x ′ i) ) , w −wD′〉\n= n−1∑ i=1 ( `′ (yi, fwD (xi))− `′ ( yi, fwD′ (xi) )) ( fwD (xi)− fwD′ (xi) ) +`′ (yn, fwD (xn)) ( fwD (xn)− fwD′ (xn) ) − `′ ( y′n, fwD′ (x ′ n) ) ( fwD (x ′ n)− fwD′ (x ′ n) )\n≥ `′ (yn, fwD (xn)) ( fwD (xn)− fwD′ (xn) ) − `′ ( y′n, fwD′ (x ′ n) ) ( fwD (x ′ n)− fwD′ (x ′ n) ) ,\nwhere the second equality follows from ∂w` (y, fw(x)) = `′ (y, fw(x)) φ(x), where `′(y, ŷ) = ∂ŷ`(y, ŷ), and x′i = xi and y ′ i = yi for each i ∈ [n − 1]. The inequality follows from the convexity of ` in its second\nargument.6 Combined with the existence of non-positive r ∈ R̃(wD) this yields that there exists g ∈ `′ ( y′n, fwD′ (x ′ n) ) ( fwD (x ′ n)− fwD′ (x ′ n) ) − `′ (yn, fwD (xn)) ( fwD (xn)− fwD′ (xn) ) such that\n0 ≥ n C r\n≥ g + n 2C ‖wD −wD′‖22\nAnd since |g| ≤ 2L ∥∥fwD − fwD′∥∥∞ by the Lipschitz continuity of `, this in turn implies\nn\n2C ‖wD −wD′‖22 ≤ 2L ∥∥fwD − fwD′∥∥∞ .(A.3) Now by the reproducing property and Cauchy-Schwartz inequality we can upper bound the classi er di erence's in nity norm by the Euclidean norm on the weight vectors: for each x∣∣fwD (x)− fwD′ (x)∣∣ = |〈φ(x),wD −wD′〉|\n≤ ‖φ(x)‖2 ‖wD −wD′‖2 = √ k(x,x) ‖wD −wD′‖2 ≤ κ ‖wD −wD′‖2 .\nCombining this with Inequality (A.3) yields ‖wD −wD′‖2 ≤ 4LCκ/n as claimed. The L1-based sensitivity then follows from ‖w‖1 ≤ √ F‖w‖2 for all w ∈ RF .\nNext we move to proofs of utility. Lemma 22 mirrors Lemma 12, generalizing the result to nondi erentiable convex loss functions.\nLemma 22. Let H be an RKHS with translation-invariant kernel k, and let Ĥ be the random RKHS corresponding to feature map (4.1) induced by k. Let C be a positive scalar and loss `(y, ŷ) be convex and L-Lipschitz continuous in ŷ. Consider the regularized empirical risk minimizers in each RKHS\nf? ∈ arg min f∈H\nC\nn n∑ i=1 `(yi, f(xi)) + 1 2 ‖f‖2H ,\ng? ∈ arg min g∈Ĥ\nC\nn n∑ i=1 `(yi, g(xi)) + 1 2 ‖g‖2Ĥ .\nLet M ⊆ Rd be any set containing x1, . . . ,xn. For any > 0, if the dual variables from both optimizations have L1-norms bounded by some Λ > 0 and ∥∥∥k − k̂∥∥∥\n∞;M ≤ min\n{ 1,\n2 22 “ Λ+2 √ (CL+Λ/2)Λ ”2 } then\n‖f? − g?‖∞;M ≤ /2.\n6Namely for convex f and any a, b ∈ R, (ga − gb) (a− b) ≥ 0 for all ga ∈ ∂f(a) and all gb ∈ ∂f(b).\nProof. Denote the empirical risk functional Remp[f ] = n−1 ∑n i=1 ` (yi, f(xi)) and the regularized empirical risk functional Rreg[f ] = C Remp[f ] + ‖f‖2/2, for the appropriate RKHS norm (either H or Ĥ). Let f? denote the regularized empirical risk minimizer in H, given by parameter vector α?, and let g? denote the regularized empirical risk minimizer in Ĥ given by parameter vector β?. Let gα? = ∑n i=1 α ? i yiφ̂(xi) and\nfβ? = ∑n i=1 β ? i yiφ(xi) denote the images of f ? and g? under the natural mapping between the spans of the data in RKHS's Ĥ and H respectively. We will rst show that these four functions have arbitrarily close regularized empirical risk in their respective RKHS, and then that this implies uniform proximity of the functions themselves. First observe that for any g ∈ Ĥ\nRĤreg[g] = C Remp[g] + 1 2 ‖g‖2Ĥ\n≥ C〈∂gRemp[g?], g − g?〉Ĥ + C Remp[g ?] + 1 2 ‖g‖2Ĥ\n= 〈∂gRĤreg[g?], g − g?〉Ĥ − 〈g ?, g − g?〉Ĥ + C Remp[g ?] + 1 2 ‖g‖2Ĥ .\nThe inequality follows from the convexity ofRemp[·] and holds for all elements of the subdi erential ∂gRemp[g?]. The subsequent equality holds by ∂gR Ĥ reg[g] = C ∂gRemp[g] + g. Now since 0 ∈ ∂gRĤreg[g?], it follows that\nRĤreg[g] ≥ C Remp[g?] + 1 2 ‖g‖2Ĥ − 〈g ?, g − g?〉Ĥ\n= C Remp[g?] + 1 2 ‖g?‖2Ĥ + 1 2 ‖g‖2Ĥ − 1 2 ‖g?‖2Ĥ − 〈g ?, g − g?〉Ĥ\n= RĤreg[g ?] + 1 2 ‖g‖2Ĥ − 〈g ?, g〉Ĥ + 1 2 ‖g?‖2Ĥ\n= RĤreg[g ?] + 1 2 ‖g − g?‖2Ĥ .\nThe remainder of Lemma 12's proof remains the same, as it does not depend on the loss's di erentiability."
    } ],
    "references" : [ {
      "title" : "Privacy, accuracy, and consistency too: a holistic solution to contingency table release",
      "author" : [ "Boaz Barak", "Kamalika Chaudhuri", "Cynthia Dwork", "Satyen Kale", "Frank McSherry", "Kunal Talwar" ],
      "venue" : "Proceedings of the Twenty-Sixth ACM SIGMOD-SIGACT-SIGART Symposium on Principles of Database Systems,",
      "citeRegEx" : "Barak et al\\.,? \\Q2007\\E",
      "shortCiteRegEx" : "Barak et al\\.",
      "year" : 2007
    }, {
      "title" : "Pattern Recognition and Machine Learning",
      "author" : [ "Christopher M. Bishop" ],
      "venue" : null,
      "citeRegEx" : "Bishop.,? \\Q2006\\E",
      "shortCiteRegEx" : "Bishop.",
      "year" : 2006
    }, {
      "title" : "Practical privacy: the SuLQ framework",
      "author" : [ "Avrim Blum", "Cynthia Dwork", "Frank McSherry", "Kobbi Nissim" ],
      "venue" : "Proceedings of the Twenty-Fourth ACM SIGMOD-SIGACT-SIGART Symposium on Principles of Database Systems,",
      "citeRegEx" : "Blum et al\\.,? \\Q2005\\E",
      "shortCiteRegEx" : "Blum et al\\.",
      "year" : 2005
    }, {
      "title" : "A learning theory approach to non-interactive database privacy",
      "author" : [ "Avrim Blum", "Katrina Ligett", "Aaron Roth" ],
      "venue" : "Proceedings of the 40th Annual ACM Symposium on Theory of Computing,",
      "citeRegEx" : "Blum et al\\.,? \\Q2008\\E",
      "shortCiteRegEx" : "Blum et al\\.",
      "year" : 2008
    }, {
      "title" : "A tutorial on support vector machines for pattern recognition",
      "author" : [ "Christopher J.C. Burges" ],
      "venue" : "Data Mining and Knowledge Discovery,",
      "citeRegEx" : "Burges.,? \\Q1998\\E",
      "shortCiteRegEx" : "Burges.",
      "year" : 1998
    }, {
      "title" : "Privacy-preserving logistic regression",
      "author" : [ "Kamalika Chaudhuri", "Claire Monteleoni" ],
      "venue" : "In Advances in Neural Information Processing Systems",
      "citeRegEx" : "Chaudhuri and Monteleoni.,? \\Q2009\\E",
      "shortCiteRegEx" : "Chaudhuri and Monteleoni.",
      "year" : 2009
    }, {
      "title" : "An Introduction to Support Vector Machines",
      "author" : [ "Nello Cristianini", "John Shawe-Taylor" ],
      "venue" : null,
      "citeRegEx" : "Cristianini and Shawe.Taylor.,? \\Q2000\\E",
      "shortCiteRegEx" : "Cristianini and Shawe.Taylor.",
      "year" : 2000
    }, {
      "title" : "Distribution-free performance bounds for potential function rules",
      "author" : [ "Luc P. Devroye", "T.J. Wagner" ],
      "venue" : "IEEE Transactions on Information Theory,",
      "citeRegEx" : "Devroye and Wagner.,? \\Q1979\\E",
      "shortCiteRegEx" : "Devroye and Wagner.",
      "year" : 1979
    }, {
      "title" : "Revealing information while preserving privacy",
      "author" : [ "Irit Dinur", "Kobbi Nissim" ],
      "venue" : "Proceedings of the Twenty-Second ACM SIGMOD-SIGACT-SIGART Symposium on Principles of Database Systems,",
      "citeRegEx" : "Dinur and Nissim.,? \\Q2003\\E",
      "shortCiteRegEx" : "Dinur and Nissim.",
      "year" : 2003
    }, {
      "title" : "Di erential privacy and robust statistics",
      "author" : [ "Cynthia Dwork", "Jing Lei" ],
      "venue" : "Proceedings of the 41st Annual ACM Symposium on Theory of Computing,",
      "citeRegEx" : "Dwork and Lei.,? \\Q2009\\E",
      "shortCiteRegEx" : "Dwork and Lei.",
      "year" : 2009
    }, {
      "title" : "New e cient attacks on statistical disclosure control mechanisms",
      "author" : [ "Cynthia Dwork", "Sergey Yekhanin" ],
      "venue" : "In CRYPTO 2008: Proceedings of the 28th Annual conference on Cryptology,",
      "citeRegEx" : "Dwork and Yekhanin.,? \\Q2008\\E",
      "shortCiteRegEx" : "Dwork and Yekhanin.",
      "year" : 2008
    }, {
      "title" : "Calibrating noise to sensitivity in private data analysis",
      "author" : [ "Cynthia Dwork", "Frank McSherry", "Kobbi Nissim", "Adam Smith" ],
      "venue" : "In 3rd Theory of Cryptography Conference (TCC",
      "citeRegEx" : "Dwork et al\\.,? \\Q2006\\E",
      "shortCiteRegEx" : "Dwork et al\\.",
      "year" : 2006
    }, {
      "title" : "The price of privacy and the limits of LP decoding",
      "author" : [ "Cynthia Dwork", "Frank McSherry", "Kunal Talwar" ],
      "venue" : "Proceedings of the Thirty-Ninth Annual ACM Symposium on Theory of Computing,",
      "citeRegEx" : "Dwork et al\\.,? \\Q2007\\E",
      "shortCiteRegEx" : "Dwork et al\\.",
      "year" : 2007
    }, {
      "title" : "On the complexity of di erentially private data release: e cient algorithms and hardness results",
      "author" : [ "Cynthia Dwork", "Moni Naor", "Omer Reingold", "Guy N. Rothblum", "Salil Vadhan" ],
      "venue" : "Proceedings of the 41st Annual ACM Symposium on Theory of Computing,",
      "citeRegEx" : "Dwork et al\\.,? \\Q2009\\E",
      "shortCiteRegEx" : "Dwork et al\\.",
      "year" : 2009
    }, {
      "title" : "What can we learn privately",
      "author" : [ "Shiva Prasad Kasiviswanathan", "Homin K. Lee", "Kobbi Nissim", "Sofya Raskhodnikova", "Adam Smith" ],
      "venue" : "Proceedings of the 2008 49th Annual IEEE Symposium on Foundations of Computer Science,",
      "citeRegEx" : "Kasiviswanathan et al\\.,? \\Q2008\\E",
      "shortCiteRegEx" : "Kasiviswanathan et al\\.",
      "year" : 2008
    }, {
      "title" : "Algorithmic stability and sanity-check bounds for leave-one-out crossvalidation",
      "author" : [ "Michael Kearns", "Dana Ron" ],
      "venue" : "Neural Computation,",
      "citeRegEx" : "Kearns and Ron.,? \\Q1999\\E",
      "shortCiteRegEx" : "Kearns and Ron.",
      "year" : 1999
    }, {
      "title" : "Some results on Tchebyche an spline functions",
      "author" : [ "George Kimeldorf", "Grace Wahba" ],
      "venue" : "Journal of Mathematical Analysis and Applications,",
      "citeRegEx" : "Kimeldorf and Wahba.,? \\Q1971\\E",
      "shortCiteRegEx" : "Kimeldorf and Wahba.",
      "year" : 1971
    }, {
      "title" : "Almost-everywhere algorithmic stability and generalization error",
      "author" : [ "Samuel Kutin", "Partha Niyogi" ],
      "venue" : "Technical report TR-2002-03,",
      "citeRegEx" : "Kutin and Niyogi.,? \\Q2002\\E",
      "shortCiteRegEx" : "Kutin and Niyogi.",
      "year" : 2002
    }, {
      "title" : "Mechanism design via di erential privacy",
      "author" : [ "Frank McSherry", "Kunal Talwar" ],
      "venue" : "Data Mining,",
      "citeRegEx" : "McSherry and Talwar.,? \\Q2009\\E",
      "shortCiteRegEx" : "McSherry and Talwar.",
      "year" : 2009
    }, {
      "title" : "Random features for large-scale kernel machines",
      "author" : [ "Ali Rahimi", "Benjamin Recht" ],
      "venue" : "IEEE Symposium on Foundations of Computer Science, pages",
      "citeRegEx" : "Rahimi and Recht.,? \\Q2007\\E",
      "shortCiteRegEx" : "Rahimi and Recht.",
      "year" : 2007
    } ],
    "referenceMentions" : [ {
      "referenceID" : 8,
      "context" : "It has been of key interest to the statistical database community to understand when the goals of utility and privacy can be e ciently achieved simultaneously (Dinur and Nissim, 2003; Barak et al., 2007; Dwork et al., 2007; Blum et al., 2008; Chaudhuri and Monteleoni, 2009; Kasiviswanathan et al., 2008).",
      "startOffset" : 159,
      "endOffset" : 304
    }, {
      "referenceID" : 0,
      "context" : "It has been of key interest to the statistical database community to understand when the goals of utility and privacy can be e ciently achieved simultaneously (Dinur and Nissim, 2003; Barak et al., 2007; Dwork et al., 2007; Blum et al., 2008; Chaudhuri and Monteleoni, 2009; Kasiviswanathan et al., 2008).",
      "startOffset" : 159,
      "endOffset" : 304
    }, {
      "referenceID" : 12,
      "context" : "It has been of key interest to the statistical database community to understand when the goals of utility and privacy can be e ciently achieved simultaneously (Dinur and Nissim, 2003; Barak et al., 2007; Dwork et al., 2007; Blum et al., 2008; Chaudhuri and Monteleoni, 2009; Kasiviswanathan et al., 2008).",
      "startOffset" : 159,
      "endOffset" : 304
    }, {
      "referenceID" : 3,
      "context" : "It has been of key interest to the statistical database community to understand when the goals of utility and privacy can be e ciently achieved simultaneously (Dinur and Nissim, 2003; Barak et al., 2007; Dwork et al., 2007; Blum et al., 2008; Chaudhuri and Monteleoni, 2009; Kasiviswanathan et al., 2008).",
      "startOffset" : 159,
      "endOffset" : 304
    }, {
      "referenceID" : 5,
      "context" : "It has been of key interest to the statistical database community to understand when the goals of utility and privacy can be e ciently achieved simultaneously (Dinur and Nissim, 2003; Barak et al., 2007; Dwork et al., 2007; Blum et al., 2008; Chaudhuri and Monteleoni, 2009; Kasiviswanathan et al., 2008).",
      "startOffset" : 159,
      "endOffset" : 304
    }, {
      "referenceID" : 14,
      "context" : "It has been of key interest to the statistical database community to understand when the goals of utility and privacy can be e ciently achieved simultaneously (Dinur and Nissim, 2003; Barak et al., 2007; Dwork et al., 2007; Blum et al., 2008; Chaudhuri and Monteleoni, 2009; Kasiviswanathan et al., 2008).",
      "startOffset" : 159,
      "endOffset" : 304
    }, {
      "referenceID" : 0,
      "context" : "It has been of key interest to the statistical database community to understand when the goals of utility and privacy can be e ciently achieved simultaneously (Dinur and Nissim, 2003; Barak et al., 2007; Dwork et al., 2007; Blum et al., 2008; Chaudhuri and Monteleoni, 2009; Kasiviswanathan et al., 2008). In this paper we consider the practical goal of private regularized empirical risk minimization (ERM) in Reproducing Kernel Hilbert Spaces for the special case of the Support Vector Machine (SVM). We adopt the strong notion of di erential privacy as formalized by Dwork (2006). Our e cient new mechanisms are shown to parametrize functions that are close to non-private SVM under the L∞-norm, with high probability.",
      "startOffset" : 184,
      "endOffset" : 583
    }, {
      "referenceID" : 2,
      "context" : "Early work on private interactive mechanisms focused on approximating real- and vector-valued statistics (e.g., Dinur and Nissim, 2003; Blum et al., 2005; Dwork et al., 2006; Dwork, 2006; Barak et al., 2007).",
      "startOffset" : 105,
      "endOffset" : 207
    }, {
      "referenceID" : 11,
      "context" : "Early work on private interactive mechanisms focused on approximating real- and vector-valued statistics (e.g., Dinur and Nissim, 2003; Blum et al., 2005; Dwork et al., 2006; Dwork, 2006; Barak et al., 2007).",
      "startOffset" : 105,
      "endOffset" : 207
    }, {
      "referenceID" : 0,
      "context" : "Early work on private interactive mechanisms focused on approximating real- and vector-valued statistics (e.g., Dinur and Nissim, 2003; Blum et al., 2005; Dwork et al., 2006; Dwork, 2006; Barak et al., 2007).",
      "startOffset" : 105,
      "endOffset" : 207
    }, {
      "referenceID" : 0,
      "context" : ", 2006; Dwork, 2006; Barak et al., 2007). McSherry and Talwar (2007) rst considered private mechanisms with range spaces parametrizing sets more general than real-valued vectors, and used such di erentially private mappings for mechanism design.",
      "startOffset" : 21,
      "endOffset" : 69
    }, {
      "referenceID" : 0,
      "context" : ", 2006; Dwork, 2006; Barak et al., 2007). McSherry and Talwar (2007) rst considered private mechanisms with range spaces parametrizing sets more general than real-valued vectors, and used such di erentially private mappings for mechanism design. More related to our work are the private mechanisms for regularized logistic regression proposed and analyzed by Chaudhuri and Monteleoni (2009). There the mechanism's range space parametrizes the VC-dimension d + 1 class of linear hyperplanes in R.",
      "startOffset" : 21,
      "endOffset" : 391
    }, {
      "referenceID" : 0,
      "context" : ", 2006; Dwork, 2006; Barak et al., 2007). McSherry and Talwar (2007) rst considered private mechanisms with range spaces parametrizing sets more general than real-valued vectors, and used such di erentially private mappings for mechanism design. More related to our work are the private mechanisms for regularized logistic regression proposed and analyzed by Chaudhuri and Monteleoni (2009). There the mechanism's range space parametrizes the VC-dimension d + 1 class of linear hyperplanes in R. Kasiviswanathan et al. (2008) showed that discretized concept classes can be PAC learned or agnostically learned privately, albeit via an ine cient mechanism.",
      "startOffset" : 21,
      "endOffset" : 526
    }, {
      "referenceID" : 0,
      "context" : ", 2006; Dwork, 2006; Barak et al., 2007). McSherry and Talwar (2007) rst considered private mechanisms with range spaces parametrizing sets more general than real-valued vectors, and used such di erentially private mappings for mechanism design. More related to our work are the private mechanisms for regularized logistic regression proposed and analyzed by Chaudhuri and Monteleoni (2009). There the mechanism's range space parametrizes the VC-dimension d + 1 class of linear hyperplanes in R. Kasiviswanathan et al. (2008) showed that discretized concept classes can be PAC learned or agnostically learned privately, albeit via an ine cient mechanism. Blum et al. (2008) showed that non-interactive mechanisms can privately release anonymized data such that utility is guaranteed over classes of predicate queries with polynomial VC dimension, when the domain is discretized.",
      "startOffset" : 21,
      "endOffset" : 674
    }, {
      "referenceID" : 0,
      "context" : ", 2006; Dwork, 2006; Barak et al., 2007). McSherry and Talwar (2007) rst considered private mechanisms with range spaces parametrizing sets more general than real-valued vectors, and used such di erentially private mappings for mechanism design. More related to our work are the private mechanisms for regularized logistic regression proposed and analyzed by Chaudhuri and Monteleoni (2009). There the mechanism's range space parametrizes the VC-dimension d + 1 class of linear hyperplanes in R. Kasiviswanathan et al. (2008) showed that discretized concept classes can be PAC learned or agnostically learned privately, albeit via an ine cient mechanism. Blum et al. (2008) showed that non-interactive mechanisms can privately release anonymized data such that utility is guaranteed over classes of predicate queries with polynomial VC dimension, when the domain is discretized. Dwork et al. (2009) more recently characterized when utility and privacy can be achieved by e cient non-interactive mechanisms.",
      "startOffset" : 21,
      "endOffset" : 899
    }, {
      "referenceID" : 0,
      "context" : "2005 and Barak et al. 2007 respectively, as examples) and learning algorithms (e.g., interval queries and half-spaces as explored by Blum et al. 2008), or on constructing learning algorithms that can be decomposed into subset-sum operations (e.g., perceptron, k-NN, ID3 as described by Blum et al. 2005, and various recommender systems due to the work of McSherry and Mironov 2009). By contrast, we consider the practical goal of SVM learning, which does not decompose into subsetsums. It is also notable that our mechanisms run in polynomial time. The most related work to our own in this regard is due to Chaudhuri and Monteleoni (2009), although their results hold only for di erentiable loss, and nite feature mappings.",
      "startOffset" : 9,
      "endOffset" : 639
    }, {
      "referenceID" : 8,
      "context" : "A sequence of prior negative results have shown that any mechanism providing overly accurate responses cannot be private (Dinur and Nissim, 2003; Dwork et al., 2007; Dwork and Yekhanin, 2008).",
      "startOffset" : 121,
      "endOffset" : 191
    }, {
      "referenceID" : 12,
      "context" : "A sequence of prior negative results have shown that any mechanism providing overly accurate responses cannot be private (Dinur and Nissim, 2003; Dwork et al., 2007; Dwork and Yekhanin, 2008).",
      "startOffset" : 121,
      "endOffset" : 191
    }, {
      "referenceID" : 10,
      "context" : "A sequence of prior negative results have shown that any mechanism providing overly accurate responses cannot be private (Dinur and Nissim, 2003; Dwork et al., 2007; Dwork and Yekhanin, 2008).",
      "startOffset" : 121,
      "endOffset" : 191
    }, {
      "referenceID" : 0,
      "context" : "Barak et al. (2007) presented a mechanism for releasing contingency tables that guarantees di erential privacy and also guarantees a notion of accuracy: with high probability all marginals from the released table are close in L1-norm to the true table's marginals.",
      "startOffset" : 0,
      "endOffset" : 20
    }, {
      "referenceID" : 0,
      "context" : "Barak et al. (2007) presented a mechanism for releasing contingency tables that guarantees di erential privacy and also guarantees a notion of accuracy: with high probability all marginals from the released table are close in L1-norm to the true table's marginals. As mentioned above, Blum et al. (2008) developed a private non-interactive mechanism that releases anonymized data such that all predicate queries in a VC-class take on similar values on the anonymized data and original data.",
      "startOffset" : 0,
      "endOffset" : 304
    }, {
      "referenceID" : 0,
      "context" : "Barak et al. (2007) presented a mechanism for releasing contingency tables that guarantees di erential privacy and also guarantees a notion of accuracy: with high probability all marginals from the released table are close in L1-norm to the true table's marginals. As mentioned above, Blum et al. (2008) developed a private non-interactive mechanism that releases anonymized data such that all predicate queries in a VC-class take on similar values on the anonymized data and original data. In the work of Kasiviswanathan et al. (2008), utility corresponds to PAC learning: with high probability the response and target concepts are close, averaged over the underlying measure.",
      "startOffset" : 0,
      "endOffset" : 536
    }, {
      "referenceID" : 0,
      "context" : "Barak et al. (2007) presented a mechanism for releasing contingency tables that guarantees di erential privacy and also guarantees a notion of accuracy: with high probability all marginals from the released table are close in L1-norm to the true table's marginals. As mentioned above, Blum et al. (2008) developed a private non-interactive mechanism that releases anonymized data such that all predicate queries in a VC-class take on similar values on the anonymized data and original data. In the work of Kasiviswanathan et al. (2008), utility corresponds to PAC learning: with high probability the response and target concepts are close, averaged over the underlying measure. A sequence of prior negative results have shown that any mechanism providing overly accurate responses cannot be private (Dinur and Nissim, 2003; Dwork et al., 2007; Dwork and Yekhanin, 2008). Dinur and Nissim (2003) showed that if noise of rate only o( √ n) is added to subset sum queries on a database of bits then an adversary can reconstruct a 1− o(1) fraction of the database.",
      "startOffset" : 0,
      "endOffset" : 895
    }, {
      "referenceID" : 12,
      "context" : "This result was more recently extended to allow for mechanisms that answer a small fraction of queries arbitrarily (Dwork et al., 2007).",
      "startOffset" : 115,
      "endOffset" : 135
    }, {
      "referenceID" : 13,
      "context" : "In passing Kasiviswanathan et al. (2008) note the similarity between notions of algorithmic stability and di erential privacy, however do not exploit this.",
      "startOffset" : 11,
      "endOffset" : 41
    }, {
      "referenceID" : 9,
      "context" : "The connection between algorithmic stability and di erential privacy is qualitatively similar to the recent work of Dwork and Lei (2009) who demonstrated that robust estimators can serve as the basis for private mechanisms, by exploiting the limited in uence of outliers on such estimators.",
      "startOffset" : 116,
      "endOffset" : 137
    }, {
      "referenceID" : 2,
      "context" : "2Note that we have chosen to overload the term ( , δ)-usefulness introduced by Blum et al. (2008) for non-interactive mechanisms that release anonymized data.",
      "startOffset" : 79,
      "endOffset" : 98
    }, {
      "referenceID" : 16,
      "context" : "The Representer Theorem (Kimeldorf and Wahba, 1971) states that the minimizing f = arg minf∈H 12‖f‖ 2 H + C n ∑n i=1 `(yi, f(xi)) lies in the span of the functions k(·,xi) ∈ H.",
      "startOffset" : 24,
      "endOffset" : 51
    }, {
      "referenceID" : 4,
      "context" : ", (Burges, 1998; Cristianini and Shawe-Taylor, 2000; Schölkopf and Smola, 2001; Bishop, 2006).",
      "startOffset" : 2,
      "endOffset" : 93
    }, {
      "referenceID" : 6,
      "context" : ", (Burges, 1998; Cristianini and Shawe-Taylor, 2000; Schölkopf and Smola, 2001; Bishop, 2006).",
      "startOffset" : 2,
      "endOffset" : 93
    }, {
      "referenceID" : 1,
      "context" : ", (Burges, 1998; Cristianini and Shawe-Taylor, 2000; Schölkopf and Smola, 2001; Bishop, 2006).",
      "startOffset" : 2,
      "endOffset" : 93
    }, {
      "referenceID" : 7,
      "context" : "Several notions of stability are known to lead to good generalization error bounds (Devroye and Wagner, 1979; Kearns and Ron, 1999; Bousquet and Elissee , 2002; Kutin and Niyogi, 2002), sometimes in cases where class capacity-based approaches such as VC theory do not apply.",
      "startOffset" : 83,
      "endOffset" : 184
    }, {
      "referenceID" : 15,
      "context" : "Several notions of stability are known to lead to good generalization error bounds (Devroye and Wagner, 1979; Kearns and Ron, 1999; Bousquet and Elissee , 2002; Kutin and Niyogi, 2002), sometimes in cases where class capacity-based approaches such as VC theory do not apply.",
      "startOffset" : 83,
      "endOffset" : 184
    }, {
      "referenceID" : 17,
      "context" : "Several notions of stability are known to lead to good generalization error bounds (Devroye and Wagner, 1979; Kearns and Ron, 1999; Bousquet and Elissee , 2002; Kutin and Niyogi, 2002), sometimes in cases where class capacity-based approaches such as VC theory do not apply.",
      "startOffset" : 83,
      "endOffset" : 184
    }, {
      "referenceID" : 11,
      "context" : "With the weight vector's sensitivity in hand, di erential privacy follows immediately from the proof technique established by Dwork et al. (2006).",
      "startOffset" : 126,
      "endOffset" : 146
    }, {
      "referenceID" : 16,
      "context" : "It is natural to look to the SVM's dual solution as a starting point: the Representer Theorem (Kimeldorf and Wahba, 1971) states that the optimizing f ∈ H must be in the span of the data a nite-dimensional subspace.",
      "startOffset" : 94,
      "endOffset" : 121
    }, {
      "referenceID" : 16,
      "context" : "It is natural to look to the SVM's dual solution as a starting point: the Representer Theorem (Kimeldorf and Wahba, 1971) states that the optimizing f ∈ H must be in the span of the data a nite-dimensional subspace. While the coordinates in this subspace the α i dual variables could be perturbed in the usual way to guarantee di erential privacy, the subspace's basis the data are also needed to parametrize f. To side-step this apparent stumbling block, we take another approach by approximating H with a random RKHS Ĥ induced by a random nite-dimensional map φ̂. This then allows us to respond with a nite primal parametrization. Algorithm 3 summarizes the PrivateSVM mechanism. As noted recently by Rahimi and Recht (2008), the Fourier transform p of the g function of a continuous positive-de nite translation-invariant kernel is a non-negative measure (Rudin, 1994).",
      "startOffset" : 95,
      "endOffset" : 727
    }, {
      "referenceID" : 4,
      "context" : "Algorithm 3 takes O(d̂) time to compute each entry of the kernel matrix, or a total time of O(d̂n) on top of running dual SVM in the random feature space which is worst-case O(ns) for the analytic solution (where ns ≤ n is the number of support vectors), and faster using numerical methods such as chunking (Burges, 1998).",
      "startOffset" : 307,
      "endOffset" : 321
    }, {
      "referenceID" : 18,
      "context" : "Rahimi and Recht (2008) applied this approximation to large-scale learning (situations where n is large).",
      "startOffset" : 0,
      "endOffset" : 24
    }, {
      "referenceID" : 19,
      "context" : "We now recall the result due to Rahimi and Recht (2008) that establishes the non-asymptotic uniform convergence of the kernel functions required by the previous Lemma (i.",
      "startOffset" : 32,
      "endOffset" : 56
    } ],
    "year" : 2009,
    "abstractText" : "Several recent studies in privacy-preserving learning have considered the trade-o between utility or risk and the level of di erential privacy guaranteed by mechanisms for statistical query processing. In this paper we study this trade-o in private Support Vector Machine (SVM) learning. We present two e cient mechanisms, one for the case of nite-dimensional feature mappings and one for potentially in nite-dimensional feature mappings with translation-invariant kernels. For the case of translation-invariant kernels, the proposed mechanism minimizes regularized empirical risk in a random Reproducing Kernel Hilbert Space whose kernel uniformly approximates the desired kernel with high probability. This technique, borrowed from large-scale learning, allows the mechanism to respond with a nite encoding of the classi er, even when the function class is of in nite VC dimension. Di erential privacy is established using a proof technique from algorithmic stability. Utility the mechanism's response function is pointwise -close to non-private SVM with probability 1− δ is proven by appealing to the smoothness of regularized empirical risk minimization with respect to small perturbations to the feature mapping. We conclude with a lower bound on the optimal di erential privacy of the SVM. This negative result states that for any δ, no mechanism can be simultaneously ( , δ)-useful and β-di erentially private for small and small β.",
    "creator" : "LaTeX with hyperref package"
  }
}