{
  "name" : "1608.08182.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "Data Poisoning Attacks on Factorization-Based Collaborative Filtering",
    "authors" : [ "Bo Li", "Yining Wang" ],
    "emails" : [ "bo.li.2@vanderbilt.edu", "ynwang.yining@gmail.com", "aarti@cs.cmu.edu", "yevgeniy.vorobeychik@vanderbilt.edu" ],
    "sections" : [ {
      "heading" : "1 Introduction",
      "text" : "Recommendation systems have emerged as a crucial feature of many electronic commerce systems. In machine learning such problems are usually referred to as collaborative filtering or matrix completion, where the known users’ preferences are abstracted into an incomplete user-by-item matrix, and the goal is to complete the matrix and subsequently make new item recommendations for each user. Existing approaches in the literature include nearest-neighbor methods, where a user’s (item’s) preference is determined by other users (items) with similar profiles [1], and factorization-based methods where the incomplete preference matrix is assumed to be approximately low-rank [2, 3].\nAs recommendation systems play an ever increasing role in current information and e-commerce systems, they are susceptible to a risk of being maliciously attacked. One particular form of attacks is called data poisoning, in which a malicious party creates dummy (malicious) users in a recommendation system with carefully chosen item preferences (i.e., data) such that the effectiveness or credibility of the system is maximally degraded. For example, an attacker might attempt to make recommendations that are as different as possible from those that would otherwise be made by the recommendation system. In another, more subtle, example, the attacker is associated with the producer of a specific movie or product, who may wish to increase or decrease the popularity of a certain item. In both cases, the credibility of a recommendation system is harmed by the malicious activities, which could lead to significant economic loss. Due to the open nature of recommendation ∗Both authors contribute equally\n29th Conference on Neural Information Processing Systems (NIPS 2016), Barcelona, Spain.\nar X\niv :1\n60 8.\n08 18\n2v 2\n[ cs\n.L G\n] 5\nsystems and their reliance on user-specified judgments for building profiles, various forms of attacks are possible and have been discussed, such as the random attack and random product push/nuke attack [4, 5]. However, these attacks are not formally analyzed and cannot be optimized according to specific collaborative filtering algorithms. As it is not difficult for attackers to determine the defender’s filtering algorithm or even its parameters settings (e.g., through insider attacks), this can lead one to significantly under-estimate the attacker’s ability and result in substantial loss.\nWe present a systematic approach to computing near-optimal data poisoning attacks for factorizationbased collaborative filtering/recommendation models. We assume a highly motivated attacker with knowledge of both the learning algorithms and parameters of the learner following the Kerckhoffs’ principle to ensure reliable vulnerability analysis in the worst case. We focus on two most popular algorithms: alternating minimization [6] and nuclear norm minimization [3]. Our main contributions are as follows:\n• Comprehensive characterization of attacker utilities: We characterize several attacker utilities, which include availability attacks, where prediction error is increased, and integrity attacks, where item-specific objectives are considered. Optimal attack strategies for all utilities can be computed under a unified optimization framework.\n• Novel gradient computations: Building upon existing gradient-based data poisoning frameworks [7, 8, 9], we develop novel methods for gradient computation based on first-order KKT conditions for two widely used algorithms: alternating minimization [6] and nuclear norm minimization [2]. The resulting derivations are highly non-trivial; in addition, to our knowledge this work is the first to give systematic data poisoning attacks for problems involving non-smooth nuclear norm type objectives.\n• Mimicking normal user behaviors: For data poisoning attacks, most prior work focuses on maximizing attacker’s utility. A less investigated problem is how to synthesize malicious data points that are hard for a defender to detect. In this paper we provide a novel technique based on stochastic gradient Langevin dynamics optimization [10] to produce malicious users that mimic normal user behaviors in order to avoid detection, while achieving attack objectives.\nRelated Work: There has been extensive prior research concerning the security of machine learning algorithms [11, 12, 13, 14, 15]. Biggio et al. pioneered the research of optimizing malicious datadriven attacks for kernel-based learning algorithms such as SVM [16]. The key optimization technique is to approximately compute implicit gradients of the solution of an optimization problem based on first-order KKT conditions. Similar techniques were later generalized to optimize data poisoning attacks for several other important learning algorithms, such as Lasso regression [7], topic modeling [8], and autoregressive models [17]. The reader may refer to [9] for a general algorithmic framework of the abovementioned methods.\nIn terms of collaborative filtering/matrix completion, there is another line of established research that focuses on robust matrix completion, in which a small portion of elements or rows in the underlying low-rank matrix is assumed to be arbitrarily perturbed [18, 19, 20, 21]. Specifically, the stability of alternating minimization solutions was analyzed with respect to malicious data manipulations in [22]. However, [22] assumes a globally optimal solution of alternating minimization can be obtained, which is rarely true in practice."
    }, {
      "heading" : "2 Preliminaries",
      "text" : "We first set up the collaborative filtering/matrix completion problem and give an overview of existing low-rank factorization based approaches. Let M ∈ Rm×n be a data matrix consisting of m rows and n columns. Mij for i ∈ [m] and j ∈ [n] would then correspond to the rating the ith user gives for the jth item. We use Ω = {(i, j) : Mij is observed} to denote all observable entries in M and assume that |Ω| mn. We also use Ωi ⊆ [n] and Ω′j ⊆ [m] for columns (rows) that are observable at the ith row (jth column). The goal of collaborative filtering (also referred to as matrix completion in the statistical learning literature [2]) is then to recover the complete matrix M from few observations MΩ.\nThe matrix completion problem is in general ill-posed as it is impossible to complete an arbitrary matrix with partial observations. As a result, additional assumptions are imposed on the underlying data matrix M. One standard assumption is that M is very close to an m × n rank-k matrix with\nk min(m,n). Under such assumptions, the complete matrix M can be recovered by solving the following optimization problem:\nmin X∈Rm×n\n‖RΩ(M−X)‖2F , s.t. rank(X) ≤ k, (1)\nwhere ‖A‖2F = ∑ i,j A 2 ij denotes the squared Frobenious norm of matrix A and [RΩ(A)]ij equals Aij if (i, j) ∈ Ω and 0 otherwise. Unfortunately, the feasible set in Eq. (1) is non-convex, making the optimimzation problem difficult to solve. There has been an extensive prior literature on approximately solving Eq. (1) and/or its surrogates that lead to two standard approaches: alternating minimization and nuclear norm minimization. For the first approach, one considers the following problem:\nmin U∈Rm×k,V∈Rn×k\n{ ‖RΩ(M−UV>)‖2F +2λU‖U‖2F + 2λV ‖V‖2F } . (2)\nEq. (2) is equivalent to Eq. (1) when λU = λV = 0. In practice people usually set both regularization parameters λU and λV to be small positive constants in order to avoid large entries in the completed matrix and also improve convergence. Since Eq. (2) is bi-convex in U and V, an alternating minimization procedure can be applied. Alternatively, one solves a nuclear-norm minimization problem\nmin X∈Rm×n\n‖RΩ(M−X)‖2F + 2λ‖X‖∗, (3)\nwhere λ > 0 is a regularization parameter and ‖X‖∗ = ∑rank(X) i=1 |σi(X)| is the nuclear norm of X, which acts as a convex surrogate of the rank function. Eq. (3) is a convex optimization function and can be solved using an iterative singular value thresholding algorithm [3]. It can be shown that both methods in Eq. (2) and (3) provably approximate the true underlying data matrix M under certain conditions [6, 2]."
    }, {
      "heading" : "3 The Attack Model",
      "text" : "In this section we describe the data poisoning attack model considered in this paper. For a data matrix consisting of m users and n items, the attacker is capable of adding αm malicious users to the training data matrix, and each malicious user is allowed to report his/her preference on at most B items with each preference bounded in the range [−Λ,Λ]. Before proceeding to describe the attacker’s goals, we first introduce some notation to facilitate presentation. We use M ∈ Rm×n to denote the original data matrix and M̃ ∈ Rm′×n to denote the data matrix of all m′ = αm malicious users. Let Ω̃ be the set of non-zero entries in M̃ and Ω̃i ⊆ [n] be all items that the ith malicious user rated. According to our attack models, |Ω̃i| ≤ B for every i ∈ {1, · · · ,m′} and ‖M̃‖max = max |M̃ij | ≤ Λ. Let Θλ(M̃; M) be the optimal solution computed jointly on the original and poisoned data matrices (M̃; M) using regularization parameters λ. For example, Eq. (2) becomes\nΘλ(M̃; M) = arg min U,Ũ,V\n‖RΩ(M−UV>)‖2F+‖RΩ̃(M̃−ŨV >)‖2F+2λU (‖U‖2F+‖Ũ‖2F )+2λV ‖V‖2F\n(4)\nwhere the resulting Θ consists of low-rank latent factors U, Ũ for normal and malicious users as well as V for items. Simiarly, for the nuclear norm minimization formulation in Eq. (3), we have\nΘλ(M̃; M) = arg min X,X̃\n‖RΩ(M − X)‖2F + ‖RΩ̃(M̃ − X̃)‖ 2 F + 2λ‖(X; X̃)‖∗, (5)\nwhere Θ = (X, X̃) . Let M̂(Θ) be the matrix estimated from learnt model Θ. For example, for Eq. (4) we have M̂(Θ) = UV> and for Eq. (5) we have M̂(Θ) = X. The goal of the attacker is to find optimal malicious users M̃∗ such that\nM̃∗ ∈ argmaxM̃∈MR(M̂(Θλ(M̃; M)),M). (6)\nHere M = {M̃ ∈ Rm ′×n : |Ω̃i| ≤ B, ‖M̃‖max ≤ Λ} is the set of all feasible poisoning attacks\ndiscussed earlier in this section and R(M̂,M) denotes the attacker’s utility for diverting the collaborative filtering algorithm to predict M̂ on an original data set M, with the help of few malicious users M̃. Below we list several typical attacker utilities:\nAvailability attack the attacker wants to maximize the error of the collaborative filtering system, and eventually render the system useless. Suppose M is the prediction of the collaborative filtering system without data poisoning attacks.2 The utility function is then defined as the total amount of perturbation of predictions between M and M̂ (predictions after poisoning attacks) on unseen entries ΩC :\nRav(M̂,M) = ‖RΩC (M̂−M)‖ 2 F . (7)\nIntegrity attack in this model the attacker wants to boost (or reduce) the popularity of a (subset) of items. Suppose J0 ⊆ [n] is the subset of items the attacker is interested in and w : J0 → R is a pre-specified weight vector by the attacker. The utility function is\nRinJ0,w(M̂,M) = m∑ i=1 ∑ j∈J0 w(j)M̂ij . (8)\nHybrid attack a hybrid loss function can also be defined: RhybridJ0,w,µ(M̂,M) = µ1R av J0,w(M̂,M) + µ2R in(M̂,M), (9) where µ = (µ1, µ2) are coefficients that trade off the availability and integrity attack objectives. In addition, µ1 could be negative, which models the case when the attacker wants to leave a “light trace\": the attacker wants to make his item more popular while making the other recommendations of the system less perturbed to avoid detection."
    }, {
      "heading" : "4 Computing Optimal Attack Strategies",
      "text" : "We describe practical algorithms to solve the optimization problem in Eq. (6) for optimal attack strategy M̃∗ that maximizes the attacker’s utility. We first consider the alternating minimization formulation in Eq. (4) and derive a projected gradient ascent method that solves for the corresponding optimal attack strategy. Similar derivations are then extended to the nuclear norm minimization formulation in Eq. (5). Finally, we discuss how to design malicious users that mimic normal user behavior in order to avoid detection."
    }, {
      "heading" : "4.1 Attacking Alternating Minimization",
      "text" : "We use the projected gradient ascent (PGA) method for solving the optimization problem in Eq. (6) with respect to the alternating minimization formulation in Eq. (4): in iteration t we update M̃(t) as follows:\nM̃(t+1) = ProjM ( M̃(t) + st · ∇M̃R(M̂,M) ) , (10)\nwhere ProjM(·) is the projection operator onto the feasible region M and st is the step size in iteration t. Note that the estimated matrix M̂ depends on the model Θλ(M̃; M) learnt on the joint data matrix, which further depends on the malicious users M̃. Since the constraint set M is highly non-convex, we generate B items uniformly at random for each malicious user to rate. The ProjM(·) operator then reduces to projecting each malicious users’ rating vector onto an `∞ ball of diameter Λ, which can be easily evaluated by truncating all entries in M̃ at the level of ±Λ.\nWe next show how to (approximately) compute ∇ M̃ R(M̂,M). This is challenging because one of the arguments in the loss function involves an implicit optimization problem. We first apply chain rule to arrive at ∇M̃R(M̂,M) = ∇M̃Θλ(M̃; M)∇ΘR(M̂,M). (11) The second gradient (with respect to Θ) is easy to evaluate, as all loss functions mentioned in the previous section are smooth and differentiable. Detailed derivation of∇ΘR(M̂,M) is deferred to Appendix A. On the other hand, the first gradient term term is much harder to evaluate because Θλ(·) is an optimization procedure. Inspired by [7, 8, 9], we exploit the KKT conditions of the optimization problem Θλ(·) to approximately compute∇M̃Θλ(M̃; M). More specifically, the optimal solution Θ = (U, Ũ,V) of Eq. (4) satisfies\nλUui = ∑ j∈Ωi (Mij − u>i vj)vj ;\n2Note that when the collaborative filtering algorithm and its parameters are set, M is a function of observed entriesRΩ(M).\nAlgorithm 1 Optimizing M̃ via PGA 1: Input: Original partially observed m × n data matrix M, algorithm regularization parameter λ, attack\nbudget parameters α, B and Λ, attacker’s utility function R, step size {st}∞t=1. 2: Initialization: random M̃(0) ∈ M with both ratings and rated items uniformly sampled at random; t = 0. 3: while M̃(t) does not converge do 4: Compute the optimal solution Θλ(M̃(t); M). 5: Compute gradient∇M̃R(M̂,M) using Eq. (10). 6: Update: M̃(t+1) = ProjM(M̃\n(t) + st∇M̃R). 7: t← t+ 1. 8: end while 9: Output: m′ × n malicious matrix M̃(t).\nλU ũi = ∑ j∈Ω̃i (M̃ij − ũ>i vj)vj ;\nλV vj = ∑ i∈Ω′j (Mij − u>i vj)ui + ∑ i∈Ω̃′j (M̃ij − ũ>i vj)ũi,\nwhere ui, ũi are the ith rows (of dimension k) in U or Ũ and vj is the jth row (also of dimension k) in V. Subsequently, {ui, ũi,vj} can be expressed as functions of the original and malicious data matrices M and M̃. Using the fact that (a>x)a = (aa>)x and M does not change with M̃, we obtain\n∂ui(M̃)\n∂M̃ij = 0;\n∂ũi(M̃) ∂M̃ij = ( λUIk + Σ (i) U )−1 vj ;\n∂vj(M̃) ∂M̃ij = ( λV Ik + Σ (j) V )−1 ui.\nHere Σ(i)U and Σ (j) V are defined as\nΣ (i) U = ∑ j∈Ωi∪Ω̃i vjv > j , Σ (j) V = ∑ i∈Ω′j∪Ω̃ ′ j uiu > i . (12)\nA framework of the proposed optimization algorithm is described in Algorithm 1."
    }, {
      "heading" : "4.2 Attacking Nuclear Norm Minimization",
      "text" : "We extend the projected gradient ascent algorithm in Sec. 4.1 to compute optimal attack strategies for the nuclear norm minimization formulation in Eq. (5). Since the objective in Eq. (5) is convex, the global optimal solution Θ = (X, X̃) can be obtained by conventional convex optimization procedures such as proximal gradient descent (a.k.a. singular value thresholding [3] for nuclear norm minimization). In addition, the resulting estimation (X; X̃) is low rank due to the nuclear norm penalty [2]. Suppose (X; X̃) has rank ρ ≤ min(m,n). We use Θ′ = (U, Ũ,V,Σ) as an alternative characterization of the learnt model with a reduced number of parameters. Here X = UΣV> and X̃ = ŨΣV> are singular value decompositions of X and X̃; that is, U ∈ Rm×ρ, Ũ ∈ Rm′×ρ, V ∈ Rn×ρ have orthornormal columns and Σ = diag(σ1, · · · , σρ) is a non-negative diagonal matrix.\nTo compute the gradient ∇ M̃ R(M̂,M), we again apply the chain rule to decompose the gradient into two parts: ∇M̃R(M̂,M) = ∇M̃Θ ′ λ(M̃; M)∇Θ′R(M̂,M). (13)\nSimilar to Eq. (11), the second gradient term ∇Θ′R(M̂,M) is relatively easier to evaluate. Its derivation details are deferred to the Appendix. In the remainder of this section we shall focus on the computation of the first gradient term, which involves partial derivatives of Θ′ = (U, Ũ,V,Σ) with respect to malicious users M̃.\nWe begin with the KKT condition at the optimal solution Θ′ of Eq. (5). Unlike the alternating minimization formulation, the nuclear norm function ‖ · ‖∗ is not everywhere differentiable. As a\nAlgorithm 2 Optimizing M̃ via SGLD 1: Input: Original partially observed m × n data matrix M, algorithm regularization parameter λ, attack\nbudget parameters α, B and Λ, attacker’s utility function R, step size {st}∞t=1, tuning parameter β, number of SGLD iterations T .\n2: Prior setup: compute ξj = 1m ∑m i=1 Mij and σ 2 j = 1 m ∑m i=1 (Mij − ξj)\n2 for every j ∈ [n]. 3: Initialization: sample M̃(0)ij ∼ N (ξj , σ 2 j ) for i ∈ [m′] and j ∈ [n]. 4: for t = 0 to T do 5: Compute the optimal solution Θλ(M̃(t); M). 6: Compute gradient∇M̃R(M̂,M) using Eq. (10). 7: Update M̃(t+1) according to Eq. (17). 8: end for 9: Projection: find M̃∗ ∈ arg minM̃∈M ‖M̃− M̃\n(t)‖2F . Details in the main text. 10: Output: m′ × n malicious matrix M̃∗.\nresult, the KKT condition relates the subdifferential of the nuclear norm function ∂‖ · ‖∗ as RΩ,Ω̃ ( [M; M̃]− [X; X̃] ) ∈ λ∂‖[X; X̃]‖∗. (14)\nHere [X; X̃] is the concatenated (m+m′)×n matrix of X and X̃. The subdifferential of the nuclear norm function ∂‖ · ‖∗ is also known [2]:\n∂‖X‖∗ = { UV> + W : U>W = WV = 0, ‖W‖2 ≤ 1 } ,\nwhere X = UΣV> is the singular value decomposition of X. Suppose {ui}, {ũi} and {vj} are rows of U, Ũ,V and W = {wij}. We can then re-formulate the KKT condition Eq. (14) as follows:\n∀(i, j) ∈ Ω, Mij = u>i (Σ + λIρ)vj + λwij ; ∀(i, j) ∈ Ω̃, M̃ij = ũ>i (Σ + λIρ)vj + λw̃ij .\nNow we can derive∇ M̃ Θ = ∇ M̃ (u, ũ,v, σ); the full derivation is deferred to the appendix."
    }, {
      "heading" : "4.3 Mimicing Normal User Behaviors",
      "text" : "Normal users generally do not rate items uniformly at random. For example, some movies are significantly more popular than others. As a result, malicious users that pick rated movies uniformly at random can be easily identified by running a t-test against a known database consisting of only normal users, as shown in Sec. 5. To alleviate this issue, in this section we propose an alternative approach to compute data poisoning attacks such that the resulting malicious users M̃ mimics normal users M to avoid potential detection, while still achieving reasonably large utility R(M̂,M) for the attacker. We use a Bayesian formulation to take both data poisoning and detection avoidance objectives into consideration. The prior distribution p0(M̃) captures normal user behaviors and is defined as a multivariate normal distribution\np0(M̃) = m′∏ i=1 n∏ j=1 N (M̃ij ; ξj , σ2j ),\nwhere ξj and σ2j are mean and variance parameters for the rating of the jth item provided by normal users. In practice both parameters can be estimated using normal user matrix M as ξj = 1m ∑m i=1 Mij\nand σ2 = 1m ∑m i=1 (Mij − ξj)2. On the other hand, the likelihood p(M|M̃) is defined as\np(M|M̃) = 1 Z\nexp ( β ·R(M̂,M) ) , (15)\nwhere R(M̂,M) = R(M̂(Θλ(M̃; M)),M) is one of the attacker utility functions defined in Sec. 3, Z is a normalization constant and β > 0 is a tuning parameter that trades off attack performance and detection avoidance. A small β shifts the posterior of M̃ toward its prior, which makes the resulting attack strategy less effective but harder to detect, and vice versa.\nGiven both prior and likelihood functions, an effective detection-avoiding attack strategy M̃ can be obtained by sampling from its posterior distribution:\np(M̃|M) = p0(M̃)p(M|M̃)/p(M) ∝ exp − m′∑ i=1 n∑ j=1 (M̃ij − ξj)2 2σ2j + βR(M̂,M)  . (16) Posterior sampling of Eq. (16) is clearly intractable due to the implicit and complicated dependency of the estimated matrix M̂ on the malicious data M̃, that is, M̂ = M̂(Θλ(M̃; M))). To circumvent this problem, we apply Stochastic Gradient Langevin Dynamics (SGLD, [10]) to approximately sample M̃ from its posterior distribution in Eq. (16). More specfically, the SGLD algorithm iteratively computes a sequence of posterior samples {M̃(t)}t≥0 and in iteration t the new sample M̃(t+1) is computed as\nM̃(t+1) = M̃(t) + st 2 ( ∇M̃ log p(M̃|M) ) + εt, (17)\nwhere {st}t≥0 are step sizes and εt ∼ N (0, stI) are independent Gaussian noises injected at each SGLD iteration. The gradient∇\nM̃ log p(M̃|M) can be computed as\n∇M̃ log p(M̃|M) = −(M̃−Ξ)Σ −1 + β∇M̃R(M̂,M),\nwhere Σ = diag(σ21 , · · · , σ2n) and Ξ is an m′ × n matrix with Ξij = ξj for i ∈ [m′] and j ∈ [n]. The other gradient ∇\nM̃ R(M̂,M) can be computed using the procedure in Sections 4.1 and 4.2. Finally,\nthe sampled malicious matrix M̃(t) is projected back onto the feasible set M by selecting B items per user with the largest absolute rating and truncating ratings to the level of {±Λ}. A high-level description of the proposed method is given in Algorithm 2."
    }, {
      "heading" : "5 Experimental Results",
      "text" : "To evaluate the effectiveness of our proposed poisoning attack strategy, we use the publicly available MovieLens dataset which contains 20 millions ratings and 465,000 tag applications applied to 27,000 movies by 138,000 users [23]. We shift the rating range to [−2, 2] for computation convenience. To avoid the “cold-start” problem, we consider users who have rated at least 20 movies. Two metrics are employed to measure the relative performance of the systems before and after data poisoning attacks: root mean square error (RMSE) for the predicted unseen entries3 and average rating for specific items. We then analyze the tradeoff between attack performance and detection avoidance, which is controled by the β parameter in Eq. (15). This serves as a guide for how β should be set in later experiments. We use a paired t-test to compare the distributions of rated items between normal and malicious users. We present the trend of p-value against different values of β in the extended version of the paper. To strive for a good tradeoff, we set β = 0.6 at which the p-value stablizes around 0.7 and the poisoning attack performance is not significantly sacrificed.\nWe employ attack models specified in Eq. (9), where the utility parameters µ1 and µ2 balance two different malicious goals (availability and integrity) an attacker wishes to achieve. For the integrity utility RinJ0,w, the J0 set contains only one item j0 selected randomly from all items whose average predicted ratings are around 0.8. The weight wj0 is set as wj0 = 2. Figure 1 (a) (b) plots the RMSE\n3defined as RMSE = √∑\n(i,j)∈ΩC (Mij − M̂ij)2/|ΩC |, where M is the prediction of model trained on clean dataRΩ(M) only (i.e., without data poisoning attacks).\nafter data poisoning attacks. When µ1 = 1, µ2 = 0, the attacker is interested in increasing the RMSE of the collaborative filtering system and hence reducing the system’s availability. On the other hand, when µ1 = 1, µ2 = −1 the attacker wishes to increase RMSE while at the same time keeping the rating of specific items (j0) as low as possible for certain malicious purposes. Figure 1 (b) shows that when the attackers consider to both objectives (µ1 = 1, µ2 = −1), the RMSE after poisoning is slightly lower than that if only availability is targeted (µ1 = 1, µ2 = 0). In addition, the projected gradient ascent (PGA) strategy generates the largest RMSE score compared with the other methods. However, PGA requires malicious users to rate each item uniformly at random, which might expose the malicious profiles to an informed defender. More specifically, the paired t-test on those malicious profiles produced by PGA rejects the null hypothesis that the items rated by the attacker strategies are the same as those obtained from normal users (p < 0.05). In contrast, the SGLD method leads to slightly worse attacker utility but generates malicious users that are hard to distinguish from the normal users (for example, the paired t-test leads to inconclusive p-values (larger than 0.7) with β = 0.6. Finally, both PGA and SGLD result in higher attacker utility compared to uniform attacks, where both ratings and rated items are sampled uniformly at random for malicious profiles.\nApart from the RMSE scores, we also plot ratings of specific items against percentage of malicious profiles in Figure 1 (c) (d). We consider two additional attack utility settings: µ1 = 0, µ2 = 1, in which the attacker wishes to push the ratings of some particular items (specified in w and J0 of Rin) as high as possible; and µ1 = −1, µ2 = 1, where the attacker also wants to leave a “light trace\" by reducing the impact on the entire system resulted from malicious activities. It is clear that targeted attackes (both PGA and SGLD) are indeed more effective at manipulating ratings of specific items for integrity attacks.\nWe also plot RMSE/Average ratings against malicious user percentage in Figure 2 for the nuclear norm minimization under similar settings based on a subset of 1000 users and 1700 movies (items), since it is more computationally expensive than alternating minimization. In general, we observe similar behavior of both RMSE/Average ratings under different attacking models µ1, µ2 with alternating minimization."
    }, {
      "heading" : "6 Discussion and Concluding Remarks",
      "text" : "Our ultimate goal for the poisoning attack analysis is to develop possible defensive strategies based on the careful analysis of adversarial behaviors. Since the poisoning data is optimized based on the attacker’s malicious objectives, the correlations among features within a feature vector may change to appear different from normal instances. Therefore, tracking and detecting deviations in the feature correlations and other accuracy metrics can be one potential defense. Additionally, defender can also apply the combinational models or sampling strategies, such as bagging, to reduce the influence of poisoning attacks."
    }, {
      "heading" : "Acknowledgments",
      "text" : "This research was partially supported by the NSF (CNS-1238959, IIS-1526860), ONR (N00014-151-2621), ARO (W911NF-16-1-0069), AFRL (FA8750-14-2-0180), Sandia National Laboratories, and Symantec Labs Graduate Research Fellowship."
    }, {
      "heading" : "A Computation of∇ΘR(M̂,M)",
      "text" : "We provide details on how to compute the “easy\" gradient ∇Θ̃R(M̂,M), M̂ = M̂(Θ) is the prediction based on the learnt model Θ. Applying the chain rule of differentiation we get\n∇ΘR(M̂,M) = ( ∇ΘM̂ )( ∇\nM̂ R(M̂,M)\n) . (18)\nWe first focus on the second term∇ M̂ R(M̂,M)). This is easy to compute because all malicious utility functions R considered in this paper are smooth and differentiable. More specifically, the availability attack utility Rav and the integrity attack utility Rin admit the following gradient computations:\n∂Rav ∂M̂ij = 2(M̂ij −Mij) · I[(i, j) /∈ Ω];\n∂RinJ0,w\n∂M̂ij = w(j) · I[j ∈ J0].\nHere I[·] is the indicator function that equals one if the corresponding condition holds true and zero otherwise. The gradient for the hybrid utility Rhybrid can then be expressed as a linear combination of the gradients of Rav and Rin:\n∇Rhybridµ,J0,w = µ1∇R av + µ2∇RinJ0,w.\nWe next turn to the computation of ∇ΘM̂, which is model specific. Alternating minimization and nuclear norm minimization are considered separately for this gradient:\nAlternating minimization In alternating minimization the learnt model Θ is parameterized by Θ = (U, Ũ,V), where U ∈ Rm×k, Ũ ∈ Rm′×k and V ∈ Rn×k. Since M̂ = UV> for normal users, we have\n∂M̂ij ∂U`t = Vjt · I[i = `], ∂M̂ij ∂V`t = Uit · I[j = `].\nNuclear norm minimization In nuclear norm minimization the learnt model Θ is parameterized by Θ = (U, Ũ,V,Σ) where U ∈ Rm×k, Ũ ∈ Rm′×k, V ∈ Rn×k and Σ = diag(σ1, · · · , σk). The estimation M̂ for normal users is then expressed as M̂ = UΣV>. As a result, we have\n∂M̂ij ∂U`t = σtVjt · I[i = `];\n∂M̂ij ∂V`t = σtUit · I[j = `];\n∂M̂ij ∂σt = UitVjt."
    }, {
      "heading" : "B Derivation of∇M̃Θ = ∇M̃(u, ũ,v, σ) for nuclear norm minimization",
      "text" : "Evaluation of ∇ M̃ ui Because ui does not depend on M̃, we have∇M̃ui = 0.\nEvaluation of∇ M̃ ũi Let Ω̃i be all (i, j) pairs such that (i, j) ∈ Ω̃. Suppose we are computing the gradient of ũi with respect to M̃i`, where ` can be either in or not in Ω̃i. Define Ω̃`i = Ω̃i∪{`} be the extended set of observations and denote r = |Ω̃`i | as the size of the extended observation set. Define M̃i = (M̃ij)j∈Ω̃`i ∈ Rr, w̃i = (w̃ij)j∈Ω̃`i ∈ R r and V`i = (vj)j∈Ω̃`i ∈ R\nρ×r. By KKT condition,[ (Σ + λIρ) V ` i ]> ũi = M̃i − λw̃i. (19)\nThe above linear system can be either over-determined or under-determined, depending on the relationship between ρ and r. When the system is under-determined (e.g., r < ρ), the solution to Eq. (19) is not unique and could be instable if the matrix Ai = [ (Σ + λIρ) V ` i ]> is ill-conditioned. On the other hand, when the system is over-determined (e.g., r > ρ) an exact solution ũi may not exist. To force unique solutions in full generality, we compute ũi by solving the following Ridge-regularized system:\nmin ũi ‖M̃i − λw̃i −Aiũi‖22 + 2τ‖ũi‖22,\nwhere τ > 0 is a smoothing parameter. Subsequently,\nũi ≈ (A>i Ai + τIρ)−1A>i (M̃i − λw̃i); ∂ũi\n∂M̃i` ≈ (A>i Ai + τIρ)−1(Σ + λIρ)v`.\nEvaluation of ∇ M̃ vj This part is similar to the gradient of ũi. Suppose we are computing ∂vj/∂M̃`j . Define Ω̄`j = Ω ′ j ∪ Ω̃′j ∪ {`} to be the extended set of all i such that (i, j) ∈ Ω ∪ Ω̃. Let r = |Ω̄`j | be the size of the extended set. We then have[ (Ū`i) >(Σ + λIρ) ] vj = M̃ ′ j − λw̃′j ,\nwhere Ū`i is a ρ× r matrix consisting of all ui or ũi for i ∈ Ω̄`j as its columns. On the right-hand side, we have M̃′j = (M̃ij)i∈Ω̄`j and w̃ ′ j = (wij)i∈Ω̄`j . Let Bj = (Ū ` i) >(Σ + λIρ) ∈ Rr×ρ and τ > 0 be a smoothing parameter. We then have\n∂vj\n∂M̃`j ≈ (B>j Bj + τIρ)−1(Σ + λIρ)ũ`.\nEvaluation of ∇ M̃ σk By KKT condition we have\nM̃ij = ũikvjk · σk + c,\nwhere c is a constant that does not depend on σk. Subsequently, we get\n∂σk\n∂M̃ij =\n1\nũikvjk ."
    }, {
      "heading" : "C Additional experimental results",
      "text" : "Here we analyze the trend of p-value against different values of β. Figure 3 plots P-values and RMSE/Average ratings against different values of β. When B = 25 (recall that B is the maximum number of items a malicious user is allowed to rate), with the increase of β, the P-value decreases while both RMSE and average per-item ratings increase.\nWe then plot ratings of specific items against percentage of malicious profiles by setting µ2 = −1 to evaluate the performance of attacker reducing the popularity of the item, whose original predicted average rating is 0.8. Figure 5 and 6 both show two settings of µ1 = 0, µ2 = −1 and µ1 = −1, µ2 = −1 for alternating minimization and nuclear norm minimization, respectively. For alternating minimization algorithm, when µ1 = 0, µ2 = −1, the attacker tries to reduce the average rating for certain item without caring about the availability error of the whole recommendation system. This way, the attacker has better control of the item and can decrease the average rating of the item from 0.8 to around -0.3. While, if µ1 = −1, µ2 = −1, the attacker want to reduce the popularity of the item and at the same time reduce the availability error for the whole system to avoid detection; therefore the attacker can only decrease the average rating of the item to about -0.1 under this setting.We obtain the similar observations for the nuclear norm minimization."
    } ],
    "references" : [ {
      "title" : "Unifying user-based and item-based collaborative filtering approaches by similarity fusion",
      "author" : [ "Jun Wang", "Arjen de Vires", "Marcel Reinders" ],
      "venue" : "In SIGIR,",
      "citeRegEx" : "1",
      "shortCiteRegEx" : "1",
      "year" : 2006
    }, {
      "title" : "Exact matrix completion via convex optimization",
      "author" : [ "Emmanuel Candès", "Ben Recht" ],
      "venue" : "Foundations of Computational Mathematics,",
      "citeRegEx" : "2",
      "shortCiteRegEx" : "2",
      "year" : 2007
    }, {
      "title" : "A singular value thresholding algorithm for matrix completion",
      "author" : [ "Jian-Feng Cai", "Emmanuel Candès", "Zuowei Shen" ],
      "venue" : "SIAM Journal on Optimization,",
      "citeRegEx" : "3",
      "shortCiteRegEx" : "3",
      "year" : 1956
    }, {
      "title" : "Effective attack models for shilling item-based collaborative filtering systems",
      "author" : [ "Bamshad Mobasher", "Robin Burke", "Runa Bhaumik", "Chad Williams" ],
      "venue" : "In Proceedings of the 2005 WebKDD Workshop, held in conjuction with ACM SIGKDD’2005,",
      "citeRegEx" : "4",
      "shortCiteRegEx" : "4",
      "year" : 2005
    }, {
      "title" : "Promoting recommendations: An attack on collaborative filtering",
      "author" : [ "Michael P O’Mahony", "Neil J Hurley", "Guenole CM Silvestre" ],
      "venue" : "In Database and Expert Systems Applications,",
      "citeRegEx" : "5",
      "shortCiteRegEx" : "5",
      "year" : 2002
    }, {
      "title" : "Low-rank matrix completion using alternating minimization",
      "author" : [ "Prateek Jain", "Praneeth Netrapalli", "Sujay Sanghavi" ],
      "venue" : "In STOC,",
      "citeRegEx" : "6",
      "shortCiteRegEx" : "6",
      "year" : 2013
    }, {
      "title" : "Is feature selection secure against training data poisoning",
      "author" : [ "Huang Xiao", "Battista Biggio", "Gavin Brown", "Giorgio Fumera", "Claudia Eckert", "Fabio Roli" ],
      "venue" : "In ICML,",
      "citeRegEx" : "7",
      "shortCiteRegEx" : "7",
      "year" : 2015
    }, {
      "title" : "The security of latent dirichlet allocation",
      "author" : [ "Shike Mei", "Xiaojin Zhu" ],
      "venue" : "In AISTATS,",
      "citeRegEx" : "8",
      "shortCiteRegEx" : "8",
      "year" : 2015
    }, {
      "title" : "Using machine teaching to identify optimal training-set attacks on machine learners",
      "author" : [ "Shike Mei", "Xiaojin Zhu" ],
      "venue" : "In AAAI,",
      "citeRegEx" : "9",
      "shortCiteRegEx" : "9",
      "year" : 2015
    }, {
      "title" : "Bayesian learning via stochastic gradient langevin dynamics",
      "author" : [ "Max Welling", "Yee W Teh" ],
      "venue" : "In Proceedings of the 28th International Conference on Machine Learning",
      "citeRegEx" : "10",
      "shortCiteRegEx" : "10",
      "year" : 2011
    }, {
      "title" : "Adversarial classification",
      "author" : [ "Nilesh Dalvi", "Pedro Domingos", "Sumit Sanghai", "Deepak Verma" ],
      "venue" : "In Proceedings of the tenth ACM SIGKDD international conference on Knowledge discovery and data mining,",
      "citeRegEx" : "11",
      "shortCiteRegEx" : "11",
      "year" : 2004
    }, {
      "title" : "Adversarial learning",
      "author" : [ "Daniel Lowd", "Christopher Meek" ],
      "venue" : "In Proceedings of the eleventh ACM SIGKDD international conference on Knowledge discovery in data mining,",
      "citeRegEx" : "12",
      "shortCiteRegEx" : "12",
      "year" : 2005
    }, {
      "title" : "Feature cross-substitution in adversarial classification",
      "author" : [ "Bo Li", "Yevgeniy Vorobeychik" ],
      "venue" : "In Advances in Neural Information Processing Systems,",
      "citeRegEx" : "13",
      "shortCiteRegEx" : "13",
      "year" : 2014
    }, {
      "title" : "Scalable optimization of randomized operational decisions in adversarial classification settings",
      "author" : [ "Bo Li", "Yevgeniy Vorobeychik" ],
      "venue" : "In Proceedings of the Eighteenth International Conference on Artificial Intelligence and Statistics,",
      "citeRegEx" : "14",
      "shortCiteRegEx" : "14",
      "year" : 2015
    }, {
      "title" : "Can machine learning be secure",
      "author" : [ "Marco Barreno", "Blaine Nelson", "Russell Sears", "Anthony D Joseph", "J Doug Tygar" ],
      "venue" : "In Proceedings of the 2006 ACM Symposium on Information, computer and communications security,",
      "citeRegEx" : "15",
      "shortCiteRegEx" : "15",
      "year" : 2006
    }, {
      "title" : "Poisoning attacks against support vector machines",
      "author" : [ "Battista Biggio", "Blaine Nelson", "Pavel Laskov" ],
      "venue" : "In ICML,",
      "citeRegEx" : "16",
      "shortCiteRegEx" : "16",
      "year" : 2012
    }, {
      "title" : "Data poisoning attacks against autoregressive models",
      "author" : [ "Scott Alfeld", "Xiaojin Zhu", "Paul Barford" ],
      "venue" : "In AAAI,",
      "citeRegEx" : "17",
      "shortCiteRegEx" : "17",
      "year" : 2016
    }, {
      "title" : "Robust matrix completion",
      "author" : [ "Olga Klopp", "Karim Lounici", "Alexandre Tsybakov" ],
      "venue" : null,
      "citeRegEx" : "18",
      "shortCiteRegEx" : "18",
      "year" : 2014
    }, {
      "title" : "Robust matrix completion and corrupted columns",
      "author" : [ "Yudong Chen", "Huan Xu", "Constantine Caramanis", "Sujay Sanghavi" ],
      "venue" : "In ICML,",
      "citeRegEx" : "19",
      "shortCiteRegEx" : "19",
      "year" : 2011
    }, {
      "title" : "Low-rank matrix recovery from errors and erasures",
      "author" : [ "Yudong Chen", "Ali Jalali", "Sujay Sanghavi", "Constantine Caramanis" ],
      "venue" : "IEEE Transactions on Information Theory,",
      "citeRegEx" : "20",
      "shortCiteRegEx" : "20",
      "year" : 2013
    }, {
      "title" : "Robust matrix completion via joint schatten p-norm and lp-norm minimization",
      "author" : [ "Feiping Nie", "Hua Wang", "Xiao Cai", "Heng Huang", "Chris Ding" ],
      "venue" : "In ICDM,",
      "citeRegEx" : "21",
      "shortCiteRegEx" : "21",
      "year" : 2012
    }, {
      "title" : "Stability of matrix factorization for collaborative filtering",
      "author" : [ "Yu-Xiang Wang", "Huan Xu" ],
      "venue" : "In ICML,",
      "citeRegEx" : "22",
      "shortCiteRegEx" : "22",
      "year" : 2012
    } ],
    "referenceMentions" : [ {
      "referenceID" : 0,
      "context" : "Existing approaches in the literature include nearest-neighbor methods, where a user’s (item’s) preference is determined by other users (items) with similar profiles [1], and factorization-based methods where the incomplete preference matrix is assumed to be approximately low-rank [2, 3].",
      "startOffset" : 166,
      "endOffset" : 169
    }, {
      "referenceID" : 1,
      "context" : "Existing approaches in the literature include nearest-neighbor methods, where a user’s (item’s) preference is determined by other users (items) with similar profiles [1], and factorization-based methods where the incomplete preference matrix is assumed to be approximately low-rank [2, 3].",
      "startOffset" : 282,
      "endOffset" : 288
    }, {
      "referenceID" : 2,
      "context" : "Existing approaches in the literature include nearest-neighbor methods, where a user’s (item’s) preference is determined by other users (items) with similar profiles [1], and factorization-based methods where the incomplete preference matrix is assumed to be approximately low-rank [2, 3].",
      "startOffset" : 282,
      "endOffset" : 288
    }, {
      "referenceID" : 3,
      "context" : "systems and their reliance on user-specified judgments for building profiles, various forms of attacks are possible and have been discussed, such as the random attack and random product push/nuke attack [4, 5].",
      "startOffset" : 203,
      "endOffset" : 209
    }, {
      "referenceID" : 4,
      "context" : "systems and their reliance on user-specified judgments for building profiles, various forms of attacks are possible and have been discussed, such as the random attack and random product push/nuke attack [4, 5].",
      "startOffset" : 203,
      "endOffset" : 209
    }, {
      "referenceID" : 5,
      "context" : "We focus on two most popular algorithms: alternating minimization [6] and nuclear norm minimization [3].",
      "startOffset" : 66,
      "endOffset" : 69
    }, {
      "referenceID" : 2,
      "context" : "We focus on two most popular algorithms: alternating minimization [6] and nuclear norm minimization [3].",
      "startOffset" : 100,
      "endOffset" : 103
    }, {
      "referenceID" : 6,
      "context" : "• Novel gradient computations: Building upon existing gradient-based data poisoning frameworks [7, 8, 9], we develop novel methods for gradient computation based on first-order KKT conditions for two widely used algorithms: alternating minimization [6] and nuclear norm minimization [2].",
      "startOffset" : 95,
      "endOffset" : 104
    }, {
      "referenceID" : 7,
      "context" : "• Novel gradient computations: Building upon existing gradient-based data poisoning frameworks [7, 8, 9], we develop novel methods for gradient computation based on first-order KKT conditions for two widely used algorithms: alternating minimization [6] and nuclear norm minimization [2].",
      "startOffset" : 95,
      "endOffset" : 104
    }, {
      "referenceID" : 8,
      "context" : "• Novel gradient computations: Building upon existing gradient-based data poisoning frameworks [7, 8, 9], we develop novel methods for gradient computation based on first-order KKT conditions for two widely used algorithms: alternating minimization [6] and nuclear norm minimization [2].",
      "startOffset" : 95,
      "endOffset" : 104
    }, {
      "referenceID" : 5,
      "context" : "• Novel gradient computations: Building upon existing gradient-based data poisoning frameworks [7, 8, 9], we develop novel methods for gradient computation based on first-order KKT conditions for two widely used algorithms: alternating minimization [6] and nuclear norm minimization [2].",
      "startOffset" : 249,
      "endOffset" : 252
    }, {
      "referenceID" : 1,
      "context" : "• Novel gradient computations: Building upon existing gradient-based data poisoning frameworks [7, 8, 9], we develop novel methods for gradient computation based on first-order KKT conditions for two widely used algorithms: alternating minimization [6] and nuclear norm minimization [2].",
      "startOffset" : 283,
      "endOffset" : 286
    }, {
      "referenceID" : 9,
      "context" : "In this paper we provide a novel technique based on stochastic gradient Langevin dynamics optimization [10] to produce malicious users that mimic normal user behaviors in order to avoid detection, while achieving attack objectives.",
      "startOffset" : 103,
      "endOffset" : 107
    }, {
      "referenceID" : 10,
      "context" : "Related Work: There has been extensive prior research concerning the security of machine learning algorithms [11, 12, 13, 14, 15].",
      "startOffset" : 109,
      "endOffset" : 129
    }, {
      "referenceID" : 11,
      "context" : "Related Work: There has been extensive prior research concerning the security of machine learning algorithms [11, 12, 13, 14, 15].",
      "startOffset" : 109,
      "endOffset" : 129
    }, {
      "referenceID" : 12,
      "context" : "Related Work: There has been extensive prior research concerning the security of machine learning algorithms [11, 12, 13, 14, 15].",
      "startOffset" : 109,
      "endOffset" : 129
    }, {
      "referenceID" : 13,
      "context" : "Related Work: There has been extensive prior research concerning the security of machine learning algorithms [11, 12, 13, 14, 15].",
      "startOffset" : 109,
      "endOffset" : 129
    }, {
      "referenceID" : 14,
      "context" : "Related Work: There has been extensive prior research concerning the security of machine learning algorithms [11, 12, 13, 14, 15].",
      "startOffset" : 109,
      "endOffset" : 129
    }, {
      "referenceID" : 15,
      "context" : "pioneered the research of optimizing malicious datadriven attacks for kernel-based learning algorithms such as SVM [16].",
      "startOffset" : 115,
      "endOffset" : 119
    }, {
      "referenceID" : 6,
      "context" : "Similar techniques were later generalized to optimize data poisoning attacks for several other important learning algorithms, such as Lasso regression [7], topic modeling [8], and autoregressive models [17].",
      "startOffset" : 151,
      "endOffset" : 154
    }, {
      "referenceID" : 7,
      "context" : "Similar techniques were later generalized to optimize data poisoning attacks for several other important learning algorithms, such as Lasso regression [7], topic modeling [8], and autoregressive models [17].",
      "startOffset" : 171,
      "endOffset" : 174
    }, {
      "referenceID" : 16,
      "context" : "Similar techniques were later generalized to optimize data poisoning attacks for several other important learning algorithms, such as Lasso regression [7], topic modeling [8], and autoregressive models [17].",
      "startOffset" : 202,
      "endOffset" : 206
    }, {
      "referenceID" : 8,
      "context" : "The reader may refer to [9] for a general algorithmic framework of the abovementioned methods.",
      "startOffset" : 24,
      "endOffset" : 27
    }, {
      "referenceID" : 17,
      "context" : "In terms of collaborative filtering/matrix completion, there is another line of established research that focuses on robust matrix completion, in which a small portion of elements or rows in the underlying low-rank matrix is assumed to be arbitrarily perturbed [18, 19, 20, 21].",
      "startOffset" : 261,
      "endOffset" : 277
    }, {
      "referenceID" : 18,
      "context" : "In terms of collaborative filtering/matrix completion, there is another line of established research that focuses on robust matrix completion, in which a small portion of elements or rows in the underlying low-rank matrix is assumed to be arbitrarily perturbed [18, 19, 20, 21].",
      "startOffset" : 261,
      "endOffset" : 277
    }, {
      "referenceID" : 19,
      "context" : "In terms of collaborative filtering/matrix completion, there is another line of established research that focuses on robust matrix completion, in which a small portion of elements or rows in the underlying low-rank matrix is assumed to be arbitrarily perturbed [18, 19, 20, 21].",
      "startOffset" : 261,
      "endOffset" : 277
    }, {
      "referenceID" : 20,
      "context" : "In terms of collaborative filtering/matrix completion, there is another line of established research that focuses on robust matrix completion, in which a small portion of elements or rows in the underlying low-rank matrix is assumed to be arbitrarily perturbed [18, 19, 20, 21].",
      "startOffset" : 261,
      "endOffset" : 277
    }, {
      "referenceID" : 21,
      "context" : "Specifically, the stability of alternating minimization solutions was analyzed with respect to malicious data manipulations in [22].",
      "startOffset" : 127,
      "endOffset" : 131
    }, {
      "referenceID" : 21,
      "context" : "However, [22] assumes a globally optimal solution of alternating minimization can be obtained, which is rarely true in practice.",
      "startOffset" : 9,
      "endOffset" : 13
    }, {
      "referenceID" : 1,
      "context" : "The goal of collaborative filtering (also referred to as matrix completion in the statistical learning literature [2]) is then to recover the complete matrix M from few observations MΩ.",
      "startOffset" : 114,
      "endOffset" : 117
    }, {
      "referenceID" : 2,
      "context" : "(3) is a convex optimization function and can be solved using an iterative singular value thresholding algorithm [3].",
      "startOffset" : 113,
      "endOffset" : 116
    }, {
      "referenceID" : 5,
      "context" : "(2) and (3) provably approximate the true underlying data matrix M under certain conditions [6, 2].",
      "startOffset" : 92,
      "endOffset" : 98
    }, {
      "referenceID" : 1,
      "context" : "(2) and (3) provably approximate the true underlying data matrix M under certain conditions [6, 2].",
      "startOffset" : 92,
      "endOffset" : 98
    }, {
      "referenceID" : 6,
      "context" : "Inspired by [7, 8, 9], we exploit the KKT conditions of the optimization problem Θλ(·) to approximately compute∇M̃Θλ(M̃; M).",
      "startOffset" : 12,
      "endOffset" : 21
    }, {
      "referenceID" : 7,
      "context" : "Inspired by [7, 8, 9], we exploit the KKT conditions of the optimization problem Θλ(·) to approximately compute∇M̃Θλ(M̃; M).",
      "startOffset" : 12,
      "endOffset" : 21
    }, {
      "referenceID" : 8,
      "context" : "Inspired by [7, 8, 9], we exploit the KKT conditions of the optimization problem Θλ(·) to approximately compute∇M̃Θλ(M̃; M).",
      "startOffset" : 12,
      "endOffset" : 21
    }, {
      "referenceID" : 2,
      "context" : "singular value thresholding [3] for nuclear norm minimization).",
      "startOffset" : 28,
      "endOffset" : 31
    }, {
      "referenceID" : 1,
      "context" : "In addition, the resulting estimation (X; X̃) is low rank due to the nuclear norm penalty [2].",
      "startOffset" : 90,
      "endOffset" : 93
    }, {
      "referenceID" : 1,
      "context" : "The subdifferential of the nuclear norm function ∂‖ · ‖∗ is also known [2]: ∂‖X‖∗ = { UV + W : UW = WV = 0, ‖W‖2 ≤ 1 } ,",
      "startOffset" : 71,
      "endOffset" : 74
    }, {
      "referenceID" : 9,
      "context" : "To circumvent this problem, we apply Stochastic Gradient Langevin Dynamics (SGLD, [10]) to approximately sample M̃ from its posterior distribution in Eq.",
      "startOffset" : 82,
      "endOffset" : 86
    } ],
    "year" : 2016,
    "abstractText" : "Recommendation and collaborative filtering systems are important in modern information and e-commerce applications. As these systems are becoming increasingly popular in the industry, their outputs could affect business decision making, introducing incentives for an adversarial party to compromise the availability or integrity of such systems. We introduce a data poisoning attack on collaborative filtering systems. We demonstrate how a powerful attacker with full knowledge of the learner can generate malicious data so as to maximize his/her malicious objectives, while at the same time mimicking normal user behavior to avoid being detected. While the complete knowledge assumption seems extreme, it enables a robust assessment of the vulnerability of collaborative filtering schemes to highly motivated attacks. We present efficient solutions for two popular factorizationbased collaborative filtering algorithms: the alternative minimization formulation and the nuclear norm minimization method. Finally, we test the effectiveness of our proposed algorithms on real-world data and discuss potential defensive strategies.",
    "creator" : "TeX"
  }
}