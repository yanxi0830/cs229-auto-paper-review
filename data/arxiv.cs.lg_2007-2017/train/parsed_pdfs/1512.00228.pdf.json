{
  "name" : "1512.00228.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : null,
    "authors" : [ "Henry Rosales-Méndez", "Yunior Ramı́rez-Cruz" ],
    "emails" : [ "hrosmendez@gmail.com,", "yunior.ramirez@urv.cat" ],
    "sections" : [ {
      "heading" : null,
      "text" : "ar X\niv :1\n51 2.\n00 22\n8v 1\n[ cs\n.L G"
    }, {
      "heading" : "1 Introduction",
      "text" : "The aim of clustering algorithms (also referred to as unsupervised classification algorithms) is to structure a collection of objects into a set of groups, or clusters, aiming to place dissimilar objects in different clusters, and similar objects in the same cluster. The solutions to a large number of real world problems may be modelled by clusterings. Also, clustering is commonly used as an auxiliary task in many fields, e.g. wireless sensor networks [21], speech recognition [25], stochastic optimization [18], data compression [12], document organization, etc. In traditional clustering, the feature space on which objects are represented is determined off-line, and the representation of every object for performing the clustering method is determined on this feature space. In the last decades, a generalization of the traditional\nclustering task, called biclustering1, has emerged. The underlying idea of biclustering is to collaboratively find adequate subspaces of features, in terms of which meaningful, high quality clusters may be discovered. A variety of biclustering algorithms have been proposed. We can find surveys about this topic in [20, 23, 24, 26, 37]. Biclustering has been applied in a wide range of problems, such as image segmentation [36], face clustering [17], image compression [19], genome expression data [5], etc. Cluster validation is the field of study dealing with the methodologies aiming to asses the quality of the results of a clustering algorithm, which we refer to as candidate clustering. The quality of a candidate clustering is assessed via one or several evaluation measures, which are expected to yield optimum scores for high quality candidate clusterings and farfrom-optimum scores for poor candidate clusterings, as well as comparable scores for two or several comparable candidate clusterings. Validation criteria are divided into internal, external or relative. Relative validation measures choose the best results of multiple runs of a clustering algorithm with different parameters, whether these results have been obtained by means of an internal or external measure. Internal validation measures assess the quality of a candidate clustering by analyzing exclusively the group structure and/or the objectto-object, object-to-cluster and cluster-to-cluster relations observed in it, whereas external validation measures compare the candidate clustering to an ideal clustering, also called gold standard. The gold standard is assumed to describe the correct clustering, i.e. the one that best fits the real world structure of the collection, and is usually the result of a manual annotation process conducted by one, or (desirably) several, human specialists. In the context of external evaluation measures, it is common to use the term cluster only to refer to the clusters in the candidate clustering, whereas the clusters in the gold standard are called classes, categories, or hidden clusters. For uniformity, throughout this work we will use the term classes for referring to the clusters of the gold standard. The large number of evaluation measures proposed has brought up the need of developing meta-evaluation criteria, which intend to assess the suitability of a given evaluation measure, or to compare two measures. Usually, these criteria are expressed as sets of conditions to be satisfied by “good” evaluation measures. No set of conditions enjoys universal acceptation. Here, when treating measures for traditional clustering, we use the set of four conditions proposed by Amigó et al. in [2] for traditional clustering, along with an additional condition proposed by the authors of this work in [32,33] for the overlapping clustering scenario, as the basis for meta-evaluation. We do so because the conditions proposed in [2] were shown to subsume the previously existing conditions. For an analogous reason, when treating measures for biclustering, we additionally use the set of conditions proposed by Patrikainen and Meila in [28]. Several studies have been conducted on external cluster validation in traditional clustering [2–4, 9, 13, 15, 22, 31, 32, 34]. Although measures defined for this purpose may be used to partially evaluate biclusterings from the object space perspective, they are unable to take into account the quality of the feature space clustering. According to Patrikainen and Meila [28], three different approaches have been followed in biclustering validation. On one hand, a number of authors have evaluated biclusterings from the object space perspective only, overlooking information about the feature space [1, 10, 29, 30, 37]. On the other hand,\n1A wide variety of terms have been used to refer to this task. While it is called biclustering in [35], it is also referred to as co-clustering [8], subspace clustering [28], (coupled) two-way clustering [7], simultaneous clustering [6], block clustering [16], direct clustering [16], projection/projected/projective clustering [1] and clustering on subsets of attributes [11].\nother authors only take into account the feature subspace perspective [27]. Finally, a third approach consists on evaluating the quality from each perspective separately and merging the partial scores into one final score [8]. In every case, a measure that only takes into account the object (feature) space yields the same value for any biclustering whose object (feature) clusters are fixed, regardless the clustering on the feature (object) space. To overcome this problem, new measures have been proposed which deal with both perspectives in a joint manner [14]. Traditional clustering may be viewed as a particular case of biclustering, where a fixed feature subspace is associated to every clustering. In light of this consideration, it is reasonable to expect that biclustering evaluation measures, when applied in this scenario, satisfy traditional clustering meta-evaluation conditions. However, as we will show later, that is not always the case. Motivated by this problem, in this paper we present a new measure for biclustering evaluation, MOCICE-BCubed F1, which builds on the measure CICE-BCubed F1, known to satisfy the most comprehensive set of meta-evaluation conditions on traditional clustering. The new measure correctly adapts to the biclustering scenario by applying the so-called micro-objects transformation, and it satisfies the most comprehensive set of biclustering meta-evaluation conditions, while also inheriting the compliance to all traditional clustering meta-evaluation conditions. The remainder of this paper is organized as follows. In Section 2, we briefly review previous work in biclustering algorithm evaluation, focusing on the most comprehensive set of meta-evaluation conditions for traditional clustering and biclustering, existing micro-objectbased external evaluation measures and the fact that these measures fail to satisfy several meta-evaluation conditions when used for evaluating traditional clusterings. In Section 3, we describe the new proposed measure and prove its compliance to meta-evaluation conditions. Finally, we present our conclusions in Section 4."
    }, {
      "heading" : "2 Background and previous work",
      "text" : "Given the pair (O,F ), where O = {o1, o2, . . . , on} is usually viewed as a set of objects and F = {f1, f2, . . . , fm} is usually viewed as a set of features, a traditional clustering of (O,F ) is a set G = {G1, G2, . . . , Gt}, where Gi ⊆ O for every i ∈ {1, . . . , t}, whereas a biclustering of (O,F ) is a set G̈ = {G̈1, G̈2, . . . , G̈t}, where G̈i = (Ḡi, G̊i), Ḡi ⊆ O and G̊i ⊆ F for every i ∈ {1, . . . , t}. Traditional clusterings may be considered as a particular case of biclusterings, where G̊i = G̊j for every i, j ∈ {1, . . . , t}. In particular, we can make G̊i = F for every i ∈ {1, . . . , t}.\nA biclustering G̈ needs not satisfy ∪G̈∈G̈Ḡ = O nor ∪G̈∈G̈G̊ = F . Moreover, for two\nbiclusters G̈, G̈′ ∈ G̈, the conditions Ḡ∩ Ḡ′ = ∅ and G̊∩ G̊′ = ∅ are not enforced neither, i.e. overlapping is allowed on both the object space and the feature space.\nFormally, an evaluation measure for traditional clusterings is a function of the form\nf : ρ(ρ(O))× ρ(ρ(O)) −→ R,\nwhere ρ(O) is the power set of O. Such a function takes a candidate clustering and a gold standard as arguments, and yields a score that indicates how good the candidate clustering is according to the gold standard. Higher scores are commonly interpreted as better, i.e. the measure is assumed to assess the similarity between the candidate clustering and the gold standard, but that is not a mandatory behaviour, as a measure may also assess the dissimilarity between the candidate clustering and the gold standard. In an analogous manner, an\nevaluation measure for biclusterings is a function of the form\nf : ρ(ρ(O)× ρ(F ))× ρ(ρ(O)× ρ(F )) −→ R.\nSeveral authors have proposed sets of meta-evaluation conditions for traditional clusterings [9, 22, 34]. A set of four conditions is proposed in [2] which subsumes those previously existing. An additional condition was proposed in [32, 33] to account for special situations arising in overlapping clusterings. These conditions are enunciated as follows:\nA.1- Homogeneity [2]: Let C be a gold standard and let G1 be a clustering where one cluster Gk contains objects belonging to two classes Ci, Cj ∈ C. Let G2 be a clustering identical to G1, except for the fact that instead of the cluster Gk, it contains two clusters G\n′ k1\nand G′k2 , one of them containing only objects belonging to Ci and the other containing only objects belonging to Cj. An evaluation measure that satisfies the homogeneity condition should score G1 worse than G2.\nA.2- Completeness [2]: Let C be a gold standard and let G1 be a clustering where two clusters G1 and G2 contain only objects belonging to one class Ck ∈ C. Let G2 be a clustering identical to G1, except for the fact that instead of the clusters G1 and G2, it contains the cluster G1,2 = G1 ∪ G2. An evaluation measure that satisfies the completeness condition should score G1 worse than G2.\nA.3- Rag Bag [2]: Let C be a gold standard. Let G1 be a clustering where one cluster Gclean contains n objects belonging to one class Ci ∈ C plus one object belonging to a different class Cj ∈ C − {Ci} and one cluster Gnoise contains n objects belonging to n different classes. Let G2 be a clustering identical to G1, except for the fact that the object in Gclean that does not belong to the same class as all other objects is placed instead in Gnoise. An evaluation measure that satisfies the rag bag condition should score G1 worse than G2.\nA.4- Clusters size versus quantity [2]: Let C be a gold standard. Let G be a clustering where one cluster Glarge contains r + 1 objects belonging to one class Ci ∈ C and r clusters G1, G2, . . . , Gr, contain each one two objects belonging to the same class. Let G1 be a clustering identical to G, except for the fact that instead of the two-object clusters G1, G2, . . . , Gr, it contains 2r singleton clusters containing the corresponding objects. Let G2 be a clustering identical to G, except for the fact that instead of the cluster Glarge, it contains one cluster of size r and one cluster of size 1. An evaluation measure that satisfies the clusters size versus quantity condition should score G1 worse than G2.\nA.5- Perfect match [32, 33]: An evaluation measure must yield the optimum score for a candidate clustering if and only if it is identical to the gold standard.\nRegarding biclustering algorithms, a set of five conditions are presented in [28] which describe what is considered as a good behavior, so good evaluation measures are expected to reward algorithms that exhibit such behavior. These conditions are enunciated as follows:\nB.1- Penalty for non-intersection area: Let G̈ be a biclustering and let G̈ ′ be a biclustering identical to G̈, except for the fact that one (or more) non-clustered object o ∈ O −( ∪G̈∈G̈Ḡ ⋃ ∪C̈∈C̈C̄ ) , is added to G̈ ′, either as a new singleton cluster, or as part of an\nexisting cluster. An evaluation measure that satisfies the penalty for non-intersection area condition should score G̈ ′ worse than G̈.\nB.2- Background independence: The score yielded for a pair of biclusterings must not depend on non-clustered objects. Let C̈X and G̈X be a gold standard and a candidate biclustering, respectively, on a collection X . Let X ′ be a collection such that X ⊂ X ′\nand let C̈X′ and G̈X′ represent C̈X and G̈X on X ′. An evaluation measure that satisfies the background independence condition should yield the same score for (G̈X , C̈X) and (G̈X′ , C̈X′).\nB.3- Scale invariance: For a positive integer k and a biclustering G̈, a k-scaled biclustering G̈ ′ of G̈ is a biclustering where, for every G̈′ ∈ G̈ ′, Ḡ′ is the disjoint union of k copies of Ḡ and G̊′ is the disjoint union of k copies of G̊. Let G̈ and C̈ be a candidate biclustering and a gold standard, respectively, and let G̈ ′ and C̈′ be k-scaled biclusterings of G̈ and C̈. An evaluation measure that satisfies the scale invariance condition should yield the same score for (G̈ ′, C̈′) and (G̈, C̈).\nB.4- Copy invariance: Let C̈ be a gold standard and let G̈ be a candidate biclustering. For a positive integer k, let G̈ ′ be the disjoint union of k copies of G̈, and let C̈′ be the disjoint union of k copies of C̈. An evaluation measure that satisfies the copy invariance condition should yield the same score for (G̈ ′, C̈′) and (G̈, C̈).\nB.5- Multiple cluster coverage penalty : Let G̈ = {G̈} be a singleton biclustering. Let C̈ = {C̈1, C̈2, . . . , C̈t} be a gold standard such that Ḡ = ∪C̈∈C̈C̄ and G̊ = ∪C̈∈C̈C̊. An evaluation measure that satisfies the multiple cluster coverage penalty condition should not yield the optimum score for (G̈, C̈).\nWe now discuss several external evaluation strategies proposed for the biclustering scenario. We describe the micro-objects transformation and the measures that have been adapted to this approach, namely CE, RNIA, Rand’s index, VI and E4SC. Patrikainen and Meila [28] propose to transform the candidate biclustering and the gold standard into traditional clusterings in order to apply existing evaluation measures for the latter. They do so by transforming (O,F ) into the new space (O × F, ∅), where O × F is composed by pairs of the form (o, f), o ∈ O, f ∈ F , which they call micro-objects. Thus, a biclustering G̈ = {(Ḡ1, G̊1), (Ḡ2, G̊2), . . . , (Ḡt, G̊t)} is transformed into a clustering G̃ = {G̃1, G̃2, . . . , G̃t} where G̃i = Ḡi × G̊i for every i ∈ {1, . . . , t}. Patrikainen and Meila introduce their proposals on non-overlapping biclusterings, which they propose to evaluate by applying the micro-objects transformation in combination with the measures Clustering Error (CE ), Relative Non-intersecting Area (RNIA), Rand’s index and Variation of information (VI ). CE determines the best matching between the candidate clustering and the gold standard, and computes the total number of objects shared by every class-cluster pair, according to this matching, which is denoted by Dmax. Let U = (∪G∈GG) ⋃ (∪C∈CC). CE is defined as\nCE(G, C) = |U | −Dmax\n|U | (1)\nNow, let I = (∪G∈GG) ⋂ (∪C∈CC). RNIA is defined as\nRNIA(G, C) = |U | − |I|\n|U | (2)\nThe traditional Rand’s index assumes the candidate clustering and the gold standard to be partitions of the object universe and is defined as\nRand(G, C) = N00 +N11\nN (3)\nwhere N01 is the number of object pairs that co-occur in a cluster of G and co-occur in a class of C, N00 is the number of object pairs that do not co-occur in a cluster of G and do not co-occur in a class of C, and N is the total number of object pairs. Patrikainen and Meila count N on the universe U = (∪G∈GG)∪ (∪C∈CC) and, to make the candidate clustering and the gold standard be partitions of U , they add as many singleton clusters as necessary. Finally, VI is based on information theory and assesses the amount of information gained and lost when transforming the candidate clustering into the gold standard, as follows:\nV I(G, C) = 1\n|U |\nt1∑\ni=1\nt2∑\nj=1\n|Gi ∩ Cj| log |Gi| · |Cj|\n|Gi ∩ Cj|2 (4)\nwhere t1 = |G| and t2 = |C|. In a manner analogous as for Rand’s index, they transform the candidate clustering and the gold standard into partitions of U by adding as many singleton clusters as necessary. Also following this approach, Günnemann et al. [14] propose to combine the microobjects transformation and a variant of the F1 measure called E4SC. They compute the macro-averaged F1 of the candidate clustering with respect to the gold standard, and vice versa, and compute the F1 measure of both scores, as shown in Eq. 8.\nP (A,B) = R(B,A) = |A ∩ B|\n|A| (5)\nF1(G,C) = 2 · P (G,C) · R(G,C)\nP (G,C) +R(G,C) (6)\nmacroF1(G, C) = 1\n|G|\n∑\nG∈G\nmax C∈C {F1(G,C)} (7)\nE4SC(G, C) = 2 · macroF1(G, C) ·macroF1(C,G)\nmacroF1(G, C) +macroF1(C,G) (8)\nSince the micro-objects transformation turns the evaluation of biclusterings into that of traditional clusterings, it is reasonable to expect that the measures applied on the microobjects universe satisfy a wide range of meta-evaluation conditions for traditional clustering. However, the measures discussed so far fail to satisfy some of these conditions. Amigó et al. [2] show that Rand’s index and VI do not satisfy the Rag Bag (A.3) condition, whereas Rand’s index additionally fails to satisfy the Clusters size versus quantity (A.4) condition. Moreover, as we will show, CE, RNIA and E4SC also fail to satisfy some of these conditions. The biclusterings presented in Figs. 1 and 2 are examples designed to test the compliance of the evaluation measures to the Homogeneity (A.1) and Rag Bag (A.3) conditions, respectively. Both figures show the projections of the biclusters on the object space, whereas their projections on the feature space are set to be {1′, 2′, 3′} in all cases. For the sake of uniformity in our presentation, in all cases we consider that a biclustering G̈1 being scored worse than a biclustering G̈2 by a measure f means that f(G̈1, C̈) < f(G̈2, C̈), i.e. we view the scores yielded by evaluation measures as similarity values. Since CE and RNIA are defined as dissimilarities in the range [0, 1], in both cases we transform the scores into similarity values by making fsim(G̈, C̈) = 1− fdissim(G̈, C̈).\nTable 1 shows the scores yielded by CE, RNIA and E4SC for the pairs of traditional clusterings obtained by applying the micro-objects transformation to the biclusterings shown in Figs. 1 and 2. Every pair of values represents the scores yielded for G̈1 and G̈2, in that order. The emphasized cells highlight cases where the corresponding condition was not satisfied by the corresponding evaluation measure, as G̈1 was scored equally or better than G̈2."
    }, {
      "heading" : "3 Our proposal",
      "text" : "The basis of our new proposal is the measure CICE-BCubed F1, which was presented in [32, 33] for traditional clusterings, with an emphasis on adequately handling the occurrence of overlapping clusters. There, it was shown that CICE-BCubed F1 satisfies conditions A.1 to A.5. Building on that proposal, our new measure is designed to keep the elements of CICE-BCubed F1 that make it satisfy these conditions, while adapting it to the biclustering scenario in such a way that conditions B.1 to B.5 are also satisfied. We do so by adapting CICE-BCubed F1 to the micro-objects transformation.\nCICE-BCubed F1 is based on BCubed F1 [4]. They both redefine the traditional Information Retrieval measures Precision and Recall, whose values are combined into F1. The redefinitions introduced by CICE-BCubed and BCubed relate to traditional Precision and Recall in the sense that that they assess the likelihood of decisions made by the clustering algorithm to be correct and the likelihood of known correct decisions to be made by the algorithm, respectively. They differ in the nature of what is considered as a decision. While the original measures treat the action of placing an object in a cluster as a decision, BCubed and CICE-BCubed variants view a decision as the action of making two objects co-occur in a cluster. CICE-BCubed Precision and Recall differ from their BCubed counterparts in the fact that they add an extra term that prevents clusterings that are not identical to the gold standard from being given the maximum score. In order to evaluate a candidate clustering G = {G1, G2, . . . , Gt1} with respect to the gold standard C = {C1, C2, . . . , Ct2}, CICE-BCubed Precision computes a score for every pair of objects o, o′ ∈ O as follows\nς(o, o′) = min(|G(o) ∩ G(o′)|, |C(o) ∩ C(o′)|) · Φ(o, o′)\n|G(o) ∩ G(o′)| (9)\nwhere G(o) = {G ∈ G : o ∈ G}, C(o) = {C ∈ C : o ∈ C}, and the function Φ(o, o′), called Cluster Identity Index (CII), averages the degrees of similarity between every candidate cluster containing o and o′ and its most similar class, measured through their Jaccard’s coefficient, and is defined as\nΦ(o, o′) = 1\n|G(o, o′)|\n∑\nG∈G(o,o′)\nmax C∈C(o,o′)\n{ |G ∩ C|\n|G ∪ C|\n} (10)\nwhere G(o, o′) = {G ∈ G : o ∈ G and o′ ∈ G} and C(o, o′) = {C ∈ C : o ∈ C and o′ ∈ C}. All pairwise scores are combined into CICE-BCubed Precision as\nPrecision(G, C) = 1\n|O|\n∑\no∈O\n1\n| ⋃\nG∈G(o)G|\n∑\no′∈EG(o)\nς(o, o′) (11)\nwhere EG(o) = {o ′ : o ∈ G and o′ ∈ G for some G ∈ G}. Following an analogous strategy, CICE-BCubed Recall computes, for every pair of objects o, o′ ∈ O, the score\nτ(o, o′) = min(|G(o) ∩ G(o′)|, |C(o) ∩ C(o′)|) · Φ(o, o′)\n|C(o) ∩ C(o′)| (12)\nand combines all pairwise scores as\nRecall(G, C) = 1\n|O|\n∑\no∈O\n1\n| ⋃\nC∈C(o) C|\n∑\no′∈EC(o)\nτ(o, o′) (13)\nwhere EC(o) = {o ′ : o ∈ C and o′ ∈ C for some C ∈ C}. Finally, CICE-BCubed Precision and Recall are combined into CICE-BCubed F1 as\nF1(G, C) = 2 · Precision(G, C) · Recall(G, C)\nPrecision(G, C) +Recall(G, C) (14)\nWe now describe our adaptation of CICE-BCubed Precision and Recall for handling the evaluation of biclusterings. As we mentioned earlier, we apply a micro-objects transformation, by which a candidate biclustering G̈ = {G̈1, G̈2, . . . , G̈t1}, where G̈i = (Ḡi, G̊i) for i ∈ {1, . . . , t1}, is transformed into the candidate clustering G̃ = {G̃1, G̃2, . . . , G̃t1}, where G̃i = Ḡi × G̊i for i ∈ {1, . . . , t1}. In an analogous manner, the gold standard C̈ = {(C̄1, C̊1), (C̄2, C̊2), . . . , (C̄t2 , C̊t2)} is transformed into C̃ = {C̃1, C̃2, . . . , C̃t2}, with C̃i = C̄i × C̊i for i ∈ {1, . . . , t2}. For G̈ and C̈, we will define our new measure by redefining CICE-BCubed Precision and Recall and combining them into F1. We will refer to these redefinitions as Micro-objectspace-fitted CICE-BCubed, abbreviated toMOCICE-BCubed. First, note that CICE-BCubed Precision and Recall are defined under the assumption that every object in the universe O belongs to at least one candidate clustering and at least one class, i.e. ∪G∈GG = ∪C∈CC = O. This assumption is not valid for clusterings obtained from biclusterings by the micro-objects transformation. Instead, we define the (possibly different) sets\nU G̃ =\nt1⋃\ni=1\nG̃i and UC̃ = t2⋃\ni=1\nC̃i\nwhich are used for defining MOCICE-BCubed Precision and Recall as\nPrecision(G̈, C̈) = 1\n|U G̃ |\n∑\nx∈U G̃\n1\n| ⋃\nG̃∈G̃(x) G̃|\n∑\ny∈E G̃ (x)\nς̃(x, y) (15)\nand\nRecall(G̈, C̈) = 1\n|U C̃ |\n∑\nx∈U C̃\n1\n| ⋃\nC̃∈C̃(x) C̃|\n∑\ny∈E C̃ (x)\nτ̃ (x, y) (16)\nwhere\nς̃(x, y) = min(|G̃(x) ∩ G̃(y)|, |C̃(x) ∩ C̃(y)|) · Φ̃(x, y)\n|G̃(x) ∩ G̃(y)| (17)\nτ̃ (x, y) = min(|G̃(x) ∩ G̃(y)|, |C̃(x) ∩ C̃(y)|) · Φ̃(x, y)\n|C̃(x) ∩ C̃(y)| (18)\nand\nΦ̃(x, y) = 1\n|G̃(x, y)|\n∑\nG̃∈G̃(x,y)\nmax C̃∈C̃(x,y)\n{ |G̃ ∩ C̃|\n|G̃ ∪ C̃|\n} (19)\nFinally, MOCICE-BCubed F1 is computed in the usual manner, combining MOCICEBCubed Precision and Recall as\nF1(G̈, C̈) = 2 · Precision(G̈, C̈) · Recall(G̈, C̈)\nPrecision(G̈, C̈) +Recall(G̈, C̈) (20)\nConsider a traditional clustering G = {G1, G2, . . . , Gt1} and a gold standard C = {C1, C2, . . . , Ct2}. As we mentioned previously, G and C may be seen as two biclusterings\nG̈ = {(G1, X), (G2, X), . . . , (Gt1 , X)} and C̈ = {(C1, X), (C2, X), . . . , (Ct2, X)}, where X ⊆ F is an arbitrary feature set. When applied to such biclustering scenario, MOCICE-BCubed F1 is equivalent to CICE-BCubed F1 on the clustering G̃ = {G1 ×X,G2 ×X, . . . , Gt1 ×X} and the gold standard C̃ = {C1 × X,C2 ×X, . . . , Ct2 ×X}, as ∪G∈GG = O. Moreover, the following result on CICE-BCubed F1 holds.\nTheorem 1. Let G = {G1, G2, . . . , Gt1} and C = {C1, C2, . . . , Ct2} be a candidate clustering and a gold standard, respectively, on (O,F ). Let X ⊆ F be an arbitrary feature set and let\nG̃ = {G1 ×X,G2 ×X, . . . , Gt1 ×X} and C̃ = {C1 ×X,C2 ×X, . . . , Ct2 ×X}. Then,\nF1(G̃, C̃) = F1(G, C).\nProof. It is simple to see that |G̃((o, f))| = |G(o)| and |C̃((o, f))| = |C(o)| for every o ∈ O and every f ∈ X . Moreover, in Eq. 10, we have that for any G ∈ G and any C ∈ C,\n|(G×X) ∩ (C ×X)| |(G×X) ∪ (C ×X)| = |X| · |G ∩ C| |X| · |G ∪ C| = |G ∩ C| |G ∪ C| .\nThus, Φ((o, f), (o′, f ′)) = Φ(o, o′) for every o ∈ O and every f ∈ X . In consequence, ς((o, f), (o′, f ′)) = ς(o, o′) and τ((o, f), (o′, f ′)) = τ(o, o′) for every o ∈ O and every f ∈ X .\nFurthermore, we have that E G̃ ((o, f)) = EG(o)×X and EC̃((o, f)) = EC(o)×X for every\no ∈ O and every f ∈ X . Finally, | ⋃ G̃∈G̃((o,f)) G̃| = |X| · | ⋃ G∈G(o) G|, so\nPrecision(G̃, C̃) = 1\n|O| · |X|\n∑\n(o,f)∈O×X 1∣∣∣∣∣∣ ⋃\nG̃∈G̃((o,f))\nG̃ ∣∣∣∣∣∣\n∑\n(o′,f ′)∈E G̃ ((o,f))\nς((o, f), (o′, f ′))\n= 1\n|O| · |X|\n∑\n(o,f)∈O×X\n|X|\n|X| · ∣∣∣∣∣∣ ⋃\nG∈G(o)\nG ∣∣∣∣∣∣\n∑\no′∈EG(o)\nς(o, o′)\n= |X|\n|O| · |X|\n∑\no∈O\n1\n| ⋃\nG∈G(o) G|\n∑\no′∈EG(o)\nς(o, o′)\n= Precision(G, C)\nand, by an analogous reasoning, Recall(G̃, C̃) = Recall(G, C). In consequence, F1(G̃, C̃) = F1(G, C), so the proof is complete.\nAs a consequence of Theorem 1, we can say that transforming a clustering G and a gold standard C into biclusterings and computing MOCICE-BCubed F1 on them is equivalent to computing CICE-BCubed F1 on G and C, so under this transformation conditions A.1 to A.5 continue to be satisfied. In what follows, we will show that MOCICE-BCubed F1 also satisfies conditions B.1 to B.5.\nTheorem 2. MOCICE-BCubed F1 satisfies condition B.1 (Penalty for non-intersection area).\nProof. Let G̈ and G̈ ′ be a pair of candidate biclusterings satisfying the premises of condition B.1, and let C̈ be the gold standard. We have that Precision(G̈, C̈) < Precision(G̈ ′, C̈) because of the extra, incorrectly clustered, object(s) involved in G̈ ′. Moreover, Recall(G̈, C̈) = Recall(G̈ ′, C̈), so F1(G̈, C̈) < F1(G̈ ′, C̈), as required by the condition.\nTheorem 3. MOCICE-BCubed F1 satisfies condition B.2 (Background independence).\nProof. The result is a direct consequence of the manner in which U G̃ and U C̃ are defined.\nTheorem 4. MOCICE-BCubed F1 satisfies condition B.3 (Scale invariance).\nProof. Let G̈ be a candidate biclustering and let C̈ be a gold standard. Let G̈ ′ and C̈′ be the k-scaled versions of G̈ and C̈, respectively, and let G̃, G̃ ′, C̃ and C̃′ be the micro-object-space clusterings into which G̈, G̈ ′, C̈ and C̈′ are transformed, respectively. It is simple to see that |G̃ ′(x)| = |G̃(x)| and |C̃′(x)| = |C̃(x)| for any x. Moreover, for any G̃ ∈ G̃ and any C̃ ∈ C̃,\n|G̃′ ∩ C̃ ′| |G̃′ ∪ C̃ ′| = k · |G̃ ∩ C̃| k · |G̃ ∪ C̃| = |G̃ ∩ C̃| |G̃ ∪ C̃| ,\nso the value yielded by Φ̃(x, y) for any pair x, y when evaluating (G̈ ′, C̈′) is the same yielded when evaluating (G̈, C̈). As a consequence of the aforementioned facts, we have that the values yielded by ς̃(x, y) and τ̃(x, y) for any pair x, y when evaluating (G̈ ′, C̈′) are also the same yielded when evaluating (G̈, C̈). Thus,\nPrecision(G̈ ′, C̈′) = 1\n|U G̃′ |\n∑\nx∈U G̃′\n1\n| ⋃\nG̃′∈G̃′(x) G̃ ′|\n∑\ny∈E G̃′ (x)\nς̃(x, y)\n= 1\nk · |U G̃ |\n∑\nx∈U G̃\nk · 1\nk · | ⋃\nG̃∈G̃(x) G̃|\n∑\ny∈E G̃ (x)\nk · ς̃(x, y)\n= Precision(G̈, C̈)\nand, by an analogous reasoning, Recall(G̈ ′, C̈′) = Recall(G̈, C̈). In consequence, F1(G̈ ′, C̈′) = F1(G̈, C̈), so the proof is complete.\nTheorem 5. MOCICE-BCubed F1 satisfies condition B.4 (Copy invariance).\nProof. Let G̈ be a candidate biclustering and let C̈ be a gold standard. Let G̈ ′ and C̈′ be the k-copied versions of G̈ and C̈, respectively, and let G̃, G̃ ′, C̃ and C̃′ be the micro-object-space clusterings into which G̈, G̈ ′, C̈ and C̈′ are transformed, respectively. For any x, we have that G̃ ′(x) is the disjoint union of k copies of G̃(x) and C̃′(x) is the disjoint union of k copies of\nC̃(x). Moreover,\n1\n|G̃ ′(x, y)|\n∑\nG̃′∈G̃′(x,y)\nmax C̃′∈C̃′(x,y)\n{ |G̃′ ∩ C̃ ′|\n|G̃′ ∪ C̃ ′|\n} =\n= 1\nk · |G̃(x, y)|\n∑\nG̃∈G̃(x,y)\nk · max C̃∈C̃(x,y)\n{ |G̃ ∩ C̃|\n|G̃ ∪ C̃|\n} =\n= 1\n|G̃(x, y)|\n∑\nG̃∈G̃(x,y)\nmax C̃∈C̃(x,y)\n{ |G̃ ∩ C̃|\n|G̃ ∪ C̃|\n} ,\nso the value yielded by Φ̃(x, y) for any pair x, y when evaluating (G̈ ′, C̈′) is the same yielded when evaluating (G̈, C̈). As a consequence of the aforementioned facts, we have that the values yielded by ς̃(x, y) and τ̃(x, y) for any pair x, y when evaluating (G̈ ′, C̈′) are also the same yielded when evaluating (G̈, C̈), as the role of the k copies is simplified out when performing the divisions in Eqs. 17 and 18. Thus,\nPrecision(G̈ ′, C̈′) = 1\n|U G̃′ |\n∑\nx∈U G̃′\n1\n| ⋃\nG̃′∈G̃′(x) G̃ ′|\n∑\ny∈E G̃′ (x)\nς̃(x, y)\n= 1\n|U G̃ |\n∑\nx∈U G̃\n1\n| ⋃\nG̃∈G̃(x) G̃|\n∑\ny∈E G̃ (x)\nς̃(x, y)\n= Precision(G̈, C̈)\nand, by an analogous reasoning, Recall(G̈ ′, C̈′) = Recall(G̈, C̈). In consequence, F1(G̈ ′, C̈′) = F1(G̈, C̈), so the proof is complete.\nTheorem 6. MOCICE-BCubed F1 satisfies condition B.5 (Multiple cluster coverage penalty).\nProof. The result is a direct consequence of MOCICE-BCubed F1 being equivalent to CICEBCubed F1 on the micro-objects space and CICE-BCubed F1 satisfying condition A.5 (Perfect match) which guarantees that the optimum score is given to a candidate clustering if and only if it is identical to the gold standard.\nSumming up, Theorems 2 to 6 show that MOCICE-BCubed F1 satisfies conditions B.1 to B.5."
    }, {
      "heading" : "4 Conclusions",
      "text" : "In this paper we have presented MOCICE-BCubed F1, a new external evaluation measure for biclustering algorithms. This measure is an adaptation, based on the micro-objects transformation, of CICE-BCubed F1, which had been previously shown to satisfy the most comprehensive set of meta-evaluation conditions for the traditional clustering task. We show that the new measure is equivalent to CICE-BCubed F1 when evaluating traditional clustering, viewed as a particular case of biclustering, thus inheriting the compliance to the most comprehensive set of meta-evaluation conditions for this task. This behaviour sets MOCICE-BCubed F1 apart from previously proposed micro-object-based measures, for which we provide counterexamples showing lack of compliance with several of these conditions. Moreover, we show that MOCICE-BCubed F1 also satisfies the most comprehensive set of meta-evaluation conditions specific to the biclustering task. Our main direction for future work has to do with the practical difficulty of handannotating gold standard collections for biclustering evaluation with both the object clusters and the associated feature subspaces. To that end, we intend to propose measures capable of using traditional clustering gold standards, of which there is a much larger availability, to evaluate biclusterings. That entails proposing hybrid mechanisms allowing the use of external criteria to evaluate the candidate biclustering from the object space perspective, and internal criteria to conduct the evaluation from the feature space perspective."
    } ],
    "references" : [ {
      "title" : "Finding Generalized Projected Clusters in High Dimensional Spaces",
      "author" : [ "C. Aggarwal", "P. Yu" ],
      "venue" : "Proc. ACM SIGMOD Int’l Conf. Management of Data (pp. 70-81)",
      "citeRegEx" : "1",
      "shortCiteRegEx" : "1",
      "year" : 2000
    }, {
      "title" : "A comparison of extrinsic clustering evaluation metrics based on formal constraints. Information Retrieval",
      "author" : [ "E. Amigó", "J. Gonzalo", "J. Artiles", "F. Verdejo" ],
      "venue" : null,
      "citeRegEx" : "2",
      "shortCiteRegEx" : "2",
      "year" : 2009
    }, {
      "title" : "A General Evaluation Measure for Document Organization Tasks. SIGIR’2013",
      "author" : [ "E. Amigó", "J. Gonzalo", "F. Verdejo" ],
      "venue" : null,
      "citeRegEx" : "3",
      "shortCiteRegEx" : "3",
      "year" : 2013
    }, {
      "title" : "Entity-based cross-document coreferencing using the vector space model",
      "author" : [ "A. Bagga", "B. Baldwin" ],
      "venue" : "In Proceedings of the 36th Annual Meeting of the Association for Computational Linguistics and the 17th International Conference on Computational Linguistics (pp. 79-85)",
      "citeRegEx" : "4",
      "shortCiteRegEx" : "4",
      "year" : 1998
    }, {
      "title" : "Identification of coexpressed gene modules across multiple brain diseases by a biclustering analysis on integrated gene expression data",
      "author" : [ "K. Cha", "O. Kimin", "H. Taeho", "Y. Gwan-Su" ],
      "venue" : "In Proceedings of the ACM 8th International Workshop on Data and Text Mining in Bioinformatics. ACM",
      "citeRegEx" : "5",
      "shortCiteRegEx" : "5",
      "year" : 2014
    }, {
      "title" : "Simultaneous clustering: A survey. Pattern Recognition and Machine Intelligence",
      "author" : [ "M. Charrad", "M. Ahmed" ],
      "venue" : null,
      "citeRegEx" : "6",
      "shortCiteRegEx" : "6",
      "year" : 2011
    }, {
      "title" : "Module function and two-way clustering analysis of Epstein-Barr virus-related nasopharyngeal cancer",
      "author" : [ "F. Chen", "J. Liu", "M. Fan", "X.M. Wei", "Y.L. Xie", "L.H. Wang", "H. Yang" ],
      "venue" : "Genetics and molecular research: GMR",
      "citeRegEx" : "7",
      "shortCiteRegEx" : "7",
      "year" : 2014
    }, {
      "title" : "Minimum Sum-Squared Residue Co- Clustering of Gene Expression Data",
      "author" : [ "H. Cho", "I. Dhillon", "Y. Guan", "S. Sra" ],
      "venue" : "In Proceedings Fourth SIAM International Conference on Data Mining",
      "citeRegEx" : "8",
      "shortCiteRegEx" : "8",
      "year" : 2004
    }, {
      "title" : "An information-theoretic external cluster-validity measure",
      "author" : [ "B. Dom" ],
      "venue" : "In Proceedings of the Eighteenth Conference on Uncertainty in Artificial Intelligence (pp. 137-145)",
      "citeRegEx" : "9",
      "shortCiteRegEx" : "9",
      "year" : 2002
    }, {
      "title" : "Subspace Clustering of High Dimensional Data",
      "author" : [ "C. Domeniconi", "D. Papadopoulos", "D. Gunopulos", "S. Ma" ],
      "venue" : "In Proceedings Fourth SIAM International Conference on Data Mining",
      "citeRegEx" : "10",
      "shortCiteRegEx" : "10",
      "year" : 2004
    }, {
      "title" : "Clustering Objects on Subsets of Attributes",
      "author" : [ "J.H. Friedman", "J.J. Meulman" ],
      "venue" : "Journal of the Royal Statistical Society: Series B (Statistical Methodology),",
      "citeRegEx" : "11",
      "shortCiteRegEx" : "11",
      "year" : 2004
    }, {
      "title" : "Adaptive clustering for hyperspectral sounder data compression",
      "author" : [ "I. Gladkova", "L. Roytman", "M. Goldberg" ],
      "venue" : "In Optics & Photonics",
      "citeRegEx" : "12",
      "shortCiteRegEx" : "12",
      "year" : 2005
    }, {
      "title" : "Measuring Similarity between Sets of Overlapping Clusters",
      "author" : [ "M. Goldberg", "M. Hayvanovych", "M. Magdon-Ismail" ],
      "venue" : "Social Computing (SocialCom),",
      "citeRegEx" : "13",
      "shortCiteRegEx" : "13",
      "year" : 2010
    }, {
      "title" : "External Evaluation Measures for Subspace Clustering",
      "author" : [ "S. Günnemann", "I. Färber", "E. Müller", "I. Assent", "T. Seidl" ],
      "venue" : "In Proceedings of the 20th ACM international conference on Information and knowledge management (pp. 1363-1372)",
      "citeRegEx" : "14",
      "shortCiteRegEx" : "14",
      "year" : 2011
    }, {
      "title" : "On Clustering Validation Techniques",
      "author" : [ "M. Halkidi", "Y. Batistakis", "M. Vazirgiannis" ],
      "venue" : "Journal of Intelligent Information Systems",
      "citeRegEx" : "15",
      "shortCiteRegEx" : "15",
      "year" : 2001
    }, {
      "title" : "Direct clustering of a data matrix. Journal of the american statistical association",
      "author" : [ "J. Hartigan" ],
      "venue" : null,
      "citeRegEx" : "16",
      "shortCiteRegEx" : "16",
      "year" : 1972
    }, {
      "title" : "Clustering appearances of objects under varying illumination conditions",
      "author" : [ "J. Ho", "M. Yang", "J. Lim", "K. Lee", "D. Kriegman" ],
      "venue" : "In IEEE Conference on Computer Vision and Pattern Recognition",
      "citeRegEx" : "17",
      "shortCiteRegEx" : "17",
      "year" : 2003
    }, {
      "title" : "Financial scenario generation for stochastic multi-stage decision processes as facility location problems",
      "author" : [ "R. Hochreiter", "G. Pflug" ],
      "venue" : "Annals of Operations Research",
      "citeRegEx" : "18",
      "shortCiteRegEx" : "18",
      "year" : 2007
    }, {
      "title" : "Multi-scale hybrid linear models for lossy image representation",
      "author" : [ "W. Hong", "J. Wright", "K. Huang", "Y. Ma" ],
      "venue" : "IEEE Transactions on Image Processing",
      "citeRegEx" : "19",
      "shortCiteRegEx" : "19",
      "year" : 2006
    }, {
      "title" : "Clustering high-dimensional data: A survey on biclustering, pattern-based clustering, and correlation clustering",
      "author" : [ "H. Kriegel", "P. Kröger", "A. Zimek" ],
      "venue" : "ACM Transactions on Knowledge Discovery from Data (TKDD)",
      "citeRegEx" : "20",
      "shortCiteRegEx" : "20",
      "year" : 2009
    }, {
      "title" : "Comparing clusterings by the Variation Information",
      "author" : [ "M. Meila" ],
      "venue" : "Lecture Notes in Computer Science",
      "citeRegEx" : "22",
      "shortCiteRegEx" : "22",
      "year" : 2003
    }, {
      "title" : "Subspace and projected clustering: experimental evaluation and analysis",
      "author" : [ "G. Moise", "A. Zimek", "P. Kröger", "H. Kriegel", "J. Sander" ],
      "venue" : "Knowledge and Information Systems",
      "citeRegEx" : "23",
      "shortCiteRegEx" : "23",
      "year" : 2009
    }, {
      "title" : "Evaluating clustering in subspace projections of high dimensional data",
      "author" : [ "E. Müller", "S. Günnemann", "I. Assent", "T. Seidl" ],
      "venue" : "In Proceedings of the VLDB Endowment",
      "citeRegEx" : "24",
      "shortCiteRegEx" : "24",
      "year" : 2009
    }, {
      "title" : "Optimization of Speech Recognition by Clustering of Phones. Fundamenta Informaticae",
      "author" : [ "A. Nowak", "A. Wakulicz-Deja", "S. Bachliónski" ],
      "venue" : null,
      "citeRegEx" : "25",
      "shortCiteRegEx" : "25",
      "year" : 2006
    }, {
      "title" : "Subspace clustering for high dimensional data: a review",
      "author" : [ "L. Parsons", "E. Haque", "H. Liu" ],
      "venue" : "ACM SIGKDD Explorations Newsletter",
      "citeRegEx" : "26",
      "shortCiteRegEx" : "26",
      "year" : 2004
    }, {
      "title" : "Subspace Clustering of High Dimensional Binary Data-A Probabilistic Approach",
      "author" : [ "A. Patrikainen", "H. Mannila" ],
      "venue" : "In Proc. Workshop on Clustering High Dimensional Data, SIAM International Conference on Data Mining (pp. 57-65)",
      "citeRegEx" : "27",
      "shortCiteRegEx" : "27",
      "year" : 2004
    }, {
      "title" : "Comparing subspace clusterings",
      "author" : [ "A. Patrikainen", "M. Meila" ],
      "venue" : "IEEE Transactions on Knowledge and Data Engineering",
      "citeRegEx" : "28",
      "shortCiteRegEx" : "28",
      "year" : 2006
    }, {
      "title" : "A systematic comparison and evaluation of biclustering methods for gene expression data",
      "author" : [ "A. Prelić", "S. Bleuler", "P. Zimmermann", "A. Wille", "P. Bühlmann", "W. Gruissem", "L. Hennig", "L. Thiele", "E. Zitzler" ],
      "venue" : null,
      "citeRegEx" : "29",
      "shortCiteRegEx" : "29",
      "year" : 2006
    }, {
      "title" : "A Monte Carlo Algorithm for Fast Projective Clustering",
      "author" : [ "C. Procopiuc", "M. Jones", "P. Agarwal", "T. Murali" ],
      "venue" : "In Proceedings of the 2002 ACM SIGMOD international conference on Management of data (pp. 418-427)",
      "citeRegEx" : "30",
      "shortCiteRegEx" : "30",
      "year" : 2002
    }, {
      "title" : "Probabilistic Metrics for Soft- Clustering and Topic Model Validation",
      "author" : [ "E. Ramı́rez", "R. Brena", "D. Maggati", "F. Stella" ],
      "venue" : "Web Intelligence and Intelligent Agent Technology (WI-IAT)",
      "citeRegEx" : "31",
      "shortCiteRegEx" : "31",
      "year" : 2010
    }, {
      "title" : "CICE-BCubed: A New Evaluation Measure for Overlapping Clustering Algorithms. In Progress in Pattern Recognition, Image Analysis, Computer Vision, and Applications",
      "author" : [ "H. Rosales-Méndez", "Y. Ramı́rez-Cruz" ],
      "venue" : "Lecture Notes in Computer Science",
      "citeRegEx" : "32",
      "shortCiteRegEx" : "32",
      "year" : 2013
    }, {
      "title" : "Addressing the validation of overlapping clustering algorithms. Intelligent Data Analysis",
      "author" : [ "H. Rosales-Méndez", "Y. Ramı́rez-Cruz" ],
      "venue" : null,
      "citeRegEx" : "33",
      "shortCiteRegEx" : "33",
      "year" : 2014
    }, {
      "title" : "V-measure: A conditional entropy-based external cluster evaluation measure",
      "author" : [ "A. Rosenberg", "J. Hirschberg" ],
      "venue" : "In Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning",
      "citeRegEx" : "34",
      "shortCiteRegEx" : "34",
      "year" : 2007
    }, {
      "title" : "Improved biclustering of microarray data demonstrated through systematic performance tests",
      "author" : [ "H. Turner", "T. Bailey", "W. Krzanowski" ],
      "venue" : "Computational Statistics & Data Analysis",
      "citeRegEx" : "35",
      "shortCiteRegEx" : "35",
      "year" : 2005
    }, {
      "title" : "Unsupervised segmentation of natural images via lossy data compression",
      "author" : [ "A. Yang", "J. Wright", "Y. Ma", "S. Sastry" ],
      "venue" : "Computer Vision and Image Understanding",
      "citeRegEx" : "36",
      "shortCiteRegEx" : "36",
      "year" : 2008
    } ],
    "referenceMentions" : [ {
      "referenceID" : 23,
      "context" : "wireless sensor networks [21], speech recognition [25], stochastic optimization [18], data compression [12], document organization, etc.",
      "startOffset" : 50,
      "endOffset" : 54
    }, {
      "referenceID" : 17,
      "context" : "wireless sensor networks [21], speech recognition [25], stochastic optimization [18], data compression [12], document organization, etc.",
      "startOffset" : 80,
      "endOffset" : 84
    }, {
      "referenceID" : 11,
      "context" : "wireless sensor networks [21], speech recognition [25], stochastic optimization [18], data compression [12], document organization, etc.",
      "startOffset" : 103,
      "endOffset" : 107
    }, {
      "referenceID" : 19,
      "context" : "We can find surveys about this topic in [20, 23, 24, 26, 37].",
      "startOffset" : 40,
      "endOffset" : 60
    }, {
      "referenceID" : 21,
      "context" : "We can find surveys about this topic in [20, 23, 24, 26, 37].",
      "startOffset" : 40,
      "endOffset" : 60
    }, {
      "referenceID" : 22,
      "context" : "We can find surveys about this topic in [20, 23, 24, 26, 37].",
      "startOffset" : 40,
      "endOffset" : 60
    }, {
      "referenceID" : 24,
      "context" : "We can find surveys about this topic in [20, 23, 24, 26, 37].",
      "startOffset" : 40,
      "endOffset" : 60
    }, {
      "referenceID" : 34,
      "context" : "Biclustering has been applied in a wide range of problems, such as image segmentation [36], face clustering [17], image compression [19], genome expression data [5], etc.",
      "startOffset" : 86,
      "endOffset" : 90
    }, {
      "referenceID" : 16,
      "context" : "Biclustering has been applied in a wide range of problems, such as image segmentation [36], face clustering [17], image compression [19], genome expression data [5], etc.",
      "startOffset" : 108,
      "endOffset" : 112
    }, {
      "referenceID" : 18,
      "context" : "Biclustering has been applied in a wide range of problems, such as image segmentation [36], face clustering [17], image compression [19], genome expression data [5], etc.",
      "startOffset" : 132,
      "endOffset" : 136
    }, {
      "referenceID" : 4,
      "context" : "Biclustering has been applied in a wide range of problems, such as image segmentation [36], face clustering [17], image compression [19], genome expression data [5], etc.",
      "startOffset" : 161,
      "endOffset" : 164
    }, {
      "referenceID" : 1,
      "context" : "in [2] for traditional clustering, along with an additional condition proposed by the authors of this work in [32,33] for the overlapping clustering scenario, as the basis for meta-evaluation.",
      "startOffset" : 3,
      "endOffset" : 6
    }, {
      "referenceID" : 30,
      "context" : "in [2] for traditional clustering, along with an additional condition proposed by the authors of this work in [32,33] for the overlapping clustering scenario, as the basis for meta-evaluation.",
      "startOffset" : 110,
      "endOffset" : 117
    }, {
      "referenceID" : 31,
      "context" : "in [2] for traditional clustering, along with an additional condition proposed by the authors of this work in [32,33] for the overlapping clustering scenario, as the basis for meta-evaluation.",
      "startOffset" : 110,
      "endOffset" : 117
    }, {
      "referenceID" : 1,
      "context" : "We do so because the conditions proposed in [2] were shown to subsume the previously existing conditions.",
      "startOffset" : 44,
      "endOffset" : 47
    }, {
      "referenceID" : 26,
      "context" : "For an analogous reason, when treating measures for biclustering, we additionally use the set of conditions proposed by Patrikainen and Meila in [28].",
      "startOffset" : 145,
      "endOffset" : 149
    }, {
      "referenceID" : 1,
      "context" : "Several studies have been conducted on external cluster validation in traditional clustering [2–4, 9, 13, 15, 22, 31, 32, 34].",
      "startOffset" : 93,
      "endOffset" : 125
    }, {
      "referenceID" : 2,
      "context" : "Several studies have been conducted on external cluster validation in traditional clustering [2–4, 9, 13, 15, 22, 31, 32, 34].",
      "startOffset" : 93,
      "endOffset" : 125
    }, {
      "referenceID" : 3,
      "context" : "Several studies have been conducted on external cluster validation in traditional clustering [2–4, 9, 13, 15, 22, 31, 32, 34].",
      "startOffset" : 93,
      "endOffset" : 125
    }, {
      "referenceID" : 8,
      "context" : "Several studies have been conducted on external cluster validation in traditional clustering [2–4, 9, 13, 15, 22, 31, 32, 34].",
      "startOffset" : 93,
      "endOffset" : 125
    }, {
      "referenceID" : 12,
      "context" : "Several studies have been conducted on external cluster validation in traditional clustering [2–4, 9, 13, 15, 22, 31, 32, 34].",
      "startOffset" : 93,
      "endOffset" : 125
    }, {
      "referenceID" : 14,
      "context" : "Several studies have been conducted on external cluster validation in traditional clustering [2–4, 9, 13, 15, 22, 31, 32, 34].",
      "startOffset" : 93,
      "endOffset" : 125
    }, {
      "referenceID" : 20,
      "context" : "Several studies have been conducted on external cluster validation in traditional clustering [2–4, 9, 13, 15, 22, 31, 32, 34].",
      "startOffset" : 93,
      "endOffset" : 125
    }, {
      "referenceID" : 29,
      "context" : "Several studies have been conducted on external cluster validation in traditional clustering [2–4, 9, 13, 15, 22, 31, 32, 34].",
      "startOffset" : 93,
      "endOffset" : 125
    }, {
      "referenceID" : 30,
      "context" : "Several studies have been conducted on external cluster validation in traditional clustering [2–4, 9, 13, 15, 22, 31, 32, 34].",
      "startOffset" : 93,
      "endOffset" : 125
    }, {
      "referenceID" : 32,
      "context" : "Several studies have been conducted on external cluster validation in traditional clustering [2–4, 9, 13, 15, 22, 31, 32, 34].",
      "startOffset" : 93,
      "endOffset" : 125
    }, {
      "referenceID" : 26,
      "context" : "According to Patrikainen and Meila [28], three different approaches have been followed in biclustering validation.",
      "startOffset" : 35,
      "endOffset" : 39
    }, {
      "referenceID" : 0,
      "context" : "On one hand, a number of authors have evaluated biclusterings from the object space perspective only, overlooking information about the feature space [1, 10, 29, 30, 37].",
      "startOffset" : 150,
      "endOffset" : 169
    }, {
      "referenceID" : 9,
      "context" : "On one hand, a number of authors have evaluated biclusterings from the object space perspective only, overlooking information about the feature space [1, 10, 29, 30, 37].",
      "startOffset" : 150,
      "endOffset" : 169
    }, {
      "referenceID" : 27,
      "context" : "On one hand, a number of authors have evaluated biclusterings from the object space perspective only, overlooking information about the feature space [1, 10, 29, 30, 37].",
      "startOffset" : 150,
      "endOffset" : 169
    }, {
      "referenceID" : 28,
      "context" : "On one hand, a number of authors have evaluated biclusterings from the object space perspective only, overlooking information about the feature space [1, 10, 29, 30, 37].",
      "startOffset" : 150,
      "endOffset" : 169
    }, {
      "referenceID" : 33,
      "context" : "While it is called biclustering in [35], it is also referred to as co-clustering [8], subspace clustering [28], (coupled) two-way clustering [7], simultaneous clustering [6], block clustering [16], direct clustering [16], projection/projected/projective clustering [1] and clustering on subsets of attributes [11].",
      "startOffset" : 35,
      "endOffset" : 39
    }, {
      "referenceID" : 7,
      "context" : "While it is called biclustering in [35], it is also referred to as co-clustering [8], subspace clustering [28], (coupled) two-way clustering [7], simultaneous clustering [6], block clustering [16], direct clustering [16], projection/projected/projective clustering [1] and clustering on subsets of attributes [11].",
      "startOffset" : 81,
      "endOffset" : 84
    }, {
      "referenceID" : 26,
      "context" : "While it is called biclustering in [35], it is also referred to as co-clustering [8], subspace clustering [28], (coupled) two-way clustering [7], simultaneous clustering [6], block clustering [16], direct clustering [16], projection/projected/projective clustering [1] and clustering on subsets of attributes [11].",
      "startOffset" : 106,
      "endOffset" : 110
    }, {
      "referenceID" : 6,
      "context" : "While it is called biclustering in [35], it is also referred to as co-clustering [8], subspace clustering [28], (coupled) two-way clustering [7], simultaneous clustering [6], block clustering [16], direct clustering [16], projection/projected/projective clustering [1] and clustering on subsets of attributes [11].",
      "startOffset" : 141,
      "endOffset" : 144
    }, {
      "referenceID" : 5,
      "context" : "While it is called biclustering in [35], it is also referred to as co-clustering [8], subspace clustering [28], (coupled) two-way clustering [7], simultaneous clustering [6], block clustering [16], direct clustering [16], projection/projected/projective clustering [1] and clustering on subsets of attributes [11].",
      "startOffset" : 170,
      "endOffset" : 173
    }, {
      "referenceID" : 15,
      "context" : "While it is called biclustering in [35], it is also referred to as co-clustering [8], subspace clustering [28], (coupled) two-way clustering [7], simultaneous clustering [6], block clustering [16], direct clustering [16], projection/projected/projective clustering [1] and clustering on subsets of attributes [11].",
      "startOffset" : 192,
      "endOffset" : 196
    }, {
      "referenceID" : 15,
      "context" : "While it is called biclustering in [35], it is also referred to as co-clustering [8], subspace clustering [28], (coupled) two-way clustering [7], simultaneous clustering [6], block clustering [16], direct clustering [16], projection/projected/projective clustering [1] and clustering on subsets of attributes [11].",
      "startOffset" : 216,
      "endOffset" : 220
    }, {
      "referenceID" : 0,
      "context" : "While it is called biclustering in [35], it is also referred to as co-clustering [8], subspace clustering [28], (coupled) two-way clustering [7], simultaneous clustering [6], block clustering [16], direct clustering [16], projection/projected/projective clustering [1] and clustering on subsets of attributes [11].",
      "startOffset" : 265,
      "endOffset" : 268
    }, {
      "referenceID" : 10,
      "context" : "While it is called biclustering in [35], it is also referred to as co-clustering [8], subspace clustering [28], (coupled) two-way clustering [7], simultaneous clustering [6], block clustering [16], direct clustering [16], projection/projected/projective clustering [1] and clustering on subsets of attributes [11].",
      "startOffset" : 309,
      "endOffset" : 313
    }, {
      "referenceID" : 25,
      "context" : "other authors only take into account the feature subspace perspective [27].",
      "startOffset" : 70,
      "endOffset" : 74
    }, {
      "referenceID" : 7,
      "context" : "Finally, a third approach consists on evaluating the quality from each perspective separately and merging the partial scores into one final score [8].",
      "startOffset" : 146,
      "endOffset" : 149
    }, {
      "referenceID" : 13,
      "context" : "To overcome this problem, new measures have been proposed which deal with both perspectives in a joint manner [14].",
      "startOffset" : 110,
      "endOffset" : 114
    }, {
      "referenceID" : 8,
      "context" : "Several authors have proposed sets of meta-evaluation conditions for traditional clusterings [9, 22, 34].",
      "startOffset" : 93,
      "endOffset" : 104
    }, {
      "referenceID" : 20,
      "context" : "Several authors have proposed sets of meta-evaluation conditions for traditional clusterings [9, 22, 34].",
      "startOffset" : 93,
      "endOffset" : 104
    }, {
      "referenceID" : 32,
      "context" : "Several authors have proposed sets of meta-evaluation conditions for traditional clusterings [9, 22, 34].",
      "startOffset" : 93,
      "endOffset" : 104
    }, {
      "referenceID" : 1,
      "context" : "A set of four conditions is proposed in [2] which subsumes those previously existing.",
      "startOffset" : 40,
      "endOffset" : 43
    }, {
      "referenceID" : 30,
      "context" : "An additional condition was proposed in [32, 33] to account for special situations arising in overlapping clusterings.",
      "startOffset" : 40,
      "endOffset" : 48
    }, {
      "referenceID" : 31,
      "context" : "An additional condition was proposed in [32, 33] to account for special situations arising in overlapping clusterings.",
      "startOffset" : 40,
      "endOffset" : 48
    }, {
      "referenceID" : 1,
      "context" : "1- Homogeneity [2]: Let C be a gold standard and let G1 be a clustering where one cluster Gk contains objects belonging to two classes Ci, Cj ∈ C.",
      "startOffset" : 15,
      "endOffset" : 18
    }, {
      "referenceID" : 1,
      "context" : "2- Completeness [2]: Let C be a gold standard and let G1 be a clustering where two clusters G1 and G2 contain only objects belonging to one class Ck ∈ C.",
      "startOffset" : 16,
      "endOffset" : 19
    }, {
      "referenceID" : 1,
      "context" : "3- Rag Bag [2]: Let C be a gold standard.",
      "startOffset" : 11,
      "endOffset" : 14
    }, {
      "referenceID" : 1,
      "context" : "4- Clusters size versus quantity [2]: Let C be a gold standard.",
      "startOffset" : 33,
      "endOffset" : 36
    }, {
      "referenceID" : 30,
      "context" : "5- Perfect match [32, 33]: An evaluation measure must yield the optimum score for a candidate clustering if and only if it is identical to the gold standard.",
      "startOffset" : 17,
      "endOffset" : 25
    }, {
      "referenceID" : 31,
      "context" : "5- Perfect match [32, 33]: An evaluation measure must yield the optimum score for a candidate clustering if and only if it is identical to the gold standard.",
      "startOffset" : 17,
      "endOffset" : 25
    }, {
      "referenceID" : 26,
      "context" : "Regarding biclustering algorithms, a set of five conditions are presented in [28] which describe what is considered as a good behavior, so good evaluation measures are expected to reward algorithms that exhibit such behavior.",
      "startOffset" : 77,
      "endOffset" : 81
    }, {
      "referenceID" : 26,
      "context" : "Patrikainen and Meila [28] propose to transform the candidate biclustering and the gold standard into traditional clusterings in order to apply existing evaluation measures for the latter.",
      "startOffset" : 22,
      "endOffset" : 26
    }, {
      "referenceID" : 13,
      "context" : "[14] propose to combine the microobjects transformation and a variant of the F1 measure called E4SC.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 1,
      "context" : "[2] show that Rand’s index and VI do not satisfy the Rag Bag (A.",
      "startOffset" : 0,
      "endOffset" : 3
    }, {
      "referenceID" : 0,
      "context" : "Since CE and RNIA are defined as dissimilarities in the range [0, 1], in both cases we transform the scores into similarity values by making fsim(G̈, C̈) = 1− fdissim(G̈, C̈).",
      "startOffset" : 62,
      "endOffset" : 68
    }, {
      "referenceID" : 30,
      "context" : "3 Our proposal The basis of our new proposal is the measure CICE-BCubed F1, which was presented in [32, 33] for traditional clusterings, with an emphasis on adequately handling the occurrence of overlapping clusters.",
      "startOffset" : 99,
      "endOffset" : 107
    }, {
      "referenceID" : 31,
      "context" : "3 Our proposal The basis of our new proposal is the measure CICE-BCubed F1, which was presented in [32, 33] for traditional clusterings, with an emphasis on adequately handling the occurrence of overlapping clusters.",
      "startOffset" : 99,
      "endOffset" : 107
    }, {
      "referenceID" : 3,
      "context" : "CICE-BCubed F1 is based on BCubed F1 [4].",
      "startOffset" : 37,
      "endOffset" : 40
    } ],
    "year" : 2017,
    "abstractText" : "The validation of biclustering algorithms remains a challenging task, even though a number of measures have been proposed for evaluating the quality of these algorithms. Although no criterion is universally accepted as the overall best, a number of meta-evaluation conditions to be satisfied by biclustering algorithms have been enunciated. In this work, we present MOCICE-BCubed F1, a new external measure for evaluating biclusterings, in the scenario where gold standard annotations are available for both the object clusters and the associated feature subspaces. Our proposal relies on the so-called micro-objects transformation and satisfies the most comprehensive set of meta-evaluation conditions so far enunciated for biclusterings. Additionally, the proposed measure adequately handles the occurrence of overlapping in both the object and feature spaces. Moreover, when used for evaluating traditional clusterings, which are viewed as a particular case of biclustering, the proposed measure also satisfies the most comprehensive set of meta-evaluation conditions so far enunciated for this task.",
    "creator" : "LaTeX with hyperref package"
  }
}