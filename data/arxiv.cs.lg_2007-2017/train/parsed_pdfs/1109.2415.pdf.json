{
  "name" : "1109.2415.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "Convergence Rates of Inexact Proximal-Gradient Methods for Convex Optimization",
    "authors" : [ "Mark Schmidt", "Nicolas Le Roux" ],
    "emails" : [ "mark.schmidt@inria.fr", "nicolas@le-roux.name", "francis.bach@ens.fr" ],
    "sections" : [ {
      "heading" : "1 Introduction",
      "text" : "In recent years the importance of taking advantage of the structure of convex optimization problems has become a topic of intense research in the machine learning community. This is particularly true of techniques for non-smooth optimization, where taking advantage of the structure of non-smooth terms seems to be crucial to obtaining good performance. Proximal-gradient methods and accelerated proximal-gradient methods [1, 2] are among the most important methods for taking advantage of the structure of many of the nonsmooth optimization problems that arise in practice. In particular, these methods address composite optimization problems of the form\nminimize x∈Rd f(x) := g(x) + h(x), (1)\nwhere g and h are convex functions but only g is smooth. One of the most well-studied instances of this type of problem is `1-regularized least squares [3, 4],\nminimize x∈Rd\n‖Ax− b‖2 + λ‖x‖1,\nar X\niv :1\n10 9.\n24 15\nv1 [\ncs .L\nG ]\nwhere we use ‖ · ‖ to denote the standard `2 norm.\nProximal-gradient methods are an appealing approach for solving these types of non-smooth optimization problems because of their fast theoretical convergence rates and strong practical performance. While classical subgradient methods only achieve an error level on the objective function of O(1/ √ k) after k iterations, proximal-gradient methods have an error of O(1/k) while accelerated proximal-gradient methods futher reduce this to O(1/k2) [1, 2]. That is, accelerated proximal-gradient methods for non-smooth convex optimization achieve the same optimal convergence rate that accelerated gradient methods achieve for smooth optimization.\nEach iteration of a proximal-gradient method requires the calculation of the proximity operator,\nproxL(y) = arg min x∈Rd\nL 2 ‖x− y‖2 + h(x), (2)\nwhere L is the Lipschitz constant of the gradient of g. We can efficiently compute an analytic solution to this problem for several notable choices of h, including the case of `1-regularization and disjoint group `1-regularization [5, 6]. However, in many scenarios the proximity operator may not have an analytic solution, or it may be very expensive to compute this solution exactly. This includes important problems such as total-variation regularization and its generalizations like the graph-guided fused-LASSO [7, 8], nuclearnorm regularization and other regularizers on the singular values of matrices [9, 10], and different formulations of overlapping group `1-regularization with general groups [11, 12]. Despite the difficulty in computing the exact proximity operator for these regularizers, efficient methods have been developed to compute approximate proximity operators in all of these cases; accelerated projected gradient and Newton-like methods that work with a smooth dual problem have been used to compute approximate proximity operators in the context of total-variation regularization [7, 13], Krylov subspace methods and low-rank representations have been used to compute approximate proximity operators in the context of nuclear-norm regularization [9, 10], and variants of Dykstra’s algorithm (and related dual methods) have been used to compute approximate proximity operators in the context of overlapping group `1-regularization [12, 14, 15].\nIt is known that proximal-gradient methods that use an approximate proximity operator converge under only weak assumptions [16, 17]; we briefly review this and other related work in the next section. However, despite the many recent works showing impressive empirical performance of (accelerated) proximal-gradient methods that use an approximate proximity operator [7, 13, 9, 10, 14, 15], we are not aware of any theoretical analysis on how the error in the calculation of the proximity operator affects the convergence rate of proximal-gradient methods. In this work we show in several contexts that, provided the error in the proximity operator calculation is controlled in an appropriate way, inexact proximal-gradient strategies achieve the same convergence rates as the corresponding exact methods. In particular, we first consider convex objectives and analyze the inexact proximal-gradient (Section 4.1) and accelerated proximal-gradient methods (Section 4.2). We then analyze these two algorithms for strongly convex objectives (Sections 4.3 and 4.4). Note that in these analyses, we also consider the possibility that there is an error in the calculation of the gradient of g. We\nthen present an experimental comparison of various inexact proximal-gradient strategies in the context of solving a structured sparsity problem (Section 5)."
    }, {
      "heading" : "2 Related Work",
      "text" : "The algorithm we shall focus on in this paper is the proximal-gradient method\nxk = proxL(yk−1 − (1/L)(g′(yk−1) + ek)) , (3)\nwhere ek is the error in the calculation of the gradient and the proximity problem (2) is solved inexactly so that xk has an error of εk in terms of the proximal objective function (2). In the basic proximal-gradient method we choose yk = xk, while in the accelerated proximalgradient method we choose\nyk = xk + βk(xk − xk−1),\nwhere the sequence {βk} is chosen in order yield an improved convergence rate.\nThere is a substantial amount of work on methods that use an exact proximity operator but have an error in the gradient calculation, corresponding to the special case where εk = 0 but ek is non-zero. For example, when the ek are independent, zero-mean, and finitevariance random variables then proximal-gradient methods achieve the (optimal) error level of O(1/ √ k) [18, 19]. This is different than the scenario we analyze in this paper, since we do not assume that the errors are unbiased and independent, but instead consider a sequence of errors converging to 0. This leads to faster convergence rates, and makes our analysis applicable to the case of deterministic (and even adversarial) errors.\nSeveral authors have recently analyzed the case of a fixed deterministic error in the gradient, and shown that accelerated gradient methods achieve the optimal convergence rate up to some accuracy that depends on the fixed error level [20, 21, 22], while the earlier work of [23] analyzes the gradient method in the context of a fixed error level. This contrasts with our analysis, where by allowing the error to change on every iteration we can achieve convergence to the optimal solution. Also, we can tolerate a large error in early iterations when we are far from the solution, which may lead to substantial computational gains. Other authors have analyzed the convergence rate of the gradient and projected-gradient methods with a decreasing sequence of errors [24, 25], but this analysis does not consider the important class of accelerated gradient methods. In contrast, the analysis of [22] allows a decreasing sequence of errors without assuming strong convexity (though convergence rates in this context are not explicitly mentioned) and considers the accelerated projectedgradient method. However, the authors of this work only consider the case of an exact projection step, and they assume the availability of an oracle that yields global lower and upper bounds on the function. This non-intuitive oracle leads to a novel analysis of smoothing methods, but leads to slower convergence rates than proximal-gradient methods. The analysis of [21] considers errors in both the gradient and projection operators for accelerated projected-gradient methods, but this analysis requires that the domain of the function is compact. None of these works consider proximal-gradient methods.\nIn the context of proximal-point algorithms, there is a substantial literature on using inexact proximity operators with a decreasing sequence of errors, dating back to the seminal work of Rockafeller [26]. Accelerated proximal-point methods with a decreasing sequence of errors have also been examined, beginning with [27]. However, unlike proximal-gradient methods where the proximity operator is computed with respect to the non-smooth function h, proximal-point methods require the calculation of the proximity operator with respect to the full objective function. In the context of composite optimization problems of the form (1), this requires the calculation of the proximity operator with respect to g+h. Since it ignores the structure of the problem, this proximity operator will typically be as difficult to compute (even approximately) as the minimizer of the original problem.\nConvergence of inexact proximal-gradient methods can be established with only weak assumptions on the method used to approximately solve (2). For example, we can establish that inexact proximal-gradient methods converge under some minor closedness assumptions on the mapping induced by the approximate proximity operator, and the assumption that the algorithm used to compute the inexact proximity operator achieves sufficient descent on problem (2) compared to the previous iteration xk−1 [16]. Convergence of inexact proximalgradient methods can also be established under the assumption that the norms of the errors are summable [17]. However, these prior works did not consider the rate of convergence of inexact proximal-gradient methods, nor did they consider accelerated proximal-gradient methods. Indeed, as pointed out by [7], even convergence of the accelerated proximalgradient method has not been established under an inexact proximity operator. This gap in the theory is one of the reasons why the authors of [7] chose to use the non-accelerated variant of the proximal-gradient algorithm."
    }, {
      "heading" : "3 Notation and Assumptions",
      "text" : "In this work we shall assume that the smooth function g in (1) is convex and differentiable, and we will assume that its gradient g′ is Lipschitz-continuous with constant L, meaning that for all x and y in Rd we have\n‖g′(x)− g′(y)‖ 6 L‖x− y‖ .\nThis is a standard assumption in differentiable optimization, see [28, §2.1.1]. If g is twicedifferentiable, this corresponds to the assumption that the eigenvalues of its Hessian are bounded above by L. For the proofs in Sections 4.3 and 4.4, we will also assume that g is µ-strongly convex (see [28, §2.1.3]), meaning that for all x and y in Rd we have\ng(y) > g(x) + 〈g′(x), y − x〉+ µ 2 ||y − x||2.\nHowever, apart from the Sections 4.3 and 4.4, we only assume that this holds with µ = 0, which is equivalent to convexity of g.\nIn contrast to these assumptions on g, we will only assume that h in (1) is a lower semicontinuous proper convex function (see [29, §1.2]), but will not assume that h is differentiable or Lipschitz-continuous. This allows h to be any real-valued convex function, but also allows\nfor the possibility that h is an extended real-valued convex function. For example, h could be the indicator function of a convex set, and in this case the proximity operator becomes the projection operator.\nWe will use xk to denote the parameter vector at iteration k, and x ∗ to denote a minimizer of f . We assume that such an x∗ exists, but do not assume that it is unique. We use ek to denote the error in the calculation of the gradient at iteration k, and we use εk to denote the error in the proximal objective function achieved by xk, meaning that\nL 2 ‖xk − y‖2 + h(xk) 6 εk + min x∈Rd\n{ L\n2 ‖x− y‖2 + h(x)\n} . (4)\nwhere y = yk−1 − (1/L)(g′(yk−1) + ek)). In practice, our framework requires such a bound on the optimality of the approximate proximity operator. However, note that the proximal optimization problem (2) is strongly convex and in practice we are often able to obtain such bounds via a duality gap (e.g., see [12] for the case of overlapping group `1-regularization)."
    }, {
      "heading" : "4 Convergence Rates of Inexact Proximal-Gradient Methods",
      "text" : "In this section we present the analysis of the convergence rates of inexact proximal-gradient methods as a function of the sequences of solution accuracies to the proximal problems {εk}, and the sequences of magnitudes of the errors in the gradient calculations {‖ek‖}."
    }, {
      "heading" : "4.1 Basic proximal-gradient method with errors in the convex case",
      "text" : "We first consider the basic proximal-gradient method in the convex case:\nProposition 1 (Basic proximal-gradient method with errors - Convexity) Assume that\n• g is convex and has L-Lipschitz-continuous gradient;\n• h is a lower semi-continuous proper convex function;\n• The function f = g + h attains its minimum at a certain x∗ ∈ Rn;\n• We iterate recursion (3) with yk = xk;\n• xk is an εk-optimal solution to the proximal problem (2) in the sense of (4).\nThen, for all k > 1, we have\nf\n( 1\nk k∑ i=1 xi\n) − f(x∗) 6 L\n2k\n( ‖x0 − x∗‖+ 2Ak + √ 2Bk )2 , (5)\nwith\nAk = k∑ i=1 ( ‖ei‖ L + √ 2εi L ) , Bk = k∑ i=1 εi L .\nThe proof is given in the Appendix. Note that while we have stated the proposition in terms of the function value achieved by the average of the iterates, it trivially also holds for the iteration that achieves the lowest function value. Note, however, that the convergence of the iterates themselves is not possible in general since there may be multiple minima.\nThis result implies that the well-known O(1/k) convergence rate for the gradient method without errors still holds when both {‖ek‖} and { √ εk} are summable. A sufficient condition to achieve this is that ‖ek‖ decreases as O(1/k1+δ) while εk decreases as O(1/k2+δ ′ ) for any δ, δ′ > 0. Note that a faster convergence of these two errors will not improve the convergence rate, but will yield a better constant factor. It is interesting to consider what happens if {‖ek‖} or { √ εk} is not summable. For instance, if ‖ek‖ and √ εk decrease as O(1/k), then Ak grows as O(log k) (note that Bk is always\nsmaller than Ak) and the convergence of the function values is in O ( log2 k k ) . Finally, a necessary condition to obtain convergence is that the partial sums Ak and Bk need to be in o( √ k)."
    }, {
      "heading" : "4.2 Accelerated proximal-gradient method with errors in the convex case",
      "text" : "We now turn to the case of accelerated proximal-gradient methods in the convex case. We focus on a basic variant of the algorithm where βk is set to (k − 1)/(k + 2) [30]:\nProposition 2 (Accelerated proximal-gradient method with errors) Assume that\n• g is convex and has L-Lipschitz-continuous gradient;\n• h is a lower semi-continuous proper convex function;\n• The function f = g + h attains its minimum at a certain x∗ ∈ Rn;\n• We iterate recursion (3) with yk = xk + k−1k+2(xk − xk−1);\n• xk is an εk-optimal solution to the proximal problem (2) in the sense of (4).\nThen, for all k > 1, we have\nf(xk)− f(x∗) 6 2L\n(k + 1)2\n( ‖x0 − x∗‖+ 2Ãk + √ 2B̃k )2 , (6)\nwith\nÃk = k∑ i=1 i ( ‖ei‖ L + √ 2εi L ) , B̃k = k∑ i=1 i2εi L .\nIn this case, we require the series {k‖ek‖} and {k √ εk} to be summable to achieve the optimal O(1/k2) rate, which is an (unsurprisingly) stronger constraint than in the basic case. A sufficient condition is for ‖ek‖ and √ εk to decrease as O(1/k\n2+δ) for any δ > 0. Note that, as opposed to Proposition 1 that is stated for the average iterate, this bound is for the last iterate xk.\nOnce again, it is interesting to see what happens when the summability assumption is not met. First, if ‖ek‖ or √ εk decreases at a rate of O(1/k 2), then k(‖ek‖ + √ ek) decreases as O(1/k) and Ãk grows as O(log k) (note that B̃k is always smaller than Ãk), yielding\na convergence rate of O ( log2 k k2 ) for f(xk) − f(x∗). Also, and perhaps more interestingly, if ‖ek‖ or √ εk decreases at a rate of O(1/k), Eq. (6) does not guarantee convergence of the function values. More generally, the form of Ãk and B̃k indicates that errors have a greater effect on the accelerated method than they do on the basic method. Hence, as also discussed in [22], unlike in the error-free case the accelerated method may not necessarily be better than the basic method because it is more sensitive to errors in the computation."
    }, {
      "heading" : "4.3 Basic proximal-gradient method with errors in the strongly convex case",
      "text" : "In the case where g is strongly convex it is possible to obtain linear convergence rates that depend on the ratio\nγ = µ\nL ,\nas opposed to the sublinear convergence rates discussed above. In particular, we obtain the following convergence rate on the iterates of the basic proximal-gradient method for strongly convex objectives:\nProposition 3 (Basic proximal-gradient method with errors - Strong convexity) Assume that\n• g is µ-strongly convex and has L-Lipschitz-continuous gradient;\n• h is a lower semi-continuous proper convex function;\n• The function f = g + h attains its minimum at a certain x∗ ∈ Rn;\n• We iterate recursion (3) with yk = xk;\n• xk is an εk-optimal solution to the proximal problem (2) in the sense of (4).\nThen, for all k > 1, we have:\n‖xk − x∗‖ 6 (1− γ)k (‖x0 − x∗‖+ Āk) , (7)\nwith\nĀk = k∑ i=1 (1− γ)−i ( ‖ei‖ L + √ 2εi L ) .\nA consequence of this proposition is that we obtain a linear rate of convergence even in the presence of errors, provided that ‖ek‖ and √ εk decrease linearly to 0. If they do so at a rate of Q′ < (1− γ), then the convergence rate of ‖xk −x∗‖ is linear with constant (1− γ), as in the error-free algorithm. If we have Q′ > (1− γ), then the convergence of ‖xk − x∗‖ will be linear with constant Q′. If we have Q′ = (1− γ), then ‖xk − x∗‖ converges to 0 as O(k (1− γ)k) = o ( [(1− γ) + δ′]k ) for all δ′ > 0."
    }, {
      "heading" : "4.4 Accelerated proximal-gradient method with errors in the strongly convex case",
      "text" : "Finally, we consider the accelerated proximal-gradient algorithm when g is strongly convex. We focus on a basic variant of the algorithm where βk is set to (1 − √ γ)/(1 + √ γ) [28, §2.2.1]:\nProposition 4 (Accelerated proximal-gradient method with errors - Strong convexity) Assume that\n• g is µ-strongly convex and has L-Lipschitz-continuous gradient;\n• h is a lower semi-continuous proper convex function;\n• The function f = g + h attains its minimum at a certain x∗ ∈ Rn; • We iterate recursion (3) with yk = xk + 1−√γ 1+ √ γ (xk − xk−1);\n• xk is an εk-optimal solution to the proximal problem (2) in the sense of (4).\nThen, for all k > 1, we have\nf(xk)− f(x∗) 6 (1− √ γ)k (√ 2(f(x0)− f(x∗)) +Ak √ 2 µ + √ Bk )2 , (8)\nwith\nAk = k∑ i=1 ( ‖ei‖+ √ 2Lεi ) (1−√γ)−i/2 ,\nBk = k∑ i=1 εi (1− √ γ)−i .\nThis proposition implies that we obtain a linear rate of convergence in the presence of errors provided that ||ek||2 and εk decrease linearly to 0. If they do so at a rate Q′ < (1 − √ γ), then the constant is (1−√γ), while if Q′ > (1−√γ) then the constant will be Q′. Thus, the accelerated inexact proximal-gradient method will have a faster convergence rate than the exact basic proximal-gradient method provided that Q′ < (1− γ).\nOddly, in our analysis of the strongly convex case, the accelerated method is less sensitive to errors than the basic method. However, unlike the basic method, the accelerated method requires knowing µ in addition to L. If µ is misspecified, then the convergence rate of the accelerated method may be slower than the basic method."
    }, {
      "heading" : "5 Experiments",
      "text" : "We tested the basic inexact proximal-gradient and accelerated proximal-gradient methods on the CUR-like factorization optimization problem introduced in [31] to approximate a\ngiven matrix W ,\nmin X\n1 2‖W −WXW‖ 2 F + λrow nr∑ i=1 ||Xi||p + λcol nc∑ j=1 ||Xj ||p .\nUnder an appropriate choice of p, this optimization problem yields a matrix X with sparse rows and sparse columns, meaning that entire rows and columns of the matrix X are set to exactly zero. In [31], the authors used an accelerated proximal-gradient method and chose p = ∞ since under this choice the proximity operator can be computed exactly. However, this has the undesirable effect that it also encourages all values in the same row (or column) to have the same magnitude. The more natural choice of p = 2 was not explored since in this case there is no known algorithm to exactly compute the proximity operator.\nOur experiments focused on the case of p = 2. In this case, it is possible to very quickly compute an approximate proximity operator using the block coordinate descent (BCD) algorithm presented in [12], which is equivalent to the proximal variant of Dykstra’s algorithm introduced by [32]. In our implementation of the BCD method, we alternate between computing the proximity operator with respect to the rows and to the columns. Since the BCD method allows us to compute a duality gap when solving the proximal problem, we can run the method until the duality gap is below a given error threshold εk to find an xk+1 satisfying (4).\nIn our experiments, we used the four data sets examined by [31]1 and we choose λrow = .01 and λcol = .01, which yielded approximately 25–40% non-zero entries in X (depending on the data set). Rather than assuming we are given the Lipschitz constant L, on the first iteration we set L to 1 and we double our estimate of L anytime f(xk+1) > f(yk). This rudimentary linesearch will always terminate for sufficiently large L because of the Lipschitz-continuity of g, provided that the BCD method returns a solution with error εk lower than the error obtained at yk. We tested three different ways to terminate the approximate proximal problem, each parameterized by a parameter α:\n• εk = 1/kα: Running the BCD algorithm until the duality gap is below 1/kα.\n• εk = α: Running the BCD algorithm until the duality gap is below α.\n• n = α: Running the BCD algorithm for a fixed number of iterations α.\nNote that all three strategies lead to global convergence in the case of the basic proximalgradient method, the first two give a convergence rate up to some fixed optimality tolerance, and in this paper we have shown that the first one (for large enough α) yields a convergence rate for an arbitrary optimality tolerance. Note that the iterates produced by the BCD iterations are sparse, so we expected the algorithms to spend the majority of their time solving the proximity problem. Thus, we used the function value against the number of BCD iterations as a measure of performance. We plot the results after 500 BCD iterations for the proximal-gradient method in Figure 1, and the accelerated proximal-gradient method\n1The datasets are freely available at http://www.gems-system.org.\nin Figure 2. In these plots, the first column varies α using the choice εk = 1/k α, the second column varies α using the choice εk = α, and the third column varies α using the choice n = α. We also include one of the best methods from the first column in the second and third columns as a reference.\nIn the context of proximal-gradient methods the choice of εk = 1/k 3, which is one choice that achieves the fastest convergence rate according to our analysis, gives the best performance across all four data sets. However, in these plots we also see that reasonable performance can be achieved by any of the three strategies above provided that α is chosen carefully. For example, choosing n = 3 or choosing εk = 10\n−6 both give reasonable performance. However, these are only empirical observations for these data sets and they may be ineffective for other data sets or if we change the number of iterations, while we have given theoretical justification for the choice εk = 1/k 3.\nSimilar trends are observed for the case of accelerated proximal-gradient methods, though the choice of εk = 1/k\n3 (which no longer achieves the fastest convergence rate according to our analysis) no longer dominates the other methods in the accelerated setting. For two data sets the choice εk = 1/k\n4, which is a choice that achieves the fastest convergence rate up to a poly-logarithmic factor, yields better performance than εk = 1/k\n3. Interestingly, the only choice that yields the fastest possible convergence rate (εk = 1/k\n5), did not give the best performance on any data set. This seems to reflect the trade-off between performing inner BCD iterations to achieve a small duality gap and performing outer gradient iterations to decrease the value of f . Also, the constant terms which were not taken into account in the analysis do play an important role here, due to the relatively small number of outer iterations performed."
    }, {
      "heading" : "6 Discussion",
      "text" : "An alternative to inexact proximal methods for solving structured sparsity problems are smoothing methods [33] and alternating direction methods [34]. However, a major disadvantage of both these approaches is that the iterates are not sparse, so they can not take advantage of the sparsity of the problem when running the algorithm. In contrast, the method proposed in this paper has the appealing property that it tends to generate sparse iterates. Further, the accelerated smoothing method only has a convergence rate of O(1/k), and the performance of alternating direction methods is often sensitive to the exact choice of their penalty parameter. On the other hand, while our analysis suggests using a sequence of errors like O(1/kα) for α large enough, the practical performance of inexact proximal-gradients methods will be sensitive to the exact choice of this sequence.\nAlthough we have illustrated the use of our results in the context of a structured sparsity problem, inexact proximal-gradient methods are also used in other applications such as total-variation [7, 8] and nuclear-norm [9, 10] regularization. This work provides a theoretical justification for using inexact proximal-gradient methods in these and other applications, and suggests some guidelines for practioners that do not want to lose the appealing convergence rates of these methods. Further, although our experiments and much of our discussion\nfocus on errors in the calculation of the proximity operator, our analysis also allows for an error in the calculation of the gradient. This may also be useful in a variety of contexts. For example, errors in the calculation of the gradien arise when fitting undirected graphical models and using an iterative method to approximate the gradient of the log-partition function [35]. Other examples include using a reduced set of training examples within kernel methods [36], or subsampling to solve semidefinite programming problems [37].\nIn our analysis we assume that L is known, and our experiments use a heuristic to estimate L. It would be interesting to extend methods for estimating L in the exact case [2] to the case of inexact algorithms. In the context of accelerated methods for strongly convex optimization, our analysis also assumes that µ is known, and it would be interesting to explore variants that do not make this assumption. Finally, we note that there has been recent interest in inexact proximal Newton-like methods [38], and it would be interesting to analyze the effect of errors on the convergence rates of these methods."
    }, {
      "heading" : "Acknowledgements",
      "text" : "Mark Schmidt, Nicolas Le Roux, and Francis Bach are supported in part by the European Research Council (SIERRA-ERC-239993)."
    }, {
      "heading" : "Appendix: Proofs of the propositions",
      "text" : "We first prove a lemma which will be used for the propositions.\nLemma 1 Assume that the nonnegative sequence uk satisfies the following recursion for all k > 1:\nu2k 6 Bk + k∑ i=1 λiui,\nwith {Bk} an increasing sequence, B0 > u20 and λi > 0 for all i. Then, for all k > 1, then\nuk 6 1\n2 k∑ i=1 λi +\nBk + ( 1\n2 k∑ i=1 λi\n)21/2\nProof We prove the result by induction. It is true for k = 0 (by assumption). We assume it is true for k − 1, and we denote by vk−1 = max{u1, . . . , uk−1}. From the recursion, we thus get\n(uk − λk/2)2 6 Bk + λ2k 4 + vk−1 k−1∑ i=1 λi\nleading to\nuk 6 λk 2 +\n( Bk +\nλ2k 4 + vk−1 k−1∑ i=1 λi\n)1/2\nand thus\nvk 6 max { vk−1,\nλk 2 +\n( Bk +\nλ2k 4 + vk−1 k−1∑ i=1 λi )1/2 } The two terms in the maximum are equal if v2k−1 = Bk + vk−1 ∑k i=1 λi, i.e., for v ∗ k−1 =\n1 2 ∑k i=1 λi + ( Bk + ( 1 2 ∑k i=1 λi )2)1/2 . If vk−1 6 v∗k−1, then vk 6 v ∗ k−1 since the two terms in the max are increasing functions of vk−1. If vk−1 > v∗k−1, then vk−1 > λk 2 +(\nBk + λ2k 4 + vk−1 ∑k−1 i=1 λi )1/2 . Hence, vk 6 vk−1, and the induction hypotheses ensure that\nthe property is satisfied for k.\nThe following lemma will allow us to characterize the elements of the εk-subdifferential of h at xk, ∂εkh(xk).\nLemma 2 If xi is an εi-optimal solution to the proximal problem (2) in the sense of (4), then there exists fi such that ‖fi‖ 6 √ 2εi L and\nL ( yi−1 − xi − 1\nL (g′(yi−1) + ei)− fi\n) ∈ ∂εih(xi) .\nProof We first recall some properties of ε-subdifferentials (see, e.g., [39, Section 4.3] for more details). By definition, x is an ε-minimizer of a convex function a if and only if a(x) 6 infy∈Rn a(y) + ε. This is equivalent to 0 belonging to the ε-subdifferential ∂εa(x). If a = a1 + a2, where both a1 and a2 are convex, we have ∂εa(x) ⊂ ∂εa1(x) + ∂εa2(x).\nIf a1(x) = L 2 ‖x− z‖ 2, then\n∂εa1(x) =\n{ y ∈ Rn ∣∣∣∣ L2 ‖x− z − yL‖2 6 ε }\n= { y ∈ Rn, y = Lx− Lz + Lf ∣∣∣∣ L2 ‖f‖2 6 ε } .\nIf a2 = h and x is an ε-minimizer of a1 + a2, then 0 belongs to ∂εa(x). Since ∂εa(x) ⊂ ∂εa1(x) + ∂εa2(x), we have that\nLz − Lx− Lf ∈ ∂εh(x) with ‖f‖ 6 √ 2ε\nL .\nUsing z = yi−1 − (1/L)(g′(yi−1) + ei and x = xi, this implies that there exists fi such that ‖fi‖ 6 √ 2εi L and\nL ( xi−1 − xi − 1\nL (g′(xi−1) + ei)− fi\n) ∈ ∂εih(xi) ."
    }, {
      "heading" : "6.1 Basic proximal-gradient method with errors in the convex case",
      "text" : "We now give the proof of Proposition of 1.\nProof Since xk is an εk-optimal solution to the proximal problem (2) in the sense of (4), we can use Lemma 2 to yield that there exists fk such that ‖fk‖ 6 √ 2εk L and\nL ( xk−1 − xk − 1\nL (g′(xk−1) + ek)− fk\n) ∈ ∂εih(xk) .\nWe now bound g(xi) and h(xi) as follows:\ng(xi) 6 g(xi−1) + 〈 g′(xi−1), xi − xi−1 〉 + L\n2 ‖xi − xi−1‖2\nusing L-Lipschitz gradient and the convexity of g, 6 g(x∗) + 〈 g′(xi−1), xi−1 − x∗ 〉 + 〈 g′(xi−1), xi − xi−1 〉 + L\n2 ‖xi − xi−1‖2\nusing convexity of g.\nUsing the εi-subgradient, we have\nh(xi) 6 h(x ∗)− 〈 g′(xi−1) + ei + L(xi + fi − xi−1), xi − x∗ 〉 + εi .\nAdding the two together, we get:\nf(xi) = g(xi) + h(xi)\n= f(x∗) + L\n2 ‖xi − xi−1‖2 − L 〈xi − xi−1, xi − x∗〉+ εi − 〈ei + Lfi, xi − x∗〉\n= f(x∗) + L\n2 〈xi − xi−1, xi − xi−1 − 2xi + 2x∗〉+ εi − 〈ei + Lfi, xi − x∗〉\n= f(x∗) + L\n2 〈xi − x∗ − (xi−1 − x∗), (x∗ − xi) + (x∗ − xi−1)〉+ εi − 〈ei + Lfi, xi − x∗〉\n= f(x∗)− L 2 ‖xi − x∗‖2 + L 2 ‖xi−1 − x∗‖2 + εi − 〈ei + Lfi, xi − x∗〉\nf(xi) 6 f(x ∗)− L 2 ‖xi − x∗‖2 + L 2 ‖xi−1 − x∗‖2 + εi + (‖ei‖+\n√ 2Lεi) · ‖xi − x∗‖\nusing Cauchy-Schwartz and ‖fi‖ 6 √ 2εi L .\nMoving f(x∗) on the other side and summing from i = 1 to k, we get: k∑ i=1 [f(xi)−f(x∗)] 6 − L 2 ‖xk−x∗‖2+ L 2 ‖x0−x∗‖2+ k∑ i=1 εi+ k∑ i=1 [ (‖ei‖+ √ 2Lεi) · ‖xi − x∗‖ ] ,\ni.e. k∑ i=1 [f(xi)− f(x∗)] + L 2 ‖xk − x∗‖2 6 L 2 ‖x0 − x∗‖2 + k∑ i=1 εi + k∑ i=1 [ (‖ei‖+ √ 2Lεi) · ‖xi − x∗‖ ] .\n(9)\nEq. (9 has two purposes. The first one is to bound the values of ‖xi−x∗‖ using the recursive definition. Once we have a bound on these quantities, we shall be able to bound the function values using only ‖x0 − x∗‖ and the values of the errors."
    }, {
      "heading" : "6.1.1 Bounding ‖xi − x∗‖",
      "text" : "We now need to bound the quantities ‖xi − x∗‖ in terms of ‖x0 − x∗‖, ei and εi. Dropping the first term in Eq. (9), which is positive due to the optimality of f(x∗), we have:\n‖xk − x∗‖2 6 ‖x0 − x∗‖2 + 2\nL k∑ i=1 εi + 2 k∑ i=1 [( ‖ei‖ L + √ 2εi L ) · ‖xi − x∗‖ ]\nWe may now use Lemma 1 (using A = ‖x0 − x∗‖2 + 2L ∑k i=1 εi and λi = 2( ‖ei‖ L + √ 2εi L ) to get ‖xk−x∗‖ 6 k∑ i=1 ( ‖ei‖ L + √ 2εi L ) + ‖x0 − x∗‖2 + 2 L k∑ i=1 εi + [ k∑ i=1 ( ‖ei‖ L + √ 2εi L\n)]21/2 . Denoting Ak = ∑k i=1 ( ‖ei‖ L + √ 2εi L ) and Bk = ∑k i=1 εi L , we get\n‖xk − x∗‖ 6 Ak + ( ‖x0 − x∗‖2 + 2Bk +A2k )1/2 .\nSince Ai and Bi are increasing sequences (‖ei‖ and εi being positive), we have for i 6 k\n‖xi − x∗‖ 6 Ai + ( ‖x0 − x∗‖2 + 2Bi +A2i )1/2 6 Ak + ( ‖x0 − x∗‖2 + 2Bk +A2k\n)1/2 6 Ak + ‖x0 − x∗‖+ √ 2Bk +Ak\nusing the positivity of ‖x0 − x∗‖2, Bk and A2k."
    }, {
      "heading" : "6.1.2 Bounding the function values",
      "text" : "Now that we have a common bound for all ‖xi − x∗‖ with i 6 k, we can upper-bound the right-hand side of Eq. (9) using only terms depending on ‖x0 − x∗‖, ei and εi. Indeed, discarding L2 ‖xk − x ∗‖2 which is positive, Eq. (9) becomes\nk∑ i=1 [f(xi)− f(x∗)] 6 L 2 ‖x0 − x∗‖2 + LBk + LAk(Ak + ‖x0 − x∗‖+ √ 2Bk +Ak)\n6 L\n2 ‖x0 − x∗‖2 + LBk + 2LA2k + LAk‖x0 − x∗‖+ LAk\n√ 2Bk\n6 L\n2\n( ‖x0 − x∗‖+ 2Ak + √ 2Bk )2 .\nSince f is convex, we get\nf\n( 1\nk k∑ i=1 xi\n) − f(x∗) 6 1\nk k∑ i=1 [f(xi)− f(x∗)]\n6 L\n2k\n( ‖x0 − x∗‖+ 2Ak + √ 2Bk )2 ."
    }, {
      "heading" : "6.2 Accelerated proximal-gradient method with errors in the convex case",
      "text" : "We now give the proof of Proposition 2.\nProof Defining\nθk = 2/(k + 1) vk = xk−1 + 1\nθk (xk − xk−1) ,\nwe can rewrite the update for yk as\nyk = (1− θk+1)xk + θk+1vk ,\nbecause\n(1− θk+1)xk + θk+1vk = (1− 2\nk + 2 )xk +\n2\nk + 2 [xk−1 +\nk + 1\n2 (xk − xk−1)]\n= xk − 2\nk + 2 (xk − xk−1) +\nk + 1 k + 2 (xk − xk−1)\n= xk − k − 1 k + 2 (xk − xk−1) = yk.\nBecause g′ is Lipschitz and g is convex, we get for any z that\ng(xk) 6 g(yk−1) + 〈 g′(yk−1), xk − yk−1 〉 + L\n2 ‖xk − yk−1‖2\n6 g(z) + 〈 g′(yk−1), yk−1 − z 〉 + 〈 g′(yk−1), xk − yk−1 〉 + L\n2 ‖xk − yk−1‖2 .\nBecause −[g′(yk−1) + ek + L(xk + fk − yk−1)] ∈ ∂εkh(xk), we have for any z that\nh(xk) 6 εk + h(z) + 〈 L(yk−1 − xk)− g′(yk−1)− ek + Lfk, xk − z 〉 = εk + h(z) + 〈 g′(yk−1), z − xk 〉 + L 〈xk − yk−1, z − xk〉+ 〈ek + Lfk, z − xk〉\nAdding these bounds together gives:\ng(xk) + h(xk) = f(xk) 6 εk + f(z) + L 〈xk − yk−1, z − xk〉+ L\n2 ‖xk − yk−1‖2 + 〈ek + Lfk, z − xk〉\nChoosing z = θkx ∗ + (1− θk)xk−1 gives\nf(xk) 6 εk + f(θkx ∗ + (1− θ)xk−1) + L 〈xk − yk−1, θkx∗ + (1− θk)xk−1 − xk〉+\nL 2 ‖xk − yk−1‖2\n+ 〈ek + Lfk, θkx∗ + (1− θk)xk−1 − xk〉\n6 εk + θkf(x ∗) + (1− θk)f(xk−1) + L 〈xk − yk−1, θkx∗ + (1− θk)xk−1 − xk〉+\nL 2 ‖xk − yk−1‖2\n+ 〈ek + Lfk, θkx∗ + (1− θk)xk−1 − xk〉 (10) using the convexity of f and the fact that θk is in [0, 1].\nSince θkx ∗ + (1− θk)xk−1 − xk = θk(x∗ − vk)\nand\nxk − yk−1 = θkvk + (1− θk)xk−1 − yk−1 = θkvk − θkvk−1 ,\nwe have\nL 〈xk − yk−1, θkx∗ + (1− θk)xk−1 − xk〉 = Lθ2k 〈vk − vk−1, x∗ − vk〉 = −Lθ2k‖vk − x∗‖2 + Lθ2k 〈vk − x∗, vk−1 − x∗〉\n(11)\nL 2 ‖xk − yk−1‖2 = Lθ2k 2 ‖vk − vk−1‖2\n= Lθ2k\n2\n( ‖vk − x∗‖2 + ‖vk−1 − x∗‖2 − 2 〈vk − x∗, vk−1 − x∗〉 ) (12)\n〈ek + Lfk, θkx∗ + (1− θk)xk−1 − xk〉 = θk 〈ek + Lfk, x∗ − vk〉 .\nSumming Eq. (11) and (12), we get\nL 〈xk − yk−1, θkx∗ + (1− θk)xk−1 − xk〉+ L\n2 ‖xk−yk−1‖2 = Lθ2k 2\n( ‖vk−1 − x∗‖2 − ‖vk − x∗‖2 ) Moving all function values in Eq. (10) to the left-side, we then get\nf(xk)− θkf(x∗)− (1− θk)f(xk−1) 6 Lθ2k ( ‖vk−1 − x∗‖2 − ‖vk − x∗‖2 ) + εk + θk 〈ek + Lfk, x∗ − vk〉 .\nReordering the terms and dividing by θ2k gives\n1\nθ2k (f(xk)−f(x∗))+\nL 2 ‖vk−x∗‖2 6 1− θk θ2k (f(xk−1)−f(x∗))+ L 2 ‖vk−1−x∗‖2+ εk θ2k + 1 θk 〈ek + Lfk, x∗ − vk〉 .\nNow we use that for all k greater than or equal to 1,\n1− θk θ2k 6 1 θ2k−1\nto apply this recursively and obtain\n1\nθ2k (f(xk)− f(x∗)) +\nL 2 ‖vk − x∗‖2 6 1− θ0 θ20 (f(x0)− f(x∗)) + L 2 ‖v0 − x∗‖2 + k∑ i=1 εi θ2i\n+ k∑ i=1 1 θi (‖ej‖+ √ 2Lεi) · ‖x∗ − vi‖\nusing ‖fi‖ 6 √ 2εi L . Since v0 = x0 and θ0 = 2, we get\nf(xk)−f(x∗)+ Lθ2k\n2 ‖vk−x∗‖2 6 Lθ2k 2 ‖x0−x∗‖2+θ2k k∑ i=1 εi θ2i +θ2k k∑ i=1 1 θi ( ‖ej‖+ √ 2Lεi ) ·‖x∗−vi‖ .\n(13)\nAs in the previous proof, we will now use Eq. (13) to first bound the values of ‖vi − x∗‖ then, using these bounds, bound the function values."
    }, {
      "heading" : "6.2.1 Bounding ‖vi − x∗‖",
      "text" : "We now need to bound the quantities ‖vi − x∗‖ in terms of ‖x0 − x∗‖, ei and εi.\n‖vk − x∗‖2 6 ‖x0 − x∗‖2 + 2\nL k∑ i=1 εi θ2i + k∑ i=1 2 θi ( ‖ej‖ L + √ 2εi L ) · ‖x∗ − vi‖ .\nSince θi = 2/(i+ 1), 1 θi = i+12 6 i since i > 1. Thus, we have\n‖vk − x∗‖2 6 ‖x0 − x∗‖2 + 2\nL k∑ i=1 i2εi + k∑ i=1 2i ( ‖ej‖ L + √ 2εi L ) · ‖x∗ − vi‖ .\nWe now denote Ãk = ∑k i=1 i ( ‖ei‖ L + √ 2εi L ) and B̃k = ∑k i=1 i2εi L . From Lemma 1, we get\n‖vk − x∗‖ 6 Ãk + ( ‖x0 − x∗‖2 + 2B̃k + Ã2k )1/2 .\nSince Ãi and B̃i are increasing sequences, we also have for i 6 k:\n‖vi − x∗‖ 6 Ãi + ( ‖x0 − x∗‖2 + 2B̃i + Ã2i )1/2 6 ‖x0 − x∗‖+ 2Ãi + B̃1/2i √ 2\n6 ‖x0 − x∗‖+ 2Ãk + B̃ 1/2 k\n√ 2 ."
    }, {
      "heading" : "6.2.2 Bounding the function values",
      "text" : "Dropping Lθ2k 2 ‖vk − x ∗‖2 in Eq. (13) (since it is positive), we thus have\nf(xk)− f(x∗) 6 Lθ2k\n2\n( ‖x0 − x∗‖2 + 2B̃k + 2Ãk [ ‖x0 − x∗‖+ 2Ãk + √ 2B̃k ]) 6 Lθ2k\n2\n( ‖x0 − x∗‖2 + 2B̃k + 2Ãk‖x0 − x∗‖+ 4Ã2k + 2Ãk √ 2B̃k ) 6 Lθ2k\n2\n( ‖x0 − x∗‖+ 2Ãk + √ 2B̃k )2 and\n1\nθ2k (f(xk)− f(x∗)) 6\nL\n2\n( ‖x0 − x∗‖+ 2Ãk + √ 2B̃k )2 ."
    }, {
      "heading" : "6.3 Basic proximal-gradient method with errors in the strongly convex case",
      "text" : "Below is the proof of Proposition 3 Proof As in section 4.1, there exists fi such that ‖fi‖ 6 √ 2εi L and\nL ( xi−1 − xi − 1\nL (g′(xi−1) + ei)− fi\n) ∈ ∂εih(xi) .\nSince x∗ is optimal, we have that x∗ = proxL ( x∗ − 1Lg ′(x∗) ) .\nWe first separate fk, the error in the proximal, from the rest: ‖xk − x∗‖2 = ∥∥∥∥proxL(xk−1 − 1Lg′(xk−1)− 1Lek ) + fk − proxL ( x∗ − 1 L g′(x∗) )∥∥∥∥2 = ∥∥∥∥proxL(xk−1 − 1Lg′(xk−1)− 1Lek ) − proxL ( x∗ − 1 L g′(x∗)\n)∥∥∥∥2 + ‖fk‖2 + 2 〈 fk,proxL ( xk−1 − 1\nL g′(xk−1)−\n1 L ek\n) − proxL ( x∗ − 1\nL g′(x∗) )〉 6 ∥∥∥∥proxL(xk−1 − 1Lg′(xk−1)− 1Lek ) − proxL ( x∗ − 1 L g′(x∗)\n)∥∥∥∥2 + 2εkL + 2 √ 2εk L ∥∥∥∥proxL(xk−1 − 1Lg′(xk−1)− 1Lek ) − proxL ( x∗ − 1 L g′(x∗)\n)∥∥∥∥ using Cauchy-Schwartz and ‖fk‖ 6 √ 2εk L\n6 ∥∥∥∥xk−1 − 1Lg′(xk−1)− 1Lek − x∗ + 1Lg′(x∗) ∥∥∥∥2 + 2εkL\n+ 2 √ 2εk L ∥∥∥∥xk−1 − 1Lg′(xk−1)− 1Lek − x∗ + 1Lg′(x∗) ∥∥∥∥\nusing the non-expansiveness of the proximal\n6 ∥∥∥∥xk−1 − 1Lg′(xk−1)− 1Lek − x∗ + 1Lg′(x∗) ∥∥∥∥2 + 2εkL\n+ 2 √ 2εk L (∥∥∥∥xk−1 − x∗ − 1L(g′(xk−1)− g′(x∗)) ∥∥∥∥+ ‖ek‖L ) using the triangular inequality.\nWe continue this computation, but now separating ek, the error in the gradient, from the rest:\n‖xk − x∗‖2 = ‖xk−1 − x∗ − 1 L (g′(xk−1)− g′(x∗))‖2 +\n‖ek‖2\nL2 − 2 L\n〈 ek, xk−1 − x∗ − 1\nL (g′(xk−1)−\n1 L g′(x∗)) 〉 +\n2εk L + 2 √ 2εk L ( ‖xk−1 − x∗ − 1 L (g′(xk−1)− g′(x∗))‖+ ‖ek‖ L ) 6 ‖xk−1 − x∗ − 1\nL (g′(xk−1)− g′(x∗))‖2 +\n‖ek‖2\nL2 +\n2 L ‖ek‖‖xk−1 − x∗ − 1 L (g′(xk−1)− g′(x∗))‖\n+ 2εk L + 2 √ 2εk L ( ‖xk−1 − x∗ − 1 L (g′(xk−1)− g′(x∗))‖+ ‖ek‖ L ) using Cauchy-Schwartz\n6 ‖xk−1 − x∗ − 1 L (g′(xk−1)− g′(x∗))‖2 +\n‖ek‖2\nL2 + 2εk L + 2 L √ 2εk L ‖ek‖\n+ ( 2‖ek‖ L + 2 √ 2εk L )∥∥∥∥xk−1 − x∗ − 1L(g′(xk−1)− g′(x∗)) ∥∥∥∥ .\nWe now need to bound ∥∥xk−1 − x∗ − 1L(g′(xk−1)− g′(x∗))∥∥ to get the final result. We have:\n‖xk−1 − x∗ − 1 L (g′(xk−1)− g′(x∗))‖2 = ‖xk−1 − x∗‖2 + 1 L2 ‖g′(xk−1)− g′(x∗)‖2\n− 2 L\n〈 g′(xk−1)− g′(x∗), xk−1 − x∗ 〉 6 ‖xk−1 − x∗‖2 + 1\nL2 ‖g′(xk−1)− g′(x∗)‖2\n− 2 L\n( 1\nL+ µ ‖g′(xk−1)− g′(x∗)‖2 +\nLµ\nL+ µ ‖xk−1 − x∗‖2 ) using theorem 2.1.12 of [28]\n= (1− 2µ L+ µ )‖xk−1 − x∗‖2 + 1 L\n( 1\nL − 2 L+ µ\n) ‖g′(xk−1)− g′(x∗)‖2\n6 (1− 2µ L+ µ )‖xk−1 − x∗‖2 + µ2 L ( 1 L − 2 L+ µ )‖xk−1 − x∗‖2\nusing the negativity of 1L − 2 L+µ and the strong convexity of g = (\n1− µ L\n)2 ‖xk−1 − x∗‖2.\nThus\n‖xk − x∗‖2 6 (\n1− µ L\n)2 ‖xk−1 − x∗‖2 + ‖ek‖2\nL2 + 2εk L + 2 L √ 2εk L ‖ek‖\n+ ( 2‖ek‖ L + 2 √ 2εk L )( 1− µ L ) ‖xk−1 − x∗‖\n= [( 1− µ\nL\n) ‖xk−1 − x∗‖+\n‖ek‖ L + √ 2εk L ]2 .\nTaking the square root of both sides and applying the bound recursively yields\n‖xk − x∗‖ 6 (\n1− µ L\n)k ‖x0 − x∗‖+ k∑ i=1 ( 1− µ L )k−i(‖ei‖ L + √ 2εi L ) ."
    }, {
      "heading" : "6.4 Accelerated proximal-gradient method with errors in the strongly convex case",
      "text" : "We now give the proof of Proposition 4.\nProof We have (following [28])\nxk = yk−1 − 1 L g′(yk−1) .\nWe define\nα2k = (1− αk)α2k−1 + µ\nL αk\nvk = xk−1 + 1\nαk−1 (xk − xk−1)\nθk = αk − µL 1− µL yk = xk + θk(vk − xk) .\nIf we choose α0 = √ γ, then this yields\nyk = xk + 1−√γ 1 + √ γ (xk − xk−1) .\nWe can bound g(xk) with\ng(xk) 6 g(yk−1) + 〈g′(yk−1), xk − yk−1〉+ L\n2 ‖xk − yk−1‖2\nusing the convexity of g\n6 g(z) + 〈g′(yk−1), yk−1 − z〉+ 〈g′(yk−1), xk − yk−1〉+ L\n2 ‖xk − yk−1‖2 −\nµ 2 ‖yk−1 − z‖2\nusing the µ-strong convexity of g.\nUsing Lemma 2, we have that −[g′(yk−1) + ek + L(xk + fk − yk−1)] ∈ ∂εkh(xk). Hence, we have for any z that\nh(xk) 6 εk + h(z) + 〈 L(yk−1 − xk)− g′(yk−1)− ek − Lfk, xk − z 〉 = εk + h(z) + 〈 g′(yk−1), z − xk 〉 + L 〈xk − yk−1, z − xk〉+ 〈ek + Lfk, z − xk〉\nAdding these two bounds, we get for any z\nf(xk) 6 εk + f(z) + L 〈xk − yk−1, z − xk〉+ L\n2 ‖xk − yk−1‖2 −\nµ 2 ‖yk−1 − z‖2 + 〈ek + Lfk, z − xk〉 .\nUsing z = αk−1x ∗ + (1− αk−1)xk−1, we get\nf(xk) 6 εk + f(αk−1x ∗ + (1− αk−1)xk−1) + L 〈xk − yk−1, αk−1x∗ + (1− αk−1)xk−1 − xk〉\n+ L\n2 ‖xk − yk−1‖2 −\nµ 2 ‖yk−1 − αk−1x∗ − (1− αk−1)xk−1‖2\n+ 〈ek + Lfk, αk−1x∗ + (1− αk−1)xk−1 − xk〉 6 εk + αk−1f(x ∗) + (1− αk−1)f(xk−1) + L 〈xk − yk−1, αk−1x∗ + (1− αk−1)xk−1 − xk〉\n+ L\n2 ‖xk − yk−1‖2 −\nµ 2 ‖yk−1 − αk−1x∗ − (1− αk−1)xk−1‖2 − µ 2 αk−1(1− αk−1)‖x∗ − xk−1‖2\n+ 〈ek + Lfk, αk−1x∗ + (1− αk−1)xk−1 − xk〉 using the µ-strong convexity of f .\nWe can replace xk − yk−1 using\nxk − yk−1 = xk − xk−1 − θk−1(vk−1 − xk−1)\n= θk−1xk−1 + θk−1 αk−1\n(xk − xk−1) + (\n1− θk−1 αk−1\n) (xk − xk−1)− θk−1vk−1\n= θk−1(vk − vk−1) + (\n1− θk−1 αk−1\n) (xk − xk−1) .\nWe also have\n(1− αk−1)xk−1 − xk = −αk−1vk αk−1x ∗ + (1− αk−1)xk−1 − xk = αk−1(x∗ − vk) ,\nand\nyk−1 − αk−1x∗ − (1− αk−1)xk−1 = yk−1 − αk−1(x∗ − vk)− xk = αk−1(vk − x∗)− θk−1(vk − vk−1)− (\n1− θk−1 αk−1\n) (xk − xk−1)\nThus,\nf(xk) 6 εk + αk−1f(x ∗) + (1− αk−1)f(xk−1)\n− Lθk−1αk−1〈vk − vk−1, vk − x∗〉 − L(αk−1 − θk−1)〈xk − xk−1, vk − x∗〉\n+ Lθ2k−1\n2 ‖vk − vk−1‖2 +\nL ( 1− θk−1αk−1 )2\n2 ‖xk − xk−1‖2\n+ Lθk−1\n( 1− θk−1\nαk−1\n) 〈vk − vk−1, xk − xk−1〉\n− µα2k−1\n2 ‖vk − x∗‖2 − µθ2k−1 2 ‖vk − vk−1‖2 −\nµ ( 1− θk−1αk−1 )2\n2 ‖xk − xk−1‖2\n+ µαk−1θk−1〈vk − x∗, vk − vk−1〉+ µ(αk−1 − θk−1)〈vk − x∗, xk − xk−1〉 − µθk−1 (\n1− θk−1 αk−1\n) 〈vk − vk−1, xk − xk−1〉 − µ\n2 αk−1(1− αk−1)‖x∗ − xk−1‖2\n+ αk−1 〈ek + Lfk, x∗ − vk〉 .\nTo avoid unnecessary clutter, we shall denote Ek the additional term induced by the errors, i.e.\nEk = εk + αk−1 〈ek + Lfk, x∗ − vk〉 .\nBefore reordering the terms together, we shall also replace all instances of vk − vk−1 with vk − x∗ − (vk−1 − x∗):\nf(xk) 6 Ek + αk−1f(x ∗) + (1− αk−1)f(xk−1)− Lθk−1αk−1‖vk − x∗‖2 + Lθk−1αk−1〈vk−1 − x∗, vk − x∗〉\n− L(αk−1 − θk−1)〈xk − xk−1, vk − x∗〉 + (L− µ)θ2k−1\n2 ‖vk − x∗‖2 + (L− µ)θ2k−1 2 ‖vk−1 − x∗‖2 − (L− µ)θ2k−1〈vk − x∗, vk−1 − x∗〉\n+ (L− µ)\n( 1− θk−1αk−1 )2 2 ‖xk − xk−1‖2\n+ Lθk−1\n( 1− θk−1\nαk−1\n) 〈vk − x∗, xk − xk−1〉 − Lθk−1 ( 1− θk−1\nαk−1\n) 〈vk−1 − x∗, xk − xk−1〉\n− µα2k−1\n2 ‖vk − x∗‖2\n+ µαk−1θk−1‖vk − x∗‖2 − µαk−1θk−1〈vk − x∗, vk−1 − x∗〉 + µ(αk−1 − θk−1)〈vk − x∗, xk − xk−1〉\n− µθk−1 (\n1− θk−1 αk−1\n) 〈vk − x∗, xk − xk−1〉+ µθk−1 ( 1− θk−1\nαk−1\n) 〈vk−1 − x∗, xk − xk−1〉\n− µ 2 αk−1(1− αk−1)‖x∗ − xk−1‖2 .\nWith a bit of well-needed cleaning, this becomes\nf(xk) 6 Ek + αk−1f(x ∗) + (1− αk−1)f(xk−1)\n+\n[ L− µ\n2 (θk−1 − αk−1)2 − Lα2k−1 2\n] ‖vk − x∗‖2\n+ (L− µ)θ2k−1\n2 ‖vk−1 − x∗‖2\n+ (L− µ)θk−1(αk−1 − θk−1)〈vk−1 − x∗, vk − x∗〉 + (L− µ)(θk−1 − αk−1) (\n1− θk−1 αk−1\n) 〈xk − xk−1, vk − x∗〉\n− (L− µ)θk−1 (\n1− θk−1 αk−1\n) 〈vk−1 − x∗, xk − xk−1〉\n+ (L− µ)\n( 1− θk−1αk−1 )2 2 ‖xk − xk−1‖2\n− µ 2 αk−1(1− αk−1)‖x∗ − xk−1‖2 .\nWe can rewrite xk − xk−1 using\nxk − xk−1 = αk−1(vk − xk−1) = αk−1(vk − x∗)− αk−1(xk−1 − x∗) .\nWe may now compute the coefficients for the following terms: ‖vk − x∗‖2, ‖vk−1 − x∗‖2, 〈vk−1 − x∗, vk − x∗〉, 〈xk−1 − x∗, vk − x∗〉, 〈xk−1 − x∗, vk−1 − x∗〉 and ‖x∗ − xk−1‖2.\nFor ‖vk − x∗‖2, we have\nL− µ 2 (θk−1 − αk−1)2 − Lα2k−1\n2︸ ︷︷ ︸ ‖vk − x∗‖2 term − (L− µ)(θk−1 − αk−1)2︸ ︷︷ ︸ 〈xk − xk−1, vk − x∗〉 term + (L− µ)(θk−1 − αk−1)2 2︸ ︷︷ ︸ ‖xk − xk−1‖2 term = − Lα2k−1 2 .\nFor ‖vk−1 − x∗‖2, there is only one term and we keep (L−µ)θ2k−1\n2 .\nFor 〈vk−1 − x∗, vk − x∗〉, we get\n(L− µ)θk−1(αk−1 − θk−1)︸ ︷︷ ︸ 〈vk−1 − x∗, vk − x∗〉 term − (L− µ)θk−1 (αk−1 − θk−1)︸ ︷︷ ︸ 〈vk−1 − x∗, xk − xk−1〉 term = 0 .\nFor 〈xk−1 − x∗, vk − x∗〉, we get\n(L− µ)(θk−1 − αk−1)2︸ ︷︷ ︸ 〈xk − xk−1, vk − x∗〉 term − (L− µ)(θk−1 − αk−1)2︸ ︷︷ ︸ ‖xk − xk−1‖2 term = 0 .\nFor 〈xk−1 − x∗, vk−1 − x∗〉, we get\n(L− µ)θk−1 (αk−1 − θk−1)︸ ︷︷ ︸ 〈vk−1 − x∗, xk − xk−1〉 term = (L− µ)θk−1 (αk−1 − θk−1) .\nFor ‖x∗ − xk−1‖2, we get\n(L− µ)(θk−1 − αk−1)2 2︸ ︷︷ ︸ ‖xk − xk−1‖2 term − µ 2 αk−1(1− αk−1)︸ ︷︷ ︸ ‖x∗ − xk−1‖2 term = −µ 2 θk−1(1− αk−1) .\nHence, we have\nf(xk) 6 Ek + αk−1f(x ∗) + (1− αk−1)f(xk−1)\n− Lα2k−1\n2 ‖vk − x∗‖2\n+ (L− µ)θ2k−1\n2 ‖vk−1 − x∗‖2\n+ (L− µ)θk−1 (αk−1 − θk−1) 〈vk−1 − x∗, xk−1 − x∗〉 − µ 2 θk−1(1− αk−1)‖xk−1 − x∗‖2 − θk−1(L− µ) 2(θk−1 − αk−1)2\n2µ(1− αk−1) ‖vk−1 − x∗‖2\n+ θk−1(L− µ)2(θk−1 − αk−1)2\n2µ(1− αk−1) ‖vk−1 − x∗‖2 ,\nthe last two lines allowing us to complete the square. We may now factor it to get\nf(xk) 6 Ek + αk−1f(x ∗) + (1− αk−1)f(xk−1)\n− Lα2k−1\n2 ‖vk − x∗‖2\n+ (L− µ)θ2k−1\n2 ‖vk−1 − x∗‖2\n− µ 2 θk−1(1− αk−1) ∥∥∥∥xk−1 − x∗ − (L− µ)(αk−1 − θk−1)µ(1− αk−1) (vk−1 − x∗) ∥∥∥∥2 + θk−1(L− µ)2(θk−1 − αk−1)2\n2µ(1− αk−1) ‖vk−1 − x∗‖2 .\nDiscarding the term depending on xk−1−x∗ and regrouping the terms depending on ‖vk−1− x∗‖2, we have\nf(xk) 6 Ek + αk−1f(x ∗) + (1− αk−1)f(xk−1)\n− Lα2k−1\n2 ‖vk − x∗‖2\n+ (Lαk−1 − µ)αk−1\n2 ‖vk−1 − x∗‖2 .\nReordering the terms, we have\nf(xk)−f(x∗)+ Lα2k−1\n2 ‖vk−x∗‖2 6 (1−αk−1) (f(xk−1)− f(x∗))+ (Lαk−1 − µ)αk−1 2\n‖vk−1−x∗‖2+Ek . (14)\nWe can rewrite Eq. (14) as\nf(xk)− f(x∗) + Lα2k−1\n2 ‖vk − x∗‖2 6 (1− αk−1)\n( f(xk−1)− f(x∗) +\nLα2k−2 2 ‖vk−1 − x∗‖2\n)\n+ Lα2k−1 − µαk−1 − (1− αk−1)Lα2k−2\n2 ‖vk−1 − x∗‖2\n+ Ek .\nUsing\nαk =\n√ µ\nL\nand denoting\nδk = f(xk)− f(x∗) + µ 2 ‖vk − x∗‖2 , (15)\nwe get the following recursion:\nδk 6\n( 1− √ µ\nL\n) δk−1 + Ek . (16)\nApplying this relationship recursively, we get\nδk 6\n( 1− √ µ\nL\n)k δ0 + k∑ t=1 Et ( 1− √ µ L )k−t . (17)\nSince Ek = εk + αk−1 〈ek + Lfk, x∗ − vk〉, we can bound it by\nEk 6 εk +\n√ µ\nL\n( ‖ek‖+ √ 2Lεk ) ‖vk − x∗‖\nusing ‖fk‖ 6 √ 2εk L . Again, we shall use Eq. (17) to first bound the values of ‖vi− x∗‖, then the function values themselves."
    }, {
      "heading" : "6.4.1 Bounding ‖vi − x∗‖",
      "text" : "We will now use Lemma 1 to bound the value of ‖vk − x∗‖. Since ‖vk − x∗‖2 is bounded by 2δk µ (using Eq. (15)), we can use Eq. (17) to get\n‖vk − x∗‖2 6 2\nµ\n( 1− √ µ\nL\n)k [ δ0 +\nk∑ t=1 εt ( 1− √ µ L )−t]\n+ 2√ Lµ k∑ t=1 ( ‖et‖+ √ 2Lεt )( 1− √ µ L )k−t ‖vt − x∗‖ .\nMultiplying both sides by ( 1− √\nµ L )−k yields(\n1− √ µ\nL\n)−k ‖vk − x∗‖2 6 2\nµ\n[ δ0 +\nk∑ t=1 εt ( 1− √ µ L )−t]\n+ 2√ Lµ k∑ t=1 ( ‖et‖+ √ 2Lεt )( 1− √ µ L )−t/2( 1− √ µ L )−t/2 ‖vt − x∗‖ .\n(18)\nUsing\nBk = k∑ t=1 εt ( 1− √ µ L )−t\nλ̃t =\n√ µ\nL\n( ‖et‖+ √ 2Lεt )( 1− √ µ\nL\n)−t/2 ,\nLemma 1 yields( 1− √ µ\nL\n)−k/2 ‖vk − x∗‖ 6 1\nµ k∑ t=1 λ̃t +  2 µ δ0 + 2 µ Bk + ( 1 µ k∑ t=1 λ̃t )21/2 . (19)\nSince Bt is an increasing sequence and the λ̃t are positive, we have for i 6 k\n( 1− √ µ\nL\n)−i/2 ‖vi − x∗‖ 6 1\nµ i∑ t=1 λ̃t +  2 µ δ0 + 2 µ Bi + ( 1 µ i∑ t=1 λ̃t )21/2\n6 1\nµ i∑ t=1 λ̃t + √ 2δ0 µ + √ 2Bi µ + 1 µ i∑ t=1 λ̃t\n= 2\nµ k∑ t=1 λ̃t + √ 2δ0 µ + √ 2Bk µ ."
    }, {
      "heading" : "6.4.2 Bounding the function values",
      "text" : "Denoting Ak = ∑k t=1 λ̃t = √ µ L ∑ t ( ‖et‖+ √ 2Lεt ) ( 1− √ µ L )−t/2 , we have\nδk 6\n( 1− √ µ\nL\n)k [ δ0 +\nk∑ t=1 εt ( 1− √ µ L )−t]\n+\n√ µ\nL k∑ t=1 ( ‖et‖+ √ 2Lεt )( 1− √ µ L )k−t/2( 2Ak µ + √ 2δ0 µ + √ 2Bk µ )\n= ( 1− √ µ\nL\n)k( δ0 +Bk +\n∑ t λ̃t ( 2Ak µ + √ 2δ0 µ + √ 2Bk µ ))\n= ( 1− √ µ\nL\n)k( δ0 +Bk +Ak ( 2Ak µ + √ 2δ0 µ + √ 2Bk µ ))\n6 ( 1− √ µ\nL\n)k (√ δ0 +Ak √ 2 µ + √ Bk )2 .\nUsing the L-Lipschitz gradient of f and the fact that v0 = x0, we have√ δ0 = √ f(x0)− f(x∗) + µ\n2 ‖v0 − x∗‖2 6 √ 2(f(x0)− f(x∗)) .\nHence, discarding the term ‖vk − x∗‖2 of δk, we have\nf(xk)− f(x∗) 6 ( 1− √ µ\nL\n)k (√ 2(f(x0)− f(x∗)) +Ak √ 2 µ + √ Bk )2 . (20)"
    } ],
    "references" : [ {
      "title" : "A fast iterative shrinkage-thresholding algorithm for linear inverse problems",
      "author" : [ "A. Beck", "M. Teboulle" ],
      "venue" : "SIAM Journal on Imaging Sciences, 2(1):183–202",
      "citeRegEx" : "1",
      "shortCiteRegEx" : null,
      "year" : 2009
    }, {
      "title" : "Gradient methods for minimizing composite objective function",
      "author" : [ "Y. Nesterov" ],
      "venue" : "CORE Discussion Papers, ",
      "citeRegEx" : "2",
      "shortCiteRegEx" : null,
      "year" : 2007
    }, {
      "title" : "Regression shrinkage and selection via the Lasso",
      "author" : [ "R. Tibshirani" ],
      "venue" : "Journal of the Royal Statistical Society: Series B, 58(1):267–288",
      "citeRegEx" : "3",
      "shortCiteRegEx" : null,
      "year" : 1996
    }, {
      "title" : "Atomic decomposition by basis pursuit",
      "author" : [ "S.S. Chen", "D.L. Donoho", "M.A. Saunders" ],
      "venue" : "SIAM Journal on Scientific Computing, 20(1):33–61",
      "citeRegEx" : "4",
      "shortCiteRegEx" : null,
      "year" : 1998
    }, {
      "title" : "Sparse reconstruction by separable approximation",
      "author" : [ "S.J. Wright", "R.D. Nowak", "M.A.T. Figueiredo" ],
      "venue" : "IEEE Transactions on Signal Processing, 57(7):2479–2493",
      "citeRegEx" : "5",
      "shortCiteRegEx" : null,
      "year" : 2009
    }, {
      "title" : "Convex optimization with sparsityinducing norms",
      "author" : [ "F. Bach", "R. Jenatton", "J. Mairal", "G. Obozinski" ],
      "venue" : "S. Sra, S. Nowozin, and S.J. Wright, editors, Optimization for Machine Learning. MIT Press",
      "citeRegEx" : "6",
      "shortCiteRegEx" : null,
      "year" : 2011
    }, {
      "title" : "Total variation projection with first order schemes",
      "author" : [ "J. Fadili", "G. Peyré" ],
      "venue" : "IEEE Transactions on Image Processing, 20(3):657–669",
      "citeRegEx" : "7",
      "shortCiteRegEx" : null,
      "year" : 2011
    }, {
      "title" : "Graph-structured multi-task regression and an efficient optimization method for general fused Lasso",
      "author" : [ "X. Chen", "S. Kim", "Q. Lin", "J.G. Carbonell", "E.P. Xing" ],
      "venue" : "arXiv:1005.3579v1",
      "citeRegEx" : "8",
      "shortCiteRegEx" : null,
      "year" : 2010
    }, {
      "title" : "A singular value thresholding algorithm for matrix completion",
      "author" : [ "J.-F. Cai", "E.J. Candès", "Z. Shen" ],
      "venue" : "SIAM Journal on Optimization, 20(4)",
      "citeRegEx" : "9",
      "shortCiteRegEx" : null,
      "year" : 2010
    }, {
      "title" : "Fixed point and Bregman iterative methods for matrix rank minimization",
      "author" : [ "S. Ma", "D. Goldfarb", "L. Chen" ],
      "venue" : "Mathematical Programming, 128(1):321–353",
      "citeRegEx" : "10",
      "shortCiteRegEx" : null,
      "year" : 2011
    }, {
      "title" : "Group Lasso with overlap and graph Lasso",
      "author" : [ "L. Jacob", "G. Obozinski", "J.-P. Vert" ],
      "venue" : "ICML",
      "citeRegEx" : "11",
      "shortCiteRegEx" : null,
      "year" : 2009
    }, {
      "title" : "Proximal methods for sparse hierarchical dictionary learning",
      "author" : [ "R. Jenatton", "J. Mairal", "G. Obozinski", "F. Bach" ],
      "venue" : "ICML",
      "citeRegEx" : "12",
      "shortCiteRegEx" : null,
      "year" : 2010
    }, {
      "title" : "Fast Newton-type methods for total variation regularization",
      "author" : [ "A. Barbero", "S. Sra" ],
      "venue" : "ICML",
      "citeRegEx" : "13",
      "shortCiteRegEx" : null,
      "year" : 2011
    }, {
      "title" : "Fast overlapping group Lasso",
      "author" : [ "J. Liu", "J. Ye" ],
      "venue" : "arXiv:1009.0306v1",
      "citeRegEx" : "14",
      "shortCiteRegEx" : null,
      "year" : 2010
    }, {
      "title" : "Convex structure learning in log-linear models: Beyond pairwise potentials",
      "author" : [ "M. Schmidt", "K. Murphy" ],
      "venue" : "AISTATS",
      "citeRegEx" : "15",
      "shortCiteRegEx" : null,
      "year" : 2010
    }, {
      "title" : "A unified framework of descent algorithms for nonlinear programs and variational inequalities",
      "author" : [ "M. Patriksson" ],
      "venue" : "PhD thesis, Department of Mathematics, Linköping University, Sweden",
      "citeRegEx" : "16",
      "shortCiteRegEx" : null,
      "year" : 1995
    }, {
      "title" : "Solving monotone inclusions via compositions of nonexpansive averaged operators",
      "author" : [ "P.L. Combettes" ],
      "venue" : "Optimization, 53(5-6):475–504",
      "citeRegEx" : "17",
      "shortCiteRegEx" : null,
      "year" : 2004
    }, {
      "title" : "Efficient online and batch learning using forward backward splitting",
      "author" : [ "J. Duchi", "Y. Singer" ],
      "venue" : "JMLR, 10:2873–2898",
      "citeRegEx" : "18",
      "shortCiteRegEx" : null,
      "year" : 2009
    }, {
      "title" : "Sparse online learning via truncated gradient",
      "author" : [ "J. Langford", "L. Li", "T. Zhang" ],
      "venue" : "JMLR, 10:777–801",
      "citeRegEx" : "19",
      "shortCiteRegEx" : null,
      "year" : 2009
    }, {
      "title" : "Smooth optimization with approximate gradient",
      "author" : [ "A. d’Aspremont" ],
      "venue" : "SIAM Journal on Optimization,",
      "citeRegEx" : "20",
      "shortCiteRegEx" : "20",
      "year" : 2008
    }, {
      "title" : "Estimate sequence methods: extensions and approximations",
      "author" : [ "M. Baes" ],
      "venue" : "Ifor internal report, ETH Zurich, Switzerland",
      "citeRegEx" : "21",
      "shortCiteRegEx" : null,
      "year" : 2009
    }, {
      "title" : "First-order methods of smooth convex optimization with inexact oracle",
      "author" : [ "O. Devolder", "F. Glineur", "Y. Nesterov" ],
      "venue" : "CORE Discussion Papers, ",
      "citeRegEx" : "22",
      "shortCiteRegEx" : null,
      "year" : 2011
    }, {
      "title" : "Convergence rate of incremental subgradient algorithms",
      "author" : [ "A. Nedic", "D. Bertsekas" ],
      "venue" : "Stochastic Optimization: Algorithms and Applications, pages 263–304",
      "citeRegEx" : "23",
      "shortCiteRegEx" : null,
      "year" : 2000
    }, {
      "title" : "Error bounds and convergence analysis of feasible descent methods: A general approach",
      "author" : [ "Z.-Q. Luo", "P. Tseng" ],
      "venue" : "Annals of Operations Research, 46-47(1):157–178",
      "citeRegEx" : "24",
      "shortCiteRegEx" : null,
      "year" : 1993
    }, {
      "title" : "Hybrid deterministic-stochastic methods for data fitting",
      "author" : [ "M.P. Friedlander", "M. Schmidt" ],
      "venue" : "arXiv:1104.2373",
      "citeRegEx" : "25",
      "shortCiteRegEx" : null,
      "year" : 2011
    }, {
      "title" : "Monotone operators and the proximal point algorithm",
      "author" : [ "R.T. Rockafellar" ],
      "venue" : "SIAM Journal on Control and Optimization, 14(5):877–898",
      "citeRegEx" : "26",
      "shortCiteRegEx" : null,
      "year" : 1976
    }, {
      "title" : "New proximal point algorithms for convex minimization",
      "author" : [ "O. Güler" ],
      "venue" : "SIAM Journal on Optimization, 2(4):649–664",
      "citeRegEx" : "27",
      "shortCiteRegEx" : null,
      "year" : 1992
    }, {
      "title" : "Introductory Lectures on Convex Optimization: A Basic Course",
      "author" : [ "Y. Nesterov" ],
      "venue" : "Springer",
      "citeRegEx" : "28",
      "shortCiteRegEx" : null,
      "year" : 2004
    }, {
      "title" : "Convex optimization theory",
      "author" : [ "D.P. Bertsekas" ],
      "venue" : "Athena Scientific",
      "citeRegEx" : "29",
      "shortCiteRegEx" : null,
      "year" : 2009
    }, {
      "title" : "On accelerated proximal gradient methods for convex-concave optimization",
      "author" : [ "P. Tseng" ],
      "venue" : null,
      "citeRegEx" : "30",
      "shortCiteRegEx" : "30",
      "year" : 2008
    }, {
      "title" : "Convex and network flow optimization for structured sparsity",
      "author" : [ "J. Mairal", "R. Jenatton", "G. Obozinski", "F. Bach" ],
      "venue" : "arXiv:1104.1872v1",
      "citeRegEx" : "31",
      "shortCiteRegEx" : null,
      "year" : 2011
    }, {
      "title" : "A Dykstra-like algorithm for two monotone operators",
      "author" : [ "H.H. Bauschke", "P.L. Combettes" ],
      "venue" : "Pacific Journal of Optimization, 4(3):383–391",
      "citeRegEx" : "32",
      "shortCiteRegEx" : null,
      "year" : 2008
    }, {
      "title" : "Smooth minimization of non-smooth functions",
      "author" : [ "Y. Nesterov" ],
      "venue" : "Mathematical Programming, 103(1):127–152",
      "citeRegEx" : "33",
      "shortCiteRegEx" : null,
      "year" : 2005
    }, {
      "title" : "Proximal splitting methods in signal processing",
      "author" : [ "P.L. Combettes", "J.C. Pesquet" ],
      "venue" : "arXiv:0912.3522v4",
      "citeRegEx" : "34",
      "shortCiteRegEx" : null,
      "year" : 2010
    }, {
      "title" : "Tree-reweighted belief propagation algorithms and approximate ML estimation by pseudo-moment matching",
      "author" : [ "M.J. Wainwright", "T.S. Jaakkola", "A.S. Willsky" ],
      "venue" : "AISTATS",
      "citeRegEx" : "35",
      "shortCiteRegEx" : null,
      "year" : 2003
    }, {
      "title" : "Online learning with kernels",
      "author" : [ "J. Kivinen", "A.J. Smola", "R.C. Williamson" ],
      "venue" : "IEEE Transactions on Signal Processing, 52(8):2165–2176",
      "citeRegEx" : "36",
      "shortCiteRegEx" : null,
      "year" : 2004
    }, {
      "title" : "Subsampling algorithms for semidefinite programming",
      "author" : [ "A. d’Aspremont" ],
      "venue" : "arXiv:0803.1990v5,",
      "citeRegEx" : "37",
      "shortCiteRegEx" : "37",
      "year" : 2009
    }, {
      "title" : "Projected Newton-type methods in machine learning",
      "author" : [ "M. Schmidt", "D. Kim", "S. Sra" ],
      "venue" : "S. Sra, S. Nowozin, and S Wright, editors, Optimization for Machine Learning. MIT Press",
      "citeRegEx" : "38",
      "shortCiteRegEx" : null,
      "year" : 2011
    }, {
      "title" : "Convex Analysis and Optimization",
      "author" : [ "D.P. Bertsekas", "A. Nedić", "A.E. Ozdaglar" ],
      "venue" : "Athena Scientific",
      "citeRegEx" : "39",
      "shortCiteRegEx" : null,
      "year" : 2003
    } ],
    "referenceMentions" : [ {
      "referenceID" : 0,
      "context" : "Proximal-gradient methods and accelerated proximal-gradient methods [1, 2] are among the most important methods for taking advantage of the structure of many of the nonsmooth optimization problems that arise in practice.",
      "startOffset" : 68,
      "endOffset" : 74
    }, {
      "referenceID" : 1,
      "context" : "Proximal-gradient methods and accelerated proximal-gradient methods [1, 2] are among the most important methods for taking advantage of the structure of many of the nonsmooth optimization problems that arise in practice.",
      "startOffset" : 68,
      "endOffset" : 74
    }, {
      "referenceID" : 2,
      "context" : "One of the most well-studied instances of this type of problem is `1-regularized least squares [3, 4], minimize x∈Rd ‖Ax− b‖ + λ‖x‖1,",
      "startOffset" : 95,
      "endOffset" : 101
    }, {
      "referenceID" : 3,
      "context" : "One of the most well-studied instances of this type of problem is `1-regularized least squares [3, 4], minimize x∈Rd ‖Ax− b‖ + λ‖x‖1,",
      "startOffset" : 95,
      "endOffset" : 101
    }, {
      "referenceID" : 0,
      "context" : "While classical subgradient methods only achieve an error level on the objective function of O(1/ √ k) after k iterations, proximal-gradient methods have an error of O(1/k) while accelerated proximal-gradient methods futher reduce this to O(1/k2) [1, 2].",
      "startOffset" : 247,
      "endOffset" : 253
    }, {
      "referenceID" : 1,
      "context" : "While classical subgradient methods only achieve an error level on the objective function of O(1/ √ k) after k iterations, proximal-gradient methods have an error of O(1/k) while accelerated proximal-gradient methods futher reduce this to O(1/k2) [1, 2].",
      "startOffset" : 247,
      "endOffset" : 253
    }, {
      "referenceID" : 4,
      "context" : "We can efficiently compute an analytic solution to this problem for several notable choices of h, including the case of `1-regularization and disjoint group `1-regularization [5, 6].",
      "startOffset" : 175,
      "endOffset" : 181
    }, {
      "referenceID" : 5,
      "context" : "We can efficiently compute an analytic solution to this problem for several notable choices of h, including the case of `1-regularization and disjoint group `1-regularization [5, 6].",
      "startOffset" : 175,
      "endOffset" : 181
    }, {
      "referenceID" : 6,
      "context" : "This includes important problems such as total-variation regularization and its generalizations like the graph-guided fused-LASSO [7, 8], nuclearnorm regularization and other regularizers on the singular values of matrices [9, 10], and different formulations of overlapping group `1-regularization with general groups [11, 12].",
      "startOffset" : 130,
      "endOffset" : 136
    }, {
      "referenceID" : 7,
      "context" : "This includes important problems such as total-variation regularization and its generalizations like the graph-guided fused-LASSO [7, 8], nuclearnorm regularization and other regularizers on the singular values of matrices [9, 10], and different formulations of overlapping group `1-regularization with general groups [11, 12].",
      "startOffset" : 130,
      "endOffset" : 136
    }, {
      "referenceID" : 8,
      "context" : "This includes important problems such as total-variation regularization and its generalizations like the graph-guided fused-LASSO [7, 8], nuclearnorm regularization and other regularizers on the singular values of matrices [9, 10], and different formulations of overlapping group `1-regularization with general groups [11, 12].",
      "startOffset" : 223,
      "endOffset" : 230
    }, {
      "referenceID" : 9,
      "context" : "This includes important problems such as total-variation regularization and its generalizations like the graph-guided fused-LASSO [7, 8], nuclearnorm regularization and other regularizers on the singular values of matrices [9, 10], and different formulations of overlapping group `1-regularization with general groups [11, 12].",
      "startOffset" : 223,
      "endOffset" : 230
    }, {
      "referenceID" : 10,
      "context" : "This includes important problems such as total-variation regularization and its generalizations like the graph-guided fused-LASSO [7, 8], nuclearnorm regularization and other regularizers on the singular values of matrices [9, 10], and different formulations of overlapping group `1-regularization with general groups [11, 12].",
      "startOffset" : 318,
      "endOffset" : 326
    }, {
      "referenceID" : 11,
      "context" : "This includes important problems such as total-variation regularization and its generalizations like the graph-guided fused-LASSO [7, 8], nuclearnorm regularization and other regularizers on the singular values of matrices [9, 10], and different formulations of overlapping group `1-regularization with general groups [11, 12].",
      "startOffset" : 318,
      "endOffset" : 326
    }, {
      "referenceID" : 6,
      "context" : "Despite the difficulty in computing the exact proximity operator for these regularizers, efficient methods have been developed to compute approximate proximity operators in all of these cases; accelerated projected gradient and Newton-like methods that work with a smooth dual problem have been used to compute approximate proximity operators in the context of total-variation regularization [7, 13], Krylov subspace methods and low-rank representations have been used to compute approximate proximity operators in the context of nuclear-norm regularization [9, 10], and variants of Dykstra’s algorithm (and related dual methods) have been used to compute approximate proximity operators in the context of overlapping group `1-regularization [12, 14, 15].",
      "startOffset" : 392,
      "endOffset" : 399
    }, {
      "referenceID" : 12,
      "context" : "Despite the difficulty in computing the exact proximity operator for these regularizers, efficient methods have been developed to compute approximate proximity operators in all of these cases; accelerated projected gradient and Newton-like methods that work with a smooth dual problem have been used to compute approximate proximity operators in the context of total-variation regularization [7, 13], Krylov subspace methods and low-rank representations have been used to compute approximate proximity operators in the context of nuclear-norm regularization [9, 10], and variants of Dykstra’s algorithm (and related dual methods) have been used to compute approximate proximity operators in the context of overlapping group `1-regularization [12, 14, 15].",
      "startOffset" : 392,
      "endOffset" : 399
    }, {
      "referenceID" : 8,
      "context" : "Despite the difficulty in computing the exact proximity operator for these regularizers, efficient methods have been developed to compute approximate proximity operators in all of these cases; accelerated projected gradient and Newton-like methods that work with a smooth dual problem have been used to compute approximate proximity operators in the context of total-variation regularization [7, 13], Krylov subspace methods and low-rank representations have been used to compute approximate proximity operators in the context of nuclear-norm regularization [9, 10], and variants of Dykstra’s algorithm (and related dual methods) have been used to compute approximate proximity operators in the context of overlapping group `1-regularization [12, 14, 15].",
      "startOffset" : 558,
      "endOffset" : 565
    }, {
      "referenceID" : 9,
      "context" : "Despite the difficulty in computing the exact proximity operator for these regularizers, efficient methods have been developed to compute approximate proximity operators in all of these cases; accelerated projected gradient and Newton-like methods that work with a smooth dual problem have been used to compute approximate proximity operators in the context of total-variation regularization [7, 13], Krylov subspace methods and low-rank representations have been used to compute approximate proximity operators in the context of nuclear-norm regularization [9, 10], and variants of Dykstra’s algorithm (and related dual methods) have been used to compute approximate proximity operators in the context of overlapping group `1-regularization [12, 14, 15].",
      "startOffset" : 558,
      "endOffset" : 565
    }, {
      "referenceID" : 11,
      "context" : "Despite the difficulty in computing the exact proximity operator for these regularizers, efficient methods have been developed to compute approximate proximity operators in all of these cases; accelerated projected gradient and Newton-like methods that work with a smooth dual problem have been used to compute approximate proximity operators in the context of total-variation regularization [7, 13], Krylov subspace methods and low-rank representations have been used to compute approximate proximity operators in the context of nuclear-norm regularization [9, 10], and variants of Dykstra’s algorithm (and related dual methods) have been used to compute approximate proximity operators in the context of overlapping group `1-regularization [12, 14, 15].",
      "startOffset" : 742,
      "endOffset" : 754
    }, {
      "referenceID" : 13,
      "context" : "Despite the difficulty in computing the exact proximity operator for these regularizers, efficient methods have been developed to compute approximate proximity operators in all of these cases; accelerated projected gradient and Newton-like methods that work with a smooth dual problem have been used to compute approximate proximity operators in the context of total-variation regularization [7, 13], Krylov subspace methods and low-rank representations have been used to compute approximate proximity operators in the context of nuclear-norm regularization [9, 10], and variants of Dykstra’s algorithm (and related dual methods) have been used to compute approximate proximity operators in the context of overlapping group `1-regularization [12, 14, 15].",
      "startOffset" : 742,
      "endOffset" : 754
    }, {
      "referenceID" : 14,
      "context" : "Despite the difficulty in computing the exact proximity operator for these regularizers, efficient methods have been developed to compute approximate proximity operators in all of these cases; accelerated projected gradient and Newton-like methods that work with a smooth dual problem have been used to compute approximate proximity operators in the context of total-variation regularization [7, 13], Krylov subspace methods and low-rank representations have been used to compute approximate proximity operators in the context of nuclear-norm regularization [9, 10], and variants of Dykstra’s algorithm (and related dual methods) have been used to compute approximate proximity operators in the context of overlapping group `1-regularization [12, 14, 15].",
      "startOffset" : 742,
      "endOffset" : 754
    }, {
      "referenceID" : 15,
      "context" : "It is known that proximal-gradient methods that use an approximate proximity operator converge under only weak assumptions [16, 17]; we briefly review this and other related work in the next section.",
      "startOffset" : 123,
      "endOffset" : 131
    }, {
      "referenceID" : 16,
      "context" : "It is known that proximal-gradient methods that use an approximate proximity operator converge under only weak assumptions [16, 17]; we briefly review this and other related work in the next section.",
      "startOffset" : 123,
      "endOffset" : 131
    }, {
      "referenceID" : 6,
      "context" : "However, despite the many recent works showing impressive empirical performance of (accelerated) proximal-gradient methods that use an approximate proximity operator [7, 13, 9, 10, 14, 15], we are not aware of any theoretical analysis on how the error in the calculation of the proximity operator affects the convergence rate of proximal-gradient methods.",
      "startOffset" : 166,
      "endOffset" : 188
    }, {
      "referenceID" : 12,
      "context" : "However, despite the many recent works showing impressive empirical performance of (accelerated) proximal-gradient methods that use an approximate proximity operator [7, 13, 9, 10, 14, 15], we are not aware of any theoretical analysis on how the error in the calculation of the proximity operator affects the convergence rate of proximal-gradient methods.",
      "startOffset" : 166,
      "endOffset" : 188
    }, {
      "referenceID" : 8,
      "context" : "However, despite the many recent works showing impressive empirical performance of (accelerated) proximal-gradient methods that use an approximate proximity operator [7, 13, 9, 10, 14, 15], we are not aware of any theoretical analysis on how the error in the calculation of the proximity operator affects the convergence rate of proximal-gradient methods.",
      "startOffset" : 166,
      "endOffset" : 188
    }, {
      "referenceID" : 9,
      "context" : "However, despite the many recent works showing impressive empirical performance of (accelerated) proximal-gradient methods that use an approximate proximity operator [7, 13, 9, 10, 14, 15], we are not aware of any theoretical analysis on how the error in the calculation of the proximity operator affects the convergence rate of proximal-gradient methods.",
      "startOffset" : 166,
      "endOffset" : 188
    }, {
      "referenceID" : 13,
      "context" : "However, despite the many recent works showing impressive empirical performance of (accelerated) proximal-gradient methods that use an approximate proximity operator [7, 13, 9, 10, 14, 15], we are not aware of any theoretical analysis on how the error in the calculation of the proximity operator affects the convergence rate of proximal-gradient methods.",
      "startOffset" : 166,
      "endOffset" : 188
    }, {
      "referenceID" : 14,
      "context" : "However, despite the many recent works showing impressive empirical performance of (accelerated) proximal-gradient methods that use an approximate proximity operator [7, 13, 9, 10, 14, 15], we are not aware of any theoretical analysis on how the error in the calculation of the proximity operator affects the convergence rate of proximal-gradient methods.",
      "startOffset" : 166,
      "endOffset" : 188
    }, {
      "referenceID" : 17,
      "context" : "For example, when the ek are independent, zero-mean, and finitevariance random variables then proximal-gradient methods achieve the (optimal) error level of O(1/ √ k) [18, 19].",
      "startOffset" : 167,
      "endOffset" : 175
    }, {
      "referenceID" : 18,
      "context" : "For example, when the ek are independent, zero-mean, and finitevariance random variables then proximal-gradient methods achieve the (optimal) error level of O(1/ √ k) [18, 19].",
      "startOffset" : 167,
      "endOffset" : 175
    }, {
      "referenceID" : 19,
      "context" : "Several authors have recently analyzed the case of a fixed deterministic error in the gradient, and shown that accelerated gradient methods achieve the optimal convergence rate up to some accuracy that depends on the fixed error level [20, 21, 22], while the earlier work of [23] analyzes the gradient method in the context of a fixed error level.",
      "startOffset" : 235,
      "endOffset" : 247
    }, {
      "referenceID" : 20,
      "context" : "Several authors have recently analyzed the case of a fixed deterministic error in the gradient, and shown that accelerated gradient methods achieve the optimal convergence rate up to some accuracy that depends on the fixed error level [20, 21, 22], while the earlier work of [23] analyzes the gradient method in the context of a fixed error level.",
      "startOffset" : 235,
      "endOffset" : 247
    }, {
      "referenceID" : 21,
      "context" : "Several authors have recently analyzed the case of a fixed deterministic error in the gradient, and shown that accelerated gradient methods achieve the optimal convergence rate up to some accuracy that depends on the fixed error level [20, 21, 22], while the earlier work of [23] analyzes the gradient method in the context of a fixed error level.",
      "startOffset" : 235,
      "endOffset" : 247
    }, {
      "referenceID" : 22,
      "context" : "Several authors have recently analyzed the case of a fixed deterministic error in the gradient, and shown that accelerated gradient methods achieve the optimal convergence rate up to some accuracy that depends on the fixed error level [20, 21, 22], while the earlier work of [23] analyzes the gradient method in the context of a fixed error level.",
      "startOffset" : 275,
      "endOffset" : 279
    }, {
      "referenceID" : 23,
      "context" : "Other authors have analyzed the convergence rate of the gradient and projected-gradient methods with a decreasing sequence of errors [24, 25], but this analysis does not consider the important class of accelerated gradient methods.",
      "startOffset" : 133,
      "endOffset" : 141
    }, {
      "referenceID" : 24,
      "context" : "Other authors have analyzed the convergence rate of the gradient and projected-gradient methods with a decreasing sequence of errors [24, 25], but this analysis does not consider the important class of accelerated gradient methods.",
      "startOffset" : 133,
      "endOffset" : 141
    }, {
      "referenceID" : 21,
      "context" : "In contrast, the analysis of [22] allows a decreasing sequence of errors without assuming strong convexity (though convergence rates in this context are not explicitly mentioned) and considers the accelerated projectedgradient method.",
      "startOffset" : 29,
      "endOffset" : 33
    }, {
      "referenceID" : 20,
      "context" : "The analysis of [21] considers errors in both the gradient and projection operators for accelerated projected-gradient methods, but this analysis requires that the domain of the function is compact.",
      "startOffset" : 16,
      "endOffset" : 20
    }, {
      "referenceID" : 25,
      "context" : "In the context of proximal-point algorithms, there is a substantial literature on using inexact proximity operators with a decreasing sequence of errors, dating back to the seminal work of Rockafeller [26].",
      "startOffset" : 201,
      "endOffset" : 205
    }, {
      "referenceID" : 26,
      "context" : "Accelerated proximal-point methods with a decreasing sequence of errors have also been examined, beginning with [27].",
      "startOffset" : 112,
      "endOffset" : 116
    }, {
      "referenceID" : 15,
      "context" : "For example, we can establish that inexact proximal-gradient methods converge under some minor closedness assumptions on the mapping induced by the approximate proximity operator, and the assumption that the algorithm used to compute the inexact proximity operator achieves sufficient descent on problem (2) compared to the previous iteration xk−1 [16].",
      "startOffset" : 348,
      "endOffset" : 352
    }, {
      "referenceID" : 16,
      "context" : "Convergence of inexact proximalgradient methods can also be established under the assumption that the norms of the errors are summable [17].",
      "startOffset" : 135,
      "endOffset" : 139
    }, {
      "referenceID" : 6,
      "context" : "Indeed, as pointed out by [7], even convergence of the accelerated proximalgradient method has not been established under an inexact proximity operator.",
      "startOffset" : 26,
      "endOffset" : 29
    }, {
      "referenceID" : 6,
      "context" : "This gap in the theory is one of the reasons why the authors of [7] chose to use the non-accelerated variant of the proximal-gradient algorithm.",
      "startOffset" : 64,
      "endOffset" : 67
    }, {
      "referenceID" : 11,
      "context" : ", see [12] for the case of overlapping group `1-regularization).",
      "startOffset" : 6,
      "endOffset" : 10
    }, {
      "referenceID" : 29,
      "context" : "We focus on a basic variant of the algorithm where βk is set to (k − 1)/(k + 2) [30]: Proposition 2 (Accelerated proximal-gradient method with errors) Assume that",
      "startOffset" : 80,
      "endOffset" : 84
    }, {
      "referenceID" : 21,
      "context" : "Hence, as also discussed in [22], unlike in the error-free case the accelerated method may not necessarily be better than the basic method because it is more sensitive to errors in the computation.",
      "startOffset" : 28,
      "endOffset" : 32
    }, {
      "referenceID" : 30,
      "context" : "We tested the basic inexact proximal-gradient and accelerated proximal-gradient methods on the CUR-like factorization optimization problem introduced in [31] to approximate a",
      "startOffset" : 153,
      "endOffset" : 157
    }, {
      "referenceID" : 30,
      "context" : "In [31], the authors used an accelerated proximal-gradient method and chose p = ∞ since under this choice the proximity operator can be computed exactly.",
      "startOffset" : 3,
      "endOffset" : 7
    }, {
      "referenceID" : 11,
      "context" : "In this case, it is possible to very quickly compute an approximate proximity operator using the block coordinate descent (BCD) algorithm presented in [12], which is equivalent to the proximal variant of Dykstra’s algorithm introduced by [32].",
      "startOffset" : 151,
      "endOffset" : 155
    }, {
      "referenceID" : 31,
      "context" : "In this case, it is possible to very quickly compute an approximate proximity operator using the block coordinate descent (BCD) algorithm presented in [12], which is equivalent to the proximal variant of Dykstra’s algorithm introduced by [32].",
      "startOffset" : 238,
      "endOffset" : 242
    }, {
      "referenceID" : 30,
      "context" : "In our experiments, we used the four data sets examined by [31]1 and we choose λrow = .",
      "startOffset" : 59,
      "endOffset" : 63
    }, {
      "referenceID" : 32,
      "context" : "An alternative to inexact proximal methods for solving structured sparsity problems are smoothing methods [33] and alternating direction methods [34].",
      "startOffset" : 106,
      "endOffset" : 110
    }, {
      "referenceID" : 33,
      "context" : "An alternative to inexact proximal methods for solving structured sparsity problems are smoothing methods [33] and alternating direction methods [34].",
      "startOffset" : 145,
      "endOffset" : 149
    }, {
      "referenceID" : 6,
      "context" : "Although we have illustrated the use of our results in the context of a structured sparsity problem, inexact proximal-gradient methods are also used in other applications such as total-variation [7, 8] and nuclear-norm [9, 10] regularization.",
      "startOffset" : 195,
      "endOffset" : 201
    }, {
      "referenceID" : 7,
      "context" : "Although we have illustrated the use of our results in the context of a structured sparsity problem, inexact proximal-gradient methods are also used in other applications such as total-variation [7, 8] and nuclear-norm [9, 10] regularization.",
      "startOffset" : 195,
      "endOffset" : 201
    }, {
      "referenceID" : 8,
      "context" : "Although we have illustrated the use of our results in the context of a structured sparsity problem, inexact proximal-gradient methods are also used in other applications such as total-variation [7, 8] and nuclear-norm [9, 10] regularization.",
      "startOffset" : 219,
      "endOffset" : 226
    }, {
      "referenceID" : 9,
      "context" : "Although we have illustrated the use of our results in the context of a structured sparsity problem, inexact proximal-gradient methods are also used in other applications such as total-variation [7, 8] and nuclear-norm [9, 10] regularization.",
      "startOffset" : 219,
      "endOffset" : 226
    }, {
      "referenceID" : 34,
      "context" : "For example, errors in the calculation of the gradien arise when fitting undirected graphical models and using an iterative method to approximate the gradient of the log-partition function [35].",
      "startOffset" : 189,
      "endOffset" : 193
    }, {
      "referenceID" : 35,
      "context" : "Other examples include using a reduced set of training examples within kernel methods [36], or subsampling to solve semidefinite programming problems [37].",
      "startOffset" : 86,
      "endOffset" : 90
    }, {
      "referenceID" : 36,
      "context" : "Other examples include using a reduced set of training examples within kernel methods [36], or subsampling to solve semidefinite programming problems [37].",
      "startOffset" : 150,
      "endOffset" : 154
    }, {
      "referenceID" : 1,
      "context" : "It would be interesting to extend methods for estimating L in the exact case [2] to the case of inexact algorithms.",
      "startOffset" : 77,
      "endOffset" : 80
    }, {
      "referenceID" : 37,
      "context" : "Finally, we note that there has been recent interest in inexact proximal Newton-like methods [38], and it would be interesting to analyze the effect of errors on the convergence rates of these methods.",
      "startOffset" : 93,
      "endOffset" : 97
    }, {
      "referenceID" : 0,
      "context" : "Choosing z = θkx ∗ + (1− θk)xk−1 gives f(xk) 6 εk + f(θkx ∗ + (1− θ)xk−1) + L 〈xk − yk−1, θkx + (1− θk)xk−1 − xk〉+ L 2 ‖xk − yk−1‖ + 〈ek + Lfk, θkx + (1− θk)xk−1 − xk〉 6 εk + θkf(x ∗) + (1− θk)f(xk−1) + L 〈xk − yk−1, θkx + (1− θk)xk−1 − xk〉+ L 2 ‖xk − yk−1‖ + 〈ek + Lfk, θkx + (1− θk)xk−1 − xk〉 (10) using the convexity of f and the fact that θk is in [0, 1].",
      "startOffset" : 352,
      "endOffset" : 358
    }, {
      "referenceID" : 27,
      "context" : "12 of [28] = (1− 2μ L+ μ )‖xk−1 − x∗‖2 + 1 L ( 1 L − 2 L+ μ ) ‖g(xk−1)− g′(x∗)‖2 6 (1− 2μ L+ μ )‖xk−1 − x∗‖2 + μ2 L ( 1 L − 2 L+ μ )‖xk−1 − x∗‖2 using the negativity of 1 L − 2 L+μ and the strong convexity of g = ( 1− μ L )2 ‖xk−1 − x∗‖2.",
      "startOffset" : 6,
      "endOffset" : 10
    }, {
      "referenceID" : 27,
      "context" : "Proof We have (following [28]) xk = yk−1 − 1 L g(yk−1) .",
      "startOffset" : 25,
      "endOffset" : 29
    } ],
    "year" : 2017,
    "abstractText" : "We consider the problem of optimizing the sum of a smooth convex function and a non-smooth convex function using proximal-gradient methods, where an error is present in the calculation of the gradient of the smooth term or in the proximity operator with respect to the non-smooth term. We show that both the basic proximal-gradient method and the accelerated proximal-gradient method achieve the same convergence rate as in the error-free case, provided that the errors decrease at appropriate rates. Using these rates, we perform as well as or better than a carefully chosen fixed error level on a set of structured sparsity problems.",
    "creator" : "LaTeX with hyperref package"
  }
}