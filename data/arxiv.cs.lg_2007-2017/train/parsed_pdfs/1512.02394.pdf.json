{
  "name" : "1512.02394.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "Online Gradient Descent in Function Space",
    "authors" : [ "Changbo Zhu", "Huan Xu" ],
    "emails" : [ "mpexuh}@nus.edu.sg" ],
    "sections" : [ {
      "heading" : null,
      "text" : "ar X\niv :1\n51 2.\n02 39\n4v 1\n[ cs\n.L G\n] 8\nD ec\n2 01"
    }, {
      "heading" : "1 Introduction",
      "text" : "Regret minimization is a general setting used in decision making and prediction. A merge of convex optimization and regret minimization leads to the online convex optimization problem [12]. Due to its simple setting and generality, online convex optimization has raised many attentions recently [12, 22]. Online convex optimization can be modeled as a game: at each time t, the online player chooses a point xt from K ⊂ Rn. Typically, we assume that K is nonempty, closed and convex. After committing to this choice xt, a convex cost function ft is revealed and the player incurs a cost ft(xt). Suppose this game has in total T rounds, we are interested in minimizing the regret – the gap between the actual cost and the cost of the best fixed decision in hindsight:\nRegret(T ) =\nT ∑\nt=1\nft(xt)−min x∈K\nT ∑\nt=1\nft(x).\nZinkevich proposed the following algorithm called online gradient descent [25] for the above problem: play x1 ∈ K arbitrarily and at round t play xt := PK(xt−1 −∇f(xt−1)), where PK stands for projection into K. The regret of online gradient descent is shown upper bounded by O( √ T ). By assuming that all ft has second derivatives bounded below by a strictly positive number, Hazan et al [13] gave an algorithm which can achieve O(log(T )) regret bound. Subsequently, Hazan et al [14] provide an algorithm achieving rates inteplay between O( √ T ) and O(log(T )) without a priori knowledge of the lower bound on the second derivatives. In the above setup, the online player chooses a point in a finite dimensional Euclidean space at each step. However, in many cases, we need to make decisions over a set of functions or random variables. For example, minimizing a risk measure over a set of random variables (chapter 4 in [6]), solving an optimization problem in the space of distribution functions [11] and learning a classifier over a set of functions [16, 18, 19]. In all these cases, we need to consider optimization problems in some infinite dimensional space. In this paper, we propose the online functional gradient algorithm which extends online gradient descent algorithm of Zinkevich [25] to a general Hilbert space (function space). We then establish the regret bound of the algorithm. Since sometimes exact projection to a convex closed set in infinite dimensional space may be hard compute, we also analyze the noisy version of the algorithm when the projection at each step is not accurate. Finally, we illustrate applications of\nour algorithms in online classifier selection, risk measure minimization and distributionally robust stochastic program. Notation: in this paper, we use H to denote a Hilbert space with inner product 〈·, ·〉H and induced norm ‖x‖H = √\n〈x, x〉 for any x ∈ H. Also, let B = {x ∈ H | ‖x‖H ≤ 1} denote the clsoed ball of H and R denote the set of real numbers. Let (Ω,Σ, µ) be a measure space. For 1 ≤ p < ∞, the space Lp(Ω,Σ, µ) is the set of all µ-measurable functions f : Ω → [−∞,+∞] such that ∫\n|f |p dµ < ∞. For a random variable ξ, we use small p to denote its probability density function and big P to denote its probability distribution. Further, for a sequence {ǫt}Tt=1 , we use ǭ to denote its average, i.e. ǭ =\n∑T t=1 ǫt/T ; and Ῡ to denote the average of squares, i.e. Ῡ = ∑T t=1 ǫ 2 t/T. Finally, we use\nP to denote the projection mapping and E to denote the expectation of a random variable."
    }, {
      "heading" : "2 Motivating Examples",
      "text" : "In this section, we provide some examples of problems which need either gradient descent or online gradient descent in the function space."
    }, {
      "heading" : "2.1 Online Classifier Selection",
      "text" : "Assuming that we can collect data points {(xt, yt)}Tt=1 from an unknown distribution P on X×Y, where X ⊆ Rn is the space of data points and Y ⊆ R is the space of labels. Then, we can learn a classifier f : X → Y, which can best predict the label of a data point by solving the following problem\nmin f∈C\n1\nT\nT ∑\nt=1\nl(f(xt), yt), (1)\nwhere C is a predefined set of classifiers and l is the loss function. If f is linear, then (1) can be reduced to a standard minimization problem (like linear SVM) in Rn. A more interesting case is studied in [18], in which the authors considered C as the set of all linear combinations of finitely many base-classifiers and then apply the gradient descent algorithm in a suitable function space to solve the problem. Another example is the nonlinear SVM considered in [21, 7], which is solved by letting C be a certain Reproducing Kernel Hilbert Space (RKHS) and using the representer theorem [15] to convert the problem into an optimization problem in Rn. A natural extension of (1), which we consider in this paper, is its online version. That is, the data points are supplied sequentially, and the goal of learning is to minimize the following regret,\nRegret(T ) = 1\nT\nT ∑\nt=1\nl(ft(xt), yt)−min f∈C\n1\nT\nT ∑\nt=1\nl(f(xt), yt), (2)\nwhere ft ∈ C only depends on {x1, · · · , xt−1, f1, · · · , ft−1} . Notice that in this case, it is challenging to convert Problem (2) into a minimization problem over Rn even with the help of representer theorem, as the data now are supplied sequentially. Hence, it is desirable to develop an online gradient descent algorithm in some proper funtion space to solve Problem (2). We remark that the case when C is an entire Reproducing Kernel Hilbert Space is considered in [16], which is a significantly simpler case than the general setup we considered in this paper, as there is no projection involved."
    }, {
      "heading" : "2.2 Risk Measure Minimization",
      "text" : "Risk Measure is used to quantify and compare uncertain outcomes, which is a central concept in decision theory [1, 20]. In this subsection, let (Ω,Σ, µ) be a probability space, i.e., Ω is a set of outcomes, σ-algebra Σ is a collection of events and µ(Ω) = 1 is a probability measure. Then a real valued random variable X is a µ-measurable function X : Ω → R, which represents an uncertain outcome. We shall focus on the space L2(Ω,Σ, µ), which contains all the random variables X such that ∫ |X |2 dµ < ∞ and is a Hilbert space with inner product defined as 〈X,Y 〉 = ∫\nXY dµ. By a risk measure ρ, we mean a function ρ : L2(Ω,Σ, µ) → R, which assigns a real number to each\nrandom variable (uncertain outcome). Then, a general risk measure minimization problem can be formulated as following\nmin X∈C ρ(X), (3)\nwhere C is typically a subset of L2(Ω,Σ, µ). In practice, uncertain outcomes (random variables) often result from decisions (actions) in some uncertain systems [20]. Mathematically, this can be modeled by a function f : S → L2(Ω,Σ, µ), where S stands for the set of feasible decisions, and is a subset of some vector space V . Then, we have C = f(S) in this case. Problem (3) is generally hard even if we can convert it to an optimization problem in the Euclidean space. On the other hand, under some conditions, we can solve or estimate the true solution by directly doing gradient descent in space L2(Ω,Σ, µ)."
    }, {
      "heading" : "2.3 Distributionally Robust Stochastic Program",
      "text" : "Robust Optimization (RO) is a framework in decision making under uncertainty that has attracted fast growing attention. RO addresses decision problems in which the problem parameter is not specific but known to belong to an uncertainty set [4, 9, 24, 5]. Mathematically, robust optimization problem can be formulated as following\nmin x∈X max ξ∈S f(x, ξ), (4)\nwhere X ⊆ Rm is the feasible set of solutions, ξ is the problem parameter and S ⊆ Rn is the unertainty set. If the uncertainty instead is probabilistic, and is governed by a probability distribution P , which itself is uncertain and belongs to a set of distributions P , we get the following Distributionally Robust Stochastic Program (DRSP) aka Distributionally Robust Optimization [8, 10, 23],\nmin x∈X\n(\nmax P∈P EP [f(x, ξ)]\n)\n, (5)\nwhere X ⊆ Rn and P is the uncertainty set consists of possible distributions of the parameter. Problem (5) is usually harder than Problem (4), because the maximization part is over a subset of some infinite dimensional space. In literature, DRSP is typically solved by exploiting special structures of the uncertainty set P and convert the problem to an optimization problem over Euclidean space. However, this is not always possible. In this paper, we propose a novel solution approach which depends on online gradient descent algorithm in function space. We briefly describe the idea here and defer the full analysis to Section 4.3: At each step t, if a distribution Pt ∈ P is given, then we solve a xt which approximately minimizes the function g(x, Pt) = EPt [f(x, ξ)]. By performing online gradient desent with respect to P , we can upper bound the term maxP g(x̄, P ) by ∑T\nt=1 g(xt, Pt)/T + δ, where x̄ = ( ∑T\nt=1 xt)/T and δ is small. Since, each g(xt, Pt) is small by the construction of xt, we conclude that maxP g(x̄, P ) is also small."
    }, {
      "heading" : "3 Online Functional Gradient Descent",
      "text" : "In this section, we present the online functional gradient descent algorithm and its variants. All proofs are postponed to the supplementary material. We also provide a brief overview of relevant background knowledge from functional analysis in the supplementary material for the completeness. Before presenting our results, we first describe the assumptions on the set, from which the online player make decisions.\nAssumption 1. K ⊆ H is nonempty, closed, convex and K ⊆ RB for some R ∈ R.\nAlso, we make some assumptions on the cost functions received by the player.\nAssumption 2. f : K → R is convex, Gâteaux differentiable over K and all the Gâteaux gradients {∇f(x) |x ∈ K} have finite norm, i.e. ‖∇f(x)‖H < +∞ for all x ∈ K.\nLemma 1. Let C ⊆ H be a nonempty closed convex subset, then for all x ∈ H and x̂ ∈ C, we have\n‖PC(x) − x̂‖H ≤ ‖x− x̂‖H.\nProof. By Theorem 3.14 in [2], we have\n〈x̂−PC(x), x −PC(x)〉H ≤ 0,\nwhich further implies that\n‖PC(x)− x̂‖2H + ‖x−PC(x)‖2H ≤ ‖x− x̂‖2H.\nThroughout this section, let x∗ ∈ K be the optimal solution of ∑Tt=1 ft : K → R or f : K → R over K, then the online functional gradient descent algorithm proceeds as follows: pick x1 ∈ K arbitrarily and for t = 2, · · · , T , choose xt as xt = PK (xt−1 − η∇ft−1 (xt−1)). Then, we have the following theorem upper bounds the regret.\nTheorem 1. [Online Functional Gradient Descent] Suppose K satisfies Assumption 1 and let f1, f2, · · · , fT : K → R be an arbitrary sequence of functions that satisfy Assumption 2. Pick x1 ∈ K arbitrarily and let x2, · · · , xT be defined by xt+1 = PK (xt − η∇ft (xt)) . Let G = maxt ‖∇ft(xt)‖H and select η = R/G √ T , we have\nT ∑\nt=1\nft(xt)− T ∑\nt=1\nft(x ∗) ≤ RG √ T .\nProof. Since each ft is convex, Gâteaux differentiable over K, by Theorem 7.3.6 in [17], there exists a x∗ in K minimizing ∑Tt=1 ft(x). Since ft is convex, by Proposition 17.10 in [2], we have\nft(xt)− ft(x∗) ≤ 〈∇ft(xt), xt − x∗〉H . (6)\nSince K is nonempty, convex and closed, by Lemma 1, we have for all x ∈ H, ‖PK(x) − x∗‖H ≤ ‖x− x∗‖H. So,\n‖xt+1 − x∗‖2H = ‖PK (xt − η∇ft(xt))− x∗‖2H ≤ ‖xt − η∇ft(xt)− x∗‖2H = ‖xt − x∗‖2H + η2‖∇ft(xt)‖2H − 2η 〈∇ft(xt), xt − x∗〉H ≤ ‖xt − x∗‖2H + η2G2 − 2η 〈∇ft(xt), xt − x∗〉H .\nAfter rearranging terms, we have\n〈∇ft(xt), xt − x∗〉H ≤ ‖xt − x∗‖2H − ‖xt+1 − x∗‖2H + η2G2\n2η .\nCombining with equation (6) and summing over t, we have\nT ∑\nt=1\nft(xt)− T ∑\nt=1\nft(x ∗) ≤ R\n2\n2η + T\nηG2\n2\n≤ RG √ T .\nIf we only consider a single function, i.e. all the ft are the same, then the online functional gradient descent reduces to functional gradient descent, with its performance characterized by the following corollary. The idea of gradient descent and variants in function space has appeared before [18, 19, 16], but all these works consider the unconstrained case only, i.e., K = H, and hence is a significantly easier case as no projection is involved.\nCorollary 1 (Functional Gradient Descent). Suppose K satisfies Assumption 1 and f : K → R satisfies Assumption 2. Pick x1 ∈ K arbitrarily and let x2, · · · , xT be defined by xt+1 = PK (xt − η∇f (xt)) . Let G = maxt ‖∇f(xt)‖H and select η = R/G √ T , we have\nf\n(\n1\nT\nT ∑\nt=1\nxt\n)\n− f(x∗) ≤ RG√ T .\nProof. Follows from the convexity of f and Theorem 1.\nIn some cases, the projection PK in general Hilbert space is not easy to calculate exactly. Hence we develop the following results with respect to noisy projection, which shows the online gradient algorithm achieves comparable guarantees if only approximated projection is used at each step.\nTheorem 2 (Online Functional Gradient Descent with Noisy Projection). Suppose K satisfies Assumption 1 and f1, f2, · · · , fT : K → R be an arbitrary sequence of functions that satisfy Assumption 2. Pick x1 ∈ K arbitrarily and let x2, · · · , xT be calculated such that ‖xt+1 − PK (xt − η∇ft (xt)) ‖H ≤ ǫt. Let G = maxt ‖∇ft(xt)‖H and select η = √\nR2/T + 4Rǭ+ Ῡ/G, we have\nT ∑\nt=1\nft(xt)− T ∑\nt=1\nft(x ∗) ≤ RG √ T + ( 2 √ Rǭ+ √ Ῡ ) GT. (7)\nProof. Since each ft is convex, Gâteaux differentiable over K, by Theorem 7.3.6 in [17], there exists a x∗ in K minimizing ∑Tt=1 ft(x). Since ft is convex, by Proposition 17.10 in [2], we have ft(xt)− ft(x∗) ≤ 〈∇ft(xt), xt − x∗〉H . (8) Since K is nonempty, convex and closed, by Lemma 1, we have for all x ∈ H, ‖PK(x) − x∗‖H ≤ ‖x− x∗‖H. So,\n‖xt+1 − x∗‖2H ≤ (‖xt+1 −PK(xt − η∇ft(xt))‖H + ‖PK(xt − η∇ft(xt))− x∗‖H)2\n≤ ‖xt − η∇ft(xt)− x∗‖2H + 4Rǫt + ǫ2t = ‖xt − x∗‖2H + η2‖∇ft(xt)‖2H − 2η 〈∇ft(xt), xt − x∗〉H + 4Rǫt + ǫ2t ≤ ‖xt − x∗‖2H + η2G2 − 2η 〈∇ft(xt), xt − x∗〉H + 4Rǫt + ǫ2t .\nAfter rearranging terms, we have\n〈∇ft(xt), xt − x∗〉H ≤ ‖xt − x∗‖2H − ‖xt+1 − x∗‖2H + η2G2 + 4Rǫt + ǫ2t\n2η .\nCombining with equation (8) and summing over t, we have\nT ∑\nt=1\nft(xt)− T ∑\nt=1\nft(x ∗) ≤ R\n2 + ∑T t=1(4Rǫt + ǫ 2 t )\n2η + T\nηG2\n2\n= G\n√ √ √\n√R2T + T ∑\nt=1\n(4Rǫt + ǫ2t ) T\n≤ RG √ T + ( 2 √ Rǭ+ √ Ῡ ) GT.\nSimilarly, when all the functions {ft} are the same, we have the following result: Corollary 2. [Functional Gradient Descent with Noisy Projection] Suppose K satisfies Assumption 1 and f : K → R satisfies Assumption 2. Pick x1 ∈ K arbitrarily and let x2, · · · , xT be calculated such that ‖xt+1 − PK (xt − η∇f (xt)) ‖H ≤ ǫt. Let G = maxt ‖∇f(xt)‖H and select η = √ R2/T + 4Rǭ+ Ῡ/G, we have\nf\n(\n1\nT\nT ∑\nt=1\nxt\n)\n− f(x∗) ≤ RG√ T + (\n2 √ Rǭ+ √ Ῡ ) G.\nProof. Follows from the convexity of f and Theorem 2.\nWe remark that the Gâteaux differentiability used in previous results is to guarantee that the optimal solution x∗ exists in C. We can relax this assumption and use subgradient instead, which leads to the following results:\nAssumption 3. f : K → R is convex, subdifferentiable function over K and all the subgradients {ux |x ∈ K and ux ∈ ∂f(x)} have finite norm, i.e. ‖ux‖H < +∞ for all x ∈ K and ux ∈ ∂f(x).\nCorollary 3. Suppose K satisfies Assumption 1 and f1, f2, · · · , fT : K → R be an arbitrary sequence of functions that satisfy Assumption 3. Pick x1 ∈ K arbitrarily and let x2, · · · , xT be calculated such that ‖xt+1 −PK (xt − ηut) ‖H ≤ ǫt, where ut ∈ ∂ft(xt). Let G = maxt ‖ut‖H and select η = √ R2/T + 4Rǭ+ Ῡ/G, we have\nT ∑\nt=1\nft(xt)− T ∑\nt=1\nft(x) ≤ RG √ T + ( 2 √ Rǭ+ √ Ῡ ) GT, for all x ∈ K.\nProof. By the definition of subgradient, it holds that\nft(xt)− ft(x) ≤ 〈ut, xt − x〉H for all x ∈ H and ut ∈ ∂ft(xt). (9)\nThen, replace equation (8) with (9) and change ∇ft(xt) to ut in the rest proof of Theorem 2, we can prove the result.\nCorollary 4. Suppose K satisfies Assumption 1 and f : K → R satisfies Assumption 3. Pick x1 ∈ K arbitrarily and let x2, · · · , xT be calculated such that ‖xt+1 −PK (xt − ηut) ‖H ≤ ǫt, where ut ∈ ∂f(xt). Let G = maxt ‖ut‖H and select η = √ R2/T + 4Rǭ+ Ῡ/G, we have\nf\n(\n1\nT\nT ∑\nt=1\nxt\n)\n− f(x) ≤ RG√ T + (\n2 √ Rǭ+ √ Ῡ ) G, for all x ∈ K.\nProof. Follows from the convexity of f and Corollary 2."
    }, {
      "heading" : "3.1 Calculate the Projection",
      "text" : "Here, we introduce some exact formulas to calculate projections onto some common sets and refer Chapter 28 in [2] for a comprehensive study of the projection operator in Hilbert space. The following two examples show that it is easy to project a point onto a closed ball or a hyperplane.\nExample 1. Let B ⊆ H be the closed ball with radius 1, then\n∀x ∈ H PB(x) = 1\nmax {‖x‖H, 1} x.\nExample 2. Let u ∈ H be a nonzero vector, let η ∈ R and set C = {x ∈ H| 〈x, u〉H = η}, then we have\n∀x ∈ H PC(x) = x+ η−〈x,u〉H‖u‖2 H u.\nSometimes, a function f ∈ L2(Ω,Σ, µ) is required to have nonnegative values (e.g., density functions), in which case we have the following formula:\nExample 3. Set C = { p ∈ L2(Ω,Σ, µ) | p ≥ 0 } , then for any q ∈ L2(Ω,Σ, µ), the projection PC(q) is given by\nPC(q) = [q]+ , where for all x ∈ Ω, [q]+ (x) = { q(x) if q(x) ≥ 0, 0 if q(x) < 0.\nThe following algorithm explains how to project a point onto the intersection of multiple sets, if calculating the projection onto each set is easy.\nTheorem 3 (Dykstra’s Algorithm). Let m be a strictly positive integer, set I = {1, · · · ,m}, let (Ci)i∈I be a family of closed convex subsets of H such that C = ∩i∈ICi 6= ∅, and let x0 ∈ H. Set\ni : N → I as i(n) = 1 + rem(n− 1,m),\nwhere rem(·,m) is the remainder function of the division by m. For every strictly positive integer n, set Pn = PCn , where Cn = Ci(n) if n > m. Moreover, set q−(m−1) = · · · = q−1 = q0 = 0 and\n(∀n ∈ N {0} ) {\nxn = Pn(xn−1 + qn−m), qn = xn−1 + qn−m − xn.\nThen xn → PC(x0)."
    }, {
      "heading" : "4 Applications",
      "text" : "In this section, we discuss some concrete examples to illustrate how to apply the developed framework. In particular, how to compute the corresponding derivatives and the projections. For each particular application, a suitable Hilbert space is chosen."
    }, {
      "heading" : "4.1 Online Classifier Selection",
      "text" : "The online classifier selection problem is described above in Section 2.1. Here, let H be a Reproducing Kernel Hilbert Space of real valued functions defined on X ⊆ Rn and associated with a reproducing kernel k : X× X → R. We consider the problem of minimizing the following regret:\nRegret(T ) = 1\nT\nT ∑\nt=1\nlt (ft)−min f∈C\n1\nT\nT ∑\nt=1\nlt (f) , (10)\nwhere {lt} and C are defined by \n \n \nlt(f) = (f(xt)− yt)2 , C = (\n⋂m i=1 Ĉi\n)\n∩RB, where B is the closed ball of H, Given gi ∈ H, ai ∈ R, we have Ĉi = {f ∈ H| 〈f, gi〉H = ai} .\nEach Ĉi corresponds to a linear constraint imposed on f . For instance, suppose we want to guarantee that f(x1) = 1 (e.g., (x1, 1) is a sample of high-confidence), we can add the linear constraint 〈k(·, x1), f〉H = 1. For the above problem, we can apply the online functional gradient descent algorithm, in which projection and gradient are calculated as follows: Gradient: we first calculate the gradient of lt for t = 1, · · · , T\nfor any h ∈ H, ∇lt(f)(h) = lim α↓0 lt(f + αh)− lt(f) α\n= lim α↓0 (f(xt) + αh(xt)− yt)2 − (f(xt)− yt)2 α =2 (f(xt)− yt)h(xt), = 〈2 (f(xt)− yt) k(·, xt), h〉H (reproducing property).\nBy Remark 2.44 in [2], we have ∇lt(f) = 2 (f(xt)− yt) k(·, xt). Projection: for any g ∈ H, we calculate the projection PC(g) onto C. Firstly, we can use Example 2 to calculate the projection PĈi(g) onto each Ĉi and Example 1 to calculate the projection PRB(g) onto RB. Then, we can calculate the projection onto the intersection of Ĉi and RB, i.e. onto C, using Theorem 3."
    }, {
      "heading" : "4.2 Risk Measure Minimization",
      "text" : "The risk measure minimization problem is introduced in Section 2.2. Here, we consider the following mean variance risk measure minimization problem as a concrete example:\nmin X∈C\nE(X) + c‖X −E(X)‖2L2(Ω,Σ,µ),\nwhere c ≥ 0 is a given constant and C is defined as \n\n\nC = (\n⋂m i=1 Ĉi\n)\n∩RB, where B is the closed ball of L2(Ω,Σ, µ), Given Yi ∈ L2(Ω,Σ, µ), ai ∈ R, we have Ĉi = { X ∈ L2(Ω,Σ, µ) ∣ ∣ 〈X,Yi〉L2(Ω,Σ,µ) = ai } .\nNotice that each Ĉi is a linear constraint which stands for E(XYi) = ai. In particular, if Yi(x) ≡ 1 for all x ∈ Ω, then Ĉi is the set of random variables whose mean is ai. Set ρ(X) = E(X) + c‖X − E(X)‖2L2(Ω,Σ,µ), it is proved in [6] (Chapter4 page128) that ρ is convex. Also, the derivative and projection can be calculated as following: Gradient: we first calculate the gradient of ρ at X , for any Y ∈ L2(Ω,Σ, µ),\n∇ρ(X)(Y ) = lim α↓0 ρ(X + αY )− ρ(X) α\n= lim α↓0\n∫ αY dµ+ c‖X + αY − ∫ X + αY dµ‖2L2(Ω,Σ,µ) − c‖X − ∫ X dµ‖2L2(Ω,Σ,µ) α\n=\n∫\nY dµ+ 2c\n〈\nX − ∫ X dµ, Y − ∫ Y dµ\n〉\nL2(Ω,Σ,µ)\n= 〈1 + 2cX − 2cE(X), Y 〉L2(Ω,Σ,µ) .\nSo, we have ∇ρ(X) = 1 + 2cX − 2cE(X). Projection: for any Y ∈ L2(Ω,Σ, µ), the projection onto each Ĉi and RB can be calculated seperately by Example 2 and 1. Then, we can use Theorem 3 to calculate the projection onto C."
    }, {
      "heading" : "4.3 Distributionally Robust Stochastic Program",
      "text" : "Applying online functional gradient descent to solve Distributionally Robust Stochastic Program is more involved than the previous examples. Here, we consider a slightly different version of Problem (5), i.e., we focus on probability density functions instead of probability distributions. In particular, we consider the space L2(Rn) = L2 (Rn,Σ, µ), where Σ and µ are the σ-algebra of Lebesgue measurable sets and the Lebesgue measure on Rn respectively. Then, L2(Rn) is a Hilbert space with inner product defined as 〈f, g〉L2 = ∫\nfg dµ. Correspondingly, the induced norm on L2(Rn) is ‖ · ‖L2 and we use BL2 to denote the closed ball of L2(Rn). Assuming that ξ is a random variable with probability density function p ∈ P , then the Distributionally Robust Stochastic Program can be written as\nmin x∈X\n(\nmax p∈P Ep [f(x, ξ)]\n)\n, (11)\nwhere X ⊆ Rn and P ⊆ L2(Rn) is a set of probability density functions. The main idea to solve this problem is inspired by [3], in which they use online learning methods to solve (arguably easier) Robust Optimization. Optimization via Binary Search: We first convert the optimization problem into a decision problem. Suppose we know the feasible range of the objective value of maxp∈P Ep [f(x, ξ)], Problem (11) can be solved by a binary search procedure in the following way: let b be our current guess of the optimal value and shift f downwards by b, i.e., h(x, ξ) = f(x, ξ) − b. Then, we solve the following decision problem, i.e., a YES or NO problem,\n∃?x ∈ Rn such that Ep [h(x, ξ)] ≤ 0 ∀p ∈ P . (12)\nAn answer YES means the true optimal value is smaller than b and NO means larger. Correspondingly, if the answer is YES (NO), we should make our new guess smaller (bigger). In the rest of the section we will focus on solving Problem (12). We say that x is a δ-approximate solution to Problem (12) if Ep [h(x, ξ)] ≤ δ for all p ∈ P . In the following, we will use online functional gradient descent with noisy projection to get a 2δ-approximate solution to Problem (12). Oracle: notice that if we fix p ∈ P , then Ep [h(x, ξ)] is a function mapping from Rn to R. We assume this finite dimensional function is easy to optimize. In particular, we assume that there exists an Oracle Oδ such that given any p ∈ P , it either returns a x ∈ X such that\nEp [h(x, ξ)] ≤ δ,\nor return “infeasible” if there does not exist a vector x ∈ X such that\nEp [h(x, ξ)] ≤ 0."
    }, {
      "heading" : "4.3.1 Functional Dual Gradient Descent",
      "text" : "Setting g(x, p) = Ep [h(x, ξ)], we assume that g is convex in x (which is true when h(·, ξ) is convex), P ⊆ RBL2 is convex and maxx,p ‖∇pg(x, p)‖L2 ≤ G. Then, we propose the following algorithm to solve Problem (12).\nAlgorithm 1: Functional Dual Gradient Descent with Noisy Projection\ninput : δ,G Initialize p0 ∈ P arbitrarily Choose T , {ǫt}Tt=1 such that RG√T + ( 2 √ Rǭ+ √ Ῡ ) G ≤ δ and set η = √ R2/T + 4Rǭ+ Ῡ/G for t = 1, 2, · · · , T do Calculate pt such that pt ∈ P and ‖pt −PP (pt−1 + η∇pg(xt−1, pt−1)) ‖L2 ≤ ǫt Set xt = Oδ(pt) if the Oracle declared infeasibility then\nreturn “NO”\nreturn x̄ = 1 T ∑T t=1 xt\nTheorem 4. Algorithm 1 either returns an 2δ-approximate solution or concludes that the answer is “No” for Problem (12).\nProof. First, if the algorithm returns “NO”, then by the definition of the Oracle, for some t, there does not exists x ∈ Rn such that Ept [h(x, ξ)] ≤ 0, which means the answer to Problem (12) is “NO”. Second, otherwise, then a solution is returned, and the premise of the oracle implies that\n1\nT\nT ∑\nt=1\ng(xt, pt) ≤ δ.\nFrom the regret guarantee of the online functional gradient descent algorithm we have\nmax p∈P\n1\nT\nT ∑\nt=1\ng(xt, p)− 1\nT\nT ∑\nt=1\ng(xt, pt) ≤ RG√ T + (\n2 √ Rǭ+ √ Ῡ ) G ≤ δ.\nWe conclude that\nδ ≥ 1 T\nT ∑\nt=1\ng(xt, pt) ≥ max p∈P\n1\nT\nT ∑\nt=1\ng(xt, p)− δ ≥ max p∈P g(x̄, p)− δ.\nHence, we have g(x̄, p) ≤ 2δ for all p ∈ P ."
    }, {
      "heading" : "4.3.2 A Concrete Example",
      "text" : "In this subsection, we consider the following simple example to illustrate how to solve DRSP via the framework outlined above:\nmin x∈B max p∈P\nEp [ (xT ξ)2 ] , (13)\nwhere B ⊆ R2 is the closed ball ofR2, the random variable ξ takes value fromC = { (x, y) |x2 + y2 ≤ 1, x ≥ 0, y ≥ 0 } and the uncertainty set P is defined as\nP = { p ∈ L2(R2) ∣ ∣ Ep [ξ] = b ∈ R2, p ≥ 0, ∫\nC p dµ = 1,\n∫\nC |p|2 dµ ≤ 2\n}\n.\nWe define the characteristic function χC by χC(x) = 1 if x ∈ C and χC(x) = 0 otherwise. Further, set ξ = (ξ1, ξ2) T and t = (t1, t2) T with ti(x) = xi for x ∈ R2, i = 1, 2. Then, we can write P = P1 ∩ P2 ∩ P3 ∩ P4 ∩ P5, where {\nPi = { p ∈ L2(R2) | Ep(ξi) = 〈tiχC, p〉L2 = bi }\nfor i = 1, 2; P3 = { p ∈ L2(R2) | p ≥ 0 } ,P4 = { p ∈ L2(R2) |〈χC, p〉L2 = 1 } ,P5 = 2BL2.\nWe can solve Problem (13) using Algorithm 1, in which the gradient and projection can be calculated as following: Gradient: fix any x ∈ R2 and set g(p) = Ep [ (xT ξ)2 ] , we calculate ∇g(p) with respect to p,\nfor any q ∈ L2(R2), ∇g(p)(q) = lim α↓0 g(p+ αq)− g(p) α\n= lim α↓0\n∫\nχC(x T t)2(p+ αq) dµ−\n∫\nχC(x T t)2p dµ\nα\n= 〈 χC(x T t)2, q 〉 .\nHence, we conclude ∇g(p) = χC(xT t)2. Projection: for any q ∈ L2(R2), the projection onto P3 and P5 can be calculated by Example 3 and Example 1 respectively. Also, the projection onto P1,P2 and P4 can be calculated by Example 2. Finally, we approximate the projection onto P by Dykstra’s algorithm described in Theorem 3."
    }, {
      "heading" : "5 Conclusion",
      "text" : "In this work, we consider online learning in infinite dimensional space. In particular, we propose an online learning algorithm called online functional gradient descent, which extends the well known online gradient descent algorithm of Zinkevich [25]. We then provide theoretical results for the proposed algorithms. Finally, we illustrate how to apply our algorithm into practical problems in machine learning and operations research, including online classifier selection, risk measure minimization and distributionally robust optimization."
    } ],
    "references" : [ {
      "title" : "Coherent measures of risk",
      "author" : [ "Philippe Artzner", "Freddy Delbaen", "Jean-Marc Eber", "David Heath" ],
      "venue" : "Mathematical finance,",
      "citeRegEx" : "1",
      "shortCiteRegEx" : "1",
      "year" : 1999
    }, {
      "title" : "Convex analysis and monotone operator theory in Hilbert spaces",
      "author" : [ "Heinz H Bauschke", "Patrick L Combettes" ],
      "venue" : "Springer Science & Business Media,",
      "citeRegEx" : "2",
      "shortCiteRegEx" : "2",
      "year" : 2011
    }, {
      "title" : "Robust convex optimization",
      "author" : [ "Aharon Ben-Tal", "Arkadi Nemirovski" ],
      "venue" : "Mathematics of Operations Research,",
      "citeRegEx" : "4",
      "shortCiteRegEx" : "4",
      "year" : 1998
    }, {
      "title" : "The price of robustness",
      "author" : [ "Dimitris Bertsimas", "Melvyn Sim" ],
      "venue" : "Operations research,",
      "citeRegEx" : "5",
      "shortCiteRegEx" : "5",
      "year" : 2004
    }, {
      "title" : "Probabilistic and randomized methods for design under uncertainty",
      "author" : [ "Giuseppe Calafiore", "Fabrizio Dabbene" ],
      "venue" : null,
      "citeRegEx" : "6",
      "shortCiteRegEx" : "6",
      "year" : 2006
    }, {
      "title" : "Distributionally robust optimization under moment uncertainty with application to data-driven problems",
      "author" : [ "Erick Delage", "Yinyu Ye" ],
      "venue" : "Operations research,",
      "citeRegEx" : "8",
      "shortCiteRegEx" : "8",
      "year" : 2010
    }, {
      "title" : "Robust solutions to least-square problems to uncertain data matrices",
      "author" : [ "L EI-Ghaoui", "H Lebret" ],
      "venue" : "Sima Journal on Matrix Analysis and Applications,",
      "citeRegEx" : "9",
      "shortCiteRegEx" : "9",
      "year" : 1997
    }, {
      "title" : "Distributionally robust optimization and its tractable approximations",
      "author" : [ "Joel Goh", "Melvyn Sim" ],
      "venue" : "Operations research,",
      "citeRegEx" : "10",
      "shortCiteRegEx" : "10",
      "year" : 2010
    }, {
      "title" : "Optimization in the space of distribution functions and applications in the Bayes analysis",
      "author" : [ "Alexandr N Golodnikov", "Pavel S Knopov", "Panos M Pardalos", "Stanislav P Uryasev" ],
      "venue" : null,
      "citeRegEx" : "11",
      "shortCiteRegEx" : "11",
      "year" : 2000
    }, {
      "title" : "The convex optimization approach to regret minimization. Optimization for machine learning, pages",
      "author" : [ "Elad Hazan" ],
      "venue" : null,
      "citeRegEx" : "12",
      "shortCiteRegEx" : "12",
      "year" : 2011
    }, {
      "title" : "Logarithmic regret algorithms for online convex optimization",
      "author" : [ "Elad Hazan", "Amit Agarwal", "Satyen Kale" ],
      "venue" : "Machine Learning,",
      "citeRegEx" : "13",
      "shortCiteRegEx" : "13",
      "year" : 2007
    }, {
      "title" : "Adaptive online gradient descent",
      "author" : [ "Elad Hazan", "Alexander Rakhlin", "Peter L Bartlett" ],
      "venue" : "In Advances in Neural Information Processing Systems,",
      "citeRegEx" : "14",
      "shortCiteRegEx" : "14",
      "year" : 2007
    }, {
      "title" : "A correspondence between bayesian estimation on stochastic processes and smoothing by splines",
      "author" : [ "George S Kimeldorf", "Grace Wahba" ],
      "venue" : "The Annals of Mathematical Statistics,",
      "citeRegEx" : "15",
      "shortCiteRegEx" : "15",
      "year" : 1970
    }, {
      "title" : "Online learning with kernels",
      "author" : [ "Jyrki Kivinen", "Alexander J Smola", "Robert C Williamson" ],
      "venue" : "Signal Processing, IEEE Transactions on,",
      "citeRegEx" : "16",
      "shortCiteRegEx" : "16",
      "year" : 2004
    }, {
      "title" : "Convex functional analysis",
      "author" : [ "Andrew J Kurdila", "Michael Zabarankin" ],
      "venue" : "Springer Science & Business Media,",
      "citeRegEx" : "17",
      "shortCiteRegEx" : "17",
      "year" : 2006
    }, {
      "title" : "Boosting algorithms as gradient descent in function space",
      "author" : [ "Llew Mason", "Jonathan Baxter", "Peter Bartlett", "Marcus Frean" ],
      "venue" : null,
      "citeRegEx" : "18",
      "shortCiteRegEx" : "18",
      "year" : 1999
    }, {
      "title" : "Grafting: Fast, incremental feature selection by gradient descent in function space",
      "author" : [ "Simon Perkins", "Kevin Lacker", "James Theiler" ],
      "venue" : "The Journal of Machine Learning Research,",
      "citeRegEx" : "19",
      "shortCiteRegEx" : "19",
      "year" : 2003
    }, {
      "title" : "Optimization of convex risk functions",
      "author" : [ "Andrzej Ruszczynski", "Alexander Shapiro" ],
      "venue" : "Mathematics of operations research,",
      "citeRegEx" : "20",
      "shortCiteRegEx" : "20",
      "year" : 2006
    }, {
      "title" : "Learning with Kernels: Support Vector Machines, Regularization, Optimization, and Beyond",
      "author" : [ "Bernhard Scholkopf", "Alexander J. Smola" ],
      "venue" : null,
      "citeRegEx" : "21",
      "shortCiteRegEx" : "21",
      "year" : 2001
    }, {
      "title" : "Online learning and online convex optimization",
      "author" : [ "Shai Shalev-Shwartz" ],
      "venue" : "Foundations and Trends in Machine Learning,",
      "citeRegEx" : "22",
      "shortCiteRegEx" : "22",
      "year" : 2011
    }, {
      "title" : "A distributional interpretation of robust optimization",
      "author" : [ "Huan Xu", "Constantine Caramanis", "Shie Mannor" ],
      "venue" : "Mathematics of Operations Research,",
      "citeRegEx" : "23",
      "shortCiteRegEx" : "23",
      "year" : 2012
    }, {
      "title" : "Robustness and generalization",
      "author" : [ "Huan Xu", "Shie Mannor" ],
      "venue" : "Machine learning,",
      "citeRegEx" : "24",
      "shortCiteRegEx" : "24",
      "year" : 2012
    }, {
      "title" : "Online convex programming and generalized infinitesimal gradient ascent",
      "author" : [ "Martin Zinkevich" ],
      "venue" : "In Proceedings of the Twentieth International Conference on Machine Learning,",
      "citeRegEx" : "25",
      "shortCiteRegEx" : "25",
      "year" : 2003
    } ],
    "referenceMentions" : [ {
      "referenceID" : 9,
      "context" : "A merge of convex optimization and regret minimization leads to the online convex optimization problem [12].",
      "startOffset" : 103,
      "endOffset" : 107
    }, {
      "referenceID" : 9,
      "context" : "Due to its simple setting and generality, online convex optimization has raised many attentions recently [12, 22].",
      "startOffset" : 105,
      "endOffset" : 113
    }, {
      "referenceID" : 19,
      "context" : "Due to its simple setting and generality, online convex optimization has raised many attentions recently [12, 22].",
      "startOffset" : 105,
      "endOffset" : 113
    }, {
      "referenceID" : 22,
      "context" : "Zinkevich proposed the following algorithm called online gradient descent [25] for the above problem: play x1 ∈ K arbitrarily and at round t play xt := PK(xt−1 −∇f(xt−1)), where PK stands for projection into K.",
      "startOffset" : 74,
      "endOffset" : 78
    }, {
      "referenceID" : 10,
      "context" : "By assuming that all ft has second derivatives bounded below by a strictly positive number, Hazan et al [13] gave an algorithm which can achieve O(log(T )) regret bound.",
      "startOffset" : 104,
      "endOffset" : 108
    }, {
      "referenceID" : 11,
      "context" : "Subsequently, Hazan et al [14] provide an algorithm achieving rates inteplay between O( √ T ) and O(log(T )) without a priori knowledge of the lower bound on the second derivatives.",
      "startOffset" : 26,
      "endOffset" : 30
    }, {
      "referenceID" : 4,
      "context" : "For example, minimizing a risk measure over a set of random variables (chapter 4 in [6]), solving an optimization problem in the space of distribution functions [11] and learning a classifier over a set of functions [16, 18, 19].",
      "startOffset" : 84,
      "endOffset" : 87
    }, {
      "referenceID" : 8,
      "context" : "For example, minimizing a risk measure over a set of random variables (chapter 4 in [6]), solving an optimization problem in the space of distribution functions [11] and learning a classifier over a set of functions [16, 18, 19].",
      "startOffset" : 161,
      "endOffset" : 165
    }, {
      "referenceID" : 13,
      "context" : "For example, minimizing a risk measure over a set of random variables (chapter 4 in [6]), solving an optimization problem in the space of distribution functions [11] and learning a classifier over a set of functions [16, 18, 19].",
      "startOffset" : 216,
      "endOffset" : 228
    }, {
      "referenceID" : 15,
      "context" : "For example, minimizing a risk measure over a set of random variables (chapter 4 in [6]), solving an optimization problem in the space of distribution functions [11] and learning a classifier over a set of functions [16, 18, 19].",
      "startOffset" : 216,
      "endOffset" : 228
    }, {
      "referenceID" : 16,
      "context" : "For example, minimizing a risk measure over a set of random variables (chapter 4 in [6]), solving an optimization problem in the space of distribution functions [11] and learning a classifier over a set of functions [16, 18, 19].",
      "startOffset" : 216,
      "endOffset" : 228
    }, {
      "referenceID" : 22,
      "context" : "In this paper, we propose the online functional gradient algorithm which extends online gradient descent algorithm of Zinkevich [25] to a general Hilbert space (function space).",
      "startOffset" : 128,
      "endOffset" : 132
    }, {
      "referenceID" : 15,
      "context" : "A more interesting case is studied in [18], in which the authors considered C as the set of all linear combinations of finitely many base-classifiers and then apply the gradient descent algorithm in a suitable function space to solve the problem.",
      "startOffset" : 38,
      "endOffset" : 42
    }, {
      "referenceID" : 18,
      "context" : "Another example is the nonlinear SVM considered in [21, 7], which is solved by letting C be a certain Reproducing Kernel Hilbert Space (RKHS) and using the representer theorem [15] to convert the problem into an optimization problem in R.",
      "startOffset" : 51,
      "endOffset" : 58
    }, {
      "referenceID" : 12,
      "context" : "Another example is the nonlinear SVM considered in [21, 7], which is solved by letting C be a certain Reproducing Kernel Hilbert Space (RKHS) and using the representer theorem [15] to convert the problem into an optimization problem in R.",
      "startOffset" : 176,
      "endOffset" : 180
    }, {
      "referenceID" : 13,
      "context" : "We remark that the case when C is an entire Reproducing Kernel Hilbert Space is considered in [16], which is a significantly simpler case than the general setup we considered in this paper, as there is no projection involved.",
      "startOffset" : 94,
      "endOffset" : 98
    }, {
      "referenceID" : 0,
      "context" : "2 Risk Measure Minimization Risk Measure is used to quantify and compare uncertain outcomes, which is a central concept in decision theory [1, 20].",
      "startOffset" : 139,
      "endOffset" : 146
    }, {
      "referenceID" : 17,
      "context" : "2 Risk Measure Minimization Risk Measure is used to quantify and compare uncertain outcomes, which is a central concept in decision theory [1, 20].",
      "startOffset" : 139,
      "endOffset" : 146
    }, {
      "referenceID" : 17,
      "context" : "In practice, uncertain outcomes (random variables) often result from decisions (actions) in some uncertain systems [20].",
      "startOffset" : 115,
      "endOffset" : 119
    }, {
      "referenceID" : 2,
      "context" : "RO addresses decision problems in which the problem parameter is not specific but known to belong to an uncertainty set [4, 9, 24, 5].",
      "startOffset" : 120,
      "endOffset" : 133
    }, {
      "referenceID" : 6,
      "context" : "RO addresses decision problems in which the problem parameter is not specific but known to belong to an uncertainty set [4, 9, 24, 5].",
      "startOffset" : 120,
      "endOffset" : 133
    }, {
      "referenceID" : 21,
      "context" : "RO addresses decision problems in which the problem parameter is not specific but known to belong to an uncertainty set [4, 9, 24, 5].",
      "startOffset" : 120,
      "endOffset" : 133
    }, {
      "referenceID" : 3,
      "context" : "RO addresses decision problems in which the problem parameter is not specific but known to belong to an uncertainty set [4, 9, 24, 5].",
      "startOffset" : 120,
      "endOffset" : 133
    }, {
      "referenceID" : 5,
      "context" : "If the uncertainty instead is probabilistic, and is governed by a probability distribution P , which itself is uncertain and belongs to a set of distributions P , we get the following Distributionally Robust Stochastic Program (DRSP) aka Distributionally Robust Optimization [8, 10, 23], min x∈X (",
      "startOffset" : 275,
      "endOffset" : 286
    }, {
      "referenceID" : 7,
      "context" : "If the uncertainty instead is probabilistic, and is governed by a probability distribution P , which itself is uncertain and belongs to a set of distributions P , we get the following Distributionally Robust Stochastic Program (DRSP) aka Distributionally Robust Optimization [8, 10, 23], min x∈X (",
      "startOffset" : 275,
      "endOffset" : 286
    }, {
      "referenceID" : 20,
      "context" : "If the uncertainty instead is probabilistic, and is governed by a probability distribution P , which itself is uncertain and belongs to a set of distributions P , we get the following Distributionally Robust Stochastic Program (DRSP) aka Distributionally Robust Optimization [8, 10, 23], min x∈X (",
      "startOffset" : 275,
      "endOffset" : 286
    }, {
      "referenceID" : 1,
      "context" : "14 in [2], we have 〈x̂−PC(x), x −PC(x)〉H ≤ 0, which further implies that ‖PC(x)− x̂‖H + ‖x−PC(x)‖H ≤ ‖x− x̂‖H.",
      "startOffset" : 6,
      "endOffset" : 9
    }, {
      "referenceID" : 14,
      "context" : "6 in [17], there exists a x∗ in K minimizing ∑Tt=1 ft(x).",
      "startOffset" : 5,
      "endOffset" : 9
    }, {
      "referenceID" : 1,
      "context" : "10 in [2], we have ft(xt)− ft(x) ≤ 〈∇ft(xt), xt − x〉H .",
      "startOffset" : 6,
      "endOffset" : 9
    }, {
      "referenceID" : 15,
      "context" : "The idea of gradient descent and variants in function space has appeared before [18, 19, 16], but all these works consider the unconstrained case only, i.",
      "startOffset" : 80,
      "endOffset" : 92
    }, {
      "referenceID" : 16,
      "context" : "The idea of gradient descent and variants in function space has appeared before [18, 19, 16], but all these works consider the unconstrained case only, i.",
      "startOffset" : 80,
      "endOffset" : 92
    }, {
      "referenceID" : 13,
      "context" : "The idea of gradient descent and variants in function space has appeared before [18, 19, 16], but all these works consider the unconstrained case only, i.",
      "startOffset" : 80,
      "endOffset" : 92
    }, {
      "referenceID" : 14,
      "context" : "6 in [17], there exists a x∗ in K minimizing ∑Tt=1 ft(x).",
      "startOffset" : 5,
      "endOffset" : 9
    }, {
      "referenceID" : 1,
      "context" : "10 in [2], we have ft(xt)− ft(x) ≤ 〈∇ft(xt), xt − x〉H .",
      "startOffset" : 6,
      "endOffset" : 9
    }, {
      "referenceID" : 1,
      "context" : "1 Calculate the Projection Here, we introduce some exact formulas to calculate projections onto some common sets and refer Chapter 28 in [2] for a comprehensive study of the projection operator in Hilbert space.",
      "startOffset" : 137,
      "endOffset" : 140
    }, {
      "referenceID" : 1,
      "context" : "44 in [2], we have ∇lt(f) = 2 (f(xt)− yt) k(·, xt).",
      "startOffset" : 6,
      "endOffset" : 9
    }, {
      "referenceID" : 4,
      "context" : "Set ρ(X) = E(X) + c‖X − E(X)‖L2(Ω,Σ,μ), it is proved in [6] (Chapter4 page128) that ρ is convex.",
      "startOffset" : 56,
      "endOffset" : 59
    }, {
      "referenceID" : 22,
      "context" : "In particular, we propose an online learning algorithm called online functional gradient descent, which extends the well known online gradient descent algorithm of Zinkevich [25].",
      "startOffset" : 174,
      "endOffset" : 178
    } ],
    "year" : 2016,
    "abstractText" : "In many problems in machine learning and operations research, we need to optimize a function whose input is a random variable or a probability density function, i.e. to solve optimization problems in an infinite dimensional space. On the other hand, online learning has the advantage of dealing with streaming examples, and better model a changing environment. In this paper, we extend the celebrated online gradient descent algorithm to Hilbert spaces (function spaces), and analyze the convergence guarantee of the algorithm. Finally, we demonstrate that our algorithms can be useful in several important problems.",
    "creator" : "LaTeX with hyperref package"
  }
}