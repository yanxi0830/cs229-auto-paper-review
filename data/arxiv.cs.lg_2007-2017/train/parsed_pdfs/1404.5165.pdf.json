{
  "name" : "1404.5165.pdf",
  "metadata" : {
    "source" : "META",
    "title" : "GP-Localize: Persistent Mobile Robot Localization using Online Sparse Gaussian Process Observation Model",
    "authors" : [ "Nuo Xu", "Kian Hsiang Low", "Jie Chen", "Keng Kiat Lim", "Bariş Özgül" ],
    "emails" : [ "ebozgul}@comp.nus.edu.sg,", "chenjie@smart.mit.edu" ],
    "sections" : [ {
      "heading" : "1 Introduction",
      "text" : "Recent research in robot exploration and mapping has focused on developing adaptive sampling and active sensing algorithms (Cao, Low, and Dolan 2013; Chen, Low, and Tan 2013; Chen et al. 2012; Hoang et al. 2014; Low, Dolan, and Khosla 2008; 2009; 2011; Low et al. 2007; 2012; Ouyang et al. 2014) to gather the most informative data/observations for modeling and predicting spatially varying environmental fields that are characterized by continuous-valued, spatially correlated measurements. Application domains (e.g., environmental sensing and monitoring) requiring such algorithms often contain multiple fields of interest: (a) Autonomous underwater and surface vehicles are tasked to sample ocean and freshwater phenomena including temperature, salinity, and oxygen concentration fields (Dolan et al. 2009; Podnar et al. 2010), (b) indoor environments are spanned by temperature, light, and carbon dioxide concentration fields that affect the occupants’ comfort and satisfaction towards the environmental quality across different areas, and (c) WiFi access points/hotspots situated at neighboring locations produce different but overlapping wireless signal strength fields over the same environment. These algorithms operate with an assumption that the locations of every robot and its gathered observations are known and provided by its onboard sensors such as the widely-used GPS\nCopyright c© 2014, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved.\ndevice. However, GPS signals may be noisy (e.g., due to urban canyon effect between tall buildings) or unavailable (e.g., in underwater or indoor environments). So, it is desirable to alternatively consider exploiting the spatially correlated measurements taken by each robot for localizing itself within the environmental fields during its exploration; this will significantly extend the range of environments and application domains in which a robot can localize itself.\nTo achieve this, our robotics community will usually make use of a probabilistic state estimation framework known as the Bayes filter: It repeatedly updates the belief of a robot’s location/state by assimilating the field measurements taken during the robot’s exploration through its observation model. To preserve time efficiency, the Bayes filter imposes a Markov property on the observation model: Given the robot’s current location, its current measurement is conditionally independent of the past measurements. Such a Markov property is severely violated by the spatial correlation structure of the environmental fields, thus strongly degrading the robot’s localization performance. To resolve this issue, the works of Ko and Fox (2009a; 2009b) have integrated a rich class of Bayesian nonparametric models called the Gaussian process (GP) into the Bayes filter, which allows the spatial correlation structure between measurements to be formally characterized (i.e., by modeling each field as a GP) and the observation model to be represented by fully probabilistic predictive distributions (i.e., one per field/GP) with formal measures of the uncertainty of the predictions.\nUnfortunately, such expressive power of a GP comes at a high computational cost, which hinders its practical use in the Bayes filter for persistent robot localization: It incurs cubic time and quadratic memory in the size of the data/observations. Existing works (Brooks, Makarenko, and Upcroft 2008; Ferris, Hähnel, and Fox 2006; Ferris, Fox, and Lawrence 2007; Ko and Fox 2009a; 2009b) have sidestepped this computational difficulty by assuming the availability of data/observations prior to exploration and localization for training the GP observation model offline; some (Brooks, Makarenko, and Upcroft 2008; Ferris, Hähnel, and Fox 2006; Ko and Fox 2009a) have assumed these given prior measurements to be labeled with known locations while others (Ferris, Fox, and Lawrence 2007; Ko and Fox 2009b) have inferred their location labels. The Markov assumption on the observation model can then be ar X\niv :1\n40 4.\n51 65\nv2 [\ncs .R\nO ]\n2 2\nA pr\n2 01\n4\n“relaxed” to conditional independence between the robot’s current measurement and past measurements (i.e., taken during its exploration) given its current location and the trained GPs using prior data/observations, thus improving the efficiency at each filtering step during its exploration to quadratic time in the size of the prior training data. Any measurement taken during the robot’s actual exploration and localization is thus not used to train the GP observation model. Such a “relaxed” Markov assumption may hold in certain static environments. However, it becomes highly restrictive and is easily violated in general, practical environmental settings where, for example, (a) limited sampling budget (i.e., in terms of energy consumption, mission time, etc.) forbids the collection of prior training data or only permits extremely sparse prior data to be gathered relative to a large environment, thus resulting in an inaccurately trained GP observation model, (b) environmental changes invalidate the prior training data, and (c) the robot’s actual exploration path is spatially distant from the prior observations, hence making the trained GP observation model uninformative to its localization. All these practical considerations motivate us to tackle a fundamental research question: Without prior training data, how can GPs be restructured to be used by a Bayes filter for persistent robot localization in environmental fields characterized by spatially correlated measurements?\nThis paper presents a Gaussian process localization (GPLocalize) algorithm that, in contrast to existing works mentioned above, can exploit the spatially correlated field measurements taken during a robot’s exploration (instead of relying on prior training data) for efficiently and scalably learning the GP observation model online through our proposed novel online sparse GP (Section 3). As a result, GPLocalize is capable of achieving constant time and memory (i.e., independent of the size of the data/observations) per filtering step, which we believe is an important first step towards demonstrating the practical feasibility of employing GPs for persistent robot localization and autonomy. We empirically demonstrate through simulated experiments with three real-world datasets as well as a real robot experiment that GP-Localize outperforms existing GP localization algorithms (Section 4). 2 Background"
    }, {
      "heading" : "2.1 Modeling Environmental Field with GP",
      "text" : "The Gaussian process (GP) can be used to model an environmental field as follows1: The environmental field is defined to vary as a realization of a GP. Let X be a set of locations representing the domain of the environmental field such that each location x ∈ X is associated with a realized (random) field measurement zx(Zx) if x is observed (unobserved). Let {Zx}x∈X denote a GP, that is, every finite subset of {Zx}x∈X has a multivariate Gaussian distribution (Rasmussen and Williams 2006). The GP is fully specified by its prior mean µx , E[Zx] and covariance σxx′ , cov[Zx, Zx′ ] for all x, x′ ∈ X , the latter of which characterizes the spatial correlation structure of the field\n1To simplify exposition, we only describe the GP for a single field; for multiple fields, we assume independence between them to ease computations.\nand can be defined using a covariance function. A common choice is the squared exponential covariance function σxx′ , σ2s exp{−0.5(x−x′)>M−2(x−x′)+σ2nδxx′}where σ2s and σ 2 n are, respectively, the signal and noise variance controlling the intensity and the noise of the measurements, M is a diagonal matrix with length-scale components `1 and `2 controlling, respectively, the degree of spatial correlation or “similarity” between measurements in the horizontal and vertical directions of the field, and δxx′ is a Kronecker delta of value 1 if x = x′, and 0 otherwise.\nA chief advantage of using the full GP to model the environmental field is its capability of performing probabilistic regression: Supposing a robot has visited and observed a set D of locations and taken a column vector zD of corresponding realized measurements, the full GP can exploit these observations to predict the measurement at any unobserved location x ∈ X \\ D as well as provide its corresponding predictive uncertainty using a Gaussian predictive distribution p(zx|x,D, zD) = N (µx|D, σxx|D) with the following posterior mean and variance, respectively:\nµx|D , µx + ΣxDΣ −1 DD (zD − µD) (1)\nσxx|D , σxx − ΣxDΣ−1DDΣDx (2) where µD is a column vector with mean components µx′ for all x′ ∈ D, ΣxD is a row vector with covariance components σxx′ for all x′ ∈ D, ΣDx is the transpose of ΣxD, and ΣDD is a matrix with components σx′x′′ for all x′, x′′ ∈ D."
    }, {
      "heading" : "2.2 Sparse Gaussian Process Approximation",
      "text" : "The key limitation hindering the practical use of the full GP in the Bayes filter for persistent robot localization is its poor scalability in the size |D| of the data/observations: Computing the Gaussian predictive distribution (i.e., (1) and (2)) requires inverting the covariance matrix ΣDD, which incurs O(|D|3) time and O(|D|2) memory. To improve its scalability, GP approximation methods (Chen et al. 2012; 2013; Quiñonero-Candela and Rasmussen 2005) have been proposed, two of which will be described below.\nThe simple sparse subset of data (SoD) approximation method uses only a subset S of the set D of locations (i.e., S ⊂ D) observed and the realized measurements zS taken by the robot to produce a Gaussian predictive distribution of the measurement at any unobserved location x ∈ X \\D with the following posterior mean and variance, which are similar to that of full GP (i.e., by replacing D in (1) and (2) with S):\nµx|S = µx + ΣxSΣ −1 SS(zS − µS) (3)\nσxx|S = σxx − ΣxSΣ−1SSΣSx . (4) The covariance matrix ΣSS is inverted using O(|S|3) time and O(|S|2) memory, which are independent of |D|. The main criticism of SoD is that it does not exploit all the data for computing the Gaussian predictive distribution, thus yielding an unrealistic overestimate (4) of the predictive uncertainty (even with fairly redundant data and informative subset S) (Quiñonero-Candela and Rasmussen 2005) and in turn an inaccurately trained observation model.\nThe sparse partially independent training conditional (PITC) approximation method is the most general form of a class of reduced-rank covariance matrix approximation\nmethods reported in (Quiñonero-Candela and Rasmussen 2005) exploiting the notion of a support set S ⊂ X . Unlike SoD, PITC can utilize all data (i.e., D and zD) to derive a Gaussian predictive distribution of the measurement at any x ∈ X \\ D with the following posterior mean and variance:\nµPITCx|D , µx + ΓxD(ΓDD + Λ) −1(zD − µD) (5)\nσPITCxx|D , σxx − ΓxD(ΓDD + Λ) −1ΓDx (6)\nwhere ΓAA′ = ΣASΣ−1SSΣSA′ for all A,A′ ⊂ X and Λ is a block-diagonal matrix constructed from the N diagonal blocks of ΣDD|S , each of which is a matrix ΣDnDn|S for n = 1, · · · , N where D = ⋃N n=1Dn. Also, unlike SoD, the support set S does not have to be observed. The covariance matrix ΣDD in (1) and (2) is approximated by a reducedrank matrix ΓDD summed with the resulting sparsified residual matrix Λ in (5) and (6). So, computing either µPITCx|D (5) or σPITCxx|D (6), which requires inverting the approximated covariance matrix ΓDD+Λ, incursO(|D|(|S|2+(|D|/N)2)) time andO(|S|2 + (|D|/N)2) memory. The sparse fully independent training conditional (FITC) approximation method is a special case of PITC where Λ is a diagonal matrix constructed from σx′x′|S for all x′ ∈ D (i.e., N = |D|). FITC is previously employed by Ko and Fox (2009a) to speed up the learning of observation model with prior training data. But, the time incurred by PITC or FITC grows with increasing size of data. So, it is computationally impractical to use them directly to repeatedly train the observation model at each filtering step for persistent localization."
    }, {
      "heading" : "2.3 Bayes Filters",
      "text" : "A Bayes filter is a probabilistic state estimation framework that repeatedly updates the belief of a robot’s location/state by conditioning on its control actions performed and field measurements taken so far. Formally, let the robot’s control action performed, its location visited and observed, and the corresponding realized field measurement taken at time/filtering step t be denoted by ut, xt, and zt2, respectively. To estimate the robot’s location, a belief b(xt) , p(xt|u1:t, z1:t) is maintained over all its possible locations xt where u1:t , (u1, . . . , ut)> and z1:t , (z1, . . . , zt)> denote, respectively, column vectors of past control actions performed and realized field measurements taken by the robot up until time step t. To track such a belief, after the robot has performed an action ut and taken a realized measurement zt at each time step t, the Bayes filter updates the prior belief b(xt−1) of the robot’s location to the posterior belief b(xt) = βp(zt|xt) ∫ p(xt|ut, xt−1)b(xt−1)dxt−1 where 1/β is a normalizing constant, p(xt|ut, xt−1) is a motion model representing the probability of the robot moving from locations xt−1 to xt after performing action ut, and p(zt|xt) is an observation model describing the likelihood of taking realized measurement zt at location xt.\nTo preserve efficiency, the Bayes filter imposes a Markov property on the observation model: Given the robot’s current location xt, its current measurement zt is conditionally\n2The field measurement zt is indexed by time step t instead of the corresponding location xt since xt is not known to the robot.\nindependent of past actions u1:t and measurements z1:t−1: p(zt|xt, u1:t, z1:t−1) = p(zt|xt) . (7)\nIn other words, the robot’s past actions performed and measurements taken during its exploration and localization are not exploited for learning the observation model. This is conventionally assumed by existing works either representing the observation model using a parametric model with known parameters (Thrun, Burgard, and Fox 2005) or training it offline using prior training data. The disadvantages of the former are extensively discussed by Ko and Fox (2009a) while that of the latter are already detailed in Section 1.\nIn the case of multiple fields (say, M of them), let zmt denote the realized measurement taken from fieldm at location xt form = 1, . . . ,M . Then, the observation model becomes p(z1t , . . . , z M t |xt) = ∏M m=1 p(z m t |xt) such that the equality follows from an assumption of independence of measurements between fields to ease computations."
    }, {
      "heading" : "3 Online Sparse GP Observation Model",
      "text" : "In contrast to existing works discussed in Section 1, our GPLocalize algorithm does not need to impose the restrictive Markov property (7) on the observation model, which can then be derived by marginalizing out the random locations visited and observed by the robot up until time step t− 1: p(zt|xt, u1:t, z1:t−1)\n=η ∫ b(x0) t∏ i=1 p(xi|ui, xi−1)p(zt|xt, x1:t−1, z1:t−1)dx0:t−1 (8) where 1/η = p(xt|u1:t, z1:t−1) is a normalizing constant, b(x0) = p(x0) is the belief of the robot’s initial location at time step 0, x1:t−1 , {x1, . . . , xt−1} denotes a set of locations visited and observed by the robot up until time step t− 1, and p(zt|xt, x1:t−1, z1:t−1) = N (µxt|x1:t−1 , σxtxt|x1:t−1) is a Gaussian predictive distribution provided by the GP (Section 2.1). The derivation of (8) is in Appendix A.\nTo make computations tractable but not constrain the type of motion model that can be specified, the observation model (8) is approximated using Monte Carlo integration:\np(zt|xt, u1:t, z1:t−1) ≈ 1\nC C∑ c=1 p(zt|xt, xc1:t−1, z1:t−1) (9)\nwhere xc1:t−1 denotes a c-th sample path simulated by first drawing the robot’s initial location xc0 from b(x0) and then sampling xci from motion model p(xi|ui, xci−1) for i = 1, . . . , t − 1 given its past actions u1:t−1 while ensuring p(xt|ut, xct−1) > 0, as observed in (8). For a practical implementation, instead of re-simulating the entire sample paths (hence, incurring linear time in t) at each time step, each c-th sample path is incrementally updated from xc1:t−2 (i.e., obtained in previous time step) to xc1:t−1 (i.e., needed in current time step) by including xct−1 sampled from motion model p(xt−1|ut, xct−2) without accounting for motion constraint p(xt|ut, xct−1) > 0. As a result, the time spent in incrementally updating the C sample paths at each time step is independent of t. To mitigate the effect of ignoring the constraint, we introduce a strategy in Remark 3 after Theorem 1 that exploits a structural property of our proposed online sparse GP. In practice, such an implementation yields considerable\ntime savings (i.e., time independent of t) and does not result in poor localization performance empirically (Section 4).\nThe scalability of our GP-Localize algorithm therefore depends on whether the Gaussian predictive probability p(zt|xt, xc1:t−1, z1:t−1) in (9) can be derived efficiently. Computing it with full GP, PITC, or FITC (Section 2) directly incurs, respectively,O(t3),O(t(|S|2 + (t/N)2)), and O(t|S|2) time. Since t is expected to be large for persistent localization, it is computationally impractical to use these offline full GP and sparse GP approximation methods to repeatedly train the observation model at each filtering step. Even when the online GP proposed by Csató and Opper (2002) is used, it still incurs quadratic time in t per filtering step. In the following subsection, we will propose an online sparse GP that can achieve constant time (i.e., independent of t) at each filtering step t."
    }, {
      "heading" : "3.1 Online Sparse GP Approximation",
      "text" : "The key idea underlying our proposed online sparse GP is to summarize the newly gathered data/observations at regular time intervals/slices, assimilate the summary information of the new data with that of all the previously gathered data/observations, and then exploit the resulting assimilated summary information to compute the Gaussian predictive probability p(zt|xt, xc1:t−1, z1:t−1) in (9). The details of our proposed online sparse GP will be described next.\nLet each time slice n span time/filtering steps (n− 1)τ + 1 to nτ for some user-defined slice size τ ∈ Z+ and the number of time slices available thus far up until time step t be denoted by N (i.e., Nτ < t). Definition 1 (Slice Summary) Given a support set S ⊂"
    }, {
      "heading" : "X common to all C sample paths, the subset Dn ,",
      "text" : "xc(n−1)τ+1:nτ of the c-th sample path x c 1:t−1 simulated during the time slice n, and the column vector zDn = z(n−1)τ+1:nτ of corresponding realized measurements taken by the robot, the slice summary of time slice n is defined as a tuple (µns ,Σ n s ) for n = 1, . . . , N where\nµns , ΣSDnΣ −1 DnDn|S(zDn − µDn)\nΣns , ΣSDnΣ −1 DnDn|SΣDnS\nsuch that µDn is defined in a similar manner as µD in (1) and ΣDnDn|S is a posterior covariance matrix with components σxx′|S for all x, x′ ∈ Dn, each of which is defined in a similar way as (4). Remark. The support set S ⊂ X of locations does not have to be observed because the slice summary is independent of zS . So, the support set S can be selected prior to exploration and localization from X using an offline greedy active learning algorithm such as (Krause, Singh, and Guestrin 2008). Definition 2 (Assimilated Summary) Given (µns ,Σns ), the assimilated summary (µna,Σ n a) of time slices 1 to n is updated from the assimilated summary (µn−1a ,Σ n−1 a ) of time slices 1 to n−1 using µna , µn−1a +µns and Σna , Σn−1a +Σns for n = 1, . . . , N where µ0a , 0 and Σ 0 a , ΣSS .\nRemark 1. After constructing and assimilating (µns ,Σ n s ) with (µn−1a ,Σ n−1 a ) to form (µna,Σ n a), Dn = xc(n−1)τ+1:nτ ,\nzDn = z(n−1)τ+1:nτ , and (µ n s ,Σ n s ) (Definition 1) are no longer needed and can be removed from memory. As a result, at time step t where Nτ + 1 ≤ t ≤ (N + 1)τ , only (µNa ,Σ N a ), x c Nτ+1:t−1, and zNτ+1:t−1 have to be kept in memory, thus requiring only constant memory (i.e., independent of t). Remark 2. The slice summaries are constructed and assimilated at a regular time interval of τ , specifically, at time steps Nτ + 1 for N ∈ Z+. Theorem 1 Given S ⊂ X and (µNa ,ΣNa ), our online sparse GP computes a Gaussian predictive distribution p(zt|xt, µNa ,ΣNa ) = N (µ̃xt , σ̃xtxt) of the measurement at any location xt ∈ X at time step t (i.e., Nτ + 1 ≤ t ≤ (N + 1)τ ) with the following posterior mean and variance:\nµ̃xt , µxt + ΣxtS ( ΣNa )−1 µNa (10)\nσ̃xtxt , σxtxt − ΣxtS ( Σ−1SS − ( ΣNa )−1) ΣSxt . (11)\nIf t = Nτ + 1, µ̃xt = µ PITC xt|xc1:t−1 and σ̃xtxt = σ PITC xtxt|xc1:t−1 .\nIts proof is given in Appendix B. Remark 1. Theorem 1 implies that our proposed online sparse GP is in fact equivalent to an online learning formulation/variant of the offline PITC (Section 2.2). Supposing τ < |S|, theO(t|S|2) time incurred by offline PITC to compute p(zt|xt, xc1:t−1, z1:t−1) in (9) can then be reduced to O(τ |S|2) time (i.e., time independent of t) incurred by our online sparse GP at time steps t = Nτ+1 forN ∈ Z+ when slice summaries are constructed and assimilated. Otherwise, our online sparse GP only incursO(|S|2) time per time step. Remark 2. The above equivalence result allows the structural property of our online sparse GP to be elucidated using that of offline PITC: The measurements ZD1 , . . . , ZDN , Zxt between different time slices are assumed to be conditionally independent given ZS . Such an assumption enables the data gathered during each time slice to be summarized independently of that in other time slices. Increasing slice size τ (i.e., less frequent assimilations of larger slice summaries) relaxes this conditional independence assumption (hence, potentially improving the fidelity of the resulting observation model), but incurs more time at time steps when slice summaries are constructed and assimilated (see Remark 1). Remark 3. Recall (see paragraph after (9)) that the motion constraint p(xt|ut, xct−1) > 0 is not accounted for when sampling xct−1 from motion model p(xt−1|ut, xct−2) at each time step t. To mitigate the effect of ignoring the constraint, at time steps t = Nτ+2 forN ∈ Z+, we draw x′Nτ from the particle-based belief b(xNτ ) maintained in our experiments (Section 4) and use it (instead of xcNτ ) for sampling x c Nτ+1 from motion model p(xNτ+1|ui, x′Nτ ). Doing this at a regular time interval of τ reduces the deviation of the simulated sample paths from the particle-based beliefs updated at each time step and consequently allows the sample paths to satisfy the motion constraint more often, especially when τ is small. Such a strategy may cause the sampled xcNτ+1 not to be located close to xcNτ (hence, their corresponding realized measurements are less spatially correlated) since xcNτ+1 is not sampled from motion model p(xNτ+1|ui, xcNτ ). But,\nthis occurs at a lower frequency of 1/τ , as compared to not considering the motion constraint at every time step. Furthermore, this fits well with the structural property of our online sparse GP that assumes ZNτ and ZNτ+1 (or, more generally, ZDN and Zxt ) to be conditionally independent. Remark 4. Since offline PITC generalizes offline FITC (Section 2.2), our online sparse GP generalizes the online learning variant of FITC (i.e., τ = 1) (Csató and Opper 2002)3.\nWhen Nτ + 1 < t ≤ (N + 1)τ (i.e., before the next slice summary of time slice N + 1 is constructed and assimilated), the most recent observations (i.e., D′ , xcNτ+1:t−1 and zD′ = zNτ+1:t−1), which are often highly informative, are not used to update µ̃xt (10) and σ̃xtxt (11). This will hurt the localization performance, especially when τ is large and the robot is localizing in an unexplored area with little/no observations; the field within this area thus cannot be predicted well with the current assimilated summary. To resolve this, we exploit incremental update formulas of Gaussian posterior mean and variance (Appendix C) to update µ̃xt and σ̃xtxt with the most recent observations, thereby yielding a Gaussian predictive distribution p(zt|xt, µNa ,ΣNa ,D′, zD′) = N (µ̃xt|D′ , σ̃xtxt|D′) where\nµ̃xt|D′ , µ̃xt + Σ̃xtD′Σ̃ −1 D′D′ (zD′ − µ̃D′) (12)\nσ̃xtxt|D′ , σ̃xtxt − Σ̃xtD′Σ̃ −1 D′D′Σ̃D′xt (13)\nsuch that µ̃D′ is a column vector with mean components µ̃x (i.e., defined similarly to (10)) for all x ∈ D′, Σ̃xtD′ is a row vector with covariance components σ̃xtx (i.e., defined similarly to (11)) for all x ∈ D′, Σ̃D′xt is the transpose of Σ̃xtD′ , and Σ̃D′D′ is a matrix with covariance components σ̃xx′ (i.e., defined similarly to (11)) for all x, x′ ∈ D′. Theorem 2 Computing p(zt|xt, µNa ,ΣNa ,D′, zD′) (i.e., (12) and (13)) incurs O(τ |S|2) time at time steps t = Nτ + 1 for N ∈ Z+ and O(|S|2) time otherwise. It requires O(|S|2) memory at each time step. Its proof is given in Appendix D. Theorem 2 indicates that our online sparse GP incurs constant time and memory (i.e., independent of t) per time step."
    }, {
      "heading" : "4 Experiments and Discussion",
      "text" : "This section evaluates the localization performance, time efficiency, and scalability of our GP-Localize algorithm empirically through simulated experiments with three realworld datasets: (a) Wireless signal strength (WSS) (signalto-noise ratio) data (Chen and Guestrin 2007) produced by 6 WiFi access points (APs) and measured at over 200 locations throughout the fifth floor of Wean Hall in Carnegie Mellon University (Fig. 1, Section 4.1), (b) indoor environmental quality (IEQ) (i.e., temperature (◦F) and light (Lux)) data (Bodik et al. 2004) measured by 54 sensors deployed in the Intel Berkeley Research lab (Fig. 3, Section 4.2), (c) urban traffic speeds (UTS) (km/h) data (Chen et al. 2012; 2013) measured at 775 road segments (including highways, arterials, slip roads, etc.) of an urban road network\n3Snelson (2007) pointed out that the sparse online GP of Csató and Opper (2002) is an online learning variant of offline FITC.\nin Tampines area, Singapore during evening peak hours on April 20, 2011 with a mean speed of 47.6 km/h and a standard deviation of 20.5 km/h (Fig. 4a, Section 4.3), and (d) a real Pioneer 3-DX mobile robot (i.e., mounted with a weather board) experiment on a trajectory of about 280 m in the Singapore-MIT Alliance for Research and Technology Future Urban Mobility (SMART FM) IRG office/lab gathering 561 relative light (%) observations/data for GP localization (Fig. 5, Section 4.4). Different from the 2-dimensional spatial domains of the WSS, IEQ, and light fields, each road segment of the urban road network is specified by a 5-dimensional vector of features: length, number of lanes, speed limit, direction, and time. The UTS field is modeled using a relational GP (previously developed in (Chen et al. 2012)) whose correlation structure can exploit both the road segment features and road network topology information. The hyperparameters of each GP modeling a different field are learned using the data via maximum likelihood estimation (Rasmussen and Williams 2006). Our GP-Localize algorithm is implemented using an odometry motion model4, our online sparse GP (i.e., setting τ = 10 and |S| = 40) for representing the observation model (Section 3), and a particle filter4 of 400 particles for representing the belief of the robot’s location. The number C of sample paths in (9) is set to 400 for all experiments. For the simulated experiments with the WSS and IEQ data, the control actions (i.e., odometry information) are generated using the realistic Pioneer mobile robot module in Player/Stage simulator (Gerkey, Vaughan, and Howard 2003) and the measurements taken along the generated trajectory of 421 (336) time steps from the WSS (IEQ) fields shown in Fig. 1 (Fig. 2) are the Gaussian predictive/posterior means (1) of each full GP modeling a separate field trained using the data. For the simulated experiment with the UTS data, the control actions of the mobile probe vehicle are assumed not to be known; its transition probability of moving from one road segment to another can be learned from vehicle route data using the hierarchical Bayesian nonparametric approach of Yu et al. (2012). The measurements taken along its generated trajectory of 370 time steps from the UTS field are shown in Fig. 4.\nThe localization performance/error (i.e., distance between the robot’s estimated and true locations) and scalability of our GP-Localize algorithm is compared to that of two sparse GP localization algorithms: (a) The SoD-Truncate method uses |S| = 10 most recent observations (i.e., compared to |D′| < τ = 10 most recent observations considered by our online sparse GP besides the assimilated summary) as training data at each filtering step while (b) the SoD-Even method uses |S| = 40 observations (i.e., compared to the support set of |S| = 40 possibly unobserved locations selected prior to localization and exploited by our online sparse GP) evenly distributed over the time of localization. The scalability of GP-Localize is further compared to that of GP localization algorithms employing full GP and offline PITC (Section 2).\n4Due to lack of space, an interested reader is referred to (Thrun, Burgard, and Fox 2005) for the technical details of the odometry motion model and particle filter."
    }, {
      "heading" : "4.1 Wireless Signal Strength (WSS) Fields",
      "text" : "Table 1 shows the localization errors (no units given in WSS data) of GP-localize, SoD-Truncate, and SoD-Even averaged over all 421 time steps and 5 simulation runs. It can be observed that GP-Localize outperforms the other two methods in every single field and in multiple fields (i.e., all 6): The observation model (i.e., represented by our online sparse GP) of GP-Localize can exploit the assimilated summary and the most recent observations to predict, respectively, the fields in explored and unexplored areas better. In contrast, SoD-Truncate performs poorly in explored areas since its predictive capability is limited by using only the most recent observations. The limited observations of SoDEven can only cover the entire area sparsely, thus producing an inaccurate observation model.\nIt can also be observed from Table 1 that GP-Localize achieves its largest (smallest) localization error in field 3 (4): Fig. 1a shows that the robot does not explore the area on the left with highly varying measurements well enough, thus yielding an assimilated summary that is less informative to localization in this area. Though it explores the area on the right densely, the field in this area is relatively constant, hence making localization difficult. As a result, localization error is high in field 3. On the other hand, Fig. 1b shows that the robot explores the area on the right with highly varying measurements densely, thus achieving low error in field 4.\nFig. 2a shows the localization error of GP-Localize at each time step in every single field and in multiple fields (i.e., all 6) averaged over 5 runs. It can be observed that although the error in multiple fields is not always smallest at each time step, it often tends to be close to (if not, lower than) the lowest error among all single fields and, more importantly, is not so high like those in single fields 1, 2, 3, 5, 6\nafter 200 time steps. In practice, since it is usually not known which single field yields a low or high error at each time step, a more robust GP-Localize algorithm (i.e., achieved by exploiting multiple fields) is preferred."
    }, {
      "heading" : "4.2 Indoor Environmental Quality (IEQ) Fields",
      "text" : "Table 2 shows the localization errors (m) of the tested methods averaged over all 336 time steps and 5 simulation runs. Similar to the observations for WSS fields (Section 4.1), GPLocalize outperforms the other two methods in every single field and in multiple fields, as explained in the previous section. It can also be observed that GP-Localize achieves a smaller error in the light field than in the temperature field because the measurements of the light field vary slightly more than that of the temperature field, as shown in Fig. 3. Fig. 2b shows the error of GP-Localize at each time step in every single field and in multiple fields averaged over 5 runs. It can again be observed that although the error in multiple fields is not always smallest at each time step, it is often close to (if not, lower than) the lowest error among all single fields and not as high as that in the single temperature field. Our GP-Localize algorithm exploiting multiple fields is therefore more robust in this experiment."
    }, {
      "heading" : "4.3 Urban Traffic Speeds (UTS) Field",
      "text" : "For the UTS field, the localization error is defined as the geodesic (i.e., shortest path) distance between the vehicle’s\nestimated and true residing road segments with respect to the road network topology (Fig. 4). GP-Localize, SoD-Truncate, and SoD-Even achieve, respectively, localization errors of 2.8, 7.3, and 6.2 road segments averaged over all 370 time steps and 3 simulation runs."
    }, {
      "heading" : "4.4 Real Pioneer 3-DX Mobile Robot Experiment",
      "text" : "The adaptive Monte Carlo localization (AMCL) package in the Robot Operating System (ROS) is run on a Pioneer 3-DX mobile robot mounted with a SICK LMS200 laser rangefinder to determine its trajectory (Fig. 5a) and the 561 locations at which the relative light measurements are taken (Fig. 5b); these locations are assumed to be the ground truth. GP-Localize, SoD-Truncate, and SoD-Even achieve, respectively, localization errors of 2.1 m, 5.4 m, and 4.6 m averaged over all 561 time steps and 3 runs.\nFig. 4b shows the time incurred by GP-Localize, SoDTruncate, SoD-Even, full GP, and offline PITC at each time step using 100 particles averaged over 5 runs. It can be seen that, with more time steps, the time incurred by full GP, offline PITC, and SoD-Even increase while that of GPLocalize and SoD-Truncate remain constant. GP-Localize is clearly much more scalable (i.e., constant time) in t than full GP and offline PITC. Though it incurs slightly more time than SoD-Truncate and SoD-Even, it can localize significantly better (Sections 4.1 and 4.2)."
    }, {
      "heading" : "5 Conclusion",
      "text" : "This paper describes the GP-Localize algorithm for persistent robot localization whose observation model is represented by our novel online sparse GP, thus achieving constant time and memory (i.e., independent of the size of the data) per filtering step. We theoretically analyze the equivalence of our online sparse GP to the online learning variant of offline PITC. We empirically demonstrate that GPLocalize outperforms existing GP localization algorithms in terms of localization performance and scalability and achieves robustness by exploiting multiple fields. Besides using our online sparse GP for persistent robot localization, note that it can in fact be applied to a wide variety of applications and are especially desirable (i.e., due to runtime and memory being independent of the size of data) for tasks with data streaming in over time or real-time requirements. Some robotic tasks include adaptive sampling, information gathering, learning of robot arm control (Low, Leow, and Ang, Jr. 2002a; 2002b; 2005), visual tracking and head pose estimation for human-robot interaction. For non-robotic applications, they include traffic and weather prediction, online action recognition, online recommendation systems, online classification, among others.\nA limitation of GP-Localize, as observed in our experiments, is that it does not localize well in near-constant fields, which is expected. So, in our future work, we plan to generalize our algorithm to handle richer, high-dimensional sensing data like laser scans and camera images (Natarajan et al. 2012a; 2012b; Natarajan, Low, and Kankanhalli 2014). We also like to investigate the effect of varying the slice size τ on the localization error of GP-Localize empirically and remove the assumption of independence between fields by exploiting techniques like multi-output GPs and co-kriging for modeling their correlation. Lastly, as mentioned in Section 4, the hyperparameters of each GP are learned using the data by maximizing the log marginal likelihood. The sparse approximation method employed by offline PITC to improve the scalability of the full GP can be similarly applied to computing such a log marginal likelihood scalably, as explained in (Quiñonero-Candela and Rasmussen 2005) (i.e., equation 30 in Section 9). Since our online sparse GP is the online variant of the offline PITC, the log marginal likelihood can be computed and maximized in an online manner as well. The exact details will be specified in the future extension of this work."
    }, {
      "heading" : "Acknowledgments",
      "text" : "This work was supported by Singapore-MIT Alliance for Research and Technology Subaward Agreement No. 41 R252-000-527-592."
    }, {
      "heading" : "B Proof of Theorem 1",
      "text" : "Since Dn = xc(n−1)τ+1:nτ (Definition 1) and t = Nτ + 1, D = ⋃N n=1Dn = ⋃N n=1 x c (n−1)τ+1:nτ = x c 1:Nτ = x c 1:t−1. Let us first simplify the ΓxtD (ΓDD + Λ) −1 term on the right-hand side expressions of µPITCxt|D = µ PITC xt|xc1:t−1 (5) and σPITCxtxt|D = σ PITC xtxt|xc1:t−1 (6).\n(ΓDD + Λ) −1 = ( ΣDSΣ −1 SSΣSD + Λ )−1 = Λ−1 − Λ−1ΣDS ( ΣSS + ΣSDΛ −1ΣDS )−1 ΣSDΛ −1\n= Λ−1 − Λ−1ΣDS ( ΣNa )−1 ΣSDΛ −1 .\n(14) The second equality is due to the matrix inversion lemma. The last equality follows from\nΣSS + ΣSDΛ −1ΣDS\n= ΣSS + N∑ n=1 ΣSDnΣ −1 DnDn|SΣDnS\n= ΣSS + N∑ n=1 Σns = Σ N a .\n(15)\nFrom (14),\nΓxtD (ΓDD + Λ) −1 = ΣxtSΣ −1 SSΣSD ( Λ−1 − Λ−1ΣDS ( ΣNa )−1 ΣSDΛ −1 )\n= ΣxtSΣ −1 SS ( ΣNa − ΣSDΛ−1ΣDS ) ( ΣNa )−1 ΣSDΛ −1\n= ΣxtS ( ΣNa )−1 ΣSDΛ −1 .\n(16) The third equality is due to (15).\nFrom (5),\nµPITCxt|xc1:t−1 = µPITCxt|D\n= µxt + ΓxtD (ΓDD + Λ) −1\n(zD − µD) = µxt + ΣxtS ( ΣNa )−1 ΣSDΛ −1 (zD − µD)\n= µxt + ΣxtS ( ΣNa )−1\nµNa = µ̃xt .\nThe third equality is due to (16). The fourth equality follows from ΣSDΛ−1 (zD − µD) =∑N n=1 ΣSDnΣ −1 DnDn|S (zDn − µDn) = ∑N n=1 µ n s = µ N a .\nFrom (6),\nσPITCxtxt|xc1:t−1 = σPITCxtxt|D\n= σxtxt − ΓxtD (ΓDD + Λ) −1\nΓDxt = σxtxt − ΣxtS ( ΣNa )−1 ΣSDΛ −1ΣDSΣ −1 SSΣSxt\n= σxtxt − ΣxtS ( ΣNa )−1 ( ΣNa − ΣSS ) Σ−1SSΣSxt\n= σxtxt − ΣxtS ( Σ−1SS − ( ΣNa )−1)\nΣSxt = σ̃xtxt .\nThe third and fourth equalities follow from (16) and (15), respectively.\nC Incremental Update Formulas of Gaussian Posterior Mean and Variance\nUsing the matrix inversion lemma, the following incremental update formulas of the Gaussian posterior mean and variance can be obtained:\nµx|D∪D′ , µx|D + ΣxD′|DΣ −1 D′D′|D ( zD′ − µD′|D ) σxx|D∪D′ , σxx|D − ΣxD′|DΣ−1D′D′|DΣD′x|D\nfor allD,D′ ⊂ X such thatD∩D′ = ∅ and x ∈ X\\(D∪D′)."
    }, {
      "heading" : "D Proof Sketch of Theorem 2",
      "text" : "Firstly, (ΣNa )\n−1 in (10) and (11) has to be evaluated at time steps t = Nτ + 1 for N ∈ Z+. To avoid incurring O(|S|3) time to invert ΣNa , the matrix inversion lemma can be used to obtain (ΣNa )\n−1 from (ΣN−1a )−1 (i.e., previously derived at time step (N − 1)τ + 1) in O(τ |S|2) time (i.e., assuming τ < |S|) and O(|S|2) memory, as observed in the following derivation:( ΣNa )−1\n= (\nΣN−1a + ΣSDNΣ −1 DNDN |SΣDNS )−1 = ( ΣN−1a )−1 + ( ΣN−1a )−1 ΣSDN(\nΣDNDN |S+ΣDNS ( ΣN−1a )−1 ΣSDN )−1 ΣDNS ( ΣN−1a )−1 .\nSince evaluating µNa in (10) also incursO(τ |S|2) time, Σ−1SS can be evaluated prior to exploration and localization while incurring O(|S|2) memory, and D′ = ∅ at time steps t = Nτ+1, computing µ̃xt|D′ = µ̃xt (10) and σ̃xtxt|D′ = σ̃xtxt (11) incurO(τ |S|2) time andO(|S|2) memory at time steps t = Nτ + 1 for N ∈ Z+.\nOn the other hand, when Nτ + 1 < t ≤ (N + 1)τ , Σ̃−1D′D′ in (12) and (13) has to be evaluated. Let D′− , xcNτ+1:t−2. Then, D′ = D′− ∪ xct−1. To avoid incurring O(|D′|3) time to invert Σ̃D′D′ , the matrix inversion lemma can again be used to obtain Σ̃−1D′D′ from Σ̃ −1 D′−D′− (i.e., previously derived at time step t−1) inO(|S|2) time andO(|S|2) memory (i.e., |D′| < τ < |S|), as observed in the following derivation:\nΣ̃−1D′D′ = Σ̃−1(D′−∪xct−1)(D′−∪xct−1)\n= ( Σ̃D′−D′− Σ̃D′−xct−1 Σ̃xct−1D′− σ̃xct−1xct−1 )−1 = ( Σ̃−1D′−D′− + Σ̃−1D′−D′− Σ̃D′−xct−1Ψ −Ψ >\n−Ψ σ̃xct−1xct−1|D′−\n)\nwhere\nσ̃xct−1xct−1|D′− = σ̃xct−1xct−1 − Σ̃xct−1D′−Σ̃ −1 D′−D′− Σ̃D′−xct−1\nand Ψ = σ̃xct−1xct−1|D′−Σ̃xct−1D′−Σ̃ −1 D′−D′− . Note that computing Σ̃xct−1D′− only incursO(|S| 2) time instead ofO(D′|S|2) time because\nΣ̃xct−1D′− = Σxct−1D′− − Σxct−1S ( Σ−1SS − ( ΣNa )−1)\nΣSD′− = Σxct−1D′− − Σxct−1S[(\nΣ−1SS− ( ΣNa )−1) ΣSxcNτ+1:t−3 , ( Σ−1SS− ( ΣNa )−1) ΣSxct−2 ]\nand (Σ−1SS − (ΣNa )−1)ΣSxcNτ+1:t−3 is previously evaluated at time step t− 1. Similarly, evaluating µ̃D′ in (12) only incursO(|S|2) time instead ofO(D′|S|2) time because µ̃D′ = (µ̃>D′− , µ̃xct−1) > and µ̃D′− is previously evaluated at time step t − 1. Therefore, computing µ̃xt|D′ (12) and σ̃xtxt|D′ (13) incur only O(|S|2) time and O(|S|2) memory at time steps t where Nτ + 1 < t ≤ (N + 1)τ ."
    }, {
      "heading" : "E Additional figures for Section 4.1",
      "text" : ""
    } ],
    "references" : [ {
      "title" : "Gaussian process models for indoor and outdoor sensor-centric robot",
      "author" : [ "P. Bodik", "C. Guestrin", "W. Hong", "S. Madden", "M. Paskin", "R. Thibaux" ],
      "venue" : null,
      "citeRegEx" : "Bodik et al\\.,? \\Q2004\\E",
      "shortCiteRegEx" : "Bodik et al\\.",
      "year" : 2004
    }, {
      "title" : "Multi-robot informative path planning for active sensing of environmental phenomena: A tale of two algorithms",
      "author" : [ "N. Cao", "K.H. Low", "J.M. Dolan" ],
      "venue" : "Proc. AAMAS, 7–14. Chen, K., and Guestrin, C.",
      "citeRegEx" : "Cao et al\\.,? 2013",
      "shortCiteRegEx" : "Cao et al\\.",
      "year" : 2013
    }, {
      "title" : "Decentralized data fusion and active sensing with mobile sensors for modeling and predicting spatiotemporal traffic phenomena",
      "author" : [ "J. Chen", "K.H. Low", "C.K.-Y. Tan", "A. Oran", "P. Jaillet", "J.M. Dolan", "G.S. Sukhatme" ],
      "venue" : "Proc. UAI, 163–173.",
      "citeRegEx" : "Chen et al\\.,? 2012",
      "shortCiteRegEx" : "Chen et al\\.",
      "year" : 2012
    }, {
      "title" : "Parallel Gaussian process regression with low-rank covariance matrix approximations",
      "author" : [ "J. Chen", "N. Cao", "K.H. Low", "R. Ouyang", "C.K.-Y. Tan", "P. Jaillet" ],
      "venue" : "Proc. UAI, 152–161.",
      "citeRegEx" : "Chen et al\\.,? 2013",
      "shortCiteRegEx" : "Chen et al\\.",
      "year" : 2013
    }, {
      "title" : "Gaussian process-based decentralized data fusion and active sensing for mobility-on-demand system",
      "author" : [ "J. Chen", "K.H. Low", "C.K.-Y. Tan" ],
      "venue" : "Proc. RSS.",
      "citeRegEx" : "Chen et al\\.,? 2013",
      "shortCiteRegEx" : "Chen et al\\.",
      "year" : 2013
    }, {
      "title" : "Sparse online Gaussian processes",
      "author" : [ "L. Csató", "M. Opper" ],
      "venue" : "Neural Computation 14(2):641–669.",
      "citeRegEx" : "Csató and Opper,? 2002",
      "shortCiteRegEx" : "Csató and Opper",
      "year" : 2002
    }, {
      "title" : "Cooperative aquatic sensing using the telesupervised adaptive ocean sensor fleet",
      "author" : [ "J.M. Dolan", "G. Podnar", "S. Stancliff", "K.H. Low", "A. Elfes", "J. Higinbotham", "J.C. Hosler", "T.A. Moisan", "J. Moisan" ],
      "venue" : "Proc. SPIE Conference on Remote Sensing of the Ocean, Sea Ice, and Large Water",
      "citeRegEx" : "Dolan et al\\.,? 2009",
      "shortCiteRegEx" : "Dolan et al\\.",
      "year" : 2009
    }, {
      "title" : "WiFi-SLAM using Gaussian process latent variable models",
      "author" : [ "B. Ferris", "D. Fox", "N. Lawrence" ],
      "venue" : "Proc. IJCAI, 2480–2485.",
      "citeRegEx" : "Ferris et al\\.,? 2007",
      "shortCiteRegEx" : "Ferris et al\\.",
      "year" : 2007
    }, {
      "title" : "Gaussian processes for signal strength-based location estimation",
      "author" : [ "B. Ferris", "D. Hähnel", "D. Fox" ],
      "venue" : "Proc. RSS.",
      "citeRegEx" : "Ferris et al\\.,? 2006",
      "shortCiteRegEx" : "Ferris et al\\.",
      "year" : 2006
    }, {
      "title" : "The Player/Stage project: Tools for multi-robot and distributed sensor systems",
      "author" : [ "B.P. Gerkey", "R.T. Vaughan", "A. Howard" ],
      "venue" : "Proc. ICAR, 317–323.",
      "citeRegEx" : "Gerkey et al\\.,? 2003",
      "shortCiteRegEx" : "Gerkey et al\\.",
      "year" : 2003
    }, {
      "title" : "Nonmyopic -Bayes-optimal active learning of Gaussian processes",
      "author" : [ "T.N. Hoang", "K.H. Low", "P. Jaillet", "M. Kankanhalli" ],
      "venue" : "Proc. ICML.",
      "citeRegEx" : "Hoang et al\\.,? 2014",
      "shortCiteRegEx" : "Hoang et al\\.",
      "year" : 2014
    }, {
      "title" : "GP-BayesFilters: Bayesian filtering using Gaussian process prediction and observation models",
      "author" : [ "J. Ko", "D. Fox" ],
      "venue" : "Autonomous Robots 27(1):75–90.",
      "citeRegEx" : "Ko and Fox,? 2009a",
      "shortCiteRegEx" : "Ko and Fox",
      "year" : 2009
    }, {
      "title" : "Learning GP-BayesFilters via Gaussian process latent variable models",
      "author" : [ "J. Ko", "D. Fox" ],
      "venue" : "Proc. RSS.",
      "citeRegEx" : "Ko and Fox,? 2009b",
      "shortCiteRegEx" : "Ko and Fox",
      "year" : 2009
    }, {
      "title" : "Near-optimal sensor placements in Gaussian processes: Theory, efficient algorithms and empirical studies",
      "author" : [ "A. Krause", "A. Singh", "C. Guestrin" ],
      "venue" : "JMLR 9:235–284.",
      "citeRegEx" : "Krause et al\\.,? 2008",
      "shortCiteRegEx" : "Krause et al\\.",
      "year" : 2008
    }, {
      "title" : "Adaptive sampling for multi-robot wide-area exploration",
      "author" : [ "K.H. Low", "G.J. Gordon", "J.M. Dolan", "P. Khosla" ],
      "venue" : "Proc. IEEE ICRA, 755–760.",
      "citeRegEx" : "Low et al\\.,? 2007",
      "shortCiteRegEx" : "Low et al\\.",
      "year" : 2007
    }, {
      "title" : "Decentralized active robotic exploration and mapping for probabilistic field classification in environmental sensing",
      "author" : [ "K.H. Low", "J. Chen", "J.M. Dolan", "S. Chien", "D.R. Thompson" ],
      "venue" : "Proc. AAMAS, 105–112.",
      "citeRegEx" : "Low et al\\.,? 2012",
      "shortCiteRegEx" : "Low et al\\.",
      "year" : 2012
    }, {
      "title" : "Adaptive multi-robot wide-area exploration and mapping",
      "author" : [ "K.H. Low", "J.M. Dolan", "P. Khosla" ],
      "venue" : "Proc. AAMAS, 23–30.",
      "citeRegEx" : "Low et al\\.,? 2008",
      "shortCiteRegEx" : "Low et al\\.",
      "year" : 2008
    }, {
      "title" : "Informationtheoretic approach to efficient adaptive path planning for mobile robotic environmental sensing",
      "author" : [ "K.H. Low", "J.M. Dolan", "P. Khosla" ],
      "venue" : "Proc. ICAPS, 233– 240.",
      "citeRegEx" : "Low et al\\.,? 2009",
      "shortCiteRegEx" : "Low et al\\.",
      "year" : 2009
    }, {
      "title" : "Active Markov information-theoretic path planning for robotic environmental sensing",
      "author" : [ "K.H. Low", "J.M. Dolan", "P. Khosla" ],
      "venue" : "Proc. AAMAS, 753–760.",
      "citeRegEx" : "Low et al\\.,? 2011",
      "shortCiteRegEx" : "Low et al\\.",
      "year" : 2011
    }, {
      "title" : "A hybrid mobile robot architecture with integrated planning and control",
      "author" : [ "K.H. Low", "W.K. Leow", "Ang, Jr., M.H." ],
      "venue" : "Proc. AAMAS, 219–226.",
      "citeRegEx" : "Low et al\\.,? 2002a",
      "shortCiteRegEx" : "Low et al\\.",
      "year" : 2002
    }, {
      "title" : "Integrated planning and control of mobile robot with selforganizing neural network",
      "author" : [ "K.H. Low", "W.K. Leow", "Ang, Jr., M.H." ],
      "venue" : "Proc. IEEE ICRA, 3870– 3875.",
      "citeRegEx" : "Low et al\\.,? 2002b",
      "shortCiteRegEx" : "Low et al\\.",
      "year" : 2002
    }, {
      "title" : "An ensemble of cooperative extended Kohonen maps for complex robot motion tasks",
      "author" : [ "K.H. Low", "W.K. Leow", "Ang, Jr., M.H." ],
      "venue" : "Neural Comput. 17(6):1411–1445.",
      "citeRegEx" : "Low et al\\.,? 2005",
      "shortCiteRegEx" : "Low et al\\.",
      "year" : 2005
    }, {
      "title" : "Decision-theoretic approach to maximizing observation of multiple targets in multi-camera surveillance",
      "author" : [ "P. Natarajan", "T.N. Hoang", "K.H. Low", "M. Kankanhalli" ],
      "venue" : "Proc. AAMAS, 155–162.",
      "citeRegEx" : "Natarajan et al\\.,? 2012a",
      "shortCiteRegEx" : "Natarajan et al\\.",
      "year" : 2012
    }, {
      "title" : "Decision-theoretic coordination and control for active multi-camera surveillance in uncertain, partially observable environments",
      "author" : [ "P. Natarajan", "T.N. Hoang", "K.H. Low", "M. Kankanhalli" ],
      "venue" : "Proc. ICDSC.",
      "citeRegEx" : "Natarajan et al\\.,? 2012b",
      "shortCiteRegEx" : "Natarajan et al\\.",
      "year" : 2012
    }, {
      "title" : "Decision-theoretic approach to maximizing fairness in multi-target observation in multi-camera surveillance",
      "author" : [ "P. Natarajan", "K.H. Low", "M. Kankanhalli" ],
      "venue" : "Proc. AAMAS.",
      "citeRegEx" : "Natarajan et al\\.,? 2014",
      "shortCiteRegEx" : "Natarajan et al\\.",
      "year" : 2014
    }, {
      "title" : "Multirobot active sensing of non-stationary Gaussian processbased environmental phenomena",
      "author" : [ "R. Ouyang", "K.H. Low", "J. Chen", "P. Jaillet" ],
      "venue" : "Proc. AAMAS.",
      "citeRegEx" : "Ouyang et al\\.,? 2014",
      "shortCiteRegEx" : "Ouyang et al\\.",
      "year" : 2014
    }, {
      "title" : "Telesupervised remote surface water quality sensing",
      "author" : [ "G. Podnar", "J.M. Dolan", "K.H. Low", "A. Elfes" ],
      "venue" : "Proc. IEEE Aerospace Conference.",
      "citeRegEx" : "Podnar et al\\.,? 2010",
      "shortCiteRegEx" : "Podnar et al\\.",
      "year" : 2010
    }, {
      "title" : "A unifying view of sparse approximate Gaussian process regression",
      "author" : [ "J. Quiñonero-Candela", "C.E. Rasmussen" ],
      "venue" : "JMLR 6:1939–1959.",
      "citeRegEx" : "Quiñonero.Candela and Rasmussen,? 2005",
      "shortCiteRegEx" : "Quiñonero.Candela and Rasmussen",
      "year" : 2005
    }, {
      "title" : "Gaussian Processes for Machine Learning",
      "author" : [ "C.E. Rasmussen", "C.K.I. Williams" ],
      "venue" : "Cambridge, MA: MIT Press.",
      "citeRegEx" : "Rasmussen and Williams,? 2006",
      "shortCiteRegEx" : "Rasmussen and Williams",
      "year" : 2006
    }, {
      "title" : "Flexible and efficient Gaussian process models for machine learning",
      "author" : [ "E.L. Snelson" ],
      "venue" : "Ph.D. Thesis, University College London, London, UK.",
      "citeRegEx" : "Snelson,? 2007",
      "shortCiteRegEx" : "Snelson",
      "year" : 2007
    }, {
      "title" : "Probabilistic Robotics",
      "author" : [ "S. Thrun", "W. Burgard", "D. Fox" ],
      "venue" : "Cambridge, MA: MIT Press.",
      "citeRegEx" : "Thrun et al\\.,? 2005",
      "shortCiteRegEx" : "Thrun et al\\.",
      "year" : 2005
    }, {
      "title" : "Hierarchical Bayesian nonparametric approach to modeling and learning the wisdom of crowds of urban traffic route planning agents",
      "author" : [ "J. Yu", "K.H. Low", "A. Oran", "P. Jaillet" ],
      "venue" : "Proc. IAT, 478–485.",
      "citeRegEx" : "Yu et al\\.,? 2012",
      "shortCiteRegEx" : "Yu et al\\.",
      "year" : 2012
    } ],
    "referenceMentions" : [ {
      "referenceID" : 2,
      "context" : "Recent research in robot exploration and mapping has focused on developing adaptive sampling and active sensing algorithms (Cao, Low, and Dolan 2013; Chen, Low, and Tan 2013; Chen et al. 2012; Hoang et al. 2014; Low, Dolan, and Khosla 2008; 2009; 2011; Low et al. 2007; 2012; Ouyang et al. 2014) to gather the most informative data/observations for modeling and predicting spatially varying environmental fields that are characterized by continuous-valued, spatially correlated measurements.",
      "startOffset" : 123,
      "endOffset" : 295
    }, {
      "referenceID" : 10,
      "context" : "Recent research in robot exploration and mapping has focused on developing adaptive sampling and active sensing algorithms (Cao, Low, and Dolan 2013; Chen, Low, and Tan 2013; Chen et al. 2012; Hoang et al. 2014; Low, Dolan, and Khosla 2008; 2009; 2011; Low et al. 2007; 2012; Ouyang et al. 2014) to gather the most informative data/observations for modeling and predicting spatially varying environmental fields that are characterized by continuous-valued, spatially correlated measurements.",
      "startOffset" : 123,
      "endOffset" : 295
    }, {
      "referenceID" : 14,
      "context" : "Recent research in robot exploration and mapping has focused on developing adaptive sampling and active sensing algorithms (Cao, Low, and Dolan 2013; Chen, Low, and Tan 2013; Chen et al. 2012; Hoang et al. 2014; Low, Dolan, and Khosla 2008; 2009; 2011; Low et al. 2007; 2012; Ouyang et al. 2014) to gather the most informative data/observations for modeling and predicting spatially varying environmental fields that are characterized by continuous-valued, spatially correlated measurements.",
      "startOffset" : 123,
      "endOffset" : 295
    }, {
      "referenceID" : 25,
      "context" : "Recent research in robot exploration and mapping has focused on developing adaptive sampling and active sensing algorithms (Cao, Low, and Dolan 2013; Chen, Low, and Tan 2013; Chen et al. 2012; Hoang et al. 2014; Low, Dolan, and Khosla 2008; 2009; 2011; Low et al. 2007; 2012; Ouyang et al. 2014) to gather the most informative data/observations for modeling and predicting spatially varying environmental fields that are characterized by continuous-valued, spatially correlated measurements.",
      "startOffset" : 123,
      "endOffset" : 295
    }, {
      "referenceID" : 6,
      "context" : ", environmental sensing and monitoring) requiring such algorithms often contain multiple fields of interest: (a) Autonomous underwater and surface vehicles are tasked to sample ocean and freshwater phenomena including temperature, salinity, and oxygen concentration fields (Dolan et al. 2009; Podnar et al. 2010), (b) indoor environments are spanned by temperature, light, and carbon dioxide concentration fields that affect the occupants’ comfort and satisfaction towards the environmental quality across different areas, and (c) WiFi access points/hotspots situated at neighboring locations produce different but overlapping wireless signal strength fields over the same environment.",
      "startOffset" : 273,
      "endOffset" : 312
    }, {
      "referenceID" : 26,
      "context" : ", environmental sensing and monitoring) requiring such algorithms often contain multiple fields of interest: (a) Autonomous underwater and surface vehicles are tasked to sample ocean and freshwater phenomena including temperature, salinity, and oxygen concentration fields (Dolan et al. 2009; Podnar et al. 2010), (b) indoor environments are spanned by temperature, light, and carbon dioxide concentration fields that affect the occupants’ comfort and satisfaction towards the environmental quality across different areas, and (c) WiFi access points/hotspots situated at neighboring locations produce different but overlapping wireless signal strength fields over the same environment.",
      "startOffset" : 273,
      "endOffset" : 312
    }, {
      "referenceID" : 11,
      "context" : "Existing works (Brooks, Makarenko, and Upcroft 2008; Ferris, Hähnel, and Fox 2006; Ferris, Fox, and Lawrence 2007; Ko and Fox 2009a; 2009b) have sidestepped this computational difficulty by assuming the availability of data/observations prior to exploration and localization for training the GP observation model offline; some (Brooks, Makarenko, and Upcroft 2008; Ferris, Hähnel, and Fox 2006; Ko and Fox 2009a) have assumed these given prior measurements to be labeled with known locations while others (Ferris, Fox, and Lawrence 2007; Ko and Fox 2009b) have inferred their location labels.",
      "startOffset" : 15,
      "endOffset" : 139
    }, {
      "referenceID" : 11,
      "context" : "Existing works (Brooks, Makarenko, and Upcroft 2008; Ferris, Hähnel, and Fox 2006; Ferris, Fox, and Lawrence 2007; Ko and Fox 2009a; 2009b) have sidestepped this computational difficulty by assuming the availability of data/observations prior to exploration and localization for training the GP observation model offline; some (Brooks, Makarenko, and Upcroft 2008; Ferris, Hähnel, and Fox 2006; Ko and Fox 2009a) have assumed these given prior measurements to be labeled with known locations while others (Ferris, Fox, and Lawrence 2007; Ko and Fox 2009b) have inferred their location labels.",
      "startOffset" : 327,
      "endOffset" : 412
    }, {
      "referenceID" : 12,
      "context" : "Existing works (Brooks, Makarenko, and Upcroft 2008; Ferris, Hähnel, and Fox 2006; Ferris, Fox, and Lawrence 2007; Ko and Fox 2009a; 2009b) have sidestepped this computational difficulty by assuming the availability of data/observations prior to exploration and localization for training the GP observation model offline; some (Brooks, Makarenko, and Upcroft 2008; Ferris, Hähnel, and Fox 2006; Ko and Fox 2009a) have assumed these given prior measurements to be labeled with known locations while others (Ferris, Fox, and Lawrence 2007; Ko and Fox 2009b) have inferred their location labels.",
      "startOffset" : 505,
      "endOffset" : 555
    }, {
      "referenceID" : 28,
      "context" : "Let {Zx}x∈X denote a GP, that is, every finite subset of {Zx}x∈X has a multivariate Gaussian distribution (Rasmussen and Williams 2006).",
      "startOffset" : 106,
      "endOffset" : 135
    }, {
      "referenceID" : 2,
      "context" : "To improve its scalability, GP approximation methods (Chen et al. 2012; 2013; Quiñonero-Candela and Rasmussen 2005) have been proposed, two of which will be described below.",
      "startOffset" : 53,
      "endOffset" : 115
    }, {
      "referenceID" : 27,
      "context" : "To improve its scalability, GP approximation methods (Chen et al. 2012; 2013; Quiñonero-Candela and Rasmussen 2005) have been proposed, two of which will be described below.",
      "startOffset" : 53,
      "endOffset" : 115
    }, {
      "referenceID" : 27,
      "context" : "The main criticism of SoD is that it does not exploit all the data for computing the Gaussian predictive distribution, thus yielding an unrealistic overestimate (4) of the predictive uncertainty (even with fairly redundant data and informative subset S) (Quiñonero-Candela and Rasmussen 2005) and in turn an inaccurately trained observation model.",
      "startOffset" : 254,
      "endOffset" : 292
    }, {
      "referenceID" : 27,
      "context" : "methods reported in (Quiñonero-Candela and Rasmussen 2005) exploiting the notion of a support set S ⊂ X .",
      "startOffset" : 20,
      "endOffset" : 58
    }, {
      "referenceID" : 11,
      "context" : "FITC is previously employed by Ko and Fox (2009a) to speed up the learning of observation model with prior training data.",
      "startOffset" : 31,
      "endOffset" : 50
    }, {
      "referenceID" : 11,
      "context" : "The disadvantages of the former are extensively discussed by Ko and Fox (2009a) while that of the latter are already detailed in Section 1.",
      "startOffset" : 61,
      "endOffset" : 80
    }, {
      "referenceID" : 5,
      "context" : "Even when the online GP proposed by Csató and Opper (2002) is used, it still incurs quadratic time in t per filtering step.",
      "startOffset" : 36,
      "endOffset" : 59
    }, {
      "referenceID" : 5,
      "context" : ", τ = 1) (Csató and Opper 2002)3.",
      "startOffset" : 9,
      "endOffset" : 31
    }, {
      "referenceID" : 0,
      "context" : ", temperature (◦F) and light (Lux)) data (Bodik et al. 2004) measured by 54 sensors deployed in the Intel Berkeley Research lab (Fig.",
      "startOffset" : 41,
      "endOffset" : 60
    }, {
      "referenceID" : 2,
      "context" : "2), (c) urban traffic speeds (UTS) (km/h) data (Chen et al. 2012; 2013) measured at 775 road segments (including highways, arterials, slip roads, etc.",
      "startOffset" : 47,
      "endOffset" : 71
    }, {
      "referenceID" : 2,
      "context" : "The UTS field is modeled using a relational GP (previously developed in (Chen et al. 2012)) whose correlation structure can exploit both the road segment features and road network topology information.",
      "startOffset" : 72,
      "endOffset" : 90
    }, {
      "referenceID" : 28,
      "context" : "The hyperparameters of each GP modeling a different field are learned using the data via maximum likelihood estimation (Rasmussen and Williams 2006).",
      "startOffset" : 119,
      "endOffset" : 148
    }, {
      "referenceID" : 2,
      "context" : "Snelson (2007) pointed out that the sparse online GP of Csató and Opper (2002) is an online learning variant of offline FITC.",
      "startOffset" : 56,
      "endOffset" : 79
    }, {
      "referenceID" : 2,
      "context" : "The UTS field is modeled using a relational GP (previously developed in (Chen et al. 2012)) whose correlation structure can exploit both the road segment features and road network topology information. The hyperparameters of each GP modeling a different field are learned using the data via maximum likelihood estimation (Rasmussen and Williams 2006). Our GP-Localize algorithm is implemented using an odometry motion model4, our online sparse GP (i.e., setting τ = 10 and |S| = 40) for representing the observation model (Section 3), and a particle filter4 of 400 particles for representing the belief of the robot’s location. The number C of sample paths in (9) is set to 400 for all experiments. For the simulated experiments with the WSS and IEQ data, the control actions (i.e., odometry information) are generated using the realistic Pioneer mobile robot module in Player/Stage simulator (Gerkey, Vaughan, and Howard 2003) and the measurements taken along the generated trajectory of 421 (336) time steps from the WSS (IEQ) fields shown in Fig. 1 (Fig. 2) are the Gaussian predictive/posterior means (1) of each full GP modeling a separate field trained using the data. For the simulated experiment with the UTS data, the control actions of the mobile probe vehicle are assumed not to be known; its transition probability of moving from one road segment to another can be learned from vehicle route data using the hierarchical Bayesian nonparametric approach of Yu et al. (2012). The measurements taken along its generated trajectory of 370 time steps from the UTS field are shown in Fig.",
      "startOffset" : 73,
      "endOffset" : 1484
    }, {
      "referenceID" : 22,
      "context" : "So, in our future work, we plan to generalize our algorithm to handle richer, high-dimensional sensing data like laser scans and camera images (Natarajan et al. 2012a; 2012b; Natarajan, Low, and Kankanhalli 2014).",
      "startOffset" : 143,
      "endOffset" : 212
    }, {
      "referenceID" : 27,
      "context" : "The sparse approximation method employed by offline PITC to improve the scalability of the full GP can be similarly applied to computing such a log marginal likelihood scalably, as explained in (Quiñonero-Candela and Rasmussen 2005) (i.",
      "startOffset" : 194,
      "endOffset" : 232
    } ],
    "year" : 2014,
    "abstractText" : "Central to robot exploration and mapping is the task of persistent localization in environmental fields characterized by spatially correlated measurements. This paper presents a Gaussian process localization (GP-Localize) algorithm that, in contrast to existing works, can exploit the spatially correlated field measurements taken during a robot’s exploration (instead of relying on prior training data) for efficiently and scalably learning the GP observation model online through our proposed novel online sparse GP. As a result, GP-Localize is capable of achieving constant time and memory (i.e., independent of the size of the data) per filtering step, which demonstrates the practical feasibility of using GPs for persistent robot localization and autonomy. Empirical evaluation via simulated experiments with real-world datasets and a real robot experiment shows that GP-Localize outperforms existing GP localization algorithms.",
    "creator" : "TeX"
  }
}