{
  "name" : "1609.09869.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "Structured Inference Networks for Nonlinear State Space Models",
    "authors" : [ "Rahul G. Krishnan", "Uri Shalit", "David Sontag" ],
    "emails" : [ "dsontag}@cs.nyu.edu" ],
    "sections" : [ {
      "heading" : "1. Introduction",
      "text" : "Models of sequence data such as hidden Markov models (HMMs) and recurrent neural networks (RNNs) are widely used in machine translation, speech recognition, and computational biology. Linear and non-linear Gaussian state space models (GSSMs, Fig. 1) are used in applications including robotic planning and missile tracking. However, despite huge progress over the last decade, efficient learning of non-linear models from complex high dimensional time-series remains a major challenge. Our paper proposes a unified learning algorithm for a broad class of GSSMs, and we introduce an inference procedure that scales easily to high dimensional data, compiling approximate (and where feasible, exact) inference into the parameters of a neural network.\nIn engineering and control, the parametric form of the GSSM model is often known, with typically a few specific parameters that need to be fit to data. The most commonly used approaches for these types of learning and inference problems are often computationally demanding, e.g. dual extended Kalman filter (Wan and Nelson, 1996), expectation maximization (Briegel and Tresp, 1999; Roweis and Ghahramani, 2000) or particle filters (Schön et al., 2011). Our compiled inference algorithm can easily deal with high-dimensions both in the observed and the latent spaces, without compromising the quality of inference and learning.\nWhen the parametric form of the model is unknown, we propose learning deep Markov models (DMM), a class of generative models where classic linear emission and transition distributions are replaced with complex multi-layer perceptrons (MLPs). These are GSSMs that retain the Markovian\nar X\niv :1\n60 9.\n09 86\n9v 1\n[ st\nat .M\nL ]\n3 0\nstructure of HMMs, but leverage the representational power of deep neural networks to model complex high dimensional data. If one augments a DMM model such as the one presented in Fig. 1 with edges from the observations xt to the latent states of the following time step zt+1, then the DMM can be seen to be similar to, though more restrictive than, stochastic RNNs (Bayer and Osendorfer, 2014) and variational RNNs (Chung et al., 2015).\nOur learning algorithm performs stochastic gradient ascent on a variational lower bound of the likelihood. Instead of introducing variational parameters for each data point, we compile the inference procedure at the same time as learning the generative model. This idea was originally used in the wake-sleep algorithm for unsupervised learning (Hinton et al., 1995), and has since led to state-of-the-art results for unsupervised learning of deep generative models (Kingma and Welling, 2014; Mnih and Gregor, 2014; Rezende et al., 2014).\nSpecifically, we introduce a new family of structured inference networks, parameterized by recurrent neural networks, and evaluate their effectiveness in three scenarios: (1) when the generative model is known and fixed, (2) in parameter estimation when the functional form of the model is known and (3) for learning deep Markov models. By looking at the structure of the true posterior, we show both theoretically and empirically that inference for a latent state should be performed using information from its future, as opposed to recent work which performed inference using only information from the past (Chung et al., 2015; Gan et al., 2015; Gregor et al., 2015). We also outperform mean-field based approaches. Finally, we learn a DMM on a polyphonic music dataset and on a dataset of electronic health records (a complex high dimensional setting with missing data). We use the model learned on health records to ask queries such as “what would have happened to patients had they not received treatment”, and show that our model correctly identifies the way certain medications affect a patient’s health.\nRelated Work: Learning GSSMs with MLPs for the transition distribution was considered by (Raiko and Tornio, 2009). They approximate the posterior with non-linear dynamic factor analysis (Valpola and Karhunen, 2002), which scales quadratically with the observed dimension and is impractical for large-scale learning.\nRecent work has also considered variational learning of time-series data using inference or recognition networks. Archer et al. (2015) propose using a block-diagonal Gaussian approximation to the posterior, parameterized by neural networks. Johnson et al. (2016) consider learning structured time-series models by approximating the posterior distribution with conditional random fields. Bayer and Osendorfer (2014) and Fabius and van Amersfoort (2014) create a stochastic variant of RNNs by making the hidden state of the RNN at every time step be a function of independently sampled latent variables. Chung et al. (2015) apply a similar model to speech data, sharing parameters between the RNNs for the generative model and the inference network. Gan et al. (2015) learn a model with\ndiscrete random variables, using a structured inference network that only considers information from the past, similar to Chung et al. (2015) and Gregor et al. (2015). In contrast to these works, we use information from the future within a structured inference network, which we show to be preferable both theoretically and practically. Additionally, we systematically evaluate the impact of the different variational approximations on learning. Watter et al. (2015) construct a first-order Markov model using inference networks. However, their learning algorithm is based on data tuples over consecutive time steps. This makes the strong assumption that the posterior distribution can be recovered based on observations at the current and next time-step. As we show, for generative models like the one in Fig. 1, the posterior distribution at any time step is a function of all future observations.\nThis paper expands an earlier work (Krishnan et al. 2015). The current paper instantiates the inference scheme presented in (Krishnan et al., 2015) [Thm. 5.1] with a specific neural architecture, evalutes several experimental benchmarks, and explores in depth the impact of inference on learning. We also revamped the names of the underlying inference scheme, based on suggestions made by reviewers."
    }, {
      "heading" : "2. Background",
      "text" : "Gaussian State Space Models: We consider both inference and learning in a class of latent variable models given by:\nzt ∼ N (Gα(zt−1,∆t), Sβ(zt−1,∆t)) (Transition) xt ∼ Π(Fκ(zt)) (Emission) (1)\nWe assume that the distribution of the latent states is a multivariate Gaussian with a mean and covariance which are differentiable functions of the previous latent state. The multivariate observations xt are distributed according to a distribution Π (e.g., independent Bernoullis if the data is binary) whose parameters are a function of the corresponding latent state zt. Collectively, we denote by θ = {α, β, κ} the parameters of the generative model. Eq. 1 subsumes a large family of linear and non-linear Gaussian state space models. For example, by setting Gα(zt−1) = Gtzt−1, Sβ = Σt,Fκ = Ftzt we obtain linear state space models. The functional forms and initial parameters for Gα, Sβ,Fκ may be pre-specified.\nVariational Learning: Using recent advances in variational inference we optimize a variational lower bound on the data log-likelihood. The key technical innovation is the introduction of an inference network or recognition network (Hinton et al., 1995), a neural network which approximates the intractable posterior. This is a parametric conditional distribution that is optimized to perform inference. Throughout this paper we will use θ to denote the parameters of the generative model, and φ to denote the parameters of the inference network.\nLet p(x, z) = pθ(z)pθ(x|z) be a generative model for the set of observations x. The posterior distribution pθ(z|x) is typically intractable. Using the well-known variational principle, we posit an approximate posterior distribution qφ(z|x) to obtain the following lower bound on the marginal likelihood:\nlog pθ(x) ≥ E qφ(z|x) [log pθ(x|z)]−KL( qφ(z|x)||pθ(z) ), (2)\nwhere the inequality is by Jensen’s inequality. Kingma and Welling (2014); Rezende et al. (2014) use a neural net (with parameters φ) to parameterize qφ. The challenge in the resulting optimization problem is that the lower bound (2) includes an expectation w.r.t. qφ, which implicitly depends on the network parameters φ. This difficulty is overcome by using stochastic backpropagation. We\nuse a Normally distributed variational approximation: ie. qφ(z|x) ∼ N (µφ(x),Σφ(x)), where µφ(x),Σφ(x) are functions of the observation x which parameterize the Normal distribution. Using this assumption, a simple transformation allows one to obtain unbiased Monte Carlo estimates of the gradients of Eqφ(z|x) [log pθ(x|z)] with respect to φ. The KL term in (2) can be estimated similarly since it is also an expectation. If we assume the prior pθ(z) is also Normally distributed, the KL and its gradients may be obtained analytically."
    }, {
      "heading" : "3. A Factorized Variational Lower Bound",
      "text" : "We leverage stochastic back-propagation to learn generative models given by Eq. 1, corresponding to the graphical model in Figure 1. Our insight is that for the purpose of inference, we can use the Markov properties of the generative model to guide us in deriving a structured approximation to the posterior. Specifically, the posterior factorizes as:\np(~z|~x) = p(z1|~x) T∏ t=2 p(zt|zt−1, xt, . . . , xT ). (3)\nThis factorization follows from conditional independencies in the model and is detailed in Appendix C. We directly mimic the structure of the posterior with the following factorization of the variational approximation:\nqφ(~z|~x) = T∏ t=1 qφ(zt|zt−1, xt, . . . , xT ) (4) s.t. qφ(zt|zt−1, xt, . . . , xT ) ∼ N (µφ(zt−1, xt, . . . , xT ),Σφ(zt−1, xt, . . . , xT ))\nwhere µφ and Σφ are functions parameterized by neural nets. Although qφ has the option to condition on all information across time, Eq. 3 suggests that in fact it suffices to condition on information from the future and the previous latent state. The previous latent state serves as a summary statistic for information from the past.\nDeriving a Variational Lower Bound: For a generative model (with parameters θ) and an inference network (with parameters φ), we are interested in maxθ log pθ(~x). For ease of exposition, we instantiate the derivation of the variational bound for a single data point ~x though we learn θ, φ from a dataset.\nThe lower bound in Eq. 2 has an analytic form of the KL term only for the simplest of transition models Gα, Sβ between zt−1 and zt (Eq. 1). One could estimate the gradient of the KL term by sampling from the variational model, but that results in high variance estimates and gradients. We use a different factorization of the KL term, leading to the variational lower bound we use as our objective function:\nL(~x; (θ, φ)) = T∑ t=1 E qφ(zt|~x) [log pθ(xt|zt)]−KL(qφ(z1|~x)||pθ(z1)) (5)\n− T∑ t=2 E qφ(zt−1|~x) [KL(qφ(zt|zt−1, ~x)||pθ(zt|zt−1))] .\nThe derivation of the bound and the factorization of the KL divergence is detailed in Appendix A,B. The key point is the resulting objective function has stable analytic gradients, since the KL divergence does not need to be approximated with Monte-Carlo estimation.\nLearning with Gradient Descent: The objective in Eq. 6 is differentiable in the parameters of the model (θ, φ). If the generative model θ is fixed, we perform gradient ascent of (6) in φ. Otherwise, we perform gradient ascent in both φ and θ. We use stochastic backpropagation (Kingma and Welling, 2014; Rezende et al., 2014) for estimating the gradient w.r.t. φ. Note that the expectations are only taken with respect to the variables zt−1, zt, which are the sufficient statistics of the Markov model. This is in contrast to the variational bound obtained by Chung et al. (2015) in Eq. 7 of their paper, where expectations are taken over all past latent states. For the KL terms in Eq. 6, we use the fact that the prior pθ(zt|zt−1) and the variational approximation to the posterior qφ(zt|zt−1, ~x) are both normally distributed, and hence their KL divergence may be estimated analytically (see Appendix B)."
    }, {
      "heading" : "4. Structured Inference Networks",
      "text" : "We now detail the way we construct the variational approximation qφ, and specifically how we model the mean and diagonal covariance functions µφ and Σφ using recurrent neural networks (RNNs). This parameterization cannot in general be expected to be equal to pθ(z|x), but in many cases is a reasonable approximation. We use RNNs due to their high model capacity and ability to scale well to large datasets.\nTable 1 details the different choices for inference networks that we evaluate. The Deep Kalman Smoother, DKS, corresponds exactly to the functional form suggested by Eq. 3, and is our proposed variational approximation. The DKS smoothes information from the past (zt) and future (xt, . . . xT ) to form the approximate posterior.\nWe also evaluate other possibilities for the variational models (inference networks) qφ: two are mean-field models (denoted MF) and two are structured models (denoted ST). They are distinguished by whether they use information from the past (denoted L, for left), the future (denoted R, for right), or both (denoted LR). See Figure 2 for an illustration of two of these methods. Each conditions on a different subset of the observations to summarize information in the input sequence ~x. DKS corresponds to ST-R.\nThe hidden states of the RNN are used to parameterize the parameters of the variational distribution, which go through what we call the “combiner function”. We obtain the mean µq and diagonal covariance σ2q for the posterior at each time-step in a manner akin to Gaussian belief propagation. Specifically, we interpret the hidden states of the forward and backward RNNs as parameterizing the mean and variance of two Gaussian-distributed “messages” summarizing the observations from the past and the future, respectively. We then multiply these two Gaussians, performing a varianceweighted average of the means. All operations should be understood to be performed element-wise on the corresponding vectors.\nCombiner Function for Mean Field Approximations: For the MF-LR inference network, the mean µt and covariance Σt of the variational distribution qφ(zt|~x) are predicted using the output of\nthe RNN (not conditioned on zt−1) as follows, where Softplus(x) = log(1 + exp(x)):\nµr = W right µr h right t + b right µr ; σ 2 r = Softplus(W right σ2r h right t + b right σ2r ) µl = W left µl hleftt + b left µl ; σ2l = Softplus(W left σ2l hleftt + b left σ2l )\nµq = µrσ\n2 l + µlσ 2 r\nσ2r + σ 2 l\n; σ2q = σ2r σ 2 l\nσ2r + σ 2 l\nCombiner Function for Structured Approximations: Since the posterior pθ(zt | zt−1, ~x) ∝ pθ(zt | x1, . . . , xt−1, zt−1)pθ(xt, . . . , xT | zt), a similar reasoning as above suggests that we should use a weighted sum of information from the left and right. The combiner functions for the structured approximations are implemented as:\n(For ST-LR) hcombined = 1\n3 (Tanh(Wzt−1 + b) + h\nleft t + h right t ),\n(For DKS) hcombined = 1\n2 (Tanh(Wzt−1 + b) + h\nright t ),\nµq = Wµqhcombined + bµq (Posterior Means and Covariances) σ2q = Softplus(Wσ2qhcombined + bσ2q )\nThe combiner function uses the Tanh non-linearity from zt−1 to approximate the transition function (alternatively, one could share parameters with the generative model), and here we use a simple weighting between the components.\nt ) respectively. Then through a\nfurther sequence of non-linearities which we call the “combiner function” (marked (a) above), and denoted by the red arrows, it outputs two vectors µ and Σ, parameterizing the mean and diagonal covariance of qφ(zt|zt−1, ~x) of Eq. 4. Samples ẑt are drawn from qφ(zt|zt−1, ~x), as indicated by the black dashed arrows. For the structured variational models ST-LR, the samples ẑt are fed into the computation of µt+1 and Σt+1, as indicated by the red arrows with the label (a). The mean-field model does not have these arrows, and therefore computes qφ(zt|~x). We use ẑ0 = ~0. Table of Inference Networks: BRNN refers to a Bidrectional RNN and comb.fxn is shorthand for combiner function."
    }, {
      "heading" : "5. Deep Markov Models",
      "text" : "Following Raiko et al. (2006), we apply the ideas of deep learning to non-linear continuous state space models. Where the transition and emission function have an unknown functional form, we parameterize Gα, Sβ,Fκ from Eq. 1 with deep neural networks. See Figure 1 (right) for an illustration of the graphical model.\nEmission Function: We parameterize the emission function Fκ using a two-layer MLP (multilayer perceptron), MLP(x,NL1,NL2) = NL2(W2NL1(W1x+ b1) + b2)), where NL denotes nonlinearities such as ReLU, sigmoid, or Tanh units applied element-wise to the input vector. For modeling binary data, Fκ(zt) = Sigmoid(WemissionMLP(zt,ReLU,ReLU)+bemission) parameterizes the mean probabilities of independent Bernoullis.\nGated Transition Function: Instead of MLPs, we use a gated transition function inspired by Gated Recurrent Units (Chung et al., 2014). Gated recurrent units (GRUs) are a neural architecture that parameterizes the recurrence equation in the RNN with gating units to control the flow of information from one hidden state to the next, conditioned on the observation. Unlike GRUs, in the DMM, the transition function is not conditional on any of the observations. All the information must be encoded in the completely stochastic latent state. To achieve this goal, we create a Gated Transition Function. We would like the model to have the flexibility to choose a linear transition for some dimensions while having a non-linear transitions for the others. We adopt the following parameterization, where I denotes the identity function and denotes element-wise multiplication: Using the notation for MLP from the main paper. How Gα and Sβ are defined as a function of zt−1.\ngt = MLP(zt−1,ReLU,Sigmoid) (Gating Unit)\nht = MLP(zt−1,ReLU, I) (Proposed mean) (Transition Mean Gα and Sβ) µt(zt−1) = (1− gt) (Wµpzt−1 + bµp) + gt ht σ2t (zt−1) = Softplus(Wσ2pReLU(ht) + bσ2p)\nNote that the architecture shares the bottom layer of the mean and covariance functions. In our experiments, we initialize Wµp to be the identity function and bµp to 0. The parameters of the emission and transition function form the set θ."
    }, {
      "heading" : "6. Evaluation",
      "text" : "Our models and learning algorithm are implemented in Theano (Theano Development Team, 2016). We use Adam (Kingma and Ba, 2015) with a learning rate of 0.0008 to train the DMM. Our code may be found at https://github.com/clinicalml/structuredinference."
    }, {
      "heading" : "6.1 Datasets",
      "text" : "We evaluate on three datasets. Synthetic: We consider simple linear and non-linear GSSMs. To train the inference networks we use N = 5000 datapoints of length T = 25. We consider both one and two dimensional systems for inference and parameter estimation. We compare our results using the training value\nof the variational bound L(~x; (θ, φ)) (Eq. 6) and the RMSE = √\n1 N ∑N i=1 1 T ∑T t=1[µφ(xi,t)− z∗i,t]2,\nwhere z∗ correspond to the true underlying zs that generated the data.\nPolyphonic Music: We train DMMs on polyphonic music data (Boulanger-lewandowski et al., 2012). An instance in the sequence comprises an 88-dimensional binary vector corresponding to the notes of a piano. We learn for 2000 epochs and report results based on early stopping using the validation set. We report held-out negative log-likelihood (NLL) in the format “a (b) {c}”. a is an importance sampling based estimate of the NLL (details in appendix); b = 1∑N\ni=1 Ti\n∑N i=1−L(~x; θ, φ)\nwhere Ti is the length of sequence i. This is an upper bound on the NLL, which facilitates comparison to RNNs; From inspecting the code for TSBN (Gan et al., 2015) we found that they report c = 1 N ∑N i=1 1 Ti L(~x; θ, φ). We compute this to facilitate comparison with their work.\nElectronic Health Records (EHRs): The dataset comprises 5000 diabetic patients using data from a major health insurance provider. The observations of interest are: A1c level (hemoglobin A1c, a protein for which a high level indicates that the patient is diabetic) and glucose (blood sugar). We bin glucose into quantiles and A1c into clinically meaningful bins. The observations also include age, gender and ICD-9 diagnosis codes for co-morbidities of diabetes such as congestive heart failure, chronic kidney disease and obesity. There are 48 binary observations for a patient at every time-step. We group each patient’s data (over 4 years) into three month intervals, yielding a sequence of length 18."
    }, {
      "heading" : "6.2 Compiling Exact Inference",
      "text" : "We investigate whether inference networks can accurately compile exact posterior inference into the network parameters φ for linear GSSMs when exact inference is feasible. For this experiment we optimize Eq. 6 over φ, while θ is fixed to a synthetic distribution given by a one-dimensional GSSM. We compare results obtained by the various approximations we propose to those obtained by Kalman smoothing (Duckworth, 2016) which performs exact inference. Fig. 4 depicts our results. The proposed DKS (i.e., ST-R) and ST-LR outperform the mean-field based variational method MF-L that only looks at information from the past. MF-LR, however, is often able to catch up when it comes to RMSE, highlighting the role that information from the future plays when performing posterior inference, as is evident in the posterior factorization (3). Both DKS and ST-LR converge to the RMSE of the exact Smoothed KF, and their bound on the likelihood becomes tight."
    }, {
      "heading" : "6.3 Inference for Parameter Estimation",
      "text" : "On synthetic non-linear datasets (see Appendix E) we find, similarly, that the structured variational approximations are more capable of generalizing inference to unseen data while being able to match inference using a smoothed Unscented Kalman Filter (Wan et al., 2000). Finally, Fig. 3 illustrates a toy instance where we perform parameter estimation in a synthetic, two-dimensional, non-linear GSSM.\n0 5 10 15 20 25 10 5\n0 5\n0 5 10 15 20 25 6 4 20\n2\n4\n6"
    }, {
      "heading" : "6.4 Mean-Field vs Structured Inference",
      "text" : ""
    }, {
      "heading" : "6.5 A Generalization of the DMM",
      "text" : "To display the efficacy of our inference algorithm to model variants beyond first-order Markov Models, we further augment the DMM with edges from xt−1 to zt and from xt−1 to xt. We refer to the resulting generative model as DMM-Augmented (Aug.). Augmenting the DMM with additional edges realizes a richer class of generative models. The baselines we compare to in Table 3 also have more complex generative models than the DMM. STORN has edges from xt−1 to zt given by the recurrence update and TSBN has edges from xt−1 to zt as well as from xt−1 to xt. HMSBN shares\nthe same structural properties as the DMM, but is learned using a simpler inference network. We show that DKS can be used as is for inference on a more complex generative model than DMM, while making gains in held-out likelihood. All following experiments use DKS for posterior inference.\nIn Table 3, as we increase the complexity of the generative model, we obtain better results across all datasets. The DMM outperforms both RNNs and HMSBN everywhere, outperforms STORN on JSB, Nottingham and outperform TSBN on all datasets except Piano. Compared to LV-RNN (that optimizes the inclusive KL-divergence), DMM-Aug obtains better results on all datasets except JSB. This showcases our flexible, structured inference network’s ability to learn powerful generative models that compare favourably to other state of the art models. We provide audio files for samples from the learned DMM models in the code repository."
    }, {
      "heading" : "6.6 EHR Patient Data",
      "text" : "Learning models from large observational health datasets is a promising approach to advancing precision medicine. Such models could be used, for example, to understand which medications work best, for whom. In this section, we show that the DMM, trained on EHR data using the DKS may be used for precisely such an application. We highlight some of the challenges we overcome to perform learning in this data:\n• We make use of the time-varying drug prescription ut for each patient. We augment the DMM’s transition function as zt ∼ N (Gα(zt−1, ut−1,∆t), Sβ(zt−1, ut−1,∆t) (cf. (1)), where ut is a binary indicator vector of eight diabetic drugs including Metformin and Insulin. Metformin is the most commonly prescribed first-line anti-diabetic drug.\n• A subset of the observations (such as A1C and Glucose values) is frequently missing in the data. We marginalize them out during learning, which is straightforward within the probabilistic semantics of our Bayesian network.\n• The choice of emission and transition function to use for such data is not well understood. In Figure 5 (right), we experiment with variants of DMMs and find that using MLPs (rather than linear functions) in the emission and transition function yield the best (in terms of held-out likelihood) generative models.\nModeling the effect of Diabetic Medications: Since our cohort comprises diabetic patients, we ask what would have happened to a patient had diabetic drugs not been prescribed? We perform inference using held-out patient data leading up to the time k of first prescription of Metformin. From the posterior mean, we perform ancestral sampling tracking two latent trajectories: (1) the factual: where we sample new latent states conditioned on the medication ut the patient had actually received and (2) the counterfactual: where we sample conditioned on not receiving any drugs for all remaining timesteps (i.e uk set to the zero-vector). We reconstruct the patient observations xk, . . . , xT , threshold the predicted values of A1C levels into high and low and visualize the average number of highs A1C levels we observe among the synthetic patients in both scenarios. This is an example of performing do-calculus (Pearl, 2009) in order to estimate model-based counterfactual effects.\nThe results are shown in Figure 5. We see the model learns that, on average, patients who were prescribed diabetes medication had more controlled levels of A1C than patients who did not receive any medication. Despite being an aggregate effect, this is interesting because it is a phenomenon that coincides with our intuition but was confirmed by the model in an entirely unsupervised manner. Note that in our model, most diabetic patients are indeed prescribed medications, making the counterfactual prediction harder. The ability of this model to answer such queries opens up possibilities into building personalized neural models of healthcare. Further experiments, samples from the learned generative model and implementation details may be found in the appendix."
    }, {
      "heading" : "7. Discussion",
      "text" : "We introduce a general algorithm for scalable learning in a rich family of latent variable models for time-series data. The space complexity of our learning algorithm depends neither on the sequence length T nor on the training set size N , offering massive savings compared to classical variational inference methods. Since we use RNNs only in the inference network, it should be possible to continue to increase their capacity and condition on different modalities that might be relevant to posterior inference without worry of overfitting the data. Finally, we showcased an application of the learning algorithm to modeling longitudinal patient data in electronic health records and inferring treatment effect."
    }, {
      "heading" : "Acknowledgements",
      "text" : "The Tesla K40s used for this research were donated by the NVIDIA Corporation. The authors gratefully acknowledge support by the DARPA Probabilistic Programming for Advancing Machine Learning (PPAML) Program under AFRL prime contract no. FA8750-14-C-0005, ONR #N00014-131-0646, and NSF CAREER award #1350965. We thank the anonymous reviewers for the comments."
    }, {
      "heading" : "Appendix A. Lower Bound on the Likelihood of data",
      "text" : "We can derive the bound on the likelihood L(~x; (θ, φ)) as follows:\nlog pθ(~x) ≥ ∫ ~z qφ(~z|~x) log pθ(~z)pθ(~x|~z) qφ(~z|~x) d~z ( Using xt ⊥ x¬t|~z )\n= E qφ(~z|~x) [log pθ(~x|~z)]−KL(qφ(~z|~x)||pθ(~z)) = T∑ t=1 E qφ(zt|~x) [log pθ(xt|zt)]−KL(qφ(~z|~x)||pθ(~z)) (6) = L(~x; (θ, φ))\nIn the following we omit the dependence of q on ~x, and omit the subscript φ. We can show that the KL divergence between the approximation to the posterior and the prior simplifies as:\nKL(q(z1, . . . , zT )||p(z1, . . . , zT )) = ∫ z1 . . . ∫ zT q(z1) . . . q(zT |zT−1) log p(z1, z2, . . . , zT )\nq(z1) . . . q(zT |zT−1) (Factorization of the variational distribution)\n= ∫ z1 . . . ∫ zT q(z1) . . . q(zT |zT−1) log p(z1)p(z2|z1) . . . p(zT |zT−1)\nq(z1) . . . q(zT |zT−1) (Factorization of the prior)\n= ∫ z1 . . . ∫ zT q(z1) . . . q(zT |zT−1) log p(z1) q(z1) + T∑ t=2 ∫ z1 . . . ∫ zT q(z1) . . . q(zT |zT−1) log p(zt|zt−1) q(zt|zt−1)\n= ∫ z1 q(z1) log p(z1) q(z1) + T∑ t=2 ∫ zt−1 ∫ zt q(zt) log p(zt|zt−1) q(zt|zt−1)\n(Each expectation over zt is constant for t /∈ {t, t− 1})\n= KL(q(z1)||p(z1)) + T∑ t=2 E q(zt−1) [KL(q(zt|zt−1)||p(zt|zt−1))]\n(7)\nFor evaluating the marginal likelihood on the test set, we can use the following Monte-Carlo estimate:\np(~x) u 1\nS S∑ s=1 p(~x|~z(s))p(~z(s)) q(~z(s)|~x) ~z (s) ∼ q(~z|~x) (8)\nThis may be derived in a manner akin to the one depicted in Appendix E (Rezende et al., 2014) or Appendix D (Kingma and Welling, 2014).\nThe log likelihood on the test set is computed using:\nlog p(~x) u log 1\nS S∑ s=1 exp log [ p(~x|~z(s))p(~z(s)) q(~z(s)|~x) ] (9)\nEq. 9 may be computed in a numerically stable manner using the log-sum-exp trick."
    }, {
      "heading" : "Appendix B. KL divergence between Prior and Posterior",
      "text" : "Maximum likelihood learning requires us to compute:\nKL(q(z1, . . . , zT )||p(z1, . . . , zT )) = KL(q(z1)||p(z1)) + T−1∑ t=2 E q(zt−1) [KL(q(zt|qt−1)||p(zt|zt−1))] (10)\nThe KL divergence between two multivariate Gaussians q, p with respective means and covariances µq,Σq, µp,Σp can be written as:\nKL(q||p) = 1 2 (log |Σp| |Σq|︸ ︷︷ ︸\n(a)\n−D + Tr(Σ−1p Σq)︸ ︷︷ ︸ (b) + (µp − µq)TΣ−1p (µp − µq)︸ ︷︷ ︸ (c) ) (11)\nThe choice of q and p is suggestive. using (10) & (11), we can derive a closed form for the KL divergence between q(z1 . . . zT ) and p(z1 . . . zT ). µq,Σq are the outputs of the variational model. Our functional form for µp,Σp is based on our generative and can be summarized as:\nµp1 = 0 Σp1 = 1 µpt = G(zt−1, ut−1) = Gt−1 Σpt = ∆~σ\nHere, Σpt is assumed to be a learned diagonal matrix and ∆ a scalar parameter. Term (a) For t = 1, we have:\nlog |Σp1| |Σq1| = log|Σp1|− log|Σq1|= − log|Σq1| (12)\nFor t > 1, we have:\nlog |Σpt| |Σqt| = log|Σpt|− log|Σqt|= D log(∆) + log|~σ|− log|Σqt| (13)\nTerm (b) For t = 1, we have: Tr(Σ−1p1 Σq1) = Tr(Σq1) (14)\nFor t > 1, we have:\nTr(Σ−1pt Σqt) = 1\n∆ Tr(diag(~σ)−1Σqt) (15)\nTerm (c) For t = 1, we have:\n(µp1 − µq1)TΣ−1p1 (µp1 − µq1) = ||µq1||2 (16)\nFor t > 1, we have:\n(µpt − µqt)TΣ−1pt (µpt − µqt) = ∆(Gt−1 − µqt)T diag(~σ)−1(Gt−1 − µqt) (17)\nRewriting (10) using (12), (13), (14), (15), (16), (17), we get:\nKL(q(z1, . . . , zT )||p(z1, . . . , zT )) = 1\n2 ((T − 1)D log(∆) log|~σ|− T∑ t=1 log|Σqt|\n+ Tr(Σq1) + 1\n∆ T∑ t=2 Tr(diag(~σ)−1Σqt) + ||µq1||2+∆ T∑ t=2 E zt−1 [ (Gt−1 − µqt)T diag(~σ)−1(Gt−1 − µqt) ] )\nAlgorithm 1 Learning a DMM with Stochastic Gradient Descent. We use Monte-Carlo (MC) estimates over K samples from the recognition network during learning to evaluate expectations in the bound and gradients. During training we use K = 1 and aggregate gradients across mini-batches.\nInputs: Dataset D := [ ~x1, . . . , ~xN ] Inference Model: qφ(~z|~x) Generative Model: pθ(~x|~z), pθ(~z) while notConverged() do 1. Sample datapoint: (~x, ~u) ∼ D 2. Estimate posterior parameters (Evaluate µφ,Σφ) 3. Sample ~̂z k ∼ qφ(~z|~x), k = 1, . . . ,K 4. Estimate conditional likelihood: pθ(~x|~̂z k) & KL 5. Evaluate L(~x; (θ, φ)) using K samples 6. Estimate MC approx. to∇θL with K samples 7. Estimate MC approx. to∇φL with K samples (Use stochastic backpropagation to move gradients with respect to qφ inside expectation) 8. Update θ, φ using ADAM (Kingma and Ba, 2015) end while"
    }, {
      "heading" : "Appendix C. Learning Algorithm",
      "text" : "Algorithm 1 depicts an overview of the learning algorithm. We outline the algorithm for a mini-batch of size one, but in practice gradients are averaged across stochastically sampled mini-batches of the training set to mitigate the effect of using a single sample (K = 1) during training for estimating expectations and their corresponding gradients. We take a gradient step in θ and φ, typically with an adaptive learning rate such as Kingma and Ba (2015). For the results in Table 3 in the main paper, as in (Kaae Sønderby et al., 2016), we found annealing the KL divergence in the variational bound (L(~x; (θ, φ))) from 0 to 1 over 5000 parameter updates got better results.\nFactorization of the posterior distribution We use the independence statements implied by the graphical model in Figure 1 of the main paper to note that p(~z|~x), the true posterior, factorizes as:\np(~z|~x) = p(z1|~x) T∏ t=2 p(zt|zt−1, ~x)\nNow, we notice that zt ⊥ x1, . . . , xt−1|zt−1, yielding the desired result."
    }, {
      "heading" : "Appendix D. Polyphonic Music Generation",
      "text" : "Experimental Setup: For the polyphonic experiments, we used two-layer MLPs in the emission and the (gated) transition function. The hidden dimension was set to be 100 for the emission distribution and 200 in the transition function. We typically used an RNN sizes from one of {400, 600} and a latent dimension of size 100.\nSamples: Figure 6 depicts mean probabilities of samples from the generative model trained JSB Chorales (Boulanger-lewandowski et al., 2012). MP3 songs corresponding to two different samples from the best DMM model learned on each of the four polyphonic data sets may be found in the code repository.\nExperiments with NADE: We also experiment with Neural Autoregressive Density Estimators (NADE) (Larochelle and Murray, 2011) in the emission distribution for DMM-Aug and denote it DMM-Aug-NADE. In Table 4, we see that DMM-Aug-NADE performs comparably to the state of the art RNN-NADE on JSB, Nottingham and Piano."
    }, {
      "heading" : "Appendix E. Experimental Results on Synthetic Data",
      "text" : "Experimental Setup: We used an RNN size of 40 in the inference networks used for the synthetic experiments.\nLinear SSMs : Figure 7 (N=500, T=25) depicts the performance of inference networks using the same setup as in the main paper, only now using held out data to evaluate the RMSE and the upper bound. We find that the results echo those in the training set, and that on unseen data points, the inference networks, particularly the structured ones, are capable of generalizing compiled inference.\nNon-linear SSMs : Figure 8 considers learning inference networks on a synthetic non-linear dynamical system (N = 5000, T = 25). We find once again that inference networks that match the posterior realize both faster convergence and better training (and validation) accuracy.\nVisualizing Inference: In Figure 9 we visualize the posterior estimates obtained by the inference network. We run posterior inference on the training set 100 times and take the empirical expectation of the posterior means and covariances of each method. For the linear generative model we used above, we compare with\nthe exact posterior means obtained from a Smoothed Kalman Filter. We also generate data from a non-linear model in which case we compare with the Unscented Kalman Filter (UKF) Wan et al. (2000). Both baselines have access to the underlying generative model parameters which they use to perform inference."
    }, {
      "heading" : "Appendix F. Generative Models of Medical Data",
      "text" : "Data from Electronic Health Records is noisy, high dimensional and difficult to characterize easily. Patient records are rarely contiguous over large parts of the dataset and data is often missing (not at random). Modeling such data is a challenging task. We use the DMM for this since:\n• The generative model of a DMM naturally expresses the idea of a time-evolving latent state of the patient (zt)\n• The deep neural networks are capable of representing arbitrarily complex non-linear functions, justifying their use in modeling the unknown emission and transition functions\nGraphical Model: As described in the main paper, we augment the DMM with an additional edge every time step from an external input ut that represents the (binary) set of medications that are prescribed to the patient. Figure 10 represents the generative model when T = 4. The additional dotted edges in the Bayesian network exist but never need to be modeled since xt and ut are always assumed to be observed in the scenarios that we evaluate. A natural line of follow up work would be to consider learning when ut is missing or latent.\n.\nLearning in the Presence of Missing Data: In the original patient data, A1C and Glucose values are not measured at every visit. To deal with this difficulty, we marginalize out missing values during learning. The sub-network of the original graph we are concerned with is the emission function since missingness affects our ability to evaluate log p(xt|zt). However, as we will show, this marginalization is not difficult since the missing random variables are leaves in the Bayesian sub-network (comprised of the emission function). To illustrate this, consider the case where we are modelling two observations at time t, namely mt, ot. The log-likelihood of the data (mt, ot) conditioned on the latent variable zt decomposes as log p(mt, ot|zt) = log p(mt|zt) + log p(ot|zt) since the random variables are conditionally independent given their parent.\nNow, ifm is missing and we wish to marginalize it out, while ot is observed then our log-likelihood is now: log ∫ m p(mt, ot|zt) = log( ∫ m p(mt|zt)p(ot|zt)) = log p(ot|zt) (since ∫ m p(mt|zt) = 1) i.e we effectively ignore the missing observations when estimating the log-likelihood of the data. In our data, we have indicators denoting whether or not the A1C values and Glucose values were observed which we use as markers of missingness. During batch learning, at every time-step t, we obtain a matrix B = log p(xt|zt) of size (batch-size × 48) comprising the log-likelihoods of every dimension for patients in the batch. We multiply this with a matrix of M . M has the same dimensions as B and has a 1 if the patient’s A1C value was observed and a 0 otherwise. For dimensions that are never missing, M is always 1.\nModel Parameterizations for Medical Data: We first investigate the different choices to parameterize the emission and transition distribution for the medical data. We consider linear and non-linear functions. In the linear case, the mean and log-covariances in the transition function are parameterized as linear functions of the previous latent state. The non-linear functions are parameterized by two layer MLPs. The results in Figure\n11 suggest that a non-linear emission and non-linear transition is important in order to be able to model the data, though a linear transition function might work almost as well. Based on this insight, we use non-linear functions in the emission and transition distribution of the DMM. The hidden dimension was set as 200 for the emission and transition functions. We used an RNN size of 400 and a latent dimension of size 50.\nSampling a Patient: We visualize samples from the DMM in Figure 12 The model captures correlations within timesteps as well as variations in A1C level and Glucose level across timesteps. It also appears to capture the rare occurrences of comorbidities that are found amongst diabetic patients.\nUpper Bound on Validation Data\nTransition-[NL]-Emission-[NL]\nTransition-[L]-Emission-[L]\nTransition-[NL]-Emission-[L]\nTransition-[L]-Emission-[NL]"
    } ],
    "references" : [ {
      "title" : "Black box variational inference for state space models",
      "author" : [ "Evan Archer", "Il Memming Park", "Lars Buesing", "John Cunningham", "Liam Paninski" ],
      "venue" : "arXiv preprint arXiv:1511.07367,",
      "citeRegEx" : "Archer et al\\.,? \\Q2015\\E",
      "shortCiteRegEx" : "Archer et al\\.",
      "year" : 2015
    }, {
      "title" : "Learning stochastic recurrent networks",
      "author" : [ "Justin Bayer", "Christian Osendorfer" ],
      "venue" : "arXiv preprint arXiv:1411.7610,",
      "citeRegEx" : "Bayer and Osendorfer.,? \\Q2014\\E",
      "shortCiteRegEx" : "Bayer and Osendorfer.",
      "year" : 2014
    }, {
      "title" : "Modeling temporal dependencies in high-dimensional sequences: Application to polyphonic music generation and transcription",
      "author" : [ "Nicolas Boulanger-lewandowski", "Yoshua Bengio", "Pascal Vincent" ],
      "venue" : "In ICML,",
      "citeRegEx" : "Boulanger.lewandowski et al\\.,? \\Q2012\\E",
      "shortCiteRegEx" : "Boulanger.lewandowski et al\\.",
      "year" : 2012
    }, {
      "title" : "Fisher scoring and a mixture of modes approach for approximate inference and learning in nonlinear state space models",
      "author" : [ "Thomas Briegel", "Volker Tresp" ],
      "venue" : "In NIPS,",
      "citeRegEx" : "Briegel and Tresp.,? \\Q1999\\E",
      "shortCiteRegEx" : "Briegel and Tresp.",
      "year" : 1999
    }, {
      "title" : "Empirical evaluation of gated recurrent neural networks on sequence modeling",
      "author" : [ "Junyoung Chung", "Caglar Gulcehre", "KyungHyun Cho", "Yoshua Bengio" ],
      "venue" : "arXiv preprint arXiv:1412.3555,",
      "citeRegEx" : "Chung et al\\.,? \\Q2014\\E",
      "shortCiteRegEx" : "Chung et al\\.",
      "year" : 2014
    }, {
      "title" : "A recurrent latent variable model for sequential data",
      "author" : [ "Junyoung Chung", "Kyle Kastner", "Laurent Dinh", "Kratarth Goel", "Aaron Courville", "Yoshua Bengio" ],
      "venue" : "In NIPS,",
      "citeRegEx" : "Chung et al\\.,? \\Q2015\\E",
      "shortCiteRegEx" : "Chung et al\\.",
      "year" : 2015
    }, {
      "title" : "Kalman filter, kalman smoother, and em library for python",
      "author" : [ "Daniel Duckworth" ],
      "venue" : "https://pykalman. github.io/,",
      "citeRegEx" : "Duckworth.,? \\Q2016\\E",
      "shortCiteRegEx" : "Duckworth.",
      "year" : 2016
    }, {
      "title" : "Variational recurrent auto-encoders",
      "author" : [ "Otto Fabius", "Joost R van Amersfoort" ],
      "venue" : null,
      "citeRegEx" : "Fabius and Amersfoort.,? \\Q2014\\E",
      "shortCiteRegEx" : "Fabius and Amersfoort.",
      "year" : 2014
    }, {
      "title" : "Deep temporal sigmoid belief networks for sequence modeling",
      "author" : [ "Zhe Gan", "Chunyuan Li", "Ricardo Henao", "David E Carlson", "Lawrence Carin" ],
      "venue" : "In NIPS,",
      "citeRegEx" : "Gan et al\\.,? \\Q2015\\E",
      "shortCiteRegEx" : "Gan et al\\.",
      "year" : 2015
    }, {
      "title" : "DRAW: A recurrent neural network for image generation",
      "author" : [ "Karol Gregor", "Ivo Danihelka", "Alex Graves", "Danilo Jimenez Rezende", "Daan Wierstra" ],
      "venue" : "In ICML,",
      "citeRegEx" : "Gregor et al\\.,? \\Q2015\\E",
      "shortCiteRegEx" : "Gregor et al\\.",
      "year" : 2015
    }, {
      "title" : "Neural adaptive sequential monte carlo",
      "author" : [ "Shixiang Gu", "Zoubin Ghahramani", "Richard E Turner" ],
      "venue" : "In NIPS,",
      "citeRegEx" : "Gu et al\\.,? \\Q2015\\E",
      "shortCiteRegEx" : "Gu et al\\.",
      "year" : 2015
    }, {
      "title" : "The\" wake-sleep\" algorithm for unsupervised neural networks",
      "author" : [ "Geoffrey E Hinton", "Peter Dayan", "Brendan J Frey", "Radford M Neal" ],
      "venue" : null,
      "citeRegEx" : "Hinton et al\\.,? \\Q1995\\E",
      "shortCiteRegEx" : "Hinton et al\\.",
      "year" : 1995
    }, {
      "title" : "Structured VAEs: Composing probabilistic graphical models and variational autoencoders",
      "author" : [ "Matthew J Johnson", "David Duvenaud", "Alexander B Wiltschko", "Sandeep R Datta", "Ryan P Adams" ],
      "venue" : "arXiv preprint arXiv:1603.06277,",
      "citeRegEx" : "Johnson et al\\.,? \\Q2016\\E",
      "shortCiteRegEx" : "Johnson et al\\.",
      "year" : 2016
    }, {
      "title" : "How to Train Deep Variational Autoencoders and Probabilistic Ladder Networks",
      "author" : [ "C. Kaae Sønderby", "T. Raiko", "L. Maaløe", "S. Kaae Sønderby", "O. Winther" ],
      "venue" : null,
      "citeRegEx" : "Sønderby et al\\.,? \\Q2016\\E",
      "shortCiteRegEx" : "Sønderby et al\\.",
      "year" : 2016
    }, {
      "title" : "Adam: A method for stochastic optimization",
      "author" : [ "Diederik Kingma", "Jimmy Ba" ],
      "venue" : "In ICLR,",
      "citeRegEx" : "Kingma and Ba.,? \\Q2015\\E",
      "shortCiteRegEx" : "Kingma and Ba.",
      "year" : 2015
    }, {
      "title" : "Auto-encoding variational bayes",
      "author" : [ "Diederik P Kingma", "Max Welling" ],
      "venue" : "In ICLR,",
      "citeRegEx" : "Kingma and Welling.,? \\Q2014\\E",
      "shortCiteRegEx" : "Kingma and Welling.",
      "year" : 2014
    }, {
      "title" : "Deep kalman filters",
      "author" : [ "Rahul G Krishnan", "Uri Shalit", "David Sontag" ],
      "venue" : "arXiv preprint arXiv:1511.05121,",
      "citeRegEx" : "Krishnan et al\\.,? \\Q2015\\E",
      "shortCiteRegEx" : "Krishnan et al\\.",
      "year" : 2015
    }, {
      "title" : "The neural autoregressive distribution estimator",
      "author" : [ "Hugo Larochelle", "Iain Murray" ],
      "venue" : "In AISTATS,",
      "citeRegEx" : "Larochelle and Murray.,? \\Q2011\\E",
      "shortCiteRegEx" : "Larochelle and Murray.",
      "year" : 2011
    }, {
      "title" : "Neural variational inference and learning in belief networks",
      "author" : [ "Andriy Mnih", "Karol Gregor" ],
      "venue" : "In ICML,",
      "citeRegEx" : "Mnih and Gregor.,? \\Q2014\\E",
      "shortCiteRegEx" : "Mnih and Gregor.",
      "year" : 2014
    }, {
      "title" : "Variational bayesian learning of nonlinear hidden state-space models for model predictive control",
      "author" : [ "Tapani Raiko", "Matti Tornio" ],
      "venue" : null,
      "citeRegEx" : "Raiko and Tornio.,? \\Q2009\\E",
      "shortCiteRegEx" : "Raiko and Tornio.",
      "year" : 2009
    }, {
      "title" : "State inference in variational bayesian nonlinear state-space models",
      "author" : [ "Tapani Raiko", "Matti Tornio", "Antti Honkela", "Juha Karhunen" ],
      "venue" : "In International Conference on ICA and Signal Separation,",
      "citeRegEx" : "Raiko et al\\.,? \\Q2006\\E",
      "shortCiteRegEx" : "Raiko et al\\.",
      "year" : 2006
    }, {
      "title" : "Stochastic backpropagation and approximate inference in deep generative models",
      "author" : [ "Danilo J. Rezende", "Shakir Mohamed", "Daan Wierstra" ],
      "venue" : "In ICML,",
      "citeRegEx" : "Rezende et al\\.,? \\Q2014\\E",
      "shortCiteRegEx" : "Rezende et al\\.",
      "year" : 2014
    }, {
      "title" : "An EM algorithm for identification of nonlinear dynamical systems",
      "author" : [ "Sam Roweis", "Zoubin Ghahramani" ],
      "venue" : null,
      "citeRegEx" : "Roweis and Ghahramani.,? \\Q2000\\E",
      "shortCiteRegEx" : "Roweis and Ghahramani.",
      "year" : 2000
    }, {
      "title" : "System identification of nonlinear state-space models",
      "author" : [ "Thomas B Schön", "Adrian Wills", "Brett Ninness" ],
      "venue" : null,
      "citeRegEx" : "Schön et al\\.,? \\Q2011\\E",
      "shortCiteRegEx" : "Schön et al\\.",
      "year" : 2011
    }, {
      "title" : "An unsupervised ensemble learning method for nonlinear dynamic state-space models",
      "author" : [ "Harri Valpola", "Juha Karhunen" ],
      "venue" : "Neural computation,",
      "citeRegEx" : "Valpola and Karhunen.,? \\Q2002\\E",
      "shortCiteRegEx" : "Valpola and Karhunen.",
      "year" : 2002
    }, {
      "title" : "The unscented kalman filter for nonlinear estimation",
      "author" : [ "Eric Wan", "Ronell Van Der Merwe" ],
      "venue" : "In Adaptive Systems for Signal Processing, Communications, and Control Symposium",
      "citeRegEx" : "Wan and Merwe,? \\Q2000\\E",
      "shortCiteRegEx" : "Wan and Merwe",
      "year" : 2000
    }, {
      "title" : "Dual kalman filtering methods for nonlinear prediction, smoothing and estimation",
      "author" : [ "Eric A. Wan", "Alex T. Nelson" ],
      "venue" : "In NIPS,",
      "citeRegEx" : "Wan and Nelson.,? \\Q1996\\E",
      "shortCiteRegEx" : "Wan and Nelson.",
      "year" : 1996
    }, {
      "title" : "Embed to control: A locally linear latent dynamics model for control from raw images",
      "author" : [ "Manuel Watter", "Jost Tobias Springenberg", "Joschka Boedecker", "Martin Riedmiller" ],
      "venue" : "In NIPS,",
      "citeRegEx" : "Watter et al\\.,? \\Q2015\\E",
      "shortCiteRegEx" : "Watter et al\\.",
      "year" : 2015
    }, {
      "title" : "For the results in Table 3 in the main paper, as in (Kaae Sønderby et al., 2016), we found annealing the KL divergence in the variational bound (L(~x; (θ, φ))) from 0 to 1 over 5000 parameter",
      "author" : [ "Kingma", "Ba" ],
      "venue" : null,
      "citeRegEx" : "Kingma and Ba,? \\Q2015\\E",
      "shortCiteRegEx" : "Kingma and Ba",
      "year" : 2015
    } ],
    "referenceMentions" : [ {
      "referenceID" : 26,
      "context" : "dual extended Kalman filter (Wan and Nelson, 1996), expectation maximization (Briegel and Tresp, 1999; Roweis and Ghahramani, 2000) or particle filters (Schön et al.",
      "startOffset" : 28,
      "endOffset" : 50
    }, {
      "referenceID" : 3,
      "context" : "dual extended Kalman filter (Wan and Nelson, 1996), expectation maximization (Briegel and Tresp, 1999; Roweis and Ghahramani, 2000) or particle filters (Schön et al.",
      "startOffset" : 77,
      "endOffset" : 131
    }, {
      "referenceID" : 22,
      "context" : "dual extended Kalman filter (Wan and Nelson, 1996), expectation maximization (Briegel and Tresp, 1999; Roweis and Ghahramani, 2000) or particle filters (Schön et al.",
      "startOffset" : 77,
      "endOffset" : 131
    }, {
      "referenceID" : 23,
      "context" : "dual extended Kalman filter (Wan and Nelson, 1996), expectation maximization (Briegel and Tresp, 1999; Roweis and Ghahramani, 2000) or particle filters (Schön et al., 2011).",
      "startOffset" : 152,
      "endOffset" : 172
    }, {
      "referenceID" : 1,
      "context" : "1 with edges from the observations xt to the latent states of the following time step zt+1, then the DMM can be seen to be similar to, though more restrictive than, stochastic RNNs (Bayer and Osendorfer, 2014) and variational RNNs (Chung et al.",
      "startOffset" : 181,
      "endOffset" : 209
    }, {
      "referenceID" : 5,
      "context" : "1 with edges from the observations xt to the latent states of the following time step zt+1, then the DMM can be seen to be similar to, though more restrictive than, stochastic RNNs (Bayer and Osendorfer, 2014) and variational RNNs (Chung et al., 2015).",
      "startOffset" : 231,
      "endOffset" : 251
    }, {
      "referenceID" : 11,
      "context" : "This idea was originally used in the wake-sleep algorithm for unsupervised learning (Hinton et al., 1995), and has since led to state-of-the-art results for unsupervised learning of deep generative models (Kingma and Welling, 2014; Mnih and Gregor, 2014; Rezende et al.",
      "startOffset" : 84,
      "endOffset" : 105
    }, {
      "referenceID" : 15,
      "context" : ", 1995), and has since led to state-of-the-art results for unsupervised learning of deep generative models (Kingma and Welling, 2014; Mnih and Gregor, 2014; Rezende et al., 2014).",
      "startOffset" : 107,
      "endOffset" : 178
    }, {
      "referenceID" : 18,
      "context" : ", 1995), and has since led to state-of-the-art results for unsupervised learning of deep generative models (Kingma and Welling, 2014; Mnih and Gregor, 2014; Rezende et al., 2014).",
      "startOffset" : 107,
      "endOffset" : 178
    }, {
      "referenceID" : 21,
      "context" : ", 1995), and has since led to state-of-the-art results for unsupervised learning of deep generative models (Kingma and Welling, 2014; Mnih and Gregor, 2014; Rezende et al., 2014).",
      "startOffset" : 107,
      "endOffset" : 178
    }, {
      "referenceID" : 5,
      "context" : "By looking at the structure of the true posterior, we show both theoretically and empirically that inference for a latent state should be performed using information from its future, as opposed to recent work which performed inference using only information from the past (Chung et al., 2015; Gan et al., 2015; Gregor et al., 2015).",
      "startOffset" : 272,
      "endOffset" : 331
    }, {
      "referenceID" : 8,
      "context" : "By looking at the structure of the true posterior, we show both theoretically and empirically that inference for a latent state should be performed using information from its future, as opposed to recent work which performed inference using only information from the past (Chung et al., 2015; Gan et al., 2015; Gregor et al., 2015).",
      "startOffset" : 272,
      "endOffset" : 331
    }, {
      "referenceID" : 9,
      "context" : "By looking at the structure of the true posterior, we show both theoretically and empirically that inference for a latent state should be performed using information from its future, as opposed to recent work which performed inference using only information from the past (Chung et al., 2015; Gan et al., 2015; Gregor et al., 2015).",
      "startOffset" : 272,
      "endOffset" : 331
    }, {
      "referenceID" : 19,
      "context" : "Related Work: Learning GSSMs with MLPs for the transition distribution was considered by (Raiko and Tornio, 2009).",
      "startOffset" : 89,
      "endOffset" : 113
    }, {
      "referenceID" : 24,
      "context" : "They approximate the posterior with non-linear dynamic factor analysis (Valpola and Karhunen, 2002), which scales quadratically with the observed dimension and is impractical for large-scale learning.",
      "startOffset" : 71,
      "endOffset" : 99
    }, {
      "referenceID" : 0,
      "context" : "Archer et al. (2015) propose using a block-diagonal Gaussian approximation to the posterior, parameterized by neural networks.",
      "startOffset" : 0,
      "endOffset" : 21
    }, {
      "referenceID" : 0,
      "context" : "Archer et al. (2015) propose using a block-diagonal Gaussian approximation to the posterior, parameterized by neural networks. Johnson et al. (2016) consider learning structured time-series models by approximating the posterior distribution with conditional random fields.",
      "startOffset" : 0,
      "endOffset" : 149
    }, {
      "referenceID" : 0,
      "context" : "Archer et al. (2015) propose using a block-diagonal Gaussian approximation to the posterior, parameterized by neural networks. Johnson et al. (2016) consider learning structured time-series models by approximating the posterior distribution with conditional random fields. Bayer and Osendorfer (2014) and Fabius and van Amersfoort (2014) create a stochastic variant of RNNs by making the hidden state of the RNN at every time step be a function of independently sampled latent variables.",
      "startOffset" : 0,
      "endOffset" : 301
    }, {
      "referenceID" : 0,
      "context" : "Archer et al. (2015) propose using a block-diagonal Gaussian approximation to the posterior, parameterized by neural networks. Johnson et al. (2016) consider learning structured time-series models by approximating the posterior distribution with conditional random fields. Bayer and Osendorfer (2014) and Fabius and van Amersfoort (2014) create a stochastic variant of RNNs by making the hidden state of the RNN at every time step be a function of independently sampled latent variables.",
      "startOffset" : 0,
      "endOffset" : 338
    }, {
      "referenceID" : 0,
      "context" : "Archer et al. (2015) propose using a block-diagonal Gaussian approximation to the posterior, parameterized by neural networks. Johnson et al. (2016) consider learning structured time-series models by approximating the posterior distribution with conditional random fields. Bayer and Osendorfer (2014) and Fabius and van Amersfoort (2014) create a stochastic variant of RNNs by making the hidden state of the RNN at every time step be a function of independently sampled latent variables. Chung et al. (2015) apply a similar model to speech data, sharing parameters between the RNNs for the generative model and the inference network.",
      "startOffset" : 0,
      "endOffset" : 508
    }, {
      "referenceID" : 0,
      "context" : "Archer et al. (2015) propose using a block-diagonal Gaussian approximation to the posterior, parameterized by neural networks. Johnson et al. (2016) consider learning structured time-series models by approximating the posterior distribution with conditional random fields. Bayer and Osendorfer (2014) and Fabius and van Amersfoort (2014) create a stochastic variant of RNNs by making the hidden state of the RNN at every time step be a function of independently sampled latent variables. Chung et al. (2015) apply a similar model to speech data, sharing parameters between the RNNs for the generative model and the inference network. Gan et al. (2015) learn a model with",
      "startOffset" : 0,
      "endOffset" : 652
    }, {
      "referenceID" : 16,
      "context" : "This paper expands an earlier work (Krishnan et al. 2015).",
      "startOffset" : 35,
      "endOffset" : 57
    }, {
      "referenceID" : 16,
      "context" : "The current paper instantiates the inference scheme presented in (Krishnan et al., 2015) [Thm.",
      "startOffset" : 65,
      "endOffset" : 88
    }, {
      "referenceID" : 4,
      "context" : "discrete random variables, using a structured inference network that only considers information from the past, similar to Chung et al. (2015) and Gregor et al.",
      "startOffset" : 122,
      "endOffset" : 142
    }, {
      "referenceID" : 4,
      "context" : "discrete random variables, using a structured inference network that only considers information from the past, similar to Chung et al. (2015) and Gregor et al. (2015). In contrast to these works, we use information from the future within a structured inference network, which we show to be preferable both theoretically and practically.",
      "startOffset" : 122,
      "endOffset" : 167
    }, {
      "referenceID" : 4,
      "context" : "discrete random variables, using a structured inference network that only considers information from the past, similar to Chung et al. (2015) and Gregor et al. (2015). In contrast to these works, we use information from the future within a structured inference network, which we show to be preferable both theoretically and practically. Additionally, we systematically evaluate the impact of the different variational approximations on learning. Watter et al. (2015) construct a first-order Markov model using inference networks.",
      "startOffset" : 122,
      "endOffset" : 467
    }, {
      "referenceID" : 11,
      "context" : "The key technical innovation is the introduction of an inference network or recognition network (Hinton et al., 1995), a neural network which approximates the intractable posterior.",
      "startOffset" : 96,
      "endOffset" : 117
    }, {
      "referenceID" : 15,
      "context" : "Kingma and Welling (2014); Rezende et al.",
      "startOffset" : 0,
      "endOffset" : 26
    }, {
      "referenceID" : 15,
      "context" : "Kingma and Welling (2014); Rezende et al. (2014) use a neural net (with parameters φ) to parameterize qφ.",
      "startOffset" : 0,
      "endOffset" : 49
    }, {
      "referenceID" : 15,
      "context" : "We use stochastic backpropagation (Kingma and Welling, 2014; Rezende et al., 2014) for estimating the gradient w.",
      "startOffset" : 34,
      "endOffset" : 82
    }, {
      "referenceID" : 21,
      "context" : "We use stochastic backpropagation (Kingma and Welling, 2014; Rezende et al., 2014) for estimating the gradient w.",
      "startOffset" : 34,
      "endOffset" : 82
    }, {
      "referenceID" : 4,
      "context" : "This is in contrast to the variational bound obtained by Chung et al. (2015) in Eq.",
      "startOffset" : 57,
      "endOffset" : 77
    }, {
      "referenceID" : 4,
      "context" : "Gated Transition Function: Instead of MLPs, we use a gated transition function inspired by Gated Recurrent Units (Chung et al., 2014).",
      "startOffset" : 113,
      "endOffset" : 133
    }, {
      "referenceID" : 18,
      "context" : "Deep Markov Models Following Raiko et al. (2006), we apply the ideas of deep learning to non-linear continuous state space models.",
      "startOffset" : 29,
      "endOffset" : 49
    }, {
      "referenceID" : 14,
      "context" : "We use Adam (Kingma and Ba, 2015) with a learning rate of 0.",
      "startOffset" : 12,
      "endOffset" : 33
    }, {
      "referenceID" : 2,
      "context" : "Polyphonic Music: We train DMMs on polyphonic music data (Boulanger-lewandowski et al., 2012).",
      "startOffset" : 57,
      "endOffset" : 93
    }, {
      "referenceID" : 8,
      "context" : "This is an upper bound on the NLL, which facilitates comparison to RNNs; From inspecting the code for TSBN (Gan et al., 2015) we found that they report c = 1 N ∑N i=1 1 Ti L(~x; θ, φ).",
      "startOffset" : 107,
      "endOffset" : 125
    }, {
      "referenceID" : 6,
      "context" : "We compare results obtained by the various approximations we propose to those obtained by Kalman smoothing (Duckworth, 2016) which performs exact inference.",
      "startOffset" : 107,
      "endOffset" : 124
    }, {
      "referenceID" : 9,
      "context" : "ST-L is a structured variational approximation that only considers information from the past and, up to implementation details, is comparable to the one used by Gregor et al. (2015). Comparing the negative log-likelihoods of the learned models, we see that the looseness in the variational bound (which we first observed in the synthetic setting in Fig.",
      "startOffset" : 161,
      "endOffset" : 182
    }, {
      "referenceID" : 2,
      "context" : "Table Legend: RNN (Boulanger-lewandowski et al., 2012), LV-RNN (Gu et al.",
      "startOffset" : 18,
      "endOffset" : 54
    }, {
      "referenceID" : 10,
      "context" : ", 2012), LV-RNN (Gu et al., 2015), STORN (Bayer and Osendorfer, 2014), TSBN, HMSBN (Gan et al.",
      "startOffset" : 16,
      "endOffset" : 33
    }, {
      "referenceID" : 1,
      "context" : ", 2015), STORN (Bayer and Osendorfer, 2014), TSBN, HMSBN (Gan et al.",
      "startOffset" : 15,
      "endOffset" : 43
    }, {
      "referenceID" : 8,
      "context" : ", 2015), STORN (Bayer and Osendorfer, 2014), TSBN, HMSBN (Gan et al., 2015).",
      "startOffset" : 57,
      "endOffset" : 75
    } ],
    "year" : 2016,
    "abstractText" : "Gaussian state space models have been used for decades as generative models of sequential data. They admit an intuitive probabilistic interpretation, have a simple functional form, and enjoy widespread adoption. We introduce a unified algorithm to efficiently learn a broad class of linear and non-linear state space models, including variants where the emission and transition distributions are modeled by deep neural networks. Our learning algorithm simultaneously learns a compiled inference network and the generative model, leveraging a structured variational approximation parameterized by recurrent neural networks to mimic the posterior distribution. We apply the learning algorithm to both synthetic and real-world datasets, demonstrating its scalability and versatility. We find that using the structured approximation to the posterior results in models with significantly higher held-out likelihood.",
    "creator" : "LaTeX with hyperref package"
  }
}