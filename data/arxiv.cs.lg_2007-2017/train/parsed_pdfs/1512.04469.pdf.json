{
  "name" : "1512.04469.pdf",
  "metadata" : {
    "source" : "META",
    "title" : "Über die Klassifizierung von Knoten in dynamischen Netzwerken mit textuellen Inhalten",
    "authors" : [ "Martin Thoma" ],
    "emails" : [ ],
    "sections" : [ {
      "heading" : null,
      "text" : "1 Über die Klassifizierung von Knoten in dynamischen Netzwerken mit Inhalt\nMartin Thoma\nZusammenfassung—In dieser Arbeit wird der DYCOSAlgorithmus, wie er in [AL11] vorgestellt wurde, erklärt. Er arbeitet auf Graphen, deren Knoten teilweise mit Beschriftungen versehen sind und ergänzt automatisch Beschriftungen für Knoten, die bisher noch keine Beschriftung haben. Dieser Vorgang wird „Klassifizierung“ genannt. Dazu verwendet er die Struktur des Graphen sowie textuelle Informationen, die den Knoten zugeordnet sind. Die in [AL11] beschriebene experimentelle Analyse ergab, dass er auch auf dynamischen Graphen mit 19 396 bzw. 806 635 Knoten, von denen nur 14 814 bzw. 18 999 beschriftet waren, innerhalb von weniger als einer Minute auf einem Kern einer Intel Xeon 2.5 GHz CPU mit"
    }, {
      "heading" : "32 G RAM ausgeführt werden kann. Zusätzlich wird [AL11] kritisch Erörtert und und es werden mögliche Erweiterungen des DYCOS-Algorithmus vorgeschlagen.",
      "text" : "Keywords: DYCOS, Label Propagation, Knotenklassifizierung"
    }, {
      "heading" : "I. EINLEITUNG",
      "text" : "Im Folgenden werden in Abschnitt I-A einige Beispiele, in denen der DYCOS-Algorithmus Anwendung finden könnte, dargelegt. In Abschnitt I-B wird die Problemstellung formal definiert und in Abschnitt I-C wird auf besondere Herausforderungen der Aufgabenstellung hingewiesen."
    }, {
      "heading" : "A. Motivation",
      "text" : "Teilweise beschriftete Graphen sind allgegenwärtig. Publikationsdatenbanken mit Publikationen als Knoten, Literaturverweisen und Zitaten als Kanten sowie von Nutzern vergebene Beschriftungen (sog. Tags) oder Kategorien als Knotenbeschriftungen; Wikipedia mit Artikeln als Knoten, Links als Kanten und Kategorien als Knotenbeschriftungen sowie soziale Netzwerke mit Eigenschaften der Benutzer als Knotenbeschriftungen sind drei Beispiele dafür. Häufig sind Knotenbeschriftungen nur teilweise vorhanden und es ist wünschenswert die fehlenden Knotenbeschriftungen automatisiert zu ergänzen."
    }, {
      "heading" : "B. Problemstellung",
      "text" : "Gegeben ist ein Graph, dessen Knoten teilweise beschriftet sind. Zusätzlich stehen zu einer Teilmenge der Knoten Texte bereit. Gesucht sind nun Knotenbeschriftungen für alle Knoten, die bisher noch nicht beschriftet sind.\nDefinition 1 (Knotenklassifierungsproblem) Sei Gt = (Vt, Et, VL,t) ein gerichteter Graph, wobei Vt die Menge aller Knoten, Et ⊆ Vt × Vt die Kantenmenge und VL,t ⊆ Vt die Menge der beschrifteten Knoten jeweils zum Zeitpunkt t bezeichne. Außerdem sei Lt die Menge aller zum Zeitpunkt t vergebenen\nKnotenbeschriftungen und f : VL,t → Lt die Funktion, die einen Knoten auf seine Beschriftung abbildet.\nWeiter sei für jeden Knoten v ∈ V eine (eventuell leere) Textmenge T (v) gegeben.\nGesucht sind nun Beschriftungen für Vt \\ VL,t, also f̃ : Vt \\ VL,t → Lt. Die Aufgabe, zu Gt die Funktion f̃ zu finden heißt Knotenklassifierungsproblem."
    }, {
      "heading" : "C. Herausforderungen",
      "text" : "Die Graphen, für die dieser Algorithmus konzipiert wurde, sind viele 10 000 Knoten groß und dynamisch. „Dynamisch“ bedeutet in diesem Kontext, dass neue Knoten und eventuell auch neue Kanten hinzu kommen bzw. Kanten oder Knoten werden entfernt werden. Außerdem stehen textuelle Inhalte zu den Knoten bereit, die bei der Klassifikation genutzt werden können. Bei kleinen Änderungen sollte nicht alles nochmals berechnen werden müssen, sondern basierend auf zuvor berechneten Knotenbeschriftungen sollte die Klassifizierung angepasst werden."
    }, {
      "heading" : "II. RELATED WORK",
      "text" : "Sowohl das Problem der Knotenklassifikation, als auch das der Textklassifikation, wurde bereits in verschiedenen Kontexten analysiert. Jedoch scheinen bisher entweder nur die Struktur des zugrundeliegenden Graphen oder nur Eigenschaften der Texte verwendet worden zu sein.\nSo werden in [BCM11], [SJ01] unter anderem Verfahren zur Knotenklassifikation beschrieben, die wie der in [AL11] vorgestellte DYCOS-Algorithmus, um den es in dieser Ausarbeitung geht, auch auf Random Walks basieren.\nObwohl es auch zur Textklassifikation einige Paper gibt [ZG02], [JCSZ10], geht doch keines davon auf den Spezialfall der Textklassifikation mit einem zugrundeliegenden Graphen ein.\nDie vorgestellten Methoden zur Textklassifikation variieren außerdem sehr stark. Es gibt Verfahren, die auf dem bagof-words-Modell basieren [Ko12] wie es auch im DYCOSAlgorithmus verwendet wird. Aber es gibt auch Verfahren, die auf dem Expectation-Maximization-Algorithmus basieren [NMTM99] oder Support Vector Machines nutzen [Joa98].\nEs wäre also gut Vorstellbar, die Art und Weise wie die Texte in die Klassifikation des DYCOS-Algorithmus einfließen zu variieren. Allerdings ist dabei darauf hinzuweisen, dass die im Folgenden vorgestellte Verwendung der Texte sowohl einfach zu implementieren ist und nur lineare Vorverarbeitungszeit in Anzahl der Wörter des Textes hat, als auch es erlaubt einzelne Knoten zu klassifizieren, wobei der Graph nur lokal um den zu klassifizierenden Knoten betrachten werden muss.\nar X\niv :1\n51 2.\n04 46\n9v 1\n[ cs\n.L G\n] 2\n3 N\nov 2\n01 5\n2"
    }, {
      "heading" : "III. DYCOS",
      "text" : "A. Überblick\nDYCOS (DYnamic Classification algorithm with cOntent and Structure) ist ein Knotenklassifizierungsalgorithmus, der Ursprünglich in [AL11] vorgestellt wurde.\nEin zentrales Element des DYCOS-Algorithmus ist der sog. Random Walk: Definition 2 (Random Walk, Sprung) Sei G = (V,E) mit\nE ⊆ V × V ein Graph und v0 ∈ V ein Knoten des Graphen.\nEin Random Walk der Länge l auf G, startend bei v0 ist nun der zeitdiskrete stochastische Prozess, der vi auf einen zufällig gewählten Nachbarn vi+1 abbildet (für i ∈ 0, . . . , l − 1). Die Abbildung vi 7→ vi+1 heißt ein Sprung.\nDer DYCOS-Algorithmus klassifiziert einzelne Knoten, indem r Random Walks der Länge l, startend bei dem zu klassifizierenden Knoten v gemacht werden. Dabei werden die Beschriftungen der besuchten Knoten gezählt. Die Beschriftung, die am häufigsten vorgekommen ist, wird als Beschriftung für v gewählt. DYCOS nutzt also die sog. Homophilie, d. h. die Eigenschaft, dass Knoten, die nur wenige Hops von einander entfernt sind, häufig auch ähnlich sind [BCM11]. Der DYCOSAlgorithmus arbeitet jedoch nicht direkt auf dem Graphen, sondern erweitert ihn mit Hilfe der zur Verfügung stehenden Texte. Wie diese Erweiterung erstellt wird, wird im Folgenden erklärt. Für diese Erweiterung wird zuerst wird Vokabular Wt bestimmt, das charakteristisch für eine Knotengruppe ist. Wie das gemacht werden kann und warum nicht einfach jedes Wort in das Vokabular aufgenommen wird, wird in Abschnitt III-D erläutert. Nach der Bestimmung des Vokabulars wird für jedes Wort im Vokabular ein Wortknoten zum Graphen hinzugefügt. Alle Knoten, die der Graph zuvor hatte, werden nun „Strukturknoten“ genannt. Ein Strukturknoten v wird genau dann mit einem Wortknoten w ∈Wt verbunden, wenn w in einem Text von v vorkommt. Abbildung 1 zeigt beispielhaft den so entstehenden, semi-bipartiten Graphen. Der DYCOS-Algorithmus betrachtet also die Texte, die einem Knoten zugeordnet sind, als eine Multimenge von Wörtern. Das heißt, zum einen wird nicht auf die Reihenfolge der Wörter geachtet, zum anderen wird bei Texten eines Knotens nicht zwischen verschiedenen Texten unterschieden. Jedoch wird die Anzahl der Vorkommen jedes Wortes berücksichtigt.\nEntsprechend werden zwei unterschiedliche Sprungtypen unterschieden, die strukturellen Sprünge und inhaltliche Zweifachsprünge: Definition 3 (struktureller Sprung) Sei GE,t = (Vt, ES,t ∪\nEW,t, VL,t,Wt) der um die Wortknoten Wt erweiterte Graph.\nDann heißt das zufällige wechseln des aktuell betrachteten Knoten v ∈ Vt zu einem benachbartem Knoten w ∈ Vt ein struktureller Sprung.\nSturkturknoten Vt Wortknoten Wt\nAbbildung 1: Erweiterter Graph\nIm Gegensatz dazu benutzten inhaltliche Zweifachsprünge tatsächlich die Grapherweiterung: Definition 4 (inhaltlicher Zweifachsprung) Sei\nGt = (Vt, ES,t ∪EW,t, VL,t,Wt) der um die Wortknoten Wt erweiterte Graph.\nDann heißt das zufällige wechseln des aktuell betrachteten Knoten v ∈ Vt zu einem benachbartem Knoten w ∈ Wt und weiter zu einem zufälligem Nachbar v′ ∈ Vt von w ein inhaltlicher Zweifachsprung.\nJeder inhaltliche Zweifachsprung beginnt und endet also in einem Strukturknoten, springt über einen Wortknoten und ist ein Pfad der Länge 2.\nOb in einem Sprung der Random Walks ein struktureller Sprung oder ein inhaltlicher Zweifachsprung gemacht wird, wird jedes mal zufällig neu entschieden. Dafür wird der Parameter 0 ≤ pS ≤ 1 für den Algorithmus gewählt. Mit einer Wahrscheinlichkeit von pS wird ein struktureller Sprung durchgeführt und mit einer Wahrscheinlichkeit von (1− pS) ein modifizierter inhaltlicher Zweifachsprung, wie er in Abschnitt III-C erklärt wird, gemacht. Der Parameter pS gibt an, wie wichtig die Struktur des Graphen im Verhältnis zu den textuellen Inhalten ist. Bei pS = 0 werden ausschließlich die Texte betrachtet, bei pS = 1 ausschließlich die Struktur des Graphen.\nDie Vokabularbestimmung kann zu jedem Zeitpunkt t durchgeführt werden, muss es aber nicht.\nIn Algorithmus 1 steht der DYCOS-Algorithmus in Form von Pseudocode: In Zeile 8 wird für jeden unbeschrifteten Knoten durch die folgenden Zeilen eine Beschriftung gewählt.\nZeile 10 führt r Random Walks durch. In Zeile 11 wird eine temporäre Variable für den aktuell betrachteten Knoten angelegt.\nIn Zeile 12 bis Zeile 21 werden einzelne Random Walks der Länge l durchgeführt, wobei die beobachteten Beschriftungen gezählt werden und mit einer Wahrscheinlichkeit von pS ein struktureller Sprung durchgeführt wird."
    }, {
      "heading" : "B. Datenstrukturen",
      "text" : "Zusätzlich zu dem gerichteten Graphen Gt = (Vt, Et, VL,t) verwaltet der DYCOS-Algorithmus zwei weitere Datenstruktu-\n3 Algorithmus 1 DYCOS-Algorithmus Input:\n1: GE,t = (Vt, ES,t ∪ EW,t, VL,t,Wt) (Erweiterter Graph), 2: r (Anzahl der Random Walks), 3: l (Länge eines Random Walks), 4: ps (Wahrscheinlichkeit eines strukturellen Sprungs), 5: q (Anzahl der betrachteten Knoten in der Clusteranalyse)\nOutput: Klassifikation von Vt \\ VL,t 6: 7: 8: for each Knoten v ∈ Vt \\ VL,t do 9: d← leeres assoziatives Array 10: for i = 1, . . . , r do 11: w ← v 12: for j = 1, . . . , l do 13: sprungTyp← RANDOM(0, 1) 14: if sprungTyp ≤ pS then 15: w ← STURKTURELLERSPRUNG(w) 16: else 17: w ← INHALTLICHERZWEIFACH-\nSPRUNG(w) 18: beschriftung ← w.GETLABEL() 19: if !d.HASKEY(beschriftung) then 20: d[beschriftung]← 0 21: d[beschriftung]← d[beschriftung] + 1 22: if d.ISEMPTY( ) then . Es wurde kein beschrifteter\nKnoten gesehen 23: MH ← HÄUFIGSTELABELIMGRAPH() 24: else 25: MH ← MAX(d) 26: 27: . Wähle aus der Menge der häufigsten Beschriftungen\nMH zufällig eine aus 28: label← RANDOM(MH) 29: v.ADDLABEL(label) . und weise dieses v zu 30: return Beschriftungen für Vt \\ VL,t\nren:\n• Für jeden Knoten v ∈ Vt werden die vorkommenden Wörter, die auch im Vokabular Wt sind, und deren Anzahl gespeichert. Das könnte z. B. über ein assoziatives Array (auch „dictionary“ oder „map“ genannt) geschehen. Wörter, die nicht in Texten von v vorkommen, sind nicht im Array. Für alle vorkommenden Wörter ist der gespeicherte Wert zum Schlüssel w ∈Wt die Anzahl der Vorkommen von w in den Texten von v.\n• Für jedes Wort des Vokabulars Wt wird eine Liste von Knoten verwaltet, in deren Texten das Wort vorkommt. Diese Liste wird bei den inhaltlichen Zweifachsprung, der in Abschnitt III-C erklärt wird, verwendet."
    }, {
      "heading" : "C. Sprungtypen",
      "text" : "Die beiden bereits definierten Sprungtypen, der strukturelle Sprung sowie der inhaltliche Zweifachsprung werden im Folgenden erklärt.\nDer strukturelle Sprung entspricht einer zufälligen Wahl eines Nachbarknotens, wie es in Algorithmus 2 gezeigt wird.\nAlgorithmus 2 Struktureller Sprung 1: function STURKTURELLERSPRUNG(Knoten v, Anzahl q) 2: n← v.NEIGHBORCOUNT . Wähle aus der Liste der\nNachbarknoten 3: r ← RANDOMINT(0, n− 1) . einen zufällig aus 4: v ← v.NEXT(r) . Gehe zu diesem Knoten 5: return v\nBei inhaltlichen Zweifachsprüngen ist jedoch nicht sinnvoll so strikt nach der Definition vorzugehen, also direkt von einem strukturellem Knoten v ∈ Vt zu einem mit v verbundenen Wortknoten w ∈ Wt zu springen und von diesem wieder zu einem verbundenem strukturellem Knoten v′ ∈ Vt. Würde dies gemacht werden, wäre zu befürchten, dass aufgrund von Homonymen die Qualität der Klassifizierung verringert wird. So hat „Brücke“ im Deutschen viele Bedeutungen. Gemeint sein können z. B. das Bauwerk, das Entwurfsmuster der objektorientierten Programmierung oder ein Teil des Gehirns.\nDeshalb wird für jeden Knoten v, von dem aus ein inhaltlicher Zweifachsprung gemacht werden soll folgende Textanalyse durchgeführt:\nC1 Gehe alle in v startenden Random Walks der Länge 2 durch und erstelle eine Liste L der erreichbaren Knoten v′. Speichere außerdem, durch wie viele Pfade diese Knoten v′ jeweils erreichbar sind.\nC2 Betrachte im Folgenden nur die Top-q Knoten bzgl. der Anzahl der Pfade von v nach v′, wobei q ∈ N eine zu wählende Konstante des DYCOS-Algorithmus ist.1 Diese Knotenmenge heiße im Folgenden T (v) und p(v, v′) sei die Anzahl der Pfade von v über einen Wortknoten nach v′. C3 Wähle mit Wahrscheinlichkeit p(v,v ′)∑\nw∈T (v) p(v,w) den Knoten\nv′ ∈ T (v) als Ziel des Zweifachsprungs.\nKonkret könnte also ein inhaltlicher Zweifachsprung sowie wie in Algorithmus 3 beschrieben umgesetzt werden. Der Algorithmus bekommt einen Startknoten v ∈ VT und einen q ∈ N als Parameter. q ist ein Parameter der für den DYCOSAlgorithmus zu wählen ist. Dieser Parameter beschränkt die Anzahl der möglichen Zielknoten v′ ∈ VT auf diejenigen q Knoten, die v bzgl. der Textanalyse am ähnlichsten sind.\nIn Zeile 2 bis Zeile 7 wird Punkt C1 durchgeführt und alle erreichbaren Knoten in reachableNodes mit der Anzahl der Pfade, durch die sie erreicht werden können, gespeichert.\n1Sowohl für den DBLP, als auch für den CORA-Datensatz wurde in [AL11, S. 364] q = 10 gewählt.\n4 In Zeile 8 wird Punkt C2 durchgeführt. Ab hier gilt\n|T | = { q falls |reachableNodes| ≥ q |reachableNodes| sonst\nBei der Wahl der Datenstruktur von T ist zu beachten, dass man in Zeile 23 über Indizes auf Elemente aus T zugreifen können muss.\nIn Zeile 10 bis 15 wird ein assoziatives Array erstellt, das von v′ ∈ T (v) auf die relative Häufigkeit bzgl. aller Pfade von v zu Knoten aus den Top-q abbildet.\nIn allen folgenden Zeilen wird Punkt C3 durchgeführt. In Zeile 17 bis Zeile 24 wird ein Knoten v′ ∈ T (v) mit einer Wahrscheinlichkeit, die seiner relativen Häufigkeit am Anteil der Pfaden der Länge 2 von v nach v′ über einen beliebigen Wortknoten entspricht ausgewählt und schließlich zurückgegeben.\nAlgorithmus 3 Inhaltlicher Zweifachsprung 1: function INHALTLICHERZWEIFACHSPRUNG(Knoten v ∈\nVT , q ∈ N) 2: erreichbareKnoten← leeres assoziatives Array 3: for each Wortknoten w in v.GETWORDNODES() do 4: for each Strukturknoten x in\nw.GETSTRUCTURALNODES() do 5: if !erreichbareKnoten.HASKEY(x) then 6: erreichbareKnoten[x]← 0 7: erreichbareKnoten[x] ←\nerreichbareKnoten[x] + 1\n8: T ← MAX(erreichbareKnoten, q) 9:\n10: s← 0 11: for each Knoten x ∈ T do 12: s← s+ erreichbareKnoten[x] 13: relativeHaeufigkeit← leeres assoziatives Array 14: for each Knoten x ∈ T do 15: relativeHaeufigkeit← erreichbareKnoten[x]s 16: 17: random← RANDOM(0, 1) 18: r ← 0.0 19: i← 0 20: while s < random do 21: r ← r + relativeHaeufigkeit[i] 22: i← i+ 1 23: v ← T [i− 1] 24: return v\nD. Vokabularbestimmung\nDa die Größe des Vokabulars die Datenmenge signifikant beeinflusst, liegt es in unserem Interesse so wenig Wörter wie möglich ins Vokabular aufzunehmen. Insbesondere sind Wörter nicht von Interesse, die in fast allen Texten vorkommen, wie im Deutschen z. B. „und“, „mit“ und die Pronomen. Es ist\nwünschenswert Wörter zu wählen, die die Texte möglichst stark voneinander Unterscheiden. Der DYCOS-Algorithmus wählt die Top-m dieser Wörter als Vokabular, wobei m ∈ N eine festzulegende Konstante ist. In [AL11, S. 365] wird der Einfluss von m ∈ { 5, 10, 15, 20 } auf die Klassifikationsgüte untersucht und festgestellt, dass die Klassifikationsgüte mit größerem m sinkt, sie also für m = 5 für den DBLP-Datensatz am höchsten ist. Für den CORA-Datensatz wurde mit m ∈ { 3, 4, 5, 6 } getestet und kein signifikanter Unterschied festgestellt.\nNun kann man manuell eine Liste von zu beachtenden Wörtern erstellen oder mit Hilfe des Gini-Koeffizienten automatisch ein Vokabular erstellen. Der Gini-Koeffizient ist ein statistisches Maß, das die Ungleichverteilung bewertet. Er ist immer im Intervall [0, 1], wobei 0 einer Gleichverteilung entspricht und 1 der größtmöglichen Ungleichverteilung.\nSei nun ni(w) die Häufigkeit des Wortes w in allen Texten mit der i-ten Knotenbeschriftung.\npi(w) := ni(w)∑|Lt| j=1 nj(w) (Relative Häufigkeit des Wortes w)\n(1)\nG(w) := |Lt|∑ j=1 pj(w) 2 (Gini-Koeffizient von w) (2)\nIn diesem Fall ist G(w) = 0 nicht möglich, da zur Vokabularbestimmung nur Wörter betrachtet werden, die auch vorkommen.\nEin Vorschlag, wie die Vokabularbestimmung implementiert werden kann, ist als Pseudocode mit Algorithmus 4 gegeben. In Zeile 6 wird eine Teilmenge St ⊆ VL,t zum Generieren des Vokabulars gewählt. In Zeile 8 wird ein Array cLabelWords erstellt, das (|Lt|+ 1) Felder hat. Die Elemente dieser Felder sind jeweils assoziative Arrays, deren Schlüssel Wörter und deren Werte natürliche Zahlen sind. Die ersten |Lt| Elemente von cLabelWords dienen dem Zählen der Häufigkeit der Wörter von Texten aus St, wobei für jede Beschriftung die Häufigkeit einzeln gezählt wird. Das letzte Element aus cLabelWords zählt die Summe der Wörter. Diese Datenstruktur wird in Zeile 9 bis 15 gefüllt.\nIn Zeile 18 bis 20 wird die relative Häufigkeit der Wörter bzgl. der Beschriftungen bestimmt. Daraus wird in Zeile 21 bis 23 der Gini-Koeffizient berechnet. Schließlich werden in Zeile 24 bis 25 die Top-q Wörter mit den höchsten Gini-Koeffizienten zurückgegeben.\nDie Menge St kann aus der Menge aller Dokumente, deren Knoten beschriftet sind, mithilfe des in [Vit85] vorgestellten Algorithmus bestimmt werden."
    }, {
      "heading" : "IV. ANALYSE DES DYCOS-ALGORITHMUS",
      "text" : "Für den DYCOS-Algorithmus wurde in [AL11] bewiesen, dass sich nach Ausführung von DYCOS für einen unbeschrifteten Knoten mit einer Wahrscheinlichkeit von höchstens (|Lt|−1)·e−l·b 2/2 eine Knotenbeschriftung ergibt, deren relative\n5 Algorithmus 4 Vokabularbestimmung Input:\n1: VL,t (beschriftete Knoten), 2: Lt (Menge der Beschriftungen), 3: f : VL,t → Lt (Beschriftungsfunktion), 4: m (Gewünschte Vokabulargröße)\nOutput: Mt (Vokabular) 5: 6: St ← SAMPLE(VL,t) . Wähle St ⊆ VL,t aus 7: Mt ← ∅ . Menge aller Wörter 8: cLabelWords← Array aus (|Lt|+1) assoziativen Arrays 9: for each v ∈ St do 10: i← GETLABEL(v) 11: . w ist das Wort, c ist die Häufigkeit 12: for each (w, c) ∈ GETTEXTASMULTISET(v) do 13: cLabelWords[i][w]← cLabelWords[i][w] + c 14: cLabelWords[|Lt|][w]← cLabelWords[i][|Lt|]+\nc 15: Mt =Mt ∪ { w } 16: 17: for each Wort w ∈Mt do 18: p← Array aus |Lt| Zahlen in [0, 1] 19: for each Label i ∈ Lt do 20: p[i]← cLabelWords[i][w]cLabelWords[i][|Lt|] 21: w.gini ← 0 22: for each i ∈ 1, . . . , |Lt| do 23: w.gini ← w.gini + p[i]2\n24: Mt ← SORTDESCENDINGBYGINI(Mt) 25: return TOP(Mt,m)\nHäufigkeit weniger als b der häufigsten Beschriftung ist. Dabei ist |Lt| die Anzahl der Beschriftungen und l die Länge der Random-Walks.\nAußerdem wurde experimentell anhand des DBLP-Datensatzes2 und des CORA-Datensatzes3 gezeigt (vgl. Tabelle I), dass die Klassifikationsgüte nicht wesentlich von der Anzahl der Wörter mit höchstem Gini-Koeffizient m abhängt. Des Weiteren betrug die Ausführungszeit auf einem Kern eines Intel Xeon 2.5GHz Servers mit 32GB RAM für den DBLP-Datensatz unter 25 s, für den CORA-Datensatz sogar unter 5 s. Dabei wurde eine für CORA eine Klassifikationsgüte von 82%–84% und auf den DBLP-Daten von 61%–66% erreicht.\nName Knoten davon beschriftet Kanten Beschriftungen CORA 19 396 14 814 75 021 5 DBLP 806 635 18 999 4 414 135 5\nTabelle I: Datensätze, die für die experimentelle Analyse benutzt wurden\nObwohl es sich nicht sagen lässt, wie genau die Ergebnisse aus [AL11] zustande gekommen sind, eignet sich das Kreuzvalidierungsverfahren zur Bestimmung der Klassifikationsgüte wie es in [Lav06], [Sto74] vorgestellt wird:\n2http://dblp.uni-trier.de/ 3http://people.cs.umass.edu/ mccallum/data/cora-classify.tar.gz\n1) Betrachte nur VL,T .\n2) Unterteile VL,T zufällig in k disjunkte Mengen M1, . . . ,Mk.\n3) Teste die Klassifikationsgüte, wenn die Knotenbeschriftungen aller Knoten in Mi für DYCOS verborgen werden für i = 1, . . . , k.\n4) Bilde den Durchschnitt der Klassifikationsgüten aus Punkt 3.\nEs wird k = 10 vorgeschlagen."
    }, {
      "heading" : "V. PROBLEME DES DYCOS-ALGORITHMUS",
      "text" : "Bei der Anwendung des in [AL11] vorgestellten Algorithmus auf reale Datensätze könnten zwei Probleme auftreten, die im Folgenden erläutert werden. Außerdem werden Verbesserungen vorgeschlagen, die es allerdings noch zu untersuchen gilt."
    }, {
      "heading" : "A. Anzahl der Knotenbeschriftungen",
      "text" : "So, wie der DYCOS-Algorithmus vorgestellt wurde, können nur Graphen bearbeitet werden, deren Knoten jeweils höchstens eine Beschriftung haben. In vielen Fällen, wie z. B. Wikipedia mit Kategorien als Knotenbeschriftungen haben Knoten jedoch viele Beschriftungen.\nAuf einen ersten Blick ist diese Schwäche einfach zu beheben, indem man beim zählen der Knotenbeschriftungen für jeden Knoten jedes Beschriftung zählt. Dann wäre noch die Frage zu klären, mit wie vielen Beschriftungen der betrachtete Knoten beschriftet werden soll.\nJedoch ist z. B. bei Wikipedia-Artikeln auf den Knoten eine Hierarchie definiert. So ist die Kategorie „Klassifikationsverfahren“ eine Unterkategorie von „Klassifikation“. Bei dem Kategorisieren von Artikeln sind möglichst spezifische Kategorien vorzuziehen, also kann man nicht einfach bei dem Auftreten der Kategorie „Klassifikationsverfahren“ sowohl für diese Kategorie als auch für die Kategorie „Klassifikation“ zählen."
    }, {
      "heading" : "B. Überanpassung und Reklassifizierung",
      "text" : "Aggarwal und Li beschreiben in [AL11] nicht, auf welche Knoten der Klassifizierungsalgorithmus angewendet werden soll. Jedoch ist die Reihenfolge der Klassifizierung relevant. Dazu folgendes Minimalbeispiel:\nGegeben sei ein dynamischer Graph ohne textuelle Inhalte. Zum Zeitpunkt t = 1 habe dieser Graph genau einen Knoten v1 und v1 sei mit dem A beschriftet. Zum Zeitpunkt t = 2 komme ein nicht beschrifteter Knoten v2 sowie die Kante (v2, v1) hinzu. Nun wird der DYCOS-Algorithmus auf diesen Knoten angewendet und v2 mit A beschriftet. Zum Zeitpunkt t = 3 komme ein Knoten v3, der mit B\n6 v1 A v2 t = 1\n(a) t = 1\nv1 A\nv2 A\nt = 2\n(b) t = 2\nv1 A\nv2 A\nv3 B\nt = 3\n(c) t = 3\nv1 A\nv2 A v3 B\nv4t = 3\n(d) t = 4\nAbbildung 2: Minimalbeispiel für den Einfluss früherer DYCOS-Anwendungen\nbeschriftet ist, und die Kante (v2, v3) hinzu. Abbildung 2 visualisiert diesen Vorgang.\nWürde man nun den DYCOS-Algorithmus erst jetzt, also anstelle von Zeitpunkt t = 2 zum Zeitpunkt t = 3 auf den Knoten v2 anwenden, so würde eine 50%-Wahrscheinlichkeit bestehen, dass dieser mit B beschriftet wird. Aber in diesem Beispiel wurde der Knoten schon zum Zeitpunkt t = 2 beschriftet. Obwohl es in diesem kleinem Beispiel noch keine Rolle spielt, wird das Problem klar, wenn man weitere Knoten einfügt:\nWird zum Zeitpunkt t = 4 ein unbeschrifteter Knoten v4 und die Kanten (v1, v4), (v2, v4), (v3, v4) hinzugefügt, so ist die Wahrscheinlichkeit, dass v4 mit A beschriftet wird bei 23 . Werden die unbeschrifteten Knoten jedoch erst jetzt und alle gemeinsam beschriftet, so ist die Wahrscheinlichkeit für A als Beschriftung bei nur 50%. Bei dem DYCOS-Algorithmus findet also eine Überanpassung an vergangene Beschriftungen statt.\nDas Reklassifizieren von Knoten könnte eine mögliche Lösung für dieses Problem sein. Knoten, die durch den DYCOSAlgorithmus beschriftet wurden könnten eine Lebenszeit bekommen (TTL, Time to Live). Ist diese abgelaufen, wird der DYCOS-Algorithmus erneut auf den Knoten angewendet."
    }, {
      "heading" : "VI. AUSBLICK",
      "text" : "Den DYCOS-Algorithmus kann in einigen Aspekten erweitert werden. So könnte man vor der Auswahl des Vokabulars jedes Wort auf den Wortstamm zurückführen. Dafür könnte zum Beispiel der in [Por97] vorgestellte Porter-Stemming-Algorithmus verwendet werden. Durch diese Maßnahme wird das Vokabular kleiner gehalten wodurch mehr Artikel mit einander durch Vokabular verbunden werden können. Außerdem könnte so der Gini-Koeffizient ein besseres Maß für die Gleichheit von Texten werden.\nEine weitere Verbesserungsmöglichkeit besteht in der Textanalyse. Momentan ist diese noch sehr einfach gestrickt und ignoriert die Reihenfolge von Wörtern beziehungsweise Wertungen davon. So könnte man den DYCOS-Algorithmus in\neinem sozialem Netzwerk verwenden wollen, in dem politische Parteiaffinität von einigen Mitgliedern angegeben wird um die Parteiaffinität der restlichen Mitglieder zu bestimmen. In diesem Fall macht es jedoch einen wichtigen Unterschied, ob jemand über eine Partei gutes oder schlechtes schreibt.\nEine einfache Erweiterung des DYCOS-Algorithmus wäre der Umgang mit mehreren Beschriftungen.\nDYCOS beschränkt sich bei inhaltlichen Zweifachsprüngen auf die Top-q-Wortknoten, also die q ähnlichsten Knoten gemessen mit der Aggregatanalyse, allerdings wurde bisher noch nicht untersucht, wie der Einfluss von q ∈ N auf die Klassifikationsgüte ist.\nLITERATUR\n[AL11] C. C. Aggarwal and N. Li, “On node classification in dynamic content-based networks,” in SDM, 2011, pp. 355–366.\n[BCM11] S. Bhagat, G. Cormode, and S. Muthukrishnan. (2011) Node classification in social networks.\n[JCSZ10] C. Jiang, F. Coenen, R. Sanderson, and M. Zito, “Text classification using graph mining-based feature extraction,” Knowledge-Based Systems, vol. 23, no. 4, pp. 302 – 308, 2010, artificial Intelligence 2009 AI-2009 The 29th {SGAI} International Conference on Artificial Intelligence. [Online]. Available: http://www.sciencedirect.com/science/article/ pii/S095070510900152X\n[Joa98] T. Joachims, “Text categorization with support vector machines: Learning with many relevant features,” 1998.\n[Ko12] Y. Ko, “A study of term weighting schemes using class information for text classification,” in Proceedings of the 35th International ACM SIGIR Conference on Research and Development in Information Retrieval, ser. SIGIR ’12. New York, NY, USA: ACM, 2012, pp. 1029–1030. [Online]. Available: http://doi.acm.org/10.1145/2348283.2348453\n[Lav06] N. Lavesson, “Evaluation and analysis of supervised learning algorithms and classifiers,” Diploma Thesis, Blekinge Institute of Technology, Sweden, Dec. 2006.\n[NMTM99] K. Nigam, A. K. Mccallum, S. Thrun, and T. Mitchell, “Text classification from labeled and unlabeled documents using em,” in Machine Learning, 1999, pp. 103–134.\n[Por97] M. F. Porter, “Readings in information retrieval,” K. Sparck Jones and P. Willett, Eds. San Francisco, CA, USA: Morgan Kaufmann Publishers Inc., 1997, ch. An Algorithm for Suffix Stripping, pp. 313–316. [Online]. Available: http: //dl.acm.org/citation.cfm?id=275537.275705\n[SJ01] M. Szummer and T. Jaakkola, “Partially labeled classification with markov random walks,” in Advances in Neural Information Processing Systems 14, T. Dietterich, S. Becker, and Z. Ghahramani, Eds., 2001, pp. 945–952. [Online]. Available: http://media.nips.cc/nipsbooks/nipspapers/paper_files/ nips14/AA36.pdf\n[Sto74] M. Stone, “Cross-Validatory Choice and Assessment of Statistical Predictions,” Journal of the Royal Statistical Society. Series B (Methodological), vol. 36, no. 2, pp. 111–147, 1974. [Online]. Available: http://dx.doi.org/10.2307/2984809\n[Vit85] J. S. Vitter, “Random sampling with a reservoir,” ACM Trans. Math. Softw., vol. 11, no. 1, pp. 37–57, 1985. [Online]. Available: http://doi.acm.org/10.1145/3147.3165\n[ZG02] X. Zhu and Z. Ghahramani, “Learning from labeled and unlabeled data with label propagation,” Carnegie Mellon University, Tech. Rep., 2002."
    } ],
    "references" : [ ],
    "referenceMentions" : [ ],
    "year" : 2015,
    "abstractText" : "Zusammenfassung—In dieser Arbeit wird der DYCOSAlgorithmus, wie er in [AL11] vorgestellt wurde, erklärt. Er arbeitet auf Graphen, deren Knoten teilweise mit Beschriftungen versehen sind und ergänzt automatisch Beschriftungen für Knoten, die bisher noch keine Beschriftung haben. Dieser Vorgang wird „Klassifizierung“ genannt. Dazu verwendet er die Struktur des Graphen sowie textuelle Informationen, die den Knoten zugeordnet sind. Die in [AL11] beschriebene experimentelle Analyse ergab, dass er auch auf dynamischen Graphen mit 19 396 bzw. 806 635 Knoten, von denen nur 14 814 bzw. 18 999 beschriftet waren, innerhalb von weniger als einer Minute auf einem Kern einer Intel Xeon 2.5 GHz CPU mit 32 G RAM ausgeführt werden kann. Zusätzlich wird [AL11] kritisch Erörtert und und es werden mögliche Erweiterungen des DYCOS-Algorithmus vorgeschlagen.",
    "creator" : "LaTeX with hyperref package"
  }
}