{
  "name" : "1402.4322.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "ON THE PROPERTIES OF α-UNCHAINING SINGLE LINKAGE HIERARCHICAL CLUSTERING",
    "authors" : [ "A. MARTÍNEZ-PÉREZ" ],
    "emails" : [ "alvaro.martinezperez@uclm.es" ],
    "sections" : [ {
      "heading" : null,
      "text" : "Keywords: Hierarchical clustering, single linkage, chaining effect, weakly unchaining, α-bridgeunchaining.\nE-mail : alvaro.martinezperez@uclm.es Address: Departamento de Análisis Económico y Finanzas. Universidad de Castilla-\nLa Mancha. Avda. Real Fábrica de Seda, s/n. 45600. Talavera de la Reina. Toledo. Spain\nContents\n1. Introduction 1 2. Background and notation 3 3. Single linkage hierarchical clustering 6 3.1. Characterization of SL 6 3.2. Stability of SL 8 4. Basic properties of SL(α) and SL∗(α) 8 5. Conclusions 13 References 14\n1. Introduction\nKleinberg discussed in [7] the problem of clustering in an axiomatic way. He proposed a few basic properties that any clustering scheme should hold. Let P(X) denote the set of all possible partitions of X. Fix a clustering method T so that T(X) = Π ∈ P(X). The properties proposed by Kleinberg were:\n• Scale invariance: For all α > 0, T(X,α · d) = Π • Richness: Given a finite set X, for every Π ∈ P(X) there exists a metric dΠ on X such that T(X, dΠ) = Π. • Consistency: Let Π = {B1, ..., Bn}. Let d′ be any metric on X such that 1) for all x, x′ ∈ Bi, d′(x, x′) ≤ d(x, x′) and 2) for all x ∈ Bi, x′ ∈ Bj , i 6= j, d′(x, x′) ≥ d(x, x′).\nThen, T(X, d′) = Π.\nThe author was partially supported by MTM-2009-07030. 1\nar X\niv :1\n40 2.\n43 22\nv1 [\ncs .L\nG ]\n1 8\nFe b\n20 14\nThen, he proved that no standard clustering scheme satisfying this conditions simultaneously can exist. This does not mean that defining a clustering function is impossible. The impossibility only holds when the unique input in the algorithm is the space and the set of distances. It can be avoided including, for example, the number of clusters to be obtained as part of the input. See [1] and [11].\nCarlsson and Mémoli studied in [4] the analogous problem for hierarchical clustering methods taking as input a finite metric space. They set three basic conditions, see Theorem 3.1, and prove that the unique method satisfying these conditions simultaneously is the well-known single linkage algorithm. The authors prove also that single linkage hierarchical clustering (SL HC) exhibits some good properties. In particular, it is stable in the Gromov-Hausdorff sense, this is, if two metric spaces are close in the Gromov-Hausdorff metric, then applying the algorithm, the ultrametric spaces obtained are also close in this metric. However, there is a basic weakness in SL HC which is the chaining effect which can be seen as the tendency of the algorithm to merge two blocks when the minimal distance between them is small ignoring everything else in the distribution.\nIn [9] we tried to offer some solution to this effect. We proposed a modified version of SL algorithm, α-unchaining single linkage (or SL(α)), which shows some sensitivity to the density distribution of the sample and it is capable to distinguish blocks even though the minimal distance between them is small. We also defined a second version of this method, SL∗(α), to detect blocks when they are connected by a chain of points. Then, we studied the unchaining properties of both methods.\nThus, we were able to offer some solution to these chaining effects but, in exchange, we lost some of the good properties of SL. In particular, SL(α) is no longer stable in the Gromov-Hausdorff sense. In fact, as we proved in [10], there is no stable solution to this chaining effect in the range of almost-standard linkage-based HC methods using `SL.\nNow, the question is when should we use SL(α) and SL∗(α). Among the large variety of clustering methods the best option usually depends on the particular clustering problem. But how do we choose the most suitable algorithm for the task? Ackerman, Ben David and Loker propose to study significant properties of the clustering functions. See [1] and [2]. The idea is finding abstract significant properties concerning the output of the algorithms which illustrate the difference between applying one clustering method or another. Then, the practitioner should decide which properties are important for the problem under study and choose the algorithm which satisfies them.\nIn [9] and [10] we proved the chaining, unchaining and stability properties of SL(α) and SL∗(α). Herein, we complete the work by analyzing which of the abstract characteristic properties of SL are also satisfied by these two methods and which properties are lost by adding the unchaining condition.\nWe start with the characterization of SL HC by Carlsson and Mémoli. In the original characterization of SL from [4], properties I, II and III characterize SL, see 3.1. However, we introduce some alternative definitions to offer a better picture of the difference.\nWe define that a HC method T satisfies property A2 if adding points to the input will never make increase the distance between previous points in the output. This is the case of SL. In fact, we prove that A2 together with A1 (the algorithm leaves ultrametric spaces invariant) and A3 (the distance between two points in the\noutput is at least the minimal ε > 0 so that there exists a ε-chain between them in the input), offers an alternative characterization of SL. See corollary 3.7.\nProperties A1 and A3 are trivially satisfied by many algorithms, in particular SL(α), SL∗(α), complete linkage (CL) or average linkage (AL). Thus, A2 illustrates the difference between SL and other methods as those mentioned above. Also, considering the original characterization from [4], it is trivial to check that SL(α), SL∗(α), AL and CL satisfy I and III but not II and therefore, property II can be used to distinguish those algorithms from SL. However, since II implies A2, we believe that A2 is a better option for the task.\nWe also prove that other basic properties as being permutation invariant or rich are satisfied by all of them.\nThe results obtained in [9], [10] and herein are summarized in Table 1.\n2. Background and notation\nA dendrogram over a finite set is a nested family of partitions. This is usually represented as a rooted tree.\nLet P(X) denote the collection of all partitions of a finite set X = {x1, ..., xn}. Then, a dendrogram can also be described as a map θ : [0,∞)→ P(X) such that:\n1. θ(0) = {{x1}, {x2}, ..., {xn}}, 2. there exists T such that θ(t) = X for every t ≥ T , 3. if r ≤ s then θ(r) refines θ(s), 4. for all r there exists ε > 0 such that θ(r) = θ(t) for t ∈ [r, r + ε].\nNotice that conditions 2 and 4 imply that there exist t0 < t1 < ... < tm such that θ(r) = θ(ti−1) for every r ∈ [ti−1, ti), i = 0, 1, ...,m and θ(r) = θ(tm) = {X} for every r ∈ [tm,∞).\nFor any partition {B1, ..., Bk} ∈ P(X), the subsets Bi are called blocks. Let D(X) denote the collection of all possible dendrograms over a finite set X. Given some θ ∈ D(X), let us denote θ(t) = {Bt1, ..., Btk(t)}. Therefore, the nested family of partitions is given by the corresponding partitions at t0, ..., tm, this is, {Bti1 , ..., B ti k(ti) }, i = 0, ...,m.\nAn ultrametric space is a metric space (X, d) such that d(x, y) ≤ max{d(x, z), d(z, y)} for all x, y, z ∈ X. Given a finite metric space X let U(X) denote the set of all ultrametrics over X.\nThere is a well known equivalence between trees and ultrametrics. See [6] and [8] for a complete exposition of how to build categorical equivalences between them. In particular, this may be translated into an equivalence between dendrograms and ultrametrics:\nThus, a hierarchical clustering method T can be presented as an algorithm whose output is a dendrogram or an ultrametric space. Let TD(X, d) denote the dendrogram obtained by applying T to a metric space (X, d) and TU (X, d) denote the corresponding ultrametric space.\nIn [4] the authors use a recursive procedure to redefine SL HC, average linkage (AL) and complete linkage (CL) hierarchical clustering. The main advantage of this procedure is that it allows to merge more than two clusters at the same time. Therefore, AL and CL HC can be made permutation invariant, meaning that the result of the hierarchical clustering does not depend on the order in which the points are introduced in the algorithm. In [9] we gave an alternative presentation of this\nrecursive procedure as a first step to define SL(α) and SL∗(α). Let us recall here, for completeness, this presentation.\nFor x, y ∈ X and any (standard) clustering C of X, x ∼C y if x and y belong to the same cluster in C and x 6∼C y, otherwise.\nTwo (standard) clusterings C = (C1, ..., Ck) of (X, d) and C ′ = (C ′1, ...C ′k) of (X ′, d′) are isomorphic clusterings, denoted (C, d) ∼= (C ′, d′), if there exists a bijection φ : X → X ′ such that for all x, y ∈ X, d(x, y) = d′(φ(x), φ(y)) and x ∼C y if and only if φ(x) ∼C′ φ(y).\nDefinition 2.1. A linkage function is a function\n` : {(X1, X2, d) | d is a distance function over X1 ∪X2} → R+\nsuch that, 1. ` is representation independent: For all (X1, X2) and (X ′1, X ′2), if (X1, X2, d) ∼=\n(X ′1, X ′ 2, d ′) (i.e., they are clustering-isomorphic), then `(X1, X2, d) = `(X ′1, X ′2, d′).\n2. ` is monotonic: For all (X1, X2) if d′ is a distance function over X1 ∪X2 such that for all x ∼{X1,X2} y, d(x, y) = d′(x, y) and for all x 6∼{X1,X2} y, d(x, y) ≤ d′(x, y) then `(X1, X2, d′) ≥ `(X1, X2, d). 3. Any pair of clusters can be made arbitrarily distant: For any pair of data sets (X1, d1), (X2, d2), and any r in the range of `, there exists a distance function d that extends d1 and d2 such that `(X1, X2, d) > r.\nFor technical reasons, it is usually assumed that a linkage function has a countable range. Say, the set of nonnegative algebraic real numbers.\nSome standard choices for ` are: • Single linkage: `SL(B,B′) = min(x,x′)∈B×B′ d(x, x′) • Complete linkage: `CL(B,B′) = max(x,x′)∈B×B′ d(x, x′) • Average linkage: `AL(B,B′) = ∑ (x,x′)∈B×B′ d(x,x ′)\n#(B)·#(B′) where #(X) denotes the cardinality of the set X.\nLet (X, d) be a finite metric space where X = {x1, ..., xn}. Let L denote a family of linkage functions on X and fix some linkage function ` ∈ L. Then, let TD(X, d) = θ\n` be as follows: 1. Let Θ0 := {x1, ..., xn} and R0 = 0. 2. For every i ≥ 1, while Θi−1 6= {X}, let Ri := min{`(B,B′) |B,B′ ∈\nΘi−1, B 6= B′}. Then, let G`Ri be a graph whose vertices are the blocks of Θi−1 and such that there is an edge joining B and B′ if and only if `(B,B′) ≤ Ri. 3. Consider the equivalence relation B ∼`,R B′ if and only if B,B′ are in the same connected component of G`R. Then, Θi =\nΘi−1 ∼`,Ri . 4. Finally, let θ` : [0,∞) → P(X) be such that θ`(r) := Θi(r) with i(r) :=\nmax{i |Ri ≤ r}. In [10] the methods defined by applying this algorithm for some linkage function\n` are called standard linkage-based HC methods. Let us now recall the definition of SL(α) and SL∗(α). Further explanations,\nfigures and easy examples of applications of these methods can be found in [9]. Given a finite metric space (X, d), let Ft(X, d) be the Rips (or Vietoris-Rips) complex of (X, d). Let us recall that the Rips complex of a metric space (X, d) is a simplicial complex whose vertices are the points of X and [v0, ..., vk] is a simplex\nof Ft(X, d) if and only if d(vi, vj) ≤ t for every i, j. Given any subset Y ⊂ X, by Ft(Y ) we refer to the subcomplex of Ft(X) defined by the vertices in Y . A simplex [v0, ..., vk] has dimension k. The dimension of a simplicial complex is the maximal dimension of its simplices.\nLet X = {x1, ..., xn}. Let dij := d(xi, xj) and D := {ti : 0 ≤ i ≤ m} = {dij : 1 ≤ i, j ≤ n} with ti < tj ∀ i < j where “<” denotes the order of the real numbers. Clearly, t0 = 0.\nLet the dendrogram defined by SL(α), TSL(α)D (X, d) = θX,α or simply θα, be as follows:\n1) Let θα(0) := {{x1}, ..., {xn}} and θα(t) := θα(0) ∀t < t1. Now, for every i, given θα[ti−1, ti) = θα(ti−1) = {B1, ..., Bm}, we define recursively θα on the interval [ti, ti+1) as follows: 2) LetGtiα be a graph with vertices V(Gtiα ) := {B1, ..., Bm} and edges E(Gtiα ) := {Bj , Bk} such that the following conditions hold: i) min{d(x, y) |x ∈ Bj , y ∈ Bk} ≤ ti. ii) there is a simplex ∆ ∈ Fti(Bj ∪Bk) such that ∆∩Bj 6= ∅, ∆∩Bk 6= ∅ and α · dim(∆) ≥ min{dim(Fti(Bj)), dim(Fti(Bk))}. 3) Let us define a relation, ∼ti,α as follows.\nLet Bj ∼ti,α Bk if Bj , Bk belong to the same connected component of the graph Gtiα . Then, ∼ti,α induces an equivalence relation. 4) For every t ∈ [ti, ti+1), θα(t) := θα(ti−1)/ ∼ti,α. This construction is generalized in [10] to define the class of almost-standard\nlinkage-based HC methods.\nRemark 2.2. Notice that if two points x, x′ belong to the same block of θα(ti) then, necessarily, there exists a ti-chain, x = x0, x1, ..., xn = x′ joining them. In particular, if xj ∈ Bj ∈ θα(ti−1), j = 0, ..., n, the corresponding edges {Bj−1, Bj}, 1 ≤ j ≤ n, satisfy condition ii. This is immediate by construction.\nLet the dendrogram defined by SL∗(α), TSL ∗(α)\nD (X, d) = θ ∗ X,α or simply θ ∗ α, be\nas follows: 1) Let θ∗α(0) := {{x1}, ..., {xn}} and θ∗α(t) := θ∗α(0) ∀t < t1.\nNow, given θ∗α[ti−1, ti) = θ∗(ti−1) = {B1, ..., Bm}, we define recursively θ∗α on the interval [ti, ti+1) as follows: 2) LetGtiα be a graph with vertices V(Gtiα ) := {B1, ..., Bm} and edges E(Gtiα ) := {Bj , Bk} such that the following conditions hold: i) min{d(x, y) |x ∈ Bj , y ∈ Bk} ≤ ti. ii) there is a simplex ∆ ∈ Fti(Bj ∪Bk) such that ∆∩Bj 6= ∅, ∆∩Bk 6= ∅\nand α · dim(∆) ≥ min{dim(Fti(Bj)), dim(Fti(Bk))}. By an abuse of the notation, we may write B to refer both to the block\nof θ(ti−1) and to the vertex of Gtiα . 3) Let us define a relation, ∼ti,α between the blocks as follows.\nLet cc(Gtiα ) be the set of connected components of the graph Gtiα . Let A ∈ cc(Gtiα ) with A = {Bj1 , ..., Bjr}.\nLet us call big blocks of A those blocks such that\n(1) α ·#(Bjk) ≥ max 1≤l≤r {#(Bjl)}.\nThe rest of blocks of A are called small blocks.\nLet Hα(A) be the subgraph of A whose vertices are the big blocks and Sα(A) be the subgraph of A whose vertices are the small blocks.\nThen, Bjk ∼ti,α Bjk′ if one of the following conditions holds: iii) ∃C ∈ cc(Hα(A)) such that Bjk , Bjk′ ∈ C. iv) Bjk ∈ C ∈ cc(Hα(A)), Bjk′ ∈ C\n′ ∈ cc(Sα(A)) and there is no big block in A\\C adjacent to any block in C ′. Then, ∼ti,α induces an equivalence relation whose classes are contained in the connected components of Gtiα .\n4) For every t ∈ [ti, ti+1), θ∗α(t) := θ∗α(ti−1)/ ∼ti,α.\nRemark 2.3. At step iii, if Hα(A) is connected, then Bj1 ∪ · · · ∪ Bjr defines a block of θα(ti).\nRemark 2.4. Notice that Remark 2.2 still applies. In fact, if two points x, x′ belong to the same block of θ∗α(ti) then, necessarily, there exists a ti-chain, x = x0, x1, ..., xn = x\n′ joining them so that if xj ∈ Bj ∈ θ∗α(ti−1), j = 0, ..., n, the corresponding edges {Bj−1, Bj}, 1 ≤ j ≤ n, satisfy condition ii.\n3. Single linkage hierarchical clustering\nIn this section we recall some basic properties and the characterization of SL HC from [4]. We also propose some alternatives. Our first intention is to find significant properties to compare SL and SL(α).\n3.1. Characterization of SL. Carlsson and Mémoli provided the following axiomatic characterization of SL HC:\nLet us recall that given a finite metric space (X, d), sep(X, d) := minx 6=x′d(x, x′).\nTheorem 3.1. [4, Theorem 18] Let T be a hierarchical clustering method such that: (I) TU ( {p, q}, ( δ 0 0 δ )) = ( {p, q}, ( δ 0 0 δ )) for all δ > 0.\n(II) Given two finite metric spaces X,Y and φ : X → Y such that dX(x, x′) ≥ dY (φ(x), φ(x ′)) for all x, x′ ∈ X, then\nuX(x, x ′) ≥ uY (φ(x), φ(x′))\nalso holds for all x, x′ ∈ X, where TU (X, dX) = (X,uX) and TU (Y, dY ) = (Y, uY ).\n(III) For any metric space (X, d),\nu(x, x′) ≥ sep(X, d) for all x 6= x′ ∈ X\nwhere TU (X, d) = (X,u). Then, T is exactly single linkage hierarchical clustering.\nNotation: For the particular case of SL HC, if there is no need to distinguish the metric space, let us denote TSLD (X, d) = θSL and T SL U (X, d) = (X,uSL).\nNotation: Given two metrics d, d′ defined on a set X, let us denote d ≤ d′ if d(x, x′) ≤ d′(x, x′) ∀x, x′ ∈ X.\nThe following propositions follow immediately from the proof of [4, Theorem 18].\nProposition 3.2. For any metric space (X, d), if T satisfies conditions II and III, then u ≥ uSL.\nThis is, the ultrametric distance between two points is at least the minimal length ε for which there is a ε-chain joining them.\nIt is readily seen that if u ≥ uSL, then T satifies III.\nProposition 3.3. If T satisfies conditions I and II, then uSL ≥ u.\nIn fact, Proposition 3.3 can be improved introducing the following condition. A2) Let (Y, d) be a metric space and X ⊂ Y . If i : X → Y is the inclusion map, then uX(x, x′) ≥ uY (i(x), i(x′)). This is, by adding points to the space we may make the ultrametric distance smaller but never bigger. Clearly, II ⇒ A2. The proof of Proposition 3.3, [4], can be trivially adapted to obtain the following.\nProposition 3.4. If T satisfies conditions I and A2, then uSL ≥ u.\nProof. Let x, x′ ∈ (X, d) such that uSL(x, x′) = δ. Then, there exists a δ-chain x = x0, x1, ..., xn = x\n′ such that maxi d(xi−1, xi) = δ. By I, if Xi = {xi−1, xi}, T(Xi, d|Xi) = (Xi, d|Xi) and uXi(xi−1, xi) ≤ δ. Then, by A2, u(xi−1, xi) ≤ uXi(xi−1, xi) ≤ δ and, by the properties of the ultrametric, u(x, x′) ≤ δ.\nAnother natural condition to ask on a hierarchical clustering method is leaving invariant any ultrametric space:\nA1) If (X, d) is an ultrametric space, then u(x, y) = d(x, y). This is, applying the hierarchical clustering method to an ultrametric space we\nobtain the same ultrametric space. Also, it can be readily seen that SL HC satisfies A1:\nProposition 3.5. If (X, d) is an ultrametric space, then uSL(x, y) = d(x, y) for every x, y ∈ X.\nProof. By definition, it is clear that uSL(x, y) ≤ d(x, y) for every x, y ∈ X. Let us see that, if (X, d) is an ultrametric space, then uSL(x, y) ≥ d(x, y). uSL(x, y) = inf{t | there exists a t-chain joining x to y}. Suppose uSL(x, y) = t and let x = x0, x1, ..., xn = y be a t-chain joining x to y. By the properties of the ultrametric, d(xi−1, xi+1) ≤ max{d(xi−1, xi), d(xi, xi+1)} ≤ t for every 1 ≤ i ≤ n−1. Therefore, d(x, y) ≤ t and uSL(x, y) ≥ d(x, y).\nRichness property for HC methods can be defined in the same way Kleinberg did for standard clustering. Thus, a HC method T satisfies richness property if given a finite set X, for every θ ∈ D(X) there exists a metric dθ on X such that TD(X, dθ) = θ.\nCorollary 3.6. TSL satisfies richness property.\nIt is trivial to check that A1 ⇒ I (and A3 ⇒ III). Therefore, by Proposition 3.4, we obtain also the following alternative characterization of SL HC.\nCorollary 3.7. Let T be a hierarchical clustering method such that: A1) If (X, d) is an ultrametric space, then uX(x, y) = d(x, y). A2) Let (Y, d) be a metric space and X ⊂ Y . If i : X → Y is the inclusion map,\nthen uX(x, x′) ≥ uY (i(x), i(x′)). A3) u ≥ uSL. Then, T is exactly SL HC.\n3.2. Stability of SL. Let us recall the definition of Gromov-Hausdorff distance from [3]. See also [5].\nLet (X, dX) and (Y, dY ) two metric spaces. A correspondence (between A and B) is a subset R ∈ A×B such that\n• ∀ a ∈ A, there exists b ∈ B s.t. (a, b) ∈ R • ∀ b ∈ B, there exists a ∈ A s.t. (a, b) ∈ R\nLet R(A,B) denote the set of all possible correspondences between A and B. Let ΓX,Y : X × Y ×X × Y → R+ given by\n(x, y, x′, y′) 7→ |dX(x, x′)− dY (y, y′)|.\nThen, the Gromov-Hausdorff distance between X and Y is:\ndGH(X,Y ) := 1\n2 inf R∈R(X,Y ) sup (x,y)(x′,y′)∈R ΓX,Y (x, y, x\n′, y′).\nThe Gromov-Hausdorff metric gives a notion of distance between metric spaces. One of the advantages of this metric is that it is well defined for metric spaces of different cardinality. In [4] this metric is used to prove that TSL holds some stability under small perturbations on the metric. The authors prove that if two metric spaces are close (in the Gromov-Hausdorff metric) then the corresponding ultrametric spaces obtained as output of the algorithm are also close. In [10] we studied Gromov-Hausdorff stability of linkage-based HC methods defining the following conditions.\nNotation: Let (M, dGH) denote the set of finite metric spaces with the GromovHausdorff metric and (U , dGH) denote the set of finite ultrametric spaces with the Gromov-Hausdorff metric.\nDefinition 3.8. A HC method T is semi-stable in the Gromov-Hausdorff sense if for any sequence of finite metric spaces ((Xk, dk))k∈N in (M, dGH) such that limk→∞(Xk, dk) = (U, d) ∈ U then limk→∞ TU (Xk, dk) = TU (U, d).\nDefinition 3.9. A HC method T is stable in the Gromov-Hausdorff sense if\nTU : (M, dGH)→ (U , dGH)\nis continuous.\nA hierarchical clustering method is said to be permutation invariant if it yields the same dendrogram under permutation of the points in the sample this is, if the output of the algorithm does not depend on the order by which the data is introduced. Although this is not the easiest way to check this property, it may be noticed that being stable in the Gromov-Hausdorff sense implies being permutation invariant.\nThe following result is a consequence of [4, Proposition 26].\nProposition 3.10. SL HC is stable in the Gromov-Hausdorff sense. In particular, it is semi-stable and permutation invariant.\n4. Basic properties of SL(α) and SL∗(α)\nIn this section, we study some basic properties on SL(α) and SL∗(α). In particular, we check those seen at Section 3 .\nThe following result is clear from the definition.\nProposition 4.1. SL(α) and SL∗(α) are permutation invariant algorithms.\nProposition 4.2. Let (X, d) be a finite metric space with X = {x1, ..., xn}. If α ≥ n−22 , then T SL(X) = TSL(α)(X).\nProof. Let TSLD (X) = θSL, T SL(α) D (X) = θα.\nWe know that θSL(t0) = θα(t0). Suppose θSL(ti−1) = θα(ti−1). Let us see that for α ≥ n−22 , condition i already implies ii and the edges of the graph Gtiα are those defined by condition i. Let B1, B2 two blocks in θα(ti−1) such that min{d(x, y) |x ∈ B1, y ∈ B2} ≤ ti. For any simplex ∆, α · dim(∆) ≥ α and min{#(B1),#(B2)} ≤ n2 . Since α ≥ n−2 2 , α · dim(∆) ≥ α ≥ min{#(B1) − 1,#(B2)− 1} ≥ min{dim(Fti(B1)), dim(Fti(B2))}. Then, θSL(ti) = θα(ti).\nProposition 4.3. Let (X, d) be a finite metric space with X = {x1, ..., xn}. If α ≥ n− 1, then TSL(X) = TSL∗(α)(X).\nProof. Let TSLD (X) = θSL and T SL∗(α) D (X) = θ ∗ α.\nWe know that θSL(t0) = θ∗α(t0). Suppose θSL(ti−1) = θ∗α(ti−1). As we saw in the proof of Proposition 4.2, since α ≥ n − 1 > n−22 , condition i already implies ii and the edges of the graph Gtiα are those defined by condition i. Now, let A = {B1, ..., Br} be any connected component of Gtiα . If the subgraph Hα(A) is not connected, then there are at least three blocks Bi1 , Bi2 , Bi3 in A, such that 1 ≤ #(Bi1) < 1α max1≤l≤r{#(Bl)} and #(Bi2),#(Bi3) ≥ 1 α max1≤l≤r{#(Bl)}. Trivially, max1≤l≤r{#(Bl)} ≤ n − 2. Hence, there is a contradiction since 1 ≤ n−2α ≤ n−2 n−1 < 1.\nThus, Hα(A) is connected and, as we saw in Remark 2.3, all the blocks in A are identified. Therefore, θ∗α(ti) = θSL(ti).\nNotation: Let X be a finite metric space. Let us recall that if there is no ambiguity on the metric space we denote TSLD (X) = θSL, η(θSL) = uSL and T SL(α) D (X) = θα. Let us denote η(θα) = uα. Similarly, let T SL∗(α) D (X) = θ ∗ α and η(θ∗α) = u∗α.\nProposition 4.4. uSL ≤ uα and uSL ≤ u∗α for every α ∈ N (i.e. TSL(α) and TSL ∗(α) satisfy A3).\nProof. As we saw at remarks 2.2 and 2.4, if two points x, x′ ∈ X belong to the same block of θα(t) (resp. θ∗α(t)), they belong, in particular, to the same t-component of X and, therefore, to the same block of θSL(t). Thus, uSL(x, x′) ≤ uα(x, x′) (resp. uSL(x, x ′) ≤ u∗α(x, x′)).\nProposition 4.5. If (X, d) is an ultrametric space, then θα = θSL = θ∗α for every α.\nProof. By definition, θα(t0) = θSL(t0) = θ∗α(t0). Suppose θα(ti−1) = θSL(ti−1) = θ∗α(ti−1) = {B1, ..., Bn}. Let us see that θα(ti) = θSL(ti) = θ∗α(ti).\nLet Bi, Bj be such that min{d(x, y) |x ∈ Bi, y ∈ Bj} ≤ ti. Since Bi, Bj are (ti−1)-components, by the properties of the ultrametric, d(x, y) ≤ ti for every (x, y) ∈ B1 ×B2.\nTherefore, every pair of points in B1 ∪B2 define a simplex in Fti(B1 ∪B2) and condition ii holds for every α. Thus, there is an edge defined between Bi and Bj . This proves that θα = θSL.\nNow, let Bi, Bj be two blocks in the same connected component of Gtiα . Then, by the properties of the ultrametric, {Bi, Bj} is an edge of Gtiα . Hence, Hα(Gtiα ) is connected and, as we saw in Remark 2.3, θ∗α(ti) is defined by the connected components of Gtiα . This proves that θ∗α = θSL.\nCorollary 4.6. If (X, d) is an ultrametric space, then uα(x, y) = u∗α(x, y) = d(x, y) for every x, y ∈ X.\nCorollary 4.7. SL(α) and SL∗(α) satisfy A1 and A3 but not A2.\nNotice that if A2 were also satisfied then, by Corollary 3.7, the method would be exactly SL. For an example of how these methods fail to satisfy A2 consider the following example from [9].\nExample 4.8. Let (X, d) be the graph from Figure 1. Suppose the edges in N1, N2 have length 1 and the rest have length 3. The distances between vertices are measured as the minimal length of a path joining them.\nLet Z := {x0, y0} and d′(x0, y0) = 3. Let i : (Z, d′) → (X, d) be the inclusion map. It is immediate to check that applying either SL(α) or SL∗(α) with α < 3 we obtain ultrametric spaces (Z, uZ), (X,uX) such that uZ(x0, y0) < uX(x0, y0).\nCorollary 4.9. SL(α) and SL∗(α) satisfy richness property.\nAs we saw in [10], SL(α) is semi-stable in the Gromov-Hausdorff sense. Unfortunately, most of the good stability properties of SL do not hold. SL(α) and SL∗(α) are not stable in the Gromov-Hausdorff sense (see [10]) and it is not difficult to check that SL∗(α) is not semi-stable in the Gromov-Hausdorff sense. Small perturbations on the distances may affect the dimension of the Rips complex and\nto whether or not condition ii applies. Also, they may affect the size of the components and yield very different graphs Gtiα . Furthermore, changing the parameter α we may obtain a very different dendrogram. However, all the instability is produced by the unchaining conditions ii, iii and iv. Thus, θα and θ∗α may be compared with θ to, at least, keep track of the undesired effects on the stability introduced with the unchaining conditions.\nExample 4.10. Let (X, d) be the graph from Figure 2 where every edge has length 1 and let (X, d′) be the same graph where d(x0, y0) = 1 + ε for some ε > 0 and the rest of the edges have length 1. Let θ1 = T SL(1) D (X, d) and θ ′ 1 = T SL(1) D (X, d\n′). As we saw above, θ1(t) = {{x0}, ..., {x3}, {y0}, ...{y3}} if t < 1 and θ1(1) = {X}. Thus, if η(θ1) = u if follows that u(x, y) = 1 ∀x, y ∈ X. If we apply SL(1) to (X, d′) we obtain that θ′1(t) = {{x0}, ..., {x3}, {y0}, ...{y3}} if t < 1 and θ′1(t) = {B1, B2} for 1 ≤ t < 1 + ε. For 1 + ε ≤ t ≤ 2, by condition ii, there is no edge in Gt1 between B1 and B2. Thus, θ′1(t) = {B1, B2} for 1 + ε ≤ t < 2 + ε. For t ≥ 2 + ε, θ′1(t) = X. Thus, if η(θ′1) = u′ if follows that u′(xi, xj) = 1 ∀xi, xj ∈ B1, u′(yi, yj) = 1 ∀ yi, yj ∈ B2 and u′(xi, yj) = 2 + ε ∀ (xi, yj) ∈ B1×B2.\nIn this case, dGH((X, d), (X, d′)) = ε2 and dGH((X,u), (X,u ′)) = 1+ε2 . Therefore,\nSL(α) is not stable in the Gromov-Hausdorff sense.\nAlso, it is unstable under the change of the parameter α.\nExample 4.11. Let (X, d′) be the graph with the metric defined in Example 4.10. As we just saw, if η(θ′1) = u′ if follows that u′(xi, xj) = 1 ∀xi, xj ∈ B1, u′(yi, yj) = 1 ∀ yi, yj ∈ B2 and u′(xi, yj) = 2 + ε ∀ (xi, yj) ∈ B1 ×B2. If we apply SL(3) to (X, d′) we obtain that θ′3(t) = {{x0}, ..., {x3}, {y0}, ...{y3}} if t < 1 and θ′3(t) = {B1, B2} for 1 ≤ t < 1+ε. For 1+ε ≤ t ≤ 2, since α = 3 there is an edge in Gt3 between B1 and B2. Thus, θ′3(t) = {X} for 1 + ε ≤ t. Hence, if η(θ′3) = u\n′′ if follows that u′′(xi, xj) = 1 ∀xi, xj ∈ B1, u′′(yi, yj) = 1 ∀ yi, yj ∈ B2 and u′′(xi, yj) = 1 + ε ∀ (xi, yj) ∈ B1 ×B2.\nTherefore, dGH((X,u′), (X,u′′)) = 12 .\nOne may wonder if given α > α′ anything can be told about the corresponding dendrograms. In particular, given TSL\n∗(α) U (X, d) = u ∗ α and T SL∗(α′) U (X, d) = u ∗ α′ , it\nis natural to ask if u∗α ≤ u∗α′ or u∗α′ ≤ u∗α. This need not be true. In fact, it may fail by conditions iii and iv, see Example 4.12, or by condition ii, see Example 4.13.\nB1 B2 B3\nti ti\nExample 4.12. Let α > α′. Suppose that θ∗α(ti−1) = θ∗α′(ti−1) = {B1, B2, B3}. See the example above from Figure 3. Now, suppose that conditions i, ii define edges {B1, B2} and {B2, B3} but not {B1, B3} in both Gtiα and G ti α′ .\nSuppose that max1≤l≤3{#(Bl)} = #(B1). Also, let us suppose that α ·#(B2) < #(B1), α′ ·#(B2) < #(B1), α ·#(B3) ≥ #(B1) but α′ ·#(B3) < #(B1). In this case, there is a unique connected component A = {B1, B2, B3} and Hα′(A) = {B1} is connected while Hα(A) = {B1, B3} is not connected. Thus, θ∗α(ti) = {B1, B2, B3} and θ∗α′(ti) = {B1 ∪B2 ∪B3} = {X}.\nSuppose that θ∗α′(ti−1) = θ ∗ α′(ti−1) = {B′1, B′2, B′3}. See the example below from Figure 3. Now, suppose that conditions i, ii define edges {B′1, B′2} and {B′2, B′3} but not {B′1, B′3} in both Gtiα and G ti α′ .\nSuppose that max1≤l≤3{#(B′l)} = #(B′1). Let us suppose that α · #(B′3) > #(B′1), α′ ·#(B′3) > #(B′1), α ·#(B′2) ≥ #(B′1) but α′ ·#(B′2) < #(B′1). In this case, there is a unique connected component A = {B1, B2, B3}, Hα(A) has vertices B′1, B ′ 2, B ′ 3 and it is connected while Hα′(A) = {B′1, B′3} is not connected. Thus, θ∗α(ti) = {B′1 ∪B′2 ∪B′3} = {X} and θ∗α′(ti) = {B′1, B′2, B′3}. Hence, even in the case when there is no chaining effect between adjacent blocks, θ∗α(ti) need not refine θ∗α′(ti) and θ ∗ α′(ti) need not refine θ ∗ α(ti).\nIn particular, u∗α 6≤ u∗α′ and u∗α′ 6≤ u∗α.\nExample 4.13. Let α > α′. Suppose θα(ti−1) = θα′(ti−1) = {B1, B2, B3, B4}, d(B1, B2) = d(B3, B4) = ti, d(B1, B3) = ti+1 and the rest of respective distances between these blocks are bigger than ti+1. See Figure 4.\nSince α > α′, we may assume, by condition ii, that there is an edge between B1, B2 and between B3, B4 in Gtiα but not in G ti α′ . Thus, suppose θα(ti) = {B6, B7} while θα′(ti) = {B1, B2, B3, B4}. Now, we may assume that dim(Fti+1(B1)), dim(Fti+1(B2)) < dim(Fti+1(B6)) and dim(Fti+1(B3)), dim(Fti+1(B4)) < dim(Fti+1(B7)). Thus, we may also assume that, at ti+1, for α′ there is no edge between B6, B7 but for α there is an edge between B1, B3. Therefore, θα′(ti+1) = {B6, B7} while θα(ti+1) = {B5, B2, B4}.\nHence, θα(ti) does not refine θα′(ti) and θα′(ti) does not refine θα(ti). In particular, it is immediate to check that uα 6≤ uα′ and uα′ 6≤ uα.\n5. Conclusions\nIn the spirit of Kleinberg impossibility result we may consider A1 (the algorithm leaves ultrametric spaces invariant) and A3 (the distance between two points in the output is at least the minimal ε > 0 so that there exists a ε-chain between them in the input) as basic desirable conditions for any HC algorithm T. Thus, if we assume that T satisfies A1 and A3, then either T is exactly SL or else, condition A2 (adding points to the input will never make increase the distance between previous points in the output) is not satisfied. In particular, condition A2 is not satisfied by the algorithms defined to treat the chaining effects: SL(α) and SL∗(α).\nApart from this inevitable difference, we prove that the properties A1, A3, permutation invariance and richness are satisfied by SL(α) and SL∗(α) and also by the classical linkage-based algorithms, SL, CL and AL.\nTheir chaining and unchaining properties were studied in [9]. The stability properties of linkage-based methods were analyzed in [10]. The main results are summarized in Table 1.\nReferences\n[1] Ackerman M, Ben-David S, Loker D. Towards Property-Based Algorithms Among Hierarchical Clustering Methods. Neural Information Processing Systems Conference (NIPS 2010). [2] Ackerman M, Ben-David S, Loker D. Characterization of Linkage-based Clustering. (COLT, 2010). [3] Burago D, Burago Y, Ivanov S. A course in metric geometry. Graduate Studies in Mathematics. 33, AMS, Providence, RI, (2001). [4] Carlsson G, Mémoli F. Characterization, Stability and Convergence of Hierarchical Clustering Methods. Journal of Machine Learning Research, 11 (2010) 1425–1470. [5] Gromov M. Metric structures for Riemannian and non-Riemannian spaces. Modern Birkhäuser Classics. Birkhäuser Boston Inc., Boston, MA, english edition, (2007). [6] Hughes B. Trees and ultrametric spaces: a categorical equivalence. Advances in Mathematics, 189, (2004) 148–191. [7] Kleinberg J M. An impossibility theorem for clustering. In Suzanna Becker, Sebastian Thrun, and Klaus Obermayer, editors, NIPS. MIT Press (2002) 446–453. [8] Martínez-Pérez A, Morón M A. Uniformly continuous maps between ends of R-trees. Math. Z., 263, No. 3, (2009) 583–606. [9] Martínez-Pérez A. A density-sensitive hierarchical clustering method. arXiv:1210.6292v2 [cs.LG] (2013). [10] Martínez-Pérez A. Gromov-Hausdorff stability of linkage-based hierarchical clustering methods. arXiv:1311.5068 [cs.LG] (2013). [11] Zadeh R B, Ben-David S. A uniqueness Theorem for Clustering. Uncertainty in Artifitial Intelligence. (UAI 2009)."
    } ],
    "references" : [ {
      "title" : "Towards Property-Based Algorithms Among Hierarchical Clustering Methods",
      "author" : [ "M Ackerman", "S Ben-David", "D. Loker" ],
      "venue" : "Neural Information Processing Systems Conference (NIPS",
      "citeRegEx" : "1",
      "shortCiteRegEx" : "1",
      "year" : 2010
    }, {
      "title" : "Characterization of Linkage-based Clustering",
      "author" : [ "M Ackerman", "S Ben-David", "D. Loker" ],
      "venue" : "(COLT,",
      "citeRegEx" : "2",
      "shortCiteRegEx" : "2",
      "year" : 2010
    }, {
      "title" : "A course in metric geometry. Graduate Studies in Mathematics",
      "author" : [ "D Burago", "Y Burago", "S. Ivanov" ],
      "venue" : null,
      "citeRegEx" : "3",
      "shortCiteRegEx" : "3",
      "year" : 2001
    }, {
      "title" : "Characterization, Stability and Convergence of Hierarchical Clustering Methods",
      "author" : [ "G Carlsson", "F. Mémoli" ],
      "venue" : "Journal of Machine Learning Research,",
      "citeRegEx" : "4",
      "shortCiteRegEx" : "4",
      "year" : 2010
    }, {
      "title" : "Metric structures for Riemannian and non-Riemannian spaces. Modern Birkhäuser Classics",
      "author" : [ "M. Gromov" ],
      "venue" : null,
      "citeRegEx" : "5",
      "shortCiteRegEx" : "5",
      "year" : 2007
    }, {
      "title" : "Trees and ultrametric spaces: a categorical equivalence",
      "author" : [ "B. Hughes" ],
      "venue" : "Advances in Mathematics,",
      "citeRegEx" : "6",
      "shortCiteRegEx" : "6",
      "year" : 2004
    }, {
      "title" : "An impossibility theorem for clustering",
      "author" : [ "M. Kleinberg J" ],
      "venue" : null,
      "citeRegEx" : "7",
      "shortCiteRegEx" : "7",
      "year" : 2002
    }, {
      "title" : "Uniformly continuous maps between ends of R-trees",
      "author" : [ "A Martínez-Pérez", "A. Morón M" ],
      "venue" : "Math. Z.,",
      "citeRegEx" : "8",
      "shortCiteRegEx" : "8",
      "year" : 2009
    }, {
      "title" : "A density-sensitive hierarchical clustering method",
      "author" : [ "A. Martínez-Pérez" ],
      "venue" : null,
      "citeRegEx" : "9",
      "shortCiteRegEx" : "9",
      "year" : 2013
    }, {
      "title" : "Gromov-Hausdorff stability of linkage-based hierarchical clustering methods",
      "author" : [ "A. Martínez-Pérez" ],
      "venue" : null,
      "citeRegEx" : "10",
      "shortCiteRegEx" : "10",
      "year" : 2013
    }, {
      "title" : "A uniqueness Theorem for Clustering",
      "author" : [ "B Zadeh R", "S. Ben-David" ],
      "venue" : "Uncertainty in Artifitial Intelligence",
      "citeRegEx" : "11",
      "shortCiteRegEx" : "11",
      "year" : 2009
    } ],
    "referenceMentions" : [ {
      "referenceID" : 6,
      "context" : "Kleinberg discussed in [7] the problem of clustering in an axiomatic way.",
      "startOffset" : 23,
      "endOffset" : 26
    }, {
      "referenceID" : 0,
      "context" : "See [1] and [11].",
      "startOffset" : 4,
      "endOffset" : 7
    }, {
      "referenceID" : 10,
      "context" : "See [1] and [11].",
      "startOffset" : 12,
      "endOffset" : 16
    }, {
      "referenceID" : 3,
      "context" : "Carlsson and Mémoli studied in [4] the analogous problem for hierarchical clustering methods taking as input a finite metric space.",
      "startOffset" : 31,
      "endOffset" : 34
    }, {
      "referenceID" : 8,
      "context" : "In [9] we tried to offer some solution to this effect.",
      "startOffset" : 3,
      "endOffset" : 6
    }, {
      "referenceID" : 9,
      "context" : "In fact, as we proved in [10], there is no stable solution to this chaining effect in the range of almost-standard linkage-based HC methods using `.",
      "startOffset" : 25,
      "endOffset" : 29
    }, {
      "referenceID" : 0,
      "context" : "See [1] and [2].",
      "startOffset" : 4,
      "endOffset" : 7
    }, {
      "referenceID" : 1,
      "context" : "See [1] and [2].",
      "startOffset" : 12,
      "endOffset" : 15
    }, {
      "referenceID" : 8,
      "context" : "In [9] and [10] we proved the chaining, unchaining and stability properties of SL(α) and SL∗(α).",
      "startOffset" : 3,
      "endOffset" : 6
    }, {
      "referenceID" : 9,
      "context" : "In [9] and [10] we proved the chaining, unchaining and stability properties of SL(α) and SL∗(α).",
      "startOffset" : 11,
      "endOffset" : 15
    }, {
      "referenceID" : 3,
      "context" : "In the original characterization of SL from [4], properties I, II and III characterize SL, see 3.",
      "startOffset" : 44,
      "endOffset" : 47
    }, {
      "referenceID" : 3,
      "context" : "Also, considering the original characterization from [4], it is trivial to check that SL(α), SL∗(α), AL and CL satisfy I and III but not II and therefore, property II can be used to distinguish those algorithms from SL.",
      "startOffset" : 53,
      "endOffset" : 56
    }, {
      "referenceID" : 8,
      "context" : "The results obtained in [9], [10] and herein are summarized in Table 1.",
      "startOffset" : 24,
      "endOffset" : 27
    }, {
      "referenceID" : 9,
      "context" : "The results obtained in [9], [10] and herein are summarized in Table 1.",
      "startOffset" : 29,
      "endOffset" : 33
    }, {
      "referenceID" : 5,
      "context" : "See [6] and [8] for a complete exposition of how to build categorical equivalences between them.",
      "startOffset" : 4,
      "endOffset" : 7
    }, {
      "referenceID" : 7,
      "context" : "See [6] and [8] for a complete exposition of how to build categorical equivalences between them.",
      "startOffset" : 12,
      "endOffset" : 15
    }, {
      "referenceID" : 3,
      "context" : "In [4] the authors use a recursive procedure to redefine SL HC, average linkage (AL) and complete linkage (CL) hierarchical clustering.",
      "startOffset" : 3,
      "endOffset" : 6
    }, {
      "referenceID" : 8,
      "context" : "In [9] we gave an alternative presentation of this",
      "startOffset" : 3,
      "endOffset" : 6
    }, {
      "referenceID" : 9,
      "context" : "In [10] the methods defined by applying this algorithm for some linkage function ` are called standard linkage-based HC methods.",
      "startOffset" : 3,
      "endOffset" : 7
    }, {
      "referenceID" : 8,
      "context" : "Further explanations, figures and easy examples of applications of these methods can be found in [9].",
      "startOffset" : 97,
      "endOffset" : 100
    }, {
      "referenceID" : 9,
      "context" : "This construction is generalized in [10] to define the class of almost-standard linkage-based HC methods.",
      "startOffset" : 36,
      "endOffset" : 40
    }, {
      "referenceID" : 3,
      "context" : "In this section we recall some basic properties and the characterization of SL HC from [4].",
      "startOffset" : 87,
      "endOffset" : 90
    }, {
      "referenceID" : 3,
      "context" : "3, [4], can be trivially adapted to obtain the following.",
      "startOffset" : 3,
      "endOffset" : 6
    }, {
      "referenceID" : 2,
      "context" : "Let us recall the definition of Gromov-Hausdorff distance from [3].",
      "startOffset" : 63,
      "endOffset" : 66
    }, {
      "referenceID" : 4,
      "context" : "See also [5].",
      "startOffset" : 9,
      "endOffset" : 12
    }, {
      "referenceID" : 3,
      "context" : "In [4] this metric is used to prove that T holds some stability under small perturbations on the metric.",
      "startOffset" : 3,
      "endOffset" : 6
    }, {
      "referenceID" : 9,
      "context" : "In [10] we studied Gromov-Hausdorff stability of linkage-based HC methods defining the following conditions.",
      "startOffset" : 3,
      "endOffset" : 7
    }, {
      "referenceID" : 8,
      "context" : "For an example of how these methods fail to satisfy A2 consider the following example from [9].",
      "startOffset" : 91,
      "endOffset" : 94
    }, {
      "referenceID" : 9,
      "context" : "As we saw in [10], SL(α) is semi-stable in the Gromov-Hausdorff sense.",
      "startOffset" : 13,
      "endOffset" : 17
    }, {
      "referenceID" : 9,
      "context" : "SL(α) and SL∗(α) are not stable in the Gromov-Hausdorff sense (see [10]) and it is not difficult to check that SL∗(α) is not semi-stable in the Gromov-Hausdorff sense.",
      "startOffset" : 67,
      "endOffset" : 71
    }, {
      "referenceID" : 8,
      "context" : "Their chaining and unchaining properties were studied in [9].",
      "startOffset" : 57,
      "endOffset" : 60
    }, {
      "referenceID" : 9,
      "context" : "The stability properties of linkage-based methods were analyzed in [10].",
      "startOffset" : 67,
      "endOffset" : 71
    } ],
    "year" : 2014,
    "abstractText" : "In the election of a hierarchical clustering method, theoretic properties may give some insight to determine which method is the most suitable to treat a clustering problem. Herein, we study some basic properties of two hierarchical clustering methods: α-unchaining single linkage or SL(α) and a modified version of this one, SL∗(α). We compare the results with the properties satisfied by the classical linkage-based hierarchical clustering methods.",
    "creator" : "LaTeX with hyperref package"
  }
}