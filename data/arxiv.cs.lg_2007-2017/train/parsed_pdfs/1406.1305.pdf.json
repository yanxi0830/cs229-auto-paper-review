{
  "name" : "1406.1305.pdf",
  "metadata" : {
    "source" : "META",
    "title" : "Faster Rates for the Frank-Wolfe Method over Strongly-Convex Sets",
    "authors" : [ "Dan Garber", "Elad Hazan" ],
    "emails" : [ "DANGAR@TX.TECHNION.AC.IL", "EHAZAN@CS.PRINCETON.EDU" ],
    "sections" : [ {
      "heading" : null,
      "text" : "In this paper we consider the special case of optimization over strongly convex sets, for which we prove that the vanila FW method converges at a rate of 1t2 . This gives a quadratic improvement in convergence rate compared to the general case, in which convergence is of the order 1t , and known to be tight. We show that various balls induced by `p norms, Schatten norms and group norms are strongly convex on one hand and on the other hand, linear optimization over these sets is straightforward and admits a closed-form solution. We further show how several previous fastrate results for the FW method follow easily from our analysis."
    }, {
      "heading" : "1. Introduction",
      "text" : "The Frank-Wolfe method, originally introduced by Frank and Wolfe in the 1950’s (Frank & Wolfe, 1956), is a first order method for the minimization of a smooth convex function over a convex set. Its main advantage in largescale problems is that it is a first-order and projection-free method - i.e. the algorithm proceeds by iteratively solving a linear optimization problem and remaining inside the feasi-\nble domain. For matrix completion problems, metric learning, sparse PCA, structural SVM and other large-scale machine learning problems, this feature enabled the derivation of algorithms that are practical on one hand and come with provable convergence rates on the other (Jaggi & Sulovský, 2010; Lacoste-Julien et al., 2013; Dudı́k et al., 2012; Harchaoui et al., 2012; Hazan & Kale, 2012; Shalev-Shwartz et al., 2011; Laue, 2012).\nDespite its empirical success, the main drawback of the method is its relatively slow convergence rate in comparison to optimal first order methods. The convergence rate of the method is on the order of 1/t where t is the number of iterations, and this is known to be tight. In contrast, Nesterov’s accelerated gradient descent method gives a rate of 1/t2 for general convex smooth problems and a rate e−Θ(t) is known for smooth and strongly convex problems. The following question arises: are there projectionfree methods with convergence rates matching that of projected gradient-descent and its extensions?\nMotivated by this question, in this work we advance the line of research for faster convergence rates of projection free methods. We prove that in case both the objective function and the feasible set are strongly convex (in fact a slightly weaker assumption than strong convexity of the objective is required), the vanilla Frank-Wolfe method converges at an accelerated rate of 1/t2. The improved convergence rate is independent of the dimension. This is also the first convergence result for the FW that we are aware of that achieves a rate that is between the standard 1/t rate and a linear rate. We further show how the analysis used to prove the latter result enables to easily derive previous fast convergence rates for the FW method.\nWe motivate the study of optimization over strongly convex sets by demonstrating that various norms that serve as popular regularizes in machine learning problems, including `p norms, matrix Schatten norms and matrix group norms, give rise to strongly convex sets. We further show that indeed linear optimization over these sets is straightforward to implement and admits a closed-form solution. Hence the\nar X\niv :1\n40 6.\n13 05\nv2 [\nm at\nh. O\nC ]\n1 4\nA ug\n2 01\nFW method is appealing for solving optimization problems with such constraints, such as regularized linear regression."
    }, {
      "heading" : "1.1. Related Work",
      "text" : "The Frank-Wolfe method dates back to the original work of Frank and Wolfe (Frank & Wolfe, 1956) which presented an algorithm for minimizing a quadratic function over a polytope using only linear optimization steps over the feasible set. Recent results by Clarkson (Clarkson, 2008), Hazan (Hazan, 2008) and Jaggi (Jaggi, 2013) extend the method to smooth convex optimization over the simplex, spectrahedron and arbitrary convex and compact sets respectively.\nIt was shown in numerous works that the convergence rate of the method is on the order of 1/t and that it could not be improved in general, even if the objective function is strongly convex for instance, as shown in (Clarkson, 2008; Hazan, 2008; Jaggi, 2013), even though it is known that in this case, the projected gradient method achieves an exponentially fast convergence rate.\nOver the past years, several results tried to improve the convergence rate of the Frank-Wolfe method under various assumptions. GuéLat and Marcotte (GuéLat & Marcotte, 1986) showed that in case the objective function is strongly convex and the feasible set is a polytope, then in case the optimal solution is located in the interior of the set, the FW method converges exponentially fast. A similar result was presented in the work of Beck and Teboulle (Beck & Teboulle, 2004) who considered a specific problem they refer to a the convex feasibility problem over an arbitrary convex set. They also obtained a linear convergence rate under the assumption that an optimal solution that is far enough from the boundary of the set exists.\nRecently, Garber and Hazan (Garber & Hazan, 2013a) gave the first natural linearly-converging FW variant without any restricting assumptions on the location of the optimum. They showed that a variant of the Frank Wolfe method with the addition of away steps converges exponentially fast in case the objective function is strongly convex and the feasible set is a polytope. In follow-up work, Jaggi and Lacoste-Julien (Lacoste-Julien & Jaggi, 2013) gave a refined analysis of an algorithm presented in (GuéLat & Marcotte, 1986) which also uses away steps and showed that it also converges exponentially fast in the same setting as the Garber-Hazan result. Also relevant in this context is the work of Ahipasaoglu, Sun and Todd (Ahipasaoglu et al., 2008) who showed that in the specific case of minimizing a smooth and strongly convex function over the unit simplex, a variant of the Frank-Wolfe method that also uses away steps converges with a linear rate.\nIn a different line of work, Migdalas and recently Lan\n(Migdalas, 1994; Lan, 2013) considered the Frank-Wolfe algorithm with a stronger optimization oracle that is able to solve quadratic problems over the feasible domain. They show that in case the objective function is strongly convex then exponentially fast convergence is attainable. However, in most settings of interest, an implementation of such a non-linear oracle is computationally much more expensive than the linear oracle, and the key benefit of the FrankWolfe method is lost.\nIn the specific case that the feasible set is strongly convex, an assumption also made in this paper, Levitin and Polyak showed in their classical work (Levitin & Polyak, 1966) that under the restrictive assumption that the norm of the gradient of the objective function is lower bounded by a constant everywhere in the feasible set, the FW method converges with an exponential rate. The same result appeared in following works by Demyanov and Rubinov (Demyanov & Rubinov, 1970) and Dunn (Dunn, 1979), both also requiring that the magnitude of the gradients is lower bounded by a constant everywhere in the feasible set. As we later show, the lower bound requirement on the gradients is in a sense much stronger than requiring that the objective function is strongly convex. Under our assumption however, which is slightly weaker than strong convexity of the objective, the gradient may become arbitrarily small on the feasible set.\nWe summarize previous convergence rate results for the standard FW method in Table 1.1."
    }, {
      "heading" : "2. Preliminaries",
      "text" : ""
    }, {
      "heading" : "2.1. Smoothness and Strong Convexity",
      "text" : "For the following definitions let E be a finite vector space and ‖ · ‖, ‖ · ‖∗ be a pair of dual norms over E. Definition 1 (smooth function). We say that a function f : E → R is β smooth over a convex set K ⊂ E with respect to ‖ · ‖ if for all x, y ∈ K it holds that\nf(y) ≤ f(x) +∇f(x) · (y − x) + β 2 ‖x− y‖2.\nDefinition 2 (strongly convex function). We say that a function f : E → R is α-strongly convex over a convex set K ⊂ E with respect to ‖ · ‖ if it satisfies the following two equivalent conditions\n1. ∀x, y ∈ K :\nf(y) ≥ f(x) +∇f(x) · (y − x) + α 2 ‖x− y‖2.\n2. ∀x, y ∈ K, γ ∈ [0, 1] :\nf(γx+ (1− γ)y) ≤ γf(x) + (1− γ)f(y)\n− α 2 γ(1− γ)‖x− y‖2.\nThe above definition (part 1) combined with first order optimality conditions imply that for a α-strongly convex function f , if x∗ = arg minx∈K f(x), then for any x ∈ K\nf(x)− f(x∗) ≥ α 2 ‖x− x∗‖2. (1)\nEq. (1) further implies that the magnitude of the gradient of f at point x, ‖∇f(x)‖∗ is at least of the order of the square-root of the approximation error at x, f(x)− f(x∗). This follows since√\n2 α (f(x)− f(x∗)) · ‖∇f(x)‖∗ ≥ ‖x− x∗‖ · ‖∇f(x)‖∗\n≥ (x− x∗) · ∇f(x) ≥ f(x)− f(x∗),\nwhere the first inequality follows from (1), the second from Holder’s inequality and the third from convexity of f . Thus we have that at any point x ∈ K it holds that\n‖∇f(x)‖∗ ≥ √ α 2 · √ f(x)− f(x∗). (2)\nWe will show that this property, that is in fact weaker than strong convexity, combined with an additional property of the convex set that we define next, allows to obtain the faster rates 1.\nDefinition 3 (strongly convex set). We say that a convex set K ⊂ E is α-strongly convex with respect to ‖ · ‖ if for any x, y ∈ K, any γ ∈ [0, 1] and any vector z ∈ E such that ‖z‖ = 1, it holds that\nγx+ (1− γ)y + γ(1− γ)α 2 ‖x− y‖2z ∈ K.\nThat is, K contains a ball of of radius γ(1− γ)α2 ‖x− y‖ 2 induced by the norm ‖ · ‖ centered at γx+ (1− γ)y. 1In this work we assume that the convex set K is fulldimensional. In case this assumption does not hold, e.g. if the convex set is the unit simplex, then Eq. (2) holds even if we replace ∇f(x) with PS(K)[∇f(x)] where PS(K) denotes the projection operator onto the smallest subspace that contains K."
    }, {
      "heading" : "2.2. The Frank-Wolfe Algorithm",
      "text" : "The Frank-Wolfe algorithm, also known as the conditional gradient algorithm, is an algorithm for the minimization of a convex function f : E → R which is assumed to be βf -smooth with respect to a norm ‖ · ‖, over a convex and compact set K ⊂ E. The algorithm implicitly assumes that the convex set K is given in terms of a linear optimization oracle OK : E → K which given a linear objective c ∈ E returns a point x = OK(c) ∈ K such that x ∈ arg miny∈K y · c. The algorithm is given below. The algorithm proceeds in iterations, taking on each iteration t the new iterate xt+1 to be a convex combination between the previous feasible iterate xt and a feasible point that minimizes the dot product with the gradient direction at xt, which is generated by invoking the oracle OK with the input vector ∇f(xt). There are various ways to set the parameter that controls the convex combination ηt in order to guarantee convergence of the method. The option that we choose here is the optimization of ηt via a simple line search rule, which is straightforward and computationally cheap to implement.\nAlgorithm 1 Frank-Wolfe Algorithm 1: Let x0 be an arbitrary point in K. 2: for t = 0, 1, ... do 3: pt ← OK(∇f(xt)). 4: ηt ← arg minη∈[0,1] η(pt − xt) · ∇f(xt) +\nη2 βf 2 ‖pt − xt‖ 2. 5: xt+1 ← xt + ηt(pt − xt). 6: end for\nThe following theorem states the well-known convergence rate of the Frank-Wolfe algorithm for smooth convex minimization over a compact and convex set, without any further assumptions. A proof is given in the appendix for completeness though similar proofs could also be found in (Levitin & Polyak, 1966; Jaggi, 2013).\nTheorem 1. Let x∗ ∈ arg minx∈K f(x) and denote DK = maxx,y∈K ‖x− y‖ (the diameter of the set with respect to\n‖ · ‖). For every t ≥ 1 the iterate xt of Algorithm 1 satisfies\nf(xt)− f(x∗) ≤ 8βfD\n2 K\nt = O\n( 1\nt\n) ."
    }, {
      "heading" : "2.3. Our Results",
      "text" : "In this work, we consider the case in which the function to optimize f is not only βf -smooth with respect to ‖ · ‖ but also αf -strongly convex with respect to ‖ · ‖ (we relax this assumption a bit in subsection 4.3). We further assume that the feasible set K is αK-strongly convex with respect to ‖ · ‖. Under these two additional assumptions alone we prove the following theorem.\nTheorem 2. Let x∗ = arg minx∈K f(x) and let M =√ αfαK\n8 √ 2βf . Denote DK = maxx,y∈K ‖x− y‖. For every\nt ≥ 1 the iterate xt of Algorithm 1 satisfies\nf(xt)− f(x∗) ≤ max{ 92βfD 2 K, 18M −2} (t+ 2)2 = O\n( 1\nt2\n) ."
    }, {
      "heading" : "3. Proof of Theorem 2",
      "text" : "We denote the approximation error of the iterate xt produced by the algorithm by ht. That is ht = f(xt)− f(x∗) where x∗ = arg minx∈K f(x).\nTo better illustrate our results, we first shortly revisit the proof technique of Theorem 1. The main observation to be made is the following:\nht+1 = f(xt + ηt(pt − xt))− f(x∗) ≤ ht + ηt(pt − xt) · ∇f(xt) + η2t βf\n2 ‖pt − xt‖2 ≤\nht + ηt(x ∗ − xt) · ∇f(xt) + η2t βf 2 ‖pt − xt‖2 ≤ (1− ηt)ht + η2t βf\n2 ‖pt − xt‖2, (3)\nwhere the the first inequality follows from the smoothness of f , the second from the optimality of pt and the third from convexity of f . Choosing ηt to be roughly 1/t yields the convergence rate of 1/t stated in Theorem 1. This rate cannot be improved in general since while the so-called duality gap (xt − pt) · ∇f(xt) could be arbitrarily small (as small as (xt − x∗) · ∇f(xt)), the quantity ‖pt − xt‖ may remain as large as the diameter of the set. Note that in case f is strongly-convex, then according to Eq. (1) it holds that xt converges to x∗ and thus according to Eq. (3) it suffices to solve the inner linear optimization problem in Algorithm 1 on the intersection of K and a small ball centered at xt. As a result the quantity ‖pt − xt‖2 will be proportional to the approximation error at time t, and a linear convergence rate will be attained. However in general, under the linear oracle assumption, we have no way to solve the linear\noptimization problem over the intersection of K and a ball without greatly increasing the number of calls to the linear oracle, which is the most expensive step in many settings.\nIn case the feasible set K is strongly convex, then the main observation to be made is that while the quantity ‖pt − xt‖ may still be much larger than ‖x∗ − xt‖ (the distance to the optimum), in this case, the duality gap must also be large, which results in faster convergence. This observation is illustrated in Figure 1 and given formally in Lemma 1.\nLemma 1. On any iteration t of Algorithm 1 it holds that\nht+1 ≤ ht ·max{ 1 2 , 1− αK‖∇f(xt)‖∗ 8βf }.\nProof. By the optimality of the point pt we have that\n(pt − xt) · ∇f(xt) ≤ (x∗ − xt) · ∇f(xt) ≤ f(x∗)− f(xt) = −ht, (4)\nwhere the second inequality follows from convexity of f . Denote ct = 12 (xt + pt) and wt ∈ arg minw∈E,‖w‖≤1 w · ∇f(xt). Note that from Holder’s inequality we have that wt ·∇f(xt) = −‖∇f(xt)‖∗. Using the strong convexity of the setK we have that the point p̃t = ct+ αK8 ‖xt − pt‖\n2wt is in K. Again using the optimality of pt we have that\n(pt − xt) · ∇f(xt) ≤ (p̃t − xt) · ∇f(xt)\n= 1\n2 (pt − xt) · ∇f(xt) +\nαK‖xt − pt‖2\n8 wt · ∇f(xt)\n≤ −1 2 ht −\nαK‖xt − pt‖2\n8 ‖∇f(xt)‖∗, (5)\nwhere the last inequality follows from Eq. (4).\nWe now analyze the decrease in the approximation error\nht+1. By smoothness of f we have\nf(xt+1) ≤ f(xt) + ηt(pt − xt) · ∇f(xt)\n+ βf 2 η2t ‖pt − xt‖2.\nSubtracting f(x∗) from both sides we have\nht+1 ≤ ht + ηt(pt − xt) · ∇f(xt) + βf 2 η2t ‖pt − xt‖2.\n(6)\nPlugging Eq. (5) we have\nht+1 ≤ ht (\n1− ηt 2\n) − ηt αK‖xt − pt‖2\n8 ‖∇f(xt)‖∗\n+ βf 2 η2t ‖pt − xt‖2\n= ht\n( 1− ηt\n2 ) + ‖xt − pt‖2\n2\n( η2t βf − ηt\nαK‖∇f(xt)‖∗ 4\n) .\nIn case αK‖∇f(xt)‖∗4 ≥ βf , by the optimal choice of ηt in Algorithm 1, we can set ηt = 1 and get\nht+1 ≤ ht 2 .\nOtherwise, we can set ηt = αK‖∇f(xt)‖∗\n4βf and get\nht+1 ≤ ht (\n1− αK‖∇f(xt)‖∗ 8βf\n) .\nNote that Lemma 1 only relies on the strong convexity of the set K and did not assume anything regrading f beyond convexity and smoothness. In particular it does not require f to be strongly convex.\nWe can now prove Theorem 2.\nProof. Let M = √ αfαK\n8 √ 2βf and C =\nmax{ 92βfD 2 K, 18M −2}. We prove by induction that for all t ≥ 1, ht ≤ C(t+2)2 .\nSince we assume that the objective function f satisfies Eq. (2), we have from Lemma 1 that on any iteration t,\nht+1 ≤ ht ·max{ 1\n2 , 1−\nαK √ αf\n8 √\n2βf\n√ ht}\n= ht ·max{ 1\n2 , 1−Mh1/2t }. (7)\nFor the base case t = 1 we need to prove that h1 = f(x1)− f(x∗) ≤ C/4. By βf smoothness of f we have\nf(x1)− f(x∗) = f(x0 + η0(p0 − x0))− f(x∗)\n≤ h0 + η0(p0 − x0) · ∇f(x0) + βfη\n2 0\n2 D2K\n≤ h0(1− η0) + βfη\n2 0\n2 D2K,\nwhere the last inequality follows from convexity of f . By the optimal choice of η0 we can in particular set η0 = 1 which gives h1 ≤ βf2 D 2 K ≤ C/9.\nAssume now that the induction holds for time t ≥ 1, that is ht ≤ C(t+2)2 .\nIf the result of the max operation in Eq. (7) is the first argument, that is 1/2, we have that\nht+1 ≤ ht 2 ≤ C 2(t+ 2)2 =\nC (t+ 3)2 · (t+ 3)\n2\n2(t+ 2)2\n≤ C (t+ 3)2 . (8)\nwhere the last inequality holds for any t ≥ 1.\nWe now turn to the case in which the result of the max operation in Eq. (7) is the second argument. We consider two cases.\nIf ht ≤ C2(t+2)2 then as in Eq. (8) it holds for any t ≥ 1 that\nht+1 ≤ ht ≤ C 2(t+ 2)2 ≤ C (t+ 3)2 ,\nwhere the first inequality follows from Eq. (7).\nOtherwise, ht > C2(t+2)2 . By Eq. (7) and the induction assumption we have ht+1 ≤ ht ( 1−Mh1/2t )\n< C\n(t+ 2)2\n( 1−M √ C\n2\n1\nt+ 2\n)\n= C (t+ 3)2 · (t+ 3)\n2\n(t+ 2)2\n( 1−M √ C\n2\n1\nt+ 2\n)\n= C (t+ 3)2 · (t+ 2)\n2 + 2t+ 5\n(t+ 2)2\n( 1−M √ C\n2\n1\nt+ 2\n)\n< C\n(t+ 3)2\n( 1 + 3(t+ 2)\n(t+ 2)2\n)( 1−M √ C\n2\n1\nt+ 2\n)\n= C\n(t+ 3)2\n( 1 + 3\nt+ 2\n)( 1−M √ C\n2\n1\nt+ 2\n) .\nThus for C ≥ 18M2 we have that\nht+1 ≤ C\n(t+ 3)2\n( 1 + 3\nt+ 2\n)( 1− 3\nt+ 2 ) < C\n(t+ 3)2 ."
    }, {
      "heading" : "4. Derivation of Previous Fast Rates Results and Extensions",
      "text" : ""
    }, {
      "heading" : "4.1. Deriving the Linear Rate of Polayk & Levitin",
      "text" : "Polyak & Levitin considered in (Levitin & Polyak, 1966) the case in which the feasible set is strongly convex, the objective function is smooth and there exists a constant g > 0 such that\n∀x ∈ K : ‖∇f(x)‖∗ ≥ g. (9)\nThey showed that under the lower-bounded gradient assumption, Algorithm 1 converges with a linear rate, that is e−Θ(t). Clearly by plugging Eq. (9) into Lemma 1 we have that on each iteration t\nht+1 ≤ ht ·max{ 1 2 , 1− αkg 8βf }.\nwhich results in the same exponentially fast convergence rate as in (Levitin & Polyak, 1966) and following works such as (Demyanov & Rubinov, 1970; Dunn, 1979)."
    }, {
      "heading" : "4.2. Deriving a Linear Rate for Arbitrary Convex Sets in case x∗ is in the Interior of the Set",
      "text" : "Assume now that the feasible setK is convex but not necessarily strongly convex. We assume that the objective function f is smooth, convex, satisfies Eq. (2) with some constant αf and admits a minimizer (not necessarily unique) x∗ that lies in the interior of K, i.e. there exists a parameter r > 0 such that the ball of radius r with respect to norm ‖ · ‖ centered at x∗ is fully contained in K 2. GuéLat and Marcotte (GuéLat & Marcotte, 1986) showed the under the above conditions, the Frank-Wolfe algorithm converges with a linear rate. We now show how a slight modification in the proof of Lemma 1 yields this linear convergence result.\nLet wt be as in the proof of Lemma 1, that is wt ∈ arg minw∈E,‖w‖≤1 w · ∇f(xt). Instead of defining the\n2We assume here thatK is full-dimensional. In any other case, we can assume instead that the intersection of the ball centered at x∗ with the smallest subspace containing K is fully contained in K. In this case we also need to replace the gradient ∇f(x) with its projection onto this subspace, see also footnote 1.\npoint p̃t as in the proof of Lemma 1 we define it to be p̃t = x\n∗ + rwt. Because of our assumption on the location of x∗, it holds that p̃t ∈ K. We thus have that\n(p̃t − xt) · ∇f(xt) = (x∗t − xt) · ∇f(xt) + rwt · ∇f(xt) ≤ −r‖∇f(xt)‖∗.\nPlugging this into Eq. (6) we have\nht+1 ≤ ht − ηtr‖∇f(xt)‖∗ + βfη\n2 tD 2 K 2\n≤ ht − ηtr √ αf 2 √ ht + βfη 2 tD 2 K 2 .\nwhere DK denotes the diameter of K with respect to norm ‖ · ‖ and the second inequality follows from Eq. (2). By the optimal choice of ηt, we can set ηt = r √ αf √ ht√\n2βfD2K and get\nht+1 ≤ ht − r2αf\n4βfD2K ht,\nwhich results in a linear convergence result."
    }, {
      "heading" : "4.3. Relaxing the Strong Convexity of f",
      "text" : "So far we have considered the case in which the objective function f is strongly convex. Notice however that our main instrument for proving the accelerated convergence rate, i.e. Lemma 1, did not rely directly on strong convexity of f , but on the magnitude of the gradient, ‖∇f(xt)‖∗. We have seen in Eq. (2) that indeed if f is strongly convex than the gradient is at least of the order of √ ht. We now show that there exists functions which are not strongly convex but still satisfy Eq. (2) and hence our results apply also for them.\nConsider the function\nf(x) = 1\n2 ‖Ax− b‖22.\nwhere x ∈ Rn, A ∈ Rm×n, b ∈ Rm. Assume that m < n and all rows of A are linearly independent. In this case the optimization problem minx∈K f(x) is the problem of finding a point in K that best satisfies an under-determined linear system in terms of the mean square error. An application of the Frank-Wolfe method to this problem was studied in (Beck & Teboulle, 2004). Under these assumptions, the function f is smooth and convex but not strongly convex since the Hessian matrix given by A>A is not positive definite (note however that the matrix AA> is positive definite).\nThe gradient of f is given by\n∇f(x) = A>(Ax− b).\nThus we have that\n‖∇f(x)‖22 = [A>(Ax− b)]>[A>(Ax− b)] ≥ λmin(AA>)‖Ax− b‖22\n≥ 2λmin(AA>) (1\n2 ‖Ax− b‖22\n− 1 2 ‖Ax∗ − b‖22\n) ,\nwhere λmin(AA>) denotes the smallest eigenvalue of AA>. Since AA> is positive definite, λmin(AA>) > 0 and it follows that f satisfies Eq. (2).\nCombining the result of this subsection with the previous one yields the linear convergence rate of the Frank-Wolfe method applied to the convex feasibility problem studied in (Beck & Teboulle, 2004)."
    }, {
      "heading" : "5. Examples of Strongly Convex Sets",
      "text" : "In this section we explore convex sets for which Theorem 2 is applicable. That is, convex sets which on one hand are strongly convex, and on the other, admit a simple and efficient implementation of a linear optimization oracle. We show that various norms that give rise to natural regularization functions in machine learning, induce convex sets that fit both of the above requirements. A summary of our findings is given in Table 5. We note that in all cases in which the norm parameter p is smaller than 2 (or one of the parameters s, p in case of group norms), we are not aware of a practical algorithm for computing the projection."
    }, {
      "heading" : "5.1. Partial Characterization of Strongly Convex Sets",
      "text" : "The following lemma is taken from (Journée et al., 2010) (Theorem 12).\nLemma 2. Let E be a finite vector space and let f : E→ R be non-negative, α-strongly convex and β-smooth. Then the set K = {x | f(x) ≤ r} is α√\n2βr -strongly convex.\nThis lemma for instance shows that the Euclidean ball of radius r is 1/r-strongly convex (by applying the lemma with f = ‖x‖22).\nThe following lemma will be useful to prove that convex sets that are induced by certain norms, which do not correspond to a smooth function as in the previous lemma, are strongly convex. The proof is given in the appendix.\nLemma 3. Let E be a finite vector space, let ‖·‖ be a norm over E and assume that the function f(x) = ‖x‖2 is αstrongly convex over E with respect to the norm ‖·‖. Then for any r > 0, the set B‖·‖(r) = {x ∈ E | ‖x‖ ≤ r} is α2r - strongly convex with respect to ‖ · ‖.\n5.2. `p Balls for p ∈ (1, 2]\nGiven a parameter p ≥ 1, consider the `p ball of radius r,\nBp(r) = {x ∈ Rn | ‖x‖p ≤ r}.\nThe following lemma is proved in (Shwartz, 2007).\nLemma 4. Fix p ∈ (1, 2]. The function 12‖x‖ 2 p is (p − 1)- strongly convex w.r.t. the norm ‖·‖p.\nThe following corollary is a consequence of combining Lemma 4 and Lemma 3. The proof is given in the appendix\nCorollary 1. Fix p ∈ (1, 2]. The set Bp(r) is p−1r -strongly convex with respect to the norm ‖ · ‖p and (p−1)n 1 2 − 1 p\nr - strongly convex with respect to the norm ‖ · ‖2.\nThe following lemma establishes that linear optimization over Bp(r) admits a simple closed-form solution that can be computed in time that is linear in the number of nonzeros in the linear objective. The proof is given in the appendix.\nLemma 5. Fix p ∈ (1, 2], r > 0 and a linear objective c ∈ Rn. Let x ∈ Rn such that xi = − r‖c‖q−1q sgn(ci)|ci| q−1 where q satisfies: 1/q + 1/p = 1, and sgn(·) is the sign function. Then x = arg miny∈Bp(r) y · c\n5.3. Schatten `p Balls for p ∈ (1, 2]\nGiven a matrix X ∈ Rm×n we denote by σ(X) the vector of singular values of X in descending order, that is σ(X)1 ≥ σ(X)2 ≥ ...σ(X)min(m,n). The Schatten `p norm is given by\n‖X‖S(p) = ‖σ(X)‖p = min(m,n)∑ i=1 σ(X)pi 1/p . Consider the Schatten `p ball of radius r,\nBS(p)(r) = {X ∈ Rm×n | ‖X‖S(p) ≤ r}.\nThe following lemma is taken from (Kakade et al., 2012).\nLemma 6. Fix p ∈ (1, 2]. The function 12‖X‖ 2 S(p) is (p − 1)-strongly convex w.r.t. the norm ‖·‖S(p).\nThe proof of the following corollary follows the exact same lines as the proof of Corollary 1 by using Lemma 6 instead of Lemma 4.\nCorollary 2. Fix p ∈ (1, 2]. The set BS(p)(r) is p−1 r -strongly convex with respect to the norm ‖ · ‖S(p) and (p−1) min(m,n) 1 2 − 1 p\nr -strongly convex with respect to the frobenius norm ‖ · ‖F .\nThe following lemma establishes that linear optimization over BS(p)(r) admits a simple closed-form solution given the singular value decomposition of the linear objective. The proof is given in the appendix.\nLemma 7. Fix p ∈ (1, 2], r > 0 and a linear objective C ∈ Rm×n. Let C = UΣV > be the singular value decomposition of C. Let σ be a vector such that σi = − r ‖σ(C)‖q−1q σ(C)q−1i where q satisfies: 1/q+ 1/p = 1. Finally, let X = UDiag(σ)V > where Diag(σ) is an m× n diagonal matrix with the vector σ as the main diagonal. Then X = arg minY ∈BS(p)(r) Y • C, where • denotes the standard inner product for matrices.\n5.4. Group `s,p Balls for s, p ∈ (1, 2]\nGiven a matrix X ∈ Rm×n denote by Xi ∈ Rn the ith row of X . That is X = (X1, X2, ..., Xm)>.\nThe `s,p norm of X is given by,\n‖X‖s,p = ‖(‖X1‖s, ‖X2‖s, ..., ‖Xm‖s)‖p.\nWe define the `s,p ball as follows:\nBs,p(r) = {X ∈ Rm×n | ‖X‖s,p ≤ r}.\nThe proof of the following lemma is given in the appendix.\nLemma 8. Let s, p ∈ (1, 2]. The set Bs,p(r) is (s−1)(p−1)(s+p−2)r - strongly convex with respect to the norm ‖ · ‖s,p and n 1 s− 1 2m 1 p− 1 2\n(s−1)(p−1) (s+p−2)r -strongly convex with respect to the\nfrobenius norm ‖ · ‖F .\nThe following lemma establishes that linear optimization over Bs,p(r) admits a simple closed-form solution that can be computed in time that is linear in the number of nonzeros in the linear objective. The proof is given in the appendix.\nLemma 9. Fix s, p ∈ (1, 2], r > 0 and a linear objective C ∈ Rm×n. Let X ∈ Rm×n be such that Xi,j = − r‖C‖q−1z,q ‖Ci‖z−qz sgn(Ci,j)|Ci,j | z−1 where z satisfies: 1/s+ 1/z = 1, q satisfies: 1/p+ 1/q = 1 and Ci denotes the ith row of C. Then X = arg minY ∈Bs,p(r) Y •C, where • denotes the standard inner product for matrices."
    }, {
      "heading" : "6. Conclusions and Open Problems",
      "text" : "In this paper we proved that the Frank-Wolfe algorithm converges at an accelerated rate of O(1/t2) for smooth and strongly-convex optimization over strongly-convex sets, beating the known tight convergence rate of the method for general smooth and convex optimization. This is one of the very few known results that achieve such an improvement in convergence rate under natural and standard assumptions (i.e. strong convexity etc.). We have further demonstrated that various regularization functions in machine learning give rise to strongly convex sets. We have also demonstrated how previous fast convergence rate results follow easily from our analysis.\nThe following questions naturally arise.\nIt is known that in case the objective function is both smooth and strongly convex, projection/prox-based methods achieve a convergence rate of O(log(1/ )). Is it possible to achieve such a rate for the FW method in case the convex set is strongly convex?\nWe have shown that it is possible to obtain faster rates for optimization over balls induced by norms that give rise to strongly convex functions. Is it possible to obtain faster rates for balls induced by norms that do not give rise to strongly convex functions (but rather to smooth functions)? e.g. is it possible to obtain faster rates for `p balls for p > 2.\nFinally, the most intriguing question is to give a linear optimization oracle-based method that enjoys the same convergence rate, at least in terms of the approximation error, as optimal projection/prox-based gradient methods, in any regime (including non-smooth problems). A progress in this direction was made recently by Garber and Hazan (Garber & Hazan, 2013b) who showed that in case the feasible set is a polytope, a variant of the FW-method obtains the same rates as the projected (sub)gradient descent method."
    }, {
      "heading" : "Acknowledgments",
      "text" : "The research leading to these results has received funding from the European Unions Seventh Framework Programme (FP7/2007-2013) under grant agreement n◦ 336078 – ERCSUBLRN."
    }, {
      "heading" : "A. Proof of Theorem 1",
      "text" : "Proof. Fix an iteration t. By the βf -smoothness of f we have that\nht+1 = f(xt + ηt(pt − xt))− f(x∗) ≤ f(xt)− f(x∗) + ηt(pt − xt) · ∇f(xt)\n+ η2t βf\n2 ‖pt − xt‖2\n≤ ht − ηtht + η2t βfD 2 K\n2 , (10)\nwhere the last inequality follows from convexity of f . Notice that by the optimal choice of ηt in Algorithm 1, it holds in particular that ht+1 ≤ ht (by setting ηt = 0 in Eq. (10)).\nFix C = 8βfD2K. We now prove by induction on t that ht ≤ Ct .\nFor the base case t = 1 we notice that by the optimal choice of η0 in Algorithm 1 we can in particular set η0 = 1 and thus it follows from Eq. (10) that h1 ≤ βfD 2 K\n2 < C as needed.\nAssume now that the induction holds for t ≥ 1. That is ht ≤ Ct . We consider two cases.\nIf ht ≤ C2t then we have\nht+1 ≤ ht ≤ C\n2t =\nC t+ 1 · t+ 1 2t ≤ C t+ 1 ,\nwhere the last inequality holds for any t ≥ 1.\nOtherwise it holds that ht > C2t . Using Eq. (10) again we have\nht+1 ≤ ht − ηtht + η2t βfD 2 K\n2 .\nBy the optimal choice of ηt in Algorithm 1 we can set ηt = ht βfD2K and get\nht+1 ≤ ht − 1\n2βfD2K h2t <\nC t − C\n2\n8βfD2Kt 2\n= C\nt+ 1\n( t+ 1\nt − C(t+ 1)\n8βfD2Kt 2 ) < C\nt+ 1\n( 1 + 1\nt − Ct\n8βfD2Kt 2\n) .\nThus for C ≥ 8βfD2K we have that ht+1 ≤ Ct+1 ."
    }, {
      "heading" : "B. Proofs of Lemmas and Corollaries from",
      "text" : "Section 5\nB.1. Proof of Lemma 3\nProof. It suffices to show that given x, y ∈ E such that f(x) ≤ r2, f(y) ≤ r2, a scalar γ ∈ [0, 1] and z ∈ E such\nthat ‖z‖ ≤ α4rγ(1−γ)‖x− y‖ 2, it holds that, f(γx+ (1− γ)y + z) ≤ r2.\nBy the definition of f and the triangle inequality for ‖ · ‖ we have\nf(γx+ (1− γ)y + z) = ‖γx+ (1− γ)y + z‖2 ≤ (‖γx+ (1− γ)y‖+ ‖z‖)2 =(√\nf(γx+ (1− γ)y) + ‖z‖ )2 . (11)\nSince f is α strongly convex with respect to ‖ · ‖ we have that\nf(γx+ (1− γ)y) ≤ γf(x) + (1− γ)f(y)− α 2 γ(1− γ)‖x− y‖2 ≤ r2 − α 2 γ(1− γ)‖x− y‖2.\nThe function g(t) = √ t is concave, meaning √ a− b = g(a− b) ≤ g(a)− g′(a) · b = √ a− b\n2 √ a . Thus,\n√ f(γx+ (1− γ)y) ≤ √ r2 − α\n2 γ(1− γ)‖x− y‖2\n≤ r − αγ(1− γ)‖x− y‖ 2\n4r .\nPlugging back in Eq. (11) we have\nf(γx+ (1− γ)y + z) ≤( r − αγ(1− γ)‖x− y‖ 2\n4r + ‖z‖\n)2 .\nBy our assumption on ‖z‖ we have\nf(γx+ (1− γ)y + z) ≤ ( r − αγ(1− γ)‖x− y‖ 2\n4r\n+ α\n4r γ(1− γ)‖x− y‖2 )2 = r2.\nB.2. Proof of Corollary 1\nProof. The strong convexity of the set w.r.t. ‖ · ‖p is an immediate consequence of Lemma 3.\nSince Bp(r) is α = (p − 1)/r strongly convex w.r.t. the norm ‖ ·‖p, we have that given x, y ∈ Bp(r), γ ∈ [0, 1] and z ∈ Rn such that ‖z‖p ≤ 1 it holds that\nγx+ (1− γ)y + α 2 γ(1− γ)‖x− y‖2pz ∈ Bp(r).\nFor any p ∈ (1, 2] and vector v ∈ Rn it holds that\n‖v‖2 ≤ ‖v‖p ≤ n 1 p− 1 2 ‖v‖2. (12)\nGiven a vector z′ ∈ Rn such that ‖z′‖F ≤ 1 we have that\n‖α 2 γ(1− γ)‖x− y‖22z′‖p = α\n2 γ(1− γ)‖x− y‖22‖z′‖p.\nUsing Eq. (12) we have\n‖α 2 γ(1− γ)‖x− y‖22z′‖p ≤ α 2 γ(1− γ)‖x− y‖2pn 1 p− 1 2 ‖z′‖2 ≤ αn 1 p− 1 2\n2 γ(1− γ)‖x− y‖2p.\nHence, Bp(r) is αn 1 2− 1 p = (p−1)n\n1 2 − 1 p\nr -strongly convex with respect to ‖ · ‖2.\nB.3. Proof of Lemma 5\nProof. Since ‖·‖p and ‖·‖q are dual norms, we have using Holder’s inequality that for all x ∈ Bp(r),\nx · c ≥ −‖x‖p‖c‖q ≥ −r‖c‖q.\nThus choosing xi = − r‖c‖q−1q sgn(ci)|ci| q−1 we have that\nx · c = − n∑ i=1 r ‖c‖q−1q sgn(ci)|ci|q−1 · ci\n= − n∑ i=1 r ‖c‖q−1q |ci|q = − r ‖c‖q−1q ‖c‖qq = −r‖c‖q.\nMoreover,\n‖x‖pp = rp( ‖c‖q−1q )p n∑ i=1 ( |ci|q−1 )p .\nSince p = q/(q − 1) we have that\n‖x‖pp = rp\n‖c‖qq n∑ i=1 |ci|q = rp.\nThus we have that x ∈ Bp(r).\nB.4. Proof of Lemma 7\nProof. Since ‖·‖S(p) and ‖·‖S(q) are dual norms we from Holder’s inequality that for all X ∈ BS(p)(r),\nX • C ≥ −‖X‖S(p)‖C‖S(q) ≥ −r‖C‖S(q) = r‖σ(C)‖q.\nBy our choice of X we have that\nX • C = Tr(X>C) = Tr(V Diag(σ)>U>UΣV >) = Tr(V Diag(σ)>ΣV >) = Tr(V >V Diag(σ)>Σ) = Tr(Diag(σ)>Σ)\n= min(m,n)∑ i=1 − r ‖σ(C)‖q−1q σ(C)q−1i · σ(C)i\n= − r ‖σ(C)‖q−1q min(m,n)∑ i=1 σ(C)qi = −r‖σ(C)‖q.\nMoreover,\n‖X‖pS(p) = ‖σ(X)‖ p p = rp( ‖σ(C)‖q−1q )p n∑ i=1 ( σ(C)q−1i )p .\nSince p = q/(q − 1) we have that\n‖X‖pS(p) = rp\n‖σ(C)‖qq n∑ i=1 |σ(C)i|q = rp.\nThus we have that X ∈ BS(p)(r).\nB.5. Proof of Lemma 8\nThe following lemma will be of use in the proof. Lemma 10. for any matrix A ∈ Rm×n and s, p ∈ (1, 2] it holds that\n‖A‖F ≤ ‖A‖s,p ≤ n 1 s− 1 2m 1 p− 1 2 ‖A‖F .\nProof. For any vector v ∈ Rn and p ∈ (1, 2] it holds that\n‖v‖2 ≤ ‖v‖p ≤ n 1 p− 1 2 ‖v‖2. (13)\nDenote by Ai the ith row of A. For any i ∈ [m] and p ∈ (1, 2] it holds that\n‖Ai‖2 ≤ ‖Ai‖p ≤ n 1 p− 1 2 ‖Ai‖2. (14)\nNote that by definition ‖ · ‖F ≡ ‖ · ‖2,2. Applying Eq. (13) and (14) we have,\n‖A‖F = ‖A‖2,2 = ‖(‖A1‖2, ‖A2‖2, ..., ‖Am‖2)‖2 ≤ ‖(‖A1‖s, ‖A2‖s, ..., ‖Am‖s)‖p ≤ n 1s− 12m 1 p− 1 2 ‖(‖A1‖2, ‖A2‖2, ..., ‖Am‖2)‖2\n= n 1 s− 1 2m 1 p− 1 2 ‖A‖F .\nWe can now prove Lemma 8.\nProof. Let z, q be such that 1/z+1/s = 1 and 1/q+1/p = 1. Note that z, q ∈ [2,∞). The norm ‖ · ‖z,q is the dual norm to ‖ · ‖s,p (see (Kakade et al., 2012) for instance).\nAccording to Lemma 4, the functions ‖x‖2s and ‖x‖2p are αs = 2(s − 1)-strongly convex w.r.t. ‖ · ‖p and αp = 2(p − 1)-strongly convex w.r.t. ‖ · ‖q respectively. Hence by the strong convexity / smoothness duality (see Theorem 3 in (Kakade et al., 2012)) we have that the functions ‖x‖2z and ‖x‖2q are α−1s -smooth w.r.t. ‖ · ‖z and α−1p -smooth w.r.t. ‖ · ‖q respectively.\nBy Theorem 13 in (Kakade et al., 2012) we have that the function ‖X‖2z,q is (α−1p +α−1s )-smooth with respect to the norm ‖·‖z,q . Again using the strong convexity / smoothness duality we have that ‖X‖2s,p is ( α−1p + α −1 s )−1 = αpαs αp+αs strongly convex with respect to the norm ‖ · ‖s,p. The first part of the lemma now follows from applying Lemma 3.\nSince Bs,p(r) is α = (s−1)(p−1)(s+p−2)r strongly convex w.r.t. the norm ‖·‖s,p, we have that givenX,Y ∈ Bs,p(r), γ ∈ [0, 1] and Z ∈ Rm×n such that ‖Z‖s,p ≤ 1 it holds that\nγX + (1− γ)Y + α 2 γ(1− γ)‖X − Y ‖2s,pZ ∈ Bs,p(r).\nGiven a matrix Z ′ ∈ Rm×n such that ‖Z ′‖F ≤ 1 we have that\n‖α 2 γ(1− γ)‖X − Y ‖2FZ ′‖s,p = α\n2 γ(1− γ)‖x− y‖2F ‖Z ′‖s,p.\nUsing Lemma 10 we have\n‖α 2 γ(1− γ)‖X − Y ‖2FZ ′‖s,p ≤ α 2 γ(1− γ)‖X − Y ‖2s,pn 1 s− 1 2m 1 p− 1 2 ‖Z ′‖F ≤ αn 1 s− 1 2m 1 p− 1 2\n2 γ(1− γ)‖X − Y ‖2s,p.\nHence, Bs,p(r) is αn 1 s− 1 2m 1 p− 1 2 = n 1 s− 1 2m 1 p− 1 2\n(s−1)(p−1) (s+p−2)r strongly convex with respect\nto ‖ · ‖F .\nB.6. Proof of Lemma 9\nProof. Since by choice of z, q it holds that ‖ · ‖s,p, ‖ · ‖z,q are dual norms, we have by Holder’s inequality that\nX • C ≥ −‖X‖s,p‖C‖z,q ≥ −r‖C‖z,q.\nThus, choosing\nXi,j = − r\n‖C‖q−1z,q ‖Ci‖z−qz sgn(Ci,j)|Ci,j |z−1,\nwe have that X • C = ∑\ni∈[m],j∈[n]\nXi,jCi,j =\n∑ i∈[m],j∈[n] − r ‖C‖q−1z,q ‖Ci‖z−qz sgn(Ci,j)|Ci,j |z−1 · Ci,j =\n∑ i∈[m],j∈[n] − r ‖C‖q−1z,q ‖Ci‖z−qz |Ci,j |z =\n∑ i∈[m] − r ‖C‖q−1z,q ‖Ci‖z−qz ∑ j∈[n] |Ci,j |z =\n∑ i∈[m] − r ‖C‖q−1z,q ‖Ci‖z−qz ‖Ci‖zz = ∑ i∈[m] − r ‖C‖q−1z,q ‖Ci‖qz = − r ‖C‖q−1z,q ∑ i∈[m] ‖Ci‖qz = − r ‖C‖q−1z,q ‖C‖qz,q = −r‖C‖z,q.\nMoreover, for all i ∈ [m] it holds that\n‖Xi‖ss = n∑ j=1 |Xi,j |s = rs ‖C‖s(q−1)z,q ‖Ci‖s(z−q)z n∑ i=j |Ci,j |s(z−1).\nSince s = z/(z − 1) we have\n‖Xi‖ss = rs\n‖C‖s(q−1)z,q ‖Ci‖s(z−q)z ‖Ci‖zz = ‖Ci‖sq−z(s−1)z ‖C‖s(q−1)z,q rs\nUsing z = s/(s− 1) we have that\n‖Xi‖ss = ‖Ci‖s(q−1)z ‖C‖s(q−1)z,q rs.\nThus,\n‖Xi‖s = ( ‖Ci‖z ‖C‖z,q )q−1 r.\nFinally, we have that\n‖X‖ps,p = ∑ i∈[m] ‖Xi‖ps = ∑ i∈[m] ( ‖Ci‖z ‖C‖z,q )p(q−1) rp =\n∑ i∈[m] ( ‖Ci‖z ‖C‖z,q )q rp = rp ‖C‖qz,q ∑ i∈[m] ‖Ci‖qz = rp.\nThus, X ∈ Bs,p(r)."
    } ],
    "references" : [ {
      "title" : "Linear convergence of a modified frank-wolfe algorithm for computing minimum-volume enclosing ellipsoids",
      "author" : [ "References Ahipasaoglu", "S. Damla", "Sun", "Peng", "Todd", "Michael J" ],
      "venue" : "Optimization Methods and Software,",
      "citeRegEx" : "Ahipasaoglu et al\\.,? \\Q2008\\E",
      "shortCiteRegEx" : "Ahipasaoglu et al\\.",
      "year" : 2008
    }, {
      "title" : "A conditional gradient method with linear rate of convergence for solving convex linear systems",
      "author" : [ "Beck", "Amir", "Teboulle", "Marc" ],
      "venue" : "Math. Meth. of OR,",
      "citeRegEx" : "Beck et al\\.,? \\Q2004\\E",
      "shortCiteRegEx" : "Beck et al\\.",
      "year" : 2004
    }, {
      "title" : "Coresets, sparse greedy approximation, and the frank-wolfe algorithm",
      "author" : [ "Clarkson", "Kenneth L" ],
      "venue" : "In Proceedings of the Nineteenth Annual ACM-SIAM Symposium on Discrete Algorithms,",
      "citeRegEx" : "Clarkson and L.,? \\Q2008\\E",
      "shortCiteRegEx" : "Clarkson and L.",
      "year" : 2008
    }, {
      "title" : "Approximate methods in optimization problems",
      "author" : [ "Demyanov", "Vladimir F", "Rubinov", "Aleksandr M" ],
      "venue" : null,
      "citeRegEx" : "Demyanov et al\\.,? \\Q1970\\E",
      "shortCiteRegEx" : "Demyanov et al\\.",
      "year" : 1970
    }, {
      "title" : "Lifted coordinate descent for learning with trace-norm regularization",
      "author" : [ "Dudı́k", "Miroslav", "Harchaoui", "Zaı̈d", "Malick", "Jérôme" ],
      "venue" : "Journal of Machine Learning Research Proceedings Track,",
      "citeRegEx" : "Dudı́k et al\\.,? \\Q2012\\E",
      "shortCiteRegEx" : "Dudı́k et al\\.",
      "year" : 2012
    }, {
      "title" : "Rates of Convergence for Conditional Gradient Algorithms Near Singular and Nonsingular Extremals",
      "author" : [ "Dunn", "Joseph C" ],
      "venue" : "SIAM Journal on Control and Optimization,",
      "citeRegEx" : "Dunn and C.,? \\Q1979\\E",
      "shortCiteRegEx" : "Dunn and C.",
      "year" : 1979
    }, {
      "title" : "An algorithm for quadratic programming",
      "author" : [ "M. Frank", "P. Wolfe" ],
      "venue" : "Naval Research Logistics Quarterly,",
      "citeRegEx" : "Frank and Wolfe,? \\Q1956\\E",
      "shortCiteRegEx" : "Frank and Wolfe",
      "year" : 1956
    }, {
      "title" : "Playing non-linear games with linear oracles",
      "author" : [ "Garber", "Dan", "Hazan", "Elad" ],
      "venue" : "In 54th Annual IEEE Symposium on Foundations of Computer Science,",
      "citeRegEx" : "Garber et al\\.,? \\Q2013\\E",
      "shortCiteRegEx" : "Garber et al\\.",
      "year" : 2013
    }, {
      "title" : "A linearly convergent conditional gradient algorithm with applications to online and stochastic optimization",
      "author" : [ "Garber", "Dan", "Hazan", "Elad" ],
      "venue" : "CoRR, abs/1301.4666,",
      "citeRegEx" : "Garber et al\\.,? \\Q2013\\E",
      "shortCiteRegEx" : "Garber et al\\.",
      "year" : 2013
    }, {
      "title" : "Some comments on Wolfe’s ‘away step",
      "author" : [ "GuéLat", "Jacques", "Marcotte", "Patrice" ],
      "venue" : "Mathematical Programming,",
      "citeRegEx" : "GuéLat et al\\.,? \\Q1986\\E",
      "shortCiteRegEx" : "GuéLat et al\\.",
      "year" : 1986
    }, {
      "title" : "Large-scale image classification with trace-norm regularization",
      "author" : [ "Harchaoui", "Zaı̈d", "Douze", "Matthijs", "Paulin", "Mattis", "Dudı́k", "Miroslav", "Malick", "Jérôme" ],
      "venue" : "In IEEE Conference on Computer Vision and Pattern Recognition,",
      "citeRegEx" : "Harchaoui et al\\.,? \\Q2012\\E",
      "shortCiteRegEx" : "Harchaoui et al\\.",
      "year" : 2012
    }, {
      "title" : "Sparse approximate solutions to semidefinite programs",
      "author" : [ "Hazan", "Elad" ],
      "venue" : "In 8th Latin American Theoretical Informatics Symposium, LATIN,",
      "citeRegEx" : "Hazan and Elad.,? \\Q2008\\E",
      "shortCiteRegEx" : "Hazan and Elad.",
      "year" : 2008
    }, {
      "title" : "Projection-free online learning",
      "author" : [ "Hazan", "Elad", "Kale", "Satyen" ],
      "venue" : "In Proceedings of the 29th International Conference on Machine Learning,",
      "citeRegEx" : "Hazan et al\\.,? \\Q2012\\E",
      "shortCiteRegEx" : "Hazan et al\\.",
      "year" : 2012
    }, {
      "title" : "Revisiting frank-wolfe: Projection-free sparse convex optimization",
      "author" : [ "Jaggi", "Martin" ],
      "venue" : "In Proceedings of the 30th International Conference on Machine Learning,",
      "citeRegEx" : "Jaggi and Martin.,? \\Q2013\\E",
      "shortCiteRegEx" : "Jaggi and Martin.",
      "year" : 2013
    }, {
      "title" : "A simple algorithm for nuclear norm regularized problems",
      "author" : [ "Jaggi", "Martin", "Sulovský", "Marek" ],
      "venue" : "In Proceedings of the 27th International Conference on Machine Learning,",
      "citeRegEx" : "Jaggi et al\\.,? \\Q2010\\E",
      "shortCiteRegEx" : "Jaggi et al\\.",
      "year" : 2010
    }, {
      "title" : "Generalized power method for sparse principal component analysis",
      "author" : [ "Journée", "Michel", "Nesterov", "Yurii", "Richtárik", "Peter", "Sepulchre", "Rodolphe" ],
      "venue" : "Journal of Machine Learning Research,",
      "citeRegEx" : "Journée et al\\.,? \\Q2010\\E",
      "shortCiteRegEx" : "Journée et al\\.",
      "year" : 2010
    }, {
      "title" : "Regularization techniques for learning with matrices",
      "author" : [ "Kakade", "Sham M", "Shalev-Shwartz", "Shai", "Tewari", "Ambuj" ],
      "venue" : "Journal of Machine Learning Research,",
      "citeRegEx" : "Kakade et al\\.,? \\Q2012\\E",
      "shortCiteRegEx" : "Kakade et al\\.",
      "year" : 2012
    }, {
      "title" : "An affine invariant linear convergence analysis for frank-wolfe algorithms",
      "author" : [ "Lacoste-Julien", "Simon", "Jaggi", "Martin" ],
      "venue" : "CoRR, abs/1312.7864,",
      "citeRegEx" : "Lacoste.Julien et al\\.,? \\Q2013\\E",
      "shortCiteRegEx" : "Lacoste.Julien et al\\.",
      "year" : 2013
    }, {
      "title" : "Block-coordinate frank-wolfe optimization for structural svms",
      "author" : [ "Lacoste-Julien", "Simon", "Jaggi", "Martin", "Schmidt", "Mark W", "Pletscher", "Patrick" ],
      "venue" : "In Proceedings of the 30th International Conference on Machine Learning,",
      "citeRegEx" : "Lacoste.Julien et al\\.,? \\Q2013\\E",
      "shortCiteRegEx" : "Lacoste.Julien et al\\.",
      "year" : 2013
    }, {
      "title" : "The complexity of large-scale convex programming under a linear optimization oracle",
      "author" : [ "Lan", "Guanghui" ],
      "venue" : "CoRR, abs/1309.5550,",
      "citeRegEx" : "Lan and Guanghui.,? \\Q2013\\E",
      "shortCiteRegEx" : "Lan and Guanghui.",
      "year" : 2013
    }, {
      "title" : "A hybrid algorithm for convex semidefinite optimization",
      "author" : [ "Laue", "Sören" ],
      "venue" : "In Proceedings of the 29th International Conference on Machine Learning,",
      "citeRegEx" : "Laue and Sören.,? \\Q2012\\E",
      "shortCiteRegEx" : "Laue and Sören.",
      "year" : 2012
    }, {
      "title" : "Constrained minimization methods",
      "author" : [ "Levitin", "Evgeny S", "Polyak", "Boris T" ],
      "venue" : "USSR Computational mathematics and mathematical physics,",
      "citeRegEx" : "Levitin et al\\.,? \\Q1966\\E",
      "shortCiteRegEx" : "Levitin et al\\.",
      "year" : 1966
    }, {
      "title" : "A regularization of the frankwolfe method and unification of certain nonlinear programming methods",
      "author" : [ "Migdalas", "Athanasios" ],
      "venue" : "Mathematical Programming,",
      "citeRegEx" : "Migdalas and Athanasios.,? \\Q1994\\E",
      "shortCiteRegEx" : "Migdalas and Athanasios.",
      "year" : 1994
    }, {
      "title" : "Large-scale convex minimization with a low-rank constraint",
      "author" : [ "Shalev-Shwartz", "Shai", "Gonen", "Alon", "Shamir", "Ohad" ],
      "venue" : "In Proceedings of the 28th International Conference on Machine Learning,",
      "citeRegEx" : "Shalev.Shwartz et al\\.,? \\Q2011\\E",
      "shortCiteRegEx" : "Shalev.Shwartz et al\\.",
      "year" : 2011
    } ],
    "referenceMentions" : [ {
      "referenceID" : 17,
      "context" : "For matrix completion problems, metric learning, sparse PCA, structural SVM and other large-scale machine learning problems, this feature enabled the derivation of algorithms that are practical on one hand and come with provable convergence rates on the other (Jaggi & Sulovský, 2010; Lacoste-Julien et al., 2013; Dudı́k et al., 2012; Harchaoui et al., 2012; Hazan & Kale, 2012; Shalev-Shwartz et al., 2011; Laue, 2012).",
      "startOffset" : 260,
      "endOffset" : 419
    }, {
      "referenceID" : 4,
      "context" : "For matrix completion problems, metric learning, sparse PCA, structural SVM and other large-scale machine learning problems, this feature enabled the derivation of algorithms that are practical on one hand and come with provable convergence rates on the other (Jaggi & Sulovský, 2010; Lacoste-Julien et al., 2013; Dudı́k et al., 2012; Harchaoui et al., 2012; Hazan & Kale, 2012; Shalev-Shwartz et al., 2011; Laue, 2012).",
      "startOffset" : 260,
      "endOffset" : 419
    }, {
      "referenceID" : 10,
      "context" : "For matrix completion problems, metric learning, sparse PCA, structural SVM and other large-scale machine learning problems, this feature enabled the derivation of algorithms that are practical on one hand and come with provable convergence rates on the other (Jaggi & Sulovský, 2010; Lacoste-Julien et al., 2013; Dudı́k et al., 2012; Harchaoui et al., 2012; Hazan & Kale, 2012; Shalev-Shwartz et al., 2011; Laue, 2012).",
      "startOffset" : 260,
      "endOffset" : 419
    }, {
      "referenceID" : 23,
      "context" : "For matrix completion problems, metric learning, sparse PCA, structural SVM and other large-scale machine learning problems, this feature enabled the derivation of algorithms that are practical on one hand and come with provable convergence rates on the other (Jaggi & Sulovský, 2010; Lacoste-Julien et al., 2013; Dudı́k et al., 2012; Harchaoui et al., 2012; Hazan & Kale, 2012; Shalev-Shwartz et al., 2011; Laue, 2012).",
      "startOffset" : 260,
      "endOffset" : 419
    }, {
      "referenceID" : 0,
      "context" : "Also relevant in this context is the work of Ahipasaoglu, Sun and Todd (Ahipasaoglu et al., 2008) who showed that in the specific case of minimizing a smooth and strongly convex function over the unit simplex, a variant of the Frank-Wolfe method that also uses away steps converges with a linear rate.",
      "startOffset" : 71,
      "endOffset" : 97
    }, {
      "referenceID" : 15,
      "context" : "The following lemma is taken from (Journée et al., 2010) (Theorem 12).",
      "startOffset" : 34,
      "endOffset" : 56
    }, {
      "referenceID" : 16,
      "context" : "The following lemma is taken from (Kakade et al., 2012).",
      "startOffset" : 34,
      "endOffset" : 55
    } ],
    "year" : 2015,
    "abstractText" : "The Frank-Wolfe method (a.k.a. conditional gradient algorithm) for smooth optimization has regained much interest in recent years in the context of large scale optimization and machine learning. A key advantage of the method is that it avoids projections the computational bottleneck in many applications replacing it by a linear optimization step. Despite this advantage, the known convergence rates of the FW method fall behind standard first order methods for most settings of interest. It is an active line of research to derive faster linear optimization-based algorithms for various settings of convex optimization. In this paper we consider the special case of optimization over strongly convex sets, for which we prove that the vanila FW method converges at a rate of 1 t2 . This gives a quadratic improvement in convergence rate compared to the general case, in which convergence is of the order 1t , and known to be tight. We show that various balls induced by `p norms, Schatten norms and group norms are strongly convex on one hand and on the other hand, linear optimization over these sets is straightforward and admits a closed-form solution. We further show how several previous fastrate results for the FW method follow easily from our analysis.",
    "creator" : "LaTeX with hyperref package"
  }
}