{
  "name" : "1406.6130.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "Generalized Mixability via Entropic Duality",
    "authors" : [ "Mark D. Reid", "Rafael M. Frongillo", "Robert C. Williamson", "Nishant Mehta" ],
    "emails" : [ ],
    "sections" : [ {
      "heading" : "1 Introduction",
      "text" : "The combination or aggregation of predictions is central to machine learning. Traditional Bayesian updating can be viewed as a particular way of aggregating information that takes account of prior information. Notions of “mixability” which play a key role in the setting of prediction with expert advice offer a more general way to aggregate by taking into account a loss function to evaluate predictions. As shown by Vovk [1], his more general “aggregating algorithm” reduces to Bayesian updating when log loss is used. However there is an implicit design variable in mixability that to date has not been fully exploited. The aggregating algorithm makes use of a distance between the current distribution and a prior which serves as a regularizer. In particular the aggregating algorithm uses the KL-divergence. We consider the general setting of an arbitrary loss and an arbitrary regularizer (in the form of a Bregman divergence) and show that we recover the core technical result of traditional mixability: if a loss is mixable in our generalized sense then there is a generalized aggregating algorithm which can be guaranteed to have constant regret. The generalized aggregating algorithm is developed by optimizing the bound that defines our new notion of mixability. Our approach relies heavily on dual representations of entropy functions defined on the probability simplex\nar X\niv :1\n40 6.\n61 30\nv1 [\ncs .L\nG ]\n2 4\n(hence the title). By doing so we gain new insight into why the original mixability argument works and a broader understanding of when constant regret guarantees are possible."
    }, {
      "heading" : "1.1 Mixability in Prediction With Expert Advice Games",
      "text" : "A prediction with expert advice game is defined by its loss, a collection of experts that the player must compete against, and a fixed number of rounds. Each round the experts reveal their predictions to the player and then the player makes a prediction. An observation is then revealed to the experts and the player and all receive a penalty determined by the loss. The aim of the player is to keep its total loss close to that of the best expert once all the rounds have completed. The difference between the total loss of the player and the total loss of the best expert is called the regret and is the typically the focus of the analysis of this style of game. In particular, we are interested in when the regret is constant, that is, independent of the number of rounds played.\nMore formally, let X denote a set of possible observations and let A denote a set of actions or predictions the experts and player can perform. A loss ` : A → RX assigns the penalty `x(a) to predicting a ∈ A when x ∈ X is observed. The set of experts is denoted Θ and the set of distributions over Θ is denoted ∆Θ. In each round t = 1, . . . , T , each expert θ ∈ Θ makes a prediction atθ ∈ A. These are revealed to the player who makes a prediction ât ∈ A. Once observation xt ∈ X is revealed the experts receive loss `xt(atθ) and the player receives loss `xt(â\nt). The aim of the player is to minimize its regret Regret(T ) := LT − minθ LTθ where LT := ∑T t=1 `xt(â t)\nand LTθ = ∑T t=1 `xt(a t θ). We will say the game has constant regret if there exists a player who can always make predictions that guarantee Regret(T ) ≤ R`,Θ for all T and all expert predictions {atθ}Tt=1 where R`,Θ is a constant that may depend on ` and Θ.\nIn [2, 3], Vovk showed that if the loss for a game satisfies a condition called mixability then a player making predictions using the aggregating algorithm (AA) will achieve constant regret.\nDefinition 1 (Mixability and the Aggregating Algorithm). Given η > 0, a loss ` : A → RX is η-mixable if, for all expert predictions aθ ∈ A, θ ∈ Θ and all mixture distributions µ ∈ ∆Θ over experts there exists a prediction â ∈ A such that for all outcomes x ∈ X we have\n`x(â) ≤ −η−1 log ∑\nθ∈Θ\nexp (−η`x(aθ))µθ. (1)\nThe aggregating algorithm starts with a mixture µ0 ∈ ∆Θ over experts. In round t, experts predict atθ and the player predicts the â\nt ∈ A guaranteed by the η-mixability of ` so that (1) holds for µ = µt−1 and aθ = atθ. Upon observing x\nt, the mixture µt ∈ ∆Θ is set so that µtθ ∝ µt−1θ e−η`xt (a t θ).\nMixability can be seen as a weakening of exp-concavity (see [4, §3.3]) that requires just enough of the loss to ensure constant regret.\nTheorem 1 (Mixability implies constant regret [3]). If a loss ` is η-mixable then the aggregating algorithm will achieve Regret(T ) = η−1 log |Θ|."
    }, {
      "heading" : "1.2 Contributions",
      "text" : "The key contributions of this paper are as follows. We provide a new general definition (Definition 2) of mixability and an induced generalized aggregating algorithm (Definition 3) and show (Theorem 2) that prediction with expert advice using a Φ-mixable loss and the associated generalized aggregating algorithm is guaranteed to have constant regret. The proof illustrates that the log and exp functions that arise in the classical aggregating algorithm are themselves not special, but rather it is a translation invariant property of the convex conjugate of and entropy Φ defined on a probability simplex that is the crucial property that leads to constant regret.\nWe characterize (Theorem 4) for which entropies Φ there exists Φ-mixable losses via the Legendre property. We show that Φ-mixability of a loss can be expressed directly in terms of the Bayes risk associated with the loss (Definition 4 and Theorem 3), reflecting the situation that holds for classical mixability [5]. As part of this analysis we show that proper losses are quasi-convex (Lemma 6) which, to the best of our knowledge appears to be a new result."
    }, {
      "heading" : "1.3 Related Work",
      "text" : "The starting point for mixability and the aggregating algorithm is the work of [3, 2]. The general setting of prediction with expert advice is summarized in [4, Chapters 2 and 3]. There one can find a range of results that study different aggregation schemes and different assumptions on the losses (exp-concave, mixable). Variants of the aggregating algorithm have been studied for classically mixable losses, with a trade-off between tightness of the bound (in a constant factor) and the computational complexity [6]. Weakly mixable losses are a generalization of mixable losses. They have been studied in [7] where it is shown there exists a variant of the aggregating algorithm that achieves regret C √ T for some constant C. Vovk [1, in §2.2] makes the observation that his Aggregating Algorithm reduces to Bayesian mixtures in the case of the log loss game. See also the discussion in [4, page 330] relating certain aggregation schemes to Bayesian updating.\nThe general form of updating we propose is similar to that considered by Kivinen and Warmuth [8] who consider finding a vector w minimizing d(w, s) + ηL(yt, w ·xt) where s is some starting vector, (xt, yt) is the instance/label observation at round t and L is a loss. The key difference between their formulation and ours is that our loss term is (in their notation) w · L(yt, xt) – i.e., the linear combination of the losses of the xt at yt and not the loss of their inner product. Online methods of density estimation for exponential families are discussed in [9, §3] where the authors compare the online and offline updates of the same sequence and make heavy use of the relationship between the KL divergence between members of an exponential family and an associated Bregman divergence between the parameters of those members. The analysis of mirror descent [10] shows that it achieves constant regret when the entropic regularizer is\nused. However, there is no consideration regarding whether similar results extend to other entropies defined on the simplex.\nWe stress that the idea of the more general regularization and updates is hardly new. See for example the discussion of potential based methods in [4] and other references later in the paper. The key novelty is the generalized notion of mixability, the name of which is justified by the key new technical result — a constant regret bound assuming the general mixability condition achieved via a generalized algorithm which can be seen as intimately related to mirror descent. Crucially, our result depends on some properties of the conjugates of potentials defined over probabilities that do not hold for potential functions defined over more general spaces."
    }, {
      "heading" : "2 Generalized Mixability and Aggregation via Convex Duality",
      "text" : "In this section we introduce our generalizations of mixability and the aggregating algorithm. One feature of our approach is the way the generalized aggregating algorithm falls out of the definition of generalized mixability as the minimizer of the mixability bound. Our approach relies on concepts and results from convex analysis. Terms not defined below can be found in a reference such as [11]."
    }, {
      "heading" : "2.1 Definitions and Notation",
      "text" : "A convex function Φ : ∆Θ → R is called an entropy (on ∆Θ) if it is proper (i.e., −∞ < Φ 6= +∞), convex1, and lower semi-continuous. In the following example and elsewhere we use 1 to denote the vector 1θ = 1 for all θ ∈ Θ so that |Θ|−11 ∈ ∆Θ is the uniform distribution over Θ. Example 1 (Entropies). The (negative) Shannon entropy H(µ) := ∑ θ µθ logµθ;\nthe quadratic entropy Q(µ) := ∑ θ(µ − |Θ|−11)2; the Tsallis entropies Sα(µ) :=\nα−1 (∑\nθ µ α+1 θ − 1 ) for α ∈ (−1, 0) ∪ (0,∞); and the Rényi entropies Rα(µ) =\nα−1 ( log ∑ θ µ α+1 θ ) , for α ∈ (−1, 0). We note that both Tsallis and Rényi entropies limit to Shannon entropy α→ 0 (cf. [12, 13]). Let 〈µ, v〉 denote the inner product between µ ∈ ∆Θ and v ∈ ∆∗Θ, the dual space of ∆Θ. The Bregman divergence associated with a suitably differentiable entropy Φ on ∆Θ is given by\nDΦ(µ, µ ′) = Φ(µ)− Φ(µ′)− 〈µ− µ′,∇Φ(µ′)〉 (2)\nfor all µ ∈ ∆Θ and µ′ ∈ ri(∆Θ), the relative interior of ∆Θ. Given an entropy Φ : ∆Θ → R, we define its entropic dual to be Φ∗(v) := supµ∈∆Θ 〈µ, v〉 − Φ(µ) where v ∈ ∆∗Θ, i.e., the dual space to ∆Θ. Note that one could also write the supremum over RΘ by setting Φ(µ) = +∞ for µ /∈ ∆Θ so that Φ∗ is just the usual convex dual\n1 While the information theoretic notion of Shannon entropy as a measure of uncertainty is concave, it is convenient for us to work with convex functions on the simplex which can be thought of as certainty measures.\n(cf. [11]). Thus, all of the standard results about convex duality also hold for entropic duals provided some care is taken with the domain of definition. We note that although the regular convex dual ofH defined over all of RΘ is v 7→∑θ exp(vθ−1) its entropic dual is H∗(v) = log ∑ θ exp(vθ).\nFor differentiable Φ, it is known [11] that the supremum defining Φ∗ is attained at µ = ∇Φ∗(v). That is,\nΦ∗(v) = 〈∇Φ∗(v), v〉 − Φ(∇Φ∗(v)). (3)\nA similar result holds for Φ by applying this result to Φ∗ and using Φ = (Φ∗)∗. We will make repeated use of two easy established properties of entropic duals (see Appendix A.1 for proof).\nLemma 1. If Φ is an entropy over ∆Θ and Φη := η−1Φ denotes a scaled version of Φ then 1) for all η > 0 we have Φ∗η(v) = η\n−1Φ∗(ηv); and 2) the entropic dual Φ∗ is translation invariant – i.e., for all v ∈ ∆∗Θ and α ∈ R we have Φ∗(v+α1) = Φ∗(v)+α and hence for differentiable Φ∗ we have∇Φ∗(v + α1) = ∇Φ∗(v).\nThe translation invariance if Φ∗ is central to our analysis. It is what ensures our Φ-mixability inequality (4) “telescopes” when it is summed. The proof of the original mixability result (Theorem 1) uses a similar telescoping argument that works due to the interaction of log and exp terms in Definition 1. Our results show that this telescoping property is not due to any special properties of log and exp, but rather because of the translation invariance of the entropic dual of Shannon entropy, H . The following analysis generalizes that of the original work on mixability precisely because this property holds for the dual of any entropy."
    }, {
      "heading" : "2.2 Φ-Mixability and the Generalized Aggregating Algorithm",
      "text" : "For convenience, we will use A ∈ AΘ to denote a collection of expert predictions and Aθ ∈ A to denote the prediction of expert θ. Abusing notation slightly, we will write `(A) ∈ RX×Θ for the matrix of loss values [`x(Aθ)]x,θ, and `x(A) = [`x(Aθ)]θ ∈ RΘ for the vector of losses for each expert θ on outcome x.\nDefinition 2 (Φ-mixability). Let Φ be an entropy on ∆Θ. A loss ` : A → RX is Φmixable if for all A ∈ AΘ, all µ ∈ ∆Θ, there exists an â ∈ A such that for all x ∈ X\n`x(â) ≤ MixΦ`,x(A,µ) := inf µ′∈∆Θ 〈µ′, `x(A)〉+DΦ(µ′, µ). (4)\nThe term on the right-hand side of (4) has some intuitive appeal. Since 〈µ′, A〉 = Eθ∼µ′ [`x(Aθ)] (i.e., the expected loss of an expert drawn at random according to µ′) we can view the optimization as a trade off between finding a mixture µ′ that tracks the expert with the smallest loss upon observing outcome x and keeping µ′ close to µ, as measured by DΦ. In the special case when Φ is Shannon entropy, ` is log loss, and expert predictions Aθ ∈ ∆X are distributions over X such an optimization is equivalent to Bayesian updating [14].\nTo see that Φ-mixability is indeed a generalization of Definition 1, we make use of an alternative form for the right-hand side of the bound in the Φ-mixability definition\nthat “hides” the infimum inside Φ∗. As shown in Appendix A.1 this is a straightforward consequence of (3).\nLemma 2. The mixability bound\nMixΦ`,x(A,µ) = Φ ∗(∇Φ(µ))− Φ∗(∇Φ(µ)− `x(A)). (5)\nHence, for Φ = η−1H we have MixΦ`,x(A,µ) = −η−1 log ∑ θ exp(−η`x(Aθ))µθ which is the bound in Definition 1.\nWe now define a generalization of the Aggregating Algorithm of Definition 1 that very naturally relates to our definition of Φ-mixability: starting with some initial distribution over experts, the algorithm repeatedly incorporates the information about the experts’ performances by finding the minimizer µ′ in (4).\nDefinition 3 (Generalized Aggregating Algorithm). The algorithm begins with a mixture distribution µ0 ∈ ∆Θ over experts. On round t, after receiving expert predictions At ∈ AΘ, the generalized aggregating algorithm (GAA) predicts any â ∈ A such that `x(â) ≤ MixΦ`,x(At, µt−1) for all x which is guaranteed to exist by the Φ-mixability of `. After observing xt ∈ X , the GAA updates the mixture µt−1 ∈ ∆Θ by setting\nµt := arg min µ′∈∆Θ\n〈 µ′, `xt(A t) 〉 +DΦ(µ ′, µt−1). (6)\nWe now show that this updating process simply aggregates the per-expert losses `x(A) in the dual space ∆∗Θ with ∇Φ(µ0) as the starting point. The GAA is therefore closely related to mirror descent techniques [10].\nLemma 3. The GAA updates µt in (6) satisfy∇Φ(µt) = ∇Φ(µt−1)− `xt(At) for all t and so\n∇Φ(µT ) = ∇Φ(µ0)− T∑\nt=1\n`xt(A t). (7)\nThe proof is given in Appendix A.1. Finally, to see that the above is indeed a generalization of the Aggregating Algorithm from Definition 1 we need only apply Lemma 3 and observe that for Φ = η−1H we have∇Φ(µ) = η−1(log(µ) + 1) and so logµt = logµt−1 − η`xt(At). Exponentiating this vector equality element-wise gives µtθ ∝ µt−1θ exp(−η`xt(Atθ))."
    }, {
      "heading" : "3 Properties of Φ-mixability",
      "text" : "In this section we establish a number of key properties for Φ-mixability, the most important of these being that Φ-mixability implies constant regret. We also show that Φ-mixability is not a vacuous concept for Φ other than Shannon entropy by showing that any Legendre Φ has Φ-mixable losses and that this is a necessary condition for such losses to exist."
    }, {
      "heading" : "3.1 Φ-mixability Implies Constant Regret",
      "text" : "Theorem 2. If ` : A → RX is Φ-mixable then there is a family of strategies parameterized by µ ∈ ∆Θ which, for any sequence of observations x1, . . . , xT ∈ X and sequence of expert predictions A1, . . . , AT ∈ AΘ, plays a sequence â1, . . . , âT ∈ A such that for all θ ∈ Θ\nT∑\nt=1\n`xt(â t) ≤\nT∑\nt=1\n`xt(A t θ) +DΦ(δθ, µ). (8)\nThe proof is in Appendix A.2 and is a straight-forward consequence of Lemma 2 and the translation invariance of Φ∗. The standard notion of mixability is recovered when Φ = 1ηH for η > 0 andH the Shannon entropy on ∆Θ. In this case, Theorem 1 is obtained as a corollary for µ = |Θ|−11, the uniform distribution over Θ. A compelling feature of our result is that it gives a natural interpretation of the constant DΦ(δθ, π) in the regret bound: if π is the initial guess as to which expert is best before the game starts, the “price” that is paid by the player is exactly how far (as measured by DΦ) the initial guess was from the distribution that places all its mass on the best expert.\nThe following example computes mixability bounds for the alternative entropies introduced in §2.1. They will be discussed again in §4.2 below.\nExample 2. Consider games with K = |Θ| experts and µ = K−11. For the (negative) Shannon entropy, the regret bound from Theorem 2 is DH(δθ, µ) = logK. For quadratic entropy the regret bound is DQ(δθ, µ) = 1 − 2(K−1)K2 . For the family of Tsallis entropies the regret bound given by DSα(δθ,K\n−11) = α−1(1 − K−α). For the family of Rényi entropies the regret bound becomes DRα(δθ,K −11) = logK.\nA second, easily established result concerns the mixability of scaled entropies. The proof is by observing that in (4) the only term in the definition of MixΦη`,x involving η is DΦη = 1 ηDΦ. The quantification over A,µ, â, µ\n′ and x in the original definition have been translated into infima and suprema.\nLemma 4. The function M(η) := infA,µ supâ infµ′,x Mix Φη `,x(A,µ) − `x(â) is nonincreasing.\nThis implies that there is a well-defined maximal η > 0 for which a given loss ` is Φη-mixable since Φη-mixability is equivalent to M(η) ≥ 0. We will call this maximal η the Φ-mixability constant for ` and denote it η(`,Φ) := sup{η > 0 : M(η) ≥ 0}. This constant is central to the discussion in Section 4.3 below."
    }, {
      "heading" : "3.2 Φ-Mixability of Proper Losses and Their Bayes Risks",
      "text" : "Entropies are known to be closely related to the Bayes risk of what are called proper losses or proper scoring rules [15, 16]. Here, the predictions are distributions over outcomes, i.e., points in ∆X . To highlight this we will use p, p̂ and P instead of a, â and A to denote actions. If a loss ` : ∆X → RX is used to assign a penalty `x(p̂) to a\nprediction p̂ upon outcome x it is said to be proper if its expected value under x ∼ p is minimized by predicting p̂ = p. That is, for all p, p̂ ∈ ∆X we have\nEx∼p [`x(p̂)] = 〈p, `(p̂)〉 ≥ 〈p, `(p)〉 =: −F `(p)\nwhere −F ` is the Bayes risk of ` and is necessarily concave [5], thus making F ` : ∆X → R convex and thus an entropy. The correspondence also goes the other way: given any convex function F : ∆X → R we can construct a unique proper loss [17]. The following representation can be traced back to [18] but is expressed here using convex duality.\nLemma 5. If F : ∆X → R is a differentiable entropy then the loss `F : ∆X → R defined by `F (p) := F ∗(∇F (p))1−∇F (p) (9) is proper.\nIt is straight-forward to show that the proper loss associated with the negative Shannon entropy Φ = H is the log loss, that is, `H(µ) := − (logµ(θ))θ∈Θ.\nThis connection between losses and entropies lets us define the Φ-mixability of a proper loss strictly in terms of its associated entropy. This is similar in spirit to the result in [5] which shows that the original mixability (for Φ = H) can be expressed in terms of the relative curvature of Shannon entropy and the loss’s Bayes risk. We use the following definition to explore the optimality of Shannon mixability in Section 4.3 below.\nDefinition 4. An entropy F : ∆X → R is Φ-mixable if\nsup P,µ\nF ∗ ({ Φ∗(∇Φ(µ)− `Fx (P )) } x − Φ∗(∇Φ(µ))1 ) ≤ 0 (10)\nwhere `F is as in Lemma 5 and the supremum is over expert predictions P ∈ ∆ΘX and mixtures over experts µ ∈ ∆Θ.\nAlthough this definition appears complicated due to the handling of vectors in RX and RΘ, it has a natural interpretation in terms of risk measures from mathematical finance [19]. Given some convex function α : ∆X → R, its associated risk measure is its dual ρ(v) := supp∈∆X 〈p,−v〉 − α(p) = α∗(−v) where v is a position meaning vx is some monetary value associated with outcome x occurring. Due to its translation invariance, the quantity ρ(v) is often interpreted as the amount of “cash” (i.e., outcome independent value) an agent would ask for to take on the uncertain position v. Observe that the risk ρF for when α = F satisfies ρF ◦ `F = 0 so that `F (p) is always a ρF -risk free position. If we now interpret µ∗ = ∇Φ(µ) as a position over outcomes in Θ and Φ∗ as a risk for α = Φ the term { Φ∗(µ∗ − `Fx (P )) } x − Φ∗(µ∗)1 can be seen as the change in ρΦ risk when shifting position µ∗ to µ∗ − `Fx (P ) for each possible outcome x. Thus, the mixability condition in (10) can be viewed as a requirement that a ρF -risk free change in positions over Θ always be ρF -risk free.\nThe following theorem shows that the entropic version of Φ-mixability Definition 4 is equivalent to the loss version in Definition 2 in the case of proper losses. Its proof can\nbe found in Appendix A.3 and relies on Sion’s theorem and the facts that proper losses are quasi-convex. This latter fact appears to be new so we state it here as a separate lemma and prove it in Appendix A.1.\nLemma 6. If ` : ∆X → R is proper then p′ 7→ 〈p, `(p′)〉 is quasi-convex for all p ∈ ∆X . Theorem 3. If ` : ∆X → RX is proper and has Bayes risk −F then F is an entropy and ` is Φ-mixable if and only if F is Φ-mixable.\nThe entropic form of mixability in (10) shares some similarities with expressions for the classical mixability constants given in [20] for binary outcome games and in [5] for general games. Our expression for the mixability is more general than the previous two being both for binary and non-binary outcomes and for general entropies. It is also arguably more efficient since the optimization in [5] for non-binary outcomes requires inverting a Hessian matrix at each point in the optimization."
    }, {
      "heading" : "3.3 Characterizing and Comparing Φ-mixability",
      "text" : "Although Theorem 2 recovers the already known constant regret bound for Shannonmixable losses, it is natural to ask whether the result is vacuous or not for other entropies. That is, do there exist Φ-mixable losses for Φ other than Shannon entropy? If so, do such Φ-mixable losses exist for any entropy Φ? The next theorem answers both of these questions, showing that the existence of “non-trivial” Φ-mixable losses is intimately related to the behaviour of an entropy’s gradient at the simplex’s boundary. Specifically, an entropy Φ is said to be Legendre [21] if: a) Φ is strictly convex in int(∆Θ); and b) ‖∇Φ(µ)‖ → ∞ as µ→ µb for any µb on the boundary of ∆Θ.\nWe will say a loss is non-trivial if there exist distinct actions which are optimal for distinct outcomes (see A.4 for formal definition). This, for example, rules out constant losses – i.e., `(a) = k ∈ RX for all a ∈ A – are easily2 seen to be Φ-mixable for any Φ. For technical reasons we will further restrict our attention to curved losses by which we mean those losses with strictly concave Bayes risks. We conjecture that the following theorem also holds for non-curved losses.\nTheorem 4. There exist non-trivial, curved Φ-mixable losses if and only if the entropy Φ is Legendre.\nThe proof is in Appendix A.4. From this result we can deduce that there are no Q-mixable losses. Also, since it is easy to show the derivatives ∇Sα and ∇Rα are unbounded for α ∈ (0, 1), the entropies Sα and Rα are Legendre. Thus there exist Sαand Rα-mixable losses when α ∈ (−1, 0)."
    }, {
      "heading" : "4 Conclusions and Open Questions",
      "text" : "The main purpose of this work was to shed new light on mixability by casting it within the broader notion of Φ-mixability. We showed that the constant regret bounds enjoyed by mixability losses are due to the translation invariance of entropic duals, and\n2 The inequality in (4) reduces to 0 ≤ infµ′ DΦ(µ′, µ) which is true for all Bregman divergences.\nso are also enjoyed by any Φ-mixable loss. The definitions and technical machinery presented here allow us to ask precise questions about entropies and the optimality of their associated aggregating algorithms."
    }, {
      "heading" : "4.1 Are All Legendre Entropies “Equivalent”?",
      "text" : "Since Theorem 4 shows the existence of Φ-mixable losses, a natural question concerns the relationship between the sets of losses that are mixable for different choices of Φ. For example, are there losses that are H-mixable but not Sα-mixable, or vice-versa? We conjecture that essentially all Legendre entropies Φ have the same Φ-mixable losses up to a scaling factor.\nConjecture 1. Let Φ be a entropy on ∆Θ and ` be a Φ-mixable loss. If Ψ is a Legendre entropy on ∆Θ then there exists an η > 0 such that ` is η−1Ψ-mixable.\nSome intuition for this conjecture is derived from observing that MixΨη`,x = η −1 MixΨη`,x\nand that as η → 0 the function η` behaves like a constant loss and will therefore be mixable. This means that scaling up MixΨη`,x by η\n−1 should make it larger than MixΦ`,x. However, some subtlety arises in ensuring that this dominance occurs uniformly."
    }, {
      "heading" : "4.2 Asymptotic Behaviour",
      "text" : "There is a lower bound due to Vovk [3] for general losses ` which shows that if one is allowed to vary the number of rounds T and the number of experts K = |Θ|, then no regret bound can be better than the optimal regret bound obtained by Shannon mixability. Specifically, for a fixed loss ` with optimal Shannon mixability constant η`, suppose that for some η′ > η` we have a regret bound of the form (logK)/η′ as well as some strategy L for the learner that supposedly satisfies this regret bound. Vovk’s lower bound shows, for this η′ and L, that there exists an instantiation of the prediction with expert advice game with T large enough and K roughly exponential in T (and both are still finite) for which the alleged regret bound will fail to hold at the end of the game with non-zero probability. The regime in which Vovk’s lower bound holds suggests that the best achievable regret with respect to the number of experts grows as logK. Indeed, there is a lower bound for general losses ` that shows the regret of the best possible algorithm on games using ` must grow like Ω(log2K) [20].\nThe above lower bound arguments apply when the number of experts is large (i.e., exponential in the number of rounds) or if we consider the dynamics of the regret bound as K grows. This leaves open the question of the best possible regret bound for moderate and possibly fixedK which we formally state in the next section. This question that serves as a strong motivation for the study of generalized mixability considered here. Note also that the above lower bounds are consistent with the fact that there cannot be non-trivial, Φ-mixable losses for non-Legendre Φ (e.g., the quadratic entropy Q) since the growth of the regret bound as a function of K (cf. Example 2) is less than logK and hence violates the above lower bounds."
    }, {
      "heading" : "4.3 Is There An “Optimal” Entropy?",
      "text" : "Since we believe that Φ-mixability for Legendre Φ yield the same set of losses, we can ask whether, for a fixed loss `, some Φ give better regret bounds than others. These bounds depend jointly on the largest η such that ` is Φη-mixable and the value of DΦ(δθ, µ). We can define the optimal regret bound one can achieve for a particular loss ` using the generalized aggregating algorithm with Φη := 1ηΦ for some η > 0. This allows us to compare entropies on particular losses, and we can say that an entropy dominates another if its optimal regret bound is better for all losses `. Recalling the definition of the maximal Φ-mixability constant from Lemma 4, we can determine a quantity of more direct interest: the best regret bound one can obtain using a scaled copy of Φ. Recall that if ` is Φ-mixable, then the best regret bound one can achieve from the generalized aggregating algorithm is infµ supθDΦ(δθ, µ). We can therefore define the best regret bound for ` on a scaled version of Φ to be R`,Φ := η(`,Φ)\n−1 infµ supθDΦ(δθ, µ) which simply corresponds to the regret bound for the entropy Φη(`,Φ). Note a crucial property of R`,Φ, which will be very useful in comparing entropies: R`,Φ = R`,αΦ for all α > 0. (This follows from the observation that η(`, αΦ) = η(`,Φ)/α.) That is, R`,Φ is independent of the particular scaling we choose for Φ.\nWe can now use R`,Φ to define a scale-invariant relation over entropies. Define Φ ≥` Ψ if R`,Φ ≤ R`,Ψ, and Φ ≥∗ Ψ if Φ ≥` Ψ for all losses `. In the latter case we say Φ dominates Ψ. By construction, if one entropy dominates another its regret bound is guaranteed to be tighter and therefore its aggregating algorithm will achieve better worst-case regret. As discussed above, one natural candidate for a universally dominant entropy is the Shannon entropy.\nConjecture 2. For all choices of Θ, the negative Shannon entropy dominates all other entropies. That is, H ≥∗ Φ for all Θ and all convex Φ on ∆Θ.\nAlthough we have not been able to prove this conjecture we were able to collect some positive evidence in the form of Table 1. Here, we took the entropic form of Φ-mixability from Definition 4 and implemented3 it as an optimization problem in the language R and computed η(`F ,Φ) for F and Φ equal to the entropies introduced in Example 1 for two expert games with two outcomes. The maximal η (and hence the optimal regret bounds) for each pair was found doing a binary search for the zero-crossing of M(η) from Lemma 4 and then applying the bounds from Example 2. Although we were expecting the dominant entropy for each loss `F to be its “matching” entropy (i.e., Φ = F ), as can be seen from the table the optimal regret bound for every loss was obtained in the column forH . However, one interesting feature for these matching cases is that the optimal η (shown in parentheses) is always equal to 1.\nConjecture 3. Suppose |X| = |Θ| so that ∆Θ = ∆X . Given a Legendre Φ : ∆Θ → R and its associated proper loss `Φ : ∆X → RX , the maximal η such that `Φ is η−1Φmixable is η = 1.\nWe conjecture that this pattern will hold for matching entropies and losses for larger numbers of experts and outcomes and hope to test or prove this in future work.\n3 In order to preserve anonymity the code will not be made available until after publication."
    }, {
      "heading" : "Acknowledgments",
      "text" : "We would like to thank Matus Telgarsky for help with restricted duals, Brendan van Rooyen for noting that there are no quadratic mixable losses, and Harish Guruprasad for identifying a flaw in an earlier “proof” of the quasi-convexity of proper losses. Mark Reid is supported by an ARC Discovery Early Career Research Award (DE130101605) and part of this work was developed while he was visiting Microsoft Research. NICTA is funded by the Australian Government and as an ARC ICT Centre of Excellence."
    }, {
      "heading" : "A Appendix",
      "text" : "A.1 Proof of Lemmas Proof of Lemma 1. To show 1) we observe that (η−1Φ)∗(v) = supp 〈v, p〉−η−1Φ(p) = η−1 supp 〈ηv, p〉 − Φ(p) = η−1Φ∗(ηv). For 2), we note that the definition of the dual implies Φ∗(v+α1) = supµ∈∆Θ 〈µ, v + α1〉−Φ(µ) = supµ∈∆Θ 〈µ, v〉−Φ(µ)+α = Φ∗(v) + α since 〈µ,1〉 = 1. Taking derivatives of both sides gives the final part of the lemma.\nProof of Lemma 2. By definition Φ∗(∇Φ(µ) − v) = supµ′∈∆Θ 〈µ′,∇Φ(µ)− v〉 − Φ(µ′) and using (3) gives Φ∗(∇Φ(µ)) = 〈µ,∇Φ(µ)〉 − Φ(µ). Subtracting the former from the latter gives 〈µ,∇Φ(µ)〉−Φ(µ)− [ supµ′∈∆Θ 〈µ′,∇Φ(µ)− v〉 − Φ(µ′) ] which, when rearranged gives infµ′∈∆Θ Φ(µ ′) − Φ(µ) − 〈∇Φ(µ), µ′ − µ〉 + 〈µ′, v〉 establishing the result. When Φ = H – i.e., Φ is the (negative) Shannon entropy – we have that ∇Φ(µ) = logµ + 1, that Φ∗(v) = log ∑ θ exp(vθ), and so ∇Φ∗(v) = exp(v)/ ∑ θ exp(vθ), where log and exp are interpreted as acting point-wise on the vector µ. By Lemma 1, Φ∗(∇Φ(µ)) = Φ∗(logµ+1) = Φ∗(log(µ))+1 = 1 since Φ∗(log(µθ)) = log ∑ θ µθ =\n0. Similarly, Φ∗(∇Φ(µ)−`x(A)) = Φ∗(log(µ)−`x(A))+1 = log ∑ θ µθ exp(−`x(A))+ 1. Substituting this into Lemma 2 and applying the second part of Lemma 1 shows that Mixη\n−1H `,x (A,µ) = −η−1 log ∑ θ exp(−η`x(Aθ)), recovering the right-hand side of\nthe inequality in Definition 1.\nProof of Lemma 5. By eq. (3) we have F ∗(∇F (p)) = 〈p,∇F (p)〉 − F (p), giving us 〈 p, `F (p′) 〉 − 〈 p, `F (p) 〉 = ( 〈p′,∇F (p′)〉 − F (p′)− 〈p,∇F (p′)〉 )\n− ( 〈p,∇F (p)〉 − F (p)− 〈p,∇F (p)〉 )\n= DF (p, p ′),\nfrom which propriety follows.\nProof of Lemma 3. By considering the LagrangianL(µ, a) = 〈µ, `xt(A)〉+DΦ(µ, µt−1)+ α(〈µ,1〉 − 1) and setting its derivative to zero we see that the minimizing µt must satisfy ∇Φ(µt) = ∇Φ(µt−1) − `xt(At) − αt1 where αt ∈ R is the dual variable at step t. For convex Φ, the functions ∇Φ∗ and ∇Φ are inverses [11] so µt = ∇Φ∗(∇Φ(µt−1) − `xt(At) − at1) = ∇Φ∗(∇Φ(µt−1) − `xt(At)) by the translation invariance of Φ∗ (Lemma 1). This means the constants αt are arbitrary and can be ignored. Thus, the mixture updates satisfy the relation in the lemma and summing over t = 1, . . . , T gives (7).\nProof of Lemma 6. Let n = |X| and fix an arbitrary p ∈ ∆X . The function fp(q) = 〈p, `(q)〉 is quasi-convex if its α sublevel sets Fαp := {q ∈ ∆X : 〈p, `(q)〉 ≤ α} are convex for all α ∈ R. Let g(p) := infq fp(q) and fix an arbitrary α > g(p) so that Fαp 6= ∅. Let Qαp := {v ∈ Rn : 〈p, v〉 ≤ α} so Fαp = {q ∈ ∆X : `(q) ∈ Qαp }.\nDenote by hβq := {v : 〈v, q〉 = β} the hyperplane in direction q ∈ ∆X with offset β ∈ R and by Hβq := {v : 〈v, q〉 ≥ β} the corresponding half-space. Since ` is proper, its superprediction set S` = {λ ∈ Rn : ∃q ∈ ∆X∀x ∈ Xλx ≥ `x(q)} (see [17, Prop. 17]) is supported at x = `(q) by the hyperplane hg(q)q and furthermore since S` is convex, S` = ⋂ q∈∆X H g(q) q .\nLet V αp :=\n⋂\nv∈`(∆X)∩Qαp\nH g(`−1(v)) `−1(v) =\n⋂\nq∈Fαp\nHg(q)q\n(see figure 1). Since V αp is the intersection of halfspaces it is convex. Note that a given half-spaceHg(q)q is supported by exactly one hyperplane, namely h g(q) q . Thus the set of hyperplanes that support V αp is {hg(q)q : q ∈ Fαp } If u ∈ Fαp then there is a hyperplane in direction u that supports V αp and its offset is given by\nσV αp (u) := infv∈V αp 〈u, v〉 = g(p) > −∞\nwhereas if u 6∈ Fαp then for all β ∈ R, hβu does not support V αp and hence σV αp (u) = −∞. Thus we have shown\n( u 6∈Wαp ) ⇔ ( σV αp (u) = −∞ ) .\nObserve that σV αp (u) = −sV αp (−u) where sC(u) = supv∈C 〈u, v〉 is the support function of a set C. It is known [22, Theorem 5.1] that the “domain of definition” of a support function {u ∈ Rn : sC(u) < +∞} for a convex set C is always convex. Thus Gαp := {u ∈ ∆X : σV αp (u) > −∞} = {u ∈ Rn : σV αp (u) > −∞} ∩ ∆X is always convex because it is the intersection of convex sets. Finally by observing that\nGαp = {p ∈ ∆X : `(p) ∈ `(∆X) ∩Qαp } = Fαp\nwe have shown that Fαp is convex. Since p ∈ ∆X and α ∈ R were arbitrary we have thus shown that fp is quasi-convex for all p ∈ ∆X .\nA.2 Proof of Theorem 2 Proof of Theorem 2. Applying Lemma 2 to the assumption that ` is Φ-mixable means that for µ equal to the updates µt from Definition 3 and At equal to the expert predictions at round t, there must exist an ât ∈ ∆X such that\n`xt(â t) ≤ Φ∗(∇Φ(µt−1))− Φ∗(∇Φ(µt−1)− `xt(At))\nVERNET, WILLIAMSON, REID\n`1(q)\n` 2 (q\n)\nS`\nz = `(q)\npQap\nVap\nq\n`(Dn)\nh L(q)q =\n{x : x ·q =\nL(q)}\nFigure 9: Illustration of proof of quasi-convexity of continuous proper losses (see text).\nthe hyperplane in direction q 2 Dn with offset b 2 R and by\nHbq := {x : x0 ·q b}\nthe corresponding half-space. Since ` is proper, S` is supported at x = `(q) by the hyperplane hL(q)q and furthermore since S` is convex, S` = T q2Dn H L(q) q .\nLet Vap :=\n\\\nx2`(Dn)\\Qap HL(` 1(x)) ` 1(x) =\n\\\nq2Fap HL(q)q\n(see figure 9). Since Vap is the intersection of halfspaces it is convex. Note that a given halfspace HL(q)q is supported by exactly one hyperplane, namely h L(q) q . Thus the set of hyperplanes that support Vap is {hL(q)q : q 2 Fap } If u 2 Fap then there is a hyperplane in direction u that supports Vap and its offset is given by\nsVap (u) := infx2Vap u0 · x = L(p) > •\nwhereas if u 62 Fap then for all b 2 R, hbu does not support Vap and hence sVap (u) = •. Thus we have shown\nu 62Wap , ⇣ sVap (u) = • ⌘ .\nObserve that sVap (u) = sVap ( u) where sC(u) = supx2C u0 · x is the support function of a set C. It is known (Valentine, 1964, Theorem 5.1) that the “domain of definition” of a support function\n44\nFigure 1: Visualization of construction in proof of Lemma 6.\nfor all xt ∈ X . Summing these bounds over t = 1, . . . , T gives T∑\nt=1\n`xt(p t) ≤\nT∑\nt=1\nΦ∗(∇Φ(µt−1))− Φ∗(∇Φ(µt−1)− `xt(At))\n=Φ∗(∇Φ(µ0))− Φ∗(∇Φ(µT )) (11)\n= inf µ′∈∆Θ\n〈 µ′, T∑\nt=1\n`xT (A t) 〉 +DΦ(µ ′, µ0) (12)\n≤ 〈 µ′, T∑\nt=1\n`xt(A t) 〉 +DΦ(µ ′, µ0) for all µ′ ∈ ∆Θ (13)\nLine (11) above is because ∇Φ(µt) = ∇Φ(µt−1) − `xt(At) by Lemma 3 and the series telescopes. Line (12) is obtained by applying (6) from Lemma 3 and matching equations (5) and (4). Setting µ′ = δθ and noting 〈δθ, `(At)〉 = `xt(Atθ) gives the required result.\nA.3 Proof of Theorem 3 We first establish a general reformulation of Φ-mixability that holds for arbitrary ` by converting the quantifiers in the definition of Φ-mixability from Lemma 2 for ` into an expression involving infima and suprema. We then further refine this by assuming\n` = `F is proper (and thus quasi-convex) and has Bayes risk F .\ninf A,µ sup â inf x\nΦ∗(∇Φ(µ))− Φ∗(∇Φ(µ)− `Fx (A))− `Fx (â) ≥ 0\n⇐⇒ inf A,µ sup â inf p\n〈 p, { Φ∗(∇Φ(µ))− Φ∗(∇Φ(µ)− `Fx (P )) } x 〉 − 〈 p, `Fx (p̂) 〉 ≥ 0\n(14)\nwhere the term in braces is a vector in RX . The infimum over x is switched to an infimum over distributions over p ∈ ∆X because the optimization over p will be achieved on the vertices of the simplex as it is just an average over random variables over X .\nFrom here on we assume that ` = `F is proper and adjust our notation to emphasis that actions â = p̂ and A = P are distributions. Note that the new expression is linear – and therefore convex in p – and, by Lemma 6, we know `F is quasi-convex and so the function being optimized in (14) is quasi-concave in p̂. We can therefore apply Sion’s theorem to swap infp and supp̂ which means ` F is Φ-mixable if and only if\ninf P,µ inf p sup p̂\n〈 p, { Φ∗(∇Φ(µ))− Φ∗(∇Φ(µ)− `Fx (P )) } x 〉 − 〈 p, `Fx (p̂) 〉 ≥ 0\n⇐⇒ inf P,µ inf p\nΦ∗(∇Φ(µ))− 〈 p, { Φ∗(∇Φ(µ)− `Fx (P )) } x ) 〉 + F (p) ≥ 0\n⇐⇒ inf P,µ\nΦ∗(∇Φ(µ))− F ∗( { Φ∗(∇Φ(µ)− `Fx (P )) } x ) ≥ 0\nThe second line above is obtained by recalling that, by the definition of `F , its Bayes risk is F . We now note that the inner infimum over p passes through Φ∗(∇Φ(µ)) so that the final two terms are just the convex dual forF evaluated at { Φ∗(∇Φ(µ)− `Fx (P )) } x\n. Finally, by translation invariance of F ∗ we can pull the Φ∗(π∗) term inside F ∗ to simplify further so that the loss `F with Bayes risk F is Φ-mixable if and only if\ninf P,µ −F ∗\n({ Φ∗(∇Φ(µ)− `Fx (P )) } x − Φ∗(∇Φ(µ))1 ) ≥ 0.\nApplying Lemma 5 to write `F in terms of F and passing the sign through the infimum and converting it to a supremum gives the required result.\nA.4 Proof of Theorem 4 We will make use the following formulation of mixability,\nM(η) := inf A∈A, π∈∆Θ sup â∈A inf µ∈∆Θ, x∈X\n〈µ, `x(A)〉+ 1\nη DΦ(µ, π)− `x(â), (15)\nso that ` is Φη-mixable if and only if M(η) ≥ 0. We call a loss ` nontrivial if there exist x∗, x′ and a∗, a′ such that\na′ ∈ arg min{`x∗(a) : `x′(a) = inf a∈A `x′(a)} and inf a∈A `x∗(a) = `x∗(a ∗) < `x∗(a ′) .\n(16) Intuitively, this means that there exist distinct actions which are optimal for different outcomes x∗, x′. Note that in particular, among all optimum actions for x′, a′ has the lowest loss on x∗.\nLemma 7. Suppose ` has a strictly concave Bayes risk L. Then given any distinct µ∗, µ′ ∈ ∆Θ, there is some A ∈ A and x∗, x′ ∈ X such that for all â ∈ A we have at least one of the following:\n〈µ∗, `x∗(A)〉 < `x∗(â) , 〈µ′, `x′(A)〉 < `x′(â) . (17)\nProof. Let θ∗ be an expert such that α := µ∗θ∗ > µ ′ θ∗ =: β, which exists as µ ∗ 6= µ′. Pick arbitrary x∗, x′ ∈ X and let p∗, p′ ∈ ∆X with support only on {x∗, x′} and p∗x∗ = α/(α+β), p ′ x∗ = (1−α)/(2−α−β). Now let a∗ = arg mina∈A Ex∼p∗ [`x(a)], a′ = arg mina∈A Ex∼p′ [`x(a)], and set A such that Aθ∗ = a∗ and Aθ = a′ for all other θ ∈ Θ.\nNow suppose there is some â ∈ A violating eq. (17). Then in particular, 1 2 (`x∗(â) + `x′(â)) ≤ 12 (〈µ∗, `x∗(A)〉+ 〈µ′, `x′(A)〉)\n= 12 (α`x∗(a ∗) + (1− α)`x∗(a′) + β`x′(a∗) + (1− β)`x′(a′))\n= α+β2\n( α\nα+β `x∗(a ∗) + βα+β `x′(a\n∗) )\n+ 2−α−β2\n( 1−α\n2−α−β `x∗(a ′) + 1−β2−α−β `x′(a\n′) )\n= α+β2 L(p ∗) + ( 1− α+β2 ) L(p′) .\nLetting p̄ ∈ ∆X with p̄x∗ = p̄x′ = 1/2, observe that p̄ = α+β2 p∗ + (1− α+β 2 )p ′. But by the above calculation, we have L(p̄) ≤ α+β2 L(p∗)+(1− α+β 2 )L(p ′), thus violating strict concavity of L.\nNon-Legendre =⇒ no nontrivial mixable ` with strictly convex Bayes risk: To show that no non-constant Φ-mixable losses exist, we must exhibit a π ∈ ∆Θ and an A ∈ A such that for all â ∈ A we can find a µ ∈ ∆Θ and x ∈ X satisfying 〈µ, `x(A)〉+ 1ηDΦ(µ, π)− `x(â) < 0. Since Φ is non-Legendre it must either (1) fail strict convexity, or (2) have a point on the boundary with bounded derivative; we will consider each case separately.\n(1) Assume that Φ is not strictly convex; then we have some µ∗ 6= µ′ such that DΦ(µ\n∗, µ′) = 0. By Lemma 7 with these two distributions, we have some A and x∗, x′ such that for all â, either (i) 〈µ∗, `x∗(A)〉 < `x∗(â) or (ii) 〈µ′, `x′(A)〉 < `x′(â). We set π = µ′; in case (i) we take µ = µ∗ and x = x∗, and in (ii) we take µ = µ′ and x = x′, but as 1ηDΦ(µ, π) = 0 in both cases, we have M(η) < 0 for all η.\n(2) Now assume instead that we have some µ′ on the boundary of ∆Θ with bounded ‖∇Φ(µ′)‖ = C < ∞. Because µ′ is on the boundary of ∆Θ there is at least one expert θ∗ ∈ Θ for which µ′θ∗ = 0. Pick x∗, x′, a∗, a′ from the definition of nontrivial, eq. (16). In particular, note that `x∗(a∗) < `x∗(a′). Let π = µ′ and A ∈ A such that Aθ∗ = a\n∗ and Aθ = a′ for all other θ. Now suppose â ∈ A has `x′(â) > `x′(a′). Then taking µ = π puts all weights on experts predicting a′ while keeping DΦ(µ, π) = 0, so choosing x = x′ gives M(η) < 0 for all η. Otherwise, `x′(â) = `x′(a′), which by eq. (16) implies `x∗(â) ≥ `x∗(a′).\nLet µα = π+α(δθ∗ − π), where δθ∗ denotes the point distribution on θ∗. Calculating, we have\nM(η) = 〈µα, `x∗(A)〉+ 1ηDΦ(µα, π)− `x∗(â) = (1− α)`x∗(a′) + α`x∗(a∗) + 1ηDΦ(µα, π)− `x∗(â) ≤ (1− α)`x∗(â) + α`x∗(a∗) + 1ηDΦ(µα, π)− `x∗(â) = α(`x∗(a ∗)− `x∗(â)) + 1ηDf (α, 0),\nwhere f(α) = Φ(µα) = Φ(π+α(δθ∗ −π)). As∇πΦ is bounded, so is f ′(0). Now as lim →0Df (x+ , x)/ = 0 for any scalar convex f with bounded f ′(x) (see e.g. [21, Theorem 24.1] and [23]), we see that for any c > 0 we have some α > 0 such that Df (α, 0) < cα. Taking c = η(`x∗(â)− `x∗(a∗)) > 0 then gives M(η) < 0.\nLegendre =⇒ ∃mixable `: Assuming Φ is Legendre, we need only show that some non-constant ` is Φ-mixable. As∇πΦ is infinite on the boundary, π must be in the relative interior of ∆Θ; otherwise DΦ(µ, π) =∞ for µ 6= π.\nTake A = ∆X and `(p, x) = ‖p − δx‖2 to be the 2-norm squared loss. Now for all µ in the interior of ∆Θ and P ∈ ∆ΘX , we have 〈µ, `x(P )〉 = ∑ θ µθ‖Pθ − δx‖2 ≥\n‖p̄ − δx‖2 by convexity, where p̄ = ∑ θ µθPθ. In fact, as µ is in the interior, this inequality is strict, and remains so if replace µ by µ′ with ‖µ′ − µ‖ < for some sufficiently small. Now for all µ, P the algorithm can take p̂ = p̄, and we can always choose η = infx,µ′:‖µ′−µ‖= DΦ(µ′, µ)/( `max) > 0, so either ‖µ − π‖ < in which case we are fine by the above, or µ is far enough away that the DΦ term dominates the algorithm’s loss. (Here `max is just maxp,x `x(p), which is bounded, and DΦ(µ′, µ) > 0 as Φ is strictly convex.) So if Φ is Legendre, squared loss is Φ-mixable."
    } ],
    "references" : [ {
      "title" : "Competitive on-line statistics",
      "author" : [ "Volodya Vovk" ],
      "venue" : "International Statistical Review,",
      "citeRegEx" : "1",
      "shortCiteRegEx" : "1",
      "year" : 2001
    }, {
      "title" : "Aggregating strategies",
      "author" : [ "Volodya Vovk" ],
      "venue" : "Proceedings of the Third Annual Workshop on Computational Learning Theory (COLT),",
      "citeRegEx" : "2",
      "shortCiteRegEx" : "2",
      "year" : 1990
    }, {
      "title" : "A game of prediction with expert advice",
      "author" : [ "Volodya Vovk" ],
      "venue" : "In Proceedings of the Eighth Annual Conference on Computational Learning Theory,",
      "citeRegEx" : "3",
      "shortCiteRegEx" : "3",
      "year" : 1995
    }, {
      "title" : "Prediction, learning, and games",
      "author" : [ "Nicolo Cesa-Bianchi" ],
      "venue" : null,
      "citeRegEx" : "4",
      "shortCiteRegEx" : "4",
      "year" : 2006
    }, {
      "title" : "Mixability is bayes risk curvature relative to log loss",
      "author" : [ "Tim van Erven", "Mark D Reid", "Robert C Williamson" ],
      "venue" : "The Journal of Machine Learning Research,",
      "citeRegEx" : "5",
      "shortCiteRegEx" : "5",
      "year" : 2012
    }, {
      "title" : "Averaging expert predictions",
      "author" : [ "Jyrki Kivinen", "Manfred K Warmuth" ],
      "venue" : "In Computational Learning Theory,",
      "citeRegEx" : "6",
      "shortCiteRegEx" : "6",
      "year" : 1999
    }, {
      "title" : "The weak aggregating algorithm and weak mixability",
      "author" : [ "Yuri Kalnishkan", "Michael V. Vyugin" ],
      "venue" : "Journal of Computer and System Sciences,",
      "citeRegEx" : "7",
      "shortCiteRegEx" : "7",
      "year" : 2008
    }, {
      "title" : "Exponentiated gradient versus gradient descent for linear predictors",
      "author" : [ "Jyrki Kivinen", "Manfred K Warmuth" ],
      "venue" : "Information and Computation,",
      "citeRegEx" : "8",
      "shortCiteRegEx" : "8",
      "year" : 1997
    }, {
      "title" : "Relative loss bounds for on-line density estimation with the exponential family of distributions",
      "author" : [ "Katy S Azoury", "Manfred K Warmuth" ],
      "venue" : "Machine Learning,",
      "citeRegEx" : "9",
      "shortCiteRegEx" : "9",
      "year" : 2001
    }, {
      "title" : "Mirror descent and nonlinear projected subgradient methods for convex optimization",
      "author" : [ "Amir Beck", "Marc Teboulle" ],
      "venue" : "Operations Research Letters,",
      "citeRegEx" : "10",
      "shortCiteRegEx" : "10",
      "year" : 2003
    }, {
      "title" : "Fundamentals of convex analysis",
      "author" : [ "J.B. Hiriart-Urruty", "C. Lemaréchal" ],
      "venue" : null,
      "citeRegEx" : "11",
      "shortCiteRegEx" : "11",
      "year" : 2001
    }, {
      "title" : "Comparison of shannon, renyi and tsallis entropy used in decision trees",
      "author" : [ "Tomasz Maszczyk", "Włodzisław Duch" ],
      "venue" : "In Artificial Intelligence and Soft Computing–",
      "citeRegEx" : "12",
      "shortCiteRegEx" : "12",
      "year" : 2008
    }, {
      "title" : "R\\’enyi divergence and kullback-leibler divergence",
      "author" : [ "Tim Van Erven", "Peter Harremoës" ],
      "venue" : "arXiv preprint arXiv:1206.2459,",
      "citeRegEx" : "13",
      "shortCiteRegEx" : "13",
      "year" : 2012
    }, {
      "title" : "Bayesian conditionalisation and the principle of minimum information",
      "author" : [ "Peter M Williams" ],
      "venue" : "British Journal for the Philosophy of Science,",
      "citeRegEx" : "14",
      "shortCiteRegEx" : "14",
      "year" : 1980
    }, {
      "title" : "The geometry of proper scoring rules",
      "author" : [ "A Philip Dawid" ],
      "venue" : "Annals of the Institute of Statistical Mathematics,",
      "citeRegEx" : "15",
      "shortCiteRegEx" : "15",
      "year" : 2007
    }, {
      "title" : "Strictly proper scoring rules, prediction, and estimation",
      "author" : [ "Tilmann Gneiting", "Adrian E Raftery" ],
      "venue" : "Journal of the American Statistical Association,",
      "citeRegEx" : "16",
      "shortCiteRegEx" : "16",
      "year" : 2007
    }, {
      "title" : "Composite multiclass losses",
      "author" : [ "Elodie Vernet", "Robert C Williamson", "Mark D Reid" ],
      "venue" : "In NIPS,",
      "citeRegEx" : "17",
      "shortCiteRegEx" : "17",
      "year" : 2011
    }, {
      "title" : "Elicitation of personal probabilities and expectations",
      "author" : [ "Leonard J Savage" ],
      "venue" : "Journal of the American Statistical Association,",
      "citeRegEx" : "18",
      "shortCiteRegEx" : "18",
      "year" : 1971
    }, {
      "title" : "Stochastic finance, volume 27 of de gruyter studies",
      "author" : [ "Hans Föllmer", "Alexander Schied" ],
      "venue" : "in mathematics,",
      "citeRegEx" : "19",
      "shortCiteRegEx" : "19",
      "year" : 2004
    }, {
      "title" : "Sequential prediction of individual sequences under general loss functions",
      "author" : [ "David Haussler", "Jyrki Kivinen", "Manfred K Warmuth" ],
      "venue" : "Information Theory, IEEE Transactions on,",
      "citeRegEx" : "20",
      "shortCiteRegEx" : "20",
      "year" : 1998
    }, {
      "title" : "Convex analysis",
      "author" : [ "R.T. Rockafellar" ],
      "venue" : null,
      "citeRegEx" : "21",
      "shortCiteRegEx" : "21",
      "year" : 1997
    } ],
    "referenceMentions" : [ {
      "referenceID" : 0,
      "context" : "As shown by Vovk [1], his more general “aggregating algorithm” reduces to Bayesian updating when log loss is used.",
      "startOffset" : 17,
      "endOffset" : 20
    }, {
      "referenceID" : 1,
      "context" : "In [2, 3], Vovk showed that if the loss for a game satisfies a condition called mixability then a player making predictions using the aggregating algorithm (AA) will achieve constant regret.",
      "startOffset" : 3,
      "endOffset" : 9
    }, {
      "referenceID" : 2,
      "context" : "In [2, 3], Vovk showed that if the loss for a game satisfies a condition called mixability then a player making predictions using the aggregating algorithm (AA) will achieve constant regret.",
      "startOffset" : 3,
      "endOffset" : 9
    }, {
      "referenceID" : 2,
      "context" : "Theorem 1 (Mixability implies constant regret [3]).",
      "startOffset" : 46,
      "endOffset" : 49
    }, {
      "referenceID" : 4,
      "context" : "We show that Φ-mixability of a loss can be expressed directly in terms of the Bayes risk associated with the loss (Definition 4 and Theorem 3), reflecting the situation that holds for classical mixability [5].",
      "startOffset" : 205,
      "endOffset" : 208
    }, {
      "referenceID" : 2,
      "context" : "The starting point for mixability and the aggregating algorithm is the work of [3, 2].",
      "startOffset" : 79,
      "endOffset" : 85
    }, {
      "referenceID" : 1,
      "context" : "The starting point for mixability and the aggregating algorithm is the work of [3, 2].",
      "startOffset" : 79,
      "endOffset" : 85
    }, {
      "referenceID" : 5,
      "context" : "Variants of the aggregating algorithm have been studied for classically mixable losses, with a trade-off between tightness of the bound (in a constant factor) and the computational complexity [6].",
      "startOffset" : 192,
      "endOffset" : 195
    }, {
      "referenceID" : 6,
      "context" : "They have been studied in [7] where it is shown there exists a variant of the aggregating algorithm that achieves regret C √ T for some constant C.",
      "startOffset" : 26,
      "endOffset" : 29
    }, {
      "referenceID" : 7,
      "context" : "The general form of updating we propose is similar to that considered by Kivinen and Warmuth [8] who consider finding a vector w minimizing d(w, s) + ηL(yt, w ·xt) where s is some starting vector, (xt, yt) is the instance/label observation at round t and L is a loss.",
      "startOffset" : 93,
      "endOffset" : 96
    }, {
      "referenceID" : 9,
      "context" : "The analysis of mirror descent [10] shows that it achieves constant regret when the entropic regularizer is",
      "startOffset" : 31,
      "endOffset" : 35
    }, {
      "referenceID" : 3,
      "context" : "See for example the discussion of potential based methods in [4] and other references later in the paper.",
      "startOffset" : 61,
      "endOffset" : 64
    }, {
      "referenceID" : 10,
      "context" : "Terms not defined below can be found in a reference such as [11].",
      "startOffset" : 60,
      "endOffset" : 64
    }, {
      "referenceID" : 11,
      "context" : "[12, 13]).",
      "startOffset" : 0,
      "endOffset" : 8
    }, {
      "referenceID" : 12,
      "context" : "[12, 13]).",
      "startOffset" : 0,
      "endOffset" : 8
    }, {
      "referenceID" : 10,
      "context" : "[11]).",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 10,
      "context" : "For differentiable Φ, it is known [11] that the supremum defining Φ∗ is attained at μ = ∇Φ∗(v).",
      "startOffset" : 34,
      "endOffset" : 38
    }, {
      "referenceID" : 13,
      "context" : "In the special case when Φ is Shannon entropy, ` is log loss, and expert predictions Aθ ∈ ∆X are distributions over X such an optimization is equivalent to Bayesian updating [14].",
      "startOffset" : 174,
      "endOffset" : 178
    }, {
      "referenceID" : 9,
      "context" : "The GAA is therefore closely related to mirror descent techniques [10].",
      "startOffset" : 66,
      "endOffset" : 70
    }, {
      "referenceID" : 14,
      "context" : "Entropies are known to be closely related to the Bayes risk of what are called proper losses or proper scoring rules [15, 16].",
      "startOffset" : 117,
      "endOffset" : 125
    }, {
      "referenceID" : 15,
      "context" : "Entropies are known to be closely related to the Bayes risk of what are called proper losses or proper scoring rules [15, 16].",
      "startOffset" : 117,
      "endOffset" : 125
    }, {
      "referenceID" : 4,
      "context" : "That is, for all p, p̂ ∈ ∆X we have Ex∼p [`x(p̂)] = 〈p, `(p̂)〉 ≥ 〈p, `(p)〉 =: −F (p) where −F ` is the Bayes risk of ` and is necessarily concave [5], thus making F ` : ∆X → R convex and thus an entropy.",
      "startOffset" : 146,
      "endOffset" : 149
    }, {
      "referenceID" : 16,
      "context" : "The correspondence also goes the other way: given any convex function F : ∆X → R we can construct a unique proper loss [17].",
      "startOffset" : 119,
      "endOffset" : 123
    }, {
      "referenceID" : 17,
      "context" : "The following representation can be traced back to [18] but is expressed here using convex duality.",
      "startOffset" : 51,
      "endOffset" : 55
    }, {
      "referenceID" : 4,
      "context" : "This is similar in spirit to the result in [5] which shows that the original mixability (for Φ = H) can be expressed in terms of the relative curvature of Shannon entropy and the loss’s Bayes risk.",
      "startOffset" : 43,
      "endOffset" : 46
    }, {
      "referenceID" : 18,
      "context" : "Although this definition appears complicated due to the handling of vectors in R and R, it has a natural interpretation in terms of risk measures from mathematical finance [19].",
      "startOffset" : 172,
      "endOffset" : 176
    }, {
      "referenceID" : 19,
      "context" : "The entropic form of mixability in (10) shares some similarities with expressions for the classical mixability constants given in [20] for binary outcome games and in [5] for general games.",
      "startOffset" : 130,
      "endOffset" : 134
    }, {
      "referenceID" : 4,
      "context" : "The entropic form of mixability in (10) shares some similarities with expressions for the classical mixability constants given in [20] for binary outcome games and in [5] for general games.",
      "startOffset" : 167,
      "endOffset" : 170
    }, {
      "referenceID" : 4,
      "context" : "It is also arguably more efficient since the optimization in [5] for non-binary outcomes requires inverting a Hessian matrix at each point in the optimization.",
      "startOffset" : 61,
      "endOffset" : 64
    }, {
      "referenceID" : 20,
      "context" : "Specifically, an entropy Φ is said to be Legendre [21] if: a) Φ is strictly convex in int(∆Θ); and b) ‖∇Φ(μ)‖ → ∞ as μ→ μb for any μb on the boundary of ∆Θ.",
      "startOffset" : 50,
      "endOffset" : 54
    }, {
      "referenceID" : 2,
      "context" : "There is a lower bound due to Vovk [3] for general losses ` which shows that if one is allowed to vary the number of rounds T and the number of experts K = |Θ|, then no regret bound can be better than the optimal regret bound obtained by Shannon mixability.",
      "startOffset" : 35,
      "endOffset" : 38
    }, {
      "referenceID" : 19,
      "context" : "Indeed, there is a lower bound for general losses ` that shows the regret of the best possible algorithm on games using ` must grow like Ω(log2K) [20].",
      "startOffset" : 146,
      "endOffset" : 150
    } ],
    "year" : 2014,
    "abstractText" : "Mixability is a property of a loss which characterizes when fast convergence is possible in the game of prediction with expert advice. We show that a key property of mixability generalizes, and the exp and log operations present in the usual theory are not as special as one might have thought. In doing this we introduce a more general notion of Φ-mixability where Φ is a general entropy (i.e., any convex function on probabilities). We show how a property shared by the convex dual of any such entropy yields a natural algorithm (the minimizer of a regret bound) which, analogous to the classical aggregating algorithm, is guaranteed a constant regret when used with Φ-mixable losses. We characterize precisely which Φ have Φ-mixable losses and put forward a number of conjectures about the optimality and relationships between different choices of entropy.",
    "creator" : "LaTeX with hyperref package"
  }
}