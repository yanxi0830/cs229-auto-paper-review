{
  "name" : "1606.02077.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "Regret Bounds for Non-decomposable Metrics with Missing Labels",
    "authors" : [ "Prateek Jain", "Nagarajan Natarajan" ],
    "emails" : [ "prajain@microsoft.com", "t-nanata@microsoft.com", "precision@k;" ],
    "sections" : [ {
      "heading" : null,
      "text" : "ar X\niv :1\n60 6.\n02 07\n7v 1\n[ cs\n.L G\n] 7\nJ un\nKeywords: Non-decomposable losses, Regret bounds, Multi-label Learning"
    }, {
      "heading" : "1. Introduction",
      "text" : "Predicting relevant labels/items for a given data point is by now a standard task with applications in several domains like recommendation systems (Koren et al., 2009), document tagging, image tagging (Prabhu and Varma, 2014), etc. Many times, like say in collaborative filtering, features for the data points might not be available and one needs to predict labels only on the basis of past labels (e.g., existing likes/dislikes for various labels/items). In presence of features, the problem is the standard multi-label classification problem.\nDesign and analysis of algorithms for such tasks should counter two fundamental challenges: a) in practical scenarios, desired performance metric for our predictions are typically complex non-decomposable functions such as F1 score or precision@k; standard metrics like Hamming loss or RMSE over the labels may not be useful, and b) any realistic system in this domain should be able to handle missing labels. Furthermore, often the location of missing labels may not be available like in the positive-unlabeled learning setting (Hsieh et al., 2015). Dealing with missing labels may necessitate imposition of certain regularization on the parameters like, say, low-rank regularization so as to exploit the correlations between labels.\nMost of the existing solutions only address one of the two aspects. For example, Koyejo et al. (2015) establish that for a large class of performance metrics, the optimal solution is to compute a score vector over all the labels and selecting all the labels whose score is greater than a constant. Their algorithm treats each label as independent to estimate class-conditional probability separately for each label. Clearly, such methods ignore available information about other labels, and hence cannot handle missing information effectively. Also, such methods do not even apply for the collaborative filtering setting. On the other hand, most of the existing collaborative filtering/matrix completion methods only focus on decomposable losses like RMSE, sum of logistic loss (Lafond, 2015; Yu et al., 2014), which are not effective in real-world systems with large number of labels (Prabhu and Varma, 2014).\nIn this work, we devise a simple and generic framework that addresses both the aforementioned issues; the framework leads to simple and efficient algorithms in several different settings and for a wide variety of performance metrics used in practice including the multilabel F -measure. Our framework is motivated by a simple observation that has been used in other contexts as well (Kotłowski and Dembczyński, 2015; Koyejo et al., 2015): for a large class of metrics Ψ, simply thresholding the class probability vector leads to bayes-optimal estimators. Hence, the goal would be to estimate per-label class probabilities accurately. To this end, we show that by using a λ-strongly proper loss along with appropriate thresholding leads to bounded regret wrt. Ψ (Theorem 1). Note that the threshold can be learned using cross-validation over a small fraction of the training data.\nMoreover, λ-strong convexity of the loss function ensures that by minimizing a nuclearnorm regularized ERM (with risk measured by the selected loss function) wrt. a parameter matrix W ∈ Rd×L, we can bound the regret in Ψ by regret in estimation of the optimal W (Theorem 1); here, d is the dimensionality of the data and is equal to number of users in case of recommender system. Hence, this result allows us to focus on estimation of W∗ in various different settings such as: a) one-bit matrix completion (Theorem 2), popularly used in recommender systems with only like/dislike information, b) one-bit matrix completion with PU learning (Theorem 4) applicable to recommender systems where only “likes\" or positive feedback is observed, and c) general multi-label learning with missing labels (Theorem 3).\nFor one-bit matrix completion (and the related PU setting), we obtain our final regret bound by adapting existing results from Lafond (2015) and Hsieh et al. (2015), respectively. For general multilabel setting, a direct application of existing results, such as (Lafond, 2015) leads to weak bounds. A main technical contribution of our work is to analyze the parameter estimation problem in this setting and provide tight regret bounds. In fact, our result strictly generalizes the result by Lafond (2015), which is for general matrix completion with exponential family noise, to the general inductive matrix completion setting (Jain and Dhillon, 2013) with exponential family noise. Hence, it should have applications beyond our framework as well. Finally, we illustrate our framework and algorithms on synthetic as well as real-world datasets. Our method exhibits significant improvement over a natural extension of the method by Koyejo et al. (2015) that optimizes Ψ directly but ignores label correlations, hence does not handle missing labels in a principled manner. For example, our method achieves 12% higher F1-measure on a benchmark dataset than that by Koyejo et al. (2015).\nRelated Work. We now highlight some related theoretical work in recommender systems and multi-label learning. Gao and Zhou (2013) study consistency and surrogate losses for\ntwo specific losses namely Hamming and expected (partial) ranking losses, and leave the other losses to future work. Dembczynski et al. (2012) consider expected pairwise ranking loss in multilabel learning, show that the problem decomposes into independent binary problems, and provide regret bound for the same. Yun et al. (2014) consider the learning to rank problem, where the goal is to rank the relevant labels for a given instance. They show that popular ranking losses like NDCG can be written as a generalization of certain robust binary loss functions, although they do not provide any explicit regret bounds. Existing theoretical guarantees for 1-bit matrix completion methods used in recommender systems focus solely on RMSE or 0-1 loss (Lafond, 2015; Hsieh et al., 2015)."
    }, {
      "heading" : "2. Problem Setup and Background",
      "text" : "Let xi ∈ X ⊆ Rd denote instances and yi ∈ {0, 1}L denote label vectors. Let Y ∈ {0, 1}n×L denote the label matrix, with yi’s as rows. In typical multi-label learning and recommender system settings a) the labeling process has some inherent uncertainty, which is usually captured by assuming a conditional distribution P(yi|xi), b) furthermore, we do not get to observe all the entries of yi, but only a small subset, say Ωi. Formally, let Ω ⊂ [n] × [L] denote a subset of indices sampled i.i.d. from a fixed distribution π over [n] × [L]. We consider the following sampling model for observing label matrix Y:\nYij =\n{ 1 with probability gj(xi;W ∗)\n0 with probability 1− gj(xi;W∗) for (i, j) ∈ Ω. (1)\nwhere W∗ parameterizes the underlying conditional distribution P(yi|xi). Following the low-rank inductive matrix completion model (Yu et al., 2014; Zhong et al., 2015), we let W\n∗ ∈ Rd×L be the parameter matrix and gj(xi;W∗) = g(〈xi,w∗j 〉) where w∗j is the jth column of W∗ corresponding to the jth label, for some differentiable function g : R → [0, 1]. A popular choice of g is given by g(〈xi,wj〉) = exp(〈xi,wj〉)1+exp(〈xi,wj〉) , which corresponds to the logistic regression model. When we do not observe feature vectors x, as in the classical recommender system or matrix completion setting, the above model (1) reduces to the widely studied 1-bit matrix completion model (Cai and Zhou, 2013; Davenport et al., 2014):\nYij =\n{ 1 with probability g(W∗ij)\n0 with probability 1− g(W∗ij) for (i, j) ∈ Ω, (2)\nwhere W∗ ∈ Rn×L is the parameter matrix that captures user-item preferences. The goal is to learn a multi-label classifier f : X n → {0, 1}n×L jointly over n instances. The training data consists of input features X ∈ Rn×d where each row corresponds to an instance, drawn iid from some distribution PX over X , and partially observed label matrix Y using the sampling model (1) or (2), such that a performance metric of interest Ψ is maximized. In this work, we consider a large family of non-decomposable metrics (Koyejo et al., 2015) that constitutes linear-fractional functions of (multi-label analogues of) true positives, false positives, false negatives and true negatives defined below. Let Ŷ ∈ {0, 1}n×L denote\nthe predicted labels, i.e. Ŷ = f(X) for some f . Define the primitives:\nT̂Pij(Ŷ,Y) = [[Ŷij = 1,Yij = 1]], F̂Pij(Ŷ,Y) = [[Ŷij = 1,Yij = 0]],\nT̂Nij(Ŷ,Y) = [[Ŷij = 0,Yij = 0]], F̂Nij(Ŷ,Y) = [[Ŷij = 0,Yij = 1]].\nFor convenience, we drop the arguments and just write T̂Pij to denote T̂Pij(Ŷ,Y) and so on.\n1. Micro-averaged metrics. Define:\nT̂P(Ŷ,Y) = 1 |Ω| ∑\n(i,j)∈Ω\nT̂Pij,\nand F̂P(Ŷ,Y), T̂N(Ŷ,Y), F̂N(Ŷ,Y) similarly. Let TP = E[T̂P],FP = E[F̂P] (and so on), where the expectation is defined wrt to the sampling distribution π over indices [n]× [L] as well as the joint distribution over instances and labels. Micro-averaged performance metric Ψ : {0, 1}n,L × {0, 1}n,L → R+ is given by:\nΨ(Ŷ,Y) = a0 + a11TP+ a01FP+ a10FN+ a00TN\nb0 + b11TP+ b01FP+ b10FN+ b00TN . (3)\nfor bounded constants a’s and b’s. Assume that Ψ is bounded, i.e. ∃γ > 0 such that b0 + b11TP+ b01FP+ b10FN+ b00TN > γ for all Ŷ,Y. 2. Instance-averaged metrics. Define\nT̂Pi(Ŷ,Y) = 1 |Ωi| ∑\nj∈Ωi\nT̂Pij.\nLet TPi = E[T̂Pi]. Instance-averaged performance metric Ψ is given by:\nΨ(Ŷ,Y) = 1\nn\nn∑\ni=1\na0 + a11TPi + a01FPi + a10FNi + a00TNi b0 + b11TPi + b01FPi + b10FNi + b00TNi . (4)\nfor bounded constants a’s and b’s. Assume that Ψ is bounded, i.e. ∃γ > 0 such that b0 + b11TPi + b01FPi + b10FNi + b00TNi > γ for all Ŷ,Y, i. 3. Macro-averaged metrics. Let Ω(j) = {i : (i, j) ∈ Ω}. Define:\nT̂Pj(Ŷ,Y) = 1 |Ω(j)| ∑\ni∈Ω(j)\nT̂Pij .\nLet TPj = E[T̂Pj ]. Macro-averaged performance metric Ψ is given by:\nΨ(Ŷ,Y) = 1\nL\nL∑\nj=1\na0 + a11TPj + a01FPj + a10FNj + a00TNj b0 + b11TPj + b01FPj + b10FNj + b00TNj . (5)\nfor bounded constants a’s and b’s. Assume that Ψ is bounded, i.e. ∃γ > 0 such that b0 + b11TPj + b01FPj + b10FNj + b00TNj > γ for all Ŷ,Y, j.\nExample metrics:\n1. Instance-averaged F1 metric defined as: ΨF1(Ŷ,Y) = 1 n ∑n i=1 2TPi 2TPi+FPI+FNi . 2. Accuracy (equivalent to the Hamming loss): ΨHam(Ŷ,Y) = 1− 1n ∑n i=1 FPi + FNi.\nRemark 1. The aforementioned definitions of performance metrics naturally apply to the recommender system setting, where data is observed via the 1-bit matrix completion sampling model (2). Here, the recovery error is ultimately measured wrt to an estimated binary-valued matrix. Note that in this case, the expectations are defined wrt the sampling distribution π and the inherent noise in 1-bit sampling P(Yij |Wij).\nLet Ψ∗ denote the Bayes optimal performance, i.e. Ψ∗ = maxf Ψ(f(X),Y) (Note that Ψ is defined in terms of expectation with respect to the underlying distribution). Our objective can be now stated learning f̂ such that the Ψ-regret, i.e. Ψ∗ − Ψ(f̂(X),Y), is provably bounded. Koyejo et al. (2015) showed that the Bayes optimal Ψ∗ thresholds the conditional probability of each label j, i.e. P(yj|x) at a certain value δ∗ ∈ (0, 1), and that the value δ∗ is shared across all the labels.1:"
    }, {
      "heading" : "3. Algorithm",
      "text" : "Our approach is based on estimating real-valued predictions and then thresholding the predictions optimally in order to maximize a given metric Ψ. Koyejo et al. (2015) proposed a simple consistent plug-in estimator algorithm, which first computes conditional marginals P(yj|x) independently for each label j, and then estimates a threshold jointly to optimize Ψ. While the approach is provably consistent asymptotically, it is not clear if it admits a useful regret bound; in particular, we would like to characterize the behavior in the finite samples regime. In case of the sampling model (1), the approach translates to learning columns of the parameter matrix W independently. In many cases, W exhibits some structure, such as low-rankness, reflecting correlation between labels (Yu et al., 2014; Zhong et al., 2015; Davenport et al., 2014). Statistically, capturing correlations via a low-rank structure could help improve the sample complexity for recovery, and computationally, it would help reduce space and time complexity of the learning procedure.\nOur proposed algorithm is presented in Algorithm 1. In Step 1, we solve a traceregularized minimization problem to estimate the parameter matrix W, where the function ℓ can be any bounded loss such as the squared, the logistic or the squared Hinge loss. In particular, using the logistic loss corresponds to the maximum likelihood estimation of the sampling model (1). Yu et al. (2014) also solve essentially the same objective as (6), except for the additional bound constraint on entries of XW. The optimization problem (6) can be solved using a proximal gradient descent algorithm, with a fast proximal operator computation by storing the current solution in a low-rank form. We could also use fast non-convex procedure, by writing W = W1W T 2 , where W1 and W2 are low-rank matrices with k ≪ min(d, L) columns each, and applying alternating minimization. The real-valued estimator is given by Z = XŴ in Step 2. To obtain binary-valued predictions, we solve a 1-dimensional optimization problem to compute the optimal threshold, on the training data. Note that this step can be done in |Ω| time. 1. The definitions in (Koyejo et al., 2015) do not include general sampling distribution π, but the results\ncan be generalized in a straight-forward manner.\nRemark 2. In the 1-bit matrix completion setting, we obtain a thresholded max-likelihood estimator of W∗ ∈ Rn×L using identical procedure; where we interpret X in Algorithm 1 as the identity matrix of size n.\nAlgorithm 1 Thresholded Max-Likelihood Estimator\nInput: Training data X ∈ Rn×d, labels YΩ ∈ {0, 1}n×L observed on indices Ω and metric Ψ. 1. Obtain Ŵ by solving the trace-constrained matrix completion:\nŴ = arg min W:‖XW‖∞≤γ\n1 |Ω| ∑\n(i,j)∈Ω\nℓ(〈xi,wj〉,Yij) + λ‖W‖∗, (6)\n2. Let Z = XŴ. Define the thresholding operator Ŷ = Thrθ(Z), such that Ŷij = [[Zij ≥ θ]].\n3. Return Ŷ = Thr θ̂ (Z), where\nθ̂ = argmax θ Ψ(Thrθ(ZΩ),YΩ)."
    }, {
      "heading" : "4. Analysis: Regret Bounds",
      "text" : "In this Section, we first show that Ψ-regret can be bounded with the regret of a certain loss ℓ. Then, under various sampling models pertaining to different settings such as 1-bit matrix completion, multi-label learning, and PU (positive-unlabeled) learning, we show that the ℓregret can be bounded, via recovering the underlying parameter matrix governing P(yij|xi)."
    }, {
      "heading" : "4.1 Low ℓ-regret implies low Ψ-regret",
      "text" : "Our first main result connects Ψ-regret to regret with respect to a strongly proper loss function ℓ (Agarwal, 2014). Canonical examples of strongly proper losses include the logistic loss ℓ(t, y) = log(1+exp(−yt)), the exponential loss ℓ(t, y) = exp(−yt) and the squared loss ℓ(t, y) = (1− yt)2. Define the ℓ-regret of Z ∈ Rn×L as:\nRegℓ(Z) = E[ℓ(Zij,Yij)]− min Z ′∈Rn×L E[ℓ(Z′ij ,Yij)],\nwhere the expectation is wrt. draws from π and the joint distribution over instances and labels.\nTheorem 1 (Main Result 1). Let Ψ be a performance metric as defined in (3) , (4) or (5). Let ℓ be a λ-strongly proper loss function. Assume the input X ∈ Rn×L consists of iid instances sampled from marginal PX, label matrix Y ∈ {0, 1}n×L, where yij is sampled iid from P(yij|xi), which is observed only on a subset of indices Ω sampled iid from a fixed distribution π. Then, the output Ŷ obtained by thresholding the estimate Z in Step 3 of\nAlgorithm 1 satisfies the regret bound:\nΨ∗ −Ψ(Ŷ,Y) ≤ C √ 2\nλ\n√ Regℓ(Z) +O ( 1√ |Ω| ) , (7)\nfor some absolute constants C and λ.\nWe emphasize that the above result holds for arbitrary metric Ψ from the family (3), (4) or (5). Consider the RHS of (7): 1/ √ |Ω| is the lower-order term, and independent of dimensionality; the first term makes the framework fairly powerful, as it can use any strongly proper loss. In the next subsection, we will provide precise instantiations of this term under various learning settings.\nProof Outline for Theorem 1. Proof technique is based on (Kotłowski and Dembczyński, 2015), where they derive similar bound in the binary classification setting. We first relate the Ψ-regret to weighted 0-1 loss regret (Lemma 2). Then, we show there exists a thresholding Thrθ∗(Z) ∈ {0, 1}n×L such that its weighted loss regret is bounded by the ℓ-regret of a strongly proper loss ℓ (Lemma 3). Finally, we argue that it suffices to estimate θ̂ from the training data (Lemma 4). Detailed proof and associated Lemmas are available in Appendix A.1."
    }, {
      "heading" : "4.2 Bounding ℓ-regret",
      "text" : "Below, we provide the desired ℓ-regret bound under three different settings."
    }, {
      "heading" : "4.2.1 Collaborative Filtering",
      "text" : "Consider the 1-bit matrix completion sampling model in (2). Then (6) reduces to the optimization problem considered by Lafond (2015). We have the following regret bound for the estimator Z = Ŵ obtained in Step 2 of Algorithm 1 (Note that X is just treated as identity in this setting).\nTheorem 2. Assume π is uniform, and consider the 1-bit matrix completion sampling model (2). Let ℓ denote a 1-Lipschitz, strongly proper loss (appearing in (7)), and Z denote the output of Step 2 of Algorithm 1. With probability at least 1− δ, the following holds:\nRegℓ(Z) ≤\n√√√√C̃max ( max(n,L) rank(W∗) log(3/δ)\n|Ω|\n( σ2γ + 1 ) , γ2\n√ log(3/δ)\n|Ω|\n) ,\nwhere C̃, cγ , c ′ γ , c ′′ γ , σγ are numerical constants, and γ = maxij |W∗ij |.\nNote that when |Ω| > max(n,L), the RHS of the above bound starts converging; in particular, the second term within max is the lower-order term: γ ≈ O (√ 1/nL ) . Theorem 2 can be extended to general distributions π beyond uniform, satisfying mild assumptions. See Appendix A.2."
    }, {
      "heading" : "4.2.2 Multi-label Learning",
      "text" : "Consider the sampling model (1) with features. We have the following regret bound for the estimator Z = XŴ obtained in Step 2 of Algorithm 1, under the following assumptions.\nAssumption 1. The marginal distribution over the features PX is sub-Gaussian with subGaussian norm K and covariance Σ ∈ Rd×d.\nAssumption 2. Let πk,l denote the probability of sampling the entry (k, l) ∈ [n]× [L];\n1. ∃ µ ≥ 1 s.t. mink∈[n],l∈[L] πk,l ≥ 1µnL , and 2. ∃ ν ≥ 1 s.t. maxi′,j′ (∑ j πi′j , ∑ i πij′ ) ≤ νmin(n,L) .\nTheorem 3 (Main Result 2). Assume 1, 2 and consider the sampling model (1). Also assume L ≥ d. Let Ŵ be the solution to the trace-norm regularized optimization problem (6) using logistic loss for ℓ, number of training data points n ≥ C ′ . d, number of observations |Ω| ≥ L + d, and setting the regularization parameter λ = 2c√\n|Ω| . Then, with probability at\nleast 1− 3(n+ L)−1 − 2(d+ L)−1, the following holds:\n‖Ŵ − W∗‖2F dL ≤ C2µ 2 d max\n( L rank(W∗) log(n+ L)\n|Ω|\n( σ2γ + 1 ) , γ2\nµ\n√ log(n + L)\n|Ω|\n) ,\nwhere c, C ′, C2 are numerical constants and σγ ≤ (1 + eγ)2eγ.\nA few remarks of our result in the multi-label setting are in order:\nRemark 3 (Generalization). The result in Theorem 3, and Theorem 8 in Appendix B for general exponential distributions, is a key technical contribution of this work. In particular, our analysis applies to Y arising from general exponential distributions, including Gaussian when Y is real-valued and Poisson when Y models counts. See Appendix B for more details.\nRemark 4 (Comparing (Lafond, 2015)). If we directly apply the method and the analysis of (Lafond, 2015), the resulting bounds are very weak; in fact, when n ≥ L and |Ω| = O(n), which is quite common in the multi-label scenario, the ensuing bound suggests that the estimator is not even consistent, even when π is uniform. See Appendix A.3 for details.\nRemark 5 (Comparing (Koyejo et al., 2015)). The plugin-in estimator algorithm of (Koyejo et al., 2015) estimates w∗j for each label j independently, and learns a common threshold as in Algorithm 1. Let ŵj denote the estimator for label j. Then, using standard analysis we have,\n‖ŵj −w∗j‖2 ≤ σ √ d |Ωj | , where |Ωj | is the number of observations per label which is O( |Ω| L ). Thus we have the bound: ‖W∗−Ŵ‖2 F\nL ≤ σO(Ld|Ω|). This is how our bounds behave, when W∗\nis indeed full rank, up to constants. When rank(W∗) ≪ min(d, L), we achieve much faster convergence.\nWe now give the desired ℓ-regret bound as a corollary.\nCorollary 1. Assume the conditions of Theorem 3 hold. Let ℓ denote a 1-Lipschitz, strongly proper loss (appearing in (7)), and Z = XŴ denote the output of Step 2 of Algorithm 1. With probability at least 1− δ − (d+ L)−1, the following holds:\nRegℓ(Z) ≤ √√√√C2µ2max ( L rank(W∗) log(3/δ)\n|Ω|\n( σ2γ + 1 ) , γ2\nµ\n√ log(3/δ)\n|Ω|\n) ,\nwhere c, C ′, C2, σγ are defined as in Theorem 3.\nProof Outline for Theorem 3. We analyze the following general exponential noise model for Y:\nyij|xi,wj ∼ exph,G(xi,wj) := h(yij) exp ( 〈xi,wj〉yij −G(〈xi,wj〉) ) , (8)\nwhere h and G are the base measure and log-partition functions associated with this canonical representation. Our proof sketch is based on Lafond (2015), but requires bounding certain quantities carefully. In particular, we prove a tight bound for ‖XT∇ΦY(X,W∗)‖2 in terms of the regularization parameter λ, where ΦY(X,W\n∗) is the MLE wrt. general exponential distribution (reduces to (6), without regularization, when yij’s are from (1)), as stated below.\nLemma 1. Consider the sampling model (8). Assume (i) d ≤ L, (ii) |Ω| ≥ (L+d), (iii) yij’s are sampled independently given xi, and (iv) |yij −G′(〈xi,w∗j 〉)| ≤ α, for all i, j ∈ [n]× [L], for any n,L. Let X ∈ Rn×d whose rows (xi’s) are iid samples from PX satisfying Assumption 1. Then, with probability at least 1− (d+ L)−1, there exists numerical constant c such that,\n∥∥XT∇ΦY (X,W∗) ∥∥ 2 ≤ c . α√\n|Ω| ."
    }, {
      "heading" : "4.2.3 PU Learning",
      "text" : "In many collaborative filtering and multi-label learning tasks, only the positive entries (yij = 1) are observed. In this setting, we can use the approach of (Hsieh et al., 2015), where they consider a two-stage sampling model: sample yij using (2) for all i, j ∈ [n] × [L] (or using (1) when features are available), and then flip a fraction ρ of the sampled 1’s to 0’s, resulting in Ỹ. We would then use the unbiased estimator ℓ̃ of loss ℓ in (6); ℓ̃ satisfies E[ℓ̃(Zij , Ỹij)] = ℓ(Zij ,Yij), where the expectation is wrt the flipping process, parameterized by ρ. For the estimator Z = Ŵ obtained thus, we have the following regret bound.\nTheorem 4. Let ℓ denote a 1-Lipschitz, strongly proper loss (appearing in (7)). Assume ‖W∗‖∗ ≤ t. Let Z = XŴ, where Ŵ is obtained by solving the unbiased estimator objective of Hsieh et al. (2015). With probability at least 1− δ, there exists absolute constant C such that:\nRegℓ(Z) ≤ √ 6 √ log(2/δ)√ nL(1− ρ) + 2C . t √ n+ √ L (1− ρ)nL.\nThe RHS of the bound above, when n = L, is of O( √\n1 n(1−ρ)), where (1−ρ) is the fraction\nof observed 1’s in Ỹ . Naturally, as ρ is large, we need more samples to achieve similar rates as in the other settings.\nRemark 6. This PU learning result is particularly very useful in extreme classification setting (Bhatia et al., 2015a; Prabhu and Varma, 2014); where there are too many labels and is unrealistic to get feedback on every label, but possible to obtain a small subset of relevant labels for instances. Furthermore, the above result serves to attest to the utility of our framework."
    }, {
      "heading" : "5. Experiments",
      "text" : "We focus on multi-label datasets for experimental study. The goal is to show that the convergence happens as suggested by the theory, and that the proposed algorithm performs well on real-world datasets. To solve (6), we use an alternating minimization procedure by forming W = W1W T 2 , such that W1 ∈ Rd×k and W2 ∈ RL×k, where k, the rank of W, is an input parameter."
    }, {
      "heading" : "5.1 Synthetic data",
      "text" : "We generate multi-label data as follows. We fix n = 1000, L = 100 and d = 10. First, we generate X ∈ Rn×d using samples from multi-variate Gaussian N (0, I). Then, we generate W\n∗ of rank 5. The label matrix Y is obtained by thresholding XW∗ at θ∗ = 0, i.e. yij = sign(〈xi,w∗j 〉). In this noise-free setting, we expect that our algorithm would recover both W∗ and θ∗ accurately as it sees more and more observations. The results for maximizing micro F1 and accuracy metrics are presented in Figure 1. As the sampling ratio |Ω| nL\nincreases, we observe that the proposed estimator achieves optimal performance in both the cases. Furthermore, even when only 10% of the observations are revealed, we observe that the proposed method achieves very high F1 as well as accuracy values, compared to learning the columns of W∗ independently via the plugin estimator method proposed by (Koyejo et al., 2015) (followed by learning a threshold)."
    }, {
      "heading" : "5.2 Real-world data",
      "text" : "We consider five real-world multi-label datasets widely used as benchmarks (Bhatia et al., 2015a; Yu et al., 2014).\n1. CAL500: a music dataset with 400 training and 100 test instances, L = 174, d = 68,\n2. Corel5k: an image dataset with 4500 training and 500 test instances, L = 374, d = 499,\n3. Bibtex: a text dataset with 4,880 training and 2,515 test instances, L = 159, d = 1, 836,\n4. Compphys dataset with 161 training and 40 test instances, L = 208, d = 33, 284, and\n5. Autofood dataset with 4,880 training and 2,515 test instances, L = 162, d = 1, 836.\nnL\nwas fixed to 20% for training. The rank of W was set to 0.4L for Algorithm 1. We observe that the proposed algorithm which captures label correlations performs better consistently across datasets.\nWe set the rank k of W to 0.4L for all the datasets in our method, and set |Ω| nL\n= 20% to train the models in each method. The results are presented in Table 1. We observe that the proposed method is competitive in all the datasets, and achieves better micro-F1 and accuracy values, with a small value of rank 0.4L. We note that the label matrices of most of the datasets are very sparse (for instance, less than 8.5% of the test data are positive labels in Autofood), which explains high accuracy and low F1 values. The learned model is much more compact than that of (Koyejo et al., 2015) (k(d+L) vs dL parameters). While our bounds in theory hold for the case L ≥ d (Theorem 3), many of the datasets considered here have d ≥ L and yet the performance is competitive."
    }, {
      "heading" : "6. Conclusions",
      "text" : "We presented a framework for optimizing general performance metrics applicable to multilabel as well as collaborative filtering settings. Our work complements recent results in this direction: on the theoretical front, we derive strong regret bounds for practically used metrics like F -measure, and on the algorithmic front, we provide simple and efficient procedure that works well in practice."
    }, {
      "heading" : "Appendix A. Proofs",
      "text" : ""
    }, {
      "heading" : "A.1 Proof of Theorem 1",
      "text" : "Proof technique is based on (Kotłowski and Dembczyński, 2015), where they derive similar bound in the binary classification setting. We first relate the Ψ-regret to weighted 0-1 loss regret. Define the α-weighted 0-1 loss ℓα : R× R → [0, 1] as:\nℓα(ŷ, y) = α[[y = 0]][[ŷ = 1]] + (1− α)[[y = 1]][[ŷ = 0]],\nLet Ŷ = f(X) for some function f . The ℓα-risk of f with respect to the underlying distribution over X,Y and Ω is defined as:\nRiskα(Ŷ) = E[ℓα(Ŷij ,Yij)] = αFP(Ŷ,Y) + (1− α)FN(Ŷ,Y).\nDefine the Bayes optimal corresponding to the above risk: f∗α = argminf Riskα(f(X),Y). Let Risk∗α := f ∗ α(X). The ℓα-regret of f is defined as:\nRegα(f(X)) := Riskα(f(X))−Risk∗α.\nLemma 2. Let Ψ be a linear-fractional performance metric as defined in (3), (4) or (5). Then for α ∈ (0, 1) defined as:\nα = Ψ∗c2 − c1\nΨ∗c2 − c1 +Ψ∗d2 − d1 , (9)\nwhere c1, d1, c2, d2 are constants that depend on Ψ, there exists some constant C > 0 such that, for any f :\nΨ∗ −Ψ(f(X),Y) ≤ C(Riskα(f(X))− Risk∗α). (10)\nLet ℓ : {0, 1} × R → R+ be a λ-strongly proper composite loss (Reid and Williamson, 2010), such as the squared loss or the logistic. Given real-valued predictions Z ∈ Rn×L, we now argue that there exists a thresholding Thrθ∗(Z) ∈ {0, 1}n×L such that Riskα(Thrθ∗(Z),Y) is bounded by the ℓ-regret of a strongly proper loss ℓ (where Thr operator is defined as in Step 2 of Algorithm 1).\nLemma 3. Let ℓ be a λ-strongly proper loss function, and α be defined as in (9). Then, there exists θ∗ s.t.\nRegα(Thrθ∗(Z)) ≤ √ 2\nλ\n√ Regℓ(Z) .\nFinally, we show that estimating θ̂ from training samples (Step 3 of Algorithm 1) is sufficient for bounding the Ψ-regret.\nLemma 4. We have: max\nθ Ψ(Thrθ(Z),Y) ≥ Ψ(Thrθ∗(Z),Y),\nand\nmax θ Ψ(Thrθ(ZΩ),YΩ) ≥ max θ\nΨ(Thrθ(Z),Y)−O (\n1√ |Ω|\n) .\nThe proof of the Theorem is complete by chaining the above three Lemmas.\nRemark 7. When Ψ∗ is known (in the noise-free or realizable setting, Ψ∗ is the maximum possible value of Ψ), we can get a closed form for θ∗, which is θ∗ = ξ(α) where ξ is the link function corresponding to the proper loss ℓ."
    }, {
      "heading" : "A.1.1 Proof of Lemma 2",
      "text" : "Let Ŷ = f(X). Consider the metric Ψ from family (3) for the moment. Define A(Ŷ) = a0+a11TP+a01FP+a10FN+a00TN := c1FP+d1FN+e1 and B(Ŷ) = b0+b11TP+b01FP+ b10FN+ b00TN := c2FP + d2FN+ e2 (for constants c1, c2, d1, d2, e1, e2 suitably defined), so that Ψ(Ŷ,Y) = A(Ŷ)/B(Ŷ). Let f∗ denote the Bayes optimal attaining Ψ∗ = A∗/B∗. We have:\nΨ∗ −Ψ(Ŷ,Y) = Ψ ∗B(Ŷ)−A(Ŷ)\nB(Ŷ)\n= Ψ∗B(Ŷ)−A(Ŷ)− (Ψ∗B∗ −A∗)\nB(Ŷ)\n= Ψ∗(B(Ŷ)−B∗)− (A(Ŷ)−A∗)\nB(Ŷ)\n= (Ψ∗c2 − c1)(FP(Ŷ,Y)− FP(f∗(X),Y)) + (Ψ∗d2 − d1)(FN(Ŷ,Y)− FN(f∗(X),Y))\nB(Ŷ)\n≤ (Ψ ∗c2 − c1)(FP(Ŷ,Y)− FP(f∗(X),Y)) + (Ψ∗d2 − d1)(FN(Ŷ,Y)− FN(f∗(X),Y))\nγ\n= C ( Riskα(Ŷ,Y)− Riskα(f∗(X),Y) ) .\nAssuming (Ψ∗c2 − c1) ≥ 0 and (Ψ∗d2 − d1) ≥ 0, the last equality follows by defining:\nα = Ψ∗c2 − c1\nΨ∗c2 − c1 +Ψ∗d2 − d1 . (11)\nand C = Ψ ∗c2−c1+Ψ∗d2−d1\nγ . The statement of the lemma follows. When Ψ is a metric\nfrom family (4), we can apply Proposition 1 of (Koyejo et al., 2015) to see that TPi = TP, FPi = FP and so on (as the expectations are defined wrt TPij ,FPij), which yields Ψ\n∗ is identical as in the micro-averaging case. So, the same regret bound applies as shown below: Define Ai = a0+a11TPi+a01FPi+a10FNi+a00TNi = c1FPi+d1FNi+ e1 and Bi similarly.\nAs before, let Ψ∗ = A∗/B∗. So when Ψ is of the form (4),\nΨ∗ −Ψ(Ŷ,Y) = 1 n\nn∑\ni=1\nΨ∗Bi(Ŷ)−Ai(Ŷ) Bi(Ŷ)\n= 1\nn\nn∑\ni=1\nΨ∗Bi(Ŷ)−Ai(Ŷ)− (Ψ∗B∗ −A∗) Bi(Ŷ)\n= 1\nn\nn∑\ni=1\nΨ∗(Bi(Ŷ)−B∗)− (Ai(Ŷ)−A∗) Bi(Ŷ)\n= 1\nn\nn∑\ni=1\n(Ψ∗c2 − c1)(FPi(Ŷ,Y)− FP(f∗(X),Y)) + (Ψ∗d2 − d1)(FNi(Ŷ,Y)− FN(f∗(X),Y)) Bi(Ŷ)\n= 1\nn\nn∑\ni=1\n(Ψ∗c2 − c1)(FP(Ŷ,Y)− FP(f∗(X),Y)) + (Ψ∗d2 − d1)(FN(Ŷ,Y)− FN(f∗(X),Y)) Bi(Ŷ)\n≤ (Ψ ∗c2 − c1)(FP(Ŷ,Y)− FP(f∗(X),Y)) + (Ψ∗d2 − d1)(FN(Ŷ,Y)− FN(f∗(X),Y))\nγ\n= C ( Riskα(Ŷ,Y)− Riskα(f∗(X),Y) ) .\nwhich is identical to the bound for family (3). It is easy to see that (5) also admits the above bound. Therefore, relation (10) holds for all definitions of Ψ, with the same α."
    }, {
      "heading" : "A.1.2 Proof of Lemma 3",
      "text" : "Let Y, Ŷ ∈ {0, 1}n×L. Note that for any ℓ, Riskℓ(f) is defined as:\nRiskℓ(f) = E[ℓ(Ŷij,Yij)] = EX∼Pn X E(i,j)∼πEYij∼P(.|xi)ℓ(Ŷij ,Yij),\nwhere π denotes the sampling distribution over (i, j) pairs. Fix instance i and label j. Let ηij denote the conditional probability of label j of instance i being 1, i.e. ηij = P(Yij = 1|xi). For convenience, denote ηij simply by η. Given η ∈ [0, 1], and ŷ ∈ {0, 1}, consider the conditional ℓα-risk of ŷ:\nLα(η, ŷ) = α(1 − η)[[ŷ = 1]] + (1− α)η[[ŷ = 0]],\nand the corresponding conditional ℓα regret of ŷ:\nRegLα(η, ŷ) = Lα(η, ŷ)−min ŷ Lα(η, ŷ),\nwhere we have: argminŷ Lα(η, ŷ) = [[η − α]]. More generally, for a loss ℓ, and a number ẑ, we have:\nLℓ(η, ẑ) = ℓ(ẑ, 1)η + ℓ(ẑ, 0)(1 − η),\nand\nRegLℓ (η, ẑ) = Lℓ(η, ẑ)−min ẑ Lℓ(η, ẑ).\nNow, observe that:\nRiskα(Ŷ,Y) = EX∼Pn X E(i,j)∼πLα(ηij , Ŷij),\nand\nRegα(Ŷ,Y) = EX∼PnXE(i,j)∼πReg L α(ηij , Ŷij),\nwhere the last equality follows from the fact that the Bayes optimal f∗α of the ℓα-risk minimizes the conditional Lα(ηij , .) risk for each (i, j). Let Z = f(X) ∈ Rn×L denote real-valued predictions obtained using some function f . Using the same arguments as by Kotłowski and Dembczyński (2015), we can show that, by setting threshold θ∗ = ξ(α), where ξ is the monotonic link function corresponding to λ-strongly proper loss ℓ, and α is defined as in (9), the conditional ℓα regret of Ŷij = [[Zij ≥ θ∗]] for a fixed (i, j) can be bounded as:\nRegLα(ηij , Ŷij) ≤ √ 2\nλ\n√ RegLℓ (ηij ,Zij),\nTaking expectation wrt sampling distribution π and the distribution over instances Pn X on both the sides of the above inequality, and applying Jensen’s inequality, the statement of the Lemma follows."
    }, {
      "heading" : "A.1.3 Proof of Lemma 4",
      "text" : "The first part of the lemma is trivially true. For the second part, we can apply the same arguments as in Lemma 9 of Koyejo et al. (2014)."
    }, {
      "heading" : "A.2 Proof of Theorem 2",
      "text" : "The following theorem bounds the error of the estimator Ŵ ∈ Rn×L in this model, via the result by Lafond (2015).\nTheorem 5 ( Lafond (2015)). Assume π is uniform, and consider the 1-bit matrix completion sampling model (2). Let Ŵ be the solution to the trace-norm regularized optimization problem (6) using logistic loss for ℓ (with input X assumed to be identity matrix of size n), number of observations |Ω| ≥ log(n+L)min(n,L)max(c′γ log2(c′′γ √ min(n,L), 1/9), and\nsetting the regularization parameter λ = 2cγ √ 2 log(n+L) min(n,L)|Ω| . Then, with probability at least 1− 3(n + L)−1, the following holds:\n‖Ŵ − W∗‖2F nL\n≤ C̃max ( max(n,L) rank(W∗) log(n+ L)\n|Ω|\n( σ2γ + 1 ) , γ2\nµ\n√ log(n+ L)\n|Ω|\n) ,\nwhere C̃, cγ , c ′ γ , c ′′ γ , σγ are numerical constants.\nThe above theorem can be extended to general distributions π satisfying Assumption 2. See Lafond (2015) for more details. Now, we use the fact that ℓ is 1-Lipschitz (say, by choosing logistic loss), and bound E[ℓ(Ŵij ,Yij) − ℓ(W∗ij ,Yij)] ≤ 1nL ∑ ij |Ŵij − W∗ij|.\nObserving that ‖Ŵ−W∗‖1 ≤ √ nL‖Ŵ−W∗‖F , and combining with the bound in Theorem 5, the proof is complete."
    }, {
      "heading" : "A.3 Weakness of using Lafond (2015) for Multi-label Learning",
      "text" : "In the multi-label learning model (1), one could hope to directly apply the analysis of Lafond (2015) for recovering XW∗ ∈ Rn×L, and in turn, W∗ ∈ Rd×L. In lieu of problem (6), we would then solve the optimization problem in Lafond (2015):\nŴ = arg min W:‖XW‖∞≤γ\n1 |Ω| ∑\n(i,j)∈Ω\nℓ(〈xi,wj〉,Yij) + λ‖XW‖∗ (12)\nNote that the only difference is how the trace-norm regularization is performed: ‖XW‖∗ versus our proposed ‖W‖∗ in Algorithm 1. The following corollary of Theorem 5 provides a bound for the recovery error of Ŵ.\nCorollary 2. Assume 1, π is uniform, and consider the sampling model (1). Let Ŵ be the solution to the trace-norm regularized optimization problem (12) using logistic loss for ℓ, number of observations |Ω| ≥ log(n + L)min(n,L)max(c′γ log2(c′′γ √ min(n,L), 1/9), and\nsetting the regularization parameter λ = 2cγ √ 2 log(n+L) min(n,L)|Ω| . Then, with probability at least 1− 3(n + L)−1, the following holds:\n‖Ŵ − W∗‖2F dL ≤ C̃ d max\n( max(n,L) rank(W∗) log(n+ L)\n|Ω|\n( σ2γ + 1 ) , γ2\nµ\n√ log(n+ L)\n|Ω|\n) ,\nwhere C̃, cγ , c ′ γ , c ′′ γ , σγ are numerical constants.\nWhen n ≥ L and |Ω| = O(n), which is quite common in multi-label scenario, the above bound suggests that Ŵ from (12) is not even a consistent estimator, even when π is uniform."
    }, {
      "heading" : "A.4 Proof of Theorem 3",
      "text" : "The statement is a corollary of the more general Theorem 8, proved in Appendix B. We can compute the constants for the logistic loss as: σ̄γ ≤ 1 and σγ ≥ (1+e γ)2 e−γ , over the domain [−γ, γ]."
    }, {
      "heading" : "A.5 Proof of Theorem 4",
      "text" : "The following result by (Hsieh et al., 2015) gives recovery bound for the resulting estimator Ŵ, as described in the text (Section 4.2.3).\nTheorem 6 ((Hsieh et al., 2015)). With probability at least 1− 2(n + L)−1,\n‖Ŵ − W∗‖2F nL\n≤ 6 √\nlog(n+ L)√ nL(1− ρ) + 2C . t\n√ n+ √ L (1− ρ)nL,\nwhere C is absolute constant and ‖W∗‖∗ ≤ t. The proof is complete by using the same argument for 1-Lipschitz ℓ as in the proof of Theorem 2."
    }, {
      "heading" : "Appendix B. Sampling from Exponential Distribution",
      "text" : "We now consider the generalized matrix completion problem when the values are sampled iid from an exponential distribution parameterized by the input features x ∈ Rd. This setting extends that of Lafond (2015). Let yij ∈ R denote a random sample corresponding to the user i and label j, which is distributed as:\nyij|xi,wj ∼ exph,G(xi,wj) := h(yij) exp ( 〈xi,wj〉yij −G(〈xi,wj〉) ) . (13)\nwhere 〈xi,wj〉, i = 1, 2, . . . , n and j = 1, 2, . . . , L are the canonical parameters, h and G are the base measure and log-partition functions associated with this canonical representation.\nLet W∗ ∈ Rd×L denote the ground-truth parameter matrix with wj’s as columns. Similarly, let Y ∈ Rn×L (with entries yij) denote a random sample from XW∗. As in the standard matrix completion setting, we only observe values of Y corresponding to a set of indices Ω sampled iid from a fixed distribution.\nNotation. With a slight abuse, we will continue to use 〈., .〉 when the arguments are matrices, instead of the trace operator, i.e. for matrices A and B of appropriate dimensions,\n〈A,B〉 := trace(ATB). Let ‖A‖∞ = maxij |Aij |, ‖A‖F = √∑ ij A 2 ij , ‖A‖∗ denote the trace norm (sum of singular values of A), σmax(A) = ‖A‖2 denote the operator norm (maximum singular value of A), and σmin(A) denote the smallest singular value."
    }, {
      "heading" : "Maximum Log-likelihood Estimator.",
      "text" : "We consider the negative log-likelihood of the observations, given by:\nΦY (X,W) = − 1 |Ω| ∑\n(i,j)∈|Ω|\nyij〈xi,wj〉 −G(〈xi,wj〉).\nConstrained ML estimator is obtained as:\nŴ := arg min W:‖XW‖∞≤γ\nΦλY (X,W) := ΦY (X,W) + λ‖W‖∗ (14)\nAssumption 3. 1. The function G(x) is twice differentiable and strongly convex on [−γ, γ], such that there exists constants σ̄γ > 0 and σγ > 0 satisfying:\nσ2γ ≤ G′′(x) ≤ σ̄2γ ,\nfor any x ∈ [−γ, γ].\n2. There exists a constant δγ > 0 such that for all x ∈ [−γ, γ] and y ∼ exph,G(x):\nEy∼P(.|x)\n[ exp ( |y −G′(x)| δγ )] ≤ e.\nDefinition 1. Given convex function G(x) define the Bregman divergence between two scalars x, x′ ∈ R as:\ndG(x, x ′) = G(x)−G(x′)−G′(x′)(x− x′). (15)\nRemark 8. Under Assumption 3.1, for any x, x′ ∈ [−γ, γ], the Bregman divergence G satisfies:\nσ2γ(x− x′)2 ≤ 2dG(x, x′) ≤ σ̄2γ(x− x′)2. (16)\nLet Eij ∈ Rn×L denote the indicator matrix with zeros everywhere except at (i, j) where it is 1. For (ǫij) |Ω| ij=1 a Rademacher sequence independent from (Ω, YΩ), define:\nΣR := 1 |Ω| ∑\n(i,j)∈Ω\nǫijEij. (17)\nTheorem 7. Assume 3.1, 2.1, ‖XW∗‖∞ ≤ γ, σmin(X) > 0 and 2‖XT∇ΦY(X,W∗)‖2 ≤ λ. Then, with probability at least 1− 2(n+ L)−1, the following holds:\n‖Ŵ − W∗‖2F dL ≤ Cµ 2n\nσ2min(X) . d max\n( L rank(W∗) ( λ2\nσ4γ\nn\nσ2min(X) +d\n( E‖ΣR‖2 )2 ) , γ2\nµ\n√ log(n+ L)\n|Ω|\n) ,\nwhere C is a numerical constant and ΣR is defined as in (17).\nProof. The proof closely follows that of Theorem 5 of Lafond (2015). As Ŵ is the minimizer of (14), we have: ΦλY (X, Ŵ)− ΦλY (X,W∗) ≤ 0 It follows that:\nλ(‖Ŵ‖∗ − ‖W ∗‖∗) + 1 |Ω| ∑\n(i,j)∈Ω\nyij〈xi,w∗j − ŵj〉+G(〈xi, ŵj〉)−G(〈xi,w∗j 〉) ≤ 0\nUsing the fact that the gradient matrix:\n∇ΦY (X,W∗) := ∇XW∗ΦY (X,W∗) = − 1 |Ω| ∑\n(i,j)∈Ω\n( yij −G′(〈xi,w∗j 〉)Eij (18)\n(where Eij are the indicator matrices defined earlier) in the above inequality, we have:\nλ(‖Ŵ‖∗ − ‖W∗‖∗) + 〈 ∇ΦY (X,W∗),X(W∗ − Ŵ) 〉 +\n1 |Ω| ∑\n(i,j)∈Ω\nG(〈xi, ŵj〉)−G(〈xi,w∗j 〉)−G′(〈xi,w∗j 〉)(〈xi, ŵj −w∗j 〉) ≤ 0.\nUsing the definition of the divergence (15), and the fact that 〈 ∇ΦY (X,W∗),X(W∗−Ŵ) 〉 = 〈 X T∇ΦY (X,W∗),W∗ − Ŵ 〉 it follows that:\nDΩG(XŴ,XW ∗) :=\n1 |Ω| ∑\n(i,j)∈Ω\ndG(〈xi, ŵj〉, 〈xi,w∗j 〉) ≤ λ(‖W∗‖∗−Ŵ‖∗)− 〈 X T∇ΦY (X,W∗),W∗−Ŵ 〉\nThe first term in the RHS of above inequality can be bounded first using Lemma 16-(iii) of Lafond (2015). The second term can be bounded using the trace inequality (that uses the duality between ‖.‖∗ and ‖.‖2) and the assumption on λ stated in the Theorem. We get:\nDΩG(XŴ,XW ∗) ≤ λ(‖PW∗(Ŵ − W∗)‖∗ +\n1 2 ‖Ŵ − W∗‖∗).\nTo bound the first term in the above equation, we can apply Lemma 16-(ii) of Lafond (2015). Lemma 5 gives a bound for the second term. Together we have:\nDΩG(XŴ,XW ∗) ≤ 3λ √ 2 rank(W∗)‖Ŵ − W∗‖F . (19)\nBy strong convexity of G (Assumption 3.1), we have:\n∆2Y(XŴ,XW ∗) :=\n1 |Ω| ∑\n(i,j)∈Ω\n(〈xi, ŵj −w∗j 〉)2 ≤ 2\nσ2γ DΩG(XŴ,XW ∗). (20)\nNow, we will get a lower bound for∆2Y (XŴ,XW ∗). To do so, let us define β := 8eγ2\n√ log(n+ L)/|Ω|\nand distinguish the two following cases:\nCase 1 If E[(〈xi, ŵj −w∗j 〉)2] ≤ β, where E is defined wrt the sampling distribution as in Assumption 2, then Lemma 18 of Lafond (2015) yields,\n‖XŴ − XW∗‖2F nL ≤ µβ. (21)\nCase 2 If E[(〈xi, ŵj − w∗j 〉)2] > β, consider Ŵ ∈ C(β, 32µdL rank(W∗)), where C(., .) is defined as:\nC(β, r) = { W ∈ Rd×L | ‖W∗ − Ŵ‖∗ ≤ √ rE[∆2 Y (XW,XW∗)];E[∆2 Y (XW,XW∗)] > β } . (22)\nThen, from Lemma 19 of Lafond (2015), it holds with probability at least 1 − 2(n + L)−1 that\n∆2Y(XŴ,XW ∗) ≥ 1\n2 E[∆2Y(XŴ,XW ∗)]− 512e(E[‖ΣR‖2)2µdL rank(W∗). (23)\nCombining the above inequality with (20), (19) and Lemma 18 of Lafond (2015) yields:\n‖XŴ − XW∗‖2F 2µnL − 512e(E[‖ΣR‖2)2µdL rank(W∗) ≤ 6λ\nσ2γ\n√ 2 rank(W∗)‖Ŵ − W∗‖F .\nWe can use Lemma (6) to bound the first term from below. Applying the identity ab ≤ (a2+ b2)/4, multiplying both sides of the inequality by 1/d, rearranging and combining with (21), the proof is complete.\nTheorem 8. Assume 1, 2, 3. Choose, n ≥ C ′ . d, L ≥ d, |Ω| ≥ L+ d and λ = 2cσ̄γ√ |Ω| . Then, with probability at least 1− 3(n+ L)−1 − 2(d+ L)−1, the following holds:\n‖Ŵ − W∗‖2F dL ≤ C2µ 2 d max\n( L rank(W∗) log(n+ L)\n|Ω|\n( σ̄2γ σ4γ + 1 ) , γ2 µ\n√ log(n+ L)\n|Ω|\n) ,\nwhere c, C ′, C2 are numerical constants.\nProof. It suffices to show 2‖XT∇Φ(X,W∗)‖2 ≤ λ for chosen λ in the statement of the Theorem and a suitable bound for E‖ΣR‖2 (the result would then follow by applying Theorem 7). The latter term can be readily bounded applying the corresponding arguments in the proof of Theorem 6 of Lafond (2015), which yields:\nE‖ΣR‖2 ≤ c∗ √ 2e log(n+ L)\n|Ω|\n( ν\nmin(n,L)\n) , (24)\nwhere we use the fact that ∑L\nl=1 πk,l = ν min(n,L) (by Assumption 2). where c ∗ is a numerical\nconstant. We can apply Lemma 1 to bound ‖XT∇Φ(X,W∗)‖2, with the λ chosen in the statement of the Theorem. The proof is complete noting that for the choice of n as in the statement of the Theorem, Lemma 7 implies σ2min(X) ≥ Cn and that for the choice of n and L as in the statement of the Theorem, dmin(n,L) ≤ 1.\nLemma 5. Let XW,XW̃ ∈ Rn×L satisfy ‖XW‖∞ ≤ γ and ‖XW̃‖∞ ≤ γ. Assume: 2‖XT∇ΦY(X, W̃)‖2 ≤ λ, and ΦλY (X,W) ≤ ΦλY (X, W̃). Then: (i) ‖P⊥\nW̃ (W − W̃)‖∗ ≤ 3‖PW̃(W − W̃)‖∗,\n(ii) ‖W − W̃‖∗ ≤ 4 √\n2 rank(W̃)‖W − W̃‖F . Proof. The proof closely follows that of Lemma 17 of (Lafond, 2015). By definition, we have: ΦλY (X,W)− ΦλY (X, W̃) ≤ 0 or, ΦY (X,W)− ΦY (X, W̃) ≤ λ(‖W̃ − W‖∗) ."
    }, {
      "heading" : "Writing W ∈ Rd×L as W = W̃+P⊥",
      "text" : "W̃ (W− W̃)+P W̃ (W− W̃), Lemma 16-(i) of (Lafond, 2015)\nand triangle inequality together give:\n‖W‖∗ ≥ ‖W̃‖∗ + ‖P⊥ W̃ (W − W̃)‖∗ + ‖PW̃(W − W̃)‖∗,\nOr, ΦY (X, W̃)− ΦY (X,W) ≥ λ(‖P⊥\nW̃ (W − W̃)‖∗ + ‖PW̃(W − W̃)‖∗) . (25)\nNote that by convexity of ΦY :\nΦY (X, W̃)− ΦY (X,W) ≤ 〈 ∇ΦY (X, W̃),XW̃ − XW 〉 = 〈 X T∇ΦY (X, W̃), W̃ − W 〉 ,\nBy trace inequality, we have:\nΦY (X, W̃)− ΦY (X,W) ≤ ‖XT∇ΦY (X, W̃)‖2‖W̃ − W‖∗ ≤ λ\n2 ‖W̃ − W‖∗\nwhere the last inequality is by assumption, ‖XT∇ΦY (X, W̃)‖2 ≤ λ/2. The last term in the above inequality can be bounded by λ2 ( ‖P⊥ W̃ (W − W̃)‖∗ + ‖PW̃(W − W̃)‖∗ ) . Together with\n(25), we get the first part of the Lemma. We can now conclude the proof of part two using identical arguments as in Lemma 17 of (Lafond, 2015).\nLemma 6. Let σmin(X) denote the smallest singular value of X. Then for any W, W̃, Then:\n‖XW − XW̃‖2F ≥ σ2min(X)‖W − W̃‖2F .\nProof. Observe that ‖X(W−W̃)‖2F = trace ( X(W−W̃)(W−W̃)TXT ) = trace ( (W−W̃)(W−\nW̃)TXTX ) ≥ σmin(XTX)trace ( (W − W̃)(W − W̃)T ) = σmin(X) 2‖W − W̃‖2F .\nLemma 7. Let X ∈ Rn×d be a matrix with rows sampled from sub-Gaussian distribution satisfying Assumption 1. Furthermore, choose:\nn ≥ C ′d .\nThen, with probability at least 1− 2e−d, each of the following statements is true:\nσmax(X T X) ≤ C̄n,\nσmin(X T X) ≥ Cn,\nwhere C ′, C̄ and C are absolute constants that depend only on the parameters K and Σ of the sub-Gaussian distribution.\nProof. Using Lemma 16 of Bhatia et al. (2015b), we have for any δ > 0, with probability at least 1− δ, each of the following statements hold:\nσmax(X T X) ≤ σmax(Σ) . n+ CK √ dn + t √ n,\nσmin(X T X) ≥ σmin(Σ) . n− CK √ dn− t√n,\nwhere t = √\n1 cK log 2 δ , and cK , CK are absolute constants that depend only on the sub-\nGaussian norm K of the distribution PX . Now, choosing δ = 2e −d or log(2/δ) = d, we have:\nCK √ dn+ t √ n = CK √ dn +\n√ 1\ncK dn =\n√ dn ( CK + √ 1\nck\n) .\nFor ease, define C ′K := CK+ √ 1 ck . Now, choosing n ≥ ( C′K σmin(Σ) )2 . d, and substituting above we have:\nCK √ dn+ t √ n ≤ 1\n2 σmin(Σ) .n.\nTherefore:\nσmax(X T X) ≤ ( σmax(Σ) + 1\n2 σmin(Σ)\n) n,\nσmin(X T X) ≥ 1\n2 σmin(Σ) . n.\nThe proof is complete."
    }, {
      "heading" : "Proof of Lemma 1",
      "text" : "Let H denote the matrix with hij = yij −G′(〈xi,w∗j 〉). Let hi denote the ith row of H. Let PΩ(H) denote the projection of H onto the observed indices Ω. Let Ωi denote the observed indices in row i of Y. For a vector v, let vΩi denote its projection onto the observed indices Ωi.\nFix u ∈ Rd and v ∈ RL. Define ai = xTi u and bi = 〈vΩi ,hiΩi〉. We have:\n1\n|Ω|u T X TPΩ(H)v =\n1 |Ω| n∑\ni=1\naibi\n= 1 |Ω| n∑\ni=1\n‖vΩi‖2 . ai bi\n‖vΩi‖2 .\nConsider bi = ∑\n(i,j)∈Ω vjhij . Note that hij ’s are sub-Gaussian random variables with subGaussian norm α. Using Lemma 5.9 of Vershynin (2010), we have bi is sub-Gaussian with norm ‖vΩi‖2α. In turn, this implies, bi‖vΩi‖2 is sub-Gaussian with sub-Gaussian norm α. Therefore, aibi‖vΩi‖2 is α-subexponential. Applying Proposition 5.16 of Vershynin (2010), we have, with probability at least 1− δ,\n1 |Ω| n∑\ni=1\n‖vΩi‖2 . ai bi ‖vΩi‖2 ≤ c . α|Ω|\n(√√√√ n∑\ni=1\n‖vΩi‖2 √ log 2\nδ +max i∈[n] ‖vΩi‖2 log\n2\nδ\n) .\nfor some absolute constant c. Noting that: ‖v‖2 = 1 and for any j ∈ [L], |{i : (i, j) ∈ Ω}| ≤ c′.|Ω| L , we have, with probability at least 1− δ,\n1 |Ω| n∑\ni=1\n‖vΩi‖2 . ai bi ‖vΩi‖2 ≤ c . α|Ω| (√ c′.|Ω| L √ log 2 δ + log 2 δ ) .\nWe conclude the proof by a covering argument: Taking a union bound over ǫ-ball of u and v, we have, with probability at least 1− (d+ L)−1:\n∥∥XT∇ΦY (X,W∗) ∥∥ 2 ≤ c . α|Ω| (√ c′.|Ω| L √ d+ L+ d+ L ) .\nAssuming d ≤ L and |Ω| ≥ (L+ d), the proof is complete."
    } ],
    "references" : [ {
      "title" : "Surrogate regret bounds for bipartite ranking via strongly proper losses",
      "author" : [ "Shivani Agarwal" ],
      "venue" : "The Journal of Machine Learning Research,",
      "citeRegEx" : "Agarwal.,? \\Q2014\\E",
      "shortCiteRegEx" : "Agarwal.",
      "year" : 2014
    }, {
      "title" : "Sparse local embeddings for extreme multi-label classification",
      "author" : [ "Kush Bhatia", "Himanshu Jain", "Purushottam Kar", "Manik Varma", "Prateek Jain" ],
      "venue" : "In Advances in Neural Information Processing Systems,",
      "citeRegEx" : "Bhatia et al\\.,? \\Q2015\\E",
      "shortCiteRegEx" : "Bhatia et al\\.",
      "year" : 2015
    }, {
      "title" : "Robust regression via hard thresholding",
      "author" : [ "Kush Bhatia", "Prateek Jain", "Purushottam Kar" ],
      "venue" : "In Advances in Neural Information Processing Systems,",
      "citeRegEx" : "Bhatia et al\\.,? \\Q2015\\E",
      "shortCiteRegEx" : "Bhatia et al\\.",
      "year" : 2015
    }, {
      "title" : "A max-norm constrained minimization approach to 1-bit matrix completion",
      "author" : [ "Tony Cai", "Wen-Xin Zhou" ],
      "venue" : "The Journal of Machine Learning Research,",
      "citeRegEx" : "Cai and Zhou.,? \\Q2013\\E",
      "shortCiteRegEx" : "Cai and Zhou.",
      "year" : 2013
    }, {
      "title" : "1-bit matrix completion",
      "author" : [ "Mark A Davenport", "Yaniv Plan", "Ewout van den Berg", "Mary Wootters" ],
      "venue" : "Information and Inference,",
      "citeRegEx" : "Davenport et al\\.,? \\Q2014\\E",
      "shortCiteRegEx" : "Davenport et al\\.",
      "year" : 2014
    }, {
      "title" : "Consistent multilabel ranking through univariate losses",
      "author" : [ "Krzysztof Dembczynski", "Wojciech Kotlowski", "Eyke Hüllermeier" ],
      "venue" : "In Proceedings of the 29th International Conference on Machine Learning,",
      "citeRegEx" : "Dembczynski et al\\.,? \\Q2012\\E",
      "shortCiteRegEx" : "Dembczynski et al\\.",
      "year" : 2012
    }, {
      "title" : "On the consistency of multi-label learning",
      "author" : [ "Wei Gao", "Zhi-Hua Zhou" ],
      "venue" : "Artificial Intelligence,",
      "citeRegEx" : "Gao and Zhou.,? \\Q2013\\E",
      "shortCiteRegEx" : "Gao and Zhou.",
      "year" : 2013
    }, {
      "title" : "Pu learning for matrix completion",
      "author" : [ "Cho-jui Hsieh", "Nagarajan Natarajan", "Inderjit Dhillon" ],
      "venue" : "In Proceedings of the 32nd International Conference on Machine Learning",
      "citeRegEx" : "Hsieh et al\\.,? \\Q2015\\E",
      "shortCiteRegEx" : "Hsieh et al\\.",
      "year" : 2015
    }, {
      "title" : "Provable inductive matrix completion",
      "author" : [ "Prateek Jain", "Inderjit S Dhillon" ],
      "venue" : "arXiv preprint arXiv:1306.0626,",
      "citeRegEx" : "Jain and Dhillon.,? \\Q2013\\E",
      "shortCiteRegEx" : "Jain and Dhillon.",
      "year" : 2013
    }, {
      "title" : "Matrix factorization techniques for recommender systems",
      "author" : [ "Yehuda Koren", "Robert Bell", "Chris Volinsky" ],
      "venue" : null,
      "citeRegEx" : "Koren et al\\.,? \\Q2009\\E",
      "shortCiteRegEx" : "Koren et al\\.",
      "year" : 2009
    }, {
      "title" : "Surrogate regret bounds for generalized classification performance metrics",
      "author" : [ "Wojciech Kotłowski", "Krzysztof Dembczyński" ],
      "venue" : "arXiv preprint arXiv:1504.07272,",
      "citeRegEx" : "Kotłowski and Dembczyński.,? \\Q2015\\E",
      "shortCiteRegEx" : "Kotłowski and Dembczyński.",
      "year" : 2015
    }, {
      "title" : "Consistent binary classification with generalized performance metrics",
      "author" : [ "Oluwasanmi O Koyejo", "Nagarajan Natarajan", "Pradeep K Ravikumar", "Inderjit S Dhillon" ],
      "venue" : "In Advances in Neural Information Processing Systems",
      "citeRegEx" : "Koyejo et al\\.,? \\Q2014\\E",
      "shortCiteRegEx" : "Koyejo et al\\.",
      "year" : 2014
    }, {
      "title" : "Consistent multilabel classification",
      "author" : [ "Oluwasanmi O Koyejo", "Nagarajan Natarajan", "Pradeep K Ravikumar", "Inderjit S Dhillon" ],
      "venue" : "In Advances in Neural Information Processing Systems,",
      "citeRegEx" : "Koyejo et al\\.,? \\Q2015\\E",
      "shortCiteRegEx" : "Koyejo et al\\.",
      "year" : 2015
    }, {
      "title" : "Low rank matrix completion with exponential family noise",
      "author" : [ "Jean Lafond" ],
      "venue" : "arXiv preprint arXiv:1502.06919,",
      "citeRegEx" : "Lafond.,? \\Q2015\\E",
      "shortCiteRegEx" : "Lafond.",
      "year" : 2015
    }, {
      "title" : "Fastxml: a fast, accurate and stable tree-classifier for extreme multi-label learning",
      "author" : [ "Yashoteja Prabhu", "Manik Varma" ],
      "venue" : "In Proceedings of the 20th ACM SIGKDD international conference on Knowledge discovery and data mining,",
      "citeRegEx" : "Prabhu and Varma.,? \\Q2014\\E",
      "shortCiteRegEx" : "Prabhu and Varma.",
      "year" : 2014
    }, {
      "title" : "Composite binary losses",
      "author" : [ "Mark D Reid", "Robert C Williamson" ],
      "venue" : "The Journal of Machine Learning Research,",
      "citeRegEx" : "Reid and Williamson.,? \\Q2010\\E",
      "shortCiteRegEx" : "Reid and Williamson.",
      "year" : 2010
    }, {
      "title" : "Introduction to the non-asymptotic analysis of random matrices",
      "author" : [ "Roman Vershynin" ],
      "venue" : "arXiv preprint arXiv:1011.3027,",
      "citeRegEx" : "Vershynin.,? \\Q2010\\E",
      "shortCiteRegEx" : "Vershynin.",
      "year" : 2010
    }, {
      "title" : "Large-scale multilabel learning with missing labels",
      "author" : [ "Hsiang-Fu Yu", "Prateek Jain", "Purushottam Kar", "Inderjit Dhillon" ],
      "venue" : "In Proceedings of The 31st International Conference on Machine Learning,",
      "citeRegEx" : "Yu et al\\.,? \\Q2014\\E",
      "shortCiteRegEx" : "Yu et al\\.",
      "year" : 2014
    }, {
      "title" : "Ranking via robust binary classification",
      "author" : [ "Hyokun Yun", "Parameswaran Raman", "S Vishwanathan" ],
      "venue" : "In Advances in Neural Information Processing Systems,",
      "citeRegEx" : "Yun et al\\.,? \\Q2014\\E",
      "shortCiteRegEx" : "Yun et al\\.",
      "year" : 2014
    }, {
      "title" : "Efficient matrix sensing using rank-1 gaussian measurements",
      "author" : [ "Kai Zhong", "Prateek Jain", "Inderjit S. Dhillon" ],
      "venue" : "In International Conference on Algorithmic Learning Theory (ALT),",
      "citeRegEx" : "Zhong et al\\.,? \\Q2015\\E",
      "shortCiteRegEx" : "Zhong et al\\.",
      "year" : 2015
    }, {
      "title" : "λ-strongly proper composite loss (Reid and Williamson, 2010), such as the squared loss or the logistic. Given real-valued predictions Z ∈ Rn×L, we now argue that there exists a thresholding Thrθ∗(Z) ∈ {0, 1}n×L such that Riskα(Thrθ∗(Z),Y) is bounded by the l-regret of a strongly proper loss",
      "author" : [ "R × R" ],
      "venue" : null,
      "citeRegEx" : "→,? \\Q2010\\E",
      "shortCiteRegEx" : "→",
      "year" : 2010
    }, {
      "title" : "Sampling from Exponential Distribution We now consider the generalized matrix completion problem when the values are sampled iid from an exponential distribution parameterized by the input features x ∈ R. This setting extends that of Lafond (2015)",
      "author" : [ "Jain", "Natarajan Appendix B" ],
      "venue" : "Let yij ∈ R",
      "citeRegEx" : "Jain and B.,? \\Q2015\\E",
      "shortCiteRegEx" : "Jain and B.",
      "year" : 2015
    }, {
      "title" : "The first term in the RHS of above inequality can be bounded first using Lemma",
      "author" : [ "Jain", "Natarajan" ],
      "venue" : null,
      "citeRegEx" : "Jain and Natarajan,? \\Q2015\\E",
      "shortCiteRegEx" : "Jain and Natarajan",
      "year" : 2015
    }, {
      "title" : "To bound the first term in the above equation, we can apply Lemma 16-(ii) of Lafond (2015). Lemma 5 gives a bound for the second term",
      "author" : [ "‖Ŵ − W" ],
      "venue" : null,
      "citeRegEx" : "W.∗..,? \\Q2015\\E",
      "shortCiteRegEx" : "W.∗..",
      "year" : 2015
    }, {
      "title" : "2015b), we have for any δ > 0, with probability at least 1− δ, each of the following statements",
      "author" : [ "Bhatia" ],
      "venue" : null,
      "citeRegEx" : "Bhatia,? \\Q2015\\E",
      "shortCiteRegEx" : "Bhatia",
      "year" : 2015
    } ],
    "referenceMentions" : [ {
      "referenceID" : 9,
      "context" : "Introduction Predicting relevant labels/items for a given data point is by now a standard task with applications in several domains like recommendation systems (Koren et al., 2009), document tagging, image tagging (Prabhu and Varma, 2014), etc.",
      "startOffset" : 160,
      "endOffset" : 180
    }, {
      "referenceID" : 14,
      "context" : ", 2009), document tagging, image tagging (Prabhu and Varma, 2014), etc.",
      "startOffset" : 41,
      "endOffset" : 65
    }, {
      "referenceID" : 7,
      "context" : "Furthermore, often the location of missing labels may not be available like in the positive-unlabeled learning setting (Hsieh et al., 2015).",
      "startOffset" : 119,
      "endOffset" : 139
    }, {
      "referenceID" : 13,
      "context" : "On the other hand, most of the existing collaborative filtering/matrix completion methods only focus on decomposable losses like RMSE, sum of logistic loss (Lafond, 2015; Yu et al., 2014), which are not effective in real-world systems with large number of labels (Prabhu and Varma, 2014).",
      "startOffset" : 156,
      "endOffset" : 187
    }, {
      "referenceID" : 17,
      "context" : "On the other hand, most of the existing collaborative filtering/matrix completion methods only focus on decomposable losses like RMSE, sum of logistic loss (Lafond, 2015; Yu et al., 2014), which are not effective in real-world systems with large number of labels (Prabhu and Varma, 2014).",
      "startOffset" : 156,
      "endOffset" : 187
    }, {
      "referenceID" : 14,
      "context" : ", 2014), which are not effective in real-world systems with large number of labels (Prabhu and Varma, 2014).",
      "startOffset" : 83,
      "endOffset" : 107
    }, {
      "referenceID" : 10,
      "context" : "Our framework is motivated by a simple observation that has been used in other contexts as well (Kotłowski and Dembczyński, 2015; Koyejo et al., 2015): for a large class of metrics Ψ, simply thresholding the class probability vector leads to bayes-optimal estimators.",
      "startOffset" : 96,
      "endOffset" : 150
    }, {
      "referenceID" : 12,
      "context" : "Our framework is motivated by a simple observation that has been used in other contexts as well (Kotłowski and Dembczyński, 2015; Koyejo et al., 2015): for a large class of metrics Ψ, simply thresholding the class probability vector leads to bayes-optimal estimators.",
      "startOffset" : 96,
      "endOffset" : 150
    }, {
      "referenceID" : 13,
      "context" : "For general multilabel setting, a direct application of existing results, such as (Lafond, 2015) leads to weak bounds.",
      "startOffset" : 82,
      "endOffset" : 96
    }, {
      "referenceID" : 8,
      "context" : "In fact, our result strictly generalizes the result by Lafond (2015), which is for general matrix completion with exponential family noise, to the general inductive matrix completion setting (Jain and Dhillon, 2013) with exponential family noise.",
      "startOffset" : 191,
      "endOffset" : 215
    }, {
      "referenceID" : 8,
      "context" : "For example, Koyejo et al. (2015) establish that for a large class of performance metrics, the optimal solution is to compute a score vector over all the labels and selecting all the labels whose score is greater than a constant.",
      "startOffset" : 13,
      "endOffset" : 34
    }, {
      "referenceID" : 8,
      "context" : "Our framework is motivated by a simple observation that has been used in other contexts as well (Kotłowski and Dembczyński, 2015; Koyejo et al., 2015): for a large class of metrics Ψ, simply thresholding the class probability vector leads to bayes-optimal estimators. Hence, the goal would be to estimate per-label class probabilities accurately. To this end, we show that by using a λ-strongly proper loss along with appropriate thresholding leads to bounded regret wrt. Ψ (Theorem 1). Note that the threshold can be learned using cross-validation over a small fraction of the training data. Moreover, λ-strong convexity of the loss function ensures that by minimizing a nuclearnorm regularized ERM (with risk measured by the selected loss function) wrt. a parameter matrix W ∈ Rd×L, we can bound the regret in Ψ by regret in estimation of the optimal W (Theorem 1); here, d is the dimensionality of the data and is equal to number of users in case of recommender system. Hence, this result allows us to focus on estimation of W in various different settings such as: a) one-bit matrix completion (Theorem 2), popularly used in recommender systems with only like/dislike information, b) one-bit matrix completion with PU learning (Theorem 4) applicable to recommender systems where only “likes\" or positive feedback is observed, and c) general multi-label learning with missing labels (Theorem 3). For one-bit matrix completion (and the related PU setting), we obtain our final regret bound by adapting existing results from Lafond (2015) and Hsieh et al.",
      "startOffset" : 97,
      "endOffset" : 1540
    }, {
      "referenceID" : 7,
      "context" : "For one-bit matrix completion (and the related PU setting), we obtain our final regret bound by adapting existing results from Lafond (2015) and Hsieh et al. (2015), respectively.",
      "startOffset" : 145,
      "endOffset" : 165
    }, {
      "referenceID" : 7,
      "context" : "For one-bit matrix completion (and the related PU setting), we obtain our final regret bound by adapting existing results from Lafond (2015) and Hsieh et al. (2015), respectively. For general multilabel setting, a direct application of existing results, such as (Lafond, 2015) leads to weak bounds. A main technical contribution of our work is to analyze the parameter estimation problem in this setting and provide tight regret bounds. In fact, our result strictly generalizes the result by Lafond (2015), which is for general matrix completion with exponential family noise, to the general inductive matrix completion setting (Jain and Dhillon, 2013) with exponential family noise.",
      "startOffset" : 145,
      "endOffset" : 506
    }, {
      "referenceID" : 7,
      "context" : "For one-bit matrix completion (and the related PU setting), we obtain our final regret bound by adapting existing results from Lafond (2015) and Hsieh et al. (2015), respectively. For general multilabel setting, a direct application of existing results, such as (Lafond, 2015) leads to weak bounds. A main technical contribution of our work is to analyze the parameter estimation problem in this setting and provide tight regret bounds. In fact, our result strictly generalizes the result by Lafond (2015), which is for general matrix completion with exponential family noise, to the general inductive matrix completion setting (Jain and Dhillon, 2013) with exponential family noise. Hence, it should have applications beyond our framework as well. Finally, we illustrate our framework and algorithms on synthetic as well as real-world datasets. Our method exhibits significant improvement over a natural extension of the method by Koyejo et al. (2015) that optimizes Ψ directly but ignores label correlations, hence does not handle missing labels in a principled manner.",
      "startOffset" : 145,
      "endOffset" : 953
    }, {
      "referenceID" : 7,
      "context" : "For one-bit matrix completion (and the related PU setting), we obtain our final regret bound by adapting existing results from Lafond (2015) and Hsieh et al. (2015), respectively. For general multilabel setting, a direct application of existing results, such as (Lafond, 2015) leads to weak bounds. A main technical contribution of our work is to analyze the parameter estimation problem in this setting and provide tight regret bounds. In fact, our result strictly generalizes the result by Lafond (2015), which is for general matrix completion with exponential family noise, to the general inductive matrix completion setting (Jain and Dhillon, 2013) with exponential family noise. Hence, it should have applications beyond our framework as well. Finally, we illustrate our framework and algorithms on synthetic as well as real-world datasets. Our method exhibits significant improvement over a natural extension of the method by Koyejo et al. (2015) that optimizes Ψ directly but ignores label correlations, hence does not handle missing labels in a principled manner. For example, our method achieves 12% higher F1-measure on a benchmark dataset than that by Koyejo et al. (2015).",
      "startOffset" : 145,
      "endOffset" : 1184
    }, {
      "referenceID" : 6,
      "context" : "Gao and Zhou (2013) study consistency and surrogate losses for",
      "startOffset" : 0,
      "endOffset" : 20
    }, {
      "referenceID" : 13,
      "context" : "Existing theoretical guarantees for 1-bit matrix completion methods used in recommender systems focus solely on RMSE or 0-1 loss (Lafond, 2015; Hsieh et al., 2015).",
      "startOffset" : 129,
      "endOffset" : 163
    }, {
      "referenceID" : 7,
      "context" : "Existing theoretical guarantees for 1-bit matrix completion methods used in recommender systems focus solely on RMSE or 0-1 loss (Lafond, 2015; Hsieh et al., 2015).",
      "startOffset" : 129,
      "endOffset" : 163
    }, {
      "referenceID" : 5,
      "context" : "Dembczynski et al. (2012) consider expected pairwise ranking loss in multilabel learning, show that the problem decomposes into independent binary problems, and provide regret bound for the same.",
      "startOffset" : 0,
      "endOffset" : 26
    }, {
      "referenceID" : 5,
      "context" : "Dembczynski et al. (2012) consider expected pairwise ranking loss in multilabel learning, show that the problem decomposes into independent binary problems, and provide regret bound for the same. Yun et al. (2014) consider the learning to rank problem, where the goal is to rank the relevant labels for a given instance.",
      "startOffset" : 0,
      "endOffset" : 214
    }, {
      "referenceID" : 17,
      "context" : "Following the low-rank inductive matrix completion model (Yu et al., 2014; Zhong et al., 2015), we let W ∗ ∈ Rd×L be the parameter matrix and gj(xi;W) = g(〈xi,w j 〉) where w∗ j is the jth column of W corresponding to the jth label, for some differentiable function g : R → [0, 1].",
      "startOffset" : 57,
      "endOffset" : 94
    }, {
      "referenceID" : 19,
      "context" : "Following the low-rank inductive matrix completion model (Yu et al., 2014; Zhong et al., 2015), we let W ∗ ∈ Rd×L be the parameter matrix and gj(xi;W) = g(〈xi,w j 〉) where w∗ j is the jth column of W corresponding to the jth label, for some differentiable function g : R → [0, 1].",
      "startOffset" : 57,
      "endOffset" : 94
    }, {
      "referenceID" : 3,
      "context" : "When we do not observe feature vectors x, as in the classical recommender system or matrix completion setting, the above model (1) reduces to the widely studied 1-bit matrix completion model (Cai and Zhou, 2013; Davenport et al., 2014):",
      "startOffset" : 191,
      "endOffset" : 235
    }, {
      "referenceID" : 4,
      "context" : "When we do not observe feature vectors x, as in the classical recommender system or matrix completion setting, the above model (1) reduces to the widely studied 1-bit matrix completion model (Cai and Zhou, 2013; Davenport et al., 2014):",
      "startOffset" : 191,
      "endOffset" : 235
    }, {
      "referenceID" : 12,
      "context" : "In this work, we consider a large family of non-decomposable metrics (Koyejo et al., 2015) that constitutes linear-fractional functions of (multi-label analogues of) true positives, false positives, false negatives and true negatives defined below.",
      "startOffset" : 69,
      "endOffset" : 90
    }, {
      "referenceID" : 11,
      "context" : "Koyejo et al. (2015) showed that the Bayes optimal Ψ∗ thresholds the conditional probability of each label j, i.",
      "startOffset" : 0,
      "endOffset" : 21
    }, {
      "referenceID" : 17,
      "context" : "In many cases, W exhibits some structure, such as low-rankness, reflecting correlation between labels (Yu et al., 2014; Zhong et al., 2015; Davenport et al., 2014).",
      "startOffset" : 102,
      "endOffset" : 163
    }, {
      "referenceID" : 19,
      "context" : "In many cases, W exhibits some structure, such as low-rankness, reflecting correlation between labels (Yu et al., 2014; Zhong et al., 2015; Davenport et al., 2014).",
      "startOffset" : 102,
      "endOffset" : 163
    }, {
      "referenceID" : 4,
      "context" : "In many cases, W exhibits some structure, such as low-rankness, reflecting correlation between labels (Yu et al., 2014; Zhong et al., 2015; Davenport et al., 2014).",
      "startOffset" : 102,
      "endOffset" : 163
    }, {
      "referenceID" : 10,
      "context" : "Koyejo et al. (2015) proposed a simple consistent plug-in estimator algorithm, which first computes conditional marginals P(yj|x) independently for each label j, and then estimates a threshold jointly to optimize Ψ.",
      "startOffset" : 0,
      "endOffset" : 21
    }, {
      "referenceID" : 4,
      "context" : ", 2015; Davenport et al., 2014). Statistically, capturing correlations via a low-rank structure could help improve the sample complexity for recovery, and computationally, it would help reduce space and time complexity of the learning procedure. Our proposed algorithm is presented in Algorithm 1. In Step 1, we solve a traceregularized minimization problem to estimate the parameter matrix W, where the function l can be any bounded loss such as the squared, the logistic or the squared Hinge loss. In particular, using the logistic loss corresponds to the maximum likelihood estimation of the sampling model (1). Yu et al. (2014) also solve essentially the same objective as (6), except for the additional bound constraint on entries of XW.",
      "startOffset" : 8,
      "endOffset" : 632
    }, {
      "referenceID" : 12,
      "context" : "The definitions in (Koyejo et al., 2015) do not include general sampling distribution π, but the results can be generalized in a straight-forward manner.",
      "startOffset" : 19,
      "endOffset" : 40
    }, {
      "referenceID" : 0,
      "context" : "1 Low l-regret implies low Ψ-regret Our first main result connects Ψ-regret to regret with respect to a strongly proper loss function l (Agarwal, 2014).",
      "startOffset" : 136,
      "endOffset" : 151
    }, {
      "referenceID" : 10,
      "context" : "Proof technique is based on (Kotłowski and Dembczyński, 2015), where they derive similar bound in the binary classification setting.",
      "startOffset" : 28,
      "endOffset" : 61
    }, {
      "referenceID" : 13,
      "context" : "Then (6) reduces to the optimization problem considered by Lafond (2015). We have the following regret bound for the estimator Z = Ŵ obtained in Step 2 of Algorithm 1 (Note that X is just treated as identity in this setting).",
      "startOffset" : 59,
      "endOffset" : 73
    }, {
      "referenceID" : 13,
      "context" : "Remark 4 (Comparing (Lafond, 2015)).",
      "startOffset" : 20,
      "endOffset" : 34
    }, {
      "referenceID" : 13,
      "context" : "If we directly apply the method and the analysis of (Lafond, 2015), the resulting bounds are very weak; in fact, when n ≥ L and |Ω| = O(n), which is quite common in the multi-label scenario, the ensuing bound suggests that the estimator is not even consistent, even when π is uniform.",
      "startOffset" : 52,
      "endOffset" : 66
    }, {
      "referenceID" : 12,
      "context" : "Remark 5 (Comparing (Koyejo et al., 2015)).",
      "startOffset" : 20,
      "endOffset" : 41
    }, {
      "referenceID" : 12,
      "context" : "The plugin-in estimator algorithm of (Koyejo et al., 2015) estimates w∗ j for each label j independently, and learns a common threshold as in Algorithm 1.",
      "startOffset" : 37,
      "endOffset" : 58
    }, {
      "referenceID" : 13,
      "context" : "Our proof sketch is based on Lafond (2015), but requires bounding certain quantities carefully.",
      "startOffset" : 29,
      "endOffset" : 43
    }, {
      "referenceID" : 7,
      "context" : "In this setting, we can use the approach of (Hsieh et al., 2015), where they consider a two-stage sampling model: sample yij using (2) for all i, j ∈ [n] × [L] (or using (1) when features are available), and then flip a fraction ρ of the sampled 1’s to 0’s, resulting in Ỹ.",
      "startOffset" : 44,
      "endOffset" : 64
    }, {
      "referenceID" : 7,
      "context" : "Let Z = XŴ, where Ŵ is obtained by solving the unbiased estimator objective of Hsieh et al. (2015). With probability at least 1− δ, there exists absolute constant C such that: Regl(Z) ≤ √ 6 √ log(2/δ) √ nL(1− ρ) + 2C .",
      "startOffset" : 79,
      "endOffset" : 99
    }, {
      "referenceID" : 14,
      "context" : "This PU learning result is particularly very useful in extreme classification setting (Bhatia et al., 2015a; Prabhu and Varma, 2014); where there are too many labels and is unrealistic to get feedback on every label, but possible to obtain a small subset of relevant labels for instances.",
      "startOffset" : 86,
      "endOffset" : 132
    }, {
      "referenceID" : 12,
      "context" : "Furthermore, even when only 10% of the observations are revealed, we observe that the proposed method achieves very high F1 as well as accuracy values, compared to learning the columns of W independently via the plugin estimator method proposed by (Koyejo et al., 2015) (followed by learning a threshold).",
      "startOffset" : 248,
      "endOffset" : 269
    }, {
      "referenceID" : 17,
      "context" : "2 Real-world data We consider five real-world multi-label datasets widely used as benchmarks (Bhatia et al., 2015a; Yu et al., 2014).",
      "startOffset" : 93,
      "endOffset" : 132
    }, {
      "referenceID" : 11,
      "context" : "Dataset Koyejo et al. (2015) Algorithm 1 Koyejo et al.",
      "startOffset" : 8,
      "endOffset" : 29
    }, {
      "referenceID" : 11,
      "context" : "Dataset Koyejo et al. (2015) Algorithm 1 Koyejo et al. (2015) Algorithm 1 micro F1 micro F1 Accuracy Accuracy CAL500 0.",
      "startOffset" : 8,
      "endOffset" : 62
    }, {
      "referenceID" : 12,
      "context" : "Table 1: Comparison of proposed algorithm and plugin-estimator method of (Koyejo et al., 2015) on multi-label micro F1 and Hamming (i.",
      "startOffset" : 73,
      "endOffset" : 94
    }, {
      "referenceID" : 12,
      "context" : "The learned model is much more compact than that of (Koyejo et al., 2015) (k(d+L) vs dL parameters).",
      "startOffset" : 52,
      "endOffset" : 73
    } ],
    "year" : 2016,
    "abstractText" : "We consider the problem of recommending relevant labels (items) for a given data point (user). In particular, we are interested in the practically important setting where the evaluation is with respect to non-decomposable (over labels) performance metrics like the F1 measure, and the training data has missing labels. To this end, we propose a generic framework that given a performance metric Ψ, can devise a regularized objective function and a threshold such that all the values in the predicted score vector above and only above the threshold are selected to be positive. We show that the regret or generalization error in the given metric Ψ is bounded ultimately by estimation error of certain underlying parameters. In particular, we derive regret bounds under three popular settings: a) collaborative filtering, b) multilabel classification, and c) PU (positive-unlabeled) learning. For each of the above problems, we can obtain precise non-asymptotic regret bound which is small even when a large fraction of labels is missing. Our empirical results on synthetic and benchmark datasets demonstrate that by explicitly modeling for missing labels and optimizing the desired performance metric, our algorithm indeed achieves significantly better performance (like F1 score) when compared to methods that do not model missing label information carefully.",
    "creator" : "LaTeX with hyperref package"
  }
}