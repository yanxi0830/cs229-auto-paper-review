{
  "name" : "1705.05154.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "LAYERWISE SYSTEMATIC SCAN: DEEP BOLTZMANN MACHINES AND BEYOND",
    "authors" : [ "HENG GUO" ],
    "emails" : [ ],
    "sections" : [ {
      "heading" : "1. Introduction",
      "text" : "Gibbs sampling, or the Markov chain Monte Carlo method in general, plays a central role in machine learning and have been widely implemented as the backbone algorithm for models such as Deep Boltzmann Machines [23], latent Dirichlet allocations [2], and factor graphs in general. Given a set of random variables and a target distribution π, the Gibbs sampler iteratively updates one variable at a time according to the distribution π conditioned on the values of all other variables. If the ergodicity condition is met, then the Gibbs sampler eventually converges to the target distribution.\nThere are two ways to choose which variable to update at the next iteration: (1) Random Update, where in each epoch one variable is picked uniformly at random with replacement; and (2) Systematic Scan, where in each epoch all variables are updated using some pre-determined order. Although most theoretical development on analyzing Gibbs sampling deals with random updates [13, 17], systematic scans are prevalent in real-world implementations due to their hardware-friendly nature (cache locality for factor graphs, SIMD for Deep Boltzmann Machines, etc.). It is natural to wonder, whether using systematic scan, rather than random updates, would delay the mixing time, the number of iterations the Gibbs sampler requires to reach the target distribution.\nThe mixing time of these two update strategies can differ by some high polynomial factors in either directions [11, 22]. Even more pathological examples were constructed for non-Gibbs Markov chains such that systematic scan is not even ergodic whereas the random-update sampler is rapidly mixing [8]. Indeed, even for a system as simple as the Ising model, a comparison result remains elusive [17, Open problem 5, p. 300]. As a consequence, theoretical results on rapidly mixing, such as [3, 20], do not readily apply to the scan algorithms used in practice. Main results. In this paper, we bridge this gap between theory and system. We focus on bipartite distributions, in which variables can be divided into two partitions — conditioned on one of the partitions, variables from the other partition are mutually independent. This bipartite structure arises naturally in practice, including Restricted/Deep Boltzmann Machines. For a bipartite distribution, the de facto implementation is that in each epoch, we scan all variables from one of the partitions first, and then the other. We call this the alternating-scan sampler. Note that in order to define a valid Markov chain, we have to consider systematic scans in epochs. Our main theorem is the following.\nTheorem 1 (Main Theorem). For any bipartite distribution π, if the random-update Gibbs sampler is ergodic, then so is the alternating-scan sampler. Moreover, the relaxation time of the\nar X\niv :1\n70 5.\n05 15\n4v 1\n[ cs\n.L G\n] 1\n5 M\nay 2\n01 7\nalternating-scan sampler (in terms of epochs) is no larger than that of the random-update one (in terms of variable updates).\nThe relaxation time (inverse spectral gap) governs various aspects of the mixing properties of a Markov chain, and is closely related to the (total variation) mixing time [17]. Through standard inequalities, Theorem 1 also implies a comparison result in terms of mixing times, Corollary 5. As we count epochs in Theorem 1, the alternating-scan sampler is implicitly slower by a factor of n, the number of variables. We also show that Theorem 1 is asymptotically tight via Example 6. Thus this implicit factor n slowdown cannot be improved in general.\nMore specifically, we summarize our contribution as follows.\n(1) In Section 4, we establish Theorem 1. By focusing on bipartite systems, we are able to obtain much stronger result than recent studies in the more general setting [11]. We note that standard Markov chain comparison results, such as [5], do not seem to fit into our setting. Instead, we give a novel analysis via estimates of operator norms of certain carefully defined matrices. One key observation is to consider an artificial but equivalent variant of the alternating-scan sampler, where we insert an extra random update between updating variables from the two partitions. This does not change the algorithm since the extra random update is either redundant with the updates in the first partition or with those in the second. (2) In Section 5, we discuss bipartite distributions that arise naturally in machine learning. In particular, our result is a rigorous justification of the popular layer-wise scan sampler for Deep Boltzmann Machines [23]. Our result also applies to other models such as Restricted Boltzmann Machines [24] and, more generally, any bipartite factor graph. (3) In Section 6, we conduct experiments to verify our theory and analyze the gap between our worst case theoretical bound and numerical evidences. We observe that in the rapidly mixing regime, the alternating-scan sampler is usually faster than the random-update one, whereas in the slow mixing regime, the alternating-scan sampler can be slower by a factor O(n). We hope these observations shed some light on more fine-grained comparison bounds in the future."
    }, {
      "heading" : "2. Related Work",
      "text" : "Probably the most relevant work is the recent analysis conducted by He et al. [11] about the impact of the scan order on the mixing time of the Gibbs sampling. They (1) constructed a variety of models in which the scan order can change the mixing time significantly in several different ways and (2) proved comparison results on the mixing time between random updates and a variant of systematic scans where “lazy” moves are allowed. In this paper, we focus on a more specific case, i.e., bipartite systems, and so our bound is stronger — in fact, our bound can be exponentially stronger when the underlying chain is slow mixing. Moreover, our result does not modify the standard scan algorithm.\nAnother related work is the recent analysis by Tosh [25] considering the mixing time of an alternating sampler for the Restricted Boltzmann Machine (RBM). Tosh showed that, under Dobrushin-like conditions [6], i.e., when the weights in the RBM are sufficiently small, the alternating sampler mixes rapidly. For models other than RBM, mixing time results for systematic scans are relatively rare. Known examples are usually restricted to very specific models [4] or under conditions to ensure that the correlations are sufficiently weak [7, 10, 8]. Typical conditions of this sort are variants of the classical Dobrushin condition [6]. Unlike all of these work, we focus on the relative performance between random updates and systematic scan, and does not rely on Dobrushin-like conditions.\nAnother line of related research is about the scan order in stochastic gradient descent [19, 21]. Our setting in this paper is very different and the techniques are different as well."
    }, {
      "heading" : "3. Preliminaries on Markov Chains",
      "text" : "Let Ω be a discrete state space and P be a |Ω|-by-|Ω| matrix describing a (discrete time) Markov chain on Ω. The matrix P is also called the transition matrix or the kernel of the chain. Thus, P t(σ0, ·) is the distribution of the chain at time t starting from σ0. Let π(·) be the stationary distribution of P . A Markov chain defined by P is reversible (with respect to π(·)) if P satisfies the detailed balance condition:\nπ(σ)P (σ, τ) = π(τ)P (τ, σ)(1)\nfor any σ, τ ∈ Ω. We note that the systematic scan sampler is not in general reversible. A Markov chain is called irreducible if P connects the whole state space Ω, namely, for any σ, τ ∈ Ω, there exists a sequence of transitions defined by P from σ to τ . Furthermore, P is ergodic if it is both irreducible and aperiodic.\nThe total variation distance ‖·‖TV is defined as\n‖µ− ν‖TV = max A⊂Ω |µ(A)− ν(A)| = 1 2 ∑ σ∈Ω |µ(σ)− ν(σ)| .\nThe mixing time Tmix is defined as\nTmix(P ) := min\n{ t ≥ 0 : max\nσ∈Ω\n∥∥P t(σ, ·)− π∥∥ TV ≤ 1\n2e\n} ,\nwhere the choice of the constant 12e is merely for convenience and is not significant [17]. When P is ergodic and reversible, the eigenvalues (ξi)i of P satisfies −1 < ξi ≤ 1, and additionally, Pf = f if and only if f is constant (see [17, Lemma 12.1]). The spectral gap of P is defined by\nλ(P ) := 1−max{|ξ| : ξ is an eigenvalue of P and ξ 6= 1}.(2) The relaxation time for a reversible P is defined as\nTrel(P ) := λ(P ) −1.(3) The relaxation time and the mixing time differ by at most a factor of log (\n2e πmin\n) where πmin =\nminσ∈Ω π(σ), shown by the following theorem (see, for example, [17, Theorem 12.4 and 12.5]). In fact, the relaxation time governs mixing properties with respect to metrics other than the total variation distance as well. See [17, Chapter 12] for more details.\nTheorem 2. Let P be the transition matrix of a reversible and ergodic Markov chain with the state space Ω and the stationary distribution π. Then\nTrel(P )− 1 ≤ Tmix(P ) ≤ Trel(P ) log ( 2e\nπmin\n) ,\nwhere πmin = minσ∈Ω π(σ).\nNote that the factor log π−1min is usually linear in n, the number of variables. Unfortunately, the systematic-scan sampler is not reversible, and therefore Theorem 2 does not apply. Instead, we use an extension developed by Fill [9]. For a non-reversible transition matrix P , let the multiplicative reversiblization be R(P ) := PP ∗, where P ∗ is the adjoint of P defined as\nP ∗(σ, τ) = π(τ)P (σ, τ)\nπ(σ) .(4)\nThen R(P ) is reversible. Let the relaxation time for a (not necessarily reversible) P be\nTrel(P ) := 1 1− √ 1− λ(R(P )) .(5)\nIn particular, if P is reversible, then (5) recovers (3). The following theorem is a simple consequence of [9, Theorem 2.1].\nAlgorithm 1 Gibbs sampling with random updates Input: Starting configuration σ = σ0 for t = 1, . . . , Tmix do With probability 1/2, do nothing. Otherwise, select a variable x ∈ V uniformly at random. Set σ ← σx,s with probability π(σ\nx,s)∑ s∈S π(σ\nx,s) . end for return σ\nTheorem 3. Let P be the transition matrix of an ergodic Markov chain with the state space Ω and the stationary distribution π. Then\nTmix(P ) ≤ log ( 4e2\nπmin\n) Trel(P ),\nwhere πmin = minσ∈Ω π(σ).\nNote that typically log π−1min is super constant, and our definition of relaxation times for non-reversible Markov chains (5) yields asymptotically the same upper bound in Theorem 2."
    }, {
      "heading" : "4. Alternating Scan",
      "text" : "To simplify the notations, we will consider discrete state spaces. Our methods generalizes to general state spaces straightforwardly. Let V = {x1, . . . , xn} be a set of variables where each variable takes values from some set S. Let π(·) be a distribution defined on SV .\nLet σ ∈ SV be a configuration, namely σ : V → S. Let σx,s be the configuration that agrees with σ except at x, where σx,s(v) = s for s ∈ S. In other words, for any y ∈ V ,\nσx,s(y) := { σ(y) if x 6= y; d if x = y.\nThe (lazy) Gibbs sampler is defined in Algorithm 1. Let n = |V | be the total number of variables. The transition kernel PRU (where RU stands for “random updates”) of the sampler above is defined as:\nPRU (σ, τ) =  1 2n · π(σv,s)∑ s∈S π(σ v,s) if τ = σ v,s for some x ∈ V and s ∈ S;\n1/2 if τ = σ; 0 otherwise,\n(6)\nwhere σ, τ are two configurations. It is not hard to see, for example, by checking the detailed balance condition (1), that π(·) is the stationary distribution of PRU . Note that this Markov chain is lazy, i.e., it remains at its current state with probability at least 1/2. This self-loop move has in fact probability higher than 1/2 because in the first case of (6) the probability of remaining in σ is positive. Lazy chains are usually studied in the literature since the self-loop eliminates (potential) periodicity. Moreover, all eigenvalues of the transition matrix PRU are non-negative.\nDefinition 4. A distribution π(·) is bipartite, if all variables can be partitioned into two sets V1 = {x1, . . . , xn1} and V2 = {y1, . . . , yn2} where n = n1 + n2, such that conditioned on the values of V2, all variables in V1 are mutually independent, and vice versa.\nIn the following we consider a particular systematic scan sampler for bipartite distributions. For a configuration σ, let σi := σ|Vi be its projection on Vi where i = 1, 2. The alternating-scan sampler is given in Algorithm 2.\nIn other words, the alternating-scan sampler sequentially resamples all variables in V1, and then resamples all variables in V2. Note that since we are considering a bipartite distribution, in order to resample xi ∈ V1, we only need to condition on σ2. In other words, for any i ∈ [n1], the\nAlgorithm 2 Alternating-scan sampler Input: Starting configuration σ = σ0 for t = 1, . . . , Tmix do for i = 1, . . . , n1 do Set σ ← σxi,s with probability π(σ\nxi,s)∑ s∈S π(σ\nxi,s) . end for for j = 1, . . . , n2 do Set σ ← σyj ,s with probability π(σ\nyj,s)∑ s∈S π(σ yj,s) .\nend for end for return σ\ndistribution {\nπ(σxi,s)∑ s∈S π(σ xi,s) } s∈S\nthat we draws from depends only on σ2. Similarly, resampling yj ∈ V2 only depends on σ1. We will denote the transition kernel of the alternating-scan sampler as PAS , where AS stands for “alternating scan”.\nAn unusual feature of systematic-scan samplers (including the alternating-scan sampler) is that they are not reversible. Namely the detailed balance condition (1) does not in general hold. This is because updating variables x and y in order is in general different from updating y and x in order. This imposes a technical difficulty as most of the theoretical tools of analyzing these chains are not suitable for irreversible chains, such as the Dirichlet form [5] or conductance bounds [14].\nOn the other hand, the scan sampler is aperiodic. Any potential state σ of the chain must be in the state space Ω. Therefore π(σ) > 0 and the probability of staying in σ is strictly positive. Moreover, if the Gibbs sampler is irreducible (namely the state space Ω is connected via single variable flips), then so is the scan sampler. This is because any single variable update can be simulated in the scan sampler, with small but strictly positive probability. Hence if the Gibbs sampler is ergodic, then so is the scan sampler.\nWe restate our main theorem here in formal terms.\nTheorem 1. For any bipartite distribution π, if PRU is ergodic, then so is PAS. Moreover,\nTrel(PAS) ≤ Trel(PRU ).\nDue to the space limit, we provide a proof sketch here.\nProof sketch. The first statement is straightforawd. For the second, let Sπ be the projection matrix of the stationary distribution, namely\nSπ(σ, τ) = π(τ).\nIf P is reversible, then we can rewrite the spectral gap in terms of an operator norm, namely,\nλ(P ) = 1− ‖P − Sπ‖π ,(7)\nwhere ‖·‖π is the operator norm with respect to the distribution π. The transition matrix of updating a particular variable x is the following\nTx(σ, τ) =\n{ π(σx,s)∑ s∈S π(σ x,s) if τ = σ x,s for some s ∈ S;\n0 otherwise.\nMoreover, let I be the identity matrix that I(σ, τ) = 1(σ, τ). Then we have that\nPRU = I\n2 +\n1\n2n ∑ x∈V Tx; PAS = n1∏ i=1 Txi n2∏ j=1 Tyj .\nWe consider an artificial but equivalent variant of PAS , where after updating all variables in V1, we do a random update according to PRU , and then proceed to update all variables in V2. This\nis equivalent to PAS since the extra random update is either redundant with the updates in V1 or with those in V2. To put it formally,\nPAS = n1∏ i=1 Txi · PRU · n2∏ j=1 Tyj .\nUsing the equation above, we can show that\n‖PAS − Sπ‖π ≤ ‖PRU − Sπ‖π .\nHowever, this is not enough as (7) only applies to reversible Markov chains. Instead, we estabilish a similar inequality for the multiplicative reversibilization R(P ) and conclude using (7).\nRemark. It is easy to check that the proof above also works if we consider the non-lazy version of PRU . To do so, we just replace I2 + 1 2n ∑ x∈V Tx with 1 n ∑ x∈V Tx and the rest of the proof goes through without changes.\nRemark. The proof above can also handle the case of general state spaces, such as Gaussian variables. However, for general state spaces, in order to apply Theorem 1 on mixing times, we need to replace Theorem 2 and Theorem 3 with their continuous counterparts. See for example [16].\nUsing Theorem 2 and Theorem 3, we translate Theorem 1 in terms of the mixing time.\nCorollary 5. For a Markov random field defined on a bipartite graph, let PRU and PAS be the transition kernels of the random-update Gibbs sampler and the alternating-scan sampler, respectively. Then,\nTmix(PAS) ≤ log ( 4e2\nπmin\n) (Tmix(PRU ) + 1) ,\nwhere πmin = minσ∈Ω π(σ).\nSince n variables are updated in each epoch of PAS , one might hope to strengthen Theorem 1 so that nTrel(PAS) is also no larger than Trel(PRU ). Unfortunately, this is not the case and we give an example (similar to the “two islands” example in [11]) where Tmix(PAS) Tmix(PRU ) and Trel(PAS) Trel(PRU ). This example implies that Theorem 1 is asymptotically tight. However, it is still possible that Corollary 5 is loose by a factor of log π−1min.\nExample 6. Let G = (L ∪R,E) be a complete bipartite graph Kn,n and we want to sample an uniform independent set in G. In other words, each vertex is a Boolean variable and a valid configuration is an independent set I ⊆ L ∪ R. The state space is Ω = {I | I ⊆ L or I ⊆ R} and the measure π is uniform on Ω. Under single-site updates, the state space Ω is composed of two independent copies of the Boolean hypercube {0, 1}n with the two origins identified. The random-update Gibbs sampler has mixing time O(2n) because the hitting time of the Boolean hypercube is O(2n) and the mixing time is upper bounded by the hitting time multiplied by a constant [17, Eq. (10.24)]. The relaxation time is also O(2n) by Theorem 2. In fact, it is not hard to see that both quantities are Θ(2n).\nOn the other hand, the alternating-scan sampler has mixing time Ω(2n) and relaxation time Ω(2n). For the mixing time, we partition the state space Ω into ΩL = {I | I ⊂ L} and ΩR = {I | I ⊂ R and I 6= ∅}. Consider the alternating scan projected down to ΩL and ΩR. If the current state is in ΩL, then there is 2−n probability to go to ∅ after updating all vertices in L, and then with probability 1− 2−n the state goes to ΩR after updating all vertices in R. Similarly, going from ΩR to ΩL has also probability O(2−n). Thus in each epoch of the alternating scan, the probability to go between ΩL and ΩR is Θ(2n) and the mixing time is thus Θ(2−n). The relaxation time can be similarly bounded using a standard conductance argument [14].\nIn summary, for this distribution π, we have that Trel(PAS) Trel(PRU ) and Tmix(PAS) Tmix(PRU ). Therefore, Theorem 1 is asymptotically tight and Corollary 5 is tight up to the factor log π−1min.\nWe note that in the example above, the alternating scan is not the best scan order. Indeed, as shown in [11], if we scan vertices alternatingly from the left and right, rather than scanning variables layerwise, the mixing time is smaller by a factor of n. Thus, although Theorem 1 and Corollary 5 provide certain guarantees of the alternating-scan sampler, the layerwise alternating order is not necessarily the best one."
    }, {
      "heading" : "5. Bipartite Distributions in Machine Learning",
      "text" : "The results we developed so far can be applied to probabilistic graphic models with bipartite structures, most notably Restricted Boltzmann Machines (RBM) and Deep Boltzmann Machines (DBM). Although real-world systems for RBM and DBM inference rely on layerwise systematic scans, we are the first to provide a theoretical justification of such implementation.\n5.1. Markov Random Fields. A Markov random field (with binary factors) 〈G,S, π〉 is defined on a graph G = (V,E), where each edge describes a “factor” fe and each vertex is a variable drawing from S, a set of possible values. Each factor is a function S2 → R. A configuration σ ∈ SV is a mapping from V to S. In addition, each vertex is equipped with a factor gv : S → R. Let Ω ⊆ SV be the state space, which is usually defined by a set of hard constraints. When there is no hard constraint, the state space Ω is simply SV . The Hamiltonian of σ ∈ Ω is defined as\nH(σ) = ∑\ne=(u,v)∈E fe(σ(u), σ(v)) + ∑ v∈V gv(σ(v)).\nThe Gibbs distribution π(·) is defined as π(σ) ∝ 1(σ ∈ Ω) exp(H(σ)). These models are popularly used in applications such as image processing [18] and natural language processing [15].\nIt is easy to check that, when the underlying graph G is bipartite, the Gibbs distribution is bipartite in the sense of Definition 4. Thus Theorem 1 and Corollary 5 apply to this setting.\n5.2. Restricted/Deep Boltzmann Machines. Restricted Boltzmann Machines (RBM) is a special case of the general MRF in which all variables are Boolean (i.e., S = {0, 1}) and are partitioned into two disjoint sets, V1 and V2. There is a factor between each variable in V1 and V2, and the Hamiltonian is\nH(σ) = ∑\nu∈V1,v∈V2 Wuvσ(u)σ(v) + ∑ v∈V Wvσ(v).\nwhere Wuv and Wv are real-valued weights. Figure 1(a) illustrates the structure of RBMs. We use [f00, f01, f10, f11] to describe a general binary factor defined on Boolean variables. Thus, [0, 0, 0,W ] denotes a standard RBM factor with weight W , and [W, 0, 0,W ] denotes an Ising model with weight W .\nThe inference task of RBMs involves sampling a configuration from the Gibbs distribution π. The de facto algorithm for this task is Gibbs sampling, in which the conditional probability of each step can be calculated from only the Hamiltonian. In this context, the alternating-scan algorithm we study corresponds to a layerwise scan — first updates all variables in V1 and then\nall variables in V2. This scan order allows one to use efficient linear algebra primitives such as dense matrix multiplication implemented with GPUs or SIMD instructions on modern CPUs.\nDBM is a Deep Learning model that extends RBM to multiple layers as illustrated in Figure 1(b). This layer structure is indeed bipartite, shown in Figure 1(c). The scan order induced is thus to update odd layers first and even ones after. Like most deep learning models, the scan (evaluation) order of variables has significant impact on the speed and performance of the system. The layerwise implementation is particularly advantageous thanks to dense linear algebra primitives.\nGiven an RBM or DBM with n variables, it is easy to see that log π−1min is O(n). Thus, Corollary 5 implies that, comparing to the random-update algorithm, the layerwise systematic scan algorithm incurs at most a O(n2) slowdown in the convergence rate."
    }, {
      "heading" : "6. Experiments",
      "text" : "Empirically evaluating the mixing time of Markov chains is difficult. In general, it is hard under certain complexity assumptions [1] and lower bounds have been established for more concrete settings [12] (see also [12] for a comprehensive survey on this topic). We evaluate the mixing time in either exact and straightforward or approximate but tractable ways, including (1) calculating directly using the transition matrix for small graphs, (2) taking advantage of symmetries in the state space for medium-sized graphs, and (3) using the coupling time as a proxy of the mixing time for large graphs.\nMixing Time on Small Graphs. Figure 2 and Figure 3 contains the comparison of the mixing time for small graphs (RBMs of up to 12 variables and DBMs with 4 layers and 3 variable per layer). We vary (1) number of variables, (2) factor functions (shown as the entries of truth table in the caption), or (3) the weight of factors, in different figures and report the mixing times of random updates and layerwise scan. All solid lines count mixing time in # variable updates and the dotted line in # epochs.\nWe see that, empirically, alternating scan has comparable, sometimes better, mixing time than random updates, even when counting in the number of variable updates. This, on one hand, confirm our theory that the mixing time of alternating scan and random updates are similar. On the other hand, this empirical result shows that our theory, although asymptotically tight for the worst case, is not “instance optimal”. This indicates promising future direction for beyond-worst case analysis.\n1E+0\n1E+2\n1E+4\n1E+6\n1E+8\n0 12 24 36 48\nR el\nax at\nio n\nTi m\ne\n# Variables\n1E+0\n1E+2\n1E+4\n1E+6\n1E+8\n0 12 24 36 48\nM ix\nin g\nTi m\ne\n# Variables\n(a) Mixing Time\nRandom Update\nAlter. Scan\nAlter. Scan (# Epochs)\nRandom Update\nAlter. Scan\nAlter. Scan (# Epochs)\n(b) Relaxation Time Medium-sized Graphs. We now turn to Example 6, which has also been studied by He et al. [11] and is asymptotically the worst case of Theorem 1. Due to symmetries in the state space, we manage to calculate the mixing and relaxation times for mildly larger graphs (up to 50 variables). As illustrated in the figures on the right, the alternating-scan sampler is slower than, but still comparable to the random-update sampler. This is consistent with the discussion in Example 6.\n1E+0 1E+1 1E+2 1E+3 1E+4 1E+5 1E+6\n0 0.2 0.4 0.6 0.8 1\nCo up\nlin g\nTi m\ne\nWeight\n1E+0\n1E+2\n1E+4\n1E+6\n0 0.1 0.2 0.3\nCo up\nlin g\nTi m e Weight\n(a) Bipartite Ising Model\nRandom Update\nAlter. Scan\nAlter. Scan (# Epochs)\nRandom Update\nAlter. Scan\nAlter. Scan (# Epochs)\n(b) Restricted Boltzmann Machine Coupling Time on Large Graphs. Lastly, we use the coupling time as a proxy of the mixing time and estimate it on large graphs with 104 variables and 5× 104 randomly chosen factors. The coupling time is closely related to the mixing time [17, Chapter 5] and is relatively easy to estimate numerically. We choose our parameters to stay within the rapidly mixing regime [20] and avoid exponential mixing times. As we can see in the figure on the right, alternating scan is faster than random updates (in terms of variable updates). Indeed, numerical evidence suggests that the speedup factor is 2."
    }, {
      "heading" : "7. Concluding Remarks",
      "text" : "In summary, we showed that for a bipartite distribution, the relaxation time of the alternatingscan sampler (in terms of epochs) is no larger than that of the random-update sampler. This is asymptotically tight and implies a (weaker) comparison result on the mixing time. Future directions include more fine-grained comparison results, and going beyond bipartite distributions."
    }, {
      "heading" : "Appendix A. Proof of Theorem 3",
      "text" : "Given the setup in Theorem 3, we first restate [9, Theorem 2.1] (note that the norm in [9] is twice the total variation distance):\n∥∥P t(σ, ·)− π∥∥2 TV ≤ (1− λ(R(P ))) t\nπ(σ) .(8)\nLet λ := λ(R(P )) and T := log ( 4e2\nπmin\n) Trel(P ) =\n1 1− √ 1−λ log ( 4e2 πmin ) . Then it is easy to verify\nthat\nT ≥ 2 λ log ( 2e √ πmin ) and by (8), we have that\nmax σ∈Ω\n∥∥P T (σ, ·)− π∥∥ TV ≤ (1− λ) T/2\n√ πmin\n≤ (1− λ) λ−1 log\n( 2e√ πmin ) √ πmin\n≤ e − log\n( 2e√ πmin ) √ πmin\n= 1\n2e .\nIn other words,\nTmix(P ) ≤ T = log ( 4e2\nπmin\n) Trel(P )."
    }, {
      "heading" : "Appendix B. Operator Norms and the Spectral Gap",
      "text" : "We also view the transition matrix P as an operator that mapping functions to functions. More precisely, let f be a function f : Ω→ R and P acting on f is defined as\nPf(x) := ∑ y∈Ω P (x, y)f(y).\nThis is also called the Markov operator corresponding to P . We will not distinguish the matrix P from the operator P as it will be clear from the context. Note that Pf(x) is the expectation of f with respect to the distribution P (x, ·). We can regard a function f as a column vector in RΩ, in which case Pf is simply matrix multiplication. Recall (4) and P ∗ is also called the adjoint operator of P . Indeed, P ∗ is the (unique) operator that satisfies 〈f, Pg〉π = 〈P ∗f, g〉π. It is easy to verify that if P satisfies the detailed balanced condition (1), then P is self-adjoint, namely P = P ∗.\nThe Hilbert space L2(π) is given by endowing RΩ with the inner product\n〈f, g〉π := ∑ x∈Ω f(x)g(x)π(x),\nwhere f, g ∈ RΩ. In particular, the norm in L2(π) is given by\n‖f‖π := 〈f, f〉π.\nThe spectral gap (2) can be rewritten in terms of the operator norm of P , which is defined by\n‖P‖π := max‖f‖π 6=0 ‖Pf‖π ‖f‖π .\nIndeed, the operator norm equals the largest eigenvalue (which is just 1 for a transition matrix P ), but we are interested in the second largest eigenvalue. Define the following operator\nSπ(σ, τ) := π(τ).(9)\nIt is easy to verify that Sπf = 〈f,1〉π. Thus, the only eigenvalues of Sπ are 0 and 1, and the eigenspace of eigenvalue 0 is {f ∈ L2(π) : 〈f,1〉π = 0}. This is exactly the union of eigenspaces of P excluding the eigenvalue 1. Hence, the operator norm of P − Sπ equals the second largest eigenvalue of P , namely,\nλ(P ) = 1− ‖P − Sπ‖π .(10)\nThe expression in (10) can be found in, for example, [26, Eq. (2.8)]. In particular, using (10), we show that the definition (5) coincides with (3) when P is reversible.\nProposition 7. Let P be the transition matrix of a reversible matrix with the stationary distribution π. Then\n1\nλ(P ) =\n1 1− √ 1− λ(R(P )) .\nProof. Since P is reversible, P is self-adjoint, namely, P ∗ = P . Hence (P − Sπ)∗ = P ∗ − Sπ and\n(P − Sπ) (P − Sπ)∗ = (P − Sπ) (P ∗ − Sπ) = PP ∗ − PSπ − SπP ∗ + SπSπ = PP ∗ − Sπ,\nwhere we use the fact that PSπ = SπP ∗ = SπSπ = Sπ. It implies that"
    }, {
      "heading" : "1− λ(R(P )) = ‖R(P )− Sπ‖π(by (10))",
      "text" : "= ‖PP ∗ − Sπ‖π = ‖(P − Sπ) (P − Sπ)∗‖π = ‖P − Sπ‖2π = (1− λ(P ))2 .\nRearranging the terms yields the claim."
    }, {
      "heading" : "Appendix C. Proof of Theorem 1",
      "text" : "The transition matrix of updating a particular variable x is the following\nTx(σ, τ) =\n{ π(σx,s)∑ s∈S π(σ x,s) if τ = σ x,s for some s ∈ S;\n0 otherwise. (11)\nMoreover, let I be the identity matrix that I(σ, τ) = 1(σ, τ).\nLemma 8. Let π be a bipartite distribution, and PRU , PAS, Tx be defined as above. Then we have that\n(1) PRU = I\n2 +\n1\n2n ∑ x∈V Tx.\n(2) PAS = n1∏ i=1 Txi n2∏ j=1 Tyj .\nProof. Note that Tx is the transition matrix of resampling σ(x). For PRU , the term I2 comes from the fact that the chain is “lazy”. With the other 1/2 probability, we resample σ(x) for a uniformly chosen x ∈ V . This explains the term 12n ∑ x∈V Tx.\nFor PAS , we sequentially resample all variables in V1 and then all variables in V2, which yields the expression.\nLemma 9. Let π be a bipartite distribution and Tx be defined as above. Then we have that (1) For any x ∈ V , Tx is a self-adjoint operator and idempotent. Namely, Tx = T ∗x and\nTxTx = Tx. (2) For any x ∈ V , ‖Tx‖π = 1. (3) For any x, x′ ∈ Vi where i = 1 or 2, Tx and Tx′ commute. In other words Tx′Tx = TxTx′\nif x, x′ ∈ Vi for i = 1 or 2.\nProof. For Item 1, the fact that Tx is self-adjoint follows from the detailed balance condition (1). Idempotence is because updating the same vertex twice is the same as a single update.\nItem 2 follows from Item 1. This is because\n‖Tx‖π = ‖TxTx‖π = ‖TxT ∗ x‖π = ‖Tx‖ 2 π .\nFor Item 3, suppose i = 1. Since π is bipartite, resampling x or x′ only depends on σ2. Therefore the ordering of updating x or x′ does not matter as they are in the same partition.\nDefine\nPGS1 := I\n2 +\n1\n2n1 n1∑ i=1 Txi , and PGS2 := I 2 + 1 2n2 n2∑ j=1 Tyj .\nThen, since n1 + n2 = n,\nPRU = 1\nn (n1PGS1 + n2PGS2) .(12)\nSimilarly, define\nPAS1 := n1∏ i=1 Txi , and PAS2 := n2∏ j=1 Tyj .\nThen\nPAS = PAS1PAS2.(13)\nWith this notation, Lemma 9 also implies the following.\nCorollary 10. The following holds: (1) ‖PAS1‖π ≤ 1 and ‖PAS2‖π ≤ 1. (2) PAS1PGS1 = PAS1 and PGS2PAS2 = PAS2.\nProof. For Item 1, by the submultiplicity of operator norms:\n‖PAS1‖π = ∥∥∥∥∥ n1∏ i=1 Txi ∥∥∥∥∥ π ≤ n1∏ i=1 ‖Txi‖π\n= 1.(By Item 2 of Lemma 9)\nThe claim ‖PAS2‖π ≤ 1 follows similarly. Item 2 follows from Item 1 and 3 of Lemma 9. We verify the first case as follows.\nPAS1PGS1 = n1∏ i=1 Txi I 2 + 1 2n1 n1∑ j=1 Txj  = 1\n2 · n1∏ i=1 Txi + 1 2n1 · n1∏ i=1 Txi n1∑ j=1 Txj\n= 1 2 · n1∏ i=1 Txi + 1 2n1 · n1∑ j=1 Txj n1∏ i=1 Txi\n= 1 2 · n1∏ i=1 Txi + 1 2n1 · n1∑ j=1 Tx1Tx2 · · ·TxjTxj · · ·Txn1(By Item 3 of Lemma 9)\n= 1 2 · n1∏ i=1 Txi + 1 2n1 · n1∑ j=1 n1∏ i=1 Txi(By Item 1 of Lemma 9)\n= 1 2 · n1∏ i=1 Txi + 1 2 · n1∏ i=1 Txi\n= PAS1.\nThe other case is similar.\nItem 2 of Corollary 10 captures the following intuition: if we sequentially update all variables in Vi for i = 1, 2, then an extra individual update either before or after does not change the distribution. Recall Eq. (5).\nLemma 11. Let π be a bipartite distribution and PRU and PAS be defined as above. Then we have that\n‖R(PAS)− Sπ‖π ≤ ‖PRU − Sπ‖ 2 π .\nProof. Recall (9), the definition of Sπ, using which it is easy to see that\nPAS1Sπ = SπPAS2 = SπSπ = Sπ.(14)\nThus,\nPAS1(PRU − Sπ)PAS2 = PAS1 (n1 n PGS1 + n2 n PGS2 − Sπ ) PAS2(By (12))\n= n1 n PAS1PGS1PAS2 + n2 n PAS1PGS2PAS2 − PAS1SπPAS2 = n1 n PAS1PAS2 + n2 n PAS1PAS2 − Sπ(By Item 2 of Cor 10) = PAS1PAS2 − Sπ = PAS − Sπ,(15)\nwhere in the last step we use (13). Moreover, we have that\nP ∗AS =  n1∏ i=1 Txi n2∏ j=1 Tyj ∗\n= n2∏ j=1 T ∗yn2+1−j n1∏ i=1 T ∗xn1+1−i\n= n2∏ j=1 Tyn2+1−j n1∏ i=1 Txn1+1−i(By Item 1 of Lemma 9)\n= n2∏ j=1 Tyj n1∏ i=1 Txi(By Item 3 of Lemma 9)\n= PAS2PAS1.\nHence, similarly to (15), we have that\nPAS2(PRU − Sπ)PAS1 = PAS2PAS1 − Sπ = P ∗AS − Sπ.(16)\nUsing (14), we further verify that\n(PAS − Sπ) (P ∗AS − Sπ) = PASP ∗AS − PASSπ − SπP ∗AS + SπSπ = PASP ∗ AS − Sπ(17)\nCombining (15), (16), and (17), we see that\n‖R(PAS)− Sπ‖π = ‖PASP ∗ AS − Sπ‖π\n= ‖(PAS − Sπ) (P ∗AS − Sπ)‖π = ‖PAS1 (PRU − Sπ)PAS2PAS2 (PRU − Sπ)PAS1‖π ≤ ‖PAS1‖π ‖PRU − Sπ‖π ‖PAS2‖π ‖PAS2‖π ‖PRU − Sπ‖π ‖PAS1‖π ≤ ‖PRU − Sπ‖2π ,\nwhere the first inequality is due to the submultiplicity of operator norms, and we use Item 1 of Corollary 10 in the last line.\nRemark. The last inequality in the proof of Lemma 11 crucially uses the fact that the graph is bipartite. If there are, say, k partitions, then the corresponding operators PAS1, . . . , PASk do not commute and the proof does not generalize.\nProof of Theorem 1. For the first part, notice that the alternating-scan sampler is aperiodic. Any possible state σ of the chain must be in the state space Ω. Therefore π(σ) > 0 and the probability of staying at σ is strictly positive. Moreover, any single variable update can be simulated in the scan sampler, with small but strictly positive probability. Hence if the random-update sampler is irreducible, then so is the scan sampler.\nTo show that Trel(PAS) ≤ Trel(PRU ), we have the following\nTrel(PAS) = 1 1− √ 1− λ(R(PAS)) (By (5))\n= 1 1− √ ‖R(PAS)− Sπ‖π (By (10))\n≤ 1 1− ‖PRU − Sπ‖π (By Lemma 11)\n= 1\nλ(PRU ) (By (10))\n= Trel(PRU ).(By (3))\nThis completes the proof.\nSchool of Mathematical Sciences, Queen Mary, University of London, Mile End Road, London E1 4NS, United Kingdom.\nE-mail address: h.guo@qmul.ac.uk\nDepartment of Computer Science, ETH Zurich, Switzerland E-mail address: kaan.kara@inf.ethz.ch\nDepartment of Computer Science, ETH Zurich, Switzerland E-mail address: ce.zhang@inf.ethz.ch"
    } ],
    "references" : [ {
      "title" : "The computational complexity of estimating MCMC convergence time",
      "author" : [ "Nayantara Bhatnagar", "Andrej Bogdanov", "Elchanan Mossel" ],
      "venue" : "In RANDOM,",
      "citeRegEx" : "1",
      "shortCiteRegEx" : "1",
      "year" : 2011
    }, {
      "title" : "Latent dirichlet allocation",
      "author" : [ "David M. Blei", "Andrew Y. Ng", "Michael I. Jordan" ],
      "venue" : "J. Mach. Learn. Res.,",
      "citeRegEx" : "2",
      "shortCiteRegEx" : "2",
      "year" : 2003
    }, {
      "title" : "Path coupling: A technique for proving rapid mixing in Markov chains",
      "author" : [ "Russ Bubley", "Martin E. Dyer" ],
      "venue" : "In FOCS,",
      "citeRegEx" : "3",
      "shortCiteRegEx" : "3",
      "year" : 1997
    }, {
      "title" : "Analysis of systematic scan Metropolis algorithms using Iwahori-Hecke algebra techniques",
      "author" : [ "Persi Diaconis", "Arun Ram" ],
      "venue" : "Michigan Math. J.,",
      "citeRegEx" : "4",
      "shortCiteRegEx" : "4",
      "year" : 2000
    }, {
      "title" : "Comparison theorems for reversible Markov chains",
      "author" : [ "Persi Diaconis", "Laurent Saloff-Coste" ],
      "venue" : "Ann. Appl. Probab., 3(3):696–730,",
      "citeRegEx" : "5",
      "shortCiteRegEx" : "5",
      "year" : 1993
    }, {
      "title" : "Prescribing a system of random variables by conditional distributions",
      "author" : [ "R.L. Dobrushin" ],
      "venue" : "Theory Probab. Appl.,",
      "citeRegEx" : "6",
      "shortCiteRegEx" : "6",
      "year" : 1970
    }, {
      "title" : "Systematic scan for sampling colourings",
      "author" : [ "Martin E. Dyer", "Leslie Ann Goldberg", "Mark Jerrum" ],
      "venue" : "Ann. Appl. Probab.,",
      "citeRegEx" : "7",
      "shortCiteRegEx" : "7",
      "year" : 2006
    }, {
      "title" : "Dobrushin conditions and systematic scan",
      "author" : [ "Martin E. Dyer", "Leslie Ann Goldberg", "Mark Jerrum" ],
      "venue" : "Combin. Probab. Comput.,",
      "citeRegEx" : "8",
      "shortCiteRegEx" : "8",
      "year" : 2008
    }, {
      "title" : "Eigenvalue bounds on convergence to stationary for nonreversible Markov chains, with an application to the exclusion process",
      "author" : [ "James A. Fill" ],
      "venue" : "Ann. Appl. Probab.,",
      "citeRegEx" : "9",
      "shortCiteRegEx" : "9",
      "year" : 1991
    }, {
      "title" : "A simple condition implying rapid mixing of single-site dynamics on spin systems",
      "author" : [ "Thomas P. Hayes" ],
      "venue" : "In FOCS,",
      "citeRegEx" : "10",
      "shortCiteRegEx" : "10",
      "year" : 2006
    }, {
      "title" : "Scan order in Gibbs sampling: Models in which it matters and bounds on how much",
      "author" : [ "Bryan D. He", "Christopher De Sa", "Ioannis Mitliagkas", "Christopher Ré" ],
      "venue" : "In NIPS,",
      "citeRegEx" : "11",
      "shortCiteRegEx" : "11",
      "year" : 2016
    }, {
      "title" : "Mixing time estimation in reversible Markov chains from a single sample path",
      "author" : [ "Daniel J. Hsu", "Aryeh Kontorovich", "Csaba Szepesvári" ],
      "venue" : "In NIPS,",
      "citeRegEx" : "12",
      "shortCiteRegEx" : "12",
      "year" : 2015
    }, {
      "title" : "Counting, Sampling and Integrating: Algorithms and Complexity",
      "author" : [ "Mark Jerrum" ],
      "venue" : "Lectures in Mathematics, ETH Zürich. Birkhäuser,",
      "citeRegEx" : "13",
      "shortCiteRegEx" : "13",
      "year" : 2003
    }, {
      "title" : "Polynomial-time approximation algorithms for the Ising model",
      "author" : [ "Mark Jerrum", "Alistair Sinclair" ],
      "venue" : "SIAM J. Comput.,",
      "citeRegEx" : "14",
      "shortCiteRegEx" : "14",
      "year" : 1993
    }, {
      "title" : "Conditional random fields: Probabilistic models for segmenting and labeling sequence data",
      "author" : [ "John D. Lafferty", "Andrew McCallum", "Fernando C.N. Pereira" ],
      "venue" : "In ICML,",
      "citeRegEx" : "15",
      "shortCiteRegEx" : "15",
      "year" : 2001
    }, {
      "title" : "Bounds on the l spectrum for Markov chains and markov processes: A generalization of Cheeger’s inequality",
      "author" : [ "Gregory F. Lawler", "Alan D. Sokal" ],
      "venue" : "Trans. Amer. Math. Soc.,",
      "citeRegEx" : "16",
      "shortCiteRegEx" : "16",
      "year" : 1988
    }, {
      "title" : "Markov chains and mixing times",
      "author" : [ "David A. Levin", "Yuval Peres", "Elizabeth L. Wilmer" ],
      "venue" : "American Mathematical Society, Providence, RI,",
      "citeRegEx" : "17",
      "shortCiteRegEx" : "17",
      "year" : 2009
    }, {
      "title" : "Convergence rate of incremental aggregated gradient algorithms",
      "author" : [ "Asu Ozdaglar Mert Gürbüzbalaban", "Pablo Parrilo" ],
      "venue" : "SIAM J. Optimiz.,",
      "citeRegEx" : "19",
      "shortCiteRegEx" : "19",
      "year" : 2017
    }, {
      "title" : "Exact thresholds for Ising-Gibbs samplers on general graphs",
      "author" : [ "Elchanan Mossel", "Allan Sly" ],
      "venue" : "Ann. Probab.,",
      "citeRegEx" : "20",
      "shortCiteRegEx" : "20",
      "year" : 2013
    }, {
      "title" : "Toward a noncommutative arithmetic-geometric mean inequality: Conjectures, case-studies, and consequences",
      "author" : [ "Benjamin Recht", "Christopher Ré" ],
      "venue" : "In COLT, pages 11.1–11.24,",
      "citeRegEx" : "21",
      "shortCiteRegEx" : "21",
      "year" : 2012
    }, {
      "title" : "Surprising convergence properties of some simple Gibbs samplers under various scans",
      "author" : [ "Gareth O. Roberts", "Jeffrey S. Rosenthal" ],
      "venue" : "Int. J. Stat. Probab.,",
      "citeRegEx" : "22",
      "shortCiteRegEx" : "22",
      "year" : 2015
    }, {
      "title" : "Deep boltzmann machines",
      "author" : [ "Ruslan Salakhutdinov", "Geoffrey Hinton" ],
      "venue" : "In AISTATS, pages 448–455,",
      "citeRegEx" : "23",
      "shortCiteRegEx" : "23",
      "year" : 2009
    }, {
      "title" : "Parallel distributed processing: Explorations in the microstructure of cognition",
      "author" : [ "P. Smolensky" ],
      "venue" : "Information Processing in Dynamical Systems: Foundations of Harmony Theory,",
      "citeRegEx" : "24",
      "shortCiteRegEx" : "24",
      "year" : 1986
    }, {
      "title" : "Mixing rates for the alternating Gibbs sampler over restricted Boltzmann machines and friends",
      "author" : [ "Christopher Tosh" ],
      "venue" : "In ICML,",
      "citeRegEx" : "25",
      "shortCiteRegEx" : "25",
      "year" : 2016
    } ],
    "referenceMentions" : [ {
      "referenceID" : 21,
      "context" : "Introduction Gibbs sampling, or the Markov chain Monte Carlo method in general, plays a central role in machine learning and have been widely implemented as the backbone algorithm for models such as Deep Boltzmann Machines [23], latent Dirichlet allocations [2], and factor graphs in general.",
      "startOffset" : 223,
      "endOffset" : 227
    }, {
      "referenceID" : 1,
      "context" : "Introduction Gibbs sampling, or the Markov chain Monte Carlo method in general, plays a central role in machine learning and have been widely implemented as the backbone algorithm for models such as Deep Boltzmann Machines [23], latent Dirichlet allocations [2], and factor graphs in general.",
      "startOffset" : 258,
      "endOffset" : 261
    }, {
      "referenceID" : 12,
      "context" : "Although most theoretical development on analyzing Gibbs sampling deals with random updates [13, 17], systematic scans are prevalent in real-world implementations due to their hardware-friendly nature (cache locality for factor graphs, SIMD for Deep Boltzmann Machines, etc.",
      "startOffset" : 92,
      "endOffset" : 100
    }, {
      "referenceID" : 16,
      "context" : "Although most theoretical development on analyzing Gibbs sampling deals with random updates [13, 17], systematic scans are prevalent in real-world implementations due to their hardware-friendly nature (cache locality for factor graphs, SIMD for Deep Boltzmann Machines, etc.",
      "startOffset" : 92,
      "endOffset" : 100
    }, {
      "referenceID" : 10,
      "context" : "The mixing time of these two update strategies can differ by some high polynomial factors in either directions [11, 22].",
      "startOffset" : 111,
      "endOffset" : 119
    }, {
      "referenceID" : 20,
      "context" : "The mixing time of these two update strategies can differ by some high polynomial factors in either directions [11, 22].",
      "startOffset" : 111,
      "endOffset" : 119
    }, {
      "referenceID" : 7,
      "context" : "Even more pathological examples were constructed for non-Gibbs Markov chains such that systematic scan is not even ergodic whereas the random-update sampler is rapidly mixing [8].",
      "startOffset" : 175,
      "endOffset" : 178
    }, {
      "referenceID" : 2,
      "context" : "As a consequence, theoretical results on rapidly mixing, such as [3, 20], do not readily apply to the scan algorithms used in practice.",
      "startOffset" : 65,
      "endOffset" : 72
    }, {
      "referenceID" : 18,
      "context" : "As a consequence, theoretical results on rapidly mixing, such as [3, 20], do not readily apply to the scan algorithms used in practice.",
      "startOffset" : 65,
      "endOffset" : 72
    }, {
      "referenceID" : 16,
      "context" : "The relaxation time (inverse spectral gap) governs various aspects of the mixing properties of a Markov chain, and is closely related to the (total variation) mixing time [17].",
      "startOffset" : 171,
      "endOffset" : 175
    }, {
      "referenceID" : 10,
      "context" : "By focusing on bipartite systems, we are able to obtain much stronger result than recent studies in the more general setting [11].",
      "startOffset" : 125,
      "endOffset" : 129
    }, {
      "referenceID" : 4,
      "context" : "We note that standard Markov chain comparison results, such as [5], do not seem to fit into our setting.",
      "startOffset" : 63,
      "endOffset" : 66
    }, {
      "referenceID" : 21,
      "context" : "In particular, our result is a rigorous justification of the popular layer-wise scan sampler for Deep Boltzmann Machines [23].",
      "startOffset" : 121,
      "endOffset" : 125
    }, {
      "referenceID" : 22,
      "context" : "Our result also applies to other models such as Restricted Boltzmann Machines [24] and, more generally, any bipartite factor graph.",
      "startOffset" : 78,
      "endOffset" : 82
    }, {
      "referenceID" : 10,
      "context" : "[11] about the impact of the scan order on the mixing time of the Gibbs sampling.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 23,
      "context" : "Another related work is the recent analysis by Tosh [25] considering the mixing time of an alternating sampler for the Restricted Boltzmann Machine (RBM).",
      "startOffset" : 52,
      "endOffset" : 56
    }, {
      "referenceID" : 5,
      "context" : "Tosh showed that, under Dobrushin-like conditions [6], i.",
      "startOffset" : 50,
      "endOffset" : 53
    }, {
      "referenceID" : 3,
      "context" : "Known examples are usually restricted to very specific models [4] or under conditions to ensure that the correlations are sufficiently weak [7, 10, 8].",
      "startOffset" : 62,
      "endOffset" : 65
    }, {
      "referenceID" : 6,
      "context" : "Known examples are usually restricted to very specific models [4] or under conditions to ensure that the correlations are sufficiently weak [7, 10, 8].",
      "startOffset" : 140,
      "endOffset" : 150
    }, {
      "referenceID" : 9,
      "context" : "Known examples are usually restricted to very specific models [4] or under conditions to ensure that the correlations are sufficiently weak [7, 10, 8].",
      "startOffset" : 140,
      "endOffset" : 150
    }, {
      "referenceID" : 7,
      "context" : "Known examples are usually restricted to very specific models [4] or under conditions to ensure that the correlations are sufficiently weak [7, 10, 8].",
      "startOffset" : 140,
      "endOffset" : 150
    }, {
      "referenceID" : 5,
      "context" : "Typical conditions of this sort are variants of the classical Dobrushin condition [6].",
      "startOffset" : 82,
      "endOffset" : 85
    }, {
      "referenceID" : 17,
      "context" : "Another line of related research is about the scan order in stochastic gradient descent [19, 21].",
      "startOffset" : 88,
      "endOffset" : 96
    }, {
      "referenceID" : 19,
      "context" : "Another line of related research is about the scan order in stochastic gradient descent [19, 21].",
      "startOffset" : 88,
      "endOffset" : 96
    }, {
      "referenceID" : 16,
      "context" : "where the choice of the constant 1 2e is merely for convenience and is not significant [17].",
      "startOffset" : 87,
      "endOffset" : 91
    }, {
      "referenceID" : 8,
      "context" : "Instead, we use an extension developed by Fill [9].",
      "startOffset" : 47,
      "endOffset" : 50
    }, {
      "referenceID" : 4,
      "context" : "This imposes a technical difficulty as most of the theoretical tools of analyzing these chains are not suitable for irreversible chains, such as the Dirichlet form [5] or conductance bounds [14].",
      "startOffset" : 164,
      "endOffset" : 167
    }, {
      "referenceID" : 13,
      "context" : "This imposes a technical difficulty as most of the theoretical tools of analyzing these chains are not suitable for irreversible chains, such as the Dirichlet form [5] or conductance bounds [14].",
      "startOffset" : 190,
      "endOffset" : 194
    }, {
      "referenceID" : 15,
      "context" : "See for example [16].",
      "startOffset" : 16,
      "endOffset" : 20
    }, {
      "referenceID" : 10,
      "context" : "Unfortunately, this is not the case and we give an example (similar to the “two islands” example in [11]) where Tmix(PAS) Tmix(PRU ) and Trel(PAS) Trel(PRU ).",
      "startOffset" : 100,
      "endOffset" : 104
    }, {
      "referenceID" : 13,
      "context" : "The relaxation time can be similarly bounded using a standard conductance argument [14].",
      "startOffset" : 83,
      "endOffset" : 87
    }, {
      "referenceID" : 10,
      "context" : "Indeed, as shown in [11], if we scan vertices alternatingly from the left and right, rather than scanning variables layerwise, the mixing time is smaller by a factor of n.",
      "startOffset" : 20,
      "endOffset" : 24
    }, {
      "referenceID" : 14,
      "context" : "These models are popularly used in applications such as image processing [18] and natural language processing [15].",
      "startOffset" : 110,
      "endOffset" : 114
    }, {
      "referenceID" : 9,
      "context" : "0 2 4 6 8 10 12 # Variables (b) RBM Factor=[0,10,10,10] 1E+0 1E+1 1E+2 1E+3 1E+4 1E+5 1E+6",
      "startOffset" : 43,
      "endOffset" : 55
    }, {
      "referenceID" : 9,
      "context" : "0 2 4 6 8 10 12 # Variables (b) RBM Factor=[0,10,10,10] 1E+0 1E+1 1E+2 1E+3 1E+4 1E+5 1E+6",
      "startOffset" : 43,
      "endOffset" : 55
    }, {
      "referenceID" : 9,
      "context" : "0 2 4 6 8 10 12 # Variables (b) RBM Factor=[0,10,10,10] 1E+0 1E+1 1E+2 1E+3 1E+4 1E+5 1E+6",
      "startOffset" : 43,
      "endOffset" : 55
    }, {
      "referenceID" : 0,
      "context" : "In general, it is hard under certain complexity assumptions [1] and lower bounds have been established for more concrete settings [12] (see also [12] for a comprehensive survey on this topic).",
      "startOffset" : 60,
      "endOffset" : 63
    }, {
      "referenceID" : 11,
      "context" : "In general, it is hard under certain complexity assumptions [1] and lower bounds have been established for more concrete settings [12] (see also [12] for a comprehensive survey on this topic).",
      "startOffset" : 130,
      "endOffset" : 134
    }, {
      "referenceID" : 11,
      "context" : "In general, it is hard under certain complexity assumptions [1] and lower bounds have been established for more concrete settings [12] (see also [12] for a comprehensive survey on this topic).",
      "startOffset" : 145,
      "endOffset" : 149
    }, {
      "referenceID" : 10,
      "context" : "[11] and is asymptotically the worst case of Theorem 1.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 18,
      "context" : "We choose our parameters to stay within the rapidly mixing regime [20] and avoid exponential mixing times.",
      "startOffset" : 66,
      "endOffset" : 70
    } ],
    "year" : 2017,
    "abstractText" : "For Markov chain Monte Carlo methods, one of the greatest discrepancies between theory and system is the scan order — while most theoretical development on the mixing time analysis deals with random updates, real-world systems are implemented with systematic scans. We bridge this gap for models that exhibit a bipartite structure, including, most notably, the Restricted/Deep Boltzmann Machine. The de facto implementation for these models scans variables in a layer-wise fashion. We show that the Gibbs sampler with a layerwise alternating scan order has its relaxation time (in terms of epochs) no larger than that of a random-update Gibbs sampler (in terms of variable updates). We also construct examples to show that this bound is asymptotically tight. Through standard inequalities, our result also implies a comparison on the mixing times.",
    "creator" : "LaTeX with hyperref package"
  }
}