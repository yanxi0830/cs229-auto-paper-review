{
  "name" : "1601.01974.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "Scale-Free Online Learning",
    "authors" : [ "Francesco Orabona", "Dávid Pál" ],
    "emails" : [ "francesco@orabona.com", "dpal@yahoo-inc.com" ],
    "sections" : [ {
      "heading" : null,
      "text" : "ar X\niv :1\n60 1.\n01 97\n4v 2\n[ cs\n.L G\n] 1\n4 D\nWe design and analyze algorithms for online linear optimization that have optimal regret and at the same time do not need to know any upper or lower bounds on the norm of the loss vectors. Our algorithms are instances of the Follow the Regularized Leader (FTRL) and Mirror Descent (MD) meta-algorithms. We achieve adaptiveness to the norms of the loss vectors by scale invariance, i.e., our algorithms make exactly the same decisions if the sequence of loss vectors is multiplied by any positive constant. The algorithm based on FTRL works for any decision set, bounded or unbounded. For unbounded decisions sets, this is the first adaptive algorithm for online linear optimization with a non-vacuous regret bound. In contrast, we show lower bounds on scale-free algorithms based on MD on unbounded domains."
    }, {
      "heading" : "1. Introduction",
      "text" : "Online Linear Optimization (OLO) is a problem where an algorithm repeatedly chooses a point wt from a convex decision set K, observes an arbitrary, or even adversarially chosen, loss vector ℓt and suffers the loss 〈ℓt, wt〉. The goal of the algorithm is to have a small cumulative loss. The performance of an algorithm is evaluated by the so-called regret, which is the difference of the cumulative losses of the algorithm and of the (hypothetical) strategy that would choose in every round the same best point in hindsight.\nOLO is a fundamental problem in machine learning [2, 3, 4]. Many learning problems can be directly phrased as OLO, e.g., learning with expert advice [5, 6, 7, 8] and online combinatorial optimization [9, 10, 11]. Other problems can be reduced to OLO, e.g., online convex optimization [12], [4, Chapter 2], online\n✩A preliminary version of this paper [1] was presented at ALT 2015. ∗Work done while at Yahoo Research.\n∗∗Corresponding author Email addresses: francesco@orabona.com (Francesco Orabona), dpal@yahoo-inc.com\n(Dávid Pál)\nPreprint submitted to Elsevier December 15, 2016\nclassification [13, 14] and regression [15], [2, Chapters 11 and 12], multi-armed bandits problems [2, Chapter 6], [16, 17], and batch and stochastic optimization of convex functions [18, 19]. Hence, a result in OLO immediately implies other results in all these domains.\nThe adversarial choice of the loss vectors received by the algorithm is what makes the OLO problem challenging. In particular, if an OLO algorithm commits to an upper bound on the norm of future loss vectors, its regret can be made arbitrarily large through an adversarial strategy that produces loss vectors with norms that exceed the upper bound.\nFor this reason, most of the existing OLO algorithms receive as an input— or implicitly assume—an upper bound B on the norm of the loss vectors. The input B is often disguised as the learning rate, the regularization parameter, or the parameter of strong convexity of the regularizer. However, these algorithms have two obvious drawbacks.\nFirst, they do not come with any regret guarantee for sequences of loss vectors with norms exceeding B. Second, on sequences of loss vectors with norms bounded by b ≪ B, these algorithms fail to have an optimal regret guarantee that depends on b rather than on B.\n1 Even if, in principle the FTRL-Proximal algorithm can be used with any proximal regularizer, to the best of our knowledge a general way to construct proximal regularizers is not known. The only proximal regularizer we are aware is based on the 2-norm.\n2 These algorithms attempt to produce an invariant sequence of predictions 〈wt, ℓt〉, rather than a sequence of invariant wt.\nThere is a clear practical need to design algorithms that adapt automatically to the norms of the loss vectors. A natural, yet overlooked, design method to achieve this type of adaptivity is by insisting to have a scale-free algorithm. That is, with the same parameters, the sequence of decisions of the algorithm does not change if the sequence of loss vectors is multiplied by a positive constant. The most important property of scale-free algorithms is that both their loss and their regret scale linearly with the maximum norm of the loss vector appearing in the sequence."
    }, {
      "heading" : "1.1. Previous results",
      "text" : "The majority of the existing algorithms for OLO are based on two generic algorithms: Follow The Regularizer Leader (FTRL) and Mirror Descent (MD). FTRL dates back to the potential-based forecaster in [2, Chapter 11] and its theory was developed in [28]. The name Follow The Regularized Leader comes from [16]. Independently, the same algorithm was proposed in [29] for convex optimization under the name Dual Averaging and rediscovered in [21] for online convex optimization. Time-varying regularizers were analyzed in [24] and the analysis tightened in [27]. MD was originally proposed in [18] and later analyzed in [30] for convex optimization. In the online learning literature it makes its first appearance, with a different name, in [15].\nBoth FTRL and MD are parametrized by a function called a regularizer. Based on different regularizers different algorithms with different properties can be instantiated. A summary of algorithms for OLO is presented in Table 1. All of them are instances of FTRL or MD.\nScale-free versions of MD include AdaGrad MD [24]. However, the AdaGrad MD algorithm has a non-trivial regret bounds only when the Bregman divergence associated with the regularizer is bounded. In particular, since a bound on the Bregman divergence implies that the decision set is bounded, the regret bound for AdaGrad MD is vacuous for unbounded sets. In fact, as we show in Section 4.1, AdaGrad MD and similar algorithms based on MD incurs Ω(T ) regret, in the worst case, if the Bregman divergence is not bounded.\nOnly one scale-free algorithm based on FTRL was known. It is the AdaHedge [25] algorithm for learning with expert advice, where the decision set is bounded. An algorithm based on FTRL that is “almost” scale-free isAdaGrad FTRL [24]. This algorithm fail to be scale-free due to “off-by-one” issue; see [23] and the discussion in Section 3. Instead, FTRL-Proximal [22, 23] solves the off-by-one issue, but it requires proximal regularizers. In general, proximal regularizers do not have a simple form and even the simple 2-norm case requires bounded domains to achieve non-vacuous regret.\nFor unbounded decision sets no scale-free algorithm with a non-trivial regret bound was known. Unbounded decision sets are practically important (see, e.g., [31]), since learning of large-scale linear models (e.g., logistic regression) is done by gradient methods that can be reduced to OLO with decision set Rd."
    }, {
      "heading" : "1.2. Overview of the Results",
      "text" : "We design and analyze two scale-free algorithms: SOLO FTRL and ScaleFree MD. A third one, AdaFTRL, is presented in the Appendix. SOLO FTRL and AdaFTRL are based on FTRL. AdaFTRL is a generalization of AdaHedge [25] to arbitrary strongly convex regularizers. SOLO FTRL can be viewed as the “correct” scale-free version of the diagonal version of AdaGrad FTRL [24] generalized to arbitrary strongly convex regularizers. Scale-Free MD is based on MD. It is a generalization of AdaGrad MD [24] to arbitrary strongly convex regularizers. The three algorithms are presented in Sections 3 and 4, and Appendix B, respectively.\nWe prove that the regret of SOLO FTRL and AdaFTRL on bounded do-\nmains after T rounds is bounded by O( √ supv∈K f(v) ∑T t=1 ‖ℓt‖2∗) where f is a non-negative regularizer that is 1-strongly convex with respect to a norm ‖·‖ and ‖·‖∗ is its dual norm. For Scale-Free MD, we proveO( √ supu,v∈K Bf (u, v) ∑T t=1 ‖ℓt‖2∗) where Bf is the Bregman divergence associated with a 1-strongly convex regu-\nlarizer f . In Section 5, we show that the √∑T t=1 ‖ℓt‖2∗ term in the bounds is\nnecessary by proving a D√ 8 √∑T t=1 ‖ℓt‖2∗ lower bound on the regret of any algorithm for OLO for any decision set with diameter D with respect to the primal norm ‖ · ‖.\nFor SOLO FTRL, we prove that the regret against a competitor u ∈ K is at most O(f(u) √∑T t=1 ‖ℓt‖2∗ + maxt=1,2,...,T ‖ℓt‖∗ √ T ). As before, f is a non-negative 1-strongly convex regularizer. This bound is non-trivial for any decision set, bounded or unbounded. The result makes SOLO FTRL the first adaptive algorithm for unbounded decision sets with a non-trivial regret bound.\nAll three algorithms are any-time, i.e., they do not need to know the number of rounds, T , in advance and the regret bounds hold for all T simultaneously.\nOur proof techniques rely on new homogeneous inequalities (Lemmas 3, 7) which might be of independent interest.\nFinally, in Section 4.1, we show negative results for existing popular variants of MD. We show two examples of decision sets and sequences of loss vectors of unit norm on which these variants of MD have Ω(T ) regret. These results indicate that FTRL is superior to MD in a worst-case sense."
    }, {
      "heading" : "2. Notation and Preliminaries",
      "text" : "Let V be a finite-dimensional3 real vector space equipped with a norm ‖ · ‖. We denote by V ∗ its dual vector space. The bi-linear map associated with (V ∗, V ) is denoted by 〈·, ·〉 : V ∗ × V → R. The dual norm of ‖ · ‖ is ‖ · ‖∗.\n3Many, but not all, of our results can be extended to more general normed vector spaces.\nIn OLO, in each round t = 1, 2, . . . , the algorithm chooses a point wt in the decision set K ⊆ V and then the algorithm observes a loss vector ℓt ∈ V ∗. The instantaneous loss of the algorithm in round t is 〈ℓt, wt〉. The cumulative loss of the algorithm after T rounds is ∑T t=1〈ℓt, wt〉. The regret of the algorithm with respect to a point u ∈ K is\nRegretT (u) =\nT∑\nt=1\n〈ℓt, wt〉 − T∑\nt=1\n〈ℓt, u〉,\nand the regret with respect to the best point is RegretT = supu∈K RegretT (u). We assume that K is a non-empty closed convex subset of V . Sometimes we will assume that K is also bounded. We denote by D its diameter with respect to ‖ · ‖, i.e., D = supu,v∈K ‖u− v‖. If K is unbounded, D = +∞."
    }, {
      "heading" : "2.1. Convex Analysis",
      "text" : "The Bregman divergence of a convex differentiable function f is defined as Bf(u, v) = f(u) − f(v) − 〈∇f(v), u − v〉. Note that Bf(u, v) ≥ 0 for any u, v which follows directly from the definition of convexity of f .\nThe Fenchel conjugate of a function f : K → R is the function f∗ : V ∗ → R∪{+∞} defined as f∗(ℓ) = supw∈K (〈ℓ, w〉 − f(w)). The Fenchel conjugate of any function is convex (since it is a supremum of affine functions) and satisfies the Fenchel-Young inequality\n∀w ∈ K, ∀ℓ ∈ V ∗ f(w) + f∗(ℓ) ≥ 〈ℓ, w〉 .\nMonotonicity of Fenchel conjugates follows easily from the definition: If f, g : K → R satisfy f(w) ≤ g(w) for all w ∈ K then f∗(ℓ) ≥ g∗(ℓ) for every ℓ ∈ V ∗.\nGiven λ > 0, a function f : K → R is called λ-strongly convex with respect to a norm ‖ · ‖ if and only if, for all x, y ∈ K,\nf(y) ≥ f(x) + 〈∇f(x), y − x〉+ λ 2 ‖x− y‖2 ,\nwhere ∇f(x) is any subgradient of f at the point x. The following proposition relates the range of values of a strongly convex function to the diameter of its domain. The proof can be found in Appendix A.\nProposition 1 (Diameter vs. Range). Let K ⊆ V be a non-empty bounded closed convex set. Let D = supu,v∈K ‖u − v‖ be its diameter with respect to ‖ · ‖. Let f : K → R be a non-negative lower semi-continuous function that is 1-strongly convex with respect to ‖ · ‖. Then, D ≤ √ 8 supv∈K f(v).\nFenchel conjugates and strongly convex functions have certain nice properties, which we list in Proposition 2 below.\nAlgorithm 1 FTRL with Varying Regularizer Require: Non-empty closed convex set K ⊆ V 1: Initialize L0 ← 0 2: for t = 1, 2, 3, . . . do 3: Choose a regularizer Rt : K → R 4: wt ← argminw∈K (〈Lt−1, w〉+Rt(w)) 5: Predict wt 6: Observe ℓt ∈ V ∗ 7: Lt ← Lt−1 + ℓt 8: end for\nProposition 2 (Fenchel Conjugates of Strongly Convex Functions). Let K ⊆ V be a non-empty closed convex set with diameter D := supu,v∈K ‖u− v‖. Let λ > 0, and let f : K → R be a lower semi-continuous function that is λ-strongly convex with respect to ‖ · ‖. The Fenchel conjugate of f satisfies:\n1. f∗ is finite everywhere and differentiable everywhere. 2. For any ℓ ∈ V ∗, ∇f∗(ℓ) = argminw∈K (f(w)− 〈ℓ, w〉). 3. For any ℓ ∈ V ∗, f∗(ℓ) + f(∇f∗(ℓ)) = 〈ℓ,∇f∗(ℓ)〉. 4. f∗ is 1λ -strongly smooth, i.e., for any x, y ∈ V ∗, Bf∗(x, y) ≤ 12λ‖x− y‖2∗. 5. f∗ has 1λ -Lipschitz continuous gradients, i.e., for any x, y ∈ V ∗, ‖∇f∗(x)−\n∇f∗(y)‖ ≤ 1λ‖x− y‖∗. 6. Bf∗(x, y) ≤ D‖x− y‖∗ for any x, y ∈ V ∗. 7. ‖∇f∗(x)−∇f∗(y)‖ ≤ D for any x, y ∈ V ∗. 8. For any c > 0, (cf(·))∗ = cf∗(·/c).\nExcept for properties 6 and 7, the proofs can be found in [28]. Property 6 is proven in Appendix A. Property 7 trivially follows from property 2."
    }, {
      "heading" : "2.2. Generic FTRL with Varying Regularizer",
      "text" : "Two of our scale-free algorithms are instances of FTRL with varying regularizers, presented as Algorithm 1. The algorithm is paramatrized by a sequence {Rt}∞t=1 of functions Rt : K → R called regularizers. Each regularizerRt can depend on the past loss vectors ℓ1, ℓ2, . . . , ℓt−1 in an arbitrary way. The following lemma bounds its regret.\nLemma 1 (Regret of FTRL). If the regularizers R1, R2, . . . chosen by Algorithm 1 are strongly convex and lower semi-continuous, the algorithm’s regret is upper bounded as\nRegretT (u) ≤ RT+1(u)+R∗1(0)+ T∑\nt=1\nBR∗ t (−Lt,−Lt−1)−R∗t (−Lt)+R∗t+1(−Lt) .\nThe proof of the lemma can be found in [27]. For completeness, we include it in Appendix A.\nAlgorithm 2 Mirror Descent with Varying Regularizer Require: Non-empty closed convex set K ⊆ V 1: Choose a regularizer R0 : K → R 2: w1 ← argminw∈K R0(w) 3: for t = 1, 2, 3, . . . do 4: Predict wt 5: Observe ℓt ∈ V ∗ 6: Choose a regularizer Rt : K → R 7: wt+1 ← argminw∈K (〈ℓt, w〉 + BRt(w,wt)) 8: end for"
    }, {
      "heading" : "2.3. Generic Mirror Descent with Varying Regularizer",
      "text" : "Mirror Descent (MD) is a generic algorithm similar to FTRL but quite different in the details. The algorithm is stated as Algorithm 2. The algorithm is parametrized by a sequence {Rt}∞t=0 of convex functions Rt : K → R called regularizers. Each regularizer Rt can depend on past loss vectors ℓ1, ℓ2, . . . , ℓt in an arbitrary way. If Rt is not differentiable,\n4 the Bregman divergence, BRt(u, v) = Rt(u)−Rt(v)−〈∇Rt(v), u−v〉 needs to be defined. This is done by choosing a subgradient map ∇Rt : K → V , i.e., a function such that ∇Rt(w) is a subgradient of Rt at any point w. If Rt is a restriction of a differentiable function R′t, it is convenient to define ∇Rt(w) = ∇R′t(w) for all w ∈ K. The following lemma bounds the regret of MD.\nLemma 2 (Regret of MD). Algorithm 2 satisfies, for any u ∈ K,\nRegretT (u) ≤ T∑\nt=1\n〈ℓt, wt − wt+1〉 − BRt(wt+1, wt) + BRt(u,wt)− BRt(u,wt+1) .\nThe proof of the lemma can be found in [3, 32]. For completeness, we give a proof in Appendix E."
    }, {
      "heading" : "2.4. Per-Coordinate Learning",
      "text" : "An interesting class of algorithms proposed in [22] and [24] are based on socalled per-coordinate learning rates. As shown in [33], any algorithm for OLO can be used with per-coordinate learning rates as well.\nAbstractly, we assume that the decision set is a Cartesian product K = K1 × K2 × · · · × Kd of a finite number of convex sets. On each factor Kj , j = 1, 2, . . . , d, we can run any OLO algorithm separately and we denote by\n4Note that this can happen even when Rt is a restriction of a differentiable function defined on a superset of K. If K is bounded and closed, Rt fails to be differentiable at the boundary of K. If K is a subset of an affine subspace of a dimension smaller than the dimension of V , then Rt fails to be differentiable everywhere.\nRegret (j) T (uj) its regret with respect to uj ∈ Kj. The overall regret with respect to any u = (u1, u2, . . . , ud) ∈ K can be written as\nRegretT (u) =\nd∑\nj=1\nRegret (j) T (uj) .\nIf the algorithm for each factor is scale-free, the overall algorithm is clearly scale-free as well. Hence, even if not explicitly mentioned in the text, any algorithm we present can be trivially transformed to a per-coordinate version."
    }, {
      "heading" : "3. SOLO FTRL",
      "text" : "In this section, we introduce our first scale-free algorithm; it will be based on FTRL. The closest algorithm to a scale-free FTRL in the existing literature is the AdaGrad FTRL algorithm [24]. It uses a regularizer on each coordinate of the form\nRt(w) = R(w)\n\nδ +\n√√√√ t−1∑\ni=1\n‖ℓi‖2∗\n\n .\nThis kind of regularizer would yield a scale-free algorithm only for δ = 0. In fact, with this choice of δ it is easy to see that the predictions wt in line 4 of Algorithm 1 would be independent of the scaling of the ℓt. Unfortunately, the regret bound in [24] becomes vacuous for such setting in the unbounded case. In fact, it requires δ to be greater than ‖ℓt‖∗ for all time steps t, requiring knowledge of the future (see Theorem 5 in [24]). In other words, despite of its name, AdaGrad FTRL is not fully adaptive to the norm of the gradient vectors. Similar considerations hold for the FTRL-Proximal in [22, 23]: The scale-free setting of the learning rate is valid only in the bounded case.\nOne simple approach would be to use a doubling trick on δ in order to estimate on the fly the maximum norm of the losses. Note that a naive strategy would still fail because the initial value of δ should be data-dependent in order to have a scale-free algorithm. Moreover, we would have to upper bound the regret in all the rounds where the norm of the current loss is bigger than the estimate. Finally, the algorithm would depend on an additional parameter, the “doubling” power. Hence, even in the case one would prove a regret bound, such strategy would give the feeling that FTRL needs to be “fixed” in order to obtain a scale-free algorithm.\nIn the following, we propose a much simpler and better approach. We propose to use Algorithm 1 with the regularizer\nRt(w) = R(w)\n√√√√ t−1∑\ni=1\n‖ℓi‖2∗ , (1)\nwhere R : K → R is any strongly convex function. Through a refined analysis, we show that this regularizer suffices to obtain an optimal regret bound for any\ndecision set, bounded or unbounded. We call this variant Scale-free Online Linear Optimization FTRL algorithm (SOLO FTRL). Our main result is Theorem 1 below, which is proven in Section 3.1.\nThe regularizer (1) does not uniquely define the FTRL minimizer wt =\nargminw∈K Rt(w) when √∑t−1\ni=1 ‖ℓi‖2∗ is zero. This happens if ℓ1, ℓ2, . . . , ℓt−1 are all zero (and in particular for t = 1). In that case, we define wt = argminw∈K R(w) which is consistent with wt = lima→0+ argminw∈K aR(w).\nTheorem 1 (Regret of SOLO FTRL). Suppose K ⊆ V is a non-empty closed convex set. Let D = supu,v∈K ‖u − v‖ be its diameter with respect to a norm ‖ · ‖. Suppose that the regularizer R : K → R is a non-negative lower semi-continuous function that is λ-strongly convex with respect to ‖ · ‖. The regret of SOLO FTRL satisfies\nRegretT (u) ≤ ( R(u) + 2.75\nλ\n) √√√√ T∑\nt=1\n‖ℓt‖2∗ + 3.5min {√ T − 1 λ ,D } max t≤T ‖ℓt‖∗ .\nWhen K is unbounded, we pay a penalty that scales as maxt≤T ‖ℓt‖∗ √ T , that has the same magnitude of the first term in the bound. On the other hand, when K is bounded, the second term is a constant and we can choose the optimal multiple of the regularizer. We choose R(w) = λf(w) where f is a 1-strongly convex function and optimize λ. The result of the optimization is Corollary 1.\nCorollary 1 (Regret Bound for Bounded Decision Sets). Suppose K ⊆ V is a non-empty bounded closed convex set. Suppose that f : K → R is a nonnegative lower semi-continuous function that is 1-strongly convex with respect to ‖ · ‖. SOLO FTRL with regularizer\nR(w) = f(w) √ 2.75√\nsupv∈K f(v) satisfies RegretT ≤ 13.3 √√√√sup v∈K f(v) T∑\nt=1\n‖ℓt‖2∗ .\nProof. Let S = supv∈K f(v). Theorem 1 applied to the regularizer R(w) = c√ S f(w), together with Proposition 1 and a crude bound maxt=1,2,...,T ‖ℓt‖∗ ≤√∑T t=1 ‖ℓt‖2∗, give\nRegretT ≤ ( c+ 2.75\nc + 3.5\n√ 8 ) √√√√S T∑\nt=1\n‖ℓt‖2∗ .\nWe choose c by minimizing g(c) = c+ 2.75c +3.5 √ 8. Clearly, g(c) has minimum\nat c = √ 2.75 and has minimal value g( √ 2.75) = 2 √ 2.75 + 3.5 √ 8 ≤ 13.3.\n3.1. Proof of Regret Bound for SOLO FTRL\nThe proof of Theorem 1 relies on an inequality (Lemma 3). Related and weaker inequalities, like Lemma 4, were proved in [34] and [35]. The main property of this inequality is that on the right-hand side C does not multiply the √∑T\nt=1 a 2 t term.\nLemma 3 (Useful Inequality). Let C, a1, a2, . . . , aT ≥ 0. Then,\nT∑\nt=1\nmin   \na2t√∑t−1 i=1 a 2 i , Cat\n   ≤ 3.5C maxt=1,2,...,T at + 3.5 √√√√ T∑\nt=1\na2t .\nProof. Without loss of generality, we can assume that at > 0 for all t. Since otherwise we can remove all at = 0 without affecting either side of the inequality. Let Mt = max{a1, a2, . . . , at} and M0 = 0. We prove that for any α > 1\nmin\n   a2t√∑t−1 i=1 a 2 i , Cat    ≤ 2 √ 1 + α2   √√√√ t∑ i=1 a2i − √√√√ t−1∑ i=1 a2i  +Cα(Mt −Mt−1) α− 1\nfrom which the inequality follows by summing over t = 1, 2, . . . , T and choosing α = √ 2. The inequality follows by case analysis. If a2t ≤ α2 ∑t−1 i=1 a 2 i , we have\nmin   \na2t√∑t−1 i=1 a 2 i , Cat\n   ≤\na2t√∑t−1 i=1 a 2 i = a2t√\n1 1+α2\n( α2 ∑t−1 i=1 a 2 i + ∑t−1 i=1 a 2 i )\n≤ a 2 t √ 1 + α2√\na2t + ∑t−1 i=1 a 2 i = a2t √ 1 + α2√∑t i=1 a 2 i ≤ 2 √ 1 + α2\n\n\n√√√√ t∑\ni=1\na2i −\n√√√√ t−1∑\ni=1\na2i\n\n\nwhere we have used x2/ √ x2 + y2 ≤ 2( √ x2 + y2 − √ y2) in the last step. On the other hand, if a2t > α 2 ∑t−1 t=1 a 2 i , we have\nmin\n   a2t√∑t−1 i=1 a 2 i , Cat    ≤ Cat = C αat − at α− 1 ≤ C α− 1  αat − α √√√√ t−1∑ i=1 a2i  \n= Cα\nα− 1\n at − √√√√ t−1∑\ni=1\na2i\n  ≤ Cα\nα− 1 (at −Mt−1) = Cα α− 1 (Mt −Mt−1)\nwhere we have used that at = Mt and √∑t−1 i=1 a 2 i ≥ Mt−1.\nLemma 4 ([34, Lemma 3.5]). Let a1, a2, . . . , aT be non-negative real numbers. If a1 > 0 then,\nT∑\nt=1 at√∑t i=1 ai ≤ 2\n√√√√ T∑\nt=1\nat .\nFor completeness, a proof of Lemma 4 is in Appendix D.\nProof (Proof of Theorem 1). Let ηt = 1√∑\nt−1 i=1 ‖ℓi‖2∗\n, henceRt(w) = 1 ηt R(w).\nWe assume without loss of generality that ‖ℓt‖∗ > 0 for all t, since otherwise we can remove all rounds t where ℓt = 0 without affecting the regret and the predictions of the algorithm on the remaining rounds. By Lemma 1,\nRegretT (u) ≤ 1\nηT+1 R(u) +\nT∑\nt=1\n( BR∗ t (−Lt,−Lt−1)−R∗t (−Lt) +R∗t+1(−Lt) ) .\nWe upper bound the terms of the sum in two different ways. First, by Proposition 2, we have\nBR∗ t (−Lt,−Lt−1)−R∗t (−Lt) +R∗t+1(−Lt) ≤ BR∗t (−Lt,−Lt−1) ≤ ηt‖ℓt‖2∗ 2λ .\nSecond, we have\nBR∗ t (−Lt,−Lt−1)−R∗t (−Lt) +R∗t+1(−Lt) = BR∗ t+1 (−Lt,−Lt−1) +R∗t+1(−Lt−1)−R∗t (−Lt−1)\n+ 〈∇R∗t (−Lt−1)−∇R∗t+1(−Lt−1), ℓt〉\n≤ ηt+1‖ℓt‖ 2 ∗\n2λ + ‖∇R∗t (−Lt−1)−∇R∗t+1(−Lt−1)‖ · ‖ℓt‖∗\n= ηt+1‖ℓt‖2∗\n2λ + ‖∇R∗(−ηtLt−1)−∇R∗(−ηt+1Lt−1)‖ · ‖ℓt‖∗\n≤ ηt+1‖ℓt‖ 2 ∗\n2λ +min\n{ 1\nλ ‖Lt−1‖∗ (ηt − ηt+1) , D\n} ‖ℓt‖∗ ,\nwhere in the first inequality we have used the fact thatR∗t+1(−Lt−1) ≤ R∗t (−Lt−1), Hölder’s inequality, and Proposition 2. In the second inequality we have used properties 5 and 7 of Proposition 2. Using the definition of ηt+1 we have\n‖Lt−1‖∗(ηt − ηt+1) λ ≤ ‖Lt−1‖∗ λ √∑t−1 i=1 ‖ℓi‖2∗ ≤\n∑t−1 i=1 ‖ℓi‖∗\nλ √∑t−1 i=1 ‖ℓi‖2∗ ≤\n√ t− 1 λ ≤ √ T − 1 λ .\nDenoting by H = min {√\nT−1 λ , D\n} we have\nRegretT (u) ≤ 1\nηT+1 R(u) +\nT∑\nt=1\nmin { ηt‖ℓt‖2∗ 2λ , H‖ℓt‖∗ + ηt+1‖ℓt‖2∗ 2λ }\n≤ 1 ηT+1 R(u) + 1 2λ\nT∑\nt=1\nηt+1‖ℓt‖2∗ + 1\n2λ\nT∑\nt=1\nmin { ηt‖ℓt‖2∗, 2λH‖ℓt‖∗ }\n= 1\nηT+1 R(u) +\n1\n2λ\nT∑\nt=1 ‖ℓt‖2∗√∑t i=1 ‖ℓi‖2∗ + 1 2λ\nT∑\nt=1\nmin\n   ‖ℓt‖2∗√∑t−1 i=1 ‖ℓi‖2∗ , 2λH‖ℓt‖∗    .\nWe bound each of the three terms separately. By definition of ηT+1, the first\nterm is 1ηT+1R(u) = R(u) √∑T t=1 ‖ℓt‖2∗. We upper bound the second term using Lemma 4 as\n1\n2λ\nT∑\nt=1 ‖ℓt‖2∗√∑t i=1 ‖ℓi‖2∗ ≤ 1 λ\n√√√√ T∑\nt=1\n‖ℓt‖2∗ .\nFinally, by Lemma 3 we upper bound the third term as\n1\n2λ\nT∑\nt=1\nmin   \n‖ℓt‖2∗√∑t−1 i=1 ‖ℓi‖2∗ , 2λ‖ℓt‖∗H\n   ≤ 3.5Hmaxt≤T ‖ℓt‖∗ + 1.75 λ √√√√ T∑\nt=1\n‖ℓt‖2∗ .\nPutting everything together gives the stated bound."
    }, {
      "heading" : "4. Scale-Free Mirror Descent",
      "text" : "In this section, we analyze scale-free version of Mirror Descent. Our algorithm uses the regularizer\nRt(w) = R(w)\n√√√√ t∑\ni=1\n‖ℓi‖2∗ , (2)\nwhere R : K → R an arbitrary strongly convex function. As for SOLO FTRL, it is easy to see that such regularizer gives rise to predictions wt that are scalefree. We call the resulting algorithm Scale-Free MD. Similar to SOLO FTRL, the regularizer (2) does not uniquely define the MD minimizer wt+1 =\nargminw∈K (〈ℓt, w〉 + BRt(w,wt)) when √∑t\ni=1 ‖ℓi‖2∗ is zero. This happens when the loss vectors ℓ1, ℓ2, . . . , ℓt are all zero. In this case, we define wt+1 = argminw∈K R(w) which agrees with wt+1 = lima→0+ argminw∈K aBR(w,wt). Similarly, w1 = argminw∈K R(w).\nPer-coordinate version of Scale-Free MD with regularizer R(w) = 12‖w‖ 2 2 is exactly the same algorithm as the diagonal version of AdaGrad MD [24]. The theorem below upper bounds the regret of Scale-Free MD (see also [24, 32, 36]). The proof is in Appendix E.\nTheorem 2 (Regret of Scale-Free Mirror Descent). Suppose K ⊆ V is a non-empty closed convex set. Suppose that R : K → R is a λ-strongly convex function with respect to a norm ‖ · ‖. Scale-Free MD with regularizer R satisfies for any u ∈ K,\nRegretT (u) ≤ ( 1\nλ + sup v∈K BR(u, v)\n) √√√√ T∑\nt=1\n‖ℓt‖2∗ .\nWe choose the regularizer R(w) = λf(w) where f is a 1-strongly convex function and optimize λ. The result is the following Corollary. Its proof is trivial.\nCorollary 2 (Regret of Scale-Free Mirror Descent). Suppose K ⊆ V is a non-empty bounded closed convex set. Suppose that f : K → R is a 1-strongly convex function with respect to a norm ‖ · ‖. Scale-Free MD with regularizer\nR(w) = f(w)√\nsup u,v∈K\nBf (u, v) satisfies RegretT ≤ 2 √√√√ sup u,v∈K Bf(u, v) T∑ t=1 ‖ℓt‖2∗ .\nThe regret bound for Scale-Free MD in the Corollary 2 depends on supu,v∈K Bf(u, v). In contrast, the regret bound for SOLO FTRL in Corollary 1 depend on supu∈K f(u). Similarly, the regret bound in Theorem 2 for Scale-Free MD depends on supv∈K BR(u, v) and the regret bounds in Theorem 1 for SOLO FTRL depend on R(u). It is not hard to show that\n∀u ∈ K R(u) ≤ sup v∈K BR(u, v) , (3)\nprovided that at the minimizer v∗ = argminv∈K R(v) both R(v ∗) and ∇R(v∗) are zero. Indeed, in that case, R(u) = BR(u, v∗) ≤ supv∈K BR(u, v). The assumption R(v∗) = 0 and ∇R(v∗) = 0 are easy to achieve by adding an affine function to the regularizer:\nR′(u) = R(u)− 〈∇R(v∗), u− v∗〉 −R(v∗) .\nThe regularizer R′ has the same parameter of strong convexity as R, the associated Bregman divergences BR′ and BR are equal, R′ and R have the same minimizer v∗, and R′(v∗) and ∇R′(v∗) are both zero.\nThus, inequality (3) implies that—ignoring constant factors—the regret bound for Scale-Free MD is inferior to the regret bound for SOLO FTRL. In fact, it is not hard to come up with examples where R(u) is finite whereas supv∈K BR(u, v) is infinite. We mention two such examples. The first example is R(w) = 12‖w‖22 defined on the whole space V , where for any u ∈ V , R(u) is a finite value but supv∈K BR(u, v) = supv∈V 12‖u−v‖22 = +∞. The second example is the shifted negative entropy regularizer R(w) = ln(d)+ ∑d j=1 wj lnwj defined\non the d-dimensional probability simplex K = {w ∈ Rd : wj ≥ 0, ∑d\nj=1 wj = 1}, where for any u ∈ K, R(u) is finite and in fact lies in the interval [0, lnd] but supv∈K BR(u, v) = supv∈K ∑d j=1 uj ln(uj/vj) = +∞. We revisit these examples in the following subsection."
    }, {
      "heading" : "4.1. Lower Bounds for Scale-Free Mirror Descent",
      "text" : "The bounds in Theorem 2 and Corollary 2 are vacuous when BR(u, v) is not bounded. One might wonder if the assumption that BR(u, v) is bounded is necessary in order for Scale-Free MD to have a sublinear regret. We show necessity of this assumption on two counter-examples. In these counterexamples, we consider strongly convex regularizers R such that BR(u, v) is not bounded and we construct sequences of loss vectors ℓ1, ℓ2, . . . , ℓT such that ‖ℓ1‖∗ = ‖ℓ2‖∗ = · · · = ‖ℓT‖∗ = 1 and Scale-Free MD has regret Ω(T ) or worse.\nThe first counter-example is stated as Theorem 3 below; our proof is in Appendix E. The decision set is the whole space K = V and the regularizer is R(w) = 12‖w‖22. Note that R(w) is 1-strongly convex with respect to ‖ · ‖2 and the dual norm of ‖ · ‖2 is ‖ · ‖2. The corresponding Bregman divergence is BR(u, v) = 12‖u− v‖22. The counter-example constructs a sequence of unit-norm loss vectors in the onedimensional subspace spanned by the first vector of the standard orthnormal basis. On such a sequence, both versions of AdaGrad MD as well as Scale-Free MD are identical to gradient descent with step size 1/ √ t, i.e., they are identical Zinkevich’s Generalized Infinitesimal Gradient Ascent (GIGA) algorithm [20]. Hence the lower bound applies to all these algorithms.\nTheorem 3 (First Counter-Example). Suppose K = V . For any T ≥ 42, there exists a sequence of loss vectors ℓ1, ℓ2, . . . , ℓT ∈ V ∗ such that ‖ℓ1‖2 = ‖ℓ2‖2 = · · · = ‖ℓT‖2 = 1 and Scale-Free MD with regularizer R(w) = 12‖w‖22, GIGA, and both versions of AdaGrad MD satisfy\nRegretT (0) ≥ T 3/2\n20 .\nThe second counter-example is stated as Theorem 4 below; our proof is in Appendix E. The decision set is the d-dimensional probability simplex K = {w ∈ Rd : wj ≥ 0, ∑d j=1 wj = 1} and the regularizer is the negative entropy R(w) = ∑d\nj=1 wj lnwj . Negative entropy is 1-strongly convex with respect to ‖·‖1 and the dual norm of ‖·‖1 is ‖ · ‖∞. The corresponding Bregman divergence is the Kullback-Leibler divergence BR(u, v) = ∑d j=1 uj ln(uj/vj). Note that despite that negative entropy is upper- and lower-bounded, Kullback-Leibler divergence can be arbitrarily large.\nTheorem 4 (Second Counter-Example). Let d ≥ 2, let V = Rd, and let K = {w ∈ V : wj ≥ 0, ∑d j=1 wj = 1} be the d-dimensional probability simplex. For any T ≥ 120, there exists a sequence of loss vectors ℓ1, ℓ2, . . . , ℓT ∈ V ∗ such\nthat ‖ℓ1‖∞ = ‖ℓ2‖∞ = · · · = ‖ℓT ‖∞ = 1 and Scale-Free MD with regularizer R(w) = ∑d j=1 wj lnwj satisfies\nRegretT ≥ T\n6 ."
    }, {
      "heading" : "5. Lower Bound",
      "text" : "We show a lower bound on the worst-case regret of any algorithm for OLO. The proof, presented in Appendix F, is a standard probabilistic argument.\nTheorem 5 (Lower Bound). Let K ⊆ V be any non-empty bounded closed convex subset. Let D = supu,v∈K ‖u − v‖ be the diameter of K. Let A be any (possibly randomized) algorithm for OLO on K. Let T be any non-negative integer and let a1, a2, . . . , aT be any non-negative real numbers. There exists a sequence of vectors ℓ1, ℓ2, . . . , ℓT in the dual vector space V\n∗ such that ‖ℓ1‖∗ = a1, ‖ℓ2‖∗ = a2, . . . , ‖ℓT ‖∗ = aT and the regret of algorithm A satisfies\nRegretT ≥ D√ 8\n√√√√ T∑\nt=1\n‖ℓt‖2∗ . (4)\nThe upper bounds on the regret, which we have proved for our algorithms, have the same dependency on the norms of the loss vectors. However, a gap remains between the lower bound and the upper bounds.\nThe upper bound on regret of SOLO FTRL is of the formO( √ supv∈K f(v) ∑T t=1 ‖ℓt‖2∗)\nwhere f is any 1-strongly convex function with respect to ‖ · ‖. The same upper bound is also achieved by FTRL with a constant learning rate when ∑T t=1 ‖ℓt‖2∗\nis known upfront [4, Chapter 2]. The lower bound is Ω(D √∑T\nt=1 ‖ℓt‖2∗). The gap between D and √ supv∈K f(v) can be substantial. For example,\nif K is the probability simplex in Rd and f(w) = ln(d) + ∑d\nj=1 wj lnwj is the shifted negative entropy, the ‖ · ‖1-diameter of K is 2, f is non-negative and 1-strongly convex with respect to ‖ · ‖1, but supv∈K f(v) = ln(d). On the other hand, if the norm ‖ · ‖2 = √ 〈·, ·〉 arises from an inner product 〈·, ·〉, the lower bound matches the upper bounds within a constant factor. The reason is that for any K with ‖ · ‖2-diameter D, the function f(w) = 12‖w−w0‖22, where w0 is an arbitrary point in K, is 1-strongly convex with respect to ‖ · ‖2 and satisfies that √ supv∈K f(v) ≤ D. This leads to the following open problem (posed also in [37]):\nGiven a bounded convex set K and a norm ‖ · ‖, construct a nonnegative function f : K → R that is 1-strongly convex with respect to ‖ · ‖ and minimizes supv∈K f(v).\nAs shown in [38], the existence of f with small supv∈K f(v) is equivalent to the\nexistence of an algorithm for OLO with Õ( √ T supv∈K f(v)) regret assuming ‖ℓt‖∗ ≤ 1. The Õ notation hides a polylogarithmic factor in T ."
    }, {
      "heading" : "6. Conclusions",
      "text" : "We have investigated scale-free algorithms for online linear optimization and we have shown that the scale-free property leads to algorithms which have optimal regret and do not need to know or assume anything about the sequence of loss vectors. In particular, the algorithms do not assume any upper or lower bounds on the norms of the loss vectors or the number of rounds.\nWe have designed a scale-free algorithm based on Follow The Regularizer Leader. Its regret with respect to any competitor u is\nO  f(u) √√√√ T∑\nt=1\n‖ℓt‖2∗ +min{ √ T ,D} max\nt=1,2,...,T ‖ℓt‖∗\n  ,\nwhere f is any non-negative 1-strongly convex function defined on the decision set and D is the diameter of the decision set. The result makes sense even when the decision set is unbounded.\nA similar, but weaker result holds for a scale-free algorithm based onMirror Descent. However, we have also shown this algorithm to be strictly weaker than algorithms based on Follow The Regularizer Leader. Namely, we gave examples of regularizers for which the scale-free version of Mirror Descent has Ω(T ) regret or worse.\nWe have proved an D√ 8 √∑T t=1 ‖ℓ‖2∗ lower bound on the regret of any algorithm for any decision set with diameter D. Notice that with the regularizer f(u) = 12‖u‖22 the regret of SOLO FTRL depends quadratically on the norm of the competitor ‖u‖2. There exist nonscale-free algorithms [39, 40, 41, 42, 43, 44] that have only a O(‖u‖2 √ log ‖u‖2) or O(‖u‖2 log ‖u‖2) dependency. These algorithms assume an a priori bound on the norm of the loss vectors. Recently, an algorithm that adapts to norms of loss vectors and has a O(‖u‖2 log ‖u‖2) dependency was proposed [45]. However, the trade-off between the dependency on ‖u‖2 and the adaptivity to the norms of the loss vectors still remains to be explored."
    }, {
      "heading" : "Acknowledgments",
      "text" : "We thank an anonymous reviewer for suggesting a simpler proof of Lemma 7."
    }, {
      "heading" : "Appendix A. Proofs for Preliminaries",
      "text" : "Proof (Proof of Proposition 1). Let S = supu∈K f(u) and v ∗ = argminv∈K f(v). The minimizer v∗ is guaranteed to exist by lower semi-continuity of f and compactness of K. The optimality condition for v∗ and 1-strong convexity of f imply that for any u ∈ K,\nS ≥ f(u)− f(v∗) ≥ f(u)− f(v∗)− 〈∇f(v∗), u− v∗〉 ≥ 1 2 ‖u− v∗‖2 .\nIn other words, ‖u− v∗‖ ≤ √ 2S. By the triangle inequality,\nD = sup u,v∈K ‖u− v‖ ≤ sup u,v∈K\n(‖u− v∗‖+ ‖v∗ − v‖) ≤ 2 √ 2S = √ 8S .\nProof (Proof of Property 6 of Proposition 2). To bound Bf∗(x, y) we add a non-negative divergence term Bf∗(y, x).\nBf∗(x, y) ≤ Bf∗(x, y) + Bf∗(y, x) = 〈x− y,∇f∗(x) −∇f∗(y)〉 ≤ ‖x− y‖∗ · ‖∇f∗(x) −∇f∗(y)‖ ≤ D‖x− y‖∗ ,\nwhere we have used Hölder’s inequality and property 7 of the Proposition.\nProof (Proof of Lemma 1). By the Fenchel-Young inequality,\nT∑\nt=1\n( R∗t+1(−Lt)−R∗t (−Lt−1) ) = R∗T+1(−LT )−R∗1(0)\n≥ −〈LT , u〉 −RT+1(u)−R∗1(0) = −RT+1(u)−R∗1(0)− T∑\nt=1\n〈ℓt, u〉 .\nWe add ∑T\nt=1〈ℓt, wt〉 to both sides and we obtain RegretT (u) on the right side. After rearrangement of the terms, we get an upper bound on the regret:\nRegretT (u) =\nT∑\nt=1\n〈ℓt, wt〉 − T∑\nt=1\n〈ℓt, u〉\n≤ RT+1(u) +R∗1(0) + T∑\nt=1\n( R∗t+1(−Lt)−R∗t (−Lt−1) + 〈ℓt, wt〉 ) .\nBy Proposition 2, property 2, we have wt = ∇R∗t (−Lt−1) and therefore we can rewrite the sum in last expression as\nT∑\nt=1\nR∗t+1(−Lt)−R∗t (−Lt−1) + 〈ℓt, wt〉\n=\nT∑\nt=1\nR∗t+1(−Lt)−R∗t (−Lt−1) + 〈ℓt,∇R∗t (−Lt−1)〉\n= T∑\nt=1\nR∗t (−Lt)−R∗t (−Lt−1) + 〈ℓt,∇R∗t (−Lt−1)〉 −R∗t (−Lt) +R∗t+1(−Lt)\n=\nT∑\nt=1\nBR∗ t (−Lt,−Lt−1)−R∗t (−Lt) +R∗t+1(−Lt) .\nThis finishes the proof."
    }, {
      "heading" : "Appendix B. AdaFTRL",
      "text" : "In this section, we show that it is possible to derive a scale-free algorithm different from SOLO FTRL. We generalize the AdaHedge algorithm [25] to the OLO setting, showing that it retains its scale-free property. We call the resulting algorithm AdaFTRL. The analysis is very general and based on general properties of strongly convex functions, rather than specific properties of the entropic regularizer as in the original analysis of AdaHedge.\nAssume that K is bounded and that R : K → R is a strongly convex lower semi-continuous function bounded from above. We instantiate Algorithm 1 with\nthe sequence of regularizers\nRt(w) = ∆t−1R(w) where ∆t = t∑\ni=1\n∆i−1BR∗ ( − Li ∆i−1 ,−Li−1 ∆i−1 ) . (B.1)\nThe sequence {∆t}∞t=0 is non-negative and non-decreasing. Also, ∆t as a function of ℓ1, ℓ2, . . . , ℓt is positive homogeneous of degree one, making the algorithm scale-free.\nIf ∆i−1 = 0, we define ∆i−1BR∗( −Li∆i−1 , −Li−1 ∆i−1 ) as lima→0+ aBR∗(−Lia , −Li−1 a ) which always exists and is finite; see Lemma 9 in Appendix C. Similarly, when ∆t−1 = 0, we define wt = argminw∈K〈Lt−1, w〉 where ties among minimizers are broken by taking the one with the smallest value of R(w), which is unique due to strong convexity. As we show in Lemma 8 in Appendix C, this is the same as wt = lima→0+ argminw∈K(〈Lt−1, w〉+ aR(w)).\nOur main result is an O( √∑T\nt=1 ‖ℓt‖2∗) upper bound on the regret of the algorithm after T rounds, without the need to know beforehand an upper bound on ‖ℓt‖∗. We prove the theorem in Appendix B.1.\nTheorem 6 (Regret Bound). Suppose K ⊆ V is a non-empty bounded closed convex set. Let D = supx,y∈K ‖x − y‖ be its diameter with respect to a norm ‖ · ‖. Suppose that the regularizer R : K → R is a non-negative lower semicontinuous function that is λ-strongly convex with respect to ‖ ·‖ and is bounded from above. The regret of AdaFTRL satisfies\nRegretT (u) ≤ √ 3max { D,\n1√ 2λ\n} √√√√ T∑\nt=1\n‖ℓt‖2∗ (1 +R(u)) .\nThe regret bound can be optimized by choosing the optimal multiple of the regularizer. Namely, we choose regularizer of the form λf(w) where f(w) is 1-strongly convex and optimize over λ. The result of the optimization is the following corollary.\nCorollary 3 (Regret Bound). Suppose K ⊆ V is a non-empty bounded closed convex set. Suppose f : K → R is a non-negative lower semi-continuous function that is 1-strongly convex with respect to ‖ · ‖ and is bounded from above. The regret of AdaFTRL with regularizer\nR(w) = f(w)\n16 · supv∈K f(v) satisfies RegretT ≤ 5.3 √√√√sup v∈K f(v) T∑\nt=1\n‖ℓt‖2∗ .\nProof. Let S = supv∈K f(v). Theorem 6 applied to the regularizer R(w) = c S f(w) and Proposition 1 gives\nRegretT ≤ √ 3(1 + c)max {√ 8,\n1√ 2c\n} √√√√S T∑\nt=1\n‖ℓt‖2∗ .\nIt remains to find the minimum of g(c) = √ 3(1 + c)max{ √ 8, 1/ √ 2c}. The function g is strictly convex on (0,∞) and has minimum at c = 1/16 and g( 116 ) = √ 3(1 + 116 ) √ 8 ≤ 5.3.\nAppendix B.1. Proof of Regret Bound for AdaFTRL Lemma 5 (Initial Regret Bound). AdaFTRL satisfies, for any u ∈ K and any T ≥ 0, RegretT (u) ≤ (1 +R(u))∆T . Proof. Recall from (B.1) that Rt(w) = ∆t−1R(w). Since R is non-negative, {Rt}∞t=1 is non-decreasing. Hence, R∗t (ℓ) ≥ R∗t+1(ℓ) for every ℓ ∈ V ∗ and thus R∗t (−Lt)−R∗t+1(−Lt) ≥ 0. So, by Lemma 1,\nRegretT (u) ≤ RT+1(u) +R∗1(0) + T∑\nt=1\nBR∗ t (−Lt,−Lt−1) . (B.2)\nTechnically, (B.2) is not justified since Rt might not be strongly convex. This happens when ∆t−1 = 0. In order to justify (B.2), we consider a different algorithm that initializes ∆0 = ǫ where ǫ > 0; that ensures that ∆t−1 > 0 and Rt is strongly convex. Applying Lemma 1 and then taking limit ǫ → 0, yields (B.2).\nSince, BR∗ t (u, v) = ∆t−1BR∗( u∆t−1 , v ∆t−1 ) by definition of Bregman diver-\ngence and property 8 of Proposition 2, we have ∑T\nt=1 BR∗t (−Lt,−Lt−1) = ∆T . Lemma 6 (Recurrence). Let D = supu,v∈K ‖u − v‖ be the diameter of K. The sequence {∆t}∞t=1 generated by AdaFTRL satisfies for any t ≥ 1,\n∆t ≤ ∆t−1 +min { D‖ℓt‖∗,\n‖ℓt‖2∗ 2λ∆t−1\n} .\nProof. By definition, ∆t satisfies the recurrence\n∆t = ∆t−1 +∆t−1BR∗ ( − Lt ∆t−1 ,−Lt−1 ∆t−1 ) .\nUsing parts 4 and 6 of Proposition 2, we can upper bound BR∗ ( − Lt∆t−1 ,− Lt−1 ∆t−1 ) with two different quantities. Taking the minimum of the two quantities finishes the proof.\nThe recurrence of Lemma 6 can be simplified. Defining\nat = ‖ℓt‖∗max { D,\n1√ 2λ\n} ,\nwe get a recurrence\n∆t ≤ ∆t−1 +min { at,\na2t ∆t−1\n} .\nThe next lemma solves this recurrence, by giving an explicit upper bound on ∆T in terms of a1, a2, . . . , aT .\nLemma 7 (Solution of the Recurrence). Let {at}∞t=1 be any sequence of non-negative real numbers. Suppose that {∆t}∞t=0 is a sequence of non-negative real numbers satisfying\n∆0 = 0 and ∆t ≤ ∆t−1 +min { at,\na2t ∆t−1\n} for any t ≥ 1 .\nThen, for any T ≥ 0,\n∆T ≤ √√√√3 T∑\nt=1\na2t .\nProof. Observe that\n∆2T = T∑\nt=1\n∆2t −∆2t−1 = T∑\nt=1\n(∆t −∆t−1)2 + 2(∆t −∆t−1)∆t−1 .\nWe bound each term in the sum separately. The left term of the minimum inequality in the definition of ∆t gives\n(∆t −∆t−1)2 ≤ a2t ,\nwhile the right term gives\n2(∆t −∆t−1)∆t−1 ≤ 2a2t .\nSo, we conclude\n∆2T ≤ 3 T∑\nt=1\na2t .\nTheorem 6 follows from Lemmas 5, 6 and 7."
    }, {
      "heading" : "Appendix C. Limits",
      "text" : "In this section, we show that prediction of AdaFTRL is correctly defined when the regularizer is multiplied by zero.\nLemma 8 (Prediction for Zero Regularizer). Let K be non-empty bounded closed convex subset of a finite dimensional normed real vector space (V, ‖ · ‖). Let R : K → R be strictly convex and lower semi-continuous, and let L ∈ V ∗. The limit\nlim η→+∞ argmin w∈K\n( 〈L,w〉+ 1\nη R(w)\n) (C.1)\nexists and it is equal to the unique minimizer of R(w) over the set (of minimizers) {\nw ∈ K : 〈L,w〉 = inf v∈K\n〈L, v〉 } .\nBefore we give the proof, we illustrate the lemma on a simple example. Let K = [−1, 1]2 be a closed square in R2 and let R(w) = ‖w‖22. Let L = (1, 0). The minimizers are\nargmin w∈K\n〈L,w〉 = {(−1, y) : y ∈ [−1, 1]} .\nThe minimizer with the smallest value of R(w) is (−1, 0). Hence the lemma implies that\nlim η→+∞ argmin w∈K\n( 〈L,w〉+ 1\nη ‖w‖22\n) = (−1, 0) .\nProof (Proof of Lemma 8). Without loss of generality, we can assume that R(w) is non-negative for any w ∈ K. For otherwise, we can replace R(w) with R′(w) = R(w)− infv∈K R(v).\nSince K is a non-empty bounded closed convex subset of a finite dimensional normed vector space, it is compact and r∗ = minw∈K〈L,w〉 exists and is attained at some w ∈ K. Consider the hyperplane\nH = {w ∈ V : 〈L,w〉 = r∗} .\nThe intersection H ∩K is a non-empty compact convex set. Let\nv∗ = argmin v∈K∩H R(v) .\nThe existence of v∗ follows from compactness ofH∩K and lower semi-continuity of R(v). Uniqueness of v∗ follows from strict convexity of R(v). We show that the limit (C.1) equals v∗.\nBy the definition of H ,\nv∗ ∈ argmin w∈K 〈L,w〉 . (C.2)\nLet S = {w ∈ K : R(w) ≤ R(v∗)}. Since R(w) is lower semi-continuous S is closed. Since R(w) is strictly convex, S ∩H = {v∗}.\nFor any η > 0, let\nw(η) = argmin w∈K\n( 〈L,w〉+ 1\nη R(w)〉\n) .\nWe prove that w(η) ∈ S. Indeed, by optimality of v∗ and w(η),\n1 η R(w(η)) + 〈L,w(η)〉 ≤ 1 η R(v∗) + 〈L, v∗〉 ≤ 1 η R(v∗) + 〈L,w(η)〉\nand hence R(w(η)) ≤ R(v∗). By non-negativity of R and optimality of w(η) we have\n〈L,w(η)〉 ≤ 〈L,w(η)〉 + 1 η R(w(η)) ≤ 〈L, v∗〉+ 1 η R(v∗) .\nTaking the limit η → +∞, we see that\nlim η→+∞ 〈L,w(η)〉 ≤ lim η→+∞\n( 〈L, v∗〉+ 1\nη R(v∗)\n) = 〈L, v∗〉 .\nFrom (C.2) we have 〈L, v∗〉 ≤ 〈L,w〉 for any w, and therefore\nlim η→+∞\n〈L,w(η)〉 = 〈L, v∗〉 . (C.3)\nConsider any sequence {ηt}∞t=1 of positive numbers approaching +∞. Since K is compact, w(ηt) has a convergent subsequence. Thus {w(ηt)}∞t=1 has at least one accumulation point; let w∗ be any of them. We will show that w∗ = v∗.\nConsider a subsequence {ξt}∞t=1 of {ηt}∞t=1 such that limt→∞ w(ξt) = w∗. Since w(ξt) ∈ S and S is closed, w∗ ∈ S. From (C.3) we have 〈L,w∗〉 = 〈L, v∗〉 and hence w∗ ∈ H . Thus w∗ ∈ S ∩H . Since v∗ is the only point in S ∩H we must have w∗ = v∗.\nLemma 9 (Limit of Bregman Divergence). Let K be a non-empty bounded closed convex subset of a finite dimensional normed real vector space (V, ‖ · ‖). Let R : K → R be a strongly convex lower semi-continuous function bounded from above. Then, for any x, y ∈ V ∗,\nlim a→0+\naBR∗(x/a, y/a) = 〈x, u − v〉\nwhere\nu = lim a→0+ argmin w∈K (aR(w)− 〈x,w〉) and v = lim a→0+ argmin w∈K (aR(w) − 〈y, w〉) .\nProof. Using property 3 of Proposition 2 we can write the divergence\naBR∗(x/a, y/a) = aR∗(x/a)− aR∗(y/a)− 〈x− y,∇R∗(y/a)〉 = a [〈x/a,∇R∗(x/a)〉 −R(∇R∗(x/a))]\n− a [〈y/a,∇R∗(y/a)〉 −R(∇R∗(y/a))]− 〈x− y,∇R∗(y/a)〉 = 〈x,∇R∗(x/a)−∇R∗(y/a)〉 − aR(∇R∗(x/a)) + aR(∇R∗(y/a)) .\nProperty 2 of Proposition 2 implies that\nu = lim a→0+ ∇R∗(x/a) = lim a→0+ argmin w∈K (aR(w) − 〈x,w〉) ,\nv = lim a→0+ ∇R∗(y/a) = lim a→0+ argmin w∈K (aR(w) − 〈y, w〉) .\nThe limits on the right exist according to Lemma 8. They are simply the minimizers u = argminw∈K −〈x,w〉 and v = argminw∈K −〈y, w〉 where ties in argmin are broken according to smaller value of R(w).\nBy assumption R(w) is upper bounded. It is also lower bounded, since it is defined on a compact set and it is lower semi-continuous. Thus,\nlim a→0+\naBR∗(x/a, y/a)\n= lim a→0+\n〈x,∇R∗(x/a)−∇R∗(y/a)〉 − aR(∇R∗(x/a)) + aR(∇R∗(y/a))\n= lim a→0+\n〈x,∇R∗(x/a)−∇R∗(y/a)〉 = 〈x, u− v〉 ."
    }, {
      "heading" : "Appendix D. Proofs for SOLO FTRL",
      "text" : "Proof (Proof of Lemma 4). We use the inequality x/ √ x+ y ≤ 2(√x+ y−√\ny) which holds for non-negative x, y that are not both zero. Substituting\nx = at and y = ∑t−1 i=1 ai, we get that for any t ≥ 1,\nat√∑t i=1 ai ≤ 2\n√√√√ t∑\ni=1\nai − 2\n√√√√ t−1∑\ni=1\nai .\nSumming the above inequality over all t = 1, 2, . . . , T , the right side telescopes\nto 2 √∑T t=1 at."
    }, {
      "heading" : "Appendix E. Proofs for Scale-Free Mirror Descent",
      "text" : "Proof (Proof of Lemma 2). Let\nΨt+1(w) = 〈ℓt, w〉+ BRt(w,wt) = 〈ℓt, w〉+Rt(w) −Rt(wt)− 〈∇Rt(wt), w − wt〉 .\nThen, wt+1 = argminw∈K Ψt+1(w). Note that ∇Ψt+1(w) = ℓt + ∇Rt(w) − ∇Rt(wt). The optimality condition for wt+1 states that 〈∇Ψt+1(wt+1), u − wt+1〉 ≥ 0 for all u ∈ K. Written explicitly,\n〈ℓt +∇Rt(wt+1)−∇Rt(wt), u− wt+1〉 ≥ 0 .\nAdding 〈ℓt, wt+1 − wt〉 to both sides and rearranging, we have\n〈ℓt, wt − u〉 ≤ 〈∇Rt(wt+1)−∇Rt(wt), u− wt+1〉+ 〈ℓt, wt − wt+1〉 = 〈ℓt, wt − wt+1〉 − BRt(wt+1, wt) + BRt(u,wt)− BRt(u,wt+1) .\nThe last equality follows by from definition of Bregman divergence. Summation over all t = 1, 2, . . . , T gives the final regret bound.\nProof (Proof of Theorem 2). Let ηt = 1√∑\nt i=1 ‖ℓi‖2∗ . We define η0 = +∞ and 1/η0 = 0. Hence Rt(w) =\n1 ηt R(w). Since Rt is λ ηt -strongly convex, we have\n〈ℓt, wt − wt+1〉 − BRt(wt+1, wt) ≤ ‖ℓt‖∗ · ‖wt − wt+1‖ − λ\n2ηt ‖wt − wt+1‖2\n≤ max z∈R\n( ‖ℓt‖∗z − λ 2ηt z2 )\n= ηt 2λ ‖ℓt‖2∗ .\nCombining the last inequality with Lemma 2, we have\nRegretT (u) ≤ T∑\nt=1\nηt 2λ\n‖ℓt‖2∗ + T∑\nt=1\n[BRt(u,wt)− BRt(u,wt+1)] .\nSince Rt(w) = 1 ηt R(w), we have\nRegretT (u) ≤ 1\n2λ\nT∑\nt=1\nηt‖ℓt‖2∗ + T∑\nt=1\n1 ηt [BR(u,wt)− BR(u,wt+1)]\n≤ 1 2λ\nT∑\nt=1\nηt‖ℓt‖2∗ + T∑\nt=1\nBR(u,wt) ( 1\nηt − 1 ηt−1\n)\n≤ 1 2λ\nT∑\nt=1 ‖ℓt‖2∗√∑t i=1 ‖ℓi‖2∗ + sup v∈K BR(u, v) T∑ t=1\n( 1\nηt − 1 ηt−1\n)\n≤ 1 λ\n√√√√ T∑\nt=1\n‖ℓt‖2∗ + sup v∈K BR(u, v)\n√√√√ T∑\nt=1\n‖ℓt‖2∗ (By Lemma 4)\n=\n( 1\nλ + sup v∈K BR(u, v)\n) √√√√ T∑\nt=1\n‖ℓt‖2∗ .\nProof (Proof of Theorem 3). We assume d = 1. For d ≥ 2, we simply embed the one-dimensional loss vectors into the first coordinate of Rd. Consider the sequence\n(ℓ1, ℓ2, . . . , ℓT ) = (−1,−1, . . . ,−1︸ ︷︷ ︸ ⌈T/2⌉ ,+1,+1, . . . ,+1︸ ︷︷ ︸ ⌊T/2⌋ ) .\nThe first half consists of −1’s, the second of +1’s. For t ≤ ⌈T/2⌉\nwt+1 = wt + 1√ t .\nUnrolling the recurrence and using w1 = 0 we get\nwt = t−1∑\ni=1\n1√ i\n(for t ≤ ⌈T/2⌉+ 1) .\nOn the other hand, for t ≥ ⌈T/2⌉+ 1, we have\nwt+1 = wt − 1√ t .\nUnrolling the recurrence up to w⌈T/2⌉+1 we get\nwt = w⌈T/2⌉+1 − t−1∑\ni=⌈T/2⌉+1\n1√ i =\n⌈T/2⌉∑\ni=1\n1√ i −\nt−1∑\ni=⌈T/2⌉+1\n1√ i\n(for t ≥ ⌈T/2⌉+ 1) .\nWe are ready to lower bound the regret.\nRegretT (0) =\nT∑\nt=1\nℓtwt\n= − ⌈T/2⌉∑\nt=1\nwt +\nT∑\nt=⌈T/2⌉+1 wt\n= − ⌈T/2⌉∑\nt=1\nt−1∑\ni=1\n1√ i +\nT∑\nt=⌈T/2⌉+1\n  ⌈T/2⌉∑\ni=1\n1√ i\n− t−1∑\ni=⌈T/2⌉+1\n1√ i\n\n\n= − ⌈T/2⌉∑\ni=1\n⌈T/2⌉ − i√ i\n+ ⌊T/2⌋ ⌈T/2⌉∑\ni=1\n1√ i\n− T∑\ni=⌈T/2⌉+1\nT − i√ i\n= − ⌈T/2⌉∑\ni=1\n⌈T/2⌉ − ⌊T/2⌋√ i +\nT∑\ni=1\n√ i − T T∑\ni=⌈T/2⌉+1\n1√ i\n≥ − ⌈T/2⌉∑\ni=1\n1√ i +\nT∑\ni=1\n√ i − T T∑\ni=⌈T/2⌉+1\n1√ i\n≥ −1− ∫ ⌈T/2⌉\ni=1\n1√ x dx +\n∫ T\n0\n√ x dx − T\n∫ T\n⌈T/2⌉\n1√ x dx\n= −1− 2 (√ ⌈T/2⌉ − 1 ) + 2\n3 T 3/2 − 2T\n(√ T − √ ⌈T/2⌉ )\n≥ 1− 2 √ ⌈T/2⌉+\n( 2\n3 − 2 +\n√ 2 ) T 3/2 .\nThe last expression is Ω(T 3/2) with dominant term (23−2+ √ 2)T 3/2 ≈ 0.08·T 3/2. For any T ≥ 42, the expression is lower bounded by 120T 3/2.\nProof (Proof of Theorem 4). Let e1, e2, . . . , ed be the standard orthnormal basis of Rd. Consider the sequence of loss vectors\n(ℓ1, ℓ2, . . . , ℓT ) = (−e1,−e1, . . . ,−e1︸ ︷︷ ︸ ⌈T/3⌉ ,−e2,−e2, . . . ,−e2︸ ︷︷ ︸ ⌊2T/3⌋ ) .\nFirst, for any t ≥ ⌈T/3⌉+ 1,\nwt,1 wt,2\n= exp(−∑t−1i=1 ℓi,1/ √ i)\nexp(− ∑t−1 i=1 ℓi,2/ √ i)\n= exp(\n∑⌈T/3⌉ i=1 1/ √ i)\nexp( ∑t i=⌈T/3⌉+1 1/ √ i)\n≥ exp( ∑⌈T/3⌉ i=1 1/ √ i)\nexp( ∑T i=⌈T/3⌉+1 1/ √ i)\n= exp\n  ⌈T/3⌉∑\ni=1\n1√ i\n− T∑\ni=⌈T/3⌉+1 1/\n√ i\n\n\n≥ exp (∫ ⌈T/3⌉+1\n1\ndx√ x\n− ∫ T\n⌈T/3⌉\ndx√ x\n)\n= exp ( 2 √ ⌈T/3⌉+ 1− 2− (2 √ T − 2 √ ⌈T/3⌉) ) ≥ exp ((\n4√ 3 − 2\n)√ T − 2 )\n≥ 4 ,\nwhere the last inequality follows from the fact that exp ((\n4√ 3 − 2\n)√ T − 2 ) is\nan increasing function of T and the inequality can be easily verified for T = 120. Since wt,1 + wt,1 ≤ 1 and wt,1 ≥ 0 and wt,2 ≥ 0, the inequality wt,1/wt,2 ≥ 4 implies that\nwt,2 ≤ 1\n5 (for any t ≥ ⌈T/3⌉+ 1) .\nNow, we lower bound the regret. Since T ≥ 120,\nRegretT ≥ RegretT (e2)\n= T∑\nt=1\n〈ℓt, wt〉 − T∑\nt=1\n〈ℓt, e2〉\n= − ⌈T/3⌉∑\nt=1\nwt,1 − T∑\nt=⌈T/3⌉+1 wt,2 + ⌊2T/3⌋\n≥ −⌈T/3⌉ − 1 5 ⌊2T/3⌋+ ⌊2T/3⌋ ≥ −T/3− 1− 2T/15 + 2T/3− 1 = T/5− 2 ≥ T/6 ."
    }, {
      "heading" : "Appendix F. Lower Bound Proof",
      "text" : "Proof (Proof of Theorem 5). Pick x, y ∈ K such that ‖x− y‖ = D. This is possible sinceK is compact. Since ‖x−y‖ = sup{〈ℓ, x−y〉 : ℓ ∈ V ∗, ‖ℓ‖∗ = 1} and the set {ℓ ∈ V ∗ : ‖ℓ‖∗ = 1} is compact, there exists ℓ ∈ V ∗ such that\n‖ℓ‖∗ = 1 and 〈ℓ, x− y〉 = ‖x− y‖ = D .\nLet Z1, Z2, . . . , ZT be i.i.d. Rademacher variables, that is, Pr[Zt = +1] = Pr[Zt = −1] = 1/2. Let ℓt = Ztatℓ. Clearly, ‖ℓt‖∗ = at. The lemma will be proved if we show that (4) holds with positive probability. We show a stronger statement that the inequality holds in expectation, i.e., E[RegretT ] ≥ D√ 8 √∑T t=1 a 2 t . Indeed,\nE [RegretT ] ≥ E [ T∑\nt=1\n〈ℓt, wt〉 ] −E [ min\nu∈{x,y}\nT∑\nt=1\n〈ℓt, u〉 ]\n= E\n[ T∑\nt=1\nZtat〈ℓ, wt〉 ] +E [ max\nu∈{x,y}\nT∑\nt=1\n−Ztat〈ℓ, u〉 ]\n= E [ max\nu∈{x,y}\nT∑\nt=1\n−Ztat〈ℓ, u〉 ]\n= E [ max\nu∈{x,y}\nT∑\nt=1\nZtat〈ℓ, u〉 ]\n= 1\n2 E\n[ T∑\nt=1\nZtat〈ℓ, x+ y〉 ] + 1\n2 E [∣∣∣∣∣ T∑\nt=1\nZtat〈ℓ, x− y〉 ∣∣∣∣∣ ]\n= D\n2 E [∣∣∣∣∣ T∑\nt=1\nZtat ∣∣∣∣∣ ]\n≥ D√ 8\n√√√√ T∑\nt=1\na2t ,\nwhere we used that E[Zt] = 0, the fact that distributions of Zt and −Zt are the same, the formula max{a, b} = (a+ b)/2 + |a− b|/2, and Khinchin’s inequality in the last step (Lemma A.9 in [2])."
    } ],
    "references" : [ ],
    "referenceMentions" : [ ],
    "year" : 2016,
    "abstractText" : "<lb>We design and analyze algorithms for online linear optimization that have opti-<lb>mal regret and at the same time do not need to know any upper or lower bounds<lb>on the norm of the loss vectors. Our algorithms are instances of the Follow the<lb>Regularized Leader (FTRL) and Mirror Descent (MD) meta-algorithms. We<lb>achieve adaptiveness to the norms of the loss vectors by scale invariance, i.e.,<lb>our algorithms make exactly the same decisions if the sequence of loss vectors is<lb>multiplied by any positive constant. The algorithm based on FTRL works for<lb>any decision set, bounded or unbounded. For unbounded decisions sets, this is<lb>the first adaptive algorithm for online linear optimization with a non-vacuous<lb>regret bound. In contrast, we show lower bounds on scale-free algorithms based<lb>on MD on unbounded domains.",
    "creator" : "LaTeX with hyperref package"
  }
}