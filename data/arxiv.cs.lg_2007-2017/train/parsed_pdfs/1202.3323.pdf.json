{
  "name" : "1202.3323.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : null,
    "authors" : [ "Pierre Gaillard", "Gilles Stoltz" ],
    "emails" : [ "NICOLO.CESA-BIANCHI@UNIMI.IT", "PIERRE.GAILLARD@ENS.FR", "GABOR.LUGOSI@UPF.EDU", "GILLES.STOLTZ@ENS.FR" ],
    "sections" : [ {
      "heading" : null,
      "text" : "ar X\niv :1\n20 2.\n33 23\nv1 [\ncs .L\nG ]"
    }, {
      "heading" : "1. Introduction",
      "text" : "Online convex optimization is a sequential prediction paradigm in which, at each time step, the learner chooses an element from a fixed convex set S and then is given access to a convex loss function defined on the same set. The value of the function on the chosen element is the learner’s loss. Many problems such as prediction with expert advice, sequential investment, and online regression/classification can be viewed as special cases of this general framework. Online learning algorithms are designed to minimize the regret. The standard notion of regret is the difference between the learner’s cumulative loss and the cumulative loss of the single best element in S . A much harder criterion to minimize is shifting regret, which is defined as the difference between the learner’s cumulative loss and the cumulative loss of an arbitrary sequence of elements in S . Shifting regret bounds are typically expressed in terms of the shift, a notion of regularity measuring the length of the trajectory in S described by the comparison sequence (i.e., the sequence of elements against which the regret is evaluated).\nIn online convex optimization, shifting regret bounds for convex subsets S ⊆ Rd are obtained for the online mirror descent (or follow-the-regularized-leader) algorithm. In this case the shift is\n†. CNRS – Ecole normale supérieure, Paris – INRIA, within the project-team CLASSIC †. CNRS – Ecole normale supérieure, Paris – INRIA, within the project-team CLASSIC\nc© 2012 .\ntypically computed in terms of the p-norm of the difference of consecutive elements in the comparison sequence —see Herbster and Warmuth (2001) and Cesa-Bianchi and Lugosi (2006). In this paper we focus on the important special case when S is the simplex, and investigate the online mirror descent with entropic regularizers. This family includes popular algorithms such as exponentially weighted average (EWA), Winnow, and exponentiated gradient. Proving general shifting bounds in this case is difficult due to the behavior of the regularizer at the boundary of the simplex. Herbster and Warmuth (2001) show shifting bounds for mirror descent with entropic regularizers using a 1-norm to measure the shift. In order to keep mirror descent from choosing points too close to the simplex boundary, they use a complex dynamic projection technique. When the comparison sequence is restricted to the corners of the simplex (which is the setting of prediction with expert advice), then the shift is naturally defined to be the number times the trajectory moves to a different corner. This problem is often called “tracking the best expert” —see, e.g., Herbster and Warmuth (1998); Vovk (1999); Herbster and Warmuth (2001); Bousquet and Warmuth (2002); György et al. (2005), and it is well known that EWA with weight sharing, which corresponds to the fixedshare algorithm of Herbster and Warmuth (1998), achieves a good shifting bound in this setting. Bousquet and Warmuth (2002) introduce a generalization of the fixed-share algorithm, and prove various shifting bounds for any trajectory in the simplex. However, their bounds are expressed using a quantity that corresponds to a proper shift only for trajectories on the simplex corners.\nOur analysis unifies, generalizes (and simplifies) the previously quite different proof techniques and algorithms used in Herbster and Warmuth (1998) and Bousquet and Warmuth (2002). Our bounds are expressed in terms of a notion of shift based on the total variation distance. The generalization of the “small expert set” result in Bousquet and Warmuth (2002) leads us to obtain better bounds when the sequence against which the regret is measured is sparse. When the trajectory is restricted to the corners of the simplex, we recover, and occasionally improve, the known shifting bounds for prediction with expert advice. Besides, our analysis also captures the setting of adaptive regret, a related notion of regret introduced by Hazan and Seshadhri (2009). It was known that shifting regret and adaptive regret had some connections but this connection is now seen to be even tighter, as both regrets can be viewed as instances of the same alma mater regret, which we minimize. Finally, we also show how to dynamically tune the parameters of our algorithms and review briefly the special case of exp-concave loss functions, exhibiting the first logarithmic shifting bounds for exp-concave loss functions on the simplex."
    }, {
      "heading" : "2. Preliminaries",
      "text" : "We first define the sequential learning framework we work with. Even though our results hold in the general setting of online convex optimization, we present them in the, somewhat simpler, online linear optimization setup. We point out in Section 6 how these results may be generalized. Online linear optimization may be cast as a repeated game between the forecaster and the environment as follows. We use ∆d to denote the simplex { q ∈ [0, 1]d : ‖q‖1 = 1 } .\nOnline linear optimization. For each round t = 1, . . . , T , 1. Forecaster chooses p̂t = (p̂1,t, . . . , p̂d,t) ∈ ∆d ; 2. Environment chooses a loss vector ℓt = (ℓ1,t, . . . , ℓd,t) ∈ [0, 1]d ; 3. Forecaster suffers loss p̂⊤t ℓt .\nA NEW LOOK AT SHIFTING REGRET\nThe goal of the forecaster is to minimize the accumulated loss L̂T = ∑T t=1 p̂ ⊤ t ℓt. In the now classical problem of prediction with expert advice, the goal of the forecaster is to compete with the best fixed component (often called “expert”) chosen in hindsight, that is, with mini=1,...,T ∑T t=1 ℓi,t. The focus of this paper is on more ambitious forecasters that compete with a richer class of sequences of components. Let [d] = {1, . . . , d}. We use iT1 = (i1, . . . , iT ) to denote a sequence in [d]T and let LT (iT1 ) = ∑T t=1 ℓit be the cumulative linear loss of the sequence i T 1 ∈ [d]T .\nWe start by introducing our main algorithmic tool, a generalized share algorithm. It is parametrized by the “mixing functions” ψt : [0, 1](t+1)d → ∆d for t = 1, . . . , T that assign probabilities to past “pre-weights” as defined below. In all examples discussed in this paper, these mixing functions are quite simple but working with such a general model makes the main ideas more transparent. We then provide a simple lemma that serves as the starting point for analyzing different instances of the generalized share algorithm.\nAlgorithm 1: The generalized share algorithm.\nParameters: learning rate η > 0 and mixing functions ψt for t = 1, . . . , T Initialization: p̂1 = v1 = (1/d, . . . , 1/d)\nFor each round t = 1, . . . , T , 1. Predict p̂t ; 2. Observe loss ℓt ∈ [0, 1]d ; 3. [loss update] For each j = 1, . . . , d define\nvj,t+1 = p̂j,t e\n−η ℓj,t\n∑d i=1 p̂i,t e −η ℓi,t the current pre-weights,\nVt+1 = [ vi,s ] i∈[d], 16s6t+1\nthe d× (t+ 1) matrix of all past and current pre-weights; 4. [shared update] Define p̂t+1 = ψt+1 ( Vt+1 ) .\nLemma 1 For all t > 1 and for all qt ∈ ∆d, Algorithm 1 satisfies\n( p̂t − qt )⊤ ℓt 6 1\nη\nd∑\ni=1\nqi,t ln vi,t+1 p̂i,t + η 8 .\nProof By Hoeffding’s inequality,\nd∑\nj=1\np̂j,t ℓj,t 6 − 1\nη ln\n  d∑\nj=1\np̂j,t e −η ℓj,t  + η\n8 . (1)\nBy definition of vi,t+1, for all i = 1, . . . , d we then have d∑\nj=1\np̂j,t e −η ℓj,t =\np̂i,t e −η ℓi,t\nvi,t+1 ,\nwhich entails p̂⊤t ℓt 6 ℓi,t + 1\nη ln vi,t+1 p̂i,t + η 8 .\nThe proof is concluded by taking a convex aggregation with respect to qt."
    }, {
      "heading" : "3. Shifting bounds",
      "text" : "In this section we prove shifting regret bounds for the generalized share algorithm. We compare the cumulative loss ∑T t=1 p̂ ⊤ t ℓt of the forecaster with the loss of an arbitrary sequence of\nvectors q1, . . . , qT in the simplex ∆d, that is, with ∑T t=1 q ⊤ t ℓt. The bounds we obtain depend, of course, on the “regularity” of the comparison sequence. In the now classical results on tracking the best expert (as in Herbster and Warmuth 1998; Vovk 1999; Herbster and Warmuth 2001; Bousquet and Warmuth 2002), this regularity is measured as the number of times qt 6= qt+1 (henceforth referred to as “hard shifts”). The main results of this paper show not only that these results may be generalized to obtain bounds in terms of “softer” regularity measures but that the same algorithms that were proposed with hard shift tracking in mind achieve such, perhaps surprisingly good, performance. Building on the general formulation introduced in Section 2, we derive such regret bounds for the fixed-share algorithm of Herbster and Warmuth (1998) and for the algorithms of Bousquet and Warmuth (2002).\nIn fact, it is advantageous to extend our analysis so that we not only compare the performance of the forecaster with sequences q1, . . . , qT taking values in the simplex ∆d of probability distributions but rather against arbitrary sequences u1, . . . ,uT ∈ Rd+ of vectors with non-negative components. The loss of such a sequence is defined by ∑T t=1 u ⊤ t ℓt. For fair comparison, we measure the cumu-\nlative loss of the forecaster by ∑T\nt=1 p̂ ⊤ t ℓt‖ut‖1. Of course, when ut ∈ ∆d, we recover the original\nnotion of regret. The norms ‖u1‖1 , . . . , ‖uT ‖1 may be viewed as a sequence of weights that give more or less importance to the instantaneous loss suffered at each step. Of particular interest is the case when ‖ut‖1 ∈ [0, 1] which is the setting of “time selection functions” (see Blum and Mansour 2007, Section 6). In particular, considering sequences ‖ut‖1 ∈ {0, 1} that include the zero vector will provide us a simple way of deriving “adaptive” regret bounds, a notion introduced by Hazan and Seshadhri (2009).\nThe first regret bounds derived below measure the regularity of the sequence uT1 = (u1, . . . ,uT ) in terms of the quantity\nm(uT1 ) = T−1∑\nt=1\nDTV(ut+1,ut) (2)\nwhere for x = (x1, . . . , xd),y = (y1, . . . , yd) ∈ Rd+, we define DTV(x,y) = ∑ xi>yi (xi − yi). Note that when x,y ∈ ∆d, we recover the total variation distance DTV(x,y) = 12 ‖x− y‖1, while for general x,y ∈ Rd+, the quantity DTV(x,y) is not necessarily symmetric and is always bounded by ‖x− y‖1. Note that when the vectors ut are incidence vectors (0, . . . , 0, 1, 0, . . . , 0) ∈ Rd of elements it ∈ [d], then m(uT1 ) corresponds to the number of shifts of the sequence iT1 ∈ [d]T , and we recover from the results stated below the classical bounds for tracking the best expert."
    }, {
      "heading" : "3.1. Fixed-share update",
      "text" : "We now analyze a specific instance of the generalized share algorithm corresponding to the update\np̂j,t+1 =\nd∑\ni=1\n(α d + (1− α)1i=j ) vi,t+1 = α d + (1− α)vj,t+1 , 0 6 α 6 1 . (3)\nA NEW LOOK AT SHIFTING REGRET\nDespite seemingly different statements, this update in Algorithm 1 can be seen to lead exactly to the fixed-share algorithm of Herbster and Warmuth (1998) for prediction with expert advice.\nProposition 2 With the above update, for all T > 1, for all sequences ℓ1, . . . , ℓT of loss vectors ℓt ∈ [0, 1]d, and for all u1, . . . ,uT ∈ Rd+,\nT∑\nt=1\n‖ut‖1 p̂⊤t ℓt − T∑\nt=1\nu⊤t ℓt 6 ‖u1‖1 ln d\nη +\nη\n8\nT∑\nt=1\n‖ut‖1\n+ m(uT1 )\nη ln\nd α +\n∑T t=1 ‖ut‖1 −m(uT1 )− 1\nη ln\n1\n1− α .\nWe emphasize that the fixed-share forecaster does not need to “know” anything about the sequence of the norms ‖ut‖. Of course, in order to minimize the obtained upper bound, the tuning parameters α, η need to be optimized and their values will depend on the maximal value of m(uTi ) for the sequences one wishes to compete against. In particular, we obtain the following corollary, in which h(x) = −x lnx− (1− x) ln(1− x) denotes the binary entropy function for x ∈ [0, 1]. We recall 1 that h(x) 6 x ln(e/x) for x ∈ [0, 1].\nCorollary 3 Suppose Algorithm 1 is run with the update (3). Let m0 > 0. For all T > 1, for all sequences ℓ1, . . . , ℓT of loss vectors ℓt ∈ [0, 1]d, and for all q1, . . . , qT ∈ ∆d with m(qT1 ) 6 m0,\nT∑\nt=1\np̂⊤t ℓt − T∑\nt=1\nq⊤t ℓt 6 √√√√T 2 ( (m0 + 1) ln d+ (T − 1) h ( m0 T − 1 )) ,\nwhenever η and α are optimally chosen in terms of m0 and T .\nIf we only consider vectors of the form qt = (0, . . . , 0, 1, 0, . . . , 0) then m(q T 1 ) corresponds to the number of times qt+1 6= qt in the sequence qT1 . We thus recover Herbster and Warmuth (1998, Theorem 1) and Bousquet and Warmuth (2002, Lemma 6) from the much more general Proposition 2.\nProof of Proposition 2 Applying Lemma 1 with qt = ut/ ‖ut‖1, and multiplying by ‖ut‖1, we get for all t > 1 and ut ∈ Rd+\n‖ut‖1 p̂⊤t ℓt − u⊤t ℓt 6 1\nη\nd∑\ni=1\nui,t ln vi,t+1 p̂i,t + η 8 ‖ut‖1 . (4)\nWe now examine\nd∑\ni=1\nui,t ln vi,t+1 p̂i,t\n= d∑\ni=1\n( ui,t ln 1\np̂i,t − ui,t−1 ln\n1\nvi,t\n) + d∑\ni=1\n( ui,t−1 ln 1\nvi,t − ui,t ln\n1\nvi,t+1\n) . (5)\nFor the first term on the right-hand side, we have\nd∑\ni=1\n( ui,t ln 1\np̂i,t − ui,t−1 ln\n1\nvi,t\n) =\n∑\ni :ui,t>ui,t−1\n( (ui,t − ui,t−1) ln 1\np̂i,t + ui,t−1 ln vi,t p̂i,t\n)\n1. As can be seen by noting that ln ( 1/(1− x) ) < x/(1− x)\n+ ∑\ni : ui,t<ui,t−1\n( (ui,t − ui,t−1) ln 1\nvi,t︸ ︷︷ ︸ 60\n+ui,t ln vi,t p̂i,t\n) . (6)\nIn view of the update (3), we have 1/p̂i,t 6 d/α and vi,t/p̂i,t 6 1/(1 − α). Substituting in (6), we get\nd∑\ni=1\n( ui,t ln 1\np̂i,t − ui,t−1 ln\n1\nvi,t\n)\n6 ∑\ni :ui,t>ui,t−1\n(ui,t − ui,t−1) ln d\nα +\n  ∑\ni: ui,t>ui,t−1\nui,t−1 + ∑\ni: ui,t<ui,t−1\nui,t\n  ln 1\n1− α\n= DTV (ut,ut−1) ln d\nα +\n  d∑\ni=1\nui,t − ∑\ni : ui,t>ui,t−1\n(ui,t − ui,t−1)\n \n︸ ︷︷ ︸ =‖ut‖1−DTV (ut,ut−1)\nln 1\n1− α .\nThe sum of the second term in (5) telescopes. Substituting the obtained bounds in the first sum of the right-hand side in (5), and summing over t = 2, . . . , T , leads to\nT∑\nt=2\nd∑\ni=1\nui,t ln vi,t+1 p̂i,t 6 m(uT1 ) ln d α +\n( T∑\nt=2\n‖ut‖1 − 1−m(uT1 ) ) ln 1\n1− α\n+\nd∑\ni=1\nui,1 ln 1\nvi,2 − ui,T ln\n1\nvi,T+1︸ ︷︷ ︸ 60\n.\nWe hence get from (4), which we use in particular for t = 1,\nT∑\nt=1\n‖ut‖1 p̂⊤t ℓt − u⊤t ℓt 6 1\nη\nd∑\ni=1\nui,1 ln 1\np̂i,1 +\nη\n8\nT∑\nt=1\n‖ut‖1\n+ m(uT1 )\nη ln\nd α +\n∑T t=1 ‖ut‖1 − 1−m(uT1 )\nη ln\n1\n1− α ."
    }, {
      "heading" : "3.2. Sparse sequences: Bousquet-Warmuth updates",
      "text" : "Bousquet and Warmuth (2002) proposed forecasters that are able to efficiently compete with the best sequence of experts among all those sequences that only switch a bounded number of times and also take a small number of different values. Such “sparse” sequences of experts appear naturally in many applications. In this section we show that their algorithms in fact work very well in comparison with a much larger class of sequences u1, . . . ,uT that are “regular”—that is, m(uT1 ), defined in (2) is small—and “sparse” in the sense that the quantity\nn(uT1 ) =\nd∑\ni=1\nmax t=1,...,T ui,t\nA NEW LOOK AT SHIFTING REGRET\nis small. Note that when qt ∈ ∆d for all t, then two interesting upper bounds can be provided. First, denoting the union of the supports of these convex combinations by S ⊆ [d], we have n(qT1 ) 6 |S|, the cardinality of S. Also,\nn(qT1 ) 6 ∣∣∣ { qt, t = 1, . . . , T }∣∣∣,\nthe cardinality of the pool of convex combinations. Thus, n(uT1 ) generalizes the notion of sparsity of Bousquet and Warmuth (2002).\nHere we consider a family of shared updates of the form\np̂j,t = (1− α)vj,t + α wj,t Zt , 0 6 α 6 1 , (7)\nwhere the wj,t are nonnegative weights that may depend on past and current pre-weights and Zt = ∑d i=1 wi,t is a normalization constant. Shared updates of this form were proposed by Bousquet and Warmuth (2002, Sections 3 and 5.2). Apart from generalizing the regret bounds of Bousquet and Warmuth (2002), we believe that the analysis given below is significantly simpler and more transparent. We are also able to slightly improve their original bounds.\nWe focus on choices of the weights wj,t that satisfy the following conditions: there exists a constant C > 1 such that for all j = 1, . . . , d and t = 1, . . . , T ,\nvj,t 6 wj,t 6 1 and C wj,t+1 > wj,t . (8)\nThe next result improves on Proposition 2 when T ≪ d and n(uT1 ) ≪ m(uT1 ), that is, when the dimension (or number of experts) d is large but the sequence uT1 is sparse.\nProposition 4 Suppose Algorithm 1 is run with the shared update (7) with weights satisfying the conditions (8). Then for all T > 1, for all sequences ℓ1, . . . , ℓT of loss vectors ℓt ∈ [0, 1]d, and for all sequences u1, . . . ,uT ∈ Rd+,\nT∑\nt=1\n‖ut‖1 p̂⊤t ℓt − T∑\nt=1\nu⊤t ℓt 6 n(uT1 ) ln d\nη +\nn(uT1 )T lnC\nη +\nη\n8\nT∑\nt=1\n‖ut‖1\n+ m(uT1 )\nη ln maxt6T Zt α +\n∑T t=1 ‖ut‖1 −m(uT1 )− 1\nη ln\n1\n1− α .\nProof The beginning and the end of the proof are similar to the one of Proposition 2, as they do not depend on the specific weight update. In particular, inequalities (4) and (5) remain the same. The proof is modified after (6), which this time we upper bound using the first condition in (8),\nd∑\ni=1\n( ui,t ln 1\np̂i,t − ui,t−1 ln\n1\nvi,t\n) =\n∑\ni :ui,t>ui,t−1\n(ui,t − ui,t−1) ln 1\np̂i,t + ui,t−1 ln vi,t p̂i,t\n+ ∑\ni :ui,t<ui,t−1 (ui,t − ui,t−1)︸ ︷︷ ︸ 60\nln 1\nvi,t︸ ︷︷ ︸ >ln(1/wi,t)\n+ui,t ln vi,t p̂i,t . (9)\nBy definition of the shared update (7), we have 1/p̂i,t 6 Zt/(αwi,t) and vi,t/p̂i,t 6 1/(1− α). We then upper bound the quantity at hand in (9) by\n∑\ni : ui,t>ui,t−1\n(ui,t − ui,t−1) ln (\nZt αwi,t\n) +   ∑\ni : ui,t>ui,t−1\nui,t−1 + ∑\ni : ui,t<ui,t−1\nui,t\n  ln 1\n1− α\n+ ∑\ni : ui,t<ui,t−1\n(ui,t − ui,t−1) ln 1\nwi,t\n= DTV(ut,ut−1) ln Zt α\n+ ( ‖ut‖1 −DTV(ut,ut−1) ) ln 1 1− α + d∑\ni=1\n(ui,t − ui,t−1) ln 1\nwi,t .\nProceeding as in the end of the proof of Proposition 2, we then get the claimed bound, provided that we can show that\nT∑\nt=2\nd∑\ni=1\n(ui,t − ui,t−1) ln 1\nwi,t 6 n(uT1 ) (ln d+ T lnC)− ‖u1‖1 ln d ,\nwhich we do next. Indeed, the left-hand side can be rewritten as\nT∑\nt=2\nd∑\ni=1\n( ui,t ln 1\nwi,t − ui,t ln\n1\nwi,t+1\n) + T∑\nt=2\nd∑\ni=1\n( ui,t ln 1\nwi,t+1 − ui,t−1 ln\n1\nwi,t\n)\n6\n( T∑\nt=2\nd∑\ni=1\nui,t ln C wi,t+1 wi,t\n) + ( d∑\ni=1\nui,T ln 1\nwi,T+1 −\nd∑\ni=1\nui,1 ln 1\nwi,2\n)\n6\n( d∑\ni=1\n( max\nt=1,...,T ui,t\n) T∑\nt=2\nln C wi,t+1 wi,t\n) + ( d∑\ni=1\n( max\nt=1,...,T ui,t\n) ln\n1\nwi,T+1 −\nd∑\ni=1\nui,1 ln 1\nwi,2\n)\n=\nd∑\ni=1\n( max\nt=1,...,T ui,t\n)( (T − 1) lnC + ln 1\nwi,2\n) − d∑\ni=1\nui,1 ln 1\nwi,2 ,\nwhere we used C > 1 for the first inequality and the second condition in (8) for the second inequality. The proof is concluded by noting that (8) entails wi,2 > (1/C)wi,1 > (1/C)vi,1 = 1/(dC) and that the coefficient maxt=1,...,T ui,t − ui,1 in front of ln(1/wi,2) is nonnegative. We now generalize Corollaries 8 and 9 of Bousquet and Warmuth (2002) by showing two specific instances of the generic update (7) that satisfy (8). The first update uses wj,t = maxs6t vj,s. Then (8) is satisfied with C = 1. Moreover, since a sum of maxima of nonnegative elements is smaller than the sum of the sums, Zt 6 min{d, t} 6 T . This immediately gives the following result.\nCorollary 5 Suppose Algorithm 1 is run with the update (7) with wj,t = maxs6t vj,s. For all T > 1, for all sequences ℓ1, . . . , ℓT of loss vectors ℓt ∈ [0, 1]d, and for all q1, . . . , qT ∈ ∆d,\nT∑\nt=1\np̂⊤t ℓt − T∑\nt=1\nq⊤t ℓt 6 n(qT1 ) ln d\nη +\nη 8 T +\nm(qT1 )\nη ln\nT α + T −m(qT1 )− 1 η ln 1 1− α .\nA NEW LOOK AT SHIFTING REGRET\nThe second update we discuss uses wj,t = maxs6t eγ(s−t)vj,s in (7) for some γ > 0. Both conditions in (8) are satisfied with C = eγ . One also has that\nZt 6 d and Zt 6 ∑\nτ>0\ne−γτ = 1 1− e−γ 6 1 γ\nas ex > 1 + x for all real x. The bound of Proposition 4 then instantiates as\nn(qT1 ) ln d\nη +\nn(qT1 )Tγ\nη +\nη 8 T +\nm(qT1 )\nη ln min{d, 1/γ} α + T −m(qT1 )− 1 η ln 1 1− α\nwhen sequences ut = qt ∈ ∆d are considered. This bound is best understood when γ is tuned optimally based on T and on two bounds m0 and n0 over the quantities m(qT1 ) and n(q T 1 ). Indeed, by optimizing n0Tγ +m0 ln(1/γ), i.e., by choosing γ = m0/(n0 T ), one gets a bound that improves on the one of the previous corollary:\nCorollary 6 Letm0, n0 > 0. Suppose Algorithm 1 is run with the update wj,t = maxs6t eγ(s−t)vj,s where γ = m0/(n0 T ). For all T > 1, for all sequences ℓ1, . . . , ℓT of loss vectors ℓt ∈ [0, 1]d, and for all q1, . . . , qT ∈ ∆d such that m(qT1 ) 6 m0 and n(qT1 ) 6 n0, we have\nT∑\nt=1\np̂⊤t ℓt − T∑\nt=1\nq⊤t ℓt 6 n0 ln d\nη + m0 η\n( 1 + ln min { d, n0 T\nm0\n})\n+ η\n8 T + m0 η ln 1 α + T −m0 − 1 η ln 1 1− α .\nAs the factors e−γt cancel out in the numerator and denominator of the ratio in (7), there is a straightforward implementation of the algorithm (not requiring the knowledge of T ) that needs to maintain only d weights.\nIn contrast, the corresponding algorithm of Bousquet and Warmuth (2002), using the updates p̂j,t = (1−α)vj,t+αS−1t ∑ s6t−1(s−t)−1vj,s or p̂j,t = (1−α)vj,t+αS−1t maxs6t−1(s−t)−1vj,s, where St denote normalization factors, needs to maintain O(dT ) weights with a naive implementation, and O(d lnT ) weights with a more sophisticated one. In addition, the obtained bounds are slightly worse than the one stated above in Corollary 6 as an additional factor of m0 ln(1 + lnT ) is present in Bousquet and Warmuth (2002, Corollary 9)."
    }, {
      "heading" : "4. Adaptive regret",
      "text" : "Next we show how the results of the previous section, e.g., Proposition 2, imply guarantees in terms of adaptive regret —a notion introduced by Hazan and Seshadhri (2009) as follows. For τ0 ∈ {1, . . . , T}, the τ0-adaptive regret of a forecaster is defined by\nRτ0−adaptT = max [r, s] ⊂ [1, T ] s+ 1− r 6 τ0\n{ s∑\nt=r\np̂⊤t ℓt − min q∈∆d\ns∑\nt=r\nq⊤ℓt } . (10)\nAdaptive regret is an alternative way to measure the performance of a forecaster against a changing environment. It is a straightforward observation that adaptive regret bounds also lead to shifting\nregret bounds (in terms of hard shifts). Here we show that these two notions of regret share an even tighter connection, as they can be both viewed as instances of the same alma mater bound, e.g., Proposition 2.\nHazan and Seshadhri (2009) essentially considered the case of online convex optimization with exp-concave loss function (see Section 6 below). In case of general convex functions, they also mentioned that the greedy projection forecaster of Zinkevich (2003) —i.e., mirror descent with a quadratic regularizer— enjoys adaptive regret guarantees. This forecaster can be implemented on the simplex in time O(d) —see, e.g., Duchi et al. (2008). We now show that the simpler fixed-share algorithm has a similar adaptive regret bound.\nProposition 7 Suppose that Algorithm 1 is run with the shared update (3). Then for all T > 1, for all sequences ℓ1, . . . , ℓT of loss vectors ℓt ∈ [0, 1]d, and for all τ0 ∈ {1, . . . , T},\nRτ0−adaptT 6 1\nη ln\nd α + τ0 − 1 η ln 1 1− α + η 8 τ0 ."
    }, {
      "heading" : "In particular, when η and α are chosen optimally (depending on τ0 and T )",
      "text" : "Rτ0−adaptT 6 √\nτ0 2\n( τ0 h ( 1\nτ0\n) + ln d ) 6 √ τ0 2 ln(edτ0) .\nProof For 1 6 r 6 s 6 T and q ∈ ∆d, the regret in the right-hand side of (10) equals the regret considered in Proposition 2 against the sequence uT1 defined as ut = q for t = r, . . . , s and 0 = (0, . . . , 0) for the remaining t. When r > 2, this sequence is such that DTV (ur,ur−1) = DTV (q,0) = 1 and DTV (us+1,us) = DTV (0, q) = 0 so that m(uT1 ) = 1, while ‖u1‖1 = 0. When r = 1, we have ‖u1‖1 = 1 and m(uT1 ) = 0. In all cases, m(uT1 ) + ‖u1‖1 = 1. Specializing the bound of Proposition 2 to the thus defined sequence uT1 gives the result."
    }, {
      "heading" : "5. Online tuning of the parameters",
      "text" : "The forecasters studied above need their parameters η and α to be tuned according to various quantities, including the time horizon T . We show here how the trick of Auer et al. (2002) of having these parameters vary over time can be extended to our setting. For the sake of concreteness we focus on the fixed-share update, i.e., Algorithm 1 run with the update (3). We respectively replace steps 3 and 4 of its description by the loss and shared updates\nvj,t+1 = p̂\nηt ηt−1\nj,t e −ηtℓj,t\n∑d i=1 p̂ ηt ηt−1 i,t e −ηtℓi,t\nand pj,t+1 = αt d + (1− αt) vj,t+1 , (11)\nfor all t > 1 and all j ∈ [d], where (ητ ) and (ατ ) are two sequences of positive numbers, indexed by τ > 1. We also conventionally define η0 = η1. Proposition 2 is then adapted in the following way (when ηt ≡ η and αt ≡ α, Proposition 2 is exactly recovered).\nA NEW LOOK AT SHIFTING REGRET\nProposition 8 The forecaster based on the above updates (11) is such that whenever ηt 6 ηt−1 and αt 6 αt−1 for all t > 1, the following performance bound is achieved. For all T > 1, for all sequences ℓ1, . . . , ℓT of loss vectors ℓt ∈ [0, 1]d, and for all u1, . . . ,uT ∈ Rd+,\nT∑\nt=1\n‖ut‖1 p̂⊤t ℓt − T∑\nt=1\nu⊤t ℓt 6 ( ‖ut‖1 η1 + T∑\nt=2\n‖ut‖1 ( 1\nηt − 1 ηt−1\n)) ln d\n+ m(uT1 )\nηT ln d(1 − αT ) αT + T∑\nt=2\n‖ut‖1 ηt−1 ln 1 1− αt +\nT∑\nt=1\nηt−1 8 ‖ut‖1 .\nDue to space constraints, we only instantiate the obtained bound to the case of T -adaptive regret guarantees, when T is unknown and/or can increase without bounds. Corollary 9 The forecaster based on the above updates with ηt = √( ln(dt) ) /t for t > 3 and\nη0 = η1 = η2 = η3 on the one hand, αt = 1/t on the other hand, is such that for all T > 3 and for all sequences ℓ1, . . . , ℓT of loss vectors ℓt ∈ [0, 1]d,\nmax [r,s]⊂[1,T ]\n{ s∑\nt=r\np̂⊤t ℓt − min q∈∆d\ns∑\nt=r\nq⊤ℓt } 6 √ 2T ln(dT ) + √ 3 ln(3d) .\nProof The sequence n 7→ ln(n)/n is only non-increasing after round n > 3, so that the defined sequences of (αt) and (ηt) are non-increasing, as desired. For a given pair (r, s) and a given q ∈ ∆d, we consider the sequence νT1 defined in the proof of Proposition 7; it satisfies that m(u T 1 ) 6 1 and ‖ut‖1 6 1 for all t > 1. Therefore, Proposition 8 ensures that\ns∑\nt=r\np̂⊤t ℓt − min q∈∆d\ns∑\nt=r\nq⊤ℓt 6 ln d\nηT +\n1\nηT ln d(1− αT ) αT︸ ︷︷ ︸ 6dT +\nT∑\nt=2\n1\nηt−1 ln\n1\n1− αt ︸ ︷︷ ︸\n6(1/ηT ) ∑T t=2 ln(t/(t−1))=(ln T )/ηT\n+\nT∑\nt=1\nηt−1 8 .\nIt only remains to substitute the proposed values of ηt and to note that\nT∑\nt=1\nηt−1 6 3η3 + T−1∑\nt=3\n1√ t\n√ ln(dT ) 6 3\n√ ln(3d)\n3 + 2\n√ T √ ln(dT ) ."
    }, {
      "heading" : "6. Online convex optimization and exp-concave loss functions",
      "text" : "By using a standard reduction, the results of the previous sections can be applied to online convex optimization on the simplex. In this setting, at each step t the forecaster chooses p̂t ∈ ∆d and then is given access to a convex loss ℓt : ∆d → [0, 1]. Now, using Algorithm 1 with the loss vector ℓt ∈ ∂ℓt(p̂t) given by a subgradient of ℓt leads to the desired bounds. Indeed, by the convexity of ℓt, the regret at each time t with respect to any vector ut ∈ Rd+ with ‖ut‖1 > 0 is then bounded as\n‖ut‖1 ( ℓt(p̂t)− ℓt ( ut\n‖ut‖1\n)) 6 ( ‖ut‖1 p̂t − ut )⊤ ℓt ."
    }, {
      "heading" : "6.1. Exp-concave loss functions",
      "text" : "Recall that a loss function ℓt is called η0-exp-concave if e−η0 ℓt is concave. (In particular, expconcavity implies convexity.) Bousquet and Warmuth (2002) study shifting regret for exp-concave loss functions. However, they define the regret of an element qT1 of the comparison class (a sequence of elements in ∆d) by\nT∑\nt=1\n( ℓt ( p̂t ) − q⊤t ℓt ) (12)\nwhere ℓt = ( ℓt(e1), . . . , ℓt(ed) ) and e1, . . . ,ed are the elements of the canonical basis of Rd. This corresponds to the linear optimization case studied in the previous sections. However, due to exp-concavity, (1) can be replaced by an application of Jensen’s inequality, namely,\nℓt ( p̂t ) 6 − 1\nη0 ln\n  d∑\nj=1\np̂j,t e −η0 ℓt(ej)   .\nHence the various propositions and corollaries of Sections 3 and 4 still hold true for the regret (12) up to some modifications (deletion of the terms linear in η, assumption of exp-concavity, boundedness no longer needed). For the sake of concreteness, we illustrate the required modifications on Proposition 4.\nProposition 10 Suppose Algorithm 1 is run with the shared update (7) with weights satisfying the conditions (8) and for the choice η = η0. Then for all T > 1, for all sequences ℓ1, . . . , ℓT of η0–exp-concave loss functions, and for all sequences u1, . . . ,uT ∈ Rd+,\nT∑\nt=1\n‖ut‖1 ℓt ( p̂t ) − T∑\nt=1\nu⊤t ℓt 6 (uT1 ) ln d\nη0 +\nn(uT1 )T lnC\nη0\n+ m(uT1 )\nη0 ln maxt6T Zt α +\n∑T t=1 ‖ut‖1 −m(uT1 )− 1\nη0 ln\n1\n1− α .\nWe now turn to the more ambitious goal of controlling regrets of the form ∑T\nt=1 ( ℓt ( p̂t ) −ℓt(qt) )\nwhere losses ℓt are exp-concave. Hazan and Seshadhri (2009) constructed algorithms with T– adaptive regret of the order of O(ln2 T ) and running in time poly(d, log T ). They also constructed different algorithms with T–adaptive regret bounded by O(lnT )) and running time poly(d, T ).\nNext, we show the first logarithmic shifting bounds for exp-concave loss functions. However, we only do so against sequences qT1 of elements in ∆d, i.e., we offer here no general bound in terms of linear vectors uT1 that would unify here as well the view between tracking bounds and adaptive regret bounds. Besides, we get shifting bounds only in terms of hard shifts\ns(qT1 ) = ∣∣{t = 2, . . . , T : qt 6= qt−1 }∣∣ .\nObviously, getting unifying bounds in terms of soft shifts of sequences uT1 of linear vectors is an important open question, which we leave for future research. To get our bound, we mix ideas of Herbster and Warmuth (1998) and Blum and Kalai (1997). We define a prior over the sequences of convex weight vectors as the distribution of the following homogeneous Markov chain Q1, Q2, . . .: The starting vector Q1 is drawn at random according to the uniform distribution µ over ∆d. Then,\nA NEW LOOK AT SHIFTING REGRET\ngiven Qt−1, the next element Qt is equal to Qt−1 with probability 1 − α and with probability α is drawn at random according to µ. In the sequel, all probabilities P and expectations E will be with respect to this Markov chain. Now, the convex weight vector used at time t > 1 by the forecaster is\np̂t = E\n[ Qt e −η0Lt−1(Q t−1 1 ) ]\nE [ e−η0Lt−1(Q t−1 1 ) ] , where Lt−1(Qt−11 ) =\nt−1∑\ns=1\nℓs(Qs) (13)\n(with the convention that an empty sum is null). For this forecaster, we get the following performance bound, whose proof can be found in appendix.\nProposition 11 For all T > 1, for all sequences ℓ1, . . . , ℓT of η0–exp-concave loss functions taking values in [0, L], the cumulative loss of the above forecaster is bounded for all sequences q1, . . . , qT ∈ ∆d by\nT∑\nt=1\nℓt(p̂t)− T∑\nt=1\nℓt(qt) 6\n( s(qT1 ) + 1 ) (d− 1)\nη max\n{ 1, ln\ne η LT( s(qT1 ) + 1 ) (d− 1)\n}\n+ s(qT1 )\nη ln\n1 α + T − s(qT1 )− 1 η ln 1 1− α .\nUnder the imposition of a bound s0 on the numbers of hard shifts s(qT1 ) and up to a tuning of α in terms of s0 and T , the last two terms of the bound are smaller than T h(s0/T ) 6 s0 ln(es0/T ) and therefore, the whole regret bound is O ( (ds0/η0) lnT ) ."
    }, {
      "heading" : "Appendix A. Proof of Proposition 8",
      "text" : "We first adapt Lemma 1.\nLemma 12 The forecaster based on the loss and shared updates (11) satisfies, for all t > 1 and for all qt ∈ ∆d,\n( p̂t − qt )⊤ ℓt 6 d∑\ni=1\nqi,t\n( 1\nηt−1 ln\n1 p̂i,t − 1 ηt ln 1 vi,t+1\n) + ( 1\nηt − 1 ηt−1\n) ln d+\nηt−1 8 ,\nwhenever ηt 6 ηt−1.\nProof By Hoeffding’s inequality,\nd∑\nj=1\np̂j,t ℓj,t 6 − 1\nηt−1 ln\n  d∑\nj=1\np̂j,t e −ηt−1 ℓj,t  + ηt−1\n8 .\nBy Jensen’s inequality, since ηt 6 ηt−1 and thus x 7→ x ηt−1 ηt is convex,\n1\nd\nd∑\nj=1\np̂j,t e −ηt−1ℓj,t =\n1\nd\nd∑\nj=1\n( p̂ ηt ηt−1\nj,t e −ηtℓj,t\n)ηt−1 ηt\n>  1 d d∑\nj=1\np̂\nηt ηt−1\nj,t e −ηtℓj,t\n  ηt−1 ηt\n.\nSubstituting in Hoeffding’s bound we get\np̂⊤t ℓt 6 − 1\nηt ln\n  d∑\nj=1\np̂\nηt ηt−1\nj,t e −ηtℓj,t\n + ( 1\nηt − 1 ηt−1\n) ln d+\nηt−1 8 .\nNow, by definition of the loss update in (11), for all i ∈ [d], d∑\nj=1\np̂\nηt ηt−1\nj,t e −ηtℓj,t =\n1\nvi,t+1 p̂\nηt ηt−1\ni,t e −ηtℓi,t ,\nwhich, after substitution in the previous bound leads to the inequality\np̂⊤t ℓt 6 ℓi,t + 1\nηt−1 ln\n1 p̂i,t − 1 ηt ln 1 vi,t+1 +\n( 1\nηt − 1 ηt−1\n) ln d+\nηt−1 8 ,\nvalid for all i ∈ [d]. The proof is concluded by taking a convex aggregation over i with respect to qt.\nThe proof of Proposition 8 follows the steps of the one of Proposition 2; we sketch it below.\nProof of Proposition 8 Applying Lemma 12 with qt = ut/ ‖ut‖1, and multiplying by ‖ut‖1, we get for all t > 1 and ut ∈ Rd+,\n‖ut‖1 p̂⊤t ℓt − u⊤t ℓt 6 1\nηt−1\nd∑\ni=1\nui,t ln 1 p̂i,t − 1 ηt\nd∑\ni=1\nui,t ln 1\nvi,t+1\n+ ‖ut‖1 ( 1\nηt − 1 ηt−1\n) ln d+\nηt−1 8 ‖ut‖1 . (14)\nWe will sum these bounds over t > 1 to get the desired result but need to perform first some additional boundings for t > 2; in particular, we examine\n1\nηt−1\nd∑\ni=1\nui,t ln 1 p̂i,t − 1 ηt\nd∑\ni=1\nui,t ln 1\nvi,t+1\n= 1\nηt−1\nd∑\ni=1\n( ui,t ln 1\np̂i,t − ui,t−1 ln\n1\nvi,t\n) + d∑\ni=1\n( ui,t−1 ηt−1 ln 1 vi,t − ui,t ηt ln 1 vi,t+1 ) , (15)\nwhere the first difference in the right-hand side can be bounded as in (6) by\nd∑\ni=1\n( ui,t ln 1\np̂i,t − ui,t−1 ln\n1\nvi,t\n)\n6 ∑\ni : ui,t>ui,t−1\n( (ui,t − ui,t−1) ln 1\np̂i,t + ui,t−1 ln vi,t p̂i,t\n) +\n∑\ni : ui,t<ui,t−1\nui,t ln vi,t p̂i,t\n6 DTV (ut,ut−1) ln d\nαt +\n( ‖ut‖1 −DTV (ut,ut−1) ) ln 1\n1− αt 6 DTV (ut,ut−1) ln\nd(1− αT ) αT + ‖ut‖1 ln 1 1− αt , (16)\nwhere we used for the second inequality that the shared update in (11) is such that 1/p̂i,t 6 d/αt and vi,t/p̂i,t 6 1/(1 − αt), and for the third inequality, that αt > αT and x 7→ (1 − x)/x is increasing on (0, 1]. Summing (15) over t = 2, . . . , T using (16) and the fact that ηt > ηT , we get\nT∑\nt=2\n( 1\nηt−1\nd∑\ni=1\nui,t ln 1 p̂i,t − 1 ηt\nd∑\ni=1\nui,t ln 1\nvi,t+1\n)\n6 m(uT1 )\nηT ln d(1 − αT ) αT +\nT∑\nt=2\n‖ut‖1 ηt−1 ln 1 1− αt +\nd∑\ni=1\n( ui,1 η1 ln 1 vi,2 − ui,T ηT ln 1\nvi,T+1︸ ︷︷ ︸ >0\n) .\nAn application of (14) —including for t = 1, for which we recall that p̂i,1 = 1/d and η1 = η0 by convention— concludes the proof.\nA NEW LOOK AT SHIFTING REGRET"
    }, {
      "heading" : "Appendix B. Proof of Proposition 11",
      "text" : "Proof By the definition of exp-concavity and by application of Jensen’s inequality to the distribution Pt over (∆d)t with density\nrt1 7−→ 1\nE [ e−η0Lt−1(r t−1 1 ) ] e−η0Lt−1(r\nt−1 1\n) × 1\nwith respect to the marginal distribution of P over (∆d)t, we have that\nexp ( −η0 ℓt(p̂t) ) = exp ( −η0 ℓt ( Et[Qt] )) > Et [ exp ( −η0 ℓt(Qt) )] = E\n[ e−η0Lt(Q t 1 ) ]\nE [ e−η0Lt−1(Q t−1 1 ) ] .\nThus, a telescoping sum appears,\nT∑\nt=1\nℓt(p̂t) =\nT∑\nt=1\n− 1 η0 ln e−η0ℓt(p̂t) 6 − 1 η0\nlnE [ e−η0LT (Q T 1 ) ] .\nIt suffices to lower bound the expectation. To do so, we define for all sequences rk1 the set of the sequences of k weight vectors that only shift when rk1 does and that at each such shift are ε–close to the corresponding values of the rt:\nSε,rk 1\n= { sk1 ∈ X k : ∀t ∈ {2, . . . , k}, st 6= st−1 ⇒ rt 6= rt−1\nand ∀t ∈ {1, . . . , k}, st = (1− ε)rt + εwt for some wt ∈ X } .\nNote that the second defining constraint is equivalent to the same constraint only at the shifting times of rk1 , in view of the first constraint. Since exp-concave loss functions are in particular convex, we get that for all sT1 ∈ Sε,qT\n1\n,\nT∑\nt=1\nℓt(st) 6 (1− ε) T∑\nt=1\nℓt(qt) + ε\nT∑\nt=1\nℓt(wt) 6\nT∑\nt=1\nℓt(qt) + εLT .\nThus,\n− 1 η0\nlnE [ e−η0LT (Q T 1 ) ] 6 − 1\nη0 lnE\n[ e−η0LT (Q T 1 ) I{\nQT 1 ∈S\nε,qT 1\n} ]\n6\nT∑\nt=1\nℓt(qt) + εLT − 1\nη0 lnP\n( Sε,qT\n1\n) .\nFurthermore, we show by induction on t that for all t > 1,\nP ( Sε,qt\n1\n) > εd−1(1− α)t−s(qT1 )−1 ( αεd−1 )s(qT 1 ) .\nThis is true for t = 1 as Sε,q1 = (1 − ε)q1 + εX has a P–probability given by its µ–probability, which is equal to εd−1 µ(X ) = εd−1, and as by convention, s(q1) = 0. Besides, when t > 2, we have by definition of P (cf. its defining transition probability distributions) and Sε,qt\n1 (cf. the st1 can only shift when the qt1 do) that\nP ( Sε,qt\n1\n) >\n{ (1− α) P ( Sε,qt−1\n1\n) when qt = qt−1\nα P ( Sε,qt−1\n1\n) µ(Sε,rt) = α ε d−1 P ( Sε,qt−1\n1\n) when qt 6= qt−1 ,\nwhich concludes the induction. Substituting the obtained bound, we have proved so far that\nT∑\nt=1\nℓt(p̂t)− T∑\nt=1\nℓt(qt) 6 εLT − 1 η0 ln ( εd−1(1− α)t−s(qT1 )−1 ( αεd−1 )s(qT 1 )) .\nε ∈ [0, 1] is a parameter of the analysis, it can be optimized to minimize\nεLT +\n( s(qT1 ) + 1 ) (d− 1)\nη0 ln\n1\nε\nand get the claimed bound. This is achieved by choosing\nε = min { 1, ( s(qT1 ) + 1 ) (d− 1)\nη0LT\n} ."
    } ],
    "references" : [ {
      "title" : "Adaptive and self-confident on-line learning algorithms",
      "author" : [ "P. Auer", "N. Cesa-Bianchi", "C. Gentile" ],
      "venue" : "Journal of Computer and System Sciences,",
      "citeRegEx" : "Auer et al\\.,? \\Q2002\\E",
      "shortCiteRegEx" : "Auer et al\\.",
      "year" : 2002
    }, {
      "title" : "Universal portfolios with and without transaction costs",
      "author" : [ "A. Blum", "A. Kalai" ],
      "venue" : "In Proceedings of the 10th Annual Conference on Learning Theory (COLT),",
      "citeRegEx" : "Blum and Kalai.,? \\Q1997\\E",
      "shortCiteRegEx" : "Blum and Kalai.",
      "year" : 1997
    }, {
      "title" : "From extermal to internal regret",
      "author" : [ "A. Blum", "Y. Mansour" ],
      "venue" : "Journal of Machine Learning Research,",
      "citeRegEx" : "Blum and Mansour.,? \\Q2007\\E",
      "shortCiteRegEx" : "Blum and Mansour.",
      "year" : 2007
    }, {
      "title" : "Tracking a small set of experts by mixing past posteriors",
      "author" : [ "O. Bousquet", "M.K. Warmuth" ],
      "venue" : "Journal of Machine Learning Research,",
      "citeRegEx" : "Bousquet and Warmuth.,? \\Q2002\\E",
      "shortCiteRegEx" : "Bousquet and Warmuth.",
      "year" : 2002
    }, {
      "title" : "Prediction, learning, and games",
      "author" : [ "N. Cesa-Bianchi", "G. Lugosi" ],
      "venue" : null,
      "citeRegEx" : "Cesa.Bianchi and Lugosi.,? \\Q2006\\E",
      "shortCiteRegEx" : "Cesa.Bianchi and Lugosi.",
      "year" : 2006
    }, {
      "title" : "Efficient projections onto the l1–ball for learning in high dimensions",
      "author" : [ "J. Duchi", "S. Shalev-Shwartz", "Y. Singer", "T. Chandra" ],
      "venue" : "In Proceedings of the 25th International Conference on Machine Learning,",
      "citeRegEx" : "Duchi et al\\.,? \\Q2008\\E",
      "shortCiteRegEx" : "Duchi et al\\.",
      "year" : 2008
    }, {
      "title" : "Tracking the best of many experts",
      "author" : [ "A. György", "T. Linder", "G. Lugosi" ],
      "venue" : "In Proceedings of the 18th Annual Conference on Learning Theory (COLT),",
      "citeRegEx" : "György et al\\.,? \\Q2005\\E",
      "shortCiteRegEx" : "György et al\\.",
      "year" : 2005
    }, {
      "title" : "Efficient learning algorithms for changing environment",
      "author" : [ "E. Hazan", "C. Seshadhri" ],
      "venue" : "Proceedings of the 26th International Conference of Machine Learning (ICML),",
      "citeRegEx" : "Hazan and Seshadhri.,? \\Q2009\\E",
      "shortCiteRegEx" : "Hazan and Seshadhri.",
      "year" : 2009
    }, {
      "title" : "Tracking the best expert",
      "author" : [ "M. Herbster", "M. Warmuth" ],
      "venue" : "Machine Learning,",
      "citeRegEx" : "Herbster and Warmuth.,? \\Q1998\\E",
      "shortCiteRegEx" : "Herbster and Warmuth.",
      "year" : 1998
    }, {
      "title" : "Tracking the best linear predictor",
      "author" : [ "M. Herbster", "M. Warmuth" ],
      "venue" : "Journal of Machine Learning Research,",
      "citeRegEx" : "Herbster and Warmuth.,? \\Q2001\\E",
      "shortCiteRegEx" : "Herbster and Warmuth.",
      "year" : 2001
    }, {
      "title" : "Derandomizing stochastic prediction strategies",
      "author" : [ "V. Vovk" ],
      "venue" : "Machine Learning,",
      "citeRegEx" : "Vovk.,? \\Q1999\\E",
      "shortCiteRegEx" : "Vovk.",
      "year" : 1999
    }, {
      "title" : "Online convex programming and generalized infinitesimal gradient ascent",
      "author" : [ "M. Zinkevich" ],
      "venue" : "In Proceedings of the 20th International Conference on Machine Learning,",
      "citeRegEx" : "Zinkevich.,? \\Q2003\\E",
      "shortCiteRegEx" : "Zinkevich.",
      "year" : 2003
    } ],
    "referenceMentions" : [ {
      "referenceID" : 7,
      "context" : "Abstract We investigate extensions of well-known online learning algorithms such as fixed-share of Herbster and Warmuth (1998) or the methods proposed by Bousquet and Warmuth (2002).",
      "startOffset" : 99,
      "endOffset" : 127
    }, {
      "referenceID" : 3,
      "context" : "Abstract We investigate extensions of well-known online learning algorithms such as fixed-share of Herbster and Warmuth (1998) or the methods proposed by Bousquet and Warmuth (2002). These algorithms use weight sharing schemes to perform as well as the best sequence of experts with a limited number of changes.",
      "startOffset" : 154,
      "endOffset" : 182
    }, {
      "referenceID" : 4,
      "context" : "typically computed in terms of the p-norm of the difference of consecutive elements in the comparison sequence —see Herbster and Warmuth (2001) and Cesa-Bianchi and Lugosi (2006).",
      "startOffset" : 116,
      "endOffset" : 144
    }, {
      "referenceID" : 3,
      "context" : "typically computed in terms of the p-norm of the difference of consecutive elements in the comparison sequence —see Herbster and Warmuth (2001) and Cesa-Bianchi and Lugosi (2006). In this paper we focus on the important special case when S is the simplex, and investigate the online mirror descent with entropic regularizers.",
      "startOffset" : 148,
      "endOffset" : 179
    }, {
      "referenceID" : 3,
      "context" : "typically computed in terms of the p-norm of the difference of consecutive elements in the comparison sequence —see Herbster and Warmuth (2001) and Cesa-Bianchi and Lugosi (2006). In this paper we focus on the important special case when S is the simplex, and investigate the online mirror descent with entropic regularizers. This family includes popular algorithms such as exponentially weighted average (EWA), Winnow, and exponentiated gradient. Proving general shifting bounds in this case is difficult due to the behavior of the regularizer at the boundary of the simplex. Herbster and Warmuth (2001) show shifting bounds for mirror descent with entropic regularizers using a 1-norm to measure the shift.",
      "startOffset" : 148,
      "endOffset" : 605
    }, {
      "referenceID" : 3,
      "context" : "typically computed in terms of the p-norm of the difference of consecutive elements in the comparison sequence —see Herbster and Warmuth (2001) and Cesa-Bianchi and Lugosi (2006). In this paper we focus on the important special case when S is the simplex, and investigate the online mirror descent with entropic regularizers. This family includes popular algorithms such as exponentially weighted average (EWA), Winnow, and exponentiated gradient. Proving general shifting bounds in this case is difficult due to the behavior of the regularizer at the boundary of the simplex. Herbster and Warmuth (2001) show shifting bounds for mirror descent with entropic regularizers using a 1-norm to measure the shift. In order to keep mirror descent from choosing points too close to the simplex boundary, they use a complex dynamic projection technique. When the comparison sequence is restricted to the corners of the simplex (which is the setting of prediction with expert advice), then the shift is naturally defined to be the number times the trajectory moves to a different corner. This problem is often called “tracking the best expert” —see, e.g., Herbster and Warmuth (1998); Vovk (1999); Herbster and Warmuth (2001); Bousquet and Warmuth (2002); György et al.",
      "startOffset" : 148,
      "endOffset" : 1175
    }, {
      "referenceID" : 3,
      "context" : "typically computed in terms of the p-norm of the difference of consecutive elements in the comparison sequence —see Herbster and Warmuth (2001) and Cesa-Bianchi and Lugosi (2006). In this paper we focus on the important special case when S is the simplex, and investigate the online mirror descent with entropic regularizers. This family includes popular algorithms such as exponentially weighted average (EWA), Winnow, and exponentiated gradient. Proving general shifting bounds in this case is difficult due to the behavior of the regularizer at the boundary of the simplex. Herbster and Warmuth (2001) show shifting bounds for mirror descent with entropic regularizers using a 1-norm to measure the shift. In order to keep mirror descent from choosing points too close to the simplex boundary, they use a complex dynamic projection technique. When the comparison sequence is restricted to the corners of the simplex (which is the setting of prediction with expert advice), then the shift is naturally defined to be the number times the trajectory moves to a different corner. This problem is often called “tracking the best expert” —see, e.g., Herbster and Warmuth (1998); Vovk (1999); Herbster and Warmuth (2001); Bousquet and Warmuth (2002); György et al.",
      "startOffset" : 148,
      "endOffset" : 1188
    }, {
      "referenceID" : 3,
      "context" : "typically computed in terms of the p-norm of the difference of consecutive elements in the comparison sequence —see Herbster and Warmuth (2001) and Cesa-Bianchi and Lugosi (2006). In this paper we focus on the important special case when S is the simplex, and investigate the online mirror descent with entropic regularizers. This family includes popular algorithms such as exponentially weighted average (EWA), Winnow, and exponentiated gradient. Proving general shifting bounds in this case is difficult due to the behavior of the regularizer at the boundary of the simplex. Herbster and Warmuth (2001) show shifting bounds for mirror descent with entropic regularizers using a 1-norm to measure the shift. In order to keep mirror descent from choosing points too close to the simplex boundary, they use a complex dynamic projection technique. When the comparison sequence is restricted to the corners of the simplex (which is the setting of prediction with expert advice), then the shift is naturally defined to be the number times the trajectory moves to a different corner. This problem is often called “tracking the best expert” —see, e.g., Herbster and Warmuth (1998); Vovk (1999); Herbster and Warmuth (2001); Bousquet and Warmuth (2002); György et al.",
      "startOffset" : 148,
      "endOffset" : 1217
    }, {
      "referenceID" : 3,
      "context" : ", Herbster and Warmuth (1998); Vovk (1999); Herbster and Warmuth (2001); Bousquet and Warmuth (2002); György et al.",
      "startOffset" : 73,
      "endOffset" : 101
    }, {
      "referenceID" : 3,
      "context" : ", Herbster and Warmuth (1998); Vovk (1999); Herbster and Warmuth (2001); Bousquet and Warmuth (2002); György et al. (2005), and it is well known that EWA with weight sharing, which corresponds to the fixedshare algorithm of Herbster and Warmuth (1998), achieves a good shifting bound in this setting.",
      "startOffset" : 73,
      "endOffset" : 123
    }, {
      "referenceID" : 3,
      "context" : ", Herbster and Warmuth (1998); Vovk (1999); Herbster and Warmuth (2001); Bousquet and Warmuth (2002); György et al. (2005), and it is well known that EWA with weight sharing, which corresponds to the fixedshare algorithm of Herbster and Warmuth (1998), achieves a good shifting bound in this setting.",
      "startOffset" : 73,
      "endOffset" : 252
    }, {
      "referenceID" : 3,
      "context" : ", Herbster and Warmuth (1998); Vovk (1999); Herbster and Warmuth (2001); Bousquet and Warmuth (2002); György et al. (2005), and it is well known that EWA with weight sharing, which corresponds to the fixedshare algorithm of Herbster and Warmuth (1998), achieves a good shifting bound in this setting. Bousquet and Warmuth (2002) introduce a generalization of the fixed-share algorithm, and prove various shifting bounds for any trajectory in the simplex.",
      "startOffset" : 73,
      "endOffset" : 329
    }, {
      "referenceID" : 3,
      "context" : ", Herbster and Warmuth (1998); Vovk (1999); Herbster and Warmuth (2001); Bousquet and Warmuth (2002); György et al. (2005), and it is well known that EWA with weight sharing, which corresponds to the fixedshare algorithm of Herbster and Warmuth (1998), achieves a good shifting bound in this setting. Bousquet and Warmuth (2002) introduce a generalization of the fixed-share algorithm, and prove various shifting bounds for any trajectory in the simplex. However, their bounds are expressed using a quantity that corresponds to a proper shift only for trajectories on the simplex corners. Our analysis unifies, generalizes (and simplifies) the previously quite different proof techniques and algorithms used in Herbster and Warmuth (1998) and Bousquet and Warmuth (2002).",
      "startOffset" : 73,
      "endOffset" : 739
    }, {
      "referenceID" : 3,
      "context" : ", Herbster and Warmuth (1998); Vovk (1999); Herbster and Warmuth (2001); Bousquet and Warmuth (2002); György et al. (2005), and it is well known that EWA with weight sharing, which corresponds to the fixedshare algorithm of Herbster and Warmuth (1998), achieves a good shifting bound in this setting. Bousquet and Warmuth (2002) introduce a generalization of the fixed-share algorithm, and prove various shifting bounds for any trajectory in the simplex. However, their bounds are expressed using a quantity that corresponds to a proper shift only for trajectories on the simplex corners. Our analysis unifies, generalizes (and simplifies) the previously quite different proof techniques and algorithms used in Herbster and Warmuth (1998) and Bousquet and Warmuth (2002). Our bounds are expressed in terms of a notion of shift based on the total variation distance.",
      "startOffset" : 73,
      "endOffset" : 771
    }, {
      "referenceID" : 3,
      "context" : ", Herbster and Warmuth (1998); Vovk (1999); Herbster and Warmuth (2001); Bousquet and Warmuth (2002); György et al. (2005), and it is well known that EWA with weight sharing, which corresponds to the fixedshare algorithm of Herbster and Warmuth (1998), achieves a good shifting bound in this setting. Bousquet and Warmuth (2002) introduce a generalization of the fixed-share algorithm, and prove various shifting bounds for any trajectory in the simplex. However, their bounds are expressed using a quantity that corresponds to a proper shift only for trajectories on the simplex corners. Our analysis unifies, generalizes (and simplifies) the previously quite different proof techniques and algorithms used in Herbster and Warmuth (1998) and Bousquet and Warmuth (2002). Our bounds are expressed in terms of a notion of shift based on the total variation distance. The generalization of the “small expert set” result in Bousquet and Warmuth (2002) leads us to obtain better bounds when the sequence against which the regret is measured is sparse.",
      "startOffset" : 73,
      "endOffset" : 949
    }, {
      "referenceID" : 3,
      "context" : ", Herbster and Warmuth (1998); Vovk (1999); Herbster and Warmuth (2001); Bousquet and Warmuth (2002); György et al. (2005), and it is well known that EWA with weight sharing, which corresponds to the fixedshare algorithm of Herbster and Warmuth (1998), achieves a good shifting bound in this setting. Bousquet and Warmuth (2002) introduce a generalization of the fixed-share algorithm, and prove various shifting bounds for any trajectory in the simplex. However, their bounds are expressed using a quantity that corresponds to a proper shift only for trajectories on the simplex corners. Our analysis unifies, generalizes (and simplifies) the previously quite different proof techniques and algorithms used in Herbster and Warmuth (1998) and Bousquet and Warmuth (2002). Our bounds are expressed in terms of a notion of shift based on the total variation distance. The generalization of the “small expert set” result in Bousquet and Warmuth (2002) leads us to obtain better bounds when the sequence against which the regret is measured is sparse. When the trajectory is restricted to the corners of the simplex, we recover, and occasionally improve, the known shifting bounds for prediction with expert advice. Besides, our analysis also captures the setting of adaptive regret, a related notion of regret introduced by Hazan and Seshadhri (2009). It was known that shifting regret and adaptive regret had some connections but this connection is now seen to be even tighter, as both regrets can be viewed as instances of the same alma mater regret, which we minimize.",
      "startOffset" : 73,
      "endOffset" : 1348
    }, {
      "referenceID" : 2,
      "context" : "In the now classical results on tracking the best expert (as in Herbster and Warmuth 1998; Vovk 1999; Herbster and Warmuth 2001; Bousquet and Warmuth 2002), this regularity is measured as the number of times qt 6= qt+1 (henceforth referred to as “hard shifts”). The main results of this paper show not only that these results may be generalized to obtain bounds in terms of “softer” regularity measures but that the same algorithms that were proposed with hard shift tracking in mind achieve such, perhaps surprisingly good, performance. Building on the general formulation introduced in Section 2, we derive such regret bounds for the fixed-share algorithm of Herbster and Warmuth (1998) and for the algorithms of Bousquet and Warmuth (2002).",
      "startOffset" : 129,
      "endOffset" : 689
    }, {
      "referenceID" : 2,
      "context" : "In the now classical results on tracking the best expert (as in Herbster and Warmuth 1998; Vovk 1999; Herbster and Warmuth 2001; Bousquet and Warmuth 2002), this regularity is measured as the number of times qt 6= qt+1 (henceforth referred to as “hard shifts”). The main results of this paper show not only that these results may be generalized to obtain bounds in terms of “softer” regularity measures but that the same algorithms that were proposed with hard shift tracking in mind achieve such, perhaps surprisingly good, performance. Building on the general formulation introduced in Section 2, we derive such regret bounds for the fixed-share algorithm of Herbster and Warmuth (1998) and for the algorithms of Bousquet and Warmuth (2002). In fact, it is advantageous to extend our analysis so that we not only compare the performance of the forecaster with sequences q1, .",
      "startOffset" : 129,
      "endOffset" : 743
    }, {
      "referenceID" : 2,
      "context" : "Of particular interest is the case when ‖ut‖1 ∈ [0, 1] which is the setting of “time selection functions” (see Blum and Mansour 2007, Section 6). In particular, considering sequences ‖ut‖1 ∈ {0, 1} that include the zero vector will provide us a simple way of deriving “adaptive” regret bounds, a notion introduced by Hazan and Seshadhri (2009). The first regret bounds derived below measure the regularity of the sequence u1 = (u1, .",
      "startOffset" : 111,
      "endOffset" : 344
    }, {
      "referenceID" : 8,
      "context" : "Despite seemingly different statements, this update in Algorithm 1 can be seen to lead exactly to the fixed-share algorithm of Herbster and Warmuth (1998) for prediction with expert advice.",
      "startOffset" : 127,
      "endOffset" : 155
    }, {
      "referenceID" : 3,
      "context" : "Sparse sequences: Bousquet-Warmuth updates Bousquet and Warmuth (2002) proposed forecasters that are able to efficiently compete with the best sequence of experts among all those sequences that only switch a bounded number of times and also take a small number of different values.",
      "startOffset" : 43,
      "endOffset" : 71
    }, {
      "referenceID" : 3,
      "context" : "Thus, n(u1 ) generalizes the notion of sparsity of Bousquet and Warmuth (2002). Here we consider a family of shared updates of the form p̂j,t = (1− α)vj,t + α wj,t Zt , 0 6 α 6 1 , (7) where the wj,t are nonnegative weights that may depend on past and current pre-weights and Zt = ∑d i=1 wi,t is a normalization constant.",
      "startOffset" : 51,
      "endOffset" : 79
    }, {
      "referenceID" : 3,
      "context" : "Thus, n(u1 ) generalizes the notion of sparsity of Bousquet and Warmuth (2002). Here we consider a family of shared updates of the form p̂j,t = (1− α)vj,t + α wj,t Zt , 0 6 α 6 1 , (7) where the wj,t are nonnegative weights that may depend on past and current pre-weights and Zt = ∑d i=1 wi,t is a normalization constant. Shared updates of this form were proposed by Bousquet and Warmuth (2002, Sections 3 and 5.2). Apart from generalizing the regret bounds of Bousquet and Warmuth (2002), we believe that the analysis given below is significantly simpler and more transparent.",
      "startOffset" : 51,
      "endOffset" : 489
    }, {
      "referenceID" : 3,
      "context" : "We now generalize Corollaries 8 and 9 of Bousquet and Warmuth (2002) by showing two specific instances of the generic update (7) that satisfy (8).",
      "startOffset" : 41,
      "endOffset" : 69
    }, {
      "referenceID" : 3,
      "context" : "In contrast, the corresponding algorithm of Bousquet and Warmuth (2002), using the updates p̂j,t = (1−α)vj,t+αS t ∑ s6t−1(s−t)vj,s or p̂j,t = (1−α)vj,t+αS t maxs6t−1(s−t)vj,s, where St denote normalization factors, needs to maintain O(dT ) weights with a naive implementation, and O(d lnT ) weights with a more sophisticated one.",
      "startOffset" : 44,
      "endOffset" : 72
    }, {
      "referenceID" : 7,
      "context" : ", Proposition 2, imply guarantees in terms of adaptive regret —a notion introduced by Hazan and Seshadhri (2009) as follows.",
      "startOffset" : 86,
      "endOffset" : 113
    }, {
      "referenceID" : 6,
      "context" : "Hazan and Seshadhri (2009) essentially considered the case of online convex optimization with exp-concave loss function (see Section 6 below).",
      "startOffset" : 0,
      "endOffset" : 27
    }, {
      "referenceID" : 6,
      "context" : "Hazan and Seshadhri (2009) essentially considered the case of online convex optimization with exp-concave loss function (see Section 6 below). In case of general convex functions, they also mentioned that the greedy projection forecaster of Zinkevich (2003) —i.",
      "startOffset" : 0,
      "endOffset" : 258
    }, {
      "referenceID" : 5,
      "context" : ", Duchi et al. (2008). We now show that the simpler fixed-share algorithm has a similar adaptive regret bound.",
      "startOffset" : 2,
      "endOffset" : 22
    }, {
      "referenceID" : 0,
      "context" : "We show here how the trick of Auer et al. (2002) of having these parameters vary over time can be extended to our setting.",
      "startOffset" : 30,
      "endOffset" : 49
    }, {
      "referenceID" : 3,
      "context" : ") Bousquet and Warmuth (2002) study shifting regret for exp-concave loss functions.",
      "startOffset" : 2,
      "endOffset" : 30
    }, {
      "referenceID" : 6,
      "context" : "Hazan and Seshadhri (2009) constructed algorithms with T– adaptive regret of the order of O(ln T ) and running in time poly(d, log T ).",
      "startOffset" : 0,
      "endOffset" : 27
    }, {
      "referenceID" : 6,
      "context" : "Hazan and Seshadhri (2009) constructed algorithms with T– adaptive regret of the order of O(ln T ) and running in time poly(d, log T ). They also constructed different algorithms with T–adaptive regret bounded by O(lnT )) and running time poly(d, T ). Next, we show the first logarithmic shifting bounds for exp-concave loss functions. However, we only do so against sequences q1 of elements in ∆d, i.e., we offer here no general bound in terms of linear vectors u1 that would unify here as well the view between tracking bounds and adaptive regret bounds. Besides, we get shifting bounds only in terms of hard shifts s(q1 ) = ∣t = 2, . . . , T : qt 6= qt−1 }∣∣ . Obviously, getting unifying bounds in terms of soft shifts of sequences u1 of linear vectors is an important open question, which we leave for future research. To get our bound, we mix ideas of Herbster and Warmuth (1998) and Blum and Kalai (1997).",
      "startOffset" : 0,
      "endOffset" : 886
    }, {
      "referenceID" : 1,
      "context" : "To get our bound, we mix ideas of Herbster and Warmuth (1998) and Blum and Kalai (1997). We define a prior over the sequences of convex weight vectors as the distribution of the following homogeneous Markov chain Q1, Q2, .",
      "startOffset" : 66,
      "endOffset" : 88
    } ],
    "year" : 2017,
    "abstractText" : "We investigate extensions of well-known online learning algorithms such as fixed-share of Herbster and Warmuth (1998) or the methods proposed by Bousquet and Warmuth (2002). These algorithms use weight sharing schemes to perform as well as the best sequence of experts with a limited number of changes. Here we show, with a common, general, and simpler analysis, that weight sharing in fact achieves much more than what it was designed for. We use it to simultaneously prove new shifting regret bounds for online convex optimization on the simplex in terms of the total variation distance as well as new bounds for the related setting of adaptive regret. Finally, we exhibit the first logarithmic shifting bounds for exp-concave loss functions on the simplex.",
    "creator" : "LaTeX with hyperref package"
  }
}