{
  "name" : "1507.04457.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "Preference Completion: Large-scale Collaborative Ranking from Pairwise Comparisons",
    "authors" : [ "Dohyung Park", "Sujay Sanghavi" ],
    "emails" : [ "dhpark@utexas.edu", "joeneeman@gmail.com", "zj@utexas.edu", "sanghavi@mail.utexas.edu", "inderjit@cs.utexas.edu" ],
    "sections" : [ {
      "heading" : "1 Introduction",
      "text" : "This paper considers the following recommendation system problem: given a set of items, a set of users, and non-numerical pairwise comparison data, find the underlying preference ordering of the users. In particular, we are interested in the setting where data is of the form “user i preferes item j over item k”, for different ordered user-item-item triples i, j, k. Pairwise preference data is wide-spread; indeed, almost any setting where a user is presented with a menu of options – and chooses one of them – can be considered to be providing a pairwise preference between the chosen item and every other item that is presented.\nCrucially, we are interested in the collaborative filtering setting, where (a) on the one hand the number of such pairwise preferences we have for any one user is woefully insufficient to infer\nar X\niv :1\n50 7.\n04 45\n7v 1\n[ st\nat .M\nanything for that user in isolation; and (b) on the other hand, we aim for personalization, i.e. for every user to possibly have different inferred preferences from every other. To reconcile these two requirements, our method relates the preferences of users to each other via a low-rank matrix, which we (implicitly) assume governs the observed preferences. Essentially, we fit a low-rank users × items score matrix X to pairwise comparison data by trying to ensure that Xij −Xik is positive when user i prefers item j to item k.\nOur contributions: We present two algorithms to infer the score matrix X from training data; once inferred, this can be used for predicting future preferences. While there has been some recent work on fitting low-rank score matrices to pairwise preference data (which we review and compare to below), in this paper we present the following two contributions: (a) A statistical analysis for the convex relaxation: we bound the generalization error of the solution to our convex program. Essentially, we show that the minimizer of the empirical loss also almost minimizes the true expected loss. We also give a lower bound showing that our error rate is sharp up to logarithmic factors. (b) A large-scale non-convex implementation: We provide a non-convex algorithm that we call Alternating Support Vector Machine (AltSVM). This non-convex algorithm is more practical than the convex program in a large-scale setting; it explicitly parameterizes the low-rank matrix in factored form and minimizes the hinge loss. Crucially, each step in this algorithm can be formulated as a standard SVM that updates one of the two factors; the algorithm proceeds by alternating updates to both factors. We apply a stochastic version of dual coordinate descent [7, 22] with lockfree parallelization. This exploits the problem structure and ensures it parallelizes well. We show that our algorithm outperforms several existing collaborative ranking algorithms in both speed and prediction accuracy, and it achieves significant speedups as the number of cores increases."
    }, {
      "heading" : "1.1 Related Work",
      "text" : "Ranking/learning preferences is a classical problem that has been considered in a large amount of work. There are many different settings for this problem, which we discuss below.\nLearning to Rank The main problem in this community has been to estimate a ranking function from given feature vectors and relevance scores. Depending on its application, a feature vector may correpond to a user-item pair or a single item. While there have been algorithms that use pairwise comparisons [6, 12] of the training samples, our setting is different in that our data consists only of pairwise comparisons. We refer the reader to the survey [15].\nOne ranking with pairwise comparisions In a single-user model, we are asked to learn a single ranking given pairwise comparisons. Jamieson & Nowak [10] and Ailon [1] consider an active query model with noiseless responses; Jamieson & Nowak [11] give an algorithm for exactly recovering the true ranking under a low-rank assumption similar to ours, while Ailon [1] approximately recovers the true ranking without such an assumption. Wauthier et al. [27] and Negahban et al. [18] learn a ranking from noisy pairwise comparisions; Negahban et al. [18] consider a Bradley-Terry-Luce model similar to ours and attempt to learn an underlying score vector, while Wauthier et al. [27] get by without structure assumptions, but only attempt to learn the ranking itself. Hajek et al. [5] considered a problem to learn a single ranking given a more generalized partial rankings from the Plackett-Luce model and provided a minimax-optimal algorithm.\nMany rankings with pairwise comparisions Given multiple users with different rankings, one could of course attempt to learn their rankings by simply applying an algorithm from the previous section to each user individually. However, it is more efficient – both statistically and computationally – to postulate some global structure and use it to relate the many users’ rankings. This is the same idea that has been applied so successfully in collaborative filtering. Rendle et al. [20] and Liu et al. [14] were the first to take this approach. They modeled the observations as coming from a BTL model with low-rank structure (i.e., very similar to our model) and gave algorithms for learning the model parameters. Yi et al. [31] took a purely optimization-based approach. Rather than assuming a probabilistic model, they minimized a convex objective using the hinge loss on a low-rank matrix. In a slightly different model, Hu et al. [9] and Shi et al. [23] consider the problem of learning from latent feedback. Recently, Lu & Negahban [16] analyzed an algorithm which is very similar to ours for the Bradley-Terry-Luce model independently from our work.\nMany rankings with 1-bit ratings Instead of moving to pairwise comparisons, some work has suggested avoiding the difficulties of numerical ratings by instead asking users to give 1-bit ratings to items; that is, each user only indicates whether they like or dislike an item. In this setting, the work of Davenport et al. [4] is most closely related to ours, in that they assume an underlying lowrank structure and give an algorithm based on convex optimization. Also, our theoretical analysis owes a lot to their work. Xu et al. [30] consider a slightly different goal: rather than attempting to recover the preferences of each user, they try to cluster similar users and similar items together. Yun et al. [32] proposed an optimization problem motivated from robust binary classification and used stochastic gradient descent to solve the problem in a large-scale setting.\nMany rankings with numerical ratings The goal in this setting is the same as ours, except that the data is in the form of numerical ratings instead of pairwise comparisons. Weimer et al. [28] attempted to directly optimize Normalized Discounted Cumulative Gain (NDCG), a widely used performance measure for ranking problems. Balakrishnan & Chopra [2], and Volkovs & Zemel [26] converted this problem into a learning-to-rank problem and solved it using the existing algorithms. While these works considered the low-rank matrix model, different models are proposed by Weston et al. [29] and Lee et al. [13]. Weston et al. [29] proposed a tensor model to rank items for different queries and users, and [13] proposed a weighted sum of low-rank matrix models."
    }, {
      "heading" : "2 Empirical Risk Minimization (ERM)",
      "text" : "Let us first formulate the problem mathematically. The task is to estimate rankings of multiple users on multiple items. We denote the numbers of users by d1, and the number of items by d2. We are given a set of triples Ω ⊂ [d1] × [d2] × [d2], where the preference of user i between items j and k is observed if (i, j, k) ∈ Ω. The observed comparison is then given by {Yijk ∈ {1,−1} : (i, j, k) ∈ Ω} where Yijk = 1 if user i prefers item j over item k, and Yijk = −1 otherwise. Let Ωi = {(j, k) : (i, j, k) ∈ Ω} denote the set of item pairs that user i has compared.\nWe predict rankings for multiple users by estimating a score matrix X ∈ Rd1×d2 such that Xij > Xik means that user i prefers item j over item k. Then the sorting order for each row provides the predicted ranking for the corresponding user.\nWe propose (as have others) that X is low-rank or close to low-rank, the intuition being that each user bases their preferences on a small set of features that are common among all the items.\nThen the empirical risk minimization (ERM) framework can naturally be formulated as\nminimize X ∑ (i,j,k)∈Ω L(Yijk(Xij −Xik)) (1)\nsubject to rank(X) ≤ r\nwhere L(·) is a monotonically non-increasing loss function which induces Xij > Xik if Yijk = 1, and Xij < Xik otherwise. (e.g., hinge loss, logistic regression loss, etc.)\nSolving (1) is NP-hard because of the rank constraint. As a first alternative, we propose a straightforward convex relaxation."
    }, {
      "heading" : "3 Convex Relaxation",
      "text" : "Our first method is the convex relaxation of (1), which involves a nuclear norm constraint.\nminimize X ∑ (i,j,k)∈Ω L(Yijk(Xij −Xik)) (2)\nsubject to ‖X‖∗ ≤ √ λd1d2\nHere, for any matrix X, the nuclear/trace norm ‖X‖∗ denotes the sum of its singular values; it is a well-recognized convex surrogate for low-rank structure (most famously in matrix completion).\nThe only parameter of this algorithm is λ, which governs the trade-off between better optimizing the likelihood of the observed data, and the strictness in imposing approximate low-rank structure. Since we motivated our algorithm with the assumption that X has low rank, we should point out how our algorithm’s parameter λ compares to the rank: note that if X is a d1 × d2 rank-r matrix whose largest absolute entry is bounded by C then ‖X‖∗ ≤ √ r‖X‖F ≤ C √ rd1d2. In other words, λ is a parameter that takes into account both the rank of X and the size of its elements, and it is roughly proportional to the rank."
    }, {
      "heading" : "3.1 Analytic results",
      "text" : "We analyze (2) by assuming a standard model for pairwise comparisons. Then we provide a statistical guarantee of the method under the model.\nRecall the classical Bradley-Terry-Luce model [3, 17] for pairwise preferences of a single user, which assumes that the probability of item j being preferred over k is given by a logistic of the difference of the underlying preference scores of the two items. For multiple users, we assume that there is some true score matrix X∗ ∈ Rd1×d2 and\nPr(Yijk = 1) = exp(X∗ij −X∗ik)\n1 + exp(X∗ij −X∗ik) .\nAssume that each user-item-item triple (i, j, k) independently belongs to Ω with probability pi,j,k, and let m = ∑ i,j,k pi,j,k be the expected size of Ω. We will assume that the pi,j,k are approximately balanced in the sense that no user-item pair is observed too frequently:\nAssumption 3.1. There is a constant κ > 0 such that for every i, j,∑ k pi,j,k ≤ κ m d1d2 .\nNote that if κ = 1 in Assumption 3.1 then the pi,j,k are all equal, meaning that each user-itemitem triple has an equal chance to be observed.\nIn order to state our error bounds, we first introduce some notation: let PX be the distribution of {Yi,j,k : 1 ≤ i ≤ d1, 1 ≤ j < k ≤ d2} (i.e. the complete distribution of all pairwise preferences, even those that are not observed).\nOur main upper bound shows that if m is sufficiently large then our algorithm finds a solution with almost minimal risk. Given a loss function L, define the expected risk of X by\nR(X) = 1\nd1d22 d1∑ i=1 d2∑ j,k=1 EX∗L(Yijk(Xij −Xik)),\nwhere the expectation is with respect to the distribution parametrized by the true parameters X∗.\nTheorem 3.1. Suppose that L is 1-Lipschitz, and let Y and Ω be distributed as PX∗ for some d1 × d2 matrix X∗. Under Assumption 3.1,\nER(X̂) ≤ inf {X:‖X‖∗≤ √ λd1d2}\nER(X) + Cκ √ λ(d1 + d2)\nm log(d1 + d2),\nwhere C is a universal constant.\nWe recall that the parameter λ is related to rank in that if X is a d1 × d2 rank-r matrix whose largest absolute entry is bounded by C then ‖X‖∗ ≤ √ r‖X‖F ≤ C √ rd1d2. In other words, λ is a parameter that takes into account both the rank of X∗ and the size of its elements, and it is roughly proportional to the rank. In particular, Theorem 3.1 shows that once we observe m ∼ r(d1+ d2) log\n2(d1 + d2) pairwise comparisons, then we can accurately estimate the probability of any user preferring any item over any other. In other words, we need to observe about r(1+d2/d1) log\n2(d1 + d2) comparisons per user, which is substantially less than the rd2 log(d2) comparisons that we would have required if each user were modelled in isolation. Moreover, our lower bound (below) shows that at least r(1+d2/d1) comparisons per user are required, which is only a logarithmic factor from the upper bound.\nTheorem 3.2. Suppose that L′(0) < 0. Let A be any algorithm that receives {Yi,j,k : (i, j, k) ∈ Ω} as input and produces X̂ as output. For any λ ≥ 1 and m ≥ d1 + d2, there exists X∗ with ‖X∗‖∗ ≤ √ λd1d2 such that when Y and Ω are distributed according to PX∗ then with probability at least 12 ,\nER(X̂) ≥ R(X∗) + cmin { 1, √ λ(d1 + d2)\nm\n} ,\nwhere c > 0 is a constant depending only on L.\nTogether, Theorems 3.1 and 3.2 show that (up to logarithmic factors) ifX∗ has rank r then about r(1 + d2/d1) comparisons per user are necessary and sufficient for learning the users’ preferences."
    }, {
      "heading" : "3.1.1 Maximum likelihood estimation of X∗",
      "text" : "By specializing the loss function L, Theorem 3.1 has a simple corollary for maximum-likelihood estimation of X∗. Recall that if µ and ν are two probability distributions on a finite set S the the\nKullback-Leibler divergence between them is\nD(µ‖ν) = ∑ s∈S µ(s) log µ(s) ν(s) ,\nunder the convention that 0 log 0 = 0. We recall that although D(·‖·) is not a metric it is always non-negative, and that D(µ‖ν) = 0 implies µ = ν.\nCorollary 3.3. Let Y and Ω be distributed as PX∗ for some d1 × d2 matrix X∗. Define the loss function L by L(z) = log(1 + exp(z))− z. Under Assumption 3.1,\n1\nd1d22 sup {X:‖X‖∗≤ √ λd1d2}\nD(PX∗‖PX̂)−D(PX∗‖PX) ≤ Cκ √ λ(d1 + d2)\nm log(d1 + d2),\nwhere C is a universal constant.\nNote that the loss function in Corollary 3.3 is exactly the negative logarithm of the logistic function, and so X̂ in Corollary 3.3 is the maximum-likelihood estimate for X∗. Thus, Corollary 3.3 shows that the distribution induced by the maximum-likelihood estimator is close to the true distribution in Kullback-Leibler divergence."
    }, {
      "heading" : "4 Large-scale Non-convex Implementation",
      "text" : "While the convex relaxation is statistically near optimal, it is not ideal for large-scale datasets because it requires the solution of a convex program with d1 × d2 variables. In this section we develop a non-convex variant which both scales and parallelizes very well, and has better empirical performance as compared to several existing empirical baseline methods.\nOur approach is based on the following steps:\n1. We represent the low-rank matrix in explicit factored form X = UV > and replace the regularizer appropriately. This results in a non-convex optimization problem in U ∈ Rd1×r and V ∈ Rd2×r, where r is the rank parameter.\n2. We solve the non-convex problem by alternating between updating U while keeping V fixed, and vice versa. With the hinge loss (which we found works best in experiments), each of these becomes an SVM problem - hence we call our algorithm AltSVM.\n3. The problem is of course not symmetric in U and V because users rank items but not vice versa. For the U update, each user vector naturally decouples and can be done in parallel (and in fact just reduces to the case of rankSVM [12]).\n4. For the V update, we show that this can also be made into an SVM problem; however it involves coupling of all item vectors, and all user ratings. We employ several tricks (detailed below) to speed up and effectively parallelize this step.\nThe non-convex problem can be written as\nmin U,V ∑ (i,j,k)∈Ω L(Yijk · u>i (vj − vk)) + λ 2 (‖U‖2F + ‖V ‖2F ) (3)\nwhere we replace the nuclear norm regularizer using the property ‖X‖∗ = minX=UV > 12(‖U‖ 2 F + ‖V ‖2F ) [24]. u>i and v>i denote the ith rows of U and V , respectively. While this is a non-convex algorithm for which it is hard to find the global optimum, it is computationally more efficient since only (d1 +d2)r variables are involved. We propose to use L2 hinge loss, i.e., L(x) = max(0, 1−x)2.\nIn the alternating minimization of (3), the subproblem for U is to solve\nU ← arg min U∈Rd1×r ∑ (i,j,k)∈Ω L(Yijk · u>i (vj − vj)) + λ 2 ‖U‖2F , (4)\nwhile V is fixed. This can be decomposed into n independent problems for ui’s where each solves for\nui ← arg min u∈Rr\nλ 2 ‖u‖22 + ∑ (j,k)∈Ωi L(Yijk · u>(vj − vk). (5)\nThis part is in general a small-scale problem as the dimension is r, and the sample size is |Ωi| for each user i.\nOn the other hand, solving for V with fixed U can be written as\nV ← arg min V ∈Rd2×r λ2 ‖V ‖2F + ∑ (i,j,k)∈Ω L(〈V,A(u,i,j)〉)  (6) where A(i,j,k) ∈ Rd2×r is such that the lth row of A(i,j,k) is Yijk · u>i if l = j, −Yijk · u>i if l = k, and 0 otherwise. It is a much larger SVM problem than (5) as the dimension is d2r and the sample size is |Ω|.\nWe note that the feature matrices {A(i,j,k) : (i, j, k) ∈ Ω} are highly sparse since in each feature matrix only 2r out of the d2r elements are nonzero. This motivates us to apply the stochastic dual coordinate descent algorithm [7, 22], which not only converges fast but also takes advantages of feature sparsity in linear SVMs. Each coordinate descent step takes O(r) computation, and iterations over |Ω| coordinates provide linear convergence [22].\nNow we describe the dual problems of our two subproblems explicitly. Let α ∈ R|Ωi| denote the dual vector for (5), in which each coordinate is denoted by αijk where (j, k) ∈ Ωi. Then the dual problem of (5) is to solve\nmin α∈R|Ωi|,α≥0\n1\n2 ∥∥∥∥∥∥ ∑\n(j,k)∈Ωi\nαijkYijk(vj − vk) ∥∥∥∥∥∥ 2\n2\n+ 1\nλ ∑ (j,k)∈Ωi L∗(−λαijk) (7)\nwhere L∗(z) is the convex conjugate of L. At each coordinate descent step for αijk, we find the value of αijk minimizing (7) while all the other variables are fixed. If we maintain ui =∑\n(j,k)∈Ωi αijkYijk(vj − vk), then the coordinate descent step is simply to find δ ∗ minimizing\n1 2 ‖ui + δ∗Yijk(vj − vk)‖22 + 1 λ L∗(−λ(αijk + δ∗)) (8)\nand update αijk ← αijk + δ∗.\nAlgorithm 1 Alternating Support Vector Machine (AltSVM)\nRequire: Ω, {Yijk : (i, j, k) ∈ Ω}, and λ ∈ R+ Ensure: U ∈ Rd1×r, V ∈ Rd2×r\n1: Initialize U , and set α, β ← 0 ∈ R|Ω| 2: while not converged do 3: vj ←\n∑ (i,j,k)∈Ω βijkYijkui − ∑\n(i,k,j)∈Ω βikjYikjui, ∀j ∈ [d2] 4: for all threads t = 1, . . . , T in parallel do 5: for s = 1, . . . , S do 6: Choose (i, j, k) ∈ Ω uniformly at random 7: Find δ∗ minimizing (10). 8: βijk ← βijk + δ∗ 9: vj ← vj + δ∗Yijkui\n10: vk ← vk − δ∗Yijkui 11: end for 12: end for 13: ui ← ∑ (i,j,k)∈Ω αijkYijk(vj − vk), ∀i ∈ [d1] 14: for all threads t = 1, . . . , T in parallel do 15: for s = 1, . . . , S do 16: Choose (i, j, k) ∈ Ω uniformly at random. 17: Find δ∗ minimizing (8). 18: αijk ← αijk + δ∗ 19: ui ← ui + δ∗Yijk(vj − vk) 20: end for 21: end for 22: end while\nThe dual problem of (6) is to solve\nmin β∈R|Ω|,β≥0\n1\n2 ∥∥∥∥∥∥ ∑\n(i,j,k)∈Ω\nβijkA (i,j,k) ∥∥∥∥∥∥ 2\nF\n+ 1\nλ ∑ (i,j,k)∈Ω L∗(−λβijk) (9)\nwhere β is the dual vector for the subproblem (6). Similarly to αijk, the coordinate descent step for βijk is to replace βijk by βijk + δ ∗ where δ∗ minimizes\n1\n2\n( ‖vj + δ∗Yijkui‖22 + ‖vk − δ ∗Yijkui‖22 ) + L∗(−λ(βijk + δ∗)), (10)\nand maintain V = ∑\n(i,j,k)∈Ω βijkYijkA (i,j,k).\nThe detailed description of AltSVM is presented in Algorithm 1. In each subproblem, we run the stochastic dual coordinate descent, in which a pairwise comparison (i, j, k) ∈ Ω is chosen uniformly at random, and the dual coordinate descent for αijk or βijk is computed. We note that each coordinate descent step takes the same O(r) computational cost in both subproblems, while the subproblem sizes are much different."
    }, {
      "heading" : "4.1 Parallelization",
      "text" : "For each subproblem, we parallelize the stochastic dual coordinate descent algorithm asynchronously without locking. Given T processors, each processor randomly sample a triple (i, j, k) ∈ Ω and update the corresponding dual variable and the user or item vectors. We note that this update is for a sparse subset of the parameters. In the user part, a coordinate descent step for one sample updates only r out of the rd1 variables. In the item part, one coordinate descent step for a sample update only 2r out of the rd2 variables. This motivates us not to lock the variables when updated, so that we ignore the conflicts. This lock-free parallelism is shown to be effective in [19] for stochastic gradient descent (SGD) on the sum of sparse functions. Moreover, in [8], it is also shown that the stochastic dual coordinate descent scales well without locking. We implemented the algorithm using the OpenMP framework. In our implementations, we also parallelized steps 3 and 13 of Algorithm 1. We show in the next section that our proposed algorithm scales up favorably."
    }, {
      "heading" : "4.2 Remark on the implementation",
      "text" : "In Algorithm 1, the subproblem for V comes first, and then it solves for the user vectors U . We empirically observed that this order gives better convergence on practical datasets. We also note that each subproblem reuses the dual variables in the previous outer iteration. When almost converged, the features (V for solving U , and U for solving V ) do not change too much. By reusing the dual variables in the previous iteration we can start with a feasible solution close to the optimum."
    }, {
      "heading" : "5 Experimental results",
      "text" : ""
    }, {
      "heading" : "5.1 Pairwise data",
      "text" : "We used the MovieLens 100k dataset, which contains 100,000 ratings given by 943 users on 1682 movies. The ratings are given as integers from one to five, but we converted them into preference data by declaring that a user preferred one movie to another if they gave it a higher rating (if two movies received the same rating, we treated it as though the user did not provide a preference). Then we held out 20% of the data as a test set.\nWe compared our algorithm to the following two:\n• Bayesian Personalized Ranking (BPR) [20]: This algorithm is based on a similar model to ours, but a different optimization procedure (essentially, a variant of stochastic gradient descent).\n• Matrix completion from pairwise differences : A standard matrix completion algorithm that observes – for various triples (i, j, k) ∈ Ω – the difference between user i’s ratings for item j and item k. Note that this algorithm has an advantage over (2) because it sees the magnitude of this difference instead of only its sign. Nevertheless, the matrix completion algorithm does not perform any better than (2). A similar phenomenon was also observed in [4].\nWe evaluate our performance by computing the proportion of pairwise comparisons in the test set T for which we correctly infer the user’s preference.\n(Prediction error) = 1 |T | ∑\n(i,j,k)∈T ,Yijk=1\nI(Xij > Xik)\nThis is similar to the AUC statistic measured by Rendle et al. [20], and if the data were fully observed then it would measure Kendall’s distance between each user’s true preferences and the learned ones. However, our main reason for choosing this measure of performance is that, as an average accuracy over all pairwise comparisions, it resembles the quantity that we study in our theoretical bounds.\nUnsurprisingly, we were more accurate at correctly inferring strong preferences; therefore, we have also shown the accuracy obtained by only measuring performance on pairs whose rankings differ by two or more. Both the methods we considered do measurably better at predicting these orderings."
    }, {
      "heading" : "5.2 Large-scale experiments on rating data",
      "text" : "Now we demonstrate that our algorithm performs well as a collaborative ranking method on rating data. We used the datasets specified in Table 1. Given a training set of ratings for each user, our algorithm will only use non-tying pairwise comparisons from the set, while other competing algorithms use the ratings themselves. Hence, they have more information than ours. The competing algorithms are those with publicly available codes provided by the authors.\n• CofiRank [28]1 This algorithm uses alternating minimization to directly optimize NDCG. 1http://www.cofirank.org, The dimension and the regularization parameter are set as suggested in the paper.\nFor the rest of the parameters, we left them as provided.\n• Local Collaborative Ranking (LCR) [13]2 : The main idea is to predict preferences from the weighted sum of multiple low-rank matrices model.\n• RobiRank [32]3 : This algorithm uses stochastic gradient descent to optimize the loss function motivated from robust binary classification.\n• Global Ranking : To see the effect of personalized ranking, we compare the results with a global ranking of the items. We fixed U to all ones and solved for V .\nThe algorithms are compared in terms of two standard performance measures of ranking, which are NDCG and Precision@K. NDCG@K is the ranking measure for numerical ratings. NDCG@K for user i is defined as\nNDCG@K(i) = DCG@K(i, πi)\nDCG@K(i, π∗i )\nwhere\nDCG@K(i, πi) = K∑ k=1 2Miπi(k) − 1 log2(k + 1) ,\nand πu(k) is the index of the kth ranked item of Ti in our prediction. Mij is the true rating of item j by user i in the given dataset, and π∗u is the permutation that maximizes DCG@K. This measure counts only the top K items in our predicted ranking and put more weights on the prediction of highly ranked items. We measured NDCG@10 in our experiments. Precision@K is the ranking measure for binary ratings. Precision@K for user i is defined as\nPrecision@K(i) = 1\nK ∑ j∈PK(i) Mij\nwhere Mij is the binary rating on item j by user i given in the dataset. This counts the number of relevant items in the predicted top K recommendation. These two measures are averaged over all of the users.\nWe first compare our algorithm with numerical rating based algorithms, CofiRank and LCR. We follow the standard setting that are used in the collaborative ranking literature [28, 2, 26, 13].\n2http://prea.gatech.edu, We run the code with each of the 48 sets of loss function and parameters given in the main code, and the best result is reported. We could not run this algorithm on the Netflix dataset due to time constraint.\n3https://bitbucket.org/d_ijk_stra/robirank, We used the part for collaborative ranking from binary relevence score. We left the parameter settings as provide with the implementation.\nFor each user, we subsampled N ratings, used them for training, and took the rest of the ratings for test. The users with less than N + 10 ratings were dropped out. Table 2 compares AltSVM with numerical rating based algorithms. While N = 20 is too small so that a global ranking provides the best NDCG, our algorithm performs the best with larger N . We also ran our algorithm with subsampled pairwise comparions with the largest numerical gap (AltSVM-sub), which are as many as N for each user (the number of numerical ratings used in the other algorithms). Even with this, we could achieve better NDCG. We can also observe that the statistical performance is better with the hinge loss than with the logistic loss.\nWe have also experimented with collaborative ranking on binary ratings. We compare our algorithm against RobiRank [32], which is a recently proposed algorithm for collaborative ranking with binary ratings. We ran an experiment on a binarized version of the Movielens1m dataset. In this case, the movies rated by a user is assumed to be relevant to the user, and the other items are not. Since it is inefficient to take all possible comparisons which are in average a half million per user, we subsampled C comparisons for each user. Both algorithms are set to estimate rank-100 matrices. Table 3 shows that our algorithm provides better performance than RobiRank."
    }, {
      "heading" : "5.3 Computational speed and Scalability",
      "text" : "We now show the computational speed and scalability of our practical algorithm, AltSVM. The experiments were run on a single 16-core machine in the Stampede Cluster at University of Texas.\nFigures 2a and 2b show NDCG@10 over time of our algorithms with 1, 4, and 16 threads, com-\npared to CofiRank. Figure 2c shows Precision@10 over time of our algorithm with C = 5000. We note that our algorithm converges faster, while the sample size |Ω| for our algorithm is larger than the number of training ratings that are used in the competing algorithms. Table 4 shows the scalability of AltSVM. We measured the time to achieve 10−5 tolerance on the binarized MovieLens1m dataset. As can be seen in the table, we could achieve significant speedup."
    }, {
      "heading" : "6 Conclusion",
      "text" : "We considered the collaborative ranking problem where one fits a low-rank matrix to the pairwise comparisons by multiple users. We showed that the convex relaxation of the empirical risk minimization provides good generalization guarantees. For the large-scale practical settings, we also proposed a non-convex algorithm, which alternately solves two SVM problems. Our algorithm was shown to outperform the existing ones and parallelizes well."
    }, {
      "heading" : "A Proof of Theorem 3.1",
      "text" : "We write L(X) for the function being optimized; i.e., L(X) = ∑\n(i,j,k)∈Ω\nL(Yi,j,k(Xi,j −Xi,k)).\nNote that for any fixed X, PX∗L(X) = mR(X) (where PX∗ denotes the expectation taken with respect to future samples from PX∗ , as distinct from E which denotes the expectation over the samples used to generate X̂). Let K be the set of d1 × d2 matrices with nuclear norm at most 1. The proof of Theorem 3.1 proceeds in three main steps.\n1. By some algebraic of manipulations L, we reduce the problem to showing a uniform law of large numbers for the family of functions {L(X) : X ∈ √ λd1d2K}.\n2. Using symmetrization and duality properties of K, we reduce the problem to bounding the norm of a matrix M whose entries are sums of random signs.\n3. We bound the norm ofM using various concentration inequalities and a theorem of Seginer [21].\nSince X̂, by definition, minimizes L(X̂), for any X̃ ∈ √ λd1d2K we can bound\nPX∗ [L(X̂)− L(X̃)] ≤ PX∗ [L(X̂)]− L(X̂)− ( PX∗ [L(X̃)]− L(X̃) ) ≤ 2 sup\nX∈ √ λd1d2k\n|PX∗L(X)− L(X)|.\nIn other words, it suffices to show a uniform law of large numbers for {L(X) : X ∈ √ λd1d2K}.\nLet i,j,k be i.i.d. ±1-valued variables and let ξi,j,k be the indicator that (i, j, k) ∈ Ω. By Giné-Zinn’s symmetrization (as in [4]),\nsup X∈ √ λd1d2K\n|PX∗L(X)− L(X)|\n≤ 2E sup X∈ √ λd1d2K ∣∣∣∣∣∣ ∑ i,j,k∈Ω i,j,kL(Yi,j,k(Xi,j −Xi,k)) ∣∣∣∣∣∣ . Since L is 1-Lipschitz, we obtain\nsup X∈ √ λd1d2K |PX∗ [L(X)]− L(X)| ≤ 2E sup X∈ √ λd1d2K ∣∣∣∣∣∣ ∑ i,j,k∈Ω i,j,kYi,j,k(Xi,j −Xi,k) ∣∣∣∣∣∣ = 2E sup\nX∈ √ λd1d2K ∣∣∣∣∣∣ ∑ i,j,k ξi,j,k i,j,k(Xi,j −Xi,k) ∣∣∣∣∣∣ , where in the last line, we recognized that i,j,kYi,j,k has the same distribution as i,j,k. Now, let M denote the matrix where Mij =\n∑ k(ξi,j,k i,j,k − ξi,k,j i,k,j). Then∑\ni,j,k\nξi,j,k i,j,k(Xi,j −Xi,k) = tr(MTX)\nand so sup\nX∈ √ λd1d2K ∑ i,j,k ξi,j,k i,j,k(Xi,j −Xi,k) = sup X∈ √ λd1d2K tr(MTX) = √ λd1d2‖M‖.\nPutting everything together, we have (for any X̃ ∈ √ λd1d2K)\nE [ PX∗ [L(X̂)]− PX∗ [L(X̃)] ] ≤ 4 √ λd1d2E‖M‖.\nTogether with the following lemma (which we prove in Appendix B), this completes the proof of Theorem 3.1\nLemma A.1. With p = md1d2 ,\nE‖M‖ ≤ Cκ √ p(d1 + d2) log(d1d2)."
    }, {
      "heading" : "B Proof of Lemma A.1",
      "text" : "We will decompose M into two parts, M = M (1) −M (2), with\nM (1) ij = ∑ k 6=j ξi,j,k i,j,k\nM (2) ij = ∑ k 6=j ξi,k,j i,k,j .\nThen ‖M‖ ≤ ‖M (1)‖+ ‖M (2)‖. Since M (1) and M (2) have the same distribution,\nE‖M‖ ≤ 2E‖M (1)‖,\nand so we are reduced to studying M (1), which has i.i.d. entries. Now, we apply Seginer’s theorem [21]:\nE‖M (1)‖ ≤ C ( Emax\ni ‖M (1)i∗ ‖2 + Emaxj ‖M (1) ∗j ‖2\n) , (11)\nwhere M (1) i∗ denotes the ith row of M (1) and M (1) ∗j denotes the jth column, and ‖ · ‖2 denotes the Euclidean norm. We will separate the task of bounding Emaxi ‖M (1)i∗ ‖2 into two parts: if ‖x‖0 denotes the\nnumber of non-zero coordinates in x and ‖x‖∞ denotes maxj |xj | then ‖x‖2 ≤ √ ‖x‖0‖x‖∞; with the Cauchy-Schwarz inequality, this implies that( E [ max i ‖M (1)i∗ ‖2 ])2 ≤ E [ max i ‖M (1)i∗ ‖0 ] E [ max i ‖M (1)i∗ ‖ 2 ∞ ] (12)\nFirst, we will show that every row of M (1) is sparse. Let Zij = ∑\nk 6=j ξi,j,k and let Yij be the indicator that Zij > 0. Recalling that Eξi,j,k = pi,j,k, we have (by Assumption 3.1) EZij ≤ κp. Since Zij takes non-negative integer values, we have Pr(Yij = 1) = Pr(Zij > 0) ≤ κp. By Bernstein’s inequality, for any fixed i\nPr(‖M (1)i∗ ‖0 ≥ κd2p+ t) ≤ Pr( d2∑ j=1 Yij ≥ κd2p+ t) ≤ exp ( − t 2/2 κpd2 + t/3 ) .\nIntegrating by parts, we have\nE [ ‖M (1)i∗ ‖0 ] ≤ κd2p+ ∫ ∞ κd2p Pr(‖M (1)i∗ ‖0 ≥ t) dt ≤ κd2p+ 3 8 .\nNext, we will consider the size of the elements in M (1). First of all, M (1) ij ≤ Zij (this fairly crude bound will lose us a factor of √\nlog(d1d2)). Now, Bernstein’s inequality applied to Zij gives\nPr(M (1) ij ≥ κp+ t) ≤ Pr(Zij ≥ κp+ t) ≤ exp\n( − t 2/2\nκp+ t/3\n) .\nTaking a union bound over i and j, if t ≥ Cκ log(d1d2) then\nPr(max ij\nM (1) ij ≥ t) ≤ d1d2 exp (−ct) ≤ exp(−c ′t).\nIntegrating by parts, E [ max ij M (1) ij ] ≤ κ log2(d1d2) + ∫ ∞ κ log2(d1d2) Pr(max ij M (1) ij ≥ √ t) dt ≤ κ log2(d1d2) + C.\nGoing back to (12), we have shown that\nEmax i ‖M (1)i∗ ‖ ≤ Cκ\n√ pd2 log(d1d2).\nThe same argument applies to M (1) ∗j (but with √ pd1 instead of √ pd2), and so we conclude from (11) that E‖M (1)‖ ≤ Cκ √ p(d1 + d2) log(d1d2)."
    }, {
      "heading" : "C Proof of Theorem 3.2",
      "text" : "C.1 A sketch of the proof\nThe proof of Theorem 3.2 uses Fano’s inequality.\n1. We construct matrices X1, . . . , X`. These matrices all have small nuclear norm, and for every pair i, j the KL-divergence between the induced observation distributions is Θ(log `). We construct these matrices randomly, using concentration inequalities and a union bound to show that we can take ` of the order √ λm(d1 + d2).\n2. We apply Fano’s inequality to show that if we generate data according to a randomly chosen Xi, then any algorithm has a reasonable chance to choose a different Xj (using the fact that the KL-divergence is O(log `)). Since the KL-divergence is Ω(log `), this implies that the algorithm incurs a substantial penalty whenever it makes a wrong choice.\nIn any application of Fano’s inequality, the key is to construct a large number of admissible models that are close to one another in KL-divergence. Specifically, if we can construct distributions P1, . . . ,P` with D(Pi‖Pj) + 1 ≤ 12 log ` for all i, j, then given a single sample from some Pi, no algorithm can accurately identify which Pi it came from. In order to apply this denote by PX,m the distribution of the data when the true parameters are X. We will construct X1 . . . , X` ∈ √ λd1d2K such that for all i 6= j,\nD(PXi,m‖PXj ,m) + 1 ≤ 1\n2 log `, (13)\nRj(X i) ≥ Rj(Xj) + c\nlog `\nm (14)\nfor some constant c > 0, where Rj denotes the expected risk when the true parameters are given by Xj . Given a single observation from some PXj ,m, (13) will imply (by Fano’s inequality) that no algorithm can correctly identify which Xj was the true parameter. On the other hand, (14) will imply that if the algorithm makes a mistake – say it chooses Xi for i 6= j – then its risk will be c log `m larger than the best in the class. In particular, if we can prove (13) and (14) with\nlog ` ∼ √ λm(d1 + d2) then it will imply Theorem 3.2.\nWe construct a set of matrices satisfying (13) and (14) using a probabilistic method. Supposing that d2 ≥ d1, we choose a parameter γ > 0 and set B to be an integer that is approximately λγ−2. We define X1 by filling its top B×d2 block with independent, uniform ±γ entries, and then copying that top block B/d1 times to fill the matrix. Then let X\n2, . . . , X` be independent copies of X1. First of all, each Xi ∈ √ λd1d2K because ‖Xi‖∗ ≤ √ rank(Xi)‖Xi‖F ≤ √ λd1d2.\nNow, let us consider D(PX1,m‖PX2,m). For a single i, j, k triple, there is probability 1/4 of having X1i,j−X1i,k different from X2i,j−X2i,k, in which case they differ by 4γ. If γ is bounded above, each different entry contributes Θ(α2γ2) to the KL-divergence between PX1,m and PX2,m. Since about m entries are observed in PX1,m, we see that\nD(PX1,m‖PX2,m) mγ2. (15)\nOn the other hand, R1(X 1) and R1(X 2) differ by Θ(γ2), because for a constant fraction of triples i, j, k, the chance that Yi,j,k is 1 differs by O(γ) in X\n1 and X2, and on the event that Yi,j,k differs in these two models the loss differs by another O(γ) factor.\nApplying standard concentration inequalities, we show that one can apply the union bound to ` = exp(cBd2) of these matrices. In view of (13) and (15), we need to take Bd2 = λ2\nγ2d1 mγ2. Eliminating γ, we end up with log ` √ λm/d1 (which is within a constant factor of √ λm(d1 + d2) under our assumption that d2 ≥ d1).\nC.2 Some concentration lemmas\nWe begin by quoting some standard concentration results (see, e.g. [25]).\nDefinition C.1. A random variable X is σ2-subgaussian if EeθX ≤ eθ2σ2/2 for all θ > 0. A random variable X is L-subexponential if EeθX ≤ (1− θ2L2) for θ < 1/L.\nOne can easily show that the product of two subgaussian variables is subexponential:\nLemma C.2. If X is σ2-subgaussian and Y is τ2-subgaussian then XY is Cστ -subexponential for a universal constant C.\nMoreover, one has a Bernstein-type inequality for sums of independent subexponential variables.\nLemma C.3. If X1, . . . , Xk are i.i.d. L-subexponential then\nPr( ∑ i Xi ≥ t) ≤ exp ( − ct 2 L2k + Lt ) .\nC.3 Construction of a packing set\nLet 0 < γ < 1 be some parameter to be determined such that B := λγ−2 is an integer.\nProposition C.4. Suppose that L′(0) < 0. For every sufficiently small γ (depending on L), there exists a set X ⊂ √ λd1d2K of exp(cBd2) d1 × d2 matrices such that for any two X1, X2 ∈ X ,\n1\nd1d22 d1∑ i=1 d2∑ j,k=1 EX1 [L(Y (X2ij −X2ik))− L(Y (X1ij −X1ik))] ≥ cγ2\nand for any m, 1\nm D(PX1,m‖PX2,m) ≤ Cγ2,\nwhere 0 < c < C are universal constants.\nFollowing Davenport et al., we construct this set X randomly: let X be a random B×d2 matrix, where each element is chosen independently to be either γ or −γ.\nLemma C.5. Let X1 and X2 be independent copies of X. Then with probability at least 1 − exp(−cBd2),\nB∑ i=1 d2∑ j,k=1 (X1ij −X1ik −X2ij +X2ik)2 ≥ 2γ2Bd22,\nwhere c > 0 is a universal constant.\nBefore proving Lemma C.5, let us see how it implies Proposition C.4. First of all, for X a random B×d2 matrix as above, let X̃ be the d1×d2 matrix obtained by stacking dd1/Be copies of X, and filling out any remaining entries by zeros. Then, for random X and Y , with high probability\nd1∑ i=1 d2∑ j,k=1 (X̃1ij − X̃1ik − X̃2ij + X̃2ik)2 = dd1/Be B∑ i=1 d2∑ j,k=1 (X1ij −X1ik −X2ij +X2ik)2\nγ2d1d22, (16)\nwhere the lower bound for the last line came from Lemma C.5, and the upper bound just came from the observation that each term in the sum is bounded by 16γ2. Let X be the set obtained by choosing exp(cBd2/4) random copies of X̃ in this way. The high-probability estimate in Lemma C.5 implies that with high probability, every pair X̃1, X̃2 in X satisfies (16). Now,\nD(PX1,m‖PX2,m) = EΩ  ∑ (i,j,k)∈Ω D(f(X1ij −X1ik)‖f(X2ij −X2ik))  m d1d22 ∑ i,j,k (X1ij −X1ik −X2ij +X2ik)2,\nwhere f(x) = ex/(1 + ex) is the logistic function, and the last line follows from a Taylor expansion of D(f(x)‖f(y)) around x = y, because all the X1ij and X2ij are bounded by γ < 1. Together with (16), this proves the first inequality in Proposition C.4; the second inequality follows because\neach term of the form D(f(Xij−Xik)‖f(Yij−Yik)) is bounded by a constant times γ2. This proves the second inequality of Proposition C.4.\nBy Taylor expansion again, if γ is sufficiently small (depending on L) then\nL(Yi,j,k(X2i,j −X2i,k))− L(Yi,j,k(X1i,j −X1i,k)) Yi,j,k(X1i,j −X1i,k −X2i,j +X2i,k).\nNow, if i, j, k is a triple for which 2γ = X1i,j−X1i,k > X2i,j−X2i,k (and under the event of Lemma C.5, there are at least cBd22 such triples) then EX1 [Yi,j,k] γ and so\nEX1 [L(Yi,j,k(X2i,j −X2i,k))− L(Yi,j,k(X1i,j −X1i,k))] γ2.\nThe same holds when i, j, k is a triple for which −2γ = X1i,j −X1i,k < X2i,j −X2i,k. Finally, if i, j, k is a triple such that X1i,j −X1i,k = X2i,j −X2i,k then the expectation is zero. Summing over all triples, we see that on the event that Lemma C.5 holds,\n1\nBd22 ∑ i,j,k EX1 [L(Yi,j,k(X2i,j −X2i,k))− L(Yi,j,k(X1i,j −X1i,k))] ≥ cγ2.\nAfter summing over all dd1/Be blocks, this proves the first inequality of Proposition C.4.\nProof of Lemma C.5. We expand the square:∑ ijk (Xij −Xik − Yij + Yik)2 = 2 ∑ ijk X2ij + Y 2 ij + 2XijYik −XijXik − YijYik − 2XijYij\n= 4γ2Bd22 + 2 ∑ ijk 2XijYik −XijXik − YijYik − 2XijYij . (17)\nWe may study each of the cross-terms separately: for the XijYik term, note that ∑ j Xij and ∑\nk Yik are both γ2d2-subgaussian (by Hoeffding’s inequality). Hence, ∑ jkXijYik is Cγ\n2d2-subexponential (by Lemma C.2) and so by Lemma C.3,\nPr ∣∣∣∣∣∣ ∑ ijk XijYik ∣∣∣∣∣∣ ≥ 18γ2Bd22  ≤ 2 exp(−cBd2).\nThe similar argument applies to the XijXik term: ∑ j Xij is γ 2d2-subgaussian and so ∑ ijkXijXik =∑\ni( ∑ j Xij) 2 is Cγ2d2-subexponential; hence\nPr ∣∣∣∣∣∣ ∑ ijk XijXik ∣∣∣∣∣∣ ≥ 18γ2Bd22  ≤ 2 exp(−cBd2).\nOf course, the YijYik term is identical. Finally, note that ∑ ijkXijYij = d2 ∑\nij XijYij . Since the terms in this sum are i.i.d., we may apply Hoeffding’s inequality to obtain\nPr ∣∣∣∣∣∣ ∑ ijk XijYij ∣∣∣∣∣∣ ≥ 18γ2Bd22  = Pr ∣∣∣∣∣∣ ∑ ij XijYij ∣∣∣∣∣∣ ≥ 18γ2Bd2  ≤ 2 exp(−cB2d22).\nPutting everything together, we see that with high probability, the total of all the cross-terms in (17) is at most half of the first term.\nC.4 Completing the proof\nLet C denote the constant from Proposition C.4. Assume that d1 ≤ d2 and that m is large enough so √\nd2 m ≤ 8C\n√ λ ≤\n√ m\nd2 . (18)\nNote that under the assumptions λ ≥ 1 and m ≥ d1 +d2 from Theorem 3.2, the lower bound of (18) is satisfied. Moreover, if the upper bound of (18) is not satisfied then we may decrease λ until it is; the conclusion of Theorem 3.2 will not be affected because as long as (18) fails, the minimum in Theorem 3.2 will be 1.\nBy the lower bound in (18), there is an integer B such that B ≤ √ λm\nd2 ≤ 2B;\nfix this B and define γ by\nγ2 = λ/B √ λd2 m .\nBy the upper bound in (18), γ ≤ 1. Now, Fano’s inequality states that if we first select a random X ∈ X and then draw a sample from PX,m, then any algorithm trying to identify X can succeed with probability at most\nmin{D(PX,m‖P(Y,m)) : X,Y ∈ X}+ 1 log |X | ≤ 2Cmγ 2 Bd2 ≤ 1 2 .\nFinally, note that by the first inequality in Proposition C.4, the error incurred by choosing the wrong X ∈ X is at least cγ2 √\nλd2 m .\nNow, we have so far only discussed the case d2 ≥ d1. The case d1 ≤ d2 is not exactly equivalent because our model is not symmetric in its treatment of users and items. However, the proof of Theorem 3.2 does not change very much. We take horizontally stacked blocks of size d1×B instead of B × d2. The main difference is in the calculation leading to (16): there are extra cross-terms appearing due to the fact that items in different blocks need to be compared with one another. However, all of these additional terms may be controlled with Lemmas C.2 and C.3 in much the same way as the existing terms are controlled."
    }, {
      "heading" : "D Comparison to Stochastic Gradient Descent",
      "text" : "Another practical algorithm to optimize (3) is Stochastic Gradient Descent (SGD). We have experimented SGD on the same datasets in Table 1. We ran the algorithm with the same regularization parameters and different step sizes. The statistical results for SGD were observed to be no better than AltSVM, and hence we did not present them in the main paper.\nLet us first describe the SGD procedure. At each step, ones chooses a triple (i, j, k) ∈ Ω\nuniformly at random and run a SGD step, which can be written as u+i ← ui − η · { g · (vj − vk) + λ\n|Ωi| ui } v+j ← vj − η · { g · ui + λ\n|Ωj | vj } v+j ← vj − η · { −g · ui + λ\n|Ωk| vk } where Ω(j) denotes the number of comparisons in Ω which involve item j. η is a step size and g ∈ ∂L(u>i (vj − vk)).\nThe following tables show the statistical result of SGD. The step size is chosen by η = α1+βt as suggested in [33]. α and β were the powers of 10−1, and the best result is reported. The results are comparable to AltSVM, but it did not achieve better results. We note that this is the best result from several different step sizes, while AltSVM does not have any other parameter to choose except for the regularization parameter."
    } ],
    "references" : [ {
      "title" : "Active learning ranking from pairwise preferences with almost optimal query complexity",
      "author" : [ "Ailon", "Nir" ],
      "venue" : "In Advances in Neural Information Processing Systems (NIPS),",
      "citeRegEx" : "1",
      "shortCiteRegEx" : "1",
      "year" : 2011
    }, {
      "title" : "Collaborative ranking",
      "author" : [ "Balakrishnan", "Suhrid", "Chopra", "Sumit" ],
      "venue" : "In ACM International Conference on Web Search and Data Mining (WSDM),",
      "citeRegEx" : "2",
      "shortCiteRegEx" : "2",
      "year" : 2012
    }, {
      "title" : "Rank analysis of incomplete block designs: I. the method of paired comparisons",
      "author" : [ "Bradley", "Ralph Allan", "Terry", "Milton E" ],
      "venue" : null,
      "citeRegEx" : "3",
      "shortCiteRegEx" : "3",
      "year" : 1952
    }, {
      "title" : "1-bit matrix completion",
      "author" : [ "Davenport", "Mark A", "Plan", "Yaniv", "Berg", "Ewout van den", "Wootters", "Mary" ],
      "venue" : "Information and Inference,",
      "citeRegEx" : "4",
      "shortCiteRegEx" : "4",
      "year" : 2014
    }, {
      "title" : "Minimax-optimal inference from partial rankings",
      "author" : [ "Hajek", "Bruce", "Oh", "Sewoong", "Xu", "Jiaming" ],
      "venue" : "In Advances in Neural Information Processing Systems (NIPS),",
      "citeRegEx" : "5",
      "shortCiteRegEx" : "5",
      "year" : 2014
    }, {
      "title" : "Large Margin Rank Boundaries for Ordinal Regression, chapter 7, pp. 115–132",
      "author" : [ "Herbrich", "Ralf", "Graepel", "Thore", "Obermayer", "Klaus" ],
      "venue" : null,
      "citeRegEx" : "6",
      "shortCiteRegEx" : "6",
      "year" : 2000
    }, {
      "title" : "A dual coordinate descent method for large-scale linear SVM",
      "author" : [ "Hsieh", "Cho-Jui", "Chang", "Kai-Wei", "Lin", "Chih-Jen", "Keerthi", "S. Sathiya", "S. Sundararajan" ],
      "venue" : "In International Conference on Machine Learning (ICML),",
      "citeRegEx" : "7",
      "shortCiteRegEx" : "7",
      "year" : 2008
    }, {
      "title" : "PASSCoDe: Parallel asynchronous stochastic dual co-ordinate descent",
      "author" : [ "Hsieh", "Cho-Jui", "Yu", "Hsiang-Fu", "Dhillon", "Inderjit S" ],
      "venue" : "In International Conference on Machine Learning (ICML),",
      "citeRegEx" : "8",
      "shortCiteRegEx" : "8",
      "year" : 2015
    }, {
      "title" : "Collaborative filtering for implicit feedback datasets",
      "author" : [ "Hu", "Yifan", "Koren", "Yehuda", "Volinsky", "Chris" ],
      "venue" : "In IEEE International Conference on Data Mining (ICDM),",
      "citeRegEx" : "9",
      "shortCiteRegEx" : "9",
      "year" : 2008
    }, {
      "title" : "Active ranking using pairwise comparisons",
      "author" : [ "K.G. Jamieson", "R. Nowak" ],
      "venue" : "In Advances in Neural Information Processing Systems (NIPS),",
      "citeRegEx" : "10",
      "shortCiteRegEx" : "10",
      "year" : 2011
    }, {
      "title" : "Active ranking using pairwise comparisons",
      "author" : [ "Jamieson", "Kevin G", "Nowak", "Robert D" ],
      "venue" : "In Advances in Neural Information Processing Systems (NIPS),",
      "citeRegEx" : "11",
      "shortCiteRegEx" : "11",
      "year" : 2011
    }, {
      "title" : "Optimizing search engines using clickthrough data",
      "author" : [ "Joachims", "Thorsten" ],
      "venue" : "In SIGKDD,",
      "citeRegEx" : "12",
      "shortCiteRegEx" : "12",
      "year" : 2002
    }, {
      "title" : "Local collaborative ranking",
      "author" : [ "Lee", "Joonseok", "Bengio", "Samy", "Kim", "Seungyeon", "Lebanon", "Guy", "Singer", "Yoram" ],
      "venue" : "In International World Wide Web Conference (WWW),",
      "citeRegEx" : "13",
      "shortCiteRegEx" : "13",
      "year" : 2014
    }, {
      "title" : "Probabilistic latent preference analysis for collaborative filtering",
      "author" : [ "Liu", "Nathan N", "Zhao", "Min", "Yang", "Qiang" ],
      "venue" : "In Proceedings of the 18th ACM conference on Information and knowledge management,",
      "citeRegEx" : "14",
      "shortCiteRegEx" : "14",
      "year" : 2009
    }, {
      "title" : "Learning to Rank for Information Retrieval",
      "author" : [ "Liu", "Tie-Yan" ],
      "venue" : "Now Publishers Inc.,",
      "citeRegEx" : "15",
      "shortCiteRegEx" : "15",
      "year" : 2009
    }, {
      "title" : "Individualized rank aggregation using nuclear norm regularization",
      "author" : [ "Lu", "Yu", "Negahban", "Sahand" ],
      "venue" : "ArXiv e-prints:",
      "citeRegEx" : "16",
      "shortCiteRegEx" : "16",
      "year" : 2014
    }, {
      "title" : "Iterative ranking from pair-wise comparisons",
      "author" : [ "Negahban", "Sahand", "Oh", "Sewoong", "Shah", "Devavrat" ],
      "venue" : "In Advances in Neural Information Processing Systems (NIPS),",
      "citeRegEx" : "18",
      "shortCiteRegEx" : "18",
      "year" : 2012
    }, {
      "title" : "Hogwild: A lock-free approach to parallelizing stochastic gradient descent",
      "author" : [ "Niu", "Feng", "Recht", "Benjamin", "Ré", "Christopher", "Wright", "Stephen" ],
      "venue" : "In Advances in Neural Information Processing Systems (NIPS),",
      "citeRegEx" : "19",
      "shortCiteRegEx" : "19",
      "year" : 2011
    }, {
      "title" : "Bpr: Bayesian personalized ranking from implicit feedback",
      "author" : [ "Rendle", "Steffen", "Freudenthaler", "Christoph", "Gantner", "Zeno", "Schmidt-Thieme", "Lars" ],
      "venue" : "In Proceedings of the Twenty-Fifth Conference on Uncertainty in Artificial Intelligence,",
      "citeRegEx" : "20",
      "shortCiteRegEx" : "20",
      "year" : 2009
    }, {
      "title" : "The expected norm of random matrices",
      "author" : [ "Seginer", "Yoav" ],
      "venue" : "Combinatorics Probability and Computing,",
      "citeRegEx" : "21",
      "shortCiteRegEx" : "21",
      "year" : 2000
    }, {
      "title" : "Stochastic dual coordinate ascent methods for regularized loss minimization",
      "author" : [ "Shalev-Shwartz", "Shai", "Zhang", "Tong" ],
      "venue" : "Journal of Machine Learning Research (JMLR),",
      "citeRegEx" : "22",
      "shortCiteRegEx" : "22",
      "year" : 2013
    }, {
      "title" : "Climf: collaborative less-is-more filtering",
      "author" : [ "Shi", "Yue", "Karatzoglou", "Alexandros", "Baltrunas", "Linas", "Larson", "Martha", "Oliver", "Nuria", "Hanjalic", "Alan" ],
      "venue" : "In Proceedings of the Twenty-Third international joint conference on Artificial Intelligence,",
      "citeRegEx" : "23",
      "shortCiteRegEx" : "23",
      "year" : 2013
    }, {
      "title" : "Maximum margin matrix factorization",
      "author" : [ "Srebro", "Nathan", "Rennie", "Jason", "Jaakkola", "Tommi" ],
      "venue" : "In Advances in Neural Information Processing Systems (NIPS),",
      "citeRegEx" : "24",
      "shortCiteRegEx" : "24",
      "year" : 2004
    }, {
      "title" : "Compressed sensing: theory and applications, chapter Introduction to the non-asymptotic analysis of random matrices",
      "author" : [ "Vershynin", "Roman" ],
      "venue" : null,
      "citeRegEx" : "25",
      "shortCiteRegEx" : "25",
      "year" : 2012
    }, {
      "title" : "Collaborative ranking with 17 parameters",
      "author" : [ "Volkovs", "Maksims N", "Zemel", "Richard S" ],
      "venue" : "In Advances in Neural Information Processing Systems (NIPS),",
      "citeRegEx" : "26",
      "shortCiteRegEx" : "26",
      "year" : 2012
    }, {
      "title" : "Efficient ranking from pairwise comparisons",
      "author" : [ "Wauthier", "Fabian L", "Jordan", "Michael I", "Jojic", "Nebojsa" ],
      "venue" : "In International Conference on Machine Learning (ICML),",
      "citeRegEx" : "27",
      "shortCiteRegEx" : "27",
      "year" : 2013
    }, {
      "title" : "Cofirank: maximum margin matrix factorization for collaborative ranking",
      "author" : [ "Weimer", "Markus", "Karatzoglou", "Alexandros", "Le", "Quoc V", "Smola", "Alex" ],
      "venue" : "In Advances in Neural Information Processing Systems (NIPS),",
      "citeRegEx" : "28",
      "shortCiteRegEx" : "28",
      "year" : 2007
    }, {
      "title" : "Latent collaborative retrieval",
      "author" : [ "Weston", "Jason", "Want", "Chong", "Weiss", "Ron", "Berenzeig", "Adam" ],
      "venue" : "In International Conference on Machine Learning (ICML),",
      "citeRegEx" : "29",
      "shortCiteRegEx" : "29",
      "year" : 2012
    }, {
      "title" : "Jointly clustering rows and columns of binary matrices: Algorithms and trade-offs",
      "author" : [ "Xu", "Jiaming", "Wu", "Rui", "Zhu", "Kai", "Hajek", "Bruce", "R Srikant", "Ying", "Lei" ],
      "venue" : "In ACM Sigmetrics,",
      "citeRegEx" : "30",
      "shortCiteRegEx" : "30",
      "year" : 2013
    }, {
      "title" : "Inferring users preferences from crowdsourced pairwise comparisons: A matrix completion approach",
      "author" : [ "Yi", "Jinfeng", "Jin", "Rong", "Jain", "Shaili", "Anil" ],
      "venue" : "In First AAAI Conference on Human Computation and Crowdsourcing,",
      "citeRegEx" : "31",
      "shortCiteRegEx" : "31",
      "year" : 2013
    }, {
      "title" : "Ranking via robust binary classification and parallel parameter estimation in large-scale data",
      "author" : [ "Yun", "Hyokun", "Raman", "Parameswaran", "S.V.N. Vishwanathan" ],
      "venue" : "In Advances in Neural Information Processing Systems (NIPS),",
      "citeRegEx" : "32",
      "shortCiteRegEx" : "32",
      "year" : 2014
    } ],
    "referenceMentions" : [ {
      "referenceID" : 6,
      "context" : "We apply a stochastic version of dual coordinate descent [7, 22] with lockfree parallelization.",
      "startOffset" : 57,
      "endOffset" : 64
    }, {
      "referenceID" : 20,
      "context" : "We apply a stochastic version of dual coordinate descent [7, 22] with lockfree parallelization.",
      "startOffset" : 57,
      "endOffset" : 64
    }, {
      "referenceID" : 5,
      "context" : "While there have been algorithms that use pairwise comparisons [6, 12] of the training samples, our setting is different in that our data consists only of pairwise comparisons.",
      "startOffset" : 63,
      "endOffset" : 70
    }, {
      "referenceID" : 11,
      "context" : "While there have been algorithms that use pairwise comparisons [6, 12] of the training samples, our setting is different in that our data consists only of pairwise comparisons.",
      "startOffset" : 63,
      "endOffset" : 70
    }, {
      "referenceID" : 14,
      "context" : "We refer the reader to the survey [15].",
      "startOffset" : 34,
      "endOffset" : 38
    }, {
      "referenceID" : 9,
      "context" : "Jamieson & Nowak [10] and Ailon [1] consider an active query model with noiseless responses; Jamieson & Nowak [11] give an algorithm for exactly recovering the true ranking under a low-rank assumption similar to ours, while Ailon [1] approximately recovers the true ranking without such an assumption.",
      "startOffset" : 17,
      "endOffset" : 21
    }, {
      "referenceID" : 0,
      "context" : "Jamieson & Nowak [10] and Ailon [1] consider an active query model with noiseless responses; Jamieson & Nowak [11] give an algorithm for exactly recovering the true ranking under a low-rank assumption similar to ours, while Ailon [1] approximately recovers the true ranking without such an assumption.",
      "startOffset" : 32,
      "endOffset" : 35
    }, {
      "referenceID" : 10,
      "context" : "Jamieson & Nowak [10] and Ailon [1] consider an active query model with noiseless responses; Jamieson & Nowak [11] give an algorithm for exactly recovering the true ranking under a low-rank assumption similar to ours, while Ailon [1] approximately recovers the true ranking without such an assumption.",
      "startOffset" : 110,
      "endOffset" : 114
    }, {
      "referenceID" : 0,
      "context" : "Jamieson & Nowak [10] and Ailon [1] consider an active query model with noiseless responses; Jamieson & Nowak [11] give an algorithm for exactly recovering the true ranking under a low-rank assumption similar to ours, while Ailon [1] approximately recovers the true ranking without such an assumption.",
      "startOffset" : 230,
      "endOffset" : 233
    }, {
      "referenceID" : 25,
      "context" : "[27] and Negahban et al.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 16,
      "context" : "[18] learn a ranking from noisy pairwise comparisions; Negahban et al.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 16,
      "context" : "[18] consider a Bradley-Terry-Luce model similar to ours and attempt to learn an underlying score vector, while Wauthier et al.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 25,
      "context" : "[27] get by without structure assumptions, but only attempt to learn the ranking itself.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 4,
      "context" : "[5] considered a problem to learn a single ranking given a more generalized partial rankings from the Plackett-Luce model and provided a minimax-optimal algorithm.",
      "startOffset" : 0,
      "endOffset" : 3
    }, {
      "referenceID" : 18,
      "context" : "[20] and Liu et al.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 13,
      "context" : "[14] were the first to take this approach.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 29,
      "context" : "[31] took a purely optimization-based approach.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 8,
      "context" : "[9] and Shi et al.",
      "startOffset" : 0,
      "endOffset" : 3
    }, {
      "referenceID" : 21,
      "context" : "[23] consider the problem of learning from latent feedback.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 15,
      "context" : "Recently, Lu & Negahban [16] analyzed an algorithm which is very similar to ours for the Bradley-Terry-Luce model independently from our work.",
      "startOffset" : 24,
      "endOffset" : 28
    }, {
      "referenceID" : 3,
      "context" : "[4] is most closely related to ours, in that they assume an underlying lowrank structure and give an algorithm based on convex optimization.",
      "startOffset" : 0,
      "endOffset" : 3
    }, {
      "referenceID" : 28,
      "context" : "[30] consider a slightly different goal: rather than attempting to recover the preferences of each user, they try to cluster similar users and similar items together.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 30,
      "context" : "[32] proposed an optimization problem motivated from robust binary classification and used stochastic gradient descent to solve the problem in a large-scale setting.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 26,
      "context" : "[28] attempted to directly optimize Normalized Discounted Cumulative Gain (NDCG), a widely used performance measure for ranking problems.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 1,
      "context" : "Balakrishnan & Chopra [2], and Volkovs & Zemel [26] converted this problem into a learning-to-rank problem and solved it using the existing algorithms.",
      "startOffset" : 22,
      "endOffset" : 25
    }, {
      "referenceID" : 24,
      "context" : "Balakrishnan & Chopra [2], and Volkovs & Zemel [26] converted this problem into a learning-to-rank problem and solved it using the existing algorithms.",
      "startOffset" : 47,
      "endOffset" : 51
    }, {
      "referenceID" : 27,
      "context" : "[29] and Lee et al.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 12,
      "context" : "[13].",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 27,
      "context" : "[29] proposed a tensor model to rank items for different queries and users, and [13] proposed a weighted sum of low-rank matrix models.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 12,
      "context" : "[29] proposed a tensor model to rank items for different queries and users, and [13] proposed a weighted sum of low-rank matrix models.",
      "startOffset" : 80,
      "endOffset" : 84
    }, {
      "referenceID" : 2,
      "context" : "Recall the classical Bradley-Terry-Luce model [3, 17] for pairwise preferences of a single user, which assumes that the probability of item j being preferred over k is given by a logistic of the difference of the underlying preference scores of the two items.",
      "startOffset" : 46,
      "endOffset" : 53
    }, {
      "referenceID" : 11,
      "context" : "For the U update, each user vector naturally decouples and can be done in parallel (and in fact just reduces to the case of rankSVM [12]).",
      "startOffset" : 132,
      "endOffset" : 136
    }, {
      "referenceID" : 22,
      "context" : "where we replace the nuclear norm regularizer using the property ‖X‖∗ = minX=UV > 12(‖U‖ 2 F + ‖V ‖F ) [24].",
      "startOffset" : 103,
      "endOffset" : 107
    }, {
      "referenceID" : 6,
      "context" : "This motivates us to apply the stochastic dual coordinate descent algorithm [7, 22], which not only converges fast but also takes advantages of feature sparsity in linear SVMs.",
      "startOffset" : 76,
      "endOffset" : 83
    }, {
      "referenceID" : 20,
      "context" : "This motivates us to apply the stochastic dual coordinate descent algorithm [7, 22], which not only converges fast but also takes advantages of feature sparsity in linear SVMs.",
      "startOffset" : 76,
      "endOffset" : 83
    }, {
      "referenceID" : 20,
      "context" : "Each coordinate descent step takes O(r) computation, and iterations over |Ω| coordinates provide linear convergence [22].",
      "startOffset" : 116,
      "endOffset" : 120
    }, {
      "referenceID" : 17,
      "context" : "This lock-free parallelism is shown to be effective in [19] for stochastic gradient descent (SGD) on the sum of sparse functions.",
      "startOffset" : 55,
      "endOffset" : 59
    }, {
      "referenceID" : 7,
      "context" : "Moreover, in [8], it is also shown that the stochastic dual coordinate descent scales well without locking.",
      "startOffset" : 13,
      "endOffset" : 16
    }, {
      "referenceID" : 18,
      "context" : "We compared our algorithm to the following two: • Bayesian Personalized Ranking (BPR) [20]: This algorithm is based on a similar model to ours, but a different optimization procedure (essentially, a variant of stochastic gradient descent).",
      "startOffset" : 86,
      "endOffset" : 90
    }, {
      "referenceID" : 3,
      "context" : "A similar phenomenon was also observed in [4].",
      "startOffset" : 42,
      "endOffset" : 45
    }, {
      "referenceID" : 18,
      "context" : "[20], and if the data were fully observed then it would measure Kendall’s distance between each user’s true preferences and the learned ones.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 26,
      "context" : "• CofiRank [28]1 This algorithm uses alternating minimization to directly optimize NDCG.",
      "startOffset" : 11,
      "endOffset" : 15
    }, {
      "referenceID" : 12,
      "context" : "• Local Collaborative Ranking (LCR) [13]2 : The main idea is to predict preferences from the weighted sum of multiple low-rank matrices model.",
      "startOffset" : 36,
      "endOffset" : 40
    }, {
      "referenceID" : 30,
      "context" : "• RobiRank [32]3 : This algorithm uses stochastic gradient descent to optimize the loss function motivated from robust binary classification.",
      "startOffset" : 11,
      "endOffset" : 15
    }, {
      "referenceID" : 26,
      "context" : "We follow the standard setting that are used in the collaborative ranking literature [28, 2, 26, 13].",
      "startOffset" : 85,
      "endOffset" : 100
    }, {
      "referenceID" : 1,
      "context" : "We follow the standard setting that are used in the collaborative ranking literature [28, 2, 26, 13].",
      "startOffset" : 85,
      "endOffset" : 100
    }, {
      "referenceID" : 24,
      "context" : "We follow the standard setting that are used in the collaborative ranking literature [28, 2, 26, 13].",
      "startOffset" : 85,
      "endOffset" : 100
    }, {
      "referenceID" : 12,
      "context" : "We follow the standard setting that are used in the collaborative ranking literature [28, 2, 26, 13].",
      "startOffset" : 85,
      "endOffset" : 100
    }, {
      "referenceID" : 30,
      "context" : "We compare our algorithm against RobiRank [32], which is a recently proposed algorithm for collaborative ranking with binary ratings.",
      "startOffset" : 42,
      "endOffset" : 46
    } ],
    "year" : 2015,
    "abstractText" : "In this paper we consider the collaborative ranking setting: a pool of users each provides a small number of pairwise preferences between d possible items; from these we need to predict each users preferences for items they have not yet seen. We do so by fitting a rank r score matrix to the pairwise data, and provide two main contributions: (a) we show that an algorithm based on convex optimization provides good generalization guarantees once each user provides as few as O(r log d) pairwise comparisons – essentially matching the sample complexity required in the related matrix completion setting (which uses actual numerical as opposed to pairwise information), and (b) we develop a large-scale non-convex implementation, which we call AltSVM, that trains a factored form of the matrix via alternating minimization (which we show reduces to alternating SVM problems), and scales and parallelizes very well to large problem settings. It also outperforms common baselines on many moderately large popular collaborative filtering datasets in both NDCG and in other measures of ranking performance.",
    "creator" : "LaTeX with hyperref package"
  }
}