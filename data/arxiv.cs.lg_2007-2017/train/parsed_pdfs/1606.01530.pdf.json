{
  "name" : "1606.01530.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "Adaptive Submodular Ranking",
    "authors" : [ "Fatemeh Navidi", "Prabhanjan Kambadur", "Viswanath Nagarajan" ],
    "emails" : [ ],
    "sections" : [ {
      "heading" : "1 Introduction",
      "text" : "Many tasks in machine learning can be represented as sequential decision processes. An algorithm is given an a priori distribution D over inputs, and its goal is to satisfy the realized input i∗ ∈ D. In each step, the algorithm chooses an action which partially satisfies i∗ and also provides a feedback depending on i∗. This feedback is then used to refine the distribution of i∗ for the subsequent steps. So an algorithm in this setting (also called policy) is an adaptive sequence of actions.\nFurthermore, many different criteria to satisfy the realized input i∗ can be modeled as covering a submodular function. Submodular functions are a very general class of set-functions that have certain convexity as well as concavity properties [24]. These functions are used to model utilities in game theory, influence maximization in social networks, diversity in search ranking etc.\nIn this paper, we study an adaptive optimization problem in the setting described above which simultaneously generalizes many previously-studied problems such as optimal decision trees [20, 23, 10, 8, 18, 9], equivalence class determination [14, 7], decision region determination [22] and submodular ranking [3, 21]. We obtain an algorithm with the best-possible approximation guarantee. Moreover, our algorithm is very simple to state and implement. We also present some preliminary experimental results which are promising.\nBefore defining the adaptive submodular ranking problem formally, we discuss two special cases with applications in active learning and search ranking.\nOptimal Decision Trees. This is a basic problem in active learning, which is also called entity identification. There are m possible hypotheses with an a priori distribution D on the true hypothesis i∗. The distribution D is given by probabilities {pi}mi=1 that sum to one. We can perform tests in order to distinguish between the hypotheses. Each test e costs ce and is positive for a particular subset Te of hypotheses. We assume that i\n∗ can be identified by performing all tests.The goal in the optimal decision tree problem is to determine the true hypothesis i∗ at the minimum expected cost. Figure 1(a) shows an example with 3 hypotheses, 7 tests and probabilities\n∗Department of Industrial and Operations Engineering, University of Michigan †Bloomberg Labs\nar X\niv :1\n60 6.\n01 53\n0v 1\n[ cs\n.D S]\n5 J\nun 2\n01 6\np1 = 0.4, p2 = 0.5, p3 = 0.1; the sets S1, S2, S3 depict the positive tests for each hypothesis; the decision tree corresponds to a feasible adaptive solution with expected cost 1.5.\nAdaptive Multiple Intent Ranking. This is an adaptive version of the search ranking problem studied in [4, 5, 25]. Suppose there are n results to a particular query and m different user-types. Each user-type i is characterized by a subset Si of the results and a threshold Ki ≤ |Si|, which means that a user of type i will be satisfied after seeing at least Ki results from the subset Si. We are also given a distribution D on the m user-types. The ranking algorithm displays results one by one, and receives feedback on whether each displayed result e is relevant to user-type i∗, i.e. whether/not e ∈ Si∗ . The goal is find an ordering of the n results that minimizes the expected number of results before satisfying a random user i∗ ∈ D. Note that the algorithm needs to balance its effort in learning the identity of i∗ and satisfying the requirement of i∗. Figure 1(b) shows an example with m = 3, n = 7 and probabilities p1 = 0.4, p2 = 0.5, p3 = 0.1; the set system depicts the interest-sets Sis and the thresholds are K1 = K2 = 2, K3 = 4; the decision tree corresponds to a feasible adaptive solution with expected cost 2.7.\nFor some adaptive optimization problems, one can come up with approximately optimal solutions using static (non-adaptive) solutions that are insensitive to the feedback obtained, eg. [11, 6]. However, this is not the case for the adaptive submodular ranking problem that we consider. Even for the special cases above, there are instances where the optimal adaptive value is much less than the optimal non-adaptive value. So it is important to come up with an adaptive algorithm.\nProblem Statement. We start with some basics. A set function f : 2U → R+ on ground set U is said to be submodular if for all subsets A,B ⊆ U we have f(A) + f(B) ≥ f(A∩B) + f(A∪B). See [24] for background. The function f is said to be monotone if f(A) ≤ f(B) for all A ⊆ B ⊆ U . We assume that set functions are given in the standard value oracle model, i.e. we can evaluate f(S) for any S ⊆ U in polynomial time.\nIn the adaptive submodular ranking problem (ASR) we have a ground set U of n elements with costs {ce}e∈U . We also have m scenarios. Each scenario i ∈ [m] := {1, · · · ,m} is specified by an interest-set Si ⊆ U and a normalized monotone submodular function fi : 2Si → [0, 1] where fi(∅) = 0 and fi(Si) = 1 (every monotone submodular function on Si can be expressed in this form by scaling and truncation). For notational simplicity, we extend each function fi : 2\nSi → [0, 1] to arbitrary subsets S ⊆ U by setting fi(S) = fi(S ∩ Si). A scenario i ∈ [m] is said to be covered/satisfied by any subset S ⊆ U of elements such that fi(S) = 1. We are also given a distribution D on the m scenarios, i.e. probabilities {pi}mi=1 that sum to one: this means that the realized scenario i∗ = i with probability pi, for each i ∈ [m]. The goal in ASR is to find an adaptive ordering of the elements in U that minimizes the expected cost to cover the realized scenario i∗ ∈ D. The key aspect of this problem is that the ranking algorithm receives feedback on whether/not each chosen element e is relevant to user i∗ (i.e. whether e ∈ Si∗), and can use this information to choose the next element.\nAn adaptive solution is represented by a binary decision tree T , where nodes are labeled by elements e ∈ U . Every scenario i ∈ [m] traces a root-leaf path in the decision tree T which takes the\nyes-branch on any node e ∈ Si and the no-branch on any node e 6∈ Si; let Ti denote the sequence of elements on this path. Every scenario i ∈ [m] must be satisfied in the decision tree, i.e. fi(Ti) ≥ 1. The cost of scenario i in decision tree T is the cost of the shortest prefix T̄i of Ti such that fi(T̄i) ≥ 1. The objective in ASR is to minimize the expected cost. We note that multiple scenarios may trace the same path in T .\nAn important parameter in the analysis of our algorithm is the following:\n:= min i∈[m], S⊆U min e∈U :fi(S∪e)>fi(S)\nfi(S ∪ e)− f(S). (1)\nThis measures the minimum positive incremental value of any element. This same parameter or its variants appear in all results on the submodular cover problem, eg. [26, 3, 21, 15].\nResults. Our main result is an O(log 1 + logm)-approximation algorithm for adaptive submodular ranking where > 0 is as defined in (1) and m is the number of scenarios. Assuming P 6= NP , this result is the best possible (up to constant factors) as the set cover problem [12] is a special case of ASR even when m = 1. Our algorithm is a simple adaptive greedy-style algorithm. At each step, we assign a score to each remaining element and select the element with maximum score.\nSuch a simple algorithm was previously unknown even in the special case of optimal decision tree (under arbitrary costs/probabilities), despite a large number of papers [20, 23, 10, 1, 8, 16, 18, 13, 9] on this topic. The first O(logm)-approximation algorithm for ODT was obtained in [18], and this result was extended to the equivalence class determination problem in [9]. Previous results, eg. [23, 10, 1, 8, 16], based on a simple greedy “splitting” algorithm, had a logarithmic dependence on either costs or probabilities which (in the worst case) can be exponential in m.\nAs direct applications of our algorithm, we obtain approximation algorithms for the two problems mentioned above: an O(log(maxiKi)+logm)-approximation for the adaptive multiple intent ranking problem and an O(logm)-approximation for optimal decision tree. More applications and details can be seen in Section 3.\nRelated Works. Our work unifies two distinct lines of work in a clean manner. One line of work is on the submodular cover problem and its variants [26, 4, 3, 21]. The other line of work is on the optimal decision tree problem and its variants, eg. [23, 10, 18, 13, 9]. In particular, we combine the time-based analysis for the deterministic submodular ranking problem in [21] with the phase-based analysis for optimal decision tree in [23, 18, 9].\nWe note that [21] also considers a stochastic variant of submodular ranking, but it is different from ASR because [21] assumes an independent distribution whereas we assume a correlated scenariobased distribution. In particular, unlike ASR, the stochastic submodular ranking problem in [21] does not capture the optimal decision tree problem and its variants.\nRecently, [15] also considered a scenario-based submodular cover problem. However, their model requires a single submodular function for all scenarios, whereas ASR allows an individual submodular function for each scenario. In this respect our setting is a generalization of [15], eg. ASR captures the submodular ranking problem [3] whereas [15] does not. On the other hand, [15] allows arbitrary feedback whereas ASR as defined only considers binary (yes/no) feedback. We note that our algorithm can be extended to obtain an O(log 1 + logm)-approximation in the setting with arbitrary feedback as well – see Section 3.\nThe notion of “adaptive submodularity” [13] has been very useful in obtaining algorithms for some previously-studied special cases [14, 7, 22] of ASR. In particular, among other results [13] obtained an O(log 1/ + log 1/pmin)-approximation algorithm for ASR when fi = f for all scenarios i, the function f is adaptive-submodular (a stronger condition than submodular) and pmin = min m i=1 pi is the minimum probability. Our result is stronger in the following ways (i) we allow non-uniform functions fi for each scenario, (ii) we only require submodularity of these functions, (iii) our performance guarantee O(log 1 + logm) is better. We note that [15] is also an improvement over [13] in points (ii) and (iii) above."
    }, {
      "heading" : "2 The Algorithm",
      "text" : "Recall that an instance of ASR consists of a ground set U of elements with costs {ce}e∈U , and m scenarios with an interest-set Si ⊆ U , submodular function fi : 2Si → [0, 1] and probability pi associated with each scenario i ∈ [m]. The goal in ASR is to find an adaptive ordering of the elements in U that minimizes the expected cost to cover the realized scenario i∗ ∈ D.\nThe “state” of our algorithm (i.e. any node in its decision tree) will be represented by (i) the set E ⊆ U of previously displayed elements, and (ii) the set H ⊆ [m] of scenarios that are compatible with feedback (on E) received so far and are still uncovered. At any state (E,H), our algorithm does the following. For each element e ∈ U \\ E, we define Le(H) ⊆ H as follows:\nLe(H) = argmin(|{i ∈ H : e ∈ Si}|, |{i ∈ H : e 6∈ Si}|) (2)\nThen we select element e ∈ U \\ E that maximizes:\n1 ce ·  ∑ j∈Le(H) pj + ∑ i∈H pi · fi(e ∪ E)− fi(E) 1− fi(E)  . (3) Note that H only contains uncovered scenarios. So fi(E) < 1 for all i ∈ H and the denominator in the sum above is always positive. Next we analyze the performance of this algorithm. Below, for any subset T ⊆ [m] of scenarios, we use Pr(T ) = ∑i∈T pi.\nLet OPT denote an optimal solution to the ASR instance and ALG be the solution found by the above algorithm. Set L := 15(1 + ln 1/ + log2m) and its choice will be clear later. We assume (without loss of generality) by scaling that all costs are positive integers. We refer to the total cost incurred at any point in a solution as the time. For any k = 0, 1, · · · , we define the following quantities:\n• Ak ⊆ [m] is the set of uncovered scenarios of ALG at time L · 2k, and ak = Pr(Ak).\n• xk is the probability of uncovered scenarios of OPT at time 2k−1. Claim 1. The expected cost of ALG and OPT can be bounded as follows.\nCALG ≤ L ∑ k≥0 2kak + L and COPT ≥ 1 2 ∑ k≥1 2k−1xk (4)\nProof. In ALG, for all k ≥ 1, the probability of scenarios for which the cover time is in (2k−1L, 2kL] is equal to ak−1 − ak. So we have:\nCovALG ≤ ∑ k≥1 2kL(ak−1 − ak) = ∑ k≥1 2kLak−1 − ∑ k≥1 2kLak (5)\n= 2 ∑ k≥0 2kLak − ( ∑ k≥0 2kLak − L) = ∑ k≥0 2kLak + L (6)\nAbove we use this fact that a0 = 1. On the other hand, in OPT, for all k ≥ 1, the probability of scenarios for which the cover time is in (2k−2, 2k−1] is equal to xk−1 − xk. So we have:\nCovOPT ≥ ∑ k≥2 2k−2(xk−1 − xk) = ∑ k≥2 2k−2xk−1 − ∑ k≥2 2k−2xk (7)\n= ∑ k≥1 2k−1xk − 1 2 ( ∑ k≥1 2k−1xk − 1) ≥ 1 2 ∑ k≥1 2k−1xk (8)\nWhere we use this fact that x1 = 1.\nThus, if we could upper bound each ak by some multiple of xk, then it is easy to establish the approximation factor. However, this is not the case here and instead we prove:\nLemma 2.1. For all k ≥ 1 we have ak ≤ 0.2ak−1 + 3xk. This lemma implies our main result:\nTheorem 2.2. The algorithm for ASR is an O(log 1/ + logm)-approximation algorithm. Proof. Let Q = ∑ k≥0 L · 2kak + L, which is the bound on CALG from (4). Using Lemma 2.1:\nQ ≤ L · ∑ k≥1 2k(0.2ak−1 + 3xk) + L(a0 + 1)\n≤ 0.4L · ∑ k≥0 2kak + 6L · ∑ k≥1 2k−1xk + L(a0 + 1)\n≤ 0.4(Q− L) + 6L · ∑ k≥1 2k−1xk + 2L ≤ 0.4 ·Q+ 12L · COPT + 1.6L (9)\nThe first inequality in (9) is by definition of Q and a0 ≤ 1. The second inequality in (9) uses the bound on COPT from (4). Finally, as COPT ≥ 1 (all costs are positive integers), we have Q ≤ 0.4 ·Q + 13.6L · COPT . This yields Q ≤ 1366 L · COPT . Since L = 15(1 + ln 1/ + logm) and CALG ≤ Q, we obtain the theorem.\nWe now prove Lemma 2.1 for a fixed k ≥ 1. Consider any time t between L · 2k−1 and L · 2k. Note that ALG’s decision tree induces a partition of all the uncovered scenarios at time t, where each part H consists of all scenarios that are at a particular node (E,H) at time t. Let R(t) denote the set of parts in this partition. Note that all scenarios in Ak appear in R(t) as these scenarios are uncovered even at time L · 2k ≥ t. Similarly, all scenarios in R(t) are also in Ak−1.\nFor any part H ∈ R(t), let (E,H) denote the node in ALG’s decision tree corresponding to H. We note that E consists of all elements that have been completely displayed by time t. The element f selected at this node is not included in E (though f starts at/before time t it is not yet completely displayed). Let TH(k) denote the subtree of OPT that corresponds to paths traced by scenarios in H up to time 2k−1. Note that each node (labeled by element e ∈ E) in TH(k) has two outgoing branches: one corresponding to Le(H) and the other to H \\ Le(H). We define Stemk(H) to be the path in TH(k) that at each node (labeled e) follows the branch corresponding to H \\ Le(H). Below we also use Stemk(H) to denote the set of elements that are completely displayed on this path. As all the scenarios in H are compatible with the feedback from elements E,\nObservation 1. Consider any node (E,H) in ALG. Then for all e ∈ E we have exactly one of the following: e ∈ Si for all i ∈ H, or e /∈ Si for all i ∈ H. Hence, Le(H) = ∅ for all e ∈ E.\nDefinition 1. Each node (E,H) in ALG is exactly of one of the following types:\n• “bad” if the probability of uncovered scenarios at the end of Stemk(H) is at least Pr(H)3 .\n• “okay” if it is not bad and the probability of ∪e∈Stemk(H) Le(H) is at least Pr(H) 3 .\n• “good” if it is neither bad nor okay and the probability of scenarios that get covered by Stemk(H) is at least Pr(H) 3 .\nTo see that this is well defined, note by definition of Stemk(H) that each scenario in H is (i) uncovered at the end of Stemk(H), or (ii) in Le(H) for some e ∈ Stemk(H), or (iii) covered by some prefix of Stemk(H). So the total probability of the scenarios in one of these 3 categories must be at least Pr(H)3 . Therefore each node (E,H) is at least of one of the three types mentioned.\ntime : L2k−1 time : L2ktime : t\ngood\nH1\nH4\nbad\nokay\nH2\nH3\nH5\nH6\nH7\nR(t) = {H1, H2, H3, H4, H5, H6, H7} R(t) is a partition of uncovered scenarios at time t\nFigure 3: Bad, good and okay nodes in ALG\nObservation 2. For any time L2k−1 < t ≤ L2k, we have ∑H∈R(t) H:bad Pr(H) < 3xk.\nProof. Note that Stemk(H) ⊆ TH(k). Recall that TH(k) was the subtree of OPT up to time 2k−1 that only contains the scenarios in H. So, the probability of uncovered scenarios at the end of Stemk(H) is at most the probability of scenarios in H that are not covered in OPT by time 2\nk−1. This probability is at least equal to P (H)/3 based on the definition of bad nodes. Now, since nodes in R(t) denotes a subpartition of scenarios, we have\n∑ H∈R(t) H:bad Pr(H)/3 < xk.\nThe following quantity turns out to be useful in our proof of Lemma 2.1.\nG := L2k∑\nt>L2k−1 ∑ H∈R(t) max e∈U\\E 1 ce · ( Pr(Le(H)) + ∑ i∈H pi · fi(e ∪ E)− fi(E) 1− fi(E) ) (10)\nAbove, for any H ∈ R(t) the set E of elements comes from the node (E,H) in ALG corresponding to H. Note that G corresponds to the total “gain” according to our algorithm’s selection criterion (3) accrued from time L2k−1 to L2k. In what follows we obtain a lower and upper bound for G and combine them to prove lemma 2.1.\nLemma 2.3. We have G ≥ L · (ak − 3xk)/3\nProof. Considering only the good/okay nodes in each R(t) in the expression (10) for G,\nG ≥ L2k∑\nt>L2k−1 ∑ H∈R(t) H:okay max e∈U\\E Pr(Le(H)) ce + L2k∑ t>L2k−1 ∑ H∈R(t) H:good max e∈U\\E 1 ce · ∑ i∈H pi · fi(e ∪ E)− fi(E) 1− fi(E)\nFix any time t. For any node (E,H) with H ∈ R(t) define W (H) = Stemk(H) \\ E. Recall that the total cost of elements in Stemk(H) is at most 2 k−1; so c(W (H)) ≤ 2k−1.\nCase 1. (E,H) is an okay node. Since W (H) ⊆ U \\ E we can write:\nmax e∈U\\E\nPr(Le(H))\nce ≥ max e∈W (H)\nPr(Le(H))\nce ≥\n∑ e∈W (H) Pr(Le(H))\nc(W (H)) ≥ Pr(∪e∈W (H)Le(H)) 2k−1\n= 1\n2k−1 · Pr(∪e∈Stemk(H)Le(H)) ≥\nPr(H)\n3 · 2k−1 (11)\nThe equality in (11) is by Observation 1, and the last inequality is by definition of an okay node. Case 2. (E,H) is a good node. Below, we use F ⊆ H to denote the set of scenarios that get covered in Stemk(H); by definition of a good node, we have Pr(F ) ≥ Pr(H)/3. Again using W (H) ⊆ U \\ E, we have:\nmax e∈U\\E\n1 ce · ∑ i∈H pi · fi(e ∪ E)− fi(E) 1− fi(E) ≥ max e∈W (H) 1 ce · ∑ i∈H pi · fi(e ∪ E)− fi(E) 1− fi(E)\n≥ 1 c(W (H)) ∑ e∈W (H) ∑ i∈H pi · fi(e ∪ E)− fi(E) 1− fi(E) ≥ 1 2k−1 ∑ i∈W (H) pi · ∑ e∈W (H) fi(e ∪ E)− fi(E) 1− fi(E)\n≥ 1 2k−1 ∑ i∈H pi · fi(W (H) ∪ E)− fi(E) 1− fi(E) =\n1\n2k−1 ∑ i∈H pi · fi(Stemk(H))− fi(E) 1− fi(E) (12)\n≥ 1 2k−1 ∑ i∈F pi · 1− fi(E) 1− fi(E) = Pr(F ) 2k−1 ≥ Pr(H) 3 · 2k−1 (13)\nThe inequality in (12) is by submodularity of the fis, and the equality is by definition of W (H). The first inequality in (13) is by definition of F being the covered scenarios in Stemk(H) and the last inequality is by definition of a good node.\nCombining lower bounds for okay (11) and good (13) nodes,\nG ≥ L2k∑\nt>L2k−1 ∑ H∈R(t) H:okay Pr(H) 3 · 2k−1 + L2k∑ t>L2k−1 ∑ H∈R(t) H:good Pr(H) 3 · 2k−1\n= L2k∑ t>L2k−1\n1\n3 · 2k−1 Pr(R(t))− ∑ H∈R(t) H:bad Pr(H)  ≥ L2 k∑ t>L2k−1 ak − 3xk 3 · 2k−1 = L · (ak − 3xk) 3\nThe first equality uses the fact that the nodes corresponding to H ∈ R(t) are exactly one of the types bad/okay/good. The last inequality uses Observation 2 and that R(t) contains all scenarios in Ak.\nLemma 2.4. We have G ≤ ak−1 · (1 + ln 1/ + logm).\nProof. For any scenario i ∈ Ak−1 (i.e. uncovered in ALG by time L2k−1) let πi be the path traced by i in ALG’s decision tree, starting from time 2k−1L and ending at 2kL or when i gets covered. For each element e that appears in πi, let 1 ≤ te,i ≤ ce denote the units of time when e is being displayed during the interval (L2k−1 , L2k]. Note that there can be at most two elements e in πi with ti,e < ce: one that is being displayed at time L2\nk−1 and another at L2k. Recall that every scenario in R(t) appears in Ak−1. So only scenarios in Ak−1 can contribute to\nG and we can rewrite (10) as follows:\nG = ∑\ni∈Ak−1 pi · ∑ e∈πi te,i · 1 ce ( fi(e ∪ E)− fi(E) 1− fi(E) + 1[i ∈ Le(H)] )\n≤ ∑\ni∈Ak−1 pi · (∑ e∈πi fi(e ∪ E)− fi(E) 1− fi(E) + ∑ e∈πi 1[i ∈ Le(H)] )\n(14)\nFix any scenario i ∈ Ak−1. For the first term, we use Claim 2.1 in [3] which relies on the definition of in (1). This implies ∑ e∈πi fi(e∪E)−fi(E) 1−fi(E) ≤ 1 + ln 1 . In order to bound the second term, note that if scenario i ∈ Le(H) when ALG selects element e then number of possible scenarios decreases by at least a factor of two in path πi. So such an event can happen at most log2m times along the path πi. Thus we can write\n∑ e∈πi\n1[i ∈ Le(H)] ≤ logm. The lemma now follows from (14).\nWe now complete the proof of Lemma 2.1. Using Lemma 2.3 and Lemma 2.4 we can write:\nL · (ak − 3xk)/3 ≤ G ≤ ak−1 · (1 + ln 1/ + logm) = ak−1 · L\n15\nRearranging, we obtain ak ≤ 0.2 · ak−1 + 3xk as needed."
    }, {
      "heading" : "3 Extensions",
      "text" : "The ASR problem as defined involves binary feedback from each element. Our algorithm can be easily generalized to handle arbitrary (non-binary) feedback as well. As before, we have elements U with costs {ce}e∈U and m scenarios with probabilities {pi}mi=1 (the realized scenario i∗ = i with probability pi). Each element e ∈ U has an initially unknown state δ(e) ∈ Γ. When an element e is displayed, it provides its state δ(e) as feedback. Each scenario specifies a state for each element in U , i.e. we are given values {di,e : e ∈ U, i ∈ [m]} where di,e is the state of element e under scenario i. In the binary case considered in Section 2, |Γ| = 2 (corresponding to yes/no) and each scenario i specifies a “yes” state for elements e ∈ Si and a “no” state for elements e 6∈ Si. Each scenario i ∈ [m] is also associated with a function fi defined over subsets of U × Γ; we again assume that fi is monotone submodular and takes values in [0, 1]. Note that the ground set of these functions is different from the set U of elements. Scenario i ∈ [m] is said to be covered by a subset S ⊆ U of elements if fi({(e, δ(e))|e ∈ S}) = 1. The goal is to find an adaptive ordering of the elements so as to minimize the expected cost to cover the realized scenario.\nA slight modification of the algorithm in Section 2 also works here. Recall the definition (2) of Le(H) where H ⊆ [m] is the “current” set of scenarios at any point in the algorithm. We extend this definition as follows. For any element e, let Be(H) denote the set with maximum cardinality amongst {i ∈ H : di,e = t} for t ∈ Γ; then Le(H) = H \\ Be(H). The algorithm again selects elements according to the criterion (3). The analysis of the O(log 1/ + logm) approximation ratio of this algorithm remains unchanged from Section 2."
    }, {
      "heading" : "4 Applications",
      "text" : "In this section we discuss various applications of ASR. Some problems have been studied previously and our result matches the best approximation ratio known with the added advantage of being a simpler (and more efficient) algorithm. Some other problems are new and our result provides the first approximation ratio for these.\nDeterministic Submodular Ranking In this problem we are given a set of elements [n] and m monotone submodular functions f1, f2, . . . , fm such that fi : 2\n[n] → R+ and are normalized between 0 and 1. We also have a weight vector w ∈ Rm+ and our goal is to find a linear ordering of elements that minimizes ∑n i=1wici, where ci is the first time that the value of function fi reaches one or higher. We can use our algorithm for this problem with the same fis if we define S1 = S2 = ... = Sm = [n] = U , and pi = wi/( ∑n j=1wj). Theorem 2.2 directly gives an O(logm+ log 1 )-approximation algorithm. Moreover, by observing that in (3) Le = ∅ always, we obtain an O(log 1 )-approximation, which matches the best result known [3].\nAdaptive Multiple Intent Ranking This problem was defined in the introduction. It can be modeled as ASR using the functions:\nfi(S) = min(|S ∩ Si|,Ki)\nKi , for all S ⊆ U and i ∈ [m].\nNote that each fi is bounded between 0 and 1, and is monotone submodular. We also have = 1/maxi∈[m]Ki. So Theorem 2.2 yields an O(log max\ni∈[m] Ki + logm)-approximation algorithm.\nOptimal Decision Tree This problem was also defined in the introduction. It captures many applications in active learning, medical diagnosis, etc. In order to cast this as an instance of ASR, we need some additional definitions. For each test e ∈ U and hypothesis i ∈ [m] we define Te(i) = {j ∈ [m]|e ∈ Si ⊕ Sj} where ⊕ is the symmetric difference operator, and set\nfi(S) = | ∪e∈S Te(i)| · 1\nm− 1 , for all S ⊆ U and i ∈ [m].\nNote that fis are coverage functions, so they are monotone and submodular; also the scaling by 1 m−1 ensures they take values between 0 and 1. By definition of Te(i), we know that ⋃ e∈S Te(i)\nare the hypotheses that differ from i in at least one of the tests S. Hence, having fi(S) = 1 is equivalent to |⋃e∈S Te(i)| = m− 1, i.e. we have identified i as the true hypothesis. Here we have = 1m−1 , so Theorem 2.2 gives an O(logm)-approximation algorithm. This matches the best result known in [18], but their algorithm is more complicated than ours.\nGeneralized Optimal Decision Tree Our algorithm also extends to the setting when we do not have to identify a unique hypothesis. Here we are given a threshold ti for each i ∈ [m] such that it suffices to output a subset of at most ti∗ hypotheses that is guaranteed to contain the true hypothesis i∗. This can be handled easily by changing the definition of fis to:\nfi(S) = min { | ∪e∈S Te(i)| ·\n1\nm− ti , 1\n} , for all S ⊆ U and i ∈ [m].\nNote that this time we will have fi(S) = 1 if the number of hypotheses that do not match i on tests S is at least m − ti; so this corresponds to having at most ti possible hypotheses. And Theorem 2.2 implies an O(logm)-approximation algorithm. To the best of our knowledge this is the first approximation algorithm in this setting; previous results only seem applicable when tis are uniform.\nEquivalence Class Determination We are given an unknown hypothesis in a set of m hypotheses and a partition Q of [m]. Let Q(i) be the subset in the partition that contains i. We are allowed to perform a set of tests, and we know that each partition is uniquely identified based on\nthe results of all tests. Our goal is to minimize the expected cost of tests until we recognize the part containing the true hypothesis. We can model this as an ASR instance with\nfi(S) = | ∪e∈S (Te(i) ∩Q(i)c)|\n|Q(i)c| , for all S ⊆ U and i ∈ [m].\nWhere Ac denotes the complement of set A. The Te(i) are as defined above for optimal decision tree. Note that fis are monotone submodular with values between 0 and 1. Furthermore, fi(S) = 1 means that Q(i)c ⊆ ∪e∈STe(i), which means that the set of compatible hypotheses based on the tests S is a subset of Q(i). Again, Theorem 2.2 implies an O(logm)-approximation algorithm. This is equal to the best previous result [9], but again our algorithm is much simpler.\nDecision Region Determination As before, we are given an unknown hypothesis in a set of m hypotheses and tests U . We also have a set of decisions: each decision j is a “region” Dj ⊆ [m] that corresponds to the hypotheses that it is applicable to. The goal is to find a policy for performing tests with minimum expected cost so as to find any decision region containing the true hypothesis.\nFor each hypothesis i ∈ [m] and decision j such that i ∈ Dj define fi,j(S) = | ⋃ e∈S(Te(i)∩Dj c)|\n|Djc| .\nClearly fi,js are monotone submodular with values between 0 and 1. Also, fi,j(S) = 1 means that Dj c ⊆ ⋃e∈S Te(i), which means that the set of compatible hypotheses based on the tests S is a subset of decision region Dj . However, we may stop when it is determined that the true hypothesis is in any one of the decision regions. This criterion (for hypothesis i) corresponds to at least one fi,j(S) = 1 among {j : i ∈ Dj} reaches one. In [17] it is shown that the “OR of submodular functions” is submodular. Based on that, we express:\nfi(S) = 1− ∏ i∈Dj (1− fi,j(S)), for all S ⊆ U and i ∈ [m].\nSo we obtain an instance of ASR. Note that here the parameter = min i\n∏ j:i∈Dj 1 |Djc| is much\nsmaller due to the OR construction. Still, we have = Ω(m−r) where r is the maximum number of decision regions that contain a hypothesis. So in this case, Theorem 2.2 implies an O(r logm)approximation algorithm where r is the maximum number of decision regions that contain a hypothesis. [22] obtained an O(min{r, d} · ln 1mini pi )-approximation algorithm for this problem, which was improved by [15] to O(min{r, d} · logm); here d is the maximum size of a decision region. Our algorithm runs in time polynomial in m and r, unlike [22, 15] which required time exponential in r. As in [22, 15], we can also obtain an O(d logm)-approximation with running time exponential in d."
    }, {
      "heading" : "5 Experiments",
      "text" : "In this section, we present experimental results for the adaptive multiple intent ranking problem (MIR) and the (generalized) optimal decision tree problem (ODT). We use expected cost (number of elements) as the performance metric to compare different algorithms for the MIR and ODT problems. For example, in the MIR case, if i∗ is satisfied after looking at k elements, we say that costi∗ = k; the performance metric is then ∑ i∈H pi · costi.\nEnvironment: We developed high-quality python modules to evaluate the performance of our algorithms against their well-known counterparts for both ODT and MIR. Our experimental machine has 40 Intel R© Xeon R© E5-2660 cores running at 2.6 Ghz, with 396 GB of RAM running Linux 2.6.32 kernel. We used the Python 2.7.10 interperter to run our experiments. Datasets: The real-world dataset used in our experiments — called ML-100 — is the 100K example from the MovieLens [19] repository, which contains 100,000 ratings on a scale of [1,5] from 943 users\n(scenarios) on 1682 movies (elements) where each user has rated ≥ 20 movies. We binarized this dataset by setting all ratings < 3 to 0, which left us with 82, 520 ratings, where the average user had 87.5 ratings with a standard deviation of 81.2, which suggests a highly-skewed distribution. With this dataset, we use the power-law (Pr[X = x;α] = αxα−1) with α = 1, 2, 3; note that when α = 1, we get a uniform distribution. To get a better understanding of the performance results, we generate multiple permuatations of scenario distributions for the same value of α. For the ODT problem, we also use a synthetic dataset — SYN-K — that is parameterized by k; this is based on a hard instance for the greedy algorithm [23]. Given k, we generate m = 2k + 3 sets, n = k + 2 elements, with 4k + 4 non-zeros as follows: (a) elements i ∈ [1, k] are contained in scenarios 2i− 1 and 2i, (b) element k + 1 is contained in all odd numbered scenarios, and (c) element k + 2 is contained in all even numbered scenarios and scenario 2k + 3. The probabilities for the scenarios are as follows: Pr[2i − 1] = Pr[2i] = 2−i−2 for i ∈ [1, k], Pr[2k + 1] = Pr[2k + 2] = 2−k−2 − , where 0 < < 2−k−2, and Pr[2k + 3] = 2−1 + 2 ."
    }, {
      "heading" : "5.1 Optimal Decision Trees",
      "text" : "Algorithms. The crux of solving the ODT problem is in chosing an element at each step and making updates to the problem state depending on whether e ∈ Si∗ . In our experiments, we compare and contrast the results of 3 algorithms that use different objectives to choose elements: (a) ODT-adsub, which uses the objective described in (3), (b) ODT-greedy, which uses the classic greedy objective [23, 10, 1, 8, 16], and (c) ODT-ml, a “machine learning” algorithm that operates as follows. ODT-ml, which is parameterized by K uses k-Means [2] to a priori partition U into K clusters. Each cluster cj , j ∈ [1,K] is initially given a weight wcj = 1. To choose the next element e ∈ U \\E, a cluster j ∈ [1,K] is first chosen by sampling non-uniformly according to wcj . Next, an element e ∈ cj is chosen uniformly at random. If e ∈ Si∗ , the cj is rewarded by setting wcj = 2wcj , else cj is penalized by setting wcj = 0.5wcj .\nResults. Table 1 depicts the results for ODT-adsub, ODT-greedy, and ODT-ml on SYN-K datasets for K = 50, 100, 150, 200, 250. For this highly-skewed distribution, ODT-adsub outperforms ODTgreedy and ODT-ml (with 10 clusters) by a large margin. It is interesting to note that even the simple ODT-ml algorithm outperforms the well-known ODT-greedy algorithm. Table 2 depicts two sets of results using the ML-100 dataset. The left panel shows the expected cost for the generalized ODT problem with a uniform distribution over scenarios and different thresholds, ti, on the ML-100 dataset. The first threshold (ti = 1) is the standard setting. For the other two settings, tis are drawn uniformly at random from the interval indicated in Table. In the left-panel, when the threshold is larger, the expected cost decreases for all three algorithms. Note that although ODT-greedy, which is the best known practical algorithm for ODT, performs the best, ODT-adsub is extremely competitive. Combined with the fact that ODT-greedy performs poorly on worst-case instances (Table 1), we think ODT-adsub is a good alternative in practice. The right panel shows the performance when ti = 1 and the scenarios are drawn from power-law distributions with α = 2, 3. For each value of α, 3 random permutations are used to test the stability of the expected cost of each\nalgorithm. From this panel, we can conclude that the performance of ODT-adsub is comparable to that of ODT-greedy for ML-100 dataset when the scenarios are distributed as power law, with ODT-ml placing a distant third. In practive, we could — as we have all the data — fit a custom distribution for the scenarios to get the lowest expected cost."
    }, {
      "heading" : "5.2 Adaptive Multiple Intent Ranking",
      "text" : "Algorithms. As for ODT, solving the MIR problem involves carefully choosing an element at each step. In our experiments, we compare and contrast the results of 4 algorithms that use different methods to chose elements: (a) MIR-adsub, which is described in (3), (b) MIR-static, which statically ranks the elements using [4] and choses elements in rank order, (c) MIR-adstatic, which improves on MIR-static by using feedback to eliminate elements from the static list if they belong to invalid scenarios, and (d) MIR-ml, a “machine learning” algorithm that uses the multiplicative scheme described in Section 5.1.\nResults. The results of running MIR-adsub, MIR-static, MIR-adstatic, and MIR-ml on the ML-100 dataset are given in the two tables in Table 3. The table in the left-panel shows the expected cost when the scenarios are drawn from a uniform distribution and the satisfaction thresholds, Kis, are varied, with Ki = |Si| being the classic setting. As expected, when Ki is relaxed, the expected cost decreases for all algorithms. MIR-adsub consistently performs better than all other algorithms in this setting, with MIR-adstatic being a close second. The performance of MIR-static, which is significantly worse than its counterparts demonstrates the importance of adaptive algorithms. The table in right panel shows the performance when Ki = |Si| and the scenarios are drawn from power-law distributions with α = 2, 3. For each α, three random permutations are used to test\nthe stability of the expected cost of each algorithm. The instability of the expected cost across permutations of the user distributions is indicative of the inherent skew in the dataset. Still, MIR-adsub consistently outperforms the other three algorithms.\nAcknowledgement: We thank Lisa Hellerstein for a clarification on [15] regarding the OR construction of submodular functions."
    } ],
    "references" : [ {
      "title" : "Approximating optimal binary decision trees",
      "author" : [ "M. Adler", "B. Heeringa" ],
      "venue" : "Algorithmica, 62(3-4):1112–1121",
      "citeRegEx" : "1",
      "shortCiteRegEx" : null,
      "year" : 2012
    }, {
      "title" : "k-means++: The advantages of careful seeding",
      "author" : [ "D. Arthur", "S. Vassilvitskii" ],
      "venue" : "SODA, pages 1027–1035. Society for Industrial and Applied Mathematics",
      "citeRegEx" : "2",
      "shortCiteRegEx" : null,
      "year" : 2007
    }, {
      "title" : "Ranking with submodular valuations",
      "author" : [ "Y. Azar", "I. Gamzu" ],
      "venue" : "SODA, pages 1070–1079",
      "citeRegEx" : "3",
      "shortCiteRegEx" : null,
      "year" : 2011
    }, {
      "title" : "Multiple intents re-ranking",
      "author" : [ "Y. Azar", "I. Gamzu", "X. Yin" ],
      "venue" : "STOC, pages 669–678",
      "citeRegEx" : "4",
      "shortCiteRegEx" : null,
      "year" : 2009
    }, {
      "title" : "A constant factor approximation algorithm for generalized min-sum set cover",
      "author" : [ "N. Bansal", "A. Gupta", "R. Krishnaswamy" ],
      "venue" : "SODA, pages 1539–1545",
      "citeRegEx" : "5",
      "shortCiteRegEx" : null,
      "year" : 2010
    }, {
      "title" : "When LP is the cure for your matching woes: Improved bounds for stochastic matchings",
      "author" : [ "N. Bansal", "A. Gupta", "J. Li", "J. Mestre", "V. Nagarajan", "A. Rudra" ],
      "venue" : "Algorithmica, 63(4):733–762",
      "citeRegEx" : "6",
      "shortCiteRegEx" : null,
      "year" : 2012
    }, {
      "title" : "Group-based active query selection for rapid diagnosis in time-critical situations",
      "author" : [ "G. Bellala", "S.K. Bhavnani", "C. Scott" ],
      "venue" : "IEEE Trans. Information Theory, 58(1):459–478",
      "citeRegEx" : "7",
      "shortCiteRegEx" : null,
      "year" : 2012
    }, {
      "title" : "Decision trees for entity identification: Approximation algorithms and hardness results",
      "author" : [ "V.T. Chakaravarthy", "V. Pandit", "S. Roy", "P. Awasthi", "M.K. Mohania" ],
      "venue" : "ACM Transactions on Algorithms, 7(2):15",
      "citeRegEx" : "8",
      "shortCiteRegEx" : null,
      "year" : 2011
    }, {
      "title" : "Diagnosis determination: decision trees optimizing simultaneously worst and expected testing cost",
      "author" : [ "F. Cicalese", "E.S. Laber", "A.M. Saettler" ],
      "venue" : "ICML, pages 414–422",
      "citeRegEx" : "9",
      "shortCiteRegEx" : null,
      "year" : 2014
    }, {
      "title" : "Analysis of a greedy active learning strategy",
      "author" : [ "S. Dasgupta" ],
      "venue" : "NIPS",
      "citeRegEx" : "10",
      "shortCiteRegEx" : null,
      "year" : 2004
    }, {
      "title" : "Approximating the stochastic knapsack problem: The benefit of adaptivity",
      "author" : [ "B.C. Dean", "M.X. Goemans", "J. Vondrák" ],
      "venue" : "Math. Oper. Res., 33(4):945–964",
      "citeRegEx" : "11",
      "shortCiteRegEx" : null,
      "year" : 2008
    }, {
      "title" : "A threshold of ln n for approximating set cover",
      "author" : [ "U. Feige" ],
      "venue" : "Journal of the ACM, 45(4):634–652",
      "citeRegEx" : "12",
      "shortCiteRegEx" : null,
      "year" : 1998
    }, {
      "title" : "Adaptive submodularity: Theory and applications in active learning and stochastic optimization",
      "author" : [ "D. Golovin", "A. Krause" ],
      "venue" : "J. Artif. Intell. Res. (JAIR), 42:427–486",
      "citeRegEx" : "13",
      "shortCiteRegEx" : null,
      "year" : 2011
    }, {
      "title" : "Near-optimal bayesian active learning with noisy observations",
      "author" : [ "D. Golovin", "A. Krause", "D. Ray" ],
      "venue" : "NIPS, pages 766–774",
      "citeRegEx" : "14",
      "shortCiteRegEx" : null,
      "year" : 2010
    }, {
      "title" : "Scenario submodular cover",
      "author" : [ "N. Grammel", "L. Hellerstein", "D. Kletenik", "P. Lin" ],
      "venue" : "CoRR, abs/1603.03158",
      "citeRegEx" : "15",
      "shortCiteRegEx" : null,
      "year" : 2016
    }, {
      "title" : "Average-Case Active Learning with Costs",
      "author" : [ "A. Guillory", "J. Bilmes" ],
      "venue" : "Algorithmic Learning Theory, pages 141–155. Springer Berlin / Heidelberg",
      "citeRegEx" : "16",
      "shortCiteRegEx" : null,
      "year" : 2009
    }, {
      "title" : "Simultaneous learning and covering with adversarial noise",
      "author" : [ "A. Guillory", "J. Bilmes" ],
      "venue" : "Proceedings of the 28th International Conference on Machine Learning (ICML-11), pages 369–376",
      "citeRegEx" : "17",
      "shortCiteRegEx" : null,
      "year" : 2011
    }, {
      "title" : "Approximation algorithms for optimal decision trees and adaptive tsp problems",
      "author" : [ "A. Gupta", "V. Nagarajan", "R. Ravi" ],
      "venue" : "ICALP (1), pages 690–701",
      "citeRegEx" : "18",
      "shortCiteRegEx" : null,
      "year" : 2010
    }, {
      "title" : "The movielens datasets: History and context",
      "author" : [ "F.M. Harper", "J.A. Konstan" ],
      "venue" : "ACM Transactions on Interactive Intelligent Systems (TiiS), 5(4):19",
      "citeRegEx" : "19",
      "shortCiteRegEx" : null,
      "year" : 2015
    }, {
      "title" : "Constructing optimal binary decision trees is NP -complete",
      "author" : [ "L. Hyafil", "R.L. Rivest" ],
      "venue" : "Information Processing Lett.,",
      "citeRegEx" : "20",
      "shortCiteRegEx" : "20",
      "year" : 1976
    }, {
      "title" : "and R",
      "author" : [ "S. Im", "V. Nagarajan" ],
      "venue" : "van der Zwaan. Minimum latency submodular cover. ICALP, pages 485–497",
      "citeRegEx" : "21",
      "shortCiteRegEx" : null,
      "year" : 2012
    }, {
      "title" : "Near optimal bayesian active learning for decision making",
      "author" : [ "Sh. Javdani", "Y. Chen", "A. Karbasi", "A. Krause", "D. Bagnell", "S.S. Srinivasa" ],
      "venue" : "In AISTATS,",
      "citeRegEx" : "22",
      "shortCiteRegEx" : "22",
      "year" : 2014
    }, {
      "title" : "On an Optimal Split Tree Problem",
      "author" : [ "S.R. Kosaraju", "T.M. Przytycka", "R.S. Borgstrom" ],
      "venue" : "Proceedings of the 6th International Workshop on Algorithms and Data Structures, pages 157–168",
      "citeRegEx" : "23",
      "shortCiteRegEx" : null,
      "year" : 1999
    }, {
      "title" : "Combinatorial optimization: polyhedra and efficiency",
      "author" : [ "A. Schrijver" ],
      "venue" : "Springer-Verlag, Berlin",
      "citeRegEx" : "24",
      "shortCiteRegEx" : null,
      "year" : 2003
    }, {
      "title" : "A note on the generalized min-sum set cover problem",
      "author" : [ "M. Skutella", "D.P. Williamson" ],
      "venue" : "Oper. Res. Lett., 39(6):433–436",
      "citeRegEx" : "25",
      "shortCiteRegEx" : null,
      "year" : 2011
    }, {
      "title" : "An analysis of the greedy algorithm for the submodular set covering problem",
      "author" : [ "L.A. Wolsey" ],
      "venue" : "Combinatorica, 2(4):385–393",
      "citeRegEx" : "26",
      "shortCiteRegEx" : null,
      "year" : 1982
    } ],
    "referenceMentions" : [ {
      "referenceID" : 23,
      "context" : "Submodular functions are a very general class of set-functions that have certain convexity as well as concavity properties [24].",
      "startOffset" : 123,
      "endOffset" : 127
    }, {
      "referenceID" : 19,
      "context" : "In this paper, we study an adaptive optimization problem in the setting described above which simultaneously generalizes many previously-studied problems such as optimal decision trees [20, 23, 10, 8, 18, 9], equivalence class determination [14, 7], decision region determination [22] and submodular ranking [3, 21].",
      "startOffset" : 185,
      "endOffset" : 207
    }, {
      "referenceID" : 22,
      "context" : "In this paper, we study an adaptive optimization problem in the setting described above which simultaneously generalizes many previously-studied problems such as optimal decision trees [20, 23, 10, 8, 18, 9], equivalence class determination [14, 7], decision region determination [22] and submodular ranking [3, 21].",
      "startOffset" : 185,
      "endOffset" : 207
    }, {
      "referenceID" : 9,
      "context" : "In this paper, we study an adaptive optimization problem in the setting described above which simultaneously generalizes many previously-studied problems such as optimal decision trees [20, 23, 10, 8, 18, 9], equivalence class determination [14, 7], decision region determination [22] and submodular ranking [3, 21].",
      "startOffset" : 185,
      "endOffset" : 207
    }, {
      "referenceID" : 7,
      "context" : "In this paper, we study an adaptive optimization problem in the setting described above which simultaneously generalizes many previously-studied problems such as optimal decision trees [20, 23, 10, 8, 18, 9], equivalence class determination [14, 7], decision region determination [22] and submodular ranking [3, 21].",
      "startOffset" : 185,
      "endOffset" : 207
    }, {
      "referenceID" : 17,
      "context" : "In this paper, we study an adaptive optimization problem in the setting described above which simultaneously generalizes many previously-studied problems such as optimal decision trees [20, 23, 10, 8, 18, 9], equivalence class determination [14, 7], decision region determination [22] and submodular ranking [3, 21].",
      "startOffset" : 185,
      "endOffset" : 207
    }, {
      "referenceID" : 8,
      "context" : "In this paper, we study an adaptive optimization problem in the setting described above which simultaneously generalizes many previously-studied problems such as optimal decision trees [20, 23, 10, 8, 18, 9], equivalence class determination [14, 7], decision region determination [22] and submodular ranking [3, 21].",
      "startOffset" : 185,
      "endOffset" : 207
    }, {
      "referenceID" : 13,
      "context" : "In this paper, we study an adaptive optimization problem in the setting described above which simultaneously generalizes many previously-studied problems such as optimal decision trees [20, 23, 10, 8, 18, 9], equivalence class determination [14, 7], decision region determination [22] and submodular ranking [3, 21].",
      "startOffset" : 241,
      "endOffset" : 248
    }, {
      "referenceID" : 6,
      "context" : "In this paper, we study an adaptive optimization problem in the setting described above which simultaneously generalizes many previously-studied problems such as optimal decision trees [20, 23, 10, 8, 18, 9], equivalence class determination [14, 7], decision region determination [22] and submodular ranking [3, 21].",
      "startOffset" : 241,
      "endOffset" : 248
    }, {
      "referenceID" : 21,
      "context" : "In this paper, we study an adaptive optimization problem in the setting described above which simultaneously generalizes many previously-studied problems such as optimal decision trees [20, 23, 10, 8, 18, 9], equivalence class determination [14, 7], decision region determination [22] and submodular ranking [3, 21].",
      "startOffset" : 280,
      "endOffset" : 284
    }, {
      "referenceID" : 2,
      "context" : "In this paper, we study an adaptive optimization problem in the setting described above which simultaneously generalizes many previously-studied problems such as optimal decision trees [20, 23, 10, 8, 18, 9], equivalence class determination [14, 7], decision region determination [22] and submodular ranking [3, 21].",
      "startOffset" : 308,
      "endOffset" : 315
    }, {
      "referenceID" : 20,
      "context" : "In this paper, we study an adaptive optimization problem in the setting described above which simultaneously generalizes many previously-studied problems such as optimal decision trees [20, 23, 10, 8, 18, 9], equivalence class determination [14, 7], decision region determination [22] and submodular ranking [3, 21].",
      "startOffset" : 308,
      "endOffset" : 315
    }, {
      "referenceID" : 3,
      "context" : "This is an adaptive version of the search ranking problem studied in [4, 5, 25].",
      "startOffset" : 69,
      "endOffset" : 79
    }, {
      "referenceID" : 4,
      "context" : "This is an adaptive version of the search ranking problem studied in [4, 5, 25].",
      "startOffset" : 69,
      "endOffset" : 79
    }, {
      "referenceID" : 24,
      "context" : "This is an adaptive version of the search ranking problem studied in [4, 5, 25].",
      "startOffset" : 69,
      "endOffset" : 79
    }, {
      "referenceID" : 10,
      "context" : "[11, 6].",
      "startOffset" : 0,
      "endOffset" : 7
    }, {
      "referenceID" : 5,
      "context" : "[11, 6].",
      "startOffset" : 0,
      "endOffset" : 7
    }, {
      "referenceID" : 23,
      "context" : "See [24] for background.",
      "startOffset" : 4,
      "endOffset" : 8
    }, {
      "referenceID" : 0,
      "context" : "Each scenario i ∈ [m] := {1, · · · ,m} is specified by an interest-set Si ⊆ U and a normalized monotone submodular function fi : 2Si → [0, 1] where fi(∅) = 0 and fi(Si) = 1 (every monotone submodular function on Si can be expressed in this form by scaling and truncation).",
      "startOffset" : 135,
      "endOffset" : 141
    }, {
      "referenceID" : 0,
      "context" : "For notational simplicity, we extend each function fi : 2 Si → [0, 1] to arbitrary subsets S ⊆ U by setting fi(S) = fi(S ∩ Si).",
      "startOffset" : 63,
      "endOffset" : 69
    }, {
      "referenceID" : 25,
      "context" : "[26, 3, 21, 15].",
      "startOffset" : 0,
      "endOffset" : 15
    }, {
      "referenceID" : 2,
      "context" : "[26, 3, 21, 15].",
      "startOffset" : 0,
      "endOffset" : 15
    }, {
      "referenceID" : 20,
      "context" : "[26, 3, 21, 15].",
      "startOffset" : 0,
      "endOffset" : 15
    }, {
      "referenceID" : 14,
      "context" : "[26, 3, 21, 15].",
      "startOffset" : 0,
      "endOffset" : 15
    }, {
      "referenceID" : 11,
      "context" : "Assuming P 6= NP , this result is the best possible (up to constant factors) as the set cover problem [12] is a special case of ASR even when m = 1.",
      "startOffset" : 102,
      "endOffset" : 106
    }, {
      "referenceID" : 19,
      "context" : "Such a simple algorithm was previously unknown even in the special case of optimal decision tree (under arbitrary costs/probabilities), despite a large number of papers [20, 23, 10, 1, 8, 16, 18, 13, 9] on this topic.",
      "startOffset" : 169,
      "endOffset" : 202
    }, {
      "referenceID" : 22,
      "context" : "Such a simple algorithm was previously unknown even in the special case of optimal decision tree (under arbitrary costs/probabilities), despite a large number of papers [20, 23, 10, 1, 8, 16, 18, 13, 9] on this topic.",
      "startOffset" : 169,
      "endOffset" : 202
    }, {
      "referenceID" : 9,
      "context" : "Such a simple algorithm was previously unknown even in the special case of optimal decision tree (under arbitrary costs/probabilities), despite a large number of papers [20, 23, 10, 1, 8, 16, 18, 13, 9] on this topic.",
      "startOffset" : 169,
      "endOffset" : 202
    }, {
      "referenceID" : 0,
      "context" : "Such a simple algorithm was previously unknown even in the special case of optimal decision tree (under arbitrary costs/probabilities), despite a large number of papers [20, 23, 10, 1, 8, 16, 18, 13, 9] on this topic.",
      "startOffset" : 169,
      "endOffset" : 202
    }, {
      "referenceID" : 7,
      "context" : "Such a simple algorithm was previously unknown even in the special case of optimal decision tree (under arbitrary costs/probabilities), despite a large number of papers [20, 23, 10, 1, 8, 16, 18, 13, 9] on this topic.",
      "startOffset" : 169,
      "endOffset" : 202
    }, {
      "referenceID" : 15,
      "context" : "Such a simple algorithm was previously unknown even in the special case of optimal decision tree (under arbitrary costs/probabilities), despite a large number of papers [20, 23, 10, 1, 8, 16, 18, 13, 9] on this topic.",
      "startOffset" : 169,
      "endOffset" : 202
    }, {
      "referenceID" : 17,
      "context" : "Such a simple algorithm was previously unknown even in the special case of optimal decision tree (under arbitrary costs/probabilities), despite a large number of papers [20, 23, 10, 1, 8, 16, 18, 13, 9] on this topic.",
      "startOffset" : 169,
      "endOffset" : 202
    }, {
      "referenceID" : 12,
      "context" : "Such a simple algorithm was previously unknown even in the special case of optimal decision tree (under arbitrary costs/probabilities), despite a large number of papers [20, 23, 10, 1, 8, 16, 18, 13, 9] on this topic.",
      "startOffset" : 169,
      "endOffset" : 202
    }, {
      "referenceID" : 8,
      "context" : "Such a simple algorithm was previously unknown even in the special case of optimal decision tree (under arbitrary costs/probabilities), despite a large number of papers [20, 23, 10, 1, 8, 16, 18, 13, 9] on this topic.",
      "startOffset" : 169,
      "endOffset" : 202
    }, {
      "referenceID" : 17,
      "context" : "The first O(logm)-approximation algorithm for ODT was obtained in [18], and this result was extended to the equivalence class determination problem in [9].",
      "startOffset" : 66,
      "endOffset" : 70
    }, {
      "referenceID" : 8,
      "context" : "The first O(logm)-approximation algorithm for ODT was obtained in [18], and this result was extended to the equivalence class determination problem in [9].",
      "startOffset" : 151,
      "endOffset" : 154
    }, {
      "referenceID" : 22,
      "context" : "[23, 10, 1, 8, 16], based on a simple greedy “splitting” algorithm, had a logarithmic dependence on either costs or probabilities which (in the worst case) can be exponential in m.",
      "startOffset" : 0,
      "endOffset" : 18
    }, {
      "referenceID" : 9,
      "context" : "[23, 10, 1, 8, 16], based on a simple greedy “splitting” algorithm, had a logarithmic dependence on either costs or probabilities which (in the worst case) can be exponential in m.",
      "startOffset" : 0,
      "endOffset" : 18
    }, {
      "referenceID" : 0,
      "context" : "[23, 10, 1, 8, 16], based on a simple greedy “splitting” algorithm, had a logarithmic dependence on either costs or probabilities which (in the worst case) can be exponential in m.",
      "startOffset" : 0,
      "endOffset" : 18
    }, {
      "referenceID" : 7,
      "context" : "[23, 10, 1, 8, 16], based on a simple greedy “splitting” algorithm, had a logarithmic dependence on either costs or probabilities which (in the worst case) can be exponential in m.",
      "startOffset" : 0,
      "endOffset" : 18
    }, {
      "referenceID" : 15,
      "context" : "[23, 10, 1, 8, 16], based on a simple greedy “splitting” algorithm, had a logarithmic dependence on either costs or probabilities which (in the worst case) can be exponential in m.",
      "startOffset" : 0,
      "endOffset" : 18
    }, {
      "referenceID" : 25,
      "context" : "One line of work is on the submodular cover problem and its variants [26, 4, 3, 21].",
      "startOffset" : 69,
      "endOffset" : 83
    }, {
      "referenceID" : 3,
      "context" : "One line of work is on the submodular cover problem and its variants [26, 4, 3, 21].",
      "startOffset" : 69,
      "endOffset" : 83
    }, {
      "referenceID" : 2,
      "context" : "One line of work is on the submodular cover problem and its variants [26, 4, 3, 21].",
      "startOffset" : 69,
      "endOffset" : 83
    }, {
      "referenceID" : 20,
      "context" : "One line of work is on the submodular cover problem and its variants [26, 4, 3, 21].",
      "startOffset" : 69,
      "endOffset" : 83
    }, {
      "referenceID" : 22,
      "context" : "[23, 10, 18, 13, 9].",
      "startOffset" : 0,
      "endOffset" : 19
    }, {
      "referenceID" : 9,
      "context" : "[23, 10, 18, 13, 9].",
      "startOffset" : 0,
      "endOffset" : 19
    }, {
      "referenceID" : 17,
      "context" : "[23, 10, 18, 13, 9].",
      "startOffset" : 0,
      "endOffset" : 19
    }, {
      "referenceID" : 12,
      "context" : "[23, 10, 18, 13, 9].",
      "startOffset" : 0,
      "endOffset" : 19
    }, {
      "referenceID" : 8,
      "context" : "[23, 10, 18, 13, 9].",
      "startOffset" : 0,
      "endOffset" : 19
    }, {
      "referenceID" : 20,
      "context" : "In particular, we combine the time-based analysis for the deterministic submodular ranking problem in [21] with the phase-based analysis for optimal decision tree in [23, 18, 9].",
      "startOffset" : 102,
      "endOffset" : 106
    }, {
      "referenceID" : 22,
      "context" : "In particular, we combine the time-based analysis for the deterministic submodular ranking problem in [21] with the phase-based analysis for optimal decision tree in [23, 18, 9].",
      "startOffset" : 166,
      "endOffset" : 177
    }, {
      "referenceID" : 17,
      "context" : "In particular, we combine the time-based analysis for the deterministic submodular ranking problem in [21] with the phase-based analysis for optimal decision tree in [23, 18, 9].",
      "startOffset" : 166,
      "endOffset" : 177
    }, {
      "referenceID" : 8,
      "context" : "In particular, we combine the time-based analysis for the deterministic submodular ranking problem in [21] with the phase-based analysis for optimal decision tree in [23, 18, 9].",
      "startOffset" : 166,
      "endOffset" : 177
    }, {
      "referenceID" : 20,
      "context" : "We note that [21] also considers a stochastic variant of submodular ranking, but it is different from ASR because [21] assumes an independent distribution whereas we assume a correlated scenariobased distribution.",
      "startOffset" : 13,
      "endOffset" : 17
    }, {
      "referenceID" : 20,
      "context" : "We note that [21] also considers a stochastic variant of submodular ranking, but it is different from ASR because [21] assumes an independent distribution whereas we assume a correlated scenariobased distribution.",
      "startOffset" : 114,
      "endOffset" : 118
    }, {
      "referenceID" : 20,
      "context" : "In particular, unlike ASR, the stochastic submodular ranking problem in [21] does not capture the optimal decision tree problem and its variants.",
      "startOffset" : 72,
      "endOffset" : 76
    }, {
      "referenceID" : 14,
      "context" : "Recently, [15] also considered a scenario-based submodular cover problem.",
      "startOffset" : 10,
      "endOffset" : 14
    }, {
      "referenceID" : 14,
      "context" : "In this respect our setting is a generalization of [15], eg.",
      "startOffset" : 51,
      "endOffset" : 55
    }, {
      "referenceID" : 2,
      "context" : "ASR captures the submodular ranking problem [3] whereas [15] does not.",
      "startOffset" : 44,
      "endOffset" : 47
    }, {
      "referenceID" : 14,
      "context" : "ASR captures the submodular ranking problem [3] whereas [15] does not.",
      "startOffset" : 56,
      "endOffset" : 60
    }, {
      "referenceID" : 14,
      "context" : "On the other hand, [15] allows arbitrary feedback whereas ASR as defined only considers binary (yes/no) feedback.",
      "startOffset" : 19,
      "endOffset" : 23
    }, {
      "referenceID" : 12,
      "context" : "The notion of “adaptive submodularity” [13] has been very useful in obtaining algorithms for some previously-studied special cases [14, 7, 22] of ASR.",
      "startOffset" : 39,
      "endOffset" : 43
    }, {
      "referenceID" : 13,
      "context" : "The notion of “adaptive submodularity” [13] has been very useful in obtaining algorithms for some previously-studied special cases [14, 7, 22] of ASR.",
      "startOffset" : 131,
      "endOffset" : 142
    }, {
      "referenceID" : 6,
      "context" : "The notion of “adaptive submodularity” [13] has been very useful in obtaining algorithms for some previously-studied special cases [14, 7, 22] of ASR.",
      "startOffset" : 131,
      "endOffset" : 142
    }, {
      "referenceID" : 21,
      "context" : "The notion of “adaptive submodularity” [13] has been very useful in obtaining algorithms for some previously-studied special cases [14, 7, 22] of ASR.",
      "startOffset" : 131,
      "endOffset" : 142
    }, {
      "referenceID" : 12,
      "context" : "In particular, among other results [13] obtained an O(log 1/ + log 1/pmin)-approximation algorithm for ASR when fi = f for all scenarios i, the function f is adaptive-submodular (a stronger condition than submodular) and pmin = min m i=1 pi is the minimum probability.",
      "startOffset" : 35,
      "endOffset" : 39
    }, {
      "referenceID" : 14,
      "context" : "We note that [15] is also an improvement over [13] in points (ii) and (iii) above.",
      "startOffset" : 13,
      "endOffset" : 17
    }, {
      "referenceID" : 12,
      "context" : "We note that [15] is also an improvement over [13] in points (ii) and (iii) above.",
      "startOffset" : 46,
      "endOffset" : 50
    }, {
      "referenceID" : 0,
      "context" : "Recall that an instance of ASR consists of a ground set U of elements with costs {ce}e∈U , and m scenarios with an interest-set Si ⊆ U , submodular function fi : 2Si → [0, 1] and probability pi associated with each scenario i ∈ [m].",
      "startOffset" : 168,
      "endOffset" : 174
    }, {
      "referenceID" : 2,
      "context" : "1 in [3] which relies on the definition of in (1).",
      "startOffset" : 5,
      "endOffset" : 8
    }, {
      "referenceID" : 0,
      "context" : "Each scenario i ∈ [m] is also associated with a function fi defined over subsets of U × Γ; we again assume that fi is monotone submodular and takes values in [0, 1].",
      "startOffset" : 158,
      "endOffset" : 164
    }, {
      "referenceID" : 2,
      "context" : "Moreover, by observing that in (3) Le = ∅ always, we obtain an O(log 1 )-approximation, which matches the best result known [3].",
      "startOffset" : 124,
      "endOffset" : 127
    }, {
      "referenceID" : 17,
      "context" : "This matches the best result known in [18], but their algorithm is more complicated than ours.",
      "startOffset" : 38,
      "endOffset" : 42
    }, {
      "referenceID" : 8,
      "context" : "This is equal to the best previous result [9], but again our algorithm is much simpler.",
      "startOffset" : 42,
      "endOffset" : 45
    }, {
      "referenceID" : 16,
      "context" : "In [17] it is shown that the “OR of submodular functions” is submodular.",
      "startOffset" : 3,
      "endOffset" : 7
    }, {
      "referenceID" : 21,
      "context" : "[22] obtained an O(min{r, d} · ln 1 mini pi )-approximation algorithm for this problem, which was improved by [15] to O(min{r, d} · logm); here d is the maximum size of a decision region.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 14,
      "context" : "[22] obtained an O(min{r, d} · ln 1 mini pi )-approximation algorithm for this problem, which was improved by [15] to O(min{r, d} · logm); here d is the maximum size of a decision region.",
      "startOffset" : 110,
      "endOffset" : 114
    }, {
      "referenceID" : 21,
      "context" : "Our algorithm runs in time polynomial in m and r, unlike [22, 15] which required time exponential in r.",
      "startOffset" : 57,
      "endOffset" : 65
    }, {
      "referenceID" : 14,
      "context" : "Our algorithm runs in time polynomial in m and r, unlike [22, 15] which required time exponential in r.",
      "startOffset" : 57,
      "endOffset" : 65
    }, {
      "referenceID" : 21,
      "context" : "As in [22, 15], we can also obtain an O(d logm)-approximation with running time exponential in d.",
      "startOffset" : 6,
      "endOffset" : 14
    }, {
      "referenceID" : 14,
      "context" : "As in [22, 15], we can also obtain an O(d logm)-approximation with running time exponential in d.",
      "startOffset" : 6,
      "endOffset" : 14
    }, {
      "referenceID" : 18,
      "context" : "Datasets: The real-world dataset used in our experiments — called ML-100 — is the 100K example from the MovieLens [19] repository, which contains 100,000 ratings on a scale of [1,5] from 943 users",
      "startOffset" : 114,
      "endOffset" : 118
    }, {
      "referenceID" : 0,
      "context" : "Datasets: The real-world dataset used in our experiments — called ML-100 — is the 100K example from the MovieLens [19] repository, which contains 100,000 ratings on a scale of [1,5] from 943 users",
      "startOffset" : 176,
      "endOffset" : 181
    }, {
      "referenceID" : 4,
      "context" : "Datasets: The real-world dataset used in our experiments — called ML-100 — is the 100K example from the MovieLens [19] repository, which contains 100,000 ratings on a scale of [1,5] from 943 users",
      "startOffset" : 176,
      "endOffset" : 181
    }, {
      "referenceID" : 22,
      "context" : "For the ODT problem, we also use a synthetic dataset — SYN-K — that is parameterized by k; this is based on a hard instance for the greedy algorithm [23].",
      "startOffset" : 149,
      "endOffset" : 153
    }, {
      "referenceID" : 22,
      "context" : "In our experiments, we compare and contrast the results of 3 algorithms that use different objectives to choose elements: (a) ODT-adsub, which uses the objective described in (3), (b) ODT-greedy, which uses the classic greedy objective [23, 10, 1, 8, 16], and (c) ODT-ml, a “machine learning” algorithm that operates as follows.",
      "startOffset" : 236,
      "endOffset" : 254
    }, {
      "referenceID" : 9,
      "context" : "In our experiments, we compare and contrast the results of 3 algorithms that use different objectives to choose elements: (a) ODT-adsub, which uses the objective described in (3), (b) ODT-greedy, which uses the classic greedy objective [23, 10, 1, 8, 16], and (c) ODT-ml, a “machine learning” algorithm that operates as follows.",
      "startOffset" : 236,
      "endOffset" : 254
    }, {
      "referenceID" : 0,
      "context" : "In our experiments, we compare and contrast the results of 3 algorithms that use different objectives to choose elements: (a) ODT-adsub, which uses the objective described in (3), (b) ODT-greedy, which uses the classic greedy objective [23, 10, 1, 8, 16], and (c) ODT-ml, a “machine learning” algorithm that operates as follows.",
      "startOffset" : 236,
      "endOffset" : 254
    }, {
      "referenceID" : 7,
      "context" : "In our experiments, we compare and contrast the results of 3 algorithms that use different objectives to choose elements: (a) ODT-adsub, which uses the objective described in (3), (b) ODT-greedy, which uses the classic greedy objective [23, 10, 1, 8, 16], and (c) ODT-ml, a “machine learning” algorithm that operates as follows.",
      "startOffset" : 236,
      "endOffset" : 254
    }, {
      "referenceID" : 15,
      "context" : "In our experiments, we compare and contrast the results of 3 algorithms that use different objectives to choose elements: (a) ODT-adsub, which uses the objective described in (3), (b) ODT-greedy, which uses the classic greedy objective [23, 10, 1, 8, 16], and (c) ODT-ml, a “machine learning” algorithm that operates as follows.",
      "startOffset" : 236,
      "endOffset" : 254
    }, {
      "referenceID" : 1,
      "context" : "ODT-ml, which is parameterized by K uses k-Means [2] to a priori partition U into K clusters.",
      "startOffset" : 49,
      "endOffset" : 52
    }, {
      "referenceID" : 3,
      "context" : "In our experiments, we compare and contrast the results of 4 algorithms that use different methods to chose elements: (a) MIR-adsub, which is described in (3), (b) MIR-static, which statically ranks the elements using [4] and choses elements in rank order, (c) MIR-adstatic, which improves on MIR-static by using feedback to eliminate elements from the static list if they belong to invalid scenarios, and (d) MIR-ml, a “machine learning” algorithm that uses the multiplicative scheme described in Section 5.",
      "startOffset" : 218,
      "endOffset" : 221
    }, {
      "referenceID" : 14,
      "context" : "Acknowledgement: We thank Lisa Hellerstein for a clarification on [15] regarding the OR construction of submodular functions.",
      "startOffset" : 66,
      "endOffset" : 70
    } ],
    "year" : 2016,
    "abstractText" : "We study a general adaptive ranking problem where an algorithm needs to perform a sequence of actions on a random user, drawn from a known distribution, so as to “satisfy” the user as early as possible. The satisfaction of each user is captured by an individual submodular function, where the user is said to be satisfied when the function value goes above some threshold. We obtain a logarithmic factor approximation algorithm for this adaptive ranking problem, which is the best possible. The adaptive ranking problem has many applications in active learning and ranking: it significantly generalizes previously-studied problems such as optimal decision trees, equivalence class determination, decision region determination and submodular cover. We also present some preliminary experimental results based on our algorithm.",
    "creator" : "LaTeX with hyperref package"
  }
}