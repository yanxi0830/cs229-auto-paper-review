{
  "name" : "1302.6009.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "On learning parametric-output HMMs",
    "authors" : [ "Aryeh Kontorovich" ],
    "emails" : [ ],
    "sections" : [ {
      "heading" : null,
      "text" : "ar X\niv :1\n30 2.\n60 09"
    }, {
      "heading" : "1 Introduction",
      "text" : "Hidden Markov Models (HMM) are a standard tool in the modeling and analysis of time series with a wide variety of applications. When the number of hidden states is known, the standard method for estimating the HMM parameters from given observed data is the Baum-Welch algorithm [Baum et al., 1970]. The latter is known to suffer from two serious drawbacks: it\ntends to converge (i) very slowly and (ii) only to a local maximum. Indeed, the problem of recovering the parameters of a general HMM is provably hard, in several distinct senses [Abe and Warmuth, 1992, Lyngsø and Pedersen, 2001, Terwijn, 2002].\nIn this paper we consider learning parametric-output HMMs with a finite and known number of hidden states, where the output from each hidden state follows a parametric distribution from a given family. A notable example is a Gaussian HMM, where from each state x, the output is a (possibly multivariate) Gaussian, N (µx,Σx), typically with unknown µx,Σx.\nMain results. We propose a novel approach to learning parametric output HMMs, based on the following two insights: (i) in an ergodic HMM, the stationary distribution is a mixture of distributions from the parametric family, and (ii) given the output parameters, or their approximate values, one can efficiently recover the corresponding transition probabilities up to small additive error.\nCombining these two insights leads to our decoupling approach to learning parametric HMMs. Rather than attempting, as in the Baum-Welch algorithm, to jointly estimate both the transition probabilities and the output density parameters, we instead learn each of them separately. First, given one or several long observed sequences, the HMM output parameters are estimated by a general purpose parametric mixture learner, such as the Expectation-Maximization (EM) algorithm. Next, once these parameters are approximately known, we learn the hidden state transition probabilities by solving a computationally efficient convex quadratic program (QP).\nThe key idea behind our approach is to treat the underlying hidden process as if it were sampled independently from the Markov chain’s stationary distribution, and operate only on the empirical distribution of singletons and consecutive pairs. Thus we avoid computing the exact likelihood, which depends on the full sequence, and obtain considerable gains in computational efficiency. Under mild assumptions on the Markov chain and on its output probabilities, we prove in Theorem 1 that given the exact output probabilities, our estimator for the hidden state transition matrix is asymptotically consistent. Additionally, this estimator is robust to small perturbations in the output probabilities (Theorems 2-6).\nBeyond its practical prospects, our proposed approach also sheds light on the theoretical difficulty of the full HMM learning problem: It shows that for parametric-output HMMs the key difficulty is fitting a mixture model, since once its parameters have been accurately estimated, learning the transition\nmatrix can be cast as a convex program. While learning a general mixture is considered a hard problem, we note that recently much progress has been made under various separation conditions on the mixture components, see e.g. Moitra and Valiant [2010], Belkin and Sinha [2010] and references therein.\nRelated work. The problem of estimating HMM parameters from observations has been actively studied since the 1970’s, see Cappé et al. [2005], Rabiner [1990], Roweis and Ghahramani [1999]. While computing the maximumlikelihood estimator for an HMM is in general computationally intractable, under mild conditions, such an estimator is asymptotically consistent and normally distributed, see Bickel et al. [1998], Chang [1996], Douc and Matias [2001].\nIn recent years, there has been a renewed interest in learning HMMs, in particular under various assumptions that render the learning problem tractable [Faragó and Lugosi, 1989, Hsu et al., 2009, Mossel and Roch, 2006, Siddiqi et al., 2010, Anandkumar et al., 2012]. Also, Cybenko and Crespi [2011], Lakshminarayanan and Raich [2010] recently suggested Non-negative Matrix Factorization (NNMF) approaches for learning HMMs. These methods are related to our approach, since with known output probabilities, NNMF reduces to a convex program similar to the one considered here. Hence, our stability and consistency analysis may be relevant to NNMFbased approaches as well.\nPaper outline. In Section 2 we present our problem setup. The algorithm for learning the HMM appears in Section 3, and its statistical analysis in Section 4. Section 5 contains some simulation results. The technical details are deferred to the Appendices."
    }, {
      "heading" : "2 Problem Setup",
      "text" : "Notation. When X ∈ X and Y ∈ Y take values in a discrete set we abbreviate P (x) for Pr(X = x) and P (y |x) for Pr(Y = y |X = x). When Y ∈ Y is continuous-valued, we denote by P (y |x) the probability density function of Y given X.\nFor x,w ∈ Rn, diag(x) denotes the n×n diagonal matrix with entries xi on its diagonal, x/w is the vector with entries xi/wi, and ‖x‖2w = ∑ iwix 2 i is a w-weighted ℓ2 norm (for wi > 0). The shorthand x . y means x ≤\n(1 + o(1))y. Similarly we write x .P y for x ≤ (1 + oP (1))y. Finally, for a positive integer n ∈ N, we write [n] = {1, 2, . . . , n}.\nHidden Markov Model. We consider a discrete-time, discrete-space HMMs with n hidden states. The HMM output alphabet, denoted Y, may be either discrete or continuous. A parametric-output HMM is characterized by a tuple (A,Fθn, P0) where A is an n× n column stochastic matrix, P0 is the distribution of the initial state and Fθn = (fθ1 , . . . , fθn) is an ordered tuple of parametrized probability density functions. In the sequel we sometimes write fi instead of fθi .\nTo generate the output sequence of the HMM, first an unobserved Markov sequence of hidden states x = {xt}T−1t=0 is generated with the following distribution.\nP (x) = P0(x0)\nT−1 ∏\nt=1\nAxt,xt−1 ,\nwhere Aij = P (Xt = i |Xt−1 = j) are the transition probabilities. Then, each hidden stateXt independently emits an observation Yt ∈ Y according to the distribution P (yt |xt) ≡ fxt(yt). Hence the output sequence y = (yt)T−1t=0 has the conditional probability\nP (y |x) = T−1 ∏\nt=0\nP (yt |xt) = T−1 ∏\nt=0\nfxt(yt).\nThe HMM Learning Problem. Given one or several HMM output sequences (Yt) T−1 t=0 , the HMM learning problem is to estimate both the transition matrix A and the parameters of the output distributions Fθn."
    }, {
      "heading" : "3 Learning Parametric-Output HMMs",
      "text" : "The standard approach to learning the parameters of an HMM is to maximize the likelihood\n∑\nx∈[n]T P0(x0)P (y0 |x0)\nT−1 ∏\nt=1\nAxt,xt−1P (yt |xt).\nAs discussed in the Introduction, this problem is in general computationally hard. In practice, neglecting the small effect of the initial distribution P0(x0)\non the likelihood, A and Fθn are usually estimated via the Baum-Welch algorithm, which is computationally slow and only guaranteed to converge to a local maximum."
    }, {
      "heading" : "3.1 A Decoupling Approach",
      "text" : "In what follows we show that when the output distributions are parametric, we can decouple the HMM learning task into two steps: learning the output parameters θ1, . . . , θn followed by learning the transition probabilities of the HMM. Under some mild structural assumptions on the HMM, this decoupling implies that the difficulty of learning a parametric-output HMM can be reduced to that of learning a parametric mixture model. Indeed, given (an approximation to) Fθn’s parameters, we propose an efficient, single-pass, statistically-consistent algorithm for estimating the transition matrix A.\nAs an example, consider learning a Gaussian HMM with univariate outputs. While the Baum-Welch approach jointly estimates n2+2n parameters (the matrix A and the parameters µi, σ 2 i ), our decoupling approach first fits a mixture model with only 3n parameters (πi, µi, σ 2 i ), and then solves a convex problem for the matrix A. While both problems are in general computationally hard, ours has a significantly lower dimensionality for large n.\nAssumptions. To recover the matrix A and the output parameters θj we make the following assumptions:\n(1a) The Markov chain has a unique stationary distribution π over the n hidden states. Moreover, each hidden state is recurrent with a frequency bounded away from zero: mink πk ≥ a0 for some constant a0 > 0.\n(1b) The n×n transition matrix A is geometrically ergodic1: there exists parameters G < ∞ and ψ ∈ [0, 1) such that from any initial distribution P0\n∥ ∥AtP0 − π ∥ ∥ 1 ≤ 2Gψt, ∀t ∈ N. (1)\n(1c) The output parameters of the n states are all distinct: θi 6= θj for i 6= j. In addition, the parametric family is identifiable.\nRemarks: Assumption (1a) rules out transient states, whose presence makes it generally impossible to estimate all entries in A from one or a few long observed sequences. Assumption (1b) implies mixing and is used later on to bound the error and the number of samples needed to learn the\n1Any finite-state ergodic Markov chain is geometrically ergodic.\nmatrix A. Assumption (1c) is crucial to our approach, which uses the distribution of only single and pairs of consecutive observations. If two states i, j had same output parameters, it would be impossible to distinguish between them based on single outputs."
    }, {
      "heading" : "3.2 Learning the output parameters.",
      "text" : "Assumptions (1a,1b) imply that the Markov chain over the hidden states is mixing, and so after only a few time steps, the distribution of Xt is very close to stationary. Assuming for simplicity that already X0 is sampled from the stationary distribution, or alternatively neglecting the first few outputs, this implies that each observable Yt is a random realization from the following parametric mixture model,\nY ∼ n ∑\ni=1\nπifθi(y). (2)\nHence, given the output sequence (Yt) T−1 t=0 one may estimate the output parameters θi and the stationary distribution πi by fitting a mixture model of the form (2) to the observations. This is commonly done via the EM algorithm.\nLike its more sophisticated cousin Baum-Welch, the mixture-learning EM algorithm also suffers from local maxima. Indeed, from a theoretical viewpoint, learning such a mixture model (i.e. the parameters of Fθn) is a non-trivial task considered in general to be computationally hard. Nonetheless, under various separation assumptions, efficient algorithms with rigorous guarantees have been recently proposed (see e.g. Belkin and Sinha [2010]).2 Note that while these algorithms have polynomial complexity in sample size and output dimension, they are still exponential in the number of mixture components (i.e., in the number of hidden states of the HMM). Hence, these methods do not imply polynomial learnability of parametric-output HMMs.\nIn what follows we assume that using some mixture-learning procedure, the output parameters θj have been estimated with a relatively small error\n(say |θ̂j − θj| = O(1/ √ T )). Furthermore, to allow for cases where θj were estimated from separate observed sequences of perhaps other HMMs with same output parameters but potentially different stationary distributions, we do not assume that πi have been estimated.\n2Note that the techniques for learning mixtures assume iid data. However, if these are algorithmically stable — as such methods typically are — the iid assumption can be replaced by strong mixing [Mohri and Rostamizadeh, 2010]."
    }, {
      "heading" : "3.3 Learning the transition matrix A",
      "text" : "Next, we describe how to recover the matrix A given either exact or approximate knowledge of the HMM output probabilities. For clarity and completeness, we first give an estimation procedure for the stationary distribution π.\nDiscrete observations. As a warm-up to the case of continuous outputs, we start with HMMs with a discrete observation space of size |Y| = m. In this case we can replace Fθn by an m × n column-stochastic matrix B such that Bki ≡ P (k | i) is the probability of observing an output k given that the Markov chain is in hidden state i. In what follows, we assume that the number of output states is larger or equal to the number of hidden states, m ≥ n, and that the m × n matrix B has full rank n. The latter is the discrete analogue of assumption (1c) mentioned above.\nFirst note that since the matrix A has a stationary distribution π, the process Yt also has a stationary distribution ρ, which by analogy to Eq. (2), is\nρ = Bπ. (3)\nSimilarly, the pair (Yt, Yt+1) has a unique stationary distribution σ, given by\nσk,k′ = ∑\nℓ,ℓ′∈[n] πℓAℓ′,ℓBk,ℓBk′,ℓ′ . (4)\nAs we shall see below, knowledge of ρ and σ suffices to estimate π and A. Although ρ and σ are themselves unknown, they are easily estimated from a single pass on the data (Yt) T−1 t=0 :\nρ̂k = 1\nT\nT−1 ∑\nt=0\n1{yt=k},\nσ̂k,k′ = 1 T − 1 T−1 ∑\nt=1\n1{yt−1=k}1{yt=k′}. (5)\nEstimating the stationary distribution π. The key idea in our approach is to replace the exact, but complicated and non-convex likelihood function by a “pseudo-likelihood”, which treats the hidden state sequence (Xt) as if they were iid draws from the unknown stationary distribution\nπ. The pseudo-likelihood has the advantage of having an easily computed global maximum, which, as we show in in Section 4, yields an asymptotically consistent estimator. Approximating the (Xt) as iid draws from π means that the (Yt) are treated as iid draws from ρ = Bπ. Thus, given a sequence (Yt) T−1 t=0 the pseudo-likelihood for a vector π is\nL(y0, . . . , yT−1 |π) = T−1 ∏\ni=0\n(Bπ)yi = m ∏\nk=1\n(Bπ)nkk\nwhere nk = ∑T−1 i=0 1{yt=k} = T ρ̂k. Its maximizer is\nπ̂ML = argmin xi≥0, ‖x‖1=1\n− m ∑\nk=1\nρ̂k log(Bx)k. (6)\nSince − log(x) is convex, (Bx)k is a linear combination of the unknown variables xj , and the constraints are all linear, the above is nothing but a convex program, easily solved via standard optimization methods [Nesterov and Nemirovskii, 1994].\nHowever, to facilitate the analysis and to increase the computational efficiency, we consider the asymptotic behavior of the pseudo-likelihood in (6), for T sufficiently large so that ρ̂ is close to ρ. First, we write\n(Bx)k = ρ̂k\n( 1 + (Bx)k − ρ̂k\nρ̂k\n)\n.\nNext, assuming that T ≫ 1 is sufficiently large to ensure |(Bx)k − ρ̂k| ≪ ρ̂k, we take a second order Taylor expansion of log(Bx)k in (6). This gives\n− n ∑\nk=1\nρ̂k log ρ̂k − n ∑\nk=1\n((Bx)k − ρ̂k) +\n+\nn ∑\nk=1\nρ̂k\n( (Bx)k − ρ̂k ρ̂k\n)2\n+O\n(\n‖Bx− ρ̂‖3∞ minj ρ2j\n)\n.\nThe first term is independent of x, whereas the second term vanishes. Thus, we may approximate (6) by the quadratic program\nargmin xi≥0, ‖x‖1=1\n‖ρ̂ −Bx‖2(1/ρ̂) (7)\nwhere ‖x‖2w = ∑ k wkx 2 k is a weighted ℓ2 norm w.r.t. the weight vector w. Eq. (7) is also a convex problem, easily solved via standard optimization techniques. However, let us temporarily ignore the non-negativity constraints xi ≥ 0 and add a Lagrange multiplier for the equality constraint\n∑ xi = 1:\nmin 1\n2\nm ∑\nk=1\n1\nρ̂k\n( ρ̂k − n ∑\nj=1\nBkjxj\n)2 − λ ( ∑\nj\nxj − 1 ) . (8)\nDifferentiating with respect to xi yields\nWx = (1 + λ)1, (9)\nwhere W = B⊺diag(1/ρ̂)B. Enforcing the normalization constraint is equivalent to solving for x∗ = W−11 and normalizing π̂ = x∗/ ‖x∗‖1. Note that if all entries of x∗ are positive, π̂ is the solution of the optimization problem in (7), and we need not invoke a QP solver. Assumptions (1a,1b) that πk is bounded away from zero and that the chain is mixing imply that for sufficiently large T , all entries of π̂ will be positive with high probability, see Section 4.\nEstimating the transition matrix A. To estimate A, we consider pairs (Yt, Yt+1) of consecutive observations. By definition we have that for a single pair,\nP (Yt = k, Yt+1 = k ′) =\n∑\ni,j\nBk′iBkjAijP (Xt = j).\nAs above, we treat the T − 1 consecutive pairs (Yt, Yt+1) as independent of each other, with the hidden state Xt sampled from the stationary distribution π. When the output probability matrix B and the stationary distribution π are both known, the pseudo-likelihood is given by\nL(y |A) = ∏\n(k,k′)\n(\n∑\nij\nBk′iBkjAijπj\n)nkk′ ,\nwhere nkk′= ∑T−1 t=1 1{yt−1=k}1{yt=k′}=(T − 1)σ̂kk′ . The resulting estimator is\nargmin Aij≥0, ∑ iAij=1,Aπ=π\n− ∑ σ̂kk′ log ( ∑\nij\nCkk ′\nij Aij\n)\n(10)\nwhere Ckk ′ ij = πjBkjBk′i. In practice, since π is not known, we use Ĉ kk′ ij = π̂jBkjBk′i, with π̂ instead of π. Again, (10) is a convex program in A and may be solved by standard constrained convex optimization methods. To obtain a more computationally efficient formulation, let us assume that mink,k′ σk,k′ ≥ a2 > 0, and that mink,k′ T σ̂kk′ ≫ 1, so that\n|(ĈA)kk′ − σ̂kk′| ≪ σ̂kk′, where (ĈA)kk′ = ∑ ij Ĉ kk′ ij Aij . Then, as above, the approximate minimization problem is\nargmin Aij≥0, ∑ iAij=1,Aπ̂=π̂\n∥ ∥ ∥ σ̂ − ĈA ∥ ∥ ∥ 2\n1/σ̂ . (11)\nIn contrast to the estimation of π, where we could ignore the non-negativity constraints, here the constraints Aij ≥ 0 are essential, since for realistic HMMs, some entries in A might be strictly zero. Finally, note that if π̂ = π and σ̂ = σ, the true matrix A satisfies σ = CA and is the minimizer of (10).\nIn summary, given one or more output sequences (yt) T−1 t=0 and an estimate of B, we first make a single pass over the data and construct the estimators ρ̂ and σ̂, with complexity O(T ). Then, the stationary distribution π is estimated via (9), and its transition matrix A via (11). To estimate A, we first compute the matrix product Ĉ⊺Ĉ, with O(n4m2) operations. The resulting QP has size n2, and is thus solvable [den Hertog, 1994] in time O(n6) — which is dominated by O(n4m2) since m ≥ n by assumption. Hence, the overall time complexity of estimating A is O(T + n4m2).\nExtension to continuous observations. We now extend the above results to the case of continuous outputs distributed according to a known parametric family. Recall that in this case, each hidden state i ∈ [n] has an associated output probability density fθi(y). As with discrete observations, we assume that an approximation (θ̂1, . . . , θ̂n) to fi’s parameters is given and use it to construct estimates of π and A.\nTo this end, we seek analogues of (3) and (4), which relate the observable quantities to the latent ones. This will enable us to construct the appropriate empirical estimates and the corresponding quadratic programs, whose solutions will be our estimators π̂ and Â. To handle infinite output alphabets, we map each observation y to an n-dimensional vector ϕ(y) = (fθ1(y), . . . , fθn(y)), whose entries are the likelihood of y from each of the underlying hidden states. As shown below, this allows us to reduce the problem to a discrete “observation” space which can be solved by the methods introduced in the previous subsection.\nEstimating the stationary distribution π. To obtain an analogue of (3), we define the vector ξ ∈ Rn, and matrix K ∈ Rn×n, which will play the role of ρ and B for discrete output alphabets. The vector ξ is defined as\nξ = E[ϕ(Y )], or more explicitly,\nξk ≡ E[fk(Y )] = n ∑\nj=1\nπj\n∫\nY fk(y)P (y | j)dy.\nSimilarly, the (i, j) entry of K is given by\nKij ≡ E[fi(Y ) |X = j] = ∫\nY fi(y)P (y | j)dy. (12)\nWith these definitions we have, as in Eq. (3),\nξ = Kπ. (13)\nThus, given an observed sequence (yt) T−1 t=0 we construct the empirical estimate\nξ̂k = 1\nT\nT−1 ∑\nt=0\nfk(yt), (14)\nand consequently solve the QP\nπ̂ = argmin ‖x‖\n1 =1,x≥0\n∥ ∥ ∥ ξ̂ −Kx ∥ ∥ ∥ 2\n1/ξ̂ . (15)\nIn analogy to the discrete case, we assume rank(K) = n so (15) has a unique solution. Its asymptotic consistency and accuracy are discussed in Section 4.\nEstimating the transition matrix A. Next, following the same paradigm we obtain an analogue of (4). Bayes rule implies that for stationary chains,\nP (k |Y ) = fk(Y )πk∑n l=1 fl(Y )πl . (16)\nWe define the matrices η ∈ Rn×n and F ∈ Rn×n (analogues of σ and B) as follows. Let Y and Y ′ be two consecutive observations of the HMM, then\nηkk′ ≡ E [ P (k |Y )P (k′ |Y ′) ] Fkj ≡ E[P (k |Y ) | j]= ∫\nY P (k | y)P (y | j)dy. (17)\nA simple calculation shows that, as in (4),\nηkk′ =\nn ∑\ni,j=1\nFk′iFkjAijπj . (18)\nSince here F plays the role of B, we may call it an effective observation matrix. This suggests estimating A with the same tools used in the discrete case. Thus, given an observed sequence (yt) T−1 t=0 we construct an empirical estimate η̂ by\nη̂kk′ = 1 T − 1 T−1 ∑\nt=1\nP̂ (k | yt−1)P̂ (k′ | yt), (19)\nwhere P̂ is given by (16) but with π replaced by π̂. Consequently we solve the following QP\nÂ = argmin Aij≥0, ∑ iAij=1,Aπ̂=π̂\n∥ ∥ ∥η̂ − (ĈA) ∥ ∥ ∥ 2\n1/η̂ , (20)\nwhere Ĉkk ′ ij = π̂jFkjFk′i and (ĈA)kk′ = ∑ ij Ĉ kk′ ij Aij . As for the matrix B in the discrete case, to ensure a unique solution to Eq. (20) we assume rank(F ) = n.\nRemark 1. Instead of (18), we could estimate η′k,k′ ≡ E[fk(Y )fk′(Y ′)], from which A can also be recovered, since\nη′k,k′ = n ∑\ni,j=1\nKk′iKkjAijπj.\nThis has the advantage that for many distributions the matrix K can be cast in a closed analytic form. For example in the Gaussian case, while F needs to be calculated numerically, we have\nKij = 1√ 2π 1 √\nσ2i + σ 2 j\nexp\n(\n−1 2 (µi − µj)2 σ2i + σ 2 j\n)\n.\nAdditionally, K does not depend on the stationary distribution. The drawback is that in principle, and as simulations suggest, accurately estimating η′ may require many more samples, see Appendix for details.\nIn summary, given approximate output parameters (θ̂1, . . . , θ̂n), we first calculate the n × n matrix K. Next, we construct the vector ξ̂ by a single pass over the data (Yt) T−1 t=0 . Then the stationary distribution π is estimated via (15). Given π̂, we calculate the n×n matrix F , construct the empirical estimate η̂, and estimate A via (20). As in the discrete observation case, the time complexity of this scheme is O(T + n6) with additional terms for calculating K and F ."
    }, {
      "heading" : "4 Error analysis",
      "text" : "First, we study the statistical properties of our estimators under the assumption that the output parameters, (θ1, . . . , θn) in the continuous case, or the matrix B in the discrete case, are known exactly. Later on we show that our estimators are stable to perturbations in these parameters. For simplicity, throughout this section we assume that the initial hidden state X0 is sampled from the stationary distribution π. This assumption is not essential and omitting it would not qualitatively change our results. All proofs are deferred to the Appendices.\nTo provide bounds on the error and required sample size we make the following additional assumptions:\n(2a) In the discrete case, there exists an a1 > 0 such that minj ρj ≥ a1. (2b) In the continuous case, all fθi are bounded:\nmax i∈[n] sup y∈R\nfθi(y) ≤ L < ∞.\nFinally, for ease of notation we define\ngψ ≡ 2G\n1− ψ .\nAsymptotic Strong Consistency. Our first result shows that with perfectly known output probabilities, as T → ∞, our estimates π̂, Â are strongly consistent. Theorem 1. Let (Yt) T−1 t=0 be an observed sequence of an HMM, whose Markov chain satisfies Assumptions (1a,1b). Assume rank(B) = n in the discrete case, or rank(F ) = rank(K) = n in the continuous case. Then, both estimators, π̂ of (9) and Â of (11) in the discrete case, or (15) and (20) in the continuous case, are asymptotically strongly consistent. Namely, as T → ∞, with probability one,\nπ̂ → π and Â → A.\nError analysis for the stationary distribution π. Recall that to estimate π in the discrete case, we argued that for sufficiently large sample size T , the positivity constraints can be ignored, which amounts to solving an n × n system of linear equations, Eq. (9). The following theorem provides both a lower bound on the required sample size T for this condition to hold with high probability, as well as error bounds on the difference π̂ − π. Theorem 2. Discrete case: Let ρ̂ be given by (5), and π̂ be the solution of (9). Let B̃ = diag(1/ √ ρ)B, and σ1(B̃) be its smallest singular value. Under Assumption (2a), a sequence of length\nT & gψ\n√ log n\na0a1σ1(B̃) , (21)\nis sufficient to ensure that with high probability, all entries in π̂ are strictly positive. Furthermore, as T → ∞,\n‖π̂ − π‖2 .P\n√\ng2ψ\nTa21σ 2 1(B̃)\n. (22)\nNext we consider the errors in the estimate π̂ for the continuous observations case. For simplicity, instead of analyzing the quadratic program (15) with a weighted ℓ2 norm, we consider the following quadratic program, whose solution is also asymptotically consistent:\nmin x≥0,\n∑ i xi=1\n‖ξ̂ −Kx‖22. (23)\nThis allows for a cleaner analysis, without changing the qualitative flavor of the results.\nTheorem 3. Continuous case: Let ξ̂ be given by (14), π̂ be the solution of (15), and K̃ = diag(1/ √ ξ)K. Under Assumption (2b), as T → ∞,\n‖π̂ − π‖2 .P\n√\n(n3 lnn)g2ψL 4\nTσ41(K̃) , (24)\nError Analysis for the Matrix A. Again, for simplicity, instead of analyzing the quadratic programs (11) and (20) with a weighted ℓ2 norm, we consider the following quadratic programs, whose solutions are also asymptotically consistent for ν̂ ∈ {σ̂, η̂}:\nmin Aij≥0, ∑ iAij=1\n‖ν̂ − ĈA‖22. (25)\nNote that this QP is applicable even if νkk′ = 0 for some k, k ′, which implies that ν̂kk′ = 0 as well.\nTheorem 4. Discrete case. Let Â be the solution of (25) with ν̂ = σ̂ given in (5). Then, as T → ∞,\n∥ ∥ ∥ Â−A ∥ ∥ ∥\nF .P\n√\nn3g2ψ Ta40a 2 1σ 10 1 (B)\n(26)\nand thus an observed sequence length\nT & n3g2ψ\na40a 2 1σ 10 1 (B)\n(27)\nsuffices for accurate estimation.\nTheorem 5. Continuous case. Let Â be the solution of (25) with ν̂ = η̂ given in (19). Then, as T → ∞,\n∥ ∥ ∥ Â−A ∥ ∥ ∥\nF .P\n√\n(n7 lnn)g2ψL 4\nTa60σ 8 1(F )σ 4 1(K)\n(28)\nand thus an observed sequence length\nT & (n7 lnn)g2ψL 4\na40σ 8 1(F )σ 4 1(K)\n(29)\nsuffices for accurate estimation.\nRemarks. Note the key role of the smallest singular value σ1, in the error bounds in the theorems above: Two hidden states with very similar output probabilities drive σ1 to zero, thus requiring many more observations to resolve the properties of the underlying hidden sequence.\nInaccuracies in the output parameters. In practice we only have approximate output parameters, found for example, via an EM algorithm. For simplicity, we study the effect of such inaccuracies only in the continuous case. Similar results hold in the discrete case. To this end, assume the errors in the matrices K and F of Eqs. (12) and (17) are of the form\nK̃ = K + ǫLQ, F̃ = F + ǫP, (30)\nwith ‖Q‖F , ‖P‖F ≤ 1. The following theorem shows our estimators are stable w.r.t. errors in the estimated output parameters. Note that if K,F are estimated by a sequence of length T , then typically ǫ = O(T−1/2).\nTheorem 6. Given an error of ǫ in the output parameters as in Eq. (30), the estimators given in Theorems 3 and 5, incur an additional error of at most\nO\n(\nnrǫ\na20σ 4 1\n)\n, (31)\nwith r = 1 for estimating π, and r = 32 for estimating A, and where σ1 is the smallest singular value of K/L2 when estimating π, and of F when estimating A."
    }, {
      "heading" : "5 Simulation Results",
      "text" : "We illustrate our algorithm by some simulation results, executed in MATLAB with the help of the HMM and EM toolboxes3. We consider a toy example with n = 4 hidden states, whose outputs are univariate Gaussians, N (µi, σ2i ), with A, Fθn and π given by\nA =\n\n   0.7 0.0 0.2 0.5 0.2 0.6 0.2 0.0 0.1 0.2 0.6 0.0 0.0 0.2 0.0 0.5\n\n   ,\nf1 = N (−4, 4) f2 = N (0, 1) f3 = N (2, 36) f4 = N (4, 1)\nπ⊺ = (0.3529, 0.2941, 0.2353, 0.1176).\nFig. 1 shows the mixture and its four components.\n3Available at http://www.cs.ubc.ca/~murphyk and http://www.mathworks.com/ (under EM GM Fast).\nTo estimate A we considered the following methods:\nmethod initial θ initial A\n1 BW random random 2 none exactly known QP 3 none EM QP 4 BW exactly known QP 5 BW EM QP 6 BW exactly known random 7 BW EM random\nFig. 2 (left) shows on a logarithmic scale E‖Â−A‖2F vs. sample size T , averaged over 100 independent realizations. Fig. 2 (right) shows the running time as a function of T . In these two figures, the number of iterations of the BW step was set to 20.\nFig. 3 (left) shows the convergence of E‖Â−A‖2F as a function of the number of BW iterations, with known output parameters, but either with or without the QP results. Fig. 3 (right) gives E‖Â−A‖2F as a function of the number of BW iterations for both known and EM-estimated output parameters with 105 samples.\nThe simulation results highlight the following points: (i) BW with a random guess of both A and the parameters θj = (µj , σ 2 j ) is useless if run for only 20 iterations. It often requires hundreds of iterations to converge, in some cases to a poor inaccurate solution (results not shows due to lack of space); (ii) For a small number of samples the accuracy of QP+EM (method 3) is comparable to BW+EM (method 5) but requires only a fraction of\nthe computation time. (iii) When the number of samples becomes large, the QP+EM is not only faster, but (surprisingly) also more accurate than BW+EM. As Fig. 3 suggests, this is due to the slow convergence of the BW algorithm, which requires more than 20 iterations for convergence. (iv) Starting the BW iterations with (µi, σ 2 i ) estimated by EM and A estimated by QP as its initial values significantly accelerated the convergence giving a superior accuracy after only 20 iterations. These results show the (well known) importance of initializing the BW algorithm with sufficiently accurate starting values. Our QP approach provides such an initial value for A by a computationally fast algorithm."
    }, {
      "heading" : "6 Appendix",
      "text" : "We now give a detailed account for the theorems stated in section 4."
    }, {
      "heading" : "6.1 Preliminaries I",
      "text" : "In what follows we use the following notation: For an n × n matrix A, vec(A) ∈ Rn2 is the result of stacking its columns vertically into a single long vector. Thus, its Frobenius matrix norm is ‖A‖F = ‖vec(A)‖2.\nRecall the definition of gψ:\ngψ ≡ 2G\n1− ψ .\nOne can easily verify that for 2G ≥ 1, we have 1 + ψgψ ≤ g2ψ. Also recall that assumption (2b) states that the distributions in Fθn are bounded by L, which is defined by:\nmax i∈[n] sup y∈R\nfθi(y) ≤ L < ∞.\nThe following concentration result from Kontorovich and Weiss [2012, Theorem 1] is our main tool in proving the error bounds given here.\nLemma 1. Let Y = Y0, . . . , YT−1 ∈ YT be the output of a Hidden Markov chain with transition matrix A and output distributions Fθn. Assume that A is geometrically ergodic with constants G,ψ as in (1). Let F : (Y0, . . . , YT−1) 7→ R be any function that is l-Lipschitz with respect to the Hamming metric on YT . Then, for all ǫ > 0,\nP (|F (Y )−EF | > ǫT ) ≤ 2 exp ( −T (1− ψ) 2ǫ2\n2l2G2\n)\n. (32)\nWe will also need the following Lemma (proved in [Kontorovich and Weiss, 2012] for the discrete output case but easily generalize to continuous outputs) for bounding the variance of our estimators.\nLemma 2. Let f(y) : R → R+ be a function of the observables of an n states geometrically ergodic HMM with constants (G,ψ) and\n∫\nY f(y)dy ≤ 1.\nAssume the HMM is started with the stationary distribution π. Then\nVar\n[\n1\nT\nT−1 ∑\nt=0\nf(Yt)\n]\n≤ Var[f(Y )] T + ψgψE[f(Y )] T .\nSimilarly, let g(y, y′) : R × R → R+ be a function of consecutive observations (y, y′) such that\n∫∫\nY g(y, y′)dydy′ ≤ 1.\nThen\nVar\n[\n1\nT\nT−1 ∑\nt=1\ng(Yt, Yt+1)\n]\n≤ Var[g(Y, Y ′)]\nT − 1 +\n(1 + ψgψ)E[g(Y, Y ′)]\nT − 1 ."
    }, {
      "heading" : "6.2 Accuracy of ρ̂, σ̂, ξ̂ and η̂",
      "text" : "Since our estimators π̂ and Â are constructed in terms of ρ̂ and σ̂ in the discrete case, and ξ̂ and η̂ in the continuous case, let us first examine the accuracy of the later. The following results shows that geometric ergodicity is sufficient to ensure their rapid convergence to the true values.\nLemma 3. Discrete case. Let (yt) T t=1 be an observed sequence from a discrete output HMM whose initial state X0 follows the stationary distribution π. Let ρ be given by (3) and σ by (4) with their empirical estimates given in (5). Then\nE[‖ρ̂− ρ‖2] ≤ √\n1 + ψgψ T\n(33)\nE[‖σ̂ − σ‖2] ≤ √\n2 + ψgψ T − 1 (34)\nFurthermore, for any ǫ > 0 ,\nP (‖ρ̂− ρ‖2 > √ 1+ψgψ T + ǫ) ≤ 2 exp\n(\n−2Tǫ2 g2 ψ\n)\n(35)\nand\nP\n(\n‖σ̂ − σ‖2 > √\n2 + ψgψ T − 1 + ǫ\n)\n≤ (36)\n2 exp\n(\n−2(T − 1)ǫ2 g2ψ\n)\n.\nFinally, we have for any fixed v ∈ Rm with ‖v‖2 = 1,\nP (|〈ρ̂,v〉 − 〈ρ,v〉| > ǫ) ≤ 2 exp ( −2Tǫ 2\ng2ψ\n)\n. (37)\nProof. First note that w.r.t the Hamming metric, T ||ρ̂−ρ||2 and |〈ρ̂,v〉 − 〈ρ,v〉| are 1-Lipschitz and T ||σ̂ − σ||2 is 2-Lipschitz. Thus the claims in (35, 36, 37) all follows directly from Lemma 1 where for (35, 36) we also take into account (33) and (34) respectively. In order to prove (33) note that\nE[‖ρ̂− ρ‖22] = ∑ k∈[n] E(ρ̂k − ρk)2 = ∑ k∈[n] V ar(ρ̂k).\nSo by taking in Lemma 2, f(y) = 1y=k, we have E[1y=k] = ρk and V ar(1y=k) = ρk(1− ρk) ≤ ρk. Since ∑m k=1 ρk = 1 we get the desired bound.\nThe bound in (34) is obtained similarly by taking g(y, y′) = 1y=k1y′=k′ in Lemma 2 with the fact that ∑\nkk′ σkk′ = 1.\nLemma 4. Continuous case. Let (Yt) T t=1 be an observed sequence from a continuous observations HMM whose initial state X0 follows the stationary distribution π. Let ξ be given by (13) , η by (18) and ξ̂ and η̂ be their empirical estimates, given by (14) and (19) respectively. Then for any ǫ > 0 ,\nP (∥ ∥ ∥ ξ̂ − ξ ∥ ∥ ∥\n2 > ǫ\n) ≤ 2n exp ( − 2Tǫ 2\ng2ψnL 2\n)\n, (38)\nand\nP (‖η̂ − η‖2 > ǫ) ≤ (39)\n2n2 exp\n(\n−2(T − 1)ǫ 2\ng2ψn 2\n)\n.\nProof. Note that Eξ̂k = ξk and T ξ̂k is L-Lipschitz for all k ∈ [n]. Thus by Lemma 1 and the union bound we have\nP (∥ ∥ ∥ξ̂ − ξ ∥ ∥ ∥ ∞ > ǫ′ )\n≤ 2n exp ( −2Tǫ ′2\ng2ψL 2\n)\n. (40)\nSince ∥\n∥ ∥ ξ̂ − ξ\n∥ ∥ ∥ 2\n2 =\n∑\nk∈[n] (ξ̂k − ξk)2 ≤ n\n∥ ∥ ∥ ξ̂ − ξ ∥ ∥ ∥ 2\n∞ ,\nwe have\nP (∥ ∥ ∥ ξ̂ − ξ ∥ ∥ ∥\n2 > ǫ\n) ≤ P (√ n ∥ ∥ ∥ ξ̂ − ξ ∥ ∥ ∥\n∞ > ǫ\n)\n.\nputting ǫ′ = ǫ/ √ n in (40), the claim in (38) follows.\nThe proof of (39) follows the same paradigm as the proof for (40). Indeed E[η̂kk′ ] = ηkk′ and T ˆηkk′ is 1-Lipschitz so by Lemma 1 and the union bound we have\nP ( ‖η̂ − η‖∞ > ǫ′ )\n≤ 2n2 exp ( −2Tǫ ′2\ng2ψL 2\n)\n. (41)\nSince\n‖η̂ − η‖22 = ∑ k,k′∈[n]×[n] (η̂kk′ − ηkk′)2 ≤ n2 ‖η̂ − η‖2∞ ,\nwe have\nP (‖η̂ − η‖2 > ǫ) ≤ P (n ‖η̂ − η‖∞ > ǫ) .\nputting ǫ′ = ǫ/n in (41), the claim in (39) follows."
    }, {
      "heading" : "6.3 Proof of theorem 1 - Strong consistency",
      "text" : "We now prove the strong consistency of our estimators stated in Theorem 1.\nProof. For the discrete case, by Lemma 3, the expectation E[‖ρ̂− ρ‖2] goes to zero as T → ∞. Furthermore, using the Borel-Cantelli lemma, ‖ρ̂− ρ‖2 converge to its expectation a.s. concluding that ρ̂ converges a.s. to ρ. The same argument goes for σ̂, ξ̂, η̂ and σ, ξ, η respectively.\nNow, the function f : Rm → Rn given by f(x) = (B⊺ diag(1/x)B)−11 is continuous on Rm+ . Moreover, f(ρ) = π since the optimization problem (7) has a unique minimizer x∗ for all ρ̂, which in particular is given by x∗ = π when ρ̂ = ρ. Since ρ ∈ Rm+ by assumption, the argument above shows that almost surely, ρ̂ ∈ Rm+ for all sufficiently large T . Therefore, limT→∞ f(ρ̂) = f(ρ) = π almost surely, and the asymptotic strong consistency of π̂ is established.\nTo prove the asymptotic strong consistency of Â in the discrete case, recall that the minimizer of the quadratic program x⊺Kx − h⊺x subject to Gx ≤ g, Dx = d, is continuous under small perturbations of K,h,G,D, d\n[Dantzig et al., 1967]. In particular, if π̂ is sufficiently close to π then Â is close to A. Since π̂ → π and σ̂ → σ almost surely, we also have Â a.s.−→A.\nFor the continuous observations case, note that π̂ and Â are also solutions of quadratic programs. Also note that ξ̂ → ξ and η̂ → η almost surely. Thus we have that Â a.s.−→A and π̂ a.s.−→π as above."
    }, {
      "heading" : "6.4 Proof of Theorem 2: Bounding the error for π̂ in the discrete observations case",
      "text" : "Proof. Lemma 3 and the fact that ‖ρ̂− ρ‖∞ ≤ ‖ρ̂ − ρ‖2 implies that ‖ρ̂− ρ‖∞ = OP (1/ √ T ). Hence we make a change of variables,\nρ̂ = ρ+ 1√ T ζ. (42)\nTo establish the (eventual) positivity of the entries of π̂, we consider the solution x∗ of (8) with λ = 0, e.g. without the normalization ∑\nxi = 1, and write it as x∗ = π+ δ. Our goal is to understand the relation between δ and ζ.\nObserve that δ satisfies the system of linear equations\n∑\nj\n(\n∑\nk\nBkjBki\nρk\n(\n1 + 1√ T ζk ρk\n)\n)\n(πj + δj) = 1.\nWe need T sufficiently large so that, with high probability, maxk 1√ T ζk ρk ≪ 1, or equivalently, |ρ̂k − ρk| ≪ ρk.\nBy taking T & 4gψ/a 2 1 we have\nE[‖ρ̂− ρ‖∞] ≤ a1/2.\nSo choosing ǫ = min ρk/2 ≥ a1/2 in (35), this condition is satisfied for T & g2ψ/a 2 1. Then, approximating 1/(1 + ǫ) = 1− ǫ+O(ǫ2) gives\n∑\nj\n[\n∑\nk\nBkjBki ρk\n(\n1− 1√ T ζk ρk\n)\n]\n(πj + δj)\n= 1 +OP\n(\n1\nT\n)\n.\nNote that since Bπ = ρ, the leading order correction for δ is simply\nδ = 1√ T (B̃⊺B̃)−1B̃⊺\n(\nζ\nρ\n)\n+OP\n(\n1\nT\n)\n,\nwhere the matrix B̃ = diag(1/ √ ρ)B.\nLet {ui} and {vi} be the right and left singular vectors of B̃ with nonzero singular values σi(B̃), where σ1 ≤ σ2 . . . ≤ σn; thus, B̃ui = σivi. The fact that B̃ also has n non-zero singular values follows from its definition combined with our Assumption 2d that B has rank n. Then\nB̃ ⊺ B̃ = ∑\ni\nσ2i uiu ⊺ i (43)\nand hence,\nδ = 1√ T ∑\ni\n1 σi 〈 ζ ρ ,vi〉ui +OP\n(\n1\nT\n)\n(44)\nFor the solution x to have strictly positive coordinates we need that |δj | < πj for each of j = 1, . . . , n. Without loss of generality, assume that π1 = minj πj and analyze the worst-case setting. This occurs when the singular vector u1 with smallest singular value coincides with the standard basis vector e1. Then,\n|δ1| ≤ 1√ T\n1\nσ1(B̃)minj ρj |〈ζ,v1〉|+OP\n(\n1\nT\n)\n. (45)\nIt follows from (37) that |δ1| will be dominated by minπj ≥ a0 provided that\nT & gψ\na0a1σ1(B̃) . (46)\nIn the unlikely event that (i) the vector π is uniform (πj = 1/n for all j), (ii) the matrix B̃ has n identical singular values, we need the equation analogous to (45) to hold for all n coordinates. By a union bound argument, an additional factor of log n in the number of samples suffices to ensure, with high probability, the non-negativity of the solution x.\nNext we proceed to bound ‖π̂ − π‖22. To this end, we write\nx∗ − π = δ = ∑\ni\n1 σi(B̃) 〈 ρ̂− ρ ρ ,vi〉ui +OP\n(\n1\nT\n)\n.\nSince both the {ui} and the {vi} are orthonormal,\n‖δ‖22 = ∑\ni\n1 σ2i (B̃) 〈 ρ̂ − ρ ρ ,vi〉2\n≤ 1 σ21(B̃)(min ρk) 2 ∑\ni\n〈ρ̂− ρ,vi〉2\n≤ ‖ρ̂− ρ‖ 2 2\nσ21(B̃)a 2 1\n.\nBounding ‖ρ̂− ρ‖22 via Lemma 3 and noting that\n‖π̂ − π‖2 = ∥ ∥ ∥ x∗\n‖x∗‖ 1\n− π ∥ ∥\n∥ 2 ≤ 2 ‖x∗ − π‖2 = 2 ‖δ‖2 ,\nthe result in (22) follows."
    }, {
      "heading" : "6.5 Preliminaries II",
      "text" : "The remaining estimators (π̂ for the continuous observations case, and Â for both the discrete and continuous observations cases) are obtained as solutions for quadratic programs. Let us take for example the QP for calculating π̂ with continuous observations HMM, given in (23). For this case, the QP is equivalent to\nπ̂ = argmin x\n1 2 x ⊺ K ⊺ Kx− x⊺K⊺ ξ̂\nsubject to x ≥ 0 and ∑i xi = 1. Note that if ξ̂ was equal to its true values ξ, the solution of the above QP would simply be the true π. In reality, we only have the estimate ξ̂. In order to analyze the error ‖π̂ − π‖2, we will need to consider how the solutions of such a quadratic program are affected by errors in ξ.\nMore generally, we are concerned with two QPs\nminQ(x) = min 1\n2 x\n⊺ Mx− x⊺h, (47)\nmin Q̂(x) = min 1\n2 x\n⊺ M̂x− x⊺ĥ, (48)\nboth subject to Gx ≤ g, Dx = d. We assume that the solution to the first QP is the “true” value while the solution to the second is our estimate. So bounding the estimate error is equivalent to bounding the error between the solutions obtained by the above two QPs, where M̂ and ĥ are perturbed versions of M and h.\nGiven that, note that only the objective function has been perturbed, while the linear constraints remained unaffected. We may thus apply the following classical result on the solution stability of definite quadratic programs.\nTheorem 7. [Daniel, 1973] Let λ = λmin(M) be the smallest eigenvalue of M , and let ǫ = max{‖M̂ −M‖2, ‖ĥ − h‖2}. Let x and x̂ be the minimizers of Eqs.(47) and (48), respectively. Then, for ǫ < λ,\n‖x− x̂‖2 ≤ ǫ\nλ− ǫ(1 + ‖x‖2).\nIn the following we will obtain bounds on ǫ and λ for the different estimators and invoke the above theorem."
    }, {
      "heading" : "6.6 Proof of Theorem 3: Bounding the error for π̂ in the continuous observations case",
      "text" : "Proof. Note that in the notation given in Theorem 7, we have h = ξ ⊺ K and ĥ = ξ̂ ⊺\nK. Since we assumed that the output density parameters are known exactly we have no error in M = K ⊺\nK. It is immediate that\nλmin(K ⊺ K) = σ21(K),\nand ǫ ≤ ∥ ∥ ∥ξ̂ − ξ ∥ ∥ ∥\n2 ‖K‖2 ≤ nL\n∥ ∥ ∥ξ̂ − ξ ∥ ∥ ∥\n2 .\nFrom Lemma 4 we have\n∥ ∥ ∥ ξ̂ − ξ ∥ ∥ ∥\n2 .P\n√\n(n lnn)g2ψL 2\nT ,\nwhile by Theorem 7 we have\n‖π̂ − π‖2 . ǫ\nλmin(K ⊺ K) (1 + ‖π‖2).\nSince ‖π‖2 ≤ 1, the claim follows.\nAs a side remark we note that the form of (24) is somewhat counterintuitive, as it suggests a worse behavior for larger L. Intuitively, however, larger L corresponds to a more peaked — and hence lower-variance — density, which ought to imply sharper estimates. Note however that as numerical simulations suggest we typically have\nσ21(F̃ )L 2\nσ21(K̃) = O(1).\nThus, whenever σ21(F̃ ) is well behaved so is the estimate in (24) and the bound is reasonable after all. Finally note that F is stochastic so it behaves very much like the matrix B in the discrete outputs case."
    }, {
      "heading" : "6.7 Proof of Theorem 4: Bounding the error of Â in the discrete observations case",
      "text" : "Let Â be the solution of\nmin Aij≥0, ∑ iAij=1\n‖σ̂ − ĈA‖22, (25)\nwhere σ̂ is given in (5). Recall that Ckk ′ ij = πjBkjBk′i and Ĉ kk′ ij = π̂jBkjBk′i. First note that if π and σ were known exactly, the above QP could be written as\nminQ(A) = min 1\n2 vec(A)\n⊺ M vec(A)− vec(A)⊺h (49)\nwhere M = C ⊺ C and h = C ⊺\nvec(σ). Its solution is precisely the transition probability matrix A. In reality, as we only have estimates π̂ and σ̂, the optimization problem is perturbed to\nmin Q̂(A) = min 1\n2 vec(A)⊺M̂ vec(A) − vec(A)⊺ ĥ (50)\nwhere M̂ = Ĉ ⊺ Ĉ, and ĥ = Ĉ ⊺\nvec(σ̂). To analyze how errors in σ̂ and Ĉ affect the optimization problem we follow the same route as above. Thus we need to bound ‖ĥ − h‖2, ‖M̂ − M‖2, and the smallest eigenvalue of M . Regarding the latter, by definition, λmin(M) = σ 2 1(C), where σ1(C) is the smallest singular value of C. A simple exercise in linear algebra yields\nσ1(C) ≥ a0σ21(B). (51) The following lemma provides bounds on ‖M̂ −M‖2 and on ‖ĥ− h‖2. Lemma 5. Asymptotically, as T → ∞,\n‖ĥ− h‖2 .P √ n (‖π̂ − π‖2 + ‖σ̂ − σ‖2) (52)\nand\n‖M̂ −M‖2 .P 2n‖π̂ − π‖2. (53) Proof. By definition, hij = ∑ k,k′ C kk′ ij σkk′, and ĥij = ∑ k,k′ Ĉ kk′ ij σ̂kk′ . Using the definitions of C and Ĉ, up to mixed terms O(‖π̂ − π‖∞‖σ̂ − σ‖∞), we obtain\nĥij − hij = (π̂j − πj) ∑\nkk′\nBkjBk′iσkk′\n+πj ∑\nkk′\nBkjBk′i(σ̂kk′ − σkk′)\nSince each of ‖π̂ − π‖∞ and ‖σ̂ − σ‖∞ are OP (1/ √ T ), the neglected mixed terms are asymptotically negligible as compared to each of the first two ones. Next, we use the fact that σkk′ ≤ 1, πj ≤ 1 and ∑\nkk′ BkjBk′i ≤ 1 to obtain that\n∥ ∥ ∥ĥ− h ∥ ∥ ∥\n2 .P\n√ n ‖π̂ − π‖2 + √ n ‖vec(σ̂)− vec(σ)‖2\nSimilarly, we have that for the n2 × n2 matrix M , and not including higher order mixed terms (π̂j − πj)(π̂β − πβ), which are asymptotically negligible,\n(M̂ −M)ij,αβ = (π̂j − πj)πβ ∑\nkk′\nBkjBkβBk′iBk′α\n+(π̂β − πβ)πj ∑\nkk′\nBkjBkβBk′iBk′α\nNote that ∑ kk′ BkjBkβBk′iBk′α = ( ∑ k BkjBkβ)( ∑ k′ Bk′iBk′α) ≤ 1. Hence, by similar arguments as for h, (53) follows.\nWe can now prove Theorem 4:\nProof. (of Theorem 4) Lemma 3, together with (22), implies that with high probability,\n‖σ̂ − σ‖F .P\n√\ng2ψ T − 1 ,\nand\n‖π̂ − π‖2 .P\n√\ng2ψ\nTa21σ 2 1(B̃)\n.\nInserting these into (52) and (53) yields, w.h.p.,\nǫ = max {∥ ∥ ∥ĥ− h ∥ ∥ ∥ 2 , ∥ ∥ ∥M̂ −M ∥ ∥ ∥ 2 }\n.\n√\nn2g2ψ\nTa21σ 2 1(B̃)\n. (54)\nBy Theorem 7, we have that ∥\n∥ ∥Â−A ∥ ∥ ∥\nF .\nǫ\nλ1(M) (1 + ‖A‖F ), (55)\nwhere ‖A‖F ≤ √ n since A is column-stochastic. The claim follows by substituting the bounds on ǫ in (54) and on λ1(M) = σ 2 1(C) ≥ a20σ41(B) in (51) into (55) and noting that σ21(B̃) ≥ σ21(B)."
    }, {
      "heading" : "6.8 Proof of Theorem 5: Bounding the error of Â in the continuous observations case",
      "text" : "Let Â be the solution of\nmin Aij≥0, ∑ iAij=1\n‖η̂ − ĈA‖22, (25)\nwhere η̂ is given in (19) and Ckk ′ ij = πjFkjFk′i and Ĉ kk′ ij = π̂jFkjFk′i. The above QP can be written as\nmin Q̂(A) = min 1\n2 vec(A)⊺M̂ vec(A) − vec(A)⊺ ĥ (56)\nwhere M̂ = Ĉ ⊺ Ĉ, and ĥ = Ĉ ⊺\nvec(σ̂). Exactly as in the previous subsection, we want to bound the difference\nbetween the solutions for the above QP and the unperturbed one. First note that\nσ1(C) ≥ a0σ21(F ). (57)\nNext we give the analogue of lemma 5.\nLemma 6. Asymptotically, as T → ∞,\n‖ĥ− h‖2 .P √ n ( 1\na0 ‖π̂ − π‖2 + ‖η̂ − η‖2\n)\n(58)\nand\n‖M̂ −M‖2 .P 2n ‖π̂ − π‖2\na0 . (59)\nProof. In contrast to Lemma 5, here F is also perturbed due to errors in π̂ with\nF̂ij =\n∫\nY\nπ̂ifi(y)fj(y) ∑\nk π̂kfk(y) dy.\nExpending the difference ∆Fij ≡ ∣ ∣ ∣F̂ij − Fij ∣ ∣\n∣ up to first order in π̂ − π we find that\n‖∆F‖F ≤ ‖π̂ − π‖∞\na0 ‖F‖F ≤\n√ n ‖π̂ − π‖∞\na0 ,\nwhere in the last inequality we used the fact that F is stochastic. Repeating the arguments in the proof for Lemma 5 and noting that a0 ≪ 1 we get (58) and (59).\nWe now come to the proof of Theorem 5.\nProof. (of Theorem 5) Lemma 4, together with (24), implies that with high probability,\n‖η̂ − η‖F .P\n√\n(n2 lnn)g2ψ T − 1 ,\nand\n‖π̂ − π‖2 .P\n√\n(n3 lnn)g2ψL 4\nTσ41(K̃)\nInserting these into (58) and (59) yields, w.h.p.,\nǫ = max {∥ ∥ ∥ ĥ− h ∥ ∥ ∥ 2 , ∥ ∥ ∥ M̂ −M ∥ ∥ ∥ 2 }\n.\n√\n(n5 lnn)g2ψL 4\nTσ41(K̃) . (60)\nBy Theorem 7, we have that\n∥ ∥ ∥Â−A ∥ ∥ ∥\nF .\nǫ\nλ1(M) (1 + ‖A‖F ), (61)\nwhere ‖A‖F ≤ √ n since A is column-stochastic. The claim follows by substituting the bounds on ǫ in (60) and on λ1(M) = σ 2 1(C) ≥ a20σ41(F ) in (51) into (61) and noting that σ21(F̃ ) ≥ σ21(F ).\nAs for remark 1, we point out that estimating η′ with the help of the matrix K (instead of η with F ) results in an estimator that is not O(1/T )- Lipschitz any more but O(L2/T )-Lipschitz with L = maxi∈[n] supy∈R fθi(y). This means that in principle we will need many more samples to accurately estimate η′ compared to η, see Lemma 4. Thus, since in high dimensions calculating F via numerical integration may be computational intensive, choosing between the two estimators is in some sense choosing between working with limited number of samples and computational efficiency."
    }, {
      "heading" : "6.9 Proof of Theorem 6: Perturbations in the output parameters",
      "text" : "We give here the proof for the perturbation in the matrix F . The proof for perturbations in the matrix K is similar.\nProof. By definition, bij = ∑ k,k′ C kk′ ij σkk′ , and b̂ij = ∑ k,k′ Ĉ kk′ ij σ̂kk′ . Using the definitions of C and Ĉ, up to first order in {‖π̂ − π‖∞ , ‖σ̂ − σ‖∞ , ǫF } we obtain\nb̂ij − bij = (π̂j − πj) ∑\nkk′\nBkjBk′iσkk′\n+πj ∑\nkk′\nBkjBk′i(σ̂kk′ − σkk′)\n+ǫFπj ∑\nkk′\n(PkjBk′i +BkjPk′i)σkk′ .\nAs the two first terms already considered we focus on the last term. It can be shown that:\n∑\nij\n(\nπj ∑\nkk′\nPkjBk′iσkk′\n)2\n≤ n ‖P‖2F .\nThus ∥\n∥ ∥ b̂− b\n∥ ∥ ∥ 2 ≤ √n (‖π̂ − π‖2 + ‖vec(σ̂)− vec(σ)‖2+ (62)\n+2ǫF ‖P‖F ) (1 + o(1)).\nSimilarly, for the matrix K up to first order in {‖π̂ − π‖∞ , ǫF} we have\n(K̂ −K)ij,αβ = (π̂j − πj)πβ ∑\nkk′\nBkjBkβBk′iBk′α\n+ (π̂β − πβ)πj ∑\nkk′\nBkjBkβBk′iBk′α\n+ ǫFπjπβ ∑\nkk′\nPkjBkβBk′iBk′α + . . .\n+ ǫFπβπj ∑\nkk′\nBkjBkβBk′iPk′α.\nAgain considering only the terms including P and using the facts that ∑\nk BkjBkβ ≤ 1 and ∑ kk′(PkjBk′i) 2 ≤ ∑k P 2kj we similarly find that\n∥ ∥ ∥ K̂ −K ∥ ∥ ∥\n2 ≤ (1 + op(1))2n (‖π̂ − π‖2 + 4ǫF ‖P‖F ) .\nRepeating the analysis in the proofs for Theorems 3, 4 and 5 give the desired result."
    } ],
    "references" : [ {
      "title" : "On the computational complexity of approximating distributions by probabilistic automata",
      "author" : [ "N. Abe", "M.K. Warmuth" ],
      "venue" : "Machine Learning,",
      "citeRegEx" : "Abe and Warmuth.,? \\Q1992\\E",
      "shortCiteRegEx" : "Abe and Warmuth.",
      "year" : 1992
    }, {
      "title" : "A method of moments for mixture models and hidden markov models",
      "author" : [ "A. Anandkumar", "D. Hsu", "S.M. Kakade" ],
      "venue" : "In COLT,",
      "citeRegEx" : "Anandkumar et al\\.,? \\Q2012\\E",
      "shortCiteRegEx" : "Anandkumar et al\\.",
      "year" : 2012
    }, {
      "title" : "A maximization technique occurring in the statistical analysis of probabilistic functions of Markov chains",
      "author" : [ "L.E. Baum", "T. Petrie", "G. Soules", "N. Weiss" ],
      "venue" : "Ann. Math. Stat.,",
      "citeRegEx" : "Baum et al\\.,? \\Q1970\\E",
      "shortCiteRegEx" : "Baum et al\\.",
      "year" : 1970
    }, {
      "title" : "Polynomial learning of distribution families",
      "author" : [ "M. Belkin", "K. Sinha" ],
      "venue" : "In Foundations of Computer Science (FOCS),",
      "citeRegEx" : "Belkin and Sinha.,? \\Q2010\\E",
      "shortCiteRegEx" : "Belkin and Sinha.",
      "year" : 2010
    }, {
      "title" : "Inference in hidden Markov models",
      "author" : [ "O. Cappé", "E. Moulines", "T. Rydén" ],
      "venue" : null,
      "citeRegEx" : "Cappé et al\\.,? \\Q2005\\E",
      "shortCiteRegEx" : "Cappé et al\\.",
      "year" : 2005
    }, {
      "title" : "Full reconstruction of Markov models on evolutionary trees: identifiability and consistency",
      "author" : [ "J.T. Chang" ],
      "venue" : "Math. Biosci.,",
      "citeRegEx" : "Chang.,? \\Q1996\\E",
      "shortCiteRegEx" : "Chang.",
      "year" : 1996
    }, {
      "title" : "Learning hidden Markov models using nonnegative matrix factorization",
      "author" : [ "G. Cybenko", "V. Crespi" ],
      "venue" : "IEEE Trans. Information Theory,",
      "citeRegEx" : "Cybenko and Crespi.,? \\Q2011\\E",
      "shortCiteRegEx" : "Cybenko and Crespi.",
      "year" : 2011
    }, {
      "title" : "Stability of the solution of definite quadratic programs",
      "author" : [ "J.W. Daniel" ],
      "venue" : "Mathematical Programming,",
      "citeRegEx" : "Daniel.,? \\Q1973\\E",
      "shortCiteRegEx" : "Daniel.",
      "year" : 1973
    }, {
      "title" : "On the continuity of the minimum sets of a continuous function",
      "author" : [ "G.B. Dantzig", "J. Folkman", "N. Shapiro" ],
      "venue" : "J. Math. Anal. Appl.,",
      "citeRegEx" : "Dantzig et al\\.,? \\Q1967\\E",
      "shortCiteRegEx" : "Dantzig et al\\.",
      "year" : 1967
    }, {
      "title" : "Interior point approach to linear, quadratic and convex programming, volume 277 of Mathematics and its Applications",
      "author" : [ "D. den Hertog" ],
      "venue" : null,
      "citeRegEx" : "Hertog.,? \\Q1994\\E",
      "shortCiteRegEx" : "Hertog.",
      "year" : 1994
    }, {
      "title" : "Asymptotics of the maximum likelihood estimator for general hidden Markov models",
      "author" : [ "R. Douc", "C. Matias" ],
      "venue" : "Bernoulli, 7(3):pp",
      "citeRegEx" : "Douc and Matias.,? \\Q2001\\E",
      "shortCiteRegEx" : "Douc and Matias.",
      "year" : 2001
    }, {
      "title" : "An algorithm to find the global optimum of left-to-right hidden Markov model parameters",
      "author" : [ "A. Faragó", "G. Lugosi" ],
      "venue" : "Problems Control Inform. Theory/Problemy Upravlen. Teor. Inform.,",
      "citeRegEx" : "Faragó and Lugosi.,? \\Q1989\\E",
      "shortCiteRegEx" : "Faragó and Lugosi.",
      "year" : 1989
    }, {
      "title" : "A spectral algorithm for learning hidden markov models",
      "author" : [ "D. Hsu", "S.M. Kakade", "T. Zhang" ],
      "venue" : "In COLT,",
      "citeRegEx" : "Hsu et al\\.,? \\Q2009\\E",
      "shortCiteRegEx" : "Hsu et al\\.",
      "year" : 2009
    }, {
      "title" : "Uniform Chernoff and Dvoretzky-KieferWolfowitz-type inequalities for Markov chains and related processes, arxiv:1207.4678",
      "author" : [ "A. Kontorovich", "R. Weiss" ],
      "venue" : null,
      "citeRegEx" : "Kontorovich and Weiss.,? \\Q2012\\E",
      "shortCiteRegEx" : "Kontorovich and Weiss.",
      "year" : 2012
    }, {
      "title" : "Non-negative matrix factorization for parameter estimation in hidden markov models",
      "author" : [ "B. Lakshminarayanan", "R. Raich" ],
      "venue" : "In Machine Learning for Signal Processing (MLSP), pages",
      "citeRegEx" : "Lakshminarayanan and Raich.,? \\Q2010\\E",
      "shortCiteRegEx" : "Lakshminarayanan and Raich.",
      "year" : 2010
    }, {
      "title" : "Complexity of comparing hidden markov models",
      "author" : [ "R.B. Lyngsø", "C.N. Pedersen" ],
      "venue" : "In Proceedings of the 12th International Symposium on Algorithms and Computation,",
      "citeRegEx" : "Lyngsø and Pedersen.,? \\Q2001\\E",
      "shortCiteRegEx" : "Lyngsø and Pedersen.",
      "year" : 2001
    }, {
      "title" : "Stability bounds for stationary φ-mixing and β-mixing processes",
      "author" : [ "M. Mohri", "A. Rostamizadeh" ],
      "venue" : "The Journal of Machine Learning Research,",
      "citeRegEx" : "Mohri and Rostamizadeh.,? \\Q2010\\E",
      "shortCiteRegEx" : "Mohri and Rostamizadeh.",
      "year" : 2010
    }, {
      "title" : "Settling the polynomial learnability of mixtures of gaussians",
      "author" : [ "Ankur Moitra", "Gregory Valiant" ],
      "venue" : "IEEE 51st Annual Symposium on Foundations of Computer Science,",
      "citeRegEx" : "Moitra and Valiant.,? \\Q2010\\E",
      "shortCiteRegEx" : "Moitra and Valiant.",
      "year" : 2010
    }, {
      "title" : "Learning nonsingular phylogenies and hidden Markov models",
      "author" : [ "E. Mossel", "S. Roch" ],
      "venue" : "Ann. Appl. Probab.,",
      "citeRegEx" : "Mossel and Roch.,? \\Q2006\\E",
      "shortCiteRegEx" : "Mossel and Roch.",
      "year" : 2006
    }, {
      "title" : "Interior-point polynomial algorithms in convex programming",
      "author" : [ "Y. Nesterov", "A. Nemirovskii" ],
      "venue" : null,
      "citeRegEx" : "Nesterov and Nemirovskii.,? \\Q1994\\E",
      "shortCiteRegEx" : "Nesterov and Nemirovskii.",
      "year" : 1994
    }, {
      "title" : "Readings in speech recognition. chapter A tutorial on hidden Markov models and selected applications in speech recognition, pages",
      "author" : [ "L.R. Rabiner" ],
      "venue" : null,
      "citeRegEx" : "Rabiner.,? \\Q1990\\E",
      "shortCiteRegEx" : "Rabiner.",
      "year" : 1990
    }, {
      "title" : "A unifying review of linear gaussian models",
      "author" : [ "S. Roweis", "Z. Ghahramani" ],
      "venue" : "Neural Comput.,",
      "citeRegEx" : "Roweis and Ghahramani.,? \\Q1999\\E",
      "shortCiteRegEx" : "Roweis and Ghahramani.",
      "year" : 1999
    }, {
      "title" : "Reduced-rank Hidden Markov Models",
      "author" : [ "S.M. Siddiqi", "B. Boots", "G.J. Gordon" ],
      "venue" : "In AISTAT,",
      "citeRegEx" : "Siddiqi et al\\.,? \\Q2010\\E",
      "shortCiteRegEx" : "Siddiqi et al\\.",
      "year" : 2010
    }, {
      "title" : "On the learnability of Hidden Markov Models",
      "author" : [ "S. Terwijn" ],
      "venue" : "In Proceedings of the 6th International Colloquium on Grammatical Inference: Algorithms and Applications,",
      "citeRegEx" : "Terwijn.,? \\Q2002\\E",
      "shortCiteRegEx" : "Terwijn.",
      "year" : 2002
    }, {
      "title" : "The following concentration result from Kontorovich and Weiss [2012, Theorem 1] is our main tool in proving the error bounds given here",
      "author" : [ "≤ L" ],
      "venue" : "Let Y = Y0,",
      "citeRegEx" : "∞.,? \\Q2012\\E",
      "shortCiteRegEx" : "∞.",
      "year" : 2012
    } ],
    "referenceMentions" : [ {
      "referenceID" : 2,
      "context" : "When the number of hidden states is known, the standard method for estimating the HMM parameters from given observed data is the Baum-Welch algorithm [Baum et al., 1970].",
      "startOffset" : 150,
      "endOffset" : 169
    }, {
      "referenceID" : 8,
      "context" : "Moitra and Valiant [2010], Belkin and Sinha [2010] and references therein.",
      "startOffset" : 0,
      "endOffset" : 26
    }, {
      "referenceID" : 2,
      "context" : "Moitra and Valiant [2010], Belkin and Sinha [2010] and references therein.",
      "startOffset" : 27,
      "endOffset" : 51
    }, {
      "referenceID" : 2,
      "context" : "Moitra and Valiant [2010], Belkin and Sinha [2010] and references therein. Related work. The problem of estimating HMM parameters from observations has been actively studied since the 1970’s, see Cappé et al. [2005], Rabiner [1990], Roweis and Ghahramani [1999].",
      "startOffset" : 27,
      "endOffset" : 216
    }, {
      "referenceID" : 2,
      "context" : "Moitra and Valiant [2010], Belkin and Sinha [2010] and references therein. Related work. The problem of estimating HMM parameters from observations has been actively studied since the 1970’s, see Cappé et al. [2005], Rabiner [1990], Roweis and Ghahramani [1999].",
      "startOffset" : 27,
      "endOffset" : 232
    }, {
      "referenceID" : 2,
      "context" : "Moitra and Valiant [2010], Belkin and Sinha [2010] and references therein. Related work. The problem of estimating HMM parameters from observations has been actively studied since the 1970’s, see Cappé et al. [2005], Rabiner [1990], Roweis and Ghahramani [1999]. While computing the maximumlikelihood estimator for an HMM is in general computationally intractable, under mild conditions, such an estimator is asymptotically consistent and normally distributed, see Bickel et al.",
      "startOffset" : 27,
      "endOffset" : 262
    }, {
      "referenceID" : 2,
      "context" : "Moitra and Valiant [2010], Belkin and Sinha [2010] and references therein. Related work. The problem of estimating HMM parameters from observations has been actively studied since the 1970’s, see Cappé et al. [2005], Rabiner [1990], Roweis and Ghahramani [1999]. While computing the maximumlikelihood estimator for an HMM is in general computationally intractable, under mild conditions, such an estimator is asymptotically consistent and normally distributed, see Bickel et al. [1998], Chang [1996], Douc and Matias [2001].",
      "startOffset" : 27,
      "endOffset" : 486
    }, {
      "referenceID" : 2,
      "context" : "Moitra and Valiant [2010], Belkin and Sinha [2010] and references therein. Related work. The problem of estimating HMM parameters from observations has been actively studied since the 1970’s, see Cappé et al. [2005], Rabiner [1990], Roweis and Ghahramani [1999]. While computing the maximumlikelihood estimator for an HMM is in general computationally intractable, under mild conditions, such an estimator is asymptotically consistent and normally distributed, see Bickel et al. [1998], Chang [1996], Douc and Matias [2001].",
      "startOffset" : 27,
      "endOffset" : 500
    }, {
      "referenceID" : 2,
      "context" : "Moitra and Valiant [2010], Belkin and Sinha [2010] and references therein. Related work. The problem of estimating HMM parameters from observations has been actively studied since the 1970’s, see Cappé et al. [2005], Rabiner [1990], Roweis and Ghahramani [1999]. While computing the maximumlikelihood estimator for an HMM is in general computationally intractable, under mild conditions, such an estimator is asymptotically consistent and normally distributed, see Bickel et al. [1998], Chang [1996], Douc and Matias [2001]. In recent years, there has been a renewed interest in learning HMMs, in particular under various assumptions that render the learning problem tractable [Faragó and Lugosi, 1989, Hsu et al.",
      "startOffset" : 27,
      "endOffset" : 524
    }, {
      "referenceID" : 1,
      "context" : ", 2010, Anandkumar et al., 2012]. Also, Cybenko and Crespi [2011], Lakshminarayanan and Raich [2010] recently suggested Non-negative Matrix Factorization (NNMF) approaches for learning HMMs.",
      "startOffset" : 8,
      "endOffset" : 66
    }, {
      "referenceID" : 1,
      "context" : ", 2010, Anandkumar et al., 2012]. Also, Cybenko and Crespi [2011], Lakshminarayanan and Raich [2010] recently suggested Non-negative Matrix Factorization (NNMF) approaches for learning HMMs.",
      "startOffset" : 8,
      "endOffset" : 101
    }, {
      "referenceID" : 16,
      "context" : "However, if these are algorithmically stable — as such methods typically are — the iid assumption can be replaced by strong mixing [Mohri and Rostamizadeh, 2010].",
      "startOffset" : 131,
      "endOffset" : 161
    }, {
      "referenceID" : 3,
      "context" : "Belkin and Sinha [2010]).",
      "startOffset" : 0,
      "endOffset" : 24
    }, {
      "referenceID" : 19,
      "context" : "(6) Since − log(x) is convex, (Bx)k is a linear combination of the unknown variables xj , and the constraints are all linear, the above is nothing but a convex program, easily solved via standard optimization methods [Nesterov and Nemirovskii, 1994].",
      "startOffset" : 217,
      "endOffset" : 249
    } ],
    "year" : 2013,
    "abstractText" : "We present a novel approach to learning an HMM whose outputs are distributed according to a parametric family. This is done by decoupling the learning task into two steps: first estimating the output parameters, and then estimating the hidden states transition probabilities. The first step is accomplished by fitting a mixture model to the output stationary distribution. Given the parameters of this mixture model, the second step is formulated as the solution of an easily solvable convex quadratic program. We provide an error analysis for the estimated transition probabilities and show they are robust to small perturbations in the estimates of the mixture parameters. Finally, we support our analysis with some encouraging empirical results.",
    "creator" : "dvips(k) 5.991 Copyright 2011 Radical Eye Software"
  }
}