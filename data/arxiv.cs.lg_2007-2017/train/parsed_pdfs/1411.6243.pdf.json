{
  "name" : "1411.6243.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "Structure Regularization for Structured Prediction: Theories and Experiments",
    "authors" : [ "Xu Sun" ],
    "emails" : [ "xusun@pku.edu.cn" ],
    "sections" : [ {
      "heading" : null,
      "text" : "ar X\niv :1\n41 1.\n62 43\nv1 [\ncs .L\nG ]\n2 3\nN ov"
    }, {
      "heading" : "1 Introduction",
      "text" : "Structured prediction models are popularly used to solve structure dependent problems in a wide variety of application domains including natural language processing, bioinformatics, speech recognition, and computer vision. To solve those problems, many structured prediction methods have been developed, with representative models such as conditional random fields (CRFs), deep neural networks, and structured perceptron models. Recently, in order to more accurately capture structural information, some studies emphasize on intensifying structural dependencies in structured prediction, such as applying long range dependencies among tags and developing long distance features or global features.\nWe argue that over-emphasis on intensive structural dependencies could be misleading, because our study suggests that complex structures are actually harmful to model accuracy. Indeed, while it is obvious that intensive structural dependencies can effectively incorporate structural information, it is less obvious that intensive structural dependencies have a drawback of increasing the generalization risk. Increasing the generalization risk means the trained model tends to overfit the training data, because more complex structures are easier to suffer from overfitting. Formally, our theoretical analysis reveals why and with what degree the structure complexity lowers the generalization ability of trained models. Since this type of overfitting is caused by structure complexity, it can hardly be solved by ordinary regularization methods such as L2 and L1 regularization schemes, which is only for controlling weight complexity.\nTo deal with this problem, we propose a simple structure regularization solution based on tag structure decomposition. The proposed method decomposes each training sample into multiple mini-\nsamples with simpler structures, deriving a model with better generalization power. The proposed method is easy to implement, and it has several interesting properties: (1) We show both theoretically and empirically that the proposed method can effectively reduce the overfitting risk on structured prediction. (2) The proposed method does not change the convexity of the objective function, such that a convex function penalized with a structure regularizer is still convex. This is important for finding global optimum. (3) The proposed method has no conflict with ordinary regularization methods such as L2 and L1 penalties. Thus we can apply structure regularization over an ordinary regularizer to penalize both feature-overfitting and structure-overfitting. We show theoretically and empirically that applying structure regularization over the ordinary regularizer can further reduce the generalization risk in structured prediction. (4) Finally and very interestingly, we show that the proposed method has a by-product of accelerating the rates of convergence in training.\nThe term structural regularization has been used in prior work for regularizing structures of features. For (typically non-structured) classification problems, there are considerable studies on structurerelated regularization, including spectral regularization for modeling feature structures in multi-task learning [1], regularizing feature structures for structural large margin classifiers [27], and many recent studies on structured sparsity. Structure sparsity is studied for a variety of non-structured classification models [14, 6] and structured prediction scenarios [18, 13], via adopting mixed norm regularization [17], Group Lasso [29], posterior regularization [8], and a string of variations [2, 16, 9]. Compared with those prior work, we emphasize that our proposal on tag structure regularization is novel. This is because the term structure in all of the aforementioned work refers to structures of feature space, which is substantially different compared with our proposal on regularizing tag structures (interactions among tags).\nAlso, there are some other related studies in different topics. [23] described an interesting heuristic piecewise training method for structured prediction models. [25] described a “lookahead” learning method based on structured perceptrons. Our work differs from [23] and [25] mainly because our work is built on a regularization framework, with arguments and theoretical justifications on reducing generalization risk and improving convergence rate. Also, our method and the theoretical results can fit general graphical models with arbitrary structures, and the detailed algorithm is very different. [26] suggested consistent approximation for both training and test phase, but there is no indication on structure regularization. On generalization risk analysis, related studies include [4, 19] on non-structured classification and [24, 12] on structured classification.\nTo the best of our knowledge, this is the first theoretical result on quantifying the relation between structure complexity and the generalization risk in structured prediction, and this is also the first proposal on structure regularization via regularizing tag-interactions. The contributions of this work1 are two-fold:\n• On the methodology side, we propose a general purpose structure regularization framework for structured prediction. We show both theoretically and empirically that the proposed method can effectively reduce the overfitting risk in structured prediction, and that the proposed method also has an interesting by-product of accelerating the rates of convergence in training. The structure regularization method and the theoretical analysis do not make assumptions or constraints based on specific structures. In other words, the method and the theoretical results can apply to graphical models with arbitrary structures, including linear chains, trees, and general graphs.\n• On the application side, for several important natural language processing tasks, including part-of-speech tagging, biomedical entity recognition, and word segmentation, our simple method can easily beat the benchmark systems on those highly-competitive tasks, achieving record-breaking accuracies as well as substantially faster training speed."
    }, {
      "heading" : "2 Structure Regularization",
      "text" : "We first describe the proposed structure regularization method, and then give theoretical results on analyzing generalization risk and convergence rates.\n1See the code at http://klcl.pku.edu.cn/member/sunxu/code.htm"
    }, {
      "heading" : "2.1 Settings",
      "text" : "A graph of observations (even with arbitrary structures) can be indexed and be denoted by using an indexed sequence of observations O = {o1, . . . , on}. We use the term sample to denote O = {o1, . . . , on}. For example, in natural language processing, a sample may correspond to a sentence of n words with dependencies of linear chain structures (e.g., in part-of-speech tagging) or tree structures (e.g., in syntactic parsing). In signal processing, a sample may correspond to a sequence of n signals with dependencies of arbitrary structures. For simplicity in analysis, we assume all samples have n observations (thus n tags). In a typical setting of structured prediction, all the n tags have inter-dependencies via connecting each Markov dependency between neighboring tags. Thus, we call n as tag structure complexity or simply structure complexity below.\nA sample is converted to an indexed sequence of feature vectorsx = {x(1), . . . ,x(n)}, wherex(k) ∈ X is of the dimension d and corresponds to the local features extracted from the position/index k.2 We can use an n×d matrix to representx ∈ Xn. In other words, we use X to denote the input space on a position, so that x is sampled from Xn. Let Yn ⊂ Rn be structured output space, so that the structured output y are sampled from Yn. Let Z = (Xn,Yn) be a unified denotation of structured input and output space. Let z = (x,y), which is sampled from Z , be a unified denotation of a (x,y) pair in the training data.\nSuppose a training set is\nS = {z1 = (x1, y1), . . . , zm = (xm, ym)}, with size m, and the samples are drawn i.i.d. from a distribution D which is unknown. A learning algorithm is a function G : Zm 7→ F with the function space F ⊂ {Xn 7→ Yn}, i.e., G maps a training set S to a function GS : Xn 7→ Yn. We suppose G is symmetric with respect to S, so that G is independent on the order of S.\nStructural dependencies among tags are the major difference between structured prediction and nonstructured classification. For the latter case, a local classification of g based on a position k can be expressed as g(x(k−a), . . . ,x(k+a)), where the term {x(k−a), . . . ,x(k+a)} represents a local window. However, for structured prediction, a local classification on a position depends on the whole input x = {x(1), . . . ,x(n)} rather than a local window, due to the nature of structural dependencies among tags (e.g., graphical models like CRFs). Thus, in structured prediction a local classification on k should be denoted as g(x(1), . . . ,x(n), k). To simplify the notation, we define\ng(x, k) , g(x(1), . . . ,x(n), k)\nGiven a training set S of size m, we define S\\i as a modified training set, which removes the i’th training sample: S\\i = {z1, . . . , z i−1, z i+1, . . . , zm}, and we define Si as another modified training set, which replaces the i’th training sample with a new sample ẑ i drawn from D:\nSi = {z1, . . . , z i−1, ẑ i, z i+1, . . . , zm},\nWe define point-wise cost function c : Y×Y 7→ R+ as c[GS(x, k), y(k)], which measures the cost on a position k by comparing GS(x, k) and the gold-standard tag y(k), and we introduce the point-wise loss as\nℓ(GS , z, k) , c[GS(x, k), y(k)]\nThen, we define sample-wise cost function C : Yn × Yn 7→ R+, which is the cost function with respect to a whole sample, and we introduce the sample-wise loss as\nL(GS , z) , C[GS(x), y ] = n∑\nk=1\nℓ(GS , z, k) =\nn∑\nk=1\nc[GS(x, k), y(k)]\n2In most of the existing structured prediction methods, including conditional random fields (CRFs), all the local feature vectors should have the same dimension of features.\nGiven G and a training set S, what we are most interested in is the generalization risk in structured prediction (i.e., expected average loss) [24, 12]:\nR(GS) = Ez [L(GS , z) n ]\nUnless specifically indicated in the context, the probabilities and expectations over random variables, including Ez (.), ES(.), Pz(.), and PS(.), are based on the unknown distribution D.\nSince the distribution D is unknown, we have to estimate R(GS) from S by using the empirical risk:\nRe(GS) = 1\nmn\nm∑\ni=1\nL(GS , z i) = 1\nmn\nm∑\ni=1\nn∑\nk=1\nℓ(GS , z i, k)\nIn what follows, sometimes we will use simplified notations, R and Re, to denote R(GS) and Re(GS).\nTo state our theoretical results, we must describe several quantities and assumptions which are important in structured prediction. We follow some notations and assumptions on non-structured classification [4, 19]. We assume a simple real-valued structured prediction scheme such that the class predicted on position k of x is the sign of GS(x, k) ∈ D.3 Also, we assume the point-wise cost function cτ is convex and τ -smooth such that ∀y1, y2 ∈ D, ∀y∗ ∈ Y\n|cτ (y1, y∗)− cτ (y2, y∗)| ≤ τ |y1 − y2| (1)\nThen, τ -smooth versions of the loss and the cost function can be derived according to their prior definitions:\nLτ (GS , z) = Cτ [GS(x), y ] = n∑\nk=1\nℓτ (GS , z, k) =\nn∑\nk=1\ncτ [GS(x, k), y(k)]\nAlso, we use a value ρ to quantify the bound of |GS(x, k) − GS\\i(x, k)| while changing a single sample (with size n′ ≤ n) in the training set with respect to the structured inputx. This ρ-admissible assumption can be formulated as ∀k,\n|GS(x, k)−GS\\i(x, k)| ≤ ρ||GS −GS\\i ||2 · ||x||2 (2) where ρ ∈ R+ is a value related to the design of algorithm G."
    }, {
      "heading" : "2.2 Structure Regularization",
      "text" : "Most existing regularization techniques are for regularizing model weights/parameters (e.g., a representative regularizer is the Gaussian regularizer or so called L2 regularizer), and we call such regularization techniques as weight regularization.\n3In practice, many popular structured prediction models have a convex and real-valued cost function (e.g., CRFs).\nAlgorithm 1 Training with structure regularization 1: Input: model weights w, training set S, structure regularization strength α 2: repeat 3: S′ ← ∅ 4: for i = 1 → m do 5: Randomly decompose z i ∈ S into mini-samples Nα(z i) = {z(i,1), . . . , z(i,α)} 6: S′ ← S′ ∪Nα(z i) 7: end for 8: for i = 1 → |S′| do 9: Sample z ′ uniformly at random from S′, with gradient ∇gz′(w) 10: w ← w − η∇gz′(w) 11: end for 12: until Convergence 13: return w\nDefinition 1 (Weight regularization) Let Nλ : F 7→ R+ be a weight regularization function on F with regularization strength λ, the structured classification based objective function with general weight regularization is as follows:\nRλ(GS) , Re(GS) +Nλ(GS) (3)\nWhile weight regularization is normalizing model weights, the proposed structure regularization method is normalizing the structural complexity of the training samples. As illustrated in Figure 1, our proposal is based on tag structure decomposition, which can be formally defined as follows:\nDefinition 2 (Structure regularization) Let Nα : F 7→ F be a structure regularization function on F with regularization strength α with 1 ≤ α ≤ n, the structured classification based objective function with structure regularization is as follows4:\nRα(GS) , Re[GNα(S)] = 1\nmn\nm∑\ni=1\nα∑\nj=1\nL[GS′ , z(i,j)] = 1\nmn\nm∑\ni=1\nα∑\nj=1\nn/α ∑\nk=1\nℓ[GS′ , z(i,j), k] (4)\nwhere Nα(z i) randomly splits z i into α mini-samples {z(i,1), . . . , z(i,α)}, so that the mini-samples have a distribution on their sizes (structure complexities) with the expected value n′ = n/α. Thus, we get\nS′ = {z(1,1), z(1,2), . . . , z(1,α) ︸ ︷︷ ︸\nα\n, . . . , z(m,1), z(m,2), . . . , z(m,α) ︸ ︷︷ ︸\nα\n} (5)\nwith mα mini-samples with expected structure complexity n/α. We can denote S′ more compactly as S′ = {z ′1, z ′2, . . . , z ′mα} and Rα(GS) can be simplified as\nRα(GS) , 1\nmn\nmα∑\ni=1\nL(GS′ , z ′i) = 1\nmn\nmα∑\ni=1\nn/α ∑\nk=1\nℓ[GS′ , z ′ i, k] (6)\nNote that, when the structure regularization strength α = 1, we have S′ = S and Rα = Re. The structure regularization algorithm (with the stochastic gradient descent setting) is summarized in Algorithm 1.\nSince we know z = (x,y), the decomposition of z simply means the decomposition of x and y . Recall that x = {x(1), . . . ,x(n)} is an indexed sequence of the feature vectors, not the observations O = {o1, . . . , on}. Thus, it should be emphasized that the decomposition of x is the decomposition of the feature vectors, not the original observations. Actually the decomposition of the feature vectors is more convenient and has no information loss — no need to regenerate features. On the other hand, decomposing observations needs to regenerate features and may lose some features.\n4The notation N is overloaded here. For clarity throughout, N with subscript λ refers to weight regularization function, and N with subscript α refers to structure regularization function.\nThe structure regularization has no conflict with the weight regularization, and the structure regularization can be applied together with the weight regularization. Actually we will show that applying the structure regularization over the weight regularization can further improve stability and reduce generalization risk.\nDefinition 3 (Structure & weight regularization) By combining structure regularization in Definition 2 and weight regularization in Definition 1, the structured classification based objective function is as follows:\nRα,λ(GS) , Rα(GS) +Nλ(GS) (7) When α = 1, we have Rα,λ = Re(GS) +Nλ(GS) = Rλ.\nLike existing weight regularization methods, currently our structure regularization is only for the training stage. Currently we do not use structure regularization in the test stage."
    }, {
      "heading" : "2.3 Stability of Structured Prediction",
      "text" : "In contrast to the simplicity of the algorithm, the theoretical analysis is quite technical. First, we analyze the stability of structured prediction.\nDefinition 4 (Function stability) A real-valued structured classification algorithmG has “function value based stability” (“function stability” for short) ∆ if the following holds: ∀z = (x,y) ∈ Z, ∀S ∈ Zm, ∀i ∈ {1, . . . ,m}, ∀k ∈ {1, . . . , n},\n|GS(x, k)−GS\\i(x, k)| ≤ ∆\nDefinition 5 (Loss stability) A structured classification algorithm G has “uniform loss-based stability” (“loss stability” for short) ∆l if the following holds: ∀z ∈ Z, ∀S ∈ Zm, ∀i ∈ {1, . . . ,m}, ∀k ∈ {1, . . . , n},\n|ℓ(GS , z, k)− ℓ(GS\\i , z, k)| ≤ ∆l\nG has “sample-wise uniform loss-based stability” (“sample loss stability” for short) ∆s with respect to the loss function L if the following holds: ∀z ∈ Z, ∀S ∈ Zm, ∀i ∈ {1, . . . ,m},\n|L(GS , z)− L(GS\\i , z)| ≤ ∆s Lemma 6 (Loss stability vs. function stability) If a real-valued structured classification algorithm G has function stability ∆ with respect to loss function ℓτ , then G has loss stability τ∆ and sample loss stability nτ∆.\nThe proof is in Section 4.\nHere, we show that our structure regularizer can further improve stability (thus reduce generalization risk) over a model which already equipped with a weight regularizer.\nTheorem 7 (Stability vs. structure regularization) With a training set S of size m, let the learning algorithm G have the minimizer f based on commonly used L2 weight regularization:\nf = argmin g∈F Rα,λ(g) = argmin g∈F\n( 1\nmn\nmα∑\nj=1\nLτ (g,z ′j) + λ\n2 ||g||22\n)\n(8)\nwhere α denotes structure regularization strength with 1 ≤ α ≤ n. Also, we have\nf\\i ′\n= argmin g∈F\nR \\i′ α,λ(g) = argmin\ng∈F\n( 1\nmn\n∑ j 6=i′ Lτ (g,z ′j) + λ 2 ||g||22\n)\n(9)\nwhere j 6= i′ means j ∈ {1, . . . , i′ − 1, i′ + 1, . . . ,mα}.5 Assume Lτ is convex and differentiable, and f(x, k) is ρ-admissible. Let a local feature value is bounded by v such that x(k,q) ≤ v for\n5Note that, in some cases the notation i is ambiguous. For example, f\\i can either denote the removing of a sample in S or denote the removing of a mini-sample in S′. Thus, when the case is ambiguous, we use different index symbols for S and S′, with i for indexing S and i′ for indexing S′, respectively.\nq ∈ {1, . . . , d}.6 Let ∆ denote the function stability of f comparing with f\\i′ for ∀z ∈ Z with |z | = n. Then, ∆ is bounded by\n∆ ≤ dτρ 2v2n2\nmλα2 , (10)\nand the corresponding loss stability is bounded by dτ 2ρ2v2n2\nmλα2 , and the corresponding sample loss\nstability is bounded by dτ 2ρ2v2n3\nmλα2 .\nThe proof is in Section 4.\nWe can see that increasing the size of training set m results in linear improvement of ∆, and increasing the strength of structure regularization α results in quadratic improvement of ∆.\nThe function stability ∆ is based on comparing f and f\\i ′\n, i.e., the stability is based on removing a mini-sample. Moreover, we can extend the analysis to the function stability based on comparing f and f\\i, i.e., the stability is based on removing a full-size sample.\nCorollary 8 (Stability based on \\i rather than \\i′) With a training set S of size m, let the learning algorithm G have the minimizer f as defined like before. Also, we have\nf\\i = argmin g∈F R \\i α,λ(g) = argmin g∈F\n( 1\nmn\n∑ j /∈i Lτ (g,z ′j) + λ 2 ||g||22\n)\n(11)\nwhere j /∈ i means j ∈ {1, . . . , (i − 1)α, iα + 1, . . . ,mα}, i.e., all the mini-samples derived from the sample z i are removed. Assume Lτ is convex and differentiable, and f(x, k) is ρ-admissible. Let a local feature value is bounded by v such that x(k,q) ≤ v for q ∈ {1, . . . , d}. Let ∆̄ denote the function stability of f comparing with f\\i for ∀z ∈ Z with |z | = n. Then, ∆̄ is bounded by\n∆̄ ≤ dτρ 2v2n2\nmλα = α sup(∆), (12)\nwhere ∆ is the function stability of f comparing with f\\i ′ , and sup(∆) = dτρ 2v2n2\nmλα2 , as described in Eq. (10).\nThe proof is in Section 4."
    }, {
      "heading" : "2.4 Reduction of Generalization Risk",
      "text" : "Theorem 9 (Generalization vs. stability) Let G be a real-valued structured classification algorithm with a point-wise loss function ℓτ such that ∀k, 0 ≤ ℓτ (GS , z, k) ≤ γ. Let f , ∆, and ∆̄ be defined like before. Let R(f) be the generalization risk of f based on the expected sample z ∈ Z with size n, as defined like before. Let Re(f) be the empirical risk of f based on S, as defined like before. Then, for any δ ∈ (0, 1), with probability at least 1− δ over the random draw of the training set S, the generalization risk R(f) is bounded by\nR(f) ≤ Re(f) + 2τ∆̄ + ( (4m− 2)τ∆+ γ ) √ α ln δ−1\n2m (13)\nThe proof is in Section 4.\nTheorem 10 (Generalization vs. structure regularization) Let the structured prediction objective function of G be penalized by structure regularization with factor α ∈ [1, n] and L2 weight regularization with factor λ, and the penalized function has a minimizer f :\nf = argmin g∈F Rα,λ(g) = argmin g∈F\n( 1\nmn\nmα∑\nj=1\nLτ (g,z ′j) + λ\n2 ||g||22\n)\n(14)\nAssume the point-wise loss ℓτ is convex and differentiable, and is bounded by ℓτ (f,z, k) ≤ γ. Assume f(x, k) is ρ-admissible. Let a local feature value be bounded by v such that x(k,q) ≤ v for\n6Recall that d is the dimension of local feature vectors defined in Section 2.1.\nq ∈ {1, . . . , d}. Then, for any δ ∈ (0, 1), with probability at least 1 − δ over the random draw of the training set S, the generalization risk R(f) is bounded by\nR(f) ≤ Re(f) + 2dτ2ρ2v2n2 mλα + ((4m− 2)dτ2ρ2v2n2 mλα2 + γ ) √ α ln δ−1 2m (15)\nSince τ, ρ, and v are typically small compared with other variables, especially m, (15) can be approximated as follows by ignoring small terms:\nR(f) ≤ Re(f) +O (dn2\n√ ln δ−1\nλα1.5 √ m\n)\n(16)\nProof According to (10) and (12), we have ∆ ≤ dτρ2v2n2mλα2 and ∆̄ ≤ dτρ2v2n2\nmλα . Inserting those bounds into (13) gives (15). ⊓⊔\nWe call the term O ( dn2 √ ln δ−1\nλα1.5 √ m\n)\nin (16) as “overfit-bound”, and reducing the overfit-bound is cru-\ncial for reducing the generalization risk bound. First, (16) suggests that structure complexity n can increase the overfit-bound on a magnitude of O(n2), and applying weight regularization can reduce the overfit-bound by O(λ). Importantly, applying structure regularization further (over weight regularization) can additionally reduce the overfit-bound by a magnitude of O(α1.5). When α = 1, it means “no structure regularization”, then we have the worst overfit-bound O ( dn2 √ ln δ−1\nλ √ m\n)\n. Also,\n(16) suggests that increasing the size of training set can reduce the overfit-bound on a square root level.\nActually, the generalization bound in Theorem 10 is based on an arguably over-strict assumption of completely dense features. Since many applications in practice are based on sparse features, this completely dense feature assumption can be relaxed, which can further improve the generalization bound (i.e., with a tighter overfit-bound).\nCorollary 11 (Generalization vs. moderate feature sparsity) Let f be defined like before. Assume the point-wise loss ℓτ is convex and differentiable, and is bounded by ℓτ (f,z, k) ≤ γ. Assume f(x, k) is ρ-admissible. Let a local feature value be bounded by v such that x(k,q) ≤ v for q ∈ {1, . . . , d}. If we assume the features are “moderately sparse” such that the global feature vector\n∑|x| k=1 x(k,q) ≤ vβ\n√\n|x| for q ∈ {1, . . . , d} (with β being a sparsity related scalar), then for any δ ∈ (0, 1), with probability at least 1 − δ over the random draw of the training set S, the generalization risk R(f) is bounded by\nR(f) ≤ Re(f) + 2dτ2ρ2v2β2n\nmλ √ α\n+ ((4m− 2)dτ2ρ2v2β2n mλα1.5 + γ ) √ α ln δ−1 2m (17)\nIt can be approximated as follows by ignoring small terms:\nR(f) ≤ Re(f) +O (dn\n√ ln δ−1\nλα √ m\n)\n(18)\nThe proof is in Section 4.\nCorollary 12 (Generalization vs. extreme feature sparsity) Let f be defined like before. Assume the point-wise loss ℓτ is convex and differentiable, and is bounded by ℓτ (f,z, k) ≤ γ. Assume f(x, k) is ρ-admissible. Let a local feature value be bounded by v such that x(k,q) ≤ v for q ∈ {1, . . . , d}. If we assume the features are “extremely sparse” such that the global feature vector ∑|x|\nk=1 x(k,q) ≤ vβ for q ∈ {1, . . . , d} (with β being a sparsity related scalar), then for any δ ∈ (0, 1), with probability at least 1− δ over the random draw of the training set S, the generalization risk R(f) is bounded by\nR(f) ≤ Re(f) + 2dτ2ρ2v2β2 mλ + ((4m− 2)dτ2ρ2v2β2 mλα + γ ) √ α ln δ−1 2m (19)\nIt can be approximated as follows by ignoring small terms:\nR(f) ≤ Re(f) +O (d\n√ ln δ−1 λ √ αm )\n(20)\nThe proof is in Section 4."
    }, {
      "heading" : "2.5 Accelerating Convergence Rates in Training",
      "text" : "We also analyze the impact on the convergence rate of online learning by applying structure regularization. Our analysis is based on the stochastic gradient descent (SGD) setting [3, 11, 15], which is arguably the most representative online training setting. Let g(w) be the structured prediction objective function and w ∈ W is the weight vector. Recall that the SGD update with fixed learning rate η has a form like this: wt+1 ← wt − η∇gzt(wt) (21) where gz(wt) is the stochastic estimation of the objective function based on z which is randomly drawn from S.\nTo state our convergence rate analysis results, we need several assumptions following (Nemirovski et al. 2009). We assume g is strongly convex with modulus c, that is, ∀w,w ′ ∈ W ,\ng(w′) ≥ g(w) + (w ′ −w)T∇g(w) + c 2 ||w′ −w||2 (22)\nWhen g is strongly convex, there is a global optimum/minimizer w∗. We also assume Lipschitz continuous differentiability of g with the constant q, that is, ∀w,w′ ∈ W ,\n||∇g(w ′)−∇g(w)|| ≤ q||w′ −w|| (23) It is also reasonable to assume that the norm of ∇gz(w) has almost surely positive correlation with the structure complexity of z ,7 which can be quantified by a bound κ ∈ R+:\n||∇gz(w)||2 ≤ κ|z | almost surely for ∀w ∈ W (24) where |z | denotes the structure complexity of z . Moreover, it is reasonable to assume\nηc < 1 (25)\nbecause even the ordinary gradient descent methods will diverge if ηc > 1.\nThen, we show that structure regularization can quadratically accelerate the SGD rates of convergence:\nProposition 13 (Convergence rates vs. structure regularization) With the aforementioned assumptions, let the SGD training have a learning rate defined as η = cǫβα 2\nqκ2n2 , where ǫ > 0 is a convergence tolerance value and β ∈ (0, 1]. Let t be a integer satisfying\nt ≥ qκ 2n2 log (qa0/ǫ)\nǫβc2α2 (26)\nwhere n andα ∈ [1, n] is like before, and a0 is the initial distance which depends on the initialization of the weights w0 and the minimizer w∗, i.e., a0 = ||w0 − w∗||2. Then, after t updates of w it converges to E[g(wt)− g(w∗)] ≤ ǫ.\nThe proof is in Section 4.\nThis Proposition demonstrates the 1/t convergence rate with t given in (26). Recall that when α = 1, the algorithm with structure regularization reduces exactly to the ordinary algorithm (without structure regularization), which has the number of SGD updates t ≥ qκ 2n2 log (qa0/ǫ)\nǫβc2 to achieve the convergence tolerance value ǫ. In other words, applying structure regularization with the strength α can quadratically accelerate the convergence rate with a factor of α2.\n7Many structured prediction systems (e.g., CRFs) satisfy this assumption that the gradient based on a larger sample (i.e., n is large) is expected to have a larger norm."
    }, {
      "heading" : "3 Experiments",
      "text" : ""
    }, {
      "heading" : "3.1 Tasks",
      "text" : "Diversified Tasks. We experiment on natural language processing tasks and signal processing tasks. The natural language processing tasks include (1) part-of-speech tagging, (2) biomedical named entity recognition, and (3) Chinese word segmentation. The signal processing task is (4) sensor-based human activity recognition. The tasks (1) to (3) use boolean features and the task (4) adopts realvalued features. From tasks (1) to (4), the averaged structure complexity (number of observations) n is very different, with n = 23.9, 26.5, 46.6, 67.9, respectively. The dimension of tags |Y| is also diversified among tasks, with |Y| ranging from 5 to 45. Part-of-Speech Tagging (POS-Tagging). Part-of-Speech (POS) tagging is an important and highly competitive task in natural language processing. We use the standard benchmark dataset in prior work [5], which is derived from PennTreeBank corpus and uses sections 0 to 18 of the Wall Street Journal (WSJ) for training (38,219 samples), and sections 22-24 for testing (5,462 samples). Following prior work [25], we use features based on unigrams and bigrams of neighboring words, and lexical patterns of the current word, with 393,741 raw features8 in total. Following prior work, the evaluation metric for this task is per-word accuracy.\nBiomedical Named Entity Recognition (Bio-NER). This task is from the BioNLP-2004 shared task, which is for recognizing 5 kinds of biomedical named entities (DNA, RNA, etc.) on the MEDLINE biomedical text corpus. There are 17,484 training samples and 3,856 test samples. Following prior work [25], we use word pattern features and POS features, with 403,192 raw features in total. The evaluation metric is balanced F-score.\nWord Segmentation (Word-Seg). Chinese word segmentation is important and it is usually the first step for text processing in Chinese. We use the Microsoft Research (MSR) data provided by SIGHAN-2004 contest. There are 86,918 training samples and 3,985 test samples. Following prior work [7], we use features based on character unigrams and bigrams, with 1,985,720 raw features in total. The evaluation metric for this task is balanced F-score.\nSensor-based Human Activity Recognition (Act-Recog). This is a task based on real-valued sensor signals, with the data extracted from the Bao04 activity recognition dataset [21]. This task aims to recognize human activities (walking, bicycling, etc.) by using 5 biaxial sensors to collect acceleration signals of individuals, with the sampling frequency at 76.25HZ. Following prior work in activity recognition [21], we use acceleration features, mean features, standard deviation, energy, and correlation features, with 1228 raw features in total. There are 16,000 training samples and 4,000 test samples. Following prior work, the evaluation metric is accuracy."
    }, {
      "heading" : "3.2 Experimental Settings",
      "text" : "To test the robustness of the proposed structure regularization (StructReg) method, we perform experiments on both probabilistic and non-probabilistic structure prediction models. We choose the conditional random fields (CRFs) [10] and structured perceptrons (Perc) [5], which are arguably the most popular probabilistic and non-probabilistic structured prediction models, respectively. The CRFs are trained using the SGD algorithm,9 and the baseline method is the traditional weight regularization scheme (WeightReg), which adopts the most representative L2 weight regularization, i.e., a Gaussian prior.10 For the structured perceptrons, the baseline WeightAvg is the popular implicit regularization technique based on parameter averaging, i.e., averaged perceptron [5].\nAll methods use the same set of features. Since the rich edge features [22] can be automatically generated from raw features and are very useful for improving model accuracy, the rich edge features are employed for all methods. All methods are based on the 1st-order Markov dependency. For\n8Raw features are those observation features based only on x, i.e., no combination with tag information. 9In theoretical analysis, following prior work we adopt the SGD with fixed learning rate, as described in Section 2.5. However, since the SGD with decaying learning rate is more commonly used in practice, in experiments we use the SGD with decaying learning rate.\n10We also tested on sparsity emphasized regularization methods, including L1 regularization and Group Lasso regularization [13]. However, we find that in most cases those sparsity emphasized regularization methods have lower accuracy than the L2 regularization.\nWeightReg, the L2 regularization strengths (i.e., λ/2 in Eq.8) are tuned among values 0.1, 0.5, 1, 2, 5, and are determined on the development data provided by the standard dataset (POS-Tagging) or simply via 4-fold cross validation on the training set (Bio-NER, Word-Seg, and Act-Recog). With this automatic tuning for WeightReg, we set 2, 5, 1 and 5 for POS-Tagging, Bio-NER, Word-Seg, and Act-Recog tasks, respectively. Our StructReg method adopts the same L2 regularization setting like WeightReg. Experiments are performed on a computer with Intel(R) Xeon(R) 3.0GHz CPU."
    }, {
      "heading" : "3.3 Experimental Results",
      "text" : "The experimental results in terms of accuracy/F-score are shown in Figure 2. For the CRF model, the training is convergent, and the results on the convergence state (decided by relative objective change with the threshold value of 0.0001) are shown. For the structured perceptron model, the training is typically not convergent, and the results on the 10’th iteration are shown. For stability of the curves, the results of the structured perceptrons are averaged over 10 repeated runs.\nSince different samples have different size n in practice, we set α being a function of n, so that the generated mini-samples are with fixed size n′ with n′ = n/α. Actually, n′ is a probabilistic distribution because we adopt randomized decomposition. For example, if n′ = 5.5, it means the minisamples are a mixture of the ones with the size 5 and the ones with the size 6, and the mean of the size distribution is 5.5. In the figure, the curves are based on n′ = 1.5, 2.5, 3.5, 5.5, 10.5, 15.5, 20.5.\nAs we can see, although the experiments are based on very different models (probabilistic or nonprobabilistic), with diversified feature types (boolean or real-value) and different structure complexity n, the results are quite consistent. It demonstrates that structure regularization leads to higher accuracies/F-scores compared with the existing baselines.\nWe also conduct significance tests based on t-test. Since the t-test for F-score based tasks (BioNER and Word-Seg) may be unreliable11, we only perform t-test for the accuracy-based tasks, i.e., POS-Tagging and Act-Recog. For POS-Tagging, the significance test suggests that the superiority\n11Indeed we can convert F-scores to accuracy scores for t-test, but in many cases this conversion is unreliable. For example, very different F-scores may correspond to similar accuracy scores.\nof StructReg over WeightReg is very statistically significant, with p < 0.01. For Act-Recog, the significance tests suggest that both the StructReg vs. WeightReg difference and the StructReg vs. WeightAvg difference are extremely statistically significant, with p < 0.0001 in both cases. The experimental results support our theoretical analysis that structure regularization can further reduce the generalization risk over existing weight regularization techniques.\nOur method actually outperforms the benchmark systems on the three important natural language processing tasks. The POS-Tagging task is a highly competitive task, with many methods proposed, and the best report (without using extra resources) until now is achieved by using a bidirectional learning model in [20],12 with the accuracy 97.33%. Our simple method achieves better accuracy compared with all of those state-of-the-art systems. Furthermore, our method achieves as good scores as the benchmark systems on the Bio-NER and Word-Seg tasks, which are also very competitive tasks in natural language processing communities. On the Bio-NER task, [25] achieves 72.28% based on lookahead learning and [28] achieves 72.65% based on reranking. On the Word-Seg task, [7] achieves 97.19% based on maximum entropy classification and our recent work [22] achieves 97.5% based on feature-frequency-adaptive online learning. The comparisons are summarized in Table 1. Note that, similar to the tuning on the WeightReg strengths, the optimal values of StructReg strengths are also decided automatically based on standard development data or cross validation on training data.\nFigure 3 shows experimental comparisons in terms of wall-clock training time. As we can see, the proposed method can substantially improve the training speed. The speedup is not only from the faster convergence rates, but also from the faster processing time on the structures, because it is more efficient to process the decomposed samples with simple structures."
    }, {
      "heading" : "4 Proofs",
      "text" : "Our analysis sometimes need to use McDiarmid’s inequality.\nTheorem 14 (McDiarmid, 1989) Let S = {q1, . . . , qm} be independent random variables taking values in the space Qm. Moreover, let g : Qm 7→ R be a function of S that satisfies ∀i, ∀S ∈ Qm, ∀q̂i ∈ Q,\n|g(S)− g(Si)| ≤ ci.\n12See a collection of the systems at http://aclweb.org/aclwiki/index.php?title=POS_Tagging_(State_of_the_art)\nThen ∀ǫ > 0, PS [g(S)− ES [g(S)] ≥ ǫ] ≤ exp ( −2ǫ2 ∑m\ni=1 c 2 i\n)\n.\nLemma 15 (Symmetric learning) For any symmetric (i.e., order-free) learning algorithm G, ∀i ∈ {1, . . . ,m}, we have\nES [R(GS)−Re(GS)] = 1\nn ES,ẑi [L(GS , ẑ i)− L(GSi , ẑ i)]"
    }, {
      "heading" : "Proof",
      "text" : "ES [R(GS)−Re(GS)] = 1\nn ES\n(\nEz(L(GS , z))− 1\nm\nm∑\nj=1\nL(GS , zj) )\n= 1\nn\n(\nES,ẑi ( L(GS , ẑ i) ) − 1\nm\nm∑\nj=1\nES ( L(GS , zj)\n))\n= 1\nn\n(\nES,ẑi ( L(GS , ẑ i) ) − ES ( L(GS , z i)\n))\n= 1\nn\n(\nES,ẑi ( L(GS , ẑ i) ) − ESi ( L(GSi , ẑ i)\n))\n= 1\nn ES,ẑi\n( L(GS , ẑ i)− L(GSi , ẑ i) )\nwhere the 3rd step is based on ESL(GS , z i) = ESL(GS , zj) for ∀z i ∈ S and ∀zj ∈ S, given that G is symmetric. ⊓⊔"
    }, {
      "heading" : "4.1 Proofs",
      "text" : ""
    }, {
      "heading" : "Proof of Lemma 6",
      "text" : "According to (1), we have ∀i, ∀S, ∀z, ∀k |ℓτ (GS , z, k)− ℓτ (GS\\i , z , k)| = |cτ [GS(x, k), y(k)]− cτ [GS\\i(x, k), y(k)]|\n≤ τ |GS(x, k)−GS\\i(x, k)| ≤ τ∆\nThis gives the bound of loss stability.\nAlso, we have ∀i, ∀S, ∀z\n|Lτ (GS , z)− Lτ (GS\\i , z)| = ∣ ∣ ∣ n∑\nk=1\ncτ [GS(x, k), y(k)]− n∑\nk=1\ncτ [GS\\i(x, k), y(k)] ∣ ∣ ∣\n≤ n∑\nk=1\n∣ ∣ ∣cτ [GS(x, k), y(k)]− cτ [GS\\i(x, k), y(k)] ∣ ∣ ∣\n≤ τ n∑\nk=1\n|GS(x, k)−GS\\i(x, k)|\n≤ nτ∆ This derives the bound of sample loss stability. ⊓⊔"
    }, {
      "heading" : "Proof of Theorem 7",
      "text" : "When a convex and differentiable function g has a minimum f in space F , its Bregman divergence has the following property for ∀f ′ ∈ F :\ndg(f ′, f) = g(f ′)− g(f)\nWith this property, we have\ndRα,λ(f \\i′ , f) + d\nR \\i′\nα,λ\n(f, f\\i ′ ) = Rα,λ(f \\i′)−Rα,λ(f) +R\\i ′ α,λ(f)−R \\i′ α,λ(f \\i′)\n= ( Rα,λ(f \\i′)−R\\i ′ α,λ(f \\i′) ) − ( Rα,λ(f)−R\\i ′ α,λ(f) )\n= 1 mn Lτ (f\\i ′ , z ′i′)− 1 mn Lτ (f,z ′i′)\n(27)\nThen, based on the property of Bregman divergence that dg+g′ = dg + dg′ , we have\ndNλ(f, f \\i′) + dNλ(f \\i′ , f) = d (R \\i′\nα,λ −R\\i′α )\n(f, f\\i ′ ) + d(Rα,λ−Rα)(f \\i′ , f)\n= dRα,λ(f \\i′ , f) + d\nR \\i′\nα,λ\n(f, f\\i ′ )− dRα(f\\i ′ , f)− d R \\i′ α (f, f\\i ′ )\n(based on non-negativity of Bregman divergence)\n≤ dRα,λ(f\\i ′\n, f) + d R \\i′\nα,λ\n(f, f\\i ′ )\n(using (27))\n= 1\nmn\n( Lτ (f\\i ′ , z ′i′)− Lτ (f,z ′i′) )\n= 1\nmn\nn/α ∑\nk=1\n( ℓτ (f \\i′ , z ′i′ , k)− ℓτ (f,z ′i′ , k) )\n≤ 1 mn\nn/α ∑\nk=1\n∣ ∣ ∣cτ ( f\\i ′ (x′i′ , k), y ′ i′(k) ) − cτ ( f(x′i′ , k), y ′ i′(k) )∣ ∣ ∣\n≤ τ mn\nn/α ∑\nk=1\n∣ ∣ ∣f\\i ′ (x′i′ , k)− f(x′i′ , k) ∣ ∣ ∣\n(using (2))\n≤ ρτ mα ||f − f\\i′ ||2 · ||x′i′ ||2\n(28)\nMoreover, Nλ(g) = λ2 ||g||22 = λ2 〈g, g〉 is a convex function and its Bregman divergence satisfies:\ndNλ(g, g ′) =\nλ\n2\n( 〈g, g〉 − 〈g′, g′〉 − 〈2g′, g − g′〉 )\n= λ\n2 ||g − g′||22\n(29)\nCombining (28) and (29) gives\nλ||f − f\\i′ ||22 ≤ ρτ mα ||f − f\\i′ ||2 · ||x′i′ ||2 (30)\nwhich further gives\n||f − f\\i′ ||2 ≤ ρτ mλα ||x′i′ ||2 (31)\nGiven ρ-admissibility, we derive the bound of function stability ∆(f) based on sample z with size n. We have ∀z = (x,y), ∀k,\n|f(x, k)− f\\i′(x, k)| ≤ ρ||f − f\\i′ ||2 · ||x||2 (using (31))\n≤ τρ 2\nmλα ||x′i′ ||2 · ||x||2\n(32)\nWith the feature dimension d and x(k,q) ≤ v for q ∈ {1, . . . , d} , we have\n||x||2 = || n∑\nk=1\nx(k)||2\n≤ ||〈nv, . . . , nv ︸ ︷︷ ︸\nd\n〉||2\n= √ dn2v2 = nv √ d\n(33)\nSimilarly, we have ||x′i′ ||2 ≤ nv √ d α because x ′ i′ is with the size n/α. Inserting the bounds of ||x||2 and ||x′i′ ||2 into (32), it goes to\n|f(x, k)− f\\i′(x, k)| ≤ dτρ 2v2n2\nmλα2 (34)\nwhich gives (10). Further, using Lemma 6 derives the loss stability bound of dτ 2ρ2v2n2\nmλα2 , and the\nsample loss stability bound of dτ 2ρ2v2n3 mλα2 on the minimizer f . ⊓⊔"
    }, {
      "heading" : "Proof of Corollary 8",
      "text" : "The proof is similar to the proof of Theorem 7. First, we have\ndRα,λ(f \\i, f) + d\nR \\i α,λ\n(f, f\\i) = Rα,λ(f \\i)−Rα,λ(f) +R\\iα,λ(f)−R \\i α,λ(f \\i)\n= ( Rα,λ(f \\i)−R\\iα,λ(f\\i) ) − ( Rα,λ(f)−R\\iα,λ(f) )\n= 1\nmn\nα∑\nj=1\nLτ (f\\i, z(i,j))− 1\nmn\nα∑\nj=1\nLτ (f,z(i,j)) (35)\nThen, we have\ndNλ(f, f \\i) + dNλ(f \\i, f) = d (R\n\\i α,λ −R\\iα )(f, f \\i) + d(Rα,λ−Rα)(f \\i, f)\n= dRα,λ(f \\i, f) + d\nR \\i α,λ (f, f\\i)− dRα(f\\i, f)− dR\\iα (f, f \\i)\n(based on non-negativity of Bregman divergence)\n≤ dRα,λ(f\\i, f) + dR\\i α,λ (f, f\\i)\n(using (35))\n= 1\nmn\nα∑\nj=1\nLτ (f\\i, z(i,j))− 1\nmn\nα∑\nj=1\nLτ (f,z(i,j))\n= 1\nmn\nα∑\nj=1\n( n/α ∑\nk=1\nℓτ (f \\i, z(i,j), k)−\nn/α ∑\nk=1\nℓτ (f,z(i,j), k)\n)\n≤ 1 mn\nα∑\nj=1\nn/α ∑\nk=1\n∣ ∣ ∣ℓτ (f \\i, z(i,j), k)− ℓτ (f,z (i,j), k) ∣ ∣ ∣\n≤ τ mn\nα∑\nj=1\nn/α ∑\nk=1\n∣ ∣ ∣f\\i(x(i,j), k)− f(x(i,j), k) ∣ ∣ ∣\n(using (2), and define ||x(i,max)||2 = max∀j ||x(i,j)||)2)\n≤ ρτ m ||f − f\\i||2 · ||x(i,max)||2\n(36)\nThis gives\nλ||f − f\\i||22 ≤ ρτ m ||f − f\\i||2 · ||x(i,max)||2 (37)\nand thus ||f − f\\i||2 ≤ ρτ\nmλ ||x(i,max)||2 (38)\nThen, we derive the bound of function stability ∆(f) based on sample z with size n, and based on \\i rather than \\i′. We have ∀z = (x,y), ∀k,\n|f(x, k)− f\\i(x, k)| ≤ ρ||f − f\\i||2 · ||x||2 (using (38))\n≤ τρ 2\nmλ ||x(i,max)||2 · ||x||2\n≤ τρ 2 mλ · nv\n√ d\nα · nv\n√ d\n= dτρ2v2n2\nmλα (using (10))\n= α sup(∆)\n(39)\n⊓⊔"
    }, {
      "heading" : "Proof of Theorem 9",
      "text" : "Let f\\i ′ and f\\i be defined like before. Similar to the definition of f\\i ′\nbased on removing a minisample from S′, we define f i ′\nbased on replacing a mini-sample from S′. Similar to the definition of f\\i based on removing a sample from S, we define f i based on replacing a sample from S. Let R(f)\\i ′ denote [R(f)]\\i ′ = R\\i ′ (f\\i ′ ).\nFirst, we derive a bound for |R(f)−R\\i′(f)|:\n|R(f)−R(f)\\i′ | = 1 n |EzLτ (f,z)− EzLτ (f\\i ′ , z)|\n= 1\nn |Ez\nn∑\nk=1\nℓτ (f,z, k)− Ez n∑\nk=1\nℓτ (f \\i′ , z , k)|\n≤ 1 n Ez |\nn∑\nk=1\nℓτ (f,z, k)− n∑\nk=1\nℓτ (f \\i′ , z, k)|\n≤ 1 n Ez\nn∑\nk=1\n|ℓτ (f,z, k)− ℓτ (f\\i ′ , z , k)|\n(based on Lemma 6)\n≤ τ∆\n(40)\nThen, we derive a bound for |R(f)−R(f)i′ |:\n|R(f)−R(f)i′ | = |R(f)−R(f)\\i′ +R(f)\\i′ −R(f)i′ | ≤ |R(f)−R(f)\\i′ |+ |R(f)\\i′ −R(f)i′ |\n(based on (40))\n≤ τ∆+ τ∆ = 2τ∆\nMoreover, we derive a bound for |Re(f) − Re(f)i ′ |. Note that, i′ means replacing a mini-sample according to the training setting with decomposition, and the calculation of Re(f) and Re(f)i ′ is\nbased on full-size samples according to the test setting without decomposition. Let ẑ ′i denote the full-size sample (with size n and indexed by i) which contains the mini-sample ẑ ′i′ (with size n/α and indexed by i′), it goes to:\n|Re(f)−Re(f)i ′ | = ∣ ∣ ∣ 1\nmn\nm∑\nj=1\nLτ (f,z j)− 1\nmn\n∑ j 6=i Lτ (f i ′ , zj)− 1 mn Lτ (f i ′ , ẑ ′i) ∣ ∣ ∣\n≤ 1 mn\n∑ j 6=i |Lτ (f,z j)− Lτ (f i ′ , zj)|+ 1 mn |Lτ (f,z i)− Lτ (f i ′ , ẑ ′i)|\n≤ 1 mn\n∑ j 6=i |Lτ (f,z j)− Lτ (f i ′ , zj)|+ 1 mn\nn∑\nk=1\n|ℓτ (f,z i, k)− ℓτ (f i ′ , ẑ ′i, k)|\n(based on 0 ≤ ℓτ (GS , z, k) ≤ γ)\n≤ 1 mn\n∑ j 6=i |Lτ (f,z j)− Lτ (f i ′ , zj)|+ γ m\n≤ 1 mn\n∑\nj 6=i\n(\n|Lτ (f,zj)− Lτ (f\\i ′ , zj)|+ |Lτ (f\\i ′ , z j)− Lτ (f i ′ , zj)| ) + γ\nm\n(based on Lemma 6, and ∆(f i ′ , f\\i ′ ) = ∆(f, f\\i ′ ) from the definition of stability)\n≤ 1 mn\n∑\nj 6=i\n( nτ∆+ nτ∆ ) + γ\nm\n= 2(m− 1)τ∆+ γ\nm\n(41)"
    }, {
      "heading" : "Based on the bounds of |R(f)−R(f)i′ | and |Re(f)−Re(f)i",
      "text" : "′ |, we show that R(f)−Re(f) satisfies the conditions of McDiarmid Inequality (Theorem 14) with ci′ = (4m−2)τ∆+γ\nm :\n|[R(f)−Re(f)]− [R(f)−Re(f)]i ′ | = |[R(f)−R(f)i′ ]− [Re(f)−Re(f)i ′ ]| ≤ |R(f)−R(f)i′ |+ |Re(f)− Re(f)i ′ |\n≤ 2τ∆+ 2(m− 1)τ∆+ γ m = (4m− 2)τ∆+ γ\nm\n(42)\nAlso, following the proof of Lemma 15, we can get a bound for ES [R(f)−Re(f)]:\nES [R(f)−Re(f)] = 1\nn ES\n(\nEz (L(f,z))− 1\nm\nm∑\nj=1\nL(f,z j) )\n= 1\nn\n(\nES,ẑi ( L(f, ẑ i) ) − 1\nm\nm∑\nj=1\nES ( L(f,zj)\n))\n= 1\nn\n(\nES,ẑi ( L(f, ẑ i) ) − ES ( L(f,z i)\n))\n= 1\nn\n(\nES,ẑi ( L(f, ẑ i) ) − ESi ( L(f i, ẑ i)\n))\n= 1\nn ES,ẑi\n( L(f, ẑ i)− L(f i, ẑ i) )\n≤ 1 n ES,ẑi |L(f, ẑ i)− L(f i, ẑ i)| ≤ 1 n ES,ẑi |L(f, ẑ i)− L(f\\i, ẑ i)|+ 1 n ES,ẑi |L(f\\i, ẑ i)− L(f i, ẑ i)|\n(based on Lemma 6 and the ∆̄ defined in (12))\n≤ τ∆̄ + τ∆̄ = 2τ∆̄\n(43)\nNow, we can apply McDiarmid Inequality (Theorem 14):\nPS\n( [R(f)−Re(f)]− ES [R(f)−Re(f)] ≥ ǫ ) ≤ exp ( −2ǫ2 ∑mα\ni′=1 c 2 i′\n)\n(44)\nBased on (42) and (43), it goes to\nPS\n( R(f)−Re(f) ≥ 2τ∆̄ + ǫ ) ≤ exp (\n−2mǫ2\nα ( (4m− 2)τ∆+ γ )2\n)\n(45)\nLet δ = exp (\n−2mǫ2\nα ( (4m−2)τ∆+γ ) 2\n)\n, we have\nǫ = ( (4m− 2)τ∆+ γ ) √ α ln δ−1\n2m (46)\nBased on (45) and (46), there is a probability no more than δ such that\nR(f)−Re(f) ≥ 2τ∆̄ + ǫ\n= 2τ∆̄ + ( (4m− 2)τ∆+ γ ) √ α ln δ−1\n2m\n(47)\nThen, there is a probability at least 1− δ such that\nR(f) ≤ Re(f) + 2τ∆̄ + ( (4m− 2)τ∆+ γ ) √ α ln δ−1\n2m\nwhich gives (13). ⊓⊔"
    }, {
      "heading" : "Proof of Proposition 13",
      "text" : "By subtractingw∗ from both sides and taking norms for (21), we have\n||wt+1 −w∗||2 = ||wt − η∇gzt(wt)−w∗||2\n= ||wt −w∗||2 − 2η(wt −w∗)T∇gzt(wt) + η2||∇gzt(wt)||2 (48)\nTaking expectations and let at = ||wt −w∗||2, we have at+1 = at − 2ηE[(wt −w∗)T∇gzt(wt)] + η2E[||∇gzt(wt)||2]\n(based on (24) )\n≤ at − 2ηE[(wt −w∗)T∇gzt(wt)] + η2κ2|zt|2 (Recall zt is of the size n/α based on the definition of structure regularization )\n= at − 2ηE[(wt −w∗)T∇gzt(wt)] + η2κ2n2\nα2\n(since the random drawing of zt is independent of wt)\n= at − 2ηE[(wt −w∗)TEzt(∇gzt(wt))] + η2κ2n2\nα2\n= at − 2ηE[(wt −w∗)T∇g(wt)] + η2κ2n2\nα2\n(49)\nBy setting w′ = w∗ in (22), we have\n(w −w∗)T∇g(w) ≥ g(w)− g(w∗) + c 2 ||w −w∗||2\n≥ c 2 ||w −w∗||2\n(50)\nCombining (49) and (50), we have\nat+1 ≤ at − ηc||wt −w∗||2 + η2κ2n2\nα2\n= (1− cη)at + η2κ2n2\nα2\n(51)\nWe can find the steady state a∞ as follows\na∞ = (1− cη)a∞ + η2κ2n2\nα2 (52)\nwhich gives\na∞ = ηκ2n2\ncα2 (53)\nDefining the function A(x) = (1− cη)x + η2κ2n2α2 , based on (51) we have at+1 ≤ A(at)\n(Taylor expansion of A(·) based on a∞, with ∇2A(·) being 0) = A(a∞) +∇A(a∞)(at − a∞) = A(a∞) + (1 − cη)(at − a∞) = a∞ + (1 − cη)(at − a∞)\n(54)\nUnwrapping (54) goes to at <= (1− cη)t(a0 − a∞) + a∞ (55)\nSince ∇g(w) is Lipschitz according to (23), we have\ng(w) ≤ g(w′) +∇g(w ′)T (w −w ′) + q 2 ||w −w′||2\nSetting w ′ = w∗, it goes to g(w)− g(w∗) ≤ q2 ||w −w∗||2, such that\nE[g(wt)− g(w∗)] ≤ q 2 ||wt −w∗||2 = q 2 at\nIn order to have E[g(wt)− g(w∗)] ≤ ǫ, it is required that q2at ≤ ǫ, that is\nat ≤ 2ǫ\nq (56)\nCombining (55) and (56), it is required that\n(1− cη)t(a0 − a∞) + a∞ ≤ 2ǫ\nq (57)\nTo meet this requirement, it is sufficient to set the learning rate η such that both terms on the left side are less than ǫq . For the requirement of the second term a∞ ≤ ǫq , recalling (53), it goes to\nη ≤ cǫα 2\nqκ2n2\nThus, introducing a real value β ∈ (0, 1], we can set η as\nη = cǫβα2\nqκ2n2 (58)\nOn the other hand, for the requirement of the first term (1 − cη)t(a0 − a∞) ≤ ǫq , it goes to\nt ≥ log ǫqa0\nlog (1− cη) (since log (1− cη) ≤ −cη given (25))\n≥ log (qa0/ǫ) cη\n(59)\nCombining (58) and (59), it goes to\nt ≥ qκ 2n2 log (qa0/ǫ)\nǫβc2α2\nwhich completes the proof. ⊓⊔"
    }, {
      "heading" : "5 Conclusions",
      "text" : "We proposed a structure regularization framework, which decomposes training samples into minisamples with simpler structures, deriving a trained model with regularized structural complexity. Our theoretical analysis showed that this method can effectively reduce the generalization risk, and can also accelerate the convergence speed in training. The proposed method does not change the convexity of the objective function, and can be used together with any existing weight regularization methods. Note that, the proposed method and the theoretical results can fit general structures including linear chains, trees, and graphs. Experimental results demonstrated that our method achieved better results than state-of-the-art systems on several highly-competitive tasks, and at the same time with substantially faster training speed."
    }, {
      "heading" : "Acknowledgments",
      "text" : "This work was supported in part by NSFC (No.61300063)."
    } ],
    "references" : [ {
      "title" : "A spectral regularization framework for multi-task structure learning",
      "author" : [ "A. Argyriou", "C.A. Micchelli", "M. Pontil", "Y. Ying" ],
      "venue" : "In Proceedings of NIPS’07",
      "citeRegEx" : "1",
      "shortCiteRegEx" : "1",
      "year" : 2007
    }, {
      "title" : "Structured sparsity through convex optimization",
      "author" : [ "F. Bach", "R. Jenatton", "J. Mairal", "G. Obozinski" ],
      "venue" : "CoRR, abs/1109.2397,",
      "citeRegEx" : "2",
      "shortCiteRegEx" : "2",
      "year" : 2011
    }, {
      "title" : "Online algorithms and stochastic approximations. Online Learning and Neural Networks. Saad, David",
      "author" : [ "L. Bottou" ],
      "venue" : null,
      "citeRegEx" : "3",
      "shortCiteRegEx" : "3",
      "year" : 1998
    }, {
      "title" : "Stability and generalization",
      "author" : [ "O. Bousquet", "A. Elisseeff" ],
      "venue" : "Journal of Machine Learning Research,",
      "citeRegEx" : "4",
      "shortCiteRegEx" : "4",
      "year" : 2002
    }, {
      "title" : "Discriminative training methods for hidden markov models: Theory and experiments with perceptron algorithms",
      "author" : [ "M. Collins" ],
      "venue" : "In Proceedings of EMNLP’02,",
      "citeRegEx" : "5",
      "shortCiteRegEx" : "5",
      "year" : 2002
    }, {
      "title" : "Boosting with structural sparsity",
      "author" : [ "J.C. Duchi", "Y. Singer" ],
      "venue" : "In ICML’09,",
      "citeRegEx" : "6",
      "shortCiteRegEx" : "6",
      "year" : 2009
    }, {
      "title" : "A comparative study of parameter estimation methods for statistical natural language processing",
      "author" : [ "J. Gao", "G. Andrew", "M. Johnson", "K. Toutanova" ],
      "venue" : "In Proceedings of ACL’07,",
      "citeRegEx" : "7",
      "shortCiteRegEx" : "7",
      "year" : 2007
    }, {
      "title" : "Posterior vs parameter sparsity in latent variable models",
      "author" : [ "J. Graça", "K. Ganchev", "B. Taskar", "F. Pereira" ],
      "venue" : "In Proceedings of NIPS’09,",
      "citeRegEx" : "8",
      "shortCiteRegEx" : "8",
      "year" : 2009
    }, {
      "title" : "Learning with structured sparsity",
      "author" : [ "J. Huang", "T. Zhang", "D.N. Metaxas" ],
      "venue" : "Journal of Machine Learning Research,",
      "citeRegEx" : "9",
      "shortCiteRegEx" : "9",
      "year" : 2011
    }, {
      "title" : "Conditional random fields: Probabilistic models for segmenting and labeling sequence data",
      "author" : [ "J. Lafferty", "A. McCallum", "F. Pereira" ],
      "venue" : "In ICML’01,",
      "citeRegEx" : "10",
      "shortCiteRegEx" : "10",
      "year" : 2001
    }, {
      "title" : "Slow learners are fast",
      "author" : [ "J. Langford", "A.J. Smola", "M. Zinkevich" ],
      "venue" : "In NIPS’09,",
      "citeRegEx" : "11",
      "shortCiteRegEx" : "11",
      "year" : 2009
    }, {
      "title" : "Pac-bayes generalization bounds for randomized structured prediction",
      "author" : [ "B. London", "B. Huang", "B. Taskar", "L. Getoor" ],
      "venue" : "In NIPS Workshop on Perturbation, Optimization and Statistics,",
      "citeRegEx" : "12",
      "shortCiteRegEx" : "12",
      "year" : 2007
    }, {
      "title" : "Structured sparsity in structured prediction",
      "author" : [ "A.F.T. Martins", "N.A. Smith", "M.A.T. Figueiredo", "P.M.Q. Aguiar" ],
      "venue" : "In Proceedings of EMNLP’11,",
      "citeRegEx" : "13",
      "shortCiteRegEx" : "13",
      "year" : 2011
    }, {
      "title" : "A family of penalty functions for structured sparsity",
      "author" : [ "C.A. Micchelli", "J. Morales", "M. Pontil" ],
      "venue" : "In Proceedings of NIPS’10,",
      "citeRegEx" : "14",
      "shortCiteRegEx" : "14",
      "year" : 2010
    }, {
      "title" : "Hogwild: A lock-free approach to parallelizing stochastic gradient descent",
      "author" : [ "F. Niu", "B. Recht", "C. Re", "S.J. Wright" ],
      "venue" : "In NIPS’11,",
      "citeRegEx" : "15",
      "shortCiteRegEx" : "15",
      "year" : 2011
    }, {
      "title" : "Joint covariate selection and joint subspace selection for multiple classification problems",
      "author" : [ "G. Obozinski", "B. Taskar", "M.I. Jordan" ],
      "venue" : "Statistics and Computing,",
      "citeRegEx" : "16",
      "shortCiteRegEx" : "16",
      "year" : 2010
    }, {
      "title" : "An efficient projection for l1,infinity regularization",
      "author" : [ "A. Quattoni", "X. Carreras", "M. Collins", "T. Darrell" ],
      "venue" : "In Proceedings of ICML’09,",
      "citeRegEx" : "17",
      "shortCiteRegEx" : "17",
      "year" : 2009
    }, {
      "title" : "Convex structure learning in log-linear models: Beyond pairwise potentials",
      "author" : [ "M.W. Schmidt", "K.P. Murphy" ],
      "venue" : "In Proceedings of AISTATS’10,",
      "citeRegEx" : "18",
      "shortCiteRegEx" : "18",
      "year" : 2010
    }, {
      "title" : "Learnability and stability in the general learning setting",
      "author" : [ "S. Shalev-Shwartz", "O. Shamir", "N. Srebro", "K. Sridharan" ],
      "venue" : "In Proceedings of COLT’09,",
      "citeRegEx" : "19",
      "shortCiteRegEx" : "19",
      "year" : 2009
    }, {
      "title" : "Guided learning for bidirectional sequence classification",
      "author" : [ "L. Shen", "G. Satta", "A.K. Joshi" ],
      "venue" : "In Proceedings of ACL’07,",
      "citeRegEx" : "20",
      "shortCiteRegEx" : "20",
      "year" : 2007
    }, {
      "title" : "Large-scale personalized human activity recognition using online multitask learning",
      "author" : [ "X. Sun", "H. Kashima", "N. Ueda" ],
      "venue" : "IEEE Trans. Knowl. Data Eng.,",
      "citeRegEx" : "21",
      "shortCiteRegEx" : "21",
      "year" : 2013
    }, {
      "title" : "Feature-frequency-adaptive on-line training for fast and accurate natural language processing",
      "author" : [ "X. Sun", "W. Li", "H. Wang", "Q. Lu" ],
      "venue" : "Computational Linguistics,",
      "citeRegEx" : "22",
      "shortCiteRegEx" : "22",
      "year" : 2014
    }, {
      "title" : "Piecewise pseudolikelihood for efficient training of conditional random fields",
      "author" : [ "C.A. Sutton", "A. McCallum" ],
      "venue" : "In ICML’07,",
      "citeRegEx" : "23",
      "shortCiteRegEx" : "23",
      "year" : 2007
    }, {
      "title" : "Max-margin markov networks",
      "author" : [ "B. Taskar", "C. Guestrin", "D. Koller" ],
      "venue" : "In NIPS’03,",
      "citeRegEx" : "24",
      "shortCiteRegEx" : "24",
      "year" : 2003
    }, {
      "title" : "Learning with lookahead: Can history-based models rival globally optimized models",
      "author" : [ "Y. Tsuruoka", "Y. Miyao", "J. Kazama" ],
      "venue" : "In Conference on Computational Natural Language Learning,",
      "citeRegEx" : "25",
      "shortCiteRegEx" : "25",
      "year" : 2011
    }, {
      "title" : "Estimating the ”wrong” graphical model: Benefits in the computation-limited setting",
      "author" : [ "M.J. Wainwright" ],
      "venue" : "Journal of Machine Learning Research,",
      "citeRegEx" : "26",
      "shortCiteRegEx" : "26",
      "year" : 2006
    }, {
      "title" : "Structural regularized support vector machine: A framework for structural large margin classifier",
      "author" : [ "H. Xue", "S. Chen", "Q. Yang" ],
      "venue" : "IEEE Transactions on Neural Networks,",
      "citeRegEx" : "27",
      "shortCiteRegEx" : "27",
      "year" : 2011
    }, {
      "title" : "Reranking for biomedical named-entity recognition",
      "author" : [ "K. Yoshida", "J. Tsujii" ],
      "venue" : "In ACL Workshop on BioNLP,",
      "citeRegEx" : "28",
      "shortCiteRegEx" : "28",
      "year" : 2007
    }, {
      "title" : "Model selection and estimation in regression with grouped variables",
      "author" : [ "M. Yuan", "Y. Lin" ],
      "venue" : "Journal of the Royal Statistical Society, Series B,",
      "citeRegEx" : "29",
      "shortCiteRegEx" : "29",
      "year" : 2006
    } ],
    "referenceMentions" : [ {
      "referenceID" : 0,
      "context" : "For (typically non-structured) classification problems, there are considerable studies on structurerelated regularization, including spectral regularization for modeling feature structures in multi-task learning [1], regularizing feature structures for structural large margin classifiers [27], and many recent studies on structured sparsity.",
      "startOffset" : 212,
      "endOffset" : 215
    }, {
      "referenceID" : 26,
      "context" : "For (typically non-structured) classification problems, there are considerable studies on structurerelated regularization, including spectral regularization for modeling feature structures in multi-task learning [1], regularizing feature structures for structural large margin classifiers [27], and many recent studies on structured sparsity.",
      "startOffset" : 289,
      "endOffset" : 293
    }, {
      "referenceID" : 13,
      "context" : "Structure sparsity is studied for a variety of non-structured classification models [14, 6] and structured prediction scenarios [18, 13], via adopting mixed norm regularization [17], Group Lasso [29], posterior regularization [8], and a string of variations [2, 16, 9].",
      "startOffset" : 84,
      "endOffset" : 91
    }, {
      "referenceID" : 5,
      "context" : "Structure sparsity is studied for a variety of non-structured classification models [14, 6] and structured prediction scenarios [18, 13], via adopting mixed norm regularization [17], Group Lasso [29], posterior regularization [8], and a string of variations [2, 16, 9].",
      "startOffset" : 84,
      "endOffset" : 91
    }, {
      "referenceID" : 17,
      "context" : "Structure sparsity is studied for a variety of non-structured classification models [14, 6] and structured prediction scenarios [18, 13], via adopting mixed norm regularization [17], Group Lasso [29], posterior regularization [8], and a string of variations [2, 16, 9].",
      "startOffset" : 128,
      "endOffset" : 136
    }, {
      "referenceID" : 12,
      "context" : "Structure sparsity is studied for a variety of non-structured classification models [14, 6] and structured prediction scenarios [18, 13], via adopting mixed norm regularization [17], Group Lasso [29], posterior regularization [8], and a string of variations [2, 16, 9].",
      "startOffset" : 128,
      "endOffset" : 136
    }, {
      "referenceID" : 16,
      "context" : "Structure sparsity is studied for a variety of non-structured classification models [14, 6] and structured prediction scenarios [18, 13], via adopting mixed norm regularization [17], Group Lasso [29], posterior regularization [8], and a string of variations [2, 16, 9].",
      "startOffset" : 177,
      "endOffset" : 181
    }, {
      "referenceID" : 28,
      "context" : "Structure sparsity is studied for a variety of non-structured classification models [14, 6] and structured prediction scenarios [18, 13], via adopting mixed norm regularization [17], Group Lasso [29], posterior regularization [8], and a string of variations [2, 16, 9].",
      "startOffset" : 195,
      "endOffset" : 199
    }, {
      "referenceID" : 7,
      "context" : "Structure sparsity is studied for a variety of non-structured classification models [14, 6] and structured prediction scenarios [18, 13], via adopting mixed norm regularization [17], Group Lasso [29], posterior regularization [8], and a string of variations [2, 16, 9].",
      "startOffset" : 226,
      "endOffset" : 229
    }, {
      "referenceID" : 1,
      "context" : "Structure sparsity is studied for a variety of non-structured classification models [14, 6] and structured prediction scenarios [18, 13], via adopting mixed norm regularization [17], Group Lasso [29], posterior regularization [8], and a string of variations [2, 16, 9].",
      "startOffset" : 258,
      "endOffset" : 268
    }, {
      "referenceID" : 15,
      "context" : "Structure sparsity is studied for a variety of non-structured classification models [14, 6] and structured prediction scenarios [18, 13], via adopting mixed norm regularization [17], Group Lasso [29], posterior regularization [8], and a string of variations [2, 16, 9].",
      "startOffset" : 258,
      "endOffset" : 268
    }, {
      "referenceID" : 8,
      "context" : "Structure sparsity is studied for a variety of non-structured classification models [14, 6] and structured prediction scenarios [18, 13], via adopting mixed norm regularization [17], Group Lasso [29], posterior regularization [8], and a string of variations [2, 16, 9].",
      "startOffset" : 258,
      "endOffset" : 268
    }, {
      "referenceID" : 22,
      "context" : "[23] described an interesting heuristic piecewise training method for structured prediction models.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 24,
      "context" : "[25] described a “lookahead” learning method based on structured perceptrons.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 22,
      "context" : "Our work differs from [23] and [25] mainly because our work is built on a regularization framework, with arguments and theoretical justifications on reducing generalization risk and improving convergence rate.",
      "startOffset" : 22,
      "endOffset" : 26
    }, {
      "referenceID" : 24,
      "context" : "Our work differs from [23] and [25] mainly because our work is built on a regularization framework, with arguments and theoretical justifications on reducing generalization risk and improving convergence rate.",
      "startOffset" : 31,
      "endOffset" : 35
    }, {
      "referenceID" : 25,
      "context" : "[26] suggested consistent approximation for both training and test phase, but there is no indication on structure regularization.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 3,
      "context" : "On generalization risk analysis, related studies include [4, 19] on non-structured classification and [24, 12] on structured classification.",
      "startOffset" : 57,
      "endOffset" : 64
    }, {
      "referenceID" : 18,
      "context" : "On generalization risk analysis, related studies include [4, 19] on non-structured classification and [24, 12] on structured classification.",
      "startOffset" : 57,
      "endOffset" : 64
    }, {
      "referenceID" : 23,
      "context" : "On generalization risk analysis, related studies include [4, 19] on non-structured classification and [24, 12] on structured classification.",
      "startOffset" : 102,
      "endOffset" : 110
    }, {
      "referenceID" : 11,
      "context" : "On generalization risk analysis, related studies include [4, 19] on non-structured classification and [24, 12] on structured classification.",
      "startOffset" : 102,
      "endOffset" : 110
    }, {
      "referenceID" : 23,
      "context" : ", expected average loss) [24, 12]:",
      "startOffset" : 25,
      "endOffset" : 33
    }, {
      "referenceID" : 11,
      "context" : ", expected average loss) [24, 12]:",
      "startOffset" : 25,
      "endOffset" : 33
    }, {
      "referenceID" : 3,
      "context" : "We follow some notations and assumptions on non-structured classification [4, 19].",
      "startOffset" : 74,
      "endOffset" : 81
    }, {
      "referenceID" : 18,
      "context" : "We follow some notations and assumptions on non-structured classification [4, 19].",
      "startOffset" : 74,
      "endOffset" : 81
    }, {
      "referenceID" : 2,
      "context" : "Our analysis is based on the stochastic gradient descent (SGD) setting [3, 11, 15], which is arguably the most representative online training setting.",
      "startOffset" : 71,
      "endOffset" : 82
    }, {
      "referenceID" : 10,
      "context" : "Our analysis is based on the stochastic gradient descent (SGD) setting [3, 11, 15], which is arguably the most representative online training setting.",
      "startOffset" : 71,
      "endOffset" : 82
    }, {
      "referenceID" : 14,
      "context" : "Our analysis is based on the stochastic gradient descent (SGD) setting [3, 11, 15], which is arguably the most representative online training setting.",
      "startOffset" : 71,
      "endOffset" : 82
    }, {
      "referenceID" : 4,
      "context" : "We use the standard benchmark dataset in prior work [5], which is derived from PennTreeBank corpus and uses sections 0 to 18 of the Wall Street Journal (WSJ) for training (38,219 samples), and sections 22-24 for testing (5,462 samples).",
      "startOffset" : 52,
      "endOffset" : 55
    }, {
      "referenceID" : 24,
      "context" : "Following prior work [25], we use features based on unigrams and bigrams of neighboring words, and lexical patterns of the current word, with 393,741 raw features8 in total.",
      "startOffset" : 21,
      "endOffset" : 25
    }, {
      "referenceID" : 24,
      "context" : "Following prior work [25], we use word pattern features and POS features, with 403,192 raw features in total.",
      "startOffset" : 21,
      "endOffset" : 25
    }, {
      "referenceID" : 6,
      "context" : "Following prior work [7], we use features based on character unigrams and bigrams, with 1,985,720 raw features in total.",
      "startOffset" : 21,
      "endOffset" : 24
    }, {
      "referenceID" : 20,
      "context" : "This is a task based on real-valued sensor signals, with the data extracted from the Bao04 activity recognition dataset [21].",
      "startOffset" : 120,
      "endOffset" : 124
    }, {
      "referenceID" : 20,
      "context" : "Following prior work in activity recognition [21], we use acceleration features, mean features, standard deviation, energy, and correlation features, with 1228 raw features in total.",
      "startOffset" : 45,
      "endOffset" : 49
    }, {
      "referenceID" : 9,
      "context" : "We choose the conditional random fields (CRFs) [10] and structured perceptrons (Perc) [5], which are arguably the most popular probabilistic and non-probabilistic structured prediction models, respectively.",
      "startOffset" : 47,
      "endOffset" : 51
    }, {
      "referenceID" : 4,
      "context" : "We choose the conditional random fields (CRFs) [10] and structured perceptrons (Perc) [5], which are arguably the most popular probabilistic and non-probabilistic structured prediction models, respectively.",
      "startOffset" : 86,
      "endOffset" : 89
    }, {
      "referenceID" : 4,
      "context" : ", averaged perceptron [5].",
      "startOffset" : 22,
      "endOffset" : 25
    }, {
      "referenceID" : 21,
      "context" : "Since the rich edge features [22] can be automatically generated from raw features and are very useful for improving model accuracy, the rich edge features are employed for all methods.",
      "startOffset" : 29,
      "endOffset" : 33
    }, {
      "referenceID" : 12,
      "context" : "We also tested on sparsity emphasized regularization methods, including L1 regularization and Group Lasso regularization [13].",
      "startOffset" : 121,
      "endOffset" : 125
    }, {
      "referenceID" : 19,
      "context" : "33 (see [20]) 72.",
      "startOffset" : 8,
      "endOffset" : 12
    }, {
      "referenceID" : 24,
      "context" : "28 (see [25]) 97.",
      "startOffset" : 8,
      "endOffset" : 12
    }, {
      "referenceID" : 6,
      "context" : "19 (see [7]) Our results 97.",
      "startOffset" : 8,
      "endOffset" : 11
    }, {
      "referenceID" : 19,
      "context" : "The POS-Tagging task is a highly competitive task, with many methods proposed, and the best report (without using extra resources) until now is achieved by using a bidirectional learning model in [20],12 with the accuracy 97.",
      "startOffset" : 196,
      "endOffset" : 200
    }, {
      "referenceID" : 24,
      "context" : "On the Bio-NER task, [25] achieves 72.",
      "startOffset" : 21,
      "endOffset" : 25
    }, {
      "referenceID" : 27,
      "context" : "28% based on lookahead learning and [28] achieves 72.",
      "startOffset" : 36,
      "endOffset" : 40
    }, {
      "referenceID" : 6,
      "context" : "On the Word-Seg task, [7] achieves 97.",
      "startOffset" : 22,
      "endOffset" : 25
    }, {
      "referenceID" : 21,
      "context" : "19% based on maximum entropy classification and our recent work [22] achieves 97.",
      "startOffset" : 64,
      "endOffset" : 68
    } ],
    "year" : 2017,
    "abstractText" : "While there are many studies on weight regularization, the study on structure regularization is rare. Many existing systems on structured prediction focus on increasing the level of structural dependencies within the model. However, this trend could have been misdirected, because our study suggests that complex structures are actually harmful to generalization ability in structured prediction. To control structure-based overfitting, we propose a structure regularization framework via structure decomposition, which decomposes training samples into mini-samples with simpler structures, deriving a model with better generalization power. We show both theoretically and empirically that structure regularization can effectively control overfitting risk and lead to better accuracy. As a by-product, the proposed method can also substantially accelerate the training speed. The method and the theoretical results can apply to general graphical models with arbitrary structures. Experiments on well-known tasks demonstrate that our method can easily beat the benchmark systems on those highly-competitive tasks, achieving record-breaking accuracies yet with substantially faster training speed.",
    "creator" : "LaTeX with hyperref package"
  }
}