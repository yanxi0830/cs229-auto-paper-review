{
  "name" : "1402.1263.pdf",
  "metadata" : {
    "source" : "META",
    "title" : "Localized epidemic detection in networks with overwhelming noise",
    "authors" : [ "Eli A. Meirom", "Chris Milling", "Constantine Caramanis", "Shie Mannor", "Ariel Orda", "Sanjay Shakkottai" ],
    "emails" : [ ],
    "sections" : [ {
      "heading" : null,
      "text" : "These secondary data are often plagued by unreliability: many people with the flu do not stay home, and many people that stay home do not have the flu. This paper identifies the precise regime where knowledge of the contact network enables finding the needle in the haystack: we provide a distributed, efficient and robust algorithm that can correctly identify the existence of a spreading epidemic from highly unreliable local data. Our algorithm requires only local-neighbor knowledge of this graph, and in a broad array of settings that we describe, succeeds even when false negatives and false positives make up an overwhelming fraction of the data available. Our results show it succeeds in the presence of partial information about the contact network, and also when there is not a single “patient zero,” but rather many (hundreds, in our examples) of initial patient-zeroes, spread across the graph."
    }, {
      "heading" : "1 Introduction",
      "text" : "Any study, analysis or curbing of an epidemic begins with the fundamental question: is the phenomenon that we experience indeed an epidemic? The identification of such processes, be they malicious malware spreading on computer networks, memes on social networks, or trends in public opinion, is of major interest across several disciplines.\nar X\niv :1\n40 2.\n12 63\nv1 [\ncs .S\nA common characteristic is a stark absence of reliable information: patients with flu-like symptoms rarely visit a medical professional. More typical, however, is the availability of significant amounts of information indicating a secondary signature of the outbreak: flu patients may stay home from work, infected computers may exhibit somewhat encumbered performance, adopters of a new technological trend (e.g., smartwatch) may show new usage patterns, or may simply “self-report.” While more plentiful, such data may be riddled with false positives and negatives.\nFurther complicating the problem is the fact that the underlying network is rarely fully known and in practice it may be possible to recover only a very limited, local, subgraph near any infected node. In the setting of an epidemic, there may be multiple epidemic sources rather than a single “patient zero.” In the early phase of the HIV epidemic, this was precisely the nature of the data, since “patient zero” was unknown, and a “hidden backbone” connected the initially identified patients (Auerbach et al. (1984)).\nThis paper addresses the algorithmic and statistical challenges that this problem poses on large scale networks. We consider the basic robust graph-learning problem in the most dire information-restricted setting: at some instant in time we are informed that a given subset of nodes exhibiting unusual behaviour (in the computer setting) or are sick. Exact reporting times are unaccessible, and moreover we assume we are unable to observe the time evolution of the sickness reporting process. Given this single snapshot in time, the statistical inference problem is to determine if there is an epidemic, spreading in a diffusive process, which propagates through the network from one or possibly many initial nodes, or rather nodes have become infected via an independent, external mechanism.\nAlgorithmically, we seek an efficient, scalable algorithm with minimal computational and information requirements. In particular, we assume each node has some knowledge of its neighbourhood (our simulations show that this too need only be approximate).\nOften, the two processes of random infection and epidemic spread, exist in parallel. For example, a video may be posted by multiple members in a social network, and spread across the network by sharing; technology trends may be spread by mass-media advertisement, as well as word-of-mouth effects. We discuss this possibility explicitly, and we ask which proliferation mechanism dominates: are more people exposed to this media by their friends, or is it more common to watch it first through an external website.\nWe describe a class of algorithms for this decision making, or statistical hypothesis testing problem. Our algorithm requires only local information, and it is computationally efficient. Furthermore, the algorithm can be applied in a distributed fashion. Our theoretical results show that it works even when the fraction of false negatives and positives goes to 1 – i.e., even as an overwhelming majority of information we see is in fact false. Our simulation results corroborate this finding."
    }, {
      "heading" : "2 Problem definition, related work and our contribution",
      "text" : "In this section we describe the basic model we consider, review related work, and then explain our contributions."
    }, {
      "heading" : "2.1 The Basic Model",
      "text" : "The problem we consider is an extension of the scenario described in Milling et al. (2012, 2013). Consider a graph G = (V,E), where the number of nodes is N = |V |. The decision making task at hand is distinguishing between the two following alternative scenarios.\n• An epidemic: At time t = 0, an arbitrary subset of nodes is infected. The infection then spreads according to a standard suceptible-infectedmodel (Ganesh et al. (2005)). That is, infected nodes infect their neighbors according to an exponential clock set on each edge. We denote the set of infected nodes at time T as S = S(T ), and the infection size as |S| = α(N)N . At this time, each infected node reports it is infected with probability q(N). We denote the set of truly reporting nodes by Sr ⊆ S, and thus call S \\ Sr the false negatives. In addition, there are f |Sr| nodes, picked uniformly over the network, that also report infected. The intersection of these nodes with Sc, represent false positives. A reporting process illustration is presented in Fig 2.1.\n• Uniform reporting: Each node, independently of all others, reports an infection with some probability. The problem is most interesting when this probability is chosen so that the expected numbers of reporting nodes in each scenario match.\nThus in summary, the key parameters that define our setting are as follows: N is the total number of nodes; α(N) is the fraction of nodes ultimately infected, denoted by S; q(N) is the probability that a node in S will report, and hence (1 − q) is the false negative rate; f controls the fraction of false positives, which scale as f/(1 + f), and hence goes to 100% as f →∞.\nMany settings exhibit the above structure. Influenza and allergies are known to produce similar symptoms – without a professional diagnosis, these may often be confused, even more so when the only indication of either is absence from work or school. Influenza of course is the epidemic, whereas allergies affect near and distant neighbors independently. Technology adoption shares similar traits. Word of mouth advertising spreads like an epidemic, where as mass media advertisement affects customers independently.\nA sample reporting map of the two processes is displayed in Fig. 2.2. When the reporting probability increases, q(N) → 1, there exists a large connected component with a ball-like shape about the set of “patient-zero”s and the problem is easier. Likewise, the problem is more difficult when f(N) → ∞, as the truly reporting nodes are washed out by the sea of falsely reporting nodes. We describe a class of algorithms that is shown to converge correctly even in settings where q(N)→ 0 and f(N)→∞."
    }, {
      "heading" : "2.2 Prior Work",
      "text" : "The predictive (forward) analysis of our SI model, as in (Ganesh et al. (2005)), is tightly related to results in First Passage Percolation theory (Blair-Stahn (2010)). These and related works focus on modeling the epidemic spread characteristics, for example, estimating the infection rate for different topologies (e.g., Gopalan et al. (2011)), predicting the first time the infection exceeds a given boundary, and so on. These are, therefore, prediction problems, or forward problems: given the initial conditions, predict what happens in the future.\nOur work focuses on the inverse question: given (a noisy version of) what happened, solve the inference problem to decide if the process is an epidemic or a random illness. Recently, related inference questions have gained considerable attention. Of particular interest are estimating the model parameters, such as transmission rate, either by MCMC methods (Streftaris & Gibson), or a Bayesian approach (Demiris & O’neill). Another frequently discussed question is the identification of the epidemic source (e.g., Shah & Zaman; Karamchandani & Franceschetti (2013)).\nThe work that most closely relates to ours paper is Milling et al. (2012, 2013). They consider a similar model, and seek to solve the same problem. The key differences here are that the algorithm and analysis are completely different, with some important consequences. In those works, the authors rely on tools from first passage percolation, which in some settings (for some graph topologies, for initial infection conditions) may be fragile. For example, it is not clear if the algorithms given there are able to handle large numbers of initial seeds. Our results in Section 5 indicate that our algorithm is largely insensitive to the number of initial infections, and works well for even hundreds of spread out “patients zero.” A second important difference comes on the algorithmic front. Our algorithm is inherently local. As we describe below, it essentially counts nodes with many infected neighbors, at a high level bearing similarity to triangle-counting as a proxy for graph clustering (Watts & Strogatz (1998)). This allows our algorithm to be run in parallel, and most significantly, requires only local knowledge of the graph – something that may be critical in applications. In Section 5 we compare the performance of our new algorithm, and find that both on synthetic (e.g., Erdos-Renyi) graphs as well as real-world networks (e.g., part of the Facebook graph) our algorithm produces statistically much better results, and significantly less computational cost. As we explain below, our algorithm’s running time scales with the number of reporting infected nodes, which may be far smaller than the number of total nodes."
    }, {
      "heading" : "2.3 Our Contributions",
      "text" : "There are two factors which control the “difficulty” of the hypothesis testing problem we have posed. First, the more the false negatives (i.e., the smaller the set Sr), the more the epidemic statistically resembles the random illness. Second, in the limit when all infected nodes report, the presence (or absence) of a large connected component is easy to test, and sufficient to solve the decision problem. Finally, the topology of the graph itself plays an important role. The more connected the graph is, the more the two processes become statistically identical. In the limiting case where the contact network\nis the complete graph, the two processes are indistinguishable. From the algorithmic standpoint, there is a further regime of interest: the very small infection setting. It is interesting to understand in this setting, how well an algorithm using only minimal graph information, can perform.\nOur contributions are statistical and algorithmic, and address both regimes discussed above. Specifically, the key contributions of this work are as follows.\n• Algorithm: We provide a simple distributed algorithm that runs in time linear in the number of reporting infected nodes, can be easily parallelized, and requires minimal knowledge of the graph: each infected node is required to know only information about its local neighborhood.\n• Statistical Performance: We give sufficient conditions for our algorithm to correctly identify the infection cause (epidemic or random). In particular, we give conditions that guarantee that our algorithm succeeds even when the number of infected nodes is a O(N), i.e., a constant fraction of all the nodes. We also consider the small-infection regime. We show here that our algorithm succeeds even if each node only knows the graph up to its 1-hop neighbors.\n• Experiments: we provide experiments on synthetic (random) graphs, as well as real-world graphs. We show that our algorithm’s performance is at least as good as the theory predicts. Moreover, its efficiency allows it to scale easily to very large networks. We compare to state-of-the-art and demonstrate that our algorithm is both faster and more accurate."
    }, {
      "heading" : "3 The Algorithm: Hotspot Aggregator",
      "text" : "The intuition behind our algorithm is simple: in an epidemic, having sick neighbors is more common than in the case of a random illness.\nDefinition 1. For Bi(l) denoting the radius-l ball about node i, and NNi(K) denoting the set of the K nearest neighbors of node i, we define the following indicator random variables:\nHNNi (K, s) = { 1 |{v ∈ NNi(K) ∩ S}| ≥ s 0 otherwise\nand a similar indicator, HBi (l, s), for the radius-l ball. These indicators are true only if there are enough (more than s) reporting nodes in the immediate neighborhood of i. These are equivalent with appropriate correspondence of l and K, and so we use them interchangeably. If the indicator evaluates to 1, we call node i a hotspot. The above intuition suggests that there are more hotspots in an epidemic than in a random infection. Thus the number of hotspots, i.e., the sum of these indicators over reporting infected nodes, suggests a threshold test, that can correctly classify the infection cause. This is precisely the crux of Hotspot Aggregator Algorithm, Algorithm 1.\nTheoretical/Practical Implementation. The algorithm depends on the nearestneighbor threshold value K, and the parameter T . The theorems that make up our\nAlgorithm 1 The hotspot aggregator Input: Threshold values K, T. Output: An epidemic or a random reporting scenario\ncounter← 0 for i = 1 to Nreporting do\ncounter← counter +HNNi (K,K) end for if counter > T then\nreturn epidemic else\nreturn uniform reporting end if\nmain results in the next section, demand a careful choice for K and T that requires approximate knowledge of the false positive rate and the graph topology. As we detail in the appendix, for some topologies the values forK and T can be computed analytically. More generally, the optimal values can be computed through simulation. On the other hand, our experimental results in Section 5 suggest that the algorithm’s performance is quite stable. For instance, choosing K corresponding to the r-hop neighborhood in a graph, for r = 2, 3 yields uniformly good computational results (see Section 5 for more).\nAlgorithm Information and Complexity. The complete graph information (its global structure) requires O ( N2 )\nto encode. In contrast, our algorithm requires only the vector C, which contains the number of reporting nodes within each local environment. The length of C is the number of reporting nodes, denoted by Nreporting, where for many cases of interest, Nreporting can be as small as O(log(N)) or even lower. In addition to being a parsimonious representation of the information required by our algorithm, the vector C may be reconstructed by knowledge of only the local neighborhood of the reporting nodes, rather than the whole graph. As discussed above, such local information is often the only reasonably accessible/reliable information.\nThe algorithm’s complexity is o(Nreporting) and it scales with the number of reporting nodes (which, again, is typically vanishingly small compared to the to the number of nodes in the network). Similarly, the memory requirement is also very small and therefore this algorithm is easily scalable.\nAlgorithm Performance. As the noise increases, so does the difficulty of the decision problem . In the next section we discuss the convergence properties of the algorithm under extremely noisy conditions and present specific choices for the parameters T and K. We show that under relaxed topological constraints, the algorithm converges correctly even when the number of falsely reporting nodes is Θ(N), irrespective of the number of truly reporting nodes, which may be even ω(1). In an extreme scenario, where the number of false positives is Θ(N) greater than the truly reporting nodes number, Corollary 4 shows the local environment about every reporting nodes should contain Θ(logN) nodes. However, if the number of falsely reporting nodes is o(N), then it possible to apply the algorithm on a local environment which contains only a\nfinite number of nodes, as shown in Theorem 5."
    }, {
      "heading" : "4 Main Results: Correctness & Convergence",
      "text" : "Before we proceed, we require some preliminary definitions.The infection boundary is the set of infected nodes that have a non-infected node in their local neighborhood. An alternative definition for a boundary is a set of infected nodes for which at least one of the k nearest neighbors is not infected.\nDefinition 2. The lth order boundary ∂S(l) is a subset of infected nodes, ∂S(l) ⊆ S, such that for every i ∈ ∂S(l) we have Bi(l) ∩ Sc 6= ∅, i.e., there exists j /∈ S in the ball Bi(l). Alternatively, the kth order border set is a subset of infected nodes, DS(k) ⊆ S, such that for every i ∈ DS(k) we have NNi(k) ∩ Sc 6= ∅. We denote by γ(k) = 1 − |DS(k)| /|S| the fraction of interior nodes, i.e., nodes for which their local neighborhood is contained in the infected region.\nAs discussed in the introduction, this decision problem’s difficulty increases with the number of false positives and false negatives. The most challenging setting is when the number of false positives is Θ(N), regardless of the number of truly reporting nodes, which may be ω(1). We call this the dense regime. As shown in our first theorem, in this regime, if γ(K) is non zero for K = O(logN), the algorithm converges correctly. Alternatively, assume the number of truly reporting node is also Θ(N). If γ (K ∈ O(1)) is non zero then the algorithm converges as well.\nThe algorithm succeeds when the number of hotspots in the epidemic and random scenarios differ significantly. The hotspot indicator is a Bernoulli random variable, hence computing the expectation of their sum across reporting nodes is straightforward. However, these Bernoulli random variables are correlated, in proportion to their graph distance to each other. Thus the key technical portion of the proof involves controlling the variance of this sum, by appropriately harnessing large deviation results for sums of correlated random variables.\nTheorem 3. Assume the number of reporting nodes, whether truly reporting or falsely reporting, is Θ(N). Assume there exist values K, γ such that\na) Pr (γ(K) 6= 0)→ 1 for N →∞ b) K = ⌈ log(γ−1 (f + 1)) ⌉ . Then, the hotspot aggregator algorithm with parameters K and\nT = Nreporting\n2\n( γpKin\n(f + 1) + pK ) classifies correctly with high probability. The type I error and type II error decay rates are o (exp(−cNreporting)), where c is a constant that depends on the problem parameters.\nAs an immediate corollary of this result, we see that in the large-infection-regime, our algorithm succeeds even as the numbers of false negatives and positives are overwhelmingly greater than the number of truly infected reporting nodes. The proof follows immediately from the theorem, and the details are deferred to the appendix.\nCorollary 4. For a large infection with Θ(N) infected nodes (i.e., α = Θ(1) ), the algorithm converges correctly if conditions (a) and (b) above are satisfied, even when the reporting probability goes to zero and noise ratio goes to infinity, i.e., q ∈ ω ( N−1 ) and f ∈ ω ( q−1 ) .\nIn particular, if the number of truly reporting nodes is Θ(N), then the algorithm converges correctly if γ(K = const) > 0. Alternatively, the algorithm converges correctly for every network such that γ(K = 2 logN) > 0. This holds, for example, for grids and tree like networks, even if the noise is f ∈ Θ(N).\nProof. Denote the epidemic (uniform reporting) indicator as I (respectively, Ĩ ), the reporting probability of an infected node in the epidemic scenario by pin.and the node reporting probability in the uniform reporting scenario as p. In the uniform reporting scenario, the probability that a local hotspot indicator is true is\nPr (|{v ∈ NNi(k) ∩ Sreporting}| ≥ k) = pk.\nTherefore, the expected number of hotspots in the uniform reporting case ∑ i∈V Hi|Ĩ\nis\nE (∑ i∈V Hi|Ĩ ) = ∑ i∈V E ( Hi|Ĩ ) = Nreportingp k.\nIn the epidemic setting, the hotspot number is greater than the interior (non-boundary) hotspot number. Therefore,\nE (∑ i∈V Hi|I ) ≥ E  ∑ i∈S,i/∈DS Hi|I  ≥ γNreporting (f + 1) pkin\nwhere we used the fact that the expected number of truly reporting nodes isNreporting/ (f + 1) and applied Lemma 9 (stated in the appendix). Set T = Nreporting ( γpkin (f+1) + p k ) /2. Applying Lemma 6, choose\nK ≥ log(γ−1 (f + 1)) ≥ log(γ−1 (f + 1))p/pin. (4.1)\nNow the key step is to evaluate the error rates, despite the correlation. To do this, we use a Hoeffding-like large deviation theorem (see Corollary 2.6 in Janson (2004)) for graph-structured correlation decay patterns. We can form a dependence graph Γ among these Nreporting random variables, drawing an edge between any two non-independent random variables. Note, then, that for each two nodes, i and j, the hotspot indicators Hi and Hj are independent iff the corresponding environments Bi and Bj , or NNi and NNj are disjoint. The number of nodes in each local environment of the k nearest neighbors of i is also k, so the number of nodes with disjoint local environments is at least N − k2. In other words, the maximal node degree in Γ is k2.\nSet P = pK , Pin = γpkin/(f + 1). Then, adapting some concentration inequalities from Janson (2004), we can show that the type I error, EI := Pr (∑ i∈V Hi|Ĩ ≥ T )\nis bounded by\nEI ≤ exp ( −Nreporting\n(Pin − P )2\n16 (K2 + 1) (P + (Pin − P ) /6) ) In the epidemic scenario, the total number of hotspots is at least as great as the\nnumber of interior hotspots. Therefore, the type II error is bounded by\nEII = Pr (∑ i∈V Hi|I < T ) ≤ Pr  ∑ i∈S,i/∈DS Hi|I < T  and similarly, the latter quantity is bounded by\nexp ( −Nreporting (Pin − P )2\n16 (K2 + 1)Pin ) As shown in the appendix, these errors tend to zero under the conditions of this\ntheorem.\nApplying Theorem 3 and Corollary4. As with the algorithm, applying the theorem or corollary requires calculating values of γ(K) and K. As we show in the appendix, γ(K) can often be explicitly (analytically) computed, and if that is not available, it can be easily computed numerically. In the appendix, we also present explicit instructions on the application of the hotspot algorithm for general networks, including specific finite size networks for which the statistical ensemble is unknown. When γ(K) is known, one can simply find the minimal value of K such"
    }, {
      "heading" : "K ≥ log (γ(K)) + log (f + 1) ,",
      "text" : "and substitute the corresponding value in the threshold. For example, for d-dimensional grids one can choose K = dlog(f + 1)e and\nT = Nreporting\n2\n( pKin\n(f + 1) + pK\n) ,\nwhile for a tree like network, such as an Erdos-Renyi network, choose K such that K ≥ logK + dlog(f + 1)e and\nT = Nreporting\n2\n( pKin\nK (f + 1) + pK\n) .\nIf the function γ(K) is not known or if it difficult to describe analytically and solve for K, one can apply the bound γ(K) ≥ 1/αN in eq. 4.1 and obtain a corresponding value for the threshold T .\nAs long as the probability to find a node for which the local environment is contained in the infected region is non-zero, the algorithm converges correctly. This is a very lenient requirement, which only fails for nearly full-mesh graphs, such that with high probability, for every ball, either there are less than logN nodes, |Bi(l)| ≤ logN , or the number of nodes in the ball is infinitely higher than logN , logN/|Bi(l)| → 0 . Indeed, an alternative description for uniform reporting is a contagion on an underlining full mesh grid, and in this case the two processes are identical.\nSmall Infections We now consider the setting of very small infections, and prove that in these settings, one can take K to be a constant (K ∈ Θ(1)), and moreover can choose this constant so that even the presence of a single hotspot indicates an epidemic infection.\nTheorem 5. Assume the total number of reporting nodes, is N1−β , while the number of truthfully reporting nodes isNρ and the truly reporting probability is q(N) = N−µ. Set K = d1/βe−1 . If γ(K) ∈ ω ( log−1(N) ) , then the hotspot aggregator algorithm with parameters K and threshold T = 1 classifies correctly with high probability if Kµ ≤ ρ. In particular, if 1 > β > 0.5, than the hotspot algorithm with K = 1 classifies correctly under the same conditions.\nIn this last case, the algorithm simply counts the expected number of infected neighboring pairs.\nProof. For each two nodes, i and j, the hotspot indicators Hi and Hj are independent iff the corresponding environment Bi and Bj are disjoint, Bi∩Bj = ∅, otherwise they are positively correlated. In the uniform reporting scenario, define the probability that all the hotspot indicators are false as Pep , Pr (∀i ∈ Nreporting, Hi = 0). The probability for such event is bounded by:\nPep ≥ Nreporting−1∏\ni=0\nPr(Hi = 0, Hj = 0|Bi ∩Bj = ∅)\n= ( 1− pk )Nreporting .\nTherefore, as p→ 0 ,Nreporting →∞\nPr (∀i ∈ Nreporting, Hi = 0)→ exp ( −pkNreporting ) According to the central limit theorem,Nreporting = pN with high probability. By Ap-\nplying Lemma 9 and choosing k such that pk ∈ O(N−1), we have Pr ( ∀i ∈ Nreporting, Hi = 0|Ĩ ) →\n1. Similarly to Theorem 3, set Pin = pkin,N ′ reporting = γN reporting/(f+1). In the epidemic setting, we can again apply Corollary 2.6 in Janson (2004), but now with a deviation of t = N ′reportingP .\nThen, the type II error is bounded by\nEII ≤ exp ( − N ′reportingP ( 1− ( K2 + 1 ) /4N ) 2 (K2 + 1) ) .\nThe type II error tends to zero if N ′reportingP → ∞. The latter condition can also be written as qαγ ( qK + (αqf) K ) ∈ ω ( N−1 ) , while the condition for the type II correct\nconvergence is (αqf)K+1 ∈ O(N−1).\nIn particular, if Nreporting/N ∈ O(N−0.5), and q2α ∈ ω ( N−1 ) then it is sufficient to\nchoose K = 1, i.e., to count the number of infected nearest neighbors pairs. This result is particularly useful for small infections (for example, α ∈ Θ ( N−0.3 ) ). It shows that it is possible to detect epidemics using the hotspot aggregator algorithm even when the ratio of the number of false positives to the number of infected nodes tends to infinity (for example, f ∈ Θ ( N0.7 ) ), and the ratio of truly reporting nodes\nnumber to the number of infected nodes tends to infinity (for example, q ∈ Θ ( N−0.3 ) ), a quadratic “needle in a haystack” scenario. Finally, note that the requirement for the algorithm convergence is that the boundary would not contain all the nodes. Therefore, even if multiple sources of an epidemic exist, then as long as this condition is satisfied, the algorithm converges correctly. Put differently, the hotspots aggregator will converge correctly as long as there are sources that had the chance to infect their local environment, rather than infect a large portion of the network. Hence, this algorithm is able to identify and nip contagions in the bud.\nNext, we deploy this algorithm on both random network models, such as ErdosRenyi networks or scale-free networks, and real-world networks, such as an enterprise email network, the Internet AS topology and Facebook."
    }, {
      "heading" : "5 Experiments",
      "text" : "We perform empirical tests of our algorithm on both synthetic and real data. We focus on demonstrating its accuracy, running time and scalability in numerous settings. These simulations also demonstrate the ease-of-use of our algorithm in real experiments. While the theorems themselves require some care in choosing the parameters of the algorithm, here we find that 1, 2, and 3-hop local neighborhoods perform extremely well across a wide range of settings, including the setting of an overwhelming number of false positives, and the setting of up to 200 infection seeds (initial infected nodes).\nSynthetic Graphs. We consider the algorithm performance in the acute regime, where the number of false positives and false negatives each tends to infinity. We tested this (Fig. 5.1) on an Erdos-Renyi graph in the regime where the giant component emerges, G(N = 8000, p = 2/N ) (Durrett (2010)). The error rate decays rapidly as the size of the graph increases, as predicted by Theorem 5, even as the fraction of truly reporting nodes among the reporting nodes tends to zero. Moreover there are infinitely more false negatives than true positives, as the network size increases. We also compare against the Median-ball-algorithm given in Milling et al. (2013). While the Median algorithm may be converging, we see that the convergence of our algorithms for l = 1, 2, 3, 4 is remarkably faster.\nInterestingly, in this experiment, the l = 4 version of our algorithms seems to have a slightly worse performance compared to l = 1, 2. This is likely because the regime of G(N, p) we consider has diameter Θ (logN), and thus even 4-hop neighborhoods are considerable in size.\nIn real-world networks, the degree distribution often follows a power law. For random power law networks, the network diameter is, like in the G(N, p) , Θ(logN), or even Θ(log (logN)) (Cohen & Havlin (2003)). In such small-world networks, choos-\ning a large ball radius deteriorates inference performance due to an overflow of the local ball about an infected node to an uncontaminated region.\nReal World Graphs. We next consider a real world graph, namely, the enterprise email network of Enron employees (Klimt & Yang). In part, this is motivated by the fact that many computer viruses spread by email attachments. Figure 5.2 shows the setting of a small infection, with a very large fraction of false negatives, a large majority of false positives, and many initial sources of infection. Our results demonstrate the stability of our algorithm with respect to the number of initial infection seeds. Even with as many as 200 initial seeds, the performance of our algorithm is hardly affected. We note again a better performance for radius values r = 1, 2, 3 in our algorithm; this is for the same reason as discussed above.\nAdditional instances of diffusive processes are the sharing of viral media and the adoption of memes on social networks. We examined the identification of such phenomena by testing our algorithm on a network of 63K Facebook contacts (Viswanath et al. (2009)). Finally, cascades of router failures due to misconfiguration or BGP attacks is a major security concern. We have performed experiments on these graphs as well, but for space concerns defer these to the appendix.\nLast, we tested our algorithm in the presence of noisy network information, to test robustness to knowledge of local neighborhoods. Indeed, a person may erroneously estimate the distance to her peers, consequently resulting in an incorrect set of nearest neighbors, or the deformation of the ball centered about her. In our experiments, we account for the effect of noisy network information by allowing an expected fraction of the conceived inter-node distances to increase or decrease by d (when the unmodified distance is greater than d). Consequently, the inference algorithm is performed on a\ndifferent network than the one the epidemic evolved on. Note that such a modification is not symmetric, as one node may correctly estimate the distance to its peer, while its peer may not. The error rate of our inference algorithm is present in Fig. 5.3. The results here show that our algorithm is robust to such noisy network knowledge.\nIn an epidemic scenario, if a reporting node is deep in the infected region, there exists some buffer to the uninfected nodes at the contagion border, and the overestimation effect should be negligible. In contrast, if the reporting node’s exterior shell is close to the border, then the reporting node may mistake an uninfected node as a member of its local ball and performance may deteriorate. Therefore, we expect that the type II error should increase with the ball radius and the misestimation rate, expressed in either increased misestimation probability or the true distance deviation. These two effects are observed in Fig. 5.3. Finally, the type I error is unaffected by this type of topological noise."
    }, {
      "heading" : "6 Conclusions",
      "text" : "Our world becomes increasingly interconnected by multiple different networks. While this interconnection speeds information transfer and facilitates communication, is it also increases the likelihood of contagion outbreaks. Depending on the context, such outbreaks may be computer viruses, opinion trends, or epidemics such as malaria. The hair-trigger identification of these diffusive processes is crucial and one may be forced to rely on a single reporting map snapshot in time. Furthermore, a complete knowledge of the underlying network graph is generally unrealistic. We have provided both analytical proofs and experiments on real data, showing that the hotspot aggregator algorithm solve this statistical inference problem in its dire setting on a wide variety of\nnetwork and settings. We have shown that this algorithm classifies correctly even when the rate of false positives and false negatives is infinitely higher than the number of true positives, as well as in the presence of multiple sources of epidemics.\nWe have simulated this algorithm both on random networks, such as Erdos-Renyi graphs or scale-free graphs, and on real world networks, such as Facebook, the Internet AS-topology and Enron email chain. Our simulations exhibit the exponential decrease of the error rate with the size of the network, as predicted. In practice, the error rates are extremely low, even when there are errors in estimating the network structure. Finally, the complexity of our algorithm is low, and it is clearly scalable, as shown by the low error rate on the Facebook network of over 60K nodes."
    }, {
      "heading" : "A Appendix A - Additional lemmas",
      "text" : "Lemma 6. Denote the reporting probability of an infected node in the epidemic scenario by pin. Similarly, denote the node reporting probability in the uniform reporting scenario as p. Then, pin > p.\nProof. First, note that\npin = q + (1− q) fqα\n1− qα\n= q ( 1 + (1− q) fα\n1− qα ) while\np = (f + 1) qα\nTherefore,\npin − p > q + (1− q) fqα\n1− qα − (f + 1) qα\n= q\n1− qα (1− qα+ (1− q)fα− (f + 1)α (1− qα))\n= q 1− qα ( 1− qα− qfα+ fα− fα− α+ qα2 + fqα2 ) = q\n1− qα ((1− α) (1 + qα+ qfα)\n> 0\nas α > 0.\nLemma 7. The errors expressed in Theorem 3 tends to zero under the corresponding conditions.\nProof. Set P = pK , Pin = γpkin/(f+1). According to Corollary 2.6 in Janson (2004) the type I error rate can be bounded by\nEI ≤ exp −Nreporting (P − Pin)2 ( 1− (∆(Γ)+1)4Nreporting )\n8 (∆(Γ) + 1) (1− P ) (P + (Pin − P ) /6)  where ∆(Γ) is the maximal degree of the dependency graph Γ. However, ∆(Γ) ≤\nmax{Nreporting,K2} and therefore,\nEI ≤ exp ( −Nreporting\n(Pin − P )2\n16 (K2 + 1) (P + (Pin − P ) /6)\n) (A.1)\nSet δ = pin− p. First, note that if lim (P − Pin) 6= 0, then this expression tends to zero. Therefore, if lim δ 6= 0 for N →∞ than the type I error rate tends to zero.\nRecall that\npin ∈ Ω (q + fqα) δ ∈ Θ(q) p ∈ Θ (fqα)\nAnd therefore in this case q ∈ Ω(1). Otherwise, assume that lim δ = 0. If\nδ/p→ 0\nor equivalently, fα ∈ ω(1), the highly noise regime, then to first order in δ/p\n(Pin − P )2 → p2k (\n1− 1 γ(f + 1) )2 with δ = pin − p. Likewise, if δ/p→ const, than we can write\np = g(N)p̃\nδ = g(N)δ̃\nwhere p̃→ const 6= 0 and δ̃ → const 6= 0 and\n(P − Pin)2 = g2K(N)  ( p̃+ δ̃ )K γ(f + 1) − p̃K  2\nTherefore, for either K = 1 or K = 2 we have\nlim  ( p̃+ δ̃ )K γ(f + 1) − p̃K  2 6= 0\nand therefore (P − Pin)2 ∈ Θ(p2k) = Θ(δ2k). Recall that with high probability Nreporting = Np. As,\nEI ≤ exp ( −NΘ ( p2k+1 )) if\n(fqα) 2K+1 ∈ ω(N−1),\nthe type I error tend to 0 for N →∞. In other words, if K is such that\n(Nreporting/N) 2K+1 ∈ ω(N−1)\nthe error tend to 0. Alternatively, if p/δ → 0 then\n(Pin − P )2 → ( γδk\n(f + 1)\n)2\nand therefore, if γ2qK/f ∈ ω(N−0.5)\nthen the algorithm converges correctly. A similar calculation shows that if this condition holds, then the type II error tends\nto 0 for N →∞. Explicitly:\nEII ≤ exp −Nreporting (P − Pin)2 ( 1− (∆(Γ)+1)4Nreporting )\n8 (∆(Γ) + 1)P  and following similar reasoning\nEI ≤ exp ( −Nreporting (Pin − P )2\n16 (K2 + 1)Pin\n)\nand this expression has the same scaling properties as eq. A.1.\nCorollary 8. Consider a large infection, where the number of infected nodes is a constant fraction of the number of nodes, α = Θ(1) . The algorithm converge correctly even when the reporting probability tends to zero as q ∈ ω ( N−1 ) while the noise ratio\ntend to infinity f ∈ ω ( q−1 ) , as long as conditions a) and b) of theorem 3 are satisified.\nIn particular, if the number of truly reporting nodes is Θ(N), then the algorithm converges correctly if γ(K = const) > 0. Alternatively, the algorithm converges correctly for every network such that γ(K = 2 logN) > 0, for example, grids and tree like networks, even if the noise is f ∈ Θ(N).\nProof. Note that f < N . If γ 6= 0, then γ < 1/αN . In particular, if the number of truly reporting nodes is Θ(N), then f ∈ Θ(1).Therefore\nK ≥ − log(γ) + log(f)\nand substituting the corresponding values in Theorem 3 concludes the proof..\nLemma 9. Consider a binomial random variable X with expectation value pN for N →∞. Then any sum of Bernoulli random variables Yi obeys\nE ( X∑ 1 Yi ≥ c ) → E ( M∑ 1 Yi ≥ c )\nE ( X∑ 1 Yi ≤ c ) → E ( M∑ 1 Yi ≤ c )\nIn other words, we can asymptotically replace the summation over random number of RVs in the summation over the mean number or RVs.\nProof. Set M = Np− (Np)2/3. First, note that\nE ( X∑ 1 Y ≥ c ) = E ( X∑ 1 Y ≥ c|X > M ) Pr(X > M) + E ( X∑ 1 Y ≥ c|X ≤M ) Pr(X ≤M)\n≤ E ( X∑ 1 Y ≥ c|X > M ) Pr(X > M)\n≤ E ( X∑ 1 Y ≥ c|X = M ) Pr(X > M).\nAccording to Hoeffding’s inequality Pr(X ≤M) ≤ exp ( − (Np)1/3 ) .\nand therefore\nE ( X∑ 1 Y ≥ c ) ≤ E ( M∑ 1 Y ≥ c )( 1− exp ( − (Np)1/3 )) Similarly, we can apply Hoeffding’s inequality for M = Np− (Np)2/3 in\nE ( X∑ 1 Y ≤ c ) = E ( X∑ 1 Y ≤ c|X > M ′ ) Pr(X > M) + E ( M∑ 1 Y ≤ c|X ≤M ′ ) Pr(X ≤M)\n≤ E ( X∑ 1 Y ≥ c|X ≤M ′ ) Pr(X < M)\nwhile Pr(X ≥M ′) ≤ exp ( − (Np)1/3 ) and obtain\nE ( X∑ 1 Y ≤ c ) ≤ E M ′∑ 1 Y ≥ c (1− exp(− (Np)1/3)) but both M,M ′ → Np and this concludes the proof."
    }, {
      "heading" : "B Appendix B - Algorithm application",
      "text" : "In order to apply the algorithm, the parameters K and T must be specified, and the number of nodes in the local environment must be set. We assume that a good estimate for the reporting probability of an infected node, pin, is known. Note that for large networks the reporting probability p can be easily estimated according to p = Nreporting/N .\nRecall that γ(K) is the fraction of infected nodes for which their K nearest neighbor nodes are also infected is known.\nWe distinguish between two classes of networks. First we discuss large networks for which the function γ(K) is known, whether numerically or analytically. As an example, consider an infinite constant degree tree with degree d. Assume that the infection, starting from the root, has infected all the nodes up to the m-th level. In this case, for every node that is deeper than the m− l level of the tree, all the nearest dl are not infected. The fraction of such nodes is\nγ(K = dl) ≤ d m−l − 1 dm → d−l\nTherefore, γ(K) = K−1. As another example, consider a d dimensional grid. In this case, the contagion is with high probability contained within an l1 ball of radius r = c|S|1/d, with c→ const forN →∞ (Milling et al. (2012)). The number of nodes on the non-infected bordering nodes near the surface of such ball is Θ(rd−1). In addition a ball of radius l contains Θ(ld) nodes. Therefore, the number of interior nodes is at least Θ(rd−1ld). Hence,\nγ ( K ∈ Θ(ld) ) ≤ Θ ( r−1ld ) Hence for balls of radii K ∈ o ( |S|1/d ) = o ( (αN) 1/d ) we have\nγ(K)→ 1\nIn these cases, Theorem 3 provides a prescription for K and T when the number of reporting nodes is large, Θ(N), while if the number of reporting nodes is small, o(N), the prescription in Theorem 5 applies\nFor a finite size network, that is not necessarily sampled from a statistical ensemble, γ(K) might be not known apriori. Nevertheless,γ(K) may be calculated at a preprocessing stage. This can be done by simulating epidemics according to the scenario details. Then, for each infected node, calculate the probability that K of its neighboring nodes are infected, and average over all infected nodes. As an example, the γ(K) function for the Internet inter-AS topology, which is often considered a scale free network, is presented in Fig. B.1. Note that for any network, and any value of K, if there is an infected node that K of its nearest neighbors are infected, then γ(K) 6= 0. In this case, γ ≥ 1/|S|, where|S| is the infection size. The maximal relevant value of K is log(|S|), according to Theorem 3.\nAfter this preprocessing stage, if the number of reporting nodes is large one applies Theorem 3 , or Theorem 5 otherwise.\nFinally, it is important to note that one can perform multiple tests with various values of K. If no epidemic occurred, then in all those tests the number of hotspots should be close to the expected number of a uniform reporting event. If any tests results is far from this value, then an epidemic occurred. This approach is particularly relevant if the critical requirement is high specificity, and if no information on the possible epidemic is available. Note that as there are at most log(N) tests, applying multiple tests does increase the algorithm complexity appreciably."
    }, {
      "heading" : "C Appendix C - Additional experiments",
      "text" : "In this section we present additional simulations, some of which are described in the main body of this paper.\nFirst, we considered idenfitiability on an Erds-Renyi graph in the regime where the giant component emerges, G(N = 8000, p = 2/N ) (Durrett (2010)). We performed 2000 trials for each scenario (epidemic or uniform reporting) and evaluated the mean number of hotspots as a function of the threshold K for a ball of a given radius. The resulting graph for a ball of radius l = 3 is presented in Fig. C.1, including the corresponding standard deviations. The graph shows that, as our theory predicts, the number of hotspots is indeed a strong statistic for distinguishing between an epidemic and a random illness. This was followed, as described in the paper, by evaluating the algorithm performance in the acute regime, where the number of false positives and false negatives each tends to infinity (Fig. 5.1). In this figure, the infection size is O(N0.3) while the reporting probability is O(N−0.2). The ratio of false positives to true positives is O(N0.3). The mean error is the average of the type I and type II error probabilities, assuming equal likelihoods of an epidemic and a uniform reporting event. The plot was obtained by Monte Carlo simulations of 2000 trials for each scenario.\nWe have followed suit and applied the algorithm on real world networks. In Fig. C.2 the algorithm’s error rate on a subgraph of the Facebook network is presented. Even though the noise level is extremely high and the infection is tiny, the error rate is negligible. We have also simulated our algorithm on the Internet autonomous system (AS) network, in order to examine whether this algorithm is able to detect failure\ncascades of BGP routers (Fig. C.3). In both cases, as discussed in Section 5, the algorithm showed very good results, even for the large ball radius l = 4. These results were obtained in a challenging setting, under a highly noisy environment with multiple epidemic sources, where only a mere fraction of the nodes truly report. In both cases, the Median Ball algorithm’s error was close to 0.5, almost as high as a random classifier. While in principle this algorithm might be modified to include multiple seeds, this modification requires knowledge of seed number, which is rarely known. In addition, if the Median Ball algorithm are modified, the type I error increases appreciably.\nThe degree distribution of these networks closely resembles power law. In particular, the degree distribution of most of this networks is Axα with 3 > α > 2. We have tested our algorithm on random power law (Fig. C.4). As the number of reporting nodes increases, there are more positive classifiers in the uniform reporting scenario. In order to compensate for this effect, one needs to design a classifier for less frequent events. This is done by increasing the threshold K, which in turn increases the rarity of the event. Indeed, it is possible to achieve low error rates with small ball radii even in the presence of a large number of false positives.\nWhile it is often clearer to state the proofs by means of the border set, it is often simpler to implement the algorithm in terms of a local ball environment. Recall the definition of the radius-l ball ball indicator\nHBi (l, s) = { 1 |{v ∈ Bi(l) ∩ S}| ≥ s 0 otherwise .\nAs the number of nodes in a ball may vary, and due to finite size effects, the optimal\nthreshold value T may be different than the corresponding theoretical value. In practice, one may optimize this threshold value in an independent preprocessing step. In practice, values close to the theoretical predictions were found adequate in most cases."
    } ],
    "references" : [ {
      "title" : "Cluster of cases of the acquired immune deficiency syndrome. Patients linked by sexual contact",
      "author" : [ "D M Auerbach", "W W Darrow", "H W Jaffe", "Curran", "J W" ],
      "venue" : "The American journal of medicine,",
      "citeRegEx" : "Auerbach et al\\.,? \\Q1984\\E",
      "shortCiteRegEx" : "Auerbach et al\\.",
      "year" : 1984
    }, {
      "title" : "First passage percolation and competition",
      "author" : [ "Blair-Stahn", "Nathaniel D" ],
      "venue" : "models. pp",
      "citeRegEx" : "Blair.Stahn and D.,? \\Q2010\\E",
      "shortCiteRegEx" : "Blair.Stahn and D.",
      "year" : 2010
    }, {
      "title" : "Scale-Free Networks Are Ultrasmall",
      "author" : [ "Cohen", "Reuven", "Havlin", "Shlomo" ],
      "venue" : "Physical Review Letters,",
      "citeRegEx" : "Cohen et al\\.,? \\Q2003\\E",
      "shortCiteRegEx" : "Cohen et al\\.",
      "year" : 2003
    }, {
      "title" : "Bayesian inference for epidemics with two levels of mixing",
      "author" : [ "N Demiris", "O’neill", "PD" ],
      "venue" : "Scandinavian journal of statistics,",
      "citeRegEx" : "Demiris et al\\.,? \\Q2005\\E",
      "shortCiteRegEx" : "Demiris et al\\.",
      "year" : 2005
    }, {
      "title" : "Random Graph Dynamics (Cambridge Series in Statistical and Probabilistic Mathematics)",
      "author" : [ "Durrett", "Rick" ],
      "venue" : "ISBN 0521150167",
      "citeRegEx" : "Durrett and Rick.,? \\Q2010\\E",
      "shortCiteRegEx" : "Durrett and Rick.",
      "year" : 2010
    }, {
      "title" : "The effect of network topology on the spread of epidemics",
      "author" : [ "A. Ganesh", "L. Massoulie", "D. Towsley" ],
      "venue" : "In Proceedings IEEE 24th Annual Joint Conference of the IEEE Computer and Communications Societies.,",
      "citeRegEx" : "Ganesh et al\\.,? \\Q2005\\E",
      "shortCiteRegEx" : "Ganesh et al\\.",
      "year" : 2005
    }, {
      "title" : "Random mobility and the spread of infection",
      "author" : [ "Gopalan", "Aditya", "Banerjee", "Siddhartha", "Das", "Abhik K", "Shakkottai", "Sanjay" ],
      "venue" : "In 2011 Proceedings IEEE INFOCOM,",
      "citeRegEx" : "Gopalan et al\\.,? \\Q2011\\E",
      "shortCiteRegEx" : "Gopalan et al\\.",
      "year" : 2011
    }, {
      "title" : "Large deviations for sums of partly dependent random variables",
      "author" : [ "Janson", "Svante" ],
      "venue" : "Random Structures and Algorithms,",
      "citeRegEx" : "Janson and Svante.,? \\Q2004\\E",
      "shortCiteRegEx" : "Janson and Svante.",
      "year" : 2004
    }, {
      "title" : "Rumor source detection under probabilistic sampling",
      "author" : [ "Karamchandani", "Nikhil", "Franceschetti", "Massimo" ],
      "venue" : "IEEE International Symposium on Information Theory, pp. 2184–2188",
      "citeRegEx" : "Karamchandani et al\\.,? \\Q2013\\E",
      "shortCiteRegEx" : "Karamchandani et al\\.",
      "year" : 2013
    }, {
      "title" : "The enron corpus: A new dataset for email classification research",
      "author" : [ "B Klimt", "Y. Yang" ],
      "venue" : "Machine learning: ECML 2004,",
      "citeRegEx" : "Klimt and Yang,? \\Q2004\\E",
      "shortCiteRegEx" : "Klimt and Yang",
      "year" : 2004
    }, {
      "title" : "Network forensics. In Proceedings of the 12th ACM SIGMETRICS/PERFORMANCE joint international conference on Measurement and Modeling of Computer Systems ",
      "author" : [ "Milling", "Chris", "Caramanis", "Constantine", "Mannor", "Shie", "Shakkottai", "Sanjay" ],
      "venue" : "SIGMETRICS ’12,",
      "citeRegEx" : "Milling et al\\.,? \\Q2012\\E",
      "shortCiteRegEx" : "Milling et al\\.",
      "year" : 2012
    }, {
      "title" : "Detecting epidemics using highly noisy data",
      "author" : [ "Milling", "Chris", "Caramanis", "Constantine", "Mannor", "Shie", "Shakkottai", "Sanjay" ],
      "venue" : "In Proceedings of the fourteenth ACM international symposium on Mobile ad hoc networking and computing - MobiHoc",
      "citeRegEx" : "Milling et al\\.,? \\Q2013\\E",
      "shortCiteRegEx" : "Milling et al\\.",
      "year" : 2013
    }, {
      "title" : "Detecting sources of computer viruses in networks: theory and experiment",
      "author" : [ "D Shah", "T. Zaman" ],
      "venue" : "ACM SIGMETRICS Performance Evaluation Review,",
      "citeRegEx" : "Shah and Zaman,? \\Q2010\\E",
      "shortCiteRegEx" : "Shah and Zaman",
      "year" : 2010
    }, {
      "title" : "Statistical inference for stochastic epidemic models",
      "author" : [ "G Streftaris", "Gibson", "GJ" ],
      "venue" : "Int’l Workshop on Statistical Modelling",
      "citeRegEx" : "Streftaris et al\\.,? \\Q2002\\E",
      "shortCiteRegEx" : "Streftaris et al\\.",
      "year" : 2002
    }, {
      "title" : "On the evolution of user interaction in Facebook",
      "author" : [ "Viswanath", "Bimal", "Mislove", "Alan", "Cha", "Meeyoung", "Gummadi", "Krishna P" ],
      "venue" : "In Proceedings of the 2nd ACM workshop on Online social networks - WOSN",
      "citeRegEx" : "Viswanath et al\\.,? \\Q2009\\E",
      "shortCiteRegEx" : "Viswanath et al\\.",
      "year" : 2009
    }, {
      "title" : "Collective dynamics of ’small-world",
      "author" : [ "D J Watts", "Strogatz", "S H" ],
      "venue" : "networks. Nature,",
      "citeRegEx" : "Watts et al\\.,? \\Q1998\\E",
      "shortCiteRegEx" : "Watts et al\\.",
      "year" : 1998
    } ],
    "referenceMentions" : [ {
      "referenceID" : 0,
      "context" : "” In the early phase of the HIV epidemic, this was precisely the nature of the data, since “patient zero” was unknown, and a “hidden backbone” connected the initially identified patients (Auerbach et al. (1984)).",
      "startOffset" : 188,
      "endOffset" : 211
    }, {
      "referenceID" : 5,
      "context" : "The infection then spreads according to a standard suceptible-infectedmodel (Ganesh et al. (2005)).",
      "startOffset" : 77,
      "endOffset" : 98
    }, {
      "referenceID" : 5,
      "context" : "2 Prior Work The predictive (forward) analysis of our SI model, as in (Ganesh et al. (2005)), is tightly related to results in First Passage Percolation theory (Blair-Stahn (2010)).",
      "startOffset" : 71,
      "endOffset" : 92
    }, {
      "referenceID" : 5,
      "context" : "2 Prior Work The predictive (forward) analysis of our SI model, as in (Ganesh et al. (2005)), is tightly related to results in First Passage Percolation theory (Blair-Stahn (2010)).",
      "startOffset" : 71,
      "endOffset" : 180
    }, {
      "referenceID" : 5,
      "context" : "2 Prior Work The predictive (forward) analysis of our SI model, as in (Ganesh et al. (2005)), is tightly related to results in First Passage Percolation theory (Blair-Stahn (2010)). These and related works focus on modeling the epidemic spread characteristics, for example, estimating the infection rate for different topologies (e.g., Gopalan et al. (2011)), predicting the first time the infection exceeds a given boundary, and so on.",
      "startOffset" : 71,
      "endOffset" : 358
    }, {
      "referenceID" : 5,
      "context" : "2 Prior Work The predictive (forward) analysis of our SI model, as in (Ganesh et al. (2005)), is tightly related to results in First Passage Percolation theory (Blair-Stahn (2010)). These and related works focus on modeling the epidemic spread characteristics, for example, estimating the infection rate for different topologies (e.g., Gopalan et al. (2011)), predicting the first time the infection exceeds a given boundary, and so on. These are, therefore, prediction problems, or forward problems: given the initial conditions, predict what happens in the future. Our work focuses on the inverse question: given (a noisy version of) what happened, solve the inference problem to decide if the process is an epidemic or a random illness. Recently, related inference questions have gained considerable attention. Of particular interest are estimating the model parameters, such as transmission rate, either by MCMC methods (Streftaris & Gibson), or a Bayesian approach (Demiris & O’neill). Another frequently discussed question is the identification of the epidemic source (e.g., Shah & Zaman; Karamchandani & Franceschetti (2013)).",
      "startOffset" : 71,
      "endOffset" : 1132
    }, {
      "referenceID" : 5,
      "context" : "2 Prior Work The predictive (forward) analysis of our SI model, as in (Ganesh et al. (2005)), is tightly related to results in First Passage Percolation theory (Blair-Stahn (2010)). These and related works focus on modeling the epidemic spread characteristics, for example, estimating the infection rate for different topologies (e.g., Gopalan et al. (2011)), predicting the first time the infection exceeds a given boundary, and so on. These are, therefore, prediction problems, or forward problems: given the initial conditions, predict what happens in the future. Our work focuses on the inverse question: given (a noisy version of) what happened, solve the inference problem to decide if the process is an epidemic or a random illness. Recently, related inference questions have gained considerable attention. Of particular interest are estimating the model parameters, such as transmission rate, either by MCMC methods (Streftaris & Gibson), or a Bayesian approach (Demiris & O’neill). Another frequently discussed question is the identification of the epidemic source (e.g., Shah & Zaman; Karamchandani & Franceschetti (2013)). The work that most closely relates to ours paper is Milling et al. (2012, 2013). They consider a similar model, and seek to solve the same problem. The key differences here are that the algorithm and analysis are completely different, with some important consequences. In those works, the authors rely on tools from first passage percolation, which in some settings (for some graph topologies, for initial infection conditions) may be fragile. For example, it is not clear if the algorithms given there are able to handle large numbers of initial seeds. Our results in Section 5 indicate that our algorithm is largely insensitive to the number of initial infections, and works well for even hundreds of spread out “patients zero.” A second important difference comes on the algorithmic front. Our algorithm is inherently local. As we describe below, it essentially counts nodes with many infected neighbors, at a high level bearing similarity to triangle-counting as a proxy for graph clustering (Watts & Strogatz (1998)).",
      "startOffset" : 71,
      "endOffset" : 2155
    }, {
      "referenceID" : 10,
      "context" : "We also compare against the Median-ball-algorithm given in Milling et al. (2013). While the Median algorithm may be converging, we see that the convergence of our algorithms for l = 1, 2, 3, 4 is remarkably faster.",
      "startOffset" : 59,
      "endOffset" : 81
    }, {
      "referenceID" : 10,
      "context" : "We also compare against the Median-ball-algorithm given in Milling et al. (2013). While the Median algorithm may be converging, we see that the convergence of our algorithms for l = 1, 2, 3, 4 is remarkably faster. Interestingly, in this experiment, the l = 4 version of our algorithms seems to have a slightly worse performance compared to l = 1, 2. This is likely because the regime of G(N, p) we consider has diameter Θ (logN), and thus even 4-hop neighborhoods are considerable in size. In real-world networks, the degree distribution often follows a power law. For random power law networks, the network diameter is, like in the G(N, p) , Θ(logN), or even Θ(log (logN)) (Cohen & Havlin (2003)).",
      "startOffset" : 59,
      "endOffset" : 698
    }, {
      "referenceID" : 14,
      "context" : "We examined the identification of such phenomena by testing our algorithm on a network of 63K Facebook contacts (Viswanath et al. (2009)).",
      "startOffset" : 113,
      "endOffset" : 137
    } ],
    "year" : 2014,
    "abstractText" : "We consider the problem of detecting an epidemic in a population where individual diagnoses are extremely noisy. The motivation for this problem is the plethora of examples (influenza strains in humans, or computer viruses in smartphones, etc.) where reliable diagnoses are scarce, but noisy data plentiful. In flu/phone-viruses, exceedingly few infected people/phones are professionally diagnosed (only a small fraction go to a doctor) but less reliable secondary signatures (e.g., people staying home, or greater-than-typical upload activity) are more readily available. These secondary data are often plagued by unreliability: many people with the flu do not stay home, and many people that stay home do not have the flu. This paper identifies the precise regime where knowledge of the contact network enables finding the needle in the haystack: we provide a distributed, efficient and robust algorithm that can correctly identify the existence of a spreading epidemic from highly unreliable local data. Our algorithm requires only local-neighbor knowledge of this graph, and in a broad array of settings that we describe, succeeds even when false negatives and false positives make up an overwhelming fraction of the data available. Our results show it succeeds in the presence of partial information about the contact network, and also when there is not a single “patient zero,” but rather many (hundreds, in our examples) of initial patient-zeroes, spread across the graph.",
    "creator" : "LaTeX with hyperref package"
  }
}