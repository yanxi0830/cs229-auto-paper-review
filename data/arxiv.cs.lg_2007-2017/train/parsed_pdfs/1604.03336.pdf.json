{
  "name" : "1604.03336.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "Typicality-Based Stability and Privacy",
    "authors" : [ "Raef Bassily", "Yoav Freund" ],
    "emails" : [ "rbassily@ucsd.edu", "yfreund@eng.ucsd.edu" ],
    "sections" : [ {
      "heading" : null,
      "text" : "We also discuss the guarantees of typical stability on the generalization error (i.e., the difference between the value of the query computed on the dataset and the expected value of the query with respect to the true data distribution). We show that these guarantees hold for a broader class of queries than that of bounded-sensitivity queries. This class contains all queries whose output distributions have a “light” tail, e.g., subgaussian and subexponential queries. In particular, we show that if a typically stable interaction with a dataset yields a query from that class, then this query when evaluated on the same dataset will have small generalization error with high probability (i.e., it will not overfit to the dataset).\nWe discuss the composition guarantees of typical stability and prove a composition theorem that gives a characterization of the degradation of the parameters of typical stability/privacy under k-fold adaptive composition. We also give simple noise-addition algorithms that achieve this notion. These algorithms are similar to their differentially private counterparts, however, the added noise is calibrated differently.\n∗University of California San Diego, Center for Information Theory and Applications and Department of Computer Science and Engineering. rbassily@ucsd.edu †University of California San Diego, Department of Computer Science and Engineering. yfreund@eng.ucsd.edu\nar X\niv :1\n60 4.\n03 33\n6v 1\n[ cs\n.L G\n] 1\n2 A\npr 2\n01 6"
    }, {
      "heading" : "1 Introduction",
      "text" : "Differential privacy [DMNS06, Dwo06] is strong notion of algorithmic stability that has been originally designed to ensure data privacy. As a notion of stability, it has also been recently re-purposed to ensure generalization and statistical validity in adaptive data analysis [DFH+15b, DFH+15a, DFH+15c, BNS+16]. Depsite of its power, releasing real-valued queries (statistics) under differential privacy in general entails the assumption that such queries are of bounded sensitivity, that is, the maximum change in the value of the query’s output due to a change in any single data point in the dataset has to be bounded.\nTypical Stability/Privacy. In this work, we introduce a new notion of algorithmic stability called typical stability that does not require the queries to be of bounded-sensitivity, but instead requires the output of each query, when evaluated on a dataset drawn from the underlying distribution, to be “well-concentrated” around its mean with respect to that distribution. Our notion can also be motivated as an alternative definition for privacy in scenarios. Moreover, this notion introduces a new algorithmic stability approach for ensuring generalization in adaptive data analysis especially in the settings where queries are not necessarily of bounded sensitivity.\nAs it is the case with differential privacy, typical stability1 is presented in two versions : pure and approximate typical stability. In general, typical stability is defined via three parameters: η,τ, and ν. When τ = 0, we call it pure typical stability, otherwise, we call it approximate typical stability. We will give here an intuitive description of this notion (Formal definitions are given in Section 2). Consider a randomized algorithm A that takes as input a dataset drawn from some arbitrary distribution P over the dataset domain X n. We say that A is (η,τ,ν)-typically stable algorithm if there is a subset S ⊆ X n whose measure with respect to P is at least 1− ν such that for any pair of datasets x,y ∈ S , the distribution of A(x) is “close” to that of A(y). Such closeness is determined by the two parameters η and τ that play similar roles to that of ε and δ in differential privacy. So, intutively, S is a set of “typical” datasets, and roughly speaking, we require the distributions of the output of A on any pair of typical datasets to be “indistinguishable”. The intuition is that the output ofA should “conceal” the identity of the dataset inside the typical set S , that is, the output should not reveal which of the typical datasets is the true input of A. However, the output should still reveal information about S as a whole since such information depends on the underlying distribution P rather than the sample. In this sense, typical stability ensures that the whatever is revealed by the algorithm is essentially information shared by all typical datasets.\nparagraphConcentrated Queries. In this work, we consider the query release problem under typical stability. As mentioned earlier, we consider classes of queries whose ouputs are concentrated around their expectation with respect to the underlying distribution on the dataset. We formally describe such classes as follows. We say that a class Qγn(P) of real-valued queries on a dataset from X n is γn-concentrated with respect to distribution P over X n if there is a non-negative, non-decreasing function γn : R+→ R+ (that possibly depends on n) such that for every query q ∈Qγn(P), with probability at least 1− e −γn(α) over the choice of a dataset X ∼ P, the generalization\nerror of q is bounded by α, where generalization error refers to the quantity ∣∣∣∣∣q(X)− EY∼P [q(Y )] ∣∣∣∣∣. For different settings of γn, we obtain query classes that contain the class of subgaussian queries and the class of sub-exponential queries which were studied in [RZ15], and the more special class of jointly Gaussian queries that was studied in both [RZ15, WLF16].\n1To avoid using long terms, in the sequel, we will just refer to this notion as typical stability. However, we stress that our motivation for this notion includes both stability and privacy.\nOur notion is similar to a notion called perfect generalization that was introduced very recently and independently by Cummings et al. [CLN+16]2 where it was also studied in the context of generalization in PAC-learning models. In this paper, we discuss the composition guarantees of this notion and prove a composition theorem that gives a characterization of the degradation of the parameters of typical stability when a sequence of k arbitrarily and adaptively chosen typically stable algorithms3 operating on the same dataset are composed together.\nProperties of Typical Stability. We show that this notion is closed under post-processing, and robust to adaptive composition. We provide a characterization of the degradation in the parameters of typical stability under k-fold adaptive composition. We also show that typical stability implies generalization by first proving an independence lemma that follows from the defintion of typical stability. In particular, we show that any γn-concentrated query generated from a typically stable interaction with the dataset will have small generalization error with high probability (i.e., it will not overfit to the same dataset).\nAchieving Typical Stability via Noise-Adding Mechanisms. We give simple noise-addition typically stable mechanisms for answering real-valued queries. Our mechanisms are based on adding Laplace and Gaussian noise to the query output to achieve pure and approximate typical stability, respectively. These mechanisms are very similar to the popular differentially private Lalplace and Gaussian mechanisms [DMNS06, DKM+06], however, the added noise is calibrated differently in our case. In particular, the noise is added based on how “well” the query output is concentrated around its expectation, that is, roughly speaking, the noise is claibrated to the concentration radius of the query. More formally, let P be an arbitratry distribution on X n. For\na query q : X n→R, if we have P X∼P [∣∣∣∣∣q(X)− EY∼P [q(Y )] ∣∣∣∣∣ > α] < ν, then, our mechanisms would add noise (Laplace for pure, and Gaussian for approximate typical stability) whose standard deviation proportional to α."
    }, {
      "heading" : "2 Typical Stability/Privacy",
      "text" : "Before we formally define typical stability, we first state a standard definition for the notion (η,τ)-indistinguishability between distributions of random variables.\nDefinition 2.1 ((η,τ)-indstinguishability). Random variables X,Y with the same range are said to have (η,τ)-indistinguishable distributions, denoted as X ≈η,τ Y , if for all measurable subsets O of their range, we have"
    }, {
      "heading" : "P [X ∈ O] ≤ eηP [Y ∈ O] + τ and P [Y ∈ O] ≤ eηP [X ∈ O] + τ.",
      "text" : "Definition 2.2 (Typical Stability/Privacy). LetA : X n→Z be a randomized algorithm. We say that A is (η,τ,ν)-typically stable (or (η,τ,ν)-typically private) with respect to a family P of distributions over X n if for any distribution P ∈ P there exists a set S ⊆ X n such that P\nX,Y∼P [X,Y ∈ S] ≥ 1 − ν\nwhere X and Y are independent, and for every x,y ∈ S and for all measurable O ⊆ Z, we have\nP A [A(x) ∈ O] ≤ eηP A [A(y) ∈ O] + τ\n2We believe there is an error in the proof of Theorem 2.13 in [CLN+16]. 3That is, the choice of a typically stable algorithm in the sequence is possibly based on all previous outputs of the\nprevious algorithms in the sequnce.\nThat is, for all x,y ∈ S , we have A(x) ≈η,τ A(y).\nThe definition with τ = 0 will sometimes be referred to as (η,ν)-pure typical stability with respect to P (as opposed to approximate typical stability when τ > 0.)\nAn equivalent way to state Definition 2.2 is as follows: A is (η,τ,ν)-typically stable with respect to a family of distributions P over X n if for any distribution P ∈ P , for any two independent X,Y ∼ P, with probability at least 1− ν over the choice of X,Y we have A(X) ≈η,τ A(Y ).\nAnother slightly stronger form of this definition is as follows. (This is almost the same as perfect generalization [CLN+16] except we do not require the distribution to be i.i.d.).\nDefinition 2.3. Let A : X n → Z be a randomized algorithm. We say that A is (η,τ,ν)-typically stable with respect to a family P of distributions over X n if for any distribution P ∈ P there exists an oracleW that takes P as input and outputs a value in Z, such that A(X) ≈η,τ W (P) with probability at least 1− ν over the choice X ∼ P.\nIt is not hard to see that (η,τ,ν)-typical stability under Definition 2.3 implies (2η,3τ,2ν)typical stability under Definition 2.2. Sometimes, it will be easier to work with this slightly stronger version in our analysis, e.g., when we discuss the adaptive composition of typically stable algorithms, since it helps in simplifying notation compared to Definition 2.2."
    }, {
      "heading" : "2.1 Some properties of typical stability",
      "text" : "Here, we state some useful properties of typically stable algorithms. In particular, we show that this notion is closed under post-processing and under non-adaptive composition where the stability parameters degrade linearly with the number of algorithms to be composed. We defer the discussion of the adaptive composition of typically stable algorithms to Section 3.\nLemma 2.4 (Postprocessing). Let A : X n→Z be an (η,τ,ν)-typically stable algorithm with respect to a family of distributions P over X n. Let B : Zn→U be a randomized algorithm. Let C : X n→U be defined as C(x) = B(A(x)). Then, C is (η,τ,ν)-typically stable algorithm with respect to P .\nProof. The proof follows from a straightforward manipulation where the probability of any measurable subset O of the outcomes of C is expressed as a convex combination of probabilities of a collection of sets over the outcomes of A.\nLemma 2.5 (Non-Adaptive Composition). Let Ai : X n → Zi , i ∈ [k] be any collection of (η,τ,ν)typically stable algorithms with respect to a common family P of distributions overX n where allAi , i ∈ [k] have independent random coins. Define C : X n → Z1 × . . . × Zk as C(x) = (A1(x), . . . ,Ak(x)) ,x ∈ X n. Then, C is (kη,kτ,kν)-typically stable.\nProof. The proof follows from combining the union bound with a standard technique for bounding the probability of the joint outcome similar to that used in proving basic composition theorems for (ε,δ)-differentially private algorithms [DKM+06, DR14]."
    }, {
      "heading" : "2.2 Queries",
      "text" : "We introduce the classes of queries (statistics on the dataset) that will be considered in this paper.\n• γn-Concentrated Queries: For any fixed dataset size n ∈ N, let γn : R+ → R+ be a nonnegative, non-decreasing function (possibly depends on n). We define Qγn(P) as the class of all real-valued queries defined on X n whose ouput on a dataset drawn from the distribution P\nis concentrated within distance α around its expected value with respect to P with probability at least 1− e−γn(α), for every α > 0. Formally,\nQγn(P) , { q : X n→R s.t. P\nX∼P [∣∣∣q(X)− E Y∼P [q(Y )] ∣∣∣ > α] < e−γn(α) for all α > 0} .\n• ∆-Sensitive Queries: We let Q∆ denote the class of ∆-sensitive queries on X n. That is,\nQ∆ = { q : X n→R s.t. ∀x,x′ ∈ X n with dH (x,x′) ≤ 1, |q(x)− q(x′)| ≤ ∆ } ,\nwhere dH (·, ·) is the Hamming distance. For all functions γn satisfying γn(α) ≤ 2α 2\nn∆2 ,α > 0, from McDiarmid’s inequality, it follows that Q∆ ⊆ ⋂ P∈Pπ Qγn(P) where P π is the class of all product distributions over X n. When ∆ is small, e.g., ∆ = 1/n, this class is usually referred to as low-sensitivity queries (or, Lipschitz statistics).\n• σ -subgaussian Queries: A query q : X n→ R is said to be σ -subgaussian with respect to a distribution P over X n if we have\nE X∼P\n[ et(q(X)−µq) ] ≤ e 1 2 t 2σ2 , t ∈R,\nwhere µq = E Y∼P [q(Y )]. We denote the class of σ -subgaussian queries with respect to P by QGσ (P). For all functions γn satisfying γn(α) ≤ α 2 2σ2 ,α > 0, we have Q G σ (P) ⊆Qγn(P). Note also that for any P ∈ Pπ, Q∆ ⊂QGσ (P) for ∆ ≤ 2σ√n .\n• (σ,b)-subexponential Queries: A query q : X n→R is said to be (σ,b)-subexponential with respect to a distribution P over X n if we have\nE X∼P\n[ et(q(X)−µq) ] ≤ e 1 2 t 2σ2 , |t| ≤ 1/b,\nwhere µq = E Y∼P [q(Y )]. We denote the class of (σ,b)-subexponential queries with respect to P by QExpσ,b (P).\nFor all functions γn satisfying γn(α) ≤min ( α2 2σ2 , σ2 2b2 ) ,α > 0, we have QExpσ,b (P) ⊆Qγn(P).\nWe note that there are σ -subgaussian (or, (σ,b)-subexponential) queries that are not necessarily ∆-sensitive (not even for arbitrary large ∆), for example, the class of those queries that correspond to the sample mean of independent random variables with bounded moments (but not necessarily bounded support) where concentration inequalities such as Bernstein’s hold. On the other hand, as indicated above ∆-sensitive queries is a subclass of σ -subgaussian queries for ∆ ≤ 2σ/ √ n. Hence, the class of subgaussian queries (and more generally the class of γn-concentrated queries) is strictly larger than the class of low-sensitivity queries."
    }, {
      "heading" : "2.3 Typical stability and the Near-Independence property",
      "text" : "The following lemma describes an important implication of typical stability. It describes the effect of typical stability on the joint distribution of the dataset and the output of a typically stable algorithm. Let P be a family of distributions over X n. Let X ∼ P for any distribution P ∈ P . Let A : X n→Z be an (η,τ,ν)-typically stable algorithm with respect to P . Lemma 2.6 below states that the joint probability measure of (X,A(X)) is “close” to the product measure of X and A(X) (i.e., the measure induced by the product of the marginal distributions). A similar statement is known for ε-differentially private algorithms via a connection to the notion of max-information [DFH+15a]. Although closely related, the argument here does not go through bounding the max-information mainly because in typical stability we assume that disribution of the dataset X comes from some given family P whereas the notion of max-information is defined for all distributions on the dataset.\nLemma 2.6 (Near-Independence Lemma of Typically Stable Algorithms). Let P be a family of distributions over X n. Let A : X n→Z be an (η,τ,ν)-typically stable algorithm with respect to P . Let P ∈ P . Let X,Y ∼ P be two independent random variables. Let S ⊆ X n be a set that satisfies the condition of typical stability in Definition 2.2, that is, P\nX,Y∼P [X,Y ∈ S] ≥ 1 − ν and for every x,y ∈ S , we have\nA(x) ≈η,τ A(y). Then, for every measurable O ⊆ X n ×Z, we have\nP [ (X,A(X)) ∈ O ∣∣∣ X ∈ S] ≤ eηP [(X,A(Y )) ∈ O ∣∣∣ X,Y ∈ S]+ τ (1) If η < 1 and ν < 1/10, then (1) implies\nP [(X,A(X)) ∈ O] ≤ eηP [(X,A(Y )) ∈ O] + τ + 4ν (2)\nProof. Fix O ⊆ X n ×Zn. For every x ∈ X n, let Ux = {z ∈ Zn : (x,z) ∈ O}. Now, observe4\nP [ (X,A(X)) ∈ O ∣∣∣ X ∈ S] = ∑ x∈X n P [ A(x) ∈Ux ∣∣∣ X = x,X ∈ S]P [X = x ∣∣∣X ∈ S] ≤\n∑ x∈X n eηP [A(y) ∈Ux]P [ X = x ∣∣∣X ∈ S]+ τ for every y ∈ S . The last inequality follows from the typical stability of A. Now, by taking the expectation of the two sides of the above inequality with respect to the conditional measure P [ Y = y\n∣∣∣ Y ∈ S], we get (1). Now, from (1) and by straightforward manipulation, we have\nP [(X,A(X)) ∈ O] ≤ eηP [ (X,A(Y )) ∈ O ∣∣∣ Y ∈ S]+ τ + ν ≤ eη P [(X,A(Y )) ∈ O]\nP [Y ∈ S] + τ + ν\n≤ eηP [(X,A(Y )) ∈ O] + τ + 4ν\nwhere the last inequality follows from the fact that P [Y ∈ S] ≥ 1− ν, and that η < 1,ν < 1/10.\n4For continuous measures, we will regard the probabilities below as density functions and sums are replaced with Lebesgue integrals with respect to the appropriate probability measures."
    }, {
      "heading" : "2.4 Generalization via Typical Stability",
      "text" : "We discuss here an implication of Lemma 2.6. Let P be a distribution over X n. The next theorem states that if an (η,τ,e−γn(α))-typically stable interaction with a dataset X ∼ P yields a query in Qγn(P), then the generlaization error of that query on the dataset will be bounded by α with high probability.\nTheorem 2.7 (Generalization via Typical Stability). Let P be any distribution on X n. Let α > 0. Let A : X n→Qγn(P) be an (η,τ,e\n−γn(α))-typically stable algorithm with respect to P that outputs an γn-concentrated query in Qγn(P). Let qX denote the output of A(X). Then, we have\nP [ |qX(X)− E\nT∼P [qX(T )] | > α\n] ≤ eη−γn(α) + 4e−γn(α) + τ\nIn particular, if η =O(1), then P [ |qX(X)− E\nT∼P [qX(T )] | > α\n] ≤O ( max ( e−γn(α), τ )) Proof. The proof follows from Lemma 2.6. In particular, observe that the event\nO = { (x,qx) : ∣∣∣∣∣qx(x)− ET∼Pn [qx(T )] ∣∣∣∣∣ > α}\nis defined over the joint measure of (X,A(X)). Now, by using (2) in Lemma 2.6 together with the fact that the output of A is γn-concentrated query with respect to P, we get the desired result."
    }, {
      "heading" : "3 Adaptive Composition of Typically Stable Algorithms",
      "text" : "In this section, we discuss an important property of typical stability. We give a characterization of how fast typical stability degrades as a result of adaptively composing (η,τ,ν)-typically stable algorithms.\nBefore we state our composition results, we first describe the adaptive composition model. Let P be a family of distribrutions over X n. We consider an arbitrary sequence of k adaptively chosen algorithms Ai : X n × Z1 × . . . × Zi−1 → Zi , i ∈ [k] such that for every i ∈ [k] and every zi−1 , (z1, . . . , zi−1) ∈ Z1 × . . .×Zi−1, the algorithm Ai(·,zi−1) is (η,τ,ν)-typically stable with respect to P . We consider the k-fold adaptive composition mechanismMk outlined in Algorithm 1.\nDefinition 3.1. We say that the class of (η,τ,ν)-typically stable mechanisms (w.r.t. P ) satisfies (η′ , τ ′ ,ν′)-typical stability (w.r.t. P ) under k-fold adaptive composition if mechanismMk (Algorithm 1) is (η′ , τ ′ ,ν′)-typically stable (w.r.t. P )."
    }, {
      "heading" : "3.1 Composition of pure typically stable algorithms",
      "text" : "In this section, we state and prove our composition theorem for pure typically stable algorithms (i.e., τ = 0). Whenever we refer to any run ofMk in this section, it will be assumed thatMk runs with τ = 0.\nFor pure typically stable algorithms, for any τ ′ > 0, the following parameters are achievable for the k-fold adaptive composition (where k ≥ 2):\nηk = 3 √ 2k log(1/τ ′)η + 3kη (eη − 1) , (3)\nτk = νk = 5 kτ ′/η + ν/η + k−1∑ t=1 eηtν/η  1/2\n(4)\nThis is formally stated in the following theorem.\nTheorem 3.2 (Adaptive Composition of Pure Typically Stable Algorithms). Let k ∈ N. For all η > 0, 0 ≤ ν < 1, and 0 < τ ′ < 1, the class of (η,0,ν)-typically stable algorithms w.r.t. P satisfies (ηk , τk ,νk)-typical stability w.r.t. P under k-fold adaptive composition where ηk , τk , and νk are as defined in (3)-(4) above.\nWe note here that νk does not scale linearly with k as one would expect if a simple application of the union bound would have been used. A straightforward application of the union bound would not be appropriate in an adaptive setting since, at each step of the k-fold composition, conditioning on the previous outputs effectively changes the data distribution.\nTo simplify our proof, we will use the slightly stronger version of the definition of typically stable algorithms (Definition 2.3) where the indistinguishability holds between the distributions of the output of the algorithm and that of an oracle that operates on the true data distribution rather than the dataset.\nThe high-level idea of the proof is as follows. Suppose X ∼ P. Let Zi = (Z1, . . . ,Zi) denote the output ofMi(X) and Z̃i = (Z̃1, . . . , Z̃i) denote the output ofW i(P) = (W1(P), . . . ,Wi(P)) whereWi(P) is the oracle corresponding to Ai(·,Zi−1). At each step i of the composition, we prune the bad set of pairs (X,Zi−1) for which the distribution of the output of Ai(X,Zi−1) is not η-indistinguishable from that ofWi(P) (the oracle corresponding toAi(·,Zi−1)). By doing so at each step i = 1, . . . , j, then at step j, we are left with a good set for which this indistinguishability condition holds for all i ∈ [j]. We then use a standard concentration inequality (Azuma’s inequality; see Theorem 3.4) to argue that by removing another tiny portion (of small measure) from that good set, we can ensure that the joint distribution of ( X,Mj(X) ) is ηj-indistinguishable from the joint distribution of ( X,W j(P) ) . We then apply a useful lemma from [KS14] (see Lemma 3.6) to argue typical stability ofMj . In our proof, in order to bound the measure of the bad set as we go from one step of the composition to the next, we use induction. Lemma 3.7 serves as the induction step where we bound the additional “bad” measure we need to prune as we go from step j to step j + 1."
    }, {
      "heading" : "3.1.1 Proof of Theorem 3.2",
      "text" : "Fix some P ∈ P . Let X ∼ P. For any integer j ≥ 1, we use Zj = (Z1, . . . ,Zj) to denote the output of Mj(X). We will also use Z̃j to denote the output of W j(P). In the sequel, we will assume that Z0 = Z̃0 =⊥ with probability 1.\nFor any integer i ≥ 1, and any (x,zi) ∈ X n ×Z1 × . . .×Zi , we define\nfi(x,z i) = ln P [ Ai ( x,zi−1 ) = zi ] P [Wi (P) = zi]  . We then define\nFj(x,z j ) = j∑ i=1 fi(x,z i).\nWe also define f̂i(x,z\ni−1) = max z∈Zi ∣∣∣∣fi (x, (zi−1, z))∣∣∣∣ where (zi−1, z) ∈ Z1 × . . .×Zi−1 ×Zi . We define\nCi = { (x,zi−1) : f̂i(x,z i−1) ≤ η } ,\nand Ĉi = { (x,zi−1) : ∀` ∈ [i] (x,z`−1) ∈ C` } Fix τ ′ > 0. Let ηj be as defined in (3). Define\nGi = { (x,zj ) : Fj(x,z j ) ≤ ηj }\nLemma 3.3. Let j ≥ 1. Suppose there is µ∗ ≥ jν such that P [ (X,Zj−1) ∈ Ĉj ] ≥ 1−µ∗. Then,\nP [ (X,Zj ) < Gj and (X,Zj−1) ∈ Ĉj ] ≤ τ ′ ,\nand hence, P [ (X,Zj ) ∈ Gj ] ≥ 1−µ∗ − τ ′ .\nProof. Consider the random variables fi(X,Zi), i ∈ [j]. Fix i ∈ [j]. Given (x,zi−1) ∈ Ĉi , then with probability 1, we have\nmax ζ∈Zi ∣∣∣fi(x,zi−1,ζ)∣∣∣ ≤ η, (5) Now, given (x,zi−1) ∈ Ĉi , we analyze the conditional expectation E [ fi(X,Zi) | x,zi−1 ] ( where we\nuse the notation E [ fi(X,Zi) | x,zi−1 ] as a shorthand for E [ fi(X,Zi) | X = x, Zi−1 = zi−1 ] ) . We note that this is a conditional KL-divergence between the distributions of the outputs of Ai and Wi conditioned on (x,zi−1). Using a standard result (see [DRV10]) together with (5), we have\nE [ fi(X,Z i) | x, zi−1 ] ≤ η(eη − 1) (6)\nNow, define\ngi(x,z i) = { fi(x,zi) for (x,zi−1) ∈ Ĉi ; 0 otherwise.\n(7)\nObserve that using (5), we have ∣∣∣gi(X,Zi)∣∣∣ ≤ η with probability 1. Moreover, using (6), for all\n(x,zi−1) ∈ X ×Z1 × . . .×Zi−1, we have E [ gi(X,Z i) | x,zi−1 ] ≤ η(eη − 1).\nNow, we use the following classical concentration inequality.\nTheorem 3.4 (Azuma’s Inequality). Let T1, . . . ,Tj be a sequence of random variables such that for every i ∈ [j] we have\nP [|Ti | ≤ b] = 1\nand for every prefix Ti−1 = ti−1 we have E [ Ti−1 | ti−1 ] ≤ c\nthen for all u ≥ 0, we have\nP  j∑ i=1 Ti ≥ jc+u √ jb  ≤ e−u2/2 Now, let ηj be as defined in (3). Observe that\nP [ (X,Zj ) < Gj and (X,Zj−1) ∈ Ĉj ] ≤ P  j∑ i=1 gi(X,Z j ) > ηj  ≤ τ ′ where the last inequality follows from Theorem 3.4. This together with the premise in the lemma concludes the proof. Lemma 3.5. Let j ≥ 1. Suppose the premise of Lemma 3.3 is true. ThenMj is (3ηj , 5 √ µ∗+τ ′ η , 5 √ µ∗+τ ′ η )- typically stable.\nProof. Observe that for any (x,zj ) ∈ Gj P [ Mj(x) = zj ] P [ W j(P) = zj\n] ≤ eηj (8) whereW j(P) = ( W1(P), . . . ,Wj(P) ) . Let Z̃j denote the output ofW j(P). Define\nG̃j = { (x,zj ) : −Fj(x,zj ) ≤ ηj } .\nHence, for any (x,zj ) ∈ G̃j\nP [ W j(P) = zj ] P [ Mj(x) = zj\n] ≤ eηj (9) Moreover, by the independence of X and Z̃j , we have\nP [ (X, Z̃j ) ∈ Ĉj ] ≥ 1− jν\nThus, by swaping the roles ofMj(X) andW j(P) in Lemma 3.3, it follows that P [ (X, Z̃j ) ∈ G̃j ] ≥ 1− jν − τ ′ ≥ 1−µ∗ − τ ′ (10)\nHence, by Lemma 3.3, and using (8)-(10) above, we have( X, Mj(X) ) ≈ηj , µ∗+τ ′ ( X, W j(P) ) Now, we use the following useful lemma from [KS14].\nLemma 3.6 (Conditioning Lemma [KS14]). Suppose that (U,V ) ≈ ,δ (U ′ ,V ′). Then, for every δ̂ > 0, the following holds\nP t∼p(V )\n[ U |V=t ≈3 ,δ̂ U ′ |V ′=t ] ≥ 1− 2δ\nδ̂ − 2δ 1− e−\nwhere p(V ) denotes the distribution of V .\nUsing Lemma 3.6, we have\nP X∼P\n[ Mj(X) ≈3ηj , τ̃ W j(P) ] ≥ 1− 2(µ∗ + τ ′) τ̃ − 2(µ∗ + τ ′) 1− e−ηj\n. We conclude the proof by setting τ̃ = 2 √\n(µ∗ + τ ′)η/5 (and noting that 1−e−ηj ≥ 1−e−η ≥ 25 min(η,1)).\nLemma 3.7. Let j ≥ 1. Suppose the premise of Lemma 3.3 is true. Then, we have P [ (X,Zj ) ∈ Ĉj+1 ] ≥ 1−µ∗ − eηjν − τ ′\nProof. Observe that P [ (X,Zj ) < Ĉj+1 ] =P [ (X,Zj ) < Cj+1 and (X,Zj−1) ∈ Ĉj ] +P [ (X,Zj−1) < Ĉj ] =P [ (X,Zj ) < Cj+1 and (X,Zj−1) ∈ Ĉj and (X,Zj ) ∈ Gj\n] +P [ (X,Zj ) < Cj+1 and (X,Zj−1) ∈ Ĉj and (X,Zj ) < Gj ] +P [ (X,Zj−1) < Ĉj\n] ≤P [ (X,Zj ) < Cj+1 and (X,Zj ) ∈ Gj ] +P [ (X,Zj−1) ∈ Ĉj and (X,Zj ) < Gj ] +P [ (X,Zj−1) < Ĉj\n] ≤P [ (X,Zj ) < Cj+1 and (X,Zj ) ∈ Gj ] + τ ′ +µ∗\nwhere the last inequality follows from Lemma 3.3 and the fact that the premise of Lemma 3.3 is true. Now, consider the remaining term. Observe that\nP [ (X,Zj ) < Cj+1 and (X,Zj ) ∈ Gj ] = ∑ (x,zj )∈Ccj+1∩Gj P [ X = x,Zj = zj ] =\n∑ (x,zj )∈Ccj+1∩Gj P [ Zj = zj | X = x ] P [X = x]\n= ∑\n(x,zj )∈Ccj+1∩Gj\nP [ Mj(x) = zj ] P [X = x]\n≤ eηj ∑\n(x,zj )∈Ccj+1∩Gj\nP [ W j(P) = zj ] P [X = x]\n≤ eηjP [ (X, Z̃j ) < Cj+1 ] (11)\nwhere Ccj+1 denotes the complement of the set Cj+1, and Z̃ j denotes the output ofW j(P). Note that the fourth inquality follows from the definition of Gj . Notice that X and Z̃j are independent. By the (η,0,ν)-typical stability of Aj+1, for any fixed prefix zj we have\nP [ Aj+1(X,zj ) ≈η Wj+1(P) ] ≥ 1− ν\nThus, by the independence of X and Z̃j , we must have\nP [ (X, Z̃j ) < Cj+1 ] ≤ ν.\nThis concludes the proof.\nThe proof of Theorem 3.2 follows from the above three lemmas and by induction on the basis of j = 1. Note that P [ (X,Z0) ∈ Ĉ1 ] = P [ (X,⊥) ∈ Ĉ1 ] ≥ 1− ν by the typical stability of A1."
    }, {
      "heading" : "3.2 Composition of approximate typically stable algorithms: τ > 0",
      "text" : "Our composition theorem for approximate typically stable algorithms is given by Theorem 3.8 below.\nFor any integer k ≥ 2, we define\nτ̂ , 2τ\n1− e−η =O (τ/η) , ψ(τ) , τ (2eη + 1) + τ2 ( 1 + 2e2η (eη − 1)2 ( 4e2η + 4eη − 3− 2e−η + e−2η )) =O ( τ + τ2/η2 ) ,\nand\nηk = 6 √ 2k log(1/τ ′)η + 3k ( 2η ( e2η\n1− τ̂ − 1\n) +ψ(τ) ) , (12)\nτk = νk = 5 k (τ̂ + τ ′2η ) + ν 2η + k−1∑ t=1 eηt ν 2η  1/2 . (13)\nTheorem 3.8 (Adaptive Composition of Approximate Typically Stable Algorithms). Let k ∈N. For all η > 0, 0 ≤ τ,ν < 1, and 0 < τ ′ < 1, the class of (η,τ,ν)-typically stable algorithms w.r.t. P satisfies (ηk , τk ,νk)-typical stability w.r.t. P under k-fold adaptive composition where ηk , τk , and νk are as defined in (12)-(13) above.\nThe proof of this theorem is a bit more complicated since we have another sequence of “bad” sets we need to keep track of. Also, there are other fine details concerning deriving a bound on the conditional expectation analogous to (6) before applying Azuma’s inequality since the bound in (6) does not necessarily hold in this case. We defer the details of this proof to the full version of this paper."
    }, {
      "heading" : "4 Achieving typical stability",
      "text" : "We describe here two simple noise-adding mechanims for achieving pure and approximate typical stability for releasing γn-concentrated queries. As a special case, we get typically stable algorithms for releasing low-sensitivity queries as well. The algorithms are based on adding Laplace and Gaussian noise to the output of the query, and hence such algorithms are very similar to their differntially private counterparts. However, the added noise is calibrated differently from the case of differential privacy. Rather than calibrating the noise based on the global (or smooth) sensitivity of the query, the noise here is added based on the concentration radius of the query output, that is, based on how well the query output is concentrated around its mean with respect to the underlying\ndistribution on the data. In particular, for the class of γn-concentrated queries, to achieve typical stability with ν =O ( e−γn(α) ) , the noise is calibrated based on α, namely, the magnitude (standard deviation) of the noise is chosen to be ≈ α/η. The intution here is that the added noise aims to conceal the identity of the specific input sample x among other typical samples (that occur with probability greater than 1− ν). Nonetheless, the output would still provide information about the set of typical samples as a whole. Such information depends on the distribution rather than the sample.\nAlthough we only describe algorithms for releasing one-dimensional real-valued queries, the extension to multiple dimensions should not be difficult. In such case, the added noise will be proportional to the L1 concentration radius in the Laplace mechanism, and proportional to the L2 concentration radius in the Gaussian mechanism. However, this would require extending the definition of the query class to the multiple-dimension setting. To keep our focus on the properties of typical stability, we will not discuss here the higher dimensional extensions of these algorithms.\nLet P be any distribution over X n. Algorithm 2 describes a Laplace-noise mechanism that achieves (η,0,ν)-typical stability with respect to P for releasing any γn-concentrated query with respect to P, i.e., for releasing any query in Qγn(P).\nTheorem 4.1 (Typical Stability of the Modified Laplace Mechanism). For any distribution P over X n, Algorithm 2 for releasing queries in Qγn(P) is (η,0,ν)-typically stable 5 with respect to P.\nProof. Let Sq , { x ∈ X n : |q(x)− E\nT∼P [q(T )] | ≤ α\n} where q is the input query in Qγn(P). By definition\nof Qγn , we have PX,Y∼P [X,Y ∈ Sq] ≥ 1 − 2e−γn(α) ≥ 1 − ν for any independent random variables X,Y ∼ P. Let u,v ∈ Sq. Let O ⊆R be any measurable set. Observe\nP [ q(u) + Lap ( η 2α ) ∈ O ] = α η ∫ O e− η 2α |w−q(u)|dw\n≤ e η 2α |q(v)−q(u)| · α η ∫ O e− η 2α |w−q(v)|dw\n≤ eηP [ q(v) + Lap ( η 2α ) ∈ O ] where the last inequality follows from the fact that |q(v)− q(u)| ≤ 2α.\nNote that under Definition 2.3, Algorithm 2 satisfies (η/2,0,ν/2)-typical stability. This can be shown be choosing the oracle associated with Algorithm 2 to be the mechanism that add Lap\n( η\n2α ) noise to E\nT∼P [q(T )] and outputs the result.\nTheorem 4.2 (Empirical Error of the Modified Laplace Mechanism). With probability at least 1− β with respect to the random coins of Algorithm 2, the output w satisfies |w − q(x)| < 2α log(1/β)η .\n5This is assuming Definition 2.2. Under Definition 2.3, Algorithm 2 achieves (η/2,0,ν/2)-typical stability.\nLet P be any distribution over X n. Algorithm 3 describes a Gaussian-noise mechanism that achieves (η,τ,ν)-typical stability with respect to P for releasing any query in Qγn(P).\nTheorem 4.3 (Typical Stability of the Modified Gaussian Mechanism). For any distribution P over X n, Algorithm 3 for releasing queries in Qγn(P) is (η,τ,ν)-typically stable 6 with respect to P.\nProof. Let Sq , { x ∈ X n : |q(x)− E\nT∼P [q(T )] | ≤ α\n} where q is the input query in Qγn(P). By definition\nofQγn , we have PX,Y∼P [X ∈ Sq] ≥ 1−2e−γn(α) ≥ 1−ν. Let u,v ∈ Sq. Consider the ratio of the densities of q(u) +N and q(v) +N . The remainder of the proof follows the same approach used to bound this ratio in the analysis of the standard Gaussian mechanism in the literature of differential privacy (e.g., [DKM+06]), and from the fact that |q(v)− q(u)| ≤ 2α.\nAs it is the case with the previous algorithm, we note that under Definition 2.3, Algorithm 3 satisfies (η/2, τ,ν/2)-typical stability. This can be shown be choosing the oracle associated with Algorithm 3 to be the mechanism that addN ( 0,σ2 ) noise to E\nT∼P [q(T )] and outputs the result.\nTheorem 4.4 (Empirical Error of the Modified Gaussian Mechanism). With probability at least 1−β with respect to the random coins of Algorithm 3, the output w satisfies |w − q(x)| < 4α √\nlog(1/τ) log(1/β) η .\nWe note that with appropriate setting of the parameters in the algorithms above, one would obtain typically stable algorithms for releasing low-sensitivity queries. We also note that in such case, the algorithms will be typically stable with respect to all product distributions on X n."
    }, {
      "heading" : "Acknowledgement",
      "text" : "We would like to thank Adam Smith for the helpful discussion and for pointing us to the conditioning lemma of [KS14] which we used in our proof for the adaptive composition guarantees of typical stability."
    } ],
    "references" : [ {
      "title" : "Algorithmic stability for adaptive data analysis",
      "author" : [ "Raef Bassily", "Kobbi Nissim", "Adam Smith", "Uri Stemmer", "Thomas Steinke", "Jonathan Ullman" ],
      "venue" : null,
      "citeRegEx" : "Bassily et al\\.,? \\Q2016\\E",
      "shortCiteRegEx" : "Bassily et al\\.",
      "year" : 2016
    }, {
      "title" : "Adaptive learning with robust generalization guarantees. arXiv:1602.07726v1, Feb. 2016",
      "author" : [ "Rachel Cummings", "Katrina Ligett", "Kobbi Nissim", "Aaron Roth", "Zhiwei Steven Wu" ],
      "venue" : null,
      "citeRegEx" : "Cummings et al\\.,? \\Q2016\\E",
      "shortCiteRegEx" : "Cummings et al\\.",
      "year" : 2016
    }, {
      "title" : "Generalization in adaptive data analysis and holdout reuse",
      "author" : [ "Cynthia Dwork", "Vitaly Feldman", "Moritz Hardt", "Toniann Pitassi", "Omer Reingold", "Aaron Roth" ],
      "venue" : "In Advances in Neural Information Processing Systems (NIPS),",
      "citeRegEx" : "Dwork et al\\.,? \\Q2015\\E",
      "shortCiteRegEx" : "Dwork et al\\.",
      "year" : 2015
    }, {
      "title" : "Preserving statistical validity in adaptive data analysis",
      "author" : [ "Cynthia Dwork", "Vitaly Feldman", "Moritz Hardt", "Toniann Pitassi", "Omer Reingold", "Aaron Roth" ],
      "venue" : "In ACM Symposium on the Theory of Computing (STOC)",
      "citeRegEx" : "Dwork et al\\.,? \\Q2015\\E",
      "shortCiteRegEx" : "Dwork et al\\.",
      "year" : 2015
    }, {
      "title" : "The reusable holdout: Preserving validity in adaptive data analysis",
      "author" : [ "Cynthia Dwork", "Vitaly Feldman", "Moritz Hardt", "Toniann Pitassi", "Omer Reingold", "Aaron Roth" ],
      "venue" : "Science,",
      "citeRegEx" : "Dwork et al\\.,? \\Q2015\\E",
      "shortCiteRegEx" : "Dwork et al\\.",
      "year" : 2015
    }, {
      "title" : "Our data, ourselves: Privacy via distributed noise generation",
      "author" : [ "Cynthia Dwork", "Krishnaram Kenthapadi", "Frank McSherry", "Ilya Mironov", "Moni Naor" ],
      "venue" : "In EUROCRYPT,",
      "citeRegEx" : "Dwork et al\\.,? \\Q2006\\E",
      "shortCiteRegEx" : "Dwork et al\\.",
      "year" : 2006
    }, {
      "title" : "Calibrating noise to sensitivity in private data analysis",
      "author" : [ "Cynthia Dwork", "Frank McSherry", "Kobbi Nissim", "Adam Smith" ],
      "venue" : "In TCC,",
      "citeRegEx" : "Dwork et al\\.,? \\Q2006\\E",
      "shortCiteRegEx" : "Dwork et al\\.",
      "year" : 2006
    }, {
      "title" : "The algorithmic foundations of differential privacy",
      "author" : [ "Cynthia Dwork", "Aaron Roth" ],
      "venue" : "Foundations and Trends in Theoretical Computer Science,",
      "citeRegEx" : "Dwork and Roth.,? \\Q2014\\E",
      "shortCiteRegEx" : "Dwork and Roth.",
      "year" : 2014
    }, {
      "title" : "Boosting and differential privacy",
      "author" : [ "Cynthia Dwork", "Guy N. Rothblum", "Salil P. Vadhan" ],
      "venue" : "In IEEE Symposium on Foundations of Computer Science (FOCS",
      "citeRegEx" : "Dwork et al\\.,? \\Q2010\\E",
      "shortCiteRegEx" : "Dwork et al\\.",
      "year" : 2010
    }, {
      "title" : "Differential privacy. In Automata, Languages and Programming, 33rd International Colloquium, ICALP 2006, Venice, Italy",
      "author" : [ "Cynthia Dwork" ],
      "venue" : "July 10-14,",
      "citeRegEx" : "Dwork.,? \\Q2006\\E",
      "shortCiteRegEx" : "Dwork.",
      "year" : 2006
    }, {
      "title" : "On the ‘semantics’ of differential privacy: A bayesian formulation",
      "author" : [ "Shiva P. Kasiviswanathan", "Adam Smith" ],
      "venue" : "Journal of Privacy and Confidentiality,",
      "citeRegEx" : "Kasiviswanathan and Smith.,? \\Q2014\\E",
      "shortCiteRegEx" : "Kasiviswanathan and Smith.",
      "year" : 2014
    }, {
      "title" : "Controlling bias in adaptive data analysis using information theory",
      "author" : [ "Daniel Russo", "James Zhou" ],
      "venue" : "Novemver",
      "citeRegEx" : "Russo and Zhou.,? \\Q2015\\E",
      "shortCiteRegEx" : "Russo and Zhou.",
      "year" : 2015
    }, {
      "title" : "A minimax theory for adaptive data analysis",
      "author" : [ "Yu-Xiang Wang", "Jing Lei", "Stephen E. Fienberg" ],
      "venue" : null,
      "citeRegEx" : "Wang et al\\.,? \\Q2016\\E",
      "shortCiteRegEx" : "Wang et al\\.",
      "year" : 2016
    } ],
    "referenceMentions" : [ ],
    "year" : 2017,
    "abstractText" : "In this paper, we introduce a new notion of algorithmic stability called typical stability. When our goal is to release real-valued queries (statistics) computed over a dataset, this notion does not require the queries to be of bounded sensitivity – a condition that is generally assumed under a standard notion of algorithmic stability known as differential privacy [DMNS06, Dwo06]. Instead, typical stability requires the output of the query, when computed on a dataset drawn from the underlying distribution, to be “well-concentrated” around its expected value with respect to that distribution. Typical stability can also be motivated as an alternative definition for database privacy (in such case, we call it typical privacy). Like differential privacy, this notion enjoys several important properties including robustness to post-processing and adaptive composition. We also discuss the guarantees of typical stability on the generalization error (i.e., the difference between the value of the query computed on the dataset and the expected value of the query with respect to the true data distribution). We show that these guarantees hold for a broader class of queries than that of bounded-sensitivity queries. This class contains all queries whose output distributions have a “light” tail, e.g., subgaussian and subexponential queries. In particular, we show that if a typically stable interaction with a dataset yields a query from that class, then this query when evaluated on the same dataset will have small generalization error with high probability (i.e., it will not overfit to the dataset). We discuss the composition guarantees of typical stability and prove a composition theorem that gives a characterization of the degradation of the parameters of typical stability/privacy under k-fold adaptive composition. We also give simple noise-addition algorithms that achieve this notion. These algorithms are similar to their differentially private counterparts, however, the added noise is calibrated differently. ∗University of California San Diego, Center for Information Theory and Applications and Department of Computer Science and Engineering. rbassily@ucsd.edu †University of California San Diego, Department of Computer Science and Engineering. yfreund@eng.ucsd.edu ar X iv :1 60 4. 03 33 6v 1 [ cs .L G ] 1 2 A pr 2 01 6",
    "creator" : "LaTeX with hyperref package"
  }
}