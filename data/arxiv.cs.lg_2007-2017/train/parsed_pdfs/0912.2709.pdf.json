{
  "name" : "0912.2709.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "The Gaussian Surface Area and Noise Sensitivity of Degree-d Polynomials",
    "authors" : [ "Daniel M. Kane" ],
    "emails" : [ ],
    "sections" : [ {
      "heading" : null,
      "text" : "ar X\niv :0\n91 2.\n27 09\nv1 [\ncs .C\nC ]\n1 4\nD ec\n2 00\n9\nThe Gaussian Surface Area and Noise Sensitivity\nof Degree-d Polynomials\nDaniel M. Kane\nDecember 15, 2009"
    }, {
      "heading" : "1 Introduction",
      "text" : "We provide asymptotically sharp bounds for the Gaussian surface area and the Gaussian noise sensitivity of polynomial threshold functions. In particular we show that if f is a degree-d polynomial threshold function, then its Gaussian sensitivity at noise rate ǫ is less than some quantity asymptotic to d √ 2ǫ\nπ and the\nGaussian surface area is at most d√ 2π . Furthermore these bounds are asymptotically tight as ǫ → 0 and f the threshold function of a product of d distinct homogeneous linear functions.\nThe noise sensitivity and surface area are both of fundamental interest and useful in the analysis of agnostic learning algorithms (see [6]). In particular our results imply that the class of degree-d polynomial threshold functions is agnostically learnable under the n-dimensional Gaussian distribution in time nO(d\n2/ǫ4). A number of other authors have attempted to prove bounds along these lines. [7] proves a bound on noise sensitivity in terms of surface area and we relate our bounds essentially by also proving the other direction of this inequality for boolean functions with smooth interface that switch signs a bounded number of times on any line through the origin. Our bounds are obtained via a simple computation in the case of d = 1. A bound of Õ(ǫ1/(2d)) noise sensitivity was recently proved by [3] and independently by [5] for multilinear polynomials.\nThere is also interest in related questions for points picked uniformly from vertices of the hypercube rather than with the Gaussian distribution. It is conjectured in [4] that the corresponding noise sensitivity in this case is also always O(d √ ǫ). The d = 1 case of this conjecture was proved by [8], improving upon a bound of O(ǫ1/4) of [2]. It is noted in [3] that such a result would imply a similar bound for the Gaussian case. Hence our results can be thought of as a first step toward proving this conjecture."
    }, {
      "heading" : "1.1 Basic Definitions",
      "text" : "Given a function f : Rn → {−1, 1} we define the Gaussian noise sensitivity at noise rate ǫ as GNSǫ(f) := Pr(f(X) 6= f(Z)) where X is an n-dimensional Gaussian random variable, and Z = (1 − ǫ)X +√ 2ǫ− ǫ2Y for Y an independent n-dimensional Gaussian. This is closely related to the Gaussian surface area of f−1(1). In particular we define the Gaussian surface area of a set A to be\nΓ(A) := lim inf δ→0 GaussianVolume(Aδ\\A) δ .\nWhere the Gaussian volume of a region R is Pr(X ∈ R) for X a Gaussian random variable, and where Aδ is the set of points x so that d(x,A) ≤ δ (under the Euclidean metric). We note that if A is an open region whose boundary is smooth away from codimension 2, that its Gaussian surface area is equal to\n∫\n∂A\nφ(x)dσ.\nWhere φ(x) is the Gaussian density, and dσ is the surface measure on ∂A. Furthermore if A is such a region, then its Gaussian surface area is seen to be equal to\nlim δ→0\nGaussianVolume((∂A)δ)\n2δ .\nFor f a boolean function, we define\nΓ(f) := Γ(f−1(1)).\nThe concepts of noise sensitivity and surface area are related to each other by noting that the noise sensitivity is roughly the probability that X is close enough to the boundary that wiggling it will push it over the boundary."
    }, {
      "heading" : "1.2 Statement of Results",
      "text" : "We focus on proving two main results. We define f to be a degree d polynomial threshold function if f(x) = sgn(p(x)) for some degree d polynomial p. We prove the following Theorems about such functions:\nTheorem 1. If f is a degree d polynomial threshold function, then\nGNSǫ(f) ≤ d arcsin(\n√ 2ǫ− ǫ2)\nπ ∼ d\n√ 2ǫ\nπ = O(d\n√ ǫ).\nFurthermore this bound is asymptotically tight as ǫ → 0 for the threshold function of any product of distinct linear functions.\nTheorem 2. If f is a degree-d polynomial threshold function then Γ(f) ≤ d√ 2π .\nSection 2 will be devoted to the proof of Theorem 1, Section 3 to the proof of Theorem 2, and Section 4 will provide some closing notes."
    }, {
      "heading" : "2 Proof of the Noise Sensitivity Bound",
      "text" : "Proof of Theorem 1. We begin by letting θ = arcsin( √ 2ǫ− ǫ2). We need to bound p := GNSǫ(f) = Pr(f(X) 6= f(cos(θ)X + sin(θ)Y )). (1)\nWe note that the value of p given in Equation 1 remains the same if X and Y are replaced by any X ′ and Y ′ that are i.i.d. Gaussian distributions. In particular we define\nXφ = cos(φ)X + sin(φ)Y.\nNote that Xφ and Xφ+π/2 are i.i.d. Gaussians. Using these distributions we find that for any φ that since\nXθ+φ = cos(θ + φ)X + sin(θ + φ)Y\n= cos(θ) cos(φ)X − sin(θ) sin(φ)X + cos(θ) sin(φ)Y + sin(θ) cos(φ)Y = cos(θ)Xφ + sin(θ)Xφ+π/2,\nwe have p = Pr(f(Xφ) 6= f(Xφ+θ)).\nTherefore we have for any integer n that\nnp = Pr(f(X0) 6= f(Xθ))+Pr(f(Xθ) 6= f(X2θ))+. . .+Pr(f(X(n−1)θ) 6= f(Xnθ)). (2) We define the random function F : R → {−1, 1} by\nF (φ) = f(Xφ).\n(F depends on X and Y as well as φ). We note that the left hand side of Equation 2 is at most the number of times that F (φ) changes signs on the interval [0, nθ]. Therefore we have that\np ≤ E[number of times F changes signs on [0, nθ]] n . (3)\nWe note that F (φ) is periodic in φ with period 2π. Therefore the number of times F changes sign on [0, nθ] is the number of times that F changes sign on [0, 2π) times (\nnθ 2π +O(1)\n)\n. Applying this to Equation 3, we get that\np ≤ E[number of sign changes of F on [0, 2π)] ( nθ 2π +O(1) )\nn .\nTaking a limit as n → ∞ yields\np ≤ θE[number of sign changes of F on [0, 2π]] 2π . (4)\nWe now make use of the fact that f is a degree d polynomial threshold function. In particular we will show that for any X and Y that F changes signs\nat most 2d times on [0, 2π). We let f = sgn(g) for some degree d polynomial g. We note that the number of sign changes of F is equal to the number of zeroes of the function g(cos(φ)X + sin(φ)Y ) (unless this function is identically 0, which happens with probability 0 and can be ignored). It should be noted though that g(cos(φ)X + sin(φ)Y ) = 0 if and only if z = eiφ is a root of the degree-2d polynomial\nzdg\n((\nz + z−1\n2\n)\nX +\n(\nz − z−1 2i\n)\nY\n)\n.\nTherefore the expectation in Equation 4 is at most 2d. Therefore we have\np ≤ 2dθ 2π = dθ π\nas desired. We also note the ways in which the above bound can fail to be tight. Firstly, there may be some probability that F changes signs less than 2d times on a full circle. Secondly, the number of times F changes signs may be more than the fraction of the time that f(nθ) 6= f((n + 1)θ) if sign changes are spaced more tightly than θ. On the other hand it should be noted that if f is the threshold function for a product of d distinct homogeneous linear functions, the first case happens with probability 0, and the probability of the second case occurring will necessarily go to 0 as ǫ does. Therefore for such functions our bound is asymptotically correct as ǫ → 0."
    }, {
      "heading" : "3 Proof of the Gaussian Surface Area Bounds",
      "text" : "We will first need to bound a slight variant of the noise sensitivity of a polynomial threshold function. We begin by proving the following Lemma:\nLemma 3. If f is a degree d polynomial threshold function in n dimensions, ǫ > 0 and X a random Gaussian variable, then\nPr(f(X) 6= f(X(1 + ǫ))) ≤ dǫ √ n\n4π .\nProof. First note that by first conditioning on the line that X lies in we may reduce this problem to the case of a one dimensional distribution. Note that f changes sign at most d times along this line. We need to bound the probability that at least one of these sign changes is between X and (1 + ǫ)X . It therefore suffices to prove that for any one of these sign changes, that it lies between X and (1 + ǫ)X with probability at most ǫ √\nn 4π . Note that the probability\nthat X is on the correct side of the origin is 12 . Beyond that |X |2 satisfies the χ2 distribution with n degrees of freedom, namely 1\n2n/2Γ(n/2) xn/2−1e−x/2dx.\nLetting y = log(x) = 2 log(|X |) we find that that y has distribution 1\n2n/2Γ(n/2) eny/2e−e y/2dy.\nWe want the probability that y is within a particular range of size 2 log(1 + ǫ). This is at most 2ǫ times the densest part of the density function. This is achieved when ny − ey is maximal, or when y = log(n). Then the density is\n1\n2n/2Γ(n/2) nn/2e−n/2 =\n√\nn\n4π\n(n/2)n/2e−n/2 √ 2π(n/2)\n(n/2)! ≤\n√\nn\n4π .\nMultiplying this by d, 2ǫ and 12 (the probability that X is on the correct side of 0), we get our bound. Notice also that this bound should be nearly sharp if the polynomial giving f is a product of terms of the form |X |2 − ri for ri approximately n and spaced apart by factors of (1 + ǫ)2.\nWe can now prove a bound on a quantity more relevant to Gaussian surface area:\nCorollary 4. If f is an n dimensional, degree d polynomial threshold function, ǫ > 0 and X and Y independent Gaussians, then\nPr(f(X) 6= f(X + ǫY )) ≤ dǫ π + dǫ2 4\n√\nn π .\nProof. We let r = √ 1 + ǫ2, θ = arctan(ǫ), and let Z = cos(θ)X + sin(θ)Y be a normal random variable. Note that X + ǫY = rZ. We then have that\nPr(f(X) 6= f(X + ǫY )) ≤ Pr(f(X) 6= f(Z)) + Pr(f(Z) 6= f(rZ)).\nBy Theorem 1 and Lemma 3 this is at most\ndθ\nπ + d(r − 1)\n√\nn 4π ≤ dǫ π +\ndǫ2\n4\n√\nn π .\nIn particular, we relate this to Gaussian surface area by:\nLemma 5. If f is a boolean function with f−1(1) open with smooth boundary and Gaussian area S, and if X and Y are independent Gaussians then,\nlim ǫ→0 Pr(f(X) = −1 and f(X + ǫY ) = 1) ǫ = S√ 2π . (5)\nProof. First note that if A = f−1(1), then\nlim ǫ→0 GaussianVolume(Aǫ\\A) ǫ = S\nrather than just the liminf being equal. Next note that since the probability that |ǫY | > ǫ2/3 goes rapidly to 0 as ǫ → 0, we can throw away all cases where X is not within ǫ2/3 of ∂A from the left hand side of Equation 5. When X is close to ∂A and when f(X) = −1, we may approximate the probability that\nf(X + ǫY ) = 1 by the probability that the component of ǫY in the direction of the shortest path from X to A is more than d(X,A). Since ∂A is smooth, this approximation is accurate for X close to A, and in particular for X within ǫ2/3 should introduce an error of O(ǫ4/3), which can be ignored. Hence if Z is a normalized one variable Gaussian, the numerator of left hand side can be replaced by\nPr(ǫZ ≥ d(X,A) > 0) = Pr ( Z ≥ d(X,A) ǫ > 0 ) .\nThis is easily seen to be ∫ ∞\n0\n1√ 2π e−x 2/2Pr(0 < d(X,A) ≤ ǫx)dx =\n∫ ∞\n0\n1√ 2π e−x 2/2GVol(Aǫx\\A)dx\n=\n∫ ∞\n0\n1√ 2π e−x 2/2Sǫx(1 + o(1))dx\n= Sǫ√ 2π + o(ǫ).\nThus completing our proof.\nProof of Theorem 2. This follows immediately from Corollary 4 and Lemma 5 after noting that\nPr(f(X) = −1, f(X + ǫY ) = 1) ∼ 1 2 Pr(f(X) 6= f(X + ǫY )) ∼ dǫ 2π ."
    }, {
      "heading" : "4 Conclusion",
      "text" : "We have shown nearly tight bounds on the Gaussian surface area and noise sensitivity of polynomial threshold functions. One might hope to generalize these results to work for other distributions, such as the uniform distribution on vertices of the hypercube. Unfortunately, several aspects of this proof are difficult to generalize. Perhaps most significantly, we lose the symmetry that allowed us to prove our original result on noise sensitivity. Another difficulty would be in the relation between noise sensitivity and surface area. In our case the two are essentially equivalent quantities of study. On the other hand [6] defined a notion of surface area for the hypercube distribution and proved that for even linear threshold functions there could be a gap between noise sensitivity and surface area of as much as Θ( √ log(n))."
    } ],
    "references" : [ {
      "title" : "The Reverse Isoperimetric Problem for Gaussian Measure",
      "author" : [ "K. Ball" ],
      "venue" : "Discrete and Computational Geometry,",
      "citeRegEx" : "1",
      "shortCiteRegEx" : "1",
      "year" : 1993
    }, {
      "title" : "Noise sensitivity of Boolean functions and applications to percolation, Inst",
      "author" : [ "I. Benjamini", "G. Kalai", "O. Schramm" ],
      "venue" : "Hautes Etudes Sci. Publ. Math.,",
      "citeRegEx" : "2",
      "shortCiteRegEx" : "2",
      "year" : 2001
    }, {
      "title" : "Average sensitivity and noise sensitivity of polynomial threshold functions, Manuscript, available at http://arxiv.org/abs/0909.5011",
      "author" : [ "I. Diakonikolas", "P. Raghavendra", "R. Servedio", "L.-Y. Tan" ],
      "venue" : null,
      "citeRegEx" : "3",
      "shortCiteRegEx" : "3",
      "year" : 2009
    }, {
      "title" : "Bounding the sensitivity of polynomial threshold functions, Manuscript, available at http://arxiv.org/abs/0909.5175",
      "author" : [ "P. Harsha", "A. Klivans", "R. Meka" ],
      "venue" : null,
      "citeRegEx" : "5",
      "shortCiteRegEx" : "5",
      "year" : 2009
    }, {
      "title" : "Learning Geometric Concepts via Gaussian Surface Area",
      "author" : [ "Adam R. Klivans", "Ryan O’Donnell", "Rocco A. Servedio" ],
      "venue" : null,
      "citeRegEx" : "6",
      "shortCiteRegEx" : "6",
      "year" : 2008
    }, {
      "title" : "Semigroup proofs of the isoperimetric inequality in Euclidean and Gauss space",
      "author" : [ "M. Ledoux" ],
      "venue" : "Bull. Sci. Math.,",
      "citeRegEx" : "7",
      "shortCiteRegEx" : "7",
      "year" : 1994
    }, {
      "title" : "Noise Stability of Weighted Majority",
      "author" : [ "Yuval Peres" ],
      "venue" : "Manuscript, available at http://arxiv.org/abs/math/0412377,",
      "citeRegEx" : "8",
      "shortCiteRegEx" : "8",
      "year" : 2004
    } ],
    "referenceMentions" : [ {
      "referenceID" : 4,
      "context" : "The noise sensitivity and surface area are both of fundamental interest and useful in the analysis of agnostic learning algorithms (see [6]).",
      "startOffset" : 136,
      "endOffset" : 139
    }, {
      "referenceID" : 5,
      "context" : "[7] proves a bound on noise sensitivity in terms of surface area and we relate our bounds essentially by also proving the other direction of this inequality for boolean functions with smooth interface that switch signs a bounded number of times on any line through the origin.",
      "startOffset" : 0,
      "endOffset" : 3
    }, {
      "referenceID" : 2,
      "context" : "A bound of Õ(ǫ) noise sensitivity was recently proved by [3] and independently by [5] for multilinear polynomials.",
      "startOffset" : 57,
      "endOffset" : 60
    }, {
      "referenceID" : 3,
      "context" : "A bound of Õ(ǫ) noise sensitivity was recently proved by [3] and independently by [5] for multilinear polynomials.",
      "startOffset" : 82,
      "endOffset" : 85
    }, {
      "referenceID" : 6,
      "context" : "The d = 1 case of this conjecture was proved by [8], improving upon a bound of O(ǫ) of [2].",
      "startOffset" : 48,
      "endOffset" : 51
    }, {
      "referenceID" : 1,
      "context" : "The d = 1 case of this conjecture was proved by [8], improving upon a bound of O(ǫ) of [2].",
      "startOffset" : 87,
      "endOffset" : 90
    }, {
      "referenceID" : 2,
      "context" : "It is noted in [3] that such a result would imply a similar bound for the Gaussian case.",
      "startOffset" : 15,
      "endOffset" : 18
    }, {
      "referenceID" : 4,
      "context" : "On the other hand [6] defined a notion of surface area for the hypercube distribution and proved that for even linear threshold functions there could be a gap between noise sensitivity and surface area of as much as Θ( √",
      "startOffset" : 18,
      "endOffset" : 21
    } ],
    "year" : 2009,
    "abstractText" : "We provide asymptotically sharp bounds for the Gaussian surface area and the Gaussian noise sensitivity of polynomial threshold functions. In particular we show that if f is a degree-d polynomial threshold function, then its Gaussian sensitivity at noise rate ǫ is less than some quantity asymptotic to d √ 2ǫ π and the Gaussian surface area is at most d √ 2π . Furthermore these bounds are asymptotically tight as ǫ → 0 and f the threshold function of a product of d distinct homogeneous linear functions. The noise sensitivity and surface area are both of fundamental interest and useful in the analysis of agnostic learning algorithms (see [6]). In particular our results imply that the class of degree-d polynomial threshold functions is agnostically learnable under the n-dimensional Gaussian distribution in time n 2/ǫ4). A number of other authors have attempted to prove bounds along these lines. [7] proves a bound on noise sensitivity in terms of surface area and we relate our bounds essentially by also proving the other direction of this inequality for boolean functions with smooth interface that switch signs a bounded number of times on any line through the origin. Our bounds are obtained via a simple computation in the case of d = 1. A bound of Õ(ǫ) noise sensitivity was recently proved by [3] and independently by [5] for multilinear polynomials. There is also interest in related questions for points picked uniformly from vertices of the hypercube rather than with the Gaussian distribution. It is conjectured in [4] that the corresponding noise sensitivity in this case is also always O(d √ ǫ). The d = 1 case of this conjecture was proved by [8], improving upon a bound of O(ǫ) of [2]. It is noted in [3] that such a result would imply a similar bound for the Gaussian case. Hence our results can be thought of as a first step toward proving this conjecture.",
    "creator" : "LaTeX with hyperref package"
  }
}