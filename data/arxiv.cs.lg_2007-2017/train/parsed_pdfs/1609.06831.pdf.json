{
  "name" : "1609.06831.pdf",
  "metadata" : {
    "source" : "META",
    "title" : "Hawkes Processes with Stochastic Excitations",
    "authors" : [ "Young Lee", "Kar Wai Lim", "Cheng Soon Ong" ],
    "emails" : [ "YOUNG.LEE@NICTA.COM.AU", "KARWAI.LIM@ANU.EDU.AU", "CHENGSOON.ONG@ANU.EDU.AU" ],
    "sections" : [ {
      "heading" : "1. Introduction",
      "text" : "Motivation. Cascading chain of events usually arise in nature or society: The economy has witnessed that financial meltdowns are often epidemic. For example, the Asian financial crisis swept across Thailand and quickly engulfed South Africa, Eastern Europe and even Brazil. Similarly, criminological research (Bernasco and Nieuwbeerta, 2005) has shown that crime can spread through local environments very rapidly where burglars will constantly attack nearby targets because local susceptibilities are well\nProceedings of the 33 rd International Conference on Machine Learning, New York, NY, USA, 2016. JMLR: W&CP volume 48. Copyright 2016 by the author(s).\nknown to thieves. As another example, in genetic analysis, Reynaud-Bouret and Schbath (2010) looked at the likelihood of occurrences of a particular event along the DNA sequence where ‘an event’ could be any biological signals occurring along the genomes that tend to cluster together.\nThe defining characteristic of these examples is that the occurrence of one event often triggers a series of similar events. The Hawkes process, or otherwise known as the self-exciting process, is an extension of Poisson processes that aims to explain excitatory interactions (Hawkes, 1971). What makes the term self-excitation worthy of its name is typically not the occurrence of the initial event, but the intensification of further events. We seek to characterize this amplification magnitude, which we call the contagion parameters, or levels of self-excitation, or simply, levels of excitation.\nThe use of Hawkes processes is not an attempt to describe all features of self-excitation in their correct proportions. Probabilistic modeling inevitably exaggerates some aspects while disregarding others, and an accurate model is one that takes care of the significant aspects and abandons the less important details. Thus, there are often two streams in modeling which are fairly contradictory; on the one hand, the model ought to mimic excitatory relationships in a real world application, and this pulls toward specifying wide families of processes. On the other hand, the model should be manageable and tractable which pulls in the direction of identifying simpler processes in which inference and parameter estimations are feasible.\nAdopting the latter view of establishing simpler processes, we present a version of self-exciting processes that permits the levels of excitation to be modulated by a stochastic differential equation (SDE). SDEs are natural tools used to describe rate of change between the excitation levels. Put differently, we attach some indeterminacy to these quantities where we model them as random values over time, rather than being a constant as in the classical Hawkes set-\nar X\niv :1\n60 9.\n06 83\n1v 1\n[ cs\n.L G\n] 2\n2 Se\np 20\nting (Hawkes, 1971; Ozaki, 1979). Our formulation implies that the contagion parameters are random processes thus inheriting tractable covariance structures, in contrast to the set-up initiated by Brémaud and Massoulié (2002) and Dassios and Zhao (2011), where contagion levels are independent and identically distributed (iid) random.\nContributions. We present a model that generalizes classical Hawkes and new insights on inference. Our noteworthy contributions are as follows: (1) We propose a fully Bayesian framework to model excitatory relationships where the contagion parameters are stochastic processes satisfying an SDE. This new feature enables the control of the varying contagion levels through periods of excitation. (2) With n denoting the counts of events, we design a sampling procedure that scales with complexityO(n) compared to a naïve implementation of Ogata’s modified thinning algorithm (Ogata, 1981) which needs O(n2) steps. (3) A hybrid of MCMC algorithms that provide significant flexibility to do parameter estimation for our self-exciting model is presented. In addition, we describe how to construct two SDEs over periods of unequal lengths and introduce general procedures for inference. (4) We conclude by making explicit deductive connections to two related areas in machine learning; (i) the ‘E-step’ of the expectation maximization (EM) algorithm for Hawkes processes (Veen and Schoenberg, 2008; Ogata, 1981) and (ii) modeling the volatility clustering phenomenon."
    }, {
      "heading" : "2. Our Model : Stochastic Hawkes",
      "text" : ""
    }, {
      "heading" : "2.1. Review of Poisson and Classical Hawkes Processes",
      "text" : "This section recapitulates some pieces of counting process theory needed in what follows. The Poisson process is frequently used as a model for counting events occurring one at a time. Formally, the Poisson process with constant intensity λ is a process N = {Nt := N(t) : t ≥ 0} taking values in S = {0, 1, 2, ...} such that: (a) N0 = 0; if s < t, then Ns ≤ Nt, (b) P(Nt+h = n + m |Nt = n) takes values λh+ o(h) if m = 1, o(h) if m > 1, and 1−λh+ o(h) if m = 0 where o(h) denotes any function h that satisfies o(h)/h → 0 as h → 0. In addition, if s < t, the number Nt − Ns of events in the interval (s, t] is independent to the times of events during (0, s]. We speak of Nt as the number of ‘arrivals’ or ‘events’ of the process by time t. However, events usually do not arrive in evenly spaced intervals but naturally arrive clustered in time. The Classical Hawkes process aims at explaining such phenomenon. It is a point process N whose intensity λt depends on the path mirrored by the point process over time. Precisely, the point process is determined by λt through the following relations: P(Nt+h = n + m |Nt = n) takes values λth+ o(h) if m = 1, o(h) if m > 1, and 1−λth+ o(h) if 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164\n165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219\nSubmission and Formatting Instructions for ICML 2016\n0\n1\n2\n3\n2\n1\n0\n1\n0\nT1 T2 T3 T4 T5 T6 T7 T8 T9\nNote the variation of heights for Y5 and Y6\nZ10 = 1\nZ20 = 1\nZ32 = 1\nT1 T2 T3 T4 T5 T6 T7\nFigure 1. A sample path of the intensity function λ(·). First note that the red region represents the base intensity λ̂0(t), which is assumed to be a constant in this diagram. Each colored region, except the red, represents the excitation contributed by each event time. For example, the blue region is contributed by T2, which in turn is represented by the blue dot. Further, note that the blue dot lies in the interior of the red region, indicating that it is an immigrant. Mathematically, this is represented by Z20 = 1. On the other hand, the offspring of the second event T2 is represented by the maroon dot, which is right on top of T3. We denote this by Z32 = 1. Observe that this offspring immediately induces another region to be conceived, which is consistently colored in maroon. Stochastic Hawkes is capable of capturing and resembling different levels of contagion and this is evident from the differing heights in Y at the event times T5 and T6, where we also allow for a non-zero covariance structure, i.e., Cov(Y5, Y6) 6= 0. Finally, it is important to note that the higher the intensity λ(·) is, the stronger the rate of decay is. In other words, the gradient is the same for a fixed intensity level, which is a property of the exponential kernel ν.\nm = 0, where λt = c0 + ∑ i:t>Ti\nc1 exp(−c2(t− Ti)) for positive constants c0, c1 and c2."
    }, {
      "heading" : "2.2. Proposed Model Specification and Interpretation",
      "text" : "We define our model as a linear self-exciting process N(t) endowed with a non-negative Ft–stochastic intensity function λ(t):\nλ(t) = λ̂0(t) + ∑ i:t>Ti Y (Ti) ν(t− Ti) (1)\nwhere λ̂0 : R 7→ R+ is a deterministic base intensity, Y is a stochastic process and ν : R 7→ R+ conveys the positive influence of the past events Ti on the current value of the intensity process. We write Nt := N(t), λt := λ(t) and Yi := Y (Ti) to ease notation and {Ft} being the history\nof the process and contains the list of times of events up to and including t, i.e. {T1, T2, ..., TNt}. Figure 1 illustrates the different components of our model, which we explain in the following subsections.\n2.2.1. BASE INTENSITY, λ̂0 This parameter is the base or background intensity describing the arrival of external-originating events in the absence of the influence of any previous events. These events are also known as exogenous events. By way of analogy, the base rate is referred to as the ‘immigrant intensity’ in ecological applications (Law et al., 2009), where it describes the rate with which new organisms are expected to arrive from other territories and colonies. In our case λ̂0(t) is a function of time and takes the form λ̂0(t) = a + (λ0 − a)e−δt where λ0 > 0 is the initial intensity jump at time t = 0, a > 0 is the constant parameter, and δ > 0 is the constant rate of exponential decay.\n2.2.2. THE CONTAGION PROCESS, (Yi)i=1,2,...\nThe levels of excitation Y measure the impact of clustering or contagion of the event times. To see this, observe in Equation (1) that whenever Y is high and of positive value, it imposes a greater value to the intensity λ, thus increasing the probability of generating an event in a shorter period of time, thereby causing the clustering phenomena.\nWe use differential equations to describe the evolution of the levels of excitation. Translating the evolution of contagiousness into the language of mathematics means setting up an equation containing a derivative (or an integral), discussed further below. The changes in the contagion is assumed to satisfy the stochastic differential equation\nY· = ∫ · 0 µ̂(t, Yt) dt+ ∫ · 0 σ̂(t, Yt) dBt\nwhere B is a standard Brownian motion and t ∈ [0, T ] where T < ∞. Different settings of the functionals µ̂ and σ̂ lead to different versions of SDEs.\nAn important criterion for selecting appropriate choices of the couple (µ̂, σ̂) essentially boils down to how we decide to model the levels of excitation within Stochastic Hawkes. A standing assumption is that the contagion process has to be positive, that is,\nAssumption 1 The contagion parameters Yt > 0,∀t ≥ 0.\nThis is necessary as the levels of excitations Y act as a parameter that scales the magnitude of the influence of each past event and subsequently contributes to the quantity λ in Equation (1), which is non-negative.\nSome notable examples of the couple (µ̂, σ̂) are the Geometric Brownian Motion (GBM): µ̂ = (µ + 12σ\n2)Y, σ̂ = σY (Kloeden and Platen, 1999; Zammit-Mangion et al.,\n2012); the Square-Root-Processes: µ̂ = k(µ − Y ), σ̂ = σ √ Y , (Archambeau et al., 2007; Opper et al., 2010); Langevin equation: µ̂ = k(µ − Y ), σ̂ = σ, and their variants (Stimberg et al., 2011; Welling and Teh, 2011; Liptser and Shiryaev, 1978).\nWhilst the positivity of Y is guaranteed for GBM, this may not be true for other candidates such as the Langevin dynamics or the Square-Root-Processes. This is because they possess the inherent property that nothing prevents them from going negative and thus may not be suitable choices to model the levels of excitation. Specifically, Square-RootProcesses can be negative if the Feller condition 2kµ > σ2 is not satisfied (Feller, 1951; Liptser and Shiryaev, 1978). For real-life applications, this condition may not be respected, thus violating Assumption 1.\nTo that end, we focus on two specifications of the SDEs, namely the GBM and we tilt the Langevin dynamics by exponentiating it so that the positivity of Y is ensured (Black and Karasinski, 1991):\n• Geometric Brownian Motion (GBM):\nY· = ∫ · 0 ( µ+ 1 2 σ2 ) Yt dt+ ∫ · 0 σYt dBt (2)\nwhere µ ∈ R and σ > 0.\n• Exponential Langevin:\nY· = exp (∫ · 0 k(µ− Yt) dt+ ∫ · 0 σ dBt ) (3)\nwhere k, µ ∈ R and σ > 0.\nThe parameter k for exponential Langevin denotes the decay or growth rate and it signifies how strongly the levels of excitation reacts to being pulled toward the asymptotic mean, µ. For fixed σ and µ, a small value of k implies Y is not oscillating about the mean.\n2.2.3. THE SUM PRODUCT, ∑ i:t>Ti Y (Ti) ν(t−Ti).\nThe product Y ν describes the impact on the current intensity of a previous event that took place at time Ti. We take ν to be the exponential kernel of the form ν(t) = e−δt. Note that δ is being shared between the base intensity λ̂0 and the kernel ν to ensure that the process has memoryless properties (see Hawkes and Oakes, 1974; Ozaki, 1979). The memoryless property states the following: given the present, the future is independent of the past. We exploit this property to design our sampling algorithm so that we do not need to track all of its past history, only the present event time matters. This would not have been possible, if we were to use a power kernel (Ogata, 1998), say. In addition, choosing this kernel enables us to derive Gibbs sampling procedures to facilitate efficient inference.\nSummarizing, the intensity of our model becomes:\nλt = a+ (λ0 − a)e−δt + Nt∑\ni:Ti<t\nYi e −δ(t−Ti). (4)\nIf we set Y to be a constant, we retrieve the model proposed by Hawkes (1971). In addition, setting Y = 0 returns us the inhomogeneous Poisson process. Furthermore, letting Y = 0 and λ0 = a simplifies it to the Poisson process."
    }, {
      "heading" : "2.3. The Branching Structure for Stochastic Hawkes",
      "text" : "This section presents a generative view of our model that permits a systematic treatment of situations where each of the observed event times can be separated into immigrants and offsprings, terminologies that we shall define shortly. This is integral to deriving efficient inference algorithms.\nWe call an event time Ti an immigrant if it is generated from the base intensity a + (λ0 − a)e−δt, otherwise, we say Ti is an offspring. This is known as the branching structure. It is therefore natural to introduce a variable that describes the specific process to which each event time Ti corresponds to. We do that by introducing the random variables Zij , where Zi0 = 1 if event i is an immigrant, and Zij = 1 if event i is an offspring of event j. We illustrate and elucidate the branching structure through Figure 1. For further details on classification of Hawkes processes via the branching structure, refer to Rasmussen (2013) and Daley and Vere-Jones (2003)."
    }, {
      "heading" : "2.4. Advantages of Stochastic Contagion",
      "text" : "Before we dive into the technical definitions of simulating samples for our point process and performing parameter inference, we illustrate the effect of model choice. The levels of contagion Y can necessarily come in different flavors: be it a constant, as in the standard classical Hawkes, or a sequence of iid random variables, or satisfying an SDE.\nFirst we generate levels of contagion Y following a GBM, see Figure 2(a). Performing inference by learning Y as a GBM leads to good estimation as indicated in Figure 2(b). However, if we let Y to be Gamma distributed, we are less able to reproduce the properties of the ground truth, as is evident from Figure 2(c). This is fairly intuitive as the Gamma distribution does not inherit any serial correlation between the samples as they are iid, whereas the ground truth does possess correlation structure of a Geometric Brownian Motion.\nProceeding further, this time with the ground truth Y inheriting iid Gamma random variables, as illustrated in Figure 2(d). Learning Y as Gamma in our model leads to good inference as illustrated in Figure 2(e). Further, letting Y to be a GBM enables us to learn some properties of the ground truth this time round, see Figure 2(f). Comparing Figures 2(a) & (c) against Figures 2(d) & (f), we conclude that a fairly general formulation for the level of contagion, such as the GBM, is advantageous in recovering stylized facts of an iid random levels of contagion, but not vice versa."
    }, {
      "heading" : "2.5. Likelihood Function",
      "text" : "This section explicates the likelihood with the presence of an SDE and the branching structure within Stochastic Hawkes. The derivation is new and merits discussion here. A key result is that the integrated intensity function Λt :=\n∫ t 0 λv dv can be derived explicitly, that is,∫ t\n0\nλv dv = ∫ t 0 ( a+(λ0−a)e−δv+ Nv∑ i=1 Yie −δ(t−v) ) dv\n(i) = ∫ t 0 a+ (λ0 − a)e−δvdv + ∫ t 0 ∫ v 0 Yse −δ(v−s)dNsdv\n(ii) = ∫ t 0 a+ (λ0 − a)e−δvdv + ∫ t 0 ∫ t s Yse −δ(v−s)dvdNs\n(iii) = at+ (λ− a)(1− e−δt) δ + 1 δ Nt∑ i=1 Yi ( 1− e−δ(t−Ti) ) where we note the second term for (i) is a Riemann integral over a stochastic integral with respect to N , (ii) is due to Fubini’s Theorem and (iii) follows from the equivalence between stochastic integral and the sum over event times. Consequently, we get the following:\nProposition 1 Let T ,Z,Y be {Ti},{Zi} and {Yi} for i = 1, 2, ..., NT respectively. Assume that no events have occurred before time 0. Further set Ji := {j : 0 < j < i}. Then the likelihood function P(T |Z,Y) is given by e−ΛT NT∏ i=1 ( a+ (λ0 − a)e−δt )Zi0 ∏ j∈Ji [ Yje −δ(Ti−Tj) ]Zij .\nThis generalizes the likelihood function of Lewis and Mohler (2011). It can be viewed that this as an alternative version of the likelihood function found in Daley and Vere-Jones (2003) and Rubin (1972) with the presence of the branching structure coupled with a stochastic process Y . The proof of this result can be found in the Supplemental Materials (Section B)."
    }, {
      "heading" : "3. Simulation of Stochastic Hawkes",
      "text" : "We present a sampling procedure for our Stochastic Hawkes model in Algorithm 1. This algorithm scales with complexity O(n) compared to a naïve implementation of Ogata’s modified thinning algorithm (Ogata, 1981) which requiresO(n2) steps with n denoting the number of events. Similarly to Ozaki (1979) but differently from Ogata’s method, it is noteworthy to mention that our algorithm does not require the stationarity condition for intensity dynamics as long as T <∞.\nAlgorithm 1 Simulation of Stochastic Hawkes\n1. We firstly set T0 = 0, λ (1) 0 = λ0 − a, and given Y0. 2. For i = 1, 2, . . . and while Ti < T : (a) Draw S(0)i = − 1a logU(0, 1). (b) Draw u ∼ U(0, 1). Set S(1)i = − 1δ log ( 1 −\nδ/λ (1) Ti−1\nlog u )\n. Note we set S(1)k :=∞ when the log term is undefined.\n(c) Set Ti = Ti−1 + min ( S (0) i , S (1) i ) . (d) Sample YTi (refer to Algorithm 1 in Supplemental Materials) (e) Update λ(1)Ti = λ (1) Ti−1 e−δ(Ti−Ti−1) + YTi .\nThe outline of Dassios and Zhao (2013) for simulating Hawkes processes is followed closely and adapted to the present setting. The idea of their algorithm is to decompose the inter-arrival event times into two independent simpler random variables, denoted by S(0) and S(1), with the intention that they can be sampled conveniently. Note however that we also need to sample the levels of self-excitation Y , which is a stochastic process in contrast to iid sequences of Y as in Dassios and Zhao (2013).\nWe seek to find laws that describe the GBM and exponential Langevin dynamics. Applying Itô’s formula (see Liptser and Shiryaev, 1978, and Section C in the Supplemental Materials) on f(y) = log(y) and performing discretization for GBM yields\nYi = Yi−1 exp ( µ∆i + √ σ∆i i ) , (5)\nwhere ∆i is introduced as a shorthand for Ti − Ti−1. Similarly for exponential Langevin, the discretization scheme returns\nlog Yi = (log Yi−1)φi + µ(1−φi) + √ σ2\n2k\n( 1− (φi)2 ) i\nwhere we define φi = e−k∆i , i ∼ N(0, 1) is standard normal, and Y0 is known. Both these expressions now allow us to sample Yi for all i. We state the following:\nProposition 2 The simulation algorithm for a sample path of Stochastic Hawkes process is presented in Algorithm 1.\nThe proof of this algorithm presented in the Supplemental Materials (Section A)."
    }, {
      "heading" : "4. Parameter Inference from Observed Data",
      "text" : "We present a hybrid of MCMC algorithms that updates the parameters one at a time, either by direct draws using Gibbs sampling or through the Metropolis–Hastings (MH) algorithm. A hybrid algorithm (Robert and Casella, 2005) combines the features of the Gibbs sampler and the MH algo-\nrithm, thereby providing significant flexibility in designing the inference thereof for the parameters within our model.\nTo see the mechanics of this, consider a two-dimensional parameterization as an illustration. Let θA and θB be parameters of interest. Assume that the posterior P(θB | θA) is of a known distribution, we can perform inference directly utilizing the Gibbs sampler. On the other hand, suppose P(θA | θB) can only be evaluated but not directly sampled; then, we resort to the use of an MH algorithm to update θA given θB . The MH step samples from a proposal distribution Q ( θ′A | θ (j) A , θ (j) B ) which implies that we draw θ (j+1) A ∼ Q ( θ′A | θ (j) A , θ (j) B ) and that the criteria to accept or reject the proposal candidate is based on the acceptance probability, denoted by AP ( θ\n(j+1) A\n) :\nmin ( 1, P ( θ′A | θ (j) B ) Q ( θ (j) A | θ′A, θ (j) B ) P ( θ\n(j) A | θ (j) B ) Q ( θ′A | θ (j) A , θ (j) B )) . (6) The hybrid algorithm is as follows: given ( θ\n(0) A , θ (0) B\n) , for\nj = 0, 1, ...., J iterations: 1. Sample θ(j+1)A ∼ Q ( θ′A | θ (j) A , θ (j) B ) and accept or re-\nject θ(j+1)A based on Equation (6). 2. Sample θ(j+1)B ∼ P ( θB | θ(j+1)A ) with Gibbs sampling.\nWe proceed by explaining the inference of a simple motivating example in Section 4.1. This is the case when the contagion parameters Y are iid random elements. The main inference procedures for Y being stochastic processes can be found in Sections 4.2 and 4.3.\nWe summarize our MCMC algorithm in Algorithm 2.\n4.1. Example: Levels of Excitation Y are iid Random\nThe focus here is on Y to be iid random elements with distribution function G(y), y > 0. To form a suitable model for the problem under consideration, we propose to model Y as a sequence of iid Gamma distribution. This is a slight generalization to the Exponential distribution suggested by Rasmussen (2013) as Gamma distribution contains an additional shape parameter that will help to improve the fitting performance.\nThe Yi are assumed to inherit iid Gamma distribution with shape τ and scale ω: P(y | τ, ω) ∝ yτe−ωy . We also fix Gamma priors for {a, λ0, δ, τ, ω} with hyperparameters {(αm, βm) where m = a, λ0, δ, τ, ω)}. Since all branching structure is equally likely a priori, we have P(Z) ∝ 1. The posterior for Yi follows Gamma distribution, Yi | · ∼ Γ ( τ + ∑NT r=i+1 Zri , ω+ 1−e−δ(T−Ti) δ\n) which can easily be sampled. Turning to the parameters of Y , we note that Gamma prior on ω gives Gamma posterior, ω | · ∼ Γ ( αω + τNT , βω + ∑NT i=1 Yi )\nAlgorithm 2 MCMC Algorithm For Stochastic Hawkes\n1. Initialize the model parameters by sampling from their priors.\n2. For all Zi: Use Gibbs sampler to generate a sequence of Zi using the posterior distribution defined in Equation (7) with parameters derived in Section 4.2.1.\n3. Depending on the choice of SDE so that for all Yi: sample Yi using an MH scheme as tabulated in Table 1 in Supplemental Materials (Section D).\n4. For a, λ0 and δ: sample these quantities with an MH scheme as tabulated in Table 1 in Supplemental Materials (Section D).\n5. For the contagion parameters µ, σ2 and k, perform Gibbs sampling using the posterior parameters derived in Section 4.2.2.\n6. Repeat steps 2–6 until the model parameters converge or when a fixed number of iterations is reached.\nand the acceptance probability for the sampled τ ′ is given by min(1, A(τ ′)) where A(τ ′) takes the form( ωNT ∏NT i=1 Yi )τ ′−τ( τ ′ τ )ατ−1(Γ(τ ′) Γ(τ) )−NT e−(τ ′−τ)βτ ."
    }, {
      "heading" : "4.2. Gibbs Sampling",
      "text" : ""
    }, {
      "heading" : "4.2.1. SAMPLING THE BRANCHING STRUCTURE Z",
      "text" : "The posterior ofZ follows the Multinomial posterior distribution Zi | T ,Y, δ, a, λ0 ∼ Multinomial(µi·) where µi· = µij for all j is a probability matrix (each row sum to 1) satisfying\nµij :=  P(Zi0 = 1) = a+(λ0−a)e−δTi Wi if j = 0\nP(Zij = 1) = Yje −δ(Ti−Tj)\nWi if 0 < j < i\n(7)\nwhere Wi = a+ (λ0 − a)e−δTi + ∑\n0<j<i\nYj e −δ(Ti−Tj) (8)\nis a normalizing constant. In the Gibbs sampler, we sample new Zi directly from its posterior."
    }, {
      "heading" : "4.2.2. SAMPLING THE CONTAGION PARAMETERS",
      "text" : "Geometric Brownian Motion. Let Xi = log(Yi/Yi−1) and X = (X1, X2, ..., XNT ). Given that the joint posterior is given by P(µ, σ2 | X ), we take two independent conjugate priors, P(µ) ∼ N(µ0, σ20) and P(σ2) ∼ ΓInv(α0, β0) where ΓInv refers to the inverse Gamma distribution. Standard calculations yield the posterior distributions P(µ |σ2,X ) ∼ N(µ∗, σ2∗) and P(σ2 |µ,X ) ∼\nΓInv(α∗, β∗) where the posterior parameters are given by\nµ∗ = σ20 ∑NT i=1Xi + µ0σ 2\nσ20 ∑NT i=1 ∆i + σ 2 , σ2∗ = (∑NT i=1 ∆i σ2 + 1 σ20 )−1 ,\n(9)\nand\nα∗ = α0 + NT 2 , β∗ = β0 + 1 2 NT∑ i=1 (Xi − µ∆i)2 ∆i . (10)\nExponential Langevin. We take similar priors for µ, σ2 as in the case for GBM. We further assume that k ∼ N(µk, σ 2 k). The posterior distributions for µ, σ\n2 and k are N(µ̂∗, σ̂ 2 ∗), ΓInv(α̂∗, β̂∗) and N(µ̂k, σ̂ 2 k) with\nµ̂∗= σ20 ∑NT i=1(log Yi−φi log Yi−1)ξi+µ0σ2\nσ20 ∑NT i=1 ξiφ − i +σ 2 , (11)\nas well as\nσ̂2∗ =\n(∑NT k=1 ξiφ − i\nσ2 +\n1\nσ20\n)−1 , (12)\nα̂∗ = α0+ NT 2 , (13)\nand also\nβ̂∗ = β0+ 1\n2 NT∑ k=1 k(log Yi−φi log Yi−1−µφ−i )2 φ−i φ + i . (14)\nRecall that the parameter k expresses the wildness of fluctuation about the mean level µ. A small value of k translates to a volatile Y . If we believe that the levels of self-excitations were erratic, which is of particular interest, then we would want a small value for k. This implies that expanding the power series on the exponential function ex ≈ 1 + x where x := −2k∆i to the first order would be sufficient. This is similar in spirit to the Milstein scheme (Kloeden and Platen, 1999) where higher orders of quadratic variations vanish. For an exact sampling of k, one needs to resort to an MH scheme. In most applications, we can even set k to be a constant and do not perform inference for it. Proceeding, we obtain\nµ̂k = σ2k ∑NT i=1(log Yi−1−µ) + σ2k0\nσ2k NT∑ i=1 ∆i(log Yi−µ)2 + σ2 , (15)\nσ̂2k =\n(∑NT k=1 ∆i(log Yi−µ)\nσ2 +\n1\nσ2k\n)−1 , (16)\nwhere we have used the following shorthand ∆i = Ti −\nTi−1, φi = e−k∆i , φ−i = 1 − φi, φ + i = 1 + φi, and ξi=2k/φ + i throughout the calculations."
    }, {
      "heading" : "4.3. Metropolis-Hastings",
      "text" : "For the case of Y following the GBM, we propose a symmetric proposal for Yi with g(Y ′i |Yi) ∼ N(Yi, σ2Y ). The posterior of Y is P(Y | T ,Z, δ, µ, σ2). The acceptance probability AP for Y ′i is AP (Y ′ i ) = min(1, A(Y ′ i )) where\nA(Y ′i ) = exp − 1 δ (Y ′i − Yi)(1− e−δ(T−Ti))\n− 1 2σ2∆i\n{( log ( Yi+1 Y ′i ) − µ∆i )2 − ( log\n( Yi+1 Yi ) − µ∆i )2} I{Ti+1<T}\n− 1 2σ2∆i\n{( log ( Y ′i Yi−1 ) − µ∆i )2 − ( log\n( Yi Yi−1 ) − µ∆i )2}(Y ′i Yi )∑NT r=i+1 Zri−1\nwhere we have defined TNT+1 =∞ and ∑ r Zri = 0 when i = NT .\nFor the case of a′ with symmetry normal proposal, the acceptance probability is min ( 1, A(a′) ) , where A ( a′ ) =\nN(T )∏ i=1 ( a′ + (λ0 − a′)e−δTi a+ (λ0 − a) e−δTi )Zi0(a′ a )αa−1\n× exp (( a′ − a )(1 δ ( 1− e−δT ) − T − βa )) For the inferences of the remaining parameters λ0, δ, and Yi for exponential Langevin, the acceptance probabilities are shown in Table 1 in Supplemental Materials."
    }, {
      "heading" : "5. Discussion and Related Work",
      "text" : "Reduction to EM. We show that careful selection of specific priors yields posterior probabilities that coincide with the distribution that is taken under the E-step in the EM (expectation–maximization) algorithm methodology launched by Veen and Schoenberg (2008). They utilized the branching structure as a strategy for obtaining the maximum likelihood estimates of a classical Hawkes process which has intensity as in Equation (4) with Y being a constant (ψ). As in their paper, we define the variables ui associated with the i−th event time Ti as ui = j if event i is caused by event j and ui = i if the event i is an immigrant event. The unobserved branching structure ui is treated as the missing data and used to construct an EM algorithm.\nThe conditional expected value of the complete data loglikelihoood can be written as\nQ ( ϑ;ϑ(q) ) =E [ log(complete data likelihood)| FT , ϑ(q) ] =E\n[ NT∑ i=1 I{ui=i}log(a+(λ0−a)e −δt)− ∫ T Ti ν†(s−Ti) ds\n+ NT∑ i=1 ∑ j 6=i I{ui=j} log ν †(Ti−Tj)| FT , ϑ(q)\n] .\nThe following probabilities are used to find an expression for the conditional expected complete data log-likelihood:\nP(ui = j | FTi , Ti)\n=  ν†(Ti−Tj) a(q)+(λ (q) 0 −a(q))e−δ (q)Ti+ ∑ j:Tj<Ti ν†(Ti−Tj |ϑ(q)) (a) a(q)+(λ (q) 0 −a (q))e−δ (q)Ti\na(q)+(λ (q) 0 −a(q))e−δ (q)Ti+ ∑ j:Tj<Ti ν†(Ti−Tj |ϑ(q)) (b)\ntaking value (a) when 0 < j < i and value (b) when j = i.\nThe kernel used by Veen and Schoenberg (2008) is ν†(t) = ψe−δt. Observe that this coincides with Equations (7) and (8) in Section 4.2.1 when Y is set to a constant ψ. These probabilities are analogous to the probabilities used to perform the thinning in the modified simulation algorithm (see Ogata, 1981; Farajtabar et al., 2014; Valera and Gomez-Rodriguez, 2015).\nThe Renewal Equation Governing E(λt). We provide an expression for E(λt) when Y follows an SDE:\nλt 1. = a+ (λ0 − a)e−δt + ∫ t 0 Yse −δ(t−s) dNs\n2. = a+ (λ0 − a)e−δt + ∫ t 0 Yse −δ(t−s)λs ds\n+ ∫ t 0 Yse −δ(t−s) d ( Ns − ∫ s 0 λu du ) E[λt] 3. = a+ (λ0 − a)e−δt + ∫ t 0 E[Ys]E[λs]e−δ(t−s) ds.\nwhere 1. rewrites λ as a stochastic integral, 2. follows from subtracting and adding the mean value process of λ and 3. propagating expectation through the equation.\nOther Point Processes. Simma and Jordan (2010) proposed an EM inference algorithm for Hawkes processes and applied to large social network datasets. Inspired by their latent variable set-up, we adapted some of their hidden variable formulation within the marked point process framework into our fully Bayesian inference setting. We have leveraged ideas from previous work on self-exciting processes to consequently treating the levels of excitation as random processes. Linderman and Adams (2014)\nintroduced a multivariate point process combining self (Hawkes) and external (Cox) flavors to study latent networks in the data. These processes have also been proposed and applied in analyzing topic diffusion and user interactions (Rodriguez et al., 2011; Yang and Zha, 2013). Farajtabar et al. (2014) put forth a temporal point process model with one intensity being modulated by the other. Bounds of self exciting processes are also studied in (Hansen et al., 2015). Differently from these, we breathe another dimension into Hawkes processes by modeling the contagion parameters as a stochastic differential equation equipped with general procedures for learning. This allows much more latitude in parameterizing the self-exciting processes as a basic building block before incorporating wider families of processes.\nStudies of inference for continuous SDEs have been launched by Archambeau et al. (2007). Later contributions, notably by Ruttor et al. (2013) and Opper et al. (2010), dealt with SDEs with drift modulated by a memoryless Telegraph or Kac process that takes binary values as well as incorporating discontinuities in the finite variation terms. We remark that the inference for diffusion processes via expectation propagation has been pursued by Cseke et al. (2015). We add some new aspects to the existing theory by introducing Bayesian approaches for performing inference on two SDEs, namely the GBM and the exponential Langevin dynamics over periods of unequal lengths."
    }, {
      "heading" : "6. Final Remarks",
      "text" : "We extended the Hawkes process by treating the magnitudes of self-excitation as random elements satisfying two versions of SDEs. These formulations allow the modeling of phenomena when the events and their intensities accelerate one another in a correlated fashion.\nWhich stochastic differential equation should one choose? We presented two SDEs of unequal lengths in this work. The availability of other SDEs in the machine learning literature leaves us the modeling freedom to maneuver and adapt to each real-life application. Each scenario presents quite distinct specifics that require certain amount of impromptu and improvised inventiveness. Finally, a flexible hybrid MCMC algorithm is put forward and connexions to the EM algorithm is spelled out."
    }, {
      "heading" : "7. Acknowledgments",
      "text" : "Young Lee wishes to thank Aditya K. Menon for inspiring discussions.\nThis work was undertaken at NICTA. NICTA is funded by the Australian Government through the Department of Communications and the Australian Research Council through the ICT Centre of Excellence Program."
    } ],
    "references" : [ {
      "title" : "Gaussian process approximations of stochastic differential equations",
      "author" : [ "C. Archambeau", "D. Cornford", "M. Opper", "J. ShaweTaylor" ],
      "venue" : "In Gaussian Processes in Practice,",
      "citeRegEx" : "Archambeau et al\\.,? \\Q2007\\E",
      "shortCiteRegEx" : "Archambeau et al\\.",
      "year" : 2007
    }, {
      "title" : "How do residential burglars select target areas? A new approach to the analysis of criminal location choice",
      "author" : [ "W. Bernasco", "P. Nieuwbeerta" ],
      "venue" : "British Journal of Criminology,",
      "citeRegEx" : "Bernasco and Nieuwbeerta,? \\Q2005\\E",
      "shortCiteRegEx" : "Bernasco and Nieuwbeerta",
      "year" : 2005
    }, {
      "title" : "Bond and option pricing when short rates are lognormal",
      "author" : [ "F. Black", "P. Karasinski" ],
      "venue" : "Financial Analyst Journal,",
      "citeRegEx" : "Black and Karasinski,? \\Q1991\\E",
      "shortCiteRegEx" : "Black and Karasinski",
      "year" : 1991
    }, {
      "title" : "Power spectra of general shot noises and Hawkes point processes with a random excitation",
      "author" : [ "P. Brémaud", "L. Massoulié" ],
      "venue" : "Advances in Applied Probability,",
      "citeRegEx" : "Brémaud and Massoulié,? \\Q2002\\E",
      "shortCiteRegEx" : "Brémaud and Massoulié",
      "year" : 2002
    }, {
      "title" : "Expectation propagation for diffusion processes by moment closure approximations",
      "author" : [ "B. Cseke", "D. Schnoerr", "M. Opper", "G. Sanguinetti" ],
      "venue" : "In arXiv preprint arXiv:1512.06098",
      "citeRegEx" : "Cseke et al\\.,? \\Q2015\\E",
      "shortCiteRegEx" : "Cseke et al\\.",
      "year" : 2015
    }, {
      "title" : "An Introduction to the Theory of Point Processes",
      "author" : [ "D.J. Daley", "D. Vere-Jones" ],
      "venue" : null,
      "citeRegEx" : "Daley and Vere.Jones,? \\Q2003\\E",
      "shortCiteRegEx" : "Daley and Vere.Jones",
      "year" : 2003
    }, {
      "title" : "A dynamic contagion process",
      "author" : [ "A. Dassios", "H. Zhao" ],
      "venue" : "Advances in Applied Probability,",
      "citeRegEx" : "Dassios and Zhao,? \\Q2011\\E",
      "shortCiteRegEx" : "Dassios and Zhao",
      "year" : 2011
    }, {
      "title" : "Exact simulation of Hawkes process with exponentially decaying intensity",
      "author" : [ "A. Dassios", "H. Zhao" ],
      "venue" : "Electronic Communications in Probability,",
      "citeRegEx" : "Dassios and Zhao,? \\Q2013\\E",
      "shortCiteRegEx" : "Dassios and Zhao",
      "year" : 2013
    }, {
      "title" : "Shaping social activity by incentivizing users",
      "author" : [ "M. Farajtabar", "N. Du", "M. Gomez-Rodriguez", "I. Valera", "H. Zha", "L. Song" ],
      "venue" : "In NIPS ’14: Advances in Neural Information Processing Systems",
      "citeRegEx" : "Farajtabar et al\\.,? \\Q2014\\E",
      "shortCiteRegEx" : "Farajtabar et al\\.",
      "year" : 2014
    }, {
      "title" : "Two singular diffusion problems",
      "author" : [ "W. Feller" ],
      "venue" : "The Annals of Mathematics,",
      "citeRegEx" : "Feller,? \\Q1951\\E",
      "shortCiteRegEx" : "Feller",
      "year" : 1951
    }, {
      "title" : "Lasso and probabilistic inequalities for multivariate point processes",
      "author" : [ "N.R. Hansen", "P. Reynaud-Bouret", "V. Rivoirard" ],
      "venue" : null,
      "citeRegEx" : "Hansen et al\\.,? \\Q2015\\E",
      "shortCiteRegEx" : "Hansen et al\\.",
      "year" : 2015
    }, {
      "title" : "Spectra of some self-exciting and mutually exciting point processes",
      "author" : [ "A.G. Hawkes" ],
      "venue" : null,
      "citeRegEx" : "Hawkes,? \\Q1971\\E",
      "shortCiteRegEx" : "Hawkes",
      "year" : 1971
    }, {
      "title" : "A cluster process representation of a self-exciting process",
      "author" : [ "A.G. Hawkes", "D. Oakes" ],
      "venue" : "Journal of Applied Probability,",
      "citeRegEx" : "Hawkes and Oakes,? \\Q1974\\E",
      "shortCiteRegEx" : "Hawkes and Oakes",
      "year" : 1974
    }, {
      "title" : "Numerical solution of stochastic differential equations. Applications of Mathematics",
      "author" : [ "P.E. Kloeden", "E. Platen" ],
      "venue" : null,
      "citeRegEx" : "Kloeden and Platen,? \\Q1999\\E",
      "shortCiteRegEx" : "Kloeden and Platen",
      "year" : 1999
    }, {
      "title" : "Ecological information from spatial patterns of plants: insights from point process theory",
      "author" : [ "R. Law", "J. Illian", "Burslem", "D.F.R. P", "G. Gratzer", "C.V.S. Gunatilleke", "Gunatilleke", "I.A.U. N" ],
      "venue" : "Journal of Ecology,",
      "citeRegEx" : "Law et al\\.,? \\Q2009\\E",
      "shortCiteRegEx" : "Law et al\\.",
      "year" : 2009
    }, {
      "title" : "A nonparametric EM algorithm for multiscale Hawkes processes",
      "author" : [ "E. Lewis", "G. Mohler" ],
      "venue" : "Journal of Nonparametric Statistics,",
      "citeRegEx" : "Lewis and Mohler,? \\Q2011\\E",
      "shortCiteRegEx" : "Lewis and Mohler",
      "year" : 2011
    }, {
      "title" : "Discovering latent network structure in point process data",
      "author" : [ "S.W. Linderman", "R.P. Adams" ],
      "venue" : "In ThirtyFirst International Conference on Machine Learning (ICML)",
      "citeRegEx" : "Linderman and Adams,? \\Q2014\\E",
      "shortCiteRegEx" : "Linderman and Adams",
      "year" : 2014
    }, {
      "title" : "On Lewis’ simulation method for point processes",
      "author" : [ "Y. Ogata" ],
      "venue" : "IEEE Transactions on Information",
      "citeRegEx" : "Ogata,? \\Q1981\\E",
      "shortCiteRegEx" : "Ogata",
      "year" : 1981
    }, {
      "title" : "Space-time point-process models for earthquake occurrences",
      "author" : [ "Y. Ogata" ],
      "venue" : "Annals of the Institute of Statistical Mathematics,",
      "citeRegEx" : "Ogata,? \\Q1998\\E",
      "shortCiteRegEx" : "Ogata",
      "year" : 1998
    }, {
      "title" : "Approximate inference in continuous time Gaussian-Jump processes",
      "author" : [ "M. Opper", "A. Ruttor", "G. Sanguinetti" ],
      "venue" : "In Advances in Neural Information Processing Systems",
      "citeRegEx" : "Opper et al\\.,? \\Q2010\\E",
      "shortCiteRegEx" : "Opper et al\\.",
      "year" : 2010
    }, {
      "title" : "Maximum likelihood estimation of Hawkes’ self-exciting point processes",
      "author" : [ "T. Ozaki" ],
      "venue" : "Annals of the Institute of Statistical Mathematics,",
      "citeRegEx" : "Ozaki,? \\Q1979\\E",
      "shortCiteRegEx" : "Ozaki",
      "year" : 1979
    }, {
      "title" : "Bayesian inference for Hawkes processes. Methodology and Computing in Applied Probability, 15(3):623–642",
      "author" : [ "J.G. Rasmussen" ],
      "venue" : null,
      "citeRegEx" : "Rasmussen,? \\Q2013\\E",
      "shortCiteRegEx" : "Rasmussen",
      "year" : 2013
    }, {
      "title" : "Adaptive estimation for Hawkes processes; application to genome analysis",
      "author" : [ "P. Reynaud-Bouret", "S. Schbath" ],
      "venue" : null,
      "citeRegEx" : "Reynaud.Bouret and Schbath,? \\Q2010\\E",
      "shortCiteRegEx" : "Reynaud.Bouret and Schbath",
      "year" : 2010
    }, {
      "title" : "Monte Carlo Statistical Methods",
      "author" : [ "C.P. Robert", "G. Casella" ],
      "venue" : null,
      "citeRegEx" : "Robert and Casella,? \\Q2005\\E",
      "shortCiteRegEx" : "Robert and Casella",
      "year" : 2005
    }, {
      "title" : "Uncovering the temporal dynamics of diffusion networks",
      "author" : [ "M.G. Rodriguez", "D. Balduzzi", "B. Schölkopf" ],
      "venue" : "In ICML,",
      "citeRegEx" : "Rodriguez et al\\.,? \\Q2011\\E",
      "shortCiteRegEx" : "Rodriguez et al\\.",
      "year" : 2011
    }, {
      "title" : "Regular point processes and their detection",
      "author" : [ "I. Rubin" ],
      "venue" : "IEEE Transactions on Information",
      "citeRegEx" : "Rubin,? \\Q1972\\E",
      "shortCiteRegEx" : "Rubin",
      "year" : 1972
    }, {
      "title" : "Approximate Gaussian process inference for the drift function in stochastic differential equations",
      "author" : [ "A. Ruttor", "P. Batz", "M. Opper" ],
      "venue" : "In Advances in Neural Information Processing Systems",
      "citeRegEx" : "Ruttor et al\\.,? \\Q2013\\E",
      "shortCiteRegEx" : "Ruttor et al\\.",
      "year" : 2013
    }, {
      "title" : "Modeling events with cascades of Poisson processes. In UAI, pages 546–555",
      "author" : [ "A. Simma", "M.I. Jordan" ],
      "venue" : null,
      "citeRegEx" : "Simma and Jordan,? \\Q2010\\E",
      "shortCiteRegEx" : "Simma and Jordan",
      "year" : 2010
    }, {
      "title" : "Inference in continuous-time change-point models",
      "author" : [ "F. Stimberg", "M. Opper", "G. Sanguinetti", "A. Ruttor" ],
      "venue" : "In Advances in Neural Information Processing Systems",
      "citeRegEx" : "Stimberg et al\\.,? \\Q2011\\E",
      "shortCiteRegEx" : "Stimberg et al\\.",
      "year" : 2011
    }, {
      "title" : "Modeling adoption and usage of competing products",
      "author" : [ "I. Valera", "M. Gomez-Rodriguez" ],
      "venue" : "In ICDM,",
      "citeRegEx" : "Valera and Gomez.Rodriguez,? \\Q2015\\E",
      "shortCiteRegEx" : "Valera and Gomez.Rodriguez",
      "year" : 2015
    }, {
      "title" : "Estimation of spacetime branching process models in seismology using an EM-type algorithm",
      "author" : [ "A. Veen", "F.P. Schoenberg" ],
      "venue" : "Journal of the American Statistical Association,",
      "citeRegEx" : "Veen and Schoenberg,? \\Q2008\\E",
      "shortCiteRegEx" : "Veen and Schoenberg",
      "year" : 2008
    }, {
      "title" : "Bayesian learning via stochastic gradient Langevin dynamics",
      "author" : [ "M. Welling", "Y.W. Teh" ],
      "venue" : "In Proceedings of the International Conference on Machine Learning",
      "citeRegEx" : "Welling and Teh,? \\Q2011\\E",
      "shortCiteRegEx" : "Welling and Teh",
      "year" : 2011
    }, {
      "title" : "Mixture of mutually exciting processes for viral diffusion",
      "author" : [ "Yang", "S.-H", "H. Zha" ],
      "venue" : "In ICML,",
      "citeRegEx" : "Yang et al\\.,? \\Q2013\\E",
      "shortCiteRegEx" : "Yang et al\\.",
      "year" : 2013
    }, {
      "title" : "Point process modelling of the Afghan war diary",
      "author" : [ "A. Zammit-Mangion", "M. Dewar", "V. Kadirkamanathan", "G. Sanguinetti" ],
      "venue" : "Proceedings of the National Academy of Sciences,",
      "citeRegEx" : "Zammit.Mangion et al\\.,? \\Q2012\\E",
      "shortCiteRegEx" : "Zammit.Mangion et al\\.",
      "year" : 2012
    } ],
    "referenceMentions" : [ {
      "referenceID" : 1,
      "context" : "Similarly, criminological research (Bernasco and Nieuwbeerta, 2005) has shown that crime can spread through local environments very rapidly where burglars will constantly attack nearby targets because local susceptibilities are well",
      "startOffset" : 35,
      "endOffset" : 67
    }, {
      "referenceID" : 11,
      "context" : "The Hawkes process, or otherwise known as the self-exciting process, is an extension of Poisson processes that aims to explain excitatory interactions (Hawkes, 1971).",
      "startOffset" : 151,
      "endOffset" : 165
    }, {
      "referenceID" : 21,
      "context" : "As another example, in genetic analysis, Reynaud-Bouret and Schbath (2010) looked at the likelihood of occurrences of a particular event along the DNA sequence where ‘an event’ could be any biological signals occurring along the genomes that tend to cluster together.",
      "startOffset" : 41,
      "endOffset" : 75
    }, {
      "referenceID" : 11,
      "context" : "ting (Hawkes, 1971; Ozaki, 1979).",
      "startOffset" : 5,
      "endOffset" : 32
    }, {
      "referenceID" : 20,
      "context" : "ting (Hawkes, 1971; Ozaki, 1979).",
      "startOffset" : 5,
      "endOffset" : 32
    }, {
      "referenceID" : 3,
      "context" : "Our formulation implies that the contagion parameters are random processes thus inheriting tractable covariance structures, in contrast to the set-up initiated by Brémaud and Massoulié (2002) and Dassios and Zhao (2011), where contagion levels are independent and identically distributed (iid) random.",
      "startOffset" : 163,
      "endOffset" : 192
    }, {
      "referenceID" : 3,
      "context" : "Our formulation implies that the contagion parameters are random processes thus inheriting tractable covariance structures, in contrast to the set-up initiated by Brémaud and Massoulié (2002) and Dassios and Zhao (2011), where contagion levels are independent and identically distributed (iid) random.",
      "startOffset" : 163,
      "endOffset" : 220
    }, {
      "referenceID" : 17,
      "context" : "(2) With n denoting the counts of events, we design a sampling procedure that scales with complexityO(n) compared to a naïve implementation of Ogata’s modified thinning algorithm (Ogata, 1981) which needs O(n) steps.",
      "startOffset" : 179,
      "endOffset" : 192
    }, {
      "referenceID" : 30,
      "context" : "(4) We conclude by making explicit deductive connections to two related areas in machine learning; (i) the ‘E-step’ of the expectation maximization (EM) algorithm for Hawkes processes (Veen and Schoenberg, 2008; Ogata, 1981) and (ii) modeling the volatility clustering phenomenon.",
      "startOffset" : 184,
      "endOffset" : 224
    }, {
      "referenceID" : 17,
      "context" : "(4) We conclude by making explicit deductive connections to two related areas in machine learning; (i) the ‘E-step’ of the expectation maximization (EM) algorithm for Hawkes processes (Veen and Schoenberg, 2008; Ogata, 1981) and (ii) modeling the volatility clustering phenomenon.",
      "startOffset" : 184,
      "endOffset" : 224
    }, {
      "referenceID" : 14,
      "context" : "By way of analogy, the base rate is referred to as the ‘immigrant intensity’ in ecological applications (Law et al., 2009), where it describes the rate with which new organisms are expected to arrive from other territories and colonies.",
      "startOffset" : 104,
      "endOffset" : 122
    }, {
      "referenceID" : 13,
      "context" : "Some notable examples of the couple (μ̂, σ̂) are the Geometric Brownian Motion (GBM): μ̂ = (μ + 12σ )Y, σ̂ = σY (Kloeden and Platen, 1999; Zammit-Mangion et al., 2012); the Square-Root-Processes: μ̂ = k(μ − Y ), σ̂ = σ √ Y , (Archambeau et al.",
      "startOffset" : 112,
      "endOffset" : 167
    }, {
      "referenceID" : 33,
      "context" : "Some notable examples of the couple (μ̂, σ̂) are the Geometric Brownian Motion (GBM): μ̂ = (μ + 12σ )Y, σ̂ = σY (Kloeden and Platen, 1999; Zammit-Mangion et al., 2012); the Square-Root-Processes: μ̂ = k(μ − Y ), σ̂ = σ √ Y , (Archambeau et al.",
      "startOffset" : 112,
      "endOffset" : 167
    }, {
      "referenceID" : 0,
      "context" : ", 2012); the Square-Root-Processes: μ̂ = k(μ − Y ), σ̂ = σ √ Y , (Archambeau et al., 2007; Opper et al., 2010); Langevin equation: μ̂ = k(μ − Y ), σ̂ = σ, and their variants (Stimberg et al.",
      "startOffset" : 65,
      "endOffset" : 110
    }, {
      "referenceID" : 19,
      "context" : ", 2012); the Square-Root-Processes: μ̂ = k(μ − Y ), σ̂ = σ √ Y , (Archambeau et al., 2007; Opper et al., 2010); Langevin equation: μ̂ = k(μ − Y ), σ̂ = σ, and their variants (Stimberg et al.",
      "startOffset" : 65,
      "endOffset" : 110
    }, {
      "referenceID" : 28,
      "context" : ", 2010); Langevin equation: μ̂ = k(μ − Y ), σ̂ = σ, and their variants (Stimberg et al., 2011; Welling and Teh, 2011; Liptser and Shiryaev, 1978).",
      "startOffset" : 71,
      "endOffset" : 145
    }, {
      "referenceID" : 31,
      "context" : ", 2010); Langevin equation: μ̂ = k(μ − Y ), σ̂ = σ, and their variants (Stimberg et al., 2011; Welling and Teh, 2011; Liptser and Shiryaev, 1978).",
      "startOffset" : 71,
      "endOffset" : 145
    }, {
      "referenceID" : 9,
      "context" : "Specifically, Square-RootProcesses can be negative if the Feller condition 2kμ > σ is not satisfied (Feller, 1951; Liptser and Shiryaev, 1978).",
      "startOffset" : 100,
      "endOffset" : 142
    }, {
      "referenceID" : 2,
      "context" : "To that end, we focus on two specifications of the SDEs, namely the GBM and we tilt the Langevin dynamics by exponentiating it so that the positivity of Y is ensured (Black and Karasinski, 1991): • Geometric Brownian Motion (GBM):",
      "startOffset" : 166,
      "endOffset" : 194
    }, {
      "referenceID" : 20,
      "context" : "Note that δ is being shared between the base intensity λ̂0 and the kernel ν to ensure that the process has memoryless properties (see Hawkes and Oakes, 1974; Ozaki, 1979).",
      "startOffset" : 129,
      "endOffset" : 170
    }, {
      "referenceID" : 18,
      "context" : "This would not have been possible, if we were to use a power kernel (Ogata, 1998), say.",
      "startOffset" : 68,
      "endOffset" : 81
    }, {
      "referenceID" : 11,
      "context" : "If we set Y to be a constant, we retrieve the model proposed by Hawkes (1971). In addition, setting Y = 0 returns us the inhomogeneous Poisson process.",
      "startOffset" : 64,
      "endOffset" : 78
    }, {
      "referenceID" : 10,
      "context" : "For further details on classification of Hawkes processes via the branching structure, refer to Rasmussen (2013) and Daley and Vere-Jones (2003).",
      "startOffset" : 41,
      "endOffset" : 113
    }, {
      "referenceID" : 5,
      "context" : "For further details on classification of Hawkes processes via the branching structure, refer to Rasmussen (2013) and Daley and Vere-Jones (2003). 2.",
      "startOffset" : 117,
      "endOffset" : 145
    }, {
      "referenceID" : 14,
      "context" : "This generalizes the likelihood function of Lewis and Mohler (2011). It can be viewed that this as an alternative version of the likelihood function found in Daley and Vere-Jones (2003) and Rubin (1972) with the presence of the branching structure coupled with a stochastic process Y .",
      "startOffset" : 44,
      "endOffset" : 68
    }, {
      "referenceID" : 5,
      "context" : "It can be viewed that this as an alternative version of the likelihood function found in Daley and Vere-Jones (2003) and Rubin (1972) with the presence of the branching structure coupled with a stochastic process Y .",
      "startOffset" : 89,
      "endOffset" : 117
    }, {
      "referenceID" : 5,
      "context" : "It can be viewed that this as an alternative version of the likelihood function found in Daley and Vere-Jones (2003) and Rubin (1972) with the presence of the branching structure coupled with a stochastic process Y .",
      "startOffset" : 89,
      "endOffset" : 134
    }, {
      "referenceID" : 17,
      "context" : "This algorithm scales with complexity O(n) compared to a naïve implementation of Ogata’s modified thinning algorithm (Ogata, 1981) which requiresO(n) steps with n denoting the number of events.",
      "startOffset" : 117,
      "endOffset" : 130
    }, {
      "referenceID" : 11,
      "context" : "We present a sampling procedure for our Stochastic Hawkes model in Algorithm 1. This algorithm scales with complexity O(n) compared to a naïve implementation of Ogata’s modified thinning algorithm (Ogata, 1981) which requiresO(n) steps with n denoting the number of events. Similarly to Ozaki (1979) but differently from Ogata’s method, it is noteworthy to mention that our algorithm does not require the stationarity condition for intensity dynamics as long as T <∞.",
      "startOffset" : 51,
      "endOffset" : 300
    }, {
      "referenceID" : 6,
      "context" : "The outline of Dassios and Zhao (2013) for simulating Hawkes processes is followed closely and adapted to the present setting.",
      "startOffset" : 15,
      "endOffset" : 39
    }, {
      "referenceID" : 6,
      "context" : "The outline of Dassios and Zhao (2013) for simulating Hawkes processes is followed closely and adapted to the present setting. The idea of their algorithm is to decompose the inter-arrival event times into two independent simpler random variables, denoted by S and S, with the intention that they can be sampled conveniently. Note however that we also need to sample the levels of self-excitation Y , which is a stochastic process in contrast to iid sequences of Y as in Dassios and Zhao (2013). We seek to find laws that describe the GBM and exponential Langevin dynamics.",
      "startOffset" : 15,
      "endOffset" : 495
    }, {
      "referenceID" : 23,
      "context" : "A hybrid algorithm (Robert and Casella, 2005) combines the features of the Gibbs sampler and the MH algo-",
      "startOffset" : 19,
      "endOffset" : 45
    }, {
      "referenceID" : 21,
      "context" : "This is a slight generalization to the Exponential distribution suggested by Rasmussen (2013) as Gamma distribution contains an additional shape parameter that will help to improve the fitting performance.",
      "startOffset" : 77,
      "endOffset" : 94
    }, {
      "referenceID" : 13,
      "context" : "This is similar in spirit to the Milstein scheme (Kloeden and Platen, 1999) where higher orders of quadratic variations vanish.",
      "startOffset" : 49,
      "endOffset" : 75
    }, {
      "referenceID" : 29,
      "context" : "We show that careful selection of specific priors yields posterior probabilities that coincide with the distribution that is taken under the E-step in the EM (expectation–maximization) algorithm methodology launched by Veen and Schoenberg (2008). They utilized the branching structure as a strategy for obtaining the maximum likelihood estimates of a classical Hawkes process which has intensity as in Equation (4) with Y being a constant (ψ).",
      "startOffset" : 219,
      "endOffset" : 246
    }, {
      "referenceID" : 8,
      "context" : "These probabilities are analogous to the probabilities used to perform the thinning in the modified simulation algorithm (see Ogata, 1981; Farajtabar et al., 2014; Valera and Gomez-Rodriguez, 2015).",
      "startOffset" : 121,
      "endOffset" : 197
    }, {
      "referenceID" : 29,
      "context" : "These probabilities are analogous to the probabilities used to perform the thinning in the modified simulation algorithm (see Ogata, 1981; Farajtabar et al., 2014; Valera and Gomez-Rodriguez, 2015).",
      "startOffset" : 121,
      "endOffset" : 197
    }, {
      "referenceID" : 26,
      "context" : "The kernel used by Veen and Schoenberg (2008) is ν†(t) = ψe−δt.",
      "startOffset" : 19,
      "endOffset" : 46
    }, {
      "referenceID" : 24,
      "context" : "These processes have also been proposed and applied in analyzing topic diffusion and user interactions (Rodriguez et al., 2011; Yang and Zha, 2013).",
      "startOffset" : 103,
      "endOffset" : 147
    }, {
      "referenceID" : 10,
      "context" : "Bounds of self exciting processes are also studied in (Hansen et al., 2015).",
      "startOffset" : 54,
      "endOffset" : 75
    }, {
      "referenceID" : 18,
      "context" : "Simma and Jordan (2010) proposed an EM inference algorithm for Hawkes processes and applied to large social network datasets.",
      "startOffset" : 0,
      "endOffset" : 24
    }, {
      "referenceID" : 7,
      "context" : "Simma and Jordan (2010) proposed an EM inference algorithm for Hawkes processes and applied to large social network datasets. Inspired by their latent variable set-up, we adapted some of their hidden variable formulation within the marked point process framework into our fully Bayesian inference setting. We have leveraged ideas from previous work on self-exciting processes to consequently treating the levels of excitation as random processes. Linderman and Adams (2014) introduced a multivariate point process combining self (Hawkes) and external (Cox) flavors to study latent networks in the data.",
      "startOffset" : 63,
      "endOffset" : 474
    }, {
      "referenceID" : 6,
      "context" : "Farajtabar et al. (2014) put forth a temporal point process model with one intensity being modulated by the other.",
      "startOffset" : 0,
      "endOffset" : 25
    }, {
      "referenceID" : 0,
      "context" : "Studies of inference for continuous SDEs have been launched by Archambeau et al. (2007). Later contributions, notably by Ruttor et al.",
      "startOffset" : 63,
      "endOffset" : 88
    }, {
      "referenceID" : 0,
      "context" : "Studies of inference for continuous SDEs have been launched by Archambeau et al. (2007). Later contributions, notably by Ruttor et al. (2013) and Opper et al.",
      "startOffset" : 63,
      "endOffset" : 142
    }, {
      "referenceID" : 0,
      "context" : "Studies of inference for continuous SDEs have been launched by Archambeau et al. (2007). Later contributions, notably by Ruttor et al. (2013) and Opper et al. (2010), dealt with SDEs with drift modulated by a memoryless Telegraph or Kac process that takes binary values as well as incorporating discontinuities in the finite variation terms.",
      "startOffset" : 63,
      "endOffset" : 166
    }, {
      "referenceID" : 0,
      "context" : "Studies of inference for continuous SDEs have been launched by Archambeau et al. (2007). Later contributions, notably by Ruttor et al. (2013) and Opper et al. (2010), dealt with SDEs with drift modulated by a memoryless Telegraph or Kac process that takes binary values as well as incorporating discontinuities in the finite variation terms. We remark that the inference for diffusion processes via expectation propagation has been pursued by Cseke et al. (2015). We add some new aspects to the existing theory by introducing Bayesian approaches for performing inference on two SDEs, namely the GBM and the exponential Langevin dynamics over periods of unequal lengths.",
      "startOffset" : 63,
      "endOffset" : 463
    } ],
    "year" : 2016,
    "abstractText" : "We propose an extension to Hawkes processes by treating the levels of self-excitation as a stochastic differential equation. Our new point process allows better approximation in application domains where events and intensities accelerate each other with correlated levels of contagion. We generalize a recent algorithm for simulating draws from Hawkes processes whose levels of excitation are stochastic processes, and propose a hybrid Markov chain Monte Carlo approach for model fitting. Our sampling procedure scales linearly with the number of required events and does not require stationarity of the point process. A modular inference procedure consisting of a combination between Gibbs and Metropolis Hastings steps is put forward. We recover expectation maximization as a special case. Our general approach is illustrated for contagion following geometric Brownian motion and exponential Langevin dynamics.",
    "creator" : "LaTeX with hyperref package"
  }
}