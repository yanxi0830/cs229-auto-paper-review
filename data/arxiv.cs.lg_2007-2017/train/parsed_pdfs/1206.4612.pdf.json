{
  "name" : "1206.4612.pdf",
  "metadata" : {
    "source" : "META",
    "title" : "Exact Soft Confidence-Weighted Learning",
    "authors" : [ "Jialei Wang", "Peilin Zhao", "Steven C.H. Hoi" ],
    "emails" : [ "jl.wang@ntu.edu.sg", "zhao0106@ntu.edu.sg", "chhoi@ntu.edu.sg" ],
    "sections" : [ {
      "heading" : "1. Introduction",
      "text" : "Online learning algorithms (Rosenblatt, 1958; Crammer et al., 2006; Jin et al., 2010; Zhao et al., 2011a;b) represent a family of fast and simple machine learning techniques, which usually make few statistical assumptions and can be applied to a wide range of applications (Li et al., 2012). Online learning has been actively studied in machine learning community, in which a variety of online learning algorithms have been proposed, including a number of first-order algorithms such as the well-known Perceptron algorithm (Rosenblatt, 1958) and the Passive-Aggressive (PA) algorithms (Crammer et al., 2006).\nAppearing in Proceedings of the 29 th International Conference on Machine Learning, Edinburgh, Scotland, UK, 2012. Copyright 2012 by the author(s)/owner(s).\nRecent years have seen a surge of studies on the second-order online learning algorithms (Cesa-Bianchi et al., 2005; Dredze et al., 2008; Crammer et al., 2009b; Orabona & Crammer, 2010; Duchi et al., 2011), which have shown that parameter confidence information can be explored to guide and improve online learning performance (Cesa-Bianchi et al., 2005). For example, Confidence-weighted (CW) learning (Dredze et al., 2008; Crammer et al., 2009a) maintains a Gaussian distribution over some linear classifier hypotheses and applies it to control the direction and scale of parameter updates (Dredze et al., 2008). Although CW learning has formal guarantees in the mistakebound model (Crammer et al., 2008), it can overfit in certain situations due to its aggressive update rules based upon a separable data assumption. Recently, an improved online algorithm, i.e., Adaptive Regularization of Weights (AROW) (Crammer et al., 2009b; Orabona & Crammer, 2010), relaxes such separable assumption by employing an adaptive regularization for each training example based upon its current confidence. This regularization comes in the form of minimizing a combination of the Kullback-Leibler divergence between Gaussian distributed weight vectors and a confidence penalty of vectors.\nAlthough AROW is able to improve the original CW learning by handling noisy and non-separable cases, it is not the exact corresponding soft extending part of CW (Like PA with PA-I and PA-II). In particular, the directly added loss and confidence regularization make AROW lose an important property of Confidence-weighted learning, i.e., Adaptive Margin property. Following the similar idea of soft margin support vector machines, the adaptive margin assigns different margins for different instances via a probability formulation, which enables CW to gain extra efficiency and effectiveness.\nIn this work, we extend the confidence-weighted learning for soft margin learning, which makes our Soft\nConfidence-Weighted (SCW) learning method more robust than the original CW learning when handling noisy and non-separable data, and more effective and efficient than the state-of-the-art AROW algorithm.\nThe rest of this paper is organized as follows. Section 2 reviews related work. Section 3 proposes the soft confidence-weighted learning method. Section 4 analyzes the mistake bounds and properties of our algorithms. Section 5 conducts an extensive set of empirical experiments, and Section 6 concludes this work."
    }, {
      "heading" : "2. Related Work and Background",
      "text" : ""
    }, {
      "heading" : "2.1. Overview of Online Learning",
      "text" : "Online learning operates on a sequence of data examples with time stamps. At time step t, the algorithm processes an incoming example xt ∈ Rd by first predicting its label ŷt ∈ {−1,+1}. After the prediction, the true label yt ∈ {−1,+1} is revealed and then the loss ℓ(yt, ŷt), which is the difference between its prediction and the revealed true label yt, is suffered. Finally, the loss is used to update the weights of the model based on some criterion. Overall, the goal of online learning is to minimize the cumulative mistake over the entire sequence of data examples.\nOur work is closely related to several first and second order online learning algorithms, including Passive-Aggressive (PA) learning (Crammer et al., 2006), Confidence-Weighted learning (Dredze et al., 2008), and Adaptive Regularization of Weights learning (Crammer et al., 2009b). Below we review the basics of these algorithms."
    }, {
      "heading" : "2.2. Passive-Aggressive Learning",
      "text" : "As the state-of-the-art first order online learning algorithm, the optimization of Passive-Aggressive (PA) learning is formulated as:\nwt+1 = arg min w∈Rd\n1 2 ‖w −wt‖2s.t.ℓ(w; (xt, yt)) = 0 (1)\nwhere the loss function is based on the hinge loss:\nℓ(w; (xt, yt)) =\n{\n0 if yt(w · xt) ≥ 1 1− yt(w · xt) otherwise\nThe above optimization has the closed-form solution:\nwt+1 = wt + η PA t ytxt (2)\nwhere ηPAt = ℓ(wt;(xt,yt))\n‖xt‖2 . Further, to let PA be able to handle non-separable instances and more robust, a slack variable ξ was introduced into the optimization (1) using one of two types of penalty: linear and quadratic, leading to the following two formulations of\nsoft-margin PA algorithms:\nwPA−It+1 = arg min w∈Rd\n1 2 ‖w−wt‖2 + Cℓ(w; (xt, yt))\nwPA−IIt+1 = arg min w∈Rd\n1 2 ‖w−wt‖2 + Cℓ(w; (xt, yt))2\nwhere C is a parameter to tradeoff between passiveness and aggressiveness. The resulting weight updates to the soft-margin PA algorithms have the same form as that of (2), but different coefficients ηt as follows:\nηPA−It = min{C, ℓ(wt; (xt, yt)) ‖xt‖2 }, ηPA−IIt = ℓ(wt; (xt, yt))\n‖xt‖2 + 12C"
    }, {
      "heading" : "2.3. Confidence-Weighted Learning",
      "text" : "To better exploring the underlying structure between features, the Confidence-Weighted (CW) learning algorithm assumes a Gaussian distribution of weights with mean vector µ ∈ Rd and covariance matrix Σ ∈ Rd×d. The weight distribution is updated by minimizing the Kullback-Leibler divergence between the new weight distribution and the old one while ensuring that the probability of correct classfication is greater than a threshold as follows:\n(µt+1,Σt+1) = argmin µ,Σ\nDKL(N (µ,Σ),N (µt,Σt))\ns.t. P r w∼N (µ,Σ)[yt(w · xt) ≥ 0] ≥ η\nThis optimization problem has a closed-form solution\nµt+1 = µt + αtytΣtxt Σt+1 = Σt − βtΣtxtTxtΣt (3) The updating coefficients are calculated as follows:\nαt = max { 0, 1\nυtζ (−mtψ +\n√\nmt2 φ4\n4 + υtφ2ζ)\n}\nβt = αtφ√\nut + υtαtφ\nwhere ut = 1 4 (−αtυtφ +\n√\nαt2υt2φ2 + 4υt) 2, υt =\nxt TΣtxt, mt = yt(µt · xt), φ = Φ−1(η)(Φ is the cumulative function of the normal distribution), ψ = 1+ φ 2\n2 , and ζ = 1 + φ2."
    }, {
      "heading" : "2.4. Adaptive Regularization of Weights",
      "text" : "Unlike the original CW learning algorithm, the Adaptive Regularization Of Weights (AROW) learning introduces adaptive regularization of the prediction function when processing a new instance in each learning step, making it more robust than CW to sudden changes of label noise in the learning tasks. In particular, the optimization of AROW is formulated as:\n(µt+1,Σt+1) = argmin µ,Σ\nDKL(N (µ,Σ),N (µt,Σt))\n+ 1\n2γ ℓ2(µ; (xt, yt)) +\n1\n2γ xt\nTΣtxt\nwhere ℓ2(µ; (xt, yt)) = (max{0, 1− yt(µ · xt)})2 and γ is a regularization parameter. The optimization has a closed-form solution similar with CW of (3), but different updating coefficients:\nαt = ℓ(µt; (xt, yt))βt, βt = 1\nxtTΣtxt + γ"
    }, {
      "heading" : "3. Soft Confidence-Weighted Learning",
      "text" : "In this section we present a new online learning method that aims to address the limitation of the CW and AROW learning. Following the same problem settings of the Confidence-Weighted learning, we assume the weight vectorw follows the Gaussian distribution with the mean vectorµ and the covariance matrix Σ. Notice that the probability constraint in the CW learning, i.e., Pr w∼N (µ,Σ)[yt(w · xt) ≥ 0] ≥ η can be rewritten as\nyt(µ · xt) ≥ φ √ x⊤t Σxt,\nwhere φ = Φ−1(η). Further, we introduce a loss function as follows:\nℓφ ( N (µ,Σ); (xt, yt) ) = max ( 0, φ\n√\nx⊤t Σxt − ytµ · xt )\nIt is easy to verify that satisfying the probability constraint (i.e., yt(µ · xt) ≥ φ √\nx⊤t Σxt for any φ > 0) is equivalent to satisfying ℓφ ( N (µ,Σ); (xt, yt) )\n= 0. Therefore, the optimization problem of the original CW can be re-written as follows\n(µt+1,Σt+1) = argmin µ,Σ\nDKL ( N (µ,Σ)‖N (µt,Σt) )\ns.t. ℓφ ( N (µ,Σ); (xt, yt) ) = 0, φ > 0\nThe original CW learning method employs a very aggressive updating strategy by changing the distribution as much as necessary to satisfy the constraint imposed by the current example. Although it results in the rapid learning effect, it could force to wrongly change the parameters of the distribution dramatically when handling a mislabeled instance. Such undesirable property makes the original CW algorithm performs poorly in many real-world applications with relatively large noise.\nTo overcome the above limitation of the CW learning problem, we propose a Soft Confidence-Weighted (SCW) learning method, which aims to soften the aggressiveness of the CW updating strategy. The idea of the SCW learning is inspired by the variants of PA algorithms (PA-I and PA-II) and the adaptive margin. In particular, we formulate the optimization of SCW for learning the soft-margin classifiers as follows:\n(µt+1,Σt+1) = argmin µ,Σ\nDKL ( N (µ,Σ)‖N (µt,Σt) )\n+ Cℓφ ( N (µ,Σ); (xt, yt) )\n(4)\nwhere C is a parameter to tradeoff the passiveness and aggressiveness. We denoted the above formulation of the Soft Confidence-Weighted algorithm, as “SCW-I” for short. Similar to the variant of PA, we can also modify the above formulation by employing a squared penalty, leading to the second formulation of SCW learning (denoted as “SCW-II” for short):\n(µt+1,Σt+1) = argmin µ,Σ\nDKL ( N (µ,Σ)‖N (µt,Σt) )\n+ Cℓφ ( N (µ,Σ); (xt, yt) )2\n(5)\nFor the optimization of SCW-I, the following proposition gives the closed-form solution.\nProposition 1. The closed-form solution of the optimization problem (4) is expressed as follows:\nµt+1 = µt + αtytΣtxt,Σt+1 = Σt − βtΣtxtTxtΣt where the updating coefficients are as follows:\nαt = min{C,max{0, 1\nυtζ (−mtψ +\n√\nmt2 φ4\n4 + υtφ2ζ)}}\nβt = αtφ√\nut + υtαtφ\nwhere ut = 1 4 (−αtυtφ +\n√\nαt2υt2φ2 + 4υt) 2,υt =\nxt TΣtxt,mt = yt(µt · xt),φ = Φ−1(η),ψ = 1 + φ 2\n2 and ζ = 1 + φ2.\nSimilarly, the following proposition gives the closedform solution to the optimization of SCW-II.\nProposition 2. The closed-form solution of the optimization problem (5) is:\nµt+1 = µt + αtytΣtxt,Σt+1 = Σt − βtΣtxtTxtΣt The updating coefficients are as follows:\nαt = max{0, −(2mtnt + φ2mtυt) + γt\n2(n2t + ntυtφ 2)\n}\nβt = αtφ√\nut + υtαtφ\nwhere γt = φ √ φ2m2tυ 2 t + 4ntυt(nt + υtφ\n2), and nt = υt + 1 2C .\nThe detailed proofs of Proposition 1 and 2 can be found in Appendix section. Finally, Algorithm 1 summarizes the proposed SCW-I and SCW-II algorithms."
    }, {
      "heading" : "4. Analysis and Discussions",
      "text" : "We first give an overview about the comparison of the proposed SCW methods with respect to several existing first-order and second-order online learning algorithms, followed by the discussions on the nonlinear extension and the bound analysis.\nAlgorithm 1 SCW learning algorithms (SCW)\nINPUT: parameters C > 0, η > 0. INITIALIZATION: µ0 = (0, . . . , 0)\n⊤, Σ0 = I. for t = 1, . . . , T do Receive an example xt ∈ Rd; Make prediction: ŷt = sgn(µt−1 · xt); Receive true label yt; suffer loss ℓφ ( N (µt−1,Σt−1); (xt, yt) ) ;\nif ℓφ ( N (µt−1,Σt−1); (xt, yt) )\n> 0 then µt+1 = µt+αtytΣtxt,Σt+1 = Σt−βtΣtxtTxtΣt where αt and βt are computed by either Proposition 1 (SCW-I) or Proposition 2 (SCW-II);\nend if\nend for"
    }, {
      "heading" : "4.1. Comparison with the existing methods",
      "text" : "Following the study of AROW, we qualitatively examine the properties of different algorithms in Table 1. Unlike the previous second-order algorithms, the proposed SCW algorithm enjoys all the four salient properties. In particular, SCW improves over the original CW algorithm by adding the capability to handle the non-separable cases, and improves over AROW by adding the adaptive margin property. To the best of our knowledge, SCW is the first second-order online learning that holds all the four properties."
    }, {
      "heading" : "4.2. Extension to Nonlinear Cases",
      "text" : "Similar to other linear online learning methods, the proposed SCW learning can be extended to nonlinear cases. The following lemma shows the possibility of extending the proposed SCW algorithms to nonlinear cases using kernel tricks.\nLemma 1. (Representer Theorem) The mean µi and covariance Σi parameters computed by the soft confidence weight algorithm can be written as linear combinations of the input vectors with coefficients that depend only on inner products of input\nvectors, i.e.,\nΣi =\ni−1 ∑\np,q=1\nπ(i)p,qxpxq T + aI, µi =\ni−1 ∑\np\nνp (i)xp\nwhere νi (i) = 1 and νp (i+1) = νp (i) + αiyi ∑i−1 q πp,q (i)xq Txi for p < i, and πp,q (i+1) = −βi ∑ r,s πp,r (i)πs,q (i)xr Txs + πp,q (i), πp,i (i) = πi,p (i) = −βi ∑i−1 p,r πp,r (i)(xr Txi), πi,i (i+1) = −βi.\nThe above lemma can be proved by induction similar to the proof in (Crammer et al., 2008)."
    }, {
      "heading" : "4.3. Analysis of the Loss Bound",
      "text" : "Our analysis begins with the definition of confidence loss, which is used in (Crammer et al., 2008). The loss is a function of the margin mi normalized by√ v, i.e., m̃i =\nmi√ vi . We modified the confidence loss\nin (Crammer et al., 2008) as an upper-bounded loss by:\nℓφi(m̃i) =\n{\n0 m̃i ≥ φ min{fφ(m̃i), C 2(1+φ2)υi φ2 } m̃i < φ\nwhere fφ(m̃) = (−m̃ψ+\n√\nm̃2 φ4\n4 +φ2ζ)2\nφ2ζ . It is easy to see\nthat the loss ℓφ(m̃) holds the properties of Lemma 5 in (Crammer et al., 2008) for SCW-I.\nWe have the following loss bound.\nTheorem 1. Let (x1, y1)...(xn, yn) be an input sequence for SCW-I. Assume there exist µ∗ and Σ∗ such that for all i for which the algorithm made an update(αi > 0),\nµ∗Txiyi ≥ µi+1Txiyi, xiTΣ∗xi ≤ xiTΣi+1xi Then the following bound holds:\n∑\ni\nℓφi(m̃i) ≤ ∑\ni\n(αi) 2 υi\n≤ (1 + φ 2)\nφ2 (− log detΣ∗ + Tr(Σ∗) + µ∗TΣn+1−1µ∗ − d)\nThe above theorem can be proved by applying Lemma 7 and property 6 in Lemma 5 in (Crammer et al., 2008). If we let ℓφi(m̃i) upper bound the 0 − 1 loss by choosing an appropriate C, then our mistake number is also bounded by\n(1 + φ2)\nφ2 (− log detΣ∗ +Tr(Σ∗) +µ∗TΣn+1−1µ∗ − d)."
    }, {
      "heading" : "5. Empirical Evaluation",
      "text" : ""
    }, {
      "heading" : "5.1. Datasets and compared algorithms",
      "text" : "We adopt a variety of datasets from different domains:\n• synthetic data: we generated this data set by the method described in (Crammer et al., 2008), which is used to examine the effectiveness of second-order algorithms. Following (Crammer et al., 2009b), we also generated another version with 0.1 noise to examine the robustness of second-order algorithms. • Digital recognition: we use two benchmarks: “USPS” 1 and “MNIST” 2. For binary classification, we choose “1” vs “all” for “USPS”, and “1” vs “2” for “MNIST”. • Face data: we use the MIT-CBCL face imags 3. • Machine Learning datasets: we randomly choose several public machine learning datasets from 4. Table 2 shows the statistics of the list of datasets used.\nWe compare our methods with various online learning algorithms, including Perceptron (Rosenblatt, 1958), PA (Crammer et al., 2006), ROMMA (Li & Long, 1999) and its aggressive version agg-ROMMA, SecondOrder Perceptron (Cesa-Bianchi et al., 2005), Confidence Weighted Learning (Crammer et al., 2008), Improved Ellipsoid Method for Online Learning(IELLIP) (Yang et al., 2009), AROW (Crammer et al., 2009b), Normal HERD (NHERD) (Crammer & D.Lee, 2010) and NAROW (Orabona & Crammer, 2010). Following the similar parameter setting methods in (Dredze et al., 2008) and (Crammer et al., 2009b). The parameter r in AROW, paramter b in NAROW and parameters C in PA-I, PA-II, NHERD, SCW-I and SCW-II are all determined by cross validation to select the best one from {2−4, 2−3, ..., 23, 24}, the parameter η in CW, SCW-I and SCW-II are determined by cross validation to select the best one from\n1 http://www-i6.informatik.rwth-aachen.de/~keysers/usps.html 2 http://yann.lecun.com/exdb/mnist/ 3 http://cbcl.mit.edu/software-datasets/FaceData2.html 4 http://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/\n{0.5, 0.55, ..., 0.9, 0.95}, the parameter b in IELLIP is determined by cross validation to select the best one from {0.1, 0.2, ..., 0.9}. After the best parameters are determined, all the experiments were conducted over 20 random permutations for each dataset. All the results were reported by averaging over these 20 runs. We evaluate the performance by three metrics: (i) online cumulative mistake rate, (ii) number of updates (which would be closely related to the potential number of support vectors in kernel extension), and (iii) running time cost."
    }, {
      "heading" : "5.2. Experimental Results",
      "text" : "Table 3 summarizes the results of our empirical evaluation, where we only show margin-based second-order learning algorithms due to space limitation. For a more complete comparison, please refer to our supplemental material. The bold elements indicate the best performance with paired t-test at 95% significance level. We can draw several observations as follows.\nFirst of all, by examining the overall mistakes, we found that second-order algorithms usually outperforms first-order algorithms, and margin based algorithms usually outperforms non-margin based methods. This shows the efficacy of “Large Margin” and “Confidence” properties for learning better classifiers.\nSecond, by examining the original CW algorithm, we found that, it significantly outperforms the first-order algorithms (e.g. Perceptron, ROMMA, and PA algorithms) on the synthetic data without noise, but fails to outperform the first-order algorithms on some real-world datasets that often have noisy data. This empirical result verifies the importance of “Handling Non-separable” property in producing robust classifiers when dealing with noisy data.\nFurther, we found that AROW significantly outperforms CW in many real-world datasets (except minist). However, AROW usually produces considerably more updates and spends more running time than CW. This verifies that the importance of “adaptive margin” property of both CW and SCW to reduce the number of updates as well as the running time.\nMoreover, among all the compared algorithms, SCW often achieves the best or close to the best performance in terms of accuracy, number of updates, and running time cost. Finally, Figure 1 shows the online results of 13 algorithms with respect to varied numbers of samples in online learning process. The results again validate the advantages of SCW in both efficacy and efficiency among all the state-of-the-art algorithms."
    }, {
      "heading" : "6. Conclusion",
      "text" : "This paper proposed the Soft Confidence-Weighted (SCW) learning, a new second-order online learning method with state-of-the-art empirical performance. Unlike the existing second-order algorithms, SCW enjoys all the four properties: (i) large margin training, (ii) confidence weighting, (iii) adaptive margin, and (iv) capability of handling non-separable data. Empirically, we found the proposed SCW algorithms perform significantly better than the original CW algorithm, and outperform the state-of-the-art AROW algorithm for most cases in terms of both accuracy and efficiency. Future work will conduct more in-depth analysis of the mistake bounds and its multi-class extension (Crammer et al., 2009a)."
    }, {
      "heading" : "Appendix: Proof of Proposition 1 and 2",
      "text" : "Proof. First, when ℓφ ( N (µt,Σt); (xt, yt) )\n= 0, it is easy to see the solution is valid. When ℓφ ( N (µt,Σt); (xt, yt) ) > 0, it is easy to see the op-\ntimization problem is equivalent to\nDKL ( N (µ,Σ)‖N (µt,Σt) ) + Cξ, s.t. ℓ φ ( N (µ,Σ); (xt, yt) ) ≤ ξ and ξ ≥ 0\nSince ∑\nis positive semi-definite (PSD), it can be written as ∑\n= Υ2 to make the optimization with a convex constraint in µ and Υ simultaneously. But for convenient, we will still use Σ instead of Υ2 in the following analysis. The Lagrangian of the above optimization is\nL(µ,Σ, ξ, τ, λ) = DKL ( N (µ,Σ)‖N (µt,Σt) ) + Cξ +τ (φ √\nx⊤t Σxt − ytµ · xt − ξ)− λξ = DKL ( N (µ,Σ)‖N (µt,Σt) ) +ξ(C − τ − λ) + τ (φ √\nx⊤t Σxt − ytµ · xt)\n= 1\n2 log( detΣt detΣ ) + 1 2 Tr(Σ−1t Σ) + 1 2 (µt −µ)⊤Σ−1t (µt −µ)\n−d 2 + ξ(C − τ − λ) + τ (φ\n√\nx⊤t Σxt − ytµ · xt)\nwhere τ ≥ 0 and λ ≥ 0 are Lagrange multipliers. We now find the minimum of the Lagrangian with respect to the primal variables µ, Σ and ξ.\n∂L ∂µ = Σ−1t (µ −µt) + τ (−ytxt) = 0 ⇒ µ = µt + τytΣtxt ∂L ∂Σ = 0 ⇒ Σ−1t+1 = Σ−1t + τφ xtx ⊤ t √\nx⊤t Σt+1xt\nand C − τ − λ = 0, so τ = C − λ ≤ C, thus τ ∈ [0, C] The KKT conditions for the optimization are:\nφ\n√\nx⊤t Σxt − ytµ · xt − ξ ≤ 0,−ξ ≤ 0, τ, λ ≥ 0\nτ (φ √\nx⊤t Σxt − ytµ · xt − ξ) = 0, λξ = 0\nCase 1. τ 6= 0 As τ(φ √\nx⊤t Σxt−ytµ ·xt−ξ) = 0 implies (φ √ x⊤t Σxt− ytµ · xt − ξ) = 0, the KKT conditions are simplified:\n−ξ ≤ 0, τ > 0, λ ≥ 0\nφ\n√\nx⊤t Σxt − ytµ · xt − ξ = 0, λξ = 0\nSub-case 1.1. λ 6= 0 When λ 6= 0, λξ = 0, implies ξ = 0. The KKT conditions are simplified as\nτ > 0, λ > 0, ξ = 0, φ √\nx⊤t Σxt − ytµ · xt = 0\nFinally, we have the following:\nΣt+1 = ( Σ−1t + τφ xtx\n⊤ t\n√\nx⊤t Σt+1xt\n)−1\n= Σt − Σtxt ( τφ √\nx⊤t Σt+1xt + τφx ⊤ t Σtxt\n)\nx ⊤\nt Σt\nLet ut = x ⊤ t Σt+1xt, vt = x ⊤ t Σtxt, mt = yt(µt ·xt), multiplying by x⊤t (left) and xt (right), we get ut = vt − vt( τφ√ut+τφvt )vt, which can be used to solve ut:\n√ ut = −τφvt + √ τ2φ2v2t + 4vt 2 .\nAnd φ √ x⊤t Σxt−ytµ ·xt = 0 implies φ √ ut−mt−τvt = 0. Thus, φ −τφvt+ √ τ2φ2v2t+4vt 2 − mt − τvt = 0, which can be rearranged as: v2t (1+φ 2)τ2+2mtvt(1+ φ2\n2 )τ + (m2t − φ2vt). The larger root is then\nτ = −mtvt(1 + φ\n2\n2 ) +\n√ ∆\nv2t (1 + φ 2)\n,\nwhere ∆ = m2tv 2 t (1 +\nφ2\n2 ) 2 − v2t (1 + φ2)(m2t − φ2vt).\nIf τ ∈ (0, C), then λ = C − τ ∈ (0, C). Sub-case 1.2. λ = 0 C − τ − λ = 0 implies τ = C. The KKT conditions can be simplified as:\n−ξ ≤ 0, τ = C, λ = 0, φ √\nx⊤t Σxt − ytµ · xt − ξ = 0\nWe thus have:\nφ\n√\nx⊤t Σxt − ytµ · xt\n= [φ −τφvt +\n√\nτ 2φ2v2t + 4vt 2 −mt − τvt]|τ=C = ξ ≥ 0\nIt is easy to verify that\nf ′(τ ) = −φ2vt 2 + φ3v2t τ 2 √ τ 2φ2v2t + 4vt − vt = 0\nhas no solution on [0,+∞) and f ′(0) = −φ2vt2 −vt < 0. As a result, f ′(τ) < 0, τ ∈ [0,+∞), which implies f(τ) is decreasing on [0,+∞).\nf(C) ≥ 0 = f(θ)\nwhere θ = −mtvt(1+φ\n2 2 )+\n√\nm2tv 2 t (1+ φ2 2 )2−v2t (1+φ2)(m2t−φ2vt)\nv2t (1+φ 2)\n,\nwhich thus implies C ≤ θ. Case 2. τ = 0 When τ = 0, since C − τ − λ = 0, λ = C, the KKT condtions are simplified as\nφ\n√\nx⊤t Σxt − ytµ · xt ≤ 0, τ = 0, λ = C, ξ = 0\nThus, µt+1 = µt and Σt+1 = Σt; as a result, φ √\nx⊤t Σtxt − ytµt · xt ≤ 0, which contradicts with ℓφ ( N (µ,Σ); (xt, yt) ) > 0.\nFor SCW-II, the Lagrangian of the optimization is\nL(µ,Σ, ξ, τ, λ) = DKL ( N (µ,Σ)‖N (µt,Σt) ) + Cξ2 +τ (φ √\nx⊤t Σxt − ytµ · xt − ξ)− λξ = DKL ( N (µ,Σ)‖N (µt,Σt) ) +ξ(Cξ − τ − λ) + τ (φ √\nx⊤t Σxt − ytµ · xt)\n= 1\n2 log( detΣt detΣ ) + 1 2 Tr(Σ−1t Σ) + 1 2 (µt −µ)⊤Σ−1t (µt −µ)\n−d 2 + ξ(Cξ − τ − λ) + τ (φ\n√\nx⊤t Σxt − ytµ · xt)\nwhere τ ≥ 0 and λ ≥ 0 are Lagrange multipliers. We now find the minimum of the Lagrangian with respect to the primal variables µ, Σ and ξ.\n∂L ∂µ = Σ−1t (µ −µt) + τ (−ytxt) = 0 ⇒ µ = µt + τytΣtxt ∂L ∂Σ = 0 ⇒ Σ−1t+1 = Σ−1t + τφ xtx ⊤ t √\nx⊤t Σt+1xt\nand 2Cξ−τ−λ = 0, so ξ = τ+λ2C . The KKT conditions for the optimization are:\nφ\n√\nx⊤t Σxt − ytµ · xt − ξ ≤ 0 ξ ≥ 0, τ ≥ 0, λ ≥ 0\nτ (φ √\nx⊤t Σxt − ytµ · xt − ξ) = 0 λξ = 0\nThe rest proof is similar to that of SCW-I."
    }, {
      "heading" : "Acknowledgments",
      "text" : "This work was in part supported by Singapore MOE tier 1 project (RG33/11) and Microsoft Research project (M4060936)."
    } ],
    "references" : [ {
      "title" : "A second-order perceptron algorithm",
      "author" : [ "Cesa-Bianchi", "Nicolò", "Conconi", "Alex", "Gentile", "Claudio" ],
      "venue" : "SIAM J. Comput.,",
      "citeRegEx" : "Cesa.Bianchi et al\\.,? \\Q2005\\E",
      "shortCiteRegEx" : "Cesa.Bianchi et al\\.",
      "year" : 2005
    }, {
      "title" : "Learning via gaussian herding",
      "author" : [ "Crammer", "Koby", "D.Lee", "Daniel" ],
      "venue" : "In NIPS, pp",
      "citeRegEx" : "Crammer et al\\.,? \\Q2010\\E",
      "shortCiteRegEx" : "Crammer et al\\.",
      "year" : 2010
    }, {
      "title" : "Online passiveaggressive algorithms",
      "author" : [ "Crammer", "Koby", "Dekel", "Ofer", "Keshet", "Joseph", "ShalevShwartz", "Shai", "Singer", "Yoram" ],
      "venue" : "Journal of Machine Learning Research,",
      "citeRegEx" : "Crammer et al\\.,? \\Q2006\\E",
      "shortCiteRegEx" : "Crammer et al\\.",
      "year" : 2006
    }, {
      "title" : "Exact convex confidence-weighted learning",
      "author" : [ "Crammer", "Koby", "Dredze", "Mark", "Pereira", "Fernando" ],
      "venue" : "In NIPS, pp",
      "citeRegEx" : "Crammer et al\\.,? \\Q2008\\E",
      "shortCiteRegEx" : "Crammer et al\\.",
      "year" : 2008
    }, {
      "title" : "Multiclass confidence weighted algorithms",
      "author" : [ "Crammer", "Koby", "Dredze", "Mark", "Kulesza", "Alex" ],
      "venue" : "In EMNLP, pp",
      "citeRegEx" : "Crammer et al\\.,? \\Q2009\\E",
      "shortCiteRegEx" : "Crammer et al\\.",
      "year" : 2009
    }, {
      "title" : "Adaptive regularization of weight vectors",
      "author" : [ "Crammer", "Koby", "Kulesza", "Alex", "Dredze", "Mark" ],
      "venue" : "In NIPS,",
      "citeRegEx" : "Crammer et al\\.,? \\Q2009\\E",
      "shortCiteRegEx" : "Crammer et al\\.",
      "year" : 2009
    }, {
      "title" : "Confidence-weighted linear classification",
      "author" : [ "Dredze", "Mark", "Crammer", "Koby", "Pereira", "Fernando" ],
      "venue" : "In ICML, pp",
      "citeRegEx" : "Dredze et al\\.,? \\Q2008\\E",
      "shortCiteRegEx" : "Dredze et al\\.",
      "year" : 2008
    }, {
      "title" : "Adaptive subgradient methods for online learning and stochastic optimization",
      "author" : [ "Duchi", "John C", "Hazan", "Elad", "Singer", "Yoram" ],
      "venue" : "Journal of Machine Learning Research,",
      "citeRegEx" : "Duchi et al\\.,? \\Q2011\\E",
      "shortCiteRegEx" : "Duchi et al\\.",
      "year" : 2011
    }, {
      "title" : "Online multiple kernel learning: Algorithms and mistake bounds",
      "author" : [ "Jin", "Rong", "Hoi", "Steven C. H", "Yang", "Tianbao" ],
      "venue" : "In ALT,",
      "citeRegEx" : "Jin et al\\.,? \\Q2010\\E",
      "shortCiteRegEx" : "Jin et al\\.",
      "year" : 2010
    }, {
      "title" : "Pamr: Passive aggressive mean reversion strategy for portfolio selection",
      "author" : [ "Li", "Bin", "Zhao", "Peilin", "Hoi", "Steven C. H", "Gopalkrishnan", "Vivekanand" ],
      "venue" : "Machine Learning,",
      "citeRegEx" : "Li et al\\.,? \\Q2012\\E",
      "shortCiteRegEx" : "Li et al\\.",
      "year" : 2012
    }, {
      "title" : "The relaxed online maximum margin algorithm",
      "author" : [ "Li", "Yi", "Long", "Philip M" ],
      "venue" : "In NIPS, pp",
      "citeRegEx" : "Li et al\\.,? \\Q1999\\E",
      "shortCiteRegEx" : "Li et al\\.",
      "year" : 1999
    }, {
      "title" : "New adaptive algorithms for online classification",
      "author" : [ "Orabona", "Francesco", "Crammer", "Koby" ],
      "venue" : "In NIPS,",
      "citeRegEx" : "Orabona et al\\.,? \\Q2010\\E",
      "shortCiteRegEx" : "Orabona et al\\.",
      "year" : 2010
    }, {
      "title" : "The perceptron: A probabilistic model for information storage and organization in the brain",
      "author" : [ "Rosenblatt", "Frank" ],
      "venue" : "Psych. Rev.,",
      "citeRegEx" : "Rosenblatt and Frank.,? \\Q1958\\E",
      "shortCiteRegEx" : "Rosenblatt and Frank.",
      "year" : 1958
    }, {
      "title" : "Online learning by ellipsoid method",
      "author" : [ "Yang", "Liu", "Jin", "Rong", "Ye", "Jieping" ],
      "venue" : "In ICML, pp",
      "citeRegEx" : "Yang et al\\.,? \\Q2009\\E",
      "shortCiteRegEx" : "Yang et al\\.",
      "year" : 2009
    }, {
      "title" : "Double updating online learning",
      "author" : [ "Zhao", "Peilin", "Hoi", "Steven C. H", "Jin", "Rong" ],
      "venue" : "Journal of Machine Learning Research,",
      "citeRegEx" : "Zhao et al\\.,? \\Q2011\\E",
      "shortCiteRegEx" : "Zhao et al\\.",
      "year" : 2011
    }, {
      "title" : "Online auc maximization",
      "author" : [ "Zhao", "Peilin", "Hoi", "Steven C. H", "Jin", "Rong", "Yang", "Tianbao" ],
      "venue" : "In ICML, pp",
      "citeRegEx" : "Zhao et al\\.,? \\Q2011\\E",
      "shortCiteRegEx" : "Zhao et al\\.",
      "year" : 2011
    } ],
    "referenceMentions" : [ {
      "referenceID" : 9,
      "context" : ", 2011a;b) represent a family of fast and simple machine learning techniques, which usually make few statistical assumptions and can be applied to a wide range of applications (Li et al., 2012).",
      "startOffset" : 176,
      "endOffset" : 193
    }, {
      "referenceID" : 2,
      "context" : "Online learning has been actively studied in machine learning community, in which a variety of online learning algorithms have been proposed, including a number of first-order algorithms such as the well-known Perceptron algorithm (Rosenblatt, 1958) and the Passive-Aggressive (PA) algorithms (Crammer et al., 2006).",
      "startOffset" : 293,
      "endOffset" : 315
    }, {
      "referenceID" : 0,
      "context" : "Recent years have seen a surge of studies on the second-order online learning algorithms (Cesa-Bianchi et al., 2005; Dredze et al., 2008; Crammer et al., 2009b; Orabona & Crammer, 2010; Duchi et al., 2011), which have shown that parameter confidence information can be explored to guide and improve online learning performance (Cesa-Bianchi et al.",
      "startOffset" : 89,
      "endOffset" : 205
    }, {
      "referenceID" : 6,
      "context" : "Recent years have seen a surge of studies on the second-order online learning algorithms (Cesa-Bianchi et al., 2005; Dredze et al., 2008; Crammer et al., 2009b; Orabona & Crammer, 2010; Duchi et al., 2011), which have shown that parameter confidence information can be explored to guide and improve online learning performance (Cesa-Bianchi et al.",
      "startOffset" : 89,
      "endOffset" : 205
    }, {
      "referenceID" : 7,
      "context" : "Recent years have seen a surge of studies on the second-order online learning algorithms (Cesa-Bianchi et al., 2005; Dredze et al., 2008; Crammer et al., 2009b; Orabona & Crammer, 2010; Duchi et al., 2011), which have shown that parameter confidence information can be explored to guide and improve online learning performance (Cesa-Bianchi et al.",
      "startOffset" : 89,
      "endOffset" : 205
    }, {
      "referenceID" : 0,
      "context" : ", 2011), which have shown that parameter confidence information can be explored to guide and improve online learning performance (Cesa-Bianchi et al., 2005).",
      "startOffset" : 129,
      "endOffset" : 156
    }, {
      "referenceID" : 6,
      "context" : "For example, Confidence-weighted (CW) learning (Dredze et al., 2008; Crammer et al., 2009a) maintains a Gaussian distribution over some linear classifier hypotheses and applies it to control the direction and scale of parameter updates (Dredze et al.",
      "startOffset" : 47,
      "endOffset" : 91
    }, {
      "referenceID" : 6,
      "context" : ", 2009a) maintains a Gaussian distribution over some linear classifier hypotheses and applies it to control the direction and scale of parameter updates (Dredze et al., 2008).",
      "startOffset" : 153,
      "endOffset" : 174
    }, {
      "referenceID" : 3,
      "context" : "Although CW learning has formal guarantees in the mistakebound model (Crammer et al., 2008), it can overfit in certain situations due to its aggressive update rules based upon a separable data assumption.",
      "startOffset" : 69,
      "endOffset" : 91
    }, {
      "referenceID" : 2,
      "context" : "Our work is closely related to several first and second order online learning algorithms, including Passive-Aggressive (PA) learning (Crammer et al., 2006), Confidence-Weighted learning (Dredze et al.",
      "startOffset" : 133,
      "endOffset" : 155
    }, {
      "referenceID" : 6,
      "context" : ", 2006), Confidence-Weighted learning (Dredze et al., 2008), and Adaptive Regularization of Weights learning (Crammer et al.",
      "startOffset" : 38,
      "endOffset" : 59
    }, {
      "referenceID" : 3,
      "context" : "The above lemma can be proved by induction similar to the proof in (Crammer et al., 2008).",
      "startOffset" : 67,
      "endOffset" : 89
    }, {
      "referenceID" : 3,
      "context" : "Our analysis begins with the definition of confidence loss, which is used in (Crammer et al., 2008).",
      "startOffset" : 77,
      "endOffset" : 99
    }, {
      "referenceID" : 3,
      "context" : "We modified the confidence loss in (Crammer et al., 2008) as an upper-bounded loss by:",
      "startOffset" : 35,
      "endOffset" : 57
    }, {
      "referenceID" : 3,
      "context" : "It is easy to see that the loss lφ(m̃) holds the properties of Lemma 5 in (Crammer et al., 2008) for SCW-I.",
      "startOffset" : 74,
      "endOffset" : 96
    }, {
      "referenceID" : 3,
      "context" : "The above theorem can be proved by applying Lemma 7 and property 6 in Lemma 5 in (Crammer et al., 2008).",
      "startOffset" : 81,
      "endOffset" : 103
    }, {
      "referenceID" : 3,
      "context" : "We adopt a variety of datasets from different domains: • synthetic data: we generated this data set by the method described in (Crammer et al., 2008), which is used to examine the effectiveness of second-order algorithms.",
      "startOffset" : 127,
      "endOffset" : 149
    }, {
      "referenceID" : 2,
      "context" : "We compare our methods with various online learning algorithms, including Perceptron (Rosenblatt, 1958), PA (Crammer et al., 2006), ROMMA (Li & Long, 1999) and its aggressive version agg-ROMMA, SecondOrder Perceptron (Cesa-Bianchi et al.",
      "startOffset" : 108,
      "endOffset" : 130
    }, {
      "referenceID" : 0,
      "context" : ", 2006), ROMMA (Li & Long, 1999) and its aggressive version agg-ROMMA, SecondOrder Perceptron (Cesa-Bianchi et al., 2005), Confidence Weighted Learning (Crammer et al.",
      "startOffset" : 94,
      "endOffset" : 121
    }, {
      "referenceID" : 3,
      "context" : ", 2005), Confidence Weighted Learning (Crammer et al., 2008), Improved Ellipsoid Method for Online Learning(IELLIP) (Yang et al.",
      "startOffset" : 38,
      "endOffset" : 60
    }, {
      "referenceID" : 13,
      "context" : ", 2008), Improved Ellipsoid Method for Online Learning(IELLIP) (Yang et al., 2009), AROW (Crammer et al.",
      "startOffset" : 63,
      "endOffset" : 82
    }, {
      "referenceID" : 6,
      "context" : "Following the similar parameter setting methods in (Dredze et al., 2008) and (Crammer et al.",
      "startOffset" : 51,
      "endOffset" : 72
    } ],
    "year" : 2012,
    "abstractText" : "In this paper, we propose a new Soft Confidence-Weighted (SCW) online learning scheme, which enables the conventional confidence-weighted learning method to handle non-separable cases. Unlike the previous confidence-weighted learning algorithms, the proposed soft confidence-weighted learning method enjoys all the four salient properties: (i) large margin training, (ii) confidence weighting, (iii) capability to handle non-separable data, and (iv) adaptive margin. Our experimental results show that the proposed SCW algorithms significantly outperform the original CW algorithm. When comparing with a variety of state-of-theart algorithms (including AROW, NAROW and NHERD), we found that SCW generally achieves better or at least comparable predictive accuracy, but enjoys significant advantage of computational efficiency (i.e., smaller number of updates and lower time cost).",
    "creator" : "LaTeX with hyperref package"
  }
}