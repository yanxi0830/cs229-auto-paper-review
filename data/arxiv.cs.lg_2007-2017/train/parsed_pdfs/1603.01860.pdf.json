{
  "name" : "1603.01860.pdf",
  "metadata" : {
    "source" : "META",
    "title" : "Generalization error bounds for learning to rank:  Does the length of document lists matter?",
    "authors" : [ "Ambuj Tewari" ],
    "emails" : [ "TEWARIA@UMICH.EDU", "SOUGATA@UMICH.EDU" ],
    "sections" : [ {
      "heading" : null,
      "text" : "ar X\niv :1\n60 3.\n01 86\n0v 1\n[ cs\n.L G\n] 6\nM ar"
    }, {
      "heading" : "1. Introduction",
      "text" : "Learning to rank at the query level has emerged as an exciting research area at the intersection of information retrieval and machine learning. Training data in learning to rank consists of queries along with associated documents, where documents are represented as feature vectors. For each query, the documents are labeled with human relevance judgements. The goal at training time is to learn a ranking function that can, for a future query, rank its associated documents in order of their relevance to the query. The performance of ranking functions on test sets is evaluated using a variety of performance measures such as NDCG (Järvelin & Kekäläinen, 2002), ERR (Chapelle et al., 2009) or Average Precision (Yue et al., 2007).\nThe performance measures used for testing ranking methods cannot be directly optimized during training time as they lead to discontinuous optimization problems. As a re-\nProceedings of the 32nd International Conference on Machine Learning, Lille, France, 2015. JMLR: W&CP volume 37. Copyright 2015 by the author(s).\nsult, researchers often minimize surrogate loss functions that are easier to optimize. For example, one might consider smoothed versions of, or convex upper bounds on, the target performance measure. However, as soon as one optimizes a surrogate loss, one has to deal with two questions (Chapelle et al., 2011). First, does minimizing the surrogate on finite training data imply small expected surrogate loss on infinite unseen data? Second, does small expected surrogate loss on infinite unseen data imply small target loss on infinite unseen data? The first issue is one of generalization error bounds for empirical risk minimization (ERM) algorithms that minimize surrogate loss on training data. The second issue is one of calibration: does consistency in the surrogate loss imply consistency in the target loss?\nThis paper deals with the former issue, viz. that of generalization error bounds for surrogate loss minimization. In pioneering works, Lan et al. (2008; 2009) gave generalization error bounds for learning to rank algorithms. However, while the former paper was restricted to analysis of pairwise approach to learning to rank, the later paper was limited to results on just three surrogates: ListMLE, ListNet and RankCosine. To the best of our knowledge, the most generally applicable bound on the generalization error of query-level learning to rank algorithms has been obtained by Chapelle & Wu (2010).\nThe bound of Chapelle & Wu (2010), while generally applicable, does have an explicit dependence on the length of the document list associated with a query. Our investigations begin with this simple question: is an explicit dependence on the length of document lists unavoidable in generalization error bounds for query-level learning to rank algorithms? We focus on the prevalent technique in literature where learning to rank algorithms learn linear scoring functions and obtain ranking by sorting scores in descending order. Our first contribution (Theorem 3) is to show that dimension of linear scoring functions that are permutation invariant (a necessary condition for being valid scoring functions for learning to rank) has no dependence on the length\nof document lists. Our second contribution (Theorems 5, 6, 9) is to show that as long as one uses the “right” norm in defining the Lipschitz constant of the surrogate loss, we can derive generalization error bounds that have no explicit dependence on the length of document lists. The reason that the second contribution involves three bounds is that they all have different strengths and scopes of application (See Table 1 for a comparison). Our final contribution is to provide novel generalization error bounds for learning to rank in two previously unexplored settings: almost dimension independent bounds when using high dimensional features with ℓ1 regularization (Theorem 12) and “optimistic” rates (that can be as fast as O(1/n)) when the loss function is smooth (Theorem 17). We also apply our results on popular convex and non-convex surrogates. All omitted proofs can be found in the appendix (see supplementary material)."
    }, {
      "heading" : "2. Preliminaries",
      "text" : "In learning to rank (also called subset ranking to distinguish it from other related problems, e.g., bipartite ranking), a training example is of the form ((q, d1, . . . , dm), y). Here q is a search query and d1, . . . , dm are m documents with varying degrees of relevance to the query. Human labelers provide the relevance vector y ∈ Rm where the entries in y contain the relevance labels for the m individual documents. Typically, y has integer-valued entries in the range {0, . . . , Ymax} where Ymax is often less than 5. For our theoretical analysis, we get rid of some of these details by assuming that some feature map Ψ exists to map a query document pair (q, d) to Rd. As a result, the training example ((q, d1, . . . , dm), y) gets converted into (X, y) where X = [Ψ(q, d1), . . . ,Ψ(q, dm)]\n⊤ is an m × d matrix with the m query-document feature vector as rows. With this abstraction, we have an input space X ⊆ Rm×d and a label space Y ⊆ Rm. A training set consists of iid examples (X(1), y(1)), . . . , (X(n), y(n)) drawn from some underlying distribution D. To rank the documents in an instance X ∈ X , often a score vector s ∈ Rm is computed. A ranking of the documents can then be obtained from s by sorting its entries in decreasing order. A common choice for the scoring function is to make it linear in the input X and consider the following class of vector-valued\nfunctions:\nFlin = {X 7→ Xw : X ∈ Rm×d, w ∈ Rd}. (1)\nDepending upon the regularization, we also consider the following two subclasses of Flin :\nF2 := {X 7→ Xw : X ∈ Rm×d, w ∈ Rd, ‖w‖2 ≤ W2}, F1 := {X 7→ Xw : X ∈ Rm×d, w ∈ Rd, ‖w‖1 ≤ W1}.\nIn the input space X , it is natural for the rows of X to have a bound on the appropriate dual norm. Accordingly, whenever we use F2, the input space is set to X = {X ∈ Rm×d : ∀j ∈ [m], ‖Xj‖2 ≤ RX} where Xj denotes jth row of X and [m] := {1, . . . ,m}. Similarly, when we use F1, we set X = {X ∈ Rm×d : ∀j ∈ [m], ‖Xj‖∞ ≤ R̄X}. These are natural counterparts to the following function classes studied in binary classification and regression:\nG2 := {x 7→ 〈x,w〉 : ‖x‖2 ≤ RX , w ∈ Rd, ‖w‖2 ≤ W2}, G1 := {x 7→ 〈x,w〉 : ‖x‖∞ ≤ R̄X , w ∈ Rd, ‖w‖1 ≤ W1}.\nA key ingredient in the basic setup of the learning to rank problem is a loss function φ : Rm × Y → R+ where R+ denotes the set of non-negative real numbers. Given a class F of vector-valued functions, a loss φ yields a natural loss class: namely the class of real-valued functions that one gets by composing φ with functions in F :\nφ ◦ F := {(X, y) 7→ φ(f(X), y) : X ∈ Rm×d, f ∈ F}.\nFor vector valued scores, the Lipschitz constant of φ depends on the norm ||| · ||| that we decide to use in the score space (||| · |||⋆ is dual of ||| · |||):\n∀y ∈ Y, s, s′ ∈ Rm, |φ(s1, y)−φ(s2, y)| ≤ Gφ|||s1−s2|||.\nIf φ is differentiable, this is equivalent to: ∀y ∈ Y, s ∈ R\nm, |||∇sφ(s, y)|||⋆ ≤ Gφ. Similarly, the smoothness constant Hφ of φ defined as: ∀y ∈ Y, s, s′ ∈ Rm,\n|||∇sφ(s1, y)−∇sφ(s2, y)|||⋆ ≤ Hφ|||s1 − s2|||.\nalso depends on the norm used in the score space. If φ is twice differentiable, the above inequality is equivalent to\n∀y ∈ Y, s ∈ Rm, |||∇2sφ(s, y)|||op ≤ Hφ\nwhere ||| · |||op is the operator norm induced by the pair ||| · |||, ||| · |||⋆ and defined as |||M |||op := supv 6=0 |||Mv|||⋆|||v||| . Define the expected loss of w under the distribution D Lφ(w) := E(X,y)∼D [φ(Xw, y)] and its empirical loss on the sample as L̂φ(w) := 1n ∑n i=1 φ(X (i)w, y(i)). The minimizer of Lφ(w) (resp. L̂φ(w)) over some function class (parameterized by w) will be denoted by w⋆ (resp. ŵ). We may refer to expectations w.r.t. the sample using Ê [·]. To reduce notational clutter, we often refer to (X, y) jointly by Z and X × Y by Z . For vectors, 〈u, v〉 denotes the standard inner product ∑ i uivi and for matrices U, V of the\nsame shape, 〈U, V 〉 means Tr(U⊤V ) = ∑ij UijVij . The set of m! permutation π of degree m is denoted by Sm. A vector of ones is denoted by 1."
    }, {
      "heading" : "3. Application to Specific Losses",
      "text" : "To whet the reader’s appetite for the technical presentation that follows, we will consider two loss functions, one convex and one non-convex, to illustrate the concrete improvements offered by our new generalization bounds. A generalization bound is of the form: Lφ(ŵ) ≤ Lφ(w ⋆)+“complexity term”. It should be noted that w⋆ is not available to the learning algorithm as it needs knowledge of underlying distribution of the data. The complexity term of Chapelle & Wu (2010) is O(GCWφ W2RX √ m/n). The constant GCWφ is the Lipschitz constant of the surrogate φ (viewed as a function of the score vector s) w.r.t. ℓ2 norm. Our bounds will instead be of the form O(GφW2RX √ 1/n), where Gφ is the Lipschitz constant of φ w.r.t. ℓ∞ norm. Note that our bounds are free of any explicit m dependence. Also, by definition, Gφ ≤ GCWφ √ m but the former can be much smaller as the two examples below illustrate. In benchmark datasets (Liu et al., 2007), m can easily be in the 100-1000 range."
    }, {
      "heading" : "3.1. Application to ListNet",
      "text" : "The ListNet ranking method (Cao et al., 2007) uses a convex surrogate, that is defined in the following way1. Define m maps from Rm to R as: Pj(v) = exp(vj)/ ∑m i=1 exp(vi) for j ∈ [m]. Then, we have, for s ∈ Rm and y ∈ Rm,\nφLN(s, y) = − m∑\nj=1\nPj(y) logPj(s).\nAn easy calculation shows that the Lipschitz (as well as smoothness) constant of φLN is m independent.\n1The ListNet paper actually defines a family of losses based on probability models for top k documents. We use k = 1 in our definition since that is the version implemented in their experimental results.\nProposition 1. The Lipschitz (resp. smoothness) constant of φLN w.r.t. ‖ · ‖∞ satisfies GφLN ≤ 2 (resp. HφLN ≤ 2) for any m ≥ 1. Since the bounds above are independent of m, so the generalization bounds resulting from their use in Theorem 9 and Theorem 17 will also be independent of m (up to logarithmic factors). We are not aware of prior generalization bounds for ListNet that do not scale with m. In particular, the results of Lan et al. (2009) have an m! dependence since they consider the top-m version of ListNet. However, even if the top-1 variant above is considered, their proof technique will result in at least a linear dependence on m and does not result in as tight a bound as we get from our general results. It is also easy to see that the Lipschitz constant GCWφLN of ListNet loss w.r.t. ℓ2 norm is also 2 and hence the bound of Chapelle & Wu (2010) necessarily has a √ m dependence in it. Moreover, generalization error bounds for ListNet exploiting its smoothness will interpolate between the pessimistic 1/ √ n and optimistic 1/n rates. These have never been provided before."
    }, {
      "heading" : "3.2. Application to Smoothed DCG@1",
      "text" : "This example is from the work of Chapelle & Wu (2010). Smoothed DCG@1, a non-convex surrogate, is defined as:\nφSD(s, y) = D(1)\nm∑\ni=1\nG(yi) exp(si/σ)∑ j exp(sj/σ) ,\nwhere D(i) = 1/ log2(1 + i) is the “discount” function and G(i) = 2i − 1 is the “gain” function. The amount of smoothing is controlled by the parameter σ > 0 and the smoothed version approaches DCG@1 as σ → 0 (DCG stands for Discounted Cumulative Gain (Järvelin & Kekäläinen, 2002)).\nProposition 2. The Lipschitz constant of φSD w.r.t. ‖ · ‖∞ satisfies GφSD ≤ 2D(1)G(Ymax)/σ for any m ≥ 1. Here Ymax is maximum possible relevance score of a document (usually less than 5).\nAs in the ListNet loss case we previously considered, the generalization bound resulting from Theorem 9 will be independent of m. This is intuitively satisfying: DCG@1, whose smoothing we are considering, only depends on the document that is put in the top position by the score vector s (and not on the entire sorted order of s). Our generalization bound does not deteriorate as the total list size m grows. In contrast, the bound of Chapelle & Wu (2010) will necessarily deteriorate as\n√ m since the constant GCWφSD\nis the same as GφSD . Moreover, it should be noted that even in the original SmoothedDCG paper, σ is present in the denominator of GCWφSD , so our results are directly comparable. Also note that this example can easily be extended to consider DCG@k for case when document list length m ≫ k (a very common scenario in practice)."
    }, {
      "heading" : "3.3. Application to RankSVM",
      "text" : "RankSVM (Joachims, 2002) is another well established ranking method, which minimizes a convex surrogate based on pairwise comparisons of documents. A number of studies have shown that ListNet has better empirical performance than RankSVM. One possible reason for the better performance of ListNet over RankSVM is that the Lipschitz constant of RankSVM surrogate w.r.t ‖ · ‖∞ doe scale with document list size as O(m2). Due to lack of space, we give the details in the supplement."
    }, {
      "heading" : "4. Does The Length of Document Lists Matter?",
      "text" : "Our work is directly motivated by a very interesting generalization bound for learning to rank due to Chapelle & Wu (2010, Theorem 1). They considered a Lipschitz continuous loss φ with Lipschitz constant GCWφ w.r.t. the ℓ2 norm. They show that, with probability at least 1− δ,\n∀w ∈ F2, Lφ(w) ≤ L̂φ(w) + 3GCWφ W2RX √ m\nn\n+\n√ 8 log(1/δ)\nn .\nThe dominant term on the right is O(GCWφ W2RX √ m/n). In the next three sections, we will derive improved bounds of the form Õ(GφW2RX √ 1/n) where Gφ ≤ GCWφ √ m but can be much smaller. Before we do that, let us examine the dimensionality reduction in linear scoring function that is caused by a natural permutation invariance requirement."
    }, {
      "heading" : "4.1. Permutation invariance removes m dependence in dimensionality of linear scoring functions",
      "text" : "As stated in Section 2, a ranking is obtained by sorting a score vector obtained via a linear scoring function f . Consider the space of linear scoring function that consists of all linear maps f that map Rm×d to Rm:\nFfull := { X 7→ [〈X,W1〉 , . . . , 〈X,Wm〉]⊤ : Wi ∈ Rm×d } .\nThese linear maps are fully parameterized by matrices W1, . . . ,Wm. Thus, a full parameterization of the linear scoring function is of dimension m2d. Note that the popularly used class of linear scoring functions Flin defined in Eq. 1 is actually a low d-dimensional subspace of the full m2d dimensional space of all linear maps. It is important to note that the dimension of Flin is independent of m. In learning theory, one of the factors influencing the generalization error bound is the richness of the class of hypothesis functions. Since the linear function class Flin has dimension independent of m, we intuitively expect that, at least under some conditions, algorithms that minimize ranking losses using linear scoring functions should have\nan m independent complexity term in the generalization bound. The reader might wonder whether the dimension reduction from m2d to d in going from Ffull to Flin is arbitrary. To dispel this doubt, we prove the lower dimensional class Flin is the only sensible choice of linear scoring functions in the learning to rank setting. This is because scoring functions should satisfy a permutation invariance property. That is, if we apply a permutation π ∈ Sm to the rows of X to get a matrix πX then the scores should also simply get permuted by π. That is, we should only consider scoring functions in the following class:\nFperminv = {f : ∀π ∈ Sm, ∀X ∈ Rm×d, πf(X) = f(πX)}.\nThe permutation invariance requirement, in turn, forces a reduction from dimension m2d to just 2d (which has no dependence on m).\nTheorem 3. The intersection of the function classes Ffull and Fperminv is the 2d-dimensional class:\nF ′lin = {X 7→ Xw + (1⊤Xv)1 : w, v ∈ Rd}. (2)\nNote that the extra degree of freedom provided by the v parameter in Eq. 2 is useless for ranking purposes since adding a constant vector (i.e., a multiple of 1) to a score vector has no effect on the sorted order. This is why we said that Flin is the only sensible choice of linear scoring functions."
    }, {
      "heading" : "5. Online to Batch Conversion",
      "text" : "In this section, we build some intuition as to why it is natural to use ‖ · ‖∞ in defining the Lipschitz constant of the loss φ. To this end, consider the following well known online gradient descent (OGD) regret guarantee. Recall that OGD refers to the simple online algorithm that makes the update wi+1 ← wi−η∇wifi(wi) at time i. If we run OGD to generate wi’s, we have, for all ‖w‖2 ≤ W2:\nn∑\ni=1\nfi(wi)− n∑\ni=1\nfi(w) ≤ W 22 2η + ηG2n\nwhere G is a bound on the maximum ℓ2-norm of the gradients ∇wifi(wi) and fi’s have to be convex. If (X(1), y(1)), . . . , (X(n), y(n)) are iid then by setting fi(w) = φ(X\n(i)w, y(i)), 1 ≤ i ≤ n we can do an “online to batch conversion”. That is, we optimize over η, take expectations and use Jensen’s inequality to get the following excess risk bound:\n∀‖w‖2 ≤ W2, E [Lφ(ŵOGD)]− Lφ(w) ≤ W2G √ 2\nn\nwhere ŵOGD = 1n ∑n\ni=1 wi and G has to satisfy (noting that s = X(i)wi)\nG ≥ ‖∇wifi(wi)‖2 = ‖(X(i))⊤∇sφ(X(i)wi, y(i))‖2\nwhere we use the chain rule to express ∇w in terms of ∇s. Finally, we can upper bound\n‖(X(i))⊤∇sφ(X(i)wi, y(i))‖2 ≤ ‖(X(i))⊤‖1→2 · ‖∇sφ(X(i)wi, y(i))‖1 ≤ RX‖∇sφ(X(i)wi, y(i))‖1\nas RX ≥ maxmj=1 ‖Xj‖2 and because of the following lemma. Lemma 4. For any 1 ≤ p ≤ ∞,\n‖X‖p→q = sup v 6=0 ‖Xv‖q ‖v‖p\n‖X⊤‖1→p = ‖X‖q→∞ = mmax j=1 ‖Xj‖p ,\nwhere q is the dual exponent of p (i.e., 1 q + 1 p = 1).\nThus, we have shown the following result.\nTheorem 5. Let φ be convex and have Lipschitz constant Gφ w.r.t. ‖ · ‖∞. Suppose we run online gradient descent (with appropriate step size η) on fi(w) = φ(X(i)w, y(i)) and return ŵOGD = 1T ∑n i=1 wi. Then we have, ∀‖w‖2 ≤ W2, E [Lφ(ŵOGD)]−Lφ(w) ≤ Gφ W2 RX √ 2\nn .\nThe above excess risk bound has no explicit m dependence. This is encouraging but there are two deficiencies of this approach based on online regret bounds. First, the result applies to the output of a specific algorithm that may not be the method of choice for practitioners. For example, the above argument does not yield uniform convergence bounds that could lead to excess risk bounds for ERM (or regularized versions of it). Second, there is no way to generalize the result to Lipschitz, but non-convex loss functions. It may noted here that the original motivation for Chapelle & Wu (2010) to prove their generalization bound was to consider the non-convex loss used in their SmoothRank method. We will address these issues in the next two sections."
    }, {
      "heading" : "6. Stochastic Convex Optimization",
      "text" : "We first define the regularized empirical risk minimizer:\nŵλ = argmin ‖w‖2≤W2\nλ 2 ‖w‖22 + L̂φ(w). (3)\nWe now state the main result of this section.\nTheorem 6. Let the loss function φ be convex and have Lipschitz constantGφ w.r.t. ‖·‖∞. Then, for an appropriate choice of λ = O(1/ √ n), we have\nE [Lφ(ŵλ)] ≤ Lφ(w⋆) + 2Gφ RX W2 ( 8\nn +\n√ 2\nn\n) .\nThis result applies to a batch algorithm (regularized ERM) but unfortunately requires the regularization parameter λ to be set in a particular way. Also, it does not apply to non-convex losses and does not yield uniform convergence bounds. In the next section, we will address these deficiencies. However, we will incur some extra logarithmic factors that are absent in the clean bound above."
    }, {
      "heading" : "7. Bounds for Non-convex Losses",
      "text" : "The above discussion suggests that we have a possibility of deriving tighter, possibly m-independent, generalization error bounds by assuming that φ is Lipschitz continuous w.r.t. ‖ · ‖∞. The standard approach in binary classification is to appeal to the Ledoux-Talagrand contraction principle for establishing Rademacher complexity (Bartlett & Mendelson, 2003). It gets rid of the loss function and incurs a factor equal to the Lipschitz constant of the loss in the Rademacher complexity bound. Since the loss function takes scalar argument, the Lipschitz constant is defined for only one norm, i.e., the absolute value norm. It is not immediately clear how such an approach would work when the loss takes vector valued arguments and is Lipschitz w.r.t. ‖ · ‖∞. We are not aware of an appropriate extension of the Ledoux-Talagrand contraction principle. Note that Lipschitz continuity w.r.t. the Euclidean norm ‖ · ‖2 does not pose a significant challenge since Slepian’s lemma can be applied to get rid of the loss. Several authors have already exploited Slepian’s lemma in this context (Bartlett & Mendelson, 2003; Chapelle & Wu, 2010). We take a route involving covering numbers and define the data-dependent (pseudo-)metric:\ndZ (1:n) ∞ (w,w ′) := n max i=1\n∣∣∣φ(X(i)w, y(i))− φ(X(i)w′, y(i)) ∣∣∣\nLet N∞(ǫ, φ ◦ F , Z(1:n)) be the covering number at scale ǫ of the composite class φ ◦F = φ ◦F1 or φ ◦F2 w.r.t. the above metric. Also define\nN∞(ǫ, φ ◦ F , n) := max Z(1:n) N∞(ǫ, φ ◦ F , Z(1:n)).\nWith these definitions in place, we can state our first result on covering numbers. Proposition 7. Let the loss φ be Lipschitz w.r.t. ‖ · ‖∞ with constant Gφ. Then following covering number bound holds: log2 N∞(ǫ, φ ◦ F2, n) ≤ ⌈ G2φ W 2 2 R 2 X\nǫ2\n⌉ log2(2mn+ 1).\nProof. Note that\nn max i=1\n∣∣∣φ(X(i)w, y(i))− φ(X(i)w′, y(i)) ∣∣∣\n≤ Gφ · nmax i=1 m max j=1\n∣∣∣ 〈 X (i) j , w 〉 − 〈 X (i) j , w ′ 〉∣∣∣ .\nThis immediately implies that if we have a cover of the class G2 (Sec.2) at scale ǫ/Gφ w.r.t. the metric\nn max i=1 m max j=1\n∣∣∣ 〈 X (i) j , w 〉 − 〈 X (i) j , w ′ 〉∣∣∣\nthen it is also a cover of φ◦F2 w.r.t. dZ (1:n)\n∞ , at scale ǫ. Now comes a simple, but crucial observation: from the point of view of the scalar valued function class G2, the vectors (X\n(i) j ) i=1:n j=1:m constitute a data set of size mn. Therefore,\nN∞(ǫ, φ ◦ F2, n) ≤ N∞(ǫ/Gφ,G2,mn). (4)\nNow we appeal to the following bound due to Zhang (2002, Corollary 3) (and plug the result into (4)):\nlog2 N∞(ǫ/Gφ,G2,mn) ≤ ⌈ G2φ W 2 2 R 2 X\nǫ2\n⌉ log2(2mn+1)\nCovering number N2(ǫ, φ◦F , Z(1:n)) uses pseudo-metric:\nd Z(1:n) 2 (w,w ′) :=\n( n∑\ni=1\n1\nn\n( φ(X(i)w, y(i))− φ(X(i)w′, y(i))\n)2 )1/2\nIt is well known that a control on N2(ǫ, φ ◦ F , Z(1:n)) provides control on the empirical Rademacher complexity and that N2 covering numbers are smaller than N∞ ones. For us, it will be convenient to use a more refined version2 due to Mendelson (2002). Let H be a class of functions, with H : Z 7→ R, uniformly bounded by B. Then, we have following bound on empirical Rademacher complexity\nR̂n (H)\n≤ inf α>0\n 4α+ 10 ∫ suph∈H √ Ê[h2]\nα\n√ log2 N2(ǫ,H, Z(1:n))\nn dǫ\n\n\n(5)\n≤ inf α>0\n(\n4α+ 10\n∫ B\nα\n√ log2 N2(ǫ,H, Z(1:n))\nn dǫ\n)\n. (6)\nHere R̂n (H) is the empirical Rademacher complexity of the class H defined as\nR̂n (H) := Eσ1:n [ sup h∈H 1 n n∑\ni=1\nσih(Zi)\n] ,\nwhere σ1:n = (σ1, . . . , σn) are iid Rademacher (symmetric Bernoulli) random variables.\n2We use a further refinement due to Srebro and Sridharan available at http://ttic.uchicago.edu/˜karthik/dudley.pdf\nCorollary 8. Let φ be Lipschitz w.r.t. ‖ · ‖∞ and uniformly bounded3 by B for w ∈ F2. Then the empirical Rademacher complexities of the class φ ◦F2 is bounded as\nR̂n (φ ◦ F2) ≤ 10GφW2RX √ log2(3mn)\nn\n× log 6B √ n\n5GφW2RX √ log2(3mn) .\nProof. This follows by simply plugging in estimates from Proposition 7 into (6) and choosing α optimally.\nControl on the Rademacher complexity immediately leads to uniform convergence bounds and generalization error bounds for ERM. The informal Õ notation hides factors logarithmic in m,n,B,Gφ, RX ,W1. Note that all hidden factors are small and computable from the results above.\nTheorem 9. Suppose φ is Lipschitz w.r.t. ‖ · ‖∞ with constant Gφ and is uniformly bounded by B as w varies over F2. With probability at least 1− δ,\n∀w ∈ F2, Lφ(w) ≤ L̂φ(w)\n+ Õ ( GφW2RX √ 1\nn +B\n√ log(1/δ)\nn\n)\nand therefore with probability at least 1− 2δ, Lφ(ŵ) ≤ Lφ(w⋆)+Õ ( GφW2RX √ 1\nn +B\n√ log(1/δ)\nn\n) .\nwhere ŵ is an empirical risk minimizer over F2.\nProof. Follows from standard bounds using Rademacher complexity. See, for example, Bartlett & Mendelson (2003).\nAs we said before, ignoring logarithmic factors, the bound forF2 is an improvement over the bound of Chapelle & Wu (2010)."
    }, {
      "heading" : "8. Extensions",
      "text" : "We extend the generalization bounds above to two settings: a) high dimensional features and b) smooth losses."
    }, {
      "heading" : "8.1. High-dimensional features",
      "text" : "In learning to rank situations involving high dimensional features, it may not be appropriate to use the class F2 of ℓ2 bounded predictors. Instead, we would like to consider the class F1 of ℓ1 bounded predictors. In this case, it is\n3A uniform bound on the loss easily follows under the (very reasonable) assumption that ∀y,∃sy s.t. φ(sy, y) = 0. Then φ(Xw, y) ≤ Gφ‖Xw − sy‖∞ ≤ Gφ(W2RX + maxy∈Y ‖sy‖∞) ≤ Gφ(2W2RX).\nnatural to measure size of the input matrix X in terms of a bound R̄X on the maximum ℓ∞ norm of each of its row. The following analogue of Proposition 7 can be shown.\nProposition 10. Let the loss φ be Lipschitz w.r.t. ‖·‖∞ with constant Gφ. Then the following covering number bound holds: log2 N∞(ǫ, φ ◦ F1, n) ≤ ⌈ 288G2φW 2 1 R̄ 2 X (2 + log d)\nǫ2\n⌉\n× log2 ( 2 ⌈ 8GφW1R̄X\nǫ\n⌉ mn+ 1 ) .\nUsing the above result to control the Rademacher complexity of φ ◦ F1 gives the following bound. Corollary 11. Let φ be Lipschitz w.r.t. ‖·‖∞ and uniformly bounded byB for w ∈ F1. Then the empirical Rademacher complexities of the class φ ◦ F1 is bounded as\nR̂n (φ ◦ F1) ≤ 120 √ 2GφW1R̄X\n√ log(d) log2(24mnGφW1R̄X)\nn\n× log2 B+24mnGφW1R̄X 40 √ 2GφW1R̄X √ log(d) log2(24mnGφW1R̄X ) .\nAs in the previous section, control of Rademacher complexity immediately yields uniform convergence and ERM generalization error bounds.\nTheorem 12. Suppose φ is Lipschitz w.r.t. ‖ · ‖∞ with constant Gφ and is uniformly bounded by B as w varies over F1. With probability at least 1− δ,\n∀w ∈ F1, Lφ(w) ≤ L̂φ(w)\n+ Õ ( GφW1R̄X √ log d\nn +B\n√ log(1/δ)\nn\n)\nand therefore with probability at least 1− 2δ,\nLφ(ŵ) ≤ Lφ(w⋆)+Õ ( GφW1R̄X √ log d\nn +B\n√ log(1/δ)\nn\n)\nwhere ŵ is an empirical risk minimizer over F1.\nAs can be easily seen from Theorem. 12, the generalization bound is almost independent of the dimension of the document feature vectors. We are not aware of existence of such a result in learning to rank literature."
    }, {
      "heading" : "8.2. Smooth losses",
      "text" : "We will again use online regret bounds to explain why we should expect “optimistic” rates for smooth losses before giving more general results for smooth but possibly nonconvex losses."
    }, {
      "heading" : "8.3. Online regret bounds under smoothness",
      "text" : "Let us go back to OGD guarantee, this time presented in a slightly more refined version. If we run OGD with learning rate η then, for all ‖w‖2 ≤ W2:\nn∑\ni=1\nfi(wi)− n∑\ni=1\nfi(w) ≤ W 22 2η + η\nn∑\ni=1\n‖gi‖22\nwhere gi = ∇wifi(wi) (if fi is not differentiable at wi then we can set gi to be an arbitrary subgradient of fi at wi). Now assume that all fi’s are non-negative functions and are smooth w.r.t. ‖ · ‖2 with constant H . Lemma 3.1 of Srebro et al. (2010) tells us that any non-negative, smooth function f(w) enjoy an important self-bounding property for the gradient:\n‖∇wfi(w)‖2 ≤ √ 4Hfi(w)\nwhich bounds the magnitude of the gradient of f at a point in terms of the value of the function itself at that point. This means that ‖gi‖22 ≤ 4Hfi(wi) which, when plugged into the OGD guarantee, gives:\nn∑\ni=1\nfi(wi)− n∑\ni=1\nfi(w) ≤ W 22 2η + 4ηH n∑\ni=1\nfi(wi)\nAgain, setting fi(w) = φ(X(i)w, y(i)), 1 ≤ t ≤ n, and using the online to batch conversion technique, we can arrive at the bound: for all ‖w‖2 ≤ W2:\nE [Lφ(ŵ)] ≤ Lφ(w) (1− 4ηH) + W 22 2η(1− 4ηH)n\nAt this stage, we can fix w = w⋆, the optimal ℓ2-norm bounded predictor and get optimal η as:\nη = W2\n4HW2 + 2 √ 4H2W 22 + 2HLφ(w ⋆)n . (7)\nAfter plugging this value of η in the bound above and some algebra (see Section H), we get the upper bound\nE [Lφ(ŵ)] ≤ Lφ(w⋆) + 2 √ 2HW 22Lφ(w ⋆)\nn + 8HW 22 n .\n(8) Such a rate interpolates between a 1/ √ n rate in the “pessimistic” case (Lφ(w⋆) > 0) and the 1/n rate in the “optimistic” case (Lφ(w⋆) = 0) (this terminology is due to Panchenko (2002)).\nNow, assuming φ to be twice differentiable, we need H such that\nH ≥ ‖∇2wφ(X(i)w, y(i))‖2→2 = ‖X⊤∇2sφ(X(i)w, y(i))X‖2→2\nwhere we used the chain rule to express ∇2w in terms of ∇2s. Note that, for OGD, we need smoothness in w w.r.t.\n‖ · ‖2 which is why the matrix norm above is the operator norm corresponding to the pair ‖·‖2, ‖·‖2. In fact, when we say “operator norm” without mentioning the pair of norms involved, it is this norm that is usually meant. It is well known that this norm is equal to the largest singular value of the matrix. But, just as before, we can bound this in terms of the smoothness constant of φ w.r.t. ‖ · ‖∞ (see Section I in the appendix):\n‖(X(i))⊤∇2sφ(X(i)w, y(i))X(i)‖2→2 ≤ R2X‖∇2sφ(X(i)w, y(i))‖∞→1.\nwhere we used Lemma 4 once again. This result using online regret bounds is great for building intuition but suffers from the two defects we mentioned at the end of Section 5. In the smoothness case, it additionally suffers from a more serious defect: the correct choice of the learning rate η requires knowledge of Lφ(w⋆) which is seldom available."
    }, {
      "heading" : "8.4. Generalization error bounds under smoothness",
      "text" : "Once again, to prove a general result for possibly nonconvex smooth losses, we will adopt an approach based on covering numbers. To begin, we will need a useful lemma from Srebro et al. (2010, Lemma A.1 in the Supplementary Material). Note that, for functions over real valued predictions, we do not need to talk about the norm when dealing with smoothness since essentially the only norm available is the absolute value.\nLemma 13. For any h-smooth non-negative function f : R → R+ and any t, r ∈ R we have\n(f(t)− f(r))2 ≤ 6h(f(t) + f(r))(t − r)2.\nWe first provide an extension of this lemma to the vector case.\nLemma 14. If φ : Rm → R+ is a non-negative function with smoothness constant Hφ w.r.t. a norm ||| · ||| then for any s1, s2 ∈ Rm we have\n(φ(s1)− φ(s2))2 ≤ 6Hφ · (φ(s1) + φ(s2)) · |||s1 − s2|||2.\nUsing the basic idea behind local Rademacher complexity analysis, we define the following loss class:\nFφ,2(r) := {(X, y) 7→ φ(Xw, y) : ‖w‖2 ≤ W2, L̂φ(w) ≤ r}.\nNote that this is a random subclass of functions since L̂φ(w) is a random variable. Proposition 15. Let φ be smooth w.r.t. ‖·‖∞ with constant Hφ. The covering numbers of Fφ,2(r) in the dZ (1:n)\n2 metric defined above are bounded as follows: log2 N2(ǫ,Fφ,2(r), Z(1:n)) ≤ ⌈ 12Hφ W 2 2 R 2 X r\nǫ2\n⌉ log2(2mn+1).\nControl of covering numbers easily gives a control on the Rademacher complexity of the random subclass Fφ,2(r). Corollary 16. Let φ be smooth w.r.t. ‖ · ‖∞ with constant Hφ and uniformly bounded by B for w ∈ F2. Then the empirical Rademacher complexity of the class Fφ,2(r) is bounded as\nR̂n (Fφ,2(r)) ≤ 4 √ rC log\n3 √ B\nC\nwhere C = 5 √ 3W2RX\n√ Hφ log2(3mn)\nn .\nWith the above corollary in place we can now prove our second key result.\nTheorem 17. Suppose φ is smooth w.r.t. ‖ · ‖∞ with constant Hφ and is uniformly bounded by B over F2. With probability at least 1− δ,\n∀w ∈ F2, Lφ(w) ≤ L̂φ(w) + Õ (√\nLφ(w)D0 n + D0 n\n)\nwhere D0 = B log(1/δ) + W 22R 2 XHφ. Moreover, with probability at least 1− 2δ,\nLφ(ŵ) ≤ Lφ(w⋆) + Õ (√\nLφ(w⋆)D0 n + D0 n\n)\nwhere ŵ, w⋆ are minimizers of L̂φ(w) and Lφ(w) respectively (over w ∈ F2)."
    }, {
      "heading" : "9. Conclusion",
      "text" : "We showed that it is not necessary for generalization error bounds for query-level learning to rank algorithms to deteriorate with increasing length of document lists associated with queries. The key idea behind our improved bounds was defining Lipschitz constants w.r.t. ℓ∞ norm instead of the “standard” ℓ2 norm. As a result, we were able to derive much tighter guarantees for popular loss functions such as ListNet and Smoothed DCG@1 than previously available.\nOur generalization analysis of learning to rank algorithms paves the way for further interesting work. One possibility is to use these bounds to design active learning algorithms for learning to rank with formal label complexity guarantees. Another interesting possibility is to consider other problems, such as multi-label learning, where functions with vector-valued outputs are learned by optimizing a joint function of those outputs."
    }, {
      "heading" : "Acknowledgement",
      "text" : "We gratefully acknowledge the support of NSF under grant IIS-1319810. Thanks to Prateek Jain for discussions that led us to Theorem 3."
    }, {
      "heading" : "A. Proof of Proposition 1",
      "text" : "Proof. Let ej’s denote standard basis vectors. We have\n∇sφLN(s, y) = − m∑\nj=1\nPj(y)ej + m∑\nj=1\nexp(sj)∑m j′=1 exp(sj′ ) ej\nTherefore,\n‖∇sφLN(s, y)‖1 ≤ m∑\nj=1\nPj(y)‖ej‖1 + m∑\nj=1\nexp(sj)∑m j′=1 exp(sj′ ) ‖ej‖1\n= 2.\nWe also have\n[∇2sφLN(s, y)]j,k =    − exp(2sj)(∑m j′=1 exp(sj′ )) 2 + exp(sj)∑ m j′=1 exp(sj′ ) if j = k\n− exp(sj+sk)(∑m j′=1 exp(sj′ )) 2 if j 6= k .\nMoreover,\n‖∇2sφLN(s, y)‖∞→1 ≤ m∑\nj=1\nm∑\nk=1\n|[∇2sφLN(s, y)]j,k|\n≤ m∑\nj=1\nm∑\nk=1\nexp(sj + sk)\n( ∑m j′=1 exp(sj′)) 2 +\nm∑\nj=1\nexp(sj)∑m j′=1 exp(sj′ )\n= ( ∑m j=1 exp(sj)) 2\n( ∑m\nj′=1 exp(sj′ )) 2 + ∑m j=1 exp(sj)∑m j′=1 exp(sj′ )\n= 2"
    }, {
      "heading" : "B. Proof of Proposition 2",
      "text" : "Proof. Let 1(condition) denote an indicator variable. We have\n[∇sφSD(s, y)]j = D(1) ( m∑\ni=1\nG(ri)\n[ 1\nσ exp(si/σ)∑ j′ exp(sj′/σ) 1(i=j) − 1 σ exp((si + sj)/σ) ( ∑ j′ exp(sj′/σ)) 2\n])\nTherefore,\n‖∇sφSD(s, y)‖1 D(1)G(Ymax) ≤ m∑\nj=1\n( m∑\ni=1\n[ 1\nσ exp(si/σ)∑ j′ exp(sj′/σ) 1(i=j) + 1 σ exp((si + sj)/σ) ( ∑ j′ exp(sj′/σ)) 2\n])\n= 1\nσ ( ∑ j exp(sj/σ)∑ j′ exp(sj′/σ) + ( ∑ j exp(sj/σ)) 2 ( ∑ j′ exp(sj′/σ)) 2 )\n= 2\nσ ."
    }, {
      "heading" : "C. RankSVM",
      "text" : "The RankSVM surrogate is defined as:\nφRS(s, y) =\nm∑\ni=1\nm∑\nj=1\nmax(0, 1(yi>yj)(1 + sj − si))\nIt is easy to see that ∇sφRS(s, y) = ∑m\ni=1 ∑m j=1 max(0, 1(yi>yj)(1 + sj − si))(ej − ei). Thus, the ℓ1 norm of gradient\nis O(m2) ."
    }, {
      "heading" : "D. Proof of Theorem 3",
      "text" : "Proof. It is straightforward to check that F ′lin is contained in both Ffull as well as Fperminv. So, we just need to prove that any f that is in both Ffull and Fperminv has to be in F ′lin as well. Let Pπ denote the m × m permutation matrix corresponding to a permutation π. Consider the full linear class Ffull. In matrix notation, the permutation invariance property means that, for any π,X , we have Pπ[〈X,W1〉 , . . . , 〈X,Wm〉〉]⊤ = [〈PπX,W1〉 , . . . , 〈PπX,Wm〉]⊤. Let ρ1 = {Pπ : π(1) = 1}, where π(i) denotes the index of the element in the ith position according to permutation π. Fix any P ∈ ρ1. Then, for any X , 〈X,W1〉 = 〈PX,W1〉. This implies that, for all X , Tr(W1⊤X) = Tr(W1⊤PX). Using the fact that Tr(A⊤X) = Tr(B⊤X), ∀X implies A = B, we have that W1⊤ = W1⊤P . Because P⊤ = P−1, this means PW1 = W1. This shows that all rows of W1, other than 1st row, are the same but perhaps different from 1st row. By considering ρi = {Pπ : π(i) = i} for i > 1, the same reasoning shows that, for each i, all rows of Wi, other than ith row, are the same but possibly different from ith row.\nLet ρ1↔2 = {Pπ : π(1) = 2, π(2) = 1}. Fix any P ∈ ρ1↔2. Then, for any X , 〈X,W2〉 = 〈PX,W1〉 and 〈X,W1〉 = 〈PX,W2〉. Thus, we have W⊤2 = W⊤1 P as well as W⊤1 = W⊤2 P which means PW2 = W1, PW1 = W2. This shows that row 1 of W1 and row 2 of W2 are the same. Moreover, row 2 of W1 and row 1 of W2 are the same. Thus, for some u, u′ ∈ Rd, W1 is of the form [u|u′|u′| . . . |u′]⊤ and W2 is of the form [u′|u|u′| . . . |u′]⊤. Repeating this argument by considering ρ1↔i for i > 2 shows that Wi is of the same form (u in row i and u′ elsewhere).\nTherefore, we have proved that any linear map that is permutation invariant has to be of the form:\nX 7→  u⊤Xi + (u′)⊤ ∑\nj 6=i Xj\n  m\ni=1\n.\nWe can reparameterize above using w = u− u′ and v = u′ which proves the result."
    }, {
      "heading" : "E. Proof of Lemma 4",
      "text" : "Proof. The first equality is true because\n‖X⊤‖1→p = sup v 6=0 ‖X⊤v‖p ‖v‖1 = sup v 6=0 sup u6=0\n〈 X⊤v, u 〉 ‖v‖1‖u‖q\n= sup u6=0 sup v 6=0 〈v,Xu〉 ‖v‖1‖u‖q = sup u6=0 ‖Xu‖∞ ‖u‖q = ‖X‖q→∞.\nThe second is true because\n‖X‖q→∞ = sup u6=0 ‖Xu‖∞ ‖u‖q = sup u6=0 m max j=1 | 〈Xj , u〉 | ‖u‖q\n= m\nmax j=1 sup u6=0 | 〈Xj, u〉 | ‖u‖q = m max j=1 ‖Xj‖p."
    }, {
      "heading" : "F. Proof of Theorem 6",
      "text" : "Our theorem is developed from the “expectation version” of Theorem 6 of Shalev-Shwartz et al. (2009) that was originally given in probabilistic form. The expected version is as follows.\nLet Z be a space endowed with a probability distribution generating iid draws Z1, . . . , Zn. Let W ⊆ Rd and f : W×Z →\nR be λ-strongly convex4 and G-Lipschitz (w.r.t. ‖ · ‖2) in w for every z. We define F (w) = E [f(w,Z)] and let w⋆ = argmin\nw∈W F (w),\nŵ = argmin w∈W\n1\nn\nn∑\ni=1\nf(w,Zi).\nThen E [F (ŵ)− F (w⋆)] ≤ 4G2 λn\n, where the expectation is taken over the sample. The above inequality can be proved by carefully going through the proof of Theorem 6 proved by Shalev-Shwartz et al. (2009).\nWe now derive the “expectation version” of Theorem 7 of Shalev-Shwartz et al. (2009). Define the regularized empirical risk minimizer as follows:\nŵλ = argmin w∈W\nλ 2 ‖w‖22 + 1 n\nn∑\ni=1\nf(w,Zi). (9)\nThe following result gives optimality guarantees for the regularized empirical risk minimizer. Theorem 18. Let W = {w : ‖w‖2 ≤ W2} and let f(w, z) be convex and G-Lipschitz (w.r.t. ‖ · ‖2) in w for every z. Let Z1, ..., Zn be iid samples and let λ = √ 4G2 n\nW2 2 2 + 4W2 2 n\n. Then for ŵλ and w⋆ as defined above, we have\nE [F (ŵλ)− F (w⋆)] ≤ 2GW2 ( 8\nn +\n√ 2\nn\n) . (10)\nProof. Let rλ(w, z) = λ2 ‖w‖22 + f(w, z). Then rλ is λ-strongly convex with Lipschitz constant λW2 + G in ‖ · ‖2. Applying “expectation version” of Theorem 6 of Shalev-Shwartz et al. (2009) to rλ, we get\nE\n[ λ\n2 ‖ŵλ‖22 + F (ŵλ)\n] ≤ min\nw∈W\n{ λ\n2 ‖w‖22 + F (w)\n} + 4(λW2 +G) 2\nλn ≤ λ 2 ‖w⋆‖22 + F (w∗) +\n4(λW2 +G) 2\nλn .\nThus, we get\nE [F (ŵλ)− F (w⋆)] ≤ λW 22 2 + 4(λW2 +G) 2 λn .\nMinimizing the upper bound w.r.t. λ, we get λ = √ 4G2\nn\n√ 1\nW2 2 2 + 4W2 2 n\n. Plugging this choice back in the equation above and\nusing the fact that √ a+ b ≤ √a+ √ b finishes the proof of Theorem 18.\nWe now have all ingredients to prove Theorem 6.\nProof of Theorem 6. Let Z = X × Y and f(w, z) = φ(Xw, y) and apply Theorem 18. Finally note that if φ is GφLipschitz w.r.t. ‖ · ‖∞ and every row of X ∈ Rm×d has Euclidean norm bounded by RX then f(·, z) is GφRX -Lipschitz w.r.t. ‖ · ‖2 in w."
    }, {
      "heading" : "G. Proof of Theorem 12",
      "text" : "Proof. Following exactly the same line of reasoning (reducing a sample of size n, where each prediction is Rm-valued, to an sample of size mn, where each prediction is real valued) as in the beginning of proof of Proposition 7, we have\nN∞(ǫ, φ ◦ F1, n) ≤ N∞(ǫ/Gφ,G1,mn). (11) Plugging in the following bound due to Zhang (2002, Corollary 5):\nlog2 N∞(ǫ/Gφ,G1,mn) ≤ ⌈ 288G2φW 2 1 R̄ 2 X (2 + ln d)\nǫ2\n⌉\n× log2 ( 2⌈8GφW1R̄X/ǫ⌉mn+ 1 )\ninto (11) respectively proves the result.\n4Recall that a function is called λ-strongly convex (w.r.t. ‖ · ‖2) iff f − λ2 ‖ · ‖22 is convex.\nH. Calculations involved in deriving Equation (8)\nPlugging in the value of η from (7) into the expression\nLφ(w ⋆) (1− 4ηH) + W 22 2η(1− 4ηH)n\nyields (using the shorthand L⋆ for Lφ(w⋆))\nL⋆ + 2HW2L\n⋆\n√ 4H2W 22 + 2HL ⋆n +\nW2 n\n[ 4H2W 22√\n4H2W 22 + 2HL ⋆n\n+ √ 4H2W 22 + 2HL ⋆n+ 4HW2\n]\nDenoting HW 22 /n by x, this simplifies to\nL⋆ + 2 √ xL⋆ + 4x √ x√\n4x+ 2L⋆ + √ x √ 4x+ 2L⋆ + 4x.\nUsing the arithmetic mean-geometric mean inequality to upper bound the middle two terms gives\nL⋆ + 2 √ 2xL⋆ + 4x2 + 4x.\nFinally, using √ a+ b ≤ √a+ √ b, we get our final upper bound\nL⋆ + 2 √ 2xL⋆ + 8x."
    }, {
      "heading" : "I. Calculation of smoothness constant",
      "text" : "‖(X(i))⊤∇2sφ(X(i)w, y(i))X(i)‖2→2 = sup v 6=0 ‖(X(i))⊤∇2sφ(X(i)w, y(i))X(i)v‖2 ‖v‖2\n≤ sup v 6=0 ‖(X(i))⊤‖1→2‖∇2sφ(X(i)w, y(i))X(i)v‖1 ‖v‖2 ≤ sup v 6=0 ‖(X(i))⊤‖1→2 · ‖∇2sφ(X(i)w, y(i))‖∞→1 · ‖X(i)v‖∞ ‖v‖2\n≤ sup v 6=0 ‖(X(i))⊤‖1→2 · ‖∇2sφ(X(i)w, y(i))‖∞→1 · ‖X(i)‖2→∞ · ‖v‖2 ‖v‖2 ≤ (\nm max j=1\n‖X(i)j ‖ )2 · ‖∇2sφ(X(i)w, y(i))‖∞→1\n≤ R2X‖∇2sφ(X(i)w, y(i))‖∞→1."
    }, {
      "heading" : "J. Proof of Lemma 14",
      "text" : "Proof. Consider the function f(t) = φ((1 − t)s1 + ts2).\nIt is clearly non-negative. Moreover\n|f ′(t1)− f ′(t2)| = | 〈∇sφ(s1 + t1(s2 − s1))−∇sφ(s1 + t2(s2 − s1)), s2 − s1〉 | ≤ |||∇sφ(s1 + t1(s2 − s1))−∇sφ(s1 + t2(s2 − s1))|||⋆ · |||s2 − s1||| ≤ Hφ |t1 − t2| |||s2 − s1|||2\nand therefore it is smooth with constant h = Hφ|||s2 − s1|||2. Appealing to Lemma 13 now gives\n(f(1)− f(0))2 ≤ 6Hφ|||s2 − s1|||2(f(1) + f(0))(1− 0)2\nwhich proves the lemma since f(0) = φ(s1) and f(1) = φ(s2)."
    }, {
      "heading" : "K. Proof of Proposition 15",
      "text" : "Proof. Let w,w′ ∈ Fφ,2(r). Using Lemma 14 n∑\ni=1\n1\nn\n( φ(X(i)w, y(i))− φ(X(i)w′, y(i)) )2\n≤ 6Hφ n∑\ni=1\n1\nn\n( φ(X(i)w, y(i)) + φ(X(i)w′, y(i)) )\n· ‖X(i)w −X(i)w′‖2∞ ≤ 6Hφ · nmax\ni=1 ‖X(i)w −X(i)w′‖2∞\n· n∑\ni=1\n1\nn\n( φ(X(i)w, y(i)) + φ(X(i)w′, y(i)) )\n= 6Hφ · nmax i=1\n‖X(i)w −X(i)w′‖2∞ · ( L̂φ(w) + L̂φ(w ′) )\n≤ 12Hφr · n\nmax i=1\n‖X(i)w −X(i)w′‖2∞.\nwhere the last inequality follows because L̂φ(w) + L̂φ(w′) ≤ 2r. This immediately implies that if we have a cover of the class G2 at scale ǫ/ √ 12Hφr w.r.t. the metric\nn max i=1 m max j=1\n∣∣∣ 〈 X (i) j , w 〉 − 〈 X (i) j , w ′ 〉∣∣∣\nthen it is also a cover of Fφ,2(r) w.r.t. dZ (1:n) 2 . Therefore, we have\nN2(ǫ,Fφ,2(r), Z(1:n)) ≤ N∞(ǫ/ √ 12Hφr,G2,mn). (12)\nAppealing once again to a result by Zhang (2002, Corollary 3), we get\nlog2 N∞(ǫ/ √ 12Hφr,G2,mn) ≤\n⌈ 12HφW 2 2 R 2 X r\nǫ2\n⌉\n× log2(2mn+ 1)\nwhich finishes the proof."
    }, {
      "heading" : "L. Proof of Corollary 16",
      "text" : "Proof. We plug in Proposition 15’s estimate into (5):\nR̂n (Fφ,2(r)) ≤ inf α>0  4α+ 10 ∫ √Br\nα\n√√√√ ⌈ 12Hφ W 22 R 2 X r\nǫ2\n⌉ log2(2mn+ 1) n dǫ  \n≤ inf α>0\n( 4α+ 20 √ 3W2RX √ rHφ log2(3mn)\nn\n∫ √Br\nα\n1 ǫ dǫ\n) .\nNow choosing α = C √ r where C = 5 √ 3W2RX\n√ Hφ log2(3mn)\nn gives us the upper bound\nR̂n (Fφ,2(r)) ≤ 4 √ rC ( 1 + log √ B\nC\n) ≤ 4√rC log 3 √ B\nC ."
    }, {
      "heading" : "M. Proof of Theorem 17",
      "text" : "Proof. We appeal to Theorem 6.1 of Bousquet (2002) that assumes there exists an upper bound\nR̂n (F2,φ(r)) ≤ ψn(r)\nwhere ψn : [0,∞) → R+ is a non-negative, non-decreasing, non-zero function such that ψn(r)/ √ r is non-increasing. The upper bound in Corollary 16 above satisfies these conditions and therefore we set ψn(r) = 4 √ rC log 3 √ B\nC with C as\ndefined in Corollary 16. From Bousquet’s result, we know that, with probability at least 1− δ,\n∀w ∈ F2, Lφ(w) ≤ L̂φ(w) + 45r⋆n + √ 8r⋆nLφ(w)\n+ √ 4r0Lφ(w) + 20r0\nwhere r0 = B(log(1/δ) + log logn)/n and r⋆n is the largest solution to the equation r = ψn(r). In our case, r ⋆ n =(\n4C log 3 √ B\nC\n)2 . This proves the first inequality.\nNow, using the above inequality with w = ŵ, the empirical risk minimizer and noting that L̂φ(ŵ) ≤ L̂φ(w⋆), we get\nLφ(ŵ) ≤ L̂φ(w⋆) + 45r⋆n + √ 8r⋆nLφ(ŵ)\n+ √ 4r0Lφ(ŵ) + 20r0\nThe second inequality now follows after some elementary calculations detailed below.\nM.1. Details of some calculations in the proof of Theorem 17\nUsing Bernstein’s inequality, we have, with probability at least 1− δ,\nL̂φ(w ⋆) ≤ Lφ(w⋆) +\n√ 4Var[φ(Xw⋆, y)] log(1/δ)\nn +\n4B log(1/δ)\nn\n≤ Lφ(w⋆) + √ 4BLφ(w⋆) log(1/δ)\nn +\n4B log(1/δ)\nn\n≤ Lφ(w⋆) + √ 4r0Lφ(w⋆) + 4r0.\nSet D0 = 45r⋆n + 20r0. Putting the two bounds together and using some simple upper bounds, we have, with probability at least 1− 2δ,\nLφ(ŵ) ≤ √ D0L̂φ(w⋆) +D0,\nL̂φ(w ⋆) ≤ √ D0Lφ(w⋆) +D0.\nwhich implies that\nLφ(ŵ) ≤ √ D0 √√ D0Lφ(w⋆) +D0 +D0.\nUsing √ ab ≤ (a+ b)/2 to simplify the first term on the right gives us\nLφ(ŵ) ≤ D0 2 +\n√ D0Lφ(w⋆) +D0\n2 +D0 =\n√ D0Lφ(w⋆)\n2 + 2D0 ."
    } ],
    "references" : [ {
      "title" : "Rademacher and Gaussian complexities: Risk bounds and structural results",
      "author" : [ "Bartlett", "Peter L", "Mendelson", "Shahar" ],
      "venue" : "The Journal of Machine Learning Research,",
      "citeRegEx" : "Bartlett et al\\.,? \\Q2003\\E",
      "shortCiteRegEx" : "Bartlett et al\\.",
      "year" : 2003
    }, {
      "title" : "Concentration inequalities and empirical processes theory applied to the analysis of learning algorithms",
      "author" : [ "Bousquet", "Olivier" ],
      "venue" : "PhD thesis, Ecole Polytechnique,",
      "citeRegEx" : "Bousquet and Olivier.,? \\Q2002\\E",
      "shortCiteRegEx" : "Bousquet and Olivier.",
      "year" : 2002
    }, {
      "title" : "Learning to rank: from pairwise approach to listwise approach",
      "author" : [ "Cao", "Zhe", "Qin", "Tao", "Liu", "Tie-Yan", "Tsai", "Ming-Feng", "Li", "Hang" ],
      "venue" : "In Proceedings of the 24th International Conference on Machine Learning,",
      "citeRegEx" : "Cao et al\\.,? \\Q2007\\E",
      "shortCiteRegEx" : "Cao et al\\.",
      "year" : 2007
    }, {
      "title" : "Gradient descent optimization of smoothed information retrieval metrics",
      "author" : [ "Chapelle", "Olivier", "Wu", "Mingrui" ],
      "venue" : "Information retrieval,",
      "citeRegEx" : "Chapelle et al\\.,? \\Q2010\\E",
      "shortCiteRegEx" : "Chapelle et al\\.",
      "year" : 2010
    }, {
      "title" : "Expected reciprocal rank for graded relevance",
      "author" : [ "Chapelle", "Olivier", "Metlzer", "Donald", "Zhang", "Ya", "Grinspan", "Pierre" ],
      "venue" : "In Proceedings of the 18th ACM Conference on Information and Knowledge Management,",
      "citeRegEx" : "Chapelle et al\\.,? \\Q2009\\E",
      "shortCiteRegEx" : "Chapelle et al\\.",
      "year" : 2009
    }, {
      "title" : "Future directions in learning to rank",
      "author" : [ "Chapelle", "Olivier", "Chang", "Yi", "Liu", "Tie-Yan" ],
      "venue" : "In Proceedings of the Yahoo! Learning to Rank Challenge June",
      "citeRegEx" : "Chapelle et al\\.,? \\Q2010\\E",
      "shortCiteRegEx" : "Chapelle et al\\.",
      "year" : 2010
    }, {
      "title" : "Cumulated gainbased evaluation of IR techniques",
      "author" : [ "Järvelin", "Kalervo", "Kekäläinen", "Jaana" ],
      "venue" : "ACM Transactions on Information Systems,",
      "citeRegEx" : "Järvelin et al\\.,? \\Q2002\\E",
      "shortCiteRegEx" : "Järvelin et al\\.",
      "year" : 2002
    }, {
      "title" : "Optimizing search engines using clickthrough data",
      "author" : [ "Joachims", "Thorsten" ],
      "venue" : "In Proceedings of the 8th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining,",
      "citeRegEx" : "Joachims and Thorsten.,? \\Q2002\\E",
      "shortCiteRegEx" : "Joachims and Thorsten.",
      "year" : 2002
    }, {
      "title" : "Query-level stability and generalization in learning to rank",
      "author" : [ "Lan", "Yanyan", "Liu", "Tie-Yan", "Qin", "Tao", "Ma", "Zhiming", "Li", "Hang" ],
      "venue" : "In Proceedings of the 25th International Conference on Machine Learning,",
      "citeRegEx" : "Lan et al\\.,? \\Q2008\\E",
      "shortCiteRegEx" : "Lan et al\\.",
      "year" : 2008
    }, {
      "title" : "Generalization analysis of listwise learning-to-rank algorithms",
      "author" : [ "Lan", "Yanyan", "Liu", "Tie-Yan", "Ma", "Zhiming", "Li", "Hang" ],
      "venue" : "In Proceedings of the 26th Annual International Conference on Machine Learning,",
      "citeRegEx" : "Lan et al\\.,? \\Q2009\\E",
      "shortCiteRegEx" : "Lan et al\\.",
      "year" : 2009
    }, {
      "title" : "LETOR: Benchmark dataset for research on learning to rank for information retrieval",
      "author" : [ "Liu", "Tie-yan", "Xu", "Jun", "Qin", "Tao", "Xiong", "Wenying", "Li", "Hang" ],
      "venue" : "In Proceedings of SIGIR 2007 Workshop on Learning to Rank for Information Retrieval,",
      "citeRegEx" : "Liu et al\\.,? \\Q2007\\E",
      "shortCiteRegEx" : "Liu et al\\.",
      "year" : 2007
    }, {
      "title" : "Rademacher averages and phase transitions in Glivenko-Cantelli classes",
      "author" : [ "Mendelson", "Shahar" ],
      "venue" : "IEEE Transactions on Information Theory,",
      "citeRegEx" : "Mendelson and Shahar.,? \\Q2002\\E",
      "shortCiteRegEx" : "Mendelson and Shahar.",
      "year" : 2002
    }, {
      "title" : "Some extensions of an inequality of Vapnik and Chervonenkis",
      "author" : [ "Panchenko", "Dmitriy" ],
      "venue" : "Electronic Communications in Probability,",
      "citeRegEx" : "Panchenko and Dmitriy.,? \\Q2002\\E",
      "shortCiteRegEx" : "Panchenko and Dmitriy.",
      "year" : 2002
    }, {
      "title" : "Stochastic convex optimization",
      "author" : [ "Shalev-Shwartz", "Shai", "Shamir", "Ohad", "Srebro", "Nathan", "Sridharan", "Karthik" ],
      "venue" : "In Proceedings of the 22nd Annual Conference on Learning Theory,",
      "citeRegEx" : "Shalev.Shwartz et al\\.,? \\Q2009\\E",
      "shortCiteRegEx" : "Shalev.Shwartz et al\\.",
      "year" : 2009
    }, {
      "title" : "Smoothness, low noise, and fast rates",
      "author" : [ "Srebro", "Nathan", "Sridharan", "Karthik", "Tewari", "Ambuj" ],
      "venue" : "In Advances in Neural Information Processing Systems",
      "citeRegEx" : "Srebro et al\\.,? \\Q2010\\E",
      "shortCiteRegEx" : "Srebro et al\\.",
      "year" : 2010
    }, {
      "title" : "Covering number bounds of certain regularized linear function classes",
      "author" : [ "Zhang", "Tong" ],
      "venue" : "The Journal of Machine Learning Research,",
      "citeRegEx" : "Zhang and Tong.,? \\Q2002\\E",
      "shortCiteRegEx" : "Zhang and Tong.",
      "year" : 2002
    }, {
      "title" : "Proof of Theorem 6 Our theorem is developed from the “expectation version” of Theorem 6 of Shalev-Shwartz et al. (2009) that was originally given in probabilistic form. The expected version is as follows. Let Z be a space endowed with a probability distribution generating iid draws Z1",
      "author" : [ "F. ‖Xj‖p" ],
      "venue" : null,
      "citeRegEx" : ".Xj.p.,? \\Q2009\\E",
      "shortCiteRegEx" : ".Xj.p.",
      "year" : 2009
    } ],
    "referenceMentions" : [ {
      "referenceID" : 4,
      "context" : "The performance of ranking functions on test sets is evaluated using a variety of performance measures such as NDCG (Järvelin & Kekäläinen, 2002), ERR (Chapelle et al., 2009) or Average Precision (Yue et al.",
      "startOffset" : 151,
      "endOffset" : 174
    }, {
      "referenceID" : 3,
      "context" : "However, as soon as one optimizes a surrogate loss, one has to deal with two questions (Chapelle et al., 2011). First, does minimizing the surrogate on finite training data imply small expected surrogate loss on infinite unseen data? Second, does small expected surrogate loss on infinite unseen data imply small target loss on infinite unseen data? The first issue is one of generalization error bounds for empirical risk minimization (ERM) algorithms that minimize surrogate loss on training data. The second issue is one of calibration: does consistency in the surrogate loss imply consistency in the target loss? This paper deals with the former issue, viz. that of generalization error bounds for surrogate loss minimization. In pioneering works, Lan et al. (2008; 2009) gave generalization error bounds for learning to rank algorithms. However, while the former paper was restricted to analysis of pairwise approach to learning to rank, the later paper was limited to results on just three surrogates: ListMLE, ListNet and RankCosine. To the best of our knowledge, the most generally applicable bound on the generalization error of query-level learning to rank algorithms has been obtained by Chapelle & Wu (2010). The bound of Chapelle & Wu (2010), while generally applicable, does have an explicit dependence on the length of the document list associated with a query.",
      "startOffset" : 88,
      "endOffset" : 1220
    }, {
      "referenceID" : 3,
      "context" : "However, as soon as one optimizes a surrogate loss, one has to deal with two questions (Chapelle et al., 2011). First, does minimizing the surrogate on finite training data imply small expected surrogate loss on infinite unseen data? Second, does small expected surrogate loss on infinite unseen data imply small target loss on infinite unseen data? The first issue is one of generalization error bounds for empirical risk minimization (ERM) algorithms that minimize surrogate loss on training data. The second issue is one of calibration: does consistency in the surrogate loss imply consistency in the target loss? This paper deals with the former issue, viz. that of generalization error bounds for surrogate loss minimization. In pioneering works, Lan et al. (2008; 2009) gave generalization error bounds for learning to rank algorithms. However, while the former paper was restricted to analysis of pairwise approach to learning to rank, the later paper was limited to results on just three surrogates: ListMLE, ListNet and RankCosine. To the best of our knowledge, the most generally applicable bound on the generalization error of query-level learning to rank algorithms has been obtained by Chapelle & Wu (2010). The bound of Chapelle & Wu (2010), while generally applicable, does have an explicit dependence on the length of the document list associated with a query.",
      "startOffset" : 88,
      "endOffset" : 1255
    }, {
      "referenceID" : 10,
      "context" : "In benchmark datasets (Liu et al., 2007), m can easily be in the 100-1000 range.",
      "startOffset" : 22,
      "endOffset" : 40
    }, {
      "referenceID" : 2,
      "context" : "Application to ListNet The ListNet ranking method (Cao et al., 2007) uses a convex surrogate, that is defined in the following way1.",
      "startOffset" : 50,
      "endOffset" : 68
    }, {
      "referenceID" : 8,
      "context" : "In particular, the results of Lan et al. (2009) have an m! dependence since they consider the top-m version of ListNet.",
      "startOffset" : 30,
      "endOffset" : 48
    }, {
      "referenceID" : 8,
      "context" : "In particular, the results of Lan et al. (2009) have an m! dependence since they consider the top-m version of ListNet. However, even if the top-1 variant above is considered, their proof technique will result in at least a linear dependence on m and does not result in as tight a bound as we get from our general results. It is also easy to see that the Lipschitz constant G φLN of ListNet loss w.r.t. l2 norm is also 2 and hence the bound of Chapelle & Wu (2010) necessarily has a √ m dependence in it.",
      "startOffset" : 30,
      "endOffset" : 465
    }, {
      "referenceID" : 14,
      "context" : "1 of Srebro et al. (2010) tells us that any non-negative, smooth function f(w) enjoy an important self-bounding property for the gradient:",
      "startOffset" : 5,
      "endOffset" : 26
    } ],
    "year" : 2016,
    "abstractText" : "We consider the generalization ability of algorithms for learning to rank at a query level, a problem also called subset ranking. Existing generalization error bounds necessarily degrade as the size of the document list associated with a query increases. We show that such a degradation is not intrinsic to the problem. For several loss functions, including the cross-entropy loss used in the well known ListNet method, there is no degradation in generalization ability as document lists become longer. We also provide novel generalization error bounds under l1 regularization and faster convergence rates if the loss function is smooth.",
    "creator" : "LaTeX with hyperref package"
  }
}