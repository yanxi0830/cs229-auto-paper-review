{
  "name" : "1412.2106.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "Consistent optimization of AMS by logistic loss minimization",
    "authors" : [ "Wojciech Kot lowski", "Wojciech Kot" ],
    "emails" : [ "wkotlowski@cs.put.poznan.pl" ],
    "sections" : [ {
      "heading" : null,
      "text" : "ar X\niv :1\n41 2.\n21 06\nv1 [\ncs .L\nG ]\n5 D\nec 2\n01 4\nfrom thresholding f on θ̂) measured with respect to the squared AMS, is upperbounded by the regret of f measured with respect to the logistic loss. Hence, we prove that minimizing logistic surrogate is a consistent method of optimizing AMS.\nKeywords: Approximate median significance (AMS), Higgs Boson Machine Learning Challenge, Kaggle, logistic loss, regret bound, statistical consistency."
    }, {
      "heading" : "1. Introduction",
      "text" : "This paper concerns a problem of learning a classifier to optimize approximate median significance (AMS), which was the goal of the Higgs Boson Machine Learning Challenge (HiggsML), hosted by Kaggle website (see Adam-Bourdarios et al. (2014) for details on this contest and description of the problem).\nIn particular, we are interested in an approach to optimize AMS, based on the following two-stage procedure. First, a real-valued function f is learned by minimizing a surrogate loss for binary classification, such as logistic loss function, on the training sample. In the second stage, given f , a threshold is tuned on a separate “validation” sample, by direct optimization of AMS with respect to a classifier obtained from f by classifying all observations with value of f above the threshold as positive class (signal event), and all observations below the threshold as negative class (background event).\nThis approach became very popular among HiggsML challenge participants, mainly due to the fact that its first stage, learning a classifier, does not exploit the task evaluation metric (AMS) in any way and thus can employ without modifications any standard classification tools such as logistic regression, LogitBoost, Stochastic Gradient Boosting, Random Forest, etc. (see, e.g., Hastie et al. (2009)). Despite its simplicity, this approach proved to be very effective in achieving high leaderboard score in HiggsML. 1\n1. See the HiggsML forum https://www.kaggle.com/c/higgs-boson/forums for discussions and presentation of the top score solutions.\nc©2014 Wojciech Kot lowski.\nThe intuition behind this approach is clear: minimization of logistic loss results in estimation of conditional probabilities of signal and background event, and the AMS is assumed to be maximized by classifying the events most likely to be signal as signal events.\nThis paper formalizes this intuition by showing that the approach described above constitutes a consistent method of optimizing AMS. More specifically, we use the notion of regret with respect to some evaluation metric, which is a difference between the performance of a given classifier and the performance of the optimal classifier with respect to this metric. Given a function f , and a classifier h\nf,θ̂ obtained from f by thresholding f at θ̂,\nwe give a bound on the regret of h f,θ̂ measured with respect to the squared AMS by the regret of f measured with respect to the logistic loss, given that the threshold θ̂ is tuned by optimization of AMS among all classifiers of the form hf,θ for any threshold value θ.\nTo our knowledge, this is the first regret bound of this form applicable to a nondecomposable performance measure such as AMS. We also discuss generalization of our approach to different performance measures and surrogate loss functions.\nRelated work. The issue of consistent optimization of performance measures which are functions of true positive and true negative rates has received increasing attention recently in machine learning community (Narasimhan et al., 2014; Natarajan et al., 2014; Zhao et al., 2013). However, these works are mainly concerned with statistical consistency also known as calibration, which determines whether convergence to the minimizer of a surrogate loss implies convergence to the minimizer of the task performance measure as sample size goes to infinity. Here we give a much stronger result which bounds the regret with respect to squared AMS by the regret with respect to logistic loss. Our result is valid for all finite sample sizes and informs about the rates of convergence.\nRecently, Mackey and Bryan (2014) proposed a classification cascade approach to optimize AMS. Their method, based on the theory of Fenchel’s duality, iteratively alternates between solving a cost-sensitive binary classification problem and updating misclassification costs. In contrast, the method described here requires solving an ordinary binary classification problem just once.\nOutline. The paper is organized as follows. In Section 2, we introduce basic concepts needed to state our main result presented in Section 3 and proved in Section 4. Section 5 discusses generalization of our results beyond AMS and logistic loss."
    }, {
      "heading" : "2. Problem Setting",
      "text" : "Binary classifier. In binary classification, the goal is, given an input (feature vector) x ∈ X, to accurately predict the output (label) y ∈ {−1, 1}. We assume input-output pairs (x, y), which we call observations, are generated i.i.d. according to Pr(x, y).2 A classifier is a mapping h : X → {−1, 1}. Given h, we define the following two quantities:\ns(h) = Pr(h(x) = 1, y = 1), b(h) = Pr(h(x) = 1, y = −1),\nwhich can be interpreted as true positive and false positive rates of h.\n2. The original HiggsML problem also involved observations’ weights, but without loss of generality, they can be incorporated into the distribution Pr(x, y).\nAMS and regret. Given a classifier h, define its approximate median significance (AMS) score (Cowan et al., 2011) as AMS(h) = AMS(s(h), b(h)), where:3\nAMS(s, b) =\n√\n2 ( (s+ b) log ( 1 + s\nb\n) − s ) .\nIt is easier to deal with a squared AMS, AMS2(h), and this quantity is used throughout the paper. It is easy to verify that AMS2(s, b) is increasing in s and decreasing in b. Moreover, AMS2(s, b) is jointly convex with respect to (s, b).\nLet h∗AMS be the classifier which maximizes the AMS 2 over all possible classifiers:\nh∗AMS = argmax h∈{−1,1}X AMS2(h).\nGiven h, we define its AMS regret as the distance of h from the optimal classifier h∗AMS measured by means of AMS2:\nRAMS(h) = AMS 2(h∗AMS)−AMS2(h).\nLogistic loss and logistic regret. Given a real number f , and a label y, we define the logistic loss ℓlog : {−1, 1} × R → R+ as:\nℓlog(y, f) = log ( 1 + e−yf ) .\nThe logistic loss is a commonly used surrogate loss function for binary classification, employed in various learning methods, such as logistic regression, LogitBoost or Stochastic Gradient Boosting (see, e.g., Hastie et al. (2009)). It is convex in f , so minimizing logistic loss over the training sample becomes a convex optimization problem, which can be solved efficiently. Another advantage of logistic loss is that the sigmoid transform of f , (1+e−f )−1, can be used to obtain probability estimates Pr(y|x).\nGiven a real-valued function f : X → R, its expected logistic loss Llog(f) is defined as:\nLlog(f) = E(x,y)[ℓlog(y, f(x))].\nLet f∗log = argminf Llog(f) be the minimizer of Llog(f) among all functions f : X → R. We define the logistic regret of f as:\nRlog(f) = Llog(f)− Llog(f∗log)."
    }, {
      "heading" : "3. Main Result",
      "text" : "Any real-valued function f : X → R can be turned into a classifier hf,θ : X → {−1, 1}, by thresholding at some value θ:\nhf,θ(x) = sgn(f(x)− θ),\n3. Comparing to the definition in (Adam-Bourdarios et al., 2014), we skip the regularization term breg. This comes without loss of generality, as breg can be incorporated into b and, since it affects all classifiers equally, will vanish in the definition of regret.\nwhere sgn(x) is the sign function, and we use the convention that sgn(0) = 1.\nThe purpose of this paper is to address the following problem: given a function f with logistic regret Rlog(f), and a threshold θ, what is the maximum AMS regret of hf,θ? In other words, can we bound RAMS(hf,θ) in terms of Rlog(f)? We give a positive answer to this question, which based on the following regret bound:\nLemma 1 There exists a threshold θ∗, such that for any f ,\nRAMS(hf,θ∗) ≤ s(h∗AMS)\nb(h∗AMS)\n√\n1 2 Rlog(f).\nThe proof is quite long and hence is postponed to Section 4. Interestingly, the proof goes by an intermediate bound of the AMS regret by a cost-sensitive classification regret, with misclassification costs proportional to the gradient coordinates of the AMS.\nLemma 1 has the following interpretation. If we are able to find a function f with small logistic regret, we are guaranteed that there exists a threshold θ∗ such that hf,θ∗ has small AMS regret. Note that the same threshold θ∗ will work for any f , and the right hand side of the bound is independent of θ∗. We are now ready to prove the main result of the paper:\nTheorem 2 Given a real-valued function f , let θ̂ = argmaxθ AMS(hf,θ). Then:\nRAMS(hf,θ̂) ≤ s(h∗AMS)\nb(h∗AMS)\n√\n1 2 Rlog(f).\nProof The result follows immediately from Lemma 1 by noticing that solving maxθ AMS(hf,θ) is equivalent to solving minθ RAMS(hf,θ), and that minθ RAMS(hf,θ) ≤ RAMS(hf,θ∗). Theorem 2 motivates the following procedure for AMS maximization:\n1. Find f with small logistic regret, e.g. by employing a learning algorithm minimizing logistic loss on the training sample.\n2. Given f , solve θ̂ = argmaxθ AMS(hf,θ).\nTheorem 2 states that the AMS regret of the classifier obtained by this procedure is upperbounded by the logistic regret of the underlying real-valued function.\nWe now discuss how to approach step 2 of the procedure in practice. In principle, this step requires maximizing AMS defined by means of an unknown distribution Pr(x, y). However, it is sufficient to optimize θ on the empirical counterpart of AMS calculated on a separate validation sample. Due to space limit, we only give a sketch of the proof of this fact: Step 2 involves optimization within a class of threshold functions (since f is fixed), which has VC-dimension equal to 2 (Devroye et al., 1996). By convexity of AMS2,\nAMS2(s, b)−AMS2(ŝ, b̂) ≤ ( ∂AMS2(s, b) ∂s , ∂AMS2(s, b) ∂b\n)⊤\n(s− ŝ, b− b̂) (1)\n(see, e.g. Boyd and Vandenberghe (2004)), where ŝ and b̂ are empirical counterparts of s and b. By VC theory, the deviations of ŝ from s, and b̂ from b can be upperbounded with high probability uniformly over the class of all threshold functions by O(1/ √ m), where m is the validation sample size. This and (1) implies, that AMS2(s, b) of the empirical maximizer is O(1/ √ m) close to the maxθ AMS\n2(hf,θ). Hence, step 2 can be performed within O(1/ √ m) accuracy on a validation sample independent from the training sample."
    }, {
      "heading" : "4. Proof of Lemma 1",
      "text" : "The proof consists of two steps. First, we bound the AMS regret of any classifier h by its cost-sensitive classification regret (introduced below). Next, we show that there exists a threshold θ∗, such that for any f , the cost-sensitive classification regret of hf,θ∗ is upperbounded by the logistic regret of f .\nBounding AMS regret by cost-sensitive classification regret. Given a real number c ∈ (0, 1), define a cost-sensitive classification loss ℓc : {−1, 1} × {−1, 1} → R+ as:\nℓc(y, h) = c1[y = −1]1[h = 1] + (1− c)1[y = 1]1[h = −1],\nwhere 1[A] is the indicator function equal to 1 if predicate A is true, and 0 otherwise. The cost-sensitive loss assigns different costs of misclassification for positive and negative labels. Given classifier h, the expected cost-sensitive loss of h is:\nLc(h) = E(x,y)[ℓc(y, h(x))] = cb(h) + (1− c)(Pr(y = 1)− s(h)),\nwhere s(h) and b(h) are true positive and false positive rates defined before. Let h∗c = argminh Lc(h) be the minimizer of the expected cost-sensitive loss among all classifiers. Define the cost-sensitive classification regret as:\nRc(h) = Lc(h)− Lc(h∗c).\nAny convex and differentiable function g(x) satisfies g(x) ≥ g(y) +∇g(y)⊤(x − y) for any x, y in its convex domain (Boyd and Vandenberghe, 2004). Applying this inequality to AMS2(s, b) jointly convex in (s, b), we have for any s, b, s∗, b∗ ∈ [0, 1]:\nAMS2(s, b) ≥ AMS2(s∗, b∗) + ( ∂AMS2(s∗, b∗) ∂s∗ , ∂AMS2(s∗, b∗) ∂b∗\n)⊤\n(s− s∗, b− b∗). (2)\nGiven classifier h, we set s = s(h), b = b(h), s∗ = s(h∗AMS), b ∗ = b(h∗AMS), and:\nC := ∂AMS2(s∗, b∗) ∂s∗ − ∂AMS 2(s∗, b∗) ∂b∗ , c := − 1 C ∂AMS2(s∗, b∗) ∂b∗ .\nSince AMS2(s, b) is increasing in s and decreasing in b, both ∂AMS 2(s∗,b∗) ∂s∗ and −∂AMS 2(s∗,b∗) ∂b∗ are positive, which implies C > 0 and 0 < c < 1. In this notation, (2) boils down to:\nRAMS(h) = AMS 2(h∗AMS)−AMS2(h) ≤ C\n( c(b(h) − b(h∗AMS)) + (1− c)(s(h∗AMS)− s(h)) )\n= C ( Lc(h)− Lc(h∗AMS) ) ≤ C (\nLc(h)− Lc(h∗c) ) = CRc(h),\nwhere the last inequality follows from the definition of h∗c . Thus, the AMS regret is upperbounded by the cost-sensitive classification regret with costs proportional to the gradient coordinates of AMS2(s∗, b∗) at optimum h∗AMS. 4\nBounding cost-sensitive classification regret by logistic regret. We first give a bound on cost-sensitive classification regret by means of logistic regret conditioned at a given x. This part relies on the techniques used by Bartlett et al. (2006). Then, the final bound is obtained by taking expectation with respect to x, and applying Jensen’s inequality.\nGiven a label h ∈ {−1, 1}, and η ∈ [0, 1], define conditional cost-sensitive classification loss as: ℓc(η, h) = c(1 − η)1[h = 1] + (1− c)η1[h = −1]. The reason this quantity is called “conditional loss” becomes clear if we note that for any classifier h, Lc(h) = Ex[ℓc(η(x), h(x))], where η(x) = Pr(y = 1|x). In other words, ℓc(η(x), h(x)) is the loss of h conditioned on x.\nGiven η, let h∗c = argminh∈{−1,1} ℓc(η, h). It can be easily verified that:\nh∗c = sgn (η − c) ,\nand ℓc(η, h ∗ c) = min{c(1− η), (1 − c)η}. The conditional regret of h is defined as rc(η, h) = ℓc(η, h) − ℓc(h∗c). Note that:\nrc(η, h) =\n{\n0 if h = h∗c , |η − c| if h 6= h∗c .\nGiven a real number f , and η ∈ [0, 1], define conditional logistic loss as:\nℓlog(η, f) = (1− η) log ( 1 + ef ) + η log ( 1 + e−f ) .\nLet f∗log = argminf∈R ℓlog(η, f). By differentiating ℓlog(η, f) with respect to f , and setting the derivative to 0, we get that:\nf∗log = log η\n1− η ,\nand ℓlog(η, f ∗ log) = −η log η − (1 − η) log(1 − η), the binary entropy of η. The conditional logistic regret of f is given by rlog(η, f) = ℓlog(η, f)− ℓlog(f∗log). The conditional regret has a particularly simple form when f is re-expressed as a probability estimate ηf :\nrlog(η, f) = D(η‖ηf ), where ηf := 1\n1 + e−f ,\nand D(η‖ηf ) = η log ηηf + (1 − η) log 1−η 1−ηf is the Kullback-Leibler divergence. By Pinsker’s inequality, D(η‖ηf ) ≥ 2(η − ηf )2.\nGiven real number f , define hf,θ∗ = sgn(f − θ∗), where:\nθ∗ = log c\n1− c .\n4. Note that the gradient at optimum does not vanish, as the optimum is with respect to h, not (s, b).\nWe will now bound the conditional cost-sensitive classification regret rc(η, hf,θ∗) in terms of conditional logistic regret rlog(η, f). First note that:\nhf,θ∗ = 1 ⇐⇒ f ≥ θ∗ = log c 1− c ⇐⇒ 1 1 + e−f ≥ c ⇐⇒ ηf ≥ c,\nso that we can equivalently write hf,θ∗ = sgn(ηf − c). Since h∗c = sgn(η− c), then whenever (ηf − c)(η − c) > 0, it holds hf,θ∗ = h∗c , and rc(η, hf,θ∗) = 0. On the other hand, when (ηf − c)(η − c) ≤ 0, it holds5 rc(η, hf,θ∗) ≤ |η − c|, whereas:\nrlog(η, f) = D(η‖ηf ) Pinsker′s ≥ 2(η − ηf )2 = 2(η − c+ c− ηf )2\n= 2(η − c)2 + 4(η − c)(c− ηf ) + 2(c − ηf )2 ≥ 2(η − c)2 ≥ 2r2c (η, hf,θ∗),\nwhere the last but one inequality is implied by (ηf − c)(η − c) ≤ 0. Taking both cases together, we get:\nrc(η, hf,θ∗) ≤ √ rlog(η, f)/2.\nNow, given any function f ,\nRc(hf,θ∗) = Ex[rc(η, hf,θ∗)] ≤ Ex [ √ rlog(η, f)/2 ] ≤ √ Ex[rlog(η, f)]/2 = √ Rlog(f)/2,\nwhere the last inequality is from Jensen’s inequality applied to the concave function x 7→ √x.\nFinishing the proof. Combining the results from both parts, we get:\nRAMS(hf,θ∗) ≤ CRc(hf,θ∗) ≤ C √ Rlog(f)/2,\nwhere θ∗ = log c1−c is independent of f . Recalling that C = ∂AMS2(s∗,b∗) ∂s∗ − ∂AMS 2(s∗,b∗) ∂b∗\n, we calculate:\nC = log\n(\n1 + s∗\nb∗\n) − ( log ( 1 + s∗\nb∗\n)\n− s ∗\nb∗\n)\n= s∗\nb∗ ,\nwhere s∗ = s(h∗AMS) and b ∗ = b(h∗AMS). This finished the proof.\nNote that the proof actually specifies the exact value of the universal threshold θ∗:\nθ∗ = log c 1− c , where c = 1− b∗ s∗ log\n(\n1 + s∗\nb∗\n)\n."
    }, {
      "heading" : "5. Generalization beyond AMS and logistic loss",
      "text" : "Results of this paper can be generalized beyond AMS metric and logistic loss surrogate. The AMS can be replaced by any other evaluation metric, which enjoys the following two properties: 1) is increasing in s, and decreasing in b; 2) is jointly convex in s and b. These were the only two properties of the AMS used in the proof of Lemma 1. The logistic loss\n5. rc(η, hf,θ∗) = |η − c| if (ηf − c)(η − c) < 0, and can be either 0 or |η − c| when (ηf − c)(η − c) = 0.\nsurrogate can be replaced by any other convex surrogate loss ℓ, such that the following property holds: There exists a threshold θ∗ which is a function of the cost c, such that for all f ,\nRc(hf,θ∗) ≤ λ √ Rℓ(f),\nfor some positive constant λ. This property is satisfied by, e.g., squared error loss ℓsq(y, f) = (y − f)2 with λ = 1, which can be verified by noticing that the logistic regret upperbounds the squared error regret by Pinsker’s inequality. We conjecture that all strongly proper composite losses (Agarwal, 2014) hold this property."
    }, {
      "heading" : "Acknowledgments",
      "text" : "The author was supported by the Foundation For Polish Science Homing Plus grant, cofinanced by the European Regional Development Fund. The author would like to thank Krzysztof Dembczyński for interesting discussions and proofreading the paper."
    } ],
    "references" : [ {
      "title" : "Learning to discover: the Higgs boson machine learning",
      "author" : [ "Claire Adam-Bourdarios", "Glen Cowan", "Cécile Germain", "Isabelle Guyon", "Balázs Kégl", "David Rousseau" ],
      "venue" : null,
      "citeRegEx" : "Adam.Bourdarios et al\\.,? \\Q2014\\E",
      "shortCiteRegEx" : "Adam.Bourdarios et al\\.",
      "year" : 2014
    }, {
      "title" : "Surrogate regret bounds for bipartite ranking via strongly proper losses",
      "author" : [ "Shivani Agarwal" ],
      "venue" : "Journal of Machine Learning Research,",
      "citeRegEx" : "Agarwal.,? \\Q2014\\E",
      "shortCiteRegEx" : "Agarwal.",
      "year" : 2014
    }, {
      "title" : "Convexity, classification, and risk bounds",
      "author" : [ "Peter L. Bartlett", "Michael I. Jordan", "Jon D. McAuliffe" ],
      "venue" : "Journal of the American Statistical Association,",
      "citeRegEx" : "Bartlett et al\\.,? \\Q2006\\E",
      "shortCiteRegEx" : "Bartlett et al\\.",
      "year" : 2006
    }, {
      "title" : "Convex Optimization",
      "author" : [ "Stephen Boyd", "Lieven Vandenberghe" ],
      "venue" : null,
      "citeRegEx" : "Boyd and Vandenberghe.,? \\Q2004\\E",
      "shortCiteRegEx" : "Boyd and Vandenberghe.",
      "year" : 2004
    }, {
      "title" : "Asymptotic formulae for likelihood-based tests of new physics",
      "author" : [ "Glen Cowan", "Kyle Cranmer", "Eilam Gross", "Ofer Vitells" ],
      "venue" : "The European Physical Journal C-Particles and Fields,",
      "citeRegEx" : "Cowan et al\\.,? \\Q2011\\E",
      "shortCiteRegEx" : "Cowan et al\\.",
      "year" : 2011
    }, {
      "title" : "Elements of Statistical Learning: Data Mining, Inference, and Prediction",
      "author" : [ "Trevor Hastie", "Robert Tibshirani", "Jerome H. Friedman" ],
      "venue" : null,
      "citeRegEx" : "Hastie et al\\.,? \\Q2009\\E",
      "shortCiteRegEx" : "Hastie et al\\.",
      "year" : 2009
    }, {
      "title" : "Weighted classification cascades for optimizing discovery significance in the HiggsML challenge",
      "author" : [ "Lester Mackey", "Jordan Bryan" ],
      "venue" : "CoRR, abs/1409.2655,",
      "citeRegEx" : "Mackey and Bryan.,? \\Q2014\\E",
      "shortCiteRegEx" : "Mackey and Bryan.",
      "year" : 2014
    }, {
      "title" : "On the statistical consistency of plug-in classifiers for non-decomposable performance measures",
      "author" : [ "Harikrishna Narasimhan", "Rohit Vaish", "Shivani Agarwal" ],
      "venue" : "In Neural Information Processing Systems (NIPS),",
      "citeRegEx" : "Narasimhan et al\\.,? \\Q2014\\E",
      "shortCiteRegEx" : "Narasimhan et al\\.",
      "year" : 2014
    }, {
      "title" : "Consistent binary classification with generalized performance metrics",
      "author" : [ "Nagarajan Natarajan", "Oluwasanmi Koyejo", "Pradeep K. Ravikumar", "Inderjit S. Dhillon" ],
      "venue" : "In Neural Information Processing Systems (NIPS),",
      "citeRegEx" : "Natarajan et al\\.,? \\Q2014\\E",
      "shortCiteRegEx" : "Natarajan et al\\.",
      "year" : 2014
    }, {
      "title" : "Beyond Fano’s inequality: Bounds on the optimal F-score, BER, and cost-sensitive risk and their implications",
      "author" : [ "Ming-Jie Zhao", "Narayanan Edakunni", "Adam Pocock", "Gavin Brown" ],
      "venue" : "Journal of Machine Learning Research,",
      "citeRegEx" : "Zhao et al\\.,? \\Q2013\\E",
      "shortCiteRegEx" : "Zhao et al\\.",
      "year" : 2013
    } ],
    "referenceMentions" : [ {
      "referenceID" : 0,
      "context" : "Introduction This paper concerns a problem of learning a classifier to optimize approximate median significance (AMS), which was the goal of the Higgs Boson Machine Learning Challenge (HiggsML), hosted by Kaggle website (see Adam-Bourdarios et al. (2014) for details on this contest and description of the problem).",
      "startOffset" : 225,
      "endOffset" : 255
    }, {
      "referenceID" : 0,
      "context" : "Introduction This paper concerns a problem of learning a classifier to optimize approximate median significance (AMS), which was the goal of the Higgs Boson Machine Learning Challenge (HiggsML), hosted by Kaggle website (see Adam-Bourdarios et al. (2014) for details on this contest and description of the problem). In particular, we are interested in an approach to optimize AMS, based on the following two-stage procedure. First, a real-valued function f is learned by minimizing a surrogate loss for binary classification, such as logistic loss function, on the training sample. In the second stage, given f , a threshold is tuned on a separate “validation” sample, by direct optimization of AMS with respect to a classifier obtained from f by classifying all observations with value of f above the threshold as positive class (signal event), and all observations below the threshold as negative class (background event). This approach became very popular among HiggsML challenge participants, mainly due to the fact that its first stage, learning a classifier, does not exploit the task evaluation metric (AMS) in any way and thus can employ without modifications any standard classification tools such as logistic regression, LogitBoost, Stochastic Gradient Boosting, Random Forest, etc. (see, e.g., Hastie et al. (2009)).",
      "startOffset" : 225,
      "endOffset" : 1326
    }, {
      "referenceID" : 7,
      "context" : "The issue of consistent optimization of performance measures which are functions of true positive and true negative rates has received increasing attention recently in machine learning community (Narasimhan et al., 2014; Natarajan et al., 2014; Zhao et al., 2013).",
      "startOffset" : 195,
      "endOffset" : 263
    }, {
      "referenceID" : 8,
      "context" : "The issue of consistent optimization of performance measures which are functions of true positive and true negative rates has received increasing attention recently in machine learning community (Narasimhan et al., 2014; Natarajan et al., 2014; Zhao et al., 2013).",
      "startOffset" : 195,
      "endOffset" : 263
    }, {
      "referenceID" : 9,
      "context" : "The issue of consistent optimization of performance measures which are functions of true positive and true negative rates has received increasing attention recently in machine learning community (Narasimhan et al., 2014; Natarajan et al., 2014; Zhao et al., 2013).",
      "startOffset" : 195,
      "endOffset" : 263
    }, {
      "referenceID" : 6,
      "context" : "Recently, Mackey and Bryan (2014) proposed a classification cascade approach to optimize AMS.",
      "startOffset" : 10,
      "endOffset" : 34
    }, {
      "referenceID" : 4,
      "context" : "Given a classifier h, define its approximate median significance (AMS) score (Cowan et al., 2011) as AMS(h) = AMS(s(h), b(h)), where:3",
      "startOffset" : 77,
      "endOffset" : 97
    }, {
      "referenceID" : 5,
      "context" : ", Hastie et al. (2009)).",
      "startOffset" : 2,
      "endOffset" : 23
    }, {
      "referenceID" : 0,
      "context" : "Comparing to the definition in (Adam-Bourdarios et al., 2014), we skip the regularization term breg.",
      "startOffset" : 31,
      "endOffset" : 61
    }, {
      "referenceID" : 3,
      "context" : "Boyd and Vandenberghe (2004)), where ŝ and b̂ are empirical counterparts of s and b.",
      "startOffset" : 0,
      "endOffset" : 29
    }, {
      "referenceID" : 3,
      "context" : "Any convex and differentiable function g(x) satisfies g(x) ≥ g(y) +∇g(y)⊤(x − y) for any x, y in its convex domain (Boyd and Vandenberghe, 2004).",
      "startOffset" : 115,
      "endOffset" : 144
    }, {
      "referenceID" : 2,
      "context" : "This part relies on the techniques used by Bartlett et al. (2006). Then, the final bound is obtained by taking expectation with respect to x, and applying Jensen’s inequality.",
      "startOffset" : 43,
      "endOffset" : 66
    }, {
      "referenceID" : 1,
      "context" : "We conjecture that all strongly proper composite losses (Agarwal, 2014) hold this property.",
      "startOffset" : 56,
      "endOffset" : 71
    } ],
    "year" : 2014,
    "abstractText" : "In this paper, we theoretically justify an approach popular among participants of the Higgs Boson Machine Learning Challenge to optimize approximate median significance (AMS). The approach is based on the following two-stage procedure. First, a real-valued function f is learned by minimizing a surrogate loss for binary classification, such as logistic loss, on the training sample. Then, given f , a threshold θ̂ is tuned on a separate validation sample, by direct optimization of AMS. We show that the regret of the resulting classifier (obtained from thresholding f on θ̂) measured with respect to the squared AMS, is upperbounded by the regret of f measured with respect to the logistic loss. Hence, we prove that minimizing logistic surrogate is a consistent method of optimizing AMS.",
    "creator" : "LaTeX with hyperref package"
  }
}