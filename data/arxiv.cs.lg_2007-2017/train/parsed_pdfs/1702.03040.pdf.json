{
  "name" : "1702.03040.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "Following the Leader and Fast Rates in Linear Prediction: Curved Constraint Sets and Other Regularities∗",
    "authors" : [ "Ruitong Huang", "Tor Lattimore", "András György", "Csaba Szepesvári" ],
    "emails" : [ ],
    "sections" : [ {
      "heading" : null,
      "text" : "known to perform well when the loss functions it is used on are convex and positively curved. In this paper we ask whether there are other “lucky” settings when FTL achieves sublinear, “small” regret. In particular, we study the fundamental problem of linear prediction over a non-empty convex, compact domain. Amongst other results, we prove that the curvature of the boundary of the domain can act as if the losses were curved: In this case, we prove that as long as the mean of the loss vectors have positive lengths bounded away from zero, FTL enjoys a logarithmic growth rate of regret, while, e.g., for polytope domains and stochastic data it enjoys finite expected regret. Building on a previously known meta-algorithm, we also get an algorithm that simultaneously enjoys the worst-case guarantees and the bound available for FTL."
    }, {
      "heading" : "1 Introduction",
      "text" : "Learning theory traditionally has been studied in a statistical framework, discussed at length, for example, by Shalev-Shwartz and Ben-David (2014). The issue with this approach is that the analysis of the performance of learning methods seems to critically depend on whether the data generating mechanism satisfies some probabilistic assumptions. Realizing that these assumptions are not necessarily critical, much work has been devoted recently to studying learning algorithms in the so-called online learning framework (Cesa-Bianchi and Lugosi, 2006). The online learning framework makes minimal assumptions about the data generating mechanism, while allowing one to replicate results of the statistical framework through online-to-batch conversions (Cesa-Bianchi et al., 2004). By following a minimax approach, however, results proven in the online learning setting, at least initially, led to rather conservative results and algorithm designs, failing to capture how more regular, “easier” data, may give rise to faster learning speed. This is problematic as it may suggest overly conservative learning strategies, missing opportunities to extract more information when the data is nicer. Also, it is hard to argue that data resulting from passive data collection, such as weather data, would ever be adversarially generated (though it is equally hard to defend that such data satisfies precise stochastic assumptions). Realizing this issue, during recent years much work has been devoted to understanding what regularities and how can lead to faster learning speed. For example, much work has been devoted to showing that faster learning speed (smaller “regret”) can be achieved in the online convex optimization setting when the loss functions are “curved”, such as when the loss functions are strongly convex or exp-concave, or when the losses show small variations, or the best prediction in hindsight has a small total loss, and that these properties can be exploited in an adaptive manner (e.g., Merhav and Feder 1992, Freund and Schapire 1997, Gaivoronski and Stella 2000, Cesa-Bianchi and Lugosi 2006, Hazan et al. 2007, Bartlett ∗R. Huang and Cs. Szepesvári are with the Department of Computing Science, University of Alberta, AB, Canada, email: ruitong@ualberta.ca, szepesva@ualberta.ca. T. Lattimore was with the School of Informatics and Computing, Indiana University, IN, USA, email: tor.lattimore@gmail.com. A. György is with the Department of Electrical and Electronic Engineering, Imperial College London, UK, email: a.gyorgy@imperial.ac.uk.\nar X\niv :1\n70 2.\n03 04\n0v 1\n[ cs\n.L G\n] 1\n0 Fe\nb 20\net al. 2007, Kakade and Shalev-Shwartz 2009, Orabona et al. 2012, Rakhlin and Sridharan 2013, van Erven et al. 2015, Foster et al. 2015).\nIn this paper we contribute to this growing literature by studying online linear prediction and the follow the leader (FTL) algorithm. Online linear prediction is arguably the simplest yet fundamental of all the learning settings, and lies at the heart of online convex optimization, while it also serves as an abstraction of core learning problems such as prediction with expert advice. FTL, the online analogue of empirical risk minimization of statistical learning, is the simplest learning strategy, one can think of. Although the linear setting of course removes the possibility of exploiting the curvature of losses, as we will see, there are multiple ways online learning problems can present data that allows for small regret, even for FTL. As is it well known, in the worst case, FTL suffers a linear regret (e.g., Example 2.2 of Shalev-Shwartz (2012)). However, for “curved” losses (e.g., exp-concave losses), FTL was shown to achieve small (logarithmic) regret (see, e.g., Merhav and Feder (1992); Cesa-Bianchi and Lugosi (2006); Gaivoronski and Stella (2000); Hazan et al. (2007)).\nIn this paper we take a thorough look at FTL in the case when the losses are linear, but the problem perhaps exhibits other regularities. The motivation comes from the simple observation that, for prediction over the simplex, when the loss vectors are selected independently of each other from a distribution with a bounded support with a nonzero mean, FTL quickly locks onto selecting the loss-minimizing vertex of the simplex, achieving finite expected regret. In this case, FTL is arguably an excellent algorithm. In fact, FTL is shown to be the minimax optimizer for the binary losses in the stochastic expert setting in the paper of Kotłowski (2016). Thus, we ask the question of whether there are other regularities that allow FTL to achieve nontrivial performance guarantees. Our main result shows that when the decision set (or constraint set) has a sufficiently “curved” boundary (equivalently, if it is strongly convex) and the linear loss is bounded away from 0, FTL is able to achieve logarithmic regret even in the adversarial setting, thus opening up a new way to prove fast rates not based on the curvature of losses, but on that of the boundary of the constraint set and non-singularity of the linear loss. In a matching lower bound we show that this regret bound is essentially unimprovable. We also show an alternate bound for polytope constraint sets, which allows us to prove that (under certain technical conditions) for stochastic problems the expected regret of FTL will be finite. To finish, we use (A, B)-prod of Sani et al. (2014) to design an algorithm that adaptively interpolates between the worst case O( √ n logn) regret and the smaller regret bounds, which we prove here for “easy data.” We also show that if the constraint set is the unit ball, both the follow the regularized leader (FTRL) algorithm and a combination of FTL and shrinkage, which we call follow the shrunken leader (FTSL), achieve logarithmic regret for easy data. Simulation results on artificial data complement the theoretical findings.\nWhile we believe that we are the first to point out that the curvature of the constraint set W can help in speeding up learning, this effect is known in convex optimization since at least the work of Levitin and Polyak (1966), who showed that exponential rates are attainable for strongly convex constraint sets if the norm of the gradients of the objective function admit a uniform lower bound. More recently, Garber and Hazan (2015) proved an O(1/n2) optimization error bound (with problem-dependent constants) for the Frank-Wolfe algorithm for strongly convex and smooth objectives and strongly convex constraint sets. The effect of the shape of the constraint set was also discussed by Abbasi-Yadkori (2010) who demonstrated O( √ n) regret in the linear bandit setting. While these results at a high level are similar to ours, our proof technique is rather different than that used there."
    }, {
      "heading" : "2 Preliminaries, online learning and the follow the leader algorithm",
      "text" : "We consider the standard framework of online convex optimization, where a learner and an environment interact in a sequential manner in n rounds: In round every round t = 1, . . . , n, first the learner predicts wt ∈ W. Then the environment picks a loss function `t ∈ L, and the learner suffers loss `t(wt) and observes `t. Here, W is a non-empty, compact convex subset of Rd and L is a set of convex functions, mapping W to the reals. The elements of L are called loss functions. The performance of the learner is measured in terms of\nits regret,\nRn = n∑ t=1 `t(wt)− min w∈W n∑ t=1 `t(w) .\nThe simplest possible case, which will be the focus of this paper, is when the losses are linear, i.e., when `t(w) = 〈ft, w〉 for some ft ∈ F ⊂ Rd. In fact, the linear case is not only simple, but is also fundamental since the case of nonlinear loss functions can be reduced to it: Indeed, even if the losses are nonlinear, defining ft ∈ ∂`t(wt) to be a subgradient1 of `t at wt and letting ˜̀t(u) = 〈ft, u〉, by the definition of subgradients, `t(wt)− `t(u) ≤ `t(wt)− (`t(wt) + 〈ft, u− wt〉) = ˜̀t(wt)− ˜̀t(u), hence for any u ∈ W,∑\nt `t(wt)− ∑ t `t(u) ≤ ∑ t ˜̀ t(wt)− ∑ t ˜̀ t(u) .\nIn particular, if an algorithm keeps the regret small no matter how the linear losses are selected (even when allowing the environment to pick losses based on the choices of the learner), the algorithm can also be used to keep the regret small in the nonlinear case. Hence, in what follows we will study the linear case `t(w) = 〈ft, w〉 and, in particular, we will study the regret of the so-called “Follow The Leader” (FTL) learner, which, in round t ≥ 2 picks\nwt = argmin w∈W t−1∑ i=1 `i(w) .\nFor the first round, w1 ∈ W is picked in an arbitrary manner. When W is compact, the optimal w of minw∈W ∑t−1 i=1〈w, ft〉 is attainable, which we will assume henceforth. If multiple minimizers exist, we simply fix one of them as wt. We will also assume that F is non-empty, compact and convex."
    }, {
      "heading" : "2.1 Support functions",
      "text" : "Let Θt = − 1t ∑t i=1 fi be the negative average of the first t vectors in (ft)nt=1, ft ∈ F . For convenience, we define Θ0 := 0. Thus, for t ≥ 2,\nwt = argmin w∈W t−1∑ i=1 〈w, fi〉 = argmin w∈W 〈w,−Θt−1〉 = argmax w∈W 〈w,Θt−1〉 .\nDenote by Φ(Θ) = maxw∈W〈w,Θ〉 the so-called support function of W. The support function, being the maximum of linear and hence convex functions, is itself convex. Further Φ is positive homogenous: for a ≥ 0 and θ ∈ Rd, Φ(aθ) = aΦ(θ). It follows then that the epigraph epi(Φ) = { (θ, z) | z ≥ Φ(θ), z ∈ R, θ ∈ Rd } of Φ is a cone, since for any (θ, z) ∈ epi(Φ) and a ≥ 0, az ≥ aΦ(θ) = Φ(aθ), (aθ, az) ∈ epi(Φ) also holds. The differentiability of the support function is closely tied to whether in the FTL algorithm the choice of wt is uniquely determined:\nProposition 2.1. Let W 6= ∅ be convex and closed. Fix Θ and let Z := {w ∈ W | 〈w,Θ〉 = Φ(Θ)}. Then, ∂Φ(Θ) = Z and, in particular, Φ(Θ) is differentiable at Θ if and only if maxw∈W〈w,Θ〉 has a unique optimizer. In this case, ∇Φ(Θ) = argmaxw∈W〈w,Θ〉.\nThe proposition follows from Danskin’s theorem when W is compact (e.g., Proposition B.25 of Bertsekas 1999), but a simple direct argument can also be used to show that it also remains true even when W is unbounded. 2 By Proposition 2.1, when Φ is differentiable at Θt−1, wt = ∇Φ(Θt−1). 1 We let ∂g(x) denote the subdifferential of a convex function g : dom(g) → R at x, i.e., ∂g(x) ={ θ ∈ Rd | g(x′) ≥ g(x) + 〈θ, x′ − x〉 ∀x′ ∈ dom(g) } , where dom(g) ⊂ Rd is the domain of g.\n2 The proofs not given in the main text can be found in the appendix."
    }, {
      "heading" : "3 Non-stochastic analysis of FTL",
      "text" : "We start by rewriting the regret of FTL in an equivalent form, which shows that we can expect FTL to enjoy a small regret when successive weight vectors move little. A noteworthy feature of the next proposition is that rather than bounding the regret from above, it gives an equivalent expression for it.\nProposition 3.1. The regret Rn of FTL satisfies\nRn = n∑ t=1 t 〈wt+1 − wt,Θt〉 .\nThe result is a direct corollary of Lemma 9 of McMahan (2010), which holds for any sequence of losses, even in the lack of convexity. It is also a tightening of the well-known inequality Rn ≤ ∑n t=1 `t(wt)− `t(wt+1), which again holds for arbitrary loss sequences (e.g., Lemma 2.1 of Shalev-Shwartz (2012)). To keep the paper self-contained, we give an elegant, short direct proof, based on the summation by parts formula:\nProof. The summation by parts formula states that for any u1, v1, . . . , un+1, vn+1 reals, ∑n t=1 ut (vt+1− vt) =\n(ut+1vt+1 − u1v1) − ∑n t=1(ut+1 − ut) vt+1. Applying this to the definition of regret with ut := wt,· and vt+1 := tΘt, we get\nRn = − n∑ t=1 〈wt, tΘt − (t− 1)Θt−1〉+ 〈wn+1, nΘn〉\n= − { hhhhhh〈wn+1, nΘn〉 − 0−\nn∑ t=1 〈wt+1 − wt, tΘt〉\n} +hhhhhh〈wn+1, nΘn〉.\nOur next proposition gives another formula that is equal to the regret. As opposed to the previous result, this formula is appealing as it is independent of wt; but it directly connects the sequence (Θt)t to the geometric properties of W through the support function Φ. For this proposition we will momentarily assume that Φ is differentiable at (Θt)t≥1; a more general statement will follow later.\nProposition 3.2. If Φ is differentiable at Θ1, . . . ,Θn,\nRn = n∑ t=1 tDΦ(Θt,Θt−1) , (1)\nwhere DΦ(θ′, θ) = Φ(θ′)− Φ(θ)− 〈∇Φ(θ), θ′ − θ〉 is the Bregman divergence of Φ and we use the convention that ∇Φ(0) = w1.\nProof. Let v = argmaxw∈W〈w, θ〉, v′ = argmaxw∈W〈w, θ′〉. When Φ is differentiable at θ,\nDΦ(θ′, θ) = Φ(θ′)− Φ(θ)− 〈∇Φ(θ), θ′− θ〉 = 〈v′, θ′〉− 〈v, θ〉 − 〈v, θ′− θ〉 = 〈v′− v, θ′〉 . (2)\nTherefore, by Proposition 3.1, Rn = ∑n t=1 t〈wt+1 − wt,Θt〉 = ∑n t=1 tDΦ(Θt,Θt−1).\nWhen Φ is non-differentiable at some of the points Θ1, . . . ,Θn, the equality in the above proposition can be replaced with inequalities. Defining the upper Bregman divergence DΦ(θ′, θ) = supw∈∂Φ(θ) Φ(θ′)− Φ(θ)− 〈w, θ′ − θ〉 and the lower Bregman divergence DΦ(θ′, θ) similarly with inf instead of sup, we can easily obtain an analogue of Proposition 3.2:\nn∑ t=1 tDΦ(Θt,Θt−1) ≤ Rn ≤ n∑ t=1 tDΦ(Θt,Θt−1) . (3)"
    }, {
      "heading" : "3.1 Constraint sets with positive curvature",
      "text" : "The previous results show in an implicit fashion that the curvature ofW controls the regret. Before presenting our first main result, which makes this connection explicit, we define some basic notions from differential geometry related to the curvature (all differential geometry concept and results that we need can be found in Section 2.5 of Schneider, 2014).\nGiven a C2 (twice continuously differentiable) planar curve γ in R2, there exists a parametrization with respect to the curve length s, such that ‖γ′(s)‖ = ‖ (x′(s), y′(s)) ‖ = x′(s)2+y′(s)2 = 1. Under the curve length parametrization, the curvature of γ at γ(s) is ‖γ′′(s)‖. Define the unit normal vector n(s) as the unit vector that is perpendicular to γ′(s).3 Note that n(s) ·γ′(s) = 0. Thus 0 = (n(s) · γ′(s))′ = n′(s) ·γ′(s)+n(s) ·γ′′(s), and ‖γ′′(s)‖ = ‖n(s) · γ′′(s)‖ = ‖n′(s) · γ′(s)‖ = ‖n′(s)‖. Therefore, the curvature of γ at point γ(s) is the length of the differential of its unit normal vector.\nDenote the boundary of W by bd(W). We shall assume that W is C2, that is, bd(W) is a twice continuously differentiable submanifold of Rd. We denote the tangent plane of bd(W) at point w by TwW. Now there exists a unique unit vector at w that is perpendicular to TwW and points outward of W. In fact, one can define a continously differentiable normal unit vector field on bd(W), uW : bd(W) → Sd−1, the so-called Gauss map, which maps a boundary point w ∈ bd(W) to the unique outer normal vector to W at w, where Sd−1 = { x ∈ Rd | ‖x‖2 = 1 } denotes the unit sphere in d-dimensions. The differential of the Gauss map, ∇uW(w), defines a linear endomorphism of TwW. Moreover, ∇uW(w) is a self-adjoint operator, with nonnegative eigenvalues. The differential of the Gauss map, ∇uW(w), describes the curvature of bd(W) via the second fundamental form. In particular, the principal curvatures of bd(W) at w ∈ bd(W) is defined as the eigenvalues of ∇uW(w). Perhaps a more intuitive, yet equivalent definition, is that the principal curvatures are the eigenvalues of the Hessian of f = fw in the parameterization t 7→ w + t− fw(t)uW(w) of bd(W) which is valid in a small open neighborhood of w, where fw : TwW → [0,∞) is a suitable convex, nonnegative valued function that also satisfies fw(0) = 0 and where TwW, a hyperplane of Rd, denotes the tangent space of W at w, obtained by taking the support plane H of W at w and shifting it by −w. Thus, the principal curvatures at some point w ∈ bd(W) describe the local shape of bd(W) up to the second order. In this paper, we are interested in the minimum principal curvature at w ∈ bd(W), which can be intepreated as the minimum curvature at w over all the planar curves γ ∈ bd(W) that go through w.\nA related concept that has been used in convex optimization to show fast rates is that of a strongly convex constraint set (Levitin and Polyak, 1966; Garber and Hazan, 2015): W is λ-strongly convex with respect to the norm ‖·‖ if, for any x, y ∈ W and γ ∈ [0, 1], the ‖·‖-ball with origin γx+ (1− γ)y and radius γ(1 − γ)λ ‖x− y‖2 /2 is included in W. We show in Proposition A.1 in the appendix that a convex body W ∈ C2 is λ-strongly convex with respect to ‖·‖2 if and only if the principal curvatures of the surface bd(W) are all at least λ.\nAs promised, our next result connects the principal curvatures of bd(W) to the regret of FTL and shows that FTL enjoys logarithmic regret for highly curved surfaces, as long as ‖Θt‖2 is bounded away from zero.\nTheorem 3.3. Let W ⊂ Rd be a C2 convex body4 with d ≥ 2. Let M = maxf∈F ‖f‖2 and assume that Φ is differentiable at (Θt)t. Assume that the principal curvatures of the surface bd(W) are all at least λ0 for some constant λ0 > 0 and Ln := min1≤t≤n ‖Θt‖2 > 0. Choose w1 ∈ bd(W). Then\nRn ≤ 2M2\nλ0Ln (1 + log(n)) .\nAs we will show later in an essentially matching lower bound, this bound is tight, showing that the forte of FTL is when Ln is bounded away from zero and λ0 is large. Note that the bound is vacuous as soon as Ln = O(log(n)/n) and is worse than the minimax bound of O( √ n) when Ln = o(log(n)/ √ n). One possibility to reduce the bound’s sensitivity to Ln is to use the trivial bound 〈wt+1 − wt,Θt〉 ≤ LW = L supw,w′∈W ‖w − w′‖2 for indices t when ‖Θt‖ ≤ L. Then, by optimizing the bound over L, one gets\n3There exist two unit vectors that are perpendicular to γ′(s) for each point on γ. Pick the ones that are consistently oriented. 4Following Schneider (2014), a convex body of Rd is any non-empty, compact, convex subset of Rd.\na data-dependent bound of the form infL>0 ( 2M2 λ0L (1 + log(n)) + LW ∑n t=1 t I (‖Θt‖ ≤ L) ) , which is more complex, but is free of Ln and thus reflects the nature of FTL better. Note that in the case of stochastic problems, where f1, . . . , fn are independent and identically distributed (i.i.d.) with µ := −E [Θt] 6= 0, the probability that ‖Θt‖2 < ‖µ‖2 /2 is exponentially small in t. Thus, selecting L = ‖µ‖2 /2 in the previous bound, the contribution of the expectation of the second term is O(‖µ‖2W ), giving an overall bound of the form O( M 2\nλ0‖µ‖2 log(n) + ‖µ‖2W ). After the proof we will provide some simple examples that should make it\nmore intuitive how the curvature of W helps keeping the regret of FTL small.\nProof. Fix θ1, θ2 ∈ Rd and let w(1) = argmaxw∈W〈w, θ1〉, w(2) = argmaxw∈W〈w, θ2〉. Note that if θ1, θ2 6= 0 then w(1), w(2) ∈ bd(W). Below we will show that\n〈w(1) − w(2), θ1〉 ≤ 1 2λ0 ‖θ2 − θ1‖22 ‖θ2‖2 . (4)\nProposition 3.1 suggests that it suffices to bound 〈wt+1 − wt,Θt〉. By (4), we see that it suffices to bound how much Θt moves. A straightforward calculation shows that Θt cannot move much: for any norm ‖·‖ on F , we have\n‖Θt −Θt−1‖ = ∥∥∥∥∥ 1t− 1 t−1∑ i=1 fi − 1 t t∑ i=1 fi ∥∥∥∥∥ = ∥∥∥∥∥ t−1∑ i=1 ( 1 t− 1 − 1 t ) fi − 1 t ft ∥∥∥∥∥ ≤\n∥∥∥∥∥ t−1∑ i=1 ( 1 t− 1 − 1 t ) fi ∥∥∥∥∥+ ∥∥∥∥1t ft ∥∥∥∥ = ∥∥∥∥∥ t−1∑ i=1 1 t(t− 1)fi ∥∥∥∥∥+ ∥∥∥∥1t ft ∥∥∥∥ = 1 t ∥∥∥∥∥ 1t− 1 t−1∑ i=1 fi\n∥∥∥∥∥+ 1t ‖ft‖ ≤ 2tM . (5) where M = maxf∈F ‖f‖ is a constant that depends on F and the norm ‖·‖.\nCombining inequality (4) with Proposition 3.1 and (5), we get\nRn = n∑ t=1 t〈wt+1 − wt,Θt〉 ≤ n∑ t=1 t 2λ0 ‖Θt −Θt−1‖22 ‖Θt−1‖2\n≤ 2M 2\nλ0 n∑ t=1 1 t‖Θt−1‖2 ≤ 2M 2 λ0Ln n∑ t=1 1 t ≤ 2M 2 λ0Ln (1 + log(n)) .\nTo finish the proof, it thus remains to show (4). The following elementary lemma relates the cosine of the angle between two vectors θ1 and θ2 to the squared normalized distance between the two vectors, thereby reducing our problem to bounding the cosine of this angle. For brevity, we denote by cos(θ1, θ2) the cosine of the angle between θ1 and θ2.\nLemma 3.4. For any non-zero vectors θ1, θ2 ∈ Rd,\n1− cos(θ1, θ2) ≤ 1 2 ‖θ1 − θ2‖22 ‖θ1‖2‖θ2‖2 . (6)\nProof. Note that ‖θ1‖2‖θ2‖2 cos(θ1, θ2) = 〈θ1, θ2〉. Therefore, (6) is equivalent to 2‖θ1‖2‖θ2‖2 − 2〈θ1, θ2〉 ≤ ‖θ1 − θ2‖22, which, by algebraic manipulations, is itself equivalent to 0 ≤ (‖θ1‖2 − ‖θ2‖2)2.\nWith this result, we see that it suffices to upper bound cos(θ1, θ2) by 1 − λ0〈w(1) − w(2), θ1‖θ1‖2 〉. To develop this bound, let θ̃i = θi‖θi‖2 for i = 1, 2. The angle between θ1 and θ2 is the same as the angle between the normalized vectors θ̃1 and θ̃2. To calculate the cosine of the angle between θ̃1 and θ̃2, let P be a plane spanned by θ̃1 and w(1) − w(2) and passing through w(1) (P is uniquely determined if θ̃1 is not parallel to\nw(1) − w(2); if there are multiple planes, just pick any of them). Further, let θ̂2 ∈ Sd−1 be the unit vector along the projection of θ̃2 onto the plane P , as indicated in Fig. 1. Clearly, cos(θ̃1, θ̃2) ≤ cos(θ̃1, θ̂2).\nConsider a curve γ(s) on bd(W) connecting w(1) and w(2) that is defined by the intersection of bd(W) and P and is parametrized by its curve length s so that γ(0) = w(1) and γ(l) = w(2), where l is the length of the curve γ between w(1) and w(2). Let uW(w) denote the outer normal vector to W at w as before, and let uγ : [0, l]→ Sd−1 be such that uγ(s) = θ̂ where θ̂ is the unit vector parallel to the projection of uW(γ(s)) on the plane P . By definition, uγ(0) = θ̃1 and uγ(l) = θ̂2. Note that in fact γ exists in two versions since W is a compact convex body, hence the intersection of P and bd(W) is a closed curve. Of these two versions we choose the one that satisfies that 〈γ′(s), θ̃1〉 ≤ 0 for s ∈ [0, l].5 Given the above, we have\ncos(θ̃1, θ̂2) = 〈θ̂2, θ̃1〉 = 1+ 〈θ̂2 − θ̃1, θ̃1〉 = 1+ 〈∫ l\n0 u′γ(s)ds, θ̃1\n〉 = 1+ ∫ l 0 〈u′γ(s), θ̃1〉ds. (7)\nNote that γ is a planar curve on bd(W), thus its curvature λ(s) satisfies λ(s) ≥ λ0 for s ∈ [0, l]. Also, for any w on the curve γ, γ′(s) is a unit vector parallel to P . Moreover, u′γ(s) is parallel to γ′(s) and λ(s) = ‖u′γ(s)‖2. Therefore,\n〈u′γ(s), θ̃1〉 = ‖u′γ(s)‖2〈γ′(s), θ̃1〉 ≤ λ0〈γ′(s), θ̃1〉,\nwhere the last inequality holds because 〈γ′(s), θ̃1〉 ≤ 0. Plugging this into (7), we get the desired\ncos(θ̃1, θ̂2) ≤ 1 + λ0 ∫ l\n0 〈γ′(s), θ̃1〉ds = 1 + λ0 〈∫ l 0 γ′(s)ds, θ̃1 〉 = 1− λ0〈w(1) − w(2), θ̃1〉 .\nReordering and combining with (6) we obtain\n〈w(1) − w(2), θ̃1〉 ≤ 1 λ0\n( 1− cos(θ̃1, θ̂2) ) ≤ 1 λ0 (1− cos(θ1, θ2)) ≤ 1 2λ0 ‖θ1 − θ2‖22 ‖θ1‖2‖θ2‖2 .\nMultiplying both sides by ‖θ1‖2 gives (4), thus, finishing the proof.\nExample 3.5. The smallest principal curvature of some common convex bodies are as follows:\n• The smallest principal curvature λ0 of the Euclidean ball W = {w | ‖w‖2 ≤ r} of radius r satisfies λ0 = 1r .\n• Let Q be a positive definite matrix. If W = { w |w>Qw ≤ 1 } then λ0 = λmin/ √ λmax, where λmin and\nλmax are the minimal, respectively, maximal eigenvalues of Q. (Polovinkin 1996 also derived this result for the strong convexity definition (ii) in Proposition A.1.)\n• In general, let φ : Rd → R be a C2 convex function. Then, for W = {w |φ(w) ≤ 1}, λ0 = minw∈bd(W) minv : ‖v‖2=1,v⊥φ′(w) v>∇2φ(w)v ‖φ′(w)‖2 .\n5γ′ and u′γ denote the derivatives of γ and u, respectively, which exist since W is C2.\nWe only prove the last statement, since it implies the other two.\nProof. Fix w ∈ bd(W). Note that φ′(w) is a normal vector at w for bd(W), thus TwW = {v : v ⊥ φ′(w)}. Then the Gauss map uW of W satisfies uW(w) = φ ′(w) ‖φ′(w)‖2 for w ∈ bd(W).\nNext we compute the Weingarten map Ww(v) : TwW → TwW, which, by definition, is the differential of uW(w) restricted to TwW. Note that the Weingarten map is a linear map.\nWw(v) = d uW d w ∣∣∣∣ TwW (v) = ∇ 2(w)v ‖φ′(w)‖2 − φ ′(w)∇2φ(w)φ′(w)T v ‖φ′(w)‖32 = ∇ 2(w)v ‖φ′(w)‖2 .\nBy (Schneider, 2014, page 105), the principal curvature of W at w are the eigenvalues of the Weingarten map Ww(v). Therefore, the smallest principal curvature at w is minv : ‖v‖2=1,v⊥φ′(w) v>∇2φ(w)v ‖φ′(w)‖2 . Taking minimum over all w ∈ bd(W) finishes the proof.\nO D = w∗\nA = −µt\nB B̃\nÃ = ŵt\nC\nA′\nÃ′\n= −µ\nFigure 2: Illustration of how curvature helps to keep the regret small.\nIn the stochastic i.i.d. case, when E [Θt] = −µ, we have ‖Θt + µ‖2 = O(1/ √ t) with high probability. Thus say, for W being the unit ball of Rd, one has wt = Θt/ ‖Θt‖2; therefore, a crude bound suggests that ‖wt − w∗‖2 = O(1/ √ t), overall predicting that\nE [Rn] = O( √ n), while the previous result predicts that Rn is much smaller. In the next example we look at the unit ball, to explain geometrically, what “causes” the smaller regret.\nExample 3.6. Let W = {w | ‖w‖2 ≤ 1} and consider a stochastic setting where the fi are i.i.d. samples from some underlying distribution with expectation E [fi] = µ = (−1, 0, . . . , 0) and ‖fi‖∞ ≤M . It is straightforward to see that w∗ = (1, 0, . . . , 0), and thus 〈w∗, µ〉 = −1. Let E = {−θ | ‖θ − µ‖2 ≤ }. As suggested beforehand, we expect −µt ∈ E with high probability. As shown in Fig. 2, the excess loss of an estimate # »OA is 〈 # » OÃ, # »\nOD〉 − 1 = |B̃D|. Similarly, the excess loss of an estimate # »\nOA′ in the figure is |CD|. Therefore, for an estimate −µt ∈ E, the point A is where the largest excess loss is incurred. The triangle OAD is similar to the triangle ADB. Thus |BD||AD| = |AD| |OD| . Therefore, |BD| = 2 and since |B̃D| ≤ |BD|, if ‖µt − µ‖2 ≤ , the excess error is at most 2 = O(1/t), making the regret Rn = O(logn).\nOur last result in this section is an asymptotic lower bound for the linear game, showing that FTL achieves the optimal rate under the condition that mint ‖Θt‖2 ≥ L > 0.\nTheorem 3.7. Let λ, L ∈ (0, 1). Assume that {(1,−L), (−1,−L)} ⊂ F and let\nW = { (x, y) ∈ R2 : x2 + y 2 λ2 ≤ 1 }\nbe an ellipsoid with principal curvature h. Then, for any learning strategy, there exists a sequence of losses in F such that Rn = Ω (log(n)/(Lh)) and ‖Θt‖2 ≥ L for all t.\nNote that by Example 3.5, the minimal principal curvature of W in the above theorem is λ. In fact, it is not too hard to extend the above argument for any set W such that there is w ∈ bd(W) where the curvature is h, and the curvature is a continuous function in a neighborhood of w over the boundary bd(W). The constants in the bound then depend on how fast the curvature changes within this neighborhood.\nProof. We define a random loss sequence, and we will show that no algorithm on this sequence can achieve an o(logn/(λ0L) regret. Let P be a random variable with Beta(K,K) distribution for some K > 0,\nand, given P , assume that Xt, t ≥ 1 are i.i.d. Bernoulli random variables with parameter P . Let ft = Xt(1,−L) + (1 − Xt)(−1,−L) = (2Xt − 1,−L). Thus, the second coordinate of ft is always −L, and so ‖Θt‖2 = ∥∥∥ 1t ∑ti=1 fi∥∥∥2 ≥ L. Furthermore, the conditional expectation of the loss vector is fp 4= E [ft|P = p] = (2p− 1,−L).\nNote that Xt is a function of ft for all t; thus the conditional expectation of P , given f1, . . . , ft−1, can be determined by the well-known formula P̂t−1 = E [P | f1 . . . ft−1] = K+ ∑t−1 i=1 Xi\n2K+t−1 . Given p, denote the optimizer of fp by wp, that is, wp = argminw∈W 〈w, fp〉. Then the Bayesian optimal choice in round t is\nargmin w∈W\nE [ [ 〈 w, fP 〉∣∣ f1 . . . ft−1] = argmin w∈W 〈 w,E [ fP ∣∣ f1 . . . ft−1]〉\n= argmin w∈W\n〈 w, f P̂t−1 〉 = wP̂t−1 , (8)\nwhere the first equality follows by linearity of the inner product, the second since fp is a linear function of p and the third by the definition of wp.\nThus, denoting by Wt the prediction of an arbitrary algorithm in round t, the expected regret can be bounded from below as\nE [Rn] = E [\nmax w∈W n∑ t=1 〈Wt − w, ft〉\n] = E [ E [ max w∈W n∑ t=1 〈Wt − w, ft〉 ∣∣∣∣∣P ]]\n≥ E [ E [ n∑ t=1 〈 Wt − wP , ft 〉∣∣∣∣∣P ]] = E [ n∑ t=1 E [〈 Wt − wP , ft 〉∣∣P, f1, . . . , ft−1]]\n= E [\nn∑ t=1 E [〈 Wt − wP , fP 〉∣∣ f1, . . . , ft−1]] (9) ≥ E\n[ n∑ t=1 min w∈W E [〈 w − wP , fP 〉∣∣ f1, . . . , ft−1]]\n= E [\nn∑ t=1 E [〈 wP̂t−1 − wP , fP 〉∣∣∣ f1, . . . , ft−1]] (10) =\nn∑ t=1 E [〈 wP̂t−1 − wP , fP 〉] ,\nwhere (9) holds because of the independence of the fs given P and since Wt is chosen based on f1, . . . , tt−1 (but not on P ), and (10) holds by (8).\nBy Lemma A.4 we have\nn∑ t=1 E [〈 wP̂t−1 − wP , fP 〉] ≥ hL2 n∑ t=1 E  ( 2P̂t−1−2P hL )2 √ 1 + ( 1−2P\nhL )2(1 + ( 1−2P̂t−1hL )2)  (11)\n= 2 hL n∑ t=1 E  1√ 1 + ( 1−2P hL )2E  (P̂t−1 − P )2 1 + ( 1−2P̂t−1 hL )2 ∣∣∣∣∣∣∣P  \n≥ 2 hL n∑ t=1 E  1√ 1 + ( 1−2P hL )2E  (P̂t−1 − P )2 1 + 2 ( 1−2P hL )2 + 2( 2P−2P̂t−1hL )2 ∣∣∣∣∣∣∣P   , (12)\nwhere in the last step we used (a+ b)2 ≤ a2 + b2. Let Gt be the event that |P̂t − P | ≤ K|1−2P |2K+t + thL\n2K+t ; note that Gt holds with high probability by Lemma A.2. Then, lower bounding the first term by 0, (12) can be lower bounded by\n2 hL n−1∑ t=1 E  1√ 1 + ( 1−2P hL )2E  (P̂t − P )2 1 + 2 ( 1−2P hL )2 + 2( 2P−2P̂thL )2 I(Gt) ∣∣∣∣∣∣∣P  \n≥ 2 hL n−1∑ t=1 E  1√ 1 + ( 1−2P hL )2 E [ (P̂t − P )2I(Gt) ∣∣∣P]( 1 + 2 ( 1−2P\nhL )2 + 2( 2K2K+t |1−2P |hL + 2t2K+t)2) \n≥ 2 hL n−1∑ t=1 E  1√ 1 + ( 1−2P hL )2 E [ (P̂t − P )2I(Gt) ∣∣∣P]( 9 + 4 ( 1−2P hL )2 + 8 |1−2P |hL )  .\nCombining the above, and using (P̂t−P )2 ≤ 1 together with the upper bound on the probability of the event Gct , the complement of Gt, given in Lemma A.2, we get\nE [Rn] ≥ 2 hL n−1∑ t=1 E  1√ 1 + ( 1−2P hL )2 E [ (P̂t − P )2 ∣∣∣P]− P [Gct ]( 9 + 4 ( 1−2P hL )2 + 8 |1−2P |hL ) \n≥ 2 hL n−1∑ t=1\nE  1√\n1 + ( 1−2P\nhL\n)2 E [ (P̂t − P )2 ∣∣∣P]( 9 + 4 ( 1−2P\nhL )2 + 8 |1−2P |hL ) − e−(t−1)h2L2  ≥ 2 hL n−1∑ t=1 E  1√ 1 + ( 1−2P hL )2 E [ (P̂t − P )2 ∣∣∣P]( 9 + 4 ( 1−2P hL )2 + 8 |1−2P |hL )  − 1 1− e−h2L2\n . (13) Now, by Lemma A.3, we have\nE [ (P̂t − P )2 ∣∣∣P] = K2(1− 2P )2(2K + t)2 + tP (1− P )(2K + t)2 ≥ P (1− P ) ( 1 t − 2 t(2K + t) ) .\nCombining this with (13) and introducing the constant\nC = E  1√ 1 + ( 1−2P hL )2 P (1− P )(9 + 4 ( 1−2PhL )2 + 8 |1−2P |hL ) \nwe obtain, for any K > 0,\nlim inf n→∞ E [Rn] logn ≥ lim infn→∞ 2 hL logn\n[ − 1\n1− e−h2L2 + n−1∑ t=1 C ( 1 t − 2 t(2K + t) )] = 2C hL . (14)\nIt remains to calculate a constant lower bound for C that is independent of h and L. Denote |1−2P |hL by Y ; then 0 ≤ P (1 − P ) = 1−Y 2h2L2\n4 ≤ 1/4. Define Ĝ to be the event when |Y | ≤ 1. Since P has Beta(K,K) distribution, E [P ] = 12 and Var(P ) = 1 8K . Therefore, by Chebyshev’s inequality,\nP [ Ĝc ] = P [∣∣∣∣P − 12 ∣∣∣∣ > hL2 ] ≤ 12Kh2L2 .\nTherefore,\nC = E [\n1√ 1 + Y 2 1− Y 2h2L2 4(9 + 4Y 2 + 8Y )\n] ≥ E [ 1√\n1 + Y 2 1− Y 2h2L2 4(9 + 4Y 2 + 8Y ) I(Ĝ) ]\n≥ 1 84 √ 2 E [ (1− Y 2h2L2)I(Ĝ) ] ≥ 1 84 √ 2 ( E [ 1− Y 2h2L2 ] − P [ Ĝc ])\n≥ 1 84 √ 2\n( 1− E [ (1− 2P )2 ] − 12Kh2L2 ) = 1 84 √ 2 ( 1 2 − h2L2 2 ) .\nTherefore,\nlim inf n→∞ E [Rn] logn ≥ 1 84 √ 2 ( 1 hL − hL ) ≥ 1 84 √ 2 ( 1 hL − 1 ) .\nThe result is completed by noting that the worst-case regret is at least as big as the expected regret, thus, for every n, there exist a P and a sequence of loss vectors f1, . . . , fn such that the regret Rn is at least Ω( lognhL )."
    }, {
      "heading" : "3.2 Other regularities",
      "text" : "So far we have looked at the case when FTL achieves a low regret due to the curvature of bd(W). The next result characterizes the regret of FTL when W is a polytope, which has a flat, non-smooth boundary and thus Theorem 3.3 is not applicable. For this statement recall that given some norm ‖ · ‖, its dual norm is defined by ‖w‖∗ = sup‖v‖≤1〈v, w〉.\nTheorem 3.8. Assume that W is a polytope and that Φ is differentiable at Θi, i = 1, . . . , n. Let wt = argmaxw∈W〈w,Θt−1〉, W = supw1,w2∈W ‖w1 − w2‖∗ and F = supf1,f2∈F ‖f1 − f2‖. Then the regret of FTL is\nRn ≤W n∑ t=1 t I(wt+1 6= wt)‖Θt −Θt−1‖ ≤ FW n∑ t=1 I(wt+1 6= wt) .\nNote that when W is a polytope, wt is expected to “snap” to some vertex of W. Hence, we expect the regret bound to be non-vacuous, if, e.g., Θt “stabilizes” around some value. Some examples after the proof will illustrate this.\nProof. Let v=argmaxw∈W〈w, θ〉, v′=argmaxw∈W〈w, θ′〉. Similarly to the proof of Theorem 3.3,\n〈v′ − v, θ′〉 = 〈v′, θ′〉 − 〈v′, θ〉+ 〈v′, θ〉 − 〈v, θ〉+ 〈v, θ〉 − 〈v, θ′〉 ≤ 〈v′, θ′〉 − 〈v′, θ〉+ 〈v, θ〉 − 〈v, θ′〉 = 〈v′ − v, θ′ − θ〉 ≤W I(v′ 6= v)‖θ′ − θ‖,\nwhere the first inequality holds because 〈v′, θ〉 ≤ 〈v, θ〉. Therefore, by Eq. (5),\nRn = n∑ t=1 t 〈wt+1 − wt,Θt〉 ≤W n∑ t=1 t I(wt+1 6=wt)‖Θt −Θt−1‖ ≤ FW n∑ t=1 I(wt+1 6=wt) .\nAs noted before, sinceW is a polytope, wt is (generally) attained at the vertices. In this case, the epigraph of Φ is a polyhedral cone. Then, the event when wt+1 6= wt, i.e., when the “leader” switches corresponds to when Θt and Θt−1 belong to different linear regions corresponding to different linear pieces of the graph of Φ.\nWe now spell out a corollary for the stochastic setting. In particular, in this case FTL will often enjoy a constant regret:\nCorollary 3.9 (Stochastic setting). Assume that W is a polytope and that (ft)1≤t≤n is an i.i.d. sequence of random variables such that E [fi] = µ and ‖fi‖∞ ≤ M . Let W = supw1,w2∈W ‖w1 − w2‖1. Further assume that there exists a constant r > 0 such that Φ is differentiable for any ν such that ‖ν − µ‖∞ ≤ r. Then,\nE [Rn] ≤ 2MW (1 + 4dM2/r2) .\nThe condition on Φ means that r can be selected to be the radius of the largest ball such that the optimal decisions for expected losses µ and ν (i.e., the maximizers defining Φ(−µ) and Φ(−ν)) belong to the same face of W.\nProof. Let V = {ν | ‖ν − µ‖∞ ≤ r}. Note that the epigraph of the function Φ is a polyhedral cone. Since Φ is differentiable in the interior of V , {(θ,Φ(θ)) | θ ∈ V } is a subset of a linear subspace. Therefore, for −Θt,−Θt−1 ∈ V , wt+1 = wt. Hence, by Theorem 3.8,\nE [Rn] ≤ 2MW n∑ t=1\nP [−Θt,−Θt−1 /∈ V ] ≤ 4MW (\n1 + n∑ t=1\nP [−Θt /∈ V ] ) .\nOn the other hand, note that ‖fi‖∞ ≤M . Then\nP [−Θt /∈ V ] = P [∥∥∥∥∥1t t∑ i=1 fi − µ ∥∥∥∥∥ ∞ ≥ r ] ≤ d∑ j=1 P [∣∣∣∣∣1t t∑ i=1 fi,j − µj ∣∣∣∣∣ ≥ r ] ≤ 2de− tr2 2M2 ,\nwhere the last inequality is due to Hoeffding’s inequality. Now, using that for α > 0, ∑n t=1 exp(−αt) ≤∫ n\n0 exp(−αt)dt ≤ 1 α , we get E [Rn] ≤ 2MW (1 + 4dM 2/r2).\nThe condition that Φ is differentiable for any ν such that ‖ν − µ‖∞ ≤ r is equivalent to that Φ is differentiable at µ. By Proposition 2.1, this condition requires that at µ, maxw∈W〈w, θ〉 has a unique optimizer. Note that the volume of the set of vectors θ with multiple optimizers is zero."
    }, {
      "heading" : "4 Adaptive algorithm for the linear game",
      "text" : "While as shown in Theorem 3.3, FTL can exploit the curvature of the surface of the constraint set to achieve O(logn) regret, it requires the curvature condition and mint ‖Θt‖2 ≥ L being bounded away from zero, or it may suffer even linear regret. On the other hand, many algorithms, such as the \"Follow the regularized leader\" (FTRL) algorithm (see,e.g., Shalev-Shwartz, 2012), are known to achieve a regret guarantee of O( √ n) even for the worst-case data in the linear setting. This raises the question whether one can have an algorithm that can achieve constant or O(logn) regret in the respective settings of Corollary 3.9 or Theorem 3.3, while it still maintains O( √ n) regret for worst-case data. One way to design an adaptive algorithm is to use the (A, B)-prod algorithm of Sani et al. (2014), trivially leading to the following result:\nProposition 4.1. Consider (A, B)-prod of Sani et al. (2014), where algorithm A is chosen to be FTRL with an appropriate regularization term, while B is chosen to be FTL. Then the regret of the resulting hybrid algorithm H enjoys the following guarantees:\n• If FTL achieves constant regret as in the setting of Corollary 3.9, then the regret of H is also constant. • If FTL achieves a regret of O(logn) as in the setting of Theorem 3.3, then the regret of H is also O(logn). • Otherwise, the regret of H is at most O( √ n logn).\nIn the next section we show that if the constraint set is the unit ball, it is possible to design adaptive algorithms directly.\nAlgorithm 1 Follow The Shrunken Leader (FTSL 1: Predict w1 = 0; 2: for t = 2, ..., n− 1 do 3: FTL: Compute w̃t = argminw∈W 〈w,Ft−1〉 4: Shrinkage: Predict wt = ‖Ft−1‖2√‖Ft−1‖22+t+2 w̃t\n5: end for 6: FTL: Compute w̃n = argminw∈W 〈w,Fn−1〉 7: Shrinkage: Predict wn = ‖Fn−1‖2√‖Fn−1‖22+n w̃n"
    }, {
      "heading" : "4.1 Adaptive Algorithms for the Unit Ball Constraint Set",
      "text" : "In this section we provide some interesting results about adaptive algorithms for the case when W is the unit ball in Rd (naturally, the results easily generalize to any ball centered at the origin). First, we show that a variant of FTL using shrinkage as regularization has O(log(n)) regret when ‖Θt‖2 ≥ L > 0 for all t, but it also has O( √ n) worst case guarantee. Furthermore, we show that the standard FTRL algorithm is adaptive if the constraint set is the unit ball and the loss vectors are stochastic. Throughout the section we will use the notation Ft = −(t− 1)Θt = ∑t−1 i=1 fi."
    }, {
      "heading" : "4.1.1 Follow the Shrunken Leader",
      "text" : "In this section we are going to analyze a combination of the FTL algorithm and the idea of shrinkage often used for regularization purposes in statistics. We assume that W = { x ∈ Rd | ‖x‖2 ≤ 1 } is the unit ball and, without loss of generality, we further assume that ‖f‖2 ≤ 1 for all f ∈ F .\nTheorem 4.2. The Follow The Shrunken Leader (FTSL) algorithm is given in Algorithm 1. The main idea of the algorithm is to predict a shrunken version of the FTL prediction, in this way keeping it away from the boundary of W. The next theorem shows that the right amount of shrinkage leads to a robust, adaptive algorithm:\n• If there exists L such that ‖Θt‖2 ≥ L > 0 for 1 ≤ t ≤ n, then the regret of FTSL is O(log(n)/L). • Otherwise, the regret of FTSL is at most O( √ n).\nProof. By the definition of Ft and W, w̃t = −Ft−1/‖Ft−1‖2. Let σn = ‖Fn−1‖2√‖Fn−1‖22+n . Our proof follows the idea of Abernethy et al. (2008). We compute the upper bound on the value of the game for each round backwards for t = n, n− 1, . . . , 1, by solving the optimal strategies for ft. The value of the game using FTSL is defined as\nVn = max f1,...,fn n∑ t=1 〈wt, ft〉 − min w∈W 〈w,Fn〉\n= max f1,...,fn−1 n−1∑ t=1 〈wt, ft〉+ max fn ‖Fn−1 + fn‖2 + 〈fn, wn〉︸ ︷︷ ︸\n=:Un We first prove that Un, the second term above, is bounded from above by √ ‖Fn−1‖22 + n. To see this, let fn = anF̃n−1 + bnΩn−1 where F̃n−1 is the unit vector parallel to Fn−1 and Ωn−1 is a unit vector orthogonal\nto Fn−1. Furthermore, since ‖fn‖2 ≤ 1, we have a2n + b2n ≤ 1. Thus,\nUn = max fn\n√ ‖Fn−1‖22 + 2an‖Fn−1‖2 + a2n + b2n − anσn\n≤ max a\n√ ‖Fn−1‖22 + 2a‖Fn−1‖2 + n− aσn\n= √ ‖Fn−1‖22 + n,\nwhere the last equality follows since the maximum is attained at a = 0. A similar statement holds for the other time indices: for any t ≥ 1,\nmax ft\n√ ‖Ft−1 + ft‖22 + t+ 1 + 〈ft, wt〉 ≤ √ ‖Ft−1‖22 + t+\n1√ t . (15)\nBefore proving this inequality, let us see how it implies the second statement of the theorem:\nVn ≤ max f1,...,fn−1 n−1∑ t=1 〈wt, ft〉+ √ ‖Fn−1‖22 + n\n≤ max f1,...,fn−2 n−2∑ t=1 〈wt, ft〉+ √ ‖Fn−2‖22 + n− 1 + 1√ n\n≤ . . .\n≤ 1 + n∑ t=1 1√ t = O( √ n).\nMoreover, if ‖Θt‖2 ≥ L for 1 ≤ t ≤ n, a stronger version of (15) also holds:\nmax ft\n√ ‖Ft−1 + ft‖22 + t+ 1 + 〈ft, wt〉 ≤ √ ‖Ft−1‖22 + t+\n1 (t− 1)L. (16)\nThis implies the first statement of the theorem, since\nVn ≤ max f1,...,fn−1 n−1∑ t=1 〈wt, ft〉+ √ ‖Fn−1‖22 + n\n≤ max f1,...,fn−2 n−2∑ t=1 〈wt, ft〉+ √ ‖Fn−2‖22 + n− 1 + 1 (n− 1)L\n≤ . . . ≤ 1 + n−1∑ t=1 1 tL = O(log(n)/L).\nTo finish the proof, it remains to show (15) and (16). Let ft = atF̃t−1 + btΩt−1 where F̃t−1 is the unit vector parallel to Ft−1 and Ωt−1 is a unit vector orthogonal to Ft−1. Since ‖ft‖2 ≤ 1, observe that\na2t + b2t = ‖ft‖2 ≤ 1. Furthermore, let σt = ‖Ft−1‖2√ ‖Ft−1‖22+t+2 . Then, for any t ≥ 1,\n∆t = max ft\n√ ‖Ft−1‖22 + 2at‖Ft−1‖2 + a2t + b2t + t+ 1− atσt − √ ‖Ft−1‖22 + t\n≤ max at\n√ ‖Ft−1‖22 + 2at‖Ft−1‖2 + t+ 2− atσt − √ ‖Ft−1‖22 + t\n= √ ‖Ft−1‖22 + t+ 2− √ ‖Ft−1‖22 + t = 2√ ‖Ft−1‖22 + t+ 2 + √ ‖Ft−1‖22 + t\n(17)\n≤ 1√ t .\nThis proves (15). Moreover, if ‖Ft−1‖2 = ‖(t− 1)Θ‖2 ≥ (t− 1)L, by (17) we obtain\n∆t ≤ 2√ ‖Ft−1‖22 + t+ 2 + √ ‖Ft−1‖22 + t ≤ 1 ‖Ft−1‖2 ≤ 1(t− 1)L,\nproving (16)."
    }, {
      "heading" : "4.1.2 FTRL for the case of the unit ball constraint set",
      "text" : "This section is to show that in the case when W is the unit ball in `2 norm, FTRL with R(w) = 12‖w‖ 2 as its regularization is an adaptive algorithm. To fix the notation, in round t, FTLR predicts\nwt = argmin w∈W ηt〈Ft−1, w〉+R(w),\nif t > 1 and w1 = 0. It has been well known that FTRL with ηt = 1/ √ t− 1 is guaranteed to achieve O( √ n) regret in the adversarial setting, see, e.g., (Shalev-Shwartz, 2012). It remains to prove that FTRL indeed achieves a fast rate in the stochastic setting.\nTheorem 4.3. Assume that the sequence of loss vectors, f1, . . . , fn ∈ Rd satisfies ‖ft‖2 ≤ 1 almost surely and E [ft] = µ for all t with some ‖µ‖2 > 0. Then FTRL with ηt = 1/ √ t− 1 suffers O(logn) regret .\nProof. Using R(w) = 12‖w‖ 2 as its regularization, in round t > 1 FTRL predicts\nwt = argmin w∈W\nηt〈Ft−1, w〉+R(w) = { 1√ t−1Ft−1 if ‖Ft−1‖ ≤ √ t− 1\nFt−1 ‖Ft−1‖ otherwise.\n(18)\nFor any 1 ≤ t ≤ n, denote the event ‖Ft‖ ≥ √ t by Et. Note that if ‖Ft−1‖ ≥ √ t− 1, FTRL predicts exactly the same wt as FTL. Denote the accumulate loss of FTL in n rounds by LFTLn . Thus, the regret of FTRL is\nE [Rn] = E [\nn∑ t=1 〈ft, wt〉 − min w∈W 〈ft, w〉\n]\n= E [\nn∑ t=1 〈ft, wt〉 − LFTLn\n] + E [ LFTLn − min\nw∈W 〈ft, w〉\n]\n≤ 2 n∑ t=1 P [Ect ] +O(logn),\nwhere, to obtain the last inequality, we applied (18) for the first term, while the second term is O(logn) by the discussion following Theorem 3.3. It remains to bound the first term, 2 ∑n t=1 P [Ect ] in the above. For any t > 4‖µ‖22 ,\nP [ ‖Ft‖2 ≤ √ t ] ≤ P [ ‖Ft‖2 < t 2‖µ‖2 ] ≤ d∑ i=1 P [ |Ft,i| < t 2 |µi| ]\n≤ d∑ i=1 P [ |Ft,i − tµi| > t 2 |µi| ] ≤ 2 d∑ i=1 e− µ2 i 4 t\nThus,\nn∑ t=1 P [Ect ] = 4/‖µ‖22∑ t=1 P [Ect ] + n∑\nt=4/‖µ‖22\nP [Ect ]\n≤ 4 ‖µ‖22 + 2 d∑ i=1 n∑ t=0 e− µ2 i 4 t\n≤ 4 ‖µ‖22 + 2 d∑ i=1\n1\n1− e− µ2 i 4\n≤ 4 ‖µ‖22 + 2 d∑ i=1 µ2i 4 = 4 ‖µ‖22 + ‖µ‖ 2 2 2 .\nwhere in the last inequality we used 1/(1− e−a) ≤ a. Therefore, if ‖µ‖ > 0, the regret of FTRL satisfies\nE [Rn] ≤ 8 ‖µ‖22 + ‖µ‖22 +O(logn) = O(logn)."
    }, {
      "heading" : "5 Simulations",
      "text" : "We performed three simulations to illustrate the differences between FTL, FTRL with the regularizer R(w) = 12 ‖w‖ 2 2 when wt = argminw∈W ∑t−1 i=1〈fi−1, w〉+R(w), and the adaptive algorithm (A, B)-prod (AB) using FTL and FTRL as its candidates, which we shall call AB(FTL,FTRL). For the experiments the constraint setW was chosen to be a slightly elongated ellipsoid in the 4-dimensional Euclidean space, with volume matching that of the 4-dimensional unit ball. The actual ellipsoid is given by W = { w ∈ R4 |w>Qw ≤ 1 } where Q is randomly generated as\nQ =  4.3367 3.6346 −2.2250 3.5628 3.6346 3.9966 −2.3613 3.2817 −2.2250 −2.3613 2.0589 −2.1295 3.5628 3.2817 −2.1295 3.4206  . We experimented with 3 types of data to illustrate the behavior of the different algorithms: stochastic, “half-adversarial”, and “worst-case” data (worst-case for FTL), as will be explained below. The first two datasets are random, so the experiments were repeated 100 times, and we report the average regret with its standard deviation; the worst case data is deterministic, so there no repetition was needed. For each experiment, we set n = 2500. The regularization coefficient for the FTRL, and the learning rate for AB were chosen based on their theoretical bounds minimizing the worst-case regret.\nStochastic data. In this setting we used the following model to generate ft: Let (f̂t)t be an i.i.d. sequence drawn from the 4-dimensional standard normal distribution, and let f̃t = f̂t/ ∥∥∥f̂t∥∥∥ 2 . Then, ft is defined as\nft = f̃t + Le1 where e1 = (1, 0, . . . , 0)>. Therefore, E [∥∥∥ 1t ∑ts=1 fs∥∥∥2]→ L as t→∞. In the experiments we picked L ∈ {0, 0.1}. The results are shown in Fig. 3. On the left-hand side we plotted the regret against the logarithm of the number of rounds, while on the right-hand side we plotted the regret against the square root of the number of rounds, together with the standard deviation of the results over the 100 independent runs. As can be seen from the figures, when L = 0.1, the growth-rate of the regret of FTL is indeed logarithmic, while when L = 0, the growth-rate is Θ( √ n). In particular, when L = 0.1, FTL enjoys a major advantage compared to FTRL, while for L = 0, FTL and FTRL perform essentially the same (in this special case, the regret of FTL will indeed be O( √ n) as wt will stay bounded but ‖Θt‖ = O(1/ √ t)). As expected, AB(FTL,FTRL), gets the better of the two regrets with little to no extra penalty.\n“Half-adversarial” data The half-adversarial data used in this experiment is the optimal solution for the adversary in the linear game when W is the unit ball (Abernethy et al., 2008). This data is generated as follows: The sequence f̂t for t = 1, . . . , n is generated randomly in the (d − 1)-dimensional subspace S = span{e2, . . . , ed} (here ei is the ith unit vector in Rd) as follows: f̂1 is drawn from the uniform distribution on the unit sphere of S (actually Sd−2. For t = 2, . . . , n, f̂t is drawn from the uniform distribution on the unit sphere of the intersection of S and the hyperplane perpendicular to ∑t−1 i=1 f̂i and going through the origin.\nThen, ft = Le1 + √\n1− L2f̂t for some L ≥ 0. The results are reported in Fig. 4. When L = 0, the regret of both FTL and FTRL grows as O( √ n). When L = 0.1, FTL achieves O(logn) regret, while the regret of FTRL appears to be O( √ n). AB(FTL,FTRL) closely matches the regret of FTL.\nWorst-case data We also tested the algorithms on data where FTL is known to suffer linear regret, mainly to see how well AB(FTL,FTRL) is able to deal with this setting. In this case, we set ft,i = 0 for all t and i ≥ 2, while for the first coordinate, f1,1 = 0.9, and ft,1 = 2(t mod 2)− 1 for t ≥ 2.\nThe results are reported in Fig. 5. It can be seen that the regret of FTL is linear (as one can easily verify theoretically), and AB(FTL,FTRL) succeeds to adapt to FTRL, and they both achieve a much smaller\nO( √ n) regret.\nThe unit ball We close this section by comparing the performance of our adaptive algorithms on the unit ball, namely, FTL, FTSL, FTLR, and AB(FTL,FTRL). All these algorithms are parametrized as above. The problem setup is similar to the stochastic data setting and the worst-case data setting. Again, we consider a 4-dimensional setting, that is, W is the unit ball in R4 centered at the origin. The worst-case data is generated exactly as above, while the generation process of the stochastic data is slightly modified to increase the difference between FTLR and FTL: we sample the i.i.d. vectors f̂t from a zero-mean normal distribution with independent components whose variance is 1/16, and let f̃t = f̂t if ‖f̂t‖2 ≤ 1 and f̃t = f̂t/\n∥∥∥f̂t∥∥∥ 2 when∥∥∥f̂t∥∥∥\n2 > 1 (i.e., we only normalize if f̂t falls outside of the unit ball). The reason of this modification is to\nencourage the occurrence of the event ‖Ft−1‖2 < √ t− 1. Recall that when ‖Ft−1‖2 ≥ √ t− 1, the prediction of FTRL matches that of FTL, so we are trying to create some data where their behavior is actually different.\nAs a result, we will be able to observe that the predictions of FTL and FTRL are different in the early rounds. Finally, as before, we let ft = f̃t + Le1, and set the time horizon to n = 20, 000.\nThe results of the simulation of the stochastic data setting are shown in Figure 6. In the case of L = 0.1, FTRL suffers more regret at the beginning for some rounds, but then succeeds to match the performance of FTL. The results of the simulation of the worst-case data setting are shown in Figure 7, where FTSL has similar performance as FTRL."
    }, {
      "heading" : "6 Conclusion",
      "text" : "FTL is a simple method that is known to perform well in many settings, while existing worst-case results fail to explain its good performance. While taking a thorough look at why and when FTL can be expected to achieve small regret, we discovered that the curvature of the boundary of the constraint and having average loss vectors bounded away from zero help keep the regret of FTL small. These conditions are significantly different from previous conditions on the curvature of the loss functions which have been considered extensively in the literature. It would be interesting to further investigate this phenomenon for other algorithms or in other learning settings."
    }, {
      "heading" : "A Appendix: Technical results",
      "text" : "A.1 Strongly convex sets and principal curvatures Recall that a convex set W ⊂ Rd is λ-strongly convex if for any x, y ∈ W, γ ∈ [0, 1], W contains the ball of center γx + (1 − γ)y that has a radius of γ(1 − γ)λ2 ‖x− y‖\n2. That is, for any z ∈ Rd with ‖z‖ = 1, γx+ (1− γ)y + γ(1− γ)λ2 ‖x− y‖ 2 z ∈ W. Let Br(x) = { y ∈ Rd | ‖x− y‖2 ≤ r } denote the Euclidean ball of radius r centered at x.\nProposition A.1. Let W ⊂ Rd be a C2 convex body with support function ϕ, and let λ be an arbitrary positive number. Then the following statements are equivalent:\n(i) The smallest principal curvature of W is at least λ.\n(ii) W = ∩θ∈Sd−1B1/λ(wθ − θ/λ) where wθ ∈ ∂ϕ(θ) ⊂ bd(W).\n(iii) W is λ-strongly convex.\nCondition (ii), which is actually the definition of Polovinkin (1996) for strongly convex sets, means that W can be obtained as the intersection of closed balls of radius 1/λ, such that there is one ball for every boundary point w and tangent hyperplane P where the ball touches P in w. Note that a ball with radius 1/λ satisfies all conditions: (i) and (ii) by definition, while (iii) holds, e.g., by Example 13 of Journée et al. (2010).\nProof. We show that (i) implies (ii), (ii) implies (iii), and (iii) implies (i). We start with showing that (i) implies (ii). First note that all principal curvatures of the d-dimensional ball B = B1/λ(0) with radius 1/λ (centered at the origin) are λ. Therefore, (i) and Theorem 3.2.9 of Schneider (2014) implies that there is a convex body M such that W +M = B, where for two sets, S1, S2 ⊂ Rd, S1 +S2 is defined as {s1 + s2 | s1 ∈ S1, s2 ∈ S2}. For any θ ∈ Sd−1, let mθ ∈ argmaxm∈M〈m, θ〉. Then clearly wθ +mθ maximizes 〈b, θ〉 for b ∈ W +M. Therefore, W +mθ is a subset of B and touches it at wθ +mθ, or equivalently W ⊂ B −mθ and they touch each other, and a tangent hyperplane with normal vector θ, in wθ. This proves that (i) implies (ii).\nNext we prove that (ii) implies (iii). Assuming (ii) holds, let w ∈ W be any point in the interior of W, and let p ∈ bd(W) be the closest boundary point to w, and recall that TpW is the tangent space of W at p. By construction, B‖w−p‖2(w) touches the boundary of W at p (in the sense that they do not intersect, but they can have multiple common points), and so w − p is orthogonal to TpW. Therefore, B‖w−p‖2(w) also touches the boundary of the ball B = B1/λ(p+ w−pλ‖w−p‖2 ), which contains W by assumption (ii). Now consider any two points x, y ∈ W and γ ∈ [0, 1] such that w = γx + (1 − γ)y. Then the ball with radius λγ(1− γ)‖x− y‖22/2 centered at w is contained in B, since B is λ-strongly convex. But then its radius is at most ‖p− w‖2, and so it is also contained in W. This shows that W is λ-strongly convex, thus (iii) holds.\nTo finish the proof of the proposition, assume (iii). To prove that (i) holds, we have to show, that for any point p on bd(W) and for any unit vector v ∈ TpW, the curvature of the boundary along v is at least λ. Let P be the hyperplane spanned by v and the outer normal vector u of W at point p, and consider the planar curve γ defined by bd(W) ∩ P . Using v as the axis of a local coordinate system, a point w(s) on the\ncurve γ in the neighborhood of p can be expressed as w(s) = p+ sv− f(s)u for an appropriate function f , as illustrated in Fig. 8.\nNote that f ′(0) = 0, and by Proposition 2.1 of Pressley (2010), the curvature of γ at p can be obtained as\nf ′′(s)√ 1 + f ′(s)23 ∣∣∣∣∣ s=0 = f ′′(0) .\nNow since w(s), w(−s) ∈ W for a sufficiently small s, the strong convexity of W applied to w(s) and w(−s) with γ = 1/2 implies that q = w(s)+w(−s)2 + λ 8 ‖w(s) − w(−s)‖ 2 2u ∈ W. Substituting the definition of w(s) and w(−s), we get\nq = p− u [ f(s) + f(−s)\n2 − λ 8\n( 4s2 + (f(s)− f(−s))2 )] .\nTherefore, q ∈ W implies f(s) + f(−s) ≥ λs2, and so\nf ′′(0) = lim s→0\nf(s)−f(0) s − f(0)−f(−s) s\ns = f(s) + f(−s) s2 ≥ λ.\nThus (i) holds, finishing the proof of the proposition.\nA.2 Proof of Proposition 2.1 Under the extra condition that W is compact the result follows from Danskin’s theorem (e.g., Proposition B.25 of Bertsekas 1999). However, compactness is not required. For completeness, we provide a short, direct proof. We need to show that Z = ∂ϕ(Θ) where recall that\n∂ϕ(Θ) = { u ∈ Rd |ϕ(Θ) + 〈u, · −Θ〉 ≤ ϕ(·) } = { u ∈ Rd |ϕ(Θ) ≤ 〈u,Θ〉+ ϕ(·)− 〈u, ·〉 } .\nSince Z ⊂ W, if w ∈ Z, ϕ(Θ′) ≥ 〈w,Θ′〉 for any Θ′ by the definition of ϕ. Hence, ϕ(Θ) = 〈w,Θ〉 ≤ 〈w,Θ〉+ ϕ(Θ′)− 〈w,Θ′〉 for any Θ′, implying that w ∈ ∂ϕ(Θ).\nOn the other hand, assume w ∈ ∂ϕ(Θ). Then ϕ(Θ) ≤ 〈w,Θ〉 since ϕ(0) = 〈w, 0〉 = 0. Since W is closed, Z is also closed. Therefore, if w 6∈ Z, the strict separation theorem (applied to {w}, a convex compact set, and Z, a convex closed set) implies that there exists ρ ∈ Rd such that 〈z, ρ〉 < 〈w, ρ〉 for all z ∈ Z. Let Θ′ = Θ + ρ. Then, ϕ(Θ′) = maxu∈W〈u,Θ〉+ 〈u, ρ〉 < ϕ(Θ) + 〈w,Θ′ −Θ〉 ≤ 〈w,Θ′〉 ≤ ϕ(Θ′), a contradiction. Hence, w ∈ Z.\nA.3 Technical lemmas for the lower bound Theorem 3.7 Lemma A.2 (Concentration of P̂t). For any u > 0,\nP [ |P̂t − P | > K\n2K + t |1− 2P |+ t 2K + tu ∣∣∣∣P] ≤ 2 exp(−tu2) .\nProof. Recall that P̂t = K+ ∑t i=1 Xi 2K+t . Thus,\nP [ |P̂t − P | > u ∣∣∣P] = P[∣∣∣∣∣K + ∑t i=1Xi 2K + t − P ∣∣∣∣∣ > K2K + t |1− 2P |+ t2K + tu ∣∣∣∣∣P ]\n= P [∣∣∣∣∣ t∑ i=1 Xi − Pt+K(1− 2P ) ∣∣∣∣∣ > K|1− 2P |+ tu ∣∣∣∣∣P ]\n≤ P [∣∣∣∣∣ t∑ i=1 Xi − Pt ∣∣∣∣∣ > tu ∣∣∣∣∣P ] , (19)\nwhere the last inequality is due to P [|A+ b| > c] ≤ P [|A| > c− |b|]. Note that conditioned on P , X1, . . . , Xt are independent Bernoulli random variables with expectation P , thus (19) holds by Hoeffding’s inequality (see, e.g., (Cesa-Bianchi and Lugosi, 2006, Corollary A.1)).\nLemma A.3. E [ (P − P̂t)2 ∣∣∣P] = K2(1− 2P )2(2K + t)2 + tP (1− P )(2K + t)2 .\nProof. Recall that P̂t = K+ ∑t i=1 Xi 2K+t .Thus,\nE [ (P − P̂t)2 ∣∣∣P] = E (K(1− 2P ) 2K + t + ∑t i=1Xi − Pt 2K + t )2∣∣∣∣∣∣P \n= K 2(1− 2P )2 (2K + t)2 + 1 (2K + t)2E ( t∑ i=1 Xi − tP )2∣∣∣∣∣∣P \n= K 2(1− 2P )2 (2K + t)2 + tP (1− P ) (2K + t)2 ,\nwhere the second equality is due to E [∑t i=1Xi − Pt ∣∣∣P] = 0, and the last equality is due to that conditioned\non P , ∑t i=1Xi has a Binomial distribution with parameters t and P .\nLemma A.4. Under the assumptions of Theorem 3.7, for any 0 < P1, P2 < 1,\n〈 wP2 − wP1 , fP1 〉 ≥ hL2\n( 2P2−2P1 hL )2√ 1 + ( 1−2P1 hL\n)2 (1 + ( 1−2P2hL )2) . Proof. It is easy to see that for any p, wp is on the boundary of W, that is, wp = argminw∈W 〈w, fp〉 = (cos(ϕp), h sin(ϕp)) for some ϕp. Then 〈wp, fp〉 = (2p− 1) cos(ϕp)− Lh sin(ϕp), and so taking the derivative it is easy to verify that tan(ϕp) = Lh1−2p and sin(ϕ p) = Lh√ (Lh)2+(1−2p)2 > 0. Thus, 1− 2P1 = Lh cos(ϕ P1 ) sin(ϕP1 ) . To\nsimplify notation, let ϕ1 = ϕP1 and ϕ2 = ϕP2 . Then,\n〈wP2 − wP1 , fP1〉 = 〈(\ncosϕ2 − cosϕ1 h (sinϕ2 − sinϕ1)\n) , ( −hL cosϕ1 sinϕ1 −L )〉 = −hL ( (cos(ϕ2)− cos(ϕ1))\ncos(ϕ1) sin(ϕ1)\n+ (sin(ϕ2)− sin(ϕ1)) )\n= −hLsin(ϕ1) ( cos(ϕ2) cos(ϕ1)− cos2(ϕ1) + sin(ϕ1) sin(ϕ2)− sin2(ϕ1) ) = hLsin(ϕ1) (1− cos(ϕ2) cos(ϕ1)− sin(ϕ1) sin(ϕ2))\n= hLsin(ϕ1) (1− cos(ϕ1 − ϕ2))\n= hLsin(ϕ1) ( 1 2 (cos(ϕ1 − ϕ2)− 1) 2 + 12 sin 2(ϕ1 − ϕ2) ) (20)\n≥ hL2 sin(ϕ1) sin2(ϕ1 − ϕ2)\n= hL2 sin(ϕ1) sin 2 ϕ2 (cot(ϕ1)− cot(ϕ2))2 . (21)\nThe proof is finished by substituting cot(ϕi) = 1−2PihL , sin(ϕ1) = 1√\n1+( 1−2P1Lh ) 2 and sin2(ϕ2) = 11+( 1−2P2Lh ) 2 ."
    }, {
      "heading" : "Acknowledgements",
      "text" : "This work was supported in part by the Alberta Innovates Technology Futures through the Alberta Ingenuity Centre for Machine Learning and by NSERC. During part of this work, T. Lattimore was with the Department of Computing Science, University of Alberta."
    } ],
    "references" : [ {
      "title" : "Forced-exploration based algorithms for playing in bandits with large action sets",
      "author" : [ "Y. Abbasi-Yadkori" ],
      "venue" : "Library and Archives Canada,",
      "citeRegEx" : "Abbasi.Yadkori.,? \\Q2010\\E",
      "shortCiteRegEx" : "Abbasi.Yadkori.",
      "year" : 2010
    }, {
      "title" : "Optimal strategies and minimax lower bounds for online convex games",
      "author" : [ "J. Abernethy", "P.L. Bartlett", "A. Rakhlin", "A. Tewari" ],
      "venue" : "In 21st Annual Conference on Learning Theory (COLT),",
      "citeRegEx" : "Abernethy et al\\.,? \\Q2008\\E",
      "shortCiteRegEx" : "Abernethy et al\\.",
      "year" : 2008
    }, {
      "title" : "Adaptive online gradient descent",
      "author" : [ "P.L. Bartlett", "E. Hazan", "A. Rakhlin" ],
      "venue" : "In Advances in Neural Information Processing Systems (NIPS),",
      "citeRegEx" : "Bartlett et al\\.,? \\Q2007\\E",
      "shortCiteRegEx" : "Bartlett et al\\.",
      "year" : 2007
    }, {
      "title" : "Nonlinear Programming",
      "author" : [ "D. Bertsekas" ],
      "venue" : "Athena Scientific,",
      "citeRegEx" : "Bertsekas.,? \\Q1999\\E",
      "shortCiteRegEx" : "Bertsekas.",
      "year" : 1999
    }, {
      "title" : "Prediction, Learning, and Games",
      "author" : [ "N. Cesa-Bianchi", "G. Lugosi" ],
      "venue" : null,
      "citeRegEx" : "Cesa.Bianchi and Lugosi.,? \\Q2006\\E",
      "shortCiteRegEx" : "Cesa.Bianchi and Lugosi.",
      "year" : 2006
    }, {
      "title" : "On the generalization ability of on-line learning algorithms",
      "author" : [ "N. Cesa-Bianchi", "A. Conconi", "C. Gentile" ],
      "venue" : "IEEE Trans. Information Theory,",
      "citeRegEx" : "Cesa.Bianchi et al\\.,? \\Q2004\\E",
      "shortCiteRegEx" : "Cesa.Bianchi et al\\.",
      "year" : 2004
    }, {
      "title" : "Adaptive online learning",
      "author" : [ "D.J. Foster", "A. Rakhlin", "K. Sridharan" ],
      "venue" : "In Advances in Neural Information Processing Systems (NIPS),",
      "citeRegEx" : "Foster et al\\.,? \\Q2015\\E",
      "shortCiteRegEx" : "Foster et al\\.",
      "year" : 2015
    }, {
      "title" : "A decision-theoretic generalization of on-line learning and an application to boosting",
      "author" : [ "Y. Freund", "R. Schapire" ],
      "venue" : "Journal of Computer and System Sciences,",
      "citeRegEx" : "Freund and Schapire.,? \\Q1997\\E",
      "shortCiteRegEx" : "Freund and Schapire.",
      "year" : 1997
    }, {
      "title" : "Stochastic nonstationary optimization for finding universal portfolios",
      "author" : [ "A.A. Gaivoronski", "F. Stella" ],
      "venue" : "Annals of Operations Research,",
      "citeRegEx" : "Gaivoronski and Stella.,? \\Q2000\\E",
      "shortCiteRegEx" : "Gaivoronski and Stella.",
      "year" : 2000
    }, {
      "title" : "Faster rates for the frank-wolfe method over strongly-convex sets",
      "author" : [ "D. Garber", "E. Hazan" ],
      "venue" : "In Proceedings of the 32nd International Conference on Machine Learning (ICML),",
      "citeRegEx" : "Garber and Hazan.,? \\Q2015\\E",
      "shortCiteRegEx" : "Garber and Hazan.",
      "year" : 2015
    }, {
      "title" : "Logarithmic regret algorithms for online convex optimization",
      "author" : [ "E. Hazan", "A. Agarwal", "S. Kale" ],
      "venue" : "Machine Learning,",
      "citeRegEx" : "Hazan et al\\.,? \\Q2007\\E",
      "shortCiteRegEx" : "Hazan et al\\.",
      "year" : 2007
    }, {
      "title" : "Generalized power method for sparse principal component analysis",
      "author" : [ "M. Journée", "Y. Nesterov", "P. Richtárik", "R. Sepulchre" ],
      "venue" : "Journal of Machine Learning Research,",
      "citeRegEx" : "Journée et al\\.,? \\Q2010\\E",
      "shortCiteRegEx" : "Journée et al\\.",
      "year" : 2010
    }, {
      "title" : "Mind the duality gap: Logarithmic regret algorithms for online optimization",
      "author" : [ "S.M. Kakade", "S. Shalev-Shwartz" ],
      "venue" : "In Advances in Neural Information Processing Systems (NIPS),",
      "citeRegEx" : "Kakade and Shalev.Shwartz.,? \\Q2009\\E",
      "shortCiteRegEx" : "Kakade and Shalev.Shwartz.",
      "year" : 2009
    }, {
      "title" : "Minimax strategy for prediction with expert advice under stochastic assumptions",
      "author" : [ "W. Kotłowski" ],
      "venue" : "Algorithmic Learning Theory (ALT),",
      "citeRegEx" : "Kotłowski.,? \\Q2016\\E",
      "shortCiteRegEx" : "Kotłowski.",
      "year" : 2016
    }, {
      "title" : "Constrained minimization methods",
      "author" : [ "E.S. Levitin", "B.T. Polyak" ],
      "venue" : "USSR Computational Mathematics and Mathematical Physics,",
      "citeRegEx" : "Levitin and Polyak.,? \\Q1966\\E",
      "shortCiteRegEx" : "Levitin and Polyak.",
      "year" : 1966
    }, {
      "title" : "Follow-the-regularized-leader and mirror descent: Equivalence theorems and implicit updates",
      "author" : [ "H.B. McMahan" ],
      "venue" : "arXiv,",
      "citeRegEx" : "McMahan.,? \\Q2010\\E",
      "shortCiteRegEx" : "McMahan.",
      "year" : 2010
    }, {
      "title" : "Universal sequential learning and decision from individual data sequences",
      "author" : [ "N. Merhav", "M. Feder" ],
      "venue" : "In 5th Annual ACM Workshop on Computational Learning Theory (COLT),",
      "citeRegEx" : "Merhav and Feder.,? \\Q1992\\E",
      "shortCiteRegEx" : "Merhav and Feder.",
      "year" : 1992
    }, {
      "title" : "Beyond logarithmic bounds in online learning",
      "author" : [ "F. Orabona", "N. Cesa-Bianchi", "C. Gentile" ],
      "venue" : "In Proceedings of the Fifteenth International Conference on Artificial Intelligence and Statistics (AISTATS),",
      "citeRegEx" : "Orabona et al\\.,? \\Q2012\\E",
      "shortCiteRegEx" : "Orabona et al\\.",
      "year" : 2012
    }, {
      "title" : "Strongly convex analysis",
      "author" : [ "E.S. Polovinkin" ],
      "venue" : "Sbornik: Mathematics,",
      "citeRegEx" : "Polovinkin.,? \\Q1996\\E",
      "shortCiteRegEx" : "Polovinkin.",
      "year" : 1996
    }, {
      "title" : "Elementary differential geometry",
      "author" : [ "A.N. Pressley" ],
      "venue" : "Springer Science & Business Media,",
      "citeRegEx" : "Pressley.,? \\Q2010\\E",
      "shortCiteRegEx" : "Pressley.",
      "year" : 2010
    }, {
      "title" : "Online learning with predictable sequences",
      "author" : [ "A. Rakhlin", "K. Sridharan" ],
      "venue" : "In 26th Annual Conference on Learning Theory (COLT),",
      "citeRegEx" : "Rakhlin and Sridharan.,? \\Q2013\\E",
      "shortCiteRegEx" : "Rakhlin and Sridharan.",
      "year" : 2013
    }, {
      "title" : "Exploiting easy data in online optimization",
      "author" : [ "A. Sani", "G. Neu", "A. Lazaric" ],
      "venue" : "In Advances in Neural Information Processing Systems (NIPS),",
      "citeRegEx" : "Sani et al\\.,? \\Q2014\\E",
      "shortCiteRegEx" : "Sani et al\\.",
      "year" : 2014
    }, {
      "title" : "Convex Bodies: The Brunn–Minkowski Theory. Encyclopedia of Mathematics and its Applications",
      "author" : [ "R. Schneider" ],
      "venue" : null,
      "citeRegEx" : "Schneider.,? \\Q2014\\E",
      "shortCiteRegEx" : "Schneider.",
      "year" : 2014
    }, {
      "title" : "Online learning and online convex optimization",
      "author" : [ "S. Shalev-Shwartz" ],
      "venue" : "Foundations and trends in Machine Learning,",
      "citeRegEx" : "Shalev.Shwartz.,? \\Q2012\\E",
      "shortCiteRegEx" : "Shalev.Shwartz.",
      "year" : 2012
    }, {
      "title" : "Understanding Machine Learning: From Theory to Algorithms",
      "author" : [ "S. Shalev-Shwartz", "S. Ben-David" ],
      "venue" : null,
      "citeRegEx" : "Shalev.Shwartz and Ben.David.,? \\Q2014\\E",
      "shortCiteRegEx" : "Shalev.Shwartz and Ben.David.",
      "year" : 2014
    }, {
      "title" : "Fast rates in statistical and online learning",
      "author" : [ "T. van Erven", "P. Grünwald", "N. Mehta", "M. Reid", "R. Williamson" ],
      "venue" : "Journal of Machine Learning Research (JMLR),",
      "citeRegEx" : "Erven et al\\.,? \\Q2015\\E",
      "shortCiteRegEx" : "Erven et al\\.",
      "year" : 2015
    } ],
    "referenceMentions" : [ {
      "referenceID" : 4,
      "context" : "Realizing that these assumptions are not necessarily critical, much work has been devoted recently to studying learning algorithms in the so-called online learning framework (Cesa-Bianchi and Lugosi, 2006).",
      "startOffset" : 174,
      "endOffset" : 205
    }, {
      "referenceID" : 5,
      "context" : "The online learning framework makes minimal assumptions about the data generating mechanism, while allowing one to replicate results of the statistical framework through online-to-batch conversions (Cesa-Bianchi et al., 2004).",
      "startOffset" : 198,
      "endOffset" : 225
    }, {
      "referenceID" : 17,
      "context" : "1 Introduction Learning theory traditionally has been studied in a statistical framework, discussed at length, for example, by Shalev-Shwartz and Ben-David (2014). The issue with this approach is that the analysis of the performance of learning methods seems to critically depend on whether the data generating mechanism satisfies some probabilistic assumptions.",
      "startOffset" : 127,
      "endOffset" : 163
    }, {
      "referenceID" : 4,
      "context" : "2015, Foster et al. 2015). In this paper we contribute to this growing literature by studying online linear prediction and the follow the leader (FTL) algorithm. Online linear prediction is arguably the simplest yet fundamental of all the learning settings, and lies at the heart of online convex optimization, while it also serves as an abstraction of core learning problems such as prediction with expert advice. FTL, the online analogue of empirical risk minimization of statistical learning, is the simplest learning strategy, one can think of. Although the linear setting of course removes the possibility of exploiting the curvature of losses, as we will see, there are multiple ways online learning problems can present data that allows for small regret, even for FTL. As is it well known, in the worst case, FTL suffers a linear regret (e.g., Example 2.2 of Shalev-Shwartz (2012)).",
      "startOffset" : 6,
      "endOffset" : 888
    }, {
      "referenceID" : 4,
      "context" : "2015, Foster et al. 2015). In this paper we contribute to this growing literature by studying online linear prediction and the follow the leader (FTL) algorithm. Online linear prediction is arguably the simplest yet fundamental of all the learning settings, and lies at the heart of online convex optimization, while it also serves as an abstraction of core learning problems such as prediction with expert advice. FTL, the online analogue of empirical risk minimization of statistical learning, is the simplest learning strategy, one can think of. Although the linear setting of course removes the possibility of exploiting the curvature of losses, as we will see, there are multiple ways online learning problems can present data that allows for small regret, even for FTL. As is it well known, in the worst case, FTL suffers a linear regret (e.g., Example 2.2 of Shalev-Shwartz (2012)). However, for “curved” losses (e.g., exp-concave losses), FTL was shown to achieve small (logarithmic) regret (see, e.g., Merhav and Feder (1992); Cesa-Bianchi and Lugosi (2006); Gaivoronski and Stella (2000); Hazan et al.",
      "startOffset" : 6,
      "endOffset" : 1035
    }, {
      "referenceID" : 3,
      "context" : ", Merhav and Feder (1992); Cesa-Bianchi and Lugosi (2006); Gaivoronski and Stella (2000); Hazan et al.",
      "startOffset" : 27,
      "endOffset" : 58
    }, {
      "referenceID" : 3,
      "context" : ", Merhav and Feder (1992); Cesa-Bianchi and Lugosi (2006); Gaivoronski and Stella (2000); Hazan et al.",
      "startOffset" : 27,
      "endOffset" : 89
    }, {
      "referenceID" : 3,
      "context" : ", Merhav and Feder (1992); Cesa-Bianchi and Lugosi (2006); Gaivoronski and Stella (2000); Hazan et al. (2007)).",
      "startOffset" : 27,
      "endOffset" : 110
    }, {
      "referenceID" : 3,
      "context" : ", Merhav and Feder (1992); Cesa-Bianchi and Lugosi (2006); Gaivoronski and Stella (2000); Hazan et al. (2007)). In this paper we take a thorough look at FTL in the case when the losses are linear, but the problem perhaps exhibits other regularities. The motivation comes from the simple observation that, for prediction over the simplex, when the loss vectors are selected independently of each other from a distribution with a bounded support with a nonzero mean, FTL quickly locks onto selecting the loss-minimizing vertex of the simplex, achieving finite expected regret. In this case, FTL is arguably an excellent algorithm. In fact, FTL is shown to be the minimax optimizer for the binary losses in the stochastic expert setting in the paper of Kotłowski (2016). Thus, we ask the question of whether there are other regularities that allow FTL to achieve nontrivial performance guarantees.",
      "startOffset" : 27,
      "endOffset" : 767
    }, {
      "referenceID" : 3,
      "context" : ", Merhav and Feder (1992); Cesa-Bianchi and Lugosi (2006); Gaivoronski and Stella (2000); Hazan et al. (2007)). In this paper we take a thorough look at FTL in the case when the losses are linear, but the problem perhaps exhibits other regularities. The motivation comes from the simple observation that, for prediction over the simplex, when the loss vectors are selected independently of each other from a distribution with a bounded support with a nonzero mean, FTL quickly locks onto selecting the loss-minimizing vertex of the simplex, achieving finite expected regret. In this case, FTL is arguably an excellent algorithm. In fact, FTL is shown to be the minimax optimizer for the binary losses in the stochastic expert setting in the paper of Kotłowski (2016). Thus, we ask the question of whether there are other regularities that allow FTL to achieve nontrivial performance guarantees. Our main result shows that when the decision set (or constraint set) has a sufficiently “curved” boundary (equivalently, if it is strongly convex) and the linear loss is bounded away from 0, FTL is able to achieve logarithmic regret even in the adversarial setting, thus opening up a new way to prove fast rates not based on the curvature of losses, but on that of the boundary of the constraint set and non-singularity of the linear loss. In a matching lower bound we show that this regret bound is essentially unimprovable. We also show an alternate bound for polytope constraint sets, which allows us to prove that (under certain technical conditions) for stochastic problems the expected regret of FTL will be finite. To finish, we use (A, B)-prod of Sani et al. (2014) to design an algorithm that adaptively interpolates between the worst case O( √ n logn) regret and the smaller regret bounds, which we prove here for “easy data.",
      "startOffset" : 27,
      "endOffset" : 1669
    }, {
      "referenceID" : 3,
      "context" : ", Merhav and Feder (1992); Cesa-Bianchi and Lugosi (2006); Gaivoronski and Stella (2000); Hazan et al. (2007)). In this paper we take a thorough look at FTL in the case when the losses are linear, but the problem perhaps exhibits other regularities. The motivation comes from the simple observation that, for prediction over the simplex, when the loss vectors are selected independently of each other from a distribution with a bounded support with a nonzero mean, FTL quickly locks onto selecting the loss-minimizing vertex of the simplex, achieving finite expected regret. In this case, FTL is arguably an excellent algorithm. In fact, FTL is shown to be the minimax optimizer for the binary losses in the stochastic expert setting in the paper of Kotłowski (2016). Thus, we ask the question of whether there are other regularities that allow FTL to achieve nontrivial performance guarantees. Our main result shows that when the decision set (or constraint set) has a sufficiently “curved” boundary (equivalently, if it is strongly convex) and the linear loss is bounded away from 0, FTL is able to achieve logarithmic regret even in the adversarial setting, thus opening up a new way to prove fast rates not based on the curvature of losses, but on that of the boundary of the constraint set and non-singularity of the linear loss. In a matching lower bound we show that this regret bound is essentially unimprovable. We also show an alternate bound for polytope constraint sets, which allows us to prove that (under certain technical conditions) for stochastic problems the expected regret of FTL will be finite. To finish, we use (A, B)-prod of Sani et al. (2014) to design an algorithm that adaptively interpolates between the worst case O( √ n logn) regret and the smaller regret bounds, which we prove here for “easy data.” We also show that if the constraint set is the unit ball, both the follow the regularized leader (FTRL) algorithm and a combination of FTL and shrinkage, which we call follow the shrunken leader (FTSL), achieve logarithmic regret for easy data. Simulation results on artificial data complement the theoretical findings. While we believe that we are the first to point out that the curvature of the constraint set W can help in speeding up learning, this effect is known in convex optimization since at least the work of Levitin and Polyak (1966), who showed that exponential rates are attainable for strongly convex constraint sets if the norm of the gradients of the objective function admit a uniform lower bound.",
      "startOffset" : 27,
      "endOffset" : 2378
    }, {
      "referenceID" : 3,
      "context" : ", Merhav and Feder (1992); Cesa-Bianchi and Lugosi (2006); Gaivoronski and Stella (2000); Hazan et al. (2007)). In this paper we take a thorough look at FTL in the case when the losses are linear, but the problem perhaps exhibits other regularities. The motivation comes from the simple observation that, for prediction over the simplex, when the loss vectors are selected independently of each other from a distribution with a bounded support with a nonzero mean, FTL quickly locks onto selecting the loss-minimizing vertex of the simplex, achieving finite expected regret. In this case, FTL is arguably an excellent algorithm. In fact, FTL is shown to be the minimax optimizer for the binary losses in the stochastic expert setting in the paper of Kotłowski (2016). Thus, we ask the question of whether there are other regularities that allow FTL to achieve nontrivial performance guarantees. Our main result shows that when the decision set (or constraint set) has a sufficiently “curved” boundary (equivalently, if it is strongly convex) and the linear loss is bounded away from 0, FTL is able to achieve logarithmic regret even in the adversarial setting, thus opening up a new way to prove fast rates not based on the curvature of losses, but on that of the boundary of the constraint set and non-singularity of the linear loss. In a matching lower bound we show that this regret bound is essentially unimprovable. We also show an alternate bound for polytope constraint sets, which allows us to prove that (under certain technical conditions) for stochastic problems the expected regret of FTL will be finite. To finish, we use (A, B)-prod of Sani et al. (2014) to design an algorithm that adaptively interpolates between the worst case O( √ n logn) regret and the smaller regret bounds, which we prove here for “easy data.” We also show that if the constraint set is the unit ball, both the follow the regularized leader (FTRL) algorithm and a combination of FTL and shrinkage, which we call follow the shrunken leader (FTSL), achieve logarithmic regret for easy data. Simulation results on artificial data complement the theoretical findings. While we believe that we are the first to point out that the curvature of the constraint set W can help in speeding up learning, this effect is known in convex optimization since at least the work of Levitin and Polyak (1966), who showed that exponential rates are attainable for strongly convex constraint sets if the norm of the gradients of the objective function admit a uniform lower bound. More recently, Garber and Hazan (2015) proved an O(1/n2) optimization error bound (with problem-dependent constants) for the Frank-Wolfe algorithm for strongly convex and smooth objectives and strongly convex constraint sets.",
      "startOffset" : 27,
      "endOffset" : 2587
    }, {
      "referenceID" : 0,
      "context" : "The effect of the shape of the constraint set was also discussed by Abbasi-Yadkori (2010) who demonstrated O( √ n) regret in the linear bandit setting.",
      "startOffset" : 68,
      "endOffset" : 90
    }, {
      "referenceID" : 15,
      "context" : "The result is a direct corollary of Lemma 9 of McMahan (2010), which holds for any sequence of losses, even in the lack of convexity.",
      "startOffset" : 47,
      "endOffset" : 62
    }, {
      "referenceID" : 15,
      "context" : "The result is a direct corollary of Lemma 9 of McMahan (2010), which holds for any sequence of losses, even in the lack of convexity. It is also a tightening of the well-known inequality Rn ≤ ∑n t=1 `t(wt)− `t(wt+1), which again holds for arbitrary loss sequences (e.g., Lemma 2.1 of Shalev-Shwartz (2012)).",
      "startOffset" : 47,
      "endOffset" : 306
    }, {
      "referenceID" : 14,
      "context" : "A related concept that has been used in convex optimization to show fast rates is that of a strongly convex constraint set (Levitin and Polyak, 1966; Garber and Hazan, 2015): W is λ-strongly convex with respect to the norm ‖·‖ if, for any x, y ∈ W and γ ∈ [0, 1], the ‖·‖-ball with origin γx+ (1− γ)y and radius γ(1 − γ)λ ‖x− y‖ /2 is included in W.",
      "startOffset" : 123,
      "endOffset" : 173
    }, {
      "referenceID" : 9,
      "context" : "A related concept that has been used in convex optimization to show fast rates is that of a strongly convex constraint set (Levitin and Polyak, 1966; Garber and Hazan, 2015): W is λ-strongly convex with respect to the norm ‖·‖ if, for any x, y ∈ W and γ ∈ [0, 1], the ‖·‖-ball with origin γx+ (1− γ)y and radius γ(1 − γ)λ ‖x− y‖ /2 is included in W.",
      "startOffset" : 123,
      "endOffset" : 173
    }, {
      "referenceID" : 22,
      "context" : "4Following Schneider (2014), a convex body of Rd is any non-empty, compact, convex subset of Rd.",
      "startOffset" : 11,
      "endOffset" : 28
    }, {
      "referenceID" : 21,
      "context" : "One way to design an adaptive algorithm is to use the (A, B)-prod algorithm of Sani et al. (2014), trivially leading to the following result: Proposition 4.",
      "startOffset" : 79,
      "endOffset" : 98
    }, {
      "referenceID" : 21,
      "context" : "One way to design an adaptive algorithm is to use the (A, B)-prod algorithm of Sani et al. (2014), trivially leading to the following result: Proposition 4.1. Consider (A, B)-prod of Sani et al. (2014), where algorithm A is chosen to be FTRL with an appropriate regularization term, while B is chosen to be FTL.",
      "startOffset" : 79,
      "endOffset" : 202
    }, {
      "referenceID" : 1,
      "context" : "Our proof follows the idea of Abernethy et al. (2008). We compute the upper bound on the value of the game for each round backwards for t = n, n− 1, .",
      "startOffset" : 30,
      "endOffset" : 54
    }, {
      "referenceID" : 23,
      "context" : ", (Shalev-Shwartz, 2012).",
      "startOffset" : 2,
      "endOffset" : 24
    }, {
      "referenceID" : 1,
      "context" : "“Half-adversarial” data The half-adversarial data used in this experiment is the optimal solution for the adversary in the linear game when W is the unit ball (Abernethy et al., 2008).",
      "startOffset" : 159,
      "endOffset" : 183
    }, {
      "referenceID" : 17,
      "context" : "Condition (ii), which is actually the definition of Polovinkin (1996) for strongly convex sets, means that W can be obtained as the intersection of closed balls of radius 1/λ, such that there is one ball for every boundary point w and tangent hyperplane P where the ball touches P in w.",
      "startOffset" : 52,
      "endOffset" : 70
    }, {
      "referenceID" : 11,
      "context" : ", by Example 13 of Journée et al. (2010). Proof.",
      "startOffset" : 19,
      "endOffset" : 41
    }, {
      "referenceID" : 11,
      "context" : ", by Example 13 of Journée et al. (2010). Proof. We show that (i) implies (ii), (ii) implies (iii), and (iii) implies (i). We start with showing that (i) implies (ii). First note that all principal curvatures of the d-dimensional ball B = B1/λ(0) with radius 1/λ (centered at the origin) are λ. Therefore, (i) and Theorem 3.2.9 of Schneider (2014) implies that there is a convex body M such that W +M = B, where for two sets, S1, S2 ⊂ R, S1 +S2 is defined as {s1 + s2 | s1 ∈ S1, s2 ∈ S2}.",
      "startOffset" : 19,
      "endOffset" : 348
    }, {
      "referenceID" : 19,
      "context" : "1 of Pressley (2010), the curvature of γ at p can be obtained as f ′′(s) √ 1 + f ′(s)2 ∣∣∣∣ s=0 = f ′′(0) .",
      "startOffset" : 5,
      "endOffset" : 21
    } ],
    "year" : 2017,
    "abstractText" : "The follow the leader (FTL) algorithm, perhaps the simplest of all online learning algorithms, is known to perform well when the loss functions it is used on are convex and positively curved. In this paper we ask whether there are other “lucky” settings when FTL achieves sublinear, “small” regret. In particular, we study the fundamental problem of linear prediction over a non-empty convex, compact domain. Amongst other results, we prove that the curvature of the boundary of the domain can act as if the losses were curved: In this case, we prove that as long as the mean of the loss vectors have positive lengths bounded away from zero, FTL enjoys a logarithmic growth rate of regret, while, e.g., for polytope domains and stochastic data it enjoys finite expected regret. Building on a previously known meta-algorithm, we also get an algorithm that simultaneously enjoys the worst-case guarantees and the bound available for FTL.",
    "creator" : "LaTeX with hyperref package"
  }
}