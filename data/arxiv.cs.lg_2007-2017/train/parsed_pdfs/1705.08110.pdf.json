{
  "name" : "1705.08110.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "Semi-Bandits with Knapsacks",
    "authors" : [ "Karthik Abinav Sankararaman" ],
    "emails" : [ "kabinav@cs.umd.edu", "slivkins@microsoft.com" ],
    "sections" : [ {
      "heading" : null,
      "text" : "ar X\niv :1\n70 5.\n08 11\n0v 1\n[ cs\n.L G\n] 2\n3 M\nay 2"
    }, {
      "heading" : "1 Introduction",
      "text" : "Multi-armed bandits (MAB) is an elegant model for studying the tradeoff between acquisition and usage of information, a.k.a. explore-exploit tradeoff. In each round an algorithm sequentially chooses from a fixed set of alternatives (a.k.a. actions, a.k.a. arms), and receives reward for the chosen action. Crucially, the algorithm does not have enough information to answer all “counterfactual\" questions about what would have happened if a different action were chosen in this round. MAB problems have been studied steadily since 1930-ies, with a huge surge of interest in the last decade. The work on MAB progresses across several directions, such as: what auxiliary information, if any, is revealed to the algorithm before or after it needs to make a decision, which “process\" are the rewards coming from, do they have some known structure that can be leveraged, are there global constraints on the algorithm, etc. Many of these directions gave rise to prominent lines of work.\nThis paper unifies two lines of work on MAB: Bandits with Knapsacks (BwK) and semi-bandits. The former concerns scenarios when there are limited “resources\" consumed by the algorithm, e.g., limited inventory in a dynamic pricing problem. In the latter, there may be a huge number of actions, but there is structure which makes the problem tractable. Namely, actions correspond to subsets of some “ground set\", rewards are additive across the elements of this ground set (atoms), and the reward for each chosen atom is revealed after each round. This happens, e.g., in an online routing problem, where each action is a path in a graph, i.e., a (feasible) subset of edges. Both lines of work has received considerable recent attention, and are supported by numerous application examples.\nOur contributions. We define a common generalization of the semi-bandits and BwK, termed SemiBandits with Knapsacks (SemiBwK). Following all prior work on BwK, we focus on an i.i.d. environment: in each round, the “outcome\" is drawn independently from a fixed distribution over the possible outcomes. Here the “outcome\" of a round is the matrix of reward and resource consumption for all atoms. Note that our model allows arbitrary correlations within a given round, both across rewards and consumption for the same atom and across multiple atoms. We design an algorithm for SemiBwK, achieving regret rates that are comparable with those for BwK and semi-bandits, and are near-optimal for important special cases.\nSpecifics are as follows. As usual, we assume “bounded outcomes\": for each atom and each round, rewards and consumption of each resource is at most 1. Regret is relative to OPT, the expected\ntotal reward of the best all-knowing policy. For BwK problems,OPT is known to be a much stronger benchmark than the traditional best-fixed-arm benchmark. We upper-bound regret in terms of relevant parameters: time horizon T , (smallest) budget B, number of atoms n, and OPT itself. We obtain\nRegret ≤ Õ( √ n)(OPT / √ B + √ T +OPT). (1.1)\nThis regret bound is optimal up to polylog factors for paradigmatic special cases of BwK and semibandits: for BwK with OPT > Ω(T ) [11] and for semi-bandits when each feasible action corresponds to a subset of size k ≤ n (and hence OPT ≤ kT ) [32]. The “shape\" of the regret bound is consistent with prior work: theOPT / √ B additive term appears in the optimal regret bound for BwK, and the √ T and √ OPT additive terms are very common in regret bounds for MAB. The per-round running time is polynomial in n, and near-linear in n for some important special cases.\nOur main result holds under assumption that the action set, i.e., the family of feasible subsets of atoms, is described by a matroid constraint. This is a rather general scenario which includes many paradigmatic special cases of semi-bandits such as cardinality constraints, partition matroid constraints, path constraints, and spanning tree constraints. We also assume that B > Ω̃(n+ √ nT ).\nIn addition to the main result, we provide an extension to “linearizable constraints\", under a somewhat restrictive assumption that each resource can be consumed by at most one atom. Further, we identify and work out several notable examples to illustrate the generality of our model.\nChallenges and techniques. BwK problems are challenging compared to traditional MAB problems with i.i.d. rewards because it no longer suffices to look for the best action and/or optimize expected per-round rewards; instead, one essentially needs to look for a distribution over actions with optimal expected total reward across all rounds. Generic challenges in semi-bandits concern handling exponentially many actions (both in terms of regret and in terms of the running time), and taking advantage of the additional feedback. And in SemiBwK, one needs to deal with distributions over subsets of atoms, rather than “just\" with distributions over actions.\nWe combine a technique from prior work on BwK with another existing technique which addresses the combinatorial aspect of the problem. More precisely, we zeroed in on one of five (!) existing techniques for BwK, and made a non-obvious connection to a randomized rounding technique from a very different problem space, approximation algorithms for combinatorial optimization.\nWe build on a BwK algorithm from [2], which combines linear relaxations and a well-known \"optimism-under-uncertainty\" paradigm. A generalization of this algorithm to SemiBwK results in a fractional solution x — a vector over the atoms — which needs to be converted to a feasible subset of atoms (or, more realistically, a distribution over feasible subsets). This is where randomized rounding techniques come in, constructing a distribution over feasible subsets that equals x in expectation. A notable conceptual challenge is to ensure that this distribution contains enough randomness so as to admit concentration bounds not only across rounds, but also across atoms. Our analysis \"opens up\" a fairly technical proof from prior work and intertwines it with a new argument based on negative correlation.\nWe present our algorithm and analysis so as to \"plug in\" any suitable randomized rounding technique, which leads to faster running times for some important special cases.\nSolving SemiBwK using prior work. Naively solving an instance of SemiBwK using an algorithm for BwK would result in a regret bound like (1.1) with n replaced with the number of actions, which could be on the order of nk if each action can consist of at most k atoms, or perhaps even exponential in n.\nSemiBwK can be solved as a special case of a much more general linear-contextual extension of BwK from Agrawal and Devanur [2, 4]. In their model, an algorithm takes advantage of the combinatorial structure of actions, yet it ignores the additional feedback from the atoms. Their regret bounds have a worse dependence on the parameters, and apply for a much more limited range of parameters. Their per-round running time is linear in the number of actions, which is often prohibitively large.\nFor a convenient comparison, let us focus on instances of SemiBwK in which at most one unit of each resource is consumed in each round. (This is the case all our motivating applications, except\nrepeated bidding.) Then [2, 4] assume B > √ nT 3/4, and achieve regret Õ(n √ T OPTB + n 2 √ T ). 1 It is easy to see that we improve upon both summands. In particular, we improves by the factor of n √ n in a lucid special case when B > Ω(T ) and OPT < O(T ).\nRelated work. Multi-armed bandits have been studied since [40] in Operations Research, Economics, and several branches of Computer Science, see [22, 15] for background. Among broad directions in MAB, most relevant is MAB with i.i.d. rewards, starting from [33, 7].\nBandits with Knapsacks (BwK) were first introduced by Badanidiyuru et al. [11] as a common generalization of several models from prior work, as well as numerous motivating examples. Subsequent papers on BwK introduced new algorithms and “smoother\" resource constraints [2], and generalized BwK to contextual bandits [12, 5, 4]. Prior work on various special cases of BwK (i.e., bandit problems with resources) includes dynamic pricing with limited supply [9, 13, 14, 43], dynamic procurement on a budget [10, 37, 39], dynamic ad allocation with advertisers’ budgets [38], and bandits with a single deterministic resource [23, 24, 41, 42]. All BwK problems have only been studied under the i.i.d. assumption, to the best of our knowledge.\nThe semi-bandit model was first studied by [25] in the adversarial setting. In the i.i.d. setting, in a series of works by [20, 19, 32], an optimal algorithm was achieved. This result was then extended to atoms with linear rewards by [44]. [30] obtained improved results for the special case when action set is described by a matroid. Some work studied a closely related “cascade model\", where the ordering of atoms matters [31, 27, 46]. Contextual semi-bandits have been studied in [29].\nRandomized rounding schemes (RRS) come from the literature on approximation algorithms in combinatorial optimization (see [45, 34] for background). RRS were introduced in [35]. [21, 6, 17, 18] among others, developed RRS for combinatorial optimization problems such that the rounded random variables are correlated in a way that gives rise to sharp concentration bounds.\nOpen questions. One question concerns an extension to linear rewards, in line with a large literature on linear bandits. Here, each atom is characterized by a known low-dimensional feature vector, and its reward and resource consumption is a linear function of the features. As in [44], the goal is to alleviate the dependence on #atoms by replacing it with the dependence on #features.\nOrganization of the paper. We formally define the model, describe the algorithm and the regret bounds, overview the analysis, and briefly discuss some of the notable examples. Due to the page limit, many details are deferred to the supplement, specifically: full proofs, a detailed discussion of examples, and some background on combinatorial constrains."
    }, {
      "heading" : "2 Our model and preliminaries",
      "text" : "Our model, called Semi-Bandits with Knapsacks (SemiBwK) is a generalization of multi-armed bandits (henceforth, MAB) with i.i.d. rewards. As such, in each round t = 1 , . . . , T , an algorithm chooses an action St from a fixed set of actions F , and receives a reward µt(St) for this action which is drawn independently from a fixed distribution that depends only on the chosen action. The number of rounds T , a.k.a. the time horizon, is known to the algorithm.\nThere are d resources being consumed by the algorithm. The algorithm starts out with budgetBj ≥ 0 of each resource j. All budgets are known to the algorithm. If in round t action S ∈ F is chosen, the outcome of this round is not only the reward µt(S) but the consumption Ct(S, j) of each resource j ∈ [d]. We refer toCt(S) = (Ct(S, j) : j ∈ [d]) as the consumption vector. Following prior work on BwK, we assume that all budgets are the same: Bj = B for all resources j.\n2 Algorithm stops as soon as any one of the resources goes strictly below 0. The round in which this happens is called the stopping time and denoted τstop. The reward in collected in this last round does not count; so the total reward of the algorithm is rew = ∑\nt<τstop µt(St).\n1Agrawal and Devanur [2, 4] state regret bound with term +n √ T rather than +n2 √\nT , but they assume that per-round rewards lie in [0, 1]. Since per-round rewards can be as large as n in our setting, we need to scale down all rewards by a factor of n, apply their regret bound, and then scale back, which results in the regret bound with+n2 √ T . When per-round consumption can be as large as n, regret bound from Agrawal and Devanur [2, 4] becomes Õ(OPT √ T/B + n2 √\nT ) due to rescaling. 2This is w.l.o.g. because we can divide all consumption of each resource j by Bj/minj′∈[d] Bj′ . Effec-\ntively, B is the smallest budget in the original problem instance.\nActions correspond to subsets of a finite ground set A, with n = |A|; we refer to elements of A as atoms. Thus, the set F of actions corresponds to the family of “feasible subsets\" of A. The rewards and resource consumption is additive over the atoms: for each round t and each atom a there is a reward µt(a) ∈ [0, 1] and consumption vector Ct(a) ∈ [0, 1]d such that for each action S ⊂ F it holds that µt(S) = ∑ a∈S µt(a) and Ct(S) = ∑ a∈S Ct(a).\nWe assume the i.i.d. property across rounds, but allow arbitrary correlations within the same round. Formally, for a given round t we consider the n× (d+1) “outcome matrix\" (µt(a),Ct(a) : a ∈ A), which specifies rewards and resource consumption for all resources and all atoms. We assume that the outcome matrix is chosen independently from a fixed distribution DM over such matrices. The distribution DM is not revealed to the algorithm. The mean rewards and mean consumption is denoted µ(a) := E[µt(a)] andC(a) := E[Ct(a)]. We extend the notation to actions, i.e., to subsets of atoms: µ(S) := ∑\na∈S µ(a) andC(S) := ∑ a∈S C(a).\nAn instance of SemiBwK consists of the action set F ⊂ 2[n], the budgets B = (Bj : j ∈ [d]), and the distribution DM. The F and and B are known to the algorithm, and DM is not. As explained in the introduction, SemiBwK subsumes Bandits with Knapsacks (BwK) and semi-bandits. BwK is the special case when F consists of singletons, and semi-bandits is the special case when all budgets are equal to Bj = nT (so that the resource consumption is irrelevant).\nFollowing the prior work on BwK, we compete against the “optimal all-knowing algorithm\": an algorithm that optimizes the expected total reward for a given problem instance; its expected total reward is denotedOPT. As observed in [11],OPT can be much larger (e.g., factor of 2 larger) than the expected cumulative reward of the best action, for a variety of important special cases of BwK. Our goal is to minimize regret, defined as OPT minus the total reward: Regret := OPT−rew. Recall that F is given by a combinatorial constraint, i.e., a family of subsets. Consider subsets of atoms as n-dimensional binary vectors; then F corresponds to a finite set of points in Rn. We assume that the convex hull H of F forms a polytope in Rn. In other words, there exists a set of linear constraints over Rn whose set of feasible integral solutions is F . We call such combinatorial constraint F linearizable; the convex hull H is called the polytope induced by F . Our main result is matroid constraints, a family of linearizable combinatorial constraints which subsumes several important special cases such as cardinality constraints, partition matroid constraints, spanning tree constraints and path constraints, see Appendix B for self-contained background.\nWe incorporate prior work on randomized rounding for linear programs. In our terms, assume action set F is linearizable, and consider the induced polytope P ⊂ [0, 1]n. The randomized rounding scheme (henceforth,RRS) for F is an algorithm that inputs a feasible fractional solution x ∈ P and the linear equations describing P , and produces a random vector Y overF . For our main result, we consider RRS’s such that E[Y ] = x and Y is negatively correlated; we call such RRS’s negatively correlated. Several such RRS are known: e.g., for cardinality constraints and bipartite matching [21], for spanning trees [6], and for matroids [17]."
    }, {
      "heading" : "2.1 Probability and concentration.",
      "text" : "Let X = (X1, X2, . . . , Xm) denote a collection of random variables which take values in [0, 1]. Let X := 1m ∑m i=1 Xi be the average, and µ := E[X ] be its expectation. Negative correlation. Family X is called negatively correlated iff\nE [ ∏ i∈S Xi ] ≤ ∏i∈S E[Xi] ∀S ⊆ [m], (2.1) E [ ∏\ni∈S(1−Xi) ] ≤ ∏i∈S E[1−Xi] ∀S ⊆ [m], (2.2)\nNote that independent random variables are negatively correlated. Additionally, a family continues to be negatively correlated under non-negative scaling. Furthermore:\nClaim 2.1. If family X is negatively correlated, then families (1+Xi−E[Xi]2 : i ∈ [m]) and (1−Xi+E[Xi]2 : i ∈ [m]) are negatively correlated, too.\nWe are also interested in a closely related property:\nE [ ∏ i∈S Xi ] ≤ (12 )|S| ∀S ⊆ [m]. (2.3)\nTheorem 2.2 ([26]). If family X satisfies (2.3), then for some absolute constant c,\nPr[X ≥ 12 + η] ≤ c · e−2mη 2\n(∀η > 0) (2.4)\nWhile Claim 2.1 is probably known, we provide a proof in the supplement. Theorem 2.2 easily follows from Theorem 3.3 of Impagliazzo and Kabanets [26], see the supplement for the easy details.\nConfidence radius. We use the notion of confidence radius from [28, 9, 11, 3]:\nRadα(x,m) = √ αx/m+ α/m. (2.5)\nThis notion allows to bound the deviations |X − µ| in a way that gets sharper when the µ is small, without knowing the µ in advance. Specifically, if random variables X are independent, then\nPr [ |X − µ| < Radα(X,m) < 3Radα(µ,m)] > 1−O(e−Ω(α)), ∀α > 0. (2.6)\nWe use the confidence radius (2.5) to define upper/lower confidence bounds on the mean rewards\nand mean consumption. Fix round t, atom a, and resource j. Let µ̂t(a) and Ĉt(a, j) denote the empirical average of the rewards and resource-j consumption, resp., between rounds 1 and t − 1. Let Nt(a) be the number of times atom a has been chosen in these rounds (i.e., how many times it has been included in the chosen action). Fixing parameter α > 0 to be chosen later, the upper/lower confidence bounds are defined as\nµ±t (a) = proj ( µ̂(a)± Radα(µ̂(a), Nt(a)) ) C±t (a, j) = proj( Ĉ(a, j)± Radα(Ĉ(a, j), Nt(a)) ),\n(2.7)\nwhere proj(x) := argminy∈[0,1] |y − x| denotes the projection into [0, 1]. We always use Rad with the same parameter α = log(ndT/δ), which we suppress from the notation. We use a vector notation µ±t and C ± t (j) to denote the corresponding n-dimensional vectors over all atoms a. By (2.6), it follows that with probability 1−O(e−Ω(α)) we have the following: µ+t (a) ≥ µ(a) ≥ µ−t (a) and C+t (a, j) ≥ C(a, j) ≥ C−t (a, j)."
    }, {
      "heading" : "3 Main algorithm",
      "text" : "Let us define our main algorithm, called SemiBwK-RRS. The algorithm builds on an arbitraryRRS for the action set F . It is parameterized by this RRS, the polytopeP induced by F (represented as a collection of linear constraints), and a number ǫ > 0. In each round t, it recomputes the upper/lower confidence bounds, as defined in (2.7), and solves the following linear program:\nmaximize µ + t · x subject to C−t (j) · x ≤ B(1−ǫ)T , j = 1, ..., d x ∈ P x ∈ [0, 1]n.\n(LPALG)\nThis linear program defines a linear relaxation of the original problem which is “optimistic\" in the sense that it uses upper confidence bounds for rewards and lower confidence bounds for consumption. The linear relaxation is also “conservative\" in the sense that it rescales the budget by 1 − ǫ. Essentially, this is to ensure that the algorithm does not run out of budget with high probability. Parameter ǫ will be fixed throughout. For ease of notation, we will denote Bǫ := (1− ǫ)B henceforth. The LP solution x can be seen as a probability vector over the atoms. Finally, the algorithm uses the RRS to convert the LP solution into a feasible action. The pseudocode is given as Algorithm 1.\nIf action set F is described by a matroid constraint, we can use the negatively correlated RRS from [17]. In particular, we obtain a complete algorithm for several combinatorial constraints commonly used in the literature on semi-bandits, such as partition matroid constarints, paths and spanning trees. More background on matroid contraints can be found in the supplement (see Appendix B).\nTheorem 3.1. Consider the SemiBwK problem with a linearizable action set F that admits a negatively correlated RRS. Then algorithm SemiBwK-RRS with this RRS achieves\nRegret ≤ O(log(ndT/δ)) √ n ( OPT / √ B + √ T +OPT )\n(3.1)\nAlgorithm 1: SemiBwK-RRS\ninput :an RRS for action set F , induced polytope P (as a set of linear constraints), ǫ > 0. 1 for t = 1, 2 , . . . , T do\n1. Recompute Confidence Bounds according to (2.7)\n2. Obtain fractional solution xt ∈ [0, 1]n by solving LPALG. 3. Obtain a feasible action St ∈ F by invoking the RRS on xt. 4. Semi-bandit Feedback: observe the rewards/consumption for all atoms a ∈ St.\nwith probability at least 1 − δ, for any δ > 0. Here T is the time horizon, n is the number of atoms, and B is the budget. The result holds as long as B > αn+ √ αnT , where α = log(ndT/δ). Parameter ǫ in the algorithm is set to ǫ = √\nαn B + αn B + √ αnT B .\nCorollary 3.2. Consider the setting in Theorem 3.1 and assume that the action set F is defined by a matroid on the set of atoms. Then, using the negatively correlated RRS from [17], we obtain the regret in equation (3.1).\nWe overview the proof in Section 3.1. Full proofs can be found in the supplement.\nRunning time (for matroid constraints). At each round t, the algorithm does two computationally intensive steps: solves the linear program and runs the RRS. The RRS from [17] has O(n2) running time. Hence, in the general case the computational bottleneck is solving the LP, which has n variables and O(2n) constraints. Matroids are known to admit a polynomial-time seperation oracle [e.g., see 36]. It follows that the entire set of constraints in LPALG admits a polynomial-time separation oracle, and therefore we can use the Ellipsoid algorithm to solve LPALG in polynomial time. For some classes of matroid constraints the LP is much smaller: e.g., for cardinality constraints (just d+1 constraints) and for traversal matroids on bipartite graphs (just 2n+d constraints). Then faster (near-linear-time) algorithms can be used.\nUsing another RSS. Recall that our algorithm works under any negatively correlated RRS. We can use this flexibility to improve the per-round running time for some special cases. Note that making decisions extremely fast is often critical in practical applications of bandits, e.g., see [1]. Specifically, we obtain near-linear per-round running times for cardinality constraints and partition matroid constraints. Indeed, LPALG can be solved in near-linear time, as mentioned above, and we can use a negatively correlated RRS from [21] which runs in linear time. These classes of matroid constraints are important in applications, see the detailed discussion in the supplement (Section 7).\nExtension to linearizable action sets. We extend our analysis to any linearizable action set, assuming each resource is consumed by at most one atom. (E.g., this is the case for the “dynamic assortment\" problem, see Section 4.) We use a very simple RRS: given a fractional solution x which lies in P , the polytope induced by the action set F , we represent x as a distribution Y over the vertices of P , and output Y . This is a valid RRS because vertices of P lie in F . However, while we get E[Y ] = x, we cannot guarantee negative correlation or any other similarly useful property.\nTheorem 3.3. Consider the SemiBwK problem with a linearizable action set. Assume each resource can be consumed by at most one atom. Use the same notation and same parameter ǫ as in Theorem 3.1. Then algorithm SemiBwK-RRS with the simple RRS described above achieves:\nRegret ≤ O(log(ndT/δ)) ( OPT √ n/B + n √ OPT+ n ) . (3.2)\nwith probability at least 1− δ, for any δ > 0. The result holds if B > αn, where α = log(ndT/δ). Parameter ǫ in the algorithm is set to ǫ = √\nαn B + αn B .\nCompared to the main result, Theorem 3.3 makes a significant assumption that resources correspond to atoms. On the other hand, it relaxes the assumption on budget B. The regret bound is incomparable with Eq. 3.1: for example, it is worse when T/n ≪ OPT < B, and better when OPT ≪ T/n < nB. The theorem is proved similarly to Theorem 3.1; the main modification is a simpler-to-prove but less efficient version of Eq. 3.3 below.\nIn particular, this extension applies to independent set constraints, which in turn helps in the application to dynamic assortment with mutually exclusive products (see the supplement, Section 7)."
    }, {
      "heading" : "3.1 Proof overview of Theorem 3.1",
      "text" : "First, we argue that LPALG provides a good benchmark that we can use instead of OPT. Fix round t and let OPTALG, t denote the optimal value for LPALG in this round. Then:\nLemma 3.4. OPTALG, t ≥ 1T (1− ǫ)OPT with probability at least 1− δ.\nWe prove this by constructing a series of LPs, starting with a generic linear relaxation for BwK and ending with LPALG, and showing that along the series the optimal value does not decrease w.h.p.\nNext we define a series of events that occur with high probability, henceforth called clean events. Our first “clean event\" concerns total rewards, and compares our algorithm against LPALG:\n|∑t∈[T ] rt − ∑ t∈[T ] µ + t · xt| ≤ O\n( √\nαn ∑ t∈[T ] rt + √ αnT + αn ) . (3.3)\nTo prove that (3.3) is indeed a high-probability event, we show that the following happens w.h.p.:\n| ∑ t∈[T ] rt − ∑ t∈[T ] µ · Yt| ≤ 3nT Rad ( 1 nT ∑ t∈[T ] µ + t · xt , nT )\n|∑t∈[T ] µ · Yt − µ + t · Yt| ≤ 12\n√\nαn ( ∑\nt∈[T ] µ + t · xt\n) + 12 √ αn+ 12αn\n| ∑ t∈[T ] µ + t · Yt − µ+t · xt| ≤\n√ αnT\nWe prove these three high-probability inequalities using several tools. First, we use the confidence radius from Section 2.1. Second, we use the negative correlation property of the RRS. To this end, we extend Theorem 2.2 to a random process that evolves over time, and only assumes that property (2.3) holds within each round conditional on the history. We apply this extension via the transformation from Claim 2.1. Third, we use a concentration bound from prior work which gets sharper when the expected sum is very small, and does not rely on independent random variables. Finally, we show that using these inequalities one can effectively upper-bound the ∑\nt∈[T ]µ + t xt\nterm, and then massage the three inequalities to obtain Eq. 3.3.\nThe second “clean event” concerns the resources consumed by the algorithm, and implies (with a little more work) that the algorithm does not run out of resources before round T . Letting χt(j) denote the consumption of resource j at time t by the algorithm, the clean event is:\n∀j ∈ [d] | ∑ t∈[T ] χt(j)− ∑ t∈[T ] C − t (j) · xt| ≤ √ αnBǫ + αn+ √ αnT . (3.4)\nThe proof that this is indeed a high-probability event is similar to that for Eq. 3.3.\nFinally, we condition on the intersection of the clean events, and obtain the final regret bound in Eq. 3.1 via a “deterministic\" argument, only relying on these high-probability inequalities."
    }, {
      "heading" : "4 Applications and special cases",
      "text" : "We briefly discuss some notable examples of SemiBwK (generalizing some of the numerous applications listed [11]). Our results for these examples improve exponentially over a naive application of the BwK framework. Compared to what can be derived from [2, 4], our results feature a substantially better dependence on parameters, a much better per-round running time, and apply to a wider range of parameters. However, we leave open the possibility that regret bounds can be improved for some special cases. A more detailed discussion, including framing the examples in the SemiBwK framework and comparisons to prior work, can be found in the supplement, see Section 7.\nThe dynamic pricing application is as follows. The algorithm has d products on sale with limited supply: for simplicity, say B units of each. Following Besbes and Zeevi [14], we also allow constraints that cut across products, such as limited inventory of a “part\" that goes into multiple products.3 In each round t, an agent arrives, the algorithm chooses a vector of prices pt ∈ [0, 1]d to offer the agent, and the agent chooses what to buy at these prices. For simplicity, assume the agent is interested in buying (and/or is only allowed to buy) at most one item of each product. The algorithm maximizes\n3We re-scale so that at most one unit of each such “part\" is consumed per one unit of any product, and assume that the inventory of this part is at least B.\nthe total revenue from sales; there is no value in left-over times. The agent has a valuation vector over products, drawn as an independent sample from a fixed and unknown distribution. (However, agents’ valuations across products may be correlated in an arbitrary way.) We assume prices are restricted to lie in a known finite subset S ⊂ [0, 1]. 4 We obtain regret Õ(d √ dB|S| + √\nT |S|) using our main result in Corollary 3.2, whenever B > Ω̃(n + √ nT ). For comparison, results of [2, 4] apply only when B > √ nT 3/4, and yield regret bound of Õ(d3|S|2 √ T ).\nThe dynamic assortment problem is similar to dynamic pricing in that the algorithm is selling d products to an agent, with a limited inventory B of each product, and is interested in maximizing the total revenue from sales. As before, agents can have arbitrary valuation vectors, drawn from a fixed but unknown distribution. However, the prices are fixed externally. Instead, the algorithm has a large number of products and offer only k ≪ d of them in each round. So the algorithm’s actions are which products to offer in which rounds. We obtain regret Õ(k √ dT ) when B > Ω(T ), and regret Õ(d √ dB+ √ dT ) in general. Since both resources and atoms correspond to products, the extension in Theorem 3.3 applies. It yields regret bound Õ(d √ dB), which is better whenB ≪ T/d2. We can also accommodate constraints on mutually exclusive products.\nIn the repeated auctions application, the auctioneer is running r simultaneous repeated auctions to sell a shared inventory of d products, with limited supply B of each product. (E.g., different auctions can cater to different audiences.) Each auction has a parameter such as a reserve price, which the algorithm can adjust over time. For simplicity, assume the auctions are synchronized with one another. As in prior work, we assume that in every round of each auction a fresh set of participants arrives, sampled independently from a fixed joint distribution, and only a minimal feedback is observed: the products sold and the combined revenue. If parameters are restricted to a finite set S, we obtain regret Õ(d √ r|S|B + √\nr|S|T ). One can also consider a “flipped version\" of the previous example: we have r simultaneous, synchronized auctions, but the algorithm is an auction bidder rather than the auction maker. We assume a stationary environment: bidder’s utility from a given bid in a given round of a given auction is an independent sample from a fixed but unknown distribution. The only limited resource here is the bidder’s budget B. Assuming the bids are constrained to lie in a finite subset S, we obtain regret Õ(OPT √ r|S|/B + √ r|S|T )."
    }, {
      "heading" : "5 Proof of the main result (Theorem 3.1)",
      "text" : "This section presents a detailed and self-contained proof of the main result: Theorem 3.1. Let us first recall the theorem statement.\nTheorem (Theorem 3.1). Consider the SemiBwK problem with a linearizable action set F that admits a negatively correlated RRS. Then algorithm SemiBwK-RRS with this RRS achieves\nRegret ≤ O(log(ndT/δ)) √ n ( OPT / √ B + √ T +OPT )\n(5.1)\nwith probability at least 1 − δ, for any δ > 0. Here T is the time horizon, n is the number of atoms, and B is the budget. The result holds as long as B > αn+ √ αnT , where α = log(ndT/δ). Parameter ǫ in the algorithm is set to ǫ = √\nαn B + αn B + √ αnT B ."
    }, {
      "heading" : "5.1 Linear programs",
      "text" : "We argue that LPALG provides a good benchmark that we can use instead of OPT. Fix round t and let OPTALG, t denote the optimal value for LPALG in this round. Then:\nLemma (Lemma 3.4). OPTALG, t ≥ 1T (1− ǫ)OPT with probability at least 1− δ.\nWe will prove this by constructing a series of LP’s, starting with a generic linear relaxation for BwK and ending with LPALG. We show that along the series the optimal value does not decrease with high probability.\nThe first LP, adapted from [11], has one decision variable for each action, and applies generically to any BwK problem.\nmaximize ∑\nS∈F µ(S)x(S) subject to ∑\nS∈F C(S, j)x(S) ≤ B/T j = 1, ..., d 0 ≤ ∑S∈F x(S) ≤ 1.\n(LPBwK)\nLet OPTBwK(B) denote the optimal value of this LP with a given budget B. Then: Claim 5.1. OPTBwK(Bǫ) ≥ (1 − ǫ)OPTBwK(B) ≥ 1T (1− ǫ) OPT.\nProof. The second inequality in Claim 5.1 follows from [Lemma 3.1 in 11]. We will prove the first inequality as follows. Let x∗ denote an optimal solution to LPBwK(B). Consider (1 − ǫ)x∗; this is feasible to LPBwK(Bǫ), since for every S, (1 − ǫ)x∗(S) ≤ 1 and ∑\nS⊆A:S∈S C(S, j)(1 − ǫ)x(S) ≤\nBǫ/T . Hence, this is a feasible solution. Now, consider the objective function. Let y denote an optimal solution to LPBwK(Bǫ). We have that\nOPTBwK(Bǫ) = ∑ S⊆A:S∈S µ(S)y∗(S) ≥ ∑ S⊆A:S∈S µ(S)(1− ǫ)x∗(S) = (1− ǫ)OPTBwK(B).\nNow consider a simpler LP where the decision variables correspond to atoms. As before, P denotes the polytope induced by action set F .\nmaximize µ · x subject to C† · x 4 Bǫ/T x ∈ P x ∈ [0, 1]n. (LPATOMS)\nHere C = (C(a, j) : a ∈ A, j ∈ d) is the n× d matrix of expected consumption, and C† denotes its transpose. The notation 4 means that the inequality ≤ holds for for each coordinate. Leting OPTatoms denote the optimal value for LPATOMS, we have: Claim 5.2. With probability at least 1− δ we have, OPTALG, t ≥ OPTatoms ≥ OPTBwK(Bǫ).\nProof. We will first prove the second inequality.\nConsider the optimal solution vector x to LPBwK(Bǫ). Define S ∗ := {S : x(S) 6= 0}.\nWe will now map this to a feasible solution to LPATOMS and show that the objective value does not decrease. This will then complete the claim. Consider the following solution y defined as follows.\ny(a) = ∑\nS∈S∗:a∈S x(S).\nWe will now show that y is a feasible solution to the polytope P . From the definition of y, we can write it as y = ∑\nS∈S∗ x(S) × I[S]. Here, I[S] is a binary vector, such that it has 1 at position a if\nand only if atom a is present in set S. Hence, y is a point in the polytope since it can be written as convex combination of its vertices.\nNow, we will show that, y also satisfies the resource consumption constraint.\nC(j) · y = ∑\na∈A C(a, j)\n∑\nS∈S∗:a∈S x(S)\n= ∑\nS∈S∗\n∑ a∈S C(a, j)x(S)\n= ∑\nS∈S∗ C(S, j)x(S) ≤ Bǫ/T.\nThe last inequality is because in the optimal solution, the x value corresponding to subset S∗ is 1 while rest all are 0. We will now show that y produces an objective value at least as large as x.\nOPTatoms = µ · y∗ ≥ µ · y = n ∑\na=1\nµ(a) ∑\nS∈S∗:a∈S x(S)\n= ∑\nS∈S∗\n∑ a∈S µ(a)x(S) = ∑ S∈S∗ µ(S)x(S)\n= OPTsubsets(Bǫ)\nNowwe will prove the first inequality. We will assume the “clean event” thatµ+t ≥ µ andC−t ≤ Ct for all t. Hence, the inequality holds with probability at least 1− δ. Consider a time t. Given an optimal solution x∗ to LPATOMS we will show that this is feasible to LPALG,t. Note that, x\n∗ satisfies the constraint set x ∈ P since that is same for both LPALG,t and LPATOMS. Now consider the constraint C − t (j) · x ≤ BǫT . Note that C − t (a, j) ≤ C(a, j). Hence, we have thatC −\nt (j) ·x∗ ≤ C(j) ·x∗ ≤ BǫT . The last inequality is because x∗ is a feasible solution\nto LPATOMS.\nNow consider the objective function. Let y∗ denote the optimal solution to LPALG,t. OPTALG, t = µ + t · y∗ ≥ µ+ t · x∗ ≥ µ · y∗ = OPTatoms.\nHence, combining Claim 5.1 and Claim 5.2, we obtain Lemma 3.4."
    }, {
      "heading" : "5.2 Concentration bounds",
      "text" : "Our analysis relies on several concentration bounds, which elaborate on those presented in Section 2.1.\nFirst, we extend Theorem 2.2 to a random process that evolves over time, and only assumes that property (2.3) holds within each round conditional on the history.\nTheorem 5.3. Let ZT = {ζt,a : a ∈ A, t ∈ [T ]} be a family of random variables taking values in [0, 1]. Assume random variables {ζt,a : a ∈ A} are negatively correlated given Zt−1 and have expectation 12 given Zt−1, for each round t. Let Z = 1nT ∑\na∈A,t∈[T ] ζt,a be the average. Then for some absolute constant c,\nPr[Z ≥ 12 + η] ≤ c · e −2mη2 (∀η > 0). (5.2)\nProof. We prove that family Zt satisfies property (2.3), and then invoke Theorem 2.2. Let us restate property (2.3) for the sake of completeness:\nE\n\n\n∏\n(t,a)∈S ζt,a\n\n ≤ 2−|S| for any subset S ⊆ ZT . (5.3)\nLet S be an arbitrary subset of ZT . Partition S into subsets St = {ζt,a ∈ ZT ∩ S}, for each round t. Fix round τ and denote\nGτ = ∏ t∈[τ ]Ht, where Ht = ∏ a∈St ζt,a.\nWe will now prove the following statement by induction on τ :\nE[Gτ ] ≤ 2−kτ , where kτ = ∑ t∈[τ ] |St|. (5.4)\nWe will prove this by induction on τ .\nBase case is when τ = 1. Note that Gτ is just the product of elements in set ζ1 and they are negatively correlated from the premise. Therefore we are done.\nNow for the inductive case of τ ≥ 2,\nE[Hτ |Zτ−1] ≤ ∏\na∈Sτ E[ζτ,a|Zτ−1] From negative correlation in the conditional space (5.5) ≤ 2−|Sτ | From assumption in Lemma 5.3 (5.6)\nTherefore, we have\nE[Gτ ] = E[E[Gτ−1Hτ |Zτ−1]] Law of iterated expectation = E[Gτ−1 E[Hτ |Zτ−1]] Since Gτ−1 is a fixed value conditional on Zτ−1 ≤ 2−|Sτ | E[Gτ−1] From Eq. 5.6 ≤ 2−kτ From inductive hypothesis\nThis completes the proof of Eq. 5.4. We obtain Eq. 5.3 for τ = T .\nSecond, we invoke Eq. 2.6 for rewards and resource consumptions:\nLemma 5.4. With probability at least 1− e−Ω(α), we have the following: |µ̂t(a)− µt(a)| ≤ 2Rad(µ̂t(a), Nt(a) + 1)\n∀j ∈ [d] |Ĉt(a, j)− Ct(a, j)| ≤ 2Rad(Ĉt(a, j), Nt(a) + 1). (5.7)\nThird, we use a concentration bound from prior work which gets sharper when the expected sum is very small, and does not rely on independent random variables:\nTheorem 5.5 (Babaioff et al. [9]). Let X1, X2, . . . , Xm denote a set of {0, 1} random variables. For each t, let αt denote the multiplier determined by random variables X1, X2, . . . , Xt−1. Let M =\n∑m t=1 Mt where Mt = E[Xt|X1, X2, . . . , Xt−1]. Then for any b ≥ 1, we have the following\nwith probability at least 1−m−Ω(b):\n| m ∑\nt=1\nαt(Xt −Mt)| ≤ b( √ M logm+ logm)"
    }, {
      "heading" : "5.3 Analysis of the “clean event\"",
      "text" : "Let us set up several events, henceforth called clean events, and prove that they hold with high probability. Then the remainder of the analysis can proceed conditional on the intersection of these events. The clean events are similar to the ones in [3], but are somewhat “stronger\", essentially because our algorithm has access to per-atom feedback and our analysis can use the negative correlation property of the RRS.\nIn what follows, it is convenient to consider a version of SemiBwK in which the algorithm does not stop, so that we can argue about what happens w.h.p. if our algorithm runs for the full T rounds. Then we show that our algorithm does indeed run for the full T rounds w.h.p.\nRecall that xt be the optimal fractional solution obtained by solving the LP in round t. Let Yt ∈ {0, 1}n be the random binary vector obtained by invoking theRRS (so that the chosen action St ∈ F corresponds to a particular realization of Yt, interpreted as a subset). Let Gt := {Yt′ : ∀t′ ≤ t} denote the family of RRS realizations up to round t."
    }, {
      "heading" : "5.3.1 “Clean event\" for rewards",
      "text" : "For brevity, for each round t let µt = (µt(a) : a ∈ A) be the vector of realized rewards, and let rt := µt(St) = µt · Yt be the algorithm’s reward at this round. Lemma 5.6. Consider SemiBwK without stopping. Then with probability at least 1− nT e−Ω(α):\n|∑t∈[T ] rt − ∑ t∈[T ] µ + t · xt| ≤ O\n( √\nαn ∑ t∈[T ] rt + √ αnT + αn ) .\nProof. We prove the Lemma by proving the following three high-probability inequalities.\nWith probability at least 1− nT e−Ω(α): the following holds:\n|∑t∈[T ] rt − ∑ t∈[T ] µ · Yt| ≤ 3nT Rad ( 1 nT ∑ t∈[T ] µ + t · xt , nT )\n(5.8)\n|∑t∈[T ] µ · Yt − µ + t · Yt| ≤ 12\n√\nαn ( ∑\nt∈[T ] µ + t · xt\n) + 12 √ αn+ 12αn (5.9)\n|∑t∈[T ] µ + t · Yt − µ+t · xt| ≤\n√ αnT . (5.10)\nWe will use the properties of RRS to prove Eq. 5.10. Proof of Eq. 5.9 is similar to [3], while proof of Eq. 5.8 follows immediately from the setup of the model. Using the parts (5.8) and (5.10) we can\nnow find an appropriate upper bound on\n√\n∑\nt∈[T ] µ + t · xt and using this upper bound, we prove\nLemma 5.6.\nProof of Eq. 5.8. Recall that rt = µtYt. Note that, E[µtYt] = µYt when the expectation is taken over just the independent samples of µ. By Theorem 5.5, with probability 1− e−Ω(α) we have:\n|∑t≤T rt − ∑ t≤T µ · Yt| ≤ 3nT Rad ( 1 nT ∑ t≤T µ · Yt , nT )\n≤ 3nT Rad (\n1 nT\n∑\nt≤T µ + t · Yt , nT\n)\n≤ 3nT Rad (\n1 nT\n∑\nt≤T µ + t · xt , nT\n)\n.\nThe last inequality is because Yt is a feasible solution to LPALG.\nProof of Eq. 5.9. For this part, the arguments similar to [3] follow with some minor adaptations. For sake of completeness we describe the full proof. Note that we have,\n|∑t≤T µ · Yt − µ + t · Yt| ≤ ∑n a=1 | ∑ t≤T µ(a)Yt(a)− µ+t (a)Yt(a)|.\nNow, using Lemma 5.4 in Appendix, we have that with probability 1− nTe−Ω(α)\n|∑t≤T µ(a)Yt(a)− µ+t (a)Yt(a)| ≤ 12 ∑ t≤T Rad(µ(a), Nt(a) + 1).\nHence, we have ∑n\na=1 | ∑ t≤T µ(a)Yt(a)− µ+t (a)Yt(a)| = 12 ∑ a∈A ∑NT (a)+1 r=1 Rad(µ(a), r)\n≤ 12∑a∈A(NT (a) + 1)Rad(µ(a), NT (a) + 1) ≤ 12 √\nαn (µ · (NT + 1)) + 12αn. The last inequality is from the definition of Rad function and using the Cauchy-Swartz inequality. Note that µNT = ∑\nt≤T µ · Yt. Also, since we have with probability 1 − e−Ω(α), µ(a) ≤ µ+t (a), we have,\n12 √ αn (µ · (NT + 1)) + 12αn ≤ 12 √ αn ( ∑ t≤T µ + t · Yt ) + 12 √ αn+ 12αn.\nFinally note that Yt is a feasible solution to the semi-bandit polytope P . Hence, we have that µ\n+ t · Yt ≤ µ+t · xt.\nHence,\n12\n√\nαn ( ∑\nt≤T µ + t · Yt\n) + 12 √ αn+ 12αn ≤ 12\n√\nαn ( ∑\nt≤T µ + t · xt\n) + 12 √ αn+ 12αn.\nProof of Eq. 5.10: Recall that for each round t, the UCB vector µ+ t\nis determined by the random variables Gt−1 = {Yt′ : ∀t′ < t}. Further, conditional on a realization of Gt−1, the random variables {Yt(a) : a ∈ A} are negatively correlated. Consequently, the random variables ζ̃t(a) = µ+t (a)Yt(a), a ∈ A are negatively correlated given Gt−1. Note that E[ζ̃t(a)|Gt−1] = µ+t (a)xt(a). Define\nζt(a) = 1 + ζ̃t(a)− µ+t (a)xt(a)\n2 .\nFrom Claim 2.1, we have that {ζt(a) : a ∈ A} conditioned on Gt−1 are negatively correlated. Further,E[ζt(a)|Gt−1] = 12 . Therefore, the family {ζt(a) : t ∈ [T ], a ∈ A} satisfies the assumptions in Theorem 5.3 and hence satisfies Eq. 5.2 for some absolute constant c. Plugging back the ζ̃t(a)’s, we obtain an upper-tail concentration bound:\nPr [\n1 nT ( ∑T t=1 ∑ a∈A ζ̃t(a)− µ+t (a)xt(a)) ≥ η ] ≤ c · e−2nTη2 .\nTo obtain a corresponding concentration bound for the lower tail, we apply a similar argument to\nζ′t(a) = 1 + µ+t (a)xt(a)− ζ̃t(a)\n2 .\nOnce again from Claim 2.1, we have that {ζ′t(a) : a ∈ A} conditioned on Gt−1 are negatively correlated. The family {ζ′t(a) : t ∈ [T ], a ∈ A} satisfies the assumptions in Theorem 5.3 and hence satisfies Eq. 5.2. Plugging back the ζ̃t(a)’s, we obtain a lower-tail concentration bound:\nPr [\n1 nT ( ∑T t=1 ∑ a∈A µ + t (a)xt(a)− ζ̃t(a)) ≥ η\n]\n≤ c · e−2nTη2 .\nCombining these two we have,\nPr [\n1 nT | ∑T t=1 ∑ a∈A µ + t (a)Yt(a)− µ+t (a)xt(a)| ≥ η\n]\n≤ 2 c · e−2nTη2 . (5.11)\nHence setting η = √ α nT , we obtain Eq. 5.10 with probability at least 1− e−Ω(α).\nCombining Eq. (5.8), (5.9) and (5.10) Let us denote H := √ ∑\nt∈[T ] µ + t · xt. Adding the three\nequations we get\n| ∑ t∈[T ] rt −H2| ≤ √ αH + α+ √ αnH + O(αn) + √ αnT (5.12)\nRearranging and solving forH , we have\nH ≤ √ ∑ t∈[T ] rt +O( √ αn) + (αnT )1/4\nPlugging this back into Eq. 5.12, we get Lemma 5.6."
    }, {
      "heading" : "5.3.2 “Clean event\" for resource consumption",
      "text" : "We define a similar “clean event\" for consumption of each resource j. The proof is similar and is deferred to later in this paper.\nBy a slight abuse of notation, for each round t let Ct(j) = (Ct(a, j) : a ∈ A) be the vector of realized consumption of resource j. Let χt(j) denote algorithm’s consumption for resource j at round t (i.e., χt(j) = Ct(j) · Yt). Lemma 5.7. Consider SemiBwK without stopping. Then with probability at least 1− nT e−Ω(α):\n∀j ∈ [d] |∑t∈[T ] χt(j)− ∑ t∈[T ] C − t (j) · xt| ≤ √ αnBǫ + αn+ √ αnT .\nProof. As we did for clean event described by Lemma 5.6, we will split the proof into following three equations. Fix an arbitrary resource j ∈ [d]. With probability at least 1 − nTe−Ω(α) the following holds:\n| ∑ t≤T χt(j)− ∑ t≤T C(j) · Yt| ≤ 3nT Rad ( 1 nT ∑ t≤T C(j) · Yt , nT ) . (5.13)\n| ∑ t≤T C(j) · Yt −C − t (j) · Yt| ≤ 12\n√\nαn ( ∑ t≤T C(j) · Yt ) + 12 √ αn+ 12αn. (5.14)\n|∑t≤T C − t (j) · Yt −C−t (j) · xt| ≤\n√ αnT . (5.15)\nUsing the parts 5.13, 5.14 and 5.15 we can find an upper bound on √ ∑\nt≤T Ct(j) · Yt. Hence, combining Lemmas 5.13, 5.14 and 5.15 with this bound and taking an Union Bound over all the resources, we get Lemma 5.7.\nProof of Eq. 5.13. We have that {Ct(a, j) : a ∈ A} is a set of independent random variables over a probability spacee CΩ. Note that, ECΩ Ct(a, j)Yt(a) = C(a, j)Yt(a). Hence, we can invoke Theorem 5.5 on independent random variables to get with probability 1− nTe−Ω(α)\n| ∑ t≤T χt(j)− ∑ t≤T C(j) · Yt| ≤ 3nT Rad ( 1 nT ∑ t≤T C(j) · Yt , nT ) .\nProof of Eq. 5.14. This is very similar to proof of 5.9 and we will skip the repetitive parts. Hence, we have with probability 1− nTe−Ω(α)\n|∑t≤T C(j) · Yt −C − t (j) · Yt| ≤ 12\n√\nαn(C(j) · (NT + 1)) + 12αn\n≤ 12 √ αn ( ∑\nt≤T C(j) · Yt )\n+ 12 √ αn+ 12αn.\nProof of Eq. 5.15. Recall that for each round t and each resource j, the LCB vector C− t (j) is determined by the random variables Gt−1 = {Yt′ : ∀t′ < t}. Similar to the proof of Eq. 5.10, random variables {Yt(a) : a ∈ A} are negatively correlated given Gt−1. Random variables ζ̃t(a) = C − t (a)Yt(a), a ∈ A are negatively correlated given Gt−1. Moreover, E[ζt(a) | Gt−1] = C−t (a)xt(a).\nBy Claim 2.1, random variables\nζt(a) = 1 + ζ̃t(a)− C−t (a)xt(a)\n2 , a ∈ A\nare negatively correlated given Gt−1. We conclude that family {ζt(a) : t ∈ [T ], a ∈ A} satisfies the assumptions in Theorem 5.3, and therefore satisfies Eq. 5.2 for some absolute constant c. Therefore, we obtain an upper-tail concentration bound for ζ̃t(a)’s:\nPr [\n1 nT ( ∑T t=1 ∑ a∈A ζ̃t(a)− C−t (a)xt(a)) ≥ η ] ≤ c · e−2nTη2 .\nTo obtain a corresponding concentration bound for the lower tail, we apply a similar argument to\nζ′t(a) = 1 + C−t (a)xt(a)− ζ̃t(a)\n2 .\nOnce again, invoking Claim 2.1 we have that {ζ′t(a) : a ∈ A} conditioned on Gt−1 are negatively correlated. Thus, family {ζt(a) : t ∈ [T ], a ∈ A} satisfies the assumptions in Theorem 5.3, and therefore satisfies Eq. 5.2. We obtain:\nPr [\n1 nT ( ∑T t=1 ∑ a∈A C − t (a)xt(a)− ζ̃t(a)) ≥ η\n]\n≤ c · e−2nTη2 .\nCombing the two tails we have,\nPr [\n1 nT | ∑T t=1 ∑ a∈A C − t (a)Yt(a)− C−t (a)xt(a)| ≥ η\n]\n≤ 2 c · e−2nTη2 . (5.16)\nOnce again, setting η = √ α nT , we obtain Eq. 5.15 with probability at least 1− e−Ω(α).\nProof of Lemma 5.7. DenoteG = √ ∑\nt≤T C(j) · Yt. From Equation 5.13, 5.14 and 5.15, we have thatG2−2Ω(√αn)G ≤ ∑t≤T C − t (j) ·xt+O(αn)+ √ αnT . Note that ∑ t≤T C − t (j) ·xt ≤ Bǫ.\nHence, G2 − 2Ω(√αn)G ≤ Bǫ +O(αn) + √ αnT . Hence, re-arranging this gives us G ≤ √ Bǫ + O( √ αn) + (αnT )1/4. Plugging this back in Equations 5.13, 5.14 and 5.15, we get Lemma 5.7."
    }, {
      "heading" : "5.4 Putting it all together",
      "text" : "Similar to [3], we will handle the hard constraint on budget, by choosing an appropriate value of ǫ. We then combine the above Lemma on \"rewards\" clean event to compare the reward of the algorithm with that of the optimal value of LP to obtain the regret bound in Eq. 3.1. Additionally, we use the Lemma on \"consumption\" clean event to argue that the algorithm doesn’t exhaust the resource budget before round T . Formally, consider the following.\nRecall that from Lemma 3.4, we haveOPTALG, ≥ 1T (1− ǫ)OPT. Let us define the performance of the algorithm as ALG = ∑\nt≤T rt. From Lemma 5.6, that with probability at least 1− ndT e−Ω(α)\nALG ≥ (1− ǫ)OPT−O( √ αnALG)−O(αn) − √ αnT\n≥ (1− ǫ)OPT−O( √ αnOPT)−O(αn) − √ αnT (since ALG ≤ OPT).\nChoosing ǫ = √ αn B + αn B + √ αnT B and using the assumption that B > αn + √ αnT , we derive Eq. 5.1. For any given δ, we set α = Ω(log(ndTδ )) to obtain a success probability of at least 1− δ. Now we will argue that the algorithm does not exhaust the resource budget before round T with probability at least 1− ndT e−Ω(α). Note that for every resource j ∈ [d],\n∑ t≤T C − t (j) · xt ≤ (1− ǫ)B.\nHence, combining this with Lemma 5.7, we have ∑ t≤T Ct(j)Yt ≤ (1− ǫ)B + ǫB ≤ B."
    }, {
      "heading" : "6 Proof sketch for an extension (Theorem 3.3)",
      "text" : "Here, we will give a sketch for proving the regret in Eq. 3.2. Note that, the RRS guarantees no form of concenteration among the atoms. Hence, we analyze it atom-by-atom and take an union bound across all the atoms. For the rewards clean event, we obtain with probability 1− n2T e−Ω(α)\n| ∑\nt≤T rt −\n∑ t≤T µ + t · xt| ≤\nn ∑\na=1\nO\n\n\n√\nαn ∑\nt≤T rt(a)\n\n+O(αn2)\nTranslating this to the final regret calculation, we obtain\nOPT −ALG ≤ O ( OPT √ αn\nB +\nn ∑\na=1\n√\nαnrt(a) + αn 2\n)\nNow, on the RHS we want to maximize ∑n\na=1\n√\nrt(a) subject to ∑n a=1 rt(a) = OPT. Using a\nstandard Lagrangian calculation, we obtain that the maximizer is when rt(a) = OPT n for all the atoms a. Hence, we have the regret in Eq. 3.2.\nNow, let us look at the resources. Here, we will critically use the fact that each atom has a dedicated resource. Since, every atom has a dedicated resource, while analyzing a particular resource, we need to consider just the corresponding arm. In other words, we have\n∀j ∈ [d] | ∑\nt≤T χt(j)−\n∑ t≤T C − t (j) · xt| = | ∑ t≤T Ct(aj , j).Yt(aj)− ∑ t≤T C−t (aj , j)xt(aj)|\nHere, aj is the arm dedicated to resource j. Since {Yt(aj) : t ≤ T } form a Martingale, we can use the concenteration bounds similar to sampling a single atom and the arguments in [3] goes as-is. Hence, with probability 1 − ndT e−Ω(α) the algorithm does not run out of resources before round T ."
    }, {
      "heading" : "7 A detailed discussion of examples",
      "text" : "This section elaborates on the discussion of applications and special cases in Section 4. For ease of presentation, this section can be read independently from the brief discussion in Section 4. For citations to the prior work on these special cases, see the corresponding subsection of the Introduction.\nDynamic pricing. Consider the dynamic pricing problem in a general formulation, where the algorithm has d products on sale with limited supply of each. For simplicity, say we have B items of each product. Further, there may be constraints that cut across products, such as limited inventory of a “part\" that goes into multiple products (e.g., same type of nut that goes into many furniture products). We re-scale so that at most one unit of each “part\" is consumed per one unit of any product, and assume that the inventory of this part is at least B.\nIn each round t, an agent arrives. The algorithm chooses a vector of prices (pt,1, pt,2 , . . . , pt,d) ∈ [0, 1]d to offer the agent. For simplicity, say, the agent is interested in buying (and/or is only allowed\nto buy) at most one item of each product. The algorithm strives to optimize the total revenue from the sales. In particular, it derives no value from left-over items.\nThe agent has a valuation vector over products v ∈ [0, 1]d such that (s)he chooses to buy one item of product j if and only if pt,j ≤ vj . As in most prior work on dynamic pricing, we assume i.i.d. environment, in this case: that the valuation vector is drawn from a fixed but unknown distribution. Note that agents’ valuations across products may be correlated in an arbitrary way.\nLet us frame this problem as a special case of SemiBwK. To side-step price discretization issues, assume the algorithm can only choose prices form a given finite set S ⊂ [0, 1]. The atoms then correspond to the (price, product) pairs: A = S × [d]. The constraint is that at most one price is chosen for each product i, i.e., that an action contains at most one atom from S × {i}. This corresponds to partition matroid constraints, see Appendix B.2. There is a “default price\" for each product which is announced if the chosen action does not specify a price for this product. (The default prices must lie in S; it does not matter for our regret bound what they are.) Algorithm’s rewards correspond to sales: the reward from selling product i at price pt,i is simply pt,i. Resources correspond to the limited inventories: there is a resource for each product and each “part\" that is in limited supply. The expected rewards and consumptions can be arbitrarily correlated across atoms, which models arbitrary valuation vectors.\nFollowing [11], we restrict prices to a finite subset S ⊂ [0, 1]. Note that OPT ≤ dB, since that is the maximum number of products available, and the number of atoms is n = d|S|. Hence, we obtain regret of Õ(d √ dB|S|+ √ dT |S|) using Corollary 3.2, wheneverB > Ω̃(n+ √ nT ).\nThis result should be contrasted with a naive application of the BwK framework. There, arms correspond to every possible realization of prices for the d products. Thus, we have |S|d arms, with a corresponding exponential blow-up in regret. As discussed in the introduction, results of Agrawal and Devanur [2, 4] apply when B > √ nT 3/4. Plugging in OPT ≤ dB and n = d|S|, they yield regret bound of Õ(d3|S|2 √ T ). 5 Thus, our regret bounds feature a better dependence on the number of allowed prices |S| (which can be very large) and the number of products d. Further, our regret bounds hold in a meaningful way for the much larger range of values for budget B.\nRemark 7.1. Some prior work on dynamic pricing with limited supply [e.g., 13, 9, 11] achieves regret boundswithout restricting itself to a particular finite set of prices. A typical approach is to pick an evenly spaced subset S, and optimize the tradeoff between |S| and the resulting “discretization error\": the difference between OPT with unrestricted price set and the OPT with prices restricted to S. However, this requires upper-bounding the discretization error, which is often quite difficult. In particular, prior work only accomplishes this for a simple special case of (essentially) a single product. Current techniques for upper-bounding discretization error seem to break when carried over to SemiBwK scenarios.\nDynamic assortment. This problem is similar to dynamic pricing in that the algorithm is selling multiple products to agents. However, the prices are fixed externally. Instead, the algorithm has a large number of products and can offer only a limited number of those in each round.\nFormally, the algorithm has d products with limited inventory of each. For simplicity we will assume that the algorithm has B copies of each product. There is a fixed price pi ∈ [0, 1] for each item of each product i. At each round an agent arrives and the algorithm has to choose a subset of at most k products to show to the agent; typically k ≪ d. Like in the dynamic pricing example, the agent can buy at most one unit of each item. The agent has a valuation vector over products v ∈ [0, 1]d, and this valuation vector is sampled each time from a fixed but unknown distribution. The agent buys one item of each product j if and only if pt,j ≤ vj . The algorithm strives to maximize the total revenue from sales, and there is no value in left-over items.\nTo frame this as a SemiBwK problem, there is an atom for each of the d products, and actions correspond to subsets of at most k atoms. Rewards correspond to sales, and resources correspond to products, exactly as in dynamic pricing. Since OPT ≤ min(dB, kT ), our main result yields regret Õ(k √ dT ) when B = Ω(T ), and regret Õ(d √ dB + √ dT ) in general.\n5This is because for dynamic pricing the total per-resource consumption is bounded by 1, so we can apply the results from [2, 4] without rescaling the consumptions.\nSince both resources and atoms correspond to products, each resource can be consumed by at most one atom, and hence the extension in Theorem 3.3 applies. It yields regret bound Õ(d √ dB), which is better when B ≪ T/d2. A naive application of the BwK framework would have arms corresponding to each subset of k products. Hence, the number of arms would be O(dk). The other parameters of the problem would remain the same. Hence, the regret obtained would be Õ(d √ Bdk). Hence, again we obtain an exponential improvement.\nDynamic assortment problem can involve side constraints. For example, some products are naturally sold in a mutually exclusive manner. In particular, when we have disjoint “clusters\" of mutually exclusive products, we can encode them via partition matroid constraints (see Appendix B.2): an action can contain at most one atom from each cluster. Then our main result applies, again, and yields the same regret bounds as above.\nMore generally, we can have a graph of mutually exclusive products, and the side constraint is that actions must be independent sets in this graph. Independent set constraints are linearizable (see Appendix B.3), so the combined combinatorial constraint on F is linearizable, too. Therefore, we can apply the extension in Theorem 3.3 (and obtain the same regret bound as above).\nAdjustable repeated auctions. Consider a repeated auction with adjustable parameters, e.g., repeated second-price auction with reserve price that can be adjusted from one round to another. While prior work [16, 11] concerned running one repeated auction, we generalize this scenario to multiple repeated auctions with shared inventory. Indeed, the same inventory may be sold via multiple channels to different audiences.\nMore formally, the auctioneer is running r simultaneous repeated auctions to sell d products with limited supply of each. For simplicity, we assume the supply of each product is B. The inventory is shared across all auctions. In each round, the algorithm specifies a parameter (such as a reserve price) for each repeated auction. The parameter comes from a finite domain S. For simplicity, assume the auctions are synchronized: in each round, we have one iteration of every auction. As in prior work, we assume that in every round a fresh set of participants arrives to each action, sampled independently from a fixed joint distribution. The participants’ types are not known to the algorithm. Algorithm’s goal is to maximize total revenue from all auctions and all rounds.\nWe will assume that this adjustable parameter comes from a finite domain S ⊂ [0, 1]. Note that, at each time-step the algorithm fixes a value to this parameter in each of the r auctions. Then a random sample of participants types are drawn from a joint distribution across the auctions. The algorithm receives feedback after each round. Following prior work, we only assume minimal feedback: for each auction, what where the products sold and what was the combined revenue from this auction. In particular, we do not assume that the algorithm has access to participants’ bids. Not using participants’ bids is desirable for privacy considerations, and in order to reduce the participants’ incentives to game the learning algorithm.\nWe will now solve this problem using the SemiBwK framework. The atoms are the auction-parameter pairs: A = [r]×S. The combinatorial constraint is that an action must specify at most one parameter value for each auction i, i.e., contain at most one atom from each subset {i} × S. This corresponds to partition matroid constraints, see Appendix B.2. As in the dynamic pricing application, there is a “default parameter\" for each auction which is chosen if the action does not specify a parameter for this auction. (The default parameters must lie in S; it does not matter for our regret bound what they are.) The resource correspond to the items being auctioned: we have a resource for each product. For simplicity, say each product has supply of B. Note that OPT ≤ dB and number of atoms is n = r|S|. Hence, our main result yields regret Õ(d √ r|S|B + √\nr|S|T ). A naive application of the BwK framework would have arms that correspond to all possible combinations of parameters, for the total of O(|S|r) arms. Again, we have an exponential blow-up in regret. Alternatively, one may try running r seperate instances of BwK, one for each auction, but that may result result in budgets being violated since the items are shared across the auctions and it is unclear a priori how much of each item will be sold in each auction.\nRepeated bidding. We can also consider a “flipped\" version of the repeated action scenario, where the algorithm is an auction participant rather than the auction maker. More precisely, consider a bidder who is placing bids in r different repeated auctions. For simplicity, assume the auctions are\nsynchronized, so that in each round, the bidder chooses a bid for each auction, and subsequently observes the utility derived from each auction. We assume a stationary environment: the bidder’s utility from a given bid in a given round of a given auction is an independent sample from a fixed but unknown distribution. For simplicity, suppose the utility derived from each auction lies in [0, 1] interval. Assume the bids are constrained to lie in a finite subset S. The only limited resource here is the bidder’s budget B.\nWe will now frame this problem in the SemiBwK framework. The atoms correspond to the auctionbid pairs: A = [r] × S. As before, each action must specify at most one bid for each auction i, i.e., choose at most one atom from each subset {i} × S. There is a “default bid\" for each auction which gets chosen when an action does not specify a bid for this auction. There is exactly one resource, which is money and the total budget is B. Note that the number of atoms is n = r|S|. Hence, our main result yields regret Õ(OPT √ r|S|/B + √\nr|S|T ). As before, a naive application of the BwK framework would have arms that correspond to all possible combinations of bids, for the total of O(|S|r) arms; so we have an exponential blow-up in regret."
    }, {
      "heading" : "A Probability and concentration: some proofs",
      "text" : "Our analysis relied on some facts about probability and concentration that we stated in Preliminaries (Section 2.1). While we believe these results are known, we provide proofs below for the sake of completeness. In what follows, let X = (X1, X2, . . . , Xm) denote a collection of random variables which take values in [0, 1], and let X := 1m ∑m i=1 Xi be their average.\nTheorem (Theorem 2.2). Suppose X satisfies (2.3), i.e., E[∏i∈S Xi] ≤ (12 )|S| for every S ⊆ [m]. Then for some absolute constant c,\nPr[X ≥ 12 + η] ≤ c · e −2mη2 (∀η > 0). (A.1)\nProof. Fix η > 0. From Theorem 3.3 in Impagliazzo and Kabanets [26], we have that\nPr[X ≥ 12 + η] ≤ c · e −mDKL(1/2+η ‖ 1/2),\nwhere DKL(· ‖ ·) denotes KL-divergence, so that\nDKL(12 + η ‖ 12 ) = (12 + η) log(1 + 2η) + (12 − η) log(1− 2η). (A.2)\nFrom Taylor series expansion we have,\nlog(1 + x) = x− x2/2 + x3/3 + . . . log(1 − x) = −x− x2/2− x3/3 . . . .\nPlugging this into (A.2), we deriveDKL(1/2 + η ‖ 1/2) ≥ 2η2, which implies (A.1).\nClaim (Claim 2.1). If family X is negatively correlated, then families (1+Xi−E[Xi]2 : i ∈ [m]) and (1−Xi+E[Xi]2 : i ∈ [m]) are negatively correlated, too.\nProof. We will show that the random variables {(1 + Xi − E[Xi])/2 : i ∈ [m]} are negatively correlated. Note that if Xi’s are neg. correlated then so are 1 − Xi’s. This would imply that {(1 + (1 −Xi)− E[(1 −Xi)])/2 : i ∈ [m]} are negatively correlated. Hence, we would have that {(1 + |Xi − E[Xi]|)/2 : i ∈ [m]} Denote µi = E[Xi] and Yi := (1 + Xi − µi)/2 and zi := (1 − µi)/2 for all i ∈ [m]. Note that Yi = Xi/2 + zi and zi ≥ 0, Xi ≥ 0.\nConsider a subset S ⊆ [m]. We have,\nE[ ∏\ni∈S Yi] = E[\n∑\nT⊆S\n∏ i∈T (Xi/2) ∏ j∈S\\T zi]\n= ∑ T⊆S E[ ∏ i∈T (Xi/2)] ∏ j∈S\\T zi From Linearity of Expectation\n≤ ∑\nT⊆S\n∏ i∈T (µi/2) ∏ j∈S\\T zi fact that zi, Xi ≥ 0 andXi are negatively correlated\n= ∏\ni∈S ((1 − µi)/2 + µi/2) = 1/2 =\n∏\ni\nE[Yi]. From Binomial Theorem\nNow we will show that the second property in the definition of negative correlation (i.e., Eq. 2.2) holds for the random variables (1−Xi−µi)/2 . Consider Y ′i := 1−(1+Xi−µi)/2 for all i ∈ [m]. Note that, we have Y ′i = (1 + µi −Xi)/2 for all i ∈ [m]. Hence, setting Z ′i := (1 −Xi)/2 for all i ∈ [m] and noting that Y ′i = µi/2 + Z ′i for µi ≥ 0, Z ′i ≥ 0, we have the following. Consider a subset S ⊆ [m]. We have,\nE[ ∏ i∈S Y ′i ] = E[ ∑ T⊆S ∏ i∈T Z ′i ∏ j∈S\\T (µi/2)]\n= ∑ T⊆S E[ ∏ i∈T Z ′i] ∏ j∈S\\T (µi/2) From Linearity of Expectation\n≤ ∑\nT⊆S\n∏ i∈T ((1 − µi)/2) ∏ j∈S\\T (µi/2) fact that µi, Z ′ i ≥ 0 and Z ′i are negatively correlated\n= ∏\ni∈S ((1 − µi)/2 + µi/2) = 1/2 =\n∏\ni\nE[Y ′i ]. From Binomial Theorem"
    }, {
      "heading" : "B Combinatorial constraints: formal discussion",
      "text" : "To make this paper more self-contained, we provide a formal discussion of combinatorial constraints for which our algorithms work, and define the corresponding linear relaxations.\nRecall that in SemiBwK, we have a finite ground set whose elements are called “atoms\", and a family F of “feasible subsets\" of the ground set which are the actions. Our main result in Theorem 3.1 holds as long as F forms a matroid. Thus, we define matroid constraints and list several important special cases thereof in Appendices B.1 and B.2, respectively. The extension in Theorem 3.3 holds for linearizable action sets. We provide an example in Appendix B.3, namely: we define constraints specified by independent sets of a graph, and show that they are linearizable.\nB.1 Matroid constraints\nTo be consistent with the literature on matroids, the ground set will be denoted E. Family F of subsets of E is called a matroid if it satisfies the following properties:\n• Empty set: The empty set φ is present in F • Hereditary property: For two subsets X,Y ⊆ E such thatX ⊆ Y , we have that\nY ∈ F =⇒ X ∈ F\n• Exchange property: ForX,Y ∈ F and |X | > |Y |, we have that\n∃e ∈ X \\ Y : Y ∪ {e} ∈ F\nMatroids are linearizable, i.e., the convex hull of F forms a polytope in RE . (Here subsets of F are intepreted as binary vectors in RE .) In other words, there exists a set of linear constraints whose set of feasible integral solutions is F . In fact, the convex hull of F , a.k.a. the matroid polytope, can be represented via the following linear system:\nx(S) ≤ rank(S) ∀S ⊆ E xe ∈ [0, 1]E ∀e ∈ E. (LP-Matroid)\nHere x(S) := ∑ e∈S xe, and rank(S) = max{|Y | : Y ⊆ S, Y ∈ F} is the “rank function\" for F . F is indeed the set of all feasible integral solutions of the above system. This is a standard fact in combinatorial optimization, e.g., see Theorem 40.2 and its corollaries in Schrijver [36].\nB.2 Examples of matroid constraints\nWe will now describe some well-studied special cases of matroids. That they indeed are special cases of matroids is well-known, we will not present the corresponding proofs here.\nIn all LPs presented below, we have variables xe for each arom e ∈ E, and we use shorthand x(S) := ∑\ne∈S xe for S ⊂ E. Cardinality constraints. Cardinality constraint is defined as follows: a subset S of atoms belongs to F if and only if |S| ≤ K for some fixedK . This is perhaps the simplest constraint that our results are applicable to. In the context of SemiBwK, each action selects at mostK atoms.\nThe corresponding induced polytope is as follows:\nx(E) ≤ K xe ∈ [0, 1] ∀e ∈ E. (LP-Cardinality)\nPartition matroid constraints. A generalization of cardinality constraints, called partition matroid constraints, is defined as follows. Suppose we have a collection B1 , . . . , Bk of disjoint subsets of E, and numbers d1 , . . . , dk. A subset S of atoms belongs to F if and only if |S ∩ Bi| ≤ di for every i. Partition matroid constraints appear in several applications of SemiBwK such as dynamic pricing, adjusting repeated auctions, and repeated bidding. In these applications, each action selects one price/bid for each offered product. Also, partition matroid constraints can model clusters of mutually exclusive products in dynamic assortment application.\nThe induced polytope is as follows:\nx(Bi) ≤ di ∀i ∈ [k] xe ∈ [0, 1] ∀e ∈ E. (LP-PartitionMatroid)\nSpanning tree constraints. Spanning tree constraints describe spanning trees in a given undirected graph G = (V,E), where the atoms correspond to edges in the graph. A spanning tree in G is a subset E′ ⊂ E of edges such that (V,E′) is a tree. Action set F consists of all spanning trees of G. The induced polytope is as follows:\nx(ES) ≤ |S| − 1 ∀S ⊆ V x(EV ) = |V | − 1 xe ∈ [0, 1] ∀e ∈ E.\n(LP-SpanningTree)\nHere, ES denotes the edge set in subgraph induced by node set S ⊂ V . Path constraints. Path constraints describe paths in a given graph G = (V,E), where the atoms correspond to edges in the graph. Path constraints are commonly used in conjunction with the online routing problem ([8] and much follow-up work), where each action is a path in the network.\nFormally, we are given an undirected graph G = (V,E) and a source sink pair (s, t) in this graph. Action set F consists of all s-t paths in G. We index edges as e = (i, j), where i, j ∈ V . The corresponding induced polytope is as follows:\n∑ j∈V x(i,j) − x(j,i) = 0 ∀i ∈ V \\ {s, t} ∑\nj∈V x(i,j) − x(j,i) = 1 i = s ∑\nj∈V x(i,j) − x(j,i) = −1 i = t xe ∈ [0, 1] ∀e ∈ E.\n(LP-Path)\nB.3 Independent set constraints\nIndependent set constraints are specified as follows. Suppose V is the set of atoms, andG = (V,E) is an undirected graph. Action set F consists of all independent sets in G, i.e., all subsets S ⊂ V such that (u, v) 6∈ E, for any nodes u, v ∈ S. Independent set constraints arise in the dynamic assortment application with mutually exclusive products.\nIndependent set constraints are linearizable. The corresponding induced polytope is as follows:\nxu + xv ≤ 1 ∀(u, v) ∈ E xe ∈ [0, 1] ∀e ∈ E. (LP-Path)"
    } ],
    "references" : [ ],
    "referenceMentions" : [ ],
    "year" : 2017,
    "abstractText" : "This paper unifies two lines of work on multi-armed bandits, Bandits with Knap-<lb>sacks (BwK) and semi-bandits. The former concerns scenarios with limited “re-<lb>sources\" consumed by the algorithm, e.g., limited inventory in a dynamic pricing<lb>problem. The latter has a huge number of actions, but there is combinatorial struc-<lb>ture and additional feedback which makes the problem tractable. Both lines of<lb>work has received considerable recent attention, and are supported by numerous<lb>application examples. We define a common generalization, and design a general<lb>algorithm for this model. Our regret rates are comparable with those for BwK and<lb>semi-bandits in general, and essentially optimal for important special cases.",
    "creator" : "LaTeX with hyperref package"
  }
}