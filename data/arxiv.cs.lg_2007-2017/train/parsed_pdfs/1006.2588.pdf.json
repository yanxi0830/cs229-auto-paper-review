{
  "name" : "1006.2588.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "Agnostic Active Learning Without Constraints",
    "authors" : [ "Alina Beygelzimer", "Daniel Hsu", "John Langford", "Tong Zhang" ],
    "emails" : [ ],
    "sections" : [ {
      "heading" : null,
      "text" : "ar X\niv :1\n00 6.\n25 88\nv1 [\ncs .L\nG ]\n1 4\nJu n\n20 10"
    }, {
      "heading" : "1 Introduction",
      "text" : "In active learning, a learner is given access to unlabeled data and is allowed to adaptively choose which ones to label. This learning model is motivated by applications in which the cost of labeling data is high relative to that of collecting the unlabeled data itself. Therefore, the hope is that the active learner only needs to query the labels of a small number of the unlabeled data, and otherwise perform as well as a fully supervised learner. In this work, we are interested in agnostic active learning algorithms for binary classification that are provably consistent, i.e. that converge to an optimal hypothesis in a given hypothesis class.\nOne technique that has proved theoretically profitable is to maintain a candidate set of hypotheses (sometimes called a version space), and to query the label of a point only if there is disagreement within this set about how to label the point. The criteria for membership in this candidate set needs to be carefully defined so that an optimal hypothesis is always included, but otherwise this set can be quickly whittled down as more labels are queried. This technique is perhaps most readily understood in the noise-free setting [CAL94, Das05], and it can be extended to noisy settings by using empirical confidence bounds [BBL06, DHM07, BDL09, Han09, Kol09].\nThe version space approach unfortunately has its share of significant drawbacks. The first is computational intractability: maintaining a version space and guaranteeing that only hypotheses from this set are returned is difficult for linear predictors and appears intractable for interesting nonlinear predictors such as neural nets and decision trees [CAL94]. Another drawback of the approach is its brittleness: a single mishap (due to, say, modeling failures or computational approximations) might cause the learner to exclude the best hypothesis from the version space forever; this is an ungraceful failure mode that is not easy to correct. A third drawback is related to sample re-usability: if (labeled) data is collected using a version space-based active learning algorithm, and we later decide to use a different algorithm or hypothesis class, then the earlier data may not be freely re-used because its collection process is inherently biased.\nHere, we develop a new strategy addressing all of the above problems given an oracle that returns an empirical risk minimizing (ERM) hypothesis. As this oracle matches our abstraction of many supervised learning algorithms, we believe active learning algorithms built in this way are immediately and widely applicable.\n∗IBM Research, beygel@us.ibm.com †UC San Diego, djhsu@cs.ucsd.edu ‡Yahoo! Research, jl@yahoo-inc.com §Rutgers University, tongz@rci.rutgers.edu\nOur approach instantiates the importance weighted active learning framework of [BDL09] using a rejection threshold similar to the algorithm of [DHM07] which only accesses hypotheses via a supervised learning oracle. However, the oracle we require is simpler and avoids strict adherence to a candidate set of hypotheses. Moreover, our algorithm creates an importance weighted sample that allows for unbiased risk estimation, even for hypotheses from a class different from the one employed by the active learner. This is in sharp contrast to many previous algorithms (e.g., [CAL94, BBL06, BBZ07, DHM07, Han09, Kol09]) that create heavily biased data sets. We prove that our algorithm is always consistent and has an improved label complexity over passive learning in cases previously studied in the literature. We also describe a practical instantiation of our algorithm and report on some experimental results."
    }, {
      "heading" : "1.1 Related Work",
      "text" : "As already mentioned, our work is closely related to the previous works of [DHM07] and [BDL09], both of which in turn draw heavily on the work of [CAL94] and [BBL06]. The algorithm from [DHM07] extends the selective sampling method of [CAL94] to the agnostic setting using generalization bounds in a manner similar to that first suggested in [BBL06]. It accesses hypotheses only through a special ERM oracle that can enforce an arbitrary number of example-based constraints; these constraints define a version space, and the algorithm only ever returns hypotheses from this space, which can be undesirable as we previously argued. Other previous algorithms with comparable performance guarantees also require similar examplebased constraints (e.g., [BBL06, BDL09, Han09, Kol09]). Our algorithm differs from these in that (i) it never restricts its attention to a version space when selecting a hypothesis to return, and (ii) it only requires an ERM oracle that enforces at most one example-based constraint, and this constraint is only used for selective sampling. Our label complexity bounds are comparable to those proved in [BDL09] (though somewhat worse that those in [BBL06, DHM07, Han09, Kol09]).\nThe use of importance weights to correct for sampling bias is a standard technique for many machine learning problems (e.g., [SB98, ACBFS02, SKM07]) including active learning [Sug05, Bac06, BDL09]. Our algorithm is based on the importance weighted active learning (IWAL) framework introduced by [BDL09]. In that work, a rejection threshold procedure called loss-weighting is rigorously analyzed and shown to yield improved label complexity bounds in certain cases. Loss-weighting is more general than our technique in that it extends beyond zero-one loss to a certain subclass of loss functions such as logistic loss. On the other hand, the loss-weighting rejection threshold requires optimizing over a restricted version space, which is computationally undesirable. Moreover, the label complexity bound given in [BDL09] only applies to hypotheses selected from this version space, and not when selected from the entire hypothesis class (as the general IWAL framework suggests). We avoid these deficiencies using a new rejection threshold procedure and a more subtle martingale analysis.\nMany of the previously mentioned algorithms are analyzed in the agnostic learning model, where no assumption is made about the noise distribution (see also [Han07]). In this setting, the label complexity of active learning algorithms cannot generally improve over supervised learners by more than a constant factor [Kää06, BDL09]. However, under a parameterization of the noise distribution related to Tsybakov’s low-noise condition [Tsy04], active learning algorithms have been shown to have improved label complexity bounds over what is achievable in the purely agnostic setting [CN06, BBZ07, CN07, Han09, Kol09]. We also consider this parameterization to obtain a tighter label complexity analysis."
    }, {
      "heading" : "2 Preliminaries",
      "text" : ""
    }, {
      "heading" : "2.1 Learning Model",
      "text" : "Let D be a distribution over X × Y where X is the input space and Y = {±1} are the labels. Let (X,Y ) ∈ X × Y be a pair of random variables with joint distribution D. An active learner receives a sequence (X1, Y1), (X2, Y2), . . . of i.i.d. copies of (X,Y ), with the label Yi hidden unless it is explicitly queried. We use the shorthand a1:k to denote a sequence (a1, a2, . . . , ak) (so k = 0 correspond to the empty sequence).\nLet H be a set of hypotheses mapping from X to Y. For simplicity, we assume H is finite but does not completely agree on any single x ∈ X (i.e., ∀x ∈ X , ∃h, h′ ∈ H such that h(x) 6= h′(x)). This keeps the focus on the relevant aspects of active learning that differ from passive learning. The error of a hypothesis h : X → Y is err(h) := Pr(h(X) 6= Y ). Let h∗ := argmin{err(h) : h ∈ H} be a hypothesis of minimum error in H. The goal of the active learner is to return a hypothesis h ∈ H with error err(h) not much more than err(h∗), using as few label queries as possible."
    }, {
      "heading" : "2.2 Importance Weighted Active Learning",
      "text" : "In the importance weighted active learning (IWAL) framework of [BDL09], an active learner looks at the unlabeled data X1, X2, . . . one at a time. After each new point Xi, the learner determines a probability Pi ∈ [0, 1]. Then a coin with bias Pi is flipped, and the label Yi is queried if and only if the coin comes up heads. The query probability Pi can depend on all previous unlabeled examples X1:i−1, any previously queried labels, any past coin flips, and the current unlabeled point Xi.\nFormally, an IWAL algorithm specifies a rejection threshold function p : (X × Y × {0, 1})∗ × X → [0, 1] for determining these query probabilities. Let Qi ∈ {0, 1} be a random variable conditionally independent of the current label Yi, Qi ⊥ Yi | X1:i, Y1:i−1, Q1:i−1 and with conditional expectation\nE[Qi|Z1:i−1, Xi] = Pi := p(Z1:i−1, Xi). where Zj := (Xj , Yj , Qj). That is, Qi indicates if the label Yi is queried (the outcome of the coin toss). Although the notation does not explicitly suggest this, the query probability Pi = p(Z1:i−1, Xi) is allowed to explicitly depend on a label Yj (j < i) if and only if it has been queried (Qj = 1)."
    }, {
      "heading" : "2.3 Importance Weighted Estimators",
      "text" : "We first review some standard facts about the importance weighting technique. For a function f : X×Y → R, define the importance weighted estimator of E[f(X,Y )] from Z1:n ∈ (X × Y × {0, 1})n to be\nf̂(Z1:n) := 1\nn\nn∑\ni=1\nQi Pi · f(Xi, Yi).\nNote that this quantity depends on a label Yi only if it has been queried (i.e., only if Qi = 1; it also depends on Xi only if Qi = 1). Our rejection threshold will be based on a specialization of this estimator, specifically the importance weighted empirical error of a hypothesis h\nerr(h, Z1:n) := 1\nn\nn∑\ni=1\nQi Pi · 1[h(Xi) 6= Yi].\nIn the notation of Algorithm 1, this is equivalent to\nerr(h, Sn) := 1\nn\n∑\n(Xi,Yi,1/Pi)∈Sn\n(1/Pi) · 1[h(Xi) 6= Yi] (1)\nwhere Sn ⊆ X × Y × R is the importance weighted sample collected by the algorithm. A basic property of these estimators is unbiasedness :\nE[f̂(Z1:n)] = 1\nn\nn∑\ni=1\nE[E[(Qi/Pi) · f(Xi, Yi) | X1:i, Y1:i, Q1:i−1]]\n= 1\nn\nn∑\ni=1\nE[(Pi/Pi) · f(Xi, Yi)]\n= E[f(X,Y )].\nSo, for example, the importance weighted empirical error of a hypothesis h is an unbiased estimator of its true error err(h). This holds for any choice of the rejection threshold that guarantees Pi > 0."
    }, {
      "heading" : "3 A Deviation Bound for Importance Weighted Estimators",
      "text" : "As mentioned before, the rejection threshold used by our algorithm is based on importance weighted error estimates err(h, Z1:n). Even though these estimates are unbiased, they are only reliable when the variance is not too large. To get a handle on this, we need a deviation bound for importance weighted estimators. This is complicated by two factors that rules out straightforward applications of some standard bounds:\n1. The importance weighted samples (Xi, Yi, 1/Pi) (or equivalently, the Zi = (Xi, Yi, Qi)) are not i.i.d. This is because the query probability Pi (and thus the importance weight 1/Pi) generally depends on Z1:i−1 and Xi.\n2. The effective range and variance of each term in the estimator are, themselves, random variables.\nTo address these issues, we develop a deviation bound using a martingale technique from [Zha05]. Let f : X × Y → [−1, 1] be a bounded function. Consider any rejection threshold function p : (X × Y × {0, 1})∗ ×X → (0, 1] for which Pn = p(Z1:n−1, Xn) is bounded below by some positive quantity (which may depend on n). Equivalently, the query probabilities Pn should have inverses 1/Pn bounded above by some deterministic quantity rmax (which, again, may depend on n). The a priori upper bound rmax on 1/Pn can be pessimistic, as the dependence on rmax in the final deviation bound will be very mild—it enters in as log log rmax. Our goal is to prove a bound on |f̂(Z1:n) − E[f(X,Y )]| that holds with high probability over the joint distribution of Z1:n.\nTo start, we establish bounds on the range and variance of each term Wi := (Qi/Pi) · f(Xi, Yi) in the estimator, conditioned on (X1:i, Y1:i, Q1:i−1). Let Ei[ · ] denote E[ · |X1:i, Y1:i, Q1:i−1]. Note that Ei[Wi] = (Ei[Qi]/Pi) · f(Xi, Yi) = f(Xi, Yi), so if Ei[Wi] = 0, then Wi = 0. Therefore, the (conditional) range and variance are non-zero only if Ei[Wi] 6= 0. For the range, we have |Wi| = (Qi/Pi)·|f(Xi, Yi)| ≤ 1/Pi, and for the variance, Ei[(Wi−Ei[Wi])2] ≤ (Ei[Q2i ]/P 2i ) ·f(Xi, Yi)2 ≤ 1/Pi. These range and variance bounds indicate the form of the deviations we can expect, similar to that of other classical deviation bounds.\nTheorem 1. Pick any t ≥ 0 and n ≥ 1. Assume 1 ≤ 1/Pi ≤ rmax for all 1 ≤ i ≤ n, and let Rn := 1/min({Pi : 1 ≤ i ≤ n ∧ f(Xi, Yi) 6= 0} ∪ {1}). With probability at least 1− 2(3 + log2 rmax)e−t/2,\n∣∣∣∣∣ 1 n n∑\ni=1\nQi Pi · f(Xi, Yi)− E[f(X,Y )] ∣∣∣∣∣ ≤ √ 2Rnt n + √ 2t n + Rnt 3n .\nWe defer all proofs to the appendices."
    }, {
      "heading" : "4 Algorithm",
      "text" : "First, we state a deviation bound for the importance weighted error of hypotheses in a finite hypothesis class H that holds for all n ≥ 1. It is a simple consequence of Theorem 1 and union bounds; the form of the bound motivates certain algorithmic choices to be described below.\nLemma 1. Pick any δ ∈ (0, 1). For all n ≥ 1, let\nεn := 16 log(2(3 + n log2 n)n(n+ 1)|H|/δ)\nn = O\n( log(n|H|/δ)\nn\n) . (3)\nLet (Z1, Z2, . . .) ∈ (X × Y × {0, 1})∗ be the sequence of random variables specified in Section 2.2 using a rejection threshold p : (X × Y × {0, 1})∗ × X → [0, 1] that satisfies p(z1:n, x) ≥ 1/nn for all (z1:n, x) ∈ (X × Y × {0, 1})n ×X and all n ≥ 1.\nThe following holds with probability at least 1− δ. For all n ≥ 1 and all h ∈ H,\n|(err(h, Z1:n)− err(h∗, Z1:n))− (err(h)− err(h∗))| ≤ √\nεn Pmin,n(h) + εn Pmin,n(h) (4)\nwhere Pmin,n(h) = min{Pi : 1 ≤ i ≤ n ∧ h(Xi) 6= h∗(Xi)} ∪ {1} .\nWe let C0 = O(log(|H|/δ)) ≥ 2 be a quantity such that εn (as defined in Eq. (3)) is bounded as εn ≤ C0 · log(n+1)/n. The following absolute constants are used in the description of the rejection threshold and the subsequent analysis: c1 := 5+2 √ 2, c2 := 5, c3 := ((c1+ √ 2)/(c1−2))2, c4 := (c1+ √ c3)\n2, c5 := c2+c3 .\nOur proposed algorithm is shown in Figure 1. The rejection threshold (Step 2) is based on the deviation bound from Lemma 1. First, the importance weighted error minimizing hypothesis hk and the “alternative” hypothesis h′k are found. Note that both optimizations are over the entire hypothesis class H (with h′k only being required to disagree with hk on xk)—this is a key aspect where our algorithm differs from previous approaches. The difference in importance weighted errors Gk of the two hypotheses is then computed. If Gk ≤ √ (C0 log k)/(k − 1) + (C0 log k)/(k − 1), then the query probability Pk is set to 1. Otherwise, Pk is set to the positive solution s to the quadratic equation in Eq. (2). The functional form of Pk is roughly\nmin { 1, O ( 1\nG2k +\n1\nGk\n) · C0 log k\nk − 1\n} .\nIt can be checked that Pk ∈ (0, 1] and that Pk is non-increasing with Gk. It is also useful to note that (log k)/(k − 1) is monotonically decreasing with k ≥ 1 (we use the convention log(1)/0 = ∞).\nIn order to apply Lemma 1 with our rejection threshold, we need to establish the (very crude) bound Pk ≥ 1/kk for all k.\nLemma 2. The rejection threshold of Algorithm 1 satisfies p(z1:n−1, x) ≥ 1/nn for all n ≥ 1 and all (z1:n−1, x) ∈ (X × Y × {0, 1})n−1 ×X .\nNote that this is a worst-case bound; our analysis shows that the probabilities Pk are more like 1/poly(k) in the typical case."
    }, {
      "heading" : "5 Analysis",
      "text" : ""
    }, {
      "heading" : "5.1 Correctness",
      "text" : "We first prove a consistency guarantee for Algorithm 1 that bounds the generalization error of the importance weighted empirical error minimizer. The proof actually establishes a lower bound on the query probabilities Pi ≥ 1/2 for Xi such that hn(Xi) 6= h∗(Xi). This offers an intuitive characterization of the weighting landscape induced by the importance weights 1/Pi.\nTheorem 2. The following holds with probability at least 1− δ. For any n ≥ 1,\n0 ≤ err(hn)− err(h∗) ≤ err(hn, Z1:n−1)− err(h∗, Z1:n−1) + √ 2C0 logn\nn− 1 + 2C0 logn n− 1 .\nThis implies, for all n ≥ 1,\nerr(hn) ≤ err(h∗) + √ 2C0 logn\nn− 1 + 2C0 logn n− 1 .\nTherefore, the final hypothesis returned by Algorithm 1 after seeing n unlabeled data has roughly the same error bound as a hypothesis returned by a standard passive learner with n labeled data. A variant of this result under certain noise conditions is given in the appendix."
    }, {
      "heading" : "5.2 Label Complexity Analysis",
      "text" : "We now bound the number of labels requested by Algorithm 1 after n iterations. The following lemma bounds the probability of querying the label Yn; this is subsequently used to establish the final bound on the expected number of labels queried. The key to the proof is in relating empirical error differences and their deviations to the probability of querying a label. This is mediated through the disagreement coefficient, a quantity first used by [Han07] for analyzing the label complexity of the A2 algorithm of [BBL06]. The disagreement coefficient θ := θ(h∗,H,D) is defined as\nθ(h∗,H,D) := sup { Pr(X ∈ DIS(h∗, r))\nr : r > 0\n}\nwhere DIS(h∗, r) := {x ∈ X : ∃h′ ∈ H such that Pr(h∗(X) 6= h′(X)) ≤ r and h∗(x) 6= h′(x)}\n(the disagreement region around h∗ at radius r). This quantity is bounded for many learning problems studied in the literature; see [Han07, Han09, Fri09, Wan09] for more discussion. Note that the supremum can instead be taken over r > ǫ if the target excess error is ǫ, which allows for a more detailed analysis.\nLemma 3. Assume the bounds from Eq. (4) holds for all h ∈ H and n ≥ 1. For any n ≥ 1,\nE[Qn] ≤ θ · 2 err(h∗) + O ( θ · √ C0 logn\nn− 1 + θ · C0 log\n2 n\nn− 1\n) .\nTheorem 3. With probability at least 1 − δ, the expected number of labels queried by Algorithm 1 after n iterations is at most\n1 + θ · 2 err(h∗) · (n− 1) +O ( θ · √ C0n logn+ θ · C0 log3 n ) .\nProof. Follows from assuming Y1 is always queried; applying Lemmas 1, 2, 3, and linearity of expectation.\nThe bound is dominated by a linear term scaled by err(h∗), plus a sublinear term. The linear term err(h∗) · n is unavoidable in the worst case, as evident from label complexity lower bounds [Kää06, BDL09]. When err(h∗) is negligible (e.g., the data is separable) and θ is bounded (as is the case for many problems studied in the literature [Han07]), then the bound represents a polynomial label complexity improvement over supervised learning, similar to that achieved by the version space algorithm from [BDL09]."
    }, {
      "heading" : "5.3 Analysis under Low Noise Conditions",
      "text" : "Some recent work on active learning has focused on improved label complexity under certain noise conditions [CN06, BBZ07, CN07, Han09, Kol09]. Specifically, it is assumed that there exists constants κ > 0 and 0 < α ≤ 1 such that Pr(h(X) 6= h∗(X)) ≤ κ · (err(h)− err(h∗))α (5) for all h ∈ H. This is related to Tsybakov’s low noise condition [Tsy04]. Essentially, this condition requires that low error hypotheses not be too far from the optimal hypothesis h∗ under the disagreement metric Pr(h∗(X) 6= h(X)). Under this condition, Lemma 3 can be improved, which in turn yields the following theorem.\nTheorem 4. Assume that for some value of κ > 0 and 0 < α ≤ 1, the condition in Eq. (5) holds for all h ∈ H. There is a constant cα > 0 depending only on α such that the following holds. With probability at least 1− δ, the expected number of labels queried by Algorithm 1 after n iterations is at most\nθ · κ · cα · (C0 logn)α/2 · n1−α/2.\nNote that the bound is sublinear in n for all 0 < α ≤ 1, which implies label complexity improvements whenever θ is bounded (an improved analogue of Theorem 2 under these conditions can be established using similar techniques). The previous algorithms of [Han09, Kol09] obtain even better rates under these noise conditions using specialized data dependent generalization bounds, but these algorithms also required optimizations over restricted version spaces, even for the bound computation."
    }, {
      "heading" : "6 Experiments",
      "text" : "Although agnostic learning is typically intractable in the worst case, empirical risk minimization can serve as a useful abstraction for many practical supervised learning algorithms in non-worst case scenarios. With this in mind, we conducted a preliminary experimental evaluation of Algorithm 1, implemented using a popular algorithm for learning decision trees in place of the required ERM oracle. Specifically, we use the J48 algorithm from Weka v3.6.2 (with default parameters) to select the hypothesis hk in each round k; to produce the “alternative” hypothesis h′k, we just modify the decision tree hk by changing the label of the node used for predicting on xk. Both of these procedures are clearly heuristic, but they are similar in spirit to the required optimizations. We set C0 = 8 and c1 = c2 = 1—these can be regarded as tuning parameters, with C0 controlling the aggressiveness of the rejection threshold. We did not perform parameter tuning with active learning although the importance weighting approach developed here could potentially be used for that. Rather, the goal of these experiments is to assess the compatibility of Algorithm 1 with an existing, practical supervised learning procedure."
    }, {
      "heading" : "6.1 Data Sets",
      "text" : "We constructed two binary classification tasks using MNIST and KDDCUP99 data sets. For MNIST, we randomly chose 4000 training 3s and 5s for training (using the 3s as the positive class), and used all of the 1902 testing 3s and 5s for testing. For KDDCUP99, we randomly chose 5000 examples for training, and another 5000 for testing. In both cases, we reduced the dimension of the data to 25 using PCA.\nTo demonstrate the versatility of our algorithm, we also conducted a multi-class classification experiment using the entire MNIST data set (all ten digits, so 60000 training data and 10000 testing data). This required modifying how h′k is selected: we force h ′\nk(xk) 6= hk(xk) by changing the label of the prediction node for xk to the next best label. We used PCA to reduce the dimension to 40."
    }, {
      "heading" : "6.2 Results",
      "text" : "We examined the test error as a function of (i) the number of unlabeled data seen, and (ii) the number of labels queried. We compared the performance of the active learner described above to a passive learner (one that queries every label, so (i) and (ii) are the same) using J48 with default parameters.\nIn all three cases, the test errors as a function of the number of unlabeled data were roughly the same for both the active and passive learners. This agrees with the consistency guarantee from Theorem 2. We note that this is a basic property not satisfied by many active learning algorithms (this issue is discussed further in [DH08]).\nIn terms of test error as a function of the number of labels queried (Figure 2), the active learner had minimal improvement over the passive learner on the binary MNIST task, but a substantial improvement over the passive learner on the KDDCUP99 task (even at small numbers of label queries). For the multiclass MNIST task, the active learner had a moderate improvement over the passive learner. Note that KDDCUP99 is far less noisy (more separable) than MNIST 3s vs 5s task, so the results are in line with the label complexity behavior suggested by Theorem 3, which states that the label complexity improvement may scale with the error of the optimal hypothesis. Also, the results from MNIST tasks suggest that the active learner may require an initial random sampling phase during which it is equivalent to the passive learner, and the advantage manifests itself after this phase. This again is consistent with the analysis (also\nsee [Han07]), as the disagreement coefficient can be large at initial scales, yet much smaller as the number of (unlabeled) data increases and the scale becomes finer."
    }, {
      "heading" : "7 Conclusion",
      "text" : "This paper provides a new active learning algorithm based on error minimization oracles, a departure from the version space approach adopted by previous works. The algorithm we introduce here motivates computationally tractable and effective methods for active learning with many classifier training algorithms. The overall algorithmic template applies to any training algorithm that (i) operates by approximate error minimization and (ii) for which the cost of switching a class prediction (as measured by example errors) can be estimated. Furthermore, although these properties might only hold in an approximate or heuristic sense, the created active learning algorithm will be “safe” in the sense that it will eventually converge to the same solution as a passive supervised learning algorithm. Consequently, we believe this approach can be widely used to reduce the cost of labeling in situations where labeling is expensive.\nRecent theoretical work on active learning has focused on improving rates of convergence. However, in some applications, it may be desirable to improve performance at much smaller sample sizes, perhaps even at the cost of improved rates as long as consistency is ensured. Importance sampling and weighting techniques like those analyzed in this work may be useful for developing more aggressive strategies with such properties."
    }, {
      "heading" : "A Proof of Deviation Bound for Importance Weighted Estimators",
      "text" : "The techniques here are mostly developed in [Zha05]; for completeness, we detail the proofs for our particular application. The first two lemmas establish a basic bound in terms of conditional moment generating functions.\nLemma 4. For all n ≥ 1 and all functionals Ξi := ξi(Z1:i),\nE [ exp ( n∑\ni=1\nΞi − n∑\ni=1\nlnEi[exp(Ξi)]\n)] = 1.\nProof. A straightforward induction on n.\nLemma 5. For all t ≥ 0, λ ∈ R, n ≥ 1, and functionals Ξi := ξi(Z1:i),\nPr ( λ n∑\ni=1\nΞi − n∑\ni=1\nlnEi[exp(λΞi)] ≥ t ) ≤ e−t.\nProof. The claim follows by Markov’s inequality and Lemma 4 (replacing Ξi with λΞi).\nIn order to specialize Lemma 5 for our purposes, we first analyze the conditional moment generating function of Wi − Ei[Wi]. Lemma 6. If 0 < λ < 3Pi, then\nlnEi[exp(λ(Wi − Ei[Wi]))] ≤ 1 Pi · λ\n2\n2(1− λ/(3Pi)) .\nIf Ei[Wi] = 0, then lnEi[exp(λ(Wi − Ei[Wi]))] = 0.\nProof. Let g(x) := (exp(x)−x−1)/x2 for x 6= 0, so exp(x) = 1+x+x2·g(x). Note that g(x) is non-decreasing. Thus,\nEi [exp(λ(Wi − Ei[Wi]))] = Ei [ 1 + λ(Wi − Ei[Wi]) + λ2(Wi − Ei[Wi])2 · g(λ(Wi − Ei[Wi])) ]\n= 1 + λ2 · Ei [ (Wi − Ei[Wi])2 · g(λ(Wi − Ei[Wi])) ] ≤ 1 + λ2 · Ei [ (Wi − Ei[Wi])2 · g(λ/Pi) ] = 1 + λ2 · Ei [ (Wi − Ei[Wi])2 ] · g(λ/Pi)\n≤ 1 + (λ2/Pi) · g(λ/Pi) where the first inequality follows from the range bound |Wi| ≤ 1/Pi and the second follows from variance bound Ei[(Wi −Ei[Wi])2] ≤ 1/Pi. Now the first claim follows from the definition of g(x), the facts exp(x)− x− 1 ≤ x2/(2(1− x/3)) for 0 ≤ x < 3 and ln(1 + x) ≤ x.\nThe second claim is immediate from the definition of Wi and the fact Ei[Wi] = f(Xi, Yi).\nWe now combine Lemma 6 and Lemma 5 to bound the deviation of the importance weighted estimator f̂(Z1:n) from (1/n) ∑n i=1 Ei[Wi]. Lemma 7. Pick any t ≥ 0, n ≥ 1, and pmin > 0, and let E be the (joint) event\n1\nn\nn∑\ni=1\nWi − 1\nn\nn∑\ni=1\nEi[Wi] ≥ √ 1\npmin · 2t n + 1 pmin · t 3n\nand min{Pi : 1 ≤ i ≤ n ∧ Ei[Wi] 6= 0} ≥ pmin. Then Pr(E) ≤ e−t.\nProof. With foresight, let\nλ := 3pmin ·\n√ 1\n3pmin · 2t3n\n1 + √\n1 3pmin · 2t3n .\nNote that 0 < λ < 3pmin. By Lemma 6 and the choice of λ, we have that if min{Pi : 1 ≤ i ≤ n ∧ Ei[Wi] 6= 0} ≥ pmin, then\n1\nnλ ·\nn∑\ni=1\nlnEi[exp(λ(Wi − Ei[Wi]))] ≤ 1 pmin · λ 2(1− λ/(3pmin)) =\n√ 1\npmin · t 2n\n(6)\nand t\nnλ =\n√ 1\npmin · t 2n + 1 pmin · t 3n . (7)\nLet E′ be the event that\n1 n ·\nn∑\ni=1\n(Wi − Ei[Wi])− 1\nnλ ·\nn∑\ni=1\nlnEi[exp(λ(Wi − Ei[Wi]))] ≥ t\nnλ\nand let E′′ be the event min{Pi : 1 ≤ i ≤ n ∧ Ei[Wi] 6= 0} ≥ pmin. Together, Eq. (6) and Eq. (7) imply E ⊆ E′ ∩E′′. And of course, E′ ∩ E′′ ⊆ E′, so Pr(E) ≤ Pr(E′ ∩ E′′) ≤ Pr(E′) ≤ e−t by Lemma 5.\nTo do away with the joint event in Lemma 7, we use the standard trick of taking a union bound over a geometric sequence of possible values for pmin.\nLemma 8. Pick any t ≥ 0 and n ≥ 1. Assume 1 ≤ 1/Pi ≤ rmax for all 1 ≤ i ≤ n, and let Rn := 1/min{Pi : 1 ≤ i ≤ n ∧ Ei[Wi] 6= 0} ∪ {1}. We have\nPr (∣∣∣∣∣ 1 n n∑\ni=1\nWi − 1\nn\nn∑\ni=1\nEi[Wi] ∣∣∣∣∣ ≥ √ 2Rnt n + Rnt 3n ) ≤ 2(2 + log2 rmax)e−t/2.\nProof. The assumption on Pi implies 1 ≤ Rn ≤ rmax. Let rj := 2j for −1 ≤ j ≤ m := ⌈log2 rmax⌉. Then\nPr\n( 1\nn\nn∑\ni=1\nWi − 1\nn\nn∑\ni=1\nEi[Wi] ≥ √ 2Rnt\nn +\nRnt\n3n\n)\n=\nm∑\nj=0\nPr\n( 1\nn\nn∑\ni=1\nWi − 1\nn\nn∑\ni=1\nEi[Wi] ≥ √ 2Rnt\nn +\nRnt\n3n ∧ rj−1 < Rn ≤ rj\n)\n≤ m∑\nj=0\nPr\n( 1\nn\nn∑\ni=1\nWi − 1\nn\nn∑\ni=1\nEi[Wi] ≥ √ 2rj−1t\nn +\nrj−1t\n3n ∧ Rn ≤ rj\n)\n=\nm∑\nj=0\nPr\n( 1\nn\nn∑\ni=1\nWi − 1\nn\nn∑\ni=1\nEi[Wi] ≥ √ 2rj(t/2)\nn +\nrj(t/2)\n3n ∧ Rn ≤ rj\n)\n≤ (2 + log2 rmax)e−t/2\nwhere the last inequality follows from Lemma 7. ReplacingWi with −Wi bounds the probability of deviations in the other direction in exactly the same way. The claim then follows by the union bound.\nProof of Theorem 1. By Hoeffding’s inequality and the fact |f(Xi, Yi)| ≤ 1, we have\nPr (∣∣∣∣∣ 1 n n∑\ni=1\nf(Xi, Yi)− E[f(X,Y )] ∣∣∣∣∣ ≥ √ 2t n ) ≤ 2e−t/2.\nSince Ei[Wi] = f(Xi, Yi), the claim follows by combining this and Lemma 8 with the triangle inequality and the union bound."
    }, {
      "heading" : "B Remaining Proofs",
      "text" : "In this section, we use the notation εk := C0 log(k + 1)/k.\nB.1 Proof of Lemma 2\nBy induction on n. Trivial for n = 1 (since p(empty sequence, x) = 1 for all x ∈ X ), so now fix any n ≥ 2 and assume as the inductive hypothesis pn−1 = p(z1:n−2, x) ≥ 1/(n − 1)n−1 for all (z1:n−2, x) ∈ (X × Y × {0, 1})n−2 × X . Fix any (z1:n−1, x) ∈ (X × Y × {0, 1})n−1 × X , and consider the error difference gn := err(h ′\nn, z1:n−1) − err(hn, z1:n−1) used to determine pn := p(z1:n−1, x). We only have to consider the case gn > √ εn−1 + εn−1. By the inductive hypothesis and triangle inequality, we have gn ≤ 2(n − 1)n−1. Solving the quadratic in Eq. (2) implies\n√ pn =\nc1 · √εn−1 + √ c21 · εn−1 + 4 · ( gn + (c1 − 1) · √εn−1 + (c2 − 1) · εn−1 ) · c2 · εn−1\n2 ( gn + (c1 − 1) · √εn−1 + (c2 − 1) · εn−1 )\n>\n√ 4 · ( gn + (c1 − 1) · √εn−1 + (c2 − 1) · εn−1 ) · c2 · εn−1\n2 ( gn + (c1 − 1) · √εn−1 + (c2 − 1) · εn−1 ) (dropping terms)\n=\n√ c2 · εn−1\ngn + (c1 − 1) · √εn−1 + (c2 − 1) · εn−1\n≥ √\nc2 · εn−1 gn + (c1 − 1) · √εn−1 + (c1 − 1) · εn−1 (since c2 ≤ c1)\n≥ √\nc2 · εn−1 c1 · gn (since gn > √ εn−1 + εn−1)\n=\n√ c2 · C0 logn\nc1 · (n− 1) · gn\n≥ √\nc2 · C0 logn 2c1 · (n− 1) · (n− 1)n−1 (inductive hypothesis)\n>\n√ 1\ne(n− 1)n (since C0 ≥ 2, n ≥ 2, and (c2 · C0 log 2)/(2c1) > 1/e)\n≥ √ 1\nnn (since (n/(n− 1))n ≥ e)\nas required.\nB.2 Proof of Theorem 2\nWe condition on the 1 − δ probability event that the deviation bounds from Lemma 1 hold (also using Lemma 2). The proof now proceeds by induction on n. The claim is trivially true for n = 1. Now pick any n ≥ 2 and assume as the (strong) inductive hypothesis that\n0 ≤ err(hk)− err(h∗) ≤ err(hk, Z1:k−1)− err(h∗, Z1:k−1) + √ 2εk−1 + 2εk−1 (8)\nfor all 1 ≤ k ≤ n− 1. We need to show Eq. (8) holds for k = n. Let Pmin := min{Pi : 1 ≤ i ≤ n − 1 ∧ hn(Xi) 6= h∗(Xi)} ∪ {1}. If Pmin ≥ 1/2, then Eq. (4) implies that Eq. (8) holds for k = n as needed. So assume for sake of contradiction that Pmin < 1/2, and let n0 := max{i ≤ n− 1 : Pi = Pmin ∧ hn(Xi) 6= h∗(Xi)}. By definition of Pn0 , we have\nerr(h′n0 , Z1:n0−1)− err(hn0 , Z1:n0−1) = (\nc1√ Pmin\n− c1 + 1 )√ εn0−1 + ( c2\nPmin − c2 + 1\n) εn0−1.\nUsing this fact together with the inductive hypothesis, we have\nerr(h′n0 , Z1:n0−1)− err(h∗, Z1:n0−1) = err(h′n0 , Z1:n0−1)− err(hn0 , Z1:n0−1) + err(hn0 , Z1:n0−1)− err(h∗, Z1:n0−1)\n≥ (\nc1√ Pmin\n− c1 + 1 ) · √εn0−1 + ( c2\nPmin − c2 + 1\n) · εn0−1 − √ 2εn0−1 − 2εn0−1\n= ( c1√ Pmin − c1 + 1− √ 2 ) · √εn0−1 + ( c2 Pmin − c2 − 1 ) · εn0−1 . (9)\nWe use the assumption Pmin < 1/2 to lower bound the righthand side to get the inequality\nerr(h′n0 , Z1:n0−1)− err(h∗, Z1:n0−1) > (c1 − 1) · ( √ 2− 1) · √εn0−1 + (c2 − 1) · εn0−1 > 0.\nwhich implies err(h′n0 , Z1:n0−1) > err(h ∗, Z1:n0−1). Since h ′ n0 minimizes err(h, Z1:n0−1) among hypotheses h ∈ H that disagree with hn0 on Xn0 , it must be that h∗ agrees with hn0 on Xn0 . By transitivity and the definition of n0, we conclude that hn(Xn0) = h ′\nn0(Xn0); so err(hn, Z1:n0−1) ≥ err(h′n0 , Z1:n0−1). Then err(hn, Z1:n−1)− err(h∗, Z1:n−1)\n≥ err(hn)− err(h∗)− √ 1\nPmin · εn−1 −\n1\nPmin · εn−1\n≥ err(hn, Z1:n0−1)− err(h∗, Z1:n0−1)− 2 · √ 1\nPmin · εn0−1 − 2 ·\n1\nPmin · εn0−1\n≥ (\nc1 − 2√ Pmin − c1 + 1− √ 2\n) · √εn0−1 + ( c2 − 2 Pmin − c2 − 1 ) · εn0−1\n> ( (c1 − 1) · ( √ 2− 1)− 2 √ 2 ) · √εn0−1 + (c2 − 5) · εn0−1\nwhere Eq. (4) is used in the first two inequalities, Eq. (9) and the fact err(hn, Z1:n0−1) ≥ err(h′n0 , Z1:n0−1) are used in the third inequality, and the fact Pmin < 1/2 is used in the last inequality. This final quantity is non-negative, so we have the contradiction err(hn, Z1:n−1) > err(h ∗, Z1:n−1).\nB.3 Proof of Lemma 3\nFirst, we establish a property of the query probabilities that relates error deviations (via Pmin) to empirical error differences (via Pn). Both quantities play essential roles in bounding the label complexity through the disagreement metric structure around h∗.\nLemma 9. Assume the bounds from Eq. (4) hold for all h ∈ H and n ≥ 1. For any n ≥ 1, we have Pn ≤ c3 · Pmin, where Pmin := min({Pi : 1 ≤ i ≤ n− 1 ∧ h(Xi) 6= h∗(Xi)} ∪ {1}) and\nh :=\n{ hn if hn disagrees with h\n∗ on Xn h′n if h ′ n disagrees with h ∗ on Xn.\n(10)\nProof. We can assume Pmin < 1/c3, since otherwise the claim is trivial. Pick any n0 ≤ n − 1 such that h(Xn0) 6= h∗(Xn0) and Pn0 = Pmin (such an n0 is guaranteed to exist given the above assumption). We now proceed as in the proof of Theorem 2. We first show a lower bound on err(h, Z1:n0−1) − err(h∗, Z1:n0−1). Note that\nerr(h′n0 , Z1:n0−1)− err(h∗, Z1:n0−1) = err(h′n0 , Z1:n0−1)− err(hn0 , Z1:n0−1) + err(hn0 , Z1:n0−1)− err(h∗, Z1:n0−1)\n≥ (\nc1√ Pmin\n− c1 + 1 ) · √εn0−1 + ( c2\nPmin − c2 + 1\n) · εn0−1 − √ 2εn0−1 − 2εn0−1\n= ( c1√ Pmin − c1 + 1− √ 2 ) · √εn0−1 + ( c2 Pmin − c2 − 1 ) · εn0−1 (11)\nwhere the inequality follows from Theorem 2. The righthand side is positive, so h∗ must disagree with h′n0 on Xn0 . By transitivity (recalling that h(Xn0) 6= h∗(Xn0)), h must agree with h′n0 on Xn0 . Therefore err(h, Z1:n0−1) − err(h′n0 , Z1:n0−1) ≥ 0, so the inequality in Eq. (11) holds with h in place of h′n0 on the lefthand side.\nNow err(h, Z1:n−1)−err(h∗, Z1:n−1) is related to err(h, Z1:n0−1)−err(h∗, Z1:n0−1) through err(h)−err(h∗) using the deviation bound from Eq. (4) (as well as the fact εn0−1 ≥ εn−1):\nerr(h, Z1:n−1)− err(h∗, Z1:n−1)\n≥ err(h, Z1:n0−1)− err(h∗, Z1:n0−1)− 2 · √ 1\nPmin · εn0−1 − 2 ·\n1\nPmin · εn0−1\n≥ (\nc1 − 2√ Pmin − c1 + 1− √ 2\n) · √εn−1 + ( c2 − 2 Pmin − c2 − 1 ) · εn−1 > 0. (12)\nIf h = hn, then err(h, Z1:n−1)− err(h∗, Z1:n−1) = err(hn, Z1:n−1)− err(h∗, Z1:n−1) ≤ 0 by the minimality of err(hn, Z1:n−1); this contradicts Eq. (12). Therefore it must be that h = h ′ n. In this case,\nerr(h, Z1:n−1)− err(h∗, Z1:n−1) ≤ err(h′n, Z1:n−1)− err(hn, Z1:n−1)\n= ( c1√ Pn − c1 + 1 ) · √εn−1 + ( c2 Pn − c2 + 1 ) · εn−1 (13)\nwhere the inequality follows from the minimality of err(hn, Z1:n−1), and the subsequent step follows from the definition of Pn. Combining the lower bound in Eq. (12) and the upper bound in Eq. (13) implies that\nc1√ Pn · √εn−1 + c2 Pn\n· εn−1 ≥ (\nc1 − 2√ Pmin − √ 2\n) · √εn−1 + ( c2 − 2 Pmin − 2 ) · εn−1.\nIt is easily checked that this implies Pn ≤ c3 · Pmin.\nProof of Lemma 3. Define h as in Eq. (10). By Lemma 9, we have min({Pi : 1 ≤ i ≤ n − 1 ∧ h(Xi) 6= h∗(Xi)} ∪ {1}) ≥ Pn/c3. We first show that\nerr(h)− err(h∗) ≤ err(h, Z1:n−1)− err(h∗, Z1:n−1) + √\nc3 Pn · εn−1 + c3 Pn · εn−1\n≤ √\nc4 Pn · √εn−1 + c5 Pn · εn−1. (14)\nThe first inequality follows from Eq. (4) and Lemma 9. For the second inequality, we consider two cases depending on h. If h = h′n, then we bound err(h, Z1:n−1) − err(h∗, Z1:n−1) from above by err(h′n, Z1:n−1)− err(hn, Z1:n−1) (by definition of h and minimality of err(hn, Z1:n−1)), and then simplify\nerr(h′n, , Z1:n−1)− err(hn, Z1:n−1) + √\nc3 Pn · εn−1 + c3 Pn · εn−1\n≤ ( c1 + √ c3√\nPn − c1 + 1\n) · √εn−1 + ( c2 + c3 Pn − c2 + 1 ) · εn−1 ≤ √ c4 Pn · √εn−1 + c5 Pn · εn−1\nusing the definition of Pn and the facts c1 ≥ 1 and c2 ≥ 1. If instead h = hn, then we use the facts err(h, Z1:n−1)− err(h∗, Z1:n−1) = err(hn, Z1:n−1)− err(h∗, Z1:n−1) ≤ 0 and c3 ≤ min{c4, c5}.\nIf err(h)− err(h∗) = γ > 0, then solving the quadratic inequality in Eq. (14) for Pn gives the bound\nPn ≤ min { 1, 3 2 · ( c4 γ2 + c5 γ ) · εn−1 } .\nIf err(h)− err(h∗) ≤ γ̄, then by the triangle inequality we have\nPr(h∗(X) 6= h(X)) ≤ err(h∗) + err(h) ≤ 2 err(h∗) + γ̄\nwhich in turn implies Xn ∈ DIS(h∗, 2 err(h∗)+ γ̄). Note that Pr(Xn ∈ DIS(h∗, 2 err(h∗)+ γ̄)) ≤ θ ·(2 err(h∗)+ γ̄) by definition of θ, so Pr(err(h)− err(h∗) ≤ γ̄) ≤ θ · (2 err(h∗) + γ̄).\nLet f(γ) := ∂ Pr(err(h)−err(h∗) ≤ γ)/∂γ be the probability density (mass) function of the error difference err(h)− err(h∗); note that this error difference is a function of (Z1:n−1, Xn). We compute the expected value of Qn by conditioning on err(h) − err(h∗) and integrating (an upper bound on) E[Qn| err(h)− err(h∗) = γ] with respect to f(γ).\nLet γ0 > 0 be the positive solution to 1.5(c4/γ 2+c5/γ)εn−1 = 1. It can be checked that γ0 > √ 1.5c4εn−1.\nWe have\nE[Qn] = E[E[Qn|Z1:n−1, Xn]] (the outer expectation is over (Z1:n−1, Xn))\n=\n∫ 1\n0\n( ∂\n∂γ Pr(err(h)− err(h∗) ≤ γ)\n) · E[Qn| err(h)− err(h∗) = γ] · dγ\n≤ ∫ 1\n0\n( ∂\n∂γ Pr(err(h)− err(h∗) ≤ γ)\n) ·min { 1, 3 2 · ( c4 γ2 + c5 γ ) · εn−1 } · dγ\n≤ 3 2 · (c4 + c5) · εn−1 · Pr(err(h)− err(h∗) ≤ 1)\n− ∫ 1\n0\n( ∂\n∂γ min\n{ 1, 3 2 · ( c4 γ2 + c5 γ ) · εn−1 }) · Pr(err(h)− err(h∗) ≤ γ) · dγ\n≤ 3 2 · (c4 + c5) · εn−1 +\n∫ 1\nγ0\n3 2 · ( 2c4 γ3 + c5 γ2 ) · εn−1 · θ · (2 err(h∗) + γ) · dγ\n= 3\n2 · (c4 + c5) · εn−1 + θ · 2 err(h∗) ·\n3 2 · ( c4 ( 1 γ20 − 1 ) + c5 ( 1 γ0 − 1 )) · εn−1\n+ θ · 3 2 · ( 2c4 ( 1 γ0 − 1 ) + c5 ln 1 γ0 ) · εn−1\n≤ 3 2 · (c4 + c5) · εn−1 + θ · 2 err(h∗) + θ ·\n√ 6c4εn−1 + θ ·\n3c5 4 · εn−1 · ln 1\n1.5c4εn−1\nwhere the first inequality uses the bound on E[Qn| err(h)−err(h∗) = γ]; the second inequality uses integrationby-parts; the third inequality uses the fact that the integrand from the previous line is 0 for 0 ≤ γ ≤ γ0, as well as the bound on Pr(err(h)− err(h∗) ≤ γ); and the fourth inequality uses the definition of γ0.\nB.4 Proof of Theorem 4\nThe theorem is a simple consequence of the following analogue of Lemma 3.\nLemma 10. Assume that for some value of κ > 0 and 0 < α ≤ 1, the condition in Eq. (5) holds for all h ∈ H. Assume the bounds from Eq. (4) holds for all h ∈ H and n ≥ 1. There is a constant cα > 0 such that the following holds. For any n ≥ 1,\nE[Qn] ≤ θ · κ · cα · ( C0 logn\nn− 1\n)α/2 .\nProof. For the most part, the proof is the same as that of Lemma 3. The key difference is to use the noise condition in Eq. (5) to directly bound Pr(h(X) 6= h∗(X)) ≤ κ · (err(h) − err(h∗))α, which in turn implies the bound Pr(err(h) − err(h∗) ≤ γ) ≤ θκγα. As before, let γ0 > √ 1.5c4εn−1 be the solution to\n1.5(c4/γ 2 + c5/γ)εn−1 = 1. First consider the case α < 1. Then, the expectation of Qn can be bounded as\nE[Qn] ≤ 3\n2 · (c4 + c5) · εn−1 +\n∫ 1\nγ0\n3 2 · ( 2c4 γ3 + c5 γ2 ) · εn−1 · Pr(err(h)− err(h∗) ≤ γ) · dγ\n≤ 3 2 · (c4 + c5) · εn−1 +\n∫ 1\nγ0\n3 2 · ( 2c4 γ3 + c5 γ2 ) · εn−1 · θκγα · dγ\n≤ 3 2 · (c4 + c5) · εn−1 + θ · κ · 3 2 · ( 2c4 2− α · 1\nγ2−α0 +\nc5 1− α · 1\nγ1−α0\n) · εn−1.\nThe case α = 1 is handled similarly.\nB.5 Analogue of Theorem 2 under Low Noise Conditions\nWe first state a variant of Lemma 1 that takes into account the probability of disagreement between a hypothesis h and the optimal hypothesis h∗.\nLemma 11. There exists an absolute constant c > 0 such that the following holds. Pick any δ ∈ (0, 1). For all n ≥ 1, let\nεn := c · log((n+ 1)|H|/δ)\nn .\nLet (Z1, Z2, . . .) ∈ (X × Y × {0, 1})∗ be the sequence of random variables specified in Section 2.2 using a rejection threshold p : (X × Y × {0, 1})∗ × X → [0, 1] that satisfies p(z1:n, x) ≥ 1/nn for all (z1:n, x) ∈ (X × Y × {0, 1})n ×X and all n ≥ 1.\nThe following holds with probability at least 1− δ. For all n ≥ 1 and all h ∈ H,\n|(err(h, Z1:n)− err(h∗, Z1:n))− (err(h)− err(h∗))| ≤ √\nPr(h(X) 6= h∗(X)) Pmin,n(h) · εn + εn Pmin,n(h)\nwhere Pmin,n(h) = min{Pi : 1 ≤ i ≤ n ∧ h(Xi) 6= h∗(Xi)} ∪ {1}.\nProof sketch. The proof of this lemma follows along the same lines as that of Lemma 1. A key difference comes in Lemma 7: the joint event is modified to also conjoin with\n1\nn\nn∑\ni=1\n1(Ei[f(Xi, Yi)] ≤ 0) ≤ a\nfor some fixed a > 0. In the proof, the parameter λ should be chosen as\nλ := 3pmin ·\n√ 1\n3pmin · 2at3n\na+ √\n1 3pmin · 2at3n .\nLemma 8 is modified to also take a union bound over a sequence of possible values for a (in fact, only n + 1 different values need to be considered). Finally, instead of combining with Hoeffding’s inequality, we use Bernstein’s inequality (or a multiplicative form of Chernoff’s bound) so the resulting bound (an analogue of Theorem 1) involves an empirical average inside the square-root term: with probability at least 1−O(n · log2 rmax)e−t/2,\n∣∣∣∣∣ 1 n n∑\ni=1\nQi Pi · f(Xi, Yi)− E[f(X,Y )] ∣∣∣∣∣ ≤ O (√ RnAnt n + Rnt 3n )\nwhere\nAn := 1\nn\nn∑\ni=1\n1(f(Xi, Yi) 6= 0).\nFinally, we apply this deviation bound to obtain uniform error bounds over all hypotheses H (a few extra steps are required to replace the empirical quantity An in the bound with a distributional quantity).\nUsing the previous lemma, a modified version of Theorem 2 follows from essentially the same proof. We note that the quantity C1 := O(log(|H|/δ)) used here may differ from C0 by constant factors.\nLemma 12. The following holds with probability at least 1− δ. For any n ≥ 1,\n0 ≤ err(hn)− err(h∗) ≤ err(hn, Z1:n−1)− err(h∗, Z1:n−1)\n+\n√ 2Pr(hn(X) 6= h∗(X))C1 logn\nn− 1 + 2C1 logn n− 1 .\nThis implies, for all n ≥ 1,\nerr(hn) ≤ err(h∗) + √\n2Pr(hn(X) 6= h∗(X))C1 logn n− 1 + 2C0 logn n− 1 .\nFinally, using the noise condition to bound Pr(hn(X) 6= h∗(X)) ≤ κ · (err(hn)− err(h∗))α, we obtain the final error bound.\nTheorem 5. The following holds with probability at least 1− δ. For any n ≥ 1,\nerr(hn) ≤ err(h∗) + cκ · ( C1 logn\nn− 1\n) 1 2−α\nwhere cκ is a constant that depends only on κ."
    } ],
    "references" : [ {
      "title" : "The nonstochastic multiarmed bandit problem",
      "author" : [ "P. Auer", "N. Cesa-Bianchi", "Y. Freund", "R.E. Schapire" ],
      "venue" : "SIAM Journal of Computing,",
      "citeRegEx" : "Auer et al\\.,? \\Q2002\\E",
      "shortCiteRegEx" : "Auer et al\\.",
      "year" : 2002
    }, {
      "title" : "Active learning for misspecified generalized linear models",
      "author" : [ "F. Bach" ],
      "venue" : "In Advances in Neural Information Processing Systems",
      "citeRegEx" : "Bach.,? \\Q2006\\E",
      "shortCiteRegEx" : "Bach.",
      "year" : 2006
    }, {
      "title" : "Agnostic active learning",
      "author" : [ "M.-F. Balcan", "A. Beygelzimer", "J. Langford" ],
      "venue" : "In Twenty-Third International Conference on Machine Learning,",
      "citeRegEx" : "Balcan et al\\.,? \\Q2006\\E",
      "shortCiteRegEx" : "Balcan et al\\.",
      "year" : 2006
    }, {
      "title" : "Margin based active learning",
      "author" : [ "M.-F. Balcan", "A. Broder", "T. Zhang" ],
      "venue" : "In Twentieth Annual Conference on Learning Theory,",
      "citeRegEx" : "Balcan et al\\.,? \\Q2007\\E",
      "shortCiteRegEx" : "Balcan et al\\.",
      "year" : 2007
    }, {
      "title" : "Importance weighted active learning",
      "author" : [ "A. Beygelzimer", "S. Dasgupta", "J. Langford" ],
      "venue" : "In Twenty-Sixth International Conference on Machine Learning,",
      "citeRegEx" : "Beygelzimer et al\\.,? \\Q2009\\E",
      "shortCiteRegEx" : "Beygelzimer et al\\.",
      "year" : 2009
    }, {
      "title" : "Improving generalization with active learning",
      "author" : [ "D. Cohn", "L. Atlas", "R. Ladner" ],
      "venue" : "Machine Learning,",
      "citeRegEx" : "Cohn et al\\.,? \\Q1994\\E",
      "shortCiteRegEx" : "Cohn et al\\.",
      "year" : 1994
    }, {
      "title" : "Upper and lower bounds for active learning",
      "author" : [ "R. Castro", "R. Nowak" ],
      "venue" : "In Allerton Conference on Communication, Control and Computing,",
      "citeRegEx" : "Castro and Nowak.,? \\Q2006\\E",
      "shortCiteRegEx" : "Castro and Nowak.",
      "year" : 2006
    }, {
      "title" : "Minimax bounds for active learning",
      "author" : [ "R. Castro", "R. Nowak" ],
      "venue" : "In Twentieth Annual Conference on Learning Theory,",
      "citeRegEx" : "Castro and Nowak.,? \\Q2007\\E",
      "shortCiteRegEx" : "Castro and Nowak.",
      "year" : 2007
    }, {
      "title" : "Coarse sample complexity bounds for active learning",
      "author" : [ "S. Dasgupta" ],
      "venue" : "In Advances in Neural Information Processing Systems",
      "citeRegEx" : "Dasgupta.,? \\Q2005\\E",
      "shortCiteRegEx" : "Dasgupta.",
      "year" : 2005
    }, {
      "title" : "Hierarchical sampling for active learning",
      "author" : [ "S. Dasgupta", "D. Hsu" ],
      "venue" : "In Twenty-Fifth International Conference on Machine Learning,",
      "citeRegEx" : "Dasgupta and Hsu.,? \\Q2008\\E",
      "shortCiteRegEx" : "Dasgupta and Hsu.",
      "year" : 2008
    }, {
      "title" : "A general agnostic active learning algorithm",
      "author" : [ "S. Dasgupta", "D. Hsu", "C. Monteleoni" ],
      "venue" : "In Advances in Neural Information Processing Systems",
      "citeRegEx" : "Dasgupta et al\\.,? \\Q2007\\E",
      "shortCiteRegEx" : "Dasgupta et al\\.",
      "year" : 2007
    }, {
      "title" : "Active learning for smooth problems",
      "author" : [ "E. Friedman" ],
      "venue" : "In Twenty-Second Annual Conference on Learning Theory,",
      "citeRegEx" : "Friedman.,? \\Q2009\\E",
      "shortCiteRegEx" : "Friedman.",
      "year" : 2009
    }, {
      "title" : "A bound on the label complexity of agnostic active learning",
      "author" : [ "S. Hanneke" ],
      "venue" : "In Twenty-Fourth International Conference on Machine Learning,",
      "citeRegEx" : "Hanneke.,? \\Q2007\\E",
      "shortCiteRegEx" : "Hanneke.",
      "year" : 2007
    }, {
      "title" : "Adaptive rates of convergence in active learning",
      "author" : [ "S. Hanneke" ],
      "venue" : "In Twenty-Second Annual Conference on Learning Theory,",
      "citeRegEx" : "Hanneke.,? \\Q2009\\E",
      "shortCiteRegEx" : "Hanneke.",
      "year" : 2009
    }, {
      "title" : "Active learning in the non-realizable case",
      "author" : [ "M. Kääriäinen" ],
      "venue" : "In Seventeenth International Conference on Algorithmic Learning Theory,",
      "citeRegEx" : "Kääriäinen.,? \\Q2006\\E",
      "shortCiteRegEx" : "Kääriäinen.",
      "year" : 2006
    }, {
      "title" : "Rademacher complexities and bounding the excess risk in active learning",
      "author" : [ "V. Koltchinskii" ],
      "venue" : null,
      "citeRegEx" : "Koltchinskii.,? \\Q2009\\E",
      "shortCiteRegEx" : "Koltchinskii.",
      "year" : 2009
    }, {
      "title" : "Reinforcement Learning: An Introduction",
      "author" : [ "R. .S. Sutton", "A.G. Barto" ],
      "venue" : null,
      "citeRegEx" : "Sutton and Barto.,? \\Q1998\\E",
      "shortCiteRegEx" : "Sutton and Barto.",
      "year" : 1998
    }, {
      "title" : "Covariate shift adaptation by importance weighted cross validation",
      "author" : [ "M. Sugiyama", "M. Krauledat", "K.-R. Müller" ],
      "venue" : "Journal of Machine Learning Research,",
      "citeRegEx" : "Sugiyama et al\\.,? \\Q2007\\E",
      "shortCiteRegEx" : "Sugiyama et al\\.",
      "year" : 2007
    }, {
      "title" : "Active learning for misspecified models",
      "author" : [ "M. Sugiyama" ],
      "venue" : "In Advances in Neural Information Processing Systems",
      "citeRegEx" : "Sugiyama.,? \\Q2005\\E",
      "shortCiteRegEx" : "Sugiyama.",
      "year" : 2005
    }, {
      "title" : "Optimal aggregation of classifiers in statistical learning",
      "author" : [ "A.B. Tsybakov" ],
      "venue" : "Annals of Statistics,",
      "citeRegEx" : "Tsybakov.,? \\Q2004\\E",
      "shortCiteRegEx" : "Tsybakov.",
      "year" : 2004
    }, {
      "title" : "Sufficient conditions for agnostic active learnable",
      "author" : [ "L. Wang" ],
      "venue" : "In Advances in Neural Information Processing Systems",
      "citeRegEx" : "Wang.,? \\Q2009\\E",
      "shortCiteRegEx" : "Wang.",
      "year" : 2009
    }, {
      "title" : "Data dependent concentration bounds for sequential prediction algorithms",
      "author" : [ "T. Zhang" ],
      "venue" : "In Eighteenth Annual Conference on Learning Theory,",
      "citeRegEx" : "Zhang.,? \\Q2005\\E",
      "shortCiteRegEx" : "Zhang.",
      "year" : 2005
    } ],
    "referenceMentions" : [ ],
    "year" : 2010,
    "abstractText" : "We present and analyze an agnostic active learning algorithm that works without keeping a version space. This is unlike all previous approaches where a restricted set of candidate hypotheses is maintained throughout learning, and only hypotheses from this set are ever returned. By avoiding this version space approach, our algorithm sheds the computational burden and brittleness associated with maintaining version spaces, yet still allows for substantial improvements over supervised learning for classification.",
    "creator" : "LaTeX with hyperref package"
  }
}