{
  "name" : "1312.1277.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : null,
    "authors" : [ "Robert Kleinberg", "Aleksandrs Slivkins", "Eli Upfal" ],
    "emails" : [ ],
    "sections" : [ {
      "heading" : null,
      "text" : "ar X\niv :1\n31 2.\n12 77\nv2 [\ncs .D\nS] 1\n9 N\nov 2\nIn this work we study a very general setting for the multi-armed bandit problem in which the strategies form a metric space, and the payoff function satisfies a Lipschitz condition with respect to the metric. We refer to this problem as the Lipschitz MAB problem. We present a solution for the multi-armed bandit problem in this setting. That is, for every metric space we define an isometry invariant which bounds from below the performance of Lipschitz MAB algorithms for this metric space, and we present an algorithm which comes arbitrarily close to meeting this bound. Furthermore, our technique gives even better results for benign payoff functions. We also address the full-feedback (“best expert”) version of the problem, where after every round the payoffs from all arms are revealed.\nACM Categories: F.2.2 [Analysis of Algorithms and Problem Complexity]: Nonnumerical Algorithms and Problems; F.1.2 [Computation by Abstract Devices]: Modes of Computation— Online computation\nKeywords: multi-armed bandits, regret, online learning, metric spaces, covering dimension, Lipschitz-continuity\n∗This manuscript is a merged and definitive version of Kleinberg, Slivkins, and Upfal (2008c) and Kleinberg and Slivkins (2010). Compared to the conference publications, the attached manuscript contains full proofs, and a significantly revised presentation that develops new terminology and modifies the proof outlines to unify the technical exposition of the two papers. The manuscript also features an updated discussion of the follow-up work and open questions. All results on the zooming algorithm and the max-min-covering dimension are from Kleinberg et al. (2008c); all results on regret dichotomies and on Lipschitz experts are from Kleinberg and Slivkins (2010). The respective full versions have appeared as technical reports on arxiv.org in September 2008 and November 2009.\n†Computer Science Department, Cornell University (Ithaca NY, USA) and Microsoft Research (Cambridge MA, USA). Email: rdk at cs.cornell.edu. Supported in part by NSF awards CCF-0643934 and CCF-0729102.\n‡Aleksandrs Slivkins, Microsoft Research (New York NY, USA). Email: slivkins at microsoft.com. Some of the work was done while the author was a postdoctoral research associate at Brown University.\n§Eli Upfal, Computer Science Department, Brown University (Providence RI, USA). Email: eli at cs.brown.edu. Supported in part by NSF awards CCR-0121154 and DMI-0600384, and ONR Award N000140610607."
    }, {
      "heading" : "1 Introduction",
      "text" : "In a multi-armed bandit problem, an online algorithm must iteratively choose from a set of possible strategies (also called “arms”) in a sequence of n trials so as to maximize the total payoff of the chosen strategies. These problems are the principal theoretical tool for modeling the exploration/exploitation tradeoffs inherent in sequential decision-making under uncertainty. Studied intensively for decades (Thompson, 1933; Robbins, 1952; Berry and Fristedt, 1985; Cesa-Bianchi and Lugosi, 2006; Gittins et al., 2011; Bubeck and Cesa-Bianchi, 2012), bandit problems are having an increasingly visible impact on computer science because of their diverse applications including online auctions, adaptive routing, and the theory of learning in games. The performance of a multi-armed bandit algorithm is often evaluated in terms of its regret, defined as the gap between the expected payoff of the algorithm and that of an optimal strategy. While the performance of bandit algorithms with a small finite strategy set is quite well understood, bandit problems with exponentially or infinitely large strategy sets are still a topic of very active investigation (see Bubeck and Cesa-Bianchi (2012) for a survey).\nAbsent any assumptions about the strategies and their payoffs, bandit problems with large strategy sets allow for no non-trivial solutions — any multi-armed bandit algorithm performs as badly, on some inputs, as random guessing. But in most applications it is natural to assume a structured class of payoff functions, which often enables the design of efficient learning algorithms Kleinberg (2005). In this paper, we consider a broad and natural class of problems in which the structure is induced by a metric on the space of strategies. While bandit problems have been studied in a few specific metric spaces (such as a one-dimensional interval) (Agrawal, 1995; Auer et al., 2007; Cope, 2009; Kleinberg, 2004; Pandey et al., 2007a), the case of general metric spaces has not been treated before, despite being an extremely natural setting for bandit problems.\nAs a motivating example, consider the problem faced by a website choosing from a database of thousands of banner ads to display to users, with the aim of maximizing the click-through rate of the ads displayed by matching ads to users’ characterizations and the web content that they are currently watching. Independently experimenting with each advertisement is infeasible, or at least highly inefficient, since the number of ads is too large. Instead, the advertisements are usually organized into a taxonomy based on metadata (such as the category of product being advertised) which allows a similarity measure to be defined. The website can then attempt to optimize its learning algorithm by generalizing from experiments with one ad to make inferences about the performance of similar ads (Pandey et al., 2007a,b).\nAnother motivating example is revenue-management problems (e.g., see (Kleinberg and Leighton, 2003; Besbes and Zeevi, 2009)). Consider a monopolistic seller with unlimited inventory of many digital products, such as songs, movies, or software. Customers arrive over time, and the seller can give customized offers to each arriving customer so as to maximize the revenue. The space of possible offers is very large, both in terms of possible product bundles and in terms of the possible prices, so experimenting with each and every offer is inefficient. Instead, the seller may be able to use experiments with one offer to make inferences about similar offers.\nAbstractly, we have a bandit problem of the following form: there is a strategy set X, with an unknown payoff function µ : X → [0, 1] satisfying a set of predefined constraints of the form |µ(x) − µ(y)| ≤ δ(x, y) for some x, y ∈ X and δ(x, y) > 0. In each period the algorithm chooses a point x ∈ X and receives payoff – a number in the [0, 1] interval – sampled independently from some distribution whose expectation is µ(x).\nA moment’s thought reveals that this abstract problem can be regarded as a bandit problem in a metric space. Specifically, define D(x, y) to be the infimum of the quantity ∑i δ(xi, xi+1)\nover all finite paths (x = x0, x1, . . . , xk = y) in X. Then D is a metric1 and the constraints |µ(x) − µ(y)| < δ(x, y) may be summarized by stating that µ is a Lipschitz function (of Lipschitz constant 1) on the metric space (X,D):\n|µ(x)− µ(y)| ≤ D(x, y) for all x, y ∈ X. (1)\nWe assume that an algorithm is given the metric space (X,D) as an input, with a promise that the payoff function µ satisfies (1). We refer to this problem as the Lipschitz MAB problem on (X,D), and we refer to the ordered triple (X,D, µ) as an instance of the Lipschitz MAB problem.2"
    }, {
      "heading" : "1.1 Prior work",
      "text" : "While our work is the first to treat the Lipschitz MAB problem in general metric spaces, special cases of the problem are implicit in prior work on the continuum-armed bandit problem (Agrawal, 1995; Auer et al., 2007; Cope, 2009; Kleinberg, 2004) — which corresponds to the space [0, 1] under the metric ℓ 1/d 1 , d ≥ 1 — and the experimental work on “bandits for taxonomies” (Pandey et al., 2007a), which corresponds to the case in which (X,D) is a tree metric.3 Also, Hazan and Megiddo (2007) considered a contextual bandit setting with a metric space on contexts rather than arms.\nBefore describing our results in greater detail, it is helpful to put them in context by recounting the nearly optimal bounds for the one-dimensional continuum-armed bandit problem, a problem first formulated in Agrawal (1995) and solved (up to logarithmic factors) by various authors (Auer et al., 2007; Cope, 2009; Kleinberg, 2004). In the following theorem and throughout this paper, the regret of a multi-armed bandit algorithm A running on an instance (X,D, µ) is defined to be the function RA(t) which measures the difference between its expected payoff at time t and the quantity t · supx∈X µ(x). The latter quantity is the expected payoff of always playing an arm x ∈ argmaxµ(x) if such arm exists. In regret-minimization, the main issue is typically how regret scales with t.\nTheorem 1.1 (Auer et al. (2007); Cope (2009); Kleinberg (2004)). For any d ≥ N, consider the Lipschitz MAB problem on ([0, 1], ℓ\n1/d 1 ), d ≥ 1. There is an algorithm whose regret on any instance\nµ satisfies R(t) = Õ(tγ) for every t, where γ = d+1d+2 . No such algorithm exists for any γ < d+1 d+2 .\nIn fact, if the time horizon t is known in advance, the upper bound in the theorem can be achieved by an extremely näıve algorithm which uses an optimal k-armed bandit algorithm, such as the UCB1 algorithm (Auer et al., 2002a), to choose arms from the set S = {0, 1k , 2k , . . . , 1}, for a suitable choice of the parameter k. Here the arms in S partition the strategy set in a uniform (and non-adaptive) way; hence, we call this algorithm UniformMesh."
    }, {
      "heading" : "1.2 Initial result",
      "text" : "We make an initial observation that the analysis of algorithm UniformMesh in Theorem 1.1 only relies on the covering properties of the metric space, rather than on its real-valued structure, and (with minor modifications) can be extended to any metric space of constant covering dimension d.\nTheorem 1.2. Consider the Lipschitz MAB problem on a metric space of covering dimension d ≥ 0. There is an algorithm whose regret on any instance µ satisfies R(t) = Õ(tγ) for every t, where γ = d+1d+2 .\n1More precisely, it is a pseudometric because some pairs of distinct points x, y ∈ X may satisfy D(x, y) = 0. 2 When the metric space (X,D) is understood from context, we may also refer to µ as an instance. 3Throughout the paper, ℓp, p ≥ 1 denotes a metric on a finite-dimensional real space given by ℓp(x, y) = ‖x− y‖p.\nThe covering dimension is a standard notion which summarizes covering properties of a metric space. It is defined as the smallest (infimum) number d ≥ 0 such that X can be covered by O(δ−d) sets of diameter δ, for each δ > 0. We denote it COV(X,D), or COV(X) when the metric D is clear from the context. The covering dimension generalizes the Euclidean dimension, in the sense that the covering dimension of ([0, 1]d, ℓp), p ≥ 1 is d. Unlike the Euclidean dimension, the covering dimension can take fractional values. Theorem 1.2 generalizes the upper bound in Theorem 1.1 because the covering dimension of ([0, 1], ℓ 1/d 1 ) is d, for any d ≥ 1."
    }, {
      "heading" : "1.3 Present scope",
      "text" : "This paper is a comprehensive study of the Lipschitz MAB problem in arbitrary metric spaces.\nWhile the regret bound in Theorem 1.1 is essentially optimal when the metric space is ([0, 1], ℓ 1/d 1 ),\nit is strikingly odd that it is achieved by such a simple algorithm as UniformMesh. In particular, the algorithm approximates the strategy set by a fixed mesh S and does not refine this mesh as it gains information about the location of the optimal arm. Moreover, the metric contains seemingly useful proximity information, but the algorithm ignores this information after choosing its initial mesh. Is this really the best algorithm?\nA closer examination of the lower bound proof raises further reasons for suspicion: it is based on a contrived, highly singular payoff function µ that alternates between being constant on some distance scales and being very steep on other (much smaller) distance scales, to create a multiscale “needle in haystack” phenomenon which nearly obliterates the usefulness of the proximity information contained in the metric ℓ 1/d 1 . Can we expect algorithms to do better when the payoff function is more benign?4 For the Lipschitz MAB problem on ([0, 1], ℓ1), the question was answered affirmatively in Cope (2009); Auer et al. (2007) for some classes of instances, with algorithms that are tuned to the specific classes.\nWe are concerned with the following two directions motivated by the discussion above:\n(Q1) Per-metric optimality. What is the best possible bound on regret for a given metric space? (Implicitly, such regret bound is worst-case over all payoff functions consistent with this metric space.) Is UniformMesh, as naive as it is, really an optimal algorithm? Is covering dimension an appropriate structure to characterize such worst-case regret bounds?\n(Q2) Benign problem instances. Is it possible to take advantage of benign payoff functions? What structures would be useful to characterize benign payoff functions and the corresponding better-than-worst-case regret bounds? What algorithmic techniques would help?\nTheorem 1.2 calibrates our intuition: for relatively “rich” metric spaces such as ([0, 1], ℓ 1/d 1 ) we expect regret bounds of the form Õ(tγ), for some constant γ ∈ (0, 1) which depends on the metric space, and perhaps also on the problem instance. Henceforth, we will call this polynomial regret. Apart from metric spaces that admit polynomial regret, we are interested in the extremes: metric spaces for which the Lipschitz MAB problem becomes very easy or very difficult.\nIt is known that one can achieve logarithmic regret as long as the number of arms is finite (Lai and Robbins, 1985; Auer et al., 2002a).5 On the other hand, all prior results for infinite metric spaces had regret O(tγ), γ ≥ 12 . We view problem instances with O(log t) regret as “very tractable”, and those with regret tγ , γ ≥ 12 , as “somewhat tractable”. It is natural to ask what is the transition between the two.\n4Here and elsewhere we use “benign” as a non-technical term. 5The constant in front of the log(t) increases with the number of arms and also depends on instance-specific\nparameters. O(log t) regret is optimal even for two arms (Lai and Robbins, 1985).\n(Q3) Is Õ( √ t) regret the best possible for an infinite metric space? Alternatively, are there infinite\nmetric spaces for which one can achieve regret O(log t)? Is there any metric space for which the best possible regret is between O(log t) and Õ( √ t)?\nOn the opposite end of the “tractability spectrum” of the Lipschitz MAB problem, there are metric spaces of infinite covering dimension, for which no algorithm can have regret of the form O(tγ), γ < 1. Intuitively, such metric spaces are intractable. Formally, will define “intractable” metric spaces is those that do not admit sub-linear regret.\n(Q4) Which metric spaces are tractable, i.e. admit o(t) regret?\nLipschitz experts. We are also interested in the full-feedback version of the Lipschitz MAB problem, which we call Lipschitz experts. For any MAB problem there exists a corresponding full-feedback version, where after each round the payoffs from all arms are revealed. (Formally, an algorithm can query any finite number of arms.) Such settings have been extensively studied in the online learning literature under the name best experts problems (Cesa-Bianchi et al., 1997; Cesa-Bianchi and Lugosi, 2006; Vovk, 1998). In particular, it is known that one can achieve constant regret for a finite set of arms (Kleinberg et al., 2008a), and Õ( √ t) regret for metric spaces of bounded covering dimension (Gupta et al., 2007). (The algorithm in Gupta et al. (2007) is a version of the UniformMesh.) To the best of our knowledge, no other results on the Lipschitz experts problem are known.\nFor Lipschitz experts, we are interested in per-metric optimality (Q1), including the extreme versions (Q3) and (Q4). For polynomial regret the goal is to handle metric spaces of infinite covering dimension. The necessary background and results are gathered in Section 6."
    }, {
      "heading" : "1.4 Our contributions: Lipschitz MAB problem",
      "text" : "We give a complete solution to (Q1), by describing for every metric space (X,D) a family of algorithms which come arbitrarily close to achieving the best possible regret bound for this metric space. In particular, we resolve (Q3) and (Q4). We also give a satisfactory answer to (Q2); our solution is arbitrarily close to optimal in terms of the zooming dimension defined below.\nUnderpinning these contributions is a new algorithm, called the zooming algorithm. It maintains a mesh of “active arms”, but (unlike UniformMesh) adapts this mesh to the observed payoffs. It combines the upper confidence bound technique used in earlier bandit algorithms such as UCB1 (Auer et al., 2002a) with a novel adaptive refinement step that uses past history to refine the mesh (“zoom in”) in regions with high observed payoffs. We show that the zooming algorithm can perform significantly better on benign problem instances. Moreover, it is a key ingredient in our design of a per-metric optimal bandit algorithm.\nBenign problem instances. For every problem instance (X,D, µ) we define a parameter called the zooming dimension, and use it to bound the performance of the zooming algorithm in a way that is often significantly stronger than the corresponding per-metric bound. Note that the zooming algorithm is self-tuning, i.e. it achieves this bound without requiring prior knowledge of the zooming dimension. Somewhat surprisingly, our regret bound for the zooming algorithm result has exactly the same “shape” as Theorem 1.2.\nTheorem 1.3. If d is the zooming dimension of a Lipschitz MAB instance then at any time t the zooming algorithm suffers regret Õ(tγ), where γ = d+1d+2 . Moreover, this is the best possible exponent γ as a function of d.\nWhile covering dimension is about covering the entire metric space, zooming dimension focuses on covering near-optimal arms. The lower bounds in Theorem 1.1 and Theorem 1.5 are based on contrived examples with a high-dimensional set of near-optimal arms which leads to the “needlein-the-haystack” phenomenon. We sidestep these examples if the set of near-optimal arms is lowdimensional, in the sense that we make formal below. We define the zooming dimension of an instance (X,D, µ) as the smallest d such that the following covering property holds: for every δ > 0 we require only O(δ−d) sets of diameter δ/8 to cover the set of arms whose expected payoff falls short of the optimum by an amount between δ and 2δ.\nZooming dimension is our way to quantify the benignness of a problem instance. It is trivially no larger than the covering dimension, and can be significantly smaller. Below let us give some examples:\n• Suppose a low-dimensional region S ⊂ X contains all arms with optimal or near-optimal payoffs. The zooming dimension of such problem instance is bounded from above by the covering dimension of S. For example, S can be a “thin” subtree of an infinitely deep tree.6\n• Suppose the metric space is ([0, 1], ℓ1/d1 ), d ∈ N, and the expected payoff of each arm x is determined by its distance from the best arm: µ(x) = max(0, µ∗ − D(x, x∗)) for some number µ∗ ∈ (0, 1] and some arm x∗. Then the zooming dimension is 0, whereas the covering dimension is d.\n• Suppose the metric space is ([0, 1]d, ℓ2), d ∈ N, and payoff function µ is C2-smooth. Assume µ has a unique maximum x∗ and is strongly concave in a neighborhood of x∗. Then the zooming dimension is d/2, whereas the covering dimension is d.\nIt turns out that the analysis of the zooming algorithm does not require the similarity function D to satisfy the triangle inequality, and needs only a relaxed version of the Lipschitz condition (1).\nTheorem 1.4 (Informal). The upper bound in Theorem 1.3 holds in a more general setting where the similarity function D does not satisfy the triangle inequality, and Lipschitz condition (1) is relaxed to hold only if one of the two arms is optimal.\nIn addition to the two theorems above, we apply the zooming algorithm to the following special cases, deriving improved or otherwise non-trivial regret bounds: (i) the maximal payoff is near 1, (ii) µ(x) = 1− f(D(x, S)), where S is a “target set” that is not revealed to the algorithm, (iii) the reward from playing each arm x is µ(x) plus an independent, benignly distributed noise.\nIn particular, we obtain an improved regret rate if the rewards are deterministic. This corollary is related to the literature on global Lipschitz optimization (e.g., see Floudas (1999)), and extends this literature by relaxing the Lipschitz assumption as in Theorem 1.4.\nWhile our definitions and results so far have been tailored to infinite strategy sets, they can be extended to the finite case as well. We use a more precise, non-asymptotic version of the zooming dimension, so that all results on the zooming algorithm are meaningful for both finite and infinite strategy sets.\nPer-metric optimality: full characterization. We are interested in per-metric optimal regret bounds: best possible regret bounds for a given metric space. We prove several theorems, which\n6Consider an infinitely deep rooted tree and let arms correspond to ends of the tree (i.e., infinite paths away from the root). The distance between two ends decreases exponentially in the height of their least common ancestor (i.e., the deepest vertex belonging to both paths). Suppose there is a subtree in which the branching factor is smaller than elsewhere in the tree. Then we can take S to be the set of ends of this subtree.\njointly provide a full characterization of per-metric optimal regret bounds for any given metric space (X,D). To state polynomial regret bounds in this characterization, we define a parameter of the metric space called max-min-covering dimension (MaxMinCOV). Our characterization is summarized in the table below.\nTable 1 should be interpreted as follows. We consider regret bounds with an instance-dependent constant, i.e. those of the form R(t) ≤ CI f(t), for some function f : N → R and a constant CI that can depend on the problem instance I; we denote this as R(t) = OI(f(t)). Let us say that the Lipschitz MAB problem on a given metric space is f(t)-tractable if there exists an algorithm whose regret satisfies R(t) = OI(f(t)). Then Lai and Robbins (1985); Auer et al. (2002a) show that the problem is log(t)-tractable if the metric space has finitely many points (here the instancedependent constant CI is essential), and not f(t)-tractable for any f(t) = o(log t). Thus, the first row of Table 1 reads O(log t) and o(log t), respectively; other rows should be interpreted similarly.\nIn what follows, we discuss the individual results which comprise the characterization in Table 1.\nPer-metric optimality: polynomial regret bounds. The definition of the max-min-covering dimension arises naturally as one tries to extend the lower bound from Kleinberg (2004) to general metric spaces. The min-covering dimension of a subset Y ⊂ X is the smallest covering dimension of any non-empty subset U ⊂ Y which is open in the metric topology of (Y,D). Further, the max-min-covering dimension of X, denoted MaxMinCOV(X), is the largest min-covering dimension of any subset Y ⊂ X. In a formula:\nMaxMinCOV(X) = sup Y⊂X\n(\ninf non-empty U ⊂ Y : U is open in (Y,D) COV(U)\n)\n.\nWe find that MaxMinCOV is precisely the right notion to characterize per-metric optimal regret.\nTheorem 1.5. Consider the Lipschitz MAB problem on a compact metric space with d = MaxMinCOV(X). If γ > d+1d+2 then there exists a bandit algorithm A such that for every problem instance I its regret satisfies R(t) = OI(tγ) for all t. No such algorithm exists if d > 0 and γ < d+1 d+2 .\nThe fact that the above result allows an instance-dependent constant makes the corresponding lower boundmuch more challenging: one needs to show that for any algorithm there exists a problem instance whose regret is at least tγ infinitely often, whereas without an instance-dependent constant it suffices to show this for any one time t.\nIn general MaxMinCOV(X) is bounded from above by the covering dimension of X. For metric spaces which are highly homogeneous, in the sense that any two ǫ-balls are isometric to one another, the two dimensions are equal, and the upper bound in the theorem can be achieved using a\ngeneralization of the UniformMesh algorithm described earlier. The difficulty in Theorem 1.5 lies in dealing with inhomogeneities in the metric space. It is important to treat the problem at this level of generality, because some of the most natural applications of the Lipschitz MAB problem, e.g. the web advertising problem described earlier, are based on highly inhomogeneous metric spaces. (That is, in web taxonomies, it is unreasonable to expect different categories at the same level of a topic hierarchy to have the roughly the same number of descendants.)\nThe simplest scenario in which we improve over Theorem 1.2 involves a point x ∈ X and a number ǫ > 0 such that cutting out any open neighborhood of x reduces the covering dimension by at least ǫ. We think of such x as a “fat point” in the metric space. This example can be extended to a “fat region” S ⊂ X such that COV(S) < COV(X) and cutting out any open superset of S reduces the covering dimension by at least ǫ. One can show that MaxMinCOV(X) ≤ max{COV(S), COV(X)−ǫ}.\nA “fat region” S becomes an obstacle for the zooming algorithm if it contains an optimal arm, in which case the algorithm needs to instantiate too many active arms in the vicinity of S. To deal with this, we impose a quota on the number of active arms outside S. The downside is that the set X \\ S is insufficiently covered by active arms. However, this downside does not have much impact on performance if an optimal arm lies in S. And if S does not contain an optimal arm then the zooming algorithm learns this fact eventually, in the sense that it stops refining the mesh of active arms on some open neighborhood U of S. From then on, the algorithm essentially limits itself to X \\ U , which is a comparatively low-dimensional set.\nThe general algorithm in Theorem 1.5 combines the above “quota-limited zooming” idea with a delicate decomposition of the metric space which gradually “peels off” regions with abnormally high covering dimension. In the above example with a “fat region” S, the decomposition consists of two sets, X and S. In general, the decomposition is a decreasing sequence of subsets X = S0 ⊃ S1 ⊃ . . . where each Si is a “fat region” with respect to Si−1. If the sequence is finite then the algorithm has a separate quota for each Si.\nFurther, to handle arbitrary metric spaces we allow this sequence to be infinite, and moreover transfinitely infinite, i.e. parameterized by ordinal numbers. The algorithm proceeds in phases. Each phase i begins by “guessing” an ordinal λ = λi that represents the algorithm’s estimate of the largest index of a set in the transfinite sequence that intersects the set of optimal arms. During a phase, the algorithm focuses on the set Sλ in the sequence, and has a quota on active arms not in Sλ. In the end of the phase it uses the observed payoffs to compute the next ordinal λi+1. The analysis of the algorithm shows that almost surely, the sequence of guesses λ1, λ2, . . . is eventually constant, and that the eventual value of this sequence is almost surely equal to the largest index of a set in the transfinite sequence that intersects the set of optimal arms. The regret bound then follows easily from our analysis of the zooming algorithm.\nFor the lower bound, we craft a new dimensionality notion (MaxMinCOV), which captures the inhomogeneity of a metric space, and connect this notion with the maximal possible “strength” of the transfinite decomposition. Further, we connect MaxMinCOV with the existence of a certain structure in the metric space (a ball-tree) which supports our lower-bounding example. This relation between the existence of two structures — d-dimensional transfinite decompositions and d-dimensional balltrees — is a new result on metric topology, and as such it may be of independent mathematical interest.\nWhile the lower bound is proved using the notion of Kullback-Leibler divergence (KL-divergence), our usage of the KL-divergence technique is encapsulated as a generic theorem statement (Theorem 5.7). A similar encapsulation (Theorem 7.12) is stated and proved for the full-feedback version. These theorems and the corresponding setup may be of independent interest. In particular, Theorem 5.7 has been used in Slivkins (2014) to encapsulate a version of the KL-divergence argument that underlies a lower bound on regret in a contextual bandit setting.\nPer-metric optimality: beyond polynomial regret. To resolve question (Q3), we show that the apparent gap between logarithmic and polynomial regret is inherent to the Lipschitz MAB problem.\nTheorem 1.6. For Lipschitz MAB on any fixed metric space (X,D), the following dichotomy holds: either it is f(t)-tractable for every f ∈ ω(log t), or it is not g(t)-tractable for any g ∈ o( √ t). In fact, the former occurs if and only if the metric completion of (X,D) is a compact metric space with countably many points.\nThus, we establish the log(t) vs. √ t regret dichotomy, and moreover show that it is determined by some of the most basic set-theoretic and topological properties of the metric space. For compact metric spaces, the dichotomy corresponds to the transition from countable to uncountable strategy sets. This is also surprising; in particular, it was natural to conjecture that if the dichotomy exists and admits a simple characterization, it would correspond to the finite vs. infinite transition.\nGiven the Ω(log t) lower bound in Lai and Robbins (1985), our upper bound for the Lipschitz MAB problem in compact, countable metric spaces is nearly the best possible bound for such spaces, modulo the gap between “f(t) = log t” and “∀f ∈ ω(log t)”. Furthermore, we show that this gap is inevitable for infinite metric spaces:\nTheorem 1.7. The Lipschitz MAB problem on any infinite metric space is not (log t)-tractable.\nTo answer question (Q4), we show that the tractability of the Lipschitz MAB problem on a complete metric space hinges on the compactness of the metric space.\nTheorem 1.8. The Lipschitz MAB problem on a fixed metric space (X,D) is f(t)-tractable for some f ∈ o(t) if and only if the metric completion of (X,D) is a compact metric space.\nThe main technical contribution in the above theorems is an interplay of online learning and point-set topology, which requires novel algorithmic and lower-bounding techniques. For the log(t) vs. √ t dichotomy result, we identify a simple topological property (existence of a topological wellordering) which entails the algorithmic result, and another topological property (perfectness) which entails the lower bound. The equivalence of the first property to countability and the second to uncountability (for compact metric spaces) follows from classical theorems of Cantor-Bendixson (Cantor, 1883) and Mazurkiewicz-Sierpinski (Mazurkiewicz and Sierpinski, 1920)."
    }, {
      "heading" : "1.5 Accessing the metric space",
      "text" : "In stating the theorems above, we have been imprecise about specifying the model of computation. In particular, we have ignored the thorny issue of how to provide an algorithm with an input describing a metric space which may have an infinite number of points. The simplest way to interpret our theorems is to ignore implementation details and interpret an “algorithm” to mean an abstract decision rule, i.e. a (possibly randomized) Borel-measurable function mapping the history of past observations to an arm x ∈ X which is played in the current period. All of our theorems are valid under this interpretation, but they can also be made into precise algorithmic results provided that the algorithm is given appropriate oracle access to the metric space.\nThe zooming algorithm requires only a covering oracle which takes a finite collection of open balls and either declares that they cover X or outputs an uncovered point. The algorithm poses only one oracle query in each round t, for a collection of at most t balls. (For infinite metric spaces of interest that admit a finite description, e.g. rational convex polytopes in Euclidean space, it is\ngenerally easy to implement a covering oracle given a description of the metric space.) The permetric optimal algorithm in Theorem 1.5 uses more complicated oracles, and we defer the definition of these oracles to Section 5.\nThe ω(log t)-regret algorithms for countably infinite metric spaces (Theorems 1.6 and 6.1) require an oracle which represents the well-ordering of the metric space. We also provide an extension for compact metric spaces with a finite number of limit points for which a more intuitive oracle access suffices. In fact, this extension holds for a much wider family of metric spaces: those with a finite Cantor-Bendixson rank, a classic notion from point-set topology."
    }, {
      "heading" : "1.6 Map of the paper",
      "text" : "We discuss related work in Section 2. In particular, there is a considerable amount of follow-up work, which we survey in Section 2.1. Preliminaries are presented in Section 3, including sufficient background on metric topology and dimensionality notions, and the proof of the initial observation (Theorem 1.2).\nIn the rest of the paper we present our technical results. Section 4 is on benign payoff functions: the zooming algorithm and extensions thereof. Section 5 is on the per-metric optimal algorithms with polynomial regret. Section 6 defines the full-feedback version (Lipschitz experts) and overviews our contributions. Section 7 is on the dichotomy between (sub)logarithmic and √ t regret. Section 8 studies for which metric spaces the Lipschitz bandits/experts problem is o(t)-tractable. Section 9 is on the polynomial-regret algorithms for Lipschitz experts. We conclude with directions for further work (Section 10).\nTo preserve the flow of the paper, some material is deferred to appendices. In Appendix A we present sufficient background on Kullback-Leibler divergence (KL-divergence) and the technical proofs which use the KL-divergence technique. In Appendix B we reduce the Lipschitz bandits/experts problem to that on complete metric spaces. In Appendix C we present a self-contained proof of a theorem from general topology, implicit in Cantor (1883); Mazurkiewicz and Sierpinski (1920), which ties together the upper and lower bounds of the regret dichotomy result. Finally, in Appendix D we flesh out an example from Section 6 (Lipschitz experts)."
    }, {
      "heading" : "2 Related work and follow-up work",
      "text" : "Multi-armed bandits. MAB problems have a long history; a thorough survey is beyond the scope of this paper. For background, a reader can refer to a book Cesa-Bianchi and Lugosi (2006) and a recent survey Bubeck and Cesa-Bianchi (2012) on regret-minimizing bandits. The Bayesian perspective (less relevant to the present paper) can be found in books and surveys (Bergemann and Välimäki, 2006; Gittins et al., 2011). On a very high level, there is a crucial distinction between regret-minimizing formulations and Bayesian/MDP formulations. Among regretminimizing formulations, an important distinction is between stochastic payoffs (Lai and Robbins, 1985; Auer et al., 2002a) and adversarial payoffs (Auer et al., 2002b).\nThis paper is on regret minimization with stochastic payoffs. The basic setting here is k < ∞ arms with no additional structure. Then the optimal regret is R(t) = O( √ kt), and R(t) = OI(log t) with an instance-dependent constant (Lai and Robbins, 1985; Auer et al., 2002b,a). Note that the distinction between regret rates with and without instance-dependent constants is inherent even in this basic bandit setting. The UCB1 algorithm (Auer et al., 2002a) achieves the OI(log t) bound and simultaneously matches the O( √ kt) bound up to a logarithmic factor.\nOur zooming algorithm relies on the “UCB index” technique from Auer et al. (2002a). This is a simple but very powerful idea: arms are chosen according to a numerical score, called index, which is defined as an upper confidence bound (UCB) on the expected payoff of a given arm. Thus, the UCB index can be represented as a sample average plus a confidence term, which represent, respectively, exploitation and exploration, so that the sum represents a balance between the two. Several papers (Audibert and Bubeck, 2010; Audibert et al., 2009; Honda and Takemura, 2010; Auer and Ortner, 2010; Maillard and Munos, 2011; Garivier and Cappé, 2011) designed improved versions of the UCB index for the k-armed MAB problem with stochastic payoffs, achieving regret bounds which are even closer to the lower bound. Moreover, the UCB index idea and various extensions thereof have been tremendously useful in many other settings with exploration-exploitation tradeoff, e.g. (Auer, 2002; Slivkins and Upfal, 2008; Kleinberg et al., 2008a; Wang et al., 2008; Bubeck and Munos, 2010; Slivkins, 2014; Abbasi-Yadkori et al., 2011; Babaioff et al., 2015a). It is worth noting that the zooming algorithm, as originally published in (Kleinberg et al., 2008c), was one of the first results in this line of work.\nMany papers enriched the basic MAB setting by assuming some structure on arms, typically in order to handle settings where the number of arms is very large or infinite. Most relevant to this paper is the work on continuum-armed bandits (Agrawal, 1995; Kleinberg, 2004; Auer et al., 2007), a special case of Lipschitz MAB where the metric space is ([0, 1], ℓ1). A closely related model posits that arms correspond to leaves on a tree, but no metric space is revealed to the algorithm (Kocsis and Szepesvari, 2006; Pandey et al., 2007a; Munos and Coquelin, 2007; Slivkins, 2011). Another commonly assumed structure is linear or convex payoffs, e.g. (Awerbuch and Kleinberg, 2008; Flaxman et al., 2005; Dani et al., 2007; Abernethy et al., 2008; Hazan and Kale, 2009). Linear/convex payoffs is a much stronger assumption than similarity, essentially because it allows to make strong inferences about far-away arms. Accordingly, it admits much stronger regret bounds, such as Õ(d √ t) for arms in Rd. Other structures in the literature include infinitely many i.i.d. arms (Berry et al., 1997; Wang et al., 2008), Gaussian Process Bandits (Srinivas et al., 2010; Krause and Ong, 2011; Desautels et al., 2012) and Functional bandits (Amin et al., 2011); Gaussian Process MAB and Functional MAB are discussed in more detail in Section 2.1.\nClosely related to continuum-armed bandits is the model of (regret-minimizing) dynamic pricing with unlimited supply (Blum et al., 2003; Kleinberg and Leighton, 2003). In this model, an algorithm is a seller with unlimited supply of identical items, such as a digital good (a movie, a song, or a program) that can be replicated at no cost. Customers arrive sequentially, and to each customer the algorithm offers one item at a non-negotiable price. Here prices correspond to arms, and accordingly the “arms” have a real-valued structure. Due to the discontinuous nature of demand (a customer who values the item at v will pay a price of v − ǫ but will pay nothing if offered a price of v + ǫ) dynamic pricing is not a special case of Lipschitz MAB, but there is a close relationship between the techniques that have been used to solve both problems. Moreover, when the distribution of customer values has bounded support and bounded probability density, the expected revenue is a Lipschitz function of the offered price, so regret-minimizing dynamic pricing in this case reduces to the Lipschitz MAB problem.7 One can also consider selling d > 1 products, offering a different price for each. When the expected revenue is a Lipschitz function of the offered price vector, this is a special case of Lipschitz MAB with arms in Rd.\nInterestingly, the dichotomy between (poly)logarithmic and √ t regret has appeared in four different MAB settings: Theorem 1.6 in this paper, k-armed bandits with stochastic payoffs (as mentioned above), bandits with linear payoffs (Dani et al., 2008), and an extension of MAB to\n7Some of the work on dynamic pricing, e.g. (Besbes and Zeevi, 2009; Wang et al., 2014), makes the Lipschitz assumption directly.\npay-per-click auctions (Babaioff et al., 2014; Devanur and Kakade, 2009; Babaioff et al., 2015b). These four dichotomy results have no obvious technical connection.\nMetric spaces and dimensionality notions. Algorithmic problems on metric spaces have a long history in many different domains. These domains include: constructing space-efficient and/or algorithmically tractable representations such as metric embeddings, distance labels, or distance oracles; problems with costs where costs have a metric structure, e.g. facility location and traveling salesman; offline and online optimization on a metric space; finding hidden structure in a metric space (classification and clustering).\nCovering dimension is closely related to several other notions of dimensionality of a metric space, such as Haussdorff dimension, capacity dimension, box-counting dimension, and MinkowskiBouligand Dimension. All these notions are used to characterize the covering properties of a metric space in fractal geometry; discussing fine distinctions between them is beyond our scope. A reader can refer to Schroeder (1991) for background.\nCovering numbers and covering dimension have been widely used in Machine Learning to characterize the complexity of the hypothesis space: a space of functions over X, the domain for which the learner needs to predict or classify, under functional ℓ2 norm and some distribution over X. This is different from the way covering numbers and similar notions are used in the context of the Lipschitz MAB problem, and we are not aware of a clear technical connection.8 Non-metric notions to characterize the complexity of function classes include VC-dimension, fat-shattering dimension, and Rademacher averages; see Shalev-Shwartz and Ben-David (2014) for background.\nVarious notions of dimensionality of metric spaces have been studied in the theoretical computer science literature, with a goal to arrive at (more) algorithmically tractable problem instances. The most popular notions have been the ball-growth dimension, e.g. (Karger and Ruhl, 2002; Hildrum et al., 2004; Abraham and Malkhi, 2005; Slivkins, 2007b), and the doubling dimension, e.g. (Gupta et al., 2003; Talwar, 2004; Kleinberg et al., 2009; Slivkins, 2007a; Mendel and Har-Peled, 2005; Chan et al., 2005). These notions have been useful in many different problems, including metric embeddings, other space-efficient representations such as distance labels and sparse spanners, network primitives such as routing schemes and distributed hash tables, and approximation algorithms for various optimization problems such as traveling salesman, k-median, and facility location."
    }, {
      "heading" : "2.1 Follow-up work",
      "text" : "Since the conference publication of Kleinberg et al. (2008c) there has been a considerable amount of follow-up work on Lipschitz MAB and various extensions thereof.\nImmediate extensions. Bubeck et al. (2011a) obtain an extension of Theorem 1.3 similar to Theorem 1.4: essentially the same regret bound under a similar, but technically different relaxation of the Lipschitz condition.9 They also obtain stronger regret bounds for some special cases; these extensions are similar in spirit to the extended analysis of the zooming algorithm in this paper (but\n8In the Lipschitz MAB problem, one is interested in the family F of all Lipschitz-continuous functions on (X,D), and therefore one could consider the covering numbers for F , or use any other standard notions such as VC-dimension or fat-shattering dimension. However, we have not been able to reach useful results with this approach.\n9Theorems 1.3 and 1.4 have appeared in Kleinberg et al. (2008c), which predates the conference publication of Bubeck et al. (2011a). (Theorem 1.4 and other extensions are briefly mentioned in the conference version, and fleshed out in the full version (Kleinberg et al., 2008b).) To the best of our understanding, Bubeck et al. (2011a) is a followup work with respect to Theorem 1.3 and independent work with respect to Theorem 1.4 and other extensions of the zooming algorithm.\ntechnically different). The results in Bubeck et al. (2011a) use a different algorithm and the proof techniques appear different.\nWhile our lower bound for “benign” problem instances (in Theorem 1.3) comes from the worstcase scenario when the zooming dimension equals the covering dimension, Slivkins (2014) and Magureanu et al. (2014) provide more refined, instance-dependent lower bounds. Slivkins (2014) proves that the upper bound in Theorem 4.4 is tight, up to O(log2 t) factors, for every value of the said upper bound.10 Magureanu et al. (2014) focus on regret bounds of the form C · log(t) +O(1), where C depends on the problem instance, but not on time. They derive a lower bound on the C, and provide an algorithm which comes arbitrarily close to this lower bound.\nContextual Lipschitz MAB and applications. Lu et al. (2010) and Slivkins (2014) (simultaneous and independent w.r.t. one another) extend Lipschitz MAB to the contextual bandit setting, where in each round the algorithm receives a context (“hint”) h and picks an arm x, and the expected payoff is a function of both h and x. The motivational examples include placing ads on webpages (webpages and/or users are contexts, ads are arms), serving documents to users (users are contexts, documents are arms), and offering prices to customers (customers are contexts, prices are arms). The similarity information is expressed as a metric on contexts and a metric on arms, with the corresponding two Lipschitz conditions. Lu et al. (2010) consider this setting and extend UniformMesh to obtain regret bounds in terms of the covering dimensions of the two metric spaces. Slivkins (2014) extends the zooming algorithm to the contextual setting and obtains improved regret bounds in terms of a suitable “contextual” version of the zooming dimension.\nThe “contextual zooming algorithm” from Slivkins (2014) works in a more general setting where similarity information is represented as a metric space on the set of “allowed” context-arm pairs, and the expected payoff function is Lipschitz with respect to this metric space. This is a very versatile setting: it can also encode sleeping bandits (Blum, 1997; Blum and Mansour, 2007; Freund et al., 1997; Kleinberg et al., 2008a) (in each round, some arms are “asleep”, i.e. not available) and slowly changing payoffs (Slivkins and Upfal, 2008) (here in each round t the context is t itself, and the metric on contexts expresses the constraint how fast the expected payoffs can change). This setting showcases the full power of the adaptive refinement technique which underlies the zooming algorithm.\nFurther, Slivkins et al. (2013) use the zooming algorithm from this paper and its contextual version from Slivkins (2014) in the context of ranked bandits (Radlinski et al., 2008). Here in each round a bandit algorithm chooses an ordered list of k documents (from a much larger pool of available documents) and presents it to a user who scrolls the list top-down and clicks on the first document that she finds relevant. The user may leave after the first click; the goal is to minimize the number of users with no clicks. The contribution of (Slivkins et al., 2013) is to combine ranked bandits with Lipschitz MAB; among other things, this requires a significantly extended model: if two documents are close in the metric space, their click probabilities are similar even conditional on the event that some other documents are not clicked by the current user.\nPartial similarity information. A number of papers tackle the issue that the numerical similarity information required for the Lipschitz MAB problem may be difficult to obtain in practice. These papers make various assumptions on what is and is not revealed to the algorithm, with a general goal to do (almost) as well as if the full metric space were known. Bubeck et al. (2011b) study a version with strategy set [0, 1]d and Lipschitz constant that is not revealed, and match the optimal regret rate for algorithms that know the Lipschitz constant. Minsker (2013) considers the same strategy set and distance function of the form ‖x − y‖β∞, where the smoothness parameter 10In fact, this lower bound extends to the contextual bandit setting.\nβ ∈ (0, 1] is not known. (Slivkins, 2011; Munos, 2011; Bull, 2015; Valko et al., 2013) study a version in which the algorithm only inputs a “taxonomy” on arms (i.e., a tree whose leaves are arms), whereas the numerical similarity information is not revealed at all. This version features a second exploration-exploitation tradeoff: the tradeoff between learning more about the numerical similarity information (or some relevant portions thereof), and exploiting this knowledge to run a Lipschitz MAB algorithm.\nThe latter line of work proceeds as follows. Slivkins (2011) considers the metric space implicitly defined by the taxonomy, where the distance between any two arms is the maximal difference in expected rewards in the least common subtree. He puts forward an extension of the zooming algorithm which adaptively reconstructs the implicit metric space, and (under some additional assumptions) essentially matches the performance of the zooming algorithm on the same metric space. Munos (2011) and Valko et al. (2013) allow a more general relation between the implicit metric space and the taxonomy, and moreover relax the Lipschitz condition to only hold w.r.t. the maximum (as in Theorem 4.3). Munos (2011) focuses on deterministic rewards, and essentially matches the regret bound in Corollary 4.16, whereas Valko et al. (2013) study the general IID case. Finally, Bull (2015) considers a somewhat more general setting with multiple taxonomies on arms (or with arms embedded in [0, 1]d, where the embedding is then used to define the taxonomies). The paper extends and refines the algorithm from Slivkins (2011), and carefully traces out the conditions under which one can achieve Õ( √ T ) regret. Munos (2014) surveys some of this work, with emphasis on the techniques from (Bubeck et al., 2011a; Munos, 2011; Valko et al., 2013). As a stepping stone to the result mentioned above, Munos (2011) considers Lipschitz MAB with deterministic rewards and essentially recovers our result for this setting (Corollary 4.16). 11\nBeyond IID rewards. Several papers (Azar et al., 2014; Maillard and Munos, 2010; Slivkins, 2014) consider Lipschitz bandits/experts with non-IID rewards.12 Azar et al. (2014) consider a version of Lipschitz MAB in which the IID condition is replaced by more sophisticated ergodicity and mixing assumptions, and essentially recover the performance of the zooming algorithm. Maillard and Munos (2010) consider Lipschitz experts in a Euclidean space (Rd, ℓ2) of constant dimension d. Assuming the Lipschitz condition on realized payoffs (rather than expected payoffs), they achieve a surprisingly strong regret of O( √ t). Slivkins (2014) considers contextual bandits with Lipschitz condition on expected payoffs, and provides a “meta-algorithm” which uses an offthe-shelf bandit algorithm such as EXP3 (Auer et al., 2002b) as a subroutine and adaptively refines the space of contexts. Also, as discussed above, the contextual zoooming algorithm from Slivkins (2014) can handle Lipschitz MAB with slowly changing rewards.\nOther structural models of MAB. One drawback of Lipschitz MAB as a model is that D(x, y) only gives a worst-case notion of similarity between arms x and y: a hard upper bound on |µ(x) − µ(y)| rather than a typical or expected upper bound. In particular, the distances may need to be very large in order to accommodate a few outliers, which would make D less informative elsewhere.13 With this criticism in mind, Srinivas et al. (2010) define a probabilistic model, called Gaussian Processes Bandits, where the expected payoff function is distributed according to a suitable Gaussian Process on X, thus ensuring a notion of “probabilistic smoothness” with respect to X. Further work in this model includes Krause and Ong (2011) and Desautels et al. (2012).\n11Corollary 4.16 is implicit in the original publication of (Kleinberg et al., 2008c,b), which predates (Munos, 2011). To the best of our understanding, the result in Munos (2011) is an independent work relative to that publication.\n12The first result in this direction appeared in Kleinberg (2004). He considers Lipschitz MAB with adversarial rewards, and proposes a version of UniformMesh where an adversarial bandit algorithm is used instead of UCB1. This algorithm achieves the same worst-case regret as UniformMesh on IID rewards.\n13This concern is partially addressed by Theorem 1.4.\nGiven the work on Lipschitz MAB (and other “structured” bandit models such as linear payoffs) it is tempting to consider MAB with arbitrary known structure on payoff functions. Amin et al. (2011) initiate this direction: in their model, the structure is explicitly represented as the collection of all possible payoff functions. However, their results do not subsume any prior work on Lipschitz MAB or MAB with linear or convex payoffs.\nFurther applications of our techniques. Ho et al. (2014) design a version of the zooming algorithm in the context of crowdsourcing markets. Here the algorithm is an employer who offers a quality-contingent contract to each arriving worker, and adjusts the contract over time. This is an MAB problem in which arms are contracts (essentially, vectors of prices), and a single round is modeled as a standard “principal-agent model” from contract theory. Ho et al. (2014) do not assume a Lipschitz condition, or any other explicit guarantee on similarity between arms. Instead, their algorithm estimates the similarity information on the fly, taking advantage of the structure provided by the principal-agent model.14\nOn a final note, one of our minor results – the improved confidence radius from Section 4.2 – may be of independent interest. In particular, this result is essential for some of the main results in (Babaioff et al., 2015a; Badanidiyuru et al., 2013; Agrawal and Devanur, 2014), in the context of dynamic pricing and other MAB problems with global supply/budget constraints."
    }, {
      "heading" : "3 Preliminaries",
      "text" : "This section contains various definitions which make the paper essentially self-contained (the only exception being ordinal numbers). In particular, the paper uses notions from General Topology which are typically covered in any introductory text or course on the subject."
    }, {
      "heading" : "3.1 Problem formulation and notation",
      "text" : "In the Lipschitz MAB problem, the problem instance is a triple (X,D, µ), where (X,D) is a metric space and µ : X → [0, 1] is a a Lipschitz function on (X,D) with Lipschitz constant 1. (In other words, µ satisfies Lipschitz condition (1)). (X,D) is revealed to an algorithm, whereas µ is not. In each round the algorithm chooses a strategy x ∈ X and receives payoff f(x) ∈ [0, 1] chosen independently from some distribution Px with expectation µ(x). Without loss of generality, the diameter of (X,D) is at most 1.\nThroughout the paper, (X,D) and µ will denote, respectively, a metric space of diameter ≤ 1 and a Lipschitz function as above. We will say that X is the set of strategies (“arms”), D is the similarity function, and µ is the payoff function.\nPerformance of an algorithm is measured via regret with respect to the best fixed strategy:\nR(t) = t sup x∈X\nµ(x)− E [ t ∑\ns=1\nµ(xs)\n]\n, (2)\nwhere xt ∈ X is the strategy chosen by the algorithm in round t. Note that when the supremum is attained, the first summand in (2) is the expected reward of an algorithm that always plays the best strategy.\n14(Slivkins, 2011; Bull, 2015; Valko et al., 2013) estimate the “hidden” similarity information for a general Lipschitz MAB setting (using some additional assumptions), but Ho et al. (2014) uses a different, problem-specific approach which side-steps some of the assumptions.\nThroughout the paper, the constants in theO(·) notation are absolute unless specified otherwise. The notation Osubscript means that the constant in O() can depend on the things listed in the subscript. Denote sup(µ,X) = supx∈X µ(x) and similarly argmax(µ,X) = argmaxx∈X µ(x)."
    }, {
      "heading" : "3.2 Metric topology and set theory",
      "text" : "Let X be a set and let (X,D) be a metric space. An open ball of radius r around point x ∈ X is B(x, r) = {y ∈ X : D(x, y) < r}. The diameter of a set is the maximal distance between any two points in this set.\nA Cauchy sequence in (X,D) is a sequence such that for every δ > 0, there is an open ball of radius δ containing all but finitely many points of the sequence. We say X is complete if every Cauchy sequence has a limit point in X. For two Cauchy sequences x = (x1, x2, . . .) and y = (y1, y2, . . .) the distance d(x,y) = limi→∞ d(xi, yi) is well-defined. Two Cauchy sequences are declared to be equivalent if their distance is 0. The equivalence classes of Cauchy sequences form a metric space (X∗,D) called the (metric) completion of (X,D). The subspace of all constant sequences is identified with (X,D): formally, it is a dense subspace of (X∗,D) which is isometric to (X,D). A metric space (X,D) is compact if every collection of open balls covering (X,D) has a finite subcollection that also covers (X,D). Every compact metric space is complete, but not vice-versa.\nA family F of subsets ofX is called a topology if it contains ∅ andX and is closed under arbitrary unions and finite intersections. When a specific topology is fixed and clear from the context, the elements of F are called open sets, and their complements are called closed sets. Throughout this paper, these terms will refer to the metric topology of the underlying metric space, the smallest topology that contains all open balls (namely, the intersection of all such topologies). A point x is called isolated if the singleton set {x} is open. A function between topological spaces is continuous if the inverse image of every open set is open.\nA well-ordering on a set X is a total order on X with the property that every non-empty subset of X has a least element in this order. In Section 9.3.2 we use ordinals, a.k.a. ordinal numbers, a class of well-ordered sets that, in some sense, extends natural numbers beyond infinity. Understanding this paper requires only the basic notions about ordinals, namely the standard (von Neumann) definition of ordinals, successor and limit ordinals, and transfinite induction. The necessary material can be found in any introductory text on Mathematical Logic and Set Theory, and also on Wikipedia."
    }, {
      "heading" : "3.3 Dimensionality notions",
      "text" : "Throughout this paper we will use various notions of dimensionality of a metric space. The basic notion will be the covering dimension, which is a version of the fractal dimension that is based on covering numbers. We will also use several refinements of the covering dimension that are tuned to the Lipschitz MAB problem.\nDefinition 3.1. Let Y be a set of points in a metric space (X,D). For each r > 0, an r-covering of Y is a collection of subsets of Y , each of diameter strictly less than r, that cover Y . The minimal number of subsets in an r-covering is called the r-covering number of Y and denoted Nr(Y ). The covering dimension of Y with multiplier c, denoted COVc(Y ), is the infimum of all d ≥ 0 such that Nr(Y ) ≤ c r−d for each r > 0. This definition is robust : Nr(Y\n′) ≤ Nr(Y ) for any Y ′ ⊂ Y , and consequently COVc(Y ′) ≤ COVc(Y ). While covering numbers are often defined via radius-r balls rather than diameter-r sets, the former alternative does not have this appealing “robustness” property.\nRemark. Fractal dimensions of infinite spaces are often defined using lim sup as the distance scale tends to 0. The lim sup-version of the covering dimension would be\nCOV(Y ) , lim sup r→0\nlogNr(Y )\nlog 1/r (3)\n= inf { d ≥ 0 : ∃c ∀r > 0 N(r) ≤ cr−d }\n= lim c→∞ COVc(Y ).\nThis definition is simpler in that it does not require an extra parameter c. However, it hides an arbitrarily large constant, and is uninformative for finite metric spaces. On the contrary, the version in Definition 3.1 makes the constant explicit (which allows for numerically sharper bounds), and is meaningful for both finite and infinite metric spaces.\nRemark. Instead of the covering-based notions in Definition 3.1 one could define and use the corresponding packing-based notions. A subset S ⊂ Y is an r-packing of Y if the distance between any two points in S is at least r. An r-net of Y is a set-wise maximal r-packing; equivalently, S is an r-net if and only if it is an r-packing and the balls B(x, r), x ∈ S cover Y . The maximal number of points of an r-packing is called the r-packing number of Y and denoted N pack r (Y ). The “packing dimension” can then be defined as in Definition 3.1. It is a well-known folklore result that the packing and covering notions are closely related:\nFact 3.2. N2r(Y ) ≤ Npackr (Y ) ≤ Nr(Y ). Proof. Suppose the maximal size of an r-packing is finite, and let S be an r-packing of this size. First, for any r-covering {Yi}, each set Yi can contain at most one point in S, and each point in S is contained in some Yi. So the r-covering has size at least |S|. Thus, Npackr (Y ) ≤ Nr(Y ). Second, {B(x, r) : x ∈ S} is a 2r-covering: else there exists a point x0 that is not covered, and S ∪ {x0} is an r-packing of larger size. So N2r(Y ) ≤ Npackr (Y ). It remains to consider the case when there exists an r-packing S of infinite size. Then using the same argument as above we show that any r-covering consists of infinitely many sets.\nFor any set of finite diameter, the covering dimension (with multiplier 1) is at most the doubling dimension, which in turn is at most d for any point set in (Rd, ℓp). The doubling dimension Heinonen (2001) has been a standard notion in the theoretical computer science literature (e.g. Gupta et al. (2003); Talwar (2004); Kleinberg et al. (2009); Cole and Gottlieb (2006)). For the sake of completeness, and because we use it in Section 4.3, let us give the definition: the doubling dimension of a subset Y ⊂ X is the smallest (infimum) d > 0 such that any subset S ⊂ Y whose diameter is r can be covered by 2d sets of diameter at most r/2. The doubling dimension is much more restrictive that the covering dimension. For example, Y = {2−i : i ∈ N} under the ℓ1 metric has doubling dimension 1 and covering dimension 0."
    }, {
      "heading" : "3.4 Concentration inequalities",
      "text" : "We use an elementary concentration inequality known as the Chernoff bounds. Several formulations exist in the literature; the one we use is from Mitzenmacher and Upfal (2005).\nTheorem 3.3 (Chernoff Bounds Mitzenmacher and Upfal (2005)). Consider i.i.d. random variables Z1, . . . , Zn with values in [0, 1]. Let Z = 1 n ∑n i=1 Zi be their average, and let ζ = E[Z]. Then: (a) Pr [|Z − ζ| > δζ] < 2 exp(−ζnδ2/3) for any δ ∈ (0, 1). (b) Pr[Z > a] < 2−an for any a > 6ζ."
    }, {
      "heading" : "3.5 Initial observation: proof of Theorem 1.2",
      "text" : "We extend algorithm UniformMesh from metric space ([0, 1], ℓd1) to an arbitrary metric space of covering dimension d. The algorithm is parameterized by d. It divides time into phases of exponentially increasing length. During each phase i, the algorithm picks some δi > 0, chooses an arbitrary δi-net Si for the metric space, and only plays arms in Si throughout the phase. Specifically, it runs an |Si|-armed bandit algorithm on the arms in Si. For concreteness, let us say that we use UCB1 (any other bandit algorithm with the same regret guarantee will suffice), and each phase i lasts 2i rounds. The parameter δi is tuned optimally given d and the phase duration T ; the optimal value turns out to be δ = Õ(T−1/(d+2)). The algorithm can be analyzed using the technique from Kleinberg (2004).\nTheorem 3.4. Consider the Lipschitz MAB problem on a metric space (X,D). Let d be the covering dimension of (X,D) with multiplier c. Then regret of UniformMesh, parameterized by d, satisfies\nR(t) = O ( (c log t)1/(d+2) t1−1/(d+2) ) for every time t. (4)\nProof. Let us analyze a given phase i of the algorithm. Let Ri(t) be the regret accumulated in rounds 1 to t in this phase. Let δ = δi and let K = |Si| be the number of arms in this phase that are considered by the algorithm. The regret of UCB1 in t rounds is O( √ K t log t) Auer et al. (2002a). It follows that\nRi(t) ≤ O( √ Kt log t) + t(µ∗ − sup(µ, Si)),where µ∗ = sup(µ,X).\nNote that sup(µ, Si) ≥ µ∗− δ. (Indeed, since µ is a Lipschitz-continuous function on a compact metric space, there exists an optimal arm x∗ ∈ X such that µ(x∗) = µ∗. Take an arm x ∈ Si such that D(x, x∗) < δ. Then µ(x) ≥ µ∗ − δ.) Further, K ≤ cδ−d since Si is a δ-net. We obtain:\nRi(t) ≤ O( √ c δ−d t log t+ δt).\nSubstituting t = 2i, δ = (ct log t)−1/(d+2), yields Ri(t) = O ( (c log t)1/(d+2) t1−1/(d+2) )\n. We obtain (4) by summing over all phases i = 1, 2 , . . . , ⌈log t⌉. For the last phase i = ⌈log t⌉ (which is possibly incomplete) we note that the regret accumulated in this phase is at most Ri(2 i)."
    }, {
      "heading" : "4 The zooming algorithm for Lipschitz MAB",
      "text" : "This section is on the zooming algorithm, which uses adaptive refinement to take advantage of “benign” input instances. We state and anlyze the algorithm, and derive a number of extensions.\nThe zooming algorithm proceeds in phases i = 1, 2, 3, . . . . Each phase i lasts 2i rounds. Let us define the algorithm for a single phase iph of the algorithm. For each arm x ∈ X and time t, let nt(x) be the number of times arm x has been played in this phase before time t, and let µt(x) be the corresponding average reward. Define µt(x) = 0 if nt(x) = 0. Note that at time t both quantities are known to the algorithm.\nDefine the confidence radius of arm x at time t as\nrt(x) :=\n√\n8 iph 1 + nt(x) . (5)\nThe meaning of the confidence radius is that with high probability (i.e., with probability tending to 1 exponentially fast as iph increases) it bounds from above the deviation of µt(x) from its expectation µ(x). That is:15\nw.h.p. |µt(x)− µ(x)| ≤ rt(x) for all times t and arms x. (6)\nOur intuition is that the samples from arm x available at time t allow us to estimate µ(x) only up to ±rt(x). Thus, the available samples from x do not provide enough confidence to distinguish x from any other arm in the ball of radius rt(x) around x. Call B(x, rt(x)) the confidence ball of arm x (at time t).\nThroughout the execution of the algorithm, a finite number of arms are designated active, so that in each round the algorithm only selects among the active arms. In each round at most one additional arm is activated. Once an arm becomes active, it stays active until the end of the phase. It remains to specify two things: the selection rule which decides which arm to play in a given round, and the activation rule which decides whether to activate some arm and which arm to activate.\n• Selection rule. Choose an active arm x with the maximal index, defined as\nIt(x) = µt(x) + 2 rt(x). (7)\nThis definition of the index is meaningful because as long as (6) holds, the index of x is an upper bound on the expected payoff of any arm in the confidence ball of x. (We will prove this later.) The factor 2 in (7) is needed because we “spend” one +rt(x) to take care of the sampling uncertainty, and another +rt(x) to generalize from x to the confidence ball of x. Note that the index in algorithm UCB1 (Auer et al., 2002a) is essentially µt(x) + rt(x).\n• Activation rule. Say that an arm is covered at time t if it is contained in the confidence ball of some active arm. We maintain the invariant that at each time all arms are covered. The activation rule simply maintains this invariant: if there is an arm which is not covered, pick any such arm and make it active. Note that the confidence radius of this newly activated arm is initially greater than 1, so all arms are trivially covered. In particular, it suffices to activate at most one arm per round. The activation rule is implemented using the covering oracle, as defined in Section 1.5.\nThe bare pseudocode of the algorithm is very simple; see Algorithm 1.\nAlgorithm 1 Zooming Algorithm\nfor phase i = 1, 2, 3, . . . do Initially, no arms are active. for round t = 1, 2, 3, . . . , 2i do\nActivation rule: if some arm is not covered, pick any such arm and activate it. Selection rule: play any active arm with the maximal index (7).\nTo state the provable guarantees, we need the notion of zooming dimension of a problem instance. As discussed in Section 1.4, this notion bounds the covering number of near-optimal arms, thus sidestepping the worst-case lower bound examples. Here and throughout this section, we let µ∗ , sup(µ,X) denote the maximal reward, and we let ∆(x) = µ∗ − µ(x) be the “badness” of arm x.\n15Here and throughout this paper, we use the abbreviation “w.h.p.” to denote the phrase with high probability.\nDefinition 4.1. Consider a problem instance (D,X, µ). The set of near-optimal arms at scale r ∈ (0, 1] is defined to be\nXµ, r , {x ∈ X : r2 < ∆(x) ≤ r}.\nThe zooming dimension with multiplier c > 0 is the smallest d ≥ 0 such that for every scale r ∈ (0, 1] the set Xµ, r can be covered by c r−d sets of diameter strictly less than r/8.\nTheorem 4.2. Consider an instance of the Lipschitz MAB problem. Fix any c > 0 and let d be the zooming dimension with multiplier c. Then the regret R(t) of the zooming algorithm satisfies:\nR(t) ≤ O(c log t) 1d+2 × t d+1 d+2 for all times t. (8)\nThe zooming algorithm is self-tuning in that it does not input the zooming dimension d. Moreover, it is not parameterized by the multiplier c, and yet it satisfies the corresponding regret bound for any given c > 0. For sharper guarantees, c can be tuned to the specific problem instance and specific time t.\nNote that the regret bound in Theorem 4.2 has the same “shape” as the worst-case result (Theorem 1.2), except that d now stands for the zooming dimension rather than the covering dimension. Thus, the zooming dimension is our way to quantify the benignness of a problem instance. (It is immediate from Definition 4.1 that the covering dimension with multiplier c is an upper bound on the zooming dimension with the same multiplier.) Let us flesh out (and generalize) two examples from Section 1 where the zooming dimension is small:\n• all arms with ∆(v) < r lie in a low-dimensional region S ⊂ X, for some r > 0.\n• µ(x) = max(0, µ∗ −D(x, S)) for some µ∗ ∈ (0, 1] and subset S ⊂ X.\nIn both examples, for a sufficiently large constant multiplier c, the zooming dimension is bounded from above by COV(S) (as opposed to COV(X)). Note that in the second example a natural special case is when S is a finite point set, in which case COV(S) = 0. The technical fine print is very mild: (X,D) can be any compact metric space, and the second example requires some open neighborhood of S to have constant doubling dimension. The first example is immediate; the second example is analyzed in Section 4.3.\nOur proof of Theorem 4.2 does not require all the assumptions in the Lipschitz MAB problem. It never uses the triangle inequality, and it only needs a relaxed version of the Lipschitz condition (1). If there exists a unique best arm x∗ then the relaxed Lipschitz condition is (1) with y = x∗. In a more efficient notation: ∆(x) ≤ D(x, x∗) for each arm x. This needs to hold for each best arm x∗ if there is more than one. A more general version, not assuming that the optimal payoff sup(µ,X) is attained by some arm, is as follows:\n(∀ǫ > 0) (∃x∗ ∈ X) (∀x ∈ X) ∆(x) ≤ D(x, x∗) + ǫ. (9)\nTheorem 4.3. The guarantees in Theorem 4.2 hold even if the similarity function D is not required to satisfy the triangle inequality,16 and the Lipschitz condition (1) is relaxed to (9).\nFurther, we obtain a regret bound in terms of the covering numbers.\n16Formally, we require D to be a symmetric function X ×X → [0,∞] such that D(x, x) = 0 for all x ∈ X. We call such a function a quasi-distance on X.\nTheorem 4.4. Fix an instance of the Lipschitz MAB problem (relaxed as in Theorem 4.3). Then the regret R(t) of the zooming algorithm satisfies\nR(t) ≤ min ρ>0\n(\nρt+O(log2 t) ∑ r∈S: r≥ρ 1 r Nr/8(Xµ,r)\n)\n, where S = {2−i : i ∈ N}.\nThis regret bound takes advantage of problem instances for which Xµ,r is a much smaller set than X. It can be useful even if the benignness of the problem instance cannot be summarized via a non-trivial upper-bound on the zooming dimension.\nThe rest of this section is organized as follows. In Section 4.1 we prove the above theorems. In addition, we provide some extensions and applications.\n• In Section 4.2 we derive a regret bound that matches (8) and gets much smaller if the maximal payoff is close to 1. This result relies on an improved confidence radius, which may be of independent interest.\n• In Section 4.3 we analyze the special case in which the expected payoff of a given arm is a function of the distance from this arm to the (unknown) “target set” S ⊂ X. This is a generalization of the µ(x) = max(0, µ∗ −D(x, S)) example above.\n• In Section 4.4 we prove improved regret bounds for several examples in which the payoff of each arm x is µ(x) plus i.i.d. noise of known and “benign” distribution. For these results, we replace µt(x), rt(x) with better estimates: µ̂t(x), r̂t(x) such that |µ̂t(x)−µ(x)| ≤ r̂t(x) < rt(x) with high probability."
    }, {
      "heading" : "4.1 Analysis of the zooming algorithm",
      "text" : "First we use Chernoff bounds to prove (6). A given phase will be called clean if for each round t in this phase and each arm x ∈ X we have |µt(x)− µ(x)| ≤ rt(x).\nClaim 4.5. Each phase iph is clean with probability at least 1− 4−iph .\nProof. The only difficulty is to set up a suitable application of Chernoff bounds along with the union bound. Let T = 2iph be the duration of a given phase iph.\nFix some arm x. Recall that each time an algorithm plays arm x, the payoff is sampled i.i.d. from some distribution Px. Define random variables Zx,s for 1 ≤ s ≤ T as follows: for s ≤ n(x), Zx,s is the payoff from the s-th time arm x is played, and for s > n(x) it is an independent sample from Px. For each k ≤ T we can apply Chernoff bounds to {Zx,s : 1 ≤ s ≤ k} and obtain that\nPr\n[\n∣ ∣ ∣µ(x)− 1k ∑k s=1 Zx,s ∣ ∣ ∣ ≤ √ 8 iph 1+k\n]\n> 1− T−4. (10)\nLet N be the number of arms activated in phase iph; note that N ≤ T . Define X-valued random variables x1, . . . , xT as follows: xj is the min(j,N)-th arm activated in this phase. For any x ∈ X and j ≤ T , the event {x = xj} is independent of the random variables {Zx,s}; the former event depends only on payoffs observed before x is activated, while the latter set of random variables has no dependence on payoffs of arms other than x. Therefore, (10) remains valid if we replace the probability on the left side with conditional probability, conditioned on the event {x = xj}. Taking the union bound over all k ≤ T , and using the notation of µt(x) and rt(x), it follows that\nPr [ ∀t |µ(x)− µt(x)| ≤ rt(x) | xj = x ] > 1− T−3,\nwhere t ranges over all rounds in phase iph. Integrating over all arms x we obtain\nPr [ ∀t |µ(xj)− µt(xj)| ≤ rt(xj) ] > 1− T−3.\nFinally, we obtain the claim by taking the union bound over all j ≤ T .\nNext, we present a crucial argument which connects the best arm and the arm played at a given round, which in turn allows us to bound the number of plays of a suboptimal arm in terms of its badness.\nLemma 4.6. If phase iph is clean then we have ∆(x) ≤ 3 rt(x) for any time t and any arm x. Proof. Suppose arm x is played at time t in clean phase iph. First we claim that It(x) ≥ µ∗. Indeed, fix ǫ > 0. By definition of µ∗ there exists a arm x∗ such that ∆(x∗) < ǫ. Recall that all arms are covered at all times, so there exists an active arm xt that covers x\n∗ at time t, meaning that x∗ is contained in the confidence ball of xt. Since arm x was chosen over xt, we have It(x) ≥ It(xt). Since this is a clean phase, it follows that It(xt) ≥ µ(xt) + rt(xt). By the Lipschitz property we have µ(xt) ≥ µ(x∗) − D(xt, x∗). Since xt covers x∗, we have D(xt, x∗) ≤ rt(xt) Putting all these inequalities together, we have It(x) ≥ µ(x∗) ≥ µ∗ − ǫ. Since this inequality holds for an arbitrary ǫ > 0, we in fact have It(x) ≥ µ∗. Claim proved.\nFurthermore, note that by the definitions of “clean phase” and “index” we have\nµ∗ ≤ It(x) ≤ µ(x) + 3 rt(x)\nand therefore ∆(x) ≤ 3 rt(x). Now suppose arm x is not played at time t. If it has never been played before time t in this phase, then rt(x) > 1 and thus the lemma is trivial. Else, let s be the last time arm x has been played before time t. Then by definition of the confidence radius rt(x) = rs(x) ≥ 13 ∆(x).\nCorollary 4.7. If phase iph is clean then each arm x is played at most O(iph) (∆(x)) −2 times.\nProof. This follows by plugging the definition of the confidence radius into Lemma 4.6.\nCorollary 4.8. In a clean phase, for any active arms x, y we have D(x, y) > 13 min(∆(x),∆(y)). Proof. Assume x has been activated before y. Let s be the time when y has been activated. Then by the algorithm specification we have D(x, y) > rs(x). By Lemma 4.6 rs(x) ≥ 13∆(x).\nConsider round t which belongs to a clean phase iph. Let St be the set of all arms that are active at time t, and let\nA(i,t) = { x ∈ St : 2i ≤ 1∆(x) < 2i+1 } .\nRecall that by Corollary 4.7 for each x ∈ A(i,t) we have nt(x) ≤ O(log t) (∆(x))−2. Therefore: ∑\nx∈A(i,t) ∆(x)nt(x) ≤ O(log t)\n∑\nx∈A(i,t)\n1 ∆(x) ≤ O(2i log t) |A(i,t)|.\nLetting r = 2−i, note that by Corollary 4.8 any set of diameter less than r/8 contains at most one arm from A(i,t). It follows that |A(i,t)| ≤ Nr/8(Xµ,r), the smallest number of sets of diameter less than r/8 sufficient to cover all arms x such that r2 < ∆(x) ≤ r. It follows that\n∑\nx∈A(i,t)\n∆(x)nt(x) ≤ O(log t) 1r Nr/8(Xµ,r).\nLet S = {2−i : i ∈ N}. For each ρ ∈ (0, 1), we have: ∑\nx∈St ∆(x)nt(x) ≤\n∑\nx∈St: ∆(x)≤ρ ∆(x)nt(x) +\n∑\ni<log(1/ρ)\n∑\nx∈A(i,t) ∆(x)nt(x)\n≤ ρ(t− 2iph−1) +O(log t) ∑r∈S: r≥ρ 1r Nr/8(Xµ,r). (11)\nHere t− 2iph−1 is the number of rounds in phase iph before and including round t. Let Rph(t) be the left-hand side of (11). By Claim 4.5, the probability that phase iph is non-clean is negligible. Therefore, we obtain the following:\nClaim 4.9. Fix round t and let iph be the round to which t belongs. Then:\nE[Rph(t)] ≤ inf ρ>0\n( ρ(t− 2iph−1) +O(log t) ∑r∈S: r≥ρ 1r Nr/8(Xµ,r) ) . (12)\nWe complete the proof as follows. Let t be the current round and let iph be the current phase. Let ti = 2\ni (for i < iph) be the last round of each phase i < iph, and let tiph = t. Note that regret up to time t can be expressed as\nR(t) = ∑ i≤iph E [ Rph(ti) ] .\nTheorem 4.4 follows by summing up (12) over all phases i ≤ iph. We derive Theorem 4.3 from (12) as follows. Note that Nr/8(Xµ,r) ≤ c r−d by definition of the zooming dimension d with multiplier c > 0. For a given phase i, letting t0 = ti − 2i−1 and choosing ρ such that ρ t0 = ( 1 ρ) d+1(c log t), we obtain\nE[Rph(ti)] ≤ O(c log t)1/(d+2) × t(d+1)/(d+2)0 .\nWe obtain Theorem 4.3 by summing this over all phases i ≤ iph."
    }, {
      "heading" : "4.2 Extension: maximal expected payoff close to 1",
      "text" : "We obtain a sharper regret bound which matches (8) and gets much smaller if the optimal reward µ∗ = sup(µ,X) is close to 1. The key ingredient here is a more elaborate confidence radius:\nr̂t(x) , α\n1 + nt(x) +\n√\nα 1− µt(x) 1 + nt(x) for some α = Θ(iph). (13)\nThe confidence radius in (13) performs as well as rt(·) (up to constant factors) in the worst case: r̂t(x) ≤ √\nO(iph) nt(x) , and gets much better when µt(x) is close to 1: r̂t(x) ≤ O(iph)nt(x) . Note that the right side of (13) can be computed from the observable data; in particular, it does not require the knowledge of µ∗.\nTheorem 4.10. Consider an instance of the Lipschitz MAB problem, in the relaxed setting of Theorem 4.3. Fix any c > 0 and let d be the zooming dimension with multiplier c. Let µ∗ = sup(µ,X) be the optimal reward. Then zooming algorithm with confidence radius (13) satisfies, for all times t:\nR(t) ≤ O(c log2 t) +O(c log t) 1d+1 ×max ( t 1− 1d+1 , (1− µ∗) t1− 1d+2 ) .\nCompared to the regret bound in Theorem 4.2, this result effectively reduces the zooming dimension by 1 if µ∗ is close to 1 (and d > 1). Moreover, regret becomes polylogarithmic if µ∗ = 1 and d = 0.\nWe analyze the new confidence radius (13) using the following corollary of Chernoff bounds which, to the best of our knowledge, has not appeared in the literature, and may be of independent interest.\nTheorem 4.11. Consider n i.i.d. random variables Z1 . . . Zn on [0, 1]. Let Z be their average, and let ζ = E[Z]. Then for any α > 0, letting r(α, x) = αn + √ αx n , we have:\nPr [ |Z − ζ| < r(α,Z) < 3 r(α, ζ) ] > 1− ( 2−α + 2 e−α/72 ) .\nProof. Suppose ζ < α6n . Then using Chernoff bounds (Theorem 3.3(b)) with a = α n > 6ζ, we obtain that with probability at least 1− 2−α we have Z < αn , and therefore |Z − ζ| < αn < r(α,Z) and\n|Z − ζ| < αn < r(α,Z) < (1 + √ 2) αn < 3 r(α, ζ).\nNow, suppose ζ ≥ α6n . Apply Chernoff bounds (Theorem 3.3(a)) with δ = 12 √ α 6ζn . Thus with\nprobability at least 1− 2 e−α/72 we have |Z − ζ| < δζ ≤ ζ/2. Plugging in δ,\n|Z − ζ| < 12 √ αζ n ≤ √ αZ n ≤ r(α,Z) < 1.5 r(α, ζ).\nProof of Theorem 4.10: Let us fix an arm x and time t. Let us use Theorem 4.11 with n = nt(x) and α = Θ(iph) as in (13), setting each random variable Xi equal to 1 minus the reward from the i-th time arm x is played in the current phase. Then ζ = 1 − µ(x) and Z = 1 − µt(x), so the theorem says that\nPr\n[ |µt(x)− µ(x)| < rt(x) < 3 ( α\nnt(x) +\n√\nα (1− µ(x)) nt(x)\n)]\n> 1− 2Ω(α). (14)\nWe modify the analysis in Section 4.1 as follows. We redefine a “clean phase” to mean that the event in the left-hand side of (14) holds for all rounds t and all arms x. We use (14) instead of the standard Chernoff bound in the proof of Claim 4.5 to show that each phase iph is clean with probability at least 1− 4iph . Then we obtain Lemma 4.6 as is, for the new definition of rt(x). Then we replace Corollary 4.7 with a more efficient corollary based on the new rt(x). More precisely, we derive two regret bounds: one assuming rt(x) = O(iph) nt(x) , and another assuming rt(x) = √ O(iph)(1−µ∗) nt(x) , and take the maximum of the two. We omit the easy details."
    }, {
      "heading" : "4.3 Application: Lipschitz MAB with a “target set”",
      "text" : "We consider a version of the Lipschitz MAB problem in which the expected reward of each arm x is determined by the distance between this arm and a fixed target set S ⊂ X which is not revealed to the algorithm. Here the distance is defined as D(x, S) , infy∈S D(x, y). The motivating example is µ(x) = max(0, µ∗ −D(x, S)). More generally, we assume that µ(x) = f(D(x, S))) for each arm x, for some known non-increasing function f : [0, 1] → [0, 1]. We call this version the Target MAB problem with target set S and shape function f .17\n17Note that the payoff function µ does not necessarily satisfy the Lipschitz condition with respect to D. However, if f(z) = µ∗ − z then µ(x) = µ∗ −D(x, S), and the Lipschitz condition is satisfied because D(x, S)−D(y, S) ≤ D(x, y).\nThe key idea is to use the quasi-distance function Df (x, y) = f(0) − f(D(x, y)). It is easy to see that Df satisfies (9). Indeed, fix any arm x∗ ∈ S. Then for each x ∈ X we have:\n∆(x) = µ(x∗)− µ(x) = f(0)− f(D(x, S)) = Df (x, S) ≤ Df (x, x∗).\nTherefore Theorem 4.3 applies: we can use the zooming algorithm in conjunction with Df rather than D. The performance of this algorithm depends on the zooming dimension of the problem instance (X,Df , µ).\nTheorem 4.12. Consider the Target MAB problem with target set S ⊂ X and shape function f . For some fixed multiplier c > 0, let d be the zooming dimension of (X,Df , µ). Then the zooming algorithm on (Df ,X) has regret R(t) ≤ (c log t) 1 d+2 t d+1 d+2 for all times t.\nNote that the zooming algorithm is self-tuning: it does not need to know the properties of S or f , and in fact it does not even need to know that it is presented with an instance of the Target MAB problem. We obtain a further improvement via Theorem 4.10 if f(0) is close to 1.\nLet us consider the main example µ(x) = max(0, µ∗ −D(x, S)) and more generally\nµ(x) = max(µ0, µ ∗ −D(x, S)1/α) (15)\nfor some constant α > 0 and 0 ≤ µ0 < µ∗ ≤ 1. Here µ0 and µ∗ are, respectively, the minimal and maximal expected payoffs. (15) corresponds to f(z) = max(µ0, µ ∗ − z1/α). Then\nDf (x, y) = min(µ∗ − µ0, (D(x, y))1/α).\nWe find that the zooming dimension of the problem instance (X,Df , µ) is, essentially, at most α times the covering dimension of S. (This result holds as long as (X,D) has constant doubling dimension.) Intuitively, S is a low-dimensional subset of the metric space, in the sense that it has a (much) smaller covering dimension.\nLemma 4.13. Consider the Target MAB problem with payoff function given by (15). Let d be the covering dimension of the target set S, for any fixed multiplier c > 0. Let dDBL be the doubling dimension of (X,D); assume it is finite. Then the zooming dimension of (X,Df , µ) is αd, with constant multiplier\nczoom = ( max (\nc 24α+2, 2µ∗−µ0\n))dDBL .\nProof. For each r > 0, it suffices to cover the set Sr = {x ∈ X : ∆(x) ≤ r} with czoom r−αd sets of Df -diameter at most r/16. Note that ∆(x) = min(µ∗ − µ0, (D(x, S))1/α).\nAssume r < µ∗ −µ0. Then for each x ∈ Sr we have D(x, S) ≤ rα. By definition of the covering dimension, S can be covered with c r−αd sets {Ci }i of D-diameter at most rα. It follows that Sr can be covered with r−αd sets {B(Ci, r) }i, where B(Ci, r) , ∪u∈Ci B(x, r). The D-diameter of each such set is at most 3 rα. Since dDBL is the doubling dimension of (X,D), each B(Ci, r) can be covered by with 2(4α+2) dDBL of sets of D-diameter at most (r/16)α. Therefore, Sr can be covered by c 2(4α+2) dDBL r−αd sets whose D-diameter is at most (r/16)α, so that their Df -diameter is at most r/16.\nFor r ≥ µ∗−µ0 we have Sr = X, and by definition of the doubling dimension X can be covered by (\n2 µ∗−µ0\n)dDBL sets of diameter at most µ∗ − µ0.\nThe most striking (and very reasonable) special case is when S consists of finitely many points.\nCorollary 4.14. Consider the Target MAB problem with payoff function given by (15). Suppose the target set S consists of finitely many points. Let czoom be from Lemma 4.13 with c = |S|. Then the zooming algorithm on (Df ,X) has regret R(t) = O( √ czoom t log t) for all times t. Moreover, the regret is R(t) = O(czoom log t) 2 if µ∗ = 1.\nProof. The covering dimension of S is 0 with multiplier c = |S|. Then by Lemma 4.13 the zooming dimension is 0, with multiplier czoom. We obtain the Õ( √ czoom t log t) regret using Theorem 4.12, and the O(czoom log t) 2 regret result using Theorem 4.10.\nThe proof of Lemma 4.13 easily extends to shape functions f such that\nx1/α ≤ f(0)− f(x) ≤ x1/α′ ∀x ∈ (0, 1],\nfor some constants α ≥ α′ > 0. Then, using the notation in Lemma 4.13, the zooming dimension of (X,Df , µ) is αd, with multiplier czoom = max ( c 2(4α ′+2) dDBL , (\n2 µ∗−µ0\n)dDBL )\n."
    }, {
      "heading" : "4.4 Application: mean-zero noise with known shape",
      "text" : "Improved regret bounds are possible if the reward from playing each arm x is µ(x) plus noise of known shape. More precisely, we assume that the reward from playing arm x is µ(x) plus an independent random sample from some fixed, mean-zero distribution P, called the noise distribution, which is revealed to the algorithm. We call this version the noisy Lipschitz MAB problem. We present several examples in which we take advantage of a “benign” shape of P. Interestingly, in these examples the payoff distributions are not restricted to have bounded support.18\nNormal distributions. We start with perhaps the most natural example when the noise distribution P is the zero-mean normal distribution. Then instead of the confidence radius rt defined by (5) we can use the confidence radius r̂t(·) = σ rt(·), where σ is the standard deviation of P. Consequently we obtain a regret bound (8) with the right-hand side multiplied by σ.\nIn fact, this result can be generalized to all noise distributions P such that\nE Z∼P\n[ erZ ] ≤ er2σ2/2 for all r ∈ [−ρ, ρ]. (16)\nThe normal distribution with standard deviation σ satisfies (16) for ρ = ∞. Any distribution with support [−σ, σ] satisfies (16) for ρ = 1. The meaning of (16) is that it is precisely the condition needed to establish an Azuma-type inequality: if Z1, . . . , Zn are independent samples from P then ∑n\ni=1 Zi ≤ Õ(σ √ n) with high probability. More precisely:\nPr [ ∑n i=1 Zi > λσ √ n] ≤ exp(−λ2/2) for any λ ≤ 12 ρ σ √ n. (17)\nWe can derive an analog of Claim 4.5 for the new confidence radius r̂t(·) = σ rt(·) by using (17) instead of the standard Chernoff bound; we omit the easy details.\nTool: generalized confidence radius. More generally, we may be able to use a different, smaller confidence radius r̂t(·) instead of rt(·) from (5), perhaps in conjunction with a different estimate µ̂t(·) of µ(·) instead of the sample average µt(·). We will need the pair (µ̂t, r̂t) to satisfy an analog of Claim 4.5:\nPr [ |µ̂t(x)− µ(x)| ≤ r̂t(x) for all times t and arms x ] ≥ 1− 4−iph . (18) 18Recall that throughout the paper the payoff distribution of each arm x has support S(x) ⊂ [0, 1]. In this\nsubsection, by a slight abuse of notation, we do not make this assumption.\nFurther, we will need the confidence radius r̂t to be small in the following sense:\nfor each arm x and any r > 0, inequality r̂t(x) ≤ r implies nt(x) ≤ c0 r−β log t, (19)\nfor some constants c0 and β ≥ 0. Recall that r̂t = rt satisfies (19) with β = 2 and c0 = O(1).\nLemma 4.15. Consider the Lipschitz MAB problem (relaxed as in Theorem 4.3). Consider the zooming algorithm with estimator µ̂t and confidence radius r̂t, and consider a problem instance such that the pair (µ̂t, r̂t) satisfies (18). Suppose r̂t satisfies (19). Let d be the zooming dimension of the problem instance, for any fixed multiplier c > 0. Then regret of the algorithm is\nR(t) ≤ O(c c0 log2 t) +O(c c0 log2 t)1/(d+β) × t1−1/(d+β) for all times t. (20)\nLemma 4.15 is proved by plugging in the improved confidence radius into the analysis in Section 4.1; we omit the easy details. We obtain an improvement over Theorem 4.2 and Theorem 4.3 whenever β < 2. Below we give some examples for which we can construct improved (µ̂t, r̂t).\nExample: deterministic rewards. For the important special case of deterministic rewards, we obtain regret bound (20) with β = 0. (The proof is a special case of the next example.)\nCorollary 4.16. Consider the Lipschitz MAB problem with deterministic rewards (relaxed as in Theorem 4.3). Then the zooming algorithm with suitably defined estimator µ̂t and confidence radius r̂t achieve regret bound (20) with β = 0.\nExample: noise distribution with a point mass. Consider noise distributions P having at least one point mass: a point z ∈ R of positive probability mass: P(z) > 0. (Deterministic rewards correspond to the special case P(0) = 1).\nCorollary 4.17. Consider the Lipschitz MAB problem (relaxed as in Theorem 4.3). Assume meanzero noise distribution with at least one point mass. Then the zooming algorithm with suitably defined estimator µ̂t and confidence radius r̂t achieve regret bound (20) with β = 0.\nProof. We will show that we can use a confidence radius r̂t(u) = rt(u)1{nt(u)≤cP log t}, for some constant cP that depends only on P. This implies regret bound (20) with β = 0.\nIndeed, let p = maxz∈R P(z) be the largest point mass in distribution P, and q = maxz∈R:P(z)<p P(z) be the second largest point mass. Let S = {z ∈ R : P(z) = p}, and let k = |S| + 1q if q > 0, or k = |S| if q = 0. Then for some cP = Θ ( log(|S|+k) p−q )\n, it suffices to have n ≥ cP log t independent samples from P to ensure that with probability at least 1− t−4 each number z ∈ S is sampled at least n(p+ q)/2 times, whereas any number z 6∈ S is sampled less often.19\nFor a given arm x and time t, we define a new estimator µ̂t(x) as follows. Let n = nt(x) be the number of rewards from x so far. If n < cP log t, use the sample average: let µ̂t(x) = µt(x). Else, let R be the set of rewards that have appeared at least n(p+ q)/2 times. Then R = µ(x) + S with probability at least 1 − t−4. In particular, max(R) = µ(x) + max(S). So we can define µ̂t(x) = max(R)−max(S).\n19To prove that each number z 6∈ S is sampled less than n(p + q)/2 times when q > 0, we need to be somewhat careful in how we apply the Union Bound. It is possible to partition the set R\\S into at most O(|S|+ 1\nq ) measurable\nsubsets, namely intervals or points, whose measure is at most q (and at least q/2). Apply Chernoff bound to each subset separately, then take the Union Bound.\nExample: noise distributions with a sharp peak. If the noise distribution P has a sharp peak around 0, then small regions around this peak can be identified more efficiently than using the standard confidence radius rt.\nMore precisely, suppose P has a probability density function f(z) which is symmetric around 0 and non-increasing for z > 0, and suppose f(z) has a sharp peak: f(z) = Θ(|z|−α) on some open neighborhood of 0, for some constant α ∈ (0, 1). We will show that we can use a new confidence radius r̂t(x) = C (iph/nt(x))\n1/(1−α), for a sufficiently high constant C, which leads to regret bound (20) with β = 1− α.\nFix arm x and time t. We define the estimator µ̂t(x) as follows. Let S be the multiset of rewards received from arm x so far. Let r = 12 r̂t(x). Cover the [0, 1] interval with ⌈1/r⌉ subintervals Ij = [jr, (j + 1)r). Pick the subinterval that has most points from S (break ties arbitrarily), and define µ̂t(x) as some point in this subinterval.\nLet us show that |µ(x) − µ̂t(x)| ≤ r̂t(x) with high probability. Let Ij be the subinterval that contains µ(x). Let n = nt(x) be the number of times arm x has been played so far; note that n > Ω(C rα−1 log t). By Chernoff bounds, for a sufficiently high constant C, it holds that with probability at least 1− t−4 subinterval Ij contains more points from S than any other subinterval Iℓ such that |j − ℓ| ≥ 2. Conditional on this high-probability event, the estimate µ̂t(x) lies in subinterval Iℓ such that |j − ℓ| ≤ 1, which implies that |µ(x)− µ̂t(x)| ≤ 2r."
    }, {
      "heading" : "5 Optimal per-metric performance",
      "text" : "This section is concerned with Question (Q1) raised in Section 1.3: What is the best possible algorithm for the Lipschitz MAB problem on a given metric space (X,D). We consider the worstcase regret of a given algorithm over all possible problem instances on (X,D).20 We focus on minimizing the exponent γ such that for each payoff function µ the algorithm’s regret is R(t) ≤ tγ for all t ≥ t0(µ). With Theorem 1.2 in mind, we will use a more focused notation: we define the regret dimension of an algorithm on (X,D) as, essentially, the smallest d ≥ 0 such that one can achieve the exponent γ = d+1d+2 . Definition 5.1. Consider the Lipschitz MAB problem on a given metric space (X,D). For algorithm A and payoff function µ, define the instance-specific regret dimension of A as\nDIMµ(A) = inf{d ≥ 0 | ∃t0 = t0(µ) RA(t) ≤ t1−1/(d+2) for all t ≥ t0} = inf{d ≥ 0 | ∃C = C(µ) RA(t) ≤ C t1−1/(d+2) for all t}.\nThe regret dimension of A is DIM(A) = supµ DIMµ(A), where the supremum is over all payoff functions µ.\nThus, according to Theorem 1.2, the regret dimension of UniformMesh is at most the covering dimension of the metric space. We ask: is it possible to achieve a better regret dimension, perhaps using a more sophisticated algorithm? We show that this is indeed the case. Moreover, we provide an algorithm such that for any given metric space its regret dimension is arbitrarily close to optimal. Our main result as follows:\nTheorem 5.2. Consider the Lipschitz MAB problem on a compact metric space (X,D). Then for any d > MaxMinCOV(X) then there exists a bandit algorithm A whose regret dimension is at most d; moreover, the instance-specific regret dimension of A is at most the zooming dimension. No algorithm can have regret dimension strictly less than MaxMinCOV(X).\n20Formally, we can define the per-metric performance of an algorithm on a given metric space as the worst-case regret of this algorithm over all problem instances on this metric space.\nHere MaxMinCOV(X) is the max-min-covering dimension which we defined in Section 1. We show that MaxMinCOV(X) can be arbitrarily small compared to COV(X).\nThe rest of this section is organized as follows. The first two subsections are concerned with the lower bound: in Section 5.1 we develop a lower bound on regret dimension which relies on a certain “tree of balls” structure, and in Section 5.2 we derive the existence of this structure from the max-min-covering dimension. A lengthy KL-divergence argument (which is similar to prior work) is deferred to Section A. The next two subsections deal with an instructive special case: in Section 5.3 we define a family of metric spaces for which MaxMinCOV(X) can be arbitrarily small compared to COV(X), and in Section 5.4 we design a version of the zooming algorithm tailored to such metric spaces. Finally, in Section 5.5 we design and analyze an algorithm whose regret dimension is arbitrarily close to MaxMinCOV(X). We use the max-min-covering dimension to derive the existence of a certain decomposition of the metric space which we then take advantage of algorithmically. Our per-metric optimal algorithm builds on the machinery developed for the special case. Collectively, these results amount to Theorem 5.2."
    }, {
      "heading" : "5.1 Lower bound on regret dimension",
      "text" : "It is known (Auer et al., 2002b) that a worst-case instance of the K-armed bandit problem consists of K − 1 arms with identical payoff distributions, and one which is slightly better. We refer to this as a “needle-in-haystack” instance. Our lower bound relies on a multi-scale needle-in-haystack instance in which there are K disjoint open sets, and K − 1 of them consist of arms with identical payoff distributions, but in the remaining open set there are arms whose payoff is slightly better. Moreover, this special open set contains K ′ ≫ K disjoint subsets, only one of which contains arms superior to the others, and so on down through infinitely many levels of recursion.\nIn more precise terms, we require the existence of a certain structure: an infinitely deep rooted tree whose nodes correspond to balls in the metric space, so that for any parent ball B the children balls are disjoint subsets of B.\nDefinition 5.3 (ball-tree). Fix a metric space (X,D). Let an extended ball be a pair w = (x, r), where x ∈ X is a “center” and r ∈ (0, 1] is a “radius”.21 A ball-tree is an infinite rooted tree where each node corresponds to an extended ball. The following properties are required:\n• all children of the same parent have the same radius, which is at most a quarter of the parent’s. • if (x, r) is a parent of (x′, r′) then D(x, x′) + r′ < r/2. • if (x, rx) and (y, ry) are siblings, then rx + ry < D(x, y).\nThe ball-tree has strength d ≥ 0 if each tree node with children of radius r has at least max(2, r−d) children.\nOnce there exists a ball-tree of strength d, we can show that, essentially, regret O(t1−1/(d+2)) is the best possible. More precisely, we construct a probability distribution over problem instances which is hard for every given algorithm. Intuitively, this is the best possible “shape” of a regret bound since, obviously, a single problem instance cannot be hard for every algorithm.\nLemma 5.4. Consider the Lipschitz MAB problem on a metric space (X,D) such that there exists a ball-tree of strength d ≥ 0. Assume 0-1 payoffs (i.e., the payoff of each arm is either 1 or 0). Then there exist a distribution P over problem instances µ and an absolute constant C > 0 such\n21Note that an open ball B(x, r) denotes a subset of the metric space, so there can be distinct extended balls (x, r) and (x′, r′) such that B(x, r) = B(x′, r′). We use extended balls to avoid this ambiguity.\nthat for any bandit algorithm A the following holds:\nPr µ∈P\n[ R(A, µ)(t) ≥ C t1−1/(d+2) for infinitely many t ] = 1. (21)"
    }, {
      "heading" : "It follows that the regret dimension of any algorithm is at least d.",
      "text" : "For our purposes, a weaker version of (21) suffices: for any algorithm A there exists a payoff function µ such that the event in (21) holds (which implies DIM(A) ≥ d). In Section 7 we will also use this lower bound for d = 0. In the rest of this subsection we prove Lemma 5.4.\nRandomized problem instance. Given a metric space (X,D) with a ball-tree, we construct a distribution P over payoff functions as follows. For each tree node w = (x0, r0) define the bump functon Fw : X → [0, 1] by\nFw(x) =\n{\nmin{r0 −D(x, x0), r0/2} if x ∈ B(x0, r0), 0 otherwise.\n(22)\nThis function constitutes a “bump” supported on B(x0, r0). An end in a ball-tree is an infinite path from the root: w = (w0, w1, w2, . . .). Let us define the payoff function induced by each node w = wj as\nµw = 1\n3 +\n1\n3\nj ∑\ni=1\nFwi ,\nand the payoff function induced by the end w as\nµw := lim j→∞\nµwj = 1\n3 +\n1\n3\n∞ ∑\ni=1\nFwi .\nLet P be the distribution over payoff functions µw in which the end w is sampled uniformly at random from the ball-tree (that is, w0 is the root, and each subsequent node wi+1 is sampled independently and uniformly at random among the children of wi).\nLet us show that µw is a valid payoff function for the Lipschitz MAB problem. First, µw(x) ∈ [0, 1] for each arm x ∈ X, and the sum in the definition of µw converges, because for each i ≥ 1, letting ri be the radius of wi, we have ri ≤ r1/4i and Fwi(x) ∈ [0, ri]. In fact, it is easy to see that the payoff function induced by any node or end in the ball-tree is bounded on [13 , 2 3 ]. Second, µw is Lipschitz on (X,D) due to Lemma 5.8, which we state and prove in Section 5.1.1 so as not to break the flow.\nThe salient property of our construction is as follows.\nLemma 5.5. Consider a tree node u in a ball-tree. Let u1 , . . . , uk be the children of u, and let r be their radius. Let B1 , . . . , Bk be the corresponding balls. Fix an arbitrary child ui, and let w be an arbitrary end in the ball-tree such that ui ∈ w. Then:\n(i) µw coincides with µu on all Bℓ, ℓ 6= i. (ii) sup(µw, Bi)− sup(µu,X) ≥ r/6. (iii) 0 ≤ µi − µu ≤ r/3.\nProof. Let w = (w0, w1, . . .), and let j0 be the depth of ui in the ball-tree. Then u = wj0−1 and ui = wj0 , and µw = µu + 1 3 Fui + 1 3 ∑ j>j0 Fwj .\nLet B be the ball corresponding to u. Observe that the balls corresponding to tree nodes wj , j > j0 are contained in Bi. It follows that on B \\Bi all functions Fwj , j ≥ j0 are identically 0, and consequently µw = µu. Since the balls B1 , . . . , Bk are pairwise disjoint, this implies part (i).\nFor part (ii), let (x∗, r∗) be the extended ball corresponding to tree node u. Note that µu attains its supremum on B(x∗, r∗/2), and in fact is a constant on that set. Also, recall that Bi ⊂ B(x∗, r∗/2) by definition of the ball-tree. Let xi be the center of ui. Observe that on B(xi, r/2) we have Fui = r/2, and therefore µw ≥ µu + r/2.\nFor part (iii), note that µi−µ0 = ∑ j≥j0 Fwj , and the latter is at most ∑ j≥j0 1 2 r/4 j−j0 ≤ r/3.\nBelow we use Lemma 5.5 to derive a lower bound on regret.\nRegret lower bounds via (ǫ, k)-ensembles. We make use of the lower-bounding technique from Auer et al. (2002b) for the basic k-armed bandit problem. For a cleaner exposition, we encapsulate the usage of this technique in a theorem. This theorem is considerably more general than the original lower bound in Auer et al. (2002b), but the underlying idea and the proof are very similar. The theorem formulation (mainly, Definition 5.6 below) is new and may be of independent interest.\nWe use a very general MAB setting where the algorithm is given a strategy set X and a collection F of feasible payoff functions; we call it the feasible MAB problem on (X,F). In our construction, F consists of all functions µ : X → [0, 1] that are Lipschitz with respect to the metric space. The lower bound relies on the existence of a collection of subsets of F with certain properties, as defined below. These subsets correspond to children of a given tree node in the ball-tree (we give a precise connection after we state the definition).\nDefinition 5.6. LetX be the strategy set and F be the set of all feasible payoff functions. An (ǫ, k)ensemble is a collection of subsets F1 , . . . ,Fk ⊂ F such that there exist mutually disjoint subsets S1 , . . . , Sk ⊂ X and a function µ0 : X → [13 , 23 ] such that for each i = 1 . . . k and each function µi ∈ Fi the following holds: (i) µi ≡ µ0 on each Sℓ, ℓ 6= i, and (ii) sup(µi, Si)− sup(µ0,X) ≥ ǫ, and (iii) 0 ≤ µi − µ0 ≤ 2ǫ on Si.\nFor each tree node u, let F(u) = {µw : u ∈ w} be the set of all payoff functions induced by ends w that contain u. By Lemma 5.5, if u1 , . . . , uk are siblings whose radius is r, then (F(u1) , . . . ,F(uk)) form an ( r6 , k)-ensemble.\nTheorem 5.7. Consider the feasible MAB problem with 0-1 payoffs. Let F1, . . . ,Fk be an (ǫ, k)ensemble, where k ≥ 2 and ǫ ∈ (0, 112). Then for any t ≤ 1128 k ǫ−2 and any bandit algorithm there exist at least k/2 distinct i’s such that the regret of this algorithm on any payoff function from Fi is at least 160 ǫt.\nThe idea is that if the payoff function µ lies in ∪iFi, an algorithm needs to play arms in Si for at least Ω(ǫ−2) rounds in order to determine whether µ lies in a given Fi, and each such round incurs regret at ǫ (or more) if µ 6∈ Fi.\nAuer et al. (2002b) analyzed a special case in which there are k arms x1 , . . . , xk, and each Fi consists of a single payoff function that assigns expected payoff 12 + ǫ to arm xi, and 1 2 to all other arms. To preserve the flow of the paper, the proof of Theorem 5.7 is presented in Appendix A.\nRegret analysis. Let us fix a bandit algorithm A, and let T the ball-tree of strength d ≥ 0. Without loss of generality, let us assume that each tree node in T has finitely many children. Recall that each end of T induces a payoff function. Let FT be the set of all payoff functions induced by the ends of T . Throughout, the constants in Ω(·) are absolute.\nConsider a level-j tree node u in T . Let u1 , . . . , uk be the children of u, and let r be their radius. Recall that k ≥ max(2, r−d). Then {F(ui) : 1 ≤ i ≤ k} is a ( r6 , k)-ensemble. By Theorem 5.7 there\nexist a subset Iu ⊂ {1 , . . . , k} and a time t > Ω(k r−2) such that for any payoff function µ ∈ F(ui), i ∈ Iu we have R(A, µ)(t) ≥ Ω(rt). Plugging in k ≥ r−d and r ≥ 4−j, we see that there exists a time t ≥ 2Ω(j) such that for each payoff function µ ∈ F(ui), i ∈ Iu we have R(A, µ)(t) ≥ Ω(t1−1/(d+2)).\nConsider the distribution P over payoff functions FT from our construction. Let Ej be the event that µ ∈ F(ui), i ∈ Iu for some level-j tree node u. If µ ∈ Ej for infinitely many j’s then R(A, µ)(t) ≥ Ω ( t1−1/(d+2) )\nfor infinitely many times t. We complete the proof of Lemma 5.4 by showing that\nPr µ∼P\n[ µ ∈ Ej for infinitely many j ] = 1. (23)\nThe proof of (23) is similar to the proof of the Borel-Cantelli Lemma. If µ ∈ Ej only for finitely many j’s, then µ ∈ ∩j≥j0 ¬Ej for some j0. Fix some j0 ∈ N, and let us show that Pr[∩j≥j0 ¬Ej] = 0. For each tree node u at level j we have Pr[Ej |µ ∈ F(u)] ≥ 12 . It follows that for any j > j0\nPr [¬Ej | ¬Ej0 , . . . ,¬Ej−1] ≤ 12 .\nTherefore Pr[∩j≥j0 ¬Ej] = Pr[¬Ej0 ]× ∏ j>j0 Pr [¬Ej | ¬Ej0 , . . . ,¬Ej−1] = 0, claim proved."
    }, {
      "heading" : "5.1.1 Lipschitz-continuity of the lower-bounding construction",
      "text" : "In this subsection we prove that µw is Lipschitz function on (X,D), for any end w of the ball-tree. In fact, we state and prove a more general lemma in which the bump functions are summed over all tree nodes with arbitrary weights in [−1, 1]. This lemma will also be used for the lower-bounding constructions in Section 7.2 and Section 9.3.1.\nLemma 5.8. Consider a ball-tree on a metric space (X,D). Let V be the set of all tree nodes. For any given weight vector σ : V → [−1, 1] and an absolute constant c0 ∈ [0, 12 ] define the payoff function\nµσ = c0 + 1\n3\n∑ w∈V σ(w) · Fw,\nwhere Fw is the bump function from (22). Then µσ is Lipschitz on (X,D). In the rest of this subsection we prove Lemma 5.8. (The proof for the special case µσ = µw uses essentially the same ideas and does not get much simpler.) Let us specify some notation. Throughout, u, v, w denote tree nodes. Write u ⊢ w if u is a parent of w, and u ≻ w if u is an ancestor of w. (Accordingly, define ⊣ and ≺ relations.) Generally our convention will be that u ≻ w ≻ v. Let xw and rw be, resp., the center and the radius of w, and let Bw = B(xw, rw) denote the corresponding ball. Fix the weight vector σ : V → [−1, 1] and arms x, y ∈ X. Write µ = µσ for brevity. We need to prove that |µ(x)− µ(y)| ≤ D(x, y).\nWe start with some observations about the bump functions. First, Fw(y) ≤ D(x, y) under appropriate conditions.\nClaim 5.9. If y ∈ Bw and x 6∈ Bw, then Fw(y) ≤ D(x, y). Proof. Observe that\nFw(y) ≤ rw −D(xw, y) (because y ∈ Bw) ≤ D(xw, x)−D(xw, y) (because x 6∈ Bw) ≤ D(x, y) (by triangle inequality)\nSecond, each bump function Fw is Lipschitz.\nClaim 5.10. |Fw(x)− Fw(y)| ≤ D(x, y).\nProof. If x, y 6∈ Bw, then Fw(x) = Fw(y) = 0, and we are done. If x 6∈ Bw, but y ∈ Bw, then Fw(x) = 0 and Fw(y) ≤ D(x, y) by Claim 5.9, and we are done. In what follows, assume x, y ∈ Bw.\nWe consider four cases, depending on whether D(x, xw) and D(y, xw) are larger than rw/2. If both D(x, xw) and D(y, xw) are at least rw/2, then Fw(x) = Fw(y) = rw/2, and we are done. If both D(x, xw) and D(y, xw) are at most rw/2, then Fw(x) − Fw(y) = D(y, xw) − D(x, xw), which is at most D(x, y) by triangle inequality, and we are done. If D(x, xw) ≤ rw/2 ≤ D(y, xw), then\nFw(x)− Fw(y) = rw/2− (rw −D(y, xw)) = D(y, xw)− rw/2 ≤ D(y, xw)−D(x, xw) ≤ D(x, y).\nThe fourth case is treated similarly.\nThird, we give a convenient upper bound for Fw(y)− Fw(x), assuming x ∈ Bw.\nClaim 5.11. Assume x ∈ Bw. Then Fw(y)− Fw(x) ≤ max(0, D(x, xw)− rw/2).\nProof. This is because Fw(y) ≤ rw/2 and Fw(x) = min(rw/2, rw −D(x, xw)).\nSome of the key arguments are encapsulated below. First, Fu is constant on Bw, u ≻ w.\nClaim 5.12. Fu(x) = ru/2 whenever x ∈ Bw and u ≻ w.\nProof. Since Bw ⊃ Bv whenever w ≻ v, it suffices to assume that u is a parent of w. Then\nD(x, xu) ≤ D(xw, xu) +D(x, xw) (by triangle inequality) < D(xw, xu) + rw (since x ∈ Bw) < ru/2 (by definition of ball-tree).\nSecond, suppose Bw separates x and y (in the sense that Bw contains y but not x), and D(x, y) is small compared to rw. We show that y 6∈ Bv, w ⊢ v.\nClaim 5.13. Assume y ∈ Bw and x 6∈ Bw. Then y 6∈ Bv, whenever w ⊢ v and D(x, y) ≤ rw/2.\nProof. Observe that\nD(xv, y) ≥ D(xw, y)−D(xw, xv) (by triangle inequality) ≥ D(xw, x)−D(x, y)−D(xw, xv) (by triangle inequality) ≥ rw −D(x, y)−D(xw, xv) (because x 6∈ Bw ) ≥ rv + rw/2−D(x, y).\nThe last inequality follows because rw/2−D(xw, xv) ≥ rv by definition of ball-tree. It follows that D(xv, y) ≥ rv whenever D(x, y) ≤ rw/2.\nClaim 5.14. Assume w ⊢ v and x ∈ Bw \\Bv and y ∈ Bv. Then Fw(y)−Fw(x)+Fv(y) ≤ D(x, y).\nProof. If Fw(y) ≤ Fw(x) then it suffices to observe that Fv(y) ≤ D(x, y) by Claim 5.9. From here on, assume Fw(y) > Fw(x) ≥ 0. Observe that\nFw(y)− Fw(x) ≤ D(x, xw)− rw/2 (by Claim 5.11) Fv(y) ≤ rv −D(xv, y) (by definition of Fv)\n0 ≤ rw/2− rv −D(xw, xv) (by definition of ball-tree). Summing this up,\nFw(y)− Fw(x) + Fv(y) ≤ D(x, xw)−D(xw, xv)−D(xv, y) ≤ D(x, xw)−D(xw, y) (by triangle inequality) ≤ D(x, y) (by triangle inequality)\nNow we are ready to put the pieces together. Let w be the least common ancestor of x and y in the ball-tree, i.e., the smallest tree node w such that x, y ∈ Bw. (Such w exists because the radii of the tree nodes go to zero along any end of the ball-tree.) Observe that:\n• Fu(x) = Fu(y) = ru/2 for all u ≻ w (by Claim 5.12). • Fw′(x) = Fw′(y) = 0 for all tree nodes w′ incomparable with w, because x, y 6∈ Bw′ .\nTherefore,\nµ(y)− µ(x) = 1 3\n\n\n∑ v w σ(v)Fv(x)\n\n . (24)\nLet wx (resp., wy) be the unique child containing x (resp., y) if such child exists, and an arbitrary child of w otherwise. By minimality of w and the fact that w has at least two children, we can pick wx and wy so that they are distinct. Then:\n• Fv(x) = 0 for all tree nodes v wy, because x 6∈ Bv. • Fv(y) = 0 for all tree nodes v wx, because y 6∈ Bv.\nPlugging these observations into (24), we obtain:\nµ(y)− µ(x) = 1 3\n\nσ(w) (Fw(y)− Fw(x)) + ∑\nv wx σ(v)Fv(x) +\n∑\nv wy σ(v)Fv(y)\n\n .\n|µ(y)− µ(x)| ≤ 1 3\n\n|Fw(y)− Fw(x)|+ ∑\nv wx Fv(x) +\n∑\nv wy Fv(y).\n\n . (25)\nNote that (25) no longer depends on the weight vector σ. To complete the proof, it suffices to show the following:\n|Fw(y)− Fw(x)|+ ∑ v wx Fv(x) ≤ 43 D(x, y). (26) |Fw(y)− Fw(x)|+ ∑\nv wy Fv(y) ≤ 43 D(x, y). (27)\nIn the remainder of the proof we show (27) (and (26) follows similarly). Let Γ denote the left-hand side of (27). If y 6∈ Bwy , then Fv(y) = 0 for all v wy, and Γ ≤ D(x, y) by Claim 5.10. From here on, assume y ∈ Bwy . Then by Claim 5.12 we have Fw(y) = rw/2. It follows that\nΓ = Fw(y)− Fw(x) + ∑ v wy Fv(y) ≤ D(x, y) + ∑ v≺wy Fv(y), (28)\nwhere the last inequality follows from Claim 5.14. Now consider two cases, depending on whether D(x, y) ≤ rwy/2. If so, then y 6∈ Bv for any v ≺ wy by Claim 5.13, and therefore Fv(y) = 0 for all such v and we are done. The remaining case is that D(x, y) > rwy/2. Define the sequence of tree nodes (vj : j ∈ N) inductively by v0 = wy and for each j ∈ N letting vj+1 be the child of vj that contains y, if such child exists, and any child of vj otherwise. Then\nFvj (y) ≤ rvj/2 ≤ 4−j rv0/2 < 4−j D(x, y) ∀j ≥ 1 ∑\nv≺wy Fv(y) =\n∞ ∑\nj=1\nFvj (y) ≤ ∞ ∑\nj=1\n4−j D(x, y) = D(x, y)/3.\nPlugging this into (28) completes the proof of (27), which in turn completes the proof of Lemma 5.8."
    }, {
      "heading" : "5.2 The max-min-covering dimension",
      "text" : "We would like to derive the existence of a strength-d ball-tree using a covering property similar to the covering dimension. We need a more nuanced notion, which we call the max-min-covering dimension, to ensure that each of the open sets arising in the construction of the ball-tree has sufficiently many disjoint subsets to continue to the next level of recursion. Further, this new notion is an intermediary that connects our lower bound with the upper bound that we develop in the forthcoming subsections.\nDefinition 5.15. For a metric space (X,D) and subsets Y ⊆ X we define\nMinCOV(Y ) = inf{COV(U) : U ⊂ Y is non-empty and open in (Y,D)}, MaxMinCOV(X) = sup{MinCOV(Y ) : Y ⊆ X}.\nWe call them, respectively, the min-covering dimension and the max-min-covering dimension of X.\nThe infimum over open U ⊆ Y in the definition of min-covering dimension ensures that every open set which may arise in the needle-in-haystack construction described above will contain Ω(δǫ−d) disjoint δ-balls for some sufficiently small positive δ, ǫ. Constructing lower bounds for Lipschitz MAB algorithms in a metric space X only requires that X should have subsets with large mincovering dimension, which explains the supremum over subsets in the definition of max-min-covering dimension. Note that for every subset Y ⊆ X we have MinCOV(Y ) ≤ COV(Y ) ≤ COV(X), which implies MaxMinCOV(X) ≤ COV(X).\nLemma 5.16. Consider the Lipschitz MAB problem on a metric space (X,D) and MaxMinCOV(X) > 0. Then for any d ∈ (0, MaxMinCOV(X)) there exists a ball-tree of strength d. It follows (using Lemma 5.4) that the regret dimension of any algorithm is at least MaxMinCOV(X).\nRecall from Section 3.3 that an r-packing of a metric space (X,D) be a subset S ⊂ X such that any two points in S are at distance at least r from one another. The proof will use the following simple packing lemma.\nLemma 5.17 (Folklore). Suppose (X,D) is a metric space of covering dimension d. Then for any b < d, r0 > 0 and C > 0 there exists r ∈ (0, r0) such that X contains an r-packing of size at least C r−b.\nProof. Let r < r0 be a positive number such that every covering of (X,D) with radius-r balls requires more than C r−b balls. Such an r exists, because the covering dimension of (X,D) is strictly greater than b.\nNow let S be any maximal r-packing in (X,D). For every x ∈ X there must exist some point y ∈ S such that D(x, y) < r, as otherwise S ∪ {x} would be an r-packing, contradicting the maximality of S. Therefore, balls B(x, r), x ∈ S cover the metric space. It follows that |S| ≥ C r−b as desired.\nProof of Lemma 5.16: Pick c ∈ (d, MaxMinCOV(X)). Let Y be a subset ofX such that MinCOV(Y ) ≥ c.\nLet us recursively construct a ball-tree of strength d. Each tree node will correspond to an extended ball centered in Y . Define the root to be some radius-1 extended ball with center in Y .22 Now suppose we have defined a tree node w which corresponds to an extended ball with center y ∈ Y and radius r. Let us consider the set B = Y ∩ B(y, r4). Then B is non-empty and open in the metric space (Y,D). By definition of the min-covering dimension we have COV(B) ≥ c. Now Lemma 5.17 guarantees the existence of a (2r′)-packing S ⊂ B such that r′ < r/4 and |S| ≥ (r′)−d. Let the children of w correspond to points in S, so that for each x ∈ S there is a child with center x and radius r′."
    }, {
      "heading" : "5.3 Special case: metric space with a “fat subset”",
      "text" : "To gain intuition on the max-min-covering dimension, let us present a family of metric spaces where for a given covering dimension the max-min-covering dimension can be arbitrarily small.\nLet us start with two concrete examples. Both examples involve an infinite rooted tree where the out-degree is low for most nodes and very high for a few. On every level of the tree the highdegree nodes produce exponentially more children than the low-degree nodes. For concreteness, let us say that all low-degree nodes have degree 2, all high-degree nodes on a given level of the tree have the same degree, and this degree is such that the tree contains 4i nodes on every level i. The two examples are as follows:\n• one high-degree node on every level; the high-degree nodes form a path, called the fat end.\n• 2i high-degree nodes on every level i; the high-degree nodes form a binary tree, called the fat subtree.\nWe assign a width of 2−id, for some constant d > 0, to each level-i node; this is the diameter of the set of points contained in the corresponding subtree. The tree induces a metric space (X,D) where X is the set of all ends23, and for x, y ∈ X we define D(x, y) to be the width of the least common ancestor of ends x and y.\nIn both examples the covering dimension of the entire metric space is 2d, whereas there exists a low-dimensional “fat subset” — the fat end or the fat subtree — which is, in some sense, responsible for the high covering dimension ofX. Specifically, for any subtree U containing of the fat end (which is just a point in the metric space) it holds that COV(U) = 2d but COV(X \\U) = d. Similarly, if S is the fat subtree and U is a union of subtrees that cover S then COV(U) = 2d but COV(S∪(X\\U)) = d.\nIt is easy to generalize the notion of “fat subtree” to an arbitrary metric space:\n22Recall from Definition 5.3 that extended ball is a pair (x, r) where x ∈ X is the “center” and r ∈ (0, 1] is the “radius”.\n23Recall from Section 5.1 that an end of an infinite rooted tree is an infinite path starting at the root.\nDefinition 5.18. Given a metric space (X,D), a subset S ⊂ X is called d-fat, d < COV(X), if for any open neighborhood U of S the covering dimension of S ∪ (X \\ U) is at most d.\nNote that any open neighborhood U of a d-fat subset S has covering dimension COV(X), whereas cutting out U \\ S reduces the covering dimension by a positive amount that is bounded away from zero, irrespective of the choice of U .\nIn both examples above, the max-min-covering dimension is d. This is because every point outside the fat subset has an open neighborhood whose covering dimension is at most d (and the covering dimension of the fat subset itself is at most d, too). We formalize this argument as follows:\nClaim 5.19. Suppose metric space (X,D) contains a subset S ⊂ X of covering dimension d such that every x ∈ X \\ S has an open neighborhood Nx of covering dimension at most d. Then MaxMinCOV(X) ≤ d.\nProof. Equivalently, we need to show that MinCOV(Y ) ≤ d for any subset Y ⊂ X. Fix Y ⊂ X. For each ǫ > 0 we need to produce a non-empty subset U ⊂ Y such that U is open in (Y,D) and its covering dimension is at most d + ǫ. If Y ⊂ S we can simply take U = Y , because COV(Y ) ≤ COV(S) = d. Now suppose there exists a point x ∈ Y \\ S. Then U = Nx ∩ Y is non-empty and open in the metric space restricted to Y , and COV(U) ≤ COV(Nx) ≤ d.\nIn fact, this property applies to any d-fat subset in a compact metric space.\nLemma 5.20. Suppose a compact metric space (X,D) contains a d-fat subset S ⊂ X. Then every x ∈ X \\ S has an open neighborhood Nx of covering dimension at most d. Therefore MaxMinCOV(X) ≤ d.\nProof. Consider some point x ∈ X \\ S. Since S is closed, D(x, S) > 0. Denoting r = 14 D(x, S), let U be the union of all radius-r open balls centered in S. Then U is an open set containing S, so COV(X \\ U) ≤ d. Since B(x, r) ⊂ X \\ U , its covering dimension is at most d, too. The bound on MaxMinCOV(X) follows from Claim 5.19."
    }, {
      "heading" : "5.4 Warm-up: taking advantage of fat subsets",
      "text" : "As a warm-up for our general algorithmic result, let us consider metric spaces with d∗-fat subsets, and design a modification of the zooming algorithm whose regret dimension can be arbitrarily close to d∗ for such metric spaces. In particular, we establish that COV(X) is, in general, not an optimal regret dimension. Further, our algorithm essentially retains the instance-specific guarantee with respect to the zooming dimension. As a by-product, we develop much of the technology needed for the general result in the next subsection.\nThe zooming algorithm from Section 4 may perform poorly on metric spaces with a fat subset S if the optimal arm x∗ is located inside S. This is because as the confidence ball containing x∗ shrinks, it may be too burdensome to keep covering24 the profusion of arms located near x∗, in the sense that it may require activating too many arms. We fix this problem by imposing quotas on the number of active arms. Thus some arms may not be covered. However, we show that (for a sufficiently long phase, with very high probability) there exists an optimal arm that is covered, which suffices for the technique in Section 4.1 to produce the desired regret bound.\nWe define the quotas as follows. For a phase of duration T and a fixed d > d∗, the quotas are\n∀Y ∈ {X \\ S, S} : |{active arms x ∈ Y : rt(x) ≥ ρ}| ≤ ρ−d, ρ = T−1/(d+2).\nAlgorithm 2 (zooming algorithm with quotas)\nfor phase i = 1, 2, 3, . . . do Initially, no arms are active. for round t = 1, 2, 3, . . . , 2i do EligibleArms = {arms x ∈ X: activating x does not violate any quotas}. Activation rule: if some arm x ∈ EligibleArms is not covered,\npick any such arm and activate it. Selection rule: play any active arm with the maximal index (7).\nWe use a generic modification of the zooming algorithm where the activation rule only considers arms that, if activated, do not violate any of the given quotas.\nTo pave the way for a generalization, consider a sequence of sets (S0, S1, S2) = (X,S, ∅), and let k = 1 be the number of non-trivial sets in this sequence. Our algorithm and analysis easily generalize to a sequence of closed subsets S0 , . . . , Sk+1 ⊂ X, k ≥ 1 which satisfies the following properties:\n• X = S0 ⊃ S1 ⊃ . . . ⊃ Sk ⊃ Sk+1 = ∅; the sequence is strictly decreasing. • COV(Si \\ U) ≤ d for every i ∈ {0 , . . . , k} and any open subset U ⊂ X that contains Si+1. 25\nWe call such sequence a d-fatness decomposition of length k. We generalize the quotas in an obvious way: for a phase of duration T and a fixed d > d∗,\n∀i ∈ {0 , . . . , k} : |{active arms x ∈ Si \\ Si+1 : rt(x) ≥ ρ}| ≤ ρ−d, ρ = T−1/(d+2). (29)\nThis completes the specification of the algorithm. Note that the invariant (29) holds for each round; this is because during a given phase the confidence radius of every active arm does not increase over time.\nTo implement the algorithm, it suffices to use a covering oracle for each subset Si+1 \\ Si, i ∈ {0 , . . . , k}. Here a covering oracle for subset Y ⊂ X generalizes the covering oracle defined in Section 1.5: the oracle takes a finite collection of open balls, where each ball is represented as a (center, radius) pair, and either declares that these balls cover Y or outputs an uncovered point.\nLemma 5.21. Consider the Lipschitz MAB problem on a compact metric space (X,D) which contains a d∗-fatness decomposition (S0 , . . . , Sk+1) of finite length k ≥ 1. Let A be the zooming algorithm (Algorithm 2) with quotas (29), for some parameter d > d∗. Then the regret dimension of A is at most d. Moreover, the instance-specific regret dimension of A is bounded from above by the zooming dimension.\nThe remainder of this section presents the full proof of Lemma 5.21. The following rough outline of the proof may serve as a useful guide.\nProof Outline. For simplicity, assume there is a unique optimal arm, and call it x∗. The desired regret bounds follow from the analysis in Section 4.1 as long as x∗ is covered w.h.p. throughout any sufficiently long phase. All arms in S = Sk are covered eventually because COV(S) < d, so if x\n∗ ∈ S then we are done. If x∗ 6∈ S then pick the largest ℓ such that x∗ ∈ Sℓ\\Sℓ+1. Then there is some ǫ > 0 such that all arms in Sℓ+1 are suboptimal by at least ǫ. Letting U be an ǫ 2 -neighborhood of Sℓ+1, note that each arm in U is suboptimal by at least ǫ2 . It follows that (w.h.p.) the algorithm cannot\n24Recall that an arm x is called covered at time t if for some active arm y we have D(x, y) ≤ rt(y). 25For i = k, this condition is equivalent to COV(Sk) ≤ d.\nactivate too many arms in U . On the other hand, Sℓ \\U has a low covering dimension, so (w.h.p.) the algorithm cannot activate too many arms in Sℓ \\ U , either. It follows that (for a sufficiently long phase, w.h.p.) the algorithm stays within the quota, in which case x∗ is covered.\nTo prove Lemma 5.21, we incorporate the analysis from Section 4.1 as follows. We state a general lemma which applies to the zooming algorithm with a modified activation rule (and no other changes). We assume that the new activation rule is at least as selective as the original one: an arm is activated only if it is not covered, and at most one arm is activated in a given round. We call such algorithms zooming-compatible.\nA phase of a zooming-compatible algorithm is called clean if the property in Claim 4.5 holds for each round in this phase. Claim 4.5 carries over: each phase i is clean with probability at least 1− 4−i. Let us say that a given round in the execution of the algorithm is well-covered if after the activation step in this round some optimal arm is covered. (We focus on compact metric spaces, so the supremum µ∗ = sup(µ,X) is achieved by some arm; we will call such arm optimal.) A phase of the algorithm is called well-covered if all rounds in this phase are well-covered.\nAn algorithm is called (k, d)-constrained if in every round t it holds that\n|{active arms x ∈ X : rt(x) ≥ ρ}| ≤ (k + 1) ρ−d, ρ = T−1/(d+2),\nwhere T is the duration of the current phase. Note that the zooming algorithm with quotas (29) is (k, d)-constrained by design.\nLemma 5.22 (immediate from Section 4.1). Consider the Lipschitz MAB problem on a compact metric space. Let AT be one phase of a zooming-compatible algorithm, where T is the duration of the phase. Consider a clean run of AT .\n(a) Consider some round t ≤ T such that all previous rounds are well-covered. Then\nD(x, y) > min(rt(x), rt(y)) ≥ 13 min(∆(x),∆(y)). (30)\nfor any two distinct active arms x, y ∈ X.\n(b) Suppose the phase is well-covered. If AT is (c, d)-constrained, d ≥ 0, then it has regret\nR(T ) ≤ O(c log T ) 1d+2 × T d+1 d+2 .\nThis regret bound also holds if d is the zooming dimension with multiplier c > 0.\nAn algorithm is called eventually well-covered if for every problem instance (X,D, µ) there is a constant i0 such that every clean phase i > i0 is guaranteed to be well-covered, as long as the preceding phase i− 1 is also clean.26\nCorollary 5.23 (immediate from Section 4.1). Consider the Lipschitz MAB problem on a compact metric space. Let A be a zooming-compatible algorithm. Assume A is eventually well-covered. Then its (instance-specific) regret dimension is at most the zooming dimension. Further, if A is (k, d)-constrained, for some constant k > 0, then the regret dimension of A is at most d.\nSince our algorithm is (k, d)-constrained by design, to complete the proof of Lemma 5.21 it suffices to prove that the algorithm is eventually well-covered. This is the part of the analysis that is new, compared to Section 4.1. The crux of the argument is encapsulated in the following claim.\n26The last clause (“as long as the preceding phase is also clean”) is not needed for this subsection; it is added for compatibility with the analysis of the per-metric optimal algorithm in Section 5.5.\nClaim 5.24. Consider the Lipschitz MAB problem on a compact metric space. Fix d > 0. Let S′ ⊂ S ⊆ X (where S′ can be empty) be closed subsets such that COV(S \\ U) < d for any open neighborhood U of S′. Further, suppose S contains some optimal arm and S′ does not. Let AT be a clean phase of a zooming-compatible algorithm, where T is the duration of the phase. Suppose AT activates an arm whenever some arm in S \\ S′ is not covered and, for some ρT > 0,\n|{active arms x ∈ S \\ S′ : rt(x) ≥ ρT }| < ρ−dT .\nHere ρT depends on T so that ρT → 0 as T → ∞. Then the phase is well-covered whenever T ≥ T0, for some finite T0 which may depend on the problem instance.\nProof. Recall that a ρ-packing is a set P ⊂ X such that any two points in this set are at distance at least ρ. For any C > 0 and any subset Y ⊂ X with COV(Y ) < d, there exists ρ0 such that for any ρ ≤ ρ0 any ρ-packing of Y consists of at most C ρ−d points.\nWe pick ρ0 > 0 as follows.\n• If S′ is empty, we pick ρ0 > 0 such that any ρ-packing of S, ρ ≤ ρ0, consists of at most ρ−d points. Such ρ0 exists because COV(S) < d.\n• Now suppose S′ is not empty. Since the metric space is compact and S′ is closed, µ attains its supremum on S′. Since S′ does not contain any optimal arm, it follows that sup(µ, S′) < µ∗−ǫ for some ǫ > 0. Let U = ∪x∈S′ B(x, ǫ2) be the ǫ2 -neighborhood of S′. Then for each arm x ∈ U we have ∆(x) > ǫ2 . Since the metric space is compact, there is c0 < ∞ such that any ǫ 6 -packing of U consists of at most c0 points. Moreover, we are given that COV(S \\ U) < d. Pick ρ0 > 0 such that any ρ 4 -packing of S \\ U consists of at most ρ−d − c0 points, for any\nρ ≤ ρ0.\nSupose T is such that ρT ≤ ρ0; denote ρ = ρT . Let us prove that all rounds in this phase are well-covered. Let us use induction on round t. The first round of the phase is well-covered by design, because in this round some arm is activated, and the corresponding confidence ball covers the entire metric space. Now assume that for some round t, all rounds before t are well-covered. Let P be the set of all arms x ∈ S that are active at time t with rt(x) ≥ ρ. We claim that |P | < ρ−d. Again, we consider two cases depending on whether S′ is empty.\n• Suppose S′ is empty. By Lemma 5.22(a), P is an ρ-packing, so |P | < ρ−d by our choice of ρ0.\n• Suppose S′ is not empty. For any active arm x ∈ U it holds that ∆(x) ≥ ǫ2 . Then by Lemma 5.22(a) the active arms in U form an ǫ6 -packing of U . So U contains at most c0 < ∞ active arms.\nFurther, let P ′ be the set of all arms in S \\ U that are active at round t with rt(x) ≥ ρ. By Lemma 5.22(a), P is a ρ-packing, so |P ′| < ρ−d − c0 by our choice of ρ0. Again, it follows that |P | < ρ−d.\nTherefore by our assumption the algorithm activates an arm whenever some arm in S \\ S′ is not covered. It follows that S \\S′ is covered after the activation step, so in particular some optimal arm is covered.\nCorollary 5.25. In the setting of Lemma 5.21, any clean phase of algorithm A of duration T ≥ T0 is well-covered, for some finite T0 which can depend on the problem instance.\nProof. Pick the largest ℓ ∈ {0 , . . . , k} such that Sℓ \\ Sℓ+1 contains some optimal arm. Then Claim 5.24 applies with S = Sℓ and S ′ = Sℓ+1.\nIn passing, let us give an example of a fatness decomposition of length > 1. Start with a metric space (X,D) with a d-fat subset S. Consider the product metric space (X ×X,D∗) defined by\nD∗((x1, x2), (y1, y2)) = D(x1, y1) +D(x2, y2).\nThis metric space admits a 2d-fatness decomposition\n(S0, S1, S2, S3) = (X ×X, (S ×X) ∪ (X × S), S × S, ∅)."
    }, {
      "heading" : "5.5 Transfinite fatness decomposition",
      "text" : "The fact that d = MaxMinCOV(X) < COV(X) does not appear to imply the existence of a d-fatness decomposition of any finite length. Instead, we prove the existence of a much more general structure which we then use to design the per-metric optimal algorithm. This structure is a transfinite sequence of subsets of X, i.e. a sequence indexed by ordinal numbers rather than integers.27\nDefinition 5.26. Fix a metric space (X,D). A transfinite d-fatness decomposition of length β, where β is an ordinal, is a transfinite sequence {Sλ}0≤λ≤β+1 of closed subsets of X such that:\n(a) S0 = X, Sβ+1 = ∅, and Sν ⊇ Sλ whenever ν < λ. (b) for any ordinal λ ≤ β and any open set U ⊂ X containing Sλ+1 it holds that COV(Sλ\\U) ≤ d. 28 (c) If λ is a limit ordinal then Sλ = ⋂ ν<λ Sν .\nFor finite length β this is the same as (non-transfinite) d-fatness decomposition. The smallest infinite length β is a countable infinity β = ω. Then the transfinite sequence {Sλ}0≤λ≤β+1 consists of subsets {Si}i∈N followed by Sω = ∩i∈N Si and Sω+1 = ∅. Proposition 5.27. For every compact metric space (X,D), the max-min-covering dimension is equal to the infimum of all d such that (X,D) has a transfinite d-fatness decomposition.\nProof. Assume there exists a transfinite d-fatness decomposition {Sλ}0≤λ≤β+1, for some ordinal β. Let us show that MaxMinCOV(X) ≤ d. Suppose not, then there exists a non-empty subset Y ⊆ X with MinCOV(Y ) > d. Let us use transfinite induction on λ to prove that Y ⊆ Sλ for all λ ≤ β. This would imply Y ⊆ Sβ and consequently COV(Sβ) > d, contradiction.\nThe transfinite induction consists of three cases: “zero case”, “limit case”, and “successor case”. The zero case is Y ⊆ S0 = X. The limit case is easy: if λ ≤ β is a limit ordinal and Y ⊆ Sν for every ν < λ then Y ⊆ Sλ = ∩ν<λSν . For the successor case, we assume Y ⊆ Sλ, λ + 1 ≤ β, and we need to show that Y ⊆ Sλ+1. Suppose not, and pick some x ∈ Y ∩ (Sλ \\ Sλ+1). Since Sλ+1 is closed, x is at some positive distance 2ǫ from Sλ+1. Then an ǫ-neighborhood U of Sλ+1 is disjoint with a ball B = B(x, ǫ). So B ⊆ Sλ \\ U , which implies COV(B) ≤ d by definition of transfinite d-fatness decomposition. However, since B ∩ Y is open in the metric topology induced by Y , by definition of the min-covering dimension we have COV(B) > d. We obtain a contradiction, which completes the successor case.\nNow given any d > MaxMinCOV(X), let us construct a transfinite d-fatness decomposition of length β, where β is any ordinal whose cardinality exceeds that of X. For a metric space (Y,D), a point is called d-thin if it is contained in some open U ⊂ Y such that COV(Y ) < d, and d-thick otherwise. Let Fat(Y, d) be the set of all d-thick points; note that it is a closed subset of Y . For every ordinal λ ≤ β + 1, we define a set Sλ ⊂ X using transfinite induction as follows:\n27Formally, a transfinite sequence of length β (where β is an ordinal) is a mapping from {ordinals λ : 0 ≤ λ ≤ β} to the corresponding domain, in this case the power set of X.\n28For λ = β, this is equivalent to COV(Sβ) ≤ d.\n1. S0 = X and Sλ+1 = Fat(Sλ, d) for each ordinal λ. 2. If λ is a limit ordinal then Sλ = ⋂\nν<λ Sν . This completes the construction of a sequence {Sλ}λ≤β+1.\nNote that each Sλ is closed, by transfinite induction. It remains to show that the sequence satisfies the properties (a)-(c) in Definition 5.26. It follows immediately from the construction that S0 = X and Sν ⊇ Sλ when ν < λ. To prove that Sβ = ∅, observe first that the sets Sλ \\ Sλ+1 (for 0 ≤ λ < β) are disjoint subsets of X, and the number of such sets is greater than the cardinality of X, so at least one of them is empty. This means that Sλ = Sλ+1 for some λ < β. If Sλ = ∅ then Sβ = ∅ as desired. Otherwise, the relation Fat(Sλ, d) = Sλ implies that the metric space (Sλ, D) contains no open set U ⊂ Sλ with COV(U) < d. It follows that MinCOV(Sλ) ≥ d, contradicting the assumption that MaxMinCOV(X) < d. This completes the proof of property (a). To prove property (b), note that if U is an open neighborhood of Sλ+1 then the set T = Sλ \\ U is closed (hence compact) and is contained in Thin(Sλ, d). Consequently T can be covered by open sets V satisfying COV(V ) < d. By compactness of T , this covering has a finite subcover V1, . . . , Vm, and consequently COV(T ) = max1≤i≤m COV(Vi) < d. Finally, property (c) holds by design.\nTheorem 5.28. Consider the Lipschitz MAB problem on a compact metric space (X,D) with a transfinite d∗-fatness decomposition, d∗ ≥ 0. Then for each d > d∗ there exists an algorithm A such that DIM(A) ≤ d. Moreover, the instance-specific regret dimension of A is bounded from above by the zooming dimension.\nIn the rest of this section we design and analyze an algorithm for Theorem 5.28. The algorithm from the previous subsection has regret proportional to the length of the fatness decomposition, so it does not suffice even if the fatness decomposition has countably infinite length. As it turns out, the main algorithmic challenge in dealing with fatness decompositions of transfinite length is to handle the special case of finite length k so that the regret bound does not depend on k.\nIn what follows, let {Sλ}0≤λ≤β+1, be a transfinite d∗-fatness decomposition of length β, for some ordinal β and d∗ ≥ 0. Fix some d > 0.\nProposition 5.29. For any closed V ⊂ X, there exists a maximal ordinal λ such that V intersects Sλ.\nProof. Let Ω = {ordinals ν ≤ β: V intersects Sν}, and let ν = sup(Ω). Then Sν ∩V = ⋂ λ∈Ω(Sλ ∩ V ), and this set is nonempty because X is compact and the closed sets {Sλ ∩ V : λ ∈ Ω} have the finite intersection property. (To derive the finite intersection property, consider a finite subset Ω′ ⊂ Ω and let ν ′ = max(Ω′) ∈ Ω. Then ⋂λ∈Ω′(Sλ∩V ) = Sν′ ∩V , which is not empty by definition of Ω.)\nRecall that the supremum µ∗ = sup(µ,X) is attained because the metric space is compact, and the arms x such that µ(x) = µ are called optimal. Let λmax be the maximal λ such that Sλ contains an optimal arm. Such λmax exists by Proposition 5.29 because the set V = µ\n−1(µ∗) is non-empty and closed. Note that Sλmax contains an optimal arm, whereas Sλmax+1 does not.\nOur algorithm is a version of Algorithm 2 from the previous subsection, with a different “eligibility rule” – the definition of EligibleArms. For phase duration T and an ordinal λ ≤ β, define the quota\nQλ , { |{active arms x ∈ Sλ : rt(x) ≥ ρ}| < ρ−d } , ρ = T−1/(d+2).\nThe algorithm maintains the target ordinal λ∗, recomputed after each phase, so that some arm in Sλ∗ is activated as long as the quota Qλ∗ is satisfied. Further, there is a subset N of cardinality at\nmost T d/(d+2), chosen in the beginning of each phase, such that all arms in N are always eligible and all arms not in Sλ∗ ∪ N are never eligible.\nNote that such algorithm is (1, d)-constrained by design, because in any round t there can be at most ρ−d active arms in Sλ∗ \\ N with confidence radius less than ρ = T−1/(d+2).\nThe analysis hinges on proving that after any sufficiently long clean phase the target ordinal is λmax, and then the subsequent phase (assuming it is also clean) is well-covered, and then the desired regret bounds follow from Corollary 5.23. Any sufficiently long clean phase with target ordinal λmax is well-covered by Claim 5.24. So the only new thing to prove is that that after any sufficiently long clean phase the target ordinal is λmax.\nWe also change the definition of index to\nIt(x) = µt(x) + 3 rt(x), (31)\nwhere, as before, µt(x) denotes the average payoff from arm x in rounds 1 to t− 1 of the current phase, and rt(x) is the current confidence radius of this arm. It is easy to check that the analysis in Section 4.1, and therefore also Lemma 5.22 and Corollary 5.23, carry over to any index of the form It(x) = µt(x) + c0 rt(x) for some absolute constant c0 ≥ 2 (the upper bound on regret increases by the factor of c0).\nIn the beginning of each phase, the subset N ⊂ X is defined as follows. We choose N to be an ǫ0-net\n29 of X which consists of at most T d/(d+2) points, for (essentially) the smallest possible ǫ0 > 0. More precisely, we compute an ǫ0 > 0 and an ǫ0-net N using a standard greedy heuristic. For a given ǫ > 0 we construct an ǫ-net S ⊂ X as follows: while there exists a point x ∈ X such that D(S, x) , infy∈S D(x, y) < ǫ, add any such point to S, and abort if |S| > T d/(d+2). We consecutively try ǫ = 2−j for each j = 1, 2, 3, . . ., and pick the smallest ǫ which results in an ǫ-net of at most T d/(d+2) points.\nIn the end of each phase, the new target ordinal λ∗ is defined as follows. We pick an ǫ∗ according to T and ǫ0, and focus on arms whose confidence radius is less than ǫ\n∗. Let A be the set of all such arms. We define λ∗ as the largest ordinal λ such that Sλ intersects B̄(A, ǫ∗) , {x ∈ X : D(A, x) ≤ ǫ∗}, the the closed ǫ∗-neighborhood of A. Such ordinal exists by Proposition 5.29.\nThe pseudocode is summarized as Algorithm 3.\nImplementation details. To implement Algorithm 3, it suffices to use the following oracles:\n• For any finite set of open balls B1 , . . . , Bn (given via the centers and the radii) whose union is denoted by B, the depth oracle returns sup{λ : Sλ intersects the closure of B}.\n• Given balls B1 , . . . , Bn as above, and an ordinal λ, the enhanced covering oracle either reports that B covers Sλ, or it returns an arm x ∈ Sλ \\B.\nTo avoid the question of how arbitrary ordinals are represented on the oracle’s output tape, we can instead say that the depth oracle outputs a point u ∈ Sλ \\ Sλ+1 instead of outputting λ. In this case, the definition of the covering should be modified so that it inputs a point u ∈ Sλ \\Sλ+1 rather than the ordinal λ itself.\nAnalysis. We bring in the machinery developed in the previous subsection. Note that Algorithm 3 is zooming-compatible and (1, d)-constrained by design. Therefore by Corollary 5.23 we only need to prove that it is eventually well-covered. If in a given clean phase the target ordinal is λmax, this phase satisfies the assumptions in Claim 5.24 for S = Sλmax and S ′ = Sλmax+1. It follows that any\n29Recall from Section 3.3 that an ǫ-net of a metric space (X,D) is a subset S ⊂ X such that any two points in S are at distance at least ǫ from one another, and any point in X is within distance ǫ from some point in S.\nAlgorithm 3 (the per-metric optimal algorithm)\nTarget ordinal λ∗ ← 0. for phase i = 1, 2, 3, . . . do\n{Phase duration is T = 2i} Compute an ǫ0 > 0 and an ǫ0-net N of X such that |N | < T d/(d+2).\n{use greedy heuristic} Initially, no arms are active. for round t = 1, 2, 3, . . . , T do\nEligibleArms =\n{\nN ∪ Sλ∗ if constraint Qλ∗ is satisfied, N otherwise.\nActivation rule: if some arm x ∈ EligibleArms is not covered, pick any such arm and activate it.\nSelection rule: play any active arm with the maximal index (31). {Recompute the target ordinal λ∗} ǫ∗ = 6 max(ǫ0, 4T−1/(d+2) √ log T ). λ∗ = max{λ : Sλ intersects B̄(A, ǫ∗) }, where A = {active arms x: rT (x) < ǫ∗ }.\nsufficiently long clean phase with target ordinal λmax is well-covered. Thus it remains to show that after any sufficiently long clean phase of Algorithm 3 the target ordinal is λmax. (This is where we use the new definition of index.)\nClaim 5.30. After any sufficiently long clean phase of Algorithm 3 the target ordinal is λmax.\nTo prove Claim 5.30 we need to “open up the hood” and analyze the internal workings of the algorithm. (We have been avoiding this so far by using Corollary 5.23.) Such analysis is encapsulated in the following claim. Note that we cannot assume that the phase is well-covered.\nClaim 5.31. Consider a clean phase of Algorithm 3 of duration T , with ǫ0-net N . Let y be an arm that has been played at least once in this phase. Then\n(a) ∆(y) ≤ 4 rT (y) + ǫ0. (b) For any optimal arm x∗, there exists an active arm x such that\nmin(D(x, x∗), rT (x)) ≤ 4 rT (y) + 2 ǫ0.\nProof. Let xnet ∈ N be such that D(x∗, xnet) ≤ ǫ0. Let t be the last time arm y is played in this phase. Let x be an arm that covers xnet at time t. (Since N ⊂ EligibleArms, all points in N are covered at all times.) Then:\nIt(x) ≥ µ(x) + 2rt(x) by definition of index and confidence radius ≥ µ(xnet) + rt(x) because x covers xnet at time t ≥ µ∗ − ǫ0 + rt(x) because D(x∗, xnet) ≤ ǫ0 It(x) ≤ It(y) because arm y is played at time t ≤ µ(y) + 4 rt(y) by definition of index and confidence radius = µ∗ −∆(y) + 4 rt(y).\nCombining the two inequalities, we obtain:\nµ∗ −∆(y) + 4 rt(y) ≥ It(x) ≥ µ∗ − ǫ0 + rt(x).\nNoting that rT (y) = rt(y), we obtain\n∆(y) + rt(x) ≤ 4 rT (y) + ǫ0.\nThis immediately implies part (a) of the claim. Part (b) follows by triangle inequality, because\nD(x, x∗) ≤ D(x, xnet) +D(xnet, x∗) ≤ rt(x) + ǫ0.\nWe also need a simple and well-known fact about compact metric spaces.\nClaim 5.32 (Folklore). For any given δ > 0 there exists T0 < ∞ such that in any phase of Algorithm 3 of duration T > T0, the algorithm computes an ǫ0-net N such that ǫ0 < δ.\nProof. Fix δ > 0. Since the metric space is compact, there exists a covering of X with finitely many subsets S1 , . . . , Sn ⊂ X of diameter less than δ2 . Suppose T is large enough so that n < T d/(d+2). Suppose the algorithm computes an ǫ0-net N such that ǫ0 ≥ δ. Then the following iteration of the greedy heuristic (if not aborted) would construct an ǫ0/2-net N ′ for X with more than T d/(d+2) points. However, any two points in N ′ lie at distance ≥ δ/2 from one another, so they cannot lie in the same set Si. It follows that |N ′| ≤ n, contradiction.\nProof of Claim 5.30: Consider a clean phase of Algorithm 3 of duration T , with an ǫ0-net N . Let ǫ∗ and A be defined as in Algorithm 3, so that A = {active arms x: rt(x) < ǫ∗ }. We need to show that for any sufficiently large T two things happen: B̄(A, ǫ∗) intersects Sλmax and it does not intersect Sλmax+1.\nLet xfreq be the most frequently played arm by the end of the phase. We claim that\nrT (xfreq) < 4T −1/(d+2)√log T .\nSuppose not. By our choice of xfreq, at time T all arms have confidence radius at least rT (xfreq). Since the algorithm is (1, d)-constrained, it follows that at most n = 2T d/(d+2) arms are activated throughout the phase. So by the pigeonhole principle nT (xfreq) ≥ T/n = 12T 2/(d+2), which implies the desired inequality. Claim proved.\nLet x∗ ∈ Sλmax be some optimal arm. Taking y = xfreq in Claim 5.31(b) and noting that 4 rT (xfreq) + 2 ǫ0 ≤ ǫ∗, we derive that there exists an active arm x such that D(x, x∗) ≤ ǫ∗ and rT (x) ≤ ǫ∗. It follows that x ∈ A and x∗ ∈ B̄(A, ǫ∗). Therefore B̄(A, ǫ∗) intersects Sλmax .\nSince the metric space is compact and Sλmax+1 is a closed subset that does not contain an optimal arm, it follows that any arm in this subset has expected payoff at most µ∗ − ǫ, for some ǫ > 0. Assume T is sufficiently large so that ǫ∗ < ǫ/6. (We can make sure that ǫ0 < ǫ/6 by Claim 5.32).\nTo complete the proof, we need to show that B̄(A, ǫ∗) does not intersect Sλmax+1. Suppose this is not the case. Then there exists x ∈ Sλmax+1 and active y ∈ X such that D(x, y) ≤ ǫ∗ and rT (y) ≤ ǫ∗. Then by Claim 5.31 (a) we have that ∆(y) ≤ 4 ǫ∗ + ǫ0 ≤ 5 ǫ∗, which implies that ∆(x) ≤ ∆(y) + D(x, y) ≤ 6 ǫ∗ < ǫ, contradicting our assumption that every arm in Sλmax+1 has expected payoff at most µ∗ − ǫ. Claim proved."
    }, {
      "heading" : "6 The Lipschitz experts problem",
      "text" : "We turn our attention to the Lipschitz experts problem: the full-feedback version of the Lipschitz MAB problem. This section defines the problem and overviews our contributions for this problem. Proofs of the theorems stated in this section will be deferred to the following three sections.\nProblem definition. A problem instance is specified by a triple (X,D,P), where (X,D) is a metric space and P is a probability measure with universe [0, 1]X , the set of all functions from X to [0, 1], such that the expected payoff function µ : x 7→ Ef∈P[f(x)] is a Lipschitz function on (X,D). The metric structure of (X,D) is known to the algorithm, the measure P is not. We will refer to P as the problem instance when the metric space (X,D) is clear from the context.\nIn each round t the algorithm picks a strategy xt ∈ X, then the environment chooses an independent sample ft : X → [0, 1] distributed according to the measure P. The algorithm receives payoff ft(xt), and also observes the entire payoff function f . More formally, the algorithm can query the value of f at an arbitrary finite number of points. Some of our upper bounds are for a (very) restricted version, called double feedback, where in each round the algorithm picks two arms (x, y), receives the payoff for x and also observes the payoff for y. By abuse of notation, we will treat the bandit setting as a special case of the experts setting.\nNote that the payoffs for different arms in a given round are not necessarily independent. This is essential because for any limit point x in the metric space one could use many independent samples from the vicinity of x to learn the expected payoff at x in a single round.\nRegret dichotomies. We show that the Lipschitz experts problem exhibits a regret dichotomy similar to the one in Theorem 1.6. It is known that the optimal regret for a finite strategy set is constant (Kleinberg et al., 2008a). Accordingly, the dichotomy is between O(1) and √ t regret.\nTheorem 6.1. The Lipschitz experts problem on metric space (X,D) is either 1-tractable, even with double feedback, or it is not g(t)-tractable for any g ∈ o( √ t), even with full feedback. The former occurs if and only if the completion of X is a compact metric space with countably many points.\nTheorem 6.1 and its bandit counterpart (Theorem 1.6) are proved jointly in Section 7, using essentially the same ideas. In both theorems, the regret dichotomy corresponds to the transition form countable to uncountable strategy set (assuming the metric space is compact and complete). Note that the upper bound in Theorem 6.1 only assumes double feedback, whereas the lower bound is for the unrestricted full feedback.\nNext, we investigate for which metric spaces the Lipschitz experts problem is o(t)-tractable. We extend Theorem 1.8 for the Lipschitz MAB problem to another regret dichotomy where the upper bound is for the bandit setting, whereas the lower bound is for full feedback. We prove this result in Section 8.\nTheorem 6.2. The Lipschitz experts problem on metric space (X,D) is either f(t)-tractable for some f ∈ o(t), even in the bandit setting, or it is not g(t)-tractable for any g ∈ o(t), even with full feedback. The former occurs if and only if the completion of X is a compact metric space.\nPolynomial regret in (very) high dimension. In view of the √ t lower bound from Theorems 6.1, we are interested in matching upper bounds. Gupta et al. (2007) observed that such bounds hold for every metric space (X,D) of finite covering dimension: namely, the Lipschitz experts problem on (X,D) is √ t-tractable. (Their algorithm is a version of algorithm UniformMesh described in Section 1.) Therefore it is natural to ask whether there exist metric spaces of infinite covering dimension with polynomial regret.\nWe settle this question by proving a characterization with nearly matching upper and lower bounds in terms of a novel dimensionality notion tailored to the experts problem. We define the log-covering dimension of (X,D) as the smallest number d ≥ 0 such that X can be covered by\nO ( 2r −d ) sets of diameter r for all r > 0. More formally:\nLCD(X) = lim sup r→0\nlog logNr(X)\nlog(1/r) . (32)\nwhere Nr(X) is the minimal size (cardinality) of a r-covering of X, i.e. the smallest number of sets of diameter at most r sufficient to cover X. Note that the number of sets allowed by this definition is exponentially larger than the one allowed by the covering dimension.\nTo give an example of a metric space with a non-trivial log-covering dimension, let us consider a uniform tree – a rooted tree in which all nodes at the same level have the same number of children. An ǫ-uniform tree metric is a metric on the ends of an infinitely deep uniform tree, in which the distance between two ends is ǫ−i, where i is the level of their least common ancestor. It is easy to see that an ǫ-uniform tree metric such that the branching factor at each level i is exp(ǫ−id(2d − 1)) has log-covering dimension d.\nFor another example, let PX denote the set of all probability measures overX = [0, 1]d. Consider PX as a metric space (PX ,W1) under the Wasserstein W1 metric, a.k.a. the Earthmover distance:\nW1(ν, ν ′) = inf E [ ‖Y − Y ′‖2 ] ,\nwhere the infimum is taken over all joint distributions (Y, Y ′) on X ×X with marginals ν and ν ′ respectively (for any two ν, ν ′ ∈ PX). 30 We show that the log-covering dimension of this metric space is equal to the covering dimension of (X,D). In fact, this example extends to any metric space X of finite diameter and covering dimension d; see Appendix D for the details.\nTheorem 6.3. Let (X,D) be a metric space of log-covering dimension d. Then the Lipschitz experts problem is (tγ)-tractable for any γ > d+1d+2 .\nThe algorithm in Theorem 6.3 is a version of UniformMesh. The same algorithm (with a much more sophisticated analysis) enjoys a better regret bound if each function f ∈ support(P) is itself a Lipschitz function on (X,D). We term this special case the uniformly Lipschitz experts problem.\nTheorem 6.4. Let (X,D) be a metric space of log-covering dimension d. Then the uniformly Lipschitz experts problem is (tγ)-tractable for any γ > d−1d .\nThe proofs of these theorems can be found in Section 9.1 and Section 9.2, respectively.\nPer-metric optimal regret bounds. We find that the log-covering dimension is not the right notion to characterize optimal regret for arbitrary metric spaces. Instead, we define the max-minlog-covering dimension (MaxMinLCD): essentially, we take the definition of MaxMinCOV and replace covering dimension with log-covering dimension.\nMaxMinLCD(X) = supY⊂X inf{ LCD(Z) : open non-empty Z ⊂ Y }. (33)\nNote that in general MaxMinLCD(X) ≤ LCD(X). Equality holds for “homogeneous” metric spaces such as ǫ-uniform tree metrics. We derive the regret characterization in terms MaxMinLCD; the characterization is tight for the uniformly Lipschitz experts problem.\nTheorem 6.5. Let (X,D) be an uncountable metric space and d = MaxMinLCD ≥ 0. Then: 30 The Wasserstein W1 metric is one of the standard ways to define a distance on probability measures. In particular, it is widely used in Computer Science literature to compare discrete distributions, e.g. in the context of image retrieval (Rubner et al., 2000).\n(a) the Lipschitz experts problem is (tγ)-tractable for any γ > d+1d+2 , (b) the uniformly Lipschitz experts problem is (tγ)-tractable for any γ > max(d−1d , 1 2 ), (c) the uniformly Lipschitz experts problem is not (tγ)-tractable for any γ < max(d−1d , 1 2).\nThe algorithms in parts (a) and (b) use a generalization of the transfinite decomposition from the bandit per-metric optimal algorithm (Theorem 1.5). The lower bound in part (c) builds on the lower-bounding technique for the √ t lower bound on uncountable metric spaces. The proof can be found in Section 9.3. Our results for Lipschitz experts amount to a nearly complete characterization of per-metric optimal regret bounds, analogous to that in Table 1 on page 7. This characterization is summarized in the table below. (The characterization falls short of being complete because the upper and lower bounds for finite MaxMinLCD = d ∈ [0,∞) do not match.)\n7 The (sub)logarithmic vs. √ t regret dichotomy This section concerns the dichotomy between (sub)logarithmic and √ t regret for Lipschitz bandits and Lipschitz experts (Theorem 1.6 and Theorem 6.1, respectively). We focus on the restriction of these results to compact metric spaces:\nTheorem 7.1. Fix a compact metric space (X,D). The following dichotomies hold:\n(a) The Lipschitz MAB problem on (X,D) is either f(t)-tractable for every f ∈ ω(log t), or it is not g(t)-tractable for any g ∈ o( √ t).\n(b) The Lipschitz experts problem on (X,D) is either 1-tractable, even with double feedback, or it is not g(t)-tractable for any g ∈ o( √ t), even with full feedback and uniformly Lipschitz\npayoffs."
    }, {
      "heading" : "In both cases, (sub)logarithmic tractability occurs if and only if X is countable.",
      "text" : "We also prove two auxiliary results: the (log t)-intractability for Lipschitz bandits on infinite metric spaces (Theorem 1.7), and an algorithmic result via a more intuitive oracle access to the metric space (for metric spaces of finite Cantor-Bendixson rank, a classic notion from point-set topology).\nThe section is organized as follows. We provide a joint analysis for Lipschitz bandits and Lipschitz experts: an overview in Section 7.1, the lower bound is in Section 7.2, and the algorithmic result is in Section 7.3. The two auxiliary results are, respectively, in Section 7.4 and Section 7.5."
    }, {
      "heading" : "7.1 Regret dichotomies: an overview of the proof",
      "text" : "We identify a simple topological property (existence of a topological well-ordering) which entails the algorithmic result, and another topological property (existence of a perfect subspace) which entails the lower bound.\nDefinition 7.2. Consider a topological space X. X is called perfect if it contains no isolated points. A topological well-ordering of X is a well-ordering (X,≺) such that every initial segment thereof is an open set. If such ≺ exists, X is called well-orderable. A metric space (X,D) is called well-orderable if and only if its metric topology is well-orderable.\nPerfect spaces are a classical notion in point-set topology. Topological well-orderings are implicit in the work of Cantor (1883), but the particular definition given here is new, to the best of our knowledge.\nThe proof of Theorem 7.1 consists of three parts: the algorithmic result for a compact, wellorderable metric space, the lower bound for a metric space with a perfect subspace, and the following lemma that ties together the two topological properties.\nLemma 7.3. For any compact metric space (X,D), the following are equivalent: (i) X is a countable set, (ii) (X,D) is well-orderable, and (iii) no subspace of (X,D) is perfect.31\nLemma 7.3 follows from classical theorems of Cantor (1883) and Mazurkiewicz and Sierpinski (1920). We provide a proof in Appendix C for the sake of making our exposition self-contained.\nExtension to arbitrary metric spaces. We extend Theorem 7.1 to the corresponding dichotomies for arbitrary metric spaces using the reduction to complete metric spaces in Appendix B, and the o(t)-intractability result for non-compact metric spaces in Theorem 6.2 (which is proved independently in Section 8).\nFor Lipschitz MAB, the argument is very simple. First, we reduce from arbitrary metric spaces to complete metric spaces: we show that the Lipschitz MAB problem is f(t)-tractable on a given metric space if and only if it is f(t)-tractable on the completion thereof (see Appendix B). Second, we reduce from complete metric spaces to compact metric spaces using Theorem 6.2: by this theorem, the Lipschitz MAB problem is not o(t)-tractable if the metric space is complete but not compact. Thus, we obtain the desired dichotomy for Lipschitz MAB on arbitrary metric spaces, as stated in Theorem 1.6.\nFor Lipschitz experts, the argument is slightly more complicated because the reduction to complete metric spaces only applies to the lower bound. Let (X,D) be an arbitrary metric space, and let (X∗,D∗) denote the metric completion thereof. First, if (X∗,D∗) is not compact then by Theorem 6.2 the Lipschitz experts problem is not o(t)-tractable. Therefore, it remains to consider the case that (X∗,D∗) is compact. Note that Theorem 7.1 applies to (X∗,D∗). If X∗ is not countable, then by Theorem 7.1 the problem is not o( √ t)-tractable on (X∗,D∗), and therefore it is not o( √ t)-tractable on (X,D) (see Appendix B). If X∗ is countable, then the algorithm and analysis in Section 7.3 apply to X, too, and guarantee O(1)-tractability. Thus, we obtain the desired dichotomy for Lipschitz experts on arbitrary metric spaces, as stated in Theorem 6.1."
    }, {
      "heading" : "7.2 Lower bounds via a perfect subspace",
      "text" : "In this section we prove the following lower bound:\n31For arbitrary metric spaces we have (ii) ⇐⇒ (iii) and (i)⇒(ii), but not (ii)⇒(i).\nTheorem 7.4. Consider the uniformly Lipschitz experts problem on a metric space (X,D) which has a perfect subspace. Then the problem is not g-tractable for any g ∈ o( √ t). In particular, for any such g there exists a distribution P over problem instances µ such that for any experts algorithm A we have\nPr µ∈P\n[ R(A, µ)(t) = Oµ(g(t)) ] = 0. (34)\nLet us construct the desired distribution over problem instances. First, we use the existence of a perfect subspace to construct a ball-tree (cf. Definition 5.3).\nLemma 7.5. For any metric space with a perfect subspace there exists a ball-tree in which each node has exactly two children.\nProof. Consider a metric space (X,D) with a perfect subspace (Y,D). Let us construct the balltree recursively, maintaining the invariant that for each tree node (y, r) we have y ∈ Y . Pick an arbitrary y ∈ Y and let the root be (y, 1). Suppose we have constructed a tree node (y, r), y ∈ Y . Since Y is perfect, the ball B(y, r/3) contains another point y′ ∈ Y . Let r′ = D(y, y′)/2 and define the two children of (y, r) as (y, r′) and (y′, r′).\nNow let us use the ball-tree to construct the distribution on payoff functions. (We will re-use this construction in Section 9.3.1.) In what follows, we consider a metric space (X,D) with a fixed ball-tree T . For each i ≥ 1, let Di be the set of all depth-i nodes in the ball-tree. Recall that an end in a ball-tree is an infinite path from the root: w = (w0, w1, w2, . . .), where w ∈ Di for all i. For each tree node w = (x0, r0) define the “bump function” Fw : X → [0, 1] as in (22):\nFw(x) =\n{\nmin{r0 −D(x, x0), r0/2} if x ∈ B(x0, r0), 0 otherwise.\n(35)\nThe construction is parameterized by a sequence δi, δ2, δ3, . . . ∈ (0, 1) which we will specify later.\nDefinition 7.6. A lineage in a ball-tree is a set of tree nodes containing at most one child of each node; if it contains exactly one child of each node then we call it a complete lineage. For each complete lineage λ there is an associated end w(λ) defined by w = (w0, w1, . . .) where w0 is the root and for i > 0, wi is the unique child of wi−1 that belongs to λ.\nConstruction 7.7. For any lineage λ let us define a problem instance Pλ (probability measure on payoff functions) via the following sampling rule. First every tree node w independently samples a random sign σ(w) ∈ {+1,−1} so that E[σ(w)] = δi if w is the depth i ≥ 1 node in w(λ), and choosing the sign uniformly at random otherwise. Define the payoff function π associated with a particular sign pattern σ(·) as follows:\nπ = 1\n2 +\n1\n3\n∑\nw∈T\\D0 σ(w)Fw . (36)\nLet µλ(x) = Eπ∼Pλ [π(x)] denote the expectation of π(x) under distribution Pλ. Let PT be the distribution over problem instances Pλ in which λ is a complete lineage sampled uniformly at random; that is, each node samples one of its children independently and uniformly at random, and λ is the set of sampled children.\nRemark. By Lemma 5.8, the payoff function in (36) is Lipschitz on (X,D) for any sign pattern σ(·). Therefore Pλ is an instance of uniformly Lipschitz experts problem, for each lineage λ.\nTo complete Construction 7.7, it remains to specify the δi’s. Fix function g() from Theorem 7.4. For each i ≥ 1, let r∗i = min{r : (x, r) ∈ Di} be the smallest radius among depth-i nodes in the ball-tree. Note that r∗i ≤ 4−i. Choose a number ni large enough that g(n) < 124 i r∗i √ n for all\nn > ni; such ni exists because g ∈ o( √ t). Let δi = n −1/2 i .\nDiscussion. For a complete lineage λ, the expected payoffs are given by\nµλ = 1\n2 +\n1\n3\n∞ ∑\ni=1\nδi Fwi , (37)\nwhere w(λ) = (w0, w1, . . .) is the end associated with λ. For the special case of MAB it would suffice to construct a problem instance with expected payoffs given by (37), without worrying about lineages or random sign patterns. This would be a “weighted” version of the lower-bounding construction from Section 5.1.\nHowever, for the full-feedback problem it is essential that the sum in (36) is over all tree nodes (except the root), rather than the end w(λ). If the sum were over w(λ), then a single sample of the payoff function π would completely inform the learner of the location of w(λ) in the tree. (Just look for the nested rings on which π varies, and they form a target whose bulls-eye is w(λ).) Instead, we fill the whole metric space with “static” in the form of a hierarchically nested set of rings on which π varies, where the only special distinguishing property of the rings that zero in on w(λ) is that there is a slightly higher probability that π increases on those rings. Thus, w(λ) is well-hidden, and in particular is impossible to learn from a single sample of π.\nLet us state and prove a salient property of Construction 7.7 which we use to derive the regret lower bound. (This property holds for an arbitrary non-increasing sequence of δi’s; we will re-use it in Section 9.3.1.)\nLemma 7.8. Fix a complete lineage λ and tree node v ∈ λ. To fix the notation, let us say that v is depth-i node with corresponding ball B of radius r.\n(i) For every event E in the Borel σ-algebra on [0, 1]X ,\nPλ(E)/Pλ\\{v}(E) ∈ [1− δi, 1 + δi].\n(ii) If v ∈ w(λ), then sup(µλ, B)− sup(µλ,X \\B) ≥ rδi/6\nProof. For part (i), let us treat E as a set of sign patterns σ : V → {±1}, where V is the set of all nodes in the ball-tree, and let us treat Pλ as a measure on these sign patterns. For each sign β ∈ {±1}, let Eβ = {σ ∈ E : σ(v) = β} be the set of all sign patterns in E with a given sign on node u. Note that\nPλ(E) = ∑ β∈{±1} Pλ(Eβ) · Pλ (σ(v) = β) .\nThis equality holds for any lineage, in particular for lineage λ \\ {v}. For brevity, denote P0 = Pλ\\{v}. Observe that P0 and Pλ differ only in how they set σ(v). We can state this property rigorously as follows:\nPλ(Eβ) = P0(Eβ) for each sign β ∈ {±1}.\nNow, recalling that the event {σ(v) = 1} is assigned probability 12 under measure P0, and probability 1 2 + δi/2 under measure Pλ, it follows that\nPλ(E)− P0(E) = (δi/2) (P0(E+)− P0(E−)) |Pλ(E)− P0(E)| ≤ (δi/2) (P0(E+) + P0(E−)) = δi P0(E).\nFor part (ii), write w(λ) = (w0, w1, . . .) be the end corresponding to λ. Recall that v = wi. For each wj, let Bj be the corresponding ball, and let rj be its radius. Using (37) and the fact that the sequence (Bj : j ∈ N) is decreasing, it follows that\nsup(µλ, B) = 1\n2 +\n1\n6\n∞ ∑\nj=1\nδj rj,\nsup(µλ,X \\B) = 1\n2 +\n1\n6\ni−1 ∑\nj=1\nδj rj,\nsup(µλ, B)− sup(µλ,X \\B) = 1\n6\n∞ ∑\nj=i\nδj rj ≥ δi ri/6.\nLemma 7.9. Consider a metric space (X,D) with a ball-tree T . Then (34) holds with P = PT . To prove this lemma, we define a notion called an (ǫ, δ, k)-ensemble, analogous to the (ǫ, k)ensembles defined in Section 5.1. As before, it is convenient to articulate this definition in the more general setting of the feasible experts problem, in which one is given a set of arms X (not necessarily a metric space) along with a collection F of Borel probability measures on the set [0, 1]X of functions π : X → [0, 1]. A problem instance of the feasible experts problem consists of a triple (X,F ,P) where X and F are known to the algorithm, and P ∈ F is not. Definition 7.10. Consider a set X and a (k + 1)-tuple ~P = (P0,P1 , . . . ,Pk) of Borel probability measures on [0, 1]X , the set of [0, 1]-valued payoff functions π on X. For 0 ≤ i ≤ k and x ∈ X, let µi(x) denote the expectation of π(x) under measure Pi. We say that ~P is an (ǫ, δ, k)-ensemble if there exist pairwise disjoint subsets S1, S2, . . . , Sk ⊆ X for which the following properties hold: (1) for every i > 0 and every event E in the Borel σ-algebra of [0, 1]X , we have\n1− δ < P0(E)/Pi(E) < 1 + δ.\n(ii) for every i > 0, we have sup(µi, Si)− sup(µi, X \\ Si) ≥ ǫ. Essentially, the measures P1 , . . . ,Pk correspond to the children of any given node in the balltree. The precise connection to Construction 7.7 is stated below, derived as corollary of Lemma 7.8.\nCorollary 7.11. Fix an arbitrary complete lineage λ in a ball-tree T and a tree node u ∈ w(λ). Let u1 , . . . , uk be the children of u. Let u\n′ be the unique child of u contained in λ. Define lineage λ0 = λ \\ {u′}, and complete lineages λi = λ0 ∪ {ui} for each i ∈ [1, k]. Then the tuple ~P = (Pλ0 ,Pλ1 , . . . ,Pλk) of probability measures from Construction 7.7 constitutes a (ǫ, 2 δj , k)ensemble where j is the depth of the tree nodes ui, r is their radius, and ǫ = rδj/6.\nProof. Let S1 , . . . , Sk be the balls that correspond to u1 , . . . , uk. Fix ui, and apply Lemma 7.8 with lineage λi and tree node ui. Then both parts of Definition 7.10 are satisfied for a given i. (For part (i), note that λ0 = λi \\{ui}. Observe that Lemma 7.8(i) bounds Pλ(E)/Pλ\\{v}(E), whereas for Definition 7.10 we need to bound the inverse ratio; hence, the bound increases from δi to 2 · δi.)\nTheorem 7.12. Consider the feasible experts problem on (X,F). Let ~P be an (ǫ, δ, k)-ensemble with {P1, . . . ,Pk} ⊆ F and 0 < ǫ, δ < 1/2. Then for any t < ln(17k)/(2δ2) and any experts algorithm A, at least half of the measures Pi have the property that R(A, Pi)(t) ≥ ǫt/2.\nRemarks. To preserve the flow of the paper, the proof of this theorem is deferred until Appendix A, where the relevant KL-divergence techniques are developed. The proof of Theorem 7.4 uses Theorem 7.12 for k = 2, and the proof of Theorem 6.5 will use it again for large k. Proof of Lemma 7.9: Let us fix an experts algorithm A and a function g ∈ o( √ t), and consider the distribution over problem instances in Construction 7.7. For each complete lineage λ and tree node w ∈ w(λ), let w1, w2 denote the children of w in the ball-tree, and let w′ denote the unique child that belongs to λ. The three lineages λ0 = λ \\ {w′}, λ1 = λ0 ∪ {w1}, λ2 = λ0 ∪ {w2} define a triple of probability measures ~P = (Pλ0 ,Pλ1 ,Pλ2). By Corollary 7.11, this triple constitutes an (ǫ, 2 δi, 2)-ensemble where i is the depth of w1, w2 in the ball-tree, r is their radius, and ǫ = r δi/6. By Theorem 7.12 there exists a problem instance α(w) ∈ {Pλ1 ,Pλ2} such that for any ti < 18 ln(34)·δ−2i one has\nR(A, α(w))(ti) ≥ ǫti/2.\nTaking ti ∈ (14 , 18 ln(34)) · δ−2i one has\nR(A, α(w))(ti) ≥ ǫti/2 = rδiti/12 > 124r∗i √ ti,\nwhere r∗i is the smallest radius among all depth-i nodes in the ball-tree. Recalling that we chose ni large enough that g(ni) < 1 24 i r ∗ i √ n for all n > ni, and that ni = δ −2 i , we see that\ni · g(ti) < 124r∗i √ ti < R(A, α(w))(ti).\nFor each depth i, let us define Ei to be the set of input distributions Pλ such that λ is a complete lineage whose associated end w(λ) = (w0, w1, . . .) satisfies wi = α(wi−1). Interpreting these sets as random events under the probability distribution PT , they are mutually independent events each having probability 12 . Furthermore, we have proved that there exists a sequence of times ti → ∞ such that for each i we have R(A, P)(ti) > i · g(ti) for any P ∈ Ei.\nFor each complete lineage λ, define the “smallest possible constant” if we were to characterize the algorithm’s regret on problem instance Pλ using function g:\nCλ := inf{C ≤ ∞ : R(A, Pλ)(t) ≤ C g(t) for all t}.\nNote that R(A, Pλ)(t) = Oµ(g(t)) if and only if Cλ < ∞. We claim that Pr[Cλ < ∞] = 0, where the probability is over the random choice of complete lineage λ. Indeed, if infinitely many events Ei happen, then event {Cλ = ∞} happens as well. But the probability that infinitely many events Ei happen is 1, because for every positive integer n, Pr [ ∩∞i=nEi ] = ∏∞ i=n Pr [ Ei ∣ ∣ ∣∩i−1j=nEj ] = 0."
    }, {
      "heading" : "7.3 Tractability for compact well-orderable metric spaces",
      "text" : "In this section we prove the main algorithmic result.\nTheorem 7.13. Consider a compact well-orderable metric space (X,D). Then: (a) the Lipschitz MAB problem on (X,D) is f -tractable for every f ∈ ω(log t); (b) the Lipschitz experts problem on (X,D) is 1-tractable, even with a double feedback.\nWe present a joint exposition for both the bandit and the experts version. Let us consider the Lipschitz MAB/experts problem on a compact metric space (X,D) with a topological wellordering ≺ and a payoff function µ. For each strategy x ∈ X, let S(x) = {y x : y ∈ X} be the corresponding initial segment of the well-ordering (X,≺). Let µ∗ = sup(µ,X) denote the maximal payoff. Call a strategy x ∈ X optimal if µ(x) = µ∗. We rely on the following structural lemma:\nLemma 7.14. There exists an optimal strategy x∗ ∈ X for which it holds that sup(µ,X \\S(x∗)) < µ∗.\nProof. Let X∗ be the set of all optimal strategies. Since µ is a continuous real-valued function on a compact space X, it attains its maximum, i.e. X∗ is non-empty, and furthermore X∗ is closed. Note that {S(x) : x ∈ X∗} is an open cover for X∗. Since X∗ is compact (as a closed subset of a compact set) this cover contains a finite subcover, call it {S(x) : x ∈ Y ∗}. Then the ≺-maximal element of Y ∗ is the ≺-maximal element of X∗. The initial segment S(x∗) is open, so its complement Y = X \\ S(x∗) is closed and therefore compact. It follows that µ attains its maximum on Y , say at a point y∗ ∈ Y . By the choice of y∗ we have x∗ ≺ y∗, so by the choice of x∗ we have µ(x∗) > µ(y∗).\nIn the rest of this section we let x∗ be the strategy from Lemma 7.14. Our algorithm is geared towards finding x∗ eventually, and playing it from then on. The idea is that if we cover X with balls of a sufficiently small radius, any strategy in a ball containing x∗ has a significantly larger payoff than any strategy in a ball that overlaps with X \\ S(x∗).\nThe algorithm accesses the metric space and the well-ordering via the following two oracles.\nDefinition 7.15. A δ-covering set of a metric space (X,D) is a subset S ⊂ X such that each point in X lies within distance δ from some point in S. An oracle O = O(k) is a covering oracle for (X,D) if it inputs k ∈ N and outputs a pair (δ, S) where δ = δO(k) is a positive number and S is a δ-covering set of X consisting of at most k points. Here δO(·) is any function such that δO(k) → 0 as k → ∞.\nDefinition 7.16. Given a metric space (X,D) and a total order (X,≺), the ordering oracle inputs a finite collection of balls (given by the centers and the radii), and returns the ≺-maximal element covered by the closure of these balls, if such element exists, and an arbitrary point in X otherwise.\nOur algorithm is based on the following exploration subroutine EXPL().\nSubroutine EXPL(k, n, r): inputs k, n ∈ N and r ∈ (0, 1), outputs a point in X. First it calls the covering oracle O(k) and receives a δ-covering set S of X consisting of at most k points. Then it plays each strategy x ∈ S exactly n times; let µav(x) be the sample average. Let us say that x a loser if µav(y) − µav(x) > 2r + δ for some y ∈ S. Finally, it calls the ordering oracle with the collection of all closed balls B̄(x, δ) such that x is not a loser, and outputs the point xor ∈ X returned by this oracle call.\nClearly, EXPL(k, n, r) takes at most kn rounds to complete. We show that for sufficiently large k, n and sufficiently small r it returns x∗ with high probability.\nLemma 7.17. Fix a problem instance and let x∗ be the optimal strategy from Lemma 7.14. Consider increasing functions k, n, T : N → N such that r(t) := 4 √\n(log T (t)) /n(t) → 0. Then for any sufficiently large t, with probability at least 1−T−2(t), the subroutine EXPL(k(t), n(t), r(t)) returns x∗.\nProof. Let us use the notation from Algorithm 7.3. Fix t and consider a run of EXPL(k(t), n(t), r(t)). Call this run clean if for each x ∈ S we have |µav(x) − µ(x)| ≤ r(t). By Chernoff Bounds, this happens with probability at least 1 − T−2(t). In the rest of the proof, let us assume that the run is clean.\nLet B̄ be the union of the closed balls B̄(x, δ), x ∈ S∗. Then the ordering oracle returns the ≺ -maximal point in B̄ if such point exists. We will show that x∗ ∈ B̄ ⊂ S(x∗) for any sufficiently large t, which will imply the lemma.\nWe claim that x∗ ∈ B̄. Since S is a δ-covering set, there exists y∗ ∈ S such that D(x∗, y∗) ≤ δ. Let us fix one such y∗. It suffices to prove that y∗ is not a loser. Indeed, if µav(y)−µav(y∗) > 2 r(t)+δ for some y ∈ S then µ(y) > µ(y∗) + δ ≥ µ∗, contradiction. Claim proved.\nLet µ0 = sup(µ,X \\ S(x∗)) and let r0 = (µ∗ − µ0)/7. Let us assume that t is sufficiently large so that r(t) < r0 and δ = δO(k(t)) < r0, where δO(·) is from the definition of the covering oracle.\nWe claim that B̄ ⊂ S(x∗). Indeed, consider x ∈ S and y ∈ X \\ S(x∗) such that D(x, y) ≤ δ. It suffices to prove that x is a loser. Consider some y∗ ∈ S such that D(x∗, y∗) ≤ δ. Then by the Lipschitz condition\nµav(y ∗) ≥ µ(y∗)− r0 ≥ µ∗ − 2r0,\nµav(x) ≤ µ(x) + r0 ≤ µ(y) + r0 ≤ µ0 + 2r0 ≤ µ∗ − 5r0 µav(y ∗)− µav(x) ≥ 3r0 > 2r(t) + δ.\nProof of Theorem 7.13: Let us fix a function f ∈ ω(log t). Then f(t) = α(t) log(t) where α(t) → ∞. Without loss of generality, assume that α(t) is non-decreasing. (If not, then instead of f(t) use g(t) = β(t) log(t), where β(t) = inf{α(t′) : t′ ≥ t}.)\nFor part (a), define kt = ⌊ √ g(t)/ log t⌋, nt = ⌊kt log t⌋, and rt = 4 √\n(log t)/nt. Note that rt → 0.\nThe algorithm proceeds in phases of a doubly exponential length32. A given phase i = 1, 2, 3, . . . lasts for T = 22 i rounds. In this phase, first we call the exploration subroutine EXPL(kT , nT , rT ). Let xor ∈ X be the point returned by this subroutine. Then we play xor till the end of the phase. This completes the description of the algorithm.\nFix a problem instance I. Let Wi be the total reward accumulated by the algorithm in phase i, and let Ri = 2\n2i µ∗ − Wi be the corresponding share of regret. By Lemma 7.17 there exists i0 = i0(I) such that for any phase i ≥ i0 we have, letting T = 22i be the phase duration, that Ri ≤ kT nT ≤ g(T ) with probability at least 1− T−2, and therefore E[Ri] ≤ g(T ) + T−1. For any t > t0 = 2\n2i0 it follows by summing over i ∈ {i0, i0 +1, . . . , ⌈log log t⌉} that RA, I(t) = O(t0 + g(t)). Note that we have used the fact that α(t) is non-decreasing.\nFor part (b), we separate exploration and exploitation. For exploration, we run EXPL() on the free peeks. For exploitation, we use the point returned by EXPL() in the previous phase. Specifically, define kt = nt = ⌊ √ t⌋, and rt = 4 √\n(t1/4)/nt. The algorithm proceeds in phases of exponential length. A given phase i = 1, 2, 3, . . . lasts for T = 2i rounds. In this phase, we run the exploration subroutine EXPL(kT , nT , rT ) on the free peeks. In each round, we bet on the point returned by EXPL() in the previous phase. This completes the description of the algorithm.\nBy Lemma 7.17 there exists i0 = i0(I) such that in any phase i ≥ i0 the algorithm incurs zero regret with probability at least 1 − eΩ(i). Thus the total regret after t > 2i0 rounds is at most t0 +O(1).\n32The doubly exponential phase length is necessary in order to get f -tractability. If we employed the more familiar doubling trick of using phase length 2i (as in (Auer et al., 2002b; Kleinberg, 2004; Kleinberg et al., 2008c), for example) then the algorithm would only be f(t) log t-tractable.\n7.4 The (log t)-intractability for infinite metric spaces: proof of Theorem 1.7\nConsider an infinite metric space (X,D). In view of Theorem 6.2, we can assume that the completion X∗ of X is compact. It follows that there exists x∗ ∈ X∗ such that xi → x∗ for some sequence x1, x2, . . . ∈ X. Let ri = D(xi, x∗). Without loss of generality, assume that ri+1 < 12 ri for each i, and that the diameter of X is 1.\nLet us define an ensemble of payoff functions µi : X → [0, 1], i ∈ N, where µ0 is the “baseline” function, and for each i ≥ 1 function µi is the “counterexample” in which a neighborhood of xi has slightly higher payoffs. The “baseline” is defined by µ0(x) = 1 2− D(x,x∗) 8 , and the “counterexamples” are given by µi(x) = µ0(x) + νi(x), where νi(x) = 3 4 max ( 0, ri3 −D(x, x∗) ) . Note that both µ0 and νi are 1 8 -Lipschitz and 3 4 -Lipschitz w.r.t. (X,D), respectively, so µi is 78 - Lipschitz w.r.t (X,D). Let us fix a MAB algorithm A and assume that it is (log t)-tractable. Then for each i ≥ 0 there exists a constant Ci such that R(A, µi)(t) < Ci log t for all times t. We will show that this is not possible.\nIntuitively, the ability of an algorithm to distinguish between payoff functions µ0 and µi, i ≥ 1 depends on the number of samples in the ball Bi = B(xi, ri/3). (This is because µ0 = µi outside Bi.) In particular, the number of samples itself cannot be too different under µ0 and under µi, unless it is large. To formalize this idea, let Ni(t) be the number of times algorithm A selects a strategy in the ball Bi during the first t rounds, and let σ(Ni(t)) be the corresponding σ-algebra. Let Pi[·] and Ei[·] be, respectively, the distribution and expectation induced by µi. Then we can connect E0[Ni(t)] with the probability of any event S ∈ σ(Ni(t)) as follows.\nClaim 7.18. For any i ≥ 1 and any event S ∈ σ(Ni(t)) it is the case that\nPi[S] < 1 3 ≤ P0[S] ⇒ − ln(Pi[S])− 3e ≤ O(r2i ) E0[Ni(t)]. (38)\nRemark. The reason our argument proves the regret lower bound in terms of log(t), rather than some other function of t, is the ln(·) term in (38), which in turn comes from the exp(·) term in Claim A.5 (which captures a crucial property of KL-divergence).\nClaim 7.18 is proved using KL-divergence techniques, see Appendix A for details. To complete the proof of the theorem, we claim that for each i ≥ 1 it is the case that E0[Ni(t)] ≥ Ω(r−2i log t) for any sufficiently large t. Indeed, fix i and let S = {Ni(t) < r−2i log t}. Since\nCi log t > R(A, µi)(t) ≥ Pi(S) (t − r−2i log t) ri8 ,\nit follows that Pi(S) < t −1/2 < 13 for any sufficiently large t. Then by Claim 7.18 either P0(S) < 1 3 or the consequent in (38) holds. In both cases E0[Ni(t)] ≥ Ω(r−2i log t). Claim proved. Finally, the fact that µ0(x\n∗) − µ0(x) ≥ ri/12 for every x ∈ Bi implies that R(A, µ0)(t) ≥ ri 12E0[Ni(t)] ≥ Ω(r−1i log t) which establishes Theorem 1.7 since r−1i → ∞ as i → ∞."
    }, {
      "heading" : "7.5 Tractability via more intuitive oracle access",
      "text" : "In Theorem 7.13, the algorithm accesses the metric space via two oracles: a very intuitive covering oracle, and a less intuitive ordering oracle. In this section we show that for a wide family of metric spaces — including, for example, compact metric spaces with a finite number of limit points — the ordering oracle is not needed: we provide an algorithm which accesses the metric space via a finite set of covering oracles. We will consider metric spaces of finite Cantor-Bendixson rank, a classic notion from point topology.\nDefinition 7.19. Fix a metric space (X,D). If for some x ∈ X there exists a sequence of points in X \\ {x} which converges to x, then x is called a limit point. For S ⊂ X let lim(S) denote the limit set : the set of all limit points of S. Let lim(S, 0) = S, and lim(S, i) = lim(lim(· · · lim(S))), where lim(·) is applied i times. The Cantor-Bendixson rank of (X,D) is defined as sup{n : lim(X,n) 6= ∅}.\nLet us say that a Cantor-Bendixson metric space is one with a finite Cantor-Bendixson rank. In order to apply Theorem 7.13, we show that any such metric space is well-orderable.\nLemma 7.20. Any Cantor-Bendixson metric space is well-orderable.\nProof. Any finite metric space is trivially well-orderable. To prove the lemma, it suffices to show the following: any metric space (X,D) is well-orderable if so is (lim(X),D).\nLet X1 = X \\ lim(X) and X2 = lim(X). Suppose (X2,D) admits a topological well-ordering ≺2. Define a binary relation ≺ on X as follows. Fix an arbitrary well-ordering ≺1 on X1. For any x, y ∈ X posit x ≺ y if either (i) x, y ∈ X1 and x ≺1 y, or (ii) x, y ∈ X2 and x ≺2 y, or (iii) x ∈ X1 and y ∈ X2. It is easy to see that (X,≺) is a well-ordering.\nIt remains to prove that an arbitrary initial segment Y = {x ∈ X : x ≺ y} is open in (X,D). We need to show that for each x ∈ Y there is a ball B(x, ǫ), ǫ > 0 which is contained in Y . This is true if x ∈ X1 since by definition each such x is an isolated point in X. If x ∈ X2 then Y = X1∪Y2 where Y2 = {x ∈ X2 : x ≺2 y} is the initial segment of X2. Since Y2 is open in (X2,D), there exists ǫ > 0 such that BX2(x, ǫ) ⊂ Y2. It follows that BX(x, ǫ) ⊂ BX2(x, ǫ) ∪X1 ⊂ Y .\nThe structure of a Cantor-Bendixson metric space is revealed by a partition of X into subsets Xi = lim(X, i) \\ lim(X, i + 1), 0 ≤ i ≤ n. For a point x ∈ Xi, we define the rank to be i. The algorithm requires a covering oracle for each Xi.\nTheorem 7.21. Consider the Lipschitz MAB/experts problem on a compact metric space (X,D) such that limN (X) = ∅ for some N . Let Oi be the covering oracle for Xi = lim(X, i)\\lim(X, i+1). Assume that access to the metric space is provided only via the collection of oracles {Oi}Ni=0. Then:\n(a) the Lipschitz MAB problem on (X,D) is f -tractable for every f ∈ ω(log t); (b) the Lipschitz experts problem on (X,D) is 1-tractable, even with a double feedback.\nIn the rest of this section, consider the setting in Theorem 7.21. We describe the exploration subroutine EXPL′(), which is similar to EXPL() in Section 7.3 but does not use the ordering oracle. Then we prove a version of Lemma 7.17 for EXPL′(). Once we have this lemma, the proof of Theorem 7.21 is identical to that of Theorem 7.13 (and is omitted).\nSubroutine EXPL′(k, n, r): inputs k, n ∈ N and r ∈ (0, 1), outputs a point in X. Call each covering oracle Oi(k) and receive a δi-covering set Si of X consisting of at most k points. Let S = ∪nl=1Sl. Play each strategy x ∈ S exactly n times; let µav(x) be the corresponding sample average. For x, y ∈ S, let us say that x dominates y if µav(x) − µav(y) > 2 r. Call x ∈ S a winner if x has a largest rank among the strategies that are not dominated by any other strategy. Output an arbitrary winner if a winner exists, else output an arbitrary point in S.\nClearly, EXPL(k, n, r) takes at most knN rounds to complete. We show that for sufficiently large k, n and sufficiently small r it returns an optimal strategy with high probability.\nLemma 7.22. Fix a problem instance. Consider increasing functions k, n, T : N → N such that r(t) := 4 √\n(log T (t)) /n(t) → 0. Then for any sufficiently large t, with probability at least 1−T−2(t), the subroutine EXPL′(k(t), n(t), r(t)) returns an optimal strategy.\nProof. Use the notation from Algorithm 7.5. Fix t and consider a run of EXPL′(k(t), n(t), r(t)). Call this run clean if for each x ∈ S we have |µav(x) − µ(x)| ≤ r(t). By Chernoff Bounds, this happens with probability at least 1 − T−2(t). In the rest of the proof, let us assume that the run is clean.\nLet us introduce some notation. Let µ be the payoff function and let µ∗ = sup(µ,X). Call x ∈ X optimal if µ(x) = µ∗. (There exists an optimal strategy since (X,D) is compact.) Let i∗ be the largest rank of any optimal strategy. Let X∗ be the set of all optimal strategies of rank i∗. Let Y = lim(X, i∗). Since each point x ∈ Xi∗ is an isolated point in Y , there exists some r(x) > 0 such that x is the only point of B(x, r(x)) that lies in Y .\nWe claim that sup(µ, Y \\X∗) < µ∗. Indeed, consider C = ∪x∈X∗B(x, r(x)). This is an open set. Since Y is closed, Y \\ C is closed, too, hence compact. Therefore there exists y ∈ Y \\ C such that µ(y) = sup(µ, Y \\C). Since X∗ ⊂ C, µ(y) is not optimal, i.e. µ(y) < µ∗. Finally, by definition of r(x) we have Y \\ C = Y \\X∗. Claim proved.\nPick any x∗ ∈ X∗. Let µ0 = sup(µ, Y \\ X∗). Assume that t is large enough so that r(t) < (µ∗ − µ0)/4 and δi∗ < r(x∗). Note that the δi∗-covering set Si∗ contains x∗.\nFinally, we claim that in a clean phase, x∗ is a winner, and all winners lie in X∗. Indeed, note that x∗ dominates any non-optimal strategy y ∈ S of larger or equal rank, i.e. any y ∈ S∩(Y \\X∗). This is because µav(x\n∗)− µav(y) ≥ µ∗ − µ0 − 2r > 2. The claim follows since any optimal strategy cannot be dominated by any other strategy."
    }, {
      "heading" : "8 Boundary of tractability: proof of Theorem 6.2",
      "text" : "We prove that Lipschitz bandits/experts are o(t)-tractable if and only if the completion of the metric space is compact. More formally, we prove Theorem 6.2 (which subsumes Theorem 1.8). We restate the theorem below for the sake of convenience.\nTheorem (Theorem 6.2 restated). The Lipschitz experts problem on metric space (X,D) is either f(t)-tractable for some f ∈ o(t), even in the bandit setting, or it is not g(t)-tractable for any g ∈ o(t), even with full feedback. The former occurs if and only if the completion of X is a compact metric space.\nFirst, we reduce the theorem to that on complete metric spaces, see Appendix B. In what follows, we will use a basic fact that a complete metric space is compact if and only if for any r > 0, it can be covered by a finite number of balls of radius r.\nAlgorithmic result. We consider a compact metric space (X,D) and use an extension of algorithm UniformMesh (described in the Introduction). In each phase i (which lasts for ti round) we fix a covering of X with Ni < ∞ balls of radius 2−i (such covering exists by compactness), and run a fresh instance of the Ni-armed bandit algorithm UCB1 from Auer et al. (2002a) on the centers of these balls. (This algorithm is for the “basic” MAB problem, in the sense that it does not look at the distances in the metric space.) The phase durations ti need to be tuned to the Ni’s. In the setting considered in Kleinberg (2004) (essentially, bounded covering dimension) it suffices to tune each ti to the corresponding ti in a fairly natural way. The difficulty in the present setting is that there are no guarantees on how fast the Ni’s grow. To take this into account, we fine-tune each ti to (essentially) all covering numbers N1 , . . . , Ni+1.\nLet Rk(t) be the expected regret accumulated by the algorithm in the first t rounds of phase k. Using the off-the-shelf regret guarantees for UCB1, it is easy to see (Kleinberg, 2004) that\nRk(t) ≤ O( √ Nk t log t) + ǫk t ≤ ǫk max(t∗k, t), where t∗k = 2 Nkǫ2 k log Nk ǫ2 k . (39)\nLet us specify phase durations ti. They are defined very differently from the ones in (Kleinberg, 2004). In particular, in Kleinberg (2004) each ti is fine-tuned to the corresponding covering number Ni by setting ti = t ∗ i , and the analysis works out for metric spaces of bounded covering dimension. In our setting, we fine-tune each ti to (essentially) all covering numbers N1 , . . . , Ni+1. Specifically, we define the ti’s inductively as follows:\nti = min(t ∗ i , t ∗ i+1, 2 ∑i−1 j=1tj).\nThis completes the description of the algorithm, call it A.\nLemma 8.1. Consider the Lipschitz MAB problem on a compact and complete metric space (X,D). Then RA(t) ≤ 5 ǫ(t) t, where ǫ(t) = min{2−k : t ≤ sk} and sk = ∑k i=1 ti. In particular, RA(t) = o(t).\nProof. First we claim that RA(sk) ≤ 2 ǫk sk for each k. Use induction on k. For the induction base, note that RA(s1) = R1(t1) ≤ ǫ1t1 by (39). Assume the claim holds for some k − 1. Then\nRA(sk) = RA(sk−1) +Rk(tk)\n≤ 2 ǫk−1 sk−1 + ǫk tk ≤ 2 ǫk(sk−1 + tk) = 2 ǫksk,\nclaim proved. Note that we have used (39) and the facts that tk ≥ t∗k and tk ≥ 2 sk−1. For the general case, let T = sk−1 + t, where t ∈ (0, tk). Then by (39) we have that\nRk(t) ≤ ǫk max(t∗k, t) ≤ ǫk max(tk−1, t) ≤ ǫk T,\nRA(T ) = RA(sk−1) +Rk(T )\n≤ 2 ǫk−1 sk−1 + ǫk T ≤ 5 ǫk T.\nLower bound: proof sketch. For the lower bound, we consider a metric space (X,D) with an infinitely many disjoint balls B(xi, r∗) for some r∗ > 0. For each ball i we define the wedge function supported on this ball:\nG(i,r)(x) =\n{\nmin{r∗ −D(x, xi), r∗ − r} if x ∈ B(xi, r∗) 0 otherwise.\nThe balls are partitioned into two infinite sets: the ordinary and special balls. The random payoff function is then defined by taking a constant function, adding the wedge function on each special ball, and randomly adding or subtracting the wedge function on each ordinary ball. Thus, the expected payoff is constant throughout the metric space except that it assumes higher values on the special balls. However, the algorithm has no chance of ever finding these balls, because at time t they are statistically indistinguishable from the 2−t fraction of ordinary balls that randomly happen to never subtract their wedge function during the first t steps of play.\nLower bound: full proof. Suppose (X,D) is not compact. Fix r > 0 such that X cannot be covered by a finite number of balls of radius r. There exists a countably infinite subset S ⊂ X such that the balls B(x, r), x ∈ S are mutually disjoint. (Such subset can be constructed inductively.) Number the elements of S as s1, s2, . . . , and denote the ball B(si, r) by B(i).\nSuppose there exists a Lipschitz experts algorithm A that is g(t)-tractable for some g ∈ o(t). Pick an increasing sequence t1, t2, . . . ∈ N such that tk+1 > 2tk ≥ 10 and g(tk) < rk tk/k for each\nk, where rk = r/2 k+1. Let m0 = 0 and mk = ∑k i=1 4 ti for k > 0, and let Ik = {mk + 1, . . . ,mk+1}. The intervals Ik form a partition of N into sets of sizes 4\nt1 , 4t2 , . . .. For every i ∈ N, let k be the unique value such that i ∈ Ik and define the following Lipschitz function supported in B(si, r):\nGi(x) =\n{\nmin{r −D(x, si), r − rk} if x ∈ B(i) 0 otherwise.\nIf J ⊆ N is any set of natural numbers, we can define a distribution PJ on payoff functions by sampling independent, uniformly-random signs σi ∈ {±1} for every i ∈ N and defining the payoff function to be\nπ = 12 + ∑ i∈J Gi + ∑ i 6∈J σiGi.\nNote that the distribution PJ has expected payoff function µ = 1 2 +\n∑\ni∈J Gi. Let us define a distribution P over problem instances PJ by letting J be a random subset of N obtained by sampling exactly one element jk of each set Ik uniformly at random, independently for each k.\nIntuitively, consider an algorithm that is trying to discover the value of jk. Every time a payoff function πt is revealed, we get to see a random {±1} sample at every element of Ik and we can eliminate the possibility that jk is one of the elements that sampled −1. This filters out about half the elements of Ik in every time step, but |Ik| = 4tk so on average it takes 2tk steps before we can discover the identity of jk. Until that time, whenever we play a strategy in ∪i∈IkB(i), there is a constant probability that our regret is at least rk. Thus our regret is bounded below by rktk ≥ kg(tk). This rules out the possibility of a g(t)-tractable algorithm. The following lemma makes this argument precise.\nLemma 8.2. PrP∈P [R(A, P)(t) = Oµ(g(t))] = 0.\nProof. Let j1, j2, . . . be the elements of the random set J , numbered so that jk ∈ Ik for all k. For any i, t ∈ N, let σ(i, t) denote the value of σi sampled at time t when sampling the sequence of i.i.d. payoff functions πt from distribution PJ . We know that σ(jk, t) = 1 for all t. In fact if S(k, t) denotes the set of all i ∈ Ik such that σ(i, 1) = σ(i, 2) = · · · = σ(i, t) = 1 then conditional on the value of the set S(k, t), the value of jk is distributed uniformly at random in S(k, t). As long as this set S(k, t) has at least n elements, the probability that the algorithm picks a strategy xt belonging to B(jk) at time t is bounded above by 1 n , even if we condition on the event that xt ∈ ∪i∈IkB(i). For any given i ∈ Ik \\ {jk}, we have PJ(i ∈ S(k, t)) = 2−t and these events are independent for different values of i. Setting n = 2tk , so that |Ik| = n2, we have\nPJ [ |S(k, t)| ≤ n ] ≤ ∑ R⊂Ik, |R|=n PJ [S(k, t) ⊆ R ]\n=\n(\nn2\nn\n)\n( 1− 2−t )n2−n < ( n2 · ( 1− 2−t )n−1)n\n< exp ( n(2 ln(n)− (n− 1)/2t) ) . (40)\nAs long as t ≤ tk−1, the relation tk > 2t implies (n− 1)/2t > √ n so the expression (40) is bounded\nabove by exp (−n√n+ 2n ln(n)), which equals exp ( −8tk + 2 ln(4)tk4tk )\nand is in turn bounded above by exp ( −8tk/2 )\n. Let B(j>k) denote the union B(jk+1)∪B(jk+2)∪. . . , and let N(t, k) denote the random variable that counts the number of times A selects a strategy in B(j>k) during rounds 1, . . . , t. We have already demonstrated that for all t ≤ tk,\nPr PJ∈P\n(xt ∈ B(j>k)) ≤ 2−tk+1 + ∑\nℓ>k\nexp ( −8tℓ/2 ) < 21−tk+1 , (41)\nwhere the term 2−tk+1 accounts for the event that S(ℓ, t) has at least 2tk+1 elements, where ℓ in the index of the set Iℓ containing the number i such that xt ∈ B(i), if such an i exists. (41) implies the bound EPJ∈P [N(tk, k)] < tk · 21−tk+1 . By Markov’s inequality, the probability that N(tk, k) > tk/2 is less than 22−tk+1 . By Borel-Cantelli, almost surely the number of k such that N(tk, k) ≤ tk/2 is finite. The algorithm’s expected regret at time t is bounded below by rk(tk − N(tk, k)), so with probability 1, for all but finitely many k we have R(A, PJ)(tk) ≥ rktk/2 ≥ (k/2)g(tk). This establishes that A is not g(t)-tractable."
    }, {
      "heading" : "9 Lipschitz experts in a (very) high dimension",
      "text" : "This section concerns polynomial regret results for Lipschitz experts in metric spaces of (very) high dimension: Theorem 6.3, Theorem 6.4, and Theorem 6.5, as outlined in Section 6."
    }, {
      "heading" : "9.1 The uniform mesh (proof of Theorem 6.3)",
      "text" : "We start with a version of algorithm UniformMesh discussed in the Introduction.33 This algorithm, called UniformMeshExp(b), is parameterized by b > 0. It runs in phases. Each phase i lasts for T = 2i rounds, and outputs its best guess x∗i ∈ X, which is played throughout phase i+ 1. During phase i, the algorithm picks a δ-hitting set34 for X of size at most Nδ(X), for δ = T\n−1/(b+2). By the end of the phase, x∗i as defined as the point in S with the highest sample average (breaking ties arbitrarily). This completes the description of the algorithm.\nIt is easy to see that the regret of UniformMeshExp is naturally described in terms of the logcovering dimension (see (32)). The proof is based the argument from Kleinberg (2004). We restate it here for the sake of completeness, and to explain how the new dimensionality notion is used.\nTheorem 9.1. Consider the Lipschitz experts problem on a metric space (X,D). For each b > LCD(X), algorithm UniformMeshExp(b) achieves regret R(t) = O(t1−1/(b+2)).\nProof. Let Nδ = Nδ(X), and let µ be the expected payoff function. Consider a given phase i of the algorithm. Let T = 2i be the phase duration. Let δ = T−1/(b+2), and let S ⊂ X the δ-hitting set chosen in this phase. Note that for any sufficiently large T it is the case that Nδ < 2\nδ−b . For each x ∈ S, let µT (x) be the sample average of the feedback from x by the end of the phase. Then by Chernoff bounds,\nPr[|µT (x)− µ(x)| < rT ] > 1− (TNδ)−3, where rT = √ 8 log(T Nδ) /T < 2δ. (42)\nNote that δ is chosen specifically to ensure that rT ≤ O(δ). We can neglect the regret incurred when the event in (42) does not hold for some x ∈ S. From now on, let us assume that the event in (42) holds for all x ∈ S. Let x∗ be an optimal strategy, and x∗i = argmaxx∈S µT (x) be the “best guess”. Let x ∈ S be a point that covers x∗. Then\nµ(x∗i ) ≥ µT (x∗i )− 2δ ≥ µT (x)− 2δ ≥ µ(x)− 4δ ≥ µ(x∗)− 5δ.\nThus the total regret Ri+1 accumulated in phase i+ 1 is\nRi+1 ≤ 2i+1 (µ(x∗)− µ(x∗i )) ≤ O(δT ) = O(T 1−1/(2+b)).\nThus the total regret summed over phases is as claimed.\n33A similar algorithm has been used by Gupta et al. (2007) to obtain regret R(T ) = O( √ T ) for metric spaces of\nfinite covering dimension. 34A subset S ⊂ X is a δ-hitting set for Y ⊂ X if Y ⊂ ∪x∈S B(x, δ)."
    }, {
      "heading" : "9.2 Uniformly Lipschitz experts (proof of Theorem 6.4)",
      "text" : "We now turn our attention to the uniformly Lipschitz experts problem, a restricted version of the Lipschitz experts problem in which a problem instance (X,D,P) satisfies a further property that each function f ∈ support(P) is itself a Lipschitz function on (X,D). We show that for this version, UniformMeshExp obtains a significantly better regret guarantee, via a more involved analysis. As we will see in the next section, for a wide class of metric spaces including ǫ-uniform tree metrics there is a matching upper bound.\nTheorem 9.2. Consider the uniformly Lipschitz experts problem with full feedback. Fix a metric space (X,D). For each b > LCD(X) such that b ≥ 2, UniformMeshExp(b − 2) achieves regret R(t) = O(t1−1/b).\nProof. The preliminaries are similar to those in the proof of Theorem 9.1. For simplicity, assume b ≥ 2. Let Nδ = Nδ(X), and let µ be the expected payoff function. Consider a given phase i of the algorithm. Let T = 2i be the phase duration. Let δ = T−1/b, and let S be the δ-hitting set chosen in this phase. (The specific choice of δ is the only difference between the algorithm here and the algorithm in Theorem 9.1.) Note that |S| ≤ Nδ, and for any sufficiently large T it is the case that Nδ < 2\nδ−b . The rest of the analysis holds for any set S such that |S| ≤ Nδ. (That is, it is not essential that S is a δ-hitting set for X.) For each x ∈ S, let ν(x) be the sample average of the feedback from x by the end of the phase. Let y∗i = argmax(µ, S) be the optimal strategy in the chosen sample, and let x∗i = argmax(ν, S) be the algorithm’s “best guess”. The crux is to show that\nPr[µ(y∗i )− µ(x∗i ) ≤ O(δ log T ) ] > 1− T−3. (43)\nOnce (43) is established, the remaining steps is exactly as the proof of Theorem 9.1. Proving (43) requires a new technique. The obvious approach – to use Chernoff Bounds for each x ∈ S separately and then take a Union Bound – does not work, essentially because one needs to take the Union Bound over too many points. Instead, we will use a more efficient version tail bound: for each x, y ∈ X, we will use Chernoff Bounds applied to the random variable f(x)− f(y), where f ∼ P and (X,D,P) is the problem instance. For a more convenient notation, we define\n∆(x, y) = [µ(x)− µ(y) ] + [ ν(y)− ν(x) ] ,\nThen for any N ∈ N we have\nPr [ |∆(x, y)| ≤ D(x, y) √ 8 log(T N)/T ] > 1− (TN)−3. (44)\nThe point is that the “slack” in the Chernoff Bound is scaled by the factor of D(x, y). This is because each f ∈ support(P) is a Lipschitz function on (X,D),\nIn order to take advantage of (44), let us define the following structure that we call the covering tree of the metric space (X,D). This structure consists of a rooted tree T and non-empty subsets X(u) ⊂ X for each internal node u. Let VT be the set of all internal nodes. Let Tj be the set of all level-j internal nodes (so that T0 is a singleton set containing the root). For each u ∈ VT , let C(u) be the set of all children of u. For each node u ∈ Tj the structure satisfies the following two properties: (i) set X(u) has diameter at most 2−j, (ii) the sets X(v), v ∈ C(u) form a partition of X(u). This completes the definition.\nBy definition of the covering number Nδ(·) there exist a covering tree T in which each node u ∈ Tj has fan-out N2−j (X(u)). Fix one such covering tree. For each node u ∈ VT , define\nσ(u) = argmax(µ, X (u) ∩ S) (45) ρ(u) = argmax(ν, X (u) ∩ S),\nwhere the tie-breaking rule is the same as in the algorithm. Let n = ⌈log 1δ ⌉. Let us say that phase i is clean if the following two properties hold: (i) for each node u ∈ VT any two children v,w ∈ C(u) we have |∆(σ(v), σ(w)) | ≤ 4δ. (ii) for any x, y ∈ S such that D(x, y) ≤ δ we have |∆(x, y)| ≤ 4δ.\nClaim 9.3. For any sufficiently large i, phase i is clean with probability at least 1− T−2.\nProof. To prove (i), let j be such that u ∈ Tj. We consider each j separately. Note that (i) is trivial for j > n. Now fix j ≤ n and apply the Chernoff-style bound (44) with N = |Tj| and (x, y) = (σ(v), σ(w)). Since |Tl| ≤ 22\nlb |Tl−1| for each sufficiently large l, it follows that log |Tj| ≤ C +\n∑j l=1 2 lb ≤ C + 43 2jb, where C is a constant that depends only on the metric space and b. It is easy to check that for any sufficiently large phase i (which, in turn, determines T , δ and n), the “slack” in (44) is at most 4δ:\nD(x, y) √ 8 log(T N)/T ≤ 3D(x, y) √ log(N)/T ≤ 4 2−j √ 2bj/2bn = 4δ 2−(n−j)(b−2)/2 ≤ 4δ.\nInterestingly, the right-most inequality above is the only place in the proof where it is essential that b ≥ 2.\nTo prove (ii), apply (44) with N = |S| similarly. Claim proved.\nFrom now on we will consider clean phase. (We can ignore regret incurred in the event that the phase is not clean.) We focus on the quantity ∆∗(u) = ∆(σ(u), ρ(u)). Note that by definition ∆∗(u) ≥ 0. The central argument of this proof is the following upper bound on ∆∗(u). Claim 9.4. In a clean phase, ∆∗(u) ≤ O(δ)(n − j) for each j ≤ n and each u ∈ Tj.\nProof. Use induction on j. The base case j = n follows by part (ii) of the definition of the clean phase, since for u ∈ Tn both σ(u) and ρ(u) lie in X(u), the set of diameter at most δ. For the induction step, assume the claim holds for each v ∈ Tj+1, and let us prove it for some fixed u ∈ Tj.\nPick children u, v ∈ C(u) such that σ(u) ∈ X(v) and ρ(u) ∈ X(w). Since the tie-breaking rules in (45) is fixed for all nodes in the covering tree, it follows that σ(u) = σ(v) and ρ(u) = ρ(w). Then\n∆∗(w) + ∆(σ(v), σ(w)) = ∆(σ(w), ρ(u)) + ∆(σ(u), σ(w))\n= µ(σ(w)) − µ(ρ(u)) + ν(ρ(u))− ρ(σ(w)) + µ(σ(u)) − µ(σ(w)) + ν(σ(w)) − ν(σ(u)) = ∆∗(u).\nClaim follows since ∆∗(w) ≤ O(δ)(n − j − 1) by induction, and ∆(σ(v), σ(w)) ≤ 4δ by part (i) in the definition of the clean phase.\nTo complete the proof of (43), let u0 be the root of the covering tree. Then y ∗ i = σ(u0) and\nx∗i = ρ(u0). Therefore by Claim 9.4 (applied for T0 = {u0}) we have\nO(δn) ≥ ∆∗(u0) = ∆∗(y∗i , x∗i ) ≥ µ(y∗i )− µ(x∗i )."
    }, {
      "heading" : "9.3 Regret characterization (proof of Theorem 6.5)",
      "text" : "As it turns out, the log-covering dimension is not the right notion to characterize optimal regret for arbitrary metric spaces. We need a more refined version: the max-min-log-covering dimension, defined in (33). similar to the max-min-covering dimension.\nTheorem 9.5. Fix a metric space (X,D) and let b = MaxMinLCD(X). The Lipschitz experts problem on (X,D) is (tγ)-tractable for any γ > b+1b+2 , and not (tγ)-tractable for any γ < b−1b .\nFor the lower bound, we use a suitably “thick” version of the ball-tree from Section 7.2 in conjunction with the (ǫ, δ, k)-ensemble idea from Section 7.2, see Section 9.3.1. For the algorithmic result, we combine the “naive” experts algorithm (UniformMeshExp) with (an extension of) the transfinite fat decomposition technique from Section 5, see Section 9.3.2.\nThe lower bound in Theorem 9.5 holds for the uniformly Lipschitz experts problem. It follows that the upper bound in Theorem 9.2 is optimal for metric spaces such that MaxMinLCD(X) = LCD(X), e.g. for ǫ-uniform tree metrics. In fact, we can plug the improved analysis of UniformMeshExp from Theorem 9.2 into the algorithmic technique from Theorem 9.5 and obtain a matching upper bound in terms of the MaxMinLCD. Thus (in conjunction with Theorem 6.1) we have a complete characterization for regret:\nTheorem 9.6. Consider the uniformly Lipschitz experts problem with full feedback. Fix a metric space (X,D) with uncountably many points, and let b = MaxMinLCD(X). The problem on (X,D) is (tγ)-tractable for any γ > max( b−1b , 1 2), and not (t γ)-tractable for any γ < max( b−1b , 1 2).\nThe proof of the upper bound in Theorem 9.6 proceeds exactly that in Theorem 9.5, except that we use a more efficient analysis of UniformMeshExp.\n9.3.1 The MaxMinLCD lower bound: proof for Theorem 9.6\nIf MaxMinLCD(X) = d, and γ < d−1d , let us first fix constants b and c such that b < c < d and γ < b−1b . Let Y ⊆ X be a subspace such that c ≤ inf{LCD(Z) : open, nonempty Z ⊆ Y }. We will repeatedly use the following packing lemma that relies on the fact that b < LCD(U) for all nonempty subsets U ⊆ Y . Lemma 9.7. For any nonempty open U ⊆ Y there exists r0 > 0 such that for all r ∈ (0, r0), U contains more than 2r −b disjoint balls of radius r.\nProof. Let r0 be a positive number such that for all positive r < r0, every covering of U requires more than 2r −b balls of radius 2r. Such an r0 exists, because LCD(U) > b. Now for any positive r < r0 let P = {B1, B2, . . . , BM} be any maximal collection of disjoint r-balls. For every y ∈ Y there must exist some ball Bi (1 ≤ i ≤ M) whose center is within distance 2r of y, as otherwise B(y, r) would be disjoint from every element of P contradicting the maximality of that collection. If we enlarge each ball Bi to a ball B + i of radius 2r, then every y ∈ Y is contained in one of the balls {B+i | 1 ≤ i ≤ M}, i.e. they form a covering of Y . Hence M ≥ 2r −b as desired.\nUsing the packing lemma we recursively construct a ball-tree on metric space (Y,D) with very high node degrees. Specifically, let us say that a ball-tree has log-strength b if each tree node with children of radius r has at least 2r −b children. For convenience, all tree nodes of the same depth will have the same radius ri. Then each node at depth i− 1 has at least ni = ⌈2r −b i ⌉ children.\nClaim 9.8. There exists a ball-tree T on (Y,D) with log-strength b, in which all tree nodes of the same depth i have the same radius ri.\nProof. The root of the ball tree is centered at any point in Y and has radius r0 = 1 4 . For each successive i ≥ 1, let ri ∈ (0, ri−1/4) be a positive number small enough that for every depth i − 1 tree node w = (x, ri−1), the sub-ball B(x, ri−1/2) contains ni = ⌈2r −b i ⌉ disjoint balls of radius ri. (Denote by Bw the collection of the corresponding disjoint extended balls.) Such ri exists by Lemma 9.7. The set of children of w is defined to be Bw.\nWe re-use Construction 7.7 for metric space (Y,D) and ball-tree T , with δi ≡ 13 . Thus, we construct a problem instance Pλ for each lineage over λ, and a distribution PT over problem instances Pλ. Recall that a problem instance is a distribution over (deterministic) payoff functions π : X → [0, 1], which are Lipschitz by Lemma 5.8.\nFix a complete lineage λ, and let w(λ) = (w0, w1, . . .) be the associated end of the ball-tree. For each i ≥ 1, let Bi be the ball in (Y,D) corresponding to tree node wi. Let µ = Eπ∼Pλ[π] be the expected payoff function corresponding to PQ. Then then µ achieves its maximum value 1 2 + 1 18 ∑∞ i=0 ri at the unique point x ∗ ∈ ∩∞i=0Bi. At any point x 6∈ Bj , we have\nµ(x∗)− µ(x) ≥ (\n1 18 ∑∞ i=j ri\n) − (\n1 18 ∑∞ i=j+1 ri\n)\n= 118 rj.\nWe now finish the lower bound proof as in the proof of Lemma 7.9. Fix depth i− 1 node w in the ball-tree, and let w1, w2 , . . . , wni be the children of w in the ball-tree. Let λ(w) be the unique child of w contained in the lineage λ. Consider the sets λ0 = λ \\ λ(w) and λj = λ0 ∪ {wj} for j = 1, 2, . . . , ni. By Corollary 7.11, the distributions (\nPλ0 ,Pλ1 , . . . ,Pλni\n)\nconstitute an (ǫ, δ, k)-ensemble\nfor ǫ = ri/18, δ = 1 3 , and k = ni. Consequently, for ti = r −b i , the inequality ti < ln(17k)/2δ 2 holds, and we obtain a lower bound of\nR(A, Pλj )(ti) > ǫ ti/2 = Ω(r 1−b i ) = Ω(t (b−1)/b i )\nfor at least half of the distributions Pλj in the ensemble. Recalling that γ < b−1 b , we see that the problem is not tγ-tractable.\n9.3.2 The MaxMinLCD upper bound: proofs for Theorem 9.5 and Theorem 9.6\nFirst, let us incorporate the analysis of UniformMeshExp(b) via the following lemma.\nLemma 9.9. Consider an instance (X,D,P) of the Lipschitz experts problem, and let x∗ ∈ X be an optimal point. Fix subset U ⊂ X which contains x∗, and let b > LCD(U). Then for any sufficiently large T and δ = T−1/(b+2) the following holds:\n(a) Let S be a δ-hitting set for U of cardinality |S| ≤ Nδ(U). Consider the feedback of all points in S over T rounds; let x be the point in S with the largest sample average (break ties arbitrarily). Then\nPr[µ(x∗)− µ(x) < O(δ log T )] > 1− T−2.\n(b) For a uniformly Lipschitz experts problem and b ≥ 2, property (a) holds for δ = T−1/b.\nTransfinite LCD decomposition. We redefine the transfinite fat decomposition from Section 5 with respect to the log-covering dimension rather than the covering dimension.\nDefinition 9.10. Fix a metric space (X,D). Let β denote an arbitrary ordinal. A transfinite LCD decomposition of depth β and dimension b is a transfinite sequence {Sλ}0≤λ≤β of closed subsets of X such that:\n(a) S0 = X, Sβ = ∅, and Sν ⊇ Sλ whenever ν < λ.\n(b) if V ⊂ X is closed, then the set {ordinals ν ≤ β: V intersects Sν} has a maximum element.\n(c) for any ordinal λ ≤ β and any open set U ⊂ X containing Sλ+1 we have LCD(Sλ \\ U) ≤ b.\nThe existence of suitable decompositions and the connection to MaxMinLCD is derived exactly as in Proposition 5.27\nLemma 9.11. For every compact metric space (X,D), MaxMinLCD(X) is equal to the infimum of all b such that X has a transfinite LCD decomposition of dimension b.\nIn what follows, let us fix metric space (X,D) and b > MaxMinLCD(X), and let {Sλ}0≤λ≤β be a transfinite LCD decomposition of depth β and dimension b. For each x ∈ X, let the depth of x be the maximal ordinal λ such that x ∈ Sλ. (Such an ordinal exists by Definition 9.10(b).) Access to the metric space. The algorithm requires two oracles: the depth oracle Length(·) and the covering oracle D-Cov(·). Both oracles input a finite collection F of open balls B0, B1, . . . , Bn, given via the centers and the radii, and return a point in X. Let B be the union of these balls, and let B be the closure of B. A call to oracle Length(F) returns an arbitrary point x ∈ B ∩Sλ, where λ is the maximum ordinal such that Sλ intersects B. (Such an ordinal exists by Definition 9.10(b).) Given a point y∗ ∈ X of depth λ, a call to oracle D-Cov(y∗,F) either reports that B covers Sλ, or it returns an arbitrary point x ∈ Sλ \\B. A call to D-Cov(∅,F) is equivalent to the call D-Cov(y∗,F) for some y∗ ∈ S0.\nThe covering oracle will be used to construct δ-nets as follows. First, using successive calls to D-Cov(∅,F) one can construct a δ-net for X. Second, given a point y∗ ∈ X of depth λ and a collection of open balls whose union is B, using successive calls to D-Cov(y∗, ·) one can construct a δ-net for Sλ \\B. The second usage is geared towards the scenario when Sλ+1 ⊆ B and for some optimal strategy x∗ we have x∗ ∈ Sλ \\B. Then by Definition 9.10(c) we have LCD(Sλ \\B) < b, and one can apply Lemma 9.9.\nThe algorithm. Our algorithm proceeds in phases i = 1, 2, 3, . . . of 2i rounds each. Each phase i outputs two strategies: x∗i , y ∗ i ∈ X that we call the best guess and the depth estimate. Throughout phase i, the algorithm plays the best guess x∗i−1 from the previous phase. The depth estimate y ∗ i−1 is used “as if” its depth is equal to the depth of some optimal strategy. (We show that for a large enough i this is indeed the case with a very high probability.)\nIn the end of the phase, an algorithm selects a finite set Ai ⊂ X of active points, as described below. Once this set is chosen, x∗i is defined simply as a point in Ai with the largest sample average of the feedback (breaking ties arbitrarily). It remains to define y∗i and Ai itself.\nLet T = 2i be the phase duration. Using the covering oracle, the algorithm constructs (roughly) the finest r-net containing at most 2 √ T points. Specifically, the algorithm constructs 2−j-nets Nj, for j = 0, 1, 2, . . ., until it finds the largest j such that Nj contains at most 2 √ T points. Let r = 2−j and N = Nj. For each x ∈ X, let µT (x) be the sample average of the feedback during this phase. Let\n∆T (x) = µ ∗ T − µT (x), where µ∗T = max(µT ,N )\nDefine the depth estimate y∗i to be the output of the oracle call Length(F), where\nF = {B(x, r) : x ∈ N and ∆T (x) < r}.\nFinally, let us specify Ai. Let B be the union of balls\n{B(x, r) : x ∈ N and ∆T (x) > 2(rT + r) }, (46)\nwhere rT = √ 8 log(T |N |)/T is chosen so that by Chernoff Bounds we have\nPr[|µT (x)− µ(x)| < rT ] > 1− (T |N |)−3 for each x ∈ N . (47)\nLet δ = T−1/b for the uniformly Lipschitz experts problem, and δ = T−1/(b+2) otherwise. Let QT = 2\nδ−b be the quota on the number of active points. Given a point y∗i−1 whose depth is (say) λ, algorithm uses the covering oracle to construct a δ-net N ′ for Sλ \\ B. Define Ai as N ′ or an arbitrary QT -point subset thereof, whichever is smaller. 35\nSketch of the analysis. The proof roughly follows that of Theorem 5.2. Call a phase clean if the event in (47) holds for all x ∈ Ni and the appropriate version of this event holds for all x ∈ Ai. (The regret from phases which are not clean is negligible). On a very high level, the proof consists of two steps. First we show that for a sufficiently large i, if phase i is clean then the depth estimate y∗i is correct, in the sense that it is indeed equal to the depth of some optimal strategy. The argument is similar to the one in Lemma 7.17. Second, we show that for a sufficiently large i, if the depth estimate y∗i−1 is “correct” (i.e. its depth is equal to that of some optimal strategy), and phase i is clean, then the “best guess” x∗i is good, namely µ(x ∗ i ) is within O(δlogT ) of the optimum. The reason is that, letting λ be the depth of y∗i−1, one can show that for a sufficiently large T the set B (defined in (46)) contains Sλ+1 and does not contain some optimal strategy. By definition of the transfinite LCD decomposition we have LCD(Sλ \\ U) < b, so in our construction the quota QT on the number of active points permits Ai to be a δ-cover of Sλ \\ U . Now we can use Lemma 9.9 to guarantee the “quality” of x∗i . The final regret computation is similar to the one in the proof of Theorem 9.1."
    }, {
      "heading" : "10 Directions for further work",
      "text" : "Kleinberg et al. (2008c) (i.e., Sections 4 and Section 5 of this paper) introduced the Lipschitz MAB problem and motivated a host of open questions. Many of these questions have been addressed in the follow-up work, including Kleinberg and Slivkins (2010) (i.e., the rest of this paper), and the work described in Section 2.1. Below we describe the current state of the open questions.\nFirst, the adaptive refinement technique from Section 4 can potentially be used in other settings in explore-exploit learning where one has side information on similarity between arms. Specific potential applications include adversarial MAB, Gaussian Process Bandits, and dynamic pricing. Also, stronger analysis of this technique appears possible in the context of ranked bandits (see Slivkins et al. (2013) for details).\nSecond, it is desirable to consider MAB with more general structure on payoff functions. A particularly attractive target would be structures that subsume Lipschitz MAB and Linear MAB.\nThird, a recurring theme in algorithm design is structural results that assert that a problem instance either has simple structure, or it contains a specific type of complex substructure that empowers the lower bound analysis. Our work contributes another example of this theme, in the form of dichotomy results in point-set topology (e.g. existence of a transfinite fat decomposition versus existence of a ball tree). It would potentially be interesting to find other applications of this technique.\n35The interesting case here is |N ′| ≤ QT . If N ′ contains too many points, the choice of Ai is not essential for the analysis."
    }, {
      "heading" : "A KL-divergence techniques",
      "text" : "All lower bounds in this paper heavily use the notion of Kullback-Leibler divergence (KL-divergence). Our usage of the KL-divergence techniques is encapsulated in several statements in the body of the paper (Theorem 5.7, Theorem 7.12, and Claim 7.18), whose proofs are fleshed out in this appendix and may be of independent interest. To make this appendix more self-contained, we restate the relevant definitions and theorem statements from the body of the paper, and provide sufficient background.\nA.1 Background\nDefinition A.1. Let Ω be a finite set with two probability measures p, q. Their KL-divergence is the sum\nKL(p; q) = ∑\nx∈Ω p(x) ln\n(\np(x)\nq(x)\n)\n,\nwith the convention that p(x) ln(p(x)/q(x)) is interpreted to be 0 when p(x) = 0 and +∞ when p(x) > 0 and q(x) = 0. If Y is a random variable defined on Ω and taking values in some set Γ, the conditional KL-divergence of p and q given Y is the sum\nKL(p; q |Y ) = ∑\nx∈Ω p(x) ln\n(\np(x |Y = Y (x)) q(x |Y = Y (x))\n)\n,\nwhere terms containing log(0) or log(∞) are handled according to the same convention as above.\nThe definition can be applied to an infinite sample space Ω provided that q is absolutely continuous with respect to p. For details, see Kleinberg (2005), Chapter 2.7. The following lemma summarizes some standard facts about KL-divergence; for proofs, see (Cover and Thomas, 1991; Kleinberg, 2005).\nLemma A.2. Let p, q be two probability measures on a measure space (Ω,F) and let Y be a random variable defined on Ω and taking values in some finite set Γ. Define a pair of probability measures pY , qY on Γ by specifying that pY (y) = p(Y = y), qY (y) = q(Y = y) for each y ∈ Γ. Then\nKL(p; q) = KL(p; q |Y ) + KL(pY ; qY ),\nand KL(p; q |Y ) is non-negative.\nAn easy corollary is the following lemma which expresses the KL-divergence of two distributions on sequences as a sum of conditional KL-divergences.\nLemma A.3. Let Ω be a sample space, and suppose p, q are two probability measures on Ωn, the set of n-tuples of elements of Ω. For a sample point ~ω ∈ Ωn, let ωi denote its first i components. If pi, qi denote the probability measures induced on Ωi by p (resp. q) then\nKL(p; q) = ∑n i=1 KL(p i; qi |ωi−1).\nProof. For m = 1, 2, . . . , n, the formula KL(pm; qm) = ∑m i=1 KL(p i; qi |ωi−1) follows by induction on m, using Lemma A.2.\nThe following three lemmas will also be useful in our lower bound argument. They may have appeared in the literature, but we cannot provide specific citations. We provide proofs for the sake of completeness. Here and henceforth we will use the following notational convention: for real numbers a, b ∈ [0, 1], KL(a; b) denotes the KL-divergence KL(p; q) where p, q are probability measures on {0, 1} such that p({1}) = a, q({1}) = b. In other words,\nKL(a; b) = a ln ( a b )\n+ (1− a) ln ( 1−a 1−b ) .\nLemma A.4. For any 0 < ǫ < y ≤ 1, KL(y − ǫ; y) < ǫ2/y(1− y).\nProof. A calculation using the inequality ln(1 + x) < x (valid for x > 0) yields\nKL(y − ǫ; y) = (y − ǫ) ln ( y−ǫ y ) + (1− y + ǫ) ln ( 1−y+ǫ 1−y )\n< (y − ǫ) ( y−ǫ y − 1 ) + (1− y + ǫ) ( 1−y+ǫ 1−y − 1 ) = −ǫ(y−ǫ)y + ǫ(1−y+ǫ) 1−y = ǫ2 y(1−y) .\nLemma A.5. Let Ω be a sample space with two probability measures p, q whose KL-divergence is κ. For any event E, the probabilities p(E), q(E) satisfy\nq(E) ≥ p(E) exp ( −κ+1/ep(E) ) .\nA consequence of the lemma, stated in less quantitative terms, is the following: if κ = KL(p; q) is bounded above and p(E) is bounded away from zero then q(E) is bounded away from zero.\nProof. Let a = p(E), b = q(E), c = (1 − a)/(1 − b). Applying Lemma A.2 with Y as the indicator random variable of E we obtain\nκ = KL(p; q) ≥ KL(pY ; qY ) = a ln ( a b )\n+ (1− a) ln ( 1−a 1−b ) = a ln ( a b ) + (1− b) c ln(c).\nNow using the inequality c ln(c) ≥ −1/e, (valid for all c ≥ 0) we obtain\nκ ≥ a ln(a/b)− (1− b)/e ≥ a ln(a/b) − 1/e.\nThe lemma follows by rearranging terms.\nLemma A.6. Let p, q be two probability measures, and suppose that for some δ ∈ (0, 12 ] they satisfy\n∀ events E , 1− δ < q(E)p(E) < 1 + δ\nThen KL(p; q) < δ2.\nProof. We will prove the lemma assuming the sample space is finite. The result for general measure spaces follows by taking a supremum.\nFor every x in the sample space Ω, let r(x) = q(x)p(x) − 1 and note that |r(x)| < δ for all x. Now we make use of the inequality ln(1 + x) ≤ x− x2, valid for x ≥ −12 .\nKL(p; q) = ∑ x p(x) ln ( p(x) q(x) )\n= ∑ x p(x) ln ( 1 1+r(x) )\n= −∑x p(x) ln(1 + r(x)) ≤ − ∑ x p(x)[r(x)− (r(x))2] < − (∑x p(x)r(x)) + δ2 ( ∑ x p(x)) = − (∑x q(x)− p(x)) + δ2 = δ2.\nA.2 Bandit lower bound via (ǫ, k)-ensembles\nWe consider an MAB problem with i.i.d. payoffs where the algorithm is given a set of arms X and a collection F of feasible payoff functions X → [0, 1]. We call it the feasible MAB problem on (X,F). We will consider 0-1 payoffs; then for a problem instance with payoff function f ∈ F , the reward from each action x ∈ X is 1 with probability f(x), and 0 otherwise. Definition (Definition 5.6, restated). Consider the feasible MAB problem on (X,F). An (ǫ, k)ensemble is a collection of subsets F1 , . . . ,Fk ⊂ F such that there exist mutually disjoint subsets S1 , . . . , Sk ⊂ X and a function µ0 : X → [13 , 23 ] such that for each i = 1 . . . k and each function µi ∈ Fi the following holds: (i) µi ≡ µ0 on each Sℓ, ℓ 6= i, and (ii) sup(µi, Si)− sup(µ0,X) ≥ ǫ, and (iii) 0 ≤ µi − µ0 ≤ 2ǫ on Si. Theorem (Theorem 5.7, restated). Consider the feasible MAB problem with 0-1 payoffs. Let F1, . . . ,Fk be an (ǫ, k)-ensemble, where k ≥ 2 and ǫ ∈ (0, 124 ). Then for any t ≤ 1128 k ǫ−2 and any bandit algorithm there exist at least k/2 distinct i’s such that the regret of this algorithm on any payoff function from Fi is at least 160 ǫt. Proof. Let us specify the notation. Let Ω = X × {0, 1}. Since we assume 0-1 payoffs, the tstep history of play of a bandit algorithm A can be expressed by an element of Ωt indicating the sequence of arms selected and payoffs received. Thus, an algorithm A and a payoff function µ together determine a probability distribution on Ωt for every natural number t. Fix any (possibly randomized) algorithm A and consider the distribution p determined by A when the payoff function is µ0. Recall the mutually disjoint sets S1, S2, . . . , Sk in the definition of an (ǫ, k)-ensemble. For 1 ≤ i ≤ k and 1 ≤ u ≤ t, let Yi,u be the indicator random variable of the event xu ∈ Si, where xu denotes the arm selected by A at time u. Let Zi = ∑t u=1 Yi,u.\nSince ∑k i=1 Ep [Zi] ≤ t, there must be at least k/2 indices i such that Ep[Zi] ≤ t/k ≤ 1/128 ǫ2. Fix one such i, and an arbitrary µi ∈ Fi. In what follows, we will show that R(A, µi)(t) ≥ ǫt/60.\nLet (xu, yu) ∈ X × {0, 1} = Ω denote the arm selected and the payoff received at time u, and let q denote the distribution on Ωt determined by A and µi. We have\nKL(pu; qu |ωu−1) = ∑\nωu∈Ωu pu(ωu) ln\n( pu(ωu |ωu−1) qu(ωu |ωu−1) )\n= ∑\nωu∈Ωu pu(ωu) ln\n( pu(xu |ωu−1) qu(xu |ωu−1) · p u(yu |xu, ωu−1) qu(yu |xu, ωu−1) )\n= ∑\nωu∈Ωu pu(ωu) ln\n( pu(yu |xu, ωu−1) qu(yu |xu, ωu−1) )\n[the distribution of xu given ω u−1 depends only on A, not on distribution p versus q.]\n= ∑\nωu−1∈Ωu−1\n∫\nxu∈X\n∑\nyu∈{0,1} pu(yu |xu, ωu−1) ln\n( pu(yu |xu, ωu−1) qu(yu |xu, ωu−1) ) d pu( · , ωu−1)\n= ∑\nωu−1∈Ωu−1\n∫\nxu∈X KL(µ0(xu); µi(xu) |xu, ωu−1) d pu( · , ωu−1)\n= ∑\nωu−1∈Ωu−1\n∫\nxu∈Si KL(µ0(xu));µi(xu) |xu, ωu−1) d pu( · , ωu−1)\n[because µ0 = µi(xu) when xu 6∈ Si.]\n≤ ∑\nωu−1∈Ωu−1\n∫\nxu∈Si\n4 ǫ2\nµi(xu)(1 − µi(xu)) d pu( · , ωu−1)\n[by Lemma A.4 and property (iii) in the definition of “ensemble”\n.] ≤ pu(xu ∈ Si) · 4ǫ2\n3/16 .\nThe last inequality holds because µi(xu) ∈ [13 , 34 ]. The latter holds by property (iii) in the definition of the “ensemble” and the assumptions that µ0 ∈ [13 , 23 ] and ǫ ≤ 124 .\nNow we can write\nKL(p; q) =\nt ∑\nu=1\nKL(pu; qu |ωu−1) ≤ ( t ∑\nu=1\npu(xu ∈ Si) ) · 64 ǫ 2\n3\n= E [Zi] · 64 ǫ2 3 ≤ 1 128 ǫ2 · 64ǫ 2 3 = 1 6 .\nLet E be the event that Zi ≤ 5t3k . By Markov’s inequality, p(E) ≥ 0.4. Now using Lemma A.5 along with the bound KL(p; q) ≤ 1/6, a short calculation leads to the bound q(E) ≥ 0.1, and consequently,\nE q [t− Zi] ≥ q(E)E q [t− Zi | E ]\n≥ 0.1 · ( t− 5t 3k ) ≥ 0.1 · ( t− 5t 6 ) = t 60 .\nAssuming the payoff function is µi, the regret of algorithm A increases by ǫ each time it chooses a arm xu 6∈ Si. Hence\nR(A, µi)(t) ≥ ǫEq [t− Zi] ≥ ǫt/60.\nA.3 Experts lower bound via (ǫ, δ, k)-ensembles\nWe consider the feasible experts problem, in which one is given an action set X along with a collection F of Borel probability measures on the set [0, 1]X of functions π : X → [0, 1]. A problem instance of the feasible experts problem consists of a triple (X,F ,P) where X and F are known to the algorithm, and P ∈ F is not. In each round the payoff function π is sampled independently from P, so that for each action x ∈ X the (realized) payoff is π(x).\nDefinition A.7 (Definition 7.10, restated). Consider a setX and a (k+1)-tuple ~P = (P0,P1 , . . . ,Pk) of Borel probability measures on [0, 1]X , the set of [0, 1]-valued payoff functions π on X. For 0 ≤ i ≤ k and x ∈ X, let µi(x) denote the expectation of π(x) under measure Pi. We say that ~P is an (ǫ, δ, k)-ensemble if there exist pairwise disjoint subsets S1, S2, . . . , Sk ⊆ X for which the following properties hold:\n(i) for every i > 0 and every event E in the Borel σ-algebra of [0, 1]X , we have\n1− δ < P0(E)/Pi(E) < 1 + δ.\n(ii) for every i > 0, we have sup(µi, Si)− sup(µi, X \\ Si) ≥ ǫ.\nTheorem A.8 (Theorem 7.12, restated). Consider the feasible experts problem on (X,F). Let ~P be an (ǫ, δ, k)-ensemble with {P1, . . . ,Pk} ⊆ F and 0 < ǫ, δ < 1/2. Then for any t < ln(17k)/(2δ2) and any experts algorithm A, at least half of the measures Pi have the property that R(A, Pi)(t) ≥ ǫt/2.\nProof. Let Ω = [0, 1]X . Using Property (i) of an (ǫ, δ, k)-ensemble combined with Lemma A.6, we find that KL(Pi;P0) < δ\n2. Let A be an experts algorithm whose random bits are drawn from a sample space Γ with probability measure ν. For any positive integer s < ln(17k)/2δ2 , let psi denote the measure ν×(Pi)s on the probability space Γ × Ωs. By the chain rule for KL-divergence (Lemma A.3), KL(psi ; ps0) < sδ2 < ln(17k)/2. Now let Esi denote the event that A selects a point x ∈ Si at time s. If psi (Esi ) ≥ 12 then Lemma A.5 implies\nps0(Esi ) ≥ psi (Esi ) exp ( − ln(17k)/2 + 1/e psi (Esi ) ) ≥ 12 exp ( − ln(k) + ln(17)− 2e ) > 4 k .\nThe events {Esi | 1 ≤ i ≤ k} are mutually exclusive, so fewer than k/4 of them can satisfy ps0(Esi ) > 4k . Consequently, fewer than k/4 of them can satisfy psi (Esi ) ≥ 12 , a property we denote in this proof by saying that s is satisfactory for i. Now assume t < ln(17k)/2δ2 . For a uniformly random i ∈ {1, . . . , k}, the expected number of satisfactory s ∈ {1, . . . , t} is less than t/4, so by Markov’s inequality, for at least half of the i ∈ {1, . . . , k}, the number of satisfactory s ∈ {1, . . . , t} is less than t/2. Property (ii) of an (ǫ, δ, k)-ensemble guarantees that every unsatisfactory s contributes at least ǫ to the regret of A when the problem instance is Pi. Therefore, at least half of the measures Pi have the property that R(A, Pi)(t) ≥ ǫt/2.\nA.4 Proof of Claim 7.18\nRecall that in Section 7.4 we defined a pair of payoff functions µ0, µi and a ball Bi of radius ri such that µ0 ≡ µi on X \\Bi, while for x ∈ Bi we have\n3 8 ≤ µ0(x) ≤ µi(x) ≤ µ0(x) + ri4 ≤ 34 .\nThus, by Lemma A.4, KL(µ0(x);µi(x)) < r 2 i /3 for all x ∈ X, and KL(µ0(x);µi(x)) = 0 for x 6∈ Bi.\nRepresent the algorithm’s choice and the payoff observed at any given time t by a pair (xt, yt). Let Ω = X × [0, 1] denote the set of all such pairs. When a given algorithm A plays against payoff functions µ0, µi, this defines two different probability measures p t 0, p t i on the set Ω\nt of possible t-step histories. Let ωt denote a sample point in Ωt. The bounds derived in the previous paragraph imply that for any non-negative integer s,\nKL(ps+10 ; p s+1 i |ωs) < 13r2i P0(xs+1 ∈ Bi). (48)\nSumming equation (48) for s = 0, 1, . . . , t− 1 and applying Lemma A.3 we obtain\nKL(pt0; p t i) < 1 3r 2 i ∑t s=1 P0(xs ∈ Bi) = 13r2i E0(Ni(t)), (49)\nwhere the last equation follows from the definition of Ni(t) as the number of times algorithm A selects a arm in Bi during the first t rounds.\nThe bound stated in Claim 7.18 now follows by applying Lemma A.5 with the event S playing the role of E , P0 playing the role of p, and Pi playing the role of q."
    }, {
      "heading" : "B Reduction to complete metric spaces",
      "text" : "In this section we reduce the Lipschitz MAB problem to that on complete metric spaces.\nLemma B.1. The Lipschitz MAB problem on a metric space (X, d) is f(t)-tractable if and only if it is f(t)-tractable on the completion of (X, d). Likewise for the Lipschitz experts problem with double feedback.\nProof. Let (X, d) be a metric space with completion (Y, d). Since Y contain an isometric copy of X, we will abuse notation and consider X as a subset of Y . We will present the proof the Lipschitz MAB problem; for the experts problem with double feedback, the proof is similar.\nGiven an algorithm AX which is f(t)-tractable for (X, d), we may use it as a Lipschitz MAB algorithm for (Y, d) as well. (The algorithm has the property that it never selects a point of Y \\X, but this doesn’t prevent us from using it when the metric space is (Y, d).) The fact that X is dense in Y implies that for every Lipschitz payoff function µ defined on Y , we have sup(µ,X) = sup(µ, Y ). From this, it follows immediately that the regret ofAX , when considered a Lipschitz MAB algorithm for (X, d), is the same as its regret when considered as a Lipschitz MAB algorithm for (Y, d).\nConversely, given an algorithm AY which is f(t)-tractable for (Y, d), we may design a Lipschitz MAB algorithm AX for (X, d) by running AY and perturbing its output slightly. Specifically, for each point y ∈ Y and each t ∈ N we fix x = x(y, t) ∈ X such that d(x, y) < 2−t. If AY recommends playing strategy yt ∈ Y at time t, algorithm AX instead plays x = x(y, t). Let π be the observed payoff. Algorithm AX draws an independent 0-1 random sample with expectation π, and reports this sample to AY . This completes the description of the modified algorithm AX .\nSuppose AX is not f(t)-tractable. Then for some problem instance I on (Y, d), letting RX(t) be the expected regret of AX on this instance, we have that supt∈NRX(t)/f(t) = ∞. Let µ be the expected payoff function in I. Consider the following two problem instances of a MAB problem on Y , called I1 and I2, in which if point y ∈ Y is played at time t, the payoff is an independent 0-1 random sample with expectation µ(y) and µ(x(y, t)), respectively. Note that algorithm AY is f(t)-tractable on I1, and its behavior on I2 is identical to that of AX on the original problem instance I. It follows that by observing the payoffs of AY one can tell apart I1 and I2 with high probability. Specifically, there is a “classifier” C which queries one point in each round, such that for infinitely many times t it tell apart I1 and I2 with success probability p(t) → 1. Now, the latter is information-theoretically impossible.\nTo see this, let Ht be the t-round history of the algorithm (the sequence of points queried, and outputs received), and consider the distribution ofHt under problem instances I∞ and I∈ (call these distributions q1 and q2). Let us consider and look at their KL-divergence. By the chain rule (See Lemma A.2), we can show that KL(q1, q2) < 1 2 . (We omit the details.) It follows that letting St be the event that C classifies the instance as I1 after round t, we have Pq1 [St]−Pq2 [St] ≤ KL(q1, q2) ≤ 12 . For any large enough time t, Pq1[St] < 1 4 , in which case C makes a mistake (on I2) with constant probability.\nLemma B.2. Consider the Lipschitz experts problem with full feedback. If it is f(t)-tractable on a metric space (X, d) then it is f(t)-tractable on the completion of (X, d).\nProof. Identical to the easy (“only if”) direction of Lemma B.1.\nRemark. Lower bounds only require Lemma B.2, or the easy (“only if”) direction of Lemma B.1. For the upper bounds (algorithmic results), we can either quote the “if” direction of Lemma B.1, or prove the desired property directly for the specific type algorithms that we use (which is much easier but less elegant)."
    }, {
      "heading" : "C Topological equivalences: proof of Lemma 7.3",
      "text" : "Let us restate the lemma, for the sake of convenience. Recall that it includes an equivalence result for compact metric spaces, and two implications for arbitrary metric spaces:\nLemma C.1. For any compact metric space (X, d), the following are equivalent: (i) X is a countable set, (ii) (X, d) is well-orderable, (iii) no subspace of (X, d) is perfect. For an arbitrary metric space we have (ii) ⇐⇒ (iii) and (i)⇒(ii), but not (ii)⇒(i).\n(compact metric spaces). Let us prove the assertions in the circular order.\n(i) implies (iii). Let us prove the contrapositive: if (X, d) has a perfect subspace Y , then X is uncountable. We have seen that if (X, d) has a perfect subspace Y then it has a ball-tree. Every end ℓ of the ball-tree (i.e. infinite path starting from the root) corresponds to a nested sequence of balls. The closures of these balls have the finite intersection property, hence their their intersection is non-empty. Pick an arbitrary point of the intersection and call if x(ℓ). Distinct ends ℓ, ℓ′ correspond to distinct points x(ℓ), x(ℓ′) because if (y, ry), (z, rz) are siblings in the ball-tree which are ancestors of ℓ and ℓ′, respectively, then the closures of B(y, ry) and B(z, rz) are disjoint and they contain x(ℓ), x(ℓ′) respectively. Thus we have constructed a set of distinct points of X, one for each end of the ball-tree. There are uncountably many ends, so X is uncountable.\n(iii) implies (ii). Let β be some ordinal of strictly larger cardinality than X. Let us define a transfinite sequence {xλ}λ≤β of points in X using transfinite recursion36, by specifying that x0 is any isolated point of X, and that for any ordinal λ > 0, xλ is any isolated point of the subspace (Yλ, d), where Yλ = X \\ {xν : ν < λ}, as long as Yλ is nonempty. (Such isolated point exists since by our assumption subspace (Yλ, d) is not perfect.) If Yλ is empty define e.g. xλ = x0. Now, Yλ is empty for some ordinal λ because otherwise we obtain a mapping from X onto an ordinal β whose cardinality exceeds the cardinality of X. Let β0 = min{λ : Yλ = ∅}. Then every point in X has been indexed by an ordinal number λ < β0, and so we obtain a well-ordering of X. By construction, for every x = xλ we can define a radius r(x) > 0 such that B(x, r(x)) is disjoint from the set of points {xν : ν > λ}. Any initial segment S of the well-ordering is equal to the union of the balls {B(x, r(x)) : x ∈ S}, hence is an open set in the metric topology. Thus we have constructed a topological well-ordering of X.\n(ii) implies (i). Suppose we have a binary relation ≺ which is a topological well-ordering of (X, d). Let S(n) denote the set of all x ∈ X such that B(x, 1n) is contained in the set P (x) = {y : y x}. By the definition of a topological well-ordering we know that for every x, P (x) is an open set, hence x ∈ S(n) for sufficiently large n. Therefore X = ∪n∈NS(n). Now, the definition of S(n) implies\n36”Transfinite recursion” is a theorem in set theory which asserts that in order to define a function F on ordinals, it suffices to specify, for each ordinal λ, how to determine F (λ) from F (ν), ν < λ.\nthat every two points of S(n) are separated by a distance of at least 1/n. (If x and z are distinct points of S(n) and x ≺ z, then B(x, 1n) is contained in the set P (x) which does not contain z, hence d(x, z) ≥ 1n .) Thus by compactness of (X, d) set S(n) is finite.\n(arbitrary metric spaces). For implications (i)⇒(ii) and (iii)⇒(ii), the proof above does not in fact use compactness. An example of an uncountable but well-orderable metric space is (R, d), where d is a uniform metric. It remains to prove that (ii)⇒(iii).\nSuppose there exists a topological well-ordering ≺. For each subset Y ⊆ X and an element λ ∈ Y let Y≺(λ) = {y ∈ Y : y λ} be the corresponding initial segment.\nWe claim that ≺ induces a topological well-ordering on any subset Y ⊆ X. We need to show that for any λ ∈ Y the initial segment Y≺(λ) is open in the metric topology of (Y, d). Indeed, fix y ∈ Y≺(λ). The initial segment X≺(λ) is open by the topological well-ordering property of X, so BX(y, ǫ) ⊂ X≺(λ) for some ǫ > 0. Since Y≺(λ) = X≺(λ)∩Y and BY (y, ǫ) = BX(y, ǫ)∩Y , it follows that BY (y, ǫ) ⊂ Y≺(λ). Claim proved.\nSuppose the metric space (X, d) has a perfect subspace Y ⊂ X. Let λ be the ≺-minimum element of Y . Then Y≺(λ) = {λ}. However, by the previous claim ≺ is a topological well-ordering of (Y, d), so the initial segment Y≺(λ) is open in the metric topology of (Y, d). Since (Y, d) is perfect, Y≺(λ) must be infinite, contradiction. This completes the (ii)⇒(iii) direction."
    }, {
      "heading" : "D Log-covering dimension: an example",
      "text" : "We flesh out an example from Section 6. Fix a metric space (X,D) of finite diameter and covering dimension κ < ∞. Let PX denote the set of all probability measures over X. Let (PX ,W1) be the space of all probability measures over (X,D) under the Wasserstein W1 metric (see Footnote 30 on page 47).\nTheorem D.1. The log-covering dimension of (PX ,W1) is κ.\nFor the sake of completeness: for any µ, µ′ ∈ PX , the Wasserstein W1 metric, a.k.a. the Earthmover distance, is defined as W1(ν, ν\n′) = inf E[D(Y, Y ′) ], where the infimum is taken over all joint distributions (Y, Y ′) on X ×X with marginals ν and ν ′ respectively.\nIn the remainder of this subsection we prove Theorem D.1.\n(Theorem D.1: upper bound). Let us cover (PX ,W1) with balls of radius 2k for some k ∈ N. Let S be a 1k -net in (X, d); note that |S| = O(kκ) for a sufficiently large k. Let P be the set of all probability distributions p on (X, d) such that support(p) ⊂ S and for every point x ∈ S, p(x) is a rational number with denominator kd+1. The cardinality of P is bounded above by (kκ+1)k κ . It remains to show that balls of radius 2k centered at the points of P cover the entire space (PX ,W1). This is true because:\n• every distribution q is 1k -close to a distribution p with support contained in S (let p be the distribution defined by randomly sampling a point of (X, d) from q and then outputting the closest point of S);\n• every distribution with support contained in S is 1k -close to a distribution in P (round all probabilities down to the nearest multiple of k−(κ+1); this requires moving only 1k units of stuff).\nTo prove the lower bound, we make a connection to the Hamming metric.\nLemma D.2. Let (X, d) be any metric space, and let H denote the Hamming metric on the Boolean cube {0, 1}n. If S ⊆ X is a subset of even cardinality 2n, and ǫ is a lower bound on the distance between any two points of S, then there is a mapping f : {0, 1}n → PX such that for all a, b ∈ {0, 1}n,\nW1(f(a), f(b)) ≥ ǫn H(a, b). (50)\nProof. Group the points of S arbitrarily into pairs Si = {xi, yi}, where i = 1, . . . , n. For a ∈ {0, 1}n and 1 ≤ i ≤ n, define ti(a) = xi if ai = 0, and ti(a) = yi otherwise. Let f(a) be the uniform distribution on the set {t1(a), . . . , tn(a)}. To prove (50), note that if i is any index such that ai 6= bi then f(a) assigns probability 1n to ti(a) while f(b) assigns zero probability to the entire ball of radius ǫ centered at ti(a). Consequently, the 1 n units of probability at ti(a) have to move a distance of at least ǫ when shifting from distribution f(a) to f(b). Summing over all indices i such that ai 6= bi, we obtain (50).\nThe following lemma, asserting the existence of asymptotically good binary error-correcting codes, is well known, e.g. see (Gilbert, 1952; Varshamov, 1957).\nLemma D.3. Suppose δ, ρ are constants satisfying 0 < δ < 12 and 0 ≤ ρ < 1 + δ log2(δ) + (1 − δ) log2(1 − δ). For every sufficiently large n, the Hamming cube {0, 1}n contains more than 2ρn points, no two of which are nearer than distance δn in the Hamming metric.\nCombining these two lemmas, we obtain an easy proof for the lower bound in Theorem D.1.\n(Theorem D.1: lower bound). Consider any γ < κ. The hypothesis on the covering dimension of (X, d) implies that for all sufficiently small ǫ, there exists a set S of cardinality 2n — for some n > ǫ−γ — such that the minimum distance between two points of S is at least 5ǫ. Now let C be a subset of {0, 1}n having at least 2n/5 elements, such that the Hamming distance between any two points of C is at least n/5. Lemma D.3 implies that such a set C exists, and we can then apply Lemma D.2 to embed C in PX , obtaining a subset of PX whose cardinality is at least 2ǫ\n−γ/5, with distance at least ǫ between every pair of points in the set. Thus, any ǫ-covering of PX must contain at least 2ǫ\n−γ/5 sets, implying that LCD(PX ,W1) ≥ γ. As γ was an arbitrary number less than κ, the proposition is proved."
    } ],
    "references" : [ ],
    "referenceMentions" : [ ],
    "year" : 2015,
    "abstractText" : "In a multi-armed bandit problem, an online algorithm chooses from a set of strategies in<lb>a sequence of trials so as to maximize the total payoff of the chosen strategies. While the<lb>performance of bandit algorithms with a small finite strategy set is quite well understood,<lb>bandit problems with large strategy sets are still a topic of very active investigation, motivated<lb>by practical applications such as online auctions and web advertisement. The goal of such<lb>research is to identify broad and natural classes of strategy sets and payoff functions which<lb>enable the design of efficient solutions.<lb>In this work we study a very general setting for the multi-armed bandit problem in which<lb>the strategies form a metric space, and the payoff function satisfies a Lipschitz condition with<lb>respect to the metric. We refer to this problem as the Lipschitz MAB problem. We present<lb>a solution for the multi-armed bandit problem in this setting. That is, for every metric space<lb>we define an isometry invariant which bounds from below the performance of Lipschitz MAB<lb>algorithms for this metric space, and we present an algorithm which comes arbitrarily close<lb>to meeting this bound. Furthermore, our technique gives even better results for benign payoff<lb>functions. We also address the full-feedback (“best expert”) version of the problem, where after<lb>every round the payoffs from all arms are revealed. ACM Categories: F.2.2 [Analysis of Algorithms and Problem Complexity]: Nonnumerical<lb>Algorithms and Problems; F.1.2 [Computation by Abstract Devices]: Modes of Computation—<lb>Online computation<lb>",
    "creator" : "LaTeX with hyperref package"
  }
}