{
  "name" : "1506.03693.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "Optimization Monte Carlo: Efficient and Embarrassingly Parallel Likelihood-Free Inference",
    "authors" : [ "Edward Meeds", "Max Welling" ],
    "emails" : [ "tmeeds@gmail.com", "welling.max@gmail.com" ],
    "sections" : [ {
      "heading" : "1 Introduction",
      "text" : "Computationally demanding simulators are used across the full spectrum of scientific and industrial applications, whether one studies embryonic morphogenesis in biology, tumor growth in cancer research, colliding galaxies in astronomy, weather forecasting in meteorology, climate changes in the environmental science, earthquakes in seismology, market movement in economics, turbulence in physics, brain functioning in neuroscience, or fabrication processes in industry. Approximate Bayesian computation (ABC) forms a large class algorithms that aims to sample from the posterior distribution over parameters for these likelihood-free (a.k.a. simulator based) models. Likelihoodfree inference, however, is notoriously inefficient in terms of the number of simulation calls per independent sample. Further, like regular Bayesian inference algorithms, care must be taken so that posterior sampling targets the correct distribution.\nThe simplest ABC algorithm, ABC rejection sampling, can be fully parallelized by running independent processes with no communication or synchronization requirements. I.e. it is an embarrassingly parallel algorithm. Unfortunately, as the most inefficient ABC algorithm, the benefits of this title are limited. There has been considerable progress in distributed MCMC algorithms aimed at large-scale data problems [2, 1]. Recently, a sequential Monte Carlo (SMC) algorithm called “the particle cascade” was introduced that emits streams of samples asynchronously with minimal memory management and communication [17]. In this paper we present an alternative embarrassingly parallel sampling approach: each processor works independently, at full capacity, and will indefinitely emit independent samples. The main trick is to pull random number generation outside of the simulator and treat the simulator as a deterministic piece of code. We then minimize the difference\n∗Donald Bren School of Information and Computer Sciences University of California, Irvine, and Canadian Institute for Advanced Research.\nar X\niv :1\n50 6.\n03 69\n3v 2\n[ cs\n.L G\n] 2\nD ec\nbetween observations and the simulator output over its input parameters and weight the final (optimized) parameter value with the prior and the (inverse of the) Jacobian. We show that the resulting weighted ensemble represents a Monte Carlo estimate of the posterior. Moreover, we argue that the error of this procedure is O( ) if the optimization gets -close to the optimal value. This “Optimization Monte Carlo” (OMC) has several advantages: 1) it can be run embarrassingly parallel, 2) the procedure generates independent samples and 3) the core procedure is now optimization rather than MCMC. Indeed, optimization as part of a likelihood-free inference procedure has recently been proposed [12]; using a probabilistic model of the mapping from parameters to differences between observations and simulator outputs, they apply “Bayesian Optimization” (e.g. [13, 21]) to efficiently perform posterior inference. Note also that since random numbers have been separated out from the simulator, powerful tools such as “automatic differentiation” (e.g. [14]) are within reach to assist with the optimization. In practice we find that OMC uses far fewer simulations per sample than alternative ABC algorithms.\nThe approach of controlling randomness as part of an inference procedure is also found in a related class of parameter estimation algorithms called indirect inference [11]. Connections between ABC and indirect inference have been made previously by [7] as a novel way of creating summary statistics. An indirect inference perspective led to an independently developed version of OMC called the “reverse sampler” [9, 10].\nIn Section 2 we briefly introduce ABC and present it from a novel viewpoint in terms of random numbers. In Section 3 we derive ABC through optimization from a geometric point of view, then proceed to generalize it to higher dimensions. We show in Section 4 extensive evidence of the correctness and efficiency of our approach. In Section 5 we describe the outlook for optimizationbased ABC."
    }, {
      "heading" : "2 ABC Sampling Algorithms",
      "text" : "The primary interest in ABC is the posterior of simulator parameters θ given a vector of (statistics of) observations y, p(θ|y). The likelihood p(y|θ) is generally not available in ABC. Instead we can use the simulator as a generator of pseudo-samples x that reside in the same space as y. By treating x as auxiliary variables, we can continue with the Bayesian treatment:\np(θ|y) = p(θ)p(y|θ) p(y) ≈ p(θ)\n∫ p (y|x)p(x|θ) dx∫\np(θ) ∫ p (y|x)p(x|θ) dx dθ\n(1)\nOf particular importance is the choice of kernel measuring the discrepancy between observations y and pseudo-data x. Popular choices for kernels are the Gaussian kernel and the uniform -tube/ball. The bandwidth parameter (which may be a vector accounting for relative importance of each statistic) plays critical role: small produces more accurate posteriors, but is more computationally demanding, whereas large induces larger error but is cheaper.\nWe focus our attention on population-based ABC samplers, which include rejection sampling, importance sampling (IS), sequential Monte Carlo (SMC) [6, 20] and population Monte Carlo [3]. In rejection sampling, we draw parameters from the prior θ ∼ p(θ), then run a simulation at those parameters x ∼ p(x|θ); if the discrepancy ρ(x,y) < , then the particle is accepted, otherwise it is rejected. This is repeated until n particles are accepted. Importance sampling generalizes rejection sampling using a proposal distribution qφ(θ) instead of the prior, and produces samples with weights wi ∝ p(θ)/q(θ). SMC extends IS to multiple rounds with decreasing , adapting their particles after each round, such that each new population improves the approximation to the posterior. Our algorithm has similar qualities to SMC since we generate a population of n weighted particles, but differs significantly since our particles are produced by independent optimization procedures, making it completely parallel."
    }, {
      "heading" : "3 A Parallel and Efficient ABC Sampling Algorithm",
      "text" : "Inherent in our assumptions about the simulator is that internally there are calls to a random number generator which produces the stochasticity of the pseudo-samples. We will assume for the moment that this can be represented by a vector of uniform random numbers u which, if known, would make the simulator deterministic. More concretely, we assume that any simulation output x can be represented as a deterministic function of parameters θ and a vector of random numbers u,\ni.e. x = f(θ,u). This assumption has been used previously in ABC, first in “coupled ABC” [16] and also in an application of Hamiltonian dynamics to ABC [15]. We do not make any further assumptions regardingu or p(u), though for some problems their dimension and distribution may be known a priori. In these cases it may be worth employing Sobol or other low-discrepancy sequences to further improve the accuracy of any Monte Carlo estimates.\nWe will first derive a dual representation for the ABC likelihood function p (y|θ) (see also [16]), p (y|θ) = ∫ p (y|x)p(x|θ) dx = ∫ ∫ p (y|x)I[x = f(θ,u)]p(u) dxdu (2)\n= ∫ p (y|f(θ,u))p(u) du (3)\nleading to the following Monte Carlo approximation of the ABC posterior, p (θ|y) ∝ p(θ) ∫ p(u)p (y|f(u,θ)) du ≈ 1\nn ∑ i p (y|f(ui,θ))p(θ) ui ∼ p(u) (4)\nSince p is a kernel that only accepts arguments y and f(ui,θ) that are close to each other (for values of that are as small as possible), Equation 4 tells us that we should first sample values for u from p(u) and then for each such sample find the value for θoi that results in y = f(θ o i ,u). In practice we want to drive these values as close to each other as possible through optimization and accept anO( ) error if the remaining distance is stillO( ). Note that apart from sampling the values for u this procedure is deterministic and can be executed completely in parallel, i.e. without any communication. In the following we will assume a single observation vector y, but the approach is equally applicable to a dataset of N cases."
    }, {
      "heading" : "3.1 The case Dθ = Dy",
      "text" : "We will first study the case when the number of parameters θ is equal to the number of summary statistics y. To understand the derivation it helps to look at Figure 1a which illustrates the derivation for the one dimensional case. In the following we use the following abbreviation: fi(θ) stands for f(θ,ui). The general idea is that we want to write the approximation to the posterior as a mixture of small uniform balls (or delta peaks in the limit):\np(θ|y) ≈ 1 n ∑ i p (y|f(ui,θ))p(θ) ≈ 1 n ∑ i wiU (θ|θ∗i )p(θ) (5)\nwith wi some weights that we will derive shortly. Then, if we make small enough we can replace any average of a sufficiently smooth function h(θ) w.r.t. this approximate posterior simply by evaluating h(θ) at some arbitrarily chosen points inside these balls (for instance we can take the center of the ball θ∗i ), ∫\nh(θ)p(θ|y) dθ ≈ 1 n ∑ i h(θ∗i )wip(θ ∗ i ) (6)\nTo derive this expression we first assume that:\np (y|fi(θ)) = C( )I[||y − fi(θ)||2 ≤ 2] (7)\ni.e. a ball of radius . C( ) is the normalizer which is immaterial because it cancels in the posterior. For small enough we claim that we can linearize fi(θ) around θoi :\nf̂i(θ) = fi(θ o i ) + J o i (θ − θoi ) +Ri, Ri = O(||θ − θoi ||2) (8)\nwhere Joi is the Jacobian matrix with columns ∂fi(θ\no i )\n∂θd . We take θoi to be the end result of our\noptimization procedure for sample ui. Using this we thus get,\n||y − fi(θ)||2 ≈ ||(y − fi(θoi ))− Joi (θ − θoi )−Ri||2 (9)\nWe first note that since we assume that our optimization has ended up somewhere inside the ball defined by ||y − fi(θ)||2 ≤ 2 we can assume that ||y − fi(θoi )|| = O( ). Also, since we only consider values for θ that satisfy ||y − fi(θ)||2 ≤ 2, and furthermore assume that the function fi(θ) is Lipschitz continuous in θ it follows that ||θ − θoi || = O( ) as well. All of this implies that we can safely ignore the remaining term Ri (which is of order O(||θ − θoi ||2) = O( 2)) if we restrict ourselves to the volume inside the ball.\nThe next step is to view the term I[||y − fi(θ)||2 ≤ 2] as a distribution in θ. With the Taylor expansion this results in,\nI[(θ − θoi − J o,−1 i (y − fi(θ o i ))) T JoTi J o i (θ − θoi − J o,−1 i (y − fi(θ o i ))) ≤ 2] (10)\nThis represents an ellipse in θ-space with a centroid θ∗i and volume Vi given by\nθ∗i = θ o i + J o,−1 i (y − fi(θ o i )) Vi = γ√ det(JoTi J o i )\n(11)\nwith γ a constant independent of i. We can approximate the posterior now as,\np(θ|y) ≈ 1 κ ∑ i U (θ|θ∗i )p(θ)√ det(JoTi J o i ) ≈ 1 κ ∑ i δ(θ − θ∗i )p(θ∗i )√ det(JoTi J o i )\n(12)\nwhere in the last step we have send → 0. Finally, we can compute the constant κ through normalization, κ = ∑ i p(θ ∗ i ) det(J oT i J o i ) −1/2. The whole procedure is accurate up to errors of the order O( 2), and it is assumed that the optimization procedure delivers a solution that is located within the epsilon ball. If one of the optimizations for a certain sample ui did not end up within the epsilon ball there can be two reasons: 1) the optimization did not converge to the optimal value for θ, or 2) for this value of u there is no solution for which f(θ|u) can get within a distance from the observation y. If we interpret as our uncertainty in the observation y, and we assume that our optimization succeeded in finding the best possible value for θ, then we should simply reject this sample θi. However, it is hard to detect if our optimization succeeded and we may therefore sometimes reject samples that should not have been rejected. Thus, one should be careful not to create a bias against samples ui for which the optimization is difficult. This situation is similar to a sampler that will not mix to remote local optima in the posterior distribution."
    }, {
      "heading" : "3.2 The case Dθ < Dy",
      "text" : "This is the overdetermined case and here the situation as depicted in Figure 1b is typical: the manifold that f(θ,ui) traces out as we vary θ forms a lower dimensional surface in the Dy dimensional enveloping space. This manifold may or may not intersect with the sphere centered at the observation y (or ellipsoid, for the general case instead of ). Assume that the manifold does intersect the\nepsilon ball but not y. Since we trust our observation up to distance , we may simple choose to pick the closest point θ∗i to y on the manifold, which is given by,\nθ∗i = θ o i + J o† i (y − fi(θ o i )) J o† i = (J oT i J o i ) −1JoTi (13)\nwhere Jo†i is the pseudo-inverse. We can now define our ellipse around this point, shifting the center of the ball from y to fi(θ∗i ) (which do not coincide in this case). The uniform distribution on the ellipse in θ-space is now defined in the Dθ dimensional manifold and has volume Vi = γ det(JoTi J o i ) −1/2. So once again we arrive at almost the same equation as before (Eq. 12) but with the slightly different definition of the point θ∗i given by Eq. 13. Crucially, since ||y − fi(θ∗i )|| ≤ 2 and if we assume that our optimization succeeded, we will only make mistakes of order O( 2)."
    }, {
      "heading" : "3.3 The case Dθ > Dy",
      "text" : "This is the underdetermined case in which it is typical that entire manifolds (e.g. hyperplanes) may be a solution to ||y − fi(θ∗i )|| = 0. In this case we can not approximate the posterior with a mixture of point masses and thus the procedure does not apply. However, the case Dθ > Dy is less interesting than the other ones above as we expect to have more summary statistics than parameters for most problems."
    }, {
      "heading" : "4 Experiments",
      "text" : "The goal of these experiments is to demonstrate 1) the correctness of OMC and 2) the relative efficiency of OMC in relation to two sequential MC algorithms, SMC (aka population MC [3]) and adaptive weighted SMC [5]. To demonstrate correctness, we show histograms of weighted samples along with the true posterior (when known) and, for three experiments, the exact OMC weighted samples (when the exact Jacobian and optimal θ is known). To demonstrate efficiency, we compute the mean simulations per sample (SS)—the number of simulations required to reach an threshold— and the effective sample size (ESS), defined as 1/wTw. Additionally, we may measure ESS/n, the fraction of effective samples in the population. ESS is a good way of detecting whether the posterior is dominated by a few particles and/or how many particles achieve discrepancy less than epsilon.\nThere are several algorithmic options for OMC. The most obvious is to spawn independent processes, draw u for each, and optimize until is reached (or a max nbr of simulations run), then compute Jacobians and particle weights. Variations could include keeping a sorted list of discrepancies and allocating computational resources to the worst particle. However, to compare OMC with SMC, in this paper we use a sequential version of OMC that mimics the epsilon rounds of SMC. Each simulator uses different optimization procedures, including Newton’s method for smooth simulators, and random walk optimization for others; Jacobians were computed using one-sided finite differences. To limit computational expense we placed a max of 1000 simulations per sample per round for all algorithms. Unless otherwise noted, we used n = 5000 and repeated runs 5 times; lack of error bars indicate very low deviations across runs. We also break some of the notational convention used thus far so that we can specify exactly how the random numbers translate into pseudo-data and the pseudo-data into statistics. This is clarified for each example. Results are explained in Figures 2 to 4."
    }, {
      "heading" : "4.1 Normal with Unknown Mean and Known Variance",
      "text" : "The simplest example is the inference of the mean θ of a univariate normal distribution with known variance σ2. The prior distribution π(θ) is normal with mean θ0 and variance kσ2, where k > 0 is a factor relating the dispersions of θ and the data yn. The simulator can generate data according to the normal distribution, or deterministically if the random effects rum are known: π(xm|θ) = N (xm|θ, σ2) =⇒ xm = θ + rum (14) where rum = σ √ 2 erf−1(2um−1) (using the inverse CDF). A sufficient statistic for this problem is\nthe average s(x) = 1M ∑ m xm. Therefore we have f(θ,u) = θ+R(u) where R(u) = ∑ rum/M (the average of the random effects). In our experiment we set M = 2 and y = 0. The exact Jacobian and θoi can be computed for this problem: for a draw ui, Ji = 1; if s(y) is the mean of the observations y, then by setting f(θoi ,ui) = s(y) we find θ o i = s(y) − R(ui). Therefore the exact weights are wi ∝ π(θoi ), allowing us to compare directly with an exact posterior based on our dual representation by u (shown by orange circles in Figure 2 top-left). We used Newton’s method to optimize each particle."
    }, {
      "heading" : "4.2 Normal Mixture",
      "text" : "A standard illustrative ABC problem is the inference of the mean θ of a mixture of two normals [19, 3, 5]: p(x|θ) = ρN (θ, σ21)+ (1− ρ)N (θ, σ22), with π(θ) = U(θa, θb) where hyperparameters are ρ = 1/2, σ21 = 1, σ 2 2 = 1/100, θa = −10, θb = 10, and a single observation scalar y = 0. For this problem M = 1 so we drop the subscript m. The true posterior is simply p(θ|y = 0) ∝ ρ N (θ, σ21) + (1− ρ) N (θ, σ22), θ ∈ {−10, 10}. In this problem there are two random numbers u1 and u2, one for selecting the mixture component and the other for the random innovation; further, the statistic is the identity, i.e. s(x) = x:\nx = [u1 < ρ](θ + σ1 √ 2 erf(2u2 − 1)) + [u1 ≥ ρ](θ + σ2 √ 2 erf(2u2 − 1)) (15)\n= θ + √ 2 erf(2u2 − 1)σ[u1<ρ]1 σ [u1≥ρ] 2 = θ +R(u) (16)\nwhere R(u) = √ 2 erf(2u2 − 1)σ[u1<ρ]1 σ [u1≥ρ] 2 . As with the previous example, the Jacobian is 1 and θoi = y − R(ui) is known exactly. This problem is notable for causing performance issues in ABC-MCMC [19] and its difficulty in targeting the tails of the posterior [3]; this is not the case for OMC."
    }, {
      "heading" : "4.3 Exponential with Unknown Rate",
      "text" : "In this example, the goal is to infer the rate θ of an exponential distribution, with a gamma prior p(θ) = Gamma(θ|α, β), based on M draws from Exp(θ):\np(xm|θ) = Exp(xm|θ) = θ exp(−θxm) =⇒ xm = − 1\nθ ln(1− um) =\n1 θ rum (17)\nwhere rum = − ln(1 − um) (the inverse CDF of the exponential). A sufficient statistic for this problem is the average s(x) = ∑ m xm/M . Again, we have exact expressions for the Jacobian and θoi , using f(θ,ui) = R(ui)/θ, Ji = −R(ui)/θ2 and θoi = R(ui)/s(y). We used M = 2, s(y) = 10 in our experiments."
    }, {
      "heading" : "4.4 Linked Mean and Variance of Normal",
      "text" : "In this example we link together the mean and variance of the data generating function as follows:\np(xm|θ) = N (xm|θ, θ2) =⇒ xm = θ + θ √ 2 erf−1(2um − 1) = θrum (18)\nwhere rum = 1+ √ 2 erf−1(2um−1). We put a positive constraint on θ: p(θ) = U(0, 10). We used 2 statistics, the mean and variance of M draws from the simulator:\ns1(x) = 1\nM xm =⇒ f1(θ,u) = θR(u)\n∂f1(θ,u)\n∂θ = R(u) (19)\ns2(x) = 1\nM ∑ m (xm − s1(x))2 =⇒ f2(θ,u) = θ2V (u) ∂f2(θ,u) ∂θ = 2θV (u) (20)\nwhere V (u) = ∑ m r 2 um/M − R(u) 2 and R(u) = ∑ m rum/M ; the exact Jacobian is therefore [R(u), 2θV (u)]T . In our experiments M = 10, s(y) = [2.7, 12.8]."
    }, {
      "heading" : "4.5 Lotka-Volterra",
      "text" : "The simplest Lotka-Volterra model explains predator-prey populations over time, controlled by a set of stochastic differential equations:\ndx1 dt = θ1x1 − θ2x1x2 + r1 dx2 dt = −θ2x2 − θ3x1x2 + r2 (21)\nwhere x1 and x2 are the prey and predator population sizes, respectively. Gaussian noise r ∼ N (0, 102) is added at each full time-step. Lognormal priors are placed over θ. The simulator runs for T = 50 time steps, with constant initial populations of 100 for both prey and predator. There is therefore P = 2T outputs (prey and predator populations concatenated), which we use as the statistics. To run a deterministic simulation, we draw ui ∼ π(u) where the dimension of u is P . Half of the random variables are used for r1 and the other half for r2. In other words, rust = 10 √ 2 erf−1(2ust − 1), where s ∈ {1, 2} for the appropriate population. The Jacobian is a 100×3 matrix that can be computed using one-sided finite-differences using 3 forward simulations."
    }, {
      "heading" : "4.6 Bayesian Inference of the M/G/1 Queue Model",
      "text" : "Bayesian inference of the M/G/1 queuing model is challenging, requiring ABC algorithms [4, 8] or sophisticated MCMC-based procedures [18]. Though simple to simulate, the output can be quite\nnoisy. In the M/G/1 queuing model, a single server processes arriving customers, which are then served within a random time. Customer m arrives at time wm ∼ Exp(θ3) after customer m−1, and is served in sm ∼ U(θ1, θ2) service time. Both wm and sm are unobserved; only the inter-departure times xm are observed. Following [18], we write the simulation algorithm in terms of arrival times vm. To simplify the updates, we keep track of the departure times dm. Initially, d0 = 0 and v0 = 0, followed by updates for m ≥ 1:\nvm = vm−1 + wm xm = sm +max(0, vm − dm−1) dm = dm−1 + xm (22)\nAfter trying several optimization procedures, we found the most reliable optimizer was simply a random walk. The random sources in the problem used for Wm (there are M ) and for Um (there are M ), therefore u is dimension 2M . Typical statistics for this problem are quantiles of x and/or the minimum and maximum values; in other words, the vector x is sorted then evenly spaced values for the statistics functions f (we used 3 quantiles). The Jacobian is anM×3 matrix. In our experiments θ∗ = [1.0, 5.0, 0.2]"
    }, {
      "heading" : "5 Conclusion",
      "text" : "We have presented Optimization Monte Carlo, a likelihood-free algorithm that, by controlling the simulator randomness, transforms traditional ABC inference into a set of optimization procedures. By using OMC, scientists can focus attention on finding a useful optimization procedure for their simulator, and then use OMC in parallel to generate samples independently. We have shown that OMC can also be very efficient, though this will depend on the quality of the optimization procedure applied to each problem. In our experiments, the simulators were cheap to run, allowing Jacobian computations using finite differences. We note that for high-dimensional input spaces and expensive simulators, this may be infeasible, solutions include randomized gradient estimates [22] or automatic differentiation (AD) libraries (e.g. [14]). Future work will include incorporating AD, improving efficiency using Sobol numbers (when the size u is known), incorporating Bayesian optimization, adding partial communication between processes, and inference for expensive simulators using gradient-based optimization."
    }, {
      "heading" : "Acknowledgments",
      "text" : "We thank the anonymous reviewers for the many useful comments that improved this manuscript. MW acknowledges support from Facebook, Google, and Yahoo."
    } ],
    "references" : [ {
      "title" : "Large scale distributed Bayesian matrix factorization using stochastic gradient MCMC",
      "author" : [ "S. Ahn", "A. Korattikara", "N. Liu", "S. Rajan", "M. Welling" ],
      "venue" : null,
      "citeRegEx" : "1",
      "shortCiteRegEx" : "1",
      "year" : 2015
    }, {
      "title" : "Distributed stochastic gradient MCMC",
      "author" : [ "S. Ahn", "B. Shahbaba", "M. Welling" ],
      "venue" : "In Proceedings of the 31st International Conference on Machine Learning",
      "citeRegEx" : "2",
      "shortCiteRegEx" : "2",
      "year" : 2014
    }, {
      "title" : "Adaptive approximate Bayesian computation",
      "author" : [ "M.A. Beaumont", "Cornuet", "J.-M", "Marin", "C.P. Robert" ],
      "venue" : null,
      "citeRegEx" : "3",
      "shortCiteRegEx" : "3",
      "year" : 2009
    }, {
      "title" : "Non-linear regression models for approximate Bayesian computation",
      "author" : [ "M.G. Blum", "O. François" ],
      "venue" : "Statistics and Computing,",
      "citeRegEx" : "4",
      "shortCiteRegEx" : "4",
      "year" : 2010
    }, {
      "title" : "Sequential Monte Carlo with adaptive weights for approximate Bayesian computation",
      "author" : [ "F.V. Bonassi", "M. West" ],
      "venue" : "Bayesian Analysis,",
      "citeRegEx" : "5",
      "shortCiteRegEx" : "5",
      "year" : 2015
    }, {
      "title" : "Sequential Monte Carlo samplers",
      "author" : [ "P. Del Moral", "A. Doucet", "A. Jasra" ],
      "venue" : "Journal of the Royal Statistical Society: Series B (Statistical Methodology),",
      "citeRegEx" : "6",
      "shortCiteRegEx" : "6",
      "year" : 2006
    }, {
      "title" : "Approximate Bayesian computation using indirect inference",
      "author" : [ "C.C. Drovandi", "A.N. Pettitt", "M.J. Faddy" ],
      "venue" : "Journal of the Royal Statistical Society: Series C (Applied Statistics),",
      "citeRegEx" : "7",
      "shortCiteRegEx" : "7",
      "year" : 2011
    }, {
      "title" : "Constructing summary statistics for approximate Bayesian computation: semi-automatic approximate Bayesian computation",
      "author" : [ "P. Fearnhead", "D. Prangle" ],
      "venue" : "Journal of the Royal Statistical Society: Series B (Statistical Methodology),",
      "citeRegEx" : "8",
      "shortCiteRegEx" : "8",
      "year" : 2012
    }, {
      "title" : "The ABC of simulation estimation with auxiliary statistics. arXiv preprint arXiv:1501.01265v2",
      "author" : [ "Forneron", "J.-J", "S. Ng" ],
      "venue" : null,
      "citeRegEx" : "9",
      "shortCiteRegEx" : "9",
      "year" : 2015
    }, {
      "title" : "A likelihood-free reverse sampler of the posterior distribution. arXiv preprint arXiv:1506.04017v1",
      "author" : [ "Forneron", "J.-J", "S. Ng" ],
      "venue" : null,
      "citeRegEx" : "10",
      "shortCiteRegEx" : "10",
      "year" : 2015
    }, {
      "title" : "Bayesian optimization for likelihood-free inference of simulator-based statistical models. Journal of Machine Learning Research, preprint arXiv:1501.03291",
      "author" : [ "M.U. Gutmann", "J. Corander" ],
      "venue" : null,
      "citeRegEx" : "12",
      "shortCiteRegEx" : "12",
      "year" : 2015
    }, {
      "title" : "Efficient global optimization of expensive black-box functions",
      "author" : [ "D.R. Jones", "M. Schonlau", "W.J. Welch" ],
      "venue" : "Journal of Global optimization,",
      "citeRegEx" : "13",
      "shortCiteRegEx" : "13",
      "year" : 1998
    }, {
      "title" : "Efficient likelihood-free Bayesian computation for household epidemics",
      "author" : [ "P. Neal" ],
      "venue" : "Statistical Computing,",
      "citeRegEx" : "16",
      "shortCiteRegEx" : "16",
      "year" : 2012
    }, {
      "title" : "Asynchronous anytime Sequential Monte Carlo",
      "author" : [ "B. Paige", "F. Wood", "A. Doucet", "Y.W. Teh" ],
      "venue" : "In Advances in Neural Information Processing Systems,",
      "citeRegEx" : "17",
      "shortCiteRegEx" : "17",
      "year" : 2014
    }, {
      "title" : "On Bayesian inference for the M/G/1 queue with efficient MCMC sampling",
      "author" : [ "A.Y. Shestopaloff", "R.M. Neal" ],
      "venue" : "Technical Report, Dept. of Statistics,",
      "citeRegEx" : "18",
      "shortCiteRegEx" : "18",
      "year" : 2013
    }, {
      "title" : "Sequential Monte Carlo without likelihoods",
      "author" : [ "S. Sisson", "Y. Fan", "M.M. Tanaka" ],
      "venue" : "Proceedings of the National Academy of Sciences,",
      "citeRegEx" : "19",
      "shortCiteRegEx" : "19",
      "year" : 2007
    }, {
      "title" : "Sequential Monte Carlo without likelihoods: Errata",
      "author" : [ "S. Sisson", "Y. Fan", "M.M. Tanaka" ],
      "venue" : "Proceedings of the National Academy of Sciences,",
      "citeRegEx" : "20",
      "shortCiteRegEx" : "20",
      "year" : 2009
    }, {
      "title" : "Practical Bayesian optimization of machine learning algorithms",
      "author" : [ "J. Snoek", "H. Larochelle", "R.P. Adams" ],
      "venue" : "Advances in Neural Information Processing Systems",
      "citeRegEx" : "21",
      "shortCiteRegEx" : "21",
      "year" : 2012
    }, {
      "title" : "Multivariate stochastic approximation using a simultaneous perturbation gradient approximation",
      "author" : [ "J.C. Spall" ],
      "venue" : "Automatic Control, IEEE Transactions on,",
      "citeRegEx" : "22",
      "shortCiteRegEx" : "22",
      "year" : 1992
    } ],
    "referenceMentions" : [ {
      "referenceID" : 1,
      "context" : "There has been considerable progress in distributed MCMC algorithms aimed at large-scale data problems [2, 1].",
      "startOffset" : 103,
      "endOffset" : 109
    }, {
      "referenceID" : 0,
      "context" : "There has been considerable progress in distributed MCMC algorithms aimed at large-scale data problems [2, 1].",
      "startOffset" : 103,
      "endOffset" : 109
    }, {
      "referenceID" : 13,
      "context" : "Recently, a sequential Monte Carlo (SMC) algorithm called “the particle cascade” was introduced that emits streams of samples asynchronously with minimal memory management and communication [17].",
      "startOffset" : 190,
      "endOffset" : 194
    }, {
      "referenceID" : 10,
      "context" : "Indeed, optimization as part of a likelihood-free inference procedure has recently been proposed [12]; using a probabilistic model of the mapping from parameters to differences between observations and simulator outputs, they apply “Bayesian Optimization” (e.",
      "startOffset" : 97,
      "endOffset" : 101
    }, {
      "referenceID" : 11,
      "context" : "[13, 21]) to efficiently perform posterior inference.",
      "startOffset" : 0,
      "endOffset" : 8
    }, {
      "referenceID" : 17,
      "context" : "[13, 21]) to efficiently perform posterior inference.",
      "startOffset" : 0,
      "endOffset" : 8
    }, {
      "referenceID" : 6,
      "context" : "Connections between ABC and indirect inference have been made previously by [7] as a novel way of creating summary statistics.",
      "startOffset" : 76,
      "endOffset" : 79
    }, {
      "referenceID" : 8,
      "context" : "An indirect inference perspective led to an independently developed version of OMC called the “reverse sampler” [9, 10].",
      "startOffset" : 112,
      "endOffset" : 119
    }, {
      "referenceID" : 9,
      "context" : "An indirect inference perspective led to an independently developed version of OMC called the “reverse sampler” [9, 10].",
      "startOffset" : 112,
      "endOffset" : 119
    }, {
      "referenceID" : 5,
      "context" : "We focus our attention on population-based ABC samplers, which include rejection sampling, importance sampling (IS), sequential Monte Carlo (SMC) [6, 20] and population Monte Carlo [3].",
      "startOffset" : 146,
      "endOffset" : 153
    }, {
      "referenceID" : 16,
      "context" : "We focus our attention on population-based ABC samplers, which include rejection sampling, importance sampling (IS), sequential Monte Carlo (SMC) [6, 20] and population Monte Carlo [3].",
      "startOffset" : 146,
      "endOffset" : 153
    }, {
      "referenceID" : 2,
      "context" : "We focus our attention on population-based ABC samplers, which include rejection sampling, importance sampling (IS), sequential Monte Carlo (SMC) [6, 20] and population Monte Carlo [3].",
      "startOffset" : 181,
      "endOffset" : 184
    }, {
      "referenceID" : 12,
      "context" : "This assumption has been used previously in ABC, first in “coupled ABC” [16] and also in an application of Hamiltonian dynamics to ABC [15].",
      "startOffset" : 72,
      "endOffset" : 76
    }, {
      "referenceID" : 12,
      "context" : "We will first derive a dual representation for the ABC likelihood function p (y|θ) (see also [16]),",
      "startOffset" : 93,
      "endOffset" : 97
    }, {
      "referenceID" : 2,
      "context" : "The goal of these experiments is to demonstrate 1) the correctness of OMC and 2) the relative efficiency of OMC in relation to two sequential MC algorithms, SMC (aka population MC [3]) and adaptive weighted SMC [5].",
      "startOffset" : 180,
      "endOffset" : 183
    }, {
      "referenceID" : 4,
      "context" : "The goal of these experiments is to demonstrate 1) the correctness of OMC and 2) the relative efficiency of OMC in relation to two sequential MC algorithms, SMC (aka population MC [3]) and adaptive weighted SMC [5].",
      "startOffset" : 211,
      "endOffset" : 214
    }, {
      "referenceID" : 15,
      "context" : "2 Normal Mixture A standard illustrative ABC problem is the inference of the mean θ of a mixture of two normals [19, 3, 5]: p(x|θ) = ρN (θ, σ 1)+ (1− ρ)N (θ, σ 2), with π(θ) = U(θa, θb) where hyperparameters are ρ = 1/2, σ 1 = 1, σ 2 2 = 1/100, θa = −10, θb = 10, and a single observation scalar y = 0.",
      "startOffset" : 112,
      "endOffset" : 122
    }, {
      "referenceID" : 2,
      "context" : "2 Normal Mixture A standard illustrative ABC problem is the inference of the mean θ of a mixture of two normals [19, 3, 5]: p(x|θ) = ρN (θ, σ 1)+ (1− ρ)N (θ, σ 2), with π(θ) = U(θa, θb) where hyperparameters are ρ = 1/2, σ 1 = 1, σ 2 2 = 1/100, θa = −10, θb = 10, and a single observation scalar y = 0.",
      "startOffset" : 112,
      "endOffset" : 122
    }, {
      "referenceID" : 4,
      "context" : "2 Normal Mixture A standard illustrative ABC problem is the inference of the mean θ of a mixture of two normals [19, 3, 5]: p(x|θ) = ρN (θ, σ 1)+ (1− ρ)N (θ, σ 2), with π(θ) = U(θa, θb) where hyperparameters are ρ = 1/2, σ 1 = 1, σ 2 2 = 1/100, θa = −10, θb = 10, and a single observation scalar y = 0.",
      "startOffset" : 112,
      "endOffset" : 122
    }, {
      "referenceID" : 15,
      "context" : "This problem is notable for causing performance issues in ABC-MCMC [19] and its difficulty in targeting the tails of the posterior [3]; this is not the case for OMC.",
      "startOffset" : 67,
      "endOffset" : 71
    }, {
      "referenceID" : 2,
      "context" : "This problem is notable for causing performance issues in ABC-MCMC [19] and its difficulty in targeting the tails of the posterior [3]; this is not the case for OMC.",
      "startOffset" : 131,
      "endOffset" : 134
    }, {
      "referenceID" : 3,
      "context" : "6 Bayesian Inference of the M/G/1 Queue Model Bayesian inference of the M/G/1 queuing model is challenging, requiring ABC algorithms [4, 8] or sophisticated MCMC-based procedures [18].",
      "startOffset" : 133,
      "endOffset" : 139
    }, {
      "referenceID" : 7,
      "context" : "6 Bayesian Inference of the M/G/1 Queue Model Bayesian inference of the M/G/1 queuing model is challenging, requiring ABC algorithms [4, 8] or sophisticated MCMC-based procedures [18].",
      "startOffset" : 133,
      "endOffset" : 139
    }, {
      "referenceID" : 14,
      "context" : "6 Bayesian Inference of the M/G/1 Queue Model Bayesian inference of the M/G/1 queuing model is challenging, requiring ABC algorithms [4, 8] or sophisticated MCMC-based procedures [18].",
      "startOffset" : 179,
      "endOffset" : 183
    }, {
      "referenceID" : 14,
      "context" : "Following [18], we write the simulation algorithm in terms of arrival times vm.",
      "startOffset" : 10,
      "endOffset" : 14
    }, {
      "referenceID" : 18,
      "context" : "We note that for high-dimensional input spaces and expensive simulators, this may be infeasible, solutions include randomized gradient estimates [22] or automatic differentiation (AD) libraries (e.",
      "startOffset" : 145,
      "endOffset" : 149
    } ],
    "year" : 2015,
    "abstractText" : "We describe an embarrassingly parallel, anytime Monte Carlo method for likelihood-free models. The algorithm starts with the view that the stochasticity of the pseudo-samples generated by the simulator can be controlled externally by a vector of random numbers u, in such a way that the outcome, knowing u, is deterministic. For each instantiation of u we run an optimization procedure to minimize the distance between summary statistics of the simulator and the data. After reweighing these samples using the prior and the Jacobian (accounting for the change of volume in transforming from the space of summary statistics to the space of parameters) we show that this weighted ensemble represents a Monte Carlo estimate of the posterior distribution. The procedure can be run embarrassingly parallel (each node handling one sample) and anytime (by allocating resources to the worst performing sample). The procedure is validated on six experiments.",
    "creator" : "LaTeX with hyperref package"
  }
}