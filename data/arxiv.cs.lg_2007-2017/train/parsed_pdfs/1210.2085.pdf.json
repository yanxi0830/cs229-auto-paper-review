{
  "name" : "1210.2085.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "Privacy Aware Learning",
    "authors" : [ "John C. Duchi", "Michael I. Jordan", "Martin J. Wainwright" ],
    "emails" : [ "jduchi@eecs.berkeley.edu", "jordan@eecs.berkeley.edu", "wainwrig@eecs.berkeley.edu" ],
    "sections" : [ {
      "heading" : null,
      "text" : "ar X\niv :1\n21 0.\n20 85\nv2 [\nst at\n.M L\n] 1\n0 O\nct 2"
    }, {
      "heading" : "1 Introduction",
      "text" : "Natural tensions between learning and privacy arise whenever a learner must aggregate data across multiple individuals. The learner wishes to make optimal use of each data point, whereas the providers of the data may wish to limit detailed exposure, either to the learner or to other individuals. A characterization of such tensions in the form of quantitative tradeoffs is of great utility: it can inform public discourse surrounding the design of systems that learn from data, and the tradeoffs can be exploited as controllable degrees of freedom whenever such a system is deployed.\nIn this paper, we approach this problem from the point of view of statistical decision theory. The decision-theoretic perspective offers a number of advantages. First, the use of loss functions and risk functions provides a compelling formal foundation for defining “learning”, one that dates back to Wald [46], and that has seen continued development in the context of research on machine learning over the past two decades. Second, by formulating the goals of a learning system in terms of loss functions, we make it possible for individuals to assess whether the goals of a learning system align with their own personal utility, and thereby determine the extent to which they are willing to sacrifice some privacy. Third, an appeal to decision theory permits abstraction over the details of specific learning procedures, allowing for the derivation of minimax lower bounds that apply to any specific procedure. Fourth, the use of loss functions—and more specifically, convex loss functions—in the design of a learning system allows the powerful tools of optimization theory to be brought to bear. Not only are optimization-based learning systems often successful in practice, but they are also often amenable to theoretical analysis. Finally, the decision-theoretic framework is a probabilistic framework, with probabilistic models definining the transformation from losses to risks. This connection provides a natural mechanism for the use of randomization to provide control over privacy.\nIn more formal detail, the analysis of this paper takes place within the following framework. Given a compact convex set Θ ⊂ Rd, we wish to find a parameter value θ ∈ Θ achieving good\naverage performance under a loss function ℓ : X × Rd → R+. Here the value ℓ(X, θ) measures the performance of the parameter vector θ ∈ Θ on the sample X ∈ X , and ℓ(x, ·) : Rd → R+ is convex for x ∈ X . We measure the expected performance of θ ∈ Θ via the risk function\nθ 7→ R(θ) := EP [ℓ(X, θ)], (1)\nwhere the expectation is taken over some unknown distribution P over the space X . In the standard formulation of statistical risk minimization, a method M is given n samples X1, . . . ,Xn, each drawn independently from P , and its goal to to output an estimate θ̂n that approximately minimizes the risk function R. In this paper, instead of providing the method M with access to the samples X1, . . . ,Xn, however, we study the effect of giving only some disguised view Zi of each datum Xi. With θ̂n now denoting an estimator based on the perturbed samples Zi, we explicitly quantify the rate of convergence of R(θ̂n) to infθ∈ΘR(θ) as a function of the number of samples n and the amount of privacy provided by Zi."
    }, {
      "heading" : "1.1 Prior work",
      "text" : "There is a long history of research at the intersection of privacy and statistics, going back at least to the 1960s, when Warner [47] suggested privacy-preserving methods for survey sampling, and to later work related to census taking and presentation of tabular data (e.g., [20]). More recently, there has been a large amount of computationally-oriented work on privacy [17, 15, 51, 48, 24, 11, 5, 7, 42]. We overview some of the key ideas in this section, but cannot hope to do justice to the large body of relevant work, referring the reader to the comprehensive survey by Dwork [15] and the statistical treatment by Wasserman and Zhou [48] for background and references.\nMost work on privacy attempts to limit disclosure risk: the probability that some adversary can link a released record to a particular member of the population or identify that someone belongs to a dataset that generates a statistic [13, 14, 41, 28]. In the statistical literature, work on disclosure limitation and so-called linkage risk, for example as in the framework of Duncan and Lambert [13], has yielded several techniques for maintaining privacy, such as aggregation, swapping features or responses among different datums, or perturbation of data. Other authors have proposed measures for measuring utility of released data (e.g., [28, 9]). The currently standard measure of privacy is differential privacy, due to Dwork et al. [17], which roughly states that θ̂n must not depend too much on the n samples, and it should be difficult to ascertain whether a vector x belongs to the set {X1, . . . ,Xn} given θ̂n. Formally, paraphrasing the definition of Wasserman and Zhou [48], the method M has α-differential privacy if\nsup S∈σ(Θ) sup x1,...,xn sup x′ 1 ,...,x′n Q(S | X1 = x1, . . . ,Xn = xn) Q(S | X1 = x′1, . . . ,Xn = x′n) ≤ exp(α). (2)\nwhere the sets x1, . . . , xn and x ′ 1, . . . , x ′ n differ in at most one element, Q(· | X1, . . . ,Xn) is (a version of) the conditional probability of the estimator θ̂ constructed by the method M using the n samples, and σ(Θ) is a suitable σ-algebra on Θ.\nDifferentially private algorithms enjoy many desirable properties [17, 15, 21] and essentially guarantee that even if an adversary knows all the entries in a dataset but the nth, it is difficult to discern whether a vector x is equal to Xn given the output of the method M. Indeed, differential privacy protects against side information and many adversarial attacks that break previous definitions of privacy, such as k-anonymity [21]. Several researchers have studied differentially private\nalgorithms for empirical risk minimization, providing guarantees on the excess risk of differentially private estimators θ̂. Chaudhuri et al. [7] use the stability of the output of regularized empirical risk minimization algorithms to show that by adding Laplace-distributed noise to an empirical estimator θ or by adding an additional random term to the empirical risk 1n ∑n i=1 ℓ(Xi, θ), it is possible to obtain differential privacy and consistency of θ̂. Dwork and Lei [16] obtain similar results using robust statistical estimators, and Smith [44] shows that if one has suitably unbiased estimators, then differential privacy is possible without compromising asymptotic rates of convergence. Rubinstein et al. [42] use similar stability and perturbation techniques to demonstrate that it is possible to obtain differential privacy when solving support vector machine problems, and also show that if the desired privacy level α in the definition (2) is too small, it is actually impossible to obtain a parameter θ̂n minimizing the risk R.\nOur goal is to understand the fundamental tradeoffs between maintaining privacy while still providing a useful output from the statistical learning procedure M. Though intuitively there must be some tradeoff, quantifying it precisely has been difficult. As alluded to above, Rubinstein et al. [42] are able to show that it is impossible to obtain what they call an (ǫ, δ)-useful parameter vector θ that enjoys any differential privacy guarantees; however, it is unknown whether or not their guarantees might be improvable. Hall et al. [24] show that if a given histogram, based on a sample {xi}ni=1, has d bins and we must guarantee α-differential privacy (2), then the (expected) L1-distance between the sample and released histograms must be at least d/(nα), and Hardt and Talwar [25] give similar lower bounds on the amount of noise necessary to answer linear database queries. Nikolov et al. [38] followed this work with extensions to relaxed notions (so called (α, δ)-approximate differential privacy) of privacy and providing higher-dimensional settings, while Kasiviswanathan et al. [30] give bounds on amounts of additive noise to protect against blatant failures of privacy in similar linear settings. Blum et al. [5] also give lower bounds on the closeness of certain statistical quantities computed from the dataset, though their upper and lower bounds do not match. Sankar et al. [43] provide rate-distortion theorems for utility models involving information-theoretic quantities, which has some similarity to our risk-based framework, but it appears somewhat challenging to explicitly map their setting onto ours. With the goal of characterizing what it means to be both useful and private, Ghosh et al. [22] show that for a one-time computation of counts on a dataset X1, . . . ,Xn (i.e., the number of variables satisfying Xi ∈ C for some set C), perturbing the output of a counting function using geometrically distributed noise is the unique optimal way to guarantee differential privacy while maximizing a natural notion of utility.\nMuch of the work providing sharp lower bounds, however, focuses on showing that if one wishes to accurately report a statistic θ̂(x1:n) computed on a sample {xi}ni=1, then there must be some worst-case sample such that the error is large (see, e.g., [25, 24, 38, 22]). In contrast, we focus on population quantities—which are substantially different—in that we wish to return a private estimator θ̂n approximately minimizing the population risk R(θ) = E[ℓ(X, θ)] rather than the sample risk 1n ∑n i=1 ℓ(Xi, θ). Providing guarantees on the population risk performance of θ̂n, rather than on the observed sample, has been a driving force behind much of the theoretical work in statistics and machine learning, and thus provides a natural focus for our work."
    }, {
      "heading" : "1.2 Our setting",
      "text" : "In contrast to the above work, we study a more local notion of privacy [19, 29], in which each datum Xi is kept private from the method M. The goal of many types of privacy is to guarantee that the output θ̂n of the method M based on the data cannot be used to discover information about the\nindividual samples X1, . . . ,Xn, but locally private algorithms only access disguised views of each datum Xi. Local algorithms are among the most classical approaches to privacy, tracing back to work on randomized response in the statistical literature [47], and rely on communication only of some disguised view Zi of each true sample Xi. In this setting, for example, the natural variant of α-differential privacy (2) is the non-interactive (in the sense that Zi depends only on Xi and not on any other private variables Zj) local privacy guarantee\nsup S sup x,x′ Q(Zi ∈ S | Xi = x) Q(Zi ∈ S | Xi = x′) ≤ exp(α). (3)\nLocally private algorithms are natural when the providers of the data—the population sampled to give X1, . . . ,Xn—do not even trust the statistician or statistical method M, but the providers are interested in the parameter vector θ∗ that minimizes the risk function. For example, in medical applications, a participant may be embarrassed about his use of drugs, or perhaps about his marital status, but if the loss ℓ is able to measure the likelihood of developing cancer, then the participant has high utility for access to the optimal parameters θ∗. Internet applications, where a user’s activity is logged across multiple websites or searches, provide another example: the user has a utility for a search engine to have a ranking function θ that returns relevant results for web searches, yet may not wish to reveal his or her search data. In essence, we would like the statistical procedure M to learn from the data X1, . . . ,Xn but not about it.\nThe work most related to ours seems to be that of Kasiviswanathan et al. [29], who show that that (in some settings) locally private algorithms coincide with concepts that can be learned with polynomial sample complexity in Kearns’s statistical query (SQ) model [31]. This result is powerful, but has some limitations, as the statistical query model relies exclusively on count queries, and we are interested in measures more precise than polynomial sample complexity to quantity convergence rates. In contrast, our analysis applies to estimators deriving from a broad class of convex risks (1), and it provides sharp rates of convergence.\nWe develop our approach to local privacy in the setting of three related privacy measures. The first is a worst-case measure of mutual information, where we view privacy preservation as a game between the providers of the data, who wish to preserve privacy, and nature. The second is based on differential privacy, where the provider of each datum communicates—subject to some constraints we make explicit later—the most differentially private view Zi of his or her datum Xi. In this general setting we allow interactivity (i.e., the mapping between Zi and Xi may depend on other Zj for j 6= i). The third setting is a non-interactive version of local differential privacy.\nTurning first to the information-theoretic formulation, and recalling that the method M sees only the perturbed version Zi of Xi, we use a uniform variant of mutual information I(Zi;Xi) between the random variables Xi and Zi as a measure for privacy. Using mutual information and related information-theoretic ideas in the privacy and security context is by no means original; see, for example, the survey by Liang et al. [34]. It is important to note, however, that standard mutual information has deficiencies as a measure of privacy (e.g. [19]). Accordingly, our uniform notion of mutual information is as follows: we say that the distribution Q generating Z from X is private only if I(X;Z) is small for all possible distributions P on X, possibly subject to some constraints.\nIn this setting, we design procedures that allow consistent estimation of the parameter θ∗ minimizing R(θ) = EP [ℓ(X, θ)], for any convex loss ℓ and distribution P on the data X. One\ncentral consequence of our analysis is a sharp characterization of the excess risk,\n∆n(θ̂; ℓ,Θ) := E [ R ( θ̂(Z1, . . . , Zn) )] − inf\nθ∈Θ R(θ), (4)\nassociated with any estimator θ̂ that satisfies a pre-specified privacy constraint. For particular collections L of loss functions ℓ ∈ L, we bound the minimax convergence rate of all estimation procedures. More precisely, let us focus on d-dimensional problems, i.e., those for which the domain Θ ⊂ Rd and observations Xi ∈ Rd. If one wishes to uniformly guarantee a level of privacy I(Xi;Zi) ≤ I∗, then we show that there exists a constant a(L,Θ) ∈ R+—dependent only on the properties of the collection L and domain Θ—such that for any estimator θ̂ for the family L, the excess risk is lower bounded as\nsup ℓ∈L ∆n(θ̂; ℓ,Θ) ≥ √ d√ I∗ a(L,Θ)√ n , (5a)\nwhere a(L,Θ) is a constant characterizing the non-private minimax rate of estimation (see, e.g., Agarwal et al. [1] for such constants). Moreover, we also prove that there exists another constant b(L,Θ) ≥ a(L,Θ) and provide explicit estimators θ̂ with privacy guarantee I∗ such that\nsup ℓ∈L ∆n(θ̂; ℓ,Θ) ≤ √ d√ I∗ b(L,Θ)√ n . (5b)\nTurning to the setting of differential privacy, we are able to show similar results to the bounds (5a) and (5b). Namely, there exist constants b′(L,Θ) ≥ a′(L,Θ) such that if we wish to guarantee αdifferential privacy, then for any estimator θ̂, the risk is lower bounded by\nsup ℓ∈L\n∆n(θ̂; ℓ,Θ) ≥ √ d\nα a′(L,Θ)√ n , (6a)\nwhile there exist estimators θ̂ such that\nsup ℓ∈L\n∆n(θ̂; ℓ,Θ) ≤ √ d\nα b′(L,Θ)√ n . (6b)\nHere again, the constant a′(L,Θ) controls the non-private minimax rate of estimation. Finally, we show that stochastic gradient descent is one procedure that achieves the above upper bounds, and moreover, that the ratios b(L,Θ)/a(L,Θ) and b′(L,Θ)/a′(L,Θ) are bounded above by a universal (numerical) constant. The bounds (5) and (6) thus establish and quantify explicitly the sharp tradeoff between learning and statistical estimation and the amount of privacy provided to the population. More concretely, we can evaluate the effective sample size of learning procedures receiving private observations. In the case of information-based privacy, the sample size of any learning procedure receiving maximally privatized observations from the data providers is decreased from n to roughly nI∗/d, while in differentially private settings, we see that the effective sample size decreases from n to nα2/d. The first of these is perhaps intuitive: in rough terms, a d-dimensional observation Xi contains about d-bits of information, and so we expect a loss in (statistical) efficiency by a factor I∗/d. For the second, recent results suggest scalings of I∗ ≈ α2 (e.g. [18, Lemma 3.2]), so the loss n 7→ nα2/d is also perhaps intuitive.\nOur subsequent analysis will build on this favorable property of gradient-based methods. Indeed, in the remainder of the paper, we will assume that the communication protocol—except in the noninteractive α-differentially private case, which allows any protocol—by which data is conveyed to the learner M is based on (sub)gradients of the loss. As further motivation for this choice, note that the subgradient (more generally, a score function) of the loss ℓ is asymptotically sufficient in the sense of Le Cam [32]. A bit more precisely, gradients (in an asymptotic sense) contain all of the statistical information for risk minimization problems. Secondly, estimation procedures based on stochastic gradient information are asymptotically efficient [40], in the sense of both Bahadur and minimax efficiency [45, Chapter 8], and are thus essentially sample optimal; they also have minimaxoptimality guarantees in finite-sample settings [1]. Moreover, many estimation procedures are gradient-based [36, 6], and distributed optimization procedures that send subgradient information across a network to a centralized procedure M are natural (e.g. [3]). Our arguments also show that in many settings, disguising subgradients is equivalent to disguising the data X itself. Thus, as an additional consequence of our gradient-based focus, our algorithmic bounds also apply in streaming and online settings, requiring only a fixed-size memory footprint."
    }, {
      "heading" : "1.3 Outline and techniques",
      "text" : "We spend the remainder of the paper deriving the bounds (5) and (6). Our route to obtaining these bounds is based on a two-part analysis. First, we consider saddle points of the mutual information I(X;Z), when viewed as a function of the distribution P of X and the conditional distribution Q(· | X) of Z, under natural constraints that still allow estimation. We consider related saddle points for differentially private conditional distributions. Having computed these saddle points, we can apply information-theoretic techniques for obtaining lower bounds on estimation and optimization [49, 1] to prove the results of the form (5a) or (6a). Our upper bounds then follow by application of known convergence rates for computationally efficient methods, such as the stochastic gradient and mirror descent algorithms [36, 37]. We provide full proofs—except for technical results deferred to appendices—and a more complete outline of our technique in Section 5.\nThe remainder of the paper is organized as follows. We give a precise definition of our notions of local privacy in Section 2. Section 3 is devoted to information-theoretic lower bounds on the convergence rate of any statistical method M in terms of the mutual information I∗ between what the method M observes and each sample Xi. We characterize the unique privacy guaranteeing distributions in Section 4, which provides a constructive mechanism for trading off privacy and learning. We present our conclusions in Section 6.\nNotation Before continuing, we give our notation and a few standard definitions. The KullbackLeibler (KL) divergence between distributions P and Q defined on a set S, where P and Q are assumed to have densities p and q with respect to a base measure ν1 is given by\nDkl (P‖Q) := ∫\nS p(s) log\np(s) q(s) dν(s).\nSimilarly, the total-variation distance between the distributions P and Q is defined as\n‖P −Q‖TV := sup A⊂S |P (A)−Q(A)| = 1 2\n∫\nS |p(s)− q(s)|dν(s).\n1This is no loss of generality, as P and Q are absolutely continuous with respect to ν = 1 2 (P +Q).\nFor a convex function f : Rd → R ∪ {+∞}, the subgradient set ∂f(θ) of f at the point θ is\n∂f(θ) := { g ∈ Rd : f(θ′) ≥ f(θ) + g⊤(θ′ − θ), for all θ′ ∈ Rd } .\nWe use ∂ℓ(x, θ) to denote the subgradient set of the function θ 7→ ℓ(x, θ), and for a convex function, ∇ℓ(x, θ) denotes an arbitrary element of ∂ℓ(x, θ). We say that a function f is L-Lipschitz with respect to the norm ‖·‖ over the set Θ if\n∣∣f(θ)− f(θ′) ∣∣ ≤ L ∥∥θ − θ′ ∥∥ for all θ, θ′ ∈ Θ.\nThe notation ‖·‖p denotes a standard ℓp-norm. We use the abbreviation r.c.d. throughout for regular conditional distribution [4]. The extreme points of a set C ⊂ Rd are denoted by Ext(C), the convex hull of C is denoted by Conv(C), and the support of a distribution P is denoted suppP . We say values an ≍ bn if limn(an/bn) = 1. The symbol ei denotes the ith standard basis vector in R d. Lastly, the symbol ⇒ denotes a set-valued mapping [26]."
    }, {
      "heading" : "2 Problem Formulation",
      "text" : "We begin with a formal description of the communication protocol by which information about the random variables X is communicated to the procedure M. We then define the notion of optimal local privacy studied in this paper and the minimax framework in which we state our main results."
    }, {
      "heading" : "2.1 Communication protocol",
      "text" : "In this paper, we focus on statistical learning procedures that have access to data through the subgradients ∂ℓ(X, θ) of the loss functions. More formally, at each round, the method M is given access to a random vector Zi such that\nE[Zi | Xi, θ] ∈ ∂ℓ(Xi, θ), (7)\nwhere θ ∈ Θ is a parameter chosen by the method. In Appendix A we present an argument that shows that the unbiasedness of the subgradient inclusion (7) is not only intuitively appealing but is, in a certain sense, necessary. In detail, our communication protocol consists of the following three steps:\n• the method M sends the parameter vector θ to the owner of the ith sample Xi;\n• owner i computes a subgradient vector g ∈ ∂ℓ(Xi, θ) to be communicated privately;\n• the vector Zi is communicated to M under the constraint that\nE[Zi | Xi, θ] = g ∈ ∂ℓ(Xi, θ).\nWe assume throughout that there is a compact set C ⊂ Rd such that ∂ℓ(x, θ) ⊆ C for all pairs (θ, x) ∈ Θ× X . Our goal is “disguise” the subgradient information with a random variable Z satisfying Z ∈ D, for some compact set D such that C ⊂ intD ⊂ Rd. For instance, a common choice of these sets are norm balls, say of the form\nC = {g ∈ Rd : ‖g‖ ≤ L}, and D = {g ∈ Rd : ‖g‖ ≤ M},\nwhere ‖·‖ is a given norm on Rd, and the radius choice M > L ensures that C ⊂ intD. This choice covers a variety of online optimization and stochastic approximation algorithms [53, 2, 37, 1], for which it is assumed that for any x ∈ X and θ ∈ Θ, if g ∈ ∂ℓ(x, θ) then ‖g‖ ≤ L for some norm ‖·‖. We may obtain privacy by allowing perturbation of the subgradient g, which is then required to live in a (larger) norm ball of radius M > L."
    }, {
      "heading" : "2.2 Optimal local privacy",
      "text" : "Suppose that X has distribution P , and for each x ∈ X , let Q(· | x) denote the regular conditional probability measure of Z given that X = x. This pair defines the marginal distribution Q(·) via Q(A) = E[Q(A | X)], where the expectation taken with respect to X ∼ P . The mutual information between X and Z is the expected Kullback-Leibler (KL) divergence between Q(· | X) and Q(·):\nI(P,Q) = I(X;Z) := EP [Dkl (Q(· | X)‖Q(·))] . (8)\nWe view the problem of privacy as a game between the adversary controlling P and the data owners, who use Q to obscure the samples X. In particular, we say a distribution Q guarantees a level of privacy I∗ if and only if supP I(P,Q) ≤ I∗. Note that this guarantee is worst-case, ensuring that for any choice of distribution P , the publicly available random variable Z provides at most mutual information I∗ about the sample X.\nOur goal is to find a saddle point P ∗, Q∗ such that\nsup P I(P,Q∗) ≤ I(P ∗, Q∗) ≤ inf Q I(P ∗, Q), (9)\nwhere the first supremum is taken over all distributions P on X such that ∇ℓ(X, θ) ∈ C with P -probability 1, and the infimum is taken over all regular conditional distributions Q such that if Z ∼ Q(· | X) (meaning that Z is drawn from Q conditional on X), then Z ∈ D and EQ[Z | X, θ] = ∇ℓ(X, θ). Indeed, if we can find P ∗ and Q∗ satisfying the saddle point (9), then combination with the trivial direction of the max-min inequality yields\nsup P inf Q I(P,Q) = I(P ∗, Q∗) = inf Q sup P I(P,Q).\nTo fully formalize this idea and our notions of privacy, we define two collections of probability measures and associated losses. For sets C ⊂ D ⊂ Rd, we define the source set\nP (C) := {Distributions P such that suppP ⊂ C} (10a)\nand the set of communicating distributions as the following regular conditional distributions (r.c.d.’s):\nQ (C,D) := { r.c.d.’s Q s.t. suppQ(· | c) ⊂ D and ∫\nD zdQ(z | c) = c for c ∈ C\n} . (10b)\nThe definitions (10a) and (10b) formally define the sets over which we may take infima and suprema in the saddle point calculations, and they capture what may be communicated. The conditional distributions Q ∈ Q (C,D) are defined so that for any loss ℓ with ∇ℓ(x, θ) ∈ C, we have\nEQ[Z | X = x, θ] := ∫\nD zdQ (z | ∇ℓ(x, θ)) = ∇ℓ(x, θ).\nWe now make the following key definition:\nDefinition 1. The conditional distributionQ∗ satisfies optimal local privacy for the sets C ⊂ D ⊂ Rd if\nsup P I(P,Q∗) = inf Q sup P I(P,Q)\nwhere the supremum is taken over distributions P ∈ P (C) and the infimum is taken over regular conditional distributions Q ∈ Q (C,D). We say Q∗ satisfies optimal local privacy at level I∗ if in addition supP I(P,Q ∗) = I∗.\nWe also formulate a corresponding notion of local optimality in the differentially private setting. For given sets C ⊂ D, define the differential privacy measure\nα⋆(C,D) := inf Q log\n[ sup\nS∈σ(D) sup x,x′∈C Q(S | X = x) Q(S | X = x′)\n] , (11)\nwhere the infimum is taken over all regular conditional distributions Q ∈ Q (C,D) such that EQ[Z | X = x] = x. We define optimal local differential privacy as follows:\nDefinition 2. The conditional distribution Q∗ satisfies optimal local differential privacy for the sets C ⊂ D ⊂ Rd if Q∗ ∈ Q (C,D) and\n1. The distribution Q∗ is α⋆(C,D)-differentially private.\n2. We have supP I(P,Q ∗) ≤ supP I(P,Q), for all α⋆(C,D)-differentially private Q ∈ Q (C,D),\nwhere the supremum is taken over all distributions P ∈ P (C).\nIf a distribution Q∗ satisfies optimal local privacy or optimal local differential privacy, then it guarantees that even for the worst possible distribution on X, the information communicated about X is limited. (Part of our results consist in showing that for suitable sets C ⊂ D, it is possible to attain α⋆(C,D), so it is sensible to, in addition, choose the distribution that minimizes mutual information.)\nIn a sense, Definitions 1 and 2 capture the natural competition between privacy and learnability. The method M specifies the set D to which the data Z it receives must belong; the “teachers,” or owners of the data X, choose the distribution Q to guarantee as much privacy as possible subject to this constraint. Using these mechanisms, if we can characterize a unique distribution Q∗ attaining the infimum (9) for P ∗ (and by extension, for any P ), then we may study the effects of requiring a bounded amount of information to be communicated to the method M about X, which we do in Section 3."
    }, {
      "heading" : "2.3 Minimax error",
      "text" : "Given an estimate θ̂ based on n samples X from a distribution P , we assess its quality in terms of the risk function (1), i.e. R(θ) = E[ℓ(X, θ)]. In this section, we describe the minimax framework for obtaining bounds uniformly over all possible estimators. Let M denote any statistical procedure or method that operates on stochastic gradient samples, and let θ̂n denote the output of M after receiving n such samples. The excess risk of the method M on the risk R(θ) after receiving n sample gradients is\nǫn(M, ℓ,Θ, P ) := R(θ̂n)− inf θ∈Θ R(θ) = EP [ℓ(X, θ̂n)]− inf θ∈Θ EP [ℓ(X, θ)]. (12)\nThe excess risk is a random variable, since the output θ̂n of the method is random. In our settings, in addition to the randomness in the sampling distribution P , there is additional randomness from the perturbation applied to stochastic gradients of the objective ℓ(X, ·) to mask X from the statistitician or method M. Let Q denote the regular conditional probability—the channel distribution—whose conditional part is defined on the range of the (set-valued) subgradient mapping ∂ℓ(X, ·) : Θ ⇒ Rd. Since the output θ̂n of the statistical procedureM is a random function of both P and Q, we take the expectation and measure the expected sub-optimality of the risk according to P and Q. We let L denote a collection of loss functions, where for a distribution P on X , the set L(P ) denotes the losses ℓ : suppP ×Θ → R+ belonging to L. The minimax error is then given by\nǫ∗n(L,Θ) := inf M sup P sup ℓ∈L(P ) EP,Q[ǫn(M, ℓ,Θ, P )], (13)\nwhere the expectation is taken over the random samples X ∼ P and Z ∼ Q(· | X, θ). In this paper, we provide characterizations of the minimax error (13) for several classes of loss functions L(P ), giving sharp results when the privacy distribution Q satisfies optimal local privacy for any loss function ℓ ∈ L(P ) and distribution P ."
    }, {
      "heading" : "3 Optimal Learning Rates and Tradeoffs",
      "text" : "With the basic framework in place, we now turn to statements of our main results. We begin by imposing certain (weak) conditions on the families of loss functions that we consider, and subsequently turn to the main results of this section (Theorems 1 and 2, which apply to informationbased privacy, and Theorems 3–5, which apply to α-differential privacy) as well as some of their consequences (Corollaries 1, 2, and 3). After describing the optimal privacy-preserving distributions in Section 4, we provide proofs of the results in this section in Section 5."
    }, {
      "heading" : "3.1 Families of loss functions and stochastic gradient methods",
      "text" : "We assume that our collection of loss functions obey certain natural smoothness conditions. For each p ∈ [1,∞], we use ‖·‖p to denote the usual ℓp-norm, and we use q = pp−1 to denote the conjugate exponent satisfying the relation 1/p+1/q = 1. With this notation, we have the following definition:\nDefinition 3. For parameters L > 0 and p ≥ 1, an (L, p)-loss function is a measurable function ℓ : X ×Θ → R such that for x ∈ X , the function θ 7→ ℓ(x, θ) is convex and L-Lipschitz continuous with respect to the norm ‖·‖q. A convex loss ℓ satisfies Definition 3 if and only if for all θ ∈ Θ, we have the inequality ‖g‖p ≤ L for any subgradient g ∈ ∂ℓ(x, θ) (e.g. [26]).\nTo illustrate this definition, let us consider a few examples:\nExample 1. Consider the problem of finding a multi-dimensional median, in which case each sample x ∈ Rd, and the loss function takes the form\nℓ(x, θ) = L ‖θ − x‖1 . This loss is L-Lipschitz with respect to the ℓ1-norm, subgradients belonging to [−L,L]d, and hence it belongs to the class of (L,∞)-loss functions.\nExample 2 (Classification). We may also consider classification based on either the hinge loss or logistic regression loss. In this setting, the data comes in pairs x = (a, b), where a ∈ Rd is the set of regressors or predictors and b ∈ {−1, 1} is the label; the losses are\nℓ(x, θ) = [1− b 〈a, θ〉]+ and ℓ(x, θ) = log (1 + exp(−b 〈a, θ〉)) .\nBy computing (sub)gradients, we may verify that each of these is an (L, p)-loss if and only if the covariate vector a ∈ Rd satisfies ‖a‖p ≤ L, which is a common assumption [7, 42].\nDefinition 3 is natural given the communication strategy we outline in Section 2.1. Since our loss functions satisfy ‖∂ℓ(X, θ)‖ ≤ L, the channel distribution Q amounts to perturbing subgradients to larger norm balls while maintaining the appropriate expectations.\nBefore proceeding, we briefly review standard algorithms for solving problems of the forms outlined above, since they are essential to our results: for each of our main results, the optimal convergence rate is attained by (a variant of) mirror descent [36, 2, 37], which is a non-Euclidean generalization of the stochastic gradient method [36, 40, 53]. Stochastic gradient methods are iterative methods that update a parameter θt over iterations t of an algorithm using stochastic gradient information. At iteration t, the algorithm receives a vector gt ∈ Rd with conditional expectation E[gt | θt] ∈ ∂R(θt), then performs the update\nθt+1 = argmin θ∈Θ\n{ η 〈gt, θ〉+Ψ(θ, θt) } .\nHere η is a step-size and Ψ is a Bregman divergence, which keeps θt+1 relatively close to θt. (See the papers [2, 37] for further details.) With appropriate choice of Ψ, the mirror descent algorithm enjoys the following convergence guarantees. Define θ̂n = 1 n ∑n t=1 θ\nt. If E[‖gt‖2∞ | θt] ≤ M2∞ for all t and Θ is contained in the ℓ1-ball of radius r1, then with appropriate choice of Ψ and η\nE[R(θ̂n)]−R(θ∗) = O ( M∞r1 √ log d√\nn\n) . (14a)\nSee, for example, Beck and Teboulle [2, Section 5] or Nemirovski et al. [37, Section 2.3]. Similarly, with the choice Ψ(θ, θ′) = ‖θ − θ′‖22, if E[‖gt‖22 | θt] ≤ M22 and Θ is contained in the ℓ2-ball of radius r2, then\nE[R(θ̂n)]−R(θ∗) = O ( M2r2√\nn\n) . (14b)\nFor instance, see the references [53, 37] for results of this type."
    }, {
      "heading" : "3.2 Minimax error bounds under privacy",
      "text" : "We now state our main theorems, and discuss some of their consequences. All proofs are deferred to Section 5."
    }, {
      "heading" : "3.2.1 Minimax errors with mutual information-based privacy",
      "text" : "Our first two main results consider privacy mechanisms Q satisfying optimal local privacy, Definition 1. We state the theorems first focusing on their dependence on the geometry of the subdifferential sets (in which the subgradients live); in the corollaries to follow we show how these choices correspond to particular mutual information guarantees on privacy.\nOur first theorem applies to the class of (L,∞) loss functions as given in Definition 3. For this theorem, we assume that the set to which the perturbed data Z must belong is [−M∞,M∞]d, where M∞ ≥ L. In the notation of Definition 1, this corresponds to taking C = [−L,L]d and D = [−M∞,M∞]d. We state two variants of the first theorem, as one version gives slightly sharper results for an important special case.\nTheorem 1. Let L be the collection of (L,∞) loss functions, assume the conditions of the preceding paragraph, and let Q be optimally locally private (Definition 1) for L. Then\n(a) If Θ contains the ℓ∞ ball of radius r, then\nǫ∗n(L,Θ) ≥ 1\n20 min\n{ rLd, M∞rd\n9 √ n\n} .\n(b) If Θ = {θ ∈ Rd : ‖θ‖1 ≤ r}, then\nǫ∗n(L,Θ) ≥ 1\n8 min\n{ rL, M∞ r √ log(2d)\n2 √ n\n} .\nOur second main theorem applies to loss functions and objectives with a different geometry. Now we assume that the loss functions L consist of (L, 1) losses, and that the perturbed data must belong to the ℓ1 ball of radius M1, i.e., Z ∈ {z ∈ Rd : ‖z‖1 ≤ M1}. Thus in the notation of Definition 1, we have D = (M1/L)C, where C = {g ∈ Rd : ‖g‖1 ≤ L}. If we define M = M1/L, we may define the constants\nγ := log\n( 2d− 2 + √ (2d− 2)2 + 4(M2 − 1) 2(M − 1) ) and ∆(γ) := eγ − e−γ eγ + e−γ + 2(d− 1) , (15)\nwhich are related to the unique distribution achieving optimal local privacy for the (L, 1) losses and the larger ℓ1-ball above (see equation (20) and Proposition 2). We have the following theorem.\nTheorem 2. Let L be the collection of (L, 1) loss functions, assume the conditions of the preceding paragraph, and let Q be optimally private for the collection L. If Θ contains the ℓ∞-ball of radius r,\nǫ∗n(L,Θ) ≥ 1\n20 min\n{ rL, rL √ d\n9 √ n∆(γ)\n} .\nRemarks We make a few remarks on Theorems 1 and 2. First, we note that, when reduced to the special case of having no random distribution Q, Theorems 1 and 2 each yield a minimax rate for stochastic optimization problems. Indeed, in Theorem 1, we may take M∞ = L, in which case (focusing on the second statement of the theorem) we obtain that for Θ = {θ ∈ Rd : ‖θ‖1 ≤ r},\nǫ∗n(L,Θ) ≥ rL\n16\n√ log(2d)\nn .\nMirror descent algorithms [36, 37] can be used to minimize this class of loss functions, and their convergence rate matches this lower bound up to constant factors (also see our results in the sequel,\nas well as the explanation of Agarwal et al. [1]). When specialized to this setting our result is thus unimprovable. Moreover, our analysis is sharper than previous analyses: none of the existing lower bounds recover the logarithmic dependence on the dimension d, which is evidently necessary.\nOur second remark is that while our results appear to require disguising only gradient information, based on our communication formulation in Section 2.1, this restriction is not actually substantial. Indeed, when the domain Θ is a norm ball we can establish each of our lower bounds using the loss function ℓ(x, θ) = 〈x, θ〉. In this case, ∇ℓ(x, θ) = x, so that the communication scheme explicitly disguises exactly the individual data Xi.\nWe now turn to some consequences of Theorems 1 and 2, where we exhibit the tradeoffs between rates of convergence for any statistical procedure and the desired privacy of a user. We present two corollaries that characterize this tradeoff. Looking ahead to Section 4, we may use Propositions 1 and 2 in that section to derive a bijection between the sizes M∞ andM1 of the perturbation sets and the amount of privacy as measured by the worst case mutual information I∗. We can then combine the lower bounds of Theorems 1 and 2 with results on stochastic approximation (the mirror descent convergence rates (14)) to obtain the following tradeoffs. We provide the full proofs in Sections 5.7 and 5.8, respectively.\nCorollary 1. Under the conditions of Theorem 1(b), assume moreover that M∞ ≥ 2L, and that Q∗ satisfies optimal local privacy at information level I∗ in the sense of Definition 1. Then for universal constants 0 < cℓ ≤ cu < ∞, the minimax error is sandwiched as\ncℓ √ d√ I∗ · rL √ log(2d)√ n ≤ ǫ∗n(L,Θ) ≤ cu √ d√ I∗ · rL √ log(2d)√ n .\nSimilar upper and lower bounds can be obtained under the conditions of part (a) of Theorem 1, again by using mirror descent, but we lose a factor of √ log d in the lower bound. (There is an additional factor of d in the statement (a), and Θ ⊇ {θ ∈ Rd : ‖θ‖∞ ≤ r/d}.) In this case we would not need to assume that Θ is an ℓ1-ball for the lower bound.\nWe now turn to an analogous result based on an application of Theorem 2 and Proposition 2.\nCorollary 2. Under the conditions of Theorem 2, assume that M1 ≥ 2L and Q∗ satisfies optimal local privacy at information level I∗. Moreover, suppose that Θ contains an ℓ∞-ball of radius c1r and is contained in an ℓ∞-ball of radius c2r, where 0 < c1 ≤ c2 are constants. Then for universal constants 0 < cℓ ≤ cu < ∞, the minimax error is sandwiched as\ncℓ √ d√ I∗ · rL √ d√ n ≤ ǫ∗n(L,Θ) ≤ cu √ d√ I∗ · rL √ d√ n .\nAs a final remark, we have stated results that depend on specific geometric properties of the loss functions L. While these geometric properties are natural, as illustrated by the example Section 3.1, it is also possible to use our techniques to derive alternative results. Such extensions require computing the optimal distribution attaining local privacy according to Definitions 1 or 2, then applying the lower-bounding techniques to developed in Section 5."
    }, {
      "heading" : "3.2.2 Minimax errors under differential privacy",
      "text" : "We now turn to the setting of differentially private algorithms. We focus on two settings for differential privacy: in the first (Theorem 3), we assume that communication respects optimal local\ndifferential privacy, as given by Definition 2. For the second two results, Theorems 4 and 5, we change the setting slightly, assuming only that the mechanism by which the private quantity Zi is communicated to the method M is α-differentially private and non-interactive (recall Eq. (3)).\nOptimal local differential privacy We begin with the result assuming optimal local differential privacy. We use the same collection of loss functions L as in Theorem 1, that is, (L,∞)-loss functions. We also assume that the set to which the perturbed data Z belong is [−M∞,M∞]d, though the specific value of M∞ is not important for the statement of the theorem.\nTheorem 3. Let L be the collection of (L,∞) loss functions, and assume that Z is optimally locally differentially private (Definition 2), attaining α-differential privacy for the set L. Let d ≥ 2 and assume α ≤ 5/4. Then\nǫ∗n(L,Θ) ≥ 1\n8 min\n{ rL, √ d\nα\nrL √ log(2d)\n4 √ n\n} .\nAs a corollary to this result, we can show an upper bound on the necessary magnitude of the gradient bound M∞ to allow α-differential privacy, again applying the mirror descent result (14a). See Section 5.9 for a proof.\nCorollary 3. Under the conditions of Theorem 3, assume that Q∗ satisfies Definition 2, attaining α-differential privacy. Then for universal constants 0 < cℓ ≤ cu, the minimax error is sandwiched as\ncℓ\n√ d\nα · rL √ log(2d)√ n ≤ ǫ∗n(L,Θ) ≤ cu √ d α · rL √ log(2d)√ n .\nNon-interactive local differential privacy We turn to our two results under non-interactive differential privacy, where we no longer assume that the channel is optimally private (the data provider simply guarantees α-differential privacy). In this setting, we give a minor refinement of the definition of minimax error (13). We let Qα denote the family of α-differentially private distributions where the channel Q is α-differentially private and non-interactive, meaning that the private variable Zi is conditionally independent of Zj for j 6= i given Xi; recall the definition (3). With this, the minimax error is defined as\nǫ∗n(L,Θ, α) := inf M,Q∈Qα sup P sup ℓ∈L(P ) EP,Q[ǫn(M, ℓ,Θ, P )],\nwhere now the infimum is taken over all α-private, non-interactive local mechanisms Q, as well as all methods M. Thus, the channel Q and M work together to find the best possible estimator, subject to the differential privacy constraint.\nOur first lower bound applies to a class of functions that are Lipschitz with respect to the ℓ1norm, where the optimization takes place over the ball B1(r) := {θ ∈ Rd | ‖θ‖1 ≤ r}. We define the set L(B1(r);L) to be the collection of convex (L,∞)-loss functions defined on B1(r). By Example 1, this loss class covers the problem of the multi-dimensional median. In stating our minimax bounds, we use a more restrictive (i.e., simpler to optimize) class, the collection of (L,∞)-linear losses:\nLlin(L,∞) := { ℓ : X × Rd → R | ∃ φ : X → Rd s.t. ℓ(x, θ) = 〈φ(x), θ〉 , sup\nx ‖φ(x)‖∞ ≤ L\n} .\nFor this class, we have the following minimax rate (see Section 5.5 for a proof):\nTheorem 4. For the loss class L = Llin(L,∞) and privacy parameter α = O(1), assuming that the channel Q is non-interactive and α-differentially private, there are universal constants 0 < cℓ ≤ cu < ∞ such that\ncℓ min\n{√ d\nα rL √ log(2d)√ n , rL } ≤ ǫ∗n(L,B1(r), α) ≤ cu min {√ d α rL √ log(2d)√ n , rL } . (16)\nWe can also give a result for a larger class of domains and related optimization functions. In particular, consider the loss class\nL(Θ;L, p) := {ℓ : X ×Θ → R | ℓ is a convex (L, p)-loss function } , (17)\nfor some p ∈ [1, 2]. Restricting the set (17) to the smaller collection of linear functionals, we define\nLlin(Θ;L, p) := { ℓ : X ×Θ → R | ∃ φ : X → Rd s.t. ℓ(x, θ) = 〈φ(x), θ〉 , sup\nx ‖φ(x)‖p ≤ L\n} .\nWe then have the following result, which captures rates of convergence for optimization of linear functionals over ℓq-norm balls of the form\nBq(rq) := {θ ∈ Rd : ‖θ‖q ≤ rq}, where q ∈ [2,∞].\nTheorem 5. For the loss class L = Llin(Bq(rq);L, p) with q ∈ [2,∞] and non-interactive αdifferentially private channel Q with α = O(1), there exist universal constants 0 < cℓ ≤ cu < ∞ such that\ncℓ rqLmin\n{√ d\nα\nd 1 2 − 1 q\n√ n\n, ( √ nα2) − 1 q , 1 } ≤ ǫ∗n(L,Bq(rq), α) ≤ cu rqLmin {√ d\nα\nd 1 2 − 1 q\n√ n , 1\n} . (18)\nFor the loss class L = L(Θ;L, p) from Eq. (17), if Θ ⊃ Bq(rq), there exists a universal (numerical) constant 0 < cℓ such that\ncℓmin\n{√ d\nα\nrqLd 1 2 − 1 q\n√ n , rqL\n} ≤ ǫ∗n(L,Θ, α). (19)\nSee Section 5.6 for a proof.\nRemarks Each of our theorems and corollaries provide sharp characterizations of the minimax rate of estimation up to the constant factors (cℓ, cu). As noted in the previous section, the nonprivate minimax rate for the class L(B1(r);L) is rL √ log(2d)/ √ n. We may compare this with the rate in Theorems 3 and 4, as well as Corollary 3. We see that α-local differential privacy has a dimension-dependent effect on the minimax rate: the effective sample size is reduced from n to α2n/d. This is a substantial reduction, as instead of a logarithmic dependence on the dimension d—which one hopes for in high-dimensional settings such as those specified by the theorem—we have a linear dependence, which is unavoidable under the conditions of the theorems.\nIn Theorem 5 as well, the inequalities (18) provide a characterization of the α-private minimax rate that is tight up to constant factors. Again, it is worthwhile to relate this minimax rate to the non-private setting: from Theorem 1 and Eq. (11) of Agarwal et al. [1], the non-private minimax\nrate for the function class Llin(Θ;L, p) is lower bounded by rqLd 1 2 − 1 q / √ n. Consequently, the price for α-privacy is again a reduction in effective sample size by the dimension-dependent factor α2/d. In general, stochastic gradient descent methods require interactivity—they iteratively process the data and query for gradients at points θ depending on the data observed—except in linear settings. We do, however, obtain matching upper bounds for the general convex case in both Theorems 4 and 5 using stochastic gradient methods (which is unsurprising, as the linear setting is, in a sense, the hardest [36, 1]). This leads to the intriguing open question of whether interactivity can sharpen the results of Theorems 4 and 5. (For Theorems 1–3, the optimal privacy game played by the data providers allows interactivity, and hence the results cannot be improved.) It is also interesting to note that in Theorems 3–5, in the α-differentially private setting, adding Laplace noise—the most common mechanism for achieving privacy [15]—appears to be substantially suboptimal: the magnitude of noise necessary to privatize the user’s data is Ω(d) larger than that provided by the optimal sampling mechanisms we develop in the sequel.\nSummarizing, each of the preceding results indicates that—no matter the type of privacy— there is a dimension-dependent increase in sample complexity. From Corollaries 1 and 2 we see that incorporating privacy induces a penalty of roughly √ d/ √ I∗ in convergence rate, or an effective sample size reduction from n to nI∗/d; in the differential privacy case we have n 7→ nα2/d. While we do not know of an explicit comparison between these two bounds, work by Dwork et al. [18, Lemma 3.2] shows that KL divergence between α-differentially private distributions scales as α2, which implies roughly that I∗ ≈ α2 (though this is informal). We see roughly similar results, though there does not appear to be a simple mapping between information-theoretic notions of privacy and differential privacy."
    }, {
      "heading" : "4 Optimal privacy-preserving distributions",
      "text" : "In this section, we explore conditions for a distribution Q∗ to satisfy optimal local privacy as given by Definitions 1 and 2. We give a few characterizations of necessary (and sometimes sufficient) conditions based on the compact sets C ⊂ D for distributions P ∗ and Q∗ to achieve the saddle point (9). Our results can be viewed as rate distortion theorems [23, 8, 10] (with source P and channel Q) for certain compact alphabets, though as far as we know, they are all new. Thus, we refer to the conditional distribution Q, which is designed to maintain the privacy of the data X by communication of Z, interchangeably as the privacy-preserving distribution or the channel distribution.\nNote that since we wish to bound I(X;Z) for general losses ℓ, as captured in the definitions of the source P (C) and communication set Q (C,D) in Eqs. (10a) and (10b), we must address the case when ℓ(X, θ) = 〈θ,X〉, in which case ∇ℓ(X, θ) = X; this shows (by the data-processing inequality [23, Chapter 5]) that it is no loss of generality to assume that X ∈ C with probability 1 and that we must have E[Z | X] = X. Thus we present each of our results assuming that ℓ(X, θ) = 〈θ,X〉, since a distribution Q∗ is optimally locally private or optimally differentially locally private if and only if it attains the saddle point with this choice of loss."
    }, {
      "heading" : "4.1 General saddle point characterizations",
      "text" : "We begin with a general characterization, first defining the types of sets C and D that we use in our characterization of privacy. Such sets are reasonable for many applications (recall Section 3.1).\nWe focus on the case when the compact sets C and D are (suitably symmetric) norm balls:\nDefinition 4. Let C ⊂ Rd be a compact convex set with extreme points ui ∈ Rd, i ∈ I for some index set I. Then C is a rotationally invariant through its extreme points if ‖ui‖2 = ‖uj‖2 for each i, j, and for any unitary matrix U such that Uui = uj for some i 6= j, then UC = C.\nSome examples of convex sets rotationally invariant through their extreme points include ℓp-norm balls for p = 1, 2,∞, though ℓp-balls for p 6∈ {1, 2,∞} are not.\nThe following theorem gives a general characterization of the minimax mutual information for such rotationally invariant sets by providing saddle point distributions P ∗ and Q∗. We provide the proof of Theorem 6 in Section E.1.\nTheorem 6. Let C be a compact convex polytope rotationally invariant through its m < ∞ extreme points {ui}mi=1 and D = (1 + κ)C for some κ > 0. Let Q∗ be the conditional distribution of Z | X that maximizes the entropy H(Z | X = x) subject to the constraints that\nEQ[Z | X = x] = x\nfor x ∈ C and that Z is supported on (1 + κ)ui for i = 1, . . . ,m. Then Q∗ satisfies Definition 1, optimal local privacy, and Q∗ is (up to measure zero sets) unique. Moreover, the distribution P ∗ that is uniform on {ui}mi=1 attains the saddle point (9).\nRemarks: We make a few brief remarks here, deferring a somewhat deeper discussion of the implications of Theorem 6 to Appendix E.1, as an understanding of the proof helps. The theorem requires that for Q∗ to attain the saddle point guaranteeing optimal local privacy, Q∗(· | X = x) should maximize the entropy of Z for each x ∈ C, but this is not essential. If x 6∈ {ui}mi=1, a twophase approach still obtains optimal local privacy. We construct a Markov chain X → X ′ → Z, where X ′ is supported on the extreme points {ui}mi=1 of C. The distribution X → X ′ may then be any distribution satisfying E[X ′ | X] = X; we then take the conditional distribution Q∗(· | ui) defined for X ′ → Z to be the maximum entropy distribution Q∗(· | ui) defined in the theorem. By the data processing inequality [23, Chapter 5], this Markov chain X → X ′ → Z guarantees the minimax information bound I(X;Z) ≤ infQ supP I(P,Q)."
    }, {
      "heading" : "4.2 Specific saddle point computations",
      "text" : "With Theorem 6 in place, we can explicitly characterize the minimax mutual information for ℓ1 and ℓ∞ balls by computing maximum entropy distributions. That is, we compute the unique distributions that attain optimal local privacy—the distributions that guarantee as much (of our definition of) privacy as possible subject to certain constraints. We present two propositions in this regard, providing some discussion and giving proofs in Sections E.2 and E.3.\nFirst, consider the case where X ∈ [−L,L]d and Z ∈ [−M,M ]d, where M ≥ L. For notational convenience, we define the binary entropy h(p) = −p log p− (1− p) log(1− p). We have\nProposition 1. For constants M ≥ L > 0, let X ∈ [−L,L]d and Z ∈ [−M,M ]d be random variables such that E[Z | X] = X almost surely. Define Q∗ to be the conditional distribution on Z | X such that the coordinates of Z are independent, have range {−M,M}, and satisfy\nQ∗(Zi = M | X) = 1\n2 + Xi 2M and Q∗(Zi = −M | X) = 1 2 − Xi 2M .\nThen Q∗ satisfies Definition 1, optimal local privacy, and moreover,\nsup P\nI(P,Q∗) = d− d · h ( 1\n2 +\nL\n2M\n) .\nBefore continuing, we give a slightly more intuitive understanding of Proposition 1. Let L = 1 for simplicity (this is no loss of generality by scaling). Concavity implies that for a, b > 0, log(a) ≤ log b+ b−1(a− b), or − log(a) ≥ − log(b) + b−1(b− a), so\n− log ( 1\n2 − 1 2M\n) ≥ − log 1\n2 + 2 · 1 2M and − log\n( 1\n2 +\n1\n2M\n) ≥ − log 1\n2 − 2 · 1 2M .\nIn particular, we see that\nh\n( 1\n2 +\n1\n2M\n) ≥ − ( 1\n2 +\n1\n2M\n)( − log 2− 1\nM\n) − ( 1\n2 − 1 2M\n)( − log 2 + 1\nM\n) = log 2− 1\nM2 .\nThat is, we have for any distribution P on X, where X ∈ [−L,L]d, that (in natural logarithms)\nI(P,Q∗) ≤ dL 2\nM2 ,\nand this bound is tight to O((M/L)−3). We now consider the case when X ∈ { x ∈ Rd : ‖x‖1 ≤ 1 } and Z ∈ { z ∈ Rd : ‖z‖1 ≤ M } . Here the arguments are slightly more complicated, as the coordinates of the random variables are no longer independent, but Theorem 6 still allows us to explicitly characterize the saddle point of the mutual information. Before stating the proposition, we recall that if ei ∈ Rd are the standard basis vectors, then the extreme points of the ℓ1-ball of radius 1 are the 2d vectors {±ei}di=1.\nProposition 2. For a constant M > 1, let X ∈ {x ∈ Rd : ‖x‖1 ≤ 1} and Z ∈ {z ∈ Rd : ‖z‖1 ≤ M} be random variables. Define the parameter\nγ := log\n( 2d− 2 + √ (2d− 2)2 + 4(M2 − 1) 2(M − 1) ) , (20)\nand let Q∗ be the conditional distribution on Z | X such that Z is supported on {±Mei}di=1, and\nQ∗(Z = Mei | X = ei) = eγ\neγ + e−γ + (2d− 2) , (21a)\nQ∗(Z = −Mei | X = ei) = e−γ\neγ + e−γ + (2d− 2) , (21b)\nQ∗(Z = ±Mej | X = ei, j 6= i) = 1\neγ + e−γ + (2d− 2) . (21c)\n(For X 6∈ {±ei}, define X ′ to be randomly selected in any way from among {±ei} such that E[X ′ | X] = X, then sample Z from X ′ according to (21a)–(21c).) Then Q∗ satisfies Definition 1, optimal local privacy, and\nsup P\nI(P,Q∗) = log(2d)− log ( eγ + e−γ + 2d− 2 ) + γ\neγ eγ + e−γ + 2d− 2 − γ e−γ eγ + e−γ + 2d− 2 .\nBy scaling, if we have X ∈ {x ∈ Rd : ‖x‖1 ≤ L} and Z ∈ {z ∈ Rd : ‖Z‖1 ≤ M1}, then the theorem holds with M = M1/L in Eq. (20) and with X = ei replaced by X = Lei in Eq. (21).\nProposition 2 is somewhat more complex than the ℓ∞ case. We remark that the additional sampling to guarantee that X ′ ∈ {±ei} (where the conditional distribution Q∗ is defined) can be accomplished simply: define the random variable X ′ so that X ′ = ei sign(xi) with probability |xi|/ ‖x‖1. Evidently E[X ′ | X] = x, and X → X ′ → Z for Z distributed according to Q∗ defines a Markov chain as in our remarks following Theorem 6. An asymptotic expansion allows us to gain a somewhat clearer picture of the values of the mutual information, though we do not derive upper bounds as we did for Proposition 1. We have the following corollary, proved in Appendix E.5.\nCorollary 4. Let Q∗ denote the conditional distribution in Proposition 2, where X and Z lie in ℓ1-balls of radii L and M , respectively. Then\nsup P\nI(P,Q∗) = dL2\n2M2 +Θ\n( min { d3L4\nM4 , log4(d) d\n}) ."
    }, {
      "heading" : "4.3 Saddle points for differentially private communication",
      "text" : "Our final result in this section characterizes saddle points for distributions satisfying Definition 2. Such calculations are, in general, non-trivial, so we restrict our attention to results necessary for the setting of Theorem 3. To that end, we focus on the case where C and D are ℓ∞ balls, which is relevant for high-dimensional statistical and optimization settings. Without loss of generality (by scaling), we may take C = [−1, 1]d and D = [−M,M ]d. We have Proposition 3. For a constant M ≥ 1, let X ∈ [−1, 1]d and Z ∈ [−M,M ]d be random variables such that E[Z | X] = X almost surely. Fix any x ∈ {−1, 1}d and for k = {0, 2, 4, . . . , 2 ⌈d/2⌉ − 2} define the constants q+k ≥ 0 and q−k ≥ 0 to satisfy the linear equations\nMq+k\n∑\nz∈{−1,1}d:〈z,x〉>k\nz +Mq−k\n∑\nz∈{−1,1}d:〈z,x〉≤k\nz = x and q+k + q − k = 1.\nSet k∗ ∈ argmink{q+k /q−k }. The optimal differential privacy (11) for the sets C = [−1, 1]d and D = [−M,M ]d is\nα⋆(C,D) = log q+k∗\nq−k∗ = min k∈{0,2,...,2⌈d/2⌉−2} log q+k q−k .\nThe distributions attaining optimal local differential privacy are characterized as follows. Define Q∗k to be the distribution supported on {−M,M}d with probability mass function defined by\nQ∗k(Z = Mz | X = x) = { q+k if 〈z, x〉 > k q−k if 〈z, x〉 ≤ k\n(22)\nfor z, x ∈ {−1, 1}d. (For X 6∈ {−1, 1}d, define X ′ to be randomly chosen from {−1, 1}d such that E[X ′ | X] = X, then sample Z according to the above p.m.f.) A distribution Q∗ satisfies Definition 2, optimal local differential privacy, if and only if it can be written as a convex combination of those Q∗k for which k ∈ argmink{q+k , q−k }, that is,\nQ∗ = ∑\nk∈argmink{q + k ,q− k }\nβkQ ∗ k, where βk ≥ 0 and\n∑\nk∈argmink{q + k ,q− k }\nβk = 1.\nThe proof of Proposition 3 is technical, and we defer it to Section E.4. We make a few remarks, however. First, we provide a simplified explanation of the linear equations in the proposition. By symmetry, no matter the value of x ∈ {−1, 1}d chosen, the same q+k and q−k solve the linear equations. Proposition 3 shows the structure of the distribution attaining optimal local differential privacy. That is, the proposition shows that the distribution Q∗(· | x) assigns mass only on the points z ∈ {−M,M}d, and moreover, it assigns one of two masses: either q+ or q−. To sample from this distribution given an initial point x, one simply flips a coin with bias probabilities {q+k , q−k }, and depending on the result of the coint flip, samples Z ∈ {−M,M}d uniformly from one of the sets {z : 〈z, x〉 > k/M} or {z : 〈z, x〉 ≤ k/M}."
    }, {
      "heading" : "5 Proofs of Statistical Rates",
      "text" : "In this section, we prove Theorems 1–5 as well as Corollaries 1, 2, and 3. Our proofs are based on classical information-theoretic techniques from statistical minimax theory [49, 50], and also exploit some additional results due to Agarwal et al. [1]. At a high level, our approach consists of the following steps. Beginning with an appropriately chosen finite set V, we assign a risk function Rv to each member v ∈ V. The resulting collection {Rv}v∈V of risk functions is chosen so that they “separate” points in the set V, meaning that if θ ∈ Θ is a point that approximately minimizes the function Rv, then for any w 6= v, the point θ cannot also be an approximate minimizer of Rw. This separation property allows us to deduce that statistical estimation implies the existence of a testing procedure that distinguishes v from w for w 6= v. We then use lower bounds on the error probability in tests, such asFano’s and Le Cam’s inequalities [50], to obtain a lower bound on the testing error. These inequalities depend on the mutual information between the random variable Xi and the vector Zi communicated, so the final step is to obtain good upper bounds on this mutual information. In the next section, we describe in more detail this reduction, finishing with an outline of the proofs to follow."
    }, {
      "heading" : "5.1 Reduction to testing",
      "text" : "We begin by describing the reduction that lower bounds the minimax error by the error of a testing problem. It assumes a given collection of risk functions {Rv}v∈V indexed by a finite set V; see the individual theorem proofs to follow for constructions of the particular collections used in our analysis. For each v ∈ V, we choose some representative θ∗v ∈ argminθ∈ΘRv(θ) of the set of all minimizing vectors. Our reduction is based on a discrepancy measure between pairs of risk functions, first introduced by Agarwal et al. [1], defined as\nρ(Rv, Rw) := inf θ∈Θ\n[Rv(θ) +Rw(θ)−Rv(θ∗v)−Rw(θ∗w)] .\nThe ρ-separation of the set V is defined as\nρ⋆(V) := min {ρ(Rv, Rw) : v,w ∈ V, v 6= w} . (23)\nWhen the set V is clear from context, we use ρ⋆ as shorthand for this separation. The key to the definition (23) is that the separation allows us to lower bound the expected optimality gap of a statistical method M by the probability of error in a hypothesis test. That is, with the family {Rv}v∈V , we can define the canonical hypothesis testing problem: nature chooses\na uniformly random V ∈ V, and conditional on V = v, the n observations Xi, i = 1, . . . , n, are drawn independently from a distribution Pv satisfying Rv(θ) = EPv [ℓ(X, θ)]. In the private setting, instead of observing Xi, the learner observes the privatized vector Zi, and given the set {Zi}ni=1, the goal is to determine the underlying index v.\nRecall the definition (12) of the excess risk ǫn. The previously described hypothesis testing problem can be used to establish lower bounds on the estimation error, as demonstrated in the following:\nLemma 1. Let P be a joint distribution over X ∈ Rd and V ∈ V such that X are i.i.d. given V and EP [ℓ(X, θ) | V = v] = Rv(θ). Let Q be the conditional distribution of Z given the observations X. Then for any minimization procedure M, there exists a hypothesis test v̂M : (Z1, . . . , Zn) → V such that\nEP,Q [ǫn(M, ℓ,Θ, P )] ≥ ρ⋆(V) 2 PP,Q [v̂M(Z1, . . . , Zn) 6= V ] .\nThis result is a variant of Lemma 2 due to Agarwal et al. [1]) It shows that if we can bound the probability of error of any hypothesis test for identifying V based on the sample Z1, . . . , Zn, we have lower bounded the rate at which it is possible to minimize the risk R.\nThe remaining challenge is to provide a lower bound on the error of hypothesis testing problems. To do so, we apply one of two well-known inequalities: Fano’s inequality [8], which applies when |V| > 2, or Le Cam’s method [33, 50], which we apply when |V| = 2. Let V ∈ V be chosen uniformly at random from V. If a procedure observes random variables Z1, . . . , Zn, Fano’s inequality ensures that for any estimate v̂ of V—that is, any measurable function v̂ of Z1, . . . , Zn—the test error probability satisfies the lower bound\nP(v̂(Z1, . . . , Zn) 6= V ) ≥ 1− I(Z1, . . . , Zn;V ) + log 2\nlog |V| . (24)\nBy contrast, Le Cam’s method provides lower bounds on the probability of error in binary hypothesis testing problems. In this setting, assume that V = {−1, 1} has two elements, and let V ∈ V be chosen uniformly at random from V. If a procedure observes random variables Z1, . . . , Zn distributed according to Qn1 if V = 1 and Q n −1 if V = −1, then any estimate v̂ of V satisfies the lower bound\nP (v̂(Z1, . . . , Zn) 6= V ) ≥ 1 2 − 1 2 ∥∥Qn1 −Qn−1 ∥∥ TV . (25)\nSee, for example, Le Cam [33, Section 2] or Yu [50, Lemma 1]. Using the lower bound provided by Lemma 1 and Fano’s inequality (24) or Le Cam’s inequality (25), the structure of our remaining proofs becomes more apparent. Each lower bound argument proceeds in three steps:\n(1) We construct a collection of loss functions satisfying Definition 3, computing the minimal separation (23) so that we may apply Lemma 1.\n(2) The second step is to provide an upper bound on the appropriate information theoretic quantity in order to apply Fano’s inequality (24), in which case we bound I(Z1, . . . , Zn;V ), or Le Cam’s inequality (25), where we bound ∥∥Qn1 −Qn−1 ∥∥ TV\n. This step requires the most work and constitutes the major arguments in this section. We provide these bounds using one of two techniques:\n(a) In the proofs of Theorems 1, 2, and 3, we use a distribution Q that satisfies Definition 1 of optimal local privacy (Theorems 1 and 2) or Definition 2 of optimal local differential privacy (Theorem 3). We can then explicitly upper bound the mutual information I(Z1:n;V ) using the definition ofQ and the losses ℓ from step 1. (See Lemmas 4, 5, 7, and 8 in the subsequent sections.)\n(b) In the proofs of Theorems 4 and 5, we use a bound on mutual information in non-interactive locally differentially private schemes, which we recently presented [12]. This requires a careful packing construction in conjunction with the loss choice from step 1.\n(3) The final step is to use the results of Steps 1 and 2 in the application of Lemma 1 and Fano’s inequality (24) (when the dimension d is low, we use Le Cam’s inequality (25)). This then yields the theorems.\nWe now turn to the proofs of the theorems. We provide each proof in turn, following the steps in the preceding outline."
    }, {
      "heading" : "5.2 Proof of Theorem 1",
      "text" : "We provide the most detail in the proof of this theorem, as it closely exhibits the blueprint by which we prove the other results."
    }, {
      "heading" : "5.2.1 Constructing well-separated losses",
      "text" : "The first step in proving our minimax lower bounds is to construct a family of well-separated risks. For Theorem 1, we use one of two families of loss functions: linear losses and median-based losses. Each of these gives a well-separated family with subgradients bounded in ℓ∞-norm.\nLinear losses Our first collection of risk functionals is relatively simple, based on families of linear loss functions; we describe the sampling scheme for X to generate them. Let V = {±ei}di=1, where the vectors ei are the standard basis vectors in R\nd, whence |V| = 2d. Fix δ ∈ (0, 1], which we specify later. We choose the distribution P on X to be nearly uniform on X ∈ {−1, 1}d. Conditional on the parameter v ∈ V, we use the following sampling distribution for X:\nChoose X ∈ {−1, 1}d with independent coordinates, where Xj = { 1 w.p. 1+δvj 2\n−1 w.p. 1−δvj2 . (26)\nNow for L ∈ R+ we may define the linear loss functions\nℓ(X, θ) := L 〈X, θ〉 = L d∑\nj=1\nXjθj. (27)\nBy inspection, the final risk is Rv(θ) = EP [〈θ,X〉] = Lδ 〈v, θ〉. We obtain the following result on the separation of the risks.\nLemma 2. Given the sampling scheme (26),\n(a) The loss (27) is L-Lipschitz with respect to the ℓ1-norm.\n(b) For the optimization domain Θ = {θ ∈ Rd : ‖θ‖1 ≤ r}, the ρ-separation of the set V = {±ei}di=1 is ρ⋆(V) = Lrδ.\nProof The first statement of the lemma is immediate, since ∇ℓ(X, θ) = LX and ‖X‖∞ ≤ 1 (cf. [26]). For the second, we verify that infθ∈Θ[Rv(θ) + Rw(θ)] − Rv(θ∗v) − Rw(θ∗w) ≥ Lrδ. To do so, we compute the minimizers of Rv: since ℓ1 and ℓ∞ are dual norms, we see that for v ∈ V,\ninf ‖θ‖1≤r Rv(θ) = inf ‖θ‖1≤r\nLδ 〈v, θ〉 = −Lδr ‖v‖∞ = −Lδr,\nand the minimizer is uniquely attained at θ∗v = −rv. Then we have for any w 6= v that\ninf ‖θ‖\n1 ≤1\n[〈v +w, θ〉] + ‖v‖∞ + ‖w‖∞ = −‖v +w‖∞ + ‖v‖∞ + ‖w‖∞ ≥ −1 + 1 + 1 = 1,\nsince any non-zero coefficients of v and w have differing signs. Multiplying the result by Lrδ completes the proof.\nMedian-type losses We now describe a class of median-type losses, one with more general applicability than the linear losses of Section 5.2.1. Let V ⊂ {−1, 1}d be a subset of the binary hypercube such that for all distinct pairs v 6= v′, we have ‖v − v′‖1 ≥ d/2, or equivalently ‖v − v′‖0 ≥ d/4. From the Gilbert-Varshamov bound [50, Lemma 4] there are sets of this form with cardinality at least card(V) ≥ exp(d/8). We define the distribution on X, conditional on v ∈ V, as\nChoose X ∈ {−1, 1}d with independent coordinates, where Xj = { 1 w.p. 1+δvj 2\n−1 w.p. 1−δvj2 . (28)\nFor L > 0, we then define the median-type loss function\nℓ(X, θ) = L ‖rX − θ‖1 , (29)\nwhich under the sampling scheme (28) gives rise to the risk functional\nRv(θ) = L\nd∑\nj=1\n1 + δvj 2 |θj − r|+ 1− δvj 2 |θj + r| = L\n( 1 + δ\n2 ‖θ − rv‖1 + 1− δ 2 ‖θ + rv‖1 ) .\nBy construction, whenever Θ contains the ℓ∞ ball of radius r, this risk function has the unique minimizer\nθ∗v := argmin θ∈Θ Rv(θ) = rv ∈ r{−1, 1}d ⊂ Θ.\nThe following lemma, due to Agarwal et al. [1], captures the separation properties of the collection {Rv}v∈V of risk functionals: Lemma 3. Assume that Θ contains [−r, r]d and let Rv be defined as in the preceding paragraph. If v,w ∈ V with v 6= w, the discrepancy ρ(Rv, Rw) ≥ rLdδ/2.\nAs a final remark, for random variables X ∈ Rd, the loss function (29) is Lipschitz continuous (for appropriate choice of L) for any distribution P on X. Specifically, defining the sign(·) function coordinate-wise, we have the subgradient equality ∂ℓ(x, θ) = L sign(θ−rx). Thus, for any p ∈ [1,∞] and Lp ≥ 0, setting L = Lpd−1/p yields a member of the collection of (Lp, p)-loss functions."
    }, {
      "heading" : "5.2.2 Bounding the mutual information",
      "text" : "As outlined in Section 5.1, the second step in our lower bound proofs is to bound the mutual information I(Z1, . . . , Zn;V ), where Zi are the private views available to the learning method. Here we provide mutual information bounds for the family of linear losses (Lemma 4) and medianbased losses (Lemma 5). Each of these mutual information bounds—and our subsequent bounds on mutual information—proceed by using independence to reduce the problem to estimating the mutual information I(Z;V | θ) for a single randomized gradient sample Z. Then, careful calculation of the distribution of Z | V yields the final inequalities. As the proofs are somewhat long and technical, we defer them to Appendix B.\nLemma 4. Let V be drawn uniformly at random from V = {±ei}di=1. Let X have the distribution (26) conditional on V = v and assume ℓ(X, θ) = L 〈X, θ〉. Let Z be constructed according to the conditional distribution specified by Proposition 1 given a subgradient ∂ℓ(Xi; θ) with Z ∈ [−M∞,M∞]d, where M∞ ≥ L. Then\nI(Z1, . . . , Zn;V ) ≤ n δ2L2\nM2∞ .\nSee Appendix B.1 for a proof of Lemma 4.\nLemma 5. Let V be drawn uniformly at random from a set V ⊂ {−1, 1}d. Let X have the distribution (28) conditional on V = v and assume ℓ(X, θ) = L ‖rX − θ‖1, where r > 0 is a constant. Let Z be constructed according to the distribution specified by Proposition 1 conditional on a subgradient ∂ℓ(Xi; θ), where Z ∈ [−M∞,M∞]d and M∞ ≥ L. Then\nI(Z1, . . . , Zn;V ) ≤ n δ2L2d\nM2∞ .\nSee Appendix B.2 for a proof of Lemma 5."
    }, {
      "heading" : "5.2.3 Applying testing inequalities",
      "text" : "Having established the two families of loss functions we consider and the resultant mutual information bounds, it remains to apply Lemma 1 and a testing inequality. We begin by proving part (a) of the theorem.\nProof of Theorem 1(a) We divide the proof of part (a) of the theorem into two parts: one assuming the dimension d ≥ 9 and the other assuming d < 9. For the first, we use Fano’s inequality (24), while for the second, an application of Le Cam’s method (25) completes the result. For both results, we use the median-type loss ℓ(X, θ) = L ‖rX − θ‖1. We first recall the beginning of the previous section, stating the following application of Lemma 1 and Fano’s inequality (24):\n2 ρ⋆(V)EP,Q [ǫn(M, ℓ,Θ, P )] ≥ PP,Q (v̂(M) 6= V ) ≥ 1− I(Z1, . . . , Zn;V ) + log 2 log |V| . (30)\nNow we give the proof of the first statement of the theorem in the case that d ≥ 9. Applying Lemmas 3 and 5, we immediately have the following specialization of the inequality (30):\n4\nrLdδ EP,Q [ǫn(M, ℓ,Θ, P )] ≥ 1−\nlog 2 log |V| − n δ2L2d M2∞ log |V| .\nTaking the set V ⊂ {−1, 1}d to be a d/4 packing of the hypercube {−1, 1}d satisfying |V| ≥ exp(d/8), as in our construction of median-type losses in Section 5.2.1, we see that\n4\nrLdδ EP,Q [ǫn(M, ℓ,Θ, P )] ≥ 1−\n8 log 2 d − n8δ\n2L2\nM2∞ .\nThe numerical inequality 8 log 2 < 6 coupled with the preceding bound implies\n4\nrdLδ EP,Q [ǫn(M, ℓ,Θ, P )] > 1−\n6 d − 8nδ\n2L2\nM2∞ .\nBy our assumption that d ≥ 9, if we choose δ = min{M∞/8L √ n, 1}, we are guaranteed the lower bound 4rdLδEP,Q [ǫn(M, ℓ,Θ, P )] > 15 , or equivalently\nEP,Q [ǫn(M, ℓ,Θ, P )] > rdLδ\n20 =\n1\n20 ·min\n{ rdL, M∞rd\n8 √ n\n} .\nWhen d < 9, we may reduce to the case that d = 1, since a lower bound in this setting extends to higher dimensions (though we may lose dimension dependence). For this case, we use the packing set V = {−1, 1} with the linear loss function from Lemma 2, which has ρ⋆(V) = Lrδ. In this case, the marginal distribution Q(· | V ) is given by\nQ(Z = z | V = 1) = 1 2 +\n{ δL 2M if z = M\n− δL2M otherwise, i.e. if z = −M.\nNow, let Qn(· | V ) denote the distribution of Z1, . . . , Zn conditional on V . Then applying Lemma 1 and Le Cam’s lower bound (25), we obtain the inequality\n2\nrLδ EP,Q[ǫn(M, ℓ,Θ, P )] ≥ PP,Q (v̂(M) 6= V ) ≥\n1 2 − 1 2 ‖Qn(· | V = 1)−Qn(· | V = −1)‖TV .\nA standard result on the total variation distance of Bernoulli distributions (see Lemma 13 in Appendix B.5) implies that\n‖Qn(· | V = 1)−Qn(· | V = −1)‖TV ≤ δL\nM\n√ (3/2)n\nif δ ≤ M/(3L). Thus we have the bound\n2\nrLδ EP,Q[ǫn(M, ℓ,Θ, P )] ≥\n1 2 −\n√ 3n\n2 √ 2 · δL M . (31)\nMultiplying both sides by rLδ, then setting δ = min{M/(3L√n), 1} ≤ M/(3L), we have\nEP,Q[ǫn(M, ℓ,Θ, P )] ≥ ( 1\n2 − 1 2 √ 6\n) rLδ\n2 ≥ √ 6− 1 4 √ 6 rLmin { M 3L √ n , 1 } .\nIn turn, for any d ≤ 8, we immediately find that ( √ 6 − 1)/4 √ 6 ≥ d/(9 · 20), which completes the proof of Theorem 1(a).\nProof of Theorem 1(b) For the second statement of the theorem, we use the linear losses of Section 5.2.1 and apply Lemmas 2 and 4 with the choice V = {±ei}di=1. In this case, the lower bound (30) and Lemma 2’s separation guarantee imply that\n2\nLrδ EP,Q [ǫn(M, ℓ,Θ, P )] ≥ 1−\nlog 2 log(2d) − I(Z1, . . . , Zn;V ) log(2d) .\nWe may assume that d ≥ 2 (using the result of part (a) for d = 1), and we have log 2/ log(2d) ≤ 1/2, which, after an application of Lemma 4, yields\n2\nLrδ EP,Q [ǫn(M, ℓ,Θ, P )] ≥\n1 2 − n δ\n2L2\nM2∞ log(2d) .\nIf we choose δ = min{M∞ √ log(2d)/2L √ n, 1}, we see that we have\n2\nLrδ EP,Q [ǫn(M, ℓ,Θ, P )] ≥\n1 4 ,\nwhich is equivalent in this case to\nEP,Q [ǫn(M, ℓ,Θ, P )] ≥ rLδ\n8 =\n1 8 min\n{ Lr, M∞r √ log(2d)\n2 √ n\n} ."
    }, {
      "heading" : "5.3 Proof of Theorem 2",
      "text" : "The proof of Theorem 2 is quite similar to that of Theorem 1, again following our outline from Section 5.1. In this section, however, we construct a different family of loss functions, necessitating a new mutual information bound."
    }, {
      "heading" : "5.3.1 Constructing well-separated losses",
      "text" : "We construct families of losses that are useful for analyzing the case of stochastic subgradients bounded in ℓ1-norm. As was the case with median losses (recall Section 5.2.1), let V ⊂ {−1, 1}d be a d/4-packing of the hypercube in ℓ0-norm; we know there is such a set with cardinality |V| ≥ exp(d/8). As our sampling process for the data, we choose X from among the 2d positive and negative standard basis vectors ±ej , namely\nChoose index j ∈ {1, . . . , d} uniformly at random, and set X = { ej w.p. 1+δvj 2\n−ej w.p. 1−δvj2 , (32)\nwhere δ ∈ (0, 1] is fixed. For a fixed L > 0, we define the hinge loss, common in classification problems, ℓ(x, θ) = L [r − 〈x, θ〉]+ . (33) The combination of hinge loss (33) and sampling strategy (32) yields the risk functional\nRv(θ) = L\nd\nd∑\nj=1\n1 + δvj 2 [r − 〈ej , θ〉]+ + L d\nd∑\nj=1\n1− δvj 2 [r + 〈ej, θ〉]+ .\nAssuming that Θ contains the ℓ∞ ball of radius r, the (unique) minimizer of the risk over Θ is\nθ∗v := argmin θ∈Θ Rv(θ) = rv ∈ r{−1, 1}d ⊂ Θ.\nMoreover, this risk has the following properties:\nLemma 6. For any set Θ ⊇ [−r, r]d, we have:\n(a) For P with support suppP ⊆ {x ∈ Rd : ‖x‖1 ≤ 1}, the loss function (33) is L-Lipschitz with respect to the ℓ∞-norm.\n(b) If v,w ∈ V with v 6= w, the discrepancy ρ(Rv, Rw) ≥ rLδ/2.\nProof The first claim is immediate (cf. [26]), since ‖∂ℓ(x, θ)‖1 ≤ L ‖x‖1 ≤ L. For the second statement of the lemma, as in the proof of Lemma 2 we verify the separation condition directly by computing the minimizers of Rv. The minimum of\nRv(θ)+Rw(θ) = L\nd\nd∑\nj=1\n( [r − 〈ej, θ〉]+ + [r + 〈ej , θ〉]+ ) + Lδ\nd\n∑\nj:vj=wj\nvj ( [r − 〈ej , θ〉]+ − [r + 〈ej , θ〉]+ )\nis attained by any θ ∈ Rd with θj ∈ [−r, r] for j such that vj 6= wj and θj = rvj for j such that vj = wj; a minimizer of Rv is θ ∗ v = rv. Thus we have\ninf θ∈Θ\n{Rv(θ) +Rw(θ)} −Rv(θ∗v)−Rw(θ∗w) = L\nd\nd∑\nj=1\n2r − 2L d\n∑\nj:vj=wj\nrδ − Lr(1− δ)− Lr(1− δ)\n= 2Lr − 2Lr + 2Lrδ − 2Lrδ d (d− ‖v − w‖0) = 2Lrδ d ‖v − w‖0 .\nSince ‖v − w‖0 ≥ d/4 by construction, we have ρ(Rv , Rw) ≥ rLδ/2, as desired."
    }, {
      "heading" : "5.3.2 Bounding the mutual information",
      "text" : "For Theorem 2, we require a somewhat careful bound on the mutual information between the subgradients and the unknown index. We have the following lemma, whose proof we provide in Appendix B.3.\nLemma 7. Let V be drawn uniformly at random from a set V ⊂ {−1, 1}d. Define the distribution P (· | A) on X as in the random sampling scheme (32) and use the loss (33). Let Z be constructed according to the conditional distribution specified by Proposition 2, where Z ∈ {z ∈ Rd : ‖z‖1 ≤ M1}, and define M = M1/L. Then\nI(Z1, . . . , Zn;V ) ≤ nδ2∆(γ)2,\nwhere\nγ := log\n( 2d− 2 + √ (2d − 2)2 + 4(M2 − 1) 2(M − 1) ) and ∆(γ) := eγ − e−γ eγ + e−γ + 2(d− 1) ."
    }, {
      "heading" : "5.3.3 Applying testing inequalities",
      "text" : "The remainder of the proof is similar to that of Theorem 1, except that we apply Lemma 7 in place of Lemmas 4 or 5. Indeed, following identical steps to those in the proof of Theorem 1, we see that with the specified packing V ⊂ {−1, 1}d of size |V| ≥ exp(d/8), we have (recall Eq. (30))\n4\nrLδ EP,Q[ǫn(M, ℓ,Θ, P )] ≥ 1−\nlog 2 log |V| − n δ2∆(γ)2 log |V| ≥ 1− 6 d − 8nδ 2∆(γ)2 d .\nConsequently, if we choose δ = min{ √ d/(8∆(γ) √ n), 1}, then for all d ≥ 9, we have the lower bound\n4 rLδEP,Q[ǫn(M, ℓ,Θ, P )] ≥ 15 , or equivalently\nEP,Q[ǫn(M, ℓ,Θ, P )] ≥ rLδ\n20 =\n1\n20 min\n{ rL, rL √ d\n8 √ n∆(γ)\n} ,\nwhich completes the proof (the case d ≤ 8 is identical to that in Theorem 1)."
    }, {
      "heading" : "5.4 Proof of Theorem 3",
      "text" : "We are somewhat more terse in our proof of Theorem 3 than the previous two, though we repeat the same steps to emphasize our technique."
    }, {
      "heading" : "5.4.1 Constructing well-separated losses",
      "text" : "We begin by choosing the family of loss functions we require: since our optimization domain Θ = {θ ∈ Rd : ‖θ‖1 ≤ r}, we use the linear losses of Section 5.2.1 with the sampling scheme (26) as in Theorem 1. Thus, using the packing set V = {±ei}di=1, we find that ρ⋆(V) = Lrδ, and consequently\n2\nLrδ EP,Q [ǫn(M, ℓ,Θ, P )] ≥ 1−\nlog 2 log(2d) − I(Z1, . . . , Zn;V ) log(2d)\nas earlier."
    }, {
      "heading" : "5.4.2 Bounding the mutual information",
      "text" : "The mutual information bound in this theorem is somewhat more complicated than the previous bounds, as the optimal privacy-preserving distribution (recall Proposition 3) is more complex. We begin by stating a lemma.\nLemma 8. Let V be drawn uniformly at random from V = {±ei}di=1. Let X | V be sampled according to the distribution (26), and let Z | X = x have support on {−1, 1}d and have p.m.f.\nq(z | x) ∝ { exp(α) if z⊤x > k\n1 if z⊤x ≤ k\nfor some k ≥ 0. Define the constants Cd(k) and ∆(δ, α, d, k) by\nCd(k) := card { z ∈ {−1, 1}d : 〈z, x〉 > k } = ⌈(d−k)/2⌉−1∑\ni=0\n( d\ni\n) .\nand\n∆(δ, α, d, k) := δ · e α − 1\n(eα + 1)Cd(k) + 2d\n( d− 1\n⌈(d− k)/2⌉ − 1\n) .\nThen I(Z;V ) ≤ ∆(δ, α, d, k)2 .\nWe provide the proof of the lemma in Appendix B.4.\nFor any α ≤ 5/4, we have eα − 1 ≤ 2α, and by properties of binomial coefficients and Stirling’s approximation we have\n1\n2d\n( d− 1\n⌈(d− k)/2⌉ − 1\n) ≤ 1\n2d\n( d− 1\n⌈d/2⌉ − 1\n) ≤ 1√\nd\nfor any k. For any distributionQ satisfying optimal local differential privacy at a differential privacy level α, Proposition 3 implies Q is a convex combination of distributions with p.m.f.s of the form in Lemma 8. That is, we sample with a channel Q whose p.m.f. is a convex combination of p.m.f.s of the form\nqk(z | x) = 1 eαCd(k) + (2d − Cd(k)) · { exp(α) if z⊤x/M > k 1 if z⊤x/M ≤ k for z ∈ {−M,M}d,\nso Q(Z = z | x) = ∑ k βkqk(z | x) for some βk ≥ 0 with ∑\nk βk = 1. Applying the convexity of mutual information—taking a convex combination of channel distributions Q can only reduce mutual information—and Lemma 8, we thus obtain\nI(Z1, . . . , Zn;V ) ≤ nmax k≥0 ∆(δ, α, d, k)2 (34)\n≤ nδ2(eα − 1)2 max k\n( 1\n(eα + 1)Cd(k) + 2d\n( d− 1\n⌈(d− k)/2⌉ − 1\n))2 ≤ 4nδ2α2 · 1\nd ."
    }, {
      "heading" : "5.4.3 Applying testing inequalities",
      "text" : "As a consequence of the display (34), we have the lower bound\n2\nLrδ EP,Q [ǫn(M, ℓ,Θ, P )] ≥\n1 2 −max k\nn∆(δ, α, d, k)2\nlog(2d) ≥ 1 2 − 4nδ\n2α2\nd log(2d) .\nBy choosing δ = min{ √ d log(2d)/4α √ n, 1}, we find that\n2\nLrδ EP,Q[ǫn(M, ℓ,Θ, P )] ≥\n1 4 ,\nwhich is equivalent to the bound given in the theorem."
    }, {
      "heading" : "5.5 Proof of Theorem 4",
      "text" : "In our proofs of Theorems 4 and 5, we exploit some of our own recent results [12] on the contractive properties of mutual information and KL-divergence under local differential privacy. A few definitions are required in order to state these results. As usual, we have an indexed set of probability measures {Pv}v∈V , and we let Qn(· | x1, . . . , xn) denote the joint probability of the n released private random variables Z1, . . . , Zn. For each v ∈ V, we then define the marginal distribution\nMnv (A) := ∫ Qn(A | x1, . . . , xn)dPnv (x1, . . . , xn) for A ∈ σ(Zn). (35)\nDuchi et al. [12] establish two results that provide bounds on ‖Mnv −Mnw‖TV and I(Z1, . . . , Zn;V ) as a function of the amount of privacy provided and the distances between the underlying distributions Pv.\nThe bounds apply to any channel distribution Q that is α-locally differentially private (for the first result) and to any non-interactive α-locally differentially private channel (for the second result; recall the definition (3)). Let Pv be the distribution of X conditional on the random packing element V = v, and let Mnv be the marginal distribution (35) induced by passing Xi through Q. Define the mixture distribution P = 1|V| ∑ v∈V Pv, and let σ(X ) denote the σ-field on X over which Pv are defined. With this notation we can state the following proposition, which summarizes the results we need from Duchi et al. [12, Theorems 1–2, Corollaries 1–2]:\nProposition 4 (Information bounds). Let the conditions of the previous paragraph hold and assume that Q is α-locally differentially private.\n(a) For all α ≥ 0, Dkl (M n v ‖Mnw) ≤ 4n(eα − 1)2 ‖Pv − Pw‖2TV . (36)\n(b) If Q is non-interactive, then for all α ≥ 0,\nI(Z1, . . . , Zn;V ) ≤ eαn ( eα − e−α )2 sup\nS∈σ(X )\n1 |V| ∑\nv∈V\n( Pv(S)− P (S) )2 . (37)\nWith Proposition 4 in place, we proceed with the proof of Theorem 4. To establish the lower bound, we follow the outline of Section 5.1. Establishing the upper bound requires a few additional steps. We defer the formal proofs of achievability to Appendix C (see C.1), as the proofs are similar to Corollaries 1–3."
    }, {
      "heading" : "5.5.1 Constructing well-separated losses",
      "text" : "Our lower bound uses an identical construction to that in Section 5.2.1. We let the loss function ℓ(x, θ) = L 〈x, θ〉, and we use the distribution (26) on x; that is, we have V = {±ej}dj=1 and for δ ∈ [0, 1/2], we sample vectors from X = {−1, 1}d with probability Pv(X = x) = (1 + δv⊤x)/2d. We then have ρ⋆(V) = Lrδ and |V| = 2d (recall Lemma 2)."
    }, {
      "heading" : "5.5.2 Bounding the mutual information",
      "text" : "With the construction of the (nearly) uniform sampling scheme, we have the following lemma [12, Lemma 7].\nLemma 9. Under the conditions of the previous paragraph, let δ ≤ 1 and V be sampled uniformly from {±ej}dj=1. For any non-interactive α-differentially private channel Q,\nI(Z1, . . . , Zn;V ) ≤ n eα\n4d\n( eα − e−α )2 δ2."
    }, {
      "heading" : "5.5.3 Applying testing inequalities",
      "text" : "Using Lemma 9, we can give an almost immediate proof of the lower bound in Theorem 4. Indeed, using Fano’s inequality (24), Lemmas 1 and 9, and the separation ρ⋆(V) = Lrδ from Lemma 2(b), we obtain\nǫ∗n(L,Θ, α) ≥ Lrδ\n2\n( 1− ne\nα(eα − e−α)2δ2/4d + log 2 log(2d)\n) .\nSo long as d ≥ 2, setting\nδ = min { √ d log(2d)√\neαn(eα − e−α) , 1\n}\nand noting that eα = O(1) and eα − e−α ≤ cα for a universal constant c if α = O(1) completes the proof.\nWhen d = 1, an argument via Le Cam’s method (25) yields an identical result. Given Proposition 4, the argument is quite similar to that used in the proof of Theorem 1. We use the packing set V = {±1} and conditional on V = v, set X = 1 with probability (1 + vδ)/2 and X = −1 with probability (1 − vδ)/2, which yields separation ρ⋆(V) = Lrδ by Lemma 2. We also have the marginal contraction\n∥∥Mn1 −Mn−1 ∥∥2 TV ≤ 1 2 Dkl ( Mn1 ‖Mn−1 ) ≤ 2(eα − 1)2n ‖P1 − P−1‖2TV\nby Pinsker’s inequality and Proposition 4. By construction, the total variation ‖P1 − P−1‖TV = δ, whence we find that ∥∥Mn1 −Mn−1 ∥∥2 TV\n≤ 2(eα − 1)2nδ2. Applying Le Cam’s method (25) and Lemma 1, we obtain\nǫ∗n(L,Θ, α) ≥ Lrδ\n2\n( 1\n2 −\n√ n(eα − 1)δ√\n2\n) .\nTake δ = min{ ( 2 √ 2 √ n(eα − 1) )−1 , 1} to complete the proof in this case."
    }, {
      "heading" : "5.6 Proof of Theorem 5",
      "text" : "The proof of this theorem follows the outline established in Section 5.1, as did the previous results. We defer the attainability results to Appendix C.2."
    }, {
      "heading" : "5.6.1 Constructing well-separated losses",
      "text" : "Before constructing the well-separated loss functions, we exhibit the set V that underlies our sampling distributions. The following lemma exhibits the existence of a special packing of the Boolean hypercube [12, Lemma 5]:\nLemma 10. There exists a packing V of the d-dimensional hypercube {−1, 1}d with ‖v − w‖1 ≥ d/2 for each v,w ∈ V with v 6= w such that the cardinality of V is at least ⌈exp(d/16)⌉ and\n1 |V| ∑\nv∈V\nvv⊤ 25Id×d.\nWith this packing V, we as usual let V ∈ V, and conditional on V = v, we sample X ∈ {±ej}dj=1 according the sampling scheme (32).\nLinear losses (for the bound (18)) We first consider the case that the loss functions are linear functionals that are L-Lipschitz with respect to the ℓp′-norm for some p\n′ ≥ 2, and we optimize over ℓq balls Bq(rq). In this case, we define the loss ℓ(x, θ) = L 〈x, θ〉, and we note that since ‖x‖1 ≤ 1 for x ∈ X , the function ℓ(x, ·) is L-Lipschitz with respect to the ℓ∞-norm. With the sampling scheme (32), Rv(θ) = Lδ 〈v, θ〉 /d. Since infθ∈Bq(rq) 〈v, θ〉 = −‖v‖p when p = (1 − 1/q)−1 is the conjugate of q, we have the pairwise separation\nρ(Rv , Rw) = − rqLδ\nd\n( ‖v + w‖p − ‖v‖p − ‖w‖p ) .\nWith the packing set V exhibited by Lemma 10, we have\n‖v + w‖pp = d∑\nj=1\n(vj + wj) p =\n∑\nj:vj=wj\n2p ≤ 3d 4 2p,\nand ‖v‖p = d1/p for each v ∈ V. This implies the following lower bound on the discrepancy:\nρ⋆(V) ≥ max v 6=w\nρ(Rv, Rw) ≥ rLδ\nd\n( 2d1/p(1− (3/4)1/p) ) ≥ 3\n5 rLδd\n1 p −1\n. (38)\nGeneral loss functions (for the bound (19)) For the general lower bound of the theorem, we use the hinge loss ℓ(x, θ) = L [r − 〈x, θ〉]+ as our loss function. In this case, as in Theorem 2 (recall Lemma 6), our sampling strategy yields that the loss ℓ(x, θ) is an (L, 1) loss, since ‖x‖1 ≤ 1, and we have the discrepancy bound ρ⋆(V) ≥ rLδ2 , since the separation depends only on the distance ‖v − w‖1, which Lemma 10 lower bounds."
    }, {
      "heading" : "5.6.2 Bounding the mutual information",
      "text" : "Using Lemma 10, we may bound the mutual information between samples Z from a particular distribution and a random sample V from a set V of the form in the lemma. Indeed, let V be a packing of the d-dimensional hypercube specified in Lemma 10. Conditional on V = v ∈ {−1, 1}d, we sample the random vector X ∈ {±ej}dj=1 according to the sampling scheme (32). Then we have the following lemma [12, Lemma 6], which applies as long as the channel Q is non-interactive and α-locally differentially private.\nLemma 11. Let Zi be α-locally differentially private for Xi and the conditions of the previous paragraph hold. Then\nI(Z1, . . . , Zn;V ) ≤ n 25eα\n16\nδ2\nd (eα − e−α)2."
    }, {
      "heading" : "5.6.3 Applying testing inequalities",
      "text" : "Our last step is to apply the usual testing inequalities. We first prove the lower bound in inequality (18). Let Llin = Llin(Bq(rq);L, p). Then by applying Lemma 11 and Fano’s inequality (24) to Lemma 1—using the separation (38)—we obtain\nǫ∗n(Llin,Θ, α) ≥ 3rqLδd\n1 p −1\n10\n( 1− 25ne\nαδ2(eα − e−α)2/16d + log 2 d/16\n) .\nSo long as d ≥ 16, we have 16 log 2/d ≤ log 2 < 7/10. Thus choosing\nδ = min\n{ d\n10 √ nCα(eα − e−α) , 1\n}\nand noting that eα − e−α = O(α) and eα = O(1) for α = O(1) we obtain\nǫ∗n(L,Θ, α) ≥ 3rqLδd\n1 p −1\n10 · 1 20\n≥ cmin { rqLd 1 p\n√ nα2\n, rqLd 1 p −1 } = crqLmin { d 1− 1 q\n√ nα2\n, d 1 p −1 } .\nfor a universal constant c. As in the proof of Theorem 4, when d < 16, we apply an essentially similar argument but with Le Cam’s method (25), which gives the desired result. (The proof of the case d = 1 from Theorem 4 applies here as well.) Finally, we remark that we may repeat a completely identical proof as that above replacing d with any k ≤ d, which mutatis mutandis implies the lower bound\nǫ∗n(L,Θ, α) ≥ cLrq max k∈[d] min\n{ k 1− 1 q\n√ nα2\n, k 1 p −1 } ≥ cLrq min { d 1− 1 q\n√ nα2\n, (nα2)\n1 2p\n√ nα2 , 1\n} ,\nwhere for the rightmost bound we have taken k = max{1,min{ √ nα2, d}}. Noting that 1/p = 1−1/q completes the proof of the lower bound (18). To prove inequality (19), we apply the same reasoning as in the proof of the inequality (18). Use Lemma 11 and Fano’s inequality (24) (via Lemma 1 and the separation from Lemma 6) to obtain\nǫ∗n(L,Θ, α) ≥ rLδ\n4\n( 1− 25ne\nα(eα − e−α)2δ2/16d + log 2 d/16\n) .\nThen choosing δ ≍ d/(√n(eα − e−α)) as in the proof of inequality (18) gives the desired result."
    }, {
      "heading" : "5.7 Proof of Corollary 1",
      "text" : "Since Θ ⊆ {θ ∈ Rd : ‖θ‖1 ≤ r}, the bound (14a) guarantees that mirror descent obtains convergence rate O(M∞r √ log(2d)/ √ n). This matches the second statement of Theorem 1. Now fix our desired amount of mutual information I∗. From the remarks following Proposition 1, if we must guarantee\nthat I∗ ≥ supP I(P,Q) for any distribution P and loss function ℓ whose gradients are bounded in ℓ∞-norm by L, we must (because of the uniqueness of the optimal privacy distribution Q) have\nI∗ ≍ dL 2\nM2∞ . (39)\nUp to higher order terms, to guarantee a level of privacy with mutual information I∗, we must allow gradient noise up to a level M∞ = L √ d/I∗. The equality (39) establishes that for a given level of allowed mutual information I∗, if optimal local privacy holds, then we must have M∞ ≍ L √ d/ √ I∗. That is, we have a bijection between I∗ and M∞ whenever optimal local privacy holds,\nso substituting M∞ = L √ d/ √ I∗ into our upper and lower bounds yields the claim."
    }, {
      "heading" : "5.8 Proof of Corollary 2",
      "text" : "According to the conditions of optimal local privacy, if we must guarantee that I∗ ≥ supP I(P,Q) for any loss function ℓ whose gradients are bounded in ℓ1-norm by L, we must have\nI∗ ≍ dL 2\n2M21 ,\nusing Corollary 4 after the statement of Proposition 2. Rewriting this, we see that we must have M1 = L √ d/2I∗ (to higher order terms) to be able to guarantee an amount of privacy I∗. As in the ℓ∞ case, we have a bijection between the multiplier M1 and the amount of information I ∗ and can apply similar techniques. Now recall the convergence guarantee (14b) provided by stochastic gradient descent. Since the ℓ∞-ball of radius r is contained in the ℓ2-ball of radius r2 = r √ d, and\n‖g‖1 ≤ ‖g‖2 for all g ∈ Rd, stochastic gradient descent guarantees that ǫ∗n(L,Θ) ≤ CM1r √ d/ √ n. Applying the lower bound provided by Theorem 2 and substituting for M1 completes the proof."
    }, {
      "heading" : "5.9 Proof of Corollary 3",
      "text" : "Without loss of generality (by scaling), we assume that L = 1. Now we consider Proposition 3, which characterizes the distributions satisfying optimal local differential privacy. We use the proposition to find an upper bound on M∞ in terms of the differential privacy level α, which in turn allows us to apply the bound from mirror descent (14a). Instead of directly using Proposition 3, it is simpler to use the linear program (61) in its proof, and note that finding a lower bound on t (in the LP) as a function of α provides an upper bound on M∞ since M∞ = 1/t. Now, in the linear program (61), we choose the values for q(z) specified by Lemma 19. Let q+ and q− denote the larger and smaller probabilities, respectively. Fix an x ∈ {−1, 1}d, and let z range over {−1, 1}d. With those choices, we note that for d odd,\n∑\nz:〈z,x〉>0\nz = ∑\nz:〈z,x〉=1\nz + ∑\nz:〈z,x〉=3\nz + . . .+ ∑\nz:〈z,x〉=d\nz\n= [( d− 1 d−1 2 ) − ( d− 1 d+1 2 )] x+ [( d− 1 d+1 2 ) − ( d− 1 d+3 2 )] x+ . . . = ( d− 1 d−1 2 ) x.\nFor d even, a similar calculation yields ∑ z:〈z,x〉>0 z = ( d−1 d/2 ) x. As a consequence, we find that\n∑\nz\nzq(z | x) = q+ ∑\nz:〈z,x〉>0\nz + q− ∑\nz:〈z,x〉≤0\nz = x(q+ − q−) · {(d−1 d−1 2 ) d odd\n( d−1 d/2 ) d even.\nFocusing on the odd case for simplicity—identical bounds hold in the even case—we have for a universal constant c > 0 that\n(q+ − q−) ( d− 1 d−1 2 ) = eα − 1 2d−1(eα + 1) ( d− 1 d−1 2 ) ≥ ce α − 1 eα + 1 1√ d ≥ c α√ d ,\nthe first inequality following from Stirling’s approximation and the second from convexity of the function α 7→ eα. In particular, we see that the minimizing value t in the linear program (61) will satisfy t ≥ cα/ √ d, which in turn yields M∞ = 1/t ≤ √ d/(cα). Noting that the lower bound in the corollary is given by Theorem 3, applying the convergence guarantee (14a) of mirror descent based on M∞ completes the proof."
    }, {
      "heading" : "6 Discussion",
      "text" : "We have studied methods for protecting privacy in general statistical risk minimization problems, and have described general techniques for obtaining sharp tradeoffs between privacy protection and estimation rates. The latter are a natural measure of utility for statistical problems.\nWe believe that there are a number of interesting open issues and areas for future work. First, we studied procedures that access each datum only once, and through a perturbed view Zi of the subgradient ∂ℓ(Xi, θ), which is natural in the context of convex risk minimization. A natural question is whether there are restrictions of the class of loss functions so that a transformed version (Z1, . . . , Zn) of the data are sufficient for inference. For instance, other researchers [51, 52] have studied applications in which a data matrix X = [X1 · · · Xn]⊤ ∈ Rn×d is pre-multiplied by a normal matrix Φ ∈ Rm×n, where m ≪ n, and statistical inference is performed using ΦX. For problems such as linear regression and PCA, the resulting estimators enjoy good statistical properties. This transformation, however, cannot be computed without the entire dataset at one’s disposal. Nonparametric data releases, such as those studied by Hall et al. [24], could provide insights here, though again, current approaches require the data to be aggregated by a trusted curator before release.\nOur constraints on the privacy-inducing channel distribution Q require that its support lie in some compact set. We find this restriction useful, but perhaps it possible to achieve faster estimation rates if all we require are moment conditions, for example, EQ[‖Z −X‖2p | X] ≤ M2. A better understanding of general privacy-preserving channels Q for alternative constraints to those we have proposed is also desirable. Moreover, one might consider attempting only to guarantee that φ(X) is private, where φ is some (known) function. For example, members of a dataset may not care if their genders are known, but more personal features of X may be more sensitive.\nThese questions do not appear to have easy answers, especially when we wish to allow each provider of a single datum to be able to guarantee his or her own privacy. Nevertheless, we hope that our view of privacy and the techniques we have developed herein prove fruitful, and we hope to investigate some of the above issues in future work."
    }, {
      "heading" : "A Unbiasedness",
      "text" : "In this appendix, we show that if an optimization procedure receives biased subgradients it is possible to be arbitrarily wrong. We do so by constructing a simple problem instance. Fix a bias b > 0 and consider the following one-dimensional problem:\nminimize f(θ) := bθ\n2 subject to θ ∈ [−c, c].\nIf a gradient oracle returns biased gradients of the form −b/2 at each point θ ∈ [−c, c], it is impossible to distinguish the objective from −bθ/2. The minimizer of this objective is θbias = sign(b)c. The true optimal point is θ∗ = − sign(b)c, yielding the worst possible error\nf(θbias)− f(θ∗) = sup θ∈[−c,c] f(θ)− inf θ∈[−c,c] f(θ).\nWe can show this more formally using an information theoretic derivation similar to that in Section 5. Omitting details, the argument is as follows. In the notation of Section 5, if a bias is chosen independently of the parameters v ∈ V of the risk Rv, then there is a bounded amount of mutual information that can be communicated to any optimization procedure. Consequently, Fano’s inequality (24) guarantees that the estimation accuracy of any procedure must be bounded away from zero."
    }, {
      "heading" : "B Calculation of the Mutual Information for Sampling Strategies",
      "text" : "This appendix is devoted to the proofs of our bounds on mutual information: Lemma 4, Lemma 5, Lemma 7, and Lemma 8. Before proving the lemmas, we make an observation that allows us to tensorize the mutual information, making our arguments simpler (we need only compute the single observation information I(Z1;V )). For each of Lemmas 4, 5, 7, and 8, recall that Z1, . . . , Zn are constructed based on an evaluation of the subgradient set ∂θℓ(Xi, θ), where Xi are independent samples according to a distribution P (· | V ). Then the samples Zi are conditionally independent of V given Xi and the parameters θ, since Z is a random function of ∂ℓ(Xi, θ). Our goal is to upper bound the mutual information between the sequence Z1, . . . , Zn of observed (stochastic) gradients and the random element V ∈ V.\nBy the general definition of mutual information [23, Chapter 5], it is no loss of generality to assume (temporarily) that the random variable Zi are supported on finite sets. Thus (using the chain rule for mutual information [8, 23, Chapter 5]) we have the decomposition\nI(Z1, . . . , Zn;V ) =\nn∑\ni=1\n[H(Zi | Z1, . . . , Zi−1)−H(Zi | V,Z1, . . . , Zi−1)] .\nLet θi denote the point at which the ith gradient is computed. Then by inspection, we must have θi ∈ σ(Z1, . . . , Zi−1). Since Zi is conditionally independent of Z1, . . . , Zi−1 given V and θi and conditioning decreases entropy, we have\nH(Zi | Z1, . . . , Zi−1)−H(Zi | V,Z1, . . . , Zi−1) = H(Zi | Z1, . . . , Zi−1)−H(Zi | V, θi) ≤ H(Zi | θi)−H(Zi | V, θi) = I(Zi;V | θi).\nIn particular, letting Fi denote the distribution of θi, we have\nI(Z1, . . . , Zn;V ) ≤ n∑\ni=1\n∫\nΘ I(Zi;V | θ)dFi(θ) ≤\nn∑\ni=1\nsup θ∈Θ\nI(Zi;V | θ). (40)\nThe representation (40) is the key to our calculations in this appendix.\nIn addition, the proofs of Lemmas 5 and 7 require a minor lemma, which we present here before giving the proofs proper.\nLemma 12. Let 1 > p > δ > 0 and p+ δ ≤ 1. Then\n(p+ δ) log(p + δ) + (p− δ) log(p− δ) > 2p log p.\nProof Since the function p 7→ f(p) = p log p is strictly convex over [0,∞), we may apply convexity. Indeed, p = 12 (p+ δ) + 1 2(p − δ), so\np log p = f\n( 1\n2 (p+ δ) +\n1 2 (p− δ)\n) < 1\n2 f(p+ δ) +\n1 2 f(p− δ),\nwhich is the desired result.\nB.1 Proof of Lemma 4\nThe subgradient set ∂ℓ(Xi; θ) is independent of θ, so we may use the inequality (40) to bound the mutual information of V and a single sample Z while ignoring the dependence on θ. Define M = M∞/L. Since the sampling scheme (26) is independent per-coordinate, we see immediately that if Zj denotes the jth coordinate of Z then\nI(Z;V ) = H(Z)−H(Z | V ) ≤ d log(2) − d∑\nj=1\nH(Zj | V ).\nSince V is uniformly chosen from one of 2d vectors, we additionally find that\nI(Z;V ) ≤ d [ log 2− 1\n2d\n∑\nv∈V\nH(Z | V = v) ] .\nBy the choice of our sampling scheme for X and Z, we see that H(Z | V = v) is identical for each v ∈ V, and we have\nQ(Zj = M∞ | Vj = vj = 0) = Q(Zj = −M∞ | Vj = vj = 0) = 1\n2 .\nOn the other hand, by our choice of sampling scheme, for the “on” index in V , we have\nQ(Zj = −M∞ | Vj = vj = −1) = Q(Zj = M∞ | Vj = vj = 1) = Q(Zj = M∞ | Xj = 1)P (Xj = 1 | Vj = vj = 1)\n+Q(Zj = M∞ | Xj = −1)P (Xj = −1 | Vj = vj = 1)\n=\n( M + 1\n2M\n)( 1 + δ\n2\n) + ( M − 1 2M )( 1− δ 2 ) = 1 2 + δ 2M .\nConsequently, defining the Bernoulli entropy h(p) = −p log p− (1− p) log(1− p), then\nI(Z;V ) ≤ d [ log 2− 1\n2d\n( (2d − 2) log 2 + 2h ( 1\n2 +\nδ\n2M\n))]\n= log 2 +\n( 1\n2 +\nδ\n2M\n) log ( 1\n2 +\nδ\n2M\n) + ( 1\n2 − δ 2M\n) log ( 1\n2 − δ 2M\n) .\nThe concavity of the function p 7→ log(p) yields that log(1/2 + p) ≤ log(1/2) + 2p, so\nI(Z;V ) ≤ log 2 + ( 1\n2 +\nδ\n2M\n)( − log 2 + δ\nM\n) + ( 1\n2 − δ 2M\n)( − log 2− δ\nM\n) = δ2\nM2 .\nMaking the substitution M = M∞/L completes the proof.\nB.2 Proof of Lemma 5\nBy using the inequality (40), a bound on the mutual information I(Z;V | θ) implies a bound on the joint information in the statement of the lemma, so we focus on bounding the mutual information of a single sample Z. In addition, it is no loss of generality to assume that r = 1.\nDefine M = M∞/L to be the multiple of the ℓ∞-norm of the subgradients that we take, and let Zj denote the jth coordinate of Z. Using the coordinate-wise independence of the sampling, we have\nI(Z;V | θ) = H(Z | θ)−H(Z | V, θ) ≤ d log(2)− d∑\nj=1\nH(Zj | Vj, θj).\nNow consider the distribution of Zj given Vj and θj. By symmetry, the distribution has identical entropy for any value of Vj , so we may fix V = v and assume vj = without loss of generality. Then for θj ∈ (−1, 1), the jth component of the subgradient ∂ℓ(X; θ) is −Xj, whence we see that Q(Zj = M∞ | vj = 1, θj) = Q(Zj = M∞ | Xj = 1, θj)P (Xj = 1 | vj = 1) +Q(Zj = M∞ | Xj = −1, θj)P (Xj = −1 | vj = 1)\n= ( M − 1 2M )( 1 + δ 2 ) + ( M + 1 2M )( 1− δ 2 ) = 2M − 2δ\n4M =\n1 2 − δ 2M .\nSimilarly, Q(Zj = −M∞ | vj = 1, θj) = 12 + δ2M . If θj ≥ 1, then we have that the subgradient ∂|θj −Xj | = 1 with probability 1, and thus\nQ(Zj = M∞ | vj = 1, θj) = ( M + 1\n2M\n)( 1 + δ\n2\n) + ( M + 1\n2M )( 1− δ 2 ) = 1 2 ,\nwhich increases the entropy H(Zj | Vj , θj) by Lemma 12. Thus we see that the value θj minimizing the entropy H(Zj | Vj, θj) is given by any θj ∈ (−1, 1), yielding Bernoulli marginal (12 + δ/2M, 12 − δ/2M) on Zj | Vj . Summarizing, we have\nI(Z;V | θ) ≤ d log(2) + d [( 1\n2 +\nδ\n2M\n) log ( 1\n2 +\nδ\n2M\n) + ( 1\n2 − δ 2M\n) log ( 1\n2 − δ 2M\n)] .\nAs in the proof of Lemma 4, we use the concavity of log to see that\nI(Z;V | θ) ≤ d log(2) + d [( 1\n2 +\nδ\n2M\n) (− log(2) + δ/M) + ( 1\n2 − δ 2M\n) (− log(2)− δ/M) ]\n= d\n( 1\n2 +\nδ\n2M\n)( δ\nM\n) + d ( 1\n2 − δ 2M )( − δ M ) = dδ2 M2 .\nApplying the bound (40) and replacing M = M∞/L completes the proof.\nB.3 Proof of Lemma 7\nLetting Z denote a single subgradient sample using the conditional distribution Q specified by Proposition 2, we prove that\nI(Z;V | θ) ≤ δ2∆(γ)2 for any θ ∈ Rd, (41) which implies the lemma by the representation (40). Recall the SVM risk defined using the individual hinge losses (33): by construction, whenever X = ei, then the loss is equal to L [r − θi]+. We have\n∂ℓ(ei, θ) = L { 0 if θi > r −ei otherwise\nand ∂ℓ(−ei, θ) = L {\n0 if θi < −r ei otherwise.\nFor the remainder of this proof, we use the shorthand\nDγ := e γ + e−γ + 2(d − 2)\nfor the denominator in many of our expressions. If X = ei, then ∂ℓ(ei, θ) = Lei or 0 as θi ≤ r or θi > r. Therefore, as we wish to communicate Lei or 0, the construction in Proposition 2 implies\nQ(Z = M1ei | X = ei, θ) = { e−γ Dγ if θi ≤ r\n1 2d if θi > r,\n(42)\nand similarly we have for j 6= i that\nQ(Z = M1ej | X = ei, θ) = { 1 Dγ\nif θi ≤ r 1 2d if θi > r.\n(43)\nFor X = −ei, we have the conditional distribution parallel to (42):\nQ(Z = M1ei | X = −ei, θ) = { eγ Dγ if θi ≥ −r\n1 Dγ if θi < −r.\nFor any given θ, we have that\nI(Z;V | θ) = H(Z | θ)−H(Z | V, θ) ≤ log(2d) − 1|V| ∑\nv∈V\nH(Z | θ, V = v) (44)\nsince the choice of V is uniform and Z takes on at most 2d values. We thus use the conditional distributions (42) and (43) to compute the entropy H(Z | θ, V ) (specifically, the minimal such entropy across all values of θ). To do this, we compute the marginal distribution Q(z | v), arguing that H(Z | θ, V ) is minimal for θ ∈ int[−r, r]d. When θj ∈ (−r, r) for all j, we have\nQ(Z = M1ei | V = v, θ) = d∑\nj=1\nQ(Z = M1ei | X = ej , θ)P (X = ej | V = v)\n+\nd∑\nj=1\nQ(Z = M1ei | X = −ej , θ)P (X = −ej | V = v).\nWhen vi = 1, we thus have that\nQ(Z = M1ei | V = v, θ) = 1 + δ\n2d\ne−γ Dγ + 1− δ 2d eγ Dγ +\n∑\nj 6=i\n1\nDγ\n( 1 + δvj\n2d + 1− δvj 2d\n)\n= eγ + e−γ + δ(e−γ − eγ)\n2dDγ + d− 1 dDγ = 1 2d + δ(e−γ − eγ) 2dDγ , (45a)\nand under the same condition,\nQ(Z = −M1ei | A = v, θ) = eγ + e−γ + δ(eγ + e−γ)\n2dDγ + d− 1 dDγ = 1 2d + δ(eγ − e−γ) 2dDγ . (45b)\nIf for any (possibly multiple) indices j we have θj 6∈ (−r, r), then via a bit of algebra and the conditional distributions (42) and (43), we see that there exists an ǫ ∈ (0, 1) such that\nQ(Z = M1ei | V = v, θ) = ǫ 1\n2d + (1− ǫ)\n( 1\n2d + δ(e−γ − eγ) 2dDγ\n) .\nLemma 12 then implies that if θ ∈ int[−r, r]d while θ′ 6∈ int[−r, r]d, then\nH(Z | θ, V = v) < H(Z | θ′, V = v).\nSince we seek an upper bound on the mutual information, we may thus assume without loss of generality that θ ∈ int[−r, r]d.\nNow we compute the entropy H(Z | θ, v) using the marginal conditional distributions (45a) and (45b), which describe Z | V when θ ∈ int[−r, r]d. Indeed, recall the definition in the statement of the lemma of the difference ∆(γ). For z ∈ {±M1ej}dj=1, define the relation z ∼ v to mean that if z = M1ei, then vi = 1 and if z = −M1ei then vi = −1. We then see that the entropy is H(Z | θ, V = v) = − ∑\nz∼v\nQ(z | v, θ) logQ(z | v, θ)− ∑\nz 6∼v\nQ(z | v, θ) logQ(z | v, θ)\n= −d ( 1\n2d +\nδ∆(γ)\n2d\n) log ( 1\n2d +\nδ∆(γ)\n2d\n) − d ( 1\n2d − δ∆(γ) 2d\n) log ( 1\n2d − δ∆(γ) 2d\n) .\nAs in the proofs of Lemmas 4 and 5, we use the concavity of log(·) to see that\n−H(Z | θ, V = v) = ( 1\n2 +\nδ∆(γ)\n2\n) log ( 1\n2d +\nδ∆(γ)\n2d\n) + ( 1\n2 − δ∆(γ) 2\n) log ( 1\n2d − δ∆(γ) 2d\n)\n≤ ( 1\n2 +\nδ∆(γ)\n2\n) (− log(2d) + δ∆(γ)) + ( 1\n2 − δ∆(γ) 2\n) (− log(2d)− δ∆(γ))\n= − log(2d) + δ2∆(γ)2.\nInvoking the earlier bound (44) and adding log(2d) to the above expression completes the proof of the claim (41).\nB.4 Proof of Lemma 8\nLet Zj denote the jth coordinate of Z. We first argue that conditional on V , the random variable Z has independent coordinates. Indeed, let q+ = q(z | x) for z such that z⊤x > k and q− = e−αq+. Without loss of generality, we may take V = e1, the first basis vector, and hence\nQ(Z = z | V = e1) = ∑\nx∈{−1,1}d\nQ(Z = z | X = x)P (X = x | V = e1)\n= 1\n2d−1\n∑\nx∈{−1,1}d\nQ(Z = z | X = x) · 1 + x1δ 2\n= 1\n2d−1\n[ ∑\nx:〈z,x〉>k\nq+ 1 + x1δ\n2 +\n∑\nx:〈z,x〉≤k\nq− 1 + x1δ\n2\n] . (46)\nNow, if z1 = 1, then\n∑\nx:〈x,z〉>k\n1 + x1δ\n2 =\n∑\nx:〈x,z〉>k,x1=1\n1 + δ\n2 +\n∑\nx:〈x,z〉>k,x1=−1\n1− δ 2 = 1 + δ 2 Cd−1(k−1)+ 1− δ 2 Cd−1(k+1)\nand similarly\n∑\nx:〈x,z〉≤k\n1 + x1δ\n2 =\n1 + δ\n2\n( 2d−1 − Cd−1(k − 1) ) +\n1− δ 2\n( 2d−1 − Cd−1(k + 1) ) .\nOn the other hand, we find that if z1 = −1, then similar equalities hold, but with the counters Cd−1(k − 1) and Cd−1(k + 1) flipped:\n∑\nx:〈x,z〉>k\n1 + x1δ\n2 =\n1 + δ\n2 Cd−1(k + 1) + 1− δ 2 Cd−1(k − 1)\n∑\nx:〈x,z〉≤k\n1 + x1δ\n2 =\n1 + δ\n2\n( 2d−1 − Cd−1(k + 1) ) +\n1− δ 2\n( 2d−1 − Cd−1(k − 1) ) .\nIn particular, we find that so long as the first coordinate z1 = z ′ 1 of z remains constant, then Q(Z = z | V = e1) = Q(Z = z′ | V = e1), and that we thus have Z2, . . . , Zd are distributed uniformly at random in {−1, 1}d.\nWe now determine q+ and compute the marginal value Q(Z1 = 1 | V = e1). For the first, we note that\nCd(k)q + + (2d − Cd(k))q− = 1, or Cd(k)q+ + e−α(2d − Cd(k))q+ = 1,\nwhich yields the expressions\nq+ = eα\n(eα − 1)Cd(k) + 2d and q− =\n1\n(eα − 1)Cd(k) + 2d .\nBy the expression (46) and calculations following, we thus find that when z1 = 1, we have\nq(z | e1) = 1 2d−1 · [ q+ (1 + δ 2 Cd−1(k − 1) + 1− δ 2 Cd−1(k + 1) )\n+ q− (1 + δ\n2 (2d−1 − Cd−1(k − 1)) + 1− δ 2\n(2d−1 − Cd−1(k + 1)) )]\n= 1 2d−1 · [ 2d−1q− + 1 2 (q+ − q−)(Cd−1(k − 1) + Cd−1(k + 1))\n+ δ\n2 (q+ − q−)(Cd−1(k − 1)− Cd−1(k + 1))\n] , (47a)\nand similarly when z1 = −1 we have\nq(z | e1) = 1 2d−1 · [ 2d−1q− + 1 2 (q+ − q−)(Cd−1(k − 1) + Cd−1(k + 1))\n− δ 2 (q+ − q−)(Cd−1(k − 1)− Cd−1(k + 1))\n] . (47b)\nNow note that\nCd−1(k − 1)− Cd−1(k + 1) = ⌈(d−k)/2⌉−1∑\ni=0\n( d− 1 i ) − ⌈(d−k)/2⌉−2∑\ni=0\n( d− 1 i ) = ( d− 1 ⌈(d− k)/2⌉ − 1 )\nand that the difference\nq+ − q− = e α − 1\n(eα − 1)Cd(k) + 2d .\nRecalling the definition of the constant ∆, we thus find from the expansions (47a) and (47b)—since they must sum to 1—that\nQ(Z = z | V = e1) = 1 2d−1 · { 1 2 + ∆(δ,α,d,k) 2 if z1 = 1\n1 2 − ∆(δ,α,d,k) 2 if z1 = −1.\n(48)\nIt is clear that similar statements hold in the other symmetric cases (i.e. if V = −e2, then the probabilities depend on z2 = −1 or 1).\nIt remains to use the marginalized representation (48) to compute the bound on the mutual information in the statement of the lemma. Given V = v, Z ∈ {−M,M}d is uniform except on the coordinate j for which vj 6= 0, by symmetry. (Marginally, Z is uniform on {−M,M}d.) By a direct calculation, we have H(Z) = d log 2 and\nH(Z | V = e1) = d∑\nj=1\nH(Zj | Z1:j−1, V = e1) = H(Z1 | V = e1) + (d− 1) log 2,\nand similarly for the other possible values of V . Therefore, using the probabilities (48), we have the mutual information bound\nI(Z;V ) = H(Z)−H(Z | V ) ≤ d log 2− 1 2d\n∑\nv\nH(Z | V = v)\n= d log 2− (d− 1) log 2\n+\n( 1\n2 +\n∆(δ, α, d, k)\n2\n) log ( 1\n2 +\n∆(δ, α, d, k)\n2\n) + ( 1\n2 − ∆(δ, α, d, k) 2\n) log ( 1\n2 − ∆(δ, α, d, k) 2\n)\n≤ log 2 + ( 1\n2 +\n∆(δ, α, d, k)\n2\n)[ log 1\n2 + ∆(δ, α, d, k)\n] + ( 1\n2 − ∆(δ, α, d, k) 2\n)[ log 1\n2 −∆(δ, α, d, k)\n]\n= ∆(δ, α, d, k)2 ,\nwhere the inequality follows from the concavity of p 7→ log(p).\nB.5 Bounds on total variation norm\nLemma 13. Let Q1 and Q−1 be distributions on {−1, 1}, where\nQ1(Z = z) = 1\n2 +\n1 2 · { δ if z = 1 −δ otherwise and Q−1(Z = z) = 1 2 + 1 2 · { −δ if z = 1 δ otherwise.\nLet Qni denote the n-fold product distribution of Qi. Then for δ ∈ [0, 1/3], ∥∥Qn1 −Qn−1 ∥∥ TV ≤ δ √ (3/2)n.\nProof For any two probability distributions P,Q, Pinsker’s inequality [8] asserts that the total variation norm is bounded as ‖P −Q‖TV ≤ √ Dkl (P‖Q) /2. Applying this inequality in our setting, we find that\n∥∥Qn1 −Qn−1 ∥∥ TV ≤ √ 1\n2 Dkl\n( Qn1‖Qn−1 ) =\n1√ 2\n√ nDkl (Q1‖Q−1),\nwhere we have exploited the product nature of Qni . Now we note that by the concavity of the log, we have (via the first-order inequality) that log 1+δ1−δ ≤ 2δ/(1 − δ), so\n1 + δ\n2 log\n1+δ 2 1−δ 2 + 1− δ 2 log 1−δ 2 1+δ 2 = 1 + δ 2 log 1 + δ 1− δ + 1− δ 2 log 1− δ 1 + δ = δ log 1 + δ 1− δ ≤ 2δ2 1− δ .\nAssuming that δ ≤ 1/3, the final term is upper bounded by 3δ2. But of course by definition of Q1 and Q−1, we have\nDkl (Q1‖Q−1) = 1 + δ\n2 log\n1+δ 2 1−δ 2 + 1− δ 2 log 1−δ 2 1+δ 2 ≤ 3δ2,\nwhich completes the proof."
    }, {
      "heading" : "C Achievability by stochastic mirror descent",
      "text" : "In this appendix, we provide further details on the algorithm used to achieve the upper bounds in Theorems 4 and 5. Both of our achievability results rely on stochastic gradient mechanisms, and their most important ingredient is a conditional distribution Q that satisfies α-local differential privacy. In particular, if g ∈ Rd is a (sub)gradient of the loss ℓ(x, θ), we construct Z ∈ Rd by perturbing g in such a way that E[Z | g] = g. Thus, each of the achievability guarantees consists of describing an α-differentially private sampling distribution, then bounding the expected norm of Z and applying one of the convergence guarantees (14).\nC.1 Achievability in Theorem 4\nThe sampling strategy we use is essentially identical to that used in Corollary 3 (and the optimal α-private scheme of Proposition 3; see also Strategy B in our paper [12]). Let πα := e\nα/(eα+1) and T be a Bernoulli(πα)-random variable, and let B ≥ L be a fixed constant (to be specified). Then given a vector g ∈ Rd with ‖g‖∞ ≤ L, construct g̃ ∈ Rd with coordinates g̃j sampled independently from {−L,L} with probabilities 1/2 − gj/(2L) and 1/2 + gj/(2L). Then sample T and set\nZ ∼ { Uniform(z ∈ {−B,B}d : 〈z, g̃〉 > 0) if T = 1 Uniform(z ∈ {−B,B}d : 〈z, g̃〉 ≤ 0) if T = 0.\n(49)\nBy inspection, the scheme (49) is α-differentially private. Moreover, we have by the calculations in the proof of Corollary 3 (see Section 5.9) that by the sampling strategy (49)\nE[Z | g] = E[E[Z | g̃] | g] = g B 2d−1L eα − 1 eα + 1\n· {(d−1 d−1 2 ) d odd\n(d−1 d/2 ) d even.\nThus, w.l.o.g. assuming d is odd, choosing\nB = 2d−1L eα + 1\neα − 1 ( d− 1 d−1 2 )−1 implies E[Z | g] = g and ‖Z‖∞ = B = O(1)(L/α) √ d.\nApplying the mirror descent method to the gradients provided from the sampling strategy (49), we obtain the bound (14a) with M∞ = B = O(1)(L/α) √ d, which is our desired result.\nC.2 Achievability in Theorem 5\nThe achievability result for Theorem 5 is similar to that for Theorem 4, but we use a modified sampling distribution. Now, using the same notation as that for the strategy (49), we use the following. Given a vector g with ‖g‖2 ≤ L, set g̃ = Lg/ ‖g‖2 with probability 12 + ‖g‖2 /2L and g̃ = −Lg/ ‖g‖2 with probability 12 − ‖g‖2 /2L. Then sample T ∼ Bernoulli(πα) and set\nZ ∼ { Uniform(z ∈ Rd : 〈z, g̃〉 > 0, ‖z‖2 = B) if T = 1 Uniform(z ∈ Rd : 〈z, g̃〉 ≤ 0, ‖z‖2 = B) if T = 0.\n(50)\n(This is Strategy A in our paper [12].) Then we have [12, Appendix D.1] that\nE[Z | g] = B L eα − 1 eα + 1 Γ(d2 + 1)√ πdΓ(d−12 + 1) ,\nso choosing\nB = L eα + 1\neα − 1\n√ πdΓ(d−12 + 1)\nΓ(d2 + 1) ≤ Le\nα + 1 eα − 1 3 √ π √ d 2\nimplies that E[Z | g] = g and ‖Z‖2 ≤ B = O(1)(L/α) √ d. Applying the stochastic gradient descent method to the gradients provided by the sampling scheme (50), we obtain the bound (14b) with M2 = B, which implies that if Θ ⊂ B2(r2) then\nE[R(θ̂n)]−R(θ∗) = O (√ d\nα Lr2√ n\n) .\nNoting that Bq(rq) ⊂ d 1 2 − 1 qB2(rq) completes the proof of the achievability result."
    }, {
      "heading" : "D Background on Conditional Probabilities",
      "text" : "In this appendix, we present some basic lemmas on conditional independence and regular conditional probabilities that will be useful in Appendix E.\nWe first recall the following classical data-processing inequality, which holds for essentially arbitrary random variables [23, Chapter 5]:\nLemma 14 (Data processing). Let X → Z → Y be a Markov chain. Then I(X;Y ) ≤ I(X;Z), with equality if and only if X is conditionally independent of Y given Z.\nThis inequality, in conjunction with with Carathéodory and Minkowski’s finite-dimensional version of the Krein-Milman theorem (e.g. [26]), allows us to argue any Q minimizing I(P,Q) must be supported on the extreme points of D. To make this point precise, however, we need to address certain measurability issues involved in the choice of the extreme points.\nWe begin with a precise definition of a regular conditional probability.\nDefinition 5. Let (Ω,F) and (T, σ(T )) be measurable spaces. A regular conditional probability, also known as a Markov kernel or transition probability, is a function ν : T ×F → [0, 1] such that\nt 7→ ν(t, A) is measurable for all A ∈ F ν(t, ·) : F → [0, 1] is a probability measure for all t ∈ T.\nAny Markov chain has a transition probability; conversely, any set of consistent transition probabilities define a Markov chain (see, e.g., Chapter 5 of Kallenberg [27]).\nSome difficulties with measurability arise in constructing the appropriate Markov chain for our setting. To deal with them, we use results from Choquet theory, which extend Krein-Milman theorems to integral representations [39]. We begin our proof by stating a measurable selection theorem [39, Theorem 11.4], though we restrict the theorem’s statement to subsets of finite dimensional space.\nProposition 5. Let D ⊂ Rd be a compact convex set. For each x, there exists a probability measure µx supported on Ext(D) such that ∫ D ydµx(y) = x. Moreover, the mapping x 7→ µx can be taken to be measurable.\nIn the statement of this result, measurability is taken with respect to the σ-field generated by the topology of weak convergence. As a consequence of the proposition, however, it is clear that since for any continuous function f the mapping x 7→ ∫ fdµx is measurable, we have that for relatively open sets A ⊂ C the mapping x 7→ µx(A) is measurable, whence for any measurable set A ⊂ C the mapping x 7→ µx(A) is measurable. That is, we can define the Markov kernel ν : Rd×σ(C) → [0, 1] according to the mapping specified by Proposition 5 (we take ν(x, ·) = µx) with the additional properties that\n∫\nD yν(x, dy) = x and ν(x,D \\ Ext(D)) = 0 for all x ∈ D.\nIn finite dimensions, a trivial extension of Proposition 5 allows us to drop the assumption that D is convex. Indeed, we have that since D is compact, then Ext(D) = Ext(Conv(D)) [26, Chapter III.2].\nGiven this measure-theoretic background, we turn to a key lemma that we will need in Appendix E. In this lemma, we assume as usual that C ⊂ D ⊂ Rd are compact sets, and that Q ∈ Q(C,D) (recall the definition (10b)).\nLemma 15. Let P be a distribution supported on C. If there exists a set A ⊂ C with P (A) > 0 and a set B ⊂ D \\ Ext(D) with Q(B | X = x) > 0 for x ∈ A, there exists a regular conditional probability distribution Q′ ∈ Q(C,D) where Q′(· | x) has support contained in Ext(D) and\nI(P,Q) > I(P,Q′).\nParaphrasing the lemma slightly, we have that any conditional distribution Q minimizing I(P,Q) must (outside of a set of measure zero) be completely supported on the extreme points Ext(D). Proof For any y ∈ D, Proposition 5 guarantees that we can represent y as the (regular conditional) measure ν(y, ·). Thus we can define a random variable Zy distributed according to ν(y, ·), whose existence we are guaranteed by standard constructions [4, 27] with regular conditional probability. Then E[Zy] = ∫ D zν(y, dz) = y, and moreover, we can define the measurable version of the conditional expectation E[ZY | Y ] via\nE[ZY | Y ] = ∫\nD zν(Y, dz) = Y\nso we have the (almost sure) chain of equalities\nE[ZY | X = x] = E[E[ZY | Y ] | X = x] = ∫\nD E[ZY | Y = y]dQ(y | X = x)\n=\n∫\nD\n∫\nD zν(y, dz)dQ(y | X = x) =\n∫\nD ydQ(y | X = x) = x.\nBy construction, X → Y → Z is a valid Markov chain, and since the sets A and B satisfy P (A) > 0 and ∫ AQ(B | X = x)dP (x) > 0, we see that I(X;Y ) > I(X;Z) by Lemma 14.\nWe turn to an analogue of Lemma 15 in the differentially private setting.\nLemma 16. Let the conditions of Lemma 15 hold, and let P be a distribution supported on C. If there exists a set A ⊂ C with P (A) > 0 and a set B ⊂ D \\ Ext(D) with Q(B | X = x) > 0 for x ∈ A, there exists a regular conditional probability distribution Q′ ∈ Q (C,D) where Q′(· | x) has support contained in Ext(D), satisfies\nI(P,Q) > I(P,Q′),\nand has no worse differential privacy than Q:\nsup S∈σ(D) sup x,x′∈C Q′(S | X = x) Q′(S | X = x′) ≤ supS∈σ(D) sup x,x′∈C Q(S | X = x) Q(S | X = x′) .\nProof Let ν : Rd × σ(C) → [0, 1] be the Markov kernel defined in the proof of Lemma 15, and without loss of generality assume that Q(· | X = x) and Q(· | X = x′) have density q with respect to an underlying measure µx,x′. Define the distribution\nQ′(S | X = x) := ∫\nD\n∫\nD ν(y, dz)q(y | x)dµx,x′(y).\nBy assumption, if Q is α-differentially private, then for µ-almost all y ∈ D, we have q(y | x) ≤ eαq(y | x′). We find that\nQ′(S | X = x) = ∫\nD\n∫\nD ν(y, dz)q(y | x)dµx,x′(y)\n≤ ∫\nD\n∫\nD ν(y, dz)eαq(y | x′)dµx,x′(y) = eαQ′(S | X = x′),\nso Q′ is at least as differentially private as Q.\nFinally, we will need the following standard maximum entropy result. Let z denote a discrete random variable and let q(z | x) denote the conditional probability mass function of Z | X = x. Consider the finite dimensional entropy maximization problem\nminimize q\n∑\nz\nq(z | x) log q(z | x) (51)\nsubject to ∑\nz\nzq(z | x) = x, ∑\nz\nq(z | x) = 1, q(z | x) ≥ 0 for all z.\nWe have the following lemma, which establishes the form of the solution to the problem (51). We include a proof for completeness.\nLemma 17. The p.m.f. q(· | x) solving problem (51) is given by\nq(z | x) = exp(−µ ⊤z)∑\nz′ exp(−µ⊤z′) , (52)\nwhere µ ∈ Rd is any vector chosen to satisfy the constraint ∑\nz zq(z | x) = x. Such a µ ∈ Rd exists. Proof We may write the Lagrangian with dual variables µ ∈ Rd, λ(z) ≥ 0, and θ ∈ R, L(q, µ, λ, θ) = ∑\nz\nq(z | x) log q(z | x)+µ⊤ (∑\nz\nzq(z | x)−x ) +θ (∑\nz\nq(z | x)−1 ) − ∑\nz\nλ(z)q(z | x).\nSince the problem (51) has convex cost, linear constraints, and non-empty domain, strong duality obtains [6, Chapter 5], and the KKT conditions hold for the problem. Thus, minimizing q out of L to find the dual, we take derivatives with respect to the m variables q(z | x) for z = (1 + α)ui and find the optimal conditional p.m.f. q must satisfy\nlog q(z | x) + 1 + µ⊤z + θ − λ(z) = 0, or q(z | x) = exp(λ(z) − 1− θ) exp(−µ⊤z). In particular, we see that since q(z | x) > 0, we must have λ(z) = 0 by complementarity, and (satisfying the summability constraint ∑ z q(z | x) = 1) we see that\nq(z | x) = exp(−µ ⊤z)∑\nz′ exp(−µ⊤z′) ,\nwhere µ ∈ Rd is any vector chosen to satisfy the constraint ∑z zq(z | x) = x. The existence of such a µ is guaranteed by the attainment of the KKT conditions."
    }, {
      "heading" : "E Proofs of Minimax Mutual Information Characterizations",
      "text" : "In this section, we provide the proofs of the results stated in Section 4, all of which follow a broadly similar outline. We make use of Lemma 15 to guarantee that any conditional distribution Q minimizing the mutual information I(P,Q) must be supported on the extreme points of the set D. This allows us to reduce computing maximal entropies and minimal mutual information values to finite dimensional convex programs, whose optimality we can check using results from convex analysis and optimization.\nE.1 Proof of Theorem 6\nWe begin by considering supP , where Q ∗ is defined as in the statement of the theorem. Since the support of Q∗ is finite (there are m extreme points of D), we have\nI(P,Q∗) = I(X;Z) = H(Z)−H(Z | X) ≤ log(m)−H(Z | X)\n= log(m)− ∫ H(Z | X = x)dP (x).\nNow, for any distribution P on the set C and for any x ∈ suppP , we can write x as x = ∑i βi(x)ui, where ui are the extreme points of C, and where βi(x) ≥ 0 and ∑ i βi(x) = 1 (using the KreinMilman theorem). Define the individual probability mass functions qi to be the maximum entropy p.m.f. (52) for each of the extreme points ui. Then we can define the conditional probability mass function by\nq(· | x) = ∑\ni\nβi(x)q i(·).\n(Without loss of generality, we may assume the βi are continuous, since the set of extreme points is finite, and thus q(· | x) can be viewed as a regular conditional probability. We can make this formal using the techniques in the proof of Lemma 15.) Denoting H(q(· | x)) := H(Z | X = x), we can use the convexity of the negative entropy to see that\nI(P,Q∗) ≤ log(m)− ∫ ∑\ni\nβi(x)H(q i(·))dP (x). (53)\nBy symmetry, the entropy H(qi(·)) = H(Q∗(· | X = ui)) is a constant determined by the maximum entropy distribution (52), and thus\nI(P,Q∗) ≤ log(m)−H(Q∗(· | X = ui)). (54)\nEquality in the upper bound (54) is attained by taking P ∗ to be the uniform distribution on the extreme points {ui} of C.\nIt remains to establish an identical lower bound for I(P ∗, Q) over all conditional distributions Q satisfying the constraints of the theorem statement. We know from Lemma 15 that Q must be supported on (1 + κ)ui for i = 1, . . . ,m. Denoting by q(z | x) the p.m.f. of Q conditional on x (for x in the finite set of extreme points of C that make up the support suppP ∗), we can write minimizing the mutual information as the parametric convex optimization problem\nminimize q\n∑\nz\n( ∑\nx\nq(z | x)p(x) ) log ( ∑\nx\nq(z | x)p(x) ) − ∑\nx\np(x) ∑\nz\nq(z | x) log q(z | x) (55)\nsubject to ∑\nz\nq(z | x) = 1 for all x, ∑\nz\nzq(z | x) = x for all x, q(z | x) ≥ 0 for all x, z.\nIn the problem (55), the sums over x and z are over the extreme points of C and D, respectively and p is the uniform distribution with p(x) = 1/m. Mutual information is convex in the conditional distribution q; moreover, it is strictly convex except when q(z | x) = ∑x′ q(z | x′)p(x′) for all x, z. (This can be seen by an inspection of the proof of Theorem 2.7.4 by Cover and Thomas [8].) In our case, since Q∗ does not satisfy this equality, the uniqueness of Q∗ as the minimizer of I(P ∗, Q∗) will follow if we show that Q∗ is a minimizer at all.\nWe proceed to solve the problem (55). Writing I(p, q) as a shorthand for the mutual information, we introduce Lagrange multiplers θ(x) ∈ R for the normalization constraints, µ(x) ∈ Rd for the conditional expectation constraints, and λ(x, z) ≥ 0 for the nonnegativity constraints. This yields the Lagrangian L(q, µ, λ, θ) = I(p, q)− ∑\nx,z\nλ(x, z)q(z | x)+ ∑\nx\nµ(x)⊤ (∑\nz\nzq(z | x)−x ) + ∑\nx\nθ(x)\n(∑\nz\nq(z | x)−1 ) .\nIf we can satisfy the Karush-Kuhn-Tucker (KKT) conditions (see, e.g., [6]) for optimality of the problem (55), we will be done. Taking derivatives with respect to q(z | x), we see\n∂ ∂q(z | x)L(q, µ, λ, θ) = p(x) [log(q(z | x)) + 1]− p(x) log (∑\nx′\nq(z | x′)p(x′) )\n− q(z) · 1 q(z) p(x)− λ(z, x) + θ(x) + µ(x)⊤z\n= p(x) log q(z | x)− p(x) log (∑\nx′\nq(z | x′)p(x′) ) − λ(z, x) + θ(x) + µ(x)⊤z,\nwhere we set q(z) = ∑\nx′ q(z | x′)p(x′) for shorthand. Now, we use symmetry to note that since we have chosen q to be the maximum entropy distribution (52) for each x in the extreme points {ui} of C, the marginal q(z) = ∑ x′ q(z | x′)p(x′) = 1/m is uniform by the symmetry of the set D and since p is uniform. In addition, since q(z | x) > 0 strictly, we have λ(z, x) = 0 by complementarity. Thus, at q chosen to be the maximum entropy distribution, we can rewrite the derivative of the Lagrangian\n∂ ∂q(z | x)L(q, µ, λ, θ) = 1 m log q(z | x)− 1 m log 1 m + θ(x) + µ(x)⊤z.\nRecalling the definition (52) of q(z | x), and denoting the maximum entropy parameters µ there by µ∗(x), we have\n∂ ∂q(z | x)L(q, µ, λ, θ) = − 1 m µ∗(x)⊤z + 1 m log\n( ∑\nz′\nexp(−µ∗(x)⊤z′) )\n− 1 m log 1 m + θ(x) + µ(x)⊤z.\nNow, by inspection we may set\nθ(x) = 1\nm log\n1 m − 1 m log\n( ∑\nz′\nexp(−µ∗(x)⊤z′) ) and µ(x) = 1\nm µ∗(x),\nand we satisfy the KKT conditions for the mutual information minimization problem (55). Summarizing, the conditional distribution Q∗ specified in the statement of the theorem as the maximum entropy distribution (52) satisfies\ninf Q\nI(P ∗, Q) ≥ I(P ∗, Q∗),\nwhich, when combined with the first part of the proof, gives the saddle point inequality\nsup P I(P,Q∗) ≤ log(m)−H(q(· | X = ui)) = I(P ∗, Q∗) ≤ inf Q I(P ∗, Q),\nas claimed.\nRemarks In the proof of the theorem, we have defined Q∗(· | x) as a conditional distribution only for x ∈ Ext(C), the extreme points of C. This can easily be remedied: take Q∗(· | x) to be the distribution maximizing the entropy H(Z | X = x) for each x ∈ C under the constraint that the support of Z be contained in Ext(D). This is equivalent to—for each x ∈ C—choosing Z = zi for zi ∈ Ext(D), i = 1, . . . ,m, with probability qi, where q ∈ Rm solves the entropy maximization problem\nmaximize q∈Rm\n− ∑\ni\nqi log qi subject to ∑\ni\nziqi = x, ∑\ni\nqi = 1, qi ≥ 0.\nInspecting the proof of Theorem 6 (see the bound (53)) shows that this choice can only decrease the mutual information I(X;Z). Additionally, the strong convexity of the entropy over the simplex guarantees that the solutions to this optimization problem are continuous in x (see Chapter X of Hiriart-Urruty and Lemaréchal [26]) so this distribution q(· | x) defines a measurable random variable as desired.\nE.2 Proof of Proposition 1\nBy scaling, we may assume w.l.o.g. that L = 1 and M ≥ 1. Using Theorem 6 (and the remarks immediately following its proof), we can focus on maximizing the entropy of the random variable Z conditional on X = x for each fixed x ∈ [−1, 1]d. Let Zi denote the ith coordinate of the random vector Z; we take the conditional distribution of Zi to be independent of Zj and let Z be distributed as\nZi | X = { M w.p. 12 + Xi 2M\n−M w.p. 12 − Xi 2M .\n(56)\nLet us now verify that the distribution (56) maximizes the entropy H(Z | X = x). Indeed, we may fix x (leaving it implicit in the vector [q(z)]z := [q(z | x)]z), and we solve the entropy maximization problem\nminimize q\n−H(q) subject to ∑\nz\nq(z) = 1, q(z) ≥ 0, ∑\nz\nzq(z) = x, (57)\nwhere all sums are taken over z ∈ Ext([−M,M ]d) = {−M,M}d. Introducing the Lagrange multipliers µ ∈ Rd, λ(z) ≥ 0, and θ ∈ R, we find that problem (57) has the Lagrangian\nL(q, µ, λ, θ) = −H(q)− ∑\nz\nλ(z)q(z) + µ⊤ (∑\nz\nzq(z)− x ) + θ (∑\nz\nq(z)− 1 ) .\nTo find the infimum of the Lagrangian with respect to q, we take derivatives (since we make the identification q ∈ R2d). We see that\n∂\n∂q(z) L(q, µ, λ, θ) = log(q(z)) + 1− λ(z) + θ + µ⊤z.\nWith the definition (56) of the probability mass function q (that zi are independent Bernoulli random variables with parameters 12 + xi/2M), the coordinate conditional distributions are\nq(zi | xi) = ( 1\n2 +\n1\n2M\n) 1 2 + xizi 2M ( 1\n2 − 1 2M\n) 1 2 − xizi 2M\n.\nTheorem 6 says that without loss of generality we may assume that x ∈ {−1, 1}d, the full probability mass function q can be written\nq(z) =\n( 1\n2 +\n1\n2M\n) d 2 +x ⊤z 2M ( 1\n2 − 1 2M\n) d 2 −x ⊤z 2M\n. (58)\nPlugging the conditional (58) results in\n∂\n∂q(z) L(q, µ, λ, θ)\n=\n( d\n2 +\nx⊤z\n2M\n) log ( 1\n2 +\n1\n2M\n) + ( d\n2 − x\n⊤z\n2M\n) log ( 1\n2 − 1 2M\n) + 1− λ(z) + θ + µ⊤z\n= d\n2\n[ log ( 1\n2 +\n1\n2M\n) + log ( 1\n2 − 1 2M\n)] + x⊤z\n2M\n[ log ( 1\n2 +\n1\n2M\n) − log ( 1\n2 − 1 2M\n)]\n+ 1− λ(z) + θ + µ⊤z.\nPerforming a few algebraic manipulations with the logarithmic terms, the final equality becomes\nd log\n(√ (M + 1)(M − 1)\nM\n) + x⊤z\nM log\n(√ M + 1\nM − 1\n) + 1− λ(z) + θ + µ⊤z.\nThe complementarity conditions for optimality [6] imply that λ(z) = 0, and since the equality constraints in the problem (57) are satisfied, we can choose θ and µ arbitrarily. Taking\nθ = −d log (√\n(M + 1)(M − 1) M\n) − 1 and µ = −x 1\nM log\n(√ M + 1\nM − 1\n)\nyields that the partial derivatives of L are 0, which shows that indeed our choice of Q∗ is optimal.\nE.3 Proof of Proposition 2\nThe proof follows along lines similar to the ℓ∞ case: we compute the maximum entropy distribution subject to the constraint that E[Z] = x for some x ∈ Rd with ‖x‖1 ≤ 1, and Z must be supported on the extreme points ±Mei of the ℓ1-ball of radius M . (Recall that ei ∈ Rd are the standard basis vectors.) Based on Theorem 6, in order to find the minimax mutual information, we need only consider the cases where x = ±ei for some i ∈ {1, . . . , d}.\nFollowing this plan, we recall the entropy maximization problem (57), where now x = ±ei and the sums are over z ∈ M{±ei}di=1. As in the proof of Proposition 1, we can write the Lagrangian and take its derivatives, finding that for z = ±Mei we have\n∂\n∂q(z) L(q, µ, λ, θ) = log(q(z)) + 1− λ(z) + θ − µ⊤z.\nSolving for q(z), we find that\nq(z) = exp(λ(z)− 1− θ) exp(µ⊤z),\nbut complementarity [6] guarantees that λ(z) = 0 since q(z) > 0, and normalizing we may write q(z) = exp(−µ⊤z)/ exp(−µ⊤∑z′ z′), where the sum is over the extreme points of the ℓ1-ball of radius M . In particular, q(Mei) ∝ e−µi and q(−Mei) ∝ eµi . Without loss of generality, let x = ei. Symmetry suggests we take (and we verify this to be true)\nq(z) = exp(−1− θ)    exp(µi) if z = Mei\nexp(−µi) if z = −Mei exp(0) otherwise.\n(59)\nIndeed, with the choice (59) of q, we have q(Mej)− q(−Mej) = 0 for j 6= i, while (setting γ = µi and normalizing appropriately)\nq(Mei)− q(−Mei) = eγ e−γ + eγ + 2(d − 1) − e−γ e−γ + eγ + 2(d − 1) .\nThus, if we can solve the equation Mq(Mei) − Mq(−Mei) = 1, we will be nearly done. To that end, we write\neγ − e−γ eγ + e−γ + 2(d− 1) = 1 M or β − β−1 = 1 M ( β + β−1 + 2(d− 1) ) ,\nwhere we identified β = eγ . Multiplying both sides by β, we have a quadratic equation in β:\nβ2 − 1 = 1 M\n( β2 + 2β(d− 1) + 1 ) or (M − 1)β2 − 2(d− 1)β − (M + 1) = 0,\nwhose solution is the positive root of\nβ = 2d− 2± √ (2d − 2)2 + 4(M2 − 1) 2(M − 1) or γ = log ( 2d− 2 + √ (2d − 2)2 + 4(M2 − 1) 2(M − 1) ) .\nBy our construction, with γ so defined, we satisfy the constraints that M [q(Mei)− q(−Mei)] = 1 and q(Mej) − q(−Mej) = 0 for j 6= i. Since q belongs to the exponential family and satisfies the constraints, it maximizes the entropy H(Z) as desired [8].\nAlgebraic manipulations and the computation of the conditional entropy H(Z | X = ei) give the remainder of the statement of the proposition.\nE.4 Proof of Proposition 3\nThe outline of the proof of Proposition 3 is as follows. Lemma 16 implies that any distribution satisfying optimal local differential privacy must be supported on the extreme points of the outer set D (as in the proof of Theorem 6). Given this result, we reduce the problem of finding an optimally private distribution to a linear program, using symmetry arguments to simplify the LP. Finally, we show that the solution to the linear program is unique, which means that we have found the unique distribution satisfying optimal local differential privacy.\nWe begin by developing a reduction of the problem of finding a distribution with optimal local differential privacy to a linear program. Note that there is a non-increasing mapping between M— the radius of the larger ℓ∞ ball—and α ⋆. Indeed, whenever M increases, the set of distributions\nQ from which to choose a privacy channel increases, so α⋆ decreases. Put inversely, for a given differential privacy level α, we can find the smallest M such that it is possible to construct an α-differentially private channel Q mapping from [−1, 1]d to [−M,M ]d. (Lemma 19 shows that the mapping from M to α⋆ is implicitly invertible.)\nThus, rather than solving for α as a function of M , we take the converse view of finding the largest M such that an α-differentially private distribution exists. Fix d ∈ N and (with some abuse of notation) let Z ∈ {−1, 1}d×2d be the matrix whose columns are the edges of the hypercube {−1, 1}d. For each z, x ∈ {−1, 1}d, define the variables q(z | x) ≥ 0 to represent the conditional probability of observing Mz given x. Let q(· | x) = [q(z | x)]z∈{−1,1}d denote the vector version of q(z | x). Then we have that a α-differentially private channel providing an unbiased perturbtation of vectors in [−1, 1]d to [−M,M ]d, exists only if we can find settings of q(z | x) such that\nZq(· | x)− 1 M x = 0 for all x ∈ {−1, 1}d\nwhile additionally q(z | x) ≤ eαq(z | x′) and ∑z q(z | x) = 1, q(z | x) ≥ 0 for all z, x, x′. Thus, if we make the change of variables t = 1/M , we see that finding the smallest possible M—which corresponds to the least perturbation possible for a given privacy level α—can be cast as solving the linear program\nminimize − t (60) subject to Zq(· | x)− tx = 0 for all x ∈ {−1, 1}d\nq(z | x) ≤ eαq(z | x′) for all x, x′, z ∈ {−1, 1}d ∑\nz\nq(z | x) = 1, q(· | x) 0 for all x ∈ {−1, 1}d.\nThe solution vectors q(· | x), x ∈ {−1, 1}d, give the probability mass function for an α-differentially private channel perturbing from [−1, 1]d to [−M,M ]d, where M = 1/t∗ and t∗ denotes the solution to the LP. This p.m.f. is then optimally locally differentially private with α = α⋆([−1, 1]d, [−M,M ]d).\nIt is possible to calculate the solution of the LP (60) by hand, but it is tedious. We thus use the structure of optimal local differential privacy to reduce the problem to a single minimization problem over a vector q ∈ R2d (rather than a matrix [q(z | x)] ∈ R2d×2d). We have\nLemma 18. A distribution satisfying optimal local differential privacy must, for each x ∈ {−1, 1}d, satisfy q(· | x) = Π(x)q, where Π(x) ∈ {0, 1}2d×2d is a permutation matrix and q is a fixed vector.\nProof Suppose for the sake of contradiction that this is not the case, but the vectors q(x) and t solve the linear program (60). Let Q1 denote the matrix of the vectors q(· | x). Choose vectors q(· | x) and q(· | x′) such that q(· | x) 6= Πq(· | x′) for any permutation matrix Π. Now construct vectors q2(· | x) and q2(· | x′) such that q2(z | x) = q(z′ | x′), where z′ is chosen so that z′ix′i = zixi, and similarly choose q2 so that q2(z | x′) = q(z′ | x), where zix′i = z′ixi. Let Q2 denote the matrix of vectors q, but where q2(· | x) and q2(· | x′) replace q(· | x), q(· | x′). Then by construction, all the constraints of the original linear program (60) are satisfied. By symmetry and the strict convexity of the mutual information in the channel distribution Q, however, we see that\nI(P,Q1) = I(P,Q2) = 1\n2 (I(P,Q1) + I(P,Q2)) > I\n( P, 1\n2 (Q1 +Q2)\n) .\nThe decrease in mutual information gives the necessary contradiction.\nWith Lemma 18 in hand, we can now turn to the smaller linear program—in a single vector q and for a single vector x ∈ {−1, 1}d—that will give us the locally optimal differentially private channel. Indeed, we consider the linear program in the variables t ∈ R and q ∈ R2d , where we let q(z) denote the entry of q corresponding to column z of Z:\nminimize − t subject to Zq − tx = 0, q(z) ≤ eαq(z′) for all z, z′, ∑\nz\nq(z) = 1, q ≥ 0. (61)\nDefine the constants\nKd =\n⌊d/2⌋∑\ni=0\n(d− 2i) ( d\ni\n) and Cd = card { z ∈ {−1, 1}d : z⊤x > 0 } = { 2d−1 if d odd\n2d−1 − 12 ( d d/2 ) if d even.\nWe have the following lemma, which characterizes the structure of the solution vector q.\nLemma 19. Define α∗ = log Kd+2 d−Cd\nKd−Cd . For any α < α∗, the unique solution to the linear pro-\ngram (61) is given by\nq(z) =\n{ eα\neαCd+2d−Cd if 〈z, x〉 > 0 1 eαCd+2d−Cd otherwise.\nProof First, problem (61) is clearly equivalent to the linear program\nminimize − t subject to Zq − tx = 0, max\nz {q(z)} + eα max z {−q(z)} ≤ 0,\n∑\nz\nq(z) = 1, q ≥ 0. (62)\nOur proof proceeds in two large steps: first, we argue that a q of the form specified in the lemma is indeed the solution to the problem (62), then we use results on uniqueness of solutions to linear programs due to Mangasarian [35].\nFor the first step, we begin by writing the Lagrangian to the problem (62). We introduce dual variables θ ∈ R2d for the constraint Zq − tx = 0, λ ≥ 0 for the first inequality, τ ∈ R for the sum constraint, and β ∈ R2d+ for the non-negativity of q. With this, we have Lagrangian\nL(q, t, θ, λ, τ, β) = −t+θ⊤ ( ∑\nz\nq(z)− tx ) +λmax\nz {q(z)}+eα max z {−q(z)}+τ(1⊤q−1)−β⊤q. (63)\nRecall the generalized subgradient KKT conditions for optimality of the solution to an optimization problem [26, Chapter VII]. A vector q > 0 is optimal for the problem (62) if the constraints maxi{qi} ≤ eα mini{qi} and ∑ i qi = 1 hold, there is a t ≥ 0 such that Zq− tx = 0, and we can find θ, λ, and τ such that\nZ⊤θ + λ [v+ − eαv−] + τ1 = 0, β = 0, and θ⊤x = −1, (64)\nwhere v+ and v− are vectors satisfying\nv+ ∈ Conv { ei : qi = max\nj {qj}\n} and v− ∈ Conv { ei : qi = min\nj {qj}\n} .\nThat β = 0 follows by complementarity (recall that q > 0 is assumed). If we can find settings for the vectors θ, λ, τ, and v± satisfying the KKT conditions (64), we are done. To that end, set θ = −x/d. Then by inspection θ⊤x = −‖x‖22 /d = −1, and we can rewrite the remaining KKT condition by noting that we must find vectors v+, v−, and τ ∈ R such that\n− 1 d Z⊤x+ v+ − eαv− + τ1 = 0, v⊤+1 = v⊤−1, v+ ≥ 0, v− ≥ 0,\nv+(z) = 0 if q(z) < max z {q(z)}, and v−(z) = 0 if q(z) > min z\n{q(z)}. (65)\nNote that we have eliminated λ as it is a non-negative homogeneous scaling term on v+ and v−. We choose values q+, q− with 0 < q− < q+ and set q(z) = q+ when z⊤x > 0 and q(z) = q− when z⊤x ≤ 0, where q+, q− are chosen so that ∑z q(z) = 1. We now choose the values of v+, v−, and τ satisfying the KKT conditions in expression (65) based on the values q+, q−. Indeed, set\nv+(z) =\n{ z⊤x d − τ if z⊤x > 0\n0 otherwise and v−(z) = { −e−α z⊤xd + e−ατ if z⊤x ≤ 0 0 otherwise\n(66)\nBy inspection, we see that −Z⊤x/d+ v+− eαv−+ τ = 0, so the only question remaining is whether we can choose τ such that v± ≥ 0 and v⊤+1 = v⊤−1.\nTo that end, we recall the definition of the constant Kd, and we seek τ such that\n∑\nz\nv+(z) = 1\nd Kd − τCd = e−α\n1 d Kd + e\n−ατ(2d − Cd) = ∑\nz\nv−(z)\nby the symmetry in the sums. Rewriting the equation, we find that for equality we must have\nτ ( e−α(2d − Cd) + Cd ) = 1\nd Kd(1− e−α) or τ = Kd d · e α − 1 eαCd + 2d − Cd = Kd dCd · e α − 1 eα + 2d/Cd − 1 .\nThus we find that if α is such that\nKd dCd eα − 1 eα + 2d/Cd − 1 < 1 d , (67)\nthen by our choice (66) of the vectors v+ and v−, we have v+(z) > 0 whenever z ⊤x > 0, and v−(z) > 0 whenever z ⊤x ≤ 0. Noting that by our setting of q(z), we have by symmetry of Z that there exists a t > 0 such that Zq = tx, we find that our choice of q is optimal (since the KKT conditions (65) hold).\nWe have two arguments remaining in the proof. The first is to show that for α < α∗ defined in the statement of the lemma, the inequality (67) holds. Rewriting the inequality, we solve\neα − 1 = Cd Kd\n( eα + 2d/Cd − 1 ) or eα ( 1− Cd\nKd\n) =\n2d − Cd Kd + 1, i.e. α∗ = log Kd + 2 d − Cd Kd − Cd .\nFor any α < α∗, the strict inequality (67) holds, so the setting (66) of v+ and v− satisfy the KKT conditions.\nOur last argument regards the uniqueness of the two-valued solution vector q. For that, we apply Mangasarian’s result [35, Theorem 1] that if there exists an ǫ > 0 such that for any vector u ∈ R2d with ‖u‖2 = 1, q is a solution of the linear program (61) when the objective is −t+ ǫu⊤q, then q is unique. Luckily, this is not difficult given our previous work. The Lagrangian (63) for the modified linear program becomes\nǫu⊤q − t+ θ⊤ ( ∑\nz\nq(z)− tx )\n+ λmax z {q(z)} + eα max z {−q(z)} + τ(1⊤q − 1)− β⊤q.\nThe only modification in our KKT conditions (64) is that the first equality becomes\nǫu+ Z⊤θ + λ [v+ − eαv−] + τ1 = 0.\nBy the strictness of the inequalities v+(z) > 0 for z such that z ⊤x > 0 (and similarly for v−) in the definitions (66) whenever α < α∗, we see that for suitably small ǫ > 0, the vectors v+ and v− can be perturbed so that the KKT conditions are still satisfied. This proves the uniqueness of the two-valued solution vector q.\nRemarks Following an argument with completely the same structure as the proof, we see that for any d ∈ N (say d ≥ 3), there are different “regimes” of α, that is, there exists a sequence α∗0, α ∗ 2, . . . , α ∗ d−1 (or α ∗ d−2 if d is even) such that for α ∈ (α∗2i, α∗2i+2), the unique optimal solution to the linear program (61) is given by taking\nq(z) ∝ { exp(α) for z s.t. 〈z, x〉 > 2(i+ 1) 1 for z s.t. 〈z, x〉 ≤ 2(i+ 1)\n(for α < α∗0, we say i = −1 above). For α = α∗2i, the set of solutions is given by the convex combinations of the solution vectors\nq<(z) ∝ { exp(α) for z s.t. 〈z, x〉 > 2i 1 for z s.t. 〈z, x〉 ≤ 2i and q>(z) ∝ { exp(α) for z s.t. 〈z, x〉 > 2(i+ 1) 1 for z s.t. 〈z, x〉 ≤ 2(i+ 1),\nwhich follows from arguments similar to our application of Mangasarian’s results [35]. Now we may complete the proof of Proposition 3. Indeed, we see from Lemma 19 that the distribution satisfying optimal local differential privacy must assign probability masses at two levels—at least when the point being perturbed comes from {−1, 1}d. Now let Q be a distribution specified in the lemma. An argument identical to that in our proof of Proposition 1—by symmetry— shows that the distribution P maximizing the mutual information I(P,Q) is uniform on {−1, 1}d. The uniqueness of Q then follows from Lemmas 18 and 19, which show that such Q is the only distribution that minimizes the radius M of the ball [−M,M ]d; inverting this bound gives the proposition.\nE.5 Proof of Corollary 4\nBy scaling, we may assume that M ≥ L = 1 in the proof of the corollary. First, we claim that as γ → 0, the following expansion holds:\nlog(2d)−log ( eγ + e−γ + 2d− 2 ) +γ\neγ eγ + e−γ + 2d− 2−γ e−γ eγ + e−γ + 2d− 2 = γ2 2d +Θ\n( γ4\nd\n) . (68)\nBefore proving this, we use the expansion (68) to prove Corollary 4. Noting that\n2d− 2 + √\n(2d− 2)2 + 4(M2 − 1) 2(M − 1) =\n√ M + 1\nM − 1 + d− 1 M − 1 + Θ(d 2/M2),\nwe see that since log(1 + x) = x − x2/2 + Θ(x3), we have γ = dM + Θ ( d2 M2 ) . Thus the mutual information in Proposition 2 is\nI(P ∗, Q∗) = log2(\n√ (M + 1)/(M − 1) + d/M +Θ(d2/M2))\n2d +Θ\n( log4(1 + d/M)\nd\n)\n= d\n2M2 +Θ\n( min { d3\nM4 , log4(d) d\n}) .\nNow we return to showing the claim (68). Indeed, define f(γ) = log(eγ + e−γ +2d− 2). Letting f (i) denote the ith derivative of f , we have\nf (1)(γ) = eγ − e−γ\neγ + e−γ + 2d− 2 , f (2)(γ) = (eγ + e−γ)(2d − 2) + 4 (eγ + e−γ + 2d− 2)2 ,\nand\nf (3)(γ) = −(e2γ − e−2γ)(2d − 2)− 8(eγ − e−γ) + (2d− 2)2(eγ − e−γ)\n(eγ + e−γ + 2d− 2)3 .\nVia a Taylor expansion, we have f(0) = f(γ)− γf (1)(γ) + γ22 f (2)(γ) +O(f (3)(γ)γ3), and so substituting values for f(γ) and f (1)(γ), we have\nlog(2d) − log ( eγ + e−γ + 2d− 2 ) + γ\neγ eγ + e−γ + 2d− 2 − γ e−γ eγ + e−γ + 2d− 2\n= (eγ + e−γ)(2d − 2) + 4 (eγ + e−γ + 2d− 2)2 · γ2 2 +O\n( f (3)(γ)γ3 ) .\nA few simpler Taylor expansions yield that f (3)(γ) = O(γ/d), which means that all we have left to tackle is f (2)(γ). But noting that\n2 ( eγ + e−γ ) = 4 ( 1 + γ2\n2! +\nγ4 4! + · · ·\n) = 4 +O(γ2)\nimplies that f (2)(γ) = (4d+O(dγ2))/4d2, and hence (γ2/2)f (2)(γ) = γ2/2d+O(γ4/d), which yields the result."
    } ],
    "references" : [ ],
    "referenceMentions" : [ ],
    "year" : 2013,
    "abstractText" : "<lb>We study statistical risk minimization problems under a privacy model in which the data<lb>is kept confidential even from the learner. In this local privacy framework, we establish sharp<lb>upper and lower bounds on the convergence rates of statistical estimation procedures. As a<lb>consequence, we exhibit a precise tradeoff between the amount of privacy the data preserves and<lb>the utility, as measured by convergence rate, of any statistical estimator or learning procedure.",
    "creator" : "LaTeX with hyperref package"
  }
}