{
  "name" : "1701.02377.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : null,
    "authors" : [ ],
    "emails" : [ ],
    "sections" : [ {
      "heading" : null,
      "text" : "ar X\niv :1\n70 1.\nContents"
    }, {
      "heading" : "1 Introduction 3",
      "text" : ""
    }, {
      "heading" : "2 Formulation of the problem 3",
      "text" : ""
    }, {
      "heading" : "3 Construction of Cost Functional 4",
      "text" : ""
    }, {
      "heading" : "4 First Application 5",
      "text" : "4.1 First Order Operator . . . . . . . . . . . . . . . . . . . . . . . 5\n4.1.1 Experimental results . . . . . . . . . . . . . . . . . . . 6 4.1.2 Choice of solutions . . . . . . . . . . . . . . . . . . . . 19\n4.2 Second Order Operator . . . . . . . . . . . . . . . . . . . . . 20 4.2.1 Experimental results . . . . . . . . . . . . . . . . . . . 21 4.2.2 Choice of solutions . . . . . . . . . . . . . . . . . . . . 32 4.3 Sampling-step τ , Parameter θ and number of Impulses . . . . 33"
    }, {
      "heading" : "5 First application on ANNs 37",
      "text" : "5.1 One dimension functions . . . . . . . . . . . . . . . . . . . . . 38 5.2 Two dimensions functions . . . . . . . . . . . . . . . . . . . . 38 5.3 Vowels Classifications . . . . . . . . . . . . . . . . . . . . . . 39"
    }, {
      "heading" : "6 Conclusions 40",
      "text" : ""
    }, {
      "heading" : "7 Appendix 41",
      "text" : "7.1 General solution and coefficients . . . . . . . . . . . . . . . . 41 7.2 From solution to parameters . . . . . . . . . . . . . . . . . . . 43\n7.2.1 First Order . . . . . . . . . . . . . . . . . . . . . . . . 43 7.2.2 Second Order . . . . . . . . . . . . . . . . . . . . . . . 44\n7.3 From continuos to discrete model . . . . . . . . . . . . . . . . 45"
    }, {
      "heading" : "1 Introduction",
      "text" : "Many real world phenomena could be interpreted in an on-line scenario within Machine Learning theory. In long-life learning problems, various approaches have been developed to deal with the large amounts of data and the exploitation of their time correlation. Usually, some difficulties arise in the storage of data and in going after the intrinsic information coming from data during time. These aspects could suggest a more natural approach to learning, in a joint theory among Mechanics, Variational Calculus and Statistics. However, we postpone a deeply analysis of these ideas at a theoretical level, focusing on a first practical implementation, to create a connection between this new ideas and some applications on existing structures, which could be useful in these preliminary steps.\nWe briefly introduce basics ideas of this theory, first formulated in [1]. The concept of dissipation is well formulated in [2],whereas an summing up of this report and an experimental analysis on standard benchmark can be find in [3]. A further theoretical abstraction applied to similar environment is proposed in [4], In this document, we will give a slightly theoretical formulation in order to allow us to go straight to the practical implementation issues. We study the meaning of the model parameters on artificial problems, using a linear function, and then we try some experiments with simple Neural Networks.\nAn important result is the fact that we can choose arbitrarily the memory of our system by a parameter, avoiding the hardware memory storage problems. Indeed, the trend of the system is influenced by the information coming from each example during an adjustable interval of time."
    }, {
      "heading" : "2 Formulation of the problem",
      "text" : "We study the case in which we want to learn a function f that aims to represent the behavior of a features representation u of the spatio-temporal domains D. If we assume the temporal domain T = [0,∞) and X ⊆ RD then we have D = T ×X and u : D → Rd so that f has input u and depends on a set of weights W, like for example if f is described by an Artificial Neural Network. The problem consits on learning the parameters W under some assumption, i.e. by minimizing a cost functional L composed by a penalty term and a regularization one. Since the weights have to be learned as time goes by, we have that W depends on time and we write f = f(u(t,x),W(t)). In the classical approach the penalty term impose a\ncoherence w.r.t. the Training Set, whereas the regularization term impose the norm of the parameters to be small, so as to f be a smooth function. If we want the process of learning itself to be smooth, we could requires some kind of regularization in the changing of W during time. We shall see in next sections how this idea could be studied in a Physics-like approach."
    }, {
      "heading" : "3 Construction of Cost Functional",
      "text" : "In a classical learning problem we have to minimize a cost functional L w.r.t. W(t). The functional is composed by a penalty term and a regularization one. The penalty term is calculated on every supervised example, over a training set P={(uk, f̄k)} l k=1, by a loss function V =f(u(t,x),W(t)) which is the summation over P :\nV (u(t,x),W(t)) = l ∑\nk=1\nV ( f(u(t,x),W(t)) , f̄k )\nwhere V could be for example the quadratic function V (f, f̄k)= 1 2(f − f̄k)\n2\n( where f means f(u(t,x),W(t)) from now on ). Since the examples are presented in time, if tk is the instant of time in which the couple (uk, f̄k) is provide, we can write V as\nV (u(t,x),W(t)) = l ∑\nk=1\nV ( f , f̄k ) ·H(t− tk).\nIn a physics-like approach we can look at the term V as the potential energy, so as the total energy of the system L is composed by K+V where K is the kinetic energy . Then in our formulation we write\nL=K+γV (1)\nwhere γ represent a regularization parameter (which includes the classical case when γ=1 ). We can write K as:\nK = m ∑\ni=1\nµiω̇ 2 i\nwhere m is the total number of weights in W, and µi represent the mass of each weight, (i.e. an additional parameters which can be use to choose the\ninertia of each weight). Since ω̇i= d dtωi we can replace D= d dt with a general differential operator T . Now we can finally write our cost functional as\nSγ =\n∫ te\n0 ψ(t) · L dt. (2)\nwhere ψ is a suitable dissipation function, that we take as ψ(t)=eθt."
    }, {
      "heading" : "4 First Application",
      "text" : ""
    }, {
      "heading" : "4.1 First Order Operator",
      "text" : "In our first application of this theoretical framework we analyze the simple case in which f is a linear function of one single real variable f :R → R and f = yu+b where u=u(t, x(t)))=x(t) . In this framework we want to learn the two weights y, b. The problem can be formulated as\ny∗ = argmin y∈R\n∫ te\n0 ψ(t) · L dt\nand analogous formula hold for b. We start with the case T =α0+α1D. By the application of the EuleroLagrange equation we have to solve the second order linear differential equation:\nÿ + θẏ + βy − γ\nµα21\nl ∑\nk=1\n(ukyk + bk − f̄k)uk · δ(t− tk) = 0 (3)\nwhere β = α0α1θ−α20\nα21 . The solution is then composed by a term given\nfrom the homogeneous solution yo(t) plus a term given from the impulsive response yF (t). Then we have1:\ny(t) = yo(t) + yF (t) = yo(t) + γ\nµα21\nl ∑\nk=1\nζk · g(t− tk) (4)\nwhere we posed ζk = (ukyk + bk − f̄k)uk. For the bias b we have an analogous solution except for the element ζk, which represent ∂V ∂y and in the correspondent formula for b is ζk=ukyk+bk−f̄k. For the stability of the system during time, we have to impose the RouthHurwitz conditions, which lead to the relation θ > α0/α1.\n1see section 7 for details about practical calculation"
    }, {
      "heading" : "4.1.1 Experimental results",
      "text" : "A first implementation (in MatLab) of our theoretical results is in the simple case in which we want to approximate a linear function in an interval [a, b] = [−1, 1] of the real axis. We assume that the examples on the training set are equally spaced in time by a factor τ with t0 = 0. This allow us to use a discretization of (4) for the computing of the evolution of the system, as you can see in Section(7.3). We also consider an equally-spaced subdivision of our interval that we cover forward and backward, i.e. we move from a to b and viceversa, so as to guarantee time correlation among the examples. We assign to every point uk a target f̄k = 2·uk−1, so we desired y(t)→ 2 and b(t)→−1 after some epochs. For start, we feed the system with a total supervised training set. We studied some results on this first implementation w.r.t. the parameters θ, α0, α1, γ, µ, τ .\nIf we start our study for a simple case we have a behavior as shown in Fig.1 . We set γ=−1 , µ=1 , θ=5 , α0 =1 , α1 =1 , y(0) = y\n′(0)= b(0)= b′(0) = 0. We repeat the training set for a total of 40 iterations. From the top to the bottom of the figure we can find :\n• the plot of the impulse response g(red line)\n• the plot of y(blue line) and b(green line)\n• the plot of the last 20% of update of the weights\n• the plot of the last 10% of update of the weights\nEach plot have the same scaling referred to the time t, so as in the graphs is reported the evolution of the system w.r.t. real time (we can think in seconds). The width of each plot depends on both the number of iterations and the parameter τ , but each plot has the same scale in seconds. As we can see in Fig.1 the weights have an initial oscillation and then assume a cyclic behavior with a smaller amplitude oscillation when the system is a steady state, near the desired value 2,−1 respectively.\nIn the remainder of this section we studied some variations produced by each parameters on the behavior of the weights.\nParameter γ\nIn our formulation of the theory this parameters only determine the sign between the two termsK and V , so we only explore the set {−1, 1} for this one. Because of some correlation with the gradient descent, we expect our weights to have a divergent trend when γ = 1. Our experimental results confirm this, as we can see in Fig.2, where we can notice the trend of the weights after just 5 iterations.\nWe tried to vary the other parameters in order to make the weights converge to the desired value also in the case γ=1. We obtained converge by imposing a strong regularization by the differential operator\n(α0 , α1 > 10), but is difficult to find a correlation between the final values and the desired ones(Fig.3 ). The same result ca be achieved with µ > 30 or θ > 120 and also by increasing the parameter τ . All these adjustments on the other parameters represent the imposition of a strong regularization on the system, which drive all the weights to zero.\nBecause of this preliminary results, we drop the parameter γ from now on as we fix γ=−1.\nParameter τ\nThis parameters represent the time-sampling step of the system. Under our practical assumptions also the time-spacing of the examples. It represent a crucial parameters of the system and we will study it\nafter the second order operator. For now we fix τ=0.01\nInitial Conditions\nBecause of the asymptotic behavior of the solution of (3), it is reasonable to assume that different Initial Conditions do not produce relevant changes in the weights at the end of optimization. Indeed in Fig.4 and Fig.5 we can see that the final values of the weights are in the same range of Fig.1, but the initial oscillation is different, due to the different starting points and derivatives. We can also see that for very different initial conditions, the time that the algorithm spent on reach the steady state is almost the same, maybe because the terms ζh, which reflect the gradient, balance these differences. As in the previous case, from now on we drop the specification of initial conditions assuming them null.\nParameter θ\nThis parameter come from the exponent in the dissipation term ψ(t)= eθt and influence the solution direct in the structure of the functions g(t) and yo(t) ( see section7). If we decrease θ=2, we have that g(t) → 0 slowly(Fig.6), the initial transient phase is longer and oscillation as a greater amplitude. On the opposite, if we set θ = 10 we have the reverse effect. In the steady state, we can observe that as θ increases, the average value of the weights decreases(y(t)∼1.956 for θ=2, y(t)∼ 1.835 for θ = 5, y(t) ∼ 1.665 for θ = 10 ), so as we can think to a regularization effect.\nParameter α0, α1\nAlso these parameters affect the solution of (3). They are expected to act as a regularization parameters, since they appear directly in the construction of term K. A larger value of α0 should lead to a weights with a smaller magnitude. α1 should impose a smaller derivatives, i.e. a smooth variations of the weights during time. These hypothesis are confirmed by Fig.8, Fig.9, Fig.10. In Fig.9, we can notice that a larger α1 gives not only the expected smoothness, but also a stronger regularization effect w.r.t. α0 in Fig.8.\nParameter µ\nµ is the correspondent of the mass in physics, so it should represent the inertia of the weights, i.e. how we want to allow to the system to change them at each step (w.r.t. the penalty term V ). Furthermore, we can see in (4) that it can be use to represent a sort of learning rate (to follow a parallel with gradient descent again). This is confirmed in Fig.11 and Fig.12 where a smaller value of µ gives more importance to the optimization than to the regularization.\nIf we try to grow up with µ, we find that this increment maintain this behavior (unbalancing towards regularization). On the other hand, if we choose a µ ≤ 0.4, the system diverges(Fig.13)."
    }, {
      "heading" : "4.1.2 Choice of solutions",
      "text" : "All this parameter contribute to model our system, but we have to choose how. Since we would like that the system promptly reacts to the stimuli, we want an Impulsive Response that reach its maximum as fast as possible. Moreover, its useful that the system is width enough to see all the examples more times before to forget them. Once we have chosen a suitable θ (w.r.t. the Training Set, see Section 4.3), we can model the parameters αj so as to satisfy these request. Often is more convenient to choose the directly the solutions to build our system (see Section 7.2). In Fig.14 we can see that if we chose a solution close to 0, and then the other close to θ (since θ=−(λ1 + λ2)) we have a longer g (green plot), whereas we go in the other direction if the solutions are similar (blue plot)."
    }, {
      "heading" : "4.2 Second Order Operator",
      "text" : "Under the practical assumptions of the previous section, we study the implementation of the case in which the term K is composed by the second order linear differential operator T =α0+α1D+α2D\n2. The Eulero-Lagrange equation lead this time to a fourth order linear differential equation:\nD4y+β3D 3y+β2D 2y+β1Dy+β0y+ γ\nµα22\nl ∑\nk=1\n(ukyk+bk− f̄k)uk ·δ(t−tk) = 0\n(5) where:\nβ0 = α0α2θ2−α0α1θ+α20\na22\nβ1 = α1α2θ2+(2α0α2−α21)θ\nα22\nβ2 = α22θ 2+α1α2θ+2α0α2−α21 α22 β3 = 2θ\n(6)\nThis time the Routh-Hurwitz conditions requires:\nβi > 0 , i = 0, ..., 3 β3β2 > β1\nβ3β2β1 > β 2 1 + β 2 3β0\n(7)\nThe updating formula is then2:\ny(t) = yo(t)− γ\nµα22 ·\nl ∑\nk\nζh · g(t− tk) (8)\nwhere we can notice a sign flip before the second term w.r.t. (4) due to the even order of T . This make us expect (because of the parallel with gradient descent again) that this time our system is stable for an opposite sign of γ w.r.t. the first order operator studied in section 4.1.1. In practice, we can observe a more complicated behavior due to the kind of the solutions of (5)."
    }, {
      "heading" : "4.2.1 Experimental results",
      "text" : "This time we start by observing that there are different possibilities in the kind of the solutions of (5):\n(1)Four distinct real solution\nWe start with the case θ = 4 , α0 = 0.8 , α1 = 1.6 , α2 = 0.8. As we can see in Fig.15 the system is divergent for γ =−1. Also in the case γ=1 in Fig.16 we have divergence, but we can notice a different oscillation of the weights. We can see in (8) that the second term is multiplied by the factor γ/(µα22). Since α2 < 1 we can apply some of the considerations done in Section 4.1.1 about the parameter µ. This divergence is maybe due to a too higher balancing on the gradients term, indeed if we set µ=4 we have convergence to the desired values Fig. 17. We can obtain convergence by increasing µ also when γ=−1 Fig. 18 but with futile values of the weights.\n2again see section 7 for details about practical calculation\nWe have this kind of solution also for 2.2 ≤ θ ≤ 4 and for 6.6 ≤ θ ≤ 7.2, with the same value of αj . When θ=2.2 we need a bigger value of µ to achieve convergence Fig. 19. This is because the impulse response has a bigger maximum than before, and then also the coefficients which multiply the gradients are bigger, so that we need a bigger balancing µ.\nWhen θ = 6.8 these first conclusion are confirmed in Fig.20, where µ=1 is enough for convergence. This is because the solutions to (5) are different, but we can comparing again the impulse response that assume a smaller value than before.\n(2) Four real solution, 1 with multiplicity 2\nAlso in this case the system diverge when γ = −1. When γ = 1 we report the case in Fig.21 where we can see a behavior similar to case (1).\n(3)Two distinct real solutions, two conjugate complex solution\nWe can obtain this solutions for example for these settings of the parameters:\nθ α0 α1 α2\n5.75 1 2 1\n7 1 2 1 1 1 3 2.25 2.25 1 3 2.25\nWhen we have the complex solution with real part smaller than the real solutions , part of the Impulse Response without oscillation (the one coming from the real solutions) disappears before the other one, and if the imaginary part is big enough we have an oscillation that lead to a more complex behavior and then to instability. We can\nchoose (see Section 7.2) λ1,2 =−0.1 ± i , λ3 =−1.2 , λ4 =−1 and we have the situation in Fig.22, where a big regularization is required to convergence.\n(4)One real solution with multiplicity 2 , two conjugate complex solution\nWe can obtain this solutions for example when:\nθ α0 α1 α2 8.2 0.2 1.2 1.8\n18.4 0.2 1.2 1.8\nand we have an analogous situation of (3).\n(5)Four complex solution, two conjugate pairs\nWe have both the case in which we have two complex conjugate pairs and the case with a complex conjugate pair with multiplicity two. They have a similar behavior depending on the magnitude of the real and imaginary parts. The real parts influence the memory of the system, whereas the imaginary parts the frequency of the sinusoidal oscillation. In each case is possible to find a value of µ which allow convergence, but often to values near to 0 with an high-oscillatory trend similar to the one reported in Fig.22, since it is due to the sinusoidal nature of the solution.\nFrom this study on the solutions is clear that the parameter µ decides again the balancing between regularization and fitting, as observed for the first order operator. The behavior w.r.t. Initial Conditions is again the same as we can see in Fig. 24. Since we have a fourth-order differential equation we need to know the values of the first n − 1 = 3 derivatives of the solution yo(t) in t= 0. We indicate I.C. with the vectors y0 = [yo(0) , yo(1)(0) , yo(2)(0) , yo(3)(0)] and b0=[b o(0) , bo(1)(0) , bo(2)(0) , bo(3)(0)]."
    }, {
      "heading" : "4.2.2 Choice of solutions",
      "text" : "Like in the First order case, we are allowed to choose a suitable set of solutions and then find the parameters for our model (Section 7.2). In this case we have four solutions related to θ by the relation 2θ=−(λ1+λ2+λ3+ λ4). Also in this case we need a solution close to 0 to allow memorization. It is also useful not to choose another one or two little (w.r.t. θ) solutions since this makes the g grow too much (Fig.25)."
    }, {
      "heading" : "4.3 Sampling-step τ , Parameter θ and number of Impulses",
      "text" : "In our first experiments we consider a totally supervised Training set, where the examples are equally spaced both in time and space. The first example comes at t1=τ , then the first supervision came at 3 2τ (see Section 7.3) and the system receives an impulse. The next example comes τ seconds after the first and so on. Since the memory is related to the saturation time of impulse response, the learning process of the system embraces all the examples appearing in the interval of time before this saturation. This means that the system has to be build so as the saturation time comes after the whole Training Set has been seen more times. Further more, since the functional in (2) contain the term eθt, the parameter θ has to be such that eθt0 = 1 is not too much smaller than eθtl (tl instant at which the last example ul comes). Another important characteristic to take in account is the delay the Impulse Response. If the supervisions (and then the impulses themselves) are too frequent, there is an accumulation of this delay that could cause instability. For these reasons it is important to study the behavior of the system w.r.t. the rate between θ and τ , with some adjustment allowed by\nthe other parameters. In this section its convenient to restrict the analysis to the second order differential operator by managing the solutions of the differential equations (5). The parameter θ is directly related to the roots λ by the relation\n2θ=−(λ1 + λ2 + λ3 + λ4).\nThis allow us to choose a suitable θ for our model by the solutions, then find the other parameters of the model to optimize the behavior (see Section 7.2). One solution close to 0 gives memory to our system. So we choose λ1 small enough to give sufficient memory w.r.t. data, from now on we fix λ1=−1× 10\n−8. We split θ−λ1 roughly equally among the others solutions, since in this way we have a quicker response with a smaller maximum (see Section 7.2), we assume they are respectively the 60,65 and 75% of 2θ. Because of this choice on the parameters, in the following figures we plot at the top both the behavior of function g near the origin and its global trend. We also pose η= γ/µ. At the bottom we plot the last five iteration on the Training Set, to better see how the oscillation at the steady state depends on the data set. In the label we specify SO to indicate we are dealing with the second order operator.\nAs a first experiment we try to better understand the oscillatory behavior when the system reach the steady state. For start we choose our models. We start with the same Training set with l=20 and τ=0.01, θ=1 produce eθtl = 1.22, using the parameters reported in Fig.26 and referring to this configuration as the low dissipation one.\nWhen we increase the parameter τ = 0.1, also the period T and the oscillation period have the same increment, as shown in Fig.27.\nNow we show the behavior of the system when we reproduce a situation similar to the classic Stochastic Gradient Descent. Since the memory of the system is very long w.r.t. data (because of λ1), the function g is almost constant once it reach its maximum. If the examples are far enough to allow the system to respond between two of them (i.e. g reach its maximum), we reply the gradient descent algorithm. Each examples modify the weights with a term related to the gradient calculated at the previous instant of time. As already said, the period both depends on τ and θ, so that we can arbitrarily fix θ = 1 and enlarge τ = 40 so as to obtain the desired configuration with eθtl =10173. The outcome of this high dissipation setting is showed in Fig.28. In the remainder of this Section we can see at the top of the figures g again, then the behavior of the two weights y (blue) and b (green) after the first iteration on the Training Set, the total trend and the last 5 iterations at the bottom."
    }, {
      "heading" : "5 First application on ANNs",
      "text" : "As first simple practical application we try some experiment in the optimization of a simply ANN. We use a network with one hidden layer and an output layer, the identity as output function and the rectifier function:\nf(x) =\n{\nx if x>0 0 otherwise\nas activation function. In this model we have simply to extend the updating formulas for the weights y, b to the weights of the two layers. In this first application we try different setting of the parameters, with different number of units and for both the first and the second order differential operator. In the next list of experiments, we refer to some results obtained by use θ=1 and 20 of units in the hidden layer, τ varying so as to guarantee a good\nvalue of eθτl, η has been changed to guarantee the best fitting, in the second order differential operator case."
    }, {
      "heading" : "5.1 One dimension functions",
      "text" : "We first attack the practical model of the first sections, i.e. a regression task on a Set containing 100 points uk ∈ [−1, 1], which are sorted and equally spaced. All the points are labeled with the target yk=2·uk − 1, but only 10 points give supervision. We have the MSE= 1.77·10−3 after 2·104 iterations. In Fig.29 we can see the trend of MSE in other 2·105 epochs if we turn off the supervisions (only labeled points for MSE evaluation).\nWe then try the same parameters for a classification task on the same set. We assign the target class true (f̄k=[1 0]\n′) to the points in [−0.5, 0.5] and the class false (f̄k=[0 1]\n′) to the others. Again we use only 10 points for supervision. After 5·104 iterations we have MSE= 0.03 and Accuracy= 0.97. Again we try to turn of the supervisions and go on with agent for other 2·105 epochs. Both MSE and accuracy remain almost the same."
    }, {
      "heading" : "5.2 Two dimensions functions",
      "text" : "We choose our point in [−1, 1]× [−1, 1] . We use two different trajectories to cover the Training set, a spiral and a flower. We obtain the points of the\nspiral as:\nu(t) =\n{\n(t/100) cos(t) (t/100) sin(t)\nwhereas the flower trajectory is obtained by\nu(t) =\n{\ncos(10t) · cos(t) cos(10t) · sin(t)\nWe take 100 supervised points coming from each trajectories with t= 1, ..., 100 (26 and 40 for the class true, respectively for the flower and spiral trajectory). The points in { (x, y)∈R2 : |x|+ |y| ≤ 0.5 }\nrepresent the class true, the others are false. We divide our experiments in two different phases. In the first phase, we train the network with the supervised points for 105 iterations on the set obtained with one trajectory. In the second phase (validation) we check the performance of the system after some epochs without supervisions. We evaluate the performance on the two sets coming from different trajectories and on set obtained by an equally spaced grid of [−0.5, 0.5]×[−0.5, 0.5] containing 100 examples, equally split in true and false label. The results are in Table 1."
    }, {
      "heading" : "5.3 Vowels Classifications",
      "text" : "We record few tracks with the sequential pronunciation of the five Italian vowels. We process the files with Matlab and take the auditory spectra coefficients coming from RASTA PLP algorithm. We obtain a sampling of the tracks with points in a 40 dimensions features space. Set 1 is obtained from a 20 seconds track with sequential pronunciation of the vowels(2053 samples, 700 labeled). Set 2 (2144 samples) is obtained from a 20 seconds track with sequential pronunciation of the vowels repeated in time (600 labeled\npoints). Set 3 is obtained from 5 tracks, each containing the pronunciation of a vowel (14934 labeled points). We carry on the experiments with the same approach of the previous section. In the first phase we train the net with a few supervised samples. Again, in the second phase we turn off the supervisions and study the performance of the system as time goes by. After some epochs, we evaluate the agent on each set. The results are in Table 2."
    }, {
      "heading" : "6 Conclusions",
      "text" : "As already said, the studied applications are not the perfect suit of our theory. However, the positive results showed could strengthen our hypothesis and help to better understand the meaning of the different aspects. This made us look for a deeper analysis from many theoretical points of view. We are talking about study others differential operators, cost functionals and forms of the function f . Simultaneously, we would like to investigate the behavior of the current model in applications in which a manifold regularization in time plays an fundamental role, as in Computer Vision problems."
    }, {
      "heading" : "7 Appendix",
      "text" : ""
    }, {
      "heading" : "7.1 General solution and coefficients",
      "text" : "In this section we report some practical calculations and assumptions to solve the differential equation of our theoretical framework. The notation is finalized to a practical general implementation.\nWe can write the general form of characteristic polynomial as:\nβnλ n + ...+ β1λ+ β0 = 0 (9)\nThen we have a set of J solution λj each with they multiplicity rj. The Laplace Transform lead to:\nG(s) = 1\n∑n q=0 βqλ\nq =\nJ ∑\nj=1\nrj ∑\ni=1\ncji (s− λj) ri (10)\nWhere cji are constants such that:\nJ ∑\nj=1\nrj ∑\ni=1\ncji(s− λj) rj−i(\nJ ∏\nk=1\nk 6=i\n(s− λk) rk) = 1 (11)\nFor practical issue we pose\nΛj,j = [ λ1 · · · λ1 · · · λJ · · · λJ λj · · · λj ] Rj,j = [ 1 · · · r1 · · · 1 · · · rJ 1 · · · rj ] Λj,q = [ λ1 · · · λ1 · · · λJ · · · λJ λj · · · λq ] Rj,q = [ 1 · · · r1 · · · 1 · · · rJ 1 · · · rq ] , q ≤ j In = [ 1 · · · n ] (12) To simplify the notation we pose R=RJ,J , Λ=ΛJ,J . If we carry out the summation in (10)(with the new notation), pose nj = n−Rj we find that each cji multiply a factor:\ncji\n\n \nnj ∑\nk=0\nsnj−k\n\n \n∑\ni∈Cnj,k(Inj )\n(\ninj ∏\np=i1\n−Λj,ip )\n\n \n\n  = cji\nnj ∑\nk=0\nsnj−kAl,j+i , l = nj−k+1\n(13)\nthen we can determine C = [c11 · · · c1r1 · · · cJ1 · · · cJrJ ] ′ from the system AC = b , b = [10 · · · 0]′ and A∈Rn,n with:\nAl,j+i =\n{\n∑ i∈Cnj ,k(Inj ) ( ∏inj p=i1 −Λj,ip ) if 1 ≤ l ≤ nj + 1 , k=nj + 1− l 0 nj + 1 < l ≤ n (14)\nThe general solution is of the form:\ng(t) =\nJ ∑\nj=1\nCjt Rj−1eΛjt (15)\nWhen we have a complex solution λj = α + iβ, also its conjugate λp = λ̄j = α − iβ is present and also the relatives constants are such that Cp = C̄j = αc − iβc. We have in the solution :\n· · ·+ Cj · e αt (cos βt+ i sin βt) + Cp · e αt (cos(−βt) + i sin(−βt)) + · · ·\n· · ·+ Cj · e αt (cos βt+ i sin βt) + Cp · e αt (cos(βt)− i sin(βt)) + · · ·\n· · · + (Cj +Cp) · e αt (cos βt) + (Cj − Cp) · e αt (i sin βt) + · · · (16)\nand since\n(Cj + Cp) = αc + iβc + αc − iβc\n(Cj − Cp) = αc + iβc − αc + iβc\nthe (16) becomes\n· · ·+ 2αc · e αt (cos βt) + 2iβc · e αt (i sin βt) + · · ·\n· · · + 2αc · e αt (cos βt)− 2βc · e αt (sinβt) + · · · (17)\nsince this is the contribution of two solution with the same real and imaginary parts, we can write (15) as\ng(t) =\nJ ∑\nj=1\ntRj−1eℜ(Λj )t (ℜ(Cj)(cos(ℑ(Λj)t))−ℑ(Cj)(sin(ℑ(Λj)t))) (18)\nalso the solution to the homogeneous equation is of the form\nyo(t) = J ∑\nj=1\nKjt Rj−1eΛjt (19)\nwhere Kj are determined by imposing the Initial Conditions given for yo(t), that is Y0 = [y o(0) · · · yo(n−1)(0)]′. Since\nyo(d)(0) =\nJ ∑\nj=1\n(d+ 2−Rj) +KjΛ\n(d+1−Rj) + j (20)\nwe can find K = [K1 · · ·Kn] ′ by solving the system MK = Y0 where:\nMvj = (v + 1−Rj) +Λ\n(v−Rj ) + j (21)\nand exactly as in the case of g(t) we can write\ny(t) = J ∑\nj=1\ntRj−1eℜ(Λj)t (ℜ(Kj)(cos(ℑ(Λj)t))−ℑ(Kj)(sin(ℑ(Λj)t))) (22)"
    }, {
      "heading" : "7.2 From solution to parameters",
      "text" : "In section 4.2 we saw that for the second order case convergence depends not only on γ, but also on the kind of the solutions of the characteristic polynomial, i.e. on βj . Moreover, the most important parameter of our model is θ, which allow to choose the memory width of the system. This memory is related to the function ψ(t)=eθt, which represent the weight that the model assigns to each samples as the time goes by. The smaller is θ( but always > 0) the bigger is the memory of our model. We are interested in find suitable values of αj which allow convergence when θ is small. In practice, we can build our model only by the solutions of the characteristic poly, since the parameters influence the updating formulas (4),(8) only by the last αj, which can be absorbed in the term µ. Then we can choose directly suitable solutions, and verify that they are related to meaningful values of parameters. So, starting from the solutions (chosen in a way to have the desired θ), is easy to find the coefficients of the characteristic poly and then find the rate between the αj that generate the model."
    }, {
      "heading" : "7.2.1 First Order",
      "text" : "If we have the solutions λ1, λ2 the characteristic poly of (3) is\nλ2 + θλ+ β = (λ− λ1) (λ− λ2) .\nSo the value of θ is given by θ = − (λ2 + λ1) and the rate α0 α1\nis computable from β. That is, if we pose ν = α0α1 , we can find suitable value of αj from the solutions of\nν2 − θν + β = 0. (23)"
    }, {
      "heading" : "7.2.2 Second Order",
      "text" : "In this case the characteristic poly is λ4 + β3λ 3 + β2λ 2 + β1λ + β0 = 0. The coefficient β3 is still given by the opposite of the summation among the solutions, and since β3=2θ it is still easy to set θ. To find the rates among αj is convenient to work with ν0 =\nα0 α2 and ν1 = α1 α2 so that:\nβ0= α0α2θ\n2 − α0α1θ + α 2 0\na22 =ν0θ\n2 − ν0ν1θ + ν 2 0 (24)\nβ1= α1α2θ\n2 + (2α0α2 − α 2 1)θ\nα22 =ν1θ\n2 + 2ν0θ − ν 2 1θ (25)\nβ2= α22θ 2 + α1α2θ + 2α0α2 − α 2 1\nα22 =θ2 + ν1θ + 2ν0 − ν 2 1 (26)\nFrom the equation (26) we can find the relation among the coefficients:\nβ1= β3β2 2 − β33 8\n(27)\nfrom equation (25) we find\nν0= 1\n2θ\n(\nβ1 + ν 2 1θ − ν1θ 2 )\n(28)\nand from (24) we have\nν41 − 4θν 3 1 + ν 2 1\n( 5θ2 + 2β1/θ ) + ν1 ( −2θ3 − 4β1 ) + ( 2θβ1 + β 2 1/θ 2 − 4β0 )\n=0. (29)\nOnce we find the solutions of (29) we can choose a suitable one and find ν0, and then have an idea of which αj generate our model. For practical reasons, since β0 = λ1 λ2 λ3 λ4, by using (24) we can find α1 by posing α0=α2=1 in (24):\nα1=ν1= ν0 θ 2 + ν20 − β0 ν0 θ . (30)\nIn our study on the model parameters, we see that is convenient to have one solution close to zero (which guarantees memory to the system). We can choose λ1=1/a (where a is a parameters which represent the memory of the system, since the saturation time is proportional to a). Since the modulus of the other solutions determine the shape of the Impulse response, is convenient to write the solutions as:\nλ1 = c1 θ=1/a λ2 = c2 θ λ3 = c3 θ λ4 = c4 θ\n(31)\nwhere ∑\ncj=2 and c2 , c3 , c4 as to be similar among them (but not too much to avoid numerical error) to give a quick Impulsive Response.\nNow we are allowed to choose suitable solutions w.r.t. the model and then find the value of γ/µ which guarantee convergence and the best fitting performance, both for first and second order."
    }, {
      "heading" : "7.3 From continuos to discrete model",
      "text" : "In the practical implementation is not convenient to use the continuos updating formulas (4),(8), since we have to store too much value of the gradient, that is, the wider is memory of the system, the bigger is the number of elements that we have to remember. For this reason, is convenient to use a discretization of the system. Indeed, when we have a linear differential equation of order bigger than one, we can transform it in a system of the same order with only linear differential equations of order one. In our case in\nD4y + β3D 3y + β2D 2y + β1Dy + β0y + η\nl ∑\nk=1\nζk · δ(t − tk)=0\nwe can substitute y0= y, y1=Dy, ... and posing u(t)= η ∑l\nk=1 ζk · δ(t − tk) so that to have:\n\n  \n  \ny1 = y ′ 0 y2 = y ′ 1 y3 = y ′ 2 y4 = −β3y3 − β2y2 − β1y1 − β0y0 − u(t)\n(32)\nand then we have the system\nẏ =\n\n   y1 y2 y3 y4\n\n   =\n\n   0 1 0 0 0 0 1 0 0 0 0 1\n−β0 −β1 −β2 −β3\n\n  \n\n   y0 y1 y2 y3\n\n   +Bu = Ay +Bu (33)\nwhere\nA =\n\n   0 1 0 0 0 0 1 0 0 0 0 1\n−β0 −β1 −β2 −β3\n\n   B =\n\n   0 0 0\n−1\n\n  \nfrom the Lagrange formula we have\ny(t)=eA(t−t0)y(t0) +\n∫ t\nt0\neA(t−s) ·Bu(s)ds. (34)\nWhen we consider an equally spaced discretization of the time of width τ , a general instant of time is t = τK and if we assume t0=0, the general evolution of the system can be computed by\ny[K] = y(τK) = eAτKy[0] +\n∫ τK\n0 eA(τK−s) ·Bu(s)ds (35)\nand at the next step we have\ny[K + 1] = eAτ(K+1)y[0] +\n∫ τ(K+1)\n0 eA(τ(K+1)−s) ·Bu(s)ds\n= eAτ ( eAτKy[0] + ∫ τK\n0 eA(τK−s) ·Bu(s)ds\n)\n+\n+\n∫ τ(K+1)\nτK eA[τ(K+1)−s] ·Bu(s)ds\n= eAτy[K] +\n∫ τ(K+1)\nτK eA[τ(K+1)−s] ·Bu(s)ds\nsince u(t) is composed by a summation of impulses we have a summation of integrals in the second term. If we assume that each impulse (i.e. each\nsupervision) is provided in the middle of two step, we have that only the integrals referred to the last impulse (the one provided at h=τK + τ/2) is different from 0 :\n∫ τ(K+1)\nτK eA(τ(K+1)−s) ·Bu(s)ds = η\nl ∑\nk=1\n∫ τ(K+1)\nτK eA[τ(K+1)−s] ·B ζk · δ(s − tk)\n= η\n∫ τ(K+1)\nτK eA[τ(K+1)−s] ·B ζh · δ[s − (τK + τ/2)]\n= η eA[τ(K+1)−(τK+τ/2)] ·B ζh = η eAτ/2 ·B ζh\nthat is y[K + 1] = eAτy[K] + eAτ/2 ·B η ζh. (36)"
    } ],
    "references" : [ {
      "title" : "Variational foundations of online backpropagation",
      "author" : [ "Salvatore Frandina", "Marco Gori", "Marco Lippi", "Marco Maggini", "Stefano Melacci" ],
      "venue" : "In Artificial Neural Networks and Machine Learning - ICANN 2013 - 23rd International Conference on Artificial Neural Networks, Sofia, Bulgaria,",
      "citeRegEx" : "1",
      "shortCiteRegEx" : "1",
      "year" : 2013
    }, {
      "title" : "The principle of least cognitive action",
      "author" : [ "Alessandro Betti", "Marco Gori" ],
      "venue" : "Theoretical Computer Science,",
      "citeRegEx" : "2",
      "shortCiteRegEx" : "2",
      "year" : 2015
    }, {
      "title" : "Neural network training as a dissipative process",
      "author" : [ "Marco Gori", "Marco Maggini", "Alessandro Rossi" ],
      "venue" : "Neural Networks,",
      "citeRegEx" : "3",
      "shortCiteRegEx" : "3",
      "year" : 2016
    }, {
      "title" : "On-line Learning on Temporal Manifolds, pages 321–333",
      "author" : [ "Marco Maggini", "Alessandro Rossi" ],
      "venue" : null,
      "citeRegEx" : "4",
      "shortCiteRegEx" : "4",
      "year" : 2016
    } ],
    "referenceMentions" : [ {
      "referenceID" : 0,
      "context" : "We briefly introduce basics ideas of this theory, first formulated in [1].",
      "startOffset" : 70,
      "endOffset" : 73
    }, {
      "referenceID" : 1,
      "context" : "The concept of dissipation is well formulated in [2],whereas an summing up of this report and an experimental analysis on standard benchmark can be find in [3].",
      "startOffset" : 49,
      "endOffset" : 52
    }, {
      "referenceID" : 2,
      "context" : "The concept of dissipation is well formulated in [2],whereas an summing up of this report and an experimental analysis on standard benchmark can be find in [3].",
      "startOffset" : 156,
      "endOffset" : 159
    }, {
      "referenceID" : 3,
      "context" : "A further theoretical abstraction applied to similar environment is proposed in [4], In this document, we will give a slightly theoretical formulation in order to allow us to go straight to the practical implementation issues.",
      "startOffset" : 80,
      "endOffset" : 83
    }, {
      "referenceID" : 0,
      "context" : "We assign the target class true (f̄k=[1 0] ) to the points in [−0.",
      "startOffset" : 37,
      "endOffset" : 42
    }, {
      "referenceID" : 0,
      "context" : "5] and the class false (f̄k=[0 1] ) to the others.",
      "startOffset" : 28,
      "endOffset" : 33
    } ],
    "year" : 2017,
    "abstractText" : null,
    "creator" : "dvips(k) 5.991 Copyright 2011 Radical Eye Software"
  }
}