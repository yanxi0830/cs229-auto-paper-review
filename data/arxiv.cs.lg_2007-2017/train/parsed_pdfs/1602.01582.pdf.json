{
  "name" : "1602.01582.pdf",
  "metadata" : {
    "source" : "META",
    "title" : "SDCA without Duality, Regularization, and Individual Convexity",
    "authors" : [ "Shai Shalev-Shwartz" ],
    "emails" : [ "SHAIS@CS.HUJI.AC.IL" ],
    "sections" : [ {
      "heading" : null,
      "text" : "ar X\niv :1\n60 2.\n01 58\n2v 2\n[ cs\n.L G\n] 2\n1 M\nay 2\n01 6"
    }, {
      "heading" : "1. Introduction",
      "text" : "We consider the following loss minimization problem:\nmin w∈Rd\nF (w) := 1\nn\nn ∑\ni=1\nfi(w) .\nAn important sub-class of problems is when each fi can be written as fi(w) = φi(w) + λ2 ‖w‖2, where φi is Lismooth and convex. A popular method for solving this sub-class of problems is Stochastic Dual Coordinate Ascent (SDCA), and (Shalev-Shwartz & Zhang, 2013) established the convergence rate of Õ((Lmax/λ+ n) log(1/ǫ)), where Lmax = maxi Li.\nAs its name indicates, SDCA is derived by considering a dual problem. In this paper, we consider the possibility of applying SDCA for problems in which individual fi do not necessarily have the form φi(w) + λ2 ‖w‖2, and can even be non-convex (e.g., deep learning optimization problems, or problems arising in fast calculation of the top singular vectors (Jin et al., 2015)). In many such cases, the\nProceedings of the 33 rd International Conference on Machine Learning, New York, NY, USA, 2016. JMLR: W&CP volume 48. Copyright 2016 by the author(s).\ndual problem is meaningless. Instead of directly using the dual problem, we describe and analyze a variant of SDCA in which only gradients of fi are being used. Following (Johnson & Zhang, 2013), we show that SDCA is a member of the Stochastic Gradient Descent (SGD) family of algorithms, that is, its update is based on an unbiased estimate of the gradient, but unlike the vanilla SGD, for SDCA the variance of the estimation of the gradient tends to zero as we converge to a minimum.\nOur analysis assumes that F is λ-strongly convex and each fi is Li-smooth. When each fi is also convex we establish the convergence rate of Õ(L̄/λ + n), where L̄ is the average of Li and the Õ notation hides logarithmic terms, including the factor log(1/ǫ). This matches the best known bound for SVRG given in (Xiao & Zhang, 2014). Lower bounds have been derived in (Arjevani et al., 2015; Agarwal & Bottou, 2014). Applying an acceleration technique ((Shalev-Shwartz & Zhang, 2015; Lin et al., 2015)) we obtain the convergence rate Õ(n1/2 √\nL̄/λ + n). If fi are non-convex we first prove that SDCA enjoys the rate Õ(L̄2/λ2+n). Finally, we show how the acceleration technique yields the bound Õ ( n3/4 √ L̄/λ+ n ) . That is, we\nhave the same dependency on the square root of the condition number, √ L̄/λ, but this term is multiplied by n3/4 rather than by n1/2. Understanding if this factor can be eliminated is left to future work.\nRelated work: In recent years, many randomized methods for optimizing average of functions have been proposed. For example, SAG (Le Roux et al., 2012), SVRG (Johnson & Zhang, 2013), Finito (Defazio et al., 2014b), SAGA (Defazio et al., 2014a), S2GD (Konečnỳ & Richtárik, 2013), and UniVr (Allen-Zhu & Yuan, 2015). All of these methods have similar convergence rates for strongly convex\nand smooth problems. Here we show that SDCA achieves the best known convergence rate for the case in which individual loss functions are convex, and a slightly worse rate for the case in which individual loss functions are non-convex. A systematic study of the convergence rate of the different methods under non-convex losses is left to future work.\nThis version of the paper improves upon a previous unpublished version of the paper (Shalev-Shwartz, 2015) in three aspects. First, the convergence rate here depends on L̄ as opposed to Lmax in (Shalev-Shwartz, 2015). Second, the version in (Shalev-Shwartz, 2015) only deals with the regularized case, while here we show that the same rate can be obtained for unregularized objectives. Last, for the non-convex case, here we derive the bound Õ ( n3/4 √ L̄/λ+ n ) while in (Shalev-Shwartz,\n2015) only the bound of Õ(L2max/λ 2 + n) has been given.\n(Csiba & Richtárik, 2015) extended the work of (Shalev-Shwartz, 2015) to support arbitrary mini-batching schemes, and (He & Takáč, 2015) extended the work of (Shalev-Shwartz, 2015) to support adaptive sampling probabilities. A primal form of SDCA has been also given in (Defazio, 2014). Using SVRG for non-convex individual functions has been recently studied in (Shamir, 2015; Jin et al., 2015), in the context of fast computation of the top singular vectors of a matrix."
    }, {
      "heading" : "2. SDCA without Duality",
      "text" : "We start the section by describing a variant of SDCA that do not rely on duality. To simplify the presentation, we start in Section 2.1 with regularized loss minimization problems. In Section 2.2 we tackle the non-regularized case and in Section 2.3 we tackle the non-convex case.\nWe recall the following basic definitions: A (differentiable) function f is λ-strongly convex if for every u,w we have f(w) − f(u) ≥ ∇f(u)⊤(w − u) + λ2 ‖w − u‖2. We say that f is convex if it is 0-strongly convex. We say that f is L-smooth if ‖∇f(w) − ∇f(u)‖ ≤ L‖w − u‖. It is well known that smoothness and convexity also implies that f(w) − f(u) ≤ ∇f(u)⊤(w − u) + L2 ‖w − u‖2."
    }, {
      "heading" : "2.1. Regularized problems",
      "text" : "In regularized problems, each fi can be written as fi(w) = φi(w)+ λ 2 ‖w‖2. Similarly to the original SDCA algorithm, we maintain vectors α1, . . . , αn, where each αi ∈ Rd. We call these vectors pseudo-dual vectors. The algorithm is described below.\nAlgorithm 1: Dual-Free SDCA for Regularized Objectives\nGoal: Minimize F (w) = 1n ∑n i=1 φi(w) + λ 2 ‖w‖2 Input: Objective F , number of iterations T , step size η, Smoothness parameters L1, . . . , Ln Initialize: w(0) = 1λn ∑n i=1 α (0) i for some α(0) = (α(0)1 , . . . , α (0) n )\n∀i ∈ [n], qi = (Li + L̄)/(2nL̄) where L̄ = 1n ∑n i=1 Li\nFor t = 1, . . . , T Pick i ∼ q, denote ηi = ηqin Update:\nα (t) i = α (t−1) i − ηiλn\n( ∇φi(w(t−1)) + α(t−1)i )\nw(t) = w(t−1) − ηi ( ∇φi(w(t−1)) + α(t−1)i )\nObserve that SDCA keeps the primal-dual relation\nw(t−1) = 1\nλn\nn ∑\ni=1\nα (t−1) i\nObserve also that the update of α can be rewritten as\nα (t) i = (1− βi)α (t−1) i + βi\n( −∇φi(w(t−1)) ) ,\nwhere βi = ηiλn. Namely, the new value of αi is a convex combination of its old value and the negative gradient. Finally, observe that, conditioned on the value of w(t−1) and α(t−1), we have that\nEi∼q[w (t)] = w(t−1) − η\n∑\ni\nqi qin ( (∇φi(w(t−1)) + α(t−1)i ) )\n= w(t−1) − η (\n∇ 1 n\nn ∑\ni=1\nφi(w (t−1)) + λw(t−1)\n)\n= w(t−1) − η∇P (w(t−1)) .\nThat is, SDCA is in fact an instance of Stochastic Gradient Descent (SGD). As we will see shortly, the advantage of\nSDCA over a vanilla SGD algorithm is because the variance of the update goes to zero as we converge to an optimum.\nOur convergence analysis relies on bounding the following potential function, defined for every t ≥ 0,\nCt = λ 2 ‖w(t) − w∗‖2 + η n2\nn ∑\ni=1\n[ 1\nqi ‖α(t)i − α∗i ‖2] , (1)\nwhere\nw∗ = argmin w F (w), and ∀i, α∗i = −∇φi(w∗) . (2)\nIntuitively, Ct measures the distance to the optimum both in primal and pseudo-dual variables. Observe that if F is LF -smooth and convex then\nF (w(t))− F (w∗) ≤ LF 2 ‖w(t) − w∗‖2 ≤ LF λ Ct ,\nand therefore a bound on Ct immediately implies a bound on the sub-optimality of w(t).\nThe following theorem establishes the convergence rate of SDCA for the case in which each φi is convex.\nTheorem 1 Assume that each φi is Li-smooth and convex, and Algorithm 1 is run with η ≤ min {\n1 4L̄ , 14λn }\n. Then, for every t ≥ 1,\nE[Ct] ≤ (1 − ηλ)t C0 ,\nwhere Ct is as defined in (1). In particular, to achieve E[F (w(T )) − F (w∗)] ≤ ǫ it suffices to set η = min {\n1 4L̄ , 14λn } and\nT ≥ Ω̃ ( L̄\nλ + n\n)\n.\nVariance Reduction: The lemma below tells us that the variance of the SDCA update decreases as we get closer to the optimum.\nLemma 1 Under the same conditions of Theorem 1, the expected value of ‖w(t) −w(t−1)‖2 conditioned on w(t−1) satisfies:\nE[‖w(t)−w(t−1)‖2] ≤ 3 η (\n1 2‖w (t−1) − w∗‖2 + Ct−1 ) ."
    }, {
      "heading" : "2.2. SDCA without regularization",
      "text" : "We now turn to the case in which the objective is not explicitly regularized. The algorithm below tackles this problem by a reduction to the regularized case. In particular, we artificially add regularization to the objective and compensate for it by adding one more loss function that cancels out the regularization term. While the added function is not convex (in fact, it is concave), we prove that the same convergence rate holds due to the special structure of the added loss function.\nAlgorithm 2: Dual-Free SDCA for Non-Regularized Objectives\nGoal: Minimize F (w) = 1n ∑n\ni=1 fi(w) Input: Objective F , number of iterations T ,\nstep size η, Strong convexity parameter λ, Smoothness parameters L1, . . . , Ln\nDefine: For all i ∈ [n], φi(w) = n+1n fi(w), L̃i = n+1n Li For i = n+ 1, φi(w) = −λ i2 ‖w‖2, L̃i = λ i Solve: Rewrite F as F (w) = 1n+1 ∑n+1 i=1 φi(w) + λ 2 ‖w‖2\nCall Algorithm 1 with F above and with {L̃i}\nTheorem 2 Assume that F is λ-strongly convex, that each fi is Li-smooth and convex, and that Algorithm 2 is run with η ≤ min {\n1 8(L̄+λ) , 14 λ(n+1)\n}\n. Then, for every t ≥ 1,\nE[Ct] ≤ (1 − ηλ)t C0 ,\nwhere Ct is as defined in (1). In particular, to achieve E[F (w(T )) − F (w∗)] ≤ ǫ it suffices to set η = min {\n1 8(L̄+λ) , 14λ(n+1)\n}\nand\nT ≥ Ω̃ ( L̄\nλ + n\n)\n."
    }, {
      "heading" : "2.3. The non-convex case",
      "text" : "We now consider the non-convex case. For simplicity, we focus on the regularized setting. In the non-regularized setting we can simply replace every fi with φi(w) = fi(w)− λ2 ‖w‖2 and apply the regularized setting. Note that this does not change significantly the smoothness (because λ is typically much smaller than the average smoothness of the fi).\nWe can apply Algorithm 1 for the non-convex case, and the only change is the choice of η, as reflected in the theorem below.\nTheorem 3 Consider running algorithm 1 on F which is λ-strongly convex, assume that each φi is Li-smooth, and η ≤ min {\nλ 4L̄2 , 14λn } . Then, for every t ≥ 1,\nE[Ct] ≤ (1 − ηλ)t C0 ,\nwhere Ct is as defined in (1). In particular, to achieve E[F (w(T )) − F (w∗)] ≤ ǫ it suffices to set η = min {\nλ 4L̄2 , 14λn } and\nT ≥ Ω̃ ( L̄2\nλ2 + n\n)\n.\nAs can be seen, the dependence of T on the condition number, L̄λ , is quadratic for the non-convex case, as opposed to a linear dependency for the convex case. We next show how to improve the bound using acceleration."
    }, {
      "heading" : "2.4. Acceleration",
      "text" : "Accelerated SDCA (Shalev-Shwartz & Zhang, 2015) is obtained by solving (using SDCA) a sequence of problems, where at each iteration, we add an artificial regularization of the form κ2 ‖w − y(t−1)‖2, where y(t−1) is a function of w(t−1) and w(t−2). The algorithm has been generalized in (Lin et al., 2015) to allow the inner solver to be any algorithm. For completeness, we provide the pseudo-code of the “Catalyst” algorithm of (Lin et al., 2015) and its analysis.\nAlgorithm 3: Acceleration\nGoal: Minimize a λ-strongly convex function F (w) Parameters: κ, T Initialize:\nInitial solution w(0) ǫ0 s.t. ǫ0 ≥ F (w(0))− F (w∗) y(0) = w(0), q = λλ+κ\nFor: t = 1, . . . , T Define Gt(w) = F (w) + κ2 ‖w − y(t−1)‖2 Set ǫt = (1 − 0.9 √ q) ǫt−1\nFind w(t) s.t. Gt(w(t))−minw Gt(w) ≤ ǫt Set y(t) = w(t) + √ q−q√ q+q (w\n(t) − w(t−1)) Output: w(T )\nLemma 2 Fix ǫ > 0 and suppose we run the Acceleration algorithm (Algorithm 3) for\nT = Ω\n(\n√\nλ+ κ\nλ log\n(\nλ+ κ\nλ ǫ\n)\n)\niterations. Then, F (w(T ))− F (w∗) ≤ ǫ.\nProof The lemma follows directly from Theorem 3.1 of (Lin et al., 2015) by observing that Algorithm 3 is a specification of Algorithm 1 in (Lin et al., 2015) with α0 = √ q (which implies that αt = α0 for every t), with ǫt = ǫ0(1− ρ)t, and with ρ = 0.9 √ q.\nTheorem 4 Let F = 1n ∑n i=1 φi(w) + λ 2 ‖w‖2, assume that each φi is Li smooth and that F is λ-strongly convex. Assume also that (L̄/λ)2 ≥ 3n (otherwise we can simply apply Õ(n) iterations of Algorithm 1). Then, running Algorithm 3 with parameters κ = L̄/ √ n, T = Ω̃ ( 1 + n−1/4 √ L̄/λ ) , and while at each iteration of Al-\ngorithm 3 using Ω̃ (n) iterations of Algorithm 1 to minimize Gt, guarantees that F (w(T ))−F (w∗) ≤ ǫ (with high probability). The total required number of iterations of Algorithm 1 is therefore bounded by Õ ( n+ n3/4 √ L̄/λ ) .\nObserve that for the case of convex individual functions, accelerating Algorithm 1 yields the upper bound Õ ( n+ n1/2 √ L̄/λ ) . Therefore, the convex and non-\nconvex cases have the same dependency on the condition number, but the non-convex case has a worse dependence on n."
    }, {
      "heading" : "3. Proofs",
      "text" : ""
    }, {
      "heading" : "3.1. Proof of Theorem 1",
      "text" : "Observe that 0 = ∇F (w∗) = 1n ∑ i ∇φi(w∗) + λw∗, which implies that w∗ = 1λn ∑ i α ∗ i , where α ∗ i = −∇φi(w∗).\nDefine ui = −∇φi(w(t−1)) and vi = −ui + α(t−1)i . We also denote two potentials:\nAt =\nn ∑\nj=1\n1 qj ‖α(t)j − α∗j‖2 , Bt = ‖w(t) − w∗‖2 .\nWe will first analyze the evolution of At and Bt. If on round t we update using element i then α(t)i = (1 − βi)α (t−1) i + βiui. It follows that,\nAt−1 −At = − 1\nqi ‖α(t)i − α∗i ‖2 +\n1 qi ‖α(t−1)i − α∗i ‖2\n(3)\n= − 1 qi ‖(1− βi)(α(t−1)i − α∗i ) + βi(ui − α∗i )‖2\n+ 1 qi ‖α(t−1)i − α∗i ‖2\n= 1 qi (−(1− βi)‖α(t−1)i − α∗i ‖2 − βi‖ui − α∗i ‖2\n+ βi(1 − βi)‖α(t−1)i − ui‖2 + ‖α (t−1) i − α∗i ‖2 )\n= βi qi ( ‖α(t−1)i − α∗i ‖2 − ‖ui − α∗i ‖2 + (1− βi)‖vi‖2 ) = η λ\nq2i\n( ‖α(t−1)i − α∗i ‖2 − ‖ui − α∗i ‖2 + (1− βi)‖vi‖2 ) .\n(4)\nTaking expectation w.r.t. i ∼ q we obtain\nE[At−1 −At] =\nηλ n ∑\ni=1\n1\nqi\n( ‖α(t−1)i − α∗i ‖2 − ‖ui − α∗i ‖2 + (1− βi)‖vi‖2 )\n(5)\n= ηλ\n(\nAt−1 +\nn ∑\ni=1\n1\nqi\n( −‖ui − α∗i ‖2 + (1− βi)‖vi‖2 )\n)\n.\n(6)\nAs to the second potential, we have\nBt−1 −Bt = −‖w(t) − w∗‖2 + ‖w(t−1) − w∗‖2 (7) = 2 (w(t−1) − w∗)⊤(η vi)− η2i ‖vi‖2 .\nTaking expectation w.r.t. i ∼ q and noting that Ei∼q(ηivi) = η∇F (w(t−1)) we obtain\nE[Bt−1 −Bt] =2η (w(t−1) − w∗)⊤∇F (w(t−1)) (8)\n− η 2\nn2\n∑\ni\n1 qi ‖vi‖2 .\nWe now take a potential of the form Ct = caAt + cbBt.\nCombining (6) and (8) we obtain\nE[Ct−1 − Ct] = caηλAt−1 − caηλ ∑\ni\n1 qi ‖ui − α∗i ‖2\n+ 2cbη(w (t−1) − w∗)⊤∇F (w(t−1))\n+ ∑\ni\n1 qi ‖vi‖2\n(\ncaηλ(1 − βi)− cbη\n2\nn2\n)\n(9)\nWe will choose the parameters η, ca, cb such that\nη ≤ min { qi 2λ , 1 4L̄ } and cb ca = λn2 2η (10)\nThis implies that βi = ηiλn = ηλ qi ≤ 1/2, and therefore the term in (9) is non-negative. Next, due to strong convexity of F we have that\n(w(t−1) − w∗)⊤∇F (w(t−1))\n≥ F (w(t−1))− F (w∗) + λ 2 ‖w(t−1) − w∗‖2 .\nTherefore,\nE[Ct−1 − Ct] = caηλAt−1 − caηλ ∑\ni\n1 qi ‖ui − α∗i ‖2\n+ 2cbη(F (w (t−1))− F (w∗)) + cbηλBt−1\n= η λCt−1+\nη\n(\n2cb(F (w (t−1))− F (w∗))− caλ\n∑\ni\n1 qi ‖ui − α∗i ‖2\n)\n.\n(11)\nNote that ui−α∗i = ∇φi(w(t−1))−∇φi(w∗). In Lemma 3 we show that when φi is Li smooth and convex then\n‖∇φi(w(t−1))−∇φi(w∗)‖2 (12) ≤ 2Li (φi(w(t−1))− φi(w∗)−∇φi(w∗)⊤(w(t−1) − w∗))\nTherefore, denoting τ = (\n2 maxi Li qi\n)\nwe obtain that\n∑\ni\n1 qi ‖ui − α∗i ‖2 = ∑\ni\n1 qi ‖∇φi(w(t−1))−∇φi(w∗)‖2\n(13)\n≤ τ ∑\ni\n(φi(w (t−1))− φi(w∗)−∇φi(w∗)⊤(w(t−1) − w∗))\n= τ n\n(\nF (w(t−1))− F (w∗)− λ 2 ‖w(t−1) − w∗‖2\n)\n≤ τ n ( F (w(t−1))− F (w∗) ) . (14)\nThe definition of qi implies that for every i,\nLi qi = 2nL̄ Li Li + L̄ ≤ 2nL̄ . (15)\nCombining this with (13) and (11) we obtain\nE[Ct−1 − Ct] ≥ η λCt−1 + η ( 2cb − 4n2L̄λca ) (F (w(t−1))− F (w∗))\nPlugging the value of cb = caλn 2\n2η yields that the coefficient in the last term is\n2 caλn\n2\n2η − 4n2L̄λca = caλn2\n(\n1 η − 4L̄\n)\n≥ 0 ,\nwhere we used the choice of η ≤ 1 4L̄ . In summary, we have shown that E[Ct−1 − Ct] ≥ η λCt−1, which implies that\nE[Ct] ≤ (1− η λ)Ct−1 .\nTaking expectation over Ct−1 and continue recursively, we obtain that E[Ct] ≤ (1− η λ)t C0 ≤ e−η λ t C0. Finally, since qi ≥ 1/(2n) for every i, we can choose\nη = min\n{\n1\n4L̄ ,\n1\n4λn\n}\nand therefore 1\nηλ ≤ 4\n(\nn+ L̄\nλ\n)\n.\nThe proof is concluded by choosing cb = λ/2 and ca = η/n2."
    }, {
      "heading" : "3.2. Proof of Lemma 1",
      "text" : "We have:\nE[‖w(t) − w(t−1)‖2] = ∑\ni\nqiη 2 i ‖∇φi(w(t−1)) + α (t−1) i ‖2\n≤ 3η 2\nn2\n∑\ni\n1 qi (‖∇φi(w(t−1)) + α∗i ‖2\n+ ‖α(t−1)i − α∗i ‖2) (triangle inequality)\n= 3η2\nn2\n∑\ni\n( 1qi ‖∇φi(w (t−1))−∇φi(w∗)‖2\n+ 1qi ‖α (t−1) i − α∗i ‖2)\n≤ 3η 2\nn2\n∑\ni\n(\n2nL̄ ‖w(t−1) − w∗‖2 + 1qi ‖α (t−1) i − α∗i ‖2\n)\n(smoothness and (15))\n≤ 3 η (\n1 2‖w (t−1) − w∗‖2 + Ct−1 )\n(because η ≤ 1 4L̄ ) ."
    }, {
      "heading" : "3.3. Proof of Theorem 2",
      "text" : "The beginning of the proof is identical to the proof of Theorem 1. The change starts in (13), where we cannot apply (12) to φn+1 because it is not convex. To overcome this, we first apply (12) to φ1, . . . , φn, and obtain that\nn ∑\ni=1\n1 qi ‖ui − α∗i ‖2 =\nn ∑\ni=1\n1 qi ‖∇φi(w(t−1))−∇φi(w∗)‖2\n≤ (\n2 max i L̃i qi\n)\n·\nn ∑\ni=1\n(φi(w (t−1))− φi(w∗)−∇φi(w∗)⊤(w(t−1) − w∗))\n= 2 (n+ 1)\n(\nmax i L̃i qi\n)\n(F (w(t−1))− F (w∗)) ,\nwhere the last equality follows from the fact that ∑n\ni=1 φi(w) = (n + 1)F (w), which also implies that ∑\ni∇φi(w∗) = 0. In addition, since φn+1(w) =\n−λ(n+1)2 ‖w‖2, we have 1\nqn+1 ‖∇φn+1(w) −∇φn+1(w∗)‖2 = λ2(n+ 1)2\nqn+1 ‖w − w∗‖2\n= 2 (n+ 1) L̃n+1 qn+1 · λ 2 ‖w − w∗‖2\n≤ 2 (n+ 1) L̃n+1 qn+1 (F (w) − F (w∗)) ,\nwhere the last inequality is because of the λ-strong convexity of F . Combining the two inequalities, we obtain an analogue of (13),\nn+1 ∑\ni=1\n1 qi ‖ui − α∗i ‖2\n≤ 4 (n+ 1) (\nmax i∈[n+1] L̃i qi\n)\n(F (w(t−1))− F (w∗)) .\nThe rest of the proof is almost identical, except that we have n replaced by n+1 and L̄ replaced by L̃ := 1n+1 ∑n i=1 L̃i. We now need to choose\nη = min\n{\n1\n8L̃ ,\n1\n4λ(n+ 1)\n}\n.\nObserve that,\n(n+1)L̃ = n+ 1\nn\n(\nn ∑\ni=1\nLi\n)\n+λ(n+1) = (n+1)(L̄+λ) ,\nso we can rewrite\nη = min\n{\n1\n8(L̄+ λ) ,\n1\n4λ(n+ 1)\n}\n.\nThis yields 1\nηλ ≤ 4\n(\nn+ 3 + 2L̄\nλ\n)\n."
    }, {
      "heading" : "3.4. Proof of Theorem 3",
      "text" : "The beginning of the proof is identical to the proof of Theorem 1 up to (9).\nWe will choose the parameters η, ca, cb such that\nη ≤ min { qi 2λ , 1 4L̄ } and cb ca = λn2 2η (16)\nThis implies that βi = ηiλn = ηλ qi ≤ 1/2, and therefore the term in (9) is non-negative. Next, due to strong convexity of F we have that\n(w(t−1) − w∗)⊤∇F (w(t−1))\n≥ F (w(t−1))− F (w∗) + λ 2 ‖w(t−1) − w∗‖2 ≥ λ‖w(t−1) − w∗‖2 .\nTherefore,\nE[Ct−1 − Ct]\n= caηλAt−1 − caηλ ∑\ni\n1 qi ‖ui − α∗i ‖2 + 2cbηλBt−1\n= η λCt−1 + η λ\n(\ncbBt−1 − ca ∑\ni\n1 qi ‖ui − α∗i ‖2\n)\n.\n(17)\nNext, we use the smoothness of the φi to get\n∑\ni\n1 qi ‖ui − α∗i ‖2 = ∑\ni\n1 qi ‖∇φi(w(t−1))−∇φi(w∗)‖2\n≤ ∑\ni\nL2i qi ‖w(t−1) − w∗‖2 = Bt−1 ∑\ni\nL2i qi .\nThe definition of qi implies that for every i,\nLi qi = 2nL̄ Li Li + L̄ ≤ 2nL̄ ,\nso by combining with (17) we obtain\nE[Ct−1 − Ct] ≥ η λCt−1 + ηλ ( cb − 2n2L̄2ca ) Bt−1\nThe last term will be non-negative if cbca ≥ 2n 2L̄2. Since we chose cbca = λn2 2η we obtain the requirement\nλn2\n2η ≥ 2n2L̄2 ⇒ η ≤ λ 4L̄2 .\nIn summary, we have shown that E[Ct−1−Ct] ≥ η λCt−1. The rest of the proof is identical, but the requirement on η is\nη ≤ min { λ\n4L̄2 ,\n1\n4λn\n}\n,\nand therefore 1\nηλ ≤ 4\n(\nn+ L̄2\nλ2\n)\n."
    }, {
      "heading" : "4. Proof of Theorem 4",
      "text" : "Proof Each iteration of Algorithm 3 requires to minimize Gt to accuracy ǫt ≤ O(1) (1 − ρ)t, where ρ = 0.9 √ q. If t ≤ T where T is as defined in Lemma 2, then we have that,\n−t log(1−ρ) ≤ −T log(1−ρ) = − log(1 − ρ) ρ log\n(\n800\nq ǫ\n)\nUsing Lemma 4, − log(1−ρ)ρ ≤ 2 for every ρ ∈ (0, 1/2). In our case, ρ is indeed in (0, 1/2) because of the definition of κ and our assumption that (L̄/λ)2 ≥ 3n. Hence,\nlog( 1ǫt ) = O(log((λ+ κ)/(λǫ))) .\nCombining this with Theorem 3, and using the definition of Gt, we obtain that the number of iterations required1 by each application of Algorithm 3 is\nÕ\n(\n(L̄+ κ)2 (λ+ κ)2 + n\n)\n= Õ(n) ,\nwhere in the equality we used the definition of κ. Finally, multiplying this by the value of T as given in Lemma 2 we obtain (ignoring log-terms):\n√\n1 + κ\nλ n ≤ (1 +\n√\nκ λ )n = n+ n3/4\n√\nL̄ λ ."
    }, {
      "heading" : "4.1. Technical Lemmas",
      "text" : "Lemma 3 Assume that φ is L-smooth and convex. Then, for every w and u,\n‖∇φ(w)−∇φ(u)‖2 ≤ 2L [ φ(w) − φ(u)−∇φ(u)⊤(w − u) ] .\nProof For every i, define\ng(w) = φ(w) − φ(u)−∇φ(u)⊤(w − u) .\nClearly, since φ is L-smooth so is g. In addition, by convexity of φ we have g(w) ≥ 0 for all w. It follows that g is nonnegative and smooth, and therefore, it is self-bounded (see\n1While Theorem 3 bounds the expected sub-optimality, by techniques similar to (Shalev-Shwartz & Zhang, 2015) it can be converted to a bound that holds with high probability.\nSection 12.1.3 in (Shalev-Shwartz & Ben-David, 2014)):\n‖∇g(w)‖2 ≤ 2Lg(w) .\nUsing the definition of g, we obtain\n‖∇φ(w) −∇φ(u)‖2\n= ‖∇g(w)‖2 ≤ 2Lg(w) = 2L [ φ(w) − φ(u)−∇φ(u)⊤(w − u) ] .\nLemma 4 For a ∈ (0, 1/2)we have− log(1−a)/a ≤ 1.4.\nProof Denote g(a) = − log(1 − a)/a. It is easy to verify that the derivative of g in (0, 1/2) is positive and that g(0.5) ≤ 1.4. The proof follows."
    }, {
      "heading" : "5. Summary",
      "text" : "We have described and analyzed a dual free version of SDCA that supports non-regularized objectives and nonconvex individual loss functions. Our analysis shows a linear rate of convergence for all of these cases. Two immediate open questions are whether the worse dependence on the condition number for the non-accelerated result for the non-convex case is necessary, and whether the factor n3/4 in Theorem 4 can be reduced to n1/2.\nAcknowledgements: In a previous draft of this paper, the bound for the non-convex case was n5/4+n3/4 √\nL̄/λ. We thank Ohad Shamir for showing us how to derive the improved bound of n + n3/4 √\nL̄/λ. The work is supported by ICRI-CI and by the European Research Council (TheoryDL project)."
    } ],
    "references" : [ {
      "title" : "A lower bound for the optimization of finite sums",
      "author" : [ "Agarwal", "Alekh", "Bottou", "Leon" ],
      "venue" : "In ICML,",
      "citeRegEx" : "Agarwal et al\\.,? \\Q2014\\E",
      "shortCiteRegEx" : "Agarwal et al\\.",
      "year" : 2014
    }, {
      "title" : "Univr: A universal variance reduction framework for proximal stochastic gradient method",
      "author" : [ "Allen-Zhu", "Zeyuan", "Yuan", "Yang" ],
      "venue" : "arXiv preprint arXiv:1506.01972,",
      "citeRegEx" : "Allen.Zhu et al\\.,? \\Q2015\\E",
      "shortCiteRegEx" : "Allen.Zhu et al\\.",
      "year" : 2015
    }, {
      "title" : "On lower and upper bounds for smooth and strongly convex optimization problems",
      "author" : [ "Arjevani", "Yossi", "Shalev-Shwartz", "Shai", "Shamir", "Ohad" ],
      "venue" : "arXiv preprint arXiv:1503.06833,",
      "citeRegEx" : "Arjevani et al\\.,? \\Q2015\\E",
      "shortCiteRegEx" : "Arjevani et al\\.",
      "year" : 2015
    }, {
      "title" : "Primal method for erm with flexible mini-batching schemes and nonconvex losses",
      "author" : [ "Csiba", "Dominik", "Richtárik", "Peter" ],
      "venue" : "arXiv preprint arXiv:1506.02227,",
      "citeRegEx" : "Csiba et al\\.,? \\Q2015\\E",
      "shortCiteRegEx" : "Csiba et al\\.",
      "year" : 2015
    }, {
      "title" : "New Optimisation Methods for Machine Learning",
      "author" : [ "Defazio", "Aaron" ],
      "venue" : "PhD thesis, Australian National Univer- sity,",
      "citeRegEx" : "Defazio and Aaron.,? \\Q2014\\E",
      "shortCiteRegEx" : "Defazio and Aaron.",
      "year" : 2014
    }, {
      "title" : "Saga: A fast incremental gradient method with support for non-strongly convex composite objectives",
      "author" : [ "Defazio", "Aaron", "Bach", "Francis", "Lacoste-Julien", "Simon" ],
      "venue" : "In Advances in Neural Information Processing Systems,",
      "citeRegEx" : "Defazio et al\\.,? \\Q2014\\E",
      "shortCiteRegEx" : "Defazio et al\\.",
      "year" : 2014
    }, {
      "title" : "Finito: A faster, permutable incremental gradient method for big data problems",
      "author" : [ "Defazio", "Aaron J", "Caetano", "Tibério S", "Domke", "Justin" ],
      "venue" : "arXiv preprint arXiv:1407.2710,",
      "citeRegEx" : "Defazio et al\\.,? \\Q2014\\E",
      "shortCiteRegEx" : "Defazio et al\\.",
      "year" : 2014
    }, {
      "title" : "Dual free sdca for empirical risk minimization with adaptive probabilities",
      "author" : [ "He", "Xi", "Takáč", "Martin" ],
      "venue" : "arXiv preprint arXiv:1510.06684,",
      "citeRegEx" : "He et al\\.,? \\Q2015\\E",
      "shortCiteRegEx" : "He et al\\.",
      "year" : 2015
    }, {
      "title" : "Robust shift-and-invert preconditioning: Faster and more sample efficient algorithms for eigenvector computation",
      "author" : [ "Jin", "Chi", "Kakade", "Sham M", "Musco", "Cameron", "Netrapalli", "Praneeth", "Sidford", "Aaron" ],
      "venue" : "arXiv preprint arXiv:1510.08896,",
      "citeRegEx" : "Jin et al\\.,? \\Q2015\\E",
      "shortCiteRegEx" : "Jin et al\\.",
      "year" : 2015
    }, {
      "title" : "Accelerating stochastic gradient descent using predictive variance reduction",
      "author" : [ "Johnson", "Rie", "Zhang", "Tong" ],
      "venue" : "In Advances in Neural Information Processing Systems,",
      "citeRegEx" : "Johnson et al\\.,? \\Q2013\\E",
      "shortCiteRegEx" : "Johnson et al\\.",
      "year" : 2013
    }, {
      "title" : "Semi-stochastic gradient descent methods",
      "author" : [ "Konečnỳ", "Jakub", "Richtárik", "Peter" ],
      "venue" : "arXiv preprint arXiv:1312.1666,",
      "citeRegEx" : "Konečnỳ et al\\.,? \\Q2013\\E",
      "shortCiteRegEx" : "Konečnỳ et al\\.",
      "year" : 2013
    }, {
      "title" : "A stochastic gradient method with an exponential convergence rate for finite training sets",
      "author" : [ "Le Roux", "Nicolas", "Schmidt", "Mark", "Bach", "Francis" ],
      "venue" : "In Advances in Neural Information Processing Systems,",
      "citeRegEx" : "Roux et al\\.,? \\Q2012\\E",
      "shortCiteRegEx" : "Roux et al\\.",
      "year" : 2012
    }, {
      "title" : "A universal catalyst for first-order optimization",
      "author" : [ "Lin", "Hongzhou", "Mairal", "Julien", "Harchaoui", "Zaid" ],
      "venue" : "In Advances in Neural Information Processing Systems,",
      "citeRegEx" : "Lin et al\\.,? \\Q2015\\E",
      "shortCiteRegEx" : "Lin et al\\.",
      "year" : 2015
    }, {
      "title" : "Accelerated proximal stochastic dual coordinate ascent for regularized loss minimization",
      "author" : [ "S. Shalev-Shwartz", "T. Zhang" ],
      "venue" : "Mathematical Programming SERIES A and B (to appear),",
      "citeRegEx" : "Shalev.Shwartz and Zhang,? \\Q2015\\E",
      "shortCiteRegEx" : "Shalev.Shwartz and Zhang",
      "year" : 2015
    }, {
      "title" : "Sdca without duality",
      "author" : [ "Shalev-Shwartz", "Shai" ],
      "venue" : "arXiv preprint arXiv:1502.06177,",
      "citeRegEx" : "Shalev.Shwartz and Shai.,? \\Q2015\\E",
      "shortCiteRegEx" : "Shalev.Shwartz and Shai.",
      "year" : 2015
    }, {
      "title" : "Understanding Machine Learning: From Theory to Algorithms",
      "author" : [ "Shalev-Shwartz", "Shai", "Ben-David" ],
      "venue" : "Cambridge university press,",
      "citeRegEx" : "Shalev.Shwartz et al\\.,? \\Q2014\\E",
      "shortCiteRegEx" : "Shalev.Shwartz et al\\.",
      "year" : 2014
    }, {
      "title" : "Stochastic dual coordinate ascent methods for regularized loss minimization",
      "author" : [ "Shalev-Shwartz", "Shai", "Zhang", "Tong" ],
      "venue" : "Journal of Machine Learning Research,",
      "citeRegEx" : "Shalev.Shwartz et al\\.,? \\Q2013\\E",
      "shortCiteRegEx" : "Shalev.Shwartz et al\\.",
      "year" : 2013
    }, {
      "title" : "A stochastic pca and svd algorithm with an exponential convergence rate",
      "author" : [ "Shamir", "Ohad" ],
      "venue" : "In ICML,",
      "citeRegEx" : "Shamir and Ohad.,? \\Q2015\\E",
      "shortCiteRegEx" : "Shamir and Ohad.",
      "year" : 2015
    }, {
      "title" : "A proximal stochastic gradient method with progressive variance reduction",
      "author" : [ "Xiao", "Lin", "Zhang", "Tong" ],
      "venue" : "SIAM Journal on Optimization,",
      "citeRegEx" : "Xiao et al\\.,? \\Q2014\\E",
      "shortCiteRegEx" : "Xiao et al\\.",
      "year" : 2014
    } ],
    "referenceMentions" : [ {
      "referenceID" : 8,
      "context" : ", deep learning optimization problems, or problems arising in fast calculation of the top singular vectors (Jin et al., 2015)).",
      "startOffset" : 107,
      "endOffset" : 125
    }, {
      "referenceID" : 2,
      "context" : "Lower bounds have been derived in (Arjevani et al., 2015; Agarwal & Bottou, 2014).",
      "startOffset" : 34,
      "endOffset" : 81
    }, {
      "referenceID" : 12,
      "context" : "Applying an acceleration technique ((Shalev-Shwartz & Zhang, 2015; Lin et al., 2015)) we obtain the convergence rate Õ(n √",
      "startOffset" : 36,
      "endOffset" : 84
    }, {
      "referenceID" : 8,
      "context" : "Using SVRG for non-convex individual functions has been recently studied in (Shamir, 2015; Jin et al., 2015), in the context of fast computation of the top singular vectors of a matrix.",
      "startOffset" : 76,
      "endOffset" : 108
    }, {
      "referenceID" : 12,
      "context" : "The algorithm has been generalized in (Lin et al., 2015) to allow the inner solver to be any algorithm.",
      "startOffset" : 38,
      "endOffset" : 56
    }, {
      "referenceID" : 12,
      "context" : "For completeness, we provide the pseudo-code of the “Catalyst” algorithm of (Lin et al., 2015) and its analysis.",
      "startOffset" : 76,
      "endOffset" : 94
    }, {
      "referenceID" : 12,
      "context" : "1 of (Lin et al., 2015) by observing that Algorithm 3 is a specification of Algorithm 1 in (Lin et al.",
      "startOffset" : 5,
      "endOffset" : 23
    }, {
      "referenceID" : 12,
      "context" : ", 2015) by observing that Algorithm 3 is a specification of Algorithm 1 in (Lin et al., 2015) with α0 = √ q (which implies that αt = α0 for every t), with ǫt = ǫ0(1− ρ), and with ρ = 0.",
      "startOffset" : 75,
      "endOffset" : 93
    } ],
    "year" : 2016,
    "abstractText" : "Stochastic Dual Coordinate Ascent is a popular method for solving regularized loss minimization for the case of convex losses. We describe variants of SDCA that do not require explicit regularization and do not rely on duality. We prove linear convergence rates even if individual loss functions are non-convex, as long as the expected loss is strongly convex.",
    "creator" : "LaTeX with hyperref package"
  }
}