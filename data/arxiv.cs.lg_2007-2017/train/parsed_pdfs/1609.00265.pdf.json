{
  "name" : "1609.00265.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : null,
    "authors" : [ "Clément L. Canonne", "Elena Grigorescu", "Siyao Guo", "Akash Kumar", "Karl Wimmer" ],
    "emails" : [ "ccanonne@cs.columbia.edu.", "elena-g@purdue.edu.", "sg191@nyu.edu.", "akumar@purdue.edu.", "wimmerk@duq.edu." ],
    "sections" : [ {
      "heading" : null,
      "text" : "ar X\niv :1\n60 9.\n00 26\n5v 2\n[ cs\n.D S]\n1 4\nMotivated by the recent interest in k-monotone functions in the context of circuit complexity and learning theory, and by the central role that monotonicity testing plays in the context of property testing, we initiate a systematic study of k-monotone functions, in the property testing model. In this model, the goal is to distinguish functions that are k-monotone (or are close to being k-monotone) from functions that are far from being k-monotone.\nOur results include the following:\n1. We demonstrate a separation between testing k-monotonicity and testing monotonicity, on the hypercube domain {0, 1}d, for k ≥ 3; 2. We demonstrate a separation between testing and learning on {0, 1}d, for k = ω(log d): testing k-monotonicity can be performed with 2O( √ d·log d·log 1/ε) queries, while learning\nk-monotone functions requires 2Ω(k· √ d·1/ε) queries (Blais et al. (RANDOM 2015)).\n3. We present a tolerant test for functions f : [n]d → {0, 1} with complexity independent of n, which makes progress on a problem left open by Berman et al. (STOC 2014).\nOur techniques exploit the testing-by-learning paradigm, use novel applications of Fourier analysis on the grid [n]d, and draw connections to distribution testing techniques.\n∗Columbia University. Email: ccanonne@cs.columbia.edu. Research supported by NSF CCF-1115703 and NSF CCF-1319788.\n†Purdue University. Email: elena-g@purdue.edu. Research supported in part by NSF CCF-1649515. ‡Courant Institute of Mathematical Sciences, New York University. Email: sg191@nyu.edu. §Purdue University. Email: akumar@purdue.edu. ¶Duquesne University. Email: wimmerk@duq.edu.\nContents"
    }, {
      "heading" : "1 Introduction 3",
      "text" : "1.1 Our results . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 3\n1.1.1 Testing k-monotonicity on the hypercube {0, 1}d . . . . . . . . . . . . . . . . 3 1.1.2 Testing k-monotonicity on the hypergrid [n]d . . . . . . . . . . . . . . . . . . 4\n1.2 Proofs overview and technical contribution . . . . . . . . . . . . . . . . . . . . . . . . 6 1.3 Discussion and open problems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 8 1.4 Related work . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 9 1.5 Organization of the paper . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 9"
    }, {
      "heading" : "2 Preliminaries 10",
      "text" : ""
    }, {
      "heading" : "3 On the Boolean hypercube 11",
      "text" : "3.1 Upper bound: beating the learning approach . . . . . . . . . . . . . . . . . . . . . . 11 3.2 Lower bounds . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 12\n3.2.1 One-sided lower bounds . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 13 3.2.2 Two-sided lower bounds . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 14"
    }, {
      "heading" : "4 On the line 16",
      "text" : "4.1 Upper and lower bounds for one-sided testers . . . . . . . . . . . . . . . . . . . . . . 16 4.2 Upper bound for two-sided testers: proof of Theorem 1.5 . . . . . . . . . . . . . . . . 19\n4.2.1 Testing k-monotonicity over [Ck] . . . . . . . . . . . . . . . . . . . . . . . . . 20 4.2.2 Reducing [n] → {0, 1} to [Ck] → {0, 1}. . . . . . . . . . . . . . . . . . . . . . 22"
    }, {
      "heading" : "5 On the grid 23",
      "text" : "5.1 The case k = 2 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 23 5.2 Possible extensions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 27"
    }, {
      "heading" : "6 On the high-dimensional grid 28",
      "text" : "6.1 Fully tolerant testing with O(kd/(ε2 − ε1)))d queries . . . . . . . . . . . . . . . . . . 29 6.2 Tolerant testing via agnostic learning . . . . . . . . . . . . . . . . . . . . . . . . . . . 31\n7 Tolerant testing and applications to L1-testing 34"
    }, {
      "heading" : "A Previous work on monotonicity testing 40",
      "text" : ""
    }, {
      "heading" : "B Structural results 42",
      "text" : "C Omitted proofs 44"
    }, {
      "heading" : "1 Introduction",
      "text" : "A function f : D → {0, 1}, defined over a finite domain D equipped with a partial order, is said to be k-monotone, for some integer k ≥ 0, if there does not exist x1 x2 . . . xk+1 in D such that f(x1) = 1 and f(xi) 6= f(xi+1) for all i ∈ [k]. Note that 1-monotone functions are the classical monotone functions, satisfying f(x1) ≤ f(x2), whenever x1 x2.\nMonotone functions have been well-studied on multiple fronts in computational complexity due to their natural structure. They have been celebrated for decades in the property testing literature [GGL+00, DGL+99, FLN+02, BCGM12, CS13b, CS13a, CS14], where we have recently witnessed ultimate results [KMS15, CDST15, BB16], in the circuit complexity literature, where we now have strong lower bounds [RW92, Raz85], and in computational learning, where we now have learning algorithms in numerous learning models [BT96, Ang87, KV94, Ser04, OS07, OW09].\nThe generalized notion of k-monotonicity has also been studied in the context of circuit lower bounds for more than 50 years. In particular, Markov [Mar57] showed that any k-monotone function (even with multiple outputs) can be computed using circuits containing only log k negation gates. The presence of negation gates appears to be a challenge in proving circuit lower bounds: “the effect of such gates on circuit size remains to a large extent a mystery” [Juk12]. The recent results of Blais et al. [BCO+15] on circuit lower bounds have prompted renewed interest in understanding k-monotone functions from multiple angles, including cryptography, circuit complexity, learning theory, and Fourier analysis ([Ros15, GMOR15, GK15, LZ16]).\nMotivated by the exponential lower bounds on PAC learning k-monotone functions due to [BCO+15], we initiate the study of k-monotonicity in the closely related Property Testing model. In this model, given query access to a function, one must decide if the function is k-monotone, or is far from being k-monotone, by querying the input only in a small number of places."
    }, {
      "heading" : "1.1 Our results",
      "text" : "We focus on testing k-monotonicity of Boolean functions defined over the d-dimensional hypegrid [n]d, and the hypercube {0, 1}d. We begin our presentation with the results for the hypercube, in order to build intuition into the difficulty of the problem, while comparing our results with the current literature on testing monotonicity. Our stronger results concern the hypegrid [n]d.\n1.1.1 Testing k-monotonicity on the hypercube {0, 1}d In light of the recent results of [KMS15] that provide a O( √ d)-query tester for monotonicity, we first show that testing k-monotonicity is strictly harder than testing monotonicity on {0, 1}d, for k ≥ 3. Theorem 1.1. For 1 ≤ k ≤ d1/4/2, any one-sided non-adaptive tester for k-monotonicity of functions f : {0, 1}d → {0, 1} must make (Ω ( d/k2 ) )k/4 queries.\nBoth Theorem 1.1 and its proof generalize the Ω(d1/2) lower bound for testing monotonicity, due to Fischer et al. [FLN+02].\nOn the upper bounds side, while the monotonicity testing problem is providing numerous potential techniques for approaching this new problem [GGL+00, DGL+99, CS13a, BCGM12, CST14, KMS15], most common techniques appear to resist generalizations to k-monotonicity. However, our upper bounds demonstrate a separation between testing and PAC learning k-monotonicity, for large enough values of k = ω(log d).\nTheorem 1.2. There exists a one-sided non-adaptive tester for k-monotonicity of functions f : {0, 1}d → {0, 1} with query complexity q(d, ε, k) = 2O( √ d·log d·log 1 ε).\nIndeed, in the related PAC learning model, [BCO+15] shows that learning k-monotone functions\non the hypercube requires 2Ω(k· √ d·1/ε) many queries.\nWe further observe that the recent non-adaptive and adaptive 2-sided lower bounds of [CDST15, BB16], imply the same bounds for k-monotonicity, using black box reductions. We summarize the state of the art for testing k-monotonicity on the hypercube in Table 1.\n1.1.2 Testing k-monotonicity on the hypergrid [n]d\nThe remainder of the paper focuses on functions defined over the d-dimensional hypergrid domain [n]d, where we denote by (i1, i2, . . . , in) (j1, j2, . . . , jn) the partial order in which i1 ≤ j1, i2 ≤ j2, . . . , in ≤ jn. Testing monotonicity has received a lot of attention over the d-dimensional hypergrids [GGL+00, EKK+00, Fis04, BRW05, AC06, HK08, BBM12, CS13b, CS13a, CS14, BRY14], where the problem is well-understood, and we refer the reader to Table 4 in the appendix for a detailed review on the state of the art in the area. We summarize our results on testing k-monotonicity over [n]d in Table 2.\nTesting k-monotonicity on the line and the 2-dimensional grid We begin with a study of function f : [n] → {0, 1}. As before, note that 1-sided tests should always accept k-monotone functions, and so, they must accept unless they discover a violation to k-monotonicity in the form of a sequence x1 x2 . . . xk+1 in [n]d, such that f(x1) = 1 and f(xi) 6= f(xi+1). Therefore, lower bounds for 1-sided k-monotonicity testing must grow at least linearly with k. We show that this is indeed the case for both adaptive and non-adaptive tests, and more over, we give a tight non-adaptive algorithm. Consequently, our results demonstrate that adaptivity does not help in testing k-monotonicity with one-sided error on the line domain.\nTheorem 1.3. Any one-sided (possibly adaptive) tester for k-monotonicity of functions f : [n] → {0, 1} must have query complexity Ω ( k ε ) .\nThe upper bound generalizes the O(1/ε) tester for monotonicity on the line.\nTheorem 1.4. There exists a one-sided non-adaptive tester for k-monotonicity of functions f : [n] → {0, 1} with query complexity q(n, ε, k) = O ( k ε ) .\nTesting with 2-sided error, however, does not require a dependence on k. In fact the problem has been well-studied in the machine learning literature in the context of testing/learning “union of intervals” [KR00, BBBY12], and in testing geometric properties, in the context of testing surface area [KNOW14, Nee14],1 resulting in an O(1/ε7/2)-query algorithm. Namely, the starting point of [BBBY12] (later improved by [KNOW14]) is a “Buffon Needle’s”-type argument, where the crucial quantity to analyze is the noise sensitivity of the function that is the probability that a randomly chosen pair of nearby points cross a “boundary” – i.e., have different values. (Moreover, the algorithm of [BBBY12] works in the active testing setting: it only requires a weaker access model that the standard query model.)\nWe provide an alternate proof of a poly(1/ε) bound (albeit with a worse exponent) that reveals a surprising connection with distribution testing, namely with the problem of estimating the support size of a distribution.\nTheorem 1.5. There exists a two-sided non-adaptive tester for k-monotonicity of functions f : [n] → {0, 1} with query complexity q(n, ε, k) = Õ ( 1/ε7 ) , independent of k.\nAn immediate implication of Theorem 1.5 is that one can test even n1−α-monotonicity of f : [n] → {0, 1}, for every α > 0, with a constant number of queries. Hence, there is a separation between 1-sided and 2-sided testing, for k = ω(1).\nTurning to the 2-dimensional grid, we show that 2-monotone functions can be tested with the minimum number of queries one could hope for:\nTheorem 1.6. There exists a two-sided adaptive tester for 2-monotonicity of functions f : [n]2 → {0, 1} with query complexity q(n, ε) = O ( 1 ε ) .\nWe also discuss possible generalizations of Theorem 1.6 to general k or d section, Section 5.2.\nTesting k-monotonicity on [n]d, tolerant testing, and distance approximation Moving to the general grid domain [n]d, we show that k-monotonicity is testable with poly(1/ε, k) queries in constant-dimension grids.\nTheorem 1.7. There exists a non-adaptive tester for k-monotonicity of functions f : [n]d → {0, 1} with query complexity q(n, d, ε, k) = min(Õ ( 1 ε2 ( 5kd ε )d) , 2Õ(k √ d/ε2)).\nIn fact, we obtain more general testing algorithms than in Theorem 1.7, namely our results hold for tolerant testers.\nThe notion of tolerant testing was first introduced in [PRR06] to account for the possibility of noisy data. In this notion, a test should accept inputs that are ε1-close to the property, and reject\n1We thank Eric Blais for mentioning the connection, and pointing us to these works\ninputs that are ε2-far from the property, where ε1 and ε2 are given parameters. Tolerant testing is intimately connected to the notion of distance approximation: given tolerant testers for every (ε1, ε2), there exists an algorithm that estimates the distance to the property within any (additive)\nε, while incurring only a Õ ( log 1ε ) factor blow up in the number of queries. Furthermore, [PRR06] shows that both tolerant testing and distance approximation are no harder than agnostic learning. We prove the following general result.\nTheorem 1.8. There exist\n• a non-adaptive (fully) tolerant tester for k-monotonicity of functions f : [n]d → {0, 1} with query complexity q(n, d, ε1, ε2, k) = Õ ( 1 (ε2−ε1)2 ( 5kd ε2−ε1 )d) ; • a non-adaptive tolerant tester for k-monotonicity of functions f : [n]d → {0, 1} with query complexity q(n, d, ε1, ε2, k) = 2 Õ(k √ d/(ε2−3ε1)2), under the restriction that ε2 > 3ε1.\nTo the best of our knowledge, the only previous results for tolerant testing for monotonicity on [n]d are due to Fattal and Ron [FR10]. They give both additive and multiplicative distance approximations algorithms, and obtain O(d)-multiplicative and ε-additive approximations with query complexity poly(1ε ). While very efficient, there results only give fully tolerant testers for dimensions d = 1 and d = 2. Our results generalize the work of [FR10] showing existence of tolerant testers for k-monotonicity (and hence for monotonicity) for any dimension d ≥ 1, and any k ≥ 1, but paying the price in the query complexity.\nAs a consequence to Theorem 1.8, we make progress on an open problem of Berman et al. [BRY14], as explained next.\nTesting k-monotonicity under Lp distance The property of being a monotone Boolean function has a natural extension to real-valued functions. Indeed, a real-valued function defined over a finite domain D is monotone if f(x) ≤ f(y) whenever x y. For real-valued functions the more natural notion of distance is Lp distance, rather than Hamming distance. The study of monotonicity has been extended to real-valued functions in a recent work by Berman et al. [BRY14]. They give tolerant testers for grids of dimension d = 1 and d = 2, and leave open the problem of extending the results to general d, as asked explicitly at the recent Sublinear Algorithms Workshop 2016 [Sub16].\nWe make progress towards solving this open problem, by combining our Theorem 1.8 with a reduction from Lp testing to Hamming testing from [BRY14].\nTheorem 1.9. There exists a non-adaptive tolerant L1-tester for monotonicity of functions f : [n] d → {0, 1} with query complexity\n• Õ (\n1 (ε2−ε1)2\n( 5d\nε2−ε1\n)d) , for any 0 ≤ ε1 < ε2 ≤ 1;\n• 2Õ( √ d/(ε2−3ε1)2), for any 0 ≤ 3ε1 < ε2 ≤ 1."
    }, {
      "heading" : "1.2 Proofs overview and technical contribution",
      "text" : "Structural properties and the separation between testing and learning on {0, 1}d. We first observe that basic structural properties, such as extendability (i.e. the feature that a function that is monotone on a sub-poset of [n]d can be extended into a monotone function on the\nentire poset domain), and properties of the violation graph (i.e., the graph whose edges encode the violations to monotonicity), extend easily to k-monotonicity (see Appendix B). These properties help us to argue the separation between testing and learning (Theorem 1.2). However, unlike the case of monotonicity testing, these properties do not seem to be enough for showing upper bounds that grow polynomially in d.\nGrid coarsening and testing by implicit/explicit learning. One pervading technique, which underlies all the hypergrid upper bounds in this work, is that of gridding: i.e., partitioning the domain into “blocks” whose size no longer depends on the main parameter of the problem, n. This technique generalizes the approach of [FR10] who performed a similar gridding for dimension d = 2. By simulating query access to the “coarsened” version of the unknown function (with regard to these blocks), we are able to leverage methods such as testing-by-learning (either fully or partially learning the function), or reduce our testing problem to a (related) question on these nicer “coarsenings.” (The main challenge here lies in providing efficient and consistent oracle access to the said coarsenings.)\nAt a high-level, the key aspect of k-monotonicity which makes this general approach possible is reminiscent of the concept of heredity in property testing. Specifically, we rely upon the fact that “gridding preserves k-monotonicity:” if f is k-monotone, then so will be its coarsening g – but now g is much simpler to handle. This allows us to trade the domain [n]d for what is effectively [m]d, with m ≪ n. We point out that this differs from the usual paradigm of dimension reduction: indeed, the latter would reduce the study of a property of functions on [n]d to that of functions on [n]d ′ for d′ ≪ d (usually even d′ = 1) by projecting f on a lower-dimensional domain. In contrast, we do not take the dimension down, but instead reduce the size of the alphabet. Moreover, it is worth noting that this gridding technique is also orthogonal to that of range reduction, as used e.g. in [DGL+99]. Indeed, the latter is a reduction of the range of the function from [R] to {0, 1}, while gridding is only concerned about the domain size.\nEstimating the support of distributions. Our proof of the poly(1/ε) upper bound for testing k-monotonicity on the line (Theorem 1.5) rests upon an unexpected connection to distribution testing, namely to the question of support size estimation of a probability distribution. In more detail, we describe how to reduce k-monotonicity testing to the support size estimation problem in (a slight modification of) the Dual access model introduced by Canonne and Rubinfeld [CR14], where the tester is granted samples from an unknown distribution as well as query access to its probability mass function.\nFor our reduction to go through, we first describe how any function f : [n] → {0, 1} determines a probability distribution Df (on [n]), whose effective support size is directly related to the kmonotonicity of f . We then show how to implement dual access to this Df from queries to f : in order to avoid any dependence on k and n in this step, we resort both to the gridding approach outlined above (allowing us to remove n from the picture) and to a careful argument to “cap” the values of Df returned by our simulated oracle. Indeed, obtaining the exact value of Df (x) for arbitrary x may require Ω(k) queries to f , which we cannot afford; instead, we argue that only returning Df (x) whenever this value is “small enough” is sufficient. Finally, we show that implementing this “capped” dual access oracle is possible with no dependence on k whatsoever, and we can now invoke the support size estimation algorithm of [CR14] to conclude.\nFourier analysis on the hypergrid. We give an algorithm for fully tolerantly testing kmonotonicity whose query complexity in exponential in d. We also describe an alternate tester (with a slightly worse tolerance guarantee) whose query complexity is instead exponential in Õ(k √ d) for constant distance parameters. As mentioned above, we use our gridding approach combined with tools from learning theory. Specifically, we employ an agnostic learning algorithm of [KKMS08] using polynomial regression. Our coarsening methods allow us to treat the domain as if it were [m]d for some m that is independent of n. To prove that this agnostic learning algorithm will succeed, we turn to Fourier analysis over [m]d. We extend the bound on average sensitivity of k-monotone functions over the Boolean hypercube from [BCO+15] to the hypergrid, and we show that this result implies that the Fourier coefficients are concentrated on “simple” functions."
    }, {
      "heading" : "1.3 Discussion and open problems",
      "text" : "This is the first work to study k-monotonicity, a natural and well-motivated generalization of monotonicity. Hence this work opens up many intriguing questions in the area of property testing, with potential applications to learning theory, circuit complexity and cryptography. As previously mentioned, the main open problem prompted by our work is the following:\nCan k-monotonicity on the hypercube {0, 1}d be tested with poly(dk) queries?\nA natural 1-sided tester for k-monotonicity is a chain tester: it queries points along a random chain, and rejects only if it finds a violation to k-monotonicity, in the form of a sequence x1 x2 . . . xk+1 in {0, 1}d, such that f(x1) = 1 and f(xi) 6= f(xi+1). In particular, the testers in [GGL+00, CS13a, CST14, KMS15] all directly imply a chain tester. We conjecture that there exists a chain tester for k-monotonicity that succeeds with probability d−O(k).\nAnother important open question concerns the hypergrid domain, and in particular it pushes for a significant strengthening of Theorem 1.7 and Theorem 1.9:\nCan k-monotonicity on the hypergrid [n]d be (tolerantly) tested with 2ok( √ d) queries?\nAnswering this question would imply further progress on the L1-testing question for monotonicity, left open in [BRY14, Sub16].\nThere also remains the question of establishing two-sided lower bounds that would go beyond those of monotonicity. Specifically:\nIs there an dΩ(k)-query two-sided lower bound for k-monotonicity on the hypercube {0, 1}d?\nIn this work we also show surprising connections to distribution testing (e.g. in the proof of Theorem 1.5), and to testing union of intervals and testing surface area (as discussed in Section 4.2). An intriguing direction is to generalize this connection to union of intervals and surface area in higher dimensions, to leverage or gain insight on k-monotonicity on the d-dimensional hypergrid.\nFinally, while we only stated here a few directions, we emphasize that every question that is relevant to monotonicity is also relevant and interesting in the case of k-monotonicity."
    }, {
      "heading" : "1.4 Related work",
      "text" : "As mentioned, k-monotonicity has deep connections with the notion of negation complexity of functions, which is the minimum number of negation gates needed in a circuit to compute a given function. The power of negation gates is intriguing and far from being understood in the context of circuit lower bounds. Quoting from Jukna’s book [Juk12], the main difficulty in proving nontrivial lower bounds on the size of circuits using AND, OR, and NOT is the presence of NOT gates: we already know how to prove even exponential lower bounds for monotone functions if no NOT gates are allowed. The effect of such gates on circuit size remains to a large extent a mystery.\nThis gap has motivated the study of circuits with few negations. Two notable works successfully extend lower bounds in the monotone setting to negation-limited setting: in [AM05], Amano and Maruoka show superpolynomial circuit lower bounds for (1/6) log log n negations using the Clique function; and recently the breakthrough work of Rossman [Ros15] establishes circuit lower bounds for NC1 with roughly 12 log n negations by drawing upon his lower bound for monotone NC\n1. The divide between the understanding of monotone and non-monotone computation exists in general: while we usually have a fairly good understanding of the monotone case, many things get murky or fail to hold even when a single negation gate is allowed. In order to get a better grasp on negation-limited circuits, a body of recent work has been considering this model in various contexts: Blais et al. [BCO+15] study negation-limited circuits from a computational learning viewpoint, Guo et al. [GMOR15] study the possibility of implementing cryptographic primitives using few negations, and Lin and Zhang [LZ16] are interested in verifying whether some classic Boolean function conjectures hold for the subset of functions computed by negation-limited circuits.\nMany of these results implicitly or explicitly rely on a simple but powerful tool: the decomposition of negation-limited circuits into a composition of some “nice” function with monotone components. Doing so enables one to apply results on separate monotone components, and finally to carefully combine the outcomes (e.g., [GK15]). Though these techniques can yield results for as many as O(log n) negations, they also leave open surprisingly basic questions:\n• [BCO+15] Can we have an efficient weak learning algorithm for functions computed by circuits with a single negation? • [GMOR15] Can we obtain pseudorandom generators when allowing only a single negation? In contexts where the circuit size is not the quantity of interest, the equivalent notion of 2- monotone functions is more natural than that of circuits allowing only one negation. Albeit seemingly simple, even the class of 2-monotone functions remains largely a mystery: as exemplified above, many basic yet non-trivial questions, ranging from the structure of their Fourier spectrum to their expressive power of k-monotone functions, remain open."
    }, {
      "heading" : "1.5 Organization of the paper",
      "text" : "After recalling some notations and definitions in Section 2, we consider the case of the Boolean hypercube in Section 3, where we establish lower bounds on testing k-monotonicity of functions f : {0, 1}d → {0, 1} for both one- and two-sided algorithms, and provide an algorithm which “beats” the testing-by-learning approach, showing that testing is provably easier than learning.\nNext, we establish our results for functions on the line in Section 4, starting with the lower and upper bounds for one-sided testers before turning in Section 4.2 to the two-sided upper bound of Theorem 1.3. We then describe in Section 5 our results for functions on the grid [n]2, focusing on the case k = 2; and discussing possible extensions in Section 5.2.\nSection 6 contains our general algorithms for k-monotonicity on the hypergrid [n]d, for arbitrary k and d. We prove Theorem 1.8 in two parts. We establishing its first item (general tolerant testing algorithm with exponential dependence in d) in Section 6.1 (Proposition 6.2). The second item (with query complexity exponential in k √ d) is proven in Section 6.2, where we analyze the Fourier-based tolerant tester of Proposition 6.11. We then apply these results to the question of tolerant L1-testing of monotonicity in Section 7, after describing a reduction between monotonicity of functions [n]d → [0, 1] and of [n]d+1 → {0, 1}.\nExcept maybe Section 7 which depends on Section 6, all sections are independent and selfcontained, and the reader may choose to read them in any order."
    }, {
      "heading" : "2 Preliminaries",
      "text" : "We denote by log the binary logarithm, and use Õ(·) to hide polylogarithmic factors in the argument (so that Õ(f) = O(f logc f) for some c ≥ 0).\nGiven two functions f, g : X → Y on a finite domain X , we write dist(f, g) for the (normalized) Hamming distance between them, i.e.\ndist(f, g) = 1 |X | ∑\nx∈X 1{f(x)6=g(x)} = Pr x∼X [ f(x) 6= g(x) ]\nwhere x ∼ X refers to x being drawn from the uniform distribution on X . A property of functions from X to Y is a subset P ⊆ XY of these functions; we define the distance of a function f to P as the minimum distance of f to any g ∈ P:\ndist(f,P) = inf g∈P dist(f, g) .\nFor some of our applications, we will also use another notion of distance specific to real-valued functions, the L1 distance (as introduced in the context of property testing in [BRY14]). For f, g : X → [0, 1], we write\nL1(f, g) = 1 |X | ∑\nx∈X |f(x)− g(x)| = Ex∼X [|f(x)− g(x)|] ∈ [0, 1]\nand extend the definition to L1(f,P), for P ⊆ X [0,1], as before.\nProperty testing. We recall the standard definition of testing algorithms, as well as some terminology:\nDefinition 2.1. Let P be a property of functions from X to Y. A q-query testing algorithm for P is a randomized algorithm T which takes as input ε ∈ (0, 1] as well as query access to a function f : X → Y. After making at most q(ε) queries to the function, T either outputs ACCEPT or REJECT, such that the following holds:\n• if f ∈ P, then T outputs ACCEPT with probability at least 2/3; (Completeness) • if dist(f,P) ≥ ε, then T outputs REJECT with probability at least 2/3; (Soundness)\nwhere the probability is taken over the algorithm’s randomness. If the algorithm only errs in the second case but accepts any function f ∈ P with probability 1, it is said to be a one-sided tester; otherwise, it is said to be two-sided. Moreover, if the queries made to the function can only depend on the internal randomness of the algorithm, but not on the values obtained during previous queries, it is said to be non-adaptive; otherwise, it is adaptive.\nAdditionally, we will also be interested in tolerant testers – roughly, algorithms robust to a relaxation of the first item above:\nDefinition 2.2. Let P, X , and Y be as above. A q-query tolerant testing algorithm for P is a randomized algorithm T which takes as input 0 ≤ ε1 < ε2 ≤ 1, as well as query access to a function f : X → Y. After making at most q(ε1, ε2) calls to the oracle, T outputs either ACCEPT or REJECT, such that the following holds:\n• if dist(f,P) ≤ ε1, then T outputs ACCEPT with probability at least 2/3; (Completeness) • if dist(f,P) ≥ ε2, then T outputs REJECT with probability at least 2/3; (Soundness)\nwhere the probability is taken over the algorithm’s randomness. The notions of one-sidedness and adaptivity of Definition 2.1 extend to tolerant testing algorithms as well.\nNote that as stated, in both cases the algorithm “knows” X ,Y, and P; so that the query complexity q can be parameterized by these quantities. More specifically, when considering X = [n]d and the property P of k-monotonicity, we will allow q to depend on n, d, and k. Finally, we shall sometimes require a probability of success 1−δ instead of the (arbitrary) constant 2/3; by standard techniques, this can be obtained at the cost of a multiplicative O(log(1/δ)) in the query complexity.\nPAC and agnostic learning [Val84] A learning algorithm A for a concept class C of functions f : X → Y (under the uniform distribution) is given parameters ε, δ > 0 and sample access to some target function f ∈ C via labeled samples 〈x, f(x)〉, where x is drawn uniformly at random from X . The algorithm should output a hypothesis h : X → Y such that dist(h, f) ≤ ε with probability at least 1− δ. The algorithm is efficient if it runs in time poly(n, 1/ε, 1/δ). If A must output h ∈ C we say it is a proper learning algorithm, otherwise, we say it is an improper learning one.\nMoreover, if A still succeeds when f does not actually belong to C, we say it is an agnostic learning algorithm. Specifically, the hypothesis function h that it outputs must satisfy dist(f, g) ≤ optf + ε with probability at least 1− δ, where optf = ming∈C dist(f, g)."
    }, {
      "heading" : "3 On the Boolean hypercube",
      "text" : "In this section, we focus on k-monotonicity of Boolean functions over the hypercube {0, 1}d. We begin in Section 3.1 with a tester with query complexity 2Õ( √ d), establishing a strict separation between learning and testing. Section 3.2 is then dedicated to our lower bounds on k-monotonicity testing."
    }, {
      "heading" : "3.1 Upper bound: beating the learning approach",
      "text" : "In this section, we prove the following theorem:2\n2We note that this result is only interesting in the regime k ≤ √ d: indeed, for k = Ω (√ d log 1\nε\n) every function is\nε-close to k-monotone.\nTheorem 1.2. There exists a one-sided non-adaptive tester for k-monotonicity of functions f : {0, 1}d → {0, 1} with query complexity q(d, ε, k) = 2O( √ d·log d·log 1 ε).\nLet us recall the following standard fact.\nFact 3.1. There exists an absolute constant C > 0 such that the number of points of {0, 1}d that do not have integer weights in the middle levels [d2 − √ d log Cε , d 2 + √ d log Cε ] is at most ε2 d−1.\nWith that fact in our hands, we now describe the following tester.\n(1) Sample O(1/ε) random points from the middle levels\n(2) For each of the queries in the first step, query all points with Hamming weight in the middle levels which fall in the subcube below and in the subcube above each such random point. We call each of these O(1/ε) collections of queries a superquery .\nThe key idea behind the tester is the extendability lemma, Lemma B.7. The tester tries to find one of the “violated hyperedges” from the matching of violations that we know exists from Lemma B.7. Now, we analyze the tester.\nProof of Theorem 1.2. Suppose k is odd.3 In this case, given a function f ε-far from k-monotonicity we can assume without loss of generality that f and equals 0 on points with Hamming weight < d2 − √ d log Cε , and equals 1 on points with Hamming weight > d 2 + √ d log Cε . The resulting function is still ε2 -far from being k-monotone.\nNow, by Lemma B.7, we know that there exists a matching Mf of violations to k-monotonicity\nin f of size 12 · ε2 d k . The set of vertices that participate in these violations has cardinality\n|Mf | · ε2d\nk =\nε(k + 1)2d\nk ≥ ε2d−1\nWith constant probability, in O(1/ε) queries in the first step, the tester queries a vertex that belongs to some violation from Mf . Then in the next step, the tester finds this violation. Now we bound the number of queries made in a single superquery. Since it involves only 2 √ d log Cε levels\nof the cube, the number of points queried in a single superquery is no more than b = dO( √ d log 1 ε ). The total query complexity of the tester can therefore be upperbounded by b/ε = dO( √ d log 1 ε ). We emphasize that the number of queries made by this tester has no dependence on k."
    }, {
      "heading" : "3.2 Lower bounds",
      "text" : "We now turn to lower bounds for testing k-monotonicity of Boolean functions over the hypercube {0, 1}d. In Section 3.2.1, we show that for constant k any one-sided non-adaptive tester for kmonotonicity requires Ω(dk/4) queries , generalizing the Ω (√ d ) lower bound for monotonicity due to Fischer et al. [FLN+02]. This bound suggests the problem become strictly harder when k increases: specifically, for k > 2 testing k-monotonicity requires ω( √ d) queries, while an O( √ d) one-sided non-adaptive upper bound holds for monotonicity testing [KMS15].\n3The case k even is similar. In this case, one may assume that f evaluates to 0 on points with hamming weight everywhere outside the middle levels.\nWe then describe in Section 3.2.2 a general reduction frommonotonicity testing to k-monotonicity testing, for arbitrary constant k. This blackbox reduction allows us to carry any lower bound (possibly 2-sided or adaptive) for monotonicity testing to k-monotonicity. In particular, combining it with the recent lower bounds [CDST15, BB16] for 2-sided monotonicity testing, we obtain an Ω(d1/2−o(1)) lower bound for non-adaptive k-monotonicity testers, and an Ω ( d1/4 ) lower bound for\nadaptive ones."
    }, {
      "heading" : "3.2.1 One-sided lower bounds",
      "text" : "Theorem 1.1. For 1 ≤ k ≤ d1/4/2, any one-sided non-adaptive tester for k-monotonicity of functions f : {0, 1}d → {0, 1} must make (Ω ( d/k2 ) )k/4 queries.\nConsider the family of functions {fS : S ⊆ [d] of size t} where t ≥ k is a parameter to be determined later and fS is a truncated anti-parity over t input coordinates indexed by S, namely,\nfS =\n{ ⊕i∈Sxi if ||x| − d/2| ≤ √ d,\n0 otherwise.\nTheorem 1.1 immediately follows from the two claims below. In particular,by Claim 3.3, for t ≤ √ d and t = 4k2, fS is Ω(1)-far from any k-monotone function, and by Claim 3.2, to reject every fS with Ω(1) probability, q needs to be at least d k/4 · ( k2e2t)k/2 = Ω(d/k2)k/4 when t = 4k2. Claim 3.2. For any non-adaptive q-query algorithm A, there exists fS where |S| = t such that A reveals a violation on fS with probability at most q 2 (2√d\nk )(t k ) / (d k ) .\nClaim 3.3. For k ≤ t ≤ √ d, fS is Ω( ∑⌊ t−k−12 ⌋ i=0 (t i ) /2t)-far from any k-monotone functions.\nProof of Claim 3.2. Let Q be an arbitrary set of q queries. Without loss of generality, we assume every query z in Q has Hamming weight |z| ∈ [d2 − √ d, d2 + √ d]. We define Qx,z = { y ∈ Q : x y z } and Rej(Q) = { fS : Q contains a violation for fS }. Note that Rej(Q) =⋃ (x,z) : x z∈QRej(Qx,z). Hence we can bound the size of Rej(Q) by\n|Rej(Q)| ≤ ∑\n(x,z)∈Q2 : x z |Rej(Qx,z)| . (1)\nFix any x z ∈ Q. Because any violation for fS in Qx,z contains at least two points x′ and z′ such that x x′ z′ z, and x′S′ = 0k and z′S′ = 1k, we have xS′ = 0k and zS′ = 1k for some S′ ⊆ S of size k. Note that x and z differ in at most 2 √ d coordinates so that there are at most (2√d k ) distinct\nS′ on which xS′ is 0k and zS′ is 1k. Moreover, for each S′ there are at most (d−k t−k ) distinct S such that S′ ⊆ S. Therefore we can bound the size of Rej(Qx,z) by\n|Rej(Qx,z)| ≤ ( 2 √ d\nk )( d− k t− k ) . (2)\nCombining (1) and (2) , |Rej(Q)| ≤ q2 (2√d\nk )(d−k t−k ) . It follows that for any non-adaptive algorithm\nmaking at most q queries,\n∑\nS⊆[d]:|S|=t Pr[A reveals a violation for fS ] ≤ E[|Rej(Q)|] ≤ q2\n( 2 √ d\nk )( d− k t− k ) .\nHence there exists fS such that Pr[A reveals a violation for fS ] ≤ q2 ( 2 √ d k )( d−k t−k)\n(dt) = q2\n(2 √ d\nk )( t k) (dk) .\nProof of Claim 3.3. Let f ′S be the closest k-monotone function to fS . Let Z denote the set {z ∈ {0, 1}d−t : d/2− √ d ≤ |z| ≤ d/2+ √ d− t}. For any t ≤ √ d, [d−t2 − √ d−t 2 , d−t 2 + √ d−t 2 ] is contained in\n[d/2 − √ d, d/2 + √ d− t] so that |Z| = Ω(2d−t). For any assignment z ∈ Z on coordinates indexed by [d] \\ S, fS(·, z) agrees with ⊕i∈Sxi and f ′S(·, z) is k-monotone. To finish the proof, it suffices to show that an anti-parity over t inputs is ∑⌊ t−k−12 ⌋ i=0 (t k ) /2t-far from any k-monotone function over t inputs. Indeed, this will imply that, for every z ∈ Z, fS(·, z) differs from f ′S(·, z) on ∑⌊ t−k−12 ⌋ i=0 (t k ) points, and thus finally that fS differs from fS′ on |Z|· ∑⌊ t−k−12 ⌋\ni=0\n(t k ) = Ω(2d−t ·∑⌊ t−k−1 2 ⌋ i=0 (t k ) ) points.\nNow we show that an anti-parity function over t inputs h(x1, . . . , xt) = ⊕ti=1xi is ∑⌊ t−k−12 ⌋ i=0 (t i ) /2tfar from any k-monotone function g (over x1, . . . , xt). We begin by noting that we can sample a random point from {0, 1}t by first sampling a random chain C = (x0 = 0t, x1, . . . , xt = 1t) (from all possible chains from 0t to 1t) then outputting xi with probability (t i ) /2t. Thus the distance between h and g, namely Prx[h(x) 6= g(x)], is equal to\nPr C,i\n[h(xi) 6= g(xi)] = EC [ t∑\ni=0\n(t i )\n2t · 1{h(xi)6=g(xi)}\n] = EC [ 1\n2t\nt∑\ni=1\n( t− 1 i− 1 ) · (1{h(xi)6=g(xi)} + 1{h(xi−1)6=g(xi−1)}) ]\n(3)\nwhere the last inequality relies on identity (t i ) = (t−1 i−1 ) + (t−1 i ) . For any fixed chain C, because g alternates at most k times, there are at least t − k choices of i ∈ [t] such that g(xi−1) = g(xi), which implies 1{h(xi)6=g(xi)} + 1{h(xi−1)6=g(xi−1)} ≥ 1 (due to h(xi−1) 6= h(xi)). Thus ∑t i=1 (t−1 i−1 ) · (1{h(xi)6=g(xi)}+1{h(xi−1)6=g(xi−1)}) is at least the sum of smallest t−k binomials among (t−1\n0\n) , . . . , (t−1 t−1 )\nwhich is\n⌊ t−k−12 ⌋∑\ni=0\n( t− 1 i ) + ⌊ t−k−22 ⌋∑\ni=0\n( t− 1\nt− 1− i\n) = ⌊ t−k−12 ⌋∑\ni=0\n( t− 1 i ) + ⌊ t−k−22 ⌋∑\ni=0\n( t− 1 i ) ≥ ⌊ t−k−12 ⌋∑\ni=0\n( t\ni\n) ,\nwhich implies Prx[h(x) 6= g(x)] ≥ 12t ∑⌊ t−k−12 ⌋ i=0 (t i ) by combining the above with (3)."
    }, {
      "heading" : "3.2.2 Two-sided lower bounds",
      "text" : "The following theorem gives a construction that enables us to convert monotone functions into k-monotone functions, and functions that are far from monotone into functions that are far from k-monotone.\nTheorem 3.4. There exists an efficiently computable function h : {0, 1}d/2 → {0, 1} such that for any g : {0, 1}d/2 → {0, 1}, then g||h : {0, 1}d → {0, 1} is a Boolean function (defined below) satisfying the following.\n• if g is monotone, then g||h is a k-monotone function; • if g is ε-far from monotone, then g||h is Ω(ε/k)-far from being a k-monotone function;\nwhere (g||h)(x, y) def= g(x)⊕ h(y) for any x, y ∈ {0, 1}d/2.\nThe above theorem reduces test monotonicity to testing k-monotonicity (for arbitrary constant k) with the same number of queries to the input function. This theorem allows us to carry any lower bound on monotonicity testing to k-monotonicity, while preserving the characteristics (twosidedness, adaptivity) of the original lower bound. In particular, combining it with the recent recent of [CDST15, BB16], we obtain the following corollary.\nCorollary 3.5. For any c > 0 and k ≥ 1, there exists ε = ε(k, c) > 0 such that any 2-sided nonadaptive algorithm for testing whether f is k-monotone or ε-far from it requires Ω(d1/2−c) queries. Any 2-sided adaptive algorithm requires Ω̃ ( d1/4 ) queries.\nTo prove Theorem 3.4, we prove following three claims. Claim 3.6 and Claim 3.7 show that the existence of a (k − 1)-monotone function h for which one can find a big enough set of vertex disjoint paths in the hypercube whose labelling under h satisfies some specific condition will imply Theorem 3.4. Finally in Claim 3.8, we establish the existence of such h, and Theorem 3.4 follows.\nClaim 3.6. Let h : {0, 1}d → {0, 1} be a (k − 1)-monotone function. Then for any monotone g : {0, 1}d → {0, 1}, f = g||h is a k-monotone function.\nClaim 3.7. Suppose there exists a h : {0, 1}d → {0, 1} such that the following holds. There exists at least M paths of length k − 1 such that (i) all paths are vertex disjoint and (ii) for every path y1 · · · yk, h(y1) = 0 and h(yi) 6= h(yi+1) for 1 ≤ i ≤ k − 1. Then, for any g : {0, 1}d → {0, 1} which is ε-far from being a monotone function, the function f = g||h is Ω(M\n2d · ε)-far from being a\nk-monotone function.\nClaim 3.8. For any constant k, there exists an efficient computable h : {0, 1}d → {0, 1} such that h is a (k − 1)-monotone function and h contains at least (1−od(1))2dk paths of length k− 1 such that all paths are vertex disjoint and for every path y1 · · · yk, h(y1) = 0 and h(yi) 6= h(yi+1) for 1 ≤ i ≤ k − 1.\nProof of Claim 3.6. Suppose f = g||h is not k-monotone, then there exist (x1, y1), . . . , (xk+1, yk+1) such that (x1, y1) · · · (xk+1, yk+1), f(x1, y1) = 1 and f(xi, yi) 6= f(xi+1, yi+1) for any 1 ≤ i ≤ k. Because g is monotone, either g is constant on x1, . . . , xk+1, or there exists an index 1 < j ≤ k+ 1 such that g(xi) = 0 for i < j and g(xi) = 1 for i ≥ j. For the first case, h(yi) = f(xi, yi) for any i and h alters exactly k times on points y1 · · · yk+1. For the second case, h(y1) = f(x1, y1) = 1, and h alters exactly k − 1 times on y1 · · · yj−1 yj+1 · · · yk+1. Both cases contradict h being (k − 1)-monotone.\nProof of Claim 3.7. Let Mh be the maximal set of paths of length k such that all paths are vertex disjoint and for every path y1 · · · yk, h(y1) = 0 and h(yi) 6= h(yi+1) for 1 ≤ i ≤ k − 1. Let Mg be the maximal set of pairs such that all pairs are vertex disjoint and every pair x1 x2 is a violation for g, i.e., g(x1) = 1 and g(x2) = 0. For each path (y1 · · · yk) ∈ Mh and any pair (x1 x2) ∈ Mg, it is easy to see following path is a violation for f ||g being k-monotone :\n(x1, y1), . . . , (x1, yk), (x2, yk).\nLet f ′ be the closest k-monotone function to f . For each violating path, f and f ′ differ on at least 1 point. Because both Mh and Mg are vertex disjoint, violating paths constructed by taking every\npath in Mh and every pair in Mg are vertex disjoint. Thus f and f ′ differ on at least |Mh| × |Mg| points and f is (|Mh|·|Mg| /22d)-far from f ′. It is known ([GGL+00]) that for any g : {0, 1}d → {0, 1} which is ε-far from monotone, |Mg| ≥ 2d−1ε. The desired conclusion follows.\nProof of Claim 3.8. Let B1, B2, . . . , Bk be consecutive blocks each consisting of consecutive layers of the hypercube such that for each i ∈ [k],\n(1− k√ d ) 2d k ≤ |Bi| ≤ (1 + k√ d ) 2d k .\nBecause k is a constant and every layer contains at most 2d/ √ d points, we can always greedily find B1, . . . , Bk one by one. Let h be a function such that h has constant value (i+1 mod 2) on block Bi for 1 ≤ i ≤ k. It is easy to see that h is (k − 1)-monotone. Next we prove for any 1 ≤ j ≤ k, B1, . . . , Bj contain at least (1−od(1))2d k vertex disjoint paths of length j − 1 such the ith point on every path is in Bi. Claim 3.8 follows from the case j = k. For j = 1, the statement holds by taking all points in B1. For j > 1, assume that B1, . . . , Bj−1 contain a set Pj−1 of such (1−od(1))2d\nk vertex disjoint paths of length j − 2. Let M be the maximal matching between Bj−1 and Bj and let Pj be the set of paths of length j−1 constructed in following way: for each path in Pj−1 with an endpoint yj−1, if there exists yj such that (yj−1, yj) ∈ M , we add the path appended with yj into Pj . Because no points in Bj will be added into two different paths in Pj and Pj−1 are vertex disjoint, paths in Pj are vertex disjoint.\nNow we show |M | = min(|Bj−1| , |Bj |) which implies |Pj | ≥ (1−od(1))2 d\nk . Suppose |Bj−1| ≤ |Bj | (the argument is analogous in the other case). For any subset S of Bj−1, let fS be the indicator function of the upper closure of S denoted as N(S). It is not hard to check that fS is monotone and thus Pr[fS(x) = 1|x ∈ Bj] ≥ Pr[fS(x) = 1|x ∈ Bj−1]. It follows\n|N(S) ∩Bj | = |Bj |Pr[fS(x) = 1|x ∈ Bj ] ≥ |Bj−1|Pr[fS(x) = 1|x ∈ Bj−1] ≥ |S| .\nBy Hall’s theorem, |M | = |Bj−1|. By similar argument, we can show |M | = |Bj | when |Bj−1| > |Bj|. Thus |M | = min(|Bj−1| , |Bj|)."
    }, {
      "heading" : "4 On the line",
      "text" : "In this section we prove our results on testing k-monotonicity on the line, that is of functions f : [n] → {0, 1}. We start with Theorem 1.4, which establishes that this can be done non-adaptively with one-sided error, with only O(k/ε) queries; we then turn to Theorem 1.3, which shows that this is the best one can hope for if insisting on one-sidedness. The last result of this section is Theorem 1.5, where we show that – perhaps unexpectedly – two-sided algorithms, even nonadaptive, can break this barrier and test k-mononicity with no dependence on k."
    }, {
      "heading" : "4.1 Upper and lower bounds for one-sided testers",
      "text" : "We first prove the upper bound, restated below:\nTheorem 1.4. There exists a one-sided non-adaptive tester for k-monotonicity of functions f : [n] → {0, 1} with query complexity q(n, ε, k) = O ( k ε ) .\nProof. We assume that εn50k is an integer, 4 and partition the domain into K def = 50kε intervals of size εn50k , the consecutive “blocks” B1, . . . , BK . We then define g : [n] → {0, 1, ∗} as the function constant on each block Bi = {bi, . . . , bi+1 − 1}, such that\n• If f(bi) = f(bi+1 − 1), then g(j) = f(bi) for all j ∈ Bi; • otherwise, g(j) = ∗ for all j ∈ Bi.\nWe say that a block Bi such that g|Bi = ∗ is a changepoint block for g. Clearly, given query access to f one can obtain the value of g on any point j ∈ [n] with only two queries to f . Moreover, defining g̃ : [n] → {0, 1} to be the function obtained from g by replacing ∗ by 0, we observe the following:\n• If f is k-monotone, then (i) so is g̃, and (ii) f and g̃ differ in at most k blocks (namely the changepoint blocks of g), so that dist(f, g) ≤ k · 1K = ε50 ; • If f is ε-far from k-monotone, then either (i) g̃ is not k-monotone, or (ii) dist(f, g̃) > ε. We start by learning g (and thus g̃) exactly, using 2K = O(k/ε) non-adaptive queries. Setting\nm def = C kε , we also sample m ′ ∼ Poisson(m) points5 j1, . . . , jm′ independently and uniformly from [n], where C > 0 is a constant to be determined in the course of the analysis, and query the value of f (and g) on all of them. Then, we reject if either (i) g̃ is not k-monotone; or (ii) there exist at least k + 1 distinct blocks which contain a sample sj such that g̃(sj) 6= f(sj).\nBy definition, this tester is non-adaptive; and it is not difficult to see it accepts any k-monotone function with probability 1, since in that case f and g (and a fortiori g̃) differ in at most k blocks: indeed, these blocks can only be changepoint blocks for g, i.e. blocks where f changes value.\nIt remains to argue soundness: we will show that if f is ε-far from k-monotone, the tester will reject with probability at least 2/3. By the first check made, (i), we can assume in the following that g̃ is k-monotone – as otherwise f is rejected with probability 1 – and we need to show that (ii) will reject with probability at least 2/3. For each block Bi (where i ∈ [K]), let pi ∈ [0, 1K ] be defined as the (normalized) number of points in Bi on which f and g̃ differ (we henceforth refer to such a point as a giveaway point):\npi def =\n1\nn\n∑\nj∈Bi 1{f(j)6=g̃(j)}.\nSince f is ε-far from the k-monotone function g̃, we have ∑K\ni=1 pi ≥ ε. Now, letting Zi be the indicator of the event that among the m′ samples, at least one is giveaway point from Bi, and Z = ∑K i=1 Zi, we can write Zi = 1{Yi 6=0}, where the (Yi)i∈[K] are independent Poisson random variables with Yi ∼ Poisson(mpi). The expected number of blocks in which a giveaway point is sampled is then\nEZ = K∑\ni=1\nEZi = K∑\ni=1\nPr[Yi 6= 0 ] = K∑\ni=1\n(1− e−mpi)\nSince for every i ∈ [K] it holds that e−mpi ≤ 1 − m2 pi (the inequality holding since 0 ≤ mpi ≤ 1, 4If not, we consider instead ε′ def = 50k\nn\n⌊ εn\n50k\n⌋ > ε − 50k\nn > ε 2 if ε > 100k n ; while if ε ≤ 100k n we query the entire\nfunction, for a total of n = O ( k ε ) queries.\n5The fact that we sample Poisson(m) instead ofm is for ease of the analysis; note that due to the tight concentration of Poisson random variables, with probability 1− o(1) we will have m′ ≤ 2m. If this does not happen, the tester can output ACCEPT, incurring only a small additional error probability (and not affecting the one-sidedness).\nwhich is verified for m ≤ K), we get\nEZ = K∑\ni=1\nEZi ≥ K∑\ni=1\nm\n2 pi ≥\nmε 2 ≥ C 2 k.\nMoreover, by a Chernoff bound, we get that\nPr [ Z < C\n4 k\n] ≤ e−Ck16 ≤ e− C16\nwhich is less that 1/4 for C ≥ 23. Setting C def= 30 satisfies both conditions that m ≤ K and C ≥ 23, and results in a one-sided non-adaptive tester which rejects functions far from k-monotone with probability at least 1− 14 + o(1) ≥ 23 .\nTurning to the lower bounds against one-sided testers, we show the following:\nTheorem 1.3. Any one-sided (possibly adaptive) tester for k-monotonicity of functions f : [n] → {0, 1} must have query complexity Ω ( k ε ) . Proof. Since a lower bound of Ω ( 1 ε ) straightforwardly holds, we can restrict ourselves to k ≥ 8, and ε < 112 ; moreover, we assume without loss of generality that εn k is an integer, and partition the domain into K def = kε intervals of size εn k , the consecutive “blocks” B1, . . . , BK . For v ∈ {0, 1}K/2, we define gv : [n] → {0, 1} as the function which has constant value vi on block B2i−1 and has constant value 1 on the remaining blocks.\nConsider the distribution over {gv}v where each coordinate of v is independently set to 0 with probability p def = 6ε, and 1 otherwise. We next show that gv is at least ε-far from any k-monotone function with very high probability over the choice of v. By a Chernoff bound, with probability at least 1− e−pK/16 = 1− e−3k/8, gv has at least pK/4 = 3k/2 blocks that are 0 blocks. Conditioned on this, it is easy to see that gv is ε-far from k-monotone: indeed, to make it k-monotone one has to flip its value on at least k blocks, and each block contains an ε/k fraction of the domain.\nFix any deterministic adaptive algorithm with query complexity q ≤ k/(24ε) queries, and denote by x1, . . . , xq the sequence of queries made (when given query access to some function gv). Note that x1 is fixed by the algorithm and that for 1 < i ≤ q, xi is uniquely determined by previous answers f(x1), . . . , f(xi−1). We can sample the distribution {gv}v and answer queries from the given algorithm in the following “lazy way”: first, by marking every even blocks with value 1 and initializing a list of queried odd blocks with their values. When a new query x comes, if x was previously queried or belongs to an even block, we return the corresponding stored value. Otherwise, we sample the value, which is 0 with probability 6ε and 1 otherwise, for the odd block which x belongs to; and mark this block as queried.\nLet y1, . . . , yr be the following subsequence of x1, . . . , xq: yi is the ith query made into an odd block which is not queried in y1, . . . , yi−1. Clearly r ≤ q and y1, . . . , yr reveals a violation if and only if number of 0’s in corresponding answers is at least k/2 + 1. Note, for arbitrary a ∈ {0, 1}r ,\nPr[ f(y1) = a1, . . . , f(yr) = ar ] = Pr[ f(y1) = a1 ] · r∏\ni=2\nPr[ f(yi) = ai | f(y1) = a1, . . . , f(yi−1) = ai−1 ] .\nyi is determined by f(y1) = a1, . . . , f(yi−1) = ai−1 and by our way of sampling f(yi), we know that for every i it holds that Pr[ f(yi) = ai | f(y1) = a1, . . . , f(yi−1) = ai−1 ] = 6ε if ai = 0 and Pr[ f(yi) = ai | f(y1) = a1, . . . , f(yi−1) = ai−1 ] = 1− 6ε if ai = 1. Thus.\nPr[ f(y1) = a1, . . . , f(yr) = ar ] = (1− 6ε)|a|(6ε)r−|a|. (4)\nLet Yi be the indicator that f(yi) = 0. We get that, writing F (i,N, p) for the cumulative distribution function of a Binomial with parameters N and p,\nPr\n[ r∑\ni=1\nYi ≥ k\n2 + 1\n] ≤\n∑\na∈{0,1}r : |ā|≥k/2 (1− 6ε)|a|(6ε)r−|a|\n=\nr−k/2∑\nℓ=0\n( r\nℓ\n) (1− 6ε)ℓ(6ε)r−ℓ = F ( r − k\n2 , r, 1 − 6ε\n)\n= F (r(1− x), r, 1 − 6ε) (x def= k2r ∈ (12ε, 1)) ≤ e−rD(1−x||1−6ε) (Relative entropy Chernoff bound6)\nwhere D(p || q) def= p ln pq + (1 − p) ln 1−p 1−q , and we used the fact that k 2 + 1 ≤ r ≤ k24ε . Rewriting\nslightly the right-hand-side, we obtain\nPr\n[ r∑\ni=1\nYi ≥ k\n2 + 1\n] ≤ e− k2Φ(x)\nfor Φ(x) def = 1x ( (1− x) ln 1−x1−6ε + x ln x6ε ) . It is not hard to see that Φ is increasing on [6ε, 1), and since x ≥ 12ε the right-hand-side is at most e− k2Φ(12ε). It then suffices to observe that, for ε ≤ 112 , it holds that Φ(12ε) ≥ Φ(0) = ln 2− 12 > 18 to conclude that\nPr\n[ r∑\ni=1\nYi ≥ k\n2 + 1\n] ≤ e− k16\nand therefore obtain\nPr[ f(y1), . . . , f(yr) contains at least (k/2 + 1) zeros ] ≤ e− k 16 .\nCombining the two, this shows that the probability that y1, . . . , yr does not reveal a violation for gv while gv is ε-far from k-monotone is at least 1− e−k/16 − e−3k/8 > 1/3 (since k ≥ 8). By Yao’s principle, for any (possibly randomized) non-adaptive algorithm A making at most k/(24ε) there exists a fixed v such that gv is ε-far from k-monotone yet A rejects gv with probability less than 2/3. The desired conclusion follows."
    }, {
      "heading" : "4.2 Upper bound for two-sided testers: proof of Theorem 1.5",
      "text" : "In this section, we prove the two-sided non-adaptive upper bound of Theorem 1.5, restated below:\n6Recall that the relative entropy version of the Chernoff bound states that F (m,N, p) ≤ e−mD(mN ||p) as long as 0 ≤ m\nN ≤ p.\nTheorem 1.5. There exists a two-sided non-adaptive tester for k-monotonicity of functions f : [n] → {0, 1} with query complexity q(n, ε, k) = Õ ( 1/ε7 ) , independent of k.\nIn what follows, we assume that k > 20/ε, as otherwise we can use for instance the O(k/ε)-query (non-adaptive, one-sided) tester of Theorem 1.4 to obtain an O ( 1/ε2 ) query complexity.\n4.2.1 Testing k-monotonicity over [Ck]\nWe begin by giving a poly(C/ε)-query tester for k-monotonicity over the domain [Ck]. The tester proceeds by reducing to support size estimation and using (a slight variant of) an algorithm of Canonne and Rubinfeld [CR14]. Let f : [Ck] → {0, 1}, and suppose f is s-monotone but not (s−1)monotone. Then there is a unique partition of [Ck] into s+1 disjoint intervals I1, I2, . . . , Is+1 such that f is constant on each interval; note that this constant value alternates in consecutive intervals. We define a distribution Df over [s + 1] such that Df (i) = |Ii| /(Ck).\nThe algorithm of [CR14] uses “dual access” to D; an oracle that provides a random sample from D, and an oracle that given an element of D, returns the probability mass assigned to this element by D.\nTheorem 4.1 ([CR14, Theorem 14 (rephrased)]). In the access model described above, there exists an algorithm that, on input a threshold n ∈ N∗ and a parameter ε > 0, and given access to a distribution D (over an arbitrary set) satisfying\nmin x∈supp(D) D(x) ≥ 1 n\nestimates the support size |supp(D)| up to an additive εn, with query complexity O (\n1 ε2\n) .\nWe only have access to Df through query access to f . One difficulty is that, to access Df (i), we need to determine where Ii lies in f . For example, finding Df (k/2) requires finding Ik/2, which might require a large number of queries to f .\nWe circumvent this by noting that the algorithm does not require knowing the “label” of any element in the support of the distribution. The only access required is being able to randomly sample elements according to Df , and evaluate the probability mass on the sampled points.\nLemma 4.2 (Sampling from Df ). Let i ∈ [n] be chosen uniformly at random, and let j be such that i ∈ Ij . Then, the distribution of j is exactly Df .\nLemma 4.3 (Evaluating Df (j)). Suppose Ij = {a, a+ 1, . . . , b}. Given i such that i ∈ Ij , we can find Ij by querying f(i + 1) = f(i + 2) = · · · = f(b) and f(b + 1) 6= f(b), as well as f(i − 1) = f(i− 2) = . . . = f(a) and f(a− 1) 6= f(a). The number of queries to f is b− a+ 3 = |Ij|+ 3.\nIf we straightforwardly use these approaches to emulate the required oracles to estimate the support size of Df , the number of queries is potentially very large. If we attempt to query Df (j) where |Ij| = Ω(k), we will need Ω(k) queries to f . It will be enough for us to “cap” the size of the interval.\nLemma 4.4 (Evaluating Df (j) with a cap). Given i such that i ∈ Ij, we will query f on every point in [i − 20C/ε, i + 20C/ε]. If |Ij| ≤ 20C/ε, then Ij will be determined by these queries. If these queries do not determine Ij, we know |Ij| > 20C/ε. Beyond querying i, this requires 40C/ε (nonadaptive) queries.\nClaim 4.5. If f is ε-far from k-monotone, then it is not (1 + ε4)k-monotone, and in particular |supp(Df )| > (1 + ε4 )k + 1.\nProof. The last part of the statement is immediate from the first, so it suffices to prove the first implication. We show the contrapositive: assuming f is (1 + ε4)k-monotone, we will “fix” it into a k-monotone function by changing at most εn points. In what follows, we assume εk4 ≥ 1, as otherwise the statement is trivial (any function that is ε-far from k-monotone is a fortiori not k-monotone).\nLet as before ℓ∗ be the minimum integer ℓ for which f is ℓ-monotone: we can assume k < ℓ∗ ≤ (1 + ε4)k (as if ℓ\n∗ ≤ k we are done.) Consider as above the maximal consecutive monochromatic intervals I1, . . . , Iℓ∗ , and let i be the index of the shortest one. In particular, it must be the case that |Ii| ≤ nℓ∗+1 . Flipping the value of f on Ii therefore has “cost” at most nℓ∗+1 , and the resulting function f ′ is now exactly (ℓ∗−2)-monotone if 1 < i < ℓ∗, and (ℓ∗−1)-monotone if i ∈ {1, ℓ∗}. This means in particular that repeating the above ε4k times is enough to obtain a k-monotone function, and the total cost is upperbounded by\nεk/4∑\nj=0\nn ℓ∗ + 1− 2j ≤ εk/4∑\nj=0\nn k + 1− 2j = k+1∑\nj=k(1− ε 2 )+1\nn j ≤ n\nε 2k + 1\n(1− ε4)k + 1 ≤ n\n3ε 4 k\n(1− ε4)k\nwhere for the last inequality (for the numerator) we used that 1 ≤ εk4 . But this last RHS is upperbounded by εn (as 34x ≤ x(1 − 14x) for x ∈ [0, 1]), showing that Therefore, f was ε-close to k-monotone to begin with, which is a contradiction.\nClaim 4.6. To ε-test k-monotonicity of f : [n] → {0, 1}, it suffices to estimate |Df | to within εk10 .\nProof. If f is ε-far from k-monotone, then |Df | > (1 + ε4)k = k + ε4k, and if f is k-monotone, then |Df | ≤ k + 1. The fact that k > 20/ε then allows us to conclude.\nClaim 4.7. There exists a two-sided non-adaptive tester for k-monotonicity of functions f : [Ck] → {0, 1} with query complexity O ( C3\nε3\n) .\nProof. We use the algorithm of [CR14] for estimating support size. Inspecting their algorithm, we see that our cap of 20C/ε for interval length (and therefore 20/(εk) for maximum probability reported) might result in further error of the estimate. The algorithm interacts with the unknown function by estimating the expected value of 1/Df (j) over random choices of j with respect to Df . Our cap can only decrease this expectation by at most (εk)/20. Indeed, the algorithm works by estimating the quantity Ex∼Df [ 1 Df (x)\n1{Df (x)>τ}], for some suitable parameter τ > 0. By capping the value of 1/Df (x) to 20/(εk), we can therefore only decrease the estimate, and by at most 20/(εk) ·Df ({ x : Df (x) > (εk)/20 }) ≤ 20/(εk).\nThe condition for their algorithm to estimate support size to within ±εm is that all elements in the support have a probability mass of at least 1/m. Since each nonempty interval has length at least 1, we have minj Df (j) ≥ (1/Ck). In order for their algorithm to report an estimate within ±εk/20 of support size, we set ε′ = (ε/20C) in their algorithm.\nThe total error in support size is at most εk/20+ εk/20 = εk/10. By Claim 4.6, this suffices to test ε-test k-monotonicity of f .\nUsing the algorithm of [CR14], we need O(1/ε′2) = O ( (C/ε)2 ) queries to Df . For every query\nto Df , we need to make O(C/ε) queries to f , so the overall query complexity is O ( C3/ε3 ) .\n4.2.2 Reducing [n] → {0, 1} to [Ck] → {0, 1}.\nNow we show how to reduce ε-testing k-monotonicity of f : [n] → {0, 1} to ε′-testing k-monotonicity of a function g : [Ck] → {0, 1} for C = poly(1/ε) and ε′ = poly(ε), resulting in a poly(1/ε)-query algorithm for ε-testing k-monotonicity.\nThe first step is (as before) to divide [n] in blocks (disjoint intervals) of size εn4k if ε > 8k n (again assuming without loss of generality that εn4k is an integer), and blocks of size 1 otherwise (in which case n ≤ 8kε and we can directly apply the result of Claim 4.7, with C = n/k ≤ 8/ε). Let m = 4k/ε be the number of resulting blocks, and define fm : [n] → {0, 1} as the m-block-coarsening of f : namely, for any j ∈ Bi, we set\nfm(j) = argmaxb∈{0,1} Pr k∈Bi [fm(k) = b] (majority vote)\nOrdering the blocks B1, B2, . . . , Bm, we also define g : [m] → {0, 1} such that g(i) = mina∈Bi fm(a).\nLemma 4.8. Suppose f is k-monotone. Then f has at most k non-constant blocks, and fm is k-monotone.\nProof. The function f only changes values k times; for a block to be non-constant, the block must contain a pair of points with a value change.\nWe call a block variable if the minority points comprise at least an ε/100-fraction of the block; formally, B is variable if minb∈{0,1} Prj∈B[f(j) = b] ≥ ε/100.\nLemma 4.9. Suppose f has s variable blocks. Then dist(f, fm) ≤ s/m+ ε/100.\nProof. We will estimate the error of fm in computing f on variable blocks and non-variable blocks separately. Each non-variable block B can contribute error on at most ε |B| /100 points. Each variable block B can contribute error on at most |B| = n/m points. The total number of errors is at most εn/100 + s(n/m) = n(ε/100 + s/m), yielding the upper bound on dist(f, fm).\nLemma 4.10. Suppose f is promised to be either (i) k-monotone or (ii) such that fm has more\nthan 54k variable blocks. Then we can determine which with O ( 1 ε2 log 1ε ) queries, and probability 9/10.\nProof. We first note that given any fixed block B, it is easy to detect whether it is variable (with probability of failure at most δ) by making O ( 1 ε log 1 δ ) uniformly distributed queries in B. Doing so, a variable block will be labelled as such with probability at least 1− δ, while a constant block will never be marked as variable. (If a block is neither constant nor variable, then any answer will do.)\nLetting s denote the number of variable blocks, we then want to non-adaptively distinguish between s ≥ 54k = 5ε16m and s ≤ k = ε4m (since if f were k-monotone, then fm had at most k variable blocks). Doing so with probability at least 19/20 can be done by checking only q = O ( 1 ε ) blocks chosen uniformly at random: by the above, setting δ = 120q all of the q checks will also yield the correct answer with probability no less than 9/10, so by a union bound we will distinguish (i) and (ii) with probability at least 9/10. We conclude by observing that all O ( q · 1ε log 1q ) = O ( 1 ε2 log 1ε ) queries are indeed non-adaptive.\nClaim 4.11. There exists a two-sided non-adaptive tester for k-monotonicity of functions f : [n] → {0, 1} with query complexity Õ ( 1 ε7 ) .\nProof. We use the estimation/test from the previous lemma as the first part of our tester. Assuming f passes, we can assume that fm has less than 5 4k variable blocks. By Lemma 4.9, dist(f, fm) ≤ 5k 4 /m+ ε 100 = 5ε 32 + ε 100 ≤ ε3 . This part takes O ( 1 ε2 log 1 ε ) queries.\nNow, we apply the tester of Claim 4.7 (with probability of success amplified to 9/10 by standard arguments) to (ε/6)-test k-monotonicity of g : [m] → {0, 1}, where g(i) is the constant value of fm on Bi, and m = (4k)/ε. Let q be the query complexity of the tester, and set δ = 1/(10q); to query\ng(i), we randomly query f on O ( 1 ε log 1 δ ) points in Bi and take the majority vote. With probability at least 1− δ, we get the correct value of g(i), and by a union bound all q simulated queries have the correct value with probability at least 9/10.\nTherefore, to get a single query to g, we use O((log q)/ε) queries. In the context of our previous section, we have C = 4/ε, so q = O(C3/ε3) = O ( 1/ε6 ) and the overall query complexity of this part is O((q log q)/ε) = O (\n1 ε7 log 1 ε\n) . This dominates the query complexity of the other part of the\ntester, from Lemma 4.10, which is O (\n1 ε2 log 1 ε\n) . By a union bound over the part from Lemma 4.10,\nthe simulation of g, and the call to the tester of Claim 4.7, the algorithm is correct with probability at least 1− 3/10 > 2/3."
    }, {
      "heading" : "5 On the grid",
      "text" : "We now turn to the grid, and consider k-monotonicity of functions defined on [n]2. More specifically, in this section we prove Theorem 1.6, giving an adaptive tester for 2-mononicity with optimal query complexity, before discussing in Section 5.2 possible extensions of these ideas."
    }, {
      "heading" : "5.1 The case k = 2",
      "text" : "Theorem 1.6. There exists a two-sided adaptive tester for 2-monotonicity of functions f : [n]2 → {0, 1} with query complexity q(n, ε) = O ( 1 ε ) .\nProof. At a high-level, the algorithm relies on two key components: the first is the observation that testing 2-monotonicity of f : [n]2 → {0, 1} under some suitable additional assumption on f reduces to (tolerant) testing monotonicity of two one-dimensional functions (but with larger range), under the L1 norm. The second is that, given access to an arbitrary f , one can efficiently provide query access to some function g which satisifies this additional assumption, and such that g will also be close to f whenever f is truly 2-monotone.\nCombining the two then enables one to test this function g for 2-monotonicity, and then check whether it is also the case that f and g are sufficiently close. The first step, by the above, can be done efficiently by simulationg query access to g, which in turn allows to (with some additional tricks) simulate access to the corresponding one-dimensional functions: and invoke on these two functions the L1-tester of [BRY14]. (The main challenges there lies in performing this two-level simulation while keeping the number of queries to f low enough; which we achieve by carefully amortizing the queries made overall.)\nDetails. We hereafter assume without loss of generality that f is identically 0 on the bottom and top rows, that is f(1, j) = f(n, j) = 0 for all j ∈ [n]. (Indeed, we can ensure this is the case by adding two extra columns, extending the domain of f to [n + 2] × [n]: note that if f remains 2-monotone if it was already, and can only decrease its distance to 2-monotonicity by O(1/n)).7 For the sake of the proof, we will require the notion of 2-column-wise-monotonicity, defined below:\nDefinition 5.1. A function f : [n]2 → {0, 1} is said to be 2-column-wise-monotone if, for every j ∈ [n], its restriction fj : [n]×{j} → {0, 1} is 2-monotone. Given such a function f , we define the two sequences (∂̄fj)j∈[n] and (\n¯ ∂fj)j∈[n] as the sequence of “changepoints” in the columns. More\nformally, we define\n¯ ∂fj = min { i ∈ [n] : f(i, j) 6= f(1, j) } − 1, ∂̄fj = max { i ∈ [n] : f(i, j) 6= f(n, j) }+ 1\nfor every j such that f |[n]×{j} is not constant; and ¯ ∂fj = ∂̄fj = 1 otherwise. Note that we have ¯ ∂fj ≤ ∂̄fj for every column j ∈ [n].\nAs it turns out, testing 2-monotonicity of functions guaranteed to be 2-column-wise-monotone reduces to testing monotonicity of these two specific subsequences:\nLemma 5.2. Let f : [n]2 → {0, 1} be 2-column-wise-monotone. If f is 2-monotone, then both sequences (\n¯ ∂fj)j∈[n] and (∂̄fj)j∈[n] are non-increasing. Moreover, if f is ε-far from 2-monotone,\nthen at least one of the two sequences is ε2-far from non-increasing (in Hamming distance).\nIt is possible to refine the above statement to obtain, in the second case, a more precise characterization in terms of the L1 distance of these two sequences to monotonicity. For conciseness, in the rest of this section we denote by M(d)k the class of k-monotone functions on [n]d, and will omit the subscript when k = 1 (i.e., for monotone functions: M(d) = M(d)1 ). Lemma 5.3. Let f : [n]2 → {0, 1} be 2-column-wise-monotone. If f is ε-far from 2-monotone then at least one of the two sequences is ε2 -far from non-increasing (in L1 distance). More precisely:\ndist ( f,M(2)2 ) ≤ L1(∂̄f,M(1)) + L1(\n¯ ∂f,M(1)) (5)\nWe defer the proof of these two lemmata to Appendix C, and turn to the proof of Theorem 1.6. We first describe a non-optimal tester making O(1/ε2) queries; before explaining how to modify it in order to amortize the number of queries, to yield the desired O(1/ε) query complexity.\nSuppose we are given query access to an arbitrary function f : [n]2 → {0, 1}. For simplicity, as before we assume without loss of generality that εn16 is an integer, and partition each column into K def = 16ε intervals of size εn 16 , that is partition the domain [n] × [n] into a grid [16ε ] × [n] (each column being divided in K blocks B1, . . . , BK of size εn 16 ). This uniquely defines a function g : [n]2 → {0, 1, ∗}: for any point x = (i, j) ∈ [n]2, we let ℓ ∈ [K] be the index such that i ∈ Bℓ = {bℓ, . . . , bℓ+1 − 1}, and set:\n• g(x) = f(i, bℓ)), if f(i, bℓ) = f(i, bℓ+1 − 1); • g(x) = ∗, if f(i, bℓ) 6= f(i, bℓ+1 − 1);\n7This will be used in the proof of Lemma 5.2 and Lemma 5.3.\nso that g is constant on any “block” Bℓ × {i}. Note that we can provide query access to g, at the price of an overhead of 2 queries (to f) per query (to g).\nHowever, this g may not itself be 2-column-wise-monotone; for this reason, we will instead work with a “fixed” version of g which will by construction be 2-column-wise-monotone. In more detail, we define g̃ to be the 2-column-wise-monotone function obtained by the following process.\n• First, we (arbitrarily) set the values ∗ to 0, so that g becomes a function g : [n]2 → {0, 1}. • Define g̃ by its restriction on each column: letting (∂̄gj)j∈[n] and (\n¯ ∂gj)j∈[n] be as defined\nin Definition 5.1 (observing that the quantities are well and uniquely defined even if g is not 2-column-wise-monotone), set\ng̃(i, j) =    g(1, j) if i ≤ ¯ ∂gj 1− g(1, j) if ¯ ∂gj < i < ∂̄gj\ng(n, j) if i ≥ ∂̄gj\nFrom this construction, it is clear that g̃ is 2-column-wise-monotone, and entirely and deterministically determined by g (and therefore by f); moreover we have g̃ = g whenever g is itself 2-columnwise-monotone. Furthermore, any query to g̃ can straightforwardly be answered by making at most queries O(1/ε) to g, and hence to f .\n• If f is 2-monotone, then g is ε8 -close to f and so is g̃; moreover, g̃ is 2-monotone as well. Therefore dist(f, g̃) ≤ ε8 and dist ( g̃,M(2)2 ) = 0. • If f is ε-far from 2-monotone, then g̃ is either (i) ε4 -far from f or (ii) 3ε4 -far from 2-monotone, since if neither hold then by the triangle inequality f is ε-close to 2-monotone.\nThe tester (first take). The algorithm now proceeds as follows:\n1. simulate query access to g̃ (defined as above) to detect if dist ( g̃,M(2)2 ) ≥ ε using Eq.(5), with\nprobability of failure 16 . More precisely, test monotonicity in L1 distance of both ¯ ∂g̃ and ∂̄g̃ with parameter ε64 , using the (non-adaptive) algorithm of [BRY14]; and reject if any of these two tests rejects.\n• If dist ( g̃,M(2)2 ) = 0, then\nL1(∂̄f,M(1)) = L1( ¯ ∂f,M(1)) = 0\nby Lemma 5.2, and both tests will accept.\n• If dist ( g̃,M(2)2 ) > 3ε4 , then\nmax(L1(∂̄f,M(1)), L1( ¯ ∂f,M(1))) > 3ε 8\nand at least one of the two tests rejects.\n2. simulate query access to g̃ to test whether dist(f, g̃) ≤ ε8 vs. dist(f, g̃) > ε4 , with probability of failure 16 ; 3. return ACCEPT if both of the two tests above passed, REJECT otherwise.\nBy a union bound, the tester is then correct with probability at least 23 ; its query complexity is\n2t ·O ( 1\nε\n) + ( t′ ·O ( 1\nε\n) +O ( 1\nε\n))\nwhere t and t′ are respectively the cost of simulating query access to ∂̄g, ¯ ∂g, and to g̃; as the first step, testing in L1 for for functions defined on the line [n], has query complexity O(1/ε) from [BRY14]. Taking t = t′ = O(1/ε) as discussed above then results in a query complexity of O ( 1/ε2 ) .\nHowever, as mentioned previously this is not optimal: as we shall see, we can modify this to obtain instead an O(1/ε) query complexity. In order to “amortize” the overall query complexity, we define the following process that specifies a 2-column-wise-monotone function g̊:\nInitialization. Let j1, . . . , j1/ε+1 ∈ [n] be the indices defined by jℓ = (ℓ− 1) · εn+ 1 for ℓ ∈ [1/ε], and j1/ε+1 = n.\n• Obtain all the values of g on the j1-st column [n]× {j1}, at a cost of O(1/ε) queries to f , to find ∂̄g̊j1,¯ ∂g̊j1. Define g̊ on this column accordingly. • Assuming g̊ has been defined on the jℓ-th column, define it on the jℓ+1-th column: starting at the “vertical” positions of the two changepoints ∂̄g̊jℓ,¯\n∂g̊jℓ of the previous column, start querying “downwards” the values of g on the jℓ+1-th column until candidates values for ∂̄g̊jℓ+1, ∂̄g̊jℓ+1 consistent with g are found or the bottom of the column is reached (in which case the corresponding changepoint ∂̄g̊jℓ+1 or ¯ ∂g̊ℓ+1 is set to 1). After this, define g̊ on the jℓ+1-th column to be consistent with these (at most) two changepoints.\nNote that the queries made in this step are adaptive, and the (partial) function g̊ obtained at the end coincides with g̃ if f (and therefore g̃) is indeed 2-monotone. This is because in this case, by Lemma 5.2 the sequences (∂̄g̃j)j , (¯ ∂g̃j)j will be non-decreasing, and therefore the process outlined above will result in ∂̄g̃jℓ = ∂̄g̊jℓ and ¯ ∂g̃jℓ = ¯\n∂g̊jℓ for all 1 ≤ ℓ ≤ 1/ε + 1. Moreover, it is not difficult to see that the total number of queries made to f in this initialization step will be O(1/ε): this is because of the fact that we only search for the current changepoint ∂̄g̊jℓ (resp. ¯\n∂g̊jℓ) starting at the position of the previous one ∂̄g̊jℓ−1 (resp.\n¯ ∂g̊jℓ−1), going downwards only. Since to obtain a changepoint we only query the\npositions of g (and therefore f) at block endpoints, there are in total at most 1/ε positions to query where starting at one and then only going “down.” Thus, the number of queries made for each column jℓ can be written as O(1) +mℓ, where ∑1/ε+1\nℓ=1 mℓ ≤ K = O(1/ε). Query time. When querying the value of g̊ on a point (i, j), first let ℓ be the index such that\njℓ ≤ j < jℓ+1. Then define ∂̄g̊j (resp. ¯∂g̊j) by querying the value of g on the j-th column for all at most 1/ε (block) indices between ∂̄g̊jℓ and ∂̄g̊jℓ+1 (resp. ¯ ∂g̊jℓ and ¯ ∂g̊jℓ+1) to find the corresponding candidate changepoints:\n¯ ∂g̊j = min\n{\n¯ ∂g̊jℓ+1 ≤ i ≤ ¯∂g̊jℓ : g(i, j) 6= g(1, j)\n} − 1,\n∂̄g̊j = max { ∂̄g̊jℓ+1 ≤ i ≤ ∂̄g̊jℓ : g(i, j) 6= g(n, j) } + 1\nAgain, note that after each query the (partial) function g̊ obtained so far will coincide with g̃ if f (and therefore g̃) is indeed 2-monotone; and g̊ is uniquely determined by f (and in particular does\nnot depend on the actual queries made nor on their order). Finally, the function g̊ thus defined will always by construction be 2-column-wise-monotone.\nThe tester previously described can then be slightly modified to simulate access to g̊ instead of g̃: by the above discussion, for the completeness case we will have the same guarantees as then g̊ = g̃, while the soundness case stays unchanged:\n• If f is 2-monotone, then g̊ = g̃ is ε8 -close to f ; so dist(f, g̊) ≤ ε8 and dist ( g̊,M(2)2 ) ≤ ε8 .\n• If f is ε-far from 2-monotone, then g̊ is either (i) ε4 -far from f or (ii) 3ε4 -far from 2-monotone. Thus, the analysis of correctness of the tester carries through with this modification; it only remains to bound the query complexity. We will show that the expected number of queries made is O(1/ε); a bound on the worst-case query complexity will then follow from standard arguments,8 at the price of a constant factor in the O(·).\nTo give this bound on the expected number of queries, we first observe that the algorithm from [BRY14] we rely on in the first stage of the tester is non-adaptive, and moreover all the queries it makes are uniformly distributed (as it works by a reduction, invoking the non-adaptive, one-sided, sample-based monotonicity tester for functions [n] → {0, 1}). Similarly, all the queries made in the second stage are uniformly distributed as well.\nTherefore, the expected number of queries aℓ made to columns with indices jℓ ≤ j < jℓ+1 is the same for each ℓ ∈ [1/ε + 1], namely\naℓ = q\n1/ε = O(1).\nwhere q = O ( 1 ε ) is the total number of queries made to g̊ (and/or to ∂̄g̊,\n¯ ∂g̊) during the second\nphase of “Query time.” Now, letting mℓ = ¯ ∂g̊jℓ − ¯∂g̊jℓ+1 and m ′ ℓ = ∂̄g̊jℓ − ∂̄g̊jℓ+1, we have that the total expected cost of simulating these queries (in terms of queries to f) is upperbounded by\n1 ε∑\nℓ=1\naℓ · ( O(1) +mℓ +m ′ ℓ ) = O\n( 1\nε\n) +O(1) · 1 ε∑\nℓ=1\nmℓ +O(1) · 1 ε∑\nℓ=1\nm′ℓ = O ( 1\nε\n) .\nSince the total number of queries made to f is the sum of the number of queries made to partly build g̊ during the “Initialization phase” (which is O(1/ε) by the foregoing discussion), the number of queries made to simulate access to g̊ or ∂̄g̊,\n¯ ∂g̊ during the “Query time” (which was just shown\nto be O(1/ε) in expectation), and the number of queries directly made to f when testing the distance of f to g̊ (which is also O(1/ε)), the expected total number of queries is indeed O(1/ε), as claimed."
    }, {
      "heading" : "5.2 Possible extensions",
      "text" : "We now discuss two possible extensions of the techniques underlying Theorem 1.6, namely to (i) kmonotonicity testing of functions over [n]2, for general k; and (ii) 2-monotonicity testing of functions over [n]d, for general d. (Note that we do provide a different tester for general k and d in the next section, Section 6).\n8Namely, stopping the algorithm and outputting REJECT if the number of queries made exceeds C ε\nfor some absolute constant C > 0, found by applying Markov’s inequality.\nExtending to general k (for d = 2). A natural direction would be to first to generalize Definition 5.1\nto k-column-wise monotone functions f , defining the k sequences ( ¯ ∂f (1) j )j∈[n], . . . , (¯ ∂f (k) j )j∈[n] of column changepoints with ¯ ∂f (1) j ≤ · · · ≤ ¯∂f (k) j for all j ∈ [n]. The next step would then be to obtain an analogue of the key lemma of the previous section, Lemma 5.3 to this setting. An issue is that it appears necessary to consider now the L1 distance to (k− 1)-monotonicity of these k sequences, instead of monotonicity as before. Thus, taking this route requires to generalize the definition of k-monotonicity to real-valued functions, but also to develop L1-testers for k-monotonicity over the line.\nThe testing algorithm now follows the same outline as in the previous section, with the same “amortizing” idea when invoking this newly obtained L1-tester for k-monotonicity in parallel on the k subsequences, each with probability of failure δ = 1/(10k) (for a union bound) and approximation parameter ε′ = ε/(10k). (Note that some more optimizations may then help further reduce the query complexity, by “sharing” the same set of queries between the k instances of the L1-testing algorithm.)\nExtending to general d (for k = 2). At a very high-level, the tester of Section 5.1 works by reducing 2-monotonicity testing of f : [n]2 → {0, 1} to monotonicity L1-testing of\n¯ ∂f, ∂̄f : [n] →\n[0, 1]. More generally, one can hope to extend this approach to higher dimensions, reducing 2- monotonicity testing of f : [n]d → {0, 1} to monotonicity L1-testing of\n¯ ∂f, ∂̄f : [n]d−1 → [0, 1]: that\nis, testing monotonicity (in L1) of the two (d − 1)-dimensional “surfaces” of changepoints. This in turn could be done invoking the L1 non-adaptive tester of [BRY14] for monotonicity over [n]\nd, which has query complexity Õ(d/ε): which may lead to a total query complexity of poly(d, 1/ε), that is polynomial in the dimension. We leave this possible extension as an interesting direction for future work."
    }, {
      "heading" : "6 On the high-dimensional grid",
      "text" : "In this section, we give two algorithms for tolerant testing, that is testing whether a function f : [n]d → {0, 1} is ε1-close to k-monotone vs. ε2-far from k-monotone, establishing Theorem 1.8. The first has query complexity exponential in the dimension d and is fully tolerant, that is works for any setting of 0 ≤ ε1 < ε2 ≤ 1. The second applies whenever ε2 > 3ε1, and has (incomparable) query complexity exponential in Õ(k √ d/(ε2 − 3ε1)2). Both of these algorithms can be used for non-tolerant (“regular”) testing by setting ε1 = 0 and ε2 = ε, which implies Theorem 1.7.\nTheorem 1.8. There exist\n• a non-adaptive (fully) tolerant tester for k-monotonicity of functions f : [n]d → {0, 1} with query complexity q(n, d, ε1, ε2, k) = Õ ( 1 (ε2−ε1)2 ( 5kd ε2−ε1 )d) ; • a non-adaptive tolerant tester for k-monotonicity of functions f : [n]d → {0, 1} with query complexity q(n, d, ε1, ε2, k) = 2 Õ(k √ d/(ε2−3ε1)2), under the restriction that ε2 > 3ε1.\nAs a corollary, this implies Theorem 1.7, restated below:\nTheorem 1.7. There exists a non-adaptive tester for k-monotonicity of functions f : [n]d → {0, 1} with query complexity q(n, d, ε, k) = min(Õ ( 1 ε2 ( 5kd ε )d) , 2Õ(k √ d/ε2)).\nFor convenience, we will view in this part of the paper the set [n] as [n] = {0, 1, . . . , n − 1}. Assuming that m divides n, we let Bm,n : [n]d → [m]d be the mapping such that Bm,n(y)i = ⌊yi/m⌋ for 1 ≤ i ≤ m. For x ∈ [m]d, we define the set B−1m,n(x) to be the inverse image of x. Specifically, B−1m,n(x) is the set of points of the form m · x + [n/m]d, with standard definitions for scalar multiplication and coordinate-wise addition. That is, B−1m,n(x) is a “coset” of [n/m]d points in [n]d. To keep on with the notations of the other sections, we will call these cosets blocks, and will say a function h : [n]d → {0, 1} is an m-block function if it is constant on each block. Moreover, for clarity of presentation, we will omit the subscripts on B and B−1 whenever they are not necessary.\nWe first establish a lemma that will be useful for the proofs of correctness of both algorithms.\nLemma 6.1. Suppose f : [n]d → {0, 1} is k-monotone. Then there is an m-block function h : [n]d → {0, 1} such that dist(f, h) < kd/m.\nProof. Fix any k-monotone function f : [n]d → {0, 1}. We partition [m]d into chains of the form\nCx = { x+ ℓ · 1d : ℓ ∈ N, x ∈ [m]d and xi = 0 for some i } .\nThere are md − (m − 1)d ≤ dmd−1 of these chains: we will show that f can only be nonconstant on at most k blocks of each chain.\nBy contradiction, suppose there exists x ∈ [m]d such that f is nonconstant on k + 1 different blocks B−1(z(i)), where z(1) ≺ z(2) ≺ . . . ≺ z(k) ≺ z(k+1), and each z(i) ∈ Cx. By construction, we have B−1(z(i)) ≺ B−1(z(j)) for i < j. For each 1 ≤ i ≤ k+1, there are two points v(i)∗ , v(i)∗∗ ∈ B−1(zi) such that v (i) ∗ ≺ v(i)∗∗ and f(v(i)∗ ) 6= f(v(i)∗∗ ). By construction v(1)∗ ≺ v(1)∗∗ ≺ v(2)∗ ≺ v(2)∗∗ ≺ v(3)∗ ≺ v(3)∗∗ ≺ . . . ≺ v(k+1)∗ ≺ v(k+1)∗∗ , and there must be at least k + 1 pairs of consecutive points with differing function values. Out of these 2k+2 many points, there is a chain of points v̄(1) ≺ v̄(2) ≺ . . . ≺ v̄(k+1) where f(v̄(i)) 6= f(v̄(i+1)) for 1 ≤ i ≤ k, which is a violation of the k-monotonicity of f .\nThus, in each of the dmd−1 many chains of blocks, there can only be k nonconstant blocks. It follows that there are at most kdmd−1 nonconstant blocks in total. We now define h(y) to be equal to f(y) if f is constant on B(y), and arbitrarily set h(y) = 0 otherwise. Each set B−1(y) contains (n/m)d = nd ·m−d many points, and f is not constant on at most kdmd−1 of these. It follows that dist(f, h) ≤ kdmd−1 ·m−d = kd/m."
    }, {
      "heading" : "6.1 Fully tolerant testing with O(kd/(ε2 − ε1)))d queries",
      "text" : "Our first algorithm (Algorithm 1) then proceeds by essentially brute-force learning an m-block function close to the unknown function, and establishes the first item of Theorem 1.8.\nProposition 6.2. Algorithm 1 accepts all functions ε1-close to k-monotone functions, and rejects all functions ε2-far from k-monotone (with probability at least 2/3). Its query complexity is\nO\n( d (ε2−ε1)2 ( 5kd ε2−ε1 + 1 )d log kdε2−ε1 ) .\nProof. The algorithm first estimates Pry∈B−1(x) [ f(y) = b ] for every x ∈ [m]d and b ∈ {0, 1} to within ±α5 . We use t = 25 ln(6md)/2α2 points in each block to ensure (by an additive Chernoff bound) that each estimate is correct except with probability at most m−d/3. By a union bound, the probability that all estimates are correct is at least 2/3, and we hereafter condition on this.\nAlgorithm 1 Fully tolerant testing with O(kd/(ε2 − ε1)))d queries. Require: Query access to f : [n]d → {0, 1}, ε2 > ε1 ≥ 0, a positive integer k 1: α ← (ε2 − ε1),m ← ⌈5kd/α⌉, t ← ⌈25 ln(6md)/(2α2)⌉ 2: ⊲ Define a distribution D over [m]d × {0, 1}. 3: for x ∈ [m]d do 4: Query f on t random points Tx ⊆ B−1(x). 5: D(x, 0) ← Pry∈Tx [ f(y) = 0 ] /md 6: D(x, 1) ← Pry∈Tx [ f(y) = 1 ] /md 7: end for 8: ⊲ Define a distribution D′ over [n]d × {0, 1} such that D′(y, b) = D(B(y), b) ·md/nd. 9: if there exists a k-monotone m-block function h such that Pr(y,b)∼D′ [ h(y) 6= b ] ≤ ε1 + α2 then\nreturn ACCEPT 10: end if 11: return REJECT\nBy construction, E(x,b)∼D[Pry∈B−1(x) [ f(y) 6= b ]] = Pr(y,b)∼D′ [ f(y) 6= b ] ≤ α5 . In this probability experiment, the marginal distribution of D′ on y is uniform over [n]d.\nLet f∗ : [n]d → {0, 1} be a k-monotone function minimizing Pr[ f(y) 6= f∗(y) ]. Lemma 6.1 ensures that there is a k-monotone m-block function h : [n]d → {0, 1} such that dist(f∗, h) < kd/m ≤ α/5. Let h∗ : [n]d → {0, 1} be a k-monotone m-block function minimizing dist(f∗, h∗).\nCompleteness. Suppose dist(f, f∗) ≤ ε1. Then by the triangle inequality,\nPr (y,b)∼D′ [ h∗(y) 6= b ] ≤ Pr (y,b)∼D′ [ h∗(y) 6= f∗(y) ]+ Pr (y,b)∼D′ [ f∗(y) 6= f(y) ]+ Pr (y,b)∼D′ [ f(y) 6= b ] ≤ ε1+ 2α 5 .\nwhere to bound the first term Pr(y,b)∼D′ [ h ∗(y) 6= f∗(y) ] by dist(f∗, h∗) ≤ α/5 we used the fact that the marginal distribution of y is uniform when (y, b) ∼ D′. Thus, the algorithm will find a k-monotone m-block function close to D (without using any queries to f) and accept.\nSoundness. Suppose dist(f, f∗) ≥ ε2. Then by the triangle inequality\nPr (y,b)∼D′ [h(y) 6= b] ≥ Pr (y,b)∼D′ [h(y) 6= f(y)]− Pr (y,b)∼D′ [f(y) 6= b]\n≥ Pr (y,b)∼D′ [f∗(y) 6= f(y)]− Pr (y,b)∼D′ [f(y) 6= b] ≥ ε2 − α\n5\nfor every k-monotone m-block function h. Since ε2 − 2α/5 ≥ ε1 + 3α/5, the algorithm never find a k-monotone m-block function h with low error with respect to D, and the algorithm will reject.\nQuery complexity. The algorithm only makes queries in constructing D; the number of queries required is md · t = O (\nd α2 ( 5kd α + 1 )d log kdα ) .\n6.2 Tolerant testing via agnostic learning\nWe now present our second algorithm, Algorithm 2, proving the second item of Theorem 1.8. At its core is the use of an agnostic learning algorithm for k-monotone functions, which we first describe.9\nProposition 6.3. There exists an agnostic learning algorithm for k-monotone functions over [r]d → {0, 1} with excess error τ with sample complexity exp(Õ(k √ d/τ2).\nAlgorithm 2 Multiplicative approximation with exp(Õ(k √ d/((ε2 − 3ε1)2)) queries Require: Query access to f : [n]d → {0, 1}, ε2 > 3ε1 ≥ 0, a positive integer k 1: α ← (ε2 − 3ε1), m ← ⌈6kd/ε⌉ , t ← ⌈3d(k + 1)/ε lnm+ ln 100⌉ 2: Define D to be the distribution over [m]d × {0, 1} such that D(x, b) = Pry∈B−1(x) [ f(y) = b ]. 3: ⊲ AD(τ, f) denotes the output of an agnostic learner of k-monotone functions with respect to D,\nwith excess error τ and probability of failure 1/10 4: h : [m]d → R ← AD(α/12, f). 5: Estimate Pr(x,b)∼D [ h(x) 6= b ] to within ±α/7 with probability of failure 1/10, using O(1/α2)\nqueries. 6: if the estimate is more than ε1 + 5α 12 then return REJECT 7: end if 8: if dist(h, ℓ) = Prx∈[m]d [ h(x) 6= ℓ(x) ] ≤ 2ε1+ 5α12 for some k-monotone m-block function ℓ then\nreturn ACCEPT 9: else return REJECT\n10: end if\nWe will rely on tools from Fourier analysis to prove Proposition 6.3. For this reason, it will be convenient in this section to view the range as {−1, 1} instead of {0, 1}.\nDefinition 6.4. For a Boolean function f : [r]d → {−1, 1}, we define\nInf i[f ] = 2Pr [ [f(x) 6= f(x(i)) ]\nwhere x = (x1, x2, . . . , xd) is a uniformly random string over [r] d, and x(i) = (x1, x2, . . . , xi−1, x′i, xi+1, . . . , xd)\nfor x′ drawn independently and uniformly from [r]. We also define Inf [f ] = ∑d\ni=1 Inf i[f ].\nWe first generalize the following result, due to Blais et al., for more general domains:\nProposition 6.5 ([BCO+15]). Let f : {0, 1}d → {−1, 1} be a k-monotone function. Then Inf [f ] ≤ k √ d.\nLemma 6.6 (Generalization). Let f : [r]d → {−1, 1} be a k-monotone function. Then Inf [f ] ≤ k √ d.\n9Recall that an agnostic learner with excess error τ for some class of functions C is an algorithm that, given an unknown distribution D, an unknown arbitrary function f , and access to random labelled samples 〈x, f(x)〉 where x ∼ D, satisfies the following. It outputs a hypothesis function ĥ such that Prx∼D [ f(x) 6= ĥ(x) ] ≤ optD + τ with probability at least 2/3, where optD = minh∈C Prx∼D [ f(x) 6= h(x) ] (i.e., it performs “almost as well as the best function in C”).\nProof. For any two strings y0, y1 ∈ [r]d, let fy0,y1 : {0, 1}d → {−1, 1} be the function obtained by setting fy0,y1(x) = f(y x), where yx ∈ [r]d is defined as\nyxi = { min{y0i , y1i } if xi = 0 max{y0i , y1i } if xi = 1\nSince f was a k-monotone function, so is fy0,y1. Thus Inf [fy0,y1 ] ≤ k √ d for every choice of y0 and y1. It is not hard to see that for any fixed i ∈ [d] the following two processes yield the same distribution over [r]d × [r]d:\n• Draw z ∈ [r]d, z′i ∈ [r] independently and uniformly at random, set z′ def = (z1, . . . , zi−1, z′i, zi+1, . . . , zd),\nand output (z, z′);\n• Draw y0, y1 ∈ [r]d, x ∈ {0, 1}d independently and uniformly at random, and output (yx, yx(i)). This implies that\nInf [f ] = d∑\ni=1\nInf i[f ] = d∑\ni=1\n2 Pr z∈[r]d\n[f(z) 6= f(z(i))] = d∑\ni=1\n2Ey0,y1∈[r]d\n[ Pr\nx∈{0,1}d\n[ f(yx) 6= f(yx(i))\n]]\n= Ey0,y1∈[r]d\n[ d∑\ni=1\n2 Pr x∈{0,1}d\n[ f(yx) 6= f(yx(i)) ]] = Ey0,y1∈[r]d [ d∑\ni=1\n2 Pr x∈{0,1}d\n[ fy0,y1(x) 6= fy0,y1(x(i))\n]]\n= Ey0,y1 [Inf [fy0,y1 ]] ≤ Ey0,y1 [k √ d] = k √ d.\nFor two functions f, g : [r]d → R, we define the inner product 〈f, g〉 = Ex[f(x)g(x)], where the expectation is taken with respect to the uniform distribution. It is known that for functions f : [r]d → R, there is a “Fourier basis” of orthonormal functions f . To construct such a basis, we can take any orthonormal basis {φ0 ≡ 1, φ1, . . . , φ|r|−1} for functions f : [r] → R. Given such a basis, a Fourier basis is the collection of functions φα, where α ∈ [r]d, and φα(x) = ∏d i=1 φαi(xi).\nThen every f : [r]d → R has a unique representation f = ∑α∈[r]d f̂(α)φα, where f̂(α) = 〈f, φα〉 ∈ R. Many Fourier formulæ hold in arbitrary Fourier bases, an important example being Parseval’s Identity: ∑\nα∈[r]d f̂(α) 2 = 1. We will use the following property:\nLemma 6.7 ([O’D14, Proposition 8.23]). For α ∈ [r]d, let |α| denote the number of nonzero coordinates in α. Then we have\nInf [f ] = ∑\nα∈[r]d |α| f̂(α)2.\nLemma 6.8. If Inf [f ] ≤ k, then ∑\nα:|α|>k/ε f̂(α)2 ≤ ε.\nProof. If not, then Inf [f ] = ∑ α |α| f̂(α)2 ≥ ∑ α:|α|>k/ε |α| f̂(α)2 ≥ kε ∑ α:|α|>k/ε f̂(α) 2 > kε · ε = k, a contradiction. Lemma 6.9. Let p be the function ∑\nα:|α|≤t f̂(α)φα. Then\n(i) ‖p − f‖22 = Ex∈[r]d[(p(x) − f(x))2] = ∑ α:|α|>t f̂(α) 2;\n(ii) p is expressible as a linear combination of real-valued functions over [r]d, each of which only depends on at most t coordinates; (iii) p is expressible as a degree-t polynomial over the rd indicator functions 1{xi=j} for 1 ≤ i ≤ d and j ∈ [r].\nTheorem 6.10 ([KKMS08, Theorem 5]). Let C be a class of Boolean functions over X and S a collection of real-valued functions over X such that for every f : X → {−1, 1} in C, there exists a function p : X → R such that p is expressible as a linear combination of functions from S and ‖p− f‖22 ≤ τ2. Then there is an agnostic learning algorithm for C achieving excess error τ which has sample complexity poly(|S| , 1/τ).\nImportantly, this algorithm is still successful with inconsistent labelled samples (examples), as long as they come from a distribution on X × {−1, 1}, where the marginal distribution on X is uniform.\nNow we put all the pieces together. To agnostically learn a k-monotone function, we simply perform the agnostic learning algorithm of [KKMS08] on the distribution D over [m]d × {−1, 1} defined by\nD(x, b) = Pr y∈B−1(x) [ f(y) = b ] .\nTo generate a sample (x, b) from D, we draw a uniformly random string in x ∈ [m]d, and b is the result of a query for the value of f(y) for a uniformly random y ∈ B−1(x). From Lemma 6.9, we can take S to be the set of (k √ d/τ2)-way products of rd indicator functions. It follows that |S| = ( rd k √ d/τ2 ) = exp(Õ(k √ d/τ2)).\nProposition 6.11. Algorithm 2 accepts all functions ε1-close to k-monotone functions, and rejects all functions ε2-far from k-monotone, when ε2 > 3ε1 (with probability at least 2/3). Its query complexity is exp(Õ(k √ d/(ε2 − 3ε1)2)).\nProof. By a union bound, we have that with probability at least 8/10 both Step 5 and Step 4 succeed. We hereafter condition on this.\nCompleteness. Suppose f is ε1-close to k-monotone. Lemma 6.1 and the triangle inequality imply that there is a k-monotone m-block function g∗ such that dist(f, g∗) ≤ ε1 + α/6. The agnostic learning algorithm thus returns a hypothesis h such that dist(f, h) ≤ ε1 + α/4. The algorithm estimates this closeness to within α/7, so the estimate obtained in Step 5 is at most ε1 + ε/4 + ε/7 < ε1 + 5α/12 and the algorithm does not reject in this step. By the triangle inequality, h is (2ε1 + 5α/12)-close to k-monotone, and the algorithm will accept. There is no estimation error here, since no queries to f are required.\nSoundness. Now suppose f is ε2-far from k-monotone, where ε2 = 3ε1 + α for some α > 0. Suppose the algorithm does not reject when estimating dist(f, h), where h is the hypothesis returned by the agnostic learning algorithm. Then dist(f, h) ≤ ε1+5α/12+α/7 < ε1+7α/12. By the triangle inequality, if t is a k-monotone function, dist(h, t) ≥ dist(f, t) − dist(f, h) > ε2 − (ε1 + 7α/12) = 2ε1 + 5α/12. The algorithm will thus reject in the final step.\nQuery complexity. The query complexity of the algorithm is dominated by the query complexity of the agnostic learning algorithm, which is exp(Õ(k √ d/α2)) = exp(Õ ( k √ d/(ε2 − 3ε1)2 ) ).\n7 Tolerant testing and applications to L1-testing\nWe now show how our techniques can be applied to solve an open problem on L1 tolerant testing of monotonicity, asked at the Sublinear Algorithms Workshop 2016 [Sub16].\nWe start by describing a reduction lemma from L1 distance to monotonicity of functions in [0, 1]X to Hamming distance to monotonicity of functions in {0, 1}X×[0,1] (that is, “trading the range for a dimension”). We note that this idea appears in Berman et al.[BRY14, Lemmata 2.1 and 2.3], although formulated in a slightly different way. For convenience and completeness, we state and prove here the version we shall use.\nIn what follows, we let X be a discrete partially ordered domain equipped with a measure µ,10 that is a tuple (X , , µ); and for a set Y ⊆ R we denote by M(X→Y) ⊆ YX the set of monotone functions from X to Y.\nDefinition 7.1 (Analogue of [BRY14, Definition 2.1]). For a function f : X → [0, 1], the threshold function T ◦ f : X × [0, 1] → {0, 1} is defined by\nT ◦ f(x, t) = 1{f(x)≥1−t} = { 1 if f(x) ≥ 1− t 0 otherwise.\nThe next fact is immediate from this definition:\nFact 7.2. For any f : X → [0, 1], it is the case that for every x ∈ X\nf(x) =\n∫ 1\n0 T ◦ f(x, t)dt.\nMoreover, f ∈ M(X→[0,1]) if, and only if, T ◦ f ∈ M(X×[0,1]→{0,1}).\nWe begin by the following characterization, which is immediately obtained from a corresponding theorem of Berman et al.; before stating a slightly modified version that we shall rely upon. For completeness, the proof of the former can be found in Appendix C.\nProposition 7.3 (Analogue of [BRY14, Lemma 2.1]). For any f : X → [0, 1],\nL1 ( f,M(X→[0,1]) ) = L1 ( T ◦ f,M(X×[0,1]→{0,1}) ) = dist ( T ◦ f,M(X×[0,1]→{0,1}) )\nProposition 7.4 (Rounding and Range-Dimension Tradeoff). For any f : X → [0, 1] and parameter m ≥ 1, let Rm def= { 1m , 2m , . . . , 1}. We define the m-rounding of f as Φm ◦ f : X → Rm by\nΦm ◦ f(x) = ⌈mf(x)⌉\nm , x ∈ X .\nThen we have\n(i) ∣∣∣L1 ( f,M(X→[0,1]) ) − L1 ( Φm ◦ f,M(X→Rm) )∣∣∣ ≤ 1m ;\n(ii) L1 ( Φm ◦ f,M(X→Rm) ) = dist ( T ◦Φm ◦ f ,M(X×Rm→{0,1}) ) .\n10We will only require that (X , µ) be a measurable space with finite measure, that is µ(X ) < ∞, and shall only hereafter concern ourselves with measurable functions.\nProof of Proposition 7.4. Fix any m ≥ 1. We start the proof of item (i) by the simple observation that if f ∈ M(X→[0,1]), then Φm ◦ f ∈ M(X→Rm) ⊆ M(X→[0,1]), that is rounding preserves monotonicity; and that Φm ◦ g = g for all g : X → Rm. This, along with the fact that for all f : X → [0, 1]\nL1(f,Φm ◦ f) = 1\nµ(X )\n∫\nX µ(dx) |Φm ◦ f(x)− f(x)|︸ ︷︷ ︸\n≤1/m\n≤ 1 m\nimplies by the triangle inequality, for any g ∈ M(X→Rm) ⊆ M(X→[0,1]), that L1 ( f,M(X→[0,1]) ) ≤ L1(f, g) ≤ 1\nm +L1(g,Φm ◦ g) + L1(Φm ◦ f,Φm ◦ g) =\n1\nm + 0+L1(Φm ◦ f, g) .\nTaking g ∈ M(X→Rm) that achieves L1(Φm ◦ f, g) = L1 ( Φm ◦ f,M(X→Rm) ) , we get\nL1 ( f,M(X→[0,1]) ) ≤ 1\nm + L1\n( Φm ◦ f,M(X→Rm) ) .\nFor the other direction, we first note that for any two functions f, g : X → [0, 1], it is the case that L1(f, g) ≥ L1(Φm ◦ f,Φm ◦ g)− 1/m (which is immediate from the definition of the rounding operator), and taking g to be the closest monotone function to f this readily yields\nL1 ( f,M(X→[0,1]) ) ≥ L1(Φm ◦ f,Φm ◦ g)− 1\nm ≥ L1\n( Φm ◦ f,M(X→Rm) ) − 1\nm .\nFinally, the proof of the second part, item (i), is identical to that of Proposition 7.3, replacing the Lebesgue measure on [0, 1] by the counting measure on Rm. (So that integrals over [0, 1] become sums over Rm, normalized by |Rm| = m.)\nGiven Proposition 7.4, it is now easy to apply the results of Section 6 to obtain a tolerant L1 tester for monotonicity of functions f : [n]d → [0, 1]. Indeed, given parameters 0 < ε1 < ε2, one can set the rounding parameter m to ⌈4/(ε2 − ε1)⌉; and from query access to f : [n]d → [0, 1], simulate query access to Φm ◦ f and therefore to g def= T ◦ Φm ◦ f : [n]d × Rm → {0, 1}. By Proposition 7.4 and our choice of m, in order to distinguish\nL1 ( f,M(X→[0,1]) ) ≤ ε1 vs. L1 ( f,M(X→[0,1]) ) ≥ ε2\nit is enough to distinguish\ndist ( g,M(X×Rm→{0,1}) ) ≤ ε1 + 1\nm vs. dist\n( g,M(X×Rm→{0,1}) ) ≥ ε2 − 1\nm .\nBy our choice of m, we also have ( ε2 − 1m ) − ( ε1 + 1 m ) ≥ ε2−ε12 .\nThe last step is to observe that one can view equivalently g as a function g : [n]d× [m] → {0, 1}; by Proposition 7.4 and our choice of m, so that the algorithms of Theorem 1.7 apply.\nTheorem 1.9. There exists a non-adaptive tolerant L1-tester for monotonicity of functions f : [n] d → {0, 1} with query complexity\n• Õ (\n1 (ε2−ε1)2\n( 5d\nε2−ε1\n)d) , for any 0 ≤ ε1 < ε2 ≤ 1;\n• 2Õ( √ d/(ε2−3ε1)2), for any 0 ≤ 3ε1 < ε2 ≤ 1.\nAcknowledgments. We would like to thank Eric Blais for helpful remarks on an earlier version of this paper, and an anonymous reviewer for very detailed and insightful comments."
    }, {
      "heading" : "A Previous work on monotonicity testing",
      "text" : "In this appendix, we summarize the state-of-the-art on monotonicity testing. We observe that this question has been considered for functions over various domains (e.g. hypergrids, hypercubes and general posets) and ranges (notably Boolean range {0, 1} and unbounded range N); as hypergrids and hypercubes are arguably the domains that have received the most attention in the literature, we will in this overview restrict ourselves on work on these, and refer readers to [FLN+02, BGJ+09] for other various posets. We will also focus on the Boolean range {0, 1}, which is most relevant to our work, and briefly mention the best known results (which are also tight) for unbounded range N. In the end of this section, we include known results for tolerant monotonicity testing.\nBefore we go over those results, we recall some notation: namely, testers can make adaptive (a.) or non-adaptive (n.a.) queries and have 1-sided (1.s.) or 2-sided (2.s.) error. The best one could hope for would then be to obtain 1-sided non-adaptive upper bound, complemented with 2-sided adaptive lower bounds. We note all testers included in below except tolerant testers are 1-sided (almost all of them are non-adaptive) algorithms.\nHypercubes with Boolean Range. The problem of monotonicity testing is introduced by Goldreich et al. [GGL+00] for functions f : {0, 1}d → {0, 1}. [GGL+00] present a simple “edge tester” with query complexity O(d/ε). A tester with O(d7/8/ε3/2) queries, the first improvement in terms of the dependence on d and the first to “break” the linear barrier, was presented by Chakrabarty and Seshadhri [CS13a], further improved to Õ(d5/6/ε4) by Chen et al. [CST14]. Recently, a Õ( √ d/ε2) upper bound was established by Khot et al. [KMS15]. All these upper bounds are obtained for 1-sided, non-adaptive testers.\nFor 1-sided non-adaptive testers, Fischer et al. [FLN+02] showed an Ω( √ d) lower bound. For 2- sided non-adaptive testers, Chen et al. [CST14] obtained an Ω̃(d1/5) lower bound, further improved by Chen et al. [CDST15]) to Ω(d1/2−c) (for any constant c > 0). All these lower bounds applying to non-adaptive testers, they only imply an Ω(log d) lower bound for adaptive ones. Recently, Belovs and Blais [BB16] showed an Ω(d1/4) lower bound for 2-sided adaptive testers, i.e. an exponential improvement over the previous bounds. All mentioned lower bounds hold for constant ε > 0, and are summarized in Table 3.\nHypergrids with Boolean Range. We remark that most known previous upper bounds for testing monotonicity over hypergrids are for unbounded range, which we will be the focus of the next section. Instead, we only mention here the case of Boolean range, giving in each setting the current best known results. For testing monotonicity over the line with Boolean range (i.e. d = 1 case), both a 1-sided non-adaptive O(1/ε) upper bound and a 2-sided adaptive Ω(1/ε) lower bound are known (both of them being folklore). For d = 2, Berman et al. [BRY14] showed a tight bound of Θ((log 1/ε)/ε) for 1-sided non-adaptive testers. Interestingly, they also prove that “adaptivity”\nhelps in the d = 2 case: that is, they establish a 1-sided tight adaptive O(1/ε) upper bound which beats Ω(log 1/ε)/ε) lower bound for 1-sided non-adaptive testers. For general d, Berman et al. [BRY14] give both a 1-sided non-adaptive tester with query complexity O(dε log d ε ), and a 1-sided\nadaptive tester with query complexity O ( d2d logd−1 1ε + d2 log d ε ) . The best known results can be found in Table 4.\nUnbounded Range. For unbounded range, tight upper and lower bounds are known for both hypergrid and hypercube domains. Chakrabarty and Seshadhri [CS14] describe a 1-sided nonadaptive tester with O(d log n/ε) queries for the hypergrid [n]d. Later, they show that O(d log n/ε) is essentially optimal even for 2-sided adaptive tester [CS13b]. For the hypercube, [CS14] give a 1-sided non-adaptive tester making O(n/ε) queries, and a matching 2-sided adaptive lower bound is proved by Joshua Brody (mentioned as private communication in [CS13b]). We refer readers to [CS14, CS13b] for overviews on previous results for testing monotonicity over the hypercube and hypergrid with unbounded range. The best known results are summarized in Table 5.\nTolerant Testing. To the best of our knowledge, prior to our work tolerant testers for monotonicity for Boolean functions over the hypergrid were only known for dimension d ∈ {1, 2}. Specifically, an O( ε2\n(ε2−ε1)2 )-query upper bound is known for d = 1, while an Õ( 1 (ε2−ε1)4 )-query one is known for\nd = 2 [BRY14, FR10]."
    }, {
      "heading" : "B Structural results",
      "text" : "In this section, we will prove that the distance to k-monotonicity of a Boolean function f can be expressed in a combinatorial way – which does not require measuring the distance between f and the closest k-monotone function to f . We will prove this for a general finite poset domain buiding up on the ideas of [FLN+02]. In the rest of this section, we denote by P = (V, ) an arbitrary poset, the underlying domain of the function.\nDefinition B.1. We define the forbidden pattern K10 as the sequence of alternating bits K10 = (b1, b2, · · · , bk, bk+1) of length (k+ 1) , where b1 = 1 and all the bits in the sequence alternate, i.e., bi 6= bi+1 ∀i ∈ [k].\nA function f : P → {0, 1} is k-monotone only if it avoids K10. That is, for any x1 ≺ x2 ≺ . . . ≺ xk+1 ∈ P we have f(xi) 6= K10(i) for some i ∈ [k + 1].\nUsing insights from the literature on monotonicity testing, we show that functions far from kmonotonicity have a large matching of “violated hyperedges” in the “violation hypergraph” which we define shortly. Let us recall the definition of “violation graph”which has been extremely useful with monotonicity testing as seen in [EKK+00, PRR06, HK08, ACCL07, FLN+02].\nDefinition B.2 (Violation graph). Given a function f : P → {0, 1}, the violation graph of f is defined as Gviol(f) = (P, E(Gviol)) where (x, y) ∈ E(Gviol) if x, y ∈ P form a monotonicity violating pair in f – that is x y but f(x) > f(y).\nThe following theorem about violation graphs has been extremely useful in monotonicity testing literature.\nTheorem B.3. Let f : P → {0, 1} be a function that is ε-far from monotone. Then, there exists a matching of edges in the violation graph for f of size at least ε |P| /2.\nNow let us define a generalization of this concept, the violation hypergraph.\nDefinition B.4 (Violation hypergraph). Given a function f : P → {0, 1}, the violation hypergraph of f is Hviol(f) = (P, E(Hviol)) where (x1, x2, · · · , xk) ∈ E(Hviol) if the ordered (k + 1)-tuple x1 < x2 < . . . < xk+1 (which is a (k + 1)-uniform hyperedge) forms a violation to k-monotonicity in f .\nNow, we state the main theorem that we intend to prove in this section. This theorem offers an alternate characterization of distance to k-monotonicity that we seek. We recall that a set of edges forms a matching in a hypergraph if any pair of hyperedges is pairwise disjoint.\nTheorem B.5. Let f : P → {0, 1} be function that is ε-far from k-monotone. Then, there exists a matching of (k + 1)-uniform hyperedges of size at least ε|P|k+1 in the violation hypergraph.\nTo prove this theorem we first exploit the key notion of extendability which we define below. Later we will show that k-monotone functions are extendable.\nDefinition B.6 (Extendability). A property of Boolean functions is said to be extendable over a poset domain if the following holds for any set X ⊆ P: given a function f : X → {0, 1} which has the property (on X), it is possible to define a function g : P → {0, 1} such that g(x) = f(x),∀x ∈ X and g has the property.\nIn other words, a property is extendable if for any subset X ⊆ P, given a function defined over the set X which respects the property, it is possible to fill in values outside X such that the new function obtained continues to respect the property. Next, we show that k-monotonicity is an extendable property:\nLemma B.7. k-monotonicity is an extendable property.\nProof of Lemma B.7. Consider X ⊆ P and some function f : X → {0, 1} which is k-monotone over X. That is, for any x1 < x2 < . . . < xk+1 ∈ X there exists i ∈ [k + 1] such that f(xi) 6= K10[i]. Take a minimal point v ∈ P \\X. That is, for any other point v′ ∈ P \\X either v ≤ v′ or v and v′ are not comparable. We will use the following result:\nClaim B.8. There exists a function g : X ∪ {v} → {0, 1} such that g(x) = f(x) for all x ∈ X, and g respects k-monotonicity over its domain.\nBefore proving this claim, we show how it implies Lemma B.7. Namely, starting with any function f : X → {0, 1} which is k-monotone on its domain X, we just keep applying the Claim B.8 inductively until we get a function defined over the entire poset which respects k-monotonicity.\nProof of Claim B.8. We will show this by contradiction. Suppose there is no good assignment available for g(v), that is that both the choices g(v) = 0 and g(v) = 1 lead to a violation to kmonotonicity in g. Consider the choice g(v) = 0. Since this results in a violation to k-monotonicity, we know that there is a path P0 = (x1 ≺ x2 ≺ . . . ≺ xk+1) which is a violation to k-monotonicity. It is clear that v ∈ P0; let i be such that xi = v. Similarly, there is path P1 = (y1 ≺ y2 ≺ . . . ≺ yk+1) corresponding to g(v) = 1 which also contains the forbidden pattern, and some j such that yj = v. And thus, g(xt) = g(yt), for all t ∈ [k+1] (as both of the paths indexed by x and y form a violation to k-monotonicity). By the above discussion 2 paths, P0 and P1, meet at v. We will see that one of the two paths P ′0 = (x1 ≺ x2 ≺ . . . < xi−1 ≺ yi ≺ yi+1 ≺ . . . ≺ yk+1) or P ′1 = (y1 ≺ y2 ≺ . . . < yj−1 ≺ xj ≺ xj+1 ≺ . . . ≺ xk+1) is already a violation to k-monotonicity in f . To see this, let us begin by recalling that we let v be the ith vertex on P0 and the j\nth vertex on P1. Now it is clear that i 6= j. Without loss of generality, suppose i < j. In this case, the evaluations of f along path P ′1 form the forbidden pattern. This is because the function values alternate along the segment (y1 ≺ y2 ≺ . . . ≺ yj−1). Also, the function values alternate along the segment (xi ≺ xi+1 ≺ xi+2 ≺ . . . ≺ xk+1). And finally note that since f(yj−1) 6= f(yj) and f(yj) = f(xj) we get that f(yj−1) 6= f(xj) as well. So, the path P ′1 indeed contains a violation to k-monotonicity as claimed. The other case, i > j, is analogous. Hence the claim follows.\nIn the next lemma, we show that there is a nice characterization of distance to k-monotonicity in terms of the size of the minimum vertex cover of the violation hypergraph.11\n11Recall that a vertex cover in a hypergraph is just a set of vertices such that every hyperedge contains at least one of the vertices from this set.\nLemma B.9. Let Mk denote the set of k-monotone functions over the poset P, and f : P → {0, 1}. Then dist(f,Mk) = εf if, and only if, the size of the minimum vertex cover in Hviol(f) is εf |P|.\nProof of Lemma B.9. We establish separately the two inequalities.\nClaim B.10. dist(f,Mk) ≥ |V Cmin(Hviol)|\nProof. Suppose the distance to k-monotonicity is εf , and let g be a k-monotone achieving it, so that dist(f, g) = εf . Define X = { x ∈ P : f(x) 6= g(x) } (thus, |X| = εf |P|). Let us consider the violation hypergraph for f given as Hviol(f) = (P, E(Hviol)). Now, delete vertices in X and the hyperedges containing any vertex v ∈ X from this hypergraph. Because X is the smallest set of vertices changing values at which gives a k-monotone function, it follows that every hyperedge in E(Hviol) must contain a vertex in X. Thus, X indeed forms a vertex cover in Hviol(f).\nClaim B.11. dist(f,Mk) ≤ |V Cmin(Hviol)|\nProof. Suppose the minimum vertex cover in the violation hypergraph has size εf |P|. We will show that the distance of the function to k-monotonicity is εf . To see this, let C ⊆ P be the smallest vertex cover of the violation hypergraph of the said size. Observe that deleting C from Hviol(f) removes all the hyperedges, and therefore that the function f restricted to X = P \\ C is k-monotone. And by the extendability of k-monotone functions established in Lemma B.7, it follows that the function can be extended to the rest of the domain (by providing values in the cover C) such that it keeps respecting k-monotonicity. Thus, the distance to k-monotonicity is at most |C| / |P|.\nHaving characterized distance to k-monotonicity as the size of the smallest vertex cover in the violation graph, we are ready to establish Theorem B.5. To do so, we will require the following standard fact:\nFact B.12. Let G = (V,E) be a t-uniform hypergraph. Let M be the maximum matching in G. Then, |M | ≤ V Cmin(G) ≤ t |M |\nProof of Theorem B.5. By Lemma B.9, we know that the violation hypergraph, Hviol(f) has a minimum vertex cover of size at least εf |P|. And by Fact B.12, it is seen that it contains a matching of t-uniform hyperedges of size at least\nεf t |P|."
    }, {
      "heading" : "C Omitted proofs",
      "text" : "Proof of Lemma 5.2. The first part of the theorem is straightforward (by contrapositive, if at least one of the two sequences is not non-increasing then we can find a violation of 2-monotonicity). We thus turn to the second part, and show the contrapositive; for this purpose, we require the following result:\nClaim C.1. If f : [n]2 → {0, 1} is a 2-column-wise monotone function such that (i) f(1, j) = f(n, j) = 0 for all j ∈ [n] and (ii) both (\n¯ ∂fj)j∈[n], ( ¯ ∂hj)j∈[n] ⊆ [n] are non-increasing, then f is\n2-monotone.\nProof. By contradiction, suppose there exists a 2-column-wise monotone function f satisfying (i) and (ii), which is not 2-monotone. This last point implies there exists a triple of comparable elements x = (ix, jx) ≺ y = (iy, jy) ≺ z = (iz , jz) constituting a violation, i.e. such that (f(x), f(y), f(z)) = (1, 0, 1). Moreover, since (i) holds we must have 1 < ix ≤ iy ≤ iz < n; more precisely, 1 ≤\n¯ ∂fjx < ix ≤ iy ≤ iz < ∂̄fjz ≤ n. As x ≺ y ≺ z, we have jx ≤ jy ≤ jz, which\nby the non-increasing assumption (ii) implies that ¯ ∂fjx ≥ ¯∂fjy and ∂̄fjy ≥ ∂̄fjz . But this is not possible, as altogether this leads to ¯ ∂fjy < iy < ∂̄fjy , i.e. f(y) = 1.\nAssume both sequences ( ¯ ∂fj)j∈[n], ( ¯ ∂hj)j∈[n] ⊆ [n] are ε2 -close to non-increasing, and let L,H ⊂ [n] (respectively) be the set of indices where the two sequences need to be changed in order to become non-increasing. By assumption, |L| , |H| ≤ εn2 , so |L ∪H| ≤ εn. But to “fix” a value of ( ¯ ∂fj)j∈[n] or (∂̄fj)j∈[n] requires to change the values of the function f inside a single column – and this can be done preserving its 2-column-wise-monotonicity, so that changing the value of f on at most n points is enough. It follows that making both (\n¯ ∂fj)j∈[n] and (∂̄fj)j∈[n] non-increasing\nrequires to change f on at most εn2 points, and with Claim C.1 this results in a function which is 2-monotone. Thus, f is ε-close to 2-monotone.\nProof of Lemma 5.3. Recall that we aim at establishing the following:\ndist ( f,M(2)2 ) ≤ L1(∂̄f,M(1)) + L1(\n¯ ∂f,M(1)) (6)\nFor notational convenience, we will view in this proof the sequences ( ¯ ∂f)j , (∂̄f)j) as functions ¯ ∂f, ∂̄f : [n] → [n]. Let ℓ, h : [n] → [n] (for “low” and ”high,” respectively) be monotone functions achieving L1(\n¯ ∂f,M(1)) and L1(∂̄f,M(1)), respectively.\n• As ¯ ∂f(j) ≤ ∂̄f(j) for all j ∈ [n], we will assume ℓ(j) ≤ h(j) for all j. Otherwise, one can\nconsider instead the functions ℓ′ = min(ℓ, h) and h′ = max(ℓ, h): both will still be monotone (non-increasing), and by construction\n∣∣ℓ′(j) − ¯ ∂f(j) ∣∣+ ∣∣∣h′(j)− ∂̄f(j) ∣∣∣ ≤ |ℓ(j) − ¯ ∂f(j)|+ ∣∣∣h(j)− ∂̄f(j) ∣∣∣\nfor all j ∈ [n], so that L1(∂̄f, ℓ′) + L1( ¯ ∂f, h′) ≤ L1(∂̄f, ℓ) + L1( ¯ ∂f, h).\n• From ℓ and h, we can define a 2-column-wise monotone function g : [n]2 → [n] such that\n¯ ∂g = ℓ and ∂̄g = h: that is,\ng(i, j) =    0 if i ≥ h(j) 1 if ℓ(j) < i < h(j)\n0 if i ≤ ℓ(j)\nfor (i, j) ∈ [n]2. It is clear that g is 2-column-wise monotone with g(1, j) = g(n, j) = 0 for all j ∈ [n]; since by construction\n¯ ∂g, ∂̄g are non-decreasing, we can invoke Claim C.1 to conclude g is 2-monotone. It\nremains to bound the distance between f and g: writing ∆j ∈ {0, . . . , n} for the number of points\non which f and g differ in the j-th column, we have\ndist ( f,M(2)2 ) ≤ dist(f, g) = 1\nn2\nn∑\nj=1\n∆j ≤ 1\nn2\nn∑\nj=1\n( |ℓ(j) −\n¯ ∂f(j)|+\n∣∣∣h(j) − ∂̄f(j) ∣∣∣ )\n= 1\nn2\nn∑\nj=1\n|ℓ(j)− ¯ ∂f(j)|+ 1 n2\nn∑\nj=1\n∣∣∣h(j) − ∂̄f(j) ∣∣∣ = L1(\n¯ ∂f, ℓ) + L1\n( ∂̄f, h )\n≤ L1( ¯ ∂f,M(1)) + L1(∂̄f,M(1))\nwhich concludes the proof.\nProof of Proposition 7.3. We write ν def = µ× Leb[0,1] for the product measure on X × [0, 1] induced by µ and the Lebesgue measure on [0, 1]; so that ν(X × [0, 1]) = µ(X ) · 1 = µ(X ). For any fixed t ∈ [0, 1], let gt ∈ M(X→{0,1}) be any function achieving L1(T ◦ f(·, t), gt) =\nL1 ( T ◦ f(·, t),M(X→{0,1}) ) , and define g ∈ [0, 1]X by g′(x) = ∫ 1 0 dtgt(x) for all x ∈ X : note that g is then monotone by construction.12 Moreover, choose h ∈ M(X×[0,1]→{0,1}) as a function achieving L1(T ◦ f, h) = L1 ( T ◦ f,M(X×[0,1]→{0,1}) ) . Then we have\nL1 ( f,M(X→[0,1]) ) ≤ L1 ( f, g′ ) = 1\nµ(X )\n∫\nX µ(dx)\n∣∣∣∣ ∫ 1\n0 dt(T ◦ f(x, t)− gt(x))\n∣∣∣∣\n≤ 1 µ(X )\n∫\nX µ(dx)\n∫ 1\n0 dt |T ◦ f(x, t)− gt(x)|\n=\n∫ 1\n0 dt\n( 1\nµ(X )\n∫\nX µ(dx) |T ◦ f(x, t)− gt(x)|\n) = ∫ 1\n0 dtL1(T ◦ f(·, t), gt)\n≤ ∫ 1\n0 dtL1(T ◦ f(·, t), h(·, t)) =\n∫ 1\n0 dt\n( 1\nµ(X )\n∫\nX µ(dx) |T ◦ f(x, t)− h(x, t)|\n)\n= 1\nν(X × [0, 1])\n∫\nX×[0,1] ν(dx, dt) |T ◦ f(x, t)− h(x, t)|\n= L1(T ◦ f, h) = L1 ( T ◦ f,M(X×[0,1]→{0,1}) )\nwhere we applied Fact 7.2 (and the definition of g′ = ∫ 1 0 gt) for the first equality, and for the third inequality the fact that h induces (for every fixed t ∈ [0, 1]) a monotone function h(·, t) ∈ M(X→{0,1}): so that L1(T ◦ f(·, t), gt) ≤ L1(T ◦ f(·, t), h(·, t)) for all t.\nFor the other direction of the inequality, fix any f : X → [0, 1], and let g ∈ M(X→[0,1]) be (any) 12Additionally, since we restrict ourselves to finite X , there are only finitely many distinct functions T ◦ f(·, t) (for\nt ∈ [0, 1], and therefore only finitely many distinct functions gt.\nfunction achieving L1(f, g) = L1 ( f,M(X→[0,1]) ) . We can write, unrolling the definitions,\nL1 ( f,M(X→[0,1]) ) = 1\nµ(X )\n∫\nX µ(dx)|f(x)− g(x)|\n= 1\nµ(X )\n∫\nX µ(dx)\n∣∣∣∣ ∫ 1\n0 dt(T ◦ f(x, t)− T ◦ g(x, t))\n∣∣∣∣\n= 1\nµ(X )\n∫\nX µ(dx)\n∣∣∣∣ ∫ 1\n0 dt(T ◦ f(x, t)− T ◦ g(x, t))\n∣∣∣∣\n= 1\nµ(X )\n∫\nX µ(dx)\n( ∫ 1\n0 dt(T ◦ f(x, t)− T ◦ g(x, t))1{f(x)>g(x)}\n+ (T ◦ g(x, t) − T ◦ f(x, t))1{g(x)>f(x)} )\n= 1\nµ(X )\n∫\nX\n∫ 1\n0 dtµ(dx)\n( (T ◦ f(x, t)− T ◦ g(x, t))1{f(x)>g(x)}\n+ (T ◦ g(x, t) − T ◦ f(x, t))1{g(x)>f(x)} )\n= 1\nν(X × [0, 1])\n∫\nX×[0,1] ν(dx, dt) |T ◦ f(x, t)− T ◦ g(x, t)| = L1(T ◦ f, T ◦ g)\n≥ L1 ( T ◦ f,M(X×[0,1]→{0,1}) )\nwhere we applied Fact 7.2 for the second equality, the definition of L1 distance for the second-tolast; and to handle the absolute values we used the fact that |a− b| = (a− b)1{a>b}+(b−a)1{a>b}, along with the observation that T ◦ f(x, t) > T ◦ g(x, t) can only hold if f(x) > g(x). Finally, we have L1(T ◦ f, T ◦ g) ≥ L1 ( T ◦ f,M(X×[0,1]→{0,1}) ) since T ◦ g ∈ M(X×[0,1]→{0,1}), yielding the desired claim. Finally, the fact that L1 ( T ◦ f,M(X×[0,1]→{0,1}) ) = dist ( T ◦ f,M(X×[0,1]→{0,1}) ) is immediate from the Boolean range, as |a− b| = 1{a6=b} for any a.b ∈ {0, 1}."
    } ],
    "references" : [ {
      "title" : "Information theory in property testing and monotonicity testing in higher dimension",
      "author" : [ "Nir Ailon", "Bernard Chazelle" ],
      "venue" : "Inf. Comput.,",
      "citeRegEx" : "Ailon and Chazelle.,? \\Q2006\\E",
      "shortCiteRegEx" : "Ailon and Chazelle.",
      "year" : 2006
    }, {
      "title" : "Estimating the distance to a monotone function",
      "author" : [ "Nir Ailon", "Bernard Chazelle", "Seshadhri Comandur", "Ding Liu" ],
      "venue" : "Random Struct. Algorithms,",
      "citeRegEx" : "Ailon et al\\.,? \\Q2007\\E",
      "shortCiteRegEx" : "Ailon et al\\.",
      "year" : 2007
    }, {
      "title" : "A superpolynomial lower bound for a circuit computing the Clique function with at most (1/6) log log n negation gates",
      "author" : [ "Kazuyuki Amano", "Akira Maruoka" ],
      "venue" : "SIAM Journal on Computing,",
      "citeRegEx" : "Amano and Maruoka.,? \\Q2005\\E",
      "shortCiteRegEx" : "Amano and Maruoka.",
      "year" : 2005
    }, {
      "title" : "Queries and concept learning",
      "author" : [ "Dana Angluin" ],
      "venue" : "Machine Learning,",
      "citeRegEx" : "Angluin.,? \\Q1987\\E",
      "shortCiteRegEx" : "Angluin.",
      "year" : 1987
    }, {
      "title" : "A polynomial lower bound for testing monotonicity",
      "author" : [ "Aleksandrs Belovs", "Eric Blais" ],
      "venue" : "In STOC,",
      "citeRegEx" : "Belovs and Blais.,? \\Q2016\\E",
      "shortCiteRegEx" : "Belovs and Blais.",
      "year" : 2016
    }, {
      "title" : "Active property testing",
      "author" : [ "Maria-Florina Balcan", "Eric Blais", "Avrim Blum", "Liu Yang" ],
      "venue" : "In FOCS,",
      "citeRegEx" : "Balcan et al\\.,? \\Q2012\\E",
      "shortCiteRegEx" : "Balcan et al\\.",
      "year" : 2012
    }, {
      "title" : "Property testing lower bounds via communication complexity",
      "author" : [ "Eric Blais", "Joshua Brody", "Kevin Matulef" ],
      "venue" : "Computational Complexity,",
      "citeRegEx" : "Blais et al\\.,? \\Q2012\\E",
      "shortCiteRegEx" : "Blais et al\\.",
      "year" : 2012
    }, {
      "title" : "Monotonicity testing and shortest-path routing on the cube",
      "author" : [ "Jop Briët", "Sourav Chakraborty", "David García-Soriano", "Arie Matsliah" ],
      "venue" : "Combinatorica, 32(1):35–53,",
      "citeRegEx" : "Briët et al\\.,? \\Q2012\\E",
      "shortCiteRegEx" : "Briët et al\\.",
      "year" : 2012
    }, {
      "title" : "Learning circuits with few negations. In APPROX-RANDOM, volume 40 of LIPIcs, pages 512–527",
      "author" : [ "Eric Blais", "Clément L. Canonne", "Igor Carboni Oliveira", "Rocco A. Servedio", "LiYang Tan" ],
      "venue" : "Schloss Dagstuhl - Leibniz-Zentrum fuer Informatik,",
      "citeRegEx" : "Blais et al\\.,? \\Q2015\\E",
      "shortCiteRegEx" : "Blais et al\\.",
      "year" : 2015
    }, {
      "title" : "Transitive-closure spanners",
      "author" : [ "Arnab Bhattacharyya", "Elena Grigorescu", "Kyomin Jung", "Sofya Raskhodnikova", "David P. Woodruff" ],
      "venue" : "In SODA,",
      "citeRegEx" : "Bhattacharyya et al\\.,? \\Q2009\\E",
      "shortCiteRegEx" : "Bhattacharyya et al\\.",
      "year" : 2009
    }, {
      "title" : "Fast approximate PCPs for multidimensional bin-packing problems",
      "author" : [ "Tŭgkan Batu", "Ronitt Rubinfeld", "Patrick White" ],
      "venue" : "Inf. Comput.,",
      "citeRegEx" : "Batu et al\\.,? \\Q2005\\E",
      "shortCiteRegEx" : "Batu et al\\.",
      "year" : 2005
    }, {
      "title" : "Lp-testing. In STOC, pages 164–173",
      "author" : [ "Piotr Berman", "Sofya Raskhodnikova", "Grigory Yaroslavtsev" ],
      "venue" : null,
      "citeRegEx" : "Berman et al\\.,? \\Q2014\\E",
      "shortCiteRegEx" : "Berman et al\\.",
      "year" : 2014
    }, {
      "title" : "On the Fourier spectrum of monotone functions",
      "author" : [ "Nader H. Bshouty", "Christino Tamon" ],
      "venue" : "J. ACM,",
      "citeRegEx" : "Bshouty and Tamon.,? \\Q1996\\E",
      "shortCiteRegEx" : "Bshouty and Tamon.",
      "year" : 1996
    }, {
      "title" : "Boolean function monotonicity testing requires (almost) n1/2 non-adaptive queries",
      "author" : [ "Xi Chen", "Anindya De", "Rocco A. Servedio", "Li-Yang Tan" ],
      "venue" : "In STOC,",
      "citeRegEx" : "Chen et al\\.,? \\Q2015\\E",
      "shortCiteRegEx" : "Chen et al\\.",
      "year" : 2015
    }, {
      "title" : "Testing probability distributions underlying aggregated data",
      "author" : [ "Clément L. Canonne", "Ronitt Rubinfeld" ],
      "venue" : "Lecture Notes in Computer Science,",
      "citeRegEx" : "Canonne and Rubinfeld.,? \\Q2014\\E",
      "shortCiteRegEx" : "Canonne and Rubinfeld.",
      "year" : 2014
    }, {
      "title" : "An o(n) monotonicity tester for boolean functions over the hypercube",
      "author" : [ "Deeparnab Chakrabarty", "C. Seshadhri" ],
      "venue" : "In STOC,",
      "citeRegEx" : "Chakrabarty and Seshadhri.,? \\Q2013\\E",
      "shortCiteRegEx" : "Chakrabarty and Seshadhri.",
      "year" : 2013
    }, {
      "title" : "Optimal bounds for monotonicity and Lipschitz testing over hypercubes and hypergrids",
      "author" : [ "Deeparnab Chakrabarty", "C. Seshadhri" ],
      "venue" : "In STOC,",
      "citeRegEx" : "Chakrabarty and Seshadhri.,? \\Q2013\\E",
      "shortCiteRegEx" : "Chakrabarty and Seshadhri.",
      "year" : 2013
    }, {
      "title" : "An optimal lower bound for monotonicity testing over hypergrids",
      "author" : [ "Deeparnab Chakrabarty", "C. Seshadhri" ],
      "venue" : "Theory of Computing,",
      "citeRegEx" : "Chakrabarty and Seshadhri.,? \\Q2014\\E",
      "shortCiteRegEx" : "Chakrabarty and Seshadhri.",
      "year" : 2014
    }, {
      "title" : "An o(n) Monotonicity Tester for Boolean Functions over the Hypercube",
      "author" : [ "Deeparnab Chakrabarty", "C. Seshadhri" ],
      "venue" : "SIAM J. Comput.,",
      "citeRegEx" : "Chakrabarty and Seshadhri.,? \\Q2016\\E",
      "shortCiteRegEx" : "Chakrabarty and Seshadhri.",
      "year" : 2016
    }, {
      "title" : "New algorithms and lower bounds for monotonicity testing",
      "author" : [ "Xi Chen", "Rocco A. Servedio", "Li-Yang Tan" ],
      "venue" : "In FOCS,",
      "citeRegEx" : "Chen et al\\.,? \\Q2014\\E",
      "shortCiteRegEx" : "Chen et al\\.",
      "year" : 2014
    }, {
      "title" : "Improved testing algorithms for monotonicity",
      "author" : [ "Yevgeniy Dodis", "Oded Goldreich", "Eric Lehman", "Sofya Raskhodnikova", "Dana Ron", "Alex Samorodnitsky" ],
      "venue" : "In RANDOMAPPROX,",
      "citeRegEx" : "Dodis et al\\.,? \\Q1999\\E",
      "shortCiteRegEx" : "Dodis et al\\.",
      "year" : 1999
    }, {
      "title" : "On the strength of comparisons in property testing",
      "author" : [ "Eldar Fischer" ],
      "venue" : "Inf. Comput.,",
      "citeRegEx" : "Fischer.,? \\Q2004\\E",
      "shortCiteRegEx" : "Fischer.",
      "year" : 2004
    }, {
      "title" : "Monotonicity testing over general poset domains",
      "author" : [ "Eldar Fischer", "Eric Lehman", "Ilan Newman", "Sofya Raskhodnikova", "Ronitt Rubinfeld", "Alex Samorodnitsky" ],
      "venue" : "In Proceedings on 34th Annual ACM Symposium on Theory of Computing, May 19-21,",
      "citeRegEx" : "Fischer et al\\.,? \\Q2002\\E",
      "shortCiteRegEx" : "Fischer et al\\.",
      "year" : 2002
    }, {
      "title" : "Approximating the distance to monotonicity in high dimensions",
      "author" : [ "Shahar Fattal", "Dana Ron" ],
      "venue" : "ACM Trans. Algorithms,",
      "citeRegEx" : "Fattal and Ron.,? \\Q2010\\E",
      "shortCiteRegEx" : "Fattal and Ron.",
      "year" : 2010
    }, {
      "title" : "Negation-limited formulas. In APPROX-RANDOM, volume 40 of LIPIcs, pages 850–866",
      "author" : [ "Siyao Guo", "Ilan Komargodski" ],
      "venue" : "Schloss Dagstuhl - Leibniz-Zentrum fuer Informatik,",
      "citeRegEx" : "Guo and Komargodski.,? \\Q2015\\E",
      "shortCiteRegEx" : "Guo and Komargodski.",
      "year" : 2015
    }, {
      "title" : "The power of negations in cryptography",
      "author" : [ "Siyao Guo", "Tal Malkin", "Igor Carboni Oliveira", "Alon Rosen" ],
      "venue" : "Lecture Notes in Computer Science,",
      "citeRegEx" : "Guo et al\\.,? \\Q2015\\E",
      "shortCiteRegEx" : "Guo et al\\.",
      "year" : 2015
    }, {
      "title" : "Testing monotonicity over graph products",
      "author" : [ "Shirley Halevy", "Eyal Kushilevitz" ],
      "venue" : "Random Struct. Algorithms,",
      "citeRegEx" : "Halevy and Kushilevitz.,? \\Q2008\\E",
      "shortCiteRegEx" : "Halevy and Kushilevitz.",
      "year" : 2008
    }, {
      "title" : "Agnostically learning halfspaces",
      "author" : [ "Adam Tauman Kalai", "Adam R. Klivans", "Yishay Mansour", "Rocco A. Servedio" ],
      "venue" : "SIAM J. Comput.,",
      "citeRegEx" : "Kalai et al\\.,? \\Q2008\\E",
      "shortCiteRegEx" : "Kalai et al\\.",
      "year" : 2008
    }, {
      "title" : "On monotonicity testing and Boolean isoperimetric type theorems. In FOCS, pages 52–58",
      "author" : [ "Subhash Khot", "Dor Minzer", "Muli Safra" ],
      "venue" : "IEEE Computer Society,",
      "citeRegEx" : "Khot et al\\.,? \\Q2015\\E",
      "shortCiteRegEx" : "Khot et al\\.",
      "year" : 2015
    }, {
      "title" : "Testing surface area",
      "author" : [ "Pravesh Kothari", "Amir Nayyeri", "Ryan O’Donnell", "Chenggang Wu" ],
      "venue" : "In SODA, pages 1204–1214",
      "citeRegEx" : "Kothari et al\\.,? \\Q2014\\E",
      "shortCiteRegEx" : "Kothari et al\\.",
      "year" : 2014
    }, {
      "title" : "Testing problems with sublearning sample complexity",
      "author" : [ "Michael J. Kearns", "Dana Ron" ],
      "venue" : "J. Comput. Syst. Sci.,",
      "citeRegEx" : "Kearns and Ron.,? \\Q2000\\E",
      "shortCiteRegEx" : "Kearns and Ron.",
      "year" : 2000
    }, {
      "title" : "Cryptographic limitations on learning Boolean formulae and finite automata",
      "author" : [ "Michael J. Kearns", "Leslie G. Valiant" ],
      "venue" : "J. ACM,",
      "citeRegEx" : "Kearns and Valiant.,? \\Q1994\\E",
      "shortCiteRegEx" : "Kearns and Valiant.",
      "year" : 1994
    }, {
      "title" : "Sensitivity conjecture and log-rank conjecture for functions with small alternating numbers",
      "author" : [ "Chengyu Lin", "Shengyu Zhang" ],
      "venue" : "CoRR, abs/1602.06627,",
      "citeRegEx" : "Lin and Zhang.,? \\Q2016\\E",
      "shortCiteRegEx" : "Lin and Zhang.",
      "year" : 2016
    }, {
      "title" : "On the inversion complexity of systems of functions",
      "author" : [ "A.A. Markov" ],
      "venue" : "Doklady Akademii Nauk SSSR,",
      "citeRegEx" : "Markov.,? \\Q1957\\E",
      "shortCiteRegEx" : "Markov.",
      "year" : 1957
    }, {
      "title" : "On the inversion complexity of a system of functions",
      "author" : [ "A.A. Markov" ],
      "venue" : "Journal of the ACM,",
      "citeRegEx" : "Markov.,? \\Q1958\\E",
      "shortCiteRegEx" : "Markov.",
      "year" : 1958
    }, {
      "title" : "Testing surface area with arbitrary accuracy",
      "author" : [ "Joe Neeman" ],
      "venue" : "In STOC, pages 393–397",
      "citeRegEx" : "Neeman.,? \\Q2014\\E",
      "shortCiteRegEx" : "Neeman.",
      "year" : 2014
    }, {
      "title" : "Analysis of Boolean Functions",
      "author" : [ "Ryan O’Donnell" ],
      "venue" : null,
      "citeRegEx" : "O.Donnell.,? \\Q2014\\E",
      "shortCiteRegEx" : "O.Donnell.",
      "year" : 2014
    }, {
      "title" : "Learning monotone decision trees in polynomial time",
      "author" : [ "Ryan O’Donnell", "Rocco A. Servedio" ],
      "venue" : "SIAM J. Comput.,",
      "citeRegEx" : "O.Donnell and Servedio.,? \\Q2007\\E",
      "shortCiteRegEx" : "O.Donnell and Servedio.",
      "year" : 2007
    }, {
      "title" : "KKL, Kruskal–Katona, and monotone nets. In FOCS, pages 725–734",
      "author" : [ "Ryan O’Donnell", "Karl Wimmer" ],
      "venue" : "IEEE Computer Society,",
      "citeRegEx" : "O.Donnell and Wimmer.,? \\Q2009\\E",
      "shortCiteRegEx" : "O.Donnell and Wimmer.",
      "year" : 2009
    }, {
      "title" : "Tolerant property testing and distance approximation",
      "author" : [ "Michal Parnas", "Dana Ron", "Ronitt Rubinfeld" ],
      "venue" : "Journal of Computer and System Sciences,",
      "citeRegEx" : "Parnas et al\\.,? \\Q2006\\E",
      "shortCiteRegEx" : "Parnas et al\\.",
      "year" : 2006
    }, {
      "title" : "Lower bounds on the monotone complexity of some Boolean functions",
      "author" : [ "Alexander A Razborov" ],
      "venue" : "In Doklady Akademii Nauk SSSR,",
      "citeRegEx" : "Razborov.,? \\Q1985\\E",
      "shortCiteRegEx" : "Razborov.",
      "year" : 1985
    }, {
      "title" : "Correlation bounds against monotone NC",
      "author" : [ "Benjamin Rossman" ],
      "venue" : "In Conference on Computational Complexity (CCC),",
      "citeRegEx" : "Rossman.,? \\Q2015\\E",
      "shortCiteRegEx" : "Rossman.",
      "year" : 2015
    }, {
      "title" : "Monotone circuits for matching require linear depth",
      "author" : [ "Ran Raz", "Avi Wigderson" ],
      "venue" : "J. ACM,",
      "citeRegEx" : "Raz and Wigderson.,? \\Q1992\\E",
      "shortCiteRegEx" : "Raz and Wigderson.",
      "year" : 1992
    }, {
      "title" : "On learning monotone DNF under product distributions",
      "author" : [ "Rocco A. Servedio" ],
      "venue" : "Inf. Comput.,",
      "citeRegEx" : "Servedio.,? \\Q2004\\E",
      "shortCiteRegEx" : "Servedio.",
      "year" : 2004
    }, {
      "title" : "A theory of the learnable",
      "author" : [ "Leslie G. Valiant" ],
      "venue" : "Commun. ACM,",
      "citeRegEx" : "Valiant.,? \\Q1984\\E",
      "shortCiteRegEx" : "Valiant.",
      "year" : 1984
    } ],
    "referenceMentions" : [ ],
    "year" : 2016,
    "abstractText" : "A Boolean k-monotone function defined over a finite poset domain D alternates between the values 0 and 1 at most k times on any ascending chain in D. Therefore, k-monotone functions are natural generalizations of the classical monotone functions, which are the 1-monotone functions. Motivated by the recent interest in k-monotone functions in the context of circuit complexity and learning theory, and by the central role that monotonicity testing plays in the context of property testing, we initiate a systematic study of k-monotone functions, in the property testing model. In this model, the goal is to distinguish functions that are k-monotone (or are close to being k-monotone) from functions that are far from being k-monotone. Our results include the following: 1. We demonstrate a separation between testing k-monotonicity and testing monotonicity, on the hypercube domain {0, 1}d, for k ≥ 3; 2. We demonstrate a separation between testing and learning on {0, 1}d, for k = ω(log d): testing k-monotonicity can be performed with 2 √ d·log d·log 1/ε) queries, while learning k-monotone functions requires 2 √ d·1/ε) queries (Blais et al. (RANDOM 2015)). 3. We present a tolerant test for functions f : [n] → {0, 1} with complexity independent of n, which makes progress on a problem left open by Berman et al. (STOC 2014). Our techniques exploit the testing-by-learning paradigm, use novel applications of Fourier analysis on the grid [n], and draw connections to distribution testing techniques. ∗Columbia University. Email: ccanonne@cs.columbia.edu. Research supported by NSF CCF-1115703 and NSF CCF-1319788. †Purdue University. Email: elena-g@purdue.edu. Research supported in part by NSF CCF-1649515. ‡Courant Institute of Mathematical Sciences, New York University. Email: sg191@nyu.edu. §Purdue University. Email: akumar@purdue.edu. ¶Duquesne University. Email: wimmerk@duq.edu.",
    "creator" : "LaTeX with hyperref package"
  }
}