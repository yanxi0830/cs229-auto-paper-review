{
  "name" : "1206.6401.pdf",
  "metadata" : {
    "source" : "META",
    "title" : "Consistent Multilabel Ranking through Univariate Loss Minimization",
    "authors" : [ "Krzysztof Dembczyński", "Wojciech Kot lowski", "Eyke Hüllermeier" ],
    "emails" : [ "kdembczynski@cs.put.poznan.pl", "wkotlowski@cs.put.poznan.pl", "eyke@informatik.uni-marburg.de" ],
    "sections" : [ {
      "heading" : "1. Introduction",
      "text" : "The problem of multilabel classification (MLC) has received increasing attention in machine learning research in recent years (Schapire & Singer, 2000; Elisseeff & Weston, 2001; Dekel et al., 2003; Dembczyński et al., 2010). In contrast to conventional (single-label) classification, where each instance is associated with a unique class label, MLC allows an instance to belong to several classes simultaneously. In other words, the “ground truth” is now a subset of positive labels instead of a single label. Correspondingly, more complex models need to be trained for predictive purposes,\nAppearing in Proceedings of the 29 th International Conference on Machine Learning, Edinburgh, Scotland, UK, 2012. Copyright 2012 by the author(s)/owner(s).\nand their predictions need to be evaluated in terms of generalized loss functions.\nInstead of producing predictions in terms of label subsets, one often prefers a multilabel ranking, that is, a ranking of labels from most likely positive to most likely negative. A prediction of that kind is commonly evaluated in terms of the rank loss, namely the fraction of incorrectly ordered label pairs; a positive and a negative label are incorrectly ordered if, in the predicted ranking, the former does not precede the latter—as it actually should do.\nMany methods for MLC are based on the direct minimization of the number of conflicts, that is, pairwise ranking errors; more specifically, since the rank loss is highly discontinuous, such methods typically seek to minimize a convex surrogate. Interestingly, this approach has recently been called into question by Gao & Zhou (2011) (following the earlier results of Duchi et al. (2010)), who showed that the most commonly used convex surrogates of that kind are inconsistent.\nIn this paper, we complement this negative result by a positive one. More specifically, we prove that common convex surrogates used for binary classification, namely exponential and logistic losses, are consistent for the minimization of rank loss. Surprisingly, our surrogates are even simpler than existing ones for ranking, as they are univariate loss functions; thus, being defined on single labels rather than label pairs, it comes with additional advantages in terms of complexity. Instead of directly proving convergence, we give a much stronger result by deriving regret bounds and convergence rates.\nThe paper is organized as follows. In the next section, we introduce the setting of multilabel classification and elaborate on the rank loss for performance evaluation. Our main theoretical result is presented in Section 3 and discussed against the background of (Gao & Zhou,\n2011) in Section 4. The theoretical contribution of the paper is complemented by some computational experiments in Section 5, prior to concluding with a summary in Section 6."
    }, {
      "heading" : "2. Multilabel Classification",
      "text" : "In this section, we explain the MLC problem more formally and, along the way, introduce the notation used throughout the paper.\nLet X denote an instance space, and let L = {λ1, λ2, . . . , λm} be a finite set of class labels. We assume that an instance x ∈ X is (non-deterministically) associated with a subset of labels L ∈ 2L; this subset is often called the set of relevant (positive) labels, while the complement L \\ L is considered as irrelevant (negative) for x. We identify a set L of relevant labels with a binary vector y = (y1, y2, . . . , ym), in which yi = 1 iff λi ∈ L. The set of possible labelings is denoted Y = {0, 1}m. We assume observations to be generated independently and randomly according to a probability distribution P (X = x,Y = y) (later denoted P (x,y)) on X × Y, i.e., an observation y = (y1, . . . , ym) is the realization of a corresponding random vector Y = (Y1, Y2, . . . , Ym).\nA multilabel classifier h assigns a (predicted) label subset to each instance x ∈ X . More generally, we allow the output of the classifier to be a vector of real numbers h(x) = (h1(x), . . . , hm(x)) ∈ Rm, which means that h is an X → Rm mapping. A score vector of this kind can not only be turned into a label subset (binary vector y ∈ {0, 1}m) via thresholding, but can also be used for ranking the labels λi in a natural way, namely by sorting them in decreasing order according to their respective scores si = hi(x)."
    }, {
      "heading" : "2.1. Loss, Risk and Regret",
      "text" : "The prediction accuracy of h is measured in terms of its risk, that is, its expected (classification) loss\nL(h, P )=E [`(Y ,h(X))]= ∫ `(y,h(x)) dP (x,y) , (1)\nwhere ` : Y×Rm → R is a loss function. In addition, it will be convenient to use an expected loss conditioned on an instance x ∈ X :\nL(h, P |x)=E [`(Y ,h(x)) |x]= ∑ y∈Y `(y,h(x))P (y |x) ,\nso that L(h, P ) = E[L(h, P |X)].\nThe risk of a classifier is not always a good indicator of its true performance, as it does not account for\nthe hardness of the problem. In fact, even the optimal classifier h∗ (which has access to the distribution P (x,y)) will normally have a non-zero risk. We call h∗ the Bayes classifier. For each x ∈ X , this classifier minimizes expected loss conditioned on x:\nh∗(x) = arg min s∈Rm ∑ y∈Y `(y, s)P (y |x) (2)\nWe note that in general, h∗ is not unique. However, the risk of h∗, denoted L∗(P ), is unique, and is called the Bayes risk. It offers a reasonable baseline for comparison and suggests to define the regret of a classifier h as follows:\nReg(h, P ) = L(h, P )− L∗(P ) (3)\nOccasionally, we will also use the regret conditioned on an instance x, denoted Reg(h, P |x). Later on, when analyzing the risk and regret for particular loss functions, such as rank loss, we will use more specific notations like Lrnk and Regrnk, which indicate the loss function that risk and regret are referring to."
    }, {
      "heading" : "2.2. Rank Loss",
      "text" : "In this paper, we focus on the rank loss, which is among the most important loss functions in MLC and has attracted much attention in recent years (Dembczyński et al., 2010; Gao & Zhou, 2011):\n`rnk(y,h)=w(y) ∑\n(i,j) :yi>yj\n( Jhi<hjK + 1\n2 Jhi=hjK\n) , (4)\nwhere J·K is the standard {false, true} → {0, 1} mapping (for the sake of clarity, we will suppress dependence on x in the notation, whenever it is clear from the context). Treating the classifier’s output as a ranking, the rank loss compares the true label subset with this ranking, in which all relevant labels ideally precede all irrelevant ones. More specifically, the rank loss counts the number of label pairs violating this condition and multiplies it by a positive weight w(y). In other words, the “penalty” or “cost” for a mistake on a label pair is given by w(y) and may thus depend on properties of the true labeling y.\nTypically, w(y) is a normalization constant equal to the reciprocal of the total number of pairwise comparisons between labels, thus accounting for the fact that the maximum number of possible mistakes depends on the number of positive labels in y. Yet, we shall not make any specific assumptions about about w(y) throughout the paper, except that it is non-negative and bounded: 0 ≤ w(y) ≤ wmax for all y.1\n1For our results, it is even enough to assume that w is bounded in expectation: E[w(Y ) |x] ≤ wmax for all x.\nLet us determine the Bayes classifier for the rank loss. To this end, it is convenient to introduce the following quantity:\n∆uvij = ∑\ny : yi=u,yj=v\nw(y)P (y |x) ,\nwhere i, j ∈ {1, . . . ,m} and u, v ∈ {0, 1}. Note that ∆uvij reduces to the marginal probability P (Yi = u, Yj = v |x) if w(y) ≡ 1. For a more general weight function w(·), ∆uvij combines the probability of the label combination (Yi = u, Yj = v) with the potential penalty in case these labels are ranked incorrectly. Thus, it can be seen as a kind of importance of this label combination.\nBy definition, ∆uvij = ∆ vu ji for all (i, j) and\n∆00ij + ∆ 01 ij + ∆ 10 ij + ∆ 11 ij = W ,\nwhere W = E[w(Y ) |x] = ∑\ny w(y)P (y |x) (which is a condition similar to the normalization property of a probability distribution). Then, the conditional risk can be written as follows:\nLrnk(h, P |x) = ∑ i>j ( ∆10ij Jhi > hjK + ∆01ij Jhi < hjK\n+ 1\n2 (∆10ij + ∆ 01 ij )Jhi = hjK\n) (5)\nTo proceed further, we define ∆ui = ∆ u0 ij + ∆ u1 ij for any j 6= i (one readily verifies that this quantity does not depend on j). ∆ui plays a role comparable to the marginal probability P (Yi = u |x). We have ∆0i + ∆1i = W for all i and\n∆1i −∆1j = ∆10ij + ∆11ij −∆10ji −∆11ji (6) = ∆10ij + ∆ 11 ij −∆01ij −∆11ij = ∆10ij −∆01ij .\nThe Bayes classifier ranks labels according to the ∆1i , i.e., a vector h∗ = (h∗1, . . . , h ∗ m) is a Bayes prediction if h∗i > h ∗ j whenever ∆ 1 i > ∆ 1 j , h ∗ i = h ∗ j whenever ∆1i = ∆ 1 j , and h ∗ i < h ∗ j whenever ∆ 1 i < ∆ 1 j . Indeed, using (6), we see that the Bayes classifier thus defined minimizes every term in the sum in (5). This result extends the result by Gao & Zhou (2011) defined in terms of ∆10ij . The Bayes risk conditioned on x is given by\nL∗rnk(P |x) = ∑\n1≤i<j≤m\nmin{∆10ij , ∆01ij } . (7)\nThe equality ∆1i −∆1j = ∆10ij −∆01ij in (6) is not only useful but also remarkable. In order to understand its meaning, it is convenient to consider the special case\nw(y) ≡ 1, in which the ∆-values reduce to conditional probabilities (Dembczyński et al., 2010). In this case, (6) becomes\nP (Yi = 1,Yj = 0 |x)− P (Yi = 0, Yj = 1 |x) = P (Yi = 1 |x)− P (Yj = 1 |x) .\nThe decision whether label λi should be ranked ahead of λj or the other way around depends on the sign of the left-hand side: If the joint probability of (Yi = 1, Yj = 0) is higher than the joint probability of (Yi = 0, Yj = 1), the answer should be affirmative, otherwise not. According to the above equation, the answer can be found by just looking at the marginal probabilities P (Yi = 1 |x) and P (Yj = 1 |x). This is remarkable, as it means that the dependency between Yi and Yj can safely be ignored—a key observation for our main result in the next section."
    }, {
      "heading" : "3. Main Result",
      "text" : "We prepare our main result, to be presented in Section 3.3, by two auxiliary results.\nFirst, in Section 3.1, we show that rank regret depends solely on the marginal weights ∆ui , and that we are allowed to replace the original distribution P by any other distribution P ′, as long as they both lead to the same marginal weights ∆ui . In particular, we can choose P ′, for which labels are (conditionally) independent.\nSecond, in Section 3.2, we provide the basic argument for the use of univariate loss functions, showing that, under the assumption of independence, such losses are sufficient for the consistent ranking of objects. This result will be shown, not for MLC directly, but in the context of the related problem of bipartite ranking.\nThe final step in Section 3.3 will therefore consist of transferring this result back to the setting of MLC, using the trick from Section 3.1 and the fact that expected univariate losses depend on distribution only through the marginal weights ∆ui ."
    }, {
      "heading" : "3.1. Label Dependence Does Not Influence Rank Regret",
      "text" : "The main problem in the analysis of the regret (3) is the conditional dependence of labels given x. As already mentioned, however, this dependence does not seem to play an important role in the minimization of rank regret. In the following, we shall make this observation more explicit by showing that rank regret depends solely on the marginal weights ∆ui : Lemma 3.1. For every x ∈ X , and every multilabel\nclassifier h: Reg(h, P |x) = ∑\n1≤j<i≤m\n( ∆1i Jhi < hjK + ∆1jJhi > hjK\n+ ∆1i + ∆ 1 j\n2 Jhi = hjK−min{∆1i ,∆1j}\n) .\nProof. According to (5) and (7), Reg(h, P |x) can be written as\nReg(h, P |x) = ∑\n1≤j<i≤m\nBij ,\nwhere\nBij = ∆ 10 ij Jhi < hjK + ∆01ij Jhi > hjK\n+ ∆10ij + ∆ 01 ij\n2 Jhi = hjK−min{∆10ij ,∆01ij } .\nSince only one of the first three terms can be nonzero, Bij will not change if we add ∆ 11 ij to the first three terms and subtract it from the last term:\nBij = (∆ 10 ij + ∆ 11 ij )Jhi < hjK + (∆01ij + ∆11ij )Jhi > hjK\n+ (∆10ij + ∆ 11 ij ) + (∆ 01 ij + ∆ 11 ij )\n2 Jhi = hjK\n−min{∆10ij + ∆11ij ,∆01ij + ∆11ij } .\nBy definition, ∆10ij + ∆ 11 ij = ∆ 1 i , ∆ 01 ij + ∆ 11 ij = ∆ 10 ji + ∆11ji = ∆ 1 j , so that:\nBij = ∆ 1 i Jhi < hjK + ∆1jJhi > hjK\n+ ∆1i + ∆ 1 j\n2 Jhi = hjK−min{∆1i ,∆1j} .\n(8)\nLemma 3.1 implies that the rank regret of any multilabel classifier h will not change if we replace the original distribution P and weight function w by any other distribution P ′ and function w′, as long as they lead to the same marginal weights ∆ui . In particular, we can choose P ′ to be a product distribution, for which labels are (conditionally) independent, and the constant weight function w′(y) = W for all y. As we shall see in Section 3.3, this will effectively result in a bipartite ranking problem for every x.\nBefore exploiting this finding in Section 3.3, we provide a second building block of our main result, showing that the minimization of specific univariate losses is sufficient for the proper ranking of objects under the assumption of independence. To this end, we refer to the related though slightly simpler setting of bipartite ranking. From now on, it will be more convenient to encode labels as −1 and +1, i.e., yi ∈ {−1,+1} instead of {0, 1}."
    }, {
      "heading" : "3.2. Univariate Loss Minimization is Sufficient under the Assumption of Independence",
      "text" : "The bipartite ranking problem (Cohen et al., 1999; Clémençon et al., 2008; Kot lowski et al., 2011) is in a sense in-between MLC and standard binary classification. Like in the latter, there is only a single binary class label, but like in MLC, performance is measured in terms of rank loss instead of classification error. However, instead of ranking labels given an instance, the problem is to rank the instances themselves.\nMore specifically, consider a simple binary classification problem with training examples (x̃, ỹ) ∈ X̃ × {−1,+1}. A classifier h̃ is a real-valued function h̃ : X̃ → R, and performance is measured in terms of a bipartite rank loss defined on pairs of labels:\n`br((ỹ, ỹ ′), (h̃, h̃′)) = Jỹ > ỹ′KJh̃ < h̃′K\n+ Jỹ < ỹ′KJh̃ > h̃′K + 1 2 Jỹ 6= ỹ′KJh̃ = h̃′K\nThis is a non-normalized version of the rank loss, which is more useful for our purposes; in the literature, it is common to use a normalized version, which differs from the non-normalized one by a product of class priors (Clémençon et al., 2008).\nGiven the loss, we can define risk and regret by taking expectations over the pairs of instances which are generated i.i.d.:\nLbr(h̃, P̃ ) = E[`br((Ỹ , Ỹ ′), (h̃(X̃), h̃(X̃ ′))]\n= ∫ `br((ỹ, ỹ ′), (h̃(x̃), h̃(x̃′)))dP̃ (x̃, ỹ)dP̃ (x̃′, ỹ′) ,\nRegbr(h̃, P̃ ) = Lbr(h̃, P̃ )− inf h̃′ Lbr(h̃\n′, P̃ ) .\nLet `exp(ỹ, h̃) = e −ỹh̃, `log(ỹ, h̃) = log(1 + e −ỹh̃) be the standard exponential and logistic losses for binary classification. For these losses, we can again define risks Lexp(h̃, P̃ ), Llog(h̃, P̃ ) and regrets Regexp(h̃, P̃ ),Reglog(h̃, P̃ ) in a standard way. The following theorem relates bipartite ranking regret to regrets in terms of exponential and logistic loss:\nTheorem 3.1. Regbr(h̃, P̃ ) ≤ √ 3\n2\n√ Regexp(h̃, P̃ ) (9)\nRegbr(h̃, P̃ ) ≤ √ 2 √ Reglog(h̃, P̃ ) (10)\nTheorem 3.1 is very similar to Theorem 4.1 in (Kot lowski et al., 2011), except that the latter involves a normalized version of the bipartite rank loss and socalled balanced loss functions. Nevertheless, in order\nto show Theorem 3.1, the proof from (Kot lowski et al., 2011) can be adapted quite easily. Here, we omit a detailed presentation of the modifications required due to space restrictions."
    }, {
      "heading" : "3.3. Minimizing Rank Loss in MLC",
      "text" : "The exponential loss and the logistic loss introduced above are commonly used in standard classification. A straightforward extension of these losses to the MLC setting, taking multiple labels and instance weights into account, is given as follows:\n`exp(y,h) = w(y) m∑ i=1 e−yihi , (11)\n`log(y,h) = w(y) m∑ i=1 log ( 1 + e−yihi ) . (12)\nThe minimization of these losses comes down to solvingm independent classification problems, one for each label. Any algorithm for classification with exponential or logistic surrogate, such as AdaBoost or logistic regression, can be used for this purpose, provided it allows for handling weighted instances. Despite its simplicity and efficiency, this approach provides a consistent way of minimizing the rank loss, as shown by the following result.\nTheorem 3.2. Let Regexp(h, P ) and Reglog(h, P ) be the regrets for exponential and logistic losses, respectively. Then\nRegrnk(h, P ) ≤ √ 6 4 C √ Regexp(h, P ), (13) Regrnk(h, P ) ≤ √ 2 2 C √ Reglog(h, P ), (14)\nwhere C ≤ m√mwmax.\nProof. The idea of the proof is to reduce an MLC problem, conditioned on an instance x, to a bipartite ranking problem, which then allows us to exploit Theorem 3.1. More specifically, for a given x, we define a bipartite ranking problem by setting X̃ = {1, . . . ,m}; that is, the objects (instances) to be ranked now correspond to the label indices of our MLC problem and are of the form x̃ = i, (i = 1, . . . ,m). Moreover, we define a distribution P̃ on X̃ × {−1,+1} as follows:\nP̃ (X̃ = i) = 1 m , P̃ (Ỹ = 1 | X̃ = i) = ∆\n1 i\nW (15)\nFor a classifier h̃ with h̃(x̃ = i) = hi, it is easy to see that\nRegbr(h̃, P̃ ) = 1\nm2 ∑ i,j B̃ij ,\nwhere B̃ij is defined as:\nB̃ij = ∆1i W\n( 1−\n∆1j W\n) Jhi < hjK +\n∆1j W\n( 1−∆ 1 i\nW\n) Jhi > hjK\n+ 1\n2 ( ∆1i W ( 1− ∆1j W ) + ∆1j W ( 1− ∆ 1 i W )) Jhi = hjK\n−min { ∆1i W ( 1− ∆1j W ) , ∆1j W ( 1− ∆ 1 i W )} = Bij W ,\nwhere the last equality is valid because the term ∆1i W ∆1j W cancels and because of (8). Using the above and Lemma 3.1, we see that\nRegbr(h̃, P̃ ) = 1\nm2 ∑ i,j B̃ij = 1 Wm2 ∑ i,j Bij\n≥ 2 Wm2 ∑ 1≤j<i≤m Bij = 2 Wm2 Regrnk(h, P |x) . (16)\nTheorem 3.1 relates Regbr(h̃, P̃ ) to Reg`(h̃, P̃ ), for ` being the exponential or logistic loss. What remains, therefore, is to trace back Reg`(h̃, P̃ ) to Reg`(h, P |x), where the latter regret is based on the original distribution P and the multilabel versions (11–12) of exponential and logistic loss. The following equalities hold:\nL`(h, P |x) = n∑ i=1 `(1, hi)∆ 1 i + `(−1, hi)∆0i ,\nL∗` (P |x) = n∑ i=1 inf h { `(1, h)∆1i + `(−1, h)∆0i } ,\nwhere we have, respectively, risks based on the multilabel loss and risks based on standard classification loss on the left-hand and right-hand side. Due to (15), we get\nReg`(h, P |x) = WmReg`(h̃, P̃ ) . (17)\nTaking (16), (9–10), and (17) together gives\nRegrnk(h, P |x) ≤ √ 6 4 C √ Regexp(h, P |x) , Regrnk(h, P |x) ≤ √ 2 2 C √ Reglog(h, P |x) ,\nwhere C = m √ mW . The Theorem is proved by noting that W ≤ wmax, taking the expectation with respect to x on both sides, and applying Jensen inequality E[f(X)] ≤ f(E[X]) for the concave function f(x) =√ x.\nOne might be concerned by the possibly large constant C = m √ mW appearing in the bound, wondering whether it could perhaps be improved. However,\nC is indeed expected to appear in the bound and does actually not weaken it. Instead, it only compensates for the difference in the scale of both sides of (13) and (14). Indeed, the rank regret on the left-hand side scales like O(m2W ), while the square root of exponential/logistic regret on the right-hand side scales like O( √ mW ). Therefore, there must be a constant O(m √ mW ) on the right-hand side to compensate for the difference.\nAnother question is whether the square-root convergence in (13–14) could be improved. The answer is negative: Bartlett et al. (2006) already showed for binary classification (which can be casted as a special MLC ranking problem) that the square-root bound is unavoidable in the worst case."
    }, {
      "heading" : "4. Relationship to Prior Work",
      "text" : "This section is meant to look at the result of Gao & Zhou (2011) against the background of our findings so far, trying to support a more intuitive understanding. As mentioned earlier, these authors consider pairwise convex surrogate losses of the form\n`φ(y,h) = ∑\n(i,j) : yi>yj\nw(y)φ(hi − hj) , (18)\nwhere φ is a convex, differential, non-linear, and nonincreasing function, and show that no such loss is consistent for multilabel ranking. Given the existence of pairwise losses that are actually consistent for bipartite ranking, this result appears to be surprising at first sight, all the more since, in our proof, we are using a reduction to bipartite ranking, too.\nThe reason for inconsistency becomes more apparent when looking at the conditional expected loss:\nLφ(h, P |x) = ∑ i>j ∆10ij φ(hi−hj)+∆10ji φ(hj−hi) (19)\nA necessary condition for consistency is that the Bayes classifier h∗ for φ-loss is also the Bayes ranker, i.e.,\nsign(h∗i − h∗j ) = sign(∆10ij −∆01ij ) . (20)\nTo ease understanding, it is again convenient to consider the special case w(y) ≡ 1, in which the ∆-values reduce to conditional probabilities (and, therefore, are more easily interpretable). In our approach of univariate loss minimization, (20) is indeed valid: According to (6), the equality ∆1i − ∆1j = ∆10ij − ∆01ij holds true. Moreover, by applying a convex loss function φ, the prediction h∗i of the Bayes classifier is a nonlinear yet monotone transformation of the conditional probability ∆1i = P (Yi = 1 |x): The larger\nthe probability of the conditional class, the larger the score produced by the Bayes classifier. Consequently, sign(h∗i − h∗j ) = sign(∆1i − ∆1j ) = sign(∆10ij − ∆01ij ). Thus, loosely speaking, our approach guarantees consistency because the (Bayes) decision of how to rank two labels λi and λj , which depends on the sign of ∆10ij −∆01ij , remains unaffected by both of our measures: the consideration of univariate marginals ∆1i instead of the bivariate ones ∆10ij and ∆ 01 ij (label dependency does not matter), as well as the transformation implied by the convex surrogate afterward.\nNow, although the first argument of the irrelevance of label dependence does in principle remain valid in case of pairwise loss, consistency is essentially lost in the second step. In fact, the use of a convex surrogate loss has a much more involved effect in the pairwise case, since the (nonlinear monotone) transformation now applies to the differences ∆1i − ∆1j = P (Yi = 1 |x)−P (Yj = 1 |x) of conditional probabilities instead of the conditionals themselves. Therefore, since each ∆1i simultaneously participates in several such differences, the minimization of (19) results in a complicated solution h∗, where h∗i generally depends on all ∆10jk (1 ≤ j, k ≤ m), and not only on ∆1i . Gao & Zhou (2011) exploit this observation to show that, for any φ defined as above, the pairwise marginals ∆10jk can be chosen such that the Bayes classifier h∗ is not the Bayes ranker. The only case in which (19) admits a simple solution for certain losses φ is when the labels are independent, and this is exactly the case of bipartite ranking, for which consistency is known to hold.\nWe note that Gao & Zhou (2011) (following Duchi et al. (2010)) showed consistency (but not regret bounds and convergence rates) of some specific pairwise surrogate losses, one of which can be rewritten as a univariate linear surrogate with regularization."
    }, {
      "heading" : "5. Empirical Results",
      "text" : "To verify our theoretical claims we performed experimental studies on synthetic and benchmark data. We measured the performance of the algorithms in terms of the rank loss (4) with weights defined as:\nw(y) = (sy(m− sy))−1 , where sy = ∑ i yi . (21)\nThis is a popular choice, as the weights are the inverses of the total number of pairwise comparisons between labels. Thus, the value of the rank loss is between 0 (perfect ordering) and 1 (reversed ordering).\nThe main goal of the experiment is to verify whether simple algorithms based on univariate surrogate losses (11) and (12) are competitive to state-of-the-art al-\ngorithms that minimize the rank loss using convex pairwise surrogates (18). Note that minimization of (11) and (12) reduces to solving m independent classification tasks with weighted training examples. In other words, each task is solved by using an algorithm that minimizes the ordinary exponential or logistic loss on a set of weighted training examples. We used AdaBoost.M1 to minimize the exponential loss and logistic regression to minimize the logistic loss. We refer to this reduction framework as Weighted Binary Relevance (WBR). We compared WBR with two well-known algorithms for multilabel ranking, AdaBoost.MR (Schapire & Singer, 2000) and log-linear models for label ranking (LLLR) (Dekel et al., 2003). These two algorithms seek to minimize the rank loss by using convex surrogates defined on label pairs (18). AdaBoost.MR uses the exponential and LLLR the logistic surrogate. Let us underline that both AdaBoost.MR and LLLR use weights (21) in their surrogates, so that all the algorithms are tailored for the same performance measure.\nIn boosting algorithms, we used decision stumps as weak learners. For AdaBoost.M1, we selected the number of decision stumps from {10, 20, 50, 100, 200}, while for AdaBoost.MR, the total number of decision stumps from {10, 20, 50, 102, . . . , 104, 2×104}. The regularization parameter in logistic regression was tuned in the range {10−3, 10−2, . . . , 103}. We ran LLLR with different numbers of iterations {10, 20, 50, 102, . . . , 104, 2×104}.2 The tuning process should not favor any of the methods, as all algorithms have a single parameter to choose."
    }, {
      "heading" : "5.1. Synthetic Data",
      "text" : "We designed synthetic data to show a difference in the performance of the algorithms in the cases of label dependence and independence, respectively. The model is based on latent variables f = (f1, f2, . . . , fm):\nf = Ax+ ,\nwhere x is a two-dimensional feature vector uniformly drawn from a unit disk, A is an m × 2 matrix of linear coefficients, and is an m-dimensional noise vector whose coordinates are drawn from N(0, 0.25). The labels are obtained from the latent variables according to\ny = JMf > 0K, 2To perform experiments, we used MULAN (http: //mulan.sourceforge.net/) and Weka (http://www.cs. waikato.ac.nz/ml/weka/) packages, implementation of logistic regression from Mallet (http://mallet.cs.umass. edu/), and the original implementation of AdaBoost.MR from the BoosTexter package (http://www.cs.princeton. edu/~schapire/boostexter.html).\nwhere M is an m×m mixing matrix introducing dependencies between labels, and J·K applies to each element of the vector separately. A single model is thus determined by the choice of A and M . The independent label case is obtained for M being the identity I.\nWe generated 10 random models, with rows of A drawn uniformly from a 2-dimensional unit sphere. For each model, we considered the case of independent (M = I) and dependent labels (entries of M drawn independently and uniformly from [−1, 1]). In each case, we trained all 4 algorithms on training sets of different sizes n, varying n from 100 to 16000 examples. For each n, 10 training sets of a given size were generated (thus, there are 100 repetitions for any given training set size n). For testing, we used a dataset containing 50 000 examples.\nThe results are given in Fig. 1. We compared the algorithms based on exponential loss separately from those for logistic loss. The results shown in Fig. 1 are nicely in agreement with what we expect from our theoretical results, at least for the logistic loss: In the case of label independence, where both pairwise and univariate loss minimization are consistent, the methods perform more or less en par. However, in the case where labels are not independent, and hence the pairwise approach is no longer consistent, our approach of univariate loss minimization shows small but consistent improvements. In the case of exponential loss, the picture is not entirely clear,3 but the univariate approach seems to outperform its competitor based on pairwise loss for large enough training data. Weaker performance of the exponential loss follows from the fact that the stumps used as base learners in boosting do not exactly match the true (linear) model."
    }, {
      "heading" : "5.2. Benchmark Data",
      "text" : "We also performed an experiment on commonly used benchmark datasets.4 We chose 4 datasets of moderate size, with around 10 labels, and one large dataset with 101 labels and more than 30K training examples. The datasets are described in Table 1. To facilitate comparison of the results presented in this paper, we used the original split for training and test sets.\nThe results are given in Table 2, again separately for\n3AdaBoost.MR behaves quite strangely on these datasets as for more than 20 stumps it quickly overfits. Therefore, we also limited the number of stumps in WBRAdaBoost.\n4 These datasets are taken from MULAN http://mulan.sourceforge.net/datasets.html and LibSVM http://www.csie.ntu.edu.tw/~cjlin/ libsvmtools/datasets/multilabel.html repositories.\nexponential and logistic loss. The picture conveyed by these results is less clear than it was for the synthetic datasets. In fact, since the true nature of the data is not known (i.e., whether or not the labels are independent), is is difficult to draw clear conclusions. Nevertheless, one can safely say the simple reduction algorithms trained independently on each label are competitive to state-of-the-art algorithms defined on pairwise surrogates. Again, this is in complete agreement with our theoretical results."
    }, {
      "heading" : "6. Conclusions",
      "text" : "In this paper, we have shown that common univariate convex surrogates are consistent for mutlilabel ranking. We proved explicit regret bounds, relating ranking regret to univariate loss regret, which not only help to answer the question of consistency, but also inform about the rates of convergence.\nFor several reasons, our results should be of interest\nto the machine learning community. Most notably, because they are arguably surprising in light of (Gao & Zhou, 2011), where inconsistency is shown for the most popular pairwise surrogates. Moreover, on the more practical side, our results motivate simple and scalable algorithms for multilabel ranking, which are plain modifications of standard algorithms for classification (such as logistic regression or AdaBoost).\nAcknowledgments. Krzysztof Dembczyński is supported by the Foundation of Polish Science under the Homing Plus programme, co-financed by the European Regional Development Fund. Wojciech Kot lowski is supported by the grant 91-517/DS funded by the Polish Ministry of Science and Higher Education. Eyke Hüllermeier is supported by German Research Foundation (DFG)."
    } ],
    "references" : [ {
      "title" : "Convexity, classification, and risk bounds",
      "author" : [ "P.L. Bartlett", "M.I. Jordan", "J.D. McAuliffe" ],
      "venue" : "Journal of the American Statistical Association,",
      "citeRegEx" : "Bartlett et al\\.,? \\Q2006\\E",
      "shortCiteRegEx" : "Bartlett et al\\.",
      "year" : 2006
    }, {
      "title" : "Ranking and empirical minimization of U-statistics",
      "author" : [ "S. Clémençon", "L. Gábor", "N. Vayatis" ],
      "venue" : "Annals of Statistics,",
      "citeRegEx" : "Clémençon et al\\.,? \\Q2008\\E",
      "shortCiteRegEx" : "Clémençon et al\\.",
      "year" : 2008
    }, {
      "title" : "Learning to order things",
      "author" : [ "W.W. Cohen", "R.E. Schapire", "Y. Singer" ],
      "venue" : "Journal of Artificial Intelligence Research,",
      "citeRegEx" : "Cohen et al\\.,? \\Q1999\\E",
      "shortCiteRegEx" : "Cohen et al\\.",
      "year" : 1999
    }, {
      "title" : "Log-linear models for label ranking",
      "author" : [ "O. Dekel", "Manning", "Ch", "Y. Singer" ],
      "venue" : "In NIPS,",
      "citeRegEx" : "Dekel et al\\.,? \\Q2003\\E",
      "shortCiteRegEx" : "Dekel et al\\.",
      "year" : 2003
    }, {
      "title" : "Bayes optimal multilabel classification via probabilistic classifier chains",
      "author" : [ "K. Dembczyński", "W. Cheng", "E. Hüllermeier" ],
      "venue" : "In ICML, pp",
      "citeRegEx" : "Dembczyński et al\\.,? \\Q2010\\E",
      "shortCiteRegEx" : "Dembczyński et al\\.",
      "year" : 2010
    }, {
      "title" : "On the consistency of ranking algorithms",
      "author" : [ "J. Duchi", "L. Mackey", "M. Jordan" ],
      "venue" : "In ICML, pp",
      "citeRegEx" : "Duchi et al\\.,? \\Q2010\\E",
      "shortCiteRegEx" : "Duchi et al\\.",
      "year" : 2010
    }, {
      "title" : "A kernel method for multilabelled classification",
      "author" : [ "A. Elisseeff", "J. Weston" ],
      "venue" : "In NIPS, pp",
      "citeRegEx" : "Elisseeff and Weston,? \\Q2001\\E",
      "shortCiteRegEx" : "Elisseeff and Weston",
      "year" : 2001
    }, {
      "title" : "On the consistency of multi-label learning",
      "author" : [ "W. Gao", "Z. Zhou" ],
      "venue" : "In COLT, pp",
      "citeRegEx" : "Gao and Zhou,? \\Q2011\\E",
      "shortCiteRegEx" : "Gao and Zhou",
      "year" : 2011
    }, {
      "title" : "Bipartite ranking through minimization of univariate loss",
      "author" : [ "W. Kot lowski", "K. Dembczyński", "E. Hüllermeier" ],
      "venue" : "In ICML, pp",
      "citeRegEx" : "lowski et al\\.,? \\Q2011\\E",
      "shortCiteRegEx" : "lowski et al\\.",
      "year" : 2011
    }, {
      "title" : "BoosTexter: A Boostingbased System for Text Categorization",
      "author" : [ "R.E. Schapire", "Y. Singer" ],
      "venue" : "Machine Learning,",
      "citeRegEx" : "Schapire and Singer,? \\Q2000\\E",
      "shortCiteRegEx" : "Schapire and Singer",
      "year" : 2000
    } ],
    "referenceMentions" : [ {
      "referenceID" : 3,
      "context" : "The problem of multilabel classification (MLC) has received increasing attention in machine learning research in recent years (Schapire & Singer, 2000; Elisseeff & Weston, 2001; Dekel et al., 2003; Dembczyński et al., 2010).",
      "startOffset" : 126,
      "endOffset" : 223
    }, {
      "referenceID" : 4,
      "context" : "The problem of multilabel classification (MLC) has received increasing attention in machine learning research in recent years (Schapire & Singer, 2000; Elisseeff & Weston, 2001; Dekel et al., 2003; Dembczyński et al., 2010).",
      "startOffset" : 126,
      "endOffset" : 223
    }, {
      "referenceID" : 5,
      "context" : "Interestingly, this approach has recently been called into question by Gao & Zhou (2011) (following the earlier results of Duchi et al. (2010)), who showed that the most commonly used convex surrogates of that kind are inconsistent.",
      "startOffset" : 123,
      "endOffset" : 143
    }, {
      "referenceID" : 4,
      "context" : "In this paper, we focus on the rank loss, which is among the most important loss functions in MLC and has attracted much attention in recent years (Dembczyński et al., 2010; Gao & Zhou, 2011):",
      "startOffset" : 147,
      "endOffset" : 191
    }, {
      "referenceID" : 4,
      "context" : "In order to understand its meaning, it is convenient to consider the special case w(y) ≡ 1, in which the ∆-values reduce to conditional probabilities (Dembczyński et al., 2010).",
      "startOffset" : 150,
      "endOffset" : 176
    }, {
      "referenceID" : 2,
      "context" : "The bipartite ranking problem (Cohen et al., 1999; Clémençon et al., 2008; Kot lowski et al., 2011) is in a sense in-between MLC and standard binary classification.",
      "startOffset" : 30,
      "endOffset" : 99
    }, {
      "referenceID" : 1,
      "context" : "The bipartite ranking problem (Cohen et al., 1999; Clémençon et al., 2008; Kot lowski et al., 2011) is in a sense in-between MLC and standard binary classification.",
      "startOffset" : 30,
      "endOffset" : 99
    }, {
      "referenceID" : 1,
      "context" : "This is a non-normalized version of the rank loss, which is more useful for our purposes; in the literature, it is common to use a normalized version, which differs from the non-normalized one by a product of class priors (Clémençon et al., 2008).",
      "startOffset" : 222,
      "endOffset" : 246
    }, {
      "referenceID" : 0,
      "context" : "The answer is negative: Bartlett et al. (2006) already showed for binary classification (which can be casted as a special MLC ranking problem) that the square-root bound is unavoidable in the worst case.",
      "startOffset" : 24,
      "endOffset" : 47
    }, {
      "referenceID" : 5,
      "context" : "We note that Gao & Zhou (2011) (following Duchi et al. (2010)) showed consistency (but not regret bounds and convergence rates) of some specific pairwise surrogate losses, one of which can be rewritten as a univariate linear surrogate with regularization.",
      "startOffset" : 42,
      "endOffset" : 62
    }, {
      "referenceID" : 3,
      "context" : "MR (Schapire & Singer, 2000) and log-linear models for label ranking (LLLR) (Dekel et al., 2003).",
      "startOffset" : 76,
      "endOffset" : 96
    } ],
    "year" : 2012,
    "abstractText" : "We consider the problem of rank loss minimization in the setting of multilabel classification, which is usually tackled by means of convex surrogate losses defined on pairs of labels. Very recently, this approach was put into question by a negative result showing that commonly used pairwise surrogate losses, such as exponential and logistic losses, are inconsistent. In this paper, we show a positive result which is arguably surprising in light of the previous one: the simpler univariate variants of exponential and logistic surrogates (i.e., defined on single labels) are consistent for rank loss minimization. Instead of directly proving convergence, we give a much stronger result by deriving regret bounds and convergence rates. The proposed losses suggest efficient and scalable algorithms, which are tested experimentally.",
    "creator" : "LaTeX with hyperref package"
  }
}