{
  "name" : "1605.09646.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "Average-case hardness of RIP certification",
    "authors" : [ "Tengyao Wang", "Quentin Berthet", "Yaniv Plan" ],
    "emails" : [ ],
    "sections" : [ {
      "heading" : null,
      "text" : "Introduction\nIn many areas of data science, high-dimensional signals contain rich structure. It is of great interest to leverage this structure to improve our ability to describe characteristics of the signal and to make future predictions. Sparsity is a structure of wide applicability (see, e.g. Mallat, 1999; Rauhut and Foucart, 2013; Eldar and Kutyniok, 2012), with a broad literature dedicated to its study in various scientific fields.\nThe sparse linear model takes the form y = Xβ + ε, where y ∈ Rn is a vector of observations, X ∈ Rn×p is a design matrix, ε ∈ Rn is noise, and the vector β ∈ Rp\n∗University of Cambridge, supported by Benefactors’ Scholarship, St John’s College. †University of Cambridge, supported by the Isaac Newton Trust Early Career Support Scheme ‡University of British Columbia, supported by NSERC grant 22R23068\nar X\niv :1\n60 5.\n09 64\n6v 1\n[ cs\n.L G\n] 3\n1 M\nis assumed to have a small number k of non-zero entries. Estimating β or the mean response, Xβ, are among the most widely studied problems in signal processing, as well as in statistical learning. In high-dimensional problems, one would wish to recover β with as few observations as possible. For an incoherent design matrix, it is known that an order of k2 observations suffice (Donoho, Elad and Temlyakov, 2006; Donoho and Elad, 2003). However, this appears to require a number of observations far exceeding the information content of β, which has only k variables, albeit with unknown locations.\nThis dependence in k can be greatly improved by using design matrices that are almost isometries on some low dimensional subspaces, i.e., matrices that satisfy the restricted isometry property with parameters k and θ, or RIP(k, θ) (see Definition 1). It is a highly robust property, and in fact implies that many different polynomial time methods, such as greedy methods (Blumensath and Davies, 2009; Needell and Tropp, 2009; Dai and Milenkovic, 2009) and convex optimization (Candès, 2008; Candès, Romberg and Tao, 2006b; Candès and Tao, 2005, 2006), are stable in recovering β. Random matrices are known to satisfy the RIP when the number n of observation is more than about k log(p)/θ2. These results were developed in the field of compressed sensing (Candès, Romberg and Tao, 2006a; Donoho, 2006; Candès and Tao, 2006; Rauhut and Foucart, 2013; Eldar and Kutyniok, 2012) where the use of randomness still remains pivotal for near-optimal results. Properties related to the conditioning of design matrices have also been shown to play a key role in the statistical properties of computationally efficient estimators of β (Zhang, Wainwright and Jordan, 2014). While the assumption of randomness allows great theoretical leaps, it leaves open questions for practitioners.\nScientists working on data closely following this model cannot always choose their design matrix X, or at least choose one that is completely random. Moreover, it is in general practically impossible to check that a given matrix satisfies these desired properties, as RIP certification is NP-hard (Bandeira et al., 2012). Having access to a function, or statistic, of X that could be easily computed, which determines how well β may be estimated, would therefore be of a great help.\nThe search for such statistics has been of great importance for over a decade now, and several have been proposed (d’Aspremont and El Ghaoui, 2011; Lee and Bresler, 2008; Juditsky and Nemirovski, 2011; d’Aspremont, Bach and El Ghaoui, 2008). Perhaps the simplest and most popular is the incoherence parameter, which measures the maximum inner product between distinct, normalized, columns of X. However, all of these are known to necessarily fail to guarantee good recovery when p ≥ 2n unless n is of order k2 (d’Aspremont and El Ghaoui, 2011). Given a specific problem instance, the strong recovery guarantees of compressed sensing cannot be verified based on these statistics.\nIn this article, we study the problem of average-case certification of the Restricted Isometry Property (RIP). A certifier takes as input a design matrix X, always outputs\n‘false’ when X does not satisfy the property, and outputs ‘true’ for a large proportion of matrices (see Definition 4). Indeed, worst-case hardness does not preclude a problem from being solvable for most instances. The link between restricted isometry and incoherence implies that polynomial time certifiers exists in a regime where n is of order k2 log(p)/θ2. It is natural to ask whether the RIP can be certified for sample size n k log(p)/θ2, where most matrices (with respect to, say, the Gaussian measure) are RIP. If it does, it would also provide a Las Vegas algorithm to construct RIP design matrices of optimal sizes. This should be compared with the currently existing limitations for the deterministic construction of RIP matrices.\nOur main result is that certification in this sense is hard even in a near-optimal regime, assuming a new, weaker assumption on detecting dense subgraphs, related to the Planted Clique hypothesis.\nTheorem (Informal). There is no computationally efficient average-case certifier for RIPn,p(k, θ) uniformly over an asymptotic regime where n k1+α/θ2, for any α < 1.\nThis suggests that even in the average case, RIP certification requires almost k2 log(p)/θ2\nobservations. This contrasts highly with the fact that a random matrix satisfies RIP with high probability when n exceeds about k log(p)/θ2. Thus, there appears to be a large gap between what a practitioner may be able to certify given a specific problem instance, and what holds for a random matrix. On the other hand, if a certifier is found which fills this gap, the result would not only have huge practical implications in compressed sensing and statistical learning, but would also disprove a long-standing conjecture from computational complexity theory.\nOur result shares many characteristics with a hypothesis by Feige (2002) on the hardness of refuting random satisfiability formulas. Indeed, our statement is also about the hardness of verifying that a property holds for a particular instance (RIP for design matrices, instead of unsatisfiability for boolean formulas). It concerns a regime where such a property should hold with high probability (n of order k1+α/θ2, linear regime for satisfiability), cautiously allowing only one type of errors, false negatives, for a problem that is hard in the worst case. In these two examples, such certifiers exist in an a sub-optimal regime. Our problem is conceptually different from results regarding the worst-case hardness of certifying this property (see, e.g. Bandeira et al., 2012; Koiran and Zouzias, 2012; Tillmann and Pfetsch, 2014). It is closer to another line of work concerned with computational lower bounds for statistical learning problems based on average-case assumptions. The planted clique assumption has been used to prove computational hardness results for statistical problems such as estimation and testing of sparse principal components (Berthet and Rigollet, 2013a,b; Wang, Berthet and Samworth, 2016), testing and localization of submatrix signals (Ma and Wu, 2013; Chen and Xu, 2014), community\ndetection (Hajek, Wu and Xu, 2015) and sparse canonical correlation analysis (Gao, Ma and Zhou, 2014). The intractability of noisy parity recovery problem (Blum, Kalai and Wasserman, 2003) has also been used recently as an average-case assumption to deduce computational hardness of detection of satisfiability formulas with lightly planted solutions (Berthet and Ellenberg, 2015). Additionally, several unconditional computational hardness results are shown for statistical problems under constraints of learning models (Feldman et al., 2013; Feldman, Perkins and Vempala, 2013). The present work has two main differences compared to previous computational lower bound results. First, in a detection setting, these lower bounds concern two specific distributions (for the null and alternative hypothesis), while ours is valid for all sub-Gaussian distributions, and there is no alternative distribution. Secondly, our result is not based on the usual assumption for the Planted Clique problem. Instead, we use a weaker assumption on a problem of detecting planted dense graphs. This does not mean that the planted graph is a random graph with edge probability q > 1/2 as considered in (Arias-Castro and Verzelen, 2013; Bhaskara et al., 2010; Awasthi et al., 2015), but that it can be any graph with an unexpectedly high number of edges (see section 3.1). This choice is made to strengthen our result: it would ‘survive’ the discovery of an algorithm that would use very specific properties of cliques (or even of random dense graphs) to detect their presence. As a consequence, the analysis of our reduction is more technically complicated.\nOur work is organized in the following manner: We recall in Section 1 the definition of the restricted isometry property, and some of its known properties. In Section 2, we define the notion of certifier, and prove the existence of a computationally efficient certifier in a sub-optimal regime. Our main result is developed in Section 3, focused on the hardness of average-case certification. The proofs of the main results are in Appendix A and those of auxiliary results in Appendix B."
    }, {
      "heading" : "1 Restricted Isometric Property",
      "text" : ""
    }, {
      "heading" : "1.1 Formulation",
      "text" : "We use the definition of Candès and Tao (2005), who introduced this notion. Below, for a vector u ∈ Rp, ‖u‖0 is the number of non-zero entries. Definition 1 (RIP). A matrix X ∈ Rn×p satisfies the restricted isometry property with sparsity k ∈ {1, . . . , p} and distortion θ ∈ (0, 1), denoted by X ∈ RIPn,p(k, θ), if it holds that 1− θ ≤ ‖Xu‖22 ≤ 1 + θ, for every u ∈ Sp(k) := {u ∈ Rp : ‖u‖2 = 1, ‖u‖0 ≤ k}.\nThis can be equivalently defined by a property on submatrices of the design matrix: X is in RIPn,p(k, θ) if and only if for any set S of k columns of X, the submatrix formed by taking any these columns is almost an isometry, i.e. if the spectrum of its Gram matrix is contained in the interval [1− θ, 1 + θ]:\n‖X>SXS − Ik‖op ≤ θ .\nDenote by ‖ · ‖op,k the k-sparse operator norm, defined for a matrix A as ‖A‖op,k = supx∈Sp(k) ‖Ax‖2. This yields another equivalent formulation of the RIP property: X ∈ RIPn,p(k, θ) if and only if\n‖X>X − Ip‖op,k ≤ θ . We assume in the following discussion that the distortion parameter θ is upperbounded by 1. For v ∈ Rp and T ⊆ {1, . . . , p}, we write vT for the #T -dimensional vector obtained by restricting v to coordinates indexed by T . Similarly, for an n × p matrix A and subsets S ⊆ {1, . . . , n} and T ⊆ {1, . . . , p}, we write AS∗ for the submatrix obtained by restricting A to rows indexed by S, A∗T for the submatrix obtained by restricting A to columns indexed by T ."
    }, {
      "heading" : "1.2 Generation via Random Design",
      "text" : "Matrices that satisfy the restricted isometry property have many interesting applications in high-dimensional statistics and compressed sensing. However, there is no known way to generate them deterministically in general, and it is even NP-hard to check whether a given matrix X belongs to RIPn,p(k, θ) (see, e.g Bandeira et al., 2012). Several deterministic constructions of RIP matrices exist for sparsity level k . θ √ n. For example, using equitriangular tight frames and Gershgorin’s circle theorem, one can construct RIP matrices with sparsity k ≤ √ n and distortion θ bounded away from 0 (see, e.g. Bandeira et al., 2012). The limitation k ≤ θ √ n is known as the ‘square root bottleneck’. To date, the only constructions that break the ‘square root bottleneck’ are due to Bourgain et al. (2011) and Bandeira, Mixon and Moreira (2014), both of which give RIP guarantee for k of order n1/2+ for some small > 0 and fixed θ (the latter construction is conditional on a number-theoretic conjecture being true).\nInterestingly though, it is easy to generate large matrices satisfying the restricted isometry property through random design, and compared to the fixed design matrices mentioned in the previous paragraph, these random design constructions are much less restrictive on the sparsity level, typically allowing k up to the order n/ log(p) (assuming θ is bounded away from zero). They can be constructed easily from any centred subGaussian distribution. We recall that a distribution (and its associated random variable) is said to be sub-Gaussian with parameter σ if ∫ R e λx dQ(x) ≤ eλ2σ2/2 for all λ ∈ R.\nDefinition 2. Define Q = Qσ to be the set of sub-Gaussian distributions Q over R with zero mean, unit variance, and sub-Gaussian parameter at most σ.\nThe most common choice for a Q ∈ Q is the standard normal distribution N (0, 1). Note that by Taylor expansion, for any Q ∈ Q, we necessarily have σ2 ≥ ∫ R x 2 dQ(x) = 1. In the rest of the paper, we treat σ as fixed. Define the normalized distribution Q̃ to be the distribution of Z/ √ n for Z ∼ Q. The following well-known result states that by concentration of measure, random matrices generated with distribution Q̃⊗(n×p) satisfy restricted isometries (see, e.g. Candès and Tao (2005) and Baraniuk et al. (2008)). For completeness, we include a proof that establishes these particular constants stated here. All proofs are deferred to Appendix A or Appendix B.\nProposition 1. Suppose X is a random matrix with distribution Q̃⊗(n×p), where Q ∈ Q. It holds that\nP ( X ∈ RIPn,p(k, θ) ) ≥ 1− 2 exp { k log ( 9ep\nk\n) − nθ 2\n256σ4\n} . (1)\nIn order to clarify the notion of asymptotic regimes used in this paper, we introduce the following.\nDefinition 3. For 0 ≤ α ≤ 1, define the asymptotic regime Rα := { (pn, kn, θn)n : p, k →∞ and n k1+αn log(pn)\nθ2n\n} .\nIt is an immediate consequence of (1) that for (p, k, θ) = (pn, kn, θn) ∈ R0 we have, limn→∞ Q̃ ⊗(n×p)(X ∈ RIPn,p(k, θ)) = 1."
    }, {
      "heading" : "2 Certification of Restricted Isometry",
      "text" : ""
    }, {
      "heading" : "2.1 Objectives and definition",
      "text" : "In practice, it is useful to know with certainty whether a particular realization of a random design matrix satisfies the RIP condition. It is known that the problem of deciding if a given matrix is RIP is NP-hard (Bandeira et al., 2012). However, NP-hardness is a only a statement about worst-case instances. It would still be of great use to have an algorithm that can correctly decide RIP property for an average instance of a design matrix, with some accuracy. Such an algorithm should identify a high proportion of RIP matrices generated through random design and make no false positive claims. We call such an algorithm an average-case certifier, or a certifier for short.\nDefinition 4 (Certifier). Given a parameter sequence (p, k, θ) = (pn, kn, θn), we define a certifier for Q̃⊗(n×p)-random matrices to be a sequence (ψn)n of measureable functions ψn : Rn×p → {0, 1}, such that\nψ−1n (1) ⊆ RIPn,p(k, θ) and lim sup n→∞\nQ̃⊗(n×p) ( ψ−1n (0) ) ≤ 1/3. (2)\nNote the definition of a certifier depends on both the asymptotic parameter sequence (pn, kn, θn) and the sub-Gaussian distribution Q. However, when it is clear from the context, we will supress the dependence and refer to certifiers for RIPn,p(k, θ) properties of Q̃⊗(n×p)-random matrices simply as ‘certifiers’.\nThe two defining properties in (2) can be understood as follows. The first condition means that if a certifier outputs 1, we know with certainty that the matrix is RIP. The second condition means that the certifier is not overly conservative; it is allowed to output 0 for at most one third (with respect to Q̃⊗(n×p) measure) of the matrices. The choice of 1/3 in the definition of a certifier is made to simplify proofs. However, all subsequent results will still hold if we replace 1/3 by any constant in (0, 1). In view of Proposition 1, the second condition in (2) can be equivalently stated as\nlim n→∞\nQ̃⊗(n×p) { ψn(X) = 1 ∣∣ X ∈ RIPn,p(k, θ)} ≥ 2/3 With such a certifier, given an arbitrary problem fitting the sparse linear model, the matrix X could be tested for the restricted isometry property, with some expectation of a positive result. This would be particularly interesting given a certifier in the parameter regime n θ2nk2n, in which presently known polynomial-time certifiers cannot give positive results.\nEven though it is not the main focus of our paper, we also note that a certifier ψ with the above properties for some distribution Q ∈ Q would form a certifier/distribution couple (ψ,Q), that yields in the usual manner a Las Vegas algorithm to generate RIP matrices. The (random) algorithm keeps generating random matrices X ∼ Q̃⊗(n×p) until ψn(X) = 1. The number of times that the certifier is invoked has a geometric distribution with success probability Q̃⊗(n×p) ( ψ−1n (1) ) . Hence, the Las Vegas algorithm runs in randomized polynomial time if and only if ψn runs in randomized polynomial time."
    }, {
      "heading" : "2.2 Certifier properties",
      "text" : "Although our focus is on algorithmically efficient certifiers, we establish first the properties of a certifier that is computationally intractable. This certifier serves as a benchmark\nfor the performance of other candidates. Indeed, we exhibit in the following proposition a certifier, based on the k-sparse operator norm, that works uniformly well in the same asymptotic parameter regime R0, where Q̃⊗(n×p)-random matrices are RIP with asymptotic probability 1. For clarity, we stress that our criterion when judging a certifier will always be its uniform performance over asymptotic regimes Rα for some α ∈ [0, 1].\nProposition 2. Suppose (p, k, θ) = (pn, kn, θn) ∈ R0. Furthermore, Let Q ∈ Q and X ∼ Q̃⊗(n×p). Then the sequence of tests (ψop,k)n based on sparse operator norms, defined by\nψop,k(X) = 1 { ‖X>X − Ip‖op,k ≤ θ } .\nis a certifier for Q̃⊗(n×p)-random matrices.\nBy a direct reduction from the clique problem, one can show that it is NP-hard to compute the k-sparse operator norm of a matrix. Hence the certifier ψop,k is computationally intractable. The next proposition concerns the certifier property of a test based on the maximum incoherence between columns of the design matrix. It follows directly from a well-known result on the incoherence parameter of a random matrix (see, e.g. Rauhut and Foucart (2013, Proposition 6.2)) and allows the construction of a polynomial-time certifier that works uniformly well in the asymptotic parameter regime R1.\nProposition 3. Suppose (p, k, θ) = (pn, kn, θn) satisfies n ≥ 196σ4k2 log(p)/θ2. Let Q ∈ Q and X ∼ Q̃⊗(n×p), then the tests ψ∞ defined by\nψ∞(X) = 1 { ‖X>X − Ip‖∞ ≤ 14σ2 √ log(p)\nn\n} ,\nis a certifier for Q̃⊗(n×p)-random matrices.\nProposition 3 shows that, when the sample size n is above k2 log(p)/θ2 in magnitude (in particular, this is satisfied asymptotically when (p, k, θ) = (pn, kn, θn) ∈ R1), there is a polynomial time certifier. In other words, in this high-signal regime, the average-case decision problem for RIP property is much more tractable than indicated by the worstcase result. On the other hand, the certifier in Proposition 3 works in a much smaller parameter range when compared to ψop,k in Proposition 2. Combining Proposition 2 and 3, we have the following schematic diagram (Figure 2.2). When the sample size is lower than specified in R0, the property does not hold, with high probability, and no certifier exists. A computationally intractable certifier works uniformly over R0. On the other end of the spectrum, when the sample size is large enough to be in R1, a simple\ncertifier based on the maximum incoherence of the design matrix is known to work in polynomial time. This leaves open the question of whether (randomized) polynomial time certifiers can work uniformly well in R0, or Rα for any α ∈ [0, 1). We will see in the next section that, assuming a weaker variant of the Planted Clique hypothesis from computational complexity theory, R1 is essentially the largest asymptotic regime where a randomized polynomial time certifier can exist."
    }, {
      "heading" : "3 Hardness of Certification",
      "text" : ""
    }, {
      "heading" : "3.1 Planted dense subgraph assumptions",
      "text" : "We show in this section that certification of RIP property is an average-case hard problem in the parameter regime Rα for any α < 1. This is precisely the regime not covered by Proposition 3. The average-case hardness result is proved via reduction to the planted dense subgraph assumption.\nFor any integer m ≥ 0, denote Gm the collection of all graphs on m vertices. We write V (G) and E(G) for the set of vertices and edges of a graph G. For H ∈ Gκ where κ ∈ {0, . . . ,m}, let G(m, 1/2, H) be the random graph model that generates a random graph G on m vertices as follows. It first picks κ random vertices K ⊆ V (G) and plants an isomorphic copy of H on these κ vertices, then every pair of vertices not in K×K is connected by an edge independently with probability 1/2. We write PH for the probability measure on Gm associated with G(m, 1/2, H). Note that if H is the empty graph, then G(m, 1/2, ∅) describes the Erdős–Rényi random graph. With slight abuse of notation, we write P0 in place of P∅. On the other hand, for ∈ (0, 1/2], if H belongs\nto the set\nH = Hκ, := { H ∈ Gκ : #E(H) ≥ (1/2 + )\nκ(κ− 1) 2\n} ,\nthen G(m, 1/2, H) generates random graphs that contain elevated local edge density. The planted dense graph problem concerns testing apart the following two hypotheses:\nH0 : G ∼ G(m, 1/2, ∅) and H1 : G ∼ G(m, 1/2, H) for some H ∈ Hκ, . (3)\nIt is widely believed that for κ = O(m1/2−δ), there does not exist randomized polynomial time tests to distinguish between H0 and H1 (see, e.g. Jerrum (1992); Feige and Krauthgamer (2003); Feldman et al. (2013)). More precisely, we have the following assumption.\nAssumption (A1) 1. Fix ∈ (0, 1/2] and δ ∈ (0, 1/2). let (κm)m be any sequence of integers such that κm → ∞ and κm = O ( m1/2−δ ) . For any sequence of randomized polynomial time tests (φm : Gm → {0, 1})m, we have\nlim inf m\n{ P0 ( φ(G) = 1 ) + max H∈Hκ, PH ( φ(G) = 0) )} > 1/3 .\nWe remark that if = 1/2, then Hκ, contains only the κ-complete graph and the testing problem becomes the well-known planted clique problem (cf. Jerrum (1992) and references in Berthet and Rigollet (2013a,b)).\nThe difficulty of this problem has been used as a primitive for hardness of other tasks, such as cryptographic applications, in Juels and Peinado (2000), testing for kwise dependence in Alon et al. (2007), approximating Nash equilibria in Hazan and Krauthgamer (2011). In this case, Assumption (A1) is a version of the planted clique hypothesis (see, e.g. Berthet and Rigollet (2013b, Assumption APC)). We emphasize that Assumption A1 is significantly milder than the planted clique hypothesis (since it allows any ∈ (0, 1/2]), or that an hypothesis on planted random graphs. We also note that when κ ≥ C √ m, spectral methods can be used to detect such graphs with high probability. Indeed, when G contains a graph of H, AG−11>/2 has a leading eigenvalue greater than (κ− 1), whereas it is of order √ m for a usual Erdős–Rényi random graph.\nThe following theorem relates the hardness of the planted dense subgraph testing problem to the hardness of certifying restricted isometry of random matrices. We recall that the distribution of X is that of an n× p random matrix with entries independently and identically sampled from Q̃ d = Q/ √ n, for some Q ∈ Q. We also write Ψrp for the class of randomized polynomial time certifiers.\nTheorem 4. Assume (A1) and fix any α ∈ [0, 1). Then there exists a sequence (p, k, θ) = (pn, kn, θn) ∈ Rα, such that there is no certifier/distribution couple (ψ,Q) ∈ Ψrp ×Q with respect to this sequence of parameters.\nOur proof of Theorem 4 relies on the following ideas: Given a graph G, instance of the planted clique problem in the assumed hard regime, we construct n random vectors based on the adjacency matrix of a bipartite subgraph of G, between two random sets of vertices. Each coefficient of these vectors is then randomly drawn from one of two carefully chosen distributions, conditionally on the presence or absence of a particular edge. This construction ensures that if the graph is an Erdős–Rényi random graph (i.e. with no planted graph), the vectors are independent with independent coefficients, with distribution Q̃. Otherwise, we show that with high probability, the presence of an unusually dense subgraph will make it very likely that the matrix does not satisfy the restricted isometry property, for a set of parameters in Rα. As a consequence, if there existed a certifier/distribution couple (ψ,Q) ∈ Ψrp×Q in this range of parameters, it could be used - by using as input in the certifier the newly constructed matrix - to determine with high probability the distribution of G, violating our assumption (A1).\nWe remark that this result holds for any distribution in Q, in contrast to computational lower bounds in statistical learning problems, that apply to a specific distribution. For the sake of simplicity, we have kept the coefficients of X identically distributed, but our analysis is not dependent on that fact, and our result can be directly extended to the case where the coefficients are independent, with different distributions in Q.\nTheorem 4 may be viewed as providing an asymptotic lower bound of the sample size n for the existence of a computationally feasible certifier. It establishes this computational lower bound by exhibiting some specific ‘hard’ sequences of parameters inside Rα and shows through a reduction to the planted dense subgraph problem. All hardness results, whether in a worst-case (NP-hardness, or other) or the average-case (by reduction from a hard problem), are by nature statements on the impossibility of accomplishing a task in a computationally efficient manner, uniformly over a range of parameters. They are therefore always based on the construction of a ‘hard’ sequence of parameters used in the reduction, for which a contradiction is shown. Here, the ‘hard’ sequence is explicitly constructed in the proof to be some (p, k, θ) = (pn, kn, θn) satisfying p ≥ n and n1/(3−α−4β) k n1/(2−β)−δ, for β ∈ [0, (1 − α)/3) and any small δ > 0. The tuning parameter β is to allow additional flexibility in choosing these ‘hard’ sequences. More precisely, using an averaging trick first seen in Ma and Wu (2013), we are able to show that the existence of such ‘hard’ sequences is not confined only in the sparsity regime k n1/2 . We note that in all our ‘hard’ sequences, θn must depend on n. An interesting extension is to see if similar computational lower bounds hold when restricted to a subset\nof Rα where θ is constant."
    }, {
      "heading" : "A Proofs of Main Results",
      "text" : "Proof of Theorem 4. We prove by contradiction. Assume the contrary, that (ψn)n is a polynomial time computable certifier for Q̃⊗(n×p)-random matrices. Let ξ denote the median of Q̃. By definition of the median, there exists a unique decomposition of the probability measure Q̃ as Q̃ = 1\n2 Q̃+ + 1 2 Q̃−, where Q̃+ and Q̃− are probability measures\nsupported on (−∞, ξ] and [ξ,∞) respectively. For α < 1 and 0 ≤ β < 1\n3 (1 − α), let (p, k, θ) = (pn, kn, θn) ∈ Rα be a sequence\nsatisfying p ≥ n, n 1 3−α−4β k n 1 2−β−δ for some δ > 0. Let L = 10 and ` = bkβc. Define m = L`n and κ = Lk. We check that\nκ2 k2−βkβ n1−δ` ≈ m1−δ′\nfor some positive δ′ that depends on δ only. We prove below that Algorithm 1, which runs in randomized polynomial time, can distinguish between P0 and PH with zero asymptotic error for any choice of H ∈ Hκ, .\nFirst, assume G ∼ P0. Then matrix A from Step 1 of Algorithm 1 have independent Rademacher entries, which implies that X ∼ Q̃⊗(n×p). Therefore, by (2) in Section 2 we must have\nP0(φ(G) = 1) = Q̃ ⊗(n×p)(ψ−1n (0))→ 0.\nNext, assume G is generated with probability measure PH for some H ∈ Hκ, . We claim that\nX̃ /∈ RIPn,n ( k, ck2\nn`2\n) (4)\nfor some absolute positive constant c. Since\nk2 n`2 √ k1+α n θ,\nwe have that for large n, X̃ /∈ RIPn,n(k, θ). Hence X is a fortiori not an RIPn,p(k, θ) matrix. As a result,\nlim inf m max H∈Hκ,\nPH ( φ(G) = 0) ) < 1/3,\ncontradicting Hypothesis AH . It remains to verify the claimed result in (4). LetK ⊆ V (G) be the κ-subset of vertices on which the subgraph H is planted. We write U = {u1, . . . , uN} and W = {w1, . . . , wN}\nAlgorithm 1: Pseudo-code for an algorithm to distinguish between P0 and PH .\nInput: m ∈ N, κ ∈ {1, . . . ,m}, G ∈ Gm, L ∈ N begin\nStep 1: Let N ← bm/Lc, `← bkβc, n← bN/`c, p← pn, k ← bκ/Lc. Draw u1, . . . , uN , w1, . . . , wN uniformly at random without replacement from V (G). Form A = (Aij) ∈ RN×N where Aij = 2 · 1{ui∼wj} − 1. Step 2: Let Y + = (Y +ij ) and Y\n− = (Y −ij ) be N -by-N random matrices independent from all other random variables and from each other, and such that Y +ij i.i.d.∼ Q̃+ and Y −ij\ni.i.d.∼ Q̃−. Define Z = (Zij) by Zij = 1{Aij = 1}Y +ij + 1{Aij = −1}Y −ij . Step 3: For 0 ≤ a, b ≤ `− 1, define Z(a,b) ∈ Rn×n by Z(a,b)i,j = Zan+i,bn+j. Define X̃ ← `−1 ∑ 0≤a,b<` Z (a,b). Finally, let X ← ( X̃ X̃ ′ ) where X̃ ′ ∈ Rn×(p−n) has entries independently drawn from distribution Q̃. Step 4: Let φ(G)← 1− ψn(X).\nend\nOutput: φ(G)\nfor the two random subsets of vertices. Let NU,W ;K be the random variable counting the number of edges in G with two endpoints in U ∩K and W ∩K respectively. Then\nNU,W ;K = # { {u,w} ∈ E(G) : u ∈ U ∩K,w ∈ W ∩K } = ∑ u∈K ∑ w∈K 1{u ∈ U}1{w ∈ W}1{u ∼ w}.\nDefine\nΩ1 := { NU,W ;K ≥ ( 1\n2 + 4\n) k2 } ∩ {∣∣#U ∩K − k∣∣ ≤\n8 k\n} ∩ {∣∣#W ∩K − k∣∣ ≤\n8 k\n} .\nLemma 5 below shows that Ω1 has asymptotic probability 1. Note Ω1 is in the σ-algebra of (U,W ). Let U = U0 and W = W0 be any realization satisfying Ω1. We write PU0,W0 and EU0,W0 as shorthand for the probability and expectation conditional on U = U0 and W = W0.\nFor each j ∈ {1, . . . , n}, define sj := ∑\nui∈U∩K Ai,j. Write k1 := (1 − /8)k and k2 = (1+ /8)k. Let S := {i : ui ∈ U∩K}, and let T be a subset of k1 indices in {1, . . . , n}\ncorresponding to the k1 largest values of sj (breaking ties arbitrarily). Note that S and T are functions of U and V . On the event U = U0 and W = W0, both #S = #U ∩K and #W ∩ K are bounded in the interval [k1, k2], so in particular k1 ≤ #W ∩ K. We have∑ wj∈W∩K sj = 2NU,W ;K −#(U ∩K)×#(W ∩K) ≥ { (1 + /2)− (1 + /8)2 } k2 ≥ 5 k2.\nAs elements of T index columns of A corresponding to largest values of sjs, we have that on event {U = U0,W = W0},∑\nj∈T\nsj ≥ #T\n#W ∩K 5 k2 ≥ 5 k2k1 k2 ≥ 6 kk1. (5)\nDefine the unit vector v ∈ Rn by vT = k−1/21 1k1 and vT c = 0. Note that v is k1-sparse and hence also k-sparse. Conditional on U = U0 and W = W0, Zij = Y + ij if Aij = 1 and Zij = Y − ij if Aij = −1. By definition of Q̃+ and Q̃−, and the fact that Q̃ is not a point\nmass, we have EY +ij = −EY −ij = c1/ √ n for some absolute constant c1 > 0. By (5), the sum ∑\ni∈S,j∈T Zij can be bounded below in conditional expectation by\nEU0,W0 ∑\ni∈S,j∈T Zij ≥ EU0,W0 ( ∑ i∈S,j∈T (1{Aij = 1}Y +ij + 1{Aij = −1}Y −ij ) )\n= c1√ n (∑ j∈T sj ) ≥ c1√ n 6 kk1 .\nBy Lemma 7, both Y +ij − EY +ij and Y −ij − EY −ij are sub-Gaussian with parameter at most c2σ/ √ n for some absolute constant c2 > 0. By Hoeffding’s inequality for sums of sub-Gaussian random variables (see e.g. Vershynin (2012, Proposition 5.10)),\nPU0,W0 ( ∑ i∈S,j∈T Zij > c1 12 √ n kk1 ) ≥ 1− 2 exp { − ( c1 12 √ n kk1) 2 2c22σ 2k1k2k/n } → 1. (6)\nBy (6) and the fact that P(Ω1)→ 1, the event\nΩ2 := { ∑ i∈S,j∈T Zij ≥ c1 kk1 12 √ n } has asymptotic probability 1.\nNow define\nS̃ = {i ∈ {1, . . . , n} : uan+i ∈ U ∩K for some 0 ≤ a ≤ `− 1} T̃ = {j ∈ {1, . . . , n} : wbn+j ∈ W ∩K for some 0 ≤ b ≤ `− 1}\nAlso, define v(b) = (vbn+1, . . . , vbn+n) > for 0 ≤ b ≤ ` − 1, ṽsum = ∑ 0≤b≤`−1 v (b) and ṽ = ṽsum/‖ṽsum‖2. By Lemma 10, we have ‖ṽsum‖∞ ≤ c2k−1/21 with asymptotic probability 1 for some c2 depending on β only. Hence ‖ṽsum‖2 ≤ c2. Thus, by Cauchy–Schwarz inequality, we have with asymptotic probability 1,\n‖X̃S̃∗ṽ‖2 ≥ ‖ṽsum‖ −1 2 ‖ṽ‖ −1/2 0 ‖X̃S̃∗ṽsum‖1 ≥ ‖ṽ‖ −1 2 ‖ṽ‖ −1/2 0\n1\n` √ k1 ∑ i∈S,j∈T Zij ≥ c3 k ` √ n .\nOn the other hand, the submatrix X̃S̃c∗ has independent and identically distributed entries. By Vershynin (2012, Lemma 5.9), for i ∈ S̃c and 1 ≤ j ≤ n, X̃ij = `−1 ∑`−1 a,b=0 Z (a,b) an+i,bn+j\nis a centred sub-Gaussian random variable with sub-Gaussian parameter σ/ √ n and variance 1/n. Let X̃i denote the ith row vector of the matrix X̃, then X̃ > i ṽ is also a centred\nsub-Gaussian random variable with parameter σ/ √ n and variance 1/n. Using Lemma 9, we have\nP ( ‖X̃Sc∗ṽ‖22 −\nn−#S̃ n ≤ −\n√ log n\nn−#S̃\n) ≤ exp { − log n\n64σ4\n} → 0.\nSince #S̃ ≤ k2 with asymptotic probability 1, the event\nΩ3 := { ‖X̃S̃c∗ṽ‖ 2 2 ≥ 1− k2 n − √ 2 log n n } has asymptotic probability 1. Finally, since X̃ṽ = (X̃S̃∗ṽ, X̃S̃c∗v) >, on Ω2 ∩ Ω3,\n‖X̃ṽ‖22 = ‖X̃S̃∗ṽ‖ 2 2 + ‖X̃S̃c∗v‖ 2 2 ≥ 1 +\nc23 2k2 `2n − k2 n − √ 2 log n n .\nThe right hand side is at least 1 + ck2/n for some absolute positive constant c for all large values of n. This verifies (4) and concludes the proof.\nLemma 5. Let G be a graph on m vertices and K a κ-subset of V (G), such that the edge density of G restricted to K is at least 1/2 + . Let n, p be integers less than m/2. Choose u1, . . . , un and w1, . . . , wp independently at random without replacement from V (G). Denote U = {u1, . . . , un} and W = {w1, . . . , wp}. Define NU,W ;K to be\nthe number of edges with two endpoints in U and W respectively. Then for m,n, p, κ sufficiently large.\nP {∣∣∣∣#U ∩K − nκm ∣∣∣∣ ≤ 8 nκm } ≤ 8 √ m nκ ,\nP {∣∣∣∣#W ∩K − pκm ∣∣∣∣ ≤ 8 pκm } ≤ 8 √ m pκ ,\nP { NU,W ;K ≥ ( 1\n2 + 4\n) npκ2\nm2\n} ≤ 4 √ m(pκ+ nκ+m)\nnpκ2 .\nProof. The cardinality of U ∩K has HyperGeom(m,κ, n) distribution. Hence\nE(#U ∩K) = nκ m and var(#U ∩K) = n κ m m− κ m m− n m− 1 ≤ nκ m .\nThe first inequality in the lemma now follows from an application of Chebyshev’s inequality. A similar argument establishes the second inequality. For the final inequality in the lemma, we have that for κ sufficiently large,\nE(NU,W ;K) = ∑ u∈K ∑ w∈K P(u ∈ U,w ∈ W )1{v ∼ w}\n= np m(m− 1) ∑ u∈K ∑ w∈K 1{u ∼ w} ≥ (1 2 + )npκ(κ− 1) m(m− 1) ≥ (1 2 + 2 )npκ2 m2 ..\nWe then compute the variance of NU,W ;K by\nvar(NU,W ;K) = cov (∑ u∈K ∑ w∈K 1{u ∈ U,w ∈ W,u ∼ w}, ∑ u′∈K ∑ w′∈K 1{u′ ∈ U,w′ ∈ W,u′ ∼ w′} )\n= ∑\nu,w,u′,w′∈K\ncov ( 1{u ∈ U,w ∈ W,u ∼ w},1{u′ ∈ U,w′ ∈ W,u′ ∼ w′} ) =: I + II + III + IV,\nwhere the four terms I, II, III and IV handle sums over subsets of indices {(u,w, u′, w′) ∈ K4 : u 6= u′, w 6= w′}, {(u,w, u′, w′) ∈ K4 : u = u′, w 6= w′}, {(u,w, u′, w′) ∈ K4 : u 6= u′, w = w′} and {(u,w, u′, w′) ∈ K4 : u = u′, w = w′} respectively.\nWe bound the four terms separately. For the first term, we have I = ∑\nu,u′,w,w′ distinct\n{ P(u, u′ ∈ U,w,w′ ∈ W )− P(u ∈ U,w ∈ W )P(u′ ∈ U,w′ ∈ W ) } 1{v ∼ w}1{u′ ∼ w′}\n= ∑\nu,u′,w,w′ distinct\n{ n(n− 1)p(p− 1) m(m− 1)(m− 2)(m− 3) − (\nnp\nm(m− 1)\n)2} 1{u ∼ w}1{u′ ∼ w′}.\nWhen m > max(2n, 2p), the term in bracket above is non-positive, hence I ≤ 0. For the second term, we get that\nII = ∑\nu,w,w′ distinct\n{ P(u ∈ U,w,w′ ∈ W )− P(u ∈ U,w ∈ W )P(u ∈ U,w′ ∈ W ) } 1{u ∼ w}1{u′ ∼ w′}\n= ∑\nu,w,w′ distinct\n{ np(p− 1) m(m− 1)(m− 2) − (\nnp\nm(m− 1)\n)2} 1{u ∼ w}1{u ∼ w′}\n≤ np(p− 1) m(m− 1)(m− 2) ∑ u,w,w′ distinct 1{u ∼ w}1{u ∼ w′} ≤ np 2κ3 m3 .\nSimilarly, we have\nIII ≤ n(n− 1)pκ(κ− 1)(κ− 2) m(m− 1)(m− 2) ≤ n 2pκ3 m3 .\nAnd finally, IV = ∑\nu,w distinct\n{ P(u ∈ U,w ∈ W )−P(u ∈ U,w ∈ W )2 } 1{u ∼ w} ≤ npκ(κ− 1)\nm(m− 1) ≤ npκ\n2\nm2 .\nSum up the four terms, we get that\nvar(NU,W ;K) ≤ npκ2\nm2\n( pκ\nm + nκ m + 1\n) .\nBy Chebyshev’s inequality, we get that\nP { NU,W ;K ≥ ( 1\n2 + 4\n) npκ2\nm2\n} ≤ 4 √ m(pκ+ nκ+m)\nnpκ2 ,\nas desired."
    }, {
      "heading" : "B Auxiliary Results",
      "text" : "Proof of Proposition 1. Let Xi denote the ith row vector of X. Then for any fixed u ∈ Sp(k),\nEeλ(X>i u) = ∏\n1≤j≤p EeλXijuj ≤ ∏ j eλ 2u2j/(2σ 2n) = eλ 2/(2σ2n).\nApply Lemma 9 to ‖Xu‖22− 1 = n−1 ∑n i=1 { ( √ nX>i u) 2−E( √ nX>i u) 2 }\n, and use the fact that θ/(8σ2) ≤ 1, we have\nP ( 1− θ ≤ ‖Xu‖22 ≤ 1 + θ ) ≥ 1− 2e−nθ2/(64σ4).\nWe claim that there is a set N of cardinality at most ( p k ) 9k such that\nsup u∈Sp(k) ∣∣‖Xu‖22 − 1∣∣ ≤ 2 sup u∈N ∣∣‖Xu‖22 − 1∣∣ (7) Given (7), by union bound, we have\nP(X ∈ RIP(k, θ)) = P (\nsup u∈Sp(k) ∣∣‖Xu‖22 − 1∣∣ ≤ θ) ≥ P(sup u∈N ∣∣‖Xu‖22 − 1∣∣ ≤ θ/2) ≥ 1− 2 ( p\nk\n) 9ke−nθ 2/(256σ4) ≥ 1− 2 exp { k log ( 9ep\nk\n) − nθ 2\n256σ4\n} ,\nas desired. It remains to verify Claim (7). For any cardinality k subset J ⊆ {1, . . . , p}, let BJ = {u ∈ Sp(k) : uJc = 0}. Each BJ contains a 1/4-net, NJ , of cardinality at most 9k (Vershynin, 2012, Lemma 5.2). Then N := ∪JNJ form a 1/4-net for Sp(k). Define uJ ∈ argmaxu∈BJ‖Xu‖\n2 and let vJ be an element in NJ closest in Euclidean distance to uJ . Define A := X >X − Ip. We have\n|u>JAuJ | ≤ |v>J AvJ |+ |(uJ − vJ)>AvJ |+ |u>JA(uJ − vJ)| ≤ max u∈NI |u>Au|2 + 1 2 |u>JAuJ |.\nHence sup\nu∈Sp(k) |u>Au| ≤ 2 max u∈N |u>Au|,\nwhich verifies the claim.\nProof of Proposition 2. By definition, ‖X>X−Ip‖op,k ≤ θ is equivalent toX ∈ RIPn,p(k, θ). Moreover, by Proposition 1, X ∈ RIPn,p(k, θ) with probability converging to 1, under Q̃⊗(n×p). The certifier hence satisfies the two desired properties.\nProof of Proposition 3. The proposed certifier is clearly polynomial time computable (it has time complexity O(n2p)). To verify that it is a certifier, we check that (i) ψ−1n (1) ⊆ RIPn,p(k, θ) and (ii) limn→∞ Q̃ ⊗(n×p)(ψ−1n (1)) > 2/3.\nFor (i), on the event ‖X>X − Ip‖∞ ≤ 14σ2 √ log p n , for any index set T ∈ {1, . . . , p} of\ncardinality k, we have ‖X>∗TX∗T − Ik‖∞ ≤ 14σ2 √ log p n , which implies that\n‖X>∗TX∗T − Ik‖op ≤ 14σ2k √ log p\nn ≤ θ\nFor (ii), let Yn ∼ χ2n. Using Lemma 9 and fact that for any A ∈ Rp×p\n‖A‖∞ = sup S⊆{1,...,p},#S=2 ‖ASS‖∞ ≤ sup S⊆{1,...,p},#S=2 ‖ASS‖op = ‖A‖op,2\nwe get P { ‖X>X − Ip‖∞ ≤ 14σ2 √ log p\nn\n} ≥ P { sup\nu∈Sp(2)\n∣∣‖Xu‖22 − 1∣∣ ≤ 14σ2√ log pn }\n≥ 1− 2 ( p\n2\n) 92 exp { − n\n64σ4 196σ4 log p n } ≥ 1− 81p2 exp{−3 log p} → 1.\nas desired.\nLemma 6. Let Z be a non-negative random variable and r ≥ 2, then\nE(Zr) ≥ E(|Z − EZ|r)."
    }, {
      "heading" : "In other words, centring a nonnegative random variable shrinks its second or higher absolute moments.",
      "text" : "Proof. Let µ := E(Z) and define Y = Z − µ. Let P denote the probability measure on R associated with random variable Y . Hence ∫ [−µ,∞) y dP (y) = 0. Without loss\nof generality, we may assume that Z is not a point mass. Then ∫ [−µ,0](−y) dP (y) =∫\n(0,∞) y dP (y) = A for some A > 0. For any measureable function f : R → [0,∞), we may write\nA ∫ [−µ,∞) f(y) dP (y) = ∫ [−µ,0] (−v) dP (v) ∫ (0,∞) f(u) dP (u) + ∫ (0,∞) u dP (u) ∫ [−µ,0] f(v)dP (v)\n= ∫ u∈(0,∞) ∫ v∈[−µ,0] ( u u− v f(v)− v u− v f(u) ) (u− v) dP (v) dP (u).\n(8)\nLet (U, V ) be a bivariate random vector having probability measure\n1 A (u− v)1(0,∞)(u)1[−µ,0](v) dP (u) dP (v)\non R2 (that this is a probability measure follows from substituting f(y) ≡ 1 in (8)). Then (8) can be rewritten as\nE { f(Y ) } = E\n{ U\nU − V f(V )− V U − V f(U)\n} .\nNow consider choosing f to be f1(y) = |y|r and f2(y) = (y+ b)r respectively in the above equation. Note that for u ∈ (0,∞) and v ∈ [−µ, 0] and r ≥ 2, we always have\nuf2(v)− vf2(u) ≥ −vf2(u) ≥ −v(u− v)r ≥ (−v)ru+ (−v)ur ≥ uf1(v)− vf1(u).\nTherefore,\nE(|Y |m) = E { U\nU − V f1(V )−\nV\nU − V f1(U) } ≤ E { U\nU − V f2(V )−\nV\nU − V f2(U)\n} = E(|Y + b|m),\nas desired.\nLemma 7. Suppose X is a sub-Gaussian random variable with parameter σ and median ξ. Let X+ = X | X ≥ ξ and X− = X | X < ξ. Then X+ − EX+ and X− − EX− are both sub-Gaussian with parameters are most cσ for some absolute constant c.\nProof. By Vershynin (2012, Lemma 5.5), X is sub-Gaussian with parameter σ implies that (E|X|p)1/p ≤ c1σ √ p for some absolute constant c1. Hence by Lemma 6, we have\nE (∣∣X+ − EX+∣∣p)1/p ≤ (E∣∣X+∣∣p)1/p = 2(E∣∣X1{X ≥ ξ}∣∣p)1/p ≤ 2c1σ√p.\nUsing Vershynin (2012, Lemma 5.5) again, we have that X+ − EX+ is sub-Gaussian with parameter at most cσ for some absolute constant c. A similar argument holds for X− − EX−.\nLemma 8. Suppose X is a random variable satisfying EeλX ≤ eσ2λ2/2 for all λ ∈ R. Define Y = X2 − EX2. Then EeλY ≤ e16σ4λ2 for all |λ| ≤ 1\n4σ2 .\nProof. By Markov’s inequality, P(|X| ≥ t) = P(X ≥ t)+P(−X ≥ t) = e−t2/σ2E ( etX/σ 2) +e−t 2/σ2E ( e−tX/σ 2) ≤ 2e−t2/(2σ2). From Lemma 6, for r ≥ 2\nE(|Y |r) ≤ E(|X|2r) = ∫ ∞ 0 P(|X| ≥ t)(2r)t2r−1 dt ≤ ∫ ∞ 0 4rt2r−1e−t 2/(2σ2) dt = 2(2σ2)rΓ(r+1).\nConsequently, if |2σ2λ| ≤ 1/2, then\nEeλY = ∞∑ r=0 λrEY r r! ≤ 1 + 2 ∞∑ r=2 (2σ2λ)r ≤ 1 + 16σ4λ2 ≤ e16σ4λ2 ,\nas desired.\nLemma 9. Let X1, X2, . . . , Xn be independent sub-Gaussian random variables with subGaussian parameters at most σ. Let Yi := X 2 i − EX2i . Then\nP ( n∑ i=1 Yi ≥ θ ) ≤ exp { − ( θ2 64nσ4 ∧ θ 8σ2 )} P ( n∑ i=1 Yi ≤ −θ ) ≤ exp { − θ 2 64nσ4\n} Proof. Using Markov’s inequality, we have\nP ( n∑ i=1 Yi ≥ θ ) = P ( eλ ∑ i Yi ≥ eλθ ) ≤ e−λθ ∏ i EeλYi .\nSet λ = θ 32nσ4 ∧ 1 4σ2 . By Lemma 8, we have P ( n∑ i=1 Yi ≥ θ ) ≤ e−λθ+16λ2nσ4 ≤ e−λθ/2,\nwhich establishes the first desired inequality. Applying the same argument with −Yi in place of Yi we get\nP ( n∑ i=1 Yi ≤ −θ ) ≤ exp { − ( θ2 64nσ4 ∧ θ 8σ2 )} . (9)\nTaylor expand the moment generating function of Xi around 0, we have EX2i ≤ σ2. Hence we may assume θ ≤ nσ2. Then we have\nθ2\n64nσ4 <\nθ\n8σ2 ,\nwhich together with (9) implies the desired result.\nLemma 10. Suppose n` balls are arranged in an array of n rows and ` columns and k balls (k < n) are chosen uniformly at random. Let Vi be the number of chosen balls in row i and V = (V1, . . . , Vn) >. Then\nP ( ‖V ‖0 ≤ k − k2 2n − √ k log k ) ≤ 1 k2 .\nMoreover, if k ≤ nγ for some γ < 1, then P ( ‖V ‖∞ ≥ a ) ≤ n1−a(1−γ) ( 1− n−(1−γ) ) .\nProof. Let Ui be the number of balls chosen in row i when balls are drawn with replacement from the array and U = (U1, . . . , Un)\n>. Then ‖V ‖0 is stochastically larger than ‖U‖0 and ‖V ‖∞ is stochastically smaller than ‖U‖0. So it suffices to show the desired inequalities with U replacing V . In the following argument, we consider only drawing with replacement.\nLet X = {e1, . . . , en} where ei denotes the ith standard basis vector in Rn. For 1 ≤ r ≤ k, let Xr be uniformly distributed in X . Then U d = ∑k\nr=1Xr. We note that changing the value of any one Xr affects the value of ‖U‖0 by at most 1. By McDiarmid’s inequality (McDiarmid, 1989), we have that for any t > 0,\nP ( ‖U‖0 − E‖U‖0 ≤ −t ) ≤ e− 2t2 k . (10)\nFor 1 ≤ i ≤ n. Define Ji = 1{no ball is chosen in row i}, then\nE‖U‖0 = n− n∑ i=1 EJi = n− n(1− 1/n)k ≥ k ( 1− k 2n ) .\nThus, together with (10), we have P ( ‖U‖0 ≤ k − k2 2n − √ k log k ) ≤ P ( ‖U‖0 − E‖U‖0 ≤ − √ k log k ) ≤ e−2 log k = k−2,\nas desired. For the second inequality, we have by union bound that\nP(‖U‖∞ ≥ a) ≤ nP(U1 ≥ a) = n k∑ s=a ( k s ) n−s\n≤ n ∞∑ s=a (k/n)s = n (k/n)a 1− k/n ≤ n1−a(1−γ)(1− n−(1−γ)),\nas desired."
    } ],
    "references" : [ {
      "title" : "Testing k-wise and almost k-wise independence",
      "author" : [ "N. Alon", "A. Andoni", "T. Kaufman", "K. Matulef", "R. Rubinfeld", "N. Xie" ],
      "venue" : "Proceedings of the Thirty-ninth ACM STOC",
      "citeRegEx" : "Alon et al\\.,? \\Q2007\\E",
      "shortCiteRegEx" : "Alon et al\\.",
      "year" : 2007
    }, {
      "title" : "Label optimal regret bounds for online local learning",
      "author" : [ "P. Awasthi", "M. Charikar", "K.A. Lai", "A. Risteki" ],
      "venue" : "J. Mach. Learn. Res. (COLT),",
      "citeRegEx" : "Awasthi et al\\.,? \\Q2015\\E",
      "shortCiteRegEx" : "Awasthi et al\\.",
      "year" : 2015
    }, {
      "title" : "Certifying the restricted isometry property is hard",
      "author" : [ "A.S. Bandeira", "E. Dobriban", "D.G. Mixon", "W.F. Sawin" ],
      "venue" : "IEEE Trans. Information Theory,",
      "citeRegEx" : "Bandeira et al\\.,? \\Q2012\\E",
      "shortCiteRegEx" : "Bandeira et al\\.",
      "year" : 2012
    }, {
      "title" : "A conditional construction of restricted isometries",
      "author" : [ "A.S. Bandeira", "D.G. Mixon", "J. Moreira" ],
      "venue" : null,
      "citeRegEx" : "Bandeira et al\\.,? \\Q2014\\E",
      "shortCiteRegEx" : "Bandeira et al\\.",
      "year" : 2014
    }, {
      "title" : "A simple proof of the restricted isometry property for random matrices",
      "author" : [ "R. Baraniuk", "M. Davenport", "R. DeVore", "M. Wakin" ],
      "venue" : "Constructive Approximation,",
      "citeRegEx" : "Baraniuk et al\\.,? \\Q2008\\E",
      "shortCiteRegEx" : "Baraniuk et al\\.",
      "year" : 2008
    }, {
      "title" : "Detection of Planted Solutions for Flat Satisfiability Problems",
      "author" : [ "Q. Berthet", "J.S. Ellenberg" ],
      "venue" : null,
      "citeRegEx" : "Berthet and Ellenberg,? \\Q2015\\E",
      "shortCiteRegEx" : "Berthet and Ellenberg",
      "year" : 2015
    }, {
      "title" : "Optimal detection of sparse principal components in high dimension",
      "author" : [ "Q. Berthet", "Rigollet P" ],
      "venue" : "Ann. Statist.,",
      "citeRegEx" : "Berthet and P.,? \\Q2013\\E",
      "shortCiteRegEx" : "Berthet and P.",
      "year" : 2013
    }, {
      "title" : "Complexity theoretic lower bounds for sparse principal component detection",
      "author" : [ "Q. Berthet", "Rigollet P" ],
      "venue" : "J. Mach. Learn. Res. (COLT),",
      "citeRegEx" : "Berthet and P.,? \\Q2013\\E",
      "shortCiteRegEx" : "Berthet and P.",
      "year" : 2013
    }, {
      "title" : "Detecting High Log-Densities an O(n) Approximation for Densest k-Subgraph",
      "author" : [ "A. Bhaskara", "M. Charikar", "E. Chlamtac", "U. Feige", "A. Vijayaraghavan" ],
      "venue" : "Proceedings of the forty-second ACM symposium on Theory of computing,",
      "citeRegEx" : "Bhaskara et al\\.,? \\Q2010\\E",
      "shortCiteRegEx" : "Bhaskara et al\\.",
      "year" : 2010
    }, {
      "title" : "Noise-tolerant learning, the parity problem, and the statistical query model",
      "author" : [ "A. Blum", "A. Kalai", "H. Wasserman" ],
      "venue" : "Journal of the ACM,",
      "citeRegEx" : "Blum et al\\.,? \\Q2003\\E",
      "shortCiteRegEx" : "Blum et al\\.",
      "year" : 2003
    }, {
      "title" : "Iterative hard thresholding for compressed sensing",
      "author" : [ "T. Blumensath", "M.E. Davies" ],
      "venue" : "Applied and Computational Harmonic Analysis,",
      "citeRegEx" : "Blumensath and Davies,? \\Q2009\\E",
      "shortCiteRegEx" : "Blumensath and Davies",
      "year" : 2009
    }, {
      "title" : "Explicit constructions of RIP matrices and related problems",
      "author" : [ "J. Bourgain", "S. Dilworth", "K. Ford", "S. Konyagin" ],
      "venue" : "Duke Math. J.,",
      "citeRegEx" : "Bourgain et al\\.,? \\Q2011\\E",
      "shortCiteRegEx" : "Bourgain et al\\.",
      "year" : 2011
    }, {
      "title" : "The restricted isometry property and its implications for compressed sensing",
      "author" : [ "E.J. Candès" ],
      "venue" : "Comptes Rendus Mathematique,",
      "citeRegEx" : "Candès,? \\Q2008\\E",
      "shortCiteRegEx" : "Candès",
      "year" : 2008
    }, {
      "title" : "Robust uncertainty principles: Exact signal reconstruction from highly incomplete frequency information",
      "author" : [ "E.J. Candès", "J. Romberg", "T. Tao" ],
      "venue" : "IEEE Trans. Inform. Theory,",
      "citeRegEx" : "Candès et al\\.,? \\Q2006\\E",
      "shortCiteRegEx" : "Candès et al\\.",
      "year" : 2006
    }, {
      "title" : "Stable signal recovery from incomplete and inaccurate measurements",
      "author" : [ "E.J. Candès", "J.K. Romberg", "T. Tao" ],
      "venue" : "Communications on pure and applied mathematics,",
      "citeRegEx" : "Candès et al\\.,? \\Q2006\\E",
      "shortCiteRegEx" : "Candès et al\\.",
      "year" : 2006
    }, {
      "title" : "Decoding by Linear Programming",
      "author" : [ "Candès E. J", "T. Tao" ],
      "venue" : "IEEE Trans. Inform. Theory,",
      "citeRegEx" : "J. and Tao,? \\Q2005\\E",
      "shortCiteRegEx" : "J. and Tao",
      "year" : 2005
    }, {
      "title" : "Near-optimal signal recovery from random projections: Universal encoding strategies",
      "author" : [ "Candès E. J", "T. Tao" ],
      "venue" : "IEEE Trans. Inform. Theory,",
      "citeRegEx" : "J. and Tao,? \\Q2005\\E",
      "shortCiteRegEx" : "J. and Tao",
      "year" : 2005
    }, {
      "title" : "Statistical-computational tradeoffs in planted problems and submatrix localization with a growing number of clusters and submatrices",
      "author" : [ "Y. Chen", "J. Xu" ],
      "venue" : null,
      "citeRegEx" : "Chen and Xu,? \\Q2014\\E",
      "shortCiteRegEx" : "Chen and Xu",
      "year" : 2014
    }, {
      "title" : "Optimal solutions for sparse principal component analysis",
      "author" : [ "A. d’Aspremont", "F. Bach", "L. El Ghaoui" ],
      "venue" : "J. Mach. Learn. Res.,",
      "citeRegEx" : "d.Aspremont et al\\.,? \\Q2008\\E",
      "shortCiteRegEx" : "d.Aspremont et al\\.",
      "year" : 2008
    }, {
      "title" : "Testing the nullspace property using semidefinite programming",
      "author" : [ "A. d’Aspremont", "L. El Ghaoui" ],
      "venue" : "Mathematical programming,",
      "citeRegEx" : "d.Aspremont and Ghaoui,? \\Q2011\\E",
      "shortCiteRegEx" : "d.Aspremont and Ghaoui",
      "year" : 2011
    }, {
      "title" : "Subspace pursuit for compressive sensing signal reconstruction",
      "author" : [ "W. Dai", "O. Milenkovic" ],
      "venue" : "IEEE Trans. Inform. Theory,",
      "citeRegEx" : "Dai and Milenkovic,? \\Q2009\\E",
      "shortCiteRegEx" : "Dai and Milenkovic",
      "year" : 2009
    }, {
      "title" : "Compressed sensing",
      "author" : [ "D.L. Donoho" ],
      "venue" : "IEEE Trans. Inform. Theory,",
      "citeRegEx" : "Donoho,? \\Q2006\\E",
      "shortCiteRegEx" : "Donoho",
      "year" : 2006
    }, {
      "title" : "mally sparse representation in general (nonorthogonal) dictionaries via `1 minimization",
      "author" : [ "D.L. Donoho", "M. Elad" ],
      "venue" : "Proceedings of the National Academy of Sciences,",
      "citeRegEx" : "Donoho and Elad,? \\Q2003\\E",
      "shortCiteRegEx" : "Donoho and Elad",
      "year" : 2003
    }, {
      "title" : "Stable recovery of sparse overcomplete representations in the presence of noise",
      "author" : [ "D.L. Donoho", "M. Elad", "V.N. Temlyakov" ],
      "venue" : "IEEE Trans. Inform. Theory,",
      "citeRegEx" : "Donoho et al\\.,? \\Q2006\\E",
      "shortCiteRegEx" : "Donoho et al\\.",
      "year" : 2006
    }, {
      "title" : "Compressed Sensing: Theory and Applications",
      "author" : [ "Y.C. Eldar", "G. Kutyniok" ],
      "venue" : null,
      "citeRegEx" : "Eldar and Kutyniok,? \\Q2012\\E",
      "shortCiteRegEx" : "Eldar and Kutyniok",
      "year" : 2012
    }, {
      "title" : "The probable value of the Lovàsz–Schrijver relaxations for a maximum independent set",
      "author" : [ "U. Feige", "R. Krauthgamer" ],
      "venue" : "SIAM J. Comput.,",
      "citeRegEx" : "Feige and Krauthgamer,? \\Q2003\\E",
      "shortCiteRegEx" : "Feige and Krauthgamer",
      "year" : 2003
    }, {
      "title" : "Statistical Algorithms and a Lower Bound for Detecting Planted Cliques",
      "author" : [ "V. Feldman", "E. Grigorescu", "L. Reyzin", "S.S. Vempala", "Y. Xiao" ],
      "venue" : "Proceedings of the Fortyfifth Annual ACM Symposium on Theory of Computing",
      "citeRegEx" : "Feldman et al\\.,? \\Q2013\\E",
      "shortCiteRegEx" : "Feldman et al\\.",
      "year" : 2013
    }, {
      "title" : "On the complexity of random satisfiability problems with planted solutions",
      "author" : [ "V. Feldman", "W. Perkins", "S. Vempala" ],
      "venue" : "Proceedings of the Forty-Seventh Annual ACM on Symposium on Theory of Computing,",
      "citeRegEx" : "Feldman et al\\.,? \\Q2013\\E",
      "shortCiteRegEx" : "Feldman et al\\.",
      "year" : 2013
    }, {
      "title" : "Sparse CCA: adaptive estimation and computational barriers",
      "author" : [ "C. Gao", "Z. Ma", "H.H. Zhou" ],
      "venue" : null,
      "citeRegEx" : "Gao et al\\.,? \\Q2014\\E",
      "shortCiteRegEx" : "Gao et al\\.",
      "year" : 2014
    }, {
      "title" : "Computational Lower Bounds for Community Detection on Random Graphs",
      "author" : [ "B. Hajek", "Y. Wu", "Xu" ],
      "venue" : "Proceedings of The 28th Conference on Learning",
      "citeRegEx" : "Hajek et al\\.,? \\Q2015\\E",
      "shortCiteRegEx" : "Hajek et al\\.",
      "year" : 2015
    }, {
      "title" : "How hard is it to approximate the best nash equilibrium",
      "author" : [ "E. Hazan", "R. Krauthgamer" ],
      "venue" : "SIAM J. Comput.,",
      "citeRegEx" : "Hazan and Krauthgamer,? \\Q2011\\E",
      "shortCiteRegEx" : "Hazan and Krauthgamer",
      "year" : 2011
    }, {
      "title" : "Large cliques elude the Metropolis process",
      "author" : [ "M. Jerrum" ],
      "venue" : "Random Struct. Algor.,",
      "citeRegEx" : "Jerrum,? \\Q1992\\E",
      "shortCiteRegEx" : "Jerrum",
      "year" : 1992
    }, {
      "title" : "On verifiable sufficient conditions for sparse signal recovery via `1 minimization",
      "author" : [ "A. Juditsky", "A. Nemirovski" ],
      "venue" : "Mathematical programming,",
      "citeRegEx" : "Juditsky and Nemirovski,? \\Q2011\\E",
      "shortCiteRegEx" : "Juditsky and Nemirovski",
      "year" : 2011
    }, {
      "title" : "Hiding cliques for cryptographic security",
      "author" : [ "A. Juels", "M. Peinado" ],
      "venue" : "Des. Codes Cryptography",
      "citeRegEx" : "Juels and Peinado,? \\Q2000\\E",
      "shortCiteRegEx" : "Juels and Peinado",
      "year" : 2000
    }, {
      "title" : "Hidden cliques and the certification of the restricted isometry property",
      "author" : [ "P. Koiran", "A. Zouzias" ],
      "venue" : null,
      "citeRegEx" : "Koiran and Zouzias,? \\Q2012\\E",
      "shortCiteRegEx" : "Koiran and Zouzias",
      "year" : 2012
    }, {
      "title" : "Computing performance guarantees for compressed sensing",
      "author" : [ "K. Lee", "Y. Bresler" ],
      "venue" : "IEEE International Conference on Acoustics, Speech and Signal Processing,",
      "citeRegEx" : "Lee and Bresler,? \\Q2008\\E",
      "shortCiteRegEx" : "Lee and Bresler",
      "year" : 2008
    }, {
      "title" : "Computational barriers in minimax submatrix detection",
      "author" : [ "Z. Ma", "Y. Wu" ],
      "venue" : null,
      "citeRegEx" : "Ma and Wu,? \\Q2013\\E",
      "shortCiteRegEx" : "Ma and Wu",
      "year" : 2013
    }, {
      "title" : "A wavelet tour of signal processing",
      "author" : [ "S. Mallat" ],
      "venue" : null,
      "citeRegEx" : "Mallat,? \\Q1999\\E",
      "shortCiteRegEx" : "Mallat",
      "year" : 1999
    }, {
      "title" : "On the method of bounded differences",
      "author" : [ "C. McDiarmid" ],
      "venue" : "Surveys in Combinatorics,",
      "citeRegEx" : "McDiarmid,? \\Q1989\\E",
      "shortCiteRegEx" : "McDiarmid",
      "year" : 1989
    }, {
      "title" : "CoSaMP: Iterative signal recovery from incomplete and inaccurate samples",
      "author" : [ "D. Needell", "J.A. Tropp" ],
      "venue" : "Applied and Computational Harmonic Analysis,",
      "citeRegEx" : "Needell and Tropp,? \\Q2009\\E",
      "shortCiteRegEx" : "Needell and Tropp",
      "year" : 2009
    }, {
      "title" : "A Mathematical Introduction to Compressive Sensing. Birkhäuser",
      "author" : [ "H. Rauhut", "S. Foucart" ],
      "venue" : null,
      "citeRegEx" : "Rauhut and Foucart,? \\Q2013\\E",
      "shortCiteRegEx" : "Rauhut and Foucart",
      "year" : 2013
    }, {
      "title" : "The computational complexity of the restricted isometry property, the nullspace property, and related concepts in compressed sensing",
      "author" : [ "A.N. Tillmann", "Pfetsch M. E" ],
      "venue" : "IEEE Trans. Inform. Theory,",
      "citeRegEx" : "Tillmann and E.,? \\Q2014\\E",
      "shortCiteRegEx" : "Tillmann and E.",
      "year" : 2014
    }, {
      "title" : "Introduction to the non-asymptotic analysis of random matrices",
      "author" : [ "R. Vershynin" ],
      "venue" : null,
      "citeRegEx" : "Vershynin,? \\Q2012\\E",
      "shortCiteRegEx" : "Vershynin",
      "year" : 2012
    }, {
      "title" : "Statistical and computational tradeoffs in Estimation of Sparse Pincipal Components",
      "author" : [ "T. Wang", "Q. Berthet", "R.J. Samworth" ],
      "venue" : "Ann. Statist.,",
      "citeRegEx" : "Wang et al\\.,? \\Q2016\\E",
      "shortCiteRegEx" : "Wang et al\\.",
      "year" : 2016
    }, {
      "title" : "Lower bounds on the performance of polynomial-time algorithms for sparse linear regression",
      "author" : [ "Y. Zhang", "M.J. Wainwright", "M.I. Jordan" ],
      "venue" : "JMLR: Workshop and Conference Proceedings (COLT),",
      "citeRegEx" : "Zhang et al\\.,? \\Q2014\\E",
      "shortCiteRegEx" : "Zhang et al\\.",
      "year" : 2014
    } ],
    "referenceMentions" : [ {
      "referenceID" : 40,
      "context" : "Sparsity is a structure of wide applicability (see, e.g. Mallat, 1999; Rauhut and Foucart, 2013; Eldar and Kutyniok, 2012), with a broad literature dedicated to its study in various scientific fields.",
      "startOffset" : 46,
      "endOffset" : 122
    }, {
      "referenceID" : 24,
      "context" : "Sparsity is a structure of wide applicability (see, e.g. Mallat, 1999; Rauhut and Foucart, 2013; Eldar and Kutyniok, 2012), with a broad literature dedicated to its study in various scientific fields.",
      "startOffset" : 46,
      "endOffset" : 122
    }, {
      "referenceID" : 22,
      "context" : "For an incoherent design matrix, it is known that an order of k observations suffice (Donoho, Elad and Temlyakov, 2006; Donoho and Elad, 2003).",
      "startOffset" : 85,
      "endOffset" : 142
    }, {
      "referenceID" : 10,
      "context" : "It is a highly robust property, and in fact implies that many different polynomial time methods, such as greedy methods (Blumensath and Davies, 2009; Needell and Tropp, 2009; Dai and Milenkovic, 2009) and convex optimization (Candès, 2008; Candès, Romberg and Tao, 2006b; Candès and Tao, 2005, 2006), are stable in recovering β.",
      "startOffset" : 120,
      "endOffset" : 200
    }, {
      "referenceID" : 39,
      "context" : "It is a highly robust property, and in fact implies that many different polynomial time methods, such as greedy methods (Blumensath and Davies, 2009; Needell and Tropp, 2009; Dai and Milenkovic, 2009) and convex optimization (Candès, 2008; Candès, Romberg and Tao, 2006b; Candès and Tao, 2005, 2006), are stable in recovering β.",
      "startOffset" : 120,
      "endOffset" : 200
    }, {
      "referenceID" : 20,
      "context" : "It is a highly robust property, and in fact implies that many different polynomial time methods, such as greedy methods (Blumensath and Davies, 2009; Needell and Tropp, 2009; Dai and Milenkovic, 2009) and convex optimization (Candès, 2008; Candès, Romberg and Tao, 2006b; Candès and Tao, 2005, 2006), are stable in recovering β.",
      "startOffset" : 120,
      "endOffset" : 200
    }, {
      "referenceID" : 12,
      "context" : "It is a highly robust property, and in fact implies that many different polynomial time methods, such as greedy methods (Blumensath and Davies, 2009; Needell and Tropp, 2009; Dai and Milenkovic, 2009) and convex optimization (Candès, 2008; Candès, Romberg and Tao, 2006b; Candès and Tao, 2005, 2006), are stable in recovering β.",
      "startOffset" : 225,
      "endOffset" : 299
    }, {
      "referenceID" : 21,
      "context" : "These results were developed in the field of compressed sensing (Candès, Romberg and Tao, 2006a; Donoho, 2006; Candès and Tao, 2006; Rauhut and Foucart, 2013; Eldar and Kutyniok, 2012) where the use of randomness still remains pivotal for near-optimal results.",
      "startOffset" : 64,
      "endOffset" : 184
    }, {
      "referenceID" : 40,
      "context" : "These results were developed in the field of compressed sensing (Candès, Romberg and Tao, 2006a; Donoho, 2006; Candès and Tao, 2006; Rauhut and Foucart, 2013; Eldar and Kutyniok, 2012) where the use of randomness still remains pivotal for near-optimal results.",
      "startOffset" : 64,
      "endOffset" : 184
    }, {
      "referenceID" : 24,
      "context" : "These results were developed in the field of compressed sensing (Candès, Romberg and Tao, 2006a; Donoho, 2006; Candès and Tao, 2006; Rauhut and Foucart, 2013; Eldar and Kutyniok, 2012) where the use of randomness still remains pivotal for near-optimal results.",
      "startOffset" : 64,
      "endOffset" : 184
    }, {
      "referenceID" : 2,
      "context" : "Moreover, it is in general practically impossible to check that a given matrix satisfies these desired properties, as RIP certification is NP-hard (Bandeira et al., 2012).",
      "startOffset" : 147,
      "endOffset" : 170
    }, {
      "referenceID" : 35,
      "context" : "The search for such statistics has been of great importance for over a decade now, and several have been proposed (d’Aspremont and El Ghaoui, 2011; Lee and Bresler, 2008; Juditsky and Nemirovski, 2011; d’Aspremont, Bach and El Ghaoui, 2008).",
      "startOffset" : 114,
      "endOffset" : 240
    }, {
      "referenceID" : 32,
      "context" : "The search for such statistics has been of great importance for over a decade now, and several have been proposed (d’Aspremont and El Ghaoui, 2011; Lee and Bresler, 2008; Juditsky and Nemirovski, 2011; d’Aspremont, Bach and El Ghaoui, 2008).",
      "startOffset" : 114,
      "endOffset" : 240
    }, {
      "referenceID" : 34,
      "context" : "Our problem is conceptually different from results regarding the worst-case hardness of certifying this property (see, e.g. Bandeira et al., 2012; Koiran and Zouzias, 2012; Tillmann and Pfetsch, 2014).",
      "startOffset" : 113,
      "endOffset" : 200
    }, {
      "referenceID" : 36,
      "context" : "The planted clique assumption has been used to prove computational hardness results for statistical problems such as estimation and testing of sparse principal components (Berthet and Rigollet, 2013a,b; Wang, Berthet and Samworth, 2016), testing and localization of submatrix signals (Ma and Wu, 2013; Chen and Xu, 2014), community",
      "startOffset" : 284,
      "endOffset" : 320
    }, {
      "referenceID" : 17,
      "context" : "The planted clique assumption has been used to prove computational hardness results for statistical problems such as estimation and testing of sparse principal components (Berthet and Rigollet, 2013a,b; Wang, Berthet and Samworth, 2016), testing and localization of submatrix signals (Ma and Wu, 2013; Chen and Xu, 2014), community",
      "startOffset" : 284,
      "endOffset" : 320
    }, {
      "referenceID" : 5,
      "context" : "The intractability of noisy parity recovery problem (Blum, Kalai and Wasserman, 2003) has also been used recently as an average-case assumption to deduce computational hardness of detection of satisfiability formulas with lightly planted solutions (Berthet and Ellenberg, 2015).",
      "startOffset" : 248,
      "endOffset" : 277
    }, {
      "referenceID" : 26,
      "context" : "Additionally, several unconditional computational hardness results are shown for statistical problems under constraints of learning models (Feldman et al., 2013; Feldman, Perkins and Vempala, 2013).",
      "startOffset" : 139,
      "endOffset" : 197
    }, {
      "referenceID" : 8,
      "context" : "This does not mean that the planted graph is a random graph with edge probability q > 1/2 as considered in (Arias-Castro and Verzelen, 2013; Bhaskara et al., 2010; Awasthi et al., 2015), but that it can be any graph with an unexpectedly high number of edges (see section 3.",
      "startOffset" : 107,
      "endOffset" : 185
    }, {
      "referenceID" : 1,
      "context" : "This does not mean that the planted graph is a random graph with edge probability q > 1/2 as considered in (Arias-Castro and Verzelen, 2013; Bhaskara et al., 2010; Awasthi et al., 2015), but that it can be any graph with an unexpectedly high number of edges (see section 3.",
      "startOffset" : 107,
      "endOffset" : 185
    }, {
      "referenceID" : 12,
      "context" : "1 Formulation We use the definition of Candès and Tao (2005), who introduced this notion.",
      "startOffset" : 39,
      "endOffset" : 61
    }, {
      "referenceID" : 2,
      "context" : "g Bandeira et al., 2012). Several deterministic constructions of RIP matrices exist for sparsity level k . θ √ n. For example, using equitriangular tight frames and Gershgorin’s circle theorem, one can construct RIP matrices with sparsity k ≤ √ n and distortion θ bounded away from 0 (see, e.g. Bandeira et al., 2012). The limitation k ≤ θ √ n is known as the ‘square root bottleneck’. To date, the only constructions that break the ‘square root bottleneck’ are due to Bourgain et al. (2011) and Bandeira, Mixon and Moreira (2014), both of which give RIP guarantee for k of order n for some small > 0 and fixed θ (the latter construction is conditional on a number-theoretic conjecture being true).",
      "startOffset" : 2,
      "endOffset" : 492
    }, {
      "referenceID" : 2,
      "context" : "g Bandeira et al., 2012). Several deterministic constructions of RIP matrices exist for sparsity level k . θ √ n. For example, using equitriangular tight frames and Gershgorin’s circle theorem, one can construct RIP matrices with sparsity k ≤ √ n and distortion θ bounded away from 0 (see, e.g. Bandeira et al., 2012). The limitation k ≤ θ √ n is known as the ‘square root bottleneck’. To date, the only constructions that break the ‘square root bottleneck’ are due to Bourgain et al. (2011) and Bandeira, Mixon and Moreira (2014), both of which give RIP guarantee for k of order n for some small > 0 and fixed θ (the latter construction is conditional on a number-theoretic conjecture being true).",
      "startOffset" : 2,
      "endOffset" : 531
    }, {
      "referenceID" : 11,
      "context" : "Candès and Tao (2005) and Baraniuk et al.",
      "startOffset" : 0,
      "endOffset" : 22
    }, {
      "referenceID" : 4,
      "context" : "Candès and Tao (2005) and Baraniuk et al. (2008)).",
      "startOffset" : 26,
      "endOffset" : 49
    }, {
      "referenceID" : 2,
      "context" : "It is known that the problem of deciding if a given matrix is RIP is NP-hard (Bandeira et al., 2012).",
      "startOffset" : 77,
      "endOffset" : 100
    }, {
      "referenceID" : 28,
      "context" : "Jerrum (1992); Feige and Krauthgamer (2003); Feldman et al.",
      "startOffset" : 0,
      "endOffset" : 14
    }, {
      "referenceID" : 25,
      "context" : "Jerrum (1992); Feige and Krauthgamer (2003); Feldman et al.",
      "startOffset" : 15,
      "endOffset" : 44
    }, {
      "referenceID" : 25,
      "context" : "Jerrum (1992); Feige and Krauthgamer (2003); Feldman et al. (2013)).",
      "startOffset" : 15,
      "endOffset" : 67
    }, {
      "referenceID" : 29,
      "context" : "Jerrum (1992) and references in Berthet and Rigollet (2013a,b)).",
      "startOffset" : 0,
      "endOffset" : 14
    }, {
      "referenceID" : 29,
      "context" : "Jerrum (1992) and references in Berthet and Rigollet (2013a,b)). The difficulty of this problem has been used as a primitive for hardness of other tasks, such as cryptographic applications, in Juels and Peinado (2000), testing for kwise dependence in Alon et al.",
      "startOffset" : 0,
      "endOffset" : 218
    }, {
      "referenceID" : 0,
      "context" : "The difficulty of this problem has been used as a primitive for hardness of other tasks, such as cryptographic applications, in Juels and Peinado (2000), testing for kwise dependence in Alon et al. (2007), approximating Nash equilibria in Hazan and Krauthgamer (2011).",
      "startOffset" : 186,
      "endOffset" : 205
    }, {
      "referenceID" : 0,
      "context" : "The difficulty of this problem has been used as a primitive for hardness of other tasks, such as cryptographic applications, in Juels and Peinado (2000), testing for kwise dependence in Alon et al. (2007), approximating Nash equilibria in Hazan and Krauthgamer (2011). In this case, Assumption (A1) is a version of the planted clique hypothesis (see, e.",
      "startOffset" : 186,
      "endOffset" : 268
    }, {
      "referenceID" : 36,
      "context" : "More precisely, using an averaging trick first seen in Ma and Wu (2013), we are able to show that the existence of such ‘hard’ sequences is not confined only in the sparsity regime k n .",
      "startOffset" : 55,
      "endOffset" : 72
    }, {
      "referenceID" : 38,
      "context" : "By McDiarmid’s inequality (McDiarmid, 1989), we have that for any t > 0,",
      "startOffset" : 26,
      "endOffset" : 43
    } ],
    "year" : 2016,
    "abstractText" : "The restricted isometry property (RIP) for design matrices gives guarantees for optimal recovery in sparse linear models. It is of high interest in compressed sensing and statistical learning. This property is particularly important for computationally efficient recovery methods. As a consequence, even though it is in general NP-hard to check that RIP holds, there have been substantial efforts to find tractable proxies for it. These would allow the construction of RIP matrices and the polynomial-time verification of RIP given an arbitrary matrix. We consider the framework of average-case certifiers, that never wrongly declare that a matrix is RIP, while being often correct for random instances. While there are such functions which are tractable in a suboptimal parameter regime, we show that this is a computationally hard task in any better regime. Our results are based on a new, weaker assumption on the problem of detecting dense subgraphs.",
    "creator" : "LaTeX with hyperref package"
  }
}