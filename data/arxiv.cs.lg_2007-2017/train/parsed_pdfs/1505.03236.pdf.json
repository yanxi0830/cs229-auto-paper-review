{
  "name" : "1505.03236.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : null,
    "authors" : [ "FLOWER POLLINATION ALGORITHM", "G.Wiselin Jiji" ],
    "emails" : [ ],
    "sections" : [ {
      "heading" : null,
      "text" : "approaches are widely applied to data clustering so that objects within the clusters are similar and objects in different clusters are far away from each other. K-Means, is one of the familiar center based clustering algorithms since implementation is very easy and fast convergence. However, K-Means algorithm suffers from initialization, hence trapped in local optima. Flower Pollination Algorithm (FPA) is the global optimization technique, which avoids trapping in local optimum solution. In this paper, a novel hybrid data clustering approach using Flower Pollination Algorithm and K-Means (FPAKM) is proposed. The proposed algorithm results are compared with K-Means and FPA on eight datasets. From the experimental results, FPAKM is better than FPA and K-Means.\nKEYWORDS Cluster Analysis, K-Means, Flower Pollination algorithm, global optimum, swarm intelligence, natureinspired"
    }, {
      "heading" : "1. INTRODUCTION",
      "text" : "Data clustering [4] [6] is an unsupervised learning technique in which class labels are not known in advance. The purpose of clustering is to partition a set of objects into clusters or groups so that the objects within the cluster are more similar to each other, while objects in different clusters are far away from each other. In past decades, many nature-inspired evolutionary algorithms have been developed for solving most engineering design optimization problems, which are highly nonlinear, involving many design variables and complex constraints. These metaheuristic algorithms are attracted very much because of the global search capability and take less time to solve real world problems. Nature-inspired algorithms [2] [3] imitate the behaviours of the living things in the nature, so they are also called as Swarm Intelligence (SI) algorithms.\nEvolutionary algorithms (EAs) were the initial stage of such optimization methods [35]. Genetic Algorithm (GA) [6] and Simulated Annealing (SA) [7] are popular examples for EAs. In the early 1970s, Genetic algorithm was developed by John Holland, which inspired by biological evolution such as reproduction, mutation, crossover and selection. Simulated annealing (SA) was developed from inspiration by annealing in metallurgy, a technique involving heating and cooling of a material to increase the size of its crystals and reduce their defects.\nThe rising body of Swarm Intelligence(SI) [2] [3] metaheuristic algorithms include Particle Swarm Optimization (PSO) [1] [5], Ant Colony Optimization (ACO) [14], Glowworm Swarm Optimization (GSO) [8], Bacterial Foraging Optimization (BFO) [9-10], the Bees Algorithm [31], Artificial Bee Colony algorithm (ABC) [25][28-29], Biogeography-based optimization (BBO) [30] , Cuckoo Search (CS) [26-27], Firefly Algorithm (FA) [32-33] , Bat Algorithm (BA) [20] and flower pollination algorithm[19] .\nSwarm Intelligence system holds a population of solutions, which are changed through random selection and alterations of these solutions. The way, the system differs depends on the generation of new solutions, random selection procedure and candidate solution encoding technique. Particle Swarm Optimization (PSO) was developed in 1995 by Kennedy and Eberhart simulating the social behaviour of bird flock or fish school. Ant Colony Optimization, introduced by Dorigo, imitates the food searching paths of ants in nature. Glowworm Swarm Optimization (GSO) was introduced by Krishnanand and Ghose in 2005 based on the behaviour of glow worms. Bacterial foraging optimization algorithm was developed based on the foraging behaviour of bacteria such as E.coli and M.xanthus. The Bees Algorithm was developed by Pham DT in 2005 imitating the food foraging behaviour of honey bee colonies. Artificial bee colony algorithm was developed by Karaboga, being motivated from food foraging behaviour of bee colonies. Biogeography-based optimization (BBO) was introduced in 2008 by Dan Simon inspired by biogeography, which is the study of the distribution of biological species through space and time. Cuckoo search was developed by Xin-she Yang and Subash Deb in 2009 being motivated by the brood parasitism of cuckoo species by laying their eggs in the nests of other host birds. Firefly algorithm was introduced by Xin-She Yang inspired by the flashing behaviour of fireflies. The primary principle for a firefly's flash is to act as an indicator system to draw other fireflies. Bat algorithm was developed in 2010 by Xin-She Yang based on the echolocation behaviour of microbats. Flower pollination algorithm was developed by Xin-She Yang in 2012 motivated by the pollination process of flowering plants.\nThe remainder of this paper is organized as follows. Section 2 presents some of the previous proposed research work on data clustering. K-Means algorithm and Flower Pollination algorithm is presented in Section 3 and Section 4 respectively. Then in Section 5 proposed algorithm is explained. Section 6 discusses experimental results and Section 7 concludes the paper with fewer discussions."
    }, {
      "heading" : "2. RELATED WORK",
      "text" : "Van, D.M. and A.P. Engelbrecht. (2003) [5] proposed data clustering approach using particle swarm optimization. The author proposed two approaches for data clustering. The first approach is, PSO, in which the optimal centroids are found and then these optimal centroids were used as a seed in K-means algorithm and the second approach is, the PSO was used to refine the clusters formed by K-means. The two approaches were tested and the results show that both PSO clustering techniques have much potential.\nAnt Colony Optimization (ACO) method for clustering is presented by Shelokar et al. (2004) [14]. In [14], the authors employed distributed agents that imitate the way real-life ants find the shortest path from their nest to a food source and back. The results obtained by ACO can be considered viable and is an efficient heuristic to find near-optimal cluster representation for the clustering problem.\nKao et al. (2008) [22] proposed a hybridized approach that combines PSO technique, Nelder– Mead simplex search and the K-means algorithm. The performance of K-NM-PSO is compared with PSO, NM-PSO, K-PSO and K-means clustering and it is proved that K-NM-PSO is both strong and suitable for handling data clustering.\nMaulik and Mukhopadhyay (2010) [7] also presented a simulated annealing approach to clustering. They combined their heuristic with artificial neural networks to improve solution quality and the similarity criteria, which used DB cluster validity index. Karaboga and Ozturk (2011) [15] presented a new clustering approach using Artificial Bee Colony (ABC) algorithm\nwhich simulates the food foraging behaviour of a honey bee swarm. The performance is compared with PSO and other classification techniques. The simulation results show that the ABC algorithm is superior to other algorithms.\nZhang et al. (2010) [23] presented the artificial bee colony (ABC) as a state-of-the-art approach to clustering. Deb’s rules are used to tackle infeasible solutions instead of the greedy selection process usually used in the ABC algorithm. When they tested their algorithm, they found very encouraging results in terms of effectiveness and efficiency.\nIn [16] (2012), X. Yan et al presented a new data clustering algorithm using hybrid artificial bee colony (HABC). The genetic algorithm crossover operator was introduced to ABC to enhance the information exchange between bees. The HABC algorithm achieved better results.\nTunchan Cura. (2012) [19] presented a new PSO approach to the data clustering and the algorithm was tested using two synthetic datasets and five real datasets. The results show that the algorithm can be applied to clustering problem with known and unknown number of clusters. Senthilnath, J., Omkar, S.N. and Mani, V. (2011) [13] presented data clustering using firefly algorithm. They measured the performance of FA with respect to supervised clustering problem and the results show that algorithm is robust and efficient.\nM.Wan and his co-authors (2012) [17] presented data clustering using Bacterial Foraging Optimization (BFO). The algorithm proposed by these researchers was tested on several wellknown benchmark data sets and Compared three clustering technique. The author concludes that the algorithm is effective and can be used to handle data sets with various cluster sizes, densities and multiple dimensions.\nJ. Senthilnatha, Vipul Dasb, Omkara, V. Mani, (2012) [18] proposed a new data clustering approach using Cuckoo search with levy flight. Levy flight is heavy-tailed which ensures that it covers output domain efficiently. The author concluded that the proposed algorithm is better than GA and PSO."
    }, {
      "heading" : "3. K-MEANS ALGORITHM",
      "text" : "K-Means Clustering algorithm is fast and easy to implement. Due to its simplicity, K-Means clustering is heavily used. The process of clustering using K-Means is as follows:\nLet O = {o1, o2,…,on} be a set of n data objects to be partitioned and each data object oi ,i=1,2,… ,n is represented as oi={oi1,oi2,….,oim} where oim represents mth dimension value of data object i.\nThe output clustering algorithm is a set of K partitions P = {P1, P2, …., Pk | ∀ k : Pk ≠ ∅ and ∀l ≠ \uD835\uDC58 : Pk∩Pl=∅} such that objects within the clusters are more similar and dissimilar to objects in different clusters. These similarities are measured by some optimization criterion, especially total within-cluster variance or the total mean-square quantization error (MSE) which is defined as:\nMin∑ ∑ \uD835\uDC64\uD835\uDC56\uD835\uDC57\uD835\uDC38(\uD835\uDC5C\uD835\uDC56, \uD835\uDC5D\uD835\uDC57) \uD835\uDC5B \uD835\uDC56=1 \uD835\uDC3E \uD835\uDC57=1 (1)\nwhere pj represents a jth cluster center , E is the distance measure between a data object oi and a cluster center pj, \uD835\uDC64\uD835\uDC56\uD835\uDC57 ∈ {0,1} denotes that object i belongs to cluster j if \uD835\uDC64\uD835\uDC56\uD835\uDC57=1 (otherwise \uD835\uDC64\uD835\uDC56\uD835\uDC57=0). In this paper Euclidean distance is used as distance metric which is defined as follows:\n\uD835\uDC38(\uD835\uDC5C\uD835\uDC56, \uD835\uDC5D\uD835\uDC57)=√∑ (\uD835\uDC5C\uD835\uDC56\uD835\uDC5A − \uD835\uDC5D\uD835\uDC57\uD835\uDC5A) 2\uD835\uDC40 \uD835\uDC5A=1 (2)\nwhere,\npj is cluster center for a cluster j and is calculated as follows:\npj = 1\n\uD835\uDC5B\uD835\uDC57 ∑ \uD835\uDC5C\uD835\uDC56\uD835\uDC5C\uD835\uDC56∈\uD835\uDC5D\uD835\uDC57 (3)\nwhere, nj is the total number of objects in cluster j. The K-Means algorithm is defined in fig. (1)."
    }, {
      "heading" : "4. FLOWER POLLINATION ALGORITHM (FPA)",
      "text" : "Flower Pollination Algorithm (FPA) is a global optimization algorithm, which was introduced by Xin-She Yang in 2012 [19], inspired by the pollination process of flowers. There are two key steps in FPA. One is global pollination and the other is local pollination. In the global pollination step, insects fly and move in a longer distance and the fittest is represented by g*. The flower pollination process with longer move distance is carried out with levy flights. Mathematically, the global pollination process is represented as\n\uD835\uDC65\uD835\uDC56 \uD835\uDC61+1 = \uD835\uDC65\uD835\uDC56 \uD835\uDC61 + \uD835\uDC3F(\uD835\uDC65\uD835\uDC56 \uD835\uDC61 − \uD835\uDC54∗) (4)\nwhere, \uD835\uDC65\uD835\uDC56 \uD835\uDC61 - solution vector at iteration t \uD835\uDC65\uD835\uDC56 \uD835\uDC61+1 - solution vector at iteration t+1 \uD835\uDC54∗ - best solution L - step size.\nThe step size L is drawn from Levy flight distribution [35],\n\uD835\uDC3F~ \uD835\uDF06\uD835\uDEE4(\uD835\uDF06) sin (\n\uD835\uDF0B\uD835\uDF06\n2 )\n\uD835\uDF0B\n1\n\uD835\uDC601+\uD835\uDF06 , (\uD835\uDC60 ≫ \uD835\uDC600 > 0). (5)\nwhere,\n\uD835\uDEE4(\uD835\uDF06)- Standard gamma function and \uD835\uDF06 =3/2.\nIn the local pollination step, self-pollination is depicted. It is mathematically represented by\n\uD835\uDC65\uD835\uDC56 \uD835\uDC61+1 = \uD835\uDC65\uD835\uDC56 \uD835\uDC61+∈ (\uD835\uDC65\uD835\uDC57 \uD835\uDC61 − \uD835\uDC65\uD835\uDC58 \uD835\uDC61 ) (6)\nwhere, \uD835\uDC65\uD835\uDC56 \uD835\uDC61 - solution vector at iteration t \uD835\uDC65\uD835\uDC56 \uD835\uDC61+1 - solution vector at iteration t+1 ∈ - random uniformly distributed number between [0,1] \uD835\uDC57, \uD835\uDC58 - randomly selected indices.\nTo perform global and local pollination process, a switch probability is used to switch between global and local scale. The FPA is summarized in Fig.(2)."
    }, {
      "heading" : "5. FLOWER POLLINATION ALGORITHM WITH K-MEANS (FPAKM)",
      "text" : "In this paper, the flower pollination algorithm is integrated with K-Means (FPAKM) to form a hybrid clustering algorithm, which gives all functionalities of FPA and K-Means. If the current best solution does not improve in a predetermined number of trials, a local search around current best solution is made. The maximum of trial is the limit value. The objective function used is total mean-square quantization error (MSE). The proposed algorithm is given in fig.(3)."
    }, {
      "heading" : "6. EXPERIMENTAL RESULTS AND DISCUSSION",
      "text" : "The K-Means, Flower Pollination Algorithm (FPA) and proposed algorithm (FPAKM) are written in Matlab 8.3 and executed in a Windows 7 Professional OS environment using Intel i3, 2.30 GHz, 2 GB RAM. Flower Pollination Algorithm (FPA) matlab code is available in [34]. For comparison easier, FPA, FPAKM are executed with the parameters except limit value as shown in Table 1."
    }, {
      "heading" : "6.1 Dataset Description",
      "text" : "To evaluate the performance of proposed algorithm, eight datasets have been used. One is artificial dataset drawn from Kao et al. (2008). The remaining seven datasets, namely, iris, thyroid, wine, Contraceptive Method Choice (CMC), crude oil and glass, are collected from [36]. The artificial dataset contains samples drawn from five independent uniform distributions with ranges of (85,100), (70, 85), (55, 70), (40, 55) and (25, 40). The eight datasets used in this paper is described in Table 2."
    }, {
      "heading" : "6.2 Performance Evaluation",
      "text" : "The quality of clustering algorithms is measured using objective function value and F-measure. The smaller the objective function value is, the quality of clustering will be higher.\nThe F-measure employs the ideas of precision and recall values used in information retrieval. The precision P(i,j) and recall R(i,j) of each cluster j for each class i are calculated as\n\uD835\uDC43(\uD835\uDC56, \uD835\uDC57) = \uD835\uDEFD\uD835\uDC56\uD835\uDC57\n\uD835\uDEFD\uD835\uDC57 (7)\n\uD835\uDC45(\uD835\uDC56, \uD835\uDC57) = \uD835\uDEFD\uD835\uDC56\uD835\uDC57\n\uD835\uDEFD\uD835\uDC56 (8)\nwhere,\nβi : is the number of members of class i βj : is the number of members of cluster j βij: is the number of members of class i in cluster j\nThe corresponding F-measure F(i,j) is given in Eq. (9):\n\uD835\uDC39(\uD835\uDC56, \uD835\uDC57) = 2 ∗ \uD835\uDC43(\uD835\uDC56, \uD835\uDC57) ∗ \uD835\uDC45(\uD835\uDC56, \uD835\uDC57)\n\uD835\uDC43(\uD835\uDC56, \uD835\uDC57) + \uD835\uDC45(\uD835\uDC56, \uD835\uDC57) (9)\nThen the F-measure of a class i can be defined as\nFtot = ∑ βi\nni (F(i, j))j\nmax (10)\nwhere, n is the total number of data objects in the collection. In general, the larger the F-measure gives the better clustering result."
    }, {
      "heading" : "6.3 Results Discussion",
      "text" : "In this paper, to compare the performance of proposed algorithm, each algorithm has been run for 10 times and the best, worst, average and the standard deviation of each algorithms’ objective function values and F-measure values are given in table 3. The best values are shown in bold face.\nFor Artificial dataset Art1, the FPAKM algorithm obtains the best objective function value and Fmeasure value is 1 for FPA and FPAKM algorithm, while K-Means algorithm also gives maximum F-measure. For all datasets except cmc data, the FPAKM outperforms other two algorithms and it results the best value in terms of objective function value and F-measure. For datasets Art1, Iris, Wine, cancer, thyroid, crude oil, the FPA obtains maximum F-measure value over 10 runs. But FPAKM always obtains the best results compared to FPA and K-Means."
    }, {
      "heading" : "7. CONCLUSION",
      "text" : "This paper presents a hybrid data clustering algorithm (FPAKM) based on the K-Means and Flower Pollination algorithm. The results obtained by the proposed algorithm are compared with K-Means and flower pollination algorithm. It is revealed that the proposed algorithm finds optimal cluster centers, hence the F-measure value is increased. In mere future, this algorithm can be applied to solve other optimization problems."
    } ],
    "references" : [ {
      "title" : "2010),”Nature-inspired Metaheuristic Algorithms",
      "author" : [ "Xin-She Yang" ],
      "venue" : null,
      "citeRegEx" : "3",
      "shortCiteRegEx" : "3",
      "year" : 2010
    }, {
      "title" : "Data clustering using particle swarm optimization",
      "author" : [ "D.M. Van", "A.P. Engelbrecht" ],
      "venue" : "Proc. Of IEEE Congress on Evolutionary Computation, Canbella,",
      "citeRegEx" : "5",
      "shortCiteRegEx" : "5",
      "year" : 2003
    }, {
      "title" : "Data clustering: A review",
      "author" : [ "A.K. Jain", "M.N. Murty", "P.J. Flynn" ],
      "venue" : "ACM Computing Survey,",
      "citeRegEx" : "6",
      "shortCiteRegEx" : "6",
      "year" : 1999
    }, {
      "title" : "Bacterial Foraging optimization Algorithm: Theoretical Foundations, Analysis, and Applications,",
      "author" : [ "Swagatam Das", "Arijit Biswas", "Sambarta Dasgupta", "Ajith Abraham" ],
      "venue" : "Foundations of Computational Intelligence Studies in Computational Intelligence,",
      "citeRegEx" : "9",
      "shortCiteRegEx" : "9",
      "year" : 2009
    }, {
      "title" : "The Bees Algorithm – Modelling Foraging Behaviour to Solve Continuous Optimisation Problems",
      "author" : [ "D.T.Pham", "M.Castellani", "(2009" ],
      "venue" : "Proc. of the Institution of Mechanical Engineers, Part C: Journal of Mechanical Engineering Science , Vol. 223, pp.2919-2938.",
      "citeRegEx" : "12",
      "shortCiteRegEx" : null,
      "year" : 2938
    }, {
      "title" : "A novel clustering approach: Artificial Bee Colony (ABC) algorithm",
      "author" : [ "Dervis Karaboga", "Celal Ozturk" ],
      "venue" : "Applied Soft Computing,",
      "citeRegEx" : "15",
      "shortCiteRegEx" : "15",
      "year" : 2011
    }, {
      "title" : "A new approach for data clustering using hybrid artificial bee colony algorithm",
      "author" : [ "Yunlong Zhu", "Xiaohui Yan", "Wenping Zou", "Liang Wang" ],
      "venue" : "Neuro computing,",
      "citeRegEx" : "16",
      "shortCiteRegEx" : "16",
      "year" : 2012
    }, {
      "title" : "Data clustering using bacterial foraging optimization",
      "author" : [ "Miao Wan", "Lixiang Li", "Jinghua Xiao", "Cong Wang", "Yixian Yang" ],
      "venue" : "Journal of Intelligent Information Systems,",
      "citeRegEx" : "17",
      "shortCiteRegEx" : "17",
      "year" : 2012
    }, {
      "title" : "2012),”Flower pollination algorithm for global optimization",
      "author" : [ "Xin-She Yang" ],
      "venue" : "Lecture Notes in Computer Science, in Unconventional Computation and Natural Computation,",
      "citeRegEx" : "19",
      "shortCiteRegEx" : "19",
      "year" : 2012
    }, {
      "title" : "Bat algorithm inspired algorithm for solving numerical optimization problems",
      "author" : [ "P.W.Tsai", "J.S.Pan", "B.Y.Liao", "M.J.Tsai", "V. Istanda", "(2012" ],
      "venue" : "Applied Mechanics and Materials, Vol. 148-149, No. 134, pp.134-137.",
      "citeRegEx" : "20",
      "shortCiteRegEx" : null,
      "year" : 0
    }, {
      "title" : "A tabu search approach for the minimum sum-ofsquares clustering problem",
      "author" : [ "Y. Liu", "Z. Yi", "H. Wu", "M. Ye", "Chen" ],
      "venue" : "Information Sciences,",
      "citeRegEx" : "21",
      "shortCiteRegEx" : "21",
      "year" : 2008
    }, {
      "title" : "A hybridized approach to data clustering",
      "author" : [ "Yi-Tung Kao", "Erwie Zahara", "I-Wei Kao" ],
      "venue" : "Expert Systems with Applications,",
      "citeRegEx" : "22",
      "shortCiteRegEx" : "22",
      "year" : 2008
    }, {
      "title" : "An artificial bee colony approach for clustering”, Expert Systems with Applications, Vol.37,No.7, pp.4761–4767",
      "author" : [ "Changsheng Zhang", "Dantong Ouyang", "Jiaxu Ning" ],
      "venue" : null,
      "citeRegEx" : "23",
      "shortCiteRegEx" : "23",
      "year" : 2010
    }, {
      "title" : "A particle swarm optimization approach to clustering",
      "author" : [ "Tunchan Cura" ],
      "venue" : "Expert Systems with Applications,",
      "citeRegEx" : "24",
      "shortCiteRegEx" : "24",
      "year" : 2012
    }, {
      "title" : "A comparative study of Artificial Bee Colony algorithm",
      "author" : [ "Dervis Karaboga", "Bahriye Akay" ],
      "venue" : "Applied Mathematics and Computation ,",
      "citeRegEx" : "25",
      "shortCiteRegEx" : "25",
      "year" : 2009
    }, {
      "title" : "Engineering optimisation by cuckoo search",
      "author" : [ "X.S.Yang", "S. Deb" ],
      "venue" : "International Journal of Mathematical Modelling and Numerical Optimisation,",
      "citeRegEx" : "26",
      "shortCiteRegEx" : "26",
      "year" : 2010
    }, {
      "title" : "Cuckoo search via Lévy flights",
      "author" : [ "X.S.Yang", "S.Deb", "(2009" ],
      "venue" : "IEEE Publications World Congress on Nature & Biologically Inspired Computing, pp.210–214",
      "citeRegEx" : "27",
      "shortCiteRegEx" : null,
      "year" : 0
    }, {
      "title" : "Biogeography-based optimization",
      "author" : [ "D. Simon" ],
      "venue" : "IEEE Transactions on Evolutionary Computation,",
      "citeRegEx" : "30",
      "shortCiteRegEx" : "30",
      "year" : 2008
    }, {
      "title" : "The Bees Algorithm – Modelling Foraging Behaviour to Solve Continuous Optimisation Problems",
      "author" : [ "D.T.Pham", "M.Castellani", "(2009" ],
      "venue" : "Proc. of the Institution of Mechanical Engineers, Part C: Journal of Mechanical Engineering Science ,Vol. 223, pp.2919-2938.",
      "citeRegEx" : "31",
      "shortCiteRegEx" : null,
      "year" : 2938
    }, {
      "title" : "Firefly algorithm for continuous constrained optimization task",
      "author" : [ "S.Lukasik", "S.Zak", "(2009" ],
      "venue" : "Lecture Notes in Artificial Intelligence , pp.97–100. Advanced Computational Intelligence: An International Journal (ACII), Vol.2, No.2, April 2015 25",
      "citeRegEx" : "32",
      "shortCiteRegEx" : null,
      "year" : 2015
    }, {
      "title" : "Firefly algorithm, stochastic test functions and design optimisation",
      "author" : [ "X.S.Yang", "(2010" ],
      "venue" : "International Journal of Bio-inspired Computation, Vol.2, No.2, pp. 78–84.",
      "citeRegEx" : "33",
      "shortCiteRegEx" : null,
      "year" : 0
    } ],
    "referenceMentions" : [ {
      "referenceID" : 2,
      "context" : "Data clustering [4] [6] is an unsupervised learning technique in which class labels are not known in advance.",
      "startOffset" : 20,
      "endOffset" : 23
    }, {
      "referenceID" : 0,
      "context" : "Nature-inspired algorithms [2] [3] imitate the behaviours of the living things in the nature, so they are also called as Swarm Intelligence (SI) algorithms.",
      "startOffset" : 31,
      "endOffset" : 34
    }, {
      "referenceID" : 2,
      "context" : "Genetic Algorithm (GA) [6] and Simulated Annealing (SA) [7] are popular examples for EAs.",
      "startOffset" : 23,
      "endOffset" : 26
    }, {
      "referenceID" : 0,
      "context" : "The rising body of Swarm Intelligence(SI) [2] [3] metaheuristic algorithms include Particle Swarm Optimization (PSO) [1] [5], Ant Colony Optimization (ACO) [14], Glowworm Swarm Optimization (GSO) [8], Bacterial Foraging Optimization (BFO) [9-10], the Bees Algorithm [31], Artificial Bee Colony algorithm (ABC) [25][28-29], Biogeography-based optimization (BBO) [30] , Cuckoo Search (CS) [26-27], Firefly Algorithm (FA) [32-33] , Bat Algorithm (BA) [20] and flower pollination algorithm[19] .",
      "startOffset" : 46,
      "endOffset" : 49
    }, {
      "referenceID" : 1,
      "context" : "The rising body of Swarm Intelligence(SI) [2] [3] metaheuristic algorithms include Particle Swarm Optimization (PSO) [1] [5], Ant Colony Optimization (ACO) [14], Glowworm Swarm Optimization (GSO) [8], Bacterial Foraging Optimization (BFO) [9-10], the Bees Algorithm [31], Artificial Bee Colony algorithm (ABC) [25][28-29], Biogeography-based optimization (BBO) [30] , Cuckoo Search (CS) [26-27], Firefly Algorithm (FA) [32-33] , Bat Algorithm (BA) [20] and flower pollination algorithm[19] .",
      "startOffset" : 121,
      "endOffset" : 124
    }, {
      "referenceID" : 3,
      "context" : "The rising body of Swarm Intelligence(SI) [2] [3] metaheuristic algorithms include Particle Swarm Optimization (PSO) [1] [5], Ant Colony Optimization (ACO) [14], Glowworm Swarm Optimization (GSO) [8], Bacterial Foraging Optimization (BFO) [9-10], the Bees Algorithm [31], Artificial Bee Colony algorithm (ABC) [25][28-29], Biogeography-based optimization (BBO) [30] , Cuckoo Search (CS) [26-27], Firefly Algorithm (FA) [32-33] , Bat Algorithm (BA) [20] and flower pollination algorithm[19] .",
      "startOffset" : 239,
      "endOffset" : 245
    }, {
      "referenceID" : 18,
      "context" : "The rising body of Swarm Intelligence(SI) [2] [3] metaheuristic algorithms include Particle Swarm Optimization (PSO) [1] [5], Ant Colony Optimization (ACO) [14], Glowworm Swarm Optimization (GSO) [8], Bacterial Foraging Optimization (BFO) [9-10], the Bees Algorithm [31], Artificial Bee Colony algorithm (ABC) [25][28-29], Biogeography-based optimization (BBO) [30] , Cuckoo Search (CS) [26-27], Firefly Algorithm (FA) [32-33] , Bat Algorithm (BA) [20] and flower pollination algorithm[19] .",
      "startOffset" : 266,
      "endOffset" : 270
    }, {
      "referenceID" : 14,
      "context" : "The rising body of Swarm Intelligence(SI) [2] [3] metaheuristic algorithms include Particle Swarm Optimization (PSO) [1] [5], Ant Colony Optimization (ACO) [14], Glowworm Swarm Optimization (GSO) [8], Bacterial Foraging Optimization (BFO) [9-10], the Bees Algorithm [31], Artificial Bee Colony algorithm (ABC) [25][28-29], Biogeography-based optimization (BBO) [30] , Cuckoo Search (CS) [26-27], Firefly Algorithm (FA) [32-33] , Bat Algorithm (BA) [20] and flower pollination algorithm[19] .",
      "startOffset" : 310,
      "endOffset" : 314
    }, {
      "referenceID" : 17,
      "context" : "The rising body of Swarm Intelligence(SI) [2] [3] metaheuristic algorithms include Particle Swarm Optimization (PSO) [1] [5], Ant Colony Optimization (ACO) [14], Glowworm Swarm Optimization (GSO) [8], Bacterial Foraging Optimization (BFO) [9-10], the Bees Algorithm [31], Artificial Bee Colony algorithm (ABC) [25][28-29], Biogeography-based optimization (BBO) [30] , Cuckoo Search (CS) [26-27], Firefly Algorithm (FA) [32-33] , Bat Algorithm (BA) [20] and flower pollination algorithm[19] .",
      "startOffset" : 361,
      "endOffset" : 365
    }, {
      "referenceID" : 15,
      "context" : "The rising body of Swarm Intelligence(SI) [2] [3] metaheuristic algorithms include Particle Swarm Optimization (PSO) [1] [5], Ant Colony Optimization (ACO) [14], Glowworm Swarm Optimization (GSO) [8], Bacterial Foraging Optimization (BFO) [9-10], the Bees Algorithm [31], Artificial Bee Colony algorithm (ABC) [25][28-29], Biogeography-based optimization (BBO) [30] , Cuckoo Search (CS) [26-27], Firefly Algorithm (FA) [32-33] , Bat Algorithm (BA) [20] and flower pollination algorithm[19] .",
      "startOffset" : 387,
      "endOffset" : 394
    }, {
      "referenceID" : 16,
      "context" : "The rising body of Swarm Intelligence(SI) [2] [3] metaheuristic algorithms include Particle Swarm Optimization (PSO) [1] [5], Ant Colony Optimization (ACO) [14], Glowworm Swarm Optimization (GSO) [8], Bacterial Foraging Optimization (BFO) [9-10], the Bees Algorithm [31], Artificial Bee Colony algorithm (ABC) [25][28-29], Biogeography-based optimization (BBO) [30] , Cuckoo Search (CS) [26-27], Firefly Algorithm (FA) [32-33] , Bat Algorithm (BA) [20] and flower pollination algorithm[19] .",
      "startOffset" : 387,
      "endOffset" : 394
    }, {
      "referenceID" : 19,
      "context" : "The rising body of Swarm Intelligence(SI) [2] [3] metaheuristic algorithms include Particle Swarm Optimization (PSO) [1] [5], Ant Colony Optimization (ACO) [14], Glowworm Swarm Optimization (GSO) [8], Bacterial Foraging Optimization (BFO) [9-10], the Bees Algorithm [31], Artificial Bee Colony algorithm (ABC) [25][28-29], Biogeography-based optimization (BBO) [30] , Cuckoo Search (CS) [26-27], Firefly Algorithm (FA) [32-33] , Bat Algorithm (BA) [20] and flower pollination algorithm[19] .",
      "startOffset" : 419,
      "endOffset" : 426
    }, {
      "referenceID" : 20,
      "context" : "The rising body of Swarm Intelligence(SI) [2] [3] metaheuristic algorithms include Particle Swarm Optimization (PSO) [1] [5], Ant Colony Optimization (ACO) [14], Glowworm Swarm Optimization (GSO) [8], Bacterial Foraging Optimization (BFO) [9-10], the Bees Algorithm [31], Artificial Bee Colony algorithm (ABC) [25][28-29], Biogeography-based optimization (BBO) [30] , Cuckoo Search (CS) [26-27], Firefly Algorithm (FA) [32-33] , Bat Algorithm (BA) [20] and flower pollination algorithm[19] .",
      "startOffset" : 419,
      "endOffset" : 426
    }, {
      "referenceID" : 9,
      "context" : "The rising body of Swarm Intelligence(SI) [2] [3] metaheuristic algorithms include Particle Swarm Optimization (PSO) [1] [5], Ant Colony Optimization (ACO) [14], Glowworm Swarm Optimization (GSO) [8], Bacterial Foraging Optimization (BFO) [9-10], the Bees Algorithm [31], Artificial Bee Colony algorithm (ABC) [25][28-29], Biogeography-based optimization (BBO) [30] , Cuckoo Search (CS) [26-27], Firefly Algorithm (FA) [32-33] , Bat Algorithm (BA) [20] and flower pollination algorithm[19] .",
      "startOffset" : 448,
      "endOffset" : 452
    }, {
      "referenceID" : 8,
      "context" : "The rising body of Swarm Intelligence(SI) [2] [3] metaheuristic algorithms include Particle Swarm Optimization (PSO) [1] [5], Ant Colony Optimization (ACO) [14], Glowworm Swarm Optimization (GSO) [8], Bacterial Foraging Optimization (BFO) [9-10], the Bees Algorithm [31], Artificial Bee Colony algorithm (ABC) [25][28-29], Biogeography-based optimization (BBO) [30] , Cuckoo Search (CS) [26-27], Firefly Algorithm (FA) [32-33] , Bat Algorithm (BA) [20] and flower pollination algorithm[19] .",
      "startOffset" : 485,
      "endOffset" : 489
    }, {
      "referenceID" : 1,
      "context" : "(2003) [5] proposed data clustering approach using particle swarm optimization.",
      "startOffset" : 7,
      "endOffset" : 10
    }, {
      "referenceID" : 11,
      "context" : "(2008) [22] proposed a hybridized approach that combines PSO technique, Nelder– Mead simplex search and the K-means algorithm.",
      "startOffset" : 7,
      "endOffset" : 11
    }, {
      "referenceID" : 5,
      "context" : "Karaboga and Ozturk (2011) [15] presented a new clustering approach using Artificial Bee Colony (ABC) algorithm",
      "startOffset" : 27,
      "endOffset" : 31
    }, {
      "referenceID" : 12,
      "context" : "(2010) [23] presented the artificial bee colony (ABC) as a state-of-the-art approach to clustering.",
      "startOffset" : 7,
      "endOffset" : 11
    }, {
      "referenceID" : 6,
      "context" : "In [16] (2012), X.",
      "startOffset" : 3,
      "endOffset" : 7
    }, {
      "referenceID" : 8,
      "context" : "(2012) [19] presented a new PSO approach to the data clustering and the algorithm was tested using two synthetic datasets and five real datasets.",
      "startOffset" : 7,
      "endOffset" : 11
    }, {
      "referenceID" : 7,
      "context" : "Wan and his co-authors (2012) [17] presented data clustering using Bacterial Foraging Optimization (BFO).",
      "startOffset" : 30,
      "endOffset" : 34
    }, {
      "referenceID" : 8,
      "context" : "Flower Pollination Algorithm (FPA) is a global optimization algorithm, which was introduced by Xin-She Yang in 2012 [19], inspired by the pollination process of flowers.",
      "startOffset" : 116,
      "endOffset" : 120
    } ],
    "year" : 2015,
    "abstractText" : "Data clustering is a technique for clustering set of objects into known number of groups. Several approaches are widely applied to data clustering so that objects within the clusters are similar and objects in different clusters are far away from each other. K-Means, is one of the familiar center based clustering algorithms since implementation is very easy and fast convergence. However, K-Means algorithm suffers from initialization, hence trapped in local optima. Flower Pollination Algorithm (FPA) is the global optimization technique, which avoids trapping in local optimum solution. In this paper, a novel hybrid data clustering approach using Flower Pollination Algorithm and K-Means (FPAKM) is proposed. The proposed algorithm results are compared with K-Means and FPA on eight datasets. From the experimental results, FPAKM is better than FPA and K-Means.",
    "creator" : "Microsoft® Word 2013"
  }
}