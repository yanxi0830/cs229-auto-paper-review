{
  "name" : "1705.07252.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "SVM via Saddle Point Optimization: New Bounds and Distributed Algorithms",
    "authors" : [ "Yifei Jin", "Lingxiao Huang", "Jian Li" ],
    "emails" : [ ],
    "sections" : [ {
      "heading" : null,
      "text" : "), where n is the number of points and d is the dimensionality. To the best of our knowledge, the current best algorithm for hard margin SVM achieved by Gilbert algorithm [16] requires O(nd/ ) time. Our algorithm improves the running time by a factor of √ d/ √ . For ν-SVM, besides the well known quadratic programming approach which requires Ω(n2d) time [21, 31], no better algorithm is known. In the paper, we provide the first nearly linear time algorithm for ν-SVM. We also consider the distributed settings and provide distributed algorithms with low communication cost via saddle point optimization. Our algorithms require Õ(k(d+√ d/ )) communication cost where k is the number of clients, almost matching the theoretical lower bound."
    }, {
      "heading" : "1 Introduction",
      "text" : "Support Vector Machine (SVM) is a fundamental model for classification and regression [7, 11], widely used in many areas such as nature language process, computer vision, and bioinformatics. Consider a set of instance-label pairs (xi, yi) for i ∈ [n], xi ∈ Rd, yi ∈ {±1}. In the hard-margin scenario in which all labeled points are linearly separable, the goal of SVM is to find a separating hyperplane such that points with different labels are separated by the hyperplane, and the margin of separation is maximized. Several SVM variants have been designed to handle linearly non-separable cases (see [16]). The common strategy for these variants is to add a penalty term for the misclassified points. The most common penalty terms are l1- and l2-losses. The corresponding SVM variant for l2-loss is called l2-SVM or the standard version SVM in the literature. Theoretically, l1-loss penalty may be more robust in the presence of the outliers [42]. There are two well-known l1-loss SVMs called C-SVM and ν-SVM\nar X\niv :1\n70 5.\n07 25\n2v 3\n[ cs\n.L G\n] 2\n4 M\nrespectively. In comparison to C-SVM, which uses the l1-loss as the penalty term directly, the penalty term of ν-SVM is somewhat more complicated. ν-SVM is first proposed by Schölkopf and Smola [34]. The advantage of ν-SVM is that the parameter ν has a clearer meaning, which is always between [0, 1].1 Moreover, Schölkopf et al. [34] showed that ν is an upper bound on the fraction of margin errors and a lower bound on the fraction of support vectors.\nIn general, SVM and its variants can be formulated as convex quadratic programs. It takesO(n2d) time by solving quadratic programs directly [21, 31]. QP-based algorithms are widely used in open source projects such as libsvm [8], scikit-learn [30] and so on. However, the quadratic running time limits SVM to be used in much larger data sets. There are several improvements for some specific settings. For hard-margin SVM, based on the geometric linear separable property, Gartner and Jaggi [16] showed that Gilbert algorithm [17] achieves a (1− )-approximation with O(nd/ β2) running time where β is the distance between the two polytopes of the two types of points after we scale all points in a unit ball. For the l2-SVM and C-SVM, since we can transform the quadratic programs to a single-objective unconstrained optimization problem, there also exist efficient algorithms for the two variants [23, 35, 13, 13, 15, 2]. However, these techniques cannot be extended to ν-SVM directly because νSVM cannot be transformed to single-objective unconstrained optimization problems. Except the traditional quadratic programming approach such as Sequential Minimal Optimization(SMO) [31, 34], there is no better algorithm with the theoretical guarantee for ν-SVM.\nDistributed SVM has also attracted significant attention in recent years. The most popular distributed model is to store data in distributed sites, and those sites collaboratively solve the algorithmic problem of interest by communicating with each other through network links. A number of distributed algorithms for SVM in this setting have been obtained in the past [14, 29, 27, 26, 9, 18, 40]. Typically, the communication complexity is one of the most important performance measurements for distributed algorithms, and has been studied extensively (see [39, 28] and the book [24] for more details). For distributed hard-margin SVM, recently, Liu et al. [25] proposed a distributed algorithm with O(kd/ ) communication cost, where k is the number of the clients.\nOur Contributions: We summarize our main contributions as follows.\n1. Hard-Margin SVM: Inspired by the recent work of Zhang and Lin [41] and Allen-Zhu et al. [3], we propose a new perspective for solving hard-margin SVM via saddle point optimization. From the geometric point of view, it is known that training an SVM is equivalent to computing the polytope distance between two sets of points. We show that this view can be translated to a saddle point optimization problem. Then, we provide a new (1− )-approximation algorithm with running time Õ(nd+ n √ d/ √ β) 2 to solve the saddle point optimization,\nwhere n is the number of points, d is the dimension and β is a lower bound of the margin after scaling points to a unit ball. Compared to Gilbert algorithm [16], our algorithm improves the running time by a factor of √ d/ √ .\n1 On the contrary, the range of parameter C in C-SVM is from zero to infinity 2Õ notation hides logarithm factors such as log(n), log(β) and log(1/ ).\n2. ν-SVM: Different from other geometric methods such as Gilbert algorithm, our algorithm can be extended to an important linearly non-separable scenario, νSVM. It is known that ν-SVM is equivalent to computing the distance between two reduced polytopes [5, 12]. The obstacle for providing an efficient algorithm based on the reduced polytopes is that the number of vertices in the reduced polytopes may be exponentially large. However, in our framework, we do not need to compute the reduced polytopes explicitly. Instead, we only need to implicitly represent the reduced polytopes. We show that using the similar saddle point optimization framework, together with a projection method, ν-SVM can be solved efficiently by the same time complexity as the hard-margin case. Compared with the QP-based algorithms in previous work [21, 31], our algorithm significantly improves the running time, by a factor of n. To the best of our knowledge, this is the first nearly linear time algorithm for ν-SVM. The experimental result shows that our algorithm is much faster than the previous QP based algorithm NuSVC, implemented in scikit-learn [30].\n3. Distributed SVM: We also consider the distributed setting and provide a distributed algorithm for SVM with low communication cost. For hard-margin SVM, Liu et al. [25] proposed a distributed algorithm withO(kd/ ) communication cost where k is the number of the clients. We improve their result through adapting our saddle point optimization algorithms to the distributed setting. Note that our distributed algorithm works for both hard-margin SVM and ν-SVM. The communication cost of our algorithm is Õ(k(d+ √ d/ )), which is significantly\nbetter than the previous one if is very small and d is large. Moreover, this communication cost is almost optimal according to the lower bound provided in [25].\nThe paper is organized as follows. In Section 2.1, we prove that hard-margin SVM and ν-SVM are equivalent to saddle point optimization problems. Then we present our algorithms to solve the saddle point optimization problems and analyze the running time in Section 2.2. In Section 3, we provide the distributed version of our algorithms and analyze its communication complexity. In Section 4, we provide the experimental results, including our algorithm of ν-SVM versus the QP based algorithm NuSVC and our distributed algorithms for SVM versus traditional distributed algorithm HOGWILD! [32] and Gilbert Algorithm [16]. Due to space constraints, we defer many proof details and some experimental results to the appendix.\nRelated Work: Two important variants C-SVM and l2-SVM have been well studied in the literature. Basically, there are three main strategies: the primal gradient-based methods [23, 35, 13, 15, 2], dual quadratic programming methods [22, 36, 20] and dual geometry methods [38, 37]. Recently, Allen-Zhu [2] provided the current best algorithms which achieve O(nd/ √ ) time for l2-SVM and O(nd/ ) time for C-SVM.\nAllen-Zhu et al. [3] used the saddle point optimization and obtained an Õ(nd + n √ d/ √ ) algorithm for the minimum enclosing ball problem (MinEB) in Euclidean space. This result also implies algorithms for l2-SVM directly by the connection of MinEB and l2-SVM (see [38, 19, 16, 10, 33, 37]). Based on Tsang et al. [38, 37], the dual of l2-SVM is equivalent to a MinEB by a specific feature mapping.\nHowever, it maps the d-dimensional points to the (d + n)-dimensional space. Thus, we need quadratic time to solve l2-SVM by this mapping. To avoid this mapping, they designed an algorithm called Core Vector Machine (CVM), in which they solve O(1/ ) MinEB problems sequentially. Under this framework, it seems impossible to achieve an algorithm for l2-SVM with running time better than O(nd/ )."
    }, {
      "heading" : "2 Saddle Point Optimization for SVM",
      "text" : "In this section, we first formulate both hard-margin SVM and ν-SVM, and show that they can be reduced to saddle point optimizations. Then we provide an algorithm SVMSPSolver to solve the saddle point optimizations. For convenience, the default vectors in the paper are all column vectors."
    }, {
      "heading" : "2.1 Formulate SVM as Saddle Point Optimization",
      "text" : "Definition 1 (Hard-margin SVM). Suppose we have n points xi ∈ Rd for 1 ≤ i ≤ n. Each xi has a label yi ∈ {+1,−1}. Let P = {x+i | x+i = xi, yi = +1} and Q = {x−i | x−i = xi, yi = −1}. The goal of hard-margin SVM is to find a hyperplane H = {x ∈ Rd | wTx = b} that separates P from Q. Meanwhile, the distances from P to H and from Q to H are equial and the sum of such distances is maximized.\nFor convenience, we assume that in the hard margin case ‖xi‖2 ≤ 1 for 1 ≤ i ≤ n.3 Moreover, we assume that the margin is at least some constant β > 0. It is well known that hard-margin SVM can be formalized as the following quadratic programming [11].\nmin w,b\n1 2‖w‖2\ns.t. yi(wTxi − b) ≥ 1, ∀i (1)\nSuppose |P| = n1 and |Q| = n2. Let d×n1 matrix A = [x+1 , x+2 , . . . , x+n1 ] and d×n2 matrix B = [x−1 , x − 2 , . . . , x − n2 ]. The dual problem of (1) is equivalent to the problem of finding the two closest points between the convex hulls of two types of points [5]. We call the problem a C-Hull problem, defined as follows.\nmin w,b\n1 2‖Aη −Bξ‖2\ns.t. ‖η‖1 = 1, ‖ξ‖1 = 1. η ≥ 0, ξ ≥ 0. (2)\nSince ∑ i ηi = 1, we can regard it as a probability distribution among points in P (similarly for Q). We denote ∆n1 to be the set of n1-dimensional probability vectors over P and ∆n2 to be that over Q. Then, we prove that the C-Hull (2) is equivalent to the following saddle point optimization by Lemma 2. We defer the proof in Appendix A.\nOPT = max w min η∈∆n1 ,ξ∈∆n2 wTAη − wTBξ − 1 2 ‖w‖2 (3)\n3 It can be achieved by scale all data by factor 1/max ‖xi‖2 in O(n) time. In the paper, ‖ · ‖ represents the l2-norm.\nLemma 2. Problem C-Hull (2) is equivalent to the saddle point optimization (3).\nLet φ(w, η, ξ) = wTAη−wTBξ− 12‖w‖2. Note that φ(w, η, ξ) is only linear with respect to η and ξ. However, in order to obtain an algorithm which converges faster, we hope the objective function is strongly convex with respect to η and ξ. Fortunately, we can add a small regularization term which ensures that the objective function is strongly convex. This is a commonly used approach in optimization (see [3] for example). In this paper, we use the entropy function H(u) := ∑ i ui log ui as the regularization term. The new saddle point optimization problem is as follows.\nmax w min η∈∆n1 ,ξ∈∆n2 wTAη − wTBξ + γH(η) + γH(ξ)− 1 2 ‖w‖2, (4)\nwhere γ = β/2 log n. The following lemma describes the efficiency of the above saddle point optimization (4). We defer the proof to Appendix A.\nLemma 3. Let (w∗, η∗, ξ∗) and (w◦, η◦, ξ◦) be the optimal solution of saddle point optimizations (3) and (4) respectively. Define OPT as in (3). Define\ng(w) := min η∈∆n1 ,ξ∈∆n2 wTAη − wTBξ − 1 2 ‖w‖2.\nThen g(w∗)− g(w◦) ≤ OPT (note that g(w∗) = OPT).\nWe call the saddle point optimization (4) a Hard-Margin Saddle problem, abbreviated to HM-Saddle. Next, we discuss ν-SVM (see [12, 34]) and again provide an equivalent saddle point optimization formulation.\nDefinition 4 (ν-SVM). Given n points xi ∈ Rd for 1 ≤ i ≤ n, each xi has a label yi ∈ {+1,−1}. ν-SVM is the quadratic programming as follows.\nmin w,b,ρ,δ\n1 2‖w‖2 − ρ+ ν2 ∑ i δi\ns.t. yi(wTxi − b) ≥ ρ− δi, δi ≥ 0, ∀i (5)\nCrisp and Burges [12] present a geometry interpretation for ν-SVM. They proved that ν-SVM is equivalent to the problem of finding the closest distance between two reduced convex hulls as follows.\nmin η,ξ\n1 2‖Aη −Bξ‖2\ns.t. ‖η‖1 = 1, ‖ξ‖1 = 1. 0 ≤ ηi ≤ ν, 0 ≤ ξj ≤ ν, ∀i, j (6)\nWe call the above problem a Reduced Convex Hull problem, abbreviated to RC-Hull. The difference between problem C-Hull (2) and RC-Hull (6) is that in the latter one, each entry of η and ξ has an upper bound ν. Geometrically, it means to compress the convex hull of P and Q such that the two reduced convex hulls are separate. We define Dn1 to be the domain of η in RC-Hull, i.e., {η | ‖η‖1 = 1, 0 ≤ ηi ≤ ν, ∀i} and Dn2 to be the domain of ξ, i.e., {ξ | ‖ξ‖1 = 1, 0 ≤ ξj ≤ ν, ∀j}. Similar to Lemma 2, we have the following lemma. The proof is deferred to Appendix A.\nLemma 5. RC-Hull (6) is equivalent to the following saddle point optimization.\nOPT = max w min η∈Dn1 , ξ∈Dn2 wTAη − wTBξ − 1 2 ‖w‖2. (7)\nSimilarly, we add two entropy terms to make the objective function strongly convex with respective to η and ξ.\nmax w min η∈Dn1 , ξ∈Dn2 wTAη − wTBξ + γH(η) + γH(ξ)− 1 2 ‖w‖2. (8)\nwhere γ = β/2 log n. We call this problem a ν-Saddle problem. Similar to Lemma 3, we can prove that ν-Saddle (8) is (1− )-approximation of the saddle point optimization (13). See Lemma 8 in Appendix A for the details. Overall, we can solve hard-margin SVM and ν-SVM through solving HM-Saddle and ν-Saddle.4"
    }, {
      "heading" : "2.2 Saddle Point Optimization Algorithms for SVM",
      "text" : "In this section, we propose efficient algorithms to solve HM-Saddle (4) and ν-Saddle (8). The framework is inspired by the prior work by Allen-Zhu et al. [3]. They provide an algorithm L1L2SPSolver for saddle point optimization. However, we have mentioned in ‘related work’ that their algorithm does not imply an effective SVM algorithm directly. Instead, we show that under the same pre-processing step, through some modified update rules, we can apply their framework to solve HM-Saddle and ν-Saddle efficiently. For completeness, we briefly introduce their algorithm.\nRecall that we assume all points are in a unit ball, i.e., ‖xi‖2 ≤ 1. We first apply a randomized Hadamard space rotation as in [3]. Concretely speaking, let H be the d× d Walsh-Hadamard matrix and D be a d× d diagonal matrix whose entries are i.i.d. chosen from ±1 with equal probability. Then, we transform our data by left-producting the matrix HD. It is well known [1] that with high probability, for any point xi we have\n∀j ∈ [d], |(HDxi)j | ≤ O( √ log n/d).\nLet X+ = HDA and X− = HDB. It means that after transformation, with high probability, each entry in X+ or X− is at most O( √ log n/d). We can speed up this transformation to O(nd log d) time by FFT. After the data transformation, we initialize the necessary parameters. Here we use “α[t]” to represent the value of variable “α” at iteration t. For example, w[0], η[0], ξ[0] are the initial value of w, η, ξ. The preprocessing step is given by Algorithm 1. We denote Xi to be the ith row and X·j to be the jth column of a given matrix X .\nThen, we discuss the update rules. We call our algorithm SVMSPSolver and provide the details in Algorithm 2. In order to unify HM-Saddle and ν-Saddle in the same framework, we use (S1,S2) to represent the domains (∆n1 ,∆n2) in HM-Saddle and (Dn1 ,Dn2) in ν-Saddle. Let Vx(y) = H(y)−〈∇H(x), y−x〉−H(x) be the Bregman\n4The careful readers may doubt that the formulations of HM-Saddle and ν-Saddle only depends on (w, η, ξ) but not the offset b. In fact, according to the hyperplane bisecting the closest points in the (reduced) convex hulls, it is not difficult to prove that b∗ = w∗T(Aη∗ +Bξ∗)/2.\nAlgorithm 1 Pre-processing Input: P: n1 points x+i with label +1 and Q: n2 points x−i with label −1\n1: H ← d-dimensional Hadamard Matrix 2: D ← d× d diagonal matrix whose entries are i.i.d. chosen from ±1 3: X+ ← HD · [x+1 , x+2 , . . . , x+n1 ], X− ← HD · [x−1 , x−2 , . . . , x−n2 ] 4: w[0] ← [0, . . . , 0]T, η[−1] = η[0] ← [ 1n1 , . . . , 1 n1\n]T, ξ[−1] = ξ[0] ← [ 1n2 , . . . , 1 n2 ]T\n5: γ ← β2 logn , q ← O( √ log n), τ ← 12q √ d γ , σ ← 12q √ dγ, θ ← 1− 1 d+q √ d/ √ γ\nAlgorithm 2 Update Rules of SVMSPSolver 1: Pick an index i∗ in [d] uniformly at random , 2: δ+i∗ ← 〈X+i∗ , η[t] + θ(η[t]− η[t− 1])〉, δ−i∗ ← 〈X−i∗ , ξ[t] + θ(ξ[t]− ξ[t− 1])〉 3: ∀i ∈ [d], wi[t+ 1]← { (wi[t] + σ(δ + i − δ−i ))/(σ + 1), if i = i∗\nwi[t], if i 6= i∗ 4: η[t+1]← arg min\nη∈S1 { 1d (w[t]+d(w[t+1]−w[t]))TX+η+ γ dH(η)+ 1 τ Vη[t](η)}\n5: ξ[t+1]← arg min ξ∈S2 {− 1d (w[t]+d(w[t+1]−w[t]))TX−ξ+ γ dH(ξ)+ 1 τ Vξ[t](ξ)}\ndivergence function. Generally speaking, we alternatively maximize the objective with respect to w and minimize with respect to η and ξ. The update rules use some useful technique for speeding up the convergence, such as the proximal gradient method and momentum (see the book [6]). In the following, we analyze the update rules in details.\nFirstly, it is not hard to check that the update rule for w (line 3 in Algorithm 2) is equivalent to\nwi∗ [t+ 1] = arg max wi∗ − { −(δ+i∗ − δ−i∗)wi∗ + w2i∗ 2 + (wi∗ − wi∗ [t])2 2σ } (9)\nIn fact, this is a variant of the proximal coordinate gradient method with l2-norm regularization. In order to accelerate the convergence, we randomly select one dimension i∗ ∈ [d] and update the corresponding wi∗ in each iteration. Moreover, note that the term (δ+i∗ − δ−i∗) can be considered as the term (〈X+i∗ , η[t]〉 − 〈X−i∗ , ξ[t]〉) appending a momentum term. The update rules for η and ξ use the proximal gradient method with a Bergman divergence regularization. We also add a momentum term d(w[t+ 1]− w[t]) for primal variable w when updating η and ξ.\nWe need to show that we can solve the optimization problems in line 4 and 5 of Algorithm 2 efficiently. In fact, for both HM-Saddle and ν-Saddle, we can obtain explicit expressions of these two optimization problems using the method of Lagrange multipliers. Firstly, the explicit expressions of HM-Saddle for η and ξ are as follows.\nηi[t+ 1]← Φ(ηi[t], X+)/Z+, ξj [t+ 1]← Φ(ξj [t], X−)/Z−, ∀i ∈ [n1], j ∈ [n2] (10)\nwhere Z+ = ∑ i ηi[t+ 1], Z − = ∑ j ξj [t+ 1], and\nΦ(λi, X) = exp { (γ + dτ−1)−1(dτ−1 log λi − yi · 〈w[t] + d(w[t+ 1]− w[t], X·i)〉) } (11) Note that the factors Z+ and Z− are used to project the value Φ(ηi[t], X+) and Φ(ξj [t], X\n−) to the domains ∆n1 and ∆n2 . The above update rules of η and ξ can be also considered as the multiplicative weight update method (see [4]).\nThen we consider ν-Saddle. The update rules are similar but require a more careful projection method. Let ηi and ξj to be Φ(ηi[t], X+)/Z+ and Φ(ξj [t], X−)/Z− respectively. However, we have an extra constraint that ηi, ξj ≤ ν compared to HM-Saddle. Thus, we need another projection process (12) to ensure that η[t+ 1] and ξ[t+ 1] locate in domain Dn1 and Dn2 respectively. For convenience, we only present the projection for η here. The projection for ξ is similar.\nwhile ς := ∑ ηi>ν\n(ηi − ν) 6= 0 : Ω = ∑ ηi<ν\nηi ∀i, if ηi ≥ ν, then ηi = ν ∀i, if ηi < ν, then ηi = ηi(1 + ς/Ω)\n(12)\nNote that there are at most 1/ν (a constant) entries ηi of value ν during the whole projection process. In each iteration, there must be at least 1 more entry ηi = ν since we make all entries ηj > ν equal to ν after the iteration. Thus, the number of iterations in (12) is at most 1/ν. By (12), we project η and ξ to the domains Dn1 and Dn2 respectively. We still need to show the projection result of (12) is exactly the optimal solution in line 4. The proof is deferred to Appendix B. Thus, we need O(n/ν) time to compute η[t+ 1]. Since we assume that ν is a constant, it only costs linear time. If ν is extremely small, we have another update rule to get η[t+ 1] and ξ[t+ 1] in O(n log n) time. See Appendix B for details. Finally, we give our main theorem for our algorithm as follows. See the proof in Appendix C.\nTheorem 6. Algorithm 2 computes (1− )-approximate solutions for HM-Saddle and ν-Saddle by Õ(d+ √ d/ β) iterations. Moreover, it takes O(n) time for each iteration.\nCombining with Lemmas 2, 3, 5 and 8 we obtain (1− )-approximate solutions for CHull and RC-Hull problems. Hence by strong duality, we obtain (1− )-approximations for hard-margin SVM and ν-SVM in Õ(n(d+ √ d/ β)) time.\nTheorem 7. A (1− )-approximation for either hard-margin SVM or ν-SVM can be computed in Õ(n(d+ √ d/ β)) time."
    }, {
      "heading" : "3 Distributed SVM",
      "text" : "Server and Clients Model: We apply Algorithm SVMSPSolver in the distributed setting and call it DisSVMSPSolver. We consider a popular distributed setting: the server and clients model. Denote by S the server. Let C be the set of clients and |C| = k. We use the notation C.α to represent any variable α saved in client C and use S.α to represent a variable α saved in the server.\nFirst, we initialize some parameters in each client as the pre-processing step in Algorithm 1 (see Algorithm 3 for the pseudocode). Each client maintains the same random diagonal matrix Dd×d and the total number of points in each type (i.e, |P| = n1 and |Q| = n2).5 Moreover, each client C applies a Hadamard transformation to its own data and initialize the partial probability vectors C.η and C.ξ for its own points. We first consider HM-Saddle. The interaction between clients and the server can be divided into three rounds in each iteration.\n1. In the first round, the server randomly chooses a number i∗ ∈ [d] and broadcasts i∗ to all clients. Each client computes C.δ+i∗ and C.δ − i∗ and sends them back to\nthe server.\n2. In the second round, the server sums up all C.δ+i∗ and C.δ − i∗ and computes S.δ + i∗\nand S.δ−i∗ . We can see that S.δ + i∗ (resp. S.δ − i∗) is exactly δ + i∗ (resp. δ − i∗ ) in Algorithm 2. The server broadcasts S.δ+i∗ and S.δ − i∗ to all clients. By S.δ + i∗ and S.δ−i∗ , each client updates w individually. Moreover, each client C ∈ C updates its own C.η and C.ξ according to the new directional vector w. In order to normalize the probability vectors η and ξ, each client sends the summation C.Z+ and C.Z− to the server.\n3. In the third round, the server computes (S.Z+, S.Z−)←∑C∈C(C.Z+, C.Z−) and broadcasts to all clients the normalization factors S.Z+ and S.Z−. Finally, each client updates its partial probability vector C.η and C.ξ based on the normalization factors.\nAs we discuss in Section 2.2, for ν-Saddle, we need another O(1/ν) rounds to project η and ξ to the domains Dn1 and Dn2 .\n4. Each client computes C.ς+, C.ς− and C.Ω+, C.Ω− according to (12) and sends them to the server. The server sums up all C.ς+, C.ς−, C.Ω+, C.Ω− respectively and gets S.ς+, S.ς−, S.Ω+, S.Ω−. If both S.ς+ and S.ς− are zeroes, the server stops this iteration. Otherwise, the server broadcasts to all clients the factors S.ς+, S.ς−, S.Ω+, S.Ω−. All clients update their C.η and C.ξ according to (12) and repeat Step 4 again.\nWe give the pseudocode in Algorithm 4 in Appendix D. By Theorem 6, after T = Õ(d+ √ d/ ) iterations, all clients compute the same (1− )-approximate solution w = w[T ] for SVM. W.l.o.g, let the first client send w to the server. By at most O(n) more communication cost, the server can compute the offset b, the margin for hard-margin SVM and the objective value for the ν-SVM. The correctness of Algorithm DisSVMSPSolver is oblivious since we obtain the same w[t] as in SVMSPSolver after each iteration.\nCommunication Complexity of DisSVMSPSolver: We claim that the communication cost of DisSVMSPSolver is Õ(k(d+ √ d/ )), and show that the lower bound of the communication cost for distributed SVM is Ω(kmin{d, 1/ }). Note that if d = Θ(1/ ), the communication lower bound is Ω(k(d+ √ d/ )) which matches the communication cost of our algorithm DisSVMSPSolver. We defer the details to Appendix D. 5It can be realized using O(k) communication bits."
    }, {
      "heading" : "4 Experiments",
      "text" : "In this section, we first compare our SVMSPSolver with library NuSVC in scikitlearn [30]. We show that under the same parameters for ν-SVM6, our algorithm achieves better accuracy using significantly less time. Second, in the distributed setting, we compare DisSVMSPSolver with two distributed algorithms for SVM, HOGWILD! [32] and distributed Gilbert algorithm [25]. Our simulation show that our DisSVMSPSolver has lower communication cost in practice. The CPU of our platform is Intel(R) Xeon(R) CPU E5-2690 v3 @ 2.60GHz, and the system is CentOS Linux. We use both synthetic and real-world data sets. The real data is from [8]. See Appendix E for the way to generate synthetic data. Besides, more experimental results can be found in Appendix E.\nThe experimental results for ν-Saddle: We compare our SVMSPSolver with NuSVC in scikit-learn [30] and summarize the results in Table 1. In the table, we can see that the time cost of SVMSPSolver is much less than NuSVC when they achieve almost the same accuracy. Especially, the gap of the running time is more significant when the size of the data set is larger. For example, the time cost of NuSVC is more than two hundreds times larger than SVMSPSolver for the data set “covtype.binary”. The running time of SVMSPSolver is nearly linear to the size of data sets, which matches Theorem 6.\nDistributed experiments: In the distributed setting, we compare our algorithms with HOGWILD! [32] and distributed Gilbert algorithm [25]. The data is distributed to k = 20 nodes. We compare both linearly separable and non-separable cases.\nFor the separable cases, we compare the margins solved by the algorithms with respect to the communication cost. We compare the results for synthetic data sets with different dimensions. Moreover, we test them in the real-world data set “mushrooms”. The experimental results can be found in Figure 1 (a)-(d). Since it takes kd communication cost if each client sends a point to the server, we set one unit of x-coordinate to represent kd communication cost.\nFor the non-separable cases, we compare the accuracy of each algorithm based on the same communication cost. Again, we generate data to analyze the relationship between the running time and the dimensionality d. We also select the real world datasets “phishing” and “a9a” from [8]. We illustrate the objective function value of\n6Scikit-learn uses another equivalent form of ν-SVM. See the details in Appendix E.\n0.1\n0.1\n0.05\n0.2\nν-Saddle in each iteration in Figure 1 (e)-(h) and compare the accuracy of different algorithms in Figure 1 (i)-(l).\nThe experimental results are consistent with our theoretical results. DisSVMSPSolver achieves better results in both linearly separable and non-separable cases. The convergence rate of the distributed algorithm DisSVMSPSolver is better than the distributed HOGWILD! and Gilbert algorithm under the same communication cost. The performance gap is more significant when the dimensionality is larger. See Figure 1 (a)-(c) and Figure 1 (i)-(j) for examples."
    }, {
      "heading" : "A Missing Proofs in Section 2.1",
      "text" : "Lemma 2 (restated). Problem C-Hull (2) is equivalent to the saddle point optimization (3).\nProof. Consider the saddle point optimization (3). First, note that\nwTAη − wTBξ − 1 2 ‖w‖2 = wT(Aη −Bξ)− 1 2 ‖w‖2\nThe range of the term (Aη − Bξ) for η ∈ ∆n1 , ξ ∈ ∆n2 is a convex set, denoted by S. Since the convex hulls of P and Q are linearly separable, we have 0 /∈ S. Denote φ(w, z) = wTz − 12‖w‖2 for any w ∈ Rd, z ∈ S. Then (3) is equivalent to maxw minz∈S φ(w, z). Note that\nmax w min z∈S φ(w, z) ≥ min z∈S φ(0d, z) = 0.\nThus, we only need to consider those directions w ∈ Rd such that there exists a point z ∈ S with wT z ≥ 0. We useW to denote the collection of such directions.\nLet u be a unit vector inW . Denote zu := arg minz∈S φ(u, z) = arg minz∈S uT z. By this definition, zu is the point with smallest projection distance to u among S (see Figure 2). Observe that if a directionw = c·u (c > 0), then we have arg minz φ(w, z) = arg minz φ(u, z). Also note that\nmax w=c·u:c>0\nwTzu − 1\n2 ‖w‖2 = max w=c·u:c>0\n1 2 (−‖w − zu‖2 + ‖zu‖2).\nLet wu := arg maxw=c·u:c>0 φ(w, zu) = arg minw=c·u:c>0 ‖w − zu‖2. wu is the projection point of zu to the line ou, where o is the origin. See Figure 2 for an example.\nOverall, we have\nmax w min η∈∆n1 ,ξ∈∆n2 wT(Aη −Bξ)− 1 2 ‖w‖2\n= max u∈W:‖u‖=1\n1 2 (−‖wu − zu‖2 + ‖zu‖2)\n= max u∈W:‖u‖=1\n1 2 ‖wu‖2.\nThe last equality is by the Pythagorean theorem. Let z∗ be the closest point in S to the origin point. Next, we show that maxu∈W:‖u‖=1 ‖wu‖2 = ‖z∗‖2. Given a unit vector u ∈ W , define w′ to be the projection point of z∗ to the line ou. By the definition of zu and wu, we have that maxu ‖wu‖2 ≤ ‖w′‖2 ≤ ‖z∗‖2. Moreover, let u = z∗/‖z∗‖. In this case, we have ‖wu‖2 = ‖z∗‖2. Thus, we conclude that maxu ‖wu‖2 = ‖z∗‖2.\nOverall, we prove that\nmax u∈W:‖u‖=1\n1 2 ‖wu‖2 = 1 2 ‖z∗‖2 = min z∈S 1 2 ‖z‖2 = min\nη∈∆n1 ,ξ∈∆n2\n1 2 ‖Aη −Bξ‖2\nThus, C-Hull (2) is equivalent to the saddle point optimization (3).\nLemma 3 (restated). Let (w∗, η∗, ξ∗) and (w◦, η◦, ξ◦) be the optimal solution of saddle point optimizations (3) and (4) respectively. Define OPT as in (3). Define\ng(w) := min η∈∆n1 ,ξ∈∆n2 wTAη − wTBξ − 1 2 ‖w‖2.\nThen g(w∗)− g(w◦) ≤ OPT (note that g(w∗) = OPT). Proof. Let\nφ(w, η, ξ) = wTAη − wTBξ − 1 2 ‖w‖2,\nφγ(w, η, ξ) = φ(w, η, ξ) + γH(η) + γH(ξ),\nη̃, ξ̃ = argmin η∈∆n1 ,ξ∈∆n2\nφ(w◦, η, ξ).\nBy the definition of saddle points, we have\ng(w◦) = φ(w◦, η̃, ξ̃) = φγ(w ◦, η̃, ξ̃)− γH(η̃)− γH(ξ̃)\n≥ φγ(w◦, η◦, ξ◦)− γH(η̃)− γH(ξ̃) ≥ φγ(w∗, η◦, ξ◦)− γH(η̃)− γH(ξ̃) = φ(w∗, η◦, ξ◦)− γH(η̃)− γH(ξ̃) + γH(η◦) + γH(ξ◦) ≥ φ(w∗, η∗, ξ∗)− γH(η̃)− γH(ξ̃) + γH(η◦) + γH(ξ◦) = g(w∗)− γH(η̃)− γH(ξ̃) + γH(η◦) + γH(ξ◦) ≥ g(w∗)− γH(η̃)− γH(ξ̃).\nNote that entropy function satisfies 0 ≤ H(u) ≤ log n for any u ∈ ∆n. Thus, γH(η̃) +γH(ξ̃) ≤ β2 logn · (log n1 + log n2) ≤ OPT. Overall, we prove that g(w∗)− g(w◦) ≤ OPT.\nLemma 5 (restated). RC-Hull (6) is equivalent to the following saddle point optimization.\nOPT = max w min η∈Dn1 , ξ∈Dn2 wTAη − wTBξ − 1 2 ‖w‖2. (13)\nProof. The proof is almost the same to the proof of Lemma 2. The only difference is that the range of the term (Aη−Bξ) is another convex set defined by η ∈ Dn1 , ξ ∈ Dn2 .\nLemma 8. Let (w∗, η∗, ξ∗) and (w◦, η◦, ξ◦) be the optimal solution of saddle point optimizations (13) and (8) respectively. Define OPT as in (13). Define\ng(w) := min η∈Dn1 ,ξ∈Dn2 wTAη − wTBξ − 1 2 ‖w‖2.\nThen g(w∗)− g(w◦) ≤ OPT. Proof. Note that Dn1 is a convex polytope contained in ∆n1 and Dn2 is a convex polytope contained in ∆n2 . It is not hard to verify that the proof of Lemma 3 still holds for Dn1 and Dn2 ."
    }, {
      "heading" : "B The Equivalence of the Explicit and Implicit Update Rules of η and ξ",
      "text" : "Lemma 9 (Update Rules of HM-Saddle). The following two update rules are equivalent.\n• η[t+1] = arg min η∈∆n1\n{ 1 d (w[t] + d(w[t+ 1]− w[t]))TXη + γ dH(η) + 1 τ Vη[t](η) } • ηi = Z−1 exp { (γ + dτ−1)−1(dτ−1 log ηi[t]− 〈w[t] + d(w[t+ 1]− w[t]), X·i〉)\n} for each i ∈ [n1], where Z = ∑ i ηi 7\nProof. The Lagrangian function of the first optimization formulation is\nL(η, λ) = 1 d (w[t] + d(w[t+ 1]− w[t]))TXη + γ d H(η) + 1 τ Vη[t](η) + λ( ∑ i ηi − 1)\nThus, we have\n∂L ∂ηi = 0 = (γd−1 + τ−1) log ηi + d −1〈w[t] + d(w[t+ 1]− w[t]), X·i〉 − τ−1 log ηi[t] + (λ+ τ−1),∀i ∂L ∂λ = 0 = −1 + ∑ i ηi\nSolve the above equalities, we obtain\nηi[t+1] = Z −1 exp { (γ + dτ−1)−1(dτ−1 log ηi[t]− 〈w[t] + d(w[t+ 1]− w[t]), X·i〉 } 7Recall that X·i is the ith column of X .\nLemma 10 (Update Rules of ν-Saddle). The following three update rules are equivalent.\nRule 1: η[t+1] = arg min η∈S1\n{ 1 d (w[t] + d(w[t+ 1]− w[t]))TXη + γ dH(η) + 1 τ Vη[t](η) } Rule 2:\n• Step 1: ηi = Z−1 exp { (γ + dτ−1)−1(dτ−1 log ηi[t]− 〈w[t] + d(w[t+ 1]− w[t]), X·i〉) }\nfor each i ∈ [n1], where Z = ∑ i ηi.\n• Step 2: Sort ηi by the increasing order. W.l.o.g., assume that η1, . . . , ηn1 is in increasing order. Define ςi = ∑ j≥i(ηj − ν) and Ωi = ∑ j<i ηj . Find the largest\nindex i∗ ∈ [n] such that ςi∗ ≥ 0 and ηi∗−1(1 + ςi∗/Ωi∗) < ν by binary search.\n• Step 3: ∀i, ηi[t+ 1] =\n{ ηi(1 + ςi∗/Ωi∗), if i < i∗\nν, if i ≥ i∗\nRule 3: • Step 1: ηi = Z−1 exp { (γ + dτ−1)−1(dτ−1 log ηi[t]− 〈w[t] + d(w[t+ 1]− w[t]), X·i〉) }\nfor each i ∈ [n1], where Z = ∑ i ηi.\n• Step 2: while ς := ∑ ηi>ν\n(ηi − ν) 6= 0 : Ω = ∑ ηi<ν\nηi ∀i, if ηi ≥ ν, then ηi = ν ∀i, if ηi < ν, then ηi = ηi(1 + ς/Ω)\n(14)\nProof. Similar to the proof of Lemma 9, we first give the Lagrangian function of the first optimization formulation as follows.\nL(η, λ, σ) = 1 d (w[t]+d(w[t+1]−w[t]))TXη+γ d H(η)+ 1 τ Vη[t](η)+λ( ∑ i ηi−1)+ ∑ i αi(ηi−ν)\nBy KKT conditions, we have the following.\n0 = (γd−1 + τ−1) log ηi + d −1〈w[t] + d(w[t+ 1]− w[t]), X·i〉 − τ−1 log ηi[t] + (λ+ αi + τ−1),∀i 1 = ∑ i ηi 0 = αi(ηi − ν),∀i 0 ≥ ηi − ν, ∀i 0 ≤ αi,∀i\nWe first show the equivalence between Rule 1 and Rule 2. Note that η[t+ 1] in Rule 2 satisfies the second and the fourth KKT conditions. We only need to give all αi and λ satisfying other KKT conditions for Rule 2. Let\nη̃i = exp { (γ + dτ−1)−1(dτ−1 log ηi[t]− 〈w[t] + d(w[t+ 1]− w[t]), X·i〉) } .\nLet\nηi = Z −1η̃i = Z −1 exp { (γ + dτ−1)−1(dτ−1 log ηi[t]− 〈w[t] + d(w[t+ 1]− w[t]), X·i〉) }\nas defined in Step 1 of Rule 2. For 1 ≤ i ≤ i∗ − 1, let αi = 0. For i ≥ i∗, let\nαi = (γd −1 + τ−1)−1 ln\nηi(1 + ςi∗/Ωi∗)\nν ≥ 0.\nThe inequality follows from the definition of i∗. Note that we only need to prove that ηi∗(1 + ςi∗/Ωi∗) ≥ ν. If i∗ ≥ ν, then the above inequality holds directly. Otherwise if ηi∗ < ν and ηi∗(1 + ςi∗/Ωi∗) < ν, we have that ςi∗+1 = ςi∗ + ν − ηi∗ > 0 and Ωi∗+1 = Ωi∗ + ηi∗ . We also have the following inequality\nηi∗(1 + ςi∗+1 Ωi∗+1 )− ν = ηi∗(ςi∗ + Ωi∗)− Ωi∗ν Ωi∗ + ηi∗ = ηi∗(1 + ςi∗/Ωi∗)− ν Ωi∗(Ωi∗ + ηi∗) < 0,\nwhich contradicts with the definition of i∗. Finally, randomly choose an index i, let\nλ = (γd−1 + τ−1)−1 ln Zηi\nηi[t+ 1] − αi − τ−1.\nBy the chosen of αi, it is not hard to check that the value of λ is the same for any index i. Thus, ηi[t+ 1], αi and λ are the unique solution of KKT conditions. So Rule 1 and Rule 2 are equivalent. By a similar argument (define suitable αi and λ), we can prove that Rule 1 and Rule 3 are equivalent, which finishes the proof.\nRemark 11. We analyze Rule 2 in Lemma 10. Roughly speaking, we find a suitable value ηi∗ , set all value ηj > ηi∗ to be ν, and scales up other values by some factor 1 + ςi∗/Ωi∗ . We can verify that the running time of Rule 2 is O(n log n) since both the sorting time and the binary search time are O(n log n). On the other hand, recall that the running time of Rule 3 is O(n/ν) (explained in Section 2.2). Thus, if the parameter ν is extremely small, we can use Rule 2 in practice."
    }, {
      "heading" : "C Proof of Theorem 6",
      "text" : "For preparation, we give two useful Lemmas 12 and 13. The two lemmas generalize Lemma A.1 and Lemma A.2 in [3] by changing the domain ∆m to a convex polytope Sm contained in ∆m. Fortunately, the proofs of Lemma A.1 and Lemma A.2 still work for the following general version. We omit detail proofs here. Recall that Vx(y) is the Bregman divergence function which is defined as H(y)− 〈∇H(x), y − x〉 −H(x).\nLemma 12. Let x2 = argminz∈Sm { Vx1 (z) τ + γH(z) }\n. Let Sm be a convex polytope contained in ∆m. Then for every u ∈ Sm, we have\n1 τ Vx1(u)−\n( 1\nτ + η\n) Vx2(u)− 1\n2τ ‖x2 − x1‖21 ≥ γH(x2)− γH(u).\nLemma 13. Let x = argminz∈Sm {H(z)}. Let Sm be a convex polytope contained in ∆m. Then for all u ∈ Sm,\nH(u)−H(x) ≥ Vx(u). Combing the above lemmas and an almost same analysis as in Theorem 2.2 in [3],\nwe obtain the following Theorem 14.\nTheorem 14. After T iterations of Algorithm 2 (both HM-Saddle and ν-Saddle versions), we obtain a directional vector w[T ] ∈ Rd satisfying that\n(τ−1 + 2γd−1)E [ Vη[T ](η ◦) + Vξ[T ](ξ ◦) ]\n+ ((4σ)−1 + 1)E[‖w◦ − w[T ]‖2] ≤θT · ( 2 ( τ−1 + 2γd−1 ) log n+ ((2σ)−1 + 1)‖w◦‖2 ) ,\nwhere τ ← 12q √ d γ , σ ← 12q √ dγ, θ ← 1− 1 d+q √ d/ √ γ , for some q = O( √ log n).\nProof Sketch. The difference between our statement and Theorem 2.2 in [3] is that we update two probability vectors η and ξ instead of one in an iteration. Thus, we have two terms Vη[T ](η◦) and Vξ[T ](ξ◦) on the left hand side. Moreover, we care about convex polytopes S1 ⊂ ∆n1 and S2 ⊂ ∆n2 instead of ∆n1 and ∆n2 .\nHowever, these differences do not influence the correctness of the proof of Theorem 2.2 in [3]. Note that we replace Lemma A.1 and Lemma A.2 in [3] by Lemma 12 and Lemma 13. It is not hard to verify the proof of Theorem 2.2 in [3] works for our theorem.\nWe also need the following lemma.\nLemma 15. Define\ng(w) := min η∈S1,ξ∈S2 wTAη − wTBξ − 1 2 ‖w‖2.\nwhere S1 and S2 are two convex polytopes such that S1 ⊂ ∆n1 and S2 ⊂ ∆n2 . For any u, v ∈ Rd, we have\ng(u)− g(v) ≤ 2(1 + ‖v‖)‖u− v‖. Proof. Denote by ∇g(w) any subgradient of g(w) at point w. We write ∇g(w) = Aη̃w −Bξ̃w −w for any arbitrary η̃w ∈ S1, ξ̃w ∈ S2 satisfying that g(w) = wTAη̃w − wTBξ̃w − ‖w‖2. Note that Aη̃w (resp. Bξ̃w) can be considered as a weighted combination of all points xi (resp. xi), we claim that ‖Aη̃w‖ ≤ 1 (‖Bξ̃w‖ ≤ 1) owing to the assumption that every xi satisfies ‖xi‖ ≤ 1. Next, we compute as follows\ng(u)− g(v) = ∫ 1 τ=0 〈∇g(v + τ(u− v)), u− v〉dτ\n= ∫ 1 τ=0 〈Aη̃v+τ(u−v) −Bξ̃v+τ(u−v) − (v + τ(u− v)), u− v〉dτ\n≤‖Aη̃v+τ(u−v)‖‖u− v‖+ ‖Bξ̃v+τ(u−v)‖‖u− v‖+ ∫ 1 τ=0 〈−v, u− v〉dτ − 1 2 ‖u− v‖2 ≤‖u− v‖+ ‖u− v‖+ ‖v‖‖u− v‖ ≤ 2(1 + ‖v‖)‖u− v‖.\nNow we are ready to prove Theorem 6 as follows.\nTheorem 6 (restated). Algorithm 2 computes (1− )-approximate solutions for HMSaddle and ν-Saddle by Õ(d + √ d/ β) iterations. Moreover, it takes O(n) time for each iteration.\nProof. Let\nψ(n, d) = ( 2 ( τ−1 + 2γd−1 ) log n+ ((2σ)−1 + 1)‖w◦‖2 ) · ((4σ)−1 + 1)−1\nAccording to Theorem 14, we have\nE[‖w◦ − w[T ]‖2] ≤ θTψ(n, d)⇒ E[‖w◦ − w[T ]‖] ≤ θT/2ψ1/2(n, d)\nIn order to get a (1− )-approximate solution, according to Lemma 15, it suffices to choose T such that\nE [ g(w◦)− g(w[T ]) ] ≤ E [ 2(1 + ‖w[T ]‖) · ‖w◦ − w[T ]‖ ] ≤ 2E [( 1 + ‖w◦ − w[T ]‖+ ‖w◦‖ ) · ‖w◦ − w[T ]‖\n] = 2E [ ‖w◦ − w[T ]‖2 ] + 2E [ (1 + ‖w◦‖)‖w◦ − w[T ]‖\n] ≤ 2θTψ(n, d) + 2(1 + ‖w◦‖)θT/2ψ1/2(n, d) ≤ OPT.\nNote that θ = 1− 1 d+q √ d/ √ γ = 1− 1 d+q √ d/ √ β/2 logn . Thus, we only need to have\nT ≥ logθ ( OPT\n2ψ(n, d)\n) + 2 logθ ( OPT\n1 + ‖w◦‖ · ψ −1/2(n, d) ) ≥ 2(d+ √ 2d/ β ·O(log n)) log ( (1 + ‖w◦‖)ψ(n, d)\nOPT ) = Ω̃(d+ √ d/ β)"
    }, {
      "heading" : "D Missing Details in Section 3",
      "text" : "First, we give the pseudocode of DisSVMSPSolver. See Algorithm 3 for the preprocessing step for each clients. Recall that we assume there arem1 points x+1 , x + 2 , . . . , x + m1 and m2 points x−1 , x − 2 , . . . , x − m2 maintained in C. We use 1\nm to denote a vector with all components being 1. The initialization is as follows.\nC.X+ = HD · [x+1 , x+2 , . . . , x+m1 ], C.η[−1] = C.η[0] = n−11 1m1 C.X− = HD · [x−1 , x−2 , . . . , x−m2 ], C.ξ[−1] = C.ξ[0] = n−12 1m2\nAlgorithm 3 Pre-processing in Clients Input: P: n1 points x+i with label +1 and Q: n2 points x−i with label −1, distributed\nat k clients 1: for all clients in C do 2: H ← d-dimensional Hadamard Matrix 3: D ← d× d diagonal matrix whose entries are i.i.d. chosen from ±1 4: γ ← β2 logn , q ← O( √ log n)\n5: τ ← 12q √ d γ , σ ← 12q √ dγ, θ ← 1− 1 d+q √ d/ √ γ . 6: d-dimension vector w(0) ← [0, . . . , 0] 7: end for 8: for client C ∈ C do 9: Assume that there are m1 points x+1 , . . . , x + m1 and m2 points x − 1 , . . . , x − m2 main-\ntained in C 10: C.X+ ← HD · [x+1 , x+2 , . . . , x+m1 ], 11: C.X− ← HD · [x−1 , x−2 , . . . , x−m2 ], 12: C.η[−1] = C.η[0]← [ 1n1 , . . . , 1 n1\n]T ∈ Rm1 , 13: C.ξ[−1] = C.ξ[0]← [ 1n2 , . . . , 1 n2\n]T ∈ Rm2 . 14: end for\nNext, see Algorithm 4 for the interactions between the server and clients in every iteration. Note that only ν-Saddle needs the fourth round in Algorithm 4. We use flagν ∈ {True,False} to distinguish the two cases. If we consider ν-Saddle, let flagν be True. Otherwise, let flagν be False.\nThen, we analyze the communication cost. Theorem 16. The communication cost of DisSVMSPSolver is Õ(k(d+ √ d/ )).\nProof. Note that in each iteration of Algorithm 4, the server and clients interact three times for hard-margin SVM and O(1/ν) times for ν-SVM. The communication cost of each iteration is O(k). By Theorem 6, it takes Õ(d+ √ d/ ) iterations. Thus, the total\ncommunication cost is Õ(k(d+ √ d/ )).\nLiu et al. [25] proved a theoretical lower bound of the communication cost for distributed SVM as follows. Note that the statement of Theorem 17 is not exactly the same as the Theorem 6 in Liu et al. [25]. This is because they omit the case that d < 1/ . We prove that they are equivalent briefly. Note that if d = Θ(1/ ), the communication lower bound is Ω(k(d + √ d/ )) which matches the communication cost of our algorithm DisSVMSPSolver.\nTheorem 17 (Theorem 6 in [25]). Consider a set of d-dimension points distributed at k clients. The communication cost to achieve a (1− )-approximation of the distributed SVM problem is at least Ω(kmin{d, 1/ }) for any > 0.\nProof Sketch. In Theorem 6 of [25], the authors obtain a lower bound Ω(kd) if ≤ ( √ 17 − 4)/16).. Their proof can be extended to the case ≥ ( √ 17 − 4)/16).. In this\ncase, we can make a reduction from the k-OR problem in which each client maintains a (( √\n17− 4)/16 )-bit vector instead of a d-bit vector. As the proof of Theorem 6 in [25], we can obtain a lower bound Ω(k/ ), which proves the theorem."
    }, {
      "heading" : "E Supplementary of Experiments",
      "text" : "Data set: We use both synthetic and real-world data sets. The real data is from [8]. The synthetic data is generated as follows. For the separable data, we randomly choose a hyperplane H which overlaps with the unit norm ball in Rd space. Then we randomly sample n points in a subset of the unit ball such that the ratio of the maximum distance among the points to H over the minimum distance to H is β1 = 0.1. Let the labels of points above H be +1 and let others be −1. For the non-separable data, the difference is that for those points with distance to H smaller than β2 = 0.1, we randomly choose their labels to be +1 or −1 with equal probability. Moreover, we also use real-world including the separable data set “mushrooms” and non-separable ones “w8a”, “gisette”, “madelon”, “phishing”, “a1a”, “a5a”,“a9a”, “ijcnn1”, “covtype.binary”, “higgs”.\nExperiments of unbalance data sets: We also process some unbalanced data sets in which one type of points is much more than the other types of points. In this case, classifying all test points to the major type could achieve a good accuracy. However, this classifier is not useful in practice. Instead, we often use true positive rate (TPR) and true negative rate (TNR) to measure a classifier over such data sets. By the experimental results, our SVMSPSolver achieves more reasonable TPR and TNR, i.e., |TPR − TNR| is smaller. See Table 2 for the details. Thus, the performance of our algorithm SVMSPSolver is better for the unbalance data. 8\nMore distributed experiments for SVM: Besides the results in Figure 1, we test more data sets for the distributed algorithms. We give the results in Figure 4. By the experimental results, we obtain the same conclusion as in Section 4.\nIn the following, we give some remarks for the Gilbert Algorithms and HOGWILD! by the experimental results.\nNuSVC in scikit-learn: The form of the ν-SVM used in scikit-learn is a variant of the 8Note that the performance of SVMSPSolver and NuSVC are not same for the unbalance data. This is because their bias b are not exactly the same. See [5, 12] for more explanations.\nform in the paper. We give the formulation as follows.\nmin w,b,ρ,δ\n1 2‖w‖2 − µρ′ + 1n ∑ i δi\ns.t. yi(wTxi − b) ≥ ρ′ − δi, δi ≥ 0, ∀i (15)\nCrisp and Burges [12] prove that through reparameterizing, the above formulation is equivalent to ν-SVM (5). Concretely speaking, let\nν = 2\nµn , ρ =\nρ′ µ .\nThen, (15) can be transformed to ν-SVM (5).\nRemark 18. The Gilbert Algorithm only has performance guarantee for the linearly separable data. The accuracy of Gilbert Algorithm for the non-separable cases is unstable and not good.\nRemark 19. Note that HOGWILD! is a lock-free stochastic gradient descent algorithm. Theoretically, the HOGWILD! can only process the non-separable case. In order to compare with our HM-Saddle algorithm, we set the penalty coefficient of HOGWILD! to be a very large constant to approximately solve the separable case.\nAlgorithm 4 DisSVMSPSolver 1: for t← 0 to T − 1 do 2: # first round 3: Server: Pick an index i∗ ∈ {1, 2, . . . , d} uniformly at random and send i∗ to\nevery client. 4: for client C ∈ C do 5: C.δ+i∗ ← 〈C.X+i∗ , C.η[t] + θ(C.η[t]− C.η[t− 1])〉 6: C.δ−i∗ ← 〈C.X−i∗ , C.ξ[t] + θ(C.ξ[t]− C.ξ[t− 1])〉 7: Send C.δ+i∗ and C.δ − i∗ to server. 8: end for 9: # second round\n10: Server: Let S.δ+i∗ = ∑ C∈C C.δ + i∗ and S.δ − i∗ = ∑ C∈C C.δ − i∗ . Broadcast S.δ + i∗ and S.δ−i∗ . 11: for client C ∈ C do 12: ∀i ∈ [d], wi[t+ 1]← { (wi[t] + σ(S.δ + i − S.δ−i ))/(σ + 1), if i = i∗ wi[t], if i 6= i∗ 13: ∀j, C.ηj [t+1]← exp { (γ + dτ−1)−1(dτ−1 logC.ηj [t]− 〈w[t] + d(w[t+ 1]− w[t]), C.X+·j 〉)\n} 14: ∀j, C.ξj [t+1]← exp { (γ + dτ−1)−1(dτ−1 logC.ξj [t] + 〈w[t] + d(w[t+ 1]− w[t]), C.X−·j 〉)\n} 15: C.Z+ ←∑j C.ηj [t+ 1], C.Z− ←∑j C.ξj [t+ 1] 16: Send C.Z+ and C.Z− to server 17: end for 18: # third round 19: Server: Let (S.Z+, S.Z−)←∑C∈C(C.Z+, C.Z−), and broadcast S.Z+ and S.Z−. 20: for client C ∈ C do 21: C.ηj [t+ 1]← C.ηj [t+ 1]/S.Z+, ∀C.ξj [t+ 1]← C.ξj [t+ 1]/S.Z− 22: end for 23: # fourth round, only for ν-Saddle. flagν is true if use the code for ν-Saddle 24: if flagν is True then 25: repeat 26: for client C ∈ C do 27: C.ς+ = ∑ ηi>ν (ηi − ν), C.Ω+ = ∑ ηi<ν\nηi. 28: C.ς− = ∑ ξj>ν (ξj − ν), C.Ω− = ∑ ξj<ν\nξj . 29: Send C.ς+, C.ς−, C.Ω+, C.Ω− to server. 30: end for 31: Server: Broadcast (S.ς+, S.ς−, S.Ω+, S.Ω−)←∑C∈C(C.ς+, C.ς−,C.Ω+,C.Ω−). 32: for client C ∈ C do 33: ∀i, if ηi > ν, then ηi = ν; ∀i, if ηi < ν, then ηi = ηi(1 + S.ς+/S.Ω+) 34: ∀j, if ξj > ν, then ξj = ν; ∀j, if ξj < ν, then ξj = ξj(1 + S.ς−/S.Ω−) 35: end for 36: until S.ς+ and S.ς− are zeroes 37: end if 38: end for 26"
    } ],
    "references" : [ {
      "title" : "Faster dimension reduction",
      "author" : [ "Nir Ailon", "Bernard Chazelle" ],
      "venue" : "Communications of the ACM,",
      "citeRegEx" : "1",
      "shortCiteRegEx" : "1",
      "year" : 2010
    }, {
      "title" : "Katyusha: The first direct acceleration of stochastic gradient methods",
      "author" : [ "Zeyuan Allen-Zhu" ],
      "venue" : "Proceedings of the 49th annual ACM symposium on theory of computing,",
      "citeRegEx" : "2",
      "shortCiteRegEx" : "2",
      "year" : 2016
    }, {
      "title" : "Optimization algorithms for faster computational geometry",
      "author" : [ "Zeyuan Allen-Zhu", "Zhenyu Liao", "Yang Yuan" ],
      "venue" : "In LIPIcs-Leibniz International Proceedings in Informatics,",
      "citeRegEx" : "3",
      "shortCiteRegEx" : "3",
      "year" : 2016
    }, {
      "title" : "The multiplicative weights update method: a meta-algorithm and applications",
      "author" : [ "Sanjeev Arora", "Elad Hazan", "Satyen Kale" ],
      "venue" : "Theory of Computing,",
      "citeRegEx" : "4",
      "shortCiteRegEx" : "4",
      "year" : 2012
    }, {
      "title" : "Duality and geometry in svm classifiers",
      "author" : [ "Kristin P Bennett", "Erin J Bredensteiner" ],
      "venue" : "In International Conference on Machine Learning (ICML),",
      "citeRegEx" : "5",
      "shortCiteRegEx" : "5",
      "year" : 2000
    }, {
      "title" : "Convex optimization algorithms",
      "author" : [ "Dimitri P Bertsekas", "Athena Scientific" ],
      "venue" : "Athena Scientific Belmont,",
      "citeRegEx" : "6",
      "shortCiteRegEx" : "6",
      "year" : 2015
    }, {
      "title" : "A training algorithm for optimal margin classifiers",
      "author" : [ "Bernhard E Boser", "Isabelle M Guyon", "Vladimir N Vapnik" ],
      "venue" : "In Proceedings of the fifth annual workshop on Computational learning theory,",
      "citeRegEx" : "7",
      "shortCiteRegEx" : "7",
      "year" : 1992
    }, {
      "title" : "Libsvm: a library for support vector machines",
      "author" : [ "Chih-Chung Chang", "Chih-Jen Lin" ],
      "venue" : "ACM Transactions on Intelligent Systems and Technology (TIST),",
      "citeRegEx" : "8",
      "shortCiteRegEx" : "8",
      "year" : 2011
    }, {
      "title" : "Psvm: Parallelizing support vector machines on distributed computers",
      "author" : [ "Edward Y Chang" ],
      "venue" : "In Foundations of Large-Scale Multimedia Information Management and Retrieval,",
      "citeRegEx" : "9",
      "shortCiteRegEx" : "9",
      "year" : 2011
    }, {
      "title" : "Coresets, sparse greedy approximation, and the frank-wolfe algorithm",
      "author" : [ "Kenneth L Clarkson" ],
      "venue" : "ACM Transactions on Algorithms (TALG),",
      "citeRegEx" : "10",
      "shortCiteRegEx" : "10",
      "year" : 2010
    }, {
      "title" : "A geometry interpretation of μ-svm classifiers",
      "author" : [ "DJ Crisp", "CJC Burges" ],
      "venue" : "Advances in Neural Information Processing Systems (NIPS",
      "citeRegEx" : "12",
      "shortCiteRegEx" : "12",
      "year" : 2000
    }, {
      "title" : "Efficient online and batch learning using forward backward splitting",
      "author" : [ "John Duchi", "Yoram Singer" ],
      "venue" : "Journal of Machine Learning Research,",
      "citeRegEx" : "13",
      "shortCiteRegEx" : "13",
      "year" : 2009
    }, {
      "title" : "Consensus-based distributed support vector machines",
      "author" : [ "Pedro A Forero", "Alfonso Cano", "Georgios B Giannakis" ],
      "venue" : "Journal of Machine Learning Research,",
      "citeRegEx" : "14",
      "shortCiteRegEx" : "14",
      "year" : 2010
    }, {
      "title" : "Optimized cutting plane algorithm for support vector machines",
      "author" : [ "Vojtěch Franc", "Soeren Sonnenburg" ],
      "venue" : "In Proceedings of the 25th international conference on Machine learning,",
      "citeRegEx" : "15",
      "shortCiteRegEx" : "15",
      "year" : 2008
    }, {
      "title" : "Coresets for polytope distance",
      "author" : [ "Bernd Gärtner", "Martin Jaggi" ],
      "venue" : "In Proceedings of the twenty-fifth annual symposium on Computational geometry,",
      "citeRegEx" : "16",
      "shortCiteRegEx" : "16",
      "year" : 2009
    }, {
      "title" : "An iterative procedure for computing the minimum of a quadratic form on a convex set",
      "author" : [ "Elmer G Gilbert" ],
      "venue" : "SIAM Journal on Control,",
      "citeRegEx" : "17",
      "shortCiteRegEx" : "17",
      "year" : 1966
    }, {
      "title" : "Parallel support vector machines: The cascade svm",
      "author" : [ "Hans Peter Graf", "Eric Cosatto", "Leon Bottou", "Igor Durdanovic", "Vladimir Vapnik" ],
      "venue" : "In Advances in Neural Information Processing Systems,",
      "citeRegEx" : "18",
      "shortCiteRegEx" : "18",
      "year" : 2004
    }, {
      "title" : "Maximum margin coresets for active and noise tolerant learning",
      "author" : [ "Sariel Har-Peled", "Dan Roth", "Dav Zimak" ],
      "venue" : "In International Joint Conference on Artificial Intelligence,",
      "citeRegEx" : "19",
      "shortCiteRegEx" : "19",
      "year" : 2007
    }, {
      "title" : "A dual coordinate descent method for large-scale linear svm",
      "author" : [ "Cho-Jui Hsieh", "Kai-Wei Chang", "Chih-Jen Lin", "S Sathiya Keerthi", "Sellamanickam Sundararajan" ],
      "venue" : "In Proceedings of the 25th international conference on Machine learning,",
      "citeRegEx" : "20",
      "shortCiteRegEx" : "20",
      "year" : 2008
    }, {
      "title" : "Making large-scale svm learning practical",
      "author" : [ "Thorsten Joachims" ],
      "venue" : "Technical report,",
      "citeRegEx" : "21",
      "shortCiteRegEx" : "21",
      "year" : 1998
    }, {
      "title" : "Training linear svms in linear time",
      "author" : [ "Thorsten Joachims" ],
      "venue" : "In Proceedings of the 12th ACM SIGKDD international conference on Knowledge discovery and data mining,",
      "citeRegEx" : "22",
      "shortCiteRegEx" : "22",
      "year" : 2006
    }, {
      "title" : "Online learning with kernels",
      "author" : [ "Jyrki Kivinen", "Alexander J Smola", "Robert C Williamson" ],
      "venue" : "IEEE transactions on signal processing,",
      "citeRegEx" : "23",
      "shortCiteRegEx" : "23",
      "year" : 2004
    }, {
      "title" : "Communication complexity",
      "author" : [ "Eyal Kushilevitz" ],
      "venue" : "Advances in Computers,",
      "citeRegEx" : "24",
      "shortCiteRegEx" : "24",
      "year" : 1997
    }, {
      "title" : "Distributed and robust support vector machine",
      "author" : [ "Yangwei Liu", "Hu Ding", "Ziyun Huang", "Jinhui Xu" ],
      "venue" : "In LIPIcs-Leibniz International Proceedings in Informatics,",
      "citeRegEx" : "25",
      "shortCiteRegEx" : "25",
      "year" : 2016
    }, {
      "title" : "Distributed parallel support vector machines in strongly connected networks",
      "author" : [ "Yumao Lu", "Vwani Roychowdhury", "Lieven Vandenberghe" ],
      "venue" : "IEEE Transactions on Neural Networks,",
      "citeRegEx" : "26",
      "shortCiteRegEx" : "26",
      "year" : 2008
    }, {
      "title" : "Distributed support vector machines",
      "author" : [ "A Navia-Vazquez", "D Gutierrez-Gonzalez", "Emilio Parrado-Hernández", "JJ Navarro-Abellan" ],
      "venue" : "IEEE Trans. Neural Networks,",
      "citeRegEx" : "27",
      "shortCiteRegEx" : "27",
      "year" : 2006
    }, {
      "title" : "Average and randomized communication complexity",
      "author" : [ "Alon Orlitsky", "Abbas El Gamal" ],
      "venue" : "IEEE Transactions on Information Theory,",
      "citeRegEx" : "28",
      "shortCiteRegEx" : "28",
      "year" : 1990
    }, {
      "title" : "Solving large scale linear svm with distributed block minimization",
      "author" : [ "Dmitry Pechyony", "Libin Shen", "Rosie Jones" ],
      "venue" : "In NIPS workshop on Big Learning,",
      "citeRegEx" : "29",
      "shortCiteRegEx" : "29",
      "year" : 2011
    }, {
      "title" : "Scikit-learn: Machine learning in python",
      "author" : [ "Fabian Pedregosa", "Gaël Varoquaux", "Alexandre Gramfort", "Vincent Michel", "Bertrand Thirion", "Olivier Grisel", "Mathieu Blondel", "Peter Prettenhofer", "Ron Weiss", "Vincent Dubourg" ],
      "venue" : "Journal of Machine Learning Research,",
      "citeRegEx" : "30",
      "shortCiteRegEx" : "30",
      "year" : 2011
    }, {
      "title" : "12 fast training of support vector machines using sequential minimal optimization",
      "author" : [ "John C Platt" ],
      "venue" : "Advances in kernel methods,",
      "citeRegEx" : "31",
      "shortCiteRegEx" : "31",
      "year" : 1999
    }, {
      "title" : "Hogwild: A lock-free approach to parallelizing stochastic gradient descent",
      "author" : [ "Benjamin Recht", "Christopher Re", "Stephen Wright", "Feng Niu" ],
      "venue" : "In Advances in Neural Information Processing Systems,",
      "citeRegEx" : "32",
      "shortCiteRegEx" : "32",
      "year" : 2011
    }, {
      "title" : "New approximation algorithms for minimum enclosing convex shapes",
      "author" : [ "Ankan Saha", "SVN Vishwanathan", "Xinhua Zhang" ],
      "venue" : "In Proceedings of the twenty-second annual ACM-SIAM symposium on Discrete Algorithms,",
      "citeRegEx" : "33",
      "shortCiteRegEx" : "33",
      "year" : 2011
    }, {
      "title" : "New support vector algorithms",
      "author" : [ "Bernhard Schölkopf", "Alex J Smola", "Robert C Williamson", "Peter L Bartlett" ],
      "venue" : "Neural computation,",
      "citeRegEx" : "34",
      "shortCiteRegEx" : "34",
      "year" : 2000
    }, {
      "title" : "Pegasos: Primal estimated sub-gradient solver for svm",
      "author" : [ "Shai Shalev-Shwartz", "Yoram Singer", "Nathan Srebro" ],
      "venue" : "In Proceedings of the 24th international conference on Machine learning,",
      "citeRegEx" : "35",
      "shortCiteRegEx" : "35",
      "year" : 2007
    }, {
      "title" : "Bundle methods for machine learning",
      "author" : [ "Alexander J Smola", "SVN Vishwanathan", "Quoc V Le" ],
      "venue" : "In Advances in Neural Information Processing Systems,",
      "citeRegEx" : "36",
      "shortCiteRegEx" : "36",
      "year" : 2007
    }, {
      "title" : "Simpler core vector machines with enclosing balls",
      "author" : [ "Ivor W Tsang", "Andras Kocsor", "James T Kwok" ],
      "venue" : "In Proceedings of the 24th international conference on Machine learning,",
      "citeRegEx" : "37",
      "shortCiteRegEx" : "37",
      "year" : 2007
    }, {
      "title" : "Core vector machines: Fast svm training on very large data sets",
      "author" : [ "Ivor W Tsang", "James T Kwok", "Pak-Ming Cheung" ],
      "venue" : "Journal of Machine Learning Research,",
      "citeRegEx" : "38",
      "shortCiteRegEx" : "38",
      "year" : 2005
    }, {
      "title" : "Some complexity questions related to distributive computing (preliminary report)",
      "author" : [ "Andrew Chi-Chih Yao" ],
      "venue" : "In Proceedings of the eleventh annual ACM symposium on Theory of computing,",
      "citeRegEx" : "39",
      "shortCiteRegEx" : "39",
      "year" : 1979
    }, {
      "title" : "Efficient distributed linear classification algorithms via the alternating direction method of multipliers",
      "author" : [ "Caoxie Zhang", "Honglak Lee", "Kang G Shin" ],
      "venue" : "In Artificial Intelligence and Statistics,",
      "citeRegEx" : "40",
      "shortCiteRegEx" : "40",
      "year" : 2012
    }, {
      "title" : "Stochastic primal-dual coordinate method for regularized empirical risk minimization",
      "author" : [ "Yuchen Zhang", "Xiao Lin" ],
      "venue" : "In International Conference on Machine Learning (ICML),",
      "citeRegEx" : "41",
      "shortCiteRegEx" : "41",
      "year" : 2015
    } ],
    "referenceMentions" : [ {
      "referenceID" : 14,
      "context" : "To the best of our knowledge, the current best algorithm for hard margin SVM achieved by Gilbert algorithm [16] requires O(nd/ ) time.",
      "startOffset" : 107,
      "endOffset" : 111
    }, {
      "referenceID" : 19,
      "context" : "For ν-SVM, besides the well known quadratic programming approach which requires Ω(nd) time [21, 31], no better algorithm is known.",
      "startOffset" : 91,
      "endOffset" : 99
    }, {
      "referenceID" : 29,
      "context" : "For ν-SVM, besides the well known quadratic programming approach which requires Ω(nd) time [21, 31], no better algorithm is known.",
      "startOffset" : 91,
      "endOffset" : 99
    }, {
      "referenceID" : 6,
      "context" : "Support Vector Machine (SVM) is a fundamental model for classification and regression [7, 11], widely used in many areas such as nature language process, computer vision, and bioinformatics.",
      "startOffset" : 86,
      "endOffset" : 93
    }, {
      "referenceID" : 14,
      "context" : "Several SVM variants have been designed to handle linearly non-separable cases (see [16]).",
      "startOffset" : 84,
      "endOffset" : 88
    }, {
      "referenceID" : 32,
      "context" : "ν-SVM is first proposed by Schölkopf and Smola [34].",
      "startOffset" : 47,
      "endOffset" : 51
    }, {
      "referenceID" : 0,
      "context" : "The advantage of ν-SVM is that the parameter ν has a clearer meaning, which is always between [0, 1].",
      "startOffset" : 94,
      "endOffset" : 100
    }, {
      "referenceID" : 32,
      "context" : "[34] showed that ν is an upper bound on the fraction of margin errors and a lower bound on the fraction of support vectors.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 19,
      "context" : "It takesO(nd) time by solving quadratic programs directly [21, 31].",
      "startOffset" : 58,
      "endOffset" : 66
    }, {
      "referenceID" : 29,
      "context" : "It takesO(nd) time by solving quadratic programs directly [21, 31].",
      "startOffset" : 58,
      "endOffset" : 66
    }, {
      "referenceID" : 7,
      "context" : "QP-based algorithms are widely used in open source projects such as libsvm [8], scikit-learn [30] and so on.",
      "startOffset" : 75,
      "endOffset" : 78
    }, {
      "referenceID" : 28,
      "context" : "QP-based algorithms are widely used in open source projects such as libsvm [8], scikit-learn [30] and so on.",
      "startOffset" : 93,
      "endOffset" : 97
    }, {
      "referenceID" : 14,
      "context" : "For hard-margin SVM, based on the geometric linear separable property, Gartner and Jaggi [16] showed that Gilbert algorithm [17] achieves a (1− )-approximation with O(nd/ β) running time where β is the distance between the two polytopes of the two types of points after we scale all points in a unit ball.",
      "startOffset" : 89,
      "endOffset" : 93
    }, {
      "referenceID" : 15,
      "context" : "For hard-margin SVM, based on the geometric linear separable property, Gartner and Jaggi [16] showed that Gilbert algorithm [17] achieves a (1− )-approximation with O(nd/ β) running time where β is the distance between the two polytopes of the two types of points after we scale all points in a unit ball.",
      "startOffset" : 124,
      "endOffset" : 128
    }, {
      "referenceID" : 21,
      "context" : "For the l2-SVM and C-SVM, since we can transform the quadratic programs to a single-objective unconstrained optimization problem, there also exist efficient algorithms for the two variants [23, 35, 13, 13, 15, 2].",
      "startOffset" : 189,
      "endOffset" : 212
    }, {
      "referenceID" : 33,
      "context" : "For the l2-SVM and C-SVM, since we can transform the quadratic programs to a single-objective unconstrained optimization problem, there also exist efficient algorithms for the two variants [23, 35, 13, 13, 15, 2].",
      "startOffset" : 189,
      "endOffset" : 212
    }, {
      "referenceID" : 11,
      "context" : "For the l2-SVM and C-SVM, since we can transform the quadratic programs to a single-objective unconstrained optimization problem, there also exist efficient algorithms for the two variants [23, 35, 13, 13, 15, 2].",
      "startOffset" : 189,
      "endOffset" : 212
    }, {
      "referenceID" : 11,
      "context" : "For the l2-SVM and C-SVM, since we can transform the quadratic programs to a single-objective unconstrained optimization problem, there also exist efficient algorithms for the two variants [23, 35, 13, 13, 15, 2].",
      "startOffset" : 189,
      "endOffset" : 212
    }, {
      "referenceID" : 13,
      "context" : "For the l2-SVM and C-SVM, since we can transform the quadratic programs to a single-objective unconstrained optimization problem, there also exist efficient algorithms for the two variants [23, 35, 13, 13, 15, 2].",
      "startOffset" : 189,
      "endOffset" : 212
    }, {
      "referenceID" : 1,
      "context" : "For the l2-SVM and C-SVM, since we can transform the quadratic programs to a single-objective unconstrained optimization problem, there also exist efficient algorithms for the two variants [23, 35, 13, 13, 15, 2].",
      "startOffset" : 189,
      "endOffset" : 212
    }, {
      "referenceID" : 29,
      "context" : "Except the traditional quadratic programming approach such as Sequential Minimal Optimization(SMO) [31, 34], there is no better algorithm with the theoretical guarantee for ν-SVM.",
      "startOffset" : 99,
      "endOffset" : 107
    }, {
      "referenceID" : 32,
      "context" : "Except the traditional quadratic programming approach such as Sequential Minimal Optimization(SMO) [31, 34], there is no better algorithm with the theoretical guarantee for ν-SVM.",
      "startOffset" : 99,
      "endOffset" : 107
    }, {
      "referenceID" : 12,
      "context" : "A number of distributed algorithms for SVM in this setting have been obtained in the past [14, 29, 27, 26, 9, 18, 40].",
      "startOffset" : 90,
      "endOffset" : 117
    }, {
      "referenceID" : 27,
      "context" : "A number of distributed algorithms for SVM in this setting have been obtained in the past [14, 29, 27, 26, 9, 18, 40].",
      "startOffset" : 90,
      "endOffset" : 117
    }, {
      "referenceID" : 25,
      "context" : "A number of distributed algorithms for SVM in this setting have been obtained in the past [14, 29, 27, 26, 9, 18, 40].",
      "startOffset" : 90,
      "endOffset" : 117
    }, {
      "referenceID" : 24,
      "context" : "A number of distributed algorithms for SVM in this setting have been obtained in the past [14, 29, 27, 26, 9, 18, 40].",
      "startOffset" : 90,
      "endOffset" : 117
    }, {
      "referenceID" : 8,
      "context" : "A number of distributed algorithms for SVM in this setting have been obtained in the past [14, 29, 27, 26, 9, 18, 40].",
      "startOffset" : 90,
      "endOffset" : 117
    }, {
      "referenceID" : 16,
      "context" : "A number of distributed algorithms for SVM in this setting have been obtained in the past [14, 29, 27, 26, 9, 18, 40].",
      "startOffset" : 90,
      "endOffset" : 117
    }, {
      "referenceID" : 38,
      "context" : "A number of distributed algorithms for SVM in this setting have been obtained in the past [14, 29, 27, 26, 9, 18, 40].",
      "startOffset" : 90,
      "endOffset" : 117
    }, {
      "referenceID" : 37,
      "context" : "Typically, the communication complexity is one of the most important performance measurements for distributed algorithms, and has been studied extensively (see [39, 28] and the book [24] for more details).",
      "startOffset" : 160,
      "endOffset" : 168
    }, {
      "referenceID" : 26,
      "context" : "Typically, the communication complexity is one of the most important performance measurements for distributed algorithms, and has been studied extensively (see [39, 28] and the book [24] for more details).",
      "startOffset" : 160,
      "endOffset" : 168
    }, {
      "referenceID" : 22,
      "context" : "Typically, the communication complexity is one of the most important performance measurements for distributed algorithms, and has been studied extensively (see [39, 28] and the book [24] for more details).",
      "startOffset" : 182,
      "endOffset" : 186
    }, {
      "referenceID" : 23,
      "context" : "[25] proposed a distributed algorithm with O(kd/ ) communication cost, where k is the number of the clients.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 39,
      "context" : "Hard-Margin SVM: Inspired by the recent work of Zhang and Lin [41] and Allen-Zhu et al.",
      "startOffset" : 62,
      "endOffset" : 66
    }, {
      "referenceID" : 2,
      "context" : "[3], we propose a new perspective for solving hard-margin SVM via saddle point optimization.",
      "startOffset" : 0,
      "endOffset" : 3
    }, {
      "referenceID" : 14,
      "context" : "Compared to Gilbert algorithm [16], our algorithm improves the running time by a factor of √ d/ √ .",
      "startOffset" : 30,
      "endOffset" : 34
    }, {
      "referenceID" : 4,
      "context" : "It is known that ν-SVM is equivalent to computing the distance between two reduced polytopes [5, 12].",
      "startOffset" : 93,
      "endOffset" : 100
    }, {
      "referenceID" : 10,
      "context" : "It is known that ν-SVM is equivalent to computing the distance between two reduced polytopes [5, 12].",
      "startOffset" : 93,
      "endOffset" : 100
    }, {
      "referenceID" : 19,
      "context" : "Compared with the QP-based algorithms in previous work [21, 31], our algorithm significantly improves the running time, by a factor of n.",
      "startOffset" : 55,
      "endOffset" : 63
    }, {
      "referenceID" : 29,
      "context" : "Compared with the QP-based algorithms in previous work [21, 31], our algorithm significantly improves the running time, by a factor of n.",
      "startOffset" : 55,
      "endOffset" : 63
    }, {
      "referenceID" : 28,
      "context" : "The experimental result shows that our algorithm is much faster than the previous QP based algorithm NuSVC, implemented in scikit-learn [30].",
      "startOffset" : 136,
      "endOffset" : 140
    }, {
      "referenceID" : 23,
      "context" : "[25] proposed a distributed algorithm withO(kd/ ) communication cost where k is the number of the clients.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 23,
      "context" : "Moreover, this communication cost is almost optimal according to the lower bound provided in [25].",
      "startOffset" : 93,
      "endOffset" : 97
    }, {
      "referenceID" : 30,
      "context" : "In Section 4, we provide the experimental results, including our algorithm of ν-SVM versus the QP based algorithm NuSVC and our distributed algorithms for SVM versus traditional distributed algorithm HOGWILD! [32] and Gilbert Algorithm [16].",
      "startOffset" : 209,
      "endOffset" : 213
    }, {
      "referenceID" : 14,
      "context" : "In Section 4, we provide the experimental results, including our algorithm of ν-SVM versus the QP based algorithm NuSVC and our distributed algorithms for SVM versus traditional distributed algorithm HOGWILD! [32] and Gilbert Algorithm [16].",
      "startOffset" : 236,
      "endOffset" : 240
    }, {
      "referenceID" : 21,
      "context" : "Basically, there are three main strategies: the primal gradient-based methods [23, 35, 13, 15, 2], dual quadratic programming methods [22, 36, 20] and dual geometry methods [38, 37].",
      "startOffset" : 78,
      "endOffset" : 97
    }, {
      "referenceID" : 33,
      "context" : "Basically, there are three main strategies: the primal gradient-based methods [23, 35, 13, 15, 2], dual quadratic programming methods [22, 36, 20] and dual geometry methods [38, 37].",
      "startOffset" : 78,
      "endOffset" : 97
    }, {
      "referenceID" : 11,
      "context" : "Basically, there are three main strategies: the primal gradient-based methods [23, 35, 13, 15, 2], dual quadratic programming methods [22, 36, 20] and dual geometry methods [38, 37].",
      "startOffset" : 78,
      "endOffset" : 97
    }, {
      "referenceID" : 13,
      "context" : "Basically, there are three main strategies: the primal gradient-based methods [23, 35, 13, 15, 2], dual quadratic programming methods [22, 36, 20] and dual geometry methods [38, 37].",
      "startOffset" : 78,
      "endOffset" : 97
    }, {
      "referenceID" : 1,
      "context" : "Basically, there are three main strategies: the primal gradient-based methods [23, 35, 13, 15, 2], dual quadratic programming methods [22, 36, 20] and dual geometry methods [38, 37].",
      "startOffset" : 78,
      "endOffset" : 97
    }, {
      "referenceID" : 20,
      "context" : "Basically, there are three main strategies: the primal gradient-based methods [23, 35, 13, 15, 2], dual quadratic programming methods [22, 36, 20] and dual geometry methods [38, 37].",
      "startOffset" : 134,
      "endOffset" : 146
    }, {
      "referenceID" : 34,
      "context" : "Basically, there are three main strategies: the primal gradient-based methods [23, 35, 13, 15, 2], dual quadratic programming methods [22, 36, 20] and dual geometry methods [38, 37].",
      "startOffset" : 134,
      "endOffset" : 146
    }, {
      "referenceID" : 18,
      "context" : "Basically, there are three main strategies: the primal gradient-based methods [23, 35, 13, 15, 2], dual quadratic programming methods [22, 36, 20] and dual geometry methods [38, 37].",
      "startOffset" : 134,
      "endOffset" : 146
    }, {
      "referenceID" : 36,
      "context" : "Basically, there are three main strategies: the primal gradient-based methods [23, 35, 13, 15, 2], dual quadratic programming methods [22, 36, 20] and dual geometry methods [38, 37].",
      "startOffset" : 173,
      "endOffset" : 181
    }, {
      "referenceID" : 35,
      "context" : "Basically, there are three main strategies: the primal gradient-based methods [23, 35, 13, 15, 2], dual quadratic programming methods [22, 36, 20] and dual geometry methods [38, 37].",
      "startOffset" : 173,
      "endOffset" : 181
    }, {
      "referenceID" : 1,
      "context" : "Recently, Allen-Zhu [2] provided the current best algorithms which achieve O(nd/ √ ) time for l2-SVM and O(nd/ ) time for C-SVM.",
      "startOffset" : 20,
      "endOffset" : 23
    }, {
      "referenceID" : 2,
      "context" : "[3] used the saddle point optimization and obtained an Õ(nd + n √ d/ √ ) algorithm for the minimum enclosing ball problem (MinEB) in Euclidean space.",
      "startOffset" : 0,
      "endOffset" : 3
    }, {
      "referenceID" : 36,
      "context" : "This result also implies algorithms for l2-SVM directly by the connection of MinEB and l2-SVM (see [38, 19, 16, 10, 33, 37]).",
      "startOffset" : 99,
      "endOffset" : 123
    }, {
      "referenceID" : 17,
      "context" : "This result also implies algorithms for l2-SVM directly by the connection of MinEB and l2-SVM (see [38, 19, 16, 10, 33, 37]).",
      "startOffset" : 99,
      "endOffset" : 123
    }, {
      "referenceID" : 14,
      "context" : "This result also implies algorithms for l2-SVM directly by the connection of MinEB and l2-SVM (see [38, 19, 16, 10, 33, 37]).",
      "startOffset" : 99,
      "endOffset" : 123
    }, {
      "referenceID" : 9,
      "context" : "This result also implies algorithms for l2-SVM directly by the connection of MinEB and l2-SVM (see [38, 19, 16, 10, 33, 37]).",
      "startOffset" : 99,
      "endOffset" : 123
    }, {
      "referenceID" : 31,
      "context" : "This result also implies algorithms for l2-SVM directly by the connection of MinEB and l2-SVM (see [38, 19, 16, 10, 33, 37]).",
      "startOffset" : 99,
      "endOffset" : 123
    }, {
      "referenceID" : 35,
      "context" : "This result also implies algorithms for l2-SVM directly by the connection of MinEB and l2-SVM (see [38, 19, 16, 10, 33, 37]).",
      "startOffset" : 99,
      "endOffset" : 123
    }, {
      "referenceID" : 36,
      "context" : "[38, 37], the dual of l2-SVM is equivalent to a MinEB by a specific feature mapping.",
      "startOffset" : 0,
      "endOffset" : 8
    }, {
      "referenceID" : 35,
      "context" : "[38, 37], the dual of l2-SVM is equivalent to a MinEB by a specific feature mapping.",
      "startOffset" : 0,
      "endOffset" : 8
    }, {
      "referenceID" : 4,
      "context" : "The dual problem of (1) is equivalent to the problem of finding the two closest points between the convex hulls of two types of points [5].",
      "startOffset" : 135,
      "endOffset" : 138
    }, {
      "referenceID" : 2,
      "context" : "This is a commonly used approach in optimization (see [3] for example).",
      "startOffset" : 54,
      "endOffset" : 57
    }, {
      "referenceID" : 10,
      "context" : "Next, we discuss ν-SVM (see [12, 34]) and again provide an equivalent saddle point optimization formulation.",
      "startOffset" : 28,
      "endOffset" : 36
    }, {
      "referenceID" : 32,
      "context" : "Next, we discuss ν-SVM (see [12, 34]) and again provide an equivalent saddle point optimization formulation.",
      "startOffset" : 28,
      "endOffset" : 36
    }, {
      "referenceID" : 10,
      "context" : "Crisp and Burges [12] present a geometry interpretation for ν-SVM.",
      "startOffset" : 17,
      "endOffset" : 21
    }, {
      "referenceID" : 2,
      "context" : "[3].",
      "startOffset" : 0,
      "endOffset" : 3
    }, {
      "referenceID" : 2,
      "context" : "We first apply a randomized Hadamard space rotation as in [3].",
      "startOffset" : 58,
      "endOffset" : 61
    }, {
      "referenceID" : 0,
      "context" : "It is well known [1] that with high probability, for any point xi we have ∀j ∈ [d], |(HDxi)j | ≤ O( √ log n/d).",
      "startOffset" : 17,
      "endOffset" : 20
    }, {
      "referenceID" : 5,
      "context" : "The update rules use some useful technique for speeding up the convergence, such as the proximal gradient method and momentum (see the book [6]).",
      "startOffset" : 140,
      "endOffset" : 143
    }, {
      "referenceID" : 3,
      "context" : "The above update rules of η and ξ can be also considered as the multiplicative weight update method (see [4]).",
      "startOffset" : 105,
      "endOffset" : 108
    }, {
      "referenceID" : 28,
      "context" : "In this section, we first compare our SVMSPSolver with library NuSVC in scikitlearn [30].",
      "startOffset" : 84,
      "endOffset" : 88
    }, {
      "referenceID" : 30,
      "context" : "Second, in the distributed setting, we compare DisSVMSPSolver with two distributed algorithms for SVM, HOGWILD! [32] and distributed Gilbert algorithm [25].",
      "startOffset" : 112,
      "endOffset" : 116
    }, {
      "referenceID" : 23,
      "context" : "Second, in the distributed setting, we compare DisSVMSPSolver with two distributed algorithms for SVM, HOGWILD! [32] and distributed Gilbert algorithm [25].",
      "startOffset" : 151,
      "endOffset" : 155
    }, {
      "referenceID" : 7,
      "context" : "The real data is from [8].",
      "startOffset" : 22,
      "endOffset" : 25
    }, {
      "referenceID" : 28,
      "context" : "The experimental results for ν-Saddle: We compare our SVMSPSolver with NuSVC in scikit-learn [30] and summarize the results in Table 1.",
      "startOffset" : 93,
      "endOffset" : 97
    }, {
      "referenceID" : 30,
      "context" : "Distributed experiments: In the distributed setting, we compare our algorithms with HOGWILD! [32] and distributed Gilbert algorithm [25].",
      "startOffset" : 93,
      "endOffset" : 97
    }, {
      "referenceID" : 23,
      "context" : "Distributed experiments: In the distributed setting, we compare our algorithms with HOGWILD! [32] and distributed Gilbert algorithm [25].",
      "startOffset" : 132,
      "endOffset" : 136
    }, {
      "referenceID" : 7,
      "context" : "We also select the real world datasets “phishing” and “a9a” from [8].",
      "startOffset" : 65,
      "endOffset" : 68
    } ],
    "year" : 2017,
    "abstractText" : "Support Vector Machine is one of the most classical approaches for classification and regression. Despite being studied for decades, obtaining practical algorithms for SVM is still an active research problem in machine learning. In this paper, we propose a new perspective for SVM via saddle point optimization. We provide an algorithm which achieves (1 − )-approximations with running time Õ(nd + n √ d/ ) for both separable (hard margin SVM) and non-separable cases (ν-SVM ), where n is the number of points and d is the dimensionality. To the best of our knowledge, the current best algorithm for hard margin SVM achieved by Gilbert algorithm [16] requires O(nd/ ) time. Our algorithm improves the running time by a factor of √ d/ √ . For ν-SVM, besides the well known quadratic programming approach which requires Ω(nd) time [21, 31], no better algorithm is known. In the paper, we provide the first nearly linear time algorithm for ν-SVM. We also consider the distributed settings and provide distributed algorithms with low communication cost via saddle point optimization. Our algorithms require Õ(k(d+ √ d/ )) communication cost where k is the number of clients, almost matching the theoretical lower bound.",
    "creator" : "LaTeX with hyperref package"
  }
}