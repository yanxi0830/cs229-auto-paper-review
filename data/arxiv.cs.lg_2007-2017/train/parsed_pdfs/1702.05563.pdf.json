{
  "name" : "1702.05563.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "On the Equivalence of Holographic and Complex Embeddings for Link Prediction",
    "authors" : [ "Katsuhiko Hayashi", "Masashi Shimbo" ],
    "emails" : [ "hayashi.katsuhiko@lab.ntt.co.jp", "shimbo@is.naist.jp" ],
    "sections" : [ {
      "heading" : null,
      "text" : "We show the equivalence of two state-of-the-art link prediction/knowledge graph completion methods: Nickel et al’s holographic embedding and Trouillon et al.’s complex embedding. We first consider a spectral version of the holographic embedding, exploiting the frequency domain in the Fourier transform for efficient computation. The analysis of the resulting method reveals that it can be viewed as an instance of the complex embedding with certain constraints cast on the initial vectors upon training. Conversely, any complex embedding can be converted to an equivalent holographic embedding."
    }, {
      "heading" : "1 Introduction",
      "text" : "Knowledge graph completion concerns augmenting missing knowledge in an incomplete knowledge base. It can be viewed as a task of link prediction, and various approaches based on vector embedding have been proposed in recent years (Bordes et al., 2011; Socher et al., 2013; Guu et al., 2015; Yang et al., 2015; Nickel et al., 2016; Trouillon et al., 2016b). Holographic embedding (Nickel et al., 2016) is one of the state-of-the-art methods along this line of research.\nIn this paper, we first show that holographic embedding can be trained entirely in the frequency domain induced by the Fourier transform, thereby reducing the computation time of the scoring function from O(n logn) to O(n). The analysis of the resulting method reveals that holographic embedding and Trouillon et al. (2016b)’s complex embedding, which is another state-of-the-art method for knowledge graph completion, differ only in terms of the constraints on the initial values and how a real-valued score is obtained from complex-valued dot product.\nWe also show that every complex embedding has an equivalent holographic embedding (with real vectors) in the sense that their scoring functions are equal up to scaling.\nar X\niv :1\n70 2.\n05 56\n3v 1\n[ cs\n.L G\n] 1\n8 Fe\nb 20"
    }, {
      "heading" : "2 Preliminaries",
      "text" : "Let i denote the imaginary unit, R be the set of real values, and C the set of complex values. For a vector v, [v] j represents the j th component of v. For a complex scalar z, vector z, and matrix Z, zT and ZT respectively denote the transpose of z and Z, and z, z, and Z their complex conjugate.\nLet x = [x0 · · · xn−1]T ∈ Rn , y = [y0 · · · yn−1]T ∈ Rn . Note that the vector indices start from 0 for notational convenience. The circular convolution of x and y, denoted by x∗y, is defined by\n[x∗y] j = n−1∑\nk=0 x[( j−k) mod n] yk . (1)\nLikewise, circular correlation x?y is defined by\n[x?y] j = n−1∑\nk=0 x[(k− j ) mod n] yk . (2)\nWhile circular convolution is commutative, circular correlation is not; i.e., x∗ y = y∗ x, but x? y 6= y? x in general. As it can be verified with Eqs. (1) and (2), x? y = flip(x)∗ y, where flip(x) = [xn−1 · · · x0]T is a vector obtained by arranging the components of x in reverse.\nFor n-dimensional vectors, naively computing circular convolution/correlation by Eqs. (1) and (2) requires O(n2) multiplications. However, we can take advantage of the discrete Fourier transform (DFT) to accelerate the computation: For circular convolution, first compute the DFTs of x and y, and then compute the inverse DFT of their elementwise vector product, i.e.,\nx∗y =F−1(F(x)¯F(y)),\nwhere F : Rn → Cn and F−1 : Cn → Rn respectively denote the DFT and inverse DFT, and ¯ denotes the elementwise product. Since DFT and inverse DFT can be computed in O(n logn) time with the Fast Fourier Transform algorithm, the computation time for circular convolution is also O(n logn). The same can be said of circular correlation. Since F(flip(x)) =F(x), we have\nx?y =F−1(F(x)¯F(y)). (3)\nIn analogy to signal processing application of the Fourier transform, the original real space Rn is customarily called the “time” domain, and the complex space Cn where DFT vectors reside is called the “frequency” domain."
    }, {
      "heading" : "3 Holographic embedding for knowledge graph completion",
      "text" : ""
    }, {
      "heading" : "3.1 Knowledge graph completion",
      "text" : "Let E and R be finite sets of entities and (binary) relations over entities, respectively. For each relation r ∈ R and each pair s,o ∈ E of entities, we are interested in whether r (s,o)\nholds1; we write r (s,o) =+1 if it holds, and r (s,o) =−1 if not. To be precise, given a training set D =R×E ×E × {−1,+1} such that (r, s,o, y) ∈D indicates y = r (s,o), we are to design a function f : R×E×E →R such that f (r, s,o) gives an estimated score of r (s,o) =+1 for triples (r, s,o) not observed inD; function f should give a higher value for triples (r, s,o) if r (s,o) =+1 is more likely, and a smaller value for those that are less likely. If necessary, f (r, s,o) can be converted to probability by P[r (s,o) = +1] = σ( f (r, s,o)), where σ : R → (0,1) is a sigmoid function.\nDataset D can be regarded as a directed graph with nodes representing entities E and edges labeled by relations R. Thus, the task is basically that of link prediction (Liben-Nowell and Kleinberg, 2003). Often, it is also called knowledge graph completion."
    }, {
      "heading" : "3.2 Holographic embedding (HolE)",
      "text" : "Nickel et al. (2016) proposed holographic embedding (HolE) for knowledge graph completion. Using training data D, this method learns the vector embeddings ek ∈Rn of entities k ∈ E and the embeddings wr ∈Rn of relations r ∈R. The score for triple (r, s,o) is then given by\nfHolE(r, s,o) = wr · (es ?eo). (4)\nEq. (4) can be evaluated in time O(n logn) if es ?eo is computed by Eq. (3)."
    }, {
      "heading" : "4 Spectral training of HolE",
      "text" : "Nickel et al. (2016) used DFT and the resulting “frequency” vectors to compute circular correlation efficiently. In this section, we extend this technique further, and consider training HolE solely in the frequency domain. That is, real-valued embeddings ek ,wr ∈ Rn in the original “time” domain are abolished, and instead we train their DFT counterparts εk = F(ek ) ∈ Cn and ωk = F(wr ) ∈ Cn in the frequency domain. This formulation eliminates the need of DFT/inverse DFT, which is the major computational bottleneck in HolE. In particular, the scoring function of Eq. (4) can be computed in O(n) time directly from εk and ωk .\n1 Depending on the context, letter r is used either as an index to an element in R or the binary relation it signifies.\nIndeed, equivalent counterparts in the frequency domain exist for not only convolution/ correlation but all other computations needed for HolE: scalar multiplication, summation (needed when vectors are updated with stochastic gradient descent), and dot product (used in Eq. (4)). The frequency-domain equivalents for these operations are summarized in Table 1. All of these can be performed efficiently (in linear time) in the frequency domain.\nConcerning dot product, the following relation holds for x,y ∈Rn :\nx ·y = 1 n F(x) ·F(y). (5)\nThis relation is known as Parseval’s theorem (also called the power theorem (Smith, 2007)), and it states that dot products in two domains are equal up to scaling.\nAfter embeddings εk ,ωr ∈ Cn are learned in the frequency domain, their time-domain counterparts ek = F−1(εk ) and wr = F−1(ωr ) can be recovered if needed, but this is not required as far as computation of the scoring function is concerned. Using Parseval’s theorem, Eq. (4) can be directly computed from the frequency vectors εk ,ωr ∈Cn by\nfHolE(r, s,o) = 1\nn ωr · (εs ¯εo). (6)"
    }, {
      "heading" : "4.1 Conjugate symmetry of spectral components",
      "text" : "A complex vector ξ = [ξ0 · · · ξn−1]T ∈ Cn is said to be conjugate symmetric (or Hermitian) if ξ j = ξ[(n− j ) mod n] for j = 0, . . . ,n −1, or, in other words, if it can be written in the form\nξ=    [ ξ0 γ flip(γ) ]T , if n is odd,\n[ ξ0 γ ξn/2 flip(γ) ]T , if n is even,\nfor some γ ∈Cdn/2e−1, with ξ0,ξn/2 ∈R. The DFT F(x) is conjugate symmetric if and only if x is a real vector. Thus, maintaining conjugate symmetry of “frequency” vectors is the key to ensure their “time” counterparts remain in real space. Below, we verify that this property is indeed preserved with stochastic gradient descent. It also provides a sufficient condition under which dot product takes a real value, and is also relevant to the discussion of space requirement."
    }, {
      "heading" : "4.2 Initialization and value update in frequency domain",
      "text" : "Typically, at the beginning of training HolE, each individual embedding is initialized by a random vector. When we train HolE in the frequency domain, we could first generate a random real vector, regard them as a HolE vector in the time domain, and compute its DFT as the initial value in the frequency domain. An alternative, easier approach is to directly generate a random complex vector that is conjugate symmetric, and used it as the initial frequency vector. This guarantees the inverse DFT to be a real vector, i.e., there exists a valid corresponding image in the time domain.\nDuring the stochastic gradient descent (SGD) training, vectors ωr ,εs ,εo are updated respectively by α∇ωr f ,α∇εs f ,α∇εo f , where α ∈ R is a factor not depending on these parameters, and\n∇ωr f = εs ¯εo , ∇εs f =ωr ¯εo , ∇εo f =ωr ¯εs .\nAs seen from above, conjugation, scalar multiplication, summation, and elementwise product are used in the SGD update. And it is easy to verify that all these operations preserve conjugate symmetry. It follows that if ωr ,εs ,εo are initially conjugate symmetric, they will remain so during the course of training, assuring the inverse DFT of the learned embeddings to be real vectors."
    }, {
      "heading" : "4.3 Real-valued dot product",
      "text" : "In the scoring function of HolE (Eq. (4)), dot product is used for generating a real-valued “score” out of two vectors, wr and es ¯eo . Likewise, in Eq. (6), the dot product is applied to ωr and εs ¯εo which are complex-valued. However, provided that the conjugate symmetry of these vectors are maintained, their dot product is always real. This follows from Parseval’s theorem; the inverse DFTs of these frequency vectors are real, and thus their dot product is also real. Therefore, the dot product of the corresponding frequency vectors must be real, too, according to Eq. (5)."
    }, {
      "heading" : "4.4 Space requirement",
      "text" : "A general complex vector ξ ∈Cn can be stored in memory as 2n floating-point numbers, i.e., one each for the real and imaginary part of a component. In our spectral representation of HolE, however, keeping only the first bn/2c components suffices to specify the frequency vector ξ, since the vector is conjugate symmetric. Moreover, ξ0 (and ξn/2 if n is even) are real values. Thus, to specify a spectral representation of HolE, we need exactly n floating-point numbers, which can be stored in the same amount of memory as needed by the original HolE."
    }, {
      "heading" : "5 Relation to Trouillon et al.’s complex embedding",
      "text" : ""
    }, {
      "heading" : "5.1 Complex embedding (CompE)",
      "text" : "Trouillon et al. (2016b) proposed a method for embedding-based knowledge graph completion, called complex embedding (CompE). The objective is the same as Nickel et al.’s; the embedding ek of entities and wr of relations are to be learned. In their model, however, these vectors are complex-valued, and is based on eigendecomposition of complex matrices Xr = EWr ET that encodes r ∈R among entities, where Xr ∈C|E |×|E |, E = [e1, . . . ,e|E |]T ∈C|E |×n , and Wr = diag(wr ) ∈Cn×n is a diagonal matrix (with diagonal elements wr ∈Cn). In practice,\nwe need Xr to be a real matrix, as its (r, s)-component defines the score for (r, s,o). To this end, they simply extracts the real part; i.e., Xr = Re(EWr ET), where Re(Z) denotes the real part of complex-valued matrix Z. Trouillon et al. (2016a) showed that any real matrix Xr can be expressed in this form.\nWith this formulation, the score for triple (r, s,o) is given by\nfCompE(r, s,o) = Re ( n−1∑\nj=0 [wr ] j [es] j [eo] j\n) . (7)"
    }, {
      "heading" : "5.2 Equivalence of holographic and complex embeddings",
      "text" : "Noting Re(z) = Re(z) and the definition of complex (Hermitian) dot product, i.e., a ·b = aTb, we can rewrite Eq. (7) as\nfCompE(r, s,o) = Re ( wr · (es ¯eo) ) . (8)\nwhere conjugation is now placed over es and not eo . In Eq. (8), we immediately observe a striking similarity to Eq. (6), the scoring function for HolE. The complex embedding extracts the real part of complex dot product, whereas in our spectral version of HolE (spectral HolE), dot product is guaranteed to be real because all embeddings satisfy conjugate symmetry. Indeed, Eq. (6) can be equally written as\nfHolE(r, s,o) = 1\nn Re\n( ωr · (εs ¯εo) ) ,\nThe Re(·) is redundant as the value is guaranteed to be real-valued, but this equation further elucidates the similarity between Eq. (6) and Eq. (8).\nAs argued in Section 4, the original HolE has an equivalent complex-valued embedding in spectral HolE, in the sense that their scoring functions always return the same score given the same triple. And as shown above, spectral HolE can be regarded as a special case of complex embedding trained with a specific form of initial vectors, i.e., conjugate symmetric vectors. It follows that a model that can be computed by HolE, either original or spectral, can also be computed by the complex embedding.\nConversely, given a complex embedding, we can construct an equivalent HolE, in the sense that fCompE(r, s,o) = c fHolE(r, s,o) for every r, s,o, where c > 0 is a constant. For each n-dimensional complex embeddings x ∈ {ek }k∈E ∪ {wr }r∈R ⊂ Cn computed by a CompE, we make a corresponding HolE h(x) ∈ R2n+1 as follows: For a given complex embedding x = [x0 · · ·xn−1] ∈Cn , first compute s(x) ∈C2n+1 by\ns(x) = [0 x0 · · · xn−1 xn−1 · · · x0 ]T\n= [0 x flip(x)]T (9)\nand then define h(x) =F−1(s(x)). Since s(x) is conjugate symmetric, h(x) is a real vector. This allows us to regard h(wr ),h(es),h(eo) ∈ R2n+1 as holographic embeddings of r , s and o, and compute the score:\nfHolE(r, s,o) = h(wr ) · (h(es)?h(eo))\n= 1 n s(wr ) · (s(es)¯s(eo)) (∵ Eq. (6)) = 1 n s(wr ) · [ 0 es ¯eo flip(es ¯eo) ]T (∵ Eq. (9)) = 1 n [ 0 wr flip(wr ) ]T · [ 0 es ¯eo flip(es ¯eo) ]T = 1 n ( wr · (es ¯eo)+flip(wr ) ·flip(es ¯eo) ) = 1 n ( wr · (es ¯eo)+wr · (es ¯eo) ) = 1 n ( wr · (es ¯eo)+wr · (es ¯eo) ) = 2 n Re ( wr · (es ¯eo) ) = 2 n fCompE(r, s,o),\nwhich shows that h(·) (or s(·)) gives the desired conversion from CompE to HolE."
    }, {
      "heading" : "6 Conclusion",
      "text" : "We have shown that the holographic embedding (HolE) can be computed entirely in the frequency domain, thereby reducing the computation time of the scoring function from O(n logn) to O(n). In particular, we showed that the conjugate symmetry of frequency vectors is preserved by stochastic gradient descent, which ensures the existence of the corresponding holographic embedding in the original space (time domain) is guaranteed.\nAlso, we have established the equivalence of HolE and the complex embedding: The spectral version of HolE is subsumed by the complex embedding as a special case in which the conjugate symmetry is imposed on embeddings. Conversely, every complex embedding has an equivalent HolE."
    } ],
    "references" : [ {
      "title" : "Learning structured embeddings of knowledge bases",
      "author" : [ "Antoine Bordes", "Jason Weston", "Ronan Collobert", "Yoshua Bengio" ],
      "venue" : "In Proceedings of the 25th AAAI Conference on Artificial Intelligence (AAAI",
      "citeRegEx" : "Bordes et al\\.,? \\Q2011\\E",
      "shortCiteRegEx" : "Bordes et al\\.",
      "year" : 2011
    }, {
      "title" : "Traversing knowledge graphs in vector space",
      "author" : [ "Kelvin Guu", "John Miller", "Percy Liang" ],
      "venue" : "In Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing (EMNLP",
      "citeRegEx" : "Guu et al\\.,? \\Q2015\\E",
      "shortCiteRegEx" : "Guu et al\\.",
      "year" : 2015
    }, {
      "title" : "The link prediction problem for social networks",
      "author" : [ "David Liben-Nowell", "Jon Kleinberg" ],
      "venue" : "In Proceedings of the 12nd Annual ACM International Conference on Information and Knowledge Management (CIKM",
      "citeRegEx" : "Liben.Nowell and Kleinberg.,? \\Q2003\\E",
      "shortCiteRegEx" : "Liben.Nowell and Kleinberg.",
      "year" : 2003
    }, {
      "title" : "Holographic embeddings of knowledge graphs",
      "author" : [ "Maximilian Nickel", "Lorenzo Rosasco", "Tomaso Poggio" ],
      "venue" : "In Proceedings of the 30th AAAI Conference on Artificial Intelligence (AAAI ’16),",
      "citeRegEx" : "Nickel et al\\.,? \\Q2016\\E",
      "shortCiteRegEx" : "Nickel et al\\.",
      "year" : 2016
    }, {
      "title" : "Mathematics of the Discrete Fourier Transform (DFT): with Audio Applications",
      "author" : [ "Julius O. III Smith" ],
      "venue" : "W3K Publishing,",
      "citeRegEx" : "Smith.,? \\Q2007\\E",
      "shortCiteRegEx" : "Smith.",
      "year" : 2007
    }, {
      "title" : "Reasoning with neural tensor networks for knowledge base completion",
      "author" : [ "R. Socher", "D. Chen", "C.D. Manning", "A.Y. Ng" ],
      "venue" : "In Advances in Neural Information Processing Systems",
      "citeRegEx" : "Socher et al\\.,? \\Q2013\\E",
      "shortCiteRegEx" : "Socher et al\\.",
      "year" : 2013
    }, {
      "title" : "Decomposing real square matrices via unitary diagonalization",
      "author" : [ "Théo Trouillon", "Christopher R. Dance", "Éric Gaussier", "Guillaume Bouchard" ],
      "venue" : "arXiv.math eprint 1605.07103,",
      "citeRegEx" : "Trouillon et al\\.,? \\Q2016\\E",
      "shortCiteRegEx" : "Trouillon et al\\.",
      "year" : 2016
    }, {
      "title" : "Complex embeddings for simple link prediction",
      "author" : [ "Théo Trouillon", "Johannes Welbl", "Sebastian Riedel", "Éric Gaussier", "Guillaume Bouchard" ],
      "venue" : "In Proceedings of the 33rd International Conference on Machine Learning (ICML",
      "citeRegEx" : "Trouillon et al\\.,? \\Q2016\\E",
      "shortCiteRegEx" : "Trouillon et al\\.",
      "year" : 2016
    }, {
      "title" : "Embedding entities and relations for learning and inference in knowledge bases",
      "author" : [ "B. Yang", "W. Yih", "X. He", "J. Gao", "L. Deng" ],
      "venue" : "In Proceedings of the 3rd International Conference on Learning Representations (ICLR ’15),",
      "citeRegEx" : "Yang et al\\.,? \\Q2015\\E",
      "shortCiteRegEx" : "Yang et al\\.",
      "year" : 2015
    } ],
    "referenceMentions" : [ {
      "referenceID" : 0,
      "context" : "It can be viewed as a task of link prediction, and various approaches based on vector embedding have been proposed in recent years (Bordes et al., 2011; Socher et al., 2013; Guu et al., 2015; Yang et al., 2015; Nickel et al., 2016; Trouillon et al., 2016b).",
      "startOffset" : 131,
      "endOffset" : 256
    }, {
      "referenceID" : 5,
      "context" : "It can be viewed as a task of link prediction, and various approaches based on vector embedding have been proposed in recent years (Bordes et al., 2011; Socher et al., 2013; Guu et al., 2015; Yang et al., 2015; Nickel et al., 2016; Trouillon et al., 2016b).",
      "startOffset" : 131,
      "endOffset" : 256
    }, {
      "referenceID" : 1,
      "context" : "It can be viewed as a task of link prediction, and various approaches based on vector embedding have been proposed in recent years (Bordes et al., 2011; Socher et al., 2013; Guu et al., 2015; Yang et al., 2015; Nickel et al., 2016; Trouillon et al., 2016b).",
      "startOffset" : 131,
      "endOffset" : 256
    }, {
      "referenceID" : 8,
      "context" : "It can be viewed as a task of link prediction, and various approaches based on vector embedding have been proposed in recent years (Bordes et al., 2011; Socher et al., 2013; Guu et al., 2015; Yang et al., 2015; Nickel et al., 2016; Trouillon et al., 2016b).",
      "startOffset" : 131,
      "endOffset" : 256
    }, {
      "referenceID" : 3,
      "context" : "It can be viewed as a task of link prediction, and various approaches based on vector embedding have been proposed in recent years (Bordes et al., 2011; Socher et al., 2013; Guu et al., 2015; Yang et al., 2015; Nickel et al., 2016; Trouillon et al., 2016b).",
      "startOffset" : 131,
      "endOffset" : 256
    }, {
      "referenceID" : 3,
      "context" : "Holographic embedding (Nickel et al., 2016) is one of the state-of-the-art methods along this line of research.",
      "startOffset" : 22,
      "endOffset" : 43
    }, {
      "referenceID" : 0,
      "context" : "It can be viewed as a task of link prediction, and various approaches based on vector embedding have been proposed in recent years (Bordes et al., 2011; Socher et al., 2013; Guu et al., 2015; Yang et al., 2015; Nickel et al., 2016; Trouillon et al., 2016b). Holographic embedding (Nickel et al., 2016) is one of the state-of-the-art methods along this line of research. In this paper, we first show that holographic embedding can be trained entirely in the frequency domain induced by the Fourier transform, thereby reducing the computation time of the scoring function from O(n logn) to O(n). The analysis of the resulting method reveals that holographic embedding and Trouillon et al. (2016b)’s complex embedding, which is another state-of-the-art method for knowledge graph completion, differ only in terms of the constraints on the initial values and how a real-valued score is obtained from complex-valued dot product.",
      "startOffset" : 132,
      "endOffset" : 695
    }, {
      "referenceID" : 2,
      "context" : "Thus, the task is basically that of link prediction (Liben-Nowell and Kleinberg, 2003).",
      "startOffset" : 52,
      "endOffset" : 86
    }, {
      "referenceID" : 3,
      "context" : "2 Holographic embedding (HolE) Nickel et al. (2016) proposed holographic embedding (HolE) for knowledge graph completion.",
      "startOffset" : 31,
      "endOffset" : 52
    }, {
      "referenceID" : 4,
      "context" : "This relation is known as Parseval’s theorem (also called the power theorem (Smith, 2007)), and it states that dot products in two domains are equal up to scaling.",
      "startOffset" : 76,
      "endOffset" : 89
    }, {
      "referenceID" : 6,
      "context" : "Trouillon et al. (2016a) showed that any real matrix Xr can be expressed in this form.",
      "startOffset" : 0,
      "endOffset" : 25
    } ],
    "year" : 2017,
    "abstractText" : "We show the equivalence of two state-of-the-art link prediction/knowledge graph completion methods: Nickel et al’s holographic embedding and Trouillon et al.’s complex embedding. We first consider a spectral version of the holographic embedding, exploiting the frequency domain in the Fourier transform for efficient computation. The analysis of the resulting method reveals that it can be viewed as an instance of the complex embedding with certain constraints cast on the initial vectors upon training. Conversely, any complex embedding can be converted to an equivalent holographic embedding.",
    "creator" : "LaTeX with hyperref package"
  }
}