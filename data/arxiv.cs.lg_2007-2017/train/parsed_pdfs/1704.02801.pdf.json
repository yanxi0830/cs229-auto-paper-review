{
  "name" : "1704.02801.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "Bayesian Inference of Individualized Treatment Effects using Multi-task Gaussian Processes",
    "authors" : [ "Ahmed M. Alaa", "Mihaela van der Schaar" ],
    "emails" : [ "ahmedmalaa@ucla.edu", "mihaela.vanderschaar@eng.ox.ac.uk" ],
    "sections" : [ {
      "heading" : null,
      "text" : "ar X\niv :1\n70 4.\n02 80\n1v 1"
    }, {
      "heading" : "1 A Multi-task Learning Approach to Causal",
      "text" : "Inference"
    }, {
      "heading" : "1.1 Causal Inference from Observational Data",
      "text" : "We consider a setting in which a specific treatment (e.g. a drug or a surgery) is applied to a population of subjects (e.g. patients), where each subject i possesses a d-dimensional feature Xi ∈ X , and two potential outcomes Y (1) i , Y (0) i ∈ Y that correspond to the subject’s response with and without the treatment (respectively). The potential outcomes Y (0) i and Y (1) i for subject i are random variables that depend on the subject’s feature Xi, i.e. Yi 6⊥⊥ Xi. The (causal) treatment effect for every individual subject manifests through the random variable (Y (1) i − Y (0) i ) |Xi = x, and the individualized treatment effect (ITE) for subject i, which we denote as T (x), is defined as the expected treatment effect for that subject, i.e.\nT (x) = E [\nY (1) i − Y (0) i ∣ ∣ ∣ Xi = x ] . (1)\nThe central goal of this paper is to efficiently estimate the function T (x) from an observational dataset, e.g. a retrospective cohort study [26, 34] or a hospital’s electronic health record [15]. Since our primary motivation for addressing the problem above comes from its medical application, it is important to associate our estimate of T (x) with a pointwise measure of confidence in order to properly guide therapeutic decisions for individual patients.\nA typical observational dataset D comprises n independent and identically distributed samples of the random tuple (Xi,Wi, Y (Wi) i ), where Wi ∈ {0, 1} is a treatment assignment indicator that indicates whether or not subject i has received the treatment under consideration. The outcomes Y (Wi) i and Y (1−Wi) i are known as the factual and the counterfactual outcomes respectively [6, 11, 15, 27]. The treatment assignment Wi is generally dependent on Xi, i.e. Wi 6⊥⊥ Xi. (In fact, the condition Wi ⊥⊥ Xi is satisfied only in the special case when D comprises data from a randomized control trial.) The conditional distribution P(Wi = 1|Xi = x), also known as the propensity score of subject i [1, 7, 21], reflects the underlying (unknown) policy for assigning the treatment to the subjects. Throughout this paper, we respect the standard assumptions of unconfoundedness (or ignorability) and overlap [1, 3, 8, 12, 15, 32-34]. The former posits that the treatment assignment is independent of the outcomes conditional on the features, i.e. Y (0) i , Y (1) i ⊥⊥ Wi |Xi, whereas the latter requires that P(Wi = 1|Xi = x) and P(Wi = 0|Xi = x) have a common support, i.e. 0 < P(Wi = 1|Xi = x) < 1. The setting described above is known in the literature as the (potential outcomes) Rubin-Neyman causal model [22, 23, 36].\nCausal inference (i.e. estimating T (x)) using D is a challenging task. Since we only observe one of the potential outcomes, we do not directly observe the treatment effect Y (1) i −Y (0) i for every subject i, and hence we cannot use standard supervised learning techniques to estimate T (x). In the next Section, we present\na novel multi-task learning treatment for the causal inference problem."
    }, {
      "heading" : "1.2 A Multi-task Learning Framework for Causal Inference",
      "text" : "We consider the following signal-in-white-noise model for the potential outcomes:\nY (Wi) i = fWi(Xi) + ǫi,Wi , (2)\nwhere ǫi,Wi ∼ N (0, σ 2 Wi\n) is an additive Gaussian noise variable, and fWi(x) is the response surface (i.e. the expected outcome) under the treatment assignment Wi. It follows from (2) that the ITE in (1), T (x) = E[Y (1) i |Xi = x]−E[Y (0) i |Xi = x], can be written as T (x) = f1(x)− f0(x). Define the vectorvalued outcomes function f(x) : X → Y2 as f(x) = [f0(x) f1(x)]T . The ITE is the projection of the outcomes function f(x) on the vector e = [−1 1]T , i.e. T (x) = (f(x)) T e.\nWe model the outcomes function f(x) as belonging to a vector-valued Reproducing Kernel Hilbert Space (vvRKHS) H [2], with a reproducing kernel1 K : X ×X → R2, where K is a symmetric matrix-valued function such that for any x, x′ ∈ X ,K(x, x′) is a positive semi-definite matrix. Using the reproducing property of the vvRKHS [2], 〈f ,K(., x) c〉H = (f(x)) T c, ∀c ∈ R2, we can write the ITE T (x) as follows\nT (x) = (f(x))T e = 〈f ,K(., x) e〉H, (3)\nwhere 〈., .〉H is the inner product in H. The formulation in (3) casts the causal inference problem as a multi-task learning problem [2, 5]. That is, learning T (x) can be achieved by jointly learning the two functions f0(x) and f1(x) through their “kernalized”, shared representation. Our premise is that such an approach would improve the data efficiency in estimating T (x), especially when there is a strong selection bias and poor overlap over the feature space.\nWe formulate the causal inference problem as a regularized empirical error\nminimization task that operates on the observational datasetD = (Xi,Wi, Y (Wi) i ) n i=1. Since we are interested in estimating T (x) rather than the individual response surfaces (f0(x) and f1(x)), we adopt the square loss in the estimated ITE as our loss function. That is, if the true ITE is T ∗(x), the true loss functional L : H × Xn × Yn × {0, 1}n → R+ that results from an ITE estimate T (x) is given by L = ∫\nX (T (x) − T ∗(x))2 P(X = x) dx. Based on (3), the true loss\n1While such a modeling choice is mainly driven by algorithmic motives, it also allows the problem to be theoretically approachable. This is because smoothness and regularity conditions on f0(x) and f1(x) are often required to ensure the pointwise consistency of a point estimate for T (x) in the frequentist framework (e.g. Lipschitz continuity is required for the consistency of causal forests in [33]), or to ensure the adaptivity of the posterior credible sets in the Bayesian framework (e.g. f0(x) and f1(x) are assumed to belong to a Sobolev space in [28, 29]).\nfunctional can be written as\nL =\n∫\nX\n(〈f ,K(., x) e〉H − 〈f ∗,K(., x) e〉H) 2 P(X = x) dx. (4)\nIf we had access to both the factual and the counterfactual outcomes Y (0) i and Y (1) i for every subject i, then the finite-sample loss functional in (4) is given by\nL = 1\nn\nn∑\ni=1\n((f1(Xi)− f0(Xi))− (Y (1) i − Y (0) i )) 2. (5)\nSince we do not observe the counterfactual outcome Y (1−W ) i for subject i, we use a surrogate for the loss functional that imputes all the counterfactual outcomes using the vvRKHS kernel K. Let n1 = ∑n i=1 Wi and n0 = n − n1. Let YW = [Y (W ) i ]i:Wi=w, X W = [Xi]i:Wi=w, w ∈ {0, 1}, Y = [Y 0 Y\n1]T and X = [X0 X1]T . Let Kw(X,X) = [kw(Xi, Xj)]i,j , w ∈ {0, 1}, Xi, Xj ∈ X, K w x (X) = [kw(x,Xi)]i,j , w ∈ {0, 1}, Xi ∈ X. Now define Ỹ = [Ỹ 0 Ỹ 1] ∈ Y2×n as the projection of YW on the vvRKHS at the points induced by X as follows\nỸ = YT [ In0×n0 K 0(X0,X1)\n0n1×n0 K 1(X0,X1)\n]\n. (6)\nHence, causal inference can be conducted by minimizing the finite-sample, regularized loss functional as follows\nf̂ = arg min f∈H\n∣ ∣ ∣ ∣ ∣ ∣f T (X) e− ỸT e ∣ ∣ ∣ ∣ ∣ ∣ 2\n2 + λ ||f ||2H, (7)\nwhere λ is a regularization parameter and ||f ||H is the norm of f in H, i.e. ||f ||H := √\n〈f , f〉 H , which reflects the complexity of the outcomes function f .\nThe loss functional in (4) can be written as\nf̂ = arg min f∈H\n\n  (f1(Xi)− ỹ 1 i )\n︸ ︷︷ ︸\nError in treated\n− (f0(Xi)− ỹ 0 i )\n︸ ︷︷ ︸\nError in control\n\n \n2\n+ λ ||f ||2H ︸ ︷︷ ︸\nComplexity\n. (8)\nIt can be easily shown that the objective above generalizes the objectives of many of the existing methods for causal inference, i.e for different settings of the vvRKHS kernelK, the objective in (8) reduces the objective of kernel matching, balancing counterfactual regression, propensity weighting via kernel density estimation, etc. (Moreover, the adoption of a vvRKHS to model the outcomes function f provides a smoother nonparameteric model for the response surfaces as compared to trees, which allows for faster learning rates for the ITE as compared to tree-based methods such as BART and Causal Forest).\nWe note that our choice of RKHS is motivated by the representer theorems that imply that we can efficiently solve the regularization problem in (8). Moreover, the solution to (8) can be interpreted as the posterior mean of a Gaussian\nprocess. The adoption of a RKHS is not limiting since it spans many function spaces for different selections of K, those include Sobolev space, Lipschitz continuous functions, etc. Moreover, the construction of the outcomes function f as being drawn from a RKHS makes it easy to understand how counterfactual outcomes are imputed in terms of the kernel representations of the data points in the observational dataset D."
    }, {
      "heading" : "1.3 Causal Multi-task Gaussian Processes (CMGPs)",
      "text" : "The causal inference procedure in (8) can be implemented through a frequentist approach as a ridge regression problem with Tikhonov regularization. However, such an approach will lack any form of pointwise (individualized) uncertainty quantification for T̂ (x), which is crucial for applications such as precision medicine. However, we know from the representer theorem that the Bayesian interpretation for (8) allows for uncertainty quantification via posterior credible intervals. Therefore, we follow the Bayesian interpretation of (8), and model the outcomes function f as a (multi-task) Gaussian process with d inputs and 2 outputs, i.e.\nf ∼ GP(0,K). (9)\nThe construction of the kernel K should take into consideration that the two response surfaces f0(x) and f1(x) may display different levels of heterogeneity (smoothness), and may have different relevant features as well. Standard intrinsic correlation models for constructing vector-valued kernels impose the same covariance parameters for all outputs [5], which may lead to slow contraction rates for the posterior distribution sandwiching T (x) over the feature space. To that end, we construct a linear model of coregionalization (LMC) [2,35], which mixes two intrinsic correlation models as follows\nK(x, x′) = A0 k0(x, x ′) +A1 k1(x, x ′), (10)\nwhere kW (x, x ′) is the radial basis function (RBF) with automatic relevance determination, i.e.\nkW (x, x ′) = exp\n(\n− 1\n2 (x− x′)T RW (x− x ′)\n)\n, (11)\nW ∈ {0, 1}, RW = diag(ℓ −2 1,W , ℓ −2 2,W , . . ., ℓ −2 d,W ). Using an LMC, we can capture response surfaces that have significantly different smoothness properties or different relevant co-variates, which cannot be captured by a standard intrinsic correlation model. The length scale parameters represent the relevance of every feature to each of the two response surfaces. The matrices A0 and A1 are given by\nA0 = [ α20 ρ0 ρ0 0 ] , A1 = [ 0 ρ1 ρ1 α 2 1 ] . (12)\nThe parameters α20 and α 2 1 represent the variances of the response surfaces f0(x) and f1(x) respectively, whereas the parameters ρ0 and ρ1 quantify the correlations between the two surfaces and hence the amount of information that are shared between the two outcomes. We denote the set of all the multi-task Gaussian process hyper-parameters as Θ.\nDefine Σ as\nΣ = A0 ◦K 0(X,X) +A1 ◦K 1 x(X,X) + I ◦ diag(σ 2 0 , σ 2 1), (13)\nwhere ◦ is the Tracy-Singh product, defined as the pairwise Kronecker product for each pair of partitions in the two matrices, i.e. A ◦ B = (Aij ◦ B)ij = ((Aij ⊗Bkl)kl)ij , where Aij is the ij-th sub-block of A.\nThe posterior distribution of the outcomes function f(x) given the observational dataset D is given by f(x) | D ∼ N (̄f (x), K̄x), f̄ (x) ∈ H, K̄x ∈ R2×2, where\nf̄(x) = Φ(x)T Σ−1 Y,\nK̄x =\n[ α20 ρ0 + ρ1\nρ0 + ρ1 α 2 1\n]\n−Φ(x)Σ−1 YΦ(x)T , (14)\nwhere Φ(x) = (A0 +A1) ◦ [K 0 x(X) K 1 x(X)].\nThe posterior distribution of the ITE T (x) is equal to the posterior distribution of the outcomes function f projected on the vector e, i.e. we have that\nE[T (x) | D ] = ((A0 e) ◦K 0 x(X) + (A1 e) ◦K 1 x(X)) T Σ −1 Y,\nVar[T (x) | D ] = K̄x(1, 1) + K̄x(2, 2)− 2 K̄x(1, 2). (15)\nWe call our model Causal Multi-task Gaussian Processes (CMGPs). The estimate for the individualized treatment effects for a subject with feature x is T̂ (x) = E[T (x) | D ], wheres the level-γ posterior credible interval is given by Cγ = [T̂ (x) − √ 2Var[T (x) | D ] erf−1(γ), T̂ (x) + √\n2Var[T (x) | D ] erf−1(γ)], where P(T (x) ∈ Cγ |D) = γ."
    }, {
      "heading" : "2 Risk-based Empirical Bayes Estimation of In-",
      "text" : "dividualized Treatment Effects\nA given prior on the RKHS, defined in terms of the kernel K, may be good for true outcomes functions f of some regularity class, but very bad for another. An arbitrary selection for the CMGPs hyper-parameter Θ may lead to unsatisfactory performance, especially for small datasets. This can be alleviated by adapting the prior to the data via empirical Bayes: using a regularity class (i.e. a selection for the kernel K) that is determined by the dataset D.\nDenote the CMGP kernel as a function of the hyper-parameters as K(Θ). The standard approach for implementing empirical Bayes is to find an estimate Θ̂ for the hyper-parameters that maximizes the marginal likelihood function log(P(D|Θ)). However, since we are not interested in directly fitting the\npotential outcomes, but rather in fitting the difference between the potential outcomes, we adopt a risk-based empirical Bayes approach in which the hyperparameters are selected to minimize the objective\nJ(Θ) = 1\nn\nn∑\ni=1\n(T̂ (xi; Θ)− (ỹ 1 i (Θ)− ỹ 0 i (Θ))) 2, (16)\nwhere T̂ (xi; Θ) and ỹ w i (Θ) are the estimated ITEs and the observed outcomes (projected onto the RKHS) given the hyper-parameter Θ. Every selection of Θ corresponds to a certain regularity class or smoothness of the two potential outcomes surfaces, and hence corresponds to a certain interpretation for the observational data. the objective function J(Θ) scores the errors in estimating the ITEs corresponding to the different interpretations of the dataset D.\nMinimizing (16) can be conducted using gradient descent in an iterative fashion as follows: Θt+1 = Θt − ηt ∇ΘJ(Θt). Different variants of the gradient descent calibrate the update rule (e.g. the setting of ηt) in order to work well for specific classes of problems. Those include: momentum, Rprop, Adagrad, RMSprop, and ADAM. Since different update rules may work well for different regularity classes for the outcomes function f , we follow the approach in [37], and we “learn to learn” the update rule by assuming a general functional form for the hyper-parameters update as follows:\nΘt+1 = Θt + gt(∇ΘJ(Θt), φ), (17)\nwhere φ is the parameter of the update rule. Since all the hyper-parameters in a CMGP need to be positive, we reparameterize the hyper-parameters as Θ′ = exp(Θ), and operate on the equivalent iterations:\nΘ′t+1 = Θ ′ t ⊙ exp\n(\ngt\n(\nΘ′t ⊙ ∂J\n∂Θ′t , φ\n))\n, (18)\nwhere ⊙ is the component-wise multiplication. We model the update rule gt(∇ΘJ(Θt), φ) using a recurrent neural network (RNN) with a hidden state that “remembers” the previous evaluations of the objective function, and learns which updates would best help converging to a (local) minimum. We use the ADAM algorithm to learn the parameter φ."
    }, {
      "heading" : "3 Experiments",
      "text" : ""
    }, {
      "heading" : "3.1 The Dataset",
      "text" : "We evaluated the performance of our algorithm through the semi-simulated dataset based on the Infant Health and Development Program (IHDP) introduced in [12]. The IHDP is intended to enhance the cognitive and health status of low birth weight, premature infants through pediatric follow-ups and parent support groups. The semi-simulated dataset in [12] is based on covariates from\na real randomized experiment that evaluated the impact of the IHDP on the subjects’ IQ test scores at the age of three: selection bias is introduced by removing a subset of the treated population. All outcomes (response surfaces) are simulated. The response surface data generation process was not designed to favor our method: we used the standard non-linear “Response Surface B” setting in [12] (also used in [15]) to generate the response surfaces. The dataset comprises 747 subjects (608 control and 139 treated), and there are 25 covariates associated with each subject."
    }, {
      "heading" : "3.2 Benchmarks",
      "text" : "We compared our algorithm to various state-of-the-art methods including BART [12] (the winner of the Causal Inference Data Analysis Challenge at the 2016 Atlantic Causal Inference Conference), in addition to two recently developed algorithms for estimating individualized treatment effects: Causal Forests (CF) [24, 33] and Balancing Neural Networks (BNN) with the BNN-2-2 configuration (i.e. 2 output layers and 2 representation layers) [15]. We also compare our method with a standard matching approach, k-nearest neighbor (k-NN) [26], and classical direct modeling approaches that fit separate regression models for the two potential outcomes using Random Forests (RF) [17] and Gaussian Processes (GP) [19]."
    }, {
      "heading" : "3.3 Evaluation Methodology and Criteria",
      "text" : "We performed 10 held-out experiments to select the hyper-parameters of all the algorithms under consideration, and 1000 experiments to evaluate the performance of the algorithms. In each experiment, we draw new values for the two potential outcomes of all subjects according to the “Response Surface B” model in [12]. (The same evaluation setup was used in [12] and [15].) For BART, we use the default prior as in [12]. We evaluated the performance of every algorithm by measuring its Precision in Estimating Heterogeneous Effects (PEHE) metric introduced in [12]. This metric reflects the accuracy of an algorithm in estimating the “heterogeneity” of a treatment’s effect; it measures the accuracies of the estimates for both the factual and the counter-factual outcomes. The PEHE is computed as the root-mean-square error of the estimates for the treatment effect as follows PEHE = √\n1 n ∑n i=1((f̂1(xi)− f̂1(xi))− T (xi)) 2. The PEHE is\ncomputable since we have simulated outcomes in our experiments, and hence we have access to all the counter-factual outcomes."
    }, {
      "heading" : "3.4 Results",
      "text" : "The results in Table 3.4 clearly demonstrate the significant gains achieved by CMGPs in terms of the accuracy in estimating the individualized treatment effects. As expected, the k-NN algorithm displays the worst performance since it relies on a fixed, non-adaptive distance metric that fails to cope with the selection bias. The gain achieved by GPs with respect to the tree-based algorithms\n(RF, BART and CF) results from the fact that GPs assign a prior distribution on a space of smooth functions (RHKS), whereas tree-based algorithms compute their estimates by averaging many non-smooth functions. That is, trees average many discontinuous functions, and these functions are all very coarse zero-order-hold approximations for the true function, so they need a large number of samples to converge to the true function since the true response function in any given practical setting is indeed smooth. In the Bayesian context, this translates in the GP’s posterior contraction rate being faster than that for treebased algorithms [25, 28, 29], and hence the estimated treatment effect function T̂ (x) converges more quickly to the true function T (x) for a given x. Unlike tree based methods, CMGPs estimate the kernel parameters first using empirical Bayes and then “adapts” its prior to the data. (The kernel parameters (length scale) determine the level of smoothness of the functions over which the GP prior is placed.)"
    } ],
    "references" : [ {
      "title" : "Matching on the Estimated Propensity Score",
      "author" : [ "A. Abadie", "G.W. Imbens" ],
      "venue" : "Econometrica, 84(2):781-807",
      "citeRegEx" : "1",
      "shortCiteRegEx" : null,
      "year" : 2016
    }, {
      "title" : "Kernels for Vector-valued Functions: A Review",
      "author" : [ "M.A. Alvarez", "L. Rosasco", "N.D. Lawrence" ],
      "venue" : "Foundations and Trends R  ©in Machine Learning, 4(3):195-266",
      "citeRegEx" : "2",
      "shortCiteRegEx" : null,
      "year" : 2012
    }, {
      "title" : "Recursive Partitioning for Heterogeneous Causal Effects",
      "author" : [ "S. Athey", "G. Imbens" ],
      "venue" : "Proceedings of the National Academy of Sciences, 113(27):7353-7360",
      "citeRegEx" : "3",
      "shortCiteRegEx" : null,
      "year" : 2016
    }, {
      "title" : "Doubly Robust Estimation in Missing Data and Causal Inference Models",
      "author" : [ "H. Bang", "J.M. Robins" ],
      "venue" : "Biometrics, 61(4):962-973",
      "citeRegEx" : "4",
      "shortCiteRegEx" : null,
      "year" : 2005
    }, {
      "title" : "Multi-task Gaussian Process Prediction",
      "author" : [ "E.V. Bonilla", "K.M. Chai", "C. Williams" ],
      "venue" : "NIPS",
      "citeRegEx" : "5",
      "shortCiteRegEx" : null,
      "year" : 2007
    }, {
      "title" : "and E",
      "author" : [ "L. Bottou", "J. Peters", "J. Candela", "J. Quinonero", "D. Charles", "M. Chickering", "E. Portugaly", "D. Ray", "P. Simard" ],
      "venue" : "Snelson,. Counterfactual Reasoning and Learning Systems: The Example of Computational Advertising. JMLR, 14(1):3207-3260",
      "citeRegEx" : "6",
      "shortCiteRegEx" : null,
      "year" : 2013
    }, {
      "title" : "Some Practical Guidance for the Implementation of Propensity Score Matching",
      "author" : [ "M. Caliendo", "S. Kopeinig" ],
      "venue" : "Journal of Economic Surveys, 22(1):31-72",
      "citeRegEx" : "7",
      "shortCiteRegEx" : null,
      "year" : 2008
    }, {
      "title" : "et al",
      "author" : [ "H.A. Chipman", "E.I. George", "R.E. McCulloch" ],
      "venue" : "BART: Bayesian Additive Regression Trees. The Annals of Applied Statistics, 4(1):266-298",
      "citeRegEx" : "8",
      "shortCiteRegEx" : null,
      "year" : 2010
    }, {
      "title" : "Doubly robust policy evaluation and learning",
      "author" : [ "M. Dudk", "J. Langford", "L. Li" ],
      "venue" : "ICML",
      "citeRegEx" : "9",
      "shortCiteRegEx" : null,
      "year" : 2011
    }, {
      "title" : "Doubly Robust Estimation of Causal Effects",
      "author" : [ "M.J. Funk", "D. Westreich", "C. Wiesen", "T. Strmer", "M.A. Brookhart", "M. Davidian" ],
      "venue" : "American Journal of Epidemiology, 173(7):761-767",
      "citeRegEx" : "10",
      "shortCiteRegEx" : null,
      "year" : 2011
    }, {
      "title" : "Counterfactual Prediction with Deep Instrumental Variables Networks",
      "author" : [ "J. Hartford", "G. Lewis", "K. Leyton-Brown", "M. Taddy" ],
      "venue" : "arXiv preprint arXiv:1612.09596,",
      "citeRegEx" : "11",
      "shortCiteRegEx" : "11",
      "year" : 2016
    }, {
      "title" : "Bayesian Nonparametric Modeling for Causal Inference",
      "author" : [ "J.L. Hill" ],
      "venue" : "Journal of Computational and Graphical Statistics",
      "citeRegEx" : "12",
      "shortCiteRegEx" : null,
      "year" : 2012
    }, {
      "title" : "Nonlinear Causal Discovery with Additive Noise Models",
      "author" : [ "P.O. Hoyer", "D. Janzing", "J.M. Mooij", "J. Peters", "B. Schlkopf" ],
      "venue" : "NIPS",
      "citeRegEx" : "13",
      "shortCiteRegEx" : null,
      "year" : 2009
    }, {
      "title" : "Causal Inference without Balance Checking: Coarsened Exact Matching",
      "author" : [ "S.M. Iacus", "G. King", "G. Porro" ],
      "venue" : "Political Analysis, 1-24",
      "citeRegEx" : "14",
      "shortCiteRegEx" : null,
      "year" : 2011
    }, {
      "title" : "Learning Representations for Counter-factual Inference",
      "author" : [ "F.D. Johansson", "U. Shalit", "D. Sontag" ],
      "venue" : "ICML",
      "citeRegEx" : "15",
      "shortCiteRegEx" : null,
      "year" : 2016
    }, {
      "title" : "ADAM: A Method for Stochastic Optimization",
      "author" : [ "D. Kingma", "J. Ba" ],
      "venue" : "arXiv preprint arXiv:1412.6980",
      "citeRegEx" : "16",
      "shortCiteRegEx" : null,
      "year" : 2014
    }, {
      "title" : "Estimating Individual Treatment Effect in Observational Data using Random Forest Methods",
      "author" : [ "M. Lu", "S. Sadiq", "D.J. Feaster", "H. Ishwaran" ],
      "venue" : "arXiv preprint arXiv:1701.05306",
      "citeRegEx" : "17",
      "shortCiteRegEx" : null,
      "year" : 2017
    }, {
      "title" : "M",
      "author" : [ "K.E. Porter", "S. Gruber" ],
      "venue" : "J. Van Der Laan, and J. S. Sekhon. The Relative Performance of Targeted Maximum Likelihood Estimators. The International Journal of Biostatistics, 7(1):1-34",
      "citeRegEx" : "18",
      "shortCiteRegEx" : null,
      "year" : 2011
    }, {
      "title" : "Gaussian Processes for Machine Learning",
      "author" : [ "Carl Edward Rasmussen" ],
      "venue" : "Citeseer,",
      "citeRegEx" : "19",
      "shortCiteRegEx" : "19",
      "year" : 2006
    }, {
      "title" : "Optimal Matching for Observational Studies",
      "author" : [ "P.R. Rosenbaum" ],
      "venue" : "Journal of the American Statistical Association, 84(408): 1024-1032",
      "citeRegEx" : "20",
      "shortCiteRegEx" : null,
      "year" : 1989
    }, {
      "title" : "The Central Role of the Propensity Score in Observational Studies for Causal Effects",
      "author" : [ "P.R. Rosenbaum", "D.B. Rubin" ],
      "venue" : "Biometrika, 70(1):41-55",
      "citeRegEx" : "21",
      "shortCiteRegEx" : null,
      "year" : 1983
    }, {
      "title" : "Bayesian Inference for Causal Effects: The Role of Randomization",
      "author" : [ "D. B Rubin" ],
      "venue" : "The Annals of statistics, 34-58",
      "citeRegEx" : "22",
      "shortCiteRegEx" : null,
      "year" : 1978
    }, {
      "title" : "Causal Inference using Potential Outcomes",
      "author" : [ "D. B Rubin" ],
      "venue" : "Journal of the American Statistical Association",
      "citeRegEx" : "23",
      "shortCiteRegEx" : null,
      "year" : 2011
    }, {
      "title" : "Estimating Individual Treatment Effect: Generalization Bounds and Algorithms",
      "author" : [ "U. Shalit", "F. Johansson", "D. Sontag" ],
      "venue" : "arXiv preprint arXiv:1606.03976",
      "citeRegEx" : "24",
      "shortCiteRegEx" : null,
      "year" : 2016
    }, {
      "title" : "A",
      "author" : [ "S. Sniekers" ],
      "venue" : "van der Vaart. Adaptive Bayesian Credible Sets in Regression with a Gaussian Process Prior. Electronic Journal of Statistics, 9(2):2475-2527",
      "citeRegEx" : "25",
      "shortCiteRegEx" : null,
      "year" : 2015
    }, {
      "title" : "Matching Methods for Causal Inference: A Review and a Look Forward",
      "author" : [ "E.A. Stuart" ],
      "venue" : "Statistical Science, 25(1):1",
      "citeRegEx" : "26",
      "shortCiteRegEx" : null,
      "year" : 2010
    }, {
      "title" : "Batch Learning from Logged Bandit Feedback Through Counter-factual Risk Minimization",
      "author" : [ "A. Swaminathan", "T. Joachims" ],
      "venue" : "JMLR, 16(1): 1731-1755",
      "citeRegEx" : "27",
      "shortCiteRegEx" : null,
      "year" : 2015
    }, {
      "title" : "A",
      "author" : [ "B. Szabo" ],
      "venue" : "van der Vaart, and H. van Zanten. Honest Bayesian Confidence Sets for the l2-norm. Journal of Statistical Planning and Inference, 166:36-51",
      "citeRegEx" : "28",
      "shortCiteRegEx" : null,
      "year" : 2015
    }, {
      "title" : "A",
      "author" : [ "B. Szabo" ],
      "venue" : "van der Vaart, J. van Zanten. Frequentist Coverage of Adaptive Nonparametric Bayesian Credible Sets. The Annals of Statistics, 43(4): 1391-1428",
      "citeRegEx" : "29",
      "shortCiteRegEx" : null,
      "year" : 2015
    }, {
      "title" : "A Nonparametric Bayesian Analysis of Heterogeneous Treatment Effects in Digital Experimentation",
      "author" : [ "M. Taddy", "M. Gardner", "L. Chen", "D. Draper" ],
      "venue" : "Journal of Business and Economic Statistics",
      "citeRegEx" : "30",
      "shortCiteRegEx" : null,
      "year" : 2016
    }, {
      "title" : "A Simple Method for Estimating Interactions Between a Treatment and a Large Number of Covariates",
      "author" : [ "L. Tian", "A.A. Alizadeh", "A.J. Gentles", "R. Tibshirani" ],
      "venue" : "Journal of the American Statistical Association, 109(508):1517-1532",
      "citeRegEx" : "31",
      "shortCiteRegEx" : null,
      "year" : 2014
    }, {
      "title" : "Model Criticism for Bayesian Causal Inference",
      "author" : [ "D. Tran", "F.J. Ruiz", "S. Athey", "D.M. Blei" ],
      "venue" : "arXiv preprint arXiv:1610.09037",
      "citeRegEx" : "32",
      "shortCiteRegEx" : null,
      "year" : 2016
    }, {
      "title" : "Estimation and Inference of Heterogeneous Treatment Effects using Random Forests",
      "author" : [ "S. Wager", "S. Athey" ],
      "venue" : "arXiv preprint arXiv:1510.04342",
      "citeRegEx" : "33",
      "shortCiteRegEx" : null,
      "year" : 2015
    }, {
      "title" : "Estimating Heterogeneous Treatment Effects with Observational Data",
      "author" : [ "Y. Xie", "J.E. Brand", "B. Jann" ],
      "venue" : "Sociological Methodology, 42(1):314-347",
      "citeRegEx" : "34",
      "shortCiteRegEx" : null,
      "year" : 2012
    }, {
      "title" : "Multivariate Geostatistics: an Introduction with Applications",
      "author" : [ "H. Wackernagel" ],
      "venue" : "Springer Science and Business Media",
      "citeRegEx" : "35",
      "shortCiteRegEx" : null,
      "year" : 2013
    }, {
      "title" : "On the Application of Probability Theory to Agricultural Experiments",
      "author" : [ "J. Splawa-Neyman", "D.M. Dabrowska", "T.P. Speed" ],
      "venue" : "Statistical Science, 5(4): 465-472",
      "citeRegEx" : "36",
      "shortCiteRegEx" : null,
      "year" : 1990
    }, {
      "title" : "Learning to Learn by Gradient Descent by Gradient Descent",
      "author" : [ "M. Andrychowicz", "M. Denil", "S. Gomez", "M.W. Hoffman", "D. Pfau", "T. Schaul", "N. de Freitas" ],
      "venue" : "NIPS 2016",
      "citeRegEx" : "37",
      "shortCiteRegEx" : "37",
      "year" : 2016
    } ],
    "referenceMentions" : [ {
      "referenceID" : 25,
      "context" : "a retrospective cohort study [26, 34] or a hospital’s electronic health record [15].",
      "startOffset" : 29,
      "endOffset" : 37
    }, {
      "referenceID" : 33,
      "context" : "a retrospective cohort study [26, 34] or a hospital’s electronic health record [15].",
      "startOffset" : 29,
      "endOffset" : 37
    }, {
      "referenceID" : 14,
      "context" : "a retrospective cohort study [26, 34] or a hospital’s electronic health record [15].",
      "startOffset" : 79,
      "endOffset" : 83
    }, {
      "referenceID" : 5,
      "context" : "The outcomes Y (Wi) i and Y (1−Wi) i are known as the factual and the counterfactual outcomes respectively [6, 11, 15, 27].",
      "startOffset" : 107,
      "endOffset" : 122
    }, {
      "referenceID" : 10,
      "context" : "The outcomes Y (Wi) i and Y (1−Wi) i are known as the factual and the counterfactual outcomes respectively [6, 11, 15, 27].",
      "startOffset" : 107,
      "endOffset" : 122
    }, {
      "referenceID" : 14,
      "context" : "The outcomes Y (Wi) i and Y (1−Wi) i are known as the factual and the counterfactual outcomes respectively [6, 11, 15, 27].",
      "startOffset" : 107,
      "endOffset" : 122
    }, {
      "referenceID" : 26,
      "context" : "The outcomes Y (Wi) i and Y (1−Wi) i are known as the factual and the counterfactual outcomes respectively [6, 11, 15, 27].",
      "startOffset" : 107,
      "endOffset" : 122
    }, {
      "referenceID" : 0,
      "context" : ") The conditional distribution P(Wi = 1|Xi = x), also known as the propensity score of subject i [1, 7, 21], reflects the underlying (unknown) policy for assigning the treatment to the subjects.",
      "startOffset" : 97,
      "endOffset" : 107
    }, {
      "referenceID" : 6,
      "context" : ") The conditional distribution P(Wi = 1|Xi = x), also known as the propensity score of subject i [1, 7, 21], reflects the underlying (unknown) policy for assigning the treatment to the subjects.",
      "startOffset" : 97,
      "endOffset" : 107
    }, {
      "referenceID" : 20,
      "context" : ") The conditional distribution P(Wi = 1|Xi = x), also known as the propensity score of subject i [1, 7, 21], reflects the underlying (unknown) policy for assigning the treatment to the subjects.",
      "startOffset" : 97,
      "endOffset" : 107
    }, {
      "referenceID" : 0,
      "context" : "Throughout this paper, we respect the standard assumptions of unconfoundedness (or ignorability) and overlap [1, 3, 8, 12, 15, 32-34].",
      "startOffset" : 109,
      "endOffset" : 133
    }, {
      "referenceID" : 2,
      "context" : "Throughout this paper, we respect the standard assumptions of unconfoundedness (or ignorability) and overlap [1, 3, 8, 12, 15, 32-34].",
      "startOffset" : 109,
      "endOffset" : 133
    }, {
      "referenceID" : 7,
      "context" : "Throughout this paper, we respect the standard assumptions of unconfoundedness (or ignorability) and overlap [1, 3, 8, 12, 15, 32-34].",
      "startOffset" : 109,
      "endOffset" : 133
    }, {
      "referenceID" : 11,
      "context" : "Throughout this paper, we respect the standard assumptions of unconfoundedness (or ignorability) and overlap [1, 3, 8, 12, 15, 32-34].",
      "startOffset" : 109,
      "endOffset" : 133
    }, {
      "referenceID" : 14,
      "context" : "Throughout this paper, we respect the standard assumptions of unconfoundedness (or ignorability) and overlap [1, 3, 8, 12, 15, 32-34].",
      "startOffset" : 109,
      "endOffset" : 133
    }, {
      "referenceID" : 31,
      "context" : "Throughout this paper, we respect the standard assumptions of unconfoundedness (or ignorability) and overlap [1, 3, 8, 12, 15, 32-34].",
      "startOffset" : 109,
      "endOffset" : 133
    }, {
      "referenceID" : 32,
      "context" : "Throughout this paper, we respect the standard assumptions of unconfoundedness (or ignorability) and overlap [1, 3, 8, 12, 15, 32-34].",
      "startOffset" : 109,
      "endOffset" : 133
    }, {
      "referenceID" : 33,
      "context" : "Throughout this paper, we respect the standard assumptions of unconfoundedness (or ignorability) and overlap [1, 3, 8, 12, 15, 32-34].",
      "startOffset" : 109,
      "endOffset" : 133
    }, {
      "referenceID" : 21,
      "context" : "The setting described above is known in the literature as the (potential outcomes) Rubin-Neyman causal model [22, 23, 36].",
      "startOffset" : 109,
      "endOffset" : 121
    }, {
      "referenceID" : 22,
      "context" : "The setting described above is known in the literature as the (potential outcomes) Rubin-Neyman causal model [22, 23, 36].",
      "startOffset" : 109,
      "endOffset" : 121
    }, {
      "referenceID" : 35,
      "context" : "The setting described above is known in the literature as the (potential outcomes) Rubin-Neyman causal model [22, 23, 36].",
      "startOffset" : 109,
      "endOffset" : 121
    }, {
      "referenceID" : 1,
      "context" : "We model the outcomes function f(x) as belonging to a vector-valued Reproducing Kernel Hilbert Space (vvRKHS) H [2], with a reproducing kernel K : X ×X → R, where K is a symmetric matrix-valued function such that for any x, x ∈ X ,K(x, x) is a positive semi-definite matrix.",
      "startOffset" : 112,
      "endOffset" : 115
    }, {
      "referenceID" : 1,
      "context" : "Using the reproducing property of the vvRKHS [2], 〈f ,K(.",
      "startOffset" : 45,
      "endOffset" : 48
    }, {
      "referenceID" : 1,
      "context" : "The formulation in (3) casts the causal inference problem as a multi-task learning problem [2, 5].",
      "startOffset" : 91,
      "endOffset" : 97
    }, {
      "referenceID" : 4,
      "context" : "The formulation in (3) casts the causal inference problem as a multi-task learning problem [2, 5].",
      "startOffset" : 91,
      "endOffset" : 97
    }, {
      "referenceID" : 32,
      "context" : "Lipschitz continuity is required for the consistency of causal forests in [33]), or to ensure the adaptivity of the posterior credible sets in the Bayesian framework (e.",
      "startOffset" : 74,
      "endOffset" : 78
    }, {
      "referenceID" : 27,
      "context" : "f0(x) and f1(x) are assumed to belong to a Sobolev space in [28, 29]).",
      "startOffset" : 60,
      "endOffset" : 68
    }, {
      "referenceID" : 28,
      "context" : "f0(x) and f1(x) are assumed to belong to a Sobolev space in [28, 29]).",
      "startOffset" : 60,
      "endOffset" : 68
    }, {
      "referenceID" : 4,
      "context" : "Standard intrinsic correlation models for constructing vector-valued kernels impose the same covariance parameters for all outputs [5], which may lead to slow contraction rates for the posterior distribution sandwiching T (x) over the feature space.",
      "startOffset" : 131,
      "endOffset" : 134
    }, {
      "referenceID" : 1,
      "context" : "To that end, we construct a linear model of coregionalization (LMC) [2,35], which mixes two intrinsic correlation models as follows",
      "startOffset" : 68,
      "endOffset" : 74
    }, {
      "referenceID" : 34,
      "context" : "To that end, we construct a linear model of coregionalization (LMC) [2,35], which mixes two intrinsic correlation models as follows",
      "startOffset" : 68,
      "endOffset" : 74
    }, {
      "referenceID" : 36,
      "context" : "Since different update rules may work well for different regularity classes for the outcomes function f , we follow the approach in [37], and we “learn to learn” the update rule by assuming a general functional form for the hyper-parameters update as follows:",
      "startOffset" : 132,
      "endOffset" : 136
    }, {
      "referenceID" : 11,
      "context" : "We evaluated the performance of our algorithm through the semi-simulated dataset based on the Infant Health and Development Program (IHDP) introduced in [12].",
      "startOffset" : 153,
      "endOffset" : 157
    }, {
      "referenceID" : 11,
      "context" : "The semi-simulated dataset in [12] is based on covariates from",
      "startOffset" : 30,
      "endOffset" : 34
    }, {
      "referenceID" : 11,
      "context" : "The response surface data generation process was not designed to favor our method: we used the standard non-linear “Response Surface B” setting in [12] (also used in [15]) to generate the response surfaces.",
      "startOffset" : 147,
      "endOffset" : 151
    }, {
      "referenceID" : 14,
      "context" : "The response surface data generation process was not designed to favor our method: we used the standard non-linear “Response Surface B” setting in [12] (also used in [15]) to generate the response surfaces.",
      "startOffset" : 166,
      "endOffset" : 170
    }, {
      "referenceID" : 11,
      "context" : "We compared our algorithm to various state-of-the-art methods including BART [12] (the winner of the Causal Inference Data Analysis Challenge at the 2016 Atlantic Causal Inference Conference), in addition to two recently developed algorithms for estimating individualized treatment effects: Causal Forests (CF) [24, 33] and Balancing Neural Networks (BNN) with the BNN-2-2 configuration (i.",
      "startOffset" : 77,
      "endOffset" : 81
    }, {
      "referenceID" : 23,
      "context" : "We compared our algorithm to various state-of-the-art methods including BART [12] (the winner of the Causal Inference Data Analysis Challenge at the 2016 Atlantic Causal Inference Conference), in addition to two recently developed algorithms for estimating individualized treatment effects: Causal Forests (CF) [24, 33] and Balancing Neural Networks (BNN) with the BNN-2-2 configuration (i.",
      "startOffset" : 311,
      "endOffset" : 319
    }, {
      "referenceID" : 32,
      "context" : "We compared our algorithm to various state-of-the-art methods including BART [12] (the winner of the Causal Inference Data Analysis Challenge at the 2016 Atlantic Causal Inference Conference), in addition to two recently developed algorithms for estimating individualized treatment effects: Causal Forests (CF) [24, 33] and Balancing Neural Networks (BNN) with the BNN-2-2 configuration (i.",
      "startOffset" : 311,
      "endOffset" : 319
    }, {
      "referenceID" : 14,
      "context" : "2 output layers and 2 representation layers) [15].",
      "startOffset" : 45,
      "endOffset" : 49
    }, {
      "referenceID" : 25,
      "context" : "We also compare our method with a standard matching approach, k-nearest neighbor (k-NN) [26], and classical direct modeling approaches that fit separate regression models for the two potential outcomes using Random Forests (RF) [17] and Gaussian Processes (GP) [19].",
      "startOffset" : 88,
      "endOffset" : 92
    }, {
      "referenceID" : 16,
      "context" : "We also compare our method with a standard matching approach, k-nearest neighbor (k-NN) [26], and classical direct modeling approaches that fit separate regression models for the two potential outcomes using Random Forests (RF) [17] and Gaussian Processes (GP) [19].",
      "startOffset" : 228,
      "endOffset" : 232
    }, {
      "referenceID" : 18,
      "context" : "We also compare our method with a standard matching approach, k-nearest neighbor (k-NN) [26], and classical direct modeling approaches that fit separate regression models for the two potential outcomes using Random Forests (RF) [17] and Gaussian Processes (GP) [19].",
      "startOffset" : 261,
      "endOffset" : 265
    }, {
      "referenceID" : 11,
      "context" : "In each experiment, we draw new values for the two potential outcomes of all subjects according to the “Response Surface B” model in [12].",
      "startOffset" : 133,
      "endOffset" : 137
    }, {
      "referenceID" : 11,
      "context" : "(The same evaluation setup was used in [12] and [15].",
      "startOffset" : 39,
      "endOffset" : 43
    }, {
      "referenceID" : 14,
      "context" : "(The same evaluation setup was used in [12] and [15].",
      "startOffset" : 48,
      "endOffset" : 52
    }, {
      "referenceID" : 11,
      "context" : ") For BART, we use the default prior as in [12].",
      "startOffset" : 43,
      "endOffset" : 47
    }, {
      "referenceID" : 11,
      "context" : "We evaluated the performance of every algorithm by measuring its Precision in Estimating Heterogeneous Effects (PEHE) metric introduced in [12].",
      "startOffset" : 139,
      "endOffset" : 143
    }, {
      "referenceID" : 24,
      "context" : "In the Bayesian context, this translates in the GP’s posterior contraction rate being faster than that for treebased algorithms [25, 28, 29], and hence the estimated treatment effect function T̂ (x) converges more quickly to the true function T (x) for a given x.",
      "startOffset" : 128,
      "endOffset" : 140
    }, {
      "referenceID" : 27,
      "context" : "In the Bayesian context, this translates in the GP’s posterior contraction rate being faster than that for treebased algorithms [25, 28, 29], and hence the estimated treatment effect function T̂ (x) converges more quickly to the true function T (x) for a given x.",
      "startOffset" : 128,
      "endOffset" : 140
    }, {
      "referenceID" : 28,
      "context" : "In the Bayesian context, this translates in the GP’s posterior contraction rate being faster than that for treebased algorithms [25, 28, 29], and hence the estimated treatment effect function T̂ (x) converges more quickly to the true function T (x) for a given x.",
      "startOffset" : 128,
      "endOffset" : 140
    } ],
    "year" : 2017,
    "abstractText" : "We consider the problem of obtaining individualized estimates for the effect of a certain treatment given observational data. The problem differs fundamentally from classical supervised learning since for each individual subject, we either observe the response with or without the treatment but never both. Hence, estimating the effect of a treatment entails a causal inference task in which we need to estimate counterfactual outcomes. To address this problem, we propose a novel multi-task learning framework in which the individuals’ responses with and without the treatment are modeled as a vector-valued function that belongs to a reproducing kernel Hilbert space. Unlike previous methods for causal inference that use the G-computation formula, our approach does not obtain separate estimates for the treatment and control response surfaces, but rather obtains a joint estimate that ensures data efficiency in scenarios where the selection bias is strong. In order to be able to provide individualized measures of uncertainty in our estimates, we adopt a Bayesian approach for learning this vector-valued function using a multi-task Gaussian process prior; uncertainty is quantified via posterior credible intervals. We develop a novel risk based empirical Bayes approach for calibrating the Gaussian process hyper-parameters in a data-driven fashion based on gradient descent in which the update rule is itself learned from the data using a recurrent neural network. Experiments conducted on semi-synthetic data show that our algorithm significantly outperforms state-of-the-art causal inference methods.",
    "creator" : "LaTeX with hyperref package"
  }
}