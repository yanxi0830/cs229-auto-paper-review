{
  "name" : "1306.1083.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "Discriminative Parameter Estimation for Random Walks Segmentation: Technical Report",
    "authors" : [ "Pierre-Yves Baudin", "Danny Goodman", "Puneet Kumar", "Noura Azzabou", "Pierre G. Carlier", "Nikos Paragios", "Pawan Kumar" ],
    "emails" : [ ],
    "sections" : [ {
      "heading" : null,
      "text" : "ar X\niv :1\n30 6.\n10 83\nv1 [\ncs .C\nV ]\n5 J\nun 2\n01 3\nDiscriminative Parameter Estimation\nfor Random Walks Segmentation:\nTechnical Report\nPierre-Yves Baudin1−6, Danny Goodman1−3, Puneet Kumar1−3, Noura Azzabou4−6, Pierre G. Carlier4−6, Nikos Paragios1−3, and\nM. Pawan Kumar1−3\n1 Center for Visual Computing, École Centrale Paris, FR 2 Université Paris-Est, LIGM (UMR CNRS), École des Ponts ParisTech, FR\n3 Équipe Galen, INRIA Saclay, FR 4 Institute of Myology, Paris, FR\n5 CEA, I2 BM, MIRCen, IdM NMR Laboratory, Paris, FR 6 UPMC University Paris 06, Paris, FR"
    }, {
      "heading" : "1 Literature Survey on the State of the Art Algorithms in Muscle Segmentation",
      "text" : "In the following, we present the principal methods addressing the segmentation of skeletal muscles.\nMuscle Segmentation using Simplex meshes with medial representations A skeletal muscle segmentation method was presented in [8] based on simplex meshes [6]. Considering a 3D surface model, simplex meshes are discrete meshes where each vertex has exactly 3 neighbors. Having a constant connectivity allows to simply parametrize the location of one vertex with respect to its neighbors, and thus parametrize deformation of the shape – translation, rotation, scaling – in a local manner. Indeed, the location of a pixel, denoted as x can be expressed as a linear combination of the locations of the three neighbors plus a local elevation term parallel to the local normal: x = ε1x1 + ε2x2 + (1− ε1 − ε2)x3 + hn. As a result, many local measurements – including curvature and cell surface – can be computed efficiently and global energy terms enforcing local constraints come up naturally.\nHere, the authors impose local smoothing via curvature averaging, which does not tend to reduce the surface like 1-order operators typically do. Prior knowledge is imposed by constraining the local scale changes on the elevation parameter with respect to a reference shape. Denoting the surface of the triangle formed by the three neighbors of a pixel as S, given the reference shape parameters ( ε̃1, ε̃2, h̃, S̃ )\n, the new location of the considered pixel is expressed as:\nx = ε̃1x1 + ε̃2x2 + (1− ε̃1 − ε̃2)x3 + h̃ ( S/S̃ )1/β n, (1)\nwhere β ∈ [2,+∞[ is a parameter which sets the amount of allowed local deformation: with β = 2 this definition is similitude invariant; with β = +∞ this"
    }, {
      "heading" : "2 Pierre-Yves Baudin et al.",
      "text" : "definition is invariant through rigid transformations only. The model is attached to the target image through either gradient norm maximization in the direction of the gradient at the location of the vertices, or maximization of similarities between the reference and the target images at the vertices location.\nA medial representation – similar to the M-reps [13] – is combined with the simplex parametrization to exploit the specific tubular shapes of the skeletal muscles. Medial vertices are added to the model, constrained to remain on the medial axis of the tubular objects. This is achieved by connecting the new vertices to the surface vertices through spring-like forces. This constrains the global structure to resemble its initial reference shape, thus acting as a global shape prior. This medial axis representation also allows efficient collision handling. The model is fit to the image through an iterative process of successive local evolutions. Such model appear to always yield a valid solution, sometimes at the price of an excessive regularization or lack of adaptability to the specifics of the target image. paragraphMuscle Segmentation using Deformable Models and Shape Matching\nMuscle Segmentation using Deformable Models and Shape Matching A shape prior for muscle segmentation in 3D images was presented in [9], deriving from a computer animation technique, called shape matching, used to efficiently approximate large soft-tissue elastic deformations. This method was applied to muscle segmentation with some success. In this approach, discrete meshes are used to parametrize the moving surface. Let x0 be the vector containing the initial position of the control points of the parametric surface. Clustering is performed on x0 such that each cluster ζi contains at least a certain number of vertices (set by the user). During segmentation, the evolution of the active surface is performed according to the following iterative procedure:\n1. Shift vertices according to the external force: x̃t = fext + x t. The external\n“force” fext is computed as the maximal gradient search in the gradient direction.\n2. Regularize vertex positions:\n(a) Compute rigid registration for each clusters:\nTi = argmin ∑\nj∈ζi\n∥ ∥Tix 0 j − x̃ t j ∥ ∥ 2 , (2)\n(b) Average target position for each vertex:\nxt+1i = 1\n|ζi|\n∑\nj∈ζi\nTjx 0 j . (3)\nSingle reference prior models are convenient in that they require only one annotated example of the objects of interest. However, when segmenting a class of objects whose shape varies a lot, such approach becomes too constraining and does not allow the model to adopt valid shapes which are too different from the single reference.\nParameter Estimation for RW Segmentation: Technical Report 3\nMuscle segmentation using a hierarchical statistical shape model A hierarchical prior model using Diffusion Wavelets was proposed to segment organs in [7] – including one calf muscle – in MRI. This model builds on the formulation of the ASM [4], using a different basis for the subspace of valid solutions. One of the main drawbacks of ASMs, is that they often require a large number of training data in order to obtain relevant decomposition modes. Indeed, some non-correlated shape features – such as global and local shape configurations – are often modeled by the same deformation modes. Thus, desired shape behaviors are often mixed with unwanted shape behaviors when optimizing the shape parameters for segmenting a new image. The hierarchical approach allows to uncorrelate small and large scale shape behaviors. Moreover, the presented method also uncorrelates long-range shape behaviors, thus ensuring that deformation mode are spatially localized.\nWe give a brief summary of this method. First, a graph G (V , E) is built on the set of landmarks: V is the set of nodes and each landmark corresponds to a node in V ; E is the set of edges, whose weights are determined through a statistical analysis of the mutual relations between the landmarks in the training set {xk}k=1...K (cf. Shape Maps [12]). As a result, landmarks with independent behaviors will be connected by edges with a small weight, whereas nodes with strongly related behaviors – such as neighboring points – will be connected by large weight edges.\nSecond, a Diffusion Wavelet decomposition of G is performed. This process involves computing the diffusion operator T of graph G, which is the symmetric normalized Laplace-Beltrami operator, and computing and compressing the dyadic powers of T. The output of this decomposition is a hierarchical orthogonal basis {Γi} for the graph, whose vectors correspond to different graph scales; considering the vector of landmark positions when decomposed on the new basis:\nx = x̄+ Γp, (4)\nglobal deformations – i.e. global relations between all the nodes – are controlled by some of the coefficients in p, while local interactions – i.e. local interactions between close-by nodes – are controlled by some other coefficients in p. Projecting all the training examples onto this new basis, a PCA is performed at each scale of the decomposition. Finally, during the segmentation process, the landmarks are positioned on the target image in an iterative manner: 1) the position of the landmarks is updated according to a local appearance model; 2) they are projected into the hierarchical subspace defined previously.\nMuscle segmentation using a continuous region model A region-based segmentation method, proposed in [5], was extended to multi-label segmentation in [2], and applied to skeletal muscle segmentation [1]. Before performing the PCA on the training samples, an Isometric Log-Ratio (ILR) transform is applied to the assignment vectors. The reason for using this transform is that multi-label segmentation requires to have probabilities at all times, which the previous method does not achieve. Here, the PCA is performed in the ILR space and its output"
    }, {
      "heading" : "4 Pierre-Yves Baudin et al.",
      "text" : "is projected back into the initial probability space. Denoting ηγ = µ + Γγ a segmentation in the subspace of valid solution spanned by the PCA in the ILR space, the following functional is proposed:\nE (ηγ) = d (ηBG,ηγ) 2 +\n∫\n(1− h (x)) |∇ηγ | 2 + γTΣ−1γ, (5)\nwhere d (ηBG, ·) is an intensity prior functional for separating muscle voxels from background voxels, and h (x) is and edge-map of the target image such that the energy is minimal when the boundaries of the model match the edges in the image."
    }, {
      "heading" : "2 The Random Walks Algorithm",
      "text" : "The Random Walks algorithm is graph-based: consider a graph G = (V , E), where V is a set of nodes – corresponding to each voxel in the 3d image – and E is a set of edges – one per pair of adjacent voxels. Let us also denote a set of labels – one per object to segment – as S.\nThe aim of the Random Walks Algorithm [10] is to compute an assignment probability of all voxels to all labels. These probabilities depend on: i) contrast between adjacent voxels, ii) manual – thus deterministic – assignments of some voxels, called seeds, and iii) prior assignment probabilities.\nThe probabilities, contained in vector y, can be obtained by minimizing the following functional:\nERWprior(x,y) = y ⊤Ly + w‖y − y0‖ 2 Ω(x)\n= y⊤\n[\n∑\nα\nwαLα\n]\ny + ∑\nβ\nwβ‖y − yβ‖ 2 Ωβ ,\nwhich is a linear combination of Laplacians and prior terms. The Laplacian matrices Lα contain the contrast terms. Its entries are of the form:\nLi,j =\n\n \n \n∑\nk ωkj if i = j,\n−ωij if (i, j) ∈ E ,\n0 otherwise.\n(6)\nHere, ωij designates the weight of edge (i, j). It is usually computed as follows:\nωij = exp ( −β (Ii − Ij) 2 ) , (7)\nwhere Ii is the intensity of voxel i. In our experiments, we used three different Laplacians using this formnulation, with three values of β: 50, 100 and 150 (with the image voxel values normalized with their empirical standard deviation).\nParameter Estimation for RW Segmentation: Technical Report 5\nWe also implemented the lesser used alternate formulation:\nwij = 1\nβ |Ii − Ij |+ ε , (8)\nwhich we employed in one additional Laplacian term with β = 100 and ε = 1 for comparison purposes, since the selected values do give good results on their own.\nSince the objective function is quadratic in y, its minimum can be computed by minimizing a linear system. The quadratic term, composed of a sum of Laplacians and diagonal matrices due to the prior term, is very sparse and has a specific structure due to the fact that only adjacent voxels are connected with an edge.\nGiven the size of the problem (several millions of variables), this system has to be solved with iterative methods, such as Conjugate Gradient. The specific structure of the problem and the existence of parallelized algorithms (such as multigrid Conjugate Gradient) allow for an efficient optimization. For instance, our own implementation takes less than 20s for volumes of size 200× 200× 100 on a regular desktop machine."
    }, {
      "heading" : "3 Derivation of the Latent SVM Upper Bound",
      "text" : "Given a dataset D = {(xk, zk) , k = 1, . . . , N}, which consists of inputs xk and their hard segmentation zk, we would like to estimate parameters w such that the resulting inferred segmentations are accurate. Here, the accuracy is measured using the loss function ∆ (·, ·). Formally, let ỹk (w) denote the soft segmentation obtained by minimizing the energy functional E (·,xk; w) for the k-th training sample, that is,\nỹk (w) = argmin y\nw⊤ψ (xk,y) . (9)\nWe would like to learn the parameters w such that the empirical risk is minimized over all samples in the dataset. In other words, we would like to estimate the parameters w⋆ such that\nw⋆ = argmin w\n1\nN\n∑\nk\n∆ (zk, ỹk (w)) . (10)\nThe above objective function is highly non-convex in w, which makes it prone to bad local minimum solutions. To alleviate this deficiency, the latent SVM"
    }, {
      "heading" : "6 Pierre-Yves Baudin et al.",
      "text" : "formulation upper bounds the risk for a sample (x, z) as follows:\n∆ (zk, ỹk (w)) = ∆ (zk, ỹk (w)) +w ⊤ [ψ (xk, ỹk (w))− ψ (xk, ỹk (w))] , (11)\n≤ min ∆(zk,ŷ)=0\nw⊤ψ (xk, ŷ) (12)\n− [ w⊤ψ (xk, ỹk (w))−∆ (zk, ỹk (w)) ] ,\n≤ min ∆(zk,ŷ)=0\nw⊤ψ (xk, ŷ) (13)\n−min y\n[ w⊤ψ (xk,y)−∆ (zk,y) ] .\nThe first inequality follows from the fact that the prediction ỹk (w) has the minimum possible energy (see equation 9). Thus, its energy has to be less than or equal to the energy of any compatible segmentation ŷ with ∆ (zk, ŷ) = 0. The second inequality is true since it replaces the loss augmented energy of the prediction ỹk (w) with the minimum loss augmented energy.\nThis inequality leads to the following minimization problem:\nmin w, ξk≥0\nλ ‖w‖2 + 1\nN\n∑\nk\nξk, (14)\ns.t. min ∆(xk,ŷ)=0\nw⊤ψ (xk, ŷ) ≤ w ⊤ψ (xk, ȳ)−∆ (zk, ȳ) + ξk, ∀ȳ, ∀k,\nwhere λ ‖w‖2 is a regularization term, preventing overfitting the parameters to the training data."
    }, {
      "heading" : "4 Dual-Decomposition Algorithm for the ACI",
      "text" : "Briefly, dual decomposition allows us to iteratively solve a convex optimization problem of the form\ny∗ = argmin y∈F\nM ∑\nm=1\ngm(y). (15)\nAt each iteration t it solves a set of slaves problems\ny∗m = argmin ym∈F\n(\ngm(ym) + ρ t mym\n)\n, (16)\nwhere ρtm are the dual variables satisfying ∑ m ρ t m = 0. The dual variables are initialized as ρ0m = 0, ∀m, and updated at iteration t as follows:\nρt+1m ← ρ t m + η t(y∗m − ∑\nn\ny∗n/M), (17)\nwhere ηt is the learning rate at iteration t. Under fairly general conditions, this iterative strategy converges to the globally optimal solution of the original problem, that is, y∗ = y∗m, ∀m. We refer the reader to [3,11] for details.\nIn order to specify our slave problems, we divide the set of voxels V into subsets Vm,m = 1, · · · ,M , such that each pair of neighboring voxels (i, j) ∈ N\nParameter Estimation for RW Segmentation: Technical Report 7\nappear together in exactly one subset Vm. Given such a division of voxels, our slave problems correspond to the following:\nmin ym∈C(Vm)\ny⊤mLm(x;w)ym + E prior m (ym,x;w) + ρ t mym, (18)\nwhere Lm(x;w) is the Laplacian corresponding to the voxels Vm. The prior energy functions Epriorm modify the original prior E\nprior by weighing each voxel i ∈ Vm by the reciprocal of the number of subsets Vn that contain i. In other words, the prior term for each voxel i ∈ Vm is multiplied by 1/|{Vn, i ∈ Vn}|.\nThe slave problems defined above can be shown to provide a valid reparameterization of the original problem:\nmin y∈C(V)\ny⊤L(x;w)y + Eprior(y,x;w). (19)\nBy using small subsets Vm we can optimize each slave problem in every iteration using a standard quadratic programming solver. In our experiments, we used the Mosek solver. To the best of our knowledge, this is the first application of dual decomposition to solve a probabilistic segmentation problem under linear constraints."
    }, {
      "heading" : "8 Pierre-Yves Baudin et al.",
      "text" : "9. Gilles, B., Pai, D.K.: Fast musculoskeletal registration based on shape matching. In: MICCAI, Lecture Notes in Computer Science, vol. 5242, pp. 822–829 (Jan 2008), http://www.ncbi.nlm.nih.gov/pubmed/18982681 10. Grady, L.: Random walks for image segmentation. PAMI (2006) 11. Komodakis, N., Paragios, N., Tziritas, G.: MRF optimization via dual decompo-\nsition: Message-passing revisited. In: ICCV (2007) 12. Langs, G., Paragios, N., Mas, L., Paris, E.C.D., Galen, E., Saclay, I.: Modeling the\nstructure of multivariate manifolds: Shape Maps (2008) 13. Pizer, S.M., Fletcher, P.T., Joshi, S., Thall, A., Chen, J.Z., Fridman, Y., Fritsch,\nD.S., Gash, A.G., Glotzer, J.M., Jiroutek, M.R., et al.: Deformable m-reps for 3d medical image segmentation. International Journal of Computer Vision 55(2-3), 85–106 (2003)\nar X\niv :1\n30 6.\n10 83\nv1 [\ncs .C\nV ]\n5 J\nun 2\n01 3\nPreface\nThis textbook is intended for use by students of physics, physical chemistry, and theoretical chemistry. The reader is presumed to have a basic knowledge of atomic and quantum physics at the level provided, for example, by the first few chapters in our book The Physics of Atoms and Quanta. The student of physics will find here material which should be included in the basic education of every physicist. This book should furthermore allow students to acquire an appreciation of the breadth and variety within the field of molecular physics and its future as a fascinating area of research.\nFor the student of chemistry, the concepts introduced in this book will provide a theoretical framework for that entire field of study. With the help of these concepts, it is at least in principle possible to reduce the enormous body of empirical chemical knowledge to a few basic principles: those of quantum mechanics. In addition, modern physical methods whose fundamentals are introduced here are becoming increasingly important in chemistry and now represent indispensable tools for the chemist. As examples, we might mention the structural analysis of complex organic compounds, spectroscopic investigation of very rapid reaction processes or, as a practical application, the remote detection of pollutants in the air.\nApril 1995 Walter Olthoff Program Chair\nECOOP’95\nOrganization\nECOOP’95 is organized by the department of Computer Science, Univeristy of Århus and AITO (association Internationa pour les Technologie Object) in cooperation with ACM/SIGPLAN.\nExecutive Commitee\nConference Chair: Ole Lehrmann Madsen (Århus University, DK) Program Chair: Walter Olthoff (DFKI GmbH, Germany) Organizing Chair: Jørgen Lindskov Knudsen (Århus University, DK) Tutorials: Birger Møller-Pedersen (Norwegian Computing Center, Norway) Workshops: Eric Jul (University of Kopenhagen, Denmark) Panels: Boris Magnusson (Lund University, Sweden) Exhibition: Elmer Sandvad (Århus University, DK) Demonstrations: Kurt Nørdmark (Århus University, DK)\nProgram Commitee\nConference Chair: Ole Lehrmann Madsen (Århus University, DK) Program Chair: Walter Olthoff (DFKI GmbH, Germany) Organizing Chair: Jørgen Lindskov Knudsen (Århus University, DK) Tutorials: Birger Møller-Pedersen (Norwegian Computing Center, Norway) Workshops: Eric Jul (University of Kopenhagen, Denmark) Panels: Boris Magnusson (Lund University, Sweden) Exhibition: Elmer Sandvad (Århus University, DK) Demonstrations: Kurt Nørdmark (Århus University, DK)\nReferees\nV. Andreev Bärwolff E. Barrelet H.P. Beck G. Bernardi E. Binder P.C. Bosetti\nBraunschweig F.W. Büsser T. Carli A.B. Clegg G. Cozzika S. Dagoret Del Buono\nP. Dingus H. Duhm J. Ebert S. Eichenberger R.J. Ellison Feltesse W. Flauger\nIII\nA. Fomenko G. Franke J. Garvey M. Gennis L. Goerlich P. Goritchev H. Greif E.M. Hanlon R. Haydar R.C.W. Henderso P. Hill H. Hufnagel A. Jacholkowska Johannsen S. Kasarian I.R. Kenyon C. Kleinwort T. Köhler S.D. Kolya P. Kostka\nU. Krüger J. Kurzhöfer M.P.J. Landon A. Lebedev Ch. Ley F. Linsel H. Lohmand Martin S. Masson K. Meier C.A. Meyer S. Mikocki J.V. Morris B. Naroska Nguyen U. Obrock G.D. Patel Ch. Pichler S. Prell F. Raupach\nV. Riech P. Robmann N. Sahlmann P. Schleper Schöning B. Schwab A. Semenov G. Siegmon J.R. Smith M. Steenbock U. Straumann C. Thiebaux P. Van Esch from Yerevan Ph L.R. West G.-G. Winter T.P. Yiou M. Zimmer\nSponsoring Institutions\nBernauer-Budiman Inc., Reading, Mass. The Hofmann-International Company, San Louis Obispo, Cal. Kramer Industries, Heidelberg, Germany\nTable of Contents\nHamiltonian Mechanics\nHamiltonian Mechanics unter besonderer Berücksichtigung der höhreren Lehranstalten . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1\nIvar Ekeland, Roger Temam, Jeffrey Dean, David Grove, Craig Chambers, Kim B. Bruce, and Elisa Bertino\nHamiltonian Mechanics2 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 7 Ivar Ekeland and Roger Temam\nAuthor Index . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 13\nSubject Index . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 17\nHamiltonian Mechanics unter besonderer\nBerücksichtigung der höhreren Lehranstalten\nIvar Ekeland1, Roger Temam2 Jeffrey Dean, David Grove, Craig Chambers, Kim B. Bruce, and Elsa Bertino\n1 Princeton University, Princeton NJ 08544, USA, I.Ekeland@princeton.edu,\nWWW home page: http://users/~iekeland/web/welcome.html 2 Université de Paris-Sud, Laboratoire d’Analyse Numérique, Bâtiment 425,\nF-91405 Orsay Cedex, France\nAbstract. The abstract should summarize the contents of the paper using at least 70 and at most 150 words. It will be set in 9-point font size and be inset 1.0 cm from the right and left margins. There will be two blank lines before and after the Abstract. . . .\nKeywords: computational geometry, graph theory, Hamilton cycles"
    }, {
      "heading" : "1 Fixed-Period Problems: The Sublinear Case",
      "text" : "With this chapter, the preliminaries are over, and we begin the search for periodic solutions to Hamiltonian systems. All this will be done in the convex case; that is, we shall study the boundary-value problem\nẋ = JH ′(t, x)\nx(0) = x(T )\nwith H(t, ·) a convex function of x, going to +∞ when ‖x‖ → ∞."
    }, {
      "heading" : "1.1 Autonomous Systems",
      "text" : "In this section, we will consider the case when the Hamiltonian H(x) is autonomous. For the sake of simplicity, we shall also assume that it is C1.\nWe shall first consider the question of nontriviality, within the general framework of (A∞, B∞)-subquadratic Hamiltonians. In the second subsection, we shall look into the special case when H is (0, b∞)-subquadratic, and we shall try to derive additional information.\nThe General Case: Nontriviality. We assume that H is (A∞, B∞)-subquadratic at infinity, for some constant symmetric matrices A∞ and B∞, with B∞ −A∞ positive definite. Set:\nγ : = smallest eigenvalue of B∞ −A∞ (1) λ : = largest negative eigenvalue of J d\ndt +A∞ . (2)\n2 Theorem 1 tells us that if λ+ γ < 0, the boundary-value problem:\nẋ = JH ′(x) x(0) = x(T )\n(3)\nhas at least one solution x, which is found by minimizing the dual action functional:\nψ(u) =\n∫ T\no\n[ 1\n2\n( Λ−1o u, u ) +N∗(−u) ] dt (4)\non the range of Λ, which is a subspace R(Λ)2L with finite codimension. Here\nN(x) := H(x)− 1\n2 (A∞x, x) (5)\nis a convex function, and\nN(x) ≤ 1\n2 ((B∞ −A∞)x, x) + c ∀x . (6)\nProposition 1. Assume H ′(0) = 0 and H(0) = 0. Set:\nδ := lim inf x→0\n2N(x) ‖x‖−2 . (7)\nIf γ < −λ < δ, the solution u is non-zero:\nx(t) 6= 0 ∀t . (8)\nProof. Condition (7) means that, for every δ′ > δ, there is some ε > 0 such that\n‖x‖ ≤ ε⇒ N(x) ≤ δ′\n2 ‖x‖2 . (9)\nIt is an exercise in convex analysis, into which we shall not go, to show that this implies that there is an η > 0 such that\n3 Since u1 is a smooth function, we will have ‖hu1‖∞ ≤ η for h small enough, and inequality (10) will hold, yielding thereby:\nψ(hu1) ≤ h2\n2\n1 λ ‖u1‖ 2 2 + h2 2 1 δ′ ‖u1‖ 2 . (11)\nIf we choose δ′ close enough to δ, the quantity ( 1\nλ + 1 δ′\n) will be negative, and\nwe end up with ψ(hu1) < 0 for h 6= 0 small . (12)\nOn the other hand, we check directly that ψ(0) = 0. This shows that 0 cannot be a minimizer of ψ, not even a local one. So u 6= 0 and u 6= Λ−1o (0) = 0. ⊓⊔\nCorollary 1. Assume H is C2 and (a∞, b∞)-subquadratic at infinity. Let ξ1, . . . , ξN be the equilibria, that is, the solutions of H\n′(ξ) = 0. Denote by ωk the smallest eigenvalue of H ′′ (ξk), and set:\nω := Min {ω1, . . . , ωk} . (13)\nIf: T\n2π b∞ < −E\n[ − T\n2π a∞\n] < T\n2π ω (14)\nthen minimization of ψ yields a non-constant T -periodic solution x.\nWe recall once more that by the integer part E[α] of α ∈ IR, we mean the a ∈ ZZ such that a < α ≤ a + 1. For instance, if we take a∞ = 0, Corollary 2 tells us that x exists and is non-constant provided that:\nT 2π b∞ < 1 < T 2π (15)\nor\nT ∈\n( 2π\nω , 2π\nb∞\n) . (16)\nProof. The spectrum of Λ is 2πT ZZ + a∞. The largest negative eigenvalue λ is given by 2πT ko + a∞, where\n2π T ko + a∞ < 0 ≤ 2π T (ko + 1) + a∞ . (17)\nHence:\nko = E\n[ − T\n2π a∞\n] . (18)\nThe condition γ < −λ < δ now becomes:\nb∞ − a∞ < − 2π\nT ko − a∞ < ω − a∞ (19)\nwhich is precisely condition (14). ⊓⊔\n4 Lemma 1. Assume that H is C2 on IR2n\\{0} and that H ′′(x) is non-degenerate for any x 6= 0. Then any local minimizer x̃ of ψ has minimal period T .\nProof. We know that x̃, or x̃ + ξ for some constant ξ ∈ IR2n, is a T -periodic solution of the Hamiltonian system:\nẋ = JH ′(x) . (20)\nThere is no loss of generality in taking ξ = 0. So ψ(x) ≥ ψ(x̃) for all x̃ in some neighbourhood of x in W 1,2 ( IR/TZZ; IR2n ) .\nBut this index is precisely the index iT (x̃) of the T -periodic solution x̃ over the interval (0, T ), as defined in Sect. 2.6. So\niT (x̃) = 0 . (21)\nNow if x̃ has a lower period, T/k say, we would have, by Corollary 31:\niT (x̃) = ikT/k(x̃) ≥ kiT/k(x̃) + k − 1 ≥ k − 1 ≥ 1 . (22)\nThis would contradict (21), and thus cannot happen. ⊓⊔\nNotes and Comments. The results in this section are a refined version of [1]; the minimality result of Proposition 14 was the first of its kind.\nTo understand the nontriviality conditions, such as the one in formula (16), one may think of a one-parameter family xT , T ∈ ( 2πω−1, 2πb−1\n∞\n) of periodic\nsolutions, xT (0) = xT (T ), with xT going away to infinity when T → 2πω−1, which is the period of the linearized system at 0.\nTheorem 1 (Ghoussoub-Preiss). Assume H(t, x) is (0, ε)-subquadratic at infinity for all ε > 0, and T -periodic in t\nH(t, ·) is convex ∀t (23)\nH(·, x) is T−periodic ∀x (24)\nH(t, x) ≥ n (‖x‖) with n(s)s−1 → ∞ as s→ ∞ (25)\n5 ∀ε > 0 , ∃c : H(t, x) ≤ ε\n2 ‖x‖2 + c . (26)\nAssume also that H is C2, and H ′′(t, x) is positive definite everywhere. Then there is a sequence xk, k ∈ IN, of kT -periodic solutions of the system\nẋ = JH ′(t, x) (27)\nsuch that, for every k ∈ IN, there is some po ∈ IN with:\np ≥ po ⇒ xpk 6= xk . (28)\n⊓⊔\nExample 1 (External forcing). Consider the system:\nẋ = JH ′(x) + f(t) (29)\nwhere the Hamiltonian H is (0, b∞)-subquadratic, and the forcing term is a distribution on the circle:\nf = d\ndt F + fo with F ∈ L\n2 ( IR/TZZ; IR2n ) , (30)\nwhere fo := T −1 ∫ T o f(t)dt. For instance,\nf(t) = ∑\nk∈IN\nδkξ , (31)\nwhere δk is the Dirac mass at t = k and ξ ∈ IR 2n is a constant, fits the prescription. This means that the system ẋ = JH ′(x) is being excited by a series of identical shocks at interval T .\nDefinition 1. Let A∞(t) and B∞(t) be symmetric operators in IR 2n, depending continuously on t ∈ [0, T ], such that A∞(t) ≤ B∞(t) for all t. A Borelian function H : [0, T ]× IR2n → IR is called (A∞, B∞)-subquadratic at infinity if there exists a function N(t, x) such that:\nH(t, x) = 1\n2 (A∞(t)x, x) +N(t, x) (32)\n∀t , N(t, x) is convex with respect to x (33)\nN(t, x) ≥ n (‖x‖) with n(s)s−1 → +∞ as s→ +∞ (34)\n∃c ∈ IR : H(t, x) ≤ 1\n2 (B∞(t)x, x) + c ∀x . (35)\nIf A∞(t) = a∞I and B∞(t) = b∞I, with a∞ ≤ b∞ ∈ IR, we shall say that H is (a∞, b∞)-subquadratic at infinity. As an example, the function ‖x‖ α , with 1 ≤ α < 2, is (0, ε)-subquadratic at infinity for every ε > 0. Similarly, the Hamiltonian\nH(t, x) = 1\n2 k ‖k‖2 + ‖x‖α (36)\nis (k, k + ε)-subquadratic for every ε > 0. Note that, if k < 0, it is not convex.\n6 Notes and Comments. The first results on subharmonics were obtained by Rabinowitz in [5], who showed the existence of infinitely many subharmonics both in the subquadratic and superquadratic case, with suitable growth conditions on H ′. Again the duality approach enabled Clarke and Ekeland in [2] to treat the same problem in the convex-subquadratic case, with growth conditions on H only.\nRecently, Michalek and Tarantello (see [3] and [4]) have obtained lower bound on the number of subharmonics of period kT , based on symmetry considerations and on pinching estimates, as in Sect. 5.2 of this article."
    }, {
      "heading" : "1 Fixed-Period Problems: The Sublinear Case",
      "text" : "With this chapter, the preliminaries are over, and we begin the search for periodic solutions to Hamiltonian systems. All this will be done in the convex case; that is, we shall study the boundary-value problem\nẋ = JH ′(t, x)\nx(0) = x(T )\nwith H(t, ·) a convex function of x, going to +∞ when ‖x‖ → ∞."
    }, {
      "heading" : "1.1 Autonomous Systems",
      "text" : "In this section, we will consider the case when the Hamiltonian H(x) is autonomous. For the sake of simplicity, we shall also assume that it is C1.\nWe shall first consider the question of nontriviality, within the general framework of (A∞, B∞)-subquadratic Hamiltonians. In the second subsection, we shall look into the special case when H is (0, b∞)-subquadratic, and we shall try to derive additional information.\nThe General Case: Nontriviality. We assume that H is (A∞, B∞)-subquadratic at infinity, for some constant symmetric matrices A∞ and B∞, with B∞ −A∞ positive definite. Set:\nγ : = smallest eigenvalue of B∞ −A∞ (1) λ : = largest negative eigenvalue of J d\ndt +A∞ . (2)\n8 Theorem 21 tells us that if λ+ γ < 0, the boundary-value problem:\nẋ = JH ′(x) x(0) = x(T )\n(3)\nhas at least one solution x, which is found by minimizing the dual action functional:\nψ(u) =\n∫ T\no\n[ 1\n2\n( Λ−1o u, u ) +N∗(−u) ] dt (4)\non the range of Λ, which is a subspace R(Λ)2L with finite codimension. Here\nN(x) := H(x)− 1\n2 (A∞x, x) (5)\nis a convex function, and\nN(x) ≤ 1\n2 ((B∞ −A∞)x, x) + c ∀x . (6)\nProposition 1. Assume H ′(0) = 0 and H(0) = 0. Set:\nδ := lim inf x→0\n2N(x) ‖x‖−2 . (7)\nIf γ < −λ < δ, the solution u is non-zero:\nx(t) 6= 0 ∀t . (8)\nProof. Condition (7) means that, for every δ′ > δ, there is some ε > 0 such that\n‖x‖ ≤ ε⇒ N(x) ≤ δ′\n2 ‖x‖2 . (9)\nIt is an exercise in convex analysis, into which we shall not go, to show that this implies that there is an η > 0 such that\n9 Since u1 is a smooth function, we will have ‖hu1‖∞ ≤ η for h small enough, and inequality (10) will hold, yielding thereby:\nψ(hu1) ≤ h2\n2\n1 λ ‖u1‖ 2 2 + h2 2 1 δ′ ‖u1‖ 2 . (11)\nIf we choose δ′ close enough to δ, the quantity ( 1\nλ + 1 δ′\n) will be negative, and\nwe end up with ψ(hu1) < 0 for h 6= 0 small . (12)\nOn the other hand, we check directly that ψ(0) = 0. This shows that 0 cannot be a minimizer of ψ, not even a local one. So u 6= 0 and u 6= Λ−1o (0) = 0. ⊓⊔\nCorollary 1. Assume H is C2 and (a∞, b∞)-subquadratic at infinity. Let ξ1, . . . , ξN be the equilibria, that is, the solutions of H\n′(ξ) = 0. Denote by ωk the smallest eigenvalue of H ′′ (ξk), and set:\nω := Min {ω1, . . . , ωk} . (13)\nIf: T\n2π b∞ < −E\n[ − T\n2π a∞\n] < T\n2π ω (14)\nthen minimization of ψ yields a non-constant T -periodic solution x.\nWe recall once more that by the integer part E[α] of α ∈ IR, we mean the a ∈ ZZ such that a < α ≤ a + 1. For instance, if we take a∞ = 0, Corollary 2 tells us that x exists and is non-constant provided that:\nT 2π b∞ < 1 < T 2π (15)\nor\nT ∈\n( 2π\nω , 2π\nb∞\n) . (16)\nProof. The spectrum of Λ is 2πT ZZ + a∞. The largest negative eigenvalue λ is given by 2πT ko + a∞, where\n2π T ko + a∞ < 0 ≤ 2π T (ko + 1) + a∞ . (17)\nHence:\nko = E\n[ − T\n2π a∞\n] . (18)\nThe condition γ < −λ < δ now becomes:\nb∞ − a∞ < − 2π\nT ko − a∞ < ω − a∞ (19)\nwhich is precisely condition (14). ⊓⊔\n10\nLemma 1. Assume that H is C2 on IR2n\\{0} and that H ′′(x) is non-degenerate for any x 6= 0. Then any local minimizer x̃ of ψ has minimal period T .\nProof. We know that x̃, or x̃ + ξ for some constant ξ ∈ IR2n, is a T -periodic solution of the Hamiltonian system:\nẋ = JH ′(x) . (20)\nThere is no loss of generality in taking ξ = 0. So ψ(x) ≥ ψ(x̃) for all x̃ in some neighbourhood of x in W 1,2 ( IR/TZZ; IR2n ) .\nBut this index is precisely the index iT (x̃) of the T -periodic solution x̃ over the interval (0, T ), as defined in Sect. 2.6. So\niT (x̃) = 0 . (21)\nNow if x̃ has a lower period, T/k say, we would have, by Corollary 31:\niT (x̃) = ikT/k(x̃) ≥ kiT/k(x̃) + k − 1 ≥ k − 1 ≥ 1 . (22)\nThis would contradict (21), and thus cannot happen. ⊓⊔\nNotes and Comments. The results in this section are a refined version of 1980; the minimality result of Proposition 14 was the first of its kind.\nTo understand the nontriviality conditions, such as the one in formula (16), one may think of a one-parameter family xT , T ∈ ( 2πω−1, 2πb−1\n∞\n) of periodic\nsolutions, xT (0) = xT (T ), with xT going away to infinity when T → 2πω−1, which is the period of the linearized system at 0.\nTheorem 1 (Ghoussoub-Preiss). Assume H(t, x) is (0, ε)-subquadratic at infinity for all ε > 0, and T -periodic in t\nH(t, ·) is convex ∀t (23)\nH(·, x) is T−periodic ∀x (24)\nH(t, x) ≥ n (‖x‖) with n(s)s−1 → ∞ as s→ ∞ (25)\n11\n∀ε > 0 , ∃c : H(t, x) ≤ ε\n2 ‖x‖2 + c . (26)\nAssume also that H is C2, and H ′′(t, x) is positive definite everywhere. Then there is a sequence xk, k ∈ IN, of kT -periodic solutions of the system\nẋ = JH ′(t, x) (27)\nsuch that, for every k ∈ IN, there is some po ∈ IN with:\np ≥ po ⇒ xpk 6= xk . (28)\n⊓⊔\nExample 1 (External forcing). Consider the system:\nẋ = JH ′(x) + f(t) (29)\nwhere the Hamiltonian H is (0, b∞)-subquadratic, and the forcing term is a distribution on the circle:\nf = d\ndt F + fo with F ∈ L\n2 ( IR/TZZ; IR2n ) , (30)\nwhere fo := T −1 ∫ T o f(t)dt. For instance,\nf(t) = ∑\nk∈IN\nδkξ , (31)\nwhere δk is the Dirac mass at t = k and ξ ∈ IR 2n is a constant, fits the prescription. This means that the system ẋ = JH ′(x) is being excited by a series of identical shocks at interval T .\nDefinition 1. Let A∞(t) and B∞(t) be symmetric operators in IR 2n, depending continuously on t ∈ [0, T ], such that A∞(t) ≤ B∞(t) for all t. A Borelian function H : [0, T ]× IR2n → IR is called (A∞, B∞)-subquadratic at infinity if there exists a function N(t, x) such that:\nH(t, x) = 1\n2 (A∞(t)x, x) +N(t, x) (32)\n∀t , N(t, x) is convex with respect to x (33)\nN(t, x) ≥ n (‖x‖) with n(s)s−1 → +∞ as s→ +∞ (34)\n∃c ∈ IR : H(t, x) ≤ 1\n2 (B∞(t)x, x) + c ∀x . (35)\nIf A∞(t) = a∞I and B∞(t) = b∞I, with a∞ ≤ b∞ ∈ IR, we shall say that H is (a∞, b∞)-subquadratic at infinity. As an example, the function ‖x‖ α , with 1 ≤ α < 2, is (0, ε)-subquadratic at infinity for every ε > 0. Similarly, the Hamiltonian\nH(t, x) = 1\n2 k ‖k‖2 + ‖x‖α (36)\nis (k, k + ε)-subquadratic for every ε > 0. Note that, if k < 0, it is not convex.\n12\nNotes and Comments. The first results on subharmonics were obtained by Rabinowitz in 1985, who showed the existence of infinitely many subharmonics both in the subquadratic and superquadratic case, with suitable growth conditions on H ′. Again the duality approach enabled Clarke and Ekeland in 1981 to treat the same problem in the convex-subquadratic case, with growth conditions on H only.\nRecently, Michalek and Tarantello (see Michalek, R., Tarantello, G. 1982 and Tarantello, G. 1983) have obtained lower bound on the number of subharmonics of period kT , based on symmetry considerations and on pinching estimates, as in Sect. 5.2 of this article."
    } ],
    "references" : [ {
      "title" : "Nonlinear oscillations and boundary-value problems for Hamiltonian systems",
      "author" : [ "F. Clarke", "I. Ekeland" ],
      "venue" : "Arch. Rat. Mech. Anal. 78, 315–333",
      "citeRegEx" : "1",
      "shortCiteRegEx" : null,
      "year" : 1982
    }, {
      "title" : "Solutions périodiques, du période donnée, des équations hamiltoniennes",
      "author" : [ "F. Clarke", "I. Ekeland" ],
      "venue" : "Note CRAS Paris 287, 1013–1015",
      "citeRegEx" : "2",
      "shortCiteRegEx" : null,
      "year" : 1978
    }, {
      "title" : "Subharmonic solutions with prescribed minimal period for nonautonomous Hamiltonian systems",
      "author" : [ "R. Michalek", "G. Tarantello" ],
      "venue" : "J. Diff. Eq. 72, 28–55",
      "citeRegEx" : "3",
      "shortCiteRegEx" : null,
      "year" : 1988
    } ],
    "referenceMentions" : [ {
      "referenceID" : 1,
      "context" : "Muscle segmentation using a continuous region model A region-based segmentation method, proposed in [5], was extended to multi-label segmentation in [2], and applied to skeletal muscle segmentation [1].",
      "startOffset" : 149,
      "endOffset" : 152
    }, {
      "referenceID" : 0,
      "context" : "Muscle segmentation using a continuous region model A region-based segmentation method, proposed in [5], was extended to multi-label segmentation in [2], and applied to skeletal muscle segmentation [1].",
      "startOffset" : 198,
      "endOffset" : 201
    }, {
      "referenceID" : 2,
      "context" : "We refer the reader to [3,11] for details.",
      "startOffset" : 23,
      "endOffset" : 29
    }, {
      "referenceID" : 0,
      "context" : "The results in this section are a refined version of [1]; the minimality result of Proposition 14 was the first of its kind.",
      "startOffset" : 53,
      "endOffset" : 56
    }, {
      "referenceID" : 1,
      "context" : "Again the duality approach enabled Clarke and Ekeland in [2] to treat the same problem in the convex-subquadratic case, with growth conditions on H only.",
      "startOffset" : 57,
      "endOffset" : 60
    }, {
      "referenceID" : 2,
      "context" : "Recently, Michalek and Tarantello (see [3] and [4]) have obtained lower bound on the number of subharmonics of period kT , based on symmetry considerations and on pinching estimates, as in Sect.",
      "startOffset" : 39,
      "endOffset" : 42
    } ],
    "year" : 2013,
    "abstractText" : "The abstract should summarize the contents of the paper using at least 70 and at most 150 words. It will be set in 9-point font size and be inset 1.0 cm from the right and left margins. There will be two blank lines before and after the Abstract. . . .",
    "creator" : "LaTeX with hyperref package"
  }
}