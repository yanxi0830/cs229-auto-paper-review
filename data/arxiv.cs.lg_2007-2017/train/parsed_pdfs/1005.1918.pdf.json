{
  "name" : "1005.1918.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "Prediction with Expert Advice under Discounted Loss",
    "authors" : [ "Alexey Chernov", "Fedor Zhdanov" ],
    "emails" : [ "chernov@cs.rhul.ac.uk", "fedor@cs.rhul.ac.uk" ],
    "sections" : [ {
      "heading" : null,
      "text" : "ar X\niv :1\n00 5.\n19 18\nv2 [\ncs .L\nG ]\n4 J\nWe study prediction with expert advice in the setting where the losses are accumulated with some discounting and the impact of old losses can gradually vanish. We generalize the Aggregating Algorithm and the Aggregating Algorithm for Regression, propose a new variant of exponentially weighted average algorithm, and prove bounds on the cumulative discounted loss."
    }, {
      "heading" : "1 Introduction",
      "text" : "Prediction with expert advice is a framework for online sequence prediction. Predictions are made step by step. The quality of each prediction (the discrepancy between the prediction and the actual outcome) is evaluated by a real number called loss. The losses are accumulated over time. In the standard framework for prediction with expert advice (see the monograph [2] for a comprehensive review), the losses from all steps are just summed. In this paper, we consider a generalization where older losses can be devalued; in other words, we use discounted cumulative loss.\nPredictions are made by Experts and Learner according to Protocol 1. In\nProtocol 1 Prediction with expert advice under general discounting\nL0 := 0. Lθ0 := 0, θ ∈ Θ. for t = 1, 2, . . . do Accountant announces αt−1 ∈ (0, 1]. Experts announce γθt ∈ Γ, θ ∈ Θ. Learner announces γt ∈ Γ. Reality announces ωt ∈ Ω. Lθt := αt−1Lθt−1 + λ(γθt , ωt), θ ∈ Θ. Lt := αt−1Lt−1 + λ(γt, ωt). end for\nthis protocol, Ω is the set of possible outcomes and ω1, ω2, ω3 . . . is the sequence\nto predict; Γ is the set of admissible predictions, and λ : Γ× Ω → [0,∞] is the loss function. The triple (Ω,Γ, λ) specifies the game of prediction. The most common examples are the binary square loss, log loss, and absolute loss games. They have Ω = {0, 1} and Γ = [0, 1], and their loss functions are λsq(γ, ω) = (γ−ω)2, λlog(γ, 0) = − log(1− γ) and λlog(γ, 1) = − log γ, λabs(γ, ω) = |γ−ω|, respectively.\nThe players in the game of prediction are Experts θ from some pool Θ, Learner, and also Accountant and Reality. We are interested in (worst-case optimal) strategies for Learner, and thus the game can be regarded as a twoplayer game, where Learner opposes the other players. The aim of Learner is to keep his total loss Lt small as compared to the total losses Lθt of all experts θ ∈ Θ.\nThe standard protocol of prediction with expert advice (as described in [19, 20]) is a special case of Protocol 1 where Accountant always announces αt = 1, t = 0, 1, 2, . . .. The new setting gives some more freedom to Learner’s opponents.\nAnother important special case is the exponential (geometric) discounting αt = α ∈ (0, 1). Exponential discounting is widely used in finance and economics (see, e. g., [16]), time series analysis (see, e. g., [8]), reinforcement learning [18], and other applications. In the context of prediction with expert advice, Freund and Hsu [6] noted that the discounted loss provides an alternative to “tracking the best expert” framework [11]. Indeed, an exponentially discounted sum depends almost exclusively on the last O(log(1/α)) terms. If the expert with the best one-step performance changes at this rate, then Learner observing the α-discounted losses will mostly follow predictions of the current best expert. Under our more general discounting, more subtle properties of best expert changes may be specified by varying the discount factor. In particular, one can cause Learner to “restart mildly” giving αt = 1 (or αt ≈ 1) most of the time and αt ≪ 1 at crucial moments. (We prohibit αt = 0 in the protocol, since this is exactly the same as the stopping the current game and starting a new, independent game; on the other hand, the assumption αt 6= 0 simplifies some statements.)\nCesa-Bianchi and Lugosi [2, § 2.11] discuss another kind of discounting\nLT =\nT ∑\nt=1\nβT−tlt , (1)\nwhere lt are one-step losses and βt are some decreasing discount factors. To see the difference, let us rewrite our definition in the same style:\nLT = αT−1LT−1 + lT = αT−2αT−1LT−2 + αT−1lT−1 + lT = . . .\n=\nT ∑\nt=1\nαt · · ·αT−1lt = 1\nβT\nT ∑\nt=1\nβtlt , (2)\nwhere βt = 1/α1 · · ·αt−1, β1 = 1. The sequence βt is non-decreasing, β1 ≤ β2 ≤ β3 ≤ . . .; but it is applied “in the reverse order” compared to (1). So, in both definitions, the older losses are the less weight they are ascribed. However, according to (1), the losses lt have different relative weights in LT , LT+1 and so on, whereas (2) fixes the relative weight of lt with respect to all previous losses forever starting from the moment t. The latter property allows us to get uniform\nalgorithms for Learner with loss guarantees that hold for all T = 1, 2, . . .; in contrast, Theorem 2.8 in [2] gives a guarantee only at one moment T chosen in advance. The only kind of discounting that can be expressed both as (1) and as (2) is the exponential discounting ∑T\nt=1 α T−tlt. Under this discounting,\nNormalHedge algorithm is analysed in [6]; we briefly compare the obtained bounds in Section 3.\nLet us say a few words about “economical” interpretation of discounting. Recall that αt ≤ 1 in Protocol 1, in other words, the previous cumulative loss cannot become more important at later steps. If the losses are interpreted as the lost money, it is more natural to assume that the old losses must be multiplied by something greater than 1. Indeed, the money could have been invested and have brought some interest, so the current value of an ancient small loss can be considerably large. Nevertheless, there is a not so artificial interpretation for our discounting model as well. Assume that the loss at each step is expressed as a quantity of some goods, and we pay for them in cash; say, we pay for apples damaged because of our incorrect weather prediction. The price of apples can increase but never decreases. Then βt in (2) is the current price, ∑T t=1 βtlt is the total sum of money we lost, and LT is the quantity of apples that we could have bought now if we had not lost so much money. (We must also assume that we cannot hedge our risk by buying a lot of cheap apples in advance—the apples will rot—and that the bank interest is zero.)\nWe need the condition αt ≤ 1 for our algorithms and loss bounds. However, the case of αt ≥ 1 is no less interesting. We cannot say anything about it and leave it as an open problem, as well as the general case of arbitrary positive αt.\nThe rest of the paper is organized as follows. In Section 2, we propose a generalization of the Aggregating Algorithm [20] and prove the same bound as in [20] but for the discounted loss. In Section 3, we consider convex loss functions and propose an algorithm similar to the Weak Aggregating Algotihm [14] and the exponentially weighted average forecaster with time-varying learning rate [2, § 2.3], with a similar loss bound. In Section 4, we consider the use of prediction with expert advice for the regression problem and adapt the Aggregating Algorithm for Regression [22] (applied to spaces of linear functions and to reproducing kernel Hilbert spaces) to the discounted square loss. All our algorithms are inspired by the methodology of defensive forecasting [4]. We do not explicitly use or refer to this technique in the main text. However, to illustrate these ideas we provide an alternative treatment of the regression task with the help of defensive forecasting in Appendix A.2."
    }, {
      "heading" : "2 Linear Bounds for Learner’s Loss",
      "text" : "In this section, we assume that the set of experts is finite, Θ = {1, . . . ,K}, and show how Learner can achieve a bound of the form Lt ≤ cLkt + (c lnK)/η for all Experts k, where c ≥ 1 and η > 0 are constants. Bounds of this kind were obtained in [19]. Loosely speaking, such a bound holds for certain c and η if and only if the game (Ω,Γ, λ) has the following property:\n∃γ ∈ Γ ∀ω ∈ Ω λ(γ, ω) ≤ − c η ln\n(\n∑\ni∈I\npie −ηλ(γi,ω)\n)\n(3)\nfor any finite index set I, for any γi ∈ Γ, i ∈ I, and for any pi ∈ [0, 1] such that ∑\ni∈I pi = 1. It turns out that this property is sufficient for the discounted case as well.\nTheorem 1. Suppose that the game (Ω,Γ, λ) satisfies condition (3) for certain c ≥ 1 and η > 0. In the game played according to Protocol 1, Learner has a strategy guaranteeing that, for any T and for any k ∈ {1, . . . ,K}, it holds\nLT ≤ cLkT + c lnK\nη . (4)\nWe formulate the strategy for Learner in Subsection 2.1 and prove the theorem in Subsection 2.2.\nFor the standard undiscounted case (Accountant announces αt = 1 at each step t), this theorem was proved by Vovk in [19] with the help of the Aggregating Algorithm (AA) as Learner’s strategy. It is known ([10, 20]) that this bound is asymptotically optimal for large pools of Experts (for games satisfying some assumptions): if the game does not satisfy (3) for some c ≥ 1 and η > 0, then, for sufficiently large K, there is a strategy for Experts and Reality (recall that Accountant always says αt = 1) such that Learner cannot secure (4). For the special case of c = 1, bound (4) is tight for any fixedK as well [21]. These results imply optimality of Theorem 1 in the new setting with general discounting (when we allow arbitrary behaviour of Accountant with the only requirement αt ∈ (0, 1]). However, they leave open the question of lower bounds under different discounting assumptions (that is, when Accountant moves are fixed); a particularly interesting case is the exponential discounting αt = α ∈ (0, 1)."
    }, {
      "heading" : "2.1 Learner’s Strategy",
      "text" : "To prove Theorem 1, we will exploit the AA with a minor modification.\nAlgorithm 1 The Aggregating Algorithm\n1: Initialize weights of Experts wk0 := 1/K, k = 1, . . . ,K. 2: for t = 1, 2, . . . do 3: Get Experts’ predictions γkt ∈ Γ, k = 1, . . . ,K. 4: Calculate gt(ω) = − cη ln ( ∑K k=1 w k t−1e −ηλ(γkt ,ω) )\n, for all ω ∈ Ω. 5: Output γt := σ(gt) ∈ Γ. 6: Get ωt ∈ Ω. 7: Update the weights w̃kt := w k t−1e −ηλ(γkt ,ωt), k = 1, . . . ,K, 8: and normalize them wkt := w̃ k t / ∑K k=1 w̃ k t , k = 1, . . . ,K. 9: end for.\nThe pseudocode of the AA is given as Algorithm 1. The algorithm has three parameters, which depend on the game (Ω,Γ, λ): c ≥ 1, η > 0, and a function σ : RΩ → Γ. The function σ is called a substitution function and must have the following property: λ(σ(g), ω) ≤ g(ω) for all ω ∈ Ω if for g ∈ RΩ there exists any γ ∈ Γ such that λ(γ, ω) ≤ g(ω) for all ω ∈ Ω. A natural example of substitution function is given by\nσ(g) = argmin γ∈Γ\n( λ(γ, ω)− g(ω) )\n(5)\n(if the minimum is attained at several points, one can take any of them). An advantage of this σ is that the normalization step in line 8 is not necessary and one can take wkt = w̃ k t . Indeed, multiplying all w k t by a constant (independent of k) we add to all gt(ω) a constant (independent of ω), and σ(gt) does not change.\nThe Aggregating Algorithm with Discounting (AAD) differs only by the use of the weights in the computation of gt and the update of the weights.\nThe pseudocode of the AAD is given as Algorithm 2.\nAlgorithm 2 The Aggregating Algorithm with Discounting\n1: Initialize weights of Experts wk0 := 1, k = 1, . . . ,K. 2: for t = 1, 2, . . . do 3: Get discount αt−1 ∈ (0, 1]. 4: Get Experts’ predictions γkt ∈ Γ, k = 1, . . . ,K. 5: Calculate gt(ω) = − cη ( ln ∑K k=1 1 K (w k t−1) αt−1e−ηλ(γ k t ,ω) )\n, for all ω ∈ Ω. 6: Output γt := σ(gt) ∈ Γ. 7: Get ωt ∈ Ω. 8: Update the weights wkt := (w k t−1) αt−1eηλ(γt,ωt)/c−ηλ(γ k t ,ωt), k = 1, . . . ,K, 9: end for.\nFor a substitution function satisfying (5), one can use in line 8 the update\nrule wkt := (w k t−1) αt−1e−ηλ(γ k t ,ωt), which does not contain Learner’s losses, in the same manner as the normalization in Algorithm 1 can be omitted."
    }, {
      "heading" : "2.2 Proof of the Bound",
      "text" : "Assume that c and η are such that condition (3) holds for the game. Let us show that Algorithm 2 preserves the following condition:\nK ∑\nk=1\n1\nK wkt ≤ 1 . (6)\nCondition (6) trivially holds for t = 0. Assume that (6) holds for t− 1, that is, ∑K\nk=1 w k t−1/K ≤ 1. Thus, we have\nK ∑\nk=1\n1\nK (wkt−1)\nαt−1 ≤ ( K ∑\nk=1\n1\nK wkt−1\n)αt−1\n≤ 1 ,\nsince the function x 7→ xα is concave for α ∈ (0, 1], x ≥ 0, and since x ≤ 1 implies xα ≤ 1 for α ≥ 0 and x ≥ 0.\nLet w̃k be any reals such that w̃k ≥ (wkt−1)αt−1/K and ∑K k=1 w̃ k = 1. Due\nto condition (3) there exists γ ∈ Γ such that for all ω ∈ Ω\nλ(γ, ω) ≤ − c η ln\n(\nK ∑\nk=1\nw̃ke−ηλ(γ k t ,ω)\n)\n≤ − c η ln\n(\nK ∑\nk=1\n1\nK (wkt−1) αt−1e−ηλ(γ k t ,ω)\n)\n= gt(ω)\n(the second inequality holds due to our choice of w̃k). Thus, due to the property of σ, we have λ(γt, ω) ≤ gt(ω) for all ω ∈ Ω. In particular, this holds for ω = ωt, and we get\nλ(γt, ωt) ≤ − c\nη ln\n(\nK ∑\nk=1\n1\nK (wkt−1) αt−1e−ηλ(γ k t ,ωt)\n)\n,\nwhich is equivalent to (6). To get the loss bound (4), it remains to note that\nlnwkt = η ( Lt/c− Lkt ) .\nIndeed, for t = 0, this is trivial. If this holds for wkt−1, then\nlnwkt = αt−1 ln(w k t−1) + ηλ(γt, ωt)/c− ηλ(γkt , ωt)\n= αt−1η ( Lt−1/c− Lkt−1 ) + ηλ(γt, ωt)/c− ηλ(γkt , ωt) = η (\n(αt−1Lt−1 + λ(γt, ωt))/c− (αt−1Lkt−1 + λ(γkt , ωt)) ) = η ( Lt/c− Lkt )\nand we get the equality for wkt . Thus, condition (6) means that\nK ∑\nk=1\n1\nK eη(Lt/c−L k t ) ≤ 1 , (7)\nand (4) follows by lower-bounding the sum by any of its terms.\nRemark. Everything in this section remains valid, if we replace the equal initial Experts’ weights 1/K by arbitrary non-negative weights wk,\n∑K k=1 w k = 1. This leads to a variant of (4), where the last additive term is replaced by cη ln 1 wk\n. Additionally, we can consider any measurable space Θ of Experts and a nonnegative weight function w(θ), and replace sums over K by integrals over Θ. Then the algorithm and its analysis remain valid (if we impose natural integrability conditions on Experts’ predictions γθt ; see [22] for more detailed discussion)—this will be used in Section 4."
    }, {
      "heading" : "3 Learner’s Loss in Bounded Convex Games",
      "text" : "The linear bounds of the form (4) are perfect when c = 1. However, for many games (for example, the absolute loss game), condition (3) does not hold for c = 1 (with any η > 0), and one cannot get a bound of the form Lt ≤ Lkt +O(1). Since Experts’ losses LθT may grow as T in the worst case, any bound with c > 1 only guarantees that Learner’s loss may exceed an Expert’s loss by at mostO(T ). However, for a large class of interesting games (including the absolute loss game), one can obtain guarantees of the form LT ≤ LkT + O( √ T ) in the undiscounted case. In this section, we prove an analogous result for the discounted setting. A game (Ω,Γ, λ) is non-empty if Ω and Γ are non-empty. The game is called bounded if L = maxω,γ λ(γ, ω) < ∞. One may assume that L = 1 (if not, consider the scaled loss function λ/L). The game is called convex if\nfor any predictions γ1, . . . , γM ∈ Γ and for any weights p1, . . . , pM ∈ [0, 1], ∑M\nm=1 pm = 1,\n∃γ ∈ Γ ∀ω ∈ Ω λ(γ, ω) ≤ M ∑\nm=1\npmλ(γm, ω) . (8)\nNote that if Γ is a convex set (e. g., Γ = [0, 1]) and λ(γ, ω) is convex in γ (e. g.,λabs), then the game is convex.\nTheorem 2. Suppose that (Ω,Γ, λ) is a non-empty convex game, and λ(γ, ω) ∈ [0, 1] for all γ ∈ Γ and ω ∈ Ω. In the game played according to Protocol 1, Learner has a strategy guaranteeing that, for any T and for any k ∈ {1, . . . ,K}, it holds\nLT ≤ LkT + √ lnK\n√\nBT βT , (9)\nwhere βt = 1/(α1 · · ·αt−1) and BT = ∑T t=1 βt.\nNote that BT /βT is the maximal predictors’ loss, which incurs when the predictor suffers the maximal possible loss lt = 1 at each step.\nIn the undiscounted case, αt = 1, thus βt = 1, BT = T , and (9) becomes\nLT ≤ LkT + √ T lnK .\nA similar bound (but with worse constant √ 2 instead of 1 before √ T lnK) is obtained in [2, Theorem 2.3]:\nLT ≤ LkT + √ 2T lnK + √ lnK\n8 .\nFor the exponential discounting αt = α, we have βt = α −t+1 and BT =\n(1− α−T )/(1− 1/α), and (9) transforms into\nLT ≤ LkT + √ lnK\n√\n1− αT 1− α ≤ L k T +\n√\nlnK\n1− α .\nA similar bound (with worse constants) is obtained in [6] for NormalHedge:\nLT ≤ LkT + √ 8 ln 2.32K\n1− α .\nThe NormalHedge algorithm has an important advantage: it can guarantee the last bound without knowledge of the number of experts K (see [3] for a precise definition). We can achieve the same with the help of a more complicated algorithm but at the price of a worse bound (Theorem 3)."
    }, {
      "heading" : "3.1 Learner’s Strategy for Theorem 2",
      "text" : "The pseudocode of Learner’s strategy is given as Algorithm 3. It contains a constant a > 0, which we will choose later in the proof.\nThe algorithm is not fully specified, since lines 6–7 of Algorithm 3 allow arbitrary choice of γ satisfying the inequality. The algorithm can be completed\nwith the help of a substitution function σ as in Algorithm 2, so that lines 6–8 are replaced by\ngt(ω) = − 1\nηt ln\n(\nK ∑\nk=1\n1\nK\n( wkt−1 )αt−1ηt/ηt−1 e−ηtλ(γ k t ,ω)−η 2 t /8\n)\nand γt = σ(gt). However, the current form of Algorithm 3 emphasizes the similarity to the Algorithm 5, which is described later (Subsection 3.3) but actually inspired our analysis.\nAlgorithm 3 Learner’s Strategy for Convex Games\n1: Initialize weights of Experts wk0 := 1, k = 1, . . . ,K. Set β1 = 1, B0 = 0. 2: for t = 1, 2, . . . do 3: Get discount αt−1 ∈ (0, 1]; update βt = βt−1/αt−1, Bt = Bt−1 + βt. 4: Compute ηt = a √\nβt/Bt. 5: Get Experts’ predictions γkt ∈ Γ, k = 1, . . . ,K. 6: Find γ ∈ Γ s.t. for all ω ∈ Ω 7: λ(γ, ω) ≤ − 1ηt ln ( ∑K k=1 1 K ( wkt−1 )αt−1ηt/ηt−1 e−ηtλ(γ k t ,ω)−η 2 t /8 ) 8: Output γt := γ. 9: Get ωt ∈ Ω.\n10: Update the weights wkt := ( wkt−1 )αt−1ηt/ηt−1\neηt ( λ(γt,ωt)−λ(γ k t ,ωt) )\n−η2t /8, 11: k = 1, . . . ,K, 12: end for.\nLet us explain the relation of Algorithm 3 to the Weak Aggregating Algorithm [14] and the exponentially weighted average forecaster with time-varying learning rate [2, § 2.3]. To this end, consider Algorithm 4.\nAlgorithm 4 Weak Aggregating Algorithm with Discounting\n1: Initialize Experts’ cumulative losses Lk0 := 0, k = 1, . . . ,K. Set β1 = 1, B0 = 0. 2: for t = 1, 2, . . . do 3: Get discount αt−1 ∈ (0, 1]; update βt = βt−1/αt−1, Bt = Bt−1 + βt. 4: Compute ηt = a √ βt/Bt. 5: Compute the weights qkt = e −αt−1ηtL k t−1 , k = 1, . . . ,K. 6: Compute the normalized weights w̃kt = q k t / ∑K j=1 q j t . 7: Get Experts’ predictions γkt ∈ Γ, k = 1, . . . ,K. 8: Find γ ∈ Γ s.t. for all ω ∈ Ω λ(γ, ω) ≤ ∑Kk=1 w̃kt λ(γkt , ω). 9: Output γt := γ.\n10: Get ωt ∈ Ω. 11: Update Lkt := αt−1Lkt−1 + λ(γkt , ωt), k = 1, . . . ,K. 12: end for.\nThe proof of Theorem 2 implies that Algorithm 4 is a special case of Al-\ngorithm 3. Indeed, (15) implies that wkt−1 = e −ηt−1L k t−1+C , where C does not depend on k and wkt−1 are the weights from Algorithm 3. Therefore q k t =\nC′(wkt−1) αt−1ηt/ηt−1 , where C′ does not depend on k, and one can take w̃kt for w̃k in the proof of Theorem 2. Thus, if Algorithm 4 output some γt then Algorithm 3 can output this γt as well.\nRecall that if αt = 1 for all t (the undiscounted case), βt = 1 and Bt = t, hence ηt = a/ √ t. In this case, Algorithm 4 is just the Weak Aggregating Algorithm as described in [14]. Consider now the case when Γ is a convex set and λ(γ, ω) is convex in γ. Then one can take γt = ∑K k=1 w̃ k t γ k t in Algorithm 4. For αt = 1, we get exactly the exponentially weighted average forecaster with time-varying learning rate [2, § 2.3]."
    }, {
      "heading" : "3.2 Proof of Theorem 2",
      "text" : "Similarly to the case of the AAD, let us show that Algorithm 3 always can find γ in lines 6–7 and preserves the following condition:\nK ∑\nk=1\n1\nK wkt ≤ 1 . (10)\nFirst check that αt−1ηt/ηt−1 ≤ 1. Indeed, αt−1 = βt−1/βt, and thus\nαt−1 ηt\nηt−1 = βt−1 βt\na √\nβt/Bt\na √ βt−1/Bt−1 =\n√\nβt−1 βt Bt−1 Bt = √ αt−1\n√\nBt−1 Bt−1 + βt ≤ 1 .\n(11) Condition (10) trivially holds for t = 0. Assume that (10) holds for t − 1,\nthat is, ∑K k=1 w k t−1/K ≤ 1. Thus, we have\nK ∑\nk=1\n1\nK (wkt−1)\nαt−1ηt/ηt−1 ≤ ( K ∑\nk=1\n1\nK wkt−1\n)αt−1ηt/ηt−1\n≤ 1 , (12)\nsince the function x 7→ xα is concave for α ∈ (0, 1], x ≥ 0, and since x ≤ 1 implies xα ≤ 1 for α ≥ 0 and x ≥ 0.\nLet w̃k be any reals such that w̃k ≥ (wkt−1)αt−1ηt/ηt−1/K and ∑K k=1 w̃ k = 1.\n(For example, w̃k = (wkt−1) αt−1ηt/ηt−1\n/\n∑K j=1(w j t−1) αt−1ηt/ηt−1 .) By the Ho-\neffding inequality (see, e. g., [2, Lemma 2.2]), we have\nln K ∑\nk=1\nw̃ke−ηtλ(γ k t ,ω) ≤ −ηt\nK ∑\nk=1\nw̃kλ(γkt , ω) + η2t 8 , (13)\nsince λ(γ, ω) ∈ [0, 1] for any γ ∈ Γ and ω ∈ Ω. Since the game is convex, there exists γ ∈ Γ such that λ(γ, ω) ≤ ∑Kk=1 w̃kλ(γkt , ω) for all ω ∈ Ω. For this γ and for all ω ∈ Ω we have\nλ(γ, ω) ≤ K ∑\nk=1\nw̃kλ(γkt , ω) ≤ − 1\nηt ln\n(\nK ∑\nk=1\nw̃ke−ηλ(γ k t ,ω)−η 2 t /8\n)\n≤ − 1 ηt ln\n(\n∑ 1\nK\n( wkt−1 )αt−1ηt/ηt−1 e−ηtλ(γ k t ,ω)−η 2 t /8\n)\n(14)\n(the second inequality follows from (13), and the third inequality holds due to our choice of w̃k). Thus, one can always find γ in lines 6–7 of Algorithm 3. It remains to note that the inequality in line 7 with γt substituted for γ and ωt substituted for ω is equivalent to\n1 ≥ ∑ 1\nK\n( wkt−1 )αt−1ηt/ηt−1 eηtλ(γt,ωt)−ηtλ(γ k t ,ωt)−η 2 t /8 =\n∑ 1\nK wkt .\nNow let us check that\nlnwkt = ηt ( Lt − Lkt ) − ηt 8βt\nt ∑\nτ=1\nβτητ . (15)\nIndeed, for t = 0, this is trivial. Assume that it holds for wkt−1. Then, taking the logarithm of the update expression in line 10 of Algorithm 3 and substituting lnwkt−1, we get\nlnwkt = αt−1ηt ηt−1 lnwkt−1 + ηt ( λ(γt, ωt)− λ(γkt , ωt) ) − η 2 t 8\n= αt−1ηt ηt−1\n(\nηt−1 ( Lt−1 − Lkt−1 ) − ηt−1 8βt−1\nt−1 ∑\nτ=1\nβτητ\n)\n+ηt ( λ(γt, ωt)−λ(γkt , ωt) )\n−η 2 t\n8\n= ηt ( αt−1Lt−1 + λ(γt, ωt)− αt−1Lkt−1 − λ(γkt , ωt) ) − ηt 8βt\nt−1 ∑\nτ=1\nβτητ − η2t 8\n= ηt ( Lt − Lkt ) − ηt 8βt\nt ∑\nτ=1\nβτητ .\nCondition (10) implies that wkT ≤ K for all k and T , hence we get a loss bound\nLT ≤ LkT + lnK\nηT +\n1\n8βT\nT ∑\nt=1\nβtηt . (16)\nRecall that ηt = a √ βt/Bt. To estimate ∑T\nt=1 βtηt, we use the following inequality (see Appendix A.1 for the proof).\nLemma 1. Let βt be any reals such that 1 ≤ β1 ≤ β2 ≤ . . .. Let BT = ∑T\nt=1 βt. Then, for any T , it holds\n1\nβT\nT ∑\nt=1\nβt\n√\nβt Bt\n≤ 2 √\nBT βT .\nThen (16) implies\nLT ≤ LkT + lnK\na\n√\nBT βT + 2a 8\n√\nBT βT = LkT + ( lnK a + a 4 )\n√\nBT βT .\nChoosing a = 2 √ lnK, we finally get\nLT ≤ LkT + √ lnK\n√\nBT βT ."
    }, {
      "heading" : "3.3 A Bound with respect to ǫ-Best Expert",
      "text" : "Algorithm 3 originates in the “Fake Defensive Forecasting” (FDF) algorithm from [5, Theorem 9]. That algorithm is based on the ideas of defensive forecasting [4], in particular, Hoeffding supermartingales [24], combined with the ideas from an early version of the Weak Aggregating Algorithm [13]. However, our analysis in Theorem 2 is completely different from [5], following the lines of [2, Theorem 2.2] and [13].\nIn this subsection, we consider a direct extension of the FDF algorithm from [5, Theorem 9] to the discounted case. Algorithm 5 becomes the FDF algorithm when αt = 1.\nAlgorithm 5 Fake Defensive Forecasting Algorithm with Discounting\n1: Initialize cumulative losses L0 = 0, Lk0 := 0, k = 1, . . . ,K. Set β1 = 1, B0 = 0. 2: for t = 1, 2, . . . do 3: Get discount αt−1 ∈ (0, 1]; update βt = βt−1/αt−1, Bt = Bt−1 + βt. 4: Compute ηt = √\nβt/Bt. 5: Get Experts’ predictions γkt ∈ Γ, k = 1, . . . ,K. 6: Find γ ∈ Γ s.t. for all ω ∈ Ω ft(γ, ω) ≤ Ct, where ft and Ct are defined by (17) and (18), respectively. 7: Output γt := γ. 8: Get ωt ∈ Ω. 9: Update Lt := αt−1Lt−1 + λ(γt, ωt).\n10: Update Lkt := αt−1Lkt−1 + λ(γkt , ωt), k = 1, . . . ,K. 11: end for.\nAlgorithm 5 in line 6 uses the function\nft(γ, ω) = K ∑\nk=1\n1\nK\n∞ ∑\nj=1\nc\nj2 exp\n(\njαt−1ηt(Lt−1 − Lkt−1)− j2ηt 2βt\nt−1 ∑\nτ=1\nβτητ\n)\n× exp ( jηt(λ(γ, ω)− λ(γkt , ω))− j2η2t 2 ) (17)\nand the constant\nCt =\nK ∑\nk=1\n1\nK\n∞ ∑\nj=1\nc\nj2 exp\n(\njαt−1ηt(Lt−1 − Lkt−1)− j2ηt 2βt\nt−1 ∑\nτ=1\nβτητ\n)\n, (18)\nwhere 1/c = ∑∞ j=1 1 j2 .\nAlgorithm 5 is more complicated than Algorithm 3, and the loss bound we get is weaker and holds for a narrower class of games. However, this bound can be stated as a bound for ǫ-quantile regret introduced in [3]. Namely, let Lǫt be any value such that for at least ǫK Experts their loss Lkt after step t is not greater than Lǫt . The ǫ-quantile regret is the difference between Lt and Lǫt . For ǫ = 1/K, we can choose Lǫt = mink Lkt ≤ Lkt for all k = 1, . . . ,K, and thus a bound in terms of the ǫ-quantile regret implies a bound in terms of Lkt . The value 1/ǫ plays the role of the “effective” number of experts. Algorithm 5 guarantees a bound in terms of Lǫt for any ǫ > 0, without the prior knowledge\nof ǫ, and in this sense the algorithm works for the unknown number of Experts (see [5] for a more detailed discussion).\nFor Algorithm 5 we need to restrict the class of games we consider. The game is called compact if the set Λ = {λ(γ, ·) ∈ RΩ | γ ∈ Γ} is compact in the standard topology of RΩ.\nTheorem 3. Suppose that (Ω,Γ, λ) is a non-empty convex compact game, Ω is finite, and λ(γ, ω) ∈ [0, 1] for all γ ∈ Γ and ω ∈ Ω. In the game played according to Protocol 1, Learner has a strategy guaranteeing that, for any T and for any ǫ > 0, it holds\nLT ≤ LǫT + 2 √\nBT βT ln 1 ǫ + 7\n√\nBT βT , (19)\nwhere βt = 1/(α1 · · ·αt−1) and BT = ∑T t=1 βt.\nProof. The most difficult part of the proof is to show that one can find γ in line 6 of Algorithm 5. We do not do this here, but refer to [5]; the proof is literally the same as in [5, Theorem 9] and is based on the supermartingale property of ft. (The rest of the proof below also follows [5, Theorem 9]; the only difference is in the definition of ft and Ct.)\nLet us check that Ct ≤ 1 for all t. Clearly, C1 = 1. Assume that we have Ct ≤ 1. This implies ft(γt, ωt) ≤ 1 due to the choice of γt, and thus (ft(γt, ωt))\nαtηt+1/ηt ≤ 1. Similarly to (11), we have αtηt+1/ηt ≤ 1. Since the function x 7→ xα is concave for α ∈ (0, 1], x ≥ 0, we get\n1 ≥ ( ft(γt, ωt) )αtηt+1/ηt\n=\n\n\nK ∑\nk=1\n1\nK\n∞ ∑\nj=1\nc\nj2 exp\n(\njηt(Lt − Lkt )− j2ηt 2βt\nt ∑\nτ=1\nβτητ\n)\n\n\nαtηt+1/ηt\n≥ K ∑\nk=1\n1\nK\n∞ ∑\nj=1\nc\nj2\n(\nexp\n(\njηt(Lt − Lkt )− j2ηt 2βt\nt ∑\nτ=1\nβτητ\n))αtηt+1/ηt\n=\nK ∑\nk=1\n1\nK\n∞ ∑\nj=1\nc\nj2 exp\n(\njαtηt+1(Lt − Lkt )− j2ηt+1 2βt+1\nt ∑\nτ=1\nβτητ\n)\n= Ct+1 .\nThus, for each t we have ft(γt, ωt) ≤ 1, that is,\nK ∑\nk=1\n1\nK\n∞ ∑\nj=1\nc\nj2 exp\n(\njηt(Lt − Lkt )− j2ηt 2βt\nt ∑\nτ=1\nβτητ\n)\n≤ 1 .\nFor any ǫ > 0, let us take any LǫT such that for at least ǫK Experts their losses LkT are smaller than or equal to LǫT . Then we have\n1 ≥ K ∑\nk=1\n1\nK\n∞ ∑\nj=1\nc\nj2 exp\n(\njηt(Lt − Lkt )− j2ηt 2βt\nt ∑\nτ=1\nβτητ\n)\n≥ ǫ ∞ ∑\nj=1\nc\nj2 exp\n(\njηt(Lt − Lǫt)− j2ηt 2βt\nt ∑\nτ=1\nβτητ\n)\n≥ cǫ j2 exp\n(\njηt(Lt − Lǫt)− j2ηt 2βt\nt ∑\nτ=1\nβτητ\n)\nfor any natural j. Taking the logarithm and rearranging, we get\nLt ≤ Lǫt + j\n2βt\nt ∑\nτ=1\nβτητ + 1\njηt ln\nj2 cǫ .\nSubstituting ηt = √ βt/Bt and using Lemma 1, we get\nLt ≤ Lǫt + ( j + 2\nj ln j +\n1 j ln 1 ǫ + 1 j ln 1 c\n)\n√\nBt βt .\nLetting j = ⌈ √ ln(1/ǫ) ⌉ +1 and using the estimates j ≤ √\nln(1/ǫ)+2, (ln j)/j ≤ 2, (ln(1/ǫ))/j ≤ √\nln(1/ǫ), 1/j ≤ 1, and ln(1/c) = ln(π2/6) ≤ 1, we obtain the final bound."
    }, {
      "heading" : "4 Regression with Discounted Loss",
      "text" : "In this section we consider a task of regression, where Learner must predict “labels” yt ∈ R for input instances xt ∈ X ⊆ Rn. The predictions proceed according to Protocol 2. This task can be embedded into prediction with expert\nProtocol 2 Competitive online regression\nfor t = 1, 2, . . . do Reality announces xt ∈ X. Learner announces γt ∈ Γ. Reality announces yt ∈ Ω. end for\nadvice if Learner competes with all functions x → y from some large class serving as a pool of (imaginary) Experts."
    }, {
      "heading" : "4.1 The Framework and Linear Functions as Experts",
      "text" : "Let the input space be X ⊆ Rn, the set of predictions be Γ = R, and the set of outcomes be Ω = [Y1, Y2]. In this section we consider the square loss λsq(γ, y) = (γ − y)2. Learner competes with a pool of experts Θ = Rn (treated as linear functionals on Rn). Each individual expert is denoted by θ ∈ Θ and predicts θ′xt at step t.\nLet us take any distribution over the experts P (dθ). It is known from [19] that (3) holds for the square loss with c = 1, η = 2(Y2−Y1)2 :\n∃γ ∈ Γ ∀y ∈ Ω = [Y1, Y2] (γ − y)2 ≤ − 1\nη ln\n(∫\nΘ\ne−η(θ ′xt−y) 2 P (dθ)\n)\n. (20)\nDenote by X the matrix of size T × n consisting of the rows of the input vectors x′1, . . . , x ′ T . Let also WT = diag(β1/βT , β2/βT , . . . , βT /βT ), i.e., WT is a diagonal matrix T × T . In a manner similar to [22], we prove the following upper bound for Learner’s loss.\nTheorem 4. For any a > 0, there exists a prediction strategy for Learner in Protocol 2 achieving, for every T and for any linear predictor θ ∈ Rn,\nT ∑\nt=1\nβt βT\n(γt − yt)2 ≤ T ∑\nt=1\nβt βT (θ′xt − yt)2\n+ a‖θ‖2 + (Y2 − Y1) 2\n4 ln det\n(\nX ′WTX\na + I\n)\n. (21)\nIf, in addition, ‖xt‖∞ ≤ Z for all t, then\nT ∑\nt=1\nβt βT\n(γt − yt)2 ≤ T ∑\nt=1\nβt βT (θ′xt − yt)2\n+ a‖θ‖2 + n(Y2 − Y1) 2\n4 ln\n(\nZ2\na ∑T t=1 βt βT + 1\n)\n. (22)\nIn the undiscounted case (αt = 1 for all t), the bounds in the theorem coincide with the bounds for the Aggregating Algorithm for Regression [22, Theorem 1] with Y2 = Y and Y1 = −Y , since, as remarked after Theorem 2, βt = 1 and ( ∑T t=1 βt ) /βT = T in the undiscounted case. Recall also that in the case of the exponential discounting (αt = α ∈ (0, 1)) we have βt = α−t+1 and (\n∑T t=1 βt\n)\n/βT = (1−αT−1)/(1−α) ≤ 1/(1−α). Thus, for the exponential discounting bound (22) becomes\nT ∑\nt=1\nαT−t(γt − yt)2 ≤ T ∑\nt=1\nαT−t(θ′xt − yt)2\n+ a‖θ‖2 + n(Y2 − Y1) 2\n4 ln\n(\nZ2(1− αT−1) a(1 − α) + 1\n)\n. (23)"
    }, {
      "heading" : "4.2 Functions from an RKHS as Experts",
      "text" : "In this section we apply the kernel trick to the linear method to compete with wider sets of experts. Each expert f ∈ F predicts f(xt). Here F is a reproducing kernel Hilbert space (RKHS) with a positive definite kernel k : X×X → R. For the definition of RKHS and its connection to kernels see [17]. Each kernel defines a unique RKHS. We use the notation KT = {k(xi, xj)}i,j=1,...,T for the kernel matrix for the input vectors at step T . In a manner similar to [7], we prove the following upper bound on the discounted square loss of Learner.\nTheorem 5. For any a > 0, there exists a strategy for Learner in Protocol 2\nachieving, for every positive integer T and any predictor f ∈ F , T ∑\nt=1\nβt βT\n(γt − yt)2 ≤ T ∑\nt=1\nβt βT (f(xt)− yt)2\n+ a‖f‖2 + (Y2 − Y1) 2\n4 ln det\n(√ WTKT √ WT\na + I\n)\n. (24)\nCorollary 1. Assume that c2F = supx∈X k(x, x) < ∞ for the RKHS F . Under the conditions of Theorem 5, given in advance any constant T such that (\n∑T t=1 βt\n)\n/βT ≤ T , one can choose parameter a such that the strategy in Theorem 5 achieves for any f ∈ F\nT ∑\nt=1\nβt βT\n(γt−yt)2 ≤ T ∑\nt=1\nβt βT (f(xt)−yt)2+ ( (Y2 − Y1)2 4 + ‖f‖2 ) cF √ T . (25)\nwhere c2F = supx∈X k(x, x) < ∞ characterizes the RKHS F . Proof. The determinant of a symmetric positive definite matrix is upper bounded by the product of its diagonal elements (see Chapter 2, Theorem 7 in [1]), and thus we have\nln det\n(\nI +\n√ WTKT √ WT\na\n)\n≤ T ln\n\n  1 +\nc2F\n(\n∏T t=1 βt βT\n)1/T\na\n\n \n≤ T c 2 F\na\n(\nT ∏\nt=1\nβt βT\n)1/T\n≤ T c 2 F\naβT\n∑T t=1 βt T ≤ c 2 FT a\n(we use ln(1 + x) ≤ x and the inequality between the geometric and arithmetic means). Choosing a = cF √ T , we get bound (25) from (24).\nRecall again that (\n∑T t=1 βt\n)\n/βT = (1−αT−1)/(1−α) ≤ 1/(1−α) in the case of the exponential discounting (αt = α ∈ (0, 1)), and we can take T = 1/(1−α).\nIn the undiscounted case (αt = 1), we have ( ∑T t=1 βt ) /βT = T , so we need to know the number of steps in advance. Then, bound (25) matches the bound obtained in [23, the displayed formula after (33)]. If we do not know an upper bound T in advance, it is still possible to achieve a bound similar to (25) using the Aggregating Algorithm with Discounting to merge Learner’s strategies from Theorem 5 with different values of parameter a, in the same manner as in [23, Theorem 3].\nCorollary 2. Assume that c2F = supx∈X k(x, x) < ∞ for the RKHS F . Under the conditions of Theorem 5, there exists a strategy for Learner in Protocol 2 achieving, for every positive integer T and any predictor f ∈ F ,\nT ∑\nt=1\nβt βT\n(γt − yt)2 ≤ T ∑\nt=1\nβt βT (f(xt)− yt)2 + cF‖f‖(Y2 − Y1)\n√\n∑T t=1 βt βT\n+ (Y2 − Y1)2\n2 ln ∑T t=1 βt βT + ‖f‖2 + (Y2 − Y1)2 ln ( cF (Y2 − Y1) ‖f‖ + 2 ) . (26)\nProof. Let us take the strategies from Theorem 5 for a = 1, 2, 3, . . . and provide them as Experts to the Aggregating Algorithm with Discounting, with the square loss function, η = 2/(Y2 − Y1)2 and initial Experts’ weights proprotional to 1/a2. Then Theorem 1 (extended as described in Remark at the end of Section 2) guarantees that the extra loss of the aggregated strategy (compared to the strategy from Theorem 5 with parameter a) is not greater than (Y2−Y1) 2\n2 ln a2 c , where c = ∑K k=1 1/k 2. On the other hand, for the strategy from\nTheorem 5 with parameter a similarly to the proof of Corollary 1 we get\nT ∑\nt=1\nβt βT\n(γt − yt)2 ≤ T ∑\nt=1\nβt βT (f(xt)− yt)2 + a‖f‖2 + c2F(Y2 − Y1)2 4a ∑T t=1 βt βT .\nAdding (Y2−Y1) 2 2 ln a2 c to the right-hand side and choosing\na =\n\n  \ncF(Y2 − Y1) 2‖f‖\n√\n∑T t=1 βt βT\n\n  \n,\nwe get the statement after simple estimations."
    }, {
      "heading" : "4.3 Proofs of Theorems 4 and 5",
      "text" : "Let us begin with several technical lemmas from linear algebra. The proofs of some of these lemmas are moved to Appendix A.1.\nLemma 2. Let A be a symmetric positive definite matrix of size n × n. Let θ, b ∈ Rn, c be a real number, and Q(θ) = θ′Aθ + b′θ + c. Then\n∫\nRn e−Q(θ)dθ = e−Q0 πn/2√ detA ,\nwhere Q0 = minθ∈Rn Q(θ).\nThe proof of this lemma can be found in [9, Theorem 15.12.1].\nLemma 3. Let A be a symmetric positive definite matrix of size n × n. Let b, z ∈ Rn, and\nF (A, b, z) = min θ∈Rn (θ′Aθ + b′θ + z′θ)− min θ∈Rn (θ′Aθ + b′θ − z′θ) .\nThen F (A, b, z) = −b′A−1z.\nLemma 4. Let A be a symmetric positive definite matrix of size n × n. Let θ, b1, b2 ∈ Rn, c1, c2 be real numbers, and Q1(θ) = θ′Aθ + b′1θ + c1, Q2(θ) = θ′Aθ + b′2θ + c2. Then\n∫\nRn e−Q1(θ)dθ\n∫\nRn e−Q2(θ)dθ\n= ec2−c1− 1 4 (b2+b1) ′A−1(b2−b1) .\nThe previous three lemmas were implicitly used in [22] to derive a bound on the cumulative undiscounted square loss of the algorithm competing with linear experts.\nLemma 5. For any matrix B of size n×m, any matrix C of size m×n, and any real number a such that the matrices aIm +CB and aIn +BC are nonsingular, it holds\nB(aIm + CB) −1 = (aIn +BC) −1B , (27)\nwhere In, Im are the unit matrices of sizes n× n and m×m, respectively.\nProof. Note that this is equivalent to (aIn +BC)B = B(aIm + CB).\nLemma 6. For matrix B of size n×m, any matrix C of size m× n, and any real number a, it holds\ndet(aIn +BC) = det(aIm + CB) , (28)\nwhere In, Im are the unit matrices of sizes n× n and m×m, respectively."
    }, {
      "heading" : "4.3.1 Proof of Theorem 4.",
      "text" : "We take the Gaussian initial distribution over the experts with a parameter a > 0:\nP0(dθ) = (aη\nπ\n)n/2\ne−aη‖θ‖ 2 dθ.\nand use “Algorithm 2 with infinitely many Experts”. Repeating the derivations from Subsection 2.2, we obtain the following analogue of (7):\n(aη\nπ\n)n/2 ∫\nΘ\ne η ( ∑ T t=1 βt βT (γt−yt) 2− ∑ T t=1 βt βT (θ′xt−yt) 2 ) e−aη‖θ‖ 2 dθ ≤ 1.\nThe simple equality\nT ∑\nt=1\nβt βT\n(θ′xt − yt)2 + a‖θ‖2 = θ′(aI +X ′WTX)θ − 2 T ∑\nt=1\nβt βT ytθ ′xt +\nT ∑\nt=1\nβt βT y2t\n(29) shows that the integral can be evaluated with the help of Lemma 2:\n(aη\nπ\n)n/2 ∫\nΘ\ne −η\n(\n∑\nT t=1 βt βT (θ′xt−yt) 2+a‖θ‖2\n)\ndθ\n= ( a\nπ\n)n/2\ne −ηminθ\n(\n∑\nT t=1 βt βT (θ′xt−yt) 2+a‖θ‖2\n) πn/2 √\ndet(aI +X ′WTX) .\nWe take the natural logarithms of both parts of the bound and using the value η = 2(Y2−Y1)2 obtain (21). The determinant of a symmetric positive definite matrix is upper bounded by the product of its diagonal elements (see Chapter 2, Theorem 7 in [1]):\ndet\n(\nX ′WTX\na + I\n) ≤ ( Z2 ∑T\nt=1 βt aβT + 1\n)n\n,\nand thus we obtain (22)."
    }, {
      "heading" : "4.3.2 Proof of Theorem 5.",
      "text" : "We must prove that for each T and each sequence (x1, y1, . . . , xT , yT ) ∈ (X × R)T the guarantee (24) is satisfied. Fix T and (x1, y1, . . . , xT , yT ). Fix an isomorphism between the linear span of kx1 , . . . , kxT obtained for the Riesz Representation theorem and RT̃ , where T̃ ≤ T is the dimension of the linear span of kx1 , . . . , kxT . Let x̃1, . . . , x̃T ∈ RT̃ be the images of kx1 , . . . , kxT , respectively, under this isomorphism. We have then k(·, xi) = 〈·, x̃i〉 for any xi.\nWe apply the strategy from Theorem 4 to x̃1, . . . , x̃T . The predictions of the strategies are the same due to Proposition 1 below. Any expert θ ∈ RT̃ in bound (21) can be represented as\nθ =\nT ∑\ni=1\ncix̃i =\nT ∑\ni=1\ncik(·, xi)\nfor some ci ∈ R. Thus the experts’ predictions are θ′x̃t = ∑T i=1 cik(xt, xi), and the norm is ‖θ‖2 = ∑Ti,j=1 cicjk(xi, xj). Denote by X̃ the T×T̃ matrix consisting of the rows of the vectors x̃′1, . . . , x̃′T . From Lemma 6 we have\ndet\n(\nX̃ ′WT X̃\na + I\n)\n= det\n(√ WT X̃X̃ ′ √ WT\na + I\n)\n.\nThus using KT = X̃X̃ ′ we obtain the upper bound\nT ∑\nt=1\nβt βT\n(γt − yt)2 ≤ T ∑\nt=1\nβt βT\n(\nT ∑\ni=1\ncik(xt, xi)− yt )2\n+ a\nT ∑\ni,j=1\ncicjk(xi, xj) + (Y2 − Y1)2\n4 ln det\n(√ WTKT √ WT\na + I\n)\nfor any ci ∈ R, i = 1, . . . , T . By the Representer theorem (see Theorem 4.2 in [17]) the minimum of\n∑T t=1 βt βT (f(xt)−yt)2+a‖f‖2 over all f ∈ F is achieved on one of the linear combinations from the bound obtained above. This concludes the proof."
    }, {
      "heading" : "4.4 Regression Algorithms",
      "text" : "In this subsection we derive explicit form of the prediction strategies for Learner used in Theorems 4 and 5."
    }, {
      "heading" : "4.4.1 Strategy for Theorem 4.",
      "text" : "In [22] Vovk suggests for the square loss the following substitution function satisfying (5):\nγT = Y2 + Y1 2 − gT (Y2)− gT (Y1) 2(Y2 − Y1) . (30)\nIt allows us to calculate gT with unnormalized weights:\ngT (y) = − 1\nη\n(\nln\n∫\nΘ\ne −η\n(\nθ′AT θ−2θ ′(bT−1+yxT )+\n(\n∑T−1 t=1 βt βT\ny2t+y 2 ))\ndθ\n)\nfor any y ∈ Ω = [Y1, Y2] (here we use the expansion (29)), where\nAT = aI +\nT−1 ∑\nt=1\nβt βT xtx ′ t + xTx ′ T = aI +X ′WTX,\nand bT−1 = ∑T−1 t=1 βt βT\nytxt. The direct calculation of gT is inefficient: it requires numerical integration. Instead, we notice that\nγT = Y2 + Y1 2 − gT (Y2)− gT (Y1) 2(Y2 − Y1)\n= Y2 + Y1 2 − 1 2(Y2 − Y1)η ln\n∫ Θ e −η\n(\nθ′AT θ−2θ ′(bT−1+Y1xT )+\n(\n∑T−1 t=1 βt βT y2t+Y 2 1\n))\ndθ ∫\nΘ e −η\n( θ′AT θ−2θ′(bT−1+Y2xT )+ ( ∑T−1 t=1 βt βT y2t+Y 2 2 ))\ndθ\n= Y2 + Y1 2 − 1 2(Y2 − Y1)η ln e\nη (\nY 22 −Y 2 1 −(bT−1+( Y2+Y1 2 )xT )\n′\nA−1 T ( Y2−Y1 2 xT ) )\n=\n(\nbT−1 +\n(\nY2 + Y1 2\n)\nxT\n)′\nA−1T xT , (31)\nwhere the third equality follows from Lemma 4. The strategy which predicts according to (31) requires O(n3) operations per step. The most time-consuming operation is the inverse of the matrix AT . Note that for the undiscounted case the inverse could be computed incrementally using the Sherman-Morrison formula, which leads to O(n2) operations per step."
    }, {
      "heading" : "4.4.2 Strategy for Theorem 5.",
      "text" : "We use following notation. Let\nkT be the last column of the matrix KT ,kT = {k(xi, xT )}Ti=1, YT be the column vector of the outcomes YT = (y1, . . . , yT ) ′. (32)\nWhen we write Z = (V;Y) or Z = (V′;Y′)′ we mean that the column vector Z is obtained by concatenating two column vectors V,Y vertically or V′,Y′ horizontally. As it is clear from the proof of Theorem 5, we need to prove that the strategy for this theorem is the same as the strategy for Theorem 4 in the case when the kernel is the scalar product.\nProposition 1. The predictions (31) can be represented as\nγT =\n(\nYT−1; Y2 + Y1\n2\n)′ √\nWT\n(\naI + √ WTKT √ WT\n)−1 √\nWTkT (33)\nfor the scalar product kernel k(x, y) = 〈x, y〉, the unit T×T matrix I, and a > 0.\nProof. For the scalar product kernel we have we haveKT = X ′X and √ WTkT =√\nWTXxT . By Lemma 5 we obtain\n(\naI + √ WTXX ′ √ WT\n)−1 √\nWTXxT = √ WTX ( aI +X ′WTX )−1 xT .\nIt is easy to see that\n(\nYT−1; Y2 + Y1\n2\n)′\nWTX =\n(\nT−1 ∑\nt=1\nβt βT ytxt +\n(\nY2 + Y1 2\n)\nxT\n)′\nand\nX ′WTX =\nT−1 ∑\nt=1\nβt βT xtx ′ t + xTx ′ T .\nThus we obtain the formula (31) from (33)."
    }, {
      "heading" : "Acknowledgements",
      "text" : "We are grateful to Yura Kalnishkan and Volodya Vovk for numerous illuminating discussions. This work was supported by EPSRC (grant EP/F002998/1)."
    }, {
      "heading" : "A Appendix",
      "text" : "A.1 Proofs of Technical Lemmas\nProof of Lemma 1. For T = 1 the inequality is trivial. Assume it for T − 1. Then\n1\nβT\nT ∑\nt=1\nβt\n√\nβt Bt = βT−1 βT\n(\n1\nβT−1\nT−1 ∑\nt=1\nβt\n√\nβt Bt\n)\n+\n√\nβT BT\n≤ 2βT−1 βT\n√\nBT−1 βT−1 +\n√\nβT BT = 2\n√\nβT−1 βT\n√\nBT−1 βT +\n√\nβT BT\n≤ 2 √\nBT−1 βT +\n√\nβT BT−1 + βT\n≤ 2 √\nBT−1 + βT βT = 2\n√\nBT βT .\nThe first inequality is by the induction assumption, and the second inequality holds since βT−1 ≤ βT . The last inequality is 2 √ x/ √ y + √ y/ √ x+ y ≤ 2 √ x+ y/ √ y, which holds for any positive x and y. (Indeed, it is equivalent to 2 √ x √ x+ y + y ≤ 2(x+ y) and 2√x√x+ y ≤ x+ y + x.)\nProof of Lemma 3. This lemma is proven by taking the derivative of the quadratic forms in F by θ and calculating the minimum: minθ∈Rn(θ ′Aθ+c′θ) = − (A −1c)′\n4 c for any c ∈ Rn (see Theorem 19.1.1 in [9]).\nProof of Lemma 4. After evaluating each of the integrals using Lemma 2 the ratio is represented as follows:\n∫\nRn e−Q1(θ)dθ\n∫\nRn e−Q2(θ)dθ\n= eminθ∈Rn Q2(θ)−minθ∈Rn Q1(θ) .\nThe difference of minimums can be calculated using Lemma 3 with b = b2+b12 and z = b2−b12 :\nmin θ∈Rn Q2(θ) − min θ∈Rn\nQ1(θ) = c2 − c1 − 1\n4 (b2 + b1)\n′A−1(b2 − b1) .\nProof of Lemma 6. Consider the product of block matrices: (\nIn B 0 Im\n)(\naIn + BC 0 −C aIm\n)\n=\n(\naIn aB −C aIm\n)\n=\n(\naIn 0 −C aIm + CB\n)(\nIn B 0 Im\n)\nTaking the determinant of both sides, and using formulas for the determinant of a block matrix, we get the statement of the lemma.\nA.2 An Alternative Derivation of Regression Algorithms\nUsing Defensive Forecasting\nIn this section we derive the upper bound and the algorithms using a different technique, the defensive forecasting [4].\nA.2.1 Description of the Proof Technique\nWe denote the predictions of any expert θ (from a finite set or following strategies from Section 4) by ξθt . For each step T and each expert θ we define the function\nQθt : Γ× Ω → [0,∞) Qθt (γ, y) := e η(λ(γ,y)−λ(ξθt ,y)). (34)\nWe also define the mixture function\nQT :=\n∫\nΘ\nT−1 ∏\nt=1\n( Qθt )\n∏T−1 i=t\nαi QθTP0(dθ)\nwith some initial weights distribution P0(dθ) on the experts. Here η is a learning rate coefficient; it will be defined later in the section. We define the correspondence γp = p(Y2 − Y1) + Y1, p ∈ [0, 1], (35) between [0, 1] and Learner’s predictions γp ∈ Γ.\nLet us introduce the notion of a defensive property. We use the notation δΩ := {Y1, Y2}. Assume that there is a fixed bijection between the space P(δΩ) of all probability measures on δΩ and the set [0, 1]. Each pπ ∈ [0, 1] corresponds to some unique π ∈ P(δΩ). Definition 1. A sequence R of functions R1, R2, . . . such that Rt : Γ × Ω → (−∞,∞] is said to have the defensive property if, for any T and any πT ∈ P(δΩ), it holds that\nEπTRT (γ pπT , y) ≤ 1, (36)\nwhere Eπ is the expectation with respect to a measure π.\nA sequence R is called forecast-continuous if, for all T and all y ∈ Ω, all the functions RT (γ, y) are continuous in γ.\nWe now prove that Qθt has the defensive property.\nLemma 7. For η ∈ (\n0, 2(Y2−Y1)2\n]\nQθt = e η((γt−yt)2−(ξθt −yt) 2)\nis a forecast-continuous sequence having the defensive property.\nProof. The continuity is obvious. We need to prove that\npeη((γ−Y2) 2−(ξθt−Y2) 2) + (1− p)eη((γ−Y1)2−(ξθt−Y1)2) ≤ 1 (37)\nholds for all γ ∈ [Y1, Y2] and η ∈ (\n0, 2(Y2−Y1)2\n]\n. Indeed, for any γ ∈ R \\ [Y1, Y2] there exists γ̃ ∈ {Y1, Y2} such that (γ̃ − y)2 ≤ (γ − y)2 for any y ∈ Ω. Since the exponent function is increasing, the inequality (37) for any γ ∈ R will follow.\nWe use the correspondence (35), ξθt = q(Y2 − Y1) + Y1 for some q ∈ R, and µ = η(Y2 − Y1)2. Then we have to show that for all p ∈ [0, 1], q ∈ R and η ∈ (\n0, 2(Y2−Y1)2\n]\npeµ((1−p) 2−(1−q)2) + (1 − p)eµ(p2−q2) ≤ 1.\nIf we substitute q = p+ x, the last inequality will reduce to\npe2µ(1−p)x + (1− p)e−2µpx ≤ eµx2 , ∀x ∈ R.\nApplying Hoeffding’s inequality (see [12]) to the random variableX that is equal to 1 with probability p and to 0 with probability (1− p), we obtain\npeh(1−p) + (1− p)e−hp ≤ eh2/8\nfor any h ∈ R. With the substitution h := 2µx it reduces to\npe2µ(1−p)x + (1 − p)e−2µpx ≤ eµ2x2/2 ≤ eµx2 ,\nwhere the last inequality holds if µ ≤ 2. The last inequality is equivalent to η ≤ 2(Y2−Y1)2 , which we assumed.\nWe will further use the maximum value for η, η = 2(Y2−Y1)2 .\nThe following lemma states the most important for us property of the sequences having the defensive property originally proven in [15].\nLemma 8. Let R be a forecast-continuous sequence having the defensive property. For any T there exists p ∈ [0, 1] such that for all y ∈ δΩ\nRT (γ p, y) ≤ 1.\nProof. Define a function ft : δΩ× [0, 1] → (−∞,∞] by\nft(p, y) = Rt(γ p, y)− 1.\nSince R is forecast-continuous and the correspondence (35) is continuous, ft(y, p) is continuous in p. Since R has the defensive property, we have\npf(p, Y2) + (1− p)f(1− p, Y1) ≤ 0 (38)\nfor all p ∈ [0, 1]. In particular, f(0, Y1) ≤ 0 and f(1, Y2) ≤ 0. Our goal is to show that for some p ∈ [0, 1] we have f(p, Y1) ≤ 0 and f(p, Y2) ≤ 0. If f(0, Y2) ≤ 0, we can take p = 0. If f(1, Y1) ≤ 0, we can take p = 1. Assume that f(0, Y2) > 0 and f(1, Y1) > 0. Then the difference\nf(p) := f(p, Y2)− f(p, Y1)\nis positive for p = 0 and negative for p = 1. By the intermediate value theorem, f(p) = 0 for some p ∈ (0, 1). By (38) we have f(p, Y2) = f(p, Y1) ≤ 0.\nThis lemma shows that at each step there is a probability measure (corresponding to p ∈ [0, 1]) such that the sequence having the defensive property remains less than one for any outcome.\nThe proof of the upper bounds for Defensive Forecasting is based on the following argument.\nLemma 9. Assume that the sequence of functions Qθt is forecast-continuous and has the defensive property. Then the mixtures Qt as functions of two variables y, γ at the step t form a forecast-continuous sequence having the defensive property.\nProof. The continuity easily follows from the continuity of Qθt and the integration functional. We proceed by induction in T . For T = 0 we have EπQ0 = Eπ1 ≤ 1. For T > 0 assume that for any y1, . . . , yT−2 ∈ δΩ and any γ1, . . . , γT−2 ∈ Γ\nEπQT−1(y1, γ1, . . . , yT−2, γT−2, y, γ pπ) ≤ 1\nfor any π ∈ P(δΩ). Then by Lemma 8 there exists πT−1 ∈ P(δΩ) such that\nQT−1(y1, γ1, . . . , yT−2, γT−2, y, γ pπT−1 ) =\n∫\nΘ\nT−2 ∏\nt=1\n( Qθt )\n∏T−2 i=t\nαi QθT−1P0(dθ) ≤ 1\n(39) for any y ∈ δΩ. We denote γT−1 = γp πT−1 and fix any yT−1 ∈ Ω. We obtain\nEπQT (y1, γ1, . . . , yT−1, γT−1, y, γ pπ)\n= Eπ\n∫\nΘ\nT−1 ∏\nt=1\n( Qθt (γt, yt) )\n∏T−1 i=t\nαi QθT (γ pπ , y)P0(dθ)\n=\n∫\nΘ\nT−1 ∏\nt=1\n( Qθt (γt, yt) )\n∏T−1 i=t αi (\nEπQ θ T (γ\npπ , y) )\nP0(dθ)\n≤ ∫\nΘ\nT−1 ∏\nt=1\n( Qθt (γt, yt) )\n∏T−1 i=t\nαi P0(dθ)\n=\n∫\nΘ\n(\nT−2 ∏\nt=1\n( Qθt )\n∏T−2 i=t\nαi QθT−1\n)αT−1\nP0(dθ)\n≤ ( ∫\nΘ\nT−2 ∏\nt=1\n( Qθt )\n∏T−2 i=t\nαi QθT−1P0(dθ)\n)αT−1\n≤ 1.\nThe first inequality holds because EπQ θ T (γ pπ , y) ≤ 1 for any π ∈ P(δΩ). The penultimate inequality holds due to the concavity of the function xα with x > 0, α ∈ [0, 1]. The last inequality holds due to (39). This completes the proof.\nBy Lemma 8 at each step t there exists a prediction γt such that Qt is less than one. Now we only need to generalize Lemma 8 for the case when the outcome set is the full interval: Ω = [Y1, Y2].\nLemma 10. If γT is such that QT (y1, γ1, . . . , yT−1, γT−1, y, γT ) ≤ 1 for all y ∈ {Y1, Y2}, then QT (y1, γ1, . . . , yT−1, γT−1, y, γT ) ≤ 1 for all y ∈ [Y1, Y2].\nProof. Note that any y ∈ [Y1, Y2] can be represented as y = uYT,2 + (1− u)YT,1 for some u ∈ [0, 1]. Thus\n(ζ1 − y)2 − (ζ2 − y)2 = ζ21 − ζ22 − 2y(ζ1 − ζ2) = u[(ζ1 − Y2)2 − (ζ2 − Y2)2] + (1− u)[(ζ1 − Y1)2 − (ζ2 − Y1)2]\nfor any ζ1, ζ2 ∈ R. Due to the convexity of the exponent function we have for any η ≥ 0\neη[(ζ1−y) 2−(ζ2−y) 2] ≤ ueη[(ζ1−Y2)2−(ζ2−Y2)2] + (1− u)eη[(ζ1−Y1)2−(ζ2−Y1)2].\nThus QθT (γT , y) ≤ uQθT (γT , Y2) + (1− u)QθT (γT , Y1)\nand therefore\nQT (y1, γ1, . . . , yT−1, γT−1, y, γT ) ≤ uQT (y1, γ1, . . . , yT−1, γT−1, Y2, γT ) + (1− u)QT (y1, γ1, . . . , yT−1, γT−1, Y1, γT ) ≤ 1\nwhere the second inequality follows from the condition of the lemma.\nFinally we obtain\n∫\nΘ\nT−1 ∏\nt=1\neη ∏T−1 i=t αi(λ(γt,yt)−λ(ξθt ,yt))eη(λ(γT ,yT )−λ(ξ θ T ,yT ))P0(dθ) ≤ 1. (40)\nA.2.2 Derivation of the Prediction Strategies Using Defensive Fore-\ncasting\nLemma 8 describes an explicit strategy of making predictions. This strategy relies on the search for a fixed point and may become very inefficient especially for the cases of infinite number of experts. Therefore we develop a more efficient strategies for each of our problems.\nWe first note that the strategy in Lemma 8 solves\n∫\nΘ\nT−1 ∏\nt=1\neη ∏T−1 i=t αi(λ(γt,yt)−λ(ξθt ,yt))eη(λ(γ,Y2)−λ(ξ θ T ,Y2))P0(dθ)\n− ∫\nΘ\nT−1 ∏\nt=1\neη ∏T−1 i=t αi(λ(γt,yt)−λ(ξθt ,yt))eηT (λ(γ,Y1)−λ(ξ θ T ,Y1))P0(dθ) = 0\nin γ ∈ [Y1, Y2] if the trivial predictions are not satisfactory (the integral becomes a sum in the case of finite number of experts). We define\ngT (y) := − 1\nη ln\n∫\nΘ\ne−ηλ(ξ θ T ,y)\nT−1 ∏\nt=1\ne−η ∏T−1 i=t αiλ(ξ θ t ,yt)P0(dθ) (41)\nfor any y ∈ Ω. Rewriting the equation for the root we have\neη(λT (γ,Y2)−gT (Y2)) − eη(λT (γ,Y1)−gT (Y1)) = 0\nMoving the second exponent to the right-hand side and taking logη of both sides we obtain\nλ(γ, Y2)− gT (Y2) = λ(γ, Y1)− gT (Y1). (42) For the square loss we can solve (42) in γ:\nγ = Y2 + Y1 2 − g(Y2)− g(Y1) 2(Y2 − Y1) . (43)\nThis formula for predictions is equivalent to (30)."
    } ],
    "references" : [ {
      "title" : "Prediction, Learning, and Games",
      "author" : [ "N. Cesa-Bianchi", "G. Lugosi" ],
      "venue" : null,
      "citeRegEx" : "2",
      "shortCiteRegEx" : "2",
      "year" : 2006
    }, {
      "title" : "A parameter-free hedging algorithm",
      "author" : [ "K. Chaudhuri", "Y. Freund", "D. Hsu" ],
      "venue" : "Advances in Neural Information Processing Systems",
      "citeRegEx" : "3",
      "shortCiteRegEx" : "3",
      "year" : 2009
    }, {
      "title" : "Supermartingales in prediction with expert advice",
      "author" : [ "A. Chernov", "Y. Kalnishkan", "F. Zhdanov", "V. Vovk" ],
      "venue" : "Theoretical Computer Science,",
      "citeRegEx" : "4",
      "shortCiteRegEx" : "4",
      "year" : 2010
    }, {
      "title" : "Prediction with Advice of Unknown Number of Experts Technical report, arXiv:1006.0475 [cs.LG], arXiv.org e-Print archive",
      "author" : [ "A. Chernov", "V. Vovk" ],
      "venue" : null,
      "citeRegEx" : "5",
      "shortCiteRegEx" : "5",
      "year" : 2010
    }, {
      "title" : "A new hedging algorithm and its application to inferring latent random variables. Technical report, arXiv:0806.4802v1 [cs.GT], arXiv.org e-Print archive",
      "author" : [ "Y. Freund", "D. Hsu" ],
      "venue" : null,
      "citeRegEx" : "6",
      "shortCiteRegEx" : "6",
      "year" : 2008
    }, {
      "title" : "On-line prediction with kernels and the complexity approximation principle",
      "author" : [ "A. Gammerman", "Y. Kalnishkan", "V. Vovk" ],
      "venue" : "Uncertainty in Artificial Intelligence, Proc. of 20th Conf., pp",
      "citeRegEx" : "7",
      "shortCiteRegEx" : "7",
      "year" : 2004
    }, {
      "title" : "Exponential smoothing: The state of the art – part II",
      "author" : [ "E.S. Gardner" ],
      "venue" : "International Journal of Forecasting 22,",
      "citeRegEx" : "8",
      "shortCiteRegEx" : "8",
      "year" : 2006
    }, {
      "title" : "Matrix algebra from a statistician’s perspective",
      "author" : [ "D.A. Harville" ],
      "venue" : null,
      "citeRegEx" : "9",
      "shortCiteRegEx" : "9",
      "year" : 1997
    }, {
      "title" : "Sequential prediction of individual sequences under general loss functions",
      "author" : [ "D. Haussler", "J. Kivinen", "M. Warmuth" ],
      "venue" : "IEEE Transactions on Information Theory,",
      "citeRegEx" : "10",
      "shortCiteRegEx" : "10",
      "year" : 1998
    }, {
      "title" : "Tracking the best expert",
      "author" : [ "M. Herbster", "M.K. Warmuth" ],
      "venue" : "Machine Learning 32,",
      "citeRegEx" : "11",
      "shortCiteRegEx" : "11",
      "year" : 1998
    }, {
      "title" : "Probability inequalities for sums of bounded random variables",
      "author" : [ "W. Hoeffding" ],
      "venue" : "Journal of the American Statistical Association 58,",
      "citeRegEx" : "12",
      "shortCiteRegEx" : "12",
      "year" : 1963
    }, {
      "title" : "The weak aggregating algorithm and weak mixability",
      "author" : [ "Y. Kalnishkan", "M. Vyugin" ],
      "venue" : "Technical report, CLRC-TR-03-01,",
      "citeRegEx" : "13",
      "shortCiteRegEx" : "13",
      "year" : 2003
    }, {
      "title" : "The weak aggregating algorithm and weak mixability",
      "author" : [ "Y. Kalnishkan", "M. Vyugin" ],
      "venue" : "Journal of Computer and System Sciences,",
      "citeRegEx" : "14",
      "shortCiteRegEx" : "14",
      "year" : 2008
    }, {
      "title" : "Uniform tests of randomness",
      "author" : [ "L. Levin" ],
      "venue" : "Soviet Mathematics Doklady 17,",
      "citeRegEx" : "15",
      "shortCiteRegEx" : "15",
      "year" : 1976
    }, {
      "title" : "Optimal properties of exponentially weighted forecasts",
      "author" : [ "J.F. Muth" ],
      "venue" : "Journal of the American Statistical Association",
      "citeRegEx" : "16",
      "shortCiteRegEx" : "16",
      "year" : 1960
    }, {
      "title" : "Learning with kernels: Support Vector Machines, regularization, optimization, and beyond",
      "author" : [ "B. Schölkopf", "A.J. Smola" ],
      "venue" : null,
      "citeRegEx" : "17",
      "shortCiteRegEx" : "17",
      "year" : 2002
    }, {
      "title" : "Reinforcement learning: An introduction",
      "author" : [ "R. Sutton", "A. Barto" ],
      "venue" : null,
      "citeRegEx" : "18",
      "shortCiteRegEx" : "18",
      "year" : 1998
    }, {
      "title" : "Aggregating strategies",
      "author" : [ "V. Vovk" ],
      "venue" : "Proceedings of the Third Annual Workshop on Computational Learning Theory. pp",
      "citeRegEx" : "19",
      "shortCiteRegEx" : "19",
      "year" : 1990
    }, {
      "title" : "A Game of Prediction with Expert Advice",
      "author" : [ "V. Vovk" ],
      "venue" : "Journal of Computer and System Sciences,",
      "citeRegEx" : "20",
      "shortCiteRegEx" : "20",
      "year" : 1998
    }, {
      "title" : "Derandomizing stochastic prediction strategies",
      "author" : [ "V. Vovk" ],
      "venue" : "Machine Learning,",
      "citeRegEx" : "21",
      "shortCiteRegEx" : "21",
      "year" : 1999
    }, {
      "title" : "Competitive on-line statistics",
      "author" : [ "V. Vovk" ],
      "venue" : "Int. Stat. Review 69,",
      "citeRegEx" : "22",
      "shortCiteRegEx" : "22",
      "year" : 2001
    }, {
      "title" : "On-line regression competitive with reproducing kernel Hilbert spaces. Technical report, arXiv:cs/0511058 [cs.LG], arXiv.org e-Print archive",
      "author" : [ "V. Vovk" ],
      "venue" : null,
      "citeRegEx" : "23",
      "shortCiteRegEx" : "23",
      "year" : 2005
    }, {
      "title" : "Hoeffding’s inequality in game-theoretic probability. Technical Report, arXiv:0708.2502 [math.PR], arXiv.org e-Print archive",
      "author" : [ "V. Vovk" ],
      "venue" : null,
      "citeRegEx" : "24",
      "shortCiteRegEx" : "24",
      "year" : 2007
    } ],
    "referenceMentions" : [ {
      "referenceID" : 0,
      "context" : "In the standard framework for prediction with expert advice (see the monograph [2] for a comprehensive review), the losses from all steps are just summed.",
      "startOffset" : 79,
      "endOffset" : 82
    }, {
      "referenceID" : 17,
      "context" : "The standard protocol of prediction with expert advice (as described in [19, 20]) is a special case of Protocol 1 where Accountant always announces αt = 1, t = 0, 1, 2, .",
      "startOffset" : 72,
      "endOffset" : 80
    }, {
      "referenceID" : 18,
      "context" : "The standard protocol of prediction with expert advice (as described in [19, 20]) is a special case of Protocol 1 where Accountant always announces αt = 1, t = 0, 1, 2, .",
      "startOffset" : 72,
      "endOffset" : 80
    }, {
      "referenceID" : 14,
      "context" : ", [16]), time series analysis (see, e.",
      "startOffset" : 2,
      "endOffset" : 6
    }, {
      "referenceID" : 6,
      "context" : ", [8]), reinforcement learning [18], and other applications.",
      "startOffset" : 2,
      "endOffset" : 5
    }, {
      "referenceID" : 16,
      "context" : ", [8]), reinforcement learning [18], and other applications.",
      "startOffset" : 31,
      "endOffset" : 35
    }, {
      "referenceID" : 4,
      "context" : "In the context of prediction with expert advice, Freund and Hsu [6] noted that the discounted loss provides an alternative to “tracking the best expert” framework [11].",
      "startOffset" : 64,
      "endOffset" : 67
    }, {
      "referenceID" : 9,
      "context" : "In the context of prediction with expert advice, Freund and Hsu [6] noted that the discounted loss provides an alternative to “tracking the best expert” framework [11].",
      "startOffset" : 163,
      "endOffset" : 167
    }, {
      "referenceID" : 0,
      "context" : "8 in [2] gives a guarantee only at one moment T chosen in advance.",
      "startOffset" : 5,
      "endOffset" : 8
    }, {
      "referenceID" : 4,
      "context" : "Under this discounting, NormalHedge algorithm is analysed in [6]; we briefly compare the obtained bounds in Section 3.",
      "startOffset" : 61,
      "endOffset" : 64
    }, {
      "referenceID" : 18,
      "context" : "In Section 2, we propose a generalization of the Aggregating Algorithm [20] and prove the same bound as in [20] but for the discounted loss.",
      "startOffset" : 71,
      "endOffset" : 75
    }, {
      "referenceID" : 18,
      "context" : "In Section 2, we propose a generalization of the Aggregating Algorithm [20] and prove the same bound as in [20] but for the discounted loss.",
      "startOffset" : 107,
      "endOffset" : 111
    }, {
      "referenceID" : 12,
      "context" : "In Section 3, we consider convex loss functions and propose an algorithm similar to the Weak Aggregating Algotihm [14] and the exponentially weighted average forecaster with time-varying learning rate [2, § 2.",
      "startOffset" : 114,
      "endOffset" : 118
    }, {
      "referenceID" : 20,
      "context" : "In Section 4, we consider the use of prediction with expert advice for the regression problem and adapt the Aggregating Algorithm for Regression [22] (applied to spaces of linear functions and to reproducing kernel Hilbert spaces) to the discounted square loss.",
      "startOffset" : 145,
      "endOffset" : 149
    }, {
      "referenceID" : 2,
      "context" : "All our algorithms are inspired by the methodology of defensive forecasting [4].",
      "startOffset" : 76,
      "endOffset" : 79
    }, {
      "referenceID" : 17,
      "context" : "Bounds of this kind were obtained in [19].",
      "startOffset" : 37,
      "endOffset" : 41
    }, {
      "referenceID" : 17,
      "context" : "For the standard undiscounted case (Accountant announces αt = 1 at each step t), this theorem was proved by Vovk in [19] with the help of the Aggregating Algorithm (AA) as Learner’s strategy.",
      "startOffset" : 116,
      "endOffset" : 120
    }, {
      "referenceID" : 8,
      "context" : "It is known ([10, 20]) that this bound is asymptotically optimal for large pools of Experts (for games satisfying some assumptions): if the game does not satisfy (3) for some c ≥ 1 and η > 0, then, for sufficiently large K, there is a strategy for Experts and Reality (recall that Accountant always says αt = 1) such that Learner cannot secure (4).",
      "startOffset" : 13,
      "endOffset" : 21
    }, {
      "referenceID" : 18,
      "context" : "It is known ([10, 20]) that this bound is asymptotically optimal for large pools of Experts (for games satisfying some assumptions): if the game does not satisfy (3) for some c ≥ 1 and η > 0, then, for sufficiently large K, there is a strategy for Experts and Reality (recall that Accountant always says αt = 1) such that Learner cannot secure (4).",
      "startOffset" : 13,
      "endOffset" : 21
    }, {
      "referenceID" : 19,
      "context" : "For the special case of c = 1, bound (4) is tight for any fixedK as well [21].",
      "startOffset" : 73,
      "endOffset" : 77
    }, {
      "referenceID" : 20,
      "context" : "Then the algorithm and its analysis remain valid (if we impose natural integrability conditions on Experts’ predictions γ t ; see [22] for more detailed discussion)—this will be used in Section 4.",
      "startOffset" : 130,
      "endOffset" : 134
    }, {
      "referenceID" : 4,
      "context" : "A similar bound (with worse constants) is obtained in [6] for NormalHedge: LT ≤ LT + √",
      "startOffset" : 54,
      "endOffset" : 57
    }, {
      "referenceID" : 1,
      "context" : "The NormalHedge algorithm has an important advantage: it can guarantee the last bound without knowledge of the number of experts K (see [3] for a precise definition).",
      "startOffset" : 136,
      "endOffset" : 139
    }, {
      "referenceID" : 12,
      "context" : "Let us explain the relation of Algorithm 3 to the Weak Aggregating Algorithm [14] and the exponentially weighted average forecaster with time-varying learning rate [2, § 2.",
      "startOffset" : 77,
      "endOffset" : 81
    }, {
      "referenceID" : 12,
      "context" : "In this case, Algorithm 4 is just the Weak Aggregating Algorithm as described in [14].",
      "startOffset" : 81,
      "endOffset" : 85
    }, {
      "referenceID" : 2,
      "context" : "That algorithm is based on the ideas of defensive forecasting [4], in particular, Hoeffding supermartingales [24], combined with the ideas from an early version of the Weak Aggregating Algorithm [13].",
      "startOffset" : 62,
      "endOffset" : 65
    }, {
      "referenceID" : 22,
      "context" : "That algorithm is based on the ideas of defensive forecasting [4], in particular, Hoeffding supermartingales [24], combined with the ideas from an early version of the Weak Aggregating Algorithm [13].",
      "startOffset" : 109,
      "endOffset" : 113
    }, {
      "referenceID" : 11,
      "context" : "That algorithm is based on the ideas of defensive forecasting [4], in particular, Hoeffding supermartingales [24], combined with the ideas from an early version of the Weak Aggregating Algorithm [13].",
      "startOffset" : 195,
      "endOffset" : 199
    }, {
      "referenceID" : 3,
      "context" : "However, our analysis in Theorem 2 is completely different from [5], following the lines of [2, Theorem 2.",
      "startOffset" : 64,
      "endOffset" : 67
    }, {
      "referenceID" : 11,
      "context" : "2] and [13].",
      "startOffset" : 7,
      "endOffset" : 11
    }, {
      "referenceID" : 1,
      "context" : "However, this bound can be stated as a bound for ǫ-quantile regret introduced in [3].",
      "startOffset" : 81,
      "endOffset" : 84
    }, {
      "referenceID" : 3,
      "context" : "of ǫ, and in this sense the algorithm works for the unknown number of Experts (see [5] for a more detailed discussion).",
      "startOffset" : 83,
      "endOffset" : 86
    }, {
      "referenceID" : 3,
      "context" : "We do not do this here, but refer to [5]; the proof is literally the same as in [5, Theorem 9] and is based on the supermartingale property of ft.",
      "startOffset" : 37,
      "endOffset" : 40
    }, {
      "referenceID" : 17,
      "context" : "It is known from [19] that (3) holds for the square loss with c = 1, η = 2 (Y2−Y1) : ∃γ ∈ Γ ∀y ∈ Ω = [Y1, Y2] (γ − y) ≤ − 1 η ln (∫",
      "startOffset" : 17,
      "endOffset" : 21
    }, {
      "referenceID" : 20,
      "context" : "In a manner similar to [22], we prove the following upper bound for Learner’s loss.",
      "startOffset" : 23,
      "endOffset" : 27
    }, {
      "referenceID" : 15,
      "context" : "For the definition of RKHS and its connection to kernels see [17].",
      "startOffset" : 61,
      "endOffset" : 65
    }, {
      "referenceID" : 5,
      "context" : "In a manner similar to [7], we prove the following upper bound on the discounted square loss of Learner.",
      "startOffset" : 23,
      "endOffset" : 26
    }, {
      "referenceID" : 20,
      "context" : "The previous three lemmas were implicitly used in [22] to derive a bound on the cumulative undiscounted square loss of the algorithm competing with linear experts.",
      "startOffset" : 50,
      "endOffset" : 54
    }, {
      "referenceID" : 15,
      "context" : "2 in [17]) the minimum of ∑T t=1 βt βT (f(xt)−yt)+a‖f‖ over all f ∈ F is achieved on one of the linear combinations from the bound obtained above.",
      "startOffset" : 5,
      "endOffset" : 9
    }, {
      "referenceID" : 20,
      "context" : "In [22] Vovk suggests for the square loss the following substitution function satisfying (5): γT = Y2 + Y1 2 − gT (Y2)− gT (Y1) 2(Y2 − Y1) .",
      "startOffset" : 3,
      "endOffset" : 7
    }, {
      "referenceID" : 7,
      "context" : "1 in [9]).",
      "startOffset" : 5,
      "endOffset" : 8
    }, {
      "referenceID" : 2,
      "context" : "2 An Alternative Derivation of Regression Algorithms Using Defensive Forecasting In this section we derive the upper bound and the algorithms using a different technique, the defensive forecasting [4].",
      "startOffset" : 197,
      "endOffset" : 200
    }, {
      "referenceID" : 10,
      "context" : "Applying Hoeffding’s inequality (see [12]) to the random variableX that is equal to 1 with probability p and to 0 with probability (1− p), we obtain pe + (1− p)e ≤ eh2/8 for any h ∈ R.",
      "startOffset" : 37,
      "endOffset" : 41
    }, {
      "referenceID" : 13,
      "context" : "The following lemma states the most important for us property of the sequences having the defensive property originally proven in [15].",
      "startOffset" : 130,
      "endOffset" : 134
    } ],
    "year" : 2010,
    "abstractText" : "We study prediction with expert advice in the setting where the losses are accumulated with some discounting and the impact of old losses can gradually vanish. We generalize the Aggregating Algorithm and the Aggregating Algorithm for Regression, propose a new variant of exponentially weighted average algorithm, and prove bounds on the cumulative discounted loss.",
    "creator" : "LaTeX with hyperref package"
  }
}