{
  "name" : "1703.02622.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "Online Convex Optimization with Unconstrained Domains and Losses",
    "authors" : [ "Ashok Cutkosky", "Kwabena Boahen" ],
    "emails" : [ "ashokc@cs.stanford.edu", "boahen@stanford.edu" ],
    "sections" : [ {
      "heading" : "1 Online Convex Optimization",
      "text" : "Online Convex Optimization (OCO) [1, 2] provides an elegant framework for modeling noisy, antagonistic or changing environments. The problem can be stated formally with the help of the following definitions:\nConvex Set: A setW is convex ifW is contained in some real vector space and tw+(1− t)w′ ∈W for all w,w′ ∈W and t ∈ [0, 1].\nConvex Function: f :W → R is a convex function if f(tw + (1− t)w′) ≤ tf(w) + (1− t)f(w′) for all w,w′ ∈W and t ∈ [0, 1].\nAn OCO problem is a game of repeated rounds in which on round t a learner first chooses an element wt in some convex space W , then receives a convex loss function `t, and suffers loss `t(wt). The regret of the learner with respect to some other u ∈W is defined by\nRT (u) = T∑ t=1 `t(wt)− `t(u)\nThe objective is to design an algorithm that can achieve low regret with respect to any u, even in the face of adversarially chosen `t.\nMany practical problems can be formulated as OCO problems. For example, the stochastic optimization problems found widely throughout machine learning have exactly the same form, but with i.i.d. loss functions, a subset of the OCO problems. In this setting the goal is to identify a vector w? with low generalization error (E[`(w?)− `(u)]). We can solve this by running an OCO algorithm for T rounds and setting w? to be the average value of wt. By online-to-batch conversion results [3, 4], the generalization error is bounded by the expectation of the regret over the `t divided by T . Thus, OCO algorithms can be used to solve stochastic optimization problems while also performing well in non-i.i.d. settings.\n30th Conference on Neural Information Processing Systems (NIPS 2016), Barcelona, Spain.\nar X\niv :1\n70 3.\n02 62\n2v 1\n[ cs\n.L G\n] 7\nM ar\n2 01\nThe regret of an OCO problem is upper-bounded by the regret on a corresponding Online Linear Optimization (OLO) problem, in which each `t is further constrained to be a linear function: `t(w) = gt · wt for some gt. The reduction follows, with the help of one more definition:\nSubgradient: g ∈W is a subgradient of f at w, denoted g ∈ ∂f(w), if and only if f(w)+ g · (w′− w) ≤ f(w′) for all w′. Note that ∂f(w) 6= ∅ if f is convex.1\nTo reduce OCO to OLO, suppose gt ∈ ∂`t(wt), and consider replacing `t(w) with the linear approximation gt · w. Then using the definition of subgradient,\nRT (u) = T∑ t=1 `t(wt)− `t(u) ≤ T∑ t=1 gt(wt − u) = T∑ t=1 gtwt − gtu\nso that replacing `t(w) with gt · w can only make the problem more difficult. All of the analysis in this paper therefore addresses OLO, accessing convex losses functions only through subgradients.\nThere are two major factors that influence the regret of OLO algorithms: the size of the space W and the size of the subgradients gt. When W is a bounded set (the “constrained” case), then given B = maxw∈W ‖w‖, there exist OLO algorithms [5, 6] that can achieve RT (u) ≤ O ( BLmax √ T )\nwithout knowing Lmax = maxt ‖gt‖. When W is unbounded (the “unconstrained” case), then given Lmax, there exist algorithms [7, 8, 9] that achieve RT (u) ≤ Õ(‖u‖ log(‖u‖)Lmax √ T ) or\nRt(u) ≤ Õ(‖u‖ √ log(‖u‖)Lmax √ T ), where Õ hides factors that depend logarithmically on Lmax and T . These algorithms are known to be optimal (up to constants) for their respective regimes [7, 10]. All algorithms for the unconstrained setting to-date require knowledge of Lmax to achieve these optimal bounds.2 Thus a natural question is: can we achieve O(‖u‖ log(‖u‖)) regret in the unconstrained, unknown-Lmax setting? This problem has been posed as a COLT 2016 open problem [12], and is solved in this paper.\nA simple approach is to maintain an estimate of Lmax and double it whenever we see a new gt that violates the assumed bound (the so-called “doubling trick”), thereby turning a known-Lmax algorithm into an unknown-Lmax algorithm. This strategy fails for previous known-Lmax algorithms because their analysis makes strong use of the assumption that each and every ‖gt‖ is bounded by Lmax. The existence of even a small number of bound-violating gt can throw off the entire analysis.\nIn this paper, we prove that it is actually impossible to achieve regret\nO ( ‖u‖ log(‖u‖)Lmax √ T + Lmax exp [( maxt ‖gt‖ L(t) )1/2− ]) for any > 0 where Lmax\nand L(t) = maxt′<t ‖gt′‖ are unknown in advance (Section 2). This immediately rules out the “ideal” bound of Õ(‖u‖ √ log(‖u‖)Lmax √ T ) which is possible in the known-Lmax case. Secondly, we provide an algorithm, RESCALEDEXP, that matches our lower bound without prior knowledge of Lmax, leading to a naturally hyperparameter-free algorithm (Section 3). To our knowledge, this is the first algorithm to address the unknown-Lmax issue while maintaining O(‖u‖ log ‖u‖) dependence on u. Finally, we present empirical results showing that RESCALEDEXP performs well in practice (Section 4).\n2 Lower Bound with Unknown Lmax\nThe following theorem rules out algorithms that achieve regret O(u log(u)Lmax √ T ) without prior knowledge of Lmax. In fact, any such algorithm must pay an up-front penalty that is exponential in T . This lower bound resolves a COLT 2016 open problem (Parameter-Free and Scale-Free Online Algorithms) [12] in the negative.\n1In full generality, a subgradient is an element of the dual space W ∗. However, we will only consider cases where the subgradient is naturally identified with an element in the original space W (e.g. W is finite dimensional) so that the definition in terms of dot-products suffices.\n2There are algorithms that do not require Lmax, but achieve only regret O(‖u‖2) [11]\nTheorem 1. For any constants c, k, > 0, there exists a T and an adversarial strategy picking gt ∈ R in response to wt ∈ R such that regret is:\nRT (u) = T∑ t=1 gtwt − gtu\n≥ (k + c‖u‖ log ‖u‖)Lmax √ T log(Lmax + 1) + kLmax exp((2T ) 1/2− )\n≥ (k + c‖u‖ log ‖u‖)Lmax √ T log(Lmax + 1) + kLmax exp [( max t ‖gt‖ L(t) )1/2− ] for some u ∈ R where Lmax = maxt≤T ‖gt‖ and L(t) = maxt′<t ‖gt′‖.\nProof. We prove the theorem by showing that for sufficiently large T , the adversary can “checkmate” the learner by presenting it only with the subgradient gt = −1. If the learner fails to have wt increase quickly, then there is a u 1 against which the learner has high regret. On the other hand, if the learner ever does make wt higher than a particular threshold, the adversary immediately punishes the learner with a subgradient gt = 2T , again resulting in high regret.\nLet T be large enough such that both of the following hold: T 4 exp( T 1/2 4 log(2)c ) > k log(2) √ T + k exp((2T )1/2− ) (1)\nT 2 exp(\nT 1/2 4 log(2)c ) > 2kT exp((2T ) 1/2− ) + 2kT\n√ T log(2T + 1) (2)\nThe adversary plays the following strategy: for all t ≤ T , so long as wt < 12 exp(T 1/2/4 log(2)c), give gt = −1. As soon as wt ≥ 12 exp(T 1/2/4 log(2)c), give gt = 2T and gt = 0 for all subsequent t. Let’s analyze the regret at time T in these two cases.\nCase 1: wt < 12 exp(T 1/2/4 log(2)c) for all t:\nIn this case, let u = exp(T 1/2/4 log(2)c). Then Lmax = 1, maxt ‖gt‖ L(t) = 1, and using (1) the learner’s regret is at least\nRT (u) ≥ Tu− T 1\n2 exp( T\n1/2\n4 log(2)c )\n= 12Tu = cu log(u) √ T log(2) + T4 exp( T 1/2 4 log(2)c ) > cu log(u)Lmax √ T log(Lmax + 1) + kLmax √ T log(Lmax + 1) + kLmax exp((2T ) 1/2− ) = (k + cu log u)Lmax √ T log(Lmax + 1) + kLmax exp [ (2T ) 1/2− ]\nCase 2: wt ≥ 12 exp(T 1/2/4 log(2)c) for some t:\nIn this case, Lmax = 2T and maxt ‖gt‖ L(t) = 2T . For u = 0, using (2), the regret is at least\nRT (u) ≥ T2 exp( T 1/2 4 log(2)c )\n≥ 2kT exp((2T )1/2− ) + 2kT √ T log(2T + 1)\n= kLmax exp((2T ) 1/2− ) + kLmax √ T log(Lmax + 1) = (k + cu log u)Lmax √ T log(Lmax + 1) + kLmax exp [ (2T ) 1/2− ]\nThe exponential lower-bound arises because the learner has to move exponentially fast in order to deal with exponentially far away u, but then experiences exponential regret if the adversary provides a gradient of unprecedented magnitude in the opposite direction. However, if we play against an adversary that is constrained to give loss vectors ‖gt‖ ≤ Lmax for some Lmax that does not grow with time, or if the losses do not grow too quickly, then we can still achieve RT (u) = O(‖u‖ log(‖u‖)Lmax √ T ) asymptotically without knowing Lmax. In the following sections we describe an algorithm that accomplishes this."
    }, {
      "heading" : "3 RESCALEDEXP",
      "text" : "Our algorithm, RESCALEDEXP, adapts to the unknown Lmax using a guess-and-double strategy that is robust to a small number of bound-violating gts. We initialize a guess L for Lmax to ‖g1‖. Then we run a novel known-Lmax algorithm that can achieve good regret in the unconstrained u setting. As soon as we see a gt with ‖gt‖ > 2L, we update our guess to ‖gt‖ and restart the known-Lmax algorithm. To prove that this scheme is effective, we show (Lemma 3) that our known-Lmax algorithm does not suffer too much regret when it sees a gt that violates its assumed bound.\nOur known-Lmax algorithm uses the Follow-the-Regularized-Leader (FTRL) framework. FTRL is an intuitive way to design OCO algorithms [13]: Given functions ψt : W → R, at time T we play wT = argmin [ ψT−1(w) + ∑T−1 t=1 `t(w) ] . The functions ψt are called regularizers. A large number of OCO algorithms (e.g. gradient descent) can be cleanly formulated as instances of this framework.\nOur known-Lmax algorithm is FTRL with regularizers ψt(w) = ψ(w)/ηt, where ψ(w) = (‖w‖+ 1) log(‖w‖+ 1)− ‖w‖ and ηt is a scale-factor that we adapt over time. Specifically, we set η−1t = k √ 2 √ Mt + ‖g‖21:t, where we use the compressed sum notations g1:T = ∑T t=1 gt and ‖g‖21:T =∑T\nt=1 ‖gt‖2. Mt is defined recursively by M0 = 0 and Mt = max(Mt−1, ‖g1:t‖/p − ‖g‖21:t), so that Mt ≥Mt−1, and Mt + ‖g‖21:t ≥ ‖g1:t‖/p. k and p are constants: k = √ 2 and p = L−1max.\nRESCALEDEXP’s strategy is to maintain an estimate Lt of Lmax at all time steps. Whenever it observes ‖gt‖ ≥ 2Lt, it updates Lt+1 = ‖gt‖. We call periods during which Lt is constant epochs. Every time it updates Lt, it restarts our known-Lmax algorithm with p = 1Lt , beginning a new epoch. Notice that since Lt at least doubles every epoch, there will be at most log2(Lmax/L1) + 1 total epochs. To address edge cases, we set wt = 0 until we suffer a non-constant loss function, and we set the initial value of Lt to be the first non-zero gt. Pseudo-code is given in Algorithm 1, and Theorem 2 states our regret bound. For simplicity, we re-index so that that g1 is the first non-zero gradient received. No regret is suffered when gt = 0 so this does not affect our analysis.\nAlgorithm 1 RESCALEDEXP Initialize: k ← √ 2, M0 ← 0, w1 ← 0, t? ← 1 // t? is the start-time of the current epoch.\nfor t = 1 to T do Play wt, receive subgradient gt ∈ ∂`t(wt). if t = 1 then L1 ← ‖g1‖ p← 1/L1\nend if Mt ← max(Mt−1, ‖gt?:t‖/p− ‖g‖2t?:t). ηt ← 1\nk √\n2(Mt+‖g‖2t?:t) //Set wt+1 using FTRL update wt+1 ← − gt?:t‖gt?:t‖ [exp(ηt‖gt?:t‖)− 1] // = argminw [ ψ(w) ηt + gt?:tw ] if ‖gt‖ > 2Lt then //Begin a new epoch: update L and restart FTRL Lt+1 ← ‖gt‖ p← 1/Lt+1 t? ← t+ 1 Mt ← 0 wt+1 ← 0 else Lt+1 ← Lt\nend if end for\nTheorem 2. Let W be a separable real inner-product space with corresponding norm ‖ · ‖ and suppose (with mild abuse of notation) every loss function `t :W → R has some subgradient gt ∈W ∗ at wt such that gt(w) = gt ·w for some gt ∈W . Let Mmax = maxtMt. Then if Lmax = maxt ‖gt‖\nand L(t) = maxt′<t ‖gt‖, rescaledexp achieves regret: RT (u) ≤ (2ψ(u) + 96) ( log2 ( Lmax L1 ) + 1 )√ Mmax + ‖g‖21:T\n+ 8Lmax ( log2 ( Lmax L1 ) + 1 ) min [ exp ( 8max t ‖gt‖2 L(t)2 ) , exp( √ T/2) ] = O ( Lmax log ( Lmax L1 )[ (‖u‖ log(‖u‖) + 2) √ T + exp ( 8max t ‖gt‖2 L(t)2\n)]) The conditions on W in Theorem 2 are fairly mild. In particular they are satisfied whenever W is finite-dimensional and in most kernel method settings [14]. In the kernel method setting, W is an RKHS of functions X → R and our losses take the form `t(w) = `t(〈w, kxt〉) where kxt is the representing element in W of some xt ∈ X , so that gt = gtkxt where gt ∈ ∂`t(〈w, kxt〉).\nAlthough we nearly match our lower-bound exponential term of exp((2T )1/2− ), in order to have a practical algorithm we need to do much better. Fortunately, the maxt ‖gt‖2 L(t)2 term may be significantly smaller when the losses are not fully adversarial. For example, if the loss vectors gt satisfy ‖gt‖ = t2, then the exponential term in our bound reduces to a manageable constant even though ‖gt‖ is growing quickly without bound.\nTo prove Theorem 2, we bound the regret of RESCALEDEXP during each epoch. Recall that during an epoch, RESCALEDEXP is running FTRL with ψt(w) = ψ(w)/ηt. Therefore our first order of business is to analyze the regret of FTRL across one of these epochs, which we do in Lemma 3 (proved in appendix): Lemma 3. Set k = √ 2. Suppose ‖gt‖ ≤ L for t < T , 1/L ≤ p ≤ 2/L, gT ≤ Lmax and Lmax ≥ L. Let Wmax = maxt∈[1,T ] ‖wt‖. Then the regret of FTRL with regularizers ψt(w) = ψ(w)/ηt is:\nRT (u) ≤ ψ(u)/ηT + 96 √ MT + ‖g‖21:T + 2Lmax min [ Wmax, 4 exp ( 4 L2max L2 ) , exp( √ T/2) ]\n≤ (2ψ(u) + 96) √√√√T−1∑ t=1 L|gt|+ L2max + 8Lmax min [ exp ( 4L2max L2 ) , exp( √ T/2) ] ≤ Lmax(2((‖u‖+ 1) log(‖u‖+ 1)− ‖u‖) + 96) √ T + 8Lmax min [ e 4L2max L2 , e √ T/2\n] Lemma 3 requires us to know the value of L in order to set p. However, the crucial point is that it encompasses the case in which L is misspecified on the last loss vector. This allows us to show that RESCALEDEXP does not suffer too much by updating p on-the-fly.\nProof of Theorem 2. The theorem follows by applying Lemma 3 to each epoch in which Lt is constant.\nLet 1 = t1, t2, t3, · · · , tn be the various increasing values of t? (as defined in Algorithm 1), and we define tn+1 = T + 1. Then define\nRa:b(u) = b−1∑ t=a gt(wt − u)\nso that RT (u) ≤ ∑n j=1Rtj :tj+1(u). We will bound Rtj :tj+1(u) for each j. Fix a particular j < n. Then Rtj :tj+1(u) is simply the regret of FTRL with k = √ 2, p = 1Ltj , ηt = 1\nk √\n2(Mt+‖g‖2tj :t) and regularizers ψ(w)/ηt. By definition of Lt, for t ∈ [1, tj+1 − 2] we have\n‖gt‖ ≤ 2Ltj . Further, if L = maxt∈[1,tj+1−2] ‖gt‖ we have L ≥ Ltj . Therefore, Ltj ≤ L ≤ 2Ltj so that 1L ≤ p ≤ 2 L . Further, we have ‖gtj+1−1‖/Ltj ≤ 2maxt ‖gt‖/L(t). Thus by Lemma 3 we\nhave Rtj :tj+1(u) ≤ ψ(u)/ηtj+1−1 + 96 √ Mtj+1−1 + ‖g‖2tj :tj+1−1\n+ 2Lmax min [ Wmax, 4 exp ( 4 ‖gtj+1−1‖2\nL2tj\n) , exp (√ tj+1 − tj√\n2\n)]\n≤ ψ(u)/ηtj+1−1 + 96 √ Mmax + ‖g‖2tj :tj+1−1 + 8Lmax min [ e 8maxt ‖gt‖2 L(t)2 , e √ T/2 ] ≤ (2ψ(u) + 96) √ Mmax + ‖g‖21:T + 8Lmax min [ exp ( 8max\nt\n‖gt‖2\nL(t)2\n) , exp( √ T/2) ] Summing across epochs, we have\nRT (u) = n∑ j=1 Rtj :tj+1(u)\n≤ n [ (2ψ(u) + 96) √ Mmax + ‖g‖21:T + 8Lmax min [ exp ( 8max\nt\n‖gt‖2\nL(t)2\n) , exp (√ T/2 )]]\nObserve that n ≤ log2(Lmax/L1) + 1 to prove the first line of the theorem. The big-Oh expression follows from the inequality: Mtj+1−1 ≤ Ltj ∑tj+1−1 t=tj ‖gt‖ ≤ Lmax ∑T t=1 ‖gt‖.\nOur specific choices for k and p are somewhat arbitrary. We suspect (although we do not prove) that the preceding theorems are true for larger values of k and any p inversely proportional to Lt, albeit with differing constants. In Section 4 we perform experiments using the values for k, p and Lt described in Algorithm 1. In keeping with the spirit of designing a hyperparameter-free algorithm, no attempt was made to empirically optimize these values at any time."
    }, {
      "heading" : "4 Experiments",
      "text" : ""
    }, {
      "heading" : "4.1 Linear Classification",
      "text" : "To validate our theoretical results in practice, we evaluated RESCALEDEXP on 8 classification datasets. The data for each task was pulled from the libsvm website [15], and can be found individually in a variety of sources [16, 17, 18, 19, 20, 21, 22]. We use linear classifiers with hinge-loss for each task and we compare RESCALEDEXP to five other optimization algorithms: ADAGRAD [5], SCALEINVARIANT [23], PISTOL [24], ADAM [25], and ADADELTA [26]. Each of these algorithms requires tuning of some hyperparameter for unconstrained problems with unknown Lmax (usually a scale-factor on a learning rate). In contrast, our RESCALEDEXP requires no such tuning.\nWe evaluate each algorithm with the average loss after one pass through the data, computing a prediction, an error, and an update to model parameters for each example in the dataset. Note that this is not the same as a cross-validated error, but is closer to the notion of regret addressed in our theorems. We plot this average loss versus hyperparameter setting for each dataset in Figures 1 and 2. These data bear out the effectiveness of RESCALEDEXP: while it is not unilaterally the highest performer on all datasets, it shows remarkable robustness across datasets with zero manual tuning."
    }, {
      "heading" : "4.2 Convolutional Neural Networks",
      "text" : "We also evaluated RESCALEDEXP on two convolutional neural network models. These models have demonstrated remarkable success in computer vision tasks and are becoming increasingly more popular in a variety of areas, but can require significant hyperparameter tuning to train. We consider the MNIST [18] and CIFAR-10 [27] image classification tasks.\nOur MNIST architecture consisted of two consecutive 5×5 convolution and 2×2 max-pooling layers followed by a 512-neuron fully-connected layer. Our CIFAR-10 architecture was two consecutive 5× 5 convolution and 3× 3 max-pooling layers followed by a 384-neuron fully-connected layer and a 192-neuron fully-connected layer.\nThese models are highly non-convex, so that none of our theoretical analysis applies. Our use of RESCALEDEXP is motivated by the fact that in practice convex methods are used to train these models. We found that RESCALEDEXP can match the performance of other popular algorithms (see Figure 3).\nIn order to achieve this performance, we made a slight modification to RESCALEDEXP: when we update Lt, instead of resetting wt to zero, we re-center the algorithm about the previous prediction point. We provide no theoretical justification for this modification, but only note that it makes intuitive sense in stochastic optimization problems, where one can reasonably expect that the previous prediction vector is closer to the optimal value than zero."
    }, {
      "heading" : "5 Conclusions",
      "text" : "We have presented RESCALEDEXP, an Online Convex Optimization algorithm that achieves regret Õ(‖u‖ log(‖u‖)Lmax √ T + exp(8maxt ‖gt‖2/L(t)2)) where Lmax = maxt ‖gt‖ is unknown in advance. Since RESCALEDEXP does not use any prior-knowledge about the losses or comparison vector u, it is hyperparameter free and so does not require any tuning of learning rates. We also prove a lower-bound showing that any algorithm that addresses the unknown-Lmax scenario must suffer an exponential penalty in the regret. We compare RESCALEDEXP to prior optimization algorithms empirically and show that it matches their performance.\nWhile our lower-bound matches our regret bound for RESCALEDEXP in terms of T , clearly there is much work to be done. For example, when RESCALEDEXP is run on the adversarial loss sequence presented in Theorem 1, its regret matches the lower-bound, suggesting that the optimality gap could be improved with superior analysis. We also hope that our lower-bound inspires work in algorithms that adapt to non-adversarial properties of the losses to avoid the exponential penalty."
    }, {
      "heading" : "A Follow-the-Regularized-Leader (FTRL) Regret",
      "text" : "Recall that the FTRL algorithm uses the strategy wt+1 = argminψt(w) + ∑t t′=1 `t′(w), where the functions ψt are called regularizers. Theorem 4. FTRL with regularizers ψt and ψ0(w1) = 0 obtains regret:\nRt(u) ≤ ψT (u) + T∑ t=1 ψt−1(wt+1)− ψt(wt+1) + `t(wt)− `t(wt+1) (3)\nFurther, if the losses are linear `t(w) = gt · w and ψt(w) = 1ηtψ(w) for some values ηt and fixed function ψ, then the regret is\nRt(u) ≤ 1\nηT ψ(u) + T∑ t=1 ( 1 ηt−1 − 1 ηt ) ψ(wt+1) + gt · (wt − wt+1) (4)\nProof. The first part follows from some algebraic manipulations: T∑ t=1 `t(u) + ψT (u) ≥ ψT (wT+1) + T∑ t=1 `t(wT+1)\n− T∑ t=1 `t(u) ≤ ψT (u)− ψT (wT+1)− T∑ t=1 `t(wT+1)\nRT (u) = T∑ t=1 `t(wt)− T∑ t=1 `t(u)\n≤ ψT (u)− ψT (wT+1) + T∑ t=1 `t(wt)− `t(wT+1)\n= ψT (u)− ψT (wT+1) + `T (wT )− `T (wT+1) +RT−1(wT+1) ≤ ψT (u)− ψT (wT+1) + `T (wT )− `T (wT+1)+\n+ T−1∑ t=1 ψt(wt+2)− ψt(wt+1) + `t(wt)− `t(wt+1)\n= ψT (u) + `1(w1)− `1(w2)− ψ1(w2)\n+ T∑ t=2 ψt−1(wt+1)− ψt(wt+1) + `t(wt)− `t(wt+1)\n= ψT (u) + T∑ t=1 ψt−1(wt+1)− ψt(wt+1) + `t(wt)− `t(wt+1)\nwhere we’re assuming ψ0(w1) = 0 in the last step.\nNow let’s specialize to the case of linear losses `t(w) = gt · w and regularizers of the form ψt(w) = 1ηtψ(w) for some fixed regularizer ψ and varying scalings ηt. Plugging this into the previous bound gives:\nRt(u) ≤ 1\nηT ψ(u) + T∑ t=1 ( 1 ηt−1 − 1 ηt ) ψ(wt+1) + gt · (wt − wt+1)\nWhile this formulation of the regret of FTRL is sufficient for our needs, our analysis is not tight. We refer the reader to [28] for a stronger FTRL bound that can improve constants in some analyses."
    }, {
      "heading" : "B Proof of Lemma 3",
      "text" : "We start off by computing the FTRL updates with regularizers ψ(w)/ηt:\n∇ψ(w) = log(‖w‖+ 1) w‖w‖\nso that\nwT+1 = argmin 1\nηT ψ(w) + T∑ t=1 gt · w\n= − g1:t‖g1:t‖ (exp(ηT ‖g1:T ‖)− 1)\nOur goal will be to show that the terms (\n1 ηt−1 − 1 ηt\n) ψ(wt+1)+ gt · (wt−wt+1) in the sum in (4) are negative.\nIn particular, note that sequence of ηt is non-increasing so that (\n1 ηt−1 − 1 ηt\n) ψ(wt+1) ≤ 0 for all t. Thus our\nstrategy will be to bound gt · (wt − wt+1)."
    }, {
      "heading" : "B.1 Reduction to one dimension",
      "text" : "In order to bound (\n1 ηt−1 − 1 ηt\n) ψ(wt+1) + gt · (wt − wt+1), we first show that it suffices to consider the case\nwhen gt and g1:t−1 are co-linear.\nTheorem 5. Let W be a separable inner-product space and suppose (with mild abuse of notation) every loss function `t :W → R has some subgradient gt ∈W ∗ such that gtw = 〈gt, w〉 for some gt ∈W . Suppose we run an FTRL algorithm with regularizers 1\nηt ψ(‖w‖) on loss functions `t such that wt+1 = g1:t‖g1:t‖f(ηt‖g1:t‖)\nfor some function f for all t where ηt = c√ Mt+‖g‖21:t for some constant c. Then for any gt with ‖gt‖ = L, both (η−1t−1 − η −1 t )ψ(‖wt+1‖) + gt(wt − wt+1) and gt(wt − wt+1) are maximized when gt is a scalar multiple of g1:t−1.\nProof. The proof is an application of Lagrange multipliers. Our Lagrangian for (η−1t−1 − η −1 t )ψ(‖wt+1‖) + gt(wt − wt+1) is\nL = (η−1t−1 − η −1 t )ψ(‖wt+1‖) + gt(wt − wt+1) + λ‖gt‖2/2\n= (η−1t−1 − η −1 t )ψ(f(ηt‖g1:t‖)) + gt ( wt −\ng1:t ‖g1:t‖\nf(ηt‖g1:t‖) ) + λ ‖gt‖2\n2\nFix a countable orthonormal basis of W . For a vector v ∈W we let vi be the projection of v along the ith basis vector of our countable orthonormal basis. We denote the action of∇L on the ith basis vector by∇Li.\nThen we have\n∇Li = λgt,i + wt,i − wt+1,i − gt,i ‖g1:t‖ f(ηt‖g1:t‖)\n+ ∑ j gt,j(g1:t)j ‖g1:t‖3 (g1:t)if(ηt‖g1:t‖) − ∑ j (g1:t)jgt,j ‖g1:t‖ f ′(ηt‖g1:t‖)  (g1:t)iηt ‖g1:t‖ − ‖g1:t‖c ( ∂Mt ∂gt,i + 2gt,i ) 2(Mt + ‖g‖21:t)3/2\n + (η−1t−1 − η −1 t )ψ ′(f(ηt‖g1:t‖))f ′(ηt‖g1:t‖)  (g1:t)iηt ‖g1:t‖ − ‖g1:t‖c ( ∂Mt ∂gt,i + 2gt,i ) 2(Mt + ‖g‖21:t)3/2\n − ψ(f(ηt‖g1:t‖)) ∂Mt ∂gt,i + 2gt,i\n2c √ Mt + ‖g‖21:t\n= λgt,i + wt,i − wt+1,i +Agt,i +B(g1:t−1)i + C ∂Mt ∂gt,i\nwhere A, B and C do not depend on i. Since wt,i and wt+1,i are scalar multiples of g1:t−1 and g1:t respectively, we can reassign the variables A and B to write\n∇Li = Agt,i +B(g1:t−1)i + C ∂Mt ∂gt,i\nNow we compute\n∂Mt ∂gt,i = ∂max(Mt−1, ‖g1:t‖/p− ‖g‖21:t) ∂gt,i\n= { 0 :Mt =Mt−1 (g1:t)i p‖g1:t‖\n− 2gt,i :Mt 6=Mt−1 Thus after again reassigning the variables A and B we have\n∇Li = Agt,i +B(g1:t−1)i\nTherefore we can only have∇L = 0 if gt is a scalar multiple of g1:t−1 as desired.\nFor gt(wt − wt+1), we apply exactly the same argument. The Lagrangian is L = gt(wt − wt+1) + λ‖gt‖2/2\n= gt ( wt −\ng1:t ‖g1:t‖\nf(ηt‖g1:t‖) ) + λ ‖gt‖2\n2\nand differentiating we have\n∇Li = λgt,i + wt,i − wt+1,i − gt,i ‖g1:t‖ f(ηt‖g1:t‖)\n+ ∑ j gt,j(g1:t)j ‖g1:t‖3 (g1:t)if(ηt‖g1:t‖) − ∑ j (g1:t)jgt,j ‖g1:t‖ f ′(ηt‖g1:t‖)  (g1:t)iηt ‖g1:t‖ − ‖g1:t‖c ( ∂Mt ∂gt,i + 2gt,i ) 2(Mt + ‖g‖21:t)3/2\n = λgt,i + wt,i − wt+1,i +Agt,i +B(g1:t−1)i + C\n∂Mt ∂gt,i\n= Agt,i +B(g1:t−1)i\nso that again we are done.\nWe make the following intuitive definition: Definition 6. For any vector v ∈W , define sign(v) = v‖v‖ .\nIn the next section, we prove bounds on the quantity (η−1t−1 − η −1 t )ψ(‖wt+1‖) + gt(wt − wt+1). By Theorem 5 this quantity is maximized when sign(gt) = ±sign(g1:t−1) and so we consider only this case."
    }, {
      "heading" : "B.2 One dimensional FTRL",
      "text" : "In this section we analyze the regret of our FTRL algorithm with the end-goal of proving Lemma 3. We make heavy use of Theorem 5 to allow us to consider only the case sign(gt) = ±sign(g1:t−1). In this setting we may identify the 1-dimensional space spanned by gt and g1:t−1 with R. Thus whenever we are operating under the assumption sign(gt) = sign(g1:t−1) we will use | · | in place of ‖ · ‖ and occasionally assume g1:t−1 > 0 as this holds WLOG. We feel that this notation and assumption aids intuition in visualizing the following results. Lemma 7. Suppose sign(gt) = sign(g1:t−1). Then\n|ηt−1‖g1:t−1‖ − ηt‖g1:t‖| ≤ ηt‖gt‖ (5) Suppose instead that sign(gt) = −sign(g1:t−1) and also ‖gt‖ ≤ L. Then we still have:\n|ηt−1‖g1:t−1‖ − ηt‖g1:t‖| ≤ ( 1 + pL\n2\n) ηt‖gt‖ (6)\nProof. First, suppose sign(gt) = sign(g1:t−1). Then sign(g1:t) = sign(g1:t−1). WLOG, assume g1:t−1 > 0. Notice that ηtg1:t is an increasing function of gt for gt > 0 because ηtg1:t is proportional to either g1:t or √ g1:t depending on whether Mt =Mt−1 or not. Then since ηt < ηt−1 we have |ηt−1g1:t−1 − ηtg1:t| = ηtg1:t − ηt−1g1:t−1\n≤ ηtg1:t − ηtg1:t−1 = ηt|gt|\nso that (5) holds.\nNow suppose sign(gt) = −sign(g1:t−1) and ‖gt‖ ≤ L. We consider two cases.\nCase 1: ηt|g1:t| ≥ ηt−1|g1:t−1|:\nSince ηt−1 ≥ ηt, we have ηt|g1:t| ≥ ηt−1|g1:t−1| ηt|g1:t| ≥ ηt|g1:t−1| |g1:t| ≥ |g1:t−1| |gt| ≥ |g1:t|\nwhere the last line follows since sign(g1:t−1) = −sign(gt). Therefore: |ηt−1|g1:t−1| − ηt|g1:t|| ≤ ηt|g1:t| ≤ ηt|gt|\nso that we are done.\nCase 2: ηt|g1:t| ≤ ηt−1|g1:t−1|:\nWhen gt < −g1:t−1 and ηt|g1:t| ≤ ηt−1|g1:t−1|, |ηt−1|g1:t−1| − ηt|g1:t|| is a decreasing function of |gt| because ηt|gt:1| is an increasing function of |gt| for gt < −g1:t−1. Therefore it suffices to consider the case gt ≥ −g1:t−1, so that sign(g1:t) = sign(g1:t−1) and |g1:t| ≤ |g1:t−1|:\nSince |g1:t| ≤ |g1:t−1|, we have Mt =Mt−1 so that we can write: ηt−1g1:t−1 − ηtg1:t = −gtηt + g1:t−1(ηt−1 − ηt)\n= |gt|ηt + g1:t−1  1 k √ 2 √ Mt−1 + ‖g‖21:t−1 − 1 k √ 2 √ Mt + ‖g‖21:t−1 + g2t  = |gt|ηt + g1:t−1\nk √ 2  1√ Mt−1 + ‖g‖21:t−1 − 1√ Mt−1 + ‖g‖21:t−1 + g2t  ≤ |gt|ηt + g1:t−1\nk √ 2 √ Mt + ‖g‖21:t−1 + g2t  √ Mt−1 + ‖g‖21:t−1 + g2t√ Mt−1 + ‖g‖21:t−1 − 1  ≤ |gt|ηt + g1:t−1ηt ( 1 +\ng2t 2(Mt−1 + ‖g‖21:t−1)\n− 1 )\n≤ |gt|ηt + ηt g1:t−1g\n2 t\n2(Mt−1 + ‖g‖21:t−1)\n≤ |gt|ηt(1 + pL\n2 ) we have used the identity √ X + g2t ≤ √ X + g2t 2 √ X\nbetween lines 4 and 5, and the last line follows because |gt| ≤ L and Mt−1 + ‖g‖21:t−1 ≥ |g1:t−1|/p.\nLemma 8. If\n‖wT ‖ ≥ exp (√ pB\nk √ 2\n) − 1\nthen ‖g1:T−1‖ ≥ B\nProof. First note that by definition of MT−1 and ηT−1, ηT−1‖g1:T−1‖ ≤ √ p‖g1:T−1‖ k √ 2\n. The proof now follows from some algebra:\nexp\n(√ pB\nk √ 2\n) ≤ ‖wT ‖+ 1\n= exp(ηT−1‖g1:T−1‖)\n≤ exp (√ p‖g1:T−1‖ k √ 2 )\nTaking squares of logs and rearranging now gives the desired inequality.\nWe have the following immediate corollary:\nCorollary 9. Suppose sign(gt) = ±sign(g1:t−1), ‖gt‖ ≤ L, and ‖wt‖ ≥ exp (√ pL\nk √ 2\n) − 1\nThen sign(g1:t) = sign(g1:t−1).\nNow we begin analysis of the sum term in (4).\nLemma 10. Suppose sign(g1:t) = sign(g1:t−1) and |gt| ≤ L. Then |wt − wt+1| ≤ |gt|ηt(|wt+1|+ 1) ( 1 + pL\n2\n) exp [ gtηt ( 1 + pL\n2 )] Proof. Since sign(g1:t) = sign(g1:t−1), we have:\n|wt − wt+1| = |sign(g1:t−1) [exp (ηt−1|g1:t−1|)− 1]− [sign(g1:t) exp (ηt|g1:t|)− 1]| = |exp (ηt−1|g1:t−1|)− exp (ηt|g1:t|)| = (|wt+1|+ 1) |exp (ηt−1|g1:t−1| − ηt|g1:t|)− 1|\nwhere the last line uses the definition of wt+1 to observe that |wt+1|+ 1 = exp(ηt|g1:t|). Now we consider two cases: either ηt−1|g1:t−1| < ηt|g1:t| or not.\nCase 1: ηt−1|g1:t−1| < ηt|g1:t|:\nBy convexity of exp, we have\n|wt − wt+1| ≤ (|wt+1|+ 1) |exp (ηt−1|g1:t−1| − ηt|g1:t|)− 1| ≤ (|wt+1|+ 1) |ηt−1|g1:t−1| − ηt|g1:t||\n≤ (|wt+1|+ 1) ( 1 + pL\n2\n) ηt|gt|\nso that the lemma holds.\nCase 2: ηt−1|g1:t−1| ≥ ηt|g1:t|:\nAgain by convexity of exp we have\n|wt − wt+1| ≤ (|wt+1|+ 1) |exp (ηt−1|g1:t−1| − ηt|g1:t|)− 1| ≤ (|wt+1|+ 1) |ηt−1|g1:t−1| − ηt|g1:t|| exp (ηt−1|g1:t−1| − ηt|g1:t|)\n≤ (|wt+1|+ 1) ( 1 + pL\n2\n) exp [ ηt|gt| ( 1 + pL\n2\n)] ηt|gt|\nso that the lemma still holds.\nThe next lemma is the main workhorse of our regret bounds:\nLemma 11. Suppose ‖gt‖ ≤ L and either of the following holds:\n1. p ≤ 2 L\n, k = √ 2, and ‖wt‖ ≥ 15.\n2. k = √ 2, pL ≥ 1, and ‖wt‖ ≥ 4 exp(p2L2).\nThen ( 1\nηt−1 − 1 ηt\n) ψ(wt+1) + gt(wt − wt+1) ≤ 0 (7)\nFurther, inequality (7) holds for any k and sufficiently large L if ‖wt‖ ≥ exp((pL)2).\nProof. By Theorem 5 it suffices to consider the case sign(gt) = ±sign(g1:t−1), so that we may adopt our identification with R and use of | · | throughout this proof.\nFor p ≤ 2 L\n, k = √ 2 we have 15 > exp( √ pL\nk √ 2 )− 1 and for sufficiently large L, exp((pL)2) > exp(\n√ pL k √ 2 )− 1.\nTherefore in all cases |wt| ≥ exp( √ pL\nk √ 2 )− 1 so that by Corollary 9 and Lemma 10 we have gt · (wt − wt+1) ≤ ηtg2t (|wt+1|+ 1) ( 1 + pL\n2\n) exp [ ηtgt ( 1 + pL\n2\n)] (8)\nFirst, we prove that (7) is guaranteed if the following holds:\n|wt+1|+ 1 ≥ exp\n[ 1 + pL\n2\nk2 exp\n( ηtgt ( 1 + pL\n2\n)) + 1 ] (9)\nThe previous line (9) is equivalent to: k2(log(|wt+1|+ 1)− 1) ≥ ( 1 + pL\n2\n) exp ( ηtgt ( 1 + pL\n2\n)) (10)\nNotice that ψ(wt+1) = (|wt+1|+ 1)(log(|wt+1|+ 1)− 1) + 1 ≥ (|wt+1|+ 1)(log(|wt+1|+ 1)− 1). Then multiplying (10) by ηt|gt| we have\n(|wt+1|+ 1) ( 1 + pL\n2\n) exp [ ηt|gt| ( 1 + pL\n2\n)] ηt|gt| ≤ k2ηt|gt|ψ(wt+1) (11)\nCombining (8) and (11), we see that (9) implies\ngt · (wt − wt+1) ≤ k2ηtg2tψ(wt+1)\nNow we bound (\n1 ηt−1 − 1 ηt\n) ψ(wt+1):\n1 ηt−1 − 1 ηt\n= k √ 2 (√ Mt−1 + ‖g‖21:t−1 − √ Mt + ‖g‖21:t−1 + g2t )\n≤ k √ 2 √Mt + ‖g‖21:t−1 + g2t − g2t +Mt −Mt−1 2 √ Mt + ‖g‖21:t−1 + g2t −√Mt + ‖g‖21:t−1 + g2t \n≤ −k √ 2\ng2t 2 √ Mt + ‖g‖21:t\n= −k2ηtg2t\nThus when (9) holds we have( 1\nηt−1 − 1 ηt\n) ψ(wt+1) + gt(wt − wt+1) ≤ −k2ηtg2tψ(wt+1) + k2η2t g2tψ(wt+1) ≤ 0\nTherefore our objective is to show that our conditions on wt imply the condition (9) on wt+1.\nFirst, we bound ηtgt in terms of |wt|. Notice that\n|wt|+ 1 = exp  |g1:t−1| k √ 2 √ Mt−1 + ‖g‖21:t−1  ≤ exp (√ p √ |g1:t−1\nk √ 2 ) 2k2 log2(|wt|+ 1)\np ≤ |g1:t−1|\nUsing this we have:\nηtgt = gt k √ 2 √ Mt + ‖g‖21:t\n≤ gt k √ 2 √ Mt−1 + ‖g‖21:t−1 + g2t ≤ gt √ p\nk √ 2 √ |g1:t−1|+ pg2t\n≤ L √ p k √ 2 √ 2k2\np log2(|wt|+ 1) + pL2\nso that we can conclude:\nηtgt ≤ Lp k √ 2 √ 2k2 log2(|wt|+ 1) + p2L2 (12)\nFurther, by Lemma 7 we have\n|wt|+ 1 |wt+1|+ 1 = exp(ηt−1|g1:t−1| − ηt|g1:t|)\n≤ exp [ ηtgt ( 1 + pL\n2 )] Therefore we have\n|wt+1|+ 1 ≥ (|wt|+ 1) exp [ −ηtgt ( 1 + pL\n2\n)] (13)\nFrom (13), we see that (9) is guaranteed if we have |wt|+ 1 ≥ exp [ ηtgt ( 1 + pL\n2\n)] exp [ 1 + pL 2\nk2 exp\n( ηtgt ( 1 + pL\n2\n)) + 1 ] (14)\nIf we use our expression (12) in (14), and assume |wt| ≥ exp(L2), we see that there exists some constant C depending on p and k such that the RHS of (14) is O(exp(L)) and so (14) holds for sufficiently large L. For p = 2/L, k = √ 2, and wt ≥ 15 we can verify (14) numerically by plugging in the bound (12). For the case k = √ 2, |wt| ≥ 4 exp(p2L2), we notice that by using (12), we can write (14) entirely in terms of pL. Graphing both sides numerically as functions of pL then allows us to verify the condition.\nWe have one final lemma we need before we can start stating some real regret bounds. This lemma can be viewed as observing that ψ(w) is roughly 1\nD strongly-convex for |w| not much bigger than D.\nLemma 12. Suppose p ≤ 2/L, k = √ 2, ‖wt‖ ≤ D and ‖gt‖ ≤ L Then gt(wt − wt+1) ≤ 6(max(D + 1, exp(1/2)))g2t ηt.\nProof. By Theorem 5 it suffices to consider sign(gt) = ±sign(g1:t−1).\nWe show that |wt −wt+1| ≤ 6(max(D + 1, exp(1/2)))|gt|ηt so that the result follows by multiplying by |gt|. From Lemma 7, we have |ηt−1|g1:t−1| − ηt|g1:t|| ≤ ηt|gt| ( 1 + pL\n2\n) ≤ 2ηt|gt|. Further, note that ηt|gt| ≤\n1 k √ 2 = 1 2 . We consider two cases, either sign(g1:t) = sign(g1:t−1) or not.\nCase 1: sign(g1:t) = sign(g1:t−1):\n|wt − wt+1| = | exp(ηt−1|g1:t−1|)− exp(ηt|g1:t|)| = (|wt|+ 1)| exp(ηt|g1:t| − ηt−1|g1:t−1|)− 1| ≤ 2(D + 1)ηt|gt| exp(2ηt|gt|)\n≤ 2(D + 1)ηt|gt| exp ( 2\nk √ 2 ) ≤ 6(D + 1)ηt|gt|\nCase 2: sign(g1:t) 6= sign(g1:t−1): In this case, we must have |g1:t| ≤ |gt|. Let X = max(ηt|g1:t|, ηt−1|g1:t−1|). Then by triangle inequality we have\n|wt − wt+1| ≤ 2max(|wt|, |wt+1|) ≤ 2(exp(X)− 1) ≤ 2X exp(X) ≤ 2(max(|wt|, |wt+1|) + 1)X\nSince |ηt−1|g1:t−1| − ηt|g1:t|| ≤ 2ηtgt, we have X ≤ 2ηtgt + ηt|g1:t| ≤ 3ηt|gt| so that we have |wt − wt+1| ≤ 6(max(|wt|, |wt+1|) + 1)ηt|gt|\nFinally, we have |wt+1|+ 1 = exp(ηt|g1:t|) ≤ exp(ηt|gt|) ≤ exp(1/2), so that\n|wt − wt+1| ≤ 6ηt|gt|(max(|wt|, |wt+1|) + 1) ≤ 6max(D + 1, exp(1/2))ηt|gt|\nNow we are finally in a position to prove Lemma 3, which we re-state below: Lemma 3. Set k = √ 2. Suppose ‖gt‖ ≤ L for t < T , 1/L ≤ p ≤ 2/L, gT ≤ Lmax and Lmax ≥ L. Let Wmax = maxt∈[1,T ] ‖wt‖. Then the regret of FTRL with regularizers ψt(w) = ψ(w)/ηt is:\nRT (u) ≤ ψ(u)/ηT + 96 √ MT + ‖g‖21:T + 2Lmax min [ Wmax, 4 exp ( 4 L2max L2 ) , exp( √ T/2) ]\n≤ (2ψ(u) + 96) √√√√T−1∑ t=1 L|gt|+ L2max + 8Lmax min [ exp ( 4L2max L2 ) , exp( √ T/2) ]\n≤ Lmax(2((‖u‖+ 1) log(‖u‖+ 1)− ‖u‖) + 96) √ T + 8Lmax min [ e 4L2max L2 , e √ T/2 ]\nProof of Lemma 3. We combine Lemma 11 with Lemma 12: if |wt| ≥ 15 we have for all t < T :( 1\nηt−1 − 1 ηt\n) ψ(wt+1) + gt · (wt − wt+1) < 0\nand if |wt| ≤ 15 we have( 1\nηt−1 − 1 ηt\n) ψ(wt+1) + gt · (wt − wt+1) ≤ gt · (wt − wt+1)\n≤ 6× (15 + 1)ηtg2t = 96ηtg 2 t\nTherefore for all t < T we have (\n1 ηt−1 − 1 ηt\n) ψ(wt+1) + gt · (wt − wt+1) ≤ 96ηtg2t .\nRT (u) ≤ ψ(u)/ηT + T∑ t=1 ( 1 ηt−1 − 1 ηt ) ψ(wt+1) + gt · (wt − wt+1)\n≤ ψ(u)/ηT + 96 T∑ t=1 ηtg 2 t + ( 1 ηT−1 − 1 ηT ) ψ(wT+1) + gT · (wT − wT+1)\nWe have ( 1\nηT−1 − 1 ηT\n) ψ(wT+1) < 0\nso that ( 1\nηT−1 − 1 ηT\n) ψ(wT+1) + gT · (wT − wT+1) ≤ 2LmaxWmax\nFurther, again using Lemma 11 we have( 1\nηT−1 − 1 ηT\n) ψ(wT+1) + gT · (wT − wT+1) < 0\nfor |wT | ≥ 4 exp(p2L2max) since k = √ 2.\nFinally, notice that by definition of ηt and L, we must have |ηtg1:t| ≤ √ p|g1:t| k √ 2 ≤ √ T/2, so that ‖wt‖ ≤\nexp (ηt|g1:t|) ≤ exp (√ T/2 )\n. Thus we have( 1\nηT−1 − 1 ηT\n) ψ(wT+1) + gT · (wT − wT+1) ≤ 2Lmax min(Wmax, 4 exp(4L2max/L2), exp( √ 2T ))\nNow we make the following classic argument:√ Mt + ‖g‖21:t − √ Mt−1 + ‖g‖21:t−1 ≥\ng2t +Mt −Mt−1 2 √ Mt + ‖g‖21:t\n≥ g 2 t 2 √ Mt + ‖g‖21:t = ηtg 2 t\nso that we can bound:\nRT (u) ≤ ψ(u)/ηT + 96 T∑ t=1 ηtg 2 t + ( 1 ηT−1 − 1 ηT ) ψ(wT+1) + gT · (wT − wT+1)\n≤ ψ(u)/ηT + 96 √ MT + ‖g‖21:T + 2Lmax min(Wmax, 4 exp(4L 2 max/L 2), exp( √ 2T ))\nTo show the remaining two lines of the theorem, we prove by induction that Mt + ‖g‖21:t ≤ L ∑t t′=1 |gt′ | for all t < T . The statement is clearly true for t = 1. Suppose it holds for some t. Then notice that |g1:t+1| ≤ |gt+1|+ |g1:t|. So we have\nMt+1 + ‖g‖21:t+1 = max ( Mt + ‖g‖21:t+1,\n|g1:t+1| p ) ≤ max ( Mt + ‖g‖21:t + L|gt+1|, L|g1:t+1|\n) ≤ L\nt+1∑ t′=1 |gt′ |\nFinally, we observe that MT = max ( MT−1 + ‖g‖21:T−1 + g2T , |g1:T |p ) ≤ L2max + L ∑T−1 t=1 |gt′ | and the last two lines of the theorem follow immediately."
    }, {
      "heading" : "C Additional Experimental Details",
      "text" : ""
    }, {
      "heading" : "C.1 Hyperparameter Optimization",
      "text" : "For the linear classification tasks, we optimized hyperparameters in a two-step process. First, we tested every power of 10 from 10−5 to 102. Second, if λ was the best hyperparameter setting in step 1, we additionally tested βλ for β ∈ {0.2, 0.4, 0.8, 2.0, 4.0, 6.0, 8.0}\nFor the neural network models, we optimized ADAM and ADAGRAD’s learning rates by testing every power of 10 from 10−5 to 100. For stochastic gradient descent, we used an exponentially decaying learning rate schedule specified in Tensorflow’s (https://www.tensorflow.org/) MNIST and CIFAR-10 example code."
    }, {
      "heading" : "C.2 Coordinate-wise updates",
      "text" : "We proved all our results in arbitrarily many dimensions, leading to a dimension-independent regret bound. However, it is also possible to achieve dimension-dependent bounds by running an independent version of our algorithm on each coordinate. Formally, for OLO we have\nRT (u) = T∑ t=1 gt(wt − u) = d∑ i=1 T∑ t=1 gt,i(wt,i − ui) = d∑ i=1 R1T (ui)\nwhere R1T is the regret of a 1-dimensional instance of the algorithm. This reduction can yield substantially better regret bounds when the gradients gt are known to be sparse (but can be much worse when they are not). We use this coordinate-wise update strategy for our linear classification experiments for RESCALEDEXP. We also considered coordinate-wise updates and non-coordinate wise updates for the other algorithms, taking the best-performing of the two.\nFor all algorithms in the linear classification experiments, we found that the difference between coordinate-wise and non-coordinate wise updates was not very striking. However, for the neural network experiments we found RESCALEDEXP performed extremely poorly when using coordinate-wise updates, and performed extremely well with non-coordinate wise updates. We hypothesize that this is due to a combination of non-convexity of the model and frequent resets at different times for each coordinate."
    }, {
      "heading" : "C.3 Re-centering RESCALEDEXP",
      "text" : "For the non-convex neural network tasks we used a variant of RESCALEDEXP in which we re-center our FTRL algorithm at the beginning of each epoch. Formally, the pseudo-code is provided below:\nAlgorithm 2 Re-centered RESCALEDEXP Initialize: k ← √ 2, M0 ← 0, w1 ← 0, t? ← 1 , w? ← 0\nfor t = 1 to T do Play wt, receive subgradient gt ∈ ∂`t(wt). if t = 1 then L1 ← ‖g1‖ p← 1/L1\nend if Mt ← max(Mt−1, ‖gt?:t‖/p− ‖g‖2t?:t). ηt ← 1\nk √\n2(Mt+‖g‖2t?:t) wt+1 ← w? + argminw [ ψ(w) ηt + gt?:tw ] = w? − gt?:t‖gt?:t‖ [exp(ηt‖gt?:t‖)− 1] if ‖gt‖ > 2Lt then Lt+1 ← ‖gt‖ p← 1/Lt+1 t? ← t+ 1 Mt ← 0 wt+1 ← 0 w? ← wt−1 else Lt+1 ← Lt\nend if end for\nSo long as ‖w? − u‖ ≤ ‖u‖, this algorithm maintains the same regret bound as the non-re-centered version of RESCALEDEXP. While it is intuitively reasonable to expect this to occur in a stochastic setting, an adversary can easily subvert this algorithm."
    }, {
      "heading" : "C.4 Aggregating Studies",
      "text" : "It is difficult to interpret the results of a study such as our linear classification experiments (see Section 4) in which no particular algorithm is always the “winner” for every dataset. In particular, consider the case of an analyst who wishes to run one of these algorithms on some new dataset, and doesn’t have the either the resources or inclination to implement and tune each algorithm. Which should she choose? We suggest the following heuristic: pick the algorithm with the lowest loss averaged across datasets.\nThis heuristic is problematic because datasets in which all algorithms do very poorly will dominate the crossdataset average. In order address this issue and compare losses across datasets properly, we compute a normalized loss for each algorithm and dataset. The normalized loss for an algorithm on a dataset is given by taking the loss experienced by the algorithm on its best hyperparameter setting on that dataset divided by the lowest loss observed by any algorithm and hyperparameter setting on that dataset. Thus a normalized loss of 1 on a dataset indicates that an algorithm outperformed all other algorithms on the dataset (at least for its best hyperparameter setting). We then average the normalized loss for each algorithm across datasets to obtain the scores for each algorithm (see Table 1).\nThese data indicate that while ADAGRAD has a slight edge after tuning, RESCALEDEXP and ADADELTA do nearly equivalently well (4% and 6% worse performance, respectively). Therefore we suggest that if our intrepid analyst is willing to perform some hyperparameter tuning, then ADAGRAD may be slightly better, but her choice doesn’t matter too much. On the other hand, using RESCALEDEXP will allow her to skip any tuning step without compromising performance."
    } ],
    "references" : [ ],
    "referenceMentions" : [ ],
    "year" : 2017,
    "abstractText" : "We propose an online convex optimization algorithm (RESCALEDEXP) that achieves<lb>optimal regret in the unconstrained setting without prior knowledge of any bounds<lb>on the loss functions. We prove a lower bound showing an exponential sep-<lb>aration between the regret of existing algorithms that require a known bound<lb>on the loss functions and any algorithm that does not require such knowledge.<lb>RESCALEDEXP matches this lower bound asymptotically in the number of itera-<lb>tions. RESCALEDEXP is naturally hyperparameter-free and we demonstrate empir-<lb>ically that it matches prior optimization algorithms that require hyperparameter<lb>optimization. 1 Online Convex Optimization Online Convex Optimization (OCO) [1, 2] provides an elegant framework for modeling noisy,<lb>antagonistic or changing environments. The problem can be stated formally with the help of the<lb>following definitions:<lb>Convex Set: A setW is convex ifW is contained in some real vector space and tw+(1− t)w′ ∈W<lb>for all w,w′ ∈W and t ∈ [0, 1].<lb>Convex Function: f :W → R is a convex function if f(tw + (1− t)w′) ≤ tf(w) + (1− t)f(w′)<lb>for all w,w′ ∈W and t ∈ [0, 1]. An OCO problem is a game of repeated rounds in which on round t a learner first chooses an element<lb>wt in some convex space W , then receives a convex loss function `t, and suffers loss `t(wt). The<lb>regret of the learner with respect to some other u ∈W is defined by",
    "creator" : "LaTeX with hyperref package"
  }
}