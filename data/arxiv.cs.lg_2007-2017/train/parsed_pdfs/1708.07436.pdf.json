{
  "name" : "1708.07436.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "Dierentially Private Regression for Discrete-Time Survival Analysis",
    "authors" : [ "THÔNG T. NGUYÊN", "SIU CHEUNG HUI" ],
    "emails" : [ ],
    "sections" : [ {
      "heading" : "Di erentially Private Regression for Discrete-Time Survival Analysis",
      "text" : "THÔNG T. NGUYÊN, Nanyang Technological University\nSIU CHEUNG HUI, Nanyang Technological University\nIn survival analysis, regression models are used to understand the e ects of explanatory variables (e.g., age, sex, weight, etc.) to the survival probability. However, for sensitive survival data such as medical data, there are serious concerns about the privacy of individuals in the data set when medical data is used to t the regression models. e closest work addressing such privacy concerns is the work on Cox regression which linearly projects the original data to a lower dimensional space. However, the weakness of this approach is that there is no formal privacy guarantee for such projection. In this work, we aim to propose solutions for the regression problem in survival analysis with the protection of di erential privacy which is a golden standard of privacy protection in data privacy research. To this end, we extend the Output Perturbation and Objective Perturbation approaches which are originally proposed to protect di erential privacy for the Empirical Risk Minimization (ERM) problems. In addition, we also propose a novel sampling approach based on the Markov Chain Monte Carlo (MCMC) method to practically guarantee di erential privacy with be er accuracy. We show that our proposed approaches achieve good accuracy as compared to the non-private results while guaranteeing di erential privacy for individuals in the private data set.\nCCS Concepts: •Mathematics of computing→ Survival analysis; •Security and privacy→ Privacy protections;\nAdditional Key Words and Phrases: survival analysis; discrete-time models; di erential privacy; regression models\nACM Reference format: ông T. Nguyên and Siu Cheung Hui. 2016. Di erentially Private Regression for Discrete-Time Survival Analysis. 1, 1, Article 1 (January 2016), 19 pages. DOI: 10.1145/nnnnnnn.nnnnnnn"
    }, {
      "heading" : "1 INTRODUCTION",
      "text" : "Survival analysis studies and models probability of failure of time-related processes (e.g., time to death of HIV patients, time to divorce of married couples, time to graduation of Ph.D. students, etc.). Two important concepts in survival analysis are (1) the hazard rate function h(t ) which is the probability of failure (death) at time t , and (2) the survival function S(t ) which is the probability of survival to time t . An example of survival data set is the electronic health records (EHRs) which have been widely used and collected at large scale in modern hospitals (Blumenthal and Tavenner 2010; DesRoches et al. 2008; Jha et al. 2009). ese health records are very useful for ing the regression models to assist doctors in the medical decision processes for treatment, diagnosis, etc. In general, regression models are used to analyze the e ects of explanatory variables (e.g., age, sex, weight, etc.) to the survival probability of patients. However, these models may also have serious problems of breaching patient’s privacy as there is no guarantee that these models do not leak any personal information of individual patients in the data set.\nPermission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for pro t or commercial advantage and that copies bear this notice and the full citation on the rst page. Copyrights for components of this work owned by others than ACM must be honored. Abstracting with credit is permi ed. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior speci c permission and/or a fee. Request permissions from permissions@acm.org. © 2016 ACM. Manuscript submi ed to ACM\nManuscript submi ed to ACM 1\nar X\niv :1\n70 8.\n07 43\n6v 1\n[ cs\n.L G\n] 2\n4 A\nug 2\n01 7\nIn this work, we focus on the privacy problems of regression models used in survival analysis. We consider the se ing in which privacy-preserving algorithms use data in the private data set to t a survival regression model. e model is then published and available to the public for the bene ts of society. erefore, in this se ing, the adversaries are assumed to know the output model, i.e., the parameters of the regression model. e goal is to design algorithms that can t the survival regression model to the data set with high accuracy while guaranteeing that the adversaries cannot learn much information about the individuals in the data set when knowing the output model.\nere are two di erent kinds of regression models in survival analysis, namely continuous-time models and discretetime models. For continuous-time models, time is a continuous variable and failure events can happen at any moment. Cox regression is a well-known continuous-time model (Andersen and Gill 1982; Cox 1992) which allows estimation without any assumption on the baseline hazard e ects. However, we have to assume the proportional hazard property (i.e., a unit increase in an explanatory variable will cause a multiplicative e ect on the hazard rate). For discrete-time models (Allison 1982; Cox and Oakes 1984; Muthén and Masyn 2005), time is discrete and failure events only happen at discrete values of time. Discrete-time regression models are be er than Cox regression when dealing with tied events (i.e., events which have the same value of survival time) and unobserved population heterogeneity (i.e., unobserved explanatory variables may cause bias to the estimation). Moreover, it does not need the proportional hazard property assumption as Cox regression does (Hess and Persson 2012).\nIn this paper, we propose solutions for the problem of guaranteeing discrete-time models not to leak personal information of the patients. Our proposed approaches guarantee di erential privacy protection, which is the state-ofthe-art privacy-preserving technique in data privacy research. Informally, a di erentially private algorithm guarantees that two neighboring data sets which are di erent at only one patient’s record are guaranteed to produce two outputs whose probability densities are very similar. is prevents an adversary from recognizing a data set from the collection of its neighbors. erefore, an adversary cannot infer the personal information of a particular patient in the data set even in the case when the adversary knew all the information of all other patients in the data set (if otherwise, then the adversary can easily distinct two neighboring data sets).\nIn our solutions, we use the maximum likelihood estimation to transform the estimation problem to the optimization problem of choosing parameters to maximize the log-likelihood of the observed data set with respect to the discrete-time model. Coincidentally, our problem has a similar likelihood form as a logistic regression problem. is allows us to use the Output Perturbation (Out-Pert) and Objective Perturbation (Obj-Pert) proposed by Chaudhuri et al. (Chaudhuri et al. 2011) for our problem. ese methods were originally proposed to protect di erential privacy for the Empirical Risk Minimization (ERM) problems which include the logistic regression problem. e Out-Pert approach adds noise to the optimization solution to protect di erential privacy. e Obj-Pert approach randomly perturbs the objective function, thereby ensuring the randomness of its optimization solution which can guarantee di erential privacy for the solution. However, these approaches cannot be applied directly to our problem due to the di erence in the loss function. Especially, this is due to the fact that our loss function is not a logistic loss function but a sum of logistic loss functions as the result of the discrete-time models. erefore, we propose generalized extensions of the Out-Pert and Obj-Pert approaches to cater for our loss function.\nA disadvantage of the above perturbation approaches is that for them to work properly they require a non-negligible regularization term in the objective function which incurs bias to the output model. To tackle this, we propose a sampling approach which protects di erential privacy by directly sampling parameters from the objective function without the need of a regularization term to guarantee di erential privacy. Similar ideas on sampling the objective\nManuscript submi ed to ACM\nfunctions to provide di erential privacy are also proposed in (Bassily et al. 2014; Kifer et al. 2012; Wang et al. 2015) for the ERM problems. However, it is required that the loss function has to have a nite maximum value. e previous works guarantee this property by boxing the output parameters in a nite-volume space (e.g., a sphere). is approach does not work well when the optimal parameter has a large magnitude. In this work, to guarantee the nite constraint, we wrap the loss function inside a sanitizer function (i.e., a scaled tanh function) to create a new nite loss function. We intentionally pick the sanitizer function that can keep the loss function in its original form when the value of the loss function is small. Meanwhile, the sanitizer function deforms the loss function at large values to make the function nite. e advantage of this approach is that the sampled parameter can arbitrary large while the objective function is kept almost the same around the optimal parameter which minimizes the objective function.\nIn order to sample an output parameter from the posterior distribution, Bassily et al. (Bassily et al. 2014) proposed a polynomial run-time algorithm to sampling the log-concave objective function but their algorithm is still impractical due to the high degree of its polynomial run-time complexity. On the other hand, Wang et al. (Wang et al. 2015) proposed to use a stochastic gradient Nosé-Hoover thermostat algorithm (Ding et al. 2014) to sample the posterior distribution. In this work, we propose to use Preconditioned Stochastic Gradient Langevin Dynamics (pSGLD) sampling algorithm (Li et al. 2015) to sample the objective function due to its advantages in sampling multi-dimensional parameters with di erent scales. It is worth to note that even though the sampling approach gives be er accuracy (as we will see in Section 6), due to the property of its Markov chain, it cannot sample the objective function exactly. erefore, the sampling approach does not mathematically guarantee di erential privacy but only guarantees it approximately in practice.\nIn summary, the main contributions of this paper are as follows:\n• We propose two privacy-preserving approaches, namely the Extended Output Perturbation and Extended Objective Perturbation, for the discrete-time survival regression problem. e proposed approaches guarantee di erential privacy for the survival regression models. We formally prove these guarantees based on the de nition of di erential privacy. • We propose a sampling approach to output a random model from its posterior distribution. e proposed sampling approach is based on pSGLD, which is a particular kind of the Markov Chain Monte Carlo (MCMC) method, to e ciently sample the random output which guarantees di erential privacy approximately in practice. • We show the e ectiveness of our proposed approaches on four real survival data sets. In addition, we show that the results obtained from the discrete-time models are very close to the results obtained from Cox regression. We also show experimentally the convergence of our proposed sampling approach.\ne rest of the paper is organized as follows: In Section 2, we review the related work on di erential privacy and discrete-time survival analysis. Section 3 presents the regression models used in this work. Sections 4 discusses the proposed approaches of the Extended Output Perturbation and Extended Objective Perturbation along with their privacy guarantees. Section 5 discusses the proposed sampling approach. Section 6 presents the experimental results from real data sets. Finally, we conclude the paper in Section 7."
    }, {
      "heading" : "2 RELATEDWORK",
      "text" : "Even though it is important to protect privacy in medical data, as far as we know the work of Yu et al. (Yu et al. 2008) is the only work on privacy protection for Cox regression. eir work considers the se ing in which Cox regression is\nManuscript submi ed to ACM\nexecuted on a distributed data set over many institutions. ey proposed to project patient’s data to a lower dimensional space by a linear projection. e projection is satis ed by an optimization constraint to preserve good properties of the original data. However, their work is not based on a formal privacy de nition such as di erential privacy. Our work on discrete-time models for survival analysis is the rst to propose a solution for the privacy problem of discrete-time survival models and also the rst to apply di erential privacy to survival analysis."
    }, {
      "heading" : "2.1 Di erential Privacy",
      "text" : "e state-of-the-art technique for the data privacy problem is di erential privacy (Dwork 2009, 2011; Dwork et al. 2014). Basically, di erential privacy is a promise to individuals in the data set that their information will not in uence much on the nal published results from the analysis. Di erential privacy is used in many applications such as histogram publication (Li et al. 2010; Zhang et al. 2014), graph analysis (Borgs et al. 2015; Kasiviswanathan et al. 2013; Lu and Miklau 2014), regression and classi cation (Bassily et al. 2014; Chaudhuri and Monteleoni 2009; Kifer et al. 2012; Wang et al. 2015), recommender systems (Machanavajjhala et al. 2011; McSherry and Mironov 2009), etc. Here, we give a brief overview of di erential privacy, interested readers can refer to (Dwork et al. 2014) for a detailed discussion on this subject.\nTo formalize the de nition of di erential privacy, we rst need to introduce the de nition of two neighboring data sets.\nDe nition 2.1 (Neighboring data sets). Two data sets D and D ′ are neighbors (denoted as d(D,D ′) = 1) if they agree in all except one record.\nFrom that, we have a formal de nition of di erential privacy.\nDe nition 2.2 (Di erential privacy). An algorithmA is ϵ−di erentially private if for any output value x ofA and for any pair of neighboring data sets D and D ′:\npdf(A(D) = x ) ≤ exp(ϵ) · pdf(A(D ′) = x )\nwhere ϵ is the privacy budget of the algorithm A."
    }, {
      "heading" : "2.2 Discrete-time Survival Analysis",
      "text" : "For discrete-time models, let time be divided into intervals [a0,a1), [a1,a2), . . . , [aq−1,aq ],a0 = 0,aq = 1, where q is the number of discrete times. e discrete time t refers to the interval [at−1,at ). A discrete random variable T represents the discrete failure time. T = t denotes the failure within the time interval t = [at−1,at ). e characteristic function of T is the discrete hazard function:\nh(t ) = Pr(T = t | T ≥ t ), t = 1, . . . ,q\nwhich is the conditional probability for the risk of failure in interval t given the survival in all previous intervals. e discrete survival function for reaching interval t is:\nS(t ) = Pr(T ≥ t ) = t−1∏ s=1 (1 − h(s)) (1)\nDiscrete-time data sets are given by (xi ,δi , ti ), i = 1, . . . ,n, where ti = min(Ti , ci ) is the minimum of the survival time Ti and censoring time ci , and δi is the indicator variable for failure (δi = 1) or censoring (δi = 0). When δi = 0, the ith patient is known to survive until time ci but the survival time Ti is not observed (Ti > ci ). xi is a real vector of Manuscript submi ed to ACM\nexplanatory variables (e.g., sex, age, weight, etc.) which a ect the survival probability. We assume that xi is inside the unit-sphere, ‖xi ‖≤ 1. is is actually a common practice in machine learning. Without loss of generality, we assume that 0 ≤ ti ≤ 1. For convenience, we use yi to refer to the term (2δi − 1) and di to refer to the tuple (xi ,yi , ti )."
    }, {
      "heading" : "3 DISCRETE-TIME REGRESSION MODEL",
      "text" : "In this section, we introduce the discrete-time regression models which are used to model the relationship between explanatory variables and the hazard rate, i.e., the predictive variable. From that, the subsequent sections will discuss the proposed di erentially private approaches to guarantee that the estimated parameters from the regression model satisfy the de nition of di erential privacy."
    }, {
      "heading" : "3.1 Generalized Linear Models",
      "text" : "We model the e ects of explanatory variables xi to the survival probability by using a generalized linear model:\nд(h(ti | xi )) = γ (ti ) + x ′i β (2)\nwhere д(·) is the link function, β is the parameter vector representing the e ects of explanatory variables and γ (ti ) is a time-varying baseline hazard e ect.\nA commonly used link function in survival probability is the logit link function д(x ) = loдit (x ) = log ( x 1−x ) . e logit link function allows the model to have a nice interpretation of the proportional odds ratio. e other two link functions, which are also used in survival analysis, are the complementary log-log link functionд(x ) = cloдloд(x ) = log(− log(1−x )), and the probit link function д(x ) = probit (x ) = Φ−1(x ), where Φ(·) is the cumulative distribution function of the standard normal distribution. Interestingly, the complementary log-log link function has the same interpretation of proportional hazard ratio as the Cox regression. We refer interested readers to (Allison 1982) for more details.\nAs illustrated in Figure 1, the three link functions have similar shapes which lead to similar estimation results. In this work, we have selected the logit link function because it has a bounded derivative for the loss function which is\nManuscript submi ed to ACM\nrequired by our proposed Extended Output Perturbation and Extended Objective Perturbation approaches. However, our proposed sampling approach can work with all three link functions."
    }, {
      "heading" : "3.2 Baseline Hazard E ect",
      "text" : "We model the baseline hazard e ect γ (t ) using natural cubic spline (Friedman et al. 2001) with e knots equally distributed over the interval [0, 1], 0 = k1 < k2 < · · · < ke = 1.\nLet\ndj (t ) = max(t − kj , 0)3 −max(t − ke , 0)3\nke − kj and\nb1(t ) = 1,b2(t ) = t ,bi+2 = di (t ) − de−1(t )\ne baseline hazard e ect γ (t ) is approximated as a linear combination of e basis functions:\nγ (t ) = α1b1(t ) + · · · + αebe (t )\nIn particular, let Ai = [b1(ti ), . . . ,be (ti )]′ and α = [α1, . . . ,αe ]′, then we can write γ (ti ) = α ′Ai ."
    }, {
      "heading" : "3.3 Maximum Likelihood Estimation (MLE)",
      "text" : "Traditionally, we use MLE to estimate parameters α and β in our models. e aim is to maximize the log-likelihood of\nthe observed data. For simplicity, let f =\n( α\nβ\n) and xti = ( At\nxi\n) . e log-likelihood function is:\nlogL(f ) = n∑ i=1 log [ h(ti | f ,xi )δi (1 − h(ti | f ,xi ))1−δi S(ti | f ,xi ) ] Let yi = 2δi − 1, from (1), (2) and substituting д(x ) = loдit (x ), we can rewrite our problem as:\nlogL(f ) = − n∑ i=1\n[ `LR(yi f ′x ti i ) + ti−1∑ s=1 `LR(−f ′xsi ) ] where `LR(x) = log(1 + exp(−x)) is the logistic loss function. To further simplify the formula, let di = (xi ,yi , ti ), i = 1, . . . ,n, and let\n`(f ;di ) = `LR(yi f ′x ti i ) + ti−1∑ s=1 `LR(−f ′xsi ) (3)\nbe the loss function. en, we get an ERM problem as follows:\nf ∗ = arg min f n∑ i=1 `(f ;di ) (4)\nIn this work, our main goal is to propose algorithms which protect di erential privacy for f ∗ in Equation (4)."
    }, {
      "heading" : "4 PERTURBATION APPROACHES",
      "text" : ""
    }, {
      "heading" : "4.1 Extended Output Perturbation",
      "text" : "In this section, we present our proposed algorithm which is the extension of the Output Perturbation approach in (Chaudhuri et al. 2011). For our problem, the loss function is a sum of logistic loss functions instead of a single logistic loss function as in (Chaudhuri et al. 2011). e proposed algorithm is in fact based on the generalized version of the Manuscript submi ed to ACM\nAlgorithm 1 AExt−Out−Pert: Extended Output Perturbation Input: Data set D = {d1, . . . ,dn }, loss function `(f ;di ), privacy budget ϵ Output: fpr iv\n1: J (f ;D) = 1n ∑n i=1 `(f ;di ) + Λ 2 ‖ f ‖2 2: Minimize J (f ;D) by using the BFGS algorithm to get the non-private solution f ∗\n3: Compute t ← ∑q s=1 √ 4+‖As ‖2+maxs∈{1, . . .,q} √ ‖2As ‖2+4 n ·Λ 4: Sample a random vector b such that pdf(b) ∝ exp ( −ϵ ‖b ‖t\n) 5: Compute and output fpr iv ← f ∗ + b\nLaplace mechanism (Dwork 2008) which is described as follows: Let f ∗ = G(D) be the value that we want to guarantee di erential privacy. f ∗ is the result of applying a function G on the private data set D (e.g., it is in our case to minimize the objective function). We de ne the sensitivity of the function G as follows:\nsen(G) = max D,D′\n‖G(D) −G(D ′)‖\nwhere D and D ′ are two neighboring data sets. en, the di erentially private version of f ∗ = G(x ) is:\nfpr iv = f ∗ + µ\nwhere µ is a noisy random variable with probability density function pdf(µ) ∝ exp(−ϵ ‖µ‖/sen(G)). As required by the Output Perturbation approach, we consider the following regularized objective function:\nJ (f ;D) = 1 n n∑ i=1 `(f ;di ) + Λ 2 ‖ f ‖2 (5)\nwhere D = {di }ni=1, `(·) is the loss function as de ned in (3) and Λ is the regularization parameter. In this approach, our goal is to compute the sensitivity of:\nf ∗ = arg min f J (f ;D)\nen, we use the sensitivity to control the amount of noise added to f ∗.\n4.1.1 Proposed Algorithm. Algorithm 1 shows the proposed Extended Output Perturbation approach. It returns a vector fpr iv as the minimizer of J (·) while guaranteeing di erential privacy. At Line 2, we compute the non-private solution f ∗ = arg minf = J (f ;D) using the well-known BFGS algorithm (Fletcher 2013). f ∗ is guaranteed to exist due to the strongly convexity of J (f ;D). At Line 3, we compute t which is the sensitivity of f ∗. Lines 4-5 add noise to the value of f ∗.\nIn order to sample a random vector b in Algorithm 1 from the distribution pdf(b) ∝ exp (−ϵ ‖b‖/t), we observe that the length of the vector b follows a Gamma distribution:\n‖b‖∼ Γ(d, t/ϵ)\nwhere d is the number of components of b. us, in order to sample b we rst sample its length r = ‖b‖ from the Gamma distribution and then sample b as a uniform random point on the surface of a sphere with radius r .\n4.1.2 Privacy Guarantee. In order to prove the di erential privacy protection, we focus on proving that the sensitivity of f ∗ at Line 2 in Algorithm 1 is equal to the value of t which is computed at Line 3. Here, we use Lemma 4.1 from (Chaudhuri et al. 2011) to bound the sensitivity of f ∗.\nManuscript submi ed to ACM\nLemma 4.1. Let G(f ) and д(f ) be two vector-valued functions, which are continuous and di erentiable at all points. In addition, let G(f ) and G(f ) + д(f ) be λ−strongly convex. If f1 = arg minf G(f ) and f2 = arg minf G(f ) + д(f ), then\n‖ f1 − f2‖≤ 1 λ max f ‖∇д(f )‖\nFrom Lemma 4.1, our goal now is to bound the magnitude of the di erence in the gradients of the objective function J (·) on any two neighboring data sets.\nLemma 4.2. For any pair of patient’s records di = (xi ,yi , ti ) and dj = (x j ,yj , tj ), and for any f ,\n‖∇`(f ;di ) − ∇`(f ;dj )‖≤ q∑ s=1 √ ‖As ‖2+4 + max s ∈{1, ...,q } √ ‖2As ‖2+4\nProof.\n∇`(f ;di ) = ∇`LR(yi f ′xtii ) + ti−1∑ s=1 ∇`LR(−f ′xsi )\n= −yixtii 1 + exp(yi f ′xtii ) + ti−1∑ s=1 xsi 1 + exp(−f ′xsi )\nerefore, we can write ∇`(f ;di ) = ∑q s=1 l s i , where\nlsi =  x si 1+exp(−f ′x si ) , i f s < ti −yix si 1+exp(yi f ′x si ) , i f s = ti ®0, i f s > ti\nSimilarly, we can also write ∇`(f ;dj ) = ∑q s=1 l s j . erefore,\n∇`(f ;di ) − ∇`(f ;dj ) = q∑ s=1 lsi − l s j\nWe have | −yi1+exp(yi f ′x si ) | ≤ 1, ‖xi ‖ ≤ 1, ‖x j ‖ ≤ 1, for any s ∈ {1 . . .q}, we consider four possible cases as follows: Case 1: if s < ti and s < tj , then\n‖lsi − l s j ‖= ( (e1 − e2)As e1xi − e2x j ) ≤ √‖As ‖2+(‖xi ‖+‖x j ‖)2 ≤ √ ‖As ‖2+4\nwhere e1 = 11+exp(−f ′x si ) and e2 = 11+exp(−f ′x sj ) .\nCase 2: if s > ti or s > tj , then ‖lsi − l s j |≤ max(‖x s i ‖, ‖x s j ‖) ≤ √ ‖As ‖2+1 < √ ‖As ‖2+4. Case 3: if lsi = −x si 1+exp(f ′x si ) and lsj = x sj 1+exp(−f ′x sj ) , then\n‖lsi − l s j ‖= − ( (e1 + e2)As e1xi + e2x j ) ≤ √‖2As ‖2+4 where e1 = 11+exp(f ′x si ) and e2 = 11+exp(−f ′x sj ) .\nCase 4: if lsi = x si 1+exp(−f ′x si ) and lsj = −x sj 1+exp(f ′x sj ) , then ‖lsi − l s j ‖≤\n√ ‖2As ‖2+4. is case is similar to Case 3.\nManuscript submi ed to ACM\nWe observe that there is at most one value of s, 1 ≤ s ≤ q, belonging to Case 3 or Case 4 in which ‖lsi − l s j ‖≤√\n‖2As ‖2+4. erefore, from the triangle inequality:\n‖ q∑ s=1 lsi − l s j ‖≤ q∑ s=1 √ ‖As ‖2+4 + max s ∈{1, ...,q } √ ‖2As ‖2+4\nerefore, the lemma follows.\nFinally, we can bound the sensitivity of f ∗ = arg minf J (f ;D) by the following lemma. Lemma 4.3. e `2−sensitivity of f ∗ = arg minf J (f ;D) is at most ∑q s=1 √ 4+‖As ‖2+maxs∈{1, . . .,q} √ ‖2As ‖2+4 nΛ .\nProof. Without loss of generality, we assume that two neighboring data sets D and D ′ are di erent at nth patient with (xn ,yn , tn ) ∈ D and (x ′n ,y′n , t ′n ) ∈ D ′.\nLetG(f ) = J (f ;D),д(f ) = J (f ;D ′)−J (f ;D) = 1n (`(f ;d ′n )−`(f ;dn )), f1 = arg minf J (f ;D), and f2 = arg minf J (f ;D ′). Because 12 ‖ f ‖2 is 1−strongly convex,G(f ) = J (f ;D) is Λ−strongly convex andG(f )+д(f ) = J (f ;D ′) is also Λ−strongly convex. From Lemma 4.2,\n‖∇д(f )‖ = 1n (∇`(f ;d ′n ) − ∇`(f ;dn )) ≤ ∑q s=1 √ 4 + ‖As ‖2 + maxs ∈{1, ...,q } √ ‖2As ‖2+4\nn\nFrom Lemma 4.1,\n‖ f1 − f2‖≤ 1 Λ\n∑q s=1 √ 4 + ‖As ‖2 + maxs ∈{1, ...,q } √ ‖2As ‖2+4\nn erefore, the lemma follows.\nTheorem 4.1. Algorithm 1 is ϵ−di erentially private.\nProof. For any pair of neighboring data sets D and D ′ and for any fpr iv ,\npdf(fpr iv | D) pdf(fpr iv | D ′) = pdf(b1) pdf(b2) = exp (−ϵ/t (‖b1‖−‖b2‖))\nwhere b1 and b2 are the corresponding noise vectors at Line 4 in Algorithm 1 with respect to the data sets D and D ′. If f ∗1 (resp., f ∗ 2 ) is the solution at Line 2 of Algorithm 1 on the data set D (resp., D ′), then f ∗1 + b1 = f ∗ 2 + b2 = fpr iv . From Lemma 4.3 and the triangle inequality:\n‖b1‖−‖b2‖≤ ‖b1 − b2‖= ‖ f1 − f2‖≤ t\nwhere t = ∑q s=1 √ 4+‖As ‖2+maxs∈{1, . . .,q} √ ‖2As ‖2+4\nn ·Λ . erefore, pdf(b1) pdf(b2) ≤ exp(ϵ). us, Algorithm 1 is ϵ−di erentially\nprivate."
    }, {
      "heading" : "4.2 Extended Objective Perturbation",
      "text" : "In this section, we present a solution based on the Objective Perturbation approach proposed in (Chaudhuri et al. 2011). Similarly to the Extended Objective Perturbation approach, we also consider the objective function as described in Equation (5). In this approach, instead of adding noise to the solution of the optimization problem as the output perturbation does, it adds noise to the objective function.\nManuscript submi ed to ACM\nAlgorithm 2 AExt−Obj−Pert: Extended Objective Perturbation Input: Data set D = {d1, . . . ,dn }, objective function J (f ;D), privacy budget ϵ , parameter Λ Output: f ∗\n1: ∆← 0 2: Compute ϵ ′ ← ϵ − 2 ∑qs=1 log (1 + 14√‖As ‖2+1n(Λ+∆) ) 3: if ϵ ′ < ϵ/2 then\n4: Binary search value of ∆ such that 2 ∑qs=1 log(1 + 14√‖As ‖2+1n(Λ+∆) ) = ϵ/2 and set ϵ ′ ← ϵ/2 5: Compute t ← ∑qs=1 √4 + ‖As ‖2 + maxs ∈{1, ...,q } √‖2As ‖2+4 6: Sample a random vector b such that pdf(b) ∝ exp (−ϵ ′‖b‖/t) 7: f ∗ ← arg minf J (f ;D) + 1n 〈b, f 〉 + 1 2 ∆‖ f ‖2 8: Output f ∗\n4.2.1 Proposed Algorithm. Algorithm 2 shows the solution in pseudo-code. At Line 2, we compute ϵ ′ which is used to calibrate the magnitude of a random variable b. Here, the regularization parameter is equal to Λ. At Line 3, if ϵ ′ < ϵ/2, then it indicates that Λ is not large enough. In this case, an additional positive regularization parameter ∆ is picked to set the value of ϵ ′ equals to ϵ/2 (Line 4). At Line 5, we compute t which is the sensitivity of ∇J (f ;D). Line 6 samples a random vector b using the same method described in Subsection 4.1.1. Lines 7-8 return the solution of the noisy objective function using the BFGS algorithm.\n4.2.2 Privacy Guarantee. In this section, we will prove that the probability density of f ∗ from Algorithm 2 satis es the di erential privacy de nition.\nTheorem 4.4. Algorithm 2 is ϵ−di erentially private.\nProof. e noisy objective function from Algorithm 2 is:\nf ∗ = arg min f 1 n n∑ i=1 `(f ;di ) + 1 n 〈b, f 〉 + 1 2 (Λ + ∆) ‖ f ‖2\nDue to the convexity of `(·), the gradient is zero at the minimal point f ∗, equivalently,\nb = −n(Λ + ∆)f ∗ − n∑ i=1 ∇`(f ∗;di )\nDue to the strongly convexity of the objective function, there is a bijective (injective and surjective) mapping from f to b (denoted as f → b). erefore, we can transform the probability density function of random variable f to the probability density function of random variable b by a multiplication factor of the Jacobian determinant (Billingsley 2008). From that, the probability density ratio in di erential privacy can be rewri en as:\npdf(f | D) pdf(f | D ′) = pdf(b | D) pdf(b ′ | D ′) ·\n|det (Jacob (f → b | D)) |−1\n|det (Jacob (f → b ′ | D ′)) |−1 (6)\nWe rst bound the ratio of the Jacobian determinants. Without loss of generality, we assume that the two data sets D and D ′ are di erent at nth record with dn ∈ D and dn′ ∈ D ′. Let\nA = −Jacob(f → b | D) = n(Λ + ∆)I + n∑ i=1 ∇2`(f ∗;di )\nManuscript submi ed to ACM\nand E = ∇2`(f ∗;dn ) − ∇2`(f ∗;d ′n ), then\n|det (Jacob (f → b | D)) |−1\n|det (Jacob (f → b ′ | D ′)) |−1 = |det (A + E)| |det (A)| = |det (I + A −1E)|\nMoreover, E = ∑qs=1 Esn −∑qs=1 Esn′ where Esn =\n (x sn )(x sn )′ (1+exp(f ′x sn ))(1+exp(−f ′x sn )) , i f s < tn −y2n (x si )(x sn )′ (1+exp(yn f ′x sn ))(1+exp(−yn f ′x sn )) , i f s = tn 0, i f s > tn\nSimilarly, we can de ne Esn′ by replacing n by n ′. From (Seiler and Simon 1975), for any square matrices A and B,\ndet (I + A + B) ≤ det (I + |A|) · det (I + |B |)\nwhere |A|= (A′A) 1 2 . Moreover, A−1Esn and A−1Esn′ are symmetric, thus\ndet (I + A−1E) ≤ q∏ s=1 det (I + A−1Esn ) · det (I + A−1Esn′ )\nWe now prove that |det ( I + A−1Esn ) |≤ 1 + 1 4 √ ‖As ‖2+1 n(Λ+∆) . Because −y2n(1+exp(yn f ′x sn ))(1+exp(−yn f ′x sn )) ≤ 14 , and Esn is either a\nzero matrix or 1-rank matrix. e only non-zero eigenvalue of Esn if exist satis es |λ1(Esn )|≤ 14 ‖xsn ‖≤ 1 4 √ ‖As ‖2+1. As the objective function is (Λ + ∆)−strongly convex, A is a full-rank matrix with each eigenvalue greater than n(Λ + ∆).\nerefore, |det ( I + A−1Esn ) |≤ 1 + 1 4 √ ‖As ‖2+1 n(Λ+∆) . Similarly, |det (I + A −1Esn′ )|≤ 1 + 1 4 √ ‖As ‖2+1 n(Λ+∆) . erefore,\n|det (Jacob (f → b) | D) |−1\n|det (Jacob (f → b ′) | D ′) |−1 ≤ exp\n( 2\nq∑ s=1 log(1 + 1 4 √ ‖As ‖2+1 nΛ ) ) (7)\nNext, we bound the ratio of the probability density of random vector b with respect to two neighboring data sets. We have:\nb − b ′ = ∇`(f ∗;dn ) − ∇`(f ∗;d ′n )\nFrom Lemma 4.2,\n‖b − b ′‖≤ q∑ s=1 √ ‖As ‖2+4 + max s ∈{1, ...,q } √ ‖2As ‖2+4\nerefore,\npdf(b | D) pdf(b ′ | D ′) ≤ exp(ϵ ′‖b − b ′‖/t ) ≤ exp(ϵ ′) (8)\nFrom (6), (7), (8), and ϵ = ϵ ′ + 2 ∑qs=1 log (1 + 14√‖As ‖2+1nΛ ) , the theorem follows."
    }, {
      "heading" : "5 PROPOSED SAMPLING APPROACH",
      "text" : "In this section, we propose a solution which guarantees di erential privacy by directly sampling a random output from a modi ed version of the posterior distribution. In this work, we pick a normal distribution as the prior distribution. is is equivalent to using:\nU(f ;D) = −1 2 σ ‖ f ‖2− n∑ i=1 `(f ;di )\nManuscript submi ed to ACM\nas the utility function in the exponential mechanism (McSherry and Talwar 2007) where the parameter σ is used to control the variance of the prior normal distribution. en, the di errentially private output is sampled from the following distribution:\npdf(f ) ∝ exp ( ϵU(f ;D)\n2∆U ) where ∆U = maxd (D,D′)=1,f ‖U(f ;D) − U(f ;D ′)‖ is the sensitivity of U . e reason we pick a normal prior distribution instead of a uniform prior distribution is not because our proposed solution required so to guarantee di erential privacy but we observe that with a normal prior distribution the sampling algorithm converges be er and is more stable.\nMoreover, this approach requires the utility functionU(f ;D) has to have a bounded sensitivity. However, the loss function `(·) is not bounded. erefore, the functionU(f ;D) has unbounded sensitivity. In order to overcome this di culty, we propose a smooth sanitizer functionC(x ) which is used to control the maximum value of the loss function `(·). e de nition of C(x ) is given as follows:\nCv (x ) = v · tanh (x v ) which is illustrated in Figure 2. We now take the composition ofCv (·) with `(f ;di ) to have a bounded-sensitivity utility function:\nU(f ;D) = −1 2 σ ‖ f ‖2− n∑ i=1 Cv (`(f ;di ))\nWe intentionally pick the tanh(·) function as the sanitizer because it nicely keeps the loss function in its original form when the value of the loss function is near 0. Meanwhile, it deforms the loss function at large values to make the function nite. e advantage of this approach is that the sampled parameter can arbitrary large while the objective function is kept almost the same around the optimal parameter which maximizes the posterior probability. We describe the pseudo-code of our approach in Algorithm 3.\nManuscript submi ed to ACM\nAlgorithm 3 ASanitized−EXP: Sanitized Loss Mechanism Input: Data set D = {di }ni=1, loss function `(f ;di ), privacy budget ϵ , maximum value v , parameter Λ Output: f\n1: U(f ;D) = − 12σ ‖ f ‖2− ∑n i=1Cv (`(f ;di )) 2: Sample a random vector f with the probability density\npdf(f ) ∝ exp ( ϵ\n2v U(f ;D)\n)\nTheorem 5.1 (Privacy guarantee). Algorithm 3 is ϵ−di erentially private.\nProof. For two neighboring data sets D and D ′, ∆U = maxf ,d (D,D′)=1 |U(f ;D) −U(f ;D ′)|≤ v . erefore, at any point f , we have\npdf(f | D) pdf(f | D ′) =\nexp ( ϵ 2vU(f ;D) ) /∫ exp( ϵ2v U(f ;D))df\nexp ( ϵ 2vU(f ;D ′) ) /∫ exp( ϵ2v U(f ;D′))df\n≤ exp (\n2ϵ 2v U(f ;D) −U(f ;D ′) ) ≤ exp(ϵ)\nerefore, Algorithm 3 is ϵ−di erentially private.\ne problem with Algorithm 3 is that there is no run-time e cient algorithm to sample the distribution of f exactly. Bassily et al. (Bassily et al. 2014) proposed a polynomial run-time sampling algorithm. However, their proposed algorithm is still impractical due to the high degree of the polynomial run-time complexity and only apply for the log-convex function. Recently, there are developments (Ahn et al. 2012; Chen et al. 2014; Ma et al. 2015) in Markov Chain Monte Carlo (MCMC) method which can be applied to machine learning problems with large data sets. e idea is to construct Markov chains to simulate dynamical systems with stochastic gradients. At each step, we compute the gradient at the current location, then add a controlled amount of noise to the gradient and follow the noisy gradient to a new location. Asymptotically, the stationary distribution of this process converges to the true distribution from which the gradient is computed.\nIn this work, we propose to use an MCMC sampling algorithm, namely Preconditioned Stochastic Gradient Langevin Dynamics (pSGLD) (Li et al. 2015), to approximately sample the posterior distribution. pSGLD is good at sampling variables with di erences in scale which is useful for our problem because the parameter α is usually much larger in magnitude than the parameter β (recall that f = [α , β]′). e pseudo-code of pSGLD is described in Algorithm 4. At Line 1, we initialize the values ofV0 and f1. Line 3 computes the learning rate ϵt . It is required that limt→∞ ∑ t ϵt →∞\nand limt→∞ ∑ t ϵ 2 t < ∞ to guarantee the convergence. We sample uniformly k records from D for estimating the average gradient д̄t (Line 5). We then compute the variance of the gradient at Line 6 ( is the element-wise product) and convert it to the preconditioned matrixGt at Line 7. We update the parameter at Line 8 with a noise variableN (0, ϵtGt ). It is worth to note that there is a permanent bias in pSGLD due to excluding a correction term in the updating step (Line 8). However, this bias is negligible and excluding the correction term helps to speed up the sampling algorithm which then helps to reduce the nite-sample bias as more steps are executed in a nite amount of time.\nManuscript submi ed to ACM\nAlgorithm 4 ApSGLD: pSGLD Sampling Algorithm Input: Data set D = {di }ni=1, loss function `, privacy parameter ϵ , µ, k , bounded value v and learning rate τ Output: f T +1\n1: V0 ← ®0, f1 ← ®0 2: for t = 1 to T do 3: Compute ϵt ← t−τ 4: Uniformly sample Ωtk = { dt1 , . . . ,dtk } ⊂ D 5: Compute д̄t = ϵ2v ( σ f t n + 1 k ∑k i=1 ∇Cv (`(f\nt ,dti ))) 6: V t ← µV t−1 + (1 − µ)(д̄t д̄t ) 7: Gt ← 1/ ( λI + diaд( √ V t ) ) 8: f t+1 ← f t − ϵt ( Gt · nд̄t ) +N (0, ϵtGt ) 9: Output f T+1"
    }, {
      "heading" : "6 EXPERIMENTAL EVALUATION",
      "text" : "In this section, we present the results of our experiments on four real data sets. We focus on answering the following three important research questions: (1) Does the sampling approach converge to its stationary distribution? (2) What is the trade-o between privacy and accuracy as compared to the non-private estimation? (3) Are the discrete-time regression models good alternatives to the Cox regression model? In the following sections, we address the above research questions accordingly.\n6.1 Data Sets\n6 8 10\nβ(1)\n−1\n0\n1\n2\nβ (2\n)\n(a) FL\n−2 −1 0 1 2 β(1)\n−4\n−2\n0\n2\nβ (2\n)\n(b) TB\n−1.0 −0.5 0.0 0.5 1.0 β(1)\n−2\n−1\n0\n1\nβ (2\n)\n(c) WT\n−1 0 1 2 3 β(1)\n−2\n−1\n0\n1\n2\nβ (2\n)\n(d) SB\ne survival times in these four data sets are normalized to the interval [0, 1]. We set the number of discrete-time intervals q = 200. All the vectors of the explanatory variables are normalized to have zero mean and ed inside the unit sphere. We use the natural cubic spline with e = 3 knots to model the baseline hazard e ect."
    }, {
      "heading" : "6.2 Convergence of the Proposed Sampling Approach",
      "text" : "is section reports on the convergence of our proposed sampling approach. e aim is to check whether it converges to the stationary distribution. e loss function is bounded by the value v = 2 log(n) where n is the size of the data set. We set the parameter σ = 10−2 · 2v/ϵ . At each step of the Markov chain, we randomly pick k = 200 records from the data set to compute the gradient. We set the parameters τ = 0.51, λ = 10−5 and µ = 0.99 in Algorithm 3. In Figure 3, we\nManuscript submi ed to ACM\nplot the estimated probability densities of the two rst parameters (β (1) and β (2)) a er 250 epochs from the sampling process. We remove the rst 104 steps as the Markov chain does not reach the stationary distribution at the beginning. We can observe that the probability densities of the samples are very similar to the normal distributions which are actually what we expect when sampling from the posterior distributions.\nFor a more formal test, we use the mean relative error (MRE) as a statistical test of convergence. MRE is de ned as follows:\nMRE = 1 t t∑ i=1 ‖ fi − f ∗‖ ‖ f ∗‖ (9)\nwhere fi is the parameter vector from the sampling process, f ∗ is the optimal parameter vector which maximizes the likelihood in non-private se ing and t is the number of samples. We plot the MRE as the function of epochs with three di erent privacy budgets in Figure 4. Each epoch is a bundle of n steps. We observe that a er 250 epochs, MRE becomes stable which indicates that the sampling procedure converges to its stationary distribution."
    }, {
      "heading" : "6.3 Trade-o between Privacy and Accuracy",
      "text" : "In this section, we investigate the trade-o between privacy and accuracy in our proposed approaches. We rst need to pick the value of regularization terms for the perturbation approaches (Ext-Obj-Pert and Ext-Out-Pert) as the accuracy of these approaches are very much depend on the regularization parameter Λ. We report in Table 2 the MREs of Ext-Out-Pert with di erent values of Λ and privacy budget ϵ = 6.4. For consistency in performance comparison, we will use the best values of Λ, which lead to the smallest relative error per data set.\nTo measure the accuracy of the proposed approaches at di erent privacy levels, the privacy budget is varied from 0.1 to 6.4. We also use MRE for the measurement. e results are shown in Figure 5. Overall, pSGLD outperforms both Manuscript submi ed to ACM\nExt-Out-Pert and Ext-Obj-Pert approaches. Moreover, we observe that the accuracy of Ext-Out-Pert and Ext-Obj-Pert does not improve much at high privacy budgets. It is due to the large regularization parameter that causes the output parameter moving towards the zero vector instead of the optimal parameter as the regularization term is the dominant factor of the objective function. Meanwhile, our proposed sampling approach (pSGLD) does not su er from this e ect which leads to much be er results at high privacy budgets."
    }, {
      "heading" : "6.4 Comparison with Cox regression",
      "text" : "Here, we want to con rm that the discrete-time regression models are good alternatives to the Cox regression model. We compare the results obtained from the non-private discrete-time regression models without regularization term to the results obtained from Cox regression. We use the relative error (RE) which is de ned as:\nRE = ‖β − β∗‖ ‖β∗‖\nwhere β is from the discrete-time regression with logit link and β∗ is from Cox regression. e results are shown in Table 3. We observe that the results obtained from the discrete-time regressions are very similar to the results obtained from the Cox regression with relative errors ranging from 2% − 9%. At the worse case of the data set TB, the parameter obtained from the discrete-time model β = [0.0122443,−0.849823,−0.239539]′ is still a good approximation of the parameter obtained from the Cox model β∗ = [0.0585478,−0.790977,−0.23906]′. As such, these results con rm that the discrete-time regression models are good alternatives to the Cox regression in practice."
    }, {
      "heading" : "7 CONCLUSION",
      "text" : "In this work, we propose solutions for the problem of protecting di erential privacy for discrete-time regression models used in survival analysis. In particular, we extend the perturbation approaches to a generalized form in which the loss function is a sum of logistic loss functions. In addition, we propose a sampling approach to practically protect di erential privacy by sampling a scaled posterior distribution with the pSGLD sampling algorithm. Even though we focus our work on discrete-time survival regression, our proposed approaches can be applied to other problems with similar loss functions as well. Moreover, our proposed approaches can be easily extended to discrete-time regression models in which the explanatory variables are changed over time. For further work, a di erentially private version of Cox regression would be a good complement to our work."
    }, {
      "heading" : "ACKNOWLEDGMENTS",
      "text" : "e authors would like to thank Dr. Xiaokui Xiao for his insightful comments on the privacy problem of Cox regression. Manuscript submi ed to ACM"
    } ],
    "references" : [ {
      "title" : "Bayesian Posterior Sampling via Stochastic Gradient Fisher Scoring",
      "author" : [ "Sungjin Ahn", "Anoop Koraikara Balan", "Max Welling" ],
      "venue" : "In ICML. Paul D Allison",
      "citeRegEx" : "Ahn et al\\.,? \\Q2012\\E",
      "shortCiteRegEx" : "Ahn et al\\.",
      "year" : 2012
    }, {
      "title" : "Private empirical risk minimization: Ecient algorithms and tight error bounds",
      "author" : [ "1100–1120. Raef Bassily", "Adam Smith", "Abhradeep akurta" ],
      "venue" : null,
      "citeRegEx" : "Bassily et al\\.,? \\Q2014\\E",
      "shortCiteRegEx" : "Bassily et al\\.",
      "year" : 2014
    }, {
      "title" : "e “meaningful use” regulation for electronic health records",
      "author" : [ "Patrick Billingsley" ],
      "venue" : "Science (FOCS),",
      "citeRegEx" : "Billingsley.,? \\Q2014\\E",
      "shortCiteRegEx" : "Billingsley.",
      "year" : 2014
    }, {
      "title" : "Privacy-preserving logistic regression",
      "author" : [ "Kamalika Chaudhuri", "Claire Monteleoni" ],
      "venue" : "In Advances in Neural Information Processing Systems. 289–296",
      "citeRegEx" : "Chaudhuri and Monteleoni.,? \\Q2009\\E",
      "shortCiteRegEx" : "Chaudhuri and Monteleoni.",
      "year" : 2009
    }, {
      "title" : "Stochastic gradient hamiltonian monte carlo",
      "author" : [ "Tianqi Chen", "Emily Fox", "Carlos Guestrin" ],
      "venue" : "In International Conference on Machine Learning",
      "citeRegEx" : "Chen et al\\.,? \\Q2014\\E",
      "shortCiteRegEx" : "Chen et al\\.",
      "year" : 2014
    }, {
      "title" : "Regression models and life-tables",
      "author" : [ "1683–1691. David R Cox" ],
      "venue" : "David Roxbee Cox and David Oakes",
      "citeRegEx" : "Cox.,? \\Q1992\\E",
      "shortCiteRegEx" : "Cox.",
      "year" : 1992
    }, {
      "title" : "Electronic health records in ambulatory care-a national survey of physicians",
      "author" : [ "Alexandra E Shields" ],
      "venue" : "New England Journal of Medicine",
      "citeRegEx" : "Shields,? \\Q2008\\E",
      "shortCiteRegEx" : "Shields",
      "year" : 2008
    }, {
      "title" : "Bayesian sampling using stochastic gradient",
      "author" : [ "Nan Ding", "Youhan Fang", "Ryan Babbush", "Changyou Chen", "Robert D Skeel", "Hartmut Neven" ],
      "venue" : null,
      "citeRegEx" : "Ding et al\\.,? \\Q2014\\E",
      "shortCiteRegEx" : "Ding et al\\.",
      "year" : 2014
    }, {
      "title" : "Use of nonclonal serum immunoglobulin free light chains to predict overall survival in the general population",
      "author" : [ "L Joseph Melton" ],
      "venue" : null,
      "citeRegEx" : "Melton,? \\Q2012\\E",
      "shortCiteRegEx" : "Melton",
      "year" : 2012
    }, {
      "title" : "Dierential privacy: A survey of results",
      "author" : [ "Cynthia Dwork" ],
      "venue" : "Clinic Proceedings,",
      "citeRegEx" : "Dwork.,? \\Q2008\\E",
      "shortCiteRegEx" : "Dwork.",
      "year" : 2008
    }, {
      "title" : "e dierential privacy frontier. In eory of Cryptography Conference. Springer, 496–502",
      "author" : [ "1–19. Cynthia Dwork" ],
      "venue" : "Cynthia Dwork",
      "citeRegEx" : "Dwork.,? \\Q2009\\E",
      "shortCiteRegEx" : "Dwork.",
      "year" : 2009
    }, {
      "title" : "Practical methods of optimization",
      "author" : [ "Roger Fletcher" ],
      "venue" : "Empirical Economics",
      "citeRegEx" : "Fletcher.,? \\Q2014\\E",
      "shortCiteRegEx" : "Fletcher.",
      "year" : 2014
    }, {
      "title" : "Use of electronic health records in US hospitals",
      "author" : [ "David Blumenthal." ],
      "venue" : "New England Journal of Medicine 360, 16 (2009), 1628–1638. Shiva Prasad Kasiviswanathan, Kobbi Nissim, Sofya Raskhodnikova, and Adam Smith. 2013. Analyzing graphs with node dierential privacy. In eory of",
      "citeRegEx" : "Blumenthal.,? 2009",
      "shortCiteRegEx" : "Blumenthal.",
      "year" : 2009
    }, {
      "title" : "Private convex empirical risk minimization and high-dimensional regression",
      "author" : [ "Cryptography. Springer", "457–476. Daniel Kifer", "Adam Smith", "Abhradeep akurta" ],
      "venue" : null,
      "citeRegEx" : "Springer et al\\.,? \\Q2012\\E",
      "shortCiteRegEx" : "Springer et al\\.",
      "year" : 2012
    }, {
      "title" : "Prevalence of monoclonal gammopathy of undetermined signicance",
      "author" : [ "L Joseph Melton III." ],
      "venue" : "New England Journal of Medicine 354, 13 (2006),",
      "citeRegEx" : "III.,? 2006",
      "shortCiteRegEx" : "III.",
      "year" : 2006
    }, {
      "title" : "Preconditioned stochastic gradient Langevin dynamics for deep neural",
      "author" : [ "1362–1369. Chunyuan Li", "Changyou Chen", "David Carlson", "Lawrence Carin" ],
      "venue" : null,
      "citeRegEx" : "Li et al\\.,? \\Q2015\\E",
      "shortCiteRegEx" : "Li et al\\.",
      "year" : 2015
    }, {
      "title" : "Optimizing linear counting queries under dierential privacy",
      "author" : [ "Chao Li", "Michael Hay", "Vibhor Rastogi", "Gerome Miklau", "Andrew McGregor" ],
      "venue" : null,
      "citeRegEx" : "Li et al\\.,? \\Q2010\\E",
      "shortCiteRegEx" : "Li et al\\.",
      "year" : 2010
    }, {
      "title" : "Knowledge discovery and data mining",
      "author" : [ "Yi-An Ma", "Tianqi Chen", "Emily Fox" ],
      "venue" : "In Advances in Neural Information Processing Systems",
      "citeRegEx" : "Ma et al\\.,? \\Q2015\\E",
      "shortCiteRegEx" : "Ma et al\\.",
      "year" : 2015
    }, {
      "title" : "Personalized social recommendations: accurate or private",
      "author" : [ "Ashwin Machanavajjhala", "Aleksandra Korolova", "Atish Das Sarma" ],
      "venue" : null,
      "citeRegEx" : "Machanavajjhala et al\\.,? \\Q2011\\E",
      "shortCiteRegEx" : "Machanavajjhala et al\\.",
      "year" : 2011
    }, {
      "title" : "Dierentially private recommender systems: building privacy into the net",
      "author" : [ "McSherry", "Ilya Mironov" ],
      "venue" : "VLDB Endowment 4,",
      "citeRegEx" : "McSherry and Mironov.,? \\Q2011\\E",
      "shortCiteRegEx" : "McSherry and Mironov.",
      "year" : 2011
    }, {
      "title" : "Discrete-time survival mixture analysis",
      "author" : [ "Katherine Masyn" ],
      "venue" : "Journal of Educational and Behavioral statistics 30,",
      "citeRegEx" : "Muthén and Masyn.,? \\Q2005\\E",
      "shortCiteRegEx" : "Muthén and Masyn.",
      "year" : 2005
    }, {
      "title" : "Privacy for free: Posterior sampling and stochastic gradient monte carlo",
      "author" : [ "3277. Yu-Xiang Wang", "Stephen Fienberg", "Alex Smola" ],
      "venue" : null,
      "citeRegEx" : "Wang et al\\.,? \\Q2015\\E",
      "shortCiteRegEx" : "Wang et al\\.",
      "year" : 2015
    }, {
      "title" : "Privacy-preserving cox",
      "author" : [ "Shipeng Yu", "Glenn Fung", "Romer Rosales", "Sriram Krishnan", "R Bharat Rao", "Cary Dehing-Oberije", "Philippe Lambin" ],
      "venue" : "Series C (Applied Statistics)",
      "citeRegEx" : "Yu et al\\.,? \\Q2008\\E",
      "shortCiteRegEx" : "Yu et al\\.",
      "year" : 2008
    }, {
      "title" : "Towards accurate histogram publication under dierential privacy",
      "author" : [ "1034–1042. Xiaojian Zhang", "Rui Chen", "Jianliang Xu", "Xiaofeng Meng", "Yingtao Xie" ],
      "venue" : null,
      "citeRegEx" : "Zhang et al\\.,? \\Q2014\\E",
      "shortCiteRegEx" : "Zhang et al\\.",
      "year" : 2014
    } ],
    "referenceMentions" : [ {
      "referenceID" : 1,
      "context" : "functions to provide dierential privacy are also proposed in (Bassily et al. 2014; Kifer et al. 2012; Wang et al. 2015) for the ERM problems.",
      "startOffset" : 62,
      "endOffset" : 120
    }, {
      "referenceID" : 21,
      "context" : "functions to provide dierential privacy are also proposed in (Bassily et al. 2014; Kifer et al. 2012; Wang et al. 2015) for the ERM problems.",
      "startOffset" : 62,
      "endOffset" : 120
    }, {
      "referenceID" : 1,
      "context" : "(Bassily et al. 2014) proposed a polynomial run-time algorithm to sampling the log-concave objective function but their algorithm is still impractical due to the high degree of its polynomial run-time complexity.",
      "startOffset" : 0,
      "endOffset" : 21
    }, {
      "referenceID" : 21,
      "context" : "(Wang et al. 2015) proposed to use a stochastic gradient Nosé-Hoover thermostat algorithm (Ding et al.",
      "startOffset" : 0,
      "endOffset" : 18
    }, {
      "referenceID" : 7,
      "context" : "2015) proposed to use a stochastic gradient Nosé-Hoover thermostat algorithm (Ding et al. 2014) to sample the posterior distribution.",
      "startOffset" : 77,
      "endOffset" : 95
    }, {
      "referenceID" : 15,
      "context" : "In this work, we propose to use Preconditioned Stochastic Gradient Langevin Dynamics (pSGLD) sampling algorithm (Li et al. 2015) to sample the objective function due to its advantages in sampling multi-dimensional parameters with dierent scales.",
      "startOffset" : 112,
      "endOffset" : 128
    }, {
      "referenceID" : 22,
      "context" : "(Yu et al. 2008) is the only work on privacy protection for Cox regression.",
      "startOffset" : 0,
      "endOffset" : 16
    }, {
      "referenceID" : 16,
      "context" : "Dierential privacy is used in many applications such as histogram publication (Li et al. 2010; Zhang et al. 2014), graph analysis (Borgs et al.",
      "startOffset" : 79,
      "endOffset" : 114
    }, {
      "referenceID" : 23,
      "context" : "Dierential privacy is used in many applications such as histogram publication (Li et al. 2010; Zhang et al. 2014), graph analysis (Borgs et al.",
      "startOffset" : 79,
      "endOffset" : 114
    }, {
      "referenceID" : 1,
      "context" : "2013; Lu and Miklau 2014), regression and classication (Bassily et al. 2014; Chaudhuri and Monteleoni 2009; Kifer et al. 2012; Wang et al. 2015), recommender systems (Machanavajjhala et al.",
      "startOffset" : 56,
      "endOffset" : 145
    }, {
      "referenceID" : 21,
      "context" : "2013; Lu and Miklau 2014), regression and classication (Bassily et al. 2014; Chaudhuri and Monteleoni 2009; Kifer et al. 2012; Wang et al. 2015), recommender systems (Machanavajjhala et al.",
      "startOffset" : 56,
      "endOffset" : 145
    }, {
      "referenceID" : 18,
      "context" : "2015), recommender systems (Machanavajjhala et al. 2011; McSherry and Mironov 2009), etc.",
      "startOffset" : 27,
      "endOffset" : 83
    }, {
      "referenceID" : 1,
      "context" : "(Bassily et al. 2014) proposed a polynomial run-time sampling algorithm.",
      "startOffset" : 0,
      "endOffset" : 21
    }, {
      "referenceID" : 0,
      "context" : "Recently, there are developments (Ahn et al. 2012; Chen et al. 2014; Ma et al. 2015) in Markov Chain Monte Carlo (MCMC) method which can be applied to machine learning problems with large data sets.",
      "startOffset" : 33,
      "endOffset" : 84
    }, {
      "referenceID" : 4,
      "context" : "Recently, there are developments (Ahn et al. 2012; Chen et al. 2014; Ma et al. 2015) in Markov Chain Monte Carlo (MCMC) method which can be applied to machine learning problems with large data sets.",
      "startOffset" : 33,
      "endOffset" : 84
    }, {
      "referenceID" : 17,
      "context" : "Recently, there are developments (Ahn et al. 2012; Chen et al. 2014; Ma et al. 2015) in Markov Chain Monte Carlo (MCMC) method which can be applied to machine learning problems with large data sets.",
      "startOffset" : 33,
      "endOffset" : 84
    }, {
      "referenceID" : 15,
      "context" : "In this work, we propose to use an MCMC sampling algorithm, namely Preconditioned Stochastic Gradient Langevin Dynamics (pSGLD) (Li et al. 2015), to approximately sample the posterior distribution.",
      "startOffset" : 128,
      "endOffset" : 144
    } ],
    "year" : 2017,
    "abstractText" : "In survival analysis, regression models are used to understand the eects of explanatory variables (e.g., age, sex, weight, etc.) to the survival probability. However, for sensitive survival data such as medical data, there are serious concerns about the privacy of individuals in the data set when medical data is used to t the regression models. e closest work addressing such privacy concerns is the work on Cox regression which linearly projects the original data to a lower dimensional space. However, the weakness of this approach is that there is no formal privacy guarantee for such projection. In this work, we aim to propose solutions for the regression problem in survival analysis with the protection of dierential privacy which is a golden standard of privacy protection in data privacy research. To this end, we extend the Output Perturbation and Objective Perturbation approaches which are originally proposed to protect dierential privacy for the Empirical Risk Minimization (ERM) problems. In addition, we also propose a novel sampling approach based on the Markov Chain Monte Carlo (MCMC) method to practically guarantee dierential privacy with beer accuracy. We show that our proposed approaches achieve good accuracy as compared to the non-private results while guaranteeing dierential privacy for individuals in the private data set.",
    "creator" : "LaTeX with hyperref package"
  }
}