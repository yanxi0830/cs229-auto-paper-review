{
  "name" : "1605.07144.pdf",
  "metadata" : {
    "source" : "META",
    "title" : "Actively Learning Hemimetrics  with Applications to Eliciting User Preferences",
    "authors" : [ "Adish Singla", "Sebastian Tschiatschek", "Andreas Krause" ],
    "emails" : [ "ADISH.SINGLA@INF.ETHZ.CH", "SEBASTIAN.TSCHIATSCHEK@INF.ETHZ.CH", "KRAUSEA@ETHZ.CH" ],
    "sections" : [ {
      "heading" : "1 Introduction",
      "text" : "Learning a distance function over a set of items or a data manifold plays a crucial role in many real-world applications. In machine learning algorithms, the distances serve as a notion of similarity (or dissimilarity) between data points and are important for various tasks such as clustering (Xing et al., 2002), object ranking (Lim & Lanckriet, 2014), image retrieval / classification (He et al., 2004; Huang et al., 2015), etc.1 In economics, the distance function can encode the\n1We refer the interested reader to the survey by Bellet et al. (2013) for a detailed discussion of various applications. Proceedings of the 33 rd International Conference on Machine Learning, New York, NY, USA, 2016. JMLR: W&CP volume 48. Copyright 2016 by the author(s).\npreferences of users (e.g., buyers or sellers in a marketplace) for different items (e.g., from a catalogue of products) to improve product recommendation and dynamic pricing of goods (Desjardins et al., 2006; Horton & Johari, 2015; Blum et al., 2015; Vázquez-Gallo et al., 2014). Motivating applications. We are interested in learning the preferences of users across different choices available in a marketplace — these choices are given in the form of n (types of) items. For instance, in a restaurant recommendation system such as Yelp, the item types could correspond to restaurants abstracted by attributes such as cuisine, locality, reviews and so on. Consider a user who seeks recommendations from the system and has chosen item i (e.g., “Mexican restaurant in Manhattan with over 50 reviews”). However, to incentivize exploration and maximize its overall utility, the marketplace may consider offering a discount to the user to instead choose item j (e.g., “Newly opened fastfood restaurant in New Jersey with 0 reviews”), e.g., to gather more reviews for item j. The price of the offer would clearly depend on how similar or dissimilar the choices i and j are. In general, a high dissimilarity would require the system to offer higher incentives (larger discounts). Distance function quantifying private costs. We capture the above-mentioned notion of dissimilarity by a pairwise distanceDi,j — the distanceDi,j corresponds to the private cost of a user incurred by switching from her default choice of item i to item j. We assume that the distance function D is a hemimetric, i.e., a relaxed form of a metric, satisfying only non-negativity constraints and triangle inequalities. The asymmetry in the distances (i.e., Di,j 6= Dj,i) is naturally required in our application setting — it may arise from various factors such as the underlying quality of the items (e.g., switching between a highly rated and an unreviewed restaurant). Our goal is to efficiently learn the distance functionD via interactions with the users, without assuming any knowledge of the underlying attributes that affect the users’ preferences. User query and active learning. In our setting, the interactions with the users take the form of a binary labeling query, i.e., given two items i and j, and a proposed value c, the user ar X iv :1 60 5. 07 14 4v 2 [ st at .M L ] 2 7 M ay\n2 01\nprovides a positive response iff value c is at least the underlying distance Di,j , and a negative response otherwise. This query is motivated by the posted-price model used in marketplaces (Abernethy et al., 2015; Singla & Krause, 2013), where users are offered a take-it-or-leave-it price by the system, and they can accept by providing a positive response, or reject by providing a negative response. However, we are not considering the economic aspects of the query, and each query has unit cost for the algorithm. Such a feedback setting is realistic and often employed by online marketplaces where queries are posted to the users in form of surveys to seek feedback or the users who accept are awarded the actual monetary offer via a lottery. This paper is concerned with the sample complexity, i.e., the number of queries required to learnD."
    }, {
      "heading" : "1.1 Our Approach and Main Contributions",
      "text" : "A naive approach to this problem is to learn each of the n2 pairwise distances independently. However, the sample complexity of this approach is Θ(n2). Our goal is to reduce the sample complexity by exploiting the structural constraints on the version space of hemimetrics. The main contributions of this paper are as follows: Novel metric learning framework. We propose a new learning problem in the framework of metric learning, motivated by the applications to eliciting users’ preferences. The key distinctive features of our setting are: (i) the specific modality of the user queries (with natural motivation from economics), and (ii) the asymmetry of the distances learnt. Exploiting structural constraints. We develop a novel active learning algorithm LEARNHM that substantially reduces the sample complexity by exploiting the structural constraints of the hemimetric polytope. We provide tight theoretical guarantees on the sample complexity of the proposed algorithm for several natural problem instances. Practical extensions. Our algorithm extends to various important practical settings, including: (i) the online setting where the n items are not known beforehand, and rather appear over time, and (ii) the noisy setting that reflects the stochastic nature of acceptance of offers by the users."
    }, {
      "heading" : "2 Problem Statement",
      "text" : "We now formalize the problem addressed in this paper. Items A. There are n items (or types of items), denoted by the set A = {1, 2, . . . , n}. For instance, in a restaurant recommendation system such as Yelp, A could consist of types of restaurants distinguished by high-level attributes such as cuisine, locality, reviews and so on. HemimetricD∗. LetD be the set of bounded hemimetrics, i.e., matricesD ∈ Rn×n that satisfy\nDi,i = 0 ∀ i ∈ [n], (1) Di,j ≥ 0 ∀ i, j ∈ [n], (2) Di,j ≤ r ∀ i, j ∈ [n], and (3) Di,j ≤ Di,k +Dk,j ∀ i, j, k ∈ [n], (4)\nwhere [n] = {1, 2, . . . , n} and r is the upper bound on the value. We assume that user preferences are represented by an underlying unknown hemimetric D∗ ∈ D. The (asymmetric) distanceD∗i,j quantifies the private costs of the user for switching from item i to j. Our goal is to learnD∗ via interactions with the users, without assuming any knowledge of the underlying attributes that affect the user preferences. User query. A query x ∈ X := {(i, j, c) | i, j ∈ [n], c ∈ [0, r]} to the user is characterized by the tuple (i, j, c), where item i denotes the choice of the user, item j denotes the alternative suggested by the algorithm, and c denotes the monetary incentives offer. Note that the notion of user as used in this paper is rather generic, and could correspond to one single user or a crowd / cohort of users. User response. The response to a query (also called label) is denoted as y = Y (x), where Y : X 7→ {0, 1}. A label y = 1 indicates acceptance, while y = 0 indicates rejection. We denote a labeled datapoint by z = (x, y), where x ∈ X , and y = Y (x). In our setting the acceptance function is stochastic. It is characterized by P(Y (x) = y) and is required to satisfy the following two mild conditions related to the decision boundary atD∗i,j and monotonicity:\nP(Y ((i, j, c)) = 1) ≥ 0.5 iff c ≥ D∗i,j , and P(Y ((i, j, c)) = 1) ≥ P(Y ((i, j, c′)) = 1) for c ≥ c′.\nFor ease of exposition of our main results, we focus on a deterministic noise-free setting in the main paper — treatment of the (more realistic) stochastic acceptance function is presented in Appendix A. In this noise-free setting, the acceptance function reduces to the threshold function\nY ((i, j, c)) = { 1 if c ≥ D∗i,j , 0 otherwise.\n(5)\nObjective. This paper is concerned with the sample complexity, i.e., the number of queries required for learning the unknown hemimetric D∗. We consider a PAC-style setting, i.e., we aim to design an algorithm that, given positive constants ( , δ), determines a hemimetric D̂ ∈ D, such that with probability at least 1− δ it holds that\n‖D̂ −D∗‖∞ ≤ , (6) i.e., |D̂i,j −D∗i,j | ≤ ∀ i, j ∈ [n].\nOur objective is to achieve the desired ( , δ)-PAC guarantee while minimizing the number of user queries."
    }, {
      "heading" : "3 Warmup: Overview of our Approach",
      "text" : "We now present the high-level ideas behind our approach."
    }, {
      "heading" : "3.1 Independent Learning: INDGREEDY",
      "text" : "One possible way to tackle our learning problem is to learn each of the n2 pairwise distances independently. Let us fix a particular pair of items (i, j) ∈ [n]2. Given the query modality considered in our framework, the goal of learning the distanceD∗i,j up to precsion is equivalent to learning a thresh-\nold function in the active-learning setting (Castro & Nowak, 2006; Settles, 2012). In terms of sample complexity, this is most effectively achieved by perfoming a binary-search over the range [0, r]. More formally, at iteration t = 0, we initialize a lower bound of D∗i,j to L t i,j = 0 and an upper bound to U ti,j = r. At any t > 0, we pick a value c t = 12 (L t−1 i,j + U t−1i,j ) and issue the queryx t = (i, j, ct). Then, based on the returned label yt, we update U ti,j = c t if yt = 1, otherwise we update Lti,j = c t if yt = 0. We continue querying until (U ti,j − Lti,j) ≤ , and then output any D̂i,j ∈ [Lti,j , U ti,j ] as the estimated distance. The number of queries required in the noise-free setting is given by dlog( r )e. As there are n 2 pairwise distance learning problems, the total sample complexity of this approach is n2dlog( r )e. Such an algorithm, based on independently learning the pairwise distances, also needs to pick a pair (it, jt) to query at iteration t. One policy inspired by uncertainty sampling (Settles, 2012) is to pick the pair (it, jt) with maximum uncertainty quantified by (U t−1i,j −L t−1 i,j ). This policy can also be seen as to greedily minimize our objective stated in Equation 6. We call this query policy QGREEDY. At any iteration, it issues the query xt = (it, jt, ct) according to\n(it, jt) = arg max (i,j)∈[n]2 (U t−1i,j − L t−1 i,j ), and (7)\nct = 12 (L t−1 it,jt + U t−1 it,jt). (8)\nWe refer to the independent learning algorithm employing query policy QGREEDY as INDGREEDY."
    }, {
      "heading" : "3.2 Exploiting Structural Constraints: LEARNHM",
      "text" : "We now present our algorithm LEARNHM in Algorithm 12. Our algorithm depends on three functions LU-PROJ, QCLIQUE and GETUSERRESPONSE. A high-level description of these functions is given as follows: LU-PROJ shrinks the search space of hemimetrics by updating the lower and upper bounds from L̃t, Ũ t toLt, U t. Details are provided in Section 4. QCLIQUE is the query policy that determines the next query xt = (it, jt, ct) at iteration t given the current state of the learning process as determined by Lt−1 and U t−1. Details are provided in Section 5. GETUSERRESPONSE returns the label yt for query xt. In the deterministic noise-free setting, this label is determined by Equation 5. We also develop a robust noise-tolerant variant of GETUSERRESPONSE for the stochastic setting, discussed in Appendix A."
    }, {
      "heading" : "4 LU-PROJ: Updating Bounds",
      "text" : "We now present the details of our function LU-PROJ. The proof of Theorem 1 is given in Appendix F and the proof of Theorem 2 is given in Appendix G.\n2Algorithm 1 reduces to INDGREEDY if QCLIQUE is replaced by QGREEDY and LU-PROJ(L̃t, Ũ t) simply returns L̃t, Ũ t.\nAlgorithm 1 Our Algorithm: LEARNHM 1: Input: setA of n items, range r, error parameters ( , δ) 2: Output: hemimetric D̂ 3: Initialize:\niteration t = 0; labeled dataZt = ∅ lower bounds: Lti,j = 0 ∀ i, j ∈ [n] upper bounds: U ti,j = r ∀ i, j ∈ [n]\nU ti,i = 0 ∀ i ∈ [n] 4: while ∃i, j : (U ti,j − Lti,j) > do 5: t = t+ 1 6: xt = (it, jt, ct)← QCLIQUE(Lt−1, U t−1) 7: zt = ((it, jt, ct), yt) ← GETUSERRESPONSE(xt) // ct = ct in the noise-free setting 8: Ũ t = U t−1, L̃t = Lt−1\n9: if yt = 1 then 10: update Ũ tit,jt = c t 11: else 12: update L̃tit,jt = c t 13: Lt, U t ← LU-PROJ(L̃t, Ũ t) 14: Zt = Zt−1 ∪ {zt} 15: D̂ ← U t 16: Return: hemimetric D̂"
    }, {
      "heading" : "4.1 Valid Bounds",
      "text" : "We begin by defining minimal conditions for the lower and upper bounds returned by LU-PROJ to be valid in terms of the version space. Let us start by formally defining the version space for our setting. In Algorithm 1, the labeled data at iteration t is given by Zt = {z1, . . . , zt} where zl = (xl, yl) for l ∈ [t]. Then, the version space at iteration t is defined as Dt := {D ∈ D | ∀ l ∈ [t] : D(xl) = yl}, (9) where D(xl) = 1(cl ≥ Dil,jl); here 1(·) denotes the indicator function. That is,Dt ⊆ D is the set of hemimetrics at iteration t that are consistent with the labeled dataZt. Also, for given lower bounds L and upper bounds U , we define the set of hemimetrics satisfying these bounds as D(L,U) := {D ∈ D |L ≤ D ≤ U}, (10) where the inequalities are understood component-wise, i.e., Li,j ≤ Di,j ≤ Ui,j ∀ i, j ∈ [n]. The bounds Lt, U t at iteration t are valid, iff D(Lt, U t) ⊇ Dt. Validity of the bounds ensures thatD∗ is always contained inD(Lt, U t)."
    }, {
      "heading" : "4.2 Updating Bounds via Projection",
      "text" : "We formalize the problem of obtaining the bounds Lt, U t as the solution of the following optimization problem: min U,L ‖U − L‖1 (P1)\ns.t. D(L,U) ⊇ Dt, where the entry-wise `1-norm of a matrix is defined as ‖M‖1 = ∑ i,j |Mi,j |. The intuitive idea behind this problem is to decrease the gap between upper and lower bounds as much as possible while ensuring that the resulting bounds are valid.\nIt turns out, cf. Theorem 1, that Problem P1 can be solved in a two step process by solving the following two problems:\nU∗t = arg min U∈ D s.t. U≤Ũt ‖U − Ũ t‖1 (P2)\nL∗t = arg min L∈ L(U∗t) s.t. L≥L̃t ‖L− L̃t‖1, (P3)\nwhere L̃t, Ũ t are obtained by Algorithm 1 in lines 8–12. Here, the set L parameterized by the upper bound matrix U ∈ D is defined as\nL(U) := {L ∈ Rn×n | Li,i = 0, 0 ≤ Li,j ≤ Ui,j , (11) Li,j ≥ max (Li,k − Uj,k, Lk,j − Uk,i) ∀ i, j, k ∈ [n]}.\nAdditional details and a formal development of these sets are given in Appendix E. While the set of upper bound matrices corresponds to the setD of bounded hemimetrics, the set L(U) represents more complex dependencies. It turns out that the setL cannot be constrained to contain only hemimetrics. In fact, we provide a counter-example in Appendix E. We can now state one of our main theoretical results:\nTheorem 1. The optimal solution of Problem P1 is unique and is given byL∗t, U∗t (defined in Problems P3 and P2)."
    }, {
      "heading" : "4.3 Function LU-PROJ: Tightening Bounds",
      "text" : "We now present an efficient solver for the optimization Problem P1 given by the function LU-PROJ in Algo-\n1: Input: L̃t, U t; Output: Lt 2: Initialize: Lt = L̃t 3: for k = 1 to n do 4: for i = 1 to n do 5: for j = 1 to n do 6: Lti,j = max ( Lti,j , L t i,k − U tj,k, Ltk,j − U tk,i\n) 7: Return: Lt\nrithm 2. The algorithm is invoked with inputs L̃t, Ũ t — its optimality is ensured by the following theorem.\nTheorem 2. The lower and upper bounds Lt, U t returned by LU-PROJ is the unique optimal solution of Problem P1.\nWe now briefly describe the function LU-PROJ. It first invokes the function U-PROJ shown in Algorithm 3 to compute U t — which in fact equals the optimal solution of Problem P2 (refer to the proof of the theorem). Then, it invokes the function L-PROJ shown in Algorithm 4 to compute Lt — which in fact equals the optimal solution of Problem P3 (again, refer to the proof of the theorem). Both U-PROJ and L-PROJ can be seen as iterating over the constraints of the sets D and L, updating variables that violate constraints. U-PROJ is in fact equivalent to the Floyd-Warshall algorithm for solving the all-pair shortest paths problem in a graph (Floyd, 1962). Similar equivalence has been shown by Brickell et al. (2008) while studying the problem of projecting a non-metric matrix to a metric via decrease-only projections. The function L-PROJ operates in similar fashion as U-PROJ. However, additional challenges in the interpretation and analysis of the solution of L-PROJ arise from the fact that the class L is not a set of hemimetrics and has more complex dependencies. Figure 1 provides a geometric interpretation of the constraints imposed by the sets D (Equation 4) and L (Equation 11) exploited by U-PROJ and L-PROJ in line 6."
    }, {
      "heading" : "4.4 Geometric Interpretation ofL∗t andU∗t",
      "text" : "In this section we provide a geometric interpretation of the optimal solution to Problem P1. Consider the space Rn2 . Let us define π0 to be the set of inequalities\n{Di,i = 0, 0 ≤ Di,j ≤ r, Di,j ≤ Di,k +Dk,j ∀ i, j, k ∈ [n]}.\nThus, the subset of Rn2 described by π0 corresponds to the set of bounded hemimetrics. At iteration t, we get a new labeled datapoint zt = ((it, jt, ct), yt) and update the set of inequalities as follows:\nπt = { πt−1 ∪ {ct ≥ Dit,jt} if yt = 1, πt−1 ∪ {ct < Dit,jt} if yt = 0.\nNow, consider the polytope Λt defined by πt in Rn2 . Furthermore, consider the hypercube in Rn2 described by any lower and upper bounds L,U — the extent of the hypercube in dimension (i, j) is given by [Li,j , Ui,j ]. Then, the optimal solution to Problem P1 describes the unique tightest hypercube containing the polytope Λt."
    }, {
      "heading" : "5 QCLIQUE: Proposing Queries",
      "text" : "We first show the limitations of a greedy myopic policy QGREEDY for proposing queries, and then design our query policy QCLIQUE that overcomes these limitations."
    }, {
      "heading" : "5.1 Myopic Policy QGREEDY",
      "text" : "The policy QGREEDY is inspired by the idea of shrinking the gap (U t−1i,j − L t−1 i,j ) of pair (i\nt, jt) with maximum uncertainty. As already mentioned, this policy can be seen as myopic (greedy) in terms of minimizing the objective ‖D̂ − D∗‖∞. However, this policy may turn out to be suboptimal in terms of exploiting the structural constraints of hemimetrics. In particular, consider a simple instance with n items belonging to a single tight cluster, i.e., ∀i, j ∈ [n] : D∗i,j = 0. Clearly, given the 2n distances D∗1,j , D ∗ j,1 for j ∈ [n], one can infer all other distances because of the tightness of the triangle inequalities. For this example, INDGREEDY will, in every iteration t, half the largest upper bound maxi,j U ti,j . Thus, in iteration t, all upper bounds U ti,j are in the range [α/2, α] where α = r · 2−bt/(n2 − n)c and all lower bounds Lti,j = 0. Here, invoking LU-PROJ cannot exploit the structural constraints, i.e., it would simply return (L̃t, Ũ t)."
    }, {
      "heading" : "5.2 Non-myopic Policy QCLIQUE",
      "text" : "We now present an alternative policy QCLIQUE that proposes pairs (it, jt) in a non-myopic way in Algorithm 5. Instead of greedily minimizing ‖D̂ − D∗‖∞, we aim to learn distances in a systematic way such that we can exploit the structural constraints of the hemimetrics more effectively. Note that in this section, we assume a fixed ordering of the items indexed by 1, . . . , n. The high level idea behind QCLIQUE is to maintain a clique of items for which all pairwise distances are already learnt. It proposes queries in a systematic way to grow the clique\nAlgorithm 5 Query Policy: QCLIQUE\n1: Input: Lt−1, U t−1; Output: query (it, jt, ct) 2: C = {i|∀j < i : U t−1i,j −L t−1 i,j ≤ ∧ U t−1 j,i −L t−1 j,i ≤ } 3: a = max C + 1 4: b = minimal i ∈ C s.t. (U t−1a,i − L t−1 a,i > ∨ U t−1 i,a −\nLt−1i,a > )\n5: ifU t−1a,b − L t−1 a,b > then 6: Return: (a, b, 12 (La,b + Ua,b)) 7: else 8: Return: (b, a, 12 (Lb,a + Ub,a))\nitem by item according to the assumed ordering. In more detail, the policy works as follows:\n1. At iteration t, the policy maintains a clique C = {1, . . . , |C|} ⊆ A of items — see line 2 of Algorithm 5. For any pair of items (i, j) ∈ C it holds thatU t−1i,j − L t−1 i,j ≤ . 2. It then identifies the next item to be added to the clique, denoted as a in line 3. 3. Now, it picks an item b ∈ C for which the distance to a is not learnt up to precision in line 4, and returns the next query.\nOnline model. In many practical scenarios, the n items are not known beforehand, and rather appear over time. Let us denote by Am = {1, . . . ,m} ⊆ A the set of items present at timem. When a new item arrives at timem+ 1 we could learn a hemimetric solution from scratch. However, it would be desirable to make use of the hemimetric solution forAm and extend it. In fact, LEARNHM together with QCLIQUE can be readily applied to this scenario. We can identify the clique C with the itemsetAm, wherem = |C|, for which the hemimetric solution is known. The idea of adding a to C in Algorithm 5, is then equivalent to extending the hemimetric solution forAm toAm+1. By this equivalence, the sample complexity of growing the hemimetric solution item by item up to size n is the same as that of computing the hemimetric solution for all n items at once."
    }, {
      "heading" : "6 Performance Analysis",
      "text" : "In this section we analyze the sample complexity and runtime of our proposed algorithm LEARNHM. All proofs are provided in Appendix D."
    }, {
      "heading" : "6.1 Sample Complexity",
      "text" : "Motivated by our preference elicitation application (see Section 7), we analyze sample complexity under a clusteredness assumption. In particular, we say the hypothesis D∗ is (rin,K)-clustered, if the following condition holds: The items are partitioned into K clusters, such that for any pair of items (i, j) their distance is D∗i,j ∈ [0, rin] if i and j are from the same cluster and D∗i,j ∈ [rin, r] otherwise. Note that K and rin are unknown to the algorithm. For this\nsetting, the sample complexity of LEARNHM is bounded by the following theorem.\nTheorem 3. If D∗ is (rin,K)-clustered, the sample complexity of LEARNHM is upper bounded by\n2nK ⌈ log (r )⌉ + n2 ⌈ log (2rin + 3 )⌉ .\nIn real-world applications, the distances D∗i,j might correspond to monetary incentives and are, therefore, naturally quantized to some precision ∆ (monetary incentives are multiples of the smallest currency unit, e.g., one cent). In this setting, the learning algorithms can learn D∗ exactly, i.e., D̂ = D∗, with a bounded number of queries. The idea is that both, INDGREEDY and LEARNHM, can collapse the gap U ti,j − Lti,j to zero whenever U ti,j − Lti,j < ∆. Hence, by invoking these algorithms with any < ∆, we learn D∗ exactly. We then obtain the following corollary for this interesting special case.\nCorollary 1. If D∗ is (0,K)-clustered, and assuming all distancesD∗i,j are quantized to precision ∆ > 0, the sample complexity of LEARNHM to exactly learn D∗ is upper bounded by 2nK ⌈ log ( r ∆ )⌉ . This matches the lower bound of Ω(nK).\nNote that our algorithm LEARNHM does not perform more queries than INDGREEDY for any instance. In fact, the hardest instance for our algorithm is given by D∗ where all distances D∗i,j = r/2. In this case, LU-PROJ cannot exploit any structural constraints — the number of queries performed by LEARNHM exactly equals that of INDGREEDY (equal to n2dlog( r )e).\nStochastic responses. We can also bound the sample complexity for the more realistic case in which query responses are stochastic. Here, we briefly introduce our noise model — a more detailed description is given in Appendix A. Our noise model is parametrized by the variance matrix σ ∈ Rn,n+ unknown to the algorithm. The acceptance functionP(Y ((i, j, c)) = 1) is given by the CDF of a normal distributionN (D∗i,j , σi,j) truncated to [D∗i,j−βi,j , D∗i,j+βi,j ] where βi,j = min{D∗i,j , r −D∗i,j}. Note that in our model the noise is unbounded, i.e., at c = D∗i,j the acceptance function P(Y ((i, j, c)) = 1) = 0.5. In order to deal with this, we develop a robust noise-tolerant variant of GETUSERRESPONSE which ensures that the maximum noise experienced by the algorithm is bounded by\nηmax = 1 2 − ∫ /3 0 e − w2 2maxi,j σ 2 i,j dw∫ r/2\n−r/2 e − w2 2maxi,j σ 2 i,j dw\n.\nThe sample complexity bounds are characterized by the quantity γ = ( 3 ln(3n2/δ) (0.5−ηmax)2 ) — the theoretical results corresponding to the settings in Theorem 3 and Corollary 1 are given as follows.\nTheorem 4. With probability 1 − δ, LEARNHM learns D∗ with precision and the sample complexity is upper bounded by3\nÕ ( γ ( 2nK ⌈ log (3r )⌉ + n2 ⌈ log (6rin + 9 )⌉)) .\nCorollary 2. Consider the case D∗ is (0,K)-clustered, and assume all distances D∗i,j are quantized to precision ∆ > 0. With probability 1 − δ, LEARNHM learns D∗ exactly and the sample complexity is upper bounded by\nÕ ( γ2nK ⌈ log (3r\n∆\n)⌉) ."
    }, {
      "heading" : "6.2 Runtime Analysis and Speeding Up LEARNHM",
      "text" : "We now begin by analyzing the runtime of LEARNHM. The algorithm LEARNHM invokes LU-PROJ after every query — there are Θ(n2 log( r )) calls to LU-PROJ in the worst case. The runtime of LU-PROJ is Θ(n3), resulting in a total runtime Θ(n5 log( r )) — this is prohibitively expensive for most realistic problem instances. The key idea for speeding up LEARNHM is that we can choose the constraints that should be exploited instead of exploiting all the constraints after every query (line 6 in U-PROJ & L-PROJ). If the constraints to be exploited are selected carefully, we can still get reasonable benefits from tightening lower and upper bounds. For LEARNHM, this can be achieved as follows:\n• First, we do not need to invoke LU-PROJ after every query (this is equivalent to not exploiting any violated constraint). At any iteration t, LEARNHM invokes LU-PROJ only if Ũ tit,jt − L̃tit,jt ≤ . Otherwise, it simply sets (Lt, U t)← (L̃t, Ũ t).\n• Second, when LEARNHM invokes LU-PROJ at iteration twe only consider the 2n constraints which involve it, jt\nin lines 4 and 5 of Algorithms 3 and 4.\nDetails of this idea are presented in Appendix B. LEARNHM implementing this idea invokes LU-PROJ at most n2 times each with a runtime of 4n. Hence, the total runtime of the speeded up LEARNHM is Θ(n3). Most importantly, the sample complexity bounds from the previous section still apply."
    }, {
      "heading" : "7 Experimental Evaluation",
      "text" : ""
    }, {
      "heading" : "7.1 Benchmarks",
      "text" : "We compare the performance of the speeded up LEARNHM against the baseline INDGREEDY. We also compare against a second baseline INDGREEDY-SIT (INDGREEDY with side information of triplet comparisons). This baseline utilizes a low-dimensional embedding of the items as a preprocessing step. Following the work of Jamieson & Nowak (2011a), using n2 log n triplet queries, i.e., for a triplet (i, j, k) such a query returns 1(D∗i,j ≤ D∗i,k), one can\n3The Õ(·) notation is used to omit factors logarithmic in the factors present explicitly.\ncompute a low-dimensional embedding of the items. Using this embedding, one can infer the response to all possiblen3 triplet queries — this is the side information that we supply to INDGREEDY-SIT. This side information can be exploited by INDGREEDY-SIT as follows. For a given triplet, 1(D∗i,j ≤ D∗i,k) = 1 implies two constraints on the lower and the upper bounds —Ui,j ≤ Ui,k and Li,k ≥ Li,j . After every query, INDGREEDY-SIT first updates an upper or lower bound according to the response. Then it exploits these two constraints for n3 triplets to tighten the bounds on every pair of items. We will report the sample complexity of INDGREEDY-SIT as the total number of queries for computing the low-dimensional embedding and for learning all distances up to precision ."
    }, {
      "heading" : "7.2 Experimental Setup",
      "text" : "Yelp dataset. We use the recently proposed Yelp Dataset Challenge (round 7) data for our experiments.4 This data contains information about 77K businesses located across 10 cities around the world. We looked into businesses belonging to the category Restaurants and being located in the city of Pittsburgh, PA. In particular, we extracted information for all 290 restaurants offering food from the cuisines Mexican (50), Thai (26), Chinese (53), Mediterranean (75), Italian (86). For each of these restaurants we also collected the review count and coordinates (longitude and latitude). We discretized the review count into High (popular, 166 restaurants) when there were more than 25 reviews and into Low (unpopular, 124 restaurants) otherwise. The collected data is visualized in Figure 3. User preference models. We simulate user preference models from this data by creating the underlying hemimetricD∗ as follows. For notational ease, we use the shorthands cuisinei, reviewi, lati, longi to refer to the above mentioned attributes for item i. We quantify the distance between item i and j by Wi,j = w1W cuisine i,j + w2W review i,j + w3W geo i,j + w4W random i,j , where W cuisinei,j = r1(cuisinei 6= cuisinej), W reviewi,j = r1(reviewi > reviewj), W geoi,j is the great-circle distance based on the latitude and longitude coordinates normalized to lie in [0, r], and W randomi,j is drawn uniformly at random from [0, r]. Recall, r is the upper bound on the distance. The weights w1, . . . , w4 ∈ R+ sum up to 1. We compute D∗ as the closest metric toW according to Brickell et al. (2008). For different weights w1, . . . , w4, we can instantiate different user preference modelsD∗. In particular, we instantiate the following two models. In the first model (YelpM1), we use w1 = 0.9, w4 = 0.1 and w2 = w3 = 0 — this corresponds to the setting we considered in Theorem 3 with K = 5 and intra cluster distance rin ≤ w4 · r. The sec-\n4https://www.yelp.com/dataset challenge/"
    }, {
      "heading" : "8 Related Work",
      "text" : "8.1 Metric Learning & Low-dimensional Embeddings Learning distances to capture notions of similarity or dissimilarity plays a central role in many machine learning\napplications. We refer the reader to the detailed surveys by Yang & Jin (2006); van der Maaten et al. (2009); Bellet et al. (2013). Some of the key distinctions of our formulation from the existing research are described in the following. Supervised metric learning. In their seminal work, Xing et al. (2002) introduced the supervised metric learning framework for learning Mahalanobis distance functions via a convex formulation. In contrast to our setting, they assume that the algorithm has access to the feature space of the input data. Furthermore, this framework and its variants are restricted to recover symmetric distance functions. Another line of research considers learning asymmetric distances, for instance by learning local invariant Mahalanobis distances (Fetaya & Ullman, 2015) or by learning general bilinear similarity matrices (Liu et al., 2015). However, this line of work is not directly applicable to our setting because it also requires access to the feature space of the input data. Learning embeddings. Another line of research is that of learning low-dimensional embeddings for a set of items respecting the observed geometric relations between these items (Amid & Ukkonen, 2015; Tamuz et al., 2011; Cox & Cox, 2000; Jamieson & Nowak, 2011a). For applications involving human subjects, a triplet-based queries framework — for a triplet (i, j, k) it queries1(Di,j ≤ Di,k) — has been employed. However the distances recovered from these approaches are merely optimized to respect the observed relations seen in the data from query responses — they are symmetric and importantly do not have an actual quantitative (economic) interpretation as we seek in our formulation."
    }, {
      "heading" : "8.2 Exploiting Structural Constraints",
      "text" : "Our approach of exploiting the structural constraints of the hemimetrics polytope is in part inspired by Elkan (2003), who acceleratesK-means by exploiting the triangle inequality. By maintaining bounds on the distances, he efficiently reduces the number of distance computations. Brickell et al. (2008) study the problem of projecting a non-metric matrix to a metric matrix, and consider a specific class of decrease-only projections. Our approach towards updating upper bounds via decrease-only projections is similar in spirit. However, the main technical difficulties arise in maintaining and updating the lower bounds, for which we develop novel techniques. The active-learning approach pro-\nposed by Jamieson & Nowak (2011a) exploits the geometry of the embedding space to minimize the sample complexity using triplet-based queries. While similar in spirit, their approach is based on triplet-based queries, and differs from our methodology of exploiting the structural constraints."
    }, {
      "heading" : "8.3 Learning User Preferences",
      "text" : "Another relevant line of research is concerned with eliciting user preferences. Specifically, we seek to learn private costs of a user for switching from her default choice of item i to instead choose item j. This type of preferences can be used in marketing applications, e.g., for persuading users to change their decisions (Kamenica & Gentzkow, 2009). Singla et al. (2015) considered similar preferences in the context of balancing a bike-sharing system by incentivizing users to go to alternate stations for pickup or dropoff of bikes. Abernethy et al. (2015) considered the application of purchasing data from users, and quantified the prices that should be offered to them. One key difference of our approach is that we are interested in jointly learning the preferences between n items, i.e., tackling n2 learning problems jointly."
    }, {
      "heading" : "8.4 Active Learning",
      "text" : "Our problem formulation shares the goal of reducing sample complexity with other instances of active learning (Settles, 2012). Our goal to specifically exploit the structural constraints of the hemimetric polytope is along the lines of research in structured active learning where the hypotheses or the output label space have some inherent structure that can be utilized, e.g., the structure of part-of-speech tagging of the sentence (Roth & Small, 2006)."
    }, {
      "heading" : "9 Conclusions",
      "text" : "We investigated the novel problem of actively learning hemimetrics. The two key techniques used in the construction of our algorithm LEARNHM are novel projection techniques for tightening the lower and upper bounds on the solution space and a non-myopic (non-greedy) query policy. Our algorithm can be readily applied to the online setting allowing one to extend the hemimetric solution over time. We provided a thorough analysis of the sample complexity and runtime of our algorithm. Our experiments on Yelp data showed substantial improvements over baseline algorithms in line with our theoretical findings.\nAcknowledgements. This research is supported in part by SNSF grant 200020 159557 and the Nano-Tera.ch program as part of the Opensense II project."
    }, {
      "heading" : "A Robust Noise-tolerant Algorithms",
      "text" : "In this section, we introduce our noise model and the corresponding stochastic acceptance function. Furthermore, we present a robust noise-tolerant variant of GETUSERRESPONSE for this stochastic setting.\nA.1 Noise Model Our noise model is parametrized by the variance matrix σ ∈ Rn,n+ which is unknown to the algorithm. The acceptance function P(Y ((i, j, c)) = 1) is given by the CDF of a normal distribution N (D∗i,j , σi,j) truncated to [ai,j , bi,j ] = [D ∗ i,j − βi,j , D∗i,j + βi,j ] where βi,j = min{D∗i,j , r −D∗i,j}, i.e.,\nP(Y ((i, j, c)) = 1) =  0 0 ≤ c < ai,j , 1 bi,j < c ≤ r, Φ ( c−D∗i,j σi,j ) −Φ (ai,j−D∗i,j σi,j ) Φ ( bi,j−D∗i,j\nσi,j\n) −Φ (ai,j−D∗i,j\nσi,j ) otherwise. Here, Φ(·) denotes the CDF of the standard normal distribution. Equivalently, the acceptance function could have been defined as\nP(Y ((i, j, c)) = y) = { 1− η((i, j, c)) if y = 1(c ≥ D∗(i,j)) η((i, j, c)) otherwise ,\nwhere η((i, j, c)) corresponds to the noise rate and is given as\nη((i, j, c)) =  0 0 ≤ c < ai,j , 0 bi,j < c ≤ r, Φ ( c−D∗i,j σi,j ) −Φ (ai,j−D∗i,j σi,j ) Φ ( bi,j−D∗i,j σi,j ) −Φ (ai,j−D∗i,j σi,j ) ai,j ≤ c < D∗i,j , 1− Φ ( c−D∗i,j σi,j ) −Φ (ai,j−D∗i,j σi,j ) Φ ( bi,j−D∗i,j\nσi,j\n) −Φ (ai,j−D∗i,j\nσi,j ) D∗i,j ≤ c ≤ bi,j . Note that in our model, for the caseD∗i,j = 0 the noise rate is zero and every offer is accepted; and for the caseD ∗ i,j = r the noise rate is also zero and all offers less than r are rejected.\nThe noise rate in our model is unbounded, i.e., at c = D∗i,j the acceptance function P(Y ((i, j, c)) = 1) = 0.5.\nA.2 Robust GETUSERRESPONSE We now develop a robust variant of the function GETUSERRESPONSE for our noise model. The key idea is to ensure that the maximum noise ηmax experienced by the function satisfies ηmax < 0.5. In this way, the noise actually experienced is bounded and we can easily extend the function GETUSERRESPONSE from the noise-free case by issuing repeated queries and deciding on the final label via majority voting — this approach has been extensively studied in the active learning literature (Kääriäinen, 2006; Jamieson & Nowak, 2011b; Castro & Nowak, 2006).\nGETUSERRESPONSE for bounded noise. Our function GETUSERRESPONSE for bounded noise is shown in Algorithm 6 — adopted from (Kääriäinen, 2006). For a query x = (i, j, c) with underlying unknown noise rate η(x), the number of queries to the user is\nÕ\n( ln(n 2\nδ )\n(0.5− η(x))2\n) .\nGETUSERRESPONSE for unbounded noise. The sample complexity of the repeated query approach depends on the noiserate η(x). In particular, the complexity is a function of γ′ = 1(0.5−η(x))2 . Thus, as long as the noise-rate is bounded away from 0.5, the repeated query approach can be used. However, in our noise model, the noise-rate is 0.5 at c = D∗i,j . The key idea to deal with this challenge is, given a query x = (i, j, c), to actually issue three queries in “parallel”: x− = (i, j,max(0, c − α )), x = (i, j, c), x+ = (i, j,min(r, c + α )), where α ∈ (0, 0.5). One of these queries has noise rate strictly less than 0.5. The repeated query algorithm GETUSERRESPONSE for unbounded noise is shown in Algorithm 7.\nAlgorithm 6 GETUSERRESPONSE for bounded noise\n1: Input: xt = (it, jt, ct), LEARNHM parameters (n, r), error parameters ( , δ) 2: Output: label yt 3: Initialize:\niteration l = 0; probabilities pl1 = p l 0 = 1 2 ; counts n l 1 = n l 0 = 0 δ′ = δ/ ( n2 log r ) // needed for the PAC guarantees 4: while TRUE do 5: l = l + 1 6: y ← get response from user for query xt 7: update nl1 = n l−1 1 + 1(y = 1); n l 0 = n l−1 0 + 1(y = 0) 8: update pl1 = nl1 l ; p l 0 = nl0 l\n9: βl = √\n1 2l̇\nln ( π2l2\n3δ′ ) 10: if pl1 − βl ≥ 0.5 then 11: Return: yt = 1 12: if pl1 + βl < 0.5 then 13: Return: yt = 0\nFor a query x = (i, j, c), the number of queries to the user is\nÕ\n( 3 ln(3n 2\nδ )\n(0.5−min{η(x−), η(x), η(x+)})2\n) .\nThe largest noise rate ηmax(i, j) experienced by GETUSERRESPONSE for pair (i, j) is bounded by ηmax(i, j) = min{η(i, j,D∗i,j), η(i, j,max(0, D∗i,j − α )), η(i, j,min(r,D∗i,j + α ))}. We can now define the largest noise rate ηmax experienced by GETUSERRESPONSE as ηmax = maxi,j∈[n] ηmax(i, j). Using the parameters of the noise model we can bound ηmax in terms of the largest variance σmax = maxi,j∈[n] σi,j by\nηmax ≤ Φ ( −α σmax ) − Φ ( −r/2 σmax ) Φ ( r/2 σmax ) − Φ ( −r/2 σmax\n) = ∫ −α −r/2 e\n− w2 2σ2max dw∫ r/2\n−r/2 e − w2 2σ2max dw\n= 1 2 − ∫ α 0 e − w2\n2σ2max dw∫ r/2 −r/2 e − w2 2σ2max dw .\nThe worst case number of queries to the user is characterized by the quantity\nγ = 3 ln( 3n\n2\nδ )\n(0.5− ηmax)2 ."
    }, {
      "heading" : "B Speeding up LEARNHM",
      "text" : "The key idea for speeding up LEARNHM is that we can choose the constraints that should be exploited instead of exploiting all the constraints after every query (line 6 in U-PROJ & L-PROJ). If the constraints to be exploited are selected cleverly, we can still get reasonable benefits from tightening lower and upper bounds. For LEARNHM this can be achieved as follows:\n• First, we do not need to invoke LU-PROJ after every query (this is equivalent to not exploiting any violated constraint). At any iteration t, LEARNHM invokes LU-PROJ only if Ũ tit,jt − L̃tit,jt ≤ . Otherwise, it simply sets (Lt, U t)← (L̃t, Ũ t). • Second, when LEARNHM invokes LU-PROJ at iteration t we only consider the 2n constraints which involve it, jt in lines 4 and 5 of Algorithms 3 and 4.\nThe faster variant of LU-PROJ is given by the function in Algorithm 8, which in turn calls the faster variant of U-PROJ (Algorithm 9) and the faster variant of L-PROJ (Algorithm 10). The function LU-PROJ in Algorithm 8 has the additional inputs Pivots,STpairs. By calling LU-PROJ with Pivots = ∅,STpairs = ∅, this is\nAlgorithm 7 GETUSERRESPONSE for unbounded noise\n1: Input: xt = (it, jt, ct), LEARNHM parameters (n, r), error parameters ( , δ) 2: Output: data point zt = ((it, jt, ct), yt) 3: Initialize: δ′′ = δ3 log( r )\nlog( r (1−2α) ) // needed for the PAC guarantees\nα = 13 xt1 = (i\nt, jt, ct) xt2 = (i\nt, jt,max(0, ct − α )) xt3 = (i\nt, jt,min(r, ct + α )) iteration l = 0;\n4: while TRUE do 5: l = l + 1 6: Invoke GETUSERRESPONSE in Algorithm 6 for xt1, x t 2 and x t 3 with noise parameters ( , δ\n′′) in parallel; terminate execution once any of these invocations terminated — letm be the index of the invocation that terminated first and let yt be its returned label\n7: Return: data point zt = (xtm, yt)\nAlgorithm 8 Faster variant of LU-PROJ\n1: Input: L̃t, Ũ t, Pivots,STpairs 2: Output: Lt, U t 3: U t ← U-PROJ(Ũ t,Pivots,STpairs) 4: Lt ← L-PROJ(L̃t, U t,Pivots,STpairs) 5: Return: Lt, U t\nAlgorithm 9 Faster variant of U-PROJ\n1: Input: Ũ t, Pivots,STpairs 2: Output: U t 3: Initialize: U t = Ũ t 4: for k ∈ Pivots do 5: for (i, j) ∈ STpairs do 6: U ti,j = min ( U ti,j , U t i,k + U t k,j\n) 7: Return: U t\nAlgorithm 10 Faster variant of L-PROJ\n1: Input: L̃t, U t, Pivots,STpairs 2: Output: Lt 3: Initialize: Lt = L̃t 4: for k ∈ Pivots do 5: for (i, j) ∈ STpairs do 6: Lti,j = max ( Lti,j , L t i,k − U tj,k, Ltk,j − U tk,i\n) 7: Return: Lt\nequivalent to not exploiting any violated constraint. At iteration t, after LEARNHM invoked the query (it, jt, ct) proposed by QCLIQUE and updated the local bounds, LEARNHM invokes LU-PROJ (when Ũ tit,jt − L̃tit,jt ≤ ) with STpairs = ({max(it, jt)} × C) ∪ (C × {max(it, jt}) and sets Pivots = {min(it, jt)}.\nLEARNHM implementing this idea invokes LU-PROJ at most n2 times with a runtime of 4n. Hence, the total runtime of LEARNHM is Θ(n3). Most importantly, the sample complexity bounds from the previous section still apply. In fact, the proofs for the sample complexity bounds analyze the speeded up variant of LEARNHM because of ease of analysis.\nFurthermore, we can make the following observations:\n• The function LU-PROJ in Algorithm 8 is a strict generalization of Algorithm 2 — by passing Pivots =\n[n],STpairs = [n]2, it reduces to Algorithm 2. • The resulting outputLt andU t may not be the optimal solutions to the Problems P3 and P2, respectively."
    }, {
      "heading" : "C Experimental Results for Stochastic Settings",
      "text" : "We perform two sets of experiments for the stochastic setting. In the stochastic setting with bounded noise rate (i.e., the algorithm knows that the noise rate is bounded away from 0.5), LEARNHM uses the function GETUSERRESPONSE for bounded noise in Algorithm 6. In our noise model (i.e., the algorithm makes no assumption about the bound on the noise rate), LEARNHM uses the function GETUSERRESPONSE for unbounded noise in Algorithm 7. Figures 4 (a-c) show results for the stochastic setting with bounded noise rate parameterized by (ηBN, σ). Then, we present results for our noise model in Figures 4 (d-f) parameterized by σ. We used the same value of variance for all the pairs, i.e., ∀i, j ∈ [n] : σi,j = σmax. The PAC-parameters are set to ( = 0.01, δ = 0.05). The other parameters are set similar to the noise-free setting, i.e., n = 100, r = 1.\nStochastic acceptance function. Figure 4d shows the acceptance function for σmax = 0.1 when D∗i,j = 0.6. Figure 4a shows the corresponding acceptance function for the bounded noise setting with the noise rate ηBN = 0.3. Results for bounded noise rate. Figure 4b and Figure 4c show the results for bounded noise rate on the two preference models YelpM1 and YelpM2 respectively. We vary the bound on the noise rate ηBN, and the value of σmax is fixed to 0.1. We observe that the sample complexity increases drastically for all the algorithms as ηBN approaches 0.5. LEARNHM outperforms INDGREEDY for both user preference models, though the relative gain of sample complexity improvements of LEARNHM in comparison to INDGREEDY decreases with increasing ηBN. Note that as ηBN increases, the cost of repeated querying near the threshold boundary dominates the sample complexity and tends to infinity. Results for our noise model. Figure 4e and Figure 4f show the results for our noise model by varying the variance σmax, on YelpM1 and YelpM2 respectively. GETUSERRESPONSE for unbounded noise in Algorithm 7 ensures that the sample complexity stays bounded away from∞. As we increase σmax, the CDF eventually resembles the uniform noise setting, and the sample complexity curve saturates.\nMost importantly, LEARNHM constantly outperforms INDGREEDY across different noise settings and different user preference models."
    }, {
      "heading" : "D Sample Complexity Analysis",
      "text" : "Proof of Theorem 3. Consider the current clique C, and a new item a ∈ A \\ C that should be added to C. In order to do so, the policy needs to learn all distances between a and all items in C. During this process of learning all distances between a\nand all items in C, let us say that LEARNHM / QCLIQUE has already learnt all distances between a and items C′ ⊂ C, and is now learning the distance between a and b ∈ C \\ C′. That is, LEARNHM / QCLIQUE is growing C′ until C′ = C, and then item awill be added. We will consider the following cases:\nC1 b is the first item of its cluster that will be added to C′. C2 Another item e from the same cluster as b is already part of C′.\nC2.1 b belongs to the same cluster as a C2.2 b belongs to a different cluster as a\nC1: In order to learn the distances between (a, b) and (b, a), the number of queries is bounded by⌈ log (r )⌉ .\nC2.1: In order to learn the distance between (a, b) or (b, a), the number of queries is bounded by⌈ log (2rin + 2 )⌉ .\nTo see this, note that Ua,b ≤ Ua,e + Ue,b\n≤ (rin + ) + (rin + ) = 2rin + 2 .\nSince La,b ≥ 0, and our goal is to shrink the gap Ua,b − La,b to at most , we need at most the above numbers of queries. The same argument clearly also holds for shrinkingUb,a − Lb,a to at most . C2.2: In order to learn distance between (a, b) or (b, a), the number of queries is bounded by⌈ log (2rin + 3 )⌉ .\nTo see this, note that we can subtract the inequalities Ua,b ≤ Ua,e + Ue,b and La,b ≥ La,e − Ub,e to get Ua,b − La,b ≤ (Ua,e − La,e) + Ue,b + Ub,e. We bound the resulting inequality as follows:\nUa,b − La,b ≤ (Ua,e − La,e) + Ue,b + Ub,e ≤ ( ) + (rin + ) + (rin + ) = 2rin + 3 .\nSince La,b ≥ 0, and our goal is to shrink the gap Ua,b − La,b to at most , we need at most the above numbers of queries. A similar argument holds for shrinkingUb,a − Lb,a to at most .\nCase C1 can only occur min{|C| − 1,K} times. Case C2.1, and C2.2 can occur up to |C| times. Hence, the total cost of adding item a to C is bounded by\n2 min{|C| − 1,K} ⌈ log (r )⌉ + 2|C| ⌈ log (max{2rin + 2 , 2rin + 3 } )⌉ .\nGiven that we will add n items to C, the total sample complexity of LEARNHM is n−1∑ |C|=1 2 min{|C| − 1,K} log (r ) + 2|C| log (max{2rin + 2 , 2rin + 3 } )\n≤ n−1∑ |C|=1 2 min{|C| − 1,K} ⌈ log (r )⌉ + 2|C| ⌈ log (2rin + 3 )⌉ .\nThis gives us the bound on the sample complexity from Theorem 3, i.e., 2nK ⌈ log (r )⌉ + n2 ⌈ log (2rin + 3 )⌉ .\nProof of Corollary 1. This proof follows the same lines as that of Theorem 3. Therefore, we only show the differences in the proof. Since we invoked the algorithm with < ∆, we can for any i, j ∈ [n] collapse the gap Ui,j − Li,j to zero wheneverUi,j − Li,j < ∆.\nC1: In order to learn the distances between (a, b) and (b, a), the number of queries is bounded by⌈ log ( r\n∆\n)⌉ .\nC2.1: In this setting, the number of queries is actually zero. To see this, note that Ua,b ≤ Ua,e + Ue,b\n≤ 0 + 0 = 0.\nC2.2: In this setting, the number of queries is again zero. To see this, note that Ua,b − La,b ≤ (Ua,e − La,e) + Ue,b + Ub,e\n≤ 0 + 0 + 0 = 0.\nThis leads to the total sample complexity\n2nK ⌈ log ( r\n∆\n)⌉ .\nTo this end, we prove a lower bound on the sample complexity. Therefore, consider a more powerful algorithm which knows that there areK clusters, as well as one item from every cluster. We assume that the clusters are balanced equally. Now, given an item i, learning all the distances to all the other items, is equivalent to assigning the item i to its cluster. On average K2 queries are need to perform this for item i, giving a lower bound of Ω(nK) — even for this powerful variant of the algorithm with additional information.\nProof of Theorem 4. Note that we introduced γ = 3 ln(\n3n2\nδ )\n(0.5−ηmax)2 in Appendix A which quantifies the maximum number of queries to the user in the unbounded noise case when using the function GETUSERRESPONSE in Algorithm 7.\nThe only key insight that is missing to prove this theorem is to bound the number of invocations of GETUSERRESPONSE with parameterα needed to shrink a gap g0 := Ui,j −Li,j to be at most . For this, note that one invocation to GETUSERRESPONSE with ct = 12 (Li,j + Ui,j) may not return the label for c but for c ± α . Thus, after updating the bounds, the gap g 1 is in the worst-case g 0\n2 + α . Thus, to ensure that the gap is shrunk below , at most dlog g0\n(1−2α)e invocations of GETUSERRESPONSE are necessary — in contrast, using binary search in the noise-free case, at most dlog g 0 e invocations are neeeded.\nTo finish the proof, consider the sample complexity from Theorem 3 from the noise-free setting and set α = 13 . We have to adopt it as follows:\n• All terms quantifying the numbers of invocations of GETUSERRESPONSE to shrink a gap g to at most , i.e., dlog( g )e, are replaced by dlog 3g e.\n• Each invocation has a cost of Õ(γ).\nThus, with probability 1− δ, LEARNHM learnsD∗ to precision and has sample complexity Õ ( γ ( 2nK ⌈ log (3r )⌉ + n2 ⌈ log (6rin + 9 )⌉)) .\nProof of Corollary 2. Apply the same arguments from Theorem 4 to Corollary 1.\nE SetL for Lower Bounds andD for Upper Bounds We now provide a formal reasoning for using the sets L andD as the lower bounds L and upper bounds U for projection in Problems P3 and P2, respectively.\nIn order to formally get the setD for upper bounds, for any i, j, k ∈ [n], we can state: D∗i,j ≤ D∗i,k +D∗k,j ≤ Ui,k + Uk,j\n=⇒ D∗i,j ≤ min k′∈[n] (Ui,k′ + Uk′,j)\n=⇒ Ui,j = min k′∈[n] (Ui,k′ + Uk′,j)\n=⇒ Ui,j ≤ Ui,k + Uk,j ∀k ∈ [n] (12)\nUsing Equation 12, we define the set of matrices for the upper bounds as follows. Note that this corresponds to the set of hemimetricsD (Equation 4). Remember,\nD := {U ∈ Rn×n | Ui,i = 0, 0 ≤ Ui,j ≤ r, Ui,j ≤ Ui,k + Uj,k ∀ i, j, k ∈ [n]}.\nIn order to formally get the setL for lower bounds, for any i, j, k ∈ [n], we can state: D∗i,k ≤ D∗i,j +D∗j,k\n=⇒ D∗i,j ≥ D∗i,k −D∗j,k ≥ Li,k − Uj,k =⇒ D∗i,j ≥ max\nk′∈[n] (Li,k′ − Uj,k′) (13)\nSimilarly, we can state: D∗k,j ≤ D∗k,i +D∗i,j\n=⇒ D∗i,j ≥ D∗k,j −D∗k,i ≥ Lk,j − Uk,i =⇒ D∗i,j ≥ max\nk′∈[n] (Lk′,j − Uk′,i) (14)\nCombining Equations 13, 14 from above, we get: D∗i,j ≥ max\nk′∈[n]\n( max (Li,k′ − Uj,k′ , Lk′,j − Uk′,i) ) =⇒ Li,j = max\nk′∈[n]\n( max (Li,k′ − Uj,k′ , Lk′,j − Uk′,i) ) =⇒ Li,j ≥ max (Li,k − Uj,k, Lk,j − Uk,i) ∀k ∈ [n] (15)\nUsing Equation 15, we define the setL parameterized by the upper bound matrixU ∈ D as follows: L(U) := {L ∈ Rn×n |Li,i = 0, 0 ≤ Li,j ≤ Ui,j , Li,j ≥ max (Li,k − Uj,k, Lk,j − Uk,i ∀ i, j, k ∈ [n])}\nWhile the set of upper bounds corresponds to the setD of bounded hemimetrics, the set L(U) represents more complex dependencies. It turns out that the setL(U) cannot be constrained to contain only hemimetrics. We provide a counter-example below.\nCounter-example. Here, we provide an example to demonstrate that if we restrict the setL(U) to hemimetrics only, we may obtain invalid lower bounds.\nConsider the following underlying hemimetricD∗:\nD∗ =  0 1 0.51 0 0.5 0.5 0.5 0  At iteration t = 0, we haveZ0 = ∅. The lower boundsL0 and upper boundsU0 are defined as follows:\nL0 = 0 0 00 0 0 0 0 0 \nU0 = 0 1 11 0 1 1 1 0  At iteration t = 1, let us consider that the algorithm picks the query x1 = (1, 2, 0.5) and receives the label y1 = 0. Let us see how to update the bounds to incorporate this labeled datapoint z1 = (x1, y1).\nWe haveU1 = Ũ1 = U0. We initialize L̃1 = L0, and update L̃11,2 = 0.5. We get:\nL̃1 = 0 0.5 00 0 0 0 0 0  Now if we restrict the classL to be of set of hemimetricsD, then the projection of L̃1 to setD will give us the followingL1:\nL1 = 0 0.5 a0 0 0 0 0.5− a 0  where a ∈ [0, 0.5].\nFirst of all, it is clear that the updated lower boundL1 is not unique as any a ∈ [0, 0.5] represents a corresponding solutionL1.\nSecondly, the boundsL1, U1 after the update are not valid anymore. Consider the following hemimetricD′, where b ∈ [0, 1], given below:\nD′ = 0 1 b1 0 1 1 1− b 0  D′ is in the version space for all b, i.e.,D′ ∈ D1. However:\n• If a > 0, then allD′ with b ∈ [0, a) are excluded, i.e.,D′ /∈ D(L1, U1). • Otherwise, if a = 0, then allD′ with b ∈ (0.5, 1] are excluded, i.e.,D′ /∈ D(L1, U1)."
    }, {
      "heading" : "F Proof of Theorem 1",
      "text" : "In this section we provide the proof of Theorem 1. The proof builds upon three lemmas, which are presented first.\nLemma 1. Assume Lt−1 and U t−1 satisfy D(Lt−1, U t−1) = cl(Dt−1), where cl(·) denotes the closure. Then, L̃t, Ũ t obtained by the local updates in Algorithm 1 (lines 9–12) after querying xt = (it, jt, ct) and observing response yt, satisfy D(L̃t, Ũ t) = cl(Dt).\nProof. Note that Dt can be written as Dt = D ∩ Πt, where Πt ⊆ Rn×n is the intersection of half-spaces defined by the constraints of the labeled datapoints. Formally,\nΠt = {D ∈ Rn×n | 1(ct ′ ≥ Dit′ ,jt′ ) = y t′ ∀t′ ≤ t} = ⋂ t′≤t {D ∈ Rn×n | 1(ct ′ ≥ Dit′ ,jt′ ) = y t′}\n= ⋂ t′≤t {D ∈ Rn×n | ct ′ ≥ Dit′ ,jt′ if y t′ = 1, or ct ′ < Dit′ ,jt′ if y t′ = 0}.\nConsequently, it follows from an easy geometric argument that cl(Dt) = D ∩Πt, where Π t = ⋂ t′≤t {D ∈ Rn×n | ct ′ ≥ Dit′ ,jt′ if y t′ = 1, or ct ′ ≤ Dit′ ,jt′ if y t′ = 0}.\nIt is now easy to see the claimed equivalence ofD(L̃t, Ũ t) and cl(Dt). Consider the following two cases:\n• C1: The response is given as yt = 1. In this case Ũ t is updated to Ũ t = ct in Algorithm 1 (lines 9–12). Hence, D(L̃t, Ũ t) consists of all hypothesis D ∈ D(Lt−1, U t−1) = cl(Dt−1) that satisfy ct ≥ Dit,jt . Also, cl(Dt) = cl(Dt−1) ∩ {D ∈ Rn×n | ct′ ≥ Dit′ ,jt′}, i.e., the same hypotheses are in cl(Dt). • C2: The response is given as yt = 0. In this case L̃t is updated to L̃t = ct in Algorithm 1 (lines 9–12). Hence, D(L̃t, Ũ t) consists of all hypothesis D ∈ D(Lt−1, U t−1) = cl(Dt−1) that satisfy ct ≤ Dit,jt . Also, cl(Dt) = cl(Dt−1) ∩ {D ∈ Rn×n | ct′ ≤ Dit′ ,jt′}, i.e., the same hypotheses are in cl(Dt).\nLemma 2. Problem P2 has a unique optimal solution U∗t that is given by U∗ti,j = maxD∈D(L̃t,Ũt)Di,j and satisfies D(L̃t, U∗t) = D(L̃t, Ũ t).\nProof. Let us define D̃tmax ∈ Rn×n via D̃tmax;i,j = max\nD∈D(L̃t,Ũt) Di,j ∀i, j ∈ [n].\nNote that D̃tmax ∈ Rn×n is feasible for Problem P2:\n• D̃tmax ≤ Ũ t is obvious from the definition. • To see that D̃tmax ∈ D, fix i, j ∈ [n]. Then, there existsD ∈ D such that D̃tmax;i,j = Di,j . SinceD is a hemimetric, we\nhave D̃tmax;i,j = Di,j ≤ Di,k +Dk,j ≤ D̃tmax;i,k + D̃tmax;k,j .\nWe now show that U∗ti,j = maxD∈D(L̃t,Ũt)Di,j , which also implies uniqueness of the optimal solution. Consider the following two cases:\n• Assume U∗t ≤ D̃tmax. If U∗t = D̃tmax, then we are done. Otherwise, this violates optimality of U∗t as D̃tmax is a better solution. • Otherwise, assume ∃i, j ∈ [n] : U∗ti,j > D̃tmax;i,j . To show a contradiction, defineM ∈ Rn×n via\nMi,j = max ( U∗ti,j , D̃ t max;i,j ) ∀i, j ∈ [n]. (16)\nThe matrixM has strictly smaller objective value for Problem P2 thanU∗t. By showing thatM is feasible for Problem P2, we reach a contradiction to the optimality ofU∗t. Clearly,M ≤ Ũ t. To see thatM ∈ D consider the following two cases for i, j ∈ [n]: – CaseMi,j = U∗ti,j . From this we get\nMi,j = U ∗t i,j ≤ U∗ti,k + U∗tk,j ≤Mi,k +Mk,j ,\nwhere the first inequality holds becauseU∗t is a hemimetric and the second inequality holds by definition ofM . – CaseMi,j = D̃tmax;i,j . Here we have\nMi,j = D̃ t max;i,j ≤ D̃tmax;i,k + D̃tmax;k,j ≤Mi,k +Mk,j ,\nwhere the first inequality holds because D̃max is a hemimetric and the second inequality again holds by definition ofM . This shows thatM is feasible — we reach a contradiction, and we must haveU∗t = D̃tmax.\nNext, we show that D(L̃t, U∗t) = D(L̃t, Ũ t). Observe that D(L̃t, U∗t) ⊆ D(L̃t, Ũ t) is obvious. On the other hand, any metric D ∈ D(L̃t, Ũ t) is also in D(L̃t, U∗t) because U∗t = D̃tmax is by definition element-wise larger than any metric in D(L̃t, Ũ t, ) . Hence, D(L̃t, U∗t) = D(L̃t, Ũ t). Informally, this implies that replacing the upper bound Ũ t on the solution space byU∗t does not remove any hypotheses.\nLemma 3. Problem P3 has a unique solution L∗t that is given by L∗ti,j = minD∈D(L̃t,U∗t)Di,j and satisfies D(L∗t, U∗t) = D(L̃t, U∗t).\nProof. This proof essentially follows the lines of the proof of Lemma 2. Let us define D̃tmin ∈ Rn×n via D̃tmin;i,j = min\nD∈D(L̃t,U∗t) Di,j ∀i, j ∈ [n].\nNote that D̃tmin ∈ Rn×n is feasible for Problem P3:\n• D̃tmin ≥ L̃t is obvious from the definition. • To see that D̃tmin ∈ L(U t∗), fix i, j ∈ [n]. Then, there exists D ∈ D(L̃t, U∗t) such that D̃tmin;i,j = Di,j . Since D is a\nhemimetric, we have D̃tmin;i,j = Di,j ≥ Di,k−Dj,k ≥ D̃tmin;i,k−U∗tj,k sinceDj,k ≤ U∗tj,k. (D̃tmin;i,j ≥ D̃tmin;k,j −U∗tk,i follows analogously)\nWe now show that L∗ti,j = minD∈D(L̃t,U∗t)Di,j , which also implies uniqueness of the optimal solution. Consider the following two cases:\n• AssumeL∗t ≥ D̃tmin. IfL∗t = D̃tmin, then we are done. Otherwise this violates the optimality ofL∗t, as D̃tmin is a better solution. • Otherwise, assume ∃i, j ∈ [n] : L∗ti,j < D̃tmin;i,j . To show a contradiction, defineM ∈ Rn×n via\nMi,j = min ( L∗ti,j , D̃ t min;i,j ) ∀i, j ∈ [n].\nThe matrixM has strictly smaller objective value for Problem P3 thanL∗t. By showing thatM is feasible for Problem P3, we reach a contradiction to the optimality of L∗t. Clearly,M ≥ L̃t. To see thatM ∈ L(U t∗) consider the following two cases for i, j ∈ [n]: – CaseMi,j = L∗ti,j . AsL∗ti,j ∈ L(U∗t), we have that\nMi,j = L ∗t i,j ≥ L∗ti,k − U∗tj,k ≥Mi,k − U∗tj,k,\nwhere the first second inequality follows from the definition ofM . (Mi,j ≥Mk,j − U∗tk,i follows analogously) – CaseMi,j = D̃tmin;i,j . From this we get that there is someD ∈ D(L̃t, U∗t) such thatDi,j = D̃tmin;i,j . As above, this\ngives Mi,j = Di,j ≥ Di,k −Dj,k ≥Mi,k − U∗tj,k, where the first inequality follows becauseD is a hemimetric and the seconds inequality follows by the definition ofM and the fact thatDj,k ≤ U∗tj,k. (Mi,j ≥Mk,j − U∗tk,i follows analogously)\nThis shows thatM is feasible — we reach a contradiction, and we must haveL∗t = D̃tmin.\nNext we show thatD(L∗t, U∗t) = D(L̃t, U∗t). Observe thatD(L∗t, U∗t) ⊆ D(L̃t, U∗t) is obvious. On the other hand, any metric D ∈ D(L̃t, U∗t) is also in D(L∗t, U∗t) because L∗t = D̃tmin is by definition element-wise smaller than any metric inD(L̃t, U∗t, ) . Hence,D(L∗t, U∗t) = D(L̃t, U∗t).\nWe can now prove the theorem.\nProof of Theorem 1. LetL′, U ′ be an optimal solution of Problem P1. ThusD(L′, U ′) ⊇ Dt.\nDefine Dmin and Dmax as the element-wise minimum and maximum of all D ∈ cl(Dt), respectively. Thus, by using Lemmas 1, 2 and 3 we have that L∗t = Dmin and U∗t = Dmax. Consequently,D(L∗t, U∗t) = cl(Dt) ⊇ Dt, i.e., L∗t, U∗t are feasible for Problem P1.\nWe now show thatL∗t = L′ andU∗t = U ′. IfL∗t = L′ andU∗t = U ′, then we are done. Otherwise,L∗t 6= L′ orU∗t 6= U ′ contradicts either the optimality or feasibility ofL′, U ′— consider the following two cases:\n• LetU∗t 6= U ′. – If U∗t ≤ U ′ and ∃i, j ∈ [n] : U∗ti,j < U ′i,j , then U ′ cannot be optimal because L′, U∗t is a feasible solution with\nsmaller objective value. – If on the other hand, ∃i, j ∈ [n] : U∗ti,j > U ′i,j , then U ′ cannot be feasible because it rules out all hemimetrics that\ncoincide withU∗t on the (i, j)th value. • For the caseL∗t 6= L′, similar arguments as above hold.\nHence,L′ = L∗t,U ′ = U∗t is the unique optimal solution for Problem P1."
    }, {
      "heading" : "G Proof of Theorem 2",
      "text" : "The proof of Theorem 2 builds upon Lemma 4 and Lemma 5.\nU-PROJ is in fact equivalent to the Floyd-Warshall algorithm for solving the all-pair shortest paths problem in a graph (Floyd, 1962). Similar equivalence has been shown by Brickell et al. (2008) while studying the problem of projecting a non-metric matrix to a metric via decrease-only projections. Brickell et al. (2008) used a similar result as Lemma 4, however they directly used the interpretation of shortest-path problem. We will give an algebric proof for completeness which also helps us develop similar proof for Lemma 5\nLemma 4. The function U-PROJ in Algorithm 3 with input parameters Ũ t returns U t ∈ D with the following property: for all i, j ∈ [n] it holds that ( EitherU ti,j = Ũ t i,j; OR ∃k s.t. U ti,j = U ti,k + U tk,j ) .\nProof of Lemma 4. For ease of notation, let us define M0 = Ũ t. During an iteration of the outer loop of pivots k ∈ [n] for U-PROJ, we updateMki,j = min ( Mk−1i,j ,M k−1 i,k +M k−1 j,k ) . At the end of execution, we have k = n, and the output of U-PROJ isMn. We will prove the following properties ofMk at the end of every iteration k ∈ [n] and ∀a, b ∈ [n]: ∀k′ ∈ [k]Mka,b ≤Mka,k′ +Mkk′,b (17) Either Mka,b = M 0 a,b OR ∃k′ ∈ [k] s.t. Mka,b = Mka,k′ +Mkk′,b (18)\nNote that the conditions hold trivially at the start since the range of k′ is ∅. Also, the claim of the lemma is equivalent to the statement that the two conditions above hold at the end when k = n. We will now prove this by induction.\nBase case forM0,M1: Conditions in Equations 17, 18 hold trivially for M0 since the range of k′ is ∅. Conditions in Equations 17,18 hold for M1\nsince the range of k′ is [1], and ∀a, b ∈ [n] updateM1a,b = min ( M0a,b,M 0 a,1 +M 0 1,b ) ensures that the conditions hold.\nInduction hypothesis: At k − 1,Mk−1 satisfies the conditions in Equations 17, 18.\nInductive step: Prove thatMk satisfies the conditions in Equations 17, 18 after we make the following update at iteration k:\n∀a, b ∈ [n] updateMka,b = min ( Mk−1a,b ,M k−1 a,k +M k−1 k,b ) Consider any a, b ∈ [n]. We consider the following 3 cases depending on the type of update toMka,b.\nC1: Mka,b = M k−1 a,k +M k−1 k,b C2: Mka,b = M k−1 a,b\nC2.1: Mk−1a,b = M 0 a,b C2.2: Mk−1a,b = M k−1 a,e +M k−1 e,b where e ∈ [k − 1]\nNote that the cases C1, C2.1 and C2.2 are exhaustive given the update rule at k and the induction hypothesis forMk−1.\nProving that the condition of Equation 17 holds forMk. Let us first prove that the condition of Equation 17 holds forMk. The proof is same for all the three cases C1, C2.1 and C2.2.\nFor k′ = k. Then, Mka,k′ +M k k′,b = M k−1 a,k +M k−1 k,b\n≥ min ( Mk−1a,b ,M k−1 a,k +M k−1 k,b ) = Mka,b\nFor k′ ∈ [k], k′ 6= k. If, after the update, we haveMka,k′ = M k−1 a,k′ andM k k′,b = M k−1 k′,b . Then,\nMka,k′ +M k k′,b = M k−1 a,k′ +M k−1 k′,b\n≥Mk−1a,b ≥ min ( Mk−1a,b ,M k−1 a,k +M k−1 k,b ) = Mka,b\nFor k′ ∈ [k], k′ 6= k. If, after the update, we haveMka,k′ = M k−1 a,k′ andM k k′,b = M k−1 k′,k +M k−1 k,b . Then,\nMka,k′ +M k k′,b = M k−1 a,k′ +M k−1 k′,k +M k−1 k,b\n≥Mk−1a,k +M k−1 k,b ≥ min ( Mk−1a,b ,M k−1 a,k +M k−1 k,b ) = Mka,b\nFor k′ ∈ [k], k′ 6= k. If, after the update, we haveMka,k′ = M k−1 a,k +M k−1 k,k′ andM k k′,b = M k−1 k′,b . Then,\nMka,k′ +M k k′,b = M k−1 a,k +M k−1 k,k′ +M k−1 k′,b\n≥Mk−1a,k +M k−1 k,b ≥ min ( Mk−1a,b ,M k−1 a,k +M k−1 k,b ) = Mka,b\nFor k′ ∈ [k], k′ 6= k. If, after the update, we haveMka,k′ = M k−1 a,k +M k−1 k,k′ andM k k′,b = M k−1 k′,k +M k−1 k,b . Then,\nMka,k′ +M k k′,b = M k−1 a,k +M k−1 k,k′ +M k−1 k′,k +M k−1 k,b\n≥Mk−1a,k +M k−1 k,b ≥ min ( Mk−1a,b ,M k−1 a,k +M k−1 k,b ) = Mka,b\nProving that the condition of Equation 18 holds forMk. We will do this analysis case by case for the three cases C1, C2.1 and C2.2.\nFor case C1, i.e. Mka,b = M k−1 a,k +M k−1 k,b . Then,\nMka,b = M k−1 a,k +M k−1 k,b\n= Mka,k +M k k,b\nHence the condition of Equation 18 holds.\nFor case C2.1, i.e. Mka,b = M k−1 a,b = M 0 a,b. Then,\nMka,b = M k−1 a,b\n= M0a,b Hence the condition of Equation 18 holds.\nFor case C2.2, i.e. Mka,b = M k−1 a,b = M k−1 a,e +M k−1 e,b where e ∈ [k− 1]. Then, ifMk−1a,e +M k−1 e,b = M k a,e +M k e,b, we have:\nMka,b = M k−1 a,e +M k−1 e,b\n= Mka,e +M k e,b\nHence, assuming Mk−1a,e + M k−1 e,b = M k a,e + M k e,b, the condition of Equation 18 holds. We conclude by showing that Mk−1a,e +M k−1 e,b = M k a,e +M k e,b holds for C2.2. We show this by contradiction as follows. For the sake of contradiction, let us assume thatMk−1a,e +M k−1 e,b > M k a,e +M k e,b. Then,\nMka,b = M k−1 a,b = M k−1 a,e +M k−1 e,b\n> Mka,e +M k e,b\n=⇒ Mka,b > Mka,e +Mke,b This is a contradiction to the proof we did above showing that Mk satisfies Equation 17. Hence, it holds that Mka,b = M k a,e +M k e,b.\nNow, putting this all together, we have proved thatMk satisfies the conditions of Equations 17, 18. Hence by induction, the final output Mn of the algorithm U-PROJ satisfies these conditions as well, which is exactly equivalent to the claim of the lemma we want to prove.\nLemma 5. The function L-PROJ in Algorithm 4 with input parameters L̃t, U t returns Lt ∈ L(U t) with the following property: for all i, j ∈ [n] it holds that ( EitherLti,j = L̃ t i,j; OR ∃k s.t. Lti,j = max ( Lti,k − U tj,k, Ltk,j − U tk,i )) .\nProof of Lemma 5. The proof follows similar ideas as in Lemma 4, however requires much more algebraic manipulations and cases for complete analysis. Furthermore, there is no direct analogue to shortest-path problem that existed for Lemma 4.\nFor ease of notation, let us defineM0 = L̃t. And, during an iteration of the outer loop of pivotsk ∈ [n] for L-PROJ, we update Mki,j = max ( Mk−1i,j ,M k−1 i,k − U t j,k,M k−1 k,j − U t k,i ) At the end of execution, we have k = n, and the output of L-PROJ isMn. We will prove following properties ofMk at the end of every iteration k ∈ [n] for ∀a, b ∈ [n]:\n∀k′ ∈ [k]Mka,b ≥ max ( Mka,k′ − U tb,k′ ,Mkk′,b − U tk′,a ) (19) Either Mka,b = M 0 a,b OR ∃k′ ∈ [k] s.t. Mka,b = max ( Mka,k′ − U tb,k′ ,Mkk′,b − U tk′,a ) (20)\nNote that the conditions hold trivially at the start since the range of k′ is ∅. Also, the claim of the lemma is equivalent to the statement that the two conditions above hold at the end when k = n. We will now prove this by induction.\nBase case forM0,M1: Conditions in Equations 19, 20 hold trivially for M0 since the range of k′ is ∅. Conditions in Equations 19,20 hold for M1\nsince the range of k′ is [1], and ∀a, b ∈ [n] updateM1a,b = max ( M0a,b,M 0 a,1 − U tb,1,M01,a − U t1,b ) ensures that conditions hold.\nInduction hypothesis: At k − 1,Mk−1 satisfies the conditions in Equations 19, 20.\nInductive step: Prove thatMk satisfies the conditions in Equations 19, 20 after we make the following update at iteration k:\n∀a, b ∈ [n] updateMka,b = max ( Mk−1a,b ,M k−1 a,k − U t b,k,M k−1 k,b − U t k,a ) Consider any a, b ∈ [n]. We consider the following 3 cases depending on the type of update toMka,b.\nC1: Mka,b = max ( Mk−1a,k − U tb,k,M k−1 k,b − U tk,a ) C2: Mka,b = M k−1 a,b\nC2.1: Mk−1a,b = M 0 a,b C2.2: Mk−1a,b = max ( Mk−1a,e − U tb,e,M k−1 e,b − U te,a ) where e ∈ [k − 1]\nNote that the cases C1, C2.1 and C2.2 are exhaustive given the update rule at k and the induction hypothesis forMk−1.\nProving that the condition of Equation 19 holds forMk. Let us first prove that the condition of Equation 19 holds forMk. The proof is same for all the three cases C1, C2.1 and C2.2.\nFor k′ = k. Then, max ( Mka,k′ − U tb,k′ ,Mkk′,b − U tk′,a ) = max ( Mk−1a,k − U t b,k,M k−1 k,b − U t k,a ) ≤ max ( Mk−1a,b ,M k−1 a,k − U t b,k,M k−1 k,b − U t k,a\n) = Mka,b\nFor k′ ∈ [k], k′ 6= k. If, after update, we haveMka,k′ = M k−1 a,k′ andM k k′,b = M k−1 k′,b . Then, max ( Mka,k′ − U tb,k′ ,Mkk′,b − U tk′,a ) = max ( Mk−1a,k′ − U t b,k′ ,M k−1 k′,b − U t k′,a ) ≤Mk−1a,b ≤ max ( Mk−1a,b ,M k−1 a,k − U t b,k,M k−1 k,b − U t k,a\n) = Mka,b\nFor k′ ∈ [k], k′ 6= k. If, after update, we haveMka,k′ = M k−1 a,k′ andM k k′,b = M k−1 k′,k − U tb,k. Then, max ( Mka,k′ − U tb,k′ ,Mkk′,b − U tk′,a ) = max ( Mk−1a,k′ − U t b,k′ ,M k−1 k′,k − U t b,k − U tk′,a ) = max ( Mk−1a,k′ − U t b,k′ ,M k−1 k′,k − U t k′,a − U tb,k )\n≤ max ( Mk−1a,b ,M k−1 a,k − U t b,k ) ≤ max ( Mk−1a,b ,M k−1 a,k − U t b,k,M k−1 k,b − U t k,a\n) = Mka,b\nFor k′ ∈ [k], k′ 6= k. If, after update, we haveMka,k′ = M k−1 a,k′ andM k k′,b = M k−1 k,b − U tk,k′ . Then, max ( Mka,k′ − U tb,k′ ,Mkk′,b − U tk′,a ) = max ( Mk−1a,k′ − U t b,k′ ,M k−1 k,b − U t k,k′ − U tk′,a ) ≤ max ( Mk−1a,k′ − U t b,k′ ,M k−1 k,b − U t k,a\n) ≤ max ( Mk−1a,b ,M k−1 k,b − U t k,a\n) ≤ max ( Mk−1a,b ,M k−1 a,k − U t b,k,M k−1 k,b − U t k,a\n) = Mka,b\nFor k′ ∈ [k], k′ 6= k. If, after update, we haveMka,k′ = M k−1 a,k − U tk′,k andMkk′,b = M k−1 k′,b . Then, max ( Mka,k′ − U tb,k′ ,Mkk′,b − U tk′,a ) = max ( Mk−1a,k − U t k′,k − U tb,k′ ,Mk−1k′,b − U t k′,a ) ≤ max ( Mk−1a,k − U t b,k,M k−1 k′,b − U t k′,a\n) ≤ max ( Mk−1a,k − U t b,k,M k−1 a,b\n) ≤ max ( Mk−1a,b ,M k−1 a,k − U t b,k,M k−1 k,b − U t k,a\n) = Mka,b\nFor k′ ∈ [k], k′ 6= k. If, after update, we haveMka,k′ = M k−1 k,k′ − U tk,a andMkk′,b = M k−1 k′,b . Then, max ( Mka,k′ − U tb,k′ ,Mkk′,b − U tk′,a ) = max ( Mk−1k,k′ − U t k,a − U tb,k′ ,Mk−1k′,b − U t k′,a ) = max ( Mk−1k,k′ − U t b,k′ − U tk,a,Mk−1k′,b − U t k′,a\n) ≤ max ( Mk−1k,b − U t k,a,M k−1 a,b\n) ≤ max ( Mk−1a,b ,M k−1 a,k − U t b,k,M k−1 k,b − U t k,a\n) = Mka,b\nFor k′ ∈ [k], k′ 6= k. We need to consider following four more possibilities after update:\n• Mka,k′ = M k−1 a,k − U tk′,k andMkk′,b = M k−1 k′,k − U tb,k • Mka,k′ = M k−1 a,k − U tk′,k andMkk′,b = M k−1 k,b − U tk,k′ • Mka,k′ = M k−1 k,k′ − U tk,a andMkk′,b = M k−1 k′,k − U tb,k • Mka,k′ = M k−1 k,k′ − U tk,a andMkk′,b = M k−1 k,b − U tk,k′\nThese four possibilities follow exactly the same arguments as used above.\nProving that the condition of Equation 20 holds forMk. We will do this analysis case by case for the three cases C1, C2.1 and C2.2.\nFor case C1, i.e. Mka,b = max ( Mk−1a,k − U tb,k,M k−1 k,b − U tk,a ) . Then,\nMka,b = max ( Mk−1a,k − U t b,k,M k−1 k,b − U t k,a ) = max ( Mka,k − U tb,k,Mkk,b − U tk,a\n) Hence the condition of Equation 20 holds.\nFor case C2.1, i.e. Mka,b = M k−1 a,b = M 0 a,b. Then,\nMka,b = M k−1 a,b\n= M0a,b Hence the condition of Equation 20 holds.\nFor case C2.2, i.e. Mka,b = M k−1 a,b = max ( Mk−1a,e − U tb,e,M k−1 e,b − U te,a ) where e ∈ [k − 1]. Then, if we assume that\nmax ( Mk−1a,e − U tb,e,Mk−1e,b − U t e,a ) = max ( Mka,e − U tb,e,Mke,b − U te,a ) ,\nwe have: Mka,b = max ( Mk−1a,e − U tb,e,Mk−1e,b − U t e,a ) = max ( Mka,e − U tb,e,Mke,b − U te,a\n) Hence the condition of Equation 20 holds. We conclude by showing that the above assumption must be true for C2.2. We show this by contradiction as follows. For the sake of contradiction, let us assume that\nmax ( Mk−1a,e − U tb,e,Mk−1e,b − U t e,a ) < max ( Mka,e − U tb,e,Mke,b − U te,a ) Then,\nMka,b = max ( Mk−1a,e − U tb,e,Mk−1e,b − U t e,a ) < max ( Mka,e − U tb,e,Mke,b − U te,a\n) =⇒ Mka,b < max ( Mka,e − U tb,e,Mke,b − U te,a\n) This is a contradiction to the proof we did above showing that Mk satisfies Equation 19. Hence, it holds that Mka,b = max ( Mka,e − U tb,e,Mke,b − U te,a ) .\nNow, putting this all together, we have proved thatMk satisfies the conditions of Equations 19, 20. Hence by induction, the final output Mn of the algorithm L-PROJ satisfies these conditions as well, which is exactly equivalent to the claim of the lemma we want to prove.\nProof of Theorem 2. We want to prove that the lower and upper boundsLt, U t returned by LU-PROJ are the unique optimal solution of Problem P1. Given the results from Theorem 1, it is enough to show that the upper bound matrixU t is the optimal solution of Problem P2 and the lower bound matrixLt is the optimal solution of Problem P3.\nWe will prove this statement of optimality separately for U t and for Lt. The approach to prove optimality of upper bounds U t is similar in spirit to that of Brickell et al. (2008) who showed the optimality of downward-only projection for the metric-nearness problem. For our optimality proofs, we will use the specific properties of U t and Lt from Lemmas 4 and Lemma 5, respectively.\nProof of optimality of upper boundsU t. We will prove by contradiction. Consider the optimal solution of Problem P2 given byU∗t. Let us assume thatU t is not an optimal solution. Let us sort the indices (i, j) ∈ [n]2 in order of increasing values ofU ti,j . For the sake of contradiction, let (a, b) be the first pair of indices in this sorted order such thatU∗ta,b > U t a,b. We will show that no such pair of indices (a, b) can exist.\nBy Lemma 4, we know thatU t returned by U-PROJ satisfies either:\nC1: U ta,b = Ũ ta,b or C2: ∃k ∈ [n] s.t. U ta,b = U ta,k + U tk,b Considering the case C1, we have the following contradiction:\nU ta,b = Ũ t a,b ≥ U∗ta,b\nConsidering the case C2, we have the following contradiction: U ta,b = U t a,k + U t k,b ≥ U∗ta,k + U∗tk,b ≥ U∗ta,b, where the first inequality holds because of the considered order on the pair of indices.\nHence, we must haveU t ≥ U∗t showing thatU t is an optimal solution. In fact, given the uniqueness of the optimal solution U∗t for Problem P2 which follows from results of Lemma 2, we haveU t = U∗t.\nProof of optimality of lower boundsLt. The ideas are similar as those used above for proving the optimality of U t. Again, we will prove by contradiction. Consider the optimal solution of Problem P3 given by L∗t. Let us assume that Lt is not an optimal solution. Let us sort the indices (i, j) ∈ [n]2 in order of decreasing values of Lti,j . For the sake of contradiction, let (a, b) be the first pair of indices in this sorted order such thatL∗ta,b < L t a,b. By will show that it is not possible for this pair of indices (a, b) to exist.\nBy Lemma 5, we know thatLt returned by L-PROJ satisfies either:\nC1: Lta,b = L̃ta,b or C2: ∃k ∈ [n] s.t. Lta,b = max ( Lta,k − U tb,k, Ltk,b − U tk,a ) Considering the case C1, we have the following contradiction:\nLta,b = L̃ t a,b ≤ L∗ta,b\nConsidering the case C2, we have the following contradiction: Lta,b = max ( Lta,k − U tb,k, Ltk,b − U tk,a ) ≤ max ( L∗ta,k − U tb,k, L∗tk,b − U tk,a\n) = max ( L∗ta,k − U∗tb,k, L∗tk,b − U∗tk,a\n) ≤ L∗ta,b,\nwhere the first inequality holds because of the considered order on the pair of indices.\nHence, we must have Lt ≤ L∗t showing that Lt is an optimal solution. In fact, given the uniqueness of optimal solution L∗t for Problem P3 which follows from results of Lemma 3, we haveLt = L∗t."
    } ],
    "references" : [ {
      "title" : "Low-cost learning via active data procurement",
      "author" : [ "J. Abernethy", "Y. Chen", "C. Ho", "B. Waggoner" ],
      "venue" : "In Proceedings of the Sixteenth ACM Conference on Economics and Computation,",
      "citeRegEx" : "Abernethy et al\\.,? \\Q2015\\E",
      "shortCiteRegEx" : "Abernethy et al\\.",
      "year" : 2015
    }, {
      "title" : "Multiview triplet embedding: Learning attributes in multiple maps",
      "author" : [ "E. Amid", "A. Ukkonen" ],
      "venue" : "In ICML, pp",
      "citeRegEx" : "Amid and Ukkonen,? \\Q2015\\E",
      "shortCiteRegEx" : "Amid and Ukkonen",
      "year" : 2015
    }, {
      "title" : "A survey on metric learning for feature vectors and structured data",
      "author" : [ "A. Bellet", "A. Habrard", "M. Sebban" ],
      "venue" : "arXiv preprint arXiv:1306.6709,",
      "citeRegEx" : "Bellet et al\\.,? \\Q2013\\E",
      "shortCiteRegEx" : "Bellet et al\\.",
      "year" : 2013
    }, {
      "title" : "Learning what’s going on: Reconstructing preferences and priorities from opaque transactions",
      "author" : [ "A. Blum", "Y. Mansour", "J. Morgenstern" ],
      "venue" : "In Proceedings of the Sixteenth ACM Conference on Economics and Computation,",
      "citeRegEx" : "Blum et al\\.,? \\Q2015\\E",
      "shortCiteRegEx" : "Blum et al\\.",
      "year" : 2015
    }, {
      "title" : "The metric nearness problem",
      "author" : [ "J. Brickell", "I.S. Dhillon", "S. Sra", "J.A. Tropp" ],
      "venue" : "SIAM Journal on Matrix Analysis and Applications,",
      "citeRegEx" : "Brickell et al\\.,? \\Q2008\\E",
      "shortCiteRegEx" : "Brickell et al\\.",
      "year" : 2008
    }, {
      "title" : "Upper and lower error bounds for active learning",
      "author" : [ "Castro", "Rui M", "Nowak", "Robert D" ],
      "venue" : "In Allerton,",
      "citeRegEx" : "Castro et al\\.,? \\Q2006\\E",
      "shortCiteRegEx" : "Castro et al\\.",
      "year" : 2006
    }, {
      "title" : "Learning user preferences for sets of objects",
      "author" : [ "M. Desjardins", "E. Eaton", "K.L. Wagstaff" ],
      "venue" : "In ICML, pp",
      "citeRegEx" : "Desjardins et al\\.,? \\Q2006\\E",
      "shortCiteRegEx" : "Desjardins et al\\.",
      "year" : 2006
    }, {
      "title" : "Using the triangle inequality to accelerate k-means",
      "author" : [ "C. Elkan" ],
      "venue" : "In ICML,",
      "citeRegEx" : "Elkan,? \\Q2003\\E",
      "shortCiteRegEx" : "Elkan",
      "year" : 2003
    }, {
      "title" : "Learning local invariant mahalanobis distances",
      "author" : [ "E. Fetaya", "S. Ullman" ],
      "venue" : "In ICML,",
      "citeRegEx" : "Fetaya and Ullman,? \\Q2015\\E",
      "shortCiteRegEx" : "Fetaya and Ullman",
      "year" : 2015
    }, {
      "title" : "Algorithm 97: shortest path",
      "author" : [ "Floyd", "Robert W" ],
      "venue" : "Communications of the ACM,",
      "citeRegEx" : "Floyd and W.,? \\Q1962\\E",
      "shortCiteRegEx" : "Floyd and W.",
      "year" : 1962
    }, {
      "title" : "Manifoldranking based image retrieval",
      "author" : [ "J. He", "M. Li", "H. Zhang", "H. Tong", "C. Zhang" ],
      "venue" : "In Proceedings of the 12th annual ACM International Conference on Multimedia,",
      "citeRegEx" : "He et al\\.,? \\Q2004\\E",
      "shortCiteRegEx" : "He et al\\.",
      "year" : 2004
    }, {
      "title" : "At what quality and what price?: Eliciting buyer preferences as a market design problem",
      "author" : [ "J.J. Horton", "R. Johari" ],
      "venue" : "In Proceedings of the Sixteenth ACM Conference on Economics and Computation,",
      "citeRegEx" : "Horton and Johari,? \\Q2015\\E",
      "shortCiteRegEx" : "Horton and Johari",
      "year" : 2015
    }, {
      "title" : "Logeuclidean metric learning on symmetric positive definite manifold with application to image set classification",
      "author" : [ "Z. Huang", "R. Wang", "S. Shan", "X. Li", "X. Chen" ],
      "venue" : "In ICML,",
      "citeRegEx" : "Huang et al\\.,? \\Q2015\\E",
      "shortCiteRegEx" : "Huang et al\\.",
      "year" : 2015
    }, {
      "title" : "Low-dimensional embedding using adaptively selected ordinal data",
      "author" : [ "K.G. Jamieson", "R.D. Nowak" ],
      "venue" : "In Allerton,",
      "citeRegEx" : "Jamieson and Nowak,? \\Q2011\\E",
      "shortCiteRegEx" : "Jamieson and Nowak",
      "year" : 2011
    }, {
      "title" : "Active ranking using pairwise comparisons",
      "author" : [ "Jamieson", "Kevin G", "Nowak", "Robert" ],
      "venue" : "In NIPS, pp",
      "citeRegEx" : "Jamieson et al\\.,? \\Q2011\\E",
      "shortCiteRegEx" : "Jamieson et al\\.",
      "year" : 2011
    }, {
      "title" : "Active learning in the non-realizable case",
      "author" : [ "Kääriäinen", "Matti" ],
      "venue" : "In ALT, pp",
      "citeRegEx" : "Kääriäinen and Matti.,? \\Q2006\\E",
      "shortCiteRegEx" : "Kääriäinen and Matti.",
      "year" : 2006
    }, {
      "title" : "Bayesian persuasion",
      "author" : [ "E. Kamenica", "M. Gentzkow" ],
      "venue" : "Technical report, National Bureau of Economic Research,",
      "citeRegEx" : "Kamenica and Gentzkow,? \\Q2009\\E",
      "shortCiteRegEx" : "Kamenica and Gentzkow",
      "year" : 2009
    }, {
      "title" : "Efficient learning of mahalanobis metrics for ranking",
      "author" : [ "D. Lim", "G. Lanckriet" ],
      "venue" : "In ICML, pp. 1980–1988,",
      "citeRegEx" : "Lim and Lanckriet,? \\Q2014\\E",
      "shortCiteRegEx" : "Lim and Lanckriet",
      "year" : 2014
    }, {
      "title" : "Similarity learning for high-dimensional sparse data",
      "author" : [ "Liu", "Kuan", "Bellet", "Aurélien", "Sha", "Fei" ],
      "venue" : "In AISTATS, pp",
      "citeRegEx" : "Liu et al\\.,? \\Q2015\\E",
      "shortCiteRegEx" : "Liu et al\\.",
      "year" : 2015
    }, {
      "title" : "Margin-based active learning for structured output spaces",
      "author" : [ "Roth", "Dan", "Small", "Kevin" ],
      "venue" : "In ECML,",
      "citeRegEx" : "Roth et al\\.,? \\Q2006\\E",
      "shortCiteRegEx" : "Roth et al\\.",
      "year" : 2006
    }, {
      "title" : "Active learning",
      "author" : [ "B. Settles" ],
      "venue" : "Synthesis Lectures on Artificial Intelligence and Machine Learning,",
      "citeRegEx" : "Settles,? \\Q2012\\E",
      "shortCiteRegEx" : "Settles",
      "year" : 2012
    }, {
      "title" : "Truthful incentives in crowdsourcing tasks using regret minimization mechanisms",
      "author" : [ "A. Singla", "A. Krause" ],
      "venue" : "In WWW, pp",
      "citeRegEx" : "Singla and Krause,? \\Q2013\\E",
      "shortCiteRegEx" : "Singla and Krause",
      "year" : 2013
    }, {
      "title" : "Incentivizing users for balancing bike sharing systems",
      "author" : [ "A. Singla", "M. Santoni", "G. Bartók", "P. Mukerji", "M. Meenen", "A. Krause" ],
      "venue" : "In AAAI,",
      "citeRegEx" : "Singla et al\\.,? \\Q2015\\E",
      "shortCiteRegEx" : "Singla et al\\.",
      "year" : 2015
    }, {
      "title" : "Adaptively learning the crowd kernel",
      "author" : [ "O. Tamuz", "C. Liu", "S. Belongie", "O. Shamir", "A.T. Kalai" ],
      "venue" : "In ICML,",
      "citeRegEx" : "Tamuz et al\\.,? \\Q2011\\E",
      "shortCiteRegEx" : "Tamuz et al\\.",
      "year" : 2011
    }, {
      "title" : "Dimensionality reduction: A comparative review",
      "author" : [ "van der Maaten", "Laurens JP", "Postma", "Eric O", "van den Herik", "H Jaap" ],
      "venue" : null,
      "citeRegEx" : "Maaten et al\\.,? \\Q2009\\E",
      "shortCiteRegEx" : "Maaten et al\\.",
      "year" : 2009
    }, {
      "title" : "Active learning and dynamic pricing policies",
      "author" : [ "M. Vázquez-Gallo", "M. Estévez", "S. Egido" ],
      "venue" : "American Journal of Operations Research,",
      "citeRegEx" : "Vázquez.Gallo et al\\.,? \\Q2014\\E",
      "shortCiteRegEx" : "Vázquez.Gallo et al\\.",
      "year" : 2014
    }, {
      "title" : "Distance metric learning with application to clustering with side-information",
      "author" : [ "E.P. Xing", "M.I. Jordan", "S. Russell", "A.Y. Ng" ],
      "venue" : "In NIPS, pp",
      "citeRegEx" : "Xing et al\\.,? \\Q2002\\E",
      "shortCiteRegEx" : "Xing et al\\.",
      "year" : 2002
    }, {
      "title" : "Distance metric learning: A comprehensive survey",
      "author" : [ "Yang", "Liu", "Jin", "Rong" ],
      "venue" : "Michigan State Universiy,",
      "citeRegEx" : "Yang et al\\.,? \\Q2006\\E",
      "shortCiteRegEx" : "Yang et al\\.",
      "year" : 2006
    } ],
    "referenceMentions" : [ {
      "referenceID" : 26,
      "context" : "In machine learning algorithms, the distances serve as a notion of similarity (or dissimilarity) between data points and are important for various tasks such as clustering (Xing et al., 2002), object ranking (Lim & Lanckriet, 2014), image retrieval / classification (He et al.",
      "startOffset" : 172,
      "endOffset" : 191
    }, {
      "referenceID" : 10,
      "context" : ", 2002), object ranking (Lim & Lanckriet, 2014), image retrieval / classification (He et al., 2004; Huang et al., 2015), etc.",
      "startOffset" : 82,
      "endOffset" : 119
    }, {
      "referenceID" : 12,
      "context" : ", 2002), object ranking (Lim & Lanckriet, 2014), image retrieval / classification (He et al., 2004; Huang et al., 2015), etc.",
      "startOffset" : 82,
      "endOffset" : 119
    }, {
      "referenceID" : 6,
      "context" : ", from a catalogue of products) to improve product recommendation and dynamic pricing of goods (Desjardins et al., 2006; Horton & Johari, 2015; Blum et al., 2015; Vázquez-Gallo et al., 2014).",
      "startOffset" : 95,
      "endOffset" : 190
    }, {
      "referenceID" : 3,
      "context" : ", from a catalogue of products) to improve product recommendation and dynamic pricing of goods (Desjardins et al., 2006; Horton & Johari, 2015; Blum et al., 2015; Vázquez-Gallo et al., 2014).",
      "startOffset" : 95,
      "endOffset" : 190
    }, {
      "referenceID" : 25,
      "context" : ", from a catalogue of products) to improve product recommendation and dynamic pricing of goods (Desjardins et al., 2006; Horton & Johari, 2015; Blum et al., 2015; Vázquez-Gallo et al., 2014).",
      "startOffset" : 95,
      "endOffset" : 190
    }, {
      "referenceID" : 2,
      "context" : "1 In economics, the distance function can encode the We refer the interested reader to the survey by Bellet et al. (2013) for a detailed discussion of various applications.",
      "startOffset" : 101,
      "endOffset" : 122
    }, {
      "referenceID" : 0,
      "context" : "This query is motivated by the posted-price model used in marketplaces (Abernethy et al., 2015; Singla & Krause, 2013), where users are offered a take-it-or-leave-it price by the system, and they can accept by providing a positive response, or reject by providing a negative response.",
      "startOffset" : 71,
      "endOffset" : 118
    }, {
      "referenceID" : 20,
      "context" : "old function in the active-learning setting (Castro & Nowak, 2006; Settles, 2012).",
      "startOffset" : 44,
      "endOffset" : 81
    }, {
      "referenceID" : 20,
      "context" : "One policy inspired by uncertainty sampling (Settles, 2012) is to pick the pair (i, j) with maximum uncertainty quantified by (U t−1 i,j −L t−1 i,j ).",
      "startOffset" : 44,
      "endOffset" : 59
    }, {
      "referenceID" : 4,
      "context" : "Similar equivalence has been shown by Brickell et al. (2008) while studying the problem of projecting a non-metric matrix to a metric via decrease-only projections.",
      "startOffset" : 38,
      "endOffset" : 61
    }, {
      "referenceID" : 4,
      "context" : "We compute D∗ as the closest metric toW according to Brickell et al. (2008). For different weights w1, .",
      "startOffset" : 53,
      "endOffset" : 76
    }, {
      "referenceID" : 18,
      "context" : "Another line of research considers learning asymmetric distances, for instance by learning local invariant Mahalanobis distances (Fetaya & Ullman, 2015) or by learning general bilinear similarity matrices (Liu et al., 2015).",
      "startOffset" : 205,
      "endOffset" : 223
    }, {
      "referenceID" : 23,
      "context" : "Another line of research is that of learning low-dimensional embeddings for a set of items respecting the observed geometric relations between these items (Amid & Ukkonen, 2015; Tamuz et al., 2011; Cox & Cox, 2000; Jamieson & Nowak, 2011a).",
      "startOffset" : 155,
      "endOffset" : 239
    }, {
      "referenceID" : 20,
      "context" : "4 Active Learning Our problem formulation shares the goal of reducing sample complexity with other instances of active learning (Settles, 2012).",
      "startOffset" : 128,
      "endOffset" : 143
    }, {
      "referenceID" : 16,
      "context" : "We refer the reader to the detailed surveys by Yang & Jin (2006); van der Maaten et al. (2009); Bellet et al.",
      "startOffset" : 74,
      "endOffset" : 95
    }, {
      "referenceID" : 1,
      "context" : "(2009); Bellet et al. (2013). Some of the key distinctions of our formulation from the existing research are described in the following.",
      "startOffset" : 8,
      "endOffset" : 29
    }, {
      "referenceID" : 1,
      "context" : "(2009); Bellet et al. (2013). Some of the key distinctions of our formulation from the existing research are described in the following. Supervised metric learning. In their seminal work, Xing et al. (2002) introduced the supervised metric learning framework for learning Mahalanobis distance functions via a convex formulation.",
      "startOffset" : 8,
      "endOffset" : 207
    }, {
      "referenceID" : 1,
      "context" : "(2009); Bellet et al. (2013). Some of the key distinctions of our formulation from the existing research are described in the following. Supervised metric learning. In their seminal work, Xing et al. (2002) introduced the supervised metric learning framework for learning Mahalanobis distance functions via a convex formulation. In contrast to our setting, they assume that the algorithm has access to the feature space of the input data. Furthermore, this framework and its variants are restricted to recover symmetric distance functions. Another line of research considers learning asymmetric distances, for instance by learning local invariant Mahalanobis distances (Fetaya & Ullman, 2015) or by learning general bilinear similarity matrices (Liu et al., 2015). However, this line of work is not directly applicable to our setting because it also requires access to the feature space of the input data. Learning embeddings. Another line of research is that of learning low-dimensional embeddings for a set of items respecting the observed geometric relations between these items (Amid & Ukkonen, 2015; Tamuz et al., 2011; Cox & Cox, 2000; Jamieson & Nowak, 2011a). For applications involving human subjects, a triplet-based queries framework — for a triplet (i, j, k) it queries1(Di,j ≤ Di,k) — has been employed. However the distances recovered from these approaches are merely optimized to respect the observed relations seen in the data from query responses — they are symmetric and importantly do not have an actual quantitative (economic) interpretation as we seek in our formulation. 8.2 Exploiting Structural Constraints Our approach of exploiting the structural constraints of the hemimetrics polytope is in part inspired by Elkan (2003), who acceleratesK-means by exploiting the triangle inequality.",
      "startOffset" : 8,
      "endOffset" : 1749
    }, {
      "referenceID" : 1,
      "context" : "(2009); Bellet et al. (2013). Some of the key distinctions of our formulation from the existing research are described in the following. Supervised metric learning. In their seminal work, Xing et al. (2002) introduced the supervised metric learning framework for learning Mahalanobis distance functions via a convex formulation. In contrast to our setting, they assume that the algorithm has access to the feature space of the input data. Furthermore, this framework and its variants are restricted to recover symmetric distance functions. Another line of research considers learning asymmetric distances, for instance by learning local invariant Mahalanobis distances (Fetaya & Ullman, 2015) or by learning general bilinear similarity matrices (Liu et al., 2015). However, this line of work is not directly applicable to our setting because it also requires access to the feature space of the input data. Learning embeddings. Another line of research is that of learning low-dimensional embeddings for a set of items respecting the observed geometric relations between these items (Amid & Ukkonen, 2015; Tamuz et al., 2011; Cox & Cox, 2000; Jamieson & Nowak, 2011a). For applications involving human subjects, a triplet-based queries framework — for a triplet (i, j, k) it queries1(Di,j ≤ Di,k) — has been employed. However the distances recovered from these approaches are merely optimized to respect the observed relations seen in the data from query responses — they are symmetric and importantly do not have an actual quantitative (economic) interpretation as we seek in our formulation. 8.2 Exploiting Structural Constraints Our approach of exploiting the structural constraints of the hemimetrics polytope is in part inspired by Elkan (2003), who acceleratesK-means by exploiting the triangle inequality. By maintaining bounds on the distances, he efficiently reduces the number of distance computations. Brickell et al. (2008) study the problem of projecting a non-metric matrix to a metric matrix, and consider a specific class of decrease-only projections.",
      "startOffset" : 8,
      "endOffset" : 1935
    }, {
      "referenceID" : 1,
      "context" : "(2009); Bellet et al. (2013). Some of the key distinctions of our formulation from the existing research are described in the following. Supervised metric learning. In their seminal work, Xing et al. (2002) introduced the supervised metric learning framework for learning Mahalanobis distance functions via a convex formulation. In contrast to our setting, they assume that the algorithm has access to the feature space of the input data. Furthermore, this framework and its variants are restricted to recover symmetric distance functions. Another line of research considers learning asymmetric distances, for instance by learning local invariant Mahalanobis distances (Fetaya & Ullman, 2015) or by learning general bilinear similarity matrices (Liu et al., 2015). However, this line of work is not directly applicable to our setting because it also requires access to the feature space of the input data. Learning embeddings. Another line of research is that of learning low-dimensional embeddings for a set of items respecting the observed geometric relations between these items (Amid & Ukkonen, 2015; Tamuz et al., 2011; Cox & Cox, 2000; Jamieson & Nowak, 2011a). For applications involving human subjects, a triplet-based queries framework — for a triplet (i, j, k) it queries1(Di,j ≤ Di,k) — has been employed. However the distances recovered from these approaches are merely optimized to respect the observed relations seen in the data from query responses — they are symmetric and importantly do not have an actual quantitative (economic) interpretation as we seek in our formulation. 8.2 Exploiting Structural Constraints Our approach of exploiting the structural constraints of the hemimetrics polytope is in part inspired by Elkan (2003), who acceleratesK-means by exploiting the triangle inequality. By maintaining bounds on the distances, he efficiently reduces the number of distance computations. Brickell et al. (2008) study the problem of projecting a non-metric matrix to a metric matrix, and consider a specific class of decrease-only projections. Our approach towards updating upper bounds via decrease-only projections is similar in spirit. However, the main technical difficulties arise in maintaining and updating the lower bounds, for which we develop novel techniques. The active-learning approach proposed by Jamieson & Nowak (2011a) exploits the geometry of the embedding space to minimize the sample complexity using triplet-based queries.",
      "startOffset" : 8,
      "endOffset" : 2360
    }, {
      "referenceID" : 1,
      "context" : "(2009); Bellet et al. (2013). Some of the key distinctions of our formulation from the existing research are described in the following. Supervised metric learning. In their seminal work, Xing et al. (2002) introduced the supervised metric learning framework for learning Mahalanobis distance functions via a convex formulation. In contrast to our setting, they assume that the algorithm has access to the feature space of the input data. Furthermore, this framework and its variants are restricted to recover symmetric distance functions. Another line of research considers learning asymmetric distances, for instance by learning local invariant Mahalanobis distances (Fetaya & Ullman, 2015) or by learning general bilinear similarity matrices (Liu et al., 2015). However, this line of work is not directly applicable to our setting because it also requires access to the feature space of the input data. Learning embeddings. Another line of research is that of learning low-dimensional embeddings for a set of items respecting the observed geometric relations between these items (Amid & Ukkonen, 2015; Tamuz et al., 2011; Cox & Cox, 2000; Jamieson & Nowak, 2011a). For applications involving human subjects, a triplet-based queries framework — for a triplet (i, j, k) it queries1(Di,j ≤ Di,k) — has been employed. However the distances recovered from these approaches are merely optimized to respect the observed relations seen in the data from query responses — they are symmetric and importantly do not have an actual quantitative (economic) interpretation as we seek in our formulation. 8.2 Exploiting Structural Constraints Our approach of exploiting the structural constraints of the hemimetrics polytope is in part inspired by Elkan (2003), who acceleratesK-means by exploiting the triangle inequality. By maintaining bounds on the distances, he efficiently reduces the number of distance computations. Brickell et al. (2008) study the problem of projecting a non-metric matrix to a metric matrix, and consider a specific class of decrease-only projections. Our approach towards updating upper bounds via decrease-only projections is similar in spirit. However, the main technical difficulties arise in maintaining and updating the lower bounds, for which we develop novel techniques. The active-learning approach proposed by Jamieson & Nowak (2011a) exploits the geometry of the embedding space to minimize the sample complexity using triplet-based queries. While similar in spirit, their approach is based on triplet-based queries, and differs from our methodology of exploiting the structural constraints. 8.3 Learning User Preferences Another relevant line of research is concerned with eliciting user preferences. Specifically, we seek to learn private costs of a user for switching from her default choice of item i to instead choose item j. This type of preferences can be used in marketing applications, e.g., for persuading users to change their decisions (Kamenica & Gentzkow, 2009). Singla et al. (2015) considered similar preferences in the context of balancing a bike-sharing system by incentivizing users to go to alternate stations for pickup or dropoff of bikes.",
      "startOffset" : 8,
      "endOffset" : 3024
    }, {
      "referenceID" : 0,
      "context" : "Abernethy et al. (2015) considered the application of purchasing data from users, and quantified the prices that should be offered to them.",
      "startOffset" : 0,
      "endOffset" : 24
    }, {
      "referenceID" : 4,
      "context" : "Similar equivalence has been shown by Brickell et al. (2008) while studying the problem of projecting a non-metric matrix to a metric via decrease-only projections.",
      "startOffset" : 38,
      "endOffset" : 61
    }, {
      "referenceID" : 4,
      "context" : "Similar equivalence has been shown by Brickell et al. (2008) while studying the problem of projecting a non-metric matrix to a metric via decrease-only projections. Brickell et al. (2008) used a similar result as Lemma 4, however they directly used the interpretation of shortest-path problem.",
      "startOffset" : 38,
      "endOffset" : 188
    }, {
      "referenceID" : 4,
      "context" : "The approach to prove optimality of upper bounds U t is similar in spirit to that of Brickell et al. (2008) who showed the optimality of downward-only projection for the metric-nearness problem.",
      "startOffset" : 85,
      "endOffset" : 108
    } ],
    "year" : 2016,
    "abstractText" : "Motivated by an application of eliciting users’ preferences, we investigate the problem of learning hemimetrics, i.e., pairwise distances among a set of n items that satisfy triangle inequalities and non-negativity constraints. In our application, the (asymmetric) distances quantify private costs a user incurs when substituting one item by another. We aim to learn these distances (costs) by asking the users whether they are willing to switch from one item to another for a given incentive offer. Without exploiting structural constraints of the hemimetric polytope, learning the distances between each pair of items requires Θ(n) queries. We propose an active learning algorithm that substantially reduces this sample complexity by exploiting the structural constraints on the version space of hemimetrics. Our proposed algorithm achieves provably-optimal sample complexity for various instances of the task. For example, when the items are embedded into K tight clusters, the sample complexity of our algorithm reduces to O(nK). Extensive experiments on a restaurant recommendation data set support the conclusions of our theoretical analysis.",
    "creator" : "LaTeX with hyperref package"
  }
}