{
  "name" : "1312.0451.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "Consistency of weighted majority votes",
    "authors" : [ "Daniel Berend", "Aryeh Kontorovich" ],
    "emails" : [ ],
    "sections" : [ {
      "heading" : null,
      "text" : "ar X\niv :1\n31 2.\n04 51\nv5 [\nm at\nh. PR\n] 2\n1 Ja"
    }, {
      "heading" : "1 Introduction",
      "text" : "The problem of weighting the input of several experts arises in many situations and is of considerable theoretical and practical importance. The rigorous study of majority vote has its roots in the work of Condorcet (1785). By the 70s, the field of decision theory was actively exploring various voting rules (see Nitzan & Paroush (1982) and the references therein). A typical setting is as follows. An agent is tasked with predicting some random variable Y ∈ {±1} based on input Xi ∈ {±1} from each of n experts. Each expert Xi has a competence level pi ∈ (0, 1), which is the probability of making a correct prediction: P(Xi = Y ) = pi. Two simplifying assumptions are commonly made:\n(i) Independence: The random variables {Xi : i ∈ [n]} are mutually independent.\n(ii) Unbiased truth: P(Y = +1) = P(Y = −1) = 1/2. We will discuss these assumptions below in greater detail; for now, let us just take them as given. (Since the bias of Y can be easily estimated from data, only the independence assumption is truly restrictive.) A decision rule is a mapping f : {±1}n → {±1} from the n expert inputs to the agent’s final decision. Our quantity of interest throughout the paper will be the agent’s probability of error,\nP(f(X) 6= Y ). (1)\nA decision rule f is optimal if it minimizes the quantity in (1) over all possible decision rules. Nitzan & Paroush (1982) showed that, when Assumptions (i)– (ii) hold and the true competences pi are known, the optimal decision rule is obtained by an appropriately weighted majority vote:\nfOPT(x) = sign\n(\nn ∑\ni=1\nwixi\n)\n, (2)\nwhere the weights wi are given by\nwi = log pi\n1− pi , i ∈ [n]. (3)\nThus, wi is the log-odds of expert i being correct — and the voting rule in (2), also known as naive Bayes (Hastie et al., 2009), may be seen as a simple consequence of the Neyman-Pearson lemma (Neyman & Pearson, 1933).\nMain results. The formula in (2) raises immediate questions, which apparently have not previously been addressed. The first one has to do with the consistency of the Nitzan-Paroush optimal rule: under what conditions does the probability of error decay to zero and at what rate? In Section 3, we show that the probability of error is controlled by the committee potential Φ, defined by\nΦ =\nn ∑\ni=1\n(pi − 12 )wi = n ∑\ni=1\n(pi − 12 ) log pi\n1− pi . (4)\nMore precisely, we prove in Theorem 1 that\n− logP(fOPT(X) 6= Y ) ≍ Φ,\nwhere ≍ denotes equivalence up to universal multiplicative constants. Another issue not addressed by the Nitzan-Paroush result is how to handle the case where the competences pi are not known exactly but rather estimated empirically by p̂i. We present two solutions to this problem: a frequentist and a Bayesian one. As we show in Section 4, the frequentist approach does not admit an optimal empirical decision rule. Instead, we analyze empirical decision rules in various settings: high-confidence (i.e., |p̂i − pi| ≪ 1) vs. low-confidence, adaptive vs. nonadaptive. The low-confidence regime requires no additional assumptions, but provides weaker guarantees (Theorem 5). In the high-confidence regime, the adaptive approach provides error estimates in terms of the empirical p̂is (Theorem 10), while the nonadaptive approach gives a bound in terms of the unknown pis, but still gives useful asymptotics (Theorem 9). The Bayesian solution sidesteps the various cases above, as it admits a simple, provably optimal empirical decision rule (Section 5). Unfortunately, we are unable to compute (or even nontrivially estimate) the probability of error induced by this rule; this is posed as a challenging open problem."
    }, {
      "heading" : "2 Background and related work",
      "text" : "Machine learning theory typically clusters weighted majority (Littlestone &Warmuth, 1989, 1994) within the framework of online algorithms; see Cesa-Bianchi & Lugosi (2006) for a modern treatment. Since the online setting is considerably more adversarial than ours, we obtain very different weighted majority rules and consistency guarantees. The weights wi in (2) bear a striking similarity to the Adaboost update rule (Freund & Schapire, 1997; Schapire & Freund, 2012). However, the latter assumes weak learners with access to labeled examples, while in our setting the experts are “static”. Still, we do not rule out a possible deeper connection between the Nitzan-Paroush decision rule and boosting. In a recent line of work Lacasse et al. (2006); Laviolette & Marchand (2007); Roy et al. (2011) have developed a PAC-Bayesian theory for the majority vote of simple classifiers. This approach facilitates data-dependent bounds and is even flexible enough to capture some simple dependencies among the classifiers — though, again, the latter are learners as opposed to our experts. Even more recently, experts with adversarial noise have been considered (Mansour et al., 2013). More directly related to the present work are the papers of Berend & Paroush (1998), which characterizes the consistency of the simple majority rule, and Boland et al. (1989); Berend & Sapir (2007) which analyze various models of dependence among the experts."
    }, {
      "heading" : "3 Known competences",
      "text" : "In this section we assume that the expert competences pi are known and analyze the consistency of the Nitzan-Paroush optimal decision rule (2). Our main result here is that the probability of error P(fOPT(X) 6= Y ) is small if and only if the committee potential Φ is large.\nTheorem 1. Suppose that the experts X = (X1, . . . , Xn) satisfy Assumptions (i)-(ii) and f : {±1}n → {±1} is the Nitzan-Paroush optimal decision rule. Then\n(i) P(fOPT(X) 6= Y ) ≤ exp ( − 12Φ ) .\n(ii) P(fOPT(X) 6= Y ) ≥ 3 4[1 + exp(2Φ + 4 √ Φ)] .\nOpen problem. Exhibit (if possible) a function g : R → R such that P(fOPT(X) 6= Y ) ≍ g(Φ).\nThe remainder of this section is devoted to proving Theorem 1."
    }, {
      "heading" : "3.1 Proof of Theorem 1(i)",
      "text" : "Define the {0, 1}-indicator variables ξi = 1{Xi=Y }, (5)\ncorresponding to the event that the ith expert is correct. A mistake fOPT(X) 6= Y occurs precisely when1 the sum of the correct experts’ weights fails to exceed half the total mass:\nP(fOPT(X) 6= Y ) = P ( n ∑\ni=1\nwiξi ≤ 1\n2\nn ∑\ni=1\nwi\n)\n. (6)\nSince Eξi = pi, we may rewrite the probability in (6) as\nP\n(\n∑\ni\nwiξi ≤ E [ ∑\ni\nwiξi\n]\n− ∑\ni\n(pi − 12 )wi ) . (7)\nA standard tool for estimating such sum deviation probabilities is Hoeffding’s inequality. Applied to (7), it yields the bound\nP(fOPT(X) 6= Y ) ≤ exp ( −2 [ ∑ i(pi − 12 )wi ]2 ∑\ni w 2 i\n)\n, (8)\nwhich is far too crude for our purposes. Indeed, consider a finite committee of highly competent experts with pi’s arbitrarily close to 1 and X1 the most competent of all. Raising X1’s competence sufficiently far above his peers will cause both the numerator and the denominator in the exponent to be dominated by w21 , making the right-hand-side of (8) bounded away from zero. The inability of Hoeffding’s inequality to guarantee consistency even in such a felicitous setting is an instance of its generally poor applicability to highly heterogeneous sums, a phenomenon explored in some depth in McAllester & Ortiz (2003). Bernstein’s and Bennett’s inequalities suffer from a similar weakness (see ibid.). Fortunately, an inequality of Kearns & Saul (1998) is sufficiently sharp to yield the desired estimate: For all p ∈ [0, 1] and all t ∈ R,\n(1 − p)e−tp + pet(1−p) ≤ exp ( 1− 2p 4 log((1− p)/p)t 2 ) . (9)\nRemark 1. The Kearns-Saul inequality (9) may be seen as a distributiondependent refinement of Hoeffding’s (which bounds the left-hand-side of (9) by et 2/8), and is not nearly as straightforward to prove. An elementary rigorous proof is given in Berend & Kontorovich (2013b). Following up, Raginsky & Sason (2013) gave a “soft” proof based on transportation and information-theoretic techniques.\nPut θi = ξi − pi, substitute into (6), and apply Markov’s inequality:\nP(fOPT(X) 6= Y ) = P ( − ∑\ni\nwiθi ≥ Φ )\n(10)\n≤ e−tΦEexp ( −t ∑\ni\nwiθi\n)\n.\n1Without loss of generality, ties are considered to be errors.\nNow\nEe−twiθi = pie −(1−pi)wit + (1 − pi)epiwit\n≤ exp ( −1 + 2pi 4 log(pi/(1− pi)) w2i t 2 )\n(11)\n= exp [ 1 2 (pi − 12 )wit2 ] ,\nwhere the inequality follows from (9). By independence,\nE exp\n(\n−t ∑\ni\nwiθi\n)\n= ∏\ni\nEe−twiθi\n≤ exp (\n1 2\n∑\ni\n(pi − 12 )wit 2\n)\n= exp ( 1 2Φt 2 )\nand hence\nP(fOPT(X) 6= Y ) ≤ exp ( 1 2Φt 2 − Φt ) .\nChoosing t = 1 yields the bound in Theorem 1(i)."
    }, {
      "heading" : "3.2 Proof of Theorem 1(ii)",
      "text" : "Define the {±1}-indicator variables\nηi = 21{Xi=Y } − 1, (12)\ncorresponding to the event that the ith expert is correct and put qi = 1 − pi. The shorthand w ·η = ∑ni=1 wiηi will be convenient. We will need some simple lemmata:\nLemma 2.\nP(fOPT(X) = Y ) = ∑\nη∈{±1}n\nmax {P (η), P (−η)}\nand\nP(fOPT(X) 6= Y ) = ∑\nη∈{±1}n\nmin {P (η), P (−η)} ,\nwhere\nP (η) = ∏\ni:ηi=1\npi ∏\ni:ηi=−1\nqi.\nProof. The identities (5), (6) and (12) imply that a mistake occurs precisely when\nn ∑\ni=1\nwi ηi + 1 2 ≤ 1 2\nn ∑\ni=1\nwi,\nwhich is equivalent to\nw · η ≤ 0. (13)\nExponentiating both sides,\nexp (w · η) = n ∏\ni=1\newiηi\n= ∏\ni:ηi=1\npi qi · ∏\ni:ηi=−1\nqi pi\n= P (η)\nP (−η) ≤ 1. (14)\nWe conclude from (14) that among two “antipodal” atoms ±η ∈ {±1}n, the one with the greater mass contributes to the probability being correct and the one with the smaller mass contributes to the probability of error, which proves the claim.\nRemark 2. The proof of Lemma 2 also establishes the optimality of the NitzanParoush decision rule.\nLemma 3. Suppose that s, s′ ∈ (0,∞)m satisfy m ∑\ni=1\n(si + s ′ i) ≥ a\nand\n1 R ≤ si s′i ≤ R, i ∈ [m]\nfor some R < ∞. Then m ∑\ni=1\nmin {si, s′i} ≥ a\n1 +R .\nProof. Immediate from\nsi + s ′ i ≤ min {si, s′i} (1 +R).\nLemma 4. Define the function F : (0, 1) → R by\nF (x) = x(1 − x) log(x/(1− x))\n2x− 1 .\nThen sup0<x<1 F (x) = 1 2 .\nProof. Deferred to the Appendix.\nContinuing with the main proof, observe that\nE [w · η] = n ∑\ni=1\n(pi − qi)wi = 2Φ (15)\nand\nVar [w · η] = 4 n ∑\ni=1\npiqiw 2 i .\nBy Lemma 4,\npiqiw 2 i ≤ 12 (pi − qi)wi,\nand hence\nVar [w · η] ≤ 4Φ. (16)\nDefine the segment I ⊂ R by\nI = [ 2Φ− 4 √ Φ, 2Φ + 4 √ Φ ] . (17)\nChebyshev’s inequality together with (15) and (16) implies that\nP (w · η ∈ I) ≥ 3 4 . (18)\nConsider an atom η ∈ {±1}n for which w ·η ∈ I. The proof of Lemma 2 shows that\nP (η) P (−η) = exp (w · η) ≤ exp(2Φ + 4 √ Φ), (19)\nwhere the inequality follows from (17). Lemma 2 further implies that\nP(fOPT(X) 6= Y ) ≥ ∑\nη∈{±1}n:w·η∈I\nmin {P (η), P (−η)}\n≥ 3/4 1 + exp(2Φ + 4 √ Φ) ,\nwhere the second inequality follows from Lemma 3, (18) and (19). This completes the proof."
    }, {
      "heading" : "4 Unknown competences: frequentist approach",
      "text" : "Our goal in this section is to obtain, insofar as possible, analogues of Theorem 1 for unknown expert competences. When the pis are unknown, they must be estimated empirically before any useful weighted majority vote can be applied. There are various ways to model partial knowledge of expert competences (Baharad et al., 2011, 2012). Perhaps the simplest scenario for estimating the pis is to assume that the ith expert has been queried independently mi times, out of which he gave the correct prediction ki times. Taking the {mi} to be fixed, define the committee profile by k = (k1, . . . , kn); this is the aggregate of the agent’s empirical knowledge of the experts’ performance. An empirical decision rule f̂ : (x,k) 7→ {±1} makes a final decision based on the expert inputs x together with the committee profile. Analogously to (1), the probability of a mistake is\nP(f̂(X,K) 6= Y ). (20)\nNote that now the committee profile is an additional source of randomness. Here we run into our first difficulty: unlike the probability in (1), which is minimized by the Nitzan-Paroush rule, the agent cannot formulate an optimal decision rule f̂ in advance without knowing the pis. This is because no decision rule is optimal uniformly over the range of possible pis. Our approach will be to consider weighted majority decision rules of the form\nf̂(x,k) = sign\n(\nn ∑\ni=1\nŵ(ki)xi\n)\n(21)\nand to analyze their consistency properties under two different regimes: lowconfidence and high-confidence. These refer to the confidence intervals of the frequentist estimate of pi, given by\np̂i = ki mi . (22)"
    }, {
      "heading" : "4.1 Low-confidence regime",
      "text" : "In the low-confidence regime, the sample sizes mi may be as small as 1, and we define2\nŵ(ki) = ŵ LC i := p̂i − 12 , i ∈ [n], (23)\nwhich induces the empirical decision rule f̂LC. It remains to analyze f̂LC’s probability of error. Recall the definition of ξi from (5) and observe that\nE [ŵLCi ξi] = E[(p̂i − 12 )ξi] = (pi − 12 )pi, (24) 2For mi min {pi, qi} ≪ 1, the estimated competences p̂i may well take values in {0, 1}, in which case log(p̂i/q̂i) = ±∞. The rule in (23) is essentially a first-order Taylor approximation to w(·) about p = 1\n2 .\nsince p̂i and ξi are independent. As in (6), the probability of error (20) is\nP\n(\nn ∑\ni=1\nŵLCi ξi ≤ 1\n2\nn ∑\ni=1\nŵLCi\n)\n= P\n(\nn ∑\ni=1\nZi ≤ 0 ) , (25)\nwhere Zi = ŵ LC i (ξi − 12 ). Now the {Zi} are independent random variables, EZi = (pi − 12 )2 (by (24)), and each Zi takes values in an interval of length 12 . Hence, the standard Hoeffding bound applies:\nP(f̂LC(X,K) 6= Y ) ≤ exp\n\n− 8 n\n(\nn ∑\ni=1\n(pi − 12 ) 2\n)2 \n . (26)\nWe summarize these calculations in\nTheorem 5. A sufficient condition for P(f̂LC(X,K) 6= Y ) → 0 is\n1√ n\nn ∑\ni=1\n(pi − 12 ) 2 → ∞.\nSeveral remarks are in order. First, notice that the error bound in (26) is stated in terms of the unknown {pi}, providing the agent with large-committee asymptotics but giving no finitary information; this limitation is inherent in the low-confidence regime. Secondly, the condition in Theorem 5 is considerably more restrictive than the consistency condition Φ → ∞ implicit in Theorem 1. Indeed, the empirical decision rule f̂LC is incapable of exploiting a single highly competent expert in the way that fOPT from (2) does. Our analysis could be sharpened somewhat for moderate sample sizes {mi} by using Bernstein’s inequality to take advantage of the low variance of the p̂is. For sufficiently large sample sizes, however, the high-confidence regime (discussed below) begins to take over. Finally, there is one sense in which this case is “easier” to analyze than that of known {pi}: since the summands in (25) are bounded, Hoeffding’s inequality gives nontrivial results and there is no need for more advanced tools such as the Kearns-Saul inequality (9) (which is actually inapplicable in this case)."
    }, {
      "heading" : "4.2 High-confidence regime",
      "text" : "In the high-confidence regime, each estimated competence p̂i is close to the true value pi with high probability. To formalize this, fix some 0 < δ < 1, 0 < ε ≤ 5, and put\nqi = 1− pi, q̂i = 1− p̂i.\nWe will set the empirical weights according to the “plug-in” Nitzan-Paroush rule\nŵHCi := log p̂i q̂i , i ∈ [n], (27)\nwhich induces the empirical decision rule f̂HC and raises immediate concerns about ŵHCi = ±∞. We give two kinds of bounds on P(f̂HC 6= Y ): nonadaptive and adaptive. In the nonadaptive analysis, we show that for mimin {pi, qi}i ≫ 1, with high probability |wi − ŵHCi | ≪ 1, and thus a “perturbed” version of Theorem 1(i) holds (and in particular, wHCi will be finite with high probability). In the adaptive analysis, we allow ŵHCi to take on infinite values\n3 and show (perhaps surprisingly) that this decision rule also asymptotically achieves the rate of Theorem 1(i).\nNonadaptive analysis. Define ε̃ ∈ (0, 1) by ε = 2ε̃+ 4ε̃2 or, explicitly,\nε̃ =\n√ 4ε+ 1− 1\n4 . (28)\nLemma 6. If\nε̃2mipi ≥ 3 log(2n/δ), i ∈ [n], (29)\nthen\nP\n(\n∃i ∈ [n] : p̂i pi /∈ (1− ε̃, 1 + ε̃) ) ≤ δ.\nProof. The multiplicative Chernoff bound yields\nP (p̂i < (1 − ε̃)pi) ≤ e−ε̃ 2mipi/2\nand\nP (p̂i > (1 + ε̃)pi) ≤ e−ε̃ 2mipi/3.\nHence,\nP\n(\np̂i pi /∈ (1− ε̃, 1 + ε̃) ) ≤ 2e−ε̃2mipi/3.\nThe claim follows from (29) and the union bound.\nLemma 7. Let wi be the optimal Nitzan-Paroush weight (3). If\n1− ε̃ ≤ p̂i pi , q̂i qi ≤ 1 + ε̃\nthen\n|wi − ŵHCi | ≤ ε. 3When the decision rule is faced with evaluating sums involving ∞−∞, we automatically\ncount this as an error.\nProof. We have\n|wi − ŵHCi | = ∣ ∣ ∣\n∣ log pi qi − log p̂i q̂i\n∣ ∣ ∣ ∣\n=\n∣ ∣ ∣ ∣ log pi p̂i − log q̂i qi ∣ ∣ ∣ ∣\n=\n∣ ∣ ∣ ∣ log pi p̂i ∣ ∣ ∣ ∣ + ∣ ∣ ∣ ∣ log q̂i qi ∣ ∣ ∣ ∣ .\nNow4\n[log(1− ε̃), log(1 + ε̃)] ⊆ [−ε̃− 2ε̃2, ε̃] ⊆ [− 12ε, 12ε],\nwhence ∣\n∣ ∣ ∣ log pi p̂i\n∣ ∣ ∣ ∣ + ∣ ∣ ∣ ∣ log q̂i qi ∣ ∣ ∣ ∣ ≤ ε.\nCorollary 8. If\nε̃2mimin {pi, qi}i ≥ 3 log(4n/δ), i ∈ [n],\nthen\nP\n(\nmax i∈[n]\n|wi − ŵHCi | > ε ) ≤ δ.\nProof. An immediate consequence of applying Lemma 6 to pi and qi with the union bound.\nTo state the next result, let us arrange the plug-in weights (27) as a vector ŵ\nHC ∈ Rn, as was done with w and η from Section 3.1. The corresponding weighted majority rule f̂HC yields an error precisely when\nŵ HC · η ≤ 0\n(cf. (13)). Our nonadaptive approach culminates in the following result.\nTheorem 9. Let 0 < δ < 1 and 0 < ε < min {5, 2Φ/n}. If\nmi min {pi, qi}i ≥ 3 ( √ 4ε+ 1− 1\n4\n)−2\nlog 4n\nδ , i ∈ [n], (30)\nthen\nP\n( f̂HC(X,K) 6= Y ) ≤ δ + exp [ − (2Φ− εn) 2\n8Φ\n]\n. (31)\n4The first containment requires log(1 − x) ≥ −x − 2x2, which holds (not exclusively) on (0, 0.9). The restriction ε ≤ 5 ensures that ε̃ is in this range.\nRemark 3. For fixed {pi} and mini∈[n] mi → ∞, we may take δ and ε arbitrarily small — and in this limiting case, the bound of Theorem 1(i) is recovered.\nProof of Theorem 9. Since\n|w · η − ŵHC · η| = |(w − ŵHC) · η|\n≤ n ∑\ni=1\n|wi − wHCi | = ‖w− ŵHC‖1 ,\nwe have\nP (ŵHC · η ≤ 0) ≤ P(‖w − ŵHC‖1 > εn) + P(w · η ≤ εn).\nCorollary 8 upper-bounds the first term on the right-hand side by δ. The second term is estimated by replacing Φ by Φ− εn in (10) and repeating the argument following that formula.\nAdaptive analysis. Theorem 9 has the drawback of being nonadaptive, in that its assumptions (30) and conclusions (31) depend on the unknown {pi} and hence cannot be evaluated by the agent (the bound in (26) is also nonadaptive). In the adaptive approach, all results are stated in terms of empirically observed quantities:\nTheorem 10. Put5\nδ =\nn ∑\ni=1\n1√ mi\nand let R be the event\nexp\n(\n−1 2\nn ∑\ni=1\n(p̂i − 12 )ŵHCi\n)\n≤ δ 2 . (32)\nThen\nP\n( R ∩ { f̂HC(X,K) 6= Y }) ≤ δ.\nRemark 4. Our interpretation for Theorem 10 is as follows. The agent observes the committee profile K, which determines the {p̂i, ŵHCi }, and then checks whether the event R has occurred. If not, the adaptive agent refrains from making a decision (and may choose to fall back on the low-confidence approach described previously). If R does hold, however, the agent predicts Y according to\nf̂HC. As explained above, there does not exist a nontrivial a priori upper bound on P(f̂HC(X,K) 6= Y ) absent any knowledge of the pis. Instead, Theorem 10\n5 Actually, as the proof will show, we may take δ to be a smaller value, but with a more complex dependence on {mi}, which simplifies to 2[1− (1 − (2 √ m)−1)n] for mi ≡ m.\nbounds the probability of the agent being “fooled” by an unrepresentative committee profile.6 Observe that for mini∈[n] mi ≫ 1, we have p̂i ≈ pi and ŵHCi ≈ wi, and thus Theorem 1(i) is recovered as a limiting case. Note that we have done nothing to prevent ŵHCi = ±∞, and this may indeed happen. Intuitively, there are two reasons for infinite ŵHCi : (a) noisy p̂i due to mi being too small, or (b) the ith expert is actually highly (in)competent, which causes p̂i ∈ {0, 1} even for large mi. The 1/ √ mi term in the bound ensures against case (a), while in case (b), choosing infinite ŵHCi causes no harm (as we show in the proof).\nProof. We will write the probability and expectation operators with subscripts (such as K) to indicate the random variable(s) being summed over. Thus,\nPK,X,Y\n( R ∩ { f̂HC(X,K) 6= Y })\n= PK,η (R ∩ {ŵHC · η ≤ 0}) = EK [1R · Pη (ŵHC · η ≤ 0 |K)] .\n(33)\nRecall that the random variable η ∈ {±1}n, with probability mass function\nP (η) = ∏\ni:ηi=1\npi ∏\ni:ηi=−1\nqi,\nis independent of K, and hence\nPη (ŵ HC · η ≤ 0 |K) = Pη (ŵHC · η ≤ 0) . (34)\nDefine the random variable η̂ ∈ {±1}n (conditioned on K) by the probability mass function\nP (η̂) = ∏\ni:ηi=1\np̂i ∏\ni:ηi=−1\nq̂i,\nand the set A ⊆ {±1}n by A = {x : ŵHC · x ≤ 0} . Now\n|Pη (ŵHC · η ≤ 0)− Pη̂ (ŵHC · η̂ ≤ 0)| = |Pη (A)− Pη̂ (A)| ≤ max\nA⊆{±1}n |Pη (A)− Pη̂ (A)|\n= ‖Pη − Pη̂‖TV ≤ n ∑\ni=1\n|pi − p̂i| =: M,\nwhere the inequality follows from a standard tensorization property of the total variation norm ‖·‖\nTV , see e.g. (Kontorovich, 2012, Lemma 2.2). By Theo-\nrem 1(i), we have\nPη̂ (ŵ HC · η̂ ≤ 0) ≤ exp\n(\n− 12 n ∑\ni=1\n(p̂i − 12 )ŵ HC i\n)\n,\n6These adaptive bounds are similar in spirit to empirical Bernstein methods, (Audibert et al., 2007; Mnih et al., 2008; Maurer & Pontil, 2009), where the player’s confidence depends on the empirical variance.\nand hence\nPη (ŵ HC · η ≤ 0) ≤ M + exp\n(\n− 12 n ∑\ni=1\n(p̂i − 12 )ŵ HC i\n)\n.\nInvoking (34), we substitute the right-hand side above into (33) to obtain\nPK,X,Y\n( R ∩ { f̂HC(X,K) 6= Y }) ≤ EK [ 1R · ( M + exp ( − 12 n ∑\ni=1\n(p̂i − 12 )ŵ HC i\n))]\n≤ EK[M ] + EK [ 1R exp ( − 12 n ∑\ni=1\n(p̂i − 12 )ŵ HC i\n)]\n.\nBy the definition of R, the second term on the last right-hand side is upperbounded by δ/2. To estimate M , we invoke a simple mean absolute deviation bound (cf. Berend & Kontorovich (2013a)):\nEK |pi − p̂i| ≤ √\npi(1− pi) mi ≤ 1 2 √ mi ,\nwhich finishes the proof.\nRemark 5. The improvement mentioned in Footnote 5 is achieved via a refinement of the bound ‖Pη − Pη̂‖TV ≤ ∑n i=1 |pi − p̂i| to ‖Pη − Pη̂‖TV ≤ α ({|pi − p̂i| : i ∈ [n]}), where α(·) is the function defined in Kontorovich (2012, Lemma 4.2).\nOpen problem. As argued in Remark 4, Theorem 10 achieves the optimal asymptotic rate in {pi}. Can the dependence on {mi} be improved, perhaps through a better choice of ŵHC?"
    }, {
      "heading" : "5 Unknown competences: Bayesian approach",
      "text" : "A shortcoming of Theorem 10 is that when condition R fails, the agent is left with no estimate of the error probability. An alternative (and in some sense cleaner) approach to handling unknown expert competences pi is to assume a known prior distribution over the competence levels pi. The natural choice of prior for a Bernoulli parameter is the Beta distribution, namely\npi ∼ Beta(αi, βi)\nwith density\npαi−1i q βi−1 i\nB(αi, βi) , αi, βi > 0,\nwhere qi = 1−pi and B(x, y) = Γ(x)Γ(y)/Γ(x+y). Our full probabilistic model is as follows. Each of the n expert competences pi is drawn independently from\na Beta distribution with known parameters αi, βi. Then the i th expert, i ∈ [n], is queried independently mi times, with ki correct predictions and mi − ki incorrect ones. As before, K = (k1, . . . , kn) is the (random) committee profile. Absent direct knowledge of the pis, the agent relies on an empirical decision rule f̂ : (x,k) 7→ {±1} to produce a final decision based on the expert inputs x together with the committee profile k. A decision rule f̂Ba is Bayes-optimal if it minimizes\nP(f̂(X,K) 6= Y ), (35) which is formally identical to (20) but semantically there is a difference: the probability in (35) is over the pi in addition to (X, Y,K). Unlike the frequentist approach, where no optimal empirical decision rule was possible, the Bayesian approach readily admits one. For a given x ∈ {±1}, define I+(x) to be the set of YES votes\nI+(x) = {i ∈ [n] : xi = +1} and I−(x) = [n] \\ I+(x) to be the set of NO votes. Let us fix some A ⊆ [n], B = [n] \\A and compute\nP(Y = +1, I+(X) = A, I−(X) = B)\n=\nn ∏\ni=1\n∫ 1\n0\npαi−1i q βi−1 i\nB(αi, βi)\n(\nmi ki\n)\npkii q mi−ki i p 1{i∈A} i q 1{i∈B} i dpi\n=\nn ∏\ni=1\n(\nmi ki\n)\npkii q mi−ki i\nB(αi, βi)\n∫ 1\n0\np αi+ki−1+1{i∈A} i q βi+mi−ki−1+1{i∈B} i dpi\n=\nn ∏\ni=1\n(\nmi ki\n)\nB(αi + ki + 1{i∈A}, βi +mi − ki + 1{i∈B}) B(αi, βi) .\nAnalogously,\nP(Y = −1, I+(X) = A, I−(X) = B)\n= n ∏\ni=1\n(\nmi ki\n)\nB(αi + ki + 1{i∈B}, βi +mi − ki + 1{i∈A}) B(αi, βi) .\nLet us use the shorthand P (+1, A,B) and P (−1, A,B) for the joint probabilities in the last two displays, along with their corresponding conditionals P (±1 |A,B). Obviously,\nP (1|A,B) > P (−1|A,B) ⇐⇒ P (1, A,B) > P (−1, A,B), which occurs precisely if\nn ∏\ni=1\nB(αi + ki + 1{i∈A}, βi +mi − ki + 1{i∈B})\n>\nn ∏\ni=1\nB(αi + ki + 1{i∈B}, βi +mi − ki + 1{i∈A}).\nThis is equivalent to\n∏\ni∈A\n(αi + ki) ∏\ni∈B\n(βi +mi − ki) > ∏\ni∈B\n(αi + ki) ∏\ni∈A\n(βi +mi − ki),\nwhich further simplifies to\n∏\ni∈A\nαi + ki βi +mi − ki > ∏\ni∈B\nαi + ki βi +mi − ki .\nHence, the choice\nŵBai = log αi + ki\nβi +mi − ki guarantees that the decision rule\nf̂Ba(x,k) = sign\n(\nn ∑\ni=1\nŵBai xi\n)\nmaximizes the probability of being correct for each input x ∈ {±1}n. Notice that for 0 < pi < 1, we have\nŵBai −→mi→∞wi, i ∈ [n],\nalmost surely, both in the frequentist and the Bayesian interpretations. Unfortunately, although\nP(f̂Ba(X,K) 6= Y ) = P(ŵBa · η ≤ 0)\nis a deterministic function of {αi, βi,mi}, we are unable to compute it at this point, or even give a non-trivial bound. One source of the problem is the coupling between ŵBa and η.\nOpen problem. Give a non-trivial estimate for P(f̂Ba(X,K) 6= Y )."
    }, {
      "heading" : "6 Experiments",
      "text" : "It is most instructive to take the committee size n to be small when comparing the different voting rules. Indeed, for a large committee of “marginally competent” experts with pi = 1 2 + γ for some γ > 0, even the simple majority rule fMAJ(x) = sign( ∑n\ni=1 xi) has a probability of error decaying as exp(−4nγ2), as can be easily seen from Hoeffding’s bounds. The more sophisticated voting rules discussed in this paper perform even better in this setting. Hence, small committees provide the natural test-bed for gauging a voting rule’s ability to exploit highly competent experts. In our experiments, we set n = 5 and the sample sizes mi were identical for all experts. The results were averaged over 105 trials. Two of our experiments are described below.\nLow vs. high confidence. The goal of this experiment was to contrast the extremal behavior of f̂LC vs. f̂HC. To this end, we numerically optimized the p ∈ [0, 1]n so as to maximize the absolute gap\n∆n(p) := P(f LC(X) 6= Y )− P(fOPT(X) 6= Y ),\nwhere fLC(x) = sign ( ∑n i=1(pi − 12 )xi )\n. We were surprised to discover that, though the ratio P(fLC(X) 6= Y )/P(fOPT(X) 6= Y ) can be made arbitrarily large by setting p1 ≈ 1 and the remaining pi < 1 − ε, the absolute gap appears to be rather small: we conjecture (with some heuristic justification) that\nsupn≥1 supp∈[0,1]n ∆n(p) = 1/16. For f̂ Ba, we used αi = βi = 1 for all i. The results are reported in Figure 1.\nBayesian setting. In each trial, a vector of expert competences p ∈ [0, 1]n was drawn independently componentwise, with pi ∼ Beta(1, 1). These values (i.e., αi = βi ≡ 1) were used for f̂Ba. The results are reported in Figure 2."
    }, {
      "heading" : "7 Discussion",
      "text" : "The classic and seemingly well-understood problem of the consistency of weighted majority votes continues to reveal untapped depth and suggest challenging unresolved questions. We hope that the results and open problems presented here will stimulate future research."
    }, {
      "heading" : "Appendix: Deferred proofs",
      "text" : "Proof of Lemma 4. Since F is symmetric about x = 12 , it suffices to prove the claim for 12 ≤ x < 1. We will show that F is concave by examining its second derivative:\nF ′′(x) = −2x− 1− 2x(1− x) log(x/(1− x)) x(1− x)(2x − 1)3 .\nThe denominator is obviously nonnegative on [ 12 , 1], while the numerator has the Taylor expansion\n∞ ∑\nn=1\n22(n+1)(x − 12 )2n+1 4n2 − 1 ≥ 0,\n1 2 ≤ x < 1\n(verified through tedious but straightforward calculus). Since F is concave and symmetric about 12 , its maximum occurs at F ( 1 2 ) = 1 2 ."
    } ],
    "references" : [ {
      "title" : "Tuning bandit algorithms in stochastic environments",
      "author" : [ "Audibert", "Jean-Yves", "Munos", "Rémi", "Szepesvári", "Csaba" ],
      "venue" : "In ALT, pp",
      "citeRegEx" : "Audibert et al\\.,? \\Q2007\\E",
      "shortCiteRegEx" : "Audibert et al\\.",
      "year" : 2007
    }, {
      "title" : "Distilling the wisdom of crowds: weighted aggregation of decisions on multiple issues",
      "author" : [ "Baharad", "Eyal", "Goldberger", "Jacob", "Koppel", "Moshe", "Nitzan", "Shmuel" ],
      "venue" : "Autonomous Agents and Multi-Agent Systems,",
      "citeRegEx" : "Baharad et al\\.,? \\Q2011\\E",
      "shortCiteRegEx" : "Baharad et al\\.",
      "year" : 2011
    }, {
      "title" : "A sharp estimate of the binomial mean absolute deviation with applications",
      "author" : [ "Berend", "Daniel", "Kontorovich", "Aryeh" ],
      "venue" : "Statistics & Probability Letters,",
      "citeRegEx" : "Berend et al\\.,? \\Q2013\\E",
      "shortCiteRegEx" : "Berend et al\\.",
      "year" : 2013
    }, {
      "title" : "On the concentration of the missing mass",
      "author" : [ "Berend", "Daniel", "Kontorovich", "Aryeh" ],
      "venue" : "Electron. Commun. Probab.,",
      "citeRegEx" : "Berend et al\\.,? \\Q2013\\E",
      "shortCiteRegEx" : "Berend et al\\.",
      "year" : 2013
    }, {
      "title" : "When is Condorcet’s jury theorem valid",
      "author" : [ "Berend", "Daniel", "Paroush", "Jacob" ],
      "venue" : "Soc. Choice Welfare,",
      "citeRegEx" : "Berend et al\\.,? \\Q1998\\E",
      "shortCiteRegEx" : "Berend et al\\.",
      "year" : 1998
    }, {
      "title" : "Monotonicity in Condorcet’s jury theorem with dependent voters",
      "author" : [ "Berend", "Daniel", "Sapir", "Luba" ],
      "venue" : "Social Choice and Welfare,",
      "citeRegEx" : "Berend et al\\.,? \\Q2007\\E",
      "shortCiteRegEx" : "Berend et al\\.",
      "year" : 2007
    }, {
      "title" : "Modelling dependence in simple and indirect majority systems",
      "author" : [ "Boland", "Philip J", "Proschan", "Frank", "Y.L. Tong" ],
      "venue" : "J. Appl. Probab.,",
      "citeRegEx" : "Boland et al\\.,? \\Q1989\\E",
      "shortCiteRegEx" : "Boland et al\\.",
      "year" : 1989
    }, {
      "title" : "Prediction, learning, and games",
      "author" : [ "Cesa-Bianchi", "Nicolò", "Lugosi", "Gábor" ],
      "venue" : null,
      "citeRegEx" : "Cesa.Bianchi et al\\.,? \\Q2006\\E",
      "shortCiteRegEx" : "Cesa.Bianchi et al\\.",
      "year" : 2006
    }, {
      "title" : "A decision-theoretic generalization of online learning and an application to boosting",
      "author" : [ "Freund", "Yoav", "Schapire", "Robert E" ],
      "venue" : "J. Comput. Syst. Sci.,",
      "citeRegEx" : "Freund et al\\.,? \\Q1997\\E",
      "shortCiteRegEx" : "Freund et al\\.",
      "year" : 1997
    }, {
      "title" : "The Elements of Statistical Learning: Data Mining, Inference, and Prediction",
      "author" : [ "Hastie", "Trevor", "Tibshirani", "Robert", "Friedman", "Jerome" ],
      "venue" : null,
      "citeRegEx" : "Hastie et al\\.,? \\Q2009\\E",
      "shortCiteRegEx" : "Hastie et al\\.",
      "year" : 2009
    }, {
      "title" : "Large deviation methods for approximate probabilistic inference",
      "author" : [ "Kearns", "Michael J", "Saul", "Lawrence K" ],
      "venue" : "In UAI,",
      "citeRegEx" : "Kearns et al\\.,? \\Q1998\\E",
      "shortCiteRegEx" : "Kearns et al\\.",
      "year" : 1998
    }, {
      "title" : "Obtaining measure concentration from Markov contraction",
      "author" : [ "Kontorovich", "Aryeh" ],
      "venue" : "Markov Processes and Related Fields,",
      "citeRegEx" : "Kontorovich and Aryeh.,? \\Q2012\\E",
      "shortCiteRegEx" : "Kontorovich and Aryeh.",
      "year" : 2012
    }, {
      "title" : "PAC-Bayes bounds for the risk of the majority vote and the variance of the gibbs classifier",
      "author" : [ "Lacasse", "Alexandre", "Laviolette", "François", "Marchand", "Mario", "Germain", "Pascal", "Usunier", "Nicolas" ],
      "venue" : "In NIPS, pp",
      "citeRegEx" : "Lacasse et al\\.,? \\Q2006\\E",
      "shortCiteRegEx" : "Lacasse et al\\.",
      "year" : 2006
    }, {
      "title" : "PAC-Bayes risk bounds for stochastic averages and majority votes of sample-compressed classifiers",
      "author" : [ "Laviolette", "François", "Marchand", "Mario" ],
      "venue" : "Journal of Machine Learning Research,",
      "citeRegEx" : "Laviolette et al\\.,? \\Q2007\\E",
      "shortCiteRegEx" : "Laviolette et al\\.",
      "year" : 2007
    }, {
      "title" : "The weighted majority algorithm",
      "author" : [ "Littlestone", "Nick", "Warmuth", "Manfred K" ],
      "venue" : "In FOCS, pp",
      "citeRegEx" : "Littlestone et al\\.,? \\Q1989\\E",
      "shortCiteRegEx" : "Littlestone et al\\.",
      "year" : 1989
    }, {
      "title" : "The weighted majority algorithm",
      "author" : [ "Littlestone", "Nick", "Warmuth", "Manfred K" ],
      "venue" : "Inf. Comput.,",
      "citeRegEx" : "Littlestone et al\\.,? \\Q1994\\E",
      "shortCiteRegEx" : "Littlestone et al\\.",
      "year" : 1994
    }, {
      "title" : "Robust aggregation of experts signals",
      "author" : [ "Mansour", "Yishay", "Rubinstein", "Aviad", "Tennenholtz", "Moshe" ],
      "venue" : null,
      "citeRegEx" : "Mansour et al\\.,? \\Q2013\\E",
      "shortCiteRegEx" : "Mansour et al\\.",
      "year" : 2013
    }, {
      "title" : "Empirical Bernstein bounds and sample-variance penalization",
      "author" : [ "Maurer", "Andreas", "Pontil", "Massimiliano" ],
      "venue" : "In COLT,",
      "citeRegEx" : "Maurer et al\\.,? \\Q2009\\E",
      "shortCiteRegEx" : "Maurer et al\\.",
      "year" : 2009
    }, {
      "title" : "Concentration inequalities for the missing mass and for histogram rule error",
      "author" : [ "McAllester", "David A", "Ortiz", "Luis E" ],
      "venue" : "Journal of Machine Learning Research,",
      "citeRegEx" : "McAllester et al\\.,? \\Q2003\\E",
      "shortCiteRegEx" : "McAllester et al\\.",
      "year" : 2003
    }, {
      "title" : "Empirical Bernstein stopping",
      "author" : [ "Mnih", "Volodymyr", "Szepesvári", "Csaba", "Audibert", "Jean-Yves" ],
      "venue" : "In ICML, pp",
      "citeRegEx" : "Mnih et al\\.,? \\Q2008\\E",
      "shortCiteRegEx" : "Mnih et al\\.",
      "year" : 2008
    }, {
      "title" : "On the problem of the most efficient tests of statistical hypotheses",
      "author" : [ "Neyman", "Jerzy", "Pearson", "Egon S" ],
      "venue" : "Philosophical Transactions of the Royal Society A: Mathematical, Physical and Engineering Sciences,",
      "citeRegEx" : "Neyman et al\\.,? \\Q1933\\E",
      "shortCiteRegEx" : "Neyman et al\\.",
      "year" : 1933
    }, {
      "title" : "Optimal decision rules in uncertain dichotomous choice situations",
      "author" : [ "Nitzan", "Shmuel", "Paroush", "Jacob" ],
      "venue" : "International Economic Review,",
      "citeRegEx" : "Nitzan et al\\.,? \\Q1982\\E",
      "shortCiteRegEx" : "Nitzan et al\\.",
      "year" : 1982
    }, {
      "title" : "Concentration of measure inequalities in information theory, communications and coding",
      "author" : [ "Raginsky", "Maxim", "Sason", "Igal" ],
      "venue" : "Foundations and Trends in Communications and Information Theory,",
      "citeRegEx" : "Raginsky et al\\.,? \\Q2013\\E",
      "shortCiteRegEx" : "Raginsky et al\\.",
      "year" : 2013
    }, {
      "title" : "From PAC-Bayes bounds to quadratic programs for majority votes",
      "author" : [ "Roy", "Jean-Francis", "Laviolette", "François", "Marchand", "Mario" ],
      "venue" : "In ICML, pp",
      "citeRegEx" : "Roy et al\\.,? \\Q2011\\E",
      "shortCiteRegEx" : "Roy et al\\.",
      "year" : 2011
    }, {
      "title" : "Boosting. Foundations and algorithms. Adaptive Computation and Machine Learning",
      "author" : [ "Schapire", "Robert E", "Freund", "Yoav" ],
      "venue" : null,
      "citeRegEx" : "Schapire et al\\.,? \\Q2012\\E",
      "shortCiteRegEx" : "Schapire et al\\.",
      "year" : 2012
    } ],
    "referenceMentions" : [ {
      "referenceID" : 9,
      "context" : "(3) Thus, wi is the log-odds of expert i being correct — and the voting rule in (2), also known as naive Bayes (Hastie et al., 2009), may be seen as a simple consequence of the Neyman-Pearson lemma (Neyman & Pearson, 1933).",
      "startOffset" : 111,
      "endOffset" : 132
    }, {
      "referenceID" : 16,
      "context" : "Even more recently, experts with adversarial noise have been considered (Mansour et al., 2013).",
      "startOffset" : 72,
      "endOffset" : 94
    }, {
      "referenceID" : 11,
      "context" : "In a recent line of work Lacasse et al. (2006); Laviolette & Marchand (2007); Roy et al.",
      "startOffset" : 25,
      "endOffset" : 47
    }, {
      "referenceID" : 11,
      "context" : "In a recent line of work Lacasse et al. (2006); Laviolette & Marchand (2007); Roy et al.",
      "startOffset" : 25,
      "endOffset" : 77
    }, {
      "referenceID" : 11,
      "context" : "In a recent line of work Lacasse et al. (2006); Laviolette & Marchand (2007); Roy et al. (2011) have developed a PAC-Bayesian theory for the majority vote of simple classifiers.",
      "startOffset" : 25,
      "endOffset" : 96
    }, {
      "referenceID" : 11,
      "context" : "In a recent line of work Lacasse et al. (2006); Laviolette & Marchand (2007); Roy et al. (2011) have developed a PAC-Bayesian theory for the majority vote of simple classifiers. This approach facilitates data-dependent bounds and is even flexible enough to capture some simple dependencies among the classifiers — though, again, the latter are learners as opposed to our experts. Even more recently, experts with adversarial noise have been considered (Mansour et al., 2013). More directly related to the present work are the papers of Berend & Paroush (1998), which characterizes the consistency of the simple majority rule, and Boland et al.",
      "startOffset" : 25,
      "endOffset" : 560
    }, {
      "referenceID" : 6,
      "context" : "More directly related to the present work are the papers of Berend & Paroush (1998), which characterizes the consistency of the simple majority rule, and Boland et al. (1989); Berend & Sapir (2007) which analyze various models of dependence among the experts.",
      "startOffset" : 154,
      "endOffset" : 175
    }, {
      "referenceID" : 6,
      "context" : "More directly related to the present work are the papers of Berend & Paroush (1998), which characterizes the consistency of the simple majority rule, and Boland et al. (1989); Berend & Sapir (2007) which analyze various models of dependence among the experts.",
      "startOffset" : 154,
      "endOffset" : 198
    }, {
      "referenceID" : 0,
      "context" : ", These adaptive bounds are similar in spirit to empirical Bernstein methods, (Audibert et al., 2007; Mnih et al., 2008; Maurer & Pontil, 2009), where the player’s confidence depends on the empirical variance.",
      "startOffset" : 78,
      "endOffset" : 143
    }, {
      "referenceID" : 19,
      "context" : ", These adaptive bounds are similar in spirit to empirical Bernstein methods, (Audibert et al., 2007; Mnih et al., 2008; Maurer & Pontil, 2009), where the player’s confidence depends on the empirical variance.",
      "startOffset" : 78,
      "endOffset" : 143
    } ],
    "year" : 2014,
    "abstractText" : "We revisit the classical decision-theoretic problem of weighted expert voting from a statistical learning perspective. In particular, we examine the consistency (both asymptotic and finitary) of the optimal NitzanParoush weighted majority and related rules. In the case of known expert competence levels, we give sharp error estimates for the optimal rule. When the competence levels are unknown, they must be empirically estimated. We provide frequentist and Bayesian analyses for this situation. Some of our proof techniques are non-standard and may be of independent interest. The bounds we derive are nearly optimal, and several challenging open problems are posed. Experimental results are provided to illustrate the theory.",
    "creator" : "dvips(k) 5.991 Copyright 2011 Radical Eye Software"
  }
}