{
  "name" : "1302.6937.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "Online Learning for Loss Functions with Memory and Applications to Statistical Arbitrage",
    "authors" : [ "Oren Anava", "Elad Hazan", "Shie Mannor" ],
    "emails" : [ "soanava@tx.technion.ac.il", "ehazan@ie.technion.ac.il", "shie@ee.technion.ac.il" ],
    "sections" : [ {
      "heading" : null,
      "text" : "ar X\niv :1\n30 2.\n69 37\nv1 [\ncs .L\nG ]\n2 7\n√ T )-regret. This improves previous online learning algorithms that guaranteed O(T 2/3) regret and required more stringent conditions. As an application of the new technique, we address the classical problem in finance of constructing mean reverting portfolios. We design an efficient online learning algorithm for this problem, and provide guarantees for its performance. We complement our theoretical findings with an empirical study that verifies our theoretical results on financial data."
    }, {
      "heading" : "1 Introduction",
      "text" : "In numerous online learning scenarios the environment is not completely oblivious to the decision maker, and the decision maker’s historical actions affect her current state and future rewards. We are particularly concerned in scenarios in which this historic effect is relatively short-term and simple, in contrast to stateaction models in which better tailored reinforcement learning models have been devised [YMS09].\nThus, our focus is on online learning in which actions have short-term effects on future losses. This model was initially considered in the information theory community [MOSW06], with an eye on applications in compression, coding and portfolio selection. In this work, after describing our contributions to this framework, we apply this model to finding statistical arbitrage opportunities in financial market data.\nWe start by studying the framework of online learning with memory. Our first result is a novel algorithm for this framework that attains optimal regret bounds on the order of O( √ T ), where T is the number of prediction iterations. The algorithm is also computationally efficient, and we show that its assumptions are not only sufficient, but in fact necessary for any efficient algorithm for learning with memory. These bounds improve [MOSW06], who attains a regret bound of O(T 2/3). Thus, our results show that in fact the optimal regret bounds for this framework are of the same order as standard memoryless learning, and the overhead for the more complicated model is in the memory effect only.\nNext, we proceed to study our motivating problem — constructing mean revering portfolios. In the literature, “statistical arbitrage” refers to statistical mispricing of one or more assets based on the expected\nvalue of these assets. One of the most common trading strategies, known as “pairs trading”, seeks to create a mean reverting portfolio by combining two different assets (typically using both short and long sales). Then, by buying the combined portfolio below its mean and selling it above, one can have an expected positive profit with low risk.\nThis strategy consists of three main steps: choosing the two underlying assets, then finding appropriate distribution of weights over them, and finally applying trading algorithms (which determine the buying and selling points) to maximize profit. In this work we focus on the first two steps with the following extensions: we allow portfolios that consist of more than two assets, and we consider an online scheme in which the distribution of weights can be updated (up to some extent). I.e., given a set of n different assets we wish to isolate a subset of k assets that has a large amount of mean reversion, and then determine a certain weight distribution over this subset.\nThe problem of modifying the weights of a portfolio in order to maximize mean reversion is a learning problem with memory: the weights of previous iterations determine the price of the mixed asset, and thus the overall performance in terms of mean reversion. We cast this problem formally as a learning with memory problem, and utilize our new technique to solve it online. This yields the first sub-linear regret algorithm for this problem. Besides the theoretical sublinear regret bound, we test the resulting algorithm and demonstrate its effectiveness on financial data."
    }, {
      "heading" : "1.1 Related work",
      "text" : "Statistical arbitrage and in particular pairs trading strategies initially took place in the mid 80’s [EG87]. Since then, a great deal of work has been done on the problem of assembling mean reverting portfolios, mostly using cointegration techniques (see [Vid11] for more comprehensive information). In order to quantify the amount of mean reversion in various portfolios, different proxies are often suggested such as zero-crossing and predictability [Sch11, D’A11]. In this work, we consider a new proxy for mean reversion which is aimed at maximizing fluctuation, as well as keeping the mean close to zero. Furthermore, whereas classical cointegration techniques require training period before applying a trading strategy (see for instance [AL10, AM12]), the online approach does not require that, in addition to providing a performance guarantee against the best mean reverting portfolio in hindsight."
    }, {
      "heading" : "2 Online learning with memory",
      "text" : "Online learning is a game-theoretic optimization framework, where iteratively an online player chooses a decision xt, and suffers loss ft(xt). The loss function ft is chosen by an all-powerful adversary with full knowledge of our learning algorithm (see for instance [CBL06]).\nHere we consider the following extension. At iteration t, an online player chooses a decision xt ∈ K, where K is called the decision set. Then, an adversary chooses a loss function ft : Km → R, and the online player suffers loss of ft(xt−m+1, . . . , xt). Notice that the loss at iteration t depends on the previous m− 1 decisions of the player, as well as on his current decision.\nOur goal in this framework is to minimize the sum of losses over predefined number of iterations T . A reasonable benchmark is to try to be not much worse than the total loss suffered by the best decision in hindsight. More precisely, we define the regret as\nRT =\nT ∑\nt=m\nft(xt−m+1, . . . , xt)−min x\nT ∑\nt=m\nft(x, . . . , x), (1)\nand wish to obtain efficient algorithms, whose regret grows sub-linearly in T , corresponding to an average per-round regret going to zero as T increases. 1\nWe henceforth make the following assumptions. The first two assumptions are standard and necessary for any regret minimization algorithm to apply, even without memory. Assumption three is the only new assumption we make, and as we explain - it is a necessary assumption if one considers efficient algorithms.\n1. The diameter of K is bounded, i.e., there exists D > 0, such that supx,y∈K ‖x− y‖ ≤ D , where ‖ · ‖ refers to the ℓ2 norm.\n2. There exists G > 0, such that\nsup (xt−m+1,...,xt),t\n‖∇ft(xt−m+1, . . . , xt)‖ ≤ G.\nIt follows that ft is Lipchitz continuous with a Lipchitz constant G.\n3. Define gt(x) = ft(x, . . . , x). Then, we assume that gt(x) is convex in x, for all t. This assumption is essentially necessary for an efficient algorithm, since achieving sublinear regret bound for {ft}Tt=1 implies also that\n∑T t=1 gt(x) can be minimized efficiently."
    }, {
      "heading" : "2.1 Algorithm and analysis",
      "text" : "By assumption 3 the functions {gt}Tt=1 are convex, and hence we can apply the Online Gradient Descent (OGD) algorithm of [Zin03] with some modifications.\nAlgorithm 1 OGD with Memory 1: Input: Learning rate η. 2: Choose x1 ∈ K arbitrarily. 3: for t = 1 to T do 4: Play xt and suffer loss ft(xt−m+1, . . . , xt).\n5: Set xt+1 ← ΠK ( xt − η∇gt(xt) ) 6: end for\nHere, ΠK is the Euclidean projection onto K, i.e.\nΠK(y) = argmin x∈K\n‖y − x‖.\n1The iterations in which t < m are ignored since we assume that the loss per iteration is bounded by a constant, this adds at most a constant to the final regret bound.\nFor Algorithm 1 we can prove the following bound.\nTheorem 2.1. Let G and D be as defined in Section 2, and set η = D G √ mT . Then, Algorithm 1 achieves the following regret bound for {ft}Tt=1:\nRT =\nT ∑\nt=m\nft(xt−m+1, . . . , xt)−min x\nT ∑\nt=m\nft(x, . . . , x) ≤ 2 ·GD √ mT. (2)\nProof. By applying algorithm 1 for the loss functions {gt}Tt=1 we have that\nT ∑\nt=m\ngt(xt)−min x\nT ∑\nt=m\ngt(x) ≤ D2\n2η +\nηG2T\n2 ,\nusing the analysis of [Zin03], and from the definitions of ft and gt it follows that\nT ∑\nt=m\nft(xt, . . . , xt)−min x\nT ∑\nt=m\nft(x, . . . , x) ≤ D2\n2η +\nηG2T\n2 . (3)\nOn the other hand, since ft is Lipshitz continuous for the Lipshitz constant G we have:\n|ft(xt, . . . , xt)− ft(xt−m+1, . . . , xt)|2\n≤ (G · ‖(xt, . . . , xt)− (xt−m+1, . . . , xt)‖)2 = G2 · m−1 ∑\nj=1\n‖xt − xt−j‖2\n≤ G2 · m−1 ∑\nj=1\nj ∑\nl=1\n‖xt−l+1 − xt−l‖2 ≤ G2 · m−1 ∑\nj=1\nj ∑\nl=1\n‖η∇gt−l(xt−l)‖2\n≤ G2 · m−1 ∑\nj=1\nj ∑\nl=1\nη2G2 = G4 · m−1 ∑\nj=1\nj ∑\nl=1\nη2 ≤ m2η2G4,\nwhich implies that |ft(xt, . . . , xt)− ft(xt−m+1, . . . , xt)| ≤ mηG2.\nSumming the above for t = m, . . . , T we get:\n∣ ∣ ∣ ∣ ∣ T ∑\nt=m\nft(xt, . . . , xt)− T ∑\nt=m\nft(xt−m+1, . . . , xt)\n∣ ∣ ∣ ∣ ∣ ≤ T ∑\nt=m\nmηG2 = mηG2T. (4)\nNow, by combining Equations (3) and (4) we get the following inequality:\nT ∑\nt=m\nft(xt−m+1, . . . , xt)−min x\nT ∑\nt=m\nft(x, . . . , x) ≤ D2\n2η +\nηG2T\n2 +mηG2T.\nFinally, substituting η = D G √ mT yields\nRT = T ∑\nt=m\nft(xt−m+1, . . . , xt)−min x\nT ∑\nt=m\nft(x, . . . , x) ≤ 2 ·GD √ mT,\nwhich completes the proof."
    }, {
      "heading" : "3 Application to finance",
      "text" : "In this section we use the technique just developed to find and exploit statistical arbitrage opportunities. Roughly speaking, the goal is to synthetically create a mean reverting portfolio, exploiting correlation between similar assets. That is, we are seeking a strategy that maintains weights upon predefined set of assets, such that the combined portfolio is mean reverting.\nAs a first step we define a criterion for measuring mean reversion, that is empirically well behaving. Unfortunately, this criterion is not convex (as are most of other previously considered criteria), and we define a semi-definite relaxation to cope with the problem. Another difficulty comes from the very nature of the problem: weights of one iteration affect future performance, thus memory comes unavoidably into the picture.\nWe proceed to formally define the new mean reversion criterion, its semi-definite relaxation, and the use of our new memory-learning algorithm in this model."
    }, {
      "heading" : "3.1 Problem definition",
      "text" : "Tendency to return to the mean is not a quantifiable criterion for mean reversion, and the literature addresses several proxies to capture the notion of mean reversion, e.g., in [Sch11, D’A11]. In this work, we present a new criterion for mean reversion effectiveness: low squared mean and high variance. More precisely, we denote by yt ∈ Rn the prices of n assets at time t, and by xt ∈ Rn a distribution of weights over these assets (we allow short selling, thus xt can contain negative entries).\nSince short selling is allowed, the norm of xt can sum up to an arbitrary number, determined by the loan flexibility of the back. Thus we assume without loss of generality that ‖xt‖2 = 1, and define the following loss function:\nft(xt−m−1, . . . , xt) =\n( m−1 ∑\ni=0\nxTt−iyt−i\n)2\n− λ · m−1 ∑\ni=0\n( xTt−iyt−i )2\nfor some λ > 0. Notice that minimizing this loss function iteratively yields a process {xTt yt}Tt=1 such that its mean is close to 0, while its variance is maximized. Variance maximization is crucial here, since high variance processes tend to create larger amount of statistical arbitrage opportunities.\nWe use the regret criterion to measure our performance against the best distribution of weights in hindsight, and wish to obtain online algorithm that generates a series {xt}Tt=1 such that\nT ∑\nt=m\nft(xt−m−1, . . . , xt)−min x\nT ∑\nt=m\nft(x, . . . , x) = o(T ).\nThe previous distributions of our weights affect the mean reversion amount of our portfolio, and hence ft is a loss function with memory. As in Section 2, we define gt(x) = ft(x, . . . , x), and show that by obtaining regret bound for {gt}Tt=1 we also guarantee a regret bound for {ft}Tt=1. Notice that gt is of the form\ngt(x) = x TAtx− xTBtx (5)\nfor\nAt =\nm−1 ∑\ni=0\nm−1 ∑\nj=0\nyt−iyt−j ,\nand\nBt = λ · ( m−1 ∑\ni=0\nyt−iy T t−i\n)\n,\nThe function gt is not convex in general, and hence we cannot apply the technique detailed in Section 2 straightforwardly. Instead, we define\nht(X) = X ◦ At −X ◦Bt, (6) where\nX ◦ A = n ∑\ni=1\nn ∑\nj=1\nX(i, j) · A(i, j),\nand X is a PSD matrix with Tr(X) = 1.\nNow, the problem of minimizing ∑T t=m ht(X) is a PSD relaxation to the problem of minimizing ∑T\nt=m gt(x), and for the optimal solution\nx⋆ = argmin x\nT ∑\nt=m\ngt(x),\nit holds in particular that\nmin X\nT ∑\nt=m\nht(X) ≤ T ∑\nt=m\nht(x ⋆x⋆⊤) =\nT ∑\nt=m\ngt(x ⋆).\nNotice that ht is linear in X for all t, and hence we can apply regret minimization techniques on the loss functions {ht}Tt=1."
    }, {
      "heading" : "3.2 Parameter setting",
      "text" : "Throughout this section we use the following parameters and notations:\n1. The decision set K is defined as:\nK = {X|X is PSD and Tr (X) = 1}.\nFrom this definition we can bound the diameter of K by supX,Y ∈K ‖X − Y ‖F ≤ D = √ 2 , when ‖ · ‖F refers to the Frobenius norm.\n2. There exists G > 0, such that\nsup (xt−m+1,...,xt),t\n‖∇ft(xt−m+1, . . . , xt)‖ ≤ G.\nIt follows that ft is Lipshitz continuous for the Lipshitz constant G, and also that\nsup Xt,t\n‖∇ht(Xt)‖F ≤ G.\nClearly, the value of G depends on the prices of assets we are considering, and its computation is done accordingly."
    }, {
      "heading" : "3.3 Algorithm and analysis",
      "text" : "We turn now to present our online algorithm.\nAlgorithm 2 Online Statistical Arbitrage (OSA)\n1: Input: Learning rate η, X0 = 1nIn×n. 2: Randomize x0 ∼ X0. 3: for t = 1 to (T − 1) do 4: Set Xt ← ΠK (Xt−1 − η∇ht(Xt)) 5: Set xt = xt−1 w.p. (\n1− 1 m √ T\n)\n,\n6: Otherwise, randomize xt ∼ Xt. 7: Play xt and suffer loss ft(xt−m+1, . . . , xt). 8: end for\nHere, ΠK refers to the following projection onto K:\nΠK(X) = arg min Y ∈K\n‖X − Y ‖F .\nAlso, xt ∼ Xt refers to the eigenvector decomposition of the matrix Xt. I.e, we represent Xt = ∑n i=1 λiviv ⊤ i , where each vi is a unit vector and ∑n\ni=1 λi = 1, when λi ≥ 0. Then, we randomize the eigenvector xt = vi with probability λi. Technically, this decomposition is possible due to the fact that Xt is positive semidefinite with Tr(Xt) = 1 for all t.\nFor Algorithm 2 we can prove the following bound.\nTheorem 3.1. Set η = D√ mGT 3/4 . Then, Algorithm 2 achieves the following regret bound for {ft}Tt=1:\nRT = T ∑\nt=m\nE [ft(xt−m+1, . . . , xt)]−min x\nT ∑\nt=m\nft(x, . . . , x) ≤ 3 · √ mGDT 3/4.\nProof. By applying Algorithm 2 for the loss functions {ht}Tt=1 we get a series of matrices {Xt}Tt=1, such that\nT ∑\nt=m\nht(Xt)−min X\nT ∑\nt=m\nht(X) ≤ D2\n2η +\nG2\n2\nT ∑\nt=m\nη,\nusing the analysis of [Zin03]. From the definitions of gt and ht it exists that\nmin X\nT ∑\nt=m\nht(X) ≤ min x\nT ∑\nt=m\ngt(x),\nand hence T ∑\nt=m\nht(Xt)−min x\nT ∑\nt=m\ngt(x) ≤ D2\n2η +\nG2\n2\nT ∑\nt=m\nη.\nNow, from Lemma 3.2 we know that ∣\n∣ ∣ ∣ ∣\nT ∑\nt=m\nht(Xt)− E [gt(xt)] ∣ ∣ ∣ ∣\n∣\n≤ √ mGDT 3/4,\nwhich yields T ∑\nt=m\nE [gt(xt)]−min x\nT ∑\nt=m\ngt(x) ≤ D2\n2η +\nG2\n2\nT ∑\nt=m\nη + √ mGDT 3/4.\nFrom the definition of gt it follows that\nT ∑\nt=m\nE [ft(xt, . . . , xt)]−min x\nT ∑\nt=m\nft(x, . . . , x) ≤ D2\n2η +\nG2\n2\nT ∑\nt=1\nη + √ mGDT 3/4. (7)\nNext, we bound the distance between xt and xt−1 in expectation for all t. Unlike presented in Section 2, we cannot rely on the closeness of xt and xt−1 that follows from the step size of the online update. However, we can use the fact that xt 6= xt−1 with probability 1m√T , and therefore\nE [ ‖xt − xt−1‖2 ] ≤ 0 · ( 1− 1 m √ T ) +D2 · 1 m √ T = D2 m √ T .\nNow, similarly to Section 2 we rely on the fact that ft is Lipchitz continuous with a Lipchitz constant G, and thus\n|E [ft(xt, . . . , xt)]− E [ft(xt−m+1, . . . , xt)]|2\n≤ E [|ft(xt, . . . , xt)− ft(xt−m+1, . . . , xt)|]2 ≤ (G · E [‖(xt, . . . , xt)− (xt−m+1, . . . , xt)‖])2 ≤ G2 · m−1 ∑\nj=1\nE [ ‖xt − xt−j‖2 ] ≤ G2 · m−1 ∑\nj=1\nj ∑\nl=1\nE [ ‖xt−l+1 − xt−l‖2 ] ≤ G2 · m−1 ∑\nj=1\nj ∑\nl=1\nD2\nm √ T\n≤ mG 2D2√ T ,\nand it follows that\n|E [ft(xt, . . . , xt)]− E [ft(xt−m+1, . . . , xt)] | ≤ √ mGD\nT 1/4 .\nSumming the above for all t yields\n∣ ∣ ∣ ∣ ∣ T ∑\nt=m\nE [ft(xt, . . . , xt)]− T ∑\nt=m\nE [ft(xt−m+1, . . . , xt)]\n∣ ∣ ∣ ∣ ∣ ≤ √ mGDT 3/4, (8)\nand by combining (7) and (8) we get that\nT ∑\nt=m\nE [ft(xt, . . . , xt)]−min x\nT ∑\nt=m\nft(x, . . . , x) ≤ D2\n2η +\nG2\n2\nT ∑\nt=1\nη + 2 · √ mGDT 3/4.\nFinally, substituting η = D√ mGT 3/4 yields\nRT =\nT ∑\nt=m\nE [ft(xt−m+1, . . . , xt)]−min x\nT ∑\nt=m\nft(x, . . . , x) ≤ 3 · √ mGDT 3/4,\nwhich completes the proof.\nWe now turn to prove Lemma 3.2.\nLemma 3.2. Let gt and ht be as denoted in Equations and (5) and (6). Then, Algorithm 2 generates online sequences {Xt}Tt=1 and {xt}Tt=1 such that\n∣ ∣ ∣ ∣ ∣ T ∑\nt=m\nht(Xt)− E [gt(xt)] ∣ ∣ ∣ ∣\n∣\n≤ √ mGDT 3/4.\nProof. Notice that gt(xt) = ht ( xtx ⊤ t ) from the definitions of gt and ht. We show by induction that\n∥ ∥ ∥ Xt − E [ xtx ⊤ t ]∥ ∥ ∥\nF ≤\n√ mD\nT 1/4 ,\nand from the Lipchitz property of {ht}Tt=1 this also implies that ∣\n∣ ∣ ht(Xt)− E\n[\nht\n(\nxtx ⊤ t\n)] ∣\n∣ ∣ ≤\n√ mGD\nT 1/4 .\nThus, for t = 0 we have that ∥\n∥ ∥ X0 − E\n[\nx0x ⊤ 0\n]∥\n∥ ∥ F = 0 ≤\n√ mD\nT 1/4 ,\nsince x0 ∼ X0. For t = 1 we have that ∥\n∥ ∥ X1 − E\n[\nx1x ⊤ 1\n] ∥\n∥ ∥\nF\n= 0 · 1 m √ T + ∥ ∥ ∥ X1 − E [ x0x ⊤ 0 ] ∥ ∥ ∥ F · ( 1− 1 m √ T )\n= ∥ ∥ ∥ X1 −X0 +X0 − E [ x0x ⊤ 0 ]∥ ∥ ∥ F · ( 1− 1 m √ T ) ≤ ‖X1 −X0‖F · (\n1− 1 m √ T\n)\n+ ∥ ∥ ∥ X0 − E [ x0x ⊤ 0 ] ∥ ∥ ∥ F · ( 1− 1 m √ T )\n≤ (ηG) · ( 1− 1 m √ T ) = D√ mT 3/4 − D m3/2T 5/4 ≤\n√ mD\nT 1/4 .\nNext, we assume that ∥\n∥ ∥ Xt − E\n[\nxtx ⊤ t\n]∥\n∥ ∥ F ≤\n√ mD\nT 1/4\nand prove that ∥\n∥ ∥ Xt+1 − E\n[\nxt+1x ⊤ t+1\n] ∥\n∥ ∥ F ≤\n√ mD\nT 1/4 .\nThus, ∥\n∥ ∥ Xt+1 − E\n[\nxt+1x ⊤ t+1\n]∥\n∥ ∥\nF\n= 0 · 1 m √ T + ∥ ∥ ∥ Xt+1 − E [ xtx ⊤ t ]∥ ∥ ∥ F · ( 1− 1 m √ T )\n= ∥ ∥ ∥ Xt+1 −Xt +Xt − E [ xtx ⊤ t ] ∥ ∥ ∥ F · ( 1− 1 m √ T ) ≤ ‖Xt+1 −Xt‖F · (\n1− 1 m √ T\n)\n+ ∥ ∥ ∥ Xt − E [ xtx ⊤ t ]∥ ∥ ∥ F · ( 1− 1 m √ T )\n≤ ( ηG+\n√ mD\nT 1/4\n) · ( 1− 1 m √ T ) = ( D√ mT 3/4 +\n√ mD\nT 1/4\n) · ( 1− 1 m √ T )\n=\n√ mD\nT 1/4 − D m3/2T 5/4 ≤\n√ mD\nT 1/4 ,\nwhich completes the induction. Now, from the Lipchitz property of {ht}Tt=1 this implies that ∣\n∣ ∣ ht(Xt)− E\n[\nht\n(\nxtx ⊤ t\n)] ∣\n∣ ∣ ≤\n√ mGD\nT 1/4 ,\nand summing the above for all t yields\n∣ ∣ ∣ ∣ ∣ T ∑\nt=m\nht(Xt)− E [ ht(xtx ⊤ t ) ]\n∣ ∣ ∣ ∣ ∣ ≤ √ mGDT 3/4."
    }, {
      "heading" : "4 Experiments",
      "text" : "The following experiments demonstrate the effectiveness of the proposed algorithms, under two different settings. In the first setting, we consider the Dow Jones Index (30 stocks) and apply our criterion to isolate subsets of stocks that have a maximal amount of mean reversion. In the second setting, we consider pairs of sector related stocks, and apply the proposed algorithm to construct mean reverting portfolios (“pairs trading”)."
    }, {
      "heading" : "4.1 Comparison method",
      "text" : "We compare the amount of mean reversion of the different portfolios using the Portmanteau test from [LB78]. This test is aimed at determining whether a process is close to be pure noise process, and hence can be effectively applied in our case as a measure for mean reversion. More accurately, we define ∆t = xTt yt − xTt−1yt−1 to be the daily change of our portfolio, and consequently\nQm ( {∆t}Tt=1 ) = T (T + 2)\nL ∑\nk=1\n(\nρ (k)2 T − k\n)\n,\nto be the Portmanteau statistic, where\nρ (k) = ∑T t=k+1∆t∆t−k ∑T\nt=1 ∆ 2 t\nis the sample autocorrelation at lag k, and L is the number of autocorrelation lags (chosen to be 20 by default). Under the null hypothesis, the asymptotic distribution of Qm is chi-square with L degrees of freedom, and therefore we can use the p-value as our measure for mean reversion.\nAdditionally, we compare the revenue obtained by applying the following trading strategy to each of the portfolios: buy whenever it reaches a certain lower threshold, and sell whenever it reaches an upper threshold (we assume no transaction cost). We arbitrarily use (−1) and (+1) as lower and upper thresholds in our experiments, but similar results can be shown for any other choice. It is highly likely that dynamic trading strategies such as those presented in [GGR99, JY06] would yield higher revenue. However, the design of a trading strategy is completely orthogonal to our work, and our goal here is simply to compare various portfolios with unified trading strategy."
    }, {
      "heading" : "4.2 Data set",
      "text" : "For the first setting, we consider time series of daily closing rates of all 30 stocks in the Dow Jones. For the second setting, we consider time series of daily closing rates of 8 pairs of stocks. The selection of the pairs relies on their sectoral belonging (Financials, Energy, Telecommunication services, etc.). In both settings, we use data between the dates 01/01/2008 and 01/02/2013, which is taken from Yahoo! Finance."
    }, {
      "heading" : "4.3 Isolating mean reverting portfolio",
      "text" : "In this setting, we test our criterion on the Dow Jones Index (30 stocks) and isolate subsets of stocks that have large amount of mean reversion. This can be done by setting a certain threshold, and including only those stocks with corresponding weights above this threshold in our portfolio. We compare the performance of our criterion for various values of λ (recall that higher value of λ corresponds to more fluctuating portfolios).\nThis setting is aimed at testing the effect of the λ parameter in the proposed criterion. In Figure 1 one can clearly see that the proposed algorithm generates distributions that create mean reverting portfolios, regardless of the value of λ. The significance of the Portmanteau test can be clearly seen in Table 1 for all three values. The supplementary material contains detailed information regarding the proposed portfolios for each of the values of λ."
    }, {
      "heading" : "4.4 Pairs trading",
      "text" : "In this setting, we compare the performance of the proposed algorithm (OSA) to the trading strategy of distributing the weight proportionally to the price of the stocks (this strategy is referred to as “Benchmark”). I.e., assume that the average prices (over certain period of time) of stocks A and B are $10 and $20. Then, we would sell two shares of A against each share of B we buy, or vise versa. We also compare the performance to the offline optimal distribution of weights (this strategy is referred to as “Off-opt”), which follows from our criterion:\nx⋆ = argmin x\n\n\n\nT ∑\nt=m\n( m−1 ∑\ni=0\nxT yt−i\n)2\n− λ · m−1 ∑\ni=0\n( xT yt−i )2\n\n\n\n.\nIn all runs, we use the parameters λ = 2 and m = 5, which were chosen arbitrarily.\nIn Tables 2 and 3 one can clearly see the advantage of the proposed algorithm (OSA) over the offline benchmarks, in the compared parameters — revenue and closeness to pure noise. In Figure 2(b) we demonstrate the performance of the proposed algorithm visually, by applying it on the pair AT&T and Verizon (Telecommunication services)."
    }, {
      "heading" : "5 Conclusion",
      "text" : "Motivated by financial applications, we have considered the setting of online learning with memory, and gave efficient and asymptotically-optimal regret algorithms for this general setting. Application to constructing mean-reverting instruments is explored theoretically and empirically.\nThe following research directions remain: First, whereas the proposed algorithm for the online learning with memory framework is optimal in the number of iterations T , the optimal dependence on the memory parameter m remains unknown. We conjecture that the regret bound of Θ( √ mT ) is tight. Second, it would be interesting to explore the optimal trading strategy in conjunction to a mean reverting portfolio."
    } ],
    "references" : [ {
      "title" : "Statistical arbitrage in the US equities market",
      "author" : [ "Marco Avellaneda", "Jeong-Hyun Lee" ],
      "venue" : "Quantitative Finance,",
      "citeRegEx" : "Avellaneda and Lee.,? \\Q2010\\E",
      "shortCiteRegEx" : "Avellaneda and Lee.",
      "year" : 2010
    }, {
      "title" : "Optimal portfolio selection in nonlinear arbitrage spreads",
      "author" : [ "Hamad Alsayed", "Frank McGroarty" ],
      "venue" : "European Journal of Finance,",
      "citeRegEx" : "Alsayed and McGroarty.,? \\Q2012\\E",
      "shortCiteRegEx" : "Alsayed and McGroarty.",
      "year" : 2012
    }, {
      "title" : "Prediction, learning, and games",
      "author" : [ "N. Cesa-Bianchi", "G. Lugosi" ],
      "venue" : null,
      "citeRegEx" : "Cesa.Bianchi and Lugosi.,? \\Q2006\\E",
      "shortCiteRegEx" : "Cesa.Bianchi and Lugosi.",
      "year" : 2006
    }, {
      "title" : "Identifying small mean-reverting portfolios",
      "author" : [ "Alexandre D’Aspremont" ],
      "venue" : "Quant. Finance,",
      "citeRegEx" : "D.Aspremont.,? \\Q2011\\E",
      "shortCiteRegEx" : "D.Aspremont.",
      "year" : 2011
    }, {
      "title" : "Co-Integration and Error Correction: Representation, Estimation, and Testing",
      "author" : [ "Robert F. Engle", "C.W.J. Granger" ],
      "venue" : null,
      "citeRegEx" : "Engle and Granger.,? \\Q1987\\E",
      "shortCiteRegEx" : "Engle and Granger.",
      "year" : 1987
    }, {
      "title" : "Pairs trading: performance of a relative-value arbitrage",
      "author" : [ "Evan Gatev", "William N. Goetzmann", "K. Geert Rouwenhorst" ],
      "venue" : "Review of Financial Studies,",
      "citeRegEx" : "Gatev et al\\.,? \\Q1999\\E",
      "shortCiteRegEx" : "Gatev et al\\.",
      "year" : 1999
    }, {
      "title" : "Dynamic portfolio selection in arbitrage",
      "author" : [ "J. Jurek", "H. Yang" ],
      "venue" : "SSRN eLibrary,",
      "citeRegEx" : "Jurek and Yang.,? \\Q2006\\E",
      "shortCiteRegEx" : "Jurek and Yang.",
      "year" : 2006
    }, {
      "title" : "On a measure of lack of fit in time series models",
      "author" : [ "G.M. Ljung", "G.E.P. Box" ],
      "venue" : null,
      "citeRegEx" : "Ljung and Box.,? \\Q1978\\E",
      "shortCiteRegEx" : "Ljung and Box.",
      "year" : 1978
    }, {
      "title" : "On sequential strategies for loss functions with memory",
      "author" : [ "N. Merhav", "E. Ordentlich", "G. Seroussi", "M.J. Weinberger" ],
      "venue" : "IEEE Trans. Inf. Theor.,",
      "citeRegEx" : "Merhav et al\\.,? \\Q2006\\E",
      "shortCiteRegEx" : "Merhav et al\\.",
      "year" : 2006
    }, {
      "title" : "Financial Markets and Trading: An Introduction to Market Microstructure and Trading Strategies (Wiley Finance). Wiley, 1 edition",
      "author" : [ "Anatoly B. Schmidt" ],
      "venue" : null,
      "citeRegEx" : "Schmidt.,? \\Q2011\\E",
      "shortCiteRegEx" : "Schmidt.",
      "year" : 2011
    }, {
      "title" : "Pairs Trading: Quantitative Methods and Analysis",
      "author" : [ "G. Vidyamurthy" ],
      "venue" : "Wiley Finance. Wiley,",
      "citeRegEx" : "Vidyamurthy.,? \\Q2011\\E",
      "shortCiteRegEx" : "Vidyamurthy.",
      "year" : 2011
    }, {
      "title" : "Markov decision processes with arbitrary reward processes",
      "author" : [ "Jia Yuan Yu", "Shie Mannor", "Nahum Shimkin" ],
      "venue" : "Math. Oper. Res.,",
      "citeRegEx" : "Yu et al\\.,? \\Q2009\\E",
      "shortCiteRegEx" : "Yu et al\\.",
      "year" : 2009
    }, {
      "title" : "Online convex programming and generalized infinitesimal gradient ascent",
      "author" : [ "M. Zinkevich" ],
      "venue" : "In ICML,",
      "citeRegEx" : "Zinkevich.,? \\Q2003\\E",
      "shortCiteRegEx" : "Zinkevich.",
      "year" : 2003
    } ],
    "referenceMentions" : [ ],
    "year" : 2017,
    "abstractText" : "In many online learning scenarios the loss functions are not memoryless, but rather depend on history. Our first contribution is a complete characterization of sufficient and necessary conditions for learning with memory, accompanied with a novel algorithm for this framework that attains the optimal O( √ T )-regret. This improves previous online learning algorithms that guaranteed O(T ) regret and required more stringent conditions. As an application of the new technique, we address the classical problem in finance of constructing mean reverting portfolios. We design an efficient online learning algorithm for this problem, and provide guarantees for its performance. We complement our theoretical findings with an empirical study that verifies our theoretical results on financial data.",
    "creator" : "LaTeX with hyperref package"
  }
}