{"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "22-May-2017", "title": "LOGAN: Evaluating Privacy Leakage of Generative Models Using Generative Adversarial Networks", "abstract": "Recent advances in machine learning are paving the way for the artificial generation of high quality images and videos. In this paper, we investigate how generating synthetic samples through generative models can lead to information leakage, and, consequently, to privacy breaches affecting individuals' privacy that contribute their personal or sensitive data to train these models. In order to quantitatively measure privacy leakage, we train a Generative Adversarial Network (GAN), which combines a discriminative model and a generative model, to detect overfitting by relying on the discriminator capacity to learn statistical differences in distributions.", "histories": [["v1", "Mon, 22 May 2017 11:05:06 GMT  (1381kb,D)", "https://arxiv.org/abs/1705.07663v1", null], ["v2", "Sat, 12 Aug 2017 10:39:48 GMT  (4156kb,D)", "http://arxiv.org/abs/1705.07663v2", "Compared to v1, this version introduces experiments on a medical dataset as well as general improvements"]], "reviews": [], "SUBJECTS": "cs.CR cs.LG", "authors": ["jamie hayes", "luca melis", "george danezis", "emiliano de cristofaro"], "accepted": false, "id": "1705.07663"}
