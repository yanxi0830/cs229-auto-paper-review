{"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "20-Dec-2013", "title": "Adaptive Seeding for Gaussian Mixture Models", "abstract": "In this paper, we consider simple and fast approaches to initialize the Expectation-Maximization algorithm (EM) for multivariate Gaussian mixture models. We present new initialization methods based on the well-known $K$-means++ algorithm and the Gonzalez algorithm. These methods close the gap between simple uniform initialization techniques and complex methods, that have been specifically designed for Gaussian mixture models and depend on the right choice of hyperparameters. In our evaluation we compare our methods with a commonly used random initialization method, an approach based on agglomerative hierarchical clustering, and a known, plain adaption of the Gonzalez algorithm. Our results indicate that algorithms based on $K$-means++ outperform the other methods.", "histories": [["v1", "Fri, 20 Dec 2013 14:08:48 GMT  (202kb,D)", "http://arxiv.org/abs/1312.5946v1", null], ["v2", "Mon, 1 Aug 2016 08:33:13 GMT  (203kb,D)", "http://arxiv.org/abs/1312.5946v2", "An improved version of this paper (Adaptive Seeding for Gaussian Mixture Models) has been accepted for publication in the Proceedings of the 20th Pacific Asia Conference on Knowledge Discovery and Data Mining (PAKDD) 2016 and is available via the DOI 10.1007/978-3-319-31750-2_24"], ["v3", "Tue, 30 May 2017 07:44:37 GMT  (652kb,D)", "http://arxiv.org/abs/1312.5946v3", "This is a preprint of a paper that has been accepted for publication in the Proceedings of the 20th Pacific Asia Conference on Knowledge Discovery and Data Mining (PAKDD) 2016. The final publication is available at link.springer.com (this http URL24)"]], "reviews": [], "SUBJECTS": "cs.LG", "authors": ["johannes bl\\\"omer", "kathrin bujna"], "accepted": false, "id": "1312.5946"}
