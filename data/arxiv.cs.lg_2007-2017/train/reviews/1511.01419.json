{"conference": "ICML", "VERSION": "v1", "DATE_OF_SUBMISSION": "4-Nov-2015", "title": "Train and Test Tightness of LP Relaxations in Structured Prediction", "abstract": "Structured prediction applications often involve complex inference problems that require the use of approximate methods. Approximations based on linear programming (LP) relaxations have proved particularly successful in this setting, with both theoretical and empirical support. Despite the general intractability of inference, it has been observed that in many real-world applications the LP relaxation is often tight. In this work we propose a theoretical explanation to this striking observation. In particular, we show that learning with LP relaxed inference encourages tightness of training instances. We complement this result with a generalization bound showing that tightness generalizes from train to test data.", "histories": [["v1", "Wed, 4 Nov 2015 18:13:35 GMT  (129kb,D)", "https://arxiv.org/abs/1511.01419v1", null], ["v2", "Fri, 6 Nov 2015 12:04:24 GMT  (128kb,D)", "http://arxiv.org/abs/1511.01419v2", null], ["v3", "Wed, 27 Apr 2016 02:58:33 GMT  (143kb,D)", "http://arxiv.org/abs/1511.01419v3", "To appear in ICML 2016"]], "reviews": [], "SUBJECTS": "stat.ML cs.AI cs.LG", "authors": ["ofer meshi", "mehrdad mahdavi", "adrian weller", "david sontag"], "accepted": true, "id": "1511.01419"}
