{"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "20-May-2016", "title": "TensorLog: A Differentiable Deductive Database", "abstract": "Large knowledge bases (KBs) are useful in many tasks, but it is unclear how to integrate this sort of knowledge into \"deep\" gradient-based learning systems. To address this problem, we describe a probabilistic deductive database, called TensorLog, in which reasoning uses a differentiable process. In TensorLog, each clause in a logical theory is first converted into certain type of factor graph. Then, for each type of query to the factor graph, the message-passing steps required to perform belief propagation (BP) are \"unrolled\" into a function, which is differentiable. We show that these functions can be composed recursively to perform inference in non-trivial logical theories containing multiple interrelated clauses and predicates. Both compilation and inference in TensorLog are efficient: compilation is linear in theory size and proof depth, and inference is linear in database size and the number of message-passing steps used in BP. We also present experimental results with TensorLog and discuss its relationship to other first-order probabilistic logics.", "histories": [["v1", "Fri, 20 May 2016 20:10:46 GMT  (69kb,D)", "https://arxiv.org/abs/1605.06523v1", null], ["v2", "Tue, 19 Jul 2016 21:03:55 GMT  (152kb,D)", "http://arxiv.org/abs/1605.06523v2", null]], "reviews": [], "SUBJECTS": "cs.AI cs.DB cs.LG", "authors": ["william w cohen"], "accepted": false, "id": "1605.06523"}
