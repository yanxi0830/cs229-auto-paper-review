{"conference": "AAAI", "VERSION": "v1", "DATE_OF_SUBMISSION": "31-May-2016", "title": "Attention Correctness in Neural Image Captioning", "abstract": "Attention mechanisms have recently been introduced in deep learning for various tasks in natural language processing and computer vision. But despite their popularity, the \"correctness\" of the implicitly-learned attention maps has only been assessed qualitatively by visualization of several examples. In this paper we focus on evaluating and improving the correctness of attention in neural image captioning models. Specifically, we propose a quantitative evaluation metric for how well the attention maps align with human judgment, using recently released datasets with alignment between regions in images and entities in captions. We then propose novel models with different levels of explicit supervision for learning attention maps during training. The supervision can be strong when alignment between regions and caption entities are available, or weak when only object segments and categories are provided. We show on the popular Flickr30k and COCO datasets that introducing supervision of attention maps during training solidly improves both attention correctness and caption quality.", "histories": [["v1", "Tue, 31 May 2016 10:04:20 GMT  (9583kb,D)", "http://arxiv.org/abs/1605.09553v1", null], ["v2", "Wed, 23 Nov 2016 07:29:46 GMT  (2067kb,D)", "http://arxiv.org/abs/1605.09553v2", "To appear in AAAI-17. Seethis http URLfor supplementary material"]], "reviews": [], "SUBJECTS": "cs.CV cs.CL cs.LG", "authors": ["chenxi liu", "junhua mao", "fei sha", "alan l yuille"], "accepted": true, "id": "1605.09553"}
