{"conference": "NIPS", "VERSION": "v1", "DATE_OF_SUBMISSION": "22-Oct-2013", "title": "Efficient Optimization for Sparse Gaussian Process Regression", "abstract": "We propose an efficient optimization algorithm for selecting a subset of training data to induce sparsity for Gaussian process regression. The algorithm estimates an inducing set and the hyperparameters using a single objective, either the marginal likelihood or a variational free energy. The space and time complexity are linear in training set size, and the algorithm can be applied to large regression problems on discrete or continuous domains. Empirical evaluation shows state-of-art performance in discrete cases and competitive results in the continuous case.", "histories": [["v1", "Tue, 22 Oct 2013 18:44:29 GMT  (217kb,D)", "https://arxiv.org/abs/1310.6007v1", "To appear in NIPS 2013"], ["v2", "Tue, 5 Nov 2013 05:13:30 GMT  (529kb,D)", "http://arxiv.org/abs/1310.6007v2", "To appear in NIPS 2013"], ["v3", "Mon, 11 Nov 2013 08:21:58 GMT  (529kb,D)", "http://arxiv.org/abs/1310.6007v3", "To appear in NIPS 2013"]], "COMMENTS": "To appear in NIPS 2013", "reviews": [], "SUBJECTS": "cs.LG", "authors": ["yanshuai cao", "marcus a brubaker", "david j fleet", "aaron hertzmann"], "accepted": true, "id": "1310.6007"}
