{"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "30-May-2016", "title": "Does Multimodality Help Human and Machine for Translation and Image Captioning?", "abstract": "This paper presents the systems developed by LIUM and CVC for the WMT16 Multimodal Machine Translation challenge. We explored various comparative methods, namely phrase-based systems and attentional recurrent neural networks models trained using monomodal or multimodal data. We also performed a human evaluation in order to estimate the usefulness of multimodal data for human machine translation and image description generation. Our systems obtained the best results for both tasks according to the automatic evaluation metrics BLEU and METEOR.", "histories": [["v1", "Mon, 30 May 2016 11:47:00 GMT  (218kb,D)", "https://arxiv.org/abs/1605.09186v1", "7 pages, 2 figures, Submitted to ACL 2016 First Conference on Machine Translation (WMT16)"], ["v2", "Thu, 2 Jun 2016 13:52:45 GMT  (218kb,D)", "http://arxiv.org/abs/1605.09186v2", "7 pages, 2 figures, Submitted to ACL 2016 First Conference on Machine Translation (WMT16) v2: Added softmax equations for attentions and revised conclusion"], ["v3", "Mon, 13 Jun 2016 15:33:11 GMT  (218kb,D)", "http://arxiv.org/abs/1605.09186v3", "7 pages, 2 figures, Submitted to ACL 2016 First Conference on Machine Translation (WMT16) v2: Added softmax equations for attentions and revised conclusion v3: Small revisions"], ["v4", "Tue, 16 Aug 2016 12:11:29 GMT  (209kb,D)", "http://arxiv.org/abs/1605.09186v4", "7 pages, 2 figures, v4: Small clarification in section 4 title and content"]], "COMMENTS": "7 pages, 2 figures, Submitted to ACL 2016 First Conference on Machine Translation (WMT16)", "reviews": [], "SUBJECTS": "cs.CL cs.LG cs.NE", "authors": ["ozan caglayan", "walid aransa", "yaxing wang", "marc masana", "mercedes garc\\'ia-mart\\'inez", "fethi bougares", "lo\\\"ic barrault", "joost van de weijer"], "accepted": false, "id": "1605.09186"}
