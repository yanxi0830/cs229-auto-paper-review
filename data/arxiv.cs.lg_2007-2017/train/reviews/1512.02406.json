{"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "8-Dec-2015", "title": "Learning Discrete Bayesian Networks from Continuous Data", "abstract": "Real data often contains a mixture of discrete and continuous variables, but many Bayesian network structure learning and inference algorithms assume all random variables are discrete. Continuous variables are often discretized, but the choice of discretization policy has significant impact on the accuracy, speed, and interpretability of the resulting models. This paper introduces a principled Bayesian discretization method for continuous variables in Bayesian networks with quadratic complexity instead of the cubic complexity of other standard techniques. Empirical demonstrations show that the proposed method is superior to the state of the art. In addition, this paper shows how to incorporate existing methods into the structure learning process to discretize all continuous variables and simultaneously learn Bayesian network structures.", "histories": [["v1", "Tue, 8 Dec 2015 11:12:04 GMT  (780kb,D)", "https://arxiv.org/abs/1512.02406v1", "This work has been submitted to Machine Learning (Springer journal)"], ["v2", "Tue, 15 Dec 2015 08:00:55 GMT  (817kb,D)", "http://arxiv.org/abs/1512.02406v2", "This work has been submitted to Machine Learning (Springer journal)"]], "COMMENTS": "This work has been submitted to Machine Learning (Springer journal)", "reviews": [], "SUBJECTS": "cs.AI cs.LG", "authors": ["yi-chun chen", "tim allan wheeler", "mykel john kochenderfer"], "accepted": false, "id": "1512.02406"}
