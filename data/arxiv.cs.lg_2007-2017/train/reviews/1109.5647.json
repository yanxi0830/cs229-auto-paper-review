{"conference": "ICML", "VERSION": "v1", "DATE_OF_SUBMISSION": "26-Sep-2011", "title": "Making Gradient Descent Optimal for Strongly Convex Stochastic Optimization", "abstract": "Stochastic gradient descent (SGD) with averaging is a simple and popular method to solve stochastic optimization problems which arise in machine learning. For strongly convex problems, its convergence rate was known to be at most O(\\log(T)/T). However, recent results showed that using a different algorithm, one can get an optimal O(1/T) rate. This might lead one to believe that SGD is suboptimal, and maybe should even be replaced as a method of choice. In this paper, we investigate the convergence rate of SGD with averaging in a stochastic setting. We show that for smooth problems, the algorithm attains the optimal O(1/T) rate. However, for non-smooth problems, the convergence rate might really be \\Omega(\\log(T)/T), and this is not just an artifact of the analysis. On the flip side, we show that a simple modification of the averaging step suffices to recover the O(1/T) step, and no significant change of the algorithm is necessary.", "histories": [["v1", "Mon, 26 Sep 2011 17:24:52 GMT  (13kb)", "http://arxiv.org/abs/1109.5647v1", null], ["v2", "Wed, 28 Sep 2011 18:43:20 GMT  (42kb,D)", "http://arxiv.org/abs/1109.5647v2", "New version with experimental results and a few other modifications"], ["v3", "Sun, 2 Oct 2011 23:14:46 GMT  (42kb,D)", "http://arxiv.org/abs/1109.5647v3", "Fixed some typos"], ["v4", "Mon, 14 May 2012 19:06:53 GMT  (207kb,D)", "http://arxiv.org/abs/1109.5647v4", "Full version of the ICML 2012 paper"], ["v5", "Tue, 3 Jul 2012 22:06:45 GMT  (199kb,D)", "http://arxiv.org/abs/1109.5647v5", "Full version of the ICML 2012 paper"], ["v6", "Thu, 5 Jul 2012 14:08:50 GMT  (207kb,D)", "http://arxiv.org/abs/1109.5647v6", "Full version of the ICML 2012 paper"], ["v7", "Sun, 9 Dec 2012 21:19:27 GMT  (199kb,D)", "http://arxiv.org/abs/1109.5647v7", "Updated version which fixes a bug in the proof of lemma 1 and modifies the step size choice. As a result, constants are changed throughout the paper"]], "reviews": [], "SUBJECTS": "cs.LG math.OC", "authors": ["alexander rakhlin", "ohad shamir", "karthik sridharan"], "accepted": true, "id": "1109.5647"}
