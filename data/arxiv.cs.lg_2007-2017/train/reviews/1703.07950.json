{"conference": "ICML", "VERSION": "v1", "DATE_OF_SUBMISSION": "23-Mar-2017", "title": "Failures of Gradient-Based Deep Learning", "abstract": "In recent years, Deep Learning has become the go-to solution for a broad range of applications, often outperforming state-of-the-art. However, it is important, for both theoreticians and practitioners, to gain a deeper understanding of the difficulties and limitations associated with common approaches and algorithms. We describe four families of problems for which some of the commonly used existing algorithms fail or suffer significant difficulty. We illustrate the failures through practical experiments, and provide theoretical insights explaining their source, and how they might be remedied.", "histories": [["v1", "Thu, 23 Mar 2017 07:16:37 GMT  (316kb,D)", "http://arxiv.org/abs/1703.07950v1", null], ["v2", "Wed, 26 Apr 2017 05:23:26 GMT  (406kb,D)", "http://arxiv.org/abs/1703.07950v2", null]], "reviews": [], "SUBJECTS": "cs.LG cs.NE stat.ML", "authors": ["shai shalev-shwartz", "ohad shamir", "shaked shammah"], "accepted": true, "id": "1703.07950"}
