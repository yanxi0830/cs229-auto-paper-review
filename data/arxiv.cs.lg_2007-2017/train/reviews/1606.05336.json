{"conference": "ICML", "VERSION": "v1", "DATE_OF_SUBMISSION": "16-Jun-2016", "title": "On the Expressive Power of Deep Neural Networks", "abstract": "We study the expressivity of deep neural networks with random weights. We provide several results, both theoretical and experimental, precisely characterizing their functional properties in terms of the depth and width of the network. In doing so, we illustrate inherent connections between the length of a latent trajectory, local neuron transitions, and network activation patterns. The latter, a notion defined in this paper, is further studied using properties of hyperplane arrangements, which also help precisely characterize the effect of the neural network on the input space. We further show dualities between changes to the latent state and changes to the network weights, and between the number of achievable activation patterns and the number of achievable labellings over input data. We see that the depth of the network affects all of these quantities exponentially, while the width appears at most as a base. These results also suggest that the remaining depth of a neural network is an important determinant of expressivity, supported by experiments on MNIST and CIFAR-10.", "histories": [["v1", "Thu, 16 Jun 2016 19:55:29 GMT  (1051kb,D)", "http://arxiv.org/abs/1606.05336v1", null], ["v2", "Fri, 24 Jun 2016 20:26:47 GMT  (1789kb,D)", "http://arxiv.org/abs/1606.05336v2", null], ["v3", "Wed, 17 Aug 2016 22:21:25 GMT  (2267kb,D)", "http://arxiv.org/abs/1606.05336v3", null], ["v4", "Mon, 3 Oct 2016 15:44:39 GMT  (951kb,D)", "http://arxiv.org/abs/1606.05336v4", null], ["v5", "Wed, 1 Mar 2017 03:00:26 GMT  (3798kb,D)", "http://arxiv.org/abs/1606.05336v5", null], ["v6", "Sun, 18 Jun 2017 13:24:34 GMT  (4061kb,D)", "http://arxiv.org/abs/1606.05336v6", "Accepted to ICML 2017"]], "reviews": [], "SUBJECTS": "stat.ML cs.AI cs.LG", "authors": ["maithra raghu", "ben poole", "jon m kleinberg", "surya ganguli", "jascha sohl-dickstein"], "accepted": true, "id": "1606.05336"}
