{"conference": "NIPS", "VERSION": "v1", "DATE_OF_SUBMISSION": "21-Apr-2013", "title": "Prior-free and prior-dependent regret bounds for Thompson Sampling", "abstract": "We consider the stochastic multi-armed bandit problem with a prior distribution on the reward distributions. We show that for any prior distribution, the Thompson Sampling strategy achieves a Bayesian regret bounded from above by $14 \\sqrt{n K}$. This result is unimprovable in the sense that there exists a prior distribution such that any algorithm has a Bayesian regret bounded from below by $1/20 \\sqrt{n K}$.", "histories": [["v1", "Sun, 21 Apr 2013 15:58:56 GMT  (6kb)", "https://arxiv.org/abs/1304.5758v1", null], ["v2", "Thu, 3 Oct 2013 00:48:53 GMT  (26kb)", "http://arxiv.org/abs/1304.5758v2", "A previous version appeared under the title 'A note on the Bayesian regret of Thompson Sampling with an arbitrary prior'"]], "reviews": [], "SUBJECTS": "stat.ML cs.LG", "authors": ["s\u00e9bastien bubeck", "che-yu liu"], "accepted": true, "id": "1304.5758"}
