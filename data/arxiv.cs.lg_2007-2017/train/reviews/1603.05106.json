{"conference": "ICML", "VERSION": "v1", "DATE_OF_SUBMISSION": "16-Mar-2016", "title": "One-Shot Generalization in Deep Generative Models", "abstract": "Humans have an impressive ability to reason about new concepts and experiences from just a single example. In particular, humans have an ability for one-shot generalization: an ability to encounter a new concept, understand its structure, and then be able to generate compelling alternative variations of the concept. We develop machine learning systems with this important capacity by developing new deep generative models, models that combine the representational power of deep learning with the inferential power of Bayesian reasoning. We develop a class of sequential generative models that are built on the principles of feedback and attention. These two characteristics lead to generative models that are among the state-of-the art in density estimation and image generation. We demonstrate the one-shot generalization ability of our models using three tasks: unconditional sampling, generating new exemplars of a given concept, and generating new exemplars of a family of concepts. In all cases our models are able to generate compelling and diverse samples---having seen new examples just once---providing an important class of general-purpose models for one-shot machine learning.", "histories": [["v1", "Wed, 16 Mar 2016 14:10:00 GMT  (6267kb,D)", "http://arxiv.org/abs/1603.05106v1", null], ["v2", "Wed, 25 May 2016 12:57:19 GMT  (77030kb,D)", "http://arxiv.org/abs/1603.05106v2", "8pgs, 1pg references, 1pg appendix, In Proceedings of the 33rd International Conference on Machine Learning, JMLR: W&amp;CP volume 48, 2016"]], "reviews": [], "SUBJECTS": "stat.ML cs.AI cs.LG", "authors": ["danilo jimenez rezende", "shakir mohamed", "ivo danihelka", "karol gregor", "daan wierstra"], "accepted": true, "id": "1603.05106"}
