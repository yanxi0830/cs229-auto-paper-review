{"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "30-Jun-2011", "title": "A Note on Improved Loss Bounds for Multiple Kernel Learning", "abstract": "The paper \\cite{hs-11} presented a bound on the generalisation error of classifiers learned through multiple kernel learning. The bound has (an improved) \\emph{additive} dependence on the number of kernels (with the same logarithmic dependence on this number). However, parts of the proof were incorrectly presented in that paper. This note remedies this weakness by restating the problem and giving a detailed proof of the Rademacher complexity bound from \\cite{hs-11}.", "histories": [["v1", "Thu, 30 Jun 2011 15:03:58 GMT  (9kb)", "https://arxiv.org/abs/1106.6258v1", "Extended proof"], ["v2", "Mon, 12 May 2014 19:40:40 GMT  (13kb)", "http://arxiv.org/abs/1106.6258v2", "Extended proof"]], "COMMENTS": "Extended proof", "reviews": [], "SUBJECTS": "cs.LG", "authors": ["zakria hussain", "john shawe-taylor", "mario marchand"], "accepted": false, "id": "1106.6258"}
