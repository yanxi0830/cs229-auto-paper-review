{"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "5-May-2016", "title": "Not Just a Black Box: Learning Important Features Through Propagating Activation Differences", "abstract": "The purported \"black box\" nature of neural networks is a barrier to adoption in applications where interpretability is essential. Here we present DeepLIFT (Learning Important FeaTures), an efficient and effective method for computing importance scores in a neural network. DeepLIFT compares the activation of each neuron to its 'reference activation' and assigns contribution scores according to the difference. We apply DeepLIFT to models trained on natural images and genomic data, and show significant advantages over gradient-based methods.", "histories": [["v1", "Thu, 5 May 2016 19:52:32 GMT  (1441kb,D)", "http://arxiv.org/abs/1605.01713v1", "6 pages, 3 figures, a version of this is under review for the ICML Workshop on Human Interpretability in Machine Learning"], ["v2", "Sun, 8 May 2016 21:34:42 GMT  (1441kb,D)", "http://arxiv.org/abs/1605.01713v2", "6 pages, 3 figures, a version of this is under review for the ICML Workshop on Human Interpretability in Machine Learning"], ["v3", "Tue, 11 Apr 2017 15:58:48 GMT  (1624kb,D)", "http://arxiv.org/abs/1605.01713v3", "6 pages, 3 figures, this is an older version; seethis https URLfor the newer version"]], "COMMENTS": "6 pages, 3 figures, a version of this is under review for the ICML Workshop on Human Interpretability in Machine Learning", "reviews": [], "SUBJECTS": "cs.LG cs.CV cs.NE", "authors": ["avanti shrikumar", "peyton greenside", "anna shcherbina", "anshul kundaje"], "accepted": false, "id": "1605.01713"}
