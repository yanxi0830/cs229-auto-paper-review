{"conference": "NIPS", "VERSION": "v1", "DATE_OF_SUBMISSION": "4-Feb-2011", "title": "EigenNet: A Bayesian hybrid of generative and conditional models for sparse learning", "abstract": "It is a challenging task to select correlated variables in a high dimensional space. To address this challenge, the elastic net has been developed and successfully applied to many applications. Despite its great success, the elastic net does not explicitly use correlation information embedded in data to select correlated variables. To overcome this limitation, we present a novel Bayesian hybrid model, the \\eig, that uses the eigenstructures of data to guide variable selection. Specifically, it integrates a sparse conditional classification model with a generative model capturing variable correlations in a principled Bayesian framework. We reparameterize the hybrid model in the eigenspace to avoid overfiting and to increase the computational efficiency of its MCMC sampler. Furthermore, we provide an alternative view to the \\eig from a regularization perspective: the \\eig has an adaptive eigenspace-based composite regularizer, which naturally generalizes the $l_{1/2}$ regularizer used by the elastic net. Experiments on synthetic and real data show that the \\eig significantly outperforms the lasso, the elastic net, and the Bayesian lasso in terms of prediction accuracy, especially when the number of training samples is smaller than the number of variables.", "histories": [["v1", "Fri, 4 Feb 2011 04:40:07 GMT  (104kb,D)", "https://arxiv.org/abs/1102.0836v1", null], ["v2", "Tue, 8 Feb 2011 04:03:50 GMT  (104kb,D)", "http://arxiv.org/abs/1102.0836v2", null]], "reviews": [], "SUBJECTS": "cs.LG", "authors": ["yuan qi", "feng yan 0003"], "accepted": true, "id": "1102.0836"}
