{"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "4-Sep-2015", "title": "Giraffe: Using Deep Reinforcement Learning to Play Chess", "abstract": "This report presents Giraffe, a chess engine that uses self-play to discover all its domain-specific knowledge, with minimal hand-crafted knowledge given by the programmer. Unlike previous attempts using machine learning only to perform parameter-tuning on hand-crafted evaluation functions, Giraffe's learning system also performs automatic feature extraction and pattern recognition. The trained evaluation function performs comparably to the evaluation functions of state-of-the-art chess engines - all of which containing thousands of lines of carefully hand-crafted pattern recognizers, tuned over many years by both computer chess experts and human chess masters. Giraffe is the most successful attempt thus far at using end-to-end machine learning to play chess.", "histories": [["v1", "Fri, 4 Sep 2015 18:21:52 GMT  (393kb,D)", "http://arxiv.org/abs/1509.01549v1", "MSc Dissertation"], ["v2", "Mon, 14 Sep 2015 15:42:35 GMT  (393kb,D)", "http://arxiv.org/abs/1509.01549v2", "MSc Dissertation"]], "COMMENTS": "MSc Dissertation", "reviews": [], "SUBJECTS": "cs.AI cs.LG cs.NE", "authors": ["matthew lai"], "accepted": false, "id": "1509.01549"}
