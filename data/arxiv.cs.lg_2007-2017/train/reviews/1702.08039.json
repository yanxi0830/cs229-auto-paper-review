{"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "26-Feb-2017", "title": "Criticality & Deep Learning I: Generally Weighted Nets", "abstract": "Motivated by the idea that criticality and universality of phase transitions might play a crucial role in achieving and sustaining learning and intelligent behaviour in biological and artificial networks, we analyse a theoretical and a pragmatic experimental set up for critical phenomena in deep learning. On the theoretical side, we use results from statistical physics to carry out critical point calculations in feed-forward/fully connected networks, while on the experimental side we set out to find traces of criticality in deep neural networks. This is our first step in a series of upcoming investigations to map out the relationship between criticality and learning in deep networks.", "histories": [["v1", "Sun, 26 Feb 2017 14:43:38 GMT  (78kb,D)", "http://arxiv.org/abs/1702.08039v1", null], ["v2", "Wed, 31 May 2017 09:38:30 GMT  (78kb,D)", "http://arxiv.org/abs/1702.08039v2", null]], "reviews": [], "SUBJECTS": "cs.AI cs.LG", "authors": ["dan oprisa", "peter toth"], "accepted": false, "id": "1702.08039"}
