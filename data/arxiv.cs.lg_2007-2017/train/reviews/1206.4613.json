{"conference": "ICML", "VERSION": "v1", "DATE_OF_SUBMISSION": "18-Jun-2012", "title": "Near-Optimal BRL using Optimistic Local Transitions", "abstract": "Model-based Bayesian Reinforcement Learning (BRL) allows a found formalization of the problem of acting optimally while facing an unknown environment, i.e., avoiding the exploration-exploitation dilemma. However, algorithms explicitly addressing BRL suffer from such a combinatorial explosion that a large body of work relies on heuristic algorithms. This paper introduces BOLT, a simple and (almost) deterministic heuristic algorithm for BRL which is optimistic about the transition function. We analyze BOLT's sample complexity, and show that under certain parameters, the algorithm is near-optimal in the Bayesian sense with high probability. Then, experimental results highlight the key differences of this method compared to previous work.", "histories": [["v1", "Mon, 18 Jun 2012 15:00:40 GMT  (502kb)", "http://arxiv.org/abs/1206.4613v1", "ICML2012"]], "COMMENTS": "ICML2012", "reviews": [], "SUBJECTS": "cs.AI cs.LG stat.ML", "authors": ["mauricio araya-l\u00f3pez", "olivier buffet", "vincent thomas"], "accepted": true, "id": "1206.4613"}
