{"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "23-Nov-2015", "title": "Modular Autoencoders for Ensemble Feature Extraction", "abstract": "We introduce the concept of a Modular Autoencoder (MAE), capable of learning a set of diverse but complementary representations from unlabelled data, that can later be used for supervised tasks. The learning of the representations is controlled by a trade off parameter, and we show on six benchmark datasets the optimum lies between two extremes: a set of smaller, independent autoencoders each with low capacity, versus a single monolithic encoding, outperforming an appropriate baseline. In the present paper we explore the special case of linear MAE, and derive an SVD-based algorithm which converges several orders of magnitude faster than gradient descent.", "histories": [["v1", "Mon, 23 Nov 2015 17:51:18 GMT  (253kb,D)", "http://arxiv.org/abs/1511.07340v1", "18 pages, 8 figures, to appear in a special issue of The Journal Of Machine Learning Research (vol.44, Dec 2015)"]], "COMMENTS": "18 pages, 8 figures, to appear in a special issue of The Journal Of Machine Learning Research (vol.44, Dec 2015)", "reviews": [], "SUBJECTS": "cs.LG", "authors": ["henry w j reeve", "gavin brown"], "accepted": false, "id": "1511.07340"}
