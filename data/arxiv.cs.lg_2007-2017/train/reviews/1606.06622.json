{"conference": "EMNLP", "VERSION": "v1", "DATE_OF_SUBMISSION": "21-Jun-2016", "title": "Question Relevance in VQA: Identifying Non-Visual And False-Premise Questions", "abstract": "Visual Question Answering (VQA) is the task of answering natural-language questions about images. We introduce the novel problem of determining the relevance of questions to images in VQA. Current VQA models do not reason about whether a question is even related to the given image (e.g. What is the capital of Argentina?) or if it requires information from external resources to answer correctly. This can break the continuity of a dialogue in human-machine interaction. Our approaches for determining relevance are composed of two stages. Given an image and a question, (1) we first determine whether the question is visual or not, (2) if visual, we determine whether the question is relevant to the given image or not. Our approaches, based on LSTM-RNNs, VQA model uncertainty, and caption-question similarity, are able to outperform strong baselines on both relevance tasks. We also present human studies showing that VQA models augmented with such question relevance reasoning are perceived as more intelligent, reasonable, and human-like.", "histories": [["v1", "Tue, 21 Jun 2016 15:38:27 GMT  (997kb,D)", "http://arxiv.org/abs/1606.06622v1", null], ["v2", "Wed, 10 Aug 2016 02:56:00 GMT  (997kb,D)", "http://arxiv.org/abs/1606.06622v2", null], ["v3", "Mon, 26 Sep 2016 15:24:28 GMT  (9709kb,D)", "http://arxiv.org/abs/1606.06622v3", "Conference on Empirical Methods in Natural Language Processing (EMNLP) 2016"]], "reviews": [], "SUBJECTS": "cs.CV cs.CL cs.LG", "authors": ["arijit ray", "gordon christie", "mohit bansal", "dhruv batra", "devi parikh"], "accepted": true, "id": "1606.06622"}
