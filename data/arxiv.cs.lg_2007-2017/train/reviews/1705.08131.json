{"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "23-May-2017", "title": "Black-Box Attacks against RNN based Malware Detection Algorithms", "abstract": "Recent researches have shown that machine learning based malware detection algorithms are very vulnerable under the attacks of adversarial examples. These works mainly focused on the detection algorithms which use features with fixed dimension, while some researchers have begun to use recurrent neural networks (RNN) to detect malware based on sequential API features. This paper proposes a novel algorithm to generate sequential adversarial examples, which are used to attack a RNN based malware detection system. It is usually hard for malicious attackers to know the exact structures and weights of the victim RNN. A substitute RNN is trained to approximate the victim RNN. Then we propose a generative RNN to output sequential adversarial examples from the original sequential malware inputs. Experimental results showed that RNN based malware detection algorithms fail to detect most of the generated malicious adversarial examples, which means the proposed model is able to effectively bypass the detection algorithms.", "histories": [["v1", "Tue, 23 May 2017 08:51:37 GMT  (299kb,D)", "http://arxiv.org/abs/1705.08131v1", null]], "reviews": [], "SUBJECTS": "cs.LG cs.CR", "authors": ["weiwei hu", "ying tan"], "accepted": false, "id": "1705.08131"}
