{"conference": "iclr", "VERSION": "v1", "DATE_OF_SUBMISSION": "20-Nov-2015", "title": "Data Representation and Compression Using Linear-Programming Approximations", "abstract": "We propose `Dracula', a new framework for unsupervised feature selection from sequential data such as text. Dracula learns a dictionary of $n$-grams that efficiently compresses a given corpus and recursively compresses its own dictionary; in effect, Dracula is a `deep' extension of Compressive Feature Learning. It requires solving a binary linear program that may be relaxed to a linear program. Both problems exhibit considerable structure, their solution paths are well behaved, and we identify parameters which control the depth and diversity of the dictionary. We also discuss how to derive features from the compressed documents and show that while certain unregularized linear models are invariant to the structure of the compressed dictionary, this structure may be used to regularize learning. Experiments are presented that demonstrate the efficacy of Dracula's features.", "histories": [["v1", "Fri, 20 Nov 2015 14:21:44 GMT  (56kb,D)", "https://arxiv.org/abs/1511.06606v1", null], ["v2", "Tue, 19 Jan 2016 22:37:58 GMT  (60kb,D)", "http://arxiv.org/abs/1511.06606v2", null], ["v3", "Tue, 23 Feb 2016 23:13:18 GMT  (60kb,D)", "http://arxiv.org/abs/1511.06606v3", null], ["v4", "Mon, 2 May 2016 11:06:31 GMT  (190kb,D)", "http://arxiv.org/abs/1511.06606v4", null], ["v5", "Tue, 3 May 2016 01:02:04 GMT  (190kb,D)", "http://arxiv.org/abs/1511.06606v5", null]], "reviews": [], "SUBJECTS": "cs.LG", "authors": ["hristo s paskov", "john c mitchell", "trevor j hastie"], "accepted": true, "id": "1511.06606"}
