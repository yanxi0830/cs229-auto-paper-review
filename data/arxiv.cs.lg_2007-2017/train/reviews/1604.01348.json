{"conference": "NIPS", "VERSION": "v1", "DATE_OF_SUBMISSION": "5-Apr-2016", "title": "Bayesian Optimization with Exponential Convergence", "abstract": "This paper presents a Bayesian optimization method with exponential convergence without the need of auxiliary optimization and without the delta-cover sampling. Most Bayesian optimization methods require auxiliary optimization: an additional non-convex global optimization problem, which can be time-consuming and hard to implement in practice. Also, the existing Bayesian optimization method with exponential convergence requires access to the delta-cover sampling, which was considered to be impractical. Our approach eliminates both requirements and achieves an exponential convergence rate.", "histories": [["v1", "Tue, 5 Apr 2016 17:53:59 GMT  (1008kb,D)", "http://arxiv.org/abs/1604.01348v1", "In NIPS 2015 (Advances in Neural Information Processing Systems 2015)"]], "COMMENTS": "In NIPS 2015 (Advances in Neural Information Processing Systems 2015)", "reviews": [], "SUBJECTS": "stat.ML cs.LG", "authors": ["kenji kawaguchi", "leslie pack kaelbling", "tom\u00e1s lozano-p\u00e9rez"], "accepted": true, "id": "1604.01348"}
