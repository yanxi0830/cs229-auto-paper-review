{"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "21-Jan-2015", "title": "Extreme Entropy Machines: Robust information theoretic classification", "abstract": "Most of the existing classification methods are aimed at minimization of empirical risk (through some simple point-based error measured with loss function) with added regularization. We propose to approach this problem in a more information theoretic way by investigating applicability of entropy measures as a classification model objective function. We focus on quadratic Renyi's entropy and connected Cauchy-Schwarz Divergence which leads to the construction of Extreme Entropy Machines (EEM).", "histories": [["v1", "Wed, 21 Jan 2015 19:54:26 GMT  (338kb,D)", "http://arxiv.org/abs/1501.05279v1", null]], "reviews": [], "SUBJECTS": "cs.LG", "authors": ["wojciech marian czarnecki", "jacek tabor"], "accepted": false, "id": "1501.05279"}
