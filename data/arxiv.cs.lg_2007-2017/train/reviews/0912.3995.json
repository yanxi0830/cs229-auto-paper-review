{"conference": "ICML", "VERSION": "v1", "DATE_OF_SUBMISSION": "21-Dec-2009", "title": "Gaussian Process Optimization in the Bandit Setting: No Regret and Experimental Design", "abstract": "We consider the problem of optimizing an unknown, noisy function that is expensive to evaluate. We cast this problem as a multiarmed bandit problem where the payoff function is sampled from a Gaussian Process. We resolve an important open problem on deriving regret bounds for this setting. In particular, we analyze an upper confidence algorithm and bound its cumulative regret in terms of the maximal information gain due to sampling, thus connecting Gaussian Process bandits and optimal experimental design. Moreover, we bound the maximal information gain by exploiting known spectral properties of popular classes of kernels and obtain sub-linear regret bounds for our algorithm. In particular, we show that, perhaps surprisingly, the regret bounds for the squared exponential kernel depend only very weakly on the dimensionality of the problem.", "histories": [["v1", "Mon, 21 Dec 2009 00:08:19 GMT  (476kb,D)", "http://arxiv.org/abs/0912.3995v1", "17 pages, 5 figures"], ["v2", "Thu, 4 Feb 2010 06:15:15 GMT  (175kb,D)", "http://arxiv.org/abs/0912.3995v2", null], ["v3", "Sat, 13 Feb 2010 18:24:43 GMT  (175kb,D)", "http://arxiv.org/abs/0912.3995v3", null], ["v4", "Wed, 9 Jun 2010 23:24:13 GMT  (292kb,DS)", "http://arxiv.org/abs/0912.3995v4", null]], "COMMENTS": "17 pages, 5 figures", "reviews": [], "SUBJECTS": "cs.LG", "authors": ["niranjan srinivas", "andreas krause 0001", "sham kakade", "matthias w seeger"], "accepted": true, "id": "0912.3995"}
