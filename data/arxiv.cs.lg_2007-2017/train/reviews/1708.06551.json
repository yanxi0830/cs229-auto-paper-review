{"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "22-Aug-2017", "title": "Reinforcement Learning in POMDPs with Memoryless Options and Option-Observation Initiation Sets", "abstract": "Most real-world reinforcement learning problems have a hierarchical nature, and often exhibit some degree of partial observability. While hierarchy and partial observability are usually tackled separately, for instance by combining recurrent neural networks and options, we show that addressing both problems simultaneously is simpler and more efficient in many cases. More specifically, we make the initiation set of options conditional on the previously-executed option, and show that options with such Option-Observation Initiation Sets (OOIs) are at least as expressive as Finite State Controllers (FSCs), a state-of-the-art approach for learning in POMDPs. In contrast to other hierarchical methods in partially observable environments, OOIs are easy to design based on an intuitive description of the task, lead to explainable policies and keep the top-level and option policies memoryless. Our experiments show that OOIs allow agents to learn optimal policies in challenging POMDPs, outperforming an human-provided policy in our robotic experiment, while learning much faster than a recurrent neural network over options.", "histories": [["v1", "Tue, 22 Aug 2017 09:51:18 GMT  (1071kb,D)", "http://arxiv.org/abs/1708.06551v1", null], ["v2", "Tue, 12 Sep 2017 08:34:04 GMT  (1099kb,D)", "http://arxiv.org/abs/1708.06551v2", null]], "reviews": [], "SUBJECTS": "cs.AI cs.LG", "authors": ["denis steckelmacher", "diederik m roijers", "anna harutyunyan", "peter vrancx", "h\\'el\\`ene plisnier", "ann now\\'e"], "accepted": false, "id": "1708.06551"}
