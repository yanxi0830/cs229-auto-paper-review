{"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "10-Oct-2016", "title": "Personalizing a Dialogue System with Transfer Reinforcement Learning", "abstract": "It is difficult to train a personalized task-oriented dialogue system because the data collected from each individual is often insufficient. Personalized dialogue systems trained on a small dataset can overfit and make it difficult to adapt to different user needs. One way to solve this problem is to consider a collection of multiple users' data as a source domain and an individual user's data as a target domain, and to perform a transfer learning from the source to the target domain. By following this idea, we propose \"PETAL\"(PErsonalized Task diALogue), a transfer-learning framework based on POMDP to learn a personalized dialogue system. The system first learns common dialogue knowledge from the source domain and then adapts this knowledge to the target user. This framework can avoid the negative transfer problem by considering differences between source and target users. The policy in the personalized POMDP can learn to choose different actions appropriately for different users. Experimental results on a real-world coffee-shopping data and simulation data show that our personalized dialogue system can choose different optimal actions for different users, and thus effectively improve the dialogue quality under the personalized setting.", "histories": [["v1", "Mon, 10 Oct 2016 12:51:05 GMT  (139kb)", "http://arxiv.org/abs/1610.02891v1", null], ["v2", "Mon, 17 Oct 2016 14:08:42 GMT  (140kb)", "http://arxiv.org/abs/1610.02891v2", null], ["v3", "Fri, 26 May 2017 14:05:07 GMT  (91kb,D)", "http://arxiv.org/abs/1610.02891v3", null]], "reviews": [], "SUBJECTS": "cs.AI cs.CL cs.LG", "authors": ["kaixiang mo", "shuangyin li", "yu zhang", "jiajun li", "qiang yang"], "accepted": false, "id": "1610.02891"}
