{"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "26-Mar-2017", "title": "Learned Multi-Patch Similarity", "abstract": "Estimating a depth map from multiple views of a scene is a fundamental task in computer vision. As soon as more than two viewpoints are available, one faces the very basic question how to measure similarity across &gt;2 image patches. Surprisingly, no direct solution exists, instead it is common to fall back to more or less robust averaging of two-view similarities. Encouraged by the success of machine learning, and in particular convolutional neural networks, we propose to learn a matching function which directly maps multiple image patches to a scalar similarity score. Experiments on several multi-view datasets demonstrate that this approach has advantages over methods based on pairwise patch similarity.", "histories": [["v1", "Sun, 26 Mar 2017 16:17:55 GMT  (3408kb,D)", "https://arxiv.org/abs/1703.08836v1", null], ["v2", "Mon, 21 Aug 2017 13:10:39 GMT  (2669kb,D)", "http://arxiv.org/abs/1703.08836v2", "10 pages, 7 figures, Accepted at ICCV 2017"]], "reviews": [], "SUBJECTS": "cs.CV cs.LG", "authors": ["wilfried hartmann", "silvano galliani", "michal havlena", "luc van gool", "konrad schindler"], "accepted": false, "id": "1703.08836"}
