{"conference": "ICML", "VERSION": "v1", "DATE_OF_SUBMISSION": "16-Mar-2016", "title": "Understanding and Improving Convolutional Neural Networks via Concatenated Rectified Linear Units", "abstract": "Recently, convolutional neural networks (CNNs) have been used as a powerful tool to solve many problems of machine learning and computer vision. In this paper, we aim to provide insight on the property of convolutional neural networks, as well as a generic method to improve the performance of many CNN architectures. Specifically, we first examine existing CNN models and observe an intriguing property that the filters in the lower layers form pairs (i.e., filters with opposite phase). Inspired by our observation, we propose a novel, simple yet effective activation scheme called concatenated ReLU (CRelu) and theoretically analyze its reconstruction property in CNNs. We integrate CRelu into several state-of-the-art CNN architectures and demonstrate improvement in their recognition performance on CIFAR-10/100 and ImageNet datasets with fewer trainable parameters. Our results suggest that better understanding of the properties of CNNs can lead to significant performance improvement with a simple modification.", "histories": [["v1", "Wed, 16 Mar 2016 18:17:36 GMT  (2926kb,D)", "http://arxiv.org/abs/1603.05201v1", null], ["v2", "Tue, 19 Jul 2016 05:18:36 GMT  (2962kb,D)", "http://arxiv.org/abs/1603.05201v2", "ICML 2016"]], "reviews": [], "SUBJECTS": "cs.LG cs.CV", "authors": ["wenling shang", "kihyuk sohn", "diogo almeida", "honglak lee"], "accepted": true, "id": "1603.05201"}
