{"conference": "NIPS", "VERSION": "v1", "DATE_OF_SUBMISSION": "23-May-2016", "title": "Deep Learning without Poor Local Minima", "abstract": "In this paper, we prove a conjecture published in 1989 and also partially address an open problem announced at the Conference on Learning Theory (COLT) 2015. For an expected loss function of a deep nonlinear neural network, we prove the following statements under the independence assumption adopted from recent work: 1) the function is non-convex and non-concave, 2) every local minimum is a global minimum, 3) every critical point that is not a global minimum is a saddle point, and 4) the property of saddle points differs for shallow networks (with three layers) and deeper networks (with more than three layers). Moreover, we prove that the same four statements hold for deep linear neural networks with any depth, any widths and no unrealistic assumptions. As a result, we present an instance, for which we can answer to the following question: how difficult to directly train a deep model in theory? It is more difficult than the classical machine learning models (because of the non-convexity), but not too difficult (because of the nonexistence of poor local minima and the property of the saddle points). We note that even though we have advanced the theoretical foundations of deep learning, there is still a gap between theory and practice.", "histories": [["v1", "Mon, 23 May 2016 17:34:20 GMT  (33kb,D)", "http://arxiv.org/abs/1605.07110v1", null], ["v2", "Mon, 22 Aug 2016 14:26:22 GMT  (39kb,D)", "http://arxiv.org/abs/1605.07110v2", "In NIPS 2016. Selected for NIPS oral presentation (top 2% submissions). ---- This accepted version's contents remain the same as v1 (presentation was improved by following the reviewers' suggestions)"], ["v3", "Tue, 27 Dec 2016 22:47:50 GMT  (39kb)", "http://arxiv.org/abs/1605.07110v3", "In NIPS 2016. Selected for NIPS oral presentation (top 2% submissions). ---- The final NIPS 2016 version: the results remain the same"]], "reviews": [], "SUBJECTS": "stat.ML cs.LG math.OC", "authors": ["kenji kawaguchi"], "accepted": true, "id": "1605.07110"}
