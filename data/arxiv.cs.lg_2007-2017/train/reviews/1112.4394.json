{"conference": "NIPS", "VERSION": "v1", "DATE_OF_SUBMISSION": "19-Dec-2011", "title": "Additive Gaussian Processes", "abstract": "We introduce a Gaussian process model of functions which are additive. An additive function is one which decomposes into a sum of low-dimensional functions, each depending on only a subset of the input variables. Additive GPs generalize both Generalized Additive Models, and the standard GP models which use squared-exponential kernels. Hyperparameter learning in this model can be seen as Bayesian Hierarchical Kernel Learning (HKL). We introduce an expressive but tractable parameterization of the kernel function, which allows efficient evaluation of all input interaction terms, whose number is exponential in the input dimension. The additional structure discoverable by this model results in increased interpretability, as well as state-of-the-art predictive power in regression tasks.", "histories": [["v1", "Mon, 19 Dec 2011 16:22:09 GMT  (3861kb,D)", "http://arxiv.org/abs/1112.4394v1", "Appearing in Neural Information Processing Systems 2011"]], "COMMENTS": "Appearing in Neural Information Processing Systems 2011", "reviews": [], "SUBJECTS": "stat.ML cs.LG", "authors": ["david k duvenaud", "hannes nickisch", "carl edward rasmussen"], "accepted": true, "id": "1112.4394"}
