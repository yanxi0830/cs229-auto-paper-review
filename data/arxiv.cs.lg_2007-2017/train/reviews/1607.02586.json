{"conference": "NIPS", "VERSION": "v1", "DATE_OF_SUBMISSION": "9-Jul-2016", "title": "Visual Dynamics: Probabilistic Future Frame Synthesis via Cross Convolutional Networks", "abstract": "We study the problem of synthesizing a number of likely future frames from a single input image. In contrast to traditional methods, which have tackled this problem in a deterministic or non-parametric way, we propose a novel approach that models future frames in a probabilistic manner. Our probabilistic model makes it possible for us to sample and synthesize many possible future frames from a single input image. Future frame synthesis is challenging, as it involves low- and high-level image and motion understanding. We propose a novel network structure, namely a Cross Convolutional Network to aid in synthesizing future frames; this network structure encodes image and motion information as feature maps and convolutional kernels, respectively. In experiments, our model performs well on synthetic data, such as 2D shapes and animated game sprites, as well as on real-wold videos. We also show that our model can be applied to tasks such as visual analogy-making, and present an analysis of the learned network representations.", "histories": [["v1", "Sat, 9 Jul 2016 08:41:40 GMT  (767kb,D)", "http://arxiv.org/abs/1607.02586v1", "The first two authors contributed equally to this work"]], "COMMENTS": "The first two authors contributed equally to this work", "reviews": [], "SUBJECTS": "cs.CV cs.LG", "authors": ["tianfan xue", "jiajun wu 0001", "katherine l bouman", "bill freeman"], "accepted": true, "id": "1607.02586"}
