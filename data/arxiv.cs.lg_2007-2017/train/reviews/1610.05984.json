{"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "19-Oct-2016", "title": "Particle Swarm Optimization for Generating Interpretable Fuzzy Reinforcement Learning Policies", "abstract": "Fuzzy controllers are known to serve as efficient and interpretable system controllers for continuous state and action spaces. To date these controllers have been constructed by hand, or automatically trained either on expert generated problem specific cost functions or by incorporating detailed knowledge about the optimal control strategy. Both requirements for automatic training processes are not given in the majority of real world reinforcement learning (RL) problems. We introduce a new particle swarm reinforcement learning (PSRL) approach which is capable of constructing fuzzy RL policies solely by training parameters on world models produced from randomly generated samples of the real system. This approach relates self-organizing fuzzy controllers to model-based RL for the first time. PSRL can be used straightforward on any RL problem, which is demonstrated on three standard RL benchmarks, mountain car, cart pole balancing and cart pole swing up. Our experiments yielded high performing and well interpretable fuzzy policies.", "histories": [["v1", "Wed, 19 Oct 2016 12:41:52 GMT  (612kb,D)", "http://arxiv.org/abs/1610.05984v1", null], ["v2", "Fri, 7 Apr 2017 07:22:21 GMT  (651kb,D)", "http://arxiv.org/abs/1610.05984v2", null], ["v3", "Fri, 5 May 2017 09:01:41 GMT  (651kb,D)", "http://arxiv.org/abs/1610.05984v3", null], ["v4", "Thu, 29 Jun 2017 07:13:09 GMT  (650kb,D)", "http://arxiv.org/abs/1610.05984v4", null], ["v5", "Tue, 15 Aug 2017 21:41:03 GMT  (687kb,D)", "http://arxiv.org/abs/1610.05984v5", null]], "reviews": [], "SUBJECTS": "cs.NE cs.AI cs.LG cs.SY", "authors": ["daniel hein", "alexander hentschel", "thomas runkler", "steffen udluft"], "accepted": false, "id": "1610.05984"}
