{"conference": "iclr", "VERSION": "v1", "DATE_OF_SUBMISSION": "9-Nov-2016", "title": "Lie-Access Neural Turing Machines", "abstract": "Recent work has demonstrated the effectiveness of employing explicit external memory structures in conjunction with deep neural models for algorithmic learning (Graves et al. 2014; Weston et al. 2014). These models utilize differentiable versions of traditional discrete memory-access structures (random access, stacks, tapes) to provide the variable-length storage necessary for computational tasks. In this work, we propose an alternative model, Lie-access memory, that is explicitly designed for the neural setting. In this paradigm, memory is accessed using a continuous head in a key-space manifold. The head is moved via Lie group actions, such as shifts or rotations, generated by a controller, and soft memory access is performed by considering the distance to keys associated with each memory. We argue that Lie groups provide a natural generalization of discrete memory structures, such as Turing machines, as they provide inverse and identity operators while maintain differentiability. To experiment with this approach, we implement several simplified Lie-access neural Turing machine (LANTM) with different Lie groups. We find that this approach is able to perform well on a range of algorithmic tasks.", "histories": [["v1", "Wed, 9 Nov 2016 08:51:54 GMT  (870kb,D)", "http://arxiv.org/abs/1611.02854v1", "Submitted to ICLR. Rewrite and improvement ofthis https URL"], ["v2", "Sun, 5 Mar 2017 21:03:22 GMT  (1046kb,D)", "http://arxiv.org/abs/1611.02854v2", "Published at ICLR. Rewrite and improvement ofarXiv:1602.08671"]], "COMMENTS": "Submitted to ICLR. Rewrite and improvement ofthis https URL", "reviews": [], "SUBJECTS": "cs.NE cs.LG", "authors": ["greg yang", "alexander m rush"], "accepted": true, "id": "1611.02854"}
