{"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "8-Mar-2017", "title": "A Manifold Approach to Learning Mutually Orthogonal Subspaces", "abstract": "Although many machine learning algorithms involve learning subspaces with particular characteristics, optimizing a parameter matrix that is constrained to represent a subspace can be challenging. One solution is to use Riemannian optimization methods that enforce such constraints implicitly, leveraging the fact that the feasible parameter values form a manifold. While Riemannian methods exist for some specific problems, such as learning a single subspace, there are more general subspace constraints that offer additional flexibility when setting up an optimization problem, but have not been formulated as a manifold.", "histories": [["v1", "Wed, 8 Mar 2017 19:08:28 GMT  (564kb,D)", "http://arxiv.org/abs/1703.02992v1", "9 pages, 3 Figures"]], "COMMENTS": "9 pages, 3 Figures", "reviews": [], "SUBJECTS": "cs.LG", "authors": ["stephen giguere", "francisco garcia", "sridhar mahadevan"], "accepted": false, "id": "1703.02992"}
