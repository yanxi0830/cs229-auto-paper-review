{"conference": "NIPS", "VERSION": "v1", "DATE_OF_SUBMISSION": "1-Nov-2015", "title": "Large-scale probabilistic predictors with and without guarantees of validity", "abstract": "This paper studies theoretically and empirically a method of turning machine-learning algorithms into probabilistic predictors that automatically enjoys a property of validity (perfect calibration) and is computationally efficient. The price to pay for perfect calibration is that these probabilistic predictors produce imprecise (in practice, almost precise for large data sets) probabilities. When these imprecise probabilities are merged into precise probabilities, the resulting predictors, while losing the theoretical property of perfect calibration, are consistently more accurate than the existing methods in empirical studies.", "histories": [["v1", "Sun, 1 Nov 2015 07:16:04 GMT  (118kb,D)", "https://arxiv.org/abs/1511.00213v1", "26 pages, 5 figures, to appear in Advances in Neural Information Processing Systems 28 (NIPS 2015)"], ["v2", "Fri, 13 Nov 2015 09:28:34 GMT  (193kb,D)", "http://arxiv.org/abs/1511.00213v2", "38 pages, 14 figures, to appear in Advances in Neural Information Processing Systems 28 (NIPS 2015). As compared with the previous version (v1), the MATLAB code (the 5 files with extension .m) and results of new empirical studies have been added"]], "COMMENTS": "26 pages, 5 figures, to appear in Advances in Neural Information Processing Systems 28 (NIPS 2015)", "reviews": [], "SUBJECTS": "cs.LG", "authors": ["vladimir vovk", "ivan petej", "valentina fedorova"], "accepted": true, "id": "1511.00213"}
