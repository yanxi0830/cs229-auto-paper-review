{"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "10-Jan-2013", "title": "Error Correction in Learning using SVMs", "abstract": "This paper is concerned with learning binary classifiers under adversarial label-noise. We introduce the problem of error-correction in learning where the goal is to recover the original clean data from a label-manipulated version of it, given (i) no constraints on the adversary other than an upper-bound on the number of errors, and (ii) some regularity properties for the original data. We present a simple and practical error-correction algorithm called SubSVMs that learns individual SVMs on several small-size (log-size), class-balanced, random subsets of the data and then reclassifies the training points using a majority vote. Our analysis reveals the need for the two main ingredients of SubSVMs, namely class-balanced sampling and subsampled bagging. Experimental results on synthetic as well as benchmark UCI data demonstrate the effectiveness of our approach. In addition to noise-tolerance, log-size subsampled bagging also yields significant run-time benefits over standard SVMs.", "histories": [["v1", "Thu, 10 Jan 2013 00:47:21 GMT  (608kb,D)", "http://arxiv.org/abs/1301.2012v1", null]], "reviews": [], "SUBJECTS": "cs.LG", "authors": ["srivatsan laxman", "sushil mittal", "ramarathnam venkatesan"], "accepted": false, "id": "1301.2012"}
