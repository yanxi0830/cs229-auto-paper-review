{"conference": "iclr", "VERSION": "v1", "DATE_OF_SUBMISSION": "20-Dec-2014", "title": "An Analysis of Unsupervised Pre-training in Light of Recent Advances", "abstract": "Convolutional neural networks perform well on object recognition because of a number of recent advances: rectified linear units (ReLUs), data augmentation, dropout, and large labelled datasets. Unsupervised data has been proposed as another way to improve performance. Unfortunately, unsupervised pre-training is not used by state-of-the-art methods leading to the following question: Is unsupervised pre-training still useful given recent advances? If so, when? We answer this in three parts: we 1) develop a unsupervised method that incorporates ReLUs and recent unsupervised regularization techniques, 2) analyze the benefits of unsupervised pre-training compared to data augmentation and dropout on CIFAR-10 while varying the ratio of unsupervised to supervised samples, 3) verify our findings on STL-10. We discover unsupervised pre-training, as expected, helps when the ratio of unsupervised to supervised samples is high, and surprisingly, hurts when the ratio is low. We also use unsupervised pre-training with additional color augmentation to achieve near state-of-the-art performance on STL-10.", "histories": [["v1", "Sat, 20 Dec 2014 04:20:55 GMT  (1040kb,D)", "https://arxiv.org/abs/1412.6597v1", "9 pages, 3 figures"], ["v2", "Tue, 27 Jan 2015 22:03:40 GMT  (1039kb,D)", "http://arxiv.org/abs/1412.6597v2", "9 pages, 3 figures We made two changes: + 2 of our 32 experiments in the CIFAR10 analysis section were misreported. Those are corrected in Table 2 and Figure 2. + Reported full results of STL10 experiments with color augmentation in Table 3"], ["v3", "Mon, 2 Mar 2015 21:05:34 GMT  (1046kb,D)", "http://arxiv.org/abs/1412.6597v3", "9 pages, 3 figures We made two changes: + 2 of our 32 experiments in the CIFAR10 analysis section were misreported. Those are corrected in Table 2 and Figure 2. + Reported full results of STL10 experiments with color augmentation in Table 3. In Version 3, we made minor changes to address reviewer questions, and added links to the code and experiments"], ["v4", "Fri, 10 Apr 2015 21:26:31 GMT  (1046kb,D)", "http://arxiv.org/abs/1412.6597v4", "Accepted as a workshop contribution to ICLR 2015"]], "COMMENTS": "9 pages, 3 figures", "reviews": [], "SUBJECTS": "cs.CV cs.LG cs.NE", "authors": ["tom le paine", "pooya khorrami", "wei han", "thomas s huang"], "accepted": true, "id": "1412.6597"}
