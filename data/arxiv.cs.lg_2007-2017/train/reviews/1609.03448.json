{"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "12-Sep-2016", "title": "Learning Sparse Graphs Under Smoothness Prior", "abstract": "In this paper, we are interested in learning the underlying graph structure behind training data. Solving this basic problem is essential to carry out any graph signal processing or machine learning task. To realize this, we assume that the data is smooth with respect to the graph topology, and we parameterize the graph topology using an edge sampling function. That is, the graph Laplacian is expressed in terms of a sparse edge selection vector, which provides an explicit handle to control the sparsity level of the graph. We solve the sparse graph learning problem given some training data in both the noiseless and noisy settings. Given the true smooth data, the posed sparse graph learning problem can be solved optimally and is based on simple rank ordering. Given the noisy data, we show that the joint sparse graph learning and denoising problem can be simplified to designing only the sparse edge selection vector, which can be solved using convex optimization.", "histories": [["v1", "Mon, 12 Sep 2016 15:31:20 GMT  (852kb)", "http://arxiv.org/abs/1609.03448v1", "ICASSP 2017 conference paper"]], "COMMENTS": "ICASSP 2017 conference paper", "reviews": [], "SUBJECTS": "cs.LG", "authors": ["sundeep prabhakar chepuri", "sijia liu", "geert leus", "alfred o hero iii"], "accepted": false, "id": "1609.03448"}
