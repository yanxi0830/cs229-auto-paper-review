{"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "4-Apr-2016", "title": "Recurrent Neural Networks for Polyphonic Sound Event Detection in Real Life Recordings", "abstract": "In this paper we present an approach to polyphonic sound event detection in real life recordings based on bi-directional long short term memory (BLSTM) recurrent neural networks (RNNs). A single multilabel BLSTM RNN is trained to map acoustic features of a mixture signal consisting of sounds from multiple classes, to binary activity indicators of each event class. Our method is tested on a large database of real-life recordings, with 61 classes (e.g. music, car, speech) from 10 different everyday contexts. The proposed method outperforms previous approaches by a large margin, and the results are further improved using data augmentation techniques. Overall, our system reports an average F1-score of 65.5% on 1 second blocks and 64.7% on single frames, a relative improvement over previous state-of-the-art approach of 6.8% and 15.1% respectively.", "histories": [["v1", "Mon, 4 Apr 2016 13:54:09 GMT  (1918kb,D)", "http://arxiv.org/abs/1604.00861v1", "To appean in Proceedings of IEEE ICASSP 2016"]], "COMMENTS": "To appean in Proceedings of IEEE ICASSP 2016", "reviews": [], "SUBJECTS": "cs.SD cs.LG cs.NE", "authors": ["giambattista parascandolo", "heikki huttunen", "tuomas virtanen"], "accepted": false, "id": "1604.00861"}
