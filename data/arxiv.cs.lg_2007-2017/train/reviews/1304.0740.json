{"conference": "ICML", "VERSION": "v1", "DATE_OF_SUBMISSION": "2-Apr-2013", "title": "O(logT) Projections for Stochastic Optimization of Smooth and Strongly Convex Functions", "abstract": "Traditional algorithms for stochastic optimization require projecting the solution at each iteration into a given domain to ensure its feasibility. When facing complex domains, such as positive semi-definite cones, the projection operation can be expensive, leading to a high computational cost per iteration. In this paper, we present a novel algorithm that aims to reduce the number of projections for stochastic optimization. The proposed algorithm combines the strength of several recent developments in stochastic optimization, including mini-batch, extra-gradient, and epoch gradient descent, in order to effectively explore the smoothness and strong convexity. We show, both in expectation and with a high probability, that when the objective function is both smooth and strongly convex, the proposed algorithm achieves the optimal $O(1/T)$ rate of convergence with only $O(\\log T)$ projections. Our empirical study verifies the theoretical result.", "histories": [["v1", "Tue, 2 Apr 2013 19:11:23 GMT  (37kb)", "http://arxiv.org/abs/1304.0740v1", null]], "reviews": [], "SUBJECTS": "cs.LG", "authors": ["lijun zhang 0005", "tianbao yang", "rong jin", "xiaofei he"], "accepted": true, "id": "1304.0740"}
