{"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "3-Jun-2016", "title": "Dependency Parsing as Head Selection", "abstract": "Conventional dependency parsers rely on a statistical model and a transition system or graph algorithm to enforce tree-structured outputs during training and inference. In this work we formalize dependency parsing as the problem of selecting the head (a.k.a. parent) of each word in a sentence. Our model which we call DeNSe (as shorthand for Dependency Neural Selection) employs bidirectional recurrent neural networks for the head selection task. Without enforcing any structural constraints during training, DeNSe generates (at inference time) trees for the overwhelming majority of sentences (95% on an English dataset), while remaining non-tree outputs can be adjusted with a maximum spanning tree algorithm. We evaluate DeNSe on four languages (English, Chinese, Czech, and German) with varying degrees of non-projectivity. Despite the simplicity of our approach, experiments show that the resulting parsers are on par with or outperform the state of the art.", "histories": [["v1", "Fri, 3 Jun 2016 21:27:03 GMT  (69kb,D)", "http://arxiv.org/abs/1606.01280v1", null], ["v2", "Mon, 20 Jun 2016 20:25:02 GMT  (70kb,D)", "http://arxiv.org/abs/1606.01280v2", null], ["v3", "Fri, 2 Dec 2016 22:22:10 GMT  (60kb,D)", "http://arxiv.org/abs/1606.01280v3", "to appear in EACL 2017"], ["v4", "Thu, 22 Dec 2016 15:28:34 GMT  (61kb,D)", "http://arxiv.org/abs/1606.01280v4", "to appear in EACL 2017; Our code is available atthis http URL"]], "reviews": [], "SUBJECTS": "cs.CL cs.LG", "authors": ["xingxing zhang", "jianpeng cheng", "mirella lapata"], "accepted": false, "id": "1606.01280"}
