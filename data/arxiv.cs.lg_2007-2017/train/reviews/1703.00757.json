{"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "2-Mar-2017", "title": "Predicting Rankings of Software Verification Competitions", "abstract": "Software verification competitions, such as the annual SV-COMP, evaluate software verification tools with respect to their effectivity and efficiency. Typically, the outcome of a competition is a (possibly category-specific) ranking of the tools. For many applications, such as building portfolio solvers, it would be desirable to have an idea of the (relative) performance of verification tools on a given verification task beforehand, i.e., prior to actually running all tools on the task.", "histories": [["v1", "Thu, 2 Mar 2017 12:28:12 GMT  (143kb,D)", "http://arxiv.org/abs/1703.00757v1", null]], "reviews": [], "SUBJECTS": "cs.LG cs.SE", "authors": ["mike czech", "eyke h\\\"ullermeier", "marie-christine jakobs", "heike wehrheim"], "accepted": false, "id": "1703.00757"}
