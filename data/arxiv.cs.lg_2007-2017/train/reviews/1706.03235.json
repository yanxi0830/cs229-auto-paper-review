{"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "10-Jun-2017", "title": "ACCNet: Actor-Coordinator-Critic Net for \"Learning-to-Communicate\" with Deep Multi-agent Reinforcement Learning", "abstract": "Communication is a critical factor for the big multi-agent world to stay organized and productive. Typically, most previous multi-agent \"learning-to-communicate\" studies try to predefine the communication protocols or use technologies such as tabular reinforcement learning and evolutionary algorithm, which can not generalize to changing environment or large collection of agents.", "histories": [["v1", "Sat, 10 Jun 2017 13:50:23 GMT  (1157kb,D)", "https://arxiv.org/abs/1706.03235v1", "Actor-Critic Method for Multi-agent Learning-to-Communicate based on Deep Reinforcement Learning, It is suitable for both continuous and discrete action space environments"], ["v2", "Tue, 13 Jun 2017 02:00:14 GMT  (1158kb,D)", "http://arxiv.org/abs/1706.03235v2", "Version-2 of original submission. Actor-Critic Method for Multi-agent Learning-to-Communicate based on Deep Reinforcement Learning, It is suitable for both continuous and discrete action space environments"], ["v3", "Sun, 29 Oct 2017 05:09:39 GMT  (2089kb,D)", "http://arxiv.org/abs/1706.03235v3", "V3 of original submission. Actor-Critic Method for Multi-agent Learning-to-Communicate based on Deep Reinforcement Learning, It is suitable for both continuous and discrete action space environments"]], "COMMENTS": "Actor-Critic Method for Multi-agent Learning-to-Communicate based on Deep Reinforcement Learning, It is suitable for both continuous and discrete action space environments", "reviews": [], "SUBJECTS": "cs.AI cs.LG", "authors": ["hangyu mao", "zhibo gong", "yan ni", "xiangyu liu", "quanbin wang", "weichen ke", "chao ma", "yiping song", "zhen xiao"], "accepted": false, "id": "1706.03235"}
