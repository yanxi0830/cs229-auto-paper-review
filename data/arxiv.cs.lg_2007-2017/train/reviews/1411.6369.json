{"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "24-Nov-2014", "title": "Scale-Invariant Convolutional Neural Networks", "abstract": "Even though convolutional neural networks (CNN) has achieved near-human performance in various computer vision tasks, its ability to tolerate scale variations is limited. The popular practise is making the model bigger first, and then train it with data augmentation using extensive scale-jittering. In this paper, we propose a scaleinvariant convolutional neural network (SiCNN), a modeldesigned to incorporate multi-scale feature exaction and classification into the network structure. SiCNN uses a multi-column architecture, with each column focusing on a particular scale. Unlike previous multi-column strategies, these columns share the same set of filter parameters by a scale transformation among them. This design deals with scale variation without blowing up the model size. Experimental results show that SiCNN detects features at various scales, and the classification result exhibits strong robustness against object scale variations.", "histories": [["v1", "Mon, 24 Nov 2014 07:28:21 GMT  (789kb,D)", "http://arxiv.org/abs/1411.6369v1", "This paper is submitted for CVPR2015"]], "COMMENTS": "This paper is submitted for CVPR2015", "reviews": [], "SUBJECTS": "cs.CV cs.LG cs.NE", "authors": ["yichong xu", "tianjun xiao", "jiaxing zhang", "kuiyuan yang", "zheng zhang"], "accepted": false, "id": "1411.6369"}
