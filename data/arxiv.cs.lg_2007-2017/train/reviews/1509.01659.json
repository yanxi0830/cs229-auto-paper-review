{"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "5-Sep-2015", "title": "Gravitational Clustering", "abstract": "The downfall of many supervised learning algorithms, such as neural networks, is the inherent need for a large amount of training data. Although there is a lot of buzz about big data, there is still the problem of doing classification from a small dataset. Other methods such as support vector machines, although capable of dealing with few samples, are inherently binary classifiers, and are in need of learning strategies such as One vs All in the case of multi-classification. In the presence of a large number of classes this can become problematic. In this paper we present, a novel approach to supervised learning through the method of clustering. Unlike traditional methods such as K-Means, Gravitational Clustering does not require the initial number of clusters, and automatically builds the clusters, individual samples can be arbitrarily weighted and it requires only few samples while staying resilient to over-fitting.", "histories": [["v1", "Sat, 5 Sep 2015 03:37:50 GMT  (57kb)", "http://arxiv.org/abs/1509.01659v1", null]], "reviews": [], "SUBJECTS": "cs.LG", "authors": ["armen aghajanyan"], "accepted": false, "id": "1509.01659"}
