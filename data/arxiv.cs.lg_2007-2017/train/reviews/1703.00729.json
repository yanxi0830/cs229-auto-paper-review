{"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "2-Mar-2017", "title": "Mixing Complexity and its Applications to Neural Networks", "abstract": "We suggest analyzing neural networks through the prism of space constraints. We observe that most training algorithms applied in practice use bounded memory, which enables us to use a new notion introduced in the study of space-time tradeoffs that we call mixing complexity. This notion was devised in order to measure the (in)ability to learn using a bounded-memory algorithm. In this paper we describe how we use mixing complexity to obtain new results on what can and cannot be learned using neural networks.", "histories": [["v1", "Thu, 2 Mar 2017 11:34:38 GMT  (86kb,D)", "http://arxiv.org/abs/1703.00729v1", null]], "reviews": [], "SUBJECTS": "cs.LG", "authors": ["michal moshkovitz", "naftali tishby"], "accepted": false, "id": "1703.00729"}
