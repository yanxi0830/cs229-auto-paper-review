{"conference": "EMNLP", "VERSION": "v1", "DATE_OF_SUBMISSION": "19-Mar-2016", "title": "How Transferable are Neural Networks in NLP Applications?", "abstract": "Transfer learning is aimed to make use of valuable knowledge in a source domain to help the model performance in a target domain. It is particularly important to neural networks because neural models are very likely to be overfitting. In some fields like image processing, many studies have shown the effectiveness of neural network-based transfer learning. For neural NLP, however, existing studies have only casually applied transfer learning, and conclusions are inconsistent. In this paper, we conduct a series of empirical studies and provide an illuminating picture on the transferability of neural networks in NLP.", "histories": [["v1", "Sat, 19 Mar 2016 16:38:31 GMT  (1061kb,D)", "http://arxiv.org/abs/1603.06111v1", null], ["v2", "Thu, 13 Oct 2016 07:45:31 GMT  (2337kb,D)", "http://arxiv.org/abs/1603.06111v2", "Accepted by EMNLP-16"]], "reviews": [], "SUBJECTS": "cs.CL cs.LG cs.NE", "authors": ["lili mou", "zhao meng", "rui yan", "ge li", "yan xu", "lu zhang 0023", "zhi jin"], "accepted": true, "id": "1603.06111"}
