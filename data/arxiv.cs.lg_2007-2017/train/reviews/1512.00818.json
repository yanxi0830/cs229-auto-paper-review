{"conference": "AAAI", "VERSION": "v1", "DATE_OF_SUBMISSION": "2-Dec-2015", "title": "Zero-Shot Event Detection by Multimodal Distributional Semantic Embedding of Videos", "abstract": "We propose a new zero-shot Event Detection method by Multi-modal Distributional Semantic embedding of videos. Our model embeds object and action concepts as well as other available modalities from videos into a distributional semantic space. To our knowledge, this is the first Zero-Shot event detection model that is built on top of distributional semantics and extends it in the following directions: (a) semantic embedding of multimodal information in videos (with focus on the visual modalities), (b) automatically determining relevance of concepts/attributes to a free text query, which could be useful for other applications, and (c) retrieving videos by free text event query (e.g., \"changing a vehicle tire\") based on their content. We embed videos into a distributional semantic space and then measure the similarity between videos and the event query in a free text form. We validated our method on the large TRECVID MED (Multimedia Event Detection) challenge. Using only the event title as a query, our method outperformed the state-of-the-art that uses big descriptions from 12.6% to 13.5% with MAP metric and 0.73 to 0.83 with ROC-AUC metric. It is also an order of magnitude faster.", "histories": [["v1", "Wed, 2 Dec 2015 19:34:00 GMT  (1528kb,D)", "http://arxiv.org/abs/1512.00818v1", "To appear in AAAI 2016"], ["v2", "Wed, 16 Dec 2015 00:58:49 GMT  (1479kb,D)", "http://arxiv.org/abs/1512.00818v2", "To appear in AAAI 2016"]], "COMMENTS": "To appear in AAAI 2016", "reviews": [], "SUBJECTS": "cs.CV cs.CL cs.LG", "authors": ["mohamed elhoseiny", "jingen liu", "hui cheng", "harpreet s sawhney", "ahmed m elgammal"], "accepted": true, "id": "1512.00818"}
