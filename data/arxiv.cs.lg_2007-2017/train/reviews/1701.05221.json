{"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "18-Jan-2017", "title": "Parsimonious Inference on Convolutional Neural Networks: Learning and applying on-line kernel activation rules", "abstract": "A new, radical CNN design approach is presented in this paper, considering the reduction of the total computational load during inference. This is achieved by a new holistic intervention on both the CNN architecture and the training procedure, which targets to the parsimonious inference by learning to exploit or remove the redundant capacity of a CNN architecture. This is accomplished, by the introduction of a new structural element that can be inserted as an add-on to any contemporary CNN architecture, whilst preserving or even improving its recognition accuracy. Our approach formulates a systematic and data-driven method for developing CNNs that are trained to eventually change size and form in real-time during inference, targeting to the smaller possible computational footprint. Results are provided for the optimal implementation on a few modern, high-end mobile computing platforms indicating a significant speed-up of up to x3 times.", "histories": [["v1", "Wed, 18 Jan 2017 20:03:12 GMT  (625kb)", "http://arxiv.org/abs/1701.05221v1", "17 pages, 10 figures, 5 tables"], ["v2", "Tue, 24 Jan 2017 06:43:02 GMT  (631kb)", "http://arxiv.org/abs/1701.05221v2", "17 pages, 10 figures, 5 tables"], ["v3", "Wed, 25 Jan 2017 08:57:29 GMT  (631kb)", "http://arxiv.org/abs/1701.05221v3", "17 pages, 10 figures, 5 tables"], ["v4", "Thu, 26 Jan 2017 08:58:52 GMT  (632kb)", "http://arxiv.org/abs/1701.05221v4", "17 pages, 10 figures, 5 tables"], ["v5", "Tue, 31 Jan 2017 12:15:43 GMT  (602kb)", "http://arxiv.org/abs/1701.05221v5", "17 pages, 10 figures, 5 tables"]], "COMMENTS": "17 pages, 10 figures, 5 tables", "reviews": [], "SUBJECTS": "cs.CV cs.AI cs.LG cs.NE", "authors": ["i theodorakopoulos", "v pothos", "d kastaniotis", "n fragoulis"], "accepted": false, "id": "1701.05221"}
