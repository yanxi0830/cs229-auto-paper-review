{"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "22-Mar-2016", "title": "Information Theoretic-Learning Auto-Encoder", "abstract": "We propose Information Theoretic-Learning (ITL) divergence measures for variational regularization of neural networks. We also explore ITL-regularized autoencoders as an alternative to variational autoencoding bayes, adversarial autoencoders and generative adversarial networks for randomly generating sample data without explicitly defining a partition function. This paper also formalizes, generative moment matching networks under the ITL framework.", "histories": [["v1", "Tue, 22 Mar 2016 01:05:47 GMT  (441kb)", "http://arxiv.org/abs/1603.06653v1", "8 pages, 4 figures"]], "COMMENTS": "8 pages, 4 figures", "reviews": [], "SUBJECTS": "cs.LG", "authors": ["eder santana", "matthew emigh", "jose c principe"], "accepted": false, "id": "1603.06653"}
