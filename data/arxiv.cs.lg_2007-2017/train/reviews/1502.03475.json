{"conference": "NIPS", "VERSION": "v1", "DATE_OF_SUBMISSION": "11-Feb-2015", "title": "Combinatorial Bandits Revisited", "abstract": "This paper investigates stochastic and adversarial combinatorial multi-armed bandit problems. In the stochastic setting, we first derive problem-specific regret lower bounds, and analyze how these bounds scale with the dimension of the decision space. We then propose COMBUCB, algorithms that efficiently exploit the combinatorial structure of the problem, and derive finite-time upper bound on their regrets. These bounds improve over regret upper bounds of existing algorithms, and we show numerically thatCOMBUCB significantly outperforms any other algorithm. In the adversarial setting, we propose two simple algorithms, namely COMBEXP-1 and COMBEXP-2 for semi-bandit and bandit feedback, respectively. Their regrets have similar scaling as state-of-the-art algorithms, in spite of the simplicity of their implementation.", "histories": [["v1", "Wed, 11 Feb 2015 22:35:50 GMT  (2512kb,D)", "http://arxiv.org/abs/1502.03475v1", "28 pages"], ["v2", "Tue, 7 Apr 2015 15:07:54 GMT  (2616kb,D)", "http://arxiv.org/abs/1502.03475v2", "29 pages"], ["v3", "Fri, 6 Nov 2015 00:53:37 GMT  (4523kb,D)", "http://arxiv.org/abs/1502.03475v3", "30 pages, Advances in Neural Information Processing Systems 28 (NIPS 2015)"]], "COMMENTS": "28 pages", "reviews": [], "SUBJECTS": "cs.LG math.OC stat.ML", "authors": ["richard combes", "mohammad sadegh talebi", "alexandre prouti\u00e8re", "marc lelarge"], "accepted": true, "id": "1502.03475"}
