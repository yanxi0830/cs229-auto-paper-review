{"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "26-Feb-2017", "title": "Learning Control for Air Hockey Striking using Deep Reinforcement Learning", "abstract": "We consider the task of learning control policies for a robotic mechanism striking a puck in an air hockey game. The control signal is a direct command to the robot's motors. We employ a model free deep reinforcement learning framework to learn the motoric skills of striking the puck accurately in order to score. We propose certain improvements to the standard learning scheme which make the deep Q-learning algorithm feasible when it might otherwise fail. Our improvements include integrating prior knowledge into the learning scheme, and accounting for the changing distribution of samples in the experience replay buffer. Finally we present our simulation results for aimed striking which demonstrate the successful learning of this task, and the improvement in algorithm stability due to the proposed modifications.", "histories": [["v1", "Sun, 26 Feb 2017 19:59:59 GMT  (1091kb,D)", "https://arxiv.org/abs/1702.08074v1", null], ["v2", "Tue, 25 Apr 2017 10:52:33 GMT  (1224kb,D)", "http://arxiv.org/abs/1702.08074v2", "Corrected typos Graphs added in results section"]], "reviews": [], "SUBJECTS": "cs.LG cs.RO", "authors": ["ayal taitler", "nahum shimkin"], "accepted": false, "id": "1702.08074"}
