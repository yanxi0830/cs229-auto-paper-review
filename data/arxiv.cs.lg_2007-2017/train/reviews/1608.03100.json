{"conference": "ICML", "VERSION": "v1", "DATE_OF_SUBMISSION": "10-Aug-2016", "title": "Estimation from Indirect Supervision with Linear Moments", "abstract": "In structured prediction problems where we have indirect supervision of the output, maximum marginal likelihood faces two computational obstacles: non-convexity of the objective and intractability of even a single gradient computation. In this paper, we bypass both obstacles for a class of what we call linear indirectly-supervised problems. Our approach is simple: we solve a linear system to estimate sufficient statistics of the model, which we then use to estimate parameters via convex optimization. We analyze the statistical properties of our approach and show empirically that it is effective in two settings: learning with local privacy constraints and learning from low-cost count-based annotations.", "histories": [["v1", "Wed, 10 Aug 2016 09:19:07 GMT  (172kb,D)", "http://arxiv.org/abs/1608.03100v1", "12 pages, 7 figures, extended and updated version of our paper appearing in ICML 2016"]], "COMMENTS": "12 pages, 7 figures, extended and updated version of our paper appearing in ICML 2016", "reviews": [], "SUBJECTS": "stat.ML cs.LG", "authors": ["aditi raghunathan", "roy frostig", "john duchi", "percy liang"], "accepted": true, "id": "1608.03100"}
