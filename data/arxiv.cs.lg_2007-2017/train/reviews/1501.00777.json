{"conference": "AAAI", "VERSION": "v1", "DATE_OF_SUBMISSION": "5-Jan-2015", "title": "Sparse Deep Stacking Network for Image Classification", "abstract": "Sparse coding can learn good robust representation to noise and model more higher-order representation for image classification. However, the inference algorithm is computationally expensive even though the supervised signals are used to learn compact and discriminative dictionaries in sparse coding techniques. Luckily, a simplified neural network module (SNNM) has been proposed to directly learn the discriminative dictionaries for avoiding the expensive inference. But the SNNM module ignores the sparse representations. Therefore, we propose a sparse SNNM module by adding the mixed-norm regularization (l1/l2 norm). The sparse SNNM modules are further stacked to build a sparse deep stacking network (S-DSN). In the experiments, we evaluate S-DSN with four databases, including Extended YaleB, AR, 15 scene and Caltech101. Experimental results show that our model outperforms related classification methods with only a linear classifier. It is worth noting that we reach 98.8% recognition accuracy on 15 scene.", "histories": [["v1", "Mon, 5 Jan 2015 08:07:31 GMT  (224kb,D)", "http://arxiv.org/abs/1501.00777v1", "8 pages, 3 figures, AAAI-2015"]], "COMMENTS": "8 pages, 3 figures, AAAI-2015", "reviews": [], "SUBJECTS": "cs.CV cs.LG cs.NE", "authors": ["jun li 0027", "heyou chang", "jian yang 0003"], "accepted": true, "id": "1501.00777"}
