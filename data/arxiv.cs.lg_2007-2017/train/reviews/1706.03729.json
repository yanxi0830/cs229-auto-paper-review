{"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "12-Jun-2017", "title": "Channel-Recurrent Variational Autoencoders", "abstract": "Variational Autoencoder (VAE) is an efficient framework in modeling natural images with probabilistic latent spaces. However, when the input spaces become complex, VAE becomes less effective, potentially due to the oversimplification of its latent space construction. In this paper, we propose to integrate recurrent connections across channels to both inference and generation steps of VAE. Sequentially building up the complexity of high-level features in this way allows us to capture global-to-local and coarse-to-fine structures of the input data spaces. We show that our channel-recurrent VAE improves existing approaches in multiple aspects: (1) it attains lower negative log-likelihood than standard VAE on MNIST; when trained adversarially, (2) it generates face and bird images with substantially higher visual quality than the state-of-the-art VAE-GAN and (3) channel-recurrency allows learning more interpretable representations; finally (4) it achieves competitive classification results on STL-10 in a semi-supervised setup.", "histories": [["v1", "Mon, 12 Jun 2017 17:01:34 GMT  (7356kb,D)", "http://arxiv.org/abs/1706.03729v1", null]], "reviews": [], "SUBJECTS": "cs.LG cs.CV", "authors": ["wenling shang", "kihyuk sohn", "zeynep akata", "yuandong tian"], "accepted": false, "id": "1706.03729"}
