{"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "30-Nov-2015", "title": "On Learning to Think: Algorithmic Information Theory for Novel Combinations of Reinforcement Learning Controllers and Recurrent Neural World Models", "abstract": "This paper addresses the general problem of reinforcement learning (RL) in partially observable environments. In 2013, our large RL recurrent neural networks (RNNs) learned from scratch to drive simulated cars from high-dimensional video input. However, real brains are more powerful in many ways. In particular, they learn a predictive model of their initially unknown environment, and somehow use it for abstract (e.g., hierarchical) planning and reasoning. Guided by algorithmic information theory, we describe RNN-based AIs (RNNAIs) designed to do the same. Such an RNNAI can be trained on never-ending sequences of tasks, some of them provided by the user, others invented by the RNNAI itself in a curious, playful fashion, to improve its RNN-based world model. Unlike our previous model-building RNN-based RL machines dating back to 1990, the RNNAI learns to actively query its model for abstract reasoning and planning and decision making, essentially \"learning to think.\" The basic ideas of this report can be applied to many other cases where one RNN-like system exploits the algorithmic information content of another. They are taken from a grant proposal submitted in Fall 2014, and also explain concepts such as \"mirror neurons.\" Experimental results will be described in separate papers.", "histories": [["v1", "Mon, 30 Nov 2015 11:35:26 GMT  (54kb,D)", "http://arxiv.org/abs/1511.09249v1", "36 pages, 1 figure. arXiv admin note: substantial text overlap witharXiv:1404.7828"]], "COMMENTS": "36 pages, 1 figure. arXiv admin note: substantial text overlap witharXiv:1404.7828", "reviews": [], "SUBJECTS": "cs.AI cs.LG cs.NE", "authors": ["juergen schmidhuber"], "accepted": false, "id": "1511.09249"}
