{"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "29-May-2015", "title": "A Critical Review of Recurrent Neural Networks for Sequence Learning", "abstract": "Countless learning tasks require awareness of time. Image captioning, speech synthesis, and video game playing all require that a model generate sequences of outputs. In other domains, such as time series prediction, video analysis, and music information retrieval, a model must learn from sequences of inputs. Significantly more interactive tasks, such as natural language translation, engaging in dialogue, and robotic control, often demand both.", "histories": [["v1", "Fri, 29 May 2015 20:16:51 GMT  (500kb,D)", "http://arxiv.org/abs/1506.00019v1", null], ["v2", "Mon, 29 Jun 2015 20:01:00 GMT  (583kb,D)", "http://arxiv.org/abs/1506.00019v2", null], ["v3", "Wed, 23 Sep 2015 04:59:24 GMT  (598kb,D)", "http://arxiv.org/abs/1506.00019v3", null], ["v4", "Sat, 17 Oct 2015 05:06:11 GMT  (598kb,D)", "http://arxiv.org/abs/1506.00019v4", null]], "reviews": [], "SUBJECTS": "cs.LG cs.NE", "authors": ["zachary c lipton", "john berkowitz", "charles elkan"], "accepted": false, "id": "1506.00019"}
