{"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "23-Jun-2013", "title": "Model Reframing by Feature Context Change", "abstract": "The feature space (including both input and output variables) characterises a data mining problem. In predictive (supervised) problems, the quality and availability of features determines the predictability of the dependent variable, and the performance of data mining models in terms of misclassification or regression error. Good features, however, are usually difficult to obtain. It is usual that many instances come with missing values, either because the actual value for a given attribute was not available or because it was too expensive. This is usually interpreted as a utility or cost-sensitive learning dilemma, in this case between misclassification (or regression error) costs and attribute tests costs. Both misclassification cost (MC) and test cost (TC) can be integrated into a single measure, known as joint cost (JC). We introduce methods and plots (such as the so-called JROC plots) that can work with any of-the-shelf predictive technique, including ensembles, such that we re-frame the model to use the appropriate subset of attributes (the feature configuration) during deployment time. In other words, models are trained with the available attributes (once and for all) and then deployed by setting missing values on the attributes that are deemed ineffective for reducing the joint cost. As the number of feature configuration combinations grows exponentially with the number of features we introduce quadratic methods that are able to approximate the optimal configuration and model choices, as shown by the experimental results.", "histories": [["v1", "Sun, 23 Jun 2013 23:36:40 GMT  (2460kb,D)", "http://arxiv.org/abs/1306.5487v1", "MSc Thesis, 126 pages"]], "COMMENTS": "MSc Thesis, 126 pages", "reviews": [], "SUBJECTS": "cs.LG", "authors": ["celestine-periale maguedong-djoumessi"], "accepted": false, "id": "1306.5487"}
