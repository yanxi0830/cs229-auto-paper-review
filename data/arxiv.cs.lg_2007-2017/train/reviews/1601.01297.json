{"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "6-Jan-2016", "title": "Angrier Birds: Bayesian reinforcement learning", "abstract": "We train a reinforcement learner to play a simplified version of the game Angry Birds. The learner is provided with a game state in a manner similar to the output that could be produced by computer vision algorithms. We improve on the efficiency of regular {\\epsilon}-greedy Q-Learning with linear function approximation through more systematic exploration in Randomized Least Squares Value Iteration (RLSVI), an algorithm that samples its policy from a posterior distribution on optimal policies. With larger state-action spaces, efficient exploration becomes increasingly important, as evidenced by the faster learning in RLSVI.", "histories": [["v1", "Wed, 6 Jan 2016 20:22:22 GMT  (503kb,D)", "https://arxiv.org/abs/1601.01297v1", "Stanford University CS221 Final Project"], ["v2", "Thu, 7 Jan 2016 01:28:34 GMT  (503kb,D)", "http://arxiv.org/abs/1601.01297v2", "Stanford University CS221 Final Project"]], "COMMENTS": "Stanford University CS221 Final Project", "reviews": [], "SUBJECTS": "cs.AI cs.LG", "authors": ["imanol arrieta ibarra", "bernardo ramos", "lars roemheld"], "accepted": false, "id": "1601.01297"}
