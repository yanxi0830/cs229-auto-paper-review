{"conference": "ICML", "VERSION": "v1", "DATE_OF_SUBMISSION": "27-Jun-2012", "title": "Regularizers versus Losses for Nonlinear Dimensionality Reduction: A Factored View with New Convex Relaxations", "abstract": "We demonstrate that almost all non-parametric dimensionality reduction methods can be expressed by a simple procedure: regularized loss minimization plus singular value truncation. By distinguishing the role of the loss and regularizer in such a process, we recover a factored perspective that reveals some gaps in the current literature. Beyond identifying a useful new loss for manifold unfolding, a key contribution is to derive new convex regularizers that combine distance maximization with rank reduction. These regularizers can be applied to any loss.", "histories": [["v1", "Wed, 27 Jun 2012 19:59:59 GMT  (451kb)", "http://arxiv.org/abs/1206.6455v1", "Appears in Proceedings of the 29th International Conference on Machine Learning (ICML 2012)"]], "COMMENTS": "Appears in Proceedings of the 29th International Conference on Machine Learning (ICML 2012)", "reviews": [], "SUBJECTS": "cs.LG stat.ML", "authors": ["james neufeld", "yaoliang yu", "xinhua zhang", "ryan kiros", "dale schuurmans"], "accepted": true, "id": "1206.6455"}
