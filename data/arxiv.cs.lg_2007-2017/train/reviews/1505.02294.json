{"conference": "NIPS", "VERSION": "v1", "DATE_OF_SUBMISSION": "9-May-2015", "title": "Estimation with Norm Regularization", "abstract": "Analysis of non-asymptotic estimation error and structured statistical recovery based on norm regularized regression, such as Lasso, needs to consider four aspects: the norm, the loss function, the design matrix, and the noise model. This paper presents generalizations of such estimation error analysis on all four aspects compared to the existing literature. We characterize the restricted error set where the estimation error vector lies, establish relations between error sets for the constrained and regularized problems, and present an estimation error bound applicable to any norm. Precise characterizations of the bound is presented for a variety of design matrices, including sub-Gaussian, anisotropic, and correlated designs, noise models, including both Gaussian and sub-Gaussian noise, and loss functions, including least squares and generalized linear models. A key result from the analysis is that the sample complexity of all such estimators depends on the Gaussian width of the spherical cap corresponding to the restricted error set. Further, once the number of samples $n$ crosses the required sample complexity, the estimation error decreases as $\\frac{c}{\\sqrt{n}}$, where $c$ depends on the Gaussian width of the unit dual norm ball.", "histories": [["v1", "Sat, 9 May 2015 17:25:14 GMT  (1218kb,D)", "https://arxiv.org/abs/1505.02294v1", null], ["v2", "Mon, 18 May 2015 16:24:01 GMT  (643kb,D)", "http://arxiv.org/abs/1505.02294v2", "Fixed minor typos"], ["v3", "Mon, 30 Nov 2015 20:47:14 GMT  (660kb,D)", "http://arxiv.org/abs/1505.02294v3", "Fixed technical issues. Generalized some results"]], "reviews": [], "SUBJECTS": "stat.ML cs.LG", "authors": ["arindam banerjee", "sheng chen", "farideh fazayeli", "vidyashankar sivakumar"], "accepted": true, "id": "1505.02294"}
