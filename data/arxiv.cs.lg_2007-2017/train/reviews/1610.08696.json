{"conference": "NIPS", "VERSION": "v1", "DATE_OF_SUBMISSION": "27-Oct-2016", "title": "Learning Bound for Parameter Transfer Learning", "abstract": "We consider a transfer-learning problem by using the parameter transfer approach, where a suitable parameter of feature mapping is learned through one task and applied to another objective task. Then, we introduce the notion of the local stability of parametric feature mapping and parameter transfer learnability, and thereby derive a learning bound for parameter transfer algorithms. As an application of parameter transfer learning, we discuss the performance of sparse coding in self-taught learning. Although self-taught learning algorithms with plentiful unlabeled data often show excellent empirical performance, their theoretical analysis has not been studied. In this paper, we also provide the first theoretical learning bound for self-taught learning.", "histories": [["v1", "Thu, 27 Oct 2016 10:50:55 GMT  (38kb)", "http://arxiv.org/abs/1610.08696v1", "This paper was accepted at NIPS 2016 as a poster presentation"], ["v2", "Wed, 9 Nov 2016 01:08:40 GMT  (37kb)", "http://arxiv.org/abs/1610.08696v2", "This paper was accepted at NIPS 2016 as a poster presentation"], ["v3", "Wed, 18 Jan 2017 04:41:17 GMT  (37kb)", "http://arxiv.org/abs/1610.08696v3", "This paper was accepted at NIPS 2016 as a poster presentation"]], "COMMENTS": "This paper was accepted at NIPS 2016 as a poster presentation", "reviews": [], "SUBJECTS": "stat.ML cs.LG", "authors": ["wataru kumagai"], "accepted": true, "id": "1610.08696"}
