{"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "2-Mar-2017", "title": "Opening the Black Box of Deep Neural Networks via Information", "abstract": "Despite their great success, there is still no com- prehensive theoretical understanding of learning with Deep Neural Networks (DNNs) or their in- ner organization. Previous work [Tishby &amp; Zaslavsky (2015)] proposed to analyze DNNs in the Information Plane; i.e., the plane of the Mutual Information values that each layer preserves on the input and output variables. They suggested that the goal of the network is to optimize the In- formation Bottleneck (IB) tradeoff between com- pression and prediction, successively, for each layer.", "histories": [["v1", "Thu, 2 Mar 2017 14:53:14 GMT  (3499kb,D)", "http://arxiv.org/abs/1703.00810v1", "9 pages, 7 figures"], ["v2", "Thu, 9 Mar 2017 10:00:24 GMT  (3499kb,D)", "http://arxiv.org/abs/1703.00810v2", "9 pages, 7 figures"], ["v3", "Sat, 29 Apr 2017 17:32:47 GMT  (6334kb,D)", "http://arxiv.org/abs/1703.00810v3", "19 pages, 8 figures"]], "COMMENTS": "9 pages, 7 figures", "reviews": [], "SUBJECTS": "cs.LG", "authors": ["ravid shwartz-ziv", "naftali tishby"], "accepted": false, "id": "1703.00810"}
