{"conference": "NIPS", "VERSION": "v1", "DATE_OF_SUBMISSION": "12-Jun-2014", "title": "Convolutional Kernel Networks", "abstract": "An important goal in visual recognition is to devise image representations that are invariant to particular transformations. In this paper, we address this goal with a new type of convolutional neural network (CNN) whose invariance is encoded by a reproducing kernel. Unlike traditional approaches where neural networks are learned either to represent data or for solving a classification task, our network learns to approximate the kernel feature map on training data. Such an approach enjoys several benefits over classical ones. First, by teaching CNNs to be invariant, we obtain simple network architectures that achieve a similar accuracy to more complex ones, while being easy to train and robust to overfitting. Second, we bridge a gap between the neural network literature and kernels, which are natural tools to model invariance. We evaluate our methodology on visual recognition tasks where CNNs have proven to perform well, e.g., digit recognition with the MNIST dataset, and the more challenging CIFAR-10 and STL-10 datasets, where our accuracy is competitive with the state of the art.", "histories": [["v1", "Thu, 12 Jun 2014 19:41:03 GMT  (49kb)", "http://arxiv.org/abs/1406.3332v1", null], ["v2", "Fri, 14 Nov 2014 16:58:48 GMT  (52kb)", "http://arxiv.org/abs/1406.3332v2", "appears in Advances in Neural Information Processing Systems (NIPS), Dec 2014, Montreal, Canada,this http URL"]], "reviews": [], "SUBJECTS": "cs.CV cs.LG stat.ML", "authors": ["julien mairal", "piotr koniusz", "za\u00efd harchaoui", "cordelia schmid"], "accepted": true, "id": "1406.3332"}
