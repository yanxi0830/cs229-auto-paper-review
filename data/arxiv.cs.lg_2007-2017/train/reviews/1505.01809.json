{"conference": "ACL", "VERSION": "v1", "DATE_OF_SUBMISSION": "7-May-2015", "title": "Language Models for Image Captioning: The Quirks and What Works", "abstract": "Two recent approaches have achieved state-of-the-art results in image captioning. The first uses a pipelined process where a set of candidate words is generated by a convolutional neural network (CNN) trained on images, and then a maximum entropy (ME) language model is used to arrange these words into a coherent sentence. The second uses the penultimate activation layer of the CNN as input to a recurrent neural network (RNN) that then generates the caption sequence. In this paper, we compare the merits of the different language modeling approaches for the first time by using the same state-of-the-art CNN as input. We examine issues in the different approaches, including linguistic irregularities, caption repetition, and data set overlap. By combining key aspects of both the ME and RNN methods, we achieve a new record performance on the benchmark COCO dataset.", "histories": [["v1", "Thu, 7 May 2015 18:36:14 GMT  (684kb,D)", "https://arxiv.org/abs/1505.01809v1", "Seethis http URLfor project information"], ["v2", "Mon, 20 Jul 2015 22:10:49 GMT  (1039kb,D)", "http://arxiv.org/abs/1505.01809v2", "Seethis http URLfor project information"], ["v3", "Wed, 14 Oct 2015 22:03:40 GMT  (1033kb,D)", "http://arxiv.org/abs/1505.01809v3", "Seethis http URLfor project information"]], "COMMENTS": "Seethis http URLfor project information", "reviews": [], "SUBJECTS": "cs.CL cs.AI cs.CV cs.LG", "authors": ["jacob devlin", "hao cheng", "hao fang", "saurabh gupta", "li deng", "xiaodong he", "geoffrey zweig", "margaret mitchell"], "accepted": true, "id": "1505.01809"}
