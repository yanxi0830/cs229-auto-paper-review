{"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "31-Aug-2016", "title": "Towards Transparent AI Systems: Interpreting Visual Question Answering Models", "abstract": "Deep neural networks have shown striking progress and obtained state-of-the-art results in many AI research fields in the recent years. However, it is often unsatisfying to not know why they predict what they do. In this paper, we address the problem of interpreting Visual Question Answering (VQA) models. Specifically, we are interested in finding what part of the input (pixels in images or words in questions) the VQA model focuses on while answering the question. To tackle this problem, we use two visualization techniques -- guided backpropagation and occlusion -- to find important words in the question and important regions in the image. We then present qualitative and quantitative analyses of these importance maps.", "histories": [["v1", "Wed, 31 Aug 2016 18:11:29 GMT  (485kb,D)", "https://arxiv.org/abs/1608.08974v1", null], ["v2", "Fri, 9 Sep 2016 19:51:06 GMT  (486kb,D)", "http://arxiv.org/abs/1608.08974v2", null]], "reviews": [], "SUBJECTS": "cs.CV cs.AI cs.CL cs.LG", "authors": ["yash goyal", "akrit mohapatra", "devi parikh", "dhruv batra"], "accepted": false, "id": "1608.08974"}
