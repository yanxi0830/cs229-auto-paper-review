{"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "10-Oct-2015", "title": "Do Deep Neural Networks Learn Facial Action Units When Doing Expression Recognition?", "abstract": "Despite being the appearance-based classifier of choice in recent years, relatively few works have examined how much convolutional neural networks (CNNs) can improve performance on accepted expression recognition benchmarks and, more importantly, examine what it is they actually learn. In this work, not only do we show that CNNs can achieve strong performance, but we also introduce an approach to decipher which portions of the face influence the CNN's predictions. First, we train a zero-bias CNN on facial expression data and achieve, to our knowledge, state-of-the-art performance on two expression recognition benchmarks: the extended Cohn-Kanade (CK+) dataset and the Toronto Face Dataset (TFD). We then qualitatively analyze the network by visualizing the spatial patterns that maximally excite different neurons in the convolutional layers and show how they resemble Facial Action Units (FAUs). Finally, we use the FAU labels provided in the CK+ dataset to verify that the FAUs observed in our filter visualizations indeed align with the subject's facial movements.", "histories": [["v1", "Sat, 10 Oct 2015 18:53:21 GMT  (1702kb,D)", "https://arxiv.org/abs/1510.02969v1", "Accepted at ICCV 2015 CV4AC Workshop"], ["v2", "Fri, 28 Oct 2016 06:12:07 GMT  (1394kb,D)", "http://arxiv.org/abs/1510.02969v2", "Accepted at ICCV 2015 CV4AC Workshop. Corrected numbers in Table 1 and some minor typos"], ["v3", "Thu, 16 Mar 2017 03:07:21 GMT  (1393kb,D)", "http://arxiv.org/abs/1510.02969v3", "Accepted at ICCV 2015 CV4AC Workshop. Corrected numbers in Tables 2 and 3"]], "COMMENTS": "Accepted at ICCV 2015 CV4AC Workshop", "reviews": [], "SUBJECTS": "cs.CV cs.LG cs.NE", "authors": ["pooya khorrami", "tom le paine", "thomas s huang"], "accepted": false, "id": "1510.02969"}
