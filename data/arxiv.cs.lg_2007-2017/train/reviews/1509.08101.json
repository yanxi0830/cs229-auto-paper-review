{"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "27-Sep-2015", "title": "Representation Benefits of Deep Feedforward Networks", "abstract": "This note provides a family of classification problems, indexed by a positive integer $k$, where all shallow networks with fewer than exponentially (in $k$) many nodes exhibit error at least $1/3$, whereas a deep network with 2 nodes in each of $2k$ layers achieves zero error, as does a recurrent network with 3 distinct nodes iterated $k$ times. The proof is elementary, and the networks are standard feedforward networks with ReLU (Rectified Linear Unit) nonlinearities.", "histories": [["v1", "Sun, 27 Sep 2015 15:26:58 GMT  (41kb,D)", "http://arxiv.org/abs/1509.08101v1", null], ["v2", "Tue, 29 Sep 2015 13:44:37 GMT  (41kb,D)", "http://arxiv.org/abs/1509.08101v2", null]], "reviews": [], "SUBJECTS": "cs.LG cs.NE", "authors": ["matus telgarsky"], "accepted": false, "id": "1509.08101"}
