{"conference": "iclr", "VERSION": "v1", "DATE_OF_SUBMISSION": "19-Dec-2014", "title": "Generative Modeling of Convolutional Neural Networks", "abstract": "The convolutional neural networks (CNNs) have proven to be a powerful tool for discriminative learning. Recently researchers have also started to show interest in the generative aspects of CNNs in order to gain a deeper understanding of what they have learned and how to further improve them. This paper investigates generative modeling of CNNs. The main contributions include: (1) We construct a generative model for the CNN in the form of exponential tilting of a reference distribution. (2) We propose a generative gradient for pre-training CNNs by a non-parametric importance sampling scheme, which is fundamentally different from the commonly used discriminative gradient, and yet has the same computational architecture and cost as the latter. (3) We propose a generative visualization method for the CNNs by sampling from an explicit parametric image distribution. The proposed visualization method can directly draw synthetic samples for any given node in a trained CNN by the Hamiltonian Monte Carlo (HMC) algorithm, without resorting to any extra hold-out images. Experiments on the challenging ImageNet benchmark show that the proposed generative gradient pre-training consistently helps improve the performances of CNNs, and the proposed generative visualization method generates meaningful and varied samples of synthetic images from a large-scale deep CNN.", "histories": [["v1", "Fri, 19 Dec 2014 11:34:37 GMT  (3478kb,D)", "http://arxiv.org/abs/1412.6296v1", null], ["v2", "Thu, 9 Apr 2015 15:07:06 GMT  (25616kb,D)", "http://arxiv.org/abs/1412.6296v2", null]], "reviews": [], "SUBJECTS": "cs.CV cs.LG cs.NE", "authors": ["jifeng dai", "yang lu", "ying-nian wu"], "accepted": true, "id": "1412.6296"}
