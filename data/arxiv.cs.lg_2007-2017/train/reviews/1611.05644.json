{"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "17-Nov-2016", "title": "Inverting The Generator Of A Generative Adversarial Network", "abstract": "Generative adversarial networks (GANs) learn to synthesise new samples from a high-dimensional distribution by passing samples drawn from a latent space through a generative network. When the high-dimensional distribution describes images of a particular data set, the network should learn to generate visually similar image samples for latent variables that are close to each other in the latent space. For tasks such as image retrieval and image classification, it may be useful to exploit the arrangement of the latent space by projecting images into it, and using this as a representation for discriminative tasks. GANs often consist of multiple layers of non-linear computations, making them very difficult to invert. This paper introduces techniques for projecting image samples into the latent space using any pre-trained GAN, provided that the computational graph is available. We evaluate these techniques on both MNIST digits and Omniglot handwritten characters. In the case of MNIST digits, we show that projections into the latent space maintain information about the style and the identity of the digit. In the case of Omniglot characters, we show that even characters from alphabets that have not been seen during training may be projected well into the latent space; this suggests that this approach may have applications in one-shot learning.", "histories": [["v1", "Thu, 17 Nov 2016 11:55:16 GMT  (500kb,D)", "http://arxiv.org/abs/1611.05644v1", "Accepted at NIPS 2016 Workshop on Adversarial Training"]], "COMMENTS": "Accepted at NIPS 2016 Workshop on Adversarial Training", "reviews": [], "SUBJECTS": "cs.CV cs.LG", "authors": ["antonia creswell", "anil anthony bharath"], "accepted": false, "id": "1611.05644"}
