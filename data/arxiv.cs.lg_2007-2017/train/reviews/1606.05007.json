{"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "15-Jun-2016", "title": "Automatic Pronunciation Generation by Utilizing a Semi-supervised Deep Neural Networks", "abstract": "Phonemic or phonetic sub-word units are the most commonly used atomic elements to represent speech signals in modern ASRs. However they are not the optimal choice due to several reasons such as: large amount of effort required to handcraft a pronunciation dictionary, pronunciation variations, human mistakes and under-resourced dialects and languages. Here, we propose a data-driven pronunciation estimation and acoustic modeling method which only takes the orthographic transcription to jointly estimate a set of sub-word units and a reliable dictionary. Experimental results show that the proposed method which is based on semi-supervised training of a deep neural network largely outperforms phoneme based continuous speech recognition on the TIMIT dataset.", "histories": [["v1", "Wed, 15 Jun 2016 23:45:33 GMT  (223kb,D)", "http://arxiv.org/abs/1606.05007v1", "Proc. of 17th Interspeech (2016), San Francisco, California, USA"]], "COMMENTS": "Proc. of 17th Interspeech (2016), San Francisco, California, USA", "reviews": [], "SUBJECTS": "cs.CL cs.LG cs.SD", "authors": ["naoya takahashi", "tofigh naghibi", "beat pfister"], "accepted": false, "id": "1606.05007"}
