{"conference": "NIPS", "VERSION": "v1", "DATE_OF_SUBMISSION": "10-Jun-2016", "title": "Memory-Efficient Backpropagation Through Time", "abstract": "We propose a novel approach to reduce memory consumption of the backpropagation through time (BPTT) algorithm when training recurrent neural networks (RNNs). Our approach uses dynamic programming to balance a trade-off between caching of intermediate results and recomputation. The algorithm is capable of tightly fitting within almost any user-set memory budget while finding an optimal execution policy minimizing the computational cost. Computational devices have limited memory capacity and maximizing a computational performance given a fixed memory budget is a practical use-case. We provide asymptotic computational upper bounds for various regimes. The algorithm is particularly effective for long sequences. For sequences of length 1000, our algorithm saves 95\\% of memory usage while using only one third more time per iteration than the standard BPTT.", "histories": [["v1", "Fri, 10 Jun 2016 17:20:39 GMT  (277kb,D)", "http://arxiv.org/abs/1606.03401v1", null]], "reviews": [], "SUBJECTS": "cs.NE cs.LG", "authors": ["audrunas gruslys", "r\u00e9mi munos", "ivo danihelka", "marc lanctot", "alex graves"], "accepted": true, "id": "1606.03401"}
