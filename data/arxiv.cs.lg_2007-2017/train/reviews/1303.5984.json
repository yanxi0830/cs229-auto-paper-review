{"conference": "NIPS", "VERSION": "v1", "DATE_OF_SUBMISSION": "24-Mar-2013", "title": "Efficient Reinforcement Learning for High Dimensional Linear Quadratic Systems", "abstract": "We study the problem of adaptive control of a high dimensional linear quadratic (LQ) system. Previous work established the asymptotic convergence to an optimal controller for various adaptive control schemes. More recently, for the average cost LQ problem, a regret bound of ${O}(\\sqrt{T})$ was shown, apart form logarithmic factors. However, this bound scales exponentially with $p$, the dimension of the state space. In this work we consider the case where the matrices describing the dynamic of the LQ system are sparse and their dimensions are large. We present an adaptive control scheme that achieves a regret bound of ${O}(p \\sqrt{T})$, apart from logarithmic factors. In particular, our algorithm has an average cost of $(1+\\eps)$ times the optimum cost after $T = \\polylog(p) O(1/\\eps^2)$. This is in comparison to previous work on the dense dynamics where the algorithm requires time that scales exponentially with dimension in order to achieve regret of $\\eps$ times the optimal cost.", "histories": [["v1", "Sun, 24 Mar 2013 19:56:49 GMT  (26kb)", "http://arxiv.org/abs/1303.5984v1", "16 pages"]], "COMMENTS": "16 pages", "reviews": [], "SUBJECTS": "stat.ML cs.LG math.OC", "authors": ["morteza ibrahimi", "adel javanmard", "benjamin van roy"], "accepted": true, "id": "1303.5984"}
