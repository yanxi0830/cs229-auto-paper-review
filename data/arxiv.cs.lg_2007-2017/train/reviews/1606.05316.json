{"conference": "icml", "VERSION": "v1", "DATE_OF_SUBMISSION": "16-Jun-2016", "title": "Learning Infinite-Layer Networks: Without the Kernel Trick", "abstract": "Infinite--Layer Networks (ILN) have recently been proposed as an architecture that mimics neural networks while enjoying some of the advantages of kernel methods. ILN are networks that integrate over infinitely many nodes within a single hidden layer. It has been demonstrated by several authors that the problem of learning ILN can be reduced to the kernel trick, implying that whenever a certain integral can be computed analytically they are efficiently learnable.", "histories": [["v1", "Thu, 16 Jun 2016 19:02:14 GMT  (20kb)", "http://arxiv.org/abs/1606.05316v1", null], ["v2", "Fri, 28 Jul 2017 04:13:58 GMT  (33kb,D)", "http://arxiv.org/abs/1606.05316v2", null]], "reviews": [], "SUBJECTS": "cs.LG", "authors": ["roi livni", "daniel carmon", "amir globerson"], "accepted": true, "id": "1606.05316"}
