{"conference": "ICML", "VERSION": "v1", "DATE_OF_SUBMISSION": "6-Mar-2017", "title": "Neural Episodic Control", "abstract": "Deep reinforcement learning methods attain super-human performance in a wide range of environments. Such methods are grossly inefficient, often taking orders of magnitudes more data than humans to achieve reasonable performance. We propose Neural Episodic Control: a deep reinforcement learning agent that is able to rapidly assimilate new experiences and act upon them. Our agent uses a semi-tabular representation of the value function: a buffer of past experience containing slowly changing state representations and rapidly updated estimates of the value function. We show across a wide range of environments that our agent learns significantly faster than other state-of-the-art, general purpose deep reinforcement learning agents.", "histories": [["v1", "Mon, 6 Mar 2017 17:23:27 GMT  (3234kb,D)", "http://arxiv.org/abs/1703.01988v1", null]], "reviews": [], "SUBJECTS": "cs.LG stat.ML", "authors": ["alexander pritzel", "benigno uria", "sriram srinivasan", "adri\u00e0 puigdom\u00e8nech badia", "oriol vinyals", "demis hassabis", "daan wierstra", "charles blundell"], "accepted": true, "id": "1703.01988"}
