{"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "2-Feb-2015", "title": "Iterated Support Vector Machines for Distance Metric Learning", "abstract": "Distance metric learning aims to learn from the given training data a valid distance metric, with which the similarity between data samples can be more effectively evaluated for classification. Metric learning is often formulated as a convex or nonconvex optimization problem, while many existing metric learning algorithms become inefficient for large scale problems. In this paper, we formulate metric learning as a kernel classification problem, and solve it by iterated training of support vector machines (SVM). The new formulation is easy to implement, efficient in training, and tractable for large-scale problems. Two novel metric learning models, namely Positive-semidefinite Constrained Metric Learning (PCML) and Nonnegative-coefficient Constrained Metric Learning (NCML), are developed. Both PCML and NCML can guarantee the global optimality of their solutions. Experimental results on UCI dataset classification, handwritten digit recognition, face verification and person re-identification demonstrate that the proposed metric learning methods achieve higher classification accuracy than state-of-the-art methods and they are significantly more efficient in training.", "histories": [["v1", "Mon, 2 Feb 2015 05:30:44 GMT  (147kb)", "http://arxiv.org/abs/1502.00363v1", "14 pages, 10 figures"]], "COMMENTS": "14 pages, 10 figures", "reviews": [], "SUBJECTS": "cs.LG cs.CV", "authors": ["wangmeng zuo", "faqiang wang", "david zhang", "liang lin", "yuchi huang", "deyu meng", "lei zhang"], "accepted": false, "id": "1502.00363"}
