{"conference": "NIPS", "VERSION": "v1", "DATE_OF_SUBMISSION": "2-Jul-2015", "title": "Fast Convergence of Regularized Learning in Games", "abstract": "We show that natural classes of regularized learning algorithms with a form of recency bias achieve faster convergence rates to approximate efficiency and to correlated equilibria in multiplayer normal form games. When each player in a game uses an algorithm from our class, their individual regret decays at $O(T^{-3/4})$, while the sum of utilities converges to an approximate optimum at $O(T^{-1})$--an improvement upon the worst case $O(T^{-1/2})$ rates. We show a black-box reduction for any algorithm in the class to achieve $O(T^{-1/2})$ rates against an adversary, while maintaining the faster rates against algorithms in the class. Our results extend those of [Rakhlin and Shridharan 2013] and [Daskalakis et al. 2014], who only analyzed two-player zero-sum games for specific algorithms.", "histories": [["v1", "Thu, 2 Jul 2015 01:55:40 GMT  (362kb,D)", "https://arxiv.org/abs/1507.00407v1", null], ["v2", "Tue, 21 Jul 2015 21:58:16 GMT  (120kb,D)", "http://arxiv.org/abs/1507.00407v2", null], ["v3", "Wed, 5 Aug 2015 14:51:56 GMT  (117kb,D)", "http://arxiv.org/abs/1507.00407v3", null], ["v4", "Tue, 8 Dec 2015 17:22:43 GMT  (112kb,D)", "http://arxiv.org/abs/1507.00407v4", null], ["v5", "Thu, 10 Dec 2015 21:52:29 GMT  (112kb,D)", "http://arxiv.org/abs/1507.00407v5", null]], "reviews": [], "SUBJECTS": "cs.GT cs.AI cs.LG", "authors": ["vasilis syrgkanis", "alekh agarwal", "haipeng luo", "robert e schapire"], "accepted": true, "id": "1507.00407"}
