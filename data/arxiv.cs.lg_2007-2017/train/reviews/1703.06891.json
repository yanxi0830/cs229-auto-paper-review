{"conference": "ICML", "VERSION": "v1", "DATE_OF_SUBMISSION": "20-Mar-2017", "title": "Dance Dance Convolution", "abstract": "Dance Dance Revolution (DDR) is a popular rhythm-based video game. Players perform steps on a dance platform in synchronization with music as directed by on-screen step charts. While many step charts are available in standardized packs, users may grow tired of existing charts, or wish to dance to a song for which no chart exists. We introduce the task of learning to choreograph. Given a raw audio track, the goal is to produce a new step chart. This task decomposes naturally into two subtasks: deciding when to place steps and deciding which steps to select. For the step placement task, we combine recurrent and convolutional neural networks to ingest spectrograms of low-level audio features to predict steps, conditioned on chart difficulty. For step selection, we present a conditional LSTM generative model that substantially outperforms n-gram and fixed-window approaches.", "histories": [["v1", "Mon, 20 Mar 2017 18:00:13 GMT  (1518kb,D)", "https://arxiv.org/abs/1703.06891v1", null], ["v2", "Wed, 22 Mar 2017 07:44:55 GMT  (1518kb,D)", "http://arxiv.org/abs/1703.06891v2", null], ["v3", "Wed, 21 Jun 2017 00:45:51 GMT  (1881kb,D)", "http://arxiv.org/abs/1703.06891v3", "Published as a conference paper at ICML 2017"]], "reviews": [], "SUBJECTS": "cs.LG cs.MM cs.NE cs.SD stat.ML", "authors": ["chris donahue", "zachary c lipton", "julian mcauley"], "accepted": true, "id": "1703.06891"}
