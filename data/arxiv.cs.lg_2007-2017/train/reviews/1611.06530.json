{"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "20-Nov-2016", "title": "Prototypical Recurrent Unit", "abstract": "The difficulty in analyzing LSTM-like recurrent neural networks lies in the complex structure of the recurrent unit, which induces highly complex nonlinear dynamics. In this paper, we design a new simple recurrent unit, which we call Prototypical Recurrent Unit (PRU). We verify experimentally that PRU performs comparably to LSTM and GRU. This potentially enables PRU to be a prototypical example for analytic study of LSTM-like recurrent networks. Along these experiments, the memorization capability of LSTM-like networks is also studied and some insights are obtained.", "histories": [["v1", "Sun, 20 Nov 2016 15:39:43 GMT  (388kb)", "http://arxiv.org/abs/1611.06530v1", null]], "reviews": [], "SUBJECTS": "cs.LG", "authors": ["dingkun long", "richong zhang", "yongyi mao"], "accepted": false, "id": "1611.06530"}
