{"conference": "ICML", "VERSION": "v1", "DATE_OF_SUBMISSION": "18-Jun-2012", "title": "Linear Regression with Limited Observation", "abstract": "We consider the most common variants of linear regression, including Ridge, Lasso and Support-vector regression, in a setting where the learner is allowed to observe only a fixed number of attributes of each example at training time. We present simple and efficient algorithms for these problems: for Lasso and Ridge regression they need the same total number of attributes (up to constants) as do full-information algorithms, for reaching a certain accuracy. For Support-vector regression, we require exponentially less attributes compared to the state of the art. By that, we resolve an open problem recently posed by Cesa-Bianchi et al. (2010). Experiments show the theoretical bounds to be justified by superior performance compared to the state of the art.", "histories": [["v1", "Mon, 18 Jun 2012 15:37:23 GMT  (350kb)", "http://arxiv.org/abs/1206.4678v1", "ICML2012"]], "COMMENTS": "ICML2012", "reviews": [], "SUBJECTS": "cs.LG stat.ML", "authors": ["elad hazan", "tomer koren"], "accepted": true, "id": "1206.4678"}
