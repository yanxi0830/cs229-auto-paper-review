{"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "8-Sep-2017", "title": "Gigamachine: incremental machine learning on desktop computers", "abstract": "We present a concrete design for Solomonoff's incremental machine learning system suitable for desktop computers. We use R5RS Scheme and its standard library with a few omissions as the reference machine. We introduce a Levin Search variant based on a stochastic Context Free Grammar together with new update algorithms that use the same grammar as a guiding probability distribution for incremental machine learning. The updates include adjusting production probabilities, re-using previous solutions, learning programming idioms and discovery of frequent subprograms. The issues of extending the a priori probability distribution and bootstrapping are discussed. We have implemented a good portion of the proposed algorithms. Experiments with toy problems show that the update algorithms work as expected.", "histories": [["v1", "Fri, 8 Sep 2017 17:39:26 GMT  (19kb)", "http://arxiv.org/abs/1709.03413v1", "This is the original submission for my AGI-2010 paper titled Stochastic Grammar Based Incremental Machine Learning Using Scheme which may be found onthis http URLand presented a partial but general solution to the transfer learning problem in AI. arXiv admin note: substantial text overlap witharXiv:1103.1003"]], "COMMENTS": "This is the original submission for my AGI-2010 paper titled Stochastic Grammar Based Incremental Machine Learning Using Scheme which may be found onthis http URLand presented a partial but general solution to the transfer learning problem in AI. arXiv admin note: substantial text overlap witharXiv:1103.1003", "reviews": [], "SUBJECTS": "cs.AI cs.LG", "authors": ["eray \\\"ozkural"], "accepted": false, "id": "1709.03413"}
