{"conference": "ICML", "VERSION": "v1", "DATE_OF_SUBMISSION": "10-Feb-2015", "title": "Cascading Bandits: Learning to Rank in the Cascade Model", "abstract": "The cascade model is a well-established model of user interaction with content. In this work, we propose cascading bandits, a learning variant of the model where the objective is to learn $K$ most attractive items out of $L$ ground items. We cast the problem as a stochastic combinatorial bandit with a non-linear reward function and partially observed weights of items. Both of these are challenging in the context of combinatorial bandits. We propose two computationally-efficient algorithms for our problem, CascadeUCB1 and CascadeKL-UCB, and prove gap-dependent upper bounds on their regret. We also derive a lower bound for cascading bandits and show that it matches the upper bound of CascadeKL-UCB up to a logarithmic factor. Finally, we evaluate our algorithms on synthetic problems. Our experiments demonstrate that the algorithms perform well and robustly even when our modeling assumptions are violated.", "histories": [["v1", "Tue, 10 Feb 2015 02:56:04 GMT  (85kb,D)", "http://arxiv.org/abs/1502.02763v1", null], ["v2", "Mon, 18 May 2015 19:03:38 GMT  (78kb,D)", "http://arxiv.org/abs/1502.02763v2", "Proceedings of the 32nd International Conference on Machine Learning"]], "reviews": [], "SUBJECTS": "cs.LG stat.ML", "authors": ["branislav kveton", "csaba szepesv\u00e1ri", "zheng wen", "azin ashkan"], "accepted": true, "id": "1502.02763"}
