{"conference": "ICML", "VERSION": "v1", "DATE_OF_SUBMISSION": "27-Jun-2012", "title": "Feature Selection via Probabilistic Outputs", "abstract": "This paper investigates two feature-scoring criteria that make use of estimated class probabilities: one method proposed by \\citet{shen} and a complementary approach proposed below. We develop a theoretical framework to analyze each criterion and show that both estimate the spread (across all values of a given feature) of the probability that an example belongs to the positive class. Based on our analysis, we predict when each scoring technique will be advantageous over the other and give empirical results validating our predictions.", "histories": [["v1", "Wed, 27 Jun 2012 19:59:59 GMT  (967kb)", "http://arxiv.org/abs/1206.6383v1", "Appears in Proceedings of the 29th International Conference on Machine Learning (ICML 2012)"]], "COMMENTS": "Appears in Proceedings of the 29th International Conference on Machine Learning (ICML 2012)", "reviews": [], "SUBJECTS": "cs.LG stat.ML", "authors": ["andrea pohoreckyj danyluk", "nicholas arnosti"], "accepted": true, "id": "1206.6383"}
