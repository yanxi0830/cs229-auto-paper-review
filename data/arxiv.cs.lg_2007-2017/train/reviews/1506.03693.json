{"conference": "NIPS", "VERSION": "v1", "DATE_OF_SUBMISSION": "11-Jun-2015", "title": "Optimization Monte Carlo: Efficient and Embarrassingly Parallel Likelihood-Free Inference", "abstract": "We describe an embarrassingly parallel, anytime Monte Carlo method for likelihood-free models. The algorithm starts with the view that the stochasticity of the pseudo-samples generated by the simulator can be controlled externally by a vector of random numbers u, in such a way that the outcome, knowing u, is deterministic. For each instantiation of u we run an optimization procedure to minimize the distance between summary statistics of the simulator and the data. After reweighing these samples using the prior and the Jacobian (accounting for the change of volume in transforming from the space of summary statistics to the space of parameters) we show that this weighted ensemble represents a Monte Carlo estimate of the posterior distribution. The procedure can be run embarrassingly parallel (each node handling one sample) and anytime (by allocating resources to the worst performing sample). The procedure is validated on six experiments.", "histories": [["v1", "Thu, 11 Jun 2015 14:45:30 GMT  (1656kb,D)", "https://arxiv.org/abs/1506.03693v1", "NIPS 2015 submission"], ["v2", "Wed, 2 Dec 2015 18:58:09 GMT  (1646kb,D)", "http://arxiv.org/abs/1506.03693v2", "NIPS 2015 camera ready"]], "COMMENTS": "NIPS 2015 submission", "reviews": [], "SUBJECTS": "cs.LG stat.ML", "authors": ["edward meeds", "max welling"], "accepted": true, "id": "1506.03693"}
