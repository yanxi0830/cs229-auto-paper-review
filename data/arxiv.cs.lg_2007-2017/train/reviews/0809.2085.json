{"conference": "NIPS", "VERSION": "v1", "DATE_OF_SUBMISSION": "11-Sep-2008", "title": "Clustered Multi-Task Learning: A Convex Formulation", "abstract": "In multi-task learning several related tasks are considered simultaneously, with the hope that by an appropriate sharing of information across tasks, each task may benefit from the others. In the context of learning linear functions for supervised classification or regression, this can be achieved by including a priori information about the weight vectors associated with the tasks, and how they are expected to be related to each other. In this paper, we assume that tasks are clustered into groups, which are unknown beforehand, and that tasks within a group have similar weight vectors. We design a new spectral norm that encodes this a priori assumption, without the prior knowledge of the partition of tasks into groups, resulting in a new convex optimization formulation for multi-task learning. We show in simulations on synthetic examples and on the IEDB MHC-I binding dataset, that our approach outperforms well-known convex methods for multi-task learning, as well as related non convex methods dedicated to the same problem.", "histories": [["v1", "Thu, 11 Sep 2008 19:01:39 GMT  (19kb)", "http://arxiv.org/abs/0809.2085v1", null]], "reviews": [], "SUBJECTS": "cs.LG", "authors": ["laurent jacob", "francis r bach", "jean-philippe vert"], "accepted": true, "id": "0809.2085"}
