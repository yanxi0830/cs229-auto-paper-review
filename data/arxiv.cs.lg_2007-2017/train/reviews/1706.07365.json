{"conference": "nips", "VERSION": "v1", "DATE_OF_SUBMISSION": "22-Jun-2017", "title": "Pixels to Graphs by Associative Embedding", "abstract": "Graphs are a useful abstraction of image content. Not only can graphs represent details about individual objects in a scene but they can capture the interactions between pairs of objects. We present a method for training a convolutional neural network such that it takes in an input image and produces a full graph. This is done end-to-end in a single stage with the use of associative embeddings. The network learns to simultaneously identify all of the elements that make up a graph and piece them together. We benchmark on the Visual Genome dataset, and report a Recall@50 of 9.7% compared to the prior state-of-the-art at 3.4%, a nearly threefold improvement on the challenging task of scene graph generation.", "histories": [["v1", "Thu, 22 Jun 2017 15:20:25 GMT  (4886kb,D)", "http://arxiv.org/abs/1706.07365v1", null]], "reviews": [], "SUBJECTS": "cs.CV cs.LG", "authors": ["alejandro newell", "jia deng"], "accepted": true, "id": "1706.07365"}
