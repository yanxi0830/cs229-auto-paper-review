{"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "28-Feb-2017", "title": "Learning Deep Nearest Neighbor Representations Using Differentiable Boundary Trees", "abstract": "Nearest neighbor (kNN) methods have been gaining popularity in recent years in light of advances in hardware and efficiency of algorithms. There is a plethora of methods to choose from today, each with their own advantages and disadvantages. One requirement shared between all kNN based methods is the need for a good representation and distance measure between samples.", "histories": [["v1", "Tue, 28 Feb 2017 16:01:22 GMT  (660kb,D)", "http://arxiv.org/abs/1702.08833v1", null]], "reviews": [], "SUBJECTS": "cs.LG", "authors": ["daniel zoran", "balaji lakshminarayanan", "charles blundell"], "accepted": false, "id": "1702.08833"}
