{"conference": "NIPS", "VERSION": "v1", "DATE_OF_SUBMISSION": "29-Sep-2014", "title": "Adaptive Low-Complexity Sequential Inference for Dirichlet Process Mixture Models", "abstract": "We develop a sequential low-complexity inference procedure for the Infinite Gaussian Mixture Model (IGMM) for the general case of an unknown mean and covariance. The observations are sequentially allocated to classes based on a sequential maximum a-posterior (MAP) criterion. We present an easily computed, closed form for the conditional likelihood, in which the parameters can be recursively updated as a function of the streaming data. We propose a novel adaptive design for the Dirichlet process concentration parameter at each iteration, and prove, under a simplified model, that the sequence of concentration parameters is asymptotically well-behaved. We sketch an equivalence between the steady-state performance of the algorithm and Gaussian classification. The methodology is applied to the problem of adaptive modulation recognition and obviates the need for storing a large modulation library required for traditional modulation recognition. We also numerically evaluate the bit error rate performance (BER) of the DPMM-trained classifier when used as a demodulator and show that there is critical signal-to-noise ratio (SNR) that characterizes whether successful decoding is possible.", "histories": [["v1", "Mon, 29 Sep 2014 16:47:44 GMT  (472kb,D)", "https://arxiv.org/abs/1409.8185v1", "31 pages, Submitted"], ["v2", "Thu, 5 Feb 2015 15:55:06 GMT  (1062kb,D)", "http://arxiv.org/abs/1409.8185v2", "27 pages, Submitted"], ["v3", "Fri, 11 Sep 2015 20:07:31 GMT  (671kb,D)", "http://arxiv.org/abs/1409.8185v3", "25 pages, To appear in Advances in Neural Information Processing Systems (NIPS) 2015"]], "COMMENTS": "31 pages, Submitted", "reviews": [], "SUBJECTS": "stat.ML cs.LG stat.ME", "authors": ["theodoros tsiligkaridis", "keith w forsythe"], "accepted": true, "id": "1409.8185"}
