{"conference": "ICML", "VERSION": "v1", "DATE_OF_SUBMISSION": "2-Jun-2015", "title": "Optimal Regret Analysis of Thompson Sampling in Stochastic Multi-armed Bandit Problem with Multiple Plays", "abstract": "We discuss a multiple-play multi-armed bandit (MAB) problem in which several arms are selected at each round. Recently, Thompson sampling (TS), a randomized algorithm with a Bayesian spirit, has attracted much attention for its empirically excellent performance, and it is revealed to have an optimal regret bound in the standard single-play MAB problem. In this paper, we propose the multiple-play Thompson sampling (MP-TS) algorithm, an extension of TS to the multiple-play MAB problem, and discuss its regret analysis. We prove that MP-TS for binary rewards has the optimal regret upper bound that matches the regret lower bound provided by Anantharam et al. (1987). Therefore, MP-TS is the first computationally efficient algorithm with optimal regret. A set of computer simulations was also conducted, which compared MP-TS with state-of-the-art algorithms. We also propose a modification of MP-TS, which is shown to have better empirical performance.", "histories": [["v1", "Tue, 2 Jun 2015 07:42:16 GMT  (660kb,D)", "http://arxiv.org/abs/1506.00779v1", "17 pages, 7 figures, to appear in ICML2015"], ["v2", "Tue, 24 May 2016 12:21:19 GMT  (673kb,D)", "http://arxiv.org/abs/1506.00779v2", "Appeared in ICML2015. Fixed the evaluation of term (B) in Lemma 3"]], "COMMENTS": "17 pages, 7 figures, to appear in ICML2015", "reviews": [], "SUBJECTS": "stat.ML cs.LG", "authors": ["junpei komiyama", "junya honda", "hiroshi nakagawa"], "accepted": true, "id": "1506.00779"}
