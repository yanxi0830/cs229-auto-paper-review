{"conference": "NIPS", "VERSION": "v1", "DATE_OF_SUBMISSION": "29-Mar-2017", "title": "Probabilistic Line Searches for Stochastic Optimization", "abstract": "In deterministic optimization, line searches are a standard tool ensuring stability and efficiency. Where only stochastic gradients are available, no direct equivalent has so far been formulated, because uncertain gradients do not allow for a strict sequence of decisions collapsing the search space. We construct a probabilistic line search by combining the structure of existing deterministic methods with notions from Bayesian optimization. Our method retains a Gaussian process surrogate of the univariate optimization objective, and uses a probabilistic belief over the Wolfe conditions to monitor the descent. The algorithm has very low computational cost, and no user-controlled parameters. Experiments show that it effectively removes the need to define a learning rate for stochastic gradient descent.", "histories": [["v1", "Wed, 29 Mar 2017 13:43:52 GMT  (3736kb,D)", "https://arxiv.org/abs/1703.10034v1", "Extended version of the NIPS '15 conference paper, includes detailed pseudo-code, 51 pages, 30 figures"], ["v2", "Fri, 30 Jun 2017 16:18:08 GMT  (4490kb,D)", "http://arxiv.org/abs/1703.10034v2", "Extended version of the NIPS '15 conference paper, includes detailed pseudo-code, 59 pages, 35 figures"]], "COMMENTS": "Extended version of the NIPS '15 conference paper, includes detailed pseudo-code, 51 pages, 30 figures", "reviews": [], "SUBJECTS": "cs.LG stat.ML", "authors": ["maren mahsereci", "philipp hennig"], "accepted": true, "id": "1703.10034"}
