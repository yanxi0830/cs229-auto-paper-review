{"conference": "NIPS", "VERSION": "v1", "DATE_OF_SUBMISSION": "24-Jun-2014", "title": "Recurrent Models of Visual Attention", "abstract": "Applying convolutional neural networks to large images is computationally expensive because the amount of computation scales linearly with the number of image pixels. We present a novel recurrent neural network model that is capable of extracting information from an image or video by adaptively selecting a sequence of regions or locations and only processing the selected regions at high resolution. Like convolutional neural networks, the proposed model has a degree of translation invariance built-in, but the amount of computation it performs can be controlled independently of the input image size. While the model is non-differentiable, it can be trained using reinforcement learning methods to learn task-specific policies. We evaluate our model on several image classification tasks, where it significantly outperforms a convolutional neural network baseline on cluttered images, and on a dynamic visual control problem, where it learns to track a simple object without an explicit training signal for doing so.", "histories": [["v1", "Tue, 24 Jun 2014 14:16:56 GMT  (982kb,D)", "http://arxiv.org/abs/1406.6247v1", null]], "reviews": [], "SUBJECTS": "cs.LG cs.CV stat.ML", "authors": ["volodymyr mnih", "nicolas heess", "alex graves", "koray kavukcuoglu"], "accepted": true, "id": "1406.6247"}
