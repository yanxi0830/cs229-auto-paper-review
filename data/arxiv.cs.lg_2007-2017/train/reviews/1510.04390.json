{"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "15-Oct-2015", "title": "Dual Principal Component Pursuit", "abstract": "We consider the problem of outlier rejection in single subspace learning. Classical approaches work directly with a low-dimensional representation of the subspace. Our approach works with a dual representation of the subspace and hence aims to find its orthogonal complement. We pose this problem as an $\\ell_1$-minimization problem on the sphere and show that, under certain conditions on the distribution of the data, any global minimizer of this non-convex problem gives a vector orthogonal to the subspace. Moreover, we show that such a vector can still be found by relaxing the non-convex problem with a sequence of linear programs. Experiments on synthetic and real data show that the proposed approach, which we call Dual Principal Component Pursuit (DPCP), outperforms state-of-the art methods, especially in the case of high-dimensional subspaces.", "histories": [["v1", "Thu, 15 Oct 2015 03:50:01 GMT  (215kb,D)", "http://arxiv.org/abs/1510.04390v1", null], ["v2", "Sun, 4 Jun 2017 21:42:05 GMT  (3261kb)", "http://arxiv.org/abs/1510.04390v2", null], ["v3", "Sat, 22 Jul 2017 16:24:27 GMT  (862kb,D)", "http://arxiv.org/abs/1510.04390v3", null]], "reviews": [], "SUBJECTS": "cs.CV cs.LG", "authors": ["manolis c tsakiris", "rene vidal"], "accepted": false, "id": "1510.04390"}
