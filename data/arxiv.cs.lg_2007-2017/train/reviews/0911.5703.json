{"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "30-Nov-2009", "title": "Hierarchies in Dictionary Definition Space", "abstract": "A dictionary defines words in terms of other words. Definitions can tell you the meanings of words you don't know, but only if you know the meanings of the defining words. How many words do you need to know (and which ones) in order to be able to learn all the rest from definitions? We reduced dictionaries to their \"grounding kernels\" (GKs), about 10% of the dictionary, from which all the other words could be defined. The GK words turned out to have psycholinguistic correlates: they were learned at an earlier age and more concrete than the rest of the dictionary. But one can compress still more: the GK turns out to have internal structure, with a strongly connected \"kernel core\" (KC) and a surrounding layer, from which a hierarchy of definitional distances can be derived, all the way out to the periphery of the full dictionary. These definitional distances, too, are correlated with psycholinguistic variables (age of acquisition, concreteness, imageability, oral and written frequency) and hence perhaps with the \"mental lexicon\" in each of our heads.", "histories": [["v1", "Mon, 30 Nov 2009 18:15:35 GMT  (18kb)", "http://arxiv.org/abs/0911.5703v1", "9 pages, 5 figues, 2 tables, 12 references, 23rd Annual Conference on Neural Information Processing Systems (NIPS): Workshop on Analyzing Networks and Learning With Graphsthis http URL"]], "COMMENTS": "9 pages, 5 figues, 2 tables, 12 references, 23rd Annual Conference on Neural Information Processing Systems (NIPS): Workshop on Analyzing Networks and Learning With Graphsthis http URL", "reviews": [], "SUBJECTS": "cs.CL cs.LG", "authors": ["olivier picard", "alexandre blondin-masse", "stevan harnad", "odile marcotte", "guillaume chicoisne", "yassine gargouri"], "accepted": false, "id": "0911.5703"}
