{"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "22-May-2017", "title": "An Out-of-the-box Full-network Embedding for Convolutional Neural Networks", "abstract": "Transfer learning for feature extraction can be used to exploit deep representations in contexts where there is very few training data, where there are limited computational resources, or when tuning the hyper-parameters needed for training is not an option. While previous contributions to feature extraction propose embeddings based on a single layer of the network, in this paper we propose a full-network embedding which successfully integrates convolutional and fully connected features, coming from all layers of a deep convolutional neural network. To do so, the embedding normalizes features in the context of the problem, and discretizes their values to reduce noise and regularize the embedding space. Significantly, this also reduces the computational cost of processing the resultant representations. The proposed method is shown to outperform single layer embeddings on several image classification tasks, while also being more robust to the choice of the pre-trained model used for obtaining the initial features. The performance gap in classification accuracy between thoroughly tuned solutions and the full-network embedding is also reduced, which makes of the proposed approach a competitive solution for a large set of applications.", "histories": [["v1", "Mon, 22 May 2017 13:14:11 GMT  (182kb,D)", "http://arxiv.org/abs/1705.07706v1", null]], "reviews": [], "SUBJECTS": "cs.LG cs.NE", "authors": ["dario garcia-gasulla", "armand vilalta", "ferran par\\'es", "jonatan moreno", "eduard ayguad\\'e", "jesus labarta", "ulises cort\\'es", "toyotaro suzumura"], "accepted": false, "id": "1705.07706"}
