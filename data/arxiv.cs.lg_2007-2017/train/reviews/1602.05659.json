{"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "18-Feb-2016", "title": "Boost Picking: A Universal Method on Converting Supervised Classification to Semi-supervised Classification", "abstract": "This paper proposes a universal method, Boost Picking, to train supervised classification models mainly by un-labeled data. Boost Picking only adopts two weak classifiers to estimate and correct the error. It is theoretically proved that Boost Picking could train a supervised model mainly by un-labeled data as effectively as the same model trained by 100% labeled data, only if recalls of the two weak classifiers are all greater than zero and the sum of precisions is greater than one. Based on Boost Picking, we present \"Test along with Training (TawT)\" to improve the generalization of supervised models. Both Boost Picking and TawT are successfully tested in varied little data sets.", "histories": [["v1", "Thu, 18 Feb 2016 02:24:54 GMT  (851kb,D)", "http://arxiv.org/abs/1602.05659v1", "9 pages, 9 figures"], ["v2", "Mon, 29 Feb 2016 13:16:23 GMT  (841kb,D)", "http://arxiv.org/abs/1602.05659v2", "9 pages, 9 figures"], ["v3", "Sat, 12 Nov 2016 09:25:54 GMT  (0kb,I)", "http://arxiv.org/abs/1602.05659v3", "This paper has been withdraw by the author due to format error"]], "COMMENTS": "9 pages, 9 figures", "reviews": [], "SUBJECTS": "cs.CV cs.LG", "authors": ["fuqiang liu", "fukun bi", "yiding yang", "liang chen"], "accepted": false, "id": "1602.05659"}
