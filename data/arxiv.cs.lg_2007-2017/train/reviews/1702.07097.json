{"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "23-Feb-2017", "title": "Bidirectional Backpropagation: Towards Biologically Plausible Error Signal Transmission in Neural Networks", "abstract": "The back-propagation (BP) algorithm has been considered the de facto method for training deep neural networks. It back-propagates errors from the output layer to the hidden layers in an exact manner using feedforward weights. In this work, we propose a more biologically plausible paradigm of neural architecture according to biological findings. Specifically, we propose two bidirectional learning algorithms with two sets of trainable weights. Preliminary results show that our models perform best on the MNIST and the CIFAR10 datasets among the asymmetric error signal passing methods, and their performance is more close to that of BP.", "histories": [["v1", "Thu, 23 Feb 2017 05:00:54 GMT  (837kb,D)", "https://arxiv.org/abs/1702.07097v1", null], ["v2", "Sun, 26 Feb 2017 16:41:35 GMT  (971kb,D)", "http://arxiv.org/abs/1702.07097v2", "Extended the paper to the length of a long paper; added references in introduction; corrected the experiments of BFA"], ["v3", "Mon, 20 Mar 2017 01:16:07 GMT  (993kb,D)", "http://arxiv.org/abs/1702.07097v3", "[v2]Extended the paper to the length of a long paper; added references in introduction; corrected the experiments of BFA. [v3] Added link to source code"]], "reviews": [], "SUBJECTS": "cs.NE cs.LG", "authors": ["hongyin luo", "jie fu", "james glass"], "accepted": false, "id": "1702.07097"}
