{"conference": "NIPS", "VERSION": "v1", "DATE_OF_SUBMISSION": "29-Sep-2016", "title": "Fast learning rates with heavy-tailed losses", "abstract": "We study fast learning rates when the losses are not necessarily bounded and may have a distribution with heavy tails. To enable such analyses, we introduce two new conditions: (i) the envelope function $\\sup_{f \\in \\mathcal{F}}|\\ell \\circ f|$, where $\\ell$ is the loss function and $\\mathcal{F}$ is the hypothesis class, exists and is $L^r$-integrable, and (ii) $\\ell$ satisfies the multi-scale Bernstein's condition on $\\mathcal{F}$. Under these assumptions, we prove that learning rate faster than $O(n^{-1/2})$ can be obtained and, depending on $r$ and the multi-scale Bernstein's powers, can be arbitrarily close to $O(n^{-1})$. We then verify these assumptions and derive fast learning rates for the problem of vector quantization by $k$-means clustering with heavy-tailed distributions. The analyses enable us to obtain novel learning rates that extend and complement existing results in the literature from both theoretical and practical viewpoints.", "histories": [["v1", "Thu, 29 Sep 2016 19:46:13 GMT  (18kb)", "http://arxiv.org/abs/1609.09481v1", "Advances in Neural Information Processing Systems (NIPS 2016): 11 pages"]], "COMMENTS": "Advances in Neural Information Processing Systems (NIPS 2016): 11 pages", "reviews": [], "SUBJECTS": "stat.ML cs.LG", "authors": ["vu c dinh", "lam s ho", "binh t nguyen", "duy m h nguyen"], "accepted": true, "id": "1609.09481"}
