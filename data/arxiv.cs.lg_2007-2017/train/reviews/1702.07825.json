{"conference": "ICML", "VERSION": "v1", "DATE_OF_SUBMISSION": "25-Feb-2017", "title": "Deep Voice: Real-time Neural Text-to-Speech", "abstract": "We present Deep Voice, a production-quality text-to-speech system constructed entirely from deep neural networks. Deep Voice lays the groundwork for truly end-to-end neural speech synthesis. The system comprises five major building blocks: a segmentation model for locating phoneme boundaries, a grapheme-to-phoneme conversion model, a phoneme duration prediction model, a fundamental frequency prediction model, and an audio synthesis model. For the segmentation model, we propose a novel way of performing phoneme boundary detection with deep neural networks using connectionist temporal classification (CTC) loss. For the audio synthesis model, we implement a variant of WaveNet that requires fewer parameters and trains faster than the original. By using a neural network for each component, our system is simpler and more flexible than traditional text-to-speech systems, where each component requires laborious feature engineering and extensive domain expertise. Finally, we show that inference with our system can be performed faster than real time and describe optimized WaveNet inference kernels on both CPU and GPU that achieve up to 400x speedups over existing implementations.", "histories": [["v1", "Sat, 25 Feb 2017 03:11:04 GMT  (123kb,D)", "http://arxiv.org/abs/1702.07825v1", "Submitted to ICML 2017"], ["v2", "Tue, 7 Mar 2017 23:09:23 GMT  (123kb,D)", "http://arxiv.org/abs/1702.07825v2", "Submitted to ICML 2017"]], "COMMENTS": "Submitted to ICML 2017", "reviews": [], "SUBJECTS": "cs.CL cs.LG cs.NE cs.SD", "authors": ["sercan \u00f6mer arik", "mike chrzanowski", "adam coates", "gregory frederick diamos", "andrew gibiansky", "yongguo kang", "xian li", "john miller", "andrew y ng", "jonathan raiman", "shubho sengupta", "mohammad shoeybi"], "accepted": true, "id": "1702.07825"}
