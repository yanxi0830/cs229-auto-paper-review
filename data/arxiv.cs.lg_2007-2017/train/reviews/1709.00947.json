{"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "4-Sep-2017", "title": "Learning Word Embeddings from the Portuguese Twitter Stream: A Study of some Practical Aspects", "abstract": "This paper describes a preliminary study for producing and distributing a large-scale database of embeddings from the Portuguese Twitter stream. We start by experimenting with a relatively small sample and focusing on three challenges: volume of training data, vocabulary size and intrinsic evaluation metrics. Using a single GPU, we were able to scale up vocabulary size from 2048 words embedded and 500K training examples to 32768 words over 10M training examples while keeping a stable validation loss and approximately linear trend on training time per epoch. We also observed that using less than 50\\% of the available training examples for each vocabulary size might result in overfitting. Results on intrinsic evaluation show promising performance for a vocabulary size of 32768 words. Nevertheless, intrinsic evaluation metrics suffer from over-sensitivity to their corresponding cosine similarity thresholds, indicating that a wider range of metrics need to be developed to track progress.", "histories": [["v1", "Mon, 4 Sep 2017 13:30:23 GMT  (178kb,D)", "http://arxiv.org/abs/1709.00947v1", null]], "reviews": [], "SUBJECTS": "cs.CL cs.LG", "authors": ["pedro saleiro", "lu\\'is sarmento", "eduarda mendes rodrigues", "carlos soares", "eug\\'enio oliveira"], "accepted": false, "id": "1709.00947"}
