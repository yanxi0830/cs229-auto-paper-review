{"conference": "iclr", "VERSION": "v1", "DATE_OF_SUBMISSION": "3-Jun-2016", "title": "Zoneout: Regularizing RNNs by Randomly Preserving Hidden Activations", "abstract": "We propose zoneout, a novel method for regularizing RNNs. At each timestep, zoneout stochastically forces some hidden units to maintain their previous values. Like dropout, zoneout uses random noise to train a pseudo-ensemble, improving generalization. But by preserving instead of dropping hidden units, gradient information and state information are more readily propagated through time, as in feedforward stochastic depth networks. We perform an empirical investigation of various RNN regularizers, and find encouraging results: zoneout gives significant performance improvements across tasks, yielding state-of-the-art results in character-level language modeling on the Penn Treebank dataset and competitive results on word-level Penn Treebank and permuted sequential MNIST classification tasks.", "histories": [["v1", "Fri, 3 Jun 2016 23:31:47 GMT  (877kb,D)", "http://arxiv.org/abs/1606.01305v1", null], ["v2", "Mon, 13 Jun 2016 18:59:48 GMT  (877kb,D)", "http://arxiv.org/abs/1606.01305v2", null], ["v3", "Wed, 18 Jan 2017 03:12:03 GMT  (1270kb,D)", "http://arxiv.org/abs/1606.01305v3", null], ["v4", "Fri, 22 Sep 2017 20:43:09 GMT  (1270kb,D)", "http://arxiv.org/abs/1606.01305v4", "David Krueger and Tegan Maharaj contributed equally to this work"]], "reviews": [], "SUBJECTS": "cs.NE cs.CL cs.LG", "authors": ["david krueger", "tegan maharaj", "j\\'anos kram\\'ar", "mohammad pezeshki", "nicolas ballas", "nan rosemary ke", "anirudh goyal", "yoshua bengio", "aaron courville", "chris pal"], "accepted": true, "id": "1606.01305"}
