{"conference": "NIPS", "VERSION": "v1", "DATE_OF_SUBMISSION": "8-Feb-2016", "title": "Generating Images with Perceptual Similarity Metrics based on Deep Networks", "abstract": "Image-generating machine learning models are typically trained with loss functions based on distance in the image space. This often leads to over-smoothed results. We propose a class of loss functions, which we call deep perceptual similarity metrics (DeePSiM), that mitigate this problem. Instead of computing distances in the image space, we compute distances between image features extracted by deep neural networks. This metric better reflects perceptually similarity of images and thus leads to better results. We show three applications: autoencoder training, a modification of a variational autoencoder, and inversion of deep convolutional networks. In all cases, the generated images look sharp and resemble natural images.", "histories": [["v1", "Mon, 8 Feb 2016 16:50:28 GMT  (14140kb,D)", "http://arxiv.org/abs/1602.02644v1", null], ["v2", "Tue, 9 Feb 2016 09:36:36 GMT  (14294kb,D)", "http://arxiv.org/abs/1602.02644v2", "minor corrections"]], "reviews": [], "SUBJECTS": "cs.LG cs.CV cs.NE", "authors": ["alexey dosovitskiy", "thomas brox"], "accepted": true, "id": "1602.02644"}
