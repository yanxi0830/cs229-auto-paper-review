{"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "30-Dec-2014", "title": "Disjunctive Normal Networks", "abstract": "Artificial neural networks are powerful pattern classifiers; however, they have been surpassed in accuracy by methods such as support vector machines and random forests that are also easier to use and faster to train. Backpropagation, which is used to train artificial neural networks, suffers from the herd effect problem which leads to long training times and limit classification accuracy. We use the disjunctive normal form and approximate the boolean conjunction operations with products to construct a novel network architecture. The proposed model can be trained by minimizing an error function and it allows an effective and intuitive initialization which solves the herd-effect problem associated with backpropagation. This leads to state-of-the art classification accuracy and fast training times. In addition, our model can be jointly optimized with convolutional features in an unified structure leading to state-of-the-art results on computer vision problems with fast convergence rates. A GPU implementation of LDNN with optional convolutional features is also available", "histories": [["v1", "Tue, 30 Dec 2014 02:17:30 GMT  (611kb,D)", "http://arxiv.org/abs/1412.8534v1", null]], "reviews": [], "SUBJECTS": "cs.LG cs.NE", "authors": ["mehdi sajjadi", "mojtaba seyedhosseini", "tolga tasdizen"], "accepted": false, "id": "1412.8534"}
