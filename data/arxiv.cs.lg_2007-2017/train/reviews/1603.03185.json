{"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "10-Mar-2016", "title": "Personalized Speech recognition on mobile devices", "abstract": "We describe a large vocabulary speech recognition system that is accurate, has low latency, and yet has a small enough memory and computational footprint to run faster than real-time on a Nexus 5 Android smartphone. We employ a quantized Long Short-Term Memory (LSTM) acoustic model trained with connectionist temporal classification (CTC) to directly predict phoneme targets, and further reduce its memory footprint using an SVD-based compression scheme. Additionally, we minimize our memory footprint by using a single language model for both dictation and voice command domains, constructed using Bayesian interpolation. Finally, in order to properly handle device-specific information, such as proper names and other context-dependent information, we inject vocabulary items into the decoder graph and bias the language model on-the-fly. Our system achieves 13.5\\% word error rate on an open-ended dictation task, running with a median speed that is seven times faster than real-time.", "histories": [["v1", "Thu, 10 Mar 2016 08:51:51 GMT  (61kb,D)", "http://arxiv.org/abs/1603.03185v1", null], ["v2", "Fri, 11 Mar 2016 22:25:39 GMT  (61kb,D)", "http://arxiv.org/abs/1603.03185v2", null]], "reviews": [], "SUBJECTS": "cs.CL cs.LG cs.SD", "authors": ["ian mcgraw", "rohit prabhavalkar", "raziel alvarez", "montse gonzalez arenas", "kanishka rao", "david rybach", "ouais alsharif", "hasim sak", "alexander gruenstein", "francoise beaufays", "carolina parada"], "accepted": false, "id": "1603.03185"}
