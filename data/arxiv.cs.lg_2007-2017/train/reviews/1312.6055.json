{"conference": "iclr", "VERSION": "v1", "DATE_OF_SUBMISSION": "20-Dec-2013", "title": "Unit Tests for Stochastic Optimization", "abstract": "Optimization by stochastic gradient descent is an important component of many large-scale machine learning algorithms. A wide variety of such optimization algorithms have been devised; however, it is unclear whether these algorithms are robust and widely applicable across many different optimization landscapes. In this paper we develop a collection of unit tests for stochastic optimization. Each unit test rapidly evaluates an optimization algorithm on a small-scale, isolated, and well-understood difficulty, rather than in real-world scenarios where many such issues are entangled. Passing these unit tests is not sufficient, but absolutely necessary for any algorithms with claims to generality or robustness. We give initial quantitative and qualitative results on a dozen established algorithms. The testing framework is open-source, extensible, and easy to apply to new algorithms.", "histories": [["v1", "Fri, 20 Dec 2013 17:44:06 GMT  (2443kb)", "http://arxiv.org/abs/1312.6055v1", "Initial submission to ICLR 2014"], ["v2", "Tue, 7 Jan 2014 20:43:40 GMT  (2923kb)", "http://arxiv.org/abs/1312.6055v2", "Submission to ICLR 2014 (revised for minor improvements, pre-reviews)"], ["v3", "Tue, 25 Feb 2014 18:16:54 GMT  (7536kb,D)", "http://arxiv.org/abs/1312.6055v3", "Final submission to ICLR 2014 (revised according to reviews, additional results added)"]], "COMMENTS": "Initial submission to ICLR 2014", "reviews": [], "SUBJECTS": "cs.LG", "authors": ["tom schaul", "ioannis antonoglou", "david silver"], "accepted": true, "id": "1312.6055"}
