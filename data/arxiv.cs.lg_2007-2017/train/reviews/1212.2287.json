{"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "11-Dec-2012", "title": "Runtime Optimizations for Prediction with Tree-Based Models", "abstract": "Tree-based models have proven to be an effective solution for web ranking as well as other problems in diverse domains. This paper focuses on optimizing the runtime performance of applying such models to make predictions, given an already-trained model. Although exceedingly simple conceptually, most implementations of tree-based models do not efficiently utilize modern superscalar processor architectures. By laying out data structures in memory in a more cache-conscious fashion, removing branches from the execution flow using a technique called predication, and micro-batching predictions using a technique called vectorization, we are able to better exploit modern processor architectures and significantly improve the speed of tree-based models over hard-coded if-else blocks. Our work represents the first instance of an architecture-conscious runtime implementation of tree-based models that we are aware of.", "histories": [["v1", "Tue, 11 Dec 2012 03:20:46 GMT  (61kb,D)", "https://arxiv.org/abs/1212.2287v1", null], ["v2", "Fri, 26 Apr 2013 16:33:08 GMT  (60kb,D)", "http://arxiv.org/abs/1212.2287v2", null]], "reviews": [], "SUBJECTS": "cs.DB cs.IR cs.LG", "authors": ["nima asadi", "jimmy lin", "arjen p de vries"], "accepted": false, "id": "1212.2287"}
