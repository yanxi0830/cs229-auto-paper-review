{"conference": "iclr", "VERSION": "v1", "DATE_OF_SUBMISSION": "7-Oct-2016", "title": "Temporal Ensembling for Semi-Supervised Learning", "abstract": "In this paper, we present a simple and efficient method for training deep neural networks in a semi-supervised setting where only a small portion of training data is labeled. We introduce temporal ensembling, where we form a consensus prediction of the unknown labels under multiple instances of the network-in-training on different epochs, and most importantly, under different regularization and input augmentation conditions. This ensemble prediction can be expected to be a better predictor for the unknown labels than the output of the network at the most recent training epoch, and can thus be used as a target for training. Using our method, we set new records for two standard semi-supervised learning benchmarks, reducing the classification error rate from 18.63% to 12.89% in CIFAR-10 with 4000 labels and from 18.44% to 6.83% in SVHN with 500 labels.", "histories": [["v1", "Fri, 7 Oct 2016 12:15:42 GMT  (21kb,D)", "http://arxiv.org/abs/1610.02242v1", null], ["v2", "Mon, 7 Nov 2016 13:27:40 GMT  (99kb,D)", "http://arxiv.org/abs/1610.02242v2", "This version was submitted to ICLR 2017. The two methods are now closer to each other and use similar parameters. Also added more experimental results and a test with corrupted labels. Code released"], ["v3", "Wed, 15 Mar 2017 14:22:41 GMT  (101kb,D)", "http://arxiv.org/abs/1610.02242v3", "Final ICLR 2017 version. Includes new results for CIFAR-100 with additional unlabeled data from Tiny Images dataset"]], "reviews": [], "SUBJECTS": "cs.NE cs.LG", "authors": ["samuli laine", "timo aila"], "accepted": true, "id": "1610.02242"}
