{"conference": "AAAI", "VERSION": "v1", "DATE_OF_SUBMISSION": "17-Sep-2015", "title": "Generalized Emphatic Temporal Difference Learning: Bias-Variance Analysis", "abstract": "We consider the off-policy evaluation problem in Markov decision processes with function approximation. We propose a generalization of the recently introduced \\emph{emphatic temporal differences} (ETD) algorithm \\citep{SuttonMW15}, which encompasses the original ETD($\\lambda$), as well as several other off-policy evaluation algorithms as special cases. We call this framework \\ETD, where our introduced parameter $\\beta$ controls the decay rate of an importance-sampling term. We study conditions under which the projected fixed-point equation underlying \\ETD\\ involves a contraction operator, allowing us to present the first asymptotic error bounds (bias) for \\ETD. Our results show that the original ETD algorithm always involves a contraction operator, and its bias is bounded. Moreover, by controlling $\\beta$, our proposed generalization allows trading-off bias for variance reduction, thereby achieving a lower total error.", "histories": [["v1", "Thu, 17 Sep 2015 09:03:35 GMT  (219kb)", "https://arxiv.org/abs/1509.05172v1", "arXiv admin note: text overlap witharXiv:1508.03411"], ["v2", "Fri, 27 Nov 2015 07:17:55 GMT  (214kb)", "http://arxiv.org/abs/1509.05172v2", "arXiv admin note: text overlap witharXiv:1508.03411"]], "COMMENTS": "arXiv admin note: text overlap witharXiv:1508.03411", "reviews": [], "SUBJECTS": "stat.ML cs.LG", "authors": ["assaf hallak", "aviv tamar", "r\u00e9mi munos", "shie mannor"], "accepted": true, "id": "1509.05172"}
