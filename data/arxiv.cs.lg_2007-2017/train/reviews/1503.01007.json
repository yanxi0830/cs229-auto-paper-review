{"conference": "NIPS", "VERSION": "v1", "DATE_OF_SUBMISSION": "3-Mar-2015", "title": "Inferring Algorithmic Patterns with Stack-Augmented Recurrent Nets", "abstract": "While machine learning is currently very successful in several application domains, we are still very far from a real Artificial Intelligence. In this paper, we study basic sequence prediction problems that are beyond the scope of what is learnable with popular methods such as recurrent networks. We show that simple algorithms can be learnt from sequential data with a recurrent network associated with trainable stacks. We focus our study on algorithmically generated sequences such as $a^n b^{n}$, that can only be learnt by models which have the capacity to count. Our study highlights certain topics in machine learning that deserve more attention, such as addressing the shortcomings of purely gradient based training of non-convex models. We achieve progress in this direction by incorporating search based strategy. Once trained, we show that our method is able generalize to sequences up to an arbitrary size.", "histories": [["v1", "Tue, 3 Mar 2015 16:50:28 GMT  (662kb,D)", "http://arxiv.org/abs/1503.01007v1", null], ["v2", "Fri, 6 Mar 2015 22:41:39 GMT  (669kb,D)", "http://arxiv.org/abs/1503.01007v2", null], ["v3", "Wed, 20 May 2015 19:23:44 GMT  (552kb,D)", "http://arxiv.org/abs/1503.01007v3", null], ["v4", "Mon, 1 Jun 2015 20:37:55 GMT  (510kb,D)", "http://arxiv.org/abs/1503.01007v4", null]], "reviews": [], "SUBJECTS": "cs.NE cs.LG", "authors": ["armand joulin", "tomas mikolov"], "accepted": true, "id": "1503.01007"}
