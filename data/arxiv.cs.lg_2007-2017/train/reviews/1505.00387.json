{"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "3-May-2015", "title": "Highway Networks", "abstract": "There is plenty of theoretical and empirical evidence that depth of neural networks is a crucial ingredient for their success. However, network training becomes more difficult with increasing depth and training of very deep networks remains an open problem. In this extended abstract, we introduce a new architecture designed to ease gradient-based training of very deep networks. We refer to networks with this architecture as highway networks, since they allow unimpeded information flow across several layers on \"information highways\". The architecture is characterized by the use of gating units which learn to regulate the flow of information through a network. Highway networks with hundreds of layers can be trained directly using stochastic gradient descent and with a variety of activation functions, opening up the possibility of studying extremely deep and efficient architectures.", "histories": [["v1", "Sun, 3 May 2015 01:56:57 GMT  (311kb,D)", "http://arxiv.org/abs/1505.00387v1", "Extended Abstract. 6 pages, 2 figures"], ["v2", "Tue, 3 Nov 2015 18:15:15 GMT  (319kb,D)", "http://arxiv.org/abs/1505.00387v2", "6 pages, 2 figures. Presented at ICML 2015 Deep Learning workshop. Full paper is atarXiv:1507.06228"]], "COMMENTS": "Extended Abstract. 6 pages, 2 figures", "reviews": [], "SUBJECTS": "cs.LG cs.NE", "authors": ["rupesh kumar srivastava", "klaus greff", "j\\\"urgen schmidhuber"], "accepted": false, "id": "1505.00387"}
