{"conference": "NIPS", "VERSION": "v1", "DATE_OF_SUBMISSION": "4-Dec-2013", "title": "Multiscale Dictionary Learning for Estimating Conditional Distributions", "abstract": "Nonparametric estimation of the conditional distribution of a response given high-dimensional features is a challenging problem. It is important to allow not only the mean but also the variance and shape of the response density to change flexibly with features, which are massive-dimensional. We propose a multiscale dictionary learning model, which expresses the conditional response density as a convex combination of dictionary densities, with the densities used and their weights dependent on the path through a tree decomposition of the feature space. A fast graph partitioning algorithm is applied to obtain the tree decomposition, with Bayesian methods then used to adaptively prune and average over different sub-trees in a soft probabilistic manner. The algorithm scales efficiently to approximately one million features. State of the art predictive performance is demonstrated for toy examples and two neuroscience applications including up to a million features.", "histories": [["v1", "Wed, 4 Dec 2013 10:44:01 GMT  (135kb,D)", "http://arxiv.org/abs/1312.1099v1", null]], "reviews": [], "SUBJECTS": "stat.ML cs.LG", "authors": ["francesca petralia", "joshua t vogelstein", "david b dunson"], "accepted": true, "id": "1312.1099"}
