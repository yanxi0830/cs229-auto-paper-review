{"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "25-Apr-2017", "title": "Decision Stream: Cultivating Deep Decision Trees", "abstract": "Various modifications of decision trees have been extensively used during the past years due to their high efficiency and interpretability. Selection of relevant features for spitting the tree nodes is a key property of their architecture, at the same time being their major shortcoming: the recursive nodes partitioning leads to geometric reduction of data quantity in the leaf nodes, which causes an excessive model complexity and data overfitting. In this paper, we present a novel architecture - a Decision Stream, - aimed to overcome this problem. Instead of building an acyclic tree structure during the training process, we propose merging nodes from different branches based on their similarity that is estimated with two-sample test statistics. To evaluate the proposed solution, we test it on several common machine learning problems~--- credit scoring, twitter sentiment analysis, aircraft flight control, MNIST and CIFAR image classification, synthetic data classification and regression. Our experimental results reveal that the proposed approach significantly outperforms the standard decision tree method on both regression and classification tasks, yielding a prediction error decrease up to 35%.", "histories": [["v1", "Tue, 25 Apr 2017 12:20:33 GMT  (659kb)", "http://arxiv.org/abs/1704.07657v1", null], ["v2", "Wed, 26 Apr 2017 10:22:29 GMT  (659kb)", "http://arxiv.org/abs/1704.07657v2", null], ["v3", "Sun, 3 Sep 2017 18:01:09 GMT  (332kb,D)", "http://arxiv.org/abs/1704.07657v3", null]], "reviews": [], "SUBJECTS": "cs.LG", "authors": ["dmitry ignatov", "andrey ignatov"], "accepted": false, "id": "1704.07657"}
