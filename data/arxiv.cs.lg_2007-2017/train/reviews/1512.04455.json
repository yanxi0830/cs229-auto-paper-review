{"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "14-Dec-2015", "title": "Memory-based control with recurrent neural networks", "abstract": "Partially observed control problems are a challenging aspect of reinforcement learning. We extend two related, model-free algorithms for continuous control -- deterministic policy gradient and stochastic value gradient -- to solve partially observed domains using recurrent neural networks trained with backpropagation through time.", "histories": [["v1", "Mon, 14 Dec 2015 18:44:48 GMT  (494kb,D)", "http://arxiv.org/abs/1512.04455v1", "NIPS Deep Reinforcement Learning Workshop 2015"]], "COMMENTS": "NIPS Deep Reinforcement Learning Workshop 2015", "reviews": [], "SUBJECTS": "cs.LG", "authors": ["nicolas heess", "jonathan j hunt", "timothy p lillicrap", "david silver"], "accepted": false, "id": "1512.04455"}
