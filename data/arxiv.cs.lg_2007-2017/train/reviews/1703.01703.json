{"conference": "iclr", "VERSION": "v1", "DATE_OF_SUBMISSION": "6-Mar-2017", "title": "Third-Person Imitation Learning", "abstract": "Reinforcement learning (RL) makes it possible to train agents capable of achiev- ing sophisticated goals in complex and uncertain environments. A key difficulty in reinforcement learning is specifying a reward function for the agent to optimize. Traditionally, imitation learning in RL has been used to overcome this problem. Unfortunately, hitherto imitation learning methods tend to require that demonstra- tions are supplied in the first-person: the agent is provided with a sequence of states and a specification of the actions that it should have taken. While powerful, this kind of imitation learning is limited by the relatively hard problem of collect- ing first-person demonstrations. Humans address this problem by learning from third-person demonstrations: they observe other humans perform tasks, infer the task, and accomplish the same task themselves.", "histories": [["v1", "Mon, 6 Mar 2017 02:02:34 GMT  (2204kb,D)", "http://arxiv.org/abs/1703.01703v1", null]], "reviews": [], "SUBJECTS": "cs.LG", "authors": ["bradly c stadie", "pieter abbeel", "ilya sutskever"], "accepted": true, "id": "1703.01703"}
