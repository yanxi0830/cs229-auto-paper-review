{"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "4-Jul-2013", "title": "Constructing Hierarchical Image-tags Bimodal Representations for Word Tags Alternative Choice", "abstract": "This paper describes our solution to the multi-modal learning challenge of ICML. This solution comprises constructing three-level representations in three consecutive stages and choosing correct tag words with a data-specific strategy. Firstly, we use typical methods to obtain level-1 representations. Each image is represented using MPEG-7 and gist descriptors with additional features released by the contest organizers. And the corresponding word tags are represented by bag-of-words model with a dictionary of 4000 words. Secondly, we learn the level-2 representations using two stacked RBMs for each modality. Thirdly, we propose a bimodal auto-encoder to learn the similarities/dissimilarities between the pairwise image-tags as level-3 representations. Finally, during the test phase, based on one observation of the dataset, we come up with a data-specific strategy to choose the correct tag words leading to a leap of an improved overall performance. Our final average accuracy on the private test set is 100%, which ranks the first place in this challenge.", "histories": [["v1", "Thu, 4 Jul 2013 11:10:45 GMT  (261kb)", "http://arxiv.org/abs/1307.1275v1", "6 pages, 1 figure, Presented at the Workshop on Representation Learning, ICML 2013"]], "COMMENTS": "6 pages, 1 figure, Presented at the Workshop on Representation Learning, ICML 2013", "reviews": [], "SUBJECTS": "cs.LG cs.NE", "authors": ["fangxiang feng", "ruifan li", "xiaojie wang"], "accepted": false, "id": "1307.1275"}
