{"conference": "ICML", "VERSION": "v1", "DATE_OF_SUBMISSION": "11-Nov-2013", "title": "Learning Mixtures of Linear Classifiers", "abstract": "We consider a regression (discriminative learning) problem, whereby the regression function is a convex combination of $k$ linear classifiers. Existing approaches are based on the EM algorithm, or similar techniques, without provable guarantees. We develop a simple method based on spectral techniques and a `mirroring' trick, that discovers the subspace spanned by the classifiers' parameter vectors. Under a probabilistic assumption on the feature vector distribution, we prove that this approach has nearly optimal statistical efficiency.", "histories": [["v1", "Mon, 11 Nov 2013 19:50:51 GMT  (115kb)", "http://arxiv.org/abs/1311.2547v1", null], ["v2", "Fri, 11 Apr 2014 18:52:34 GMT  (127kb)", "http://arxiv.org/abs/1311.2547v2", null], ["v3", "Mon, 14 Jul 2014 18:26:20 GMT  (128kb)", "http://arxiv.org/abs/1311.2547v3", null], ["v4", "Wed, 30 Jul 2014 23:40:04 GMT  (134kb)", "http://arxiv.org/abs/1311.2547v4", null]], "reviews": [], "SUBJECTS": "cs.LG stat.ML", "authors": ["yuekai sun", "stratis ioannidis", "andrea montanari"], "accepted": true, "id": "1311.2547"}
