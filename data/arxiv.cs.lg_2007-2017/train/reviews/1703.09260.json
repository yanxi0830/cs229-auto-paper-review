{"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "27-Mar-2017", "title": "Goal-Driven Dynamics Learning via Bayesian Optimization", "abstract": "Real-world robots are becoming increasingly complex and commonly act in poorly understood environments where it is extremely challenging to model or learn their true dynamics. Therefore, it might be desirable to take a task-specific approach, wherein the focus is on explicitly learning the dynamics model which achieves the best control performance for the task at hand, rather than learning the true dynamics. In this work, we use Bayesian optimization in an active learning framework where a locally linear dynamics model is learned with the intent of maximizing the control performance, and used in conjunction with optimal control schemes to efficiently design a controller for a given task. This model is updated directly based on the performance observed in experiments on the physical system in an iterative manner until a desired performance is achieved. We demonstrate the efficacy of the proposed approach through simulations and real experiments on a quadrotor testbed.", "histories": [["v1", "Mon, 27 Mar 2017 18:38:06 GMT  (5999kb,D)", "http://arxiv.org/abs/1703.09260v1", null], ["v2", "Fri, 22 Sep 2017 02:06:56 GMT  (2712kb,D)", "http://arxiv.org/abs/1703.09260v2", "This is the extended version of the CDC'17 paper titled \"Goal-Driven Dynamics Learning via Bayesian Optimization.\""]], "reviews": [], "SUBJECTS": "cs.SY cs.LG", "authors": ["somil bansal", "roberto calandra", "ted xiao", "sergey levine", "claire j tomlin"], "accepted": false, "id": "1703.09260"}
