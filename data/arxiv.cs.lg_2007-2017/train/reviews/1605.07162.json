{"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "23-May-2016", "title": "Pure Exploration of Multi-armed Bandit Under Matroid Constraints", "abstract": "We study the pure exploration problem subject to a matroid constraint (Best-Basis) in a stochastic multi-armed bandit game. In a Best-Basis instance, we are given $n$ stochastic arms with unknown reward distributions, as well as a matroid $\\mathcal{M}$ over the arms. Let the weight of an arm be the mean of its reward distribution. Our goal is to identify a basis of $\\mathcal{M}$ with the maximum total weight, using as few samples as possible.", "histories": [["v1", "Mon, 23 May 2016 19:51:42 GMT  (39kb)", "http://arxiv.org/abs/1605.07162v1", "To appear in COLT 2016"], ["v2", "Tue, 24 May 2016 19:20:41 GMT  (50kb)", "http://arxiv.org/abs/1605.07162v2", "Accepted for presentation at Conference on Learning Theory (COLT) 2016"], ["v3", "Wed, 25 May 2016 16:03:23 GMT  (39kb)", "http://arxiv.org/abs/1605.07162v3", "Accepted for presentation at Conference on Learning Theory (COLT) 2016"]], "COMMENTS": "To appear in COLT 2016", "reviews": [], "SUBJECTS": "cs.LG cs.DS", "authors": ["lijie chen", "anupam gupta", "jian li"], "accepted": false, "id": "1605.07162"}
