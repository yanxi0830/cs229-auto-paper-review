{"conference": "NIPS", "VERSION": "v1", "DATE_OF_SUBMISSION": "17-Jun-2015", "title": "Learning with a Wasserstein Loss", "abstract": "Learning to predict multi-label outputs is challenging, but in many problems there is a natural metric on the outputs that can be used to improve predictions. In this paper we develop a loss function for multi-label learning, based on the Wasserstein distance. The Wasserstein distance provides a natural notion of dissimilarity for probability measures. Although optimizing with respect to the exact Wasserstein distance is costly, recent work has described a regularized approximation that is efficiently computed. We describe efficient learning algorithms based on this regularization, extending the Wasserstein loss from probability measures to unnormalized measures. We also describe a statistical learning bound for the loss and show connections with the total variation norm and the Jaccard index. The Wasserstein loss can encourage smoothness of the predictions with respect to a chosen metric on the output space. We demonstrate this property on a real-data tag prediction problem, using the Yahoo Flickr Creative Commons dataset, achieving superior performance over a baseline that doesn't use the metric.", "histories": [["v1", "Wed, 17 Jun 2015 19:36:41 GMT  (2371kb,D)", "http://arxiv.org/abs/1506.05439v1", null], ["v2", "Fri, 6 Nov 2015 03:46:05 GMT  (2370kb,D)", "http://arxiv.org/abs/1506.05439v2", "NIPS 2015"], ["v3", "Wed, 30 Dec 2015 01:08:11 GMT  (2376kb,D)", "http://arxiv.org/abs/1506.05439v3", "NIPS 2015; v3 updates Algorithm 1 and Equations 6, 8"]], "reviews": [], "SUBJECTS": "cs.LG cs.CV stat.ML", "authors": ["charlie frogner", "chiyuan zhang", "hossein mobahi", "mauricio araya-polo", "tomaso a poggio"], "accepted": true, "id": "1506.05439"}
