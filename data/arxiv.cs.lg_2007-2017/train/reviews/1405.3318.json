{"conference": "ICML", "VERSION": "v1", "DATE_OF_SUBMISSION": "13-May-2014", "title": "Adaptive Monte Carlo via Bandit Allocation", "abstract": "We consider the problem of sequentially choosing between a set of unbiased Monte Carlo estimators to minimize the mean-squared-error (MSE) of a final combined estimate. By reducing this task to a stochastic multi-armed bandit problem, we show that well developed allocation strategies can be used to achieve an MSE that approaches that of the best estimator chosen in retrospect. We then extend these developments to a scenario where alternative estimators have different, possibly stochastic costs. The outcome is a new set of adaptive Monte Carlo strategies that provide stronger guarantees than previous approaches while offering practical advantages.", "histories": [["v1", "Tue, 13 May 2014 22:29:14 GMT  (1197kb,D)", "http://arxiv.org/abs/1405.3318v1", "The 31st International Conference on Machine Learning (ICML 2014)"]], "COMMENTS": "The 31st International Conference on Machine Learning (ICML 2014)", "reviews": [], "SUBJECTS": "cs.AI cs.LG", "authors": ["james neufeld", "andr\u00e1s gy\u00f6rgy", "csaba szepesv\u00e1ri", "dale schuurmans"], "accepted": true, "id": "1405.3318"}
