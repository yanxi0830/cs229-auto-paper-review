{"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "5-May-2017", "title": "Learning to see people like people", "abstract": "Humans make complex inferences on faces, ranging from objective properties (gender, ethnicity, expression, age, identity, etc) to subjective judgments (facial attractiveness, trustworthiness, sociability, friendliness, etc). While the objective aspects of face perception have been extensively studied, relatively fewer computational models have been developed for the social impressions of faces. Bridging this gap, we develop a method to predict human impressions of faces in 40 subjective social dimensions, using deep representations from state-of-the-art neural networks. We find that model performance grows as the human consensus on a face trait increases, and that model predictions outperform human groups in correlation with human averages. This illustrates the learnability of subjective social perception of faces, especially when there is high human consensus. Our system can be used to decide which photographs from a personal collection will make the best impression. The results are significant for the field of social robotics, demonstrating that robots can learn the subjective judgments defining the underlying fabric of human interaction.", "histories": [["v1", "Fri, 5 May 2017 05:47:15 GMT  (4744kb,D)", "http://arxiv.org/abs/1705.04282v1", "10 pages"]], "COMMENTS": "10 pages", "reviews": [], "SUBJECTS": "cs.CV cs.AI cs.LG", "authors": ["amanda song", "linjie li", "chad atalla", "garrison cottrell"], "accepted": false, "id": "1705.04282"}
