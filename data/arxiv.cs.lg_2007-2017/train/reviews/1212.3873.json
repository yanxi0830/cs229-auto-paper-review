{"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "17-Dec-2012", "title": "Learning Markov Decision Processes for Model Checking", "abstract": "Constructing an accurate system model for formal model verification can be both resource demanding and time-consuming. To alleviate this shortcoming, algorithms have been proposed for automatically learning system models based on observed system behaviors. In this paper we extend the algorithm on learning probabilistic automata to reactive systems, where the observed system behavior is in the form of alternating sequences of inputs and outputs. We propose an algorithm for automatically learning a deterministic labeled Markov decision process model from the observed behavior of a reactive system. The proposed learning algorithm is adapted from algorithms for learning deterministic probabilistic finite automata, and extended to include both probabilistic and nondeterministic transitions. The algorithm is empirically analyzed and evaluated by learning system models of slot machines. The evaluation is performed by analyzing the probabilistic linear temporal logic properties of the system as well as by analyzing the schedulers, in particular the optimal schedulers, induced by the learned models.", "histories": [["v1", "Mon, 17 Dec 2012 03:40:47 GMT  (150kb)", "http://arxiv.org/abs/1212.3873v1", "In Proceedings QFM 2012,arXiv:1212.3454"]], "COMMENTS": "In Proceedings QFM 2012,arXiv:1212.3454", "reviews": [], "SUBJECTS": "cs.LG cs.LO cs.SE", "authors": ["hua mao", "yingke chen", "manfred jaeger", "thomas d nielsen", "kim g larsen", "brian nielsen"], "accepted": false, "id": "1212.3873"}
