{"conference": "AAAI", "VERSION": "v1", "DATE_OF_SUBMISSION": "5-Sep-2015", "title": "Reinforcement Learning with Parameterized Actions", "abstract": "We introduce a model-free algorithm for learning in Markov decision processes with parameterized actions-discrete actions with continuous parameters. At each step the agent must select both which action to use and which parameters to use with this action. This models domains where there are distinct actions which can be adjusted to a particular state. We introduce the Q-PAMDP algorithm for learning in these domains. We show that Q-PAMDP converges to a local optima, and compare different approaches in a robot soccer goal-scoring domain and a platformer domain.", "histories": [["v1", "Sat, 5 Sep 2015 00:17:35 GMT  (160kb,D)", "http://arxiv.org/abs/1509.01644v1", "This paper is pre-submission. It will be submitted to AAAI 2015. It is currently missing experimental results from the second domain"], ["v2", "Tue, 15 Sep 2015 20:44:11 GMT  (583kb,D)", "http://arxiv.org/abs/1509.01644v2", "This paper has been submitted to AAAI 2015"], ["v3", "Tue, 22 Sep 2015 14:48:21 GMT  (583kb,D)", "http://arxiv.org/abs/1509.01644v3", "This paper has been submitted to AAAI 2015"], ["v4", "Thu, 26 Nov 2015 12:00:42 GMT  (577kb,D)", "http://arxiv.org/abs/1509.01644v4", "Accepted for AAAI 2016"]], "COMMENTS": "This paper is pre-submission. It will be submitted to AAAI 2015. It is currently missing experimental results from the second domain", "reviews": [], "SUBJECTS": "cs.AI cs.LG", "authors": ["warwick masson", "pravesh ranchod", "george konidaris"], "accepted": true, "id": "1509.01644"}
