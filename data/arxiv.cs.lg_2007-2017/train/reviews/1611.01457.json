{"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "4-Nov-2016", "title": "Multi-task learning with deep model based reinforcement learning", "abstract": "In recent years, model-free methods that use deep learning have achieved great success in many different reinforcement learning environments. Most successful approaches focus on solving a single task, while multi-task reinforcement learning remains an open problem. In this paper, we present a model based approach to deep reinforcement learning which we use to solve different tasks simultaneously. We show that our approach not only does not degrade but actually benefits from learning multiple tasks. For our model, we also present a new kind of recurrent neural network inspired by residual networks that decouples memory from computation allowing to model complex environments that do not require lots of memory. The code will be released before ICLR 2017.", "histories": [["v1", "Fri, 4 Nov 2016 17:20:22 GMT  (260kb,D)", "http://arxiv.org/abs/1611.01457v1", null], ["v2", "Fri, 11 Nov 2016 12:48:31 GMT  (260kb,D)", "http://arxiv.org/abs/1611.01457v2", null], ["v3", "Mon, 22 May 2017 09:08:44 GMT  (256kb,D)", "http://arxiv.org/abs/1611.01457v3", null], ["v4", "Tue, 23 May 2017 18:52:37 GMT  (256kb,D)", "http://arxiv.org/abs/1611.01457v4", null]], "reviews": [], "SUBJECTS": "cs.LG", "authors": ["asier mujika"], "accepted": false, "id": "1611.01457"}
