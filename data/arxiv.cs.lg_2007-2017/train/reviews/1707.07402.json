{"conference": "EMNLP", "VERSION": "v1", "DATE_OF_SUBMISSION": "24-Jul-2017", "title": "Reinforcement Learning for Bandit Neural Machine Translation with Simulated Human Feedback", "abstract": "Machine translation is a natural candidate problem for reinforcement learning from human feedback: users provide quick, dirty ratings on candidate translations to guide a system to improve. Yet, current neural machine translation training focuses on expensive human-generated reference translations. We describe a reinforcement learning algorithm that improves neural machine translation systems from simulated human feedback. Our algorithm combines the advantage actor-critic algorithm (Mnih et al., 2016) with the attention-based neural encoder-decoder architecture (Luong et al., 2015). This algorithm (a) is well-designed for problems with a large action space and delayed rewards, (b) effectively optimizes traditional corpus-level machine translation metrics, and (c) is robust to skewed, high-variance, granular feedback modeled after actual human behaviors.", "histories": [["v1", "Mon, 24 Jul 2017 04:35:19 GMT  (1008kb,D)", "http://arxiv.org/abs/1707.07402v1", "11 pages, 5 figures, In Proceedings of Empirical Methods in Natural Language Processing (EMNLP) 2017"], ["v2", "Tue, 1 Aug 2017 17:19:01 GMT  (1008kb,D)", "http://arxiv.org/abs/1707.07402v2", "11 pages, 5 figures, In Proceedings of Empirical Methods in Natural Language Processing (EMNLP) 2017"], ["v3", "Fri, 13 Oct 2017 06:10:55 GMT  (1008kb,D)", "http://arxiv.org/abs/1707.07402v3", "11 pages, 5 figures, In Proceedings of Empirical Methods in Natural Language Processing (EMNLP) 2017"]], "COMMENTS": "11 pages, 5 figures, In Proceedings of Empirical Methods in Natural Language Processing (EMNLP) 2017", "reviews": [], "SUBJECTS": "cs.CL cs.AI cs.HC cs.LG", "authors": ["khanh nguyen", "hal daum\u00e9 iii", "jordan l boyd-graber"], "accepted": true, "id": "1707.07402"}
