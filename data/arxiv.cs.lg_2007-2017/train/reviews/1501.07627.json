{"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "29-Jan-2015", "title": "Representing Objects, Relations, and Sequences", "abstract": "Vector Symbolic Architectures (VSAs) are high-dimensional vector representations of objects (eg., words, image parts), relations (eg., sentence structures), and sequences for use with machine learning algorithms. They consist of a vector addition operator for representing a collection of unordered objects, a Binding operator for associating groups of objects, and a methodology for encoding complex structures.", "histories": [["v1", "Thu, 29 Jan 2015 22:13:02 GMT  (960kb)", "http://arxiv.org/abs/1501.07627v1", "41 pages"]], "COMMENTS": "41 pages", "reviews": [], "SUBJECTS": "cs.LG", "authors": ["stephen i gallant", "t wendy okaywe"], "accepted": false, "id": "1501.07627"}
