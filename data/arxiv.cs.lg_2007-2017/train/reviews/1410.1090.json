{"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "4-Oct-2014", "title": "Explain Images with Multimodal Recurrent Neural Networks", "abstract": "In this paper, we present a multimodal Recurrent Neural Network (m-RNN) model for generating novel sentence descriptions to explain the content of images. It directly models the probability distribution of generating a word given previous words and the image. Image descriptions are generated by sampling from this distribution. The model consists of two sub-networks: a deep recurrent neural network for sentences and a deep convolutional network for images. These two sub-networks interact with each other in a multimodal layer to form the whole m-RNN model. The effectiveness of our model is validated on three benchmark datasets (IAPR TC-12, Flickr 8K, and Flickr 30K). Our model outperforms the state-of-the-art generative method. In addition, the m-RNN model can be applied to retrieval tasks for retrieving images or sentences, and achieves significant performance improvement over the state-of-the-art methods which directly optimize the ranking objective function for retrieval.", "histories": [["v1", "Sat, 4 Oct 2014 20:24:34 GMT  (346kb,D)", "http://arxiv.org/abs/1410.1090v1", null]], "reviews": [], "SUBJECTS": "cs.CV cs.CL cs.LG", "authors": ["junhua mao", "wei xu", "yi yang", "jiang wang", "alan l yuille"], "accepted": false, "id": "1410.1090"}
