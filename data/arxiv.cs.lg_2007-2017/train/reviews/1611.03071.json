{"conference": "ICML", "VERSION": "v1", "DATE_OF_SUBMISSION": "9-Nov-2016", "title": "Fairness in Reinforcement Learning", "abstract": "We initiate the study of fair learning in Markovian settings, where the actions of a learning algorithm may affect its environment and future rewards. Working in the model of reinforcement learning, we define a fairness constraint requiring that an algorithm never prefers one action over another if the long-term (discounted) reward of choosing the latter action is higher.", "histories": [["v1", "Wed, 9 Nov 2016 20:19:45 GMT  (415kb,D)", "http://arxiv.org/abs/1611.03071v1", null], ["v2", "Thu, 17 Nov 2016 17:46:00 GMT  (411kb,D)", "http://arxiv.org/abs/1611.03071v2", null], ["v3", "Wed, 1 Mar 2017 16:35:53 GMT  (409kb,D)", "http://arxiv.org/abs/1611.03071v3", null], ["v4", "Sun, 6 Aug 2017 00:12:49 GMT  (426kb,D)", "http://arxiv.org/abs/1611.03071v4", "The short version of this paper appears in the proceedings of ICML-17"]], "reviews": [], "SUBJECTS": "cs.LG", "authors": ["shahin jabbari", "matthew joseph", "michael kearns", "jamie morgenstern", "aaron roth"], "accepted": true, "id": "1611.03071"}
