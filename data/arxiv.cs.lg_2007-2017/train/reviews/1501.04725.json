{"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "20-Jan-2015", "title": "Learning Invariants using Decision Trees", "abstract": "The problem of inferring an inductive invariant for verifying program safety can be formulated in terms of binary classification. This is a standard problem in machine learning: given a sample of good and bad points, one is asked to find a classifier that generalizes from the sample and separates the two sets. Here, the good points are the reachable states of the program, and the bad points are those that reach a safety property violation. Thus, a learned classifier is a candidate invariant. In this paper, we propose a new algorithm that uses decision trees to learn candidate invariants in the form of arbitrary Boolean combinations of numerical inequalities. We have used our algorithm to verify C programs taken from the literature. The algorithm is able to infer safe invariants for a range of challenging benchmarks and compares favorably to other ML-based invariant inference techniques. In particular, it scales well to large sample sets.", "histories": [["v1", "Tue, 20 Jan 2015 07:20:30 GMT  (338kb,D)", "http://arxiv.org/abs/1501.04725v1", "15 pages, 2 figures"]], "COMMENTS": "15 pages, 2 figures", "reviews": [], "SUBJECTS": "cs.PL cs.LG", "authors": ["siddharth krishna", "christian puhrsch", "thomas wies"], "accepted": false, "id": "1501.04725"}
