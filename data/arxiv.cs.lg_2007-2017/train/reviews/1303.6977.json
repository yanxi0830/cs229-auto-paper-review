{"conference": "ICML", "VERSION": "v1", "DATE_OF_SUBMISSION": "27-Mar-2013", "title": "ABC Reinforcement Learning", "abstract": "This paper introduces a simple, general framework for likelihood-free Bayesian reinforcement learning, through Approximate Bayesian Computation (ABC). The main advantage is that we only require a prior distribution on a class of simulators (generative models). This is useful in domains where an analytical probabilistic model of the underlying process is too complex to formulate, but where detailed simulation models are available. ABC-RL allows the use of any Bayesian reinforcement learning technique, even in this case. In addition, it can be seen as an extension of rollout algorithms to the case where we do not know what the correct model to draw rollouts from is. We experimentally demonstrate the potential of this approach in a comparison with LSPI. Finally, we introduce a theorem showing that ABC is a sound methodology in principle, even when non-sufficient statistics are used.", "histories": [["v1", "Wed, 27 Mar 2013 20:51:33 GMT  (26kb)", "https://arxiv.org/abs/1303.6977v1", "16 pages, 4 figures"], ["v2", "Wed, 8 May 2013 12:54:53 GMT  (58kb)", "http://arxiv.org/abs/1303.6977v2", "10 pages, 4 figures"], ["v3", "Tue, 18 Jun 2013 09:42:59 GMT  (58kb)", "http://arxiv.org/abs/1303.6977v3", "10 pages, 4 figures"], ["v4", "Fri, 28 Jun 2013 11:18:26 GMT  (58kb)", "http://arxiv.org/abs/1303.6977v4", "Corrected version of paper appearing in ICML 2013"]], "COMMENTS": "16 pages, 4 figures", "reviews": [], "SUBJECTS": "stat.ML cs.LG", "authors": ["christos dimitrakakis", "nikolaos tziortziotis"], "accepted": true, "id": "1303.6977"}
