{"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "19-Jun-2013", "title": "Multiarmed Bandits With Limited Expert Advice", "abstract": "We solve the COLT 2013 open problem of Seldin et. al. on minimizing regret in the setting of advice-efficient multiarmed bandits with expert advice. We give an algorithm for the setting of K arms and N experts out of which we are allowed to query and use only M experts' advices in each round, which has a regret bound of 4\\sqrt{\\frac{\\min\\{K, M\\} N \\log(N)}{M} T} after T rounds.", "histories": [["v1", "Wed, 19 Jun 2013 19:25:51 GMT  (5kb)", "http://arxiv.org/abs/1306.4653v1", null], ["v2", "Thu, 27 Jun 2013 19:48:35 GMT  (8kb)", "http://arxiv.org/abs/1306.4653v2", "Updated with lower bound nearly matching the upper bound"], ["v3", "Fri, 28 Jun 2013 18:35:06 GMT  (8kb)", "http://arxiv.org/abs/1306.4653v3", "Updated with lower bound nearly matching the upper bound, and fixed some typos"], ["v4", "Mon, 8 Jul 2013 19:05:49 GMT  (9kb)", "http://arxiv.org/abs/1306.4653v4", "Updated with tighter upper bound based on PolyINF algorithm, lower bound nearly matching the upper bound, and fixed some typos"]], "reviews": [], "SUBJECTS": "cs.LG", "authors": ["satyen kale"], "accepted": false, "id": "1306.4653"}
