{"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "11-Jun-2013", "title": "Large Margin Low Rank Tensor Analysis", "abstract": "Other than vector representations, the direct objects of human cognition are generally high-order tensors, such as 2D images and 3D textures. From this fact, two interesting questions naturally arise: How does the human brain represent these tensor perceptions in a \"manifold\" way, and how can they be recognized on the \"manifold\"? In this paper, we present a supervised model to learn the intrinsic structure of the tensors embedded in a high dimensional Euclidean space. With the fixed point continuation procedures, our model automatically and jointly discovers the optimal dimensionality and the representations of the low dimensional embeddings. This makes it an effective simulation of the cognitive process of human brain. Furthermore, the generalization of our model based on similarity between the learned low dimensional embeddings can be viewed as counterpart of recognition of human brain. Experiments on applications for object recognition and face recognition demonstrate the superiority of our proposed model over state-of-the-art approaches.", "histories": [["v1", "Tue, 11 Jun 2013 21:39:56 GMT  (1379kb,D)", "http://arxiv.org/abs/1306.2663v1", "30 pages"]], "COMMENTS": "30 pages", "reviews": [], "SUBJECTS": "cs.LG cs.NA", "authors": ["guoqiang zhong", "mohamed cheriet"], "accepted": false, "id": "1306.2663"}
