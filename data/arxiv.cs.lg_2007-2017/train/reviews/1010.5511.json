{"conference": "NIPS", "VERSION": "v1", "DATE_OF_SUBMISSION": "26-Oct-2010", "title": "Efficient Minimization of Decomposable Submodular Functions", "abstract": "Many combinatorial problems arising in machine learning can be reduced to the problem of minimizing a submodular function. Submodular functions are a natural discrete analog of convex functions, and can be minimized in strongly polynomial time. Unfortunately, state-of-the-art algorithms for general submodular minimization are intractable for larger problems. In this paper, we introduce a novel subclass of submodular minimization problems that we call decomposable. Decomposable submodular functions are those that can be represented as sums of concave functions applied to modular functions. We develop an algorithm, SLG, that can efficiently minimize decomposable submodular functions with tens of thousands of variables. Our algorithm exploits recent results in smoothed convex minimization. We apply SLG to synthetic benchmarks and a joint classification-and-segmentation task, and show that it outperforms the state-of-the-art general purpose submodular minimization algorithms by several orders of magnitude.", "histories": [["v1", "Tue, 26 Oct 2010 20:23:39 GMT  (229kb,DS)", "http://arxiv.org/abs/1010.5511v1", "Expanded version of paper for Neural Information Processing Systems 2010"]], "COMMENTS": "Expanded version of paper for Neural Information Processing Systems 2010", "reviews": [], "SUBJECTS": "cs.LG math.OC", "authors": ["peter stobbe", "andreas krause 0001"], "accepted": true, "id": "1010.5511"}
