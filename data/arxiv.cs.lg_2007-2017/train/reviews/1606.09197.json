{"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "29-Jun-2016", "title": "Model-Free Trajectory Optimization with Monotonic Improvement", "abstract": "Many of the recent Trajectory Optimization algorithms alternate between local approximation of the dynamics and conservative policy update. However, linearly approximating the dynamics in order to derive the new policy can bias the update and prevent convergence to the optimal policy. In this article, we propose a new model-free algorithm that backpropagates a local quadratic time-dependent Q-Function, allowing the derivation of the policy update in closed form. Our policy update ensures exact KL-constraint satisfaction without simplifying assumptions on the system dynamics demonstrating improved performance in comparison to related Trajectory Optimization algorithms linearizing the dynamics.", "histories": [["v1", "Wed, 29 Jun 2016 17:39:09 GMT  (936kb,D)", "http://arxiv.org/abs/1606.09197v1", "10 pages, 4 figures, one page supplementary"], ["v2", "Fri, 12 May 2017 08:35:57 GMT  (920kb,D)", "http://arxiv.org/abs/1606.09197v2", null], ["v3", "Thu, 29 Jun 2017 09:07:37 GMT  (921kb,D)", "http://arxiv.org/abs/1606.09197v3", null]], "COMMENTS": "10 pages, 4 figures, one page supplementary", "reviews": [], "SUBJECTS": "cs.LG cs.RO", "authors": ["riad akrour", "abbas abdolmaleki", "hany abdulsamad", "jan peters", "gerhard neumann"], "accepted": false, "id": "1606.09197"}
