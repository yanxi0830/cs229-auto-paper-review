{"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "15-Jan-2013", "title": "Why Size Matters: Feature Coding as Nystrom Sampling", "abstract": "Recently, the computer vision and machine learning community has been in favor of feature extraction pipelines that rely on a coding step followed by a linear classifier, due to their overall simplicity, well understood properties of linear classifiers, and their computational efficiency. In this paper we propose a novel view of this pipeline based on kernel methods and Nystrom sampling. In particular, we focus on the coding of a data point with a local representation based on a dictionary with fewer elements than the number of data points, and view it as an approximation to the actual function that would compute pair-wise similarity to all data points (often too many to compute in practice), followed by a Nystrom sampling step to select a subset of all data points.", "histories": [["v1", "Tue, 15 Jan 2013 21:36:06 GMT  (25kb,D)", "https://arxiv.org/abs/1301.5348v1", null], ["v2", "Tue, 16 Apr 2013 00:17:54 GMT  (25kb,D)", "http://arxiv.org/abs/1301.5348v2", null]], "reviews": [], "SUBJECTS": "cs.LG cs.CV", "authors": ["oriol vinyals", "yangqing jia", "trevor darrell"], "accepted": false, "id": "1301.5348"}
