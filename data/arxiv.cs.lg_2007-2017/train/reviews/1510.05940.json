{"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "20-Oct-2015", "title": "Max-margin Metric Learning for Speaker Recognition", "abstract": "Probabilistic linear discriminant analysis (PLDA) is among the most popular methods that accompany the i-vector model to deliver state-of-the-art performance for speaker recognition. A potential problem of the PLDA model, however, is that it essentially assumes strong Gaussian distributions over i-vectors as well as speaker mean vectors, and the objective function is not directly related to the goal of the task, e.g., discriminating true speakers and imposters. We propose a max-margin metric learning approach to solve the problem. It learns a linear transform with the criterion that target trials and imposter trials are discriminated from each other by a large margin. Experiments conducted on the SRE08 core test show that this new approach achieves a performance comparable to or even better than PLDA, though the scoring is as simple as a cosine computation.", "histories": [["v1", "Tue, 20 Oct 2015 16:01:05 GMT  (354kb,D)", "https://arxiv.org/abs/1510.05940v1", null], ["v2", "Thu, 31 Mar 2016 05:27:17 GMT  (112kb,D)", "http://arxiv.org/abs/1510.05940v2", null]], "reviews": [], "SUBJECTS": "cs.SD cs.LG", "authors": ["lantian li", "dong wang", "chao xing", "thomas fang zheng"], "accepted": false, "id": "1510.05940"}
