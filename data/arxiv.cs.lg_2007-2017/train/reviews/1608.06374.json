{"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "23-Aug-2016", "title": "Deep Double Sparsity Encoder: Learning to Sparsify Not Only Features But Also Parameters", "abstract": "This paper emphasizes the significance to jointly exploit the problem structure and the parameter structure, in the context of deep modeling. As a specific and interesting example, we describe the deep double sparsity encoder (DDSE), which is inspired by the double sparsity model for dictionary learning. DDSE simultaneously sparsities the output features and the learned model parameters, under one unified framework. In addition to its intuitive model interpretation, DDSE also possesses compact model size and low complexity. Extensive simulations compare DDSE with several carefully-designed baselines, and verify the consistently superior performance of DDSE. We further apply DDSE to the novel application domain of brain encoding, with promising preliminary results achieved.", "histories": [["v1", "Tue, 23 Aug 2016 03:50:01 GMT  (427kb,D)", "http://arxiv.org/abs/1608.06374v1", null], ["v2", "Sun, 2 Oct 2016 03:01:51 GMT  (426kb,D)", "http://arxiv.org/abs/1608.06374v2", null]], "reviews": [], "SUBJECTS": "cs.LG cs.CV", "authors": ["zhangyang wang", "thomas s huang"], "accepted": false, "id": "1608.06374"}
