{"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "16-Jan-2013", "title": "Switched linear encoding with rectified linear autoencoders", "abstract": "Several recent results in machine learning have established formal connections between autoencoders---artificial neural network models that attempt to reproduce their inputs---and other coding models like sparse coding and K-means. This paper explores in depth an autoencoder model that is constructed using rectified linear activations on its hidden units. Our analysis builds on recent results to further unify the world of sparse linear coding models. We provide an intuitive interpretation of the behavior of these coding models and demonstrate this intuition using small, artificial datasets with known distributions.", "histories": [["v1", "Wed, 16 Jan 2013 17:04:10 GMT  (8405kb,D)", "https://arxiv.org/abs/1301.3753v1", null], ["v2", "Sat, 19 Jan 2013 19:38:36 GMT  (8405kb,D)", "http://arxiv.org/abs/1301.3753v2", null]], "reviews": [], "SUBJECTS": "cs.LG", "authors": ["leif johnson", "craig corcoran"], "accepted": false, "id": "1301.3753"}
