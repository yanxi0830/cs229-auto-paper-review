{"conference": "iclr", "VERSION": "v1", "DATE_OF_SUBMISSION": "30-Mar-2016", "title": "Recurrent Batch Normalization", "abstract": "We propose a reparameterization of LSTM that brings the benefits of batch normalization to recurrent neural networks. Whereas previous works only apply batch normalization to the input-to-hidden transformation of RNNs, we demonstrate that it is both possible and beneficial to batch-normalize the hidden-to-hidden transition, thereby reducing internal covariate shift between time steps.", "histories": [["v1", "Wed, 30 Mar 2016 02:57:20 GMT  (223kb,D)", "http://arxiv.org/abs/1603.09025v1", null], ["v2", "Thu, 31 Mar 2016 20:45:03 GMT  (222kb,D)", "http://arxiv.org/abs/1603.09025v2", null], ["v3", "Mon, 4 Apr 2016 17:16:08 GMT  (222kb,D)", "http://arxiv.org/abs/1603.09025v3", null], ["v4", "Tue, 12 Apr 2016 19:23:44 GMT  (222kb,D)", "http://arxiv.org/abs/1603.09025v4", null], ["v5", "Tue, 28 Feb 2017 00:59:42 GMT  (292kb,D)", "http://arxiv.org/abs/1603.09025v5", null]], "reviews": [], "SUBJECTS": "cs.LG", "authors": ["tim cooijmans", "nicolas ballas", "c\\'esar laurent", "\\c{c}a\\u{g}lar g\\\"ul\\c{c}ehre", "aaron courville"], "accepted": true, "id": "1603.09025"}
