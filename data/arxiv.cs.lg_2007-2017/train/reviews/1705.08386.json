{"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "23-May-2017", "title": "Better Text Understanding Through Image-To-Text Transfer", "abstract": "Generic text embeddings are successfully used in a variety of tasks. However, they are often learnt by capturing the co-occurrence structure from pure text corpora, resulting in limitations of their ability to generalize. In this paper, we explore models that incorporate visual information into the text representation. Based on comprehensive ablation studies, we propose a conceptually simple, yet well performing architecture. It outperforms previous multimodal approaches on a set of well established benchmarks. We also improve the state-of-the-art results for image-related text datasets, using orders of magnitude less data.", "histories": [["v1", "Tue, 23 May 2017 16:06:32 GMT  (2837kb,D)", "https://arxiv.org/abs/1705.08386v1", null], ["v2", "Fri, 26 May 2017 08:08:20 GMT  (2837kb,D)", "http://arxiv.org/abs/1705.08386v2", null]], "reviews": [], "SUBJECTS": "cs.CL cs.CV cs.LG", "authors": ["karol kurach", "sylvain gelly", "michal jastrzebski", "philip haeusser", "olivier teytaud", "damien vincent", "olivier bousquet"], "accepted": false, "id": "1705.08386"}
