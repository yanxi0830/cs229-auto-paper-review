{"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "24-Feb-2017", "title": "Tight Bounds for Bandit Combinatorial Optimization", "abstract": "We revisit the study of optimal regret rates in bandit combinatorial optimization---a fundamental framework for sequential decision making under uncertainty that abstracts numerous combinatorial prediction problems. We prove that the attainable regret in this setting grows as $\\widetilde{\\Theta}(k^{3/2}\\sqrt{dT})$ where $d$ is the dimension of the problem and $k$ is a bound over the maximal instantaneous loss, disproving a conjecture of Audibert, Bubeck, and Lugosi (2013) who argued that the optimal rate should be of the form $\\widetilde{\\Theta}(k\\sqrt{dT})$. Our bounds apply to several important instances of the framework, and in particular, imply a tight bound for the well-studied bandit shortest path problem. By that, we also resolve an open problem posed by Cesa-Bianchi and Lugosi (2012).", "histories": [["v1", "Fri, 24 Feb 2017 11:17:33 GMT  (17kb)", "http://arxiv.org/abs/1702.07539v1", null]], "reviews": [], "SUBJECTS": "cs.LG", "authors": ["alon cohen", "tamir hazan", "tomer koren"], "accepted": false, "id": "1702.07539"}
