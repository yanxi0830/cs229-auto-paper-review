{"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "2-Apr-2017", "title": "Hidden Two-Stream Convolutional Networks for Action Recognition", "abstract": "Analyzing videos of human actions involves understanding the temporal relationships among video frames. CNNs are the current state-of-the-art methods for action recognition in videos. However, the CNN architectures currently being used have difficulty in capturing these relationships. State-of-the-art action recognition approaches rely on traditional local optical flow estimation methods to pre-compute the motion information for CNNs. Such a two-stage approach is computationally expensive, storage demanding, and not end-to-end trainable. In this paper, we present a novel CNN architecture that implicitly captures motion information. Our method is 10x faster than a two-stage approach, does not need to cache flow information, and is end-to-end trainable. Experimental results on UCF101 and HMDB51 show that it achieves competitive accuracy with the two-stage approaches.", "histories": [["v1", "Sun, 2 Apr 2017 23:39:51 GMT  (2895kb,D)", "https://arxiv.org/abs/1704.00389v1", "under review at ICCV 2017"], ["v2", "Sat, 8 Jul 2017 21:48:54 GMT  (2897kb,D)", "http://arxiv.org/abs/1704.00389v2", "Code available atthis https URLUpdate results for HMDB51. Attach supplemental materials"], ["v3", "Sun, 22 Oct 2017 03:53:21 GMT  (3445kb,D)", "http://arxiv.org/abs/1704.00389v3", "Extended journal version, under review. Code available atthis https URL"]], "COMMENTS": "under review at ICCV 2017", "reviews": [], "SUBJECTS": "cs.CV cs.LG cs.MM", "authors": ["yi zhu", "zhenzhong lan", "shawn newsam", "alexander g hauptmann"], "accepted": false, "id": "1704.00389"}
