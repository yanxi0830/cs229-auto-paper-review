{"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "7-Jun-2010", "title": "Regression on fixed-rank positive semidefinite matrices: a Riemannian approach", "abstract": "The paper addresses the problem of learning a regression model parameterized by a fixed-rank positive semidefinite matrix. The focus is on the nonlinear nature of the search space and on scalability to high-dimensional problems. The mathematical developments rely on the theory of gradient descent algorithms adapted to the Riemannian geometry that underlies the set of fixed-rank positive semidefinite matrices. In contrast with previous contributions in the literature, no restrictions are imposed on the range space of the learned matrix. The resulting algorithms maintain a linear complexity in the problem size and enjoy important invariance properties. We apply the proposed algorithms to the problem of learning a distance function parameterized by a positive semidefinite matrix. Good performance is observed on classical benchmarks.", "histories": [["v1", "Mon, 7 Jun 2010 16:20:02 GMT  (173kb,D)", "http://arxiv.org/abs/1006.1288v1", null], ["v2", "Mon, 31 Jan 2011 09:59:44 GMT  (361kb)", "http://arxiv.org/abs/1006.1288v2", null]], "reviews": [], "SUBJECTS": "cs.LG", "authors": ["gilles meyer", "silvere bonnabel", "rodolphe sepulchre"], "accepted": false, "id": "1006.1288"}
