{"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "23-Jun-2014", "title": "Stationary Mixing Bandits", "abstract": "We study the bandit problem where arms are associated with stationary phi-mixing processes and where rewards are therefore dependent: the question that arises from this setting is that of recovering some independence by ignoring the value of some rewards. As we shall see, the bandit problem we tackle requires us to address the exploration/exploitation/independence trade-off. To do so, we provide a UCB strategy together with a general regret analysis for the case where the size of the independence blocks (the ignored rewards) is fixed and we go a step beyond by providing an algorithm that is able to compute the size of the independence blocks from the data. Finally, we give an analysis of our bandit problem in the restless case, i.e., in the situation where the time counters for all mixing processes simultaneously evolve.", "histories": [["v1", "Mon, 23 Jun 2014 18:48:59 GMT  (19kb)", "http://arxiv.org/abs/1406.6020v1", null]], "reviews": [], "SUBJECTS": "cs.LG", "authors": ["julien audiffren", "liva ralaivola"], "accepted": false, "id": "1406.6020"}
