{"conference": "EMNLP", "VERSION": "v1", "DATE_OF_SUBMISSION": "4-Apr-2016", "title": "Character-Level Question Answering with Attention", "abstract": "We show that an encoder-decoder framework can be successfully be applied to question-answering with a structured knowledge base. In addition, we propose a new character-level modeling approach for this task, which we use to make our model robust to unseen entities and predicates. We use our model for single-relation question answering, and demonstrate the effectiveness of our novel approach on the SimpleQuestions dataset, where we improve state-of-the-art accuracy by 2% for both Freebase2M and Freebase5M subsets proposed. Importantly, we achieve these results even though our character-level model has 16x less parameters than an equivalent word-embedding model, uses significantly less training data than previous work which relies on data augmentation, and encounters only 1.18% of the entities seen during training when testing.", "histories": [["v1", "Mon, 4 Apr 2016 02:43:23 GMT  (646kb,D)", "http://arxiv.org/abs/1604.00727v1", null], ["v2", "Tue, 5 Apr 2016 23:09:31 GMT  (647kb,D)", "http://arxiv.org/abs/1604.00727v2", null], ["v3", "Fri, 8 Apr 2016 21:12:47 GMT  (647kb,D)", "http://arxiv.org/abs/1604.00727v3", null], ["v4", "Sun, 5 Jun 2016 02:02:10 GMT  (9011kb,D)", "http://arxiv.org/abs/1604.00727v4", null]], "reviews": [], "SUBJECTS": "cs.CL cs.AI cs.LG", "authors": ["xiaodong he", "david golub"], "accepted": true, "id": "1604.00727"}
