{"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "12-Jun-2017", "title": "Clustering over Multi-Objective Samples: The one2all Sample", "abstract": "Clustering is a fundamental technique in data analysis. Consider data points $X$ that lie in a (relaxed) metric space (where the triangle inequality can be relaxed by a constant factor). Each set of points $Q$ ({\\em centers}) defines a clustering of $X$ according to the closest center with {\\em cost} $V(Q)=\\sum_{x\\in X} d_{xQ}$. This formulation generalizes classic $k$-means clustering, which uses squared distances. Two basic tasks, parametrized by $k \\geq 1$, are {\\em cost estimation}, which returns (approximate) $V(Q)$ for queries $Q$ such that $|Q|=k$ and {\\em clustering}, which returns an (approximate) minimizer of $V(Q)$ of size $|Q|=k$. With very large data sets $X$, we seek efficient constructions of small summaries that allow us to efficiently approximate clustering costs over the full data.", "histories": [["v1", "Mon, 12 Jun 2017 13:05:46 GMT  (19kb,D)", "http://arxiv.org/abs/1706.03607v1", "10 pages, 1 figure"], ["v2", "Sun, 29 Oct 2017 10:27:20 GMT  (76kb,D)", "http://arxiv.org/abs/1706.03607v2", "17 pages, 2 figure"]], "COMMENTS": "10 pages, 1 figure", "reviews": [], "SUBJECTS": "cs.LG cs.DS", "authors": ["edith cohen", "shiri chechik", "haim kaplan"], "accepted": false, "id": "1706.03607"}
