{"conference": "EMNLP", "VERSION": "v1", "DATE_OF_SUBMISSION": "6-Jul-2017", "title": "A causal framework for explaining the predictions of black-box sequence-to-sequence models", "abstract": "We interpret the predictions of any black-box structured input-structured output model around a specific input-output pair. Our method returns an \"explanation\"' consisting of groups of input-output tokens that are causally related. Our method infers these dependencies by querying the model with perturbed inputs, generating a graph over tokens from the responses, and solving a partitioning problem to select the most relevant components. We focus the general approach on sequence-to-sequence problems, adopting a variational autoencoder to yield meaningful input perturbations. We test our method across several NLP sequence generation tasks.", "histories": [["v1", "Thu, 6 Jul 2017 19:36:43 GMT  (394kb,D)", "https://arxiv.org/abs/1707.01943v1", "EMNLP 2017"], ["v2", "Tue, 25 Jul 2017 16:31:23 GMT  (223kb,D)", "http://arxiv.org/abs/1707.01943v2", "12 Pages, EMNLP 2017"]], "COMMENTS": "EMNLP 2017", "reviews": [], "SUBJECTS": "cs.LG", "authors": ["david alvarez-melis", "tommi s jaakkola"], "accepted": true, "id": "1707.01943"}
