{"conference": "NIPS", "VERSION": "v1", "DATE_OF_SUBMISSION": "10-Jun-2016", "title": "Causal Bandits: Learning Good Interventions via Causal Inference", "abstract": "We study the problem of using causal models to improve the rate at which good interventions can be learned online in a stochastic environment. Our formalism combines multi-arm bandits and causal inference to model a novel type of bandit feedback that is not exploited by existing approaches. We propose a new algorithm that exploits the causal feedback and prove a bound on its simple regret that is strictly better (in all quantities) than algorithms that do not use the additional causal information.", "histories": [["v1", "Fri, 10 Jun 2016 06:19:32 GMT  (1110kb,D)", "http://arxiv.org/abs/1606.03203v1", null]], "reviews": [], "SUBJECTS": "stat.ML cs.LG", "authors": ["finnian lattimore", "tor lattimore", "mark d reid"], "accepted": true, "id": "1606.03203"}
