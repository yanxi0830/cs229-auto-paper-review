{"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "2-Oct-2014", "title": "Stochastic Discriminative EM", "abstract": "Stochastic discriminative EM (sdEM) is an online-EM-type algorithm for discriminative training of probabilistic generative models belonging to the exponential family. In this work, we introduce and justify this algorithm as a stochastic natural gradient descent method, i.e. a method which accounts for the information geometry in the parameter space of the statistical model. We show how this learning algorithm can be used to train probabilistic generative models by minimizing different discriminative loss functions, such as the negative conditional log-likelihood and the Hinge loss. The resulting models trained by sdEM are always generative (i.e. they define a joint probability distribution) and, in consequence, allows to deal with missing data and latent variables in a principled way either when being learned or when making predictions. The performance of this method is illustrated by several text classification problems for which a multinomial naive Bayes and a latent Dirichlet allocation based classifier are learned using different discriminative loss functions.", "histories": [["v1", "Thu, 2 Oct 2014 12:10:40 GMT  (679kb)", "http://arxiv.org/abs/1410.1784v1", "UAI 2014 paper + Supplementary Material. In Proceedings of the Thirtieth Conference on Uncertainty in Artificial Intelligence (UAI 2014), edited by Nevin L. Zhang and Jian Tian. AUAI Press"]], "COMMENTS": "UAI 2014 paper + Supplementary Material. In Proceedings of the Thirtieth Conference on Uncertainty in Artificial Intelligence (UAI 2014), edited by Nevin L. Zhang and Jian Tian. AUAI Press", "reviews": [], "SUBJECTS": "cs.LG", "authors": ["andres r masegosa"], "accepted": false, "id": "1410.1784"}
