{"conference": "iclr", "VERSION": "v1", "DATE_OF_SUBMISSION": "10-Nov-2016", "title": "Understanding deep learning requires rethinking generalization", "abstract": "Despite their massive size, successful deep artificial neural networks can exhibit a remarkably small difference between training and test performance. Conventional wisdom attributes small generalization error either to properties of the model family, or to the regularization techniques used during training.", "histories": [["v1", "Thu, 10 Nov 2016 22:02:36 GMT  (296kb,D)", "http://arxiv.org/abs/1611.03530v1", null], ["v2", "Sun, 26 Feb 2017 19:36:40 GMT  (308kb,D)", "http://arxiv.org/abs/1611.03530v2", "Published in ICLR 2017"]], "reviews": [], "SUBJECTS": "cs.LG", "authors": ["chiyuan zhang", "samy bengio", "moritz hardt", "benjamin recht", "oriol vinyals"], "accepted": true, "id": "1611.03530"}
