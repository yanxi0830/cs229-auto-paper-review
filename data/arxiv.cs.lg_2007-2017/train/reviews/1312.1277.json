{"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "4-Dec-2013", "title": "Bandits and Experts in Metric Spaces", "abstract": "In a multi-armed bandit problem, an online algorithm chooses from a set of strategies in a sequence of trials so as to maximize the total payoff of the chosen strategies. While the performance of bandit algorithms with a small finite strategy set is quite well understood, bandit problems with large strategy sets are still a topic of very active investigation, motivated by practical applications such as online auctions and web advertisement. The goal of such research is to identify broad and natural classes of strategy sets and payoff functions which enable the design of efficient solutions.", "histories": [["v1", "Wed, 4 Dec 2013 18:48:00 GMT  (101kb)", "https://arxiv.org/abs/1312.1277v1", "This manuscript is a merged and definitive version of (R. Kleinberg, Slivkins, Upfal: STOC 2008) and (R. Kleinberg, Slivkins: SODA 2010), with a significantly revised presentation"], ["v2", "Thu, 19 Nov 2015 14:26:27 GMT  (149kb)", "http://arxiv.org/abs/1312.1277v2", "This manuscript is a merged and definitive version of (R. Kleinberg, Slivkins, Upfal: STOC 2008) and (R. Kleinberg, Slivkins: SODA 2010), with a significantly revised presentation"]], "COMMENTS": "This manuscript is a merged and definitive version of (R. Kleinberg, Slivkins, Upfal: STOC 2008) and (R. Kleinberg, Slivkins: SODA 2010), with a significantly revised presentation", "reviews": [], "SUBJECTS": "cs.DS cs.LG", "authors": ["robert kleinberg", "aleksandrs slivkins", "eli upfal"], "accepted": false, "id": "1312.1277"}
