{"conference": "ICML", "VERSION": "v1", "DATE_OF_SUBMISSION": "19-Feb-2015", "title": "Trust Region Policy Optimization", "abstract": "We propose a family of trust region policy optimization (TRPO) algorithms for learning control policies. We first develop a policy update scheme with guaranteed monotonic improvement, and then we describe a finite-sample approximation to this scheme that is practical for large-scale problems. In our experiments, we evaluate the method on two different and very challenging sets of tasks: learning simulated robotic swimming, hopping, and walking gaits, and playing Atari games using images of the screen as input. For these tasks, the policies are neural networks with tens of thousands of parameters, mapping from observations to actions.", "histories": [["v1", "Thu, 19 Feb 2015 06:44:25 GMT  (547kb,D)", "http://arxiv.org/abs/1502.05477v1", "16 pages"], ["v2", "Mon, 18 May 2015 14:56:50 GMT  (540kb,D)", "http://arxiv.org/abs/1502.05477v2", "16 pages, ICML 2015"], ["v3", "Mon, 8 Jun 2015 10:47:03 GMT  (540kb,D)", "http://arxiv.org/abs/1502.05477v3", "16 pages, ICML 2015"], ["v4", "Mon, 6 Jun 2016 01:00:57 GMT  (541kb,D)", "http://arxiv.org/abs/1502.05477v4", "16 pages, ICML 2015"], ["v5", "Thu, 20 Apr 2017 18:04:12 GMT  (541kb,D)", "http://arxiv.org/abs/1502.05477v5", "16 pages, ICML 2015"]], "COMMENTS": "16 pages", "reviews": [], "SUBJECTS": "cs.LG", "authors": ["john schulman", "sergey levine", "pieter abbeel", "michael i jordan", "philipp moritz"], "accepted": true, "id": "1502.05477"}
