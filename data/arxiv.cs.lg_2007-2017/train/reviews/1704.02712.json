{"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "10-Apr-2017", "title": "Adaptive Relaxed ADMM: Convergence Theory and Practical Implementation", "abstract": "Many modern computer vision and machine learning applications rely on solving difficult optimization problems that involve non-differentiable objective functions and constraints. The alternating direction method of multipliers (ADMM) is a widely used approach to solve such problems. Relaxed ADMM is a generalization of ADMM that often achieves better performance, but its efficiency depends strongly on algorithm parameters that must be chosen by an expert user. We propose an adaptive method that automatically tunes the key algorithm parameters to achieve optimal performance without user oversight. Inspired by recent work on adaptivity, the proposed adaptive relaxed ADMM (ARADMM) is derived by assuming a Barzilai-Borwein style linear gradient. A detailed convergence analysis of ARADMM is provided, and numerical results on several applications demonstrate fast practical convergence.", "histories": [["v1", "Mon, 10 Apr 2017 05:07:38 GMT  (163kb,D)", "http://arxiv.org/abs/1704.02712v1", "CVPR 2017"]], "COMMENTS": "CVPR 2017", "reviews": [], "SUBJECTS": "cs.CV cs.AI cs.LG", "authors": ["zheng xu", "mario a t figueiredo", "xiaoming yuan", "christoph studer", "tom goldstein"], "accepted": false, "id": "1704.02712"}
