{"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "22-May-2012", "title": "Off-Policy Actor-Critic", "abstract": "This paper presents the first actor-critic algorithm for off-policy reinforcement learning. Our algorithm is online and incremental, and its per-time-step complexity scales linearly with the number of learned weights. Previous work on actor-critic algorithms is limited to the on-policy setting and does not take advantage of the recent advances in off-policy gradient temporal-difference learning. Off-policy techniques, such as Greedy-GQ, enable a target policy to be learned while following and obtaining data from another (behavior) policy. For many problems, however, actor-critic methods are more practical than action value methods (like Greedy-GQ) because they explicitly represent the policy; consequently, the policy can be stochastic and utilize a large action space. In this paper, we illustrate how to practically combine the generality and learning potential of off-policy learning with the flexibility in action selection given by actor-critic methods. We derive an incremental, linear time and space complexity algorithm that includes eligibility traces, prove convergence under assumptions similar to previous off-policy algorithms, and empirically show better or comparable performance to existing algorithms on standard reinforcement-learning benchmark problems.", "histories": [["v1", "Tue, 22 May 2012 08:36:41 GMT  (1034kb,D)", "http://arxiv.org/abs/1205.4839v1", "Full version of the paper including the appendix; Proceedings of the 2012 International Conference on Machine Learning"], ["v2", "Wed, 23 May 2012 14:36:42 GMT  (1034kb,D)", "http://arxiv.org/abs/1205.4839v2", "Full version of the paper, appendix included"], ["v3", "Tue, 17 Jul 2012 20:40:47 GMT  (1034kb,D)", "http://arxiv.org/abs/1205.4839v3", "Full version of the paper, appendix included"], ["v4", "Tue, 14 Aug 2012 07:08:17 GMT  (1034kb,D)", "http://arxiv.org/abs/1205.4839v4", "Full version of the paper, appendix included; Proceedings of the 2012 International Conference on Machine Learning"], ["v5", "Thu, 20 Jun 2013 10:53:42 GMT  (1035kb,D)", "http://arxiv.org/abs/1205.4839v5", "Full version of the paper, appendix and errata included; Proceedings of the 2012 International Conference on Machine Learning"]], "COMMENTS": "Full version of the paper including the appendix; Proceedings of the 2012 International Conference on Machine Learning", "reviews": [], "SUBJECTS": "cs.LG", "authors": ["thomas degris", "martha white", "richard s sutton"], "accepted": false, "id": "1205.4839"}
