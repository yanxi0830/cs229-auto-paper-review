{"conference": "NIPS", "VERSION": "v1", "DATE_OF_SUBMISSION": "23-May-2016", "title": "Fairness in Learning: Classic and Contextual Bandits", "abstract": "We introduce the study of fairness in multi-armed bandit problems. Our fairness definition can be interpreted as demanding that given a pool of applicants (say, for college admission or mortgages), a worse applicant is never favored over a better one, despite a learning algorithm's uncertainty over the true payoffs. We prove results of two types.", "histories": [["v1", "Mon, 23 May 2016 18:58:24 GMT  (511kb,D)", "http://arxiv.org/abs/1605.07139v1", null], ["v2", "Mon, 7 Nov 2016 15:49:05 GMT  (150kb,D)", "http://arxiv.org/abs/1605.07139v2", "A condensed version of this work appears in the 30th Annual Conference on Neural Information Processing Systems (NIPS), 2016"]], "reviews": [], "SUBJECTS": "cs.LG stat.ML", "authors": ["matthew joseph", "michael kearns", "jamie h morgenstern", "aaron roth"], "accepted": true, "id": "1605.07139"}
