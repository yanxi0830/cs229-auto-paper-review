{"conference": "ICML", "VERSION": "v1", "DATE_OF_SUBMISSION": "1-Jun-2015", "title": "Coordinate Descent Converges Faster with the Gauss-Southwell Rule Than Random Selection", "abstract": "There has been significant recent work on the theory and application of randomized coordinate descent algorithms, beginning with the work of Nesterov [SIAM J. Optim., 22(2), 2012], who showed that a random-coordinate selection rule achieves the same convergence rate as the Gauss-Southwell selection rule. This result suggests that we should never use the Gauss-Southwell rule, as it is typically much more expensive than random selection. However, the empirical behaviours of these algorithms contradict this theoretical result: in applications where the computational costs of the selection rules are comparable, the Gauss-Southwell selection rule tends to perform substantially better than random coordinate selection. We give a simple analysis of the Gauss-Southwell rule showing that---except in extreme cases---it's convergence rate is faster than choosing random coordinates. Further, in this work we (i) show that exact coordinate optimization improves the convergence rate for certain sparse problems, (ii) propose a Gauss-Southwell-Lipschitz rule that gives an even faster convergence rate given knowledge of the Lipschitz constants of the partial derivatives, (iii) analyze the effect of approximate Gauss-Southwell rules, and (iv) analyze proximal-gradient variants of the Gauss-Southwell rule.", "histories": [["v1", "Mon, 1 Jun 2015 16:04:37 GMT  (77kb,D)", "http://arxiv.org/abs/1506.00552v1", "ICML 2015, 34 pages"]], "COMMENTS": "ICML 2015, 34 pages", "reviews": [], "SUBJECTS": "math.OC cs.LG stat.CO stat.ML", "authors": ["julie nutini", "mark w schmidt", "issam h laradji", "michael p friedlander", "hoyt a koepke"], "accepted": true, "id": "1506.00552"}
