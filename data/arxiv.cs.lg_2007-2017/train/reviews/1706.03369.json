{"conference": "ICML", "VERSION": "v1", "DATE_OF_SUBMISSION": "11-Jun-2017", "title": "On the Sampling Problem for Kernel Quadrature", "abstract": "The standard Kernel Quadrature method for numerical integration with random point sets (also called Bayesian Monte Carlo) is known to converge in root mean square error at a rate determined by the ratio $s/d$, where $s$ and $d$ encode the smoothness and dimension of the integrand. However, an empirical investigation reveals that the rate constant $C$ is highly sensitive to the distribution of the random points. In contrast to standard Monte Carlo integration, for which optimal importance sampling is well-understood, the sampling distribution that minimises $C$ for Kernel Quadrature does not admit a closed form. This paper argues that the practical choice of sampling distribution is an important open problem. One solution is considered; a novel automatic approach based on adaptive tempering and sequential Monte Carlo. Empirical results demonstrate a dramatic reduction in integration error of up to 4 orders of magnitude can be achieved with the proposed method.", "histories": [["v1", "Sun, 11 Jun 2017 16:08:17 GMT  (4491kb,D)", "http://arxiv.org/abs/1706.03369v1", "To appear at Thirty-fourth International Conference on Machine Learning (ICML 2017)"]], "COMMENTS": "To appear at Thirty-fourth International Conference on Machine Learning (ICML 2017)", "reviews": [], "SUBJECTS": "stat.ML cs.LG math.NA stat.CO", "authors": ["fran\u00e7ois-xavier briol", "chris j oates", "jon cockayne", "wilson ye chen", "mark a girolami"], "accepted": true, "id": "1706.03369"}
