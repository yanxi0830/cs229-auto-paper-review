{"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "4-Dec-2016", "title": "Learning to superoptimize programs - Workshop Version", "abstract": "Superoptimization requires the estimation of the best program for a given computational task. In order to deal with large programs, superoptimization techniques perform a stochastic search. This involves proposing a modification of the current program, which is accepted or rejected based on the improvement achieved. The state of the art method uses uniform proposal distributions, which fails to exploit the problem structure to the fullest. To alleviate this deficiency, we learn a proposal distribution over possible modifications using Reinforcement Learning. We provide convincing results on the superoptimization of \"Hacker's Delight\" programs.", "histories": [["v1", "Sun, 4 Dec 2016 10:39:49 GMT  (758kb,D)", "http://arxiv.org/abs/1612.01094v1", "Workshop version for the NIPS NAMPI Workshop. Extended version atarXiv:1611.01787"]], "COMMENTS": "Workshop version for the NIPS NAMPI Workshop. Extended version atarXiv:1611.01787", "reviews": [], "SUBJECTS": "cs.LG", "authors": ["rudy bunel", "alban desmaison", "m pawan kumar", "philip h s torr", "pushmeet kohli"], "accepted": false, "id": "1612.01094"}
