{"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "13-Apr-2016", "title": "Bridging the Gaps Between Residual Learning, Recurrent Neural Networks and Visual Cortex", "abstract": "We discuss relations between Residual Networks (ResNet), Recurrent Neural Networks (RNNs) and the primate visual cortex. We begin with the observation that a shallow RNN is exactly equivalent to a very deep ResNet with weight sharing among the layers. A direct implementation of such a RNN, although having orders of magnitude fewer parameters, leads to a performance similar to the corresponding ResNet. We propose 1) a generalization of both RNN and ResNet architectures and 2) the conjecture that a class of moderately deep RNNs is a biologically-plausible model of the ventral stream in visual cortex. We demonstrate the effectiveness of the architectures by testing them on the CIFAR-10 dataset.", "histories": [["v1", "Wed, 13 Apr 2016 02:59:34 GMT  (1036kb,D)", "http://arxiv.org/abs/1604.03640v1", null]], "reviews": [], "SUBJECTS": "cs.LG cs.NE", "authors": ["qianli liao", "tomaso poggio"], "accepted": false, "id": "1604.03640"}
