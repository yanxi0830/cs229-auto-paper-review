{"conference": "nips", "VERSION": "v1", "DATE_OF_SUBMISSION": "28-May-2017", "title": "Convergence Analysis of Two-layer Neural Networks with ReLU Activation", "abstract": "In recent years, stochastic gradient descent (SGD) based techniques has become the standard tools for training neural networks. However, formal theoretical understanding of why SGD can train neural networks in practice is largely missing.", "histories": [["v1", "Sun, 28 May 2017 02:11:10 GMT  (1221kb,D)", "http://arxiv.org/abs/1705.09886v1", null]], "reviews": [], "SUBJECTS": "cs.LG", "authors": ["yuanzhi li", "yang yuan"], "accepted": true, "id": "1705.09886"}
