{"conference": "NIPS", "VERSION": "v1", "DATE_OF_SUBMISSION": "13-Jun-2013", "title": "Bregman Alternating Direction Method of Multipliers", "abstract": "The mirror descent algorithm (MDA) generalizes gradient descent by using a Bregman di- vergence to replace squared Euclidean distance as a proximal function. In this paper, we simi- larly generalize the alternating direction method of multipliers (ADMM) to Bregman ADMM (BADMM), which uses Bregman divergences as proximal functions in updates. BADMM allows the use of different Bregman divergences for different variable updates and involves alternating MDA-style updates, including alternating additive and alternating multiplicative updates as special cases. BADMM provides a unified framework for ADMM and its variants, including generalized ADMM and inexact ADMM. We establish the global convergence for BADMM. We present promising preliminary empirical results for BADMM applied to opti- mization over doubly stochastic matrices.", "histories": [["v1", "Thu, 13 Jun 2013 19:22:16 GMT  (254kb)", "http://arxiv.org/abs/1306.3203v1", null], ["v2", "Tue, 1 Jul 2014 05:57:36 GMT  (325kb)", "http://arxiv.org/abs/1306.3203v2", null], ["v3", "Tue, 8 Jul 2014 03:55:36 GMT  (625kb)", "http://arxiv.org/abs/1306.3203v3", null]], "reviews": [], "SUBJECTS": "math.OC cs.LG stat.ML", "authors": ["huahua wang", "arindam banerjee"], "accepted": true, "id": "1306.3203"}
