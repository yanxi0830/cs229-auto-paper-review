{"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "7-May-2015", "title": "Learning and Optimization with Submodular Functions", "abstract": "In many naturally occurring optimization problems one needs to ensure that the definition of the optimization problem lends itself to solutions that are tractable to compute. In cases where exact solutions cannot be computed tractably, it is beneficial to have strong guarantees on the tractable approximate solutions. In order operate under these criterion most optimization problems are cast under the umbrella of convexity or submodularity. In this report we will study design and optimization over a common class of functions called submodular functions. Set functions, and specifically submodular set functions, characterize a wide variety of naturally occurring optimization problems, and the property of submodularity of set functions has deep theoretical consequences with wide ranging applications. Informally, the property of submodularity of set functions concerns the intuitive \"principle of diminishing returns. This property states that adding an element to a smaller set has more value than adding it to a larger set. Common examples of submodular monotone functions are entropies, concave functions of cardinality, and matroid rank functions; non-monotone examples include graph cuts, network flows, and mutual information.", "histories": [["v1", "Thu, 7 May 2015 04:04:02 GMT  (271kb,D)", "http://arxiv.org/abs/1505.01576v1", "Tech Report - USC Computer Science CS-599, Convex and Combinatorial Optimization"]], "COMMENTS": "Tech Report - USC Computer Science CS-599, Convex and Combinatorial Optimization", "reviews": [], "SUBJECTS": "cs.LG", "authors": ["bharath sankaran", "marjan ghazvininejad", "xinran he", "david kale", "liron cohen"], "accepted": false, "id": "1505.01576"}
