{"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "16-Sep-2014", "title": "A Mixtures-of-Experts Framework for Multi-Label Classification", "abstract": "We develop a novel probabilistic approach for multi-label classification that is based on the mixtures-of-experts architecture combined with recently introduced conditional tree-structured Bayesian networks. Our approach captures different input-output relations from multi-label data using the efficient tree-structured classifiers, while the mixtures-of-experts architecture aims to compensate for the tree-structured restrictions and build a more accurate model. We develop and present algorithms for learning the model from data and for performing multi-label predictions on future data instances. Experiments on multiple benchmark datasets demonstrate that our approach achieves highly competitive results and outperforms the existing state-of-the-art multi-label classification methods.", "histories": [["v1", "Tue, 16 Sep 2014 16:52:14 GMT  (223kb,D)", "http://arxiv.org/abs/1409.4698v1", null]], "reviews": [], "SUBJECTS": "cs.LG", "authors": ["charmgil hong", "iyad batal", "milos hauskrecht"], "accepted": false, "id": "1409.4698"}
