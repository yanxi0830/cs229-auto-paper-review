{"conference": "NIPS", "VERSION": "v1", "DATE_OF_SUBMISSION": "10-Feb-2017", "title": "Following the Leader and Fast Rates in Linear Prediction: Curved Constraint Sets and Other Regularities", "abstract": "The follow the leader (FTL) algorithm, perhaps the simplest of all online learning algorithms, is known to perform well when the loss functions it is used on are convex and positively curved. In this paper we ask whether there are other \"lucky\" settings when FTL achieves sublinear, \"small\" regret. In particular, we study the fundamental problem of linear prediction over a non-empty convex, compact domain. Amongst other results, we prove that the curvature of the boundary of the domain can act as if the losses were curved: In this case, we prove that as long as the mean of the loss vectors have positive lengths bounded away from zero, FTL enjoys a logarithmic growth rate of regret, while, e.g., for polytope domains and stochastic data it enjoys finite expected regret. Building on a previously known meta-algorithm, we also get an algorithm that simultaneously enjoys the worst-case guarantees and the bound available for FTL.", "histories": [["v1", "Fri, 10 Feb 2017 01:59:02 GMT  (1791kb,D)", "http://arxiv.org/abs/1702.03040v1", null]], "reviews": [], "SUBJECTS": "cs.LG", "authors": ["ruitong huang", "tor lattimore", "andr\u00e1s gy\u00f6rgy", "csaba szepesv\u00e1ri"], "accepted": true, "id": "1702.03040"}
