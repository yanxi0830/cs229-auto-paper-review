{"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "7-Dec-2010", "title": "Bridging the Gap between Reinforcement Learning and Knowledge Representation: A Logical Off- and On-Policy Framework", "abstract": "Knowledge Representation is important issue in reinforcement learning. In this paper, we bridge the gap between reinforcement learning and knowledge representation, by providing a rich knowledge representation framework, based on normal logic programs with answer set semantics, that is capable of solving model-free reinforcement learning problems for more complex do-mains and exploits the domain-specific knowledge. We prove the correctness of our approach. We show that the complexity of finding an offline and online policy for a model-free reinforcement learning problem in our approach is NP-complete. Moreover, we show that any model-free reinforcement learning problem in MDP environment can be encoded as a SAT problem. The importance of that is model-free reinforcement", "histories": [["v1", "Tue, 7 Dec 2010 16:57:54 GMT  (676kb)", "http://arxiv.org/abs/1012.1552v1", null]], "reviews": [], "SUBJECTS": "cs.AI cs.LG cs.LO", "authors": ["emad saad"], "accepted": false, "id": "1012.1552"}
