{"conference": "iclr", "VERSION": "v1", "DATE_OF_SUBMISSION": "31-Aug-2016", "title": "Pruning Filters for Efficient ConvNets", "abstract": "Convolutional Neural Networks (CNNs) are extensively used in image and video recognition, natural language processing and other machine learning applications. The success of CNNs in these areas corresponds with a significant increase in the number of parameters and computation costs. Recent approaches towards reducing these overheads involve pruning and compressing the weights of various layers without hurting the overall CNN performance. However, using model compression to generate sparse CNNs mostly reduces parameters from the fully connected layers and may not significantly reduce the final computation costs.", "histories": [["v1", "Wed, 31 Aug 2016 02:29:59 GMT  (2623kb,D)", "http://arxiv.org/abs/1608.08710v1", null], ["v2", "Thu, 15 Sep 2016 02:12:36 GMT  (2624kb,D)", "http://arxiv.org/abs/1608.08710v2", null], ["v3", "Fri, 10 Mar 2017 17:57:56 GMT  (7203kb,D)", "http://arxiv.org/abs/1608.08710v3", "Published as a conference paper at ICLR 2017"]], "reviews": [], "SUBJECTS": "cs.CV cs.LG", "authors": ["hao li", "asim kadav", "igor durdanovic", "hanan samet", "hans peter graf"], "accepted": true, "id": "1608.08710"}
