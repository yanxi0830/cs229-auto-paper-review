{"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "15-Feb-2017", "title": "Distributed deep learning on edge-devices: feasibility via adaptive compression", "abstract": "The state-of-the-art results provided by deep learning come at the price of an intensive use of computing resources. The leading frameworks (eg., TensorFlow) are executed on GPUs or on high-end servers in datacenters. On the other end, there is a proliferation of personal devices with possibly free CPU cycles. In this paper, we ask the following question: Is distributed deep learning computation on WAN connected devices feasible, in spite of the traffic caused by learning tasks? We show that such a setup rises some important challenges, most notably the ingress traffic that the servers hosting the up-to-date model have to sustain. In order to reduce this stress, we propose AdaComp, a new algorithm for compressing worker updates to the model on the server. Applicable to stochastic gradient descent based approaches, it combines efficient gradient selection and learning rate modulation. We then experiment and measure the impact of compression and device reliability on the accuracy of learned models. To do so, we leverage an emulator platform we developed, that embeds the TensorFlow code into Linux containers. We report a reduction of the total amount of data sent by workers to the server by two order of magnitude (eg., 191-fold reduction for a convolutional network on the MNIST dataset), when compared to the standard algorithm based on asynchronous stochastic gradient descent, while maintaining model accuracy.", "histories": [["v1", "Wed, 15 Feb 2017 16:57:24 GMT  (1431kb,D)", "http://arxiv.org/abs/1702.04683v1", null]], "reviews": [], "SUBJECTS": "cs.LG", "authors": ["corentin hardy", "erwan le merrer", "bruno sericola"], "accepted": false, "id": "1702.04683"}
