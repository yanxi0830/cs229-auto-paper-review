{"conference": "iclr", "VERSION": "v1", "DATE_OF_SUBMISSION": "28-Feb-2016", "title": "Lie Access Neural Turing Machine", "abstract": "Recently, Neural Turing Machine and Memory Networks have shown that adding an external memory can greatly ameliorate a traditional recurrent neural network's tendency to forget after a long period of time. Here we present a new design of an external memory, wherein memories are stored in an Euclidean key space $\\mathbb R^n$. An LSTM controller performs read and write via specialized structures called read and write heads, following the design of Neural Turing Machine. It can move a head by either providing a new address in the key space (aka random access) or moving from its previous position via a Lie group action (aka Lie access). In this way, the \"L\" and \"R\" instructions of a traditional Turing Machine is generalized to arbitrary elements of a fixed Lie group action. For this reason, we name this new model the Lie Access Neural Turing Machine, or LANTM.", "histories": [["v1", "Sun, 28 Feb 2016 04:55:19 GMT  (1474kb,D)", "http://arxiv.org/abs/1602.08671v1", null], ["v2", "Tue, 23 Aug 2016 01:23:46 GMT  (781kb,D)", "http://arxiv.org/abs/1602.08671v2", null], ["v3", "Tue, 6 Sep 2016 14:42:56 GMT  (14976kb,AD)", "http://arxiv.org/abs/1602.08671v3", null]], "reviews": [], "SUBJECTS": "cs.NE cs.AI cs.LG", "authors": ["greg yang"], "accepted": true, "id": "1602.08671"}
