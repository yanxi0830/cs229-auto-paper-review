{"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "7-Jun-2017", "title": "Generative-Discriminative Variational Model for Visual Recognition", "abstract": "The paradigm shift from shallow classifiers with hand-crafted features to end-to-end trainable deep learning models has shown significant improvements on supervised learning tasks. Despite the promising power of deep neural networks (DNN), how to alleviate overfitting during training has been a research topic of interest. In this paper, we present a Generative-Discriminative Variational Model (GDVM) for visual classification, in which we introduce a latent variable inferred from inputs for exhibiting generative abilities towards prediction. In other words, our GDVM casts the supervised learning task as a generative learning process, with data discrimination to be jointly exploited for improved classification. In our experiments, we consider the tasks of multi-class classification, multi-label classification, and zero-shot learning. We show that our GDVM performs favorably against the baselines or recent generative DNN models.", "histories": [["v1", "Wed, 7 Jun 2017 10:19:30 GMT  (1660kb,D)", "http://arxiv.org/abs/1706.02295v1", null]], "reviews": [], "SUBJECTS": "cs.LG", "authors": ["chih-kuan yeh", "yao-hung hubert tsai", "yu-chiang frank wang"], "accepted": false, "id": "1706.02295"}
