{"conference": "iclr", "VERSION": "v1", "DATE_OF_SUBMISSION": "15-Nov-2016", "title": "PixelVAE: A Latent Variable Model for Natural Images", "abstract": "Natural image modeling is a landmark challenge of unsupervised learning. Variational Autoencoders (VAEs) learn a useful latent representation and model global structure well but have difficulty capturing small details. PixelCNN models details very well, but lacks a latent code and is difficult to scale for capturing large structures. We present PixelVAE, a VAE model with an autoregressive decoder based on PixelCNN. Our model requires very few expensive autoregressive layers compared to PixelCNN and learns latent codes that are more compressed than a standard VAE while still capturing most non-trivial structure. Finally, we extend our model to a hierarchy of latent variables at different scales. Our model achieves state-of-the-art performance on binarized MNIST, competitive performance on 64x64 ImageNet, and high-quality samples on the LSUN bedrooms dataset.", "histories": [["v1", "Tue, 15 Nov 2016 20:16:27 GMT  (2749kb,D)", "http://arxiv.org/abs/1611.05013v1", null]], "reviews": [], "SUBJECTS": "cs.LG", "authors": ["ishaan gulrajani", "kundan kumar", "faruk ahmed", "adrien ali taiga", "francesco visin", "david vazquez", "aaron courville"], "accepted": true, "id": "1611.05013"}
