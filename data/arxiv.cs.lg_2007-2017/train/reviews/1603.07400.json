{"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "24-Mar-2016", "title": "A Reconfigurable Low Power High Throughput Architecture for Deep Network Training", "abstract": "General purpose computing systems are used for a large variety of applications. Extensive supports for flexibility in these systems limit their energy efficiencies. Given that big data applications are among the main emerging workloads for computing systems, specialized architectures for big data processing are needed to enable low power and high throughput execution. Several big data applications are particularly focused on classification and clustering tasks. In this paper we propose a multicore heterogeneous architecture for big data processing. This system has the capability to process key machine learning algorithms such as deep neural network, autoencoder, and k-means clustering. Memristor crossbars are utilized to provide low power high throughput execution of neural networks. The system has both training and recognition (evaluation of new input) capabilities. The proposed system could be used for classification, unsupervised clustering, dimensionality reduction, feature extraction, and anomaly detection applications. The system level area and power benefits of the specialized architecture is compared with the NVIDIA Telsa K20 GPGPU. Our experimental evaluations show that the proposed architecture can provide four to six orders of magnitude more energy efficiency over GPGPUs for big data processing.", "histories": [["v1", "Thu, 24 Mar 2016 00:52:22 GMT  (1436kb)", "http://arxiv.org/abs/1603.07400v1", "11 pages"], ["v2", "Wed, 15 Jun 2016 01:26:31 GMT  (1111kb)", "http://arxiv.org/abs/1603.07400v2", "9 pages"]], "COMMENTS": "11 pages", "reviews": [], "SUBJECTS": "cs.LG cs.AR cs.DC", "authors": ["raqibul hasan", "tarek taha"], "accepted": false, "id": "1603.07400"}
