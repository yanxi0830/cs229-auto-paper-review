{"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "21-May-2016", "title": "Cross Domain Adaptation by Learning Partially Shared Classifiers and Weighting Source Data Points in the Shared Subspaces", "abstract": "Transfer learning is a problem defined over two domains. These two domains share the same feature space and class label space, but have significantly different distributions. One domain has sufficient labels, named as source domain, and the other domain has few labels, named as target do- main. The problem is to learn a effective classifier for the target domain. In this paper, we propose a novel transfer learning method for this problem by learning a partially shared classifier for the target domain, and weighting the source domain data points. We learn some shared subspaces for both the data points of the two domains, and a shared classifier in the shared subspaces. We hope that in the shared subspaces, the distributions of two domain can match each other well, and to match the distributions, we weight the source domain data points with different weighting factors. Moreover, we adapt the shared classifier to each domain by learning different adaptation functions. To learn the subspace transformation matrices, the classifier parameters, and the adaptation parameters, we build a objective function with weighted clas- sification errors, parameter regularization, local reconstruction regularization, and distribution matching. This objective function is minimized by an itera- tive algorithm. Experiments show its effectiveness over benchmark data sets, including travel destination review data set, face expression data set, spam email data set, etc.", "histories": [["v1", "Sat, 21 May 2016 16:57:37 GMT  (35kb)", "http://arxiv.org/abs/1605.06673v1", null]], "reviews": [], "SUBJECTS": "cs.LG", "authors": ["hongqi wang", "anfeng xu", "shanshan wang", "sunny chughtai"], "accepted": false, "id": "1605.06673"}
