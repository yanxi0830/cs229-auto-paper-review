{"conference": "acl", "VERSION": "v1", "DATE_OF_SUBMISSION": "23-Jun-2016", "title": "Analyzing the Behavior of Visual Question Answering Models", "abstract": "Recently, a number of deep-learning based models have been proposed for the task of Visual Question Answering (VQA). The performance of most models is clustered around 60-70%. In this paper we propose systematic methods to analyze the behavior of these models as a first step towards recognizing their strengths and weaknesses, and identifying the most fruitful directions for progress. We analyze the best performing models from two major classes of VQA models -- with-attention and without-attention and show the similarities and differences in the behavior of these models.", "histories": [["v1", "Thu, 23 Jun 2016 16:05:16 GMT  (8531kb,D)", "http://arxiv.org/abs/1606.07356v1", "13 pages, 20 figures; Under review at EMNLP 2016"], ["v2", "Tue, 27 Sep 2016 19:56:22 GMT  (5647kb,D)", "http://arxiv.org/abs/1606.07356v2", "13 pages, 20 figures; To appear in EMNLP 2016"]], "COMMENTS": "13 pages, 20 figures; Under review at EMNLP 2016", "reviews": [], "SUBJECTS": "cs.CL cs.AI cs.CV cs.LG", "authors": ["aishwarya agrawal", "dhruv batra", "devi parikh"], "accepted": true, "id": "1606.07356"}
