{"conference": "NIPS", "VERSION": "v1", "DATE_OF_SUBMISSION": "2-Apr-2014", "title": "Exploiting Linear Structure Within Convolutional Networks for Efficient Evaluation", "abstract": "We present techniques for speeding up the test-time evaluation of large convolutional networks, designed for object recognition tasks. These models deliver impressive accuracy but each image evaluation requires millions of floating point operations, making their deployment on smartphones and Internet-scale clusters problematic. The computation is dominated by the convolution operations in the lower layers of the model. We exploit the linear structure present within the convolutional filters to derive approximations that significantly reduce the required computation. Using large state-of-the-art models, we demonstrate speedups by a factor of 2x, while keeping the accuracy within 1% of the original model.", "histories": [["v1", "Wed, 2 Apr 2014 23:31:12 GMT  (907kb,D)", "https://arxiv.org/abs/1404.0736v1", null], ["v2", "Mon, 9 Jun 2014 15:53:55 GMT  (1261kb,D)", "http://arxiv.org/abs/1404.0736v2", null]], "reviews": [], "SUBJECTS": "cs.CV cs.LG", "authors": ["emily l denton", "wojciech zaremba", "joan bruna", "yann lecun", "rob fergus"], "accepted": true, "id": "1404.0736"}
