{"conference": "EMNLP", "VERSION": "v1", "DATE_OF_SUBMISSION": "19-Jun-2015", "title": "LCSTS: A Large Scale Chinese Short Text Summarization Dataset", "abstract": "Automatic text summarization is widely regarded as the highly difficult problem, partially because of the lack of large text summarization data set. Due to the great challenge of constructing the large scale summaries for full text, in this paper, we introduce a large corpus of Chinese short text summarization dataset constructed from the Chinese microblogging website Sina Weibo, which will be released to public soon. This corpus consists of over 2 million real Chinese short texts with short summaries given by the writer of each text. We also manually tagged the relevance of 10,666 short summaries with their corresponding short texts. Based on the corpus, we introduce recurrent neural network for the summary generation and achieve promising results, which not only shows the usefulness of the proposed corpus for short text summarization research, but also provides a baseline for further research on this topic.", "histories": [["v1", "Fri, 19 Jun 2015 02:40:42 GMT  (1912kb,D)", "https://arxiv.org/abs/1506.05865v1", null], ["v2", "Mon, 22 Jun 2015 14:33:39 GMT  (1908kb,D)", "http://arxiv.org/abs/1506.05865v2", null], ["v3", "Mon, 17 Aug 2015 02:43:38 GMT  (1904kb,D)", "http://arxiv.org/abs/1506.05865v3", null], ["v4", "Fri, 19 Feb 2016 16:35:35 GMT  (1310kb,D)", "http://arxiv.org/abs/1506.05865v4", "Recently, we received feedbacks from Yuya Taguchi from NAIST in Japan and Qian Chen from USTC of China, that the results in the EMNLP2015 version seem to be underrated. So we carefully checked our results and find out that we made a mistake while using the standard ROUGE. Then we re-evaluate all methods in the paper and get corrected results listed in Table 2 of this version"]], "reviews": [], "SUBJECTS": "cs.CL cs.IR cs.LG", "authors": ["baotian hu", "qingcai chen", "fangze zhu"], "accepted": true, "id": "1506.05865"}
