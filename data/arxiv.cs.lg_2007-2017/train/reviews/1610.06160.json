{"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "19-Oct-2016", "title": "Streaming Normalization: Towards Simpler and More Biologically-plausible Normalizations for Online and Recurrent Learning", "abstract": "We systematically explored a spectrum of normalization algorithms related to Batch Normalization (BN) and propose a generalized formulation that simultaneously solves two major limitations of BN: (1) online learning and (2) recurrent learning. Our proposal is simpler and more biologically-plausible. Unlike previous approaches, our technique can be applied out of the box to all learning scenarios (e.g., online learning, batch learning, fully-connected, convolutional, feedforward, recurrent and mixed --- recurrent and convolutional) and compare favorably with existing approaches. We also propose Lp Normalization for normalizing by different orders of statistical moments. In particular, L1 normalization is well-performing, simple to implement, fast to compute, more biologically-plausible and thus ideal for GPU or hardware implementations.", "histories": [["v1", "Wed, 19 Oct 2016 19:34:48 GMT  (894kb,D)", "http://arxiv.org/abs/1610.06160v1", null]], "reviews": [], "SUBJECTS": "cs.LG cs.NE", "authors": ["qianli liao", "kenji kawaguchi", "tomaso poggio"], "accepted": false, "id": "1610.06160"}
