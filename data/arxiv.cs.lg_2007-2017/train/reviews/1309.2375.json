{"conference": "ICML", "VERSION": "v1", "DATE_OF_SUBMISSION": "10-Sep-2013", "title": "Accelerated Proximal Stochastic Dual Coordinate Ascent for Regularized Loss Minimization", "abstract": "We introduce a proximal version of the stochastic dual coordinate ascent method and show how to accelerate the method using an inner-outer iteration procedure. We analyze the runtime of the framework and obtain rates that improve state-of-the-art results for various key machine learning optimization problems including SVM, logistic regression, ridge regression, Lasso, and multiclass SVM. Experiments validate our theoretical findings.", "histories": [["v1", "Tue, 10 Sep 2013 05:39:25 GMT  (38kb,D)", "https://arxiv.org/abs/1309.2375v1", null], ["v2", "Tue, 8 Oct 2013 06:06:09 GMT  (38kb,D)", "http://arxiv.org/abs/1309.2375v2", null]], "reviews": [], "SUBJECTS": "stat.ML cs.LG cs.NA stat.CO", "authors": ["shai shalev-shwartz", "tong zhang 0001"], "accepted": true, "id": "1309.2375"}
