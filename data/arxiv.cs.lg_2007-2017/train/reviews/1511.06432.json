{"conference": "iclr", "VERSION": "v1", "DATE_OF_SUBMISSION": "19-Nov-2015", "title": "Delving Deeper into Convolutional Networks for Learning Video Representations", "abstract": "We propose an approach to learn spatio-temporal features in videos from intermediate visual representations we call \"percepts\" using Gated-Recurrent-Unit Recurrent Networks (GRUs).Our method relies on percepts that are extracted from all level of a deep convolutional network trained on the large ImageNet dataset. While high-level percepts contain highly discriminative information, they tend to have a low-spatial resolution. Low-level percepts, on the other hand, preserve a higher spatial resolution from which we can model finer motion patterns. Using low-level percepts can leads to high-dimensionality video representations. To mitigate this effect and control the model number of parameters, we introduce a variant of the GRU model that leverages the convolution operations to enforce sparse connectivity of the model units and share parameters across the input spatial locations.", "histories": [["v1", "Thu, 19 Nov 2015 22:46:13 GMT  (387kb,D)", "http://arxiv.org/abs/1511.06432v1", "ICLR submission"], ["v2", "Mon, 23 Nov 2015 02:46:54 GMT  (386kb,D)", "http://arxiv.org/abs/1511.06432v2", "ICLR submission"], ["v3", "Thu, 7 Jan 2016 19:43:19 GMT  (387kb,D)", "http://arxiv.org/abs/1511.06432v3", "ICLR submission"], ["v4", "Tue, 1 Mar 2016 18:54:11 GMT  (388kb,D)", "http://arxiv.org/abs/1511.06432v4", "ICLR 2016"]], "COMMENTS": "ICLR submission", "reviews": [], "SUBJECTS": "cs.CV cs.LG cs.NE", "authors": ["nicolas ballas", "li yao", "chris pal", "aaron courville"], "accepted": true, "id": "1511.06432"}
