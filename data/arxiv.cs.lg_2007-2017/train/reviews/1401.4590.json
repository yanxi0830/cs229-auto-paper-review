{"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "18-Jan-2014", "title": "Combining Evaluation Metrics via the Unanimous Improvement Ratio and its Application to Clustering Tasks", "abstract": "Many Artificial Intelligence tasks cannot be evaluated with a single quality criterion and some sort of weighted combination is needed to provide system rankings. A problem of weighted combination measures is that slight changes in the relative weights may produce substantial changes in the system rankings. This paper introduces the Unanimous Improvement Ratio (UIR), a measure that complements standard metric combination criteria (such as van Rijsbergen's F-measure) and indicates how robust the measured differences are to changes in the relative weights of the individual metrics. UIR is meant to elucidate whether a perceived difference between two systems is an artifact of how individual metrics are weighted.", "histories": [["v1", "Sat, 18 Jan 2014 21:03:23 GMT  (1181kb)", "http://arxiv.org/abs/1401.4590v1", null]], "reviews": [], "SUBJECTS": "cs.AI cs.LG", "authors": ["enrique amig\\'o", "julio gonzalo", "javier artiles", "felisa verdejo"], "accepted": false, "id": "1401.4590"}
