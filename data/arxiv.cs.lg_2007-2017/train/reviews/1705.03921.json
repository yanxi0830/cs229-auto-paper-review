{"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "10-May-2017", "title": "Why & When Deep Learning Works: Looking Inside Deep Learnings", "abstract": "The Intel Collaborative Research Institute for Computational Intelligence (ICRI-CI) has been heavily supporting Machine Learning and Deep Learning research from its foundation in 2012. We have asked six leading ICRI-CI Deep Learning researchers to address the challenge of \"Why &amp; When Deep Learning works\", with the goal of looking inside Deep Learning, providing insights on how deep networks function, and uncovering key observations on their expressiveness, limitations, and potential. The output of this challenge resulted in five papers that address different facets of deep learning. These different facets include a high-level understating of why and when deep networks work (and do not work), the impact of geometry on the expressiveness of deep networks, and making deep networks interpretable.", "histories": [["v1", "Wed, 10 May 2017 18:52:26 GMT  (254kb)", "http://arxiv.org/abs/1705.03921v1", "This paper is the preface part of the \"Why &amp; When Deep Learning works looking inside Deep Learning\" ICRI-CI paper bundle"]], "COMMENTS": "This paper is the preface part of the \"Why &amp; When Deep Learning works looking inside Deep Learning\" ICRI-CI paper bundle", "reviews": [], "SUBJECTS": "cs.LG", "authors": ["ronny ronen"], "accepted": false, "id": "1705.03921"}
