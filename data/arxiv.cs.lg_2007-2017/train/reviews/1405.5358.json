{"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "21-May-2014", "title": "Off-Policy Shaping Ensembles in Reinforcement Learning", "abstract": "Recent advances of gradient temporal-difference methods allow to learn off-policy multiple value functions in parallel with- out sacrificing convergence guarantees or computational efficiency. This opens up new possibilities for sound ensemble techniques in reinforcement learning. In this work we propose learning an ensemble of policies related through potential-based shaping rewards. The ensemble induces a combination policy by using a voting mechanism on its components. Learning happens in real time, and we empirically show the combination policy to outperform the individual policies of the ensemble.", "histories": [["v1", "Wed, 21 May 2014 10:20:15 GMT  (828kb,D)", "http://arxiv.org/abs/1405.5358v1", "Full version of the paper to appear in Proc. ECAI 2014"]], "COMMENTS": "Full version of the paper to appear in Proc. ECAI 2014", "reviews": [], "SUBJECTS": "cs.AI cs.LG", "authors": ["anna harutyunyan", "tim brys", "peter vrancx", "ann nowe"], "accepted": false, "id": "1405.5358"}
