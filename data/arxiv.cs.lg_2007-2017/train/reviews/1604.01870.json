{"conference": "NIPS", "VERSION": "v1", "DATE_OF_SUBMISSION": "7-Apr-2016", "title": "Efficient Globally Convergent Stochastic Optimization for Canonical Correlation Analysis", "abstract": "We study the stochastic optimization of canonical correlation analysis (CCA), whose objective is nonconvex and does not decouple over training samples. Although several stochastic optimization algorithms have been recently proposed to solve this problem, no global convergence guarantee was provided by any of them. Based on the alternating least squares formulation of CCA, we propose a globally convergent stochastic algorithm, which solves the resulting least squares problems approximately to sufficient accuracy with state-of-the-art stochastic gradient methods for convex optimization. We provide the overall time complexity of our algorithm which significantly improves upon that of previous work. Experimental results demonstrate the superior performance of our algorithm.", "histories": [["v1", "Thu, 7 Apr 2016 04:14:54 GMT  (478kb)", "http://arxiv.org/abs/1604.01870v1", null], ["v2", "Wed, 20 Apr 2016 17:58:52 GMT  (461kb)", "http://arxiv.org/abs/1604.01870v2", null], ["v3", "Fri, 20 May 2016 03:09:29 GMT  (198kb)", "http://arxiv.org/abs/1604.01870v3", null], ["v4", "Mon, 14 Nov 2016 18:11:15 GMT  (648kb)", "http://arxiv.org/abs/1604.01870v4", "Accepted by NIPS 2016"]], "reviews": [], "SUBJECTS": "cs.LG", "authors": ["weiran wang", "jialei wang", "dan garber", "nati srebro"], "accepted": true, "id": "1604.01870"}
