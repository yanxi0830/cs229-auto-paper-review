{"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "16-Jan-2013", "title": "Learning Output Kernels for Multi-Task Problems", "abstract": "Simultaneously solving multiple related learning tasks is beneficial under a variety of circumstances, but the prior knowledge necessary to correctly model task relationships is rarely available in practice. In this paper, we develop a novel kernel-based multi-task learning technique that automatically reveals structural inter-task relationships. Building over the framework of output kernel learning (OKL), we introduce a method that jointly learns multiple functions and a low-rank multi-task kernel by solving a non-convex regularization problem. Optimization is carried out via a block coordinate descent strategy, where each subproblem is solved using suitable conjugate gradient (CG) type iterative methods for linear operator equations. The effectiveness of the proposed approach is demonstrated on pharmacological and collaborative filtering data.", "histories": [["v1", "Wed, 16 Jan 2013 20:16:02 GMT  (31kb,D)", "http://arxiv.org/abs/1301.3816v1", null]], "reviews": [], "SUBJECTS": "cs.LG", "authors": ["francesco dinuzzo"], "accepted": false, "id": "1301.3816"}
