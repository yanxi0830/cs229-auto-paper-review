{"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "10-Jan-2017", "title": "Multi-task Learning Of Deep Neural Networks For Audio Visual Automatic Speech Recognition", "abstract": "Multi-task learning (MTL) involves the simultaneous training of two or more related tasks over shared representations. In this work, we apply MTL to audio-visual automatic speech recognition(AV-ASR). Our primary task is to learn a mapping between audio-visual fused features and frame labels obtained from acoustic GMM/HMM model. This is combined with an auxiliary task which maps visual features to frame labels obtained from a separate visual GMM/HMM model. The MTL model is tested at various levels of babble noise and the results are compared with a base-line hybrid DNN-HMM AV-ASR model. Our results indicate that MTL is especially useful at higher level of noise. Compared to base-line, upto 7\\% relative improvement in WER is reported at -3 SNR dB", "histories": [["v1", "Tue, 10 Jan 2017 08:47:56 GMT  (35kb,D)", "http://arxiv.org/abs/1701.02477v1", null]], "reviews": [], "SUBJECTS": "cs.CL cs.AI cs.CV cs.LG", "authors": ["abhinav thanda", "shankar m venkatesan"], "accepted": false, "id": "1701.02477"}
