{"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "1-Jun-2016", "title": "Automatic tagging using deep convolutional neural networks", "abstract": "We present a content-based automatic music tagging algorithm using fully convolutional neural networks (FCNs). We evaluate different architectures consisting of 2D convolutional layers and subsampling layers only. In the experiments, we measure the AUC-ROC scores of the architectures with different complexities and input types using the MagnaTagATune dataset, where a 4-layer architecture shows state-of-the-art performance with mel-spectrogram input. Furthermore, we evaluated the performances of the architectures with varying the number of layers on a larger dataset (Million Song Dataset), and found that deeper models outperformed the 4-layer architecture. The experiments show that mel-spectrogram is an effective time-frequency representation for automatic tagging and that more complex models benefit from more training data.", "histories": [["v1", "Wed, 1 Jun 2016 14:18:08 GMT  (125kb,D)", "http://arxiv.org/abs/1606.00298v1", "Accepted to ISMIR (International Society of Music Information Retrieval) Conference 2016"]], "COMMENTS": "Accepted to ISMIR (International Society of Music Information Retrieval) Conference 2016", "reviews": [], "SUBJECTS": "cs.SD cs.LG", "authors": ["keunwoo choi", "george fazekas", "mark sandler"], "accepted": false, "id": "1606.00298"}
