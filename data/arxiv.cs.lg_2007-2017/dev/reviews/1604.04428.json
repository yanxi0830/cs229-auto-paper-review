{"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "15-Apr-2016", "title": "The Artificial Mind's Eye: Resisting Adversarials for Convolutional Neural Networks using Internal Projection", "abstract": "We introduce a novel type of artificial neural network structure and training procedure that results in networks that are provably, quantitatively more robust to adversarial samples than classical, end-to-end trained classifiers. The main idea of our approach is to force the network to make predictions on what the given instance of the class under consideration would look like and subsequently test those predictions. By forcing the network to redraw the relevant parts of the image and subsequently comparing this new image to the original, we are having the network give a 'proof' of the presence of the object.", "histories": [["v1", "Fri, 15 Apr 2016 11:07:45 GMT  (1969kb,D)", "https://arxiv.org/abs/1604.04428v1", "Under review as a conference paper at ECML PKDD 2016"], ["v2", "Thu, 14 Jul 2016 15:18:56 GMT  (1967kb,D)", "http://arxiv.org/abs/1604.04428v2", null]], "COMMENTS": "Under review as a conference paper at ECML PKDD 2016", "reviews": [], "SUBJECTS": "cs.LG cs.NE", "authors": ["harm berntsen", "wouter kuijper", "tom heskes"], "accepted": false, "id": "1604.04428"}
