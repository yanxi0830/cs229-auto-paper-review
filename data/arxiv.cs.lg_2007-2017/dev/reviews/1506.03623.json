{"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "11-Jun-2015", "title": "Max-Entropy Feed-Forward Clustering Neural Network", "abstract": "The outputs of non-linear feed-forward neural network are positive, which could be treated as probability when they are normalized to one. If we take Entropy-Based Principle into consideration, the outputs for each sample could be represented as the distribution of this sample for different clusters. Entropy-Based Principle is the principle with which we could estimate the unknown distribution under some limited conditions. As this paper defines two processes in Feed-Forward Neural Network, our limited condition is the abstracted features of samples which are worked out in the abstraction process. And the final outputs are the probability distribution for different clusters in the clustering process. As Entropy-Based Principle is considered into the feed-forward neural network, a clustering method is born. We have conducted some experiments on six open UCI datasets, comparing with a few baselines and applied purity as the measurement . The results illustrate that our method outperforms all the other baselines that are most popular clustering methods.", "histories": [["v1", "Thu, 11 Jun 2015 11:01:40 GMT  (456kb)", "http://arxiv.org/abs/1506.03623v1", "This paper has been published in ICANN 2015"]], "COMMENTS": "This paper has been published in ICANN 2015", "reviews": [], "SUBJECTS": "cs.LG", "authors": ["han xiao", "xiaoyan zhu"], "accepted": false, "id": "1506.03623"}
