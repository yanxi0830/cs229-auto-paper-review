{"conference": "NIPS", "VERSION": "v1", "DATE_OF_SUBMISSION": "17-Mar-2016", "title": "Optimal Black-Box Reductions Between Optimization Objectives", "abstract": "The diverse world of machine learning applications has given rise to a plethora of algorithms and optimization methods, finely tuned to the smoothness, convexity, and other parameterizations of the objective. In this paper we attempt to simplify and reduce the complexity of algorithm design for machine learning by reductions: we develop reductions that take a method developed for one setting and apply it to the entire spectrum of smoothness and strong-convexity found in practice.", "histories": [["v1", "Thu, 17 Mar 2016 19:51:59 GMT  (3863kb,D)", "http://arxiv.org/abs/1603.05642v1", null], ["v2", "Thu, 24 Mar 2016 05:11:42 GMT  (3864kb,D)", "http://arxiv.org/abs/1603.05642v2", "corrected a few typos in version 2"], ["v3", "Fri, 20 May 2016 17:03:15 GMT  (3658kb,D)", "http://arxiv.org/abs/1603.05642v3", "new applications of our optimal reductions are obtained in this version 3"]], "reviews": [], "SUBJECTS": "math.OC cs.DS cs.LG stat.ML", "authors": ["zeyuan allen zhu", "elad hazan"], "accepted": true, "id": "1603.05642"}
