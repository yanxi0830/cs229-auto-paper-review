{"conference": "ICML", "VERSION": "v1", "DATE_OF_SUBMISSION": "2-Nov-2011", "title": "Revisiting k-means: New Algorithms via Bayesian Nonparametrics", "abstract": "One of the many benefits of Bayesian nonparametric processes such as the Dirichlet process is that they can be used for modeling infinite mixture models, thus providing a flexible answer to the question of how many clusters exist in a data set. For the most part, such flexibility is currently lacking in techniques based on hard clustering, such as k-means, graph cuts, and Bregman hard clustering. For finite mixture models, there is a precise connection between k-means and mixtures of Gaussians, obtained by an appropriate limiting argument. In this paper, we apply a similar technique to an infinite mixture arising from the Dirichlet process (DP). We show that a Gibbs sampling algorithm for DP mixtures approaches a hard clustering algorithm in the limit, and further that the resulting algorithm monotonically minimizes an elegant underlying k-means-like objective that includes a penalty term based on the number of clusters. We generalize our analysis to the case of clustering multiple related data sets through a similar asymptotic argument with the hierarchical Dirichlet process. We discuss additional extensions that further highlight the benefits of our analysis: i) a spectral relaxation involving thresholded eigenvectors, and ii) a normalized cut graph clustering algorithm that requires O(|E|) time per iteration and automatically determines the number of clusters in a graph.", "histories": [["v1", "Wed, 2 Nov 2011 00:09:18 GMT  (148kb,D)", "http://arxiv.org/abs/1111.0352v1", "18 pages"], ["v2", "Thu, 14 Jun 2012 15:05:55 GMT  (101kb,D)", "http://arxiv.org/abs/1111.0352v2", "14 pages. Updated based on the corresponding ICML paper"]], "COMMENTS": "18 pages", "reviews": [], "SUBJECTS": "cs.LG stat.ML", "authors": ["brian kulis", "michael i jordan"], "accepted": true, "id": "1111.0352"}
