{"conference": "ICML", "VERSION": "v1", "DATE_OF_SUBMISSION": "8-Jun-2014", "title": "Learning Word Representations with Hierarchical Sparse Coding", "abstract": "We propose a new method for learning word representations using hierarchical regularization in sparse coding inspired by the linguistic study of word meanings. We apply an efficient online and distributed learning method. Experiments on various benchmark tasks---word similarity ranking, analogies, sentence completion, and sentiment analysis---demonstrate that the method outperforms or is competitive with state-of-the-art neural network representations. Our word representations are available at \\url{", "histories": [["v1", "Sun, 8 Jun 2014 22:35:09 GMT  (1145kb,D)", "http://arxiv.org/abs/1406.2035v1", null], ["v2", "Thu, 6 Nov 2014 14:26:21 GMT  (1142kb,D)", "http://arxiv.org/abs/1406.2035v2", null]], "reviews": [], "SUBJECTS": "cs.CL cs.LG stat.ML", "authors": ["dani yogatama", "manaal faruqui", "chris dyer", "noah a smith"], "accepted": true, "id": "1406.2035"}
