{"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "8-Jul-2010", "title": "A note on sample complexity of learning binary output neural networks under fixed input distributions", "abstract": "We show that the learning sample complexity of a sigmoidal neural network constructed by Sontag (1992) required to achieve a given misclassification error under a fixed purely atomic distribution can grow arbitrarily fast: for any prescribed rate of growth there is an input distribution having this rate as the sample complexity, and the bound is asymptotically tight. The rate can be superexponential, a non-recursive function, etc. We further observe that Sontag's ANN is not Glivenko-Cantelli under any input distribution having a non-atomic part.", "histories": [["v1", "Thu, 8 Jul 2010 03:58:25 GMT  (72kb)", "http://arxiv.org/abs/1007.1282v1", "6 pages, latex in IEEE conference proceedings format"]], "COMMENTS": "6 pages, latex in IEEE conference proceedings format", "reviews": [], "SUBJECTS": "cs.LG", "authors": ["vladimir pestov"], "accepted": false, "id": "1007.1282"}
