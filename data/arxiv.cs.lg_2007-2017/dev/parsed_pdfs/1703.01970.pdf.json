{
  "name" : "1703.01970.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "Concentration Bounds for High Sensitivity Functions Through Differential Privacy*",
    "authors" : [ "Kobbi Nissim", "Uri Stemmer" ],
    "emails" : [ "kobbi.nissim@georgetown.edu.", "stemmer@cs.bgu.ac.il." ],
    "sections" : [ {
      "heading" : null,
      "text" : "Very recently, Steinke and Ullman [16] observed that these generalization guarantees can be used for proving concentration bounds in the non-adaptive setting, where the low-sensitivity function is fixed beforehand. In particular, they obtain alternative proofs for classical concentration bounds for low-sensitivity functions, such as the Chernoff bound and McDiarmid’s Inequality.\nIn this work, we set out to examine the situation for functions with high-sensitivity, for which differential privacy does not imply generalization guarantees under adaptive analysis. We show that differential privacy can be used to prove concentration bounds for such functions in the non-adaptive setting.\nKeywords: Differential privacy, concentration bounds, high sensitivity functions\n*Research by K.N. and U.S. is supported by NSF grant No. 1565387. †Dept. of Computer Science, Georgetown University and Center for Research on Computation and Society (CRCS),\nHarvard University. kobbi.nissim@georgetown.edu. ‡Center for Research on Computation and Society (CRCS), Harvard University. stemmer@cs.bgu.ac.il.\nar X\niv :1\n70 3.\n01 97\n0v 1\n[ cs\n.L G\n] 6\nM ar\n1 Introduction\nA new line of work [6, 9, 15, 2] demonstrates how differential privacy [8] can be used as a mathematical tool for guaranteeing statistical validity in data analysis. Specifically, if a differentially private analysis is applied on a sample S of i.i.d. examples to select a low-sensitivity function f , then w.h.p. f (S) is close to its expectation, even when f is being chosen based on the data. Dwork et al. [6] showed how to utilize this connection for the task of answering adaptively chosen queries w.r.t. an unknown distribution using i.i.d. samples from it.\nTo make the setting concrete, consider a data analyst interested in learning properties of an unknown distribution D. The analyst interacts with the distribution D via a data curator A holding a database S containing n i.i.d. samples from D. The interaction is adaptive, where at every round the analyst specifies a query q : Xn→R and receives an answer aq(S) that (hopefully) approximates q(Dn) , ES ′∼Dn[q(S ′)]. As the analyst chooses its queries based on previous interactions with the data, we run the risk of overfitting if A simply answers every query with its empirical value on the sample S. However, if A is a differentially private algorithm then the interaction would not lead to overfitting:\nTheorem 1.1 ([6, 2], informal). A function f : Xn → R has sensitivity λ if |f (S) − f (S ′)| ≤ λ for every pair S,S ′ ∈ Xn differing in only one entry. Define f (Dn) , E\nS ′∼Dn [f (S ′)]. Let A : Xn → Fλ be\n(ε,δ)-differentially private where Fλ is the class of λ-sensitive functions, and n ≥ 1ε2 log( 4ε δ ). Then for every distribution D on X,\nPr S∼Dn f←A(S)\n[|f (S)− f (Dn)| ≥ 18ελn] < δ ε .\nIn words, if A is a differentially private algorithm operating on a database containing n i.i.d. samples from the distribution D, then A cannot (with significant probability) identify a lowsensitivity function that behaves differently on the sample S and on Dn.\nVery recently, Steinke and Ullman [16] observed that Theorem 1.1 gives alternative proofs for classical concentration bounds for low-sensitivity functions, such as the Chernoff bound and McDiarmid’s Inequality: Fix a function f : Xn → R with sensitivity λ and consider the trivial mechanismAf that ignores its input and always outputs f . Such a mechanism is (ε,δ)-differentially private for any choice of ε,δ ≥ 0 and hence Theorem 1.1 yields (up to constants) McDiarmid’s Inequality:\nPr S∼Dn [|f (S)− f (Dn)| ≥ 18ελn] < δ ε = 2−Ω(ε 2·n), (1)\nwhere the last equality follows by setting n = 1ε2 log( 4ε δ ).\nIn light of this result it is natural to ask if similar techniques yield concentration bounds for more general families of queries, and in particular queries that are not low-sensitivity functions. In this work we derive conditions under which this is the case.\n1.1 Differential Privacy, Max-Information, and Typical Stability\nLet D be a fixed distribution over a domain X, and consider a family of functions mapping databases in Xn to the reals, such that for every function f in the family we have that |f (S)− f (Dn)| is small w.h.p. over S ∼ Dn. Specifically,\nFα,β(D) = { f : Xn→R : Pr\nS∼Dn [|f (S)− f (Dn)| > α] ≤ β\n} .\nThat is, for every function f ∈ Fα,β(D) we have that its empirical value over a sample S ∼ Dn is α-close to its expected value w.p. 1− β. Now consider a differentially private algorithm A : Xn→ Fα,β(D) that takes a database and returns a function from Fα,β(D). What can we say about the difference |f (S)− f (Dn)| when f is chosen by A(S) based on the sample S itself?\nUsing the notion of max-information, Dwork et al. [5] showed that if β is small enough, then w.h.p. the difference remains small. Informally, they showed that if A is differentially private, then\nPr S∼Dn f←A(S)\n[|f (S)− f (Dn)| > α] ≤ β · eε 2·n.\nSo, if A is a differentially private algorithm that ranges over functions which are very concentrated around their expected value (i.e., β < e−ε\n2n), then |f (S)− f (Dn)| remains small (w.h.p.) even when f is chosen by A(S) based on the sample S. When β > e−ε2n it is easy to construct examples where a differentially private algorithm identifies a function f ∈ Fα,β(D) such that |f (S)−f (Dn)| is arbitrarily large with high probability. So, in general, differential privacy does not guarantee generalization for adaptively chosen functions of this sort. However, a stronger notion than differential privacy – typical stability – presented by Bassily and Freund [1] does guarantee generalization in this setting. Informally, they showed that if a typically stable algorithm B outputs a function f ∈ Fα,β(D), then |f (S)− f (Dn)| remains small.1\nThe results of this article provide another piece of this puzzle, as we show that (a variant of) differential privacy can in some cases be used to prove that a function f is in Fα,β(D).\n1.2 Our Results\nNotation. Throughout this article we use the convention that f (Dn) is the expected value of the function f over a sample containing n i.i.d. elements drawn according to the distribution D. That is, f (Dn) , E\nS∼Dn [f (S)].\nFix a function f : Xn→R, let D be a distribution over X, and let S ∼ Dn. Our goal is to bound the probability that |f (S)− f (Dn)| is large by some (hopefully) easy-to-analyze quantity. To intuit our result, consider for example what we get by a simple application of Markov’s Inequality:\nPr S∼Dn [|f (S)− f (Dn)| > λ] ≤ 1 λ · E S∼Dn\n[ 1|f (S)−f (Dn)|>λ · |f (S)− f (Dn)| ] . (2)\nWe show that using differential privacy we can replace the term |f (S)−f (Dn)| in the expectation with |f (S ∪ {x})− f (S ∪ {y})|, which can sometimes be easier to analyze. Specifically, we show the following.\nTheorem 1.2 (part 1). Let D be a distribution over a domain X, let f : Xn→R , and let ∆,λ ∈R≥0 be s.t. for every 1 ≤ i ≤ n it holds that\nE S∼Dn z∼D\n[ 1|f (S)−f (S(i←z))|>λ · ∣∣∣∣f (S)− f (S(i←z))∣∣∣∣] ≤ ∆, (3) where S(i←z) is the same as S except that the ith element is replaced with z. Then for every ε > 0 we have that\nPr S∼Dn [|f (S)− f (Dn)| ≥ 18ελn] < 14∆ ελ ,\nprovided that n ≥O (\n1 ε·min{1,ε} log( λ·min{1,ε} ∆ )\n) .\n1A similar notion – perfect generalization – was presented in [4].\nObserve that for a λ-sensitive function f , we have that the expectation in Equation (3) is zero, so the statement holds for every choice of β > 0 and n ≥ O ( 1 ε2 log( 1 β ) ) , resulting in McDiarmid’s Inequality (Equation (1)). Intuitively, Theorem 1.2 states that in order to obtain a high probability\nbound on |f (S)− f (Dn)| is suffices to analyze the “expectation of the tail” of ∣∣∣∣f (S)− f (S(i←z))∣∣∣∣, as a function of the starting point λ. We also show that the above bound can be improved whenever the “expectation of the head” of∣∣∣∣f (S)− f (S(i←z))∣∣∣∣ is smaller than λ. Specifically,\nTheorem 1.2 (part 2). If, in addition to (3), ∃τ ≤ λ s.t. for every S ∈ Xn and every 1 ≤ i ≤ n we have\nE y,z∼D\n[ 1|f (S(i←y))−f (S(i←z))|≤λ · ∣∣∣∣f (S(i←y))− f (S(i←z))∣∣∣∣] ≤ τ, (4) Then for every ε > 0 we have that\nPr S∼Dn [|f (S)− f (Dn)| ≥ 18ετn] < 14∆ ετ ,\nprovided that n ≥O (\nλ ε·min{1,ε}τ log( τ ·min{1,ε} ∆ ) ) Observe that while the expectation in (3) is over the entire sample S (as well as the replacement point), in requirement (4) the sample S is fixed. We do not know if this “worst-case” restriction is necessary.\nIn Section 4 we demonstrate how Theorem 1.2 can be used in proving a variety of concentration bounds, such as a high probability bound on |f (S)− f (Dn)| for Lipschitz functions. In addition we show that Theorem 1.2 can be used to bound the probability that the number of triangles in a random graph significantly exceeds the expectation.\n2 Preliminaries\n2.1 Differential Privacy\nOur results rely on a number of basic facts about differential privacy. An algorithm operating on databases is said to preserve differential privacy if a change of a single record of the database does not significantly change the output distribution of the algorithm. Formally:\nDefinition 2.1. Databases S ∈ Xn and S ′ ∈ Xn over a domain X are called neighboring if they differ in exactly one entry.\nDefinition 2.2 (Differential Privacy [8, 7]). A randomized algorithmA : Xn→ Y is ( ,δ)-differentially private if for all neighboring databases S,S ′ ∈ Xn, and for every set of outputs T ⊆ Y , we have\nPr[A(S) ∈ T ] ≤ eε ·Pr[A(S ′) ∈ T ] + δ.\nThe probability is taken over the random coins of A.\n2.2 The Exponential Mechanism\nWe next describe the exponential mechanism of McSherry and Talwar [14].\nDefinition 2.3 (Sensitivity). The sensitivity (or global sensitivity) of a function f : Xn→ R is the smallest λ such that for every neighboring S,S ′ ∈ Xn, we have |f (S)− f (S ′)| ≤ λ. We use the term “λ-sensitive function” to mean a function of sensitivity ≤ λ.\nLetX be a domain andH a set of solutions. Given a database S ∈ X∗, the exponential mechanism privately chooses a “good” solution h out of the possible set of solutions H . This “goodness” is quantified using a quality function that matches solutions to scores.\nDefinition 2.4 (Quality function). A quality function is a function q : X∗ ×H → R that maps a database S ∈ X∗ and a solution h ∈H to a real number, identified as the score of the solution h w.r.t. the database S.\nGiven a quality function q and a database S, the goal is to chooses a solution h approximately maximizing q(S,h). The exponential mechanism chooses a solution probabilistically, where the probability mass that is assigned to each solution h increases exponentially with its quality q(S,h):\nThe Exponential Mechanism Input: privacy parameter ε > 0, finite solution set H , database S ∈ Xn, and a λ-sensitive quality function q.\n1. Randomly choose h ∈H with probability exp( ε 2λ ·q(S,h))∑ h′∈H exp( ε2λ ·q(S,h′)) .\n2. Output h.\nTheorem 2.5 (Properties of the exponential mechanism). (i) The exponential mechanism is (ε,0)differentially private. (ii) Let Opt(S) ,maxf ∈H {q(S,f )} and ∆ > 0. The exponential mechanism outputs a solution h such that q(S,h) ≤ (Opt(S)−∆) with probability at most |H | · exp ( − ε∆2λ ) .\n2.3 Concentration Bounds\nLet X1, . . . ,Xn be independent random variables where Pr[Xi = 1] = p and Pr[Xi = 0] = 1 − p for some 0 < p < 1. Clearly, E[ ∑n i=1Xi] = pn. Chernoff and Hoeffding bounds show that the sum is concentrated around this expected value:\nPr  n∑ i=1 Xi > (1 + δ)pn  ≤ exp(−pnδ2/3) for 0 < δ ≤ 1, Pr\n n∑ i=1 Xi < (1− δ)pn  ≤ exp(−pnδ2/2) for 0 < δ < 1, Pr\n ∣∣∣∣∣∣∣ n∑ i=1 Xi − pn ∣∣∣∣∣∣∣ > δ  ≤ 2exp(−2δ2/n) for δ ≥ 0.\nThe first two inequalities are known as the multiplicative Chernoff bounds [3], and the last inequality is known as the Hoeffding bound [10]. The next theorem states that the Chernoff bound above is tight up to constant factors in the exponent.\nTheorem 2.6 (Tightness of Chernoff bound [12]). Let 0 < p,δ ≤ 12 , and let n ≥ 3 δ2p . Let X1, . . . ,Xn be independent random variables where Pr[Xi = 1] = p and Pr[Xi = 0] = 1− p. Then,\nPr  n∑ i=1 Xi ≤ (1− δ)pn  ≥ exp(−9δ2pn), Pr\n n∑ i=1 Xi ≥ (1 + δ)pn  ≥ exp(−9δ2pn). 3 Concentration Bounds via Differential Privacy\nIn this section we show how the concept of differential privacy can be used to derive conditions under which a function f and a distributionD satisfy that |f (S)−f (Dn)| is small w.h.p. when S ∼ Dn. Our proof technique builds on the proof of Bassily et al. [2] for the generalization properties of a differentially private algorithm that outputs a low-sensitivity function. The proof consists of two steps:\n1. Let S1, . . . ,ST be T independent samples from Dn (each containing n i.i.d. samples from D). Let A be selection procedure that, given S1, . . . ,ST , chooses an index t ∈ [T ] with the goal of maximizing |f (St)− f (Dn)|. We show that if A satisfies (a variant of) differential privacy then, under some conditions on the function f and the distribution D, the expectation of |f (St)− f (Dn)| is bounded. That is, if A is differentially private, then its ability to identify a “bad” index t with large |f (St)− f (Dn)| is limited.\n2. We show that if |f (S)− f (Dn)| is large w.h.p. over S ∼ Dn, then it is possible to construct an algorithm A satisfying (a variant of) differential privacy that contradicts our expectation bound.\nWe begin with a few definitions.\n3.1 Definitions\nNotations. We use ~S ∈ (Xn)T to denote a multi-database consisting of T databases of size n over X. Given a distribution D over a domain X we write ~S ∼ DnT to denote a multi-database sampled i.i.d. from D.\nDefinition 3.1. Fix a function f : Xn → R mapping databases of size n over a domain X to the reals. We say that two multi-databases ~S = (S1, . . . ,ST ) ∈ (Xn)T and ~S ′ = (S ′1, . . . ,S ′ T ) ∈ (X\nn)T are (f ,λ)-neighboring if for all 1 ≤ i ≤ T we have that\n|f (Si)− f (S ′i )| ≤ λ.\nDefinition 3.2 ((ε, (f ,λ))-differential privacy). Let M : (Xn)T → Y be a randomized algorithm that operates on T databases of size n from X. For a function f : Xn → R and parameters ε,λ ≥ 0, we say that M is (ε, (f ,λ))-differentially private if for every set of outputs F ∈ Y and for every (f ,λ)-neighboring ~S, ~S ′ ∈ (Xn)T it holds that\nPr[M(~S) ∈ F] ≤ eε ·Pr[M(~S ′) ∈ F].\nClaim 3.3. Fix a function f : Xn→R and parameters ε ≤ 1 and λ ≥ 0. If M : (Xn)T → Y is (ε, (f ,λ))differentially private then for every (f ,λ)-neighboring databases ~S, ~S ′ ∈ (Xn)T and every function h : Y →R we have that\nE y←M(~S) [h(y)] ≤ E y←M(~S ′) [h(y)] + 4ε · E y←M(~S ′) [|h(y)|] .\nClaim 3.3 follows from basic arguments in differential privacy. The proof appears in the appendix for completeness.\n3.2 Multi Sample Expectation Bound\nThe proof of Theorem 1.2 contains somewhat unwieldy notation. For readability, we present here a restricted version of the theorem, tailored to the case where the function f computes the sample sum, which highlights most of the ideas in the proof. The full proof of Theorem 1.2 is included in the appendix. Notation. Given a sample S ∈ Xn, we use f̄ (S) to denote the sample sum, i.e., f̄ (S) = ∑ x∈S x.\nLemma 3.4 (Simplified Expectation Bound). Let D be a distribution over a domain X such that E x∼D [x] = 0 and E x∼D [ 1{|x|>1} · |x| ] ≤ ∆. Fix 0 < ε ≤ 1, and letA : (Xn)T → [T ] be an (ε, (f̄ ,1))-differentially private algorithm that operates on T databases of size n from X, and outputs an index 1 ≤ t ≤ T . Then∣∣∣∣∣∣∣∣∣∣ E~S∼DnTt←A(~S) [ f̄ (St)\n]∣∣∣∣∣∣∣∣∣∣ ≤ 4εn+ 2nT∆. Proof. We denote ~S = (S1, . . . ,ST ), where every St is itself a vector St = (xt,1, . . . ,xt,n). We have:\nE ~S∼DnT t←A(~S)\n[ f̄ (St) ] = ∑ i∈[n] E ~S∼DnT E t←A(~S) [ xt,i ]\n= ∑ i∈[n] E ~S∼DnT 1{max m∈[t] |xm,i | ≤ 1 } · E t←A(~S) [ xt,i ] +1 { max m∈[t] |xm,i | > 1 } · E t←A(~S) [ xt,i ] . (5) In the case where maxm∈[t] |xm,i | > 1 we replace the expectation over t←A(~S) with the deterministic choice for the maximal t (this makes the expression larger). When maxm∈[t] |xm,i | ≤ 1 we can use the privacy guarantees of algorithm A. Given a multi-sample ~S ∈ (Xn)T we use ~S−i to denote a multi-sample identical to ~S, except that the ith element of every sub-sample is replaced with 0. Using Claim 3.3 we get\n(5) ≤ ∑ i∈[n] E ~S∼DnT 1{max m∈[t] |xm,i | ≤ 1 } ·  E t←A(~S−i ) [ xt,i ] + 4ε E t←A(~S−i ) [ |xt,i | ]+1{max m∈[t] |xm,i | > 1 } · max m∈[T ] |xm,i | \n≤ 4εn + ∑ i∈[n] E ~S∼DnT 1{max m∈[t] |xm,i | ≤ 1 } · E t←A(~S−i ) [ xt,i ] +1 { max m∈[t] |xm,i | > 1 } · max m∈[T ] |xm,i |  (6)\nWe next want to remove the first indicator function. This is useful as without it, the expectation of a fresh example from D is zero. To that end we add and subtract the expression 1 { maxm∈[t] |xm,i | > 1 } · E t←A(~S−i ) [ xt,i ] to get (after replacing again Et with maxt)\n(6) ≤ 4εn + ∑ i∈[n] E ~S∼DnT  E t←A(~S−i ) [ xt,i ] + 2 ·1 { max m∈[t] |xm,i | > 1 } · max m∈[T ] |xm,i | \n≤ 4εn + 2 ∑ i∈[n] ∑ m∈[T ] E ~S∼DnT [ 1 { |xm,i | > 1 } · |xm,i | ] ≤ 4εn + 2nT∆.\n3.3 Multi Sample Amplification\nTheorem 3.5 (Simplified High Probability Bound). Let D be a distribution over a domain X such that E x∼D [x] = 0. Let ∆ ≥ 0 be such that E x∼D [ 1{|x|>1} · |x| ] ≤ ∆. Fix 1 ≥ ε ≥ √ 1 n ln(2/∆). We have that\nPr S∼Dn\n[ |f̄ (S)| ≥ 30εn ] < ∆\nε .\nWe present the proof idea of the theorem. Any informalities made hereafter are removed in Section A.\nProof sketch. We only analyze the probability that f̄ (S) is large. The analysis is symmetric for when f̄ (S) is small. Assume towards contradiction that with probability at least ∆2ε we have that f̄ (S) ≥ 30εn. We now construct the following algorithm B that contradicts our expectation bound.\nAlgorithm 1 B\nInput: T databases of size n each: ~S = (S1, . . . ,ST ), where T , b2ε/∆c.\n1. For i ∈ [T ], define q(~S, i) = f̄ (Si). 2. Sample t∗ ∈ [T ] with probability proportional to exp ( ε 2q(~S, t) ) .\nOutput: t.\nThe fact that algorithm B is (ε, (f̄ ,1))-differentially private follows from the standard analysis of the Exponential Mechanism of McSherry and Talwar [14]. The analysis appears in the full version of this proof (Section A) for completeness.\nNow consider applying B on databases ~S = (S1, . . . ,ST ) containing i.i.d. samples from D. By our assumption on D, for every t we have that f̄ (St) ≥ 30εn with probability at least ∆2ε . By our choice of T = b2ε/∆c, we therefore get\nPr ~S∼DnT [ max t∈[T ] { f̄ (St) } ≥ 30εn ] ≥ 1− ( 1− ∆ 2ε )T ≥ 1 2 .\nThe probability is taken over the random choice of the examples in ~S according to D. Had it been the case that the random variable maxt∈[T ] { f̄ (St) } is non-negative, we could have used Markov’s\ninequality to get\nE ~S∼DnT [ max t∈[T ] { q(~S, t) }] = E ~S∼DnT [ max t∈[T ] { f̄ (St) }] ≥ 15εn. (7)\nEven though it is not the case that maxt∈[T ] { f̄ (St) } is non-negative, we now proceed as if Equation (7) holds. As described in the full version of this proof (Section A), this technical issue has an easy fix. So, in expectation, maxt∈[T ] ( q(~S, t) ) is large. In order to contradict the expectation bound of Theorem A.2, we need to show that this is also the case for the index t∗ that is sampled on Step 2. To that end, we now use the following technical claim, stating that the expected quality of a solution sampled as in Step 2 is high.\nClaim 3.6 (e.g., [2]). Let H be a finite set, h :H →R a function, and η > 0. Define a random variable Y on H by Pr[Y = y] = exp(ηh(y))/C, where C = ∑ y∈H exp(ηh(y)). Then E [h(Y )] ≥ maxy∈H h(y) − 1 η ln |H |.\nFor every fixture of ~S, we can apply Claim 3.6 with h(t) = q(~S, t) and η = ε2 to get\nE t∗∈R[T ] [q(~S, t∗)] = E t∗∈R[T ]\n[ f̄ (St∗) ] ≥max t∈[T ] { f̄ (St) } − 2 ε ln(T ).\nTaking the expectation also over ~S ∼ DnT we get that\nE ~S∼DnT t∗←B ( ~S ) [ f̄ (St∗) ] ≥ E ~S∼DnT [ max t∈[T ] { f̄ (St) }] − 2 ε ln(T )\n≥ 15εn− 2 ε ln(T ).\nThis contradicts Theorem A.2 whenever ε > √\n1 n ln(T ) = √ 1 n ln(2ε/∆).\n4 Applications\nIn this section we demonstrate how Theorem 1.2 can be used in proving a variety of concentration bounds.\n4.1 Example: Subgaussian Diameter and Beyond\nRecall that for a low-sensitivity function f , one could use McDiarmid’s Inequality to obtain a high probability bound on the difference |f (S)− f (Dn)|, and this bound is distribution-independent. That is, the bound does not depend onD. Over the last few years, there has been some work on providing distribution-dependent refinements to McDiarmid’s Inequality, that hold even for functions with high worst-case sensitivity, but with low “average-case” sensitivity, where “average” is with respect to the underlying distribution D. The following is one such refinement, by Kontorovich [13].\nDefinition 4.1 ([13]). Let D be a distribution over a domain X, and let ρ : X2 → R≥0. The symmetrized distance of (X,ρ,D) is the random variable Ξ = ξ ·ρ(x,x′) where x,x′ ∼ D are independent and ξ is uniform on {±1} independent of x,x′. The subgaussian diameter of (X,ρ,D), denoted ∆SG(X,ρ,D), is the smallest σ ∈R≥0 such that\nE [ eλΞ ] ≤ eσ 2λ2/2, ∀λ ∈R.\nIn [13], Kontorovich showed the following theorem:\nTheorem 4.2 ([13], informal). Let f : Xn→R be a function mapping databases of size n over a domain X to the reals. Assume that there exists a function ρ : X2→R≥0 s.t. for every i ∈ [n], every S ∈ Xn, and every y,z ∈ X we have that ∣∣∣∣f (S(i←y))− f (S(i←z))∣∣∣∣ ≤ ρ(y,z), where S(i←x) is the same as S except that the ith element is replaced with x. Then,\nPr S∼Dn [|f (S)− f (Dn)| ≥ t] ≤ 2exp − t22n ·∆2SG(X,ρ,D)  . Informally, using the above theorem it is possible to obtain concentration bounds for functions with unbounded sensitivity (in worst case), provided that the sensitivity (as a random variable) is subgaussian. In this section we show that our result implies a similar version of this theorem. While the bound we obtain is weaker then Theorem 4.2, our techniques can be extended to obtain concentration bounds even in cases where the sensitivity is not subgaussian (that is, in cases where the subgaussian diameter is unbounded, and hence, Theorem 4.2 could not be applied).\nLet us denote σ = ∆SG(X,ρ,D). Now for t ≥ 0,\nPr x,y∼D [ρ(x,y) ≥ t] ≤ 2 Pr x,y∈D ξ∈{±1}\n[ξ · ρ(x,y) ≥ t] = 2Pr[Ξ ≥ t] = 2Pr[e t σ2 ·Ξ ≥ e t σ2 ·t]\n≤ 2e− t2 σ2 ·E [ e t σ2 ·Ξ ] ≤ 2e− t2 σ2 · e σ2 2 · t2 σ4 = 2exp ( − t 2\n2σ2\n) . (8)\nSo,\nE S∼Dn x′∼D\n[ 1 {∣∣∣∣f (S)− f (S(i←x′))∣∣∣∣ > λ} · ∣∣∣∣f (S)− f (S(i←x′))∣∣∣∣] ≤ E x,y∼D [1 { ρ(x,y) > λ } · ρ(x,y)]\n= ∫ λ\n0 Pr x,y∼D [1\n{ ρ(x,y) > λ } · ρ(x,y) ≥ t]dt + ∫ ∞ λ Pr x,y∼D [1 { ρ(x,y) > λ } · ρ(x,y) ≥ t]dt\n= ∫ λ\n0 Pr x,y∼D [ρ(x,y) ≥ λ]dt + ∫ ∞ λ Pr x,y∼D [ρ(x,y) ≥ t]dt\n= λ · Pr x,y∼D [ρ(x,y) ≥ λ] + ∫ ∞ λ Pr x,y∼D [ρ(x,y) ≥ t]dt\n≤ λ · 2exp ( − λ 2\n2σ2\n) + ∫ ∞ λ 2exp ( − t 2 2σ2 ) dt\n= λ · 2exp ( − λ 2\n2σ2\n) + √ 2πσ · erfc ( λ √\n2σ ) ≤ λ · 2exp ( − λ 2\n2σ2\n) + √ 2πσ · exp ( − λ 2\n2σ2\n) ≤ 3(λ+ σ ) · exp ( − λ 2\n2σ2\n) , ∆.\nIn order to apply Theorem 1.2 we need to ensure that n ≥ O (\n1 ε·min{1,ε} ln\n( λ·min{1,ε}\n∆\n)) . For our\nchoice of ∆, it suffices to set ε0 = Θ ( λ√ nσ ) , assuming that λ√ nσ ≤ 1. Otherwise, if λ√ nσ > 1, we will\nchoose ε1 = Θ ( λ2\nnσ2\n) . Plugging (ε0,∆) or (ε1,∆) into Theorem 1.2, and simplifying, we get\nPr S∼D\n[|f (S)− f (Dn)| ≥ t] ≤  e −Ω ( t√ nσ ) , t ≤ σ ·n1.5\ne −Ω\n( t2/3\nσ2/3 ) , t > σ ·n1.5\n(9)\nClearly, the bound of Theorem 4.2 is stronger. Note, however, that the only assumption we used here is that ∫∞ λ\nPrx,y∼D[ρ(x,y) ≥ t]dt is small. Hence, as the following section shows, this argument could be extended to obtain concentration bounds even when ∆SG(X,ρ,D) is unbounded. We remark that Inequality 9 can be slightly improved by using part 2 of Theorem 1.2. This will be illustrated in the following section.\n4.2 Example: Concentration Under Infinite Variance\nLet f : Xn→R be a function mapping databases of size n over a domain X to the reals. Assume that there exists a function ρ : X2→ R≥0 s.t. for every i ∈ [n], every S ∈ Xn, and every y,z ∈ X we have that ∣∣∣∣f (S(i←y))− f (S(i←z))∣∣∣∣ ≤ ρ(y,z), where S(i←x) is the same as S except that the ith element is replaced with x.\nAs stated in the previous section, the results of [13] can be used to obtain a high probability bound on |f (S)− f (Dn) | whenever Prx,y∼D[ρ(x,y) ≥ t] ≤ exp ( −t2/σ2 ) for some σ > 0. In contrast,\nour bound can be used whenever ∫∞ λ\nPrx,y∼D[ρ(x,y) ≥ t]dt is finite. In particular, we now use it to obtain a concentration bound for a case where the probability distribution of ρ(x,y) is heavy tailed, and in fact, has infinite variance. Specifically, assume that all we know on ρ(x,y) is that Pr[ρ(x,y) ≥ t] ≤ 1/t2 for every t ≥ 1 (this is a special case of the Pareto distribution, with infinite variance). Let λ ≥ 1. We calculate:\nE S∼Dn x′∼D\n[ 1 {∣∣∣∣f (S)− f (S(i←x′))∣∣∣∣ > λ} · ∣∣∣∣f (S)− f (S(i←x′))∣∣∣∣] ≤ E x,y∼D [1 { ρ(x,y) > λ } · ρ(x,y)]\n= ∫ λ\n0 Pr x,y∼D [1\n{ ρ(x,y) > λ } · ρ(x,y) ≥ t]dt + ∫ ∞ λ Pr x,y∼D [1 { ρ(x,y) > λ } · ρ(x,y) ≥ t]dt\n= ∫ λ\n0 Pr x,y∼D [ρ(x,y) ≥ λ]dt + ∫ ∞ λ Pr x,y∼D [ρ(x,y) ≥ t]dt\n= λ · Pr x,y∼D [ρ(x,y) ≥ λ] + ∫ ∞ λ Pr x,y∼D [ρ(x,y) ≥ t]dt ≤ λ 1 λ2 + ∫ ∞ λ 1 t2 dt = 2 λ , ∆.\nIn order to apply Theorem 1.2 we need to ensure that n ≥O (\n1 ε·min{1,ε} ln\n( λ·min{1,ε} ∆ + 1 )) . Assum-\ning that n ≥ ln(λ), with our choice of ∆ it suffices to set ε = Θ (√\n1 n ln(λ)\n) . Plugging ε and ∆ into\nTheorem 1.2, and simplifying, we get\nPr S∼D\n[|f (S)− f (Dn)| ≥ t] ≤ Õ ( n3/2\nt2\n) . (10)\nObserve that the above bound decays as 1/t2. This should be contrasted with Markov’s Inequality, which would decay as 1/t. Recall the assumption that the variance of ρ(x,y) is unbounded. Hence, the variance of f (S) can also be unbounded, and Chebyshev’s inequality could not be applied.\nAs we now explain, Inequality 10 can be improved using part 2 of Theorem 1.2. To that end, for a fixed database S ∈ Xn, we calculate:\nE y,z∼D\n[ 1 {∣∣∣∣f (S(i←y))− f (S(i←z))∣∣∣∣ ≤ λ} · ∣∣∣∣f (S(i←y))− f (S(i←z))∣∣∣∣] ≤ E y,z∼D [ρ(y,z)] ≤ ∫ 1 0 1dt + ∫ ∞ 1 1 t2 dt = 2 , τ.\nIn order to apply part 2 of Theorem 1.2 we need to ensure that n ≥O (\nλ ε·min{1,ε}τ ln ( ετ ∆ )) . For our\nchoice of ∆ and τ , if n ≥ λ ln(λ) then it suffices to set ε0 = Θ (√ λ n ln(λ) ) . Otherwise, if n < λ ln(λ)\nthen it suffices to set ε1 = Θ ( λ n ln(λ) ) . Plugging (ε0,∆) or (ε1,∆) into Theorem 1.2, and simplifying, we get\nPr S∼D\n[|f (S)− f (Dn)| ≥ t] ≤  Õ ( n2 t3 ) , t ≤ n\nÕ ( n t2 ) , t > n\n4.3 Example: Triangles in Random Graphs\nA random graph G(N,p) on N vertices 1,2, . . . ,N is defined by drawing an edge between each pair 1 ≤ i < j ≤ N independently with probability p. There are n = (N 2 )\ni.i.d. random variables x{i,j} representing the choices: x{i,j} = x{j,i} = 1 if the edge {i, j} is drawn, and 0 otherwise. We will useD to denote the probability Prx∼D[x = 1] = p and Prx∼D[x = 0] = 1−p, and let S = ( x{1,2}, . . . ,x{n−1,n} ) ∼ Dn.\nWe say that three vertices i, j, ` form a triangle if there is an edge between any pair of them. Denote fK3(S) the number of triangles in the graph defined by S. For a small constant α, we would like to have an exponential bound on the following probability\nPr [ fK3(S) ≥ (1 +α) · fK3(D n) ] .\nSpecifically, we are interested in small values of p = o(1) such that fK3(D n) = (N 3 ) p3 = Θ ( N3p3 ) = o(N ). The difficulty with this choice of p is that (in worst-case) adding a single edge to the graph can increase the number of triangles by (N − 2), which is much larger then the expected number of triangles. Indeed, until the breakthrough work of Vu [17] in 2002, no general exponential bounds were known. Following the work of [17], in 2004 Kim and Vu [11] presented the following sharp bound:\nTheorem 4.3 ([11], informal). Let α be a small constant. It holds that exp ( −Θ ( p2N2 log(1/p) )) ≤ Pr S∼Dn [ fK3(S) ≥ (1 +α) · fK3(D n) ] ≤ exp ( −Θ ( p2N2 )) .\nIn this section we show that our result can be used to analyze this problem. While the bound we obtain is much weaker than Theorem 4.3, we find it interesting that the same technique from the last sections can also be applied here. To make things more concrete, we fix\np =N−3/4.\nIn order to use our concentration bound, we start by analyzing the expected difference incurred to fK3 by resampling a single edge. We will denote Ni,j(S) as the number of triangles that are created (or deleted) by adding (or removing) the edge {i, j}. That is,\nNi,j(S) = ∣∣∣∣{` , i, j : x{i,`} = 1 and x{`,j} = 1}∣∣∣∣ .\nObserve that Ni,j(S) does not depend on x{i,j}. Moreover, observe that for every fixture of i < j we have that Ni,j(S) is the sum of (N − 2) i.i.d. indicators, each equals to 1 with probability p2.\nFix S = ( x{1,2}, . . . ,x{n−1,n} ) ∈ {0,1}n and x′ ∈ {0,1}. We have that∣∣∣∣fK3(S)− fK3 (S({i,j}←x′))∣∣∣∣ = { 0 , x{i,j} = x′Ni,j(S) , x{i,j} , x′\nwhere S({i,j}←x ′) is the same as S except with x{i,j} replaced with x′. Fix i < j. We can now calculate\nE S∼Dn x′∼D\n[ 1 {∣∣∣∣fK3(S)− fK3 (S({i,j}←x′))∣∣∣∣ > λ} · ∣∣∣∣fK3(S)− fK3 (S({i,j}←x′))∣∣∣∣] = E S∼Dn x′∼D [ 1 { x{i,j},x′ } ·1 { Ni,j(S) > λ } ·Ni,j(S)\n] = Pr x{i,j},x′∼D [ x{i,j} , x ′ ] · E S∼Dn [ 1 { Ni,j(S) > λ } ·Ni,j(S)\n] = 2p(1− p) · ( λ · Pr\nS∼Dn [Ni,j(S) ≥ λ] + ∫ N λ Pr S∼Dn [Ni,j(S) ≥ t]dt )\n≤ 2pN · Pr S∼Dn [Ni,j(S) ≥ λ]. (11)\nRecall that Ni,j(S) is the sum of (N − 2) i.i.d. indicators, each equals to 1 with probability p2. We can upper bound the probability that Ni,j(S) ≥ λ with the probability that a sum of N such random variables is at least λ. We will use the following variant of the Chernoff bound, known as the Chernoff-Hoeffding theorem:\nTheorem 4.4 ([10]). Let X1, . . . ,Xn be independent random variables where Pr[Xi = 1] = p and Pr[Xi = 0] = 1− p for some 0 < p < 1. Let k be s.t. p < kn < 1. Then,\nP r  n∑ i=1 Xi ≥ k  ≥ exp(−n ·D ( kn ∥∥∥∥∥p)) ,\nwhere D(a‖b) is the relative entropy between an a-coin and a p-coin (i.e. between the Bernoulli(a) and Bernoulli(p) distribution):\nD(a‖p) = a · log ( a p ) + (1− a) · log ( 1− a 1− p ) .\nUsing the Chernoff-Hoeffding theorem, for p2N < λ < N , we have\n(11) ≤ 2pN · exp ( −N ·D ( λ N ∥∥∥∥∥p2)) . (12) Recall that we fixed p =N−3/4. Choosing λ =N1/13, we get:\n(12) = 2pN · exp ( −N ·D ( N−12/13 ∥∥∥N−6/4)) . (13) We will use the following claim to bound D ( N−12/13\n∥∥∥N−6/4): Claim 4.5. Fix constants c > b > 0. For N ≥max{21/b,28/(c−b)} we have that D ( N−b\n∥∥∥N−c) ≥ c−b2 ·N−b · log(N ).\nUsing Claim 4.5, for large enough N , we have that\n(13) ≤ 2pN · exp ( −N1/13 ) . (14)\nSo, denoting ∆ = 2pN · exp ( −N1/13 ) , we get that\nE S∼Dn x′∼D\n[ 1 {∣∣∣∣fK3(S)− fK3 (S({i,j}←x′))∣∣∣∣ > λ} · ∣∣∣∣fK3(S)− fK3 (S({i,j}←x′))∣∣∣∣] ≤ ∆. In order to obtain a meaningful bound, we will need to use part 2 of Theorem 1.2. To that end,\nfor every fixture of S ∈ Xn and i < j we can compute\nE y,z∼D\n[ 1 {∣∣∣∣fK3(S({i,j}←y))− fK3 (S({i,j}←z))∣∣∣∣ ≤ λ} · ∣∣∣∣fK3(S({i,j}←y))− fK3 (S({i,j}←z))∣∣∣∣] ≤ Ey,z∼D [1 {y , z} ·λ] = 2p(1− p)λ ≤ 2pλ , τ.\nFinally, in order to apply Theorem 1.2, we need to ensure that n ≥ O (\nλ εmin{1,ε}τ ln\n( min{1,ε}τ\n∆\n)) .\nWith our choices for ∆ and τ , it suffices to set ε = Θ (√\nλ np\n) . Plugging ε, ∆ and τ into Theorem 1.2,\nand simplifying, we get that\nPr S∼Dn\n[ |fK3(S)− fK3(D n)| ≥ o ( fK3(D n) )] < exp ( −N1/13 ) .\nIt remains to prove Claim 4.5: Claim 4.5. Fix constants c > b > 0. For N ≥max{21/b,28/(c−b)} we have that D ( N−b ∥∥∥N−c) ≥ c−b2 ·N−b · log(N ).\nProof of Claim 4.5.\nD ( N−b ∥∥∥N−c) =N−b · log(N c−b)+ (1−N−b) · log(1−N−b 1−N−c ) =N−b · log ( N c−b ) + ( 1−N−b ) · log ( N c −N c−b\nN c − 1 ) =N−b · log ( N c−b ) + ( 1−N−b ) · log ( 1− N\nc−b − 1 N c − 1\n) (15)\nUsing the fact that log(1− x) ≥ −2x for every 0 ≤ x ≤ 12 , and assuming that N ≥ 2 1/b, we have\nthat\n(15) ≥N−b · log ( N c−b ) − 2 ( 1−N−b ) · N\nc−b − 1 N c − 1\n=N−b · log ( N c−b ) − 2 · N\nc−b − 1 N c − 1 + 2N−b · N c−b − 1 N c − 1\n≥N−b · log ( N c−b ) − 2 · N\nc−b − 1 N c − 1\n≥N−b · log ( N c−b ) − 2 · N c−b\n1 2N c ≥N−b · log ( N c−b ) − 4N−b (16)\nAssuming that N ≥ 28/(c−b) we get\n(16) ≥ 1 2 ·N−b · log\n( N c−b ) ≥ c − b\n2 ·N−b · log(N ) .\n5 Privately Identifying a High-Sensitivity Function\nLet S be a sample of n i.i.d. elements from some distribution D. Recall that if a low-sensitivity function f is identified by a differentially private algorithm operating on S, then w.h.p. f (S) ≈ f (Dn) , E\nS ′∼Dn [f (S ′)]. In this section we present a simple example showing that, in general, this\nis not the case for high-sensitivity functions. Specifically, we show that a differentially private algorithm operating on S can identify a high-sensitivity function f s.t. |f (S)− f (Dn)| is arbitrarily large, even though |f (S ′)− f (Dn)| is small for a fresh sample S ′ ∼ Dn.\nTheorem 5.1. Fix β,ε,B > 0, let U be the uniform distribution over X = {±1}d where d = poly(1/β), and let n ≥ O( 1ε2 ln(1/β)). There exists an (ε,0)-differentially private algorithm A that operates on a database S ∈ ({±1}d)n and returns a function mapping ({±1}d)n to R, s.t. the following hold.\n1. For every f in the range of A it holds that PrS ′∼Un[f (S ′) , f (Un)] ≤ β.\n2. Pr S∼Un f←A(S)\n[|f (S)− f (Un)| ≥ B] ≥ 1/2.\nProof. For t ∈ [d], define ft : ({±1}d)n→R as\nft(x1, . . . ,xn) =  0 , ∣∣∣∑i∈[n] xi,t∣∣∣ ≤√2n ln(2/β) B , ∑ i∈[n] xi,t > √ 2n ln(2/β) −B , ∑ i∈[n] xi,t < − √ 2n ln(2/β)\nThat is, given a database S of n rows from {±1}d , we define ft(S) as 0 if the sum of column t (in absolute value) is less than some threshold, and otherwise set ft(S) to be ±B (depending on the\nsign of the sum). Observe that the global sensitivity of ft is B, and that ft(Un) , E S ′∼Un [ft(S ′)] = 0. Also, by the Hoeffding bound, we have that\nPr S∼Un [ft(S) , 0] ≤ β.\nSo, for every fixed t, with high probability over sampling S ∼ Un we have that ft(S) = 0 = ft(Un). Nevertheless, as we now explain, if d is large enough, then an (ε,0)-differentially private algorithm can easily identify a “bad” index t∗ such that |ft∗(S)| = B.\nConsider the algorithm that on input S = (x1,x2, . . . ,xn) samples an index t ∈ [d] with probability proportional to exp ( ε 4 ∣∣∣∑i∈[n] xi,t∣∣∣). We will call it algorithm BadIndex. By the properties of the exponential mechanism, algorithm BadIndex is (ε,0)-differentially private. Moreover, with probability at least 3/4, the output t∗ satisfies∣∣∣∣∣∣∣∣ ∑ i∈[n] xi,t∗ ∣∣∣∣∣∣∣∣ ≥ maxt∈[d]  ∣∣∣∣∣∣∣∣ ∑ i∈[n] xi,t ∣∣∣∣∣∣∣∣  − 4ε ln(4d) . (17)\nIn addition, by Theorem 2.6 (tightness of Chernoff bound), for every fixed t it holds that\nPr ∑ i∈[n] xi,t ≥ 1.11 · √ 2n ln(2/β)  ≥ (β2 )45 . As the columns are independent, taking d = 2 ( 2 β )45 , we get that\nPr maxt∈[d]  ∑ i∈[n] xi,t  ≥ 1.11 ·√2n ln(2/β)  ≥ 3/4. (18)\nCombining (17) and (18) we get that with probability at least 1/2 algorithm BadIndex identifies an index t∗ such that ∣∣∣∣∣∣∣∣ ∑ i∈[n] xi,t∗ ∣∣∣∣∣∣∣∣ ≥ 1.11 · √ 2n ln(2/β) − 4 ε ln(4d) .\nAssuming that n ≥ O( 1ε2 ln(1/β)) we get that with probability at least 1/2 algorithm BadIndex outputs an index t∗ s.t. ft∗(S) = B.\n5.1 Max-Information\nIn this section we show that algorithm BadIndex has relatively high max-information: Given two (correlated) random variables Y , Z, we use Y ⊗Z denote the random variable obtained by drawing independent copies of Y and Z from their respective marginal distributions.\nDefinition 5.2 (Max-Information [5]). Let Y and Z be jointly distributed random variables over the domain (Y ,Z). The β-approximate max-information between Y and Z is defined as\nI β ∞(Y ;Z) = log sup\nO⊆(Y×Z), Pr[(Y ,Z)∈O]>β\nPr[(Y ,Z) ∈ O]− β Pr[Y ⊗Z ∈ O] .\nAn algorithm A : Xn → F has β-approximate max-information of k over product distributions, written Iβ∞,P (A,n) ≤ k, if for every distribution D over X, we have I β ∞(S;A(S)) ≤ k when S ∼ Dn.\nIt follows immediately from the definition that approximate max-information controls the probability of “bad events” that can happen as a result of the dependence of A(S) on S: for every event O, we have Pr[(S,A(S)) ∈ O] ≤ 2k Pr[S ⊗A(S) ∈ O] + β.\nConsider again algorithm BadIndex : ({±1})n → F that operates on database S of size n = O( 1ε2 ln(1/β)) and identifies, with probability 1/2, a function f s.t. f (S) , 0, even though f (S\n′) = 0 w.p. 1− β for a fresh sample S ′. Let us define O as the set of all pairs (S,f ), where S is a database and f is a function in the range of algorithm BadIndex such that f (S) , 0. That is,\nO = {(S,f ) ∈ ({±1})n ×F : f (S) , 0} .\nIf we assume that I1/4∞,P (BadIndex,n) ≤ k, then by Definition 5.2 we have:\n1 2 ≤ Pr\nS∼Un f←BadIndex(S) [(S,f ) ∈ O] ≤ ek · Pr S∼Un T∼Un\nf←BadIndex(T )\n[(S,f ) ∈ O] + 1 4 ≤ ek · β + 1 4 .\nSo k ≥ ln( 14β ) = Ω(ε 2n).\nReferences\n[1] Raef Bassily and Yoav Freund. Typicality-based stability and privacy. CoRR, abs/1604.03336, 2016.\n[2] Raef Bassily, Kobbi Nissim, Adam D. Smith, Thomas Steinke, Uri Stemmer, and Jonathan Ullman. Algorithmic stability for adaptive data analysis. In Proceedings of the 48th Annual ACM SIGACT Symposium on Theory of Computing, STOC 2016, Cambridge, MA, USA, June 18-21, 2016, pages 1046–1059, 2016.\n[3] Herman Chernoff. A measure of asymptotic efficiency for tests of a hypothesis based on the sum of observations. Ann. Math. Statist., 23:493–507, 1952.\n[4] Rachel Cummings, Katrina Ligett, Kobbi Nissim, Aaron Roth, and Zhiwei Steven Wu. Adaptive learning with robust generalization guarantees. In Proceedings of the 29th Conference on Learning Theory, COLT 2016, New York, USA, June 23-26, 2016, pages 772–814, 2016.\n[5] Cynthia Dwork, Vitaly Feldman, Moritz Hardt, Toniann Pitassi, Omer Reingold, and Aaron Roth. Generalization in adaptive data analysis and holdout reuse. In Advances in Neural Information Processing Systems (NIPS), Montreal, December 2015.\n[6] Cynthia Dwork, Vitaly Feldman, Moritz Hardt, Toniann Pitassi, Omer Reingold, and Aaron Roth. Preserving statistical validity in adaptive data analysis. In ACM Symposium on the Theory of Computing (STOC). ACM, June 2015.\n[7] Cynthia Dwork, Krishnaram Kenthapadi, Frank McSherry, Ilya Mironov, and Moni Naor. Our data, ourselves: Privacy via distributed noise generation. In Serge Vaudenay, editor, EUROCRYPT, volume 4004 of Lecture Notes in Computer Science, pages 486–503. Springer, 2006.\n[8] Cynthia Dwork, Frank McSherry, Kobbi Nissim, and Adam Smith. Calibrating noise to sensitivity in private data analysis. In TCC, volume 3876 of Lecture Notes in Computer Science, pages 265–284. Springer, 2006.\n[9] Moritz Hardt and Jonathan Ullman. Preventing false discovery in interactive data analysis is hard. In FOCS, pages 454–463, 2014.\n[10] Wassily Hoeffding. Probability inequalities for sums of bounded random variables. Journal of the American Statistical Association, 58(301):13–30, 1963.\n[11] J. H. Kim and V. H. Vu. Divide and conquer martingales and the number of triangles in a random graph. Random Structures and Algorithms, 24(2):166–174, 2004.\n[12] Philip N. Klein and Neal E. Young. On the number of iterations for dantzig-wolfe optimization and packing-covering approximation algorithms. SIAM J. Comput., 44(4):1154–1172, 2015.\n[13] Aryeh Kontorovich. Concentration in unbounded metric spaces and algorithmic stability. In Proceedings of the 31th International Conference on Machine Learning, ICML 2014, Beijing, China, 21-26 June 2014, pages 28–36, 2014.\n[14] Frank McSherry and Kunal Talwar. Mechanism design via differential privacy. In FOCS, pages 94–103. IEEE, Oct 20–23 2007.\n[15] Thomas Steinke and Jonathan Ullman. Interactive fingerprinting codes and the hardness of preventing false discovery. In COLT, pages 1588–1628, 2015.\n[16] Thomas Steinke and Jonathan Ullman. Subgaussian tail bounds via stability arguments. ArXiv.org, (arXiv:1701.03493 [cs.DM]), 2017.\n[17] Van H. Vu. Concentration of non-lipschitz functions and applications. Random Structures and Algorithms, 20(3):262–316, 2002.\nA Concentration Bounds Through Differential Privacy – Missing Details\nClaim 3.3. Fix a function f : Xn → R and parameters ε,λ ≥ 0. If M : (Xn)T → Y is (ε, (f ,λ))differentially private then for every (f ,λ)-neighboring databases ~S, ~S ′ ∈ (Xn)T and every function h : Y →R we have that\nE y←M(~S) [h(y)] ≤ e−ε · E y←M(~S ′) [h(y)] + (eε − e−ε) · E y←M(~S ′) [|h(y)|] .\nProof.\nE y←M(~S)\n[h(y)] = ∫ ∞\n0 Pr y←M(~S) [h(y) ≥ z]dz − ∫ 0 −∞ Pr y←M(~S) [h(y) ≤ z]dz\n≤ eε · ∫ ∞\n0 Pr y←M(~S ′) [h(y) ≥ z]dz − e−ε · ∫ 0 −∞ Pr y←M(~S ′) [h(y) ≤ z]dz\n= e−ε ∫ ∞\n0 Pr y←M(~S ′) [h(y) ≥ z]dz − ∫ 0 −∞ Pr y←M(~S ′) [h(y) ≤ z]dz \n+ (eε − e−ε) · ∫ ∞\n0 Pr y←M(~S ′) [h(y) ≥ z]dz\n= e−ε · E y←M(~S ′)\n[h(y)] + (eε − e−ε) · ∫ ∞\n0 Pr y←M(~S ′) [h(y) ≥ z]dz\n≤ e−ε · E y←M(~S ′)\n[h(y)] + (eε − e−ε) · ∫ ∞\n0 Pr y←M(~S ′) [|h(y)| ≥ z]dz\n= e−ε · E y←M(~S ′) [h(y)] + (eε − e−ε) · E y←M(~S ′) [|h(y)|]\nA.1 Multi Sample Expectation Bound\nLemma A.1 (Expectation Bound). Let D be a distribution over a domain X, let f : Xn→R , and let ∆,λ be s.t. for every 1 ≤ i ≤ n it holds that\nE S∼Dn z∼D\n[ 1 {∣∣∣∣f (S)− f (S(i←z))∣∣∣∣ > λ} · ∣∣∣∣f (S)− f (S(i←z))∣∣∣∣] ≤ ∆, (19) where S(i←z) is the same as S except that the ith element is replaced with z. Let A : (Xn)T → ([T ]∪⊥) be an (ε, (f ,λ))-differentially private algorithm that operates on T databases of size n from X, and outputs an index 1 ≤ t ≤ T or ⊥. Then∣∣∣∣∣∣∣∣∣∣ E~S∼DnTt←A(~S) [1{t ,⊥} · (f (D n)− f (St))] ∣∣∣∣∣∣∣∣∣∣ ≤ (e ε − e−ε) ·λn+ 6∆nT .\nIf, in addition to (19), there exists a number 0 ≤ τ ≤ λ s.t. for every 1 ≤ i ≤ n and every fixture of S ∈ Xn we have that\nE y,z∼D\n[ 1 {∣∣∣∣f (S(i←y))− f (S(i←z))∣∣∣∣ ≤ λ} · ∣∣∣∣f (S(i←y))− f (S(i←z))∣∣∣∣] ≤ τ, (20) Then, ∣∣∣∣∣∣∣∣∣∣ E~S∼DnTt←A(~S) [1{t ,⊥} · (f (D n)− f (St))] ∣∣∣∣∣∣∣∣∣∣ ≤ (e ε − e−ε) · τn+ 6∆nT .\nWe now present the proof assuming that (20) holds for some 0 ≤ τ ≤ λ. This is without loss of generality, as trivially it holds for τ = λ.\nProof of Lemma A.1. Let ~S ′ = (S ′1, . . . ,S ′ T ) ∼ D nT be independent of ~S. Recall that each element St of ~S is itself a vector (xt,1, . . . ,xt,n), and the same is true for each element S ′t of ~S\n′ . We will sometimes refer to the vectors S1, . . . ,ST as the subsamples of ~S.\nWe define a sequence of intermediate samples that allow us to interpolate between ~S and ~S ′. Formally, for ` ∈ {0,1, . . . ,n} define ~S` = (S`1, . . . ,S ` T ) ∈ (X n)T where S`t = (x ` t,1, . . . ,x ` t,n) and\nx`t,i = { xt,i , i > ` x′t,i , i ≤ `\nThat is, every subsample S`t of ~S ` is identical to S ′t on the first ` elements, and identical to St thereafter. By construction we have ~S0 = ~S and ~Sn = ~S ′. Moreover, for every t we have that S`t and S`−1t differ in exactly one element. In terms of these intermediate samples we can write:∣∣∣∣∣∣ E~S∼DnT Et←A(~S) [1{t ,⊥} · (f (Dn)− f (St))]\n∣∣∣∣∣∣ =\n∣∣∣∣∣∣ E~S∼DnT Et←A(~S) [ 1{t ,⊥} · ( E ~S ′∼DnT [ f (S ′t) ] − f (St) )]∣∣∣∣∣∣ =\n∣∣∣∣∣∣ E~S∼DnT Et←A(~S) E~S ′∼DnT [1{t ,⊥} · (f (S ′t)− f (St))] ∣∣∣∣∣∣\n= ∣∣∣∣∣∣∣∣ ∑ `∈[n] E ~S,~S ′∼DnT E t←A(~S) [ 1{t ,⊥} · ( f (S`t )− f (S`−1t ) )]∣∣∣∣∣∣∣∣ ≤\n∑ `∈[n] ∣∣∣∣∣∣ E~S,~S ′∼DnT Et←A(~S) [1{t ,⊥} · (f (S`t )− f (S`−1t ))] ∣∣∣∣∣∣\n= ∑ `∈[n] ∣∣∣∣∣∣ E~S,~S ′∼DnT EZ∼DT Et←A(~S) [1{t ,⊥} · (f (S`t )− f (S`−1t ))] ∣∣∣∣∣∣ (21)\nGiven a multisample ~S = (S1, . . . ,ST ) ∈ (Xn)T , a vector Z = (z1 . . . , zT ) ∈ XT , and an index 1 ≤ k ≤ n, we define ~S(k←Z) to be the same as ~S except that the kth element of every subsample Si is replaced with zi . Observe that by construction, for every `,Z we have ~S`,(`←Z) = ~S`−1,(`←Z). Thus, (21) = ∑ `∈[n] ∣∣∣∣∣∣ E~S,~S ′∼DnT EZ∼DT Et←A(~S) 1{t ,⊥} · f (S`t )− f (S`,(`←Z)t )−1{t ,⊥} · f (S`−1t )− f (S`−1,(`←Z)t )∣∣∣∣∣∣ .\n(22) Observer that the pairs (~S, ~S`) and ( ~S, ~S`,(`←Z) ) are identically distributed. Namely, both ~S` and\n~S`,(`←Z) agree with ~S on the last (n − `) entries of every subsample, and otherwise contain i.i.d. samples from D. Hence, the expectation of ( f (S`t )− f ( S `,(`←Z) t )) is zero, and we get\n(22) = ∑ `∈[n] ∣∣∣∣∣∣ E~S,~S ′∼DnT EZ∼DT Et←A(~S) 1{t ,⊥} · f (S`−1,(`←Z)t )− f (S`−1t )∣∣∣∣∣∣ . (23)\nObserver that the pair (~S`−1, ~S) has the same distribution as (~S, ~S`−1). Specifically, the first component is nT independent samples from D and the second component is equal to the first component with a subset of the entries replaced by fresh independent samples from D. Thus,\n(23) = ∑ `∈[n] ∣∣∣∣∣∣ E~S,~S ′∼DnT EZ∼DT Et←A(~S`−1) 1{t ,⊥} · f (S(`←Z)t )− f (St)∣∣∣∣∣∣\n≤ ∑ `∈[n] ∣∣∣∣∣∣∣∣∣∣∣∣ E ~S,~S ′∼DnT E Z∼DT 1  maxm∈[T ] |f (S`−1m )− f (S`m)| ≤ λ and maxm∈[T ] |f ( S (`←Z) m ) − f (Sm)| ≤ λ  · Et←A(~S`−1) 1{t ,⊥} · f (S(`←Z)t )− f (St)  ∣∣∣∣∣∣∣∣∣∣∣∣\n+ ∑ `∈[n] ∣∣∣∣∣∣∣∣∣∣∣∣ E ~S,~S ′∼DnT E Z∼DT 1  maxm∈[T ] |f (S`−1m )− f (S`m)| > λ or maxm∈[T ] |f ( S (`←Z) m ) − f (Sm)| > λ  · maxm∈[T ] ∣∣∣∣∣f (S(`←Z)m )− f (Sm)∣∣∣∣∣  ∣∣∣∣∣∣∣∣∣∣∣∣\n(24)\nWhen maxm∈[T ] |f (S`−1m )− f (S`m)| ≤ λ we now use the properties of algorithm A to argue that A(~S`−1) ≈ A(~S`). Be Claim 3.3 we get that\n(24)\n≤ ∑ `∈[n] ∣∣∣∣∣∣∣∣∣∣∣∣ E ~S,~S ′∼DnT E Z∼DT 1  maxm∈[T ] |f (S`−1m )− f (S`m)| ≤ λ and maxm∈[T ] |f ( S (`←Z) m ) − f (Sm)| ≤ λ  · Et←A(~S`) 1{t ,⊥} · f (S(`←Z)t )− f (St)  ∣∣∣∣∣∣∣∣∣∣∣∣\n+ (eε − e−ε) · ∑ `∈[n] ∣∣∣∣∣∣∣∣∣∣∣∣ E ~S,~S ′∼DnT E Z∼DT 1  maxm∈[T ] |f (S`−1m )− f (S`m)| ≤ λ and maxm∈[T ] |f ( S (`←Z) m ) − f (Sm)| ≤ λ  · Et←A(~S`) [ 1{t ,⊥} · ∣∣∣∣∣f (S(`←Z)t )− f (St)∣∣∣∣∣]  ∣∣∣∣∣∣∣∣∣∣∣∣\n+ ∑ `∈[n] ∣∣∣∣∣∣∣∣∣∣∣∣ E ~S,~S ′∼DnT E Z∼DT 1  maxm∈[T ] |f (S`−1m )− f (S`m)| > λ or maxm∈[T ] |f ( S (`←Z) m ) − f (Sm)| > λ  · maxm∈[T ] ∣∣∣∣∣f (S(`←Z)m )− f (Sm)∣∣∣∣∣  ∣∣∣∣∣∣∣∣∣∣∣∣\n(25)\nWe can remove one of the two requirements in the indicator function in the middle row (this makes the expression bigger), to get:\n(25)\n≤ ∑ `∈[n] ∣∣∣∣∣∣∣∣∣∣∣∣ E ~S,~S ′∼DnT E Z∼DT 1  maxm∈[T ] |f (S`−1m )− f (S`m)| ≤ λ and maxm∈[T ] |f ( S (`←Z) m ) − f (Sm)| ≤ λ  · Et←A(~S`) 1{t ,⊥} · f (S(`←Z)t )− f (St)  ∣∣∣∣∣∣∣∣∣∣∣∣ + (eε − e−ε) · ∑ `∈[n] ∣∣∣∣∣∣ E~S,~S ′∼DnT EZ∼DT Et←A(~S`) [ 1 { max m∈[T ] |f ( S (`←Z) m ) − f (Sm)| ≤ λ } ·1{t ,⊥} · ∣∣∣∣∣f (S(`←Z)t )− f (St)∣∣∣∣∣] ∣∣∣∣∣∣\n+ ∑ `∈[n] ∣∣∣∣∣∣∣∣∣∣∣∣ E ~S,~S ′∼DnT E Z∼DT 1  maxm∈[T ] |f (S`−1m )− f (S`m)| > λ or maxm∈[T ] |f ( S (`←Z) m ) − f (Sm)| > λ  · maxm∈[T ] ∣∣∣∣∣f (S(`←Z)m )− f (Sm)∣∣∣∣∣  ∣∣∣∣∣∣∣∣∣∣∣∣\n(26)\nFurthermore, we can replace 1 { maxm∈[T ] |f ( S (`←Z) m ) − f (Sm)| ≤ λ } in the middle row with the\nweaker requirement – just for the specific t that was selected by algorithm A. This yields:\n(26)\n≤ ∑ `∈[n] ∣∣∣∣∣∣∣∣∣∣∣∣ E ~S,~S ′∼DnT E Z∼DT 1  maxm∈[T ] |f (S`−1m )− f (S`m)| ≤ λ and maxm∈[T ] |f ( S (`←Z) m ) − f (Sm)| ≤ λ  · Et←A(~S`) 1{t ,⊥} · f (S(`←Z)t )− f (St)  ∣∣∣∣∣∣∣∣∣∣∣∣ + (eε − e−ε) · ∑ `∈[n] ∣∣∣∣∣∣ E~S,~S ′∼DnT EZ∼DT Et←A(~S`) [ 1 { |f ( S (`←Z) t ) − f (St)| ≤ λ } ·1{t ,⊥} · ∣∣∣∣∣f (S(`←Z)t )− f (St)∣∣∣∣∣] ∣∣∣∣∣∣\n+ ∑ `∈[n] ∣∣∣∣∣∣∣∣∣∣∣∣ E ~S,~S ′∼DnT E Z∼DT 1  maxm∈[T ] |f (S`−1m )− f (S`m)| > λ or maxm∈[T ] |f ( S (`←Z) m ) − f (Sm)| > λ  · maxm∈[T ] ∣∣∣∣∣f (S(`←Z)m )− f (Sm)∣∣∣∣∣  ∣∣∣∣∣∣∣∣∣∣∣∣\n(27)\nUsing the fact that the pairs (~S, ~S`) and (~S`, ~S) are identically distributed, we can switch them in the middle row, to get\n(27)\n≤ ∑ `∈[n] ∣∣∣∣∣∣∣∣∣∣∣∣ E ~S,~S ′∼DnT E Z∼DT 1  maxm∈[T ] |f (S`−1m )− f (S`m)| ≤ λ and maxm∈[T ] |f ( S (`←Z) m ) − f (Sm)| ≤ λ  · Et←A(~S`) 1{t ,⊥} · f (S(`←Z)t )− f (St)  ∣∣∣∣∣∣∣∣∣∣∣∣\n+ (eε − e−ε) · ∑ `∈[n] ∣∣∣∣∣∣∣∣∣ E~S∼DnT Et←A(~S) E~S ′∼DnT Z∼DT [ 1 { |f ( S `,(`←Z) t ) − f (S`t )| ≤ λ } ·1{t ,⊥} · ∣∣∣∣∣f (S`,(`←Z)t )− f (S`t )∣∣∣∣∣] ∣∣∣∣∣∣∣∣∣\n+ ∑ `∈[n] ∣∣∣∣∣∣∣∣∣∣∣∣ E ~S,~S ′∼DnT E Z∼DT 1  maxm∈[T ] |f (S`−1m )− f (S`m)| > λ or maxm∈[T ] |f ( S (`←Z) m ) − f (Sm)| > λ  · maxm∈[T ] ∣∣∣∣∣f (S(`←Z)m )− f (Sm)∣∣∣∣∣  ∣∣∣∣∣∣∣∣∣∣∣∣\n(28)\nUsing our assumptions on the function f and the distribution D (for the middle row), brings us to:\n(28)\n≤ ∑ `∈[n] ∣∣∣∣∣∣∣∣∣∣∣∣ E ~S,~S ′∼DnT E Z∼DT 1  maxm∈[T ] |f (S`−1m )− f (S`m)| ≤ λ and maxm∈[T ] |f ( S (`←Z) m ) − f (Sm)| ≤ λ  · Et←A(~S`) 1{t ,⊥} · f (S(`←Z)t )− f (St)  ∣∣∣∣∣∣∣∣∣∣∣∣\n+ (eε − e−ε)nτ\n+ ∑ `∈[n] ∣∣∣∣∣∣∣∣∣∣∣∣ E ~S,~S ′∼DnT E Z∼DT 1  maxm∈[T ] |f (S`−1m )− f (S`m)| > λ or maxm∈[T ] |f ( S (`←Z) m ) − f (Sm)| > λ  · maxm∈[T ] ∣∣∣∣∣f (S(`←Z)m )− f (Sm)∣∣∣∣∣  ∣∣∣∣∣∣∣∣∣∣∣∣\n(29)\nOur next task is to remove the indicator function in the first row. This is useful as the pairs( ~S`, ~S(`←Z) ) and (~S`, ~S) are identically distributed, and hence, if we were to remove the indicator function, the first row would be equal to zero. To that end we add and subtract the first row with the complementary indicator function (this amounts to multiplying the third row by 2). We get\n(29) ≤ ∑ `∈[n] ∣∣∣∣∣∣ E~S,~S ′∼DnT EZ∼DT  E t←A(~S`) 1{t ,⊥} · f (S(`←Z)t )− f (St)∣∣∣∣∣∣ + (eε − e−ε)nτ\n+ 2 · ∑ `∈[n] ∣∣∣∣∣∣∣∣∣∣∣∣ E ~S,~S ′∼DnT E Z∼DT 1  maxm∈[T ] |f (S`−1m )− f (S`m)| > λ or maxm∈[T ] |f ( S (`←Z) m ) − f (Sm)| > λ  · maxm∈[T ] ∣∣∣∣∣f (S(`←Z)m )− f (Sm)∣∣∣∣∣  ∣∣∣∣∣∣∣∣∣∣∣∣\n(30)\nNow the first row is 0, so\n(30) = (eε − e−ε)nτ\n+ 2 · ∑ `∈[n] ∣∣∣∣∣∣∣∣∣∣∣∣ E ~S,~S ′∼DnT E Z∼DT 1  maxm∈[T ] |f (S`−1m )− f (S`m)| > λ or maxm∈[T ] |f ( S (`←Z) m ) − f (Sm)| > λ  · maxm∈[T ] ∣∣∣∣∣f (S(`←Z)m )− f (Sm)∣∣∣∣∣  ∣∣∣∣∣∣∣∣∣∣∣∣\n(31)\nWe can replace the or condition in the indicator function with the sum of the two conditions:\n(31) ≤ (eε − e−ε)nτ\n+ 2 · ∑ `∈[n] ∣∣∣∣∣∣ E~S,~S ′∼DnT EZ∼DT [ 1 { max m∈[T ] |f (S`−1m )− f (S`m)| > λ } · max m∈[T ] ∣∣∣∣∣f (S(`←Z)m )− f (Sm)∣∣∣∣∣] ∣∣∣∣∣∣\n+ 2 · ∑ `∈[n] ∣∣∣∣∣∣ E~S,~S ′∼DnT EZ∼DT [ 1 { max m∈[T ] |f ( S (`←Z) m ) − f (Sm)| > λ } · max m∈[T ] ∣∣∣∣∣f (S(`←Z)m )− f (Sm)∣∣∣∣∣] ∣∣∣∣∣∣ (32)\nIn the third row, we can replace maxm∈[T ] with ∑ m∈[T ], to get\n(32) ≤ (eε − e−ε)nτ\n+ 2 · ∑ `∈[n] ∣∣∣∣∣∣ E~S,~S ′∼DnT EZ∼DT [ 1 { max m∈[T ] |f (S`−1m )− f (S`m)| > λ } · max m∈[T ] ∣∣∣∣∣f (S(`←Z)m )− f (Sm)∣∣∣∣∣] ∣∣∣∣∣∣\n+ 2 · ∑ `∈[n] ∑ m∈[T ] ∣∣∣∣∣∣ E~S,~S ′∼DnT EZ∼DT [ 1 { |f ( S (`←Z) m ) − f (Sm)| > λ } · ∣∣∣∣∣f (S(`←Z)m )− f (Sm)∣∣∣∣∣] ∣∣∣∣∣∣ (33) Applying our assumptions on f and D to the third row brings us to\n(33) ≤ (eε − e−ε)nτ + 2nT∆\n+ 2 · ∑ `∈[n] ∣∣∣∣∣∣ E~S,~S ′∼DnT EZ∼DT [ 1 { max m∈[T ] |f (S`−1m )− f (S`m)| > λ } · max m∈[T ] ∣∣∣∣∣f (S(`←Z)m )− f (Sm)∣∣∣∣∣] ∣∣∣∣∣∣\n(34)\nThe issue now is that the expression inside the indicator function is different from the expression outside of it. To that end, we split the indicator function as follows:\n(34) ≤ (eε − e−ε)nτ + 2nT∆\n+ 2 · ∑ `∈[n] ∣∣∣∣∣∣∣∣∣∣∣∣ E ~S,~S ′∼DnT E Z∼DT 1  maxm∈[T ] |f (S`−1m )− f (S`m)| > λ and maxm∈[T ] ∣∣∣∣∣f (S(`←Z)m )− f (Sm)∣∣∣∣∣ > λ  · maxm∈[T ] ∣∣∣∣∣f (S(`←Z)m )− f (Sm)∣∣∣∣∣  ∣∣∣∣∣∣∣∣∣∣∣∣\n+ 2 · ∑ `∈[n] ∣∣∣∣∣∣∣∣∣∣∣∣ E ~S,~S ′∼DnT E Z∼DT 1  maxm∈[T ] |f (S`−1m )− f (S`m)| > λ and maxm∈[T ] ∣∣∣∣∣f (S(`←Z)m )− f (Sm)∣∣∣∣∣ ≤ λ  · maxm∈[T ] ∣∣∣∣∣f (S(`←Z)m )− f (Sm)∣∣∣∣∣  ∣∣∣∣∣∣∣∣∣∣∣∣\n≤ (eε − e−ε)nτ + 2nT∆\n+ 2 · ∑ `∈[n] ∣∣∣∣∣∣ E~S,~S ′∼DnT EZ∼DT [ 1 { max m∈[T ] ∣∣∣∣∣f (S(`←Z)m )− f (Sm)∣∣∣∣∣ > λ} · maxm∈[T ] ∣∣∣∣∣f (S(`←Z)m )− f (Sm)∣∣∣∣∣] ∣∣∣∣∣∣ + 2 ·\n∑ `∈[n] ∣∣∣∣∣∣ E~S,~S ′∼DnT EZ∼DT [ 1 { max m∈[T ] |f (S`−1m )− f (S`m)| > λ } · max m∈[T ] |f (S`−1m )− f (S`m)| ]∣∣∣∣∣∣\n≤ (eε − e−ε)nτ + 6nT∆.\nA.2 Multi Sample Amplification\nTheorem A.2 (High Probability Bound). Let D be a distribution over a domain X, let f : Xn→ R , and let ∆,λ,τ be s.t. for every 1 ≤ i ≤ n it holds that\nE S∼Dn z∼D\n[ 1 {∣∣∣∣f (S)− f (S(i←z))∣∣∣∣ > λ} · ∣∣∣∣f (S)− f (S(i←z))∣∣∣∣] ≤ ∆, and, furthermore, ∀S ∈ Xn and ∀1 ≤ i ≤ n we have\nE y,z∼D\n[ 1 {∣∣∣∣f (S(i←y))− f (S(i←z))∣∣∣∣ ≤ λ} · ∣∣∣∣f (S(i←y))− f (S(i←z))∣∣∣∣] ≤ τ, where S(i←z) is the same as S except that the ith element is replaced with z. Then for every ε > 0 we have that\nPr S∼Dn [|f (S)− f (Dn)| ≥ 6(eε − e−ε)τn] < 14∆ (eε − e−ε)τ ,\nprovided that n ≥O (\nλ ε(eε−e−ε)τ log ( (eε−e−ε)τ ∆ ))\nProof. We only analyze the probability that (f (S)− f (Dn)) is large. The analysis for (f (Dn)− f (S)) is symmetric. Assume towards contradiction that with probability at least 7∆(eε−e−ε)τ we have that f (S) − f (Dn) ≥ 6(eε − e−ε)τn. We now construct the following algorithm B that contradicts our expectation bound.\nAlgorithm 2 B Input: T databases of size n each: ~S = (S1, . . . ,ST ), where T , ⌊ (eε−e−ε)τ\n7∆\n⌋ .\n1. Set H = {⊥,1,2, . . . ,T }.\n2. For i = 1, ...,T , define q(~S, i) = f (Si)− f (Dn). Also set q(~S,⊥) = 0. 3. Sample t∗ ∈H with probability proportional to exp ( ε 2λq(~S, t) ) .\nOutput: t.\nThe fact that algorithm B is (ε, (f ,λ))-differentially private follows from the standard analysis of the Exponential Mechanism of McSherry and Talwar [14]. The proof appears in Claim A.4 for completeness.\nNow consider applying B on databases ~S = (S1, . . . ,ST ) containing i.i.d. samples from D. By our assumption on D and f , for every t we have that f (St)− f (Dn) ≥ 6(eε − e−ε)τn with probability at least 7∆(eε−e−ε)τ . By our choice of T = ⌊ (eε−e−ε)τ 7∆ ⌋ , we therefore get\nPr ~S∼DnT [ max t∈[T ] {f (St)− f (Dn)} ≥ 6(eε − e−ε)τn ] ≥ 1− ( 1− 7∆ (eε − e−ε)τ )T ≥ 1 2 .\nThe probability is taken over the random choice of the examples in ~S according to D. Thus, by Markov’s inequality,\nE ~S∼DnT [ max t∈H { q(~S, t) }] = E ~S∼DnT [ max { 0 , max t∈[T ] (f (St)− f (D)) }] ≥ 3(eε − e−ε)τn. (35)\nSo, in expectation, maxt∈H ( q(~S, t) ) is large. In order to contradict the expectation bound of Theorem A.2, we need to show that this is also the case for the index t∗ that is sampled on Step 3. To that end, we now use the following technical claim, stating that the expected quality of a solution sampled as in Step 3 is high.\nClaim A.3 (e.g., [2]). Let H be a finite set, h :H →R a function, and η > 0. Define a random variable Y on H by Pr[Y = y] = exp(ηh(y))/C, where C = ∑ y∈H exp(ηh(y)). Then E [h(Y )] ≥ maxy∈H h(y) − 1 η ln |H |.\nFor every fixture of ~S, we can apply Claim A.3 with h(t) = q(~S, t) and η = ε2λ to get\nE t∗∈RH [q(~S, t∗)] = E t∗∈RH\n[ 1{t∗ ,⊥} · (f (St∗)− f (Dn))} ] ≥max{0 , max\nt∈[T ] (f (St)− f (Dn))} − 2λ ε ln(T + 1).\nTaking the expectation also over ~S ∼ DnT we get that\nE ~S∼DnT t∗←B ( ~S ) [ 1{t∗ ,⊥} · (f (St∗)− f (Dn))} ] ≥ E ~S∼DnT [ max { 0 , max t∈[T ] (f (St)− f (Dn)) }] − 2λ ε ln(T + 1)\n≥ 3(eε − e−ε)τn− 2λ ε ln(T + 1).\nThis contradicts Theorem A.2 whenever n > 2λε(eε−e−ε)τ ln(T + 1) = 2λ ε(eε−e−ε)τ ln( (eε−e−ε)τ 7∆ + 1).\nClaim A.4. Algorithm B is (ε, (f ,λ))-differentially private.\nProof. Fix two (f ,λ)-neighboring databases ~S and ~S ′, and let b ∈ {⊥,1,2, . . . ,T } be a possible output. We have that\nPr[B(~S) = b] = exp( ε2λ · q(~S,b))∑ a∈H exp( ε 2λ · q(~S,a))\n(36)\nUsing the fact that ~S and ~S ′ are (f ,λ)-neighboring, for every a ∈ H we get that q(~S ′ , a) − λ ≤ q(~S,a) ≤ q(~S ′ , a) +λ. Hence,\n(36) ≤ exp( ε2λ · [q(~S ′ ,b) +λ])∑ a∈H exp( ε 2λ · [q(~S ′ , a)−λ])\n= eε/2 · exp( ε2λ · q(~S ′ ,b)) e−ε/2 ∑ a∈H exp( ε 2λ · q(~S ′ , a)) = eε ·Pr[B(~S ′) = b].\nFor any possible set of outputs B ⊆ {⊥,1,2, . . . ,T } we now have that\nPr[B(~S) ∈ B] = ∑ b∈B Pr[B(~S) = b] ≤ ∑ b∈B eε ·Pr[B(~S ′) = b] = Pr[B(~S ′) ∈ B]."
    } ],
    "references" : [ {
      "title" : "Typicality-based stability and privacy",
      "author" : [ "Raef Bassily", "Yoav Freund" ],
      "venue" : "CoRR, abs/1604.03336,",
      "citeRegEx" : "1",
      "shortCiteRegEx" : "1",
      "year" : 2016
    }, {
      "title" : "Algorithmic stability for adaptive data analysis",
      "author" : [ "Raef Bassily", "Kobbi Nissim", "Adam D. Smith", "Thomas Steinke", "Uri Stemmer", "Jonathan Ullman" ],
      "venue" : "In Proceedings of the 48th Annual ACM SIGACT Symposium on Theory of Computing,",
      "citeRegEx" : "2",
      "shortCiteRegEx" : "2",
      "year" : 2016
    }, {
      "title" : "A measure of asymptotic efficiency for tests of a hypothesis based on the sum of observations",
      "author" : [ "Herman Chernoff" ],
      "venue" : "Ann. Math. Statist.,",
      "citeRegEx" : "3",
      "shortCiteRegEx" : "3",
      "year" : 1952
    }, {
      "title" : "Adaptive learning with robust generalization guarantees",
      "author" : [ "Rachel Cummings", "Katrina Ligett", "Kobbi Nissim", "Aaron Roth", "Zhiwei Steven Wu" ],
      "venue" : "In Proceedings of the 29th Conference on Learning Theory, COLT 2016,",
      "citeRegEx" : "4",
      "shortCiteRegEx" : "4",
      "year" : 2016
    }, {
      "title" : "Generalization in adaptive data analysis and holdout reuse",
      "author" : [ "Cynthia Dwork", "Vitaly Feldman", "Moritz Hardt", "Toniann Pitassi", "Omer Reingold", "Aaron Roth" ],
      "venue" : "In Advances in Neural Information Processing Systems (NIPS),",
      "citeRegEx" : "5",
      "shortCiteRegEx" : "5",
      "year" : 2015
    }, {
      "title" : "Preserving statistical validity in adaptive data analysis",
      "author" : [ "Cynthia Dwork", "Vitaly Feldman", "Moritz Hardt", "Toniann Pitassi", "Omer Reingold", "Aaron Roth" ],
      "venue" : "In ACM Symposium on the Theory of Computing (STOC)",
      "citeRegEx" : "6",
      "shortCiteRegEx" : "6",
      "year" : 2015
    }, {
      "title" : "Our data, ourselves: Privacy via distributed noise generation",
      "author" : [ "Cynthia Dwork", "Krishnaram Kenthapadi", "Frank McSherry", "Ilya Mironov", "Moni Naor" ],
      "venue" : "In Serge Vaudenay, editor, EUROCRYPT,",
      "citeRegEx" : "7",
      "shortCiteRegEx" : "7",
      "year" : 2006
    }, {
      "title" : "Calibrating noise to sensitivity in private data analysis",
      "author" : [ "Cynthia Dwork", "Frank McSherry", "Kobbi Nissim", "Adam Smith" ],
      "venue" : "In TCC,",
      "citeRegEx" : "8",
      "shortCiteRegEx" : "8",
      "year" : 2006
    }, {
      "title" : "Preventing false discovery in interactive data analysis is hard",
      "author" : [ "Moritz Hardt", "Jonathan Ullman" ],
      "venue" : "In FOCS,",
      "citeRegEx" : "9",
      "shortCiteRegEx" : "9",
      "year" : 2014
    }, {
      "title" : "Probability inequalities for sums of bounded random variables",
      "author" : [ "Wassily Hoeffding" ],
      "venue" : "Journal of the American Statistical Association,",
      "citeRegEx" : "10",
      "shortCiteRegEx" : "10",
      "year" : 1963
    }, {
      "title" : "Divide and conquer martingales and the number of triangles in a random graph",
      "author" : [ "J.H. Kim", "V.H. Vu" ],
      "venue" : "Random Structures and Algorithms,",
      "citeRegEx" : "11",
      "shortCiteRegEx" : "11",
      "year" : 2004
    }, {
      "title" : "On the number of iterations for dantzig-wolfe optimization and packing-covering approximation algorithms",
      "author" : [ "Philip N. Klein", "Neal E. Young" ],
      "venue" : "SIAM J. Comput.,",
      "citeRegEx" : "12",
      "shortCiteRegEx" : "12",
      "year" : 2015
    }, {
      "title" : "Concentration in unbounded metric spaces and algorithmic stability",
      "author" : [ "Aryeh Kontorovich" ],
      "venue" : "In Proceedings of the 31th International Conference on Machine Learning,",
      "citeRegEx" : "13",
      "shortCiteRegEx" : "13",
      "year" : 2014
    }, {
      "title" : "Mechanism design via differential privacy",
      "author" : [ "Frank McSherry", "Kunal Talwar" ],
      "venue" : "In FOCS,",
      "citeRegEx" : "14",
      "shortCiteRegEx" : "14",
      "year" : 2007
    }, {
      "title" : "Interactive fingerprinting codes and the hardness of preventing false discovery",
      "author" : [ "Thomas Steinke", "Jonathan Ullman" ],
      "venue" : "In COLT, pages 1588–1628,",
      "citeRegEx" : "15",
      "shortCiteRegEx" : "15",
      "year" : 2015
    }, {
      "title" : "Subgaussian tail bounds via stability arguments. ArXiv.org, (arXiv:1701.03493 [cs.DM]), 2017",
      "author" : [ "Thomas Steinke", "Jonathan Ullman" ],
      "venue" : null,
      "citeRegEx" : "16",
      "shortCiteRegEx" : "16",
      "year" : 2017
    } ],
    "referenceMentions" : [ {
      "referenceID" : 5,
      "context" : "Abstract A new line of work [6, 9, 15, 2] demonstrates how differential privacy [8] can be used as a mathematical tool for guaranteeing generalization in adaptive data analysis.",
      "startOffset" : 28,
      "endOffset" : 41
    }, {
      "referenceID" : 8,
      "context" : "Abstract A new line of work [6, 9, 15, 2] demonstrates how differential privacy [8] can be used as a mathematical tool for guaranteeing generalization in adaptive data analysis.",
      "startOffset" : 28,
      "endOffset" : 41
    }, {
      "referenceID" : 14,
      "context" : "Abstract A new line of work [6, 9, 15, 2] demonstrates how differential privacy [8] can be used as a mathematical tool for guaranteeing generalization in adaptive data analysis.",
      "startOffset" : 28,
      "endOffset" : 41
    }, {
      "referenceID" : 1,
      "context" : "Abstract A new line of work [6, 9, 15, 2] demonstrates how differential privacy [8] can be used as a mathematical tool for guaranteeing generalization in adaptive data analysis.",
      "startOffset" : 28,
      "endOffset" : 41
    }, {
      "referenceID" : 7,
      "context" : "Abstract A new line of work [6, 9, 15, 2] demonstrates how differential privacy [8] can be used as a mathematical tool for guaranteeing generalization in adaptive data analysis.",
      "startOffset" : 80,
      "endOffset" : 83
    }, {
      "referenceID" : 15,
      "context" : "Very recently, Steinke and Ullman [16] observed that these generalization guarantees can be used for proving concentration bounds in the non-adaptive setting, where the low-sensitivity function is fixed beforehand.",
      "startOffset" : 34,
      "endOffset" : 38
    }, {
      "referenceID" : 5,
      "context" : "1 Introduction A new line of work [6, 9, 15, 2] demonstrates how differential privacy [8] can be used as a mathematical tool for guaranteeing statistical validity in data analysis.",
      "startOffset" : 34,
      "endOffset" : 47
    }, {
      "referenceID" : 8,
      "context" : "1 Introduction A new line of work [6, 9, 15, 2] demonstrates how differential privacy [8] can be used as a mathematical tool for guaranteeing statistical validity in data analysis.",
      "startOffset" : 34,
      "endOffset" : 47
    }, {
      "referenceID" : 14,
      "context" : "1 Introduction A new line of work [6, 9, 15, 2] demonstrates how differential privacy [8] can be used as a mathematical tool for guaranteeing statistical validity in data analysis.",
      "startOffset" : 34,
      "endOffset" : 47
    }, {
      "referenceID" : 1,
      "context" : "1 Introduction A new line of work [6, 9, 15, 2] demonstrates how differential privacy [8] can be used as a mathematical tool for guaranteeing statistical validity in data analysis.",
      "startOffset" : 34,
      "endOffset" : 47
    }, {
      "referenceID" : 7,
      "context" : "1 Introduction A new line of work [6, 9, 15, 2] demonstrates how differential privacy [8] can be used as a mathematical tool for guaranteeing statistical validity in data analysis.",
      "startOffset" : 86,
      "endOffset" : 89
    }, {
      "referenceID" : 5,
      "context" : "[6] showed how to utilize this connection for the task of answering adaptively chosen queries w.",
      "startOffset" : 0,
      "endOffset" : 3
    }, {
      "referenceID" : 5,
      "context" : "1 ([6, 2], informal).",
      "startOffset" : 3,
      "endOffset" : 9
    }, {
      "referenceID" : 1,
      "context" : "1 ([6, 2], informal).",
      "startOffset" : 3,
      "endOffset" : 9
    }, {
      "referenceID" : 15,
      "context" : "Very recently, Steinke and Ullman [16] observed that Theorem 1.",
      "startOffset" : 34,
      "endOffset" : 38
    }, {
      "referenceID" : 4,
      "context" : "[5] showed that if β is small enough, then w.",
      "startOffset" : 0,
      "endOffset" : 3
    }, {
      "referenceID" : 0,
      "context" : "However, a stronger notion than differential privacy – typical stability – presented by Bassily and Freund [1] does guarantee generalization in this setting.",
      "startOffset" : 107,
      "endOffset" : 110
    }, {
      "referenceID" : 3,
      "context" : "1A similar notion – perfect generalization – was presented in [4].",
      "startOffset" : 62,
      "endOffset" : 65
    }, {
      "referenceID" : 7,
      "context" : "2 (Differential Privacy [8, 7]).",
      "startOffset" : 24,
      "endOffset" : 30
    }, {
      "referenceID" : 6,
      "context" : "2 (Differential Privacy [8, 7]).",
      "startOffset" : 24,
      "endOffset" : 30
    }, {
      "referenceID" : 13,
      "context" : "2 The Exponential Mechanism We next describe the exponential mechanism of McSherry and Talwar [14].",
      "startOffset" : 94,
      "endOffset" : 98
    }, {
      "referenceID" : 2,
      "context" : "The first two inequalities are known as the multiplicative Chernoff bounds [3], and the last inequality is known as the Hoeffding bound [10].",
      "startOffset" : 75,
      "endOffset" : 78
    }, {
      "referenceID" : 9,
      "context" : "The first two inequalities are known as the multiplicative Chernoff bounds [3], and the last inequality is known as the Hoeffding bound [10].",
      "startOffset" : 136,
      "endOffset" : 140
    }, {
      "referenceID" : 11,
      "context" : "6 (Tightness of Chernoff bound [12]).",
      "startOffset" : 31,
      "endOffset" : 35
    }, {
      "referenceID" : 1,
      "context" : "[2] for the generalization properties of a differentially private algorithm that outputs a low-sensitivity function.",
      "startOffset" : 0,
      "endOffset" : 3
    }, {
      "referenceID" : 13,
      "context" : "The fact that algorithm B is (ε, (f̄ ,1))-differentially private follows from the standard analysis of the Exponential Mechanism of McSherry and Talwar [14].",
      "startOffset" : 152,
      "endOffset" : 156
    }, {
      "referenceID" : 1,
      "context" : ", [2]).",
      "startOffset" : 2,
      "endOffset" : 5
    }, {
      "referenceID" : 12,
      "context" : "The following is one such refinement, by Kontorovich [13].",
      "startOffset" : 53,
      "endOffset" : 57
    }, {
      "referenceID" : 12,
      "context" : "1 ([13]).",
      "startOffset" : 3,
      "endOffset" : 7
    }, {
      "referenceID" : 12,
      "context" : "In [13], Kontorovich showed the following theorem: Theorem 4.",
      "startOffset" : 3,
      "endOffset" : 7
    }, {
      "referenceID" : 12,
      "context" : "2 ([13], informal).",
      "startOffset" : 3,
      "endOffset" : 7
    }, {
      "referenceID" : 12,
      "context" : "As stated in the previous section, the results of [13] can be used to obtain a high probability bound on |f (S)− f (Dn) | whenever Prx,y∼D[ρ(x,y) ≥ t] ≤ exp ( −t2/σ2 ) for some σ > 0.",
      "startOffset" : 50,
      "endOffset" : 54
    }, {
      "referenceID" : 10,
      "context" : "Following the work of [17], in 2004 Kim and Vu [11] presented the following sharp bound:",
      "startOffset" : 47,
      "endOffset" : 51
    }, {
      "referenceID" : 10,
      "context" : "3 ([11], informal).",
      "startOffset" : 3,
      "endOffset" : 7
    }, {
      "referenceID" : 9,
      "context" : "4 ([10]).",
      "startOffset" : 3,
      "endOffset" : 7
    }, {
      "referenceID" : 4,
      "context" : "2 (Max-Information [5]).",
      "startOffset" : 19,
      "endOffset" : 22
    } ],
    "year" : 2017,
    "abstractText" : "A new line of work [6, 9, 15, 2] demonstrates how differential privacy [8] can be used as a mathematical tool for guaranteeing generalization in adaptive data analysis. Specifically, if a differentially private analysis is applied on a sample S of i.i.d. examples to select a lowsensitivity function f , then w.h.p. f (S) is close to its expectation, although f is being chosen based on the data. Very recently, Steinke and Ullman [16] observed that these generalization guarantees can be used for proving concentration bounds in the non-adaptive setting, where the low-sensitivity function is fixed beforehand. In particular, they obtain alternative proofs for classical concentration bounds for low-sensitivity functions, such as the Chernoff bound and McDiarmid’s Inequality. In this work, we set out to examine the situation for functions with high-sensitivity, for which differential privacy does not imply generalization guarantees under adaptive analysis. We show that differential privacy can be used to prove concentration bounds for such functions in the non-adaptive setting.",
    "creator" : "LaTeX with hyperref package"
  }
}