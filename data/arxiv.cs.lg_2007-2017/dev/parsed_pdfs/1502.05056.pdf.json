{
  "name" : "1502.05056.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : null,
    "authors" : [ ],
    "emails" : [ ],
    "sections" : [ {
      "heading" : null,
      "text" : "ar X\niv :1\n50 2.\n05 05\n6v 1\nWe revisit the theory, eliminating both the requirement of weak selection and any assumption on the distribution of the population. Removing the assumption of product distributions is crucial, since as we show, this assumption is inconsistent with the population dynamics. We show that the marginal allele distributions induced by the population dynamics precisely match the marginals induced by a multiplicative weights update algorithm in this general setting, thereby affirming and substantially generalizing these earlier results.\nWe further revise the implications for convergence and utility or fitness guarantees in coordination games. In contrast to the claim of Chastain et al. [2014], we conclude that the sexual evolutionary dynamics does not entail any property of the population distribution, beyond those already implied by convergence."
    }, {
      "heading" : "1 Introduction",
      "text" : "Connections between the theory of evolution, machine learning and games have captured the imagination of researchers for decades. Evolutionary models inspired a range of applications from genetic algorithms to the design of distributed multiagent systems [Goldberg and Holland, 1988; Cetnarowicz et al., 1996; Phelps et al., 2008]. Within game theory, several solution concepts follow evolutionary processes, and some of the most promising dynamics that lead to equilibria in games assume that players learn the behavior of their opponents [Haigh, 1975; Valiant, 2009].\nA different connection between sex, evolution and machine learning was recently suggested by Chastain, Livnat, Papadimitriou and Vazirani [2014]. As they explain, also referring to Barton and Charlesworth [1998], sexual reproduction is costly for the individual and for the society in terms of time and energy, and often breaks successful gene combinations. From the perspective of an individual, sex dilutes his or her genes by only transferring half of them to each offspring. Thus the question that arises is why sexual reproduction is so common in nature, and why is it so successful. Chastain et al. [2014] suggest that the evolutionary process under sexual reproduction effectively implements a celebrated no-regret learning algorithm. The structure of their argument is as follows.\nFirst, they restrict attention to a particular class of fitness landscape where weak selection holds. Informally, weak selection means that the fitness difference between genotypes is bounded by a small constant, i.e., there are no extremely good or extremely bad gene combinations.1 Second, they consider the distribution of each gene’s alleles as a mixed strategy in a matrix-form game, where there is one player for each gene. The game is an identical interest game, where each player gets the same utility— thus the joint distribution of alleles corresponds to the mixed strategy of each player, and the expected payoff of the game corresponds to the average fitness level of the population.\nChastain et al. [2014] provide a correspondence between the sexual population dynamics and the multiplicative weights update algorithm (MWUA) [Littlestone and Warmuth, 1994; Cesa-Bianchi et al., 1997]. In particular, they establish a correspondence between strategies adopted by players in the game that adopt MWUA and the population dynamics, under an assumption that the fitness matrix is in the weak selection regime, and that the population dynamic retains the structure of a product distribution on alleles. With this correspondence in place, these authors apply the fact that using MWUA in a repeated game leads to diminishing regret for each player\n1A gene takes on a particular form, known as allele. By a genotype, or gene combination, we refer to a set of alleles– one for each gene. The genotype determines the properties of the creature, and hence its fitness in a given environment.\nto conclude that the regret experienced by genes also diminishes. They interpret this result as maximization of a property of the population distribution, namely “the sum of the expected cumulative differential fitness over the alleles, plus the distribution’s entropy.”\nWe believe that such a multiagent abstraction of the evolutionary process can contribute much to our understanding, both of evolution and of learning algorithms. Interestingly, the agents in this model are not the creatures in the population, nor Dawkins’ [Dawkins, 2006] genetic properties (alleles) that compete one another, but rather genes that share a mutual cause."
    }, {
      "heading" : "1.1 Our Contribution",
      "text" : "We show that the main results of Chastain et al. [2014] can be substantially generalized. Specifically, we consider the two standard population dynamics (where recombination acts before selection (RS), and vice versa (SR)), and show that each of them precisely describes the marginal allele distribution under a variation of the multiplicative updates algorithm that is described for correlated strategies. This correspondence holds for any number of genes/players, any fitness matrix, any recombination rate, and any initial population frequencies. In particular, and in contrast to Chastain et al., we do not assume weak selection or require the population distribution remains a product distribution (i.e., with allele probabilities that are independent), and we allow both the SR model and the RS model.\nWe discuss some of the implications of this correspondence between these biological and algorithmic processes for theoretical convergence properties. Under weak selection, the observation that the cumulative regret of every gene is bounded follows immediately from known convergence results, both in population dynamics and in game theory (see related work). We show that under the SR dynamics, every gene still has a bounded cumulative regret, without assuming weak selection or a product distribution.\nOur analysis also uncovers what we view as one technical gap and one conceptual gap regarding the fine details in the original argument of Chastain et al. [2014]. We believe that due to the far reaching consequences of the theory it is important to rectify these details. First, according to the population dynamics the population frequencies may become highly correlated (even under weak selection), and thus it is important to avoid the assumption on product distributions. Second, the property that is supposedly maximized by the population dynamics is already entailed by the convergence of the process (regardless of what equilibrium is reached). We should therefore be careful when interpreting it as some nontrivial advantage of the evolutionary process."
    }, {
      "heading" : "1.2 Related Work",
      "text" : "The multiplicative weights update algorithm (MWUA) is a general name for a broad class of methods in which a decision maker facing uncertainty (or a player in a repeated game), updates her strategy. While specifics vary, all variations of MWUA increase the probability of actions that have been more successful in previous rounds. In general games, the MWUA dynamic is known to lead to diminishing regret over time [Jafari et al., 2001; Blum and Mansour, 2007; Kale, 2007; Cesa-Bianchi et al., 2007], but does not, in general, converge to a Nash equilibrium of the game. For some classes of games better convergence results are known; see Section 5.2 for details.\nThe fundamental theorem of natural selection, which dates back to Fisher [1930], states that the population dynamics of a single-locus diploid always increases the average fitness of each generation, until it reaches convergence [Mulholland and Smith, 1959; Li, 1969].2 The fundamental theorem further relates the rate of increase to the variance of fitness in the population. In the general case, for genotypes with more than a single locus, the fundamental theorem does not hold, although constructing a counter example where a cycle occurs is non-trivial [Hastings, 1981; Hofbauer and Iooss, 1984]. However, convergence of the population dynamics has been shown to hold when the fitness landscape has some specific properties, such as weak selection, or weak epistasis [Nagylaki et al., 1999].3\nIn asexual evolutionary dynamics, every descendent is an exact copy of a single parent, with more fit parents producing more offspring (“survival of the fittest”). Regardless of the number of loci, asexual dynamics coincides with MWUA by a single player [Börgers and Sarin, 1997; Hopkins, 1999]. Chastain et al. [2014] were the first to suggest that a similar correspondence can be established for sexual population dynamics."
    }, {
      "heading" : "2 Definitions",
      "text" : "We follow the definitions of Chastain et al. [2014] where possible. For more detailed explanation of the biological terms and equations, see Bürger [2011].\n2Roughly, a single-locus means there is only one property that determines fitness, for example eye color or length of tail. Multiple loci mean that fitness is determined by a combination of several such properties. We explain what are diploids and haploids in the next section.\n3Weak epistasis means that the various genes have separate, nearly-additive contribution to fitness. It is incomparable to weak selection."
    }, {
      "heading" : "2.1 Population dynamics",
      "text" : "A haploid is a creature that has only one copy of each gene. Each gene has several distinct alleles. For example, a gene for eye color can have alleles for black, brown, green or blue color. In contrast, people are diploids, and have two copies of each gene, one from each parent.\nUnder asexual reproduction, an offspring inherits all of its genes from its single parent. In the case of sexual reproduction, each parent transfers half of its genes. Thus a haploid inherits half of its properties from one parent and half from the other parent. To keep the presentation simple we focus on the case of a 2-locus haploid. This means that there are two genes, denoted A and B. In the appendix we extend the definitions and results to k-locus haploids, for k > 2. Gene A has n possible alleles a1, . . . , an, and gene B has m possible alleles b1, . . . , bm. It is possible that n 6= m. We denote the set {1, . . . , n} by [n]. A pair 〈ai, bj〉 of alleles defines a genotype.\nLet W = (wij)i≤n,j≤m denote a fitness matrix. The fitness value wij ∈ R+ can be interpreted as the expected number of offspring of a creature whose genotype is 〈ai, bj〉. We assume that the fitness matrix is fixed, and does not change throughout evolution. See Table 1 for an example.\nWe denote by P t = (ptij)i≤n,j≤m the distribution of the population at time t. The average fitness wt at time t is written as\nwt = w(P t) = ∑\nij\nptijwij . (1)\nFor example, the populations in Table 1 have an average fitness of w(P 0) = 1.005 and w(P 1) = 1.1012. Denote by xti = ∑ j p t ij and y t j = ∑ i p t ij the marginal frequencies at time t of alleles ai and bj , respectively. Clearly ptij = x t iy t j for all\ni, j iff P t is a product distribution. In the context of population dynamics, the set of product distributions is also called the Wright manifold. For general distributions, Dtij = p t ij − x t iy t j is called the linkage disequilibrium.\nThe selection strength of W is the minimal s s.t. wij ∈ [1 − s, 1 + s] for all i, j. We say that W is in the weak selection regime if s is very small, i.e., all of wij are close to 1.\nUpdate step In asexual reproduction, every creature of genotype 〈ai, bj〉 has in expectation wij offspring, all of which are of genotype 〈ai, bj〉. Thus there is only selection and no recombination, and the frequencies in the next period are pt+1ij = p S ij = wij wt\nptij . In sexual reproduction, every pair of creatures, say of genotypes 〈ai, bl〉 and 〈ak, bj〉 bring offspring who may belong (with equal probabilities) to genotype 〈ai, bl〉 , 〈ak, bj〉 , 〈ai, bj〉, or 〈ak, bl〉. Thus, in the next generation, a creature of genotype 〈ai, bj〉 can be the result of combining one parent of genotype 〈ai, ?〉 with another parent of genotype 〈?, bj〉. There are two ways to infer the distribution of the next generation, depending on whether recombination occurs before selection or vice versa (see, e.g., [Michalakis and Slatkin, 1996]). We describe each of these two ways next.\nSelection before recombination (SR) Summing over all possible matches and their frequencies, and normalizing, we get:\npSRij =\n∑\nl∈[m]\n∑\nk∈[n] p t ilwilp t kjwkj\n(wt)2 .\nIn addition, the recombination rate, r ∈ [0, 1], determines the part of the genome that is being replaced in crossover, so r = 1 means that the entire genome is the result of recombination, whereas r = 0 means no recombination occurs, and the offspring are genetically identical to one of their parents. Given this, population frequencies in the next period are set as:\npt+1ij = rp SR ij + (1− r)p S ij. (2)\nRecombination before selection (RS) With only recombination, the frequency of the genotype 〈ai, bj〉 is the product of the respective probabilities in the previous generation, i.e., pRij = x t iy t j . When recombination occurs before selection, we have (before normalization):\npRSij = wijp R ij = wijx t iy t j.\nTaking into account the recombination rate and normalization, we get,\npt+1ij = 1\nwR (rpRSij + (1− r)p S ij) =\n1\nwR wij(p\nt ij − rD t ij), (3)\nwhere wR = ∑ ij wij(p t ij − rD t ij), and D t ij is the linkage disequilibrium at time t.\nFor an example of change in population frequencies, see Tables 1-4. We say that P t is a stable state under a particular dynamics, if P t+1 = P t."
    }, {
      "heading" : "2.2 Identical interest games",
      "text" : "An identical interest game of two players is defined by a payoff matrix G, where gij is the payoff of each player if the first plays action i, and the second plays action j. A mixed strategy of a player is an independent distribution over her actions. The mixed strategies x,y are a Nash equilibrium if no player can switch to a strategy that has a strictly higher expected payoff. That is, if for any action i′ ∈ [n], ∑\nj yjgi′j ≤ ∑ i ∑ j xiyigij , and similarly for any j ′ ∈ [m].\nEvery fitness matrix W induces an identical interest game, where gij = wij . This is a game where each of the two genes selects an allele as an action (or a distribution over alleles, as a mixed strategy). A matrix of population frequencies P can be thought of as correlated strategies for the players. The expected payoff of each player under these strategies is w(P ). Given a distribution P , G|P is the subgame of G induced by the support of P . That is, the subgame where action i is allowed iff pij > 0 for some j, and likewise for action j."
    }, {
      "heading" : "2.3 Multiplicative updates algorithms",
      "text" : "Suppose that two players play a game G (not necessarily identical interest) repeatedly. Each player observes the strategy of her opponent in each turn, and can change her own strategy accordingly.4One prominent approach is to gradually put more weight (i.e., probability) on pure actions that were good in the previous steps. Many variations of the multiplicative weights update algorithm (MWUA) are built upon this idea, and some have been applied to strategic settings [Blum and Mansour, 2007; Marden et al., 2009; Kleinberg et al., 2009]. We follow the variation used by Chastain et al. [2014]. This variation is equivalent to the Polynomial Weights (PW) algorithm [2007], under the assumption that the utility of all actions (ai)i≤n is observed after each period (see Kale [2007], p. 10).\n4 We assume that the player observes the full joint distribution P t, and can thus infer the (expected) utility of every action ai at time t.\nPolynomial Weights We use the term PW to distinguish this from other variations of MWUA. For any ǫ > 0, the ǫ-PW algorithm for a single decision maker is defined as follows. Suppose first that in time t, the player uses strategy xt. Let gti be the utility to the player when playing some pure action i ∈ [n]. According to the ǫ-PW algorithm, the strategy of the player in the next step would be xt+1(i) ∼= xt(i)(1 + ǫgti), where\n∼= stands for “proportional to” (we need to normalize, since xt+1 has to be a valid distribution). A special case of the algorithm is the limit case ǫ → ∞, where xt+1(i) ∼= xt(i)gti ; i.e., the probability of playing an action increases proportionally to its expected performance in the previous round. Unless specified otherwise we assume this limit case, which we refer to as the parameter-free PW.\nPW in Games The fundamental feature of the PW algorithm is that the probability of playing action ai changes proportionally to the expected utility of action ai.\nConsider 2-player game G, where gij is the utility (of both players if G is an identical interest game) from the joint action 〈ai, bj〉. In the context of a game, we can think of at least two different interpretations of the utility of playing ai, derived\nfrom the joint distribution P . For this, let ytj(ai) = P t(bj |ai), i.e., the probability that player 2 plays bj given that player 1 plays ai, according to the distribution P t. The two interpretations we have in mind are:\n• Set gt i =\n∑\nj y t j(ai)gij . This is the expected utility that player 1 would\nget for playing ai in round t. This definition is consistent with common interpretation of expected utility in games (e.g., in Kale [2007], Sec. 2.3.1).\n• Set gti = ∑ j y t jgij . This is the expected utility that player 1 will get in\nthe next round for playing ai if player 2 will select an action independently according to her current marginal probabilities. Thus each agent updates her strategy as if the strategies are independent, and ignoring any observed correlation. This definition results in the PW algorithm used in Chastain et al. [2014].\nThe above definitions require some discussion. While the traditional assumption is that each player only observes a sample from the joint distribution at each round, and updates the strategy based on the empirical distribution, strategy updates can also be performed in the same way when the player observes the joint distribution at round t, even if it is hard to imagine such a case occurs in practice.\nIntuitively, under the first interpretation, the player considers correlation, whereas under the second the player assumes independence, and then uses the marginals to compute the expected utility. E.g suppose that players play RockPaper-Scissors, and the history is 100 repetitions of the sequence [(R,P) (P,S) (S,S)]. Then under the first interpretation the best action for agent 1 is S (since it leads to the best expected utility); whereas under the second interpretation the best action for agent 1 is R, since agent 2 is more likely to play S.5 Clearly, when P t is a\n5We can also think of the two approaches as the two sides of Newcomb’s paradox [Nozick, 1969]: the player observes a correlation, even though deciding on a strategy cannot change the expected utility of each action. Thus it is not obvious whether the observed correlation should be considered in the strategy update.\nproduct distribution (as in Chastain et al. [2014]) then gti = g t i , and the algorithms coincide. We can also combine the two interpretations to induce new algorithms. We thus define the PW(α) algorithm (either Parameter-free PW(α) or ǫ-PW(α)), where the probability of playing ai is updated according to g t,(α) i = αg t i+(1−α)g t i .\nExponential Weights The Hedge algorithm [Freund and Schapire, 1995, 1999] is another variation of MWUA that is very similar to PW. The difference is that the weight of action i in each step changes by a factor that is exponential in the utility, rather than linear. That is, xt+1(i) ∼= xt(i)(1 + ǫ)g t i . For negligible ǫ > 0, ǫ-Hedge and ǫ-PW are essentially the same, but for large ǫ they may behave quite differently."
    }, {
      "heading" : "3 Analysis of the SR dynamics",
      "text" : "In this section we prove that the SR population dynamics of marginal allele frequencies coincide precisely with the multiplicative updates dynamics in the corresponding game. This extends Theorem 4 in Chastain et al. [2014] (SI text), in that it holds without weak selection or the assumption of product distributions through multiple iterations. We also generalize the proposition to hold for any number of loci/players in Appendix A.\nProposition 1. Let W be any fitness matrix, and consider the game G where gij = wij . Then under the SR population dynamics, for any distribution P t and any r ∈ [0, 1], we have xt+1i = 1 wt xtig t i .\nProof. By the SR population dynamics (Eq. (2)),\nxt+1i = ∑\nj\npt+1ij = ∑\nj\n(rpSRij + (1− r)p S ij)\n= r ∑\nj\n∑\nl\n∑\nk p t ilwilp t kjwkj\n(wt)2 + (1− r)\n∑\nj\nptijwij\nwt\n= r 1\nwt\n∑\nl\nptilwil 1\nwt\n∑\nk\n∑\nj\nptkjwkj + (1− r) ∑\nj\nptijwij\nwt\nThen since ∑\nk\n∑\nj p t kjwkj is the average fitness at time t,\nxt+1i = r 1\nwt\n∑\nj\nptijwij 1\nwt wt + (1− r)\n∑\nj\nptijwij\nwt\n= r 1\nwt\n∑\nj\nptijwij + (1− r) ∑\nj\nptijwij\nwt\n= 1\nwt\n∑\nj\nptijwij = 1\nwt\n∑\nj\nxtiy t j(ai)wij ,\nthus the recombination factor r does not play a direct role in the new marginal under the SR dynamics. It does have an indirect role though, since it affects the correlation, and thus the marginal distribution at the next generation t+ 2.\nTheorem 4 in Chastain et al. [2014] follows as a special case when P t is a product distribution. By repeatedly applying Proposition 1, we get the following result, which holds for any value of r.\nCorollary 1. Let W be a fitness matrix, P 0 be any distribution. Suppose that P t+1 is attained from P t by the SR population dynamics, and that xt+1,yt+1 are attained from P t by players using the parameter-free PW(0) algorithm in the game G = W . Then for all t > 0 and any i, xti = ∑ j p t ij .\nIt is important to note that the marginal distributions xt,yt do not determine P t completely. Thus the PW algorithm specifies the strategy of each player (regardless of r), but not how these strategies are correlated."
    }, {
      "heading" : "4 Analysis of the RS dynamics",
      "text" : "Turning to the RS population dynamics, our starting point is Lemma 3 in Chastain et al. [2014] (SI text), which states that pt+1ij = 1 wR wijx t iy t j (under the assumption that P t is a product distribution). We establish a similar property for general distributions. We use the fact that for any fitness matrix W and distribution P t,\npt+1ij = 1\nwR (rwijx\nt iy t j + (1− r)wijp t ij).\nThis follows immediately from the definition (Eq. (3)). Recall that gt,(r)i = (\nrgti + (1− r)g t i\n)\n. We derive an alternative extension of Theorem 4 in Chastain\net al. [2014] (SI text) for the RS dynamics.\nProposition 2. Let W be any fitness matrix, and consider the game G where gij = wij . Then under the RS population dynamics, for any distribution P t and any r ∈ [0, 1], xt+1i = 1 wR xtig t,(r) i .\nProof. By the RS population dynamics (Eq. (3)),\nxt+1i = ∑\nj\npt+1ij = ∑\nj\n1\nwR (rwijx\nt iy t j + (1− r)wijp t ij)\n= 1\nwR\n∑\nj\n(rwijx t iy t j + (1− r)wijx t iy t j(ai))\n= 1\nwR xti(r\n∑\nj\nwijy t j + (1− r)\n∑\nj\nwijy t j(ai)).\nFinally, by the definitions of gti and g t i ,\nxt+1i = 1\nwR xti\n(\nrgti + (1− r)g t\ni\n) = 1\nwR xtig t,(r) i .\nIn contrast to the SR dynamics, here r appears explicitly in the marginal distribution xt+1.\nSo we get that under RS the marginal frequency of allele ai is updated according to an expected utility that takes only part of the correlation into account. This part is proportional to the recombination rate r. We get a similar result to Corollary 1:\nCorollary 2. Let W be a fitness matrix, P 0 be any distribution. Suppose that P t+1 is attained from P t by the RS population dynamics, and that xt+1,yt+1 are attained from P t by players using the parameter-free PW(r) algorithm in the game G = W . Then for all t > 0 and any i, xti = ∑ j p t ij ."
    }, {
      "heading" : "5 Convergence and Equilibrium",
      "text" : "In this section, we consider implications of the general theory on the correspondence between sexual population dynamics and multiplicative-weights algorithms on convergence properties."
    }, {
      "heading" : "5.1 Diminishing regret",
      "text" : "In Chastain et al. [2014] (Sections 3 and 4 of the SI text), the authors apply standard properties of MWUA to show that the cumulative external regret of each gene is bounded (Corollary 5 there). In other words, if in retrospect gene 1 would have “played” some fixed allele ai throughout the game, the cumulative fitness (summing over all iterations) would not have been much better. This result leans only on the properties of the algorithm, and does not require the independence of strategies. Thus we will write a similar regret bound explicitly in our more general model.\nConsider any fitness matrix W whose selection strength is s. Let AF Ti = 1 T ∑T t=1 g t i (the average fitness in retrospect if allele ai had been used throughout the game), and AF TSR = 1 T ∑T t=1 w\nt (the actual average fitness under the SR dynamics).\nCorollary 3. For any T ∈ N, any s ∈ (0, 12) and all i ≤ n, AF T SR ≥ AF T i − s 2 − ln(n)/T .\nProof. Set ∆ij = wij−1 s ; m(t)i = ∑ j y t j(ai)∆ij , and ǫ = s. Note that ∆ij and m (t) i are in the range [−1, 1]. Intuitively, m (t) i is the expected profit of player 1 from playing action ai in the “differential game” W−1s . Theorem 3 [Kale, 2007] states that under the ǫ-PW algorithm6\nT ∑\nt=1\nx(t)m(t) ≥\nT ∑\nt=1\nm (t) i − ǫ\nT ∑\nt=1\n(m (t) i )\n2 − ln(n)\nǫ , (4)\nwhere x(t)i is the probability that the decision maker chose action ai in iteration t (thus x(t)i = x t i by our notation).\nThe proof follows directly from the theorem. Observe that m(t)i = (g t i − 1)/s,\nand\nx(t) ·m(t) = ∑\ni\nxtim (t) i =\n∑\ni\nxti ∑\nj\nytj(ai)∆ij\n= ∑\nij\nptij wij − 1\ns =\nwt − 1\ns .\n6Kale [2007] analyzes the Exponential Weights algorithm but a slight modification of the analysis works for PW.\nThus\nAF Ti = 1\nT\nT ∑\nt=1\ngt i =\n1\nT\nT ∑\nt=1\nsm (t) i + 1 = 1 + ǫ\n1\nT\nT ∑\nt=1\nm (t) i\nAF TSR = 1\nT\nT ∑\nt=1\nwt = 1\nT\nT ∑\nt=1\n(1 + sm(t) · p(t))\n= 1 + ǫ 1\nT\nT ∑\nt=1\nm(t) · p(t). (replacing ǫ = s)\nPlugging in Eq. (4),\nAF TSR ≥ 1 + ǫ 1\nT\n(\nT ∑\nt=1\nm (t) i − ǫ\nT ∑\nt=1\n(m (t) i )\n2 − ln(n)\nǫ\n)\n≥ 1 + ǫ 1\nT\n(\nT ∑\nt=1\nm (t) i − ǫ\nT ∑\nt=1\n1− ln(n)\nǫ\n)\n=\n(\n1 + ǫ 1\nT\nT ∑\nt=1\nm (t) i\n)\n− ǫ2 − 1\nT ln(n)\n= AF Ti − s 2 − ln(n)/T,\nas required.\nWe highlight that the bound on the regret of each player (or gene) stated in this result depends only on the algorithm used by the agent, and not on the strategies of other agents. These may be independent, correlated, or even chosen in an adversarial manner. For simplicity we present the proof for two players/genes. The extension to any number of players is immediate because the theorem bounds the regret of each agent separately.\nBy taking s to zero and T to infinity, we get that the average cumulative regret AF TSR − AF T i tends to zero, as stated in Chastain et al. [2014] (they use a more refined form of the inequality that contains the entropy of P t rather than lnn). For the RS dynamics we get something similar but not quite the same. Since g t,(r) i is not exactly the expected fitness at time t, we get that cumulative regret is diminishing but not w.r.t. the actual average fitness wt. That is, the regret is determined as if the actual expected fitness of action ai is g t,(r) i . More formally, we get a variation of Corollary 3, where AF Ti = 1 T ∑T t=1 g t,(r) i and AF T RS = 1 T ∑T t=1 ∑ i x t ig t,(r) i ."
    }, {
      "heading" : "5.2 Convergence under weak selection",
      "text" : "In normal-form games, following strategies with bounded or diminishing regret does not, in general, guarantee convergence to a fixed point in the strategy space.7 For some classes of games though, much more is known. For example, if all players in a potential game apply the ǫ-Hedge algorithm, with a sufficiently small ǫ, then P t converges to a Nash equilibrium [Kleinberg et al., 2009], and almost always to a pure Nash equilibrium. Similar results have been shown for concave games [Even-Dar et al., 2009]. Since identical-interest games are both potential games and concave games, and since for small ǫ we have that Hedge and PW are essentially the same, these results apply to our setting. This means that under each of RS and SR dynamics, the population converges to a stable state, for a sufficiently low selection strength s.\nThis implication is not new, and has been shown independently in the evolutionary biology literature. Indeed, Nagylaki et al. [1999] prove that under weak selection, the population dynamics converges to a point distribution from any initial state (that is, to a Nash equilibrium of the subgame induced by the support of the initial distribution). Note that under weak selection, Corollary 3 becomes trivial: once in a pure Nash equilibrium (ai∗ , bj∗) (say at time t∗), the optimal action of agent 1 is to keep playing a∗i . Thus for any t > t ∗, wt = gt i∗\n, and the cumulative regret does not increase further."
    }, {
      "heading" : "6 Discussion",
      "text" : "Chastain et al. [2014] extend an interesting connection between evolution, learning, and games from asexual reproduction (i.e., replicator dynamics) to sexual reproduction. The proof of Theorem 4 in Chastain et al. [2014] gives a formal meaning to this connection. Namely, that the strategy update of each player who is using PW(1) in the fitness game, coincides with the change in allele frequencies of the corresponding gene (under weak selection and product distributions). This relation is generalized in our Propositions 1 and 2, since for product distributions PW(α) is the same for all α.\nChastain et al. [2014] also claim something stronger: that the population dynamics is precisely the PW dynamics. The natural formal interpretation of this conclusion would be in the spirit of our Corollary 1, i.e., that allele distributions and players’ strategies would coincide after any number of steps. In our case we\n7It is known that the average joint distribution over all iterations converges to the set of correlated equilibria [Blum and Mansour, 2007]. This is less relevant to us because we are interested in the limit of P t.\nprove this for the marginal probabilities. But as we have discussed, their conclusion only follows from their Theorem 4 under the assumption that P t remains a product distribution. This is counterfactual, in that P t+1 is in general not a product distribution (under their assumptions on the dynamic process), and thus the next step of the PW(r) algorithm and the population dynamics would not be precisely equivalent but only approximately equivalent. The approximation becomes less accurate in each step, and in fact even under weak selection the population dynamics may diverge from the Wright manifold, or converge to a different outcome than the PW(r) algorithm, as we show in Appendix B. Thus while the intuition of Chatain et al. [2014] was correct, the only way to rectify their analysis is via the more general proof without assumptions on the selection strength (even if we accept weak selection as biologically plausible).\nWhat does evolution maximize? In Chastain et al. [2014] (Corollary 5 in the SI text), it is also shown that under weak selection, “population genetics is tantamount to each gene optimizing at generation t a quantity equal to the cumulative expected fitness over all generations up to t,” (plus the entropy). While this is technically correct (our Cor. 3 is a restatement of this result), we feel that an unwary reader might reach the wrong impression, that this is a mathematical explanation of some guarantee on the average fitness of the population. We thus emphasize that the both [2014] and our paper establish only the property of diminishing regret, which is already implied when P t converges to a Nash equilibrium. Players never have regret in a Nash equilibrium, and thus the cumulative regret tends to zero after the equilibrium is played sufficiently many times.\nThus the population dynamics cannot provide any guarantees on fitness (or on any other property) that are not already implied by an arbitrary Nash equilibrium. In the evolutionary context this means that the outcome can be as bad as the worst local maximum of the fitness matrix. Also note that convergence is to a point distribution (a pure Nash equilibrium, see Sec. 5.2), and thus its entropy is 0 and irrelevant for the maximization claim.\nConvergence without weak selection It is an open question as to what other natural conditions are sufficient to guarantee convergence of sexual population dynamics. We have conducted simulations that show that convergence to a pure equilibrium occurs w.h.p. even without weak selection, and in fact the convergence speed increases as selection strength s (or the learning rate ǫ) grows. At the same time, the quality of the solution/population reached seems to be the same regardless of the selection strength/learning rate (we measured quality as the fitness of the local maximum the dynamics converged to, normalized w.r.t. the global maximum).\nQ, where q = w\nt−1 maxij wij−1\n(the ratio between average fitness in the equilibrium that was reached, and the optimal fitness). Results are for random fitness matrices of size 8 × 5, where wij is sampled uniformly at random from [1 − s, 1 + s]. Note that most instances do not converge to the optimal outcome.\nBoth trends are visible in Figure 1 for 8× 5 matrices, based on 1000 instances for each plot. Similar results are obtained with other sizes of matrices.\nHowever, it is known that the sexual population dynamics on general fitness matrices (even on 4× 4 matrices) does not always converge, and explicit examples have been constructed [Hastings, 1981; Akin, 1983; Hofbauer and Iooss, 1984]. By Corollaries 1 and 2, convergence of the PW algorithm to a pure Nash equilibrium, and convergence of the population dynamics to a point distribution is the same thing. Thus characterizing the conditions under which these dynamics converge will answer two questions at once.\nConclusions We formally describe a precise connection between population dynamics and the multiplicative weights update algorithm. For this connection, we adopt a version of MWUA that takes the correlation of player strategies into account, while still supporting no regret claims. More specifically, two different variations of the Polynomial Weights subclass of MWUA each coincide with the marginal allele distribution under the two common sexual population dynamics (SR and RS). It is important to note that the correspondence that we establish is between the marginal frequencies/probabilities, rather than the full joint distribution.\nNotably, weak selection is not required to make these connections.Yet, it is\nknown that weak selection provides an additional guarantee, which is that the dynamics converge to a particular population distribution [Nagylaki, 1993]. It remains an open question to understand what other conditions are sufficient for convergence of the PW algorithm in identical interest games. Solving this question will also uncover more cases where the fundamental theorem of natural selection applies."
    }, {
      "heading" : "Acknowledgments",
      "text" : "We thank Avrim Blum, Yishay Mansour and James Zou for helpful discussions. We also acknowledge a useful correspondence with the authors of Chastain et al. [2014], who clarified many points about their paper. Any mistakes and misunderstandings remain our own."
    }, {
      "heading" : "A Extension to Multiple Genes",
      "text" : "A k-locus haploid has k genes, each of which is inherited from one of its two parents. In this appendix we show how to extend our main results to a haploid with k > 2 loci.\nA.1 Notation\nWe consider a haploid with k loci, each with nj alleles, j ≤ k. We denote K = [k] = {1, 2, . . . , k}, and use J to denote subsets of K .\nA genotype is defined by a vector of indices iK = 〈i1, . . . , ik〉 for ij ∈ [nj]. We denote by I(J) the set of all ∏\nj∈J nj partial index vectors of the form 〈ij〉j∈J .\nWe sometimes concatenate two or more partial genotypes: i′′J ′′ = 〈 iJ , i ′ J ′ 〉\nfor some iJ ∈ I(J), i′J ′ ∈ I(J\n′). We use −J to denote K \\ J . The fitness of a genotype iK is denoted by wiK . W = (wiK )iK∈I(K) is called the fitness landscape (which is a matrix for k = 2). Similarly, the population frequency of genotype iK at time t is denoted by ptiK , and P t = (pt iK )iK∈I(K).\nThe average fitness at time t is\nwt = ∑\niK∈I(K)\nptiKwiK =\nn1 ∑\ni1=1\n· · ·\nnk ∑\nik=1\nptiKwiK . (5)\nLet xtj be the marginal distribution of locus j ∈ K at time t, i.e., for all ij ∈ [nj],\nxtij = ∑\ni−j∈I(−j)\nptij ,i−j .\nIn the special case of 2 loci, K = {1, 2}, and xti1 , x t l2 correspond to xti, y t l as used in the main text. We also define the marginal fitness of allele ij ∈ [nj ] at time t as the average fitness of all the population with allele ij . That is,\nwtij = ∑\ni−j∈I(−j)\npt(i−j |ij)wij ,i−j . (6)\nA.2 RS dynamics\nAccording to the multi-dimensional extension of pt+1 iK ,\npt+1 iK\n= 1\nwR (rwiK\n∏\nj∈K\nxtij + (1− r)wiKp t iK ). (7)\nGiven a game G and a joint distribution P t, let gtij = ∑\ni−j∈I(−j) ( ∏ j′∈I(−j) x t ij′ )gij ,i−j . That is, the expected utility of playing\naij when every agent j ′ independently plays xtj′ .\nLemma 1. Let W be any fitness matrix, and consider the game G = W . Then under the RS population dynamics, for any distribution P t and any r ∈ [0, 1],\nxt+1ij = 1\nwR xtijg t,(r) ij .\nProof.\nxt+1ij = ∑\ni−j∈I(−j)\npt+1ij ,i−j (By definition)\n= ∑\ni−j∈I(−j)\n1\nwR (rwij ,i−jx\nt ij\n∏\nj′∈I(−|)\nxtij′ + (1− r)wij ,i−jp t ij ,i−j )\n(By Eq. (7))\n= 1\nwR xtij\n\nr ∑\ni−j∈I(−j)\nwij ,i−j ∏\nj′∈I(−|)\nxtij′\n+ (1− r) ∑\ni−j∈I(−j)\nwij ,i−jP t(i−j|ij)\n\n\n= 1\nwR xtij\n(\nrgti + (1− r)g t\ni\n) = 1\nwR xtijg t,(r) i .\nA.3 SR dynamics\nThe SR population dynamics under sexual reproduction is defined as:\npt+1 iK\n= r ∑\ni′ K ∈I(K)\n1\n2k\n∑\nJ⊆K\npt iJ ,i ′ −J wiJ ,i′−Jp t i′ J ,i−J wi′ J ,i−J\n(wt)2 + (1− r) wiKpiK wt . (8)\nWe can think of J as the set of genes that are inherited from the “first” parent, and −J as the set of genes that are inherited form the “second” parent. Thus a possible genotype of the offspring of parents with genotypes i, i′ is 〈\niJ , i ′ −J\n〉\n.\nLemma 2. Let W be any fitness landscape, then under the SR dynamics,\nxt+1ij = 1\nwt\n∑\ni−j∈I(−j)\nptij ,i−jwij ,i−j .\nProof. Let J∗ = J ∪ {j}, −J∗ = K \\ (J ∪ {j}).\nxt+1ij = ∑\ni−j∈I(−j)\npt+1ij ,i−j (By definition)\n= ∑\ni−j∈I(−j)\n(r ∑\ni′ K ∈I(K)\n1\n2k\n∑\nJ⊆K\n1\n(wt)2 pt iJ ,i ′ −J wiJ ,i′−Jp t i′ J ,i−J wi′ J ,i−J\n+ (1− r) ptij ,i−jwij ,i−j\nwt ) (By Eq. (8))\n=r 1\n2k\n∑\nJ⊆K\n∑\ni−j∈I(−j)\n∑\ni′ J ∈I(J)\ni ′ −J∈I(−J)\n1\n(wt)2 pt iJ ,i ′ −J wiJ ,i′−Jp t i′ J ,i−J wi′ J ,i−J\n+ (1− r) ∑\ni−j∈I(−j)\nptij ,i−jwij ,i−j\nwt\n=rC + (1− r)D\nWe first analyze part C:\nC = 1\n2k(wt)2\n∑\nJ⊆−{j}\n∑\niJ∈I(J) i −J∗∈I(−J ∗)\n∑\ni ′ J∈I(J) i′ −J ∈I(−J)\npt iJ ,i ′ −J wiJ ,i′−Jp t i′ J ,i−J wi′ J ,i−J .\n+ ∑\nJ⊆−{j}\n∑\niJ∈I(J) i −J∗∈I(−J ∗)\n∑\ni ′ J∗ ∈I(J∗)\ni ′ −J∗ ∈I(−J∗)\npt iJ∗ ,i ′ −J∗ wiJ∗ ,i′−J∗ pt i′ J∗ ,i −J∗ wi′ J∗ ,i −J∗\n= 1\n2k(wt)2\n∑\nJ⊆−{j}\n\n\n∑\ni −J∗∈I(−J ∗)\n∑\ni′ J ∈I(J)\npt i′ J ,i−J wi′ J ,i−J\n∑\niJ∈I(J)\n∑\ni′ −J ∈I(−J)\npt iJ ,i ′ −J wiJ ,i′−J\n+ ∑\niJ∈I(J)\n∑\ni′ −J∗ ∈I(−J∗)\npt iJ∗ ,i ′ −J∗ wiJ∗ ,i′−J∗\n∑\ni′ J∗ ∈I(J∗)\n∑\ni −J∗∈I(−J ∗)\npt i′ J∗ ,i −J∗ wi′ J∗ ,i −J∗\n\n\n= 1\n2k(wt)2\n∑\nJ⊆−{j}\n\n\n∑\ni −J∗∈I(−J∗)\n∑\ni′ J ∈I(J)\npt i′ J ,i−J wi′ J ,i−J\n∑\ni′′ K ∈I(K)\npt i′′ K wi′′ K\n+ ∑\niJ∈I(J)\n∑\ni′ −J∗ ∈I(−J∗)\npt iJ∗ ,i ′ −J∗ wiJ∗ ,i′−J∗\n∑\ni′′ K ∈I(K)\npt i′′ K wi′′ K\n\n\n= 1\n2k(wt)2\n∑\nJ⊆−{j}\n\n\n∑\ni −J∗∈I(−J ∗)\n∑\ni′ J ∈I(J)\npt i′ J ,i−J wi′ J ,i−Jw t\n+ ∑\niJ∈I(J)\n∑\ni′ −J∗ ∈I(−J∗)\npt iJ∗ ,i ′ −J∗ wiJ∗ ,i′−J∗ wt\n\n (By Eq. (5))\n= 1 wt 1 2k ∑\nJ⊆−{j}\n\n\n∑\ni−j∈I(−j)\nptij ,i−jwij ,i−j + ∑\ni−j∈I(−j)\nptij ,i−jwij ,i−j\n\n\n= 1\nwt\n∑\ni−j∈I(−j)\nptij ,i−jwij ,i−j 1\n2k−1\n∑\nJ⊆−{j}\n1\n= 1\nwt\n∑\ni−j∈I(−j)\nptij ,i−jwij ,i−j .\nFinally,\nxt+1ij = rC + (1− r)D = r 1\nwt\n∑\ni−j∈I(−j)\nptij ,i−jwij ,i−j + (1− r) ∑\ni−j∈I(−j)\nptij ,i−jwij ,i−j\nwt\n= 1\nwt\n∑\ni−j∈I(−j)\nptij ,i−jwij ,i−j .\nAs in the case of two loci, we use the lemma to show that under the SR dynamics, the marginal distribution of gene j ∈ K develops as if gene j is applying the PW algorithm.\nGiven a game G and a joint distribution P t, let gt ij = ∑\ni−j∈I(−j) P t(i−j |ij)gij ,i−j . That is, the expected utility to j of using the\npure action aij at time t.\nProposition 3. Let W be any fitness matrix, and consider the game G = W . Then under the SR population dynamics, for any distribution P t and any r ∈ [0, 1], we have\nxt+1ij = 1 wt xtijg t i . (9)\nProof. Applying Lemma 2,\nxt+1ij = 1\nwt\n∑\ni−j∈I(−j)\nptij ,i−jP t(i−j |ij)wij ,i−j =\n1\nwt\n∑\ni−j∈I(−j)\nxtijwij ,i−j\n= 1\nwt xtij\n∑\ni−j∈I(−j)\nP t(i−j |ij)wij ,i−j = 1\nwt xtijg t ij . (By Eq. (6))\nThe multi-dimensional extension of Corollary 1 follows in the same way from Proposition 3."
    }, {
      "heading" : "B PW and product distributions",
      "text" : "Consider the “uncorrelated” version of the PW algorithm, which is the one used in [Chastain et al., 2014]:\nxt+1i = x t i\n∑\nj\nytjwij = x t ig t i. (10)\nIn [Chastain et al., 2014] there is no distinction between RS and SR. The formal definition that they use coincides with RS (p. 1 of the SI text), whereas in an earlier draft they used SR (p.5 in [Chastain et al., 2013]). In a private communication the authors clarified that they use SR and RS interchangeably, since under weak selection they are very close.\nDivergence from the Wright manifold Chastain et al. [2014] justify the assumption that P t is a product distribution by quoting the result of Nagylaki [1993], which states for any process (P t)t there is a “corresponding process” on the Wright manifold, which converges to the same point. However the authors do not explain why this corresponding process is the one they assume in their paper. To further stress this point, we will show that the population dynamics and the PW algorithm used in [Chastain et al., 2014] can significantly differ (we saw empirically that the marginals also differ significantly).\nConsider the 2 × 2 fitness matrix where w11 = 1 + s, and wij = 1 otherwise. For simplicity assume first that r = 0 (thus SR and RS are the same). Suppose that P 0 is the uniform distribution (that is on the Wright manifold). While the population dynamics will eventually converge to p11 = 1, there is some t s.t. P t\nis approximately\n(\n5/8 1/8 1/8 1/8\n)\n. Thus ∥ ∥P t − xt × yt ∥ ∥ d > 18 = Ω(1) for any\nℓd norm and regardless of the selection strength s. The gap is still large for other small constant values of r (including when s ≪ r). Thus the population dynamics can get very far from the Wright manifold.\nIn the example above both processes will converge to the same outcome (p11 = 1), but at different rates.\nDifference in convergence One can also construct examples that converge to different outcomes. For example, for s = 0.01 consider W = (\n1.01 1 1 1.0099603\n)\n. If the initial distribution is x0 = yt = (0.499, 0.501),\nthen the (independent) PW dynamics converges to p22 = 1, whereas for r = 0.5 the SR dynamics converges to p11 = 1. Such examples can be constructed for any values of s > 0 and r < 1."
    } ],
    "references" : [ {
      "title" : "Hopf bifurcation in the two locus genetic model, volume 284",
      "author" : [ "Ethan Akin" ],
      "venue" : "American Mathematical Soc.,",
      "citeRegEx" : "Akin.,? \\Q1983\\E",
      "shortCiteRegEx" : "Akin.",
      "year" : 1983
    }, {
      "title" : "Learning, regret minimization, and equilibria",
      "author" : [ "Avrim Blum", "Yishay Mansour" ],
      "venue" : null,
      "citeRegEx" : "Blum and Mansour.,? \\Q2007\\E",
      "shortCiteRegEx" : "Blum and Mansour.",
      "year" : 2007
    }, {
      "title" : "Learning through reinforcement and replicator dynamics",
      "author" : [ "Tilman Börgers", "Rajiv Sarin" ],
      "venue" : "Journal of Economic Theory,",
      "citeRegEx" : "Börgers and Sarin.,? \\Q1997\\E",
      "shortCiteRegEx" : "Börgers and Sarin.",
      "year" : 1997
    }, {
      "title" : "Some mathematical models in evolutionary genetics",
      "author" : [ "Reinhard Bürger" ],
      "venue" : "In The Mathematics of Darwin’s Legacy,",
      "citeRegEx" : "Bürger.,? \\Q2011\\E",
      "shortCiteRegEx" : "Bürger.",
      "year" : 2011
    }, {
      "title" : "How to use expert advice",
      "author" : [ "Nicolo Cesa-Bianchi", "Yoav Freund", "David Haussler", "David P Helmbold", "Robert E Schapire", "Manfred K Warmuth" ],
      "venue" : "Journal of the ACM (JACM),",
      "citeRegEx" : "Cesa.Bianchi et al\\.,? \\Q1997\\E",
      "shortCiteRegEx" : "Cesa.Bianchi et al\\.",
      "year" : 1997
    }, {
      "title" : "Improved second-order bounds for prediction with expert advice",
      "author" : [ "Nicolo Cesa-Bianchi", "Yishay Mansour", "Gilles Stoltz" ],
      "venue" : "Machine Learning,",
      "citeRegEx" : "Cesa.Bianchi et al\\.,? \\Q2007\\E",
      "shortCiteRegEx" : "Cesa.Bianchi et al\\.",
      "year" : 2007
    }, {
      "title" : "The application of evolution process in multi-agent world to the prediction system",
      "author" : [ "Krzysztof Cetnarowicz", "Marek Kisiel-Dorohinicki", "Edward Nawarecki" ],
      "venue" : "In Proceedings of the Second International Conference on Multi-Agent Systems, ICMAS,",
      "citeRegEx" : "Cetnarowicz et al\\.,? \\Q1996\\E",
      "shortCiteRegEx" : "Cetnarowicz et al\\.",
      "year" : 1996
    }, {
      "title" : "Multiplicative updates in coordination games and the theory of evolution",
      "author" : [ "Erick Chastain", "Adi Livnat", "Christos Papadimitriou", "Umesh Vazirani" ],
      "venue" : "In Proceedings of the 4th conference on Innovations in Theoretical Computer Science,",
      "citeRegEx" : "Chastain et al\\.,? \\Q2013\\E",
      "shortCiteRegEx" : "Chastain et al\\.",
      "year" : 2013
    }, {
      "title" : "Algorithms, games, and evolution",
      "author" : [ "Erick Chastain", "Adi Livnat", "Christos Papadimitriou", "Umesh Vazirani" ],
      "venue" : "Proceedings of the National Academy of Sciences,",
      "citeRegEx" : "Chastain et al\\.,? \\Q2014\\E",
      "shortCiteRegEx" : "Chastain et al\\.",
      "year" : 2014
    }, {
      "title" : "The selfish gene",
      "author" : [ "Richard Dawkins" ],
      "venue" : "Number 199. Oxford university press,",
      "citeRegEx" : "Dawkins.,? \\Q2006\\E",
      "shortCiteRegEx" : "Dawkins.",
      "year" : 2006
    }, {
      "title" : "On the convergence of regret minimization dynamics in concave games",
      "author" : [ "Eyal Even-Dar", "Yishay Mansour", "Uri Nadav" ],
      "venue" : "In Proceedings of the forty-first annual ACM symposium on Theory of computing,",
      "citeRegEx" : "Even.Dar et al\\.,? \\Q2009\\E",
      "shortCiteRegEx" : "Even.Dar et al\\.",
      "year" : 2009
    }, {
      "title" : "The Genetical Theory of Natural Selection",
      "author" : [ "R.A. Fisher" ],
      "venue" : null,
      "citeRegEx" : "Fisher.,? \\Q1930\\E",
      "shortCiteRegEx" : "Fisher.",
      "year" : 1930
    }, {
      "title" : "A desicion-theoretic generalization of online learning and an application to boosting",
      "author" : [ "Yoav Freund", "Robert E Schapire" ],
      "venue" : "In Computational learning theory,",
      "citeRegEx" : "Freund and Schapire.,? \\Q1995\\E",
      "shortCiteRegEx" : "Freund and Schapire.",
      "year" : 1995
    }, {
      "title" : "Adaptive game playing using multiplicative weights",
      "author" : [ "Yoav Freund", "Robert E Schapire" ],
      "venue" : "Games and Economic Behavior,",
      "citeRegEx" : "Freund and Schapire.,? \\Q1999\\E",
      "shortCiteRegEx" : "Freund and Schapire.",
      "year" : 1999
    }, {
      "title" : "Genetic algorithms and machine learning",
      "author" : [ "David E Goldberg", "John H Holland" ],
      "venue" : "Machine learning,",
      "citeRegEx" : "Goldberg and Holland.,? \\Q1988\\E",
      "shortCiteRegEx" : "Goldberg and Holland.",
      "year" : 1988
    }, {
      "title" : "Game theory and evolution",
      "author" : [ "John Haigh" ],
      "venue" : "Advances in Applied Probability,",
      "citeRegEx" : "Haigh.,? \\Q1975\\E",
      "shortCiteRegEx" : "Haigh.",
      "year" : 1975
    }, {
      "title" : "Stable cycling in discrete-time genetic models",
      "author" : [ "Alan Hastings" ],
      "venue" : "Proceedings of the National Academy of Sciences,",
      "citeRegEx" : "Hastings.,? \\Q1981\\E",
      "shortCiteRegEx" : "Hastings.",
      "year" : 1981
    }, {
      "title" : "A Hopf bifurcation theorem for difference equations approximating a differential equation",
      "author" : [ "J Hofbauer", "G Iooss" ],
      "venue" : "Monatshefte für Mathematik,",
      "citeRegEx" : "Hofbauer and Iooss.,? \\Q1984\\E",
      "shortCiteRegEx" : "Hofbauer and Iooss.",
      "year" : 1984
    }, {
      "title" : "Learning, matching, and aggregation",
      "author" : [ "Ed Hopkins" ],
      "venue" : "Games and Economic Behavior,",
      "citeRegEx" : "Hopkins.,? \\Q1999\\E",
      "shortCiteRegEx" : "Hopkins.",
      "year" : 1999
    }, {
      "title" : "On no-regret learning, Fictitious play, and Nash equilibrium",
      "author" : [ "Amir Jafari", "Amy Greenwald", "David Gondek", "Gunes Ercal" ],
      "venue" : "In ICML,",
      "citeRegEx" : "Jafari et al\\.,? \\Q2001\\E",
      "shortCiteRegEx" : "Jafari et al\\.",
      "year" : 2001
    }, {
      "title" : "Efficient algorithms using the multiplicative weights update method",
      "author" : [ "Satyen Kale" ],
      "venue" : "PhD thesis, Princeton University,",
      "citeRegEx" : "Kale.,? \\Q2007\\E",
      "shortCiteRegEx" : "Kale.",
      "year" : 2007
    }, {
      "title" : "Multiplicative updates outperform generic no-regret learning in congestion games",
      "author" : [ "Robert Kleinberg", "Georgios Piliouras", "Eva Tardos" ],
      "venue" : "In Proceedings of the 41st annual ACM symposium on Theory of computing,",
      "citeRegEx" : "Kleinberg et al\\.,? \\Q2009\\E",
      "shortCiteRegEx" : "Kleinberg et al\\.",
      "year" : 2009
    }, {
      "title" : "Increment of average fitness for multiple alleles",
      "author" : [ "CC Li" ],
      "venue" : "Proceedings of the National Academy of Sciences,",
      "citeRegEx" : "Li.,? \\Q1969\\E",
      "shortCiteRegEx" : "Li.",
      "year" : 1969
    }, {
      "title" : "The weighted majority algorithm",
      "author" : [ "Nick Littlestone", "Manfred K Warmuth" ],
      "venue" : "Information and computation,",
      "citeRegEx" : "Littlestone and Warmuth.,? \\Q1994\\E",
      "shortCiteRegEx" : "Littlestone and Warmuth.",
      "year" : 1994
    }, {
      "title" : "Payoffbased dynamics for multiplayer weakly acyclic games",
      "author" : [ "Jason R Marden", "H Peyton Young", "Gürdal Arslan", "Jeff S Shamma" ],
      "venue" : "SIAM Journal on Control and Optimization,",
      "citeRegEx" : "Marden et al\\.,? \\Q2009\\E",
      "shortCiteRegEx" : "Marden et al\\.",
      "year" : 2009
    }, {
      "title" : "Interaction of selection and recombination in the fixation of negative-epistatic genes",
      "author" : [ "Yannis Michalakis", "Montgomery Slatkin" ],
      "venue" : "Genetical research,",
      "citeRegEx" : "Michalakis and Slatkin.,? \\Q1996\\E",
      "shortCiteRegEx" : "Michalakis and Slatkin.",
      "year" : 1996
    }, {
      "title" : "An inequality arising in genetical theory",
      "author" : [ "H.P. Mulholland", "C.A.B. Smith" ],
      "venue" : "Am. Math. Monthly,",
      "citeRegEx" : "Mulholland and Smith.,? \\Q1959\\E",
      "shortCiteRegEx" : "Mulholland and Smith.",
      "year" : 1959
    }, {
      "title" : "Brunovskỳ. Convergence of multilocus systems under weak epistasis or weak selection",
      "author" : [ "Thomas Nagylaki", "Josef Hofbauer", "Pavol" ],
      "venue" : "Journal of mathematical biology,",
      "citeRegEx" : "Nagylaki et al\\.,? \\Q1999\\E",
      "shortCiteRegEx" : "Nagylaki et al\\.",
      "year" : 1999
    }, {
      "title" : "The evolution of multilocus systems under weak selection",
      "author" : [ "Thomas Nagylaki" ],
      "venue" : "Genetics, 134(2):627–647,",
      "citeRegEx" : "Nagylaki.,? \\Q1993\\E",
      "shortCiteRegEx" : "Nagylaki.",
      "year" : 1993
    }, {
      "title" : "Newcomb’s paradox and two principles of choice",
      "author" : [ "R Nozick" ],
      "venue" : "Essays in Honor of Carl G. Hempel, D. Reidel, Dordrecht,",
      "citeRegEx" : "Nozick.,? \\Q1969\\E",
      "shortCiteRegEx" : "Nozick.",
      "year" : 1969
    }, {
      "title" : "Auctions, evolution, and multi-agent learning",
      "author" : [ "Steve Phelps", "Kai Cai", "Peter McBurney", "Jinzhong Niu", "Simon Parsons", "Elizabeth Sklar" ],
      "venue" : "In Adaptive Agents and Multi-Agent Systems III. Adaptation and Multi-Agent Learning,",
      "citeRegEx" : "Phelps et al\\.,? \\Q2008\\E",
      "shortCiteRegEx" : "Phelps et al\\.",
      "year" : 2008
    } ],
    "referenceMentions" : [ {
      "referenceID" : 8,
      "context" : "on the role of sex in evolution [Chastain et al., 2014].",
      "startOffset" : 32,
      "endOffset" : 55
    }, {
      "referenceID" : 7,
      "context" : "” —Graham Bell, 1982 Abstract We consider a recent innovative theory by Chastain et al. on the role of sex in evolution [Chastain et al., 2014]. In short, the theory suggests that the evolutionary process of gene recombination implements the celebrated multiplicative weights updates algorithm (MWUA). They prove that the population dynamics induced by sexual reproduction can be precisely modeled by genes that use MWUA as their learning strategy in a particular coordination game. The result holds in the environments of weak selection, under the assumption that the population frequencies remain a product distribution. We revisit the theory, eliminating both the requirement of weak selection and any assumption on the distribution of the population. Removing the assumption of product distributions is crucial, since as we show, this assumption is inconsistent with the population dynamics. We show that the marginal allele distributions induced by the population dynamics precisely match the marginals induced by a multiplicative weights update algorithm in this general setting, thereby affirming and substantially generalizing these earlier results. We further revise the implications for convergence and utility or fitness guarantees in coordination games. In contrast to the claim of Chastain et al. [2014], we conclude that the sexual evolutionary dynamics does not entail any property of the population distribution, beyond those already implied by convergence.",
      "startOffset" : 72,
      "endOffset" : 1317
    }, {
      "referenceID" : 14,
      "context" : "Evolutionary models inspired a range of applications from genetic algorithms to the design of distributed multiagent systems [Goldberg and Holland, 1988; Cetnarowicz et al., 1996; Phelps et al., 2008].",
      "startOffset" : 125,
      "endOffset" : 200
    }, {
      "referenceID" : 6,
      "context" : "Evolutionary models inspired a range of applications from genetic algorithms to the design of distributed multiagent systems [Goldberg and Holland, 1988; Cetnarowicz et al., 1996; Phelps et al., 2008].",
      "startOffset" : 125,
      "endOffset" : 200
    }, {
      "referenceID" : 30,
      "context" : "Evolutionary models inspired a range of applications from genetic algorithms to the design of distributed multiagent systems [Goldberg and Holland, 1988; Cetnarowicz et al., 1996; Phelps et al., 2008].",
      "startOffset" : 125,
      "endOffset" : 200
    }, {
      "referenceID" : 15,
      "context" : "Within game theory, several solution concepts follow evolutionary processes, and some of the most promising dynamics that lead to equilibria in games assume that players learn the behavior of their opponents [Haigh, 1975; Valiant, 2009].",
      "startOffset" : 208,
      "endOffset" : 236
    }, {
      "referenceID" : 23,
      "context" : "[2014] provide a correspondence between the sexual population dynamics and the multiplicative weights update algorithm (MWUA) [Littlestone and Warmuth, 1994; Cesa-Bianchi et al., 1997].",
      "startOffset" : 126,
      "endOffset" : 184
    }, {
      "referenceID" : 4,
      "context" : "[2014] provide a correspondence between the sexual population dynamics and the multiplicative weights update algorithm (MWUA) [Littlestone and Warmuth, 1994; Cesa-Bianchi et al., 1997].",
      "startOffset" : 126,
      "endOffset" : 184
    }, {
      "referenceID" : 4,
      "context" : "Evolutionary models inspired a range of applications from genetic algorithms to the design of distributed multiagent systems [Goldberg and Holland, 1988; Cetnarowicz et al., 1996; Phelps et al., 2008]. Within game theory, several solution concepts follow evolutionary processes, and some of the most promising dynamics that lead to equilibria in games assume that players learn the behavior of their opponents [Haigh, 1975; Valiant, 2009]. A different connection between sex, evolution and machine learning was recently suggested by Chastain, Livnat, Papadimitriou and Vazirani [2014]. As they explain, also referring to Barton and Charlesworth [1998], sexual reproduction is costly for the individual and for the society in terms of time and energy, and often breaks successful gene combinations.",
      "startOffset" : 154,
      "endOffset" : 585
    }, {
      "referenceID" : 4,
      "context" : "Evolutionary models inspired a range of applications from genetic algorithms to the design of distributed multiagent systems [Goldberg and Holland, 1988; Cetnarowicz et al., 1996; Phelps et al., 2008]. Within game theory, several solution concepts follow evolutionary processes, and some of the most promising dynamics that lead to equilibria in games assume that players learn the behavior of their opponents [Haigh, 1975; Valiant, 2009]. A different connection between sex, evolution and machine learning was recently suggested by Chastain, Livnat, Papadimitriou and Vazirani [2014]. As they explain, also referring to Barton and Charlesworth [1998], sexual reproduction is costly for the individual and for the society in terms of time and energy, and often breaks successful gene combinations.",
      "startOffset" : 154,
      "endOffset" : 652
    }, {
      "referenceID" : 4,
      "context" : "Evolutionary models inspired a range of applications from genetic algorithms to the design of distributed multiagent systems [Goldberg and Holland, 1988; Cetnarowicz et al., 1996; Phelps et al., 2008]. Within game theory, several solution concepts follow evolutionary processes, and some of the most promising dynamics that lead to equilibria in games assume that players learn the behavior of their opponents [Haigh, 1975; Valiant, 2009]. A different connection between sex, evolution and machine learning was recently suggested by Chastain, Livnat, Papadimitriou and Vazirani [2014]. As they explain, also referring to Barton and Charlesworth [1998], sexual reproduction is costly for the individual and for the society in terms of time and energy, and often breaks successful gene combinations. From the perspective of an individual, sex dilutes his or her genes by only transferring half of them to each offspring. Thus the question that arises is why sexual reproduction is so common in nature, and why is it so successful. Chastain et al. [2014] suggest that the evolutionary process under sexual reproduction effectively implements a celebrated no-regret learning algorithm.",
      "startOffset" : 154,
      "endOffset" : 1052
    }, {
      "referenceID" : 4,
      "context" : "Evolutionary models inspired a range of applications from genetic algorithms to the design of distributed multiagent systems [Goldberg and Holland, 1988; Cetnarowicz et al., 1996; Phelps et al., 2008]. Within game theory, several solution concepts follow evolutionary processes, and some of the most promising dynamics that lead to equilibria in games assume that players learn the behavior of their opponents [Haigh, 1975; Valiant, 2009]. A different connection between sex, evolution and machine learning was recently suggested by Chastain, Livnat, Papadimitriou and Vazirani [2014]. As they explain, also referring to Barton and Charlesworth [1998], sexual reproduction is costly for the individual and for the society in terms of time and energy, and often breaks successful gene combinations. From the perspective of an individual, sex dilutes his or her genes by only transferring half of them to each offspring. Thus the question that arises is why sexual reproduction is so common in nature, and why is it so successful. Chastain et al. [2014] suggest that the evolutionary process under sexual reproduction effectively implements a celebrated no-regret learning algorithm. The structure of their argument is as follows. First, they restrict attention to a particular class of fitness landscape where weak selection holds. Informally, weak selection means that the fitness difference between genotypes is bounded by a small constant, i.e., there are no extremely good or extremely bad gene combinations.1 Second, they consider the distribution of each gene’s alleles as a mixed strategy in a matrix-form game, where there is one player for each gene. The game is an identical interest game, where each player gets the same utility— thus the joint distribution of alleles corresponds to the mixed strategy of each player, and the expected payoff of the game corresponds to the average fitness level of the population. Chastain et al. [2014] provide a correspondence between the sexual population dynamics and the multiplicative weights update algorithm (MWUA) [Littlestone and Warmuth, 1994; Cesa-Bianchi et al.",
      "startOffset" : 154,
      "endOffset" : 1948
    }, {
      "referenceID" : 9,
      "context" : "Interestingly, the agents in this model are not the creatures in the population, nor Dawkins’ [Dawkins, 2006] genetic properties (alleles) that compete one another, but rather genes that share a mutual cause.",
      "startOffset" : 94,
      "endOffset" : 109
    }, {
      "referenceID" : 7,
      "context" : "1 Our Contribution We show that the main results of Chastain et al. [2014] can be substantially generalized.",
      "startOffset" : 52,
      "endOffset" : 75
    }, {
      "referenceID" : 7,
      "context" : "1 Our Contribution We show that the main results of Chastain et al. [2014] can be substantially generalized. Specifically, we consider the two standard population dynamics (where recombination acts before selection (RS), and vice versa (SR)), and show that each of them precisely describes the marginal allele distribution under a variation of the multiplicative updates algorithm that is described for correlated strategies. This correspondence holds for any number of genes/players, any fitness matrix, any recombination rate, and any initial population frequencies. In particular, and in contrast to Chastain et al., we do not assume weak selection or require the population distribution remains a product distribution (i.e., with allele probabilities that are independent), and we allow both the SR model and the RS model. We discuss some of the implications of this correspondence between these biological and algorithmic processes for theoretical convergence properties. Under weak selection, the observation that the cumulative regret of every gene is bounded follows immediately from known convergence results, both in population dynamics and in game theory (see related work). We show that under the SR dynamics, every gene still has a bounded cumulative regret, without assuming weak selection or a product distribution. Our analysis also uncovers what we view as one technical gap and one conceptual gap regarding the fine details in the original argument of Chastain et al. [2014]. We believe that due to the far reaching consequences of the theory it is important to rectify these details.",
      "startOffset" : 52,
      "endOffset" : 1493
    }, {
      "referenceID" : 19,
      "context" : "In general games, the MWUA dynamic is known to lead to diminishing regret over time [Jafari et al., 2001; Blum and Mansour, 2007; Kale, 2007; Cesa-Bianchi et al., 2007], but does not, in general, converge to a Nash equilibrium of the game.",
      "startOffset" : 84,
      "endOffset" : 168
    }, {
      "referenceID" : 1,
      "context" : "In general games, the MWUA dynamic is known to lead to diminishing regret over time [Jafari et al., 2001; Blum and Mansour, 2007; Kale, 2007; Cesa-Bianchi et al., 2007], but does not, in general, converge to a Nash equilibrium of the game.",
      "startOffset" : 84,
      "endOffset" : 168
    }, {
      "referenceID" : 20,
      "context" : "In general games, the MWUA dynamic is known to lead to diminishing regret over time [Jafari et al., 2001; Blum and Mansour, 2007; Kale, 2007; Cesa-Bianchi et al., 2007], but does not, in general, converge to a Nash equilibrium of the game.",
      "startOffset" : 84,
      "endOffset" : 168
    }, {
      "referenceID" : 5,
      "context" : "In general games, the MWUA dynamic is known to lead to diminishing regret over time [Jafari et al., 2001; Blum and Mansour, 2007; Kale, 2007; Cesa-Bianchi et al., 2007], but does not, in general, converge to a Nash equilibrium of the game.",
      "startOffset" : 84,
      "endOffset" : 168
    }, {
      "referenceID" : 26,
      "context" : "The fundamental theorem of natural selection, which dates back to Fisher [1930], states that the population dynamics of a single-locus diploid always increases the average fitness of each generation, until it reaches convergence [Mulholland and Smith, 1959; Li, 1969].",
      "startOffset" : 229,
      "endOffset" : 267
    }, {
      "referenceID" : 22,
      "context" : "The fundamental theorem of natural selection, which dates back to Fisher [1930], states that the population dynamics of a single-locus diploid always increases the average fitness of each generation, until it reaches convergence [Mulholland and Smith, 1959; Li, 1969].",
      "startOffset" : 229,
      "endOffset" : 267
    }, {
      "referenceID" : 16,
      "context" : "In the general case, for genotypes with more than a single locus, the fundamental theorem does not hold, although constructing a counter example where a cycle occurs is non-trivial [Hastings, 1981; Hofbauer and Iooss, 1984].",
      "startOffset" : 181,
      "endOffset" : 223
    }, {
      "referenceID" : 17,
      "context" : "In the general case, for genotypes with more than a single locus, the fundamental theorem does not hold, although constructing a counter example where a cycle occurs is non-trivial [Hastings, 1981; Hofbauer and Iooss, 1984].",
      "startOffset" : 181,
      "endOffset" : 223
    }, {
      "referenceID" : 27,
      "context" : "However, convergence of the population dynamics has been shown to hold when the fitness landscape has some specific properties, such as weak selection, or weak epistasis [Nagylaki et al., 1999].",
      "startOffset" : 170,
      "endOffset" : 193
    }, {
      "referenceID" : 2,
      "context" : "Regardless of the number of loci, asexual dynamics coincides with MWUA by a single player [Börgers and Sarin, 1997; Hopkins, 1999].",
      "startOffset" : 90,
      "endOffset" : 130
    }, {
      "referenceID" : 18,
      "context" : "Regardless of the number of loci, asexual dynamics coincides with MWUA by a single player [Börgers and Sarin, 1997; Hopkins, 1999].",
      "startOffset" : 90,
      "endOffset" : 130
    }, {
      "referenceID" : 1,
      "context" : ", 2001; Blum and Mansour, 2007; Kale, 2007; Cesa-Bianchi et al., 2007], but does not, in general, converge to a Nash equilibrium of the game. For some classes of games better convergence results are known; see Section 5.2 for details. The fundamental theorem of natural selection, which dates back to Fisher [1930], states that the population dynamics of a single-locus diploid always increases the average fitness of each generation, until it reaches convergence [Mulholland and Smith, 1959; Li, 1969].",
      "startOffset" : 8,
      "endOffset" : 315
    }, {
      "referenceID" : 1,
      "context" : ", 2001; Blum and Mansour, 2007; Kale, 2007; Cesa-Bianchi et al., 2007], but does not, in general, converge to a Nash equilibrium of the game. For some classes of games better convergence results are known; see Section 5.2 for details. The fundamental theorem of natural selection, which dates back to Fisher [1930], states that the population dynamics of a single-locus diploid always increases the average fitness of each generation, until it reaches convergence [Mulholland and Smith, 1959; Li, 1969].2 The fundamental theorem further relates the rate of increase to the variance of fitness in the population. In the general case, for genotypes with more than a single locus, the fundamental theorem does not hold, although constructing a counter example where a cycle occurs is non-trivial [Hastings, 1981; Hofbauer and Iooss, 1984]. However, convergence of the population dynamics has been shown to hold when the fitness landscape has some specific properties, such as weak selection, or weak epistasis [Nagylaki et al., 1999].3 In asexual evolutionary dynamics, every descendent is an exact copy of a single parent, with more fit parents producing more offspring (“survival of the fittest”). Regardless of the number of loci, asexual dynamics coincides with MWUA by a single player [Börgers and Sarin, 1997; Hopkins, 1999]. Chastain et al. [2014] were the first to suggest that a similar correspondence can be established for sexual population dynamics.",
      "startOffset" : 8,
      "endOffset" : 1352
    }, {
      "referenceID" : 6,
      "context" : "2 Definitions We follow the definitions of Chastain et al. [2014] where possible.",
      "startOffset" : 43,
      "endOffset" : 66
    }, {
      "referenceID" : 3,
      "context" : "For more detailed explanation of the biological terms and equations, see Bürger [2011]. Roughly, a single-locus means there is only one property that determines fitness, for example eye color or length of tail.",
      "startOffset" : 73,
      "endOffset" : 87
    }, {
      "referenceID" : 25,
      "context" : ", [Michalakis and Slatkin, 1996]).",
      "startOffset" : 2,
      "endOffset" : 32
    }, {
      "referenceID" : 1,
      "context" : "Many variations of the multiplicative weights update algorithm (MWUA) are built upon this idea, and some have been applied to strategic settings [Blum and Mansour, 2007; Marden et al., 2009; Kleinberg et al., 2009].",
      "startOffset" : 145,
      "endOffset" : 214
    }, {
      "referenceID" : 24,
      "context" : "Many variations of the multiplicative weights update algorithm (MWUA) are built upon this idea, and some have been applied to strategic settings [Blum and Mansour, 2007; Marden et al., 2009; Kleinberg et al., 2009].",
      "startOffset" : 145,
      "endOffset" : 214
    }, {
      "referenceID" : 21,
      "context" : "Many variations of the multiplicative weights update algorithm (MWUA) are built upon this idea, and some have been applied to strategic settings [Blum and Mansour, 2007; Marden et al., 2009; Kleinberg et al., 2009].",
      "startOffset" : 145,
      "endOffset" : 214
    }, {
      "referenceID" : 1,
      "context" : "Many variations of the multiplicative weights update algorithm (MWUA) are built upon this idea, and some have been applied to strategic settings [Blum and Mansour, 2007; Marden et al., 2009; Kleinberg et al., 2009]. We follow the variation used by Chastain et al. [2014]. This variation is equivalent to the Polynomial Weights (PW) algorithm [2007], under the assumption that the utility of all actions (ai)i≤n is observed after each period (see Kale [2007], p.",
      "startOffset" : 146,
      "endOffset" : 271
    }, {
      "referenceID" : 1,
      "context" : "Many variations of the multiplicative weights update algorithm (MWUA) are built upon this idea, and some have been applied to strategic settings [Blum and Mansour, 2007; Marden et al., 2009; Kleinberg et al., 2009]. We follow the variation used by Chastain et al. [2014]. This variation is equivalent to the Polynomial Weights (PW) algorithm [2007], under the assumption that the utility of all actions (ai)i≤n is observed after each period (see Kale [2007], p.",
      "startOffset" : 146,
      "endOffset" : 349
    }, {
      "referenceID" : 1,
      "context" : "Many variations of the multiplicative weights update algorithm (MWUA) are built upon this idea, and some have been applied to strategic settings [Blum and Mansour, 2007; Marden et al., 2009; Kleinberg et al., 2009]. We follow the variation used by Chastain et al. [2014]. This variation is equivalent to the Polynomial Weights (PW) algorithm [2007], under the assumption that the utility of all actions (ai)i≤n is observed after each period (see Kale [2007], p.",
      "startOffset" : 146,
      "endOffset" : 458
    }, {
      "referenceID" : 29,
      "context" : "5 Clearly, when P t is a We can also think of the two approaches as the two sides of Newcomb’s paradox [Nozick, 1969]: the player observes a correlation, even though deciding on a strategy cannot change the expected utility of each action.",
      "startOffset" : 103,
      "endOffset" : 117
    }, {
      "referenceID" : 18,
      "context" : ", in Kale [2007], Sec.",
      "startOffset" : 5,
      "endOffset" : 17
    }, {
      "referenceID" : 7,
      "context" : "This definition results in the PW algorithm used in Chastain et al. [2014]. The above definitions require some discussion.",
      "startOffset" : 52,
      "endOffset" : 75
    }, {
      "referenceID" : 7,
      "context" : "product distribution (as in Chastain et al. [2014]) then gi = g t i , and the algorithms coincide.",
      "startOffset" : 28,
      "endOffset" : 51
    }, {
      "referenceID" : 7,
      "context" : "product distribution (as in Chastain et al. [2014]) then gi = g t i , and the algorithms coincide. We can also combine the two interpretations to induce new algorithms. We thus define the PW(α) algorithm (either Parameter-free PW(α) or ǫ-PW(α)), where the probability of playing ai is updated according to g t,(α) i = αg t i+(1−α)g t i . Exponential Weights The Hedge algorithm [Freund and Schapire, 1995, 1999] is another variation of MWUA that is very similar to PW. The difference is that the weight of action i in each step changes by a factor that is exponential in the utility, rather than linear. That is, xt+1(i) ∼= x(i)(1 + ǫ) t i . For negligible ǫ > 0, ǫ-Hedge and ǫ-PW are essentially the same, but for large ǫ they may behave quite differently. 3 Analysis of the SR dynamics In this section we prove that the SR population dynamics of marginal allele frequencies coincide precisely with the multiplicative updates dynamics in the corresponding game. This extends Theorem 4 in Chastain et al. [2014] (SI text), in that it holds without weak selection or the assumption of product distributions through multiple iterations.",
      "startOffset" : 28,
      "endOffset" : 1012
    }, {
      "referenceID" : 7,
      "context" : "Theorem 4 in Chastain et al. [2014] follows as a special case when P t is a product distribution.",
      "startOffset" : 13,
      "endOffset" : 36
    }, {
      "referenceID" : 7,
      "context" : "Theorem 4 in Chastain et al. [2014] follows as a special case when P t is a product distribution. By repeatedly applying Proposition 1, we get the following result, which holds for any value of r. Corollary 1. Let W be a fitness matrix, P 0 be any distribution. Suppose that P t+1 is attained from P t by the SR population dynamics, and that xt+1,yt+1 are attained from P t by players using the parameter-free PW(0) algorithm in the game G = W . Then for all t > 0 and any i, xi = ∑ j p t ij . It is important to note that the marginal distributions x,y do not determine P t completely. Thus the PW algorithm specifies the strategy of each player (regardless of r), but not how these strategies are correlated. 4 Analysis of the RS dynamics Turning to the RS population dynamics, our starting point is Lemma 3 in Chastain et al. [2014] (SI text), which states that p ij = 1 w wijx t iy t j (under the assumption that P t is a product distribution).",
      "startOffset" : 13,
      "endOffset" : 836
    }, {
      "referenceID" : 7,
      "context" : "We derive an alternative extension of Theorem 4 in Chastain et al. [2014] (SI text) for the RS dynamics.",
      "startOffset" : 51,
      "endOffset" : 74
    }, {
      "referenceID" : 20,
      "context" : "Theorem 3 [Kale, 2007] states that under the ǫ-PW algorithm6",
      "startOffset" : 10,
      "endOffset" : 22
    }, {
      "referenceID" : 7,
      "context" : "1 Diminishing regret In Chastain et al. [2014] (Sections 3 and 4 of the SI text), the authors apply standard properties of MWUA to show that the cumulative external regret of each gene is bounded (Corollary 5 there).",
      "startOffset" : 24,
      "endOffset" : 47
    }, {
      "referenceID" : 7,
      "context" : "By taking s to zero and T to infinity, we get that the average cumulative regret AF T SR − AF T i tends to zero, as stated in Chastain et al. [2014] (they use a more refined form of the inequality that contains the entropy of P t rather than lnn).",
      "startOffset" : 126,
      "endOffset" : 149
    }, {
      "referenceID" : 21,
      "context" : "For example, if all players in a potential game apply the ǫ-Hedge algorithm, with a sufficiently small ǫ, then P t converges to a Nash equilibrium [Kleinberg et al., 2009], and almost always to a pure Nash equilibrium.",
      "startOffset" : 147,
      "endOffset" : 171
    }, {
      "referenceID" : 10,
      "context" : "Similar results have been shown for concave games [Even-Dar et al., 2009].",
      "startOffset" : 50,
      "endOffset" : 73
    }, {
      "referenceID" : 1,
      "context" : "In our case we It is known that the average joint distribution over all iterations converges to the set of correlated equilibria [Blum and Mansour, 2007].",
      "startOffset" : 129,
      "endOffset" : 153
    }, {
      "referenceID" : 7,
      "context" : "Similar results have been shown for concave games [Even-Dar et al., 2009]. Since identical-interest games are both potential games and concave games, and since for small ǫ we have that Hedge and PW are essentially the same, these results apply to our setting. This means that under each of RS and SR dynamics, the population converges to a stable state, for a sufficiently low selection strength s. This implication is not new, and has been shown independently in the evolutionary biology literature. Indeed, Nagylaki et al. [1999] prove that under weak selection, the population dynamics converges to a point distribution from any initial state (that is, to a Nash equilibrium of the subgame induced by the support of the initial distribution).",
      "startOffset" : 51,
      "endOffset" : 532
    }, {
      "referenceID" : 6,
      "context" : "6 Discussion Chastain et al. [2014] extend an interesting connection between evolution, learning, and games from asexual reproduction (i.",
      "startOffset" : 13,
      "endOffset" : 36
    }, {
      "referenceID" : 6,
      "context" : "6 Discussion Chastain et al. [2014] extend an interesting connection between evolution, learning, and games from asexual reproduction (i.e., replicator dynamics) to sexual reproduction. The proof of Theorem 4 in Chastain et al. [2014] gives a formal meaning to this connection.",
      "startOffset" : 13,
      "endOffset" : 235
    }, {
      "referenceID" : 6,
      "context" : "6 Discussion Chastain et al. [2014] extend an interesting connection between evolution, learning, and games from asexual reproduction (i.e., replicator dynamics) to sexual reproduction. The proof of Theorem 4 in Chastain et al. [2014] gives a formal meaning to this connection. Namely, that the strategy update of each player who is using PW(1) in the fitness game, coincides with the change in allele frequencies of the corresponding gene (under weak selection and product distributions). This relation is generalized in our Propositions 1 and 2, since for product distributions PW(α) is the same for all α. Chastain et al. [2014] also claim something stronger: that the population dynamics is precisely the PW dynamics.",
      "startOffset" : 13,
      "endOffset" : 632
    }, {
      "referenceID" : 7,
      "context" : "What does evolution maximize? In Chastain et al. [2014] (Corollary 5 in the SI text), it is also shown that under weak selection, “population genetics is tantamount to each gene optimizing at generation t a quantity equal to the cumulative expected fitness over all generations up to t,” (plus the entropy).",
      "startOffset" : 33,
      "endOffset" : 56
    }, {
      "referenceID" : 7,
      "context" : "What does evolution maximize? In Chastain et al. [2014] (Corollary 5 in the SI text), it is also shown that under weak selection, “population genetics is tantamount to each gene optimizing at generation t a quantity equal to the cumulative expected fitness over all generations up to t,” (plus the entropy). While this is technically correct (our Cor. 3 is a restatement of this result), we feel that an unwary reader might reach the wrong impression, that this is a mathematical explanation of some guarantee on the average fitness of the population. We thus emphasize that the both [2014] and our paper establish only the property of diminishing regret, which is already implied when P t converges to a Nash equilibrium.",
      "startOffset" : 33,
      "endOffset" : 591
    }, {
      "referenceID" : 16,
      "context" : "However, it is known that the sexual population dynamics on general fitness matrices (even on 4× 4 matrices) does not always converge, and explicit examples have been constructed [Hastings, 1981; Akin, 1983; Hofbauer and Iooss, 1984].",
      "startOffset" : 179,
      "endOffset" : 233
    }, {
      "referenceID" : 0,
      "context" : "However, it is known that the sexual population dynamics on general fitness matrices (even on 4× 4 matrices) does not always converge, and explicit examples have been constructed [Hastings, 1981; Akin, 1983; Hofbauer and Iooss, 1984].",
      "startOffset" : 179,
      "endOffset" : 233
    }, {
      "referenceID" : 17,
      "context" : "However, it is known that the sexual population dynamics on general fitness matrices (even on 4× 4 matrices) does not always converge, and explicit examples have been constructed [Hastings, 1981; Akin, 1983; Hofbauer and Iooss, 1984].",
      "startOffset" : 179,
      "endOffset" : 233
    }, {
      "referenceID" : 28,
      "context" : "known that weak selection provides an additional guarantee, which is that the dynamics converge to a particular population distribution [Nagylaki, 1993].",
      "startOffset" : 136,
      "endOffset" : 152
    }, {
      "referenceID" : 7,
      "context" : "We also acknowledge a useful correspondence with the authors of Chastain et al. [2014], who clarified many points about their paper.",
      "startOffset" : 64,
      "endOffset" : 87
    }, {
      "referenceID" : 8,
      "context" : "B PW and product distributions Consider the “uncorrelated” version of the PW algorithm, which is the one used in [Chastain et al., 2014]: x i = x t i ∑",
      "startOffset" : 113,
      "endOffset" : 136
    }, {
      "referenceID" : 8,
      "context" : "In [Chastain et al., 2014] there is no distinction between RS and SR.",
      "startOffset" : 3,
      "endOffset" : 26
    }, {
      "referenceID" : 7,
      "context" : "5 in [Chastain et al., 2013]).",
      "startOffset" : 5,
      "endOffset" : 28
    }, {
      "referenceID" : 8,
      "context" : "To further stress this point, we will show that the population dynamics and the PW algorithm used in [Chastain et al., 2014] can significantly differ (we saw empirically that the marginals also differ significantly).",
      "startOffset" : 101,
      "endOffset" : 124
    }, {
      "referenceID" : 7,
      "context" : "In [Chastain et al., 2014] there is no distinction between RS and SR. The formal definition that they use coincides with RS (p. 1 of the SI text), whereas in an earlier draft they used SR (p.5 in [Chastain et al., 2013]). In a private communication the authors clarified that they use SR and RS interchangeably, since under weak selection they are very close. Divergence from the Wright manifold Chastain et al. [2014] justify the assumption that P t is a product distribution by quoting the result of Nagylaki [1993], which states for any process (P )t there is a “corresponding process” on the Wright manifold, which converges to the same point.",
      "startOffset" : 4,
      "endOffset" : 419
    }, {
      "referenceID" : 7,
      "context" : "In [Chastain et al., 2014] there is no distinction between RS and SR. The formal definition that they use coincides with RS (p. 1 of the SI text), whereas in an earlier draft they used SR (p.5 in [Chastain et al., 2013]). In a private communication the authors clarified that they use SR and RS interchangeably, since under weak selection they are very close. Divergence from the Wright manifold Chastain et al. [2014] justify the assumption that P t is a product distribution by quoting the result of Nagylaki [1993], which states for any process (P )t there is a “corresponding process” on the Wright manifold, which converges to the same point.",
      "startOffset" : 4,
      "endOffset" : 518
    } ],
    "year" : 2015,
    "abstractText" : "We consider a recent innovative theory by Chastain et al. on the role of sex in evolution [Chastain et al., 2014]. In short, the theory suggests that the evolutionary process of gene recombination implements the celebrated multiplicative weights updates algorithm (MWUA). They prove that the population dynamics induced by sexual reproduction can be precisely modeled by genes that use MWUA as their learning strategy in a particular coordination game. The result holds in the environments of weak selection, under the assumption that the population frequencies remain a product distribution. We revisit the theory, eliminating both the requirement of weak selection and any assumption on the distribution of the population. Removing the assumption of product distributions is crucial, since as we show, this assumption is inconsistent with the population dynamics. We show that the marginal allele distributions induced by the population dynamics precisely match the marginals induced by a multiplicative weights update algorithm in this general setting, thereby affirming and substantially generalizing these earlier results. We further revise the implications for convergence and utility or fitness guarantees in coordination games. In contrast to the claim of Chastain et al. [2014], we conclude that the sexual evolutionary dynamics does not entail any property of the population distribution, beyond those already implied by convergence.",
    "creator" : "LaTeX with hyperref package"
  }
}