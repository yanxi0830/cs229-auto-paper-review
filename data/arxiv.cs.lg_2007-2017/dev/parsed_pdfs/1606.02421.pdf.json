{
  "name" : "1606.02421.pdf",
  "metadata" : {
    "source" : "META",
    "title" : "Gossip Dual Averaging for Decentralized Optimization of  Pairwise Functions",
    "authors" : [ "Igor Colin", "Aurélien Bellet" ],
    "emails" : [ "IGOR.COLIN@TELECOM-PARISTECH.FR", "AURELIEN.BELLET@INRIA.FR", "JOSEPH.SALMON@TELECOM-PARISTECH.FR", "STEPHAN.CLEMENCON@TELECOM-PARISTECH.FR" ],
    "sections" : [ {
      "heading" : "1. Introduction",
      "text" : "The increasing popularity of large-scale and fully decentralized computational architectures, fueled for instance by\nProceedings of the 33 rd International Conference on Machine Learning, New York, NY, USA, 2016. JMLR: W&CP volume 48. Copyright 2016 by the author(s).\nthe advent of the “Internet of Things”, motivates the development of efficient optimization algorithms adapted to this setting. An important application is machine learning in wired and wireless networks of agents (sensors, connected objects, mobile phones, etc.), where the agents seek to minimize a global learning objective which depends of the data collected locally by each agent. In such networks, it is typically impossible to efficiently centralize data or to globally aggregate intermediate results: agents can only communicate with their immediate neighbors (e.g., agents within a small distance), often in a completely asynchronous fashion. Standard distributed optimization and machine learning algorithms (implemented for instance using MapReduce/Spark) require a coordinator node and/or to maintain synchrony, and are thus unsuitable for use in decentralized networks.\nIn contrast, gossip algorithms (Tsitsiklis, 1984; Boyd et al., 2006; Kempe et al., 2003; Shah, 2009) are tailored to this setting because they only rely on simple peer-to-peer communication: each agent only exchanges information with one neighbor at a time. Various gossip algorithms have been proposed to solve the flagship problem of decentralized optimization, namely to find a parameter vector θ which minimizes an average of convex functions (1/n) ∑n i=1 f(θ;xi), where the data xi is only known to agent i. The most popular algorithms are based on (sub)gradient descent (Johansson et al., 2010; Nedić & Ozdaglar, 2009; Ram et al., 2010; Bianchi & Jakubowicz, 2013), ADMM (Wei & Ozdaglar, 2012; 2013; Iutzeler et al., 2013) or dual averaging (Duchi et al., 2012; Yuan et al., 2012; Lee et al., 2015; Tsianos et al., 2015), some of which can also accommodate constraints or regularization on θ. The main idea underlying these methods is that each agent seeks to minimize its local function by applying local updates (e.g., gradient steps) while exchanging inforar X iv :1\n60 6.\n02 42\n1v 1\n[ st\nat .M\nL ]\n8 J\nmation with neighbors to ensure a global convergence to the consensus value.\nIn this paper, we tackle the problem of minimizing an average of pairwise functions of the agents’ data:\nmin θ\n1\nn2 ∑ 1≤i,j≤n f(θ;xi, xj). (1)\nThis problem finds numerous applications in statistics and machine learning, e.g., Area Under the ROC Curve (AUC) maximization (Zhao et al., 2011), distance/similarity learning (Bellet et al., 2015), ranking (Clémençon et al., 2008), supervised graph inference (Biau & Bleakley, 2006) and multiple kernel learning (Kumar et al., 2012), to name a few. As a motivating example, consider a mobile phone application which locally collects information about its users. The provider could be interested in learning pairwise similarity functions between users in order to group them into clusters or to recommend them content without having to centralize data on a server (which would be costly for the users’ bandwidth) or to synchronize phones.\nThe main difficulty in Problem (1) comes from the fact that each term of the sum depends on two agents i and j, making the local update schemes of previous approaches impossible to apply unless data is exchanged between nodes. Although gossip algorithms have recently been introduced to evaluate such pairwise functions for a fixed θ (Pelckmans & Suykens, 2009; Colin et al., 2015), to the best of our knowledge, efficiently finding the optimal solution θ in a decentralized way remains an open challenge. Our contributions towards this objective are as follows. We propose new gossip algorithms based on dual averaging (Nesterov, 2009; Xiao, 2010) to efficiently solve Problem (1) and its constrained or regularized variants. Central to our methods is a light data propagation scheme which allows the nodes to compute biased estimates of the gradients of functions in (1). We then propose a theoretical analysis of our algorithms both in synchronous and asynchronous settings establishing their convergence under an additional hypothesis that the bias term decreases fast enough over the iterations (and we have observed such a fast decrease in all our experiments). Finally, we present some numerical simulations on Area Under the ROC Curve (AUC) maximization and metric learning problems. These experiments illustrate the practical performance of the proposed algorithms and the influence of network topology, and show that in practice the influence of the bias term is negligible as it decreases very fast with the number of iterations.\nThe paper is organized as follows. Section 2 formally introduces the problem of interest and briefly reviews the dual averaging method, which is at the root of our approach. Section 3 presents the proposed gossip algorithms and their convergence analysis. Section 4 displays our numerical\nsimulations. Finally, concluding remarks are collected in Section 5."
    }, {
      "heading" : "2. Preliminaries",
      "text" : ""
    }, {
      "heading" : "2.1. Definitions and Notation",
      "text" : "For any integer p > 0, we denote by [p] the set {1, . . . , p} and by |F | the cardinality of any finite set F . We denote an undirected graph by G = (V,E), where V = [n] is the set of vertices and E ⊆ V × V is the set of edges. A node i ∈ V has degree di = |{j : (i, j) ∈ E}|. G is connected if for all (i, j) ∈ V 2 there exists a path connecting i and j; it is bipartite if there exist S, T ⊂ V such that S ∪ T = V , S∩T = ∅ andE ⊆ (S×T )∪(T×S). The graph Laplacian of G is denoted by L(G) = D(G)−A(G), whereD(G) and A(G) are respectively the degree and the adjacency matrices of G.\nThe transpose of a matrix M ∈ Rn×n is denoted by M>. A matrix P ∈ Rn×n is termed stochastic whenever P ≥ 0 and P1n = 1n, where 1n = (1, . . . , 1)> ∈ Rn, and bistochastic whenever both P and P> are stochastic. We denote by In the identity matrix in Rn×n, by (e1, . . . , en) the canonical basis of Rn, by I{E} the indicator function of any event E and by ‖ · ‖ the usual `2-norm. For θ ∈ Rd and g : Rd → R, we denote by ∇g(θ) the gradient of g at θ. Finally, given a collection of vectors u1, . . . , un, we denote by ūn = (1/n) ∑n i=1 ui its empirical mean."
    }, {
      "heading" : "2.2. Problem Statement",
      "text" : "We represent a network of n agents as an undirected graph G = ([n], E), where each node i ∈ [n] corresponds to an agent and (i, j) ∈ E if nodes i and j can exchange information directly (i.e., they are neighbors). For ease of exposition, we assume that each node i ∈ [n] holds a single data point xi ∈ X . Though restrictive in practice, this assumption can easily be relaxed, but it would lead to more technical details to handle the storage size, without changing the overall analysis (see supplementary material for details).\nGiven d > 0, let f : Rd × X × X → R a differentiable and convex function with respect to the first variable. We assume that for any (x, x′) ∈ X 2, there exists Lf > 0 such that f(·;x, x′) is Lf -Lipschitz (with respect to the `2-norm). Let ψ : Rd → R+ be a non-negative, convex, possibly non-smooth, function such that, for simplicity, ψ(0) = 0. We aim at solving the following optimization problem:\nmin θ∈Rd\n1\nn2 ∑ 1≤i,j≤n f(θ;xi, xj) + ψ(θ). (2)\nIn a typical machine learning scenario, Problem (2) is a (regularized) empirical risk minimization problem and θ\nAlgorithm 1 Stochastic dual averaging in the centralized setting Require: Step size (γ(t))t≥0 > 0. 1: Initialization: θ = 0, θ̄ = 0, z = 0. 2: for t = 1, . . . , T do 3: Update z ← z + g(t), where E[g(t)|θ] = ∇f̄n(θ) 4: Update θ ← πt(z) 5: Update θ̄ ← ( 1− 1\nt\n) θ̄ + 1\nt θ\n6: end for 7: return θ̄\ncorresponds to the model parameters to be learned. The quantity f(θ;xi, xj) is a pairwise loss measuring the performance of the model θ on the data pair (xi, xj), while ψ(θ) represents a regularization term penalizing the complexity of θ. Common examples of regularization terms include indicator functions of a closed convex set to model explicit convex constraints, or norms enforcing specific properties such as sparsity (a canonical example being the `1-norm).\nMany machine learning problems can be cast as Problem (2). For instance, in AUC maximization (Zhao et al., 2011), binary labels (`1, . . . , `n) ∈ {−1, 1}n are assigned to the data points and we want to learn a (linear) scoring rule x 7→ x>θ which hopefully gives larger scores to positive data points than to negative ones. One may use the logistic loss\nf(θ;xi, xj) = I{`i>`j} log ( 1 + exp((xj − xi)>θ) ) ,\nand the regularization term ψ(θ) can be the square `2-norm of θ (or the `1-norm when a sparse model is desired). Other popular instances of Problem (2) include metric learning (Bellet et al., 2015), ranking (Clémençon et al., 2008), supervised graph inference (Biau & Bleakley, 2006) and multiple kernel learning (Kumar et al., 2012).\nFor notational convenience, we denote by fi the partial function (1/n) ∑n j=1 f(·;xi, xj) for i ∈ [n] and by f̄n =\n(1/n) ∑n i=1 fi. Problem (2) can then be recast as:\nmin θ∈Rd\nRn(θ) = f̄ n(θ) + ψ(θ). (3)\nNote that the function f̄n is Lf -Lipschitz, since all the fi are Lf -Lipschitz.\nRemark 1. Throughout the paper we assume that the function f is differentiable, but we expect all our results to hold even when f is non-smooth, for instance in L1-regression problems or when using the hinge loss. In this case, one simply needs to replace gradients by subgradients in our algorithms, and a similar analysis could be performed."
    }, {
      "heading" : "2.3. Centralized Dual Averaging",
      "text" : "In this section, we review the stochastic dual averaging optimization algorithm (Nesterov, 2009; Xiao, 2010) to solve\nProblem (2) in the centralized setting (where all data lie on the same machine). This method is at the root of our gossip algorithms, for reasons that will be made clear in Section 3. To explain the main idea behind dual averaging, let us first consider the iterations of Stochastic Gradient Descent (SGD), assuming ψ ≡ 0 for simplicity:\nθ(t+ 1) = θ(t)− γ(t)g(t),\nwhere E[g(t)|θ(t)] = ∇f̄n(θ(t)), and (γ(t))t≥0 is a nonnegative non-increasing step size sequence. For SGD to converge to an optimal solution, the step size sequence must satisfy γ(t) −→\nt→+∞ 0 and\n∑∞ t=0 γ(t) = ∞. As no-\nticed by Nesterov (2009), an undesirable consequence is that new gradient estimates are given smaller weights than old ones. Dual averaging aims at integrating all gradient estimates with the same weight.\nLet (γ(t))t≥0 be a positive and non-increasing step size sequence. The dual averaging algorithm maintains a sequence of iterates (θ(t))t>0, and a sequence (z(t))t≥0 of “dual” variables which collects the sum of the unbiased gradient estimates seen up to time t. We initialize to θ(1) = z(0) = 0. At each step t > 0, we compute an unbiased estimate g(t) of ∇f̄n(θ(t)). The most common choice is to take g(t) = ∇f(θ;xit , xjt) where it and jt are drawn uniformly at random from [n]. We then set z(t + 1) = z(t) + g(t) and generate the next iterate with the following rule: θ(t+ 1) = πψt (z(t+ 1)),\nπψt (z) := arg min θ∈Rd\n{ −z>θ + ‖θ‖ 2\n2γ(t) + tψ(θ)\n} .\nWhen it is clear from the context, we will drop the dependence in ψ and simply write πt(z) = π ψ t (z). Remark 2. Note that πt(·) is related to the proximal operator of a function φ : Rd → R defined by proxφ(x) = arg minz∈Rd ( ‖z − x‖2/2 + φ(x) ) . Indeed, one can write:\nπt(z) = proxtγ(t)ψ (γ(t)z) .\nFor many functions ψ of practical interest, πt(·) has a closed form solution. For instance, when ψ = ‖ · ‖2, πt(·) corresponds to a simple scaling, and when ψ = ‖ · ‖1 it is a soft-thresholding operator. If ψ is the indicator function of a closed convex set C, then πt(·) is the projection operator onto C.\nThe dual averaging method is summarized in Algorithm 1. If γ(t) ∝ 1/ √ t then for any T > 0:\nET [ Rn(θ̄(T ))−Rn(θ∗) ] = O(1/ √ T ),\nwhere θ∗ ∈ arg minθ∈Rd Rn(θ), θ̄(T ) = 1T ∑T i=1 θ(t) is the averaged iterate and ET is the expectation over all possible sequences (g(t))1≤t≤T . A precise statement of this\nresult along with a proof can be found in the supplementary material for completeness.\nNotice that dual averaging cannot be easily adapted to our decentralized setting. Indeed, a node cannot compute an unbiased estimate of its gradient: this would imply an access to the entire set of data points, which violates the communication and storage constraints. Therefore, data points have to be appropriately propagated during the optimization procedure, as detailed in the following section."
    }, {
      "heading" : "3. Pairwise Gossip Dual Averaging",
      "text" : "We now turn to our main goal, namely to develop efficient gossip algorithms for solving Problem (2) in the decentralized setting. The methods we propose rely on dual averaging (see Section 2.3). This choice is guided by the fact that the structure of the updates makes dual averaging much easier to analyze in the distributed setting than sub-gradient descent when the problem is constrained or regularized. This is because dual averaging maintains a simple sum of sub-gradients, while the (non-linear) smoothing operator πt is applied separately.\nOur work builds upon the analysis of Duchi et al. (2012), who proposed a distributed dual averaging algorithm to optimize an average of univariate functions f(·;xi). In their algorithm, each node i computes unbiased estimates of its local function ∇f(·;xi) that are iteratively averaged over the network. Unfortunately, in our setting, the node i cannot compute unbiased estimates of ∇fi(·) = ∇(1/n) ∑n j=1 f(·;xi, xj): the latter depends on all data points while each node i ∈ [n] only holds xi. To go around this problem, we rely on a gossip data propagation step (Pelckmans & Suykens, 2009; Colin et al., 2015) so that the nodes are able to compute biased estimates of ∇fi(·) while keeping the communication and memory overhead to a small level for each node.\nWe present and analyze our algorithm in the synchronous setting in Section 3.1. We then turn to the more intricate analysis of the asynchronous setting in Section 3.2."
    }, {
      "heading" : "3.1. Synchronous Setting",
      "text" : "In the synchronous setting, we assume that each node has access to a global clock such that every node can update simultaneously at each tick of the clock. Although not very realistic, this setting allows for simpler analysis. We assume that the scaling sequence (γ(t))t≥0 is the same for every node. At any time, each node i has the following quantities in its local memory register: a variable zi (the gradient accumulator), its original observation xi, and an auxiliary observation yi, which is initialized at xi but will change throughout the algorithm as a result of data propagation.\nAlgorithm 2 Gossip dual averaging for pairwise function in synchronous setting Require: Step size (γ(t))t≥1 > 0. 1: Each node i initializes yi = xi, zi = θi = θ̄i = 0. 2: for t = 1, . . . , T do 3: Draw (i, j) uniformly at random from E 4: Set zi, zj ← zi+zj2 5: Swap auxiliary observations: yi ↔ yj 6: for k = 1, . . . , n do 7: Update zk ← zk +∇θf(θk;xk, yk) 8: Compute θk ← πt(zk) 9: Average θ̄k ← ( 1− 1\nt\n) θ̄k +\n1 t θk\n10: end for 11: end for 12: return Each node k has θ̄k\nThe algorithm goes as follows. At each iteration, an edge (i, j) ∈ E of the graph is drawn uniformly at random. Then, nodes i and j average their gradient accumulators zi and zj , and swap their auxiliary observations yi and yj . Finally, every node of the network performs a dual averaging step, using their original observation and their current auxiliary one to estimate the partial gradient. The procedure is detailed in Algorithm 2, and the following proposition adapts the convergence rate of centralized dual averaging under the hypothesis that the contribution of the bias term decreases fast enough over the iterations.\nTheorem 1. Let G be a connected and non-bipartite graph with n nodes, and let θ∗ ∈ arg minθ∈Rd Rn(θ). Let (γ(t))t≥1 be a non-increasing and non-negative sequence. For any i ∈ [n] and any t ≥ 0, let zi(t) ∈ Rd and θ̄i(t) ∈ Rd be generated according to Algorithm 2. Then for any i ∈ [n] and T > 1, we have:\nET [Rn(θ̄i)−Rn(θ∗)] ≤ C1(T ) + C2(T ) + C3(T ),\nwhere  C1(T ) = 1 2Tγ(T ) ‖θ∗‖2 + L2f 2T T−1∑ t=1 γ(t), C2(T ) = 3L2f T ( 1− √ λG2 ) T−1∑ t=1 γ(t), C3(T ) = 1\nT T−1∑ t=1 Et[(ω(t)− θ∗)>̄n(t)],\nand λG2 < 1 is the second largest eigenvalue of the matrix W (G) = In − 1|E|L(G).\nSketch of proof. First notice that at a given (outer) iteration t+ 1, z̄n is updated as follows:\nz̄n(t+ 1) = z̄n(t) + 1\nn n∑ k=1 dk(t), (4)\nwhere dk(t) = ∇θf(θk(t);xk, yk(t + 1)) is a biased estimate of∇fk(θk(t)). Let k(t) = dk(t)− gk(t) be the bias, so that we have E[gk(t)|θk(t)] = ∇fk(θk(t)).\nLet us define ω(t) = πt(z̄n(t)). Using convexity of Rn, the gradient’s definition and the fact that the functions f̄n and πt are both Lf -Lipschitz, we obtain: for T ≥ 2 and i ∈ [n],\nET [Rn(θ̄i(T ))−Rn(θ∗)]\n≤ Lf nT T∑ t=2 γ(t− 1) n∑ j=1 Et [ ‖zi(t)− zj(t)‖ ] (5)\n+ Lf nT T∑ t=2 γ(t− 1) n∑ j=1 Et [ ‖z̄n(t)− zj(t)‖ ] (6)\n+ 1\nT T∑ t=2 Et[(ω(t)− θ∗)>ḡn(t)]. (7)\nUsing Lemma 4 (see supplementary material), the terms (5)-(6) can be bounded by C2(T ). The term (7) requires a specific analysis because the updates are performed using biased estimates. We decompose it as follows:\n1\nT T∑ t=2 Et [ ω(t)− θ∗)>ḡn(t) ] = 1\nT T∑ t=2 Et [ (ω(t)− θ∗)>(d̄n(t)− ̄n(t)) ] ≤ 1\nT T∑ t=2 Et [ (ω(t)− θ∗)>d̄n(t) ] (8)\n+ 1\nT T∑ t=2 Et [ (ω(t)− θ∗)>̄n(t) ] .\nThe term (8) can be bounded by C1(T ) (see Xiao, 2010, Lemma 9). We refer the reader to the supplementary material for the detailed proof.\nThe rate of convergence in Proposition 1 is divided into three parts: C1(T ) is a data dependent term which corresponds to the rate of convergence of the centralized dual averaging, while C2(T ) and C3(T ) are network dependent terms since 1 − λG2 = βGn−1/|E|, where βGn−1 is the second smallest eigenvalue of the graph Laplacian L(G), also known as the spectral gap of G. The convergence rate of our algorithm thus improves when the spectral gap is large, which is typically the case for well-connected graphs (Chung, 1997). Note that C2(T ) corresponds to the network dependence for the distributed dual averaging algorithm of Duchi et al. (2012) while the term C3(T ) comes from the bias of our partial gradient estimates. In practice, C3(T ) vanishes quickly and has a small impact on the rate of convergence, as shown in Section 4.\nAlgorithm 3 Gossip dual averaging for pairwise function in asynchronous setting Require: Step size (γ(t))t≥0 > 0, probabilities (pk)k∈[n]. 1: Each node i initializes yi = xi, zi = θi = θ̄i = 0, mi = 0. 2: for t = 1, . . . , T do 3: Draw (i, j) uniformly at random from E 4: Swap auxiliary observations: yi ↔ yj 5: for k ∈ {i, j} do 6: Set zk ← zi+zj2 7: Update zk ← 1pk∇θf(θk;xk, yk) 8: Increment mk ← mk + 1pk 9: Compute θk ← πmk (zk)\n10: Average θ̄k ← (\n1− 1 mkpk\n) θ̄k\n11: end for 12: end for 13: return Each node k has θ̄k"
    }, {
      "heading" : "3.2. Asynchronous Setting",
      "text" : "For any variant of gradient descent over a network with a decreasing step size, there is a need for a common time scale to perform the suitable decrease. In the synchronous setting, this time scale information can be shared easily among nodes by assuming the availability of a global clock. This is convenient for theoretical considerations, but is unrealistic in practical (asynchronous) scenarios. In this section, we place ourselves in a fully asynchronous setting where each node has a local clock, ticking at a Poisson rate of 1, independently from the others. This is equivalent to a global clock ticking at a rate n Poisson process which wakes up an edge of the network uniformly at random (see Boyd et al., 2006, for details on clock modeling).\nWith this in mind, Algorithm 2 needs to be adapted to this setting. First, one cannot perform a full dual averaging update over the network since only two nodes wake up at each iteration. Also, as mentioned earlier, each node needs to maintain an estimate of the current iteration number in order for the scaling factor γ to be consistent across the network. For k ∈ [n], let pk denote the probability for the node k to be picked at any iteration. If the edges are picked uniformly at random, then one has pk = 2dk/|E|. For simplicity, we focus only on this case, although our analysis holds in a more general setting.\nLet us define an activation variable (δk(t))t≥1 such that for any t ≥ 1,\nδk(t) = { 1 if node k is picked at iteration t, 0 otherwise.\nOne can immediately see that (δk(t))t≥1 are i.i.d. random variables, Bernoulli distributed with parameter pk. Let us define (mk(t)) ≥ 0 such that mk(0) = 0 and for t ≥ 0, mk(t + 1) = mk(t) +\nδk(t+1) pk . Since (δk(t))t≥1 are\nBernoulli random variables, mk(t) is an unbiased estimate of the time t.\nUsing this estimator, we can now adapt Algorithm 2 to the fully asynchronous case, as shown in Algorithm 3. The update step slightly differs from the synchronous case: the partial gradient has a weight 1/pk instead of 1 so that all partial functions asymptotically count in equal way in every gradient accumulator. In contrast, uniform weights would penalize partial gradients from low degree nodes since the probability of being drawn is proportional to the degree. This weighting scheme is essential to ensure the convergence to the global solution. The model averaging step also needs to be altered: in absence of any global clock, the weight 1/t cannot be used and is replaced by 1/(mkpk), where mkpk corresponds to the average number of times that node k has been selected so far.\nThe following result is the analogous of Theorem 1 for the asynchronous setting.\nTheorem 2. Let G be a connected and non bipartite graph. Let (γ(t))t≥1 be defined as γ(t) = c/t1/2+α for some constant c > 0 and α ∈ (0, 1/2). For i ∈ [n], let (di(t))t≥1, (gi(t))t≥1, ( i(t))t≥1, (zi(t))t≥1 and (θi(t))t≥1 be generated as described in Algorithm 3. Then, there exists some constant C < +∞ such that, for θ∗ ∈ arg minθ′∈Rd Rn(θ ′), i ∈ [n] and T > 0,\nRn(θ̄i(T ))−Rn(θ∗) ≤C max(T−α/2, Tα−1/2)\n+ 1\nT T∑ t=2 Et[(ω(t)− θ∗)> n(t)].\nThe proof is given in the supplementary material.\nRemark 3. In the asynchronous setting, no convergence rate was known even for the distributed dual averaging algorithm of Duchi et al. (2012), which deals with the simpler problem of minimizing univariate functions. The arguments used to derive Theorem 2 can be adapted to derive a convergence rate (without the bias term) for an asynchronous version of their algorithm.\nRemark 4. We have focused on the setting where all pairs of observations are involved in the objective. In practice, the objective may depend only on a subset of all pairs. To efficiently apply our algorithm to this case, one should take advantage of the potential structure of the subset of interest: for instance, one could attach some additional concise information to each observation so that a node can easily identify whether a pair contributes to the objective, and if not set the loss to be zero. This is essentially the case in the AUC optimization problem studied in Section 4, where pairs of similarly labeled observations do not contribute to the objective. If the subset of pairs cannot be expressed in such a compact form, then one would need to provide\neach node with an index list of active pairs, which could be memory-intensive when n is large."
    }, {
      "heading" : "4. Numerical Simulations",
      "text" : "In this section, we present numerical experiments on two popular machine learning problems involving pairwise functions: Area Under the ROC Curve (AUC) maximization and metric learning. Our results show that our algorithms converge and that the bias term vanishes very quickly with the number of iterations.\nTo study the influence of the network topology, we perform our simulations on three types of network (see Table 1 for the corresponding spectral gap values):\n• Complete graph: All nodes are connected to each other. It is the ideal situation in our framework, since any pair of nodes can communicate directly. In this setting, the bias of gradient estimates should be very small, as one has for any k ∈ [n] and any t ≥ 1, Et[dk(t)|θk(t)] = 1/(n − 1) ∑ y′ 6=yk(t)∇θf(θk(t);xk, y\n′). For a network size n, the complete graph achieves the highest spectral gap: 1 − λG2 = 1/n, see Bollobás (1998, Ch.9) or Chung (1997, Ch.1) for details.\n• Cycle graph: This is the worst case in terms of connectivity: each node only has two neighbors. This network has a spectral gap of order 1/n3, and gives a lower bound in terms of convergence rate.\n• Watts-Strogatz: This random network generation technique (Watts & Strogatz, 1998) relies on two parameters: the average degree of the network k and a rewiring probability p. In expectation, the higher the rewiring probability, the better the connectivity of the network. Here, we use k = 5 and p = 0.3 to achieve a compromise between the connectivities of the complete graph and the cycle graph.\nAUC Maximization We first present an application of our algorithms to AUC maximization on a real dataset. Given a set of data points x1, . . . , xn ∈ Rd with associated binary labels `1, . . . , `n ∈ {−1, 1}, the goal is to learn a linear scoring rule x 7→ x>θ parameterized by θ ∈ Rd which maximizes:\nAUC(θ) = ∑ 1≤i,j≤n I{`i>`j}I{x>i θ>x>j θ}∑\n1≤i,j≤n I{`i>`j} .\nIt corresponds to the probability that the scoring rule associated with θ outputs a higher score on a positively labeled sample than on a negatively labeled one. This formulation leads to a non-smooth optimization problem; therefore, one\ntypically minimizes a convex surrogate such as the logistic loss:\nRn(θ) = 1\nn2 ∑ 1≤i,j≤n I{`i>`j} log ( 1 + exp((xj − xi)>θ) ) .\nWe do not apply any regularization (i.e., ψ ≡ 0), and use the Breast Cancer Wisconsin dataset,1 which consists of n = 699 points in d = 11 dimensions.\nWe initialize each θi to 0 and for each network, we run 50 times Algorithms 2 and 3 with γ(t) = 1/ √ t.2 Figure 1(a) shows the evolution of the objective function and the associated standard deviation (across nodes) with the number of iterations in the synchronous setting. As expected, the average convergence rate on the complete and the WattsStrogatz networks is much better than on the poorly connected cycle network. The standard deviation of the node estimates also decreases with the connectivity of the network.\nThe results for the asynchronous setting are shown in Figure 1(b). As expected, the convergence rate is slower in terms of number of iterations (roughly 5 times) than in the synchronous setting. Note however that much fewer dual averaging steps are performed: for instance, on the WattsStrogatz network, reaching a 0.1 loss requires 210, 000\n1https://archive.ics.uci.edu/ml/datasets/ Breast+Cancer+Wisconsin+(Original)\n2Even if this scaling sequence does not fulfill the hypothesis of Theorem 2 for the asynchronous setting, the convergence rate is acceptable in practice.\n(partial) gradient computations in the synchronous setting and only 25, 000 in the asynchronous setting. Moreover, the standard deviation of the estimates is much lower than in the synchronous setting. This is because communication and local optimization are better balanced in the asynchronous setting (one optimization step for each gradient accumulator averaged) than in the synchronous setting (n optimization steps for 2 gradient accumulators averaged).\nThe good practical convergence of our algorithm comes from the fact that the bias term n(t)>ω(t) vanishes quite fast. Figure 1(c) shows that its average value quickly converges to 0 on all networks. Moreover, its order of magnitude is negligible compared to the objective function. In order to fully estimate the impact of this bias term on the performance, we also compare our algorithm to the ideal but unrealistic situation where each node is given an unbiased estimate of its partial gradient: instead of adding ∇f(θi(t);xi, yi(t)) to zi(t), a node i will add ∇f(θi(t);xi, xj) where j ∈ [n] is picked uniformly at random. As shown in Figure 2, the performance of both methods are very similar on well-connected networks.\nMetric Learning We now turn to a metric learning application. We consider the family of Mahalanobis distances Dθ(xi, xj) = (xi − xj)>θ(xi − xj) parameterized by θ ∈ Sd+, where Sd+ is the cone of d × d positive semi-definite real-valued matrices. Given a set of data points x1, . . . , xn ∈ Rd with associated labels `1, . . . , `n ∈ {−1, 1}, the goal is to find θ ∈ Sd+ which minimizes the\nfollowing criterion (Jin et al., 2009):\nRn(θ) = 1\nn2 ∑ 1≤i,j≤n [ `i`j(b−Dθ(xi, xj)) ] + + ψ(θ),\nwhere [u]+ = max(0, 1 − u), b > 0, and ψ(θ) = ∞ if θ /∈ Sd+ and 0 otherwise. We use a synthetic dataset of n = 1, 000 points generated as follows: each point is drawn from a mixture of 10 Gaussians in R40 (each corresponding to a class) with all Gaussian means contained in a 5d subspace and their shared covariance matrix proportional to the identity with a variance factor such that some overlap is observed.\nFigure 3(a) shows the evolution of the objective function and its standard deviation for the asynchronous setting. As in the case of AUC maximization, the algorithm converges much faster on the well-connected networks than on the cycle network. Again, we can see in Figure 3(b) that the bias vanishes very quickly with the number of iterations.\nAdditional Experiment We refer to the supplementary material for a metric learning experiment on a real dataset."
    }, {
      "heading" : "5. Conclusion",
      "text" : "In this work, we have introduced new synchronous and asynchronous gossip algorithms to optimize functions depending on pairs of data points distributed over a network. The proposed methods are based on dual averaging and can readily accommodate various popular regularization terms. We provided an analysis showing that they behave similarly to the centralized dual averaging algorithm, with additional terms reflecting the network connectivity and the gradient bias. Finally, we proposed some numerical experiments on AUC maximization and metric learning which illustrate the performance of the proposed algorithms, as well as the influence of network topology. A challenging line of future research consists in designing and analyzing novel adaptive gossip schemes, where the communication scheme is dynamic and depends on the network connectivity properties and on the local information carried by each node."
    }, {
      "heading" : "A. Outline of the Supplementary Material",
      "text" : "The supplementary material is organized as follows. In Section B, we recall the standard proof of convergence rate for the (centralized) dual averaging. Then, in Section C, we improve the analysis of the decentralized version of the dual averaging algorithm for simple sums of functions, and provide insights to analyze the case of sum of pairwise functions. Our asynchronous variant is investigated in Section D. Technical details on how to extend our framework to the case with multiple points per node are given in Section E. Finally, additional numerical results are discussed in Section F."
    }, {
      "heading" : "B. Centralized Dual Averaging",
      "text" : "B.1. Deterministic Setting\nWe introduce the dual averaging algorithm for minimizing the sum f + ψ, in a context where f is convex and smooth, ψ(0) = 0, ψ is convex, non-negative and possibly non-smooth, with a proximity operator simple to compute. In the centralized framework, this algorithm reads as follows:\nθ(t+ 1) = arg min θ′∈Rd\n{ θ′>\nt∑ s=1 g(s) + ‖θ′‖2 2γ(t) + tψ(θ′)\n} , (9)\nfor any t ≥ 1, where γ(t) represents a scale factor similar to a gradient step size use in standard gradient descent algorithms, and g(t) is a sequence of gradient of f taken at θ(t). Moreover we initialize θ(1) = 0. The function f we consider is here of the form f̄n(θ) = 1/n ∑n i=1 fi(θ), where each fi is assumed Lf -Lipschitz for simplicity (so is f then). We denote Rn = f̄ n + ψ. As a reminder, note that the Centralized dual averaging method is explicitly stated in Algorithm 4.\nThis particular formulation was introduced in (Xiao, 2009; 2010), extending the method introduced by (Nesterov, 2009) in the specific case of indicator functions. In this work, we borrow the notation from (Xiao, 2010).\nIn order to perform a theoretical analysis of this algorithm, we introduce the following functions. Let us define, for t ≥ 0\nVt(z) := max θ∈Rd\n{ z>θ − ‖θ‖ 2\n2γ(t) − tψ(θ)\n} .\nRemark that with the assumption that ψ(0) = 0, then Vt(0) = 0. We also define the smoothing function πt that plays a crucial role in the dual algorithm formulation:\nπt(z) := arg max θ∈Rd\n{ z>θ − ‖θ‖ 2\n2γ(t) − tψ(θ)\n} = arg min\nθ∈Rd\n{ −z>θ + ‖θ‖ 2\n2γ(t) + tψ(θ)\n}\nStrong convexity in θ of the objective function, ensures that the solution of the optimization problem is unique. The following lemma links the function Vt and the algorithm update and is a simple application of the results from (Xiao, 2009, Lemma 10):\nLemma 1. For any z ∈ Rd, one has:\nπt(z) = ∇Vt(z) , (10)\nand the following statements hold true: for any z1, z2 ∈ Rd\n‖πt(z1)− πt(z2)‖ ≤ γ(t)‖z1 − z2‖ , (11)\nand for any g, z ∈ Rd,\nVt(z + g) ≤ Vt(z) + g>∇Vt(z) + γ(t)\n2 ‖g‖2. (12)\nWith this notation one can write the dual averaging rule as θ(t+ 1) = πt (−z(t+ 1)), where z(t) := ∑t−1 s=1 g(s), with the convention z(1) = 0. Moreover, adapting (Xiao, 2009, Lemma 11) we can state:\nAlgorithm 4 Centralized dual averaging Require: Step size (γ(t))t≥1 > 0. 1: Initialization θ = 0, θ̄ = 0, z = 0. 2: for t = 1, . . . , T do 3: Update z ← z + g(t), where g(t) = ∇f̄n(θ) 4: Update θ ← πt(z) 5: Update θ̄ ← ( 1− 1\nt\n) θ̄ + 1\nt θ\n6: end for 7: returnθ̄\nLemma 2. For any t ≥ 1 and any non-increasing sequence (γ(t))t≥1, we have\nVt (−z(t+ 1)) + ψ(θ(t+ 1)) ≤ Vt−1 (−z(t+ 1)) . (13)\nWe also need a last technical result that we will use several times in the following: Lemma 3. Let θ(t) = πt( ∑t−1 s=1 g(s)), and let (γ(t))t≥1 be a non-increasing and non-negative sequence sequence (with the convention γ(0) = 0), then for any θ ∈ Rd:\n1\nT T∑ t=1 g(t)>(θ(t)− θ) + 1 T T∑ t=1 (ψ(θ(t))− ψ(θ)) ≤ 1 T T∑ t=1 γ(t− 1) 2 ‖g(t)‖2 + ‖θ‖ 2 2Tγ(T ) . (14)\nProof. Use the definition of VT to get the following upper bound\n1\nT T∑ t=1 g(t)>(θ(t)− θ) + 1 T T∑ t=1 (ψ(θ(t))− ψ(θ)) = 1 T T∑ t=1 g(t)>θ(t) + ψ(θ(t)) + ‖θ‖2 2Tγ(T ) − ψ(θ)\n− ( z(T + 1)\nT\n)> θ − ‖θ‖ 2\n2Tγ(T )\n≤ 1 T T∑ t=1 ( g(t)>θ(t) + ψ(θ(t)) ) + ‖θ∗‖2\n2Tγ(T ) + VT (−z(T + 1)) . (15)\nThen one can check that with (12) and Lemma 2 that:\nVt(−z(t+ 1)) + ψ(θ(t+ 1)) ≤Vt−1(−z(t+ 1)) =Vt−1(−z(t)− g(t))\n≤Vt−1(−z(t))− g(t)>∇Vt−1(−z(t)) + γ(t− 1)\n2 ‖g(t)‖2\n=Vt−1(−z(t))− g(t)>θ(t) + γ(t− 1)\n2 ‖g(t)‖2.\nFrom the last display, the following holds:\ng(t)>θ(t) + ψ(θ(t+ 1)) ≤ Vt−1(−z(t))− Vt(−z(t+ 1)) + γ(t− 1)\n2 ‖g(t)‖2.\nSumming the former for t = 1, . . . , T yields\nT∑ t=1 g(t)>θ(t) + ψ(θ(t+ 1)) ≤ V0(−s0)− VT (−sT ) + T∑ t=1 γ(t− 1) 2 ‖gt‖2.\nRemark that V0(0) = 0 and ψ(θ(1))− ψ(θ(T + 1)) = −ψ(θ(T + 1)) ≤ 0, so the previous display can be reduced to:\nT∑ t=1 g(t)>θ(t) + ψ(θ(t)) + VT (−z(T + 1)) ≤ T∑ t=1 γ(t− 1) 2 ‖g(t)‖2. (16)\nCombining with (15), the lemma holds true.\nBounding the error of the dual averaging is provided in the next theorem, where we remind that Rn = f̄n + ψ:\nTheorem 3. Let (γ(t))t≥1 be a non increasing sequence. Let (z(t))t≥1, (θ(t))t≥1, (θ̄(t))t≥1 and (g(t))t≥1 be generated according to Algorithm 4. Assume that the function f̄n is Lf -Lipschitz and that θ∗ ∈ arg minθ′∈Rd Rn(θ′), then for any T ≥ 2, one has:\nRn(θ̄(T ))−Rn(θ∗) ≤ ‖θ∗‖2 2Tγ(T ) + L2f 2T T−1∑ t=1 γ(t). (17)\nMoreover, if one knows D > 0 such that ‖θ∗‖ ≤ D, then for the choice γ(t) = D Lf √ 2t , one has:\nRn(θ̄(T ))−Rn(θ∗) ≤ √\n2DLf√ T .\nProof. Let T ≥ 2. Using the convexity of f̄n and ψ, we can get:\nRn(θ̄(T ))−Rn(θ∗) ≤ 1\nT T∑ t=1 f̄n(θ(t))− f̄n(θ∗) + ψ(θ̄)− ψ(θ∗)\n≤ 1 T T∑ t=1 g(t)>(θ(t)− θ∗) + 1 T T∑ t=1 (ψ(θ(t))− ψ(θ∗))\n≤ 1 T T∑ t=1 γ(t− 1) 2 ‖g(t)‖2 + ‖θ‖ 2 2Tγ(T ) .\nwhere the second inequality holds since g(t) = ∇f̄n(θ(t)), and the third one is from an application of Lemma 3 with the choice θ = θ∗. Provided that ‖g(t)‖ ≤ Lf , which is true whenever f̄n is Lf -Lipschitz.\nB.2. Stochastic Dual Averaging\nSimilarly to sub-gradient descent algorithms, one can adapt dual averaging algorithm to a stochastic setting; this was studied extensively by Xiao (2009). Instead of updating the dual variable z(t) with the (full) gradient of f̄n at θ(t), one now only requires the expected value of the update to be the gradient, as detailed in Algorithm 1.\nAs in the gradient descent case, convergence results still hold in expectation, as stated in Theorem 4.\nTheorem 4. Let (γ(t))t≥1 be a non increasing sequence. Let (z(t))t≥1, (θ(t))t≥1 and (g(t))t≥1 be generated according to Algorithm 1. Assume that the function f̄n is Lf -Lipschitz and that θ∗ ∈ arg minθ′∈Rd Rn(θ′), then for any T ≥ 2, one has:\nET [ Rn(θ̄(T ))−Rn(θ∗) ] ≤ ‖θ ∗‖2\n2Tγ(T ) + L2f 2T T−1∑ t=1 γ(t), (18)\nwhere ET is the expectation over all possible sequence (g(t))1≤t≤T .\nMoreover, if one knows that D > 0 such that ‖θ∗‖ ≤ D, then for γ(t) = D Lf √ 2t , one has:\nET [ Rn(θ̄(T ))−Rn(θ∗) ] ≤ √\n2DLf√ T .\nProof. One only has to prove that the convexity inequality in Lemma 3 holds in expectation. The rest of the proof can be directly adapted from Theorem 3.\nLet T ≥ 2; using the convexity of f̄n, one obtains:\nET [f̄n(θ̄(T ))− f̄n(θ∗)] ≤ 1\nT T∑ t=1 ET [f̄n(θ(t))− f̄n(θ∗)].\nFor any 0 < t ≤ T , E[θ(t)|g(0), . . . , g(t− 1)] = θ(t). Therefore, we have:\nET [f̄n(θ(t))− f̄n(θ∗)] = Et−1[f̄n(θ(t))− f̄n(θ∗)].\nThe vector Et[g(t)|θ(t)] is the gradient of f̄n at θ(t), we can then use f̄n convexity to write: Et−1[f̄n(θ(t))− f̄n(θ∗)] ≤ Et−1 [ (θ(t)− θ∗)>Et[g(t)|θ(t)] ] .\nUsing properties of conditional expectation, we obtain: Et−1 [ (θ(t)− θ∗)>Et[g(t)|θ(t)] ] = Et−1 [ Et[(θ(t)− θ∗)>g(t)|θ(t)] ] = Et[(θ(t)− θ∗)>g(t)].\nFinally, we can write:\nET [f̄n(θ̄(T )− f(θ∗)] ≤ 1\nT T∑ t=1 Et[(θ(t)− θ∗)>g(t)] = ET\n[ 1\nT T∑ t=1 (θ(t)− θ∗)>g(t)\n] . (19)"
    }, {
      "heading" : "C. Convergence Proof for Synchronous Pairwise Gossip Dual Averaging",
      "text" : "In (Duchi et al., 2012), the following convergence rate for distributed dual averaging is established:\nRn(θ̄i(T ))−Rn(θ∗) ≤ 1\n2Tγ(T ) ‖θ∗‖2 + L2f 2T T∑ t=2 γ(t− 1)\n+ Lf nT T∑ t=2 γ(t− 1) n∑ j=1 ( ‖zi(t)− zj(t)‖+ ‖z̄n(t)− zj(t)‖ ) .\nThe first part is an optimization term, which is exactly the same as in the centralized setting. Then, the second part is a network-dependent term which depends on the global variation of the dual variables; the following lemma provides an explicit dependence between this term and the topology of the network.\nLemma 4. Let W (G) = In − L(G)|E| and let (G(t))t≥1 and (Z(t))t≥1 respectively be the gradients and the gradients cummulative sum of the distributed dual averaging algorithm. If G is connected and non bipartite, then one has for t ≥ 1:\n1\nn n∑ i=1 E‖zi(t)− zn(t)‖ ≤ Lf 1− √ λG2 ,\nwhere λG2 is the second largest eigenvalue of W (G).\nProof. For t ≥ 1, let W (t) be the random matrix such that if (i, j) ∈ E is picked at t, then\nW (t) = In − 1\n2 (ei − ej)(ei − ej)>.\nAs denoted in (Duchi et al., 2012), the update rule for Z can be expressed as follows:\nZ(t+ 1) = G(t) +W (t)Z(t),\nfor any t ≥ 1, reminding that G(0) = 0, Z(1) = 0. Therefore, one can obtain recursively\nZ(t) = t∑ s=0 W (t : s)G(s),\nwhere W (t : s) = W (t) . . .W (s + 1), with the convention W (t : t) = In. For any t ≥ 1, let W ′(t) := W (t) − 1n1 > n\nn .\nOne can notice that for any 0 ≤ s ≤ t, W ′(t : s) = W (t : s)− 1n1 > n\nn and write:\nZ(t)− 1nzn(t)> = t∑\ns=0\nW ′(t : s)G(s).\nWe now take the expected value of the Frobenius norm:\nE [∥∥Z(t)− 1nzn(t)>∥∥F ] ≤ t∑\ns=0\nE [‖W (t : s)G(s)‖F ]\n≤ t∑\ns=0\n√ E [ ‖W (t : s)G(s)‖2F ] =\nn∑ i=1 t∑ s=0 √ E [ g(i)(s)>W ′(t : s)>W ′(t : s)g(i)(s) ] ,\nwhere g(i)(s) is the column i of matrixG(s). Since for any s ≥ 0,W (s) is a symmetric projection matrix,W ′(s)>W ′(s) = W ′(s); moreover, conditioning over Fs leads to:\nE [ g(i)(s)>W ′(t : s)>W ′(t : s)g(i)(s) ] = E [ g(i)(s)>E[W ′(t : s)|Fs]g(i)(s) ] ≤ λG2 ‖g(i)(s)‖2. (20)\nUsing the fact that for any s ≥ 0, ‖G(s)‖2F ≤ nL2f , one has:\nE [∥∥Z(t)− 1nzn(t)>∥∥F ] ≤ √nLf t∑\ns=0\n( λG2 ) t−s 2 ≤ √ nLf\n1− √ λG2 .\nFinally, using the bounds between `1 and `2-norms yields:\n1\nn n∑ i=1 E‖zi(t)− zn(t)‖ ≤ 1√ n E ∥∥Z(t)− 1nzn(t)>∥∥F ≤ Lf 1− √ λG2 .\nWith this bound on the dual variables, one can reformulate the convergence rate as stated below.\nCorollary 1. Let G be a connected and non bipartite graph. Let (γ(t))t≥1 be a non-increasing and non-negative sequence. For i ∈ [n], let (gi(t))t≥1, (zi(t))t≥1 and (θi(t))t≥1 be generated according to the distributed dual averaging algorithm. For θ∗ ∈ arg minθ′∈Rd Rn(θ′), i ∈ [n] and T ≥ 2, one has:\nRn(θ̄i(T ))−Rn(θ∗) ≤ 1\n2Tγ(T ) ‖θ∗‖2 + L2f 2T T−1∑ t=1 γ(t)\n+ 3L2f\nT ( 1− √ λG2 ) T−1∑ t=1 γ(t),\nwhere λG2 < 1 is the second largest eigenvalue of W (G).\nWe now focus on gossip dual averaging for pairwise functions, as shown in Algorithm 2. The key observation is that, at each iteration, the descent direction is stochastic but also a biased estimate of the gradient. That is, instead of updating a dual variable zi(t) with gi(t) such that E[gi(t)|θi(t)] = ∇fi(θi(t)), we perform some update di(t), and we denote by i(t) the quantity such that E[di(t)− i(t)|θi(t)] = E[gi(t)|θi(t)] = ∇fi(θi(t)). The following theorem allows to upper-bound the error induced by the bias.\nTheorem 5. Let G be a connected and non bipartite graph. Let (γ(t))t≥1 be a non increasing and non-negative sequence. For i ∈ [n], let (di(t))t≥1, (gi(t))t≥1, ( i(t))t≥1, (zi(t))t≥1 and (θi(t))t≥1 be generated by Algorithm 2. Assume that the function f̄n is L-Lipschitz and that θ∗ ∈ arg minθ′∈Rd Rn(θ′), then for any i ∈ [n] and T ≥ 2, one has:\nET [Rn(θ̄i(T ))]−Rn(θ∗) ≤ 1\n2Tγ(T ) ‖θ∗‖2 + L2f 2T T−1∑ t=1 γ(t)\n+ 3L2f\nT ( 1− √ λG2 ) T−1∑ t=1 γ(t)\n+ 1\nT T−1∑ t=1 Et[(ω(t)− θ∗)>̄n(t)].\nProof. We can apply the same arguments as in the proofs of centralized and distributed dual averaging, so for T > 0 and i ∈ [n]:\nET [Rn(θ̄i(T ))]−Rn(θ∗) ≤ L\nnT T∑ t=2 γ(t− 1) n∑ j=1 E [ ‖zi(t)− zj(t)‖+ ‖z̄n(t)− zj(t)‖ ]\n+ 1\nT T∑ t=2 Et[(ω(t)− θ∗)>ḡn(t)].\nHowever, Lemma 3 can no longer be applied here since the updates are performed with dj(t) and not gj(t) = dj(t)− j(t). With the definition of dj(t), the former yields:\n1\nT T∑ t=2 Et[ω(t)− θ∗)>ḡn(t)] = 1 T T∑ t=2 Et[(ω(t)− θ∗)>(d̄n(t)− ̄n(t))].\nNow Lemma 3 can be applied to the first term in the right hand side and the result holds."
    }, {
      "heading" : "D. Asynchronous Distributed Setting",
      "text" : "In this section, we focus on a fully asynchronous setting where each node has a local clock. We assume for simplicity that each node has a clock ticking at a Poisson rate equals to 1, so it is equivalent to a global clock ticking at a Poisson rate of n, and then drawing an edge uniformly at random (see (Boyd et al., 2006) for more details). Under this assumption, we can state a method detailed in Algorithm 3.\nThe main difficulty in the asynchronous setting is that each node i has to use a time estimate mi instead of the global clock reference (that is no longer available in such a context). Even if the time estimate is unbiased, its variance puts an additional error term in the convergence rate. However, for an iteration T large enough, one can bound these estimates as stated bellow.\nLemma 5. There exists T1 > 0 such that for any t ≥ T1, any k ∈ [n] and any q > 0,\nt− := t− t 12+q ≤ mk(t) ≤ t+ t 1 2+q =: t+ a.s.\nProof. Let k ∈ [n]. For t ≥ 1, let us define δk(t) such that δk(t) = 1 if k is picked at iteration t and δk(t) = 0 otherwise. Then one has mk(t) = (1/pk) ∑t s=1 δk(t). Since (δk(t))t≥1 is a Bernoulli process of parameter 1/pk, by the law of\niterative logarithms (Dudley, 2010), (Nedić, 2011, Lemma 3) one has with probability 1 and for any q > 0\nlim t→+∞ |mk(t)− t| t 1 2+q = 0,\nand the result holds.\nTheorem 6. Let G be a connected and non bipartite graph. Let (γ(t))t≥1 be defined as γ(t) = c/t1/2+α for some constant c > 0 and α ∈ (0, 1/2). For i ∈ [n], let (di(t))t≥1, (gi(t))t≥1, ( i(t))t≥1, (zi(t))t≥1 and (θi(t))t≥1 be generated as stated previously. For θ∗ ∈ arg minθ′∈Rd Rn(θ′), i ∈ [n] and T > 0, one has for some C:\nRn(θ̄i(T ))−Rn(θ∗) ≤ C max(T−α/2, Tα−1/2) + 1\nT T∑ t=1 Et[ n(t)>ω(t)] . (21)\nProof. In the asynchronous case, for i ∈ [n] and t ≥ 1, one has\nθ̄i(T ) = 1\nmi(T ) T∑ t=1 δi(t) pi θi(t).\nThen, using the convexity of Rn, one has:\nET [Rn(θ̄i(T )]−Rn(θ∗) ≤ ET\n[ 1\nmi(T ) T∑ t=1 δi(t) pi Rn(θi(t))\n] −Rn(θ∗). (22)\nBy Lemma 5, one has for q > 0\nET [Rn(θ̄i(T )]−Rn(θ∗) ≤ 1\nT− T∑ t=1 ET [ δi(t) pi Rn(θi(t)) ] −Rn(θ∗).\nSimilarly to the synchronous case, one can write ET [ δi(t)\npi f̄n(θi(t))\n] = n∑ j=1 1 n ET [ δi(t) pi fj(θi(t)) ]\n= 1\nn n∑ j=1 ET [ δi(t) pi (fj(θi(t))− fj(θj(t)) ] + 1 n n∑ j=1 ET [ δi(t) pi fj(θj(t)) ] .\nIn order to use the gradient inequality, we need to introduce δj(t)fj(θj(t)) instead of δi(t)fj(θj(t)). For j ∈ [n], one has:\n1\nT− T∑ t=1 ET [ δi(t) pi fj(θj(t)) ] = 1 T− T∑ t=1 ET [( δi(t) pi − δj(t) pj ) fj(θj(t)) ] + 1 T− T∑ t=1 ET [ δj(t) pj fj(θj(t)) ] .\nLet Nj = ∑T t=1 δj(t) and let 1 ≤ t1 < . . . < tNj ≤ T be such that δj(tk) = 1 for k ∈ [Nj ]. One can write\n1\nT− T∑ t=1 ET [( δi(t) pi − δj(t) pj ) fj(θj(t)) ] = 1 T− ET Nj−1∑ k=1 (( tk+1−1∑ t=tk δi(t) pi ) − 1 pj ) fj(θj(tk))  + 1\nT− ET [( t1∑ t=0 δi(t) pi ) fj(θj(0)) ]\n+ 1\nT− ET  T∑ t=tNj δi(t) pi − 1 pj  fj(θj(tNj )) \n≤+ 1 T− ET Nj−1∑ k=1 (( tk+1−1∑ t=tk δi(t) pi ) − 1 pj ) fj(θj(tk))  + fj(0)\npipjT− + L2fET [γ(tNj − 1)] pipj . (23)\nWe need to study the behavior of δi and δj in the first term of the right hand side. One can check that\nET Nj−1∑ k=1 (( tk+1−1∑ t=tk δi(t) pi ) − 1 pj ) fj(θj(tk))  = ET Nj−1∑ k=1 ( E [ tk+1−1∑ t=tk δi(t) pi ∣∣∣∣∣tk, tk+1 ] − 1 pj ) fj(θj(tk))  . δi(t) will not have the same dependency in tk whether i and j are connected or not. Let us first assume that (i, j) ∈ E. Then,\nE[δi(tk)|tk] = E[δi(t)|δj(t) = 1] = 1\ndj .\nAlso, for tk < t < tk+1, we get:\nE[δi(t)|tk] = E[δi(t)|δj(t) = 0] = pi − 2/|E|\n1− pj .\nFinally, if (i, j) ∈ E, we obtain\nE [ tk+1−1∑ t=tk δi(t) pi ∣∣∣∣∣tk, tk+1 ] = ( 1 dj + (tk+1 − tk − 1) pi − 2/|E| 1− pj ) 1 pi .\nBefore using this relation in the full expectation, let us denote that since tk+1 − tk is independent from tk, one can write\nE\n[( 1\ndj + (tk+1 − tk − 1) pi − 2/|E| 1− pj\n) 1\npi\n∣∣∣∣∣tk ] = ( 1 dj + ( 1− pj pj ) pi − 2/|E| 1− pj ) 1 pi = 1 pj .\nWe can now use this relation in the full expectation\nET [( δi(t)\npi − δj(t) pj\n) fj(θj(t)) ] = ET Nj−1∑ k=1 ( E [ E [ tk+1−1∑ t=tk δi(t) pi ∣∣∣∣∣tk+1 − tk ] ∣∣∣∣∣tk ] − 1 pj ) fj(θj(tk))  = 0. (24) Similarly if (i, j) 6∈ E, one has\nE[δi(tk)|tk] = E[δi(t)|δj(t) = 1] = 0,\nand for tk < t < tk+1,\nE[δi(t)|tk] = E[δi(t)|δj(t) = 0] = pi\n1− pj ,\nso the result of Equation (24) holds in this case. We have just shown that for every j ∈ [n], we can use δj(t)fj(θj(t))/pj instead of δi(t)fj(θj(t))/pi . Combining (22) and (23) yields:\nET [Rn(θ̄i(T ))]−Rn(θ∗) ≤ 1\nnT− T∑ t=2 n∑ j=1 ET [ δi(t) pi (fj(θi(t))− fj(θj(t)) ] (25)\n+ 1\nnT− T∑ t=2 n∑ j=1 ET [ δj(t) pj (fj(θj(t))− fj(θ∗)) ] (26)\n+ 1\nT− T∑ t=2 ET [ δi(t) pi (ψ(θi(t))− ψ(θ∗)) ] (27)\n+ fj(0) pipjT− + L2fET [γ(tNj − 1)] pipj . (28)\nLet us focus on the second term of the right hand side. For t ≥ 2, one can write\n1\nn n∑ j=1 ET [ δj(t) pj (fj(θj(t))− fj(θ∗)) ] ≤ 1 n n∑ j=1 ET [ δj(t) pj gj(t) >(θj(t)− θ∗) ]\n= 1\nn n∑ j=1 ET [ δj(t) pj gj(t) >(θj(t)− ω(t)) ]\n(29)\n+ 1\nn n∑ j=1 ET [ δj(t) pj gj(t) >(ω(t)− θ∗) ]\n(30)\n• Here we control the term from (30) using ω(t) := πmi(t)(z̄n(t))\n1\nn n∑ j=1 ET [ δj(t) pj gj(t) >(ω(t)− θ∗) ] = ET   1 n n∑ j=1 δj(t) pj gj(t) > (ω(t)− θ∗) \n= ET [ ḡn(t)>(ω(t)− θ∗) ] ,\nand the reasoning of the synchronous case can be applied to obtain\n1\nnT− T∑ t=2 n∑ j=1 ET [ δj(t) pj gj(t) >(ω(t)− θ∗) ] ≤ L2f 2T− T∑ t=2 γ(t− 1) + ‖θ ∗‖2 2γ(T )\n+ 1\nT T∑ t=2 Et[ n(t)>ω(t)]\n+ 1\nT− T∑ t=2 (ψ(θ∗)− ET [ψ(ω(t))]). (31)\nLet us regroup the term from (31) and (27) together:\n1\nT− T∑ t=2 ET [ δi(t) pi (ψ(θi(t))− ψ(θ∗)) ] + 1 T− T∑ t=2 (ψ(θ∗)− ET [ψ(ω(t))]) = 1 T− T∑ t=2 ET [ δi(t) pi ψ(θi(t))− ψ(ω(t)) ]\n= 1\nT− T∑ t=2 ET [ δi(t) pi (ψ(θi(t))− ψ(ω(t))) ]\n+ 1\nT− T∑ t=2 ET [ ( δi(t) pi − 1)ψ(ω(t)) ]\n= 1\nT− T∑ t=2 ET [ δi(t) pi (ψ(θi(t))− ψ(ω(t))) ] ,\n(32)\nwhere we have used for the last term the same arguments as in (24) to state 1T− ∑T t=2 ET [ ( δi(t)pi − 1)ψ(ω(t)) ] = 0. Then, one can use the fact that πt is γ(t)-Lipschitz to write:\n1\npiT− T∑ t=2 ET [ 2Lfγ(mi(t− 1))‖z̄n(t)− zi(t)‖+ γ(mi(t− 1))‖z̄n(t)− zi(t)‖2 2(mi(t− 1)) ] .\nProvided that γ(t) ≤ C√ t for some constant C, then using Lemma 5 we can bound this term by C ′ √ T .\n• Now we control the term in (29) as follows:\n1\nn n∑ j=1 ET [ δj(t) pj gj(t) >(θj(t)− ω(t)) ] ≤ Lf npj n∑ j=1 ET [‖θj(t)− ω(t)‖] (33)\n≤ Lf npj n∑ j=1 ET [ ‖θj(t)− θ̃j(t)‖+ ‖θ̃j(t)− ω(t)‖ ] (34)\n≤ Lf npj n∑ j=1 ET [ γ(mj(t− 1))‖zj(t)− z̄n(t)‖+ ‖θ̃j(t)− ω(t)‖ ] . (35)\nwhere θ̃j(t) = πmj(t−1)(−z̄n(t)). We can apply Lemma 6 with the choice θ1 = θ̃j(t), θ2 = ω(t), t1 = mj(t), t2 = mi(t) and z = z̄n(t).\n‖ω(t)− θ̃j(t)‖ ≤‖z̄n(t)‖ ( |γ(mi(t))− γ(mj(t))|+(\n3 2 + max( γ(mj(t)) γ(mi(t)) , γ(mi(t)) γ(mj(t)) )\n)( 1\nmj(t) +\n1\nmi(t)\n) |mj(t)γ(mj(t))−mi(t)γ(mi(t))| ) . (36)\nWe use Lemma 5 with the choice q = α/2, so we can bound for t large enough the former expression by a term of order ‖z̄n(t)‖|γ(mi(t))− γ(mj(t))|. Note also that ‖z̄n(t)‖ ≤ Lf maxk=1,...,nmk(t), so for t large enough we obtain:\n‖ω(t)− θ̃j(t)‖ ≤ LF t+|γ(t−)− γ(t+)| . (37)\nWith the additional constraint that γ(t) = Ct−1/2−α, ‖ω(t)− θ̃j(t)‖ is bounded by C ′t−α/2 for t large enough, and so is 1 n ∑n j=1 ET [ δj(t) pj gj(t) >(θj(t)− ω(t)) ] .\n• To control the term in (25) we use that fj is Lf -Lipschitz\n|fj(θi(t))− fj(θj(t)| ≤Lf‖θi(t)− θj(t)‖ (38) ≤Lf (‖θi(t)− ω(t)‖+ ‖ω(t)− θj(t)‖). (39)\nand we use now the same control as for (33), hence the result.\nLemma 6. Let γ : R+ → R+ be a non-increasing positive function and let z ∈ Rd. For any t1, t2 > 0, one has ‖θ2 − θ1‖ ≤‖z‖ ( |γ(t2)− γ(t1)|+ ( 3\n2 + max(\nγ(t1) γ(t2) , γ(t2) γ(t1) )\n)( 1\nt1 +\n1\nt2\n) |t1γ(t1)− t2γ(t2)| ) , (40)\nwhere\nθ1 = πt1(z) := arg max θ∈Rd\n{ z>θ − ‖θ‖ 2\n2γ(t1) − t1ψ(θ) } θ2 = πt2(z) := arg max\nθ∈Rd\n{ z>θ − ‖θ‖ 2\n2γ(t2) − t2ψ(θ)\n} .\nProof. Using the optimality property of the minimizers, for any s1 ∈ ∂ψ(θ1) (resp. s2 ∈ ∂ψ(θ2)):\n(γ(t1)z − t1γ(t1)s1 − θ1)>(θ2 − θ1) ≤ 0 (γ(t2)z − t2γ(t2)s2 − θ2)>(θ1 − θ2) ≤ 0\nRe-arranging the terms, and using properties of sub-gradients yields:\n‖θ2 − θ1‖2 ≤(γ(t2)− γ(t1))z>(θ2 − θ1) + (t1γ(t1)s1 − t2γ(t2)s2)>(θ2 − θ1) (41) ≤(γ(t2)− γ(t1))z>(θ2 − θ1) + (t1γ(t1)− t2γ(t2))(ψ(θ2)− ψ(θ1)) (42)\nAlso, using the definition of θ1 and θ2, one has: |ψ(θ1)− ψ(θ1)| ≤ ‖z‖‖θ1 − θ2‖ ( 3\n2 + max(\nγ(t1) γ(t2) , γ(t2) γ(t1) )\n)( 1\nt1 +\n1\nt2\n) . (43)\nWith relation (41) and (43) we bound the distance between θ1 and θ2 as follows:\n‖θ2 − θ1‖ ≤‖z‖ ( |γ(t2)− γ(t1)|+ ( 3\n2 + max(\nγ(t1) γ(t2) , γ(t2) γ(t1) )\n)( 1\nt1 +\n1\nt2\n) |t1γ(t1)− t2γ(t2)| ) (44)"
    }, {
      "heading" : "E. Extension to Multiple Points per Node",
      "text" : "For ease of presentation, we have assumed throughout the paper that each node i holds a single data point xi. In this section, we discuss simple extensions of our results to the case where each node holds the same number of points k ≥ 2. First, it is easy to see that our results still hold if nodes swap their entire set of k points (essentially viewing the set of k points as a single one). However, depending on the network bandwidth, this solution may be undesirable.\nWe thus propose another strategy where only two data points are exchanged at each iteration, as in the algorithms proposed in the main text. The idea is to view each “physical” node i ∈ V as a set of k “virtual” nodes, each holding a single observation. These k nodes are all connected to each other as well as to the neighbors of i in the initial graph G and their virtual nodes. Formally, this new graph G⊗ = (V ⊗, E⊗) is given by G × Kk, the tensor product between G and the k-node complete graph Kk. It is easy to see that |V ⊗| = kn and |E⊗| = k2|E|. We can then run our algorithms on G⊗ (each physical node i ∈ V simulating the behavior of its corresponding k virtual nodes) and the convergence results hold, replacing 1− λG2 by 1− λG ⊗ 2 in the bounds. The following result gives the relationship between these two quantities. Proposition 1. Let G be a connected, non-bipartite and non-complete graph with n nodes. Let k ≥ 2 and let G⊗ be the tensor product graph of G and Kk. Let 1− λG2 = βGn−1/|E| and 1− λG ⊗ 2 = β G⊗ kn−1/|E⊗|, where β G n−1 and β G⊗ kn−1 are the second smallest eigenvalues of L(G) and L(G⊗) respectively. We have that\n1− λG ⊗ 2 = 1\nk\n( 1− λG2 ) .\nProof. Let A ∈ {0, 1}n×n and A⊗ ∈ {0, 1}nk×nk be the adjacency matrices of G and G⊗ respectively. Similarly, let D ∈ Nn×n and D⊗ ∈ Nnk×nk be the diagonal degree matrices of G and G⊗ respectively, i.e., Dii = ∑n j=1Aij and\nD⊗ii = ∑nk j=1A ⊗ ij . Denoting the Kronecker product by ⊗, we can write:\nA⊗ = 1k1 T k ⊗A, D⊗ = kIk ⊗D.\nRecall that L(G) = D −A and L(G⊗) = D⊗ −A⊗.\nLet (v, βG ⊗ ) ∈ Rnk×R be an eigenpair of L(G⊗), i.e., (D⊗−A⊗)v = βG⊗v and v 6= 0nk. Let us write v = [v1 . . . vk]> where v1, . . . , vk ∈ Rn. Exploiting the structure of A⊗ and D⊗, we have:\nkDvi − k∑ j=1 Avj = β G⊗vi, ∀i ∈ {1, . . . , k}. (45)\nSumming up (45) over all i ∈ {1, . . . , k} gives\nD k∑ i=1 vi −A k∑ i=1 vi = βG ⊗ k k∑ i=1 vi,\nwhich shows that if (v, βG ⊗ ) is an eigenpair of L(G⊗) with ∑k i=1 vi 6= 0n, then ( ∑k i=1 vi, β\nG⊗/k) is an eigenpair of L(G). In the case where ∑k i=1 vi = 0n, then there exists an index j ∈ {1, . . . , k} such that vj = − ∑ i 6=j vj 6= 0n. Hence (45) gives\nDvj = βG ⊗\nk vj ,\nwhich shows that (vj , βG ⊗ /k) is an eigenpair of L(G). Observe that βG⊗ = kdi for some i ∈ {1, . . . , n}.\nWe have thus shown that any eigenvalue βG ⊗ of L(G⊗) is either of the form βG⊗ = kβG , where βG is an eigenvalue of L(G), or of the form βG⊗ = kdi for some i ∈ {1, . . . , n}.\nSince L(G⊗) is a Laplacian matrix, its smallest eigenvalue is 0. Let βG ⊗\nnk−1 be the second smallest eigenvalue of L(G⊗). Note that G⊗ is not a complete graph since G is not complete. Therefore, βG ⊗\nnk−1 is bounded above by the vertex connectivity of G⊗ (Fiedler, 1973), which is itself trivially bounded above by the minimum degree d⊗min = min kn i=1D ⊗ ii of G\n⊗. This implies that βG ⊗\nnk−1 = kβ G n−1, and hence\n1− λG ⊗ 2 = βG ⊗\nkn−1 |E⊗| = kβGn−1 k2|E| = 1 k (1− λG2 ).\nProposition 1 shows that the network-dependent term in our convergence bounds is only affected by a factor k. Furthermore, note that iterations involving two virtual nodes corresponding to the same physical node will not require actual network communication, which somewhat attenuates this effect in practice."
    }, {
      "heading" : "F. Additional experiments",
      "text" : "In this section, we present additional results of decentralized metric learning. First, we discuss the comparison to the unbiased basline for metric learning on the synthetic dataset introduced in Section 4. Then, we analyze numerical experiments of decentralized metric learning on the Breast Cancer Wisconsin dataset3.\n3https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+(Original)\nSynthetic Dataset In Section 4, we discussed the results of decentralized metric learning over a synthetic dataset of n = 1, 000 points generated from a mixture of 10 Gaussians in R40 such that all gaussian means are contained in a 5d subspace.\nWe compare the logistic loss associated to our algorithm’s iterates to the loss associated to the following baseline: instead of adding ∇f(θi(t);xi, yi(t)) to its dual variable zi(t), a node i ∈ [n] receives a vector drawn uniformly at random from the set {∇f(θi(t);xi, x1), . . . ,∇f(θi(t);xi, xn)}. The bias introduced by the random walk procedure is already shown to be very small in comparison to the objective function on Figure 3(b). Here, Figure 4 evidences the fact that this small bias has close to no influence on the optimization process for well-connected networks.\nBreast Cancer Wisconsin Dataset We now focus on decentralized metric learning on the Breast Cancer Wisconsin Dataset already used in Section 4 for AUC maximization. This dataset contains n = 699 observations of dimension 11. Figure 5(a) shows the evolution of the metric learning criterion with the number of iterations, averaged over 50 runs. As in previous experiments, there is almost no difference between the convergence rate of the Watts-Strogatz network and the complete network. Moreover, the bias term is again largely negligible when compared to the metric learning criterion, as shown on Figure 5(b)."
    }, {
      "heading" : "Acknowledgments",
      "text" : "This work was partially supported by the chair “Machine Learning for Big Data” of Télécom ParisTech and by a grant from CPER Nord-Pas de Calais/FEDER DATA Advanced data science and technologies 2015-2020."
    } ],
    "references" : [ {
      "title" : "Metric Learning",
      "author" : [ "Bellet", "Aurélien", "Habrard", "Amaury", "Sebban", "Marc" ],
      "venue" : null,
      "citeRegEx" : "Bellet et al\\.,? \\Q2015\\E",
      "shortCiteRegEx" : "Bellet et al\\.",
      "year" : 2015
    }, {
      "title" : "Convergence of a Multi-Agent Projected Stochastic Gradient Algorithm for Non-Convex Optimization",
      "author" : [ "Bianchi", "Pascal", "Jakubowicz", "Jérémie" ],
      "venue" : "IEEE Trans. Autom. Control,",
      "citeRegEx" : "Bianchi et al\\.,? \\Q2013\\E",
      "shortCiteRegEx" : "Bianchi et al\\.",
      "year" : 2013
    }, {
      "title" : "Statistical Inference on Graphs",
      "author" : [ "Biau", "Gérard", "Bleakley", "Kevin" ],
      "venue" : "Statistics & Decisions,",
      "citeRegEx" : "Biau et al\\.,? \\Q2006\\E",
      "shortCiteRegEx" : "Biau et al\\.",
      "year" : 2006
    }, {
      "title" : "Modern Graph Theory, volume 184",
      "author" : [ "Bollobás", "Béla" ],
      "venue" : null,
      "citeRegEx" : "Bollobás and Béla.,? \\Q1998\\E",
      "shortCiteRegEx" : "Bollobás and Béla.",
      "year" : 1998
    }, {
      "title" : "Randomized gossip algorithms",
      "author" : [ "Boyd", "Stephen", "Ghosh", "Arpita", "Prabhakar", "Balaji", "Shah", "Devavrat" ],
      "venue" : "IEEE Trans. Inf. Theory,",
      "citeRegEx" : "Boyd et al\\.,? \\Q2006\\E",
      "shortCiteRegEx" : "Boyd et al\\.",
      "year" : 2006
    }, {
      "title" : "Spectral Graph Theory, volume 92",
      "author" : [ "Chung", "Fan" ],
      "venue" : "Amer. Math. Soc.,",
      "citeRegEx" : "Chung and Fan.,? \\Q1997\\E",
      "shortCiteRegEx" : "Chung and Fan.",
      "year" : 1997
    }, {
      "title" : "Ranking and Empirical Minimization of U-statistics",
      "author" : [ "Clémençon", "Stéphan", "Lugosi", "Gàbor", "Vayatis", "Nicolas" ],
      "venue" : "Ann. Stat.,",
      "citeRegEx" : "Clémençon et al\\.,? \\Q2008\\E",
      "shortCiteRegEx" : "Clémençon et al\\.",
      "year" : 2008
    }, {
      "title" : "Extending Gossip Algorithms to Distributed Estimation of U-Statistics",
      "author" : [ "I. Colin", "A. Bellet", "J. Salmon", "S. Clémençon" ],
      "venue" : "In NIPS,",
      "citeRegEx" : "Colin et al\\.,? \\Q2015\\E",
      "shortCiteRegEx" : "Colin et al\\.",
      "year" : 2015
    }, {
      "title" : "Dual Averaging for Distributed Optimization: Convergence Analysis and Network Scaling",
      "author" : [ "Duchi", "John", "Agarwal", "Alekh", "Wainwright", "Martin" ],
      "venue" : "IEEE Trans. Autom. Control,",
      "citeRegEx" : "Duchi et al\\.,? \\Q2012\\E",
      "shortCiteRegEx" : "Duchi et al\\.",
      "year" : 2012
    }, {
      "title" : "Distances of probability measures and random variables",
      "author" : [ "Dudley", "Richard M" ],
      "venue" : "Selected Works of RM Dudley, pp",
      "citeRegEx" : "Dudley and M.,? \\Q2010\\E",
      "shortCiteRegEx" : "Dudley and M.",
      "year" : 2010
    }, {
      "title" : "Algebra connectivity of graphs",
      "author" : [ "Fiedler", "Miroslav" ],
      "venue" : "Czechoslovake Mathematical Journal,",
      "citeRegEx" : "Fiedler and Miroslav.,? \\Q1973\\E",
      "shortCiteRegEx" : "Fiedler and Miroslav.",
      "year" : 1973
    }, {
      "title" : "Asynchronous Distributed Optimization using a Randomized Alternating Direction Method of Multipliers",
      "author" : [ "Iutzeler", "Franck", "Bianchi", "Pascal", "Ciblat", "Philippe", "Hachem", "Walid" ],
      "venue" : "In IEEE CDC,",
      "citeRegEx" : "Iutzeler et al\\.,? \\Q2013\\E",
      "shortCiteRegEx" : "Iutzeler et al\\.",
      "year" : 2013
    }, {
      "title" : "Regularized Distance Metric Learning: Theory and Algorithm",
      "author" : [ "R. Jin", "S. Wang", "Y. Zhou" ],
      "venue" : "In NIPS, pp",
      "citeRegEx" : "Jin et al\\.,? \\Q2009\\E",
      "shortCiteRegEx" : "Jin et al\\.",
      "year" : 2009
    }, {
      "title" : "A Randomized Incremental Subgradient Method for Distributed Optimization in Networked Systems",
      "author" : [ "Johansson", "Björn", "Rabi", "Maben", "Mikael" ],
      "venue" : "SIAM J. Optimiz.,",
      "citeRegEx" : "Johansson et al\\.,? \\Q2010\\E",
      "shortCiteRegEx" : "Johansson et al\\.",
      "year" : 2010
    }, {
      "title" : "Gossip-Based Computation of Aggregate Information",
      "author" : [ "Kempe", "David", "Dobra", "Alin", "Gehrke", "Johannes" ],
      "venue" : "In FOCS, pp",
      "citeRegEx" : "Kempe et al\\.,? \\Q2003\\E",
      "shortCiteRegEx" : "Kempe et al\\.",
      "year" : 2003
    }, {
      "title" : "A Binary Classification Framework for Two-Stage Multiple Kernel Learning",
      "author" : [ "Kumar", "Abhishek", "Niculescu-Mizil", "Alexandru", "K. Kavukcuoglu", "Daumé", "Hal" ],
      "venue" : "In ICML,",
      "citeRegEx" : "Kumar et al\\.,? \\Q2012\\E",
      "shortCiteRegEx" : "Kumar et al\\.",
      "year" : 2012
    }, {
      "title" : "Decentralized online optimization with global objectives and local communication",
      "author" : [ "Lee", "Soomin", "Nedić", "Angelia", "Raginsky", "Maxim" ],
      "venue" : "arXiv preprint arXiv:1508.07933,",
      "citeRegEx" : "Lee et al\\.,? \\Q2015\\E",
      "shortCiteRegEx" : "Lee et al\\.",
      "year" : 2015
    }, {
      "title" : "Asynchronous broadcast-based convex optimization over a network",
      "author" : [ "Nedić", "Angelia" ],
      "venue" : "Automatic Control, IEEE Transactions on,",
      "citeRegEx" : "Nedić and Angelia.,? \\Q2011\\E",
      "shortCiteRegEx" : "Nedić and Angelia.",
      "year" : 2011
    }, {
      "title" : "Distributed Subgradient Methods for Multi-Agent Optimization",
      "author" : [ "Nedić", "Angelia", "Ozdaglar", "Asuman E" ],
      "venue" : "IEEE Trans. Autom. Control,",
      "citeRegEx" : "Nedić et al\\.,? \\Q2009\\E",
      "shortCiteRegEx" : "Nedić et al\\.",
      "year" : 2009
    }, {
      "title" : "Primal-dual subgradient methods for convex problems",
      "author" : [ "Nesterov", "Yurii" ],
      "venue" : "Math. Program.,",
      "citeRegEx" : "Nesterov and Yurii.,? \\Q2009\\E",
      "shortCiteRegEx" : "Nesterov and Yurii.",
      "year" : 2009
    }, {
      "title" : "Gossip Algorithms for Computing U-Statistics",
      "author" : [ "Pelckmans", "Kristiaan", "Suykens", "Johan" ],
      "venue" : "In NecSys, pp",
      "citeRegEx" : "Pelckmans et al\\.,? \\Q2009\\E",
      "shortCiteRegEx" : "Pelckmans et al\\.",
      "year" : 2009
    }, {
      "title" : "Distributed Stochastic Subgradient Projection Algorithms for Convex Optimization",
      "author" : [ "S. Ram", "Nedić", "Angelia", "V. Veeravalli" ],
      "venue" : "J. Optimiz. Theory. App.,",
      "citeRegEx" : "Ram et al\\.,? \\Q2010\\E",
      "shortCiteRegEx" : "Ram et al\\.",
      "year" : 2010
    }, {
      "title" : "Push-Sum Distributed Dual Averaging for convex optimization",
      "author" : [ "Tsianos", "Konstantinos", "Lawlor", "Sean", "Rabbat", "Michael" ],
      "venue" : "In IEEE CDC,",
      "citeRegEx" : "Tsianos et al\\.,? \\Q2015\\E",
      "shortCiteRegEx" : "Tsianos et al\\.",
      "year" : 2015
    }, {
      "title" : "Problems in decentralized decision making and computation",
      "author" : [ "Tsitsiklis", "John" ],
      "venue" : "PhD thesis, Massachusetts Institute of Technology,",
      "citeRegEx" : "Tsitsiklis and John.,? \\Q1984\\E",
      "shortCiteRegEx" : "Tsitsiklis and John.",
      "year" : 1984
    }, {
      "title" : "Collective dynamics of ‘small-world’networks",
      "author" : [ "Watts", "Duncan J", "Strogatz", "Steven H" ],
      "venue" : "Nature, 393(6684):440–442,",
      "citeRegEx" : "Watts et al\\.,? \\Q1998\\E",
      "shortCiteRegEx" : "Watts et al\\.",
      "year" : 1998
    }, {
      "title" : "Distributed Alternating Direction Method of Multipliers",
      "author" : [ "Wei", "Ermin", "Ozdaglar", "Asuman" ],
      "venue" : "In IEEE CDC,",
      "citeRegEx" : "Wei et al\\.,? \\Q2012\\E",
      "shortCiteRegEx" : "Wei et al\\.",
      "year" : 2012
    }, {
      "title" : "On the O(1/k) Convergence of Asynchronous Distributed Alternating Direction Method of Multipliers",
      "author" : [ "Wei", "Ermin", "Ozdaglar", "Asuman" ],
      "venue" : "In IEEE GlobalSIP,",
      "citeRegEx" : "Wei et al\\.,? \\Q2013\\E",
      "shortCiteRegEx" : "Wei et al\\.",
      "year" : 2013
    }, {
      "title" : "Dual averaging method for regularized stochastic learning and online optimization",
      "author" : [ "Xiao", "Lin" ],
      "venue" : "In NIPS, pp",
      "citeRegEx" : "Xiao and Lin.,? \\Q2009\\E",
      "shortCiteRegEx" : "Xiao and Lin.",
      "year" : 2009
    }, {
      "title" : "Dual averaging methods for regularized stochastic learning and online optimization",
      "author" : [ "Xiao", "Lin" ],
      "venue" : "JMLR, 11:2543–2596,",
      "citeRegEx" : "Xiao and Lin.,? \\Q2010\\E",
      "shortCiteRegEx" : "Xiao and Lin.",
      "year" : 2010
    }, {
      "title" : "Distributed dual averaging method for multi-agent optimization with quantized communication",
      "author" : [ "Yuan", "Deming", "Xu", "Shengyuan", "Zhao", "Huanyu", "Rong", "Lina" ],
      "venue" : "Systems & Control Letters,",
      "citeRegEx" : "Yuan et al\\.,? \\Q2012\\E",
      "shortCiteRegEx" : "Yuan et al\\.",
      "year" : 2012
    }, {
      "title" : "Online AUC Maximization",
      "author" : [ "Zhao", "Peilin", "Hoi", "Steven", "Jin", "Rong", "Yang", "Tianbao" ],
      "venue" : "In ICML,",
      "citeRegEx" : "Zhao et al\\.,? \\Q2011\\E",
      "shortCiteRegEx" : "Zhao et al\\.",
      "year" : 2011
    } ],
    "referenceMentions" : [ {
      "referenceID" : 4,
      "context" : "In contrast, gossip algorithms (Tsitsiklis, 1984; Boyd et al., 2006; Kempe et al., 2003; Shah, 2009) are tailored to this setting because they only rely on simple peer-to-peer communication: each agent only exchanges information with one neighbor at a time.",
      "startOffset" : 31,
      "endOffset" : 100
    }, {
      "referenceID" : 14,
      "context" : "In contrast, gossip algorithms (Tsitsiklis, 1984; Boyd et al., 2006; Kempe et al., 2003; Shah, 2009) are tailored to this setting because they only rely on simple peer-to-peer communication: each agent only exchanges information with one neighbor at a time.",
      "startOffset" : 31,
      "endOffset" : 100
    }, {
      "referenceID" : 13,
      "context" : "The most popular algorithms are based on (sub)gradient descent (Johansson et al., 2010; Nedić & Ozdaglar, 2009; Ram et al., 2010; Bianchi & Jakubowicz, 2013), ADMM (Wei & Ozdaglar, 2012; 2013; Iutzeler et al.",
      "startOffset" : 63,
      "endOffset" : 157
    }, {
      "referenceID" : 21,
      "context" : "The most popular algorithms are based on (sub)gradient descent (Johansson et al., 2010; Nedić & Ozdaglar, 2009; Ram et al., 2010; Bianchi & Jakubowicz, 2013), ADMM (Wei & Ozdaglar, 2012; 2013; Iutzeler et al.",
      "startOffset" : 63,
      "endOffset" : 157
    }, {
      "referenceID" : 11,
      "context" : ", 2010; Bianchi & Jakubowicz, 2013), ADMM (Wei & Ozdaglar, 2012; 2013; Iutzeler et al., 2013) or dual averaging (Duchi et al.",
      "startOffset" : 42,
      "endOffset" : 93
    }, {
      "referenceID" : 8,
      "context" : ", 2013) or dual averaging (Duchi et al., 2012; Yuan et al., 2012; Lee et al., 2015; Tsianos et al., 2015), some of which can also accommodate constraints or regularization on θ.",
      "startOffset" : 26,
      "endOffset" : 105
    }, {
      "referenceID" : 29,
      "context" : ", 2013) or dual averaging (Duchi et al., 2012; Yuan et al., 2012; Lee et al., 2015; Tsianos et al., 2015), some of which can also accommodate constraints or regularization on θ.",
      "startOffset" : 26,
      "endOffset" : 105
    }, {
      "referenceID" : 16,
      "context" : ", 2013) or dual averaging (Duchi et al., 2012; Yuan et al., 2012; Lee et al., 2015; Tsianos et al., 2015), some of which can also accommodate constraints or regularization on θ.",
      "startOffset" : 26,
      "endOffset" : 105
    }, {
      "referenceID" : 22,
      "context" : ", 2013) or dual averaging (Duchi et al., 2012; Yuan et al., 2012; Lee et al., 2015; Tsianos et al., 2015), some of which can also accommodate constraints or regularization on θ.",
      "startOffset" : 26,
      "endOffset" : 105
    }, {
      "referenceID" : 30,
      "context" : ", Area Under the ROC Curve (AUC) maximization (Zhao et al., 2011), distance/similarity learning (Bellet et al.",
      "startOffset" : 46,
      "endOffset" : 65
    }, {
      "referenceID" : 0,
      "context" : ", 2011), distance/similarity learning (Bellet et al., 2015), ranking (Clémençon et al.",
      "startOffset" : 38,
      "endOffset" : 59
    }, {
      "referenceID" : 6,
      "context" : ", 2015), ranking (Clémençon et al., 2008), supervised graph inference (Biau & Bleakley, 2006) and multiple kernel learning (Kumar et al.",
      "startOffset" : 17,
      "endOffset" : 41
    }, {
      "referenceID" : 15,
      "context" : ", 2008), supervised graph inference (Biau & Bleakley, 2006) and multiple kernel learning (Kumar et al., 2012), to name a few.",
      "startOffset" : 89,
      "endOffset" : 109
    }, {
      "referenceID" : 7,
      "context" : "Although gossip algorithms have recently been introduced to evaluate such pairwise functions for a fixed θ (Pelckmans & Suykens, 2009; Colin et al., 2015), to the best of our knowledge, efficiently finding the optimal solution θ in a decentralized way remains an open challenge.",
      "startOffset" : 107,
      "endOffset" : 154
    }, {
      "referenceID" : 30,
      "context" : "For instance, in AUC maximization (Zhao et al., 2011), binary labels (`1, .",
      "startOffset" : 34,
      "endOffset" : 53
    }, {
      "referenceID" : 0,
      "context" : "Other popular instances of Problem (2) include metric learning (Bellet et al., 2015), ranking (Clémençon et al.",
      "startOffset" : 63,
      "endOffset" : 84
    }, {
      "referenceID" : 6,
      "context" : ", 2015), ranking (Clémençon et al., 2008), supervised graph inference (Biau & Bleakley, 2006) and multiple kernel learning (Kumar et al.",
      "startOffset" : 17,
      "endOffset" : 41
    }, {
      "referenceID" : 15,
      "context" : ", 2008), supervised graph inference (Biau & Bleakley, 2006) and multiple kernel learning (Kumar et al., 2012).",
      "startOffset" : 89,
      "endOffset" : 109
    }, {
      "referenceID" : 7,
      "context" : "To go around this problem, we rely on a gossip data propagation step (Pelckmans & Suykens, 2009; Colin et al., 2015) so that the nodes are able to compute biased estimates of ∇fi(·) while keeping the communication and memory overhead to a small level for each node.",
      "startOffset" : 69,
      "endOffset" : 116
    }, {
      "referenceID" : 7,
      "context" : "Our work builds upon the analysis of Duchi et al. (2012), who proposed a distributed dual averaging algorithm to optimize an average of univariate functions f(·;xi).",
      "startOffset" : 37,
      "endOffset" : 57
    }, {
      "referenceID" : 8,
      "context" : "Note that C2(T ) corresponds to the network dependence for the distributed dual averaging algorithm of Duchi et al. (2012) while the term C3(T ) comes from the bias of our partial gradient estimates.",
      "startOffset" : 103,
      "endOffset" : 123
    }, {
      "referenceID" : 8,
      "context" : "In the asynchronous setting, no convergence rate was known even for the distributed dual averaging algorithm of Duchi et al. (2012), which deals with the simpler problem of minimizing univariate functions.",
      "startOffset" : 112,
      "endOffset" : 132
    }, {
      "referenceID" : 12,
      "context" : "following criterion (Jin et al., 2009):",
      "startOffset" : 20,
      "endOffset" : 38
    }, {
      "referenceID" : 8,
      "context" : "Convergence Proof for Synchronous Pairwise Gossip Dual Averaging In (Duchi et al., 2012), the following convergence rate for distributed dual averaging is established:",
      "startOffset" : 68,
      "endOffset" : 88
    }, {
      "referenceID" : 8,
      "context" : "As denoted in (Duchi et al., 2012), the update rule for Z can be expressed as follows:",
      "startOffset" : 14,
      "endOffset" : 34
    }, {
      "referenceID" : 4,
      "context" : "We assume for simplicity that each node has a clock ticking at a Poisson rate equals to 1, so it is equivalent to a global clock ticking at a Poisson rate of n, and then drawing an edge uniformly at random (see (Boyd et al., 2006) for more details).",
      "startOffset" : 211,
      "endOffset" : 230
    } ],
    "year" : 2016,
    "abstractText" : "In decentralized networks (of sensors, connected objects, etc.), there is an important need for efficient algorithms to optimize a global cost function, for instance to learn a global model from the local data collected by each computing unit. In this paper, we address the problem of decentralized minimization of pairwise functions of the data points, where these points are distributed over the nodes of a graph defining the communication topology of the network. This general problem finds applications in ranking, distance metric learning and graph inference, among others. We propose new gossip algorithms based on dual averaging which aims at solving such problems both in synchronous and asynchronous settings. The proposed framework is flexible enough to deal with constrained and regularized variants of the optimization problem. Our theoretical analysis reveals that the proposed algorithms preserve the convergence rate of centralized dual averaging up to an additive bias term. We present numerical simulations on Area Under the ROC Curve (AUC) maximization and metric learning problems which illustrate the practical interest of our approach.",
    "creator" : "LaTeX with hyperref package"
  }
}