{
  "name" : "1407.1082.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "Online Submodular Maximization under a Matroid Constraint with Application to Learning Assignments",
    "authors" : [ "Daniel Golovin", "Andreas Krause", "Matthew Streeter" ],
    "emails" : [ "GOLOVIN@GMAIL.COM", "KRAUSEA@ETHZ.CH", "MATT@DUOLINGO.COM" ],
    "sections" : [ {
      "heading" : "1. Introduction",
      "text" : "Consider the problem of repeatedly choosing advertisements to display in sponsored search to maximize our revenue. In this problem, there is a small set of positions on the page, and each time a query arrives we would like to assign, to each position, one out of a large number of possible ads. In this and related problems that we call online assignment learning problems, there is a set of positions, a set of items, and a sequence of rounds, and on each round we must assign an item to each position. After each round, we obtain some reward depending on the selected assignment, and we observe the value of the reward. When there is only one position, this problem becomes the well-studied multi-armed bandit problem (Auer et al., 2002). When the positions have a linear ordering the assignment can be construed as a ranked list of elements, and the problem becomes one of selecting lists online. Online assignment learning thus models a central challenge in web search, sponsored search, news aggregators, and recommendation systems, among other applications.\nA common assumption made in previous work on these problems is that the quality of an assignment is the sum of a function on the (item, position) pairs in the assignment. For example, online advertising models with click-through-rates (Edelman et al., 2007) make an assumption of this form. More recently, there have been attempts to incorporate the value of diversity in the reward function (Radlinski et al., 2008). Intuitively, even though the best K results for the query “turkey” might happen to be about the country, the best list of K results is likely to contain some recipes for the bird as well. This will be the case if there are diminishing returns on the number of relevant links presented to a user; for example, if it is better to present each user with at least one relevant result than to present half of the users with no relevant results and half with two\n∗. Work done while at Carnegie Mellon University and at the California Institute of Technology. Current affiliation: Google, Inc. †. An earlier version of this work appeared as Streeter et al. (2009).\nc©2014 Daniel Golovin, Andreas Krause, and Matthew Streeter.\nar X\niv :1\n40 7.\n10 82\nv1 [\ncs .L\nG ]\n3 J\nul 2\nrelevant results. We incorporate these considerations in a flexible way by providing an algorithm that performs well whenever the reward for an assignment is a monotone submodular function of its set of (item, position) pairs. The (simpler) offline problem of maximizing a single assignment for a fixed submodular function is an important special case of the problem of maximizing a submodular function subject to a matroid constraint. Matroids are important objects in combinatorial optimization, generalizing the notion of linear independence in vector spaces. The problem of maximizing a submodular function subject to arbitrary matroid constraints was recently resolved by Calinescu et al. (2011), who provided an algorithm with optimal (under reasonable complexity assumptions) approximation guarantees. In this paper, besides developing a specialized algorithm, TGONLINE, optimized for online learning of assignments, we also develop an algorithm, OCG, for the general problem of maximizing submodular functions subject to a matroid constraint.\nOur key contributions are:\ni) an efficient algorithm, TABULARGREEDY, that provides a (1−1/e) approximation ratio for the problem of optimizing assignments under submodular utility functions,\nii) a specialized algorithm for online learning of assignments, TGONLINE, that has strong performance guarantees in the no-regret model,\niii) an algorithm for online maximization of submodular functions subject to a general matroid constraint, iv) an empirical evaluation on two problems of information gathering on the web.\nThis manuscript is organized as follows. In §2, we introduce the assignment learning problem. In §3, we develop a novel algorithm for the offline problem of finding a near-optimal assignment subject to a monotone submodular utility function. In §4, we develop TGONLINE for online learning of assignments. We then, in §5, develop an algorithm, OCG, for online optimization of submodular functions subject to arbitrary matroid constraints. We evaluate our algorithms in §6, review related work in §7, and conclude in §8."
    }, {
      "heading" : "2. The assignment learning problem",
      "text" : "We consider problems, where we have K positions (e.g., slots for displaying ads), and need to assign to each position an item (e.g., an ad) in order to maximize a utility function (e.g., the revenue from clicks on the ads). We address both the offline problem, where the utility function is specified in advance, and the online problem, where a sequence of utility functions arrives over time, and we need to repeatedly select a new assignment in order to maximize the cumulative utility.\nThe Offline Problem. In the offline problem we are given sets P1, P2, . . . , PK , where Pk is the set of items that may be placed in position k. We assume without loss of generality that these sets are disjoint∗. An assignment is a subset S ⊆ V , where V = P1 ∪ P2 ∪ · · · ∪ PK is the set of all items. We call an assignment feasible, if at most one item is assigned to each position (i.e., for all k, |S ∩ Pk| ≤ 1). We use P to refer to the set of feasible assignments.\nOur goal is to find a feasible assignment maximizing a utility function f : 2V → R≥0. As we discuss later, many important assignment problems satisfy submodularity, a natural diminishing returns property: Assigning a new item to a position k increases the utility more if few elements have been assigned, and less if many items have already been assigned. Formally, a utility function f is called submodular, if for all S ⊆ S′ and s /∈ S′ it holds that f(S ∪ {s})− f(S) ≥ f(S′ ∪ {s})− f(S′). We will also assume f is monotone, i.e., for all S ⊆ S′, we have f(S) ≤ f(S′). Our goal is thus, for a given non-negative, monotone and submodular utility function f , to find a feasible assignment S∗ of maximum utility,\nS∗ = arg max S∈P f(S).\nThis optimization problem is NP-hard. In fact, Mirrokni et al. (2008) show that any algorithm that is guaranteed to obtain a solution within a factor of (1−1/e+ ) of the optimal value requires exponentially many evaluations\n∗. If the same item can be placed in multiple positions, simply create multiple distinct copies of it.\nof f in the worst case. In light of this negative result, we can only hope to efficiently obtain a solution that achieves a fraction of (1− 1/e) of the optimal value. In §3.2 we develop such an algorithm.\nThe Online Problem. The offline problem is inappropriate to model dynamic settings, where the utility function may change over time, and we need to repeatedly select new assignments, trading off exploration (experimenting with the ads displayed to gain information about the utility function), and exploitation (displaying ads which we believe will maximize utility). More formally, we face a sequential decision problem, where, on each round (which, e.g., corresponds to a user query for a particular term), we want to select an assignment St (ads to display). We assume that the sets P1, P2, . . . , PK are fixed in advance for all rounds. After we select the assignment we obtain reward ft(St) for some non-negative monotone submodular utility function ft. We call the setting where we do not get any information about ft beyond the reward the bandit feedback model. In contrast, in the full-information feedback model we obtain oracle access to ft (i.e., we can evaluate ft on arbitrary feasible assignments). Both models arise in real applications, as we show in §6.\nThe goal is to maximize the total reward we obtain, namely ∑ t ft(St). Following the multi-armed bandit literature, we evaluate our performance after T rounds by comparing our total reward against that obtained by a clairvoyant algorithm with knowledge of the sequence of functions 〈f1, . . . , fT 〉, but with the restriction that it must select the same assignment on each round. The difference between the clairvoyant algorithm’s total reward and ours is called our regret. The goal is then to develop an algorithm whose expected regret grows sublinearly in the number of rounds; such an algorithm is said to have (or be) no-regret. However, since sums of submodular functions remain submodular, the clairvoyant algorithm has to solve an offline assignment problem with f(S) = ∑ t ft(S). Considering the hardness of this problem, no polynomial-time algorithm can possibly hope to achieve a no-regret guarantee. To accommodate this fact, we discount the reward of the clairvoyant algorithm by a factor of (1 − 1/e): We define the (1 − 1/e)-regret of a random sequence 〈S1, . . . , ST 〉 as (\n1− 1 e ) ·max S∈P { T∑ t=1 ft(S) } − E [ T∑ t=1 ft(St) ] .\nOur goal is then to develop efficient algorithms whose (1− 1/e)-regret grows sublinearly in T .\nSubsumed Models. Our model generalizes several common models for sponsored search ad selection, and web search results. These include models with click-through-rates, in which it is assumed that each (ad, position) pair has some probability p(a, k) of being clicked on, and there is some monetary reward b(a) that is obtained whenever ad a is clicked on. Often, the click-through-rates are assumed to be separable, meaning p(a, k) has the functional form α(a) · β(k) for some functions α and β. See Feldman and Muthukrishnan (2008) and Lahaie et al. (2007) for more details on sponsored search ad allocation. Note that in both of these cases, the (expected) reward of a set S of (ad, position) pairs is ∑ (a,k)∈S g(a, k) for some nonnegative function g. It is easy to verify that such a reward function is monotone submodular. Thus, we can capture this model in our framework by setting Pk = A× {k}, where A is the set of ads. Another subsumed model, for web search, appears in Radlinski et al. (2008); it assumes that each user is interested in a particular set of results, and any list of results that intersects this set generates a unit of value; all other lists generate no value, and the ordering of results is irrelevant. Again, the reward function is monotone submodular. In this setting, it is desirable to display a diverse set of results in order to maximize the likelihood that at least one of them will interest the user.\nOur model is flexible in that we can handle position-dependent effects and diversity considerations simultaneously. For example, we can handle the case that each user u is interested in a particular set Au of ads and looks at a set Iu of positions, and the reward of an assignment S is any monotone-increasing concave function g of |S ∩ (Au × Iu)|. If Iu = {1, 2, . . . , k} and g(x) = x, this models the case where the quality is the number of relevant result that appear in the first k positions. If Iu equals all positions and g(x) = min {x, 1} we recover the model of Radlinski et al. (2008)."
    }, {
      "heading" : "3. An approximation algorithm for the offline problem",
      "text" : ""
    }, {
      "heading" : "3.1 The locally greedy algorithm",
      "text" : "A simple approach to the assignment problem is the following greedy procedure: the algorithm steps through all K positions (according to some fixed, arbitrary ordering). For position k, it simply chooses the item that increases the total value as much as possible, i.e., it chooses\nsk = arg max s∈Pk\n{f({s1, . . . , sk−1}+ s)} ,\nwhere, for a set S and element e, we write S + e for S ∪ {e}. Perhaps surprisingly, no matter which ordering over the positions is chosen, this so-called locally greedy algorithm produces an assignment that obtains at least half the optimal value (Fisher et al., 1978). In fact, the following more general result holds. We will use this lemma in the analysis of our improved offline algorithm, which uses the locally greedy algorithm as a subroutine.\nLemma 1 Suppose f : 2V → R≥0 is of the form f(S) = f0(S) + ∑K k=1 fk(S ∩ Pk) where f0 : 2V → R≥0 is monotone submodular, and fk : 2Pk → R≥0 is arbitrary for k ≥ 1. Let L be the solution returned by the locally greedy algorithm. Then\nf(L) + f0(L) ≥ max S∈P f(S).\nThe proof is given in Appendix A. Observe that in the special case where fk ≡ 0 for all k ≥ 1, Lemma 1 says that f(L) ≥ 12 maxS∈P f(S).\nThe following example shows that the 1/2 approximation ratio is tight. Consider an instance of the ad allocation problem with two ads, two positions and two users, Alice and Bob. Alice is interested in ad 1, but pays relatively little attention to ads: She will only click on the ad if it appears in the first position. Bob is interested in ad 2, and will look through all positions. Now suppose that Alice searches slightly less frequently (with probability 12 − ε) than Bob (who searches with probability 1 2 + ε). The greedy algorithm first chooses the ad to assign to slot 1. Since the ad is more likely to be shown to Bob, the algorithm chooses ad 2, with an expected utility of 12 + ε. Since Alice will only look at position 1, no ad assigned to slot 2 can increase the expected utility further. On the other hand, the optimal solution is to assign ad 1 to slot 1, and ad 2 to slot 2, with an expected utility of 1."
    }, {
      "heading" : "3.2 An algorithm with optimal approximation ratio",
      "text" : "We now present an algorithm that achieves the optimal approximation ratio of 1− 1/e, improving on the 12 approximation for the locally greedy algorithm. Our algorithm associates with each partition Pk a color ck from a palette [C] of C colors, where we use the notation [n] = {1, 2, . . . , n}. For any set S ⊆ V × [C] and vector ~c = (c1, . . . , cK), define\nsample~c(S) = K⋃ k=1 {x ∈ Pk : (x, ck) ∈ S} .\nGiven a set S of (item, color) pairs, which we may think of as labeling each item with one or more colors, sample~c(S) returns a set containing each item x that is labeled with whatever color ~c assigns to the partition that contains x. Let F (S) denote the expected value of f(sample~c(S)) when each color ck is selected uniformly at random from [C]. Our TABULARGREEDY algorithm greedily optimizes F , as shown in the following pseudocode.\nObserve that when C = 1, there is only one possible choice for ~c, and TABULARGREEDY is simply the locally greedy algorithm from §3.1. In the limit as C →∞, TABULARGREEDY can intuitively be viewed as an algorithm for a continuous extension of the problem followed by a rounding procedure, in the same spirit as Vondrák’s CONTINUOUSGREEDY algorithm (Calinescu et al., 2011). In our case, the continuous extension is to compute a probability distribution Dk for each position k with support in Pk (plus a special “select nothing”\nAlgorithm: TABULARGREEDY Input: integer C, sets P1, P2, . . . , PK , function f : 2V → R≥0 (where V = ⋃K k=1 Pk)\nset G := ∅. for c from 1 to C do /* For each color */\nfor k from 1 to K do /* For each partition */ set gk,c = arg maxx∈Pk×{c} {F (G+ x)} /* Greedily pick gk,c */ set G := G+ gk,c;\nfor each k ∈ [K], choose ck uniformly at random from [C]. return sample~c(G), where ~c := (c1, . . . , cK).\noutcome), such that if we independently sample an element xk from Dk, E [f({x1, . . . , xK})] is maximized. It turns out that if the positions individually, greedily, and in round-robin fashion, add infinitesimal units of probability mass to their distributions so as to maximize this objective function, they achieve the same objective function value as if, rather than making decisions in a round-robin fashion, they had cooperated and added the combination of K infinitesimal probability mass units (one per position) that greedily maximizes the objective function. The latter process, in turn, can be shown to be equivalent to a greedy algorithm for maximizing a (different) submodular function subject to a cardinality constraint, which implies that it achieves a 1− 1/e approximation ratio (Nemhauser et al., 1978). TABULARGREEDY represents a tradeoff between these two extremes; its performance is summarized by Theorem 2. For now, we assume that the arg max in the inner loop is computed exactly. In Appendix A we bound the performance loss that results from approximating the arg max (e.g., by estimating F by repeated sampling).\nTheorem 2 Suppose f is monotone submodular. Then\nF (G) ≥ β(K,C) ·max S∈P f(S),\nwhere β(K,C) is defined as 1− (1− 1C ) C − ( K 2 ) C−1.\nIt follows that, for any ε > 0, TABULARGREEDY achieves a (1− 1/e− ε) approximation factor using a number of colors that is polynomial in K and 1/ε. The theorem will follow immediately from the combination of two key lemmas, which we now prove. Informally, Lemma 3 analyzes the approximation error due to the outer greedy loop of the algorithm, while Lemma 4 analyzes the approximation error due to the inner loop.\nLemma 3 LetGc = {g1,c, g2,c, . . . , gK,c}, and letG−c = G1∪G2∪. . .∪Gc−1. For each color c, chooseEc ∈ R such thatF (G−c ∪Gc) ≥ maxx∈Rc {F (G−c + x)}−Ec whereRc := {R : ∀k ∈ [K] , |R ∩ (Pk × {c})| = 1} is the set of all possible choices for Gc. Then\nF (G) ≥ β(C) ·max S∈P {f(S)} − C∑ c=1 Ec . (1)\nwhere β(C) = 1− ( 1− 1C )C .\nProof (Sketch) We will refer to an element R ofRc as a row, and to c as the color of the row. LetR[C] :=⋃C c=1Rc be the set of all rows. Consider the function H : 2R[C] → R≥0, defined as H(R) = F (⋃ R∈RR ) . We will prove the lemma in three steps: (i) H is monotone submodular, (ii) TABULARGREEDY is simply the locally greedy algorithm for finding a set of C rows that maximizes H , where the cth greedy step is performed with additive error Ec, and (iii) TABULARGREEDY obtains the guarantee (1) for maximizing H , and this implies the same ratio for maximizing F .\nTo show that H is monotone submodular, it suffices to show that F is monotone submodular. Because F (S) = E~c [f(sample~c(S))], and because a convex combination of monotone submodular functions is monotone submodular, it suffices to show that for any particular coloring ~c, the function f(sample~c(S)) is monotone submodular. This follows from the definition of sample and the fact that f is monotone submodular.\nThe second claim is true by inspection. To prove the third claim, we note that the row colors for a set of rows R can be interchanged with no effect on H(R). For problems with this special property, it is known that the locally greedy algorithm obtains an approximation ratio of β(C) = 1− (1− 1C )\nC (Nemhauser et al., 1978). Theorem 6 of Streeter and Golovin (2007) extends this result to handle additive error, and yields\nF (G) = H({G1, G2, . . . , GC}) ≥ β(C) · max R⊆R[C]:|R|≤C {H(R)} − C∑ c=1 Ec .\nTo complete the proof, it suffices to show that maxR⊆R[C]:|R|≤C {H(R)} ≥ maxS∈P {f(S)}. This follows from the fact that for any assignment S ∈ P , we can find a set R(S) of C rows such that sample~c( ⋃ R∈R(S)R) = S with probability 1, and therefore H(R(S)) = f(S).\nWe now bound the performance of the the inner loop of TABULARGREEDY.\nLemma 4 Let f∗ = maxS∈P {f(S)}, and let Gc, G−c , and Rc be defined as in the statement of Lemma 3. Then, for any c ∈ [C],\nF (G−c ∪Gc) ≥ max R∈Rc\n{ F (G−c ∪R) } − ( K\n2\n) C−2f∗ .\nProof (Sketch) Let N denote the number of partitions whose color (assigned by ~c) is c. For R ∈ Rc, let ∆~c(R) := f(sample~c(G − c ∪R))−f(sample~c(G−c )), and let Fc(R) := F (G−c ∪R)−F (G−c ). By definition, Fc(R) = E~c [∆~c(R)] = P [N = 1]E~c [∆~c(R)|N = 1] + P [N ≥ 2]E~c [∆~c(R)|N ≥ 2], where we have used the fact that ∆~c(R) = 0 when N = 0. The idea of the proof is that the first of these terms dominates as C →∞, and that E~c [∆~c(R)|N = 1] can be optimized exactly simply by optimizing each element of Pk×{c} independently. Specifically, it can be seen that E~c [∆~c(R)|N = 1] = ∑K k=1 fk(R ∩ (Pk × {c})) for suitable fk. Additionally, f0(R) = P [N ≥ 2]E~c [∆~c(R)|N ≥ 2] is a monotone submodular function of a set of (item, color) pairs, for the same reasons F is. Applying Lemma 1 with these {fk : k ≥ 0} yields\nFc(Gc) + P [N ≥ 2]E~c [∆~c(Gc)|N ≥ 2] ≥ max R∈Rc {Fc(R)} .\nTo complete the proof, it suffices to show P [N ≥ 2] ≤ ( K 2 ) C−2 and E~c [∆~c(Gc)|N ≥ 2] ≤ f∗. The first inequality holds because, if we let M be the number of pairs of partitions that are both assigned color c, we have P [N ≥ 2] = P [M ≥ 1] ≤ E [M ] = ( K 2 ) C−2. The second inequality follows from the fact that for any ~c we have ∆~c(Gc) ≤ f(sample~c(G−c ∪Gc)) ≤ f∗."
    }, {
      "heading" : "4. An algorithm for online learning of assignments",
      "text" : "We now transform the offline algorithm of §3.2 into an online algorithm. The high-level idea behind this transformation is to replace each greedy decision made by the offline algorithm with a no-regret online algorithm. A similar approach was used by Radlinski et al. (2008) and Streeter and Golovin (2008) to obtain an online algorithm for different (simpler) online problems.\nThe following theorem summarizes the performance of TGONLINE. Theorem 5 Let rk,c be the regret of Ek,c, and let β(K,C) = 1− ( 1− 1C )C − (K2 )C−1. Then E\n[ T∑ t=1 ft(Gt) ] ≥ β(K,C) ·max S∈P { T∑ t=1 ft(S) } − E [ K∑ k=1 C∑ c=1 rk,c ] .\nAlgorithm: TGONLINE (described in the full-information feedback model) Input: integer C, sets P1, P2, . . . , PK\nfor each k ∈ [K] and c ∈ [C], let Ek,c be a no-regret algorithm with action set Pk × {c}. for t from 1 to T do\nfor each k ∈ [K] and c ∈ [C], let gtk,c ∈ Pk × {c} be the action selected by Ek,c for each k ∈ [K], choose ck uniformly at random from [C]. Define ~c = (c1, . . . , cK). select the set Gt = sample~c ({ gtk,c : k ∈ [K] , c ∈ [C] }) observe ft, and let F̄t(S) := ft(sample~c(S)) for each k ∈ [K], c ∈ [C] do\ndefine Gt−k,c ≡ { gtk′,c′ : k ′ ∈ [K] , c′ < c } ∪ { gtk′,c : k ′ < k } for each x ∈ Pk × {c}, feed back F̄t(Gt−k,c + x) to Ek,c as the reward for choosing x\nObserve that Theorem 5 is similar to Theorem 2, with the addition of the E [rk,c] terms. The idea of the proof is to view TGONLINE as a version of TABULARGREEDY that, instead of greedily selecting single (element,color) pairs gk,c ∈ Pk × {c}, greedily selects (element vector, color) pairs ~gk,c ∈ PTk × {c} (here, PTk is the T\nth power of the set Pk). We allow for the case that the greedy decision is made imperfectly, with additive error rk,c; this is the source of the extra terms. Once this correspondence is established, the theorem follows along the lines of Theorem 2. For a proof, see Appendix A.\nCorollary 4.1 If TGONLINE is run with randomized weighted majority (Cesa-Bianchi et al., 1997) as the subroutine, then\nE [ T∑ t=1 ft(Gt) ] ≥ β(K,C) ·max S∈P { T∑ t=1 ft(S) } −O ( C K∑ k=1 √ T log |Pk| ) .\nwhere β(K,C) = 1− ( 1− 1C )C − (K2 )C−1. Optimizing for C in Corollary 4.1 yields (1− 1e )-regret Θ̃(K 3/2T 1/4 √ OPT) ignoring logarithmic factors,\nwhere OPT := maxS∈P {∑T t=1 ft(S) } is the value of the static optimum.\nDealing with bandit feedback. TGONLINE can be modified to work in the bandit feedback model. The idea behind this modification is that on each round we “explore” with some small probability, in such a way that on each round we obtain an unbiased estimate of the desired feedback values F̄t(Gt−k,c + x) for each k ∈ [K], c ∈ [C], and x ∈ Pk. This technique can be used to achieve a bound similar to the one stated in Corollary 4.1, but with an additive regret term of O ( (T |V|CK) 2 3 (log |V|) 1 3 ) .\nStronger notions of regret. By substituting in different algorithms for the subroutines Ek,c, we can obtain additional guarantees. For example, Blum and Mansour (2007) consider online problems in which we are given time-selection functions I1, I2, . . . , IM . Each time-selection function I : [T ] → [0, 1] associates a weight with each round, and defines a corresponding weighted notion of regret in the natural way. Blum and Mansour’s algorithm guarantees low weighted regret with respect to all M time selection functions simultaneously. This can be used to obtain low regret with respect to different (possibly overlapping) windows of time simultaneously, or to obtain low regret with respect to subsets of rounds that have particular features. By using their algorithm as a subroutine within TGONLINE, we get similar guarantees, both in the full information and bandit feedback models."
    }, {
      "heading" : "5. Handling arbitary matroid constraints",
      "text" : "Our offline problem is known as maximizing a monotone submodular function subject to a (simple) partition matroid constraint in the operations research and theoretical computer science communities. The study of this problem culminated in the elegant (1− 1/e) approximation algorithm of Vondrák (2008) and a matching unconditional lower bound of Mirrokni et al. (2008). Vondrák’s algorithm, called the CONTINUOUSGREEDY algorithm, has also been extended to handle arbitrary matroid constraints (Calinescu et al., 2011). The CONTINUOUSGREEDY algorithm, however, cannot be applied to our problem directly, because it requires the ability to sample f(·) on infeasible sets S /∈ P . In our context, this means it must have the ability to ask (for example) what the revenue will be if ads a1 and a2 are placed in position #1 simultaneously. We do not know how to answer such questions in a way that leads to meaningful performance guarantees, and hence we developed the TABULARGREEDY algorithm to circumvent this difficulty. However, in some applications, it may be possible to evaluate f(·) on infeasible sets S /∈ P at the end of each round, particularly in the full information setting. As we will now show, in this case we may implement an online version of the CONTINUOUSGREEDY algorithm, which has the virtue of being able to deal with arbitrary matroid constraints."
    }, {
      "heading" : "5.1 Background: Matroid Constraints and the Continuous Greedy Algorithm",
      "text" : "A matroidM = (V, I) consists of a finite ground set V and a nonempty collection of independent sets I ⊆ 2V such that (i) A ⊂ B and B ∈ I implies A ∈ I, and (ii) A,B ∈ I and |A| < |B| implies there exists some b ∈ B \\ A such that A + b ∈ I. Matroids play an important role in the theory of optimization, where they generalize the notion of linear independence in vector spaces; see e.g. Schrijver (2003).\nWe are interested in problems of the form\nmax {f(S) : S ∈ I} (2)\nfor a monotone submodular function f : 2V → R≥0 such that f(∅) = 0 and a matroid (V, I). This is known as maximizing f subject to a matroid constraint. Note our offline assignment problem is a special case with a so-called simple partition matroid constraint, so that V = P1 ∪ P2 ∪ · · · ∪ PK , where Pk is the set of items suitable for position k, and I = {S : ∀k, |S ∩ Pk| ≤ 1} is the set of feasible assignments.\nTo obtain a (1 − 1/e) approximation to Problem (2), Calinescu et al. (2011) use Vondrák’s CONTINUOUSGREEDY algorithm. This algorithm defines a continuous relaxation of the problem, obtains a (1− 1/e) approximation to the relaxation, and then rounds the resulting fractional solution to a feasible solution to the original problem without losing any objective value in expectation. We discuss each step in turn.\nThe continuous relaxation of Problem (2) that the CONTINUOUSGREEDY algorithm works with has a feasible set consisting of the matroid polytope of the constraint matroidM = (V, I), denoted P (M). It is defined as the convex hull of all characteristic vectors of independent sets inM, i.e.,\nP (M) := conv {1S : S ∈ I}\nand lies in RV . The objective is the smooth multilinear extension of the monotone submodular objective function f : 2V → R≥0, which is a function F : [0, 1]V → R≥0 defined as follows. For y ∈ [0, 1]V , let Sy ⊆ V be a random set such that each v ∈ V is included in Sy independently with probability yv. Then the multilinear extension of f is defined as\nF (y) := E [f(Sy)] = ∑ S⊆V f(S) ∏ v∈S yv ∏ v/∈S (1− yv) (3)\nCalinescu et al. (2011) show that for all u, v ∈ V the multilinear extension satisfies ∂F ∂yu ≥ 0 and ∂\n2F\n∂yu∂yv ≤ 0.\nGiven the definitions of P (M) and F , we can define the continuous relaxation of Problem (2) as\nmax {F (y) : y ∈ P (M)} (4)\nThis relaxation is NP-hard, and indeed is as hard to approximate as the original problem. However, Vondrák (2008) shows how a (1− 1/e) approximation may be obtained as follows. Define a parameterized curve {y(t) : t ∈ [0, 1]} ⊂ [0, 1]V satisfying y(0) = 0 and dy dt ∈ arg maxz∈P (M) (z · ∇F (y)). Then\ny(1) ∈ P (M) since y(1) = ∫ 1 t=0\n( dy\ndt\n) dt is a convex combination of vectors in P (M). Moreover,\nF (y(1)) ≥ (1− 1/e) OPT, where OPT = max {F (y′) : y′ ∈ P (M)} is the optimal value of Problem (4). This is proved by demonstrating that any y ∈ P (M) there is a direction v ∈ P (M) such that v · ∇F (y) ≥ OPT − F (y). Given this fact, it is easy to show that F (y(t)) dominates the solution to the differential equation dφ/dt ≥ OPT − φ with boundary condition φ(0) = 0, whose solution is φ(t) = (1 − e−t)OPT. Hence F (y(1)) ≥ (1 − 1/e) OPT. To implement this procedure, first note that given ∇F (y), computing arg maxz∈P (M) (z · ∇F (y)) is easy, as it amounts to optimizing a linear function over P (M); in fact an integral optimum may be found using a simple greedy algorithm. However, two complications arise. The first is that this continuous process must be discretized. For technical reasons, Calinescu et al. (2011) replace all occurrences of the gradient∇F (y) in the continuous process with a related quantity called the marginal, ∆F (y) ∈ RV≥0, defined coordinate-wise by\n(∆F (y))v = E [f(Sy ∪ {v})− f(Sy)] = (1− yv)(∇F (y))v.\nThe second complication arises because ∆F (y) cannot be computed exactly given oracle access to f , but must be estimated via random sampling. Calinescu et al. (2011) choose to take enough samples are taken so that by Chernoff bounds it is likely that the estimate of each coordinate of ∆F (y(t)) for each iteration t ∈ {0, δ, 2δ, . . . , 1} is accurate to up high precision, namely δOPT.\nAlgorithm: Continuous Greedy (Vondrák (2008); Calinescu et al. (2011)) Input: matroidM = (V, I), monotone submodular f : 2V → R≥0, δ ∈ {1/n : n ∈ N}, ρ ∈ N\nset y(0) = 0. for t from δ to 1 in increments of δ do\nfor each v ∈ V do Compute estimates ωv(t− δ) of (∆F (y(t− δ)))v = F (y(t− δ) + (1− y(t− δ)v)1{v})− F (y(t− δ)) via random sampling, by taking the average of f(Sy(t−δ) ∪ {v})− f(Sy(t−δ)) over ρ independent samples of Sy(t−δ) as described in (3); Let I(t) be a maximum-weight independent set inM, according to the weights ωv(t− δ). This may be computed via a simple greedy algorithm. set y(t) = y(t− δ) + δ 1I(t).\nreturn PipageRound(y(1)); Algorithm 1: Pseudocode for the CONTINUOUSGREEDY algorithm. For default parameters, Calinescu et al. (2011) select δ = 1/9d2 where d = max {|S| : S ∈ I} is the rank ofM, and ρ = 10δ2 (1 + ln |V|) samples per marginal coordinate.\nFinally, given a fractional solution y, the CONTINUOUSGREEDY algorithm rounds it to an integral solution which is the characteristic vector of a feasible set, using a rounding technique called pipage rounding. Refer to (Calinescu et al., 2011) for details."
    }, {
      "heading" : "5.2 The Online Continuous Greedy Algorithm",
      "text" : "In this section we develop an online version of the CONTINUOUSGREEDY algorithm. We begin with an observation that the (randomized variant of the) pipage rounding scheme in Calinescu et al. (2011) is oblivious, in the sense that it does not require access to the objective function. This was emphasized by Calinescu et al. (2011), who point out its advantage in settings where we have only approximate-oracle access to f . For the\nsame reason, it is extremely convenient for the design of the online continuous greedy algorithm. In particular, once we obtain a fractional solution y to Problem (4), we can round it to a random feasible solution S ∈ I for the original problem such that E [f(S)] ≥ F (y) before gaining access to f . We elect to do so, and hence the final rounding step is identical for the CONTINUOUSGREEDY algorithm and our online version of it.\nHence we may focus on developing an online algorithm for the online version of the continuous relaxation, Problem (4). Hence there is a stream of nonnegative monotone submodular functions {ft}Tt=1 with multilinear extensions {Ft}Tt=1, and a fixed matroidM = (V, I), and in each time step twe must output some yt ∈ P (M) with the goal of maximizing ∑T t=1 Ft(y\nt), and after outputting yt we then receive oracle access to ft. We assume here the full information model, in which we have oracle access to (i.e., we may efficiently compute) ft(S) for arbitrary S ⊆ V .\nConsider the CONTINUOUSGREEDY algorithm. There are 1/δ stages of the algorithm, and in each stage τ it seeks a set I(τ) ∈ I maximizing a linear objective, namely 1I(τ) ·∆F (y(τ − δ)). Our online variant will thus need to solve, for each stage τ , the problem of the online maximization of linear functions subject to a matroid constraint. For this, the follow the perturbed leader algorithm (Kalai and Vempala, 2005) is suitable. On each round t, this algorithm simply outputs the feasible solution maximizing g0 + ∑ 1≤t′<t gt′ , where gt′ is the linear objective seen in round t′, and g0 is a random linear objective drawn from a suitably chosen distribution. To ensure that these algorithms have no-regret, we must offer suitable feedback to them at the end of each round. The objective faced by the algorithm for stage τ will be S 7→ 1S ·∆F (yt(τ − δ)), where yt(τ − δ) is the point reached in the algorithm’s trajectory through P (M) for that round at stage τ , i.e., δ times the sum of characteristic vectors of the outputs of the earlier stages. Unfortunately, we cannot compute ∆F (yt(τ − δ)) exactly. We will defer the details of how to address this point to §5.2.3. For now, suppose we can in fact feed back S 7→ 1S ·∆F (yt(τ − δ)).\nAlgorithm: Online Continuous Greedy Input: matroidM = (V, I), sequence of monotone submodular functions ft : 2V → R≥0,\nδ ∈ {1/n : n ∈ N}\nInitialize 1/δ Perturbed Follow the Leader algorithms {Eτ : τ ∈ {δ, 2δ, . . . , 1}} for maximizing a linear objective over I. for t from 1 to T do\nfor each τ ∈ {δ, 2δ, . . . , 1} do Let I(τ) ∈ I be the set selected by Eτ .\nLet y = ∑1/δ s=1 δ 1I(sδ). Select St = PipageRound(y); Obtain reward ft(St) and oracle access to ft. for each τ ∈ {δ, 2δ, . . . , 1} do\nIf τ = δ let y(τ) = 0, otherwise let y(τ) = ∑τ/δ−1 s=1 δ1I(sδ). Generate an unbiased estimate ωτ (t) for ∆Ft(y(τ)), where Ft is the multilinear extension of ft. Feed back the linear objective function S 7→ (1S · ωτ (t)) to Eτ .\nAlgorithm 2: The ONLINECONTINUOUSGREEDY algorithm."
    }, {
      "heading" : "5.2.1 ANALYSIS OF THE CONTINUOUS GREEDY ALGORITHM WITH NOISE",
      "text" : "Streeter and Golovin (2008) introduced an analysis framework based on “meta-actions”, in which an online process over T rounds is interpreted as a single run in a combined instance of a suitable offline problem with objective ∑T t=1 Ft, in which the algorithm makes errors. Using this framework, we will analyze the CONTINUOUSGREEDY algorithm with noise in much the same way we analyzed TABULARGREEDY. Recall that in the analysis of TABULARGREEDY (specifically, in the proof of Lemma 3) we considered problem of selecting a set of C rows to maximize a monotone submodular function H , where each row\ncorresponds to a way of filling in a row of the algorithm’s table of items (i.e., a choice of item for each partition). TABULARGREEDY is then interpreted as a noisy version of the locally greedy algorithm for this problem. We analyze CONTINUOUSGREEDY likewise, where the role of a row is played by a set in I , and the monotone submodular objective function H : 2I×δN → R≥0 defined by H(R) = F ( ∑ (S,τ)∈R δ1S), where F is the multilinear extension of the original objective f . Note that maxR:|R|≤1/δ (H(R)) = maxS∈I (f(S)), since we can use pipage rounding to round any y = ∑ (S,τ)∈R δ1S to some S ∈ I with f(S) ≥ F (y), and given any S ∈ I we can construct R(S) = {(S, τ) : τ ∈ δN, 0 ≤ τ ≤ 1} which has the property that H(R(S)) := F ( ∑ (S,τ)∈R δ1S) = F (1S) = f(S).\nNow, let I(τ) be the set chosen in round τ of CONTINUOUSGREEDY, and define the stage τ error τ to be such that\nH({I(τ ′) : τ ′ ≤ τ})−H({I(τ ′) : τ ′ < τ}) ≥ δ (OPT−H({I(τ ′) : τ ′ < τ}))− τ .\nwhere OPT = maxR:|R|≤1/δ (H(R)). We obtain the following result.\nTheorem 6 Suppose f : 2V → R≥0 is monotone submodular. Let S be the output of the noisy CONTINUOUSGREEDY algorithm with errors { τ : τ ∈ δN, 0 ≤ τ ≤ 1} run on matroid (V, I). Then\nE [f(S)] ≥ (\n1− 1 e ) max S∈I {f(S)} − ∑ τ τ .\nProof CONTINUOUSGREEDY can be viewed as a noisy version of the locally greedy algorithm for selecting the set of 1/δ rows maximizing the monotone submodular objective function H : 2I×δN → R≥0 is defined by H(R) := F ( ∑ (S,τ)∈R δ1S), where F is the multilinear extension of the original objective f . Note the order of the rows does not matter, since from the definition of H , it is clear that permuting the order of rows has no effect on the objective, i.e., for all permutations π, we have H({(Sτ , τ) : τ ∈ δN, 0 ≤ τ ≤ 1}) = H({(Sτ , π(τ)) : τ ∈ δN, 0 ≤ τ ≤ 1}). That H is monotone submodular follows easily from the facts that ∂F\n∂yu ≥ 0 and ∂\n2F\n∂yu∂yv ≤ 0 (Calinescu et al., 2011). Hence from Theorem 6 of Streeter and Golovin (2007),\nwhich bounds the performance of a noisy version of the locally greedy algorithm for precisely this problem, we obtain\nF (y(1)) = H({I(τ) : τ ∈ δN, 0 ≤ τ ≤ 1}) ≥ (\n1− 1 e\n) max\nR:|R|≤1/δ {H(R)} − ∑ τ τ . (5)\nAs we proved above when introducing H , maxR:|R|≤1/δ {H(R)} = maxS∈I f(S). Hence F (y(1)) ≥( 1− 1e ) maxS∈I f(S)− ∑ τ τ , and to complete the proof it suffices to note that pipage rounding results in an output S with E [f(S)] ≥ F (y(1)).\nWe distinguish two different sources of error: that arising because of discretization, and that arising from not computing arg maxS∈I {1S ·∆F (y(τ − δ))} exactly for whatever reason. The CONTINUOUSGREEDY algorithm, even when it is given a perfect estimate of the vector ∆F and computes arg maxS∈I {1S ·∆F} exactly, will not generally achieve zero error. This is because maximizing 1S ·∆F (y(τ − δ)) is not equivalent to maximizing F (y(τ)) − F (y(τ − δ)), due to the nonlinearity of F . We bound this source of error as in Lemma 4, using a slight variation of an argument of Calinescu et al. (2011).\nLemma 7 Let OPT = maxS∈P {f(S)}. Fix τ and arbitrary I(δ), I(2δ), . . . , I(τ − δ) ∈ I. Let I(τ) ∈ I and ′τ be such that 1I(τ) ·∆F (y(τ−δ)) ≥ maxS∈I 1S ·∆F (y(τ−δ))− ′τ , where y(τ−δ) = ∑ τ ′<τ δ1I(τ ′) as in the description of CONTINUOUSGREEDY. Let I−(τ) := {(I(τ ′), τ ′) : τ ′ ∈ δN, τ ′ < τ}. Then,\nH(I−(τ) ∪ {(I(τ), τ)})−H(I−(τ)) ≥ δ ( OPT−H(I−(τ)) ) − dδ2OPT− δ ′τ\nwhere d = max {|S| : S ∈ I} is the rank ofM.\nProof For any S, define ∆(S) := H(I−(τ) ∪ {(S, τ)})−H(I−(τ)), where H(R) := F ( ∑\n(S,τ)∈R δ1S). Let y(1) = y(τ − δ) = ∑ τ ′<τ δ1I(τ ′), y\n(2) = y(1) + δ1I(τ). Then ∆(I(τ)) = F (y(2))−F (y(1)). Since F is monotone, we may bound ∆(I(τ)) from below by ∆(I(τ)) ≥ F (z)− F (y(1)) for any z ≤ y(2). We select z such that zv = y (2) v for all v /∈ I(τ), and zv = yv + δ− δyv = 1− (1− yv)(1− δ) for all v ∈ I(τ). Recall Sy is a random set such that each v is in Sy independently with probability yv , and F (y) = E [f(Sy)]. We apply the following interpretation to F (z): Sample A = Sy(1) and then independently sample B = S(y(2)−y(1)). Then the random set A ∪B has the same distribution as Sz . We then bound\n∆(I(τ)) ≥ E [f(A ∪B)− f(A)] (6) ≥ ∑ v∈I(τ) E [f(A ∪B)− f(A) | B = {v}] · P [B = {v}] (7)\n= ∑ v∈I(τ) (∆F (y(1)))v ( δ(1− δ)|I(τ)|−1 ) (8)\n≥ δ(1− dδ)1I(τ) ·∆F (y(1)) (9) ≥ δ(1− dδ) (\nmax S∈I\n( 1S ·∆F (y(1)) ) − ′τ ) (10)\nHere we have used that |I(τ)| ≤ d, and that (1− δ)d−1 ≥ (1− dδ). The latter follows easily from Bernoulli’s inequality.\nNext we claim that\nmax S∈I\n(1S ·∆F (y(τ − δ))) ≥ OPT− F (y(τ − δ)) = OPT−H(I−(τ)) (11)\nFix an optimal solution S∗ ∈ I , and letA be in the support of Sy(τ−δ). By the monotonicity and submodularity of f , we have f(S∗) ≤ f(A ∪ S∗) ≤ f(A) + ∑ v∈S∗ (f(A+ v)− f(A)). Taking the expectation of these inequalities yields OPT ≤ F (y(τ − δ)) +\n∑ v∈S∗ ∆F (y(τ − δ))\nfrom which we easily obtain Eq. (11). Combining Eq. (11) with Eq. (10) yields\n∆(I(τ)) ≥ δ(1− dδ) (OPT− F (y(τ − δ))− ′τ ) ≥ δ (OPT− F (y(τ − δ)))− dδ2OPT− δ ′τ\nwhich is equivalent to the claimed inequality, since H(I−(τ)) = F (y(τ − δ)).\nBy combining Theorem 6 with Lemma 7 we obtain the following result.\nTheorem 8 Suppose a noisy version of the CONTINUOUSGREEDY algorithm is run on a matroid (V, I) of rank d with discretization parameter δ, such that in stage τ the selected independent set I(τ) satisfies 1I(τ) · ∆F (y(τ − δ)) ≥ maxS∈I 1S · ∆F (y(τ − δ)) − ′τ for some error terms { ′τ : τ ∈ δN}. Then the random set S output by the algorithm satisfies\nE [f(S)] ≥ (\n1− 1 e − dδ\n) OPT− ∑ τ δ ′τ ."
    }, {
      "heading" : "5.2.2 THE META-ACTIONS ANALYSIS OF THE ONLINE CONTINUOUS GREEDY ALGORITHM",
      "text" : "After running the online continuous greedy algorithm for T rounds, we may view the T choices made by the algorithm Eτ for any fixed stage τ in aggregate, as a single choice made in the (noisy) execution of the offline continuous greedy algorithm in a larger instance. This larger instance is the direct sum of the T instances. Thus\nwe have T copies of the input matroid,Mt = (V × {t} , I × {t}) for 1 ≤ t ≤ T , from which we construct a larger matroidM⊕ with groundset V⊕ := ⋃T t=1 Vt and independent sets I⊕ := {S : ∀t, S ∩ Vt ∈ It}, and we have T monotone submodular objective functions f1, . . . , fT from which we construct the monotone submodular objective f⊕(S) := ∑T t=1 ft(S∩Vt). By analogy with the single instance case, we can define the multilinear extension F⊕ : [0, 1]V×[T ] → R≥0 of f⊕ by F⊕(Y ) = E [f⊕(SY )], where SY is a random set such that each v ∈ Vt is included in SY independently with probability Yvt. We can also define an objective on rows, H⊕(R) = F⊕( ∑ (S,τ)∈R δ[S]) where [S] is the 0/1 characteristic matrix of S with [S]vt = 1 iff (v, t) ∈ S. Call a row S proper if S ∈ I⊕ and also, S consists of T copies of the same subset of V , so that S = Q× [T ] for some Q ∈ I. We interpret the online problem as noisily selecting 1/δ proper rows to maximize H⊕. By construction, the regret incurred by each Eτ over the T rounds of the online algorithm is precisely the error ′τ measured with respect to this larger instance. Combining this fact with Theorem 8 yields the following result.\nTheorem 9 Let r(τ) be the regret of Eτ in the online continuous greedy algorithm with discretization parameter δ. Then\nE [ T∑ t=1 ft(St) ] ≥ ( 1− 1 e − dδ ) max S∈I T∑ t=1 ft(S)− δ 1/δ∑ s=1 r(sδ)\nThe regret bound for the follow the perturbed leader algorithm (Theorem 1.1 of Kalai and Vempala (2005)), suitably tailored for our purposes, is O(d √ ngT ) where d is the rank ofM, n = |V|, and g = maxt,v ft({v}) is an upper bound for each coordinate of ∆Ft. Therefore if we were to feed back the exact marginals ∆Ft(y(τ)) to each Eτ , we would obtain the following bound.\nE [ T∑ t=1 ft(St) ] ≥ ( 1− 1 e − dδ ) max S∈I T∑ t=1 ft(S)−O(d √ ngT )\nThough we cannot precisely compute these marginals ∆Ft(y(τ)), we will still obtain the above bound using unbiased estimates of them, using only one evaluation of each function ft."
    }, {
      "heading" : "5.2.3 GENERATING FEEDBACK: HOW TO ESTIMATE THE MARGINAL",
      "text" : "We could follow Calinescu et al. (2011) and take sufficiently many samples to ensure that with high probability the estimates for ∆F (yt(τ − δ)) are sharp. Instead, we will feed back a rough estimate of ∆F (yt(τ − δ)). Perhaps surprisingly, using unbiased estimates, or even certain biased estimates, results in exactly the same expected regret bounds as using the actual marginals. This is a consequence of the following lemma.\nLemma 10 (Lemma 5 of Streeter and Golovin (2007)) Let E be a no-regret algorithm that incurs a worst-case expected regret R(T ) over T rounds in the full-information feedback model. For each feasible S, let xtS be the payoff of S in round t, and let x̂tS be an estimate of x t S such that E [x̂tS ] = γxtS + ηt for all S. Let E ′ be the algorithm that results from running E but feeding back the estimates x̂tS instead of the true payoffs xtS . Then the expected worst-case regret of E ′ is R(T )/γ.\nTo generate an unbiased estimate of ∆F (y), from the multilinearity of F with only one evaluation of f , we pick some v ∈ V uniformly at random, and sample θ ∈ [0, 1]V uniformly at random, and define A = {u : θu ≤ yu}, B = A ∪ {v}. Then sample X ∈ {0, 1} uniformly at random. We then generate an estimate of the gradient\nω =\n{ −2|V|f(A) · 1{v} if X = 0\n2|V|f(B) · 1{v} if X = 1\nLemma 11 The estimate ω described above is an unbiased estimate of ∆F .\nProof By the multilinearity of F ,\n(∆F (y))v = F (y + (1− yv)1{v})− F (y) (12) = E [f(Sy ∪ {v})− f(Sy)] (13)\nThe estimate has ωv 6= 0 only if v is the selected coordinate, so that E [ωv] = E [ωv | v selected]P [v selected], and v is selected with probability 1/|V|. Hence E [ωv] = 1|V|E [ωv | v selected]. In the case that v is selected, it is clear that f(A) is an unbiased estimate of F (y) and f(B) is an unbiased estimate of F (y+ (1− yv)1{v}). Hence, E [ωv | v selected, X = 0] = −2|V|F (y) and E [ωv | v selected, X = 1] = 2|V|F (y+ (1− yv)1{v}). It follows that E [ωv | v selected] = |V|(∆F (y))v , and E [ωv] = (∆F (y))v .\nOf course, one may take more samples to reduce the variance in the estimates for ∆F , e.g., several per coordinate, though Lemma 10 indicates that this will not improve the worst-case regret."
    }, {
      "heading" : "5.2.4 USING ONLINE CONTINUOUS GREEDY FOR THE OFFLINE PROBLEM",
      "text" : "The ONLINECONTINUOUSGREEDY algorithm guarantees no-regret against arbitrary sequences of objectives {ft}t≥0. Our analysis also suggests it can be used to solve the original offline problem, maxS∈I f(S), faster than Vondrák’s original (offline) CONTINUOUSGREEDY algorithm. As described in (Calinescu et al., 2011), CONTINUOUSGREEDY has a running time of order Õ(n8) plus the time required to evaluate f on Õ(n7) arguments, where the Õ notation suppresses logarithmic factors. Calinescu et al. (2011) describe this high complexity as being “mostly due to the number of random samples necessary to achieve high probability bounds” and suggest that this “can be substantially reduced by a more careful implementation and analysis.”\nTo use ONLINECONTINUOUSGREEDY to solve the offline problem, simply run it for some number T of rounds with objectives ft ≡ f for all rounds t, generating solutions {yt} T t=1 to the fractional relaxation of the problem, while omitting the step in which the algorithm generates St via the pipage rounding of yt. Then select a round t ∈ [T ] uniformly at random, and pipage round yt to obtain a set S. As T increases the bound on the expected quality of the solution will increase. Fix a desired relative error bound , so that we will compute a set S′ such that E [f(S′)] ≥ (1− 1/e− ) maxS∈I f(S). Setting δ = /2d and T = 4d 2ng 2OPT2 suffices, where d = max {|S| : S ∈ I} is the rank of the input matriodM = (V, I), n = |V| is the size of the groundset, OPT = maxS∈I f(S) is the offline optimum value, and g = maxv∈V f({v}) is an upper bound on (∆F (y))v for all y ∈ P (M). The running time is proportional to nT/δ = O ( d3n2g 3OPT2 ) plus the time for\nthe final pipage rounding operation and the time required to evaluate f on T/δ = O (\nd3ng 3OPT2\n) arguments."
    }, {
      "heading" : "6. Evaluation",
      "text" : "We evaluate TGONLINE experimentally on two applications: Learning to rank blogs that are effective in detecting cascades of information, and allocating advertisements to maximize revenue."
    }, {
      "heading" : "6.1 Online learning of diverse blog rankings",
      "text" : "We consider the problem of ranking a set of blogs and news sources on the web. Our approach is based on the following idea: A blogger writes a posting, and, after some time, other postings link to it, forming cascades of information propagating through the network of blogs.\nMore formally, an information cascade is a directed acyclic graph of vertices (each vertex corresponds to a posting at some blog), where edges are annotated by the time difference between the postings. Based on this notion of an information cascade, we would like to select blogs that detect big cascades (containing many nodes) as early as possible (i.e., we want to learn about an important event before most other readers). In Leskovec et al. (2007) it is shown how one can formalize this notion of utility using a monotone submodular function that measures the informativeness of a subset of blogs. Optimizing the submodular function yields a\nsmall set of blogs that “covers” most cascades. This utility function prefers diverse sets of blogs, minimizing the overlap of the detected cascades, and therefore minimizing redundancy.\nThe work by Leskovec et al. (2007) leaves two major shortcomings: Firstly, they select a set of blogs rather than a ranking, which is of practical importance for the presentation on a web service. Secondly, they do not address the problem of sequential prediction, where the set of blogs must be updated dynamically over time. In this paper, we address these shortcomings.\nResults on offline blog ranking. In order to model the blog ranking problem, we adopt the assumption that different users have different attention spans: Each user will only consider blogs appearing in a particular subset of positions. In our experiments, we assume that the probability that a user is willing to look at position k is proportional to γk, for some discount factor 0 < γ < 1. More formally, let g be the monotone submodular function measuring the informativeness of any set of blogs, defined as in Leskovec et al. (2007). Let Pk = B×{k}, where B is the set of blogs. Given an assignment S ∈ P , let S[k] = S ∩{P1 ∪ P2 ∪ . . . ∪ Pk} be the assignment of blogs to positions 1 through k. We define the discounted value of the assignment S as f(S) = ∑K k=1 γ k ( g(S[k])− g(S[k−1]) ) . It can be seen that f : 2V → R≥0 is monotone submodular.\nFor our experiments, we use the data set of Leskovec et al. (2007), consisting of 45,192 blogs, 16,551 cascades, and 2 million postings collected during 12 months of 2006. We use the population affected objective of Leskovec et al. (2007), and use a discount factor of γ = 0.8. Based on this data, we run our TABULARGREEDY algorithm with varying numbers of colors C on the blog data set. Fig. 1(a) presents the results of this experiment. For each value of C, we generate 200 rankings, and report both the average performance and the maximum performance over the 200 trials. IncreasingC leads to an improved performance over the locally greedy algorithm (C = 1).\nResults on online learning of blog rankings. We now consider the online problem where on each round t we want to output a ranking St. After we select the ranking, a new set of cascades occurs, modeled using a separate submodular function ft, and we obtain a reward of ft(St). In our experiments, we choose one assignment per day, and define ft as the utility associated with the cascades occurring on that day. Note that ft allows us to evaluate the performance of any possible ranking St, hence we can apply TGONLINE in the full-information feedback model.\nWe compare the performance of our online algorithm using C = 1 and C = 4. Fig. 1(b) presents the average cumulative reward gained over time by both algorithms. We normalize the average reward by the utility achieved by the TABULARGREEDY algorithm (with C = 1) applied to the entire data set. Fig. 1(b) shows that the performance of both algorithms rapidly (within the first 47 rounds) converges to the performance of the offline algorithm. The TGONLINE algorithm with C = 4 levels out at an approximately 4% higher reward than the algorithm with C = 1."
    }, {
      "heading" : "6.2 Online ad display",
      "text" : "We evaluate TGONLINE for the sponsored search ad selection problem in a simple Markovian model incorporating the value of diverse results and complex position-dependence among clicks. In this model, each user u is defined by two sets of probabilities: pclick(a) for each ad a ∈ A, and pabandon(k) for each position k ∈ [K]. When presented an assignment of ads {a1, a2, . . . , aK}, where ak occupies position k, the user scans the positions in increasing order. For each position k, the user clicks on ak with probability pclick(ak), leaving the results page forever. Otherwise, with probability (1− pclick(ak)) · pabandon(k), the user loses interest and abandons the results without clicking on anything. Finally, with probability (1− pclick(ak)) · (1− pabandon(k)), the user proceeds to look at position k + 1. The reward function ft is the number of clicks, which is either zero or one. We only receive information about ft(St) (i.e., bandit feedback).\nIn our evaluation, there are 5 positions, 20 available ads, and two (equally frequent) types of users: type 1 users interested in all positions (pabandon ≡ 0), and type 2 users that quickly lose interest (pabandon ≡ 0.5). There are also two types of ads, half of type 1 and half of type 2, and users are probabilistically more interested in ads of their own type than those of the opposite type. Specifically, for both types of users we set pclick(a) = 0.5 if a has the same type as the user, and pclick(a) = 0.2 otherwise. In Fig. 1(c) we compare the performance of\nTGONLINE with C = 4 to the online algorithm of Radlinski et al. (2008); Streeter and Golovin (2008), based on the average of 100 experiments. The latter algorithm is equivalent to running TGONLINE with C = 1. They perform similarly in the first 104 rounds; thereafter the former algorithm dominates.\nIt can be shown that with several different types of users with distinct pclick(·) functions the offline problem of finding an assignment within 1− 1e + ε of optimal is NP-hard. This is in contrast to the case in which pclick and pabandon are the same for all users; in this case the offline problem simply requires finding an optimal policy for a Markov decision process, which can be done efficiently using well-known algorithms. A slightly different Markov model of user behavior which is efficiently solvable was considered in Aggarwal et al. (2008). In that model, pclick and pabandon are the same for all users, and pabandon is a function of the ad in the slot currently being scanned rather than its index."
    }, {
      "heading" : "7. Related Work",
      "text" : "An earlier version of this work appeared as Streeter et al. (2009) (also Golovin et al. (2009)). The present article is significantly extended, including a new algorithm for online optimization over arbitrary matroids. For a general introduction to the literature on submodular function maximization (including offline versions of the problems we study), see Vondrák (2007) and the survey by Krause and Golovin (2014). For an overview of applications of submodularity to machine learning and artificial intelligence, see Krause and Guestrin (2011).\nIn the online setting, the most closely related work is that of Streeter and Golovin (2008). Like us, they consider sequences of monotone submodular reward functions that arrive online, and develop an online algorithm that uses multi-armed bandit algorithms as subroutines. The key difference from our work is that, as in Radlinski et al. (2008), they are concerned with selecting a set of K items rather than the more general problem of selecting an assignment of items to positions addressed in this paper. Kakade et al. (2007) considered the general problem of using α-approximation algorithms to construct no α-regret online algorithms, and essentially proved it could be done for the class of linear optimization problems in which the cost function has the form c(S,w) for a solution S and weight vector w, and c(S,w) is linear in w. However, their result is orthogonal to ours, because our objective function is submodular and not linear†.\nSince the earlier version of this paper appeared, subsequent research has produced algorithms that incorporate context into their decisions: Dey et al. (2013) developed an algorithm for contextual optimization of sequences of actions, and used it to optimize control libraries used for various robotic planning tasks. Ross et al.\n†. Of course, it is possible to linearize a submodular function by using a separate dimension for every possible function argument, but this results in an exponential number of dimensions, which leads to exponentially worse convergence time and regret bounds for the algorithms in Kakade et al. (2007) relative to TGONLINE.\n(2013) developed an improved variant, and applied it to tasks such as news recommendation and document summarization."
    }, {
      "heading" : "8. Conclusions",
      "text" : "In this paper, we showed that important problems, such as ad display in sponsored search and computing diverse rankings of information sources on the web, require optimizing assignments under submodular utility functions. We developed an efficient algorithm, TABULARGREEDY, which obtains the optimal approximation ratio of (1− 1/e) for this NP-hard optimization problem. We also developed an online algorithm, TGONLINE, that asymptotically achieves no (1− 1/e)-regret for the problem of repeatedly selecting informative assignments, under the full-information and bandit-feedback settings. We demonstrated that our algorithm outperforms previous work on two real world problems, namely online ranking of informative blogs and ad allocation. Finally, we developed ONLINECONTINUOUSGREEDY, an online algorithm that can handle more general matroid constraints, while still guaranteeing no (1− 1/e)-regret. Acknowledgments. This work was supported in part by Microsoft Corporation through a gift as well as through the Center for Computational Thinking at Carnegie Mellon, by NSF ITR grant CCR-0122581 (The Aladdin Center), NSF grant IIS-0953413, and by ONR grant N00014-09-1-1044."
    }, {
      "heading" : "Appendix A: Proofs",
      "text" : "Lemma 1 is a corollary of the following more general lemma. The difference between the two lemmas is that, unlike Lemma 1, Lemma 12 allows for the possibility that each arg max in the locally greedy algorithm is evaluated with additive error. We will need this result in analyzing TGONLINE later on.\nLemma 12 Let f : P → R≥0 be a function of the form f(S) = f0(S) + ∑K k=1 fk(S ∩ Pk), where f0 : 2 V → R≥0 is monotone submodular, and fk : Pk → R≥0 is arbitrary for k ≥ 1. Let L = {`1, `2, . . . , `K}, where `k ∈ Pk (for 1 ≤ k ≤ K). Suppose that for any k,\nf({`1, `2, . . . , `k}) ≥ max x∈Pk {f({`1, `2, . . . , `k−1}+ x)} − εk . (14)\nThen\nf(L) + f0(L) ≥ max S∈P {f(S)} − K∑ k=1 εk .\nProof Let OPT = arg maxS∈P {f(S)}, and let OPT = {o1, o2, . . . , oK}, where ok ∈ Pk (for 1 ≤ k ≤ K). Define\n∆k(L) := fk({ok}) + f0(L ∪ {o1, o2, . . . , ok})− f0(L ∪ {o1, o2, . . . , ok−1}) .\nLet Lk = {`1, `2, . . . , `k−1}. Using submodularity of f0, we have\n∆k(L) ≤ fk({ok}) + f0(Lk + ok)− f0(Lk) = f(Lk + ok)− f(Lk) ≤ f(Lk + `k)− f(Lk) + εk .\nThen, using monotonicity of f0,\nf(OPT) ≤ f0(L ∪OPT) + K∑\nk=1\nfk(OPT ∩ Pk)\n= f0(L) + K∑ k=1 ∆k(L) ≤ f0(L) + K∑\nk=1\nf(Lk + `k)− f(Lk) + εk\n= f0(L) + f(L)− f(∅) + K∑\nk=1\nεk .\nRearranging this inequality and using f(∅) ≥ 0 completes the proof.\nTo analyze TGONLINE, we will also need Theorem 13, which is a generalization of Theorem 2.\nTheorem 13 Suppose f is monotone submodular. Let G = {gk,c : k ∈ [K] , c ∈ [C]}, where gk,c ∈ Pk for all k and c. Suppose that for all k ∈ [K] and c ∈ [C],\nF (G−k,c + gk,c) ≥ max x∈Pk×{c}\n{ G−k,c + x } − εk,c (15)\nwhere G−k,c = {gk′,c′ : k ′ ∈ [K] , c′ < c} ∪ {gk′,c : k′ < k} (i.e., G−k,c equals G just before gk,c is added). Then f(G) ≥ β(C,K) ·maxS∈P {f(S)} − ∑K\nk=1 ∑C c=1 εk,c, where β(C,K) is defined as 1− (1− 1 C )C − ( K 2 ) C−1.\nProof The proof is identical to the proof of Theorem 2 in the main text, using Lemma 12 in place of Lemma 1.\nFinally, we prove Theorem 5, which we restate here for convenience. Theorem 5 Let rk,c be the regret of Ek,c, and let β(K,C) = 1− ( 1− 1\nC )C − (K 2 ) C−1. Then\nE\n[ T∑\nt=1\nft(Gt) ] ≥ β(K,C) ·max\nS∈P\n{ T∑\nt=1\nft(S) } − E [ K∑\nk=1 C∑ c=1 rk,c\n] .\nProof The idea of the proof is to view TGONLINE as a version of TABULARGREEDY that, instead of greedily selecting single (element,color) pairs gk,c ∈ Pk × {c}, greedily selects (element vector, color) pairs ~gk,c ∈ PTk × {c}, where T is the number of rounds.\nFirst note that for any k ∈ [K], c ∈ [C], and x ∈ Pk × {c}, by definition of rk,c we have T∑\nt=1\nF̄t ( Gtk,c + g t k,c ) ≥\n( T∑\nt=1\nF̄t ( Gtk,c + x )) − rk,c .\nTaking the expectation of both sides over c, and choosing x to maximize the right hand side, we get\nT∑ t=1 Ft ( Gtk,c + g t k,c ) ≥ max x∈Pk×{c}\n{ T∑\nt=1\nFt ( Gtk,c + x )} − εk,c (16)\nwhere we define Ft(S) = E~c [ft(sample~c(S))] and εk,c = E [rk,c]. We now define some additional notation. For any set ~S of vectors in VT , define\nf(~S) = T∑ t=1 ft ({ ~at : ~a ∈ ~S }) .\nNext, for any set ~S of (element vector, color) pairs in ⋃K\nk=1(P T k ×{c}), define sample~c(~S) = ⋃K k=1 { ~x ∈ PTk : (~x, ck) ∈ ~S } .\nDefine F (~S) = E~c [ f(sample~c(~S)) ] . By linearity of expectation,\nF (~S) = T∑ t=1 Ft ({ (~xt, c) : (~x, c) ∈ ~S }) . (17)\nLet ~gk,c = (~x, c), where ~x is such that (~xt, c) = gtk,c for all t ∈ [T ]. Analogously to Gt−k,c, define ~G − k,c = {~gk′,c′ : k′ ∈ [K] , c′ < c} ∪ {~gk′,c : k′ < k}. By (17), for any (~x, c) ∈ VT × [C] we have F (~G−k,c + (~x, c)) =∑T t=1 Ft(G t− k,c + (~xt, c)). Combining this with (16), we get\nF ( ~G−k,c + ~gk,c ) ≥ max\na:a∈Pk\n{ F ( ~G−k,c + (a T , c) )} − εk,c (18)\nwhere aT is the unique element of {a}T . Having proved (18), we can now use Theorem 13 to complete the proof. Let ~Pk := { aT : a ∈ Pk } for each k ∈ [K], and define a new partition matroid over ground set { aT : a ∈ V } with feasible\nsolutions ~P := { ~S : ∀k ∈ [K] , |~S ∩ ~Pk| ≤ 1 } . Let ~G = {~gk,c : k ∈ [K] , c ∈ [C]}. As argued in the proof of Lemma\n3, Ft is monotone submodular. Using this fact together with (17), it is straightforward to show that F itself is monotone submodular. Thus by Theorem 13,\nF ( ~G) ≥ β(C,K) ·max ~S∈~P\n{ f(~S) } − K∑ k=1 C∑ c=1 εk,c .\nTo complete the proof, it suffices to show thatF (~G) = E [∑T t=1 ft(Gt) ] , and that max~S∈~P { f(~S) } ≥ maxS∈P {∑T t=1 ft(S) } . Both facts follow easily from the definitions."
    } ],
    "references" : [ {
      "title" : "Sponsored search auctions with Markovian users",
      "author" : [ "Gagan Aggarwal", "Jon Feldman", "S. Muthukrishnan", "Martin Pál" ],
      "venue" : "In WINE,",
      "citeRegEx" : "Aggarwal et al\\.,? \\Q2008\\E",
      "shortCiteRegEx" : "Aggarwal et al\\.",
      "year" : 2008
    }, {
      "title" : "The nonstochastic multiarmed bandit problem",
      "author" : [ "Peter Auer", "Nicolò Cesa-Bianchi", "Yoav Freund", "Robert E. Schapire" ],
      "venue" : "SIAM Journal on Computing,",
      "citeRegEx" : "Auer et al\\.,? \\Q2002\\E",
      "shortCiteRegEx" : "Auer et al\\.",
      "year" : 2002
    }, {
      "title" : "From external to internal regret",
      "author" : [ "Avrim Blum", "Yishay Mansour" ],
      "venue" : "Journal of Machine Learning Research,",
      "citeRegEx" : "Blum and Mansour.,? \\Q2007\\E",
      "shortCiteRegEx" : "Blum and Mansour.",
      "year" : 2007
    }, {
      "title" : "Maximizing a submodular set function subject to a matroid constraint",
      "author" : [ "Gruia Calinescu", "Chandra Chekuri", "Martin Pál", "Jan Vondrák" ],
      "venue" : "SIAM Journal on Computing,",
      "citeRegEx" : "Calinescu et al\\.,? \\Q2011\\E",
      "shortCiteRegEx" : "Calinescu et al\\.",
      "year" : 2011
    }, {
      "title" : "How to use expert advice",
      "author" : [ "Nicolò Cesa-Bianchi", "Yoav Freund", "David Haussler", "David P. Helmbold", "Robert E. Schapire", "Manfred K. Warmuth" ],
      "venue" : "J. ACM,",
      "citeRegEx" : "Cesa.Bianchi et al\\.,? \\Q1997\\E",
      "shortCiteRegEx" : "Cesa.Bianchi et al\\.",
      "year" : 1997
    }, {
      "title" : "Contextual sequence prediction with application to control library optimization",
      "author" : [ "Debadeepta Dey", "Tian Yu Liu", "Martial Hebert", "J Andrew Bagnell" ],
      "venue" : null,
      "citeRegEx" : "Dey et al\\.,? \\Q2013\\E",
      "shortCiteRegEx" : "Dey et al\\.",
      "year" : 2013
    }, {
      "title" : "Internet advertising and the generalized second price auction: Selling billions of dollars worth of keywords",
      "author" : [ "Benjamin Edelman", "Michael Ostrovsky", "Michael Schwarz" ],
      "venue" : "American Economic Review,",
      "citeRegEx" : "Edelman et al\\.,? \\Q2007\\E",
      "shortCiteRegEx" : "Edelman et al\\.",
      "year" : 2007
    }, {
      "title" : "Algorithmic methods for sponsored search advertising",
      "author" : [ "Jon Feldman", "S. Muthukrishnan" ],
      "venue" : "Performance Modeling and Engineering",
      "citeRegEx" : "Feldman and Muthukrishnan.,? \\Q2008\\E",
      "shortCiteRegEx" : "Feldman and Muthukrishnan.",
      "year" : 2008
    }, {
      "title" : "An analysis of approximations for maximizing submodular set functions - II",
      "author" : [ "Marshall L. Fisher", "George L. Nemhauser", "Laurence A. Wolsey" ],
      "venue" : "Mathematical Programming Study,",
      "citeRegEx" : "Fisher et al\\.,? \\Q1978\\E",
      "shortCiteRegEx" : "Fisher et al\\.",
      "year" : 1978
    }, {
      "title" : "Online learning of assignments that maximize submodular functions",
      "author" : [ "Daniel Golovin", "Andreas Krause", "Matthew Streeter" ],
      "venue" : "CoRR, abs/0908.0772,",
      "citeRegEx" : "Golovin et al\\.,? \\Q2009\\E",
      "shortCiteRegEx" : "Golovin et al\\.",
      "year" : 2009
    }, {
      "title" : "Playing games with approximation algorithms",
      "author" : [ "Sham M. Kakade", "Adam Tauman Kalai", "Katrina Ligett" ],
      "venue" : "In STOC,",
      "citeRegEx" : "Kakade et al\\.,? \\Q2007\\E",
      "shortCiteRegEx" : "Kakade et al\\.",
      "year" : 2007
    }, {
      "title" : "Efficient algorithms for online decision problems",
      "author" : [ "Adam Kalai", "Santosh Vempala" ],
      "venue" : "Journal of Computer and System Sciences,",
      "citeRegEx" : "Kalai and Vempala.,? \\Q2005\\E",
      "shortCiteRegEx" : "Kalai and Vempala.",
      "year" : 2005
    }, {
      "title" : "Submodular function maximization. In Tractability: Practical Approaches to Hard Problems (to appear)",
      "author" : [ "Andreas Krause", "Daniel Golovin" ],
      "venue" : "URL files/krause12survey.pdf",
      "citeRegEx" : "Krause and Golovin.,? \\Q2014\\E",
      "shortCiteRegEx" : "Krause and Golovin.",
      "year" : 2014
    }, {
      "title" : "Submodularity and its applications in optimized information gathering",
      "author" : [ "Andreas Krause", "Carlos Guestrin" ],
      "venue" : "ACM Transactions on Intelligent Systems and Technology,",
      "citeRegEx" : "Krause and Guestrin.,? \\Q2011\\E",
      "shortCiteRegEx" : "Krause and Guestrin.",
      "year" : 2011
    }, {
      "title" : "Sponsored search auctions",
      "author" : [ "Sébastien Lahaie", "David M. Pennock", "Amin Saberi", "Rakesh V. Vohra" ],
      "venue" : null,
      "citeRegEx" : "Lahaie et al\\.,? \\Q2007\\E",
      "shortCiteRegEx" : "Lahaie et al\\.",
      "year" : 2007
    }, {
      "title" : "Cost-effective outbreak detection in networks",
      "author" : [ "Jure Leskovec", "Andreas Krause", "Carlos Guestrin", "Christos Faloutsos", "Jeanne VanBriesen", "Natalie Glance" ],
      "venue" : "In KDD,",
      "citeRegEx" : "Leskovec et al\\.,? \\Q2007\\E",
      "shortCiteRegEx" : "Leskovec et al\\.",
      "year" : 2007
    }, {
      "title" : "Tight information-theoretic lower bounds for welfare maximization in combinatorial auctions",
      "author" : [ "Vahab Mirrokni", "Michael Schapira", "Jan Vondrák" ],
      "venue" : "In EC,",
      "citeRegEx" : "Mirrokni et al\\.,? \\Q2008\\E",
      "shortCiteRegEx" : "Mirrokni et al\\.",
      "year" : 2008
    }, {
      "title" : "An analysis of approximations for maximizing submodular set functions - I",
      "author" : [ "George L. Nemhauser", "Laurence A. Wolsey", "Marshall L. Fisher" ],
      "venue" : "Mathematical Programming,",
      "citeRegEx" : "Nemhauser et al\\.,? \\Q1978\\E",
      "shortCiteRegEx" : "Nemhauser et al\\.",
      "year" : 1978
    }, {
      "title" : "Learning diverse rankings with multi-armed bandits",
      "author" : [ "Filip Radlinski", "Robert Kleinberg", "Thorsten Joachims" ],
      "venue" : "In ICML,",
      "citeRegEx" : "Radlinski et al\\.,? \\Q2008\\E",
      "shortCiteRegEx" : "Radlinski et al\\.",
      "year" : 2008
    }, {
      "title" : "Learning policies for contextual submodular prediction",
      "author" : [ "Stephane Ross", "Jiaji Zhou", "Yisong Yue", "Debadeepta Dey", "Drew Bagnell" ],
      "venue" : "In Proceedings of The 30th International Conference on Machine Learning,",
      "citeRegEx" : "Ross et al\\.,? \\Q2013\\E",
      "shortCiteRegEx" : "Ross et al\\.",
      "year" : 2013
    }, {
      "title" : "Combinatorial optimization : polyhedra and efficiency. Volume B: Matroids, Trees, Stable Sets, chapters 39-69",
      "author" : [ "Alexander Schrijver" ],
      "venue" : null,
      "citeRegEx" : "Schrijver.,? \\Q2003\\E",
      "shortCiteRegEx" : "Schrijver.",
      "year" : 2003
    }, {
      "title" : "An online algorithm for maximizing submodular functions",
      "author" : [ "Matthew Streeter", "Daniel Golovin" ],
      "venue" : "Technical Report CMU-CS-07-171,",
      "citeRegEx" : "Streeter and Golovin.,? \\Q2007\\E",
      "shortCiteRegEx" : "Streeter and Golovin.",
      "year" : 2007
    }, {
      "title" : "An online algorithm for maximizing submodular functions",
      "author" : [ "Matthew Streeter", "Daniel Golovin" ],
      "venue" : "In NIPS,",
      "citeRegEx" : "Streeter and Golovin.,? \\Q2008\\E",
      "shortCiteRegEx" : "Streeter and Golovin.",
      "year" : 2008
    }, {
      "title" : "Online learning of assignments",
      "author" : [ "Matthew Streeter", "Daniel Golovin", "Andreas Krause" ],
      "venue" : "Advances in Neural Information Processing Systems",
      "citeRegEx" : "Streeter et al\\.,? \\Q2009\\E",
      "shortCiteRegEx" : "Streeter et al\\.",
      "year" : 2009
    }, {
      "title" : "Submodularity in Combinatorial Optimization",
      "author" : [ "Jan Vondrák" ],
      "venue" : "PhD thesis, Charles University, Prague, Czech Republic,",
      "citeRegEx" : "Vondrák.,? \\Q2007\\E",
      "shortCiteRegEx" : "Vondrák.",
      "year" : 2007
    }, {
      "title" : "Optimal approximation for the submodular welfare problem in the value oracle model",
      "author" : [ "Jan Vondrák" ],
      "venue" : "In STOC,",
      "citeRegEx" : "Vondrák.,? \\Q2008\\E",
      "shortCiteRegEx" : "Vondrák.",
      "year" : 2008
    } ],
    "referenceMentions" : [ {
      "referenceID" : 1,
      "context" : "When there is only one position, this problem becomes the well-studied multi-armed bandit problem (Auer et al., 2002).",
      "startOffset" : 98,
      "endOffset" : 117
    }, {
      "referenceID" : 6,
      "context" : "For example, online advertising models with click-through-rates (Edelman et al., 2007) make an assumption of this form.",
      "startOffset" : 64,
      "endOffset" : 86
    }, {
      "referenceID" : 18,
      "context" : "More recently, there have been attempts to incorporate the value of diversity in the reward function (Radlinski et al., 2008).",
      "startOffset" : 101,
      "endOffset" : 125
    }, {
      "referenceID" : 23,
      "context" : "An earlier version of this work appeared as Streeter et al. (2009).",
      "startOffset" : 44,
      "endOffset" : 67
    }, {
      "referenceID" : 3,
      "context" : "The problem of maximizing a submodular function subject to arbitrary matroid constraints was recently resolved by Calinescu et al. (2011), who provided an algorithm with optimal (under reasonable complexity assumptions) approximation guarantees.",
      "startOffset" : 114,
      "endOffset" : 138
    }, {
      "referenceID" : 16,
      "context" : "In fact, Mirrokni et al. (2008) show that any algorithm that is guaranteed to obtain a solution within a factor of (1−1/e+ ) of the optimal value requires exponentially many evaluations",
      "startOffset" : 9,
      "endOffset" : 32
    }, {
      "referenceID" : 7,
      "context" : "See Feldman and Muthukrishnan (2008) and Lahaie et al.",
      "startOffset" : 4,
      "endOffset" : 37
    }, {
      "referenceID" : 7,
      "context" : "See Feldman and Muthukrishnan (2008) and Lahaie et al. (2007) for more details on sponsored search ad allocation.",
      "startOffset" : 4,
      "endOffset" : 62
    }, {
      "referenceID" : 7,
      "context" : "See Feldman and Muthukrishnan (2008) and Lahaie et al. (2007) for more details on sponsored search ad allocation. Note that in both of these cases, the (expected) reward of a set S of (ad, position) pairs is ∑ (a,k)∈S g(a, k) for some nonnegative function g. It is easy to verify that such a reward function is monotone submodular. Thus, we can capture this model in our framework by setting Pk = A× {k}, where A is the set of ads. Another subsumed model, for web search, appears in Radlinski et al. (2008); it assumes that each user is interested in a particular set of results, and any list of results that intersects this set generates a unit of value; all other lists generate no value, and the ordering of results is irrelevant.",
      "startOffset" : 4,
      "endOffset" : 507
    }, {
      "referenceID" : 7,
      "context" : "See Feldman and Muthukrishnan (2008) and Lahaie et al. (2007) for more details on sponsored search ad allocation. Note that in both of these cases, the (expected) reward of a set S of (ad, position) pairs is ∑ (a,k)∈S g(a, k) for some nonnegative function g. It is easy to verify that such a reward function is monotone submodular. Thus, we can capture this model in our framework by setting Pk = A× {k}, where A is the set of ads. Another subsumed model, for web search, appears in Radlinski et al. (2008); it assumes that each user is interested in a particular set of results, and any list of results that intersects this set generates a unit of value; all other lists generate no value, and the ordering of results is irrelevant. Again, the reward function is monotone submodular. In this setting, it is desirable to display a diverse set of results in order to maximize the likelihood that at least one of them will interest the user. Our model is flexible in that we can handle position-dependent effects and diversity considerations simultaneously. For example, we can handle the case that each user u is interested in a particular set Au of ads and looks at a set Iu of positions, and the reward of an assignment S is any monotone-increasing concave function g of |S ∩ (Au × Iu)|. If Iu = {1, 2, . . . , k} and g(x) = x, this models the case where the quality is the number of relevant result that appear in the first k positions. If Iu equals all positions and g(x) = min {x, 1} we recover the model of Radlinski et al. (2008).",
      "startOffset" : 4,
      "endOffset" : 1536
    }, {
      "referenceID" : 8,
      "context" : "Perhaps surprisingly, no matter which ordering over the positions is chosen, this so-called locally greedy algorithm produces an assignment that obtains at least half the optimal value (Fisher et al., 1978).",
      "startOffset" : 185,
      "endOffset" : 206
    }, {
      "referenceID" : 3,
      "context" : "In the limit as C →∞, TABULARGREEDY can intuitively be viewed as an algorithm for a continuous extension of the problem followed by a rounding procedure, in the same spirit as Vondrák’s CONTINUOUSGREEDY algorithm (Calinescu et al., 2011).",
      "startOffset" : 213,
      "endOffset" : 237
    }, {
      "referenceID" : 17,
      "context" : "The latter process, in turn, can be shown to be equivalent to a greedy algorithm for maximizing a (different) submodular function subject to a cardinality constraint, which implies that it achieves a 1− 1/e approximation ratio (Nemhauser et al., 1978).",
      "startOffset" : 227,
      "endOffset" : 251
    }, {
      "referenceID" : 17,
      "context" : "For problems with this special property, it is known that the locally greedy algorithm obtains an approximation ratio of β(C) = 1− (1− 1 C ) C (Nemhauser et al., 1978).",
      "startOffset" : 143,
      "endOffset" : 167
    }, {
      "referenceID" : 17,
      "context" : "For problems with this special property, it is known that the locally greedy algorithm obtains an approximation ratio of β(C) = 1− (1− 1 C ) C (Nemhauser et al., 1978). Theorem 6 of Streeter and Golovin (2007) extends this result to handle additive error, and yields",
      "startOffset" : 144,
      "endOffset" : 210
    }, {
      "referenceID" : 18,
      "context" : "A similar approach was used by Radlinski et al. (2008) and Streeter and Golovin (2008) to obtain an online algorithm for different (simpler) online problems.",
      "startOffset" : 31,
      "endOffset" : 55
    }, {
      "referenceID" : 18,
      "context" : "A similar approach was used by Radlinski et al. (2008) and Streeter and Golovin (2008) to obtain an online algorithm for different (simpler) online problems.",
      "startOffset" : 31,
      "endOffset" : 87
    }, {
      "referenceID" : 4,
      "context" : "1 If TGONLINE is run with randomized weighted majority (Cesa-Bianchi et al., 1997) as the subroutine, then",
      "startOffset" : 55,
      "endOffset" : 82
    }, {
      "referenceID" : 2,
      "context" : "For example, Blum and Mansour (2007) consider online problems in which we are given time-selection functions I1, I2, .",
      "startOffset" : 13,
      "endOffset" : 37
    }, {
      "referenceID" : 3,
      "context" : "Vondrák’s algorithm, called the CONTINUOUSGREEDY algorithm, has also been extended to handle arbitrary matroid constraints (Calinescu et al., 2011).",
      "startOffset" : 123,
      "endOffset" : 147
    }, {
      "referenceID" : 22,
      "context" : "The study of this problem culminated in the elegant (1− 1/e) approximation algorithm of Vondrák (2008) and a matching unconditional lower bound of Mirrokni et al.",
      "startOffset" : 88,
      "endOffset" : 103
    }, {
      "referenceID" : 15,
      "context" : "The study of this problem culminated in the elegant (1− 1/e) approximation algorithm of Vondrák (2008) and a matching unconditional lower bound of Mirrokni et al. (2008). Vondrák’s algorithm, called the CONTINUOUSGREEDY algorithm, has also been extended to handle arbitrary matroid constraints (Calinescu et al.",
      "startOffset" : 147,
      "endOffset" : 170
    }, {
      "referenceID" : 20,
      "context" : "Schrijver (2003). We are interested in problems of the form",
      "startOffset" : 0,
      "endOffset" : 17
    }, {
      "referenceID" : 3,
      "context" : "To obtain a (1 − 1/e) approximation to Problem (2), Calinescu et al. (2011) use Vondrák’s CONTINUOUSGREEDY algorithm.",
      "startOffset" : 52,
      "endOffset" : 76
    }, {
      "referenceID" : 23,
      "context" : "However, Vondrák (2008) shows how a (1− 1/e) approximation may be obtained as follows.",
      "startOffset" : 9,
      "endOffset" : 24
    }, {
      "referenceID" : 3,
      "context" : "For technical reasons, Calinescu et al. (2011) replace all occurrences of the gradient∇F (y) in the continuous process with a related quantity called the marginal, ∆F (y) ∈ R≥0, defined coordinate-wise by (∆F (y))v = E [f(Sy ∪ {v})− f(Sy)] = (1− yv)(∇F (y))v.",
      "startOffset" : 23,
      "endOffset" : 47
    }, {
      "referenceID" : 3,
      "context" : "For technical reasons, Calinescu et al. (2011) replace all occurrences of the gradient∇F (y) in the continuous process with a related quantity called the marginal, ∆F (y) ∈ R≥0, defined coordinate-wise by (∆F (y))v = E [f(Sy ∪ {v})− f(Sy)] = (1− yv)(∇F (y))v. The second complication arises because ∆F (y) cannot be computed exactly given oracle access to f , but must be estimated via random sampling. Calinescu et al. (2011) choose to take enough samples are taken so that by Chernoff bounds it is likely that the estimate of each coordinate of ∆F (y(t)) for each iteration t ∈ {0, δ, 2δ, .",
      "startOffset" : 23,
      "endOffset" : 427
    }, {
      "referenceID" : 23,
      "context" : "Algorithm: Continuous Greedy (Vondrák (2008); Calinescu et al.",
      "startOffset" : 30,
      "endOffset" : 45
    }, {
      "referenceID" : 3,
      "context" : "Algorithm: Continuous Greedy (Vondrák (2008); Calinescu et al. (2011)) Input: matroidM = (V, I), monotone submodular f : 2V → R≥0, δ ∈ {1/n : n ∈ N}, ρ ∈ N",
      "startOffset" : 46,
      "endOffset" : 70
    }, {
      "referenceID" : 3,
      "context" : "For default parameters, Calinescu et al. (2011) select δ = 1/9d where d = max {|S| : S ∈ I} is the rank ofM, and ρ = 10 δ2 (1 + ln |V|) samples per marginal coordinate.",
      "startOffset" : 24,
      "endOffset" : 48
    }, {
      "referenceID" : 3,
      "context" : "Refer to (Calinescu et al., 2011) for details.",
      "startOffset" : 9,
      "endOffset" : 33
    }, {
      "referenceID" : 3,
      "context" : "We begin with an observation that the (randomized variant of the) pipage rounding scheme in Calinescu et al. (2011) is oblivious, in the sense that it does not require access to the objective function.",
      "startOffset" : 92,
      "endOffset" : 116
    }, {
      "referenceID" : 3,
      "context" : "We begin with an observation that the (randomized variant of the) pipage rounding scheme in Calinescu et al. (2011) is oblivious, in the sense that it does not require access to the objective function. This was emphasized by Calinescu et al. (2011), who point out its advantage in settings where we have only approximate-oracle access to f .",
      "startOffset" : 92,
      "endOffset" : 249
    }, {
      "referenceID" : 11,
      "context" : "For this, the follow the perturbed leader algorithm (Kalai and Vempala, 2005) is suitable.",
      "startOffset" : 52,
      "endOffset" : 77
    }, {
      "referenceID" : 21,
      "context" : "1 ANALYSIS OF THE CONTINUOUS GREEDY ALGORITHM WITH NOISE Streeter and Golovin (2008) introduced an analysis framework based on “meta-actions”, in which an online process over T rounds is interpreted as a single run in a combined instance of a suitable offline problem with objective ∑T t=1 Ft, in which the algorithm makes errors.",
      "startOffset" : 57,
      "endOffset" : 85
    }, {
      "referenceID" : 3,
      "context" : "That H is monotone submodular follows easily from the facts that ∂F ∂yu ≥ 0 and ∂ F ∂yu∂yv ≤ 0 (Calinescu et al., 2011).",
      "startOffset" : 95,
      "endOffset" : 119
    }, {
      "referenceID" : 3,
      "context" : "That H is monotone submodular follows easily from the facts that ∂F ∂yu ≥ 0 and ∂ F ∂yu∂yv ≤ 0 (Calinescu et al., 2011). Hence from Theorem 6 of Streeter and Golovin (2007), which bounds the performance of a noisy version of the locally greedy algorithm for precisely this problem, we obtain",
      "startOffset" : 96,
      "endOffset" : 173
    }, {
      "referenceID" : 3,
      "context" : "We bound this source of error as in Lemma 4, using a slight variation of an argument of Calinescu et al. (2011).",
      "startOffset" : 88,
      "endOffset" : 112
    }, {
      "referenceID" : 11,
      "context" : "1 of Kalai and Vempala (2005)), suitably tailored for our purposes, is O(d √ ngT ) where d is the rank ofM, n = |V|, and g = maxt,v ft({v}) is an upper bound for each coordinate of ∆Ft.",
      "startOffset" : 5,
      "endOffset" : 30
    }, {
      "referenceID" : 3,
      "context" : "3 GENERATING FEEDBACK: HOW TO ESTIMATE THE MARGINAL We could follow Calinescu et al. (2011) and take sufficiently many samples to ensure that with high probability the estimates for ∆F (y(τ − δ)) are sharp.",
      "startOffset" : 68,
      "endOffset" : 92
    }, {
      "referenceID" : 21,
      "context" : "Lemma 10 (Lemma 5 of Streeter and Golovin (2007)) Let E be a no-regret algorithm that incurs a worst-case expected regret R(T ) over T rounds in the full-information feedback model.",
      "startOffset" : 21,
      "endOffset" : 49
    }, {
      "referenceID" : 3,
      "context" : "As described in (Calinescu et al., 2011), CONTINUOUSGREEDY has a running time of order Õ(n) plus the time required to evaluate f on Õ(n) arguments, where the Õ notation suppresses logarithmic factors.",
      "startOffset" : 16,
      "endOffset" : 40
    }, {
      "referenceID" : 3,
      "context" : "As described in (Calinescu et al., 2011), CONTINUOUSGREEDY has a running time of order Õ(n) plus the time required to evaluate f on Õ(n) arguments, where the Õ notation suppresses logarithmic factors. Calinescu et al. (2011) describe this high complexity as being “mostly due to the number of random samples necessary to achieve high probability bounds” and suggest that this “can be substantially reduced by a more careful implementation and analysis.",
      "startOffset" : 17,
      "endOffset" : 225
    }, {
      "referenceID" : 15,
      "context" : "In Leskovec et al. (2007) it is shown how one can formalize this notion of utility using a monotone submodular function that measures the informativeness of a subset of blogs.",
      "startOffset" : 3,
      "endOffset" : 26
    }, {
      "referenceID" : 15,
      "context" : "The work by Leskovec et al. (2007) leaves two major shortcomings: Firstly, they select a set of blogs rather than a ranking, which is of practical importance for the presentation on a web service.",
      "startOffset" : 12,
      "endOffset" : 35
    }, {
      "referenceID" : 15,
      "context" : "The work by Leskovec et al. (2007) leaves two major shortcomings: Firstly, they select a set of blogs rather than a ranking, which is of practical importance for the presentation on a web service. Secondly, they do not address the problem of sequential prediction, where the set of blogs must be updated dynamically over time. In this paper, we address these shortcomings. Results on offline blog ranking. In order to model the blog ranking problem, we adopt the assumption that different users have different attention spans: Each user will only consider blogs appearing in a particular subset of positions. In our experiments, we assume that the probability that a user is willing to look at position k is proportional to γ, for some discount factor 0 < γ < 1. More formally, let g be the monotone submodular function measuring the informativeness of any set of blogs, defined as in Leskovec et al. (2007). Let Pk = B×{k}, where B is the set of blogs.",
      "startOffset" : 12,
      "endOffset" : 908
    }, {
      "referenceID" : 15,
      "context" : "The work by Leskovec et al. (2007) leaves two major shortcomings: Firstly, they select a set of blogs rather than a ranking, which is of practical importance for the presentation on a web service. Secondly, they do not address the problem of sequential prediction, where the set of blogs must be updated dynamically over time. In this paper, we address these shortcomings. Results on offline blog ranking. In order to model the blog ranking problem, we adopt the assumption that different users have different attention spans: Each user will only consider blogs appearing in a particular subset of positions. In our experiments, we assume that the probability that a user is willing to look at position k is proportional to γ, for some discount factor 0 < γ < 1. More formally, let g be the monotone submodular function measuring the informativeness of any set of blogs, defined as in Leskovec et al. (2007). Let Pk = B×{k}, where B is the set of blogs. Given an assignment S ∈ P , let S = S ∩{P1 ∪ P2 ∪ . . . ∪ Pk} be the assignment of blogs to positions 1 through k. We define the discounted value of the assignment S as f(S) = ∑K k=1 γ k ( g(S)− g(S[k−1]) ) . It can be seen that f : 2V → R≥0 is monotone submodular. For our experiments, we use the data set of Leskovec et al. (2007), consisting of 45,192 blogs, 16,551 cascades, and 2 million postings collected during 12 months of 2006.",
      "startOffset" : 12,
      "endOffset" : 1287
    }, {
      "referenceID" : 15,
      "context" : "The work by Leskovec et al. (2007) leaves two major shortcomings: Firstly, they select a set of blogs rather than a ranking, which is of practical importance for the presentation on a web service. Secondly, they do not address the problem of sequential prediction, where the set of blogs must be updated dynamically over time. In this paper, we address these shortcomings. Results on offline blog ranking. In order to model the blog ranking problem, we adopt the assumption that different users have different attention spans: Each user will only consider blogs appearing in a particular subset of positions. In our experiments, we assume that the probability that a user is willing to look at position k is proportional to γ, for some discount factor 0 < γ < 1. More formally, let g be the monotone submodular function measuring the informativeness of any set of blogs, defined as in Leskovec et al. (2007). Let Pk = B×{k}, where B is the set of blogs. Given an assignment S ∈ P , let S = S ∩{P1 ∪ P2 ∪ . . . ∪ Pk} be the assignment of blogs to positions 1 through k. We define the discounted value of the assignment S as f(S) = ∑K k=1 γ k ( g(S)− g(S[k−1]) ) . It can be seen that f : 2V → R≥0 is monotone submodular. For our experiments, we use the data set of Leskovec et al. (2007), consisting of 45,192 blogs, 16,551 cascades, and 2 million postings collected during 12 months of 2006. We use the population affected objective of Leskovec et al. (2007), and use a discount factor of γ = 0.",
      "startOffset" : 12,
      "endOffset" : 1459
    }, {
      "referenceID" : 18,
      "context" : "Note that C = 1 corresponds to the online algorithm of Radlinski et al. (2008) and Streeter and Golovin (2008).",
      "startOffset" : 55,
      "endOffset" : 79
    }, {
      "referenceID" : 18,
      "context" : "Note that C = 1 corresponds to the online algorithm of Radlinski et al. (2008) and Streeter and Golovin (2008).",
      "startOffset" : 55,
      "endOffset" : 111
    }, {
      "referenceID" : 17,
      "context" : "TGONLINE with C = 4 to the online algorithm of Radlinski et al. (2008); Streeter and Golovin (2008), based on the average of 100 experiments.",
      "startOffset" : 47,
      "endOffset" : 71
    }, {
      "referenceID" : 17,
      "context" : "TGONLINE with C = 4 to the online algorithm of Radlinski et al. (2008); Streeter and Golovin (2008), based on the average of 100 experiments.",
      "startOffset" : 47,
      "endOffset" : 100
    }, {
      "referenceID" : 0,
      "context" : "A slightly different Markov model of user behavior which is efficiently solvable was considered in Aggarwal et al. (2008). In that model, pclick and pabandon are the same for all users, and pabandon is a function of the ad in the slot currently being scanned rather than its index.",
      "startOffset" : 99,
      "endOffset" : 122
    }, {
      "referenceID" : 14,
      "context" : "Related Work An earlier version of this work appeared as Streeter et al. (2009) (also Golovin et al.",
      "startOffset" : 57,
      "endOffset" : 80
    }, {
      "referenceID" : 8,
      "context" : "(2009) (also Golovin et al. (2009)).",
      "startOffset" : 13,
      "endOffset" : 35
    }, {
      "referenceID" : 8,
      "context" : "(2009) (also Golovin et al. (2009)). The present article is significantly extended, including a new algorithm for online optimization over arbitrary matroids. For a general introduction to the literature on submodular function maximization (including offline versions of the problems we study), see Vondrák (2007) and the survey by Krause and Golovin (2014).",
      "startOffset" : 13,
      "endOffset" : 314
    }, {
      "referenceID" : 8,
      "context" : "(2009) (also Golovin et al. (2009)). The present article is significantly extended, including a new algorithm for online optimization over arbitrary matroids. For a general introduction to the literature on submodular function maximization (including offline versions of the problems we study), see Vondrák (2007) and the survey by Krause and Golovin (2014). For an overview of applications of submodularity to machine learning and artificial intelligence, see Krause and Guestrin (2011).",
      "startOffset" : 13,
      "endOffset" : 358
    }, {
      "referenceID" : 8,
      "context" : "(2009) (also Golovin et al. (2009)). The present article is significantly extended, including a new algorithm for online optimization over arbitrary matroids. For a general introduction to the literature on submodular function maximization (including offline versions of the problems we study), see Vondrák (2007) and the survey by Krause and Golovin (2014). For an overview of applications of submodularity to machine learning and artificial intelligence, see Krause and Guestrin (2011). In the online setting, the most closely related work is that of Streeter and Golovin (2008).",
      "startOffset" : 13,
      "endOffset" : 488
    }, {
      "referenceID" : 8,
      "context" : "(2009) (also Golovin et al. (2009)). The present article is significantly extended, including a new algorithm for online optimization over arbitrary matroids. For a general introduction to the literature on submodular function maximization (including offline versions of the problems we study), see Vondrák (2007) and the survey by Krause and Golovin (2014). For an overview of applications of submodularity to machine learning and artificial intelligence, see Krause and Guestrin (2011). In the online setting, the most closely related work is that of Streeter and Golovin (2008). Like us, they consider sequences of monotone submodular reward functions that arrive online, and develop an online algorithm that uses multi-armed bandit algorithms as subroutines.",
      "startOffset" : 13,
      "endOffset" : 581
    }, {
      "referenceID" : 8,
      "context" : "(2009) (also Golovin et al. (2009)). The present article is significantly extended, including a new algorithm for online optimization over arbitrary matroids. For a general introduction to the literature on submodular function maximization (including offline versions of the problems we study), see Vondrák (2007) and the survey by Krause and Golovin (2014). For an overview of applications of submodularity to machine learning and artificial intelligence, see Krause and Guestrin (2011). In the online setting, the most closely related work is that of Streeter and Golovin (2008). Like us, they consider sequences of monotone submodular reward functions that arrive online, and develop an online algorithm that uses multi-armed bandit algorithms as subroutines. The key difference from our work is that, as in Radlinski et al. (2008), they are concerned with selecting a set of K items rather than the more general problem of selecting an assignment of items to positions addressed in this paper.",
      "startOffset" : 13,
      "endOffset" : 835
    }, {
      "referenceID" : 8,
      "context" : "(2009) (also Golovin et al. (2009)). The present article is significantly extended, including a new algorithm for online optimization over arbitrary matroids. For a general introduction to the literature on submodular function maximization (including offline versions of the problems we study), see Vondrák (2007) and the survey by Krause and Golovin (2014). For an overview of applications of submodularity to machine learning and artificial intelligence, see Krause and Guestrin (2011). In the online setting, the most closely related work is that of Streeter and Golovin (2008). Like us, they consider sequences of monotone submodular reward functions that arrive online, and develop an online algorithm that uses multi-armed bandit algorithms as subroutines. The key difference from our work is that, as in Radlinski et al. (2008), they are concerned with selecting a set of K items rather than the more general problem of selecting an assignment of items to positions addressed in this paper. Kakade et al. (2007) considered the general problem of using α-approximation algorithms to construct no α-regret online algorithms, and essentially proved it could be done for the class of linear optimization problems in which the cost function has the form c(S,w) for a solution S and weight vector w, and c(S,w) is linear in w.",
      "startOffset" : 13,
      "endOffset" : 1019
    }, {
      "referenceID" : 5,
      "context" : "Since the earlier version of this paper appeared, subsequent research has produced algorithms that incorporate context into their decisions: Dey et al. (2013) developed an algorithm for contextual optimization of sequences of actions, and used it to optimize control libraries used for various robotic planning tasks.",
      "startOffset" : 141,
      "endOffset" : 159
    }, {
      "referenceID" : 10,
      "context" : "Of course, it is possible to linearize a submodular function by using a separate dimension for every possible function argument, but this results in an exponential number of dimensions, which leads to exponentially worse convergence time and regret bounds for the algorithms in Kakade et al. (2007) relative to TGONLINE.",
      "startOffset" : 278,
      "endOffset" : 299
    } ],
    "year" : 2014,
    "abstractText" : "Which ads should we display in sponsored search in order to maximize our revenue? How should we dynamically rank information sources to maximize the value of the ranking? These applications exhibit strong diminishing returns: Redundancy decreases the marginal utility of each ad or information source. We show that these and other problems can be formalized as repeatedly selecting an assignment of items to positions to maximize a sequence of monotone submodular functions that arrive one by one. We present an efficient algorithm for this general problem and analyze it in the no-regret model. Our algorithm possesses strong theoretical guarantees, such as a performance ratio that converges to the optimal constant of 1 − 1/e. We empirically evaluate our algorithm on two real-world online optimization problems on the web: ad allocation with submodular utilities, and dynamically ranking blogs to detect information cascades. Finally, we present a second algorithm that handles the more general case in which the feasible sets are given by a matroid constraint, while still maintaining a 1− 1/e asymptotic performance ratio.",
    "creator" : "LaTeX with hyperref package"
  }
}