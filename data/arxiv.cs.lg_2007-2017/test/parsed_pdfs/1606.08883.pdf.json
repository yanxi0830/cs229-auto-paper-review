{
  "name" : "1606.08883.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : null,
    "authors" : [ "Lili Su", "Nitin H. Vaidya" ],
    "emails" : [ "nhv}@illinois.edu", "(lilisu3@illinois.edu)" ],
    "sections" : [ {
      "heading" : null,
      "text" : "ar X\niv :1\n60 6.\n08 88\n3v 1\n[ cs\n.D C\n] 2\n8 Ju\nn 20\nagents repeatedly collect partially informative observations about an unknown state of the world, and try to collaboratively learn the true state. We focus on the impact of the adversarial agents on the performance of consensus-based non-Bayesian learning, where non-faulty agents combine local learning updates with consensus primitives. In particular, we consider the scenario where an unknown subset of agents suffer Byzantine faults – agents suffering Byzantine faults behave arbitrarily.\nWe propose two learning rules.\n– In our first update rule, each agent updates its local beliefs as (up to normalization) the product of (1) the likelihood of the cumulative private signals and (2) the weighted geometric average of the beliefs of its incoming neighbors and itself. Under reasonable assumptions on the underlying network structure and the global identifiability of the network, we show that all the non-faulty agents asymptotically agree on the true state almost surely. For the case when every agent is failure-free, we show that (with high probability) each agent’s beliefs on the wrong hypotheses decrease at rate O(exp(−Ct2)), where t is the number of iterations, and C is a constant. – In general when agents may be adversarial, network identifiability condition specified for the above learning rule scales poorly in the number of state candidates m. In addition, the computation complexity per agent per iteration of this learning rule is forbiddingly high. Thus, we propose a modification of our first learning rule, whose complexity per iteration per agent is O(m2n log n), where n is the number of agents in the network. We show that this modified learning rule works under a much weaker network identifiability condition. In addition, this new condition is independent of m.\n⋆ This research is supported in part by National Science Foundation award NSF 1421918. Any opinions, findings, and conclusions or recommendations expressed here are those of the authors and do not necessarily reflect the views of the funding agencies or the U.S. government.\n2"
    }, {
      "heading" : "1 Introduction",
      "text" : "Decentralized hypothesis testing (learning) has received significant amount of attention [1,2,3,5,6,7,8]. The traditional decentralized detection framework consists of a collection of spatially distributed sensors and a fusion center [5,6,7]. The sensors independently collect noisy observations of the environment state, and send only summary of the private observations to the fusion center, where a final decision is made. In the case when the sensors directly send all the private observations, the detection problem can be solved using a centralized scheme. The above framework does not scale well, since each sensor needs to be connected to the fusion center and full reliability of the fusion center is required, which may not be practical as the system scales.\nDistributed hypothesis testing in the absence of fusion center is considered in [2,22,23,21]. In particular, Gale and Kariv [2] studied the distributed hypothesis testing problem in the context of social learning, where fully Bayesian belief update rule is studied. Bayesian update rule is impractical in many applications due to memory and computation constraints of each agent.\nTo avoid the complexity of Bayesian learning, a non-Bayesian learning framework that combines local Bayesian learning with distributed consensus was proposed by Jadbabaie et al. [3], and has attracted much attention [10,14,15,16,11,18,17,13]. Jadbabaie et al. [3] considered the general setting where external signals are observed during each iteration of the algorithm execution. Specifically, the belief of each agent is repeatedly updated as the arithmetic mean of its local Bayesian update and the beliefs of its neighbors – combining iterative consensus algorithm with local Bayesian update. It is shown [3] that, under this learning rule, each agent learns the true state almost surely. The publication of [3] has inspired significant efforts in designing and analyzing non-Bayesian learning rules with a particular focus on refining the fusion strategies and analyzing the (asymptotic and/or finite time) convergence rates of the refined algorithms [10,14,15,16,11,18,17,13]. In this paper we are particularly interested in the log-linear form of the update rule, in which, essentially, each agent updates its belief as the geometric average of the local Bayesian update and its neighbors’ beliefs [15,10,14,16,11,18,17,13]. The log-linear form (geometric averaging) update rule is shown to converge exponentially fast [10,16]. Taking an axiomatic approach, the geometric averaging fusion is proved to be optimal [13]. An optimization-based interpretation of this rule is presented in [16], using dual averaging method with properly chosen proximal functions. Finite-time convergence rates are investigated independently in [14,11,17]. Both [14] and [18] consider time-varying networks, with slightly different network models. Specifically, [14] assumes that the union of every consecutive B networks is strongly connected, while [18] considers random networks. In this paper, we consider static networks for ease of exposition, although we believe that our results can be easily generalized to time-varying networks.\nThe prior work implicitly assumes that the networked agents are reliable in the sense that they correctly follow the specified learning rules. However, in some practical multi-agent networks, this assumption may not hold. For example, in social networks, it is possible that some agents are adversarial, and try to prevent the true state from being learned by the good agents. Thus, this paper focuses on the fault-tolerant version the non-Bayesian framework proposed in [3]. In particular, we assume that an unknown subset of agents may suffer Byzantine faults.\nAn agent suffering Byzantine fault may not follow the pre-specified algorithms/protocols, and misbehave arbitrarily. For instance, a faulty agent may lie to other agents (possibly non-consistently) about its own estimates. In addition, a faulty agent is assumed to have a complete knowledge of the system, including the network topology, the local functions of all the non-faulty agents, the algorithm specification of the non-faulty agents, the execution of the algorithm, the local estimates of all the non-faulty agents, and contents of messages the other agents send to each other. Also,\n3 the faulty agents can potentially collaborate with each other to prevent the non-faulty agents from achieving their goal. An alternative fault model, where some agents may unexpectedly cease computing and communicate with each other asynchronously, is considered in our companion work [34]. The Byzantine fault-tolerance problem was introduced by Pease et al. [24] and has attracted intensive attention from researchers [25,26,27,30,28,31]. Our goal is to design algorithms that enable all the non-faulty agents to learn the underlying true state.\nThe existing non-Bayesian learning algorithms [10,11,13,14,15,16,17,18] are not robust to Byzantine agents, since the malicious messages sent by the Byzantine agents are indiscriminatingly utilized in the local belief updates. On the other hand, the incorporation of Byzantine consensus is nontrivial, since (i) the effective communication networks are dependent on the all the random local observations, making it non-trivial to adapt analysis of previous algorithms to our setting; and (ii) the problem of identifying tight topological condition for reaching Byzantine multi-dimensional consensus iteratively is open, making it challenging to identify the minimal detectability condition on the networked agents to learn the true environmental state.\nContributions: Our contributions are two-fold.\n– We first propose an update rule wherein each agent iteratively updates its local beliefs as (up to normalization) the product of (1) the likelihood of the cumulative private signals and (2) the weighted geometric average of the beliefs of its incoming neighbors and itself (using iterative Byzantine multi-dimensional consensus). In contrast to the existing algorithms [14,11], where only the current private signal is used in the update, our proposed algorithm relies on the cumulative private signals. Under reasonable assumptions on the underlying network structure and the global identifiability of the network, we show that all the non-faulty agents asymptotically agree on the true state almost surely. In addition, for the special case when every agent is guaranteed to be failure-free, we show that (with high probability) each agent’s beliefs on the wrong hypotheses decrease at rate O(exp(−Ct2)), where t is the number of iterations, and C is a constant. Thus, our proposed rule may be of independent interest for the failure-free setting considered in [10,11,13,14,15,16,17,18]. – The local computation complexity per agent of the first learning rule is high due to the adoption of multi-dimensional consensus primitives. More importantly, the network identifiability condition used for that learning rule scales poorly in the number of possible states m. Thus, we propose a modification of our first learning rule, whose complexity per iteration per agent is O(m2n log n), where n is the number of agents in the network. We show that this modified learning rule works under a much weaker global identifiability condition, which is independent of m. We cast the general m–ary hypothesis testing problem into a collection of binary hypothesis testing sub-problems.\nOutline: The rest of the paper is organized as follows. Section 2 presents the problem formulation. Section 3 briefly reviews existing results on vector Byzantine consensus, and matrix representation of the state evolution. Our first algorithm and its correctness analysis are presented in Section 4. Section 5 demonstrates the above learning rule in the special case when f = 0, and presents a finite-time analysis.The modified learning rule and its correctness analysis are summarized in Section 6. Section 7 concludes the paper, and discusses possible extensions."
    }, {
      "heading" : "2 Problem Formulation",
      "text" : "Network Model: Our network model is similar to the model used in [4,30]. We consider a synchronous system. A collection of n agents (also referred as nodes) are connected by a directed network G(V, E),\n4 where V = {1, . . . , n} and E is the collection of directed edges. For each i ∈ V, let Ii denote the set of incoming neighbors of agent i. In any execution, up to f agents suffer Byzantine faults. For a given execution, let F denote the set of Byzantine agents, and N denote the set of non-faulty agents. Throughout this paper, we assume that f satisfies the condition implicitly imposed by the given topology conditions mentioned later. We assume that each non-faulty agent knows f , but does not know the actual number of faulty agents |F|. 1 Possible misbehavior of faulty agents includes sending incorrect and mismatching (or inconsistent) messages. The Byzantine agents are also assumed to have complete knowledge of system, including the network topology, underlying running algorithm, the states or even the entire history. The faulty agents may collaborate with each other adaptively [12]. Note that |F| ≤ f and |N | ≥ n− f since at most f agents may fail. (As noted earlier, although we assume a static network topology, our results can be easily generalized to time-varying networks.)\nThroughout this paper, we use the terms agent and node interchangeably.\nObservation Model: Our observation model is identical the model used in [3,11,18]. Let Θ = {θ1, θ2, . . . , θm} denote a set of m environmental states, which we call hypotheses. In the t-th iteration, each agent independently obtains a private signal about the environmental state θ∗, which is initially unknown to every agent in the network. Each agent i knows the structure of its private signal, which is represented by a collection of parameterized marginal distributions Di = {ℓi(wi|θ)| θ ∈ Θ, wi ∈ Si}, where ℓi(·|θ) is the distribution of private signal when θ is the true state, and Si is the finite private signal space. For each θ ∈ Θ, and each i ∈ V, the support of ℓi(·|θ) is the whole signal space, i.e., ℓi(wi|θ) > 0, ∀wi ∈ Si and ∀ θ ∈ Θ. Let sit be the private signal observed by agent i in iteration t, and let st = {s1t , s2t , . . . , snt } be the signal profile at time t (i.e., signals observed by the agents in iteration t). Given an environmental state θ, the signal profile st is generated according to the joint distribution ℓ1(s 1 t |θ)× ℓ2(s2t |θ)× · · · × ℓn(snt |θ). In addition, let si1,t be the signal history up to time t for agent i = 1, · · · , n, and let s1,t = {s11,t, s21,t, . . . , sn1,t} be the signal profile history up to time t."
    }, {
      "heading" : "3 Byzantine Consensus",
      "text" : "In this section, we briefly review relevant exsting results on Byzantine consensus. Byzantine consensus has attracted significant amount of attention [25,26,29,27,30,28,31]. While the past work mostly focus on scalar inputs, the more general vector (or multi-dimensional) inputs have been studied recently [31,29,28]. Complete communication networks are considered in [31,29], where tight conditions on the number of agents are identified. Incomplete communication networks are studied in [28]. Closer to the non-Bayesian learning problem is the class of iterative approximate Byzantine consensus algorithms, where each agent is only allowed to exchange information about its state with its neighbors. In particular, our learning algorithms build upon Byz-Iter algorithm proposed in [28] and a simple algorithm proposed in [30] for iterative Byzantine consensus with vector inputs and scalar inputs, respectively, in incomplete networks. A matrix representation of the non-faulty agents’ states evolution under Byz-Iter algorithm is provided by [28], which also captures the dynamics of the simple algorithm with scalar inputs in [30]. To make this paper self-contained, in this section, we briefly review the algorithm Byz-Iter and its matrix representation.\n3.1 Algorithm Byz-Iter [28]\nAlgorithm Byz-Iter is based on Tverberg’s Theorem [32].\n1 This is because the upper bound f can be learned via long-time performance statistics, whereas, the actual size of F varies across executions, and may be impossible to be predicted in some applications.\n5 Theorem 1. [32] Let f be a nonnegative integer. Let Y be a multiset containing vectors from R m such that |Y | ≥ (m + 1)f + 1. There exists a partition Y1, Y2, · · · , Yf+1 of Y such that Yi is nonempty for 1 ≤ i ≤ f + 1, and the intersection of the convex hulls of Yi’s are nonempty, i.e., ∩f+1i=1 Conv(Yi) 6= Ø, where Conv(Yi) is the convex hull of Yi for i = 1, · · · , f + 1.\nThe proper partition in Theorem 1, and the points in ∩f+1i=1 Conv(Yi), are referred as Tverberg partition of Y and Tverberg points of Y , respectively.\nFor convenience of presenting our algorithm in Section 4, we present Byz-Iter (described in Algorithm 2) below using One-Iter (described in Algorithm 1) as a primitive. The parameter xi passed to One-Iter at agent i, and yi returned by One-Iter are both m-dimensional vectors. Let vi be the state of agent i that will be iteratively updated, with vit being the state at the end of iteration t and vi0 being the input of agent i. In each iteration t ≥ 1, a non-faulty agent performs the steps inOne-Iter. In particular, in the message receiving step, if a message is not received from some neighbor, that neighbor must be faulty, as the system is synchronous. In this case, the missing message values are set to some default value. Faulty agents may deviate from the algorithm specification arbitrarily. In Byz-Iter, the value returned by One-Iter at agent i is assigned to vit.\nAlgorithm 1: Algorithm One-Iter with input xi at agent i\n1 Zi ← Ø; 2 Transmit xi on all outgoing links;\n3 Receive messages on all incoming links. % These message values form a multiset Ri of size |Ii|.% 4 for every C ⊆ Ri ∪ {xi} such that |C| = (m+ 1)f + 1 do 5 add to Zi a Tverberg point of multiset C 6 end 7 Compute yi as follows: yi ← 1 1+|Zi| ( xi + ∑ z∈Zi z ) ; 8 Return yi;\nAlgorithm 2: Algorithm Byz-Iter [28]: t-th iteration at agent i\n1 vit ← One-Iter(vit−1);\nRemark 1. Note that for each agent i ∈ N , the computation complexity per iteration is\nΩ (( |Ri ∪ {xi}| (m+ 1)f + 1 )) = Ω (( |Ii|+ 1 (m+ 1)f + 1 )) .\nIn the worst case, ||Ii|+ 1| = n, and\nΩ (( |Ii|+ 1 (m+ 1)f + 1 )) = Ω ((\nn\n(m+ 1)f + 1\n))\n= Ω\n(\n(n\ne\n)(m+1)f+1 )\n.\nSince our first learning rule is based on Algorithm Byz-Iter, the computation complexity of our first proposed algorithm is also high. Nevertheless, our first learning rule contains our main algorithmic\n6 ideas. More importantly, this learning rule can be modified such that the computation complexity per iteration per agent is O(m2n log n). Specifically, the modified learning rule adopts the scalar Byzantine consensus instead of the m–dimensional consensus. This modified learning rule is optimal in the sense that it works under minimal network identifiability requirements.\n3.2 Correctness of Algorithm Byz-Iter\nWe briefly summarize the aspects of correctness proof of Algorithm 2 from [28] that are necessary for our subsequent discussion. By using the Tverberg points in the update of vit above, effectively, the extreme message values (that may potentially be sent by faulty agents) are trimmed away. Informally speaking, trimming certain messages can be viewed as ignoring (or removing) incoming links that carry the outliers. [28] shows that the effective communication network thus obtained can be characterized by a “reduced graph” of G(V, E), defined below. It is important to note that the non-faulty agents do not know the identity of the faulty agents.\nDefinition 1 (m–dimensional reduced graph). An m–dimensional reduced graph H(N , EF ) of G(V, E) is obtained by (i) removing all faulty nodes F , and all the links incident on the faulty nodes F ; and (ii) for each non-faulty node (nodes in N ), removing up to mf additional incoming links.\nDefinition 2. A source component in any given m–dimensional reduced graph is a strongly connected component (of that reduced graph), which does not have any incoming links from outside that component.\nIt turns out that the effective communication network is potentially time-varying (partly) due to time-varying behavior of faulty nodes. Assumption 1 below states a condition that is sufficient for reaching approximate Byzantine vector consensus using Algorithm 1 [28].\nAssumption 1 Every m–dimensional reduced graph of G(V, E) contains a unique source component.\nLet Cm be the set of all the m–dimensional reduced graph of G(V, E). Define χm , |Cm|. Since G(V, E) is finite, we have χm < ∞. Let Hm ∈ Cm be an m–dimensional reduced graph of G(V, E) with source component SHm . Define\nγm , minHm∈Cm |SHm |, (1)\ni.e., γm is the minimum source component size among all the m–dimensional reduced graphs. Note that γm ≥ 1 if Assumption 1 holds for a given m.\nTheorem 2. [28] Suppose Assumption 1 holds for a given m ≥ 1. Under Algorithm Byz-Iter, all the non-faulty agents (agents in N ) reach consensus asymptotically, i.e., limt→∞ |vit − vjt | = 0,∀ i, j ∈ N .\nThe proof of Theorem 2 relies crucially on a matrix representation of the state evolution."
    }, {
      "heading" : "3.3 Matrix Representation [28]",
      "text" : "Let |F| = φ (thus, 0 ≤ φ ≤ f). Without loss of generality, assume that agents 1 through n− φ are non-faulty, and agents n− φ+ 1 to n are Byzantine.\n7 Lemma 1. [28] Suppose Assumption 1 holds for a given m ≥ 1. The state updates performed by the non-faulty agents in the t–th iteration (t ≥ 1) can be expressed as\nvit =\nn−φ ∑\nj=1\nAij[t]v j t−1, (2)\nwhere A[t] ∈ R(n−φ)×(n−φ) is a row stochastic matrix for which there exists an m–dimensional reduced graph Hm[t] with adjacency matrix Hm[t] such that A[t] ≥ βmHm[t], where 0 < βm ≤ 1 is a constant that depends only on G(V, E).\nLet Φ(t, r) , A[t] · · ·A[r] for 1 ≤ r ≤ t+ 1. By convention, Φ(t, t) = A[t] and Φ(t, t+ 1) = I. Note that Φ(t, r) is a backward product. Using prior work on coefficients of ergodicity [9], under Assumption 1, it has been shown [28,19] that\nlim t≥r, t→∞ Φ(t, r) = 1π(r), (3)\nwhere π(r) ∈ Rn−φ is a row stochastic vector, and 1 is the column vector with each entry being 1. Recall that χm is the total number of m–dimensional reduced graphs of G(V, E), and βm is defined in Lemma 1, and φ , |F|. The convergence rate in (3) is exponential.\nTheorem 3. [28] For all t ≥ r ≥ 1, it holds that |Φij(t, r)− πj(r)| ≤ (1 − βνm)⌈ t−r+1 ν ⌉, where ν , χm(n− φ). Recall that γm is defined in (1). The next lemma is a consequence of the results in [28].\nLemma 2. [28] For any r ≥ 1, there exists a reduced graph H[r] with source component Sr such that πi(r) ≥ βχm(n−φ)m for each i ∈ Sr. In addition, |Sr| ≥ γm."
    }, {
      "heading" : "3.4 Tight Topological Condition for Scalar Iterative Byzantine Consensus",
      "text" : "The above analysis shows that Assumption 1 is sufficient for achieving Byzantine consensus iteratively. For the special case when m = 1,(i.e., the inputs provided at individual non-faulty agents are scalars) it has been shown [30] that Assumption 1 is also necessary.\nTheorem 4. [30] For scalar inputs, iterative approximate Byzantine consensus is achievable among non-faulty agents if and only if every 1-dimensional reduced graph of G(V, E) contains only one source component.\nMoreover, the following simple algorithm (Algorithm 3) works under Assumption 1 when m = 1. In addition, it has been show that the dynamic of the non-faulty agents states admits the same matrix representation as in Subsection 3.3 with the reduced graph being 1–dimensional reduced graph defined in Definition 1.\nWith the above background on Byzantine vector consensus, we are now ready to present our first algorithm and its analysis."
    }, {
      "heading" : "4 Byzantine Fault-Tolerant Non-Bayesian Learning (BFL)",
      "text" : "In this section, we present our first learning rule, named Byzantine Fault-Tolerant Non-Bayesian Learning (BFL). In BFL, each agent i maintains a belief vector µi ∈ Rm, which is a distribution over the set Θ, with µi(θ) being the probability with which the agent i believes that θ is the true\n8 Algorithm 3: Algorithm Scalar Byzantine Consensus: iteration t ≥ 1 [30] 1 Transmit vi[t− 1] on all outgoing links; 2 Receive messages on all incoming links. % These message values wj [t] for each j ∈ Ii form a multiset\nRi[t] of size |Ii|. %\n3 Sort the received values wj [t] for each j ∈ Ii in a non-decreasing order; 4 Remove the largest f values and the smallest f values. % Denote the set of indices of incoming\nneighbors whose values have not been removed at iteration t by I∗i [t].%\n5 Update vi as follows: vi[t] ← ∑ j∈I∗ i [t] wj [t]+v\ni[t−1] 1+|I∗\ni [t]| ;\nenvironmental state. Since no signals are observed before the execution of an algorithm, the belief µi is often initially set to be uniform over the set Θ, i.e., (\nµi0(θ1), µ i 0(θ1), . . . , µ i 0(θm)\n)T = ( 1 m , . . . , 1 m )T .\nRecall that θ∗ is the true environmental state. We say the networked agents collaboratively learn θ∗ if for every non-faulty agent i ∈ N ,\nlim t→∞\nµit(θ ∗) = 1 a.s. (4)\nwhere a.s. denotes almost surely.\nBFL is a modified version of the geometric averaging update rule that has been investigated in previous work [14,15,11,17]. In particular, we modify the averaging rule to take into account Byzantine faults. More importantly, in each iteration, we use the likelihood of the cumulative local observations (instead of the likelihood of the current observation only) to update the local beliefs.\nFor t ≥ 1, the steps to be performed by agent i in the t–th iteration are listed below. Note that faulty agents can deviate from the algorithm specification. The algorithm below uses One-Iter presented in the previous section as a primitive. Recall that si1,t is the cumulative local observations up to iteration t. Since the observations are i.i.d., it holds that ℓi(s i 1,t|θ) = ∏t r=1 ℓi(s i r|θ). So ℓi(si1,t|θ) can be computed iteratively in Algorithm 4.\nAlgorithm 4: BFL: Iteration t ≥ 1 at agent i 1 ηit ← One-Iter(log µit−1); 2 Observe sit; 3 for θ ∈ Θ do 4 ℓi(s i 1,t|θ) ← ℓi(sit|θ) ℓi(si1,t−1|θ); 5 µit(θ) ← ℓi(si1,t|θ) exp(ηit(θ))∑m\np=1 ℓi(s i 1,t|θp) exp(ηit(θp))\n;\n6 end\nThe main difference of Algorithm 4 with respect to the algorithms in [14,15,11,17] is that (i) our algorithm uses a Byzantine consensus iteration as a primitive (in line 1), and (ii) ℓi(s i 1,t|θ) used in line 5 is the likelihood for observations from iteration 1 to t (the previous algorithms instead use ℓi(s i t|θ) here). Observe that the consensus step is being performed on log of the beliefs, with the result being stored as ηit (in line 1) and used in line 4 to compute the new beliefs.\n9 Recalling the matrix representation of the Byz-Iter algorithm as per Lemma 1, we can write the following equivalent representation of line 1 of Algorithm 4.\nηit(θ) =\nn−φ ∑\nj=1\nAij [t] log µ j t−1(θ) = log\nn−φ ∏\nj=1\nµ j t−1(θ) Aij [t], ∀θ ∈ Θ. (5)\nwhere A[t] is a row stochastic matrix whose properties are specified in Lemma 1. Note that µit(θ) is random for each i ∈ N and t ≥ 1, as it is updated according to local random observations. Since the consensus is performed over log µit ∈ Rm, the update matrix A[t] is also random. In particular, for each t ≥ 1, matrix A[t] is dependent on all the cumulative observations over the network up to iteration t. This dependency makes it non-trivial to adapt analysis from previous algorithms to our setting. In addition, adopting the local cumulative observation likelihood makes the analysis with Byzantine faults easier."
    }, {
      "heading" : "4.1 Identifiability",
      "text" : "In the absence of agent failures [3], for the networked agents to detect the true hypothesis θ∗, it is sufficient to assume that G(V, E) is strongly connected, and that θ∗ is globally identifiable. That is, for any θ 6= θ∗, there exists a node j ∈ V such that the Kullback-Leiber divergence between the true marginal ℓj(·|θ∗) and the marginal ℓj(·|θ), denoted by D (ℓj(·|θ∗)||ℓj(·|θ)), is nonzero; equivalently,\n∑ j∈V D (ℓj(·|θ∗)||ℓj(·|θ)) 6= 0, (6)\nwhere D (ℓj(·|θ∗)||ℓj(·|θ)) is defined as\nD (ℓj(·|θ∗)||ℓj(·|θ)) , ∑ wj∈Sj ℓj(wj |θ∗) log\nℓj(wj |θ∗) ℓj(wj |θ) . (7)\nSince θ∗ may change from execution to execution, (6) is required to hold for any choice of θ∗. Intuitively speaking, if any pair of states θ1 and θ2 can be distinguished by at least one agent in the network, then sufficient exchange of local beliefs over strongly connected network will enable every agent distinguish θ1 and θ2. However, in the presence of Byzantine agents, a stronger global identifiability condition is required. The following assumption builds upon Assumption 1.\nAssumption 2 Suppose that Assumption 1 holds for m = |Θ|. For any θ 6= θ∗, and for any m–dimensional reduced graph H of G(V, E) with SH denoting the unique source component, the following holds\n∑\nj∈SH D (ℓj(·|θ∗) ‖ ℓj(·|θ)) 6= 0. (8)\nIn contrast to (6), where the summation is taken over all the agents in the network, in (8), the summation is taken over agents in the source component only. Intuitively, the condition imposed by Assumption 2 is that all the agents in the source component can detect the true state θ∗ collaboratively. If iterative consensus is achieved, the accurate belief can be propagated from the source component to every other non-faulty agent in the network.\n10\nRemark 2. We will show later that when Assumption 2 holds, BFL algorithm enables all the nonfaulty agents concentrate their beliefs on the true state θ∗ almost surely. That is, Assumption 2 is a sufficient condition for a consensus-based non-Bayesian learning algorithm to exist. However, Assumption 2 is not necessary, observing that Assumption 1 (upon which Assumption 2 builds) is not necessary for m-dimensional Byzantine consensus algorithms to exist. As illustrated by our second learning rule (described later), the adoption of m-dimensional Byzantine consensus primitives is not necessary. Nevertheless, BFL contains our main algorithmic and analytical ideas. In addition, BFL provides an alternative learning rule for the failure-free setting (where no fault-tolerant consensus primitives are needed)."
    }, {
      "heading" : "4.2 Convergence Results",
      "text" : "Our proof parallels the structure of a proof in [14], but with some key differences to take into account our update rule for the belief vector.\nFor any θ1, θ2 ∈ Θ, and any i ∈ V, define ψit(θ1, θ2) and Lt(θ1, θ2) as follows\nψit(θ1, θ2) , log µit(θ1)\nµit(θ2) , Lit(θ1, θ2) , log\nℓi(s i t|θ1) ℓi(s i t|θ2) . (9)\nTo show Algorithm 4 solves (4), we will show that ψit(θ, θ ∗) a.s.−−→ −∞ for θ 6= θ∗, which implies that µit(θ)\na.s.−−→ 0 for all θ 6= θ∗ and for all i ∈ N , i.e., all non-faulty agents asymptotically concentrate their beliefs on the true hypothesis θ∗. We do this by investigating the dynamics of beliefs which is represented compactly in a matrix form.\nFor each θ 6= θ∗, and each i ∈ N = {1, 2, · · · , n− φ}, we have\nψit(θ, θ ∗) = log\nµit(θ)\nµit(θ ∗)\n(a) = log\n\n\nn−φ ∏\nj=1\n(\nµ j t−1(θ)\nµ j t−1(θ ∗)\n)Aij [t]\n× ℓi(s\ni 1,t|θ)\nℓi(s i 1,t|θ∗)\n\n\n=\nn−φ ∑\nj=1\nAij[t] log µ j t−1(θ)\nµ j t−1(θ\n∗) + log\nℓi(s i 1,t|θ)\nℓi(s i 1,t|θ∗)\n=\nn−φ ∑\nj=1\nAij[t]ψ j t−1(θ, θ\n∗) + t ∑\nr=1\nLir(θ, θ∗), (10)\nwhere equality (a) follows from (5) and the update of µi in Algorithm 4, and the last equality follows from (9) and the fact that the local observations are i.i.d. for each agent.\nLet ψt(θ, θ ∗) ∈ Rn−φ be the vector that stacks ψit(θ, θ∗), with the i–th entry being ψit(θ, θ∗) for\nall i ∈ N . The evolution of ψ(θ, θ∗) can be compactly written as\nψt(θ, θ ∗) = A[t]ψt−1(θ, θ ∗) + t ∑\nr=1\nLr(θ, θ∗). (11)\nExpanding (11), we get\nψt(θ, θ ∗) = Φ(t, 1)ψ0(θ, θ ∗) + t ∑\nr=1\nΦ(t, r + 1)\nr ∑\nk=1\nLk(θ, θ∗). (12)\n11\nFor each θ ∈ Θ and i ∈ V, define Hi(θ, θ∗) ∈ Rn−φ as\nHi(θ, θ ∗) ,\n∑\nwi∈Si ℓi(wi|θ∗) log\nℓi(wi | θ) ℓi(wi | θ∗)\n= −D(ℓi(·|θ∗) ‖ ℓi(·|θ)) by (7) ≤ 0. (13)\nLet H ∈ C be an arbitrary reduced graph with source component SH. Define C0 and C1 as\n−C0 , min i∈V min θ1,θ2∈Θ;θ1 6=θ2 min wi∈Si\n( log ℓi(wi|θ1) ℓi(wi|θ2) ) , (14)\nC1 , minH∈C min θ,θ∗∈Θ;θ 6=θ∗\n∑\ni∈SH D(ℓi(·|θ∗) ‖ ℓi(·|θ)). (15)\nThe constant C0 serves as an universal upper bound on | log ℓi(wi|θ1)ℓi(wi|θ2) | for all choices of θ1 and θ2, and for all signals. Intuitively, the constant C1 is the minimal detection capability of the source component under Assumption 2.\nDue to |Θ| = m < ∞ and |Si| < ∞ for each i ∈ N , we know that C0 < ∞. Besides, it is easy to see that −C0 ≤ 0 (thus, C0 ≥ 0). In addition, under Assumption 2, we have C1 > 0.\nNow we present a key lemma for our main theorem.\nLemma 3. Under Assumption 2, for any θ 6= θ∗, it holds that\n1 t2\nt ∑\nr=1\n\n\nn−φ ∑\nj=1\nΦij(t, r + 1) r ∑\nk=1\nLjk(θ, θ∗)− r n−φ ∑\nj=1\nπj(r + 1)Hj(θ, θ ∗)\n\n a.s.−−→ 0. (16)\nAs it can be seen later, the proof of Lemma 3 is significantly different from the analogous lemma in [14].\nTheorem 5. When Assumption 2 holds, each non-faulty agent i ∈ N will concentrate its belief on the true hypothesis θ∗ almost surely, i.e., µit(θ) a.s.−−→ 0 for all θ 6= θ∗.\nProof. Consider any θ 6= θ∗. Recall from (12) that\nψt(θ, θ ∗) = Φ(t, 1)ψ0(θ, θ ∗) + t ∑\nr=1\nΦ(t, r + 1)\nr ∑\nk=1\nLk(θ, θ∗)\n=\nt ∑\nr=1\nΦ(t, r + 1)\nr ∑\nk=1\nLk(θ, θ∗).\nThe last equality holds as µi0 is uniform, and ψ i 0(θ, θ ∗) = 0 for each i ∈ N . Since the supports of ℓi(·|θ) and ℓi(·|θ∗) are the whole signal space Si for each agent i ∈ N , it holds that ∣ ∣ ∣\nℓi(wi|θ) ℓi(wi|θ∗)\n∣ ∣\n∣ < ∞ for each wi ∈ Si, and\n0 ≥ Hi(θ, θ∗) ≥ min wi∈Si\n(\nlog ℓi(wi|θ) ℓi(wi|θ∗)\n)\n≥ − C0 > −∞. (17)\n12\nBy (17), we know that |∑n−φj=1 πj(r+1)Hj(θ, θ∗)| ≤ C0 < ∞. Due to the finiteness of ∑n−φ j=1 πj(r+ 1)Hj(θ, θ ∗), we are able to add and subtract r1 ∑n−φ j=1 πj(r + 1)Hj(θ, θ ∗) from (12). We get\nψt(θ, θ ∗) =\nt ∑\nr=1\n\nΦ(t, r + 1)\nr ∑\nk=1\nLk(θ, θ∗)− r1 n−φ ∑\nj=1\nπj(r + 1)Hj(θ, θ ∗)\n\n\n+ t ∑\nr=1\nr1\nn−φ ∑\nj=1\nπj(r + 1)Hj(θ, θ ∗). (18)\nFor each i ∈ N , we have\nψit(θ, θ ∗) =\nt ∑\nr=1\n\n\nn−φ ∑\nj=1\nΦij(t, r + 1)\nr ∑\nk=1\nLjk(θ, θ∗)− r n−φ ∑\nj=1\nπj(r + 1)Hj(θ, θ ∗)\n\n\n+\nt ∑\nr=1\nr\nn−φ ∑\nj=1\nπj(r + 1)Hj(θ, θ ∗). (19)\nTo show limt→∞ µit(θ) a.s.−−→ 0 for θ 6= θ∗, it is enough to show ψit(θ, θ∗) a.s.−−→ −∞. Our convergence proof has similar structure as the analysis in [14]. From Lemma 3, we know that\n1 t2\nt ∑\nr=1\n\n\nn−φ ∑\nj=1\nΦij(t, r + 1)\nr ∑\nk=1\nLjk(θ, θ∗)− r n−φ ∑\nj=1\nπj(r + 1)Hj(θ, θ ∗)\n\n a.s.−−→ 0. (20)\nNext we show that the second term of the right hand side of (19) decreases quadratically in t.\nt ∑\nr=1\nr\nn−φ ∑\nj=1\nπj(r + 1)Hj(θ, θ ∗) ≤\nt ∑\nr=1\nr ∑\nj∈Sr πj(r + 1)Hj(θ, θ\n∗) by (13)\n≤ t ∑\nr=1\nrβχ(n−φ) ∑\nj∈Sr Hj(θ, θ\n∗) by Lemma 2\n≤ − t ∑\nr=1\nrβχ(n−φ)C1 by (15) and (13)\n≤ − t 2\n2 βχ(n−φ)C1. (21)\nTherefore, by (19), (20) and (21), almost surely, the following hold\nlim t→∞\n1 t2 ψit(θ, θ ∗) ≤ −1 2 βχ(n−φ)C1.\nTherefore, we have ψit(θ, θ ∗) a.s.−−→ −∞ and µit(θ) a.s.−−→ 0 for i ∈ N and θ 6= θ∗, proving Theorem 5.\nWe now present the proof of our key lemma – Lemma 3.\n13\nProof (Proof of Lemma 3). By (9), we have\n∣ ∣Lir(θ, θ∗) ∣ ∣ =\n∣ ∣ ∣ ∣ log ℓi(s i t|θ)\nℓi(s i t|θ∗)\n∣ ∣ ∣ ∣\n≤ max i∈V max θ1,θ2∈Θ;θ1 6=θ2 max wi∈Si\n∣ ∣ ∣ ∣ log ℓi(wi|θ1) ℓi(wi|θ2) ∣ ∣ ∣ ∣ .\nNote that maxi∈V maxθ1,θ2∈Θ;θ1 6=θ2 maxwi∈Si\n∣ ∣\n∣ log ℓi(wi|θ1)\nℓi(wi|θ2)\n∣ ∣ ∣ is symmetric in θ1 and θ2. Thus,\n∣ ∣Lir(θ, θ∗) ∣ ∣ ≤ max i∈V max θ1,θ2∈Θ;θ1 6=θ2 max wi∈Si\n∣ ∣ ∣ ∣ log ℓi(wi|θ1) ℓi(wi|θ2) ∣ ∣ ∣ ∣ = max i∈V max θ1,θ2∈Θ;θ1 6=θ2 max wi∈Si log ℓi(wi|θ1) ℓi(wi|θ2)\n= max i∈V max θ1,θ2∈Θ;θ1 6=θ2 max wi∈Si − log ℓi(wi|θ2) ℓi(wi|θ1)\n= −min i∈V min θ1,θ2∈Θ;θ1 6=θ2 min wi∈Si log ℓi(wi|θ2) ℓi(wi|θ1) = −(−C0) = C0 < ∞. (22)\nThus, adding and subtracting 1 t2 ∑t r=1 ∑n−φ j=1 πj(r + 1) ∑r k=1L j k(θ, θ ∗) from the first term on the right hand side of (19), we can get\n1 t2\nt ∑\nr=1\n\n\nn−φ ∑\nj=1\nΦij(t, r + 1) r ∑\nk=1\nLjk(θ, θ∗)− πj(r + 1)r n−φ ∑\nj=1\nHj(θ, θ ∗)\n\n\n= 1\nt2\nt ∑\nr=1\nn−φ ∑\nj=1\n(Φij(t, r + 1)− πj(r + 1)) r ∑\nk=1\nLjk(θ, θ∗)\n+ 1\nt2\nt ∑\nr=1\nn−φ ∑\nj=1\nπj(r + 1)\n(\nr ∑\nk=1\nLjk(θ, θ∗)− rHj(θ, θ∗) ) . (23)\nFor the first term of the right hand side of (23), we have\n1 t2\n∣ ∣ ∣ ∣ ∣ ∣ t ∑\nr=1\nn−φ ∑\nj=1\n(Φij(t, r + 1)− πj(r + 1)) r ∑\nk=1\nLjk(θ, θ∗)\n∣ ∣ ∣ ∣ ∣ ∣\n≤ 1 t2\nt ∑\nr=1\nn−φ ∑\nj=1\n|Φij(t, r + 1)− πj(r + 1)| r ∑\nk=1\n∣ ∣\n∣ Ljk(θ, θ∗)\n∣ ∣ ∣ (24)\n≤ 1 t2\nt ∑\nr=1\nn−φ ∑\nj=1\n|Φij(t, r + 1)− πj(r + 1)| rC0 by (22)\n≤ 1 t2\nt ∑\nr=1\nn−φ ∑\nj=1\n(1− βν)⌈ t−rν ⌉rC0 by Theorem 3\n≤ 1 t2\n(t(n− φ)C0) t ∑\nr=1\n(1− βν)⌈ t−rν ⌉\n≤ (n− φ)C0 (1− βν)(1− (1− βν) 1ν )t . (25)\nThus, for every sample path, we have\n1 t2\nt ∑\nr=1\nn−φ ∑\nj=1\n(Φij(t, r + 1)− πj(r + 1)) r ∑\nk=1\nLjk(θ, θ∗) → 0.\n14\nFor the second term of the right hand side of (23), we will show that\n1 t2\nt ∑\nr=1\nn−φ ∑\nj=1\nπj(r + 1)\n(\nr ∑\nk=1\nLjk(θ, θ∗)− rHj(θ, θ∗) ) a.s.−−→ 0,\ni.e., almost surely for any ǫ > 0 there exists sufficiently large t(ǫ) such that ∀ t ≥ t(ǫ),\n1 t2\n∣ ∣ ∣ ∣ ∣ ∣ t ∑\nr=1\nn−φ ∑\nj=1\nπj(r + 1)\n(\nr ∑\nk=1\nLjk(θ, θ∗)− rHj(θ, θ∗) )\n∣ ∣ ∣ ∣ ∣ ∣ ≤ ǫ. (26)\nWe prove this by dividing r into two ranges r ∈ {1, · · · , √ t} and r ∈ { √ t+ 1, · · · , t}, i.e.,\n1 t2\nt ∑\nr=1\nn−φ ∑\nj=1\nπj(r + 1)\n(\nr ∑\nk=1\nLjk(θ, θ∗)− rHj(θ, θ∗) )\n= 1\nt2\n√ t\n∑\nr=1\nn−φ ∑\nj=1\nπj(r + 1)\n(\nr ∑\nk=1\nLjk(θ, θ∗)− rHj(θ, θ∗) )\n+ 1\nt2\nt ∑\nr= √ t+1\nn−φ ∑\nj=1\nπj(r + 1)\n(\nr ∑\nk=1\nLjk(θ, θ∗)− rHj(θ, θ∗) ) . (27)\nFor the first term of the right hand side of (27), we have\n1 t2\n∣ ∣ ∣ ∣ ∣ ∣\n√ t\n∑\nr=1\nn−φ ∑\nj=1\nπj(r + 1)\n(\nr ∑\nk=1\nLjk(θ, θ∗)− rHj(θ, θ∗) )\n∣ ∣ ∣ ∣ ∣ ∣\n≤ 1 t2\n√ t\n∑\nr=1\nn−φ ∑\nj=1\nπj(r + 1) (2rC0) by (13) and (22)\n= 1\nt2 (2C0)\n√ t\n∑\nr=1\nr\n≤ C0 ( 1\nt +\n1\nt 3 2\n)\n.\nThus, there exists t1(ǫ) such that for all t ≥ t1(ǫ), it holds that\n1 t2\n∣ ∣ ∣ ∣ ∣ ∣\n√ t\n∑\nr=1\nn−φ ∑\nj=1\nπj(r + 1)\n(\nr ∑\nk=1\nLjk(θ, θ∗)− rHj(θ, θ∗) )\n∣ ∣ ∣ ∣ ∣ ∣ ≤ ǫ 2 .\nFor the second term of the right hand side of (27), we have\n1 t2\nt ∑\nr= √ t+1\nn−φ ∑\nj=1\nπj(r + 1)\n(\nr ∑\nk=1\nLjk(θ, θ∗)− rHj(θ, θ∗) )\n= 1\nt\nt ∑\nr= √ t+1\nn−φ ∑\nj=1\nπj(r + 1) r\nt\n(\n1\nr\nr ∑\nk=1\nLjk(θ, θ∗)−Hj(θ, θ∗) )\n15\nSince Ljk(θ, θ∗)’s are i.i.d., from Strong LLN, we know that 1r ∑r k=1L j k(θ, θ ∗)−Hj(θ, θ∗) a.s.−−→ 0. That is, with probability 1, the sample path converges. Now, focus on each convergent sample path. For sufficiently large r(ǫ), it holds that for any r ≥ r(ǫ),\n∣ ∣ ∣ ∣ ∣ 1 r r ∑\nk=1\nLjk(θ, θ∗)−Hj(θ, θ∗) ∣ ∣ ∣ ∣\n∣ ≤ ǫ 2 .\nRecall that r ≥ √ t. Thus, we know that there exists sufficiently large t2(ǫ) such that ∀ t ≥ t2(ǫ),\nr ≥ √ t is large enough and\n∣ ∣ ∣ ∣ ∣ 1 r r ∑\nk=1\nLjk(θ, θ∗)−Hj(θ, θ∗) ∣ ∣ ∣ ∣\n∣ ≤ ǫ 2 .\nThen, we have ∀ t ≥ t2(ǫ),\n1 t2\n∣ ∣ ∣ ∣ ∣ ∣ t ∑\nr= √ t+1\nn−φ ∑\nj=1\nπj(r + 1)\n(\nr ∑\nk=1\nLjk(θ, θ∗)− rHj(θ, θ∗) )\n∣ ∣ ∣ ∣ ∣ ∣\n= 1\nt\nt ∑\nr= √ t+1\nn−φ ∑\nj=1\nπj(r + 1) r\nt\n∣ ∣ ∣ ∣ ∣ 1 r r ∑\nk=1\nLjk(θ, θ∗)−Hj(θ, θ∗) ∣ ∣ ∣ ∣\n∣\n≤ 1 t\nt ∑\nr= √ t+1\nn−φ ∑\nj=1\nπj(r + 1) r\nt\nǫ\n2\n= 1\nt\nt ∑\nr= √ t+1\nr\nt\nǫ 2 = ǫ 2 1 t2\nt ∑\nr= √ t+1\nr\n= ǫ\n4\n1 t2 (\nt2 − √ t )\n≤ ǫ 2 .\nTherefore, for any ǫ > 0, there exists max{t1(ǫ), t2(ǫ)}, such that for any t ≥ max{t1(ǫ), t2(ǫ)},\n1 t2\n∣ ∣ ∣ ∣ ∣ ∣ t ∑\nr=1\nn−φ ∑\nj=1\nπj(r + 1)\n(\nr ∑\nk=1\nLjk(θ, θ∗)− rHj(θ, θ∗) )\n∣ ∣ ∣ ∣ ∣ ∣ ≤ ǫ,\nfor every convergent sample path. In addition, we know a sample path is convergent with probability 1. Thus (26) holds almost surely.\nTherefore, Lemma 3 is proved."
    }, {
      "heading" : "5 BFL in the absence of Byzantine Agents, i.e., f = 0",
      "text" : "In this section, we present BFL for the special case in the absence of Byzantine agents, i.e., f = 0, named Failure-free BFL. Since f = 0, all the agents in the network are cooperative, and no trimming is needed. Indeed, the BFL for f = 0 is a simple modification of the algorithm proposed in [14].\nFor each time t ≥ 1, we define a matrix that follows the structure of G(V, E) as follows:\nAij ,\n{\n1 |Ii|+1 , j ∈ Ii ∪ {i} 0, otherwise.\n(28)\n16\nAlgorithm 5: Failure-free BFL\n1 Transmit current belief vector µit−1 on all outgoing edges; 2 Wait until a private signal sit is observed and belief vectors are received from all incoming neighbors Ii; 3 for θ ∈ Θ do\n4 µit(θ) ← ℓi(si1,t|θ)\n∏ j∈Ii∪{i} µ j t−1(θ) 1 |Ii|+1\n∑m p=1 ℓi(s i 1,t|θ) ∏ j∈Ii∪{i} µ j t−1(θ) 1 |Ii|+1\n.\n5 end\nThus, the dynamic of ψit(θ, θ ∗) (defined in (9)) under Algorithm 5 can be written as\nψit(θ, θ ∗) = log\nµit(θ)\nµit(θ ∗)\n= log ℓi(s\ni 1,t|θ)\n∏ j∈Ii∪{i} µ j t−1(θ)\n1 |Ii|+1\nℓi(si1,t|θ∗) ∏ j∈Ii∪{i} µ j t−1(θ\n∗) 1 |Ii|+1\n= log ∏\nj∈Ii∪{i}\n[\nµ j t−1(θ)\nµ j t−1(θ ∗)\n] 1 |Ii|+1\n+ log ℓi(s\ni 1,t | θ)\nℓi(si1,t | θ∗)\n= log ∏\nj∈Ii∪{i}\n[\nµ j t−1(θ)\nµ j t−1(θ ∗)\n] 1 |Ii|+1\n+\nt ∑\nr=1\nlog ℓi(s\ni r | θ)\nℓi(sir | θ∗)\n= n ∑\nj=1\nAijψ i t−1(θ, θ\n∗) + t ∑\nr=1\nLir(θ, θ∗) by (9) and (28)\nRecall that ψt(θ, θ ∗) ∈ Rn−φ is the vector that stacks ψit−1(θ, θ∗) with the i–th entry being\nψit−1(θ, θ ∗) for all i ∈ N . Since f = 0, i.e., the network is free of failures, it holds that\n0 ≤ φ = |F| ≤ f = 0. Thus, ψt(θ, θ ∗) ∈ Rn. Similar to (12), the evolution of ψt(θ, θ∗) can be compactly written as follows.\nψt(θ, θ ∗) = Atψ0(θ, θ ∗) + t ∑\nr=1\nAt−r r ∑\nk=1\nLk(θ, θ∗)\n=\nt ∑\nr=1\nAt−r r ∑\nk=1\nLk(θ, θ∗). (29)\nThe last equality holds from the fact that ψ0(θ, θ ∗) = 0.\nAs mentioned before, the non-Bayesian learning rules [14,15,11,17] are consensus-based learning algorithms, wherein agents are required to reach a common decision asymptotically.\nAssumption 3 The underlying communication network G(V, E) is strongly connected. It is easy to see that G(V, E) itself is the only reduced graph of G(V, E), and that Assumption 3 is the special case of Assumption 1 when f = 0. Thus,\nχm = 1, and νm = χm(n− φ) = n.\n17\nNote that both χm and νm are independent of m when f = 0. Henceforth in this section, we drop the subscripts of χm and νm for ease of notation.\nSimilar to (3), for any r ≥ 1, we get\nlim t≥r, t→∞\nAt−r = 1π.\nSince A is time-invariant, the product limit limt≥r, t→∞At−r is also independent of r.\nIt is easy to see that\nA ≥ 1 n H,\nwhere H is the adjacency matrix of the communication graph G(V, E), and that\nπj ≥ 1\nnn , ∀ j = 1, · · · , n. (30)\nThe following corollary is a direct consequence of Theorem 3, and its proof is omitted.\nCorollary 1. For all t ≥ r ≥ 1, it holds that ∣ ∣[At−r]ij − πj ∣ ∣ ≤ (1− 1 nn )⌈ t−r n ⌉, where [At−r]ij is the i, j–th entry of matrix At−r.\nIn addition, when f = 0, Assumption 2 becomes\nAssumption 4 Suppose that Assumption 3 holds. For any θ 6= θ∗, the following holds\nm ∑\nj=1\nD (ℓj(·|θ∗) ‖ ℓj(·|θ)) 6= 0. (31)\nAs an immediate consequence of Theorem 5, we have the following corollary.\nCorollary 2. When Assumption 4 holds, each agent i will concentrate its belief on the true hypothesis θ∗ almost surely, i.e., µit(θ) a.s.−−→ 0 for all θ 6= θ∗.\nSince Corollary 2 is the special case of Theorem 5 for f = 0, the proof of Corollary 2 is omitted."
    }, {
      "heading" : "5.1 Finite-Time Analysis of Failure-Free BFL",
      "text" : "In this subsection, we present the convergence rate that is achievable in finite time with high probability. Our proof is similar to the proof presented in [14,17].\nLemma 4. Let λ , ( 1− ( 1 n )n ) 1 n , and let θ 6= θ∗, and consider ψit(θ, θ∗) as defined in (9). Then, for each agent i we have\nE [ ψit(θ, θ ∗) ] ≤ nC0 (1− 1 nn )(1− λ)t− C1 2nn t2.\n18\nProof. By (29), we have ψit(θ, θ ∗) = ∑t r=1 ∑n j=1[A t−r]ij ∑r k=1L j k(θ, θ ∗). Taking expectation of ψit(θ, θ ∗) with respect to ℓi(· | θ∗), we get\nE ∗ [ψit(θ, θ ∗) ] = E∗\n\n\nt ∑\nr=1\nn ∑\nj=1\n[At−r]ij\nr ∑\nk=1\nLjk(θ, θ∗)\n\n\n= t ∑\nr=1\nn ∑\nj=1\n[At−r]ij\nr ∑\nk=1\nE ∗ [ Ljk(θ, θ∗) ]\n= t ∑\nr=1\nn ∑\nj=1\n[At−r]ijrHj(θ, θ ∗) by (13)\n= t ∑\nr=1\nn ∑\nj=1\n( [At−r]ij − πj ) rHj(θ, θ ∗) +\nt ∑\nr=1\nn ∑\nj=1\nπjrHj(θ, θ ∗). (32)\nFor the first term in the right hand side of (32), we have\nt ∑\nr=1\nn ∑\nj=1\n( [At−r]ij − πj ) rHj(θ, θ ∗) ≤\nt ∑\nr=1\nn ∑\nj=1\n∣ ∣[At−r]ij − πj ∣ ∣ r |Hj(θ, θ∗)|\n≤ t ∑\nr=1\nn ∑\nj=1\n[\n1− 1 nn\n]⌈ t−r n ⌉ rC0 by Corollary 1, and (14)\n= nC0\nt ∑\nr=1\n[\n1− 1 nn\n]⌈ t−r n ⌉ r\n≤ nC0 (1− 1\nnn )(1− λ)t. (33)\nSince G(V, E) is the only source component, C1 (defined in (15)) becomes\nC1 = min θ,θ∗∈Θ;θ 6=θ∗\nn ∑\ni=1\nD(ℓi(·|θ∗) ‖ ℓi(·|θ)).\nThus, for the second term in the right hand side of (32), we get\nt ∑\nr=1\nn ∑\nj=1\nπjrHj(θ, θ ∗) ≤\nt ∑\nr=1\nn ∑\nj=1\n1\nnn rHj(θ, θ\n∗) by (30) and (13)\n= 1\nnn\nt ∑\nr=1\nr\nn ∑\nj=1\nHj(θ, θ ∗)\n≤ − 1 nn\nt ∑\nr=1\nrC1\n≤ − C1 2nn t2. (34)\n19\nBy (33) and (34), (32) becomes\nE ∗ [ψit(θ, θ ∗) ]\n= t ∑\nr=1\nn ∑\nj=1\n( [At−r]ij − πj ) rHj(θ, θ ∗) +\nt ∑\nr=1\nn ∑\nj=1\nπjrHj(θ, θ ∗)\n≤ nC0 (1− 1 nn )(1− λ)t− C1 2nn t2, (35)\nproving the lemma.\nSimilar to [14,17], we also use McDiarmid’s Inequality.\nTheorem 6 (McDiarmid’s Inequality). Let X1, · · · ,Xt be independent random variables and consider the mapping H : X t → R. If for r = 1, · · · , t, and every sample x1, · · · , xt, x′r ∈ X , the function H satisfies\n∣ ∣H(x1, · · · , xr, · · · , xt)−H(x1, · · · , x′r, · · · , xt) ∣ ∣ ≤ cr,\nthen for all ǫ > 0,\nP [|H(x1, · · · , xt)− E[H(x1, · · · , xt)]| ≥ ǫ] ≤ exp { −2ǫ2 ∑t\nr=1 c 2 r\n}\n.\nTheorem 7. Under Assumption 4, for any ρ ∈ (0, 1), there exists an integer T (ρ) such that with probability 1− ρ, for all t ≥ T (ρ) and for all θ 6= θ∗, we have\nµit(θ) ≤ exp (\nnC0\n(1− 1 nn\n)(1− λ) t− C1 4nn t2\n)\nwhere C0 and C1 are defined in (14) and (15) respectively, and T (ρ) = 64C20n 2n\n3C21 log 1 ρ .\nProof. Since µit(θ ∗) ∈ (0, 1], we have\nµit(θ) ≤ µit(θ)\nµit(θ ∗)\n= exp ( ψit(θ, θ ∗) ) .\nThus, we have\nP\n( µit(θ) ≥ exp (\nnC0\n(1− 1 nn\n)(1− λ) t− C1 4nn t2\n)) ≤ P ( ψit(θ, θ ∗) ≥ nC0\n(1− 1 nn\n)(1− λ)t− C1 4nn t2\n)\n≤ P (\nψit(θ, θ ∗)− E∗ [ ψit(θ, θ ∗) ] ≥ C1 4nn\nt2 ) .\n20\nNote that ψit(θ, θ ∗) is a function of the random vector s1, · · · , st. For a given sample path\ns1, · · · , st, and for all p ∈ {1, · · · , t}, we have\nmax sp∈S1×···×St\nψit(θ, θ ∗)− min sp∈S1×···×St ψit(θ, θ ∗)\n= max sp∈S1×···×St\nt ∑\nr=1\nn ∑\nj=1\n[At−r]ij\nr ∑\nk=1\nLk(θ, θ∗)− min sp∈S1×···×St\nt ∑\nr=1\nn ∑\nj=1\n[At−r]ij\nr ∑\nk=1\nLk(θ, θ∗)\n= max sp∈S1×···×St\nt ∑\nr=p\nn ∑\nj=1\n[At−r]ij\nr ∑\nk=1\nLk(θ, θ∗)− min sp∈S\nt ∑\nr=p\nn ∑\nj=1\n[At−r]ij\nr ∑\nk=1\nLk(θ, θ∗)\n= max sp∈S1×···×St\nt ∑\nr=p\nn ∑\nj=1\n[At−r]ijLp(θ, θ∗)− min sp∈S\nt ∑\nr=p\nn ∑\nj=1\n[At−r]ijLp(θ, θ∗)\n≤ t ∑\nr=p\nn ∑\nj=1\n[At−r]ijC0 + t ∑\nr=p\nn ∑\nj=1\n[At−r]ijC0\n= 2C0(t− p+ 1) , cp.\nBy McDiarmid’s inequality (Theorem 6), we obtain that\nP\n(\nψ∗t (θ, θ ∗)− E∗ [ψ∗t (θ, θ∗)] ≥\nC1 4nn t2 ) ≤ exp ( − 2 C21 16n2n t4\n∑t p=1(2C0(t− p+ 1))2\n)\n≤ exp ( − 3C 2 1\n64C20n 2n\nt\n)\n,\nwhere the last inequality follows from the fact that\nt(t+ 1)(2t+ 1) ≤ 4t3 ∀ t ≥ 2,\nwhich can be shown by induction. Therefore, for a given confidence level ρ, in order to have\nP\n( µit(θ) ≥ exp (\nnC0\n(1− 1 nn\n)(1− λ)t− C1 4nn t2\n))\n≤ ρ,\nwe require that\nt ≥ T (ρ) = 64C 2 0n 2n\n3C21 log\n1 ρ .\nRemark 3. The above finite-time analysis is not directly applicable for the general case when f > 0, due to the fact that the local beliefs are dependent on all the observations collected so far as well as all the future observations.\nRemark 4. Our analysis for the special when f = 0 also works for time-varying networks [14]. In addition, with identical analysis, we are able to adapt the failure-free scheme to work in the more general setting where there is no underlying true state, and the goal is to have the agents collaboratively identify an optimal θ ∈ Θ that best explains all the observations obtained over the whole network.\n21"
    }, {
      "heading" : "6 Modified BFL and Minimal Network Identifiability",
      "text" : "To reduce the computation complexity per iteration in general, and to identify the minimal (tight) global identifiability of the network for any consensus-based learning rule of interest to learn the true state, we propose a modification of the above learning rule, which works under much weaker network topology and global identifiability condition.\nWe decompose the m-ary hypothesis testing problem into m(m−1) (ordered) binary hypothesis testing problems. For each pair of hypotheses θ1 and θ2, each non-faulty agent updates the likelihood ratio of θ1 over θ2 as follows. Let r i t(θ1, θ2) be the log likelihood ratio of θ1 over θ2 kept by agent i at the end of iteration t. Our modified learning rule applies consensus procedures to log likelihood ratio, i.e., rit(θ1, θ2), which is a scalar. For Algorithm 6, we only require scalar iterative Byzantine (approximate) consensus among the non-faulty agents to be achievable.\nWhen scalar consensus is achievable, the following assumption on the identifiability of the network to detect θ∗ is minimal, meaning that if this assumption is not satisfied, then no correct consensus-based non-Bayesian learning exists.\nAssumption 5 Suppose that every 1-dimensional reduced graph of G(V, E) contains only one source component. For any θ 6= θ∗, and for any 1-dimensional reduced graph H1 of G(V, E) with SH1 denoting the unique source component, the following holds\n∑\nj∈SH1\nD (ℓj(·|θ∗) ‖ ℓj(·|θ)) 6= 0. (36)\nAssumption 5 is minimal for the following reasons: (1) For any consensus-based learning rule to work, the communication network G(V, E) should support consensus with scalar inputs. That is, every 1-dimensional reduced graph of G(V, E) must contain only one source component. (2) Under some faulty behaviors of the Byzantine agents, one particular 1–dimensional reduced graph may govern the entire dynamics of ri(θ1, θ2). If (36) does not hold for that reduced graph, then the good agents may not able to distinguish θ1 from θ2.\nAlgorithm 6: Pairwise Learning\n1 Initialization: for θ1, θ2 ∈ Θ, and θ1 6= θ2 do 2 ri0(θ1, θ2) ← 0; 3 end 4 while t ≥ 1 do 5 for θ1, θ2 ∈ Θ, and θ1 6= θ2 do 6 Transmit current belief vector rit−1(θ1, θ2) on all outgoing edges; 7 Wait until a private signal sit is observed and log likelihood ratios r̃ j t−1(θ1, θ2) are received from all incoming neighbors Ii; 8 Sort the received log likelihood ratios r̃jt−1(θ1, θ2) in a non-decreasing order, and\nremove the smallest f values and the largest f values. % Denote the set of indices of incoming neighbors whose ratios have not been removed at iteration t by I∗i [t].%\n9 rit(θ1, θ2) ← ∑ j∈I∗ i [t] r̃ j t−1(θ1,θ2)+r i t−1(θ1,θ2)\n|I∗[t]|+1 + log ℓi(si1,t|θ1) ℓi(si1,t|θ2) .\n10 end\n11 end\n22\nFor each iteration, the computation complexity per agent (non-faulty) can be calculated as follows. The cost-dominant procedure in each iteration is sorting the received log likelihood ratios, which takes O(n log n) operations. In total, we have m(m− 1) order pairs of hypotheses. Thus, the total computation per agent per iteration is O(m2n log n).\nTheorem 8. Suppose Assumption 5 holds. Under Algorithm 6, for any θ 6= θ∗, the following holds:\nrit(θ ∗, θ) a.s.−−→ +∞, and rit(θ, θ∗) a.s.−−→ −∞.\nProof. By [20], we know that for each pair of hypotheses θ1 and θ2, there exists a row-stochastic matrix M1,2[t] ∈ R(n−φ)×(n−φ) such that\nrit(θ1, θ2) =\nn−φ ∑\nj=1\nM1,2ij [t]r j t−1(θ1, θ2) + log\nℓi(s i 1,t | θ1) ℓi(si1,t | θ2) . (37)\nNote that matrix M1,2 depends on the choice of hypotheses θ1 and θ2. For a given pair of hypotheses θ1 and θ2, let rt(θ1, θ2) ∈ Rn−φ be the vector that stacks rit(θ1, θ2). The evolution of r(θ1, θ2) can be compactly written as\nrt(θ1, θ2) = M 1,2[t]rt−1(θ1, θ2) +\nt ∑\nr=1\nLr(θ1, θ2)\n= t ∑\nr=1\nΦ1,2(t, r + 1) r ∑\nk=1\nLk(θ1, θ2), (38)\nwhere Φ1,2(t, r+1) , M1,2[t]M1,2[t− 1] · · ·M1,2[r+1] for r ≤ t, Φ1,2(t, t) , M1,2[t] and Φ1,2(t, t+ 1) , I. We do the analysis for each pair of θ1 and θ2 separately.\nThe remaining proof is identical to the proof of Theorem 5, and is omitted.\nProposition 1. Suppose there exists θ̃ ∈ Θ such that for any θ 6= θ̃, it holds that rit(θ̃, θ) a.s.−−→ +∞, and rit(θ, θ̃) a.s.−−→ −∞. Then θ̃ = θ∗.\nProof. We prove this proposition by contradiction. Suppose there exists θ̃ 6= θ∗ ∈ Θ such that for any θ 6= θ̃, it holds that rit(θ̃, θ) a.s.−−→ +∞, and rit(θ, θ̃) a.s.−−→ −∞. Then we know that rit(θ̃, θ∗)\na.s.−−→ +∞ and rit(θ∗, θ̃) a.s.−−→ −∞, contradicting Theorem 8. Thus, Proposition 1 is true."
    }, {
      "heading" : "7 Conclusion",
      "text" : "This paper addresses the problem of consensus-based non-Bayesian learning over multi-agent networks when an unknown subset of agents may be adversarial (Byzantine). We propose two learning rules, and characterize the tight network identifiability condition for any consensus-based learning rule of interest to exist. In our first update rule, each agent updates its local beliefs as (up to normalization) the product of (1) the likelihood of the cumulative private signals and (2) the weighted geometric average of the beliefs of its incoming neighbors and itself. Under reasonable assumptions on the underlying network structure and the global identifiability of the network, we show that all the non-faulty agents asymptotically agree on the true state almost surely. For the case when every agent is failure-free, we show that (with high probability) each agent’s beliefs on the wrong\n23\nhypotheses decrease at rate O(exp(−Ct2)), where t is the number of iterations, and C is a constant. In general when agents may be adversarial, network identifiability condition specified for the above learning rule scales poorly in m. In addition, the computation complexity per agent per iteration of this learning rule is forbiddingly high. Thus, we propose a modification of our first learning rule, whose complexity per iteration per agent is O(m2n log n). We show that this modified learning rule works under a much weaker global identifiability condition that is independent of m.\nWe so far focussed on synchronous system and static network, our results may be generalizable to asynchronous as well as time varying network.\nThroughout this paper, we assume that consensus among non-faulty agents needs to be achieved. Although this is necessary for the family of consensus-based algorithms (by definition), this is not the case for the non-faulty agents to collaboratively learn the true state in general. Indeed, there is a tradeoff between the capability of the network to reach consensus and the tight condition of the network detectability. For instance, if the network is disconnected, then information cannot be propagated across the connected components. Thus, the non-faulty agents in each connected component have to be able to learn the true state. We leave investigating the above tradeoff as future work."
    } ],
    "references" : [ {
      "title" : "Decentralized detection in sensor networks",
      "author" : [ "J.-F. Chamberland", "V.V. Veeravalli" ],
      "venue" : "IEEE Transactions on Signal Processing,",
      "citeRegEx" : "1",
      "shortCiteRegEx" : "1",
      "year" : 2003
    }, {
      "title" : "Bayesian learning in social networks",
      "author" : [ "D. Gale", "S. Kariv" ],
      "venue" : "Games and Economic Behavior,",
      "citeRegEx" : "2",
      "shortCiteRegEx" : "2",
      "year" : 2003
    }, {
      "title" : "Non-bayesian social learning",
      "author" : [ "A. Jadbabaie", "P. Molavi", "A. Sandroni", "A. Tahbaz-Salehi" ],
      "venue" : "Games and Economic Behavior,",
      "citeRegEx" : "3",
      "shortCiteRegEx" : "3",
      "year" : 2012
    }, {
      "title" : "Reaching approximate byzantine consensus with multi-hop communication",
      "author" : [ "L. Su", "N.H. Vaidya" ],
      "venue" : "In Proceedings of International Symposium on Stabilization, Safety, and Security of Distributed Systems (SSS),",
      "citeRegEx" : "4",
      "shortCiteRegEx" : "4",
      "year" : 2015
    }, {
      "title" : "Decentralized detection by a large number of sensors",
      "author" : [ "J. Tsitsiklis" ],
      "venue" : "Mathematics of Control, Signals and Systems,",
      "citeRegEx" : "5",
      "shortCiteRegEx" : "5",
      "year" : 1988
    }, {
      "title" : "Decentralized detection",
      "author" : [ "J.N. Tsitsiklis" ],
      "venue" : "Advances in Statistical Signal Processing,",
      "citeRegEx" : "6",
      "shortCiteRegEx" : "6",
      "year" : 1993
    }, {
      "title" : "Distributed Detection and Data Fusion",
      "author" : [ "P.K. Varshney" ],
      "venue" : "Springer Science & Business Media,",
      "citeRegEx" : "7",
      "shortCiteRegEx" : "7",
      "year" : 2012
    }, {
      "title" : "Stochastic Processes in Engineering Systems",
      "author" : [ "E. Wong", "B. Hajek" ],
      "venue" : "Springer Science & Business Media,",
      "citeRegEx" : "8",
      "shortCiteRegEx" : "8",
      "year" : 2012
    }, {
      "title" : "Weak ergodicity in non-homogeneous markov chains",
      "author" : [ "J. Hajnal", "M. Bartlett" ],
      "venue" : "In Mathematical Proceedings of the Cambridge Philosophical Society,",
      "citeRegEx" : "9",
      "shortCiteRegEx" : "9",
      "year" : 1958
    }, {
      "title" : "Information heterogeneity and the speed of learning in social networks",
      "author" : [ "A. Jadbabaie", "P. Molavi", "A. Tahbaz-Salehi" ],
      "venue" : "Columbia Business School Research Paper,",
      "citeRegEx" : "10",
      "shortCiteRegEx" : "10",
      "year" : 2013
    }, {
      "title" : "Social learning and distributed hypothesis testing",
      "author" : [ "A. Lalitha", "A. Sarwate", "T. Javidi" ],
      "venue" : "In Information Theory (ISIT),",
      "citeRegEx" : "11",
      "shortCiteRegEx" : "11",
      "year" : 2014
    }, {
      "title" : "Distributed Algorithms",
      "author" : [ "N.A. Lynch" ],
      "venue" : null,
      "citeRegEx" : "12",
      "shortCiteRegEx" : "12",
      "year" : 1996
    }, {
      "title" : "Foundations of non-bayesian social learning",
      "author" : [ "P. Molavi", "A. Jadbabaie" ],
      "venue" : "Columbia Business School Research Paper,",
      "citeRegEx" : "13",
      "shortCiteRegEx" : "13",
      "year" : 2015
    }, {
      "title" : "Nonasymptotic convergence rates for cooperative learning over timevarying directed graphs",
      "author" : [ "A. Nedić", "A. Olshevsky", "C.A. Uribe" ],
      "venue" : "arXiv preprint arXiv:1410.1977,",
      "citeRegEx" : "14",
      "shortCiteRegEx" : "14",
      "year" : 2014
    }, {
      "title" : "Distributed parameter estimation in networks",
      "author" : [ "K.R. Rad", "A. Tahbaz-Salehi" ],
      "venue" : "In IEEE Conference on Decision and Control (CDC),",
      "citeRegEx" : "15",
      "shortCiteRegEx" : "15",
      "year" : 2010
    }, {
      "title" : "Exponentially fast parameter estimation in networks using distributed dual averaging",
      "author" : [ "S. Shahrampour", "A. Jadbabaie" ],
      "venue" : "In IEEE Conference on Decision and Control (CDC),",
      "citeRegEx" : "16",
      "shortCiteRegEx" : "16",
      "year" : 2013
    }, {
      "title" : "Distributed detection: Finite-time analysis and impact of network topology",
      "author" : [ "S. Shahrampour", "A. Rakhlin", "A. Jadbabaie" ],
      "venue" : "arXiv preprint arXiv:1409.8606,",
      "citeRegEx" : "17",
      "shortCiteRegEx" : "17",
      "year" : 2014
    }, {
      "title" : "Finite-time analysis of the distributed detection problem",
      "author" : [ "S. Shahrampour", "A. Rakhlin", "A. Jadbabaie" ],
      "venue" : "arXiv preprint arXiv:1512.09311,",
      "citeRegEx" : "18",
      "shortCiteRegEx" : "18",
      "year" : 2015
    }, {
      "title" : "Products of indecomposable, aperiodic, stochastic matrices",
      "author" : [ "J. Wolfowitz" ],
      "venue" : "In Proceedings of the American Mathematical Society,",
      "citeRegEx" : "19",
      "shortCiteRegEx" : "19",
      "year" : 1963
    }, {
      "title" : "Matrix Representation of Iterative Approximate Byzantine Consensus in Directed Graphs",
      "author" : [ "N.H. Vaidya" ],
      "venue" : "arXiv 1203.1888,",
      "citeRegEx" : "20",
      "shortCiteRegEx" : "20",
      "year" : 2012
    }, {
      "title" : "Large deviations performance of consensus+ innovations distributed detection with non-gaussian observations",
      "author" : [ "D. Bajović", "D. Jakovetić", "J.M. Moura", "J. Xavier", "B. Sinopoli" ],
      "venue" : "Signal Processing, IEEE Transactions on,",
      "citeRegEx" : "21",
      "shortCiteRegEx" : "21",
      "year" : 2012
    }, {
      "title" : "Distributed detection over adaptive networks using diffusion adaptation",
      "author" : [ "F.S. Cattivelli", "A.H. Sayed" ],
      "venue" : "Signal Processing, IEEE Transactions on,",
      "citeRegEx" : "22",
      "shortCiteRegEx" : "22",
      "year" : 1917
    }, {
      "title" : "Distributed detection over noisy networks: Large deviations analysis",
      "author" : [ "D. Jakovetić", "J.M. Moura", "J. Xavier" ],
      "venue" : "Signal Processing, IEEE Transactions on,",
      "citeRegEx" : "23",
      "shortCiteRegEx" : "23",
      "year" : 2012
    }, {
      "title" : "Reaching agreement in the presence of faults",
      "author" : [ ],
      "venue" : "J. ACM",
      "citeRegEx" : "24",
      "shortCiteRegEx" : "24",
      "year" : 1980
    }, {
      "title" : "Reaching approximate agreement in the presence of faults",
      "author" : [ "D. Dolev", "N.A. Lynch", "S.S. Pinter", "E.W. Stark", "W.E. Weihl" ],
      "venue" : "J. ACM,",
      "citeRegEx" : "25",
      "shortCiteRegEx" : "25",
      "year" : 1986
    }, {
      "title" : "Asymptotically optimal algorithms for approximate agreement",
      "author" : [ "A.D. Fekete" ],
      "venue" : "Distributed Computing,",
      "citeRegEx" : "26",
      "shortCiteRegEx" : "26",
      "year" : 1990
    }, {
      "title" : "Consensus of multi-agent networks in the presence of adversaries using only local information",
      "author" : [ "H.J. LeBlanc", "H. Zhang", "S. Sundaram", "X. Koutsoukos" ],
      "venue" : "In Proceedings of the 1st International Conference on High Confidence Networked Systems, HiCoNS",
      "citeRegEx" : "27",
      "shortCiteRegEx" : "27",
      "year" : 2012
    }, {
      "title" : "Iterative byzantine vector consensus in incomplete graphs",
      "author" : [ "N.H. Vaidya" ],
      "venue" : "In Distributed Computing and Networking,",
      "citeRegEx" : "28",
      "shortCiteRegEx" : "28",
      "year" : 2014
    }, {
      "title" : "Byzantine vector consensus in complete graphs",
      "author" : [ "N.H. Vaidya", "V.K. Garg" ],
      "venue" : "In Proceedings of the 2013 ACM symposium on Principles of distributed computing,",
      "citeRegEx" : "29",
      "shortCiteRegEx" : "29",
      "year" : 2013
    }, {
      "title" : "Iterative approximate byzantine consensus in arbitrary directed graphs",
      "author" : [ "N.H. Vaidya", "L. Tseng", "G. Liang" ],
      "venue" : "In Proceedings of the 2012 ACM symposium on Principles of distributed computing,",
      "citeRegEx" : "30",
      "shortCiteRegEx" : "30",
      "year" : 2012
    }, {
      "title" : "Multidimensional approximate agreement in byzantine asynchronous systems",
      "author" : [ "H. Mendes", "M. Herlihy" ],
      "venue" : "In Proceedings of the Forty-fifth Annual ACM Symposium on Theory of Computing,",
      "citeRegEx" : "31",
      "shortCiteRegEx" : "31",
      "year" : 2013
    }, {
      "title" : "Sigron. A generalization of Tverberg’s",
      "author" : [ "M.M.A. Perles" ],
      "venue" : "theorem. arXiv",
      "citeRegEx" : "32",
      "shortCiteRegEx" : "32",
      "year" : 2007
    }, {
      "title" : "Network Independent Rates in Distributed Learning",
      "author" : [ "A. Nedić", "A. Olshevsky", "C.A. Uribe" ],
      "venue" : "arXiv preprint arXiv:1509.08574,",
      "citeRegEx" : "33",
      "shortCiteRegEx" : "33",
      "year" : 2015
    }, {
      "title" : "Asynchronous Distributed Hypothesis Testing in the Presence of Crash Failures University of Illinois at Urbana-Champaign",
      "author" : [ "L. Su", "N.H. Vaidya" ],
      "venue" : "Tech. Rep,",
      "citeRegEx" : "34",
      "shortCiteRegEx" : "34",
      "year" : 2016
    } ],
    "referenceMentions" : [ {
      "referenceID" : 0,
      "context" : "2 1 Introduction Decentralized hypothesis testing (learning) has received significant amount of attention [1,2,3,5,6,7,8].",
      "startOffset" : 106,
      "endOffset" : 121
    }, {
      "referenceID" : 1,
      "context" : "2 1 Introduction Decentralized hypothesis testing (learning) has received significant amount of attention [1,2,3,5,6,7,8].",
      "startOffset" : 106,
      "endOffset" : 121
    }, {
      "referenceID" : 2,
      "context" : "2 1 Introduction Decentralized hypothesis testing (learning) has received significant amount of attention [1,2,3,5,6,7,8].",
      "startOffset" : 106,
      "endOffset" : 121
    }, {
      "referenceID" : 4,
      "context" : "2 1 Introduction Decentralized hypothesis testing (learning) has received significant amount of attention [1,2,3,5,6,7,8].",
      "startOffset" : 106,
      "endOffset" : 121
    }, {
      "referenceID" : 5,
      "context" : "2 1 Introduction Decentralized hypothesis testing (learning) has received significant amount of attention [1,2,3,5,6,7,8].",
      "startOffset" : 106,
      "endOffset" : 121
    }, {
      "referenceID" : 6,
      "context" : "2 1 Introduction Decentralized hypothesis testing (learning) has received significant amount of attention [1,2,3,5,6,7,8].",
      "startOffset" : 106,
      "endOffset" : 121
    }, {
      "referenceID" : 7,
      "context" : "2 1 Introduction Decentralized hypothesis testing (learning) has received significant amount of attention [1,2,3,5,6,7,8].",
      "startOffset" : 106,
      "endOffset" : 121
    }, {
      "referenceID" : 4,
      "context" : "The traditional decentralized detection framework consists of a collection of spatially distributed sensors and a fusion center [5,6,7].",
      "startOffset" : 128,
      "endOffset" : 135
    }, {
      "referenceID" : 5,
      "context" : "The traditional decentralized detection framework consists of a collection of spatially distributed sensors and a fusion center [5,6,7].",
      "startOffset" : 128,
      "endOffset" : 135
    }, {
      "referenceID" : 6,
      "context" : "The traditional decentralized detection framework consists of a collection of spatially distributed sensors and a fusion center [5,6,7].",
      "startOffset" : 128,
      "endOffset" : 135
    }, {
      "referenceID" : 1,
      "context" : "Distributed hypothesis testing in the absence of fusion center is considered in [2,22,23,21].",
      "startOffset" : 80,
      "endOffset" : 92
    }, {
      "referenceID" : 21,
      "context" : "Distributed hypothesis testing in the absence of fusion center is considered in [2,22,23,21].",
      "startOffset" : 80,
      "endOffset" : 92
    }, {
      "referenceID" : 22,
      "context" : "Distributed hypothesis testing in the absence of fusion center is considered in [2,22,23,21].",
      "startOffset" : 80,
      "endOffset" : 92
    }, {
      "referenceID" : 20,
      "context" : "Distributed hypothesis testing in the absence of fusion center is considered in [2,22,23,21].",
      "startOffset" : 80,
      "endOffset" : 92
    }, {
      "referenceID" : 1,
      "context" : "In particular, Gale and Kariv [2] studied the distributed hypothesis testing problem in the context of social learning, where fully Bayesian belief update rule is studied.",
      "startOffset" : 30,
      "endOffset" : 33
    }, {
      "referenceID" : 2,
      "context" : "[3], and has attracted much attention [10,14,15,16,11,18,17,13].",
      "startOffset" : 0,
      "endOffset" : 3
    }, {
      "referenceID" : 9,
      "context" : "[3], and has attracted much attention [10,14,15,16,11,18,17,13].",
      "startOffset" : 38,
      "endOffset" : 63
    }, {
      "referenceID" : 13,
      "context" : "[3], and has attracted much attention [10,14,15,16,11,18,17,13].",
      "startOffset" : 38,
      "endOffset" : 63
    }, {
      "referenceID" : 14,
      "context" : "[3], and has attracted much attention [10,14,15,16,11,18,17,13].",
      "startOffset" : 38,
      "endOffset" : 63
    }, {
      "referenceID" : 15,
      "context" : "[3], and has attracted much attention [10,14,15,16,11,18,17,13].",
      "startOffset" : 38,
      "endOffset" : 63
    }, {
      "referenceID" : 10,
      "context" : "[3], and has attracted much attention [10,14,15,16,11,18,17,13].",
      "startOffset" : 38,
      "endOffset" : 63
    }, {
      "referenceID" : 17,
      "context" : "[3], and has attracted much attention [10,14,15,16,11,18,17,13].",
      "startOffset" : 38,
      "endOffset" : 63
    }, {
      "referenceID" : 16,
      "context" : "[3], and has attracted much attention [10,14,15,16,11,18,17,13].",
      "startOffset" : 38,
      "endOffset" : 63
    }, {
      "referenceID" : 12,
      "context" : "[3], and has attracted much attention [10,14,15,16,11,18,17,13].",
      "startOffset" : 38,
      "endOffset" : 63
    }, {
      "referenceID" : 2,
      "context" : "[3] considered the general setting where external signals are observed during each iteration of the algorithm execution.",
      "startOffset" : 0,
      "endOffset" : 3
    }, {
      "referenceID" : 2,
      "context" : "It is shown [3] that, under this learning rule, each agent learns the true state almost surely.",
      "startOffset" : 12,
      "endOffset" : 15
    }, {
      "referenceID" : 2,
      "context" : "The publication of [3] has inspired significant efforts in designing and analyzing non-Bayesian learning rules with a particular focus on refining the fusion strategies and analyzing the (asymptotic and/or finite time) convergence rates of the refined algorithms [10,14,15,16,11,18,17,13].",
      "startOffset" : 19,
      "endOffset" : 22
    }, {
      "referenceID" : 9,
      "context" : "The publication of [3] has inspired significant efforts in designing and analyzing non-Bayesian learning rules with a particular focus on refining the fusion strategies and analyzing the (asymptotic and/or finite time) convergence rates of the refined algorithms [10,14,15,16,11,18,17,13].",
      "startOffset" : 263,
      "endOffset" : 288
    }, {
      "referenceID" : 13,
      "context" : "The publication of [3] has inspired significant efforts in designing and analyzing non-Bayesian learning rules with a particular focus on refining the fusion strategies and analyzing the (asymptotic and/or finite time) convergence rates of the refined algorithms [10,14,15,16,11,18,17,13].",
      "startOffset" : 263,
      "endOffset" : 288
    }, {
      "referenceID" : 14,
      "context" : "The publication of [3] has inspired significant efforts in designing and analyzing non-Bayesian learning rules with a particular focus on refining the fusion strategies and analyzing the (asymptotic and/or finite time) convergence rates of the refined algorithms [10,14,15,16,11,18,17,13].",
      "startOffset" : 263,
      "endOffset" : 288
    }, {
      "referenceID" : 15,
      "context" : "The publication of [3] has inspired significant efforts in designing and analyzing non-Bayesian learning rules with a particular focus on refining the fusion strategies and analyzing the (asymptotic and/or finite time) convergence rates of the refined algorithms [10,14,15,16,11,18,17,13].",
      "startOffset" : 263,
      "endOffset" : 288
    }, {
      "referenceID" : 10,
      "context" : "The publication of [3] has inspired significant efforts in designing and analyzing non-Bayesian learning rules with a particular focus on refining the fusion strategies and analyzing the (asymptotic and/or finite time) convergence rates of the refined algorithms [10,14,15,16,11,18,17,13].",
      "startOffset" : 263,
      "endOffset" : 288
    }, {
      "referenceID" : 17,
      "context" : "The publication of [3] has inspired significant efforts in designing and analyzing non-Bayesian learning rules with a particular focus on refining the fusion strategies and analyzing the (asymptotic and/or finite time) convergence rates of the refined algorithms [10,14,15,16,11,18,17,13].",
      "startOffset" : 263,
      "endOffset" : 288
    }, {
      "referenceID" : 16,
      "context" : "The publication of [3] has inspired significant efforts in designing and analyzing non-Bayesian learning rules with a particular focus on refining the fusion strategies and analyzing the (asymptotic and/or finite time) convergence rates of the refined algorithms [10,14,15,16,11,18,17,13].",
      "startOffset" : 263,
      "endOffset" : 288
    }, {
      "referenceID" : 12,
      "context" : "The publication of [3] has inspired significant efforts in designing and analyzing non-Bayesian learning rules with a particular focus on refining the fusion strategies and analyzing the (asymptotic and/or finite time) convergence rates of the refined algorithms [10,14,15,16,11,18,17,13].",
      "startOffset" : 263,
      "endOffset" : 288
    }, {
      "referenceID" : 14,
      "context" : "In this paper we are particularly interested in the log-linear form of the update rule, in which, essentially, each agent updates its belief as the geometric average of the local Bayesian update and its neighbors’ beliefs [15,10,14,16,11,18,17,13].",
      "startOffset" : 222,
      "endOffset" : 247
    }, {
      "referenceID" : 9,
      "context" : "In this paper we are particularly interested in the log-linear form of the update rule, in which, essentially, each agent updates its belief as the geometric average of the local Bayesian update and its neighbors’ beliefs [15,10,14,16,11,18,17,13].",
      "startOffset" : 222,
      "endOffset" : 247
    }, {
      "referenceID" : 13,
      "context" : "In this paper we are particularly interested in the log-linear form of the update rule, in which, essentially, each agent updates its belief as the geometric average of the local Bayesian update and its neighbors’ beliefs [15,10,14,16,11,18,17,13].",
      "startOffset" : 222,
      "endOffset" : 247
    }, {
      "referenceID" : 15,
      "context" : "In this paper we are particularly interested in the log-linear form of the update rule, in which, essentially, each agent updates its belief as the geometric average of the local Bayesian update and its neighbors’ beliefs [15,10,14,16,11,18,17,13].",
      "startOffset" : 222,
      "endOffset" : 247
    }, {
      "referenceID" : 10,
      "context" : "In this paper we are particularly interested in the log-linear form of the update rule, in which, essentially, each agent updates its belief as the geometric average of the local Bayesian update and its neighbors’ beliefs [15,10,14,16,11,18,17,13].",
      "startOffset" : 222,
      "endOffset" : 247
    }, {
      "referenceID" : 17,
      "context" : "In this paper we are particularly interested in the log-linear form of the update rule, in which, essentially, each agent updates its belief as the geometric average of the local Bayesian update and its neighbors’ beliefs [15,10,14,16,11,18,17,13].",
      "startOffset" : 222,
      "endOffset" : 247
    }, {
      "referenceID" : 16,
      "context" : "In this paper we are particularly interested in the log-linear form of the update rule, in which, essentially, each agent updates its belief as the geometric average of the local Bayesian update and its neighbors’ beliefs [15,10,14,16,11,18,17,13].",
      "startOffset" : 222,
      "endOffset" : 247
    }, {
      "referenceID" : 12,
      "context" : "In this paper we are particularly interested in the log-linear form of the update rule, in which, essentially, each agent updates its belief as the geometric average of the local Bayesian update and its neighbors’ beliefs [15,10,14,16,11,18,17,13].",
      "startOffset" : 222,
      "endOffset" : 247
    }, {
      "referenceID" : 9,
      "context" : "The log-linear form (geometric averaging) update rule is shown to converge exponentially fast [10,16].",
      "startOffset" : 94,
      "endOffset" : 101
    }, {
      "referenceID" : 15,
      "context" : "The log-linear form (geometric averaging) update rule is shown to converge exponentially fast [10,16].",
      "startOffset" : 94,
      "endOffset" : 101
    }, {
      "referenceID" : 12,
      "context" : "Taking an axiomatic approach, the geometric averaging fusion is proved to be optimal [13].",
      "startOffset" : 85,
      "endOffset" : 89
    }, {
      "referenceID" : 15,
      "context" : "An optimization-based interpretation of this rule is presented in [16], using dual averaging method with properly chosen proximal functions.",
      "startOffset" : 66,
      "endOffset" : 70
    }, {
      "referenceID" : 13,
      "context" : "Finite-time convergence rates are investigated independently in [14,11,17].",
      "startOffset" : 64,
      "endOffset" : 74
    }, {
      "referenceID" : 10,
      "context" : "Finite-time convergence rates are investigated independently in [14,11,17].",
      "startOffset" : 64,
      "endOffset" : 74
    }, {
      "referenceID" : 16,
      "context" : "Finite-time convergence rates are investigated independently in [14,11,17].",
      "startOffset" : 64,
      "endOffset" : 74
    }, {
      "referenceID" : 13,
      "context" : "Both [14] and [18] consider time-varying networks, with slightly different network models.",
      "startOffset" : 5,
      "endOffset" : 9
    }, {
      "referenceID" : 17,
      "context" : "Both [14] and [18] consider time-varying networks, with slightly different network models.",
      "startOffset" : 14,
      "endOffset" : 18
    }, {
      "referenceID" : 13,
      "context" : "Specifically, [14] assumes that the union of every consecutive B networks is strongly connected, while [18] considers random networks.",
      "startOffset" : 14,
      "endOffset" : 18
    }, {
      "referenceID" : 17,
      "context" : "Specifically, [14] assumes that the union of every consecutive B networks is strongly connected, while [18] considers random networks.",
      "startOffset" : 103,
      "endOffset" : 107
    }, {
      "referenceID" : 2,
      "context" : "Thus, this paper focuses on the fault-tolerant version the non-Bayesian framework proposed in [3].",
      "startOffset" : 94,
      "endOffset" : 97
    }, {
      "referenceID" : 33,
      "context" : "An alternative fault model, where some agents may unexpectedly cease computing and communicate with each other asynchronously, is considered in our companion work [34].",
      "startOffset" : 163,
      "endOffset" : 167
    }, {
      "referenceID" : 23,
      "context" : "[24] and has attracted intensive attention from researchers [25,26,27,30,28,31].",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 24,
      "context" : "[24] and has attracted intensive attention from researchers [25,26,27,30,28,31].",
      "startOffset" : 60,
      "endOffset" : 79
    }, {
      "referenceID" : 25,
      "context" : "[24] and has attracted intensive attention from researchers [25,26,27,30,28,31].",
      "startOffset" : 60,
      "endOffset" : 79
    }, {
      "referenceID" : 26,
      "context" : "[24] and has attracted intensive attention from researchers [25,26,27,30,28,31].",
      "startOffset" : 60,
      "endOffset" : 79
    }, {
      "referenceID" : 29,
      "context" : "[24] and has attracted intensive attention from researchers [25,26,27,30,28,31].",
      "startOffset" : 60,
      "endOffset" : 79
    }, {
      "referenceID" : 27,
      "context" : "[24] and has attracted intensive attention from researchers [25,26,27,30,28,31].",
      "startOffset" : 60,
      "endOffset" : 79
    }, {
      "referenceID" : 30,
      "context" : "[24] and has attracted intensive attention from researchers [25,26,27,30,28,31].",
      "startOffset" : 60,
      "endOffset" : 79
    }, {
      "referenceID" : 9,
      "context" : "The existing non-Bayesian learning algorithms [10,11,13,14,15,16,17,18] are not robust to Byzantine agents, since the malicious messages sent by the Byzantine agents are indiscriminatingly utilized in the local belief updates.",
      "startOffset" : 46,
      "endOffset" : 71
    }, {
      "referenceID" : 10,
      "context" : "The existing non-Bayesian learning algorithms [10,11,13,14,15,16,17,18] are not robust to Byzantine agents, since the malicious messages sent by the Byzantine agents are indiscriminatingly utilized in the local belief updates.",
      "startOffset" : 46,
      "endOffset" : 71
    }, {
      "referenceID" : 12,
      "context" : "The existing non-Bayesian learning algorithms [10,11,13,14,15,16,17,18] are not robust to Byzantine agents, since the malicious messages sent by the Byzantine agents are indiscriminatingly utilized in the local belief updates.",
      "startOffset" : 46,
      "endOffset" : 71
    }, {
      "referenceID" : 13,
      "context" : "The existing non-Bayesian learning algorithms [10,11,13,14,15,16,17,18] are not robust to Byzantine agents, since the malicious messages sent by the Byzantine agents are indiscriminatingly utilized in the local belief updates.",
      "startOffset" : 46,
      "endOffset" : 71
    }, {
      "referenceID" : 14,
      "context" : "The existing non-Bayesian learning algorithms [10,11,13,14,15,16,17,18] are not robust to Byzantine agents, since the malicious messages sent by the Byzantine agents are indiscriminatingly utilized in the local belief updates.",
      "startOffset" : 46,
      "endOffset" : 71
    }, {
      "referenceID" : 15,
      "context" : "The existing non-Bayesian learning algorithms [10,11,13,14,15,16,17,18] are not robust to Byzantine agents, since the malicious messages sent by the Byzantine agents are indiscriminatingly utilized in the local belief updates.",
      "startOffset" : 46,
      "endOffset" : 71
    }, {
      "referenceID" : 16,
      "context" : "The existing non-Bayesian learning algorithms [10,11,13,14,15,16,17,18] are not robust to Byzantine agents, since the malicious messages sent by the Byzantine agents are indiscriminatingly utilized in the local belief updates.",
      "startOffset" : 46,
      "endOffset" : 71
    }, {
      "referenceID" : 17,
      "context" : "The existing non-Bayesian learning algorithms [10,11,13,14,15,16,17,18] are not robust to Byzantine agents, since the malicious messages sent by the Byzantine agents are indiscriminatingly utilized in the local belief updates.",
      "startOffset" : 46,
      "endOffset" : 71
    }, {
      "referenceID" : 13,
      "context" : "In contrast to the existing algorithms [14,11], where only the current private signal is used in the update, our proposed algorithm relies on the cumulative private signals.",
      "startOffset" : 39,
      "endOffset" : 46
    }, {
      "referenceID" : 10,
      "context" : "In contrast to the existing algorithms [14,11], where only the current private signal is used in the update, our proposed algorithm relies on the cumulative private signals.",
      "startOffset" : 39,
      "endOffset" : 46
    }, {
      "referenceID" : 9,
      "context" : "Thus, our proposed rule may be of independent interest for the failure-free setting considered in [10,11,13,14,15,16,17,18].",
      "startOffset" : 98,
      "endOffset" : 123
    }, {
      "referenceID" : 10,
      "context" : "Thus, our proposed rule may be of independent interest for the failure-free setting considered in [10,11,13,14,15,16,17,18].",
      "startOffset" : 98,
      "endOffset" : 123
    }, {
      "referenceID" : 12,
      "context" : "Thus, our proposed rule may be of independent interest for the failure-free setting considered in [10,11,13,14,15,16,17,18].",
      "startOffset" : 98,
      "endOffset" : 123
    }, {
      "referenceID" : 13,
      "context" : "Thus, our proposed rule may be of independent interest for the failure-free setting considered in [10,11,13,14,15,16,17,18].",
      "startOffset" : 98,
      "endOffset" : 123
    }, {
      "referenceID" : 14,
      "context" : "Thus, our proposed rule may be of independent interest for the failure-free setting considered in [10,11,13,14,15,16,17,18].",
      "startOffset" : 98,
      "endOffset" : 123
    }, {
      "referenceID" : 15,
      "context" : "Thus, our proposed rule may be of independent interest for the failure-free setting considered in [10,11,13,14,15,16,17,18].",
      "startOffset" : 98,
      "endOffset" : 123
    }, {
      "referenceID" : 16,
      "context" : "Thus, our proposed rule may be of independent interest for the failure-free setting considered in [10,11,13,14,15,16,17,18].",
      "startOffset" : 98,
      "endOffset" : 123
    }, {
      "referenceID" : 17,
      "context" : "Thus, our proposed rule may be of independent interest for the failure-free setting considered in [10,11,13,14,15,16,17,18].",
      "startOffset" : 98,
      "endOffset" : 123
    }, {
      "referenceID" : 3,
      "context" : "2 Problem Formulation Network Model: Our network model is similar to the model used in [4,30].",
      "startOffset" : 87,
      "endOffset" : 93
    }, {
      "referenceID" : 29,
      "context" : "2 Problem Formulation Network Model: Our network model is similar to the model used in [4,30].",
      "startOffset" : 87,
      "endOffset" : 93
    }, {
      "referenceID" : 11,
      "context" : "The faulty agents may collaborate with each other adaptively [12].",
      "startOffset" : 61,
      "endOffset" : 65
    }, {
      "referenceID" : 2,
      "context" : "Observation Model: Our observation model is identical the model used in [3,11,18].",
      "startOffset" : 72,
      "endOffset" : 81
    }, {
      "referenceID" : 10,
      "context" : "Observation Model: Our observation model is identical the model used in [3,11,18].",
      "startOffset" : 72,
      "endOffset" : 81
    }, {
      "referenceID" : 17,
      "context" : "Observation Model: Our observation model is identical the model used in [3,11,18].",
      "startOffset" : 72,
      "endOffset" : 81
    }, {
      "referenceID" : 24,
      "context" : "Byzantine consensus has attracted significant amount of attention [25,26,29,27,30,28,31].",
      "startOffset" : 66,
      "endOffset" : 88
    }, {
      "referenceID" : 25,
      "context" : "Byzantine consensus has attracted significant amount of attention [25,26,29,27,30,28,31].",
      "startOffset" : 66,
      "endOffset" : 88
    }, {
      "referenceID" : 28,
      "context" : "Byzantine consensus has attracted significant amount of attention [25,26,29,27,30,28,31].",
      "startOffset" : 66,
      "endOffset" : 88
    }, {
      "referenceID" : 26,
      "context" : "Byzantine consensus has attracted significant amount of attention [25,26,29,27,30,28,31].",
      "startOffset" : 66,
      "endOffset" : 88
    }, {
      "referenceID" : 29,
      "context" : "Byzantine consensus has attracted significant amount of attention [25,26,29,27,30,28,31].",
      "startOffset" : 66,
      "endOffset" : 88
    }, {
      "referenceID" : 27,
      "context" : "Byzantine consensus has attracted significant amount of attention [25,26,29,27,30,28,31].",
      "startOffset" : 66,
      "endOffset" : 88
    }, {
      "referenceID" : 30,
      "context" : "Byzantine consensus has attracted significant amount of attention [25,26,29,27,30,28,31].",
      "startOffset" : 66,
      "endOffset" : 88
    }, {
      "referenceID" : 30,
      "context" : "While the past work mostly focus on scalar inputs, the more general vector (or multi-dimensional) inputs have been studied recently [31,29,28].",
      "startOffset" : 132,
      "endOffset" : 142
    }, {
      "referenceID" : 28,
      "context" : "While the past work mostly focus on scalar inputs, the more general vector (or multi-dimensional) inputs have been studied recently [31,29,28].",
      "startOffset" : 132,
      "endOffset" : 142
    }, {
      "referenceID" : 27,
      "context" : "While the past work mostly focus on scalar inputs, the more general vector (or multi-dimensional) inputs have been studied recently [31,29,28].",
      "startOffset" : 132,
      "endOffset" : 142
    }, {
      "referenceID" : 30,
      "context" : "Complete communication networks are considered in [31,29], where tight conditions on the number of agents are identified.",
      "startOffset" : 50,
      "endOffset" : 57
    }, {
      "referenceID" : 28,
      "context" : "Complete communication networks are considered in [31,29], where tight conditions on the number of agents are identified.",
      "startOffset" : 50,
      "endOffset" : 57
    }, {
      "referenceID" : 27,
      "context" : "Incomplete communication networks are studied in [28].",
      "startOffset" : 49,
      "endOffset" : 53
    }, {
      "referenceID" : 27,
      "context" : "In particular, our learning algorithms build upon Byz-Iter algorithm proposed in [28] and a simple algorithm proposed in [30] for iterative Byzantine consensus with vector inputs and scalar inputs, respectively, in incomplete networks.",
      "startOffset" : 81,
      "endOffset" : 85
    }, {
      "referenceID" : 29,
      "context" : "In particular, our learning algorithms build upon Byz-Iter algorithm proposed in [28] and a simple algorithm proposed in [30] for iterative Byzantine consensus with vector inputs and scalar inputs, respectively, in incomplete networks.",
      "startOffset" : 121,
      "endOffset" : 125
    }, {
      "referenceID" : 27,
      "context" : "A matrix representation of the non-faulty agents’ states evolution under Byz-Iter algorithm is provided by [28], which also captures the dynamics of the simple algorithm with scalar inputs in [30].",
      "startOffset" : 107,
      "endOffset" : 111
    }, {
      "referenceID" : 29,
      "context" : "A matrix representation of the non-faulty agents’ states evolution under Byz-Iter algorithm is provided by [28], which also captures the dynamics of the simple algorithm with scalar inputs in [30].",
      "startOffset" : 192,
      "endOffset" : 196
    }, {
      "referenceID" : 27,
      "context" : "1 Algorithm Byz-Iter [28] Algorithm Byz-Iter is based on Tverberg’s Theorem [32].",
      "startOffset" : 21,
      "endOffset" : 25
    }, {
      "referenceID" : 31,
      "context" : "1 Algorithm Byz-Iter [28] Algorithm Byz-Iter is based on Tverberg’s Theorem [32].",
      "startOffset" : 76,
      "endOffset" : 80
    }, {
      "referenceID" : 31,
      "context" : "[32] Let f be a nonnegative integer.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 27,
      "context" : "Algorithm 2: Algorithm Byz-Iter [28]: t-th iteration at agent i 1 v t ← One-Iter(v t−1); Remark 1.",
      "startOffset" : 32,
      "endOffset" : 36
    }, {
      "referenceID" : 27,
      "context" : "2 Correctness of Algorithm Byz-Iter We briefly summarize the aspects of correctness proof of Algorithm 2 from [28] that are necessary for our subsequent discussion.",
      "startOffset" : 110,
      "endOffset" : 114
    }, {
      "referenceID" : 27,
      "context" : "[28] shows that the effective communication network thus obtained can be characterized by a “reduced graph” of G(V, E), defined below.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 27,
      "context" : "Assumption 1 below states a condition that is sufficient for reaching approximate Byzantine vector consensus using Algorithm 1 [28].",
      "startOffset" : 127,
      "endOffset" : 131
    }, {
      "referenceID" : 27,
      "context" : "[28] Suppose Assumption 1 holds for a given m ≥ 1.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 27,
      "context" : "3 Matrix Representation [28] Let |F| = φ (thus, 0 ≤ φ ≤ f).",
      "startOffset" : 24,
      "endOffset" : 28
    }, {
      "referenceID" : 27,
      "context" : "[28] Suppose Assumption 1 holds for a given m ≥ 1.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 8,
      "context" : "Using prior work on coefficients of ergodicity [9], under Assumption 1, it has been shown [28,19] that lim t≥r, t→∞ Φ(t, r) = 1π(r), (3) where π(r) ∈ Rn−φ is a row stochastic vector, and 1 is the column vector with each entry being 1.",
      "startOffset" : 47,
      "endOffset" : 50
    }, {
      "referenceID" : 27,
      "context" : "Using prior work on coefficients of ergodicity [9], under Assumption 1, it has been shown [28,19] that lim t≥r, t→∞ Φ(t, r) = 1π(r), (3) where π(r) ∈ Rn−φ is a row stochastic vector, and 1 is the column vector with each entry being 1.",
      "startOffset" : 90,
      "endOffset" : 97
    }, {
      "referenceID" : 18,
      "context" : "Using prior work on coefficients of ergodicity [9], under Assumption 1, it has been shown [28,19] that lim t≥r, t→∞ Φ(t, r) = 1π(r), (3) where π(r) ∈ Rn−φ is a row stochastic vector, and 1 is the column vector with each entry being 1.",
      "startOffset" : 90,
      "endOffset" : 97
    }, {
      "referenceID" : 27,
      "context" : "[28] For all t ≥ r ≥ 1, it holds that |Φij(t, r)− πj(r)| ≤ (1 − β m) t−r+1 ν ⌉, where ν , χm(n− φ).",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 27,
      "context" : "The next lemma is a consequence of the results in [28].",
      "startOffset" : 50,
      "endOffset" : 54
    }, {
      "referenceID" : 27,
      "context" : "[28] For any r ≥ 1, there exists a reduced graph H[r] with source component Sr such that πi(r) ≥ βχm(n−φ) m for each i ∈ Sr.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 29,
      "context" : ", the inputs provided at individual non-faulty agents are scalars) it has been shown [30] that Assumption 1 is also necessary.",
      "startOffset" : 85,
      "endOffset" : 89
    }, {
      "referenceID" : 29,
      "context" : "[30] For scalar inputs, iterative approximate Byzantine consensus is achievable among non-faulty agents if and only if every 1-dimensional reduced graph of G(V, E) contains only one source component.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 29,
      "context" : "8 Algorithm 3: Algorithm Scalar Byzantine Consensus: iteration t ≥ 1 [30] 1 Transmit vi[t− 1] on all outgoing links; 2 Receive messages on all incoming links.",
      "startOffset" : 69,
      "endOffset" : 73
    }, {
      "referenceID" : 13,
      "context" : "BFL is a modified version of the geometric averaging update rule that has been investigated in previous work [14,15,11,17].",
      "startOffset" : 109,
      "endOffset" : 122
    }, {
      "referenceID" : 14,
      "context" : "BFL is a modified version of the geometric averaging update rule that has been investigated in previous work [14,15,11,17].",
      "startOffset" : 109,
      "endOffset" : 122
    }, {
      "referenceID" : 10,
      "context" : "BFL is a modified version of the geometric averaging update rule that has been investigated in previous work [14,15,11,17].",
      "startOffset" : 109,
      "endOffset" : 122
    }, {
      "referenceID" : 16,
      "context" : "BFL is a modified version of the geometric averaging update rule that has been investigated in previous work [14,15,11,17].",
      "startOffset" : 109,
      "endOffset" : 122
    }, {
      "referenceID" : 13,
      "context" : "Algorithm 4: BFL: Iteration t ≥ 1 at agent i 1 η t ← One-Iter(log μt−1); 2 Observe st; 3 for θ ∈ Θ do 4 li(s i 1,t|θ) ← li(st|θ) li(s1,t−1|θ); 5 μt(θ) ← li(s1,t|θ) exp(η t(θ)) ∑m p=1 li(s i 1,t|θp) exp(η t(θp)) ; 6 end The main difference of Algorithm 4 with respect to the algorithms in [14,15,11,17] is that (i) our algorithm uses a Byzantine consensus iteration as a primitive (in line 1), and (ii) li(s i 1,t|θ) used in line 5 is the likelihood for observations from iteration 1 to t (the previous algorithms instead use li(s i t|θ) here).",
      "startOffset" : 288,
      "endOffset" : 301
    }, {
      "referenceID" : 14,
      "context" : "Algorithm 4: BFL: Iteration t ≥ 1 at agent i 1 η t ← One-Iter(log μt−1); 2 Observe st; 3 for θ ∈ Θ do 4 li(s i 1,t|θ) ← li(st|θ) li(s1,t−1|θ); 5 μt(θ) ← li(s1,t|θ) exp(η t(θ)) ∑m p=1 li(s i 1,t|θp) exp(η t(θp)) ; 6 end The main difference of Algorithm 4 with respect to the algorithms in [14,15,11,17] is that (i) our algorithm uses a Byzantine consensus iteration as a primitive (in line 1), and (ii) li(s i 1,t|θ) used in line 5 is the likelihood for observations from iteration 1 to t (the previous algorithms instead use li(s i t|θ) here).",
      "startOffset" : 288,
      "endOffset" : 301
    }, {
      "referenceID" : 10,
      "context" : "Algorithm 4: BFL: Iteration t ≥ 1 at agent i 1 η t ← One-Iter(log μt−1); 2 Observe st; 3 for θ ∈ Θ do 4 li(s i 1,t|θ) ← li(st|θ) li(s1,t−1|θ); 5 μt(θ) ← li(s1,t|θ) exp(η t(θ)) ∑m p=1 li(s i 1,t|θp) exp(η t(θp)) ; 6 end The main difference of Algorithm 4 with respect to the algorithms in [14,15,11,17] is that (i) our algorithm uses a Byzantine consensus iteration as a primitive (in line 1), and (ii) li(s i 1,t|θ) used in line 5 is the likelihood for observations from iteration 1 to t (the previous algorithms instead use li(s i t|θ) here).",
      "startOffset" : 288,
      "endOffset" : 301
    }, {
      "referenceID" : 16,
      "context" : "Algorithm 4: BFL: Iteration t ≥ 1 at agent i 1 η t ← One-Iter(log μt−1); 2 Observe st; 3 for θ ∈ Θ do 4 li(s i 1,t|θ) ← li(st|θ) li(s1,t−1|θ); 5 μt(θ) ← li(s1,t|θ) exp(η t(θ)) ∑m p=1 li(s i 1,t|θp) exp(η t(θp)) ; 6 end The main difference of Algorithm 4 with respect to the algorithms in [14,15,11,17] is that (i) our algorithm uses a Byzantine consensus iteration as a primitive (in line 1), and (ii) li(s i 1,t|θ) used in line 5 is the likelihood for observations from iteration 1 to t (the previous algorithms instead use li(s i t|θ) here).",
      "startOffset" : 288,
      "endOffset" : 301
    }, {
      "referenceID" : 2,
      "context" : "1 Identifiability In the absence of agent failures [3], for the networked agents to detect the true hypothesis θ∗, it is sufficient to assume that G(V, E) is strongly connected, and that θ∗ is globally identifiable.",
      "startOffset" : 51,
      "endOffset" : 54
    }, {
      "referenceID" : 13,
      "context" : "2 Convergence Results Our proof parallels the structure of a proof in [14], but with some key differences to take into account our update rule for the belief vector.",
      "startOffset" : 70,
      "endOffset" : 74
    }, {
      "referenceID" : 13,
      "context" : "(16) As it can be seen later, the proof of Lemma 3 is significantly different from the analogous lemma in [14].",
      "startOffset" : 106,
      "endOffset" : 110
    }, {
      "referenceID" : 13,
      "context" : "Our convergence proof has similar structure as the analysis in [14].",
      "startOffset" : 63,
      "endOffset" : 67
    }, {
      "referenceID" : 13,
      "context" : "Indeed, the BFL for f = 0 is a simple modification of the algorithm proposed in [14].",
      "startOffset" : 80,
      "endOffset" : 84
    }, {
      "referenceID" : 13,
      "context" : "As mentioned before, the non-Bayesian learning rules [14,15,11,17] are consensus-based learning algorithms, wherein agents are required to reach a common decision asymptotically.",
      "startOffset" : 53,
      "endOffset" : 66
    }, {
      "referenceID" : 14,
      "context" : "As mentioned before, the non-Bayesian learning rules [14,15,11,17] are consensus-based learning algorithms, wherein agents are required to reach a common decision asymptotically.",
      "startOffset" : 53,
      "endOffset" : 66
    }, {
      "referenceID" : 10,
      "context" : "As mentioned before, the non-Bayesian learning rules [14,15,11,17] are consensus-based learning algorithms, wherein agents are required to reach a common decision asymptotically.",
      "startOffset" : 53,
      "endOffset" : 66
    }, {
      "referenceID" : 16,
      "context" : "As mentioned before, the non-Bayesian learning rules [14,15,11,17] are consensus-based learning algorithms, wherein agents are required to reach a common decision asymptotically.",
      "startOffset" : 53,
      "endOffset" : 66
    }, {
      "referenceID" : 13,
      "context" : "Our proof is similar to the proof presented in [14,17].",
      "startOffset" : 47,
      "endOffset" : 54
    }, {
      "referenceID" : 16,
      "context" : "Our proof is similar to the proof presented in [14,17].",
      "startOffset" : 47,
      "endOffset" : 54
    }, {
      "referenceID" : 13,
      "context" : "Similar to [14,17], we also use McDiarmid’s Inequality.",
      "startOffset" : 11,
      "endOffset" : 18
    }, {
      "referenceID" : 16,
      "context" : "Similar to [14,17], we also use McDiarmid’s Inequality.",
      "startOffset" : 11,
      "endOffset" : 18
    }, {
      "referenceID" : 13,
      "context" : "Our analysis for the special when f = 0 also works for time-varying networks [14].",
      "startOffset" : 77,
      "endOffset" : 81
    }, {
      "referenceID" : 19,
      "context" : "By [20], we know that for each pair of hypotheses θ1 and θ2, there exists a row-stochastic matrix M1,2[t] ∈ R(n−φ)×(n−φ) such that r t(θ1, θ2) = n−φ ∑",
      "startOffset" : 3,
      "endOffset" : 7
    } ],
    "year" : 2016,
    "abstractText" : "Abstract This paper addresses the problem of non-Bayesian learning over multi-agent networks, where agents repeatedly collect partially informative observations about an unknown state of the world, and try to collaboratively learn the true state. We focus on the impact of the adversarial agents on the performance of consensus-based non-Bayesian learning, where non-faulty agents combine local learning updates with consensus primitives. In particular, we consider the scenario where an unknown subset of agents suffer Byzantine faults – agents suffering Byzantine faults behave arbitrarily.",
    "creator" : "LaTeX with hyperref package"
  }
}