{
  "name" : "1511.04397.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "DEEPLY SUPERVISED SIAMESE NETWORK",
    "authors" : [ "Ehsan Hosseini-Asl" ],
    "emails" : [ "ehsan.hosseiniasl@louisville.edu", "angshumang@captricity.com" ],
    "sections" : [ {
      "heading" : null,
      "text" : "In this paper, we propose a new text recognition model based on measuring the visual similarity of text and predicting the content of the unlabeled texts. First a Siamese network is trained with deep supervision on a labeled training dataset. This network projects texts into a similarity manifold. The Deeply Supervised Siamese network learns visual similarity of texts. Then a K-nearest neighbor classifier is used to predict unlabeled text based on similarity distance to labeled texts. The performance of the model is evaluated on three datasets of machine-print and hand-written text combined. We demonstrate that the model reduces the cost of human estimation by 50%− 85%. The error of the system is less than 0.1%. The results also demonstrate that the predicted labels are sometimes better than human labels e.g. spelling correction."
    }, {
      "heading" : "1 INTRODUCTION",
      "text" : "Optical Character Recognition (OCR) is traditionally used to convert images of machine printed text into textual content. Intelligent Character Recognition (ICR) is used to do the same for images of handwritten text. State-of-the-art OCR engines can work well, but only for clean data and where the OCR engine can be adjusted to deal with a single font or a small set of fonts. State-of-the-art ICR engines are significantly worse.\nFor a real-life application of high-accuracy character recognition involving both machine print and handwriting, one has to develop ones own OCR/ICR engine. This typically requires plenty of character-segmented data, as well as labeling at the character level. This is a very expensive proposition in most real-world situations, if not an impossible one. To avoid the character segmentation cost, Keeler et al. (1991) proposed learning character segmentation and recognition simultaneously from un-segmented data. This does not work well in practice beyond numeric characters and for large vocabularies. There has been some work at limited-vocabulary whole word recognition, see, for example, Lavrenko et al. (2004). Recently there also has been work involving innovative models where nth characters are predicted for an input word of a fixed-size input image. For instance, one model might predict the first character, another model might predict the second character, and so on. See for example, Jaderberg et al. (2014).\nOur goal is for a practical system that organically incorporates human labeling with machine learning to achieve very low error rates (≤ 0.1%) while minimizing the amount of necessary human labeling. In this paper, we propose and discuss a novel method of text recognition that does not require character-segmented data. We use a Siamese Convolutional Network to map variable-size text images into a fixed-size feature space that preserves similarity between inputs. This induces a similarity/distance metric between different text images. This, in turn, allows for the development of a k-nearest neighbor algorithm for text prediction. See Fig. 1 for examples of similar images i.e. with the same text content.\n∗The work was performed during an internship at Captricity, Inc.\nar X\niv :1\n51 1.\n04 39\n7v 1\n[ cs\n.C V\n] 1\n3 N\nov 2\n01 5"
    }, {
      "heading" : "2 PROPOSED MODEL",
      "text" : "In this section, we propose a model of text recognition based on learning similarity of images. In section 2.1, a Siamese network is proposed for learning similarity of text, and section 2.2 describes a text recognition framework."
    }, {
      "heading" : "2.1 LEARNING TEXT SIMILARITY",
      "text" : "To train a model to be able to learn the similarity between texts, a Siamese network is used as in Chopra et al. (2005); Hadsell et al. (2006). The Siamese network is trained to project the images into a feature space, where the similar images are projected with short mutual Euclidean distance, and dissimilar images are projected with large mutual Euclidean distances. The training of Siamese network is based on minimizing the contrastive loss of a pair of images,\nL(W ) = (1− Y ) ∗ 1 2 D2w + 1 2 ∗ Y ∗max(0,m−Dw)2 (1)\nwhere W = {{w0, ..., wn}, wo} are the weights of the hidden layers and output layer of Siamese network, Y is the label of paired images, i.e. 0 if similar and 1 if dissimilar, Dw is the Euclidean distance between a pair of images, and m is the desired Euclidean distance between a pair of dissimilar images. Siamese networks have shown promising results in learning similarity of handwritten digits dataset, MNIST. However, in complicated cases of long text, capturing the similarities between two texts is infeasible using a single loss function in the output layer of Siamese network. The performance of contrastive loss L is dependent on feature extraction of the hidden layers, where it should capture the similarities in a hierarchical way, to enable the output layer to extract features which can clearly represent the similarities of long and complex text. In order to boost the performance of\nthe Siamese network for learning similarity of long text, we used the method of deep supervision proposed in Lee et al. (2014), where several contrastive loss functions are used for hidden and output layers, to improve the discriminativeness of feature learning, as shown in Fig. 2. Therefore, the proposed method is called Deeply Supervised Siamese Network (DSSN) and it is trained using the combined contrastive loss,\nLDSSN (W ) = n∑\nl=0\nLl(w(l)) + Lo(wo) (2)\nwhere l indicates the index for hidden layer, o is the output layer. Eq. 2 indicates that the loss Ll of each hidden layer is only the function of weights of that layer, i.e. w(l). The DSSN network will generate a Similarity Manifold, where similar texts are projected in short mutual Euclidean distance. The next section describes the text recognition model based on the Similarity Manifold."
    }, {
      "heading" : "2.2 TEXT RECOGNITION BY TEXT SIMILARITY",
      "text" : "This section desribes a text recognition framework to predict the label of text using developed DSSN model in previous section. The text recognition model is based on feature extraction of text using proposed DSSN network. We use K-nearest neighbor to predict the label of text images in test data, based on similarity distance to the labeled text in train data. Then the predicted label is compared with the human estimation as shown in Fig. 3(a).\nOur human-based model to predict a text label is based on voting of two human on a text. The proposed framework in Fig. 3 (a) is based on reducing the cost of human in predicting the label. As shown in Fig. 3(a), the predicted label of DSSN-KNN is evaluated by the computed confidence and high-confidence parameters, i.e. θ1 and θ2 respectively. Based on the selected θ1 and θ2, if the high-confident, we omit the required two human estimation. However, if the label is only confident, we validate the predicted label of DSSN-KNN with one human.\nTo measure the performance of DSSN-KNN in reducing the human estimation, we define an efficiency metric as shown in Fig. 3(b),\nefficiency = A1+B1 2 +A2 +B2\nT (3)\nwhere T is the total number of unlabeled texts, A1 and B1 are the number of confident wrong and correctly predicted texts, and A2 and B2 are the number of high-confident wrong and correctly predicted texts, respectively."
    }, {
      "heading" : "3 EXPERIMENTS",
      "text" : "In this section, we design several experiments to evaluate the performance of our proposed model on text recognition. First we apply some metrics to evaluate the performance of DSSN in learning\nthe similarity manifold in section 3.1. Then the performance of DSSN-KNN is evaluated for text recognition of three hand-written text dataset in section 3.2."
    }, {
      "heading" : "3.1 SIMILARITY MANIFOLD EVALUATION",
      "text" : "In order to evaluate the performance of proposed DSSN for text recognition, we evaluate the trained similarity manifold for detecting similar and dissimilar texts. For this purpose, we implemented two separate experiment for non-numeric and numeric texts.\nThe non-numeric dataset contains 8 classes, where there are two major class with highest number of data. We found that most of the human predicted ’blank’ text are actually not blank, and contain some text from the two major classes. Therefore, the misclassified text in training data decrease performance of DSSN.\nTo investigate the distribution of text in similarity manifold, the feature space of hidden layers and output layer is visualzied in Fig. 4 and Fig. 5. Fig.4 shows the visualization of texts based on the 50 and 20-dimensional features extracted in ’conv2’ and ’relu1’ layer, respectively. (Visualization of multidimensional data is done using a technique called t-SNE.) It demonstrates that the three major classes, are separated e.g. ’LEER, ”BECKLEY’ and ’Mountain Laurel’. Fig. 5 depicts the distribution of all texts in ’feat’ layer is shown below, where each region is expanded for better visualization. Accordingly, some boxes contain textss belonging to only one class, e.g. 2, 3, 5, 8, 9, 10, 11. The ’2014’ class is mixed with other classes of ’2018’ and ’2016’, as shown in boxes 1, 4, 6, 7, 13. The ’blank’ shreds in box 12 which are combined with ’2016’ texts are mis-labeled texts, which reduce the clustering performance of the DSSN model.\nIn order to evaluate the similarity manifold, several random pairs of images are selected from test set and feed-forwarded to the DSSN. Then, the Euclidean distance between the paired images are computed based on the output of ’feat’ layer. Finally, a threshold value θ is computed to minimizes the False Positive (FP), i.e. similar images predicted as dissimilar, and False Negative (FN), i.e. dissimilar images predicted as similar. Table 1 shows the results for model initialized by MNISTdata, and after fine-tuning on the training dataset,\nTo further evaluate the similarity manifold, the clustering algorithm is applied on texts and the clustered texts are evaluated based on truth labels. For this matter, the parallel network of DSSN is removed. Then we use the extracted features from hidden and output layers for clustering of the\ntext. Several clustering algorithms are implemented. To have a better evaluation of features in each layer, we applied clustering algorithms on the features of the ’relu1’, ’ip1’, and ’feat’ layers. The number of clusters for K-means and spectral clustering are set to 8. For DBSCAN and Agglomerative algorithms, the number of clusters are based on the similarity distance between shreds. The clustering performance is computed as the ranking match between the predicted labels (computed by clustering algorithm) and the truth labels. Table 2 shows the best clustering algorithm perfrmance, i.e. agglomerative clustering on 3 layers of DSSN network,"
    }, {
      "heading" : "3.2 TEXT RECOGNITION EVALUATION",
      "text" : "In section 3.1, the similarity manifold learnd by DSSN was evaluated on for clustering and similarity orediction. This section focuses on performance of the proposed DSSN-KNN framework, as shown in Fig. 3 for text recognition. The trained DSSN model are tested on the three most difficult handwritten fields, where they include hand-written and machine printed text which contains several variation, e.g. translation, scale and pattern variations for each classs. The number of texts and unique classes in each datasets are tabluated in Table 3.\nIn order to select the confidence and high-confidence thresholds (θ1 and θ2) for each dataset, several levels of thereholds are selected, and the best selection which yileds minumim High Confidence False Negative (HCFN) are chosen. The chisen threshold for each dataset and the error values are shown in Table 4.\nThe text recognition performance of DSSN-KNN on the three dataset are shown in Table 5, where the reduction in human estimation are shown. To investigate the source of HCFN errors, some of the text where DSSN-KNN produce high confidence error are shown in Fig. 6. It is shown that most\nof the texts with visual similarities are mislabeled because of humarn error in labeling. However, DSSN-KNN predict similar text as similar based on Similarity Manifold. Moreover, DSSN-KNN sometimes predict better label than human, by spelling corrections."
    }, {
      "heading" : "4 CONCLUSION",
      "text" : "In this paper, we proposed a new text recognition model based on measuring the visual similarity of text and predicting the content of the unlabeled texts. A Deeply Supervised Siamese Network is trained along with a K-nearest neighbor classifier, to predict the label of text. The performance of the proposed model was evaluated in learning text similarity and reducing the human cost of prediction. The results showed that the predicted labels are sometimes better than human estimates labels e.g. spelling correction. Some of the false negative errors we count are in whitespace and irrelevant punctuation (the ”real” error is lower than reported here). The average value of humanless efficiency on successful field is: 25− 45% using Only 1-human with NO error, and 50− 85% using 0&1-human with < 0.1% error. Explainable Errors are observed for labels which are visually similar."
    } ],
    "references" : [ {
      "title" : "Learning a similarity metric discriminatively, with application to face verification",
      "author" : [ "Chopra", "Sumit", "Hadsell", "Raia", "LeCun", "Yann" ],
      "venue" : "In Computer Vision and Pattern Recognition,",
      "citeRegEx" : "Chopra et al\\.,? \\Q2005\\E",
      "shortCiteRegEx" : "Chopra et al\\.",
      "year" : 2005
    }, {
      "title" : "Dimensionality reduction by learning an invariant mapping",
      "author" : [ "Hadsell", "Raia", "Chopra", "Sumit", "LeCun", "Yann" ],
      "venue" : "In Computer vision and pattern recognition,",
      "citeRegEx" : "Hadsell et al\\.,? \\Q2006\\E",
      "shortCiteRegEx" : "Hadsell et al\\.",
      "year" : 2006
    }, {
      "title" : "Synthetic data and artificial neural networks for natural scene text recognition",
      "author" : [ "Jaderberg", "Max", "Simonyan", "Karen", "Vedaldi", "Andrea", "Zisserman", "Andrew" ],
      "venue" : "arXiv preprint arXiv:1406.2227,",
      "citeRegEx" : "Jaderberg et al\\.,? \\Q2014\\E",
      "shortCiteRegEx" : "Jaderberg et al\\.",
      "year" : 2014
    }, {
      "title" : "Self-organizing integrated segmentation and recognition neural network",
      "author" : [ "Keeler", "James D", "Rumelhart", "David E", "W.K. Leow", "R.P. Lippmann", "J.M. Moody", "D.S. Touretzky" ],
      "venue" : "In Neural Information Processing Systems,",
      "citeRegEx" : "Keeler et al\\.,? \\Q1991\\E",
      "shortCiteRegEx" : "Keeler et al\\.",
      "year" : 1991
    }, {
      "title" : "Holistic word recognition for handwritten historical documents",
      "author" : [ "Lavrenko", "Victor", "Rath", "Toni M", "R. Manmatha" ],
      "venue" : "In Document Image Analysis for Libraries,",
      "citeRegEx" : "Lavrenko et al\\.,? \\Q2004\\E",
      "shortCiteRegEx" : "Lavrenko et al\\.",
      "year" : 2004
    }, {
      "title" : "Under review as a conference paper at ICLR",
      "author" : [ "Chen-Yu", "Xie", "Saining", "Gallagher", "Patrick", "Zhang", "Zhengyou", "Tu", "Zhuowen" ],
      "venue" : "Deeplysupervised nets. arXiv preprint arXiv:1409.5185,",
      "citeRegEx" : "Chen.Yu et al\\.,? \\Q2016\\E",
      "shortCiteRegEx" : "Chen.Yu et al\\.",
      "year" : 2016
    } ],
    "referenceMentions" : [ {
      "referenceID" : 2,
      "context" : "To avoid the character segmentation cost, Keeler et al. (1991) proposed learning character segmentation and recognition simultaneously from un-segmented data.",
      "startOffset" : 42,
      "endOffset" : 63
    }, {
      "referenceID" : 2,
      "context" : "To avoid the character segmentation cost, Keeler et al. (1991) proposed learning character segmentation and recognition simultaneously from un-segmented data. This does not work well in practice beyond numeric characters and for large vocabularies. There has been some work at limited-vocabulary whole word recognition, see, for example, Lavrenko et al. (2004). Recently there also has been work involving innovative models where n characters are predicted for an input word of a fixed-size input image.",
      "startOffset" : 42,
      "endOffset" : 361
    }, {
      "referenceID" : 2,
      "context" : "See for example, Jaderberg et al. (2014). Our goal is for a practical system that organically incorporates human labeling with machine learning to achieve very low error rates (≤ 0.",
      "startOffset" : 17,
      "endOffset" : 41
    }, {
      "referenceID" : 0,
      "context" : "1 LEARNING TEXT SIMILARITY To train a model to be able to learn the similarity between texts, a Siamese network is used as in Chopra et al. (2005); Hadsell et al.",
      "startOffset" : 126,
      "endOffset" : 147
    }, {
      "referenceID" : 0,
      "context" : "1 LEARNING TEXT SIMILARITY To train a model to be able to learn the similarity between texts, a Siamese network is used as in Chopra et al. (2005); Hadsell et al. (2006). The Siamese network is trained to project the images into a feature space, where the similar images are projected with short mutual Euclidean distance, and dissimilar images are projected with large mutual Euclidean distances.",
      "startOffset" : 126,
      "endOffset" : 170
    } ],
    "year" : 2017,
    "abstractText" : "In this paper, we propose a new text recognition model based on measuring the visual similarity of text and predicting the content of the unlabeled texts. First a Siamese network is trained with deep supervision on a labeled training dataset. This network projects texts into a similarity manifold. The Deeply Supervised Siamese network learns visual similarity of texts. Then a K-nearest neighbor classifier is used to predict unlabeled text based on similarity distance to labeled texts. The performance of the model is evaluated on three datasets of machine-print and hand-written text combined. We demonstrate that the model reduces the cost of human estimation by 50%− 85%. The error of the system is less than 0.1%. The results also demonstrate that the predicted labels are sometimes better than human labels e.g. spelling correction.",
    "creator" : "LaTeX with hyperref package"
  }
}