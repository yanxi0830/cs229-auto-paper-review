{
  "name" : "1705.04193.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "NONNEGATIVE MATRIX FACTORIZATION WITH TRANSFORM LEARNING",
    "authors" : [ "Dylan Fagot", "Cédric Févotte", "Herwig Wendt" ],
    "emails" : [ "firstname.lastname@irit.fr" ],
    "sections" : [ {
      "heading" : null,
      "text" : "Index Terms— Nonnegative matrix factorization (NMF), transform learning, single-channel source separation"
    }, {
      "heading" : "1. INTRODUCTION",
      "text" : "Nonnegative matrix factorization (NMF) has become a privileged approach to spectral decomposition in several fields such as remote sensing and audio signal processing. In the latter field, it has led to state-of-the-art results in source separation [1] or music transcription [2]. The nonnegative data V ∈ RM×N+ is typically the spectrogram |X| or |X|◦2 of some temporal signal y ∈ RT , where X ∈ CM×N is a short-time Fourier transform (STFT) of y, | · | denotes the entry-wise absolute value and ◦ here denotes entry-wise exponentiation. NMF produces the approximate factorization\nV ≈WH, (1)\nwhere W ∈ RM×K+ is a nonnegative matrix referred to as dictionary that contains spectral patterns characteristic of the data while H ∈ RK×N+ is the nonnegative matrix that contains the activation coefficients that approximate the data samples onto the dictionary. The factorization is usually low-rank (K < min(M,N)) but not necessarily so (in which case regularization constraints should apply on W and/or H). The decomposition (1) can then be inverted back to the time domain or post-processed in various ways to solve a variety of audio signal processing problems.\nIn this traditional setting, the STFT (or any regularly-paved time-frequency transform) acts as a pre-processing of the raw temporal data y. This is a potential limitation as any ill-chosen specification of the time-frequency transform may harm the quality of the decomposition. As such, we here propose to learn the transform together with the latent factors W and H. We propose to address this task by solving an optimization problem of the form\nmin φ,W,H\nD(|φ(y)|◦2|WH) (2)\nsubject to structure constraints on φ : RT → CM×N and to nonnegativity of W and H, and where D( · | · ) is a measure of fit.\nWe present the details of our approach and its connections with the state of the art in Section 2. Section 3 describes an algorithm\nthat returns stationary points of (2). Section 4 and 5 report results from music decomposition & speech enhancement experiments. In particular, we show that the proposed framework can significantly improve separation accuracy as compared to standard STFT-based NMF."
    }, {
      "heading" : "2. NMF MEETS TRANSFORM LEARNING",
      "text" : ""
    }, {
      "heading" : "2.1. Learning a short-time unitary transform",
      "text" : "As a first step, we propose in this paper to gently depart from the traditional STFT setting by restricting the transform φ(y) to be a short-time unitary transform, likewise the STFT. Let us denote by Y ∈ RM×N the matrix that contains adjacent & overlapping shorttime frames of size M of y and denote by ΦFT ∈ CM×M the unitary complex-valued Fourier matrix with coefficients [ΦFT]qm = exp (j2π(q − 1)(m− 1)/M). Under these notations, the power spectrogram of y is simply given by |ΦFTY|◦2. As such, traditional NMF may be cast as\nmin W,H\nD(|ΦFTY|◦2|WH) s.t. W ≥ 0,H ≥ 0, (3)\nwhere the notation A ≥ 0 expresses the nonnegativity of A. We propose in this work to relax the pre-fixed transform ΦFT and learn it jointly with W and H. This means we consider the following problem\nmin Φ,W,H\nD(|ΦY|◦2|WH) s.t. ΦHΦ = I,W ≥ 0,H ≥ 0. (4)\nWe choose at this stage to impose Φ to be unitary likewise the STFT though one could consider relaxing this assumption as well. The unitary constraint implicitly keeps Φ nonsingular and excludes trivial solutions such as (Φ,W,H) = (0,0,0) or (1M×M ,1M×1,11×M |Y|◦2), where 1M×N denotes the M × N matrix filled with ones. In this paper, we also choose the measure of fit D( · | · ) to be the Itakura-Saito (IS) divergence DIS(A|B) =∑ ij(aij/bij − log(aij/bij) − 1). Used with power spectral data, it is known to underly a variance-structured Gaussian composite model that is relevant to the representation of audio signals [3] and has proven an efficient choice for audio source separation, e.g., [4]. However, the proposed framework can accommodate any other measure of fit. We denote byC (Φ,W,H) = DIS ( |ΦY|◦2|WH\n) the IS-based objective function in problem (4). We refer to the objective described by (4) as TL-NMF, which stands for transformlearning NMF."
    }, {
      "heading" : "2.2. Connection to other works",
      "text" : "TL-NMF is inspired by the work of Ravishankar & Bresler [5] on learning sparsifying transforms. Given a collection of data samples Y (such as images collected in the columns of Y), their work\nar X\niv :1\n70 5.\n04 19\n3v 1\n[ cs\n.L G\n] 1\n1 M\nay 2\n01 7\nAlgorithm 1: TL-NMF Input : Y, τ Output: Φ, W, H s.t. |ΦY|◦2 ≈WH Initialize Φ, W and H while > τ do\nW←W ◦ ((WH) ◦−2◦|ΦY|◦2)HT\n(WH)◦−1HT % MM update [10]\nH← H ◦ W T ((WH)◦−2◦|ΦY|◦2)\nWT (WH)◦−1 % MM update [10]\nNormalize W and H to remove scale ambiguity Compute γ and Ω as in Section 3 Φ← π (Φ + γΩ) Compute stopping criterion as in Eq. (6)\nend\nconsist in finding an invertible transform Φ such that the output of ΦY is sparse. We are instead looking for a transform Φ such that |ΦY|◦2 can be well approximated by a NMF. Note that we could more generally consider the problem of finding Φ such that ΦY is low-rank.\nTL-NMF can be viewed as finding a one-layer factorizing network, where Y acts as the raw data, Φ the linear operator, | · |◦2 the nonlinearity and WH the output of the network. As future work, we could imagine fully bridging deep learning and NMF by looking for a cascade of decompositions fL(ΦL . . . f1(Φ1Y)) such that the output is a NMF. Some recent papers have combined deep learning and NMF but in a different way. For instance, [6] considers a discriminative NMF setting and [7] studies nonnegative auto-encoders.\nFinally, note that TL-NMF still operates in a transformed domain and is not directly related to synthesis-based NMF models in which the raw data y(t) is modeled as y(t) = ∑ k ck(t) where the spectrogram of ck(t) is penalized so as to be closely rank-one [8, 9]."
    }, {
      "heading" : "3. ALGORITHM",
      "text" : "We describe a block-coordinate descent algorithm that returns stationary points of problem (4). Like the objective function in (3), the objective function C (Φ,W,H) is nonconvex and the returned solution depends on initialization. The blocks are the individual variables W, H and Φ that are updated in turn until a convergence criterion is met. We use for W and H the standard multiplicative IS-NMF updates presented in, e.g., [10], that can be derived from a majorization-minimization procedure. Let us now turn our attention towards the update of Φ. We propose to use a gradient-descent procedure with a line-search step selection followed by a projection onto the unitary constraint, following the approach of [11]. The main benefit of this approach is that it yields an efficient yet simple algorithm for finding a unitary update for Φ.\nThe gradient of the objective function with respect to (w.r.t.) Φ is given by\n∇ def= ∇ΦC (Φ) = 2 (∆ ◦X)YT (5)\nwhere X = ΦY, ∆ = V̂◦−1 −V◦−1, V = |X|◦2, V̂ = WH. The steepest manifold-dependent descent direction is given by the natural gradient Ω = Φ∇HΦ − ∇. A suitable step-size γ is then chosen according to the Armijo rule so that the projection π (Φ + γΩ) of the updated transform onto the unitary constraint induces a significant decrease of the objective function [11].\nOur block-coordinate descent algorithm is stopped when the relative variation\n(i) = C(Φ(i),W(i),H(i))− C(Φ(i−1),W(i−1),H(i−1))\nC(Φ(i−1),W(i−1),H(i−1)) (6)\nbetween iteration i − 1 and i falls below a given threshold τ . The resulting TL-NMF algorithm is summarized in Algorithm 1. In our experiments, we used nonnegative random values for initializing W and H. The transform Φ is initialized with baseline STFT, i.e., Φ = ΦFT."
    }, {
      "heading" : "4. MUSIC DECOMPOSITION EXPERIMENT",
      "text" : "In this section, we report results obtained with the proposed algorithm for decomposing real audio data y(t) consisting of a 23s excerpt of Mamavatu by Susheela Raman that has been downsampled to fs = 16kHz. Y is constructed using 40ms-long, 50%- overlapping temporal segments that are windowed with a sine bell. This construction leads to M = 640 and N = 1191. The behavior of TL-NMF is compared to traditional IS-NMF, which we recall only amounts to TL-NMF with fixed transform ΦFT. The two algorithms are run with the same stopping threshold τ = 10−5 and arbitrary decomposition rank K = 6.\nFig. 1 displays the objective function values w.r.t. iterations for the two approaches. They are initialized with the same starting point so that they return the same objective value at iteration i = 0. Fig. 1 shows that the proposed algorithm enables to drastically reduce the objective value at convergence as compared to traditional IS-NMF: IS-NMF converges to a divergence of 6.7 × 105 while our variant reaches 5.5 × 104. This indicates that the proposed algorithm is effective in exploiting the extra flexibility offered by learning the transform Φ jointly with the factorization.\nWe now examine examples of the atoms returned by TL-NMF (rows φm of Φ). Fig. 2 displays the real and imaginary parts of the twelve atoms which most contribute to the audio signal, in the sense that they correspond to the twelve largest values of ||φmY||2. It can be observed on the one hand that TL-NMF learns basis elements that do not drastically deviate from the Fourier atoms in that they, e.g., tend to maintain a dominant oscillatory pattern close to the initial Fourier atom. On the other hand, the learnt atoms are also different in that they are neither smooth nor necessarily periodical. They do not necessarily respect phase-quadrature of the real and imaginary part nor respect the Hermitian symmetry that is inherent in ΦFT. Because we are dealing with a nonconvex problem and using a descent algorithm, the estimated transform Φ is inevitably dependent on its Fourier initialization. The effect of this initialization will be more thoroughly studied in future work. However it makes sense in this preliminary work to use ΦFT as the initialization as it corresponds to the traditional NMF setting."
    }, {
      "heading" : "5. SUPERVISED SOURCE SEPARATION",
      "text" : "In the previous section, we reported results of exploratory nature that show how TL-NMF is effective in learning a transform. We now examine whether learning an adaptive transform is actually usefully for source separation. To this end, we consider a supervised NMF-based separation setting that follows the approach of [12]. In the following we address the separation of speech from interfering noise, but the method can be applied to any classes of sound."
    }, {
      "heading" : "5.1. Principle",
      "text" : "We assume that we are given speech and noise training data ys(t) and yn(t) from which we form short-time matrices Ys and Yn of sizes M × Ns and M × Nn, as in Section 2.1. Given a noisy speech recording y(t) with short-time matrix Y, traditional supervised NMF amounts to estimating activation matrices Hs and Hn such that\nV ≈WsHs + WnHn, (7)\nsubject to sparsity of Hs and Hn, where V = |ΦFTY|◦2, Ws = |ΦFTYs|◦2, Wn = |ΦFTYn|◦2 [12]. Temporal source and noise estimates are then reconstructed in a second step by so-called Wiener filtering [3], based on the spectrogram estimates V̂s = WsHs and V̂n = WnHn.\nIn this section, we generalize this procedure by again learning an optimal transform within the separation procedure. To this end, we propose to build an approximation like Eq. (7) but where the fixed transform Φ = ΦFT is now relaxed and learnt together with Hs and Hn. This means we propose to minimize\nCe(Φ,Hs,Hn) def = DIS ( |ΦY|◦2 ∣∣ |ΦYs|◦2Hs + |ΦYn|◦2Hn) + λs||Hs||1 + λn||Hn||1 s.t. ΦHΦ = I,Hs ≥ 0,Hn ≥ 0. (8)\nThe sparsity-inducing `1 terms on Hs and Hn regularize the factorization which becomes potentially overcomplete in the event of large training datasets. Note how Φ now appears in both sides of the data-fitting term DIS(·|·) as the same transform is logically applied to the mixed data Y and the training data Ys and Yn. This requires to slightly modify the gradient of Ce w.r.t. Φ as compared to Section 2 and described in next section. After optimization, given V = |ΦY|◦2 along with speech and noise spectrogram estimates V̂s = |ΦYs|◦2Hs and V̂n = |ΦYn|◦2Hn, temporal estimates may still be produced with Wiener filtering, i.e.,\nŶs = Φ H ( V̂s V ◦ (ΦY) ) (9)\nfollowed by standard overlap-adding of the columns of Ŷs to return ŷs(t), and likewise for the noise. This is exactly the same procedure than in traditional NMF-based separation except that the Fourier and inverse-Fourier operations are replaced by Φ and ΦH ."
    }, {
      "heading" : "5.2. Algorithm",
      "text" : "Denote Ytrain = [Ys,Yn], Xtrain = ΦYtrain, W = |Xtrain|◦2, H =[ HTs ,H T n ]T and V̂ = WH. Given W, H can be updated with\nAlgorithm 2: Supervised TL-NMF Input : Y, Ytrain, τ Output: Φ, H Initialize Φ, H while > τ do\nV = |ΦY|◦2, W = |ΦYtrain|◦2 H← H ◦ W T ((WH)◦−2◦V)\nWT (WH)◦−1+[λs1N×Ns ,λn1N×Nn ] T\nCompute γ and Ω as in Section 5.2 Φ← π (Φ + γΩ) Compute stopping criterion\nend\nmultiplicative rules derived from majorization-minimization as in [10]. We use again a gradient-descent approach for the update of Φ. The gradient of the objective function (8) can be expressed as\n∇ΦCe (Φ,H) = 2 (∆ ◦X)YT + 2 (Ξ ◦Xtrain)YTtrain (10)\nwhere ∆ = V̂◦−1 − V◦−1 and Ξ = ∆eHT with ∆e = V̂−V V̂◦2\n. Note that the first term of Eq. (10) is the gradient in Eq. (5). The second term is nothing but the gradient of the data-fitting term DIS with its first argument fixed. Based on Eq. (10), we again use a line-search step selection in the steepest natural gradient direction followed by a projection, like in Section 3 and following [11]. The resulting algorithm is summarized in Algorithm 2."
    }, {
      "heading" : "5.3. Speech enhancement experiment",
      "text" : "We consider clean speech and noise data from the TIMIT corpus [13] and the CHIME challenge,1 respectively. For speech training data ys(t), we use all utterances but the first one in the train/fcjf0 directory (about 21s in total). For noise training data yn(t), we use 30s of the file BGD 150204 010 BUS.CH1.wav, which contains noise recorded in a bus. A simulated mixed signal y(t) of duration 3s is generated by mixing the remaining speech utterance with another segment of the noise file (as such, the test data is not included in the training data), using a signal-to-noise ratio of−10dB. The audio files sampling frequency is fs = 16kHz and short-term matrices Y, Ys and Yn are constructed using 40ms-long, 50%- overlapping windowed segments like in Section 4, leading to dimensions M = 640, N = 149, Ns = 1059 and Nn = 1517. The regularization parameters λs and λn are arbitrarily set to 102 and we again used τ = 10−5.\nOur supervised TL-NMF approach is compared to the traditional supervised NMF procedure (with the IS divergence) described in Section 5.1, based on the same training data and using the same regularization parameters (only the transform Φ differs between the two approaches). Source separation performance was assessed using the standard BSS eval criteria [14]. We also compute the performance criteria obtained by ŷs = ŷn = y/2 as an indicative baseline. Table 1 reports the comparison results. The results show that the extra adaptability offered by TL-NMF is clearly beneficial as far as source separation capabilities are concerned. Indeed, TL-NMF improves the signal to distortion, interference, and artifact ratios for the speech source by 4.3, 8.0 and 4.1dB, respectively, as compared to traditional IS-NMF. Interestingly, the noise\n1http://spandh.dcs.shef.ac.uk/chime_challenge\nseparation performance is very similar for TL-NMF and IS-NMF, indicating that the speech source is the one that principally benefits from the adaptive transform. The scores are dependent on the values of λs and λn but the speech separation performance of TLNMF was found superior to IS-NMF for all values we tested. This will be reported in a forthcoming long version of this paper.\nFig. 3 displays the values of the objective function Ce returned by supervised TL-NMF and supervised IS-NMF (in which case Φ = ΦFT). It clearly indicates that, at convergence, the value of the objective function obtained by the proposed algorithm is nearly one order of magnitude lower than that of IS-NMF: the latter algorithm makes the objective function reach a value of 9.5 × 104 (IS divergence of 6.8 × 104) while our algorithm brings the objective function value down to 1.5× 104 (IS divergence of 6.0× 103)."
    }, {
      "heading" : "6. CONCLUSION AND FUTURE WORK",
      "text" : "We addressed the task of learning the transform underlying NMFbased signal decomposition jointly with the factorization. Specifically, we have proposed a block-coordinate descent algorithm that enables us to find a unitary transform Φ jointly with the dictionary W and the activation matrix H. To our knowledge, the proposed algorithm is the first operational procedure for learning a transform in the context of NMF. Our preliminary experiments with real audio data indicate that automatically adapting the transform to the signal pays off when seeking latent factors that accurately represent the data. In particular, the improvement in data fit permits to achieve source separation performance that compares very favorably against the state-of-the-art. Note that although our presentation focused on the processing of audio data, the approach can be adapted to many other settings where NMF is applied to preprocessed data.\nFuture work will include studying the effect of the initialization of Φ, the influence of the value ofK on the learnt transform as well as relaxations of the unitary constraint on Φ, e.g., to nonsingular matrices Φ. Also, the use of alternative optimization strategies that lend themselves well to dealing with nonconvex problems in high dimension, including stochastic gradient descent, will be investigated."
    }, {
      "heading" : "7. REFERENCES",
      "text" : "[1] P. Smaragdis, C. Févotte, G. Mysore, N. Mohammadiha, and M. Hoffman, “Static and dynamic source separation using nonnegative factorizations: A unified view,” IEEE Signal Processing Magazine, vol. 31, no. 3, pp. 66–75, May 2014.\n[2] E. Vincent, N. Bertin, and R. Badeau, “Harmonic and inharmonic nonnegative matrix factorization for polyphonic pitch transcription,” in Proc. IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), 2008.\n[3] C. Févotte, N. Bertin, and J.-L. Durrieu, “Nonnegative matrix factorization with the itakura-saito divergence : With application to music analysis,” Neural Computation, vol. 21, no. 3, pp. 793–830, 2009.\n[4] B. King, C. Févotte, and P. Smaragdis, “Optimal cost function and magnitude power for NMF-based speech separation and music interpolation,” in Proc. IEEE International Workshop on Machine Learning for Signal Processing (MLSP), 2012.\n[5] S. Ravishankar and Y. Bresler, “Learning sparsifying transforms,” IEEE Transactions on Signal Processing, vol. 61, no. 5, pp. 1072–1086, 2013.\n[6] J. L. Roux, J. R. Hershey, and F. Weninger, “Deep NMF for speech separation,” in Proc. IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), 2015.\n[7] P. Smaragdis and S. Venkataramani, “A neural network alternative to non-negative audio models,” in Proc. IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), 2017.\n[8] C. Févotte and M. Kowalski, “Low-rank time-frequency synthesis,” in Advances in Neural Information Processing Systems (NIPS), 2014.\n[9] H. Kameoka, “Multi-resolution signal decomposition with time-domain spectrogram factorization,” in Proc. IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), 2015.\n[10] C. Févotte and J. Idier, “Algorithms for nonnegative matrix factorization with the β-divergence,” Neural Computation, vol. 23, no. 9, pp. 2421–2456, 2011.\n[11] J. H. Manton, “Optimization algorithms exploiting unitary constraints,” IEEE Transactions on Signal Processing, vol. 50, no. 3, pp. 635–650, 2002.\n[12] P. Smaragdis, B. Raj, and M. V. Shashanka, “Supervised and semi-supervised separation of sounds from single-channel mixtures,” in Proc. International Conference on Independent Component Analysis and Signal Separation (ICA), 2007.\n[13] J. S. Garofolo, L. F. Lamel, W. M. Fisher, J. G. Fiscus, and D. S. Pallett, “Timit acoustic-phonetic continuous speech corpus LDC93S1,” Philadelphia: Linguistic Data Consortium, Tech. Rep., 1993.\n[14] E. Vincent, R. Gribonval, and C. Févotte, “Performance measurement in blind audio source separation,” IEEE Transactions on Audio, Speech, and Language Processing, vol. 14, no. 4, pp. 1462–1469, 2006."
    } ],
    "references" : [ {
      "title" : "Static and dynamic source separation using nonnegative factorizations: A unified view",
      "author" : [ "P. Smaragdis", "C. Févotte", "G. Mysore", "N. Mohammadiha", "M. Hoffman" ],
      "venue" : "IEEE Signal Processing Magazine, vol. 31, no. 3, pp. 66–75, May 2014.",
      "citeRegEx" : "1",
      "shortCiteRegEx" : null,
      "year" : 2014
    }, {
      "title" : "Harmonic and inharmonic nonnegative matrix factorization for polyphonic pitch transcription",
      "author" : [ "E. Vincent", "N. Bertin", "R. Badeau" ],
      "venue" : "Proc. IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), 2008.",
      "citeRegEx" : "2",
      "shortCiteRegEx" : null,
      "year" : 2008
    }, {
      "title" : "Nonnegative matrix factorization with the itakura-saito divergence : With application to music analysis",
      "author" : [ "C. Févotte", "N. Bertin", "J.-L. Durrieu" ],
      "venue" : "Neural Computation, vol. 21, no. 3, pp. 793–830, 2009.",
      "citeRegEx" : "3",
      "shortCiteRegEx" : null,
      "year" : 2009
    }, {
      "title" : "Optimal cost function and magnitude power for NMF-based speech separation and music interpolation",
      "author" : [ "B. King", "C. Févotte", "P. Smaragdis" ],
      "venue" : "Proc. IEEE International Workshop on Machine Learning for Signal Processing (MLSP), 2012.",
      "citeRegEx" : "4",
      "shortCiteRegEx" : null,
      "year" : 2012
    }, {
      "title" : "Learning sparsifying transforms",
      "author" : [ "S. Ravishankar", "Y. Bresler" ],
      "venue" : "IEEE Transactions on Signal Processing, vol. 61, no. 5, pp. 1072–1086, 2013.",
      "citeRegEx" : "5",
      "shortCiteRegEx" : null,
      "year" : 2013
    }, {
      "title" : "Deep NMF for speech separation",
      "author" : [ "J.L. Roux", "J.R. Hershey", "F. Weninger" ],
      "venue" : "Proc. IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), 2015.",
      "citeRegEx" : "6",
      "shortCiteRegEx" : null,
      "year" : 2015
    }, {
      "title" : "A neural network alternative to non-negative audio models",
      "author" : [ "P. Smaragdis", "S. Venkataramani" ],
      "venue" : "Proc. IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), 2017.",
      "citeRegEx" : "7",
      "shortCiteRegEx" : null,
      "year" : 2017
    }, {
      "title" : "Low-rank time-frequency synthesis",
      "author" : [ "C. Févotte", "M. Kowalski" ],
      "venue" : "Advances in Neural Information Processing Systems (NIPS), 2014.",
      "citeRegEx" : "8",
      "shortCiteRegEx" : null,
      "year" : 2014
    }, {
      "title" : "Multi-resolution signal decomposition with time-domain spectrogram factorization",
      "author" : [ "H. Kameoka" ],
      "venue" : "Proc. IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), 2015.",
      "citeRegEx" : "9",
      "shortCiteRegEx" : null,
      "year" : 2015
    }, {
      "title" : "Algorithms for nonnegative matrix factorization with the β-divergence",
      "author" : [ "C. Févotte", "J. Idier" ],
      "venue" : "Neural Computation, vol. 23, no. 9, pp. 2421–2456, 2011.",
      "citeRegEx" : "10",
      "shortCiteRegEx" : null,
      "year" : 2011
    }, {
      "title" : "Optimization algorithms exploiting unitary constraints",
      "author" : [ "J.H. Manton" ],
      "venue" : "IEEE Transactions on Signal Processing, vol. 50, no. 3, pp. 635–650, 2002.",
      "citeRegEx" : "11",
      "shortCiteRegEx" : null,
      "year" : 2002
    }, {
      "title" : "Supervised and semi-supervised separation of sounds from single-channel mixtures",
      "author" : [ "P. Smaragdis", "B. Raj", "M.V. Shashanka" ],
      "venue" : "Proc. International Conference on Independent Component Analysis and Signal Separation (ICA), 2007.",
      "citeRegEx" : "12",
      "shortCiteRegEx" : null,
      "year" : 2007
    }, {
      "title" : "Timit acoustic-phonetic continuous speech corpus LDC93S1",
      "author" : [ "J.S. Garofolo", "L.F. Lamel", "W.M. Fisher", "J.G. Fiscus", "D.S. Pallett" ],
      "venue" : "Philadelphia: Linguistic Data Consortium, Tech. Rep., 1993.",
      "citeRegEx" : "13",
      "shortCiteRegEx" : null,
      "year" : 1993
    }, {
      "title" : "Performance measurement in blind audio source separation",
      "author" : [ "E. Vincent", "R. Gribonval", "C. Févotte" ],
      "venue" : "IEEE Transactions on Audio, Speech, and Language Processing, vol. 14, no. 4, pp. 1462–1469, 2006.",
      "citeRegEx" : "14",
      "shortCiteRegEx" : null,
      "year" : 2006
    } ],
    "referenceMentions" : [ {
      "referenceID" : 0,
      "context" : "In the latter field, it has led to state-of-the-art results in source separation [1] or music transcription [2].",
      "startOffset" : 81,
      "endOffset" : 84
    }, {
      "referenceID" : 1,
      "context" : "In the latter field, it has led to state-of-the-art results in source separation [1] or music transcription [2].",
      "startOffset" : 108,
      "endOffset" : 111
    }, {
      "referenceID" : 2,
      "context" : "Used with power spectral data, it is known to underly a variance-structured Gaussian composite model that is relevant to the representation of audio signals [3] and has proven an efficient choice for audio source separation, e.",
      "startOffset" : 157,
      "endOffset" : 160
    }, {
      "referenceID" : 3,
      "context" : ", [4].",
      "startOffset" : 2,
      "endOffset" : 5
    }, {
      "referenceID" : 4,
      "context" : "TL-NMF is inspired by the work of Ravishankar & Bresler [5] on learning sparsifying transforms.",
      "startOffset" : 56,
      "endOffset" : 59
    }, {
      "referenceID" : 9,
      "context" : "Initialize Φ, W and H while > τ do W←W ◦ ((WH) ◦−2◦|ΦY|◦2)HT (WH)◦−1HT % MM update [10] H← H ◦ W T ((WH)◦−2◦|ΦY|◦2) WT (WH)◦−1 % MM update [10] Normalize W and H to remove scale ambiguity Compute γ and Ω as in Section 3 Φ← π (Φ + γΩ) Compute stopping criterion as in Eq.",
      "startOffset" : 83,
      "endOffset" : 87
    }, {
      "referenceID" : 9,
      "context" : "Initialize Φ, W and H while > τ do W←W ◦ ((WH) ◦−2◦|ΦY|◦2)HT (WH)◦−1HT % MM update [10] H← H ◦ W T ((WH)◦−2◦|ΦY|◦2) WT (WH)◦−1 % MM update [10] Normalize W and H to remove scale ambiguity Compute γ and Ω as in Section 3 Φ← π (Φ + γΩ) Compute stopping criterion as in Eq.",
      "startOffset" : 139,
      "endOffset" : 143
    }, {
      "referenceID" : 5,
      "context" : "For instance, [6] considers a discriminative NMF setting and [7] studies nonnegative auto-encoders.",
      "startOffset" : 14,
      "endOffset" : 17
    }, {
      "referenceID" : 6,
      "context" : "For instance, [6] considers a discriminative NMF setting and [7] studies nonnegative auto-encoders.",
      "startOffset" : 61,
      "endOffset" : 64
    }, {
      "referenceID" : 7,
      "context" : "Finally, note that TL-NMF still operates in a transformed domain and is not directly related to synthesis-based NMF models in which the raw data y(t) is modeled as y(t) = ∑ k ck(t) where the spectrogram of ck(t) is penalized so as to be closely rank-one [8, 9].",
      "startOffset" : 254,
      "endOffset" : 260
    }, {
      "referenceID" : 8,
      "context" : "Finally, note that TL-NMF still operates in a transformed domain and is not directly related to synthesis-based NMF models in which the raw data y(t) is modeled as y(t) = ∑ k ck(t) where the spectrogram of ck(t) is penalized so as to be closely rank-one [8, 9].",
      "startOffset" : 254,
      "endOffset" : 260
    }, {
      "referenceID" : 9,
      "context" : ", [10], that can be derived from a majorization-minimization procedure.",
      "startOffset" : 2,
      "endOffset" : 6
    }, {
      "referenceID" : 10,
      "context" : "We propose to use a gradient-descent procedure with a line-search step selection followed by a projection onto the unitary constraint, following the approach of [11].",
      "startOffset" : 161,
      "endOffset" : 165
    }, {
      "referenceID" : 10,
      "context" : "A suitable step-size γ is then chosen according to the Armijo rule so that the projection π (Φ + γΩ) of the updated transform onto the unitary constraint induces a significant decrease of the objective function [11].",
      "startOffset" : 211,
      "endOffset" : 215
    }, {
      "referenceID" : 11,
      "context" : "To this end, we consider a supervised NMF-based separation setting that follows the approach of [12].",
      "startOffset" : 96,
      "endOffset" : 100
    }, {
      "referenceID" : 11,
      "context" : "subject to sparsity of Hs and Hn, where V = |ΦFTY|, Ws = |ΦFTYs|, Wn = |ΦFTYn| [12].",
      "startOffset" : 79,
      "endOffset" : 83
    }, {
      "referenceID" : 2,
      "context" : "Wiener filtering [3], based on the spectrogram estimates V̂s = WsHs and V̂n = WnHn.",
      "startOffset" : 17,
      "endOffset" : 20
    }, {
      "referenceID" : 9,
      "context" : "multiplicative rules derived from majorization-minimization as in [10].",
      "startOffset" : 66,
      "endOffset" : 70
    }, {
      "referenceID" : 10,
      "context" : "(10), we again use a line-search step selection in the steepest natural gradient direction followed by a projection, like in Section 3 and following [11].",
      "startOffset" : 149,
      "endOffset" : 153
    }, {
      "referenceID" : 12,
      "context" : "We consider clean speech and noise data from the TIMIT corpus [13] and the CHIME challenge, respectively.",
      "startOffset" : 62,
      "endOffset" : 66
    }, {
      "referenceID" : 13,
      "context" : "Source separation performance was assessed using the standard BSS eval criteria [14].",
      "startOffset" : 80,
      "endOffset" : 84
    } ],
    "year" : 2017,
    "abstractText" : "Traditional NMF-based signal decomposition relies on the factorization of spectral data which is typically computed by means of the short-time Fourier transform. In this paper we propose to relax the choice of a pre-fixed transform and learn a short-time unitary transform together with the factorization, using a novel block-descent algorithm. This improves the fit between the processed data and its approximation and is in turn shown to induce better separation performance in a speech enhancement experiment.",
    "creator" : "LaTeX with hyperref package"
  }
}