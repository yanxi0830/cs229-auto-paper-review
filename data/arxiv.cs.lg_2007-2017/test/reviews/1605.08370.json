{"conference": "NIPS", "VERSION": "v1", "DATE_OF_SUBMISSION": "26-May-2016", "title": "Provable Efficient Online Matrix Completion via Non-convex Stochastic Gradient Descent", "abstract": "Matrix completion, where we wish to recover a low rank matrix by observing a few entries from it, is a widely studied problem in both theory and practice with wide applications. Most of the provable algorithms so far on this problem have been restricted to the offline setting where they provide an estimate of the unknown matrix using all observations simultaneously. However, in many applications, the online version, where we observe one entry at a time and dynamically update our estimate, is more appealing. While existing algorithms are efficient for the offline setting, they could be highly inefficient for the online setting.", "histories": [["v1", "Thu, 26 May 2016 17:26:18 GMT  (35kb)", "http://arxiv.org/abs/1605.08370v1", null]], "reviews": [], "SUBJECTS": "cs.LG math.OC stat.ML", "authors": ["chi jin", "sham m kakade", "praneeth netrapalli"], "accepted": true, "id": "1605.08370"}
