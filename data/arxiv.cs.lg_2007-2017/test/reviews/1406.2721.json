{"conference": "ICML", "VERSION": "v1", "DATE_OF_SUBMISSION": "10-Jun-2014", "title": "Learning Latent Variable Gaussian Graphical Models", "abstract": "Gaussian graphical models (GGM) have been widely used in many high-dimensional applications ranging from biological and financial data to recommender systems. Sparsity in GGM plays a central role both statistically and computationally. Unfortunately, real-world data often does not fit well to sparse graphical models. In this paper, we focus on a family of latent variable Gaussian graphical models (LVGGM), where the model is conditionally sparse given latent variables, but marginally non-sparse. In LVGGM, the inverse covariance matrix has a low-rank plus sparse structure, and can be learned in a regularized maximum likelihood framework. We derive novel parameter estimation error bounds for LVGGM under mild conditions in the high-dimensional setting. These results complement the existing theory on the structural learning, and open up new possibilities of using LVGGM for statistical inference.", "histories": [["v1", "Tue, 10 Jun 2014 21:03:22 GMT  (436kb,D)", "http://arxiv.org/abs/1406.2721v1", "To appear in The 31st International Conference on Machine Learning (ICML 2014)"]], "COMMENTS": "To appear in The 31st International Conference on Machine Learning (ICML 2014)", "reviews": [], "SUBJECTS": "stat.ML cs.LG math.ST stat.TH", "authors": ["zhaoshi meng", "brian eriksson", "alfred o hero iii"], "accepted": true, "id": "1406.2721"}
