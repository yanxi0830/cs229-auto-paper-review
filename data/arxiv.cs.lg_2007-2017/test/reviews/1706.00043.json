{"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "31-May-2017", "title": "Biased Importance Sampling for Deep Neural Network Training", "abstract": "Importance sampling has been successfully used to accelerate stochastic optimization in many convex problems. However, the lack of an efficient way to calculate the importance still hinders its application to Deep Learning. In this paper, we show that the loss value can be used as an alternative importance metric, and propose a way to efficiently approximate it for a deep model, using a small model trained for that purpose in parallel.", "histories": [["v1", "Wed, 31 May 2017 18:25:09 GMT  (941kb,D)", "http://arxiv.org/abs/1706.00043v1", null], ["v2", "Wed, 13 Sep 2017 12:54:33 GMT  (1051kb,D)", "http://arxiv.org/abs/1706.00043v2", null]], "reviews": [], "SUBJECTS": "cs.LG", "authors": ["angelos katharopoulos", "fran\\c{c}ois fleuret"], "accepted": false, "id": "1706.00043"}
