{"conference": "ICML", "VERSION": "v1", "DATE_OF_SUBMISSION": "3-Apr-2017", "title": "On Kernelized Multi-armed Bandits", "abstract": "We consider the stochastic bandit problem with a continuous set of arms, with the expected reward function over the arms assumed to be fixed but unknown. We provide two new Gaussian process-based algorithms for continuous bandit optimization-Improved GP-UCB (IGP-UCB) and GP-Thomson sampling (GP-TS), and derive corresponding regret bounds. Specifically, the bounds hold when the expected reward function belongs to the reproducing kernel Hilbert space (RKHS) that naturally corresponds to a Gaussian process kernel used as input by the algorithms. Along the way, we derive a new self-normalized concentration inequality for vector- valued martingales of arbitrary, possibly infinite, dimension. Finally, experimental evaluation and comparisons to existing algorithms on synthetic and real-world environments are carried out that highlight the favorable gains of the proposed strategies in many cases.", "histories": [["v1", "Mon, 3 Apr 2017 06:47:42 GMT  (127kb,D)", "http://arxiv.org/abs/1704.00445v1", null], ["v2", "Wed, 17 May 2017 09:04:40 GMT  (127kb,D)", "http://arxiv.org/abs/1704.00445v2", null]], "reviews": [], "SUBJECTS": "cs.LG", "authors": ["sayak ray chowdhury", "aditya gopalan"], "accepted": true, "id": "1704.00445"}
