{"conference": "nips", "VERSION": "v1", "DATE_OF_SUBMISSION": "21-Mar-2017", "title": "One-Shot Imitation Learning", "abstract": "Imitation learning has been commonly applied to solve different tasks in isolation. This usually requires either careful feature engineering, or a significant number of samples. This is far from what we desire: ideally, robots should be able to learn from very few demonstrations of any given task, and instantly generalize to new situations of the same task, without requiring task-specific engineering. In this paper, we propose a meta-learning framework for achieving such capability, which we call one-shot imitation learning.", "histories": [["v1", "Tue, 21 Mar 2017 17:22:29 GMT  (4955kb,D)", "http://arxiv.org/abs/1703.07326v1", null], ["v2", "Wed, 22 Mar 2017 00:24:03 GMT  (4926kb,D)", "http://arxiv.org/abs/1703.07326v2", null]], "reviews": [], "SUBJECTS": "cs.AI cs.LG cs.NE cs.RO", "authors": ["yan duan", "marcin", "rychowicz", "bradly c stadie", "jonathan ho", "jonas schneider", "ilya sutskever", "pieter abbeel", "wojciech zaremba"], "accepted": true, "id": "1703.07326"}
