{"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "8-Jun-2016", "title": "Towards End-to-End Learning for Dialog State Tracking and Management using Deep Reinforcement Learning", "abstract": "This paper presents an end-to-end framework for task-oriented dialog systems using a variant of Deep Recurrent Q-Networks (DRQN). The model is able to interface with a relational database and jointly learn policies for both language understanding and dialog strategy. Moreover, we propose a hybrid algorithm that combines the strength of reinforcement learning and supervised learning to achieve faster learning speed. We evaluated the proposed model on a 20 Question Game conversational game simulator. Results show that the proposed method outperforms the modular-based baseline and learns a distributed representation of the latent dialog state.", "histories": [["v1", "Wed, 8 Jun 2016 14:03:25 GMT  (2922kb,D)", "http://arxiv.org/abs/1606.02560v1", "8 pages. Under peer review of to SigDial 2016"], ["v2", "Thu, 15 Sep 2016 21:50:30 GMT  (3036kb,D)", "http://arxiv.org/abs/1606.02560v2", "In proceeding of SIGDIAL 2016. Added changes based-on peer review, including: 1. Added references, 2. fixed typos in text and figures, 3. added minor change to introduction"]], "COMMENTS": "8 pages. Under peer review of to SigDial 2016", "reviews": [], "SUBJECTS": "cs.AI cs.CL cs.LG", "authors": ["tiancheng zhao", "maxine eskenazi"], "accepted": false, "id": "1606.02560"}
