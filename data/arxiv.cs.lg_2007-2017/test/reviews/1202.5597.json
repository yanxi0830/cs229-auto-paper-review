{"conference": "ICML", "VERSION": "v1", "DATE_OF_SUBMISSION": "25-Feb-2012", "title": "Hybrid Batch Bayesian Optimization", "abstract": "Bayesian Optimization aims at optimizing an unknown non-convex/concave function that is costly to evaluate. We are interested in application scenarios where concurrent function evaluations are possible. Under such a setting, BO could choose to either sequentially evaluate the function, one input at a time and wait for the output of the function before making the next selection, or evaluate the function at a batch of multiple inputs at once. These two different settings are commonly referred to as the sequential and batch settings of Bayesian Optimization. In general, the sequential setting leads to better optimization performance as each function evaluation is selected with more information, whereas the batch setting has an advantage in terms of the total experimental time (the number of iterations). In this work, our goal is to combine the strength of both settings. Specifically, we systematically analyze Bayesian optimization using Gaussian process as the posterior estimator and provide a hybrid algorithm that, based on the current state, dynamically switches between a sequential policy and a batch policy with variable batch sizes. We provide theoretical justification for our algorithm and present experimental results on eight benchmark BO problems. The results show that our method achieves substantial speedup (up to %78) compared to a pure sequential policy, without suffering any significant performance loss.", "histories": [["v1", "Sat, 25 Feb 2012 02:00:51 GMT  (210kb,D)", "https://arxiv.org/abs/1202.5597v1", null], ["v2", "Wed, 29 Feb 2012 01:55:33 GMT  (211kb,D)", "http://arxiv.org/abs/1202.5597v2", null], ["v3", "Tue, 1 May 2012 03:08:22 GMT  (214kb,D)", "http://arxiv.org/abs/1202.5597v3", null]], "reviews": [], "SUBJECTS": "cs.AI cs.LG", "authors": ["javad azimi", "ali jalali", "xiaoli zhang fern"], "accepted": true, "id": "1202.5597"}
