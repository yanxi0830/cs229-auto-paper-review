{"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "1-Jun-2016", "title": "On a Topic Model for Sentences", "abstract": "Probabilistic topic models are generative models that describe the content of documents by discovering the latent topics underlying them. However, the structure of the textual input, and for instance the grouping of words in coherent text spans such as sentences, contains much information which is generally lost with these models. In this paper, we propose sentenceLDA, an extension of LDA whose goal is to overcome this limitation by incorporating the structure of the text in the generative and inference processes. We illustrate the advantages of sentenceLDA by comparing it with LDA using both intrinsic (perplexity) and extrinsic (text classification) evaluation tasks on different text collections.", "histories": [["v1", "Wed, 1 Jun 2016 12:34:50 GMT  (77kb,D)", "http://arxiv.org/abs/1606.00253v1", null]], "reviews": [], "SUBJECTS": "cs.CL cs.IR cs.LG", "authors": ["georgios balikas", "massih-reza amini", "marianne clausel"], "accepted": false, "id": "1606.00253"}
