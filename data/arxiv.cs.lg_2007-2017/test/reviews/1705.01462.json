{"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "2-May-2017", "title": "Ternary Neural Networks with Fine-Grained Quantization", "abstract": "We propose a novel fine-grained quantization method for ternarizing pre-trained full precision models, while also constraining activations to 8-bits. Using this method, we demonstrate minimal loss in classification accuracy on state-of-the-art topologies without additional training. This enables a full 8-bit inference pipeline, with best reported accuracy using ternary weights on ImageNet dataset. Further, we also provide an improved theoretical formulation that forms the basis for a higher quality solution with this approach. Our method involves ternarizing the original weight tensor in groups of $N$ weights. Using $N=4$, we achieve Top-1 accuracy within $3.7\\%$ and $5.8\\%$ of the baseline full precision result for Resnet-101 and Resnet-50 respectively, while eliminating $75\\%$ of all multiplications. We also study the impact of group size on both performance and accuracy. With a group size of $N=64$, we eliminate $\\approx99\\%$ of the multiplications; however, this introduces a significant drop in accuracy, which necessitates fine tuning the parameters (re-training) at lower precision. To address this, we re-train Resnet-50 with 8-bit activations and ternary weights, improving the Top-1 accuracy to within $4\\%$ of the full precision result with $&lt;30\\%$ additional overhead. Our final quantized model can run on a full 8-bit compute pipeline using 2-bit weights and has the potential of up to $16\\times$ improvement in performance compared to baseline full-precision models.", "histories": [["v1", "Tue, 2 May 2017 10:15:21 GMT  (647kb,D)", "https://arxiv.org/abs/1705.01462v1", null], ["v2", "Thu, 11 May 2017 09:19:55 GMT  (652kb,D)", "http://arxiv.org/abs/1705.01462v2", null], ["v3", "Tue, 30 May 2017 17:10:24 GMT  (675kb,D)", "http://arxiv.org/abs/1705.01462v3", null]], "reviews": [], "SUBJECTS": "cs.LG cs.NE", "authors": ["naveen mellempudi", "abhisek kundu", "dheevatsa mudigere", "dipankar das", "bharat kaul", "pradeep dubey"], "accepted": false, "id": "1705.01462"}
