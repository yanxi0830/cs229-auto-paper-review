{"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "12-Jan-2016", "title": "Robobarista: Learning to Manipulate Novel Objects via Deep Multimodal Embedding", "abstract": "There is a large variety of objects and appliances in human environments, such as stoves, coffee dispensers, juice extractors, and so on. It is challenging for a roboticist to program a robot for each of these object types and for each of their instantiations. In this work, we present a novel approach to manipulation planning based on the idea that many household objects share similarly-operated object parts. We formulate the manipulation planning as a structured prediction problem and learn to transfer manipulation strategy across different objects by embedding point-cloud, natural language, and manipulation trajectory data into a shared embedding space using a deep neural network. In order to learn semantically meaningful spaces throughout our network, we introduce a method for pre-training its lower layers for multimodal feature embedding and a method for fine-tuning this embedding space using a loss-based margin. In order to collect a large number of manipulation demonstrations for different objects, we develop a new crowd-sourcing platform called Robobarista. We test our model on our dataset consisting of 116 objects and appliances with 249 parts along with 250 language instructions, for which there are 1225 crowd-sourced manipulation demonstrations. We further show that our robot with our model can even prepare a cup of a latte with appliances it has never seen before.", "histories": [["v1", "Tue, 12 Jan 2016 00:56:30 GMT  (7318kb,D)", "http://arxiv.org/abs/1601.02705v1", "Journal Version"]], "COMMENTS": "Journal Version", "reviews": [], "SUBJECTS": "cs.RO cs.AI cs.LG", "authors": ["jaeyong sung", "seok hyun jin", "ian lenz", "ashutosh saxena"], "accepted": false, "id": "1601.02705"}
