{"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "15-Jan-2014", "title": "Content Modeling Using Latent Permutations", "abstract": "We present a novel Bayesian topic model for learning discourse-level document structure. Our model leverages insights from discourse theory to constrain latent topic assignments in a way that reflects the underlying organization of document topics. We propose a global model in which both topic selection and ordering are biased to be similar across a collection of related documents. We show that this space of orderings can be effectively represented using a distribution over permutations called the Generalized Mallows Model. We apply our method to three complementary discourse-level tasks: cross-document alignment, document segmentation, and information ordering. Our experiments show that incorporating our permutation-based model in these applications yields substantial improvements in performance over previously proposed methods.", "histories": [["v1", "Wed, 15 Jan 2014 05:38:17 GMT  (319kb)", "http://arxiv.org/abs/1401.3488v1", null]], "reviews": [], "SUBJECTS": "cs.IR cs.CL cs.LG", "authors": ["harr chen", "s r k branavan", "regina barzilay", "david r karger"], "accepted": false, "id": "1401.3488"}
