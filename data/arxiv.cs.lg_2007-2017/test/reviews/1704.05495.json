{"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "18-Apr-2017", "title": "Investigating Recurrence and Eligibility Traces in Deep Q-Networks", "abstract": "Eligibility traces in reinforcement learning are used as a bias-variance trade-off and can often speed up training time by propagating knowledge back over time-steps in a single update. We investigate the use of eligibility traces in combination with recurrent networks in the Atari domain. We illustrate the benefits of both recurrent nets and eligibility traces in some Atari games, and highlight also the importance of the optimization used in the training.", "histories": [["v1", "Tue, 18 Apr 2017 18:46:12 GMT  (400kb,D)", "http://arxiv.org/abs/1704.05495v1", "8 pages, 3 figures, NIPS 2016 Deep Reinforcement Learning Workshop"]], "COMMENTS": "8 pages, 3 figures, NIPS 2016 Deep Reinforcement Learning Workshop", "reviews": [], "SUBJECTS": "cs.AI cs.LG", "authors": ["jean harb", "doina precup"], "accepted": false, "id": "1704.05495"}
