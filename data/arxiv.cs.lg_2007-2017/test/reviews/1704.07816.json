{"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "25-Apr-2017", "title": "Introspective Classifier Learning: Empower Generatively", "abstract": "In this paper we propose introspective classifier learning (ICL) that emphasizes the importance of having a discriminative classifier empowered with generative capabilities. We develop a reclassification-by-synthesis algorithm to perform training using a formulation stemmed from the Bayes theory. Our classifier is able to iteratively: (1) synthesize pseudo-negative samples in the synthesis step; and (2) enhance itself by improving the classification in the reclassification step. The single classifier learned is at the same time generative --- being able to directly synthesize new samples within its own discriminative model. We conduct experiments on standard benchmark datasets including MNIST, CIFAR, and SVHN using state-of-the-art CNN architectures, and observe improved classification results.", "histories": [["v1", "Tue, 25 Apr 2017 17:49:03 GMT  (1105kb,D)", "http://arxiv.org/abs/1704.07816v1", "11 pages, 6 figure"]], "COMMENTS": "11 pages, 6 figure", "reviews": [], "SUBJECTS": "cs.CV cs.LG cs.NE", "authors": ["long jin", "justin lazarow", "zhuowen tu"], "accepted": false, "id": "1704.07816"}
